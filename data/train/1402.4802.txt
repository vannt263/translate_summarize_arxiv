{
  "article_text": [
    "one of the latest and yet more profound evolutionary transitions involved the appearance of a new form of communication .",
    "human language represented the triumph of non - genetic information , in a scale and quality that allowed a virtually infinite repertoire of meaningful constructs out of a collection of basic lexical units .",
    "cultural evolution became a major player in shaping the character of human societies @xcite .",
    "it is fair to say that language , and human language in particular , has received the most dedicated multidisciplinary efforts .",
    "these include a vast range of fields , from genetics and anthropology to cognitive sciences , artificial intelligence or game theory . and yet",
    ", despite its undeniable importance , the origins of language remain largely unknown .",
    "moreover , a graded transition to this complex form of communication does not exist .",
    "it is a sharp , drastic change what mediates between human languages and other animal communication systems .",
    "this enormous gap makes difficult to retrieve information by comparing our tongues to any midway stages .",
    "we deal with a complex system that involves multiple scales and intricate interactions between levels and component units @xcite . as such , a proper approach to its complexity needs a framework that explicitly considers systemic properties .",
    "born by this complexity , language displays all kinds of apparently odd features , from the sometimes quirky appearance of syntactic rules to the ubiquitous presence of ambiguity .",
    "ambiguity is specially puzzling : it seems to make little sense when we consider language from an engineering perspective or even under a standard optimization view based on communicative pressures @xcite . under this view ,",
    "selection for comprehensible symbols would act removing unreliable components , thus reducing ambiguous features to the minimum .    following the optimization line of thought",
    ", the ultimate basis of our discourse will be that a _ least effort _",
    "principle is a driving force of languages .",
    "always focused on this argument , in this paper we present recent theoretical advances that share a common systems - level perspective of language structure and function .",
    "we adopt a non - reductionist approach towards human language @xcite that largely relies on a network view of its structure  closer to a structuralist view of evolution . within this view ,",
    "constraints and genuine , endogenous features manifest themselves promoting ( and being masked behind ) universal statistical regularities .",
    "the discussed theoretical arguments are preceded by the description and discussion of experimental facts  always following the same systemic approach  that clearly show the kind of universal traits that we refer to and that happen to pervade every known language .",
    "+ after discussing some striking empirical universal regularities of human language in sections [ sec:02 ] and [ sec:03 ] and their connections to ambiguity in section [ sec:04 ] we briefly present experimental support of the least effort argument and analyze in detail some of its theoretical consequences in sections [ sec:05 ] and [ sec:06 ] .",
    "we will also see how some of these consequences link back to the ever present statistical regularities mentioned earlier .",
    "finally , in section [ sec:07 ] we sketch out open questions and research lines that could further our understanding about the fascinating matter of human language .",
    "language structure has been very often contemplated under the perspective of word inventories .",
    "the properties of isolated words and how these properties can be used to classify them within given general groups provide a first way of studying language architecture . the abundance of words ,",
    "how they become adopted over language acquisition , or how different levels of language structure shape their relative importance define major research areas within linguistics . when exploring word inventories , one is faced with a dual character of languages that confronts the heterogeneity of tongues with the deep universality of a variety of their traits .",
    "so , on the one hand languages are diverse .",
    "this is reflected in several features displayed by its constituents .",
    "word inventories obviously differ from one dialect to another .",
    "many characteristics , such as the number of letters in a word  for example , show a statistical pattern with a distinctive single - hump distribution , but the average number of letters is rather different across languages . in mongolian or german",
    "this is close to 12 letters per word , whereas for croatian or serbian this drops down to around seven .",
    "the diversity in this trait might originate in historic contingencies idiosyncratic of each language and is not  a priori  the kind of universalities that we wish to study .",
    "on the other hand , it has been shown that all languages seem to share some remarkable universal patterns , best exemplified by the so called zipf s law @xcite .",
    "earlier noted by other authors , but popularized by g. k. zipf , this law states that the frequency of words in a given word inventory  such as the one we can obtain from a book  follows a universal power law .",
    "specifically , if we rank all the occurrences of words in a given text from the most to the less common one , zipf s law states that the probability @xmath0 that in a random trial we find the @xmath1-th most common word @xmath2 ( with @xmath3 ) falls off as : @xmath4 with @xmath5 and @xmath6 the normalization constant ",
    "i.e. , the sum @xmath7 .",
    "we can observe this regularity in any modern human language when analyzing any adequate corpus .",
    "this is the kind of traits that we are interested in , and of which we demand an explanation with the hope of gaining a deeper understanding about the origins of language or the constrains that shape it",
    ". +        roughly speaking , zipf s law tells us that the most frequent word will appear twice as often as the second most frequent word , three times as often as the third one , and so on . instead of using a word s rank ,",
    "an alternative form considers the use of the standard probability @xmath8 that we come across a word that is repeated @xmath9 times throughout a text .",
    "then the corresponding zipf s law scales as : @xmath10 where now the normalization constant is @xmath11 with @xmath12 the maximum observed frequency .",
    "now the scaling exponent is @xmath13 . in figure",
    "[ fig:02.01]*a * the frequency - rank distribution of words collected from herman melville s moby dick is shown in logarithmic scale .",
    "the scaling law @xmath14 is plotted against the rank @xmath15 . the logarithmic plot provides a direct way of testing the presence of a scaling law , since it gives a linear relationship : @xmath16 \\nonumber \\\\                      & = & \\log \\left [ \\frac{1}{z } \\right ] - \\gamma \\log k ,                   \\label{eq:02.03 }              \\end{aligned}\\ ] ] the slope of which is the scaling exponent @xmath17 .    the widespread , virtually universal presence of zipf s law in all known languages , and perhaps even in the context of dna and the genetic code @xcite suggests two potential interpretations .",
    "it might be the case that the observed scaling is so widespread that it is essentially a meaningless signal .",
    "( note the discussion about zipf s law in random texts @xcite . )",
    "the other possibility is that its universal presence has to do with some relevant feature shared by all languages , perhaps associated to some deep functional role . given the disparate trajectories followed by human languages over their evolution , it seems unlikely that such a unique scaling law would be so robust unless it involves a relevant constraint . + an additional component related to the logical organisation of language deals with its enormous combinatorial potential .",
    "language defines a non - genetic form of heredity and as such allows rapid cultural exchanges , the formation of a collective memory , and an enormous plasticity while facing environmental challenges .",
    "its success is tied to the brain s capacity for storing a large number of communication elements .",
    "however , an inventory of words can only be part of the whole story .",
    "another important aspect must be the associations that these units can build between them and that will be treated in more detail in the next section .",
    "let us explore first the scaling facet of such associativity to have a scope of the relevance of the generative power of language .",
    "words are combined and related to each other in multiple ways .",
    "such combinatorial potential pervades all linguistic levels from phonemes to whole texts .",
    "as we move towards higher levels , the potential universe of objects expands super - exponentially ( figure [ fig:02.01]*b * ) .",
    "we can appreciate this inflationary behavior explicitly when moving from words to sentences to texts .",
    "let us assume a set of words @xmath18 is sampled from the whole repertoire of words defining a language @xmath19 ( i. e. @xmath20 ) .",
    "our set @xmath21 is finite and involves @xmath22 words .",
    "of course the combinatorial nature of word arrangements easily explodes with @xmath23 .",
    "now consider a finite ( but long ) written text , to be indicated as @xmath24 .",
    "it is composed by a set of @xmath12 sentences @xmath25 , each one formed by an ordered , sequential collection of words extracted from @xmath26 : @xmath27 with @xmath28 and thus we have our text defined as the union : @xmath29 if we indicate by @xmath30 the length of a given sentence , the average sentence size in @xmath31 will be @xmath32 a very rough first approximation assuming that all components can be combined in similar ways",
    " i.e. leaving syntactic constrains aside  provides a total number of ( possible ) sentences as given by the power law : @xmath33 which gives , for @xmath34 and @xmath35 ( two reasonable estimates ) a hyperastronomic number : @xmath36 . in natural language",
    ", many of these combinations will never appear , most of words will be extremely rare and a few of them extremely frequent ( as we saw above ) since there exist nontrivial rules for a string of symbols make sense as a word of @xmath37 .",
    "the plausibility of a sentence existence and its frequency will be constrained as well because there are further nontrivial ( syntactic ) rules for the use of words from @xmath19 in a real context .",
    "nevertheless , this quick calculation allows us to grasp the scope of the expressive power of this system .",
    "the enormous potential for combination that is present in human language embodies the uniqueness of such complex form of communication .",
    "no other species in our planet shares such a spectacular capacity and a chasm seems to exist between us and all the other species inhabiting our planet .",
    "this uniqueness is also interesting for another reason .",
    "major innovations that have occurred through evolution have been found independently a number of times .",
    "multicellularity , sight or sex have emerged in many different groups through different paths @xcite thus indicating that the same basic innovations can be obtained following different paths . by contrast , our complex communication system that we use as a species , is unique @xcite .",
    "no othe rparallel experiments in evolution leading to such achievement have taken place .    however , storing words is one thing ; combining them , another ; and being able to relate each other in a flexible , efficient manner is yet another one .",
    "our potential for storing a large inventory of words together with an astonishing potential of relating them in complex ways through intricate paths ( sentences being just one of them ) is at the core of the evolutionary success of humans . in this paper",
    "we consider language organization in terms of a statistical physics picture , where networks instead of word inventories play a central role . by using them",
    ", we will argue that ambiguity is an expected feature of human language , and a specially relevant and perhaps inevitable one .",
    "it is ambiguity what hides behind zipf s law and an essential element that makes our use of language so efficient and flexible .",
    "in our previous illustration of the combinatorial potential of language , we used sentences as higher - order structures obtained as linear chains that combine words in syntactically meaningful ways . sentences provide us with a first example for the kind of recursive linguistic structures that we are capable of forming .",
    "they will also serve us to introduce networks and how language can be interpreted in terms of these complex webs .",
    "the simplest case of language network that can be introduced is defined in terms of co - occurrence @xcite .",
    "two words in a sentence that appear one after the other are said to co - occur .",
    "we will build a graph ( a network ) using these words and their co - occurrence as follows : words @xmath38 @xmath39 are the fundamental units , defining a set @xmath40 . the relationships between words are encoded in a matrix @xmath41 called the _",
    "adjacency matrix_. an undirected link @xmath42 will be defined between two words @xmath43 if they follow one another within at least one sentence ( otherwise the matrix element is set to @xmath44 ) . the resulting _ language production network _",
    "( lpn ) @xmath45 is thus defined as a pair @xmath46 , where @xmath41 constitutes the set of unweighted links of the graph .",
    "it should be noticed that the mapping @xmath47 is expected to capture some of the underlying rules of word ordering .",
    "this web provides in fact a glimpse to the production capacity of the underlying grammar structure and shares , as we will see below , a large number of common traits with syntactic webs @xcite .        in figure",
    "* we display an example of lpn network .",
    "this particular one has been obtained from the words that appear in paul auster s short story _",
    "augie wren xmas tale_. here spheres correspond to specific words and connections among them indicate that the pair of word co - occurred at least within one sentence throughout the tale .",
    "the size of the spheres has been increased in some cases to indicate their high frequency of appearance in the text .",
    "several interesting features need to be noticed .",
    "one is that the network is highly heterogeneous : a vast majority of words have only one or two links with others , whereas a small number of them ( the hubs ) have a very large number of connections .",
    "these super connectors can be seen in figure [ fig:03.01]*c * and correspond to words that are very common and highly ambiguous .",
    "figure [ fig:03.01]*b * gives us a glance of the  local \" organization stemming from the sentence structure .",
    "we can actually read well defined chains that make sense in a given direction .",
    "these readable chains become less and less common as the size of the word inventory grows and more and more crossings occur .",
    "a distribution of connections , or _ degree distribution _ @xmath48 , can be defined by measuring the number of links @xmath15 of each node ( also known as its degree ) and calculating the relative frequencies for each @xmath15 . in a randomly wired graph of @xmath49 nodes , where we simply connect every two elements with some probability @xmath50 the number of links associated to a randomly chosen word",
    "would follow a gaussian distribution , centered around the average degree value @xmath51 .",
    "we call such a graph _ homogeneous _ because the average value represents fairly well everything that can be awaited of the graph .",
    "but many real networks  including language graphs  follow a functional form that displays a scaling law , namely @xmath52 once again , we have @xmath53 and , for all lpn networks , @xmath54 .",
    "let us note once more the remarkable universality of this observation : for any language , from any adequate collection of sentences , despite the disparity that both elements ( languages and sentences  and collections of sentences , indeed ) can present we will derive such a degree distribution with roughly the same exponent @xmath55 ; just as if some inner mechanisms of the human language were eventually responsible of such scaling .",
    "as opposed to the gaussian , these kind of power law distributions feature an extreme variability that the average alone can not capture .",
    "this is a consequence of the existence of a miscellany of structures within the network .",
    "the real world example from auster s short story is shown in figure [ fig:03.01]*d * , where we have used ( to smooth out the statistics ) the cumulative distribution , defined as @xmath56 we find an exponent @xmath57 , which is actually the same that we observed in zipf s law ( in its frequency form ) .",
    "this is not surprising , since there is an almost perfect correlation between the frequency of a given word and the number of co - occurrences it can establish within @xmath40 .",
    "therefore , it could be argued that the only thing that matters is the frequency distribution of words : this would eventually determine the degree distribution . however , there is more to the structure of the network than this power law distribution of its degree @xmath15 . to appreciate it",
    "we must look at some other traits .",
    "a randomly connected graph following the previous @xmath48 scaling would not recover many observable properties exhibited by the original graph based on co - occurrence .",
    "as an example , there is a widespread feature that is present in the lpn and not in a randomized version of it : hubs are usually not connected in the former but they can be so in the later .",
    "this particular result tells us that , despite not being a true syntactic network , lpns do preserve some essential constraints associated to syntactic rules .",
    "there is another interesting property .",
    "the lpn graph is sparse : the average number of connections per word is small . despite this sparseness and the local organization suggested by the previous features ,",
    "the network is extremely well connected . in complex networks",
    "theory , this is known as a _ small world _ graph @xcite .",
    "small world networks were first analyzed by stanley milgram in the context of social ties within a country @xcite .",
    "it was found that only a small number of links separates , within the network of social acquaintances , two randomly chosen individuals . since a given country involves millions of humans , the basic result  that only about six jumps are needed ( on average ) to connect any two random persons  was highly surprising .",
    "this qualitative property can be quantified by means of the _ average path length _ ( @xmath58 ) defined as @xmath59 over all pairs @xmath60 , where @xmath61 indicates the length of the shortest path between two nodes . within the context of a lpn",
    ", a short path length means that it is easy to reach a given word @xmath62 starting from another arbitrary word @xmath63 .",
    "the path can not be interpreted here in terms of meaningful trajectories ( such as sentences ) but instead as a measure of accessibility .",
    "an additional measure of network organization that characterizes small world graphs is the so called _ clustering coefficient _ ( @xmath64 ) .",
    "it is defined as the probability that two vertices ( words , in out context ) that are neighbors of a given vertex are neighbors of each other as well . in order to compute the clustering",
    ", we associate to each word @xmath38 a neighborhood @xmath65 , defined as the set of words linked to @xmath38 , i. e. @xmath66 each word @xmath67 has co - occurred at least once with @xmath38 in some sentence .",
    "the words in @xmath65 can also be linked among them .",
    "the clustering @xmath68 of this set is defined as the fraction of triangles found , compared to the maximal number expected from an all - connected scenario .",
    "formally , it is given by : @xmath69 and the average clustering is simply @xmath70 .",
    "many triangles in a sparse graph indicate an excess in local richness of connections .",
    "such an excess needs to be compared with a null model of random connections among words ",
    "i.e. with a randomized version of the lpn as we did to compare the likelihood that the hubs are connected .    concerning the average path length , for random graphs with poissonian structure ",
    "i.e. with nodes simply connected with a probability @xmath50 and thus their degree distribution following the rather unremarkable gaussian distribution",
    " it is possible to show that we have a logarithmic growth in the number of degrees of separation with @xmath49 @xcite : @xmath71 whereas the clustering is expected to decay inversely with system size",
    " i. e. @xmath72    on a first approximation , it is said that a network is a _ small - world _",
    "when @xmath73 whereas the clustering coefficient is much larger @xmath74 @xcite .",
    "lpns happen to be small worlds , as remarked above .",
    "this nature of lpns and other language networks tells us that despite their locally ordered , correlated structure ( far from that of a random graph ) association and routing between words can be highly efficient .",
    "network theory does not offer a full explanation for the cognitive substrate responsible for word association and optimal search  this last property being related to the easy navigation that small worlds enable .",
    "this theory does provide , though , a valid formal framework within which relevant questions can be consistently stated .",
    "hopefully , the answers attained also constitute compelling knowledge about human language .",
    "the relational nature of language can be analyzed from different scopes .",
    "they include semantics , syntax , morphology and phonology @xcite .",
    "they define the different relationships between units and the structures made by such units .",
    "we saw a syntactic example in the previous section .",
    "moreover , at the community level social interactions also describe a web within which languages are enforced .",
    "this social structure can play a determinant role , for example , in the success or failure of a contingent linguistic trait and even in the emergence of further universal regularities @xcite .",
    "we see that network theory is not only useful but perhaps inescapable to understand our communication system .",
    "all these networks must somehow contain information concerning the way in which components  _ generally , but not necessarily , words _  are organized within sentences or how they are related in terms of their semantic content .",
    "the links can thus have a very different nature in each graph and the overall patterns of organization of such graphs do not need to be the same .    a prominent subfield of linguistics , semantics has been traditionally defined as the study of the meaning of ( parts of ) words , phrases , sentences , and texts .",
    "semantic organization is a widely explored topic in psycholinguistics . as a search for an adequate characterization of meaning ,",
    "semantic relations have strong ties with memory and categorization .",
    "semantic relations are also known to deteriorate in patients with alzheimer s disease and other types of brain impairment @xcite .",
    "such a semantic decline can also be appreciated in the kind of properties ( e.g. zipf s law ) that we are interested for other diseased patients @xcite .",
    "+        semantic networks can be built starting from individual words that lexicalise concepts and by then mapping out basic semantic relations such as isa - relations , part - whole , or binary opposition .",
    "they can potentially be built automatically from corpus data @xcite and also from retrieve experiments in which subjects are asked to quickly list down words as they come to their minds @xcite .",
    "one of the most interesting efforts in understanding the organization of semantic relationships is the wordnet project @xcite .",
    "this data set explicitly defines a graph structure where words from the english lexicon are connected through various kinds of semantic links .",
    "a possible subset of such kind of web is displayed in figure [ fig:04.01]*a*-*b*. as pointed out by sigman and cecchi @xcite mental concepts emerge as a consequence of their interrelationships , and meanings are often related through chains of semantic relations . linking `` stripes '' with `` lion",
    "'' requires following a mental path through a sequence of words , such as lion - feline - tiger - stripes @xcite .",
    "different paths are possible on a semantic network  as exemplified in figure [ fig:04.01]*a*-*b *  and experience shows that we find them easily despite the very large set of items potentially available .",
    "the efficient character of the semantic network is associated to an important , universal , and yet apparently undesirable property of language : polysemy .",
    "all languages exhibit polysemy , meaning that a given word form corresponds to two or more meanings . at first sight",
    "we would think that polysemy is a rather undesirable feature , since some ideal language should be expected to avoid such ambiguity .",
    "the analysis of the large - scale architecture of semantic networks reveals a likely reason for polysemy to exist and be so widespread .",
    "the answer lies on the global organization of these graphs which are both highly heterogeneous and exhibit the small world phenomenon .",
    "the network analysis of wordnet shows a scale - free structure ( figure [ fig:04.01]*c * ) where most elements would be more specialized , and thus semantically linked to just a few others . by contrast , a few of them would have a large number of semantic links .",
    "as before , we have a degree distribution @xmath75 , now with @xmath76 and thus a higher scaling exponent that indicates a much faster decay in the frequency of high - degree elements .",
    "this network is a small world _ provided that polysemy is included_. the high clustering found in these webs favors search by association , while the short paths separating two arbitrary items makes search very fast @xcite even if distant fields need to be reached .",
    "additionally , as discussed in @xcite , the scale - free topology of semantic webs places some constraints on how these webs ( and others mentioned above ) can be implemented in neural hardware . this is a remarkable example of how statistical regularities could be hiding a very relevant constrain of language evolution .",
    "to summarise , the mapping of language into networks captures novel features of language complexity far beyond word inventories .",
    "it provides further evidence for universal traits shared by all languages and how to characterise and measure them .",
    "more interestingly , they suggest novel ways of approaching old questions related to language efficiency and how it might have evolved .",
    "but they also allow us to formulate new questions that could not be expressed without using the network formalism . among them , how these network patterns might emerge and how they might be linked to zipf s law . in the next section , we will review a model of language evolution that also involves graphs and that is based on an early proposal by zipf himself .",
    "that model provides a first approximation to the potential components that make human language unique .",
    "it turns out that ambiguity might actually be a key component behind some of our more remarkable singularities .",
    "as we insisted throughout the text : statistic regularities are a narrow window that allows us to glimpse the existence of universal laws driving the emergence and evolution of human languages .",
    "zipf s law remains the most singular of such universal observations .",
    "opposed to partial collections of words  such as the analysis performed on _ moby dick _ in section [ sec:02 ]  a careful analysis of extensive corpora clearly indicates that the whole of a language does not feature the pattern observed by zipf @xcite . just a _ core vocabulary _ does so , but the observation remains universal anyway .",
    "furthermore , recent analysis indicate that diseased patients as well as lexicon not in the core might follow a version of zipf s law with a generalized exponent @xmath77 @xcite . in sight of this evidence",
    ", the general scientific intuition has a broad consensus about the importance of zipf s law and efforts to find model explanations to it do not diminish over time .    in its original account",
    ", zipf proposed that a tension between minimizing user s efforts and maximizing the communication power of a language would be the main driver towards the statistic regularity that he observed empirically , thus he coined the _ least effort language _",
    "principle @xcite .",
    "our main concern in this section is not necessarily zipf s law , but the least effort optimization as a mechanistic driving force  which , anyway , has been shown to be a mechanism for the generation of scale - free distributions @xcite .",
    "there are strong evolutionary reasons why a least effort principle might be acting upon human languages . to appreciate the selection for least effort in communication we can adopt any of two complementary view points  both of which",
    "are visited in @xcite . on the one hand",
    "we could argue that a human group with a more efficient code could enjoy an evolutionary advantage over other groups .",
    "those with less adequate dialects would be selected against and their tongues would perish with them .",
    "the other possibility is to look at each language as a system enduring natural selection .",
    "we can conceive different codes simultaneously spreading over a population . those fitter to be transmitted by humans ",
    "i.e. those better coping with our biological , social , and technological constrains  would be naturally selected for and become dominant . because the fitness now is the ease of tongues to humans we can see a least effort driving language evolution quite directly , not necessarily through an intermediate step of human selection .",
    "how can we approach language evolution from a sensible facet ?",
    "there are in principle multiple ways and scales of approximation that can be used .",
    "they span an enormous range of views , from game - theoretic models to computational linguistic or language evolution in embodied , robotic agents .",
    "perhaps the answer to previous questions needs to be tied to another , more basic one : what do we want to understand ? here",
    "we are concerned with ambiguity as part of the fabric of language organization .",
    "we would like to understand if ambiguity plays any role in how the previous scaling laws emerge and why there might be sharply defined classes of languages  perhaps separated by some sort of barrier  thus directly tackling the harsh gap between human and any other form of communication .",
    "following the steps indicated in @xcite , we will use zipf s least effort hypothesis to derive a model within which we can frame these kind of questions properly .",
    "we will ultimately study communication between pairs of agents sharing a given channel , so information theory ( as formulated by claude shannon ) is the natural framework .    in @xcite ,",
    "the tension between simplicity and communicative power proposed by zipf rests upon the trade - off between speaker and hearer s requirements of a language .",
    "the former prefers to name every possible object with the same signal ",
    "there lays their least effort to find an object s proper name  and the latter prefers to have a one - to - one mapping between available signals and existing objects , so that no decoding effort is necessary .",
    "note that the speaker s option is the most ambiguous language possible in which communication is not possible .",
    "meanwhile , the hearer s proposal is not degenerated at all .",
    "the conflicting needs of different users pose an evolutionary game for languages .",
    "these are modeled by allocations of available signals @xmath78 ( with @xmath79 ) to name existing objects @xmath80 ( with @xmath81 ) . the assignments that identify a given tongue",
    "are encoded in the entries of a matrix : @xmath82 with @xmath83 if signal @xmath2 refers to object @xmath84 and @xmath85 otherwise .",
    "signals ( indicated as @xmath86 ) with a set of @xmath9 objects or actions of reference ( @xmath87 ) . a simple case with @xmath88 is displayed .",
    "a signal is associated to an object using a link connecting them . here for example signal @xmath89 is used to refer to object @xmath90 . ,",
    "width=11 ]    similarly to the matrices introduced in section [ sec:03 ] , @xmath91 is known as an _ adjacency matrix _ ; only before it linked elements from within a set to one another and now it connects the constituents of two different sets , @xmath92 and @xmath93 , thus accounting for their relationships and other relevant features .",
    "a very important trait is related to the presence of ambiguity .",
    "as defined , the model and its matrix representation include both polysemy ( i. e. presence of multiple meanings associated to a given signal ) as well as synonymy , where different signals refer to the same object .",
    "the two traits can be detected by direct inspection of the rows and columns of the adjacency matrix .",
    "if we look at the example given in figure [ fig:05.01]*b * , using @xmath94 the matrix reads : @xmath95 the a matrix structure apprehends both the capacity for a signal to have multiple meanings ( by referring to multiple objects ) , and synonymy , where multiple signals refer to the same object .",
    "these two features are directly detectable here by looking at rows and columns within @xmath91 .",
    "synonyms are associated to vertical strings of ones , indicating that the same object @xmath96 can be labelled or referred to by multiple ( synonymous ) words .",
    "conversely , a polysemous word would correspond to a signal having multiple ones in a row .",
    "this contributes to the ambiguity of the language . in our example , @xmath90 is connected to three synonyms , whereas signal @xmath97 is used to label three different objects .",
    "in @xcite it is assumed that objects are recalled randomly with uniform frequency @xmath98 .",
    "a speaker then chooses from among the available signals that name the required object in its language @xmath82 , yielding a frequency for each signal : @xmath99 with @xmath100 .",
    "we will indicate the joint probability ( of having a signal and a given object ) and the corresponding probability of a given signal as : @xmath101 we can write the entropy associated to the signal diversity , which in the proposed framework stands for the effort of the speaker : @xmath102 recalling our needs of information theory , shannon s entropy @xmath103 provides a measure of the underlying diversity in the system .",
    "it is also a measure of uncertainty : the higher the entropy , the more difficult it is to predict the state of the system .",
    "for this reason @xmath104 is often considered a measure of randomness .",
    "its maximum value is obtained for a homogeneous distribution . in our case",
    ", it corresponds to @xmath105 for all signals involved : @xmath106 conversely , the lowest entropy is obtained for @xmath107 and @xmath108 . for this single - signal scenario",
    "we obtain @xmath109 .",
    "another key quantity involves the noise associated to the communication channel . using the definition of conditional probability ,",
    "namely @xmath110 we define a measure of noise associated to a given signal as follows : @xmath111 this entropy weights the uncertainty associated to retrieving the right object object from @xmath92 when signal @xmath2 has been used .",
    "the average uncertainty is obtained from : @xmath112 for simplicity , let us assume @xmath113 . if each signal were used to refer to a single and separated object , we could order our set of objects and signals so that @xmath114 where we define @xmath115 for @xmath116 and zero otherwise . in this case",
    ", it is easy to see that @xmath117 and thus no uncertainty would be present : given a signal , the right object can be immediately fetched without ambiguity .",
    "this corresponds to a perfect mapping between signals and meanings / objects .",
    "the opposite case would be a completely degenerate situation where a single signal @xmath118 is used to refer to all objects indistinctly .",
    "then @xmath119 for all @xmath120 . in this case",
    ", it can be shown that @xmath121  thus the uncertainty that the hearer faces is maximal .",
    "summing up , this conditional entropy @xmath122 works as the average ambiguity perceived by the hearer , and thus stands for its effort when _ decoding _",
    "language @xmath123 .",
    "finally , both communicative costs are collapsed into the following energy function : @xmath124 using this as a kind of  fitness \" function , an evolutionary search was performed in order to minimize @xmath125 .",
    "the minima obtained from this algorithm provide a picture of the expected graphs  as defined by the adjacency matrices  compatible with the least effort minimization principle .    along with the relative efforts defined above",
    ", two key properties were also measured .",
    "the first is the information transfer ( or mutual information ) obtained from : @xmath126 which plays a central role within information theory and is interpreted as _ how much information _ do signals convey about which object needs to be retrieved .",
    "the second is the effective lexicon size @xmath127 , i. e. the number of signals that are used to name objects .",
    "this was defined as @xmath128 where @xmath129 actually indicates whether or not the signal is being used .",
    "clearly the meta - parameter @xmath130 weights the importance of the hearer and speaker s needs . in @xcite",
    "a phase transition is uncovered at a certain value @xmath131 when varying @xmath130 between @xmath132 and @xmath133 , as it is illustrated in fig .",
    "[ fig:05.03 ] . for @xmath134",
    "the speaker s effort is minimized and completely ambiguous languages are persistently achieved .",
    "the @xmath91 matrix for the extreme case in a @xmath135 system would be @xmath136 as expected , in that scenario communication is impossible , given the complete degeneracy associated to the unique signal used to refer to every item within @xmath92 .",
    "this is revealed by the vanishing mutual information between signals and objects ( fig .",
    "[ fig:05.03]*a * ) .",
    "obviously the vocabulary requirements of this solution are minimal ( fig .",
    "[ fig:05.03]*b * ) .",
    "the word - object association graph that we would obtain is illustrated in figure [ fig:05.03]*c*.    for @xmath137 the one - to - one mapping preferred by the hearer ( fig .",
    "[ fig:05.03]*d * ) is always optimal . in this special case",
    ", the adjacency matrix for the signal - object association can be written in a diagonal form : @xmath138 most models of language evolution that explore the origins of communication under natural selection end up in finding these type of diagonal matrices.this is compared to animal communicative systems in @xcite .",
    "such systems present a non- degenerated mapping between objects and signals .",
    "the exhaustive vocabulary needs of this regime is illustrated in figure [ fig:05.03]*b*. this case would be favored in a scenario where few signals suffice for communication , and it would be restrained by the memory capacities of hearer and speaker . indeed , it has been shown how memory constrains could prompt the development of a fully articulated human language when vocabulary size overcomes a certain threshold @xcite so that units might be reused , but at the expense of making them ambiguous . in the least - effort framework proposed in @xcite , such a language would show up only at the phase transition @xmath139 .",
    "then , hearer and speaker s needs are equally taken into account , language instances with a moderate level of ambiguity are found , and communication is still possible  as the sharply varying mutual information between signals and objects around @xmath131 points out ( fig . [ fig:05.03]*a * ) .    in the original work @xcite the phase transition reported was of second order , meaning that the shift from non - communicative codes to one - to - one mappings was a smooth drift across several intermediate steps ",
    "any of them could be a relatively fit candidate of human language , not so urgently needing to tune @xmath130 to its critical value @xmath131 .",
    "but further investigation of the problem clearly indicates that the transition is of first order in nature and that @xmath140 ( for m = n ) , as figure [ fig:05.03 ] clearly shows .",
    "this means that the jump between the two extreme cases happens swiftly at @xmath141 , that a graduated range of possibilities that solve the optimization problem for @xmath142 does not exist , and that only at @xmath143 could we find a phenomenology akin to human language .",
    "the analysis in @xcite is complemented with an investigation of the frequency with which different signals show up for a given language in the model .",
    "this can be made thanks to equations [ eq:05.02 ] and [ eq:05.03 ] .",
    "remarkably , at the phase transition it was found that the frequency of different words obey zipf s law @xcite , thus closing the circle with one of the observations that opened our quest . +",
    "this work @xcite has been featured here for its historical importance in promoting the least - effort language agenda .",
    "however , its results have been contested and can not be held as correct anymore without a critical revision .",
    "the first and foremost claim has been that the algorithm employed in @xcite usually only achieves local minimization , thus the portrayed languages would not correspond to global least - effort codes @xcite .",
    "furthermore , when analyzing the global optima of the problem we find ourselves with a degenerated solution ",
    "i.e. multiple assignments between objects and signals optimize the trade - off between speaker and hearer needs at the phase transition @xcite .",
    "three observations are pertinent about these critics : i ) among the several solutions to the least - effort problem at the indicated phase transitions we find zipf s law as well @xcite .",
    "this is not the dominating solution , though  i.e. there are more solutions with some other frequency distribution of signals than solutions whose signal usage follows equations [ eq:02.01 ] and [ eq:02.02 ] @xcite .",
    "thus we would expect that when choosing randomly among all least - effort solutions for @xmath144 we would likely arrive to some other distribution but to zipf s .",
    "however , ii ) the original investigation of least - effort communicative systems and the framework that this model introduces remain valid and very appealing , even if they do not suffice to produce zipf s law .",
    "the least - effort principle has still got robust experimental and theoretical motivations , and we should not discard further forces operating upon language evolution that would select zipf s law against others . in such a case , the least - effort game described in this section would be just a sub - problem that language evolution has solved over time .",
    "finally , iii ) concerning the main topic of this volume ; even if zipf s law were not recovered , robust evidence exists indicating that the trade - off posed by the least - effort procedure is a way in of ambiguity into human language .",
    "the featured model has been furthered by successive works .",
    "the hunt for a robust mechanism that generates the zipf distribution continues and interesting proposals are being explored .",
    "a very promising one relies on the open - ended nature of human language @xcite .",
    "previous work by the same authors showed how zipf s law is unavoidable in a series of stochastic systems .",
    "a key feature of those systems is that they grow by sampling an infinite number of states @xcite .",
    "when applied to language , not only the unboundedness of human language is necessary but also the sempiternal least effort , so that zipf s law can be successfully obtained for communicating systems .",
    "interestingly , the approach in @xcite applies the least - effort principle upon the transition between stages of the language as it grows in size  by incorporating new signals to its repertoire .",
    "this explicit role of the contingent historical path is an interesting lead absent in the main body of literature .",
    "a slightly different research line followed by these authors uses the proposed model to quantify precisely how much information is lost due to the ambiguity of optimal languages when the trade - offs discussed above are satisfied @xcite .",
    "finally , several authors elaborate upon the model described above . in the critical review",
    "mentioned earlier @xcite it is noted how the original model is not sufficient to always derive zipf s law for the optimal model languages .",
    "the authors modify equation [ eq:05.08 ] and propose : @xmath145 as a target for minimization ; where @xmath146 is the mutual information between signals and objects in the sets @xmath93 and @xmath92 respectively .",
    "this new target becomes eq .",
    "[ eq:05.08 ] if all objects are equally probable .",
    "equation [ eq:05.13 ] is more adequate to `` better account for subtle communication efforts '' @xcite , as more costs implicit in equation [ eq:05.13 ] but absent in equation [ eq:05.08 ] are considered . in a follow up paper @xcite it",
    "is demonstrated how an ingredient to robustly derive zipf s law in their model is to take into account signal costs , which makes sense considering that different signals require different time , effort , or energy to be produced , broadcast , collected , and interpreted .",
    "this , as we will see in the following section , can also be an important element for the presence of ambiguity in human languages .",
    "several recent empirical observations illustrate an optimization force  that justifies our least effort point of view  acting upon different linguistic facets such as prosody , syntax , phonology , and many others @xcite .",
    "this evidence accumulates with other , previously shown global - level language organizational features epitomized by the properties of the small worlds ( sects .",
    "[ sec:03 ] and [ sec:04 ] ) .",
    "all this indicates that optimization principles and natural selection should play a paramount role to understanding human communication in a broad sense .",
    "as we have seen , entropies arise or need to be explicitly introduced with a twofold purpose : as a metric and as a specific optimization target .",
    "the ubiquity of this mathematical construct  that , we recall , gives a measure of degeneracy and , more specifically in our context , of degeneracy of meanings  is a first clue that the price to pay for a least effort language is ambiguity , as we will argue right below again and as suggested by the results from section [ sec:05 ] .    in @xcite a formalization of this trade - off between least - effort and ambiguity",
    "is presented .",
    "they argue that any optimal code will be ambiguous when examined out of context , provided the context offers redundant information ; and they do so presenting extremely elegant , easy , and powerful information theoretical arguments that apply beyond human communication .",
    "specially the first argument is of general validity for _ any communicative system _ within a context that is informative about a message .",
    "the two alternative  but similar  paths that the authors provide towards ambiguity are the following ( the quotes are from @xcite ) :    * _ `` where context is informative about meaning , unambiguous language is partly redundant with the context and therefore inefficient . '' _ + the authors conceive a space @xmath12 consisting of all possible meanings @xmath9 such that inferring a precise meaning out of a signal demands at least @xmath147 & = & -\\sum_{m\\in m}p(m)log\\{p(m)\\ }                              \\label{eq:06.01 }                          \\end{aligned}\\ ] ] bits of information , with @xmath148 the probability that meaning @xmath9 needs to be recalled .",
    "similarly , they assume a space @xmath64 that encompasses all possible contexts @xmath149 , compute the entropy of each meaning conditioned to happen within each context , and average over contexts : @xmath150 & = & \\sum_{c\\in c } p(c ) \\sum_{m\\in m } p(m|c)log\\{p(m|c)\\}.                               \\label{eq:06.02 }                          \\end{aligned}\\ ] ] this accounts for the average number of information ( in bits ) that a code needs to provide to tell apart different meanings within discriminative enough contexts .",
    "if context is informative it is likely that @xmath151>h[m|c]$ ] @xcite .",
    "+ with this in hand the authors have shown how `` the least amount of information that a language can convey without being ambiguous is @xmath152 $ ] '' , which is lower than @xmath151 $ ] ; thus any optimal code will seem ambiguous when examined out of context and any unambiguous code will be suboptimal in that it produces more information than strictly necessary .",
    "+ note once more the elegance of the argument and its generality : no requirements are made about the meanings or the contexts , and the later are general enough as to include any circumstance of any kind affecting communication in any way . *",
    "_ `` ambiguity allows the re - use of words and sounds which are more easily produced or understood . '' _",
    "+ this second argument only diminishes in generality because the authors must consider that different signals in a code vary in cost ",
    "i.e. that they are not of equal length or complexity , or that distinct signs require different amount of effort when they are used .",
    "this becomes obvious in human speech , e.g. , considering the longer time that larger words demand .",
    "note anyway that this is a quite general scenario still affecting most conceivable communicative systems and , of course , any kind of human communication .",
    "+ the argument acknowledges that it is preferable to use simpler signals .",
    "then , ambiguity enables us to re - use the same signal in different contexts , assuming always that the context provides the needed disambiguation .    according to these ideas , that optimal codes are ambiguous",
    "if the context is informative does not imply that human languages must be ambiguous , neither that any ambiguous coding is more optimal than any unambiguous one .",
    "however , ambiguity  say polysemy , in certain contexts , but not only  is an extremely extended phenomenon in human language when tongues are analyzed out of context , and the authors propose that such simple yet forceful reasoning explains its pervasiveness . in previous sections a much stronger point was made based on empirical observations : this polysemy not only does exist , but it also shapes the structure of tongues such that a global order arises in many aspects of it ( e.g. semantic networks ) , and such that it presents very convenient features that render human language optimal or very effective ( e.g. for semantic navigation ) .",
    "thus not only ambiguity is present , it seems to be of a very precise kind in order to comply with several optimization needs at a same time , such as zipf s least effort paradigm proposed @xcite .",
    "the models and real networks presented above provide a well - defined theoretical and quantitative framework to address language structure and its evolution .",
    "the sharp transition between non - communicative and communicative phases is a remarkable finding  and the fact that intuitive models can reproduce this feature is impressive .",
    "this suggests that a fundamental property associated to the least effort minimization principle involves an inevitable gap to be found among its solutions .",
    "from another perspective , both real language networks and the simple graphs emerging from the least effort algorithm(s ) introduce ambiguity as a natural outcome of their heterogeneous nature .    while the path explored this far invites us to be optimistic , several open problems arise from the results reviewed .",
    "these will require further research until a complete picture of human language  beyond the role of ambiguity ",
    "is attained .",
    "here is a tentative list of open issues :    1 .",
    "both the topological analysis of semantic networks and what can be proposed from simple models are typically disconnected from an explicit cognitive substrate .",
    "some remarkable works on semantic webs have shown that the structure of semantic webs includes a modular organization where groups of semantically related words are more connected among them than with other items .",
    "individuals mentally searching on this space seem to make fast associations between items within modules as well as seemingly random jumps between modules @xcite .",
    "the pattern of search is actually related to the ways search is performed on computer networks .",
    "moreover , there is a literature on neural network models of semantic association @xcite that could be explored in order to see how the space of neural attractors and the underlying categorization emerging from them are linked to a semantic network .",
    "models of damage in semantic webs ( using topological methods ) already suggest that relevant information might be obtained in relation with the process of cognitive decay associated to some neurodegenerative diseases @xcite .",
    "a very promising field within language evolution involves using embodied agents ( robots or physical simulations of them ) that are capable of learning , memory , and association @xcite .",
    "a protogrammar has been shown to emerge in these embodied communicating agents @xcite .",
    "the study of lexical and grammatical processing in these robotic agents using so called fluid construction grammars ( fcgs ) @xcite reveals that language evolution might take place by optimizing lexicon size and the construction structures in order to minimize search . more traditional approaches to computer languages  as in programming languages  explicitly reject ambiguity for the challenges it presents .",
    "it is made clear that fcgs seek more malleable structures ( thus the _ fluid _ ) , ready to evolve and be adopted and adapted by a population  in this case , of robots .",
    "the population is usually not expected to share the exact same grammatic structure as it emerges , thus clearing a path for ambiguity .",
    "notwithstanding this , part of the problems solved by this novel approach is one of reducing ambiguity out of the messages being interchanged by the talking agents @xcite . also , the emergence of grammatical rules is a direct consequence of this ambiguity reduction @xcite .",
    "3 .   in all studies",
    "so far developed , models of language evolution involve only one type of network level of description .",
    "however , semantic , syntactic and even phonologic levels interact and any relevant analysis should include several network levels .",
    "how are different networks connected to each other ? what is the impact of their special topological and scaling properties on the global behavior of language as a whole",
    "statistical physics is at the core of many of the approximations considered in this paper . despite the biological nature of language and its historical origins , we have seen that some strong regularities are inevitable and are more fundamental than we would expect .",
    "there are many other ways of approaching language structure using these methods , including the analysis of language ontogeny @xcite and the structure of syntactic networks .",
    "available evidence from data and models suggests that , once zipf s law is at work , a number of well known regularities exhibited by syntax graphs are obtained @xcite .",
    "this would be consistent with an evolutionary scenario where syntax might come for free , as a byproduct of possibly inevitable features of correlations among words following zipf s law @xcite .",
    "the idea is appealing and worth researching and , once again , complex networks and information theory might provide a valid framework .",
    "5 .   a twin problem to that of ambiguity is revealed when we consider synonymy .",
    "this trait might be a contingency , and it is considered rare by scholars @xcite .",
    "indeed , while different models account for it @xcite , all of them predict that synonymy should not be present in optimal languages or languages in equilibrium ; but yet we observe some degree of synonymy in every human code .",
    "altmann , eduardo g. , giampaolo cristadoro , and mirko degli esposti .",
    "`` on the origin of long - range correlations in texts . '' proceedings of the national academy of sciences 109 , no .",
    "29 ( 2012 ) : 11582 - 11587 .",
    "chan , agnes s. , nelson butters , and david p. salmon .",
    "`` the deterioration of semantic networks in patients with alzheimer s disease : a cross - sectional study . '' neuropsychologia 35 , no . 3 ( 1997):241 - 248 .          corominas - murtra , bernat , sergi valverde , and ricard sole .",
    "`` the ontogeny of scale - free syntax networks : phase transitions in early language acquisition . '' advances in complex systems 12 , no .",
    "03 ( 2009 ) : 371 - 392 .",
    "ferrer i cancho , ramon , and ricard v. sol .",
    " two regimes in the frequency of words and the origins of complex lexicons : zipf s law revisited",
    ". \" journal of quantitative linguistics 8 , no . 3 ( 2001 ) : 165 - 173 .",
    "ferrer i cancho , ramon , oliver riordan , and bla bollobs .",
    "`` the consequences of zipf s law for syntax and symbolic reference . ''",
    "proceedings of the royal society b : biological sciences 272 , no .",
    "1562 ( 2005 ) : 561 - 565 .",
    "ferrer i cancho , ramon , and albert daz - guilera .",
    "`` the global minima of the communicative energy of natural communication systems . '' journal of statistical mechanics : theory and experiment 2007 , no . 06 ( 2007 ) : p06009 .",
    "goi , joaqun , gonzalo arrondo , jorge sepulcre , iigo martincorena , vlez de mendizbal , nieves , corominas - murtra , bernat , bejarano , bartolom et al .",
    "`` the semantic organization of the animal category : evidence from semantic verbal fluency and network theory . '' cognitive processing 12 , no . 2 ( 2011 ) : 183 - 196 .",
    "holanda , adriano de jesus , ivan torres , osame kinouchi , alexandre souto , and evandro e. seron .",
    "`` thesaurus as a complex network . ''",
    "physica a : statistical mechanics and its applications 344 , no . 3 ( 2004 )",
    ": 530 - 536 .",
    "huth , alexander g. , shinji nishimoto , an t. vu , and jack l. gallant .",
    "`` a continuous semantic space describes the representation of thousands of object and action categories across the human brain . ''",
    "neuron 76 , no . 6 ( 2012 ) : 1210 - 1224 .",
    "kinouchi , osame , alexandre s. martinez , gilson f. lima , g. m. loureno , and sebastian risau - gusman .",
    "`` deterministic walks in random networks : an application to thesaurus graphs . ''",
    "physica a : statistical mechanics and its applications 315 , no . 3 ( 2002 ) : 665 - 676 .",
    "mantegna , r. n. , s. v. buldyrev , a. l. goldberger , s .",
    "havlin , c. k. peng , m. simons , and h. e. stanley .",
    "`` linguistic features of noncoding dna sequences . '' physical review letters 73 , no . 23 ( 1994 ) : 3169 .",
    "petersen , alexander m. , joel n. tenenbaum , shlomo havlin , h. eugene stanley , and matja perc .",
    "`` languages cool as they expand : allometric scaling and the decreasing need for new words . ''",
    "scientific reports 2 ( 2012 ) .",
    "sol , ricard v. , bernat corominas - murtra , and jordi fortuny .",
    "`` diversity , competition , extinction : the ecophysics of language change . ''",
    "journal of the royal society interface 7 , no .",
    "53 ( 2010 ) : 1647 - 1664 .",
    "steels , luc , and joachim de beule . `` a ( very ) brief introduction to fluid construction grammar . '' in proceedings of the third workshop on scalable natural language understanding , pp .",
    "association for computational linguistics , 2006 ."
  ],
  "abstract_text": [
    "<S> human language defines the most complex outcomes of evolution . </S>",
    "<S> the emergence of such an elaborated form of communication allowed humans to create extremely structured societies and manage symbols at different levels including , among others , semantics . </S>",
    "<S> all linguistic levels have to deal with an astronomic combinatorial potential that stems from the recursive nature of languages . </S>",
    "<S> this recursiveness is indeed a key defining trait . </S>",
    "<S> however , not all words are equally combined nor frequent . in breaking the symmetry between less and more often used and between less and more meaning - bearing units , </S>",
    "<S> universal scaling laws arise . </S>",
    "<S> such laws , common to all human languages , appear on different stages from word inventories to networks of interacting words . among these seemingly universal traits exhibited by language networks , ambiguity appears to be a specially relevant component . </S>",
    "<S> ambiguity is avoided in most computational approaches to language processing , and yet it seems to be a crucial element of language architecture . here </S>",
    "<S> we review the evidence both from language network architecture and from theoretical reasonings based on a least effort argument . </S>",
    "<S> ambiguity is shown to play an essential role in providing a source of language efficiency , and is likely to be an inevitable byproduct of network growth . </S>"
  ]
}