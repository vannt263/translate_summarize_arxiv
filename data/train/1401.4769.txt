{
  "article_text": [
    "a common characteristic of massive data sets whose major purpose of study is to discover the association between response and predictors is that the number of predictors is larger than the number of independent individuals .",
    "although linear regression or its generalizations are useful tools to detect associations , some computational and theoretical issues are still remained unsolved for massive data .",
    "many statistical approaches have been developed during the past two decades in many aspects . in this work ,",
    "we concentrate on the screening problem for binary response regressions . considering all predictors in one linear model",
    "is not practical without placing restrictions on the parameter space . instead , one may design screening statistics to rule out unimportant predictors before building final models .",
    "a screening statistic is defined as a surrogate measure of the underlying association between the response and a predictor .",
    "fan and lv ( 2008 ) and fan and song ( 2010 ) propose the concept of  sure screening \" : a screening statistic possesses the sure screening property if that the statistic is relatively small if the true association is negligible or 0 .",
    "their sure independence screenings were designed toward this end .",
    "fan and lv ( 2008 ) proposes the sure independence screening ( sis ) for linear regression .",
    "they choose the predictors with large absolute covariances between response and predictors as important predictors and then build final regression models based on these important predictors . as we will show later , the covariance is proportional to the slope of the simple linear regression so hereafter , we use slope instead of covariance if there is no confusion .",
    "the computation of sis is extraordinarily fast because it only involves centering and inner products but no matrix inversion .",
    "note that when the term  linear regression \" is applied , we generally presume that the response is continuous or more restrictively , the response follows normal distribution . either way",
    ", least - square estimation can be applied to estimate the regression coefficients .",
    "one of our major interest is the consequence of applying least - square estimation to binary response data . as we will show later , under some conditions , it is useful for screening but not for estimation and prediction .",
    "for binary response regressions , it is popular to choose logit , probit or complementary log - log link function ( mccullagh and nelder , 1989 ) to formulate the likelihood .",
    "many statistical softwares perform estimation and testing tasks well . however , there are two major issues on using these models .",
    "first , the choice of link function is essential to estimation science different link functions yield different regression coefficient estimates .",
    "li and duan ( 1989 ) proves that , the maximum likelihood estimate ( mle ) is consistent to the true regression coefficient up to an unknown constant when the link function is misspecified .",
    "so , when the true link function is unknown , the regression coefficient estimates is always questionable .",
    "second , the mle of regression coefficient is sometimes unidentifiable , unique or finite mle does not exist ( albert and anderson , 1984 ) .",
    "these two reasons urge us to find a computational efficient procedure for screening rather than merely using traditional logistic or probit regressions .",
    "the rest of this article is arranged as follows . in section 2",
    ", we review some useful results of linear model as well as the sure independence screening in linear model ( fan and lv , 2008 ) and in generalized linear regression ( fan and song , 2010 ) .",
    "moreover , we show that , for binary response regressions , the screening statistics of both sis and the newly proposed least - square screening ( less ) converge in probability to its linear model counterpart up to a constant when the predictors follow multivariate normal and the link function belongs to a class of scale mixture of normals .",
    "simulation and data analysis are shown in section 4 followed by our concluding remarks in section 5 .",
    "we begin with matching parameters of the true model and parameters of working models .",
    "consider the linear model @xmath0 where @xmath1 , @xmath2 follows @xmath3 , and @xmath4 and @xmath5 s are independent .",
    "assume that not all of @xmath6 s are 0 .",
    "denote @xmath7 and @xmath8 as the @xmath9 element of @xmath10 .",
    "let ( [ eq : truemodel ] ) be the true model and call the predictors with non - zero ( zero ) regression coefficients as active ( inactive ) predictors .",
    "as taught in the first course of linear regression , the least - square estimator of the slop of the working model @xmath11 converges in probability to @xmath12 and hence @xmath13 where @xmath14 , @xmath15 , and @xmath16 is a diagonal matrix with diagonal elements @xmath17 .    for a more general case ,",
    "let the working model be @xmath18 where @xmath19 .",
    "define @xmath20 and @xmath21 and partition the regression coefficient vector as @xmath22 where @xmath23 and @xmath24 are regression coefficients corresponding to @xmath25 and @xmath26 , respectively .",
    "further , define the partition of the variance covariance matrix as @xmath27\\ ] ] with respect to @xmath25 and @xmath26 , too",
    ". then we have @xmath28 which implies that the least - square estimate of the working model ( [ eq : working1 ] ) converges in probability to @xmath29 this suggests that @xmath30 if either @xmath31 or @xmath32 which is actually the partial orthogonality condition defined in huang , horowitz and ma ( 2008 ) .",
    "in other words , to successfully estimate regression coefficients ( @xmath33 ) without contamination ( @xmath34 ) , a subset of predictors , say @xmath25 , should be chosen so that @xmath25 and @xmath26 are uncorrelated or none of predictors in @xmath26 is active . note that , the multiple regression with @xmath35 predictors is a misspecified model for the true model ( [ eq : truemodel ] ) as long as these @xmath35 predictors do not include all active predictors .",
    "a well - known result in linear model literature is that if the working model is misspecified , the least - square estimator of the regression coefficient is biased .",
    "the asymptotic bias can be quantified explicitly by ( [ eq : main ] ) . however , to our best knowledge , there is no such expression under binary response regressions .",
    "the score equation is applied to link the true model parameters and the maximum likelihood estimates of the parameter under a specific misspecified model .",
    "suppose the true model is @xmath36 and @xmath37 , where @xmath38 is the so called logit link .",
    "assume that the true link is known and a simple working model @xmath39 is specified .",
    "consequently , the score function converges in probability to @xmath40 and thus , the maximum likelihood estimator of @xmath41 converges to @xmath42 such that @xmath43=      e\\left [ x_1 \\frac{1}{1+\\exp\\{-\\gamma_0 - \\sum_{j=1}^p x_j\\gamma_j\\ } } \\right ]      - e\\left[x_1 \\frac{1}{1+\\exp\\{-\\beta_0^{ml } - \\beta_1^{ml } x_1\\ } } \\right]\\ ] ] so the relationship between the true model and working model can be quantified by these two expectations .",
    "the calculation of these expectations are not trivial and their numerical evaluations had been studies by crouch and spiegelman ( 1990 ) and monahan and stefanski ( 1992 ) .",
    "one of the major contribution is providing a closed - form expression of these expectations .",
    "it is worth to emphasize that @xmath44 in general and we wish to express @xmath45 in terms of true parameter values @xmath46 s like ( [ eq : main ] ) .",
    "hereafter , denote @xmath47 and @xmath48 as the probability density function ( _ p.d.f . _ ) and cumulative distribution function ( _ c.d.f . _ ) of the standard normal distribution , respectively , and denote @xmath49 as the density function of the normal distribution with mean @xmath50 and variance @xmath51 .",
    "now , we derive the relationship between the regression coefficient of the true model and of the working model for binary response regression models .",
    "let the true model be @xmath52 and the working model be @xmath53 where a function with the subscript @xmath54 means that the function is unknown but one is posited to it , and the function with subscript @xmath55 means that the function is the underlying function .",
    "moreover , we require that @xmath56 as well as @xmath57 is a valid _ c.d.f . _ with the form of scale normal mixture @xmath58 and @xmath59 is a valid density function for either continuous or discrete @xmath60 .",
    "this implies that @xmath61 is a symmetric _ p.d.f . _",
    "such an @xmath62 can be the _",
    "_ of gaussian , logistic , double exponential , student-@xmath63 ( andrews and mallows , 1974 ) , exponential power family ( box and tiao , 1973 ; west , 1987 ) and others .",
    "hereafter , @xmath64 s should satisfy 1 ) @xmath65 , 2 ) @xmath59 is a valid density function , and 3 ) @xmath66 for every @xmath67 and @xmath68 . a sufficient and necessary condition for the existence of @xmath59 is provided by andrews and mallows ( 1974 ) .",
    "following is one of our major conclusion and it is the result of lemma [ lm : ab00 ] and lemma [ lm : probit ] .",
    "theirs proofs are deferred to appendix a. theorem [ th : main ] implies that the least square estimator @xmath69 converges to a value proportional to the desire value ( [ eq : main ] ) and the proportion is expressed in a form of integration .",
    "[ th : main ] under the true model ( [ eq : btrue ] ) and the working model ( [ eq : bworking ] ) , the least - square estimator @xmath70 converges in probability to @xmath71 where @xmath72 .",
    "[ lm : ab00 ] arnold and beaver ( 2000 ) prove that    1 .",
    "linearly skewed normal @xmath73 is defined according to the following equation @xmath74 2 .",
    "if @xmath73 then @xmath75^{-1}\\ ] ]    [ lm : probit ] under the true model ( [ eq : btrue ] ) with probit link ( @xmath76 ) , @xmath77    under the working model ( [ eq : bworking ] ) , we show that the maximum likelihood estimator of @xmath78 converges in probability to @xmath79 in theorem [ th : mle ] where the proof is rooted from the score equation @xmath80 \\right\\ }      = e\\left\\{{\\bf z}_1\\left[h_t({\\bf z}^t{{\\boldsymbol}\\gamma})-h_w({\\bf z}^t_1{{\\boldsymbol}\\beta}^{ml}_1)\\right]\\right\\}$ ] which implies that the theorem holds according to theorem [ th : main ] and we omit .",
    "note that theorem [ th : mle ] also says that when @xmath81 , the link function is misspecified , the regression coefficient estimator of the working model converges to a value which is proportional to the true regression coefficient .",
    "this conclusion is also made in li and duan ( 1989 ) but they do not provide an explicit form of the proportion .",
    "[ th : mle ] under the true model ( [ eq : btrue ] ) and the working model ( [ eq : bworking ] ) , the maximum likelihood estimator @xmath82 converges in probability to @xmath83 where @xmath84 .",
    "the integrations involved in theorem [ th : main ] and theorem [ th : mle ] are not easy to evaluate because @xmath85 and @xmath59 may not have simple forms .",
    "for example , stefanski ( 1990 ) shows that when @xmath86 is the density function of the logistic distribution , @xmath87 and @xmath88 .",
    "a friendly computation form can be @xmath89 which can be numerically evaluated by many computer softwares easily when all parameters and @xmath90 are specified . finally , we emphasize that the inverse function of the complementary log - log link is the _ c.d.f .",
    "_ of extreme value distribution , and since the corresponding _ p.d.f .",
    "_ is not symmetric around 0 , theorem 1 does not apply to this case .",
    "in this section , we formally define the screening statistics including the sis and the less . for the @xmath91th individual , @xmath92 ,",
    "let the true model be @xmath93 and the working model for the @xmath94th screening statistic be @xmath95 denote the likelihood of the working model as @xmath96 .",
    "similarly , define the least - square objective function as @xmath97 . for the sis ( fan and song , 2010 )",
    ", the screening statistic is @xmath98 .",
    "we further distinguish it into two methods : sis with probit link ( sisp ) , @xmath99 , and sis with logit link ( sisl ) , @xmath100 where @xmath101 .",
    "moreover , the screening statistic of less is @xmath102 .",
    "in addition , because @xmath103 plays no role in screening so we omit but readers should know that above maximizations are taken with respect to @xmath103 and @xmath104 simultaneously . by theorems [ th : main ] and [ th : mle ] , we conclude that @xmath105 , @xmath106 , and @xmath107 where @xmath108 is the contamination due to other active predictors .",
    "if @xmath109 then @xmath110 implies @xmath111 .",
    "a general condition for @xmath109 is that both @xmath112 and @xmath10 are sparse ( fan and lv , 2008 ) .",
    "finally , the sis recommends choosing @xmath113 largest @xmath114 s to build final models where @xmath115 and @xmath116 is the sample size .",
    "we shall follow this rule for sisp and less procedures .    following ( true ) model",
    "is designed to demonstrate the consequence of model misspecification .",
    "suppose that predictors @xmath117 follows normal distribution with zero mean and the true covariance structure is either autoregression ( ar1 ) , @xmath118 , or compound symmetry ( cs ) , @xmath119 where @xmath120 if @xmath121 is true and @xmath122 otherwise .",
    "let the true model be @xmath123 and @xmath124 where @xmath125 . by theorem [ th : main ] ,",
    "@xmath126 s can be evaluated according to the true model .",
    "unfortunately , there is no closed - form expression for @xmath127 s and therefore , we estimate @xmath128 s by averaging 100 maximum likelihood estimates where each of them was calculated based on 200 independent samples drawn from the true model . the results are shown in figure [ fig : ass ] .",
    "this figure expresses the intuition that the sure screening property does not hold for all kind of data sets . from figure",
    "[ fig : ass ] , when the predictors have the ar1 correlation structure ( the left panel ) , both less and sis seems to have high chance to detect all active predictors . on the other hand ,",
    "when predictors have the cs correlation structure ( the right panel ) , the predictor @xmath129 is barely chosen by all mentioned screening method .",
    "a simple scheme was applied to demonstrate theorem 1 .",
    "let the true model be @xmath130 and @xmath131 where the link function is either the probit link or the logit link .",
    "moreover , we generate normal predictors @xmath132 with zero mean and aforementioned covariance structures ar1 and cs . for each dataset , 200 _ i.i.d .",
    "_ samples were generated and 100 datasets were simulated .",
    "table [ tb : bias ] shows that if the link function and the true regression coefficients are known then the least - square regression coefficient estimates with adjustment ( @xmath133 s ) seem to be consistent .",
    ".biases of adjusted least square estimation ( @xmath125 ) [ cols=\"<,<,>,>,>,>,>,>,>\",options=\"header \" , ]      + bold - faced numbers are gene ids that discovered by all of three screening methods .",
    "in this work , we investigate the screening statistics , sisl , sisp , and less , in population level .",
    "the quality of screening depends on the sparseness of the true regression coefficient and the sparseness of the covariance structure of predictors .",
    "this conclusion can be drawn from ( [ eq : main ] ) and numerically proved by our simulations .",
    "also , none of these methods satisfies the sure screening property defined by fan and lv ( 2008 ) without placing some restrictions on these two sparseness .",
    "fortunately , in many experiments , it is nature to make these sparseness assumptions .",
    "the leukemia dataset demonstrated in section 4.2 is a good example .",
    "first , it is reasonable to assume that only a few genes affects the subtypes of leukemia and second , indeed , the covariance among gene expressions is low on average .",
    "moreover , dudoit _ et al . _",
    "( 2002 ) analyze this dataset via many classification methods . among these approaches ,",
    "the diagonal linear discriminate analysis , assuming that all gene expressions are uncorrelated , beats others .",
    "this may imply that the sparseness of the covariance structure assumption and the gaussian assumption on gene expressions fit the observed data well .",
    "although both the sis s and the less are defined in a very restrictive manner , we suggest two rules to apply them . first , if the covariance structure is rich then aforementioned screening approaches would fail . under this circumstance , using other delicate statistical approaches is recommended .",
    "second , if predictors do not follow normal distribution then the sample size should be large for an acceptable screening result .",
    "when there is no significant violation of above conditions and the dataset is huge , we advocate using less because it is very computational efficient . for the leukemia dataset , sisl and sisp cost 23 and 31 seconds , respectively , whereas less cost less than 1 second .",
    "00 albert , a. and anderson , j.a .",
    "( 1984 )  on the existence of maximum likelihood estimates in logistic regression models \" , _ biometrika _ , * 71 * , 1  10 .",
    "andrews , d.f . and mallows , c.l .",
    "( 1974 )  scale mixtures of normal distributions \" , _ journal of the royal statistical society , series b _ , * 36 * , 99  102 .",
    "arnold , b.c . and beaver , r.j .",
    "( 2000 )  hidden truncation models \" , _ sankhy@xmath134 : the indian journal of statistics _ , * 62 * , 23  35 .",
    "biswas , a. and hwang , j .- s .",
    "( 2002 )  a new bivariate binomial distribution \" , _ statistics & probability letters _ , * 60 * , 231  240 .",
    "box , g.e.p . and tiao , g.c .",
    "( 1973 ) _ bayesian inference in statistical analysis _ , addison - wesley .",
    "crouch , e.a . and spiegelman , d. ( 1990 )  the evaluation of integrals of the form @xmath135 : applications to logistic - normal models \" , _ journal of the american statistical associations _ , * 85 * , 464  467 .",
    "dudoit , s. , fridlyand , j. and speed t.p .",
    "( 2002 )  comparison of discrimination methods for the classification of tumors using gene expression data \" , _ journal of the american statistical association _",
    ", * 97 * , 77  87 .",
    "fan , j. and lv , j. ( 2008 )  sure independence screening for ultrahigh dimensional feature space \" , _ journal of the royal statistical society , series b _ , * 70 * , 849  911 .",
    "fan , j. and song , r. ( 2010 )  sure independence screening in generalized linear models with np - dimensionality \" , _ the annals of statistics _ , * 38 * , 3567  3604 .",
    "huang , j. , horowitz , j. and ma , s. ( 2008 ) ",
    "asymptotic properties of bridge estimators in sparse high - dimentional regression models \" , _ annals of statistics _ ,",
    "* 36 * , 587  613 .",
    "li , k .- c . and duan , h. ( 1989 )  regression analysis under link violation \" , _ the annals of statistics _ , * 17 * , 1009  1052 .",
    "mccullagh , p. and nelder , j.a .",
    "( 1989 ) _ generalized linear models _",
    ", second edt . , chapman & hall / crc monahan , j. and stefanski , l.a .",
    "( 1992 )  normal scale mixture approximations to @xmath136 and computation of the logistic - normal integral \" , in _ handbook of the logistic distribution _ , pp 529  540 , n. balakrishnan , editor .",
    "marcel dekker , new york .",
    "stefanski , l.a .",
    "( 1990 )  a normal scale mixture representation of the logistic distribution \" , _ statistics & probability letters _ , * 11 * , 69  70 . west , m. ( 1987 )  on scale mixtures of normal distributions \" ,",
    "_ biometrika _ , * 74 * , 664  668 .",
    "proof of theorem [ th : main ]    note that the least square estimator converges in probability to the inverse of the covariance matrix among predictors multiplied by the covariance between the response and the predictors .",
    "the former is trivial and thus we show the latter .",
    "we begin with the conditional expectation @xmath137 where @xmath138 , @xmath139 and @xmath140 . according to the proof of lemma 2 , @xmath141       \\phi({\\bf z}_1 ; { { \\boldsymbol}\\mu } , { { \\boldsymbol}\\omega } ) d { \\bf z}_1\\\\      & = \\int_{{\\mathbb{r}}^+ }      \\left [          \\int_{{\\mathbb{r } } } { \\bf z}_1   \\phi\\left(\\frac{c_1 + { { \\boldsymbol}\\gamma}_1^t{\\bf z}_1}{\\sigma}\\right )          \\phi({\\bf z}_1 ; { { \\boldsymbol}\\mu } , { { \\boldsymbol}\\omega } ) d { \\bf z}_1      \\right ]       q(\\sigma)d\\sigma \\end{split}\\ ] ] and therefore @xmath142 where @xmath143 , @xmath144 , @xmath145 , and @xmath146 .",
    "after change of variable , we have @xmath147 last , since @xmath148 exists , @xmath149 exists .",
    "proof of lemma [ lm : probit ]    define @xmath150 .",
    "then @xmath151 where @xmath152 and @xmath140 .",
    "let @xmath153 .",
    "the conditional expectation @xmath154 can be rewritten as @xmath155 further , let @xmath156 and @xmath157 . by lemma [ lm : ab00 ] , above integration becomes @xmath158 or equivalently @xmath159 where @xmath160 .",
    "since @xmath161 and @xmath162 , @xmath163\\\\          & + { { \\boldsymbol}\\omega}{{\\boldsymbol}\\gamma_1 } \\int_{{\\mathbb{r } } } \\phi\\left ( w ; - \\gamma_0 ,           1 + { { \\boldsymbol}\\gamma}_1^t{{\\boldsymbol}\\omega}{{\\boldsymbol}\\gamma}_1\\right ) \\phi(w ; 0 , { \\bf b}^t{{\\boldsymbol}\\sigma}_{22}{\\bf b } ) dw . \\end{split}\\ ] ] again , by lemma [ lm : ab00 ] , @xmath164 and therefore , after some algebra , @xmath165 .",
    "let @xmath166 follow bivariate binomial distribution with marginal distribution @xmath167 and @xmath168 .",
    "following biswas and hwang ( 2002 ) , the joint distribution can be @xmath169 where @xmath170 @xmath171/(1+\\alpha)$ ] , @xmath172 , and @xmath173 is a carefully chosen constant .",
    "note that @xmath174 is not necessarily a probability mass function for arbitrary @xmath175 .",
    "a sufficient condition to make @xmath176 a probability mass function is that @xmath177 moreover , the correlation coefficient between @xmath178 and @xmath179 is @xmath180 given by biswas and hwang ( 2002 ) .",
    "consequently , an algorithm to simulate correlated @xmath181 is as follows :    1 .",
    "sample @xmath182 from @xmath183 .",
    "sample @xmath184 from @xmath185 .",
    "set @xmath186 .",
    "2 .   for simulating @xmath187 , sample @xmath188 from @xmath183 and @xmath189 from @xmath190 .",
    "3 .   given @xmath191 , if the sufficient condition ( [ eq : suf ] ) is not satisfied , let @xmath192 .",
    "sample @xmath187 from the conditional probability ( [ eq : cond ] ) with @xmath191 .",
    "5 .   let @xmath193 .",
    "goto 2 . while @xmath194 and stop while @xmath195 .",
    "note that , setting @xmath196 makes two binomial random variables independent .",
    "so step 3 .",
    "enforces two consecutive variables to be independent with probability roughly equal to 0.1 according to simulation .",
    "moreover , the resulting correlation ranges from 0.2 to 0.8 with median 0.4 by simulation ."
  ],
  "abstract_text": [
    "<S> screening before model building is a reasonable strategy to reduce the dimension of regression problems . </S>",
    "<S> sure independence screening is an efficient approach to this purpose . </S>",
    "<S> it applies the slope estimate of a simple linear regression as a surrogate measure of the association between the response and the predictor so that the final model can be built by those predictors with steep slopes . </S>",
    "<S> however , if the response is truly affected by a nontrivial linear combination of some predictors then the simple linear regression model is a misspecified model . in this work </S>",
    "<S> , we investigate the performance of the sure independence screening in the view of model misspecification for binary response regressions . </S>",
    "<S> both maximum likelihood screening and least square screening are studied with the assumption that predictors follow multivariate normal distribution and the true and the working link function belong to a class of scale mixtures of normal distributions .    </S>",
    "<S> link function , logistic model , probit model , sure independence screening </S>"
  ]
}