{
  "article_text": [
    "given a connected , weighted undirected graph @xmath0 , a spanning tree is a tree in this graph that contains all its vertices .",
    "minimum spanning tree ( mst )  @xcite is a spanning tree having minimum possible weight , where the weight of the tree is the sum of the weights of all the edges contained in it .",
    "the paper considers the minimum spanning tree problem in large graphs . by large graphs we mean graphs that can not fit in the memory of the typical node of the distributed memory system .",
    "the mst problem is encountered in many areas , for example , in bioinformatics , computer vision and also when designing various networks .",
    "requirements to the size of the processed graphs in real problems are constantly increasing .",
    "for example , in bioinformatics when solving clustering problem  @xcite that can be solved by constructing a mst , graphs may take up to one petabyte or even more memory .",
    "there are many algorithms  @xcite that solve the mst problem ; the best known algorithms are prim s  @xcite , kruskal s  @xcite and boruvka s algorithms  @xcite .",
    "some algorithms are suitable for shared memory parallelization , there are lot of such implementations , for example  @xcite .    some of the mentioned algorithms are adapted for implementation on distributed memory systems  @xcite . among the parallel implementations listed above",
    "there is not one implementation scalable to at least one hundred parallel processes .",
    "there are algorithms specially designed for distributed systems , for example , the ghs ( gallager , humblet , spira ) algorithm  @xcite and awerbuch  @xcite . to the best of our knowledge , there is only one paper  @xcite that describes the implementation of ghs algorithm , but it presents no good experimental results .    in this paper",
    "we present a parallel algorithm for solving a minimum spanning tree problem on distributed memory systems .",
    "the algorithm has been developed on the basis of the ghs algorithm .",
    "the algorithm allows processing of large - scale graphs and linearly scales to more than two hundred parallel processes .",
    "the ghs algorithm has been chosen for the study as a fundamental distributed parallel mst algorithm .",
    "this algorithm is based on a vertex - centric programming model  @xcite .",
    "the idea of the algorithm is as follows : all vertices perform the same procedure , which consists of sending , receiving and processing the messages from adjacent vertices .",
    "the messages can be transmitted independently in both directions of an edge , the order of messages must be preserved along the edge direction .    at any time",
    ", the set of graph vertices is represented as a union of a certain number of fragments , i.e. the disjoint sets of vertices .",
    "initially , each vertex is a fragment .",
    "each fragment finds an edge with a minimum weight among the edges outgoing from this fragment to the other fragments .",
    "the fragments are then combined over these edges .",
    "the edges , which are used to combine the fragments , will compose a minimum spanning tree when there is only one fragment comprising all the vertices left .",
    "consider the algorithm in detail .",
    "there are three possible vertex states : _ sleeping _ , _ find _ and _ found _ where _ sleeping _ is the initial state of all vertices .",
    "the vertex will be in the state _ find _ when participating in a fragment s search for the minimum - weight outgoing edge , and in the state _ found _ in other cases .",
    "each fragment has an @xmath1 variable characterizing its level .",
    "initially the level of each fragment is 0 .",
    "two fragments of the same level @xmath1 can be combined into a level @xmath2 fragment .",
    "a fragment can not join to another fragment of a lower level .",
    "the following is the detailed description of the searching process of the minimum - weight outgoing edge of the fragment . in the trivial case where the fragment consists of a single vertex and",
    "its level is 0 , the vertex locally chooses its minimum - weight outgoing edge , marks this edge as a branch of the minimum spanning tree and sends a message called _ connect _ over this edge and goes into the _ found _ state .",
    "now consider the case where a fragment level is greater than 0 .",
    "suppose a new fragment at level @xmath1 has just been formed by the combination of two level @xmath3 fragments with the same outgoing edge , which becomes the core of the new fragment .",
    "the weight of this core edge is used as the identity of the fragment . then an _ initiate _ message",
    "is broadcast all over the fragment starting from the vertices adjacent to the core , so that all vertices receive new fragment level and identity and are placed in the _ find _ state .",
    "when a vertex receives the _ initiate _ message , it starts finding the minimum - weight outgoing edge .",
    "each edge of the graph can be in one of three states : _ branch _ , if the edge belongs to the minimum spanning tree ; _ rejected _ , if the edge is not part of the mininum spanning tree ; and _ basic _ if it is not yet known whether the edge is part of the minimum spanning tree or not . in order to find minimum - weight outgoing edge , for each vertex @xmath4 all edges in the _ basic _ state are sorted out starting from the most light - weight edge . each edge is probed by sending _ test _",
    "messages along that edge .",
    "the _ test _",
    "message contains fragment level and identity as arguments .",
    "when vertex @xmath5 receives the _ test _ message , it compares its own fragment identity with one received in the message .",
    "if the identities are equal , then the vertex @xmath5 sends the _ reject _ message back , and then both vertices put the edge in the _ reject _ state . in this case , the vertex @xmath4 that has sent the _ test _",
    "message , continues the search , analyzing the next best edge and so on .",
    "if the fragment identity in the received _ test _ message is different from the fragment identity of the receiving vertex @xmath5 , and if the receiving vertex fragment level is greater or equal to the one in the _ test _ message , then an _ accept _ message is sent back . in this case",
    "the state of the edge incident to the vertex @xmath4 is changed to _",
    "branch_. however , if the fragment level of the vertex @xmath5 is smaller than the one in the received message , then the message is postponed , until the fragment level of the vertex @xmath5 increases to the necessary value .",
    "finally each vertex finds a minimum - weight outgoing edge , if any .",
    "now vertices are sending _ report _ messages ( see .",
    "[ ris : ghs].a )  ) , to find the minimum - weight outgoing edge of the whole fragment .",
    "if none of the graph vertices have outgoing edges in the _ basic _ state , then the algorithm terminates , and the edges in the _ branch _ state are the minimum spanning tree .",
    "_ report _ messages are sent by the following rules .",
    "each leaf vertex of the fragment sends _",
    "report(w ) _ along the only incident edge in the _ branch _ state ( _ w _ is a weight of the minimum outgoing edge from the vertex or infinity , if there are no outgoing edges ) .",
    "each internal vertex finds its own minimum - weight outgoing edge and waits for all messages from all the subtrees .",
    "then the vertex chooses minimum weight from all the weight values .",
    "if the minimum is achieved with the value which came from the subtrees , then a number of the outgoing branch is put into vertex variable _ best_edge _",
    ", otherwise a number of the minimum - weight outgoing edge is put into this variable .",
    "this is done in order to easily restore the path by moving to where the _ best_edge _ is pointing .",
    "further there is a sending of the _ report _ message up the tree of the fragment with an argument equal to the found minimum value among all the weight values .",
    "when the vertex sends the _ report _ message , it also goes into the _ found _ state .",
    "finally , two vertices that are incident to the core edge send the _ report _ messages along the core and determine the weight of the minimum outgoing edge and the direction to this edge .    in order to try to connect one fragment to another over the found minimum - weight outgoing edge of the fragment ,",
    "it is possible to use _ best_edge _ variable in every vertex to trace the path from the core to the minimum - weight outgoing edge . for this purpose",
    ", a _ change core _ message is sent from one of the core vertices that is closer to the minimum - weight outgoing edge ( see .",
    "[ ris : ghs].b )  ) .",
    "a vertex that has received this message , sends it further in accordance with its own _",
    "best_edge _ value , and so on .",
    "when the message reaches the vertex having minimum - weight outgoing edge , then this vertex becomes the root of the tree formed by the fragment .",
    "this vertex sends the _",
    "connect(l ) _ message over the minimum - weight outgoing edge , where @xmath1 is a fragment level .",
    "if two level @xmath1 fragments have the same minimum - weight outgoing edge , then each of them sends the _",
    "connect(l ) _ message over this edge , and this edge becomes the core of the new level @xmath2 fragment , which immediately starts to send the _",
    "initiate _ message with a new level number and identity all over the fragment .",
    "when a level @xmath1 fragment with an identity @xmath6 sends the _ connect _ message into the level @xmath7 fragment with identity @xmath8 , the larger fragment will send the _ initiate _ message with @xmath9 and @xmath8 into the smaller fragment .",
    "time complexity of the ghs algorithm is @xmath10 , the number of communication messages is @xmath11 , where @xmath12 is a number of vertices , @xmath13 is a number of edges in the graph .",
    "not all the occurring cases are considered in this algorithm description but only the basic ones .",
    "ghs algorithm presented in the paper of 1983  @xcite is only a description and analysis of the necessary high - level steps , that must be performed at every vertex . as far as we know",
    ", there is no paper that describes implementation details of the algorithm and scales well .",
    "it is necessary to reasonably choose and develop a set of techniques and to solve a number of problems for the development of parallel algorithm for finding an mst based on ghs algorithm .",
    "implementation of the proposed algorithm has been made using c++ language with an mpi library .",
    "when running on a supercomputer the number of vertices in the graph is significantly larger than the number of mpi - processes , so a large number of vertices and all related information are typically stored in the memory of each process .",
    "all graph vertices are sequentially distributed in blocks among the processes .",
    "the local part of the graph in each process is stored in the crs ( compressed row storage ) format .",
    "preprocessing of the graph is conducted before searching for minimum spanning tree in the graph : loops and multiple edges are removed from the graph .",
    "the removal of multiple edges is used to fulfill ghs algorithm condition which says that all the edges must be unique .",
    "the time spent on the preprocessing is negligible and not included in the total time of algorithm execution .",
    "the base version of the algorithm has been developed at the beginning of work .",
    "every mpi - process supports a queue where vertices can postpone a message if it is necessary .",
    "the aggregation of messages is implemented to speed up the algorithm ; a separate buffer is created in every process for every possible receiving process .    _ implementation scheme of the base version of the parallel algorithm for construction of an mst using mpi library ; executed in parallel at every mpi - process . _",
    ".... input : local_g - local part of the graph output : local part of the mst    while ( true ) {      / * read messages and push them to the queue * /      read_msgs ( ) ;      / * queue processing , sending messages ( write to the send buffer ) * /      if ( time_to_process_queue ) {          process_queue ( ) ;      }      if ( time_to_send ) {          / * send all aggregated messages * /          send_all_bufs ( ) ;      }      / * checking for algorithm completion using mpi_allreduce * /      check_finish ( ) ; } ....    besides information that is necessary for algorithm execution messages also contain service information : the number of sending vertex and the number of the receiving vertex , as well as the message type .",
    "it is important to note that the ghs algorithm requires original graph to be connected .",
    "it is not necessary for the proposed algorithm because it will work until the interconnect is in the `` silence '' state , when all queues are empty , all messages are processed and there are no undelivered messages in the network .",
    "thus , the proposed algorithm allows finding not only an mst in a connected graph , but also a minimum spanning forest in the graph with any number of connected components .",
    "since ghs algorithm requires the weights of graph edges to be different , a special identity @xmath14 is added to the usual weight of the edge .",
    "@xmath14 for every graph edge @xmath15 is calculated as follows : let @xmath5 and @xmath4 be the vertices that are incident to the edge @xmath15 , then @xmath14 in binary representation equals to the consecutively recorded binary representations of @xmath16 , @xmath17 . such an arrangement enables algorithm to work correctly even if the input graph has two different edges with the same weights .",
    "when mpi process received an incoming message , it is necessary to find the edge ( an edge index in the list of local edges ) over which the message came , i.e. to find an index of the edge formed by the two vertices ( sending and receiving ) in the list of local edges .",
    "the search is necessary because the change of the local data related to that edge may be required .",
    "the base version uses a linear search for this operation . during linear search all edges that are incident to receiving vertex are sorted out . if the vertex on the other end of the edge is equal to the sending vertex , then the right edge is found .",
    "the first possible way to optimize this operation was sorting of all incident edges at every vertex of the original graph in increasing order of vertices numbers on the opposite end of the edge .",
    "with such an approach , at the beginning of the algorithm execution it is necessary to spend a little time on sorting , but during the algorithm execution a binary search can be used instead of linear .",
    "such an approach provides a small gain in performance .",
    "the second optimization that was considered is hashing .",
    "it is possible to create a hash table in every process instead of sorting and binary search .",
    "let @xmath5 be the vertex sending a message , @xmath4 is receiving vertex , vertex identifier is a 32 bit machine word .",
    "let s define a hash function @xmath18 as @xmath19 where @xmath20 is a bit left shift , @xmath21 is a bitwise or , @xmath22 is a remainder of division , @xmath23 is a hash table size ( several times larger than the number of local edges ) .",
    "hashing method used in the proposed algorithm is called _ linear search and insertion _  @xcite .",
    "thus an identity of the local edge can be found on two adjacent vertices for within @xmath24 , but first it is necessary to create and populate the hash table .",
    "this procedure is a part of the algorithm initialization and takes very little time and is not included in the total time of algorithm execution .",
    "it is not always possible to immediately process certain types of messages ( _ connect _ , _ test _ and _ report _ ) , because several conditions must be satisfied to perform the processing . the condition would be satisfied when some data changes , and to change the specific data it is necessary to wait for a specific message .",
    "so , there are situations when a message should be postponed , and then an attempt to process it again should be made .",
    "it is not known when it will be processed .",
    "original ghs algorithm requires the preservation of the messages order , but the study of the algorithm execution showed that _ test _",
    "messages constitute a significant part of all messages . it was found that it is beneficial to organize a separate queue for _ test _ messages , and to process it much less frequently than the main queue",
    ".      to achieve maximum possible performance of the algorithm implementation on a distributed memory system it is necessary to minimize the size of the communication messages .",
    "it is therefore important that the structure that stores the message takes as little memory as possible .    at first messages",
    "were grouped into `` short '' ( _ connect _ , _ accept _ , _ reject _ , _ change core _ ) and `` long '' messages ( _ initiate _ , _ test _ , _ report _ ) .",
    "the main difference is that `` long '' messages contain the weight and it takes significant amount of memory ( 64 bit ) .    in the beginning of each structure , for both `` long '' and `` short '' messages , a packed bit field of 16 bits is stored ( actually only 9 bits are necessary : 3 bits for message type , 5 bits for fragment level , 1 bit for vertex state ) .",
    "further , the structure stores the identifiers of sending vertex and receiving vertex ( vertex identifier is a 32 bit machine word ) . long messages further store the extended weight of the edge ( @xmath14 ) and the weight itself .",
    "finally the following optimization is implemented . instead of storing @xmath14 in the extended weight ( concatenation of two vertices identifiers , 64 bits in total ) , it is possible to store the minimal number from all the numbers of mpi processes which store this edge after verifying that the weights of all the edges in every process are different .",
    "indeed , if the weights of all edges in every process are different , then two different edges with the same weights can only be in different processes , but then , the numbers of relevant processes are enough to understand that such edges are different .    as a result short and long messages are 80 and 152 bits size respectively .      there are relevant implementation parameters :    * @xmath25 is the maximum size of aggregated messages ( by default , 10000 bytes ) , * @xmath26 is the frequency of flushing aggregated messages ( by default , every 5 iterations of @xmath27 loop ) , * @xmath28 is the frequency of processing the queue with @xmath29 messages ( by default , every 5 iterations of @xmath27 loop ) , * @xmath30 is the frequency of checking for completion",
    "( by default , every 100000 iterations of @xmath27 loop ) , * @xmath31 is the size of the hash table , in number of elements .",
    "default value is @xmath32 , where @xmath33 is the number of local edges in the mpi process after removing multiple edges and self - loops .",
    "rmat , ssca2 and uniformly random graphs are used for performance evaluation of the algorithm .",
    "* rmat  @xcite graphs represent real - world large - scale graphs from social networks and internet , and are complex enough to analyze , so they are often used to evaluate performance of graph processing algorithms .",
    "* ssca2  @xcite graphs represent set of randomly connected cliques . * in uniformly random  @xcite graphs neighbours of each vertex",
    "are chosen randomly .",
    "the paper examines graphs with an average vertex degree of 32 and a pow of 2 number of vertices .",
    "weights of the edges are a real numbers in the ( 0 , 1 ) interval .",
    "@xmath34 parameter specifies the number of vertices in the graph . if @xmath35 is the @xmath34 parameter , then @xmath36 is the number of vertices in the graph .",
    "graph with @xmath37 is hereinafter referred to as , for example , rmat-@xmath35 .",
    "the default values of the algorithm parameters listed in subsection [ lab : params ] are used for performance evaluation .",
    "we focus our design and experimental evaluation on the mvs-10p cluster system .",
    "table  [ tab : systems ] provides an architecture overview of the system .",
    ".[tab : systems]mvs-10p cluster system configuration . [ cols=\"<,<\",options=\"header \" , ]      in this subsection rmat graph with scale 23 was used for testing ( rmat-23 ) .",
    "the number of mpi processes per one node of the mvs-10p cluster is 8 .    if binary search is used instead of linear search when finding a local edge , then the execution time on the cluster node is reduced by 2% , if hashing is used instead of linear search , then the execution time on the node is approximately 18% less ( mvs-10p cluster , rmat-23 graph , 8 mpi processes per node ) .",
    "thus , the option of hashing was chosen for the final version .",
    "[ ris : rmat23_all].a ) shows how the runtime has been changing ( in seconds ) , as the optimizations described in [ lab : find_version ] , [ lab : test_version ] , [ lab : msg_opt_version ] have been added .",
    "[ ris : rmat23_all].b ) shows the scalability of the same runs , i.e. , the ratio of the problem solution time on one node to the problem solution time on a given number of nodes .    fig .  [ ris : timing_profile].a ) shows the profiling results of the algorithm version with one optimization of the local edge search , and  fig .",
    "[ ris : timing_profile].b ) shows the profiling results of the final version of the algorithm .",
    "the profiling shows that the most of the time is spent on processing of queues .",
    "some messages are processed repeatedly including _ test _ messages , so in the final version of the algorithm in which _ test _ messages are processed less frequently the part of queue processing in total execution time of the algorithm is less than in version with only hashing optimization .",
    "exactly this optimization improved the algorithm scalability by 2 times , see  fig .",
    "[ ris : rmat23_all].b ) .    also , message length optimization has made a considerable contribution to performance of algorithm implementation .",
    "this optimization reduced the execution time of the final version of the algorithm on any number of nodes by approximately 50% .",
    "table  [ tab : perf_vert ] shows performance evaluation results of the final algorithm version on the mvs-10p cluster for rmat-24 , ssca2 - 24 and random-24 graphs .",
    "number of mpi processes per node is 8 .     * 2 * & * 4 * & * 8 * & * 16 * & * 32 * & * 64 * +    & & * time ( s ) * & 63,27 & 36,12 & 17,98 & 8,47 & 5,41 & 2,04 & 1,45 + & & * scaling * & 1,00 & 1,75 & 3,52 & 7,47 & 11,7 & 31,01 & 43,63 + & & * time ( s ) * & 54,69 & 32,37 & 11,90 & 6,02 & 3,63 & 1,72 & n / a + & & * scaling * & 1,00 & 1,69 & 4,60 & 9,08 & 15,07 & 31,62 & n / a + & & * time ( s ) * & 88,61 & 51,65 & 21,47 & 10,27 & 6,68 & 3,23 & n / a + & & * scaling * & 1,00 & 1,72 & 4,13 & 8,63 & 13,26 & 27,43 &",
    "n / a +    @xmath34 24 is the largest graph scale that fits into the memory the mvs-10p node .",
    "the size of these graphs is approximately 6.5 gb . the rest of the memory node is needed for algorithm implementation . in particular , a large amount of memory is required to organize the hash table .",
    "scalable mode in intel mpi 4.1 on the mvs-10p cluster provides linear scaling on 32 nodes . on 64 nodes ( 512 cores ) of the mvs-10p",
    "the scaling is 43.6 .    in  fig .",
    "[ ris : avg_msg_size ] we show the dependence between average size of communication messages and execution time of the final algorithm version . here",
    "the message size refers to an aggregated message sent over the interconnect .",
    "the value of the @xmath25 aggregation parameter is 20000 bytes .",
    "the figure shows that with increasing number of nodes the message size decreases . on 32 nodes messages are short ;",
    "their size does not exceed 2 kb .",
    "it is also clear that the size of messages depends on the algorithm execution time .",
    "we suppose that the main limitation factor of the algorithm performance can be latency or injection rate of short messages .",
    "[ ris : best_v_time_diff_graphs ] shows the weak scaling for rmat graphs on 32 nodes of the mvs-10p cluster .",
    "rmat-29 is the largest graph that fits into the memory of 32 nodes ; it takes a total of 205 gb . it should be noted that the implementation of the algorithm for solving an mst problem is scalable in - memory , i.e. with an increase in the number of nodes it is possible to increase the size of the graph .",
    "the paper presents the parallel algorithm for finding minimum spanning tree ( forest ) in the graph for distributed memory systems , and the algorithm implementation that has been made using mpi .      *",
    "the requirement of message processing order has been relaxed for _ test _ messages , which doubled the scaling of the algorithm ; * algorithm is generalized for the case of processing a disconnected graph and builds a minimum spanning forest , while the original algorithm is only applicable to connected graphs .",
    "as well the presented algorithm adopts some optimization techniques , namely hashing as the local edge search and the compression of communication messages .",
    "the algorithm implementation linearly scales on 32 nodes of the mvs-10p infiniband cluster .    in the next paper edition",
    "we plan to present extended performance evaluation of the proposed algorithm and to study the main limiting factors of the algorithm using loggops model and large - scale applications simulator . in the future we plan to improve algorithm scaling and",
    "develop hybrid mpi+openmp implementation of the algorithm .",
    "katsigiannis a. , anastopoulos n. , nikas k. : an approach to parallelize kruskal s algorithm using helper threads .",
    "ieee 26th international parallel and distributed processing symposium workshops and phd forum , pp . 16011610 ( 2012 )      awerbuch b. : optimal distributed algorithms for minimum weight spanning tree , counting , leader election , and related problems .",
    "19th acm symposium on theory of computing ( stoc ) , pp .",
    "230240 . new york ( 1987 )                  chakrabarti d. , zhan y. , faloutsos c. : r - mat : a recursive model for graph mining .",
    "proceedings of the fourth siam international conference on data mining , http://repository.cmu.edu/cgi/viewcontent.cgi?article=1541&context=compsci ( 2004 )    bader d. a. , madduri k. : design and implementation of the hpcs graph analysis benchmark on symmetric multiprocessors .",
    "12th international conference on high performance computing ( hipc ) , lecture notes in computer science , goa , india ( 2005 )"
  ],
  "abstract_text": [
    "<S> in this paper we present and evaluate a parallel algorithm for solving a minimum spanning tree ( mst ) problem for supercomputers with distributed memory . </S>",
    "<S> the algorithm relies on the relaxation of the message processing order requirement for one specific message type compared to the original ghs ( gallager , humblet , spira ) algorithm . </S>",
    "<S> our algorithm adopts hashing and message compression optimization techniques as well . to the best of our knowledge , </S>",
    "<S> this is the first parallel implementation of the ghs algorithm that linearly scales to more than 32 nodes ( 256 cores ) of infiniband cluster . </S>"
  ]
}