{
  "article_text": [
    "traditionally , learning classifier systems ( lcs ) @xcite use a ternary encoding to generalize over the environmental inputs and to associate appropriate actions .",
    "a number of representations have previously been presented beyond this scheme however , including real numbers @xcite , fuzzy logic @xcite and artificial neural networks @xcite .",
    "temporally dynamic representation schemes within lcs represent a potentially important approach since temporal behaviour of such kinds is viewed as a significant aspect of artificial life , biological systems , and cognition in general @xcite .    in this paper",
    "we explore examples of a dynamical system representation within the xcsf learning classifier system @xcite  termed `` dynamical genetic programming '' ( dgp ) @xcite .",
    "traditional tree - based genetic programming ( gp ) @xcite has been used within lcs both to calculate the action @xcite and to represent the condition ( e.g. , @xcite ) .",
    "dgp uses a graph - based representation , each node of which is constantly updated with asynchronous parallelism , and evolved using an open - ended , self - adaptive scheme . in the discrete case ,",
    "each node is a boolean function and therefore the representation is a form of random boolean network ( rbn ) ( e.g. , @xcite ) . in the continuous case , each node performs a fuzzy logical function and the representation is a form of fuzzy logic network ( fln ) ( e.g. , @xcite ) .",
    "we show that xcsf is able to solve a number of well - known immediate and delayed reward tasks using this temporally dynamic knowledge representation scheme with competitive performance with other representations .",
    "moreover , we exploit the memory inherent to rbn for the discrete case .",
    "a significant benefit of symbolic representations is the expressive power to represent relationships between the sensory inputs @xcite .",
    "lisp s - expressions comprised from a set of boolean functions ( i.e. , and , or , and not ) have been used to represent symbolic classifier conditions in lcs to solve boolean multiplexer and woods problems @xcite , and to extract useful knowledge in a data mining assay @xcite .",
    "an analysis of the populations @xcite has subsequently shown an increasing prevalence of sub - expressions through the course of evolution as the system constructs the required building blocks to find solutions . however , when logical disjunctions are involved , optimality is unattainable because the symbolic conditions highly overlap , resulting in classifiers sharing their fitness with other classifiers and thereby lowering the fitness values @xcite .",
    "this was later extended to also include arithmetic functions ( i.e. , plus , minus , multiply , divide , and powerof ) and domain specific functions ( i.e. , valueat and addrof ) to solve a number of multiplexer tasks @xcite .",
    "in addition , lanzi _ et al . _",
    "@xcite based classifier conditions on stack - based genetic programming @xcite and solved the 6 and 11 bit multiplexer as well as woods1 problems . here",
    "the conditions are linear sequences of tokens , expressed in reverse polish notation , where each token represents either a variable , constant or function .",
    "the function set used comprised boolean operators ( i.e. , and , or , not and eor ) and arithmetic operators ( i.e. , + , - , @xmath0 , =) .    ahulwalia and bull @xcite presented a simple form of lcs which used numerical s - expressions for feature extraction in classification tasks . here",
    "each rule s condition was a binary string indicating whether or not a rule matched for a given feature and the actions were s - expressions which performed a function on the input feature value .",
    "more recently , wilson @xcite has explored the use of a form of gene expression programming ( gep ) @xcite within lcs . here",
    "the expressions are comprised from arithmetic functions and applied to regression tasks .",
    "the conditions are represented as expression trees which are evaluated by assigning the environmental inputs to the tree s terminals , evaluating the tree , and then comparing the result with a predetermined threshold . whenever the threshold value is exceeded",
    ", the rule becomes eligible for use as the output .",
    "landau _ et al . _",
    "@xcite used a purely evolution - based form of lcs ( pittsburgh style @xcite ) in which the rules are represented as directed graphs where the genotypes are tokens of a stack - based language , whose execution builds the labeled graph .",
    "bit - strings are used to represent the language tokens and applied to non - markov problems .",
    "the genotype is translated into a sequence of tokens and then interpreted similarly to a program in a stack - based language with instructions to create the graph s nodes , connections and labels .",
    "subsequently , the unused conditions and actions in the stack are added to the structure which is then popped from the stack .",
    "tokens are used to specify the matching conditions and executable actions as well as instructions to construct the graph , and to manipulate the stack .",
    "the bit - strings were later replaced with integer tokens and again applied to non - markov problems @xcite .",
    "most relevant to the form of gp used herein is the relatively small amount of prior work on graph - based representations .",
    "neural programming ( np ) @xcite uses a directed graph of connected nodes , each performing an arbitrary function .",
    "potentially selectable functions include read , write , and if - then - else , along with standard arithmetic and zero - arity functions .",
    "additionally , complex user defined functions may be used .",
    "significantly , recursive connections are permitted and each node is executed with synchronous parallelism for some number of cycles before an output node s value is taken .",
    "poli ( e.g. , @xcite ) presented a similar scheme wherein the graph is placed over a two - dimensional grid and executes its nodes synchronously in parallel .",
    "connections are directed upwards and are only permitted between nodes situated on adjacent rows ; however by including identity functions , connections between non - adjacent layers are possible and thus any parallel distributed program may be represented .",
    "teller and veloso @xcite presented parallel algorithm discovery and orchestration ( pado ) which uses an arbitrary directed graph of nodes and an indexed memory .",
    "each node in the graph consists of an action and a branch - decision component , with multiple outgoing branches permitting the various potential flows of control .",
    "a stack is used from where each program s inputs are drawn and the results pushed .",
    "the potentially selectable actions are similar to np and include arithmetic operators , negation , minimum and maximum , and the ability to read from and write to the indexed memory , along with non - deterministic and deterministic branching instructions .",
    "the graphs are executed chronologically for a fixed amount of time with each node selecting the next to take control .",
    "the output nodes are then averaged giving additional weighting to the more recent states",
    ".    other examples of graph - based gp typically contain sequentially updating nodes , e.g. , finite state machines ( e.g. , @xcite ) , cartesian gp @xcite , genetic network programming @xcite , linear - graph gp @xcite , and graph structured program evolution @xcite . schmidt and lipson @xcite have recently demonstrated a number of benefits from graph encodings over traditional trees , such as reduced bloat and increased computational efficiency .",
    "we have recently introduced the use of the graph - based random boolean networks within lcs @xcite . in this paper",
    "we extend that work to the most recent form of lcs , wilson s xcsf , and to the continuous - valued domain with fuzzy logical functions .",
    "the most common form of discrete dynamical system is the cellular automaton ( ca ) @xcite which consists of an array of cells ( lattice of nodes ) where the cells exist in states from a finite set and update their states with synchronous parallelism in discrete time .",
    "traditionally , each cell calculates its next state depending upon its current state and the states of its closest neighbours .",
    "that is , cas may be seen as a graph with a ( typically ) restricted topology .",
    "packard @xcite was the first to use evolutionary computing techniques to design cas such that they exhibit a given emergent global behaviour .",
    "following packard @xcite , mitchell _ et al .",
    "_ @xcite have investigated the use of a ga to learn the rules of uniform binary cas . as in packard",
    "s work , the ga produces the entries in the update table used by each cell , candidate solutions being evaluated with regard to their degree of success for the given task .",
    "@xcite used traditional gp to evolve the update rules and reported similar results to mitchell _ et al .",
    "sipper @xcite presented a non - uniform , or heterogeneous , approach to evolving cas .",
    "each cell of a one- or two - dimensional ca is also viewed as a ga population member , mating only with its lattice neighbours and receiving an individual fitness .",
    "he shows an increase in performance over mitchell _",
    "_ @xcite by exploiting the potential for spatial heterogeneity in the tasks . in this paper , a more general form of dynamical system is exploited .",
    "the discrete dynamical systems known as random boolean networks ( rbn ) were originally introduced by kauffman ( see @xcite ) to explore aspects of biological genetic regulatory networks . since then they have been used as a tool in a wide range of areas , such as self - organisation ( e.g. , @xcite ) and computation ( e.g. , @xcite ) and robotics ( e.g. , @xcite ) .",
    "an rbn typically consists of a network of @xmath1 nodes , each performing a boolean function with @xmath2 inputs from other nodes in the network , all updating synchronously ( see figure  [ fig : examplerbn ] ) . as such",
    ", rbn may be viewed as a generalization of binary cellular automata ( ca ) @xcite and unorganized machines @xcite .",
    "since they have a finite number of possible states and they are deterministic , the dynamics of rbn eventually fall into a basin of attraction .",
    "it is well - established that the value of @xmath2 affects the emergent behaviour of rbn wherein attractors typically contain an increasing number of states with increasing @xmath2 .",
    "three phases of behaviour are suggested : ordered when @xmath3 , with attractors consisting of one or a few states ; chaotic when @xmath4 , with a very large number of states per attractor ; and , a critical regime around @xmath5 , where similar states lie on trajectories that tend to neither diverge nor converge and 5 - 15% of nodes change state per attractor cycle ( see @xcite for discussions of this critical regime , e.g. , with respect to perturbations ) .",
    "analytical methods have been presented by which to determine the typical time taken to reach a basin of attraction and the number of states within such basins for a given degree of connectivity @xmath2 ( see @xcite ) .",
    "closely akin to the work described here , kauffman @xcite describes the use of simulated evolution to design rbn which must play a ( mis)matching game wherein mutation is used to change connectivity , the boolean functions , @xmath2 and @xmath1 .",
    "he reports the typical emergence of high fitness solutions with @xmath2=2 to 3 , together with an increase in @xmath1 over the initialised size .",
    "sipper and ruppin @xcite extended sipper s heterogeneous ca approach @xcite to enable heterogeneity in the node connectivity , along with the node function ; they evolved a form of random boolean network .",
    "van den broeck and kawai @xcite explored the use of a simulated annealing - type approach to design feedforward rbn for the four - bit parity problem and lemke _ et al .",
    "_ @xcite evolved rbn of fixed @xmath1 and @xmath2 to match an arbitrary attractor .",
    "figure  [ fig : k - affect - all ] shows the affect of @xmath2 on a 13 node rbn ; results are an average of one hundred runs for each value of @xmath2 .",
    "it can be seen that the higher the value of @xmath2 , the greater the number of states the networks will cycle through , as shown by the higher rate of change of node states .",
    "further , that after an initial rapid decline in the rate of change , this value stabilises as the states fall into their respective attractors . in the synchronous case ( figure  [ fig : k - affect - synch ] ) when @xmath5 , the number of nodes changing state converges to around 20% , and when @xmath6 to just above 35% ; thus we can see that the ordered regime occurs when approximately 20% or less nodes are changing state each cycle , and the chaotic regime occurring for larger rates of change .    as noted above , traditional rbn consist of @xmath1 nodes updating synchronously in discrete time steps , but asynchronous versions",
    "have also been presented , after @xcite , leading to a classification of the space of possible forms of rbn @xcite .",
    "asynchronous forms of ca have also been explored ( e.g. , @xcite ) wherein it is often suggested that asynchrony is a more realistic underlying assumption for many natural and artificial systems since `` discrete time , synchronously updating networks are certainly not biologically defensible : in development the interactions between regulatory elements do not occur in a lock - step fashion '' @xcite .",
    "asynchronous logic devices are known to have the potential to consume less power and dissipate less heat @xcite , which may be exploitable during efforts towards hardware implementations of such systems .",
    "asynchronous logic is also known to have the potential for improved fault tolerance , particularly through delay insensitive schemes ( e.g. , @xcite ) .",
    "this may also prove beneficial for hardware implementations .",
    "harvey and bossomaier @xcite showed that asynchronous rbn exhibit either point attractors , as seen in asynchronous cas , or `` loose '' attractors where `` the network passes indefinitely through a subset of its possible states '' ( as opposed to distinct cycles in the synchronous case ) .",
    "thus the use of asynchrony represents another feature of rbn with the potential to significantly alter their underlying dynamics thereby offering another mechanism by which to aid the simulated evolutionary design process for a given task . di paulo @xcite showed it is possible to evolve asynchronous rbn which exhibit rhythmic behaviour at equilibrium .",
    "asynchronous cas have also been evolved ( e.g. , @xcite ) .",
    "figure  [ fig : k - affect - asynch ] shows the percentage of nodes changing state on each cycle for various values of @xmath2 on a 13 node asynchronous rbn .",
    "it can be seen that , similar to the synchronous case ( see figure  [ fig : k - affect - synch ] ) , the higher the value of @xmath2 , the greater the number of states the networks will cycle through in an attractor .",
    "these values are significantly lower than in the synchronous case however .",
    "for example , when @xmath5 , approximately 20% of nodes change each synchronously updated cycle compared with 5% when updated asynchronously .",
    "the difference is to be expected because , in the asynchronous case , `` the lack of synchronicity increases the complexity of the rbn , enhancing the number of possible states and interactions .",
    "and this complexity changes the attractor basins , transforming and enlarging them .",
    "this reduces the number of attractors and states in attractors '' @xcite .",
    "as previously mentioned , in the asynchronous case there are no cycle attractors , only point and loose attractors .",
    "an lcs rule ( also termed a classifier ) traditionally takes the form of an environment string consisting of the ternary alphabet [ 0,1 , # ] , a binary action string , and subsequent information including the classifier s expected payoff ( reward ) @xmath7 , the error rate @xmath8 ( in units of payoff predicted ) , and the fitness @xmath9 .",
    "the # symbol in the environment condition provides a mechanism to generalise the inputs received by matching for both logical 0 and 1 for that bit .    for each phase in the learning cycle ,",
    "a _ match set _",
    "[ m ] is generated from the _ population set _ [ p ] , comprising all of the classifiers whose environment condition matches the current environmental input . in the event that the number of actions present in [ m ] is less than a threshold value , @xmath10 , covering is used to produce a classifier that matches the current environment state along with an action assigned randomly from those not present in [ m ] ; typically @xmath10 is set to the maximum number of possible actions so that there must be at least one classifier representing each action present .",
    "subsequently , a system prediction is made for each action in [ m ] , based upon the fitness - weighted average of all of the predictions of the classifiers proposing the action . if there are no classifiers in [ m ] advocating one of the potential system actions , covering is invoked to generate classifiers that both match the current environment state and advocate the relevant action .",
    "an action is then selected using the system predictions , typically by alternating exploring ( by either roulette wheel or random selection ) and exploiting ( the best action ) . in multi - step problems a biased selection strategy is often employed wherein exploration is conducted at probability @xmath11 otherwise exploitation occurs @xcite .",
    "action set _ [ a ] is then built comprising all the classifiers in [ m ] advocating the selected action .",
    "next , the action is executed in the environment and feedback is received in the form of a payoff , @xmath7 .    in a single - step problem ,",
    "[ a ] is updated using the current reward .",
    "the ga is then run in [ a ] if the average time since the last ga invocation is greater than the threshold value , @xmath12 .",
    "when the ga is run , two parent classifiers are chosen ( typically by roulette wheel selection ) based on fitness .",
    "offspring are then produced from the parents , usually by use of recombination and mutation .",
    "typically , the offspring then have their payoff , error , and fitness set to the average of their parents. if subsumption is enabled and the offspring are subsumed by either parent , it is not included in [ p ] ; instead the parents numerosity is incremented . in a multi - step problem , the previous action set [ a]@xmath13 is updated using a q - learning @xcite type algorithm and the ga may be run as described above on [ a]@xmath13 as opposed to [ a ] for single - step problems .",
    "the sequence then loops until it is terminated after a predetermined number of problem instances .    in xcsf",
    "each classifier also maintains a vector of a series of weights , where there are as many weights as there are inputs from the environment , plus one extra , @xmath14 .",
    "that is , each classifier maintains a prediction ( @xmath15 ) which is calculated as a product of the environmental input ( @xmath16 ) and the classifier weight vector ( @xmath17 ) :    @xmath18    each of the input weights is initially set to zero , and subsequently adapted to accurately reflect the prediction using a _ modified delta rule _ @xcite .",
    "the delta rule was modified such that the correction for each step is proportional to the difference between the current and correct prediction , and controlled by a correction rate , @xmath19 .",
    "the _ modified delta rule _ for the reinforcement update is thus :    @xmath20    where @xmath19 is the correction rate and @xmath21 is the norm of the input vector @xmath16 .",
    "the values @xmath22 are used to update the weights of the classifier @xmath23 with :    @xmath24    subsequently , the prediction error @xmath8 is updated with :    @xmath25    this enables a more accurate , piecewise - linear , approximation of the payoff ( or function ) , as opposed to a piecewise - constant approximation , and can also be applied to binary problems such as the boolean multiplexer and maze environments , resulting in faster convergence to optimality as well as a more compact rule - base @xcite .",
    "see @xcite for further details .",
    "to use asynchronous rbn as the rules within xcsf ( see example rule in figure  [ fig : ddgp - examplerule ] ) , the following scheme is adopted .",
    "each of an initial randomly created rule s nodes has @xmath2 randomly assigned connections , here @xmath26 .",
    "there are initially as many nodes @xmath1 as input fields @xmath27 for the given task and its outputs @xmath28 , plus one other , as will be described , i.e. , @xmath29 . the first connection of each input node is set to the corresponding locus of the input message .",
    "the other connections are assigned at random within the rbn as usual . in this way ,",
    "the current input state is always considered along with the current state of the rbn itself per network update cycle by such nodes .",
    "nodes are initialised randomly each time the network is run to determine [ m ] , etc .",
    "the population is initially empty and covering is applied to generate rules as in the standard xcsf approach .",
    "l l l +   +   + & truth table : & connections : + node 0 ( m ) : & 10011000100000001110011010101000 & 7 , 4 , 0 , 3 , 1 + node 1 ( out ) : & 10 & 3 + node 2 ( i ) : & 00011111 & _ input1 _ , 2 , 5 + node 3 ( i ) : & 0001 & _ input2 _ , 2 + node 4 ( i ) : & 11101110 & _ input3 _ , 6 , 3 + node 5 ( i ) : & 0110110100001010 & _ input4 _ , 2 , 7 , 6 + node 6 ( i ) : & 0001011101010101 & _ input5 _ , 5 , 2 , 3 + node 7 ( i ) : & 0100 & _ input6 _",
    ", 3 + node 8 ( n ) : & 00010111 & 3 , 1 , 5 +    matching consists of executing each rule for @xmath30 cycles based on the current input .",
    "the value of @xmath30 is chosen to be a value typically within the basin of attraction of the rbn .",
    "asynchrony is here implemented as a randomly chosen node being updated on a given cycle , with as many updates per overall network update cycle as there are nodes in the network before an equivalent cycle to one in the synchronous case is said to have occurred .",
    "see @xcite for alternative schemes .    in this study , where well - known maze problems are explored",
    "there are eight possible actions and accordingly three required output nodes .",
    "an extra `` matching '' node is also required to enable rbns to ( potentially ) only match specific sets of inputs . if a given rbn has a logical ` 0 ' on the match node , regardless of its output node s state , the rule does not join [ m ] . this scheme has also been exploited within neural lcs @xcite .",
    "a ` windowed approach ' is utilised where the output is decided by the most common state over the last @xmath31 steps up to @xmath30 .",
    "for example , if the last few states on a node updating prior to cycle @xmath30 is 0101001 and @xmath32 , then the ending node s state would be ` 0 ' and not ` 1 ' .    when covering is necessitated , a randomly constructed rbn is created and then executed for @xmath30 cycles to determine the status of the match and output nodes .",
    "this procedure is repeated until an rbn is created that matches the environment state .",
    "self - adaptive mutation affecting a variable length representation was first explored by fogel _",
    "@xcite where a self - adaptive value was used to control the deletion rate of states within finite state machines .",
    "furthermore , ghozeil and fogel @xcite used self - adaptive mutation to control the rate of addition and deletion of hyperboxes to cluster spatial data .",
    "self - adaptive mutation was first applied within lcs by bull",
    "_ et al . _",
    "@xcite where each rule maintains its own mutation rate @xmath33 . self - adaptive mutation affecting rule size was first used in lcs with a neural representation @xcite .",
    "this is similar to the approach used in evolution strategies ( es ) @xcite where the mutation rate is a locally evolving entity in itself , i.e. , it adapts during the search process .",
    "self - adaptive mutation not only reduces the number of hand - tunable parameters of the evolutionary algorithm , it has also been shown to improve performance .",
    "following @xcite , mutation only is used here .",
    "a node s truth table is represented by a binary string and its connectivity by a list of @xmath2 integers in the range @xmath34 $ ] .",
    "since each node has a given fixed @xmath2 value , each node maintains a binary string of length @xmath35 which forms the entries in the look - up table for each of the possible @xmath35 input states of that node , i.e. , as in the aforementioned work @xcite on evolving cas , for example .",
    "these strings are subjected to mutation on reproduction at the self - adapting rate @xmath33 for that rule .",
    "hence , within the rbn representation , evolution can define different boolean functions for each node within a given network rule , along with its connectivity map .",
    "specifically , each rule has its own mutation rate stored as a real number and initially seeded uniform randomly in the range @xmath36 $ ] .",
    "this parameter is passed to its offspring .",
    "the offspring then applies its mutation rate to itself using a gaussian distribution , i.e. , @xmath37 , before mutating the rest of the rule at the resulting rate .",
    "due to the need for a possible different number of nodes within the rules for a given task , the dgp scheme is also of variable length .",
    "once the truth table and connections have been mutated , a new randomly connected node is either added or the last added node is removed with the same probability @xmath33 . the latter case only occurs if the network currently consists of more than the initial number of nodes .",
    "in addition , each rule maintains its own @xmath30 value which is initially seeded randomly between 1 and 50 .",
    "thereafter , offspring potentially increment or decrement @xmath30 by 1 at probability @xmath33 .",
    "@xmath31 is evolved in a similar fashion , however it is initially seeded between 0 and @xmath30 , and can not be greater than @xmath30 .",
    "thus dgp is temporally dynamic both in the search process and the representation scheme .    whenever an offspring classifier is created and no changes occur to its rbn when undergoing mutation , the parent s numerosity is increased and mutation rate set to that of the offspring .",
    "the simplest form of short - term memory is a fixed - length buffer containing the @xmath38 most recent inputs ; a common extension is to then apply a kernel function to the buffer to enable non - uniform sampling of the past values , e.g. an exponential decay of older inputs @xcite .",
    "however it is not clear that biological systems make use of such shift registers .",
    "registers require some interface with the environment which buffers the input so that it can be presented simultaneously .",
    "they impose a rigid limit on the duration of patterns , defining the longest possible pattern and requiring that all input vectors be of the same length .",
    "furthermore , such approaches struggle to distinguish relative temporal position from absolute temporal position @xcite .",
    "whereas many gp systems are expression based , some have also utilised a form of memory or state .",
    "for example , linear gp @xcite ; indexed memory , e.g. , @xcite , @xcite , and @xcite ; and work on evolving data structures which maintain internal state , e.g. , @xcite .",
    "in addition , some systems have used ( instead of evolved ) data structures to manipulate the internal state , e.g. , pushgp @xcite .",
    "recently , poli _ et al . _",
    "@xcite explored the use of soft assignment and soft return operations as forms of memory within linear and tree - based gp . for soft assignment",
    ", they replaced the traditional ( entirely destructive ) method of variable assignment with one of merging new values with previous ones , instead of overwriting them . to achieve this ,",
    "the new value becomes a weighted average of the old register value with the new value to be assigned , i.e. , @xmath39 where @xmath40 is a value in the range [ 0,1 ] specifying the assignment `` hardness '' .",
    "for soft return operations , tree function nodes return a weighted average of their first argument with the result of the corresponding calculation , i.e. , @xmath41 where @xmath42 is an input to a function , @xmath43 .    here",
    "we explore and extend the hypothesis of inherent content - addressable memory existing within synchronous rbn due to different possible routes to a basin of attraction @xcite for the asynchronous case by maintaining the node states across each input - update - output cycle .",
    "a significant advantage of this approach is that each rule / network s short - term memory is variable - length and _ adaptive _ , i.e. , the networks can adjust the memory parameters , selecting within the limits of the capacity of the memory , what aspects of the input sequence are available for computing predictions @xcite .",
    "in addition , as we use open - ended evolution , the maximum size of the short - term memory is also open - ended , increasing as the number of nodes within the network grows .    here , nodes are initialised at random for the initial random placing in the maze but thereafter they are not reset for each subsequent matching cycle .",
    "consequently , each network processes the environmental input and the final node states then become the starting point for the next processing cycle , whereupon the network receives the new environmental input and places the network on a trajectory toward a ( potentially ) different locally stable limit point . therefore , a network given the same environmental input ( i.e. , the agent s current maze perception ) but with different initial node states ( representing the agent s history through the maze ) may fall into a different basin of attraction ( advocating a different action ) . _",
    "thus the rules dynamics are ( potentially ) constantly affected by the inputs as the system executes .",
    "_    we now apply ddgp - xcsf to two well - known multi - step non - markov maze environments that require memory to resolve perceptual aliasing : woods101 ( see figure  [ fig : woods101 ] ) and woods102 ( see figure  [ fig : woods102 ] ) .    each cell in the maze environments is encoded with two binary bits , where white space is represented as a ` * ' , obstacles as ` o ' , and food as ` f ' .",
    "furthermore , actions are encoded in binary as shown in figure  [ fig : maze - encoding ] . the task is simply to find the shortest path to the food ( f ) given a random start point .",
    "obstacles ( o ) represent cells which can not be occupied . in woods1",
    "the optimal number of steps to the food is 1.7 , in maze4 optimal is 3.5 steps , in woods101 it is 2.9 , and in woods102 it is 3.23 .",
    "a teletransportation mechanism is employed whereby a trial is reset if the agent has not reached the goal state within 50 discrete movements .",
    "+      the woods101 maze ( see figure  [ fig : woods101 ] ) is a non - markov environment containing two _ communicating aliasing states _ ,",
    "i.e. , two positions which border on the same non - aliasing state and are identically sensed , but require different optimal actions .",
    "thus , to solve this maze optimally , a form of memory must be utilised ( with at least two internal states ) .",
    "optimal performance has previously been achieved in woods101 through the addition of a memory register mechanism in lcs @xcite , by a corporate lcs using rule - linkage @xcite , and by a neural lcs using recurrent links @xcite .",
    "furthermore , in a proof of concept experiment , the cyclical directed graph from neural programming has been shown capable of representing rules with memory to solve woods101 , however it was only found to do so twice in fifty experiments @xcite .",
    "figure  [ fig : ddgp - xcsf - woods101-all ] shows the performance of ddgp - xcsf in the woods101 environment with @xmath44 , @xmath45 , @xmath46 , @xmath47 , @xmath48 , @xmath49 , @xmath50 , @xmath51 , and @xmath52 ( 16 inputs , 3 outputs , 1 match node ) . here ,",
    "optimality is observed after approximately 6,000 trials ( figure  [ fig : ddgp - xcsf - woods101-perf ] ) .",
    "this is similar to the performance of lcs using a 1-bit memory register ( @xmath537,000 trials , @xmath54 ) @xcite .",
    "the number of macro - classifiers in the population converges to around 1800 ( figure  [ fig : ddgp - xcsf - woods101-sizemut ] ) .",
    "furthermore , the average number of nodes in the networks increases by almost one and the number of connections declines fractionally ( figure  [ fig : ddgp - xcsf - woods101-topology ] ) .",
    "the mutation rate ( also figure  [ fig : ddgp - xcsf - woods101-sizemut ] ) declines rapidly from approx 35% to its lowest point , 1.2% , around the six thousandth trial , which is at the same moment optimal performance is also observed .",
    "lastly , figure  [ fig : ddgp - xcsf - woods101-topology ] conveys that the first thousand trials sees a rapid increase in the number of cycles , @xmath30 , ( 30.6 to 34.4 ) and a rapid decrease in the value of @xmath31 ( 17 to 14.7 ) .",
    "subsequently , @xmath30 continues to increase , ( although at a much slower rate ) along with the average number of nodes in the networks ; @xmath31 remains stable at just fewer than 15 .     +      the woods102 maze ( see figure  [ fig : woods102 ] ) is a non - markov environment containing _ aliasing conglomerates _ ,",
    "i.e. , adjacent aliasing states .",
    "the introduction of aliasing conglomerates increases the complexity of the learning task facing the agent significantly .",
    "`` it would appear that three memory - register bits are required to resolve [ the ] perceptual aliasing .",
    "however , since the two situations occur in separate parts of the environment , there is the possibility that an optimal policy could evolve in which certain register bits are used in more than one situation , thus requiring fewer bits in all .",
    "it is therefore not clear how large a bit - register is strictly necessary '' @xcite .",
    "however , in practice , register redundancy was found to be important and an 8-bit memory register was required within lcs to solve the maze optimally , with 2 and 4-bit registers achieving only 4 and 3.7 steps respectively ( ibid . ) .",
    "figure  [ fig : ddgp - xcsf - woods102-all ] shows the performance of ddgp - xcsf in woods102 with the same parameters used in the prior experiment , however , here @xmath55 and @xmath56 .",
    "although a population size of 20,000 may seem disproportionate , a population of 2,000 classifiers was required for woods101 , representing a scale up of @xmath57 , which can be compared with the increase required by lcs with a memory register ( 800 to 6,000 , or @xmath58 ) , where the potential number of internal actions required rises from @xmath59 to @xmath60 ( ibid . ) , thus resources are clearly not increasing as quickly as the search space .",
    "optimality is observed after approximately 80,000 trials ( figure  [ fig : ddgp - xcsf - woods102-perf ] ) , this is slower than lcs with an explicit 8-bit memory register ( @xmath5330,000 trials , @xmath61 ) @xcite .",
    "however here the size of the memory did not need to be predetermined as it is inherent within the networks , and the action selection policy remains constant , with constant ga activity , unlike in @xcite .",
    "the number of macro - classifiers in the population converges to around 17,750 ( figure  [ fig : ddgp - xcsf - woods102-sizemut ] ) .",
    "furthermore , the average number of nodes in the networks increases fractionally to 20.6 and the number of connections declines on average from 2.95 to 2.82 ( figure  [ fig : ddgp - xcsf - woods102-topology ] ) .",
    "the mutation rate ( figure  [ fig : ddgp - xcsf - woods102-sizemut ] ) declines rapidly over the first 40,000 trials from 32% to 5% and reaches its lowest point , 3.5% , at 100,000 trials .",
    "lastly , from figure  [ fig : ddgp - xcsf - woods102-topology ] it can be seen that on average @xmath30 increases from 30 to 35 and @xmath31 from 17.5 to 20.5 .     +",
    "continuous network models of genetic regulatory networks ( grn ) are an extension of boolean networks where nodes still represent genes , and the connections between them regulate the influence on gene expression .",
    "differential equations wherein gene interactions are incorporated as logical functions are a typical approach @xcite .",
    "there is a growing body of work exploring the evolution of different forms of such continuous - valued grn .",
    "for example , knabe _ et al .",
    "_ @xcite devised a model that allows the grouping of inputs to a node and is formally closer to a higher order recurrent neural network .",
    "this was later used to model the evolution of cellular differentiation @xcite and multicellular morphogenesis @xcite .",
    "another model is the dynamic recurrent gene network ( drgn ) @xcite which consist of a fully connected network of @xmath1 nodes , each with a continuous activation state in the range [ 0,1 ] , updated synchronously . here",
    "a distinction is made between structural nodes ( i.e. , nodes that specify the current state but have no regulatory output ) and regulatory nodes ( i.e. , nodes that only play a regulatory role ) .",
    "a single input node is used to specify the relative position of the cell in the lineage . to simulate the development of an organism , the node activations and the relative position input",
    "are initialised .",
    "subsequently , cell division occurs through repeatedly duplicating the network , adjusting the relative positions in each network , and updating the states .",
    "the network weights are adapted through the use of an evolutionary algorithm .",
    "furthermore , dynamic bayesian networks ( dbn ) @xcite combine bayesian networks ( bn ) @xcite with features of hidden markov models @xcite , incorporating feedback cycles that simulate the temporal evolution of the network .",
    "dbn provide a stochastic model where both discrete and continuous states are possible .",
    "heuristics are used to learn the connectivity map and create additional hidden nodes .",
    "dbn have been shown to generalise many of the grn models including rbn ( see @xcite ) .",
    "fuzzy cellular automata ( fuzzy - ca ) @xcite are an extension of boolean cellular automata ( ca ) and consists of an array of cells ( lattice of nodes ) where the cells exist in real - valued states in the range [ 0,1 ] and ( typically ) update their states with synchronous parallelism in discrete time .",
    "traditionally , each cell calculates its next state depending upon its current state and the states of its closest neighbours .",
    "that is , fuzzy - ca may be seen as a graph with a ( typically ) restricted topology .",
    "since both transition and output functions are replaced by fuzzy relations , fuzzy - ca include deterministic and non - deterministic finite automata as special cases @xcite and were initially applied to pattern recognition and automatic control problems @xcite .",
    "following cattaneo _",
    "@xcite , reiter @xcite investigated the affect of the fuzzy background on the dynamics of cellular automata with various fuzzy logic sets .",
    "they found that the choice of logic used leads to significantly different behaviours .",
    "for example , applying the various logical functions to create fuzzy versions of the game of life , it was noted that certain sets of logics generated fuzzy - ca that tended toward homogeneous fuzzy behaviour , whereas others were consistent with chaotic or complex behaviour .",
    "fuzzy set theory @xcite is a generalization of boolean logic wherein continuous variables can partially belong to sets .",
    "a fuzzy set is defined by a membership function , typically within the range [ 0,1 ] , that determines the degree of belonging to a value of that set .",
    "fuzzy set theory has been successfully applied to myriad engineering , medical , business , and natural science problems .",
    "genetic fuzzy systems ( gfs ) @xcite use gas to optimise a fuzzy rule based system composed of `` if - then '' rules , whose antecedents and consequents comprise fuzzy logic statements from fuzzy set theory . the first application of the ga - only , i.e. , pittsburgh , approach to learning a fuzzy rule base was by thrift @xcite .",
    "valenzuela - rendon @xcite provided the first use of the michigan approach for reinforcement learning with an evolving set of fuzzy rules .",
    "this was later extended to enable delayed - reward reinforcement learning @xcite , including continuous multi - step problems using continuous vector actions @xcite .",
    "fuzzy logic has been used in accuracy - based lcs for single - step reinforcement learning @xcite and for data mining on several uci data sets @xcite .",
    "in addition , fuzzy logic has been used under a lcs supervised learning scheme for data mining on uci data sets @xcite and for epidemiologic classification @xcite .    aside from using lcs , alternative rule - like approaches have been applied such as @xcite who used a ga to modify a fuzzy relational matrix of a one - input , one - output fuzzy model .    by combining fuzzy logic with neural networks , neurons can deal with imprecision @xcite . bull and ohara @xcite presented a form of fuzzy representation within lcs using radial basis function neural networks ( rbf ) @xcite to embody each condition - action rule .",
    "that is , a simple class of neural - fuzzy hybrid system .",
    "furthermore , su _ et al . _",
    "@xcite explored a similar representation based on rbf within lcs .",
    "however , here the contribution of each rule is determined by its strength ( which is updated by a fuzzy bucket brigade algorithm ) as well as the extent to which the antecedent matches the environment .",
    "furthermore , in contrast to bull and ohara @xcite , each condition - action rule corresponds to a hidden node instead of a fully - connected network and rules are added incrementally instead of being evolved through the ga . to date , only the use of rbf has been explored as a neuro - fuzzy hybrid representation within lcs .",
    "fuzzy logic networks ( fln ) @xcite can be seen as both a generalization of fuzzy - ca and rbn , where the boolean functions from rbn are replaced with fuzzy logical functions from fuzzy set theory .",
    "thus , fln generalize rbn through a continuous representation and generalize fuzzy - ca through a less restricted graph topology .",
    "kok and wang @xcite explored 3-gene regulation networks using fln and found that not only were fln able to represent the varying degrees of gene expression but also that the dynamics of the networks were able to mimic a cell s irreversible changes into an invariant state or progress through a periodic cycle .",
    "fln are defined as , given a set of @xmath1 variables ( genes ) , @xmath62 ( i=1 , 2 , ... , n)\\ ] ] index @xmath63 represents time ; and the variables are updated by means of dynamic equations , @xmath64 where @xmath65 is a randomly chosen fuzzy logical function .",
    "the total number of choices for fuzzy logical functions is decided only by the number of inputs .",
    "if a node has @xmath66 inputs , then there are @xmath35 different fuzzy logical functions . in the definition of fln ,",
    "each node , @xmath67 has @xmath2 inputs ( see figure  [ fig : example - fln ] ) .",
    "the membership function is defined as a function @xmath68 $ ] where @xmath69 is the degree of membership @xcite . in all work thus far , all nodes are updated simultaneously , i.e. , synchronously .",
    "a number of different fuzzy logic sets have been introduced since the original max / min method was proposed .",
    "other commonly used fuzzy logics include cfmqvs , probabilistic , mv , and gcd / lcm @xcite .",
    "as previously mentioned , the choice of fuzzy set can result in significantly different behaviour .",
    "therefore , in this paper a range of the most commonly used logics is potentially selectable ( see table  [ table : fuzzylogics ] ) , leaving evolution to identify the most appropriate combinations for a given problem .",
    ".selectable fuzzy logic functions [ cols=\"<,<,<\",options=\"header \" , ]     [ table : fuzzylogics ]    as previously mentioned , fln are typically updated synchronously , however asynchronous schemes in ca , rbn , and fuzzy - ca have been shown to provide a number of benefits , such as modeling the dynamics of grn more realistically .",
    "figure  [ fig : fuzzy - k - affect - asynch ] shows the affect of @xmath2 on a 13 node fln updated asynchronously and figure  [ fig : fuzzy - k - affect - synch ] when updated synchronously ; results are an average of one hundred experiments for each value of @xmath2 .",
    "in contrast to rbn where larger @xmath2 results in an increased percentage of nodes changing state per update cycle @xcite , it can be seen that with fln the greater the value of @xmath2 , the less the number of states the networks will cycle through within an attractor .",
    "this is due to the tendency of the fuzzy logic functions to gravitate to extremes ( i.e. , 0 or 1 ) with increased inputs .",
    "after an initial rapid decline in the rate of change , the networks begin to stabilise as the states fall into their respective attractors .",
    "however , similarly to rbn , it can be seen that an asynchronous updating scheme results in a lower percent of nodes changing state when compared to the synchronous case . in the asynchronous case , when @xmath5 , the number of nodes changing state converges to around 10% compared with 30% of synchronous nodes , and when @xmath70 to approximately 2.5% compared with 7% of nodes in the synchronous case .",
    "whereas fln have been used previously to model aspects of grn , no prior studies have explored the evolution of the networks for computation .",
    "furthermore , all prior studies have only considered a synchronous updating scheme . to use asynchronous fln as the rules within xcsf ( hereinafter , `` fdgp - xcsf '' ) ,",
    "the following scheme is adopted .",
    "each of an initial randomly created rule s nodes has @xmath2 randomly assigned connections , here @xmath71 , where a node with @xmath72 thus retains a constant node state .",
    "there are initially as many nodes @xmath1 as input fields @xmath27 for the given task and its outputs @xmath28 , plus one other , for matching , i.e. , @xmath29 .",
    "the first connection of each input node is set to the corresponding locus of the input message .",
    "the other connections are assigned at random within the fln .",
    "node states are initialised at random for the first step of a trial but thereafter they are not reset for each subsequent matching cycle .",
    "the population is initially empty and covering is applied to generate rules as in the standard xcsf approach .",
    "if a given fln has a ( real ) value of fewer than 0.5 on the match node , regardless of the state of its outputs , the rule does not join [ m ] ( see figure  [ fig : example - fln ] ) .",
    "this scheme has also been exploited within neural lcs @xcite .",
    "the output nodes are discretised in a similar fashion where a state fewer than 0.5 translates to a binary 0 , otherwise 1 . furthermore",
    ", a windowed approach is utilised whereby the final state of each node is calculated as an average over the last @xmath31 cycles to @xmath30 .    a node s function",
    "is represented by an integer which references the appropriate operation to execute upon its received inputs ( see table  [ table : fuzzylogics ] for the fuzzy functions used ) .",
    "further , each node s connectivity is represented as a list of max_k integers ( here max_k = 5 ) in the range @xmath73 $ ] , where 0 represents no input to be received on that connection .",
    "each integer in the list is subjected to mutation on reproduction at the self - adapting rate @xmath33 for that rule .",
    "hence , within the representation , evolution can select different fuzzy logic functions for each node within a given network rule , along with its connectivity map .",
    "the 2-d continuous gridworld environment @xcite is a two dimensional environment wherein the current state is a real valued coordinate @xmath74 ^ 2 $ ] .",
    "the agent is initially randomly placed within the grid and attempts to find the shortest path to the goal , located in the upper right corner ; more specifically , in this paper the goal is found when @xmath75 , at which point the agent is given a fixed reward of 1000 , otherwise 0 is given .",
    "any action that would take the system outside of the environment moves the system to the nearest boundary .",
    "a teletransportation mechanism is employed whereby a trial is reset if the agent has not reached the goal state within 500 movements . as actions ,",
    "the agent may choose one of four possible movements ( north , south , east , or west ) each of which is a step size , @xmath76 , of 0.05 .",
    "the optimal number of steps is thus 18.6 .",
    "the continuous state space , combined with the long sequence of actions required to reach the goal , make the continuous gridworld one of the most challenging multistep problems hitherto considered by lcs @xcite .",
    "figure  [ fig : fdgp - grid - all ] shows the performance of fdgp - xcsf in the continuous gridworld environment using the same parameters used by @xcite . however , here @xmath56 , @xmath77 ( 2 inputs , 2 outputs , 1 match node ) . from figure",
    "[ fig : fdgp - grid - perf ] it can be seen that an optimal solution is learnt around 30,000 trials , which is slower than xcsf with interval - conditions ( @xmath5315,000 trials , @xmath78 ) @xcite , however is similar in performance to an mlp - based neural - xcsf @xcite .",
    "the average mutation rate within the networks ( see figure  [ fig : fdgp - grid - sizemut ] ) declines rapidly from 40% to 5% after 10,000 trials and then declines at a slower rate until reaching a bottom around 2.5% after 50,000 trials .",
    "the number of ( non - unique ) macro - classifiers ( also figure  [ fig : fdgp - grid - sizemut ] ) initially grows rapidly , reaching a peak at 10,000 before declining to around 6,900 .",
    "furthermore , from figure  [ fig : fdgp - grid - top ] it can be seen that the average number of nodes in the fuzzy logic networks increases from 5 to 7.1 and the average number of connections within the networks remains near static around 2 .",
    "additionally , the average value of @xmath31 remains static around 10 , while the value of @xmath30 increases slightly , on average , from 26 to  27 .",
    "+      the frog problem @xcite is a single - step problem with a non - linear continuous - valued payoff function in a continuous one - dimensional space .",
    "a frog is given the learning task of jumping to catch a fly that is at a distance , @xmath79 , from the frog , where @xmath80 .",
    "the frog receives a sensory input , @xmath81 , before jumping a chosen distance , @xmath82 , and receiving a reward based on its new distance from the fly , as given by :    @xmath83    in the continuous - action case , the frog may select any continuous number in the range [ 0,1 ] and thus the optimal achievable performance is 100% .",
    "wilson @xcite presented a form of xcsf where the action was computed directly as a linear combination of the input state and a vector of action weights , and conducted experimentation on the continuous - action frog problem , selecting the classifier with the highest prediction for exploitation .",
    "@xcite subsequently extended this by adapting the action weights to the problem through the use of an evolution strategy ( es ) .",
    "in addition to the action weights , a vector of standard deviations is maintained for use as the mutation step size by the es . during exploration ,",
    "the es is applied to each member of [ a ] to evolve the action weights and standard deviations , where each rule functions as a single parent producing an offspring via mutation ; the offspring is then evaluated on the current environment state and its fitness updated and compared with the parent , if the offspring has a higher fitness it replaces the parent , otherwise it is discarded . moreover ,",
    "the exploration action selection policy was modified from purely random to selecting the action with the highest prediction . after reinforcement updates and running the es ,",
    "the ga is invoked using a combination of mixed crossover and mutation .",
    "they reported greater than 99% performance after an averaged number of 30,000 trials ( @xmath44 ) , which was superior to the performance reported by @xcite .",
    "more recently , ramirez - ruiz _ et al . _",
    "@xcite applied a fuzzy - lcs with continuous vector actions , where the ga only evolved the action parts of the fuzzy systems , to the continuous - action frog problem , and achieved a lower error than q - learning ( discretized over 100 elements in @xmath84 and @xmath82 ) after 500,000 trials ( @xmath85 ) .    to accommodate continuous - actions",
    ", the following modifications were made to fdgp - xcsf .",
    "firstly , the output nodes are no longer discretized , instead providing a real numbered output in the range [ 0,1 ] . after building [ m ] in the standard way , [ a ]",
    "is built by selecting a single classifier from [ m ] and adding matching classifiers whose actions are within a predetermined range of that rule s proposed action ( here the range , or window size , is set to @xmath86 ) .",
    "parameters are then updated and the ga executed as usual in [ a ] .",
    "exploitation functions by selecting the single ` best ' rule from [ m ] ; the following experiments compare the performance achieved using various criteria to select the best rule from the match set .",
    "the parameters used here are the same as used by @xcite and @xcite , i.e. , @xmath44 , @xmath45 , @xmath87 , @xmath88 , @xmath89 , @xmath48 , @xmath49 , @xmath50 .",
    "only one output node is required and thus @xmath90 .",
    "figure  [ fig : fdgp - frog - all ] illustrates the performance of fdgp - xcsf in the continuous - action frog problem . from figure",
    "[ fig : fdgp - frog - asynch ] it can be seen that greater than 99% performance is achieved in fewer than 4,000 trials ( @xmath44 ) , which is faster than previously reported results ( @xmath099% after 30,000 trials , @xmath44 @xcite ) ( @xmath095% after 10,000 trials , @xmath44 @xcite ) , and with minimal changes resulting in none of the drawbacks ; i.e. , exploration is here conducted with roulette wheel on prediction instead of deterministically selecting the highest predicting rule , an approach more suitable for online learning .",
    "furthermore , in @xcite the action weights update component includes the evaluation of the offspring on the last input / payoff before being discarded if the mutant offspring is not more accurate than the parent ; therefore additional evaluations are performed which are not reflected in the number of trials reported .    from figure",
    "[ fig : fdgp - frog - asynch - top ] it can be seen that the average number of ( non - unique ) macro - classifiers rapidly increases to approximately 1400 after 3,000 trials , before converging to around 150 ; this is more compact than xcsf with interval conditions ( @xmath531400 ) @xcite , showing that fdgp - xcsf can provide strong generalisation .",
    "in addition , the networks grow , on average , from 3 nodes to 3.5 , and the average connectivity remains static around 1.9 . the average mutation rate declines from 50% to 2% over the first 15,000 trials before converging to around 1.2% and the average value of @xmath30 increases by from 28.5 to 31.5 .",
    "this paper has explored examples of a temporally dynamic graph - based representation updated with asynchronous parallelism ( dgp ) .",
    "the dgp syntax presented consists of each node receiving an arbitrary number of inputs from an unrestricted topology ( i.e. , recursive connections are permitted ) , and then performing an arbitrary function . the representation is evolved under a self - adaptive and open - ended scheme , allowing the topology to grow to any size to meet the demands of the problem space .    in the discrete case , dgp is equivalent to a form of random boolean network ( rbn ) .",
    "it was shown that the xcsf learning classifier system is able to design ensembles of asynchronous rbn whose emergent behaviour can collectively solve discrete - valued computational tasks under a reinforcement learning scheme . in particular , it was shown possible to evolve and retrieve the content - addressable memory existing as locally stable limit points ( attractors ) within the asynchronously ( randomly ) updated networks when the final node states from the previous match processing cycle become the starting states for the next environmental input .",
    "furthermore , it was shown that the parameters controlling system sampling of the networks dynamical behaviour can be made to self - adapt to the temporal complexities of the target environment .",
    "the introduced system thus does not need prior knowledge of the dynamics of the solution networks necessary to represent the environment .",
    "in particular , the representation scheme was exploited to solve the woods102 non - markov maze ( i.e. , without extra mechanisms ) , a maze which has only previously been solved by lcs using an explicit 8-bit memory register .",
    "a significant advantage of the memory inherent within dgp is that each rule / network s short - term memory is variable - length and adaptive , i.e. , the networks can adjust the memory parameters , selecting within the limits of the capacity of the memory , what aspects of the input sequence are available for computing predictions .",
    "in addition , as the topology is variable - length , the maximum size of the short - term memory is open - ended , increasing as the number of nodes within the network grows .",
    "thus the maximum size of the content - addressable memory does not need to be predetermined .",
    "subsequently , the generality of the dgp scheme was further explored by replacing the selectable boolean functions with fuzzy logical functions , permitting the application to continuous - valued domains .",
    "specifically , the collective emergent behaviour of ensembles of asynchronous fuzzy logic networks were shown to be exploitable in solving continuous - valued input - output reinforcement learning problems , with similar performance to mlp - based neural - xcsf in the continuous - valued multi - step grid environment and superior performance to those reported previously in the frog problem .",
    "angeline , p.j . : an alternative to indexed memory for evolving programs with explicit state representations . in : proceedings of the 2nd annual conference on genetic programming .",
    ". 423430 .",
    "morgan kaufmann ( 1997 )      balan , g.c . , luke , s. : a demonstration of neural programming applied to non - markovian problems . in : proceedings of the 6th annual conference on genetic and evolutionary computation .",
    "gecco 04 , acm ( 2004 )    banzhaf , w. , nordin , p. , keller , r.e . ,",
    "francone , f.d .",
    ": genetic programming : an introduction : on the automatic evolution of computer programs and its applications .",
    "the morgan kaufmann series in artificial intelligence , morgan kaufmann ( 1997 )    bonarini , a. : fuzzy and crisp representations of real - valued input for learning classifier systems . in : learning classifier systems , from foundations to applications .",
    "lnai , vol .",
    "1813 , pp . 107124 .",
    "springer - verlag , berlin ( 2000 )    boyan , j. , moore , a. : generalization in reinforcement learning : safely approximating the value function . in : advances in neural information processing systems",
    "369376 . nips 1995 , mit press ( 1995 )        bull , l. : on using constructivism in neural classifier systems . in : merelo , j.j .",
    ", adamidis , p. , beyer , h.g .",
    "parallel problem solving from nature : ppsn vii , lecture notes in computer science , vol .",
    "2439 , pp .",
    "springer berlin / heidelberg ( 2002 )      bull , l. , hurst , j. , tomlinson , a. : self - adaptive mutation in classifier system controllers . in : meyer , j.a .",
    ", berthoz , a. , floreano , d. , roitblat , h. , wilson , s.w .",
    "( eds . ) from animals to animats 6 , proceedings of the sixth international conference on simulation of adaptive behavior .",
    "460468 . mit press ( 2000 )    bull , l. , hurst , j. : a neural learning classifier system with self - adaptive constructivism . in : evolutionary computation , 2003 .",
    "the ieee congress on .",
    "vol .  2 , pp .",
    "991997 . ieee press ( december 2003 )    bull , l. , ohara , t. : accuracy - based neuro and neuro - fuzzy classifier systems . in : proceedings of the genetic and evolutionary computation conference .",
    "gecco 02 , morgan kaufmann publishers inc .",
    ", san francisco , ca , usa ( 2002 )    bull , l. , preen , r.j . : on dynamical genetic programming : random boolean networks in learning classifier systems . in : proceedings of the 12th european conference on genetic programming .",
    "eurogp 09 , springer - verlag , berlin , heidelberg ( 2009 )    cao , y. , wang , p. , tokuta , a. : gene regulatory network modeling : a data driven approach . in : wang ,",
    "p. , ruan , d. , kerre , e. ( eds . ) fuzzy logic , studies in fuzziness and soft computing , vol .",
    "springer berlin / heidelberg ( 2007 )        di , j. , lala , p.k . : cellular array - based delay - insensitive asynchronous circuits design and test for nanocomputing systems .",
    "journal of electronic testing : theory and applications 23 , 175192 ( june 2007 )            fogel , d.b .",
    ", angeline , p.j . , fogel , d.b .",
    ": an evolutionary programming approach to self - adaptation on finite state machines . in : proceedings of the fourth annual conference on evolutionary programming .",
    "mit press ( 1995 )    fogel , l.j . ,",
    "owens , a.j . ,",
    "walsh , m.j . : artificial intelligence through a simulation of evolution . in : biophysics and cybernetic systems : proceedings of the 2nd cybernetic sciences symposium .",
    ". 131155 .",
    "spartan book co. , washington , d.c . , usa ( 1965 )        ghahramani , z. : learning dynamic bayesian networks . in : adaptive processing of sequences and data structures , international summer school on neural networks , `` e.r .",
    "caianiello''-tutorial lectures .",
    ". 168197 .",
    "springer - verlag , london , uk ( 1998 )    ghozeil , a. , fogel , d.b . : discovering patterns in spatial data using evolutionary programming . in : proceedings of the first annual conference on genetic programming .",
    "gecco 96 , mit press , cambridge , ma , usa ( 1996 )          hirasawa , k. , okubo , m. , katagiri , h. , hu , j. , murata , j. : comparison between genetic network programming ( gnp ) and genetic programming ( gp ) . in : evolutionary computation , 2001 .",
    "proceedings of the ieee congress on .",
    "vol .  2 , pp .",
    "ieee press ( 2001 )          ioannides , c. , browne , w. : investigating scaling of an abstracted lcs utilising ternary and s - expression alphabets . in : bacardit , j. , bernado - mansilla , e. , butz , m.v . , kovacs , t. , llora , x. , takadama , k. ( eds . ) learning classifier systems , pp .",
    "springer - verlag , berlin , heidelberg ( 2008 )            knabe , j.f .",
    ", schilstra , m.j . ,",
    "nehaniv , c.l . : evolution and morphogenesis of differentiated multicellular organisms : autonomously generated diffusion gradients for positional information . in : proceedings of the 7th german workshop on artificial life 2006 .",
    "gwal-7 , akademische verlagsgesellschaft aka ( 2006 )    knabe , j.f . ,",
    "schilstra , m.j . ,",
    "nehaniv , c.l . : evolution and morphogenesis of differentiated multicellular organisms : autonomously generated diffusion gradients for positional information . in : artificial life xi : proceedings of the eleventh international conference on the simulation and synthesis of living systems .",
    "321328 . mit press ( 2008 )    kok , t. , wang , p. : a study of 3-gene regulation networks using nk - boolean network model and fuzzy logic networking . in : kahraman , c. ( ed . )",
    "fuzzy applications in industrial engineering , studies in fuzziness and soft computing , vol .",
    "springer berlin / heidelberg ( 2006 )              lanzi , p.l . : mining interesting knowledge from data with the xcs classifier system . in : proceedings of the genetic and evolutionary computation conference .",
    ". 958965 .",
    "gecco 01 , morgan kaufmann ( 2001 )        lanzi , p.l . ,",
    "loiacono , d. , wilson , s.w . ,",
    "goldberg , d.e . : xcs with computed prediction in continuous multistep environments . in : evolutionary computation , 2005 .",
    "the 2005 ieee congress on .",
    "vol .  3 , pp .",
    "ieee press ( september 2005 )    lanzi , p.l . , perrucci , a. : extending the representation of classifier conditions part ii : from messy coding to s - expressions . in : proceedings of the genetic and evolutionary computation conference .",
    "gecco 99 , morgan kaufmann ( 1999 )    lanzi , p.l . , rocca , s. , sastry , k. , solari , s. : analysis of population evolution in classifier systems using symbolic representations . in : bacardit , j. , bernad - mansilla , e. ,",
    "butz , m.v .",
    ", kovacs , t. , llor , x. , takadama , k. ( eds . ) learning classifier systems , lecture notes in computer science , vol .",
    "4998 , pp .",
    "springer berlin / heidelberg ( 2008 )        lemke , n. , mombach , j.c.m .",
    ", bodmann , b.e.j . : a numerical investigation of adaptation in populations of random boolean networks .",
    "physica a : statistical mechanics and its applications 301 , 589600 ( 2001 )    loiacono , d. , lanzi , p.l . : computed prediction in binary multistep problems . in : evolutionary computation , 2008 .",
    "( ieee world congress on computational intelligence ) .",
    "ieee congress on .",
    "ieee press ( june 2008 )          miller , j.f . : an empirical study of the efficiency of learning boolean functions using a cartesian genetic programming approach . in : proceedings of the genetic and evolutionary computation conference .",
    ". 11351142 .",
    "gecco 99 , morgan kaufmann ( 1999 )          mozer , m.c . : neural net architectures for temporal sequence processing . in : weigend , a.s . ,",
    "gershenfeld , n.a .",
    "time series prediction : forecasting the future and understanding the past , pp .",
    "addison - wesley ( 1994 )      orriols - puig , a. , casillas , j. , bernad - mansilla , e. : fuzzy - ucs : preliminary results . in : proceedings of the 2007 gecco conference companion on genetic and evolutionary computation .",
    ". 28712874 .",
    "gecco 07 , acm , new york , ny , usa ( 2007 )      pearl , j. : bayesian networks : a model of self - activated memory for evidential reasoning",
    ", university of california , los angeles ( 1985 ) , http://ftp.cs.ucla.edu/tech-report/198_-reports/850021.pdf    perkis , t. : stack - based genetic programming . in : evolutionary computation , 1994 .",
    "ieee world congress on computational intelligence .",
    ", proceedings of the first ieee conference on .",
    ". 148153 .",
    "ieee press ( june 1994 )        preen , r.j . , bull , l. : discrete dynamical genetic programming in xcs . in : proceedings of the 11th annual conference on genetic and evolutionary computation .",
    ". 12991306 .",
    "gecco 09 , acm , new york , ny , usa ( 2009 )    pujol , j.c.f . ,",
    "poli , r. : efficient evolution of asymmetric recurrent neural networks using a pdgp - inspired two - dimensional representation . in : proceedings of the first european workshop on genetic programming .",
    ". 130141 .",
    "springer - verlag , london , uk ( 1998 )    quick , t. , nehaniv , c. , dautenhahn , k. , roberts , g. : evolving embedded genetic regulatory network - driven control systems . in : proceedings of the seventh european artificial life conference .",
    ". 266277 .",
    "springer , heidelberg ( 2003 )    ramirez  ruiz , j.a .",
    ", valenzuela - rendn , m. , terashima - marn , h. : qfcs : a fuzzy lcs in continuous multi - step environments with continuous vector actions . in : rudolph , g. , jansen , t. , lucas , s.m .",
    ", poloni , c. , beume , n. ( eds . ) parallel problem solving from nature : ppsn x. pp .",
    "springer - verlag , berlin , heidelberg ( 2008 )        schmidt , m. , lipson , h. : comparison of tree and graph encodings as function of problem complexity . in : proceedings of the 9th annual conference on genetic and evolutionary computation .",
    ". 16741679 .",
    "gecco 07 , acm , new york , ny , usa ( 2007 )      shirakawa , s. , ogino , s. , nagao , t. : graph structured program evolution . in : proceedings of the 9th annual conference on genetic and evolutionary computation .",
    ". 16861693 .",
    "gecco 07 , acm , new york , ny , usa ( 2007 )                teller , a. , veloso , m. : neural programming and an internal reinforcement policy . in : koza , j.r .",
    "( ed . ) late breaking papers at the genetic programming 1996 conference .",
    ". 186192 .",
    "stanford university ( 1996 )    teller , a. , veloso , m. : pado : a new learning architecture for object recognition . in : ikeuchi , k. , veloso , m. ( eds . ) symbolic visual learning , pp .",
    "oxford university press , inc .",
    ", new york , ny , usa ( 1997 )        tran , h.t . , sanza , c. , duthen , y. , nguyen , t.d . : xcsf with computed continuous action . in : proceedings of the 9th annual conference on genetic and evolutionary computation .",
    ". 18611869 .",
    "gecco 07 , acm , new york , ny , usa ( 2007 )        valenzuela - rendn , m. : the fuzzy classifier system : a classifier system for continuously varying variables . in : proceedings of the fourth international conference on genetic algorithms .",
    ". 346353 .",
    "morgan kaufmann publishers inc .",
    ", san francisco , ca , usa ( 1991 )                    wilson , s.w .",
    ": classifier systems for continuous payoff environments . in : genetic and evolutionary computation ",
    "gecco 2004 , lecture notes in computer science , vol . 3103 , pp .",
    "springer berlin / heidelberg ( 2004 )    wilson , s.w . : three architectures for continuous action . in : proceedings of the 2003 - 2005 international conference on learning classifier systems .",
    ". 239257 .",
    "iwlcs03 - 05 , springer - verlag , berlin , heidelberg ( 2007 )    wilson , s.w .",
    ": classifier conditions using gene expression programming . in : bacardit , j. , bernado - mansilla , e. , butz , m.v . , kovacs , t. , llora , x. , takadama , k. ( eds . ) learning classifier systems .",
    ". 206217 .",
    "springer - verlag , berlin , heidelberg ( 2008 )    wuensche , a. : basins of attraction in network dynamics : a conceptual framework for biomolecular networks . in : schlosser , g. , wagner , g.p .",
    "modularity in development and evolution , pp .",
    "chicago , university press ( 2004 )"
  ],
  "abstract_text": [
    "<S> a number of representation schemes have been presented for use within learning classifier systems , ranging from binary encodings to neural networks . </S>",
    "<S> this paper presents results from an investigation into using discrete and fuzzy dynamical system representations within the xcsf learning classifier system . </S>",
    "<S> in particular , asynchronous random boolean networks are used to represent the traditional condition - action production system rules in the discrete case and asynchronous fuzzy logic networks in the continuous - valued case . </S>",
    "<S> it is shown possible to use self - adaptive , open - ended evolution to design an ensemble of such dynamical systems within xcsf to solve a number of well - known test problems . </S>"
  ]
}