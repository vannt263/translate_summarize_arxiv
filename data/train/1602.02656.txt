{
  "article_text": [
    "text - to - speech ( tts ) synthesis is the technique of generating intelligible speech from a given text .",
    "applications of tts have expanded from early supporting artifacts for the visually impaired , to in - car navigation systems , e - book readers , spoken dialog systems , communicative robots , singing speech synthesizers , and speech - to speech - translation systems  @xcite .",
    "more recently , tts systems have evolved from the sole production of intelligible voices to pursuit more sophisticated production of voices in multiple languages , with different styles and emotions  @xcite . despite these trends ,",
    "there are challenges , for example the overall quality of the voices .",
    "researchers are striving to improve tts systems by more closely mimicking natural human voices    the statistical methods for tts , which arise in the late 1990s , have grown in popularity since then  @xcite , particularly those based on hidden markov models ( hmm ) , for their flexibility in changing speaker characteristics and low footprint , including capacities to produce average voices .",
    "hmm have been utilized extensively in speech recognition since about 30 years ago , as they provide a robust representation of the main events in which speech can be segmented  @xcite , with efficient parameter estimation algorithms .",
    "more than 30 reports of hmm - based speech synthesis implementations ( also called statistical parametric speech synthesis ) can be found for several languages around the world .",
    "for example  @xcite , are a few of the recent ones .",
    "every implementation in a new language or its variants requires the adoption of hmm - related algorithms , incorporating their own linguistic specifications and making a series of decisions regarding the multiple definitions related to hmm , decision tress , and training conditions .    in this paper",
    ", we present our implementation of a statistical parametric speech synthesis system based on hmm with long short - term memory postfilter neural networks for improving its spectral quality .",
    "the rest of this paper is organized as follows : section 2 provides some details of the hmm - based speech synthesis system ; section 3 presents the long short - term memory neural networks ; and section 4 describes the system and experiments carried out in order to test the postfilter .",
    "section 5 presents the results and analysis of objective evaluations , and the conclusions are in section 6 .",
    "hmm can be described from a markov process , in which state transitions are given by a stochastic process . a second stochastic process models",
    "the emission of symbols when it comes to each state .    in figure  [ hmm ] , a representation of a left to right hmm is shown , where there is a first state to the left from which transitions can occur to the same state or to the next on the right , but not in reverse direction . in this @xmath0",
    "represents the probability of transition from state @xmath1 to state @xmath2 , and @xmath3 represents the observation emitted in state @xmath4 .        in hmm - based speech synthesis",
    ", the speech waveforms can be reasonably reconstructed from a sequence of acoustic parameters learned and emitted as vectors from the hmm states  @xcite .",
    "typical implementation of this model includes vectors of observations with @xmath5 , mfcc and their delta and delta delta features for the adequate modeling of dynamic features of speech .    in order to improve the quality of the results",
    ", some researchers have recently experienced postfiltering stages in which the parameters obtained with hts voices have enhanced deep generative architectures  @xcite , for example dbm , rmb , bam and recurrent neural networks .    in the next section ,",
    "we present our proposal to incorporate long short - term memory recurrent neural networks in the improvement of the quality of hmm - based speech synthesis .",
    "mong the new algorithms to improve some tasks related to speech , such as speech recognition , groups of researchers have explored the use of deep neural networks ( dnn ) , with encouraging results .",
    "deep learning , based on several kinds of neural networks with many hidden layers , have achieved great results in many machine learning and pattern recognition tasks .",
    "the disadvantage of using such networks is they can not directly model the dependent nature of each sequence of parameters with the former , which is desirable to mimic the production of human speech . to solve this problem ,",
    "it has been suggested to include rnn  @xcite  @xcite in which there is feedback from some of the neurons in the network , backwards or to themselves , forming a kind of memory that retains previous states .",
    "an extended kind of rnn , which can store information over long or short time intervals , has been presented in  @xcite , called long short - term memory ( lstm ) .",
    "lstm was recently introduced to speech recognition , giving the lowest recorded error rates on the timit database  @xcite , among other successful applications of speech recognition  @xcite .",
    "the storage and use of long - term and short - term information is potentially significant for many applications , including speech processing , non - markovian control , and music composition  @xcite .    in a rnn ,",
    "output vector sequences @xmath6 are computed from input vector sequences @xmath7 and hidden vector sequences @xmath8 iterating equations  [ eq : rnn1 ] and  [ eq : rnn2 ] from @xmath9 to @xmath10  @xcite :    @xmath11    @xmath12    where @xmath13 is the weight matrix between layer @xmath1 and @xmath2 , @xmath14 is the bias vector for layer @xmath4 and @xmath15 is the activation function for hidden nodes , usually a sigmoid function @xmath16 .",
    "each cell in the hidden layers of a lstm , has some extra gates to store values : an input gate , forget gate , output gate and cell activation , so values can be stored in the long or short term .",
    "these gates are implemented following the equations :    @xmath17    @xmath18    @xmath19    @xmath20    @xmath21    where @xmath22 is the sigmoid function , @xmath1 is the input gate activation vector , @xmath23 the forget gate activation function , @xmath24 is the output gate activation function , and @xmath25 the cell activation function .",
    "@xmath26 are the weight matrices from each cell to gate vector .",
    "the resulting voices from the hts system have notable differences with the original voices used in its production .",
    "reducing the gap between natural and artificial voices can be learned directly from data  @xcite . in our proposal",
    ", we use aligned utterances from natural and synthetic voices produced in the hts system to establish correspondence between each frame .    given a sentence of natural speech and voice corresponding hts , we extract a representation consisting of one coefficient for f0 , one coefficient for energy , and 39 mfcc coefficients , using the system ahocoder  @xcite . the inputs to the lstm network correspond to the mfcc parameters of each frame of the sentences produced with the hts voice , while the output corresponds to the mfcc parameters of the natural voice of the same sentence .",
    "in this case , we have an exact correspondence between the vector , representing each phrase from hts voice and natural voice by the alignment between both .    in this way , each lstm network attempts to solve the regression problem of transforming the values of the artificial speech and natural voice .",
    "this allows further improvement of the quality of new synthesized utterances with hts , using this neural network as a subsequent step to approach these synthetic parameters to those of natural voice .",
    "figure  [ fig : scheme ] outlines the proposed system .",
    "the cmu_arctic databases were constructed at the language technologies institute at carnegie mellon university .",
    "they are phonetically balanced , with several us english speakers .",
    "it was designed for unit selection speech synthesis research .",
    "the databases consist of around 1150 utterances selected from out - of - copyright texts from project gutenberg .",
    "the databases include us english male and female speakers . a detailed report on the structure and content of",
    "the database and the recording conditions is available in the language technologies institute tech report cmu - lti-03 - 177  @xcite .",
    "four of the available voices were selected : bdl ( male ) , clb ( female ) , rms ( male ) and slt ( female ) .",
    "each voice was parameterized , and the resulting set of vectors was divided into training , validation , and testing sets .",
    "the amount of data available for each voice are shown in table  [ table : data ] . despite all voices uttering the same phrases , the length differences are due to variations in the speech rate of each speaker .",
    ".amount of data ( vectors ) available for each voice in the databases [ cols=\"<,<,<,<,<\",options=\"header \" , ]     the best result of mcd improvement with the lstm postfiltering is clb ( 7.9% ) and the least best was rms(1% ) .",
    "figure  [ fig : evolution ] shows how the mcd evolves with the training epochs for each voice .",
    "all hts voices , except one , were improved by the lstm neural network postfilter in the mcd from the first 50 ephocs of training .",
    "the differences in the amount of necessary epochs to reach convergence in each case are notable .",
    "this can be explaned by the difference in the mcd between hts and natural voices .",
    "the gap between them is variable and the lstm network requires more epochs to model the regression function between them .",
    "an example of parameters generated by the hts and the enhancement obtained by the lstm postfilter is shown in figure  [ fig : trajectory ] .",
    "it can be seen how the lstm postfilter fits the trajectory of the mfcc better than the hts base system .        in figure",
    "[ fig : spectrograms ] a comparison of three spectrograms of the utterance `` will we ever forget it ? '' for the hts voice ( a ) , original ( b ) and lstm postfilter enhanced ( c ) is shown .",
    "the hts spectrogram usually shows bands in higher frequencies not present in the natural voice , and the lstm - postfilter helps to smooth it , making it closer to the original voice spectrogram .    0.4        0.4        0.4",
    "we have presented a new proposal to improve the quality of synthetic voices based on hmm with lstm postfiltering networks .",
    "the lstm have been able to learn directly from the data how to improve an artificial voice and make it mimic a more natural sound in its spectral characteristics .",
    "we evaluated the proposed lstm postfilter in four voices , two masculine and two feminine , and the results show that all of them were improved in spectral features such as mcd measurement , spectrograms and mfcc trajectory generation .    the improvement of the hts voices in mcd to the original voices were observed from the first training epochs of the lstm neural network , but the convergence to a minimum distance took many more epochs . due to the extensive amount of time required to train each epoch , further",
    "exploration should determine new network configurations or training conditions to reduce training time .",
    "future work will include the exploration of new representation of speech signals , hybrid neural networks and fundamental frequency enhancement with lstm postfilters .",
    "this work was supported by the sep and conacyt under the program sep - conacyt , cb-2012 - 01 , no.182432 , in mexico , as well as the university of costa rica in costa rica .",
    "we also want to thank elra for supplying the original emotional speech synthesis database .                    stan  a , yamagishi  y , king  s , and aylett  m ( 2011 ) : the romanian speech synthesis ( rss ) corpus : building a high quality hmm - based speech synthesis system using a high sampling rate . in : speech",
    "communication , 53(3):442450 .",
    "boothalingam  r , sherlin solomi  v , gladston  ar , christina  sl , vijayalakshmi  p , thangavelu  n , and murthy ha ( 2013 ) : development and evaluation of unit selection and hmm - based speech synthesis systems for tamil . in : national conference on communications ( ncc ) , ieee , p 15 .",
    "nakamura  k , oura  k , nankaku  y , and tokuda  k ( 2014 ) : hmm - based singing voice synthesis and its application to japanese and english . in ieee international conference on acoustics , speech and signal processing ( icassp ) , p 265269 .",
    "chen  lh , raitio  t , valentini - botinhao  c , ling  zh and yamagishi  j ( 2015 ) : a deep generative architecture for postfiltering in statistical parametric speech synthesis .",
    "ieee / acm transactions on audio , speech and language processing ( taslp ) , 23(11):20032014 .",
    "takamichi  s , toda  t , neubig  g , sakti  s and nakamura  s ( 2014 ) : a postfilter to modify the modulation spectrum in hmm - based speech synthesis . in : ieee international conference on acoustics , speech and signal processing ( icassp ) , p 290 - 294 .",
    "takamichi  s , toda  t , black  aw and nakamura  s ( 2014 ) : modified post - filter to recover modulation spectrum for hmm - based speech synthesis . in ieee global conference on signal and information processing ( globalsip ) , p 547551 .",
    "zen  h and sak  h ( 2015 ) : unidirectional long short - term memory recurrent neural network with recurrent output layer for low - latency speech synthesis . in : ieee international conference on acoustics , speech and signal processing ( icassp ) , p 44704474 .",
    "graves  a , fernndez  s and schmidhuber  j. ( 2005 ) : bidirectional lstm networks for improved phoneme classification and recognition . artificial neural networks : formal models and their applications  icann .",
    "springer berlin heidelberg , p 799804 .",
    "zen  h and senior  a ( 2014 ) : deep mixture density networks for acoustic modeling in statistical parametric speech synthesis . in : ieee international conference on acoustics , speech and signal processing ( icassp ) ."
  ],
  "abstract_text": [
    "<S> recent developments in speech synthesis have produced systems capable of outcome intelligible speech , but now researchers strive to create models that more accurately mimic human voices . </S>",
    "<S> one such development is the incorporation of multiple linguistic styles in various languages and accents .    </S>",
    "<S> hmm - based speech synthesis is of great interest to many researchers , due to its ability to produce sophisticated features with small footprint . despite such progress , </S>",
    "<S> its quality has not yet reached the level of the predominant unit - selection approaches that choose and concatenate recordings of real speech . </S>",
    "<S> recent efforts have been made in the direction of improving these systems .    in this paper </S>",
    "<S> we present the application of long - short term memory deep neural networks as a postfiltering step of hmm - based speech synthesis , in order to obtain closer spectral characteristics to those of natural speech . </S>",
    "<S> the results show how hmm - voices could be improved using this approach .    </S>",
    "<S> lstm , hmm , speech synthesis , statistical parametric speech synthesis , postfiltering , deep learning </S>"
  ]
}