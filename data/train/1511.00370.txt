{
  "article_text": [
    "we consider a linear system with @xmath2 endogenous and @xmath3 exogenous variables . with a sample of @xmath4 observations from this system ,",
    "we denote by @xmath5 and @xmath6 the observed values of endogenous and exogenous variables , respectively .",
    "the interactions between endogenous variables and direct causal effects by exogenous variables can be described by a system of structural equations , @xmath7 where the @xmath8 matrix @xmath9 has zero diagonal elements and contains regulatory effects , the @xmath10 matrix @xmath11 contains causal effects , and @xmath12 is an @xmath13 matrix of error terms .",
    "we assume that @xmath14 and @xmath12 are independent of each other , and each component of @xmath12 is independently distributed as normal with zero mean while rows of @xmath12 are identically distributed .    with gene expression levels and genotypic values as endogenous and exogenous variables , respectively , model ( [ eqn - fullinfo ] ) has been used to represent a gene regulatory network with each equation modeling the regulatory effects of other genes and causal effects of cis - eqtl ( i.e. , expression quantitative trait loci located within the region of their target gene ) on a given gene , see @xcite , @xcite , @xcite , and @xcite , among others .",
    "genetical genomics experiments @xcite have been widely undertaken to obtain genome - wide gene expressions and genotypic values @xcite",
    ". however , fitting a system of structural equations in ( [ eqn - fullinfo ] ) to genetical genomics data for the purpose of revealing a whole - genome gene regulatory network is still hindered by lack of an effective statistical method which addresses issues brought by large numbers of endogenous and exogenous variables .",
    "several efforts have been put to construct the system ( [ eqn - fullinfo ] ) with genetic genomics data .",
    "@xcite proposed to use a genetic algorithm to search for genetic networks which minimize the akaike information criterion ( aic ; @xcite ) , and @xcite instead proposed to minimize the bayesian information criterion ( bic ; @xcite ) and its modification @xcite for the optimal genetic networks .",
    "both aic and bic are applicable to inferring networks for only a small number of endogenous variables . for a large system with many endogenous and exogenous variables",
    ", @xcite proposed to maximize a penalized likelihood to construct a sparse system .",
    "however , it is computationally prohibitive to fit a large system based on the likelihood function of the complete model .",
    "@xcite instead proposed to apply the adaptive lasso @xcite to fitting each structural equation separately , then recover the network relying on additional assumption on unique exogenous variables .",
    "however , @xcite demonstrated its inferior performance via simulation studies , which is consistent with our conclusion .    instead of the full information model specified in ( [ eqn - fullinfo ] ) ,",
    "we here seek to establish the large system via constructing a large number of limited information models , each for one endogenous variable @xcite .",
    "for example , when @xmath15-th endogenous variable is concerned , we can focus on the @xmath15-th structural equation in ( [ eqn - fullinfo ] ) which models the regulatory effects of other endogenous variables and direct causal effects of exogenous variables , however , the system structures contained in other structural equations are skipped , leading to the following limited - information model , @xmath16 here @xmath17 refers to @xmath18 excluding the @xmath15-th column , @xmath19 refers to the @xmath15-th column of @xmath9 excluding the diagonal zero , and @xmath20 and @xmath21 refer to the @xmath15-th columns of @xmath11 and @xmath22 respectively .",
    "the second part of the model ( [ eqn - limitedinfo ] ) is from the following reduced model by excluding the @xmath15-th equation , with @xmath23 and @xmath24 , @xmath25    in a classical low - dimensional setting , it is well known that a two - stage least squares ( 2sls ) method can produce consistent estimates of the parameters when the system is identifiable @xcite .",
    "however , as in a typical genetical genomics experiment , we here are interested in constructing a large system with the number of endogenous variables @xmath2 much larger than the sample size @xmath4 .",
    "such a high - dimensional and small sample size data set makes it infeasible to directly apply 2sls method .",
    "indeed , @xmath26 results in perfect fits of reduced form equations at the first stage , which implies to regress against the observed values of endogenous variables at the second stage and therefore obtain ordinary least squares estimates of the parameters .",
    "it is well known that such ordinary least squares estimates are inconsistent .",
    "furthermore , constructing a large system demands , at the second stage , selecting regulatory endogenous variables among massive candidates , i.e. , variable selection in fitting high - dimensional linear models .    here",
    "we propose a two - stage penalized least squares ( 2spls ) method to address the challenges in establishing system ( [ eqn - fullinfo ] ) in the case @xmath26 .",
    "the method fits one regularized linear model for each endogenous variable at each stage . at the first stage ,",
    "the @xmath0 penalty is employed to obtain consistent estimates of a set of well - defined surrogate variables which allow to separately investigate individual structural models and consistently estimate all regulatory effects for each endogenous variable . at the second stage ,",
    "each endogenous variable is regressed against the estimates of surrogate variables , and the @xmath1 penalty is employed to identify regulatory variables among massive candidates .",
    "the use of regularization techniques helps avoid overfitting at the first stage and allows to exploit sparse structure of the system at the second stage .",
    "we show that the resultant estimates of regulatory effects enjoy the oracle properties .",
    "the proposed method addresses three challenging issues in constructing a large system of structural equations , i.e. , memory capacity , computational time , and statistical power .",
    "first , the limited information models are employed to develop the algorithm so as to avoid managing the full information models which may consist of many subnetworks and involve a massive number of endogenous variables .",
    "second , allowing to fit one linear model for each endogenous variable at each stage makes the algorithm computationally fast .",
    "it also makes it feasible to parallel the large number of model fittings at each stage .",
    "third , the oracle properties of the resultant estimates show that the proposed method can achieve optimal power in identifying and estimating regulatory effects .",
    "furthermore , the efficient computation makes it feasible to use the bootstrap method to evaluate the significance of regulatory effects for small data sets .",
    "the rest of this paper is organized as follows .",
    "we first state an identifiable model in the next section .",
    "provided in section  [ sec-2sls ] is a new view on the classical 2sls method , which motivates our development of the 2spls method in section  [ sec-2spls ] . in section",
    "[ sec - theory ] , we show that the estimates from 2spls have the oracle properties with the proof included in the appendix .",
    "simulation studies are carried out in section  [ sec - simu ] to evaluate the performance of 2spls .",
    "an application to a real data set to infer a yeast gene regulatory network is presented in section  [ sec - rdata ] .",
    "we conclude this paper with a discussion in section  [ sec - disc ] .",
    "we follow the practice of constructing system ( [ eqn - fullinfo ] ) in analyzing genetic genomics data , and assume that each endogenous variable is affected by a unique set of exogenous variables .",
    "that is , the structural equation in ( [ eqn - limitedinfo ] ) has known zero elements of @xmath20 .",
    "explicitly , we use @xmath27 to denote the set of row indices of known nonzero elements in @xmath20 . then we have known sets @xmath28 , which dissect the set @xmath29 .",
    "we explicitly state this assumption in the below .",
    ": :    * assumption a. * @xmath30 for    @xmath31 , but    @xmath32 as long as    @xmath33 .",
    "the above assumption indeed satisfies the rank condition @xcite , which is a sufficient condition for model identification .",
    "since each @xmath20 has a set of known zero components , hereafter we ignore them and simply rewrite the structural equation in model ( [ eqn - limitedinfo ] ) as , @xmath34",
    "because @xmath17 and @xmath21 are correlated , fitting solely model ( [ eqn - ykstructural ] ) results in biased estimates of @xmath19 and @xmath20 . however , we notice that the following two sets of variables are independent , @xmath35 = \\mathbf{x}\\boldsymbol{\\pi}_{-k},\\\\ \\boldsymbol{\\varepsilon}_k = \\boldsymbol{\\epsilon}_k+\\boldsymbol{\\xi}_{-k}\\boldsymbol{\\gamma}_k . \\end{array}\\right.\\end{aligned}\\ ] ] consequently , consistent estimates of @xmath19 and @xmath20 can be obtained by applying least squares method to the following model , @xmath36 when regulatory effects are considered , @xmath37 = \\mathbf{x}\\boldsymbol{\\pi}_j : j=1 , 2 , \\cdots , p\\}$ ] serves as a set of surrogate variables which can help estimate both @xmath9 and @xmath11 in model ( [ eqn - fullinfo ] ) .    in practice",
    ", @xmath38 is unknown as it involves unknown @xmath39 .",
    "suppose we instead have a consistent estimate @xmath40 of @xmath39 , i.e. , @xmath41 let @xmath42 , and further take the following assumption .",
    ": :    * assumption b. *    @xmath43 , where    @xmath44 is a positive definite matrix .",
    "it is easy to see that @xmath45 when replacing @xmath38 with @xmath46 in model ( [ eqn - idealmodel ] ) , we obtain the following least squares estimators of @xmath19 and @xmath20 , @xmath47 certainly , the properties in ( [ eqn - asymz ] ) imply that the above estimators approach to the least squares estimators of fitting model ( [ eqn - idealmodel ] ) , which are also consistent .",
    "[ thm-2sls ] suppose assumptions a and b are satisfied for the system ( [ eqn - fullinfo ] ) with fixed @xmath48 and @xmath49 .",
    "when there exists a consistent estimator @xmath40 of @xmath39 , the ordinary least squares estimators of @xmath50 obtained by regressing @xmath51 against @xmath52 are also consistent .",
    "when a @xmath53-consistent least squares estimator of @xmath54 is obtained by fitting each equation in ( [ eqn - reducedform ] ) for @xmath55 , the resultant estimators of @xmath19 and @xmath20 are exactly the 2sls estimators by @xcite and @xcite . in the following ,",
    "we consider to construct the system ( [ eqn - fullinfo ] ) in the case that @xmath26 .",
    "such a high - dimensional and small sample size data set makes it infeasible to directly apply the 2sls method .",
    "to construct the limited - information model ( [ eqn - limitedinfo ] ) , we can obtain consistent estimates of the surrogate variables by fitting high - dimensional linear models , and then conduct a high - dimensional variable selection following our view on model ( [ eqn - idealmodel ] ) . hence we propose a two - stage penalized least squares ( 2spls ) procedure to construct each model in ( [ eqn - limitedinfo ] ) so as to establish the large system ( [ eqn - fullinfo ] ) .    at the first stage",
    ", we use the ridge regression to fit each reduced - form model in ( [ eqn - reducedform ] ) to obtain consistent estimates of the surrogate variables .",
    "that is , for each @xmath56 , we obtain the ridge regression estimator of @xmath57 by minimizing the following penalized sum of squares @xmath58 where @xmath59 is a tuning parameter that controls the strength of the penalty .",
    "the solution to the minimization problem is @xmath60 , which leads to a consistent estimate of @xmath61 , @xmath62 where @xmath63 . with a proper choice of @xmath64 ,",
    "ridge regression has very good prediction performance as shown in the next section .    at the second stage",
    ", we replace @xmath38 with @xmath46 in model ( [ eqn - idealmodel ] ) to derive estimates of @xmath19 and @xmath20 . specifically , we minimize the following penalized error squares to obtain estimates of @xmath19 and @xmath20 , @xmath65 where @xmath66 implies to componentwisely take absolute values of @xmath19 , @xmath67 is a known weight vector , and @xmath68 is a tuning parameter .    minimizing for @xmath20 in ( [ est - gammapsi ] ) leads to @xmath69 where @xmath70 is usually of low dimension , and the above least squares estimator of @xmath20 is easy to obtain .",
    "plugging @xmath71 into ( [ est - gammapsi ] ) , we can solve the following minimization problem to obtain an estimate of @xmath19 , @xmath72 this is equivalent to a variable selection problem in regressing @xmath73 against high - dimensional @xmath74 .",
    "we will resort to adaptive lasso to select nonzero components of @xmath19 and estimate them . specifically , picking up a @xmath75 and obtaining @xmath76 as a @xmath53-consistent estimate of @xmath19 , we calculate the weight vector @xmath67 with components inversely proportional to components of @xmath77 . the above minimization problem ( [ est - gamma ] ) is a convex optimization problem which is computationally efficient .      in this method",
    ", we need to select tuning parameters at each stage . at the first stage",
    ", we propose to choose each @xmath64 in ( [ est - pi ] ) by the method of generalized cross - validation ( gcv ; @xcite ) , that is , @xmath78 it is a rotation - invariant version of ordinary cross - validation , and leads to an approximately optimal estimate of the surrogate variable @xmath61 .",
    "at the second stage , the tuning parameter @xmath79 in ( [ est - gamma ] ) is obtained via @xmath80-fold cross validation .",
    "as an extension of the classical 2sls method to high dimensions , the proposed 2spls method also has some good theoretical properties . in this section , we will show that the 2spls estimates enjoy the oracle properties . as the second - stage estimation replies on the ridge estimates @xmath46 obtained from the first stage , we first discuss the theoretical properties on @xmath46 , which provide guarantee for the oracle properties of our proposed estimates .    as aforementioned , each @xmath64 in ( [ est - pi ] )",
    "is obtained by the method of generalized cross - validation .",
    "interestingly , as stated by @xcite , @xmath64 obtained by gcv is closely related to the one minimizing @xmath81 indeed , the following result follows theorem 2 of @xcite .",
    "[ thm - gcv ] suppose that all components of @xmath57 are i.i.d .",
    "with mean zero and variance @xmath82 , then @xmath83\\right ] = \\arg\\min_{\\tau>0 } e\\left[e[t_j(\\tau)|\\boldsymbol{\\pi}_j]\\right ] = \\frac{\\sigma_{\\boldsymbol{\\xi}_j}^2}{\\sigma_{\\boldsymbol{\\pi}}^2},\\ ] ] where @xmath84 is the variance component of @xmath85 in model ( [ eqn - limitedinfo ] ) .",
    "this theorem implies that the gcv estimate @xmath86 is approximately the optimal estimate of the surrogate variable @xmath61 .",
    "furthermore , as the optimal tuning parameter approximates a constant determined by the variance components ratio , hereafter we take the following assumption on @xmath64 .    : :    * assumption c. * @xmath87 as    @xmath88 , for @xmath55 .    denote @xmath89 , we then have the following properties on @xmath46 .",
    "[ thm - ridgeest ] for @xmath90 , let @xmath91 where each @xmath92 is a submatrix of @xmath44 identified with row indices in @xmath93 and column indices in @xmath94 ( the dot implies all rows or columns ) . then , under assumptions a , b , and c ,    1 .   @xmath95 , as @xmath96 ; 2 .",
    "@xmath97 , as @xmath96 .    since @xmath98 , theorem  [ thm - ridgeest].a states that @xmath99 is a good approximation to @xmath100 . on the other hand , @xmath101 is the error term in regressing @xmath73 against @xmath74 , and theorem  [ thm - ridgeest].b implies that @xmath102 .",
    "thus @xmath46 results in regression errors with good properties , i.e. , the error effects on the 2spls estimators will vanish when the sample size gets sufficiently large .    in summary",
    ", the above theorem indicates that @xmath46 behaves the same way as @xmath38 asymptotically , which makes it feasible to replace @xmath38 with @xmath46 at the second stage .",
    "the crucial properties of @xmath46 in theorem  [ thm - ridgeest ] , together with the good theoretical properties of adaptive lasso , will lead to the oracle properties of our proposed estimates .",
    "we denote the @xmath103-th elements of @xmath104 and @xmath105 as @xmath106 and @xmath107 , respectively .",
    "then , with a proper choice of @xmath79 , the proposed method enjoys the following oracle properties .",
    "( oracle properties ) [ thm - oracle ] let @xmath108 , @xmath109 , and @xmath110 be the submatrix of @xmath111 identified with both row and column indices in @xmath112",
    ". suppose that @xmath113 and @xmath114 .",
    "then , under assumptions a , b , and c , the estimates from the proposed 2spls method satisfy the following properties ,    1 .   consistency in variable selection : @xmath115 ; 2 .",
    "asymptotic normality : @xmath116 , as @xmath117 .",
    "it is worthwhile to mention that theorem  [ thm - ridgeest ] plays an essential role in establishing the oracle properties of 2spls .",
    "in fact , as long as the properties in theorem  [ thm - ridgeest ] hold true for the first - stage estimates of @xmath38 , we can generalize the second - stage regularization to a wide class of regularization methods , all the theoretical properties of which can be inherited by our proposed two - stage method .",
    "we conducted simulation studies to compare 2spls with the adaptive lasso based algorithm ( al ) by @xcite , and the sparsity - aware maximum likelihood algorithm ( sml ) by @xcite . both acyclic networks and cyclic networks were simulated , each involving @xmath118 endogenous variables .",
    "each endogenous variable was simulated to have , on average , one regulatory effect for sparse networks , or three regulatory effects for dense networks .",
    "the regulatory effects were independently simulated from a uniform distribution over @xmath119 . to allow the use of al and sml , every endogenous variable in the same network was simulated to have the same number ( either one or three ) of known causal effects by the exogenous variables , with all effects equal to one .",
    "each exogenous variable was simulated to take values 0 , 1 and 2 with probabilities 0.25 , 0.5 and 0.25 , respectively , emulating genotypes of an f2 cross in a genetic genomics experiment .",
    "all error terms were independently simulated from @xmath120 , and the sample size @xmath4 varied from @xmath121 to @xmath122 . for each network setup",
    ", we simulated 100 data sets and applied all three algorithms to calculate the power and false discovery rate ( fdr ) .    for inferring acyclic networks ,",
    "the power and fdr of the three different algorithms are plotted in figure  [ figure - acycliclarge ] . in the case",
    "that each endogenous variable has only one known exogenous effect ( ee ) , 2spls has the greatest power to infer both sparse and dense acyclic networks from data sets with different sample sizes . in the case of three ees available for each endogenous variable ,",
    "2spls still has greater power than the other two algorithms when the sample size is small or moderate . when the sample size is large , 2spls and sml are comparable for constructing both sparse and dense acyclic networks . in any case ,",
    "2spls and sml provide much greater power than al .",
    "indeed , al provides power as low as under @xmath123 when the sample size is not large , and its power is still under @xmath124 even when the sample size increases to @xmath122 . on the other hand ,",
    "2spls provides power over @xmath125 for small sample sizes , and over @xmath126 for moderate to large sample sizes .",
    "power of sparse networks    \\b .",
    "fdr of sparse networks    \\c .",
    "power of dense networks    \\d .",
    "fdr of dense networks    as shown in figure  [ figure - acycliclarge ] , 2spls controls the fdr under @xmath127 except the case with three available ees and very small sample sizes ( @xmath128 ) . while it controls the fdr as low as under @xmath129 for sparse acyclic networks when the sample sizes are large , sml reports large fdrs when the sample sizes are not large .",
    "indeed , when the sample sizes are under 200 , sml reports fdr over @xmath130 for dense acyclic networks . in general , both 2spls and sml outperform al in terms of fdr though al reports fdr lower than 2spls when inferring sparse acyclic networks with one available ee from data sets of very large sample sizes .",
    "plotted in figure  [ figure - cycliclarge ] are the power and fdr of the three different algorithms when inferring cyclic networks . similar to the results on acyclic networks , 2spls has greater power than the other two algorithms across all sample sizes and has lower fdr when the sample size is not large . for dense cyclic networks",
    ", al has power mostly under @xmath127 and fdr over @xmath131 . while it improves the fdr for sparse cyclic networks with large sample sizes",
    ", al has power as low as under @xmath123 .",
    "sml provides power competitive to 2spls for sparse cyclic networks , but its power is much lower than that of 2spls for dense cyclic networks .",
    "similar to the case of acyclic networks , sml reports much higher fdr for inferring dense networks from data sets with small sample sizes though it reports very small fdr when the sample sizes are large .",
    "we also conducted simulation studies on both acyclic and cyclic networks with small to moderate number of endogenous variables ( e.g. , 10 to 50 endogenous variables ) .",
    "the performance of 2spls is better than al and comparable to sml in those scenarios ( results are not shown ) .",
    "indeed , the power of 2spls exceeds @xmath132 while maintaining low fdr in most of the scenarios .",
    "power of sparse networks    \\b .",
    "fdr of sparse networks    \\c .",
    "power of dense networks    \\d .",
    "fdr of dense networks    while it generally reports higher power and more robust fdr than sml , 2spls significantly reduces the computation time in comparison to sml as it assembles the network by investigating limited - information models . to demonstrate such advantage of 2spls over sml , we recorded the computing time of all algorithms in inferring the same networks from small data sets ( @xmath128 ) .",
    "each algorithm analyzed the same data set using only one cpu in a server with quad - core amd opteron  processor 8380 .",
    "reported in table  [ table - runtime ] are the running times of the three algorithms for inferring different networks .",
    "apparently , al is the fastest , and the running time of 2spls usually doubles or triples that of al .",
    "the slowest algorithm is sml which generally takes more than 40 times longer than 2spls to infer different networks . in particular , sml is almost 200 times slower than 2spls when inferring acyclic sparse networks .",
    ".the running time ( in seconds ) of inferring networks from a data set with @xmath128 . [ cols=\"^,^,^,^,^,^,^,^,^ \" , ]",
    "we analyzed a yeast data set with 112 segregants from a cross between two strains by4716 and rm11-la @xcite .",
    "a total of 5,727 genes were measured for their expression values , and 2,956 markers were genotyped . each marker within a genetic region ( including 1 kb upstream and downstream regions )",
    "was evaluated for its association with the corresponding gene expression , yielding 722 genes with marginally significant cis - eqtl ( @xmath2-value @xmath133 ) .",
    "the set of cis - eqtl for each gene was filtered to control the pairwise correlation under @xmath134 , and then further filtered to keep up to three cis - eqtl which have the strongest association with the corresponding gene expression .    with 112 observations of 722 endogenous variables and 732 exogenous variables",
    ", we applied 2spls to infer the gene regulatory network in yeast .",
    "the constructed network includes 7,300 regulatory effects in total . to evaluate the reliability of constructed gene regulations",
    ", we generated 10,000 bootstrap data sets ( each with @xmath135 ) by randomly sampling the original data with replacement , and applied 2spls to each data set to infer the gene regulatory network . among the 7,300 regulatory effects ,",
    "323 effects were repeatedly identified in more than 80% of the 10,000 data sets , and figure  [ figure - subnetwork ] shows the three largest subnetworks formed by these 323 effects . specifically , the largest subnetwork consists of 22 endogenous variables and 26 regulatory effects , the second largest one includes 14 endogenous variables and 18 regulatory effects , and the third largest one has 11 endogenous variables and 16 regulatory effects .",
    "a.    b.    c.    a gene - enrichment analysis with david @xcite showed that the three subnetworks are enriched in different gene clusters ( controlling @xmath2-values from fisher s exact tests under @xmath136 ) .",
    "a total of six gene clusters are enriched with genes from the first subnetwork , and four of them are related to either methylation or methyltransferase .",
    "six of 22 genes in the first subnetwork are found in a gene cluster which is related to none - coding rna processing .",
    "the second subnetwork is enriched in nine gene clusters .",
    "while three of them are related to electron , one cluster includes half of the genes from the second subnetwork and is related to oxidation reduction .",
    "the third subnetwork is also enriched in nine different gene clusters , with seven clusters related to proteasome .",
    "a total of 18 regulations were constructed from each of the 10,000 bootstrap data sets , and are shown in figure  [ figure - yeastedge ] .",
    "there are seven pairs of genes which regulate each other .",
    "it is interesting to observe that all regulatory genes up regulate the target genes except two genes , namely , ycl018w and yel021w .     the yeast gene regulatory subnetworks constructed in each of 10,000 bootstrap data sets ( with arrow- and bar - headed lines implying up and down regulations , respectively).,width=480,height=168 ]",
    "in a classical setting with small numbers of endogenous / exogenous variables , constructing a system of structural equations has been well studied since @xcite .",
    "@xcite first proposed to estimate the parameters of a single structural equation with the limited information maximum likelihood estimator .",
    "later on , @xcite and @xcite independently developed the 2sls estimator , which is the simplest and most common estimation method for fitting a system of structural equations .",
    "however , the genetical genomics experiments usually collect data in which both the number of endogenous variables and the number of exogenous variables can be very large , invalidating the classical methods for building gene regulatory networks .    replacing the ordinary least squares at the two stages with ridge regression and adaptive lasso respectively , the proposed 2spls method can consistently identify and further estimate the regulatory effects of the endogenous variables , even with a large number of endogenous variables . as a high - dimensional extension of the classical 2sls method , the 2spls method is also computationally fast and easy to implement . as shown in constructing a genome - wide gene regulatory network of yeast , the high computational efficiency of 2spls allows us to employ the bootstrap method to calculate the @xmath2-values of regulatory effects .",
    "meanwhile , each of the two steps , especially the second one , may be further improved by incorporating recent progresses in high - dimensional variable selection , see , for example , @xcite , @xcite , and @xcite .",
    "\\a . since @xmath87 for any @xmath137",
    ", the different choice of @xmath64 for each @xmath103 does not affect the following asymptotic property involving @xmath64 , @xmath138 without loss of generality , we assume @xmath139",
    ". then @xmath140 .",
    "@xmath141 we will consider the asymptotic property of each of the above four terms .",
    "first , @xmath142 implies that @xmath143 the above result and ( [ asy - xxtau ] ) easily lead to the following result , @xmath144    the other three terms approaching to zero directly follows that @xmath145 .",
    "thus , @xmath146 .    \\b .",
    "since @xmath147 , we have @xmath148    in the following , we will prove that the second term approaches to zero , and the first term asymptotically approaches to the required distribution , i.e. , @xmath149    we notice that @xmath150 following ( [ asy - mk ] ) , we have @xmath151    because of ( [ asy - xhx ] ) and @xmath152 we have @xmath153 since @xmath154 , we can apply slutsky s theorem and obtain that @xmath155 pooling the above result and ( [ asy - ehpxpi ] ) leads to the asymptotic distribution in ( [ asy - ehpx ] ) .    to prove that the second term asymptotically approaches to zero , we further partition it as follows , @xmath156 it suffices to prove each of these four parts asymptotically approaches to zero .",
    "first , notice that @xmath157 we have @xmath158 which follows ( [ asy - xhx ] ) and that @xmath159 as @xmath88 .    because @xmath160 , we have @xmath161 which implies that @xmath162 since var@xmath163 is proportional to an identity matrix , the above result leads to that @xmath164 which implies that @xmath165    similarly",
    ", we can prove that , for each @xmath166 , @xmath167 which implies that @xmath168    note that @xmath169 since @xmath170 we have @xmath171 therefore , @xmath172 which , together with @xmath173 , leads to that @xmath174    pooling ( [ asy - xiphpxpi ] ) , ( [ asy - gxiphpxpi ] ) , ( [ asy - gpixiphpx ] ) and ( [ asy - gxiphpx ] ) , we have proved that @xmath175 , which concludes our proof .",
    "let @xmath176 . let @xmath177 , then @xmath178 or @xmath179 . note that @xmath180 , where @xmath181    denote the @xmath103-th elements of @xmath67 and @xmath182 as @xmath183 and @xmath184 , respectively .    if @xmath185 , then @xmath186 and @xmath187 . by slutsky s theorem",
    ", we have @xmath188 . if @xmath189 , then @xmath190 and @xmath191 , where @xmath192 .",
    "thus , @xmath193 hence , following theorem [ thm - ridgeest ] and slutsky s theorem , we see that @xmath194 for every @xmath182 , where @xmath195 @xmath196 is convex , and the unique minimizer of @xmath197 is @xmath198 . following the epi - convergence results of @xcite and @xcite ,",
    "we have @xmath199 since @xmath200 , we indeed have proved the asymptotic normality .",
    "now we show the consistency in variable selection . for @xmath201",
    ", the asymptotic normality indicates that @xmath202 , thus @xmath203 .",
    "then it suffices to show that @xmath204 , @xmath205 .    when @xmath206 , by the kkt normality conditions , we know that @xmath207 .",
    "note that @xmath208 , whereas @xmath209 .",
    "following theorem [ thm - ridgeest ] and the asymptotic normality , @xmath210 asymptotically follows a normal distribution .",
    "thus , @xmath211 . then we have proved the consistency in variable selection .",
    "akaike , h. ( 1974 ) ,  a new look at the statistical model identification , \" , 19 , 716 - 723 .",
    "schadt , e.  e. , monks , s.  a. , drake , t.  a. , lusis , a.  j. , che , n. , colinayo , v. , ruff , t.  g. , milligan , s.  b. , lamb , j.  r. , cavet , g. , linsley , p.  s. , mao , m. , stoughton , r.  b. , and friend , s.  h. ( 2003 ) ,  genetics of gene expression surveyed in maize , mouse and man , \" , 422 , 297 - 302 ."
  ],
  "abstract_text": [
    "<S> linear systems of structural equations have been recently investigated to reveal the structures of genome - wide gene interactions in biological systems . however , building such a system usually involves a huge number of endogenous variables and even more exogenous variables , and hence demands a powerful statistical method which limits memory consumption and avoids intensive computation . </S>",
    "<S> we propose a two - stage penalized least squares method to build large systems of structural equations . </S>",
    "<S> fitting one linear model for each endogenous variable at each stage , the method employs the @xmath0 penalty at the first stage to obtain consistent estimation of a set of well - defined surrogate variables , and the @xmath1 penalty at the second stage to consistently select regulatory endogenous variables among massive candidates . without fitting a full information model , the method is computationally fast and allows for parallel implementation . </S>",
    "<S> the resultant estimates of the regulatory effects enjoy the oracle properties , that is , they perform as well as if the true regulatory endogenous variables were known . </S>",
    "<S> we also demonstrated the effectiveness of the method by conducting simulation studies , showing its improvements over other methods . </S>",
    "<S> our method was applied to construct a yeast gene regulatory network with a genetical genomics data .    </S>",
    "<S> # 1    1    1    0    1    * two - stage penalized least squares method for constructing large systems of structural equations *    _ keywords : _ graphical model ; high - dimensional data ; reciprocal graphical model ; simultaneous equation model ; structural equation model . </S>"
  ]
}