{
  "article_text": [
    "ever since the 1920s , every wireless system has been required to have an exclusive license from the government in order not to interfere with other users of the radio spectrum . today ,",
    "with the emergence of new technologies which enable new wireless services , virtually all usable radio frequencies are already licensed to commercial operators and government entities . according to former u.s .",
    "federal communications commission ( fcc ) chair william kennard , we are facing with a  spectrum drought \"   @xcite . on the other hand ,",
    "not every channel in every band is in use all the time ; even for premium frequencies below 3 ghz in dense , revenue - rich urban areas , most bands are quiet most of the time .",
    "the fcc in the united states and the ofcom in the united kingdom , as well as regulatory bodies in other countries , have found that most of the precious , licensed radio frequency spectrum resources are inefficiently utilized  @xcite .    in order to increase the efficiency of spectrum utilization ,",
    "diverse types of technologies have been deployed .",
    "cognitive radio is one of those that leads to the greatest technological gain in wireless capacity . through the detection and utilization of the spectra that are assigned to the licensed users but standing idle at certain times , cognitive radio acts as a key enabler for spectrum sharing .",
    "spectrum sensing , aiming at detecting spectrum holes ( i.e. , channels not used by any primary users ) , is the precondition for the implementation of cognitive radio . the cognitive radio ( cr )",
    "nodes must constantly sense the spectrum in order to detect the presence of the primary radio ( pr ) nodes and use the spectrum holes without causing harmful interference to the prs .",
    "hence , sensing the spectrum in a reliable manner is of vital importance and constitutes a major challenge in cr networks .",
    "however , detection is compromised when a user experiences shadowing or fading effects or fails in an unknown way . to get a better understanding of the problem ,",
    "consider the following example : a typical digital tv receiver operating in a 6 mhz band must be able to decode a signal level of at least -83 dbm without significant errors @xcite .",
    "the typical thermal noise in such bands is -106 dbm .",
    "hence a cr which is 30 dbm more sensitive has to detect a signal level of -113 dbm , which is below the noise floor  @xcite . in such cases",
    ", one cr user can not distinguish between an unused band and a deep fade . in order to combat such effects",
    ", recent studies suggest collaboration among multiple cr nodes for improving spectrum sensing performance .",
    "collaborative spectrum sensing ( css ) techniques are introduced to improve the performance of spectrum sensing . by allowing different secondary users to collaborate and share their information ,",
    "pr detection probability can be greatly increased .",
    "css can be classified into two categories .",
    "the first category involves multiple users exchanging information @xcite , and the second category uses relay transmission @xcite . some recent studies on collaborative spectrum sensing",
    "include cooperative scheme design guided by game theory @xcite and random matrix theory @xcite , cluster - based cooperative css @xcite , and distributed rule - regulated css @xcite ; studies concentrating on css performance improvement include @xcite introducing spatial diversity techniques to combat the error probability due to fading on the reporting channel between the cr nodes and the central fusion center .",
    "there are also studies concerning other interesting aspects of css performance under different constraints @xcite .",
    "very recently , there are emerging applications of the compressive sensing concept for css @xcite",
    ".    existing literature mostly focuses on the css performance examination when the centralized fusion center receives and combines _ all _ cr reports . in an @xmath1 channel cognitive radio network with @xmath2 cr nodes",
    ", the fusion center has to deal with @xmath3 reports and combine them wisely to form a channel sensing result .",
    "however , it is known that wireless channels are subject to fading and shadowing . when secondary users experience multi - path fading or happen to be shadowed , the reports transmitted by cr users are subject to transmission loss . as a result , in practice ,",
    "no entire report data set is available at the fusion center .",
    "besides , due to the fact that each cognitive radio can only sense a small proportion of the spectrum with limited hardware , each cr user gathers only very limited information about the entire spectrum .",
    "* contributions : *    we seek to release crs from sending , and the central control unit from gathering , an excessively large number of reports , also target at the situations where there are only a few cr nodes in a large network and thus unable to gather enough sensing information for the traditional css .",
    "we propose to equip each cognitive radio node with a frequency selective filter , which linearly combines multiple channel information .",
    "the linear combinations are sent as reports to the fusion center , where the occupied channels are decoded from the reports by compressive sensing algorithms . as a consequence ,",
    "the amount of channel sensing at crs and the number of reports sent from the crs to the fusion center are both significantly reduced .",
    "following our previous work @xcite on compressive sensing , we propose two approaches to collaborative spectral sensing .",
    "the first approach is based on solving a matrix completion problem @xcite , which seeks to efficiently reconstruct a matrix ( typically low - rank ) from a relatively small number of revealed entries . in this approach ,",
    "the entries of the underlying matrix are linear combinations of channel powers .",
    "each cr node takes its local spectrum measurements , but instead of directly recording channel powers , it uses its frequency - selective filters to take @xmath4 _ linear combinations _ of channel powers and reports them to the fusion center .",
    "the total @xmath5 linear combinations taken by @xmath2 crs form a @xmath5 matrix at the fusion center . considering transmission loss , we allow the the matrix to be incomplete . we show that this matrix is low - rank and has the properties enabling its reconstruction from only a small number of its entries , and therefore , information about the complete spectrum usage can be recovered from a small number of reports from the cr nodes .",
    "this approach significantly reduces the amount of sensing and communication workload .",
    "the second approach is based on joint sparsity recovery @xcite , which is motivated by the observation that the spectrum usage information the cr nodes collect has a common sparsity pattern : each of the few occupied channels is typically observed by multiple crs .",
    "we develop a novel algorithm for joint sparsity signal recovery , which is more effective than existing algorithms in the compressive sensing literature since it can accommodate a large dynamic range of channel gains .    in both approaches",
    ", every cr senses all channels ( by taking random linear projections of the powers of all channels ) , and the crs do not communicate . while they work independently , their measurements are analyzed jointly by the detection algorithms running at the fusion center .",
    "therefore , our approaches are very different from the existing collaborative spectrum sensing schemes in which different crs are assigned to different channels .",
    "our approaches move from collaborative sensing to  collaborative \" computation and shift coordination from the sensing phase to the post - sensing phase .",
    "our work is among the first that applies matrix completion or joint sparsity recovery to collaborative spectrum sensing in cognitive radio networks .",
    "matrix completion and joint sparsity recovery are both being intensively studied in the compressive sensing community .",
    "we present them both because it is too early at this time to make a verdict of an eventual winner .",
    "the rest of this paper is organized as follows : in section [ sec : model ] , the system model is given .",
    "the matrix completion - based algorithm for collaborative sensing is described in section [ sec : algorithm1 ] , and the joint sparsity based algorithm is described in section [ sec : algorithm2 ] .",
    "after that , in section [ sec : discussion ] we compare the two proposed approaches , discuss their computational complexity as well as filter design and dynamic update .",
    "simulation results are presented in section [ sec : simulation ] , and conclusions are drawn in section [ sec : conclusion ] .",
    "we consider a cognitive radio network with @xmath2 cr nodes that locally monitor a subset of @xmath1 channels .",
    "a channel is either occupied by a pr or unoccupied , corresponding to the states @xmath6 and @xmath7 , respectively .",
    "we assume that the number @xmath8 of occupied channels is much smaller than @xmath1 .",
    "the goal is to recover the occupied channels from the cr nodes observations .",
    "since each cr node can only sense limited spectrum at a time , it is impossible for limited @xmath2 crs to observe @xmath1 channels simultaneously .    to overcome this problem",
    ", we propose the scheme depicted in fig .",
    "[ f : system_model ] .",
    "instead of scanning all channels and sending each channel s status to the fusion center , using its frequency - selective filters , a cr takes a small number of measurements that are linear combinations of multiple channels .",
    "the filter coefficients can be designed and implemented easily . in order to mix the different channel sensing information ,",
    "the filter coefficients are designed to be random numbers .",
    "then , these filter outputs are sent to the fusion center .",
    "suppose that there are @xmath4 frequency selective filters in each cr node sending out @xmath4 reports regarding the @xmath1 channels .",
    "for the non - ideal cases , where we have relatively less measurements @xmath9 , i.e. , the number of reports sent from all crs is less than the total number of channels .",
    "the sensing process at each cr can be represented by a @xmath10 filter coefficient matrix @xmath11 .",
    "let an @xmath12 _ diagonal _ matrix @xmath13 represent the states of all the channel sources using @xmath7 and @xmath6 as diagonal entries , indicating the unoccupied or occupied states , respectively .",
    "there are @xmath8 nonzero entries in @xmath14 .",
    "in addition , channel gains between the crs and channels are described in an @xmath15 channel gain matrix @xmath16 given by @xcite : @xmath17 where @xmath18 is the @xmath19 primary user s transmitted power , @xmath20 is the distance between the primary transmitter using @xmath21 channel and the @xmath19 cr node , @xmath22 is the propagation loss factor , and @xmath23 is the channel fading gain . for awgn channel , @xmath24 ; for rayleigh channel , @xmath25 follows independent rayleigh distribution ; and for shadowing fading , @xmath25 follows log - normal distribution @xcite . without loss of generality , we assume that all prs use unit transmit power ( otherwise , we can compensate by altering the corresponding channel gains ) . the measurement reports sent to the fusion center can be written as a @xmath5 matrix @xmath26 note that due to loss or errors , some of the entries of @xmath27 are possibly missing .",
    "the binary numbers on the diagonal of @xmath13 are the @xmath1channel states that we shall estimate from the available entries of @xmath27 .",
    "it is typically difficult for the fusion center to acquire all entries of @xmath27 due to transmission failure , which means that our observation is a subset @xmath28\\times[m]$ ] of @xmath27 .",
    "however , it is possible to recover the missing entries in @xmath27 since it holds the following two important properties @xcite required for matrix completion :    1 .   *",
    "low rank * : @xmath29 equals to @xmath8 , which is the number of prime users in the network and is usually very small .",
    "incoherent property * : generate @xmath11 randomly ( subject to hardware limitation ) . from and the fact that @xmath13 has only @xmath8 nonzeros on the diagonal , @xmath27 s svd factors @xmath30 , @xmath31 , and @xmath32 satisfy the _ incoherence condition _ @xcite . * there exists a constant @xmath33 such that for all @xmath34 $ ] , @xmath35 $ ] , we have @xmath36 , @xmath37 @xmath38 .",
    "* there exists @xmath39 such that @xmath40 .",
    "@xmath27 is in general incomplete because of transmission failure .",
    "moreover , each cr might only be able to collect a random ( up to @xmath4 ) number of reports due to the hardware limitation .",
    "therefore , the fusion certain receives a subset @xmath28\\times[m]$ ] of @xmath27 s entries .",
    "we assume that the received entries are uniformly distributed with high probability .",
    "hence , we work with a model in which each entry shows up in @xmath41 identically and independently with probability @xmath42 .",
    "given @xmath43 , the partial observation of @xmath27 is defined as a @xmath5 matrix given by @xmath44 we shall first recover the unobserved elements of @xmath27 from @xmath45 .",
    "then , we reconstruct @xmath46 from the given @xmath11 and @xmath27 using the fact that all but @xmath8 rows of @xmath46 are zero .",
    "these nonzero rows correspond to the occupied channels .",
    "since @xmath4 and @xmath2 are much smaller than @xmath1 , our approach requires a much less amount of sensing and transmission , compared to traditional spectrum sensing in which each channel is monitored separatively .    in previous research on matrix completion @xcite , it was proved that under some suitable conditions , a low - rank matrix can be recovered from a random , yet small subset of its entries by nuclear norm minimization : @xmath47 where @xmath48 denotes the nuclear norm of matrix @xmath27 and @xmath49 is a parameter discussed in section [ sec : stop ] below . for notational simplicity ,",
    "we introduce the linear operator @xmath50 that selects the components @xmath41 out of a @xmath10 matrix and form them into a vector such that @xmath51 .",
    "the adjoint of @xmath50 is denoted by @xmath52 .",
    "recent algorithms developed for ( [ mtx_cmp ] ) include , but not limited to , the singular value thresholding ( svt ) algorithm @xcite and the fixed - point continuation iterative algorithm ( fpca ) @xcite for fast completion of large - scale matrices ( e.g. , more than @xmath53@xmath54@xmath53 ) , a special trimming step introduced by keshavan et al . in @xcite . for our problem , we adopt fpca , which appears to run very well for our small  dimensional tests . in the following subsections ,",
    "we describe this algorithm and the steps we take for nuclear norm minimization .",
    "also , we study how to use the approximate singular value decomposition ( svd)-based iterative algorithm introduced in @xcite for fast execution .",
    "we further discuss the stopping criteria for iterations to acquire optimal recovery .",
    "finally we show how to obtain @xmath13 from the estimation @xmath55 of @xmath27 .",
    "fpca is based on the following fixed ",
    "point iteration : @xmath56 where @xmath57 is step size and @xmath58 is the matrix shrinkage operator defined as follows :    [ def : shrinkage ] * matrix shrinkage operator @xmath59 * : assume @xmath60 and its svd is given by @xmath61 , where @xmath62 , @xmath63 , and @xmath64 . given @xmath65 ,",
    "@xmath59 is defined as @xmath66 with the vector @xmath67 defined as : @xmath68    simply speaking , @xmath69 reduces every singular values ( which is nonnegative ) of @xmath27 by @xmath49 ; if one is smaller than @xmath22 , it is reduced to zero . in addition",
    ", @xmath70 is the solution of @xmath71 where @xmath72 is the frobenius norm .",
    "to understand , observe that the first step of is a gradient - descent applied to the second term in and thus reduces its value . because the previous gradient - descent generally increases the nuclear norm ,",
    "the second step of involves solving to reduce the nuclear norm of @xmath73 .",
    "iterations based on converge when the step sizes @xmath57 are properly chosen ( e.g. , less than 2 , or select by line search ) so that the first step of is not `` expansive '' ( the other step is always non - expansive ) .",
    "as stated in @xcite , the second step of requires computing the svd decomposition of @xmath73 , which is the main computational cost of .",
    "however , if one can predetermine the rank of the matrix @xmath27 , or have the knowledge of the approximate range of its rank , a full svd can be simplified to computing only a rank-@xmath74 approximation to @xmath73 .",
    "combined with the above fixed point iteration , the resulting algorithm is called fixed - point continuation algorithm with approximate svd ( fpca ) .",
    "specifically , the approximate svd is computed by a fast monte carlo algorithm developed by drineas et al.@xcite . for a given matrix @xmath75 and parameters @xmath76",
    ", this algorithm returns an approximations to the largest @xmath76 singular values corresponding left singular vectors of the matrix @xmath77 in a linear time .",
    "we tune the parameters in fpca for a better overall performance .",
    "continuation is adopted by fpca , which solves a sequence of instances of , easy to difficult , corresponding to a sequence of large to small values of @xmath49 .",
    "the final @xmath49 is the given one but solving the easier instances of gives intermediate solutions that warm start the more difficult ones so that the entire solution time is reduced .",
    "solving each instance of requires proper stopping . because our ultimate goal is to recover 0/1 values on the diagonal of @xmath13 , accurate solutions of are not required .",
    "therefore , we use the criterion : @xmath78 where @xmath79 is a small positive scalar .",
    "experiments shows that @xmath80 is good enough for obtaining optimal @xmath13 .",
    "since @xmath11 has more columns than rows , directly solving @xmath81 in from given @xmath27 is under - determined .",
    "however , each row @xmath82 of @xmath83 corresponds to the occupancy status of channel @xmath84 . ignoring noise in @xmath27 for now",
    ", @xmath82 contains a positive entry if and only if channel @xmath84 is used .",
    "hence , most rows of @xmath83 are completely zero , so every column @xmath85 of @xmath83 is sparse and all @xmath85 s are jointly sparse",
    ". such sparsity allows us to reconstruct @xmath83 from and identify the occupied channels , which are the nonzero rows of @xmath83 .",
    "since the channel fading decays fast , the entries of @xmath83 have a large dynamic range , which none of the existing algorithms can deal with well enough . hence , we develop a novel joint - sparsity algorithm briefly described as follows .",
    "the algorithm is much faster than matrix completion and typically needs 1 - 5 iterations . at each iteration",
    ", every column @xmath85 of @xmath83 is independently reconstructed using the model @xmath86 , where @xmath87 is the @xmath88th column of @xmath27 .",
    "for noisy @xmath27 , we instead use the constraint @xmath89 .",
    "the same set of weights @xmath90 is shared by all @xmath88 at each iteration .",
    "@xmath90 is set to 1 uniformly at iteration 1 .",
    "after channel @xmath84 is detected in an iteration , @xmath90 is set to 0 . through @xmath90 ,",
    "joint sparsity information is passed to all @xmath88 .",
    "channel detection is performed on the reconstructed @xmath85 s at each iteration .",
    "it is possible that some reconstructed @xmath85 is wrong , so we let larger and sparser @xmath85 s have more say . if there is a relatively large @xmath91 in a sparse @xmath85 , then @xmath84 is detected .",
    "we have found this algorithm to be very reliable .",
    "the detection accuracy is determined by the accuracy of @xmath27 provided .",
    "in this section , we describe a new , highly effective algorithm for recovering @xmath92 and thus @xmath13 by thresholding @xmath83 . the algorithm allows but does not require the same @xmath11 for all crs , i.e.",
    ", each cr can use a different sensing matrix @xmath11 .",
    "the design of @xmath11 is discussed in section [ sec : discussion_design ] below .    in @xmath83",
    ", each column ( denoted by @xmath85 ) corresponds to the channel occupancy status received by cr @xmath88 , and each row @xmath93 corresponds to the occupancy status of channel @xmath84 . _",
    "ignoring noise _ for now , a row has a positive value ( i.e. , @xmath94 ) if and only if channel @xmath84 is used .",
    "since there are only a small number of used channels , @xmath83 is sparse in terms of the number of rows containing nonzero . in each nonzero row @xmath93",
    ", there is typically more than one nonzero entry ; in other words , if @xmath95 , other entries in the same row are likely nonzero . therefore , @xmath83 is _",
    "jointly sparse_. in the case that the true @xmath83 contains noise , it is approximately , rather than exactly , jointly sparse .",
    "joint sparsity is utilized in our algorithm to recover @xmath83 .",
    "while there are existing algorithms for recovering jointly sparse signals in the literature ( e.g. , in @xcite ) , our algorithm is very different and more effective for our underlying problem .",
    "none of the existing algorithms works well to recover @xmath83 because the entries of @xmath83 have a very large dynamic range because , in any channel fading model , channel gains decay rapidly with distance between crs and prs .",
    "most existing algorithms are based on minimizing @xmath96 for @xmath97 and @xmath98 .",
    "if @xmath99 , it is the same as minimizing the 1-norm of each column independently , so joint sparsity is not used for recovery . if @xmath100 or @xmath98 , joint sparsity is considered , but it penalizes a large dynamic range since the large values in a nonzero row of @xmath83 contribute superlinearly , more than the small values in that row , to the minimizing objective . in short , @xmath4 close 1 loses joint sparsity and @xmath4 bigger than 1 penalizes large dynamic ranges .",
    "our new algorithm not only utilizes joint sparsity but also takes advantages of the large dynamic range of @xmath83 .",
    "the large dynamic range has its pros and cons in cs recovery .",
    "it makes it easy to recover the locations of large entries , which can be achieved even without recovering the locations of smaller ones . on the other hand",
    ", it makes difficult to recover both the locations and values of the smaller entries .",
    "this difficulty has been studied in our previous work @xcite , where we proposed a fast and accurate algorithm for recovering 1d signals @xmath101 by solving several ( about 5 - 10 ) subproblems in the form of @xmath102 where the index set @xmath103 is formed iteratively as @xmath104 excluding the identified locations of large entries of @xmath101 . with techniques such as early detections and warm starts ,",
    "it achieves both the state  of  the  art speed and least requirement on the number of measurements .",
    "we integrate the idea of this algorithm with joint sparsity into the new algorithm below .",
    "@xmath105 @xmath106 for every cr @xmath88 with enough measurements ( in presence of measurement noise , @xmath107 is replaced by @xmath108 ) report @xmath83 , and @xmath13 by thresholding @xmath83    the framework of the proposed algorithm is shown in table [ t : algorithm ] . at each iteration , every channel is first subject to independent recovery . unlike minimizing @xmath96 , which ties all crs together",
    ", independent recovery allows large entries of @xmath83 to be quickly recovered .",
    "joint sparsity information is passed among the crs through a shared index set @xmath103 , which is updated iteratively to exclude the used channels that are already discovered .",
    "below , we describe each step of the above algorithm in more details .    in the * independence recovery * step , for every qualified cr , a constrained problem in the form of with constraints @xmath109 in the noiseless case , or @xmath108 in the noisy case ,",
    "is considered , where @xmath110 is an estimated noise level . as",
    "problem dimensions are small in our application , solvers are easily chosen : matlab s ` linprog ' for noiseless cases and mosek @xcite for noisy cases .",
    "both of these solvers run in polynomial times .",
    "this step dominates the total running time of algorithm [ t : algorithm ] , but up to @xmath2 optimization problems can be solved in parallel .",
    "parallelization is simple for the joint - sparsity approach . at each outer iteration ,",
    "all lps are solved independently , and they have small scales relative to today s lp solvers , like gurobi @xcite and its matlab interface gurobi mex @xcite , where gurobi automatically detects and uses all cpu and cores for solving lps .",
    "crs without enough measurements ( e.g. , most of their reports are missing due to transmission losses or errors ) are not qualified for independent recovery because cs recovery is known unstable in such a case .",
    "specifically , we require the number of the available measurements from each qualified cr to exceed twice as many as used channels or @xmath111 .",
    "when measurements are ample , the first iteration will yield exact or nearly exact @xmath85 s . otherwise , insufficient measurements can cause a completely wrong @xmath85 that misleads channel detection ; neither the locations nor the values of the nonzero entries are correct . the algorithm , therefore , filters trusted @xmath85 s that must be either sparse or compressible .",
    "large entries in such @xmath85 s likely indicate correct locations .",
    "a theoretical explanation of this argument based on stability analysis for is given in @xcite .",
    "used channels are detected among the set of trusted @xmath85 s . to further reduce the risk of false detections , we compute a percentage for every channel in a way that those channels corresponding to larger values in @xmath83 and whose values",
    "are located in relatively sparser @xmath85 s are given higher percentages . here",
    ", relative sparsity is defined proportionally to the number of measurements ; for fixed number of non - zeros or degree of compressibility , the more the measurements , the higher the relative sparsity .",
    "hence , @xmath85 corresponding to more reported cr @xmath88 also tends to have a higher percentage . in short , larger and sparse solutions",
    "have more say .",
    "the channels receiving higher percentages are detected as used channels .",
    "the index set @xmath103 is set as @xmath112 excluding the used channels that are already detected .",
    "obviously , @xmath103 needs to change from one iteration to the next ; otherwise , two iterations will result in an identical @xmath83 and thus the stagnation of algorithm .",
    "therefore , if the last iteration posts no change in the set of used channels yet the stopping criterion ( see next paragraph ) is not met , the channels @xmath84 corresponding to the larger @xmath113 are also excluded from @xmath103 , and such exclusion becomes more aggressive as iteration number increases .",
    "this is not an ad hoc but a rigorous treatment .",
    "it is shown in @xcite that larger entries in an inexact cs recovery tend to be the true nonzero entries , and furthermore , as long as the new @xmath103 excludes more true than false nonzero entries by a certain fraction , will yield a better solution in terms of a certain norm . in short ,",
    "used channels leave @xmath103 , and in case of no leaves , channels with larger joint values @xmath113 leave @xmath103 .",
    "finally , the iteration is terminated when the tail of @xmath83 is small enough .",
    "one way to define the tail size of @xmath83 is the fraction @xmath114 , i.e. , the thought ",
    "unused divided by the thought  used .",
    "suppose that @xmath103 precisely contains the unused channels and measurements are noiseless , then every recovered @xmath85 in channel detection is exact , so the fraction is zero ; with noise , the fraction depends on noise magnitude and is small as long as noise is small .",
    "if @xmath103 includes any used channel , the numerator will be large whether or not @xmath85 s are ( nearly ) exact . in a sense , the tail size measures how well @xmath83 and @xmath103 match the measurements @xmath115 and expected sparseness .",
    "unless the true number of used channels is known , the tail size appears to be an effective stopping indicator .",
    "in the worst case , algorithm [ t : algorithm ] reduces the cardinality of @xmath103 by 1 per iteration , corresponding to recovering at least 1 additional used channel . therefore , the number of iterations can not exceed the number of total channels .",
    "however , the first couple of iterations typically recover most of the used channels . at each iteration",
    ", the independence recovery step solves up to @xmath2 optimization problems , which can be independently solved in parallel , so the complexity equals a linear program ( or second - order cone program ) whose size is no more than @xmath1 .",
    "the worst case complexity is @xmath116 but it is almost never observed in sparse optimization thanks to solution sparsity .",
    "the two other steps are based on basic arithmetic and logical operations , and they run in @xmath117 . in practice ,",
    "algorithm [ t : algorithm ] is implemented and run on a workstation at the fusion center .",
    "computational complexity will not be a bottleneck of the system . as to the matrix completion algorithm",
    ", according to @xcite , fpca can recover @xmath118 matrices of rank 50 with a relative error of @xmath119 in about 3 minutes by sampling only 20 percent of the elements .",
    "the matrix completion ( section [ sec : algorithm1 ] ) and joint sparsity recovery ( section [ sec : algorithm2 ] ) approaches both take linear channel measurements as input and both return the estimates of used channels . on the other hand",
    ", the joint sparsity approach takes the full advantage of @xmath11 , so it is expected to work with smaller numbers of measurements . in addition , even though only one matrix completion problem needs to be solved in the matrix completion approach , it still takes much longer than running the entire joint sparsity recovery , and it is not easy to parallelize any of the existing matrix completion algorithms .",
    "however , in the small - scale networks , in cases where too much sensing information is lost during transmission or there are too many active prs in the network , which increase the signal sparsity level , joint sparsity recovery algorithm with our current settings will experience degradation in performance .    we , however , can not verdict an eventual winner between the two approaches as they are both being studied and improved in the literature .",
    "for example , if a much faster matrix completion algorithm is developed which takes advantage of @xmath11 , the disadvantages of the approach may no longer exist .",
    "the proposed method senses the channels , not by measuring the responses of individual channels one by one , but rather measures a few incoherent linear combinations of all channels responses through onboard frequency - selective filter set .",
    "the filter coefficients which perform as the sensing matrix should have entries independently sampled from a sub - gaussian distribution , since this is known to be best for compressive sensing in terms of the number of measurements ( given in order of magnitude ) required for exact recovery . in other words ,",
    "up to a constant , which is independent of problem dimensions , no other type of matrix is yet known to perform consistently better . however , other types of matrices ( such as partial fourier / dct matrices @xcite and other random circulant matrices @xcite ) have been either theoretically and/or numerically demonstrated to work as effectively in many cases .",
    "these latter sensing matrices are often easier to realize physically or electrically .",
    "for example , applying a random circulant matrix performs sub - sampled convolution with a random vector .    frequency - selective surfaces ( fsss ) can be used to realize frequency filtering .",
    "this can be done by designing a planar periodic structure with a unit element size around half wavelength of the frequency of interests .",
    "both the metallic and dielectric materials can be used . to deal with the bandwidth , unit elements in different shapes will be tested .",
    "channel occupancy evolves over time as prs start and stop using their channels .",
    "channel gains can also change when the prs move .",
    "however , the cs research has so far focused on static signal sensing except the very recent path following algorithms in @xcite . in the future work",
    ", we can investigate recovery methods for a dynamic wireless environment where based on existing channel occupancy information , an insignificant change of channel states can be quickly and reliably discovered . given existing channel occupancy @xmath83 , each new report , which is an entry @xmath120 of @xmath27 ,",
    "is compared with @xmath121 .",
    "if a significant number of such comparisons show differences , then there is a change in the true @xmath83 . since @xmath122 , either @xmath13 or @xmath16 , or both , have changed .",
    "a change in @xmath13 means new channel occupation or release . if @xmath13 is unchanged , then those channel gains in @xmath16 corresponding to occupied channels have changed .",
    "it is easy to deal with the latter case ( i.e. , @xmath16 changed , but @xmath13 did nt ) and update the gains of occupied channels because it boils down to solving a small linear system .",
    "let @xmath123 and @xmath124 denote the sub - matrices of @xmath11 and @xmath83 , respectively , formed by their columns and rows corresponding to the occupied channels .",
    "then , the new gains are given in the least - squares solution of @xmath125 , where @xmath27 shall include new reports arrived after the previous recovery / update but may still have missing entries . this system is easy to solve since the number of occupied channels is small .    in a similar way it is easy",
    "to discover released channels as long as there is no introduction of new occupied channels .",
    "the release of channel @xmath84 means row @xmath82 of @xmath83 turns into 0 , or small numbers .",
    "therefore , one can solve the system @xmath125 and find the released channels , which correspond to the rows of @xmath124 with all zero ( or small ) entries .",
    "when the system @xmath125 is inconsistent , it means that the received reports can not be explained by the previously occupied channels , so there must be new channel occupation . discovering new channel occupation is more difficult since it is to find changes in the previously unoccupied ones , which are much more than the occupied channels .",
    "however , it is computationally much easier than starting from scratch .",
    "let @xmath126 and @xmath83 denote the previous and current channel information , respectively .",
    "arguably , @xmath127 is highly sparse in the joint sense because only its rows corresponding to newly occupied or released channels can have large nonzero entries .",
    "hence , @xmath83 can be quickly recovered by performing joint sparsity recovery on @xmath127 over the constraints @xmath128 ( or a relax version in the noisy case ) , a task that can be done by the algorithms for stationary recovery .",
    "the probability of detection ( pod ) and false alarm rate ( far ) are the two most important indices associated with spectrum sensing .",
    "we also consider the miss detection rate ( mdr ) of the proposed system .",
    "the higher the pod , the less interference will the crs bring to the prs , while from the crs perspective , lower far will increase their chance of transmission .",
    "there is a tradeoff between pod and far .",
    "while designing the algorithms , we try to balance the cr nodes capability of transmission and their interferences to the pr nodes .",
    "performance is evaluated in terms of pod , far and mdr defined as follows : @xmath129 where _ no . false _ is the number of false alarms , _ no . miss _ is the number of miss detections , _ no .",
    "hit _ is the number of successful detections of primary users , and _ no .",
    "correct _ is the number of correct reports of no appearance of pr . we define sampling rate as @xmath130 where @xmath131 is the amount of total sensing workload in traditional spectrum sensing .     +      according to fcc and defense advance research projects agency ( darpa )",
    "reports @xcite data , we chose to test the proposed matrix completion recovery algorithm for spectrum utilization efficiency over a range from 3% to 12% , which is large enough in practice .",
    "specifically , the number of active primary users is 1 to 4 on a given set of 35 channels with 20 cr nodes .",
    "[ f : far_mdr_sr ] shows the false alarm and miss detection rates at different sampling rates for different numbers of pr nodes . among all cases ,",
    "the highest miss detection rate is no more than 5% , and this is from only 20% samples which are supposed to be gathered from the cr nodes regarding all the channels .",
    "when the sampling rate is increased to 50% and even when the channel occupancy is relatively high , i.e. , 12% of the channels are occupied by the prs , the miss detection rates can be as low as no more than 2% . from our simulation results , with a moderate channel occupancy at 9% ,",
    "the false alarm rates are around 3% to 5% .",
    "[ f : pod_sr ] shows the probability of detection at different sampling rates .",
    "when the spectrum is lightly occupied by the licensed user at 3% channels being occupied , only 20% samples offer a pod close to 100% , and when there is a slightly raise in sampling rate , pod can reach 100% . in the worst case of 12% spectrum occupancy , 20% sampling rate still can offer a pod of higher than 95% , and as the sampling rate reaches 50% , pod can reach 98% .",
    "joint sparsity recovery is designed for large scale application , and simulations carried out for a larger dimensional applications with the following settings : we consider a @xmath132-node cognitive radio network within a @xmath133 meter square area centered at the fusion center .",
    "the @xmath132 cr nodes are uniformly randomly located .",
    "these cognitive radio nodes collaboratively sense the existence of primary users within a @xmath118 meter square area on @xmath134 channels , which are centered also at the fusion center .",
    "we chose to test the proposed algorithm for the number of active pr nodes ranging from @xmath6 to @xmath135 on the given set of 500 channels .",
    "since the fading environments of the cognitive radio networks vary , we evaluate the algorithm performance under three typical channel fading models : awgn channel , rayleigh fading channel , and lognormal shadowing channel .",
    "+     +    we first evaluate the pod , far , and mdr performance of the proposed joint sparsity recovery performance in the noiseless environment .",
    "[ f : nn_t0_5 ] , fig .",
    "[ f : nn_t1_5 ] , and fig .",
    "[ f : nn_t2_5 ] show the pod , far and mdr performance at different sampling rate , for awgn channel , rayleigh fading channel , and lognormal shadowing channel , respectively , when small number of cr nodes sense the spectrum collaboratively . fig .",
    "[ f : nn_t0_10 ] , fig .",
    "[ f : nn_t1_10 ] , and fig .",
    "[ f : nn_t2_10 ] show the pod , far and mdr performance at different sampling rate , for the aforementioned three types of channel models , when there are more cr nodes involved in the collaborative sensing of the spectrum .",
    "we observe that , log - normal shadowing channel model shows the best pod , far , and mdr performance no matter how many cr nodes are involved in the spectrum sensing . while the agwn channel model shows the worst pod , far , and mdr performance .",
    "with respect to pod , the performance gap between these two models is at most 10% , which happens when the sampling rate is extremely low . for the rayleigh fading channel model , when the number of samples is @xmath136 of the total number of channels , for all tested cases we achieve @xmath137 pod .",
    "if there are less active pr nodes in the network , smaller number of samples are required for exact detection .",
    "in essence , the proposed ccs system is robust to severe or poorly modeled fading environments .",
    "cooperation among the cr nodes and robust recovery algorithm allow us to achieve this robustness without imposing stringent requirements on individual radios .",
    "+    we then evaluate the pod , far , and mdr performance of the proposed joint sparsity recovery performance in noisy environments .",
    "for all the simulations considering noise , we adopt the rayleigh fading channel model .",
    "[ f : n_performance ] and fig .",
    "[ f : n_per_snr ] show the corresponding results .",
    "we observe that noise does degrade the performance .",
    "however , as shown in fig .",
    "[ f : n_performance ] , when the number of active prs is small enough ( e.g. , no . of pr = 1 ) , even with signal to noise ratio as low as 15 db , we still can achieve @xmath137 pod with a sampling rate of merely @xmath0 . then with an increase in the signal to noise ratio",
    ", lower sampling rate enables more pr nodes to be detected exactly .",
    "[ f : n_per_snr ] shows the pod , far and mdr performance vs. sampling rate at different noise level , each curve for a specific noise level is relatively flat ( i.e. , performance varies a little as sampling rate changes ) .",
    "this shows that the noise level has greater impact on the spectrum sensing performance rather than the sampling rate . at low noise level ,",
    "e.g. , snr = 45 db , @xmath138 sampling rate enables @xmath137 pod for 4 pr nodes .",
    "as snr reduces to 15 db , no more than @xmath139 pod will be achieved even when the number of samples equals to the number of channels in the network .     +      for comparison , we applied joint sparsity recovery algorithm on a small - scale network with the same settings as we have used to test the matrix completion recovery . instead of using a 500-channel network",
    ", we use a network with only 35 channels .",
    "simulation results show that joint sparsity recovery algorithm performs better than the matrix completion algorithm in the following aspects :    1 .",
    "faster computation due to lower computational complexity ; 2 .   higher pod for the spectrum utilization rate between 3% and 12% in the noise free simulations ;    to conclude , matrix completion algorithm is good for small - scale networks , with relatively high spectrum utilization , while joint sparsity recovery algorithm has the advantage of low computational complexity which enables fast computation in large - scale networks .",
    "+     +     +",
    "in order to reduce the amount of sensing and transmission overhead of cognitive radio ( cr ) nodes , we have applied compressive sensing for collaborative spectrum detection in cognitive radio networks . we propose to equip each cr node with a frequency - selective filter , which linearly combines multiple channel information , and let it send a small number of such linear combinations to the fusion center , where the channel occupancy information is then decoded .",
    "consequently , the amount of channel sensing at the crs and the number of reports sent from the crs to the fusion center reduce significantly .",
    "two novel decoding approaches have been proposed ",
    "one based on matrix completion and the other based on joint sparsity recovery .",
    "the novel matrix completion approach recovers the complete cr  to  center reports from a small number of valid reports and then reconstructs the channel occupancy information .",
    "the joint sparsity approach , on the other hand , skips recovering the reports and directly reconstructs channel occupancy information by exploiting the fact that each occupied channel is observable by multiple cr nodes .",
    "our algorithm enables faster recovery for large - scale cognitive radio networks .",
    "the primary user detection performance of the proposed approaches has been evaluated by simulations .",
    "the results of random tests show that , in noiseless cases , the number of samples required are no more than 50% of the number of channels in the network to guarantee exact primary user detection for both approaches ; while in noisy environments , at low channel occupancy rate , we can still have high probability of detection .",
    "the work of w. yin was supported in part by nsf career award dms-07 - 48839 , onr grant n00014 - 08 - 1 - 1101 , and an alfred p. sloan research fellowship .",
    "the work of h. li was supported in part by nsf grants 0831451 and 0901425 .",
    "the work of z. han was supported in part by nsf cns-0910461 , cns-0901425 , nsf career award cns-0953377 , and air force office of scientific research .",
    "the work of e. hossain was supported by the nserc , canada , strategic project grant stpgp 380888 .                c. h. lee and w. wolf ,  energy efficient techniques for cooperative spectrum sensing in cognitive radios , \" in _ proc .",
    "ieee consumer communications and networking conference ( ccnc08 ) _ , las vegas , nevada , january 2008 .",
    "a. ghasemi and e. sousa ,  collaborative spectrum sensing for opportunistic access in fading environments , \" in _ proc .",
    "ieee international symposium on new frontiers in dynamic spectrum access networks ( dyspan05 ) _ , baltimore , md , november 2005 .",
    "w. saad , z. han , m. debbah , a. hjrungnes , and t. basar ,  coalitional games for distributed collaborative spectrum sensing in cognitive radio networks , \" in _ proc .",
    "ieee conference on computer communications ( infocom09 ) _ , rio de janeiro , brazil , april 2009 .    l. s. cardoso , m. debbah , p. bianchi , and j. najim ,  cooperative spectrum sensing using random matrix theory , \" in _ proc . international symposium on wireless pervasive computing ( iswpc08 ) _ , santorini , greece , may 2008 .    c. sun , w. zhang , and k. b. letaief , ",
    "cluster - based cooperative spectrum sensing in cognitive radio systems , \" in _ proc .",
    "ieee international conference on communications ( icc07 ) _ , glasgow , scottland , june 2007 .",
    "l. cao and h. zheng ,  distributed rule - regulated spectrum sharing , \" _ ieee journal on selected areas in communications : special issue on cognitive radio : theoryand applications _ , vol .",
    "1 , pp . 130145 , january 2008 .      c. sun , w. zhang , and k. b. letaief ,  cooperative spectrum sensing for cognitive radios under bandwidth constraint , \" in _ proc .",
    "ieee wireless communications and networking conference ( wcnc07 ) _ , hong kong , march 2007 .",
    "j. meng , j. ahmadi - shokouh , h. li , z. han , s. noghanian , and e. hossain ,  sampling rate reduction for 60 ghz uwb communication using compressive sensing , \" in _ proc .",
    "asilomar conference on signals , systems @xmath140 computers _ ,",
    "monterey , ca , november 2009 .",
    "j. meng , h. li , and z. han ,  sparse event detection in wireless sensor networks using compressive sensing , \" in _ proc .",
    "43rd annual conference on information sciences and systems ( ciss ) _ , baltimore , md , march 2009 .",
    "e. j. cands and b. recht ,  exact low - rank matrix completion via convex optimization , \" in _ proc .",
    "communication , control , and computing , 46th annual allerton conference _ , monticello , il , september 2008 .",
    "m. f. duarte , s. sarvotham , m. b. wakin , d. baron , and r. g. baraniuk ,  joint sparsity models for distributed compressed sensing , \" in _ proc .",
    "workshop on signal processing with adaptive sparse structured representations _ ,",
    "rennes , france , november 2005 .",
    "j. tropp , a. c. gilbert , and m. j. strauss ,  simulataneous sparse approximation via greedy pursuit , \" in _ proc .",
    "ieee 2005 international conference on acoustics , speech , and signal processing ( icassp ) _ , philadelphia , pa , march 2005 .",
    "j. meng , w. yin , h. li , e. hossain , and z. han ,  collaborative spectrum sensing from sparse observations using matrix completion for cognitive radio networks , \" in _ proc .",
    "ieee 2010 international conference on acoustics , speech , and signal processing ( icassp ) _ , march 2010 .",
    "e. j. cands , j. romberg , and t. tao ,  robust uncertainty principles : exact signal reconstruction from highly incomplete frequency information , \" _ ieee trans . on information theory _ , 52(2 ) , pp . 489509 , february 2006 .",
    "w. yin , s. p. morgan , j. yang , and y. zhang ,  fast sensing and signal reconstruction : practical compressive sensing with toeplitz and circulant matrices , \" _ rice university caam technical report tr10 - 01_. _ submitted to vcip 2010 _ , 2010 ."
  ],
  "abstract_text": [
    "<S> spectrum sensing , which aims at detecting spectrum holes , is the precondition for the implementation of cognitive radio ( cr ) . </S>",
    "<S> collaborative spectrum sensing among the cognitive radio nodes is expected to improve the ability of checking complete spectrum usage . due to hardware limitations , </S>",
    "<S> each cognitive radio node can only sense a relatively narrow band of radio spectrum . </S>",
    "<S> consequently , the available channel sensing information is far from being sufficient for precisely recognizing the wide range of unoccupied channels . aiming at breaking this bottleneck , we propose to apply matrix completion and joint sparsity recovery to reduce sensing and transmitting requirements and improve sensing results . </S>",
    "<S> specifically , equipped with a frequency selective filter , each cognitive radio node senses linear combinations of multiple channel information and reports them to the fusion center , where occupied channels are then decoded from the reports by using novel matrix completion and joint sparsity recovery algorithms . as a result , the number of reports sent from the crs to the fusion center is significantly reduced . </S>",
    "<S> we propose two decoding approaches , one based on matrix completion and the other based on joint sparsity recovery , both of which allow exact recovery from incomplete reports . </S>",
    "<S> the numerical results validate the effectiveness and robustness of our approaches . in particular , </S>",
    "<S> in small - scale networks , the matrix completion approach achieves exact channel detection with a number of samples no more than @xmath0 of the number of channels in the network , while joint sparsity recovery achieves similar performance in large - scale networks .    </S>",
    "<S> _ keywords _ : collaborative spectrum sensing , matrix completion , compressive sensing , joint sparsity recovery . </S>"
  ]
}