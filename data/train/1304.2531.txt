{
  "article_text": [
    "optimal quantization method appears first in @xcite where the author studies in particular the optimal quantization problem for the uniform distribution .",
    "it has become an important field of information theory since the early @xmath2 s .",
    "a common use of quantization is the conversion of a continuous signal into a discrete signal that assumes only a finite number of values .",
    "since then , optimal quantization is applied in many fields like in signal processing , in data analysys , in computer sciences and recently in numerical probability from the seminal work @xcite .",
    "its application to numerical probability relies on the possibility to discretize a random vector @xmath3 taking infinitely many values by a discrete random vector @xmath4 valued in a set of finite cardinality .",
    "this allows to approximate either expectations of the form @xmath5 or more significantly some conditional expectations like @xmath6 ( by quantizing both randoms variables @xmath3 and @xmath7 ) .",
    "optimal quantization is used to solve some problems emerging in quantitative finance as optimal stopping problems ( see @xcite ) , the pricing of swing options ( see @xcite ) , stochastic control problems ( see @xcite ) , nonlinear filtering problems ( see e.g. @xcite ) , the pricing of barrier options ( see @xcite ) .    in quantitative finance , several problems of interest amounts to the estimation of quantities of the form ( for a given borel function @xmath8 ) @xmath9 , \\quad t>0,\\ ] ] or involving terms like @xmath10 , \\quad   0<s < t,\\ ] ] related to a stochastic diffusion process @xmath11}$ ] solution to the stochastic differential equation @xmath12 where @xmath13 is a standard @xmath14-dimensional brownian motion starting at @xmath15 and where the functions @xmath16 \\times \\mathbb r^d \\rightarrow \\mathbb r^d$ ] and the matrix - valued diffusion coefficient function @xmath17 \\times \\mathbb r^d \\rightarrow \\mathbb r^{d \\times q}$ ] are borel measurable and satisfy some appropriate conditions which ensure the existence of a strong solution of the stochastic differential equation . since in general the solution of ( [ eqsignalintro ] ) is not explicit we have first to approximate the continuous paths of the process @xmath18}$ ] by a discretization scheme , typically , the euler scheme . given the ( regular ) time discretization mesh @xmath19 , @xmath20 , @xmath21 , the `` discrete time euler process '' @xmath22 , @xmath23 , associated to the previous diffusion process @xmath11}$ ] is recursively defined by @xmath24 then , once we have access to the discretization scheme of the stochastic process @xmath11}$ ] , the quantities ( [ eqpriceeurolikeoptionsc ] ) and ( [ eqnlfilterlikeoptionsc ] ) can be estimated by @xmath25\\ ] ] and @xmath26 , \\quad \\textrm{when   } t = t_{k+1 } \\textrm { and }   s = t_k.\\ ] ]    [ remconvereuler ] ( a ) for smooth functions @xmath27 or under hypoellipticity assumptions on @xmath28 ( see e.g. @xcite ) , the estimation of @xmath29 by @xmath30 induces the following weak error : @xmath31 with @xmath32 and where @xmath33 is the number of time discretization steps .",
    "\\(b ) also note that for every @xmath34 , @xmath35    the estimation of quantities like ( [ eqpriceeurolikeoptions ] ) or ( [ eqnlfilterlikeoptions ] ) can be performed using monte carlo simulations .",
    "nevertheless , an alternative to the monte carlo method can be to use cubature formulas produced by an optimal quantization approximation method , especially in small or medium dimension ( @xmath36 in the theory but in practice it may remain competitive with respect to the monte carlo method up to dimension @xmath37 , see @xcite ) .",
    "in fact , suppose that we have access to the optimal quantization or to some `` good '' ( in a sense to be specified further on ) quantizations @xmath38 ( we will sometimes denote @xmath39 by @xmath40 to simplify notations ) of the process @xmath41 on the grids @xmath42 of size @xmath43 ( which will be called an @xmath43-quantizer ) , for @xmath23 .",
    "suppose as well that we have access or have computed ( offline ) the associated weights @xmath44 , @xmath45 ; @xmath23 ( which are the distributions of the @xmath39 s ) , and the transition probabilities @xmath46 for every @xmath47 ; @xmath48 ; @xmath49 ( in other words , the conditional distributions @xmath50 ) .",
    "then , using optimal quantization method , the expressions ( [ eqpriceeurolikeoptions ] ) and ( [ eqnlfilterlikeoptions ] ) can be estimated by @xmath51   = \\sum_{i=1}^{n_n } f(x^{n}_i )   \\ , \\mathbb p \\big(\\widehat x_{t_n}^{\\gamma_n }    =   x^{n_n}_i \\big)\\ ] ] and @xmath52   = \\sum_{j=1}^{n_{k+1 } } \\widehat p_k^{ij } f(x^{k+1 } _ j ) , \\ ] ] respectively .",
    "the remaining question to be solved is then to know how to get the optimal or at least `` good '' grids @xmath53 , for every @xmath54 , their associated weights and transition probabilities . in a more general framework , as soon as the stochastic process @xmath41 ( or the underlying diffusion process @xmath55 ) can be simulated one may use stochastic gradient algorithm ( clvq ) or a randomized fixed point procedure ( lloyd ) to compute the ( hopfully almost ) optimal grids and their associated weights or transition probabilities . in the special case of",
    "the one dimensional setting we can often use the newton - raphson s algorithm in several situations of interest .",
    "this deterministic algorithm leads to more precise estimations and is dramatically faster than stochastic optimization methods .    to highlight the usefulness of our method , suppose for example that we aim to estimate the price of a put option with a maturity @xmath56 , strike @xmath57 and a present value @xmath58 in a local volatility model where the dynamics of the stock price process evolves following the stochastic differential equation ( called pseudo - cev in @xcite ) : @xmath59,\\ ] ] where @xmath60 and @xmath61 $ ] , @xmath62 , and @xmath63 stands for the interest rate",
    "in this situation the solution at time @xmath56 , @xmath64 , is not known analytically and if we want to estimate the quantity of interest : @xmath65 , where @xmath66 is the ( lipschitz continuous ) payoff function , we have first of all to discretize the process @xmath18}$ ] as @xmath67 , with @xmath68 ( using e.g. the euler scheme ) , and then estimate @xmath69 by optimal quantization",
    ". the only way to get the optimal grids and the associated weights in this situation is to perform stochastic algorithms like the clvq ( see e.g. @xcite ) or the lloyd s procedure ( see e.g. @xcite ) , even in the one dimensional framework .",
    "however , these methods may be very time consuming . in this framework ( as well as in the general local volatility model framework in dimension @xmath70 )",
    ", our approach allows us to quantize the diffusion process in the pseudo - cev model using the newton - raphson algorithm to reduce dramatically the computational complexity of the search of optimal quantizers while increasing their computational precision with respect to commonly proposed algorithms .",
    "it is important to notice that the companion weights and the probability transitions associated to the quantized process are obtained by a closed formula so that the method involves by no means monte carlo simulations . on the other hand ,",
    "a comparison with monte carlo simulation for the pricing of european options in a local volatility model also shows that the proposed method is more efficient ( with respect to both computational precision and time complexity ) than the monte carlo method .",
    "let us be more precise about our proposed method in the general setting where the diffusion @xmath11}$ ] evolves following equation .",
    "let @xmath67 be the discrete euler process , with step @xmath71 , associated to the diffusion @xmath11}$ ] .",
    "our aim is in practice to compute the quadratic optimal quantizers @xmath72 associated with the @xmath73 s , for @xmath23 .",
    "such a sequence @xmath72 is defined for every @xmath23 by @xmath74 where for every @xmath54 , the function @xmath75 is called the distortion function associated to @xmath76 and is defined for every @xmath43-quantizer @xmath53 by @xmath77    now , by conditioning with respect to @xmath76 , we observe that we can connect the distortion function @xmath78 associated to @xmath79 with the distribution of @xmath76 by introducing the euler scheme operator as follows : @xmath80            \\end{aligned}\\ ] ] where @xmath81 is an @xmath82 sequence of @xmath83-distributed random vectors independent from @xmath84 and for every @xmath85 , the euler operator @xmath86 is defined by @xmath87 now , here is how we construct the algorithm .",
    "given the distribution of @xmath84 , we quantize @xmath84 and denote its quantization by @xmath88 .",
    "we want now to quantize @xmath89 , which distribution is unknown . keeping in mind equation ( [ eqdistasdistxtkintro ] ) and setting @xmath90 ,",
    "we may approximate the distortion function @xmath91 by @xmath92 \\nonumber    =   \\mathbb e \\big [    d({\\cal e}_0(\\widehat x_{0}^{\\gamma_0 } , z_{1 } ) , \\gamma_{1})^2 \\big].\\ ] ] we then define the marginal quantization of @xmath89 by @xmath93 .",
    "this leads us to consider the sequence of marginal quantizations @xmath94 of @xmath95 , defined from the following recursion : @xmath96    from an analytical point of view , this approach raises some new challenging problems among which the estimation of the quadratic error bound @xmath97 , for every @xmath54 .",
    "we will show in particular that for any sequences of ( quadratic ) optimal quantizers @xmath53 for @xmath98 , for every @xmath99 , the quantization error @xmath100 is bounded by the cumulative quantization errors @xmath101 , for @xmath102 .",
    "owing to the non - asymptotic bound for the quantization errors @xmath101 , known as pierce s lemma ( which will be recalled further on ) we precisely show that for every @xmath103 , for any @xmath1040,1]$ ] , @xmath105 where @xmath106 is a positive real constant depending on the indicated parameters .    the paper is organized as follows .",
    "we recall first some basic facts about ( regular ) optimal quantization in section [ secoptiquant ] .",
    "the marginal quantization method is described in section [ sectmq ] .",
    "we give in this section the induced quantization error . in section [ sectioncommarquan ] ,",
    "we illustrate how to get the optimal grids using newton - raphson s algorithm and show how to estimate the associated weights and transition probabilities .",
    "the last section , section [ sectnum ] , is devoted to numerical examples .",
    "we first compare the recursive marginal quantization of @xmath107 with its regular marginal quantization ( see section [ secoptiquant ] ) , where @xmath108}$ ] stands for the brownian motion and show the numerical performance of the marginal quantization method with respect to the regular quantization method .",
    "secondly , we use the marginal quantization method for the pricing of an european put option in a local volatility model ( as well as in the black - scholes model ) and compare the results with those obtained from the monte carlo method .    notations .",
    "we denote by @xmath109 , the set of @xmath110 real value matrices . if @xmath111 \\in { \\cal m}(d , q,\\mathbb r)$ ] , @xmath112 denotes its transpose and we define the norm @xmath113 , where @xmath114 stands for the trace of @xmath115 , for @xmath116 . for every @xmath117",
    ", we will set @xmath118_{\\rm lip}= \\sup_{x\\neq",
    "y}\\frac{\\vert f(x)-f(y ) \\vert}{\\vert x - y \\vert}$ ] . for @xmath119 , @xmath120 .",
    "let @xmath121 be a probability space and let @xmath122 be a random variable with distribution @xmath123 .",
    "the @xmath124-optimal quantization problem at level @xmath125 for the random vector @xmath3 ( or for the distribution @xmath126 ) consists in finding the best approximation of @xmath3 by a borel function @xmath127 of @xmath3 taking at most @xmath125 values . assuming that @xmath128 , we associate to every borel function @xmath127 taking at most @xmath125 values , the @xmath124-mean error @xmath129 measuring the distance between the two random vectors @xmath3 and @xmath127 w.r.t .",
    "the mean @xmath124-norm , where @xmath130 and @xmath131 denotes an arbitrary norm on @xmath132 .",
    "then finding the best approximation of @xmath3 by a borel function of @xmath3 taking at most @xmath125 values turns out to solve the following minimization problem : @xmath133 where @xmath134 stands for the cardinality of @xmath135 , for @xmath136 .",
    "now , let @xmath137 be a codebook of size @xmath125 ( also called an @xmath125-quantizer or a grid of size @xmath125 ) and define a voronoi partition @xmath138 of @xmath132 , which is a borel partition of @xmath139 satisfying for every @xmath140 , @xmath141 consider the voronoi quantization of @xmath3 ( simply called quantization of @xmath3 ) by the @xmath125-quantizer @xmath142 defined by @xmath143 then , for any borel function @xmath144 we have @xmath145 so that the optimal @xmath124-mean quantization error @xmath146 reads @xmath147    recall that for every @xmath148 , the infimum in @xmath149 is attained at least one codebook .",
    "any @xmath125-quantizer realizing this infimum is called an @xmath124-optimal @xmath125-quantizer . moreover , when @xmath150 then any @xmath124-mean optimal @xmath125-quantizer has exactly size @xmath125 ( see @xcite or @xcite ) . on the other hand , the quantization error , @xmath151 ,",
    "decreases to zero as the grid size @xmath125 goes to infinity and its rate of convergence is ruled by the so - called zador theorem recalled below .",
    "there also is a non - asymptotic upper bound for optimal quantizers .",
    "it is called pierce lemma ( we recall it below for the quadratic case ) and will allows us to put a finishing touches to the proof of the main result of the paper , stated in theorem [ theoconvergencerate ] .",
    "\\(a ) ( * zador * , see @xcite ) .",
    "let @xmath3 be an @xmath139-valued random vector such that @xmath152 and let @xmath153 be the lebesgue decomposition of @xmath126 with respect to the lebesgue measure @xmath154 and @xmath155 denotes its singular part .",
    "then @xmath156 with @xmath157 @xmath158^d ) ) \\in ( 0,+\\infty),\\ ] ] where @xmath159^d ) $ ] denotes the uniform distribution over the hypercube @xmath160^d$ ] .",
    "\\(b ) ( * pierce * , see @xcite ) .",
    "let @xmath161 .",
    "there exists a universal constant @xmath162 such that for every random vector @xmath163 , @xmath164 where @xmath165    we will call @xmath166 the zador s constant associated to @xmath3 . from the numerical probability point of view , finding an optimal @xmath125-quantizer @xmath142 may be a challenging task . in practice ( we will only consider the quadratic case , i.e. @xmath167 for numerical implementations ) we are sometimes led to find some `` good '' quantizations @xmath168 which are close to @xmath3 in distribution , so that for every continuous function @xmath169 , we can approximate @xmath170 by @xmath171 where @xmath172 we recall below the stationarity property for a quantizer .",
    "an @xmath125-quantizer @xmath173 inducing the quantization @xmath174 of @xmath3 is stationary if @xmath175 and @xmath176    we define the distortion function by @xmath177 so that @xmath178 by definition , a stationary quantizer @xmath173 is in fact an @xmath125-quantizer satisfying the stationary equality : @xmath179 the following result justifies the interchange of the differentiation and the integral leading to ( [ eqstation ] ) when differentiating ( [ eqdistor ] ) , see @xcite .",
    "[ propdifferentiability ] the function @xmath180 is differentiable at any @xmath125-tuple @xmath181 having pairwise distinct components and such that @xmath182 .",
    "furthermore , we have @xmath183    for numerical implementations , the search of stationary quantizers is based on zero search recursive procedures like newton - raphson algorithm for real valued random variables , and some algorithms like lloyd s i algorithms ( see e.g. @xcite ) , the competitive learning vector quantization ( clvq ) algorithm ( see @xcite ) or stochastic algorithms ( see @xcite ) in the multidimensional framework .",
    "optimal quantization grids associated to multivariate gaussian random vectors can be downloaded on the website www.quantize.math-fi.com .    when approximating @xmath170 by @xmath184 where @xmath142 is an @xmath125-quantizer , the resulting error may be bounded by the squared quantization error @xmath185 , depending on the regularity of the function @xmath27 .",
    "we next recall some error bounds induced from the approximation of @xmath186 by ( [ quantprocedureestim ] ) ( we refer to @xcite for further detail ) .",
    "* let @xmath142 be a stationary quantizer and @xmath27 be a borel function on @xmath139 . if @xmath27 is a convex function then @xmath187 * lipschitz functions : * * if @xmath27 is lipschitz continuous then for any @xmath125-quantizer @xmath142 we have @xmath188_{{\\rm lip } } \\vert x-    \\widehat{x}^{\\gamma } \\vert_{_2},\\ ] ] where @xmath189_{{\\rm lip}}:=",
    "\\sup_{x \\not= y } \\frac{\\vert f(x ) - f(y ) \\vert}{\\vert x - y \\vert}.\\ ] ] * * let @xmath190 be a nonnegative convex function such that @xmath191 .",
    "if @xmath27 is locally lipschitz with at most @xmath192-growth , i.e. @xmath193_{{\\rm lip } } \\vert x - y \\vert ( \\theta(x)+\\theta(y))$ ] then @xmath194 and @xmath195_{{\\rm lip } } \\vert x- \\widehat{x}^{\\gamma } \\vert_{_2 } \\vert \\theta(x ) \\vert_{_2}.\\ ] ] * differentiable functionals : if @xmath27 is differentiable on @xmath139 with an @xmath196-hlder gradient @xmath197 ( @xmath198 $ ] ) , then for any stationary @xmath125-quantizer @xmath142 , @xmath199_{\\alpha } \\vert x-   \\widehat{x}^{\\gamma } \\vert_{_2}^{1+\\alpha}.\\ ] ]",
    "let @xmath200 be a stochastic process taking values in a @xmath201-dimensional euclidean space @xmath139 and solution to the stochastic differential equation : @xmath202 where @xmath13 is a standard @xmath14-dimensional brownian motion starting at @xmath15 and where @xmath16 \\times \\mathbb r^d \\rightarrow   \\mathbb r^d$ ] and the matrix diffusion coefficient function @xmath17 \\times \\mathbb r^d \\rightarrow   { \\cal m}(d , q , \\mathbb r ) $ ] are measurable and satisfy the global lipschitz and linear growth conditions : for every @xmath203 $ ] , @xmath204_{\\rm lip } \\vert   x - y   \\vert     \\label{lipassb } \\\\   &   &   \\vert   \\sigma(t , x ) - \\sigma(t , y)\\vert   \\leq   [ \\sigma]_{\\rm lip } \\vert   x - y   \\vert   \\label{lipasssig }   \\\\    &   & \\vert b(t , x )    \\vert   \\leq l ( 1 + \\vert x \\vert )",
    "\\   \\textrm {   and   } \\",
    "\\vert \\sigma(t , x )    \\vert   \\leq   l   ( 1 + \\vert x \\vert ) .",
    "\\label{eqlingrowth } \\ ] ] @xmath205 .",
    "this guarantees the existence of a strong solution of ( [ eqsignalprocess ] ) .",
    "we also suppose that the matrix @xmath28 is positive definite . throughout the paper",
    "we will suppose that @xmath139 is equipped with the canonical euclidean norm .",
    "consider the euler scheme of the process @xmath200 starting from @xmath206 : @xmath207 where @xmath208 , for every @xmath209 .",
    "notations simplification . to alleviate notations",
    ", we set @xmath210    recall that the distortion function @xmath211 associated to @xmath212 may be wriiten for every @xmath213 , as @xmath214   \\label { eqdistornonquant}\\ ] ] where @xmath215 now , supposing that @xmath216 has already been quantized and setting @xmath217 , we may approximate the distortion function @xmath218 by @xmath219 \\\\    & = & \\mathbb e \\big [    d({\\cal e}_0(\\widehat x_0^{\\gamma_0 } , z_{1 } ) , \\gamma_{1})^2 \\big ] \\\\     &   = &   \\sum_{i=1}^{n_{0 } }   \\mathbb e \\big [    d({\\cal e}_0(x_i^{0},z_{1 } ) , \\gamma_{1})^2 \\big ] \\mathbb p\\big(\\widehat x_0^{\\gamma_0 } = x_i^{0 } \\big ) .",
    "\\end{aligned}\\ ] ]    this allows us ( as it is already said in the introduction ) to consider the sequence of ( marginal ) quantizations @xmath220 defined from the following recursion : @xmath221      our aim is now to compute the quantization error bound @xmath222 .",
    "the analysis of this error bound will be the subject of the following theorem , which is the main result of the paper .",
    "keep in mind that @xmath223 .",
    "[ theoconvergencerate ] let the coefficients @xmath224 , @xmath28 satisfy the assumptions , and .",
    "let for every @xmath23 , @xmath53 be a quadratic optimal quantizer for @xmath225 at level @xmath43 .",
    "then , for every @xmath103 , for any @xmath1040,1]$ ] , @xmath226 where for every @xmath227 $ ] , @xmath228^{\\frac{1}{p}},\\ ] ] with @xmath229_{\\rm lip } + \\frac{1}{2 } [ \\sigma]_{\\rm lip}^2 $ ] , @xmath162 is a universal constant defined in equation and given in @xcite ; @xmath230    let us make the following remarks .",
    "it is important to notice that the constants @xmath231 do not explode when @xmath33 goes to infinity and we have @xmath232^{\\frac{1}{p}}.\\ ] ] we also remark that @xmath233 .    before dealing with the proof of the theorem",
    ", we give below a lemma which will be used to complete the proof of the theorem .",
    "the proof of the lemma is postponed to the appendix .",
    "[ propprinc ] let the coefficients @xmath224 , @xmath28 of the diffusion satisfy the assumptions and . then , for every @xmath227 $ ] , for every @xmath54 , @xmath234 where @xmath235 and @xmath236 are defined in theorem [ theoconvergencerate ] .    let us prove the theorem .",
    "first we note that for every @xmath23 , @xmath237 let us control the first term of the right hand side of the above equation . to this end",
    ", we first note that , for every @xmath54 , the function @xmath238 is lipschitz w.r.t .",
    "the @xmath239-norm : in fact , for every @xmath240 , @xmath241_{\\rm lip } + [ \\sigma_k(.)]^2_{\\rm lip } \\big)+ \\delta^2   [ b_k(.)]_{\\rm lip}^2   \\big ) \\vert x - x ' \\vert^2 \\\\     & \\le & \\big(1 + \\delta \\big(2[b]_{\\rm lip } + [ \\sigma]^2_{\\rm lip } \\big)+ \\delta^2   [ b]_{\\rm lip}^2",
    "\\big ) \\vert x - x ' \\vert ^2\\\\     & \\le & ( 1+\\delta c_{b,\\sigma})^2 \\vert x - x ' \\vert^2\\\\     & \\le & e^ { 2 \\delta c_{b,\\sigma } } \\vert x - x ' \\vert^2 ,      \\end{aligned}\\ ] ] where @xmath242_{\\rm lip } + \\frac{1}{2 } [ \\sigma]_{\\rm lip}^2 $ ] does not depend on @xmath33 .",
    "then , it follows that for every @xmath243 , @xmath244 then , we show by a backward induction using and that @xmath245 now , one deduces from lemma [ lempierce ] and then , from lemma [ propprinc ] that , for every @xmath103 , for any @xmath161 @xmath246 which is the announced result .",
    "[ remchoicegridsizes ] @xmath247 when we consider the upper bound of equation , a natural question is to determine how to dispatch optimally the sizes @xmath248 ( for a fixed mesh of length @xmath33 ) of the quantization grids when we wish to use a total `` budget '' @xmath249 of elementary quantizers ( with @xmath250 , for every @xmath54 ) .",
    "this amounts to solving the minimization problem @xmath251 where @xmath252 .",
    "this leads ( see e.g.  @xcite ) to the following optimal dispatching : @xmath253 ( since @xmath58 is not random ) and for every @xmath254 , @xmath255 so that equation becomes ( for @xmath256 ) @xmath257 and using the convexity inequality leads to @xmath258    @xmath259 if we assign @xmath260 points to each grid @xmath53 , the error bound in theorem [ theoconvergencerate ] leads to @xmath261",
    "we focus now on the numerical computation of the quadratic optimal quantizers of the marginal random variable @xmath262 given the probability distribution function of @xmath263 . such a task requires the use of some algorithms like the clvq algorithm , lloyd s algorithms ( both requiring the computation of the gradient of the distortion function ) or newton - raphson s algorithm ( especially for the one - dimensional setting ) which involves the gradient and the hessian matrix of the distortion ( we refer to @xcite for more details ) .",
    "let @xmath264 be the quantization of @xmath225 induced y the grid @xmath53 and let @xmath265 be the associated distortion function , for @xmath23 .",
    "our aim is to compute the ( at least locally ) optimal quadratic quantization grids @xmath266 associated with the @xmath225 s , @xmath23 .",
    "such a sequence of grids @xmath267 is defined for every @xmath23 by @xmath268 recall that the sequence of ( marginal ) quantizations @xmath269 is defined by the following induction : @xmath270 supposing that @xmath225 has already been quantized , we have for every @xmath271 , @xmath272 \\\\    &   = &   \\sum_{i=1}^{n_{k } }   \\mathbb e \\big [    d({\\cal e}_k(x_i^{n_k},z_{k+1 } ) , \\gamma_{k+1})^2 \\big ] \\mathbb p(\\widehat x_k = x_i^{n_k } ) .    \\end{aligned}\\ ] ] then , owing to proposition [ propdifferentiability ] , the distortion function @xmath273 is continuously differentiable as a function of the @xmath274-quantizer @xmath275 ( having pairwise distinct components ) and its gradient is given by @xmath276_{j=1,\\cdots , n_{k+1}}.\\ ] ]    @xmath277 if @xmath275 is a quadratic optimal @xmath274-quantizer for @xmath278 and if @xmath279 denotes the quantization of @xmath278 on the grid @xmath275 .",
    "then @xmath275 is a stationary quantizer , @xmath280 , @xmath281 equivalently , we have for every @xmath282 , @xmath283 this also means that @xmath284    @xmath285 in higher dimension @xmath286 , equations ( [ eqstation ] ) and ( [ eqlloyd ] ) allow us to compute stationary quantizers for @xmath278 using stochastic algorithms and lloyd s type algorithms , given that @xmath287 has already been quantized .",
    "as mentioned in @xcite , the usual clvq or lloyd s companion algorithms become quickly untractable when the dimension @xmath286 due to the fact that we have to compute @xmath201-dimension integrals on voronoi cells .",
    "moreover , in our setting the complexity of these algorithms will increase since we have to compute additional @xmath201-dimensional integrals .",
    "for these reasons , we will restrict our analysis to the one - dimensional setting where we will use the newton - raphson algorithm in @xmath288 to perform recursively quadratic optimal quantizers of the marginals @xmath287 given the distribution of @xmath58 .      for @xmath289 ,",
    "let @xmath290 and @xmath291 denote respectively the gradient vector and the hessian matrix of the distortion function @xmath292 . to simplify notations set , for @xmath47 and for @xmath293 , @xmath294 and",
    "let @xmath295 where @xmath296 and @xmath297 .",
    "we also denote by @xmath298 and @xmath299 the probability distribution function and the cumulative distribution function , respectively , of the standard gaussian distribution .",
    "our procedure is recursive and we suppose that @xmath53 ( quantizer for @xmath287 ) has been computed as well as the companion weights : @xmath300 .",
    "therefore , using the newton - raphson zero search , a zero of the gradient can be computed via the following recursive procedure starting from a given initial point @xmath301 : @xmath302 where the components of @xmath303 are given for every @xmath304 , @xmath305 ( where @xmath306 is the number of iterations of the newton - raphson procedure ) , and for every @xmath293 , by @xmath307 the diagonal terms of the hessian matrix @xmath308 are given by : @xmath309 \\mathbb p(\\widetilde x_{k } \\in c_i ( \\gamma_{k}))\\end{aligned}\\ ] ] and its sub - diagonal terms are @xmath310 the super - diagonals terms are @xmath311 a similar idea combining ( vector or functional ) optimal quantization with newton - raphson zero search procedure is used in @xcite in a variance reduction context as an alternative and robust method to simulation based recursive importance sampling procedure to estimate the optimal change of measure .",
    "furthermore , the convergence of the modified newton - raphson algorithm to the optimal quantizer is shown in the framework of @xcite to be bounded by the quantization error .",
    "however , the tools used to show it does not apply directly to our context and the proof of the convergence of our modified newton algorithm to an optimal quantizer is an open question .",
    "once we have access to the quadratic optimal quantizers @xmath312 of the marginals @xmath287 , for @xmath20 ( which are estimated using the newton - raphson algorithm described previously ) we need to compute the associated weights @xmath313 , @xmath314 , for @xmath23 or the transition probabilities @xmath315 , @xmath316 , @xmath317 .",
    "we show in the next result how to compute them .",
    "let @xmath275 be a quadratic optimal quantizer for the marginal random variable @xmath278 .",
    "suppose that the quadratic optimal quantizer @xmath53 for @xmath287 and its companion weights @xmath318 , @xmath45 , are computed .    1 .   the transition probability @xmath319 is given by @xmath320 2 .   the probability @xmath321 is given for every @xmath293 by @xmath322    [ * proof . * ] 1",
    "for every @xmath323 , for every @xmath324 and for every @xmath293 , we have @xmath325    \\2 .",
    "we have for every @xmath323 and for every @xmath293 , @xmath326   \\\\   & = &     \\sum_{i=1}^{n_{k } } \\mathbb p \\big(\\widetilde x_{k+1 } \\in c_{j}(\\gamma_{k+1 } )    \\vert \\widehat   x_{k } =   x_i^{n_{k } } \\big )   \\mathbb p(\\widetilde x_k \\in c_i(\\gamma_k ) ) .",
    "\\end{aligned}\\ ] ] now , il follows from the first assertion that @xmath327 this completes the proof .",
    "we consider a real valued brownian motion @xmath108}$ ] and quantize the random variable @xmath107 by both regular marginal quantization and recursive marginal quantization methods . denote by @xmath328 the regular quantization distortion associated to @xmath107 and @xmath329 , @xmath103 , the sequence of distortions associated to the @xmath330 s , @xmath54 , where @xmath33 is the mesh size and @xmath331 is a grid of size @xmath43 .",
    "we recall that for a given grid size @xmath115 , the optimal grid for the regular marginal quantization is obtained by solving ( using newton - raphson algorithm ) the following minimization problem : @xmath332 which corresponds to the optimal grid of the standard gaussian distribution . on the other hand , the sequence of recursive marginal quantization grids @xmath267 are defined for every @xmath23 by @xmath333 where @xmath334 & = & \\mathbb e \\big [    d \\big(\\widehat w_{t_{k-1}}^{\\gamma_{k-1 } } + \\sqrt{\\delta } z_{k } , \\gamma \\big)^2 \\big ] \\\\    &   = &   \\sum_{i=1}^{n_{k-1 } }   \\mathbb e \\big [    d \\big(w_i^{k-1 } + \\sqrt{\\delta } z_{k } , \\gamma \\big)^2 \\big ] \\mathbb p\\big(\\widehat w_{t_{k-1}}^{\\gamma_{k-1 } } = w_i^{k-1 } \\big )   \\end{aligned}\\ ] ] and @xmath335 is defined from the following recursion : @xmath336 and for @xmath337 , @xmath338    we make a comparison of the quantization errors ( the square root of the distortions ) obtained from both methods .",
    "the result is depicted in figure [ figcompregmar ] . in these graphics",
    "we fix the mesh size @xmath339 and we make the total budget @xmath340 ( given that @xmath253 ) of the grid sizes vary @xmath341 by @xmath341 , from @xmath342 up to @xmath343 . we choose the sizes",
    "@xmath43 following two procedures : without ( and with ) optimal dispatching , and for both procedures we compare the associated quantization errors with the regular marginal quantization error . in concrete terms , here is how we choose the grid sizes @xmath43 .",
    "@xmath344 without optimal dispatching . for a given global budget @xmath125",
    ", we make an `` equal grid size dispatching '' by choosing @xmath345 , for @xmath346 . if for example @xmath347 , we will have @xmath348 , for every @xmath349 . on the right hand side graphic of figure [ figcompregmar ]",
    ", we depict the marginal quantization errors @xmath350 , for @xmath351 , and the regular quantization errors @xmath352 , for @xmath353 .",
    "@xmath344 with optimal dispatching . in this case",
    ", the sizes @xmath43 are obtained from the optimal dispatching procedure described in remark [ remchoicegridsizes ] .",
    "first of all , we have to choose the coefficients @xmath354 ( appearing in theorem [ theoconvergencerate ] ) corresponding to the brownian motion . following , step by step , the proof of theorem [ theoconvergencerate ] and setting @xmath355 ( keep in mind that in the brownian case @xmath356 ) , we may choose for @xmath357 , @xmath358^{1/3}.\\ ] ] making @xmath125 vary from @xmath342 to @xmath343 , the optimal dispatching leads to the following sizes for the grid @xmath359 : @xmath360 this means for example that , if @xmath361 , then the grids @xmath53 , for @xmath362 , are not of equal size and @xmath363 ; if @xmath364 then @xmath365 ; @xmath366 ; and if @xmath367 then @xmath368 .",
    "the graphic on the left hand side of figure [ figcompregmar ] depicts the marginal quantization errors @xmath350 , where @xmath369 is given by the optimal dispatching procedure , and the regular quantization errors @xmath352 for @xmath370 .     with its recursive marginal quantization ( mq ) ( where @xmath13 is a brownian motion ) .",
    "abscissa axis : @xmath339 and the total budget @xmath371 varies from @xmath342 up to @xmath343 .",
    "ordinate axis : for a given @xmath125 , @xmath247 ( right hand side graphics ) we set @xmath345 , for @xmath346 and depict the mq errors @xmath350 , for @xmath351 , and the rq errors @xmath352 , for @xmath353 ; @xmath259 ( left hand side graphic ) we depict the mq errors @xmath350 where @xmath369 is given by the optimal dispatching procedure , and the rq errors @xmath352 for @xmath372 .",
    ", title=\"fig:\",width=321,height=264 ]   with its recursive marginal quantization ( mq ) ( where @xmath13 is a brownian motion ) .",
    "abscissa axis : @xmath339 and the total budget @xmath371 varies from @xmath342 up to @xmath343 .",
    "ordinate axis : for a given @xmath125 , @xmath247 ( right hand side graphics ) we set @xmath345 , for @xmath346 and depict the mq errors @xmath350 , for @xmath351 , and the rq errors @xmath352 , for @xmath353 ; @xmath259 ( left hand side graphic ) we depict the mq errors @xmath350 where @xmath369 is given by the optimal dispatching procedure , and the rq errors @xmath352 for @xmath372 . , title=\"fig:\",width=321,height=264 ]     and the total grid sizes @xmath371 varies from @xmath342 up to @xmath343 .",
    "ordinate axis : on one hand , we set @xmath345 , for @xmath346 and depict the recursive marginal quantization errors @xmath350 , for @xmath351 ( mq without optimal dispatching ) , and , on the other hand , we depict the marginal quantization errors @xmath350 where @xmath369 is given by the optimal dispatching procedure ( mq with optimal dispatching).,width=434,height=302 ]    conclusion",
    ". the graphics of figure [ figcompregmar ] and [ figcompmq ] lead to two observations .",
    "the first one is that both recursive marginal quantization ( without and with optimal dispatching ) of @xmath107 are more efficient than its regular marginal quantization , especially when the regular quantization grid is of small size .",
    "in fact , in the general setting , the search for the optimal grids associated to the marginals of a stochastic process is based on the computation of the gradient ( and the hessian ) of the associated distortion function , which are some expectation with respect to these marginal random variables .",
    "since the recursive marginal quantization procedure is based on successive conditionings which are known to reduce the variance , it is not surprising to observe that the recursive marginal quantization method is more successful than the regular marginal quantization method .",
    "the second conclusion is that the recursive marginal quantization method with the optimal dispatching of the grid size over discretization time steps outperform a setting where the grids are of equal sizes , especially , when the global budget @xmath373 is small .",
    "however , when @xmath125 increases , the recursive marginal quantization with optimal dispatching becomes more time consuming and at the same time , both methods lead to almost the same results .",
    "in fact , the following heuristic suggests that , in the general setting , the complexity of the recursive marginal quantization method with optimal dispatching is greater than the one with equal size allocation .",
    "practitioner s corner .",
    "notice that the complexity of the quantization tree @xmath374 for the recursive marginal quantization is of order @xmath375 .",
    "now , assuming that @xmath253 and that for every @xmath47 , @xmath376 we want to solve ( heuristically ) the problem @xmath377 since @xmath378 and that @xmath379 , this suggests that @xmath380 . then",
    ", if we switch to @xmath381 where @xmath382 , it is well known that the solution of the previous problem is given by @xmath383 , @xmath280 , @xmath345 , for every @xmath384 . plugging the solution of in ,",
    "this leads to the sub - optimal complexity @xmath385 .",
    "in fact , any other choice leads to the global complexity @xmath386 0.5 cm    in the next section we propose an application of our method to the pricing of european options in a local volatility models .",
    "we remark that when using the marginal quantization methods , we have to choose a big global budget @xmath125 to reach good price estimates . as in the brownian case ,",
    "numerical results show that both recursive marginal quantization methods ( with and without optimal dispatching ) lead to the same price estimates ( up to @xmath387 ) whereas the complexity of the optimal dispatching method becomes higher ( as pointed out in the practitioner s corner ) .",
    "this is why we will use in the following section the recursive marginal quantization method without optimal dispatching procedure .",
    "we consider a pseudo - cev model ( see e.g. @xcite ) where the dynamics of the stock price process is ruled by the following sde ( under the risk neutral probability ) @xmath388 for some @xmath60 and @xmath61 $ ] with @xmath62 .",
    "the parameter @xmath63 stands for the interest rate and @xmath389 corresponds to the local volatility function .",
    "this model becomes very close to the cev model , specially when the initial value of the stock process @xmath58 is large enough . in this case the local volatility @xmath390 .",
    "0.3 cm    l*5l & & & & + & @xmath391 & mc ( @xmath392 ) & mc ( @xmath393 ) &   rmq + & & & & & + & @xmath394 &   @xmath395 & @xmath396 & @xmath397 + ci & & @xmath398 } $ ] & @xmath399 } $ ] & + & @xmath400 &   @xmath401 & @xmath402 &   @xmath403 + ci & & @xmath404 } $ ] & @xmath405 } $ ] & + & @xmath406 &  @xmath407 & @xmath408 &   @xmath409 + ci & & @xmath410 } $ ] & @xmath411 } $ ] & + & @xmath412 &   @xmath413 & @xmath414 &  @xmath415 + ci & & @xmath416 } $ ] &   @xmath417 } $ ] & + & @xmath418 &   @xmath419 & @xmath420 &   @xmath421 + ci & & @xmath422 } $ ] &   @xmath423 } $ ] & + & @xmath424 & @xmath425 &    @xmath426 & @xmath427 + ci & &    @xmath428 } $ ] &   @xmath429 } $ ] & + & @xmath430 & @xmath431 &    @xmath432 & @xmath433 + ci & &   @xmath434 } $ ] &   @xmath435 } $ ] & + & @xmath436 & @xmath437 &   @xmath438 & @xmath439 + ci & &    @xmath440 } $ ] &   @xmath441 } $ ] & + & @xmath442 & @xmath443 &    @xmath444 & @xmath445 + ci & &   @xmath446 } $ ] &   @xmath447 } $ ] & + & & & & +    0.3 cm    l*6l & @xmath57 &   mc ( @xmath392 ) &   mc ( @xmath393 ) &   mc ( @xmath448 ) &   rmq + & & & & & + & @xmath449 & @xmath450 &   @xmath451 &   @xmath451 & @xmath451 + ci & &  @xmath452 } $ ] &   @xmath453 } $ ] &   @xmath454 } $ ] & + & @xmath455 & @xmath456 &  @xmath457 &   @xmath458 & @xmath458 + ci & &   @xmath459 } $ ] &    @xmath460 } $ ] &   @xmath461 } $ ] & + & @xmath462 & @xmath463 &   @xmath464 &   @xmath464 & @xmath464 + ci & &  @xmath465 } $ ] &   @xmath466 } $ ] &   @xmath467 } $ ] & + & @xmath468 & @xmath469 &   @xmath470 &    @xmath471 & @xmath472 + ci & &  @xmath473 } $ ] &   @xmath474 } $ ] &   @xmath475 } $ ] & + & @xmath476 & @xmath477 &   @xmath478 &   @xmath479 & @xmath480 + ci & &   @xmath481 } $ ] &   @xmath482 } $ ] &   @xmath483 } $ ] & + & @xmath484 & @xmath485 &   @xmath486 &   @xmath487 & @xmath488 + ci & &   @xmath489 } $ ] &    @xmath490 } $ ] &    @xmath491 } $ ] & + & @xmath492 & @xmath493 &    @xmath494 &    @xmath495 & @xmath496 + ci & &   @xmath497 } $ ] &    @xmath498 } $ ] &    @xmath499 } $ ] & + & & & & & +    we aim at computing the price of a european put option with payoff @xmath500 , where @xmath57 corresponds to the strike of the option and @xmath56 to its maturity",
    ". then we have to approximate the quantity @xmath501 where @xmath502 stands for the expectation under the risk neutral probability .",
    "if the process @xmath41 denotes the discrete euler process at regular time discretization steps @xmath0 , with @xmath503 , associated to the diffusion process @xmath200 , this turns out to estimate @xmath504 by optimal quantization .",
    "we estimate this quantity by the recursive marginal quantization method introduced in this paper and compare the numerical results with those obtained from standard monte carlo simulations .      to deal with numerical examples we set @xmath505 , @xmath506 , and choose the interest rate @xmath507 .",
    "we discretize the price process using the euler scheme with @xmath508 ( regular ) discretization steps and quantize the euler marginal processes by our proposed method .",
    "we put all the marginal quantization grid sizes @xmath43 equals to @xmath509 except for @xmath510 which grid size is @xmath253 .",
    "we estimate the price of the put option by @xmath511 = \\sum_{i=1}^{n_n } ( k- x_i^{n_n})^{+ } \\ , \\mathbb p \\big(\\widehat x_{t_n}^{\\gamma_n } = x_i^{n_n } \\big)\\ ] ] where @xmath512 , and where @xmath513 is the quantizer of size @xmath514 computed from the newton - raphson algorithm ( with @xmath515 iterations ) and where the associated weight are estimated from ( [ eqestproba ] ) .",
    "we compare the prices obtained from the recursive marginal quantization ( rmq ) method with those obtained by the monte carlo ( mc ) simulations even for various values of @xmath391 with a fixed strike @xmath516 ( see table [ tabprixputlv ] ) or for varying values of the strike @xmath57 with a fixed @xmath517 ( see table [ tabprixputlvstrike ] ) . for the monte carlo simulations we set the sample size @xmath518 equal to @xmath519 and @xmath520 for @xmath516 and to @xmath521 , @xmath520 and @xmath522 when making the strike @xmath57 varying .",
    "( _ on the computation time _ ) @xmath523 remark that all the quantization grids @xmath53 of sizes @xmath524 , for every @xmath525 , and there companion weights are obtained in around @xmath526 minute from the newton - raphson algorithm with @xmath515 iterations .",
    "computations are performed using _ scilab _ software on a cpu @xmath527 ghz and 4 go memory computer .",
    "@xmath259 it is clear that once the grids and the associated weights are available , the estimation of the price by rmq method using the sum ( [ eqsummq ] ) is instantaneous ( compared to a monte carlo simulation ) .",
    "( _ initialization of the newton - raphson algorithm _ )",
    "let @xmath528 be the time discretization steps , let @xmath529 be the present value of the stock price process and suppose that the grid sizes @xmath43 are all equal . since the random variable @xmath530 , in order to compute the ( optimal ) @xmath531-quantizer for @xmath89 we initialize the algorithm to @xmath532 , where @xmath533 is the optimal @xmath531-quantizer of the @xmath534 .",
    "once we get the optimal @xmath531-quantization @xmath535 for @xmath89 and its companion weights , we initialize the algorithm to @xmath535 to perform the optimal @xmath536-quantizer for @xmath537 and its companion weights , @xmath366 , and so on , until we get the optimal @xmath514-quantizer for @xmath538 and the associated weights .",
    "notice that doing",
    "so we observe no failure of the convergence in all the considered examples .",
    "we show in figure [ figure1 ] and figure [ figure2 ] two graphics where we depict on the abscissa axis the optimal grids ( of sizes @xmath539 ) and on the ordinate axis the corresponding weights .",
    "the dynamics of the price process in figure [ figure1 ] is given by @xmath540 with @xmath541 , @xmath542 whereas its dynamics in figure [ figure2 ] is given by @xmath543 with @xmath507 , @xmath544 , @xmath545 .",
    "for our numerical examples , we remark first that in all examples the prices obtained by rmq stay in the confidence interval induced by the mc price estimates . on the other hand the prices obtained by the rmq method are more precise ( more especially when @xmath546 and @xmath57 grows away from @xmath449 ) than those obtained by the mc method when @xmath547 or @xmath520 .",
    "consequently , the rmq method seems to be more efficient than the mc when the sample size is less than @xmath520 .",
    "however , when increasing the sample size to @xmath548 the two prices become closer ( up to @xmath549 ) .",
    "we remark that when the monte carlo sample sample size @xmath548 it takes about @xmath550 minutes and @xmath551 seconds to get a price using the _ c programming language _ on the same computer described previously .",
    "then , in this situation , it takes much more time to obtain a price by mc method than by rmq .    to strengthen the previous conclusions related to the local volatility model we compare the two methods in the black - scholes framework where the stock price process evolves following the dynamics : @xmath552 in this setting the true prices are available and will serve us as a support for comparisons .",
    "the parameters are chosen so that the model remains close to the pseudo - cev model : @xmath507 and @xmath553 .",
    "numerical results are printed in tables [ tabprixputbs ] and table [ tabprixputbsstrike ] and confirm our conclusions on the pseudo - cev model .",
    "we notice that in the black - scholes model , the estimated prices from the rmq method are close to the true prices ( the best absolute error is of order @xmath554 for a volatility @xmath555 and the worse absolute error @xmath556 is achieved with high volatility : @xmath557 ) .",
    "this shows the robustness of the rmq method even for reasonably high values of the volatility .",
    "0.3 cm    l*7l & & & & & & + & @xmath28 & mc ( @xmath392 ) & mc ( @xmath393 ) &   rmq &  true price & abs .",
    "error + & & & & & & & + & @xmath558 &   @xmath559 &  @xmath560 & @xmath561 & @xmath562 & @xmath563 + ci & & @xmath564 } $ ] & @xmath399 } $ ] & & & + & @xmath565 &   @xmath566 & @xmath567 &   @xmath568 &  @xmath569 & @xmath570 + ci & & @xmath571 } $ ] & @xmath572 } $ ] & & & + & @xmath573 &  @xmath574 & @xmath409 &   @xmath575 &  @xmath408 & @xmath576 + ci & & @xmath577 } $ ] & @xmath578 } $ ] & & & + & @xmath579 &   @xmath580 & @xmath414 &  @xmath581 &  @xmath582 & @xmath583 + ci & & @xmath584 } $ ] & @xmath585 } $ ] & & & + & @xmath586 &   @xmath587 & @xmath588 &   @xmath589 &  @xmath590 & @xmath591 + ci & & @xmath592 } $ ] & @xmath593 } $ ] & & & + & @xmath594 & @xmath595 &    @xmath426 & @xmath427 & @xmath596 & @xmath597 + ci & &   @xmath598 } $ ] &   @xmath599 } $ ] & & & + & @xmath600 & @xmath601 &    @xmath602 & @xmath603 & @xmath604 & @xmath605 + ci & &   @xmath606 } $ ] &   @xmath607 } $ ] & & & + & @xmath608 & @xmath609 &   @xmath610 & @xmath611 & @xmath612 & @xmath613 + ci & &   @xmath614 } $ ] &   @xmath615 } $ ] & & & + & @xmath616 & @xmath617 &    @xmath618 & @xmath619 & @xmath620 & @xmath621 + ci & &   @xmath622 } $ ] &   @xmath623 } $ ] & & & + & & & & & & +    0.3 cm    l*7l & @xmath57 &   mc ( @xmath392 ) &   mc ( @xmath393 ) &   rmq &  true price & abs .",
    "error + & & & & & & & + & @xmath449 & @xmath617 &    @xmath618 & @xmath624 & @xmath620 & @xmath625 + ci & &   @xmath622 } $ ] &   @xmath623 } $ ] & & & + & @xmath455 &   @xmath626 &  @xmath627 &   @xmath628 &  @xmath629 & @xmath630 + ci & &   @xmath631 } $ ] &  @xmath632 } $ ] & & & + & @xmath462 & @xmath633 &   @xmath634 & @xmath635 & @xmath636 & @xmath637 + ci & &  @xmath638 } $ ] &   @xmath639 } $ ] & & & + & @xmath468 & @xmath640 &   @xmath641 & @xmath642 & @xmath643 & @xmath644 + ci & &  @xmath645 } $ ] &   @xmath646 } $ ] & & & + & @xmath476 & @xmath647 &   @xmath648 & @xmath649 & @xmath648 & @xmath637 + ci & &   @xmath650 } $ ] &   @xmath651 } $ ] & & & + & @xmath484 & @xmath652 &   @xmath653 & @xmath654 & @xmath655 & @xmath637 + ci & &   @xmath656 } $ ] &    @xmath657 } $ ] & & & + & @xmath492 & @xmath658 &    @xmath659 & @xmath660 & @xmath661 & @xmath662 + ci & &   @xmath663 } $ ] &    @xmath664 } $ ] & & & + & & & & & & +    , @xmath665 , @xmath541 , @xmath542 .",
    "abscissa axis : the optimal grids , @xmath666 , @xmath667 , @xmath668 , @xmath669 , @xmath45 .",
    "ordinate axis : the associated weights , @xmath670 , @xmath669 , @xmath671 .",
    "@xmath672 is depicted in dots @xmath673 , @xmath674 is represented by the symbol ** , @xmath675 and @xmath676 and the remaining in continuous line , width=548,height=340 ]    , @xmath677 , @xmath507 , @xmath678 , @xmath505 .",
    "abscissa axis : the optimal grids , @xmath666 , @xmath667 , @xmath668 , @xmath669 , @xmath45 .",
    "ordinate axis : the associated weights .",
    "@xmath672 is depicted in dots @xmath673 , @xmath674 is represented by the symbol ** ,",
    "@xmath675 and @xmath676 and the remaining in continuous line.,width=548,height=340 ]",
    "the proof of lemma [ propprinc ] needs a additional result we give below as a lemma .",
    "0.3 cm        define the function @xmath682 , @xmath683 .",
    "we have ( denoting by @xmath684 the transpose of the the row vector @xmath685 ) , @xmath686 it follows from taylor - lagrange formula that @xmath687 where @xmath688 stands for the inner product and where @xmath689 , @xmath690 $ ] .",
    "however , owing to cauchy - schwarz inequality we have @xmath691 so that @xmath692 then , the result follows since @xmath693 ( because @xmath694 $ ] ) and @xmath695 .",
    "let @xmath135 be a @xmath696-matrix .",
    "we prove that for any random variable @xmath697 such that @xmath698 and @xmath699 @xmath700 where @xmath701 .",
    "in fact , it follows from equation that @xmath702 applying young s inequality with conjugate exponents @xmath703 and @xmath704 , we get @xmath705 which leads to @xmath706 taking the expectation yields ( owing to the fact that @xmath707 ) @xmath708 as a consequence , we get @xmath709    step 2 . keeping in mind the result of the first step and setting for every @xmath710 $ ] and @xmath711 , @xmath712 and @xmath713 , we get ( owing to the linear growth assumption on the coefficients of the diffusion process ) @xmath714 where @xmath715 .",
    "it follows that ( keep in mind that @xmath716 $ ] ) @xmath717 then , we derive @xmath718 using the inequality @xmath719 , for every @xmath720 , we finally get @xmath721 where @xmath722 and @xmath723 .",
    "now , owing to the previous step and to the fact that for every @xmath384 , @xmath724 is independent from @xmath725 , we have @xmath726 \\\\   & \\le & \\big ( e^ { \\kappa_p \\delta }   + k_p \\delta",
    "\\big )   \\mathbb e   \\vert \\widehat x_{k-1 } \\vert^p   +   \\big (   e^{\\kappa_p   \\delta } l + k_p \\big ) \\delta .",
    "\\end{aligned}\\ ] ] since by construction , @xmath727 is a stationary quantizer ( with respect to @xmath287 ) for every @xmath23 , we get @xmath728 we show by induction that for every @xmath346 , @xmath729 using the inequality @xmath730 , for every @xmath720 , yields @xmath731 the last inequality follows from the fact that @xmath732 .",
    "m. corsi , h. pham and w. runggaldier .",
    "numerical approximation by quantization of control problems in finance under partial observations .",
    "_ mathematical modeling and numerical methods in finance , special volume of handbook of numerical analysis _ , 2009 .",
    "h. pham , w. runggaldier and a. sellami .",
    "approximation by quantization of the filter process and applications to optimal stopping problems under partial observation .",
    "_ monte carlo methods and applications _ , 11 , 57 - 82 , 2005 ."
  ],
  "abstract_text": [
    "<S> we propose a new approach to quantize the marginals of the discrete euler diffusion process . </S>",
    "<S> the method is built recursively and involes the conditional distribution of the marginals of the discrete euler process . </S>",
    "<S> analytically , the method raises several questions like the analysis of the induced quadratic quantization error between the marginals of the euler process and the proposed quantizations . </S>",
    "<S> we show in particular that at every discretization step @xmath0 of the euler scheme , this error is bounded by the cumulative quantization errors induced by the euler operator , from times @xmath1 to time @xmath0 . for numerics , </S>",
    "<S> we restrict our analysis to the one dimensional setting and show how to compute the optimal grids using a newton - raphson algorithm . </S>",
    "<S> we then propose a close formula for the companion weights and the transition probabilities associated to the proposed quantizations . </S>",
    "<S> this allows us to quantize in particular diffusion processes in local volatility models by reducing dramatically the computational complexity of the search of optimal quantizers while increasing their computational precision with respect to the algorithms commonly proposed in this framework . </S>",
    "<S> numerical tests are carried out for the brownian motion and for the pricing of european options in a local volatility model . </S>",
    "<S> a comparison with the monte carlo simulations shows that the proposed method is more efficient ( w.r.t . both computational precision and time complexity ) than the monte carlo method . </S>"
  ]
}