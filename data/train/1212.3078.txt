{
  "article_text": [
    "neurons in neural networks interact by synaptic connections . these complex networks ,",
    "even if they consist of the integrated - and - fire models or the extended models , are very complicated to deal with directly . up to now",
    ", many studies of the neural networks treat the inputs from another neuron as a stochastic process  @xcite .",
    "because the stochastic process under random noises ( namely langevin forces ) is well studied  @xcite , the behavior of a neuron s membrane potential is well analyzed using the fokker - planck equation  @xcite as an ornstein - uhlenbeck process  @xcite . essentially , however , these stochastic input models approximate the network as a single neuron model  @xcite .",
    "thus , it is difficult ( but not impossible  @xcite ) to introduce synaptic connections appropriately into the distribution functions of random inputs .",
    "recently , chen and jasnow  @xcite introduced the mean field theory to study the synaptic plasticity . in this theory",
    "we need to introduce the `` effective input '' as a mean value of inputs to a population of several neurons , namely cluster neurons , from outside of the cluster neurons .",
    "especially , they @xcite have focused this virtue of the mean field theory on the behavior of neural networks driven by poisson noises with fixed mean frequency for all neurons . and",
    "they have clarified the relation between the mean firing frequency ( or the mean firing rate ) and the mean synaptic weight using the self - consistent condition obtained from the mean field theory@xcite .",
    "because the mean field theory can reduce many synaptic connections to one connection , it enables us to analyze the effects of many synaptic connections in neural networks with ease . when there are a lot of neurons with connections and the input trains are stationary , it is reasonable to apply the mean - field theory to this system@xcite .",
    "however , the mean field theory is not applicable when the variance of the values is so large and/or the population size of the variables ( synaptic connections per neuron , for example ) are so small that the mean value can not be regarded as representative . in addition ,",
    "when we focus on the synchronized firings , its stability can not be discussed from the view point of this mean - field theory , because we do not take into account the transient to the steady state .",
    "this is one of the limitations of the method .",
    "biologically , accompanied with visual perception or motor control , coherent oscillations have been reported in the cortices  @xcite .",
    "the oscillations are thought to play an important role in the information processing in the cortices  @xcite .",
    "for example , precise synchronization among cortical areas suggest visuomotor integration  @xcite . on the other hand ,",
    "both feedforward and feedback anatomical projections exist in corticocortical connections  @xcite .",
    "the pyramidal neurons of the superficial layer project to the middle layer of the higher functional region , whereas the ones of the deep layer project back to the superficial and deep layers  @xcite . thus cortical areas are reciprocally connected by feedforward ( bottom - up ) and feedback ( top - down ) pathways .",
    "the bottom - up signals usually originate from sensory information .",
    "consequently , some cortical regions receive both bottom - up ( sensory ) and top - down signals  @xcite .",
    "according to the modeling study using a population of neurons that receives bottom - up and top - down periodic inputs with different periods  @xcite , the synchrony of firing often collapses .",
    "in other words , the loss of synchronized firings requires remarkably different cycles of inputs .",
    "when the differences of the cycle times are small , the loss of synchrony does not occur . when the neurons receive independently fixed periodic inputs , what determines critically if the firings synchronize or not ?",
    "it is expected that the strength of synaptic connections have great effects on synchrony because numerical studies showed that synaptic plasticity evokes synchrony  @xcite .",
    "taken together , generally , synchrony depends on the synaptic connections as well as the periods of inputs .",
    "thus the purpose of our study is to understand the effects of input trains such as amplitude and period , and synaptic connections on the synchrony of neural networks , using the mean field theory . for convenience of applying this framework",
    ", we regard the state in which two neurons fire with the same period as synchronous in this paper . thus , although this synchrony does not require simultaneous firings , so - called synchrony never occurs if this synchrony does not occur .",
    "before we try to achieve this aim , we discuss two more fundamental cases , that is , connected neurons without input trains and a single neuron receiving periodic inputs .",
    "in section [ sec2 ] , we apply the mean field theory for the simplest neural network without external inputs .",
    "we assume that this network can be represented by a cluster consists of only two integrate - and - fire model neurons .",
    "this analysis clarifies that the stronger synaptic connections enhance the shorter cycle synchrony cycle of cluster neurons . in section [ sec3 ]",
    ", we consider the cycle of synchrony when one periodic external input is provided to a neuron .",
    "the result shows that the cycle of the synchrony becomes longer as the cycle of external inputs becomes longer . in section [ sec4 ]",
    ", we describe that the network receiving two different cycle inputs ( supposed to be bottom - up inputs and top - down inputs ) show the loss of synchronies in certain conditions .",
    "in this section , using our formulation , we discuss a periodic synchronized firing of neurons located in the same cortical region . at first , to simplify many neurons connected complicatedly , we assume that two particular neurons @xmath1 and @xmath2 with a synaptic connection from @xmath2 to @xmath1 represent `` cluster neurons '' .",
    "the membrane potentials are denoted as @xmath3 and @xmath4 , respectively .",
    "the neuron @xmath2 receives inputs from other neurons located outside the cluster . the effective value ( mean value ) of the inputs is assumed to be an  effective input \" @xmath5 .",
    "this approximation is illustrated in fig.[fig1 ] .",
    "after the firings of neuron @xmath2 , the neuron @xmath1 receives the output of the neuron @xmath2 through the synaptic weight @xmath6 .",
    "thus , we can obtain the effective equations of the membrane potentials @xmath3 and @xmath4 as follows : @xmath7 and @xmath8 where the parameters @xmath9 , @xmath10 , and @xmath11 denote the time - constant , the number of connections , and the @xmath12-th firing time of neuron @xmath2 , respectively . here",
    ", we assumed that @xmath5 is constant , because the number of inputs from outside of the cluster is so large that the time average corresponds to the population average .    from eq .",
    "( [ eq1 ] ) , the membrane potential @xmath4 is obtained as @xmath13 then we obtain the firing time @xmath14 using the effective input @xmath5 as @xmath15 with the threshold @xmath16 . here , for convenience of calculations , we use a simple condition that the resting potential and the reset potential after firing take the same value of @xmath17 . in our study , using the integrate - and - fire model , we assume that the membrane potentials reset their potential @xmath3 and @xmath4 for the reset potential @xmath18 after firings immediately .     and @xmath2 ( whose membrane potentials are denoted as @xmath3 and @xmath4 )",
    "are assumed to be the effective inputs @xmath5 .",
    "we focus on the neurons @xmath1 and @xmath2 with @xmath5 .",
    "the self - consistency eq.([eq7 ] ) requires the correspondence between output signals of the neuron @xmath1 ( namely @xmath19 ) and input signals to the neuron @xmath2 ( namely @xmath5 ) .",
    "consequently , the self - consistency requires the global transition symmetry of the neural network .",
    "this approximation is one of the mean field theory.[fig1],width=245 ]    the time dependence of @xmath3 is derived from eq .",
    "( [ eq2 ] ) under the firing of @xmath2-neuron satisfying eq .",
    "( [ eq4 ] ) as follows : @xmath20 where the parameter @xmath21 means the total synaptic weight .",
    "then , we obtain the cycle - time @xmath22 of @xmath1-neuron s firings as @xmath23.\\label{eq6}\\ ] ] now , we consider the self - consistency @xmath24 ( the mean output of the neuron @xmath1 is denoted as @xmath19 in fig.[fig1 ] ) ; @xmath25 this consistency assumes that the firings of neurons are periodic and synchronized .",
    "thus the value of @xmath5 should indicate the mean value of the periodic inputs .",
    "the formula of @xmath5 in eq.([eq7 ] ) looks plausible because it corresponds to the assumed mean value of inputs with periodicity in the mean - field theory of previous studies  @xcite .",
    "we assumed the hypothetical cycle time @xmath22 of the effective inputs .",
    "then , if the periodic firings can occur , we can find the appropriate cycle time @xmath22 .",
    "but if there does not exist the cycle time @xmath22 , the periodic firings can not occur .",
    "this condition for the @xmath22 is expressed in the self - consistency eq.([eq7 ] ) .    from eqs.([eq4 ] ) , ( [ eq6 ] ) , and ( [ eq7 ] ) , we obtain the self - consistent equation as @xmath26 where we have redefined @xmath27 . the cycle - time @xmath0 of spontaneous firing of the cluster neurons is given as a solution of eq.([eq8 ] ) . the function @xmath28 is defined as the left - side of eq.([eq8 ] ) , namely @xmath29 .",
    "the function @xmath28 can be expanded as @xmath30\\right\\}\\notag\\\\ & = 1-\\frac{1}{2}\\left(\\frac{t}{\\tau}\\right)+\\cdots,\\label{eq9}\\end{aligned}\\ ] ] with respect to @xmath31 .",
    "then , the function @xmath28 has the asymptotic value @xmath32 in the case of @xmath33 ( namely the frequency @xmath34 ) .",
    "consequently , in the case of @xmath35 , there does not exist the spontaneous firing .",
    "on the other hand , in the case of @xmath36 , there exists the spontaneous firing .",
    "this result is supported by the following physical phenomena , that is , the firing frequency of neurons are enhanced by effective inputs ( from neighbor neurons ) exceeding the threshold .",
    "meanwhile the spontaneous firing does not occur under the weak effective inputs .",
    "in this section , we consider the case of a single neuron receiving a periodic input train .",
    "this simple example may be useful to discuss the specific cases of the neural networks including the connections and input trains .",
    "the membrane potential @xmath3 of neuron @xmath1 is characterized as follows : @xmath37 where the input trains @xmath38 is denoted by @xmath39 here the parameter @xmath40 means the cycle time of periodic input trains and @xmath41 means a firing phase ( time lag ) .",
    "@xmath41 is the initial phase in a cycle so that the next firing time shifts linearly with @xmath41 .    from the equations ( [ eq10 ] ) and ( [ eq11 ] ) ,",
    "the time dependence @xmath3 is obtained as @xmath42 where @xmath22 denotes the firing cycle of @xmath1-neuron .",
    "then the condition for the firing @xmath43",
    "( @xmath16 means the threshold ) gives the firing cycle @xmath27 as @xmath44.\\label{eq13}\\ ] ] the derivative @xmath45 is derived as @xmath46 for the condition @xmath47 , where @xmath48 is defined as @xmath49 . here",
    "the function @xmath0 of @xmath40 is defined in the region @xmath50 in eq.([eq13 ] ) , so that the equation ( [ eq14 ] ) shows that the firing cycle @xmath0 diverges exponentially with increase of @xmath40 . from the above discussion",
    ", the firing cycle depends on the cycle time of input trains as a monotonically increasing function .",
    "in the previous discussions in sections [ sec2 ] and [ sec3 ] , the stronger synaptic connections yield the synchrony with shorter cycle while the longer cycle input train yields the longer cycle synchrony .",
    "thus , one can predict catastrophes of synchrony if periodic spikes with longer ( or shorter ) period are input to the neurons with stronger ( or weaker ) synaptic weights .",
    "this is the reason why the relationship between the synaptic connections and cycle of inputs under the condition of synchrony in the neural networks is not so simple . in this section ,",
    "we examine the neural network receiving two external periodical inputs . to clarify this condition and related phenomena analytically",
    ", we apply the mean field theory to the cluster neurons @xmath1 and @xmath2 in the network with two external inputs , namely @xmath51 and @xmath52 . these two external inputs @xmath51 and",
    "@xmath52 have the independent cycle @xmath53 and @xmath54 , respectively , and the time dependence of these inputs are expressed as @xmath55 here @xmath56 means the strength of inputs . in this study , we assume that the two external inputs have common strength .",
    "these input trains are constructed by independent poisson processes , whose mean interstimulus interval is @xmath41 . for the convenience of analysis ,",
    "these input trains are averaged over the period from @xmath57 @xmath58 to @xmath59 @xmath60 .",
    "this averaging procedure does not lose the periodicity of input trains .",
    "these inputs are received by the cluster neurons @xmath1 and @xmath2 as a total external input @xmath61 the parameter @xmath62 denotes the rate of the input @xmath51 , which implies the balance ratio ( relative strength ) of the two inputs . for example , in the case of @xmath63 , both two inputs @xmath51 and @xmath52 have the same intensity of the input current .",
    "when @xmath64 , @xmath51 has the stronger intensity than @xmath52 .    from the above discussion , we obtain the effective equations of motion about the cluster neurons as follows : @xmath65 and @xmath66 we assumed that @xmath5 is constant because a large number of synaptic inputs to each neuron will cancel out the periodicity of input signals except the external inputs . from eq .",
    "( [ eq17 ] ) , the membrane potential @xmath4 is obtained as @xmath67 with using the effective input @xmath5 . the integration shown in the second term of eq .",
    "( [ eq19 ] ) is performed as follows :    @xmath68    then the condition to determine the firing cycle @xmath69 of the neuron @xmath2 is obtained as @xmath70(1-e^{-(t_j-\\lambda)/\\tau})\\label{eq21}\\ ] ]    with the negative function @xmath71 .",
    "the time dependence of @xmath3 is derived from eq .",
    "( [ eq18 ] ) as follows : @xmath72 the time dependence of @xmath3 yields the condition to determine the firing cycle @xmath22 of @xmath1-neuron as    @xmath73(1-e^{-(t_i-\\lambda)/\\tau}).\\label{eq23}\\ ] ]    from solving the eq.([eq21 ] ) with respect to @xmath69 and inserting to eq.([eq23 ] ) , when the cycle time @xmath27 satisfies the self - consistent condition ( [ eq7 ] ) , namely @xmath74 , the cluster neurons show the synchronized firings .",
    "the self - consistency is transcribed in more details as @xmath75    where @xmath76 , @xmath77j_0/\\theta$ ] and @xmath78 .",
    "these parameters are normalized by @xmath16 or @xmath9 .",
    "the function @xmath79 takes negative value for any @xmath53 and @xmath54 , and tends to zero for as @xmath53 or @xmath54 tends to infinity ( fig.[fig2 ] ) .",
    "the important parameters of input trains , namely the strength of inputs @xmath56 and the input balance @xmath62 as well as @xmath53 and @xmath54 , are included in the function @xmath79 . then the behavior of this parameter express the property of input trains ; therefore , we treat the parameter @xmath79 as a continuous real number defined in the region @xmath80 for characterizing the input trains .",
    "the parameter @xmath81 in eq .",
    "( [ eq24 ] ) corresponds to the cycle time of synchrony of cluster neurons .",
    "unfortunately , one can not solve the condition eq .",
    "( [ eq24 ] ) rigorously with respect to @xmath81 .",
    "then we have solved it numerically as shown in fig.[fig3 ] .    as are shown in fig.[fig3 ] , there are two typical anomalies of synchronies , where the value of @xmath81 can not exist .",
    "first , in the region of larger @xmath82 ( stronger synaptic connections ) and larger @xmath79 ( longer cycle of external inputs ) , the shorter cycle synchrony enhanced by strong synaptic connections conflicts with the longer cycle of external inputs .",
    "we call this region `` region 1 '' .",
    "second , in the region of smaller @xmath82 ( weaker synaptic connections ) and larger @xmath79 , the cycle time of the synchrony increases exponentially with increasing cycle time of inputs .",
    "we call this region `` region 2 '' .",
    "the limiting cases of eq .",
    "( [ eq24 ] ) clarify the `` region 1 '' and `` region 2 '' in fig.[fig3 ] . in the case of @xmath83 , eq . ( [ eq24 ] ) yields the relation @xmath84 on the other hand , in the case of @xmath85 , eq .",
    "( [ eq24 ] ) yields the relation    @xmath86e^{\\lambda/\\tau}}}\\equiv h_{\\infty}(\\alpha,\\lambda,\\tau).\\label{eq26}\\ ] ]    then , in the region 1 , parameters @xmath79 and @xmath82 satisfy the inequality @xmath87 while , in the region 2 , they satisfy the inequality @xmath88 using eqs.([eq27 ] ) and ( [ eq28 ] ) , we obtain the phase diagram as fig.[fig4 ] .",
    "the phase boundaries are expressed by eqs.([eq25 ] ) and ( [ eq26 ] ) . as is shown in fig.[fig4 ] , the synchrony occurs only in the outside of the region 1 @xmath89 region 2 .",
    "this simple conditional equation can provide us with feasibility of synchrony . from the derivation of eqs.([eq25 ] ) and ( [ eq26 ] ) , it is clearly understood that there are two types of loss of the synchrony , that is , the firing cycle vanishes ( region 1 ) and the firing cycle diverges ( region 2 ) . in the intersection region of region 1 and region 2 , either type of",
    "the loss of synchrony can occur , which will be affected by the initial conditions , boundary conditions , noises , or others .",
    "divided by @xmath90 is shown when @xmath91 .",
    "@xmath79 tends to zero as @xmath53 or @xmath54 tends to infinity.,width=302 ]     is shown in the @xmath92 space .",
    "the large @xmath79 corresponds to the long cycle input(s ) as is shown in fig[fig2 ] .",
    "region 1 shows that the synchrony does not occur because strong synaptic connections ( large @xmath82 ) conflict with the long cycle inputs ( large @xmath79 ) . in region 2 , the firing cycle @xmath81 diverges exponentially with increase of @xmath79 . here",
    "[ fig3],width=245 ]    ) and ( [ eq28 ] ) is figured .",
    "the horizontal axis denotes the parameter @xmath82 while the vertical axis denotes the parameter @xmath79 . here",
    "the regions 1 and 2 correspond to them in fig.[fig3 ] . in region 1 , the firing cycle vanishes , while the firing cycle diverges in region 2.[fig4],width=302 ]",
    "we have shown that the synchrony of neurons depends on the conditions between the cycle times of inputs and the amount of strength of synaptic connections , and that the synchrony collapses when they ( the cycle time of inputs and the amount of synaptic connections ) do not satisfy the condition . in order to obtain the conditions for synchronized firings , we have used the mean field theory .",
    "the solution of the self - consistent conditions corresponds to the cycle time of synchrony .",
    "when the conditions are constructed by indeterminate equations , such parameter regions show the loss of synchronies . as a result , there are two critical cases for synchrony :    1 .",
    "when the synaptic connections are weaker enough and the cycle times of external inputs are longer enough , the frequency of synchronized firings becomes too small to observe .",
    "the conflicts between stronger synaptic connections ( which lead to the shorter cycle synchrony ) and longer cycle of external inputs make the loss of synchronized firings of the cluster neurons .",
    "the results mean that the synchronization in a population of neurons will never occur when the parameters are in the critical regions . from the viewpoint of information processing in the brain , this discussion suggests that a cortical region works when the synaptic structure matches the bottom - up and top - down signals .",
    "generally , this mean field theory is applicable to many neuron models ( for example , hodgkin - huxley model as is suggested by chen and jasnow  @xcite ) .",
    "because of this universality of the mean field theory , the same results may be obtained from other neural network models .    in this study , we assume that a cluster of a number of neurons can be stochastically represented as two neurons as shown in fig.[fig1 ] .",
    "if we assume three or more representative neurons as the cluster , are the results in this study is still available ? there are two factors to affect the availability .",
    "first , they may depend on the structure of synaptic connections between the neurons .",
    "when the neurons are fully connected each other , the results will be similar because of homogeneity . however , other cases with some neurons with heterogeneous connections are too complicated to be analyzed by our method . secondly ,",
    "when the ratio of the number of neurons to the number of connections is larger , the synchrony becomes difficult to occur under the same condition .",
    "this is because the fluctuations of internal states of neurons become larger .",
    "consequently , our approximation is applicable when the ratio of the number of neurons to the number of connections is not so large and the connections are homogeneous .",
    "finally , we would like to discuss the correspondence between the mean field theory and bethe approximation  @xcite .",
    "from the view point of statistical mechanics , bethe approximation has been introduced to analyze magnetic materials .",
    "it is very difficult to analyze the magnetization because many spins interact each other in the magnetic materials .",
    "bethe has introduced the effective theory to approximate in order to simplify the systems . in the bethe approximation",
    ", we choose some spins from huge spins and call the spins a `` cluster '' .",
    "then we ignore the spins on the outside of the cluster in spite of introducing the effective field interacting with the boundary spins of the cluster .",
    "the intra - cluster interactions can be analyzed rigorously since the cluster system is of finite size . here",
    "the effective fields are determined by the self - consistency , that is , the bulk system corresponds to the surface system . while bethe approximations are introduced in the equilibrium systems , we or chen and jasnow used the mean field theory in the neural networks as a nonequilibrium system .",
    "however this mean field theory will lead to appropriate results even in the time - dependent systems as far as the effective input @xmath5 is appropriate . as is also discussed in section [ sec1 ] , this mean field theory can treat the synaptic connections rigorously between the cluster neurons .",
    "this is the reason why it is useful to discuss the effects of synaptic connections .",
    "using this mean field theory , one may be able to clarify the other phenomena and the effects of synaptic connections in the neural networks .    00 g. l. gerstein and b. mandelbrot , biophys .",
    "j. * 4 * , 41 ( 1964 ) .",
    "r. b. stein , biophys .",
    "j. * 5 * , 173 ( 1965 ) .",
    "r. b. stein , biophys .",
    "j. * 7 * , 37 ( 1967 ) .",
    "w. calvin and c. f. stevens , j. neurophysiol .",
    "* 31 * , 574 ( 1968 ) .",
    "h. l. bryant and j. p. segundo , j. physiol .",
    "* 260 * , 279 ( 1976 ) . z.",
    "f. mainen and t. j. sejnowski , science * 268 * , 1503 ( 1995 ) .",
    "d. h. perkel , g. l. gerstein and g. p. moore , biophys .",
    "j. * 7 * , 391 ( 1967 ) .",
    "d. h. johnson , j. comp . neurosci . * 3 * , 275 ( 1996 ) .",
    "a. n. burkitt , biol . cybern . * 95 * , 1 ( 2006 ) .",
    "d. j. amit and m. v. tsodyks , network * 2 * , 259 ( 1991 ) .",
    "d. j. amit and n. brunel , cereb .",
    "cortex * 7 * , 237 ( 1997 ) .",
    "n. brunel , j. comp . neurosci . * 8 * , 183 ( 2000 ) .",
    "h. c. tuckwell , _ introduction to theoretical neurobiology _ , ( cambridge university press , 1988 , cambridge ) .",
    "a. einstein , ann .",
    "physik * 17 * , 549 ( 1905 ) .",
    "h. risken , _ the fokker - plank equation 2nd edition _ , ( springer , 1989 , new york ) .",
    "g. e. uhlenbeck and l. s. ornstein , phys . rev . * 36 * , 823 ( 1930 ) .",
    "c. c. chen and d. jasnow , phys .",
    "e * 81 * , 011907 ( 2010 ) .",
    "m. petrides , b. alivisatos , a. c. evans and e. meyer , proc . national acad .",
    "usa . * 90 * , 873 ( 1993 ) . c. s. carter , m. m. botvinick and j. d. choen , rev . neurosci . * 10 * , 49 ( 1999 ) . w. j. gehring and r. t. knight , nature neurosci . * 3 * , 516 ( 2000 ) .",
    "r. rodriguez , u. kallenbach , w. singer and m. h. munk , j. neurosci .",
    "* 24 * , 10369 ( 2004 ) .",
    "g. buzsaki , _ rhythms of the brain _",
    "( oxford univ . press , 2011 , oxford ) .",
    "s. ohara , t.miya , k. baba , a.ikeda , t. kunieda , r.matsumoto , j. yamamoto , m. matsuhashi , t. nagamine , k. hirasawa , t.hori , t. mihara , n.hashimoto , s. salenius and h. shibasaki , j. neurosci . * 21 * , 9377 ( 2001 ) . c. m.",
    "gray , p. knig , a. k. engel and w. singer , nature * 338 * , 334 ( 1989 ) .",
    "d.lee , j. neurosci .",
    "* 23 * , 6798 ( 2003 ) .",
    "a. k. engel , p. fries and w. singer , nature rev . neurosci . * 2 * , 704 ( 2001 ) .",
    "p. fries , annu .",
    "neurosci . * 32 * , 209 ( 2009 ) .",
    "p. r. roelfsema , a. k. engel , p. knig and w. singer , nature * 385 * , 157 ( 1997 ) .",
    "g. m. shepherd , _ the synaptic organization of the brain fifth edition _ , ( oxford univ.press , 2004 , oxford ) .",
    "d. j. felleman and d. c. van essen , cereb .",
    "cortex * 1 * , 1 ( 1991 )",
    ". j. m. fuster , _ physiology of executive functions : the perception - action cycle _ ( _ principles of frontal lobe function _ , edited by d.t.stuss and r.t.knight , oxford univ.press . , 2002 , oxford ) o. araki , lect . n. comp . sci . * 6443 * , 231 ( 2010 ) . k. kitano and t. fukai , learn .",
    "mem . * 11 * , 267 ( 2004 ) .",
    "r. hosaka , o. araki and t. ikeguchi , neural comp .",
    "* 20 * , 415 ( 2008 ) .",
    "m. suzuki , _ coherent - anomaly method : mean field , fluctuations and systematics _",
    "( world scientific , 1995 , singapore )"
  ],
  "abstract_text": [
    "<S> in this study , we apply a mean field theory to the neural network model with two periodic inputs in order to clarify the conditions of synchronies . this mean field theory yields a self - consistent condition for the synchrony and enables us to study the effects of synaptic connections for the behavior of neural networks . </S>",
    "<S> then , we have obtained a condition of synaptic connections for the synchrony with the cycle time @xmath0 . </S>",
    "<S> the neurons in neural networks receive sensory inputs and top - down inputs from outside of the network . when the network neurons receive two or more inputs , their synchronization depends on the conditions of inputs . </S>",
    "<S> we have also analyzed this case using the mean field theory . as a result , we clarified the following points : ( 1 ) the stronger synaptic connections enhance the shorter synchrony cycle of neurons . ( 2 ) the cycle of the synchrony becomes longer as the cycle of external inputs becomes longer . </S>",
    "<S> ( 3 ) the relationships among synaptic weights , the properties of input trains , and the cycle of synchrony are expressed by one equation , and there are two areas for asynchrony . in association with the third point , the yielded equation is so simple for calculation that they can easily provide us feasible and infeasible conditions for synchrony . </S>"
  ]
}