{
  "article_text": [
    "all musical pieces are similar , but some are more similar than others . apart from being an infinite source of discussion ( `` haydn is just like mozart  no , he s not ! '' ) , such similarities are also crucial for the design of efficient music information retrieval systems .",
    "the amount of digitized music available on the internet has grown dramatically in recent years , both in the public domain and on commercial sites .",
    "napster and its clones are prime examples .",
    "websites offering musical content in some form or other ( mp3 , midi ,  ) need a way to organize their wealth of material ; they need to somehow classify their files according to musical genres and subgenres , putting similar pieces together .",
    "the purpose of such organization is to enable users to navigate to pieces of music they already know and like , but also to give them advice and recommendations ( `` if you like this , you might also like  '' ) .",
    "currently , such organization is mostly done manually by humans , but some recent research has been looking into the possibilities of automating music classification .",
    "a human expert , comparing different pieces of music with the aim to cluster likes together , will generally look for certain specific similarities .",
    "previous attempts to automate this process do the same . generally speaking",
    ", they take a file containing a piece of music and extract from it various specific numerical features , related to pitch , rhythm , harmony etc .",
    "one can extract such features using for instance fourier transforms  @xcite or wavelet transforms  @xcite .",
    "the feature vectors corresponding to the various files are then classified or clustered using existing classification software , based on various standard statistical pattern recognition classifiers  @xcite , bayesian classifiers  @xcite , hidden markov models  @xcite , ensembles of nearest - neighbor classifiers  @xcite or neural networks  @xcite .",
    "for example , one feature would be to look for rhythm in the sense of beats per minute .",
    "one can make a histogram where each histogram bin corresponds to a particular tempo in beats - per - minute and the associated peak shows how frequent and strong that particular periodicity was over the entire piece . in @xcite we see a gradual change from a few high peaks to many low and spread - out ones going from hip - hip , rock , jazz , to classical .",
    "one can use this similarity type to try to cluster pieces in these categories .",
    "however , such a method requires specific and detailed knowledge of the problem area , since one needs to know what features to look for .",
    "our aim is much more general .",
    "we do not look for similarity in specific features known to be relevant for classifying music ; instead we apply a general mathematical theory of similarity .",
    "the aim is to capture , in a single similarity metric , _ every effective metric _ : effective versions of hamming distance , euclidean distance , edit distances , lempel - ziv distance , and so on .",
    "such a metric would be able to simultaneously detect _ all _ similarities between pieces that other effective metrics can detect .",
    "rather surprisingly , such a `` universal '' metric indeed exists .",
    "it was developed in @xcite , based on the `` information distance '' of @xcite .",
    "roughly speaking , two objects are deemed close if we can significantly `` compress '' one given the information in the other , the idea being that if two pieces are more similar , then we can more succinctly describe one given the other . here compression is based on the ideal mathematical notion of kolmogorov complexity , which unfortunately is not effectively computable .",
    "it is well known that when a pure mathematical theory is applied to the real world , for example in hydrodynamics or in physics in general , we can in applications only approximate the theoretical ideal .",
    "but still the theory gives a framework and foundation for the applied science .",
    "similarly here .",
    "we replace the ideal but noncomputable kolmogorov - based version by standard compression techniques .",
    "we lose theoretical optimality in some cases , but gain an efficiently computable similarity metric intended to approximate the theoretical ideal .",
    "in contrast , a later and partially independent compression - based approach of @xcite for building language - trees  while citing @xcite  is by _ ad hoc _ arguments about empirical shannon entropy and kullback - leibler distance resulting in non - metric distances .    earlier research has demonstrated that this new universal similarity metric works well on concrete examples in very different application fields  the first completely automatic construction of the phylogeny tree based on whole mitochondrial genomes , @xcite and a completely automatic construction of a language tree for over 50 euro - asian languages @xcite .",
    "other applications , not reported in print , are detecting plagiarism in student programming assignments @xcite , and phylogeny of chain letters .",
    "in this paper we apply this compression - based method to the classification of pieces of music .",
    "we perform various experiments on sets of mostly classical pieces given as midi ( musical instrument digital interface ) files .",
    "this contrasts with most earlier research , where the music was digitized in some wave format or other ( the only other research based on midi that we are aware of is  @xcite ) .",
    "we compute the distances between all pairs of pieces , and then build a tree containing those pieces in a way that is consistent with those distances . first ,",
    "as proof of principle , we run the program on three artificially generated data sets , where we know what the final answer should be .",
    "the program indeed classifies these perfectly .",
    "secondly , we show that our program can distinguish between various musical genres ( classical , jazz , rock ) quite well .",
    "thirdly , we experiment with various sets of classical pieces .",
    "the results are quite good ( in the sense of conforming to our expectations ) for small sets of data , but tend to get a bit worse for large sets .",
    "considering the fact that the method knows nothing about music , or , indeed , about any of the other areas we have applied it to elsewhere , one is reminded of dr johnson s remark about a dog s walking on his hind legs : `` it is not done well ; but you are surprised to find it done at all . ''",
    "the paper is organized as follows .",
    "we first give a domain - independent overview of compression - based clustering : the ideal distance metric based on kolmogorov complexity , and the quartet method that turns the matrix of distances into a tree . in section  [ secdetails ]",
    "we give the details of the current application to music , the specific file formats used etc . in section  [ secresults ]",
    "we report the results of our experiments .",
    "we end with some directions for future research .",
    "each object ( in the application of this paper : each piece of music ) is coded as a string @xmath0 over a finite alphabet , say the binary alphabet .",
    "the integer @xmath1 gives the length of the shortest compressed binary version from which @xmath0 can be fully reproduced , also known as the _ kolmogorov complexity _ of @xmath0 .",
    "`` shortest '' means the minimum taken over every possible decompression program , the ones that are currently known as well as the ones that are possible but currently unknown .",
    "we explicitly write only `` decompression '' because we do not even require that there is also a program that compresses the original file to this compressed version ",
    "if there is such a program then so much the better . technically , the definition of kolmogorov complexity is as follows .",
    "first , we fix a syntax for expressing all and only computations ( computable functions ) .",
    "this can be in the form of an enumeration of all turing machines , but also an enumeration of all syntactically correct programs in some universal programming language like java , lisp , or c. we then define the kolmogorov complexity of a finite binary string as the length of the shortest turing machine , java program , etc . in our chosen syntax .",
    "which syntax we take is unimportant , but we have to stick to our choice .",
    "this choice attaches a definite positive integer as the kolmogorov complexity to each finite string .    though defined in terms of a particular machine model ,",
    "the kolmogorov complexity is machine - independent up to an additive constant and acquires an asymptotically universal and absolute character through church s thesis , and from the ability of universal machines to simulate one another and execute any effective process .",
    "the kolmogorov complexity of an object can be viewed as an absolute and objective quantification of the amount of information in it .",
    "this leads to a theory of _ absolute _ information _ contents _ of _ individual _ objects in contrast to classic information theory which deals with _ average _ information _ to communicate _ objects produced by a _",
    "random source_.    so @xmath1 gives the length of the ultimate compressed version , say @xmath2 , of @xmath0 .",
    "this can be considered as the amount of information , number of bits , contained in the string .",
    "similarly , @xmath3 is the minimal number of bits ( which we may think of as constituting a computer program ) required to reconstruct @xmath0 from @xmath4 . in a way",
    "@xmath1 expresses the individual `` entropy '' of @xmath0the minimal number of bits to communicate @xmath0 when sender and receiver have no knowledge where @xmath0 comes from .",
    "for example , to communicate mozart s `` zauberflte '' from a library of a million items requires at most 20 bits ( @xmath5 ) , but to communicate it from scratch requires megabits . for more details on this pristine notion of individual information",
    "content we refer to the textbook @xcite .",
    "as mentioned , our approach is based on a new very general similarity distance , classifying the objects in clusters of objects that are close together according to this distance . in mathematics ,",
    "lots of different distances arise in all sorts of contexts , and one usually requires these to be a ` metric ' , since otherwise undesirable effects may occur .",
    "a metric is a distance function @xmath6 that assigns a non - negative distance @xmath7 to any two objects @xmath8 and @xmath9 , in such a way that    1 .",
    "@xmath10 only where @xmath11 2 .",
    "@xmath12 ( symmetry ) 3 .",
    "@xmath13 ( triangle inequality )    a familiar example of a metric is the euclidean metric , the everyday distance @xmath14 between two objects @xmath15 expressed in , say , meters .",
    "clearly , this distance satisfies the properties @xmath16 , @xmath17 , and @xmath18 ( substitute @xmath19 amsterdam , @xmath20 brussels , and @xmath21 chicago . )",
    "we are interested in `` similarity metrics '' .",
    "for example , if the objects are classical music pieces then the function @xmath10 if @xmath8 and @xmath9 are by the same composer and @xmath22 otherwise , is a similarity metric , albeit a somewhat elusive one .",
    "this captures only one , but quite a significant , similarity aspect between music pieces .    in @xcite , a new theoretical approach to a wide class of similarity metrics",
    "was proposed : the `` normalized information distance '' is a metric , and it is universal in the sense that this single metric uncovers all similarities simultaneously that the metrics in the class uncover separately .",
    "this should be understood in the sense that if two pieces of music are similar ( that is , close ) according to the particular feature described by a particular metric , then they are also similar ( that is , close ) in the sense of the normalized information distance metric .",
    "this justifies calling the latter _ the _ similarity metric .",
    "oblivious to the problem area concerned , simply using the distances according to the similarity metric , our method fully automatically classifies the objects concerned , be they music pieces , text corpora , or genomic data .",
    "more precisely , the approach is as follows .",
    "each pair of such strings @xmath0 and @xmath4 is assigned a distance @xmath23 there is a natural interpretation to @xmath24 : if , say , @xmath25 then we can rewrite @xmath26 where @xmath27 is the information in @xmath4 about @xmath0 satisfying the symmetry property @xmath28 up to a logarithmic additive error @xcite .",
    "that is , the distance @xmath24 between @xmath0 and @xmath4 is the number of bits of information that is not shared between the two strings per bit of information that could be maximally shared between the two strings .",
    "it is clear that @xmath24 is symmetric , and in @xcite it is shown that it is indeed a metric .",
    "moreover , it is universal in the sense that every metric expressing some similarity that can be computed from the objects concerned is comprised ( in the sense of minorized ) by @xmath24 .",
    "it is these distances that we will use , albeit in the form of a rough approximation : for @xmath1 we simply use standard compression software like ` gzip ' , ` bzip2 ' , or ` compress ' . to compute the conditional version , @xmath3 we use a sophisticated theorem , known as `` symmetry of algorithmic information '' in @xcite",
    "this says @xmath29 so to compute the conditional complexity @xmath3 we can just take the difference of the unconditional complexities @xmath30 and @xmath31 .",
    "this allows us to approximate @xmath24 for every pair @xmath32 .",
    "our actual practice falls short of the ideal theory in at least three respects :    \\(i ) the claimed universality of the similarity distance @xmath24 holds only for indefinitely long sequences @xmath32 .",
    "once we consider strings @xmath32 of definite length @xmath33 , the similarity distance is only universal with respect to `` simple '' computable normalized information distances , where `` simple '' means that they are computable by programs of length , say , logarithmic or polylogarithmic in @xmath33 .",
    "this reflects the fact that , technically speaking , the universality is achieved by summing the weighted contribution of all similarity distances in the class considered with respect to the objects considered .",
    "only similarity distances of which the complexity is small ( which means that the weight is large ) with respect to the size of the data concerned kick in .",
    "\\(ii ) the kolmogorov complexity is not computable , and it is in principle impossible to compute how far off our approximation is from the target value in any useful sense .",
    "\\(iii ) to approximate the information distance in a practical sense we use the standard compression program bzip2 .",
    "while better compression of a string will always approximate the kolmogorov complexity better , this is , regrettably , not true for the ( normalized ) information distance .",
    "namely , using ( [ eq.condition ] ) we consider the difference of two compressed quantities .",
    "different compressors may compress the two quantities differently , causing an increase in the difference even when both quantities are compressed better ( but not both as well ) . in the normalized information distance",
    "we also have to deal with a ratio that causes the same problem .",
    "thus , a better compression program may not necessarily mean that we also approximate the ( normalized ) information distance better .",
    "this was borne out by the results of our experiments using different compressors .    despite these caveats it turns out that the practice inspired by the rigorous ideal theory performs quite well .",
    "we feel this is an example that an _ ad hoc _ approximation guided by a good theory is preferable above _ ad hoc _ approaches without underlying theoretical foundation .",
    "the above approach allows us to compute the distance between any pair of objects ( any two pieces of music ) .",
    "we now need to cluster the objects , so that objects that are similar according to our metric are placed close together .",
    "we do this by computing a phylogeny tree based on these distances . such a phylogeny tree can represent evolution of species but more widely simply accounts for closeness of objects from a set with a distance metric . such a tree will group objects in subtrees : the clusters . to find the phylogeny tree",
    "there are many methods .",
    "one of the most popular is the quartet method .",
    "the idea is as follows : we consider every group of four elements from our set of @xmath33 elements ( in this case , musical pieces ) ; there are @xmath34 such groups . from each group",
    "@xmath35 we construct a tree of arity 3 , which implies that the tree consists of two subtrees of two leaves each .",
    "let us call such a tree a _",
    "quartet_. there are three possibilities denoted ( i ) @xmath36 , ( ii ) @xmath37 , and ( iii ) @xmath38 , where a vertical bar divides the two pairs of leaf nodes into two disjoint subtrees ( figure  [ figquart ] ) .",
    "the cost of a quartet is defined as the sum of the distances between each pair of neighbors ; that is , @xmath39 .",
    "for any given tree @xmath40 and any group of four leaf labels @xmath35 , we say @xmath40 is @xmath41 with @xmath36 if and only if the path from @xmath42 to @xmath43 does not cross the path from @xmath44 to @xmath0 .",
    "note that exactly one of the three possible quartets for any set of 4 labels must be consistent for any given tree .",
    "we may think of a large tree having many smaller quartet trees embedded within its structure ( figure  [ figquartex ] ) .",
    "the total cost of a large tree is defined to be the sum of the costs of all consistent quartets .",
    "first , generate a list of all possible quartets for all groups of labels under consideration .",
    "for each group of three possible quartets for a given set of four labels , calculate a best ( minimal ) cost , and a worst ( maximal ) cost .",
    "summing all best quartets yields the best ( minimal ) cost .",
    "conversely , summing all worst quartets yields the worst ( maximal ) cost .",
    "the minimal and maximal values need not be attained by actual trees , however the score of any tree will lie between these two values . in order to be able to compare tree scores in a more uniform way , we now rescale the score linearly such that the worst score maps to 0 , and the best score maps to 1 , and term this the _ normalized tree benefit score _ @xmath45 . the goal of the quartet method is to find a full tree with a maximum value of @xmath45 , which is to say , the lowest total cost .",
    "this optimization problem is known to be np - hard @xcite ( which means that it is infeasible in practice ) but we can sometimes solve it , and always approximate it .",
    "the current methods in @xcite are far too computationally intensive ; they run many months or years on moderate - sized problems of 30 objects .",
    "we have designed a simple method based on randomization and hill - climbing .",
    "first , a random tree with @xmath46 nodes is created , consisting of @xmath33 leaf nodes ( with 1 connecting edge ) labeled with the names of musical pieces , and @xmath47 non - leaf or _",
    "internal _ nodes labeled with the lowercase letter `` n '' followed by a unique integer identifier .",
    "each internal node has exactly three connecting edges . for this tree @xmath40",
    ", we calculate the total cost of all consistent quartets , and invert and scale this value to find @xmath45 .",
    "typically , a random tree will be consistent with around @xmath48 of all quartets .",
    "now , this tree is denoted the currently best known tree , and is used as the basis for further searching .",
    "we define a simple mutation on a tree as one of the three possible transformations :    1 .   a _ leaf swap _ , which consists of randomly choosing two leaf nodes and swapping them .",
    "2 .   a _ subtree swap _ , which consists of randomly choosing two internal nodes and swapping the subtrees rooted at those nodes .",
    "3 .   a _ subtree transfer _ , whereby a randomly chosen subtree ( possibly a leaf ) is detached and reattached in another place , maintaining arity invariants .",
    "each of these simple mutations keeps invariant the number of leaf and internal nodes in the tree ; only the structure and placements change .",
    "define a full mutation as a sequence of at least one but potentially many simple mutations , picked according to the following distribution .",
    "first we pick the number @xmath49 of simple mutations that we will perform with probability @xmath50 . for each such simple mutation , we choose one of the three types listed above with equal probability .",
    "finally , for each of these simple mutations , we pick leaves or internal nodes , as necessary .",
    "notice that trees which are close to the original tree ( in terms of number of simple mutation steps in between ) are examined often , while trees that are far away from the original tree will eventually be examined , but not very frequently .",
    "so in order to search for a better tree , we simply apply a full mutation on @xmath40 to arrive at @xmath51 , and then calculate @xmath52 .",
    "if @xmath53 , then keep @xmath51 as the new best tree . otherwise , try a new different tree and repeat .",
    "if @xmath52 ever reaches @xmath54 , then halt , outputting the best tree .",
    "otherwise , run until it seems no better trees are being found in a reasonable amount of time , in which case the approximation is complete .",
    "note that if a tree is ever found such that @xmath55 , then we can stop because we can be certain that this tree is optimal , as no tree could have a lower cost .",
    "in fact , this perfect tree result is achieved in our artificial tree reconstruction experiment ( section  [ sect.artificial ] ) reliably in less than ten minutes . for real - world data",
    ", @xmath45 reaches a maximum somewhat less than @xmath54 , presumably reflecting inconsistency in the distance matrix data fed as input to the algorithm , or indicating a search space too large to solve exactly . on many typical problems of up to 40 objects",
    "this tree - search gives a tree with @xmath56 within half an hour . for large numbers of objects , tree scoring itself",
    "can be slow ( as this takes order @xmath57 computation steps ) , and the space of trees is also large , so the algorithm may slow down substantially . for larger experiments",
    ", we use a c++/ruby implementation with mpi ( message passing interface , a common standard used on massively parallel computers ) on a cluster of workstations in parallel to find trees more rapidly .",
    "we can consider the graph of figure  [ figprogress ] , mapping the achieved @xmath45 score as a function of the number of trees examined .",
    "progress occurs typically in a sigmoidal fashion towards a maximal value @xmath58 .",
    "a problem with the outcomes is as follows : for natural data sets we often see some leaf nodes ( data items ) placed near the center of the tree as singleton leaves attached to internal nodes , without sibling leaf nodes .",
    "this results in a more linear , stretched out , and less balanced , tree .",
    "such trees , even if they represent the underlying distance matrix faithfully , are hard to fully understand and may cause misunderstanding of represented relations and clusters . to counteract this effect , and to bring out the clusters of related items more visibly , we have added a penalty term of the following form : for each internal node with exactly one leaf node attached , the tree s score is reduced by 0.005 .",
    "this induces a tendency in the algorithm to avoid producing degenerate mostly - linear trees in the face of data that is somewhat inconsistent , and creates balanced and more illuminating clusters .",
    "it should be noted that the penalty term causes the algorithm in some cases to settle for a slightly lower @xmath45 score than it would have without penalty term .",
    "also the value of the penalty term is heuristically chosen .",
    "the largest experiment used 60 items , and we typically had only a couple of orphans causing a penalty of only a few percent .",
    "this should be set off against the final @xmath45 score of above 0.85 .",
    "another practicality concerns the stopping criterion , at which @xmath45 value we stop .",
    "essentially we stopped when the @xmath45 value did nt change after examining a large number of mutated trees .",
    "an example is the progress of figure  [ figprogress ] ,",
    "initially , we downloaded 118 separate midi ( musical instrument digital interface , a versatile digital music format available on the world - wide - web ) files selected from a range of classical composers , as well as some popular music .",
    "each of these files was run through a preprocessor to extract just midi note - on and note - off events .",
    "these events were then converted to a player - piano style representation , with time quantized in @xmath59 second intervals .",
    "all instrument indicators , midi control signals , and tempo variations were ignored . for each track in the midi file , we calculate two quantities : an _ average volume _ and a _ modal note_.",
    "the average volume is calculated by averaging the volume ( midi note velocity ) of all notes in the track .",
    "the modal note is defined to be the note pitch that sounds most often in that track .",
    "if this is not unique , then the lowest such note is chosen .",
    "the modal note is used as a key - invariant reference point from which to represent all notes .",
    "it is denoted by @xmath60 , higher notes are denoted by positive numbers , and lower notes are denoted by negative numbers .",
    "a value of @xmath54 indicates a half - step above the modal note , and a value of @xmath61 indicates a whole - step below the modal note .",
    "the tracks are sorted according to decreasing average volume , and then output in succession . for each track , we iterate through each time sample in order , outputting a single signed 8-bit value for each currently sounding note .",
    "two special values are reserved to represent the end of a time step and the end of a track .",
    "this file is then used as input to the compression stage for distance matrix calculation and subsequent tree search .",
    "with the natural data sets of music pieces that we use , one may have the preconception ( or prejudice ) that music by bach should be clustered together , music by chopin should be clustered together , and so should music by rock stars .",
    "however , the preprocessed music files of a piece by bach and a piece by chopin , or the beatles , may resemble one another more than two different pieces by bach  by accident or indeed by design and copying .",
    "thus , natural data sets may have ambiguous , conflicting , or counterintuitive outcomes . in other words ,",
    "the experiments on actual pieces have the drawback of not having one clear `` correct '' answer that can function as a benchmark for assessing our experimental outcomes . before describing the experiments we did with midi files of actual music , we discuss three experiments that show that our program indeed does what it is supposed to do  at least in artificial situations where we know in advance what the correct answer is .",
    "the similarity machine consists of two parts : ( i ) extracting a distance matrix from the data , and ( ii ) constructing a tree from the distance matrix using our novel quartet - based heuristic .",
    "* testing the quartet - based tree construction : * we first test whether the quartet - based tree construction heuristic is trustworthy : we generated a random ternary tree @xmath40 with 18 leaves , and derived a distance metric from it by defining the distance between two nodes as follows : given the length of the path from @xmath8 to @xmath9 , in an integer number of edges , as @xmath62 , let @xmath63 except when @xmath64 , in which case @xmath65 .",
    "it is easy to verify that this simple formula always gives a number between 0 and 1 , and is monotonic with path length .",
    "given only the @xmath66 matrix of these normalized distances , our quartet method exactly reconstructed @xmath40 represented in figure  [ figarttreereal ] , with @xmath67 .    * testing the similarity machine on artificial data : * given that the tree reconstruction method is accurate on clean consistent data , we tried whether the full procedure works in an acceptable manner when we know what the outcome should be like :    we randomly generated 22 separate 1-kilobyte blocks of data where each byte was equally probable and called these _ tags_. each tag was associated with a different lowercase letter of the alphabet .",
    "next , we generated 80-kilobyte files by starting with a block of purely random bytes and applying one , two , three , or four different tags on it . applying a tag consists of ten repetitions of picking a random location in the 80-kilobyte file , and overwriting that location with the universally consistent tag that is indicated .",
    "so , for instance , to create the file referred to in the diagram by `` a '' , we start with 80 kilobytes of random data , then pick ten places to copy over this random data with the arbitrary 1-kilobyte sequence identified as tag _",
    "a_. similarly , to create file `` ab '' , we start with 80 kilobytes of random data , then pick ten places to put copies of tag _ a _ , then pick ten more places to put copies of tag _ b _ ( perhaps overwriting some of the _ a _ tags ) . because we never use more than four different tags , and therefore never place more than 40 copies of tags , we can expect that at least half of the data in each file is random and uncorrelated with the rest of the files .",
    "the rest of the file is correlated with other files that also contain tags in common ; the more tags in common , the more related the files are .",
    "the resulting tree is given in figure  [ figtaggedfiles ] ; it can be seen that clustering occurs exactly as we would expect .",
    "the @xmath45 score is 0.905 .",
    "* testing the similarity machine on natural data : * we test gross classification of files based on markedly different file types . here",
    ", we chose several files :    1 .",
    "four mitochondrial gene sequences , from a black bear , polar bear , fox , and rat .",
    "four excerpts from the novel _ the zeppelin s passenger _ by e.  phillips oppenheim 3 .",
    "four midi files without further processing ; two from jimi hendrix and two movements from debussy s suite bergamasque 4 .   two linux x86 elf executables ( the _ cp _ and _ rm _ commands ) 5 .   two compiled java class files .",
    "as expected , the program correctly classifies each of the different types of files together with like near like .",
    "the result is reported in figure  [ figfiletypes ] with @xmath45 equal to 0.984 .      before testing whether our program can see the distinctions between various classical composers ,",
    "we first show that it can distinguish between three broader musical genres : classical music , rock , and jazz .",
    "this should be easier than making distinctions `` within '' classical music .",
    "all musical pieces we used are listed in the tables in the appendix . for the genre - experiment we used 12 classical pieces ( the small set from table  [ tableclassicalpieces ] , consisting of bach , chopin , and debussy ) , 12 jazz pieces ( table  [ tablejazzpieces ] ) , and 12 rock pieces ( table  [ tablerockpieces ] ) .",
    "the tree that our program came up with is given in figure  [ figgenres ] .",
    "the @xmath45 score is 0.858 .",
    "the discrimination between the 3 genres is good but not perfect .",
    "the upper branch of the tree contains 10 of the 12 jazz pieces , but also chopin s prlude no .  15 and a bach prelude .",
    "the two other jazz pieces , miles davis `` so what '' and john coltrane s `` giant steps '' are placed elsewhere in the tree , perhaps according to some kinship that now escapes us but can be identified by closer studying of the objects concerned . of the rock pieces ,",
    "9 are placed close together in the rightmost branch , while hendrix s `` voodoo chile '' , rush `` yyz '' , and dire straits `` money for nothing '' are further away . in the case of the hendrix piece",
    "this may be explained by the fact that it does not fit well in a specific genre .",
    "most of the classical pieces are in the lower left part of the tree .",
    "surprisingly , 2 of the 4 bach pieces are placed elsewhere .",
    "it is not clear why this happens and may be considered an error of our program , since we perceive the 4 bach pieces to be very close , both structurally and melodically ( as they all come from the mono - thematic `` wohltemperierte klavier '' ) .",
    "however , bach s is a seminal music and has been copied and cannibalized in all kinds of recognizable or hidden manners ; closer scrutiny could reveal likenesses in its present company that are not now apparent to us .",
    "in effect our similarity engine aims at the ideal of a perfect data mining process , discovering unknown features in which the data can be similar .      in table",
    "[ tableclassicalpieces ] we list all 60 classical piano pieces used , together with their abbreviations .",
    "some of these are complete compositions , others are individual movements from larger compositions .",
    "they all are piano pieces , but experiments on 34 movements of symphonies gave very similar results ( section  [ secsymphonies ] ) .",
    "apart from running our program on the whole set of 60 piano pieces , we also tried it on two smaller sets : a small 12-piece set , indicated by ` ( s ) ' in the table , and a medium - size 32-piece set , indicated by ` ( s ) ' or ` ( m ) ' .",
    "the small set encompasses the 4 movements from debussy s suite bergamasque , 4 movements of book 2 of bach s wohltemperierte klavier , and 4 preludes from chopin s opus  28 .",
    "as one can see in figure  [ figsmallset ] , our program does a pretty good job at clustering these pieces .",
    "the @xmath45 score is also high : 0.958 .",
    "the 4 debussy movements form one cluster , as do the 4 bach pieces .",
    "the only imperfection in the tree , judged by what one would intuitively expect , is that chopin s prlude no .  15 lies a bit closer to bach than to the other 3 chopin pieces .",
    "this prlude no  15 , in fact , consistently forms an odd - one - out in our other experiments as well .",
    "this is an example of pure data mining , since there is some musical truth to this , as no .",
    "15 is perceived as by far the most eccentric among the 24 prludes of chopin s opus  28 .      the medium set adds 20 pieces to the small set : 6 additional bach pieces , 6 additional chopins , 1 more debussy piece , and 7 pieces by haydn .",
    "the experimental results are given in figure  [ figmediumset ] .",
    "the @xmath45 score is slightly lower than in the small set experiment : 0.895 .",
    "again , there is a lot of structure and expected clustering .",
    "most of the bach pieces are together , as are the four debussy pieces from the suite bergamasque .",
    "these four should be together because they are movements from the same piece ; the fifth debussy item is somewhat apart since it comes from another piece .",
    "both the haydn and the chopin pieces are clustered in little sub - clusters of two or three pieces , but those sub - clusters are scattered throughout the tree instead of being close together in a larger cluster .",
    "these small clusters may be an imperfection of the method , or , alternatively point at musical similarities between the clustered pieces that transcend the similarities induced by the same composer .",
    "indeed , this may point the way for further musicological investigation .",
    "figure  [ figlargeset ] gives the output of a run of our program on the full set of 60 pieces .",
    "this adds 10 pieces by beethoven , 8 by buxtehude , and 10 by mozart to the medium set .",
    "the experimental results are given in figure  [ figlargeset ] .",
    "the results are still far from random , but leave more to be desired than the smaller - scale experiments . indeed , the @xmath45 score has dropped further from that of the medium - sized set to 0.844 .",
    "this may be an artifact of the interplay between the relatively small size , and large number , of the files compared : ( i ) the distances estimated are less accurate ; ( ii ) the number of quartets with conflicting requirements increases ; and ( iii ) the computation time rises to such an extent that the correctness score of the displayed cluster graph within the set time limit is lower than in the smaller samples .",
    "nonetheless , bach and debussy are still reasonably well clustered , but other pieces ( notably the beethoven and chopin ones ) are scattered throughout the tree .",
    "maybe this means that individual music pieces by these composers are more similar to pieces of other composers than they are to each other ?",
    "the placement of the pieces is closer to intuition on a small level ( for example , most pairing of siblings corresponds to musical similarity in the sense of the same composer ) than on the larger level .",
    "this is similar to the phenomenon of little sub - clusters of haydn or chopin pieces that we saw in the medium - size experiment .      finally , we tested whether the method worked for more complicated music , namely 34 symphonic pieces .",
    "we took two haydn symphonies ( no .",
    "95 in one file , and the four movements of  104 ) , three mozart symphonies ( 39 , 40 , 41 ) , three beethoven symphonies ( 3 , 4 , 5 ) , of schubert s unfinished symphony , and of saint - saens symphony no .",
    "the results are reported in figure  [ figsymphonies ] , with a quite reasonable @xmath45 score of 0.860 .",
    "our research raises many questions worth looking into further :    * the program can be used as a data mining machine to discover hitherto unknown similarities between music pieces of different composers or indeed different genres . in this manner",
    "we can discover plagiarism or indeed honest influences between music pieces and composers .",
    "indeed , it is thinkable that we can use the method to discover seminality of composers , or separate music eras and fads .",
    "* a very interesting application of our program would be to select a plausible composer for a newly discovered piece of music of which the composer is not known .",
    "in addition to such a piece , this experiment would require a number of pieces from known composers that are plausible candidates .",
    "we would just run our program on the set of all those pieces , and see where the new piece is placed .",
    "if it lies squarely within a cluster of pieces by composer such - and - such , then that would be a plausible candidate composer for the new piece . *",
    "each run of our program is different  even on the same set of data  because of our use of randomness for choosing mutations in the quartet method",
    ". it would be interesting to investigate more precisely how stable the outcomes are over different such runs .",
    "* at various points in our program , somewhat arbitrary choices were made .",
    "examples are the compression algorithms we use ( all practical compression algorithms will fall short of kolmogorov complexity , but some less so than others ) ; the way we transform the midi files ( choice of length of time interval , choice of note - representation ) ; the cost function in the quartet method .",
    "other choices are possible and may or may not lead to better clustering .",
    "ideally , one would like to have well - founded theoretical reasons to decide such choices in an optimal way .",
    "lacking those , trial - and - error seems the only way to deal with them . *",
    "the experimental results got decidedly worse when the number of pieces grew .",
    "better compression methods may improve this situation , but the effect is probably due to unknown scaling problems with the quartet method or nonlinear scaling of possible similarities in a larger group of objects ( akin to the phenomenon described in the so - called `` birthday paradox '' : in a group of about two dozen people there is a high chance that at least two of the people have the same birthday ) .",
    "inspection of the underlying distance matrices makes us suspect the latter . *",
    "our program is not very good at dealing with very small data files ( 100 bytes or so ) , because significant compression only kicks in for larger files .",
    "we might deal with this by comparing various sets of such pieces against each other , instead of individual ones .",
    "we thank john tromp for useful discussions .",
    "99    d.  benedetto , e.  caglioti , and v.  loreto .",
    "language trees and zipping , _ physical review letters _ , 88:4(2002 ) 048702 .",
    "algorithm makes tongue tree , _ nature _ , 22 january , 2002 .",
    "bennett , p.  gcs , m. li , p.m.b .",
    "vitnyi , and w.  zurek .",
    "information distance , _ ieee transactions on information theory _ , 44:4(1998 ) , 14071423 .",
    "d.  bryant , v.  berry , p.  kearney , m.  li , t.  jiang , t.  wareham and h.  zhang .",
    "a practical algorithm for recovering the best supported edges of an evolutionary tree .",
    "11th acm - siam symposium on discrete algorithms _",
    ", 287296 , 2000 .",
    "w.  chai and b.  vercoe .",
    "folk music classification using hidden markov models .",
    "_ proc .  of international conference on artificial intelligence _ , 2001 .",
    "r.  dannenberg , b.  thom , and d.  watson .",
    "a machine learning approach to musical style recognition , _ proc .",
    "international computer music conference _ , pp .",
    "344 - 347 , 1997 .",
    "m.  grimaldi , a.  kokaram , and p.  cunningham .",
    "classifying music by genre using the wavelet packet transform and a round - robin ensemble .",
    "technical report tcd - cs-2002 - 64 , trinity college dublin , 2002 .",
    "t.  jiang , p.  kearney , and m.  li . a polynomial time approximation scheme for inferring evolutionary trees from quartet topologies and its application .",
    "_ siam j. computing _ , 30:6(2001 ) , 19421961 .",
    "m.  li , j.h .",
    "badger , x.  chen , s.  kwong , p.  kearney , and h.  zhang . an information - based sequence distance and its application to whole mitochondrial genome phylogeny , _ bioinformatics _ , 17:2(2001 ) , 149154 .",
    "m.  li and p.m.b .",
    "algorithmic complexity , pp .",
    "376382 in : _ international encyclopedia of the social & behavioral sciences _ , n.j .",
    "smelser and p.b .",
    "baltes , eds . ,",
    "pergamon , oxford , 2001/2002 .",
    "m.  li , x.  chen , x.  li , b.  ma , p.  vitnyi .",
    "the similarity metric , _ proc .",
    "14th acm - siam symposium on discrete algorithms _",
    ", 2003 .",
    "m.  li and p.m.b .",
    "_ an introduction to kolmogorov complexity and its applications _ , springer - verlag , new york , 2nd edition , 1997 .",
    "p.  scott .",
    "music classification using neural networks , 2001 .",
    "+ http://www.stanford.edu/class/ee373a/musicclassification.pdf    shared information distance or software integrity detection , computer science , university of california , santa barbara , http://dna.cs.ucsb.edu/sid/    g.  tzanetakis and p.  cook , music genre classification of audio signals , _ ieee transactions on speech and audio processing _ , 10(5):293302 , 2002",
    ".the 60 classical pieces used ( ` m ' indicates presence in the medium set , ` s ' in the small and medium sets ) [ cols=\"<,<,<\",options=\"header \" , ]"
  ],
  "abstract_text": [
    "<S> we present a fully automatic method for music classification , based only on compression of strings that represent the music pieces . </S>",
    "<S> the method uses no background knowledge about music whatsoever : it is completely general and can , without change , be used in different areas like linguistic classification and genomics . </S>",
    "<S> it is based on an ideal theory of the information content in individual objects ( kolmogorov complexity ) , information distance , and a universal similarity metric . </S>",
    "<S> experiments show that the method distinguishes reasonably well between various musical genres and can even cluster pieces by composer . </S>"
  ]
}