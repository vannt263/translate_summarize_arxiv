{
  "article_text": [
    "a newborn antelope attempts its first steps only minutes after birth and is capable of walking within half an hour . a human baby ,",
    "when lifted so that its feet just graze the ground , will step in a cyclical walking motion @xcite .",
    "nature provides clear examples of evolutionarily determined , innate behaviors of surprising complexity , and basic locomotor circuits are well - developed prior to any significant goal - directed experience .",
    "the innate structure simplifies the production of goal - directed behavior by confining exploration to stable and coherent , yet flexible dynamics .    on the other hand , machine learning",
    "s recent success stories have emphasized rich models with weakly - defined prior structure , sculpted by large amounts of data . and",
    "indeed , several recent studies have shown that end - to - end reinforcement learning approaches are capable of generating high - quality motor control policies using generic neural networks @xcite .",
    "a key question is how to get the best of both worlds : to build modular , hierarchical components that support coherent exploration while retaining the richness and flexibility of data - driven learning .    here",
    ", we aim to create flexible motor primitives using a reinforcement learning method .",
    "we explore an approach based on a general - purpose , closed - loop motor controller that is designed to be modulated by another system .",
    "when modulated by random noise , this low - level controller generates stable and coherent exploratory behavior .",
    "a higher - level controller can then recruit these motor behaviors to simplify the solution of complex tasks . as a result",
    ", it can learn effective control strategies given only weak feedback , including tasks where reward is only provided infrequently after completion of a goal ( a natural description of many tasks ) .",
    "our architecture takes inspiration from the division of labor in neurobiological motor control  @xcite .",
    "biological motor primitives are formed by spinal cord interneurons , which mediate both fast , reflexive actions and the elementary constituents of motor behaviors like locomotion and reaching . the spinal cord has direct sensory inputs that measure muscle tension and load , joint position , and haptic information from the skin .",
    "these sensory modalities are _ proprioceptive _ ( `` taken from near '' ) because they carry information measured at close range to the body as opposed to the _ exteroceptive _ ( `` taken from afar '' ) modalities like vision , audition and olfaction .",
    "cortical motor neurons produce voluntary motor behavior primarily through the modulation of these interneuron populations .    based on these considerations ,",
    "we explore hierarchical motor controllers with the following properties :    1 .",
    "_ hierarchy _ : the controller is subdivided into a low - level controller , which computes direct motor commands ( e.g. joint torques ) , and a high - level controller , which selects among abstract motor behaviors . 2 .",
    "_ modulation _ : the high - level controller outputs a signal that modulates the behavior of the low - level controller , through a communication bottleneck .",
    "information hiding _ : the low - level controller has direct access only to task - independent , proprioceptive information . for the control problems considered in this paper , this proprioceptive information contains , for instance , the joint angles and velocities of the body and haptic information .",
    "notably , it does not include information about absolute position or orientation in space or task - specific information such as a goal location .",
    "the high - level controller has access to all necessary proprioceptive and exteroceptive information .",
    "4 .   _ multiple time scales _ : while the low - level controller operates at a basic control rate ( i.e. , it receives an observation and produces an action at every time step in the simulation ) , the high - level controller can operate at a slower rate , updating the modulatory control signal to the low - level controller less frequently .",
    "these design decisions are intended to create an abstraction barrier between the low and high levels : separating the high level from the physics and detailed demands of motor actuation and likewise , sheltering the low - level controller from specific task objectives so it can acquire domain - general functionality .",
    "below we present results demonstrating that our architecture solves several non - trivial control problems .",
    "a more detailed analysis of the implications of the design decisions listed above is , however , left for future work .",
    "[ sec : methods : overview ]    , red ) .",
    "the high - level controller has access to all observations ( @xmath0 , yellow and red ) .",
    "while both controllers observe sensory input at the world - clock frequency , the modulatory control signal @xmath1 from the high - level is updated every @xmath2 steps ( here @xmath3 ) . ]",
    "we now describe the architecture of the hierarchical controller in greater detail ( see fig .  1 ) .",
    "the setup is the standard agent - environment interaction model . at each point in time",
    "@xmath4 , an agent executes an action @xmath5 , and subsequently receives a reward @xmath6 and a new observation @xmath7 .",
    "its goal is to maximize the expected sum of discounted future rewards @xmath8 , known as the _ return_.    the agent is characterized by a policy @xmath9 with parameters @xmath10 which specify a distribution over actions as a function of the history @xmath11 , i.e.  @xmath12 the stochastic policy is defined by the composition of networks for the high - level controller @xmath13 and low - level controller @xmath14 .",
    "this combined network outputs the parameters of the action distribution @xmath9 . in the experiments below ,",
    "actions are multi - dimensional , and we parameterize the action distribution as a factorized normal distribution with mean and variance being functions of @xmath15 : @xmath16 .    in the experiments presented here , the low - level controller is a non - recurrent neural network that maps the proprioceptive information @xmath17 and the control signal received from the high - level controller @xmath18 onto the parameters of the action - distribution : @xmath19 for the high - level controller , we have used recurrent networks @xmath20 that integrate observations at every time step and produce a new control signal @xmath1 every @xmath2 time steps : @xmath21 where @xmath22 is the full observation ( including task - specific information ) , @xmath23 is the recurrent state of the high - level controller , @xmath2 is the control interval , and @xmath24 is the most recent update time for the high - level control signal .",
    "we use an actor - critic policy gradient framework for learning during pre - training as well as transfer .",
    "we consider both fully observed ( mdps ) and partially observed problems ( pomdps ) .",
    "we perform gradient ascent in the expected discounted return @xmath25 } $ ] , where the expectation is taken with respect to the trajectory distribution induced by the policy and the environment dynamics .",
    "this gradient is given by @xmath26 } , \\label{eq : reinforceupdate}\\ ] ] where @xmath27 is some baseline that does not depend on @xmath28 .",
    "in this work we use a learned , parameterized value function @xmath29 with parameters @xmath30 to lower the variance of the estimate .",
    "we replace @xmath31 by the @xmath32-weighted return @xmath33 where @xmath34 .",
    "the parameter @xmath32 trades off bias in the value function against variance in the return .",
    "we also use estimates of the return @xmath35 as targets for the value function , so that the loss for value function training is @xmath36 note that we allow for different values of @xmath32 and @xmath37 for computing the policy and value function updates , respectively . additionally ,",
    "although each @xmath35 nominally includes value function terms dependent on @xmath30 from future time steps , we do not differentiate with respect to them , as is typical for temporal difference learning .",
    "the policy gradient framework outlined above performs on - policy learning where the stochasticity of the policy is used for exploration .",
    "choosing the action distribution @xmath9 to be a diagonal gaussian is common due to its simplicity . at the same time , as we will demonstrate below , it can lead to very poor exploratory behavior , especially in high - dimensional action spaces . due to its restricted form , it is unable to describe correlations across action dimensions or time steps .",
    "actuating physical bodies with this form of white noise tends to produce undirected , twitchy movements that are attenuated by the second - order dynamics of the physics .",
    "in contrast , our low - level controllers are feedback controllers that produce pre - trained locomotor behavior . modulating this behavior appropriately can lead to exploratory behavior that is more consistent in space and time .",
    "thus , we allow stochasticity not only at the output of the low - level controller but also in the high - level controller .",
    "more precisely , in transfer training we treat the high - level controller as a stochastic network where @xmath38 the policy distribution composed of the high- and low - level controllers can be seen as a distribution with latent variables : @xmath39 .",
    "this hierarchical model can be optimized in different ways .",
    "the particular approach we take relies on the re - parameterization trick recently applied in the probabilistic modeling literature @xcite and in a policy gradient framework by @xcite :    to use the re - parameterization trick , note that an equivalent formulation of equation ( [ eq : stochasthlexplicit ] ) can be obtained by considering @xmath40 , where @xmath41 and @xmath42 . in this view , @xmath43 is a deterministic function that takes as additional input a random variable drawn from a fixed distribution .",
    "since we have knowledge of @xmath44 , we can now evaluate @xmath45 , which would otherwise be difficult for a latent variable model .",
    "the policy gradient estimate in equation ( @xmath46 ) is simply formed by backpropagating directly into the high - level controller . affects future primitive actions .",
    "this could be accounted for by making @xmath47 dependent on @xmath1 , or by bootstrapping only after resampling @xmath1 . in our experiments",
    "we ignore this influence on the value and use @xmath48 as above . ]",
    "this high - level noise can achieve a dramatically different effect from i.i.d .",
    "noise added to each action dimension independently at every time step .",
    "since the high - level noise is held constant over the high - level control interval and transformed by the low - level controller , it induces spatially and temporally correlated stochasticity at the primitive action level .",
    "we evaluate our framework on three physical domains : a swimming snake , a quadruped and a humanoid .",
    "the snake has 6-links with a 5 dimensional action space and can propel itself forward by exploiting frictional forces .",
    "the quadruped has a 8 dimensional action space with two joints per leg .",
    "the humanoid has 21 action dimensions . for the following motor control problems ,",
    "the core challenge is to learn basic locomotion . for more complex behaviors like navigation",
    ", the locomotion pattern can be reused .",
    "in addition to the description below , we encourage the reader to watch the supplemental videos .",
    "we train our hierarchical motor controller on a simple _ pre - training _ task , and then evaluate its performance in one or more _ transfer _ tasks .",
    "this involves training the low - level controller ( which will be re - used later ) jointly with a provisional high - level controller which provides task - specifc information during pre - training and hence ensures controllability of the low - level controller .",
    "the pre - training task , which facilitates the development of generic locomotion skills , is described by an informative shaping reward and requires the controller to move each creature from a random initial configuration to a randomly positioned target .",
    "after pre - training the provisional high - level controller is discarded and the weights of low - level controller are frozen . for each transfer task a new high - level controller",
    "is trained to modulate the inputs of the frozen low - level controller .",
    "the transfer tasks are most naturally described by _",
    "sparse _ reward functions which are zero everywhere except at goal states . in order to obtain any reward , these tasks demand temporally - extended , structured exploration , posing a significant challenge for reinforcement learning methods .",
    "we use multiple transfer tasks for each domain to test the versatility of the learned low - level controllers .",
    "we implemented our experiments using the asynchronous actor - critic framework introduced in  @xcite . for each experiment and architecture ( pre - training and transfer )",
    ", we perform a coarse grid search over the following hyper - parameters : learning rate , relative scaling of learning rate for the value function , @xmath32 , @xmath37 , and the length of the backpropagation - through - time truncation window . unless noted",
    "otherwise we report results for the hyper - parameter setting which performed best over an average of 5 repeated experiments .    depending on the transfer task we compare learning with the pre - trained low - level controller to learning a feedforward ( _ ff _ ) or recurrent policy ( _ lstm _ ) from scratch ; and we also compare to re - using a pre - learned ff network where we only learn a new input layer ( _ init ff _ ; the new input layer is to account for the fact that the observation space may change between pre - training and transfer task , or that the new task requires a different mapping from observations to motor behavior ) .",
    "* pre - training task * the pre - training task initializes the snake at an origin with a random orientation and a random configuration of the joint angles .",
    "it is required to swim towards a fixed target over 300 time - steps , which requires being able to turn and swim straight .",
    "the low - level controller s sensory input consists of the joint angles , the angular velocities , and the velocities of the 6 segments in their local coordinate frames .",
    "the provisional high - level controller is also exposed to an egocentric ( i.e. , relative to the body frame ) representation of the target position .",
    "a shaping reward in the form of the negative of the distance to the target is given at every step .",
    "the modulatory input from the high - level controller to the low - level controller is updated every @xmath49 time steps .",
    "* analysis of the locomotor primitives * the training task is easily solved . to assess the locomotor primitives embodied by the learned low - level controller , we remove the high - level controller and modulate the low - level controller with i.i.d .",
    "gaussian noise sampled every 10 steps .",
    "the resulting behavior , obtained by initializing the swimmer at the origin in a random configuration and running for 4000 time steps , is shown in figure [ fig : swimmernoise ] .",
    "using the center of the most anterior body segment as a reference point , swimming trajectories are shown .",
    "clearly , the locomotor primitives produce coherent swimming behavior , and the nature of the input noise determines the structure of the behavior . in the absence of high - level modulation",
    ", the snake swims nearly straight ; increasing the amplitude of modulatory noise leads to more variable trajectories . for comparison",
    ", we also show the behavior elicited by the commonly used zero - mean i.i.d .  gaussian noise applied directly as motor commands , which produces barely any displacement of the body , even at high noise levels .",
    "the largest standard deviation we tested was 0.8 , which is large compared to the action range @xmath50 $ ] .",
    "* transfer task 1 : target - seeking * the first transfer task is a partially - observed target - seeking task with a sparse reward function ( see fig .  [",
    "fig : swimmertasks ] , left ) .",
    "the high - level controller egocentrically senses the vector from head to the green target region s center but only when the target center is within @xmath51 of the head direction . at the beginning of each episode , both the snake and target are deposited at random , with a minimum distance between them . to solve this task",
    ", the snake needs to learn a strategy to turn around until it sees the target and then swim towards it .",
    "each episode lasts 800 time steps , and reward is delivered when the snake s head is within the target region .",
    "* transfer task 2 : canyon traversal * the snake must swim through a simple canyon ( fig .  [ fig : swimmertasks ] , right ) .",
    "perceptual input to the high - level controller is given in the form of a @xmath52 pixel strip from an egocentric depth camera attached to the head .",
    "a positive reward is received when the swimmer has successfully navigated from start to end .",
    "an episode is terminated 25 steps after the snake s head has passed the canyon exit or after 3000 steps , whichever comes first .",
    "figure [ fig : swimmertransfer ] shows the results of using the low - level controller to solve the transfer tasks .",
    "both tasks are solved successfully when the learned motor primitives are harnessed . without pre - training the low - level controller , however , an end - to - end system fails to learn . in both tasks , rewards are sparse : i.i.d .",
    "gaussian exploration lacks the ability to make consistent progress in a given direction , so reaching the goals and receiving reward is highly unlikely ; thus , no learning gradient exists .",
    "-position of the anterior segment of the snake after initialization at the origin in a random configuration . without high - level modulatory input",
    "@xmath53 the snake swims mostly straight ; high - level modulation leads to more diverse trajectories . ,",
    "scaledwidth=100.0% ]    [ cols=\"^,^ \" , ]      in a final set of experiments , we applied the approach to a particularly challenging 27 degree - of - freedom control problem : the humanoid model shown in figure [ fig : humanoidtask ] . with 21 actuators",
    "the problem is much higher dimensional than the others .",
    "moreover , whereas the snake and quadruped are passively stable , keeping the humanoid from falling is a non - trivial control problem in itself .",
    "* pre - training task * the training task consists of a simple multi - task setup : in every episode the humanoid is initialized in a standing position facing in the direction of the x - axis and is required to either move straight , or follow a leftward or a rightward circle of a fixed radius ( 5 m ) . the reward function consists of a small quadratic control penalty , a positive constant stay - alive reward , the velocity in the desired direction ( forward or along the circle ) clipped at 2.5 m/s , and , for the circle tasks , a quadratic penalty for deviating from the desired distance to the center point of the circle .",
    "episodes last for up to 300 steps but are terminated when height of the humanoid falls below 0.9 m .",
    "the input to the low - level controller consists of proprioceptive features describing the configuration of the body relative to the model root ( torso ) and ground , and associated velocities .",
    "the high - level controller additionally receives the relative position of the target as input .",
    "the control interval for the high - level controller is @xmath49 .",
    "* analysis of the locomotor primitives * controlling the humanoid is a challenging problem and learning in the pre - training task is more sensitive to initial conditions and learning parameters than for the quadruped and snake .",
    "nevertheless , we obtained several well performing policies with some variability across the gaits .",
    "analyzing several of the associated low - level controllers in the same way as in the previous sections revealed that the locomotor primitives encode quite stable walking behaviors , typically taking hundreds of steps before falling ( fig .",
    "[ fig : humanoidtask]a ) .",
    "* transfer task : slalom * our transfer task consists of a slalom walk where the humanoid is presented with a sequence of virtual gates to pass through .",
    "a reward of 5 is given for passing a gate , and missing a gate results in termination of the episode .",
    "no other reward is given .",
    "after a gate has been passed , the next gate is positioned randomly to the left or the right of the previous one .",
    "the newly trained high - level controller receives the proprioceptive features provided to the low - level controller as input , as well as the relative position and orientation of the next gate .",
    "we trained high - level controllers to solve the transfer task using some of the pre - trained low - level controllers and obtained several good solutions in which the humanoid learned to actively navigate the gates .",
    "nevertheless , as expected from the already somewhat diverse set of solutions to the pretraining task , not all low - level controllers were equally suitable for solving the transfer task . and for a given low - level controller we further observed a much stronger sensitivity to the learning parameters and the initial conditions during transfer ( see also section [ sec : appendix : variability ] in the appendix ) .",
    "considering the complexity of the humanoid and the relatively small number of constraints imposed by the pre - training task this is , however , perhaps not too surprising .",
    "we expect that a richer , more constrained pre - training regime would lead to more uniformly versatile and robust low - level controllers .",
    "the notion that biological motor systems are hierarchical is ancient , dating to the 19th century @xcite . in the 20th century , bernstein promulgated the notion of hierarchical control through `` motor synergies , '' or stereotyped , multi - joint muscle activation combinations @xcite .",
    "more recently , the notion of spinal motor primitives has been forwarded by mussa - ivaldi and bizzi @xcite and others @xcite .",
    "motor primitives have resonated in robotics , especially as dynamic movement primitives @xcite , which are low - dimensionality attractor systems that can simplify the learning of robot movements , and hierarchical robot control abstractions date to at least the 1980s @xcite .",
    "modern control theorists have also considered abstract hierarchical architectures for manipulation @xcite and more bio - mechanical descriptions of locomotion @xcite .",
    "the reinforcement learning literature has also explored a wide variety of temporal abstractions that wrap low - level control into _ options _ @xcite or _ skills _",
    "@xcite . these temporal abstractions may be applied to motor control @xcite , may be transferred to new tasks @xcite , and may also incorporate information hiding principles @xcite .",
    "however , this prior work typically requires precise subgoals to be specified , and treats options or skills as atomic actions .",
    "in contrast , our low - level motor skills emerge organically from pre - training in the context of natural tasks ; and our high - level controller modulates these skills in a flexible manner to achieve its ends .",
    "recent work @xcite proposes an architecture for discovering temporally extended macro actions from scratch .",
    "we have provided a preliminary investigation of a hierarchical motor control architecture that can learn low - level motor behaviors and transfer them to new tasks .",
    "our architecture contains two levels of abstraction that differ both in their access to sensory information and in the time scales at which they operate .",
    "our design encourages the low - level controller to focus on the specifics of reactive motor control , while a high - level controller directs behavior towards the task goal by communicating a modulatory signal .",
    "our investigation departs from the common but unnatural setting where an agent is trained on a single task .",
    "instead , we exploit the fact that many complex motor behaviors share low - level structure by building reusable low - level controllers for a variety of tasks . we found our method to be especially effective when attempting challenging transfer tasks with sparse rewards where exploration via `` motor babbling '' is unlikely to accrue reward at all .",
    "this is illustrated in the transfer tasks for the swimmer , quadruped , and humanoid , in which direct end - to - end learning failed , but our method produced solutions .",
    "we believe that the general idea of reusing learned behavioral primitives is important , and the design principles we have followed represent possible steps towards this goal . our hierarchical design with information hiding has enabled the construction of low - level motor behaviors that are sheltered from task - specific information , enabling their reuse .",
    "however , the detailed individual and joint contributions of the features of our architecture remain to be investigated more thoroughly in future work ( in particular the role and relevance of different time scales ) , alongside strategies to increase the reliability and stereotypy of the low - level behaviors , especially for difficult control problems such as humanoid walking .",
    "our approach currently depends on the assumption that we can propose a set of low - level tasks that are simple to solve yet whose mastery in turn facilitates the solution of other high - level tasks . for motor behavior , we believe this assumption holds rather generally , as walking , for example , underpins a multitude of more complex tasks . by instilling a relatively small number of reusable skills into the low - level controllers",
    ", we expect that a large number of more complicated tasks involving composition of multiple behaviors should become solvable .",
    "we believe that this general direction could open new avenues for solving complex real - world , robotic control problems ."
  ],
  "abstract_text": [
    "<S> we study a novel architecture and training procedure for locomotion tasks . </S>",
    "<S> a high - frequency , low - level `` spinal '' network with access to proprioceptive sensors learns sensorimotor primitives by training on simple tasks . </S>",
    "<S> this pre - trained module is fixed and connected to a low - frequency , high - level `` cortical '' network , with access to all sensors , which drives behavior by modulating the inputs to the spinal network . </S>",
    "<S> where a monolithic end - to - end architecture fails completely , learning with a pre - trained spinal module succeeds at multiple high - level tasks , and enables the effective exploration required to learn from sparse rewards . </S>",
    "<S> we test our proposed architecture on three simulated bodies : a 16-dimensional swimming snake , a 20-dimensional quadruped , and a 54-dimensional humanoid ( see attached https://youtu.be/sbopyvhpraq[video ] ) . </S>"
  ]
}