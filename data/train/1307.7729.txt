{
  "article_text": [
    "networked systems , such as social , biological , and technological networks , have been the subject of much recent research activity  @xcite . along with many studies focusing on local properties of networks , such as clustering  @xcite , degree distributions  @xcite , and correlations  @xcite ,",
    "are studies that examine large - scale properties like path lengths  @xcite , percolation  @xcite , or hierarchy  @xcite . among large - scale network properties , however , the one attracting by far the most attention has been community structure  @xcite .",
    "many networks are found to possess communities or modules , groups of nodes within which connections are relatively dense and between which they are sparser .",
    "communities are of fundamental interest in networked systems because of their functional implications",
    " communities in a social network , for instance , may indicate factions , interest groups , or social divisions ; communities in a metabolic network might correspond to functional units , cycles , or circuits that perform certain tasks .",
    "the detection of communities in network data is also of interest from an algorithmic point of view .",
    "it is a remarkably challenging and subtle task for which a large number of approaches have been proposed . in this paper",
    "we examine two of the most widely used , the modularity maximization method  @xcite and the method of statistical inference by maximum likelihood  @xcite . in both of these approaches the community detection problem is mapped to one of optimizing a given objective function ( either modularity or likelihood ) over possible divisions of a network into groups , but the resulting optimization problem is , in general , a computationally hard one  @xcite , so one typically employs one of a range of polynomial - time heuristics to find approximate optima , such as markov chain monte carlo  @xcite , extremal optimization  @xcite , or greedy algorithms  @xcite .    in this paper",
    "we study one of the most elegant classes of heuristics for network optimization problems , the spectral algorithms , inherently global methods based on the eigenvectors of matrix representations of network structure .",
    "we show that both the maximum modularity and maximum likelihood methods for community detection can be formulated as spectral algorithms that rely on the eigenvectors of the so - called normalized laplacian matrix .",
    "we also describe a standard spectral algorithm for a third network problem , the well - known problem of normalized - cut graph partitioning .",
    "our primary finding is that the spectral algorithms for all three of these problems are identical . at least within the spectral approach taken here",
    ", there is no difference between the detection of community structure using the methods of maximum modularity and maximum likelihood , or between either and normalized - cut graph partitioning .",
    "the latter equivalence is of particular interest because graph partitioning has been studied in depth for several decades and a broad range of results both applied and theoretical have been established , some of which can now be applied to the community detection problem as well .",
    "the outline of this paper is as follows . in sections  [ sec :",
    "modularity ] , [ sec : inference ] and  [ sec : partitioning ] we derive in turn our spectral algorithms for the maximum modularity , maximum likelihood , and normalized - cut partitioning problems , which , as we have said , turn out all to be the same . in section",
    "[ sec : examples ] we give a selection of applications of the method to example networks , including both computer - generated benchmark networks and real - world networks , demonstrating its efficacy in community detection . in section  [ sec : conclusions ] we give our conclusions .",
    "in its most basic form , the problem of community detection in networks is one of dividing the vertices of a given network into nonoverlapping groups such that connections within groups are relatively dense while those between groups are sparse .",
    "as it stands , this definition is imprecise and leaves room for interpretation , and there have , as a result , been a large number of different methods proposed for solving the problem  @xcite . of these , however , probably the most widely used is the method of modularity maximization , in which the objective function known as modularity is optimized over possible divisions of the network  @xcite .",
    "the modularity for a given division of a network is defined to be the fraction of edges within groups minus the expected fraction of such edges in a randomized null model of the network .",
    "various null models have been used , but the most common by far is the so - called configuration model  @xcite , a random graph model in which the degrees of vertices are fixed to match those of the observed network but edges are in other respects placed at random .",
    "the expected number of edges falling between two vertices @xmath0 and @xmath1 in the configuration model is equal to @xmath2 , where @xmath3 is the degree of vertex  @xmath0 and @xmath4 is the total number of edges in the observed network .",
    "the actual number of edges observed to fall between the same two vertices is equal to the element  @xmath5 of the adjacency matrix  @xmath6 , so that the actual - minus - expected edge count for the vertex pair is @xmath7 . giving integer labels to the groups in the proposed network division and denoting by @xmath8 the label of the group to",
    "which vertex  @xmath0 belongs , the modularity  @xmath9 is then equal to @xmath10 \\delta_{g_ig_j } , \\label{eq : modularity1}\\ ] ] where @xmath11 is the kronecker delta .",
    "the leading constant  @xmath12 is purely conventional ; it has no effect on the position of the modularity maximum .",
    "the modularity can be calculated for divisions of a network into any number of groups , but for the purposes of this paper we will focus on the simplest case of division into just two groups , which is probably the most widely studied case .",
    "consider , then , a network of @xmath13  vertices and @xmath4  edges , which is to be divided into two groups of any size so as to maximize the modularity , eq .  .",
    "the modularity can be conveniently rewritten in terms of a set of @xmath13 `` ising spin '' variables  @xmath14 , one for each vertex , having values @xmath15 then @xmath16 and @xmath17 ( s_is_j+1 ) .",
    "\\label{eq : modularity2}\\ ] ] we define the quantity @xmath18 to be an element of a symmetric  @xmath19 matrix  @xmath20 , called the modularity matrix  @xcite .",
    "the modularity matrix has the crucial property that the sums of all its rows and columns are zero : @xmath21 where we have made use of @xmath22 and @xmath23 .",
    "thus eq .   can be written as @xmath24 the second term in the brackets vanishing because of  .",
    "the matrix elements  @xmath25 are fixed once the network is given , while the spins  @xmath14 represent the division of the network into groups .",
    "our task is to maximize  @xmath9 over the possible choices of the  @xmath14the values of @xmath14 that achieve the maximum indicate the optimal division of the network into communities .",
    "this is still a difficult computational task , known to be np - complete in general  @xcite , so the maximization is usually performed using approximate heuristics . in this paper",
    "we consider a spectral optimization strategy , similar in spirit to the spectral method proposed previously in  @xcite , but differing from it in one crucial detail .",
    "maximization of   is difficult because the variables  @xmath14 are discrete - valued .",
    "the problem can be made much easier by relaxing the discreteness and allowing the  @xmath14 to take any real values .",
    "this is an approximation  we will be solving a somewhat different problem from the one we really want to solve  but in practice it often gives good results .",
    "when we relax the  @xmath14 , however , we must still impose at least a minimal constraint on them to prevent them from becoming arbitrarily large , which would make  @xmath9 large but only in a trivial way that yields no information about community structure .",
    "most commonly one applies a constraint of the form  @xmath26 , which limits any individual  @xmath14 to the range @xmath27 and fixes the mean - square value at  1 .",
    "falling at the corner of a hypercube centered on the origin .",
    "the most common relaxation involves generalizing to values that lie anywhere on the bounding hypersphere that touches the cube at the corners ( blue ) . in this paper , however , we generalize instead to a bounding hyperellipsoid , which also touches the cube at its corners ( green).,width=226 ]    in the language of spin models , this would be called a `` spherical model ''  @xcite .",
    "one can think of it in geometric terms , as shown in fig .",
    "[ fig : relax ] .",
    "if we consider the variables  @xmath14 to be the elements of an @xmath13-element vector  @xmath28 , then the allowed values  @xmath29 in the original `` unrelaxed '' problem restrict the vector to the corners of an @xmath13-dimensional hypercube centered on the origin , while the relaxed values @xmath26 of the spherical model fall on the bounding hypersphere of radius  @xmath30 that touches the hypercube at each of its corners . thus the relaxed values include all the allowed values in the original problem , but also include many other values as well .",
    "while this spherical relaxation is the commonest approach to the spectral method , it is only one of an infinite number of possible relaxations , differing from one another in the details of the constraint used to prevent the values of the @xmath14 from diverging .",
    "for instance , rather than relaxing onto the bounding hypersphere , we can relax onto any hyperellipsoid that touches the hypercube at all of its corners .",
    "in other words , we can choose a constraint of the form @xmath31 for any set of nonnegative constants  @xmath32 .",
    "it is trivially the case that this constraint is satisfied by the unrelaxed values  @xmath29 .",
    "the standard hypersphere corresponds to  @xmath33 for all  @xmath0 , but in this paper we will find it convenient to make a different choice , leading to a spectral modularity optimization algorithm that is different in some important respects from previous algorithms .",
    "we set @xmath32 equal to  @xmath3 , the observed degrees of the vertices , so that our constraint takes the form @xmath34 where @xmath4 is again the number of edges in the network and we have made use of @xmath35 .",
    "although the original unrelaxed modularity maximization problem is a hard one to solve , this relaxed problem is much easier .",
    "it can be solved exactly by simple differentiation . applying the constraint   with a lagrange multiplier  @xmath36 ,",
    "the maximum is given by @xmath37 = 0.\\ ] ] performing the derivatives and rearranging , we find that @xmath38 or , in matrix notation , @xmath39 where @xmath40 is the diagonal matrix with elements equal to the vertex degrees  @xmath41 . in other words",
    "@xmath28 is a solution of a generalized eigenvector equation , with @xmath36 being the eigenvalue .    to determine which eigenvector we should take",
    ", we multiply eq .   by  @xmath14 and sum over  @xmath0 , making use of   and  , to get an expression for the modularity : @xmath42 to achieve the highest value of the modularity , therefore",
    ", we should choose  @xmath36 to be the highest ( most positive ) eigenvalue of the generalized eigenvector equation  .",
    "since all rows of the modularity matrix  @xmath20 sum to zero , it follows that eq .",
    "always has a solution  @xmath43 with eigenvalue  @xmath44 .",
    "this solution , with all @xmath45 , corresponds to putting all vertices in group  1 and none in group  2 , i.e. ,  not dividing the network at all .",
    "this tells us that if @xmath44 is the highest eigenvalue then the best modularity is achieved by not dividing the network at all  the calculation is telling us that there is no good division of the network into groups , so we should leave it undivided . in our previous work we called such networks `` indivisible . ''",
    "if , however , there is even a single strictly positive eigenvalue , then there will exist some nontrivial solution vector  @xmath28 that achieves a higher modularity than the undivided network .",
    "most , though not all , networks do have such a strictly positive eigenvalue , and we will assume this to be the case here .",
    "the solution above can be simplified further . using the definition   of the modularity matrix",
    ", we can rewrite eq .   as @xmath46 or in matrix notation as @xmath47 where @xmath48 is the vector with elements  @xmath3 and @xmath49 . noting that @xmath50 and @xmath51",
    ", we now multiply eq .   throughout by  @xmath52 to get @xmath53 , which implies either that the largest eigenvalue  @xmath36 is zero or that @xmath54 since we are assuming there exists a nontrivial eigenvalue @xmath55 , we know that @xmath56 and hence   applies , which in turn means that eq .",
    "simplifies to @xmath57 thus our solution vector  @xmath28 is also a solution of this generalized eigenvector equation , involving only the standard adjacency matrix .",
    "again we should choose the largest allowed value of  @xmath36 .",
    "now , however , the most positive eigenvalue is disallowed  it is straightforward to see that the uniform vector  @xmath58 is an eigenvector and by the perron - frobenius theorem it must have the most positive eigenvalue , since it has all elements positive . but this choice of eigenvector fails to satisfy eq .   and hence is forbidden , in which case the best we can do is choose the eigenvector corresponding to the second most positive eigenvalue ( which can easily be shown to satisfy  , as indeed do all the remaining eigenvectors ) .",
    "this eigenvector is precisely equal to the leading eigenvector of eq .  , and",
    "hence either   or   will give us the solution we seek .",
    "this is an exact solution of our relaxed modularity maximization problem . to get a solution to the original unrelaxed problem , in which @xmath14 is constrained to take only the values  @xmath59 ,",
    "the normal approach is simply to round the  @xmath14 to the nearest allowed value  @xmath59 . in practice",
    ", this just means that positive elements get rounded to  @xmath60 and negative elements to  @xmath61 .",
    "thus our final algorithm is a simple one : we calculate the eigenvector  @xmath28 of eq .",
    "corresponding to the second - highest eigenvalue , then divide the vertices of our network into two groups according to the signs of the elements of this vector .",
    "this is an approximation .",
    "it is not guaranteed to give an exact solution to the unrelaxed problem , but in many cases it does a good job , as we will later see .    as a practical matter ,",
    "the solution of the generalized eigenvector equation   is most straightforwardly achieved by defining a rescaled vector  @xmath62 , where @xmath63 is the diagonal matrix with diagonal elements equal to  @xmath64 . substituting into eq .   and rearranging",
    ", we then find that @xmath65 the matrix @xmath66 is symmetric , and thus @xmath67 is an ordinary eigenvector of a symmetric matrix , with elements having the same signs as those of  @xmath28 , and with the same eigenvalue .",
    "the spectral algorithm is thus a simple matter of calculating the eigenvector for the second - highest eigenvalue of this symmetric matrix and then dividing the vertices according to the signs of its elements . for sparse networks",
    "this can be done efficiently using sparse matrix methods such as the lanczos method .",
    "the matrix @xmath68 is sometimes called the normalized laplacian of the network and we will use that terminology here .",
    "( the normalized laplacian is sometimes defined as @xmath69 , where @xmath70 is the identity , but the two matrices differ only in a trivial transformation of their eigenvalues and the eigenvectors are the same for both . )",
    "we now turn to a second method for community detection in networks , the method of statistical inference using stochastic block models .",
    "this method has attracted attention in recent years for the excellent results it returns and because of the solid mathematical foundations on which it rests , which have allowed researchers to prove rigorously a range of results about its expected performance . indeed",
    "the method is provably optimal for certain classes of networks , in the sense that no other method will classify more vertices into their correct groups on average  @xcite .",
    "the simplest form of the method is based on the standard stochastic block model  @xcite , sometimes also called the planted partition model  @xcite , a random graph model of a network containing community structure .",
    "the model does not itself constitute a method for community detection .",
    "instead it provides a way of generating synthetic networks . to perform community detection ,",
    "one fits the model to observed network data using a maximum likelihood method in much the same way as one might fit a straight line through a set of points to estimate their slope .    while formally elegant , however , this method has been found to work poorly in practice .",
    "the standard stochastic block model generates networks whose vertices have a poisson degree distribution , quite unlike the degree distributions of most real - life networks , which means that the model is not , typically , a good fit to observed networks for any values of its parameters .",
    "the situation is akin to fitting a straight line through an inherently curved set of points  even the best fit will be a poor one because all fits are poor .",
    "we can get around this problem by employing a slightly more sophisticated model , the degree - corrected block model  @xcite , which incorporates additional parameters that allow the model to fit non - poisson degree distributions , improving the fit to real - world data to the point where the degree - corrected model appears to give good community inference in practical situations .",
    "the problem of fitting the degree - corrected block model to network data by likelihood maximization is , like the modularity maximization problem , a computationally difficult one in general , but it too can be tackled using approximate spectral methods , as we now describe . indeed , as we will see , the spectral algorithm for the degree - corrected model is ultimately identical to the one we derived for the maximum modularity problem in the previous section .    in the degree - corrected block model",
    "@xmath13 vertices are divided into groups and edges placed between them independently at random with probabilities that depend on the desired degrees of the vertices and on their group membership .",
    "let  @xmath8 again denote the label of the group to which vertex  @xmath0 belongs .",
    "then between each pair  @xmath71 of vertices we place a poisson - distributed number of edges with mean equal to  @xmath72 , where @xmath3 is the desired degree of vertex  @xmath0 and @xmath73 is a set of parameters whose values control the relative probabilities of connections within and between groups .",
    "if @xmath5 is again an element of the adjacency matrix of the observed network , equal to the number of edges between vertices  @xmath0 and  @xmath1 , then the probability , or likelihood , that this network was generated by the degree - corrected stochastic block model is @xmath74 where the desired degrees  @xmath3 are equal to the actual degrees of the vertices in the observed network .",
    "thus the likelihood of observing the network that we did in fact observe , assuming it was generated by this model , depends on the assignment of the vertices to the groups .",
    "for some assignments the network would be highly unlikely to have occurred ; for others it is more likely . in the maximum likelihood approach , we assume that the best assignment of vertices to groups is the one that maximizes the likelihood . this again turns the community detection problem into an optimization problem which , although hard to solve exactly , often has good approximate solutions that can be found with relative ease .    typically ,",
    "in fact , we maximize not the likelihood itself but its logarithm  @xmath75 , which has its maximum in the same place : @xmath76 , \\label{eq : loglike}\\ ] ] where we have switched to a sum over all @xmath71 and compensated with the leading factor of  @xmath77 , and we have assumed that the number of edges  @xmath5 between any pair of vertices is either one or zero so that @xmath78 for all @xmath71 .    as in section  [ sec : modularity ] , we will concentrate on the simplest case of a network with just two groups , and in addition we will assume ( as most other authors also have ) that there are just two different values for the model parameters : @xmath79  for pairs of vertices that fall in the same group and  @xmath80 for pairs in different groups , with @xmath81 for traditional community structure ( so - called assortative structure ) . introducing indicator variables  @xmath29 to denote group membership as we did in section  [ sec : modularity ] , we note that @xmath82 , \\\\ \\ln \\omega_{g_ig_j } & = \\tfrac12 \\biggl [ \\ln ( { \\omega_\\textrm{in}}{\\omega_\\textrm{out } } )                 + s_is_j \\ln { { \\omega_\\textrm{in}}\\over{\\omega_\\textrm{out } } } \\biggr].\\end{aligned}\\ ] ] substituting these expressions into eq .",
    ", we then find that @xmath83 where @xmath84 is a positive constant given by @xmath85 and we have dropped unimportant additive and multiplicative constants , which have no effect on the position of the likelihood maximum .",
    "our goal is now to maximize eq .   with respect to the variables  @xmath14 , but there is a problem : in most cases we do nt know the values of the parameters  @xmath79 and  @xmath80 and hence we do nt know  @xmath84 either .",
    "let us , however , suppose for the moment that we do know  @xmath84 and see where it leads us .",
    "equation   is closely similar in form to the modularity of eq .  , the only differences being a trivial leading constant , and the substitution of @xmath84 in the place of  @xmath12 when compared to the modularity matrix of eq .  .",
    "the similarities are sufficiently strong that we can use the same spectral approach to maximize   as we did for the modularity , and it turns out to give the same answer .",
    "we relax the variables  @xmath14 , allowing them to take any real values subject only to the elliptical constraint of eq .  , then introduce a lagrange multiplier  @xmath36 and differentiate to get @xmath86 or , in matrix notation , @xmath87 where @xmath40 is the diagonal matrix of degrees as previously .",
    "thus the solution to our relaxed maximization problem is an eigenvector of the matrix  @xmath88 and , by the same argument as before , we should choose the leading eigenvector .",
    "multiplying   on the left by  @xmath52 and making use of @xmath50 and @xmath51 , we get @xmath89 which implies either that @xmath90 or that @xmath91 .",
    "we are not at liberty , however , to choose any of the quantities @xmath36 , @xmath84 , or  @xmath4 , and hence can not in general satisfy the latter condition .",
    "hence we must have @xmath90 and eq .",
    "simplifies to @xmath92 which is identical to eq .   for the maximum modularity problem .",
    "note that the constant  @xmath84 has dropped out of the equation , so the fact that its value is unknown is , after all , not a problem .    from this point onward ,",
    "the argument is the same as for the maximum modularity problem and leads to the same result , that the optimal division of the network is given by the signs of the elements of the eigenvector of the normalized laplacian matrix of eq .",
    "corresponding to the second most positive eigenvalue .",
    "thus , within the spectral approximation used here , the maximum modularity and maximum likelihood methods for community detection are functionally identical and give identical results .",
    "we now turn to the third of the three problems mentioned in the introduction , the problem of normalized - cut graph partitioning , which , when tackled using the spectral method , we will show to be identical to the community detection problems of the previous sections . in a previous paper  @xcite",
    "we noted a mapping between maximum - likelihood community detection and the slightly different problem of minimum - cut partitioning , although that mapping requires an extra computational step not required by the mapping presented here .",
    "connections between graph partitioning and modularity maximization have also been noted previously  @xcite , although only for modified forms of the modularity and not for the standard modularity studied in this paper .",
    "traditional graph partitioning is the problem of dividing a network into a given number of parts of given sizes such that the cut size  @xmath93the number of edges running between parts  is minimized . in the most commonly studied case",
    "the parts are taken to be of equal size . in many situations ,",
    "however , one is willing to tolerate a little inequality of sizes if it allows for a better cut .",
    "focusing once more on the case of division into two parts , a standard way to achieve this kind of tolerance is to minimize not the cut size but the ratio cut  @xmath94 , where @xmath93 is again the cut size and @xmath95 and @xmath96 are the sizes of the two groups .",
    "the minimization is now performed with no constraint on the group sizes , but since @xmath97 is maximized when @xmath98 , the minimization still favors equally - sized groups , but it balances this favoritism against a desire for small cut size , and the compromise seems to work well in many practical situations .",
    "another variant on the same idea , which is particularly effective for networks that have broad degree distributions , as do many real - world networks , is minimization of the normalized cut  @xmath99 , where @xmath100 and @xmath101 are the sums of the degrees of the vertices in the two groups .",
    "this choice favors divisions of the network where the groups contain equal numbers of edges , rather than equal numbers of vertices , which is desirable in certain applications .",
    "it is on this normalized - cut partitioning problem that we focus in this section .",
    "the normalized - cut problem , like the other problems we have studied , is hard to solve exactly , but good approximate solutions can be found using spectral methods .",
    "the spectral approach given here is a standard one and is not new to this paper  see , for example , zhang and jordan  @xcite .",
    "as before , we define index variables  @xmath14 to denote the group membership of each vertex , but rather than the @xmath59 values we used previously , we define @xmath102{0pt}{9pt}\\phantom{- }          \\sqrt{\\kappa_2/\\kappa_1 } & \\qquad\\mbox{if $ i$ is in group~1 , } \\\\",
    "-\\sqrt{\\kappa_1/\\kappa_2 } & \\qquad\\mbox{if $ i$ is in group~2 , }        \\end{array } \\label{eq : spart}\\ ] ] where @xmath100 and  @xmath101 are again the sums of the degrees of the vertices in each group .",
    "note that this means that the values denoting the two groups change when the composition of the groups changes .    with this choice for the  @xmath14 , and using our previous notations  @xmath48 and @xmath40 for the vector and diagonal matrix of degrees respectively",
    ", we have @xmath103 and @xmath104 where @xmath4 is the number of edges in the network as before and the notation @xmath105 indicates that vertex  @xmath0 is a member of group  1 .    note also that @xmath106 meaning this quantity is nonzero only if @xmath0 belongs to group  1 . similarly @xmath107    using these results , we have @xmath108 where , as before , @xmath93  is the cut size between the two groups .",
    "but the quantity on the left can also be written in matrix form as @xmath109 where we have made use of @xmath110 , @xmath111 , and eq .  .",
    "combining eqs .   and  , we now have a matrix expression for the normalized cut : @xmath112 thus minimizing the normalized cut is equivalent to maximizing @xmath113 over choices of  @xmath14 satisfying  .",
    "this hard optimization problem is once more made easier by relaxation .",
    "we relax the requirement that the @xmath14 take the values in eq .",
    ", allowing them to take any real values subject only to the constraints   and  .",
    "the relaxed problem can then be solved straightforwardly by introducing lagrange multipliers @xmath114 for the two constraints and differentiating , which gives @xmath115 multiplying on the left by  @xmath52 and making use of @xmath116 gives @xmath117 which implies that @xmath118 because of eq .  , and",
    "hence we find once again that  @xmath28 is a solution of the generalized eigenvector equation @xmath119    using eqs .   and  , the optimal value of the normalized cut is then @xmath120 which is minimized by choosing @xmath36 as large as possible .",
    "the leading eigenvalue , however , is ruled out , since its eigenvector  @xmath58 fails to satisfy eq .",
    ", so once again our solution of the relaxed problem is given by the eigenvector corresponding to the second largest eigenvalue of eq .",
    "( which does satisfy  , as do all the other eigenvectors ) .",
    "reversing the relaxation process is a little more complicated in this case than in the previous cases we have studied , because the discrete values of  @xmath14 that we are rounding to , given by eq .",
    ", are not constant , but depend on the composition of the groups themselves . in principle , the most correct way to do it is to go through every possible division of the elements of the leading eigenvector , of which there are  @xmath121 , and find the one that gives the smallest value of the normalized cut . in practice , however , since we are looking for solutions with roughly equal group sizes , the values of @xmath100 and @xmath101 are also roughly equal , meaning that the discrete values of  @xmath14 are approximately  @xmath59 , and we can usually get good solutions by rounding to these values , which is equivalent to dividing vertices according to the signs of the vector elements . as we show in the next section , the divisions returned by the method are typically insensitive to the precise threshold value at which we divide the vector elements , so the results do not depend strongly on the rounding strategy chosen .    with this choice , which is the most common one , the algorithm becomes the same as the algorithms we have given for community detection , either by modularity maximization or the method of maximum likelihood .",
    "we have shown that three different problems  two - way community detection by maximum modularity and maximum likelihood , and normalized - cut bisection of a graph  can all be solved using the same spectral algorithm .",
    "we compute the leading eigenvector of the normalized laplacian matrix , eq .  , and divide vertices according to the signs of the vector elements . in this section",
    "we give some example applications of the algorithm to both computer - generated and real - world networks .",
    "vertices and within - group and between - group edge probabilities @xmath122 and @xmath123 respectively .",
    "the curves are , from left to right , for networks in which group  1 has size 1000 , 2000 , 3000 ,  , 9000 .",
    "( b )  similar curves for networks of @xmath124 vertices and equally sized groups , but with varying edge probabilities .",
    "the edge probabilities are given by @xmath125 , 65 , 70 , 75 , 80 , 85 , and  90 and @xmath126 . ]    figure  [ fig : sbm ] shows results from the application of the method to networks generated using the stochastic block model of section  [ sec : inference ] , which in addition to its use in community inference is also widely used as a benchmark test for community detection methods  @xcite .",
    "panel  ( a ) of the figure shows a series of curves representing the elements of the second eigenvector of eq .   in increasing order for single networks with two communities of varying sizes .",
    "the horizontal dashed line indicates the point at which the values of the elements pass zero  vertices on one side of this line are placed in the first group and vertices on the other side are placed in the second .",
    "each curve passes briskly through zero at a point close to the sizes of the two groups planted in the network  the size of the first group in this test was 1000 , 2000 , 3000 , and so on for each successive curve .",
    "this shows that the algorithm is capable of the accurate unsupervised detection of groups of a wide range of different sizes .",
    "moreover it shows that detection is robust against fluctuations ",
    "because the line is close to vertical as it passes zero , the division of the network is insensitive to changes in the cut point .",
    "if the dashed line were moved up or down , even by quite a large amount , very few vertices would change group membership .",
    "this observation provides some justification for our contention at the end of section  [ sec : partitioning ] that the exact choice of the cut point is unimportant .",
    "panel  ( b ) of the figure shows similar curves for stochastic block model networks with two equally sized groups ( which is the most challenging case ) but varying strength of community structure . when the structure is strongest the curves show a pronounced step at the half - way point , indicating robust detection of the equally sized communities , but the step becomes progressively smaller as the planted structure gets weaker , and eventually disappears completely , so that the curve becomes featureless .",
    "the point at which the step disappears coincides with the `` detectability threshold '' below which it is believed that all algorithms ( including this one ) must fail to detect community structure  @xcite .",
    "vertices generated from a stochastic block model with two equally sized groups and mean degree  50 .",
    "the vertical dashed line represents the position of the detectability threshold below which all community detection algorithms must fail this test  @xcite . ]",
    "figure  [ fig : lb ] further quantifies the algorithm s success at detecting community structure in block model networks .",
    "the figure shows the fraction of vertices classified into the correct groups for the same situation as in fig .",
    "[ fig : sbm]b  block model networks with @xmath127 and two equally sized groups , but varying strength of community structure . for most of the parameter range spanned by the figure the algorithm does a good job of putting vertices in the right groups .",
    "the vertical dashed line in the figure shows the position of the detectability threshold , below which we expect the algorithm ( and indeed all algorithms ) to return results no better than a random guess ( which means 50% of vertices classified correctly ) .",
    "as we can see , the algorithm does better than random all the way down to the transition point ( if only by a small margin in the region close to the threshold ) , which agrees with previous theoretical results finding that other spectral algorithms do the same  @xcite .",
    "also shown in fig .",
    "[ fig : lb ] are results for tests on the same networks of the more standard spectral community detection method of  @xcite , in which one examines the leading eigenvector of the modularity matrix .",
    "as the figure shows , the performance of the two algorithms , at least in this test , is essentially identical .",
    "figure  [ fig : examples ] shows example applications to two well - studied real - world networks , the dolphin social network of lusseau  _ et  al . _",
    "@xcite and the political book network of krebs  @xcite , both of which are believed to break clearly into two communities .",
    "the top two panels in the figure show the equivalent of the curves in fig .",
    "[ fig : sbm]values of the elements of the second eigenvector in increasing order .",
    "each shows a clear step where it crosses the zero line ( dashed lines in the plots ) and the groups generated by dividing the vertices at this point are shown in the lower panels . in both cases",
    "the groups correspond closely to the accepted ground truth for these networks .",
    "a further interesting example is given in fig .",
    "[ fig : polblogs ] , which shows an application of the method to a network of us political weblogs compiled by adamic and glance  @xcite .",
    "again this network is believed to divide strongly into two communities ( along lines of political outlook ) , and the algorithm finds the accepted division to a good approximation . in this case , however , the division was found by examining the _ third _ eigenvector of the normalized laplacian , not the second , as the developments of this paper would suggest .",
    "an examination of the second eigenvector reveals that it is entirely uncorrelated with the community structure in the network , instead being strongly localized around a few of the highest - degree vertices in the network  very large vector elements for these few hub vertices and small and apparently random elements for all other vertices .",
    "it is known that very high - degree vertices in networks can give rise to high - lying , localized eigenvectors  @xcite , by mechanisms quite different from those that produce the eigenvectors containing community structure , and the two types of high - lying eigenvectors may compete to be the highest in the overall spectrum .",
    "the network of political blogs has a particularly broad distribution of vertex degrees , with some degrees far above the network mean , which in this case is apparently enough to create an additional eigenvector with eigenvalue above that of the vector containing the community structure .",
    "nonetheless , the community structure is still there , clearly present in the third eigenvector . in practice",
    ", this means that application of the algorithm may not be quite as simple as our derivations suggest : it may require some finesse to extract useful community structure , particularly in the case of networks with very high - degree hubs .",
    "anecdotally , based on our experiments , we believe that the replacement of the second eigenvector with a localized vector related to network hubs may occur more frequently in the algorithm described in this paper than it does in more conventional algorithms based on the eigenvectors of the modularity matrix  @xcite , but this at present is merely conjecture .",
    "in this paper we have given spectral algorithms for the solution of three distinct network problems : community detection by modularity maximization , community detection by likelihood maximization using the degree - corrected block model , and normalized - cut graph partitioning .",
    "as we have shown , the algorithms for all three of these problems turn out to be the same , so that there is no difference , at least within the spectral formulation we use , between these three problems , although the algorithm described is different from standard spectral algorithms for modularity maximization described in the previous literature .",
    "we have given results from applications of the algorithm to a range of computer - generated and real - world networks , and it appears to perform well in practice .",
    "one clear possibility for extension of the calculations outlined here is their generalization to the case of networks containing more than two groups or communities .",
    "the fundamental techniques needed for such a generalization are known  @xcite  one replaces the index variables  @xmath14 of eq .   with vectors pointing to the corners of a ( possibly irregular ) simplex and the objective function ( modularity , likelihood , or normalized cut ) with the trace of a quadratic form involving the appropriate matrix . at present , however , a good all - purpose approach for community detection using such methods has yet to be found , and so the generalization to more than two communities must be considered an open problem .",
    "this work was funded in part by the national science foundation under grant dms1107796 and by the air force office of scientific research ( afosr ) and the defense advanced research projects agency ( darpa ) under grant fa95501210432 .",
    "u.  brandes , d.  delling , m.  gaertler , r.  grke , m.  hoefer , z.  nikoloski , and d.  wagner , on finding graph clusterings with maximum modularity . in _ proceedings of the 33rd international workshop on graph - theoretic concepts in computer science _ , number 4769 in lecture notes in computer science , springer , berlin ( 2007 ) .",
    "l.  yu and c.  ding , network community discovery : solving modularity clustering via normalized cut . in _ proceedings of the eighth workshop on mining and learning with graphs _ , pp .",
    "3436 , association of computing machinery , new york ( 2010 ) .",
    "d.  lusseau , k.  schneider , o.  j. boisseau , p.  haase , e.  slooten , and s.  m. dawson , the bottlenose dolphin community of doubtful sound features a large proportion of long - lasting associations .",
    "can geographic isolation explain this unique trait ?",
    "_ behavioral ecology and sociobiology _ * 54 * , 396405 ( 2003 ) ."
  ],
  "abstract_text": [
    "<S> we consider three distinct and well studied problems concerning network structure : community detection by modularity maximization , community detection by statistical inference , and normalized - cut graph partitioning . </S>",
    "<S> each of these problems can be tackled using spectral algorithms that make use of the eigenvectors of matrix representations of the network . </S>",
    "<S> we show that with certain choices of the free parameters appearing in these spectral algorithms the algorithms for all three problems are , in fact , identical , and hence that , at least within the spectral approximations used here , there is no difference between the modularity- and inference - based community detection methods , or between either and graph partitioning . </S>"
  ]
}