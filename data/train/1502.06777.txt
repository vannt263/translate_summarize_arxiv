{
  "article_text": [
    "the canonical polyadic decomposition ( cpd ) , which can be seen as one possible extension of the svd to higher - order tensors @xcite , is by now a well - established mathematical tool utilized in many scientific disciplines @xcite .",
    "as it requires only mild assumptions for being essentially unique , the cpd provides means for blindly and jointly identifying the components of multilinear models , which arise in many real - world applications ; see @xcite for some examples .    in particular , the computation of cpds having structured factors  such as vandermonde , toeplitz or hankel matrices  has been shown useful in problems including channel estimation @xcite , nonlinear system identification @xcite and multidimensional harmonic retrieval @xcite . as a consequence ,",
    "several special - purpose algorithms have been developed @xcite .",
    "+ in practice , the data tensor to be decomposed is always corrupted by noise . therefore , the assessment of the statistical performance of cpd computation algorithms via comparison with the cramr - rao bound ( crb ) @xcite is of practical interest , since it can guide the choice for an appropriate algorithm in application domains .",
    "furthermore , it can provide valuable information for the study and development of such algorithms .",
    "for the unstructured cpd , @xcite has derived the associated crb and presented an evaluation of the popular alternating least - squares ( als ) algorithm for tensors of orders three and four . regarding the structured case ,",
    "the crb for the estimation of a complex cpd with a particular vandermonde factor has been derived in @xcite , motivated by the problem of estimating the directions of arrival of multiple source signals .",
    "also , @xcite has provided a closed - form expression for the crb associated with the estimation of a cpd having hankel and/or toeplitz factors .",
    "+ this paper addresses the statistical evaluation of algorithms specialized in computing a cpd having banded circulant factors when applied to estimate the parameters of a wiener - hammerstein ( wh ) model , which is a well - known block - oriented model used for representing nonlinear dynamical systems @xcite .",
    "because many systems of practical relevance can be ( approximately ) described by the wh model , the problem of identifying its parameters from a set of experimental data ( _ i.e. _ , measured input and output samples ) is well - studied ; see , _ e.g. _ , @xcite and references therein .",
    "one possible approach , as described in @xcite , consists in estimating the wh model parameters by computing the structured cpd of a kernel of its equivalent volterra model . here",
    ", we derive a closed - form expression for the crb associated with this estimation problem , assuming the availability of a previously identified volterra kernel corrupted by white gaussian noise .",
    "then , we formulate specialized estimation algorithms based on the cp toeplitz ( cptoep ) and circulant - constrained als ( cals ) methods proposed in @xcite and evaluate their performance by comparing their mean - square error with the crb through monte carlo simulations .    * notation.*[sec : notation ] scalars are denoted by lowercase letters , _ e.g. _ @xmath0 or @xmath1 , vectors by lowercase boldface , _",
    "e.g. _ @xmath2 or @xmath3 , matrices by boldface capitals , _",
    "e.g. _ @xmath4 or @xmath5 , and higher order arrays by calligraphic letters , _",
    "e.g. _ @xmath6 .",
    "we use the superscripts @xmath7 for transposition , @xmath8 for pseudo - inverse , @xmath9 and @xmath10 denote the kronecker and khatri - rao products , respectively , and @xmath11 stands for the ( tensor ) outer product . the shorthand @xmath12 denotes @xmath13 , where @xmath14 appears @xmath15 times ; @xmath16 and @xmath17 are defined analogously . for our purposes , a tensor @xmath6 of order @xmath18",
    "will be assimilated to its array of coordinates , which is indexed by @xmath18 indices .",
    "its entries will be denoted by @xmath19 .",
    "the polyadic decomposition of a @xmath15th - order tensor is defined by @xmath20 where @xmath21 is the @xmath22 column of @xmath23 . the minimal value of @xmath24 such that @xmath6 can be written as in ( [ eq : cp ] )",
    "is called the rank of @xmath6 , in which case we refer to the above decomposition as the cpd of @xmath6 .",
    "another way of expressing is @xmath25 where @xmath26 is a @xmath15th - order diagonal tensor such that @xmath27_{r,\\ldots , r}=1 $ ] and @xmath28 denotes the mode-@xmath29 product ( see , _",
    "e.g. _ , ( * ? ? ?",
    "2.5 ) ) .",
    "the structure of a discrete - time wh model is as depicted in fig .",
    "[ fig : wiener - hamm ] .",
    "basically , it consists of a cascade connection comprising a memoryless nonlinearity @xmath30 `` sandwiched '' by two linear systems , @xmath31 and @xmath32 .",
    "because of its structured form constituted by fundamental blocks , the wh model is said to belong to the class of block - oriented models @xcite .    in this paper , we consider the time - invariant wh model constituted by a polynomial nonlinearity @xmath33 and by finite impulse response filters @xmath34 , with @xmath35 , and @xmath36 .",
    "hence , the resulting expression relating the input @xmath37 to the output @xmath38 is @xmath39^p .",
    "\\label{whmodel}\\ ] ] after some manipulation , this relation can be put in the equivalent volterra model form @xmath40 whose symmetric discrete - time volterra kernels are ( uniquely ) given by @xcite @xmath41 with @xmath42 , @xmath43 and @xmath44 .",
    "( 385,15)(-8,-15 )    ( 0,-15)(1,0)30 ( 5,-11)@xmath37 ( 30,-22)(35 , 14)@xmath31 ( 65,-15)(1,0)25 ( 90,-22)(40 , 14)@xmath30 ( 130,-15)(1,0)25 ( 155,-22)(35 , 14)@xmath32 ( 196,-11)@xmath38 ( 190,-15)(1,0)35      we now describe the wh model identification approach proposed in @xcite , which involves computing the cpd of a symmetric high - order volterra kernel .",
    "we start by noting that , being a function of multiple discrete indices , any @xmath15th - order symmetric volterra kernel @xmath45 of memory @xmath46 can be uniquely identified with a @xmath15th - order symmetric tensor @xmath47 defined by @xmath48 . owing to its convolutive form involving separable terms ,",
    "the kernel in can be identified with the tensor @xmath49 where @xmath50 $ ] , with @xmath51 denoting the @xmath52th canonical basis vector of @xmath53 , and @xmath54^t$ ] .",
    "expression is a symmetric cpd that can also be written as @xmath55 ,   \\label{x - matrix - cpd}\\ ] ] where @xmath56^t$ ] and @xmath57 \\in \\mathbb{r}^{m   \\times r}$ ] .",
    "note that the choice of which factor is postmultiplied by @xmath58 is irrelevant , due to the scaling indeterminacy .",
    "we thus conclude that the wh model has equivalent symmetric volterra kernels whose cpd are constituted by circulant factors @xmath59 and a factor of the form @xmath60 , which absorbs the scaling coefficients @xmath61 and @xmath62 .     as the factors in contain the parameters of the linear blocks of the wh model , the above observations suggest the following three - step procedure for its identification : ( i ) estimate @xmath45 from an available set of input / output samples , using some volterra kernel identification method ( as , _",
    "e.g. _ , @xcite ) , ( ii ) compute the structured cpd from the associated symmetric tensor @xmath6 and ( iii ) estimate the coefficients @xmath63 , @xmath64 , in the least - squares sense as explained in @xcite .",
    "note that this requires choosing some @xmath65 , since otherwise the model is not identifiable : for @xmath66 , it is a vector containing sums of products of coefficients @xmath61 , @xmath62 and @xmath67 ; for @xmath68 , we have a bilinear decomposition , which is only unique under restrictive assumptions ( such as orthogonality ) .",
    "henceforth , we assume that ( i ) has been accomplished and focus on step ( ii ) .",
    "let us consider that a @xmath15th - order tensor has been constructed from a non - null estimated kernel @xmath45 , as described in the previous section",
    ". in practice , it is evident that such a tensor satisfies @xmath69 , where @xmath70 is an error tensor accounting for the inevitable uncertainties which arise in the data - driven kernel estimation procedure .",
    "furthermore , since @xmath71 is symmetric in @xmath72 , in practice one estimates only the elements whose indices pertain to a suitable non - redundant domain such as @xmath73 , determining the others by symmetry .",
    "hence , @xmath74 and @xmath70 are also @xmath15th - order symmetric tensors , containing redundant elements . introducing the selection matrix @xmath75 , where @xmath76 , which contains as rows is of no consequence for our purposes . ]",
    "every product of the form @xmath77 for @xmath78 , we can write the ( non - redundant ) vectorized model @xmath79 where @xmath80 and @xmath81 is a random vector . now , from",
    ", we can deduce @xmath82 \\mathbf{w}^{{\\boxtimes}p }   \\\\                    = &",
    "\\left [ g_p \\sum_{r=1}^r h_{r-1 } \\mathbf{\\phi}_r \\right ]   \\mathbf{w}^{{\\boxtimes}p }                    = \\mathbf{\\phi}(\\mathbf{h } ) \\mathbf{f}(\\mathbf{w } ) ,   \\label{vec - x}\\end{aligned}\\ ] ] where @xmath83 is given by the term between brackets , in which @xmath84 , and @xmath85 .",
    "our problem can therefore be expressed as that of estimating the parameters @xmath61 , @xmath86 and @xmath87 of the wh model from observations which satisfy @xmath88 .",
    "we assume that the random vector @xmath89 has zero - mean i.i.d .",
    "components drawn from the gaussian distribution with variance @xmath90 .      due to the inherent scaling indeterminacy of our model , its local identifiability",
    "is only guaranteed with further assumptions . to eliminate this indeterminacy , we assume @xmath91 , which is sufficient due to the model structure . note that this entails no loss of generality , as @xmath87 and the other coefficients @xmath67 can be rescaled accordingly . defining now @xmath92 such that @xmath93^t$ ] ,",
    "we can write the parameter vector of the wh model as @xmath94^t \\in \\mathbb{r}^{m}$ ] . global identifiability , on the other hand , is related to the uniqueness of the structured cpd .",
    "as the @xmath95-rank @xcite of @xmath59 equals @xmath24 , uniqueness follows from kruskal s condition ( * ? ? ?",
    "3.2 ) if @xmath96 ( which implies that the @xmath95-rank of @xmath97 is @xmath24 ) and @xmath98 .",
    "if @xmath99 , then the @xmath95-rank of @xmath97 equals zero ; in this case , kruskal s condition is only met for @xmath100 if @xmath101 and for @xmath102 if @xmath103 .      in this section , we briefly review two methods that can be used to estimate the parameters @xmath104 of a model of the form .",
    "the first method consists of a specialization of the well - known alternating least squares ( als ) algorithm in which the factor matrices of the cpd are constrained as in . in the case of a cpd involving only circulant factors , such strategy has already been followed in @xcite , leading to the cals algorithm . here , we adapt that algorithm for our purposes .",
    "initially , we define @xmath105 \\in \\mathbb{r}^{m \\times r}$ ] , for @xmath106 , and @xmath107 $ ] . with these definitions , we have @xmath108 .",
    "next , we note that any flat matrix unfolding of @xmath74 can then be written as @xmath109 where the above approximation is due to the presence of noise and the operator @xmath110 is defined such that , @xmath111 @xmath112^t$ ] with @xmath113 , @xmath114 $ ] . using the property @xmath115 , we have also @xmath116 . hence , given current estimates @xmath117 and @xmath118 , we can update them with the scheme @xmath119^{-1 } \\right\\ } , \\\\",
    "\\text{(ii ) } \\ & \\hat{\\mathbf{w}}^{k+1 } =   \\frac{1}{\\left[\\hat{\\mathbf{v}}^{k+1}\\right]_1 } \\ , \\hat{\\mathbf{v}}^{k+1 } , \\\\",
    "\\text{(iii ) } \\ & \\hat{\\mathbf{h}}^{k+1 } =     \\left ( { \\hat{\\mathbf{w}}^{k+1 } } \\odot \\hat{\\mathbf{c}}^{k+1 } \\right)^\\dagger   { \\text{vec}}(\\mathbf{y}),\\end{aligned}\\ ] ] where @xmath120 $ ] and @xmath121 .",
    "note that , to derive ( i ) , we have used @xmath122 .    as stopping criteria",
    ", one can check whether the relative difference between two consecutive values of the reconstruction error @xmath123 falls below some fixed threshold @xmath124 or a maximum number of iterations @xmath125 is attained .",
    "since the objective is multimodal , the main goal is to find a good approximation of the solution by using a _ low - complexity _ algorithm . in @xcite ,",
    "non - iterative procedures have been proposed , which are able to compute the _ exact _",
    "cpd when matrix factors are banded or structured .",
    "consider a matrix unfolding of @xmath74 under the form : @xmath126 , where the structure of @xmath127 is ignored , and where @xmath128 are assumed toeplitz circulant of same size @xmath129 , that is , they can each be expressed in the orthonormal basis @xmath130 defined in section [ sec : cals ] : let @xmath131 denote the svd of @xmath132 .",
    "then there exists a matrix @xmath133 such that @xmath134 and @xmath135 .",
    "following the lines of @xcite , one can find matrix @xmath133 and coefficients @xmath136 by solving a linear system of @xmath137 equations in @xmath138 unknowns .",
    "if there are more equations than unknowns and if the system has full rank @xmath24 , the solution @xmath139 is unique .",
    "first , coefficients @xmath140 and @xmath141 are obtained from the best rank-1 approximation of matrix @xmath142 , which eventually yields estimates @xmath143 and @xmath144 .",
    "next , we calculate @xmath145 , and the estimate of @xmath87 is obtained as in stage ( iii ) of the cals algorithm .",
    "the algorithm described above is suboptimal for several reasons : ( a )  the model is noisy , ( b )  the @xmath15 factor matrices are assumed to be independent , whereas they are not , and ( c )  the structure of @xmath146 is ignored .",
    "hence the solution obtained will be inaccurate , but can be easily refined by a quasi - newton algorithm , as will be subsequently shown .",
    "if we assume that @xmath147 contains deterministic parameters associated with a system of interest , we have that the ( vectorized ) measured kernel satisfies @xmath148 where @xmath90 denotes the variance of the elements of @xmath89 .",
    "hence , the mean - square error ( mse ) of any locally unbiased estimator @xmath149 satisfies @xmath150 where the crb matrix @xmath151 can be computed by applying the slepian - bangs formula , which yields @xcite @xmath152 where @xmath153 is the jacobian matrix given by @xmath154   = \\left [ \\frac{\\partial \\mathbf{x}}{\\partial \\tilde{\\mathbf{w } } } \\ \\",
    "\\frac{\\partial \\mathbf{x}}{\\partial               \\mathbf{h}}\\right].\\ ] ]    from and the definition of @xmath155 , we have @xmath156,\\end{aligned}\\ ] ] in which @xmath157 ( with the convention @xmath158 ) .",
    "to derive @xmath159 , we first apply the property @xmath160 to write @xmath161 leading thus to @xmath162.\\ ] ]    in order to identify the contribution of @xmath86 and @xmath87 in @xmath163 and @xmath164 , we propose to extend the results presented in  @xcite by using oblique projection .",
    "this is the purpose of the following proposition .",
    "we denote by @xmath165 the oblique projection whose range is @xmath166 and whose null space contains @xmath167 ( see  @xcite for details ) .",
    "the closed - form expression for the crb of @xmath168 is given by : @xmath169 where @xmath170 is the @xmath95th column of @xmath171 and @xmath172 is the submatrix of @xmath171 obtained by removing its @xmath95th column .",
    "similarly , the closed - form expression for the crb of @xmath62 is : @xmath173 where @xmath174 is the @xmath175th column of @xmath176 and @xmath177 is the submatrix of @xmath176 obtained by removing its @xmath175th column .    the proof is omitted due to the lack of space .",
    "to illustrate the utility of the derived crb , we now present some monte carlo simulation results .",
    "specifically , we evaluate several estimators when applied to identify a wh model with parameters @xmath1781 0.538 1.834 -2.259 0.862@xmath179^t$ ] , @xmath1801.594 -6.538 -2.168@xmath179^t$ ] from estimates of the equivalent symmetric third - order kernel @xmath6 , proceeding as follows . for each realization of the ( symmetric ) noise tensor @xmath70 , we vary @xmath90 and then construct a data tensor @xmath181 for each chosen level of @xmath90 .",
    "next , we compute estimates @xmath182 given by : ( i ) the family of estimators @xmath183-cals , which consist in applying @xmath183 times the algorithm of section [ sec : cals ] with random initializations and keeping the best solution in terms of reconstruction error ( w.r.t .",
    "@xmath74 ) ; ( ii ) the estimator cptoep , described in section [ sec : cptoep ] ; ( iii ) the estimator cptoep - cals , which corresponds to refining the cptoep estimate by applying the cals algorithm ; ( iv ) the estimator cptoep - bfgs , in which a similar refinement is obtained by minimizing a least - squares criterion ( w.r.t .",
    "@xmath74 ) with the broyden  fletcher  goldfarb  shanno ( bfgs ) algorithm @xcite .",
    "the maximum number of iterations established for cals and bfgs is @xmath184 .",
    "we choose @xmath185 and set the tolerance of bfgs also as @xmath186 . for each estimate @xmath187 ,",
    "we compute @xmath188 .",
    "this procedure is repeated for 100 realizations of @xmath189 and then @xmath190 is averaged for each level of @xmath90 , yielding a mean - square error estimate denoted by mse@xmath191 .",
    "= 0.15 cm    .simulation results : estimated mse@xmath191 values ( in db ) .",
    "[ cols=\"^,^,^,^,^,^,^ \" , ]     the results are shown in table [ tab : scen-1 ] , as well as the computed values of the crb .",
    "one can see that 1-cals has a very poor performance , due to its frequent premature termination or inability to converge .",
    "although 5-cals performs better , its results are degraded for the same reasons .",
    "cptoep , in its turn , performs slightly worse than 10-cals , but attains a similar level when refined by cals . yet",
    ", there remains a gap between their mse curves and that of the crb .",
    "indeed , only cptoep - bgfs attains an mse close to the crb .",
    "note that a similar gap has been reported by @xcite for the als algorithm . along the lines of their discussion , we believe that , in the case of cals , this gap is due to the convergence problems which are always observed in practice , at least for a few runs .",
    "as for cptoep , this seems to happen because the adapted procedure yields suboptimal estimates .",
    "finally , we note that the above comparison is justified since , under the assumption of gaussian additive noise , the least - squares criterion leads to the maximum likelihood ( ml ) estimator . in signal - in - noise problems ,",
    "the ml estimator is often approximately unbiased even for a small sample size , provided that the snr is sufficiently high @xcite .",
    "a closed - form expression of the crb has been derived for the parameter estimates of a cpd having identical banded circulant factors , one of which is post - multiplied by a diagonal scaling matrix .",
    "then , two specialized algorithms have been proposed to compute a cpd with that structure .",
    "the first , named cals , is an adaptation of the als method taking the structural constraints into account , whereas the second is composed of two steps : ( i ) compute an approximate solution thanks to a non iterative algorithm ( cptoep ) , and ( ii ) refine the solution via cals or via a quasi - newton descent ( bfgs ) .",
    "the latter ( cptoep - bfgs ) reached the cramr - rao bound over a wide range of snr values .",
    "the proposed algorithms have been applied to identify a wh model , and their statistical performance has been evaluated using the derived crb .            c.  e.  r. fernandes , g.  favier , and j.  c.  m. mota , `` blind channel identification algorithms based on the parafac decomposition of cumulant tensors : the single and multiuser cases , '' , vol .",
    "88 , no . 6 , pp .",
    "13821401 , 2008 ."
  ],
  "abstract_text": [
    "<S> the computation of a structured canonical polyadic decomposition ( cpd ) is useful to address several important modeling problems in real - world applications . in this paper , we consider the identification of a nonlinear system by means of a wiener - hammerstein model , assuming a high - order volterra kernel of that system has been previously estimated . </S>",
    "<S> such a kernel , viewed as a tensor , admits a cpd with banded circulant factors which comprise the model parameters . to estimate them , we formulate specialized estimators based on recently proposed algorithms for the computation of structured cpds . </S>",
    "<S> then , considering the presence of additive white gaussian noise , we derive a closed - form expression for the cramer - rao bound ( crb ) associated with this estimation problem . </S>",
    "<S> finally , we assess the statistical performance of the proposed estimators via monte carlo simulations , by comparing their mean - square error with the crb .    </S>",
    "<S> tensor decomposition , structured cpd , cramr - rao bound , wiener - hammerstein model </S>"
  ]
}