{
  "article_text": [
    "privacy preserving data mining ( ppdm ) and statistical disclosure control ( sdc ) are two active areas of research that study how to avoid disclosure of sensitive information when data is released to third parties for their analysis .",
    "one of the existing approaches for ensuring privacy consists of manipulating the datafile adding some noise or reducing the quality of the information .",
    "several data protection methods have been developed in this direction .",
    "noise addition , microaggregation , rank swapping and pram are some of the existing methods . in general , these methods consists of transforming a data file @xmath0 by means of a masking method @xmath1 into a new data file @xmath2 .",
    "that is , the masking method returns @xmath3 .",
    "methods reduce the disclosure risk at the expenses of some information loss . in other words ,",
    "the results from an analysis of @xmath0 will in general give different results than an analysis of @xmath2 . with the aim of quantifying this loss ,",
    "several information loss measures have been defined in the literature .",
    "nevertheless , although the function @xmath1 inflicts a perturbation in the data that causes some information to be lost , the modification of the data may be insufficient for ensuring privacy .",
    "due to this , disclosure risk measures have been defined and studied in the literature .",
    "disclosure risk measures can be defined in terms of re - identification .",
    "this corresponds to identity disclosure .",
    "re - identification algorithms permit us to model the situation in which an adversary wants to attack a published data set using some information that he has available .",
    "the adversary tries to link his information expressed as records in a datafile with the records in the published data set .",
    "the more records he reidentifies , the larger the risk . therefore , given a particular file ,",
    "the proportion of reidentified records is a measure of the risk .",
    "the concept of re - identification is also the cornerstone of the theory of @xmath4-anonymity .",
    "a dataset is @xmath4-anonymous if for each record in the dataset , there are other @xmath5 records that are equal to it .",
    "nevertheless , as pointed out in  , the important question here is not whether the records have the same or different values , but that the records are indistinguishable in the re - identification process ( when the adversary attacks the dataset ) .",
    "this idea permitted us in  @xcite to define @xmath6-confusion as an alternative to @xmath4-anonymity which provides the same level of anonymity without requiring records to have the same values .    because of that , re - identification algorithms are fundamental in data privacy and the literature presents several algorithms for re - identification  .",
    "the literature also discusses some models   for re - identification that are used to determine the parameters of the algorithms .",
    "nevertheless , up to our knowledge , there is no approach for how to formalize and determine correctness of re - identification algorithms .",
    "that is , there is no discussion on what a proper and correct re - identification algorithm is , and what kind of result a correct re - identification algorithm should give .    in this paper",
    "we present a formalization of re - identification in terms of belief functions and true probabilities .",
    "the basic idea is that a good re - identification algorithm , given some information , a probability distribution over a population .",
    "if we assume that this re - identification algorithm behaves correctly , then it can not return any probability distribution but must return a distribution that is compatible with the true one .",
    "in addition , we would expect that the more information we have available , the more the probability of the algorithm should resemble the true one .    in this paper we model",
    "this situation in terms of belief functions   and the transferable belief model  @xcite .",
    "departing from a true probability , we define two types of re - identification algorithms . first , we define a re - identification algorithm as one that returns a belief function that is compatible  @xcite with the true probability , and later as one that returns the pignistic transformation of a belief function that is compatible with the true probability .",
    "the structure of the paper is as follows . in section  [ sec:2 ]",
    "we review some concepts that are needed later in this work .",
    "in particular , we discuss belief functions and re - identification algorithms . in section  [ sec:4 ] ,",
    "we introduce our model and discuss some relevant results about it .",
    "the paper finishes with some conclusions .",
    "this section is divided into three parts . in the first part we review some concepts related to belief functions , a model for approximate reasoning .",
    "we will use belief functions to construct a model for record linkage . in the second part we review k - anonymity , one of the approaches in data masking .",
    "belief functions can be used to represent uncertainty with respect to probability distributions .",
    "we will not go into the details of their justification .",
    "the description in this section focuses on the concepts we need in the rest of the paper . for details and additional discussion",
    "see e.g.  .",
    "[ def : chmeas : bel ] a set function @xmath7 $ ] is a _",
    "belief function _ if and only if it satisfies    1 .",
    "@xmath8 , @xmath9 ( boundary conditions ) 2 .",
    "@xmath10 implies @xmath11 ( monotonicity ) 3 .   for all @xmath12",
    ", @xmath13    belief functions are closely related to basic probability assignments .",
    "there is a basic probability assignment for each belief function , and a belief function for each basic probability assignment .",
    "a function @xmath14 $ ] is a _ basic probability assignment _ if and only if    ( i ) : :    @xmath15 ( ii ) : :    @xmath16    there exist two names for this function in the literature : basic probability assignment ( e.g. in  @xcite ) and basic belief assignment ( e.g. in  @xcite ) . in the rest of the paper",
    "we will say just assignment .",
    "the following proposition establishes the relationship between assignments and belief functions .",
    "let @xmath17 be a belief function defined on the reference set @xmath0 , then the function @xmath18 defined below is a basic probability assignment @xmath19 : @xmath20 let @xmath19 be a basic probability assignment , then , the function @xmath21 defined below is a belief function @xmath22    belief functions generalize probabilities . in particular ,",
    "when @xmath23 for all @xmath24 such that @xmath25 , then @xmath17 is a probability . in this case",
    ", the assignment @xmath19 to the singletons is the probability distribution .",
    "that is , @xmath26 for all @xmath27 , and then @xmath28 for all @xmath29 .    as stated before",
    ", belief functions can represent uncertainty in probability distributions .",
    "they permit to differentiate situations which standard probabilities can not .",
    "for example , total ignorance in a set @xmath0 is modeled defining @xmath30 and @xmath23 for all @xmath31 .",
    "in contrast , when we know that the elements in @xmath0 all have the same support we assign @xmath32 for all @xmath33 . note that this is different from the case of standard probabilities where both situations are represented by @xmath34 for @xmath33 .    given a belief function @xmath17 defined from @xmath19 ,",
    "dempster defined the pignistic transformation as a function that finds a probability distribution from @xmath17 .",
    "this pignistic transformation is based on the transferable belief model by smets  @xcite that distinguishes between the credal and the pignistic level .",
    "the credal level is where beliefs are taken into consideration and operated on , and the pignistic level is where beliefs are used .",
    "although we do not understand probabilities and beliefs as subjective , as smets does , both levels are appropriate for modeling re - identification .",
    "an ideal re - identification algorithm will compute belief functions in the credal level , with the minimal possible commitments in case of uncertainty .",
    "then , when decisions are to be made , we move to the pignistic level and probabilities are made concrete .",
    "[ def : pignistictransformation ] let @xmath17 be a belief function , then we define the pignistic probability distribution derived from @xmath17 , @xmath35 , as : @xmath36      formally , given a data set @xmath0 , a masking method @xmath1 constructs a data set @xmath3",
    ". data privacy studies masking methods that return datasets which can be released to third parties in a way that avoids disclosure of sensitive information , but preserves the value of the data as material for analysis .",
    "one of the existing concepts for data privacy is @xmath4-anonymity .",
    "a dataset satisfies @xmath4-anonymity when for each record there are @xmath5 other records that are indistinguishable in the dataset .",
    "several algorithms have been proposed in the literature to build a dataset compliant with @xmath4-anonymity through generalization , suppression and clustering .",
    "for example , if we have 6 records with values 18,16,19,22,24,24 for attribute",
    "@xmath37 , we can consider the intervals [ 15,19],[20,25 ] and then recode the original values according to these intervals .",
    "doing so , we will have three in the interval [ 15,19 ] and three other in the interval [ 20,25 ] .",
    "this ensures @xmath4-anonymity for @xmath38 if only this sole attribute is discussed .",
    "we will use @xmath39 to denote a method that ensures @xmath4-anonymity for a single attribute @xmath40 using generalization for some appropriate value @xmath4 .",
    "given a dataset @xmath0 , a protection method @xmath1 , and the protected dataset @xmath3 , disclosure risk can be measured in terms of the number of records in @xmath2 that can be correctly reidentified .",
    "indeed , a common approach when constructing re - identification algorithms is to optimize with respect to this criterion  @xcite .",
    "nevertheless , although formalizations of the expected outcome of these algorithms exist ( i.e. , we expect a method to maximize the number of correct links ) , no formalization exists on what we mean when we say that a re - identification method is correct .",
    "we would like a formalization that excludes re - identification methods which perform incorrect re - identifications . in this paper",
    ", we discuss a formalization based on belief functions and a true probability .",
    "we will base our discussion on a previous definition of re - identification algorithms used to define @xmath6-confusion in  @xcite .",
    "the definition is as follows .",
    "[ def : reidentification ] @xcite let @xmath1 be a method for anonymization of databases , @xmath0 a table with @xmath6 records indexed by @xmath41 in the space of tables @xmath42 and @xmath3 the anonymization of @xmath0 using @xmath1 .",
    "then a re - identification method is a function that , given a collection of entries @xmath43 in @xmath44 and some additional information from a space of auxiliary informations @xmath24 , returns the probability that @xmath43 are entries from the record with index @xmath45 , @xmath46^{n}\\\\\\\\ & ( y , a ) & \\mapsto & \\left(p(y \\textrm { corresponds to record } x[i ] ) : i\\in i\\right ) . \\end{array}\\ ] ] consider the objective probability distribution corresponding to the re - identification problem . then , we require from a re - identification method that it returns a probability distribution that is compatible with this probability , also when missing some relevant information .",
    "compatibility can be modeled in terms of compatibility of belief functions ( see ) .",
    "section  [ sec:4 ] discusses re - identification algorithms and the compatibility issue mentioned above .",
    "before , we review some of the approaches that can be found in the literature on record linkage . recall that we have defined record linkage in terms of the probability that @xmath43 , the protected record , are entries from the record with index @xmath47 , and we denote this by @xmath48 $ ] .    as we will see , for some methods we can understand probabilities as following a bayesian objective approach , and for other methods as subjective probabilities . in the latter case , we can understand the probabilities as votes .",
    "some of the methods described below are not completely formalized in the literature , so the formulation is ours .    * * @xmath4-anonymity and re - identification . *",
    "re - identification methods applied to @xmath4-anonymous databases return for each @xmath43 a list of possible records @xmath49 that are possible matches of the given record .",
    "+ on the basis of the principle of insufficient reason ( or principle of indifference ) this can be modeled by means of a uniform distribution over the records in @xmath50 .",
    "that is , @xmath48 = 1/|{\\cal j}|$ ] for all @xmath51 .",
    "+ an alternative model , not previously considered in the literature up to our knowledge , is to consider belief functions",
    ". this will be the subject of this article , and example  [ ex : kanon.probs.belief ] focuses on the use of belief functions for their use in @xmath4-anonymity . * * probabilistic record linkage . *",
    "the mathematical model formalized by fellegi and sunter in 1969  @xcite is based on a probabilistic model that computes the probability of a particular coincidence pattern @xmath52 conditioned by the existence of a match : @xmath53 .",
    "probabilistic record linkage returns the probability of a correct match given a particular coincidence pattern ( i.e , @xmath54 ) .",
    "the bayes rule is used in this process .",
    "this situation can be modeled by @xmath55 = p(match|\\gamma(y , x_i)).\\ ] ] * * specific attacks to data protection methods . *",
    "the approach to attack rank swapping in  @xcite can be represented in terms of a list of candidates , in the line of the re - identification methods for @xmath4-anonymity as described above",
    ". re - identification attacks for rank swapping @xmath56-buckets can be modeled by means of probabilities .",
    "* * distance - based record linkage .",
    "* some literature exists where re - identification methods assign to each record in one file the most similar record ( at a minimum distance ) in the other file . in this case",
    ", probabilities can be defined from the distances , but such assignments should typically be only interpreted as voting or indications for subjective probabilities .",
    "@xcite is an exception to this , where a real probability is estimated taking into account the similarity between records .",
    "in this section we analyse the concept of re - identification further . in definition",
    "[ def : reidentification ] , re - identification is a function that , given some partial information on @xmath2 and some additional information , returns a probability distribution on the set of records .    we claim that this probability distribution should be compatible with the true probability .",
    "our motivation is to create a theoretical foundation for disclosure risk evaluation .",
    "the formalization will leave aside those re - identification algorithms that do not satisfy some minimum requirements .",
    "in particular , we will not approve algorithms that deliver incorrect results on purpose , and we will force algorithms to perform as well as possible , according to the evidence found in the data and any a priori knowledge . for the purpose of risk evaluation , using the worst case scenario ,",
    "this implies no loss of generality .    in this section ,",
    "we introduce a formalization that relies on a true probability of re - identification .",
    "this true probability corresponds to the case in which we know _ everything _ about the whole anonymization process , and assuming this information is used in the re - identification process .",
    "that is , the true probability only includes the uncertainty that can not be removed because e.g. randomness .",
    "we would expect that the re - identification process leads to a probability that is less informative than the true probability in case of uncertainty , e.g. on the masking process or on the data available for re - identification .",
    "examples of such uncertainty could be that some variables are not included in the risk analysis , or that part of the masking process is not disclosed and can not be taken into account in the risk analysis .",
    "nevertheless , uncertainty does not justify all probability distributions .",
    "only some of them are valid . as an extreme example",
    ", we can not accept as a re - identification method one that assigns @xmath57=1 $ ] if and only if @xmath58 for any @xmath59 . in order to represent less informative probabilities",
    "we use imprecise probabilities and , more specifically , belief functions .",
    "as stated in section  [ seccio.belief.functions ] , belief functions can be used when there is uncertainty in the values of a probability distribution . when no additional uncertainty is present in the re - identification process , the corresponding belief function is equivalent to a probability distribution .",
    "we will pressume that an ideal re - identification method is the one that expresses uncertainty by means of a belief function .",
    "the belief function computed by this re - identification method should be _ compatible _ with the true probability .",
    "here we use the term _ compatible _ according to chateauneuf  @xcite , who defined it for belief functions .",
    "definition 1 in  @xcite defines two belief functions as compatible when the joint information is non - empty .",
    "the definition which we will use here is the same as chateauneuf s definition except for the fact that we will compare a probabilty ( the true one ) and a belief function .",
    "we will use @xmath60 to denote the true probability of re - identification .",
    "we give its formal definition below .",
    "let @xmath0 be a dataset , @xmath1 a data masking method , and @xmath3 .",
    "then , we define the true probability @xmath61 as the probability that the protected record @xmath62 proceeds from the record @xmath63 given @xmath1 , @xmath0 , and @xmath2 .",
    "given a true probability and a belief function , we define their compatibility as follows .    given a probability @xmath60 , we say that a belief function @xmath17 is compatible with @xmath60 if @xmath64 .",
    "for the sake of illustration , let us consider the following example with partial information in the re - identification process .",
    "this will be a running example of this paper .",
    "[ ex : kanon.probs ] let @xmath0 be a dataset with different attributes @xmath65 . consider the masking method @xmath1 where each attribute @xmath40 is protected by means of a generalization method @xmath39 which ensures @xmath4-anonymity for @xmath66 .",
    "that is , given that @xmath67 $ ] represents the column of @xmath0 with attribute @xmath40 , we have that @xmath39 is applied to @xmath67 $ ] for all @xmath68 , and @xmath2 is defined in terms of the results of @xmath39 putting their results side by side as follows @xmath69)||\\dots||gen_{v_m}(x[v_m])\\right].\\ ] ]    the true probability @xmath70 for the re - identification of @xmath0 and @xmath3 for a given record @xmath59 assigns the same non - zero probability to all records @xmath71 in @xmath0 such that @xmath43 can proceed from @xmath71 ( taking into account the generalization processes @xmath39 ) , and assigns 0 to all other records . formally , let the record @xmath43 be @xmath72 and let us define the candidate set of @xmath43 as the records @xmath33 such that @xmath43 can proceed from @xmath71 ( i.e. , @xmath73 ) .",
    "then , the true probability of @xmath71 given @xmath43 is defined by :    @xmath74    re - identification methods that are applied to subsets of @xmath2 consisting of only some attributes will lead to probability distributions that may be different from the true probability distribution .",
    "if this is the case , then they will be less informative .",
    "note that , when only a subset of attributes @xmath75 are considered , then the re - identification algorithm may select more candidates than there are in the true candidate set .    in the next example we consider the re - identification of the @xmath76th register of @xmath2 taking into account only partial knowledge consisting of some of the attributes .",
    "[ ex : kanon.probs.reidentif ] let @xmath0 , @xmath1 , @xmath3 , @xmath59 and @xmath39 be defined as in example  [ ex : kanon.probs ] .",
    "let @xmath77 for @xmath78 represent all possible ( non - empty ) subsets of attributes of @xmath79 indexed by @xmath80 .",
    "let @xmath81 for @xmath78 represent a record of the database @xmath2 restricted to @xmath77 .",
    "an example of an indexation of attribute subset is @xmath82 and @xmath83 .",
    "then , we expect a re - identification method applied to @xmath84 , and taking into account how @xmath2 is generated from @xmath0 using @xmath1 , to deliver the following probability distribution :    @xmath85 = \\left\\ {    \\begin{array}{ll }      \\frac{1}{|candidateset_{attrs(j)}(y)| } & \\textrm{if~ } x_i \\in     candidateset_{attrs(j)}(y ) \\\\      0                                       & \\textrm{if~ } x_i \\notin candidateset_{attrs(j)}(y ) \\\\",
    "\\end{array } \\right.\\ ] ]    where @xmath86 includes a record @xmath33 if @xmath43 can proceed from @xmath71 when only the attributes in @xmath24 are considered .",
    "it is easy to see that for any record @xmath43 in @xmath2 , we have @xmath87 and therefore @xmath88 $ ] for all @xmath63 in @xmath0 .    in this example",
    "the re - identification method assigns to all records in the candidate set the same probability .",
    "this is the usual way to assign probabilities under the principle of indifference .",
    "nevertheless , in reality we only know that the true match is one of the records in the candidate set and that we do not have any preference on them . if we instead allow the re - identification to return a belief function , then this situation can be properly expressed .",
    "we define now the concept of _ re - identification method expressing uncertainty _ , a re - identification method that is not required to assign probabilities to singletons .",
    "[ def : reidentification.amb.belief ] let @xmath1 be a method for anonymization of databases , @xmath0 a table with @xmath6 records indexed by @xmath41 in the space of tables @xmath42 and @xmath3 the anonymization of @xmath0 using @xmath1 .",
    "let @xmath89 be the true probability of @xmath1 , @xmath0 and @xmath2 . then",
    "a _ re - identification method expressing uncertainty _ is a function that , given a collection of entries @xmath43 in @xmath44 and some additional information from a space of auxiliary informations @xmath24 , returns the belief function compatible with the true probability @xmath90 that @xmath43 are entries from the record with index @xmath47 @xmath91^{2^{|x|}}\\\\\\\\ & ( y , a ) & \\mapsto & \\left(m(y\\textrm { proceeds from a record in } b ) : b \\subseteq x\\right ) .",
    "\\end{array}\\ ] ]    as for any belief function , in this definition we expect    ( 1 ) : :    @xmath30 and @xmath23 for all    @xmath31 when there is no evidence on which are the    original records corresponding to the protected record    @xmath43 , and ( 2 ) : :    an increment of the belief function for @xmath92    when the evidence increases for records in @xmath93 .    in addition , the same belief functions will apply to different protected records whenever these have the same values .",
    "formally , we have that @xmath94 if @xmath95 holds .",
    "the following example illustrates the use of a re - identification method expressing uncertainty .",
    "[ ex : kanon.probs.belief ] let @xmath0 , @xmath1 , @xmath3 , @xmath59 , @xmath96 , @xmath39 , @xmath97 and @xmath98 be defined as in examples  [ ex : kanon.probs ] and  [ ex : kanon.probs.reidentif ] .",
    "then , the belief function @xmath99 that better represents the uncertainty is defined by the following assignment :    @xmath100    therefore , for all @xmath92 , @xmath101    it is easy to see that @xmath102 if and only if @xmath103 .    for the belief functions in this example we can prove the following .    the belief functions @xmath99 defined in example  [ ex : kanon.probs.belief ] are compatible with the true probability in example  [ ex : kanon.probs ] .    for simplicity ,",
    "let us use the notation @xmath104 .",
    "we need to prove that @xmath105 for all @xmath106 .",
    "since @xmath107 , we only need to check two cases .",
    "* when @xmath108 , it is clear that @xmath105 for all @xmath109 .",
    "* when @xmath110 , then @xmath111",
    ". therefore , @xmath112 .",
    "so , @xmath113 .    in the case of",
    "@xmath110 we use the condition discussed above that @xmath114    this proves the proposition .",
    "in contrast , if the re - identification method assigns @xmath115 to a set @xmath93 that misses one record @xmath63 of the candidate set of @xmath43 , then the inferred belief function is not compatible with the true probability .",
    "this is formalized in the next lemma .",
    "let @xmath116 be a record of the candidate set , let @xmath93 be an arbitrary subset of @xmath0 , and let @xmath117 let a re - identification method assign @xmath118 and @xmath119 for all @xmath106 such that @xmath120 .",
    "the belief function induced from @xmath19 is not compatible with the true probability .",
    "it is easy to see that the belief function satisfies @xmath121 . nevertheless ,",
    "since @xmath122 does not include @xmath116 , we have that the true probabiliy for @xmath122 is @xmath123 therefore , as @xmath124 , the belief function is not compatible with the probability .",
    "it is important to note that this result removes from the set of valid re - identification methods expressing uncertainty those that miss the correct records from the candidate set .      in the previous section we defined a general re - identification method that returns a belief function , and this belief function",
    "is required to be compatible with the true probability . nevertheless , as re - identification methods in real applications return probabilities , we reconsider our definition of re - identification algorithms so that they also return probability distributions .",
    "nevertheless , these probability distributions are required to proceed from the belief function .",
    "in particular , the probability is constructed from the belief function following the principle of insufficient reason ( or principle of indifference ) .",
    "that is , the assignment @xmath19 to a set is distributed to the singletons of this set according to a uniform distribution .",
    "we say that a probability constructed in this way is compatible with the original distribution .",
    "this construction precisely corresponds to the _ pignistic transformation _ and follows the transferable belief model by smets .",
    "details of a characterization of the transformation is given in  @xcite .",
    "this pignistic transformation was defined in definition  [ def : pignistictransformation ] .    given two probabilities @xmath60 and @xmath125 , we say that @xmath125 is compatible with @xmath60 if there exists a belief function @xmath17 compatible with @xmath60 such that @xmath125 is the pignistic probability distribution derived from @xmath17 ( i.e. , @xmath126 ) .",
    "we now present the pignistic probabilities for the running example .",
    "the pignistic probabilities for the belief functions of example  [ ex : kanon.probs.belief ] for @xmath96 are as follows :    @xmath127 = \\left\\ {    \\begin{array}{ll }      \\frac{1}{|candidateset_{attrs(j)}(y)| }                                      & \\textrm{if~ } x_i \\in candidateset_{attrs(j)}(y ) \\\\      0                                                                           & \\textrm{otherwise . } \\\\",
    "\\end{array } \\right.\\ ] ]    the probabilities defined in this example satisfy the following inequalities :    * if @xmath128 , then @xmath129 for all @xmath80",
    ". then , we have @xmath127=\\frac{1}{|candidateset_{attrs(j)}(y)| } \\leq p_{\\rho , x , y}(x_i|y ) = \\frac{1}{|candidateset(y)|}\\ ] ] * if @xmath130 and @xmath129 , then we have @xmath127=\\frac{1}{|candidateset_{attrs(j)}(y)| } \\geq p_{\\rho , x , y}(x_i|y ) = 0\\ ] ] * if @xmath130 and @xmath131 , then we have @xmath127 = p_{\\rho , x , y}(x_i|y ) = 0\\ ] ]    therefore , in general , for a given @xmath63 the pignistic probability can be either larger or smaller than the true probability .",
    "however , it can not assign a zero probability to an @xmath63 in the candidate set .",
    "in fact , the next proposition proves that the support of the probability of the re - identification method should contain the support of the true probability .",
    "[ prop.16 ] let @xmath60 be a true probability , let @xmath17 be a belief function compatible with @xmath60 , let @xmath125 be the pignistic probability derived from @xmath17 .",
    "let @xmath132 be the support of @xmath60 ( i.e. , @xmath133 ) , and let @xmath134 be the support of @xmath125 .",
    "then , @xmath135 .",
    "let @xmath116 be an arbitrary element of the support of @xmath60 , so @xmath136 .",
    "let @xmath137 . then , taking into account that @xmath17 is compatible with @xmath60 , we have @xmath138 so , @xmath139 as @xmath140 , we have @xmath141 so , there exists at least one @xmath109 such that @xmath142 and @xmath143 .",
    "then , by definition of the pignistic transformation , for all @xmath144 , @xmath145",
    ". therefore , @xmath116 is an element of the support of @xmath125 .",
    "as @xmath116 is an arbitrary element of the support of @xmath60 , the statement is proven .",
    "now we will discuss two properties of the probability of re - identification that concern the case in which the probability is one for a single record .",
    "that is , we have that the true probability is a dirac delta distribution at a single record @xmath116 .",
    "this distribution is denoted by @xmath146 and its value is 1 if and only if @xmath147 .",
    "note that this case is possible in example  [ ex : kanon.probs ] when the intersection of the candidate sets of two ( or more variables ) is a singleton .",
    "formally , @xmath148 .",
    "a similar situation was exploited in  @xcite to attack rank swapping .",
    "[ lemma.bel.i.p.singleton ] let @xmath60 be a dirac delta distribution at @xmath116 .",
    "let @xmath17 be a belief function compatible with @xmath60 . then , @xmath23 if any only if @xmath149 .",
    "suppose that @xmath149 , then we have @xmath150 .    as @xmath151 , then we have @xmath152 .    therefore , as @xmath153 and @xmath154 for all @xmath155 , we have @xmath23 .    the fact that @xmath23 implies @xmath156 is a corollary of proposition  [ prop.16 ] .    [ prop : p.singleton.llavors.p.peak ] let @xmath157 be a dirac delta distribution at @xmath158 .",
    "let @xmath125 be a probability compatible with @xmath60 . then , if @xmath125 has its maximum in @xmath159 ( i.e. @xmath160 ) , then @xmath161 .",
    "suppose that @xmath162 for all @xmath163 , and @xmath164 .",
    "lemma  [ lemma.bel.i.p.singleton ] implies that @xmath23 for all @xmath165 .",
    "let @xmath166 , then for any belief function compatible with @xmath60 , @xmath167 for all @xmath168",
    ".    if @xmath125 is compatible with @xmath60 , then there exists a belief function @xmath17 compatible with @xmath60 such that @xmath126 .",
    "note that this proposition is valid only when the true probability is a dirac delta distribution",
    ". however this should not usually be the case if the data protection algorithm is effective .",
    "for example , in example  [ ex : kanon.probs ] there may be @xmath43 with @xmath169 , but for other @xmath170 , so that the probability is @xmath171 . in general , we might even have that the record with a maximal probability is not one of the records in the candidate set .",
    "the next proposition establishes this fact .",
    "[ prop : maxim.p.no.solucio ] let @xmath0 be a reference set with @xmath172 , let @xmath29 be a set of @xmath173 records with a true probability for record @xmath43 equal to @xmath174 . then it is possible to have a probability compatible with the true probability such that the record with maximum probability is none of the ones in @xmath24 .",
    "let @xmath60 represent the true probability .",
    "then @xmath175 for all @xmath176 .",
    "consider a record @xmath116 not in @xmath24 .",
    "therefore @xmath177 .",
    "then , define a belief function @xmath17 in terms of @xmath19 as follows :    @xmath178    first we prove that this belief function is compatible with @xmath60 .",
    "to do so , we need to prove that @xmath179 for all @xmath180 . to do so , we consider two cases for the sets @xmath92 according to the membership of @xmath116 to @xmath93 .",
    "note that in both cases we have @xmath181 .",
    "* case @xmath182 : as @xmath183 , we have that @xmath184 . * case @xmath185 : as @xmath186 , we have that @xmath187 .",
    "now we consider the pignistic probability from @xmath17 .",
    "it is easy to prove that    @xmath188    therefore , we have that @xmath116 is the record with maximum pignistic probability when precisely @xmath116 is not in @xmath24 .",
    "this proposition implies the following corollary .",
    "given a compatible probability @xmath125 of a true probability @xmath60 , the record with maximal value in @xmath125 can be different from the record with maximal value in @xmath60 .",
    "the next example illustrates a masking method that leads to a belief function and a probability distribution as the one in the above proposition  [ prop : maxim.p.no.solucio ] .",
    "let @xmath1 be a masking method defined as follows for records @xmath71 in @xmath189 .    1 .",
    "let @xmath190 be a random number in @xmath191 according to a uniform distribution .",
    "2 .   let @xmath192 be a random number in @xmath193 according to a uniform distribution .",
    "3 .   let @xmath194 where @xmath195 is the unit vector in @xmath189 .    given @xmath196 and @xmath197",
    ", we can model the re - identification of @xmath198 by means of the belief function in proposition  [ prop : maxim.p.no.solucio ] .",
    "therefore , when we guess by selecting the most probable record using the pignistic transformation , we select @xmath116 . however , if @xmath190 is known to be zero , @xmath116 is impossible .",
    "the results given in this section describe the behaviour of our formalization for re - identification . at the same time , they give constraints on what we consider to be a proper re - identification algorithm , and , thus , they define the minimal requirements for these algorithms .",
    "when new information is given to the re - identification algorithm , the belief function is updated according to this new evidence .",
    "the most particular case is when we consider that mass is transferred to a set @xmath199 from a larger set @xmath200 .",
    "that is , we increment the mass of @xmath199 while reducing the one of @xmath200 and not modifying the rest of sets .",
    "the literature presents several definitions of uncertainty measures to evaluate either belief functions or probability distributions .",
    "klir and wierman  @xcite give an account and a classification of some of these measures .    in this section ,",
    "we first show with examples that the entropy of the pignistic probability is not monotonic .",
    "we give these examples because entropy is often interpreted as a measure of information and , as such , one might think that in our case @xmath199 is more informative than @xmath200 .",
    "as the examples show , in some cases the entropy is monotonic to this type of transformations , but in other cases it is not .",
    "later , we prove that the measure of nonspecificity is monotonic with respect to the changes caused by transferring evidence from @xmath200 to @xmath199 .",
    "this measure was defined by dubois and prade  @xcite as a generalization of the measure by higashi and klir  @xcite .",
    "a characterization of this measure was given by ramer in  @xcite ( see klir and wierman  @xcite for details ) .",
    "we consider that this measure represents better the quantity of information in a belief function .",
    "the section finishes with a discussion on the uncertainty measures for re - identification .",
    "the entropy of a belief function @xmath17 is defined as the entropy of the pignistic probability distribution derived from @xmath17 .",
    "that is , @xmath201    let us now consider two examples of the entropy of belief functions .",
    "let @xmath202 and let @xmath17 be the belief function defined by    * @xmath203 * @xmath204    the pignistic probability @xmath35 corresponds to :    * @xmath205 * @xmath206    define @xmath207 by _ transferring _ mass from @xmath208 to @xmath209 .",
    "we have that , @xmath210 , and , therefore , @xmath199 is more specific than @xmath200",
    ". let be the _ transferred _ mass be equal to @xmath211 .",
    "therefore , we have that the new belief function is defined by :    * @xmath212 * @xmath213 * @xmath214    the pignistic probability @xmath215 corresponds to :    * @xmath216 * @xmath217 * @xmath218    the entropy of @xmath35 is 2.0317593 and the entropy of @xmath215 is 1.8300099 .",
    "so , in this case transferring mass / evidence from a larger set to a smaller one reduces entropy .",
    "[ example.2.entropy ] let @xmath219 .",
    "let @xmath17 be the belief function defined by :    * @xmath220 * @xmath221    the pignistic probability @xmath35 corresponds to :    * @xmath222 * @xmath223    define @xmath207 by _ transferring _ mass equivalent to @xmath224 from @xmath225 to @xmath226 .",
    "then , the new belief function @xmath207 is defined by :    * @xmath227 * @xmath228 * @xmath229    therefore , its pignistic probability @xmath215 corresponds to :    * @xmath230 * @xmath231    here , we have that the entropy of @xmath35 is 2.2538579 while the one of @xmath215 is 2.2989538 .",
    "so , we have that the entropy of the pignistic distribution of the belief function with more information @xmath215 is larger than the entropy of the other distribution @xmath35 .",
    "the behaviour of the entropy in these two examples can be explained from the fact that the entropy is a schur - concave function ( see e.g.  @xcite for details ) . in the first example",
    ", @xmath35 majorizes @xmath215 , and therefore @xmath232 . in the second example , is @xmath215 who majorizes @xmath35 and thus @xmath233 .",
    "we prove now that the measure of nonspecificity is monotonic with respect to a mass transfer .",
    "first we introduce this measure .",
    "@xcite the measure of non - specificity @xmath234 for a belief function @xmath17 is defined by @xmath235    for this measure , the following holds .    [ prop : beliefs.nonspecificity ] let @xmath199 , @xmath200 be two subsets of @xmath0 such that @xmath210 , let @xmath17 be a belief function defined by @xmath19 and @xmath207 a belief function defined by the following @xmath236    * @xmath237 * @xmath238 * @xmath239 for all @xmath240 and @xmath241    where @xmath242 is a value such that @xmath243 $ ] for all @xmath244    then , the nonspecificity of @xmath17 is larger than the nonspecificity of @xmath207 , that is @xmath245    to prove this proposition , let us consider the nonspecificity of @xmath17 and put it in terms of the nonspecificity of @xmath207 : @xmath246 as @xmath247 we have that @xmath248 , so that @xmath249 .",
    "we have seen in this section that nonspecificity is useful to measure the information in a belief function , and that entropy is not .",
    "the _ failure _ of entropy in this context might seem to be in contradiction with the fact that entropy typically is understood as a measure of information . nevertheless , the classification of uncertainty measures given in klir and wierman  @xcite sheds some light over this issue .",
    "entropy is classified as a measure of conflict . in this sense ,",
    "the belief function @xmath236 in example  [ example.2.entropy ] presents a larger conflict for a decision than when mass is transferred from @xmath200 to @xmath199 .",
    "this is so because the probabilities are much more similar in @xmath236 that in @xmath19 although we have more information in @xmath236 than in @xmath19 .",
    "in contrast , klir and wierman classify non - specificity as a measure of imprecision , which is said to be connected with sizes ( cardinalities ) of relevant sets of alternatives ( see p. 43 in  @xcite ) which is precisely the case here .",
    "proposition  [ prop : beliefs.nonspecificity ] clearly shows that any transference of mass from a set to a more concrete one will always increase the measure .",
    "indeed , we have that @xmath250 when @xmath17 is a probability distribution .",
    "when additional information is given to the re - identification algorithm , the belief function is expected to change accordingly . in general",
    ", we can pressume that this information can also be represented in terms of a belief function .",
    "note that conditioning in probability theory can be expressed by a belief function .",
    "for example , conditioning by the presence of an element in a set @xmath93 which in probability theory results into the probability @xmath251 , will be expressed by the conditioning with respect to the belief function generated from @xmath252 and @xmath253 for all @xmath254 .",
    "naturally , the belief function used in the conditioning should also be compatible with the true probability .    therefore , given two belief functions compatible with the true probability , the conditioning should lead to another belief function , also compatible with the true probability .    given two belief functions @xmath255 and @xmath256 compatible with a true probabilty @xmath60 , an _ acceptable combination function _",
    "@xmath257 is a combination function that returns a new belief function @xmath17 that is compatible with @xmath60 and such that @xmath258 .",
    "any combination function that satisfies this property will be suitable for conditioning .",
    "see e.g.   for functions satisfying this property .",
    "[ def : combinacio.r.beliefs ] given @xmath259 belief functions @xmath260 compatible with a true probability @xmath60 , we define their combination @xmath261 as the extension of the acceptable combination function @xmath257 as follows : @xmath262    then , when different items @xmath263 of additional information are considered , all of them expressed by means of belief functions @xmath264 , which are compatible with the true probability , and we combine them , the result will converge to be the true probability , and the nonspecificity is reduced . when the true probability is achieved , we have that the nonspecificity is zero .",
    "let @xmath263 be a set of items of additional information expressed by means of belief functions @xmath264 compatible with a true probability @xmath60 .",
    "let @xmath257 be an acceptable combination function .    then , the combination of belief functions @xmath265 for @xmath266 using @xmath261 as in definition  [ def :",
    "combinacio.r.beliefs ] is a belief function @xmath267 compatible with the true probability @xmath60 , and such that @xmath268 .",
    "in addition , if , for a given @xmath269 the belief function @xmath270 is a probability , then @xmath271 and for all @xmath272 we have @xmath273 .",
    "the proof of this proposition is trivial taking into account that @xmath257 is an acceptable combination function and that @xmath250 when @xmath17 is a probability distribution .",
    "in this paper we have formalized re - identification algorithms in terms of belief functions and probabilities . we have shown that belief functions and their pignistic transformation permits us to express the uncertainty in re - identification algorithms in a natural way .",
    "partial support by the spanish mec projects ares ( consolider ingenio 2010 csd2007 - 00004 ) , eaegis ( tsi2007 - 65406-c03 - 02 ) , coprivacy ( tin2011 - 27076-c03 - 03 ) , and ripup ( tin2009 - 11689 ) is acknowledged . partial support of the european project dwb ( grant agreement number 262608 ) is also acknowledged .",
    "one author is partially supported by the fpu grant ( boes 17/11/2009 and 11/10/2010 ) and by the government of catalonia under grant 2009 sgr 1135 .",
    "the authors are with the unesco chair in data privacy , but their views do not necessarily reflect those of unesco nor commit that organization .",
    "dubois , d. , prade , h. ( 1985 ) a note on measures of specificity for fuzzy sets , int .",
    "j. of general systems 10:4 279 - 283 .",
    "fellegi , i. p. , sunter , a. b. ( 1969 ) a theory of record linkage , journal of the american statistical association 64 1183 - 1210 .",
    "klir , g. j. , wierman , m. j. ( 1999 ) uncertainty - based information : elements of generalized information theory , physica - verlag .",
    "marshall , a. w. , olkin , i. , arnold , b. c. ( 2011 ) inequalities : theory of majorization and its applications , springer ( 2nd edition ) .",
    "nin , j. , herranz , j. , torra , v. ( 2008 ) rethinking rank swapping to decrease disclosure risk , data and knowledge engineering , 64:1 346 - 364 .",
    "torra , v. , abowd , j. m. , domingo - ferrer , j. ( 2006 ) using mahalanobis distance - based record linkage for disclosure risk assessment , lecture notes in computer science 4302 233 - 242 .",
    "walley , p. ( 1991 ) statistical reasoning with imprecise probabilities , chapman and hall .",
    "yancey , w. e. , winkler , w. e. , creecy , r. h. ( 2002 ) disclosure risk assessment in perturbative microdata protection , in j. domingo - ferrer ( ed . ) inference control in statistical databases , lecture notes in computer science 2316 135 - 152 ."
  ],
  "abstract_text": [
    "<S> re - identification algorithms are used in data privacy to measure disclosure risk . </S>",
    "<S> they model the situation in which an adversary attacks a published database by means of linking the information of this adversary with the database .    in this paper </S>",
    "<S> we formalize this type of algorithm in terms of true probabilities and compatible belief functions . </S>",
    "<S> the purpose of this work is to leave aside as re - identification algorithms those algorithms that do not satisfy a minimum requirement . </S>"
  ]
}