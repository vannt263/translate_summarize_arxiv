{
  "article_text": [
    "let @xmath3 be a sequence of i.i.d .",
    "random variables from some distribution @xmath4 with mean @xmath5 .",
    "traditionally , studentization has been considered to make inference about the mean for relatively light - tailed distributions .",
    "this approach demands only the second moment assumption .",
    "moreover , the bootstrap inference is arguably accurate and a simple approach to make inference for the univariate mean for finite variance observations ( see , for example , diciccio and efron ( 1996 ) and singh ( 1981 ) ) .",
    "now consider that @xmath6 are in the domain of attraction of a stable law with infinite second moment .",
    "since the sample mean @xmath7 is a common estimator of the mean , it is natural to base inference about @xmath5 on @xmath7 .",
    "thus , there exists a constant @xmath8 such that @xmath9 where @xmath10 is a stable random variable with index @xmath11 .",
    "it is known that @xmath12 where @xmath13 is a slowly varying functions at @xmath14 ; see feller ( 1971 ) for more details . despite the fact that the sample mean is an intuitive estimate for the population mean ,",
    "the rate of convergence of the sample mean is @xmath15 which approaches zero very slowly when @xmath16 is close to 1 .",
    "properties of the bootstrapping for the mean of heavy - tailed distributions have been considered extensively in statistical literatures ( see , for example , hall ( 1990 ) and knight ( 1989a ) ) .",
    "it has been shown that the regular bootstrap is not consistent for estimating the distribution of the mean .",
    "for the finite variance observations , the bootstrap distribution of the sample mean converges almost surely to a fixed distribution . while , athreya ( 1987 ) shows that the bootstrap distribution of the sample mean of infinite variance observations converges in distribution to a random probability distribution .",
    "athreya , lahiri , and wu ( 1998 ) demonstrate that bootstrapping based on resampling @xmath17 out of @xmath18 observations , such that @xmath19 , rectifies the asymptotic failure of the regular bootstrap for relatively heavy - tailed distributions .",
    "they also consider the bootstrap methods for conducting inference about the mean for a sequence of i.i.d .",
    "random variables in the domain of attraction of a stable law whose index exceeds 1 .",
    "arcones and gin@xmath20 ( 1989 ) discuss almost sure and in probability bootstrap central limit theorem when the random variable @xmath21 is in the domain of attraction of a stable law with infinite second moment .",
    "hall and lepage ( 1996 ) propose a bootstrap method for estimating the distribution of the studentized mean under more general conditions on the tails of the sampling distributions .",
    "they also show that this method holds even when the sampling distribution is not in the domain of attraction of any limit law .",
    "zarepour and knight ( 1999b ) consider the weak limit behavior of a certain type of point process obtained by replacing the original observations by the bootstrap sample .",
    "we wish to make inference about the mean vector @xmath22 of a multivariate heavy - tailed distribution .",
    "consider the model @xmath23 where @xmath24^t$ ] , @xmath25 , are @xmath26-valued random vectors , and @xmath27^t$ ] is an unknown fixed parameter .",
    "let @xmath28^t\\}$ ] form a sequences of i.i.d .",
    "random vectors with zero mean in the domain of attraction of a multivariate stable law .",
    "the following generalizes the definition of the domain of attraction of a bivariate stable law in resnick and greenwood ( 1979 ) to the multivariate stable law .",
    "[ dad ] given @xmath29^t\\}$ ] i.i.d .",
    "random vectors on @xmath26 with distribution @xmath30 , let @xmath31 and @xmath32 for @xmath33 .",
    "then , @xmath34 , @xmath35 $ ] , if there exist sequences @xmath36 with @xmath37 such that @xmath38 where @xmath39 is a random vector on @xmath26 with stable distribution and the distribution of @xmath40 is in the domain of attraction of the distribution of @xmath39 .    for more discussion about the class of all possible limits in see resnick and greenwood ( 1979 ) . for the multivariate case",
    ", observations can be in the domain of attraction of a stable law with different indices of stability .",
    "in many real life examples , some coordinates may have light tails while other coordinates may have heavier tails . in this paper",
    ", we assume that errors are in @xmath41 with possibly different values of @xmath42 $ ] for @xmath43    it is obvious that the limiting distribution of the sample mean depends on the tail indices when the errors are in the domain of attraction of a stable law .",
    "thus , it is hard to derive any inference for the mean vector @xmath22 based on the limit , especially when the limiting distribution of each coordinate has different indices of stability .",
    "a bootstrap procedure may circumvent this difficulty but , as mentioned before , the ordinary bootstrap fails in this case . using the bootstrap samples of size @xmath17 , when @xmath44 , typically resolves the problem .",
    "note that the choice of @xmath17 is a key issue and several investigations consider different rules to pick @xmath17 .",
    "see bickel and sakov ( 2008 ) for more details .",
    "these difficulties prompted us to look at a robust estimation based on m - estimate method for constructing any inference about the mean vector such as confidence regions when the errors are in the domain of attraction of a multivariate stable law with possibly different indices of stability in @xmath45 $ ] . in our approach ,",
    "the proposed robust estimation method of the mean vector has higher rate of convergency compared to the sample mean .",
    "we also show that the regular bootstrap is applicable since the limiting distribution is a multivariate normal distribution .",
    "section [ memean ] presents our main theorem , the robust estimation of the mean vector for a sequence of i.i.d .",
    "observations in the domain of attraction of a stable law with different indices of stability , @xmath0 , such that @xmath1 , @xmath2 .",
    "the bootstrap procedure is discussed in section [ bootmean ] .",
    "section [ simmean ] presents some simulations supporting the results of this paper .",
    "let @xmath22 be the parameter vector of interest and for a random sample @xmath46 , let @xmath47 denote the data satisfying .",
    "the classical m - estimate for @xmath22 , denoted by @xmath48 , is defined as the minimizer of the function @xmath49 with respect to @xmath50^t$ ] , where @xmath51 is an almost everywhere differentiable convex function .",
    "this guarantees the uniqueness of the solution . for more details",
    "see davis , knight , and liu ( 1992 ) . for convenience , similar to zarepour and roknossadati ( 2008 ) , we consider the multivariate loss function as @xmath52 where @xmath53 , @xmath33 , are univariate loss functions .",
    "a good justification for using the objective function of the form is the ability to calibrate each coordinate to derive more precise estimates in practice .    here , we impose the following assumptions on the functions @xmath54 , for @xmath33 .    1 .",
    "@xmath55 is a convex and twice differentiable function , and take @xmath56 , and @xmath57 .",
    "2 .   @xmath58 , @xmath59 , and @xmath60 .",
    "@xmath61 has lipschitz - continuous derivative @xmath62 ; i.e. , there exists a real constant @xmath63 such that for all @xmath64 and @xmath65 , @xmath66    the following lemma is used to prove our main results .",
    "[ asy.tn3 ] suppose that @xmath67 is a sequence of convex stochastic processes on @xmath68 and suppose that @xmath69 then @xmath67 has a unique minimum @xmath70 .",
    "if @xmath71 minimize @xmath72 , then @xmath73    * proof .",
    "* the proof is given in lemma 2.2 of davis et al .",
    "see also page 279 from knight ( 1989b ) .",
    "@xmath74 +    [ conf int ] suppose holds . with the loss function ,",
    "let @xmath48 be the m - estimation of the mean vector for a sequence of i.i.d .",
    "observations in the domain of attraction of a stable law with indices of stability @xmath75 such that @xmath76 , @xmath33 .",
    "then , we have @xmath77 where @xmath78^t$ ] has a multivariate normal distribution with mean zero and covariance matrix @xmath79}{e^2(\\psi_1^{'}(\\epsilon_{11}))},\\ldots , \\frac{e[(\\psi_p(\\epsilon_{1p}))^{2}]}{e^2(\\psi_p^{'}(\\epsilon_{1p}))}\\right)$ ] .",
    "* proof : * under the conditions a1-a3 , define the convex process @xmath80 where @xmath81 , for @xmath33 , and @xmath82 is between @xmath83 and @xmath84 .",
    "asymptotically , @xmath85 can be replaced by @xmath86 in since @xmath87 it is well known that @xmath88^{1/2}z_j,\\ ] ] where @xmath89 , @xmath33 , have standard normal distributions .",
    "therefore , @xmath90^{1/2}z_j+ \\frac12\\sum_{j=1}^pu_j^{2}e(\\psi_j^{'}(\\epsilon_{1j})).\\ ] ] from lemma [ asy.tn3 ] , the minimizer of @xmath91 converges to the minimizer of @xmath92 .",
    "thus , follows by setting the derivative of @xmath93 to 0 and solving for @xmath94 , and @xmath95 .",
    "note that @xmath78^t$ ] in has a multivariate normal distribution and @xmath96^{1/2}}{e(\\psi_j^{'}(\\epsilon_{1j } ) ) } z_j,\\ ] ] @xmath33 , are independent .",
    "@xmath74 + based on theorem [ conf int ] , a simple approach to construct a @xmath97 confidence region for the mean of a @xmath98dimemtional random vectors in the domain of attraction of a multivariate stable law with large sample size is the ellipsoid determined by all @xmath22 such that @xmath99 here , @xmath100 is the @xmath101 quantile of a @xmath102 distribution and @xmath103 is the estimated value of @xmath104 using residuals , @xmath105 for @xmath106 .",
    "the confidence region in gives the joint knowledge concerning reasonable values of @xmath22 when the correlation between the measured variables is taken into account .",
    "typically , any summary of conclusions includes confidence statements about the individual component means specially when the covariance matrix is diagonal similar to our case .",
    "let hold for i.i.d .",
    "random vectors @xmath107 .",
    "consider the following linear combination @xmath108 simultaneously for all @xmath109 , the interval @xmath110 contains @xmath111 with probability @xmath101 .",
    "the consecutive choices @xmath112 , @xmath113 , and so on through @xmath114 for the @xmath115intervals allow us to conclude that @xmath116 all hold simultaneously with confidence coefficient @xmath101 .",
    "it has been pointed out that the regular bootstrap fails to estimate the distribution for the mean of heavy - tailed observations .",
    "the main reason for the failure of the regular bootstrap comes from the fact that the rare events occur when we resample the data .",
    "this means the resampling procedure will remember the magnitude of the observations in the resampled data .",
    "this fact can be reflected in the point process theory which is used as a machinery tool for the asymptotic theory of heavy - tailed observations .",
    "let @xmath117 be a sequence of i.i.d .",
    "random vectors in @xmath118 . given @xmath46 , we draw an i.i.d . sequence of observations",
    "@xmath119 from the empirical distribution @xmath120 define @xmath121 . by lemma 3.1 of zarepour and knight ( 1989a )",
    ", we have @xmath122 where @xmath123 are i.i.d .",
    "poisson(1 ) random variables . define the point process @xmath124 where @xmath125 is a measure defined by @xmath126 for any borel set a such that @xmath127\\times \\mathbb{r}$ ] .",
    "also , let @xmath128^t$ ] .",
    "thus , we have @xmath129 with a considerable help from theorem 4 of resnick and greenwood ( 1979 ) and resnick ( 2004 ) and zarepour and knight ( 1999b ) , it can be shown that @xmath130 in distribution . here",
    ", @xmath131 is a sequence of arrival times of a poisson process with unit arrival rate and @xmath132 and @xmath133 is a distribution on the boundary of unit sphere . to have a valid bootstrap",
    ", we expect to have @xmath134 which is not the case here .",
    "the limiting distribution for the bootstrap sample mean , @xmath135 , can be derived from and continuous mapping theorem along with some other mathematical discussions .",
    "similar to the univariate case , this result shows that the regular bootstrap fails asymptotically . as discussed in the introduction , a subsampling scheme ( @xmath17 out of @xmath18 bootstrap such that @xmath19 ) is an appropriate approach to achieve asymptotic validity of a bootstrap procedure for constructing a confidence region for the mean vector of i.i.d .",
    "heavy - tailed data .",
    "however , choosing the proper subsample size @xmath17 is of great concern to many authors .",
    "on the other hand , theorem [ conf int ] shows that the weak limit behavior of @xmath136 is a multivariate normal distribution .",
    "thus , the regular bootstrap works if we use the robust estimates ( m - estimates ) for the mean vector .",
    "our approach in this section is to consider a bootstrap approach to estimate the confidence region for @xmath22 . given @xmath137 $ ] , find m - estimates of @xmath22 in model using the objective function in .",
    "then calculate the residuals , where @xmath138 let @xmath139 be a sample of size @xmath18 from the centered residuals in .",
    "these assumptions imply the following lemma .",
    "[ srs ] let @xmath140 be an i.i.d .",
    "sample from @xmath141 where @xmath142^t$ ] , @xmath25 , and @xmath143 denotes the expectation under @xmath144 .",
    "also , let @xmath145 , @xmath33 , be an odd function and satisfy conditions a2-a3 .",
    "then , for @xmath33 , we have    a.   @xmath146 b.   @xmath147 where @xmath89 has a standard normal distribution and @xmath148 . c.   @xmath149 .",
    "* proof : * the proofs are straightforward under the conditions that @xmath145 is odd and the bootstrap errors are symmetric .",
    "we omit the proofs here ; for more details see singh ( 1981 ) .",
    "@xmath74 + now , we find @xmath150 from the model @xmath151 .",
    "then , we have @xmath152 where @xmath153 for @xmath33 and @xmath154 is between @xmath155 and @xmath156 . then by lemma [ srs ] , we have @xmath157 in probability , where @xmath158 is defined in .",
    "we apply to approximate the critical points of @xmath158 . to do so",
    ", we carry out a large number , say @xmath159 , of the bootstrap replicates of size @xmath18 from @xmath160 set @xmath161 to be the @xmath162-th percentile value of @xmath163 .",
    "thus an approximate confidence region for @xmath22 at level @xmath97 will be @xmath164",
    "to illustrate the preceding results , some simulation studies are performed .",
    "the first step in our simulation study is choosing the loss function .",
    "an example for the univariate @xmath165 is the huber loss function given by @xmath166 for a known constant @xmath167 ; see huber ( 1981 ) . then , @xmath168 $ ] . the huber loss function satisfies conditions",
    "a1-a3 except @xmath145 might not exist everywhere . in this case , although @xmath145 is not differentiable at a countable number of points , the results will usually hold with some additional complexity in the proofs .",
    "the choice of a truncation value @xmath167 is of practical interest specially when we have different indices of stability .",
    "the following univariate simulation study is undertaken in order to explore whether there is a relationship between values of @xmath167 in the huber loss function and the index of stability @xmath16 .",
    "consider the univariate model @xmath169 where @xmath170 .",
    "we generate the time series @xmath171 in model for @xmath172 and @xmath173 with different values of @xmath174 .",
    "then , the m - estimates of @xmath5 in are calculated from generated time series using the huber loss function given in . to seek a more efficient @xmath175 in the huber loss function",
    ", the estimation is repeated for different values of @xmath175 between @xmath176 and @xmath177 for each choice of @xmath16 .",
    "we find the average deviation by calculating the absolute deviation @xmath178 and then carrying out 10,000 replications .",
    "the numbers in table [ tab : talphac ] are the averages of the replications . meanwhile , the scatterplot of the average deviations presented in figure [ fig : ad ] . for each level of @xmath16 and @xmath175 ,",
    "the minimum of the average deviations are emboldened in table [ tab : talphac ] .",
    "this table shows that , for instance , for @xmath179 if we choose @xmath180 , we get the minimum of the error estimation .",
    "table [ tab : talphac ] and figure [ fig : ad ] also show that there is a positive relationship between the truncation value @xmath175 and the index of stability @xmath16 .",
    "in fact , to have less estimation errors , we must choose larger value of @xmath175 as @xmath16 gets larger .",
    ".average values of @xmath181 for different values of @xmath16 and truncation values of @xmath175 in the huber loss function with the replication size of 10,000 .",
    "[ cols=\"<,^,^,^,^,^,^,^,^,^ \" , ]     [ tab : cp ]",
    "in this paper , a robust estimation of the mean vector is considered when the observations are a sequence of i.i.d .",
    "random vectors in the domain of attraction of a stable law with different indices of stability , @xmath0 , such that @xmath1 , @xmath2 .",
    "notice that it is not necessary to enforce the condition that @xmath182 . for",
    "@xmath183 , @xmath184 , @xmath25 , does not exist .",
    "therefore , @xmath22 is not the mean for the observations @xmath185 in but we can still consider @xmath22 as the location parameter .",
    "the estimation procedure and the asymptotic behaviour of our m - estimate remains valid and the bootstrapping still works when we wish to estimate the location parameter @xmath22 . in this case @xmath186 , @xmath25 in model should be considered to be in @xmath118 with @xmath187 for @xmath33 .",
    "the model can be modified to a more complex form when @xmath22 plays the role of the location parameter in other statistical methods . as an example",
    ", one may consider the time series models with the location parameter , @xmath188 .",
    "thus , such analysis can help to characterize the asymptotic distribution for the location parameter in more complex statistical models .",
    "another application for the location parameter is calculating the data depth of the observations in the domain of attraction of a multivariate stable law ( see liu , parelius , and singh ( 1999 ) ) .",
    "huber , p.j .",
    "( 1981 ) _ robust statistics_. wiley series in probability and mathematical statistics .",
    "wiley , new york .",
    "knight , k. ( 1989a ) . on the bootstrap of the sample mean in the infinite variance case .",
    "_ annals of statistics_. 17 , 1168 - 1175 .",
    "resnick , s. and greenwood , p. ( 1979 ) a bivariate stable characterization and domains of attraction .",
    "_ journal of multivariate analysis _",
    ", 9 , 206 - 221 .",
    "singh , k. ( 1981 ) on the asyptotic accuracy of efron bootstrap .",
    "_ the annals of statistics _ , 9 , 1187 - 1195 ."
  ],
  "abstract_text": [
    "<S> we consider a robust estimation of the mean vector for a sequence of i.i.d . </S>",
    "<S> observations in the domain of attraction of a stable law with different indices of stability , @xmath0 , such that @xmath1 , @xmath2 . </S>",
    "<S> the suggested estimator is asymptotically gaussian with unknown parameters . </S>",
    "<S> we apply an asymptotically valid bootstrap to construct a confidence region for the mean vector . </S>",
    "<S> a simulation study is performed to show that the estimation method is efficient for conducting inference about the mean vector for multivariate heavy - tailed distributions . </S>"
  ]
}