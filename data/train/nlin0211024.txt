{
  "article_text": [
    "a common approach to the problem of how cooperation emerges in societies of `` selfish '' individuals - individuals which pursue exclusively their own self - benefit - is based on game theory , and specifically on the _ prisoner s dilemma _ ( pd ) of the early fifties . in a series of works robert axelrod and co - workers @xcite used this kind of computer games to examine the basis of cooperation between selfish agents in a wide variety of contexts",
    ". mechanisms of cooperation based on the pd have shown their usefulness in economy @xcite-@xcite , political science @xcite-@xcite , international relations theory @xcite-@xcite , theoretical biology @xcite-@xcite , ecosystems @xcite- @xcite , etc .",
    "the beauty of the pd game relies on the fact that it embodies the central ingredients of the cooperation problem in a very simple and intuitive way .",
    "there are two players , each confronting two choices : cooperate ( c ) or defect ( d ) and each makes its choice without knowing what the other will do .",
    "independently of what the other player does , defection d yields a higher payoff than cooperation and is the dominant strategy . in other words , the outcome",
    "( d , d ) of both players is the nash equilibrium @xcite .",
    "the dilemma is that if both defect , both do worse than if both had cooperated .    the emergence of cooperation in prisoner s dilemma ( pd ) games is generally assumed to require repeated play ( and strategies such as tit for tat ( tft ) @xcite , involving memory of previous interactions ) or features ( `` tags '' ) permitting cooperators and defectors to distinguish one another @xcite .    in this work ,",
    "i consider a simple model of selfish agents playing pd , possessing neither memory nor tags , to study the self - organized cooperative states which emerge for different payoff matrices .",
    "the model consists of @xmath16 agents , with two variables assigned to each agent at the site or cell @xmath0 and at time @xmath1 : its probability of cooperation @xmath3 and its capital @xmath2 .",
    "pairs of agents , 1 and 2 , interact by playing the pd game at each time step @xmath1 .",
    "that is , there are 4 possible outcomes for the interaction of agent @xmath0 with agent @xmath17 : 1 ) they can both cooperate ( c , c ) 2 ) both defect ( d , d ) , 3 ) @xmath0 cooperates and @xmath17 defects ( c , d ) and 4 ) @xmath0 defects and @xmath17 cooperates ( d , c ) . depending on the situation 1)-4 ) , the agent @xmath0 ( @xmath17 ) gets respectively : the `` reward '' @xmath18 , the `` punishment '' @xmath19 , the `` sucker s payoff''@xmath20 or @xmath21 , _ i.e. _ the payoff matrix m@xmath22 is    @xmath23    the payoff matrix gives the payoffs for row actions when confronting with column actions .",
    "after playing the pd the agents update their probability of cooperation @xmath3 and @xmath24 according to the same definite `` measure of success '' which does not vary with time .",
    "thus all agents follow a universal and invariant strategy defined by a measure of success plus an updating rule to transform @xmath25 and @xmath26 into @xmath27 and @xmath28 .",
    "the 4!=24 different payoff matrices produced by permutation of the four prisoner s dilemma canonical payoffs -3 , 0 , 1 , and 5- are analyzed by means of a mean field ( mf ) approach , in which all the spatial correlations in the system are neglected .",
    "it turns out that for all these 24 possibilities , after a transient , the system self - organizes into a state of equilibrium characterized by the average probability of cooperation and average per - capita - income ( @xmath15 ) , always with @xmath29 .",
    "furthermore , in the majority of cases @xmath30 .",
    "payoff matrices can be classified into sub - categories according to their dominant strategy .",
    "let us call @xmath31 the class of those matrices such that : @xmath32 for which the dominant strategy is d. this class comprises six matrices : m@xmath33 , m@xmath34 , m@xmath35 , m@xmath36 , m@xmath37 and m@xmath38 .",
    "a second class @xmath39 corresponds to @xmath40 for which the dominant strategy is c and comprises the following six matrices : m@xmath41 , m@xmath42 , m@xmath43 , m@xmath44 , m@xmath45 and m@xmath46 .",
    "the remaining twelve matrices do not comply with equation ( [ eq : class1 ] ) or ( [ eq : class2 ] ) and produce situations not dominated by ( d , d ) or ( c , c ) .",
    "the only payoff matrix that implies a dilemma , in the sense explained above , is the canonical one with @xmath47 and @xmath48 which belongs to class @xmath31 and comply with the condition ( [ eq : class1 ] ) plus condition @xmath49 , or equivalently the chain of inequalities : @xmath50 .",
    "for which @xmath51 and although the dominant strategy is c both players would prefer the punishment p associated with ( d , d ) .",
    "] however , some matrices exhibit a tension between c and d and give rise to @xmath52 .",
    "the matrices which do not embodie such trade - off produce the situations which depart from @xmath53 .",
    "clearly , these payoff matrices are unrealistic in order to model the social behavior of the majority of individuals .",
    "so , why bother to study matrices which imply no dilemma ?",
    "well , one reason is that they could be of importance in other contexts .",
    "one might envisage situations in which a definite value of @xmath13 is required in the design of a system or is the one which optimizes the functioning of a particular mechanism , etc .",
    "another motivation is that this `` unreasonable '' payoff matrices can be used by minorities of individuals which depart from the `` normal '' ones ( assumed to be neutral ) for instance , d - inclined `` free riders '' or c - inclined `` altruistic '' individuals .",
    "finally , we will show results for these payoff matrices which , at first glance , defy our intuition .",
    "for example , payoff matrices which , at least in principle , one would bet that favor cooperation and indeed produce a very low degree of cooperation .",
    "the pairs of interacting partners , by virtue of the mf treatment , are chosen randomly instead of being restricted to some neighborhood .",
    "the implicit assumptions are that the population is sufficiently large and the system connectivity is high _ i.e. _ the agents display high mobility or they experiment interaction at a distance ( for instance electronic transactions ) . in this work the population of agents will be fixed to @xmath54 and the number of time steps will be of order @xmath55 in such a way that both assumptions be also consistent with the fact that agents have no memory .",
    "starting from an initial state at @xmath56 taken as @xmath57 chosen at random ( in the interval [ 0,1 ] ) and @xmath58 = 0 for each cell @xmath0 , the system evolves by iteration during @xmath59 time steps following these stages in this order :    1 .   _",
    "selection of players : _ at each time step @xmath1 two agents , located at random positions @xmath0 and @xmath17 , are selected to interact _",
    "i.e. _ for playing the pd game .",
    "playing pairwise pd : _ the action , c or d , of each interacting agent @xmath60 ( @xmath60=@xmath0 or @xmath60=@xmath17 ) is decided generating a random number @xmath61 and if @xmath62 then it cooperates and , conversely , if @xmath63 it defects .",
    "_ capital update : _ as a result of the interaction the capital of each interacting agent @xmath60 is updated as @xmath64 , being the profit of agent @xmath60 , @xmath65 one of the four pd payoffs : @xmath9 , @xmath10 , @xmath11 or @xmath12 .",
    "assessment of success : _ each of the two agent who have just interacted compares its profit @xmath65 with an _ estimate _ @xmath66 of the expected utilities .",
    "if @xmath67 ( @xmath68 ) the agent assumes it is doing well ( badly ) and therefore its level of cooperation is adequate ( inadequate ) . 5 .   _ probability of cooperation update : _ pursuing to increse their utilities in future pd games the agents that just interacted update their @xmath69 .",
    "if agent @xmath60 is doing well it increases its probability of cooperation @xmath69 choosing an uniformly distributed value between @xmath69 and 1 .",
    "on the other hand , if agent @xmath60 is doing badly it decreases its probability of cooperation @xmath69 choosing an uniformly distributed value between 0 and @xmath69 ( see below for a discusion of this update rule ) .",
    "let us see how the estimate @xmath66 emerges naturally . if the interacting agents @xmath0 and @xmath17 cooperate with probabilities @xmath70 and @xmath71 respectively ( and defect with probabilities @xmath72 and @xmath73 ) , then the expected value of the payoff to @xmath0 , @xmath74 is given by : @xmath75 hence i consider an estimate @xmath66 , which only involves the probability of cooperation @xmath69 of the agent @xmath60 who uses the estimate , obtained by replacing in equation ( [ eq : deltacap ] ) @xmath70 and @xmath71 by @xmath69 : @xmath76    while the measure of success seems natural , the updating rule for the probability of cooperation is quite arbitrary .",
    "for instance , for the case of the canonical payoff matrix , the update rule for the probability of cooperation implies the following : if your partner cooperated , increase your level of cooperation ; else lower it ( of course , with boundaries at 0 and 1 ) . a priori , it is not obvious if this is a good update rule in order to maximize your utilities .",
    "after all , the other player might be a sucker .",
    "in that case perhaps you should defect more .",
    "however , as we will see in the next section , this update rule basically works by tuning the agent s cooperation in order to accomplish some sort of `` indirect reciprocity '' which in turn produces cooperative equilibrium states .",
    "furthermore , modifying the strategy of each agent so that it defects more often , when it is doing well , pursuing to exploit an assumed high percentage of suckers , ends by spoiling cooperation",
    ". a natural implementation of this change of strategy would be : if you are doing well decrease your probability of cooperation @xmath77 with probability proportional to @xmath78 and increase it with probability proportional to @xmath77 .",
    "but this is equivalent to the _ replicator dynamics _",
    "@xcite - @xcite for which , in ordinary situations , it is known that the cooperation becomes extinct .",
    "_ general remarks on the model .",
    "_    _ i. _ among the weaknesses of major approaches that have been considered to answer the question about the emergence of cooperation two are often remarked .    _",
    "i.a _ the first criticism is about the generally assumed `` binary '' probability of cooperation _",
    "i.e. _ agents either always cooperate ( c ) or always defect ( d ) . clearly , this is no very realistic . indeed",
    "the levels of cooperation of the individuals are continuous .",
    "hence a real @xmath3 ( in the interval [ 0,1 ] ) is used , reflecting existence of a `` gray scale '' of levels of cooperation instead of just `` black '' and `` white '' .    _",
    "i.b _ the second objection is concerning the deterministic nature of the algorithms which seem to fail to incorporate the stochasticity of agent behavior .",
    "the used algorithm is non deterministic .",
    "comparison with the random number @xmath61 reflects a stochastic component of agents behavior .    _",
    "all the agents follow the same universal strategy which does not evolve over time",
    ". however , the system is adaptive in the sense that the probabilities of cooperation of the agents do evolve .",
    "for all the 24 payoff matrices the system self - organizes , after a transient , in equilibrium states with six values of @xmath29 : 1 , 0.56@xmath79 , 0.5@xmath80 , 0.42@xmath81 , 0.22@xmath82 and 0.115@xmath83 .",
    "the 24 measures are performed over 100 simulations of @xmath84 time steps each .",
    "1 show the average probability of cooperation for different payoff matrices vs. time for the 200,000 first time steps .",
    "roughly , the equilibrium asymptotic states can be classified in 3 classes : _ highly cooperative _ ( @xmath85 ) , _ moderately cooperative _ ( @xmath86 ) and of _ loow cooperation _ ( @xmath87 ) . in the second column of table 1 are listed the values of @xmath13 for the 24 payoff matrices .    [ cols=\"<,<,<\",options=\"header \" , ]     table 1 .",
    "equilibrium values of probability of cooperation @xmath88 & income - per - agent @xmath89 for the 24 possible payoff sets @xmath90 _",
    "r s t p _ @xmath91 .",
    "( c ) or ( d ) in first column indicate if the dominant strategy is c or d.    _ the relation between utilities and probability of cooperation _    let us now analyze the average equilibrium income - per - agent @xmath92 for the different payoff matrices .",
    "the curves of per - capita - income @xmath93 as a function of the average probability of cooperation @xmath77 are the parabolas obtained by replacing in equation ( [ eq : deltacap ] ) @xmath70 and @xmath71 by @xmath77 _",
    "i.e. _ @xmath94 these curves are invariant under the interchange of the sucker s payoff @xmath10 and the temptation @xmath11 , _",
    "i.e. _ @xmath95 _ i.e. _ the 24 payoff matrices give rise to the 12 different parabolas depicted in fig .",
    "2 . in each subplot , the values of @xmath96 and @xmath97 and the equation ( [ eq : deltacap2 ] ) for the corresponding parabola is indicated .",
    "for example , we have in the first box : @xmath98 & @xmath99 . in all the subplots the equilibrium points ( @xmath15 ) for the payoff matrix with @xmath100 and @xmath101 are denoted , respectively , by circles and the + s .",
    "note that by virtue that    @xmath102    all the parabolas @xmath103 pass through the point [ 1/2,9/4 ] .",
    "the values of @xmath89 are listed in the third column of table 1 for the 24 payoff matrices .",
    "let us analyze the distributions of probabilities of cooperation and their corresponding average capitals and average income - per - agent .",
    "3 , fig.4 and fig.5 illustrate , respectively , the cases of payoff matrices giving rise to equilibrium states with @xmath104 , @xmath105 and @xmath106 .",
    "measures are performed over 100 simulations of 50,000 time steps each , after the equilibrium state was reached _",
    "i.e. _ typically discarding the first 200,000 configurations .",
    "approach to @xmath107 more slowly and after 200,000 iterations the system has not reached equilibrium yet as can be seen from fig.1 . in that case",
    "450,000 iterations were discarded before measuring . ] the upper plots are distributions for the probabilities of cooperation @xmath77 using 100-bin histograms .",
    "the frequencies @xmath108 are normalized in such a way that the total area is equal to 1 .",
    "the middle ( lower ) plots present the corresponding average capitals @xmath109 ( average income - per - agent @xmath110 ) obtained by taking the quotients between the histograms for the capitals ( income - per - agent ) and the frequencies histograms .",
    "fig.3 corresponds to 2 payoff matrices giving rise to high cooperation : m@xmath111 and m@xmath37 , with @xmath112 and @xmath113 .",
    "the histograms of frequencies @xmath108 exhibit a peak at @xmath114 ( in the case of m@xmath111 the 3 histograms are non null only for @xmath114 ) .",
    "4 illustrates two cases of moderate cooperation produced by payoff matrices m@xmath33 ( the canonical one ) and m@xmath41 , with @xmath115 and @xmath116 .",
    "both histograms exhibit two peaks , one at @xmath117 and one at @xmath114 .    in fig.5",
    "are shown two cases of low cooperation , produced by m@xmath42 and m@xmath118 , with @xmath119 and @xmath120 .",
    "both histograms of frequencies exhibit a peak at @xmath117 .",
    "let us summarize the main results which emerge from the data :    * the state of complete cooperation @xmath107 is reached for payoff matrices with @xmath121 : m@xmath44 , m@xmath45 and m@xmath111 .",
    "produce the highest possible average cooperation @xmath107 . *",
    "the payoff matrices with the highest possible reward r=5 , contrary to one might think , do not produce the higher @xmath13 .",
    "moreover , the states of lower average cooperation is produced by a payoff matrix with @xmath122 : @xmath123 occurs for m@xmath42 and @xmath124 for m@xmath118 .",
    "the explanation of this fact relies on the adopted measure of success based on the estimate @xmath6 : from equation ( [ eq : localest ] ) and from fig.2 note that for @xmath122 the estimates , for high values of @xmath77 , are @xmath125 ( _ i.e. _ they are greater than all the payoffs except the reward ) , making agents excessively exigent . in other words : too much rewarding makes the expectation of utilities by the agents to be so high that spoils cooperation .",
    "* from the two above results it is obvious that there is no completely clear connection between the dominant strategy and the equilibrium state .",
    "for instance , matrices belonging to class @xmath39 produce both the highest and lowest values of @xmath13 . * the highest @xmath92",
    "is obtained from payoff matrices which produce the highest @xmath13 , namely @xmath126 . on the other hand , the lowest @xmath92",
    "is obtained from payoff matrix which produce the lowest @xmath13 , namely @xmath127 .",
    "* the distributions for the probability of cooperation are clearly non uniform showing peaks at @xmath117 or / and at @xmath114 .",
    "* the strategy used by the agents is robust enough to lead _ for all _ the payoff matrices to @xmath29 .",
    "furthermore , for the majority of the 24 payoff matrices @xmath30 .",
    "this robustness relies on the strategy combining the proposed measure of success and update rule for the probability of cooperation .",
    "basically it works by tuning the agent s cooperation guided by a trade - off between efficiency ( increase of utilities ) and equity ( indirect reciprocity ) .",
    "if the agent is doing well it behaves nicely and increases its probability of cooperation .",
    "nevertheless , in future interactions , if its probability of cooperation is inadequate ( too high ) and it does badly ( it is exploited ) then it reacts by decreasing its cooperation till it starts doing well again . *",
    "the equilibrium states are such that , although the average income - per - agent depends on the value of the probability of cooperation @xmath77 _ i.e. _ @xmath128 , the distribution of average capitals is almost uniform and does not depend on @xmath77 ( as can be observed from fig.3 to fig.5 ) .",
    "this is consistent with the fact that agents constantly adapt their probability of cooperation in such a way to improve utilities .",
    "hence , for a given value of @xmath129 , the utilities of each agent , with probability of cooperation @xmath77 , oscillates around @xmath130 in such a way that their accumulated capital at a given time ( in equilibrium ) is independent of @xmath77 .",
    "the first general conclusion is concerning the robustness of the cooperative asymptotic state , which indicates that , in this model , _ cooperation seems based more in a sort of indirect reciprocity than in selfish incentives_. for example , the permutation of the canonical values of @xmath9 and @xmath11 has the dramatic effect of transforming a society with an intermediate level of cooperation into one dominated by defection , as it arises from comparing the results for payoff matrices m@xmath33 and m@xmath118 . on the other hand , the permutation of the canonical values of @xmath10 and @xmath12 has also a dramatic effect : it transforms a society with an intermediate level of cooperation into a completely cooperative one , as one can see from comparing the results for payoff matrices m@xmath33 and m@xmath111 .",
    "an interesting extension of the model would be to allow competition of different strategies to promote their evolution _",
    "i.e. _ players which imitate the best - performing ones in such a way that lower scoring strategies decrease in number and the higher scoring increase .",
    "in particular , a possibility would be to associate different strategies with the use of disctint payoff matrices .",
    "for instance , individuals inclined to cooperate ( defect ) might be represented by agents using the payoff matrix m@xmath111 ( m@xmath42 ) while `` neutral '' agents by agents using the canonical payoff matrix m@xmath33 .",
    "this would make possible to study if mutants inclined to d can invade a group of neutral individuals or individuals inclined to c and drive out all cooperation . however , a previous necessary step was the knowledge of the effect of changing the payoff matrix on the system self - organization and in particular on the equilibrium point ( @xmath131 ) .",
    "so in this work we considered each of these 24 payoff matrices by separate .    this model can be extended in other ways in order to make it more realistic .",
    "for instance , here i considered a mf approximation which neglects all the spatial correlations .",
    "one virtue of this simplification is that it shows the model does not require that agents interact only with those within some geographical proximity in order to sustain cooperation .",
    "playing with fixed neighbors is sometimes considered as an important ingredient to successfully maintain the cooperative regime @xcite,@xcite",
    ". however , the quality of this mf approximation depends on the nature of the system one desires to model ( people , cultures of bacteria , market of providers of different services or products , etc . ) .",
    "therefore , in order to apply the model to situations in which the effect of geographic closeness can not be neglected an interesting extensions of the model would be : to transform the entirely random pd game into a spatial pd game , in which individuals interact only ( or mainly ) with those within some geographical proximity .    to conclude ,",
    "this work is based on the canonical assumption that individuals are entirely self - interested .",
    "however , recent investigations , performed in twelve countries on four continents , have uncovered systematic deviations from the material payoff - maximizing _",
    "in addition to their own material payoffs , many experimental subjects appear to prefer to share resources and undertake costly reciprocal actions in anonymous one - shot interactions .",
    "therefore , an open issue is how to incorporate this fact in a more realistic model .",
    "r. axelrod , in _ the evolution of cooperation _",
    ", basic books , new york , 1984 ; r. axelrod , in _ the complexity of cooperation _ , princeton university press 1997 .",
    "these two volumes include lots of useful references .",
    "also it is illuminating the chapter 3 of _ harnesing complexity _ by r. axelrod and m. cohen , the free press 1999 ."
  ],
  "abstract_text": [
    "<S> the self - organization in cooperative regimes in a simple mean - field version of a model based on `` selfish '' agents which play the prisoner s dilemma ( pd ) game is studied . </S>",
    "<S> the agents have no memory and use strategies not based on direct reciprocity nor tags. two variables are assigned to each agent @xmath0 at time @xmath1 , measuring its capital @xmath2 and its probability of cooperation @xmath3 . at each time step @xmath1 a pair of agents interact by playing the pd game . </S>",
    "<S> these 2 agents update their probability of cooperation @xmath4 as follows : they compare the profits they made in this interaction @xmath5 with an estimator @xmath6 and , if @xmath7 , agent @xmath0 increases its @xmath3 while if @xmath8 the agent decreases @xmath3 . </S>",
    "<S> the 4!=24 different cases produced by permuting the four prisoner s dilemma canonical payoffs 3 , 0 , 1 , and 5 - corresponding , respectively , to @xmath9 ( reward ) , @xmath10 ( sucker s payoff ) , @xmath11 ( temptation to defect ) and @xmath12 ( punishment ) - are analyzed . </S>",
    "<S> it turns out that for all these 24 possibilities , after a transient , the system self - organizes into a stationary state with average equilibrium probability of cooperation @xmath13 = constant @xmath14 . </S>",
    "<S> depending on the payoff matrix , there are different equilibrium states characterized by their average probability of cooperation and average equilibrium per - capita - income ( @xmath15 ) .    </S>",
    "<S> = -1.50 cm = 0.5 cm = 0.5 cm = 35pt    psfig.sty    _ keybords _ : complex adaptive systems , agent - based models , social systems    pacs numbers : 02.50.le , 87.23.ge , 89.65.gh , 89.75.-k </S>"
  ]
}