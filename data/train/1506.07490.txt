{
  "article_text": [
    "a lattice @xmath9 is the set of all integer linear combinations of some linearly independent basis vectors @xmath10 .",
    "the two central computational problems on lattices are the shortest vector problem ( svp ) and the closest vector problem ( cvp ) . given a lattice @xmath9 ,",
    "the svp is to find a shortest non - zero vector in @xmath11 .",
    "given a lattice @xmath9 and a target vector @xmath12 , the cvp is to find a vector in @xmath11 whose distance to @xmath13 is minimal .",
    "algorithms for svp and cvp , in both their exact and approximate versions , have found many diverse applications in computer science .",
    "they have been used to factor polynomials over the rationals  @xcite , solve integer programming  @xcite , and break cryptographic schemes  @xcite . and ,",
    "over the past twenty years , a wide range of strong cryptographic primitives have been constructed with their security based on the _ worst - case _ hardness of the approximate versions of these problems  @xcite .",
    "both problems are known to be hard , even to approximate to within the nearly polynomial factor of @xmath14 for some constant @xmath15  @xcite .",
    "indeed , cvp is in some sense `` lattice complete '' in that nearly all well - studied lattice problems are reducible to cvp via dimension - preserving ( and approximation - factor - preserving ) reductions .",
    "( see  @xcite for a list of such problems . ) in particular , a dimension - preserving reduction from svp to cvp has long been known  @xcite .",
    "however , the best - known dimension - preserving reduction in the other direction only reduces @xmath16-approximate cvp to svp .",
    "a powerful tool for studying lattices is the discrete gaussian , the probability distribution @xmath0 that assigns to each vector @xmath17 probability proportional to its gaussian mass , @xmath3 , for a lattice @xmath9 , shift vector @xmath12 , and parameter @xmath18 .",
    "the discrete gaussian and the closely related theta functions have been used to prove transference theorems on lattices  @xcite ; to show that @xmath19-approximate cvp and svp are in co - np  @xcite ; to embed flat tori in a hilbert space with low distortion  @xcite ; to solve the bounded distance decoding problem  @xcite ; and even in the study of the riemann zeta function ( e.g. , in  @xcite ) .    note that the discrete gaussian is concentrated on relatively short vectors .",
    "in particular , in the important special case when the discrete gaussian is _ centered _ so that @xmath6 , @xmath20 assigns higher weight to shorter lattice vectors .",
    "this suggests a connection between @xmath20 and svp . in the more general case , @xmath0 is concentrated on short vectors in the shifted lattice @xmath2 . by translating this distribution by @xmath13 ( i.e. , considering the distribution of @xmath21 )",
    ", we obtain a distribution over the lattice that assigns higher weight to the vectors that are closest to @xmath13 , suggesting a connection between @xmath0 and cvp .",
    "as the parameter @xmath4 becomes lower , the distribution becomes more concentrated .",
    "indeed , one can show that samples from @xmath0 ( when suitably translated ) yield @xmath22-approximate solutions to cvp when @xmath23 .",
    "( see figure  [ fig : dgs ] for two examples of the discrete gaussian in two dimensions . )    largely because of its connection to other lattice problems , algorithms for discrete gaussian sampling ( dgs ) have recently played an important role in computer science .",
    "gentry , peikert , and vaikuntanathan introduced a polynomial - time trapdoor algorithm for sampling from the discrete gaussian with very high parameters @xmath4 in order to construct a secure signature scheme @xcite . and",
    ", many reductions between lattice problems use a dgs algorithm as a subroutine  @xcite .",
    "but , these reductions also only work for very high parameters @xmath4 .",
    "in particular , all previously known polynomial - time algorithms ( even those with access to trapdoors and oracles ) can only sample from @xmath24 when @xmath4 is significantly above the `` smoothing parameter '' of the lattice , in which case the discrete gaussian `` looks like a continuous gaussian distribution '' in a certain precise sense that we do not define here .",
    "( see @xcite for the formal definition . )    in the past year , aggarwal , dadush , regev , and stephens - davidowitz introduced an exponential - time algorithm for sampling from the discrete gaussian with much lower parameters in order to solve exact svp  @xcite , and @xcite showed how to extend this result to cvp .",
    "these are the current fastest - known algorithms for svp and cvp .",
    "in particular ,  @xcite showed how to sample exponentially many vectors from the _ centered _ discrete gaussian for _ any _ parameter @xmath4 in @xmath5 time , which yields a solution to svp .",
    "@xcite extended this work to show how to sample many vectors from @xmath0 for very small parameters @xmath25 , also in @xmath5 time .",
    "surprisingly , they showed how to use such an algorithm to construct a @xmath5-time algorithm for cvp . and",
    "any @xmath4 is sufficient to solve cvp efficient .",
    "( we include a proof in section  [ sec : cvptodgs ] for completeness . )",
    "the difficulty in @xcite is that the sampler only works for parameters @xmath4 greater than roughly @xmath26 .",
    "while this minimum value is very small , this does not seem to be enough to efficiently solve exact cvp on its own .",
    "@xcite manage to solve exact cvp in spite of this difficulty because their dgs algorithm outputs very many samples , which they use to recursively find an exact closest vector . ]",
    "( in table  [ tab : dgs ] , we summarize the previous known algorithms for discrete gaussian sampling , together with the results of this work . )",
    ".[tab : dgs]known results concerning the problem of sampling from @xmath0 .",
    "lines marked with a * are new results .",
    "we have omitted some constants .",
    "@xmath27 is the smoothing parameter , as defined in  @xcite , and @xmath28 is the @xmath29th successive minimum .",
    "( they are related by @xmath30 , where the upper bound is tight for the lattices that are relevant for cryptography .",
    "we also have have @xmath31 . ) [ cols=\"<,<,<,<,<\",options=\"header \" , ]     all of these results reflect the increasing prominence of discrete gaussian sampling algorithms in computer science .",
    "however , they left open a natural question : what is the complexity of dgs itself ?",
    "in particular , prior to this work , dgs was one of the only prominent lattice problems not known to be reducible to cvp via a dimension - preserving reduction .",
    "( another important example is the lattice isomorphism problem . ) in fact , previously , there was simply no known algorithm that sampled from @xmath0 for an arbitrary shift @xmath13 and parameter @xmath18 , and it was not even known whether sampling from the _ centered _ distribution @xmath20 could be reduced to a problem in np .",
    "( since dgs is a sampling problem , it technically can not be placed directly in classes of decision problems or search problems like np or fnp .",
    "but , we can still reduce it to such problems .",
    "see , e.g. ,  @xcite for a discussion of the complexity of sampling problems and their relationship to search problems . )      our first main result is a dimension - preserving reduction from discrete gaussian sampling to cvp .",
    "( see theorem  [ thm : dgstocvp ] . )",
    "this immediately implies two important corollaries .",
    "first , together with the relatively straightforward reduction from cvp to dgs(see section  [ sec : cvptodgs ] ) , this shows that cvp and dgs are equivalent via efficient dimension - preserving reductions .",
    "in particular , this suggests that the approach of @xcite is in some ( weak ) sense the `` correct '' way to attack cvp , since we now know that any faster algorithm for cvp necessarily implies a similarly efficient discrete gaussian sampler , and vice versa .",
    "second , together with the result of @xcite , this gives a @xmath5-time algorithm for discrete gaussian sampling that works for any parameter @xmath4 and shift @xmath13 , the first known algorithm for this problem .",
    "our second main result is a dimension - preserving reduction from _ centered _ dgs to svp .",
    "( see theorem  [ thm : dgstosvp ] . ) as we describe below , this result requires quite a bit more work , and we consider it to be more surprising , since , in a fixed dimension , an svp oracle seems to be significantly weaker than a cvp oracle .",
    "in contrast to the cvp case , we know of no efficient reduction from svp to centered dgs , and we do not even know whether centered dgs is np - hard .",
    "( while @xcite use centered dgs to solve svp , they require exponentially many samples to do so . ) the full version , we present only a much weaker reduction from @xmath7-approximate svp to centered dgs for any @xmath8 .",
    "we also show that , for any @xmath32 , no `` simple '' reduction from @xmath7-svp to centered dgs will work .",
    "( see section  [ sec : svptodgs ] . ) finally , we note that our proofs do not make use of any unique properties of the discrete gaussian or of the @xmath33 norm .",
    "we therefore show a much more general result : any distribution that is close to a weighted combination of uniform distributions over balls in some norm reduces to cvp in this norm .",
    "( see section  [ sec : other ] . ) in particular , sampling from the natural @xmath34 analogue of the discrete gaussian is equivalent to cvp in the @xmath34 norm , under efficient dimension - preserving reductions .",
    "we imagine that a similar result holds for svp , but since we know of no application , we do not endeavor to prove such a result in the more difficult setting of svp .",
    "now provide a high - level description of our techniques .",
    "[ [ reduction - from - dgs - to - cvp . ] ] reduction from dgs to cvp .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + +    our basic idea is to sample from the discrete gaussian @xmath0 in two natural steps .",
    "we first sample some radius @xmath35 from a carefully chosen distribution .",
    "we then sample a uniformly random point in @xmath36 .",
    "in particular , the distribution on the radius should assign probability to each radius @xmath35 that is roughly proportional to @xmath37 .",
    "( see the proof of theorem  [ thm : dgstocvp ] for the exact distribution . )",
    "so , in order to solve dgs , it suffices to ( 1 ) compute @xmath38 for arbitrary @xmath35 , and ( 2 ) sample a uniformly random point from @xmath36 .",
    "we actually use the same technical tool to solve both problems : lattice sparsification , as introduced by khot  @xcite ( though our analysis is more similar to that of dadush and kun  @xcite and @xcite ) .",
    "intuitively , sparsification allows us to sample a random sublattice @xmath39 of index @xmath40 such that for any vector @xmath41 , we have @xmath42 \\approx 1/p$ ] .",
    "suppose we could find a sublattice @xmath43 such that for the closest @xmath44 points to @xmath13 in @xmath11 , we have @xmath42 = 1/p$ ] , independently of the other points .",
    "then , this would suffice for our two use cases .",
    "in particular , if the lattice has @xmath45 points in the ball of a given radius around @xmath13 , then @xmath46 would have a point in this ball with probability very close to @xmath47 .",
    "we can use a cvp oracle to approximate this probability empirically , and we therefore obtain a good approximation for the number of lattice points in any ball .",
    "( achieve an approximation factor of @xmath48 for any @xmath49 .",
    "see theorem  [ thm : counter ] . ) similarly , if we know that the number of lattice points in a ball of radius @xmath35 around @xmath13 is roughly @xmath45 , then we can take @xmath50 and repeatedly sample @xmath43 until @xmath43 has a point inside the ball of radius @xmath35 around @xmath13 .",
    "the resulting point will be a nearly uniformly random sample from the lattice points in the ball of radius @xmath35 around @xmath13 .",
    "combining these two operations allows us to sample from the discrete gaussian using a cvp oracle , as described above .",
    "( see theorem  [ thm : dgstocvp ] . )    unfortunately , sparsification does not give us exactly this distribution .",
    "more specifically , sparsification works as follows .",
    "given a prime @xmath40 and lattice basis @xmath51 , we sample @xmath52 uniformly at random and define the corresponding sparsified sublattice as @xmath53 then , for any vector @xmath41 , we have @xmath42 = 1/p$ ] unless @xmath54 ( in which case @xmath1 is always in @xmath43 ) . unfortunately ,",
    "even if we ignore the issue that points in @xmath55 do not behave properly , it is easy to see that these probabilities are not at all independent .",
    "for example , if @xmath56 , then @xmath57 if and only if @xmath58 .",
    "of course , more complex dependencies can exist as well .",
    "fortunately , we can get around this by using an idea from @xcite ( and implicit in @xcite ) .",
    "in particular , we can show that the probabilities are close to independent if we also shift the sublattice @xmath43 by a `` random lattice vector '' @xmath59 .",
    "i.e. , while the distribution of the points in @xmath60 might be very complicated , each point in @xmath61 will land in @xmath62 with probability @xmath63 , and their distributions are nearly independent .",
    "( see theorem  [ thm : shiftedsparsification ] for the precise statement . )",
    "our cvp oracle makes no distinction between lattices and shifted lattices ( we can just shift @xmath13 by @xmath64 ) , so this solution suffices for our purposes .    [",
    "[ reduction - from - centered - dgs - to - svp . ] ] reduction from centered dgs to svp",
    ". + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    our reduction from centered dgs to svp uses the same high - level ideas described above , but the details are a bit more complicated . as in the cvp case ,",
    "our primary tool is lattice sparsification , in which we choose a sparsified sublattice as in eq .  .",
    "as before , we wish to control the distribution of the shortest vector in @xmath43 , and we note that , ignoring degenerate cases , @xmath1 is a shortest vector of @xmath43 if and only if @xmath57 and @xmath65 where the @xmath66 are the non - zero lattice vectors shorter than @xmath1 ( up to sign ) . however , as in the cvp case , this probability can be affected by linear dependencies . in the cvp case , we solved this problem by considering a random shift of @xmath43 .",
    "but , this solution clearly does not work here because an svp oracle simply `` can not handle '' shifted lattices .",
    "we therefore have to deal explicitly with these dependencies .",
    "the most obvious type of dependency occurs when @xmath1 is not _ primitive _ , so that @xmath67 for @xmath68 . in this case",
    ", there is nothing that we can do@xmath69 is shorter than @xmath1 and @xmath70 if and only if @xmath57 , so @xmath1 will _ never _ be a shortest non - zero vector in @xmath43 .",
    "we therefore are forced to work with only primitive vectors ( i.e. , lattice vectors that are not a scalar multiple of a shorter lattice vector ) .",
    "even if we only consider primitive vectors , it can still be the case that two such vectors are scalar multiples of each other mod @xmath40 , @xmath71 .",
    ", we show that this can only happen if there are @xmath72 primitive vectors shorter than @xmath1 in the lattice , so that this issue does not affect the @xmath72 shortest primitive vectors .",
    "( see lemma  [ lem : nogoodnameforthislemma ] . )",
    "we also show that higher - order dependencies ( e.g. , equations of the form @xmath73 ) have little effect .",
    "( see lemma  [ lem : almostindependent].)the full version , we show that such issues can be overcome .",
    "so , the shortest non - zero vector in the sparsified lattice will be distributed nearly uniformly over the @xmath72 shortest primitive vectors in the original lattice .",
    "( see theorem  [ thm : sparsification ] and proposition  [ prop : sparsifier ] for the precise statement , which might be useful in future work . )    as in the cvp case , this suffices for our purposes . in particular ,",
    "if there are @xmath45 _ primitive _ lattice vectors in the ball of radius @xmath35 centered at the origin for @xmath74 , then there will be a non - zero vector in @xmath75 with probability very close to @xmath47 . with an svp oracle , we can estimate this probability , and this allows us to approximate the number of primitive lattice vectors in a ball with very good accuracy .",
    "( see theorem  [ thm : primcounter ] . ) and , the sparsification algorithm and svp oracle also allow us to sample a primitive lattice vector in the ball of radius @xmath35 around the origin with nearly uniform probability , as in the cvp case .",
    "( see lemma  [ lem : uniformsampler ] . )    then , the same approach as before would allow us to use an svp oracle to sample from the discrete gaussian over the _ primitive _ lattice vectors . in order to obtain the true discrete gaussian , we first `` add @xmath76 in '' by estimating the total gaussian mass @xmath77 and returning @xmath76 with probability @xmath78 .",
    "second , after sampling a primitive vector @xmath1 using roughly the above idea , we sample an integer coefficient @xmath79 according to a one - dimensional discrete gaussian ( using an algorithm introduced by @xcite ) and output @xmath80 . if we choose the primitive vector appropriately , we show that the resulting distribution is @xmath20",
    ". might be strictly harder than centered dgs .",
    "in particular , in section  [ sec : svptodgs ] , we show a family of lattices for which @xmath20 almost never returns a @xmath81-approximate shortest vector . however , it is easy to see that the discrete gaussian over the _ primitive _ lattice vectors or even just over the lattice without @xmath76 will output the shortest vector with overwhelming probability if the parameter @xmath4 is sufficiently small . therefore , both of these sampling problems are actually polynomial - time equivalent to svp , while we have some evidence to suggest that sampling from @xmath20 is not .",
    "indeed , we know of no application of centered dgs in which non - primitive vectors are actually desirable . ]",
    "[ [ dgs - algorithms . ] ] dgs algorithms .",
    "+ + + + + + + + + + + + + + + +    there are now many very different algorithms for sampling from the discrete gaussian .",
    "( see table  [ tab : dgs ] . )",
    "the procedure of @xcite ( which was originally introduced by klein in a different context  @xcite and was later improved by brakerski et al .",
    "@xcite ) is a randomized variant of babai s celebrated nearest plane algorithm @xcite .",
    "it chooses the coordinates of a lattice vector in a given basis one - by - one by sampling from appropriate shifts of the @xmath29 one - dimensional gaussians generated by the gram - schmidt orthogonalization of the basis vectors .",
    "peikert showed a similar algorithm that uses the one - dimensional gaussians generated by the basis vectors themselves instead of their gram - schmidt orthogonalizations  @xcite .",
    "this yields an elliptical discrete gaussian , and peikert convolves this with an elliptical continuous gaussian in a clever way to obtain a spherical discrete gaussian .",
    "both of these algorithms are useful for building trapdoor primitives because they can sample from lower parameters if the input basis is shorter .    from our perspective",
    ", the algorithms of @xcite and @xcite can be viewed as reductions from dgs with high parameters @xmath4 to approximate svp , where a better approximation factor allows us to sample with a lower parameter @xmath4 by finding a better basis . and",
    ", regev  @xcite explicitly showed a _ quantum _ reduction from dgs with large @xmath4 to a different lattice problem .",
    "indeed , many reductions between lattice problems start by sampling vectors from @xmath20 for some large @xmath4 using one of these algorithms and then using an oracle for some lattice problem to find small combinations of the samples whose average lies in the lattice ( e.g. ,  @xcite )",
    ". one can show that the distribution of the resulting average will be close to @xmath82 for some @xmath83 ( as long as certain conditions are met ) .",
    "however , all of the above - mentioned algorithms only work above the smoothing parameter of the lattice because they incur error that depends on `` how smooth '' the distribution is .",
    "recently , @xcite showed that the averages of pairs of vectors sampled from the centered discrete gaussian will be distributed _ exactly _ as discrete gaussians with a lower parameter , as long as we condition on the averages lying in the lattice .",
    "they then showed how to choose such pairs efficiently and proved that this is sufficient to sample from any centered discrete gaussian in @xmath5 time  even for parameters @xmath4 below smoothing .",
    "@xcite then extended this idea to arbitrary gaussians ( as opposed to just centered gaussians ) with very low parameters @xmath84 . in both cases , the sampler actually outputs exponentially many vectors from the desired distribution .",
    "[ [ sparsification . ] ] sparsification .",
    "+ + + + + + + + + + + + + + + +    the samplers in this work approach discrete gaussian sampling in a completely different way .",
    "( indeed , the author repeatedly tried and failed to modify the above techniques to work in our context . ) instead , as we described above , we use a new method of sampling based on lattice sparsification .",
    "this tool was originally introduced by khot for the purposes of proving the hardness of approximating svp  @xcite .",
    "khot analyzed the behavior of sparsification only on the specific lattices that arose in his reduction , which were cleverly designed to `` behave nicely '' when sparsified .",
    "later , dadush and kun analyzed the behavior of sparsification over general lattices  @xcite and introduced the idea of adding a random shift to the target in order to obtain deterministic approximation algorithms for cvp in any norm .",
    "dadush , regev , and stephens - davidowitz used a similar algorithm to obtain a reduction from approximate cvp to the same problem with an upper bound on the distance to the lattice ( and a slightly smaller approximation factor )  @xcite .",
    "our sparsification analysis in the cvp case is most similar to that of  @xcite , though our reduction requires tighter analysis .",
    "however , in the svp case our analysis is quite different from that of prior work . in particular",
    ", we deal explicitly with primitive lattice vectors , which allows us to tightly analyze the behavior of sparsification without a random shift .",
    "this seems necessary for studying the distribution of the shortest vector of an arbitrary sparsified lattice , but prior work managed to avoid this by either working with a specific type of lattice or adding a random shift .",
    "our use case for sparsification is also novel . in all prior work , sparsification",
    "was used to `` filter out annoying short vectors , leaving only desirable vectors behind . ''",
    "we instead use it specifically to sample from the resulting distribution of the shortest or closest vector in the sparsified lattice .",
    "we suspect that this technique will have additional applications .",
    "[ [ dimension - preserving - reductions . ]",
    "] dimension - preserving reductions .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    more generally , this paper can be considered as part of a long line of work that studies the relationships between various lattice problems under dimension - preserving reductions .",
    "notable examples include  @xcite , which showed that svp reduces to cvp ;  @xcite , which gave a reduction from sivp to cvp ; and  @xcite , which showed the equivalence of usvp , gapsvp , and bdd up to polynomial approximation factors .",
    "in particular , this work together with  @xcite shows that exact sivp , exact cvp , and dgs are all equivalent under dimension - preserving reductions .",
    "( see  @xcite for a summary of such reductions . )",
    "[ [ centered - dgs . ] ] centered dgs .",
    "+ + + + + + + + + + + + + +    in this work , we completely characterize the complexity of arbitrary discrete gaussian sampling by showing that it is equivalent to cvp under dimension - preserving reductions .",
    "but , the complexity of centered dgs is still unknown .",
    "this is therefore the most natural direction for future work . in particular , we show that centered dgs is no harder than svp ( and therefore no harder than np ) , but our lower bound only shows that it is at least as hard as @xmath7-approximate svp for any @xmath8 .",
    "the decision version of svp is not np - hard for such high approximation factors unless the polynomial hierarchy collapses , so there is a relatively large gap between our lower and upper bounds .",
    "indeed , for @xmath85 , the decision version of @xmath7-approximate svp is known to be in co - am , and even in szk  @xcite .",
    "we provide some ( relatively weak ) evidence to suggest that @xmath8 is the best achievable approximation factor ( see section  [ sec : svptodgs ] ) , and we therefore ask whether centered dgs can be reduced to an easier problem  perhaps even the search variant of a problem in @xmath86 .    a related and arguably much more important question is whether there is an algorithm for centered dgs that is faster than the @xmath5-time algorithm of  @xcite  perhaps a sampler that outputs only one sample , as opposed to exponentially many .",
    "indeed ,  @xcite discuss possible ways to improve their techniques to achieve a roughly @xmath87-time algorithm for centered dgs , and they make some progress towards this goal .",
    "it seems that entirely new techniques would be needed to achieve running times below @xmath88 .",
    "any algorithm with a substantially better constant in the exponent would be the asymptotically fastest algorithm to break nearly all lattice - based cryptographic schemes .",
    "[ [ reductions - to - approximate - lattice - problems . ] ] reductions to approximate lattice problems .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we note that the sampling algorithm of  @xcite and many of the dgs subroutines used in hardness proofs can be seen as dimension - preserving reductions from dgs with very high parameters to _ approximate _ lattice problems .",
    "if one simply plugs an exact svp solver into these reductions , they will still only work for very high parameters .",
    "( more specifically , these works can be seen as reducing dgs with @xmath89 to @xmath7-approximate svp or sivp . ) our reductions , on the other hand , can handle any parameter but only work with exact solvers .",
    "we therefore ask if there are better reductions from dgs to _ approximate _ lattice problems with a better lower bound on the parameter @xmath4 than the one obtained in  @xcite .",
    "ideally , we would like a smooth trade - off between the approximation factor @xmath7 and the lower bound on the parameter @xmath4 that matches our result that works for any @xmath4 in the exact case when @xmath90 .",
    "but , any non - trivial improvement over  @xcite would be a major breakthrough .",
    "( a dimension - preserving reduction from dgs with parameter @xmath91 to @xmath7-approximate cvp would show that the two problems are equivalent and therefore completely characterize dgs . furthermore ,  @xcite show that it actually suffices to handle cases when either @xmath92 or @xmath4 is above the smoothing parameter . )",
    "indeed , it is still plausible that we could obtain a dimension - preserving reduction from _ centered _ dgs to @xmath7-approximate svp for some @xmath93 .",
    "a reduction with @xmath8 would completely characterize the complexity of centered dgs , but it seems far out of reach .",
    "however , any non - trivial @xmath94 would be quite interesting .",
    "in fact , dgs is essentially equivalent to centered dgs above the smoothing parameter .",
    "( see , e.g. ,  ( * ? ? ?",
    "* section 5.4 ) . )",
    "so , a result for centered dgs might also advance the study of arbitrary dgs above smoothing .",
    "for @xmath95 , we write @xmath96 to represent the @xmath33 norm of @xmath1 .",
    "( except for the last section , this is the only norm that we consider . )",
    "we write @xmath97 to represent the ( closed ) ball of radius @xmath35 in @xmath98 , @xmath99 .",
    "will make repeated use of the simple fact that @xmath100 for any constant @xmath101.of the proofs that are not included in this extended abstract can be found in the full version .",
    "lattice @xmath102 is the set of all integer linear combinations of linearly independent vectors @xmath103 .",
    "@xmath51 is called a basis of the lattice .",
    "as the basis is not unique , we often refer to the lattice itself , as opposed to its representation by a basis .",
    "we write @xmath104 for the length of a shortest non - zero vector in the lattice , and @xmath105 is the length of a shortest vector in the lattice that is linearly independent from a vector of length @xmath104 . for any @xmath106 , we define @xmath107 , and the covering radius is then @xmath108",
    ".    will need basic bounds on @xmath104 and @xmath109 for rational lattices in terms of the bit length of the basis .",
    "( many of our results are restricted to lattices and targets in @xmath110 entirely for the sake of bounds like this .",
    "we could instead work over the reals , provided that the chosen representation of real numbers leads to similar bounds . )",
    "[ lem : lambda1bitlength ] for any lattice @xmath9 with basis @xmath111 , let @xmath112 be a bound on the bit length of @xmath113 for all @xmath114 in the natural representation of rational numbers .",
    "then , @xmath115 and @xmath116    the first upper bound is trivial , as @xmath117 . for the lower bound , let @xmath118 be a the minimal positive integer such that @xmath119 .",
    "note that @xmath120 . then , for any vector @xmath41 , we have @xmath121 .",
    "therefore , @xmath122 .",
    "similarly , the lower bound on @xmath109 is trivial , as @xmath123 . for the upper bound",
    ", we have @xmath124 .",
    "following lemma is due to  @xcite .",
    "[ lem : weakkl ] for any lattice @xmath102 and @xmath125 , @xmath126    [ cor : ballcountingbitlength ] for any lattice @xmath9 with basis @xmath127 , @xmath12 , and @xmath125 , let @xmath112 be a bound on the bit length of the @xmath113 for all @xmath114 in the natural representation of rational numbers .",
    "then , @xmath128    it suffices to bound @xmath129 .",
    "the result then follows by applying lemma  [ lem : lambda1bitlength ] and lemma  [ lem : weakkl ] .      for @xmath95 and @xmath18",
    ", we write @xmath130 . for @xmath131 , a discrete set , we write @xmath132 , and we define the discrete gaussian distribution over @xmath133 with parameter @xmath4 , @xmath134 , as the distribution that assigns probability @xmath135 to all @xmath136 .",
    "when @xmath137 , we omit it and simply write @xmath138 , @xmath139 , etc .    proved the following two useful bounds on the discrete gaussian over lattices @xcite .",
    "[ lem : rholt ] for any lattice @xmath102 , @xmath18 , and @xmath106 , @xmath140    [ lem : banaszczyk ] for any lattice @xmath141 , @xmath18 , @xmath106 , and @xmath142 , @xmath143 < \\frac{\\rho_s({\\mathcal{l}})}{\\rho_s({\\mathcal{l}}- { \\ensuremath{\\mathbf{t}}})}\\big ( \\sqrt{2 \\pi e r^2 } \\exp(-\\pi r^2 ) \\big)^n \\ ; .\\ ] ]    this , we derive a corollary similar to ( * ? ? ?",
    "* corollary 2.7 ) .",
    "[ cor : shiftedbanaszczyk ] for any lattice @xmath102 , @xmath18 , @xmath144 , and @xmath145 , @xmath146 < \\big ( \\sqrt{2 \\pi e r^{\\prime 2 } } \\exp(-\\pi r^{2 } ) \\big)^n \\ ; , \\ ] ] where @xmath147 .",
    "in particular , if @xmath148 then @xmath146 < e^{-r^2n } \\ ; .\\ ] ]    combining the above two lemmas , we have @xmath149 & < e^{\\pi \\length{{\\ensuremath{\\mathbf{t}}}}^2/s^2}\\cdot \\big ( \\sqrt{2 \\pi e r^{\\prime 2 } } \\exp(-\\pi r^{\\prime 2 } ) \\big)^n \\\\ & =   \\big ( \\sqrt{2 \\pi e r^{\\prime 2 } } \\exp(-\\pi r^{2 } ) \\big)^n \\ ; , \\end{aligned}\\ ] ] as needed .",
    "now , suppose , @xmath150 .",
    "we consider two cases .",
    "first , suppose @xmath151 .",
    "then , we have @xmath152 , and the result follows . otherwise , we have @xmath153 so , @xmath154 as needed .",
    "[ cor : shiftedbanaszczyk ] for any lattice @xmath9 , @xmath18 , @xmath155 , and @xmath156 , @xmath146 < e^{-r^2n } \\ ; .\\ ] ]    following lemma is actually true for `` almost all lattices , '' in a certain precise sense that is outside the scope of this paper .",
    "( see , e.g. ,  @xcite . )",
    "[ lem : randomlattice ] for any @xmath157 , there is a lattice @xmath9 such that for any @xmath18 , @xmath158 and @xmath159 .      for any parameter @xmath160 , @xmath7-svp ( the shortest vector problem )",
    "is the search problem defined as follows : the input is a basis @xmath51 for a lattice @xmath9 .",
    "the goal is to output a lattice vector @xmath1 with @xmath161 .    for any parameter @xmath160 , @xmath7-cvp ( the closest vector problem )",
    "is the search problem defined as follows : the input is a basis @xmath51 for a lattice @xmath9 and a target vector @xmath12 .",
    "the goal is to output a lattice vector @xmath1 with @xmath162 .",
    "svp ( the shortest vector problem ) is the search problem defined as follows : the input is a basis @xmath51 for a lattice @xmath9 .",
    "the goal is to output a lattice vector @xmath1 with @xmath163 .",
    "cvp ( the closest vector problem ) is the search problem defined as follows : the input is a basis @xmath51 for a lattice @xmath9 and a target vector @xmath12 .",
    "the goal is to output a lattice vector @xmath1 with @xmath164 .",
    "will mostly be interested in the exact case , when @xmath90 , in which case we simply write svp and cvp respectively .",
    "note that there may be many shortest lattice vectors or closest lattice vectors to @xmath13 .    for @xmath160 and @xmath165",
    ", we say that a distribution @xmath166 is @xmath167-close to a distribution @xmath168 if there is another distribution @xmath169 with the same support as @xmath168 such that    1 .",
    "the statistical distance between @xmath166 and @xmath169 is at most @xmath170 ; and 2 .   for all @xmath171 in the support of @xmath168 , @xmath172/\\gamma \\leq \\pr[x ' = x ]",
    "\\leq \\gamma \\pr[y = x ] $ ] .    for any parameters @xmath173 and @xmath160 , @xmath167-dgs ( the discrete gaussian sampling problem ) is defined as follows : the input is a basis @xmath51 for a lattice @xmath9 , a shift @xmath12 , and a ( rational ) parameter @xmath18 .",
    "the goal is to output a vector whose distribution is @xmath167-close to @xmath0 .    for any parameters @xmath173 and @xmath160 , @xmath167-cdgs ( the centered discrete gaussian sampling problem ) is defined as follows : the input is a basis @xmath51 for a lattice @xmath9 and a ( rational ) parameter @xmath18 .",
    "the goal is to output a vector whose distribution is @xmath167-close to @xmath20 .",
    "is typically defined with an additional parameter @xmath174 , such that the algorithm only needs to output discrete gaussian samples if @xmath175 . since both of our reductions achieve @xmath176 , we omit this parameter .",
    "brakerski , langlois , peikert , regev , and stehl show how to efficiently sample from the one - dimensional discrete gaussian @xmath177 for any @xmath178 and @xmath18  @xcite . for completeness",
    ", we describe a slightly modified version of their algorithm to sample from @xmath179 .",
    "[ lem : samplez ] there is an algorithm that samples from @xmath179 for any @xmath18 in ( expected ) polynomial time .",
    "we describe an algorithm that samples from @xmath180 , which is clearly sufficient .",
    "let @xmath181 .",
    "the algorithm outputs @xmath182 with probability @xmath183 . otherwise , it samples @xmath171 from the one - dimensional continuous gaussian with parameter @xmath4 restricted to the interval @xmath184 .",
    "let @xmath185 . with probability @xmath186 , the algorithm outputs @xmath187 .",
    "otherwise , it repeats .    on a single run of the algorithm , for any integer @xmath188 , the probability that the algorithm outputs @xmath189 is @xmath190 and , the probability that the algorithm outputs @xmath182 is of course @xmath183 .",
    "so , the algorithm outputs the correct distribution .",
    "it remains to bound the expected running time . after a single run ,",
    "the algorithm outputs an integer with probability @xmath191 it follows that it runs in expected polynomial time .",
    "furthermore , we will need to efficiently compute @xmath192 for arbitrary @xmath4 .",
    "brakerski et al .",
    "give a simple algorithm for this problem as well .",
    "( here , we ignore the bit - level concerns of what it means to `` efficiently compute '' a real number , as this will not be an issue for us . )",
    "[ clm : computerhoz ] there is an efficient algorithm that computes @xmath192 .",
    "our primary technical tool will be lattice sparsification , in which we consider the sublattice @xmath193 where @xmath40 is some prime , @xmath52 is uniformly random , and @xmath51 is a basis of the lattice @xmath9 .",
    "as such , we will need some lemmas concerning the behavior of lattice vectors mod @xmath55 .",
    "we first simply note that we can compute @xmath43 efficiently .",
    "[ clm : efficientsparse ] there is a polynomial - time algorithm that takes as input a basis @xmath51 for a lattice @xmath102 , a number @xmath194 , and a vector @xmath52 and outputs a basis @xmath195 for @xmath196    on input @xmath197 , @xmath194 , and @xmath198 , if @xmath199 , the algorithm simply outputs @xmath51 .",
    "otherwise , we assume without loss of generality that @xmath200 .",
    "the algorithm then computes @xmath201 .",
    "it sets @xmath202 finally , it outputs @xmath203 .",
    "a quick computation shows that @xmath204 has full rank and that @xmath195 is indeed a basis for @xmath43 .",
    "since we will only be concerned with the coordinates of the vectors mod @xmath40 , it will suffice to work over @xmath205 .",
    "[ lem : almostindependent ] for any prime @xmath40 and collection of vectors @xmath206 such that @xmath1 is not a scalar multiple of any of the @xmath207 , we have @xmath208 \\leq \\frac{1}{p } \\ ; , \\ ] ] where @xmath209 is sampled uniformly at random from @xmath205 .    for the upper bound , it suffices to note that , since @xmath1 is non - zero , @xmath210 is uniformly distributed over @xmath211 .",
    "therefore , @xmath212 = 1/p$ ] . for the lower bound , note that @xmath213 and @xmath214 are distinct subspaces of dimension @xmath215 . therefore , @xmath216 is a subspace of dimension @xmath217 with @xmath218 elements .",
    "let @xmath219 .",
    "it follows that @xmath220 & = \\frac{|a \\setminus b|}{|{\\ensuremath{\\mathbb{z}}}_p^n |}\\\\ & \\geq \\frac{|a| - \\sum_i |a \\cap b_i|}{|{\\ensuremath{\\mathbb{z}}}_p^n|}\\\\ & = \\frac{p^{n-1 } - n p^{n-2}}{p^n}\\\\ & = \\frac{1}{p } -\\frac{n}{p^2 } \\ ; .\\end{aligned}\\ ] ]    [ cor : shiftedindependence ] for any prime @xmath40 , collection of vectors @xmath221 , and @xmath222 with @xmath223 for any @xmath114 , we have @xmath224 \\leq \\frac{1}{p } + \\frac{1}{p^{n } } \\ ; , \\ ] ] where @xmath225 and @xmath226 are sampled uniformly and independently at random from @xmath205 .    for the upper bound , it suffices to note that @xmath227 \\leq \\frac{1}{p } + \\frac{1}{p^n}$ ] .    turning to the lower",
    "bound , note that for any @xmath114 , we have @xmath228 = 1/p^n$ ] . by union",
    "bound , the probability that @xmath229 for any @xmath114 is at most @xmath230 .",
    "now , fix @xmath114 , and note that if there exists some @xmath231 such that @xmath232 , then we must have @xmath233 there are therefore at most @xmath234 values for @xmath235 that satisfy the above ",
    "one for each value of @xmath236 .",
    "so , the probability that @xmath235 will satisfy the above equation for any @xmath236 is at most @xmath237 . taking a union bound over all @xmath114 , we see that the probability that @xmath238 is a multiple of any of the @xmath239 is at most @xmath240 .",
    "the result then follows from lemma  [ lem : almostindependent ] and union bound .      a lattice @xmath102",
    ", we say that @xmath41 is non - primitive in @xmath11 if @xmath241 for some @xmath242 and @xmath243 .",
    "otherwise , @xmath1 is primitive in @xmath11 .",
    "let @xmath244 be the set of primitive vectors in @xmath11 .",
    "for a radius @xmath125 , let @xmath245 be the number of primitive lattice vectors in a ( closed ) ball of radius @xmath35 around the origin ( counting @xmath1 and @xmath246 as a single vector )",
    ".    will need the following technical lemma , which shows that relatively short primitive vectors can not be scalar multiples of each other mod @xmath40 .",
    "[ lem : nogoodnameforthislemma ] for any lattice @xmath102 with basis @xmath51 , suppose @xmath247 are primitive with @xmath248 and @xmath249 such that @xmath250 for any number @xmath251 and @xmath252 .",
    "then , @xmath253 .",
    "we assume @xmath254 , since otherwise @xmath255 is not even primitive .",
    "so , we have that @xmath256 for some integer @xmath257 with @xmath258 .",
    "let @xmath259 and note that @xmath260 is not a multiple of @xmath261 .",
    "it suffices to find at least @xmath262 primitive vectors in the lattice spanned by @xmath260 and @xmath261 that are at least as short as @xmath255 .",
    "we consider two cases .",
    "if @xmath263 , then for @xmath264 , the vectors @xmath265 are clearly primitive in the lattice spanned by @xmath260 and @xmath261 , and we have @xmath266 as needed .    now , suppose @xmath267 . then , for @xmath268 , let @xmath269 be an integer such that @xmath270 and @xmath271 .",
    "( note that such an integer exists , since @xmath272 ) .",
    "then , @xmath273 when @xmath114 is prime , then since @xmath271 , we must have @xmath274 .",
    "therefore , the vector @xmath275 must be primitive in the lattice spanned by @xmath260 and @xmath261 when @xmath114 is prime .",
    "it follows from a suitable effective version of the prime number theorem that there are at least @xmath262 primes between @xmath276 and @xmath277 ( see , e.g. , @xcite ) , as needed .",
    "we next show that we can find many primitive lattice vectors in a suitably large ball around @xmath76 .",
    "[ lem : notdegenerate ] for any lattice @xmath102 and radius @xmath278 , @xmath279    let @xmath280 with @xmath281 and @xmath282 .",
    "then , for @xmath283 , @xmath284 similarly , for @xmath285 , @xmath286 the result follows by noting that all of these vectors are distinct and primitive in the lattice generated by @xmath287 ( as is @xmath288 ) .      we will also need the chernoff - hoeffding bound  @xcite .",
    "[ lem : chernoff ] let @xmath289 be independent and identically distributed random variables with @xmath290 and @xmath291 $ ] .",
    "then , for @xmath18 @xmath292 \\leq e^{-s^2/n } \\ ; , \\ ] ] and @xmath293 \\leq e^{-s^2/n } \\ ; .\\ ] ]",
    "we now present the main sparsification result that we require . in particular theorem  [ thm : shiftedsparsification](which is immediate from the work done in section  [ sec : sparseprelims ] , and is presented in this form here for the reader s convenience ) shows the generic behavior of the sparsification procedure .",
    "proposition  [ prop : shiftedsparsifier ] then applies the theorem to show how sparsification interacts with a cvp oracle .",
    "[ thm : shiftedsparsification ] for any lattice @xmath102 with basis @xmath51 , prime @xmath40 , and lattice vectors @xmath294 such that @xmath295 for all @xmath114 , we have @xmath296 \\leq    \\frac{1}{p } + \\frac{1}{p^n } \\ ; , \\ ] ] where @xmath297 are chosen uniformly and independently at random",
    ".    simply apply corollary  [ cor : shiftedindependence ] to @xmath298 and @xmath299 .",
    "[ prop : shiftedsparsifier ] there is a polynomial - time algorithm that takes as input a basis @xmath51 for a lattice @xmath102 and a prime @xmath40 and outputs a full - rank sublattice @xmath300 and shift @xmath59 such that , for any @xmath106 , @xmath41 with @xmath301 , and any @xmath302 oracle , @xmath303 \\leq    \\frac{1}{p } + \\frac{1}{p^n } \\ ; .\\ ] ] particular , @xmath304   \\leq \\frac{n}{p } + \\frac{n}{p^n } \\ ; .\\ ] ]    on input @xmath102 with basis @xmath51 and @xmath40 , the algorithm samples @xmath297 uniformly and independently at random .",
    "it then returns the sublattice @xmath305 and the shift @xmath306 .    by claim  [ clm : efficientsparse ]",
    ", the algorithm can be run in polynomial time .",
    "let @xmath307 be the unique vectors such that @xmath308 with @xmath309 .",
    "note that @xmath310 must be @xmath311 if @xmath312 for all @xmath313 _ and _ @xmath314 .",
    "we therefore wish to apply theorem  [ thm : shiftedsparsification ] , which requires showing that @xmath315 for all @xmath114 .",
    "suppose on the contrary that @xmath316 for some @xmath114 .",
    "then , @xmath317 , and there are therefore @xmath318 lattice vectors on the line segment between @xmath69 and @xmath1 ( including the two endpoints ) .",
    "note that all of these vectors are at least as close to @xmath13 as @xmath1 .",
    "but , there can be at most @xmath319 such vectors , a contradiction .",
    "therefore , we can apply theorem  [ thm : shiftedsparsification ] , yielding the result .    as a consequence of proposition  [ prop : shiftedsparsifier ] ,",
    "we show that we can use a cvp oracle to sample nearly uniformly from the lattice points in a ball around @xmath13 .",
    "this relatively straightforward algorithm is the core idea behind our reduction . for simplicity",
    ", we provide the algorithm with an estimate of the number of points inside the ball as input .",
    "( in the next section , we show how to obtain this estimate using roughly the same techniques .",
    ") proof is in the full version .",
    "[ lem : shifteduniformsampler ] for any efficiently computable @xmath320 with @xmath321 , there is an algorithm with access to a cvp oracle that takes as input a lattice @xmath9 , shift @xmath12 , radius @xmath125 , and integer @xmath322 and outputs a vector @xmath260 such that , if @xmath323 then the algorithm runs in expected polynomial time , and for any @xmath324 , @xmath325 \\leq \\frac{\\gamma}{|{\\mathcal{l}}\\cap ( rb_2^n+ { \\ensuremath{\\mathbf{t}}})| } \\ ; , \\ ] ] where @xmath326 .",
    "furthermore , all of the algorithm s oracle calls are on full - rank sublattices of the input lattice .",
    "we assume without loss of generality that @xmath327 .",
    "on input @xmath9 , @xmath12 , @xmath328 , and @xmath322 , the algorithm chooses a prime @xmath40 with @xmath329 and calls the procedure from proposition  [ prop : shiftedsparsifier ] on input @xmath11 and @xmath40 , receiving as output a sublattice @xmath300 and a shift @xmath59 .",
    "it then calls its cvp oracle on input @xmath43 and @xmath330 , receiving as output @xmath331 .",
    "if @xmath332 , it outputs @xmath333 . otherwise , it repeats .    from proposition  [ prop : shiftedsparsifier ] , we have that , after a single run of the algorithm , @xmath334 \\leq \\frac{1}{p } + \\frac{1}{p^n } \\leq \\frac{\\sqrt{\\gamma}}{p } \\ ; .\\ ] ] correctness follows immediately .",
    "furthermore , note that the reduction outputs something on each run with probability at least @xmath335 .",
    "so , in particular , the expected number of runs is polynomial in @xmath29 .",
    "it is clear that a single run takes polynomial time , and the result follows .",
    "we now show how to use the sparsification algorithm to approximate the number of lattice points in a ball , given access to a cvp oracle .",
    "will use this both to instantiate the procedure from lemma  [ lem : shifteduniformsampler ] and directly in our dgs sampling procedure.proof is in the full version .    for any parameter @xmath160 , @xmath7-gapvcp ( the vector counting problem )",
    "is the promise problem defined as follows : the input is a lattice @xmath9 ( represented by a basis ) , shift @xmath12 , radius @xmath125 , and an integer @xmath322 .",
    "it is a no instance if @xmath336 and a yes instance if @xmath337 .    [ thm : counter ] for any efficiently computable function @xmath320 with @xmath338 , there is a polynomial - time reduction from @xmath7-gapvcp to cvp where @xmath326 .",
    "the reduction dimension and only calls the cvp oracle on sublattices of the input lattice .",
    "we assume without loss of generality that @xmath339 and @xmath340 . on input a lattice @xmath9 with basis @xmath51 , target @xmath12 , @xmath125 , and @xmath322",
    ", the reduction behaves as follows .",
    "first , it finds a prime @xmath40 with @xmath341 . then",
    ", for @xmath342 , the reduction calls the procedure from proposition  [ prop : shiftedsparsifier ] on @xmath11 , @xmath13 , and @xmath40 .",
    "it receives as output @xmath343 and @xmath344 .",
    "it then calls the cvp oracle on @xmath343 and @xmath345 , receiving as output a vector whose distance from @xmath345 is @xmath346 .",
    "finally , it returns yes if @xmath347 for all but at most @xmath348 values of @xmath346 and no otherwise .",
    "it is clear that the reduction runs in polynomial time . now , suppose @xmath349 . by proposition  [ prop : shiftedsparsifier ] , we have that for each @xmath114 , @xmath350 \\leq \\frac{n}{p } + \\frac{n}{p^n } < \\frac{n}{p } + \\frac{1}{2\\sqrt{\\ell } } \\ ; .\\ ] ] then , applying the chernoff - hoeffding bound ( lemma  [ lem : chernoff ] ) , we have @xmath351 < 1/e \\ ; .\\ ] ] so , the reduction returns the correct answer in this case with probability at least @xmath352 .    on the other hand",
    ", suppose that @xmath353 .",
    "using the lower bound in proposition  [ prop : shiftedsparsifier ] , @xmath350 \\geq \\frac{\\gamma n}{p } - \\frac{\\gamma^2 n^2}{p^2 } - \\frac{\\gamma^2 n^2}{p^{n-1 } } > \\frac{n}{p } + \\frac{5}{\\sqrt{\\ell } } \\ ; .\\ ] ] applying the chernoff - hoeffding bound again , we have @xmath354 < 1/e \\;,\\ ] ] as needed .",
    "[ thm : dgstocvp ] for any efficiently computable function @xmath320 with @xmath355 , there exists an ( expected ) polynomial - time reduction from @xmath167-dgs to cvp , where @xmath356 and @xmath326 .",
    "the reduction preserves dimension and only calls the cvp oracle on full - rank sublattices of the input lattice .",
    "we assume without loss of generality that @xmath357 and @xmath137 .",
    "( if @xmath358 , we can simply rescale the lattice . ) on input @xmath9 and @xmath12 , the reduction behaves as follows .",
    "it first calls its cvp oracle to compute @xmath359 . for @xmath360 , let @xmath361 . for each @xmath114 ,",
    "the reduction uses its cvp oracle together with the procedure given in theorem  [ thm : counter ] to compute @xmath362 such that @xmath363 .",
    "let @xmath364 , and for @xmath365 , let @xmath366 .",
    "let @xmath367 .",
    "the reduction then chooses an index @xmath368 , from the distribution that assigns to index @xmath114 probability @xmath369 .",
    "it then runs the procedure from lemma  [ lem : shifteduniformsampler ] with input @xmath11 , @xmath13 , @xmath370 , and @xmath371 , receiving as output a vector @xmath372 whose distribution is @xmath373-close to the uniform distribution over @xmath374 .",
    "it then simply returns @xmath260 .",
    "see that the reduction runs in polynomial time , first note that lemma  [ lem : lambda1bitlength ] implies that @xmath375 is polynomial in the length of the input .",
    "similarly , corollary  [ cor : ballcountingbitlength ] implies that the @xmath362 have bit lengths polynomial in the length of the input .",
    "it follows that the reduction runs in expected polynomial time .",
    "we now prove correctness.is clear that the reduction runs in polynomial time .",
    "let @xmath376 be the support of @xmath260 . by corollary  [ cor : shiftedbanaszczyk ]",
    ", @xmath377 is within statistical distance @xmath170 of @xmath378 , so it suffices to show that the output of the reduction is @xmath379-close to @xmath380 . in order to show this , it suffices to show that , for any @xmath136 , @xmath381 $ ] is proportional to @xmath138 , up to a factor of @xmath382 .. note that @xmath383 = \\frac{1}{w } \\sum_{i\\ : \\",
    "r_i \\geq \\length{{\\ensuremath{\\mathbf{x } } } - { \\ensuremath{\\mathbf{t } } } } } w_in_i \\cdot \\pr[{\\ensuremath{\\mathbf{y } } } = { \\ensuremath{\\mathbf{x } } } \\ |\\ k = i ]   \\ ; .\\ ] ] for any @xmath114 such that @xmath384 , by lemma  [ lem : shifteduniformsampler ] we have that @xmath385 \\leq \\frac{\\gamma^{1/10}}{|({\\mathcal{l}}- { \\ensuremath{\\mathbf{t } } } ) \\cap r_i b_2^n| } \\leq \\frac{\\gamma^{1/10}}{n_i }   \\ ; .\\ ] ] @xmath386 be minimal such that @xmath387 . plugging in the upper bound to eq .",
    ", we have @xmath388 \\leq \\frac{\\gamma^{1/10}}{w}\\cdot \\sum_{i \\geq j } w_i = \\frac{\\gamma^{1/10}}{w } \\cdot e^{-\\pi r_j^2 } \\leq \\frac{\\sqrt{\\gamma}}{w } \\cdot \\rho({\\ensuremath{\\mathbf{x } } } ) \\ ; .\\ ] ] a nearly identical computation shows that @xmath381 \\geq \\rho({\\ensuremath{\\mathbf{x}}})/(\\sqrt{\\gamma } w)$ ] , as needed.these bounds into eq .",
    "gives the result .",
    "we are now interested in the svp case , we can no longer handle the shifts used in theorem  [ thm : shiftedsparsification ] and proposition  [ prop : shiftedsparsifier ] ( neither the input shift @xmath13 nor the output shifts @xmath64 and @xmath235 ) . as a result",
    ", we are forced to consider the effect of sparsification on primitive vectors only , which requires new analysis .",
    "recall that @xmath389 is the number of primitive lattice vectors in a ball of radius @xmath35 ( counting @xmath390 as a single vector ) .",
    "[ thm : sparsification ] for any lattice @xmath102 with basis @xmath51 , primitive lattice vectors @xmath391 with @xmath392 for all @xmath393 , and prime @xmath394 , if @xmath395 for all @xmath114 , then @xmath396 \\leq \\frac{1}{p } \\ ; , \\ ] ] where @xmath52 is chosen uniformly at random .",
    "let @xmath397 .",
    "by lemma  [ lem : nogoodnameforthislemma ] , we have that @xmath398 is not a scalar multiple of @xmath207 mod @xmath40 for any @xmath393 .",
    "the result then follows from lemma  [ lem : almostindependent ] .",
    "proof of the next result is in the full version .",
    "[ prop : sparsifier ] there is a polynomial - time algorithm that takes as input a basis @xmath51 for a lattice @xmath102 and a prime @xmath394 and outputs a full - rank sublattice @xmath300 such that for every @xmath41 with @xmath399 and @xmath400 , we have that for any svp oracle , @xmath401 \\leq \\frac{1}{p } \\ ; .\\ ] ] particular , @xmath402   \\leq \\frac{n}{p } \\ ; .\\ ] ]    on input @xmath102 with basis @xmath51 and @xmath40 , the algorithm samples @xmath52 uniformly at random .",
    "it then returns the sublattice @xmath403    it is clear that the algorithm runs in polynomial time . since @xmath42 = 1/p$ ] , the upper bound on the probability is immediate as well .    for the lower bound ,",
    "let @xmath404 such that @xmath405 , @xmath406 , and @xmath407 .",
    "let @xmath397 .",
    "note that , if @xmath408 and @xmath409 for @xmath393 , then @xmath410 .",
    "( here , we have used the fact that @xmath400 . ) the result then follows from theorem  [ thm : sparsification ] .",
    "[ lem : uniformsampler ] for any efficiently computable @xmath320 with @xmath321 , there is an ( expected ) polynomial - time algorithm with access to a svp oracle that takes as input a lattice @xmath9 , radius @xmath125 , and integer @xmath322 and outputs a vector @xmath242 such that , if @xmath411 and @xmath412 , then for any @xmath413 ,",
    "@xmath414 \\leq \\frac{\\gamma}{\\xi({\\mathcal{l } } , r ) } \\ ; , \\ ] ] where @xmath415 . furthermore",
    ", the algorithm dimension and only calls its oracle on full - rank sublattices of @xmath11 .",
    "we assume without loss of generality that @xmath416 . on input @xmath9 , @xmath328 , and @xmath322",
    ", the algorithm chooses a prime @xmath40 with @xmath417 and calls the algorithm from proposition  [ prop : sparsifier ] on input @xmath11 and @xmath40 , receiving as output a sublattice @xmath39 .",
    "it then calls its svp oracle on input @xmath43 , receiving as output @xmath260 .",
    "if @xmath418 , it outputs @xmath260 . otherwise , it repeats .    from proposition  [ prop : sparsifier ]",
    ", we have that , after a single run of the algorithm @xmath419 \\leq \\frac{1}{p } \\ ; .\\ ] ] correctness follows immediately . furthermore , note that the algorithm terminates after a given run with probability at least @xmath420 . by corollary  [ cor : ballcountingbitlength ]",
    ", @xmath421 is polynomial in the length of the input .",
    "so , in particular , the expected number of runs is polynomial in the length of the input .",
    "it is clear that a single run takes polynomial time , and the result follows .      for any parameters @xmath422 , @xmath160 , @xmath423-gappvcp ( the primitive vector counting problem )",
    "is the promise problem defined as follows : the input is a lattice @xmath9 ( represented by a basis ) , radius @xmath125 , and an integer @xmath322 .",
    "it is a no instance if @xmath424 or if @xmath425 and a yes instance if @xmath426 .    ,",
    "the condition that @xmath425 handles the degenerate case in which there are many non - primitive vectors that may `` hide '' the primitive vectors in the lattice .",
    "it is not clear that this should be treated as a degenerate case in general , but it is clear that our methods fail in this case . the full version , we prove the following .",
    "[ thm : primcounter ] for any efficiently computable @xmath320 with @xmath355 , there is a polynomial - time reduction from @xmath423-gappvcp to svp where @xmath427 and @xmath326 .",
    "the reduction preserves dimension and only calls the svp oracle on sublattices of the input lattice .    on input",
    "@xmath9 with basis @xmath51 , @xmath125 , and @xmath322 , the reduction behaves as follows .",
    "it first calls its svp oracle on @xmath11 to compute @xmath104 .",
    "if @xmath428 or @xmath429 , it returns no .",
    "the reduction then finds a prime @xmath40 with @xmath430 , and for @xmath431 , it calls the procedure from proposition  [ prop : sparsifier ] on @xmath11 and @xmath40 , receiving as output @xmath343 .",
    "it then calls the svp oracle on each @xmath343 , receiving as output a vector of length @xmath346 .",
    "finally , it returns yes if @xmath347 for all but at most @xmath348 values of @xmath346 and no otherwise .",
    "it is clear that the reduction runs in polynomial time .",
    "we assume @xmath432 ( since otherwise the reduction clearly outputs the correct answer ) .",
    "suppose @xmath433 . by proposition  [ prop : sparsifier",
    "] , we have @xmath434 \\leq \\frac{m}{p } \\leq \\frac{n}{p } $ ] , for each @xmath114 . applying the chernoff - hoeffding bound ( lemma  [ lem : chernoff ] )",
    ", we have @xmath435 < 1/e   \\ ; .\\ ] ] so , the reduction returns the correct answer in this case with probability at least @xmath352 .    now , suppose @xmath436 .",
    "we again apply proposition  [ prop : sparsifier ] to obtain @xmath350 \\geq \\frac{\\gamma n}{p } - \\frac{\\gamma^2 n^2}{p^2 } > \\frac{n}{p } + \\frac{5}{\\sqrt{\\ell}}\\ ] ] applying the chernoff - hoeffding bound again , we have @xmath437 < 1/e   \\ ; .\\ ] ] the result follows .",
    "[ thm : dgstosvp ] for any efficiently computable function @xmath320 with @xmath355 , there is an ( expected ) polynomial - time reduction from @xmath167-cdgs to svp , where @xmath356 and @xmath326 .",
    "the reduction preserves dimension and only calls the svp oracle on sublattices of the input lattice .",
    "we assume without loss of generality that @xmath137 .",
    "( if @xmath358 , we can simply scale the lattice . ) on input @xmath9 , the reduction behaves as follows .",
    "first , it computes @xmath104 using its svp oracle . for @xmath438 ,",
    "let @xmath439 . for each @xmath114 ,",
    "the reduction uses its svp oracle together with the procedure given in theorem  [ thm : primcounter ] to compute @xmath362 such that @xmath440 or @xmath441 if @xmath442 .",
    "let @xmath443 , and for @xmath365 , let @xmath444 .",
    "(  [ clm : computerhoz]@xcite shows one way to compute @xmath445 efficiently . )",
    "let @xmath367 .",
    "then , the reduction outputs @xmath76 with probability @xmath446 .",
    "otherwise , it chooses an index @xmath368 , assigning to each index @xmath114 probability @xmath369 . if @xmath447 , the reduction then calls the procedure from lemma  [ lem : uniformsampler ] on input @xmath11 , @xmath370 , and @xmath371 , receiving as output a vector @xmath448 that is distributed uniformly over @xmath449 , up to a factor of @xmath450 . if @xmath451 , the reduction simply sets @xmath452 .",
    "finally , it the procedure from lemma  [ lem : samplez ] to sample an integer @xmath189 from @xmath453 and returns @xmath454 .",
    "( @xcite shows how to sample such an integer efficiently . )    , we note that the reduction runs in expected polynomial time .",
    "in particular , the @xmath362 have polynomial bit length by corollary  [ cor : ballcountingbitlength ] , and the various subprocedures have expected running times that are polynomial in the length of their input .",
    "we now prove correctness.is clear that the reduction runs in polynomial time .",
    "let @xmath455 be the set of all points that are integer multiples of a lattice vector whose length is at most @xmath456 .",
    "by lemma  [ lem : banaszczyk ] , it suffices to consider the distribution @xmath457 , as this is within statistical distance @xmath170 of @xmath139 .",
    "then , @xmath458 a quick computation shows that for any @xmath260 with @xmath459 , we have @xmath460 recalling the definition of the @xmath445 , it follows that @xmath461    now , we would like to say that @xmath462 , as in eq .  .",
    "this is of course true by definition _ except _ when @xmath463 and @xmath464 , i.e. , when @xmath442 and @xmath465 .",
    "but , in this case , a quick computation together with lemma  [ lem : notdegenerate ] shows that @xmath466 , and therefore @xmath467 satisfies eq .",
    "for all @xmath468 .",
    "( in other words , the @xmath362 can only be `` wrong '' for at most one value of @xmath114 . )",
    "it follows that , for any @xmath469 , we have @xmath470 ( the case @xmath471 can be handled separately .",
    "correctness in this case follows essentially immediately from lemma  [ lem : banaszczyk ] . ) putting everything together , we have that @xmath472 so , in particular , the probability that the reduction outputs @xmath76 is @xmath446 , which is a good approximation to the correct probability of @xmath473@xmath474 , as needed .",
    "now , for any @xmath475 , it follows from lemma  [ lem : uniformsampler ] and the argument above that @xmath476 \\leq \\gamma^{1/2 } \\cdot \\frac{\\rho_{1/\\length{{\\ensuremath{\\mathbf{y}}}}}({\\ensuremath{\\mathbb{z}}}\\setminus \\{0\\})}{\\rho({\\mathcal{l}}^\\dagger ) } \\ ; .\\ ] ] finally , for any @xmath477 , let @xmath260 be one of the two primitive lattice vectors that are scalar multiples of @xmath64 , and let @xmath478 such that @xmath479 .",
    "then , @xmath480 & = \\pr[{\\ensuremath{\\mathbf{x } } } = \\pm { \\ensuremath{\\mathbf{y } } } ] \\cdot \\pr[z = \\bar{z}\\ |\\ { \\ensuremath{\\mathbf{x } } } = \\pm { \\ensuremath{\\mathbf{y}}}]\\\\ & = \\pr[{\\ensuremath{\\mathbf{x } } } = \\pm { \\ensuremath{\\mathbf{y } } } ] \\cdot \\frac{\\rho({\\ensuremath{\\mathbf{w}}})}{\\rho_{1/\\length{{\\ensuremath{\\mathbf{y}}}}}({\\ensuremath{\\mathbb{z}}}\\setminus \\{0\\})}\\end{aligned}\\]]@xmath481 = \\pr[{\\ensuremath{\\mathbf{x } } } = \\pm { \\ensuremath{\\mathbf{y } } } ] \\cdot \\pr[z = \\bar{z}\\ |\\ { \\ensuremath{\\mathbf{x } } } = \\pm { \\ensuremath{\\mathbf{y}}}]= \\pr[{\\ensuremath{\\mathbf{x } } } = \\pm { \\ensuremath{\\mathbf{y } } } ] \\cdot \\frac{\\rho({\\ensuremath{\\mathbf{w}}})}{\\rho_{1/\\length{{\\ensuremath{\\mathbf{y}}}}}({\\ensuremath{\\mathbb{z}}}\\setminus \\{0\\})}\\ ] ] the result follows from plugging the above equation into eq .  .",
    "we note that our reductions from sections  [ sec : dgstocvp ] and  [ sec : dgstosvp ] do not use any unique properties of the discrete gaussian distribution or of the @xmath33 norm . above",
    ", we focused on this particular case because it has so many applications , while other distributions on lattices seem to be of much less interest . in this section , we show that a much larger class of sampling problems can be reduced to cvp in various different norms .",
    "first , we show that the sparsification result in proposition  [ prop : shiftedsparsifier ] naturally extends to arbitrary norms @xmath482 . in particular , for any norm @xmath482",
    ", we can use a cvp oracle in norm @xmath482 to sample ( nearly ) uniformly from the lattice points in a @xmath482-ball .",
    "( see below for the definitions . )",
    "we can naturally extend this to any distribution that can be efficiently written as the weighted average of uniform distributions over the lattice points in @xmath482-balls .",
    "for example , this will be enough to show how to use a cvp oracle in the @xmath34 norm to sample from the natural @xmath34 generalization of the discrete gaussian , which assigns to @xmath17 probability proportional @xmath483 , where @xmath484 for @xmath485 is the @xmath34 norm .",
    "below , we make this precise . for simplicity",
    ", we will not worry about the more difficult analogous problem of reducing sampling from centered distributions to svp .",
    "recall that any norm @xmath486 over @xmath98 is uniquely represented by a compact symmetric convex body with non - empty interior @xmath487 , its unit ball .",
    "the norm itself is then simply @xmath488 ( since we are interested in asymptotics , we formally identify @xmath489 with a sequence of such bodies with @xmath490 , but we will ignore such details . ) a @xmath482-ball with center @xmath235 and radius @xmath35 is @xmath491 , the set of all points within distance @xmath35 of @xmath235 in the norm @xmath486 .",
    "we define the general problem that interests us below , together with the natural generalization of cvp to arbitrary norms .    for any @xmath160 , @xmath492 , and",
    "function @xmath493 mapping a shifted lattice @xmath2 to a distribution over @xmath2 , the sampling problem @xmath494 ( the lattice sampling problem ) is defined as follows : the input is ( a basis of ) a lattice @xmath9 and a shift @xmath12 .",
    "the goal is to output a vector whose distribution is @xmath167-close to @xmath495 .    for any norm @xmath486 ,",
    "the search problem @xmath496 ( the closest vector problem in norm @xmath482 ) is defined as follows : the input is ( a basis of ) a lattice @xmath9 and a target vector @xmath12 . the goal is to output a lattice vector @xmath1 such that @xmath497 is minimal .",
    "we now observe that proposition  [ prop : shiftedsparsifier ] generalizes to arbitrary norms .",
    "( one can simply check that the proof of proposition  [ prop : shiftedsparsifier ] does not use any special properties of the @xmath33 norm . )",
    "[ prop : shiftedsparsifier - ell_q ] there is a polynomial - time algorithm that takes as input a basis @xmath51 for a lattice @xmath102 and a prime @xmath40 and outputs a sublattice @xmath300 and shift @xmath59 such that , for any norm @xmath498 , @xmath106 , @xmath41 with @xmath499 , and any @xmath496 oracle , @xmath500 \\leq    \\frac{1}{p } + \\frac{1}{p^n } \\ ; .\\ ] ]    and , from this , we obtain a generalization of lemma  [ lem : shifteduniformsampler ] and theorem  [ thm : counter ] .",
    "for any parameter @xmath160 and norm @xmath501 , @xmath502 ( the vector counting problem in norm @xmath482 ) is the promise problem defined as follows : the input is ( a basis of ) a lattice @xmath9 , shift @xmath12 , radius @xmath125 , and an integer @xmath322 .",
    "it is a no instance if @xmath503 and a yes instance if @xmath504 .    [ thm : counter_q ] for any efficiently computable norm @xmath498 and efficiently computable function @xmath320 with @xmath321 ,",
    "there is a polynomial - time reduction from @xmath502 to @xmath496 , where @xmath326 .",
    "furthermore , there is an ( expected ) polynomial - time reduction from @xmath505 to @xmath496 , where @xmath495 is the uniform distribution on @xmath506 ( or @xmath493 is constant on @xmath507 if @xmath506 is empty ) .",
    "both reductions preserve dimension and only make calls to the @xmath496 oracle on sublattices of the input lattice .",
    "recall that the sampling algorithm from theorem  [ thm : dgstocvp ] works by computing a finite sequence of balls @xmath508 such that the discrete gaussian distribution is @xmath167-close to a weighted average of the uniform distributions over these balls .",
    "this motivates the following definition and theorem .",
    "[ def : ball - decomposable ] for a norm @xmath482 , @xmath509 , and @xmath510 , we say that a function @xmath493 that maps a shifted lattice @xmath2 to a distribution over @xmath2 is @xmath511-ball decomposable if it is @xmath167-close to a weighted average of uniform distributions over the lattice points inside @xmath482-balls , and these balls and weightings can be computed efficiently with access to a @xmath496 oracle .    for any efficiently computable norm @xmath482 , @xmath509 , and",
    "@xmath510 , if @xmath493 is @xmath511-ball decomposable , then for any efficiently computable function @xmath512 , there is a polynomial - time reduction from @xmath513 to @xmath496 , where @xmath514 .",
    "the reduction preserves dimension and only calls its oracle on sublattices of the input lattice .    on input @xmath9 and @xmath12 ,",
    "the reduction first calls the procedure guaranteed by definition  [ def : ball - decomposable ] to obtain a sequence of @xmath482-balls @xmath508 and weights @xmath515 .",
    "it then selects an index @xmath114 with probability @xmath445 .",
    "finally , it uses the sampling procedure from theorem  [ thm : counter_q ] to sample a vector that is @xmath373-close to uniform over @xmath516 and outputs the result .",
    "it is clear that the reduction runs in polynomial time .",
    "correctness follows from the correctness of the various subprocedures and some simple calculations .    for any efficiently computable function @xmath512 and constant @xmath485",
    ", there is an efficient reduction from @xmath517 to @xmath518 , where @xmath326 , @xmath519 , and @xmath520 is the distribution that assigns to each @xmath17 probability proportional to @xmath521 .",
    "it suffices to show that @xmath522 is @xmath523-ball decomposable , i.e. , that there is an efficient algorithm with access to a @xmath524 oracle that outputs balls and weights as in definition  [ def : ball - decomposable ] .",
    "the algorithm first computes @xmath525 using its @xmath524 oracle . for @xmath526 , let @xmath527 , @xmath528 , and @xmath529 .",
    "let @xmath530 , and for @xmath531 , let @xmath532 .",
    "the algorithm then uses the counting procedure from theorem  [ thm : counter_q ] to approximate @xmath533 up to a factor of @xmath534 , receiving as output @xmath362 .",
    "finally , let @xmath535 .",
    "the algorithm then simply outputs the @xmath536 and @xmath445 .",
    "a simple calculation shows that this is a valid @xmath523-ball decomposition of @xmath522 .",
    "it is an immediate consequence of lemma  [ lem : banaszczyk ] that @xmath16-svp reduces to dgs .",
    "in fact , we can do a bit better .- svp . though they are interested in exponential - time algorithms , it is easy to see that their approach yields a polynomial - time reduction from ( the decisional variant of ) @xmath7-svp to dgs for any @xmath8 .",
    "see  ( * ? ? ?",
    "* theorem 6.5 ) .",
    "their reduction only requires samples above the smoothing parameter , which is in some sense the reason that they only solve the decisional variant of svp . ]    for any efficiently computable function @xmath537 , there is a polynomial - time reduction from @xmath7-svp to @xmath538-dgs , where @xmath539 , and @xmath540 .",
    "the reduction only calls the oracle on the input lattice .",
    "we assume without loss of generality that @xmath29 is large enough so that @xmath541 . on input @xmath9",
    ", the reduction behaves as follows .",
    "let @xmath542 such that @xmath543 such that the bit lengths of @xmath544 and @xmath545 are polynomially bounded .",
    "( e.g. , we can take @xmath544 and @xmath545 to be the values guaranteed by lemma  [ lem : lambda1bitlength ] . ) for @xmath546 , let @xmath547 the reduction calls the dgs oracle on input @xmath11 and @xmath548 for each @xmath114 , @xmath549 times",
    ". it then returns the shortest resulting non - zero vector .",
    "it is clear that the reduction runs in polynomial time .",
    "let @xmath114 such that @xmath550 .",
    "note that @xmath551 < \\frac{1}{1 + 4/f(n ) } < 1 - 2/f(n ) \\ ; .\\ ] ] by lemma  [ lem : banaszczyk ] , @xmath552 \\leq   \\pr_{{\\ensuremath{\\mathbf{x } } } \\sim d_{{\\mathcal{l } } , s_i}}[\\length{{\\ensuremath{\\mathbf{x } } } } > s_i\\sqrt{n } ] < 2^{-n } \\ ; .\\ ] ] therefore , if the samples were truly from @xmath553 , each would be a valid approximation with probability at least @xmath554 .",
    "it follows that each sample from the dgs oracle is a valid approximation with probability at least @xmath555 , and the result follows .",
    "we now show a lower bound on the length of non - zero discrete gaussian vectors . in particular , for any approximation factor @xmath32 , we show a lattice ( technically , a family of lattices indexed by the dimension @xmath29 ) such that the probability that @xmath20 yields a @xmath7-approximate shortest vector is negligible for any @xmath4 .",
    "this shows that any efficient reduction from @xmath7-svp to dgs with @xmath32 must output a vector not returned by the dgs oracle and/or make dgs calls on a lattice other than the input lattice .",
    "[ thm : svptodgs ] for any sufficiently large @xmath29 and @xmath556 , there exists a lattice @xmath9 with @xmath557 such that for any @xmath18 ,",
    "@xmath558 < e^{-t^2 } \\ ; .\\ ] ] in particular , for any @xmath559 , @xmath20 will yield a @xmath560-approximate shortest vector with at most negligible probability .    fix @xmath29 .",
    "let @xmath561 be an @xmath562-dimensional lattice with @xmath563 and @xmath564 , as promised by lemma  [ lem : randomlattice ] .",
    "then , let @xmath565 be the lattice obtained by `` appending '' a vector of length @xmath566 to @xmath43 .",
    "note that the only vectors of length at most @xmath567 in @xmath11 are those that are multiples of the `` appended '' vector .",
    "so , @xmath568 \\leq \\frac{\\rho_s(t{\\ensuremath{\\mathbb{z}}}\\setminus \\ { { \\ensuremath{\\mathbf{0}}}\\})}{\\rho_s({\\mathcal{l } } ' ) } \\leq \\frac{\\rho_{s / t}({\\ensuremath{\\mathbb{z}}}\\setminus \\ { { \\ensuremath{\\mathbf{0}}}\\})}{1+s^{n-1 } } \\ ; .\\ ] ] now , if @xmath569 , then the numerator is less than @xmath570 .",
    "if @xmath571 , then we have @xmath572 where we have used the fact that @xmath573 , and the fact that @xmath556 .",
    "for completeness , we give a simple reduction from cvp to dgs .",
    "it suffices to find a parameter @xmath4 that is small enough so that the weight of a closest vector to the target is much larger than the weight of all non - closest vectors .",
    "the only slightly non - trivial observation necessary is that we can take @xmath4 large enough that it still has polynomial bit length .",
    "[ prop : cvptodgs ] for any efficiently computable function @xmath512 , there is a polynomial - time reduction from cvp to @xmath538-dgs where @xmath574 .",
    "the reduction succeeds with probability at least @xmath575 and only makes one oracle call on @xmath2 where @xmath11 is the input lattice and @xmath13 is the input target .    on input @xmath9 and @xmath12 , the reduction behaves as follows .",
    "let @xmath576 with polynomial bit length such that @xmath577 and @xmath578 .",
    "let @xmath579 be the upper bound on @xmath109 guaranteed by lemma  [ lem : lambda1bitlength ] ( which in particular has polynomial bit length ) , and let @xmath580 .",
    "the reduction simply samples @xmath260 from @xmath0 and returns @xmath581 .",
    "it is clear that the reduction runs in polynomial time .",
    "note that for any point @xmath41 that is not a closest point to @xmath13 , we must have @xmath582 . by corollary  [ cor : shiftedbanaszczyk ] , we have @xmath583 < e^{-1/(ns^2q^2 ) } < e^{-2f(n)n } \\ ; .\\ ] ] therefore , any distribution within statistical distance @xmath170 of @xmath21 must output a closest point with probability at least @xmath584 .",
    "it follows that the oracle outputs a closest point with probability at least @xmath575 , as needed .",
    "cvp is equivalent to dgs under polynomial - time , dimension - preserving reductions",
    ".    combine theorem  [ thm : dgstocvp ] with proposition  [ prop : cvptodgs ] .",
    "i would like to thank divesh aggarwal , daniel dadush , and oded regev for many enlightening discussions and for their helpful comments on early drafts of this work ; daniele micciancio for finding a bug in an earlier version of proposition  [ prop : cvptodgs ] ; and the soda reviewers for their very helpful and thorough reviews ."
  ],
  "abstract_text": [
    "<S> the discrete gaussian @xmath0 is the distribution that assigns to each vector @xmath1 in a shifted lattice @xmath2 probability proportional to @xmath3 . </S>",
    "<S> it has long been an important tool in the study of lattices . </S>",
    "<S> more recently , algorithms for discrete gaussian sampling ( dgs ) have found many applications in computer science . in particular , </S>",
    "<S> polynomial - time algorithms for dgs with very high parameters @xmath4 have found many uses in cryptography and in reductions between lattice problems . </S>",
    "<S> and , in the past year , aggarwal , dadush , regev , and stephens - davidowitz showed @xmath5-time algorithms for dgs with a much wider range of parameters and used them to obtain the current fastest known algorithms for the two most important lattice problems , the shortest vector problem ( svp ) and the closest vector problem ( cvp ) .    </S>",
    "<S> motivated by its increasing importance , we investigate the complexity of dgs itself and its relationship to cvp and svp . </S>",
    "<S> our first result is a polynomial - time dimension - preserving reduction from dgs to cvp . </S>",
    "<S> there is a simple reduction from cvp to dgs , so this shows that dgs is equivalent to cvp . </S>",
    "<S> our second result , which we find to be more surprising , is a polynomial - time dimension - preserving reduction from _ centered _ dgs ( the important special case when @xmath6 ) to svp . in the other direction , there is a simple reduction from @xmath7-approximate svp for any @xmath8 , and we present some ( relatively weak ) evidence to suggest that this might be the best achievable approximation factor .    </S>",
    "<S> we also show that our cvp result extends to a much wider class of distributions and even to other norms . </S>"
  ]
}