{
  "article_text": [
    "top quarks were first observed in top  quark ",
    "top  antiquark pair production via the strong interaction in 1995  @xcite .",
    "the standard model also predicts that the electroweak interaction can produce a top quark together with a bottom antiquark or a light quark , without the antiparticle top quark partner that is always produced in strong - coupling processes .",
    "this electroweak process is generally referred to as single top quark production . since 1995 ,",
    "the d0 and cdf collaborations have been searching ever larger datasets for signs of single top quark production .",
    "we present here the results of a search for top quarks produced singly via the electroweak interaction from the decay of an off - shell @xmath1  boson or fusion of a virtual @xmath1  boson with a @xmath2  quark .",
    "previously measured top quarks have been produced in pairs from highly energetic virtual gluons via the strong interaction . the cross section for production at the fermilab tevatron proton - antiproton collider ( center - of - mass energy = 1.96  tev ) is @xmath10  pb  @xcite at next - to - leading order ( nlo ) plus higher - order soft - gluon corrections , for a top quark of mass @xmath11  gev  @xcite .",
    "the standard model predicts three processes for production of a top quark without its antiparticle partner .",
    "these are as follows : ( i ) the s - channel process @xmath12",
    "@xcite , with a cross section of @xmath13  pb  @xcite at nlo for @xmath11  gev ; ( ii ) the t - channel process @xmath14",
    "@xcite , with a cross section of @xmath15  pb  @xcite at the same order in perturbation theory and top quark mass ; and ( iii ) the @xmath16 process @xmath17",
    "@xcite , where the cross section at the tevatron energy is small , @xmath18  pb  @xcite at lo .",
    "the main tree - level feynman diagrams for the dominant single top quark production processes are illustrated in fig .",
    "[ feynman - diagrams ] . for brevity , in this paper we will use the notation `` @xmath19 '' to mean the sum of @xmath20 and @xmath21 , and `` @xmath22 '' to mean the sum of @xmath23 and @xmath24 .",
    "the analysis reported in this paper searches only for the s - channel process @xmath19 and the t - channel process @xmath22 , and does not include a search for the @xmath16 process because of its small production rate at the tevatron .",
    "top quarks are interesting particles to study since in the standard model their high mass implies a yukawa coupling to the higgs boson with a value near unity , unlike any other known particle .",
    "they also decay before they hadronize , allowing the properties of a bare quark such as spin to be transferred to its decay products and thus be measured and compared to the standard model predictions .",
    "events with single top quarks can also be used to study the @xmath5 coupling  @xcite , and to measure directly the absolute value of the quark mixing matrix ( the cabibbo - kobayashi - maskawa ( ckm ) matrix  @xcite ) element @xmath25 without assuming there are only three generations of quarks  @xcite . a measured value for @xmath25 significantly different from unity could imply the existence of a fourth quark family or other effects from beyond the standard model  @xcite .",
    "the d0 collaboration has published three searches for single top quark production using smaller datasets .",
    "we analyzed 90  pb@xmath0 of data from tevatron run  i ( 19921996 at a center - of - mass energy of 1.8  tev ) which resulted in the first upper limits on single top quark production  @xcite and we performed a more refined search using neural networks that achieved greater sensitivity  @xcite . in run  ii",
    ", we used 230  pb@xmath0 of data collected from 2002 to 2004 to set more stringent upper limits  @xcite .",
    "our best published 95% c.l .",
    "upper limits are 6.4  pb in the s - channel ( @xmath19 production ) and 5.0  pb in the t - channel ( @xmath22 production ) .",
    "students in the d0 collaboration have completed ten ph.d .",
    "dissertations on the single top quark search  @xcite .",
    "our most recent publication  @xcite presents first evidence for single top quark production using a 0.9  fb@xmath0 dataset .",
    "we provide a more detailed description of that result here , and also include several improvements to the analysis methods that lead to a final result on the same dataset with slightly higher significance .",
    "the cdf collaboration has published two results from analyzing 106  pb@xmath0 of run  i data  @xcite , and one that uses 162  pb@xmath0 of run  ii data  @xcite .",
    "their best 95% c.l .",
    "upper limits are 14  pb in the s - channel , 10  pb in the t - channel , and 18  pb in the s - channel and t - channel combined .",
    "students in the cdf collaboration have completed seven ph.d .",
    "dissertations on the single top quark search  @xcite .",
    "the experimental signal for single top quark events consists of one isolated high transverse momentum ( ) , central pseudorapidity ( @xmath26  @xcite ) charged lepton and missing transverse energy ( ) from the decay of a @xmath1  boson from the top quark decay , accompanied by a @xmath2  jet from the top quark decay .",
    "there is always a second jet , which originates from a @xmath2  quark produced with the top quark in the s - channel , or which comes from a forward - traveling up- or down - type quark in t - channel events .",
    "some t - channel events have a detectable @xmath2  jet from the gluon splitting to @xmath27 .",
    "since there may be significant initial - state or final - state radiation , we include in our search events with two , three , or four jets .",
    "we use data collected with triggers that include an electron or a muon , and a jet . in the electron channel ,",
    "multijet events can fake signal ones when a jet is misidentified as an electron , and we have stringent identification criteria for electrons to reduce this type of background . in the muon channel ,",
    "+ jets events can fake signal ones when one of the @xmath2 s decays to a muon .",
    "we reject much of this background by requiring the muon to be isolated from all jets in the event .",
    "finally , we apply a set of simple selection criteria to retain regions of phase space that single top quark events tend to populate .",
    "we divide the selected events into 12 nonoverlapping samples , referred to as analysis channels , depending on the flavor of the lepton ( @xmath28 or @xmath29 ) , the number of jets ( 2 , 3 , 4 ) , and the number of jets identified as originating from @xmath2  quarks ( number of `` tagged '' jets = 1 , 2 ) , because the signal - to - background ratios and fractions of expected signal in each channel differ significantly .",
    "the dominant background in most of these channels is @xmath1+jets events .",
    "we model this background using events simulated with monte carlo ( mc ) techniques and normalized to data before @xmath2  tagging .",
    "we also use an mc model to simulate the background from events .",
    "finally , we use data events with poorly identified leptons to model the multijet background where a jet is misidentified as an electron , or a muon in a jet from @xmath30 or @xmath2  decay is misidentified as a muon from a @xmath1  boson decay .",
    "we apply a neural - network - based @xmath2-identification algorithm to each jet in data and keep events with one or two jets that are identified as @xmath2  jets .",
    "we model this @xmath2  tagging in the mc event samples by weighting each event by the probability that one or more jets is tagged .    after event selection ,",
    "we calculate multivariate discriminants in each analysis channel to separate as much as possible the expected signal from the background .",
    "we then perform a binned likelihood fit of the background model plus possible signal to the data in the discriminant output distributions and combine the results from all channels that improve the expected sensitivity .",
    "finally , we calculate the probability that our data are compatible with background only , use the excess of data over background in each bin to measure the signal cross section , and calculate the probability that the data contains both background and signal produced with at least the measured cross section value .    for each potential analysis channel , the relevant details are the signal acceptance and the signal - to - background ratio .",
    "table  [ acceptance - percentages ] shows the percentage of the total signal acceptance for each jet multiplicity and number of @xmath2-tagged jets , and the associated signal - to - background ratios .",
    "we used this information to determine that the most sensitive channels have two , three , or four jets , and one or two @xmath2 tags . in the future , it could be beneficial to extend the analysis to include events with only one jet , @xmath2  tagged , since the signal - to - background ratios are not bad , and to study the untagged events with two or three jets where there is significant signal acceptance .",
    "l||ccccc + & 1 jet & 2 jets & 3 jets & 4 jets & @xmath31 jets + & + 0 @xmath2 tags  & 8% & 19% & 9% & 3% & 1% + & 1:11,000 & 1:1,600 & 1:1,200 & 1:1,100 & 1:1,000 + 1 @xmath2 tag & 6% & * 24% * & * 12% * & * 3% * & 1% + & 1:270 & * 1:55 * & * 1:73 * & * 1:130 * & 1:200 + 2 @xmath2 tags &  & * 9% * & * 4% * & * 1% * & 0% + &  & * 1:12 * & * 1:27 * & * 1:92 * & 1:110 + & + 0 @xmath2 tags & 10% & 27% & 13% & 4% & 1% + & 1:4,400 & 1:520 & 1:400 & 1:360 & 1:300 + 1 @xmath2 tag & 6% & * 20% * & * 11% * & *",
    "4% * & 1% + & 1:150 & * 1:32 * & * 1:37 * & * 1:58 * & 1:72 + 2 @xmath2 tags &  & * 1% * & * 2% * & *",
    "1% * & 0% + &  & * 1:100 * & * 1:36 * & * 1:65 * & 1:70",
    "we summarize here the changes and improvements made to the analysis since the previously published d0 result that used 230  pb@xmath0 of data  @xcite .",
    "the most important difference is that we have analyzed a dataset four times as large .",
    "other changes include the following : ( i ) use of an improved model for the t - channel @xmath22 signal from the package  @xcite , based on  @xcite , which better reproduces nlo - like parton kinematics ; ( ii ) use of an improved model for the and @xmath1+jets backgrounds from the alpgen package  @xcite that has parton - jet matching  @xcite implemented with pythia  @xcite to avoid duplicate generation of some initial - state and final - state jet kinematics ; ( iii ) determination from data of the ratio of @xmath1 boson plus or jets to the total rate of @xmath1+jets production ; ( iv ) omission of a separate calculation of the diboson backgrounds @xmath32 and @xmath33 since they are insignificant ; ( v ) differences in electron , muon , and jet identification requirements and minimum s ; ( vi ) use of a significantly higher efficiency @xmath2-tagging algorithm based on a neural network ; ( vii ) splitting of the analysis by jet and @xmath2-tag multiplicity so as not to dilute the strength of high - acceptance , good signal - to - background channels by mixing them with poorer ones ; ( viii ) simplification of the treatment of the smallest sources of systematic uncertainty ( since the analysis precision is statistics dominated ) ; ( ix ) use of improved multivariate techniques to separate signal from background ; and ( x ) optimization of the search to find the combined single top quark production from both the s- and t - channels , @xmath19+@xmath22 .",
    "the d0 detector  @xcite consists of three major parts : a tracking system to determine the trajectories and momenta of charged particles , a calorimeter to measure the energies of electromagnetic and hadronic showers , and a system to detect muons , which are the only charged particles that are typically not contained within the calorimeter .",
    "the first element at the core of the detector is a tracking system that consists of a silicon microstrip tracker ( smt ) and a central fiber tracker ( cft ) , both located within a 2  t superconducting solenoidal magnet .",
    "the smt has six barrel modules in the central region , each comprising four layers arranged axially around the beam pipe , and 16 radial disks interspersed with and beyond the central barrels .",
    "ionization charge is collected by @xmath34 @xmath35- or @xmath36-type silicon strips of pitch between @xmath37 and @xmath38 that are used to measure the positions of the hits .",
    "tracks can be reconstructed up to pseudorapidities  @xcite of @xmath39 .",
    "the cft surrounds the smt with eight thin coaxial barrels , each supporting two doublets of overlapping scintillating fibers of 0.835  mm diameter , one doublet being parallel to the beam axis , and the other alternating by @xmath40 relative to the axis .",
    "visible - light photon counters ( vlpcs ) collect the light signals from the fibers , achieving a cluster resolution of about @xmath41 per doublet layer .",
    "central and forward preshower detectors contribute to the identification of electrons and photons .",
    "the central preshower detector is located just outside of the superconducting coil and the forward ones are mounted in front of the endcap calorimeters .",
    "the preshower detectors comprise several layers of scintillator strips that are read out using wavelength - shifting fibers and vlpcs .",
    "three finely grained uranium / liquid - argon sampling calorimeters constitute the primary system used to identify electrons , photons , and jets .",
    "the central calorimeter ( cc ) covers @xmath42 up to @xmath43 .",
    "the two end calorimeters ( ec ) extend the coverage to @xmath44 .",
    "each calorimeter contains an electromagnetic ( em ) section closest to the interaction region with approximately 20 radiation lengths of material , followed by fine and coarse hadronic sections with modules that increase in size with distance from the interaction region and ensure particle containment with approximately six nuclear interaction lengths .",
    "in addition to the preshower detectors , scintillators between the cc and ec provide sampling of developing showers in the cryostat walls for @xmath45 .    the three - layer muon system is located beyond the calorimetry , with 1.8  t iron toroids after the first layer to provide a stand - alone muon - system momentum measurement .",
    "each layer comprises tracking detectors and scintillation trigger counters .",
    "proportional drift tubes 10  cm in diameter allow tracking in the region @xmath46 , and 1  cm mini drift tubes extend the tracking to @xmath47 .",
    "additionally , plastic scintillator arrays covering @xmath48 are used to measure the rate of inelastic collisions in the d0 interaction region and calculate the tevatron instantaneous and integrated luminosities .",
    "we select the events to be studied offline with a three - tiered trigger system . the first level of the trigger makes a decision based on partial information from the tracking , calorimeter , and muon systems .",
    "the second level of the trigger uses more refined information to further reduce the rate .",
    "the third trigger level is based on software filters running in a farm of computers that have access to all information in the events .",
    "the data were collected between august 2002 and december 2005 , with @xmath49  pb@xmath0 and @xmath50  pb@xmath0 of good quality events in the electron and muon channels respectively .    as the average instantaneous luminosity of the tevatron has increased over time , the triggers used to collect the data have been successively changed to maintain background rejection .",
    "the requirements at the highest trigger level are the following , with the associated integrated luminosity included in parentheses :    one electron with @xmath51  gev and two jets with @xmath51  gev ( 103  pb@xmath0 )    one electron with @xmath51  gev and two jets with @xmath52  gev ( 227  pb@xmath0 )    one electron with @xmath51  gev , one jet with @xmath53  gev , and a second jet with @xmath52  gev ( 289  pb@xmath0 )    one electron with @xmath51  gev and two jets with @xmath54  gev ( 294  pb@xmath0 )    * muon+jets triggers *    one lower - trigger - level muon with no @xmath55 threshold and one jet with @xmath52  gev ( 107  pb@xmath0 )    one lower - trigger - level muon with no @xmath55 threshold and one jet with @xmath53  gev ( 278  pb@xmath0 )    one muon with @xmath56  gev and one jet with @xmath54  gev ( 252  pb@xmath0 )    one isolated muon with @xmath56  gev and one jet with @xmath53  gev ( 21  pb@xmath0 )    one muon with @xmath56  gev and one jet with @xmath57  gev ( 214  pb@xmath0 )    the average efficiency of the electron+jets triggers is 87% for @xmath19 events and",
    "86% for @xmath22 events that pass the final selection cuts .",
    "the average efficiency of the muon+jets triggers is 87% for @xmath19 and 82% for @xmath22 events .",
    "note that for the electron+jets triggers , the electron usually satisfies one of the jet requirements , and thus there are usually only two independent objects required in each event ( one electron and one jet ) .",
    "physics objects are reconstructed from the digital signals recorded in each part of the detector .",
    "particles can be identified by certain patterns and , when correlated with other objects in the same event , they provide the basis for understanding the physics that produced such signatures in the detector .",
    "the location of the hard - scatter interaction point is reconstructed by means of an adaptive primary vertex algorithm  @xcite .",
    "this algorithm first selects tracks coming from different interactions by clustering them according to their @xmath58  position along the nominal beam line . in the second step , the location and width of the beam in the transverse plane ( perpendicular to the beam line )",
    "are determined and then used to re - fit tracks , and each cluster of tracks is associated with a vertex using the `` adaptive '' technique that gives all tracks a weight and iterates the fit .",
    "the third and last step consists of choosing the vertex that has the lowest probability of coming from a minimum bias interaction ( a scatter event ) , based on the @xmath59 values of the tracks assigned to each vertex .",
    "the hard - scatter vertex is distinguished from soft - interaction vertices by the higher average @xmath59 of its tracks . in multijet data , the position resolution of the primary vertex in the transverse plane is around 40  @xmath29 m , convoluted with a typical beam spot size of around 30  @xmath29 m .",
    "electron candidates are defined as clusters of energy depositions in the electromagnetic section of the central calorimeter ( @xmath60 ) consistent in shape with an electromagnetic shower .",
    "at least 90% of the energy of the cluster must be contained in the electromagnetic section of the calorimeter , @xmath61 , and the cluster must satisfy the following isolation criterion : @xmath62 where @xmath63 is the electron candidate s energy measured in the calorimeter , and @xmath64 is the radius of a cone defined by the azimuthal angle @xmath65 and the pseudorapidity @xmath26 , centered on the electron candidate s track if there is an associated track , or the calorimeter cluster if there is not .",
    "two classes of electrons are subsequently defined and used in this analysis :    * loose electron * + a loose electron must pass the identification requirements listed above .",
    "in addition , the energy deposition in the calorimeter must be matched with a charged particle track from the tracking detectors with @xmath66  gev . finally , a shower - shape chi - squared , based on seven variables that compare the values of the energy deposited in each layer of the electromagnetic calorimeter with average distributions from simulated electrons , has to satisfy @xmath67 .",
    "* tight electron * + a tight electron must pass the loose requirements , and have a value of a seven - variable em - likelihood @xmath68 .",
    "the following variables are used in the likelihood : ( i )  @xmath69 ; ( ii )  @xmath70 ; ( iii )  @xmath71 , the transverse energy of the cluster divided by the transverse momentum of the matched track ; ( iv )  the @xmath72 probability of the match between the track and the calorimeter cluster ; ( v )  the distance of closest approach between the track and the primary vertex in the transverse plane ; ( vi ) the number of tracks inside a cone of @xmath73 around the matched track ; and ( vii )  the @xmath74 of tracks within an @xmath75 cone around the matched track .",
    "the average tight electron identification efficiency in data is around @xmath76 .",
    "muons are identified by combining tracks in the muon spectrometer with central detector tracks .",
    "muons are reconstructed up to @xmath77 by first finding hits in all three layers of the muon spectrometer and requiring that the timing of these hits be consistent with the muon originating in the center of the detector from the correct proton - antiproton bunch crossing , thereby rejecting cosmic rays .",
    "secondly , all muon candidates must be matched to a track in the central tracker , where the central track must pass the following criteria : ( i )  @xmath72 per degree of freedom must be less than 4 ; and ( ii )  the distance of closest approach between the track and the primary vertex must be less than 0.2  mm if the track has smt hits and less than 2  mm if it does not .",
    "two classes of muons are then defined for this analysis :    * loose - isolated muon * + a loose muon must pass the identification requirements given above .",
    "loose muons must in addition be isolated from jets .",
    "the distance between the muon and any jet axis in the event has to satisfy @xmath78 .",
    "* tight - isolated muon * + a tight muon must pass the loose - isolation requirement and additional isolation criteria as follows : ( i )  the transverse momenta of all tracks within a cone of radius @xmath79 around the muon direction , except the track matched to the muon , must add up to less than @xmath80 of the muon @xmath59 ; and ( ii )  the energy deposited in a cone of radius @xmath81 around the muon direction must be less that @xmath80 of the muon @xmath59 .",
    "we reconstruct jets based on calorimeter cell energies , using the midpoint cone algorithm  @xcite with radius @xmath82 .",
    "noisy calorimeter cells are ignored in the reconstruction algorithm by only selecting cells whose energy is at least four standard deviations above the average electronic noise and any adjacent cell with at least two standard deviations above the average electronic noise .    to reject poor quality or noisy jets , we require all jets to have the following : ( i )  @xmath83 in the central region , with the lower cut looser in the intercryostat and forward regions ; ( ii )  fraction of jet @xmath59 in the coarse hadronic calorimeter layers @xmath84 in the central region , with looser requirements in the forward regions ; and ( iii )  at least @xmath85 of the @xmath59 of the jet , not including the coarse hadronic layers , matched to energy depositions in towers in level  1 of the trigger in a cone of radius @xmath86 around the jet axis in the central region , with looser requirements in the forward regions .    jet energy scale corrections are applied to convert reconstructed jet energies into particle - level energies .",
    "the energy of each jet containing a muon within @xmath87 ( considered to originate from a semileptonic @xmath30- or @xmath2-quark decay ) is corrected to account for the energy of the muon and the accompanying neutrino ( because that energy is not deposited in the calorimeter and so would otherwise be undermeasured ) . for this correction , it is assumed that the neutrino has the same energy as the muon .",
    "jets that have the same @xmath26 and @xmath65 as a reconstructed electron are removed from the list of jets to avoid double - counting objects .",
    "neutrinos carry away momentum that can be inferred using momentum conservation in the transverse plane .",
    "the sum of the transverse momenta of undetected neutrinos is equal to the negative of the sum of the transverse momenta of all particles observed in the detector . in practice , we compute the missing transverse energy by adding up vectorially the transverse energies in all cells of the electromagnetic and fine hadronic calorimeters",
    ". cells in the coarse hadronic calorimeter are only added if they are part of a jet .",
    "this raw quantity is then corrected for the energy corrections applied to the reconstructed objects and for the momentum of all muons in the event , corrected for their energy loss in the calorimeter .",
    "given that single top quark events have at least one @xmath2  jet in the final state , we use a @xmath2-jet tagger to identify jets originating from @xmath2  quarks .",
    "in addition to the jet quality criteria described in previous sections , a `` taggability '' requirement is applied .",
    "this requires the jets to have at least two good quality tracks with @xmath89  gev and @xmath90  gev respectively , that include smt hits and which point to a common origin .",
    "a neural network ( nn ) tagging algorithm is used to identify jets originating from a @xmath2  quark .",
    "the tagger and its performance in the data is described in detail in ref .",
    "we summarize briefly here its main characteristics .",
    "the nn tagger uses the following variables , ranked in order of separation power , to discriminate @xmath2  jets from other jets : ( i )  decay length significance of the secondary vertex reconstructed by the secondary vertex tagger ( svt ) ; ( ii )  weighted combination of the tracks impact parameter significances ; ( iii )  jet lifetime probability ( jlip ) , the probability that the jet originates from the primary vertex  @xcite ; ( iv )  @xmath72 per degree of freedom of the svt secondary vertex ; ( v )  number of tracks used to reconstruct the secondary vertex ; ( vi )  mass of the secondary vertex ; and ( vii )  number of secondary vertices found inside the jet .    for this analysis",
    ", we require the nn output to be greater than 0.775 for the jet to be considered @xmath2  tagged .",
    "the average probability for a light jet in data to be falsely tagged at this operating point is @xmath91 , and the average @xmath2-tagging efficiency in data is @xmath92 for jets with @xmath93 .",
    "for this analysis , we generate single top quark events with the -  @xcite monte carlo event generator . produces events whose kinematic distributions match those from nlo calculations  @xcite .",
    "the top quark mass is set to 175  gev , the set of parton distribution functions ( pdf ) is cteq6l1  @xcite , and the renormalization and factorization scales are @xmath94 for the s - channel and @xmath95 for the t - channel .",
    "these scales are chosen such that the lo cross sections are closest to the nlo cross sections  @xcite .",
    "the top quarks and the @xmath1  bosons from the top quark decays are decayed in to ensure the spins are properly transferred .",
    "@xcite is used to add the underlying event , initial - state and final - state radiation , and for hadronization .",
    "@xcite is used to decay tau leptons , and  @xcite to decay @xmath2  hadrons . to calculate the expected number of signal events , these samples are normalized to the nlo cross sections  @xcite for a top quark mass of 175  gev : @xmath13  pb for the s - channel and @xmath15  pb for the t - channel .    the @xmath1+jets and samples are generated using  @xcite .",
    "the version we use includes a parton - jet matching algorithm that follows the mlm prescription  @xcite .",
    "for the samples , the top quark mass is set to 175  gev , the scale is @xmath96 , and the pdf set is cteq6l1 . for the @xmath1+jets events , the pdf is also cteq6l1 and the scale is @xmath97 .",
    "the @xmath1+jets events include separate generation of each jet multiplicity from @xmath1 + 0 light partons to @xmath1 + at least 5 light partons for events with no heavy - flavor partons ( we refer to these samples as @xmath98 ) .",
    "those with @xmath99 and @xmath100 partons have separately generated samples with between 0 and 3 additional light partons .",
    "the events include separate samples with additional jets from 0 to 2 light partons .    for the @xmath1+jets sets , we remove events with heavy flavor jets added by so as not to duplicate the phase space of those generated already by .",
    "the @xmath101 subprocesses are included in the @xmath98 sample with massless charm quarks .    since the @xmath1+jets background is normalized to data ( see sec .",
    "[ matrix - method ] ) , it implicitly includes all sources of @xmath1+jets , @xmath102+jets , and diboson events with similar jet - flavor composition , in particular @xmath102+jets events where one of the leptons from the @xmath102  boson decay is not identified .",
    "the proportions of @xmath103 and @xmath104 in the @xmath1+jets model are set by at leading order precision .",
    "however , higher order calculations  @xcite indicate that there should be a higher fraction of events with heavy - flavor jets .",
    "we measure a scale factor for the @xmath103 and @xmath104 subsamples using several untagged data samples ( with zero @xmath2-tagged jets ) that have negligible signal content .",
    "we obtain : @xmath105 where the numbers of events @xmath106 for each background component correspond to the expected number of events after event selection ( described in sec .",
    "[ event - selection ] ) and background normalization ( described in sec .  [ background ] ) and removing events with one or more @xmath2-tagged jets . additionally , we check that the same value of @xmath107 is obtained from the complementary @xmath1 + 1 jet sample , where we require the only jet to be @xmath2  tagged .",
    "figure  [ alpha - scalefactor ] illustrates the measurement of the scale factor @xmath108 .",
    "used to convert the fraction of @xmath103 and @xmath104 events in the @xmath1+jets background model from leading order to higher order .",
    "the points are the measured correction factor in each dataset .",
    "the solid line is the average of these values .",
    "the dot - dash inner band shows the uncertainty from the fit to the eight data points .",
    "the dashed outer line shows the uncertainty on @xmath108 used in the analysis to allow for the assumption that the scale factor should be the same for @xmath103 and @xmath104 , and for small differences in the shapes of distributions between the @xmath1 + heavy flavor and @xmath1 + light flavor jets.,scaledwidth=38.0% ]    we examine the distributions expected to suffer the largest shape dependence from higher order corrections , such as the invariant mass of the two leading jets and the @xmath59 of the @xmath2-tagged jet , and find good agreement between the shapes of the data and the background model , not only in the signal region , but also in samples enriched with @xmath1+jets events .",
    "table  [ mcstats ] shows the cross sections , branching fractions , initial numbers of events , and integrated luminosities of the simulated samples used in this analysis .",
    "l||cccc + & cross section & branching & number & integrated + event type & [ pb ] & fraction & of events & luminosity [ fb@xmath0 ] + & & & & +  @xmath110+jets & @xmath13 & @xmath111 & 92,620 & 947 +  @xmath112+jets & @xmath13 & @xmath111 & 122,346 & 1,251 +  @xmath113+jets & @xmath13 & @xmath111 & 76,433 & 782 +  @xmath114+jets & @xmath115 & @xmath111 & 130,068 & 591 +  @xmath116+jets & @xmath115 & @xmath111 & 137,824 & 626 +  @xmath117+jets & @xmath115 & @xmath111 & 117,079 & 532 +  * signal total * & @xmath118 & @xmath119 & * 676,370 * & + * backgrounds * & & & & +  @xmath120+jets & @xmath121 & @xmath122 & 474,405 & 157 +  @xmath123 & @xmath121 & @xmath124 & 468,126 & 620 +  * top pairs total  * & @xmath125 & @xmath126 & * 942,531 * & +  @xmath127 & @xmath128 & @xmath129 & 1,335,146 & 28 +  @xmath130 & @xmath131 & @xmath129 & 1,522,767 & 8 +  @xmath132 & @xmath133 & @xmath129 & 8,201,446 & 1 +  @xmath134*+jets total * & @xmath135 & @xmath119 & * 11,059,359 * &      we pass the simulated events through a -based model  @xcite of the d0 detector .",
    "the simulated samples then have correction factors applied to ensure that the reconstruction and selection efficiencies match those found in data .",
    "generally the efficiency to reconstruct , identify , and select objects in the simulated samples is higher than in data , so the following scale factors are used to correct for that difference :    * trigger efficiency correction factors * + the probability for each simulated event to fire the triggers detailed in sec .",
    "[ triggers - data ] is calculated as a weight applied to each object measured in the event .",
    "electron and jet efficiencies , for all levels of the trigger architecture , are parametrized as functions of @xmath59 and @xmath136 .",
    "muon efficiencies are parametrized as functions of @xmath136 and @xmath65 .",
    "these corrections are measured using data obtained with triggers different from those used in this search to avoid biases .",
    "* electron identification efficiency correction factors * + we correct each simulated event in the electron channel with a factor that accounts for the differences in electron cluster finding identification , @xmath137 , and isolation efficiencies in the simulation and data .",
    "this correction factor is measured in @xmath138 data and simulated events , and parametrized as a function of @xmath136 .",
    "a second scale factor is applied to account for the differences between the data and the simulation in the @xmath139 , track matching , and em - likelihood efficiencies .",
    "this second scale factor is also derived from @xmath138 data and simulated events and parametrized as a function of @xmath136 and @xmath140 .    *",
    "muon identification and isolation efficiency correction factors * + we correct each simulated event in the muon channel for the muon identification , track match , and isolation efficiencies .",
    "the identification correction factor is parametrized as a function of @xmath136 and @xmath65 , track match as a function of track-@xmath58 and @xmath136 , and isolation as a function of the number of jets in the event .",
    "these corrections are measured in @xmath141 data and simulated events .    * jet reconstruction efficiency and energy resolution correction factors * + simulated jets need to be corrected for differences in the reconstruction and identification efficiency and for the worse energy resolution found in data than in the simulation .",
    "the jet energy scale correction is applied to the simulation as in the data , but then simulated jets are corrected for the jet reconstruction efficiency and smeared to match the jet energy resolution found in back - to - back photon+jet events .    *",
    "taggability and @xmath88-tagging efficiency correction factors * + in data , the taggability and @xmath2-tagging requirements are applied directly , as described in sec .",
    "[ b - tagging ] . for simulated samples ,",
    "_ taggability - rate functions _ and _ tag - rate functions _",
    "are applied instead of the direct selection because the modeling of the detector is not sufficiently accurate .",
    "the taggability - rate function is parametrized in jet @xmath59 , @xmath26 , and primary vertex @xmath58 , and is measured in the selected data sample ( sec .",
    "[ event - selection ] ) with one loose - isolated lepton .",
    "we check that the efficiency is the same as in the data sample with one tight - isolated lepton within the uncertainties .",
    "the average taggability for central high-@xmath59 jets is around @xmath142 .",
    "the @xmath2-jet efficiency correction is measured in data using a muon - in - jet sample and a @xmath2-jet enriched subset where one jet is required to have a small jlip value , and in an admixture of @xmath143 and @xmath144 simulated events where the @xmath2-jets are required to contain a muon .",
    "the @xmath2-tag efficiency correction for @xmath30-quark jets is derived in a combined mc sample with @xmath102  boson , multijets , and @xmath144 decays to @xmath30 quarks , and assuming that the mc - to - data scale factor is the same as for the @xmath2-jet efficiency .",
    "the @xmath2-tag efficiency correction for light jets is derived from multijet data .",
    "all these @xmath2-tagging corrections are parametrized as functions of the jet @xmath59 and @xmath145 .",
    "figure  [ tag - rate - functions ] illustrates the tag - rate functions used in this analysis .",
    "we apply a loose event selection to find @xmath1-like events containing an isolated lepton , missing transverse energy , and two to four jets with high transverse momentum .",
    "the samples after this selection , which we call `` pretagged , '' ( i.e. , _ before _ tagging has been applied ) , are dominated by @xmath1+jets events , with some contribution that becomes more significant for higher jet multiplicities .",
    "the final selection improves the signal - to - background ratio significantly by requiring the presence of one or two @xmath2-tagged jets .    for both @xmath28 and @xmath29 channels    good quality ( for data with all subdetectors working properly )    pass trigger : offline electrons and muons in the data",
    "are matched to the object that fired the appropriate trigger for that run period    good primary vertex : @xmath146  cm with at least three tracks attached    missing transverse energy : @xmath147  gev    two , three , or four jets with @xmath148  gev and @xmath149    leading jet @xmath150  gev and @xmath151    second leading jet @xmath152  gev    jet triangle cut @xmath153 ( see fig .",
    "8 in ref .",
    "@xcite for a pictorial view of these cuts ) :    @xmath154(gev)@xmath155  rad    one or two @xmath2-tagged jets    * electron channel selection *    only one tight electron with @xmath148  gev and @xmath156    no tight muon with @xmath157  gev and @xmath158    no second loose electron with @xmath148  gev and any @xmath159    electron coming from the primary vertex : @xmath160  cm    electron triangle cuts @xmath161 ( see fig .  8 in ref .",
    "@xcite ) :    1 .   @xmath162(gev)@xmath163  rad 2 .",
    "@xmath164(gev)@xmath165  rad 3 .",
    "@xmath166(gev)@xmath167  rad    * muon channel selection *    only one tight muon with @xmath157  gev and @xmath158    no tight electron with @xmath148  gev and @xmath168    muon coming from the primary vertex : @xmath169  cm    muon triangle cuts @xmath170 ( see fig .  8 in ref .",
    "@xcite ) :    1 .   @xmath171(gev)@xmath172  rad 2 .",
    "@xmath173(gev)@xmath165  rad 3 .",
    "@xmath174(gev)@xmath175  rad    some of the selection criteria listed above are designed to remove areas of the data that are difficult to model . in particular ,",
    "the upper selection gets rid of a few events where the muon @xmath59 fluctuated to a large value .",
    "the `` triangle cuts '' are very efficient in removing multijet events where a misreconstructed jet creates fake missing energy aligned or anti - aligned in azimuth with the lepton or jet .    for measuring the multijet background    all the same selection criteria as listed above except for the tight lepton requirements    electron channel",
    " only one loose - but - not - tight electron    muon channel  only one loose - but - not - tight muon    the definitions of loose and tight electrons and muons are in secs .",
    "[ electron - id ] and [ muon - id ] .",
    "table  [ numbers - of - events ] shows the numbers of events in the signal and background samples and in the data after applying the selection criteria . note that these numbers are just counts of events used later in the analysis , and not signal or background yields after normalizations and corrections have been applied .",
    "l||ccccc|ccccc + & & + & 1 jet & 2 jets & 3 jets & 4 jets & @xmath31 jets & 1 jet & 2 jets & 3 jets & 4 jets & @xmath176 jets + & & & & & & & & & & +  @xmath19 & 6,908 & 19,465 & 9,127 & 2,483 & 595 & 3,878 & 12,852 & 6,458 & 1,809 & 401 +  @xmath22 & 8,971 & 22,758 & 12,080 & 3,797 & 1,092 & 8,195 & 21,066 & 11,193 & 3,489 & 835 + * background mc *   & & & & & & & & & & +  @xmath177 & 7,671 & 29,537 & 26,042 & 12,068 & 5,396 & 5,509 & 24,595 & 21,803 & 9,788 & 3,442 +  @xmath178+jets & 522 & 5,659 & 22,477 & 27,319 & 14,298 & 232 & 3,376 & 16,293 & 22,680 & 8,658 +  @xmath179 & 26,611 & 13,914 & 9,011 & 3,848 & 1,434 & 27,764 & 14,488 & 9,427 & 3,874 & 1,204 +  @xmath180 & 21,765 & 13,453 & 7,562 & 2,252 & 591 & 32,712 & 19,047 & 10,141 & 3,051 & 663 +  @xmath98 & 134,660 & 61,497 & 34,162 & 8,290 & 1,750 & 147,842 & 66,201 & 36,673 & 9,169 & 1,502 + * pretag data * & & & & & & & & & & +  multijets & 11,565 & 6,993 & 4,043 & 1,317 & 431 & 897 & 658 & 462 & 151 & 48 +  signal data & 27,370 & 8,220 & 3,075 & 874 & 223 & 17,816 & 6,432 & 2,590 & 727 & 173 + * one - tag data * & & & & & & & & & & +  multijets & 246 & 322 & 226 & 93 & 34 & 31 & 51 & 49 & 21 & 8 +  signal data & 445 & 357 & 207 & 97 & 35 & 289 & 287 & 179 & 100 & 38 + * two - tags data * & & & & & & & & & & +  multijets &  & 12 & 15 & 14 & 7 &  & 3 & 4 & 1 & 4 +  signal data &  & 30 & 37 & 22 & 10 &  & 23 & 32 & 27 & 10",
    "the @xmath1+jets background is modeled using the parton - jet matched simulated samples described in sec .  [ mc - samples ] .",
    "this background is normalized to data before @xmath2  tagging , using a procedure explained below . because we normalize to data and do not use theory cross sections , small components of the total background from @xmath102+jets and diboson processes ( @xmath32 , @xmath33 , and @xmath181 , which amount to less than 4% of the total background expectation after tagging )",
    "are implicitly included in the @xmath1+jets part of the background model .",
    "this simplification does not affect the final results because of the low rate from these processes in the final selected dataset , and because the kinematics of the events are similar to those in @xmath1+jets events .",
    "they are thus identified together with @xmath1+jets events by the multivariate discriminants .",
    "the multijet background is modeled using datasets that contain misidentified leptons , as described at the end of sec .",
    "[ selection - cuts ] .",
    "these datasets provide the shape for the multijet background component in each analysis channel .",
    "they are normalized to data as part of the @xmath1+jets normalization process .",
    "we normalize the @xmath1+jets and multijet backgrounds to data before tagging using the matrix method  @xcite , which lets us estimate how many events in the pretagged samples contain a misidentified lepton ( originating from multijet production ) and how many events have a real isolated lepton ( originating from @xmath1+jets or @xmath182 ) .",
    "two data samples are defined , the _ tight _ sample , which is the signal sample after all selection cuts have been applied , and the _ loose _ sample , where the same selection has been applied but requiring only loose lepton quality . the tight data sample , with @xmath183 events , is a subset of the loose data sample with @xmath184 events .",
    "the loose sample contains @xmath185 events with a real lepton ( signal - like events , mostly @xmath1+jets and @xmath182 ) and @xmath186 fake lepton events , which is the number of multijet events in the loose sample .",
    "we measure the probability @xmath187 for a real isolated lepton to pass the tight lepton selection in @xmath188 data events .",
    "the probability for a fake - isolated lepton to pass the tight - isolated lepton criteria , @xmath189 , is measured in a sample enriched in multijet events with the same selection as the signal data but requiring @xmath190  gev . in the electron channel , these probabilities are parametrized as @xmath191 and @xmath192 . in the muon channel",
    ", they are parametrized as @xmath193 and @xmath194 . with these definitions ,",
    "the matrix method is applied using the following two equations : @xmath195 and solving for @xmath196 and @xmath197 so that the multijet and the @xmath1-like contributions in the tight sample @xmath198 and @xmath199 can be determined .",
    "the results of the matrix method normalization , which we apply separately in each jet multiplicity bin , are shown in table  [ mm - numbers ] .",
    "the values shown for @xmath200 and @xmath201 are averages for illustration only .",
    "the pretagged background - data sample is scaled to @xmath198 , and the @xmath1+jets simulated samples ( @xmath179+@xmath180+@xmath98 ) are scaled to @xmath202 , after subtracting the expected number of @xmath182 events in each jet multiplicity bin of the tight sample .",
    "these normalization factors are illustrated in fig .",
    "[ wjets - mm - factors ] .",
    "l||ccccc|ccccc + & & + & 1 jet & 2 jets & 3 jets & 4 jets & @xmath31 jets & 1 jet & 2 jets & 3 jets & 4 jets & @xmath176 jets + @xmath203 & 38,935 & 15,213 & 7,118 & 2,191 & 654 & 18,714 & 7,092 & 3,054 & 878 & 221 + @xmath183 & 27,370 & 8,220 & 3,075 & 874 & 223 & 17,816 & 6,432 & 2,590 & 727 & 173 + @xmath204 & 0.873 & 0.874 & 0.874 & 0.875 & 0.875 & 0.991 & 0.989 & 0.987 & 0.961 & 0.878 + @xmath189 & 0.177 & 0.193 & 0.188 & 0.173 & 0.173 & 0.408 & 0.358 & 0.342 & 0.309 & 0.253 + @xmath205  & 1,691 & 1,433 & 860 & 256 & 86 & 498 & 329 & 223 & 56 & 10 + @xmath206 & 25,679 & 6,787 & 2,215 & 618 & 137 & 17,319 & 6,105 & 2,369 & 669 & 162    + jets background model to pretagged data in each analysis channel.,scaledwidth=38.0% ]      background from the process is modeled using the parton - jet matched simulated samples described in sec .",
    "[ mc - samples ] .",
    "these events are normalized to the theoretical cross section  @xcite at @xmath11  gev ( chosen to match the value used to generate the samples ) , which is 6.8  pb .",
    "table  [ acceptances ] shows the percentage of each signal that remains after selection .",
    "we achieve roughly 30% higher acceptances in this analysis compared to our previously published analysis  @xcite from the use of the more efficient neural network @xmath2-tagging algorithm .",
    "the total acceptance for the s - channel @xmath19 process is @xmath207 and for the t - channel @xmath22 process it is @xmath208 .",
    "l||ccccc|ccccc + & & + & 1 jet & 2 jets & 3 jets & 4 jets & @xmath31 jets & 1 jet & 2 jets & 3 jets & 4 jets & @xmath176 jets +   & & & & & & & & & & +  @xmath19 & 0.55% & 1.77% & 0.83% & 0.23% & 0.06% & 0.33% & 1.36% & 0.69% & 0.19% & 0.05% +  @xmath22 & 0.52% & 1.49% & 0.79% & 0.25% & 0.07% & 0.36% & 1.17% & 0.64% & 0.20% & 0.05% + * one - tag * & & & & & & & & & & +  @xmath19 & 0.24% & 0.82% & 0.39% & 0.11% & 0.03% & 0.15% & 0.64% & 0.32% & 0.09% & 0.02% +  @xmath22 & 0.18% & 0.61% & 0.34% & 0.11% & 0.03% & 0.13% & 0.50% & 0.28% & 0.09% & 0.02% + * two - tags * & & & & & & & & & & +  @xmath19 &  & 0.29% & 0.14% & 0.04% & 0.02% &  & 0.24% & 0.12% & 0.03% & 0.01% +  @xmath22 &  & 0.02% & 0.05% & 0.02% & 0.01% &  & 0.01% & 0.04% & 0.02% & 0.01%",
    "we use the term `` yield '' to mean the number of events of the signal or background in question predicted to be in the 0.9  fb@xmath0 of data analyzed here .",
    "tables  [ pretag - yields ] , [ onetag - yields ] , and [ twotag - yields ] show these yields for all signals and backgrounds separated by lepton flavor and jet multiplicity within each table , and by the numbers of @xmath2-tagged jets between the tables .",
    "because the @xmath1+jets and multijet backgrounds are normalized to data before tagging , the sum of the backgrounds is constrained to equal the number of events observed in the data , as seen in the first table .",
    "the yield values shown in these tables have been rounded to integers for clarity , so that the sums of the components will not always equal exactly the values given for these sums .",
    "all calculations however have been done with full - precision values .",
    "only events with two , three and four jets are used in this analysis , but we show the acceptances and the yields for events with one and for five or more jets in these tables to demonstrate the consistency of the analysis in those channels .",
    "tables  [ onetag - yields ] and [ twotag - yields ] show that most of the signal is contained in the two and three jet bins . however , as discussed in sec .",
    "[ sec : expected - sensitivity ] , our maximum predicted sensitivity is obtained by including events with 24 jets .",
    "l||ccccc|ccccc + & & + & 1 jet & 2 jets & 3 jets & 4 jets & @xmath31 jets & 1 jet & 2 jets & 3 jets & 4 jets & @xmath176 jets + & & & & & & & & & & +  @xmath19 & 4 & 14 & 7 & 2 & 0 & 3 & 10 & 5 & 1 & 0 +  @xmath22 & 9 & 27 & 14 & 5 & 1 & 6 & 20 & 11 & 3 & 1 + * backgrounds * & & & & & & & & & & +  @xmath177 & 9 & 35 & 28 & 10 & 4 & 5 & 27 & 22 & 8 & 3 +  @xmath178+jets & 2 & 26 & 103 & 128 & 67 & 1 & 14 & 71 & 99 & 43 +  @xmath179 & 659 & 358 & 149 & 42 & 5 & 431 & 312 & 161 & 47 & 10 +  @xmath180 & 1,592 & 931 & 389 & 93 & 10 & 1,405 & 1,028 & 523 & 131 & 21 +  @xmath98 & 23,417 & 5,437 & 1,546 & 343 & 51 & 15,476 & 4,723 & 1,591 & 385 & 85 +  multijets & 1,691 & 1,433 & 860 & 256 & 86 & 498 & 329 & 223 & 58 & 10 +   & 27,370 & 8,220 & 3,075 & 874 & 223 & 17,816 & 6,434 & 2,592 & 727 & 172 + & 27,370 & 8,220 & 3,075 & 874 & 223 & 17,816 & 6,432 & 2,590 & 727 & 173    l||ccccc|ccccc + & & + & 1 jet & 2 jets & 3 jets & 4 jets & @xmath31 jets & 1 jet & 2 jets & 3 jets & 4 jets & @xmath176 jets + & & & & & & & & & & +  @xmath19 & 2 & 7 & 3 & 1 & 0 & 1 & 5 & 2 & 1 & 0 +  @xmath22 & 3 & 11 & 6 & 2 & 1 & 2 & 9 & 5 & 2 & 0 + * backgrounds * & & & & & & & & & & +  @xmath177 & 4 & 16 & 13 & 5 & 2 & 2 & 13 & 10 & 4 & 1 +  @xmath178+jets & 1 & 11 & 47 & 58 & 30 & 0 & 6 & 32 & 45 & 20 +  @xmath179 & 188 & 120 & 50 & 14 & 2 & 131 & 110 & 56 & 16 & 4 +  @xmath180 & 81 & 74 & 36 & 9 & 1 & 64 & 74 & 46 & 13 & 2 +  @xmath98 & 175 & 61 & 20 & 5 & 1 & 125 & 58 & 23 & 6 & 2 +  multijets & 36 & 66 & 48 & 18 & 7 & 17 & 26 & 24 & 8 & 2 +   & 484 & 348 & 213 & 110 & 43 & 340 & 286 & 191 & 93 & 30 + & 445 & 357 & 207 & 97 & 35 & 289 & 287 & 179 & 100 & 38    l||ccccc|ccccc + & & + & 1 jet & 2 jets & 3 jets & 4 jets & @xmath31 jets & 1 jet & 2 jets & 3 jets & 4 jets & @xmath176 jets + & & & & & & & & & & +  @xmath19 &  & 2.3 & 1.1 & 0.3 & 0.1 &  & 1.9 & 0.9 & 0.3 & 0.1 +  @xmath22 &  & 0.3 & 0.8 & 0.4 & 0.2 &  & 0.2 & 0.7 & 0.4 & 0.1 + * backgrounds * & & & & & & & & & & +  @xmath177 &  & 5.5 & 4.6 & 1.7 & 0.7 &  & 4.6 & 3.8 & 1.4 & 0.5 +  @xmath178+jets &  & 1.7 & 13.6 & 21.8 & 11.7 &  & 1.0 & 10.2 & 18.0 & 8.1 +  @xmath179 &  & 16.2 & 6.8 & 1.8 & 0.3 &  & 15.3 & 8.2 & 2.3 & 0.6 +  @xmath180 &  & 1.6 & 1.1 & 0.4 & 0.1 &  & 1.6 & 1.5 & 0.5 & 0.1 +  @xmath98 &  & 0.1 & 0.1 & 0.0 & 0.0 &  & 0.1 & 0.1 & 0.0 & 0.0 +  multijets &  & 2.5 & 3.2 & 2.7 & 1.4 &  & 1.5 & 1.9 & 0.4 & 0.8 +   &  & 27.5 & 29.4 & 28.4 & 14.2 &  & 24.1 & 25.7 & 22.7 & 10.1 + &  & 30 & 37 & 22 & 10 &  & 23 & 32 & 27 & 10    table  [ yields - errors ] summarizes the signals , summed backgrounds , and data for each channel , showing the uncertainties on the signals and backgrounds , and the signal - to - background ratios .",
    "table  [ allchans - yields ] shows the signal and background yields summed over electron and muon channels and 1- and 2-tagged jets in the 2-jet , 3-jet , and 4-jet bins , and for the 2- , 3- , and 4-jet bins combined .",
    "l||cccc|cccc + & & + & 1 jet & 2 jets & 3 jets & 4 jets & 1 jet & 2 jets & 3 jets & 4 jets + & & & & & & & & +  signal sum & @xmath209 & @xmath210 & @xmath211 & @xmath212 & @xmath213 & @xmath214 & @xmath215 & @xmath212 +  bkgd sum & @xmath216 & @xmath217 & @xmath218 & @xmath219 & @xmath220 & @xmath221 & @xmath222 & @xmath223 +  data & 29,925 & 7,833 & 2,831 & 752 & 17,527 & 6,122 & 2,378 & 599 +  signal : bkgd   & 1:3,104 & 1:378 & 1:286 & 1:259 & 1:3,253 & 1:407 & 1:320 & 1:292 + * one - tag * & & & & & & & & +  signal sum & @xmath213 & @xmath224 & @xmath209 & @xmath212 & @xmath212 & @xmath225 & @xmath215 & @xmath226 +  bkgd sum & @xmath227 & @xmath228 & @xmath229 & @xmath230 & @xmath231 & @xmath232 & @xmath233 & @xmath234 +  data & 445 & 357 & 207 & 97 & 289 & 287 & 179 & 100 +  signal : bkgd   & 1:95 & 1:20 & 1:23 & 1:38 & 1:101 & 1:21 & 1:26 & 1:42 + * two - tags * & & & & & & & & +  signal sum &  & @xmath235 & @xmath236 & @xmath237 &  & @xmath238 & @xmath239 & @xmath240 +  bkgd sum &  & @xmath241 & @xmath242 & @xmath243 &  & @xmath244 & @xmath245 & @xmath246 +  data &  & 30 & 37 & 22 &  & 23 & 32 & 27 +  signal : bkgd   &  & 1:10 & 1:15 & 1:39 &  & 1:12 & 1:16 & 1:37    l|@r@@xmath247l@ @r@@xmath247l@ @r@@xmath247l@ @r@@xmath247l@ + & + & & & & + & +  @xmath19 & 16 & 3 & 8 & 2 & 2 & 1 & 25 & 6 +  @xmath22 & 20 & 4 & 12 & 3 & 4 & 1 & 37 & 8 + * backgrounds * & +  @xmath177 & 39 & 9 & 32 & 7 & 11 & 3 & 82 & 19 +  @xmath178+jets & 20 & 5 & 103 & 25 & 143 & 33 & 266 & 63 +  @xmath179 & 261 & 55 & 120 & 24 & 35 & 7 & 416 & 87 +  @xmath180 & 151 & 31 & 85 & 17 & 23 & 5 & 259 & 53 +  @xmath98 & 119 & 25 & 43 & 9 & 12 & 2 & 174 & 36 +  multijets & 95 & 19 & 77 & 15 & 29 & 6 & 202 & 39 + & 686 & 131 & 460 & 75 & 253 & 42 & 1,398 & 248 +   & 721 & 132 & 480 & 76 & 260 & 43 & 1,461 & 251 + & & & &    some basic kinematic distributions are shown for electron channel events in fig .",
    "[ agreement - electron ] and for muon channel events in fig .",
    "[ agreement - muon ] .",
    "since the yields are normalized before @xmath2  tagging , in each case the pretagged distributions are shown in the first row of distributions and the one - tag distributions are shown in the second row .",
    "we consider several sources of systematic uncertainty in this analysis and propagate them separately for each signal and background source throughout the calculation .",
    "systematic uncertainties enter the analysis in two ways : as uncertainty on the normalization of the background samples and as effects that change the shapes of distributions for the backgrounds and the expected signals . the effect of these uncertainties on the discriminant outputs and how they affect the cross section measurement is described in sec .",
    "[ sec : priordensity ] .",
    "table  [ systematics - values ] summarizes the relative uncertainties on each of the sources described below .",
    "the first uncertainties listed here affect only the background normalization .    * integrated luminosity * + at 6.1%  @xcite , this is a small contribution to the yield uncertainty .",
    "* theoretical cross section * + the uncertainty on the cross section includes components for the choice of scale and pdf , and also , more significantly , a large component from the top quark mass uncertainty ( i.e. , using 175  gev in this analysis when the latest world average value is @xmath248  gev ) . the combined uncertainty on the cross section is taken as 18% .",
    "the following uncertainties arise from the correction factors and functions applied to the simulated samples to make them match data , and thus affect both the signal acceptances and the background yield .",
    "* trigger efficiency * + functions that represent the trigger efficiency for each object type and trigger level as a function of @xmath59 , @xmath136 , and @xmath65 are used to weight simulated events .",
    "the functions are shifted up and down by one standard deviation of the statistical error arising from the data samples used to calculate the functions and the weight of each event is recalculated . fixed uncertainties of 3% in the electron channel and 6% in the muon channel",
    "are chosen since they encompass all the small variations seen in each analysis channel .    * primary vertex selection efficiency * + the primary vertex selection efficiency in data and the simulation",
    "are not the same .",
    "we assign a systematic uncertainty of 3% for the difference between the beam profile along the longitudinal direction in data and the simulated distribution .",
    "* electron reconstruction and basic identification efficiency * + the electron reconstruction and basic identification correction factors are parametrized as a function of . the 2% uncertainty in the efficiency accounts for its dependence on variables other than , and as a result of limited data statistics used to determine the correction factors .",
    "* electron shower shape , track match , and likelihood efficiency * + the electron shower shape , track match , and likelihood correction factors are parametrized as a function of @xmath136 and @xmath65 . the 5% uncertainty in the efficiency accounts for the dependence on other variables , such as the number of jets and the instantaneous luminosity , and as a result of limited data statistics in determining these correction factors .",
    "* muon reconstruction and identification efficiency * + the correction factor uncertainty of 7% includes contributions from the method used to determine the correction functions , from the background subtraction , and from the limited statistics in the parametrization as a function of the @xmath136 and @xmath65 of the muon .    * muon track matching and isolation * + the muon tracking correction functions have an uncertainty that includes contributions from the method used to measure the functions , from the background subtraction , luminosity and timing bias , and from averaging over @xmath65 and the limited statistics in each bin used to calculate the functions . the muon isolation correction uncertainty is estimated based on its dependence on the number of jets , and covers the dependences not taken into account such as @xmath59 and @xmath136 .",
    "the overall value of these uncertainties combined is 2% .",
    "* jet fragmentation * + this systematic uncertainty covers the lack of certainty in the jet fragmentation model ( and is measured as the difference between and  @xcite fragmentation ) as well as the uncertainty in the modeling of initial - state and final - state radiation .",
    "it is 5% for @xmath19 and @xmath22 and 7% for .",
    "* jet reconstruction and identification * + the efficiency to reconstruct jets is similar in data and simulated events , but the efficiency of the simulated jets is nevertheless corrected by a parametrization of this discrepancy as a function of jet @xmath59 .",
    "we assign a 2% error to the parametrization based on the statistics of the data sample .",
    "* jet energy scale and jet energy resolution * + the jet energy scale ( jes ) is raised and lowered by one standard deviation of the uncertainty on it and the whole analysis repeated . in the data ,",
    "the jes uncertainty contains the jet energy resolution uncertainty .",
    "but in the simulation , the jet energy resolution uncertainty is not taken into account in the jes uncertainty . to account for this ,",
    "the energy smearing in the simulated samples is varied by the size of the jet energy resolution .",
    "this uncertainty affects the acceptance and the shapes of the distributions .",
    "the value of this uncertainty varies from @xmath249 to @xmath80 , depending on the analysis channel , with typical values between @xmath250 and @xmath251 .",
    "the uncertainty on the @xmath1+jets and multijets background yields comes from the normalization to data .",
    "the @xmath1+jets yield is 100% anticorrelated with the multijets yield .",
    "* matrix - method normalization * + the determination of the number of real - lepton events in data is affected by the uncertainties associated with the determination of the probabilities for a loose lepton to be ( mis)identified as a ( fake ) real lepton , @xmath189 and @xmath204 .",
    "the normalization is also affected by the limited statistics of the data sample as described in sec .",
    "[ matrix - method ] .",
    "the combined uncertainties on the @xmath1+jets and multijets yields vary between 17% and 28% , depending on the analysis channel .",
    "* heavy flavor ratio * + the uncertainty on the scale factor applied to set the @xmath179 and @xmath180 fractions of the @xmath1+jets sample , as described in sec .",
    "[ mc - samples ] , is estimated to cover several effects : dependence on the @xmath2-quark @xmath55 , the difference between the zero - tag samples where it is estimated and the signal samples where it is used , and the intrinsic uncertainty on the value of the lo cross section it is being applied to .",
    "this uncertainty is 30% .",
    "it is included in the matrix method uncertainty described above .",
    "there is one source of uncertainty that affects the signal acceptances , and both the and @xmath1+jets background yields .    * @xmath252-tag modeling * + the uncertainty associated with the taggability - rate and tag - rate functions",
    "is evaluated by raising and lowering the tag rate by one standard deviation separately for both the taggability and the tag rate components and determining the new event tagging weight .",
    "these uncertainties originate from several sources as follows : statistics of the simulated event sets ; the assumed fraction of heavy flavor in the simulated multijet sample used for the mistag rate determination ; and the choice of parametrizations . the @xmath2-tag modeling uncertainty varies from 2% to 16% , depending on the analysis channel , and we include the variation on distribution shapes , as well as on sample normalization .",
    "l|c + integrated luminosity & @xmath250 + cross section & @xmath253 + electron trigger & @xmath254 + muon trigger & @xmath250 + primary vertex & @xmath254 + electron reconstruction & identification   & @xmath255 + electron track match & likelihood & @xmath256 + muon reconstruction & identification & @xmath257 + muon track match & isolation & @xmath255 + jet fragmentation & ( 57)@xmath258 + jet reconstruction and identification & @xmath255 + jet energy scale & ( 120)@xmath258 + tag - rate functions & ( 216)@xmath258 + matrix - method normalization & ( 1728)@xmath258 + heavy flavor ratio & @xmath259 + @xmath260 & @xmath255 + @xmath261 & @xmath255 + @xmath262 & ( 340)@xmath258 + @xmath263 & ( 215)@xmath258",
    "the search for single top quark production is significantly more challenging than the search for production .",
    "the principal reasons are the smaller signal - to - background ratio for single top quarks and the large overlap between the signal distributions and those of the backgrounds .",
    "we therefore concluded from the outset that optimal signal - background discrimination would be necessary to have any chance of extracting a single top quark signal from the available dataset .",
    "optimal event discrimination is a well - defined problem with a well - defined and unique solution .",
    "given the probability @xmath264 that an event described by the variables @xmath265 is of the signal class , @xmath266 , the signal can be extracted optimally , that is , with the smallest possible uncertainty  @xcite , by weighting events with @xmath267 , or , as we have done , by fitting the sum of distributions of @xmath267 for signal and background to data , as described in sec .  [ sec : cross_section_measurements ] . in practice , since _ any _ one - to - one function of @xmath267 is equivalent to @xmath267 , it is sufficient to construct an approximation to the discriminant @xmath268 built using equal numbers of signal and background events , that is , with @xmath269 .",
    "each of the three analyses we have undertaken is based on a different numerical method to approximate the discriminant @xmath270 .",
    "from this perspective , they are conceptually identical .    in this paper , we present results from three different multivariate techniques applied to the selected dataset : boosted decision trees ( dt ) in sec .",
    "[ sec : decisiontree ] , bayesian neural networks ( bnn ) in sec .",
    "[ sec : bayesiannn ] , and matrix elements ( me ) in sec .",
    "[ sec : matrixelement ] .",
    "the dt analysis approximates the discriminant @xmath270 using an average of many piece - wise approximations to @xmath270 .",
    "the bnn analysis uses nonlinear functions that approximate @xmath270 directly , that is , without first approximating the densities @xmath271 and @xmath272 .",
    "the me method approximates the densities @xmath271 and @xmath272 semi - analytically , starting with leading - order matrix elements , and computes @xmath270 from them .",
    "the three analyses also differ by the choice of variables used .",
    "the basic observables are :    missing transverse energy 2-vector @xmath273 ,    lepton 4-vector @xmath274 , assuming massless leptons ,    jet 4-vector @xmath274 , assuming massless jets , and jet - type , that is , whether it is a @xmath2  jet or not , for each jet .",
    "these , essentially , are the observables used in the matrix element analysis .",
    "the other analyses , however , make use of physically motivated variables  @xcite derived from the fundamental observables . of course",
    ", the derived variables contain no more information than is contained in the original degrees of freedom .",
    "however , for some numerical approximation methods , it may prove easier to construct an accurate approximation to @xmath270 if it is built using carefully chosen derived variables than one constructed directly in terms of the underlying degrees of freedom .",
    "it may also happen that a set of judiciously chosen derived variables , perhaps one larger than the set of fundamental observables , yields better performing discriminants simply because the numerical approximation algorithm is better behaved or converges faster .",
    "the complete set of variables used in the dt and bnn analyses is shown in table  [ variables ] .",
    "jets are sorted in @xmath59 and index  1 refers to the leading jet in a jet category : `` jet@xmath36 '' ( @xmath36=1,2,3,4 ) corresponds to each jet in the event , `` tag@xmath36 '' to @xmath2-tagged jets , `` untag@xmath36 '' to non-@xmath2-tagged jets , and `` notbest@xmath36 '' to all but the best jet .",
    "the `` best '' jet is defined as the one for which the invariant mass @xmath275 is closest to @xmath276  gev .",
    "aplanarity , sphericity , and centrality are variables that describe the direction and shape of the momentum flow in the events  @xcite .",
    "the variable @xmath277 is the scalar sum of the energy in an event for the jets as shown .",
    "@xmath278 is the scalar sum of the transverse energy of the objects in the event .",
    "@xmath279 is the invariant mass of various combinations of objects .",
    "@xmath280 is the transverse mass of those objects .",
    "@xmath281 is the charge of the electron or muon .",
    "a selection of these variables is shown in figs .",
    "[ fig : vars_obj ] ,  [ fig : vars_evt ] , and  [ fig : vars_ang ] for the sum of all channels : electron plus muon channels , two to four jets , and one or two @xmath2-tagged jets .",
    "figure  [ fig : vars_separation ] shows distributions for some of the variables from table  [ variables ] for sm signals and the background components , normalized to unit area , so that the differences in shapes may be seen .",
    "l|l + * object kinematics & * event kinematics +  @xmath59(jet1 ) &  aplanarity(alljets,@xmath1 ) +  @xmath59(jet2 ) &  sphericity(alljets,@xmath1 ) +  @xmath59(jet3 ) &  centrality(alljets)@xmath282 +  @xmath59(jet4 ) &  @xmath283 +  @xmath59(best ) &  @xmath277(alljets)@xmath282 +  @xmath59(notbest1)@xmath284 &  @xmath277(jet1,jet2)@xmath282 +  @xmath59(notbest2)@xmath284 &  @xmath278(alljets ) +  @xmath59(tag1 ) &  @xmath278(alljets@xmath285best)@xmath284 +  @xmath59(untag1 ) &  @xmath278(alljets@xmath285tag1)@xmath284 +  @xmath59(untag2 ) &  @xmath278(alljets,@xmath1 ) +  @xmath59(@xmath286)@xmath282 &  @xmath278(jet1,jet2 ) + &  @xmath278(jet1,jet2,@xmath1 ) + * angular variables &  @xmath279(alljets ) +  @xmath287(jet1,alljets)@xmath288 &  @xmath279(alljets@xmath285best)@xmath284 +  @xmath287(jet2,alljets)@xmath288 &  @xmath279(alljets@xmath285tag1)@xmath284 +  @xmath287(notbest1,alljets)@xmath288 &  @xmath279(jet1,jet2 ) +  @xmath287(tag1,alljets)@xmath289 &  @xmath279(jet1,jet2,@xmath1 ) +  @xmath287(untag1,alljets)@xmath288 &  @xmath279(@xmath1,best ) +  @xmath287(best , notbest1)@xmath290 &  ( i.e. , `` best '' @xmath291 ) +  @xmath287(best,@xmath286)@xmath290 &  @xmath279(@xmath1,tag1 ) +  @xmath287(notbest1,@xmath286)@xmath290 &  ( i.e. , `` @xmath2-tagged '' @xmath291 ) +  @xmath287(,@xmath286)@xmath290 &  @xmath280(jet1,jet2 ) +  @xmath287(besttop@xmath292 ) &  @xmath59(@xmath1)@xmath282 +  @xmath287(jet1,@xmath286)@xmath293 &  @xmath59(alljets@xmath285best ) +  @xmath287(jet2,@xmath286)@xmath293 &  @xmath59(alljets@xmath285tag1 ) +  @xmath287(tag1,@xmath286)@xmath293 &  @xmath59(jet1,jet2 ) +  @xmath287(untag1,@xmath286)@xmath293 &  @xmath280(@xmath1 ) +  @xmath287(btaggedtop@xmath294 ) &  @xmath281(@xmath286)@xmath295(untag1 ) +  @xmath287(jet1,@xmath286)@xmath296 &  @xmath297 +  @xmath287(jet2,@xmath286)@xmath296 & +  @xmath287(best,@xmath286)@xmath296 & +  @xmath287(tag1,@xmath286)@xmath296 & +  @xmath298(jet1,jet2)@xmath284 & * * *",
    "a decision tree  @xcite employs a machine - learning technique that effectively extends a simple cut - based analysis into a multivariate algorithm with a continuous discriminant output .",
    "boosting is a process that can be used on any weak classifier ( defined as any classifier that does a little better than random guessing ) . in this analysis",
    ", we apply the boosting procedure to decision trees in order to enhance separation of signal and background .",
    "a decision tree classifies events based on a set of cumulative selection criteria ( cuts ) that define several disjoint subsets of events , each with a different signal purity .",
    "the decision tree is built by creating two _ branches _ at every nonterminal node , i.e. , splitting the sample of events under consideration into two subsets based on the most discriminating selection criterion for that sample .",
    "terminal nodes are called _ leaves _ and each leaf has an assigned purity value @xmath35 .",
    "a simple decision tree is illustrated in fig .",
    "[ fig : dt ] . an event defined by variables",
    "@xmath265 will follow a unique path through the decision tree and end up in a leaf .",
    "the associated purity @xmath35 of this leaf is the decision tree discriminant output for the event : @xmath299 , with @xmath270 given in eq .",
    "[ eq : d ] .",
    "of which @xmath300  gev and @xmath301  gev will return @xmath302 , and an event with variables @xmath303 of which @xmath304  gev and @xmath305  gev will have @xmath306 .",
    "all nodes continue to be split until they become leaves .",
    "( color online),scaledwidth=38.0% ]    one of the primary advantages of decision trees over a cut - based analysis is that events which fail an individual cut continue to be considered by the algorithm",
    ". limitations of decision trees include the instability of the tree structure with respect to the training sample composition , and the piecewise nature of the output .",
    "training on different samples may produce very different trees with similar separation power .",
    "the discrete output comes from the fact that the only possible values are the purities of each leaf and the number of leaves is finite .",
    "decision tree techniques have interesting features , as follows : the tree has a human - readable structure , making it possible to know why a particular event was labeled signal or background ; training is fast compared to neural networks ; decision trees can use discrete variables directly ; and no preprocessing of input variables is necessary .",
    "in addition , decision trees are relatively insensitive to extra variables : unlike neural networks , adding well - modeled variables that are not powerful discriminators does not degrade the performance of the decision tree ( no additional noise is added to the system ) .",
    "the process in which a decision tree is created is usually referred to as _ decision tree training_. consider a sample of known signal and background events where each event is defined by a weight  @xmath307 and a list of variables  @xmath265 .",
    "the following algorithm can be applied to such a sample in order to create a decision tree :    initially normalize the signal training sample to the background training sample such that @xmath308 .",
    "create the first node , containing the full sample .",
    "sort events according to each variable in turn . for each variable ,",
    "the splitting value that gives the best signal - background separation is found ( more on this in the next section ) .",
    "if no split that improves the separation is found , the node becomes a leaf .",
    "the variable and split value giving the best separation are selected and the events in the node are divided into two subsamples depending on whether they pass or fail the split criterion .",
    "these subsamples define two new child nodes .",
    "if the statistics are too low in any node , it becomes a leaf .",
    "apply the algorithm recursively from step 3 until all nodes have been turned into leaves .",
    "each of the leaves is assigned the purity value @xmath309 where @xmath310 ( @xmath2 ) is the weighted sum of signal ( background ) events in the leaf .",
    "this value is an approximation of the discriminant @xmath270 defined in eq .",
    "[ eq : d ] .",
    "consider an impurity measure @xmath311 for node @xmath312 .",
    "desirable features of such a function are that it should be maximal for an equal mix of signal and background ( no separation ) , minimal for nodes with either only signal or only background events ( perfect separation ) , symmetric in signal and background purity , and strictly concave in order to reward purer nodes .",
    "several such functions exist in the literature .",
    "we have not found a significant advantage to any specific choice and hence use the common `` gini index ''  @xcite .",
    "the impurity measure , or gini index , is defined as @xmath313 where @xmath310 ( @xmath2 ) is the sum of signal ( background ) weights in a node .",
    "one can now define the decrease of impurity ( goodness of split ) associated with a split @xmath266 of node @xmath312 into children @xmath314 and @xmath315 : @xmath316 where @xmath317 ( @xmath318 ) is the fraction of events that passed ( failed ) split @xmath266 .",
    "the goal is to find the split @xmath319 that maximizes the decrease of impurity , which corresponds to finding the split that minimizes the overall tree impurity .",
    "a powerful technique to improve the performance of any weak classifier was introduced a decade ago : boosting  @xcite .",
    "boosting was recently used in high energy physics with decision trees by the miniboone experiment  @xcite .",
    "the basic principle of boosted decision trees is to train a tree , minimize some error function , and create a tree @xmath320 as a modification of tree @xmath321 .",
    "the boosting algorithm used in d0 s single top quark search is adaptive boosting , known in the literature as adaboost  @xcite .",
    "once a tree indexed by @xmath36 is built with associated discriminant @xmath322 , its associated error @xmath323 is calculated as the sum of the weights of the _ misclassified _ events .",
    "an event is considered misclassified if @xmath324 where @xmath325 is 1 for a signal event and 0 for background .",
    "the tree weight is calculated according to @xmath326 where @xmath327 is the boosting parameter . for each misclassified event ,",
    "its weight @xmath328 is scaled by the factor @xmath329 ( which will be greater than 1 ) .",
    "hence misclassified events will get higher weights .",
    "a new tree indexed by @xmath330 is created from the reweighted training sample now working harder on the previously misclassified events . this is repeated @xmath331 times , where @xmath331 , the number of boosting cycles , is a parameter specified by the user .",
    "the final boosted decision tree result for event @xmath332 is @xmath333    in all of our tests , boosting improves performance .",
    "another advantage of boosting decision trees is that averaging produces smoother approximations to @xmath270 . in this analysis",
    "20 boosted trees are used for each analysis channel , which improves the performance by 5 to 10% . the increase in performance saturates in the region of 20 boosting cycles , varying slightly from channel to channel .",
    "several internal parameters can influence the development of a decision tree .",
    "initial normalization .",
    "step 1 in sec .",
    "[ sec : dttraining ] . in this analysis",
    ", we normalize both signal and background such that their sums of weights are both 0.5 .",
    "criteria to decide when to stop the splitting procedure due to too low statistics ( step 3 in sec .",
    "[ sec : dttraining ] ) . in this analysis",
    "the minimum node size is 100 events per node .",
    "impurity function to use to find the best split .",
    "we use the gini index as mentioned in sec .",
    "[ sec : dtsplitting ] .",
    "number of boosting cycles . for this analysis",
    "we use 20 boosting cycles .",
    "value of the boosting parameter @xmath327 .",
    "we find @xmath334 gives the best expected separation .",
    "a list of sensitive variables has been derived based on an analysis of the signal and background feynman diagrams  @xcite , from studies of single top quark production at next - to - leading order  @xcite , and from other analyses  @xcite .",
    "the variables fall into three categories : individual object kinematics , global event kinematics , and variables based on angular correlations .",
    "the complete list of 49 variables is shown in table  [ variables ] .",
    "previous iterations of the single top quark analysis at d0  @xcite have always used far fewer input variables .",
    "one of the main reasons was that the discriminant was computed with neural networks .",
    "introducing too many variables can degrade the performance of a network , and testing each combination of variables is time - consuming .",
    "however , we observe that adding more variables does not degrade the dt performance . if newly introduced variables have some discriminative power , they improve the performance of the tree . if they are not discriminative enough , they are ignored .",
    "we tested this empirical observation by training different trees using several subsets of variables from the list of 49 variables . adding more variables to the training sets never degraded the performance of the trees .",
    "therefore , rather than producing separately optimized lists of variables for each analysis channel , the full list of 49 variables is used in all cases .",
    "we train the decision trees on one third of the available simulated events and keep the rest of the events to measure the acceptances . as a cross check ,",
    "we have also trained on one half and on two thirds of the sample and have found consistent results with those obtained from using only one third .",
    "we therefore only present results with one third of the sample used for training .",
    "three signals are considered :    s - channel single top quark process only ( @xmath19 )    t - channel single top quark process only ( @xmath22 )    s- and t - channel single top quark processes combined ( @xmath19+@xmath22 )    for simplicity , and because the decision trees are expected to deal well with all components at once , trees are trained against all backgrounds together rather than making separate trees for each background .",
    "the background includes simulated events for @xmath178+jets , @xmath177+jets , and @xmath1+jets ( with three separate components for @xmath103 , @xmath104 and @xmath98 ) .",
    "each background component is represented in proportion to its expected fraction in the background model .",
    "this leads to three different decision trees : ( @xmath19 , @xmath22 , @xmath19+@xmath22 against @xmath144 , @xmath1+jets ) for each training . in the @xmath19+@xmath22 training",
    ", the s- and t - channel components of the signal are taken in their sm proportions .",
    "samples are split by lepton flavor , jet multiplicity , and number of @xmath2-tagged jets .",
    "the current analysis uses the following samples : one isolated electron or muon ; 2 , 3 or 4 jets ; and 1 or 2 @xmath2  tags .",
    "each sample is treated independently with its own training for each signal , leading to 36 different trees ( 3 signals @xmath335 2 lepton flavors @xmath335 3 jet multiplicities @xmath335 2 @xmath2-tagging possibilities ) .",
    "a neural network ( nn ) @xmath336  @xcite is a nonlinear function , with adjustable parameters @xmath337 , which is capable of modeling any real function of one or more variables  @xcite . in particular , it can model the discriminant @xmath270 in eq .",
    "[ eq : d ] .",
    "typically , one finds a single point @xmath338 in the network parameter space for which @xmath339 .",
    "this can be achieved by minimizing an error function that measures the discrepancy between the value of the function @xmath340 and the desired outcome for variables @xmath265 : 1 for a signal event and 0 ( or @xmath341 ) if @xmath265 pertain to a background event .",
    "if the error function is built using equal numbers of signal and background events , the minimization yields the result @xmath342  @xcite provided that the function @xmath340 is sufficiently flexible and that a sufficient number of training events are used .",
    "one shortcoming of the minimization is its tendency , unless due care is exercised , to pick a point @xmath338 that fits the function @xmath340 too tightly to the training data .",
    "this over - training can yield a function , @xmath343 , that is a poor approximation to the discriminant @xmath270 ( eq .  [ eq : d ] ) . in principle",
    ", the over - training problem can be mitigated , and more accurate and robust estimates of @xmath270 constructed , by recasting the task of finding the best approximation to @xmath270 as one of inference from a bayesian viewpoint  @xcite .",
    "the task is to infer the set of parameters @xmath337 that yield the best approximation of @xmath340 to @xmath270 .",
    "given training data @xmath344 , which comprise an equal admixture of signal and background events , one assigns a probability @xmath345 to each point in the parameter space of the network .",
    "since each point @xmath307 corresponds to a network with a specific set of parameter values , the probability @xmath345 quantifies the degree to which the network is a good fit to the training data @xmath344 .",
    "however , instead of finding the best single point @xmath338 , one averages @xmath340 over every possible point @xmath337 , weighted by the probability of each point . a bayesian neural network ( bnn )  @xcite is defined by the function @xmath346 that is , it is a weighted average over all possible network functions of a given architecture .",
    "the calculation is bayesian because one is performing an integration over a parameter space .",
    "if the function @xmath347 is sufficiently smooth , one would expect the averaging in eq .",
    "[ eq : bnn ] to yield a more robust and more accurate estimate of the discriminant @xmath270 than from a single best point @xmath338 .",
    "there is however a practical difficulty with eq .",
    "[ eq : bnn ] : it requires the evaluation of a complicated high - dimension integral .",
    "fortunately , this is feasible using sophisticated numerical methods , such as markov chain monte carlo  @xcite .",
    "we use this method to sample from the posterior density @xmath347 and to approximate eq .",
    "[ eq : bnn ] by the sum @xmath348 where @xmath349 is the sample size .",
    "we perform the bayesian neural network calculations for this analysis using the `` software for flexible bayesian modeling '' package  @xcite .      given training event @xmath350 , where @xmath351 denotes the _ targets _  1 for signal and 0 for background  and @xmath265 denotes the set of associated variables , we construct the posterior probability density @xmath347 via bayes theorem @xmath352 with @xmath353 .",
    "we see that there are two functions to be defined : the likelihood @xmath354 and the prior probability density @xmath355 . for this analysis",
    ", the neural network functions have the form @xmath356 } , \\\\",
    "\\mathrm{where } \\nonumber \\\\ \\label{eq : f }   f(\\mathbf{x},\\mathbf{w } )   & = & b + \\sum_{h=1}^h v_h \\ ,          \\tanh(a_h + \\sum_{i=1}^i u_{hi } \\ , x_i ) \\ , .\\end{aligned}\\ ] ] @xmath277 is the number of hidden nodes and @xmath357 is the number of input variables , @xmath265 .",
    "the adjustable parameters @xmath337 of the networks are @xmath358 and @xmath359 ( the weights ) and @xmath360 and @xmath2 ( the biases ) .",
    "if @xmath265 are the variables for an event , then the event s probability to be signal is @xmath336 ; if it is a background event , then its probability is @xmath361 . therefore , the probability of the training event set is @xmath362 where @xmath363 for signal and @xmath364 for background , and @xmath36 is the total number of events .",
    "the bnn likelihood is proportional to this probability .",
    "the last ingredient needed to complete the bayesian calculation is a prior probability density .",
    "this is the most difficult function to specify .",
    "however , experience suggests that for each network parameter , a gaussian centered at the origin of the parameter space produces satisfactory results .",
    "moreover , the widths of the gaussian should be chosen to favor parameter values close to the origin , since smaller parameter values yield smoother approximations to @xmath270 .",
    "conversely , large parameter values yield jagged approximations .",
    "however , since one does not know _ a priori _ what widths are appropriate , initially we allowed their values to adapt according to the noise level in the training data .",
    "subsequently , we found that excessive noise in the training data can cause the parameter values to grow too large .",
    "therefore , we now keep the widths fixed to a small set of values determined using single neural networks .",
    "this change is an improvement over the method used in ref .",
    "@xcite .      to compute the average in eq .",
    "[ eq : bnnaverage ] requires a sample of points @xmath337 from the posterior density , @xmath347 .",
    "these points are generated using a markov chain monte carlo method .",
    "we first write the posterior density as @xmath365},\\ ] ] where @xmath366 may be thought of as a `` potential '' through which a `` particle '' moves .",
    "we then add a `` kinetic energy '' term @xmath367 , where @xmath368 is a vector of the same dimensionality as @xmath337 , which together with the potential yields the particle s `` hamiltonian '' @xmath369 .",
    "for a system governed by a hamiltonian , every phase space point @xmath370 will be visited eventually in such a way that the phase space density of points is proportional to @xmath371 .",
    "the phase space is traversed by alternating between long deterministic trajectories and stochastic changes in momentum .",
    "after every random change , one decides whether or not to accept the new phase space point : the new state is accepted if the energy has decreased , and accepted with a probability less than one if the contrary is true .",
    "this algorithm yields a markov chain @xmath372 of points , which converges to a sequence of points that constitute a faithful sample from the density @xmath347 .",
    "in our calculations , each deterministic trajectory comprises 100 steps , followed by a randomization of the momentum .",
    "this creates a point that could be used in eq .",
    "[ eq : bnnaverage ] .",
    "however , since the correlation between adjacent points is high , this pair of actions is repeated 20 times , which constitutes one iteration of the algorithm , and a point is saved after each iteration .",
    "the bayesian neural networks are trained separately for each of the 12 analysis channels , with different sets of variables in each channel .",
    "the variables are selected using an algorithm called rulefit  @xcite that orders them according to their discrimination importance ( on a scale of 1 to 100 ) .",
    "variables with discrimination importance greater than 10 are used , which results in the selection of between 18 and 25 variables in the different channels .",
    "for example , the variables for the electron+2jets/1tag channel are shown in fig .  [",
    "fig : e1tag ] .",
    "each network contains a single hidden layer with 20 nodes , with the sample size @xmath349 set to 100 .",
    "the number of signal and background events used in the training is 10,000 each .",
    "the main idea behind the matrix element ( me ) technique is that the physics of a collision , including all correlations , is contained in the matrix element @xmath373 , where @xmath374 and @xmath375 is the differential cross section , @xmath376 is the flux factor , and @xmath377 is the lorentz invariant phase space factor .",
    "the me analysis builds a discriminant directly using eq .",
    "[ golden ] , thereby potentially making use of all the available kinematic information in the event . in particular , the method uses @xmath378 where @xmath265 is the configuration of the event , and @xmath379 is the probability density to observe @xmath265 given that the physics process is @xmath380 to build the discriminant given in eq .",
    "[ eq : d ] .    for each data and simulated event ,",
    "two discriminant values are calculated : a t - channel discriminant and an s - channel discriminant .",
    "the t - channel discriminant uses the t - channel matrix elements when calculating @xmath381 as in eq .",
    "[ eq : d ] , while the s - channel discriminant uses s - channel matrix elements . for each analysis channel , these discriminant values are plotted in a two - dimensional histogram , out of which a cross section measurement is extracted , as will be discussed in sec .",
    "[ sec : cross_section_measurements ] .",
    "the me analysis only uses events with two or three jets and one or two @xmath2-tags , and given the two types of leptons , that results in eight independent analysis channels .",
    "the matrix element method was developed by d0 to measure the top quark mass  @xcite and has been used by d0  @xcite and cdf  @xcite for subsequent measurements .",
    "the me method has also been used to measure the longitudinal @xmath1  boson helicity fraction in top quark decays  @xcite .",
    "the result detailed here marks the first use of the method to separate signal from background in a particle search  @xcite .",
    "the event configuration , @xmath265 , represents the set of reconstructed four - momenta for all selected final state objects , plus any extra reconstruction - level information , such as whether a jet is @xmath2  tagged , if there is a muon in a jet , the quality of the muon track , and so on .",
    "however , the matrix element , @xmath373 , depends on the parton - level configuration of the event , which we label @xmath382 .",
    "the differential cross section , @xmath383 , can be related to the parton - level variant , @xmath384 , by integrating over all the possible parton values , using the parton distribution functions to relate the initial state partons to the proton and antiproton , and using a _ transfer function _ to relate the outgoing partons to the reconstructed objects :    @xmath385\\ ] ]    where    @xmath386 is the sum over different configurations that contribute to the differential cross section : it is the discrete analogue to @xmath387 .",
    "specifically , this summation includes summing over the initial parton flavors in the hard scatter collision and the different permutations of assigning jets to partons .",
    "@xmath387 is an integration over the phase space : @xmath388 many of these integrations are reduced by delta functions .",
    "@xmath389 is the parton distribution function in the proton or antiproton ( @xmath36 = 1 or 2 , respectively ) for the initial state parton associated with configuration @xmath390 , carrying momentum @xmath391 , evaluated at the factorization scale @xmath392 .",
    "we use the same factorization scales as used when the simulated samples were generated .",
    "this analysis uses cteq6l1  @xcite leading - order parton distribution functions via  @xcite .",
    "@xmath393 is the differential cross section for the hard scatter ( hs ) collision .",
    "it is proportional to the square of the leading - order matrix element as given by ( c.f .",
    ",  eq .  [ golden ] ) : @xmath394 where @xmath391 and @xmath395 are the four - momenta and masses of the initial - state partons .",
    "@xmath396 is called the transfer function ; it represents the conditional probability to observe configuration @xmath265 in the detector given the original parton configuration ( @xmath382 , @xmath390 ) .",
    "the transfer function is divided into two parts : @xmath397 where @xmath398 , discussed in sec .  [",
    "sec : perm ] , is the weight assigned to the given jet - to - parton permutation and @xmath399 , discussed in sec .",
    "[ sec : tf ] , relates the reconstructed value to parton values for a given permutation .",
    "@xmath400 represents the parton - level cuts applied in order to avoid singularities in the matrix element evaluation .",
    "vegas monte carlo integration is used , as implemented in the gnu scientific library  @xcite .    the probability to observe a particular event given a process hypothesis , eq .",
    "[ px ] , also requires the total cross section ( @xmath335 branching fraction ) as a normalization .",
    "the total cross section ( @xmath401 ) is just an integration of eq .",
    "[ dsigma ] : @xmath402 the term @xmath403 approximates the selection cuts . while conceptually simple , eq .  [ cross ] represents a large integral : 13 dimensions for two - jet events , 17 dimensions for three - jet events other than , and 20 dimensions for events .",
    "however , this integral needs to be calculated only once , not once per event , so the actual integration time is insignificant .",
    "the matrix elements used in this analysis are listed in table  [ elements ] .",
    "the code to calculate the matrix elements is taken from the  @xcite leading - order matrix - element generator and uses the  @xcite routines to evaluate the diagrams . in table",
    "[ elements ] , for the single top quark processes , the top quark is assumed to decay leptonically : @xmath404 .",
    "for the @xmath405 processes , the @xmath1 boson is also assumed to decay leptonically : @xmath406 .",
    "charge - conjugate processes are included .",
    "the same matrix elements are used for both the electron and muon channels .",
    "furthermore , we use the same matrix elements for heavier generations of incoming quarks , assuming a diagonal ckm matrix . in other words , for the @xmath20 process , we use the same matrix element for @xmath407 and @xmath408 initial - state partons .",
    "ll|ll + & + name & process & name & process + & & * signals * & +  @xmath19 & @xmath409 ( 1 ) &  @xmath410 & @xmath411 ( 5 ) +  @xmath412 & @xmath413 ( 1 ) &  @xmath414 & @xmath415 ( 5 ) + & @xmath416 ( 1 ) & & @xmath417 ( 5 ) + & &  @xmath22 & @xmath418 ( 4 ) + & & & @xmath419 ( 4 ) + * backgrounds * & & * backgrounds * & +  @xmath420 & @xmath421 ( 2 ) &  @xmath422 & @xmath423 ( 12 ) +  @xmath424 & @xmath425 ( 8) &  @xmath426 & @xmath427 ( 54 ) +  @xmath428 & @xmath429 ( 8)   &  @xmath430 & @xmath431 ( 54 ) + & &   & @xmath432 ( 3 ) + & & & @xmath433 ( 3 )    new to the analysis after the result published in ref .",
    "@xcite is an optimization of the three - jet analysis channel . for these events ,",
    "a significant fraction of the background is @xmath434+jets , as can be seen from the yield tables ( see , e.g. , table  [ allchans - yields ] ) .",
    "while no new processes are added to the two - jet analysis , @xmath414 , @xmath426 , @xmath430 , and are now included in the three - jet analysis .      for the integration",
    ", we can not assume one - to - one matching of parton to reconstructed object .",
    "the final state has four quarks , so one - to - one matching would lead to a four - jet event .",
    "we are interested , however , in using the  matrix element in the three - jet bin .",
    "the  events therefore have to `` lose '' one jet to enter this bin .",
    "one way that a jet could be lost is by having its reconstructed  be below the selection threshold , which is 15gev .",
    "another way to lose a jet is if it is merged with another nearby jet .",
    "the jet could also be outside the @xmath26 acceptance of the analysis with @xmath435 .",
    "there is in addition a general reconstruction inefficiency that can cause a jet to be lost , but it is a small effect .    a study of simulated events before tagging shows that @xmath436 of the time when a jet is lost , there is no other jet that passes the selection cuts within @xmath437 ,",
    "that is , it has not been merged with another jet .",
    "the transverse momentum of quarks not matched to a jet passing the selection cuts is peaked at around 15  gev , indicating that the jet is often lost because it falls below the jet @xmath59 threshold .",
    "this study shows that the light - quark jets , which have a softer @xmath59 spectrum , are 1.7 times as likely to be lost owing to the @xmath59 cut as the heavy - quark jets .",
    "this observation motivated the following simplification : assume that the lost jet is from a light quark coming from the hadronically decaying @xmath1 boson . in the most common case ,",
    "the probability assigned to losing a jet given parton transverse energy @xmath438 is the probability that the jet is reconstructed to have @xmath439  gev , which can be calculated from the jet transfer function @xmath440 ( discussed in sec .",
    "[ sec : tf ] ) : @xmath441 a minimum probability of 5% is used to account for other inefficiencies in reconstructing a jet . a random number determines which of the two quarks coming from the @xmath1 boson is lost for a particular sample point in the mc integration .",
    "other special cases considered are when the two light quarks have @xmath442 , in which case they are assumed to merge , or if the pseudorapidity of the quark is outside our acceptance , in which case it is assumed lost .",
    "the ( discrete ) summation over different configurations incorporated in eq .",
    "[ dsigma ] includes the summation over the different ways to assign the partons to the jets .",
    "a weight for each permutation is included as the @xmath443 part of the transfer function .",
    "this analysis uses two pieces of information to determine the weight , namely @xmath2  tagging and muon charge ( the muon from @xmath2  decay ) : @xmath444    the @xmath2-tagging weight is assumed to factor by jet : @xmath445 where @xmath446 is the flavor of quark @xmath332 and @xmath447 is true or false depending on whether the jet is @xmath2  tagged or not .",
    "the weights assigned to cases with and without a @xmath2  tag are : @xmath448 where @xmath449 is the tag - rate function for the particular quark flavor and @xmath450 is the taggability - rate function , which is the probability that a jet is taggable .    for the s - channel matrix element and for the matrix element , there are both a @xmath2  quark and a @xmath451  quark in the final state . furthermore , the matrix element is not symmetric with respect to the interchange of the @xmath2 and @xmath451 quarks , so it is helpful to be able to distinguish between @xmath2  jets and @xmath451  jets to make the correct assignment . in the case of muonic decays of the @xmath2 or @xmath451 quark , it is possible to distinguish between the jets by the charge of the decay muon .",
    "one complication is that a charm quark may also decay muonically , and the charge of the muon differs between @xmath452 and @xmath453 .",
    "however , because @xmath454 , the muon transverse momentum relative to the jet axis , differs in the two cases , the charge of the muon still provides information . similarly to @xmath455 , we assign the muon charge weight @xmath456 based on whether the jet , if it is assumed to be a @xmath2 or @xmath451 in the given permutation , contains a muon of the appropriate charge .",
    "the weight is calculated by the probability that a @xmath2 or a @xmath451 quark decays directly into a muon given that there is a muon in the jet , parametrized as a function of @xmath454 of the muon .",
    "we assume that the parton - level to reconstruction - level transfer function , @xmath457 in eq .",
    "[ wbreakdown ] , can be factorized into individual per - object transfer functions : @xmath458 where @xmath459 is a transfer function for one object  a jet , a muon , an electron  and @xmath460 and @xmath461 are reconstructed and parton - level information , respectively , for that object .",
    "we assume that angles are well measured , so the only transfer functions that are not delta functions are those for energy ( for jets and electrons ) and @xmath462 ( for muons ) .",
    "the jet transfer functions , which give the probability to measure a jet energy given a certain parton energy , are parametrized as double gaussians in four pseudorapidity ranges , for light jets , for @xmath2  jets with a muon within the jet , and for @xmath2  jets with no muon in the jet .",
    "the electron and muon transfer functions are parametrized as single gaussians .",
    "the jet and muon transfer functions are measured in simulated events .",
    "the electron transfer functions are based on the electron resolution measured in single electron and @xmath102  boson peak simulated events .",
    "we build separate s - channel and t - channel discriminants , @xmath463 and @xmath464 .",
    "the signal probability densities for the various channels are : @xmath465 equation  [ eq:3 t ] can also be written as : @xmath466 where @xmath467 and @xmath468 are the relative yields of the two signal processes . calculating the yield fractions using eq .",
    "[ cross ] , for single - tagged events we use @xmath469 and @xmath470 , while for double - tagged events we use @xmath471 and @xmath472 .",
    "we apply the same methodology of using weights based on yield fraction for the @xmath473 calculations .",
    "we do not use a matrix element for every background that exists , however , so the yield fractions can not be determined as for the signal probabilities .",
    "some , such as @xmath474 , are not included because they have similar characteristics to ones that are included , such as @xmath421 .",
    "therefore , we use the yields as determined from the simulated samples and consider what background the matrix elements are meant to discriminate against .",
    "we find the performance of the discriminant to be not very sensitive to the chosen weights if the weights are reasonable , and have used the weights given in table  [ frac ] .",
    "l||cc|cc + & & + weight & electron & muon   & electron & muon + & & & & +  @xmath475 & 0.55 & 0.60 & 0.83 & 0.87 +  @xmath476 & 0.15 & 0.15 & 0.04 & 0.04 +  @xmath477 & 0.35 & 0.30 & 0.13 & 0.09 + * three - jet events *  & & & & +  @xmath478 & 0.35 & 0.45 & 0.30 & 0.40 +  @xmath479 & 0.10 & 0.10 & 0.02 & 0.03 +  @xmath480 & 0.30 & 0.25 & 0.13 & 0.10 +  @xmath481 & 0.25 & 0.20 & 0.55 & 0.47",
    "discriminant output shapes for signal and different background components are shown in fig .  [",
    "fig : discriminantoutputs ] , demonstrating the ability of the three analyses to separate signal from background .",
    "the dt discriminant is narrower and more central owing to the averaging effect of boosting ( according to eq .",
    "[ eq : bdtoutput ] ) .",
    "the separation powers of the discriminants shown in fig .",
    "[ fig : discriminantoutputs ] are more directly visualized in fig .",
    "[ fig : sigbkgeff ] .                                                    the discriminant outputs for the data and the expected standard model contributions are shown in fig .",
    "[ fig : disc ] for the three multivariate techniques .",
    "the outputs show good agreement between data and backgrounds , except in the high discriminant regions , where an excess of data over the background prediction is observed .",
    "we have described three sophisticated analyses ( dt , bnn , me ) , each of which produces a posterior density for the single top quark production cross section .",
    "when applied to real data , we obtain well - behaved posterior densities . however , this does not guarantee that these methods are trustworthy and perform as advertised . in order to validate the methods ,",
    "it is necessary to study their behavior on ensembles of pseudodatasets with characteristics as close as possible to those of the real data .",
    "we can use such ensembles to determine , for example , whether an analysis is able to extract a cross section from a signal masked by large backgrounds .",
    "we can also determine whether the claimed accuracy is warranted .",
    "moreover , by running the three analyses on exactly the same ensembles , we can study in detail the correlations across analyses and the frequency properties of combined results and their significance .",
    "we generate pseudodatasets from a pool of weighted signal and background events , separately for the electron and muon channels .",
    "for example , out of 1.3 million electron events , we calculate a total background yield of 756 events in the selected data .",
    "we randomly sample a count @xmath331 from a poisson distribution of mean @xmath482 and select @xmath331 events , with replacement , from the pool of 1.3 million weighted events so that events are selected with a frequency proportional to their weight .",
    "the sample contains the appropriate admixture of signal and background events , as well as the correct poisson statistics .",
    "moreover , we take into account the fact that the multijets and @xmath1+jets sample sizes are @xmath483 anticorrelated . the sample is then partitioned according to the @xmath2  tag and jet multiplicities , mirroring what is done to the real data .",
    "the poisson sampling , followed by sampling with replacement , is repeated to generate as many pseudodatasets as needed .",
    "each pseudodataset is then analyzed in exactly the same way as real data .",
    "we have performed studies using many different ensembles , of which the most important ones are :    * background only ( i.e. , zero signal ) ensemble with systematics *  the background is set to the estimated background yield value ; the signal cross section is set to 0  pb ; these poisson - smeared means are further randomized to represent the effects of all systematic uncertainties .    * standard model signal ensemble with systematics *",
    " the background is set to the estimated background yield value ; the signal cross section is set to the standard model value of 2.86  pb ; these poisson - smeared means are further randomized to represent the effects of all systematic uncertainties .    * ensembles with different signal cross sections *",
    " the background is set to the estimated background yield value ; the signal cross section is set to a fixed value between 0  pb and a few times the standard model value in each ensemble ; only poisson - smearing for statistical effects is applied .",
    "we use the zero - signal ensemble ( with systematics ) to calculate the @xmath35-value , a measure of the significance of the observed excess .",
    "the @xmath35-value is the probability that we obtain a measured cross section greater than or equal to the observed cross section , if there were no signal present in the data .",
    "we use the sm signal ensemble ( with systematics ) to determine the correlations between the three analysis methods so we can combine their results .",
    "we also use this ensemble to calculate the compatibility of our measured result with the sm prediction , by determining how many pseudodatasets have a measured cross section at least as high as the result measured with data .",
    "the set of ensembles with different values for the signal cross section is used to assess bias in the cross section measurement , that is , the difference between the input cross section and the mean of the distribution of measured cross sections . for each multivariate analysis ,",
    "the bias is estimated by applying the entire analysis chain to the ensembles of pseudodatasets that each have a different value for the single top quark cross section .",
    "straight - line fits of the average of the measured cross sections versus the input cross section for the three multivariate analyses are shown in fig .",
    "[ fig : calibration ] . from this measurement ,",
    "we conclude that the bias in all three analyses is small . moreover , when compared with the variances of the ensemble distributions of measured values , the biases are negligible .",
    "we thus perform no correction to the expected or measured cross section values .",
    "in order to check the background model , we apply the multivariate discriminants to two background - dominated samples defined by the following criteria : ( i )  2  jets , 1  @xmath2  tag , and @xmath484  gev for a `` @xmath1+jets '' sample ; and ( ii )  4  jets , 1  @xmath2  tag , and @xmath485  gev for a `` '' sample .",
    "the first sample is mostly @xmath1+jets and almost no , while the second is mostly and almost no @xmath1+jets .    the @xmath19+@xmath22 decision tree output distributions for these cross - check samples are shown in fig .",
    "[ fig : dt - wjets - ttbar - crosscheck ] and the corresponding bayesian neural network output distributions are shown in fig .",
    "[ fig : bnn - wjets - ttbar - crosscheck ] . from these data - background comparisons , we conclude that there is no obvious bias in our measurement .",
    "the background model describes the data within uncertainties .",
    "the matrix element analysis does not use four - jet events , so the cross - check samples are defined to have @xmath486  gev or @xmath487  gev for any number of jets .",
    "figure  [ fig : me - lowht - crosscheck ] shows the s- and t - channel discriminant outputs for two - jet and three - jet events for the @xmath486  gev cross - check samples .",
    "the plots have the electron and muon channels and the one and two @xmath2-tag channels combined for increased statistics .",
    "figure  [ fig : me - highht - crosscheck ] shows the same for the @xmath487  gev samples .",
    "we use a bayesian approach  @xcite to extract the cross section @xmath488 from the observed binned discriminant distributions . in principle , the binning of data should be avoided because information is lost . in practice , however , an unbinned likelihood function is invariably approximate because of the need to fit smooth functions to the distributions of the unbinned data .",
    "consequently , the uncertainty in the fits induces an uncertainty in the likelihood function that grows linearly with the number of events . without study , it is not clear whether an unbinned , but approximate , likelihood function will yield superior results to those obtained from a binned but exact one .",
    "since we have not yet studied the matter , we choose to bin the data and avail ourselves of an exact likelihood function .      for a given bin ,",
    "the likelihood to observe count @xmath489 , if the mean count is @xmath490 , is given by the poisson distribution @xmath491 where @xmath492 is the gamma function .",
    "( we write the poisson distribution in this form to permit the use of noninteger counts in the calculation of expected results . for observed results ,",
    "the counts are of course integers . )",
    "the mean count @xmath490 is the sum of the predicted contributions from the signal and background sources @xmath493 where @xmath108 is the signal acceptance , @xmath494 the integrated luminosity , @xmath401 the single top quark production cross section , @xmath495 the mean count ( that is , yield ) for background source @xmath332 , @xmath331 the number of background sources , and @xmath496 is the effective luminosity for the signal . for analyses in which the signal comprises s- and t - channel simulated events ,",
    "the latter are combined in the ratio predicted by the standard model .",
    "( without this assumption , the probability of count @xmath489 would depend on the s- and t - channel cross sections @xmath497 and @xmath498 explicitly . )    for a distribution of observed counts , the single - bin likelihood is replaced by a product of likelihoods @xmath499 where @xmath500 and @xmath501 represent vectors of the observed and mean counts , and @xmath502 and @xmath503 are vectors of effective luminosity and background yields .",
    "the product is over @xmath279 statistically independent bins : either all bins of a given lepton flavor , @xmath2-tag multiplicity , or jet multiplicity , or all bins of a combination of these channels .    from bayes theorem",
    ", we can compute the posterior probability density of the parameters , @xmath504 , which is then integrated with respect to the parameters @xmath502 and @xmath503 to obtain the posterior density for the single top quark production cross section , given the observed distribution of counts @xmath500 , @xmath505 here , @xmath506 is an overall normalization obtained from the requirement @xmath507 , where the integration is performed numerically up to an upper bound @xmath508 when the value of the posterior is sufficiently close to zero . in this analysis ,",
    "varying @xmath509 from 30 to 150  pb has negligible effect on the result .",
    "the function @xmath510 is the prior probability density , which encodes our knowledge of the parameters @xmath401 , @xmath511 , and @xmath503 . since our knowledge of the cross section @xmath401",
    "does not inform our prior knowledge of @xmath502 and @xmath503 , we may write the prior density as @xmath512 the prior density for the cross section is taken to be a nonnegative flat prior , @xmath513 for @xmath514 , and @xmath515 otherwise .",
    "we make this choice because it is simple to implement and yields acceptable results in ensemble studies ( see sec .  [",
    "sec : ensembles ] ) .",
    "the posterior probability density for the signal cross section is therefore @xmath516 we take the mode of @xmath517 as our measure of the cross section , and the @xmath518 interval about the mode as our measure of the uncertainty with which the cross section is measured .",
    "we have verified that these intervals , although bayesian , have approximately 68% coverage probability and can therefore be interpreted as approximate frequentist intervals if desired .",
    "the integral in eq .",
    "[ eq : finalposterior ] is done numerically using monte carlo importance sampling .",
    "we generate a large number @xmath349 of points @xmath519 randomly sampled from the prior density @xmath520 and estimate the posterior density using @xmath521    in the presence of two signals , we use the same procedure and calculate the posterior probability density according to eq .",
    "[ eq : mcintegration ] , replacing @xmath401 by @xmath522 everywhere .",
    "we also replace the term @xmath523 in eq .",
    "[ eq : meancount ] by @xmath524 , where @xmath525 and @xmath526 are the effective luminosities of the @xmath19 and @xmath22 signals , and @xmath527 and @xmath528 are their cross sections . the prior density for the cross section @xmath529 in eq .",
    "[ eq : meancount ] becomes @xmath530 if both @xmath527 and @xmath528 are @xmath531 , and @xmath532 otherwise . with these two replacements ,",
    "the posterior probability density becomes a two - dimensional distribution as a function of the two cross sections .",
    "the prior density @xmath533 encodes our knowledge of the effective signal luminosities and the background yields ( see sec .  [ systematics ] ) .",
    "the associated uncertainties fall into two classes : those that affect the overall normalization only , such as the integrated luminosity measurement , and those that also affect the shapes of the discriminant distributions , which are the jet energy scale and @xmath2-tag modeling .",
    "the normalization effects are modeled by sampling the effective signal luminosities * a * and the background yields * b * from a multivariate gaussian , with the means set to the estimated yields and the covariance matrix computed from the associated uncertainties .",
    "the covariance matrix quantifies the correlations of the systematic uncertainties across different sources of signal and background .",
    "the shape effects are modeled by changing , one at a time , the jet energy scale and @xmath2-tag probabilities by plus or minus one standard deviation with respect to their nominal values .",
    "therefore , for a given systematic effect , we create three model distributions : the nominal one , and those resulting from the plus and minus shifts . for each bin , gaussian fluctuations , with standard deviation defined by the plus and minus shifts in bin yield , are generated about the nominal yield , and added linearly to the nominal yields generated from the sampling of the normalization - only systematic effects .",
    "since effects such as a change in jet energy scale affect all bins coherently , we assume 100@xmath258 correlation across all bins and sources .",
    "this is done by sampling from a zero mean , unit variance gaussian and using the same variate to generate the fluctuations in all bins .      given two well - defined hypotheses @xmath534 and @xmath535 ( e.g. , the background - only and the signal+background hypotheses ) , it is natural in a bayesian context to consider a bayes factor @xmath536 , @xmath537 as a way to quantify the significance of hypothesis @xmath535 relative to @xmath534 . here",
    ", @xmath538 is the marginal ( or integrated ) likelihood and @xmath529 is the cross section prior density , which could be taken as a gaussian about the standard model predicted value .",
    "another possible use of a bayes factor is as an objective function to be maximized in the optimization of analyses ; the optimal analysis would be the one with the largest expected bayes factor .",
    "these considerations motivate a quantity akin to a bayes factor that is somewhat easier to calculate , which we have dubbed a bayes ratio , defined by @xmath539 where @xmath540 is the mode of the posterior density .",
    "the three analyses are optimized using the expected bayes ratio , which is computed by setting the distribution * d * to the expected one .",
    "before making a measurement using data , it is useful to calculate the expected sensitivity of these analyses . furthermore , this expected sensitivity is used to optimize the choice of parameters in the analyses . for each case under consideration",
    "we calculate an expected bayes ratio as defined in sec .",
    "[ bayes - ratio ] .",
    "the highest bayes ratio corresponds to the optimal parameter choice .",
    "table  [ tab : expbayesratios ] shows the expected bayes ratio for each possible combination of analysis channels in the dt analysis . it can be seen from the numbers in the table that combining the two single top quark signals ( i.e. , searching for @xmath19+@xmath22 together ) results in the best expected sensitivity .",
    "the single - tag two - jet channel contributes the most to this sensitivity , as expected from the high signal acceptance and reasonable signal - to - background ratio , but the addition of the other channels does improve the result ; including the poorer ones does not degrade it . while the result from this table refers specifically to the dt analysis ,",
    "the conclusions hold for all three multivariate techniques .",
    "therefore , from this point onward , the 24 jets 12 tags result , using electrons and muons in the @xmath19+@xmath22 channel will be considered as default ( 23 jets for the me analysis ) .",
    "l||cc|cc|ccc|c + & & & & all + & @xmath28-chan & @xmath29-chan & 1 tag & 2 tags & 2 jets & 3 jets & 4 jets&channels +  @xmath19 & 1.1 & 1.1 & 1.1 & 1.1 & 1.2 & 1.0 & 1.0 & * 1.2 * +  @xmath22 & 2.5 & 1.8 & 4.5 & 1.1 & 3.1 & 1.5 & 1.1 & * 4.7 * +  @xmath19+@xmath22   & 3.2 & 2.3 & 6.7 & 1.3 & 4.8 & 1.5 & 1.1 & * 8.0 *      we measure the expected cross sections for the various channels by setting the number of data events in each channel equal to the ( noninteger ) expected number of background events plus the expected number of signal events ( using the sm cross section of 2.86  pb at @xmath11  gev ) , and obtain the following results : @xmath541    the expected cross sections agree with the input cross section . the small deviation , less than @xmath251 , is from the nonsymmetric nature of several of the systematic uncertainties , in particular the jet energy scale and @xmath2  tagging .",
    "this effect is also observed in the pseudodatasets .",
    "the linearity of the methods to measure the appropriate signal cross section was discussed in sec .",
    "[ sec : ensembles ] and fig .",
    "[ fig : calibration ] , and no calibration is necessary based on those results .",
    "the cross sections measured using data with the three multivariate techniques are shown in fig .",
    "[ fig : crosssec - channels ] where each measurement represents an independent subset of the data , for example , the 2-jet sample with 1 @xmath2  tag in the electron channel .",
    "the full combination of available channels ( the most sensitive case ) yields the bayesian posterior density functions shown in fig .",
    "[ fig : finalposteriors ] and cross sections of : @xmath542            figure  [ fig : disc - zooms ] shows the high - discriminant regions for each of the multivariate methods , with the signal component normalized to the cross section measured from data . clearly , a model including a signal contribution fits the data better than does a background - only model .                to further illustrate the excess of data events over background in the high - discriminant region , fig .",
    "[ fig : eventchars ] shows three variables that are inputs to the dt analysis : invariant mass of lepton+@xmath2-tagged jet+neutrino , @xmath1 transverse mass , and so - called `` @xmath543 '' ( lepton charge times @xmath26 of the leading untagged jet ) .",
    "they are each shown for low discriminant output , high output , and very high output .",
    "the excess of data over a background - only model clearly increases as the discriminant cut is increased .",
    "the dt analysis has also measured the s- and t - channel cross sections separately .",
    "the cross sections are found to be : @xmath544 these measurements each assume the standard model value of the single top quark cross sections not being measured , since the s - channel measurement considers the t - channel process as a background and vice versa .",
    "we can remove the constraint of the standard model ratio and form the posterior probability density as a function of the @xmath19 and @xmath22 cross sections .",
    "this model - independent posterior is shown in fig .",
    "[ fig:2dpost ] for the dt analysis , using the @xmath19+@xmath22 discriminant .",
    "the most probable value corresponds to cross sections of @xmath545  pb and @xmath546  pb . also shown are the one , two , and three standard deviation contours . while this result favors a higher value for the @xmath312-channel contribution than the sm expectation , the difference is not statistically significant .",
    "several models of new physics that are also consistent with this result are shown in ref .",
    "@xcite .     and",
    "@xmath528 , when both cross sections are allowed to float in the fit of the @xmath547 dt analysis . shown",
    "are the contours of equal probability density corresponding to one , two , and three standard deviations and the location of the most probable value , together with the sm expectation.,scaledwidth=40.0% ]",
    "since each multivariate analysis uses the same dataset to measure the single top quark cross section , their results are highly correlated . however , because the correlation is rather less than 100% , one can still gain some additional sensitivity by combining the results .",
    "we combine the three cross section measurements , @xmath548 ( @xmath332  =  dt , bnn , me ) using the best linear unbiased estimate ( blue ) method  @xcite ; that is , we take as the new estimate of the cross section the weighted sum @xmath549 with @xmath550 , and with the weights chosen so as to minimize the variance @xmath551 where @xmath552 are the matrix elements of the covariance matrix of the measurements .",
    "the variance is minimized when @xmath553 where @xmath554 denotes the matrix elements of the inverse of the covariance matrix . in order to estimate the correlation matrix , each analysis",
    "is run on the same ensemble of pseudodatasets , specifically , the sm ensemble with systematics , which comprises 1,900 pseudodatasets common to all three analyses . to estimate the @xmath35-value of the combined result",
    ", the analyses are run on 72,000 pseudodatasets of the background - only ensemble .",
    "we use the sm ensemble with systematics to determine the weights @xmath328 and to check the coverage probability of the confidence intervals calculated as described in sec .",
    "[ bayesian - xsec ] .",
    "the cross section measurements from this ensemble are shown in fig .",
    "[ fig : com_fig1 ] for the individual and combined analyses .",
    "the mean and square root of the variance obtained from these distributions give the following results : @xmath555    the weights @xmath328 for the three analyses are found to be    @xmath556 = 0.127 ,    @xmath557 = 0.386 ,    @xmath558 = 0.488 .",
    "the correlation matrix is @xmath559 and the one - standard - deviation coverage probability of the ( bayesian ) confidence interval is 0.67 .",
    "the result from combining the dt , bnn , and dt measurements for the single top quark cross section is @xmath560 using the values listed at the beginning of sec .",
    "[ sec : measured - cross - sections ] . figure  [ fig : com_fig2 ] summarizes the measurements of the @xmath19+@xmath22 cross section from the individual analyses as well as the combination .",
    "having determined the combined result for the single top quark cross section , we can now determine the signal significance corresponding to this measurement .",
    "distributions of the results from all the analyses are shown in fig .",
    "[ fig : com_fig3 ] .",
    "the expected @xmath35-value ( and the associated significance in gaussian - like standard deviations ) is obtained by counting how many background - only pseudodatasets yield a measured cross section greater than the sm value of 2.86  pb . the result is @xmath561 or 2.3 standard deviations , as shown in table  [ com_tab2 ] .",
    "l||ccc + & expected & expected & expected + & cross section & @xmath35-value & significance + analysis & [ pb ] & & ( std . dev . ) + dt & 2.7 & 0.018 & 2.1 + bnn & 2.7 & 0.016 & 2.2 + me & 2.8 & 0.031 & 1.9 + combined  & 2.8 & 0.011 & 2.3    the observed @xmath35-value is similarly calculated by counting how many background - only pseudodatasets result in a cross section above the value of 4.7  pb measured from data .",
    "the result is @xmath4 or 3.6 standard deviations .",
    "the observed cross sections , @xmath35-values , and significances from all the analyses are summarized in table  [ com_tab3 ] .",
    "l||ccc + & measured & measured & measured + & cross section & @xmath35-value & significance + analysis & [ pb ] & & ( std . dev . ) + dt & 4.9 & 0.00037 & 3.4 + bnn & 4.4 & 0.00083 & 3.1 + me & 4.8 & 0.00082 & 3.2 + combined  & 4.7 & 0.00014 & 3.6    finally , using the sm ensemble with systematics , we quantify the compatibility of our result with the sm expectation by counting how many pseudodatasets result in a cross section with the observed value or higher for each of the analyses .",
    "the probabilities for the different analyses are @xmath251 for the dt analysis , @xmath562 for the me analysis , @xmath562 for the bnn analysis , and @xmath251 for the combined analysis .      in order to compare the expected performance of the three multivariate techniques , it is instructive to compute a power curve for each method using the two hypotheses @xmath535 = sm - signal+background and @xmath534 = background only .",
    "the power curve in fig .  [ powercurve ] is a plot of the probability to accept hypothesis @xmath535 , if it is true , versus the significance level , that is , the probability to reject hypothesis @xmath534 , if it is true .",
    "figure  [ powercurve ] shows that all three methods exhibit comparable performance .",
    "-value computed from the sm - signal+background ensemble versus the @xmath35-value from the background - only ensemble for reference cross sections varying monotonically from 010  pb . for a given significance , that is , the probability to reject the background - only hypothesis if true , the power is the probability to accept the signal+background hypothesis if it is true . for a given significance ,",
    "one wants the power to be a large as possible.,scaledwidth=45.0% ]",
    "within the sm with three generations of quarks , the charged - current interactions of the top quark are of the type @xmath564@xmath565 , and involve a @xmath1 boson and a down - type quark @xmath391 ( @xmath566 ) : @xmath567 where @xmath568 is one of the elements of the 3@xmath3353 unitary ckm matrix  @xcite , @xmath569 in the sm , and @xmath570 is the left - handed ( @xmath285 ) projection operator . under the assumption of three generations and a unitary ckm matrix , the @xmath568 elements are severely constrained  @xcite : @xmath571    in several extensions of the sm involving , for example , a fourth generation of quarks or an additional heavy quark singlet that mixes with the top quark , the 3@xmath3353 ckm matrix is no longer required to be unitary , and @xmath25 can be significantly smaller than unity  @xcite .",
    "this paper describes in detail the first direct measurement of @xmath25 , based on the single top quark production cross section measurement using decision trees  @xcite .",
    "the @xmath25 measurement is a relatively straightforward extension of the cross section measurement using the same dataset and analysis infrastructure , since the cross section for single top quark production is directly proportional to @xmath572 .",
    "this measurement of @xmath25 makes no assumptions on the number of generations or unitarity of the ckm matrix .",
    "however , some assumptions are made in the generation of our signal mc samples and the extraction of @xmath25 from the cross section measurement .",
    "in particular , we assume the following : ( i )  there are only sm sources of single top quark production ; ( ii )  top quarks decay to @xmath573 ; and ( iii )  the @xmath5 interaction is @xmath574-conserving and of @xmath564@xmath565 type .",
    "we discuss these assumptions in more detail here .",
    "first , we assume that the only production mechanism for single top quarks involves an interaction with a @xmath1  boson .",
    "therefore , extensions of the sm where single top quark events can be produced , for example , via flavor - changing neutral current interactions  @xcite or heavy scalar or vector boson exchange  @xcite , are not considered here .",
    "the second assumption is that @xmath575 are negligible compared to @xmath25 , without making any assumption on the magnitude of @xmath25 .",
    "this is reasonable given the measurements of @xmath576 by the cdf  @xcite and d0  @xcite collaborations , obtained by comparing the rates of @xmath577 events with zero , one and two @xmath2-tagged jets .",
    "for instance , d0 s measurement results in @xmath578 . the requirement that @xmath579 implies that @xmath580 and that single top quark production is completely dominated by the @xmath5 interaction .",
    "this assumption is made explicitly when measuring the combined @xmath19+@xmath22 cross section when assuming the sm ratio of @xmath581  @xcite , as well as in the generation of single top quark and @xmath144 simulated samples .",
    "finally , we assume that the @xmath5 vertex is charge - parity ( @xmath574 ) conserving and of the @xmath564@xmath565 type as given in eq .",
    "[ couplingsm ] , but it is allowed to have an anomalous strength @xmath7 .",
    "we do not allow for right - handed or tensor couplings that may occur in the most general @xmath5 vertex  @xcite .",
    "the simulated samples can still be used under the assumption of an anomalous @xmath7 coupling : the cross section and kinematics , as well as the @xmath19 and @xmath22 kinematics are completely unaffected .",
    "an anomalous value for @xmath7 would only rescale the single top quark cross section , allowing it to be larger or smaller than the sm prediction , even under the assumption of @xmath582 . therefore , strictly speaking , we are measuring the strength of the @xmath564@xmath565 coupling , i.e. , @xmath583 , which is allowed to be @xmath584 . limiting our measurement to the @xmath585 $ ] range",
    "implies the additional assumption that @xmath569 .",
    "this measurement uses exactly the same machinery as used to obtain the single top quark cross section posterior .",
    "following standard convention for parameters that multiply the cross section , we choose a prior that is nonnegative and flat in , which means it is flat in the cross section .",
    "however , in one of the two cases presented below , we restrict the prior to the sm allowed region [ 0,1 ] .      in order to extract from the measured cross section , additional theoretical uncertainties  @xcite need to be considered .",
    "these uncertainties are applied separately to the @xmath19 and @xmath22 samples in order to take the correlations into account properly .",
    "they are listed in table  [ tab : sys ] .",
    "the uncertainty on the top quark mass of 5.1  gev  @xcite is used when estimating the @xmath182 cross section uncertainty and the @xmath19 and @xmath22 cross section uncertainties .",
    "l|cc + & @xmath19 & @xmath22 + top quark mass & 8.5% & 13.0% + factorization scale & 4.0% & 5.5% + parton distributions  &",
    "4.5% & 10.0% + @xmath586 & 1.4% & 0.01%      the measurement for the ckm matrix element is obtained from the most probable value of , given by @xmath587 , and the uncertainty is computed as @xmath588 .",
    "we have used the decision tree result to derive a posterior for @xmath25 .",
    "the posterior without the prior restricted to be only nonnegative gives @xmath589 , which results in @xmath590 the posterior with the prior restricted to the [ 0,1 ] region gives @xmath591 , which results in @xmath592 the corresponding @xmath9 c.l .",
    "lower limit on is 0.46 , corresponding to a lower limit of @xmath593 the posterior densities for @xmath572 for each choice of prior are shown in fig .",
    "[ fig : vtb - posteriors ] .     for ( a ) a nonnegative flat prior , and ( b ) a flat prior restricted to the region [ 0,1 ] and assuming @xmath594 .",
    "the dashed lines show the positions of the one , two , and three standard deviation distances away from the peak of each curve.,title=\"fig:\",scaledwidth=35.0% ]   for ( a ) a nonnegative flat prior , and ( b ) a flat prior restricted to the region [ 0,1 ] and assuming @xmath594 .",
    "the dashed lines show the positions of the one , two , and three standard deviation distances away from the peak of each curve.,title=\"fig:\",scaledwidth=35.0% ]",
    "using approximately 0.9  fb@xmath0 of d0 data , we have performed an analysis of events with a single isolated lepton ( electron or muon ) , missing transverse energy , and 24 jets ( 1 or 2 of them @xmath2  tagged ) . using three different multivariate techniques , decision trees , bayesian neural networks , and matrix elements , we have searched for single top quark events from the s - channel ( @xmath19 ) and t - channel ( @xmath22 ) processes combined .",
    "we measure the cross section to be @xmath595 this corresponds to an excess of 3.6 gaussian - equivalent standard deviation significance and constitutes the first evidence of a single top quark signal .",
    "ensemble tests have shown this result to be compatible with the standard model cross section with @xmath251 probability .",
    "the decision tree cross section result has been used to extract the first direct measurement of the ckm matrix element @xmath25 .",
    "this result does not assume three - generation unitarity of the matrix .",
    "the model independent measurement is @xmath596 where @xmath7 is a generic left - handed vector coupling . if we constrain the value of @xmath25 to the standard model region ( i.e. , @xmath597 and @xmath569 ) , then at @xmath9 c.l .",
    ", @xmath25 has been measured to be @xmath598    we thank the staffs at fermilab and collaborating institutions , and acknowledge support from the doe and nsf ( usa ) ; cea and cnrs / in2p3 ( france ) ; fasi , rosatom and rfbr ( russia ) ; cnpq , faperj , fapesp and fundunesp ( brazil ) ; dae and dst ( india ) ; colciencias ( colombia ) ; conacyt ( mexico ) ; krf and kosef ( korea ) ; conicet and ubacyt ( argentina ) ; fom ( the netherlands ) ; stfc ( united kingdom ) ; msmt and gacr ( czech republic ) ; crc program , cfi , nserc and westgrid project ( canada ) ; bmbf and dfg ( germany ) ; sfi ( ireland ) ; the swedish research council ( sweden ) ; cas and cnsf ( china ) ; and the alexander von humboldt foundation .",
    "visitor from augustana college , sioux falls , sd , usa . visitor from the university of liverpool , liverpool , uk .",
    "visitor from icn - unam , mexico city , mexico . visitor from ii .",
    "institut , georg - august - university , gttingen , germany . also at triumf , vancouver , b.c .",
    "visitor from helsinki institute of physics , helsinki , finland .",
    "visitor from universitt zrich , zrich , switzerland .",
    "f.  abe _ et al . _",
    "( cdf collaboration ) , phys .",
    "lett .  * 74 * , 2626 ( 1995 ) .",
    "s.  abachi _ et al . _",
    "( d0 collaboration ) , phys .",
    "lett .  * 74 * , 2632 ( 1995 ) .",
    "n.  kidonakis and r.  vogt , phys .",
    "d  * 68 * , 114014 ( 2003 ) .",
    "the most recent world - average measurement of the top quark mass is @xmath599 , ( hep - ex/0703034 ) , but at the time this analysis was started , the value was @xmath600  gev , ( hep - ex/0507006 ) , and we rounded this to 175  gev when choosing a mass to use in the analysis .",
    "s.  cortese and r.  petronzio , phys .",
    "b * 253 * , 494 ( 1991 ) .",
    "t.  stelzer and s.  willenbrock , phys .",
    "b * 357 * , 125 ( 1995 ) .",
    "heinson , a.s .",
    "belyaev , and e.e .",
    "boos , phys .",
    "d  * 56 * , 3114 ( 1997 ) .",
    "z.  sullivan , phys .",
    "d * 70 * , 114012 ( 2004 ) .",
    "willenbrock and d.a .",
    "dicus , phys .",
    "d * 34 * , 155 ( 1986 ) .",
    "yuan , phys .  rev .",
    "d * 41 * , 42 ( 1990 ) .",
    "ellis and s.j .",
    "parke , phys .",
    "d * 46 * , 3785 ( 1992 ) .",
    "tait , phys .",
    "d * 61 * , 034001 ( 1999 ) .",
    "carlson , e.  malkawi , and c .- p .",
    "yuan , phys .",
    "b * 337 * , 145 ( 1994 ) .",
    "e.  malkawi and c .- p.yuan , phys .",
    "d * 50 * , 4462 ( 1994 ) .",
    "n.  cabibbo , phys .",
    "* 10 * , 531 ( 1963 ) .",
    "m.  kobayashi and k.  maskawa , prog .",
    "49 * , 652 ( 1973 ) .",
    "jikia and s.r .",
    "slabospitsky , phys .",
    "b * 295 * , 136 ( 1992 ) .",
    "t.  stelzer , z.  sullivan , and s.  willenbrock , phys .",
    "d * 58 * , 094021 ( 1998 ) .",
    "j.  alwall , r.  frederix , j .-",
    "grard , a.  giammanco , m.  herquet , s.  kalinin , e.  kou , v.  lematre , and f.  maltoni , eur .",
    "j.   c * 49 * , 791 ( 2007 ) .",
    "b.  abbott _ et al . _",
    "( d0 collaboration ) , phys .",
    "d  * 63 * , 031101 ( 2000 ) .",
    "abazov _ et al . _",
    "( d0 collaboration ) , phys .",
    "b * 517 * , 282 ( 2001 ) .",
    "abazov _ et al . _",
    "( d0 collaboration ) , phys .",
    "b * 622 * , 265 ( 2005 ) .",
    "abazov _ et al . _",
    "( d0 collaboration ) , phys .",
    "d * 75 * , 092007 ( 2007 ) .",
    "dissertations on single top quark physics : + j.  mcdonald , florida state university , may 1999 ; + l.  dudko , moscow state university , september 2001 ; + e.  busato , university of paris vi , april 2005 ; + m.  agelou , university of paris vi , may 2005 ; + s.  jabeen , university of kansas , january 2006 ; + b.  clment , ires de strasbourg , april 2006 ; + p.  perea , university of california , riverside , june 2006 ; + t.  gadfort , university of washington , april 2007 ; + j.  mitrevski , columbia university , july 2007 , + d.  kau , florida state university , august 2007 .    v.m .",
    "abazov _ et al . _",
    "( d0 collaboration ) , phys .",
    "* 98 * , 181802 ( 2007 ) .",
    "d.  acosta _ et al .",
    "_ ( cdf collaboration ) , phys .  rev .",
    "d  * 65 * , 091102 ( 2002 ) .",
    "d.  acosta _ et al .",
    "_ ( cdf collaboration ) , phys .  rev .",
    "d  * 69 * , 053003 ( 2004 ) .",
    "d.  acosta _ et al .",
    "_ ( cdf collaboration ) , phys .  rev .",
    "d  * 71 * , 012005 ( 2005 ) .",
    ". dissertations on single top quark physics : + t.  kikuchi , tsukuba university , march 2000 ; + s.  wolinski , university of michigan , 2002 ; + c.  ciobanu , ohio state university , august 2002 ; + b.  stelzer , university of toronto , may 2005 ; + t.  walter , university of karlsruhe , june 2005 ; + y.  kemp , university of karlsruhe , february 2006 ; + s.  richter , university of karlsruhe ,",
    "november 2007 .",
    "pseudorapidity is defined as @xmath601 $ ] , where @xmath602 is the polar angle with the origin at the primary vertex .",
    "the detector pseudorapidity , or @xmath136 , measures @xmath602 as the polar angle with origin at the center of the detector .",
    "boos , v.e .",
    "bunichev , l.v .",
    "dudko , v.i .",
    "savrin , and v.v .",
    "sherstnev , phys .",
    "nucl .  * 69 * , 1317 ( 2006 ) .",
    "e.  boos , v.  bunichev , m.  dubinin , l.  dudko , v.  ilyin , a.  kryukov , v  edneral , v.  savrin , a.  semenov , and a.  sherstnev ( comphep collaboration ) , nucl .",
    "instrum .",
    "methods phys .",
    "a * 534 * , 250 ( 2004 ) .",
    "mangano , f.  piccinini , a.d .",
    "polosa , m.  moretti , and r.  pittau , j.  high energy phys .",
    "07 ( 2003 ) 001 .",
    "we used version  2.05 .",
    "s.  hche , f.  krauss , n.  lavesson , l.  lnnblad , m.  mangano , a.  schlicke , and s.  schumann , in _ proceedings of the workshop on the implications of hera for lhc physics _ edited by a.  de  roeck and h.  jung ( desy , hamburg , 2005 ) , p.  288 .",
    "mangano , m.  moretti , f.  piccinini , and m.  treccani , j.  high energy phys .",
    "01 ( 2007 ) 013 .",
    "t.  sjstrand , l.  lnnblad , s.  mrenna , and p.  skands , hep - ph/0308153 .",
    "we used version  6.323 .",
    "abazov _ et al . _",
    "( d0 collaboration ) , nucl .",
    "instrum .",
    "methods phys .",
    "res . , sect .",
    "a * 565 * , 463 ( 2006 ) .",
    "r.  frhwirth , w.  waltenberger , and p.  vanlaer , cern - cms - note-2007 - 008 .",
    "jets are defined using the iterative seed - based cone algorithm with radius @xmath603 , including midpoints as described on pp .",
    "4777 in g.c .",
    "blazey _ et al .",
    "_ , in _ proceedings of the workshop on qcd and weak boson physics in run ii _ , edited by u.  baur , r.k .",
    "ellis , and d.  zeppenfeld , fermilab - pub-00 - 297 ( 2000 ) .",
    "t.  scanlon , ph.d .",
    "thesis , imperial college , university of london , october 2006 .",
    "s.  greder , ph.d .",
    "thesis , universit louis pasteur , strasbourg , october 2004 .",
    "j.  pumplin _ et al .",
    "_ , j.  high energy phys .  07 ( 2002 ) 012 .",
    "we used version cteq6l1 .",
    "e.  boos , l.  dudko , and t.  ohl , eur .",
    "j.   c * 11 * , 473 ( 1999 ) .",
    "s.  jadach _ et al .",
    "_ , comput .",
    "commun .  * 76 * , 361 ( 1993 ) .",
    "we used version  2.5 .",
    "lange , nucl .",
    "instrum .",
    "methods phys .",
    "res . , sect .",
    "a * 462 * , 152 ( 2001 ) .",
    "we used version 00.00.17 .",
    "ellis and s.  veseli , phys .",
    "d * 60 * , 011501 ( 1999 ) .",
    "f.  febres cordero , l.  reina , and d.  wackeroth , phys .",
    "d * 74 * , 034007 ( 2006 ) .",
    "j.  campbell , r.  k.  ellis , f.  maltoni , and s.  willenbrock , phys .",
    "d * 75 * , 054015 ( 2007 ) .",
    "r.  brun and f.  carminati , cern program library long writeup , report no .",
    "w5013 , 1994 .",
    "abazov _ et al . _",
    "( d0 collaboration ) , phys .",
    "d * 74 * , 112004 ( 2006 ) .",
    "t.  andeen , b.c.k .",
    "casey , k.  devaughan , y.  enari , e.  gallas , d.  krop , r.  partridge , h.  schellman , g.r .",
    "snow , s.  yacoob , and h.d .",
    "yoo , fermi national accelerator laboratory technical memorandum no .",
    "2365 , ( 2007 ) .",
    "g.  corcella , i.g .",
    "knowles , g.  marchesini , s.  moretti , k.  odagiri , p.  richardson , m.h .",
    "seymour , and b.r .",
    "webber , arxiv : hep - ph/0210213 , revised october 2005 .",
    "r.  barlow , j.  comp .",
    "phys .  * 72 * , 202 ( 1987 ) .",
    "l.  dudko , aip conf .",
    "proc .  * 583 * , 83 ( 2001 ) .",
    "e.  boos and l.  dudko , nucl .",
    "instrum .",
    "methods phys .",
    "res . , sect .",
    "a * 502 * , 486 ( 2003 ) .",
    "v.d .  barger and r.j.n .",
    "phillips , _ collider physics _",
    "( addison - wesley , reading , ma , 1987 ) .      d.  bowser - chao and d.l .",
    "dzialo , phys .",
    "d * 47 * , 1900 ( 1993 ) . c.  gini , _ variabilit e mutabilit _ ( 1912 ) , reprinted in _ memorie di metodologica statistica _ , edited by e.  pizetti and t.  salvemini , rome : libreria eredi virgilio veschi ( 1955 ) .",
    "roe , h .- j .",
    "yang , j.  zhu , y.  liu , i.  stancu , and g.  mcgregor , nucl .",
    "instrum .",
    "methods phys .",
    "res . , sect .",
    "a * 543 * , 577 ( 2005 ) .",
    "yang , b.p .",
    "roe , and j.  zhu , nucl .",
    "instrum .",
    "methods phys .",
    "res . , sect .",
    "a * 555 * , 370 ( 2005 ) . q .-",
    "cao , r.  schwienhorst , and c .-",
    "p  yuan , phys .",
    "d * 71 * , 054023 ( 2005 ) . q .- h .  cao , r.  schwienhorst , j.a .",
    "benitez , r.  brock , and c .-",
    "p  yuan , phys .",
    "d * 72 * , 094027 ( 2005 ) .",
    "g.  mahlon and s.j .",
    "parke , phys .",
    "d * 55 * , 7249 ( 1997 ) .",
    "bishop , _ neural networks for pattern recognition _",
    "( clarendon press , oxford , 1998 ) .",
    "s.  duane , a.d .",
    "kennedy , b.j .",
    "pendleton , and d.   roweth , phys .",
    "b * 195 * , 216 ( 1987 ) .",
    "berg , _ markov chain monte carlo simulations and their statistical analysis _ ( world scientific , singapore , 2004 ) .",
    "friedman , in _ statistical problems in particle physics , astrophysics and cosmology _ , edited by l.  lyons and m.  k.  nel ( imperial college press , london , england , 2006 ) , p.  127",
    ", http://www-stat.stanford.edu/~jhf/r-rulefit.html .",
    "abazov _ et al . _",
    "( d0 collaboration ) , nature * 429 * , 638 ( 2004 ) . v.m .",
    "abazov _ et al . _",
    "( d0 collaboration ) , phys .",
    "d * 74 * , 092005 ( 2006 ) .",
    "a.  abulencia _ et al .",
    "_ ( cdf collaboration ) , phys .",
    "lett . * 96 * , 152002 ( 2006 ) .",
    "a.  abulencia _ et al .",
    "_ ( cdf collaboration ) , phys .  rev .",
    "d * 74 * , 032009 ( 2006 ) .",
    "a.  abulencia _ et al .",
    "_ ( cdf collaboration ) , phys .  rev .",
    "d * 75 * , 031105(r ) ( 2007 ) .",
    "abazov _ et al . _",
    "( d0 collaboration ) , phys .",
    "b * 617 * , 1 ( 2005 ) .",
    "whalley , d.  bourikov , and r.c .",
    "group , in _ proceedings of hera and the lhc , a workshop on the implications of hera for lhc physics _ , edited by a.  de  roeck and h.  jung ( desy , hamburg , 2005 ) , p.  575",
    ", http://hepforge.cedar.ac.uk/lhapdf .",
    "lepage , j.  comput .",
    "* 27 * , 192 ( 1978 ) .",
    "m.  galassi , j.  davies , j.  theiler , b.  gough , g.  jungman , m.  booth , and f.  rossi , _ gnu scientific library reference manual  revised second edition _",
    "( network theory limited , bristol , 2006 ) , http://www.gnu.org / software / gsl/.          t.  tait and c.p .",
    "yuan , phys .",
    "d * 63 * , 014018 ( 2000 ) .",
    "l.  lyons , d.  gibaut , and p.  clifford , nucl .",
    "instrum .",
    "methods phys .",
    "res . , sect .",
    "a * 270 * , 110 ( 1988 ) .",
    "barlow , _ statistics : a guide to the use of statistical methods in the physical sciences _",
    "( the manchester physics series , john wiley and sons , new york , 1989 ) .",
    "yao _ et al .",
    "_ ( particle data group ) , j.  phys .",
    "g * 33 * , 1 ( 2006 ) .",
    "abazov _ et al . _",
    "( d0 collaboration ) , phys .",
    "lett .  * 99 * , 191802 ( 2007 ) .",
    "abazov _ et al . _",
    "( d0 collaboration ) , phys .",
    "b * 641 * , 423 ( 2006 ) .",
    "d.  acosta _ et al .",
    "_ ( cdf collaboration ) , phys .  rev .",
    "lett .  * 95 * , 102002 ( 2005 ) .",
    "abazov _ et al . _",
    "( d0 collaboration ) , phys .",
    "b * 639 * , 616 ( 2006 ) .",
    "kane , g.a .",
    "ladinsky , and c .- p .",
    "yuan , phys .",
    "d * 45 * , 124 ( 1992 ) .",
    "k.  whisnant , j.m .",
    "yang , b .-",
    "young , and x.  zhang , phys .  rev .",
    "d * 56 * , 467 ( 1997 ) ."
  ],
  "abstract_text": [
    "<S> we present first evidence for the production of single top quarks in the d0 detector at the fermilab tevatron collider . </S>",
    "<S> the standard model predicts that the electroweak interaction can produce a top quark together with an antibottom quark or light quark , without the antiparticle top quark partner that is always produced from strong coupling processes . </S>",
    "<S> top quarks were first observed in pair production in 1995 , and since then , single top quark production has been searched for in ever larger datasets . in this analysis </S>",
    "<S> , we select events from a 0.9  fb@xmath0 dataset that have an electron or muon and missing transverse energy from the decay of a @xmath1  boson from the top quark decay , and two , three , or four jets , with one or two of the jets identified as originating from a @xmath2  hadron decay . </S>",
    "<S> the selected events are mostly backgrounds such as @xmath1+jets and events , which we separate from the expected signals using three multivariate analysis techniques : boosted decision trees , bayesian neural networks , and matrix element calculations . a binned likelihood fit of the signal cross section plus background to the data from the combination of the results from the three analysis methods gives a cross section for single top quark production of @xmath3  pb . </S>",
    "<S> the probability to measure a cross section at this value or higher in the absence of signal is @xmath4 , corresponding to a 3.6  standard deviation significance . </S>",
    "<S> the measured cross section value is compatible at the 10% level with the standard model prediction for electroweak top quark production . </S>",
    "<S> we use the cross section measurement to directly determine the cabibbo - kobayashi - maskawa quark mixing matrix element that describes the @xmath5 coupling and find @xmath6 , where @xmath7 is a generic vector coupling . </S>",
    "<S> this model - independent measurement translates into @xmath8 at the @xmath9  c.l . in the standard model </S>"
  ]
}