{
  "article_text": [
    "recently , there has been a dramatic increase in extra - galactic observational data through , e.g. , the hubble and cobe satellites , and very large ground based telescopes .",
    "these detailed observations have put new demands on theoretical models of galaxy formation .",
    "gas dynamics with proper energy dissipation is of fundamental importance in galaxy formation .",
    "analytic models of gas dynamics are typically restricted to systems possessing a high degree of symmetry .",
    "hierarchical galaxy formation , on the other hand , is a highly inhomogeneous process . in order to follow the three - dimensional evolution of the baryonic component in a proto - galaxy",
    ", numerical techniques are required .",
    "smooth particle hydrodynamics ( sph ) is a fully lagrangian numerical method for gas dynamics .",
    "sph was introduced by lucy ( @xcite ) and gingold & monaghan ( @xcite ) to avoid the limitations of grid - based methods . when coupled with a fast algorithm to calculate gravitational forces ,",
    "this method has been used successfully to study hierarchical galaxy formation ( evrard @xcite , hernquist & katz @xcite , navarro & white @xcite ) .    in this paper",
    "we present an sph implementation , coupled with a gravitational tree method , that has been specifically developed to study the formation of galaxies .",
    "the code is applied to several test cases to clarify the advantages and limitations of the implementation .",
    "the code used for the simulations described in this paper is fully lagrangian , does not put restrictions on the geometry of the problem , and has a locally varying resolution both in space and time .    simulating the formation of galaxies in a hierarchical model",
    "is a demanding task for any numerical method .",
    "small objects form first , and the characteristic mass of objects then grows rapidly with time , as smaller objects merge into larger ones . at any given time",
    "there is a wide range of object masses , and the code must be able to handle many different scales simultaneously .",
    "when galaxies merge , part of the gas falls to the center of the new galaxy .",
    "this gas concentration effect is especially pronounced in simulations without star formation , where the baryonic mass remains gaseous throughout the simulation .",
    "the gas cores that collect at the center of dark matter halos are typically to small to be gravitationally resolved , but can still be the cause of much of the calculational cost .",
    "we avoid this problem by merging particles in unresolved gas cores , thereby limiting the hydrodynamical resolution to the gravitational resolution , and furthermore speeding up the calculations significantly .",
    "the central concept in sph is the introduction of the interpolation procedure .",
    "this is a procedure to define a continuous , differentiable function , given values at discrete points in space .",
    "we shall only outline the procedure , since the method has been presented many times elsewhere ( hernquist & katz @xcite , benz @xcite and monaghan @xcite ) .    a common way to smooth a continuous field is to convolve it with a suitable kernel @xmath0 , @xmath1 the integration being over all space .",
    "the kernel , or window function , @xmath2 goes to zero for large values of @xmath3 .",
    "the parameter @xmath4 thus specifies the width of the smoothing window .",
    "furthermore , to preserve the overall normalization of the field that is smoothed , and to ensure that @xmath5 , the kernel must satisfy @xmath6    in sph , particles are assigned local values of thermodynamic quantities , and corresponding continuous fields are defined by convolution of particle properties with a suitable kernel . the volume integration in eq . ( [ kernel - smooth ] ) then turns into a sum over all particles @xmath7 where n is the total number of particles , @xmath8 , @xmath9 , @xmath10 , @xmath11 are the position , mass , smoothing length , and density , respectively associated with particle @xmath12 .",
    "the factor @xmath13 is the volume element that sph associates with particle @xmath12 .",
    "much of the usefulness of sph derives from the ease with which gradients of fields can be calculated . ignoring surface terms , a direct differentiation of eq .",
    "( [ mc - formula ] ) yields @xmath14 we see that once the gradient of the chosen kernel has been calculated , calculations of field gradients proceed similarly to the calculation of field values .",
    "it is especially worth noting , that the sets of particles that contribute to the sph sums in eq .",
    "( [ mc - formula ] ) and ( [ mc - gradient ] ) are identical .",
    "as is common , we use the spline kernel , that was first proposed by monaghan & lattanzio ( @xcite ) , @xmath15 where @xmath16 and @xmath17 is @xmath18 in the three dimensional case .",
    "the time evolution of the fluid is determined by the usual set of hydrodynamic equations .",
    "expressed in lagrangian form , the sph expression for the momentum equation has the form @xmath19 where @xmath20 is the velocity field and @xmath21 is the gravitational potential .",
    "@xmath22 is the kernel used for the interaction between particle @xmath23 and @xmath12 , and @xmath24 is an artificial viscosity pressure term , needed to handle shocks in sph , described in detail later . for work with galaxy formation , the gas is usually assumed to be ideal .",
    "the pressure can then be expressed in terms of the density , and the specific internal energy @xmath25 , @xmath26 where @xmath27 is the specific heat ratio , being @xmath28 for a mono - atomic gas , and the density is obtained through @xmath29 the energy equation can be written as    @xmath30    where @xmath31 and @xmath32 are non - adiabatic heating and cooling terms , respectively .    in order to get fully symmetric inter - particle forces , the kernel term @xmath22 , must be symmetric .",
    "we have chosen to symmetrize in the smoothing lengths , so that @xmath33 , where @xmath34 and @xmath35 .    in sph shocks are handled by introducing artificial viscosity to smear out discontinuities to resolvable scales .",
    "we use the artificial viscosity introduced by monaghan & gingold ( @xcite ) and monaghan & varnas ( @xcite ) . the viscosity term in eq .",
    "( [ sph - pressure ] ) is given by @xmath36 where @xmath37 , and @xmath38 is the average speed of sound of particles @xmath23 and @xmath12 .",
    "@xmath39 is given by @xmath40 where @xmath41 , @xmath35 , and @xmath42 is a constant that prevents singularities for small particle separations .",
    "typically , @xmath43 , and @xmath44 and @xmath45 are set to values close to unity .",
    "there is a disadvantage with this type of artificial viscosity , in that it introduces shear viscosity into the flow , in addition to the ( desired ) bulk viscosity effects .",
    "we correct for this as shown in navarro & steinmetz ( @xcite ) .",
    "all simulations in this paper uses this correction , except the collapse test , sect .",
    "[ collapse ] , where essentially no shear flow is present .",
    "the smoothing length for a particle @xmath23 is set by requiring that the number of particle neighbors , within a distance of @xmath46 , are roughly equal to a constant number , @xmath47 .",
    "the smoothing length of a particle is adjusted at each time - step according to this criterion . to fulfill this ,",
    "the smoothing length is updated at the beginning of each time - step according to @xmath48,\\ ] ] where @xmath49 , @xmath50 , and @xmath51 are the previous and present values of the smoothing length and the previous number of neighbors respectively . the number of neighbors is then calculated using the predicted value of the smoothing length , and if found to deviate from @xmath47 by more than @xmath52 , the above formula is reiterated .",
    "we chose @xmath53 and @xmath54 .",
    "we do not ( yet ) include the , so called , @xmath55 terms , which have been closely examined by nelson & papaloizou ( @xcite ) and serna et al .",
    "( @xcite ) , due to the relative complexity of these terms .",
    "we have chosen the hierarchical tree approach when calculating gravitational accelerations .",
    "it is a common choice together with sph , because , like sph , it uses no grid and shares a similar kind of flexibility .",
    "moreover , the gravitational force calculation can then be efficiently combined with the sph calculations .",
    "we use the barnes - hut algorithm ( barnes & hut @xcite , hernquist @xcite , and hernquist & katz @xcite ) , which uses an octal tree to represent a hierarchical subdivision of space into cubes .",
    "we have introduced a small modification in the tree construction , in that cells are recursively subdivided until the sub - cells contain eight or less particles .",
    "( the standard barnes - hut algorithm continues subdividing space until a cube contains one or zero particles . )",
    "this modification significantly reduces the number of cells in the tree , and has the additional advantage that particles can be placed on top of each other .",
    "the latter is sometimes useful when setting up initial conditions for simulations that involve both a gas and a dark matter component .",
    "when computing the acceleration or potential of a particle , we use the standard barnes - hut criteria .",
    "the tree is traversed , root cell first , level by level , and a cell is accepted as a force term if @xmath56 , where @xmath57 is the size of the cell and @xmath58 is the distance to the center of mass of the cell .",
    "@xmath59 is usually in the range @xmath60 .",
    "rejected cells are sub - divided further .",
    "we avoid self - forces by rejecting cells that the particle itself resides in .",
    "( salmon & warren @xcite ) .",
    "quadrupole moments are optionally included .    the tree construction , as well as the traversal is fully vectorized .",
    "the `` breath - first '' approach was preferred over the `` depth - first '' method , because it leads to better vectorization with individual particle time - steps ( makino @xcite ) .",
    "the gravitational softening is implemented with kernel softening ( gingold & monaghan @xcite and hernquist & katz @xcite ) , where the force between two particles is calculated by considering one particle to have a radial density distribution given by the same spline kernel as for the sph interactions , eq .",
    "( [ b - spline ] ) .",
    "gravitational softening parameters @xmath61 can be specified for each particle .",
    "typically , the softening will be different for the dark matter component and the gas component , and sometime regions with different resolution are used .",
    "the softening is chosen so as to keep two - body relaxation at reasonable levels .",
    "typically , we calculate the two - body relaxation time - scale ( binney & tremaine @xcite ) for gravitationally bound objects as @xmath62 where @xmath63 , @xmath64 and @xmath65 are , respectively , the total number of particles , radius and mean velocity , for the object under consideration .",
    "@xmath66 , is known as the _ coulomb logarithm_. we use impact parameters , @xmath67 , according to smith ( @xcite ) .",
    "@xmath68 , the minimum softening parameter in the object .",
    "the need to symmetrize pairwise forces occurs also here , and for particle - particle interactions we symmetrize the softening lengths , @xmath69 , in the same way as the sph smoothing lengths .",
    "the particle - cell interactions are not straight - forward to symmetrize in a hierarchical tree method , and we do not do this .    instead of starting from scratch ,",
    "we begin the neighbor search where the tree traversal for the gravitational force stops , making the calculations more efficient .",
    "the gravity - neighbor calculations typically constitutes over 60% of the computing time .",
    "the gravity - neighbor package is calculating for one particle at a time , and can therefore be executed in parallel .",
    "it was straight forward to implement this on shared memory ( smp ) architectures , like the cray y - mp .",
    "generally this reduces calculation times by a factor of two .",
    "we use the second order runge - kutta ( rk ) integrator , with individual time - steps , described by navarro and white ( navarro & white @xcite ) .",
    "the main reason for this choice is that it allows the time integration errors to be estimated , and thereby gives good control over particle time - steps .",
    "there is no need to directly incorporate any stability criteria , e.g. , the courant condition .",
    "the system is always advanced with the smallest time - step , and a subroutine keeps track of which time - levels of particles are at either the beginning of a time - step , or at the middle of a time - step , and need to have derivatives of dynamical variables calculated .",
    "a linked list structure is used for the bookkeeping of the particles different time levels . the overhead caused by this book - keeping constitutes less than 1% of the computing time for a typical simulation .",
    "we use an implicit scheme for the integration of the energy equation , similar to hernquist & katz ( @xcite ) and anzer et al .",
    "( @xcite ) . a trapezoidal formula @xmath70 is solved iteratively , together with eq . ( [ sph - energy ] ) , at each individual time - step @xmath71 . a combined newton - raphson and bisection scheme , as described in press et al . ( @xcite ) ,",
    "is used to find the root of the energy equation ( [ trapez ] ) . in absence of cooling and heating terms ,",
    "( [ sph - energy ] ) is linear in @xmath72 , and eq .",
    "( [ trapez ] ) is solved in one iteration cycle .",
    "when strong radiative cooling is present , the integration tolerance criterion on the internal energy equation would become very prohibitive , regardless of what type of criterion is used , ( courant e.t.c . ) .",
    "physically , this occurs when the cooling time - scale becomes much shorter than the local dynamical time - scale @xmath73 it would be extremely expensive in terms of computing time to integrate the system at the time - step imposed by the cooling time - scale .",
    "moreover , for the purpose of tracking the dynamical evolution of the system , it is not necessary to let the time - step become much shorter than the local dynamical time - scale .",
    "therefore , the accuracy constraint on the energy equation is not allowed to limit the time - step below @xmath74 .",
    "although the implicit scheme is unconditionally stable , there will still be errors in the time integration .",
    "we have found that a damping of the cooling terms , similar to katz & gunn ( @xcite ) , improves the accuracy of the time integration , without affecting the dynamical evolution .",
    "a particle is not allowed to lose more than half its internal energy during one time - step , by cooling .",
    "we use a sharp cutoff on the cooling part of the derivative .",
    "this has the effect of broadening the fast time variation into a resolved exponential decay over a few time - steps .",
    "the reason why this works is that it occurs only in regions where the cooling time - scale is much shorter than the dynamical time - scale .",
    "the energy that is not radiated away in one time - step , will be radiated away in the following few , while the other variables , like density and velocity , can be considered to be roughly constant .",
    "typical radiative cooling functions often have multiple peaks .",
    "we have noted this may cause multiple roots in the solution of the energy equation . of course , only one root is correct , i.e. , the one closest to the root at the previous time - step .",
    "we solve this problem by finding all roots and accepting only the closest one .",
    "this may seem both computationally costly ( and mathematically impossible , but the cooling functions used , are tabulated at a finite number of points . typically , 128 - 256 , and therefore these calculations take insignificant computational time .",
    "our code was written with simulations of hierarchical galaxy formation in mind .",
    "a typical feature of such simulations is extreme clumping of matter .",
    "the gas collapses into very dense gravitationally bound objects , where cooling time scales are much less than the local dynamical time - scale .",
    "some of these objects contain very little angular momentum , and the gas therefore continues to contract until the contraction is artificially halted by the finite numerical force resolution .",
    "this clumping leads to two problems .",
    "first , the suppression of gas contraction on unresolved scales is completely artificial , and also puts a limit on the gravitational binding energy .",
    "this makes it easier for gas to be ejected from bound objects during violent mergers , and could lead to an underestimate of the fraction of matter that has collapsed to galactic densities at a given time .",
    "second , this is a challenge for sph because accurate time integration of the gas in extreme high density regions requires large amounts of computational work .",
    "we have chosen to set the sph smoothing lengths by requiring a roughly constant number of interacting neighbors .",
    "this leads to very small smoothing lengths in regions with extremely high density . to maintain stability",
    ", it is therefore necessary to use very small time - steps in these regions .",
    "we have found that the computational cost for evolving gas in gravitationally unresolved cores of compact objects can dominate the total run - time .",
    "this is a very undesirable situation .",
    "the problems with small time - steps in unresolved regions can be somewhat alleviated , by requiring that the sph smoothing always be larger than the gravitational smoothing .",
    "this limits the maximum gas resolution to roughly the gravitational force resolution .",
    "however , the problem then occurs in the sph force evaluations instead . setting a lower limit on the sph smoothing in high density regions leads to large numbers of interacting neighbors .",
    "this makes the force evaluations very expensive , due both to the large amounts of terms in the sph loops and the cost of finding the sph neighbors .",
    "the code deteriorates towards an inefficient implementation of direct summation . limiting",
    "the hydrodynamical resolution in this way actually slows the code down .",
    "the reason that the run - time can increase when the resolution is decreased , by setting a lower limit on the sph smoothing length , is that the accuracy of the sph force calculations increases .",
    "a lower limit on the sph smoothing length leads to large numbers of hydrodynamically interacting neighbors in unresolved regions , and therefore reduced sampling errors in the sph force calculations .",
    "an alternative would be to only use a random subset of the interacting neighbors in the sph calculations .",
    "this is consistent with the sph formalism , but it introduces an extra source of noise in forces",
    ". it would also be ineffective to first find all neighbors of a particle , and then discard most of them only to use a small subset in the actual force evaluation .",
    "a tree search can be implemented to find a pseudo - random subset of a particles neighbors , one by one , by using a depth - first search .",
    "this would make it unnecessary to find large numbers of neighbors .",
    "it looks non - trivial to vectorize such a scheme , and we have found that large subsets have to be used for good accuracy .",
    "we avoid all these problems by not imposing any lower limit on @xmath4 , thus ensuring efficient force evaluations , and by instead merging particles in high density regions , thus avoiding small time - steps and further speeding up the simulation by reducing the number of particles .",
    "this has previously been tried with success by monaghan & varnas ( @xcite ) for simulations of cloud collapse , and by steinmetz ( @xcite ) for galaxy formation problems .",
    "merging of particles in high density regions can keep the hydrodynamical resolution from exceeding the gravitational resolution , without slowing down the force evaluations , thus greatly speeding up simulations without sacrificing accuracy .",
    "the first step is to identify high density regions that are severely affected by gravitational smoothing . in these regions",
    "it is pointless to calculate substructure on scales smaller than the gravitational smoothing length .",
    "we therefore merge particles in these regions into more massive , and fewer , particles .",
    "the dynamics on these small , unresolved , scales can not be followed in our code , with or without merging of particles .",
    "the dynamical effects of particle merging should be small outside the regions where merging occurs . to satisfy this requirement all global dynamical quantities",
    "must be left unchanged by the merging process .",
    "thus , when merging two particles into one , global quantities like mass , kinetic energy , internal energy , potential energy and angular momentum must be preserved .    to make sure that global dynamical quantities are accurately conserved",
    ", the following five conditions have to be met before two particles are allowed to merge .",
    "( @xmath75 , @xmath76 , etc .",
    "are tolerance parameters .",
    "the quantities @xmath77 , @xmath78 , @xmath79 , @xmath61 and @xmath80 are the mass , local gas density , velocity , gravitational softening length and gravitational potential of particle @xmath23 .",
    "a `` cm '' subscript indicates a quantity that is evaluated in the center of mass of the two merging particles .",
    "@xmath81 is the relative position of the two merging particles . )",
    "\\i ) the two particles are in a region where gravitational forces are severely affected by limited force resolution .",
    "@xmath82 where @xmath83 which is the density that would be calculated for particle @xmath23 if all particles were evenly distributed within radius @xmath84 , and they all had mass @xmath77 . in regions where the density is much higher than @xmath85",
    ", the mean inter - particle distance will be much less than @xmath86 , and gravitational forces will be affected by the limited resolution . using @xmath87 , instead of summing up the mass of all neighbors , makes the density criterion stricter for more massive particles , in regions with particles of varying masses .",
    "this evens out spatial particle mass fluctuations , by letting less massive particles merge before more massive ones .",
    "\\ii ) the two particles are sph neighbors and within one smoothing length of each other .",
    "the particles should be close together to minimize the artificial displacement of gas properties that occurs when two particles are merged .",
    "\\iii ) the resultant particle mass of the merger is below the preset limit @xmath88 where @xmath89 is the gas particle mass before any merging has taken place .",
    "this is a limit on the amount of merging that can occur in a simulation , and can be useful as a guarantee that the gas resolution does not fall below a preset limit .",
    "\\iv ) the angular momentum lost is small .",
    "@xmath90 where @xmath91 is a relevant angular momentum scale for the problem at hand , which in all cases discussed here is equal to the total angular momentum of the system .",
    "\\v ) the kinetic energy lost is small compared to the gravitational potential energy , @xmath92",
    "\\vi ) the particles are synchronized in time and have just completed a full time - step .",
    "this is necessary to avoid breaking the time integration scheme .",
    "these criteria are ordered so that the least computationally expensive ones are checked first .",
    "the computational cost for the whole merging procedure is then negligible .",
    "whenever criteria i - vi are met the two particles merge , and form a new particle .",
    "the new particle is given properties to conserve mass , momentum and thermal energy .",
    "furthermore , we let the gravitational smoothing be proportional to @xmath93 .",
    "changing gravitational smoothing changes the potential . if conservation of binding energy is desired , it is safer to leave the gravitational smoothing unchanged .",
    "the reason is that the internal energy have to be changed and this may cause unphysical decrease in entropy .    when two particles merge , the resolution in that region changes .",
    "this is accompanied by a small change in the sph smoothing length in the region . to avoid large discontinuous changes in sph quantities , which could lead to spurious effects in the time integration scheme and",
    "could set up artificial shock waves , a given mass element is not allowed to merge more than once per local dynamical time .",
    "this ensures that particle merging is a smooth process where sph quantities have time to adjust to changes in the resolution .",
    "we have found this criterion to be crucial to accurately reproduce the results of simulations without particle merging .    throughout this paper",
    "the values of the tolerance parameters are @xmath94 . with these values",
    "we have always found that energy and angular momentum are conserved to well within one per cent .",
    "it should be noted , this choice of parameters allow for rather aggressive merging , sometimes making more than half the gas particles to merge , but all merging occurs in unresolved cores , and it does work well in the tests presented here .",
    "for objects like galaxies , which have a tremendous number of constituent bodies , the dynamics may be described by the boltzmann equation .",
    "a dark matter component can usually be considered collision - less in contrast to the collisional gas component , for which the boltzmann equation can be well approximated with the hydrodynamical equations . in an n - body method",
    "discreetness effects are unavoidable , due to the finite number of particles used .",
    "a practical way to test an n - body code , is to run it on a steady state system .",
    "conservation of energy , and linear and angular momentum , can be examined .",
    "also important is that the effects of two - body relaxation may be investigated . for a steady state system",
    "the potential is time - independent , and thus the energies of individual particles should be conserved . moreover , if the system is spherically symmetric , individual particle angular momenta are conserved . due to the motions of the particles in an n - body model",
    "the potential will never be strictly time - independent , the forces not strictly central , and there will always be some relaxation .",
    "the particles energies and angular momenta will diffuse , and this effect can be measured .    the most practical static models to choose for testing purposes are king models ( king @xcite ) , since they are of finite extent in phase space . following binney & tremaine ( @xcite )",
    ", king models have a phase space density          the parameter @xmath17 is a measure of the one dimensional velocity dispersion , and @xmath99 is a mass - normalization constant . integrating over velocity space we get the density as a function of @xmath97 ,          which is an ordinary differential equation for @xmath103 and can be integrated numerically once we have suitable boundary conditions . for positive @xmath96 , which is our region of interest , we must have positive @xmath97 , thus the value of @xmath104 is one condition .",
    "we note that the enclosed mass inside radius @xmath105 can be given in terms of @xmath97 as      restricting ourselves to a finite central density , we see that @xmath107 at @xmath108 is a natural condition .",
    "since @xmath104 is positive and @xmath109 is negative for @xmath110 , @xmath103 must decrease and become zero for some radius @xmath111 where also the density will vanish .",
    "this radius is known as the _",
    "tidal radius_.    king models are commonly parameterized in terms of @xmath112 , because the dispersion parameter @xmath17 just specifies the velocity scale .",
    "the mass scale is still free , but can be specified with a change of scale , i.e. , by adjusting the parameter @xmath99 .",
    "the radial poisson equation is solved numerically using a runge kutta method .",
    "the enclosed mass @xmath113 , is calculated in order to distribute the particles .",
    "particles are initially placed on a grid in a spherical region and then the grid is stretched into the desired density profile . in general",
    ", it can be hazardous to use grid - setups for very cool collision - less systems , but this will not be the case here since the particles are started with substantial velocities that are randomly distributed .",
    "the advantage with the grid placement , over a random placement , is that random fluctuations are minimized , and it is easier to compare the realization with the analytic potential .",
    "the system will also be closer to equilibrium .                in order to be able to compare results with the tests of hernquist & barnes ( @xcite ) and huang et al .",
    "( @xcite ) we set up a king model with central potential @xmath118 .",
    "units were chosen such that the gravitational constant @xmath119 , the total mass @xmath120 and dispersion parameter @xmath121 .",
    "this gives a total three - dimensional velocity dispersion of unity , and thus a total energy of @xmath122 .",
    "the tidal radius is @xmath123 .",
    "four different runs were made with @xmath124 or @xmath125 .",
    "a softening parameter @xmath126 was used in all runs , and they were continued to time @xmath127 , which corresponds to around 20 half - mass dynamical times .",
    "the barnes - hut parameter @xmath59 was 1.0 in all runs , except run 3 , where @xmath128 was used .",
    "all runs used individual time - steps , except run 4 , where a constant time step @xmath129 , was used . in order to test the relaxation effects we examined the relative changes in particle energies      between times @xmath131 and @xmath132 , where @xmath133 in fig .",
    "[ ediff0008 ] , the results for run 1 is shown . in table",
    "[ bh_tab ] , the standard deviation @xmath134 and mean value @xmath135 are presented for the runs .",
    "absolute deviations were also examined , but they had the same behavior as the standard deviations .",
    "the changes in energies are expected to be a random walk diffusion process because of small random accelerations , caused by the random noise in the particle forces .",
    "the diffusion is expected to behave such that      where @xmath137 is an empirical diffusion constant .",
    "@xmath137 was calculated with a linear least squares fit of @xmath138 as function of @xmath139 .",
    "the diffusion rates are slightly larger , but comparable to those of hernquist & barnes ( @xcite ) .",
    "llllllllllll run & @xmath63 & @xmath59 & @xmath140 & @xmath134 & @xmath135 & @xmath137 & @xmath141 & @xmath142 & @xmath143 & @xmath144 & cpu + 1 & 4626 & 1.0 & 0.0039 * & 0.078 & @xmath145 & 0.035 & @xmath146 & @xmath147 & 0.011 & 0.036 & 1.94 + 2 & 15238 & 1.0 & 0.0063 * & 0.041 & @xmath148 & 0.020 & @xmath149 & @xmath150 & @xmath151 & 0.026 & 9.39 + 3 & 4626 & 0.1 & 0.0039 * & 0.080 & @xmath152 & 0.036 & @xmath153 & 0.016 & @xmath154 & @xmath155 & 32.1 + 4 & 4626 & 1.0 & 0.020 & 0.076 & -0.011 & 0.036 & 0.021 & @xmath156 & @xmath157 & 0.019 & 0.83 +      conservation of energy , linear and angular momentum , and center of mass position was also examined .",
    "the maximum deviations during each run , are listed in table [ bh_tab ] .",
    "the time evolution of @xmath134 is plotted in fig .",
    "[ edev0039 ] .",
    "the straight line implies a fairly good fit of eq .",
    "( [ diffusion ] ) . in agreement with what was found by hernquist & barnes ( @xcite ) ,",
    "the only parameter having a significant effect on the diffusion rate was the number of particles used .",
    "judging from the cpu time used , run 4 seems to be over two times as fast as run 1 , but run 4 uses a constant time step , five times larger than the smallest time step of run 1 .",
    "run 1 conserves energy roughly a factor of four better than run 4 .",
    "three time levels are occupied for run 1 , and the benefit of individual time - steps is roughly a factor of two .",
    "one of the most common tests for astrophysical sph codes is the collapse test of evrard ( @xcite ) .",
    "it has also been presented by hernquist & katz ( @xcite ) , steinmetz & mller ( @xcite ) , nelson & papaloizou ( @xcite ) , and serna et al .",
    "( @xcite ) .",
    "one dimensional , ( spherically symmetric ) , finite difference solutions have been calculated by thomas ( @xcite ) and steinmetz & mller ( @xcite ) .",
    "we will henceforth refer to this test as the `` collapse test '' .",
    "the reason why this test is popular is that it is simple to set up , and that it tests an `` sph + gravity '' code on the aspects of adiabatic flow , shocks and gravitational collapse .",
    "the initial setup for this problem is a gas sphere , of mass @xmath160 and radius @xmath64 , with density profile      the gas is initially isothermal with an internal energy @xmath162 , and the velocity is zero everywhere .",
    "other test parameters are the specific heat ratio @xmath163 , the artificial viscosity parameters @xmath164 , @xmath165 and @xmath43 , the barnes - hut tolerance for the gravitational interaction @xmath166 and a softening parameter @xmath167 .",
    "the number of particles used was @xmath168 , and the number of neighbors in the sph summations was @xmath53 .",
    "we use the same kind of stretched grid set up , as in sect .",
    "[ bh - test ] .",
    "it gives a more relaxed initial configuration than the corresponding random distribution .",
    "for this particular distribution the errors in the sph - density are very small , as can be seen in fig .",
    "[ cllps_dens_fig ] .",
    "a good way to check for sph sampling errors , is to perform an sph evaluation of a constant unity field , putting @xmath169 in eq .",
    "( [ mc - formula ] ) .",
    "it is important that no edges etc . , where the sampling necessarily is bad due to the neglect of surface terms are within the investigated volume .",
    "correspondingly , the gradient of the unit field may be examined .",
    "the statistics of the sph representations of a unit field and its gradient , for the initial configuration in fig .",
    "[ cllps_dens_fig ] , are presented in table [ one_tab ] .",
    "although the result for a unit field shows very little spread for this particular configuration , the result for the corresponding gradient field shows considerably more spread .",
    "however , these fluctuations are much smaller than those corresponding to a random placement setup , as shown in table [ one_tabr ] . to avoid boundary effects , when calculating the numbers in table [ cllps_dens_fig ] and table [ one_tabr ] , only a selection of 1800 particles within radius 0.7 were used .",
    "units in the collapse test are chosen so that @xmath172 , and the usual plots of density , pressure , internal energy , velocity and mach number are shown in fig .",
    "[ cllps_fig ] .",
    "the results show good agreement with what have been reported by the authors mentioned above .        with only 4000 particles",
    "the outgoing shock is not very sharp , but as noted in steinmetz & mller ( @xcite ) all global quantities are still reproduced rather well .",
    "usually the smearing of shock fronts is rather severe in sph , but still this affects the evolution of the shock fronts surprisingly little . depending on the problem ,",
    "one often needs some factors of 10000 particles in shock regions , to see the shocks clearly resolved . as for the king - model test ,",
    "some conservation properties were examined and are listed in table [ coll_tab ] .",
    "the shortest ( individual ) time - step during the simulation was @xmath177 , and the particles occupied a span of 7 time - levels . in fig .",
    "[ coll_energy ] , the total thermal energy , total kinetic energy , total potential energy and total energy , are plotted .",
    "the maximum thermal energy is slightly lower , than reported by hernquist & katz ( @xcite ) and steinmetz & mller ( @xcite ) .",
    "this is because of the higher number of neighbors used , here being 64 , as compared to the 32 neighbors used by above mentioned authors .      as a test including radiative cooling , and merging of particles",
    ", we have simulated the collapse of a rotating sphere , with parameters reminiscent of a proto - galaxy .",
    "this test case has been studied by navarro & white ( @xcite ) and serna et al .",
    "( @xcite ) .",
    "the initial density field is spherically symmetric , with a radial density profile @xmath178 .",
    "the sphere is started in solid body rotation with a dimensionless spin parameter @xmath179 ( @xmath180 and @xmath181 are the total angular momentum and total energy ) .",
    "the initial radius is 100 kpc , and the total mass is @xmath182 , with 10% of the mass in gas and 90% of the mass in dark matter .",
    "the gas starts at a temperature of 1000 k. the gas and the dark matter components are represented by 2000 particles each .",
    "gravitational softening parameters were taken to be 2 and 5 kpc for the gas and dark matter , respectively .",
    "[ nwg10 ] shows the evolution of the gas and dark matter distributions for a simulation without particle merging .",
    "the dark matter virializes soon after the main collapse , whereas the gas forms a thin disk .",
    "collisional line cooling is almost completely effective in radiating away thermal energy from adiabatic compression and shock heating .",
    "only a slight fraction of the gas is heated to temperatures above 30,000 k ( see fig .",
    "[ nwmhotfrac ] ) , and thermal pressure does not play any significant role in the evolution .",
    "radial velocities are effectively dissipated , and most of the gas has formed a rotationally supported disk after one collapse time .",
    "the disk displays clear spiral structures after @xmath183 .",
    "as reported by navarro & white ( @xcite ) , the disk is unstable and starts breaking up into small clumps towards the end of the simulation .",
    "navarro & white found that if the gas mass fraction is reduced to 2% , thereby increasing the toomre ( 1964 ) stability parameter , the disk is substantially stabilized .",
    "serna et al .",
    "( @xcite ) found the stability of the disk , when the gas mass fraction was 10% , to be intermediate to the 10% and 2% gas mass fraction case of navarro & white .",
    "our results resemble those of serna et al .",
    "the reason that we get a more stable disk than navarro & white , is probably due to the fact that we set the sph smoothing so as to acquire @xmath184 particle neighbors ( @xmath53 ) , whereas navarro & white uses roughly 32 neighbors .",
    "when we reduce the number of sph neighbors to @xmath185 , we find that the disk evolution closely matches that of navarro & white .    in the simulation that includes our prescription for merging particles in high density regions ( see fig .",
    "[ nwmg10 ] ) , the number of particles decrease as more particles collapse into high density regions and merge with other particles . as can be seen from fig .",
    "[ nwnpart ] , the number of particles has been reduced to half the initial value at the end of the simulation .",
    "the gas cooling rate depends on the square of the local gas density .",
    "when particles are merged the local resolution decreases , and small scale fluctuations in the density field are damped .",
    "this could potentially have significant effects on the gas cooling .",
    "this is a fundamental problem in all gas dynamical simulations of galaxy formation .",
    "the gas density field has to be assumed to be reasonably smooth on scales smaller than can be resolved in the simulation .",
    "[ nwmhotfrac ] shows that the fraction of hot gas is not altered by the inclusion of particle merging .    the rotation curves , ( @xmath186 ) , for the simulations are shown in fig [ nwrotcurve ] .",
    "the mass distribution when merging is included is in excellent agreement with the more conventional run , without merging .",
    "the rotation curves are approximately flat out to the edge of the disk at @xmath187 .",
    "the disk that forms in the run without particle merging is slightly more concentrated , with a 30% higher gas mass inside 3 kpc .",
    "[ nwg10 ] and [ nwmg10 ] indicates that particle merging stabilizes the disk , and slightly suppresses the formation of substructure .",
    "this is a natural consequence of the decreasing gas mass resolution and gravitational force resolution , when particles merge .",
    "the total cpu time for the simulation is halved when particle merging is allowed , at the end of the simulation the cpu cost per unit time has been reduced by a factor of five , and the total cpu time for the simulation is halved , when particle merging is allowed .      in order to test our code , and especially the particle merging scheme , on problems that are typical of those we wish to study , we simulate the collapse of a proto - galaxy that has been set up consistently with the cdm cosmological model , in a fashion similar to katz & gunn ( @xcite ) .",
    "the same starting conditions were used for three different simulations , two with particle merging and one without .    the zeldovich approximation together with a standard cdm model ( @xmath188 , @xmath189 , @xmath190 , @xmath191 , @xmath192 , bardeen et al .",
    "@xcite ) power spectrum , was used to set up a cosmological density field .",
    "the system is given an initial over - density corresponding to a 3 @xmath17 peak in the cdm spectrum when it is convolved with a top hat filter of mass @xmath182 .",
    "this density field was realized inside a sphere with a co - moving radius of 1.46 mpc , using both gas and dark matter ( collision - less ) particles .",
    "gas and dark matter particles had a gravitational smoothing of 2 and 5 kpc , respectively .",
    "the system is started in solid body rotation , corresponding to a dimensionless spin parameter of @xmath193 , in an attempt to roughly approximate the effects of tidal interactions .",
    "the initial gas temperature is 10,000 k , and the gas cooling rate is that of a gas in collisional ionization equilibrium and with a 0.1 solar metallicity , as given by sutherland & dopita ( @xcite ) .",
    "three simulations were made , differing only in the number of particles used , and whether or not particles were allowed to merge .",
    "two simulations were started with 8000 particles , half of them used to represent the gas and the other half to represent the dark matter component .",
    "the only difference between these two simulations is that one employed the previously described scheme for merging gas particles , and the other did not .",
    "the third simulation was made with ten times more gas particles , and with particle merging .",
    "the same realization of initial conditions were used in all three simulations , in order to make the final initial conditions as similar as possible .",
    "the systems were started at z = 30 , and evolved to z=0 .",
    "the main collapse of the proto - galaxy occurs at @xmath194 . at z=0 a single dominant gas object with galactic densities",
    "has formed in all the simulations .",
    "this galactic object consists of a compact core surrounded by a thin disk , fig [ galpict8k ] , fig [ galpict8 km ] , and fig [ galpict45 km ] .",
    "this object is built up from a combination of continuous in - fall and the merging of smaller collapsed objects .",
    "the mass build - up of the final objects can be seen in fig [ objmassgal ] , which shows the gas mass of the most massive collapsed object as a function of redshift . collapsed gas objects",
    "were identified using a friends - of - friends algorithm , grouping particles together that had an over - density exceeding 1000 .",
    "the magnitude of the mass build - up over time is very similar in all three simulations .",
    "the mass fraction of gas with a temperature exceeding @xmath195 , as a function of redshift , is shown in fig [ hotfracgal ] .",
    "the two 8000 particle simulations differ slightly , with roughly 1% more hot gas being produced after z=1.2 in the simulation including merging .",
    "the curve for the high resolution simulation deviates clearly from the other two after z = 1 . between @xmath196 more hot gas",
    "is produced , and after @xmath197 more hot gas is able to cool than in the lower resolution simulations . at z=0",
    "the mass fraction of hot gas is close to 10% for all three simulations .",
    "these results seem to indicate that the effects of applying the particle merging scheme are small , outside the gravitationally unresolved cores of collapsed gas objects .",
    "furthermore , a ten - fold increase of the initial number of gas particles in a simulation produced only moderate differences , lending some tentative support for low resolution sph simulations of galaxy formation .    evolving a system with 4000 gas and 4000",
    "dark matter particles initially , took 64 cpu hours on a cray - ymp . the same system with merging of particles required only 13 cpu hours .",
    "the high resolution system required 63 cpu hours , almost the same as the low resolution system without merging .",
    "the decrease in the cpu time required for a simulation , due to particle merging , will vary with the problem and the tolerance parameters used in the merging scheme ."
  ],
  "abstract_text": [
    "<S> we present and test a code for two - fluid simulations of galaxy formation , one of the fluids being collision - less . </S>",
    "<S> the hydrodynamical evolution is solved through the sph method while gravitational forces are calculated using a tree method . </S>",
    "<S> the code is lagrangian , and fully adaptive both in space and time . </S>",
    "<S> a significant fraction gas in simulations of hierarchical galaxy formation ends up in tight clumps where it is , in terms of computational effort , very expensive to integrate the sph equations . </S>",
    "<S> furthermore , this is a computational waste since these tight gas clumps are typically not gravitationally resolved . </S>",
    "<S> we solve this by merging gas particles in these regions , thereby limiting the sph resolution to the gravitational force resolution , and further speeding up the simulation through the reduction in the number of particles . </S>"
  ]
}