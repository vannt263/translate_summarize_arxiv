{
  "article_text": [
    "one of the most fascinating complex adaptive systems in nature is the brain . despite its relatively simple basic units",
    "the neurons the cooperative bebaviour of the interconnected neurons and their functional implications are only poorly understood .",
    "the problem in investigating this system is not only its complexity , because e.g. the human brain consists of about @xmath0 neurons @xcite , but also its characteristic cycle structure which is known as action - perception - cycle .",
    "the difficulty with the action - perception - cycle , which was already known to von uexkll in 1928 @xcite , is that a closed formulation of the problem has to include a coupled description of the brain and the environment because the actions of an animal are transformed by the environment to perceptions which are transformed by the brain to actions and so on . from this",
    "it is also clear that neither the perceptions nor the actions occurring in the system are randomly generated .    in this paper",
    "we address the question : how is the learning dynamics of a neural network affected by different mechanisms for the selection of an action ?",
    "because learning in neural networks is modulated by a learning rule for the modification of the synaptic weights one can ask more precisely , if the learning rule itself is concerned by the action - selection mechanism .",
    "we approach this problem by comparing two different biologically motivated learning rules for neural networks .",
    "the first was proposed by bak and chialvo @xcite and combines experimental findings of frey and morris @xcite about _ synaptic tagging _ with a global reinforcement signal which can be interpreted as a dopamin signal e.g. as in the experiments of otmakhova and lisman @xcite .",
    "the second was introduced by the author @xcite and extends the ingredients above by the results of fitzsimonds @xcite about heterosynaptic _ long - term depression _",
    "( ltd ) which can be qualitatively explained by our stochastic learning rule .",
    "both learning rules are local in the sense that the information , which is used for the synaptic modification , is only provided by the neurons which enclose the synapse and hence can be interpreted as extentions to the classical hebbian learning rule @xcite .    as problem",
    "to be learned we choose the problem of timing , e.g. catching a ball , in a recurrent network topology which is generated by an algorithm of watts and strogatz @xcite .",
    "this network class was chosen because the topology is generated in dependence of one parameter , the so called rewiring parameter , and allows to convert a regularly connected network continously in a random one .",
    "recently of special interest was the regime between these two extrema , called small world networks , which could be brought in contact with experimental results about the neuroanatomic structure @xcite .",
    "this paper is organized as follows . in section [ model_timing ]",
    "we define our model .",
    "section [ results ] demonstrates the practical working mechanism exemplified in learning the problem of timing in a recurrent neural network .",
    "we compare the learning behavior of our learning rule @xcite with the learning rule of chialvo and bak @xcite in dependence of two different action - selection - mechanisms .",
    "the paper ends in section [ conclusions ] with conclusions and an prospect on future work .",
    "if one wants to investigate the learning dynamic of a neural network one has to define every item of table [ gen_sys ] which characterizes the entire system .",
    ".[gen_sys]characterization of the entire system [ cols=\"^ , < \" , ]     one recognizes by comparison with table [ list_ens1 ] that the overall results are confirmed .",
    "learning rule 4.b ) obtains always significantly better results than 4.a ) .",
    "moreover , a direct comparison between the learning rules for asm i. and ii . reveals that learning rule 4.a ) seems to be unaffected by the action - selection mechanism whereas learning rule 4.b ) is clearly influenced .      to quantify the dependence of the learning behavior of the action - selection mechanism we calculate the mean first - passage time @xmath1 from the simulation results obtained so far .",
    "figure [ meanfpt_rs ] compares the results for learning rule 4.a ) and 4.b ) in dependence of the rewiring parameter @xmath2 and the patterns to be learned .",
    "one can clearly see that the mean first - passage time for learning rule 4.b ) ( upper ( lower ) two curves correspond to @xmath3 ( @xmath4 ) ) is significantly reduced for asm ii .",
    "( full lines ) whereas the results for learning rule 4.a ) are not affected ( middle curves correspond to @xmath4 ) .",
    "this can be explained by the different structure of both learning rules .",
    "learning rule 4.a ) possesses no memory with respect to the outcomings of past results but only a tagging mechanism for the neurons which were involved in the last signal processing step .",
    "hence it can not detect the differences of the two action - selection mechanisms because they differ only in the order of the presented patterns but not in the overall presentation statistics .",
    "this follows from the fact that learning the last pattern takes about @xmath5 of the first - passage time .",
    "learning rule 4.b ) is due to the neuron counters @xmath6 different in this point .",
    "the neuron counters are a memory for the outcomings of the past results and thus can detect the slight difference in the two action - selection mechanisms .",
    "we think that this result is worth to be discussed in detail because it reveals some deep characteristics of animals which is normally neglected in investigations of neural networks .",
    "the consequences of the results obtained above are not only that the learning rule of a neural network effects on the neural activity by synaptic changes and hence on the behavior of an animal which is common sense , but also that the reverse holds .",
    "that means the actions of an animal influence the learning rule of its neural network .",
    "this is caused by the stimuli generated by the animal s actions which are represented in the examples above as patterns which lead to a modulation of the neural activity in the network and hence to a modulation of the learning rule due to memory effects by the neuron counters .",
    "this seems to be plausible because we do not choose our actions randomly but we choose them to learn something as fast as possible to survive .",
    "moreover , it is not only plausible but also efficient to us the action - selection mechanism as source of information which is shown in figure [ meanfpt_rs ] .",
    "hence our investigations lead not only to a bottom - up communication but also to a top - down communication between different system levels . in this respect",
    "our learning rule with neuron counters is different to all other hebb - like learning rules which has been proposed as extentions to the classical hebbian rule @xcite which lack the ability of a memory because they can not be affected by action - selection mechanisms which differ not in the presentation statistics but only in the presentation order .",
    "in this article we investigated the properties of our recently proposed stochastic hebb - like learning rule for neural networks .",
    "we demonstrated by extensive numerical simulations that the problem of timing can be learned in different topologies of a neural network generated by the algorithm of watts and strogatz @xcite .",
    "a comparison with the learning rule of chialvo and bak @xcite gave not only always significantly better results but revealed that our stochastic hebb - like learning rule can discriminate between different action - selection mechanisms with the same presentation statistics but different presentation order .",
    "this difference forms a source of information and can positively effect the learning behavior due to the bidirectional communication between different system levels .",
    "this effect was only recognized because we did not want to model the brain of an animal but its action - perception - cycle schematically depicted in table [ gen_sys ] where the brain is only one part of the entire system .    in summary our stochastic hebb - like learning rule",
    "is not only universal applicable in feedforward multilayer networks @xcite but also in a class of recurrent networks generated by @xcite as demonstrated in this article . together with its biological interpretation as qualitative form of heterosynaptic plasticity @xcite and its sensitivity to the presentation order of the patterns to be learned",
    "we belief that our learning rule unites some crucial ingredients on the way of our understanding of the action - perception - cycle and hence of the brain .",
    "we belief that only such an integrated ansatz can explain the functional working method of the entire system because its parts are coupled in a nonlinear or stochastic way ."
  ],
  "abstract_text": [
    "<S> we demonstrate that our recently introduced stochastic hebb - like learning rule @xcite is capable of learning the problem of timing in general network topologies generated by an algorithm of watts and strogatz @xcite . </S>",
    "<S> we compare our results with a learning rule proposed by bak and chialvo @xcite and obtain not only a significantly better convergence behavior but also a dependence of the presentation order of the patterns to be learned by introduction of an additional degree of freedom which allows the neural network to select the next pattern itself whereas the learning rule of bak and chialvo stays uneffected . </S>",
    "<S> this dependence offers a bidirectional communication between a neuronal and a behavioural level and hence completes the action - perception - cycle which is a characteristics of any living being with a brain . </S>"
  ]
}