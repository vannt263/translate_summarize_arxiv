{
  "article_text": [
    "* probabilistic vs. deterministic domain decomposition . * in the solution of large boundary value problems ( bvps ) arising in realistic applications ( such as airfoil simulation or weather forecast ) , the discretization of the bvp on a domain @xmath0 leads to algebraic systems of equations that can only be solved on a parallel computer with @xmath1 processors .",
    "not only does parallelization require multiple processors but also parallel algorithms .",
    "the classical schwarz alternating method @xcite is the best known of the state - of - the - art algorithms  which we will refer to as deterministicand serves to illustrate the difficulty that they all face .",
    "the idea is to divide @xmath0 into a set of @xmath2 overlapping subdomains , @xmath3 , and have processor @xmath4 solve the restriction of the partial differential equation ( pde ) to the subdomain @xmath5 .",
    "but because the solution is not known in the first place , an initial guess has to be made at start , in order to give processor @xmath4 a well - posed ( yet incorrect ) problem .",
    "the boundary conditions ( bcs ) along the fictitious interfaces of @xmath5 are then updated from the solution of the surrounding subdomains in an iterative way , hopefully leading to convergence . however , since the inter - processor communication involved in this updating procedure is intrinsically sequential , it will eventually set an upper limit to the scalability of the algorithm according to amdahl s law .",
    "summing up , the matrix algebra arising in the discretization of bvps does not , in general , lend itself optimally to parallellization .",
    "+ an alternative to deterministic methods which is specifically designed to circumvent the scalability issue is the probabilistic domain decomposition ( pdd ) method , which has been successfully applied to elliptic @xcite , parabolic @xcite and hyperbolic bvps @xcite .",
    "pdd consists of two stages . in the first stage ,",
    "the solution is calculated only on a set of interfacial nodes along the fictitious interfaces , by solving the probabilistic representation of the bvp with the monte carlo method .",
    "more precisely , the pointwise solution of the bvp is @xmath6 $ ] , i.e. the expected value of a functional @xmath7 of a given stochastic process @xmath8 conditioned to @xmath9 .",
    "it is then possible to reconstruct ( approximately ) the solution on the interfaces , so that the pde restricted to each of the subdomains is now well posed , and can be independently solved  the second stage of pdd .",
    "note that both stages in pdd are embarrasingly parallel by construction",
    ". moreover , pdd is naturally fault - tolerant .",
    "subdomains and @xmath10 interfaces with @xmath11 nodes each ( @xmath12 ) . *",
    "b ) * fem mesh on subdomain @xmath13 .",
    "* c ) * the nodal values interpolated with rbfs along the interface @xmath14 , making up a dirichlet bc for @xmath13 and @xmath15 . ]    * nomenclature of pdd .",
    "* in this paper , we shall exclusively deal with elliptic bvps .",
    "let us introduce some terminology ( see figure [ i : figura1 ] ) .",
    "the domain @xmath16 ( not necessarily simply connected ) on which the bvp is being solved is partitioned into @xmath17 _ nonoverlapping _ subdomains @xmath18 .",
    "the boundary @xmath19 of a subdomain @xmath20 contains several ( @xmath21 ) _ artificial interfaces_each of which is shared between @xmath20 and another adjacent subdomain  which are labeled @xmath22 ( note that this labeling is not unique ) .",
    "a subdomain boundary @xmath19 may or not contain some portion of the actual boundary . in sum , @xmath23 .",
    "artificial interfaces are discretized into _ interfacial nodes _ ( or simply , nodes ) uniquely labeled @xmath24 .",
    "assume @xmath17 functions @xmath25 defined on @xmath17 domains @xmath26 such that @xmath27 if @xmath28 .",
    "then , their direct sum is defined as @xmath29    the solution of the bvp on the nodes is calculated by resorting to the probabilistic formulation of the bvp with a monte carlo method , yielding the _ nodal values _ ( or _ nodal solutions _ ) @xmath30 .",
    "consider a subdomain @xmath20 .",
    "a dirichlet bc can then be provided on every @xmath31 by interpolation of the nodal values @xmath32 .",
    "along with the actual bcs which apply on @xmath33 , the bvp on @xmath20 now is well posed and can be solved right away , yielding @xmath34 . once the subdomain solutions @xmath35 are available , they are put together to form a global pdd solution : @xmath36 .",
    "( we reserve @xmath37 for the exact solution of the bvp and denote the global pdd approximations with @xmath38 . ) since adjacent subdomains @xmath39 and @xmath5 share a dirichlet bc on their common interface , the pdd solution is continuous in @xmath0although not necessarily differentiable .",
    "* the cost of computing the nodal solutions . * the convenience of pdd depends on whether a suitable stochastic representation for the bvp under consideration is available , and on the cost involved in numerically solving it . due to the poor accuracy of the monte carlo method ( compared with deterministic ones ) ,",
    "the bulk of the cost of pdd falls on the calculation of the nodal solutions to within a required accuracy .",
    "more precisely , given a _",
    "nodal error tolerance _ @xmath40 and a _ confidence interval _ @xmath41 , the cost of solving the bvp on an interfacial node scales as @xmath42 , where @xmath43 is the weak convergence rate of the numerical integration scheme ( also called the _ bias _ )",
    ". this poor rate of convergence is due to the slow convergence of both the statistical error and the bias , which have to be tackled simultaneously . for bvps with dirichlet bcs there quite a few linear integrators ( i.e. with @xmath44 ) . regarding the statistical error , replacing the mean by a multilevel estimator of the expected value of feynman - kac functionals",
    "has recently been shown to dramatically reduce the cost to @xmath45 @xcite .",
    "when the bias law is sharp , extrapolation  la talay - tubaro or regression methods in the spirit of @xcite can further improve the accuracy at virtually no extra cost . * using rougher numerical solutions to reduce the variance . * by construction , pdd offers an additional device to accelerate the monte carlo simulation of the nodal values , namely the possibility of calculating and exploiting rougher estimates of the global solution of the bvp .",
    "assuming that a numerical solution @xmath46 with a _ target nodal error tolerance _",
    "@xmath47 is required , it may be worth to calculate before a rougher approximation @xmath48 , with an @xmath49 tolerance ; and then use it to draw the stochastic pathwise nodal control variate @xmath50 alongside the monte carlo realizations of the feynman - kac functional .",
    "( in ( [ f : intro_xi ] ) , the integrals are ito s , @xmath51 is the bvp potential , and @xmath52 and @xmath53 are the diffusion matrix and first - exit time from @xmath0 of the stochastic process ( [ f : sde ] ) driven by a wiener process @xmath54 . )",
    "this allows one to construct afterwards an estimator of the feynman - kac functional involving the control variate ( [ f : intro_xi ] ) , which has the same expected value but a much smaller variance .",
    "this notion is what we call iterpdd . in order to fix ideas ,",
    "let us introduce the following notation : @xmath55 means that @xmath38 is a pdd approximation obtained with tolerance @xmath40 and no variance reduction ; while @xmath56= \\textrm{iterpdd$(a_0,a_1)$ , or simply iterpdd$(a_0,a_1)$}\\ ] ] means that first @xmath57 is calculated without variance reduction , then differentiated in order to construct @xmath58 according to ( [ f : intro_xi ] ) , which in turn is used as control variate in order to reduce the variance in calculating @xmath59 with a target tolerance @xmath47 , which is the ultimate goal . because the nodal values of @xmath59 can now be calculated with much less variance , statistical errors are smaller , and the time ( or cost ) it takes the computer to hit the tolerance @xmath47 is also less .",
    "in fact , @xmath60\\big)\\times$cost plainpdd$(a_0)$},\\end{aligned}\\ ] ]    where @xmath61 $ ] is pearson s correlation . as ( [ f : cost_of_iterpdd ] ) indicates , there is a tradeoff between the effort invested in calculating @xmath62 , and the reduction of variance yielded by @xmath63 , which depends on the quality of @xmath62 .",
    "the most straightforward procedure is to simply guess some @xmath49 .",
    "while numerical tests indicate that the iterpdd strategy can be quite successful , a poorly chosen @xmath64 may well result in an overall cost of iterpdd@xmath65 _ larger _ than that of plainpdd@xmath66 .",
    "therefore , at the heart of iterpdd lies an optimization problem for @xmath64 . in order to make educated guesses of @xmath64 given @xmath47 ,",
    "two questions must be tackled : i ) how does the cost of a @xmath67plainpdd@xmath68 simulation depend on @xmath40 ; and ii ) how does @xmath69 $ ] depend on @xmath40 .",
    "the former requires that the sde integrator have a predictable and sharp order of weak convergence .",
    "deriving a _ sensitivity formula _ for ii ) is one of the main points of this paper .    * a multigrid - like pdd algorithm .",
    "* with such a sensitivity formula in place which can predict an optimal ( or more realistically , good enough ) initial tolerance @xmath64 for @xmath70=$]iterpdd@xmath65 , it is natural to try and compute @xmath62 faster by finding @xmath71 which minimizes the cost of @xmath72=$]iterpdd@xmath73 . much like in the multigrid method ,",
    "a number @xmath74 and an _ optimal sequence _ of nested iterpdd simulations can be envisioned with tolerances @xmath75 which fully exploits the potential of control variates for a given bvp . however , in iterpdd , given a target tolerance @xmath47 , the number @xmath74 and the sequence @xmath76 must be determined _ before _ actually running one single pdd simulation . to compound matters , all of @xmath74 , @xmath77 , and in general any result provided by any such _ scheduling algorithm _",
    "will be affected by the randomness introduced by monte carlo , making its performance meaningful only in terms of its expected value and variance .",
    "* outline of the paper .",
    "* we start by revisiting the probabilistic formulation of elliptic bvps with dirichlet bcs in section [ s : representation ] , and identifying the pathwise control variates .",
    "section [ s : theory ] formally poses the problem  namely , acceleration of pdd with the iterpdd scheme  and presents our own theoretical results concerning the aforesaid sensitivity @xmath69 $ ] .",
    "section [ s : globalerror ] links the nodal target error tolerance , @xmath47 , to the global pdd error tolerance @xmath78and discusses the stability of pdd . in section [ s : approximations ] , the formal restrictions in section [ s : theory ] are relaxed leading to practical , but partially heuristic , scheduling algorithm / sensitivity formula ( algorithm [ a : scheduling ] ) and final iterative , multigrid - like pdd loop ( algorithm [ a : iterpdd ] ) .",
    "they are numerically tested in section [ s : experiment ] , and section [ s : conclusions ] concludes the paper .",
    "consider the linear elliptic bvps with dirichlet bcs in @xmath79 :    @xmath80    where the _ differential generator _ @xmath81 is @xmath82    and the functions @xmath83 are regular enough that the solution to ( [ f : ellipticbvp ] ) exists and is unique . in particular , if @xmath84 and the matrix @xmath85 $ ] is such that @xmath86 the pointwise solution to ( [ f : ellipticbvp ] ) admits the following probabilistic representation    @xmath87:= e\\big[\\ , g({\\bf x}_{\\tau})e^{\\int_0^{\\tau}c\\big({\\bf x}_s\\big)ds } \\ , - \\ , \\int_0^{\\tau}f\\big({\\bf x}_t\\big)e^{\\int_0^t c\\big({\\bf x}_s\\big)ds}dt\\,\\big],\\ ] ]    where @xmath88 $ ] stands for the expected value , the functional @xmath7 is called _ score _ , and @xmath89 is the value at @xmath90 of the stochastic process @xmath91\\rightarrow\\mathbb{r}^d$ ] , driven by the stochastic differential equation ( sde )    @xmath92    where the diffusion matrix @xmath52 is obtained from @xmath93 ( by lu decomposition , by instance ) , and @xmath54 is a standard @xmath94-dimensional wiener process .",
    "the _ first exit time _",
    "@xmath53 is defined as @xmath95 , i.e. the time when a solution of the sde ( [ f : sde ] ) first touches @xmath96 at the _ first exit point _ @xmath89 .",
    "the process @xmath97 can be thought of as a non - differentiable trajectory inside @xmath0 .",
    "equation ( [ f : dynkin ] ) is dynkin s formula , a particular case of the more general feynman - kac formula for parabolic bvps ",
    "see @xcite for more details .      in practice , solving ( [ f : dynkin ] ) involves two levels of discretization .",
    "first , the sde ( [ f : sde ] ) has to be integrated numerically according to a numerical scheme @xmath98 ( which we will call _ integrator _ ) with a timestep @xmath99 , yielding a discretized score @xmath100 .",
    "this results in @xmath101 $ ] being a biased estimator of @xmath102 $ ] , with _ signed _ bias    @xmath103\\big):=e[\\phi_h]-e[\\phi].\\ ] ]    as suggested by the notation , the bias depends on both the timestep @xmath104 and the specific integrator @xmath98 .",
    "it takes asymptotically the form of a power law : @xmath105\\big)\\shortrightarrow \\beta h^{\\delta } \\textrm { as } h\\shortrightarrow 0^+,\\ ] ]    where @xmath106 is a signed constant independent of @xmath104 .",
    "second , the expected value in ( [ f : dynkin ] ) is replaced by an estimator over @xmath107 independent realizations @xmath108 of the sde ( [ f : sde])which is the essence of the monte carlo ( mc ) method .",
    "typically , that estimator is the mean , which , according to the central limit theorem , introduces a _ statistical error _",
    "@xmath109 - \\frac{1}{n}\\sum_{j=1}^n \\phi_h^{(j)}\\big|\\leq q\\sqrt{\\frac{v[\\phi_h]}{n}}\\ ] ]    with probability @xmath110 , and @xmath111 for @xmath112 .",
    "moreover ,    @xmath113:=e\\big[\\big(\\phi_h - e[\\phi_h]\\big)^2\\big]\\leq b_{\\xi}^2(e[\\phi ] ) + v[\\phi]/n , \\ ] ]    where mse stands for mean square error . since @xmath114|]\\leq e[(\\phi_h - e[\\phi_h])^2]$ ] , @xmath101=u({\\bf x}_0)$ ] , and @xmath102=u({\\bf x}_0)$ ] , it holds    @xmath115)|v[\\phi]/n}\\leq \\\\\\nonumber \\leq |b_{\\xi}(e[\\phi_h])|+\\sqrt{v[\\phi]/n } \\leq |b_{\\xi}(e[\\phi_h])|+q\\sqrt{v[\\phi]/n},\\end{aligned}\\ ] ]    with probabilities approaching @xmath41 as @xmath116",
    ". looking at ( [ f : mse_error ] ) or ( [ f : bound_of_error ] ) , the two ways to speed up monte carlo simulations of ( [ f : dynkin ] ) are : using an integrator @xmath98 with the highest possible @xmath43 for the bvp under consideration ; and/or replacing the mean in ( [ f : statistical_error ] ) by another estimator of the expected value which has less variance , thus achieving the same statistical error with a smaller @xmath107 .      in this paper",
    ", we investigate a technique of variance reduction based on pathwise control variates , which is difficult to implement in other contexts , but suits the framework of pdd ideally . in order to discuss it ,",
    "we adopt the same ansatz as in . consider the system of sdes : @xmath117dt + \\sigma({\\bf x}_t)d{\\bf w}_t , & { \\bf x}_0={\\bf x}_0 , \\\\",
    "dy_t= c({\\bf x}_t)y_tdt + { \\bm \\mu}^t({\\bf x}_t)y_td{\\bf w}_t , & y_0=1,\\\\ dz_t= -f({\\bf x}_t)y_tdt + { \\bf f}^t({\\bf x}_t)y_td{\\bf w}_t , & z_0= 0 , \\end{array } \\right.\\ ] ]    where @xmath118 are smooth arbitrary fields , and let @xmath119 be the evaluation of the processes @xmath120 at @xmath121 . if @xmath122 , the system ( [ f : vr_milstein_sys ] ) is just another way of writing down the functional in ( [ f : dynkin ] ) : @xmath123 it turns out  see for details  that @xmath124=e[{\\tilde\\phi}]=e[\\phi]\\ ] ] regardless of the arbitrary functions @xmath125 and @xmath126 , but the variance @xmath127\\neq v[{\\tilde\\phi}]= e\\big[\\ , \\int_0^{\\tau}y_t^2\\parallel \\sigma^t\\nabla u+u{\\bm\\mu}+{\\bf f}\\parallel_2 ^ 2\\,dt \\big]\\ ] ]    _ does _ depend on them ; and in fact , making the choice @xmath128    then @xmath129=0$]meaning that one single realization would yield the exact pointwise solution @xmath130 deterministically .",
    "certainly this is a moot point , for in order to do so , the exact solution would be required in the first place ; and the system ( [ f : vr_milstein_sys ] ) would still have to be integrated numerically  so that the variance of the discretized approximation would be small , but finite .",
    "let @xmath131 .",
    "choosing @xmath132 in ( [ f : combining_method ] ) , @xmath133 leads to the pathwise equivalent of importance sampling , while if @xmath134 , @xmath135 can be interpreted as the stochastic equivalent of control variates . both importance sampling and",
    "control variates are well - known variance reduction techniques in statistics @xcite .",
    "there are several reasons why the second method is the more convenient :    * control variates do not need to store @xmath38 . * for inadequate @xmath136 and @xmath137 , importance sampling",
    "may actually lead to _ increased _ variance .",
    "this is much less likely so with control variates ( as it will be seen in a moment ) .",
    "* from the point of view of numerical integration , introducing a non - zero @xmath138 in ( [ f : vr_milstein_sys ] ) leads to a system of stochastic equations with multiplicative noise : @xmath139 .",
    "such sdes can be unstable .",
    "* finally , the trajectories are not affected by control variates , while if @xmath140 , the particles are actually pushed around depending on @xmath137 .",
    "the first fact facilitates the analysis of iterpdd .",
    "therefore , we will settle for ( [ f : exactf ] ) henceforth . in statistics ,",
    "a control variate @xmath58 for @xmath7 is a variable which is drawn alongside @xmath7 and has a large correlation with it ( i.e. close to @xmath141 ) .",
    "then , the variable @xmath142 ) \\ ] ] is such that @xmath143=e[\\phi]$ ] , but the variance is not . at the unique critical point @xmath144/v[\\xi]$ ] , @xmath129 $ ] is minimal and yields a reduction of variance @xmath145}{v[\\phi ] } = 1-\\rho^2[\\phi,\\xi]\\ ] ] ( see @xcite for details ) , where @xmath146 is pearson s correlation : @xmath147:= \\frac{cov[\\phi,\\xi]}{\\sqrt{v[\\phi]v[\\xi]}}\\qquad\\textrm{(such that $ \\rho^2[\\phi,\\xi]\\leq 1$).}\\ ] ]    by comparison of ( [ f : statistics_vr ] ) and ( [ f : vr_milstein_sys ] ) , the pathwise control variate is ito s integral @xmath148    ( note that @xmath149 , with @xmath150 , yields the same @xmath151 $ ] as @xmath58 and thus the same reduction of variance . )",
    "when @xmath152 , we will refer to @xmath58 as the _ exact control variate_. in that case , the correlation is perfect and the variance is zero ( in the limit @xmath116 ) . if @xmath153 , @xmath58 is close to the minimizer @xmath154 of ( [ f : statistics_vr ] ) and the equality in ( [ f : variance_reduction ] ) still holds . but even if @xmath136 is so poor that ( [ f : variance_reduction ] ) breaks down becoming a mere lower bound , any reasonable substitute of @xmath155 will still produce a @xmath58 with sufficient correlation as not to increase the variance .",
    "summing up , the method of pathwise control variates is intrinsically robust  unlike pathwise importance sampling ( [ f : exactmu ] ) .",
    "the control variate @xmath58 can be drawn by a quadrature of ito s integral ( [ f : xicontrolvariate ] ) , or alternatively , by enlarging system ( [ f : vr_milstein_sys ] ) with one extra equation : @xmath156    importantly , the same pathwise control variate can be used for parabolic bvps and bcs involving derivatives .",
    "we close this section by adressing the choice of integrator @xmath98 for solving ( [ f : vr_milstein_sys ] ) with @xmath157 and @xmath158 .",
    "the simplest integrator for bounded sdes is the euler - maruyama scheme plus a naive boundary test .",
    "this yields @xmath159 , which is much poorer than the linear rate of weak convergence of the euler - maruyama integrator in free space . however , if the solution , coefficients , and boundary of the bvp are smooth enough , then there are a variety of methods which manage to raise @xmath43 to one ",
    "see @xcite for a recent review .",
    "in particular , the integrator of gobet and menozzi restores weak linearity of the euler - maruyama scheme by simply shrinking the domain ( algorithm [ a : gobet_menozzi ] ) .",
    "@xmath160    [ a : gobet_menozzi ]    in algorithm [ a : gobet_menozzi ] , @xmath161 is the signed distance from @xmath162 to @xmath96 with the convention that it is negative inside @xmath0 ( see @xcite for further details ) ; @xmath163 is the approximation to @xmath53 ; @xmath164 is a @xmath165dimensional standard normal distribution ; and @xmath166 is the projection of @xmath167 on @xmath96 along the outward normal @xmath168 ( @xmath0 is supposed smooth enough that such projection exists and is unique ) .",
    "[ d : balanced_mc_simulation ] a balanced mc simulation with accuracy @xmath40 and confidence interval @xmath41 is such that : statistical error = @xmath169 = absolute value of signed bias .    a balanced mc simulation is thus one guaranteed to attain a total @xmath170 ( [ f : mse_error ] ) smaller than @xmath40 ( with a probability @xmath41 ) with the least computational complexity ( cost ) , because it takes the largest possible @xmath104 and the fewest possible realizations compatible with @xmath171 and @xmath41 , namely    @xmath172}{a^2}\\qquad\\textrm {   and   } \\qquad h=\\big ( \\frac{a}{2|\\beta| } \\big)^{1/\\delta}.\\ ] ]    ( we remark in passing that , while splitting the total error between bias and variance looks natural enough , it is definitely suboptimal @xcite . )",
    "the average number of steps before hitting the boundary is @xmath173/h,\\ ] ]    where mean first exit time , @xmath174 $ ] , is well defined for a given bvp and @xmath175 . on average , every trajectory makes @xmath176 visits to the integrator @xmath98 . for a balanced mc simulation and a tolerance @xmath40 , the expected",
    "cost is , then : @xmath177/h= 4q^2e[\\tau](2|\\beta|)^{1/\\delta}\\frac{v[\\phi]}{a^{2 + 1/\\delta}}:= k\\frac{v[\\phi]}{a^{2 + 1/\\delta}}.\\ ] ]    using control variates to reduce the variance , the trajectories remain the same , but the cost per timestep is increased by a factor @xmath178 .",
    "this is due to the extra cost of interpolating the control variates from a lookup table and evaluating the extra term @xmath126 in ( [ f : vr_milstein_sys ] ) . inserting ( [ f : variance_reduction ] ) ,",
    "the pointwise cost with control variates is    @xmath179(1-\\rho^2[\\phi,\\xi])}{a^{2 + 1/\\delta}}.\\ ] ]    the cost of a global pdd approximation @xmath180 with plainpdd(@xmath47 ) is then    @xmath181}{a_0^{2 + 1/\\delta}},\\ ] ]    @xmath182 is the cost ( independent of @xmath47 ) involved in solving all the subdomains once the interfacial values are available . finally , @xmath183 \\bigg ( \\big(\\frac{a_0}{a_1}\\big)^{2 + 1/\\delta } + \\kappa\\big(1-\\rho_i^2[\\phi,\\xi]\\big ) \\bigg).\\ ] ]    above",
    ", @xmath184 is the cost ( independent of @xmath47 and @xmath64 ) of constructing and storing @xmath185 with @xmath186plainpdd@xmath187 , and @xmath188 $ ] depends on @xmath64 only as long as there are no quadrature errors ( ie as @xmath116 ) .",
    "the results in this subsection are exact ( within the assumptions ) in the limit @xmath116 ; approximations are left to section [ s : approximations ] . to the best of our knowledge",
    ", they are also new .",
    "let us introduce the following notation :    * @xmath190 , with @xmath191 means that @xmath192 is some realization of the distribution @xmath193 .",
    "the notation @xmath194 denotes a specific realization , labeled with the chance variable @xmath195 .",
    "thus , @xmath194 is the same as @xmath190 , but the former considers @xmath196 fixed and treats @xmath192 as a scalar ( or vector ) .",
    "* @xmath197 is an @xmath198-dimensional standard normal distribution , with @xmath199 ( by default ) , or known from the context .",
    "for instance , @xmath200 is the realization labeled by @xmath195 . *",
    "the notation @xmath201 means that the stochastic variable @xmath192 ( which may depend on several parameters represented by the first argument ) is constructed based on a pdd simulation with nodal statistical errors labeled with @xmath202 , where @xmath203 labels the statistical error on node @xmath204 .",
    "( an arbitrary node is denoted by @xmath175 and @xmath205 . )",
    "[ th : lema1 ] let @xmath7 and @xmath192 be stochastic variables , @xmath58 an exact control variate for @xmath7 , and assume that @xmath206,v[\\xi]$ ] and @xmath207 $ ] are finite .",
    "it holds :    1 .",
    "@xmath208=v[\\phi]$ ] .",
    "@xmath209=-v[\\phi]\\leq 0.$ ] 3 .",
    "@xmath210=-cov[\\phi,\\eta]$ ] .    _ proof .",
    "_ we will make use of the cauchy - schwarz inequality @xmath211|\\leq \\sqrt{v[a]v[b]}$ ] for @xmath40,@xmath212 with finite variances .",
    "notice first that @xmath213=0=v[\\phi]+v[\\xi]+cov[\\phi,\\xi]$ ] , so that @xmath209 $ ] can not be positive .",
    "for the first result , note that @xmath214|=-cov[\\phi,\\xi]$ ] , and using the cauchy - schwarz inequality , @xmath215v[\\xi]}-2cov[\\phi,\\xi]\\leq 0 $ ] . summing this and @xmath206+v[\\xi]+2cov[\\phi,\\xi]=0 $ ] yields @xmath216 + v[\\xi ] - 2\\sqrt{v[\\phi]v[\\xi]}= \\big(\\sqrt{v[\\phi ] } - \\sqrt{v[\\xi ] } \\,\\big)^2\\ ] ] which can only happen if @xmath206=v[\\xi]$ ] .",
    "then , it is clear that @xmath217=-2v[\\phi]$ ] .",
    "finally , @xmath218|\\leq \\sqrt{v[\\phi+\\xi]v[\\eta]}=0 $ ] , so that @xmath219=cov[\\phi,\\eta]+cov[\\xi,\\eta]=0 $ ] and the third result follows .",
    "@xmath220    the central limit theorem behind the estimates for the statistical error in ( [ f : statistical_error ] ) assumes that monte carlo errors are normally distributed .",
    "moreover , they are biased due to discretization .",
    "lemma [ th : lema3 ] makes this assumption explicit .",
    "[ th : lema3 ] let @xmath221/n}{\\cal n}$ ] .",
    "then @xmath222=\\beta h^{\\delta}$ ] and @xmath223=\\beta^2h^{2\\delta}+v[\\phi]/n$ ] .",
    "_ the first moment is trivial . for the mse ,",
    "just notice that @xmath223= e[(\\beta h^{\\delta}+\\sqrt{v[\\phi]/n}{\\cal n})^2]= \\beta^2h^{2\\delta } + ( v[\\phi]/n)e[{\\cal n}^2 ] + \\beta\\sqrt{v[\\phi]/n}e[{\\cal n}]$ ] .",
    "the distribution of @xmath224 defined in lemma [ th : lema3 ] results from combining the central limit theorem in ( [ f : statistical_error ] ) with the @xmath225 in ( [ f : mse_error ] ) .",
    "it is natural enough and further justified by the match of the first two moments of the error , but rigourous only asymptotically as @xmath116 .    in order to track errors from the nodal values into the subdomains",
    ", one needs to know how they are propagated by the interfacial interpolators .",
    "definition [ d : linear_interpolator ] introduces the relevant notation and properties .",
    "[ d : linear_interpolator ] let @xmath226 be real constants , @xmath227 a set of @xmath228 distinct points in @xmath229 ; @xmath230 and @xmath231 two sets of scalars associated to the points in @xmath232 , and @xmath233 a function .",
    "let @xmath234({\\bf x}):\\gamma\\mapsto{\\mathbb r}$ ] be a smooth approximation to @xmath235 obtained by interpolation of @xmath236 .",
    "we say that @xmath237 is a linear interpolator if @xmath238({\\bf x})= \\lambda r[u_i\\,|\\,{\\bf x}_i\\in\\gamma]({\\bf x } ) + \\mu r[v_i\\,|\\,{\\bf x}_i\\in\\gamma]({\\bf x } ) , \\qquad { \\bf x}\\in{\\gamma}.\\ ] ] for some norm @xmath239 in @xmath232 we call the interpolation error @xmath240-z||.\\ ] ]    the most common interpolation schemes are linear in the sense of definition [ d : linear_interpolator]for instance , rbf interpolation @xcite .",
    "[ d : error_propagation_function ] the error propagation function @xmath241 for the elliptic bvp ( [ f : ellipticbvp ] ) in the subdomain @xmath242 is defined as @xmath243 where @xmath244 and @xmath245 are respectively the solution of the deterministic and stochastic bvps @xmath246({\\bf x } ) \\\\",
    "{ \\tilde w}_k({\\bf x};{\\bm\\omegaup})= r[\\,{\\cal n}(\\omega_i)\\,|\\,{\\bf x}_i\\in\\gamma_j^k\\,]({\\bf x } ) \\end{array } \\right\\ } & \\textrm { if } & { \\bf x}\\in\\gamma_j^k,\\,1\\leq j \\leq m_k . \\end{array } \\right.\\ ] ]    [ d : definition_of_psi ] let @xmath53 , @xmath52 , @xmath247 , @xmath248 , and @xmath54 be the same as in ( [ f : xicontrolvariate ] ) .",
    "for a fixed @xmath249 , @xmath250    thanks to the smoothness of the iterfacial interpolator , gradients inside @xmath20 are well defined , and thus the integral in ( [ f : definition_of_psi ] ) is also well defined regardless of the continuity of @xmath251 across the interfaces .",
    "we are now prepared to state the main theoretical result .",
    "[ th : teorema ] assume an elliptic bvp with dirichlet bcs like ( [ f : ellipticbvp ] ) with exact solution @xmath37 , and let @xmath252 be a pdd simulation of it in the limit @xmath116 , with accuracy @xmath253 , nodal statistical errors labeled by @xmath196 , balanced mc simulations , and smooth linear interpolator @xmath237 . let @xmath254 be the control variate at a given interfacial node @xmath255 constructed from @xmath252 according to ( [ f : xicontrolvariate ] )",
    ". then @xmath256 } v[\\xi(a;{\\bm\\omegaup } ) ] = v[\\phi]-cov[\\phi,\\psi(\\bm\\omegaup)]\\,a+v[\\psi(\\bm\\omegaup)]\\big(\\frac{a}{2}\\big)^2 + { \\cal o}\\bigg(\\sum_{k=1}^m\\sum_{j=1}^{m_k}\\epsilonup_u|_{\\gamma_j^k}\\bigg ) + { \\cal o}\\bigg(\\sum_{k=1}^m\\epsilonup_{\\omega_k}(a)\\bigg)\\ ] ] and @xmath257 =   -\\sqrt{\\frac{v[\\phi]}{v[\\xi(a;{\\bm\\omegaup } ) ] } } + \\frac{cov[\\phi,\\psi({\\bm\\omegaup})]}{\\sqrt{v[\\phi]v[\\xi(a;{\\boldsymbol\\omega})]}}\\frac{a}{2 } + { \\cal o}\\bigg(\\sum_{k=1}^m\\sum_{j=1}^{m_k}\\epsilonup_u|_{\\gamma_j^k}\\bigg ) + { \\cal o}\\bigg(\\sum_{k=1}^m\\epsilonup_{\\omega_k}(a)\\bigg),\\ ] ] where @xmath258 is the auxiliar variate defined by ( [ f : definition_of_psi ] ) , @xmath259 the error of interpolating @xmath155 along an interface @xmath232 , and @xmath260 is the error of the pdd subdomain solver .    _",
    "_ let us consider the integral representation of the solution of ( [ f : ellipticbvp ] ) @xmath261 where @xmath262 and @xmath263 is green s function , defined as the solution of @xmath264 under the adequate smoothness requirements on @xmath81 and @xmath96 the solution @xmath263 to the homogeneous bvp ( [ f : green_g ] ) exists and is unique , which ensures the validity of ( [ f : green_representation ] ) @xcite .",
    "consider the solution restricted to subdomain @xmath20 . since @xmath263 does not depend on the boundary data , @xmath265 can also be represented as @xmath266 on the other hand , the pdd subdomain approximation is affected by the error of the subdomain solver , @xmath267 , which depends on @xmath40 due to the bc along the interfaces : @xmath268 in the limit @xmath116 , the nodal values are given by the distribution in lemma [ th : lema3 ] .",
    "running a pdd simulation with balanced mc simulations , tolerance @xmath40 and probability @xmath41 , is then equivalent to fixing @xmath196 and taking @xmath269 ( note that the statistical error , and hence @xmath196 , are only known after running the pdd simulation . )",
    "the dirichlet bc condition on an interface @xmath232 is then @xmath270({\\bf x})= u|_{\\gamma}({\\bf x})+\\frac{a}{2}r\\big[\\,sign\\big(\\beta({\\bf x}_i)\\big)+\\frac{1}{q}{\\cal n}(\\omega_i)\\,|\\,{{\\bf x}_i\\in\\gamma}\\,\\big]({\\bf x } ) + { \\cal o}(\\epsilonup_u|_{\\gamma}).\\ ] ] inserting ( [ f : v_restricted_to_gamma ] ) into ( [ f : greens_representation_of_vk ] ) : @xmath271({\\bf",
    "y})d^{d-1}{\\bf y}+\\\\\\nonumber    + { \\cal o}\\bigg(\\sum_{j=1}^{m_k}\\epsilonup_u|_{\\gamma_j^k}\\bigg )   + \\epsilonup_{\\omega_k}(a).\\end{aligned}\\ ] ]    since @xmath237 is a smooth interpolator , gradients are well defined inside @xmath20 and along the interfaces , but not necessarily across them . in order to circumvent this issue",
    "we take the direct sum of subdomain gradients , @xmath272    where @xmath273({\\bf y})d^{d-1}{\\bf y}\\bigg).\\ ] ]    note that the quantity in parentheses in ( [ f : aux1 ] ) is the green representation of the bvp with solution @xmath274 ( [ f : error_propagation_function ] ) , by linearity . now , according to definitions ( [ f : xicontrolvariate ] ) and ( [ f : definition_of_psi ] ) for node @xmath175 ,    @xmath275    in ( [ f : xi(a ) ] ) , we have used the fact that @xmath276 except on the interfaces .",
    "since the interfaces are smooth and the random paths are not , the trajectories cross the interfaces at isolated points which make no contribution to the integral , so that @xmath277 .",
    "taking the variance of ( [ f : xi(a ) ] ) and using lemma [ th : lema1 ] yields ( [ f : v[xi(a , w ) ] ] ) .",
    "moreover ,    @xmath278= cov[\\phi,\\xi ] + \\frac{a}{2}\\,cov[\\phi,\\psi({\\boldsymbol\\omega ) } ] + { \\cal o}\\bigg(\\sum_{k=1}^m\\sum_{j=1}^{m_k}\\epsilonup_u|_{\\gamma_j^k}\\bigg ) + { \\cal o}\\bigg(\\sum_{k=1}^m\\epsilonup_{\\omega_k}(a)\\bigg).\\ ] ]    finally , equation ( [ f : rho(a , w ) ] ) follows from @xmath279=cov[\\phi,\\xi(a;\\boldsymbol\\omega)]/\\sqrt{v[\\phi]v[\\xi(a;{\\boldsymbol\\omega})]}$ ] recalling that the correlation with the exact control variate is @xmath280 by lemma [ th : lema1 ] .",
    "@xmath281 + the point of lemma [ th : teorema ] is to predict the correlation between the score @xmath7 and an approximate control variate @xmath282 without actually running a pdd simulation to produce the latter  but rather `` simulating '' it . in exchange ,",
    "the variable @xmath283 must be computed , but it can be constructed on a subdomain - per - subdomain basis , i.e. in a fully parallellizable way .",
    "the drawback is that the formulas derived so far are only rigourous at @xmath284 , and that they depend on quite a few problem - dependent constants  many of them node - dependent as well .",
    "these difficulties will be addressed in section [ s : approximations ] .",
    "but before that , we shall examine the issues of global error and stability of pdd , and introduce some more results which will later be useful in assessing the necessary simplifications .",
    "the main tool is theorem 3.7 in gilbarg and trudinger :    [ th : gandt ] let @xmath285 be the solution of an elliptic bvp like ( [ f : ellipticbvp ] ) with @xmath84 , such that @xmath285 is continuous on @xmath286 and twice differentiable on @xmath96 .",
    "then @xmath287 where @xmath288 is a constant depending only on @xmath289 and @xmath290 .",
    "in particular , if @xmath0 lies between two parallel planes a distance @xmath291 apart , then ( [ f : gandt ] ) is satisfied with @xmath292}-1 $ ] .",
    "recall that @xmath293 $ ] , and @xmath289 is the largest distance between two points in @xmath0 .",
    "it is convenient to introduce the following parameter :    [ d : overshoot ] let @xmath237 be a linear interpolator and @xmath232 a subdomain interface with nodes @xmath294 .",
    "let @xmath295 be @xmath296 scalars such that @xmath297 .",
    "the overshoot constant of @xmath237 with respect to the discretization @xmath298 of @xmath232 is defined as @xmath299({\\bf x})\\big|.\\ ] ] analogously , let @xmath300 and @xmath301 .",
    "the overshoot constant measures the excess of the reconstructed function over any of the interpolated values which are @xmath302 in absolute value . for piecewise interpolation , @xmath303 , but for more accurate interpolators",
    ", @xmath304 due to the runge and gibbs phenomena @xcite  see figure [ i : figura3 ] ( right ) for illustration .",
    "we are interested in bounding the largest pdd error throughout @xmath0 .",
    "assuming as always balanced mc simulations , and neglecting the error of the subdomain solver , the pdd error in subdomain @xmath20 obeys @xmath305({\\bf x } ) & \\textrm{if $ { \\bf x}\\in\\gamma_j^k,\\,1\\leq j\\leq m_k.$ } \\end{array } \\right.\\ ] ]    therefore , @xmath306hence the name of error propagation function . applying theorem [ th : gandt ] to ( [ f : error_pde ] ) and by linearity of @xmath237 ,    @xmath307({\\bf x})\\big| \\leq \\frac{aq_k\\gamma_r^{\\omega_k}}{2}\\big ( 1 +   \\frac{1}{q}\\sup_{{\\bf x}_i\\in\\omega_k}|{\\cal n}(\\omegaup_i)|\\big),\\ ] ]    where @xmath308 depends on the size and shape of @xmath20 and @xmath309 .",
    "thanks to the symmetry of the standard normal distribution around zero , @xmath310 , so that the _ global _ pdd error ( neglecting the error of the subdomain solver ) can be bounded by    @xmath311    equation ( [ f : global_pdd_error_bound ] ) reflects that the global pdd error depends on pde coefficients in ( [ f : ellipticbvp ] ) , on the shape and size @xmath312 of the subdomains ( typically , @xmath313 ) , and on the number of nodes per subdomain ( typically , around @xmath314 ) , rather than on @xmath315 and @xmath316 . therefore , pdd is intrinsically stable provided that the number , shape and discretization of the subdomains are so chosen that the subdomain errors are controlled",
    ".    we will now derive the nodal tolerance @xmath317 required to enforce a set global pdd error tolerance @xmath318 . recall that @xmath319 is the total number of interfacial nodes sitting on @xmath19 .",
    "the distribution @xmath320 is an _ extreme value _ distribution .",
    "the value @xmath319 for which its maximum is less than @xmath321 with probability @xmath41 is to be extracted from @xmath322^{-1}(p_q ) \\textrm {   ( such that } pr[\\sup_{1\\leq j\\leq n_k } { \\cal n}(\\omega_j ) < x ] = p_q.)\\ ] ] where @xmath323 $ ] and @xmath323^{-1}$ ] stand for the cumulative distribution function ( cdf ) of a given distribution and its inverse , respectively .",
    "let @xmath324^{-1}(p_q)\\big)\\ ] ] and define @xmath325 since the @xmath198 standard normals in @xmath326 are i.i.d . , the cdf is    @xmath327(x)= \\int_{-\\infty}^x s_s(t ) dt= pr[\\big({\\cal n}_1\\leq x\\big)\\cap \\ldots \\cap \\big({\\cal n}_s\\leq x\\big)]= \\big ( cdf[{\\cal n}](x ) \\big)^s . \\ ] ]    for the standard normal distribution @xmath328(x)= \\frac{1}{2\\pi}\\int_{-\\infty}^xe^{-t^2}dt= \\frac{1}{2}\\big ( 1+\\textrm{erf}(x/\\sqrt{2 } ) \\big),\\ ] ]    where erf@xmath329 is the error function .",
    "the nodal target tolerance @xmath47 can then be related to the global pdd error tolerance by    @xmath330    as figure [ i : figura2 ] shows , @xmath331 depends very mildly on the typical number of nodes per subdomain .",
    "anyway , the bound ( [ f : a(eps ) ] ) will be a large overestimation in many cases , for the effect of the statistical errors decays fast away from the interfaces .",
    "if the moments of @xmath332 were required , a useful fact is that as @xmath198 grows , @xmath326 tends to the gumbel distribution @xmath333(x)= g\\big(\\frac{x - l_s}{b_s}\\big):= \\exp[-e^{-x}]\\ ] ] with location and scaling parameters @xmath334^{-1}(1/s)$ ] and @xmath335 .     from ( [ f : a(eps ) ] ) as a function of @xmath198 for several values of @xmath336 and @xmath337 ( notice the different scales ) . ]",
    "in order to construct an implementable multigrid - like iterpdd algorithm , several approximations are needed , which are listed as heuristics @xmath338 through @xmath339 below .",
    "this assumption is used on several occasions in * h2 * -*h5*.      interfacial interpolation errors in ( [ f : v[xi(a , w ) ] ] ) and ( [ f : rho(a , w ) ] ) will be dropped .",
    "then , inserting ( [ f : v[xi(a , w ) ] ] ) into ( [ f : rho(a , w ) ] ) yields , after some manipulation , @xmath341 \\gtrsim \\frac{\\frac{v[\\psi({\\bm\\omegaup})]}{v[\\phi]}\\big(1-\\rho^2[\\phi,\\psi(\\bm\\omegaup)]\\big)(a/2)^2 } { 1 -\\sqrt{\\frac{v[\\psi(\\bm\\omegaup)]}{v[\\phi]}}\\rho[\\phi,\\psi(\\bm\\omegaup)]a + \\frac{v[\\psi(\\bm\\omegaup)]}{v[\\phi]}(a/2)^2},\\ ] ]    where the sign @xmath342 has replaced the equality to make up for dropping the interpolation and subdomain - solver errors . next , note that @xmath343}{v[\\phi ] } \\gtrsim 1-\\rho^2[\\phi,\\xi(a;{\\bm\\omegaup})],\\ ] ]    since ( [ f : variance_reduction ] ) only strictly holds for the minimizer of ( [ f : statistics_vr ] ) , and with @xmath253 , the pdd solution @xmath136 yields a control variate off the minimizer , regardless of @xmath104 . note also that the denominator in ( [ f : aux2 ] ) is positive , since @xmath344|\\leq 1 $ ] :    @xmath345}{v[\\phi]}}\\rho[\\phi,\\psi(\\bm\\omegaup)]a + \\frac{v[\\psi(\\bm\\omegaup)]}{v[\\phi]}(a/2)^2 \\geq \\bigg(1-\\sqrt{\\frac{v[\\psi({\\bm\\omegaup})]}{v[\\phi]}}(a/2)\\bigg)^2.\\ ] ]    for small @xmath40 ( see * h1 * ) , the denominator in ( [ f : aux2 ] ) can be dropped .",
    "more precisely , since the mc simulations are balanced , @xmath346}{v[\\phi]}}\\frac{a}{2}=q\\sqrt{\\frac{v[\\psi({\\bm\\omegaup})]}{n}},\\ ] ]    which is negligible if @xmath347<<n$]recall that this @xmath348 is meant without variance reduction , and @xmath347={\\cal o}(v[\\bar\\psi])$ ] is bounded by ( [ f : v[barpsi ] ] ) in * h4 * below . assuming this and putting all together , it holds    @xmath349}{v[\\phi]}\\gtrsim \\frac{v[{\\psi({\\bm\\omegaup})}]a^2}{4v[\\phi]}\\big ( 1-\\rho^2[\\phi,{\\psi({\\bm\\omegaup})}]\\big).\\ ] ]    the importance of ( [ f : the_key ] ) is that the two factors affecting iterpdd  namely @xmath40 and the random statistical errors on the nodes  have been separated .",
    "moreover , the latter has been expressed in terms of @xmath347 $ ] and @xmath350 $ ] . also ,    * if the score @xmath7 and the auxiliar variate @xmath283 were perfectly correlated ( i.e. @xmath351=1 $ ] ) , then @xmath352=0 $ ] , meaning that @xmath353 . since this can only happen",
    "if @xmath354 , the solution would be @xmath355 .",
    "* the opposite limit , @xmath356=0 $ ] , yields asymptotically @xmath357}{v[\\phi]}= \\frac{v[\\psi({\\bm\\omegaup})]}{v[\\phi]}(a/2)^2.\\ ] ]      the propagation of nodal statistical errors ( labeled with @xmath196 ) onto the subdomain solutions in critical in pdd . in section [ s : globalerror ] , it was shown that the effect of @xmath196 on the pdd aggregate error can be controlled on a subdomain - per - subdomain basis . in iterpdd(@xmath359 ) , there are two further aspects to @xmath196 .",
    "first , how much the variance reduction produced by @xmath360 depends on the chance variable .",
    "second , how it affects the decrease predicted by ( [ f : the_key])for @xmath64 will be determined based on that formula .",
    "in particular , the nodal simulations will in turn be `` simulated '' themselves by randomly drawing a chance variable ",
    "say @xmath361and computing @xmath362 $ ] and @xmath363 $ ] .",
    "[ th : e[w ] ] let @xmath364 $ ] be the expected value relative to @xmath358 and assume that interpolation errors are negligible .",
    "then , @xmath365=0 $ ] ( @xmath366 ) .    _ proof . _",
    "the green function representation of @xmath367 is @xmath368({\\bf y})d^{d-1}{\\bf y},\\ ] ]    where @xmath263 is determined by ( [ f : green_g ] ) and is deterministic . by linearity of the integral , the interpolator , and the expected value , @xmath369= \\sum_{j=1}^{m_k}\\int_{\\gamma_j^k } \\frac{\\partial g({\\bf x},{\\bf y})|_{\\omega_k}}{\\partial { \\bf n}}r\\big[e_{\\bm\\omegaup}[{\\cal n}({\\omegaup_i})]\\,|\\,{\\bf x}_i\\in\\gamma_j^k\\big]({\\bf y})d^{d-1}{\\bf y}= \\\\\\nonumber \\sum_{j=1}^{m_k}\\int_{\\gamma_j^k } \\frac{\\partial g({\\bf x},{\\bf y})|_{\\omega_k}}{\\partial { \\bf n } } \\big ( 0 + \\epsilon_0|_{\\gamma_j^k } \\big)d^{d-1}{\\bf y } , \\end{aligned}\\ ] ] where @xmath370 is the error in the reconstruction of the constant function @xmath371 on the interface @xmath31 with @xmath237 , and which is zero by hypothesis .",
    "@xmath372    as a consequence of lemma [ th : e[w ] ] , @xmath373=\\nabla e_{\\bm\\omegaup}[{\\tilde w}_k]=0 $ ] , and thus @xmath374= \\int_0^{\\tau}y_t\\sigma^t\\sum\\limits_{k=1}^m\\nabla\\big({\\bar w}_k+\\frac{1}{q}e_{\\bm\\omegaup}[{\\tilde w}_k]\\big)d{\\bf w}_t=   \\int_0^{\\tau}y_t\\sigma^t\\sum\\limits_{k=1}^m\\nabla{\\bar w}_kd{\\bf w}_t= : { \\bar \\psi}.\\ ] ]    the variance can be calculated by ito s isometry :    @xmath375= e\\big[\\,\\int_0^{\\tau } y_t^2({\\bf x}_t)||\\sigma^t({\\bf x}_t)\\sum\\limits_{k=1}^m\\nabla w_k({\\bf x}_t,{\\bm\\omegaup})||^2_2\\,dt\\,\\big],\\ ] ]    where @xmath376 . by the triangular inequality and the inequalities    @xmath377 }",
    "e_{\\bm\\omegaup}\\big[\\ , v[\\psi({\\bm\\omegaup } ) ] \\,\\big]\\leq v[{\\bar \\psi } ] + \\frac{2\\lambda\\,e\\big[\\int_0^{\\tau}y_t^2({\\bf x}_t)dt\\,\\big]}{q^2 } \\,e_{\\bm\\omegaup}\\big[\\,\\big(\\sup_{{\\bf x}\\in\\omega}||\\sum\\limits_{k=1}^m{\\nabla\\tilde w}_k({\\bf x};{\\bm\\omegaup})||_2 ^ 2\\big)\\,\\big].\\end{aligned}\\ ] ]    to the best of the authors knowledge , there are no interior , a priori estimates of the gradient of the solution of ( [ f : ellipticbvp ] ) ( with @xmath378 ) as sharp as the bound provided by ( [ th : gandt ] ) for the solution itself . therefore , based on more particular results such as and",
    ", we make the reasonable assumption that for the pde @xmath379 in @xmath20 with dirichlet bcs on @xmath19 @xmath380    where @xmath381 and @xmath382 are positive and may depend on anything but the value of the dirichlet bc .",
    "then , there exist positive constants @xmath383 and @xmath198 such that @xmath384    the values @xmath385 are the @xmath386 of the subdomain @xmath387 with the largest gradient estimate , and @xmath198 its number of nodes",
    ". the @xmath388 shows up due to the interpolation along the interfaces ; and @xmath389 .",
    "this leads to the bounds    @xmath390 \\leq v[{\\bar\\psi } ] + 2\\lambda e[\\int_0^{\\tau } y_t^2dt]\\frac{1}{q^2}\\big ( k ' + 2\\gamma_r k''\\sup\\limits_{1\\leq j \\leq s } { \\cal n}(\\omegaup_j ) \\big)^2 = : v[{\\bar\\psi } ] + { { \\tilde v}({\\bm\\omegaup})},\\ ] ]    @xmath391 } v[{\\bar\\psi}]\\leq 2\\lambda e[\\int_0^{\\tau } y_t^2dt](k'+\\gamma_r k'')^2 = : { \\bar v}.\\ ] ]    as the final preparatory step , let us calculate the noise - to - signal ratio ( nsr)defined as @xmath392=\\sqrt{v[\\cdot]}/e[\\cdot]$]of the variable @xmath393 ( [ f : nsr ] ) : @xmath394}}{e_{{\\bm\\omegaup}}[{\\bar v}+{\\tilde v}({\\bm\\omegaup})]}= \\frac{\\sqrt{v_{\\bm\\omegaup}\\big[\\big(1 + 2\\gamma_r\\frac{\\textrm{k'}}{\\textrm{k''}}\\sup\\limits_{1\\leq j \\leq s}{\\cal n}(\\omegaup_j)\\big)^2\\big ] } } { q^2\\big(1+\\gamma_r\\frac{\\textrm{k'}}{\\textrm{k''}}\\big)^2+e_{\\bm\\omegaup}\\big [ \\big(1 + 2\\gamma_r\\frac{\\textrm{k'}}{\\textrm{k''}}\\sup\\limits_{1\\leq j \\leq s}{\\cal n}(\\omegaup_j)\\big)^2 \\big]}.\\ ] ]    @xmath395    we are finally in a position to precisely estate our claim and the supporting heuristic .",
    "the ultimate goal is to use the deterministic value @xmath396 $ ] instead of a random @xmath347 $ ] yielded by one simulation ( note that @xmath396\\leq e_{{\\bm\\omegaup}}\\big[v[\\psi({\\bm\\omegaup})]\\big]$ ] ) .",
    "therefore , it is important that the ratio @xmath397\\big]}/e_{{\\bm\\omegaup}}\\big[v[\\psi({\\bm\\omegaup})]\\big]$ ] be small so that @xmath398:=v[{\\bar\\psi}]\\approx v[\\psi({\\bm\\omegaup})]$ ] .",
    "this ratio is problem - dependent but , in order to provide a rough estimate , we substitute @xmath347 $ ] by its upper bound @xmath393 .",
    "then , we simulate the nsr of the bound ( table [ t : nsr ] ) for realistic values @xmath399 and over a broad range of @xmath400 ( which captures the effect of the @xmath81 , @xmath51 , the geometry @xmath0 , and the pdd partition @xmath401 ) , and the typical number of nodes per subdomain , @xmath198 .",
    "since the nsr of the proxy is negligible in most of the scenarios ( and specially as @xmath198 grows ) , we argue that the same should hold for @xmath347 $ ] .",
    "obviously , specific problems would allow for sharper estimates .",
    "given @xmath47 and its corresponding timestep @xmath402 from ( [ f : n_y_h ] ) , the correlation between @xmath7 and @xmath403 is better than between their discretized counterparts @xmath404 and @xmath405 .",
    "this leads to an overestimation of the predicted decrease of variance and has a significant effect , especially if @xmath40 and @xmath47 are comparable , or if @xmath151\\gtrsim.99 $ ] .",
    "we invoke * h1 * to justify the following perturbative ansatz : @xmath406\\approx cov[\\phi,\\xi(a;{\\bm\\omegaup})]+b_{\\xi}\\big ( cov[\\phi_{h_0},\\xi_{h_0 } ] \\big),\\ ] ]    where @xmath407 \\big)$ ] is the discrete covariance bias . since @xmath408=e[\\phi_{h_0}\\xi_{h_0}]-u_{h_0}e[\\xi_{h_0}])]$ ] and @xmath402 is small enough , @xmath407 \\big)= { \\cal o}(h_0^{\\delta})$ ] .",
    "that covariance bias does not seem accessible without having @xmath409 , but we can use the fact that @xmath209=-v[\\phi]$ ] ( lemma [ th : lema1 ] ) to argue that @xmath410 \\big)\\big|\\approx \\big|b_{\\xi}\\big ( v[\\phi_{h_0 } ] \\big)\\big|=:|\\alpha|h^{\\delta},\\ ] ] which can be extracted from a fit ( see * h5 * ) . then , assuming further that @xmath411}\\approx \\frac{1}{v[\\phi ] } \\qquad\\textrm {    and    } \\qquad \\frac{1}{v[\\xi_{h_0}(a;{\\bm\\omegaup})]}\\approx \\frac{1}{v[\\xi(a)]},\\ ] ]    the squared correlation of the discretized variables is    @xmath412 \\approx \\rho^2[\\phi,\\xi(a;{\\bm\\omegaup } ) ] - \\frac{2\\big|\\alpha\\rho[\\phi,\\xi(a;{\\bm\\omegaup})]\\big|}{v[\\phi]}h_0^{\\delta},\\ ] ]    and since @xmath413 , the effective variance reduction in iterpdd(@xmath414 ) is    @xmath415}{v[\\phi_{h_0}]}\\approx \\frac{v[\\phi+\\xi(a;{\\bm\\omegaup})]}{v[\\phi ] } + \\big|\\frac{\\alpha\\rho[\\phi,\\xi(a)]}{\\beta v[\\phi ] } \\big|a_0.\\ ] ]    for @xmath47 small enough , as @xmath416 , @xmath417|\\shortrightarrow 1 ^ -$ ] , so ( [ f : final_formula ] ) is capped by @xmath418}{v[\\phi_{h_0 } ] }   = \\big| \\frac{\\alpha}{\\beta v[\\phi ] } \\big|a_0= \\frac{2|b_{\\xi}(v[\\phi])|}{v[\\phi]}. \\end{aligned}\\ ] ]    this makes intuitively sense , because the variance of the score can hardly drop below its discretization error , even with an exact control variate .      in order to apply the sensitivity formula ( [ f : sensitivity_formula ] ) and algorithms [ a : iterpdd ] and [ a : scheduling ] ,",
    "a number of constants must be estimated . here",
    ", we describe a fast way of accomplishing this .",
    "we stress the fact that any monte carlo simulation ( whether or not related to pdd ) also would require @xmath419 and @xmath206 $ ] in order to enforce a set error tolerance .    * global constants ( @xmath43 and @xmath420 ) .",
    "* as already discussed , with smooth bvps , integrators with at least approximately known @xmath43 should be available @xcite .",
    "the constant @xmath420 can easily be found by comparing the time taken by the computer to complete a number of visits to the implementations of ( [ f : vr_milstein_sys ] ) with and without @xmath126 .    * nodal constants related to first moments .",
    "* they are @xmath174 $ ] ( needed for @xmath421 ) , @xmath422 $ ] , and @xmath106 .",
    "we consider a generic discretized random variable @xmath423 , and assume that its first moment obeys the noisy model @xmath424\\sim e[\\eta_0 ] + { \\cal n}(b^{(1)}h^{\\delta},v[\\eta_0]).\\ ] ]    let @xmath425 be a cloud of @xmath426 equispaced timesteps . set a number @xmath427 and let @xmath428 $ ] be the mean of @xmath427 realizations of @xmath429 . after computing @xmath426 mc independent simulations ,",
    "the cloud of data @xmath430\\big),\\ldots,\\big(h_{\\hat m},{\\hat e}[\\eta_{h_{\\hat m}}]\\big)$ ] is fitted to the noisy model ( [ f : noisy_model_moment1 ] ) in order to extract @xmath431 $ ] and @xmath432 .",
    "( in order to do so , @xmath433 $ ] in ( [ f : noisy_model_moment1 ] ) can be replaced by the mean of the sample variances @xmath434 $ ] . )    here , we provide a rougher recipe to carry out the fit with matlab ( see also @xcite ) . for this purpose , it is convenient to think of model ( [ f : noisy_model_moment1 ] ) as a member of the generalized linear model ( glm ) family .",
    "since @xmath435)]=b^{(1)}h^{\\delta}$ ] , the link is the identity and the fit is readily carried out by issuing the matlab command    .... coeff= glmfit((h.^delta),eh,'normal','link','identity ' ) ....    where ` h ` and ` eh ` above are matlab arrays with respectively @xmath436 and @xmath437, ... ,{\\hat e}[\\eta_{h_{\\hat m}}]\\,)$ ] ; and the components of the output , ` coeff(1 ) ` and ` coeff(2 ) ` , are the fitted values to @xmath431 $ ] and @xmath432 , respectively ( check the matlab documention for getting error bounds alongside ) .    by applying this recipe ,",
    "one gets approximations to the following quantities : if @xmath438 , to @xmath422\\approx { \\hat cov}[\\phi,{\\bar\\psi}]= \\verb|coeff(1)|$ ] ( and to its bias as a byproduct ) ; and if @xmath439 , to @xmath440 and to @xmath102\\approx{\\hat e}[\\phi]=\\verb|coeff(1)|$ ] as a byproduct .",
    "the values @xmath441, ...",
    ",{\\hat e}[\\tau_{h_{\\hat m}}]$ ] are obtained along the means @xmath442, ...",
    ",{\\hat e}[\\phi_{h_{\\hat m}}]$ ] ( see last line in algorithm [ a : gobet_menozzi ] ) , and are used to fit @xmath174 $ ] .",
    "* nodal constants related to second moments . * regarding the fitting of variances , it is well - known that variances of i.i.d .",
    "gaussian distributions obey a scaled chi - squared pdf . accommodating the discretization bias ,",
    "the appropriate noisy model is @xmath443\\sim b^{(2)}h^{\\delta } + \\frac{v[\\eta_0]}{{\\hat",
    "n}-1}\\chiup^2_{{\\hat n}-1}= b^{(2)}h^{\\delta } + \\gamma\\big ( \\frac{{\\hat n}-1}{2},\\frac{2v[\\eta_0]}{{\\hat n}-1}\\big)\\ ] ] where @xmath444 is the chi - squared distribution with @xmath445 degrees of freedom , and @xmath446 is a gamma distribution with shape parameter @xmath447 and scale parameter @xmath448/({\\hat n}-1)$ ] .",
    "then , ( [ f : noisy_model_moment2 ] ) can be identified with a glm where the noise is gamma and the link function is the identity , since    @xmath449\\big]= b^{(2)}h^{\\delta } + e\\big[\\gamma\\big ( \\frac{{\\hat n}-1}{2},\\frac{2v[\\eta_0]}{{\\hat n}-1}\\big)\\big]= b^{(2)}h^{\\delta}+v[\\eta_0].\\ ] ]    let @xmath450= \\sum_{j=1}^{{\\hat n}}(\\eta_h^{(j)}-{\\hat e}[\\eta_h])^2\\big/({\\hat n}-1)$ ] be the sample variance .",
    "after filling the matlab array ` vh ` with @xmath451,\\ldots,{\\hat v}[\\phi_{h_{\\hat m}}]$ ] , issuing the command    .... coeff= glmfit((h.^delta),vh,'gamma','link','identity ' ) ....    yields ` coeff(1)`@xmath452/({\\hat n}-1)$ ] and ` coeff(2)`@xmath453 .",
    "particularizing to @xmath439 allows to estimate @xmath454\\approx v[\\phi]$ ] and @xmath455 ; and to @xmath456 yields the fitted @xmath454\\approx v[{\\bar\\psi}]$ ] ( and its bias ) .",
    "[ a : fitting ]    the full fitting procedure is sketched as algorithm [ a : fitting ] .",
    "note that the same sets of trajectories can be used for all the poinwise constants  it is only the functionals that change .      combining heuristics",
    "* h1 * through * h5 * we put forward the sensitivity formula ( [ f : sensitivity_formula ] ) , based on ( [ f : the_key ] ) and ( [ f : final_formula ] ) with @xmath457 replacing @xmath283 :    @xmath458\\approx \\rho^2[\\phi,\\xi]-\\big|\\frac{\\alpha\\rho[\\phi,\\xi]}{\\beta}\\big|a_0 , \\textrm {   with } \\rho^2[\\phi,\\xi]\\approx \\frac{v[{\\bar\\psi}]a^2}{4v[\\phi]}\\big ( 1-\\rho^2[\\phi,{\\bar\\psi}]\\big).\\ ] ]    with it , a scheduling algorithm could be as algorithm [ a : scheduling ] .",
    "there , the stopping criterion should take into account the quality of the available estimates and thus be problem - dependent .",
    "( we discuss this aspect further on section [ s : experiment ] . )",
    "[ a : scheduling ]    finally , we summarize the new version of pdd in algorithm [ a : iterpdd ] .    [ a : iterpdd ]",
    "we consider a bvp like ( [ f : ellipticbvp ] ) with on the two - dimensional domain sketched in figure [ i : figura1 ] with @xmath459 subdomains , three interfaces and @xmath12 nodes .",
    "the pde is @xmath460 with @xmath461 such that @xmath462 is the exact solution , as well as the dirichlet bc ",
    "see figure [ i : figura3 ] .",
    "the coefficients of the stochastic representation of ( [ f : pde_ejemplo ] ) are : @xmath463 ( @xmath464 is the two - dimensional identity matrix ) , @xmath465\\,/\\big(1.1+\\sin{(x+y)}\\big)$ ] , and @xmath466 .",
    "the integrator is gobet and menozzi s ( algorithm [ a : gobet_menozzi ] ) , for which we assume that @xmath44 ; @xmath237 is an rbf interpolator with multiquadrics @xcite , and the subdomain solver is fem .",
    "the parameters of @xmath237 and fem were so chosen that their errors are negligible compared with the nodal errors .    ) . *",
    "* the bias - related function @xmath467 ( [ f : error_propagation_function ] ) used to generate @xmath457 ( [ f : definition_of_psi ] ) on the subdomain singled out in figure [ i : figura1 ] .",
    "notice the various signs of @xmath468 and the overshoots of the rbf interpolator . in this problem , @xmath469 .",
    "]    with just four small subdomains , it obviously does not take a parallel computer to solve this toy problem  but it serves to test the idea , theory and approximations introduced in this paper in a controlled environment . with that purpose ,",
    "the algorithms have been coded in fully vectorized matlab , and the nodal values and subdomain bvps solved on single processors sequentially .",
    "@xmath470     & 0.16   & 0.16 & 0.16 & 0.17 & 0.19 & 0.47\\\\ \\hline         \\textrm{cost of plainpdd$(a_1)$ } &   & & 1.60\\times 10 ^ 9 & 1.47\\times 10 ^ 7 & 8.43\\times 10 ^ 5 & 65989 \\\\ v[\\phi_{h_1 } ]     & & & 4.92   & 5.10   & 5.45 & 4.08 \\\\ \\big ( \\sum_{i=1}^n |u({\\bf x}_i)-{\\tilde u}_1({\\bf x}_i)| \\big)/n   & \\multicolumn{2}{c|}{\\textrm{use exact $ u$ instead of $ { \\tilde u}(a_1)$ } } & 0.012   & 0.06 & 0.11 & 0.77 \\\\",
    "\\sup_{\\omega}|u-{\\tilde u}_1|   & & & 0.03 & 0.12 & 0.24 & 0.34 \\\\ \\sup_{\\omega}||\\nabla { \\tilde u}_1||_2 & & & 0.87 & 0.94 & 2.14 & 6.61 \\\\ \\hline    s(a_0,a_1 )    & 128.16 & 72.61   & 7.37   & 58.14 & 46.39 & 22.67 \\\\ \\hline                                                                                                 \\hline \\end{array}\\ ] ]    as a preparatory step , we carefully compute @xmath420 and the nodal constants . in particular , the precise values of @xmath471 ensure that the pointwise mc simulations are balanced .",
    "then , we pick @xmath472 ; @xmath473 ; and run a set of @xmath474=$]iterpdd@xmath65 simulations that will serve as reference .",
    "table [ t : illustration ] illustrates some typical quantities . on the column labeled exact , the control variate from the exact solution",
    "@xmath475 has been used , so that all of the error is quadrature error .",
    "this represents the maximum benefit that could possibly be extracted .",
    "otherwise , the approximation @xmath476 is stored on a lookup table ( here , a grid ) , and interpolated from there to compute @xmath63except on the column lookup , where the lookup table has been filled with the exact @xmath477 in order to gauge purely the effect of interpolation .",
    "since the cost of solving the subdomains and filling the lookup tables is negligible , the cost of iterpdd(@xmath359 ) is measured as : @xmath478    where @xmath479 is the number of trajectories from node @xmath204 at @xmath480 , and so on . in table",
    "[ t : illustration ] , @xmath481 is the mean over the @xmath316 nodes of @xmath482\\,\\big|$ ] ; and the speedup of iterpdd over plainpdd is defined as @xmath483     over plainpdd@xmath66 .",
    "the symbols denote the reference ( balanced ) pdd simulations . in order to show the trend ,",
    "they have been approximated with smoothing splines ( solid color curves ) .",
    "* dashed curves * : predicted speedup , based on the sensitivity formula ( [ f : sensitivity_formula ] ) and fast estimates of constants ( algorithm [ a : fitting ] ) .",
    "although the latter do not lead to balanced mc simulations as with the reference simulations , their maxima calculated with algorithm [ a : scheduling ] ( vertical lines ) are coincident  see also ( * ) on table [ t : schedula ] . ]    on figure [ i : figura4 ] , the values of @xmath484 for the full set of reference simulations are depicted with symbols ( and joined with smoothing splines ) . as @xmath64 grows , the effect of randomness is more significant .",
    "now , we proceed to test algorithm [ a : iterpdd ] proper .",
    "first , we estimate the nodal constants with algorithm [ a : fitting ] , taking ( without trying to optimize in any sense ) , @xmath485 equispaced timesteps @xmath104 in @xmath486 $ ] and @xmath487 .",
    "( the cost of this is comparatively very small . )",
    "a good estimate @xmath488 is straightforward to produce .",
    "based on the resulting fitted constants , we run the scheduling algorithm [ a : scheduling ] in order to get the optimal sequences @xmath489 for the same set @xmath472 as with the reference simulations before .",
    "the minimization ( line @xmath490 in algorithm [ a : scheduling ] ) is carried out with matlab s ` fmincon ` , and stopped as soon as the predicted @xmath491 .",
    "the results , both those predicted by algorithm [ a : scheduling ] , and those actually attained ( using the same set of @xmath492 ) are listed on table [ t : schedula ] .",
    "the cumulative speedup is defined as the cost of iterpdd@xmath493plainpdd@xmath66 .",
    "the speedup curves predicted by algorithm [ a : scheduling ] for @xmath472 are also plotted with dashed lines on figure [ i : figura4 ] , and their maxima highlighted with vertical lines .",
    "a few comments are in order .",
    "@xmath494    even though algorithm [ a : scheduling ] relies on fast estimates of the constants , non - balanced simulations , and neglects the effects of randomness , the predicted speedup curves resemble quite well those obtained from the reference simulations .",
    "in particular , the position of the maxima of both sets are nearly coincident .",
    "moreover , for @xmath359 small enough , algorithm [ a : scheduling ] provides estimates of the costs , speedup and mean correlation ( on figure [ i : figura4 ] and table [ t : schedula ] ) which are consistently conservative , as predicted by the theory in section [ s : approximations ] .",
    "later , when the tolerances @xmath495 are not so small , heuristics * h1-h4 * break down , and the fact that @xmath396<e_{{\\bm\\omegaup}}\\big[v[\\psi({\\bm\\omegaup})]\\big]$ ] begins to tell , so the estimates may not be conservative , but still they are acceptable . in any case , since most of the cumulative speedup is attained on the last iterpdd simulation  i.e .",
    "on iterpdd@xmath65 , as shown on table [ t : schedula]there is not much to gain from iterating iterpdd more than once or twice .    finally , let us mention that running the scheduling algorithm with nodal constants based on @xmath496 instead of @xmath457 ( as we did ) leads to very similar results to those reported .",
    "in fact , in this bvp , it seems that the effect of discretization on @xmath497 $ ] ( [ f : vr_cap ] ) outweighs the effect of randomness in the range of @xmath47 studied . this is why the speedups in table [ t : schedula ] grow linearly with @xmath47 .",
    "importantly , this means that one order of magnitude has been knocked down from the monte carlo cost estimate @xmath498 given in the introduction  see also ( [ f : pointwise_cost ] ) .",
    "therefore , the nodal cost goes now as @xmath499 , which is still larger than for the deterministic subdomain solver  but now in a fully scalable way .",
    "in this paper we have laid out the theoretical foundations of a much improved version of pdd , which we have called iterpdd .",
    "we have analyzed in detail the ingredients of iterpdd and their relative importance .",
    "while the numerical results on the bvp used for illustration are very encouraging , substantially larger and more challenging problems must be tackled in order to assess the real potential of iterpdd .    with this goal ,",
    "the pdd programme is currently being further developed in three main directions : i ) blending it with giles multilevel method along the lines of @xcite ; ii ) extending it to parabolic bvps , mixed bcs , and processors with insufficient memory ; and iii ) producing a c++/mpi code which allows us to perform realistic comparisons with deterministic domain decomposition methods . while nonlinear bvps could be accommodated into that framework by linearization , of far greater interest",
    "are probabilistic representations of nonlinear equations , such as in @xcite .",
    "this work was supported by portuguese national funds through fct under grants uid / cec/50021/2013 and ptdc / eia - cco/098910/2008 .",
    "fb also acknowledges fct funding under grant sfrh / bpd/79986/2011 .",
    "f. bernal , j.a .",
    "acebrn and i. anjam , _ a stochastic algorithm based on fast marching for automatic capacitance extraction in non - manhattan geometries_. siam journal on imaging sciences * 7*(4 ) , 2657 - 2674 ( 2014 ) .",
    "s. mancini , f. bernal and j.a .",
    "acebrn , _ an efficient algorithm for accelerating monte carlo approximations of the solution to boundary value problems_. accepted in the journal of scientific computing ( 2015 ) . g. n. milstein and m. v. tretyakov , _ stochastic numerics for mathematical physics _ , springer - verlag , berlin , 2004 ."
  ],
  "abstract_text": [
    "<S> we present an iterative scheme , reminiscent of the multigrid method , to solve large boundary value problems with probabilistic domain decomposition ( pdd ) . in it , </S>",
    "<S> increasingly accurate approximations to the solution are used as control variates in order to reduce the monte carlo error of the following iterates  resulting in an overall acceleration of pdd for a given error tolerance . </S>",
    "<S> the key ingredient of the proposed algorithm is the ability to approximately predict the speedup with little computational overhead and in parallel . </S>",
    "<S> besides , the theoretical framework allows to explore other aspects of pdd , such as stability . </S>",
    "<S> one numerical example is worked out , yielding an improvement of between one and two orders of magnitude over the previous version of pdd .    </S>",
    "<S> * keywords : * pdd , domain decomposition , scalability , high - performance supercomputing , variance reduction , feynman - kac formula . </S>"
  ]
}