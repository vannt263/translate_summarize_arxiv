{
  "article_text": [
    "a peer grading system works well only if students put effort in evaluating their peer s work , and produce reasonably accurate evaluations .",
    "this is hard work . to motivate students , a natural solution consists in assigning to each student an overall assignment grade that combines both the grade received by their submitted solution , and their accuracy in grading other students work .",
    "the grading accuracy of a student can be measured from the difference between the grades assigned by the student , and the consensus grade the system computes for each submission .",
    "unfortunately , such a simple evaluation scheme can easily be gamed : students can collude to both avoid work , and receive high grades . the simplest way for students to collude consists in assigning the maximum grade to all submissions : in this way",
    ", each student spends zero time evaluating other people s work , while receiving both a top grade for her own submission , and a top grade for her review precision , the latter since all grades for all submissions are in perfect agreement .",
    "we have seen this behavior arise in real classes .",
    "once a nucleus of students starts to assign top grades to all the submissions they review , other initially honest students see what is happening , and join the colluders , both to save work in reviewing , and to avoid being penalized in review precision as the only honest students who disagree with their colluding peers .    a radical way to eliminate collusion on grades",
    "consists in eliminating grades altogether , asking instead students to rank the submissions they review in quality order .",
    "a global ordering can then be constructed using rank aggregation methods @xcite , and grades can be assigned via curving mechanisms , for instance , via the instructor assigning grades to some of the submissions , and deriving the remaining grades via interpolation . as we briefly discuss in section  [ sec - problem ] ( see @xcite for a more in - depth discussion ) , we have experimented with rank - based mechanisms for classroom grading . while we indeed found that they could be precise ,",
    "the rank - based tool we built was not well received by students ; the acceptance of the tool for classroom use increased markedly when we moved from rank - based to grade - based mechanisms .",
    "we do not wish to generalize our experience and claim that grade - based crowd - evaluations provide a universally better student experience than mechanisms based on ranking .",
    "the difference might have lied in how the rank - based tool was designed , or in how it was presented to students , or in some other factor of our experience .",
    "nevertheless , since grades are a common and time - tested method for evaluating homework , building incentive systems for grade - based peer - grading that promote accurate evaluations is an interesting research question .",
    "while we present our work in the context of classroom peer - grading tool , the incentive schemes we develop can be applied to any kind of peer - grading setting .    in this paper",
    ", we examine the question of how to construct incentive systems for peer - grading systems that promote accurate grading while preventing collusion .",
    "we propose two classes of incentive schemes : _ supervised , _ and _ unsupervised .",
    "_    in the supervised schemes , the instructor grades a small number of submissions , and the structure of the incentive system will ensure that the small amount of work by the instructor nevertheless suffices to discourage collusion .",
    "we propose two such supervised schemes .",
    "the first is _ flat : _ the instructor simply grades some submissions , creating a non - zero probability for each student that one of the submissions they reviewed is also reviewed by the instructor .",
    "this scheme works well for small classes ( a few hundred students at most ) , but can not scale , as the amount of work by the instructor needs to be proportional to the number of students . the second scheme we propose is _ hierarchical . _",
    "the participants are organized in a tree , with the instructor as root , the submissions as leaves , and the students filling the intermediate levels . for each edge of the tree ,",
    "the parent node shares with the child node a submission they both reviewed ; the child s review precision is evaluated by comparing the child and parent grades on this shared submission .",
    "the tree is built at random , and students at all levels of the tree perform the same task : they review submissions . in particular",
    ", there is no meta - review involved .",
    "we show that in our proposed hierarchical scheme , a bounded and small amount of work by the instructor suffices to discourage collusion and reward accuracy in arbitrarily large classes , dedicating only a fixed and small percentage of the students to the role of lieutenants that will help in evaluating the work of their underlings .",
    "the result holds provided that students act to maximize their personal benefit , measured as their overall grade . we express the result in game - theoretic terms :",
    "we show that being accurate is a nash equilibrium for students , and that it provides better reward than any other nash equilibrium .",
    "we also present an unsupervised incentive scheme , which does not require any grading by the instructor . to develop the scheme , we assume that the expected true grade distribution for the submissions in the assignment is known .",
    "this is often true in practice , since previous experience teaching the class , and testing students with non - peer grading methods or the supervised schemes above , can yield information on the true grade distribution .",
    "the knowledge of the expected true grade distribution can be used to create an incentive scheme such that the most beneficial nash equilibrium in the resulting game is achieved when students are truthful .",
    "the drawback of such an unsupervised incentive scheme , however , is that it is not _ individually fair : _ the reward of a student depends on the _ global _ lack of collusion in the whole class .",
    "of course , the hierarchical supervised scheme we propose is also not individually fair , as a student s reward depends on the behavior of the student s supervisors at all levels .",
    "nevertheless , the set of students on which an individual student s reward depends is inherently more limited in the hierarchical supervised approach , making it more acceptable in practice .",
    "we have implemented the supervised incentive schemes in the peer - grading tool crowdgrader @xcite . before the incentive scheme was implemented , students colluded and use the strategy of giving maximum grade to every submission in many assignements , and in more than one class .",
    "once the incentive scheme was implemented , the percentage of students adopting this strategy dropped to less than half ( and many , if not all , of the remaining max grades are likely to be justified ) .",
    "providing incentives to human agents to return thuthful responses is a central challenge of crowdsourcing algorithms and applications @xcite .",
    "prediction markets are models with a goal of obtaining predictions about events of interest from experts .",
    "after experts provide predictions , a system assigns a reward based on a scoring rule to every expert .",
    "proper scoring rules ensure that the highest reward is achieved by reporting the true probability distribution @xcite .",
    "the limiting assumption of the scoring rules is that the future outcome must be observable .",
    "however , in peer review and other crowdsourcing tasks the final outcome is frequently not available .",
    "the model presented in @xcite relaxes this assumption .",
    "the proposed scoring rule evaluates experts by comparing them to each other .",
    "the model assigns a higher score for an expert if her predictions are in agreement with predictions of other experts .",
    "the peer - prediction method @xcite uses proper scoring rules to reward experts depending on how good their input for predicting other experts reports . similarly , the model described in @xcite evaluates experts depending on how good their reports are in predicting the consensus of other workers .",
    "other studies based on the peer - prediction method @xcite ensure that the truthful reporting is a nash equilibrium . however , such models elicit truthful answers by analyzing the consensus between experts in one form or another . as a result",
    "these models are prone to gaming when every expert agrees to always output the same answer .",
    "the study in @xcite shows that for the scoring rules proposed in the peer - prediction method @xcite , a strategy that always outputs `` good '' or `` bad '' answer is a nash equilibrium with a higher payoff that the truthful strategy .",
    "the model proposed in @xcite elicits truthful subjective answers on multiple choice questions .",
    "the author shows that the truthful reporting is a nash equilibrium with the highest payoff .",
    "the model is different from other approaches in that besides the answers , workers need to provide predictions on the final distribution of answers .",
    "a worker receives a high score if her answer is `` surprisingly '' common - the actual percentage of her answers is larger than the predicted fraction .",
    "there are several reasons that limit the applicability of this model in peer review grading .",
    "first , it is not clear in what form students should provide their prediction about the final distribution over numerical grades .",
    "moreover , even if we can solicit such predictions , there are not enough reviews per submission to estimate their distribution . in peer grading , the amount of work is linearly dependent on the number of reviewers .",
    "for example , in crowdgrader each submission receives about 5 reviews on average no matter how large the class is .",
    "finally , another assumption in the model is that there is no ground truth .",
    "this means that two workers with different answers can be both correct . in our setting",
    ", every submission has a unique intrinsic quality .",
    "the model described in @xcite considers a scenario of rational buyers who report on the quality of products of different types . in the developed payment mechanism the strategy of honest reporting is the only nash equilibrium .",
    "however , the model requires that the prior distribution over product types and condition distributions of qualities is the common knowledge .",
    "such assumptions do not hold in our peer review setting .",
    "the work in @xcite studies the problem of incentives for truthfulness in a setting where persons vote other persons for a position .",
    "the analysis derives a randomized approximation technique to obtain the higher voted persons .",
    "the technique is strategyproof , that is , voters ( which are also candidates ) can not game the system for their own benefit .",
    "the setting of this analysis is significantly different from ours , as the limiting assumption is that the sets of voters are votees are identical , while in peer grading the sets of reviewers and submissions are different ( and in fact , a student files multiple submissions ) .",
    "the votes that people cast in @xcite are binary , that is , a person votes for other persons choosing from the entire set , while in the peer - grading setting a reviewer assigns grades to a set of assigned submissions . also , the study focuses on obtaining the top-@xmath1 voted items , while in peer - grading we are interested in assigning accurate grades to the totality of students .",
    "another @xmath1-selection method that provides truthful incentives is proposed in @xcite .",
    "a relevant previous study on peer - grading is the work in @xcite .",
    "the authors develop a mechanism for soliciting answers for binary questions where agents have endogenous proficiencies .",
    "the strategies of agents consist in choosing the amount of effort to put into a task and a decision on which answer to report .",
    "the developed mechanism has the property that the truthful strategy with maximum effort is a nash equilibrium .",
    "moreover , this equilibrium yields the maximum payoff to all agents . similarly to our proposed unsupervised method , the scoring rule in @xcite consists of two components .",
    "the first component depends on agreement with other reviewers .",
    "the higher the agreement , the higher the payoff . the second component of the score is a negative static term that is designed in a way that only the truthful reporting compensates it .",
    "the applicability of this method may be limited , as the grades are only binary ( high quality and low quality ) , whereas a range of grades is the standard practice in classrooms and what we consider in our study .",
    "also , it is not always practical to grant students the freedom to evaluate the assignments they feel confident about . finally , the validity of the assumption of endogenous proficiencies used throughout the analysis , that is , that one can infer the fitness of evaluators for grading particular tasks based on the choice of the tasks they evaluated , is not substantiated or supported with analytical arguments or real - world data .",
    "the peerrank method proposed in @xcite obtains the final grades of students using a fixed point equation similar to the pagerank method .",
    "however , while it encourages precision , it does not provide a strategyproof method for the scenario that students collude to game the system without making the effort to grade truthfully .",
    "reviewing is hard work . in order to motivate students to perform high quality reviews of other students work , some incentive is needed .",
    "a simple approach consists in making the review work part of the overall assignment grade , giving each student a review grade that is related to the student s grading accuracy . to measure the grading accuracy of a student ,",
    "the simplest solution is to look at the discrepancy between the grades assigned by the student , and the consensus grades computed from all input on the assignment .",
    "unfortunately , such approach opens up an opportunity for students to game the system .",
    "a big enough group of students can affect the consensus grades and thus affect how they and other reviewers are evaluated .",
    "one obvious grading strategy for a reviewer is to assign the maximum grade to every assignment they grade . in this way",
    ", students spend no time examining the submissions , and yet get perfect grades both for their submission , and for their reviewing work .",
    "we have observed this behavior in real classrooms . in a class",
    "whose grading data we analyzed , held at a us university , the tool crowdgrader was used to peer - grade homework .",
    "the initial homework assignments were somewhat easy , so that a large share of submissions deserved the maximum grade on their own merit . as more homework was assigned and graded , a substantial number of students switched to a strategy where they assigned the maximum grade to every submission they were assigned to grade .",
    "submissions that had obvious flaws were getting high grades , and reviewers who did diligent work were getting low review grades because their accurate evaluations did not match the top - grade consensus for the submissions they reviewed .",
    "figure [ fig - frac - max - reviewers ] displays the fraction of students who assignmed maximum grades to assignments in the class .",
    "a surprisingly high percentage of students were giving maximum grades ; the percentage rose to 60% in the 13th assignment . between the 13th and 14th assignment",
    "there was a big drop in the fraction of such students , as the instructor announced that there would be a new grading procedure introduced that would penalize such behavior .",
    "however , the hastily - introduced procedure did not work , and the students returned to give inflated evaluations spending little time reviewing .",
    "we study in this paper incentive schemes that encourage students to carefully evalue submissions , and enter accurate grades in classroom peer - grading systems .",
    "a way to eliminate the collusion on grades that grade - based evaluation makes possible consists in asking students to rank submissions in quality order , rather than assign a grade to each of them .",
    "the ranks provided by each student can then be aggregated in a single overall ranking using _",
    "rank aggregation _ techniques that have been very widely studied ( see @xcite , and for a survey and general framework , @xcite ) .",
    "if desired , the ranking can then be converted to grades via curving methods .",
    "while incentive systems are still needed to ensure student take the time to provide truthful rather than random rankings , they are intrinsically resistant to many types of collusion .",
    "these mechanisms have been studied in the literature as alternatives to students assigning grades @xcite .",
    "we built a tool , crowdranker , to experiment with peer grading based on ranking and rank aggregation . while precise , crowdranker was intensely disliked by students in our university @xcite .",
    "students complained that a ranking did not allow them to express the difference between the cases of submissions of nearly equal , and vastly different , quality ; no amount of references to the body of literature on rank aggregation seemed to lessen their intuitive distrust in the mechanism , and having to explain how accurate ranks can indeed be obtained from many partial ranks became a burden for the instructor at the beginning of every class .",
    "further , students disliked the task of ranking the work of their peers .    at some point the evolution of crowdranker , we switched to grades , but we required that the floating point grades assigned by each student to the submissions reviewed be all different .",
    "this allowed us to reconstruct the underlying ranking .",
    "the inability of giving the same grade to two different submissions was by a wide margin the most common complaint with crowdranker , notwithstanding that in principle , the probability that two different submissions are exactly of the same quality is zero .",
    "students liked to group submissions they reviewed into mental `` quality bins '' , and were not eager to resolve the issue of what was the precise quality order in each bin .",
    "eventually , we removed the restriction on grades being different , we renamed the tool crowdgrader , and we based it on grades rather than rankings ; the tool gained much wider acceptance .",
    "as our goal was to develop a widely used and accepted tool , we have been using grades ever since .",
    "as we mentioned in the introduction , we do not wish to make a general claim on the basis of our particular experience ; the greater acceptance of grades compared to rankings might very well have lied in the implementation or user interface of crowdranker , or in the type of classroom use to which we tried to apply it .",
    "nevertheless , grading mechanisms are very commonly used , making the question of how to devise incentive schemes that make them precise a relevant one .",
    "we denote the set of students and submissions by @xmath2 and @xmath3 respectively .",
    "each submission @xmath4 has a true quality @xmath5 $ ] where @xmath6 is the maximum of the grading range .",
    "students evaluate submissions by assigning numerical grades : we denote by @xmath7 $ ] the grade assigned by user @xmath8 to submission @xmath9 .",
    "each reviewer grades only a subset of submissions .",
    "the grades can be represented as a labeled bipartite graph @xmath10 , where @xmath11 if @xmath12 reviewed @xmath13 , assigning grade @xmath14 to it.we denote the set of submissions that are graded by user @xmath12 is @xmath15 , and conversely , we denote by @xmath16 the set of users that graded submission @xmath13 .",
    "we assume that the grading system anonymizes submissions , as it is commonly done to avoid students grading their friends in a special way .",
    "further , we assume that the grade that a student assigns to a submission can depend on the individual submission only through the quality of the submission .",
    "in other words , students can distinguish submissions only through their quality .    to make this assumption precise",
    ", we define the set of _ admissible grading strategies _ as follows , and we restrict our attention to students following admissible strategies . in an admissible strategy , students grade a submission @xmath13 in two steps .",
    "first , they estimate the true quality of @xmath13 , obtaining @xmath17 , where @xmath18 is a random measurement error whose distribution does not depend on @xmath13 .",
    "the student then assigns grade @xmath19 , where @xmath20 \\to [ 0 , m]$ ] is a grade modification function , and @xmath21 is additional noise added intentionally by the student ; again , neither @xmath22 nor the distribution of @xmath21 can depend on @xmath13 directly .",
    "the function @xmath22 models the conscious intention of the student to report a grade that does not correspond to the truth , and the additional noise represents intentional randomization on the part of the user .",
    "an admissible grading strategy @xmath23 is defined by a tuple of @xmath24 where @xmath22 is as above , and @xmath25 and @xmath26 are expectation and standard deviation of the voluntary noise @xmath21 .",
    "we denote by @xmath27 the set of all admissible strategies .",
    "obviously , if a student plays a strategy with constant function @xmath22 , the student does not need to measure the quality of the submission being graded .",
    "an example of a non - admissible strategy is one in which , given a submission @xmath13 , students compute a hash function that maps the content of the submission to a grade in @xmath28 $ ] .",
    "assuming that students follow admissible grading strategies is a strong assumption from a mathematical point of view , and it rules out some strategies , such as the above , where students collude to appear to be in perfect agreement on the quality of each submission . on the other hand ,",
    "it is highly implausible that students would agree to a scheme that arbitrarily gives higher grade to some of their submissions , and lower to others .",
    "such scheme would require communication and coordination ahead of time between the students .",
    "the students who would be arbitrarily disadvantaged by the scheme , such as those in the example above whom the hash function assigns grade @xmath29 , would object to its adoption .",
    "if students were to pre - agree on a scheme that assigned different grades to their submissions , it is implausible that they would agree on any scheme that depends on aspects of the submission other than the quality .",
    "indeed , such collusion has never been observed in crowdgrader , nor reported in any of the other peer grading systems .",
    "thus , we believe that restricting our attention to the game equilibria determined by admissible strategies is not restrictive from a pragmatic point of view .      to provide an incentive towards accurate grading , we propose that students who participate in the peer - grading system receive a grade that consists in two components :    * a _ submission grade , _ that captures the quality of the student s own submission .",
    "this grade is computed by combining the grades provided for the submission by the peer graders into a single consensus grade . * a _ review grade , _ capturing the accuracy of the grades assigned by the student with respect to the consensus grades .",
    "we propose to make the review grade inversely and linearly proportional to a _",
    "loss function _ that evaluates the imprecision of a student .    in this paper",
    ", we study grading strategies in the framework of game theory , considering whether certain strategies form nash equilibria , whether certain strategies are best responses to adversary strategies , and so on @xcite .",
    "the notion of nash equilibrium , and several other notions we rely upon , can be stated in terms of strategies that are the _ best response _ to strategies played by the other participants in the game , which in our case are the other students . at first sight , it would seem that we need to consider both the submission and review components of a student s grade in order to reason about best responses , but this is not the case .",
    "since students are never assigned their own submissions to grade , students can not modify their review grades by playing different review strategies . in order to reason about best responses , and nash equilibria , we can thus focus on the review grade only , and thus , on the loss functions used to compute it .",
    "we denote by @xmath30 the loss of user @xmath12 in the graph @xmath31 of reviews . in the remainder of the paper",
    ", we study the properties of various loss functions .",
    "a simple example of loss function consists in measuring the average square difference between the student s grade for a submission , and the average grade received by the submission : @xmath32 to evaluate a strategy @xmath23 , we compute the expected loss of a student @xmath12 who plays according to @xmath23 . we distinguish two types of strategy losses , one with respect to a specified set of submissions , and one that averages over all submissions .",
    "the first type of loss is the expectation of @xmath30 at instances @xmath15 that has been graded by the reviewer .",
    "we keep submissions and strategies fixed , but we take expectation over errors ( @xmath18 and @xmath21 ) of all reviewers involved in evaluating @xmath15 .",
    "we denote such loss as @xmath33 where @xmath34 is the vector of strategies by other reviewers , and @xmath35 is the set of true qualities of the submissions graded by the reviewer .",
    "the second type of strategy loss is the expectation of @xmath36 , with the expectation taken over all errors ( @xmath18 and @xmath21 ) _ and _ a distribution of submission qualities .",
    "we denote such loss as @xmath37",
    ".    our goal will be to design loss functions that create an incentive for students to play the truthful strategy .",
    "we call a strategy _ @xmath38-truthful _ if it outputs a true grade with the average square error smaller than @xmath39 .",
    "a strategy @xmath40 is @xmath38-truthful if for every @xmath41 $ ] @xmath42 [ def - sigma - truth ]    the square error of any strategy can be written as a sum of two components : a variance and a squared bias . indeed , denoting with @xmath43 for brevity",
    ", we have : @xmath44 thus a strategy is a @xmath38-truthful strategy if for every submission quality @xmath41 $ ] the next condition holds : @xmath45 where @xmath46 and @xmath26 are the bias and standard deviation of the grade @xmath47 .",
    "we say that a loss function creates an incentive for students to grade truthfully if the best nash equilibrium is @xmath38-truthful .",
    "throughout the paper we will be able to prove stronger results from which it will follow that the best nash equilibrium is @xmath38-truthful .    to analyze strategies",
    "we introduce a notion of a best response set with respect to the other set of strategies .",
    "let all users except user @xmath12 play according to strategies from set @xmath48 , i.e. @xmath49 . a set of strategies @xmath50 is called a best response for @xmath51 if for every submission quality @xmath52 there is @xmath53 such that it has the minimum loss @xmath54 for all possible choices of strategies @xmath55 .",
    "note that there could be multiple best response sets .",
    "a set of strategies @xmath56 contains the best response strategies for a set of strategies @xmath48 if for every submission quality @xmath57 $ ] there exists @xmath58 that @xmath59    theorem [ th : obvious - one ] in formally proves next intuitive observation . if every student grades according to a @xmath60-precise strategy , then under the squared average loss function ( [ eq - square - loss ] ) the best response strategy is the truthful strategy , i.e. the strategy with the identity function @xmath22 and zero noise @xmath21 .",
    "in the supervised approach , the instructor grades a subset of the submissions , and the information thus obtained is used , along with the student - provided grades , to compute the review grade of every student .",
    "we present two approaches to supervised grading .",
    "the first is a one - level approach , in which the review grade of students is computed by comparing student grades preferentially with instructor grades , when those are available .",
    "the one - level approach is simple to implement , and can scale to class size of a hundred or a few hundred students , while requiring only moderate amount of instructor work .",
    "the second approach is a hierarchical one , in which we organize the review assignment in a hierarchy that allows us to construct a review incentive that scales to arbitrarily large classes , with bounded ( in fact , constant ) amount of instructor work .      in the one - level approach ,",
    "the instructor randomly chooses a subset of submissions to grade .",
    "if a student has one of the submissions , or more , graded by the instructor , the student s loss is determined by comparing the student grade(s ) with the instructor s , rather than with those provided by other students . without loss of generality",
    ", we can discuss the situation for a student doing a single review ; the analysis for the case of multiple reviews follows simply by taking expectations , so that the incentives are unchanged . assuming ( as we do throughout this section ) that the instructor is able to discern the true quality of a submission , if the submission @xmath61 is graded by the instructor , the loss of user @xmath12 is @xmath62 .",
    "otherwise , the loss is measured using @xmath36 loss ( [ eq - square - loss ] ) .",
    "let @xmath0 be the probability of a submission being reviewed by the instructor .",
    "the expected loss of a reviewer @xmath12 is @xmath63 where @xmath64 is a scaling coefficient . by choosing probability @xmath0",
    "the instructor varies the influence on reviewers : the higher @xmath0 is , the more likely that the review grade of a student depends on a comparison with the instructor rather than on a comparison with other students .",
    "the instructor can influence the review behavior of students because students are interested in receiving a higher review grade .",
    "thus , we are implicitly assuming that every student has a utility function that measures the value of receiving a high review grade .",
    "for simplicity , we assume here that the utility @xmath65 a student receives from the review grade is simply the opposite of the reviewing loss @xmath66 .",
    "on the other hand , reviewing a submission to evaluate its quality takes time and effort , which corresponds to a cost @xmath67 .",
    "the user thus has a choice :    * either review the submission , and receive utility @xmath68 , where @xmath66 is computed according to ( [ eq - expected - squared - loss ] ) , * or play the `` lazy '' strategy , ignore the content of the submission , and assing the submission a constant grade plus random amount , and receive utility @xmath69 , where @xmath70 is the loss for the grade assigned .",
    "the first strategy is clearly the one we intend to encourage .",
    "we note that , if the student does not examine the content of the paper , the only admissible strategy consists in playing a constant plus random noise ( see section  [ subseq - grading - strategies ] ) .",
    "when students have a positive review cost @xmath67 , the value of the instructor review probability @xmath0 determines the balance between review loss , and review cost . our goal is to provide a lower bound for @xmath0 that ensures that all nash equilibria strategies are @xmath38-truthful strategies . to prove the result on the lower bound , we first state and prove two lemmas .",
    "the first lemma states that if two strategies have the same bias on submission @xmath13 , then the strategy that has the smaller variance also has the smaller loss ( [ eq - expected - squared - loss ] ) .",
    "[ lemma - smaller - var - better - strategey ] let strategies @xmath71 and @xmath72 have the same expected grade of submission @xmath4 , or @xmath73 strategy @xmath71 has smaller expected loss ( [ eq - expected - squared - loss ] ) computed on submission @xmath13 than strategy @xmath72 if the variance of @xmath71 is smaller than the variance of @xmath72 @xmath74    we apply lemma  [ lem:1 ] of appendix to represent loss ( [ eq - expected - squared - loss ] ) as a sum of variance and bias terms . in the context of the lemma , @xmath75 .",
    "expectations are taken with respect to strategies errors .",
    "the expected loss of strategy @xmath23 on submission @xmath13 is @xmath76 summands ( [ lem - smaller - var - better - strategy : eq-1 ] ) and ( [ lem - smaller - var - better - strategy : eq-5 ] ) add up to the variance of strategy @xmath23 on submission @xmath13 times @xmath77 .",
    "summands ( [ lem - smaller - var - better - strategy : eq-2 ] ) , ( [ lem - smaller - var - better - strategy : eq-3 ] ) , ( [ lem - smaller - var - better - strategy : eq-6 ] ) depend on the bias of @xmath23 .",
    "summand ( [ lem - smaller - var - better - strategy : eq-4 ] ) does not depend on strategy @xmath23 . if two strategies @xmath71 and @xmath72 have the same bias @xmath78 , then all summands but ( [ lem - smaller - var - better - strategy : eq-1]),([lem - smaller - var - better - strategy : eq-5 ] ) are the same for both strategies .",
    "thus , the strategy that has the smaller variance has the smaller loss .",
    "the next lemma focuses on strategies that assign grades with 0  variance .",
    "the lemma shows that strategies that assign submissions a fixed grade too far from the true quality can not be best - response strategies .",
    "[ lem - p - for - const - strategies ] consider a submission @xmath13 .",
    "let every reviewer @xmath79 play according to a strategy @xmath23 that assigns @xmath13 a fixed grade @xmath80 $ ] , with @xmath81 .",
    "a reviewer @xmath79 has an incentive to perform the review of @xmath13 ( paying cost @xmath82 ) and deviate from @xmath23 if : @xmath83    from ( [ eq - expected - squared - loss ] ) , the loss @xmath84 of strategy @xmath23 is @xmath85 if user @xmath12 modifies the grade she assigns to @xmath13 , the optimal grade can be found my minimizing ( @xmath86 ) , and is given by : @xmath87 the loss @xmath88 of this best response is the loss ( [ eq - expected - squared - loss ] ) at grade @xmath89 : @xmath90 the condition @xmath91 yields @xmath92 yielding the desired result .    note that if the true grades @xmath93 and guessed grades @xmath94 are close ,",
    "that is , if most submissions have similar quality and the reviewers can easily guess it , then the reviewers have little incentive to actually perform the reviews .",
    "this is indeed what we observed in practice .",
    "using these two lemmas , we can finally provide the desired lower bound for the instructor review probability that ensures a desired level of review accuracy .",
    "[ th - one - level - supervised ] if probability @xmath0 satisfies inequality @xmath95 then all nash equilibrium strategies belong to the set of @xmath38-truthful strategies .",
    "according to lemma  [ lemma - smaller - var - better - strategey ] we can limit our attention to strategies that have 0 variance on each submission @xmath96 .",
    "indeed , any strategy @xmath23 that is not constant on submissions @xmath3 is dominated by strategy @xmath97 that grades with @xmath98 , where the expectation is taken over errors of strategy @xmath23 .",
    "according to lemma  [ lem - p - for - const - strategies ] , if @xmath0 satisfies inequality ( [ lem - p - for - const - strategeis : ineq ] ) then there is an incentive for a user @xmath12 to deviate on submission @xmath13 from strategy that grades submission @xmath13 with constant @xmath94 .",
    "in particular , if @xmath0 satisfies inequality ( [ ineq - low - bond - p ] ) then the user has an incentive to deviate from any strategy @xmath23 such that that @xmath99 .",
    "thus , if a strategy is not @xmath38-truthful and @xmath0 satisfies inequality ( [ ineq - low - bond - p ] ) then the strategy can not be a nash equilibrium .",
    "what follows is an immediate corollary of theorem  [ th - one - level - supervised ] by setting the cost of performing a review to 0 .",
    "[ theo - nash - simple ] if the instructor reviews each submission with strictly positive probability and the cost of reviewing is not included in the utility function , then all the nash equilibria strategies belong to the set of @xmath38-truthful strategies .",
    "_ example .",
    "_ we provide an application of bound ( [ ineq - low - bond - p ] ) to a classroom setting that is typical of how crowdgrader is used .",
    "submissions are graded in the interval from 0 to 10 , and the final grade is determined as the weighed average of the submission grade , and of the review grade ; the submission grade carries 75% weight , and the review grade 25% .",
    "we assume that it takes 5 hours for a student to obtain a basic version of the homework submission ( i.e. , before 5 hours , students do not have a solution they can realistically submit ) .",
    "after these 5 hours , the additional benefit of spending more time on the homework is 1 grade point per additional hour .",
    "each student is asked to review 5 submissions .",
    "we assume that students must budget the total time they devote to each class .",
    "any extra time @xmath100 can be spent either improving the homework , or doing the reviews .",
    "thus , the cost @xmath82 of working on a review for an amount of time @xmath100 can be measured as the loss of utility incurred by not using time @xmath100 to work on the homework instead .",
    "an amount @xmath100 hours spent on the homework is valued @xmath101 ( due to the 75% weight and 1 point / hour ) , so we let @xmath102 .",
    "the scaling coefficient @xmath77 for ( eq - expected - squared - loss ) is @xmath103 , which reflects also the 25% weighing of the review grade ( of course , the decision of @xmath77 is independent , and we could choose a larger @xmath77 to penalize more strongly imprecise students , but too large a value of @xmath77 leads to unhappy students ) . in order for the instructor to encourage @xmath38-truthful strategies with @xmath104 ,",
    "the lower bound for @xmath0 is : @xmath105    figure  [ fig - prob - vs - cost ] depicts the lower bound ( [ ineq - lower - bound - p - example ] ) as a function of time required to do a review . for @xmath106 hours , or  5 minutes",
    ", the probability @xmath0 of being reviewer by the instructor should be at least 0.5 .",
    "let us estimate the instructor s workload that ensures that @xmath0 is at least 0.5 .",
    "let @xmath107 , @xmath108 , @xmath1 be the class size , the number of submissions per reviewer and the number of submissions for the instructor respectively . to compute @xmath0 as a function of @xmath109 , and @xmath1 , we note that @xmath110 where @xmath52 is the probability that the instructor and a reviewer do not have submissions in common .",
    "the probability @xmath52 is the fraction of the number of ways of successful submission assignment and the total number of ways of assigning submissions @xmath111 if we fix @xmath0 , we can estimate the instructor s workload depending on the class size . when there are 100 students in a class and it takes 5 minutes to grade a submission , then @xmath0 is 0.5 and the instructor needs to grade at least 13 submissions .",
    "the dependency of @xmath1 on @xmath107 is roughly linear , indicating that the instructor workload increases linearly with class size .",
    "in this example we assume that the instructor chooses which submissions to review uniformy at random .",
    "the instructor could also pick submissions to review trying to maximize the number of reviewers with whom there is a reviewed submission in common , but in general , this requires solving _ vertex cover , _ an np - hard optimization problem @xcite . furthermore , the size of the resulting cover would still scale linearly with class size . in the next section , we present hierarchical review schemes that can scale to any classroom size while requiring only a constant amount of work from the instructor .     of being reviewed by the instructor as a function of cost in minutes of doing a review .",
    "]      the loss of a student participating in peer - grading with the proposed one - level supervised scheme is given in ( [ eq - expected - squared - loss ] ) .",
    "the loss consists in two components : one due to comparison with other students , one due to comparison with the instructor .",
    "the comparison with other students might engender unfairness , in the case in which a truthful student is compared with students who grade carelessly . on the other hand ,",
    "this portion is important for two reasons . first , if this part were missing , and student received a loss only when compared with the instructor grade , there would be an obvious ( if random ) source of unfairness due to the random choice of the students whose review work is compared with the instructor s .",
    "second , this component of the loss makes the overall system more effective , as it amplifies the incentive provided by the instructor beyond the students that are directly reviewed .",
    "we have implemented the one - level incentive approach described here in the tool crowdgrader @xcite .",
    "let us nickname a _",
    "max - grader _ a student who gave maximum grade to all submissions he or she reviewed .",
    "we report here the statistics for the winter and spring quarter of 2015 , that is , from the beginning of january , to the summer break , for classes with at least 50 students .",
    "before the one - level incentive approach was implemented , the percentage of max - graders was 24.3% , as measured over 93 assignments and 8,190 total submissions .",
    "the class whose behavior was reported in figure  [ fig - frac - max - reviewers ] belonged to this set .",
    "after we allowed instructors and tas to also grade submissions , on 31 assignments where this option was used , for a total of 3,781 submissions , the percentage of max - graders dropped to 11.3% . to see whether this percentage reflected collusion",
    ", we evaluated the percentage of top grades that , upon instructor review , turned out to be justified .",
    "over these 28 assignments , 62.7% of top grades were confirmed by the instructor within 5% ( i.e. , the instructor gave a grade within 5% of the top grade ) , and 73.3% of the top grades were confirmed within 10% .",
    "therefore , in classes where the incentive scheme described in this section was introduced , collusion in giving unjustified top grades effectively ceased .",
    "theorem  [ th - one - level - supervised ] provides a lower bound on @xmath0 .",
    "however , values of @xmath0 above the bound provide incentive of different strength .",
    "if we imagine a sequence of best responses grades for a submission , then @xmath0 specifies the speed of convergence towards the true grade .",
    "next proposition obtains the speed of convergence as a function of @xmath0 .",
    "[ prop - convergence - rate ] consider a sequence of the best response grades on submission @xmath4 .",
    "on the first step every @xmath112 grades submission @xmath13 with grade @xmath113 . on step",
    "@xmath114 every user grades submission @xmath13 with the best response to strategy on step @xmath115 .",
    "denote the evaluation error on step @xmath116 s @xmath117 .",
    "in such iterative process the error decreases geometrically : @xmath118    we will show that the best response grade on iteration @xmath116 is @xmath119 the proof is by induction on @xmath116 . for @xmath120",
    "the grade of submission @xmath13 is @xmath121 by the assumption of the theorem .",
    "next , assume that @xmath122 and let us show that @xmath123 indeed , the best response grade for grades on iteration @xmath115 is the grade that minimizes loss ( [ eq - expected - squared - loss ] ) , @xmath124 .",
    "the loss achieves its minimum at @xmath125 equations ( [ prop - convergence - rate : eq - t-1 ] ) and ( [ prop - convergence - rate : from - lemma ] ) yield ( [ prop - convergence - rate : eq - t ] ) .",
    "therefore the error at step @xmath116 is @xmath126 thus @xmath127 .      in this section",
    "we develop a hierarchical grading schema that requires a fixed amount of work from the instructor to provide an incentive to grade truthfully .",
    "the schema organizes reviewers into a _ review tree . _",
    "the internal nodes of the review tree represent reviewers ; the leafs represent submissions .",
    "a parent - child relation between reviewers indicates that the child review grade depends on the parent evaluation . a parent node and a child node share one submission they both reviewed ; this shared submission is used to evaluate the quality of the child node s review work .",
    "the root of the tree is the instructor .",
    "a review tree of depth @xmath128 is a tree with submission as leaves , student as internal nodes , and the instructor as root .",
    "the nodes are grouped into levels @xmath129 , according to their depth ; the leaves are the nodes at level @xmath130 ( and are thus all at the same depth ) . in the tree ,",
    "every node at level @xmath131 reviews exactly one submission in common with each of its children .    to construct a review tree of branching factor at most @xmath132 , we proceed as follows .",
    "we place the submissions as leaves .",
    "once level @xmath66 is built , we build level @xmath133 by enforcing a branching factor of at most @xmath134 . for each node @xmath100 at level @xmath66 ,",
    "let @xmath135 be its children .",
    "for each @xmath135 , we pick at random a submission @xmath136 reviewed by @xmath137 , and we assign to @xmath100 to review the set @xmath138 of submissions . at the root of the tree , we place the instructor , following the same method for assigning submissions to review to the instructor .",
    "figure  [ fig - review - tree ] illustrates a review tree with branching factor 2 and depth 3 .        in a tree",
    "constructed thus , there are many submissions that have only one reviewer .",
    "this construction suffices for the purposes of this section , but if desired , it is possible to construct a dag , rather than a tree , so that each submission is reviewed by multiple reviewers at the tree level immediately above .",
    "while the tree organizes their review activity hierarchically , the students participating all do the same task : they review papers .",
    "in particular , the review scheme does not require any explicit meta - review activity .",
    "the review loss of a reviewer @xmath139 in the tree is computed by considering the parent @xmath100 of @xmath139 , and the grades @xmath140 and @xmath141 assigned by @xmath100 and @xmath139 on the submission they both graded .",
    "the loss of reviewer @xmath139 is given by @xmath142 .",
    "we assume that the instructor provides true grades , that are accurate and without bias . under the assumption of rational players",
    ", the next theorem proves that if reviewers are evaluated by the average squared loss ( [ eq - square - loss ] ) , then the set of @xmath38-truthful strategies contains all nash equilibria .",
    "[ th - supervised - tree ] if reviewers are rational , then the truthful strategy is the only nash equilibrium of players arranged in a review tree",
    ".    we will prove by induction on the depth @xmath143 of the tree that the only nash equilibrium for players at depths up to @xmath66 is the truthful strategy . at depth",
    "@xmath29 , the instructor provides true grades , and the result holds trivially , as the instructor plays a fixed truthful strategy .",
    "let us consider a reviewer @xmath26 at depth level @xmath1 , and denote by @xmath144 the set of submissions reviewed by @xmath26 .",
    "since @xmath26 does know know which submission in @xmath144 has been reviewed also by its parent , and since the parent is by induction hypothesis truthful , the expected loss of @xmath26 can be written as @xmath145 where the first expectation is taken over the submissions graded by @xmath26 , and the second is taken on the grade @xmath146 assigned by @xmath26 to @xmath13 .",
    "it is clear that this loss is minimized when @xmath147 for all @xmath148 , that is , when @xmath26 plays the truthful strategy .",
    "the grading scheme based on a random review tree ensures that users achieve the smallest loss when grading with the truthful strategy .",
    "however , some students still might not chose the truthful strategy as it requires effort to evaluates submissions .",
    "our next result provides a general condition for users to prefer the honest behavior in a random review tree .",
    "let users @xmath2 be organized into a review tree with branching factor @xmath132 .",
    "let @xmath149 and @xmath150 be costs for a user to grade honestly and to defect respectively . if a user defects and is caught by its superior then the punishment is @xmath151 .",
    "then , users have incentive to stay honest if @xmath152    similarly to theorem  ( [ th - supervised - tree ] ) , the proof is by induction of level @xmath153 of the tree . a reviewer @xmath12 from level @xmath66 has incentives to stay truthful on a review if the gain @xmath154 due to defecting is smaller than the expected punishment @xmath155 .",
    "thus , if inequality ( [ ineq - defect ] ) holds , reviewer @xmath12 has incentive to play truthfully .    as an application of the above result",
    ", we consider a scenario when reviewers are organized into a random review tree with branching factor @xmath132 , and must choose between a truthful grading strategy , and grading with the maximum grade @xmath6 .",
    "the punishment of a reviewer for deviating is the loss in utility @xmath156 , where @xmath157 are expected losses of the truthful and the maximum grade strategies .",
    "we have @xmath158 and @xmath159 , where the expectation is taken over the distribution of true item qualities .",
    "expression @xmath160 can be simplified to @xmath161 , where @xmath162 and @xmath163 are the variance and the mean of the true quality distribution .",
    "the cost of being truthful is @xmath164 ; the cost of defecting is @xmath165 . inequality ( [ ineq - defect ] ) yields @xmath166 if the true item qualities are mostly distributed close to the maximum @xmath6 , then users have less incentives to put effort in grading .",
    "we are interested in analyzing parameters of the true quality distribution and costs @xmath82 that satisfy inequality ( [ ineq - hierarch - cost - bound ] ) . for the class example in section [ sec - supervised - flat ] , we considered cost @xmath102 where @xmath100 is the amount of time in hours it takes to review a submission .    in figure  [ fig - hierarchical - cost ]",
    ", we plot the lower bound of the variance @xmath162 as a function of the average submission quality @xmath163 for reviewing costs 5 , 10 , 20 and 60 minutes .",
    "if the average item quality is 9.5 then the variance should be at least 1 to ensure incentives for grading with reviewing time less than 20 minutes .",
    "interesting enough , for this case strategies that grade with the maximum strategy are 1-truthful .     as a function of the average submission quality @xmath163 for reviewing costs 5 , 10 , 20 and 60 minutes . ]",
    "in the previous section we considered supervised approaches that required the instructor to grade a subset of submissions . in this section",
    "we explore a grading scheme that relies on a priory knowledge of the typical grade distribution in assignments .",
    "the advantage of the scheme is that it does not require work on the instructor s part ; this comes with the drawback , however , that the scheme might be unfair to individual students . in many cases",
    "the instructor , based on experience and historical data , has expectations about the overall grade distribution in the class . by tying grade distributions to student incentives",
    ", we can create incentives for truthful grading .",
    "in particular , we will be able to show that the students will prefer the truthful grading strategy to strategies that are truthful but have large noise , and to strategies that always provide a fixed grade , plus optional noise .",
    "the drawback of the incentives we consider is the potential unfairness towards individual students , as we will discuss in more detail later .",
    "we assume that the variance @xmath162 of the true quality distribution is known , usually via an analysis of the performance of students in past similar assignments .",
    "we propose a loss function ( [ eq : loss - var ] ) for a reviewer that consists of two parts : @xmath167 the first part @xmath168 , defined by ( [ eq : loss - var - l2-part ] ) , measures the agreement between grades by reviewer @xmath12 and the average grades by other reviewers .",
    "it is similar to the loss @xmath169 defined by ( [ eq - square - loss ] ) , except for the fact that the average consensus grade excludes grades by the reviewer : @xmath170 we propose two versions for the second part : a _ local _ and a _ global _ version . in the _ local _ version ,",
    "we define @xmath171 as the sample variance ( [ eq : loss - var - part ] ) of the grades that the reviewer has given to assigned submissions : @xmath172 in the _ global _ version , we define @xmath171 as the overall variance of the grades in graph @xmath173 : @xmath174 both versions penalize students who give grades that are too similar : the local version penalizes a student based on the variance of the grades that this student has assigned , while the global version considers the variance of all grades assigned by students across all submissions .",
    "the parameter @xmath175 controls the influence of these variances .",
    "thus , the overall loss function ( [ eq : loss - var ] ) consists of two components : a positive one that accounts for disagreement with other students ; and a negative one that accounts for variance among grades , either global or local .",
    "we will study the preference of students with respect to two classes of strategies : the strategies that report the true grade , plus possible additive noise , and the strategies that report a constant grade , plus possible additive noise .",
    "these two strategies correspond to the two possible behaviors of a student : either review the submission , and report its grade plus some noise , or skip the review , and report a constant grade plus some noise . in the latter case , the student adds some random noise to overcome the lack of variance that will be penalized by the loss function .",
    "since the second component of the loss ( [ eq : loss - var ] ) encourages variance , students will not prefer to play the maximum grade strategy .",
    "however , a natural way to overcome the penalization of zero variance in their attempt to game the system is to add noise to a constant grade .",
    "we compare strategies according to the expected loss @xmath176 , where the expectation is taken over the submission quality distribution and the evaluation errors of all reviewers involved in grading submissions @xmath15 .    to express the result precisely , we introduce the following sets of grading strategies .",
    "let @xmath177 be the set of grading strategies that report the true grade plus additive noise , i.e. , @xmath178 iff there exists a random variable @xmath179 such that for every submission @xmath4 , we have @xmath180 .",
    "let @xmath181 be the subset of strategies @xmath182 whose noise has an expected value of  0 , that is , such that @xmath183 iff @xmath184 and @xmath185 . note that @xmath186 .",
    "we denote by @xmath187 the truthful strategy , for which @xmath188 is identically  0 .",
    "we also introduce a set of strategies that grade submissions with a constant grade plus additive noise . for @xmath189 and",
    "@xmath190 $ ] , let @xmath191 be the set of strategies @xmath23 such that @xmath192 , where the random variable @xmath18 has variance @xmath193 .",
    "note that @xmath194 .",
    "the next theorem expresses the preference for the truthful strategy , compared to both strategies in @xmath195 , and strategies in @xmath181 .",
    "[ th - unsup ] consider the loss function ( [ eq : loss - var ] ) , with @xmath171 defined by either ( [ eq : loss - var - part ] ) or ( [ eq : loss - var - part - glob ] ) . for @xmath196 ,",
    "the following statements hold :    * if every reviewer @xmath197 plays with a strategy @xmath181 and reviewer @xmath12 is limited to strategies @xmath184 , then reviewer @xmath12 minimizes her loss by playing with the truthful strategy @xmath198 .",
    "* for any @xmath199 , reviewers have smaller loss when they play with the truthful strategy @xmath198 compared to strategies @xmath200 .    to prove the first part of the theorem , we analyze the expected loss ( [ eq : loss - var ] ) of user @xmath112 with strategy @xmath184 when users @xmath201 play with strategies @xmath181 . according to lemma  [ lem - long1 ] ,",
    "the expectation of the first component of the loss ( [ eq : loss - var ] ) is @xmath202 , where @xmath203 and @xmath204 is the variance and the expectation of error @xmath205 , and @xmath206 does not depend on user @xmath12 .",
    "the second component can be defined whether by ( [ eq : loss - var - part ] ) or ( [ eq : loss - var - part - glob ] ) .",
    "first , let us consider loss ( [ eq : loss - var ] ) with @xmath171 defined by ( [ eq : loss - var - part ] ) . expression ( [ eq : loss - var - part ] ) is an unbiased variance estimator , therefore @xmath207 . combining both parts together ,",
    "if @xmath209 , then user @xmath12 minimizes her loss when @xmath210 , i.e. with the truthful strategy .",
    "next , let us consider the loss ( [ eq : loss - var ] ) with @xmath171 defined by ( [ eq : loss - var - part - glob ] ) .",
    "according to lemma  [ lem - long1 ] , @xmath211 , where @xmath212 and @xmath213 .",
    "therefore , @xmath214 .",
    "again , the truthful strategy yields the smallest loss when coefficients @xmath215 and @xmath216 are positive .",
    "it is straightforward to verify that for @xmath209 and @xmath217 both coefficients are positive .    to prove the second part of the theorem we compare user losses in the following two scenarios .",
    "in the first scenario all users play with the truthful strategy . in the second scenario",
    "all user play with @xmath97 such that @xmath218 , where @xmath18 has 0 expectation and variance @xmath193 .",
    "the loss of the truthful strategy is @xmath219 .",
    "the loss ( [ eq : loss - var ] ) of strategy @xmath97 can be computed directly from equation ( [ eq : loss - var ] ) .",
    "the first part of the loss is @xmath220 as the variance of a difference between independent random variables @xmath221 where @xmath222 is an error by user @xmath26 while playing strategy @xmath97 .",
    "for both ( [ eq : loss - var - part ] ) and ( [ eq : loss - var - part - glob ] ) , the second part of the loss is @xmath223 .",
    "therefore , the loss of strategy @xmath97 is @xmath224 .",
    "the condition that the loss of strategy @xmath97 is bigger than the loss of the truthful strategy is @xmath225 to show that the inequality holds for @xmath226 , we consider three cases when @xmath227 , @xmath228 and @xmath229 . if @xmath227 inequality ( [ th - unsup - ineq - gamma ] ) yields @xmath230 the right part of the inequality is always negative",
    ", therefore for @xmath231 reviewers have smaller loss when they play with the truthful strategy than with strategy @xmath97 . if @xmath228 then inequality ( [ th - unsup - ineq - gamma ] ) is true for any @xmath232 .",
    "if @xmath233 then the condition on @xmath234 is @xmath235 the inequality holds for @xmath209 as the right hand side is always greater than 1 as @xmath236 and @xmath237 .",
    "therefore , for @xmath226 inequality ( [ th - unsup - ineq - gamma ] ) holds and the truthful strategy has smaller loss than strategy @xmath97 .",
    "theorem  [ th - unsup ] assumes that the cost of reviewing a submission is zero or not included in the reviewer s utility function . for non - zero costs ,",
    "we can still obtain a range for @xmath234 such that the statements of theorem  [ th - unsup ] hold .",
    "[ th - unsup - cost ] consider the loss function ( [ eq : loss - var ] ) , with @xmath171 defined by either ( [ eq : loss - var - part ] ) or ( [ eq : loss - var - part - glob ] ) .",
    "let @xmath238 be reviewer cost to evaluate a submission .",
    "for any @xmath239 , if @xmath240 then for @xmath234 that satisfies the inequalities @xmath241 the two statements of theorem  [ th - unsup ] hold .",
    "the proof of the theorem is tightly connected to the proof of theorem  [ th - unsup ] .",
    "we showed that for @xmath209 , the loss ( [ eq : loss - var ] ) is minimized when user @xmath12 plays with the truthful strategy @xmath198 , where the loss is defined by either ( [ eq : loss - var - part ] ) or ( [ eq : loss - var - part - glob ] ) .",
    "moreover , we limit our attention to @xmath231 as we want the second component of the loss ( [ eq : loss - var ] ) to penalize small variance among grades by the reviewers",
    ". we will analyze the conditions on @xmath242 and @xmath238 so that the truthful strategy is more preferable that strategies @xmath243 .",
    "if cost @xmath244 , then the loss of users who play with the truthful strategy is due to measurement cost @xmath82 and the loss of the truthful strategy according to function ( [ eq : loss - var ] ) .",
    "therefore , the condition that users have smaller loss when evaluating the true submission quality and playing with the truthful strategy than a strategy from @xmath243 is satisfied when both of the following conditions hold : @xmath245      \\label{th - unsup - cost - ineq - gamma }      \\gamma ( \\sigma_q^2 - \\eta^2 ) > c - \\frac{n}{n-1}\\eta^2 \\eqpun .\\end{aligned}\\ ] ] we consider 3 cases .",
    "* case 1 : @xmath227*. the inequality ( [ th - unsup - cost - ineq - gamma ] ) becomes @xmath246 the set of possible values for @xmath234 is not empty if the right hand side of the inequality is less than 1 .",
    "this condition yields @xmath247 therefore , when @xmath227 and @xmath240 , reviewers has smaller loss by spending cost @xmath82 on evaluating the true grades and playing with the truthful strategy if @xmath248    * case 2 : @xmath228*. the inequality ( [ th - unsup - cost - ineq - gamma ] ) always holds for @xmath249 .",
    "thus @xmath226 .",
    "* case 3 : @xmath233*. the inequality ( [ th - unsup - cost - ineq - gamma ] ) becomes @xmath250 the set of possible values for @xmath234 is not empty if the right hand side of the inequality is positive .",
    "this yields the following condition on @xmath82 : @xmath251 we notice that if @xmath240 and @xmath252 , then @xmath253 .",
    "therefore , when @xmath233 and @xmath254 inequality ( [ th - unsup - cost - ineq - gamma ] ) holds for @xmath255 we have shown that for any @xmath189 , @xmath256 and @xmath234 that satisfies the inequalities of the theorem , reviewers receive smaller loss if they spend grading cost @xmath82 and play with the truthful strategy compared to playing with strategies @xmath243 .",
    "if @xmath257 , and assuming that colluding students can lower the variance @xmath193 accordingly , then there is no range of @xmath234 for which the above properties hold .",
    "the incentive scheme based on the loss ( [ eq : loss - var ] ) is not individually fair . if we adopt the local definition of loss ( [ eq : loss - var - part ] ) , then students who receive submissions that are close to each other in qualilty are at a disadvantage , as their loss will be greater than that of students who were assigned to review submissions of more different value .",
    "if we adopt the global definition of loss ( [ eq : loss - var - part - glob ] ) , then students who are honest might be individually penalized , if everybody else adopts a `` constant plus noise '' strategy in @xmath243 . as intructor grades are not available as absolute reference point",
    ", the possibility of individual unfairness seems however unavoidable in unsupervised grading incentive schemes .",
    "we studied two supervised schemes and one unsupervised scheme which provide incentives for truthful grading in peer review . in the _ flat _ supervised scheme , each student has a non - zero probability of being graded by the instructor .",
    "we computed a lower bound on this probability so students have an incentive to grade truthfully .",
    "the lower bound shows that the _ flat _ supervised approach is applicable for classes of moderate size .",
    "the second scheme , which we considered , organizes students into a hierarchy .",
    "the instructor grades a subset of submissions that were graded by the top ranked lieutenants . in turn ,",
    "lieutenants grade submission by lieutenants of lower rank .",
    "this _ hierarchical _ scheme provides an incentive for truthful grading under the assumption of rational students .",
    "the instructor and every student need to grade only a fixed number of submission no matter how big the class is .",
    "the third scheme does not require supervision from the instructor .",
    "reviewers are evaluated based on a criteria that penalizes the lack of agreement with peers and the lack of variance in review grades .",
    "this scheme is not individually fair as a reviewer might be assigned submissions with low true quality variance .",
    "however , we showed that in expectation the best strategy for a reviewer is to grade truthfully .",
    "10    n.  ailon .",
    "aggregation of partial rankings , p - ratings and top - m lists .",
    ", 57(2):284300 , 2010 .",
    "n.  alon , f.  fischer , a.  procaccia , and m.  tennenholtz .",
    "sum of us : strategyproof selection from the selectors . in _ proceedings of the 13th conference on theoretical aspects of rationality and knowledge",
    "_ , tark xiii , pages 101110 , new york , ny , usa , 2011 .",
    "a.  carvalho , s.  dimitrov , and k.  larson .",
    "inducing honest reporting without observing outcomes : an application to the peer - review process . , 2013 .",
    "r.  t. clemen .",
    "incentive contrats and strictly proper scoring rules .",
    ", 11(1):167189 , 2002 .",
    "a.  dasgupta and a.  ghosh .",
    "crowdsourced judgement elicitation with endogenous proficiency . in _ proceedings of the 22nd international conference on world wide web _ , pages 319330 .",
    "international world wide web conferences steering committee , 2013 .",
    "l.  de  alfaro and m.  shavlovsky .",
    "crowdgrader : a tool for crowdsourcing the evaluation of homework assignments . in _ the 45th acm technical symposium on computer science education , sigcse 14 , atlanta , ga , usa - march 05 - 08 , 2014 _ , pages 415420 , 2014 .",
    "c.  dwork , r.  kumar , m.  naor , and d.  sivakumar .",
    "rank aggregation methods for the web . in _ proceedings of the 10th international conference on world wide web",
    "_ , pages 613622 .",
    "acm , 2001 .",
    "a.  ghosh .",
    "game theory and incentives in human computation systems . in _",
    "handbook of human computation _ , pages 725742 .",
    "springer , 2013 .",
    "s.  johnson , j.  w. pratt , and r.  j. zeckhauser .",
    "efficiency despite mutually payoff - relevant private information : the finite case .",
    ", pages 873900 , 1990 .",
    "r.  jurca and b.  faltings .",
    "enforcing truthful strategies in incentive compatible reputation mechanisms . in _ internet and network economics _ , pages 268277 .",
    "springer , 2005 .",
    "r.  jurca and b.  faltings .",
    "minimum payments that reward honest reputation feedback . in _ proceedings of the 7th acm conference on electronic commerce _ , pages 190199 .",
    "acm , 2006 .",
    "r.  jurca and b.  faltings .",
    "mechanisms for making crowds truthful . , 34(1):209 , 2009 .",
    "e.  kamar and e.  horvitz .",
    "incentives for truthful reporting in crowdsourcing . in _ proceedings of the 11th international conference on autonomous agents and multiagent systems - volume 3 _ , pages 13291330 . international foundation for autonomous agents and multiagent systems , 2012 .",
    "r.  m. karp . .",
    "springer , 1972 .",
    "d.  kurokawa , o.  lev , j.  morgenstern , and a.  d. procaccia .",
    "impartial peer review . .",
    "n.  miller , p.  resnick , and r.  zeckhauser . eliciting informative feedback : the peer - prediction method .",
    ", 51(9):13591373 , 2005 .",
    "m.  j. osborne and a.  rubinstein . .",
    "mit press , 1994 .",
    "d.  prelec . a bayesian truth serum for subjective data .",
    ", 306(5695):462466 , 2004 .",
    "k.  raman and t.  joachims .",
    "methods for ordinal peer grading . in _ proceedings of the 20th acm sigkdd international conference on knowledge discovery and data mining _ , kdd 14 , pages 10371046 , new york , ny , usa , 2014 .",
    "t.  walsh .",
    "the peerrank method for peer assessment . ,",
    "abs/1405.7192 , 2014 .",
    "r.  l. winkler and a.  h. murphy .",
    "`` good '' probability assessors .",
    ", 7(5):751758 , 1968 .",
    "the next lemma provides an alternative expression for the expectation of the square of a random variable @xmath21 that we obtain through a linear transformation of another random variable @xmath258 , with @xmath259 .",
    "we add and subtract @xmath262 to @xmath258 , to obtain the following transformation : @xmath263 in the last equality we used the fact that @xmath264 we obtain equality  [ lem:1statement ] by combining equality ( [ eq : lemma-1 ] ) with the following transformation of ( @xmath265 by adding and subtracting @xmath46 to @xmath266 : @xmath267      [ lem - long1 ] consider function @xmath168 defined by ( [ eq : loss - var - l2-part ] ) , where @xmath27 , @xmath182 and @xmath181 are as in the statement of theorem  [ th - unsup ] .",
    "let reviewer @xmath8 play with a strategy @xmath178 , and let every other reviewer @xmath197 play with strategies in @xmath181 .",
    "let the error @xmath205 of user @xmath12 have variance @xmath203 and expectation @xmath204 .",
    "the expectation of expression ( [ eq : loss - var - l2-part ] ) taken over the submission quality distribution and users errors has the form @xmath268 where the term @xmath206 does not depend on user @xmath12 .",
    "we use @xmath269 to denote the expectation of an expression @xmath270 over all errors @xmath271 of users @xmath26 that are involved in @xmath270 , and we use @xmath272 to denote the expectation over the true submission quality distribution . without loss of generality ,",
    "we let @xmath273 .    to extract the components of @xmath274 that depend on @xmath203 and @xmath204 , we add and subtract the terms @xmath275 and @xmath276 inside the squared expression of ( [ eq : loss - var - l2-part ] ) . after we expand the square , three of the six summands of the expanded expression are equal to @xmath29 .",
    "we apply the formula @xmath278 to the expression , obtaining : @xmath279 \\\\",
    "\\label{lem - long1-eq-3 }      - & 2e_qe_{\\xi}\\left[\\left(g_{iu } - e_{\\xi}g_{iu}\\right)\\left(\\frac{1}{n-1}\\sum_{v\\in \\partial i\\backslash u } ( g_{iv } - e_{\\xi}g_{iv})\\right)\\right ] \\\\",
    "\\label{lem - long1-eq-4 }      - & \\left.2e_qe_{\\xi}\\left[\\left(\\frac{1}{n-1}\\sum_{v\\in \\partial i\\backslash u}(g_{iv } - e_{\\xi}g_{iv})\\right)\\left(e_{\\xi}g_{iu } - \\frac{1}{n-1}\\sum_{v\\in \\partial i\\backslash u } e_{\\xi}g_{iv}\\right)\\right]\\right\\ } \\eqpun .",
    "\\end{aligned}\\ ] ] expression ( [ lem - long1-eq-2 ] ) is 0 because @xmath280 and both factors under the expectation of ( [ lem - long1-eq-2 ] ) are independent from the error @xmath281 of user @xmath12 .",
    "similarly , expressions ( [ lem - long1-eq-3 ] ) and ( [ lem - long1-eq-4 ] ) are 0 too .",
    "note that factors in expression ( [ lem - long1-eq-3 ] ) are independent from the error of user @xmath12 because the average grade @xmath282 is computed without the grade by user @xmath12 .",
    "therefore , we have : @xmath283 the double - expectation expression in ( [ lem - long1-eq-5 ] ) is the variance @xmath203 . by definition of set @xmath181 , for every @xmath284 the expectation",
    "@xmath285 equals @xmath93 .",
    "therefore , expression ( [ lem - long1-eq-6 ] ) equals @xmath286 .",
    "expression ( [ lem - long1-eq-7 ] ) does not depend on user @xmath12 . combining all parts together ,",
    "we obtain equation ( [ lem - long1-eq1 ] ) .",
    "[ lem - long2 ] consider the function @xmath171 defined by ( [ eq : loss - var - part - glob ] ) .",
    "let reviewer @xmath112 play with strategy @xmath178 , and let every other reviewer @xmath197 play with strategies in @xmath181 .",
    "let the error @xmath205 of user @xmath12 have variance @xmath203 and expectation @xmath204 .",
    "the expectation of expression ( [ eq : loss - var - part - glob ] ) taken over the submission quality distribution and users errors can be written as : @xmath287 where @xmath288 , @xmath289 and expression @xmath206 does not depend on user @xmath12 .    to show the statement of the lemma we split @xmath290 into the following two components @xmath291 and @xmath134 : @xmath292 we simplify expressions @xmath291 and @xmath134 separately and introduce subcomponents @xmath82 and @xmath113 .",
    "@xmath293 in the last equality we used the fact that expressions @xmath294 and @xmath295 are independent of user errors @xmath21 and @xmath296 . to compute @xmath297",
    "we notice that there is a variance of random noises involved in expression @xmath82 . using the formula for the variance of a sum of independent random variables ,",
    "we obtain : @xmath298 the expectation of expression @xmath299 is : @xmath300 we modify expression ( [ lem - long2-eq - b2 ] ) using the fact that @xmath301 for @xmath302 and @xmath303 .",
    "the expression @xmath304 becomes : @xmath305      + e_q\\left(q_i - \\frac{1}{k}\\sum_{(j , w ) \\in g }",
    "q_{j}\\right)^2\\\\      = & \\left(\\frac{k - n}{k}\\right)^2e_{\\xi}\\xi_u^2 + e_q\\left(q_i - \\frac{1}{k}\\sum_{(j , w ) \\in g } q_{j}\\right)^2 \\eqpun .\\end{aligned}\\ ] ] in the last equality , we used the fact that @xmath306 , because @xmath307 . if use @xmath206 to denote the part of @xmath304 that does not depend on user @xmath12 , then @xmath308 we note that @xmath309 does not depend on user @xmath12 .",
    "combining all parts together , the expression for component @xmath291 is @xmath310 where we use @xmath206 again to denote components that do not depend on user @xmath12 .",
    "we now compute the expression for component @xmath134 :      again , we use the fact that @xmath294 and @xmath295 are independent with respect to users noise @xmath312 and that @xmath296 . using the formula for the variance of a sum of independent random variables , we obtain @xmath313 .",
    "we use assumptions @xmath301 for @xmath302 and @xmath303 to simplify expectation @xmath314 .",
    "expression @xmath316 is 0 , as @xmath317 .",
    "thus , the expression for terms of @xmath314 that depend on user @xmath12 is : @xmath318 to obtain terms in expression @xmath134 that depend on user @xmath12 , we notice that @xmath319 does not depend on @xmath12 . combining all parts together ,",
    "we obtain : @xmath320 we have extracted terms that depend on user @xmath12 in expressions @xmath291 and @xmath134 . denoting @xmath321 as @xmath204 and combining expressions @xmath291 and @xmath134",
    ", we obtain @xmath322 thus , we obtain equation ( [ lem - long2-eq1 ] ) .",
    "we note that for @xmath323 equation ( [ lem - long2-eq1 ] ) becomes equation ( [ lem - long1-eq1 ] ) ."
  ],
  "abstract_text": [
    "<S> peer grading systems work well only if users have incentives to grade truthfully . </S>",
    "<S> an example of non - truthful grading , that we observed in classrooms , consists in students assigning the maximum grade to all submissions . with a naive grading scheme , such as averaging the assigned grades , all students would receive the maximum grade . in this paper </S>",
    "<S> , we develop three grading schemes that provide incentives for truthful peer grading . in the first scheme , </S>",
    "<S> the instructor grades a fraction @xmath0 of the submissions , and penalizes students whose grade deviates from the instructor grade . </S>",
    "<S> we provide lower bounds on @xmath0 to ensure truthfulness , and conclude that these schemes work only for moderate class sizes , up to a few hundred students . to overcome this limitation , we propose a hierarchical extension of this supervised scheme , and we show that it can handle classes of any size with bounded ( and little ) instructor work , and is therefore applicable to massive open online courses ( moocs ) . </S>",
    "<S> finally , we propose unsupervised incentive schemes , in which the student incentive is based on statistical properties of the grade distribution , without any grading required by the instructor . </S>",
    "<S> we show that the proposed unsupervised schemes provide incentives to truthful grading , at the price of being possibly unfair to individual students . </S>"
  ]
}