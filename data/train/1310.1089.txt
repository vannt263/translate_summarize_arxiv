{
  "article_text": [
    "in general , the understanding of a given phenomenon relies on our ability to construct a model that describes the relevant data and their corresponding uncertainties . one way to summarize what the data tell us about",
    "a model is to find a probability density function for its parameters .",
    "for such a task , standard fitting techniques such as @xmath0 minimization are commonly used to determine this probability density .",
    "typically , this process is iterative : once new data are available , a new fit is performed combining the old and new data",
    ". we shall refer to this procedure as a _ global fit_. in some cases , the complexity of the model is such that its numerical evaluation makes the fitting procedure time consuming . for practical reasons",
    ", it would be desirable to update the probability density by incorporating the information from new data without having to perform a full global fit .",
    "such updating can be achieved by a statistical inference procedure , based on bayes theorem , known as the reweighting technique .",
    "a particular example , where the reweighting technique is useful , is in the context of global fits for the determination of parton distribution functions ( pdfs ) .",
    "modeling and fitting these functions has been the central task of several collaborations , e.g. , cteq , cj , mstw , and nnpdf , among others .",
    "but still , there are kinematic regions where the pdfs are relatively unconstrained . given the complexity of the calculations , it is desirable to use the reweighting technique to update our knowledge of the pdfs or to quantify the potential impact of anticipated data sets on the pdfs",
    "the idea of reweighting pdfs was originally proposed in  @xcite and later discussed by the nnpdf collaboration in  @xcite . however , there is disagreement about the reweighting procedure , which has led to methods that differ mathematically .",
    "the purpose of this paper is to discuss the differences between the reweighting methods . in particular , we investigate the degree to which the reweighting procedures yield results that are consistent with those from global fits .",
    "we shall argue that this is the case for the method proposed in  @xcite .",
    "the paper is organized as follows . in sec .",
    "[ sec : the reweighting method ] , we describe the basics of the reweighting technique . in sec .",
    "[ sec : the nnpdf paradox ] , we will discuss subtleties in the nnpdf arguments . in sec .",
    "[ sec : numerical example ] , we will present a simple numerical example to display the differences between the reweighting methods .",
    "our conclusions are given in sec .",
    "[ sec : conclusions ] .",
    "the reweighting of probability densities in order to incorporate the information from new data is merely the recursive application of bayes theorem .",
    "suppose a probability density function ( pdf ) @xmath1 of the parameters",
    "@xmath2 in a model is known .",
    "( to avoid confusion , we shall take  pdf \" to mean parton distribution function , and  pdf \" to mean probability density function . ) given new data @xmath3 , bayes theorem states that @xmath4 where @xmath5 , known as _ posterior _ density , is the updated pdf from the _ prior _ density ( or prior for short ) @xmath1 , which can serve as the prior in a subsequent analysis . the quantity",
    "@xmath6 called the _ likelihood _ function , represents the conditional probability for a data set @xmath3 given the parameters @xmath2 of the model .",
    "the quantity @xmath7 ensures the normalization of the posterior density . with the new data , the expectation value of an observable @xmath8 can be written as , @xmath9 & =   \\int d^n\\alpha \\mathcal{p}(\\vec{\\alpha}|d )      \\mathcal{o}(\\vec{\\alpha})\\notag\\\\ & =   \\int d^n\\alpha \\frac{\\mathcal{p}(d|\\vec{\\alpha})}{\\mathcal{p}(d ) }       \\mathcal{p}(\\vec{\\alpha})\\mathcal{o}(\\vec{\\alpha})\\notag\\\\ & =   \\frac{1}{n } \\sum_k w_k \\mathcal{o}(\\vec{\\alpha}_k ) .",
    "\\label{eq : e}\\end{aligned}\\ ] ] in the last line , we have used a monte carlo approximation of the integral in which the parameters @xmath10 are distributed according to the prior @xmath11 . similarly , the variance is given by @xmath12 & = \\frac{1}{n } \\sum_k w_k ( \\mathcal{o}(\\vec{\\alpha}_k)-\\text{e } [ \\mathcal{o}])^2 .",
    "\\label{eq : var}\\end{aligned}\\ ] ] the quantities @xmath13 are _ weights _ that are proportional to @xmath14 . their normalization is fixed by demanding @xmath15=1 $ ] , that is , @xmath16 .",
    "the reweighting procedure depends on the form assumed for the likelihood function .",
    "the form of the likelihood function is not unique since it depends on the amount of information we want to extract from the new data . to clarify ,",
    "suppose the new data consist of @xmath17 data points @xmath18 with uncertainties in @xmath19 given by a covariance matrix @xmath20 .",
    "let us call @xmath21 the @xmath17 predictions from the model @xmath22 with parameters @xmath2 .",
    "assuming a gaussian model , the conditional probability for new data to be confined in a differential volume @xmath23 around @xmath24 for a given configuration of parameters @xmath2 is @xmath25 where the @xmath26 is defined in the standard way @xmath27 on the other hand , we might be interested in the probability for the new data to be confined only in a differential shell @xmath28 to @xmath29 .",
    "this probability density can be obtained by integrating @xmath30 inside the shell ( see appendix [ sec : lh2 ] ) .",
    "the result , @xmath31 is the well - known @xmath0 distribution . using the functions from eqs .",
    "( [ eq : lh1 ] ) and ( [ eq : lh2 ] ) as likelihoods in eq .",
    "( [ eq : bayes ] ) , we obtain the corresponding posterior densities and weights , @xmath32 @xmath33 note that @xmath34 has less information than @xmath35 : a given data set @xmath36 uniquely determines @xmath28 , but a given @xmath28 is consistent with infinitely many data sets @xmath36 .",
    "therefore , the posterior density @xmath37 has less information than @xmath38 , a mathematical fact that we shall quantify using a standard information - theoretic measure .",
    "the nnpdf collaboration argues in ref .",
    "@xcite that we should avoid the use of the likelihood @xmath39 because of the borel - kolmogorov paradox , the observation that conditional probabilities , such as @xmath40 , for continuous variables @xmath36 are ambiguous because they condition on a set of measure zero for which the probability is strictly zero . in the present context ,",
    "the probability that @xmath36 is _ exactly _ equal to @xmath3 is zero . in order to give meaning to @xmath41",
    ", the latter must be defined by a limit .",
    "the paradox arises because different ways of taking the limit can yield different results .",
    "however , no issue arises in bayes theorem , eq .",
    "( [ eq : bayes ] ) , even when @xmath42 is multidimensional .",
    "indeed , statisticians ( and some physicists ) routinely use multivariate densities in bayes theorem .",
    "our intuitive understanding of why eq .",
    "( [ eq : bayes ] ) is mathematically sound is that , first , the probabilities are defined by integrals about the point @xmath36 and second that the _ shapes _ of the sequence of nested sets about the limit point @xmath36 is the same in both the numerator and the denominator .",
    "when the sets become sufficiently small , the integrals can be approximated by the probability density times a small , but _",
    "finite _ , volume element which cancels in bayes theorem .",
    "crucially , this is true for _ all _ shapes of the @xmath17-dimensional , small but _ finite _ , volume element and therefore for all sequences of ( measurable ) sets . therefore , the suggestion by the nnpdf authors that , in effect , bayes theorem , eq .",
    "( [ eq : bayes ] ) , is problematic when @xmath42 is multidimensional is not convincing . indeed , eq .",
    "( [ eq : bayes ] ) is the bedrock of state - of - the - art bayesian analyses ( see for example , ref .",
    "this section aims to study the differences between the reweighting results from the likelihoods @xmath43 and @xmath34 by a numerical example .",
    "simulated data from the function @xmath44 are generated by adding gaussian noise with independent random variances for each value of @xmath45 .",
    "the parameters of the function has been arbitrary set to @xmath46 and a sample 100 points equally spaced in the range @xmath47 is taken .",
    "this particular functional form is inspired by a typical parton distribution function parametrization used in global fits .",
    "for the analysis , the data are divided into 11 equally spaced regions in @xmath45 and labeled as @xmath48 from the lowest @xmath45 region ( @xmath49 ) to the highest @xmath45 region ( @xmath50 ) .",
    "then , the data sets are organized as described in table [ tab : datasplit ] . using @xmath0 minimization",
    ", we perform global fits to each data set @xmath51 .",
    "the uncertainties in the fitted parameters are obtained using the hessian method ( see appendix [ sec : hessian ] ) . as a result",
    "we obtain four parameter vectors @xmath52 with @xmath53 for each data set @xmath51 .",
    "these vectors encode the @xmath54 confidence interval of the fitted parameters . for the reweighting ,",
    "is necessary to construct a monte carlo representation of the fitted results .",
    "this is done by sampling the parameters as @xmath55 where @xmath56 are normally distributed random numbers with variance 1 and mean 0 .",
    "@xmath57 is the number of samples .",
    "evaluating eq .",
    "( [ eq : func ] ) with parameters @xmath58 from the fit @xmath51 yields the desired monte carlo sample @xmath59 .",
    "we compute the latter and its corresponding expectation value @xmath60 $ ] and variance @xmath61 $ ] for each set @xmath51 . in order to perform the reweighting , we select the monte carlo sample @xmath62 as the _ prior _ to be reweighted . using the data sets @xmath63 as new evidence , we compute the expectation value @xmath64 $ ] and variance @xmath65 $ ] using eqs .",
    "( [ eq : e])and ( [ eq : var ] ) with the weights from eq .",
    "( [ eq : bayes1 ] ) or eq .",
    "( [ eq : bayes2 ] ) for each set @xmath66 .",
    "the results are shown in fig .",
    "[ fig : example5a ] where a clear disagreement between the two reweighting methods is exhibited .",
    "the variances obtained by using the likelihood @xmath34 are greater than the variances obtained from the likelihood @xmath35 and the convergence of the expectation values is much faster for the latter case .",
    "this is consistent with the discussion in section [ sec : the reweighting method ] where we argued that the posterior @xmath37 contains less information than @xmath38 .",
    "more importantly , reweighting with the likelihood @xmath35 yields a result that is more compatible with that obtained from the global fits than is that obtained using the likelihood @xmath34 .",
    "this is illustrated by the dotted and dashed curves being nearly identical while the solid and dashed curves show significant differences . in the light of above",
    ", it is important to discuss why the nnpdf collaboration has obtained reweighting results compatible with global fits in  @xcite even when they have used the likelihood @xmath34 instead of @xmath35 . in their case ,",
    "their prior corresponds to pdfs fitted using deep inelastic scattering data ( dis ) and lepton pair production data ( lpp ) . by performing the reweighting and comparing it with a new global fit using the w - lepton asymmetry data",
    ", they have proven the consistency of their reweighting method .",
    "however , it is also known that pdfs are already reasonably well constrained by the dis and lpp data .",
    "this means that the information provided by the w - lepton data is sub - dominant with respect to the dis and lpp data .",
    "we have performed a similar exercise as before but this time using the monte carlo sample @xmath67 as the _ prior _ and the data set @xmath68 as the new evidence .",
    "this setup aims to mimic the conditions at which nnpdf had studied the reweighting technique : the data set @xmath69 contains more data than @xmath68 and therefore the effects of including the later must be sub - dominant for a global fit as well as the reweighting .",
    "the results are shown in fig .",
    "[ fig : example5b ] .",
    "it is clear that in this situation the reweighting of both methods yield similar results compatible with global fits .",
    "one way to quantify the information about the parameters @xmath2 provided by the likelihood @xmath70 , where @xmath45 is either @xmath24 or @xmath28 is to calculate the kullback - leibler ( kl ) divergence ( see appendix [ sec : kullbakc ] .",
    "table [ tab : kl ] shows the kl divergences for the reweighting results performed above .",
    "the values in the table confirms the loss of information when using @xmath37 as the likelihood instead of @xmath38 in the reweighting procedure .    .data sets . [ cols=\"^,^,^,^,^,^,^,^\",options=\"header \" , ]      ( black ) from which the prior distribution is obtained and the new evidence @xmath66 ( colored ) that is used for reweighting or appended to @xmath71 to perform a global fit .",
    "the data is normalized respect to the `` true '' model .",
    "columns 2,3,4 shows expectation values and variances from global fits and reweighting . dashed lines are the results from global fits .",
    "black dashed uses only the data @xmath71 while the colored dashed line includes the new evidences .",
    "solid and dotted lines are reweighting results of data set @xmath71 using the evidences of data @xmath66 .",
    "dotted uses @xmath72 while solid uses @xmath73 .",
    ", scaledwidth=85.0% ]    . in this case ,",
    "set @xmath69 is used to obtain the prior distribution and set @xmath68 is used for reweighting or appended to @xmath69 for a global fit .",
    ", scaledwidth=85.0% ]",
    "the technique of statistical inference is a useful tool to constrain probability density functions in the presence of new evidence .",
    "it is an alternative method to obtain updated distributions without having to perform a global fit by appending the old data and the new data .",
    "the nnpdf collaboration has argued that the method proposed in  @xcite is not adequate and they proposed their own method . in the light of the results presented in this paper ,",
    "we conclude that both methods are statistically equivalent in the limit when the prior densities are well constrained by the data and the new evidence do not provide significant information .",
    "we have shown using a numerical example that , if the uncertainties in the prior distribution are larger compared to the uncertainties obtained by the inclusion of new data , the method proposed by nnpdf collaboration is less efficient than the method proposed by  @xcite and the latter yields results that are significantly closer to those obtained from global fits .",
    "we thank seth quackenbush for helpful discussions on the subject .",
    "this work was supported by doe contract no .",
    "de - sc0010102 .",
    "the distribution @xmath74 can be obtained by integrating @xmath35 subjected to @xmath75 .",
    "mathematically this is simply @xmath76       \\,p(y|\\vec{\\alpha})\\,d^ny\\notag\\\\ = &   \\frac{1}{2\\pi i } \\int_{-\\infty}^\\infty d ( i\\omega )       \\,e^{i\\omega \\chi^2 } \\int e^{-i \\omega \\chi^2(\\vec{y},\\vec{t } ) }       \\,p(y|\\vec{\\alpha } ) \\,d^n y,\\notag\\\\ = &   \\frac{1}{2\\pi i } \\int_{-\\infty}^\\infty d ( i\\omega ) \\ ,       e^{i\\omega \\chi^2 } \\int \\frac{1}{(2\\pi)^{n/2}|\\sigma|^{1/2 } }       e^{-\\frac{1}{2 } ( 2 i \\omega + 1 ) \\chi^2(y,\\vec{\\alpha } ) }       \\,d^n y,\\nonumber\\\\ = &   \\frac{1}{2^{n/2 } } \\frac{1}{2\\pi i }       \\int_{-\\infty}^\\infty d ( i\\omega ) \\ , e^{i\\omega \\chi^2 }      \\frac{1}{(i \\omega + 1/2)^{n/2 } } , \\nonumber\\\\ = &   \\frac{1}{2^{n/2 } \\ , \\gamma(n/2 ) } ( \\chi^2)^{\\frac{1}{2}(n - 2 ) }       e^{-\\frac{1}{2}\\chi^2}.\\end{aligned}\\ ] ] then we obtain @xmath77       \\,\\mathcal{p}(\\tilde{\\chi}^2|\\vec{\\alpha})\\notag\\\\ = &   \\frac{1}{2^{n/2 - 1 } \\ , \\gamma(n/2 ) } ( \\chi^2)^{\\frac{1}{2}(n - 1 ) }       e^{-\\frac{1}{2}\\chi^2}.\\end{aligned}\\ ] ]",
    "for completeness in this appendix we present the standard hessian method for error propagation .",
    "suppose the model parameters @xmath78 that minimizes the @xmath0 is found .",
    "the method consists of expanding the @xmath0 around the minima as a function of the parameters : @xmath79 where @xmath80 is the hessian matrix given by @xmath81 that is evaluated at @xmath82 .",
    "next we diagonalize the matrix @xmath83 which gives eigenvectors @xmath84 with eigenvalues @xmath85 .",
    "the displacements @xmath86 in eq .  (",
    "[ eq : hessian ] ) can be written in terms of rescaled vectors @xmath87 @xmath88 replacing eq .",
    "( [ eq : disp ] ) in eq .",
    "( [ eq : hessian ] ) gives @xmath89 notice that each displacements @xmath90 ( @xmath91 ) corresponds in eq .",
    "( [ eq : chi2_z ] ) a @xmath0 change of @xmath92 unit .",
    "the interval defined by these displacements is known as the one - sigma confidence interval .",
    "the kullback - leibler ( kl ) divergence  @xcite of the posterior density @xmath93 from the prior @xmath1 is given by @xmath94 where the weights are defined as in sec .",
    "[ sec : the reweighting method ]",
    ". the larger the kl divergence , the greater the difference between @xmath95 and @xmath1 and , therefore , the more informative are the data @xmath45 about the pdf parameters , relative to what was known about them prior to inclusion of these data .",
    "a similar quantity called _ effective _ number of replicas @xmath96 was defined in the references @xcite : @xmath97 here @xmath98 is the number of monte carlo sample ( _ replicas _ ) taken from the prior distribution . clearly the kl divergence is related to @xmath96 via @xmath99"
  ],
  "abstract_text": [
    "<S> two different techniques for adding additional data sets to existing global fits using bayesian reweighting have been proposed in the literature . </S>",
    "<S> the derivation of each reweighting formalism is critically reviewed . </S>",
    "<S> a simple example is constructed that conclusively favors one of the two formalisms . </S>",
    "<S> the effects of this choice for global fits is discussed . </S>"
  ]
}