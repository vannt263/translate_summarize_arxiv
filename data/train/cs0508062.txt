{
  "article_text": [
    "a classical work of shannon states that reliable communications over a communication channel can be achieved for all information rates which are less than the certain threshold rate , capacity , which is a function of the channel characteristics .",
    "codes and decoding algorithms that attain the channel capacity were extensively studied over the last decades . for such codes with respective decoding algorithms , at rates less than the capacity ,",
    "the probability of decoding error approaches zero , as the code length grows .",
    "fastness of decrease of the decoding error probability as a function of the code length , @xmath0 , is a characteristic of capacity - approaching codes , which was widely studied for many code families .",
    "however , this probability depends also on ratio between the channel capacity and an actual code rate .",
    "namely , let the code rate be @xmath5 , where @xmath2 is the channel capacity .",
    "it is an interesting question to ask is how the decoding error probability depends on @xmath6 .",
    "another characteristic of ( decoding algorithms of ) codes is a time complexity of decoding . as of yet , there are known families of capacity - achieving codes ( over various channels ) with decoding algorithm time complexity only linear in @xmath0 .",
    "however , one might look onto the decoding time complexity of code families in terms of @xmath6 . in the next two paragraphs we discuss these characteristics for two code families .",
    "it is known that ldpc - type codes can attain a capacity of a binary erasure channel ( bec ) , the reader can refer to  @xcite ,  @xcite ,  @xcite .",
    "it is generally believed that ldpc - type codes can approach capacity of a variety of other communication channels .",
    "however , it is also believed that the decoding error probability decreases only polynomially with the code length . as to the decoding time complexity , it was conjectured in  @xcite that per - bit complexity of message - passing decoding ( e.g. @xcite , @xcite ) of ldpc or irregular repeat accumulative ( ira ) codes over any ` typical ' channel is @xmath7 , where @xmath8 is a decoded error probability . lately , for ldpc - type codes with message - passing decoding over the bec , the time complexity was shown to be linear in a code length and sub - linear in @xmath4 .",
    "more specifically , it was shown in  @xcite and  @xcite that the decoding complexity per bit for some sub - families of ldpc - type codes behaves as @xmath9 . recently , in  @xcite , ira codes with bounded decoding complexity per bit were constructed .",
    "in contrast , modifications of expander codes presented in  @xcite , @xcite ,  @xcite ,  @xcite ,  @xcite also attain the capacity of the memoryless @xmath10-ary symmetric channel , and the error probability decreases exponentially with the code length .",
    "several recent works were devoted to analysis of fraction of errors that expander codes can correct ( e.g.  @xcite ,  @xcite ,  @xcite ,  @xcite ) and their rate - distance trade - offs ( see  @xcite ,  @xcite ,  @xcite ) . while it is well known that there are decoders for expander codes having linear - time ( in the code length ) complexity , the dependence of this complexity on @xmath4 was not studied . in the present work",
    ", we aim at studying this dependence .",
    "we investigate time complexity of decoding algorithms of expander codes in terms of @xmath6 , in particular for the codes in @xcite ,  @xcite .",
    "we show that these specific codes have time complexity that is exponential in @xmath11 .    in this work , we study capacity - achieving codes over a binary symmetric channel ( bsc ) .",
    "we show that if there exists a family of codes @xmath12 of length @xmath0 and rate @xmath5 ( @xmath2 is a bsc capacity ) , with the decoding probability vanishing inverse polynomially in @xmath0 and @xmath6 ( under conditions of our theorem ) , then there exists another such family of codes @xmath13 with the decoding error probability vanishing exponentially in @xmath0 .",
    "moreover , if the decoding time complexity of the codes @xmath12 is polynomial in @xmath0 and @xmath4 , then the decoding time complexity of the codes @xmath13 is linear in @xmath0 and polynomial in @xmath4 .",
    "the structure of this paper is as follows . in section  [ sec : preliminaries ] , we describe the basic ingredients in our construction .",
    "the main result of our paper appears in section  [ sec : main - results ] : we present a sufficient condition for existence of a family of codes with the decoding error probability vanishing exponentially fast .",
    "we also analyze the decoding time complexity of the presented codes .",
    "finally , in sections  [ sec : analysis - zemor02 ] and  [ sec : analysis - zemor03 ] , we show that the codes in  @xcite ,  @xcite with their respective algorithms can not be tuned to have decoding error probability that decreases exponentially fast ( in terms of @xmath0 ) , while the respective decoding algorithms have time complexity linear in @xmath0 and polynomial in @xmath4 .",
    "in this subsection we assume existence of some ( family of ) linear code @xmath12 , which achieves the capacity @xmath2 of the bsc , and which has fast decoding algorithm .",
    "we denote its rate @xmath14 , and its length @xmath15 ( constant for a fixed @xmath6 ) .",
    "below , we discuss the parameters of this code .",
    "@xmath16 we assume that the decoding complexity of @xmath12 over the bsc is given by @xmath17 where @xmath18 are some constants .",
    "let @xmath19 be a decoder that have a time complexity as in  ( [ eq : ldpc - complexity ] ) .",
    "based on the results in  @xcite ,  @xcite ,  @xcite , several ldpc - type code families ( with respective message - passing decoding algorithms ) do have such decoding complexity over the bec ( for @xmath20 ) .",
    "there are no such results known for the bsc , although in the light of the surveyed works , this assumption sounds reasonable for ldpc - type codes over the bsc . as of",
    "yet , there are no satisfying results on asymptotical behavior of the decoding error probability of ldpc - type codes over the binary erasure channel under the message - passing decoding , for rates near capacity of the bec .",
    "the behavior of the decoding error probability of ldpc - type codes over other channels is even less investigated . in this work ,",
    "we obtain a sufficient condition on the probability of the decoding error @xmath21 of the decoder @xmath19 ( for the @xmath12 ) to guarantee the existence of a code with an exponentially - fast decreasing error probability .",
    "the results presented in the sequel are valid for any code @xmath12 whose decoding time complexity and error probability are as stated above . however , ldpc - type codes are very promising candidates to meet these conditions , and in fact we do not see any other candidate at the present moment .",
    "since there is no such candidate , it makes sense to speak about ldpc - type codes in this context .      in this section ,",
    "we consider linear - time decodable codes of rate @xmath22 ( for small @xmath23 ) that can correct a fraction @xmath24 of errors , where @xmath25 are constants .",
    "there are several code families known to date that can be shown to have the above property , and at the same time allow a linear - time ( in a code length ) decoding . in this connection",
    ", the reader can refer to  @xcite ,  @xcite ,  @xcite ,  @xcite ,  @xcite .",
    "however , as of yet , the codes in  @xcite ,  @xcite have the best relations between their rate , distance and alphabet size among all known expander - based linear - time decodable codes . moreover , unlike the codes in  @xcite ,  @xcite , not all aforementioned codes have decoding time complexity , which is polynomial in @xmath26 .",
    "below , we recall the construction in  @xcite ,  @xcite .",
    "let @xmath27 be a bipartite @xmath28-regular undirected connected graph with a vertex set @xmath29 such that @xmath30 and @xmath31 , and an edge set @xmath32 of size @xmath33 such that every edge in @xmath32 has one endpoint in @xmath34 and one endpoint in @xmath35 .",
    "for every vertex @xmath36 , denote by @xmath37 the set of edges incident with @xmath38 , and assume some ordering on @xmath37 , for every @xmath36 .",
    "let @xmath39 be some finite field , and @xmath40 .",
    "take @xmath41 and @xmath42 to be generalized reed - solomon codes with parameters @xmath43 $ ] and @xmath44 $ ] over @xmath45 , respectively .",
    "( we use notation @xmath46 $ ] for a linear code of length @xmath47 , dimension @xmath48 , and minimum distance @xmath49 . )",
    "we define the code @xmath50 as in  @xcite , namely @xmath51 where @xmath52 denotes the sub - word of @xmath53 that is indexed by @xmath37 .",
    "the produced code @xmath54 is a linear code of length @xmath0 over @xmath45 .",
    "let @xmath55 denote the alphabet @xmath56 .",
    "taking some linear one - to - one mapping @xmath57 over @xmath45 , and the mapping @xmath58 given by @xmath59 the authors of  @xcite define the code @xmath60 of length @xmath47 over @xmath55 by @xmath61    _ definition .",
    "_ an infinite sequence @xmath62 , @xmath63 , @xmath64 , is called _ a dense sequence of values _ if @xmath65 and @xmath66 ( for @xmath67 ) .",
    "( the number @xmath68 is a large absolute constant , the condition @xmath65 ensures that not all elements in the sequence are exponentially large . )",
    "let @xmath69 be the second largest eigenvalue of the adjacency matrix of @xmath70 and denote by @xmath71 the value @xmath72 .",
    "when @xmath70 is taken from a family of @xmath28-regular bipartite ramanujan graphs ( e.g.  @xcite ,  @xcite ) , we have @xmath73 there are explicit constructions for such @xmath28-regular ramanujan graph families for dense sequences of values @xmath28 ( @xcite ,  @xcite ) .",
    "it was shown in  @xcite , that the code @xmath60 has the relative minimum distance @xmath74 it is also known that the rate of @xmath60 is @xmath75 the linear - time decoding algorithm @xmath76 in figure  [ fig : decoder ] was proposed in  @xcite .",
    "it corrects any pattern of @xmath77 errors and @xmath78 erasures such that @xmath79 , where @xmath80 is given by @xmath81 the number of iterations @xmath82 in the algorithm was established in  @xcite such that @xmath83 .",
    "the notation `` ? '' is used for erasures , and the notations @xmath84 and @xmath85 are used for decoders of the codes @xmath41 and @xmath42 , respectively .",
    "the proof in  @xcite requires that the decoder @xmath84 is a mapping @xmath86 that recovers correctly any pattern of less than @xmath87 errors over @xmath45 , and the decoder @xmath85 is a mapping @xmath88 that recovers correctly any pattern of @xmath89 errors and @xmath90 erasures , provided that @xmath91 .",
    "the decoders @xmath84 and @xmath85 are polynomial - time , for example berlekamp - massey decoder can be used for both of them .",
    "it can be implemented then in @xmath92 time ( or less ) .    in the next proposition ,",
    "we show that the parameters of the codes in  @xcite of rate @xmath22 can be tuned to correct @xmath93 errors for a constant @xmath94 .    for any @xmath95 , and for a sequence of alphabets @xmath96 such that the sequence @xmath97 is dense , the codes @xmath60 ( as above ) of rate @xmath98 ( with decoder @xmath76 ) can correct a fraction @xmath93 of errors , where @xmath94 is some constant .",
    "[ prop : parameter - selection ]    * proof .",
    "* there is a dense sequence of values @xmath99 such that there exists a family of @xmath28-regular bipartite ramanujan graphs @xmath70 ( see  @xcite ,  @xcite ) . for any such value @xmath28",
    ", we can take both codes @xmath41 and @xmath42 to be grs codes of length @xmath28 over alphabet of size @xmath28 , rate @xmath100 and relative minimum distance @xmath101 .",
    "consider a code @xmath60 defined with respect to these @xmath41 and @xmath42 .",
    "the rate @xmath102 of @xmath60 satisfies @xmath103 .",
    "from  ( [ eq : beta ] ) , the fraction of errors that the decoder @xmath76 can correct is given by @xmath104    take any @xmath28 such that @xmath105 : for such @xmath28 , @xmath106    next , we observe that @xmath107 .",
    "based on the density of @xmath108 , we show the density of the sequence @xmath97 . indeed , for any @xmath109 , @xmath110 { } & & \\\\ & = & \\lim_{i \\rightarrow \\infty }   \\frac{\\delta_{i+1 } \\log_2 \\delta_{i+1 } - \\delta_i \\log_2 \\delta_{i}}{\\delta_i \\log_2 \\delta_{i } } \\\\ & = & \\lim_{i \\rightarrow \\infty } \\bigg ( \\frac{\\delta_{i+1 } \\log_2 \\delta_{i+1}}{\\delta_i \\log_2 \\delta_{i}}\\bigg ) - 1 \\\\ & = & \\lim_{i \\rightarrow \\infty } \\bigg ( \\frac{\\delta_{i } + o(\\delta_{i})}{\\delta_i } \\cdot   \\frac{\\log_2 ( \\delta_{i } + o(\\delta_{i } ) ) } { \\log_2 \\delta_{i } } \\bigg ) - 1 \\\\ & = & 1 \\ ; - \\ ; 1 \\ ; = \\ ; 0 \\ ; . \\end{aligned}\\ ] ] finally , from  @xcite and  @xcite , @xmath111 can be taken small enough , such that @xmath112 , as required .      in this subsection",
    ", we revisit the definition of concatenated codes .",
    "the following ingredients will be used :    * a linear @xmath113 $ ] code @xmath12 over @xmath45 ( inner code ) . * a linear code @xmath60 of length @xmath47 and rate @xmath102 over @xmath114 ( outer code ) . * a linear one - to - one mapping @xmath115 .",
    "the respective concatenated code @xmath13 is defined as @xmath116 the rate of @xmath13 is known to be @xmath117 .",
    "let @xmath118 and @xmath119 be decoders for the codes @xmath12 and @xmath60 , respectively .",
    "a simple decoder @xmath120 for the code @xmath13 is presented in figure  [ fig : decoder - concatenated ] .",
    "there exist more advanced decoders for the code @xmath13 ( e.g. gmd decoding ,  @xcite ) that can correct more errors , but we consider the decoder @xmath120 due to its simplicity .",
    "consider a memoryless binary symmetric channel with crossover probability @xmath121 .",
    "its capacity is given by @xmath122 , where @xmath123 is the binary entropy function .",
    "let @xmath124 be a design rate .",
    "take @xmath45 to be @xmath125 , @xmath126 , @xmath127 .",
    "let @xmath12 be a binary code of length @xmath15 assumed in section  [ sec : assumed - code ] .",
    "it can also be seen as an additive linear code of length @xmath128 over @xmath45 .",
    "let @xmath60 be a linear code of length @xmath47 and rate @xmath102 over an alphabet @xmath129 . pick some linear one - to - one mapping @xmath115 .",
    "let @xmath13 be a code , corresponding to a concatenation of the code @xmath12 ( as an inner code ) with the code @xmath60 ( as an outer code ) , as defined in section  [ sec : concatenated - code ] .",
    "suppose @xmath130 is a rate of the ( binary ) code @xmath13 and @xmath131 is its length .",
    "denote by @xmath132 its error probability , under the decoding by @xmath120 .",
    "the following lemma is based on the result in  ( * ? ? ?",
    "* chapter 4.2 ) .",
    "the error probability of the code @xmath13 ( as defined in this section ) under the decoding by @xmath120 , when the error probability of the decoder @xmath19 for the code @xmath12 is @xmath21 , and the decoder @xmath76 corrects any pattern of less than @xmath133 errors , is bounded by @xmath134 where @xmath32 is a constant given by @xmath135 if a right - hand side of  ( [ expr : forney ] ) is negative , we assume that @xmath32 is zero .",
    "[ lemma : forney ]    the proof of this lemma appears in appendix a.    * remark .",
    "* it is possible to improve an error exponent by a constant factor if allowing the decoder for the code @xmath12 to put out an `` erasure '' message in a case of unreliable decoding of the code @xmath12 .",
    "see  ( * ? ? ?",
    "* chapter 4.2 ) for details .",
    "we omit this analysis for the sake of simplicity .      in this subsection",
    ", we derive a sufficient condition on the probability of decoding error of the code @xmath12 for providing a positive error exponent for the code @xmath13 as defined in subsection  [ sec : main - settings ] .",
    "below , we use the notation @xmath136 $ ] for the code @xmath12 of rate @xmath137 and length @xmath15 .",
    "[ theorem ] consider the bsc , and let @xmath2 be its capacity .",
    "suppose that the following two conditions hold :    * there exist constants @xmath138 , @xmath94 , @xmath139 , such that for any @xmath140 , @xmath141 , and for a sequence of alphabets @xmath142 where the sequence @xmath143 is dense , there exists a family of codes @xmath60 of rate @xmath22 ( with their respective decoders ) that can correct a fraction @xmath24 of errors .",
    "* there exist constants @xmath144 and @xmath145 , such that for any @xmath140 , @xmath146 , the decoding error probability of a family of codes @xmath12 satisfies @xmath147 \\right ) < \\epsilon^{{\\mathsf{b}}}\\ ; .\\ ] ]    then , for any rate @xmath148 , there exist a family of the codes @xmath13 as defined in subsection  [ sec : main - settings ] ( with respective decoder ) that has an exponentially decaying ( in @xmath149 ) error probability .",
    "* let @xmath150 be a design rate of the code @xmath13 , and @xmath151 be small ( namely , @xmath152 ) .",
    "let @xmath153 be a constant , @xmath154 , which will be defined later , and let the rate of the code @xmath12 be @xmath155 .",
    "we set the rate of @xmath60 as @xmath156 then , by condition ( i ) , the fraction @xmath80 of errors correctable by the code @xmath60 is at least @xmath157 .    for an alphabet @xmath55 ,",
    "the length @xmath15 of the code @xmath12 is given by @xmath158 we select the smallest @xmath159 such that @xmath160 and , so , @xmath161    next , we use lemma  [ lemma : forney ] to evaluate the decoding error probability of the code @xmath13 .",
    "it holds for small positive values of @xmath80 that @xmath162 and thus , from lemma  [ lemma : forney ] we obtain ( by ignoring the positive term @xmath163 in  ( [ expr : forney ] ) ) , @xmath164 { } \\nonumber \\\\ & < & \\exp \\left\\ { - n \\cdot \\left ( - \\beta \\ln \\left ( { { \\mathsf{prob}}}_e({{\\mathcal{c}}}_{in } ) \\right ) + \\beta \\ln \\beta - \\beta \\right ) \\right\\ } \\\\ & = & \\exp \\left\\ { - n_{cont } \\frac{\\beta}{n_{in } } \\left (   \\ln \\beta - \\ln\\left({{\\mathsf{prob}}}_e({{\\mathcal{c}}}_{in})\\right ) - 1 \\right ) \\right\\ } \\ ; .",
    "\\end{aligned}\\ ] ]    in order to have a positive error exponent , we require that @xmath165 or , equivalently , @xmath166    the decoding error probability of the selected code @xmath12 satisfies : @xmath167 \\right ) } \\makebox[5ex ] { } \\nonumber \\\\ & < & { { \\mathsf{prob}}}_e \\left ( { { \\mathcal{c}}}_{in } \\left [ ( 1 - \\kappa \\varepsilon ) c , \\ ; \\frac{1}{(\\kappa \\varepsilon)^{h_0 } }   \\right ] \\right ) \\nonumber \\\\ & < & ( \\kappa \\varepsilon)^{{\\mathsf{b}}}\\ ;   \\le \\ ; \\frac{\\vartheta ( ( 1 - \\kappa ) \\varepsilon)^{{\\mathsf{b}}}}{{\\mathsf{e } } } \\ ; , \\label{eq : prob - c - in}\\end{aligned}\\ ] ] where the first inequality is due to  ( [ eq : n - in - epsilon ] ) , the second inequality follows from condition ( ii ) , and the third inequality can be satisfied by a selection of a small constant @xmath153 such that @xmath168 .",
    "the inequality  ( [ eq : prob - c - in ] ) implies  ( [ eq : beta - required ] ) , as required .",
    "* example . *",
    "suppose that the decoding error probability of the code @xmath12 of rate @xmath169 and length @xmath15 ( for some decoder ) is bounded by @xmath170    we choose @xmath171 ( where @xmath172 is as in condition ( i ) of theorem  [ theorem ] ) .",
    "there obviously exists @xmath173 such that for every @xmath146 , for the code @xmath12 of length @xmath174 and rate @xmath175 , @xmath176 from the expression  ( [ eq : prob - example-1 ] ) we see that condition ( ii ) of theorem  [ theorem ] is satisfied .",
    "this selection guarantees existence of a positive error exponent for the code @xmath13 .",
    "* example . *",
    "suppose that the decoding error probability of the code @xmath12 ( of rate @xmath169 and length @xmath15 ) is bounded by @xmath177 we choose @xmath178 .",
    "there obviously exists @xmath173 such that for every @xmath146 , for the code @xmath12 of length @xmath174 and rate @xmath175 , and for every @xmath179 , @xmath180 and therefore theorem  [ theorem ] yields existence of a positive error exponent for the code @xmath13 .      in this subsection",
    ", we consider a specific case of decoding error probability for the code @xmath12 .",
    "theorem  [ theorem ] can be directly applied in this case .",
    "however , we conduct a direct minimization of the decoding error probability of the code @xmath13 , which is obtained by concatenation of the code @xmath60 in  @xcite with the assumed code @xmath12 , and obtain an analytical expression on the error exponent .",
    "we show that the overall decoding error probability for this code @xmath13 has a positive error exponent .",
    "suppose that the decoding error probability for some inner code @xmath12 over the binary symmetric channel with crossover probability @xmath181 and some polynomial decoder is given by : @xmath182 where @xmath183 is a constant , @xmath184 .",
    "below , we make a selection of parameters for the code @xmath13 .",
    "this selection allows us to estimate a decoding error exponent as a function of @xmath6 .",
    "let @xmath5 be a design code rate .",
    "pick the rate of @xmath12 to be @xmath185 , where @xmath186 is a constant . then , we can write @xmath187 next , we select the parameters of the code @xmath60 in  @xcite , which serves as an outer code . take @xmath41 and @xmath42 as grs codes over @xmath45 , with @xmath188 .",
    "we fix @xmath189 , where @xmath190 ( and thus , @xmath191 ) , and select the degree @xmath28 of the graph @xmath70 as @xmath192 , where @xmath193 is a constant , such that @xmath194 we have , @xmath195 by our selection ( see  ( [ eq : ramanujan ] ) ) , @xmath196 we obtain from  ( [ eq : expander - distance ] ) , @xmath197 where @xmath198 is a constant which depends only on @xmath153 , @xmath199 and @xmath193 .",
    "the number of bits needed to represent each symbol of @xmath55 is @xmath200 .",
    "recall that @xmath201 .",
    "therefore , the length @xmath15 of the binary code @xmath12 is given by @xmath202 and thus , by ignoring the small term , the decoding error probability of @xmath12 is @xmath203    we substitute the expressions in  ( [ eq : delta ] ) ( only the main term ) and  ( [ eq : prob - e ] ) into the result of lemma  [ lemma : forney ] to obtain @xmath204    note that for small @xmath205 , @xmath206 and @xmath207 hence , the equation  ( [ eq : exponent - forney ] ) ( when neglecting @xmath208 terms ) becomes @xmath209 using substitution of the expression  ( [ eq : n - in ] ) for @xmath15 , the latter equation can be rewritten as @xmath210 the dominating term in the expression @xmath211 is @xmath212 . by taking into account that @xmath213 , the equation  ( [ eq : exponent02 ] ) can be rewritten , when ignoring all but the main term , as @xmath214 thus , the decoding error probability is given by @xmath215 where @xmath216 and the parameters @xmath217 are taken over @xmath218    next , we optimize the value of the constant @xmath219 it is easy to see that the maximum is received for @xmath220 .",
    "we substitute @xmath221 in expression  ( [ eq : exponent - max ] ) to obtain @xmath222 by taking a derivative of @xmath223 over @xmath193 and comparing it to zero , we obtain that @xmath224 by substituting it back to the expression  ( [ eq : exponent - max-2 ] ) and finding its maximum , we have @xmath225 and @xmath226 .",
    "these values obviously satisfy condition  ( [ eq : parameters ] ) .",
    "the appropriate value of @xmath223 is then @xmath227 finally , we have @xmath228    figure  [ fig : exponents ] shows value of error exponent @xmath229 in the example for @xmath230 , @xmath231 and @xmath232 .",
    "= 45ex    selection : @xmath233 ; @xmath234 ; @xmath235 ( bottom to top ) .",
    "[ fig : exponents ]      in this subsection , we show that under the assumption in section  [ sec : assumed - code ] on the decoding time complexity of the code @xmath12 , and if the parameters of the codes are selected as in the proof of theorem  [ theorem ] , then the decoding time complexity of the respective code @xmath13 is linear in the overall length @xmath149 and inverse polynomial in the gap from capacity @xmath6 .",
    "[ theorem : complexity ] consider the bsc , and let @xmath2 be its capacity .",
    "let @xmath150 be a design rate .",
    "suppose that the following two conditions hold :    * let @xmath60 be a ( family of ) code defined in section  [ sec : expander - code ] of rate @xmath236 , @xmath186 is a constant , over a smallest alphabet @xmath55 satisfying @xmath237 from a dense sequence @xmath143 , and @xmath238 is a constant .",
    "* let @xmath12 be a code of rate @xmath239 with the decoding complexity over the bsc of capacity @xmath2 given by @xmath240 where @xmath18 are some constants .",
    "then , the time complexity of the respective code @xmath13 , when decoded by @xmath120 , is given by @xmath241 @xmath16    * proof .",
    "* below we count the total number of operations when decoding the code @xmath13 by the decoder @xmath120 .",
    "there are two main steps",
    ".    * step 1 : @xmath47 applications of the decoder @xmath19 on the binary word of length @xmath15 .",
    "* step 2 : one application of the decoder @xmath76 on the word of length @xmath47 over @xmath55 .",
    "in addition , there are @xmath47 applications of each of the mappings @xmath242 and @xmath243 .",
    "we separately count the number of operations during each step .",
    "* step 1 : by the assumption on the decoding complexity of @xmath19 , @xmath47 applications of this decoder result in time @xmath244 + from the definition of @xmath13 , @xmath245 , so , we have @xmath246 by using the density of values of @xmath247 , we have @xmath248 , thus yielding @xmath249 . by substitution into  ( [ eq : complexity - step1 ] ) , we obtain that the time complexity of step 1 is @xmath250 . *",
    "step 2 : it is shown in  @xcite that the number of applications of decoders @xmath84 and @xmath85 on the word of @xmath60 of length @xmath47 over @xmath55 is bounded by @xmath251 , where @xmath252 and @xmath253 is an actual number of errors in the word .",
    "thus , if the ratio @xmath254 is bounded away from @xmath255 , and @xmath70 is a ramanujan graph , then the value of @xmath256 is bounded from above by an absolute constant ( independent of @xmath28 ) .",
    "+ the decoders @xmath84 and @xmath85 are applied on the words of length @xmath257 . when half minimum distance decoders for grs codes are used , their complexity is polynomial in @xmath4 . therefore , the decoding complexity in step 2 is bounded by @xmath258    each application of mapping @xmath242 or @xmath243 is equivalent to multiplication of a vector by a matrix , where the number of rows and columns in the matrix is @xmath259 .",
    "this can be done in time @xmath259 .",
    "summing up the decoding complexities of all steps of the decoder , we obtain that the total number of operations is bounded by @xmath241    * note . *",
    "the result in theorem  [ theorem : complexity ] is still valid if the outer code @xmath60 be replaced by any other code of rate @xmath260 , whose decoding time complexity is linear in @xmath47 and polynomial in @xmath4 , for a @xmath261-dense sequence of alphabet sizes .",
    "similarly to section  [ sec : main - results ] , assume in this and the next sections that @xmath2 is the capacity of the bsc with crossover probability @xmath121 , and the design code rate is @xmath1 .",
    "our purpose is to compare the parameters of the codes from section  [ sec : main - results ] with codes presented by barg and zmor in  @xcite and  @xcite ( with their respective decoding algorithms ) . in the sequel",
    "we show that the parameters of the codes from  @xcite and  @xcite can not be modified such that the decoding time complexity would be only sub - exponential in @xmath4 while keeping a non - zero error exponent .",
    "the reason is this : both decoding algorithms in  @xcite and  @xcite make use of sub - routines ( decoders for small constituent codes ) that have time complexity exponential in a degree of underlying expander graph .",
    "this degree , in turn , depends ( at least ) polynomially on @xmath4 .",
    "we briefly recall the construction and the decoder in  @xcite .",
    "let @xmath262 be a bipartite @xmath28-regular undirected connected graph with a vertex set @xmath29 such that @xmath30 and @xmath31 , and an edge set @xmath32 of size @xmath33 such that every edge in @xmath32 has one endpoint in @xmath34 and one endpoint in @xmath35 .",
    "let the size of the finite field @xmath45 be a power of @xmath231 .",
    "let @xmath41 and @xmath42 be two _ random _ codes of length @xmath28 over @xmath45 .",
    "the code @xmath263 is defined similarly to the definition of @xmath54 in  ( [ eq : define_c ] ) , with respect to @xmath41 and @xmath42 as defined in this paragraph .",
    "let us submit a word @xmath264 to the bsc .",
    "assume that @xmath265 is a received ( erroneous ) word . a formal definition of the decoder @xmath266 appears in figure  [ fig : decoder - bz2 ] .",
    "the number of iterations @xmath82 is taken to be @xmath267 .",
    "the decoders @xmath84 and @xmath85 are the _ maximum - likelihood _ decoders for the codes @xmath41 and @xmath42 , respectively .",
    "the analysis of codes in  @xcite is divided into two cases . in the first case , the codes @xmath41 and @xmath42 over @xmath268 are considered . in the second case , the analysis is generalized toward field sizes , which are large powers of 2 .",
    "we analyze these two cases separately .      in the binary case , following the analysis of  @xcite it is possible to show that for the code @xmath269 with the decoder @xmath266 , the decoding error probability , @xmath270 , is bounded by @xmath271 where @xmath272 , and the main term of @xmath273 is less or equal to @xmath274 and @xmath275 is the",
    "_ random coding exponent _ for rate @xmath276 over the bsc with a crossover probability @xmath121 .    if the codes @xmath269 ( binary , as assumed in this subsection ) , have a positive error exponent under the decoding by @xmath266 , then @xmath277 .",
    "[ prop : exp - zemor-2 ]    * proof . * in order to have a positive error exponent it is needed that @xmath278    observe that @xmath279 .",
    "it follows from  ( [ eq : zemor-2-exp ] ) that @xmath280 and thus @xmath281 .",
    "@xmath282    it is suggested in  @xcite to use the maximum - likelihood decoding for _ random _ codes @xmath41 and @xmath42 .",
    "this decoding , however , has time complexity at least @xmath283      suppose that the size of the field @xmath45 is a large power of 2 .",
    "in this case , for the code @xmath269 under the decoding by @xmath266 , the decoding error probability @xmath270 is bounded by @xmath284 and the main term of @xmath285 is less or equal to @xmath286 in this case , proposition  [ prop : exp - zemor-2 ] can be rewritten as    if the codes @xmath269 ( over large @xmath45 , as assumed in this subsection ) have a positive error exponent under the decoding by @xmath266 , then @xmath287 .",
    "the proof is very similar to that of proposition  [ prop : exp - zemor-2 ] .",
    "when using the maximum - likelihood decoder for _ random _ codes @xmath41 and @xmath42 , the decoding time complexity is at least @xmath288        recall the construction of expander codes presented in  @xcite .",
    "let @xmath289 be a bipartite graph with @xmath290 , such that each edge has one endpoint in @xmath291 and one endpoint in either @xmath292 or @xmath293 .",
    "let @xmath294 for @xmath295 .",
    "let the degree of each vertex in @xmath291 , @xmath292 , and @xmath293 be @xmath28 , @xmath111 , and @xmath296 , respectively .",
    "in addition , let the subgraph @xmath297 induced by @xmath298 be a regular bipartite ramanujan graph and denote by @xmath299 its edge set .",
    "let @xmath300 be a second largest eigenvalue of the adjacency matrix of @xmath297 .",
    "let @xmath41 be a @xmath301 $ ] linear binary code of rate @xmath302 .",
    "let @xmath42 be @xmath10-ary @xmath303 $ ] additive code , and let @xmath304 .",
    "let @xmath305 be @xmath10-ary code of length @xmath111 .",
    "the code @xmath306 is defined as the set of vectors @xmath307 , indexed by the set @xmath32 of size @xmath33 , such that    1 .   for every vertex @xmath308 ,",
    "the subvector @xmath309 is a @xmath10-ary codeword of @xmath41 and the set of coordinates @xmath310 is an information set for the code @xmath41 .",
    "2 .   for every vertex @xmath311 ,",
    "the subvector @xmath309 is a @xmath10-ary codeword of @xmath42 .",
    "3 .   for every vertex @xmath308 , the subvector @xmath312 is a codeword of @xmath305 .",
    "the authors of  @xcite proposed decoding algorithm for the code @xmath306 . in the first iteration , each subvector @xmath313 , @xmath308 , is treated as following : the decoder computes , for every symbol @xmath314 of the @xmath10-ary alphabet , and for every edge @xmath315 incident to @xmath316 , the weight of the edge as follows : @xmath317 where @xmath318 denotes the @xmath10-ary coordinate of the codeword @xmath319 that corresponds to the edge @xmath320 , and @xmath321 is the binary hamming distance .",
    "this information is passed along the edge @xmath320 to the corresponding decoder on the right - hand side of the bipartite graph . in the second iteration ,",
    "for every vertex @xmath322 the right decoder associated to it finds a @xmath10-ary codeword @xmath323 that satisfies @xmath324 and writes @xmath325 on the edge @xmath326 , @xmath327 .",
    "then , the decoder continues similarly to the decoder in  @xcite .",
    "let @xmath121 satisfy @xmath328 , and let @xmath329 .",
    "then , @xmath330 [ lemma : entropy-1 ]    the proof of this lemma appears in the appendix b.    let @xmath2 be the capacity of the bsc .",
    "the decoding error probability of a random code of rate @xmath331 , under the maximum - likelihood decoding , behaves as @xmath332 when @xmath333 .",
    "[ prop : epsilon-2 ]    * proof .",
    "* we start with the well - known expression for the probability exponent of the decoding error of a random code under the maximum - likelihood decoding  @xcite ,  @xcite .",
    "@xmath334 where @xmath335 and @xmath336 are some threshold rates , @xmath337 and @xmath338 at the code rates @xmath339 which are close to @xmath2 , the relevant expression for random coding exponent becomes @xmath340    next , we express all terms of the relevant part of  ( [ eq : exp - random ] ) in terms of @xmath6 .",
    "we recall , that @xmath341 and , thus , @xmath342 thus , when disregarding @xmath343 term , the equation  ( [ eq : decod_error ] ) becomes    @xmath344    @xmath345 @xmath346 where @xmath347 is a constant that depends only on the crossover probability @xmath121 of the channel .",
    "note that the transition @xmath348 follows from lemma  [ lemma : entropy-1 ] .",
    "@xmath282    if the codes @xmath306 have a positive error exponent , then @xmath349 .    *",
    "proof . * it is shown in  @xcite that the decoding error probability of the code @xmath306 , @xmath350 , satisfies @xmath351 where @xmath352 is a constant defined in  @xcite ( in paritcular , @xmath353 ) , and @xmath354 @xmath355 is the gilbert - varshamov relative distance for the rate r , and @xmath356 is a so - called _ critical rate _ , where @xmath357 ( see  @xcite for details ) .",
    "we are interested in small values of @xmath6 , i.e. @xmath358 . in this case",
    ", the value of @xmath359 can be rewritten as @xmath360 { } \\nonumber \\\\   & = & \\log_2 \\left ( \\frac{{{\\mathsf{h}}}_2^{-1}(1-r ) ( 1-p)}{(1 - { { \\mathsf{h}}}_2^{-1}(1-r))p } \\right ) \\nonumber \\\\ & = & \\log_2 \\left ( \\frac{{{\\mathsf{h}}}_2^{-1}({{\\mathsf{h}}}_2(p ) + \\varepsilon - \\varepsilon { { \\mathsf{h}}}_2(p ) ) ( 1-p ) } { ( 1 - { { \\mathsf{h}}}_2^{-1}({{\\mathsf{h}}}_2(p ) + \\varepsilon - \\varepsilon { { \\mathsf{h}}}_2(p)))p } \\right ) \\ ; , \\label{eq : m_r_p}\\end{aligned}\\ ] ] where the last transition is due to @xmath361 .",
    "using lemma  [ lemma : entropy-1 ] , the equality  ( [ eq : m_r_p ] ) becomes @xmath362 when ignoring the terms of @xmath363 and highest powers of @xmath6 , and denoting @xmath364 , this equation becomes @xmath365 using taylor s series for @xmath366 around @xmath255 we obtain @xmath367 and switching back to @xmath6 notation this becomes @xmath368 next , we evaluate the value of @xmath352 .",
    "recall that @xmath369 , and @xmath370 .",
    "we have @xmath371 in order to have a positive error exponent it is necessary that @xmath372 using proposition  [ prop : epsilon-2 ] , @xmath373 , and thus from  ( [ eq : m ] ) @xmath374 @xmath282    assuming that the first two decoding iterations are as suggested in @xcite , we conclude that the time complexity of the decoding is @xmath375 .",
    "* proof of lemma  [ lemma : forney ] .",
    "*    we analyze the error exponent , following the guidelines of the analysis of forney  ( * ? ? ?",
    "* chapter 4.2 ) .",
    "let @xmath376 , @xmath377 , be a random variable which equals @xmath255 if no inner decoding error is made while decoding @xmath378-th inner codeword , and @xmath379 otherwise . the outer code will fail to decode correctly if and only if @xmath380 denote @xmath381 using the chernoff bound , we obtain @xmath382 optimization of the exponent over values of @xmath383 yields that the maximum of the expression @xmath384 is achieved when @xmath385 and the maximum is @xmath386 thus completing the proof .",
    "* proof of lemma  [ lemma : entropy-1 ] .",
    "*    consider the value of the binary entropy function at the point @xmath387 for small @xmath388 .",
    "using taylor series around point @xmath121 , @xmath389 by calculation of the derivatives of the entropy function , one obtains @xmath390 and @xmath391 therefore , @xmath392 by applying the inverse of the binary entropy function on both sides of the equation , @xmath393 denote by @xmath89 the value of @xmath394 , thus obtaining @xmath395 by solving the quadratic equation @xmath396 or equivalently @xmath397 we obtain two solutions for the intermediate @xmath398 , namely @xmath399 however , only one of these solutions is positive : @xmath400 the later equality can be rewritten as @xmath401 using taylor series approximation @xmath402 for small values of @xmath403 , this becomes @xmath404 we substitute the evaluation of value of @xmath398 in  ( [ eq : value - x ] ) into the equation  ( [ eq : entropy - taylor-1 ] ) .",
    "thus , we obtain @xmath405 if @xmath406 is fixed and @xmath89 is small , then the value of @xmath407 is bounded away from @xmath255 . in this case , the derivative of @xmath408 at point @xmath409 is bounded , and , therefore @xmath410 then , the equality  ( [ eq : almost - final ] ) becomes @xmath411 finally , we substitute @xmath412 and receive that @xmath413 thus completing the proof of the lemma . @xmath282",
    "the authors are thankful to ronny roth and tom richardson for several helpful suggestions .",
    "the authors would also like to thank the anonymous reviewer c and amin shokrollahi for helpful comments that substantially improved the manuscript . the support of dimacs is gratefully acknowledged ."
  ],
  "abstract_text": [
    "<S> the decoding error probability of codes is studied as a function of their block length . </S>",
    "<S> it is shown that the existence of codes with a polynomially small decoding error probability implies the existence of codes with an exponentially small decoding error probability . </S>",
    "<S> specifically , it is assumed that there exists a family of codes of length @xmath0 and rate @xmath1 ( @xmath2 is a capacity of a binary symmetric channel ) , whose decoding probability decreases polynomially in @xmath3 . </S>",
    "<S> it is shown that if the decoding probability decreases sufficiently fast , but still only polynomially fast in @xmath3 , then there exists another such family of codes whose decoding error probability decreases exponentially fast in @xmath0 . moreover , if the decoding time complexity of the assumed family of codes is polynomial in @xmath0 and @xmath4 , then the decoding time complexity of the presented family is linear in @xmath0 and polynomial in @xmath4 . </S>",
    "<S> these codes are compared to the recently presented codes of barg and zmor , `` error exponents of expander codes , '' _ ieee trans . </S>",
    "<S> inform . </S>",
    "<S> theory , _ 2002 , and `` concatenated codes : serial and parallel , '' _ ieee trans . </S>",
    "<S> inform . theory , </S>",
    "<S> _ 2005 . </S>",
    "<S> it is shown that the latter families can not be tuned to have exponentially decaying ( in @xmath0 ) error probability , and at the same time to have decoding time complexity linear in @xmath0 and polynomial in @xmath4 .    </S>",
    "<S> concatenated codes , decoding complexity , decoding error probability , error exponent , expander codes , ira codes , iterative decoding , ldpc codes , linear - time decoding . </S>"
  ]
}