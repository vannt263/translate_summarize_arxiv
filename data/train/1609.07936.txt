{
  "article_text": [
    "the problem of the inverse transform arises in many different areas of sciences , including mathematics , physics , signal processing , image recognition , medical scanning , and many others @xcite .",
    "even some animals ( bats and dolphins ) effectively rely on inverse transformation when they use echolocation for determining the position of objects in space by using a special tool known as the sonar system @xcite .",
    "it is interesting that the processing of this information is so complicated , that in animal it is done by a dedicated part of its brain . in the following , we aim to benefit from the computational power of gpu for solving the problem of laplace inversion .    to be specific , we consider the spectral analysis formulation of the inverse problem , when the function of interest @xmath0 is integrated over a known kernel @xmath1 and the resulting function @xmath2 is assumed to have been obtained from the experiments or numerical simulations , @xmath3 the problem of inversion consists in reconstructing the spectral function @xmath0 given the knowledge of @xmath2 . for some kernels @xmath1 ,",
    "the reconstruction can be done relatively easily .",
    "for example , for the fourier transform with @xmath4 , the inversion is straightforwardly obtained by the inverse fourier transform . on the other hand , in the case of the also physically relevant laplace transform with its exponentially decaying kernel , @xmath5 , @xmath6 , the problem of inversion becomes mathematically ill - posed .",
    "this means that for a given signal @xmath2 , it is possible to find multiple spectral reconstructions @xmath0 such that the transformation  ( [ eq : transform ] ) is satisfied within the same level of numerical accuracy .",
    "the problem of the inverse laplace transform being ill - posed is gravely exacerbated when the task is being solved purely numerically .",
    "the presence of a grid for @xmath2 or @xmath7 , and the limit on the computer level of numerical accuracy are both sufficient to produce a continuum of equally `` satisfactory '' inverse transforms .",
    "additionally , the input data usually comes from other numerical calculations and contains a significant amount of statistical noise .",
    "one of the typical problems arising in the inverse laplace transform is the appearance of the sawtooth instability @xcite .",
    "the reconstructed weights @xmath0 with adjacent frequencies @xmath8 wildly oscillate , while they nonetheless provide a numerically good reconstruction for @xmath9 .",
    "one possible way out is to demand continuity of @xmath10 , but unfortunately , _ a priory _ it is not known if @xmath10 is continuous everywhere . on the contrary , it is quite typical that the spectrum contains a narrow peak .",
    "there are also known examples with discontinuous spectrum ( for example , one - dimensional ideal fermi gas ) .",
    "approaches based on _ stochastic reconstruction _ use the linear property of eq .",
    "( [ eq : transform ] ) , that is , that the transform  ( [ eq : transform ] ) of a sum of functions is a sum of their transforms . in other words , by generating a large number of inverse transforms of the same input data and averaging over the reconstructions with good values of the residue , typically it is possible to alleviate the problem caused by the sawtooth instability .",
    "another good feature of the stochastic averaging is that it provides a measure on the errorbars of the reconstruction .    a popular approach which produces rather smooth results is the _ maximal entropy _",
    "method @xcite . within this technique",
    "one formulates a target class of functions and ensures that the found reconstruction is the best within this class .",
    "the function which is minimized consists of the residue with an additional `` entropy '' term , which is weighted by an external parameter , sometimes associated with an effective temperature .",
    "an intermediate value of this parameter ensures that both the quality of the reconstruction and the smoothness through likeness to a chosen model are simultaneously optimized .",
    "although the maximal entropy method is very fast , it has a drawback in that due to the imposed constraints , an important systematic bias may be introduced .",
    "the reconstruction depends on the model and on the exact value of the external parameter ( effective temperature ) . additionally , it is not obvious to which extent the resulting errorbars reflect a possible bias due to a particular choice of the model .",
    "method of _ consistent constraints _",
    "@xcite aims at finding a reconstruction which at the same time is locally smooth and has a rather good residue .",
    "this method incorporates four penalties : optimizing residue , first derivative ( avoids sawtooth instability ) , amplitudes ( searches for a non - negative solution ) , and deviations from the target form ( chosen to stabilize the second derivative ) .",
    "the regularization constants in the penalties are adjusted consistently with the solution using a feedback protocol during the iterations .",
    "another recent approach dealing with the problem of inversion is based on the so - called genetic inversion via falsification of theories ( gift ) strategy @xcite .",
    "two main ingredients of this approach are the falsification principle and the genetic dynamics .",
    "a number of models are generated such that none of them falsify the requested properties , including the sum rules .",
    "the averaging over the resulting models is used to remove the spurious differences while enhancing the physical information .",
    "the `` genetic '' part of the method refers to the evolution - like processes ( selection , crossover and mutation of reconstructions ) that are used to evolve the subsequent generations .",
    "the large number of different approaches dealing with the inverse laplace problem underlines the importance of this task to the physics community , and the fact that no universal consensus has been reached as to which method provides the most reliable result . in this work",
    ", we implement what is essentially a brute - force approach to the inverse transform .",
    "we employ a very general piecewise spectral model , and assume little about the properties of the spectrum beyond the first two sum rules .",
    "we thus aim to put some light on the extend to which the inverse laplace transform can be carried on a computer without imposing any particular restraint on the nature of the resulting spectrum .",
    "this limit , one may hope , is changing as more powerful computing architecture becomes available .",
    "we use the method of simulated annealing to minimize the residue of the transform , and build the final spectrum from a large number of transforms computed in parallel on a graphical processing card ( gpu ) .",
    "the program is written in cuda as is made available to public .",
    "interested readers are welcome to use this program with limits to the spectral model that are specific to their particular systems of interest .",
    "it is assumed that the correlation data @xmath11 is available on a uniform grid of size @xmath12 , @xmath13 in the case of dynamic form factor , @xmath14 , each @xmath15-vector can be transformed independently , thus for simplicity we will omit the @xmath15 index in the following .",
    "the _ spectral model _ in the frequency domain is taken to be a piecewise - rectangular function , @xmath16 we start the indexing from zero to be consistent with the computer program .",
    "the real - valued nonnegative coefficients @xmath17 define the spectral model in the range @xmath18 $ ] .",
    "the _ correlation model _ in the imaginary - time domain is therefore given by @xmath19 terminating the above integral at @xmath20 enforces the assumption that the spectral model @xmath7 is equal to zero everywhere above the maximal frequency .",
    "although in general the spectrum might have an infinite support , physically the containing energy is finite and is mostly contained in a finite range of frequencies . in practice",
    ", the assumption of the maximal frequency works well and always can be checked by making the ceiling higher .",
    "the evaluation of correlation model  ( [ eq : correlation - model ] ) is numerically efficient .",
    "one can write @xmath21 with @xmath22 we define the residue , or error , function as @xmath23 the residue is a nonnegative function defined in the space of coefficients @xmath17 . given the large size of this space , it is troublesome to minimize @xmath24 directly . instead , we follow the prescription of the simulated annealing method  @xcite .",
    "we interpret the function @xmath25 \\prod_j\\theta(a_j ) \\label{eq : probability - density}\\ ] ] as a multivariate probability density for the spectral coefficients @xmath17 with @xmath26 being the effective temperature . in the limit when the parameter @xmath26 is small , the likely values of the coefficients are limited to those which minimize @xmath24 .",
    "the assumption of the annealing method is that one may begin to sample probability density  ( [ eq : probability - density ] ) with large @xmath26 , where a broad range of values of @xmath17 is allowed by the probability density , then to gradually decrease @xmath26 to compress the allowed space of @xmath17 close to the region where one minimizes the residue function .",
    "that is , we aim to compute the `` frozen '' limits @xmath27 , defined as @xmath28 fittingly for multidimensional integration , the above expression is evaluated with the monte carlo method . by analogy with the classical statistical mechanics , we refer to @xmath26 as the annealing temperature , although in our case its meaning is purely mathematical .",
    "the manner in which one lowers the annealing temperature is called the annealing prescription .",
    "we will describe our prescription further below .",
    "the annealing method relies on an efficient sampling of the probability density given by eq .",
    "( [ eq : probability - density ] ) .",
    "we carry this sampling with the metropolis method  @xcite .",
    "the progress of the markov chain benefits from an efficient choice of updates . we have designed the moves to be simultaneously numerically efficient and to preserve the first two sum rules . for our spectral model , the sum rules are satisfied if the moves preserve two sums on the spectral coefficients @xmath17 , @xmath29 and @xmath30 where we have defined the sum constants @xmath31 and @xmath32",
    ". the first constant is known directly from the input as one can notice from eq .",
    "( [ eq : efficient - correlation - model ] ) , @xmath33 constant @xmath32 requires the knowledge of the @xmath15-vector at which the correlation data was collected and thus must be provided as an additional input to the program .",
    "we intent to perform the metropolis updates in the restricted space where both @xmath31 and @xmath32 sums are constant . to this end , we select two indices , @xmath34 and @xmath35 , and two amplitudes , @xmath36 and @xmath37 .",
    "the spectral model is updated according to @xmath38 it is straight - forward to verify that both sum rules are preserved if one satisfies @xmath39 ( 1-r ) \\label{eq : update - delta - p}\\\\ \\delta_s ( { \\omega}_s-{\\omega}_p ) & = [ b - a({\\omega}_p+\\delta{\\omega}/2 ) ] ( 1-r ) \\label{eq : update - delta - s}.\\end{aligned}\\ ] ] we select the value of @xmath40 as our `` random move '' , which determines the values of @xmath36 and @xmath37 .    the moves that would result in a negative spectral model are rejected according to the definition of the probability density given in eq .",
    "( [ eq : probability - density ] ) .",
    "the strength of the update scheme  ( [ eq : update - scheme - p])([eq : update - scheme - j ] ) becomes apparent when one notices that the updated correlation model is given by @xmath41 thus each update requires only @xmath42 calculations and even does not require memory loads for the spectral coefficients @xmath17 . to update the entire model",
    ", one needs @xmath43 single updates .",
    "thus a macroupdate requires only @xmath44 calculations .",
    "the ergodicity of the update scheme can be easily verified for the case of small update amplitudes , which is always the case towards the end of the annealing procedure .    at first glance",
    ", this update scheme introduces a special sampling frequency , @xmath45 according to eqs .",
    "( [ eq : update - delta - p ] ) and ( [ eq : update - delta - s ] ) , if one of the updated frequencies is close to @xmath46 , amplitude update to the spectral density at the other frequency will be suppressed .",
    "however , the amplitude update at the @xmath46 itself is not suppressed .",
    "it is the update at the other frequency that would be suppressed on such an occasion .",
    "however , the pairs of @xmath47 and @xmath48 are selected independently of each other and thus the effect , if any , is spread throughout the spectrum .",
    "whenever we do find any artifacts around @xmath46 , they are usually on the same level of magnitude as other artifacts in the system .",
    "we have found that our annealing scheme is more efficient when we update more frequently the elements that contain larger spectral density . on the other hand , frequencies with small spectral coefficients @xmath17",
    "must also be updated , although perhaps less often .",
    "the spectral coefficients are nonnegative and can be interpreted as probability density . for each move",
    ", we perform a truncated markov walk in the space of the spectral coefficients , and thus select the indices @xmath34 and @xmath35 .",
    "if the walk has zero length , indices @xmath34 and @xmath35 are selected randomly and uniformly on @xmath49 $ ] . in the limit of",
    "infinitely long walks , the indices are selected according to probability @xmath50 .",
    "the truncated walk provides a convenient mixture of the two distributions .",
    "additionally , a small fraction of the uniform distribution can be mixed in .",
    "we found it rather difficult to provide a universal cooling prescription for the different correlation data that we have had considered .",
    "instead , we developed a `` self - cooling '' prescription in which the temperature is lowered according to the residue to which the system has already been able to relax .",
    "suppose @xmath51 is the average residue of the annealing population , and @xmath52 is the smallest one . in the beginning , we set @xmath26 close @xmath51 . in this regime ,",
    "the system `` boils '' to the largest residues allowed under the restraint of the sum rules and the limited number of the degrees of freedom . after a certain number of steps , the temperature is slowly ramped towards @xmath52",
    "this is usually accompanied by a sharp decrease in the residue .",
    "such a cooling stage is followed by a freeze - out as the temperature is lowered below the minimal residue in the ensemble .",
    "the freeze - out has temperature lowered proportionately to the the number of steps carried .",
    "the annealing is carried on an ensemble of @xmath53 walkers , each representing a separate markov chain of the metropolis monte carlo described in the above subsections .",
    "we have found that the annealing process is improved if we incorporate branching between the walkers , similar to the branching of walkers in the green s function monte carlo @xcite methods .",
    "this idea was inspired by the replication of information in the gift method @xcite , and by the recent success of the simulated quantum annealing methods .",
    "branching made a considerable difference in minimizing the residue of the resulting transform .",
    "however , several attempts to map the system to a quantum hamiltonian and carry a full simulated quantum annealing did not lead to an improvement .",
    "for this reason , we carry an annealing process in which sampling is carried with the metropolis method as described above , i.e. sampling the probability density given by eq .",
    "( [ eq : probability - density ] ) .",
    "after a certain number of metropolis steps , weights are assigned according to eq .",
    "( [ eq : probability - density ] ) , @xmath54,\\ ] ] with two constants @xmath55 and @xmath56 as explained below .",
    "each walker is assigned an integer multiplier @xmath57 according to @xmath58 where @xmath59 is a random number uniformly distributed on the unit interval and @xmath60 denotes the floor function .",
    "the expectation value of the multiplier @xmath57 equals to the weight @xmath61 . for each branching event",
    ", the parameter @xmath55 is adjusted in such a way that , for a once generated set of random numbers @xmath59 , the sum of all multipliers equals to the number of walkers , i.e.  fixing the population of walkers .",
    "parameter @xmath56 is found numerically such that a given fraction of walkers is assigned a zero multiplier , @xmath62 .",
    "we refer to this fraction of walkers as the _ branching fraction_. these walkers are to be replaced by the walkers with @xmath63 .",
    "linearity of the transform ( and the sum rules ) allows for a unique branching in which the walkers are not completely removed and replaced by `` better '' walkers but instead are transformed to a linear combination of their own spectral density and the density from the replacing walker .",
    "we refer to this process as _ imprinting_. let the index of one of the walkers with zero multiplier be @xmath64 and its spectral model @xmath65 ; let @xmath66 be the index of the walker that was selected to imprint on @xmath64 .",
    "the result of imprinting is a change in the spectrum of @xmath64 , @xmath67 and no change in the spectrum of @xmath66 .",
    "the imprint strength @xmath68 can be set constant or adjusted during the execution . in the limit @xmath69 one recovers traditional branching .",
    "as the system freezes to a minimum of the residue , each walker begins to develop sawtooth instability .",
    "branching can then propagate a particular instability through the entire population of walkers .",
    "an example of this effect is shown further below .",
    "we find that it is possible to counter most of this effect by reducing the imprinting strength and the branching fraction according to the decrease of the acceptance probability . with less branching , the population effectively self - averages as random moves are taken around the global minimum .",
    "the average is then enforced on the population through the imprinting .",
    "the adaptive branching strength described in the above section significantly delays the onset of the sawtooth instability , but does not prevent its eventual formation . to counter this effect , we introduced a three - point stencil for smoothing the transform , according to @xmath70 which we carry with a rather small smoothing amplitude @xmath35 , usually of the order of several percent .",
    "the smoothing stencil preserves the first sum rule , but requires an additional renormalization due to a violation in the second sum rule of the order of @xmath71 , which is quite small both because the spectral density on the endpoints tends to vanish , and because @xmath72 .",
    "it is important to point out that smoothing here is not a form of post - processing , but is instead a part of the algorithm itself .",
    "once the transforms are smoothed and renormalized , they undergo metropolis updates and branching .",
    "the process is then repeated .",
    "walkers in which smoothing were to produce unfavorable residue values are branched away .      as the residue function approaches its minimum , and the annealing temperature",
    "is significantly decreased , the acceptance rate of the proposed moves decreases . to improve sampling at this stage ,",
    "one may decrease the width of the distribution of the displacement of @xmath73 .",
    "we choose to scale the displacement amplitude by an additional factor @xmath74 which is computed according to the ongoing acceptance rate @xmath75 as @xmath76 where one selects parameters @xmath57 and @xmath34 , @xmath63 and @xmath77 .",
    "the choice of parameters is discussed below .",
    "this inversion code aims to require minimal user and problem - specific input , even at expense of additional computational effort .",
    "this requires a number of choices to be fixed `` out - of - the - box '' .",
    "however , if required , most of the parameters discussed in this section can be readily adjusted .",
    "the number of nodes in the correlation data @xmath12 and the timestep @xmath78 are fixed by the user in the input data .",
    "the user must also select the spectral domain , by specifying @xmath79 and @xmath80 .",
    "the `` natural '' scale for the annealing temperature @xmath26 is determined by the value of the residual , which is in turn determined by the input data . before the annealing",
    ", the program computes the starting residue value .",
    "it is then used as a unit of both annealing temperature and the residue .",
    "thus the starting ( scaled ) residue is always equal to unity .",
    "we choose the starting annealing temperature as equal to @xmath81 , which results in the initial boiling of the system .",
    "the annealing process in organized into blocks .",
    "each block consists of a number of metropolis steps . to update the entire spectral model",
    ", one should carry about @xmath80 such steps .",
    "each block thus consists of some @xmath82 steps .",
    "we select @xmath83 .",
    "each block is followed by the branching step .",
    "we select to branch a quarter of all walkers on the branching step , combined with a small imprinting strength equal to @xmath84 .",
    "after some experimentation , we found that the parameter @xmath34 from eq .",
    "( [ eq : amplitude - acceptance - adjustment ] ) might as well be set to @xmath85 .",
    "we also select @xmath86 .    ) .",
    "solid line shows the numerically precise correlation data .",
    "samples a through c show data resampled as outlined in section  [ sec : resampling ] .",
    "these samples correspond to the r.m.s .",
    "noise level close to , correspondingly , @xmath87 , @xmath88 , and @xmath89 .",
    "the lowest noise level required sampling of @xmath90 correlated sequences .",
    "the inset shows the spectral density that was used to build the correlation data .",
    "[ fig : lorentzian - noise ] ]",
    "the package has been maximally streamlined and simplified for the distribution .",
    "it includes just three files , ` sail.cpp ` which includes all of the host functions and gpu kernels , ` sail.h ` which is simultaneously a header file and the file which contains certain execution parameters , and ` main.cpp ` file which shows how to invoke the transform .",
    "all the relevant methods are wrapped in a single c++ class called ` ilaplace ` .",
    "the user is expected to invoke a single instance of this class for a given transform , call parameter setters and finally invoke the anneal method .",
    "all of this is demonstrated in ` main.cpp ` .",
    "a makefile is included to aid compilation .",
    "since most of the parameters are set through the preprocessor macros , it is expected that recompilation will be often necessary .    upon unpacking , the code may be compiled on a cuda - enabled machine by invoking    .... make sail ....    the program requires nvidia gpu with compute capability of at least 3.5 ( i.e.  kepler generation ) or larger .",
    "the directory contains a file named ` corr.in ` which is the data for sample c from the next section .",
    "the annealing may be invoked by executing    ....",
    "./sail   ....    as the annealing proceeds , the code will print current values of temperature , residue , and the acceptance rate .",
    "a sample output is located in a subdirectory , in file ` sample - run / log-1500 ` .",
    "the sample was obtained on a k40 card .",
    "the same subdirectory contains other input data that was used in section  [ sec : intro - toy ] .",
    "this sample execution will store the ongoing spectrum after each execution block , to the file named ` spectrum.dat ` and to a file named ` spectrum-%5d.dat ` , where the five - digits number space ` % 5d ` contains the block number .",
    "once the program reaches the anneal minimum , it will terminate and store the final spectrum into file ` spectrum-fin.dat ` .",
    "a number of example spectra are placed in directory ` sample - run ` .",
    "users are encouraged to explore the header file , ` sail.h ` , to see the adjustable parameters . in particular ,",
    "if the user s gpu lacks in memory capacity , it may be necessary to reduce the number of walkers defined in the macro ` ninstance ` .",
    "here we present the results of the inversion obtained for a toy model .",
    "the input is exact to double numerical precision and thus by far exceeds any input that may be possible with real - world data .",
    "however , the number of grid points and the extend of the time domain are both limited .",
    "thus there is a continuum of spectral models that can fit this `` exact '' correlation data .",
    "studying such a case allows one to understand the fundamental limitations of the particular inversion algorithm , before they are masked by inaccuracy of the input data .",
    "we also invert toy models which simulate noisy input data .",
    "the outcome of typical monte carlo simulation for the correlation data contains strongly correlated statistical noise .",
    "such noise arises primarily from undersampling of the density - density correlation .",
    "the errors that originate from the algorithm itself are instead systematic in nature . characteristically , undersampling is also more severe for larger values of @xmath91 .",
    "we emulate this effect as follows .",
    "starting from the known model @xmath92 , we compute the multivariate gaussian distribution which has the autocorrelation equal to the one we desire . from this distribution",
    "we draw a limited number of instances , where each instance is itself a correlated gaussian sequence .",
    "we compute the autocorrelation of this limited set , which thus has the undersampling noise built into it .",
    "this process results in correlation data with a realistic noise profile . noise level can be varied by adjusting the number of sampled sequences .",
    "an example of resulting correlation data is shown in fig .",
    "[ fig : lorentzian - noise ] .      for our model , we select a double - peak lorentzian spectrum that is additionally cut to a strip of frequencies , that is @xmath93 \\theta({\\omega}-{\\omega}_{l } ) \\theta({\\omega}_{h}-{\\omega } ) , \\label{eq : lorentzian - band}\\ ] ] where @xmath94 is a lorentzian centered around @xmath95 with half - width at half - maximum given by @xmath96 .",
    "we use lorentzians of equal width , @xmath97 , and located at @xmath98 and @xmath99 .",
    "band is clipped at @xmath100 and @xmath101 .",
    "the resulting function can be seen in the inset to fig .",
    "[ fig : lorentzian - noise ] .",
    "such a structure allows to study several aspects of the inversion algorithm .",
    "the exact shape of the second peak is known to be difficult to reconstruct @xcite .",
    "the low but non - vanishing region between the peaks allows to see the `` dynamic range '' of the method , that is , how well does the method resolve the low amplitudes that are present in conjunction with the large ones .",
    "finally , the band clippings at @xmath102 and @xmath103 provide a well - defined frequency domain but are challenging to resolve as they occur at low amplitudes .",
    "we carried the annealing procedure following the described above protocol .",
    "the frequency domain was limited to @xmath104 and the spectral model was intentionally oversampled .",
    "we use one thousand points in the frequency domain . in this regime",
    ", there is little observable dependence on the number of frequency nodes .",
    "all the results presented here were obtained with @xmath105 walkers .    .",
    "the reconstruction used imprinted branching as described in section  [ sec : branching ] , but employed neither adaptive branching nor smoothing .",
    "the transforms shown here are from the same sequence , marked by their decreasing value of the residue function @xmath24 .",
    "once the transform reached the residue value of @xmath106 , it has mostly converged .",
    "however , further `` improvement '' followed with the residue dropping to below @xmath107 .",
    "this gain came mostly from the sawtooth pattern which developed in the spectrum .",
    "that is , such a pattern fits the grid input data better .",
    "[ fig : sawtooth ] ]    .",
    "one can notice deterioration of the transform quality .",
    "the low - level features , such as the lower cusp frequency , are not reproduced .",
    "the shape of the peak is increasingly deteriorated .",
    "furthermore , sample b dataset , with noise at the level of about @xmath88 , developed a phantom low - frequency feature , albeit with low intensity .",
    "transform for sample a , with noise level @xmath108 , failed to discern the second peak and is not shown here .",
    "the inset shows the transforms on the linear scale .",
    "[ fig : anneals ] ]    annealing with fixed branching ratio and imprint strength @xmath84 , as described in section  [ sec : branching ] , revealed the sawtooth instability .",
    "the corresponding transforms are shown in fig .",
    "[ fig : sawtooth ] .",
    "it is worthwhile to notice that the transformation has mostly converged before the instability started to develop .",
    "thus in some cases , user may prefer to terminate the transform early . to avoid the instability , below we have used both the adaptive branching and smoothing as described in sections  [ sec : branching ] and  [ sec : smoothing ] .",
    "the smoothing parameter was selected to be @xmath108 .",
    "because of its small amplitude , and the large number of steps taken in each block ( @xmath109 ) , the effect of smoothing did not appear until the late stages of annealing .",
    "we further tested the method with the artificially noisy input data , built as described above and shown in fig .",
    "[ fig : lorentzian - noise ] .",
    "the resulting transforms are shown in fig .",
    "[ fig : anneals ] .",
    "we find that the for the noise levels under @xmath108 ( samples b and c ) , both peaks are discovered by the method .",
    "the location and shape of the peaks is increasingly distorted with increasing noise , until the peaks are no longer discernible ( transform for sample a with noise level @xmath108 is not shown in fig .",
    "[ fig : anneals ] ) .",
    "position of each peak is determined with certain error , which increased with the increasing noise level . for sample b data ,",
    "error in the peak location reached 0.05 , i.e.  as much as @xmath110 for the first peak .",
    "the heights of the peaks are not reproduced very well , which is quite visible on the linear scale ( see the inset in fig .",
    "[ fig : anneals ] ) .",
    "we compared the discrepancy in strength of the peaks . here",
    "we define the skew as @xmath111 where @xmath112 is the midpoint between the peaks in eq .",
    "( [ eq : lorentzian - band ] ) .",
    "we found that for the noiseless data , the skew is rather small , @xmath113 . for noise level @xmath89 , we found @xmath114 and for noise level of @xmath88 , @xmath115 .",
    "that is , the absolute strength of the peak is a property that is reproduced much better than its shape , a property of the inverse transform reported and studied in detail in @xcite . indeed",
    ", it is possible to find properties that map from ill - posed transforms but are themselves well - posed  @xcite .",
    "finally , it is worth noting that the upper cusp of the band @xmath103 was not detected by either transform , while the lower cusp @xmath102 was only detected by the transform of the noiseless data . in all transforms , it is possible to notice the feature around the special sampling frequency , which in our case lies exactly in - between the peaks .",
    "however , the distortion introduced at this frequency is in fact of the same magnitude as the distortion introduced around the lower cusp edge etc .",
    "to conclude , we addressed the problem of the inverse laplace transform .",
    "the main achievements are twofold : ( i ) we have proposed the _ imprinted branching _",
    "strategy to improve the quality of the reconstructed spectral function ; ( ii ) we have implemented an efficient cuda - based parallel code that is being released as an open - source software .    in order to demonstrate the efficiency of our code , we have considered a complicated example of a truncated double - peak lorentzian spectrum .",
    "we show how the noise in the input data affects the reconstruction . for the noise @xmath108",
    "the second peak is absent , while with @xmath87 and @xmath88 the reconstruction is getting progressively better .",
    "the inversion scheme is based on the annealing technique where the effective temperature is introduced in order to deal efficiently with the minimization of the @xmath24 function which has a large number of degrees of freedom . to improve the accuracy",
    "further we propose the method of imprinted branching in which the spectrum is replicated into an ensemble of _",
    "walkers_. according to the goodness of the reconstruction of the walkers , each of them may produce different number of descendants including one ( the walker is simply copied ) , zero ( the walker is killed ) , two and more ( i.e. it gets replicated ) . in the latter case",
    ", the branching is done using a mixture of walkers , so that some properties of one walker is imprinted on the other .",
    "when very low values of the @xmath24 are reached , the sawtooth instability appears . in order to deal with it",
    "we use a smoothing method",
    ".    we have developed and tested a cuda program for an efficient inverse laplace transform .",
    "we create such an algorithm that all updates are local using to its best the cuda architecture .",
    "furthermore , we write the updates in such a form that the first two sum rules are preserved , incorporating the known physical information .",
    "importantly , we do not impose any restriction on the spectrum so that the code has a very general applicability .",
    "the use of cuda is extremely well suited to this heavy - number crunching problem , resulting in a community - friendly code .",
    "a computational power of s single gpu card may be comparable to that of several modern multicore cpus , an is equivalent to having a small cluster in a single pc .",
    "we hope that our package will be useful for scientists who have to deal with the inverse laplace transform .",
    "authors thankfully acknowledge the computer resources and assistance provided by the spanish supercomputing network ( red espaola de supercomputacin ) .",
    "we thank the nvidia corp . for provided hardware and support . g.e.a .",
    "acknowledges support by the micinn ( spain ) grant no .",
    "fis2014 - 56257-c2 - 1-p .",
    "a.  dirks , p.  werner , m.  jarrell , t.  pruschke , continuous - time quantum monte carlo and maximum entropy approach to an imaginary - time formulation of strongly correlated steady - state transport , phys .",
    "e   82 ( 2010 ) 026701 .",
    "a.  s. mishchenko , stochastic optimization method for analytic continuation , in : f.  a. e.  pavarini , w.  koch , m.  jarrel ( eds . ) , correlated electrons : from models to materials , forschungszentrum julich , julich , 2012 , ch ."
  ],
  "abstract_text": [
    "<S> we developed a cuda - based parallelization of the annealing method for the inverse laplace transform problem . </S>",
    "<S> the algorithm is based on annealing algorithm and minimizes residue of the reconstruction of the spectral function . </S>",
    "<S> we introduce local updates which preserve first two sum rules and allow an efficient parallel cuda implementation . </S>",
    "<S> annealing is performed with the monte carlo method on a population of markov walkers . </S>",
    "<S> we propose _ imprinted branching _ method to improve further the convergence of the anneal . </S>",
    "<S> the algorithm is tested on truncated double - peak lorentzian spectrum with examples of how the error in the input data affects the reconstruction .    </S>",
    "<S> laplace transform , analytic continuation , monte carlo , cuda , gpu .    </S>",
    "<S> * program summary *    _ program title : _ sail ( simulated annealing for the inverse laplace transform ) + _ licensing provisions : _ mit + _ programming language : _ cuda - c + _ nature of problem : _ </S>",
    "<S> + inverse laplace transform is carried by means of repeated simulated annealing of the correlation data with a simple spectral model . </S>",
    "<S> use of the gpu computing allows for significant improvement in the computational throughput . </S>"
  ]
}