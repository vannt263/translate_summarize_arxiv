{
  "article_text": [
    "distributed optimization problems over networks are usually formulated as having agents in a network cooperatively minimize the sum of local costs incurred by the agents .",
    "formally , we consider a decision variable @xmath3 and a strongly - connected network containing @xmath4 agents where each agent @xmath5 has only access to a local objective function @xmath6 .",
    "the agents aim to minimize the sum of their objectives , @xmath7 , through local information exchange .",
    "this class of problems has recently received much attention and has found various applications , e.g. , in distributed learning ,  @xcite , source localization ,  @xcite , and formation control @xcite .    to address the problem , many distributed optimization methods",
    "have been developed in recent years .",
    "the initial approaches were based on distributed ( sub)gradient descent ,  @xcite , which is intuitive and computationally simple but usually slow due to the diminishing step - size used in the algorithm .",
    "the convergence rates are shown to be @xmath8 .",
    "afterwards , methods based on lagrangian dual variables were developed .",
    "the resulting algorithms include distributed dual decomposition ,  @xcite , and distributed implementation of alternating direction method of multipliers ( admm ) ,  @xcite .",
    "the convergence rates of these approaches accelerate to @xmath9 . under the strong convexity assumption ,",
    "the convergence rate has been shown to be linear , i.e. , @xmath0 for @xmath1 . however , the updates require to solve an optimization sub - problem at each iteration , which increases the computational burden . to achieve both fast convergence rate and computational simplicity ,",
    "some distributed algorithms do not ( explicitly ) use dual variables while sticking to a constant step - size .",
    "for example , the distributed nesterov - based method ,  @xcite , achieves @xmath10 under the bounded and lipschitz gradients assumptions .",
    "it can be interpreted to have an inner loop , where information is exchanged , within every outer loop where the optimization - step is performed .",
    "@xcite use a constant step - size and the gradients of the last two iterates to achieve an exact convergence with fast convergence rate .",
    "the methods converge at @xmath9 for general convex functions and they have a linear rate under the strong - convexity assumption .",
    "all these methods ,  @xcite , assume the multi - agent network to be an undirected graph , i.e. , if agent  @xmath5 can send information to agent  @xmath11 , then agent  @xmath11 can also send information to agent  @xmath5 .",
    "however , it is not always practical to assume the underlying graph to be undirected .",
    "for example , agents may broadcast at different power levels , implying communication capability in one direction , but not in the other .",
    "moreover , an algorithm may require disconnecting slow communication links while still remaining convergent ; a procedure that may result in a directed graph . in general ,",
    "a directed topology is more flexible compared with an undirected topology .",
    "typical distributed optimization methods require the use of doubly - stochastic weighting matrices , which are not available in a distributed fashion when the graphs are directed .",
    "in fact , either row - stochastic matrices or column - stochastic matrices can be achieved .",
    "we report the papers considering directed graphs here . the ( sub)gradient - push ( sp ) ,  @xcite , is the first to employ only column - stochastic matrices by applying the push - sum consensus ,  @xcite , to distributed ( sub)gradient descent ,  @xcite . inspired by these ideas , directed - distributed ( sub)gradient descent ( d - dsd ) ,  @xcite , combines surplus consensus ,  @xcite , and distributed ( sub)gradient descent ,  @xcite .",
    "@xcite combines the weight - balancing technique in @xcite with the distributed ( sub)gradient descent ,  @xcite .",
    "these ( sub)gradient - based methods ,  @xcite , restricted by diminishing step - sizes , converge at  @xmath8 . to accelerate the convergence , dextra ,  @xcite combines push - sum consensus ,  @xcite , and extra ,  @xcite .",
    "the method converges linearly under the strong - convexity assumption with the step - size being carefully chosen in some interval .",
    "this interval of step - size is later relaxed in refs .",
    "@xcite , while keeping the linear convergence unchanged .",
    "note that though avoiding constructing a doubly - stochastic matrix , all above methods ,  @xcite , require that each agent knows its out - degree exactly and controls its outgoing weights so that they sum up to one , leading to column - stochastic weighting matrices .",
    "this requirement is impractical in many situations , especially when the agents use a broadcast - based communication scheme , and thus each agent neither knows its out - neighbors nor is able to adjust its outgoing weights .",
    "compared with column - stochastic matrices , row - stochastic matrices are much easier to implement in a distributed fashion as each agent can locally decide the weights .",
    "the proposed algorithm in this paper builds on ref .",
    "@xcite , which employs only row - stochastic weighting matrices .",
    "however , the convergence rate in ref .",
    "@xcite is  @xmath8 , which is relatively slow . in this paper",
    ", we propose a fast and fully distributed algorithm to solve the distributed optimization problem over directed graphs .",
    "the algorithm assumes no information of agents out - degree , and achieves a linear convergence rate , i.e. ,  @xmath0 for  @xmath1 , which is the best rate of convergence for this class of problems .",
    "the remainder of the paper is organized as follows .",
    "section  [ s2 ] formulates the problem and describes the algorithm with appropriate assumptions .",
    "section  [ s3 ] states the main convergence results , the proofs of which are provided in section  [ s4 ] .",
    "we show numerical results in section  [ s5 ] and section  [ s6 ] contains the concluding remarks .",
    "* notations : * we use lowercase italic letters to denote scalars , lowercase bold letters to denote vectors , and uppercase italic letters to denote matrices , e.g. ,  @xmath12 ,  @xmath13 ,  @xmath14 , for some positive integer  @xmath4 .",
    "the matrix ,  @xmath15 , represents the  @xmath16 identity , and  @xmath17 and @xmath18 are the  @xmath4-dimensional vectors of all @xmath19 s and @xmath20 s for any @xmath4 .",
    "we denote @xmath21^\\top$ ] . for an arbitrary vector @xmath22 , we denote @xmath23_i$ ] its @xmath5th element .",
    "the euclidean norm of any vector , @xmath22 , is denoted by @xmath24 . for a differentiable function",
    "@xmath25 ,  @xmath26 denotes the gradient of  @xmath27 at  @xmath22 .",
    "the spectral radius of a matrix , @xmath28 , is represented by @xmath29 , and @xmath30 denotes the @xmath5th eigenvalue of @xmath28 . for a matrix @xmath31",
    ", we denote @xmath32 a diagonal matrix consisting of the corresponding diagonal elements of @xmath31 .",
    "in this section , we formulate the distributed optimization problem , formalize the assumptions , and describe our algorithm . consider a strongly - connected network of  @xmath4 agents communicating over a _ directed _ graph ,  @xmath33 , where  @xmath34 is the set of agents , and  @xmath35 is the collection of ordered pairs ,  @xmath36 , such that agent  @xmath11 can send information to agent  @xmath5 .",
    "define  @xmath37 to be the collection of agent @xmath5 s in - neighbors , i.e. , the set of agents that can send information to agent  @xmath5 .",
    ", in this paper since the algorithm requires no knowledge of out - degree of any agent .",
    "] we focus on solving an optimization problem that is distributed over the above multi - agent network .",
    "in particular , the network of agents cooperatively wants to solve the following optimization problem : @xmath38 where each local objective function , @xmath39 , is convex and differentiable , and known only by agent @xmath5 .",
    "our goal is to develop a distributed iterative algorithm such that each agent converges to the global solution of problem p1 given that the underlying graph , @xmath40 , is directed .    before proposing the algorithm",
    ", we are going to formalize the set of assumptions we will use for our results .",
    "the following assumptions are standard in the literature concerning distributed , smooth optimization , see e.g. ,  @xcite .",
    "[ asp2 ] the directed graph is strongly - connected .",
    "[ asp3 ] the optimal solution exists .    [ asp1 ] each local function ,  @xmath41 , is differentiable and strongly - convex , and the gradient is lipschitz continuous , i.e. , for any @xmath5 and @xmath42 ,    1 .",
    "there exists a positive constant @xmath43 such that , @xmath44 2 .",
    "there exists a positive constant @xmath45 such that , @xmath46    to solve problem p1 , we propose the following algorithm . each agent @xmath5 maintains three vectors , @xmath47 , @xmath48 , and @xmath49 , where @xmath2 is the discrete - time index . at @xmath2th iteration ,",
    "agent  @xmath5 performs the following updates    [ alg1 ] @xmath50_i}-\\frac{\\nabla \\mb{f}_i(\\mb{x}_{k , i})}{[\\mb{y}_{k , i}]_i},\\label{alg1d }      \\end{aligned}\\ ] ]    where @xmath51 is the weight agent @xmath5 assigning to agent @xmath11 , @xmath52 is the constant step - size , @xmath53 is the gradient of @xmath41 at @xmath47 , and @xmath54_i$ ] denotes the @xmath5th element of @xmath55 .",
    "moreover , the weight @xmath51 satisfies that @xmath56 for any agent @xmath5 , it is initiated with an arbitrary vector , @xmath57 , with @xmath58 and  @xmath59 .  . ] in essence , the updates in eqs .   and   form a modified version of the algorithm in @xcite where the gradients are scaled by the updates in eq .  .",
    "the modification enables the algorithm s convergence to the optimal solution with the collection of weights being only row - stochastic but not doubly - stochastic .    to simplify the analysis , we assume in the remaining of the paper that the sequences , @xmath60 and @xmath61 , updated by eq .  , have only one dimension , i.e. , @xmath62 ; thus @xmath63 , @xmath64 , @xmath65 , @xmath66 . for @xmath47 , @xmath67 ,",
    "@xmath53 being  @xmath68-dimensional vectors , the proof will be the same by introducing kronecker product .",
    "therefore , assuming  @xmath62 is without the loss of generality .",
    "we next write eq .   in a matrix form .",
    "define @xmath69 , @xmath70 , @xmath71 and @xmath72 as @xmath73^\\top,\\nonumber\\\\ \\mb{z}_k&=[z_{k,1},\\cdots , z_{k , n}]^\\top,\\nonumber\\\\",
    "\\nabla\\mb{f}_k&=[\\nabla f_1(x_{k,1}),\\cdots,\\nabla f_n(x_{k , n})]^\\top,\\nonumber\\\\ y_k&=[\\mb{y}_{k,1},\\cdots,\\mb{y}_{k , n}]^\\top,\\nonumber\\\\ \\widetilde{y}_k&=\\mbox{diag}(y_k).\\nonumber\\end{aligned}\\ ] ] let @xmath74 be the collection of weights @xmath51 , which is clear row - stochastic .",
    "given that the graph is strongly - connected and the corresponding weighting matrix , @xmath28 , is non - negative , it follows that  @xmath75 is invertible for any  @xmath2 .",
    "based on notations above , we write eq .   in the matrix form",
    "equivalently as follows :    [ alg1_matrix ] @xmath76    where we have the initial condition @xmath77 and @xmath78 .    from either eqs . or , we emphasize that the implementation needs no knowledge of agent s out - degree for any agent in the network .",
    "this is because the algorithm only involves a row - stochastic matrix .",
    "compared to the column - stochastic matrix , used in related literatures @xcite , a row - stochastic only matrix is easier to implement in a distributed fashion as each agent can locally decide the weights that are to be assigned to the incoming information .",
    "in this section , we present the linear convergence result of eq .  .",
    "based on earlier notations , we further define @xmath79^\\top,\\nonumber\\\\ \\nabla\\widehat{\\mb{f}}_k&=\\frac{1}{n}\\mb{1}_n\\mb{1}_n^\\top[\\nabla f_1(\\widehat{x}_k), ... ,\\nabla f_n(\\widehat{x}_k)]^\\top,\\nonumber\\end{aligned}\\ ] ] where @xmath80 denotes the optimal solution assumed in assumption [ asp3 ] .",
    "we denote constants @xmath81 , @xmath82 , and @xmath83 as @xmath84 where @xmath28 is the row - stochastic weighting matrix used in eq . , @xmath85 is the step - size , and @xmath43 and @xmath45 are respectively the lipschitz gradient constant and strong - convexity constant in assumption [ asp1 ] .",
    "let @xmath86 and @xmath87 be the maximum of @xmath88 and @xmath89 over @xmath2 , respectively , @xmath90 moreover , we define two constants , @xmath91 , and , @xmath92 , through the following two lemmas , which are related to the convergence of @xmath28 and @xmath93 .",
    "note that lemmas [ lem2 ] and [ lem3 ] are reformulated with notations introduced above .",
    "[ lem2 ] ( nedic _ et al_.  @xcite ) consider @xmath94 , generated from the row - stochastic matrix , @xmath28 , and its limit @xmath93 .",
    "there exist @xmath95 and @xmath96 such that for all @xmath2 @xmath97    [ lem3 ] ( olshevsky _ et al_.  @xcite ) for any @xmath98 , define @xmath99 .",
    "there exists @xmath100 such that for all @xmath2 @xmath101    based on the above notations , we finally denote @xmath102 , @xmath103 , and @xmath104 , @xmath105 for all @xmath2 as @xmath106 , \\mb{s}_k=\\left [ \\begin{array}{cc } \\left\\|\\nabla\\mb{f}_k\\right\\| \\\\ 0\\\\ 0 \\end{array } \\right ] , \\notag\\\\ g&=\\left [ \\begin{array}{ccc } \\sigma & 0 & \\alpha \\\\ \\alpha nl & \\eta & 0\\\\ \\epsilon",
    "l\\tau \\widetilde{y}+\\alpha(\\epsilon l^2\\widetilde{y}n ) & \\alpha(\\epsilon l^2\\widetilde{y}n ) & \\sigma+\\alpha(\\epsilon l\\widetilde{y } ) \\end{array } \\right ] , \\notag\\\\ h_k&=\\left [ \\begin{array}{ccc } 0 & 0 & 0\\\\ ( \\alpha y\\widetilde{y}^2t)\\gamma_1^k & 0 & 0\\\\ ( \\alpha\\epsilon\\widetilde{y}l y+2\\epsilon)\\widetilde{y}^2t\\gamma_1^k & 0 & 0 \\end{array } \\right].\\end{aligned}\\ ] ] according to the definition of @xmath107 in eq . , it is sufficient to show the linear convergence of @xmath107 to zero if we want to prove that @xmath69 converges to @xmath108 linearly .",
    "the following theorem builds an inequality for comparison for @xmath102 , which is an important result going forward .",
    "[ thm1 ] let assumptions [ asp2 ] , [ asp3 ] , and [ asp1 ] hold .",
    "we have the following inequality hold for all @xmath2 , @xmath109    see section iv .    note that eq .",
    "provides a linear inequality between @xmath102 and @xmath110 with matrices , @xmath104 and @xmath111 .",
    "thus , the convergence of @xmath102 is fully determined by @xmath104 and @xmath111 . more specifically , if we want to prove a linear convergence rate of @xmath107 going to zero , it is sufficient to show that @xmath112 , where @xmath113 denotes the spectral radius , as well as the linear decaying of @xmath111 , which is straightforward since @xmath95 . in lemma",
    "[ lem_g ] , we first show that with an appropriate step - size , the spectral radius of @xmath104 is less than @xmath19 .",
    "following lemma [ lem_g ] , we show the linear convergence rate of @xmath114 and @xmath111 in lemma [ lem_gh ] .",
    "we finally present the main result in theorem [ main_result ] , which is based on these lemmas as well as theorem [ thm1 ] .",
    "[ lem_g ] consider @xmath115 defined in eq .   as a function of the step - size ,",
    "it follows that @xmath116 if the step - size , @xmath117 , where @xmath118 and @xmath119 .    since @xmath120",
    ", we have @xmath121 . when @xmath122 , we obtain that @xmath123 ,      \\end{aligned}\\ ] ] the eigenvalues of which are @xmath92 , @xmath92 , and @xmath19 .",
    "note that @xmath100 . therefore , @xmath124 , where @xmath113 denotes the spectral radius .",
    "we now consider how the spectral radius , @xmath125 , is changed if we slightly increase @xmath85 from 0 .",
    "we denote @xmath126 the characteristic polynomial of @xmath115 . by letting @xmath127",
    ", we get the following equation .",
    ".   shows an implicit relation between @xmath129 and @xmath85 .",
    "since we have already shown that @xmath19 is one of the eigenvalues of @xmath130 , eq .",
    "is valid when @xmath131 and @xmath122 .",
    "take the derivative on both sides of eq .",
    ", and let @xmath131 and @xmath122 , we obtain that @xmath132 .",
    "this is saying that when @xmath85 increases slightly from @xmath20 , @xmath133 will decrease .",
    "note that @xmath134 , we obtain that @xmath116 when @xmath85 is slightly increased from @xmath20 , i.e. , there exists some @xmath135 such that @xmath136 and @xmath116 , @xmath137 .",
    "we now calculate the value of @xmath135 .",
    "since @xmath115 is non - negative , by perron - frobenius theorem @xcite , @xmath19 is a eigenvalue of @xmath138 .",
    "let @xmath131 in eq .",
    ", then solving for the step - size , @xmath85 , we obtain that , @xmath139 , @xmath140 , and @xmath141 where @xmath119 . since there is no other value of @xmath85 that leads to @xmath142 , we know that all eigenvalues of @xmath115 are less than @xmath19 for @xmath117 by considering the fact that eigenvalues are continuous functions of a matrix",
    ". therefore , @xmath116 , when @xmath117 .",
    "[ lem_gh ] with the step - size , @xmath117 , where @xmath135 is defined in eq .  , the following statements hold for all @xmath2 ,    1 .",
    "there exist @xmath95 and @xmath143 , where @xmath91 is defined in eq .  ,",
    "such that @xmath144 2 .",
    "there exist @xmath145 and @xmath146 , such that @xmath147 3 .",
    "let @xmath148 and @xmath149 .",
    "then for all @xmath150 , @xmath151    \\(a ) this is easy to verify according to eq .  , and by letting @xmath152 .",
    "\\(b ) we represent  @xmath114 in the jordan canonical form as @xmath153 . according to lemma [ lem_g ]",
    ", we have that all diagonal entries in  @xmath154 are smaller than one . therefore , there exist @xmath146 and @xmath145 , such that @xmath155 ( c ) the proof of ( c ) is achieved by combining ( a ) and ( b ) .",
    "[ lem_polyak ] ( polyak @xcite ) if nonnegative sequences @xmath156 , @xmath157 , @xmath158 and @xmath159 are such that @xmath160 , @xmath161 and @xmath162 , then @xmath156 converges and @xmath163 .    in theorem 1 , we provide the linear iterative relation on @xmath164 with matrix @xmath104 and @xmath111 . moreover ,",
    "we show that @xmath112 and the linear decaying of @xmath111 in lemmas [ lem_g ] and [ lem_gh ] . by combining these relations and lemma [ lem_polyak ] ,",
    "we are ready to prove the linear convergence of our algorithm .",
    "[ main_result ] let assumptions [ asp2 ] , [ asp3 ] , and [ asp1 ] hold . with the step - size , @xmath117 , where @xmath135 is defined in eq .",
    ", the sequence , @xmath165 , generated by eq .  , converges linearly to the optimal solution , @xmath108 , i.e. , there exist some bounded constants @xmath166 and @xmath167 , where @xmath168 is used in lemma [ lem_gh](c ) , such that for any @xmath2 , @xmath169    we write eq .",
    "recursively , which results @xmath170 by taking the norm on both sides of eq .  , and considering lemma [ lem_gh ] , we obtain that @xmath171 in which we can bound @xmath172 as @xmath173 therefore , we have that for all @xmath2 @xmath174 denote @xmath175 , @xmath176 , and @xmath177 , eq . results that @xmath178 which implies that @xmath179 . applying lemma [ lem_polyak ] with @xmath180 and @xmath181 ( here @xmath182 )",
    ", we have @xmath183 converges .",
    "thus @xmath184 .",
    "moreover , since @xmath156 is bounded , eq .   implies that @xmath184 with rate @xmath185 ( note @xmath186 is only linear in @xmath2 ) , i.e. , there exist @xmath187 and @xmath185 such that for all @xmath2 , we have @xmath188 it follows that @xmath189 and @xmath190 satisfy the relation that @xmath191 by combining eqs .   and , we obtain that @xmath192 the desired result is obtained by letting @xmath193 .",
    "theorem [ main_result ] shows the linear convergence of the algorithm , the result of which is based on the iterative relation in theorem [ thm1 ] . in next section , we present the proof of theorem [ thm1 ] .",
    "we first provide several auxiliary relations .",
    "lemma [ w - x- ] derives iterative equations that govern the sequences @xmath194 and @xmath195 .",
    "lemma [ gd_approach ] is a standard result in the optimization literature ,  @xcite .",
    "it states that if we perform a gradient descent step with a fixed step - size for a strongly - convex and smooth function , then the distance to optimizer shrinks by at least a fixed ratio .",
    "lemma [ yy- ] gives inequalities that are direct consequences of eq .  .",
    "[ w - x- ] the following equations hold for all @xmath2 ,    1 .   @xmath196 ; 2 .",
    "@xmath197 .    by noting that @xmath198",
    ", we obtain from eq .",
    "@xmath199 do this recursively , and we have that @xmath200 recall the initial condition @xmath201 , since @xmath77 .",
    "thus , @xmath202 . then we obtain the result of ( a ) .",
    "the proof of ( b ) follows directly from eq .  ; in particular , @xmath203 which completes the proof .    [ gd_approach ]",
    "( bubeck @xcite ) let assumption [ asp1 ] hold for the objective function ,  @xmath204 , in p1 , and @xmath45 and @xmath43 are the strong - convexity constant and lipschitz continuous gradient constant , respectively . for any @xmath12 , define @xmath205 , where @xmath206 .",
    "then @xmath207 where @xmath208 .",
    "[ yy- ] the following inequalities hold for all @xmath209 ,    1 .",
    "@xmath210 ; 2 .",
    "@xmath211 .",
    "the proof of ( a ) follows @xmath212 where the second inequality holds because @xmath213 and we apply lemma [ lem2 ] .",
    "the result in ( b ) is straightforward by applying ( a ) .",
    "this finishes the proof .",
    "we now provide the proof of theorem [ thm1 ] .",
    "we will bound @xmath214 , @xmath215 , and @xmath216 by the linear combinations of their past values , i.e. , @xmath217 , @xmath218 , and @xmath219 , as well as @xmath220 . the coefficients will be shown to be the entries of @xmath104 and @xmath221 .",
    "* step 1 : * bounding @xmath214 .",
    "+ according to eq .   and lemma [ w - x-](b )",
    ", we obtain that @xmath222 by noting that @xmath223 from lemma [ lem3 ] , we have @xmath224    * step 2 : * bounding @xmath215 .",
    "+ by considering lemma [ w - x-](b ) , we obtain that @xmath225 let @xmath226 , which is performing a ( centralized ) gradient descent with step - size @xmath85 to minimize the objective function in problem p1 .",
    "therefore , we have that , according to lemma [ gd_approach ] , @xmath227 we next bound the second term in the rhs of eq .   by splitting it such that @xmath228 the first term on the rhs of eq .",
    "is bounded by @xmath229 where in the first equality we apply the result of lemma [ w - x-](a ) that @xmath196 , and in the second inequality we use the result of lemma [ yy-](a ) . the second term on the rhs of eq .",
    "is bounded by @xmath230 where in the first inequality we use the relation that @xmath231 . by combining eqs .  , , and",
    ", it follows that @xmath232 therefore , we can bound @xmath215 as @xmath233 * step 3 : * bounding @xmath216 . + according to eq .",
    ", we have @xmath234 with the result of lemma [ lem3 ] , we obtain that @xmath235 note that @xmath196 from lemma [ w - x-](a )",
    ". therefore , @xmath236 by combining eqs .   and",
    ", it follows that @xmath237 we now bound @xmath238 in eq .  .",
    "note that @xmath239 for all @xmath2 , which results into @xmath240 where @xmath241 can be bounded with the following derivation : @xmath242 where we use the fact that @xmath243 and we bound @xmath244 using the result in eq . . by combining eqs .",
    ", , and , we finally get that @xmath245    * step 4 : * by combining eqs .   in step 1 , in step 2 , and in step 3 , we complete the proof .",
    "in this section , we verify the performance of the proposed algorithm .",
    "we compare the convergence rates between our algorithm and other existing methods , including add - opt @xcite , dextra @xcite , subgradient - push @xcite , directed - distributed subgradient descent @xcite , and the weighting balancing - distributed subgradient descent @xcite .",
    "our numerical experiments are based on the distributed logistic regression problem over a directed graph : @xmath246,\\nonumber\\end{aligned}\\ ] ] where for any agent @xmath5 , it is accessible to @xmath247 training examples , @xmath248 , where @xmath249 includes the @xmath68 features of the @xmath11th training example of agent @xmath5 , and @xmath250 is the corresponding label . the directed graph is shown in fig .",
    "[ fig1 ] this problem can be formulated in the form of p1 with the private objective function @xmath41 being @xmath251.\\nonumber\\end{aligned}\\ ] ]        in our setting , we have @xmath252 , @xmath253 , for all @xmath5 , and @xmath254 . fig .",
    "[ fig2 ] shows the convergence rates .",
    "we apply the same local degree weighting strategy to all methods .",
    "it can be found that our algorithm , as well as add - opt and dextra , has a fast linear convergence rate , while other methods are sub - linear .",
    "compared to add - opt and dextra , our algorithm requires no knowledge of agents out - degree , which is more practical in a directed circumstance .",
    "this paper considers the distributed optimization problem of minimizing the sum of local objective functions over a multi - agent network , where the communication between agents is described by a _ directed _ graph .",
    "existing distributed optimization algorithms considering directed graphs require at least the knowledge of neighbors out - degree for all agents ( due to the requirement of column - stochastic matrices ) .",
    "in contrast , our algorithm requires no such knowledge .",
    "moreover , the proposed distributed algorithm achieves the best rate of convergence for this class of problems , @xmath0 for @xmath1 , given that the objective functions are strongly - convex , where @xmath2 is the number of iterations ."
  ],
  "abstract_text": [
    "<S> this paper deals with a distributed optimization problem over a multi - agent network , in which the objective function is the sum of individual agent costs . </S>",
    "<S> we focus on the case when the communication between agents is described by a _ directed _ graph . </S>",
    "<S> existing distributed optimization algorithms for directed graphs require at least the knowledge of neighbors out - degree for all agents ( due to the requirement of column - stochastic matrices ) . </S>",
    "<S> in contrast , our algorithm requires no such knowledge . </S>",
    "<S> moreover , the proposed distributed algorithm achieves the best known rate of convergence for this class of problems , @xmath0 for @xmath1 , given that the objective functions are strongly - convex , where @xmath2 is the number of iterations . </S>",
    "<S> numerical experiments are provided to illustrate the theoretical findings .    </S>",
    "<S> optimization algorithms ; agents and autonomous systems ; cooperative control ; directed graphs </S>"
  ]
}