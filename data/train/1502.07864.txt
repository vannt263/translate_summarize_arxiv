{
  "article_text": [
    "scientific studies are often evaluated by correcting for multiple comparisons , for instance using the @xcite correction or the procedure of @xcite .",
    "although testing procedures such as the @xcite correction require exact knowledge of the p - value underlying each statistical test , the ideal p - values of the tests are usually not available analytically in practice and thus have to be approximated using monte - carlo methods , for instance via bootstrap or permutation tests . by the ideal p - value we refer to the one obtained by integrating over the theoretical bootstrap distribution ( in case of bootstrap tests ) or by generating all permutations ( in case of permutation tests ) .",
    "this scenario is common in scientific studies involving real data @xcite .",
    "if the overall number of samples one is able to spend on the approximation of all p - values is limited as is the case in practice ( for instance due to time constraints ) , increasing the approximation accuracy of certain p - value estimates comes at the cost of decreasing the accuracy of others .",
    "we are interested in deriving the optimal allocation of a finite number of samples to a finite number of hypotheses tested using the @xcite correction . by optimal",
    "we refer to the allocation which minimizes the total expected number of misclassified hypotheses , that is the expected number of hypotheses whose classification ( rejected , non - rejected ) differs from the one obtained with the ideal p - values .",
    "recent examples for studies evaluated by applying the @xcite correction to approximated p - values include @xcite , @xcite and @xcite .    several methods to compute significant and non - significant hypotheses via approximated p - values are available in the literature .",
    "for instance the method of @xcite , the approaches by @xcite , @xcite , @xcite , the ` mcfdr ` algorithm of @xcite or the ` mmctest ` algorithm of @xcite . however , it is unclear how the allocation of samples computed by the algorithms aforementioned compares to the optimal allocation .",
    "this article is organized as follows . in section [ section_optallocation ]",
    "we will first state a mathematical formulation of the problem under investigation ( section [ subsection_formulation_problem ] ) .",
    "we then derive the optimal allocation minimizing the overall expected number of misclassifications of hypotheses under the assumption that the number of samples to be allocated is continous ( section [ subsection_kuhntucker_derivation ] ) .",
    "this is achieved by solving a suitable optimization problem using the @xcite formalism ( section [ subsection_solving ] ) . as in practice",
    "any allocation is discrete , the related discrete optimization problem is heuristcally solved to indicate that both the continous and discrete optimal solutions do not differ by much ( appendix [ section_greedy ] ) .    in section [ section_thompson_optimality ]",
    "we demonstrate empirically that a simple sampling algorithm based on thompson sampling @xcite introduced in @xcite asympotically mimics the optimal allocation of samples .",
    "the article concludes with a discussion in section [ section_discussion ] .",
    "the following section introduces the problem under investigation in this article and presents a mathematical formulation as an optimization problem . the optimal allocation minimizing the expected number of misclassifications",
    "is derived with the help of a @xcite condition .",
    "suppose we are interested in testing @xmath0 hypotheses @xmath1 for statistical significance using the @xcite correction at a fixed threshold @xmath2 .",
    "the ideal but unknown p - value underlying each hypothesis @xmath3 is denoted by @xmath4 , @xmath5 .",
    "the @xcite correction returning the indices of rejected hypotheses is defined as @xmath6 , where @xmath7 is a vector of @xmath0 p - values .",
    "the threshold @xmath8 typically is a fixed significance level @xmath9 divided by the number of hypotheses @xmath0 to correct for multiple tests , that is @xmath10 .",
    "as the ideal p - values are unknown , we assume that monte - carlo methods are used to approximate them via @xmath11 , where @xmath12 is the total number of random samples drawn for @xmath3 and @xmath13 of these were significant .",
    "the significant samples can be modeled as @xmath14 .",
    "we assume that in practical applications where the ideal p - values are unknown , @xmath3 is rejected if @xmath15 , that is if its p - value estimate @xmath16 is below the constant threshold @xmath8 .",
    "all remaining hypotheses are non - rejected .",
    "this strategy is employed in all the real data studies mentioned in section [ section_introduction ] .",
    "we are interested in finding the allocation of samples @xmath17 to the hypotheses@xmath1 which minimizes the expected number of misclassifications , subject to the constraint that @xmath18 for a total number of samples @xmath19 specified in advance by the user .",
    "let @xmath20 be the event that hypothesis @xmath3 is misclassified .",
    "for the @xcite correction under consideration , this event occurs if the p - value estimate @xmath11 and the ideal @xmath4 for @xmath3 are on the two different sides of the threshold @xmath8 . using the event @xmath21",
    ", the total number of misclassifications can be expressed as @xmath22 , where @xmath23 is the indicator function . when allocating @xmath12 samples to hypothesis @xmath3 to estimate its p - value , the expected total number of false classifications is thus @xmath24,\\end{aligned}\\ ] ] where @xmath25 and @xmath14 .",
    "the function @xmath26 goes to zero as @xmath27 .",
    "this is to be expected as by the central limit theorem , the estimates converge to the ideal p - values as more samples are drawn , hence the probability for a wrong classification decreases .",
    "we determine the vector @xmath28 minimizing @xmath26 under the condition that @xmath18 which is imposed via a kuhn - tucker constraint @xcite . as derivatives are needed for the kuhn - tucker formalism , the binomial distribution in @xmath26 was replaced by its normal approximation : @xmath29 = : h(k),\\end{aligned}\\ ] ] where @xmath30 is the cumulative distribution function of the standard normal distribution .",
    "the derivative of @xmath31 is given by @xmath32 where @xmath33 is the density function of the standard normal distribution .",
    "the partial derivative @xmath34 depends on @xmath12 only .",
    "the function @xmath31 needs to be optimised under the constraints @xmath35 and @xmath36 , meaning that each hypothesis receives at least one sample and that the total number of samples allocated equals @xmath37 .",
    "the optimal solution @xmath38 minimizing @xmath31 satisfies @xmath39 where @xmath40 and @xmath41 @xcite .",
    "the functions @xmath42 encode the constraints @xmath43 ( primal feasibility ) with @xmath44 ( dual feasibility ) and satisfy @xmath45 ( complementary slackness ) , where @xmath5",
    ".    complementary slackness and the condition @xmath43 imply that @xmath46 for all @xmath47 .",
    "as each partial derivative @xmath48 only depends on @xmath12 , the kuhn - tucker condition simplifies to @xmath49 for @xmath5 and a @xmath50 .",
    "this section looks at useful computational considerations for solving ( [ eq_kuhn_tucker ] ) . the optimal allocation for a normal approximation",
    "is obtained by tuning the parameter @xmath51 towards an optimal value @xmath52 with the property that the corresponding optimal vector @xmath53 solving ( [ eq_kuhn_tucker ] ) satisfies @xmath54 .",
    "the optimal @xmath52 can be found using a binary search as follows .",
    "similarly to @xmath26 , the function @xmath31 is positive and monotonically decreases to zero as @xmath27 .",
    "the derivatives @xmath48 are therefore negative for @xmath43 and monotonically increase to zero as @xmath55 . as a consequence , when solving @xmath56 for @xmath12 , smaller values of @xmath51 correspond to larger values of @xmath12 and vice versa .",
    "this observation applies to all @xmath12 , @xmath5 .",
    "thus , @xmath57 for the solution @xmath28 of ( [ eq_kuhn_tucker ] ) also monotonically decreases as @xmath58 .",
    "the optimal value can therefore be found easily with a binary search .",
    "likewise , as @xmath31 is monotonic , the solution @xmath12 of @xmath56 can be found using a binary search in @xmath12 for each proposed value of @xmath51 .",
    "in this section , a runtime study is conducted to empirically demonstrate that the allocation of samples to multiple hypotheses computed by the ` quickmmctest ` algorithm of @xcite asympotically behaves like the optimal allocation .    `",
    "quickmmctest ` is used to iteratively allocate samples to all @xmath0 hypotheses .",
    "the algorithm is designed in such a way as to allocate more samples adaptively to those p - values which are closer to the testing threshold and thus harder to classify .",
    "although ` quickmmctest ` is capable , in principle , to compute allocations for tests evaluated with arbitrary step - up and step - down procedures , we use it in connection with the @xcite correction @xmath59 only ( section [ subsection_formulation_problem ] ) . moreover ,",
    "` quickmmctest ` depends on two parameters : the total number of samples @xmath37 to be spent and the total number of iterations @xmath60 .",
    "the choice of @xmath37 and @xmath60 is given individually in each of the following subsections .          in the present section , the allocation of samples computed by ` quickmmctest ` will be compared to the continous optimal allocation derived in section [ section_optallocation ] .",
    "although we use the continous optimal allocation as a reference for the comparison , we show in appendix [ section_greedy ] that solving the discrete optimisation problem using a greedy approach indicates that the discrete and continous optimal solutions are most likely similar .    for all comparisons in this section , we use a mixture distribution introduced in @xcite .",
    "it consists of a proportion @xmath61 of the @xmath0 hypotheses drawn from a uniform@xmath62 $ ] distribution and the remaining proportion @xmath63 drawn from a beta@xmath64 distribution .",
    "we fix a realisation generated from this mixture distribution with @xmath65 p - values and parameter @xmath66 .",
    "the p - values were then sorted in order to be able to plot the continous optimal allocation as a continous curve and hence increase clarity in plots .",
    "we refer to the fixed p - values as @xmath4 , @xmath5 .",
    "we compute the optimal continous allocation for our fixed distribution as described in section [ subsection_solving ] . additionally , we apply ` quickmmctest ` to the fixed p - values and record its allocation of samples to each hypothesis .",
    "testing was carried out at a @xcite threshold of @xmath67 .",
    "figure [ plot_opt_vs_thompson ] shows the continous optimal solution ( solid curve ) as well as the number of samples allocated to each hypothesis by ` quickmmctest ` ( crosses ) .",
    "the total number of samples was @xmath68 .",
    "the cutoff for multiple testing occurred at the @xmath69th p - value .",
    "as visible in the plot , p - values far away from the cutoff point and thus far away from the threshold are not allocated any samples . on approaching the cutoff , more samples are needed to accurately classify p - values closer to the threshold as lying in the rejection or non - rejection area .",
    "however , p - values which are too close to the threshold on either side are not worth being spent too much effort on as deciding them is out of scope for a limited effort ( as shown in @xcite , deciding if a single p - value is above or below a constant threshold takes an expected infinite number of samples under suitable assumptions on the distribution of p - values ) .",
    "therefore , the continous optimal allocation decreases again on either side of the intersection point , yielding a bimodal allocation .",
    "the allocation computed by ` quickmmctest ` roughly resembles the shape of the optimal allocation . `",
    "quickmmctest ` allocates no sample or just one sample to hypotheses with p - values which are considerably above the threshold . moreover , ` quickmmctest ` allocates samples to hypotheses with p - values above the threshold in such a way that its allocation roughly approximates the second mode of the continous allocation .",
    "however , the first mode of the continous allocation is poorly approximated as ` quickmmctest ` seems to give an equal number of samples ( according to figure [ plot_opt_vs_thompson ] : about @xmath70 samples ) to each hypothesis below the cutoff .",
    ".average empirically observed misclassifications and theoretical misclassifications for the optimal allocation and the one returned by ` quickmmctest ` .",
    "[ cols=\"<,<,<,<\",options=\"header \" , ]     the allocation returned by ` quickmmctest ` and the continous optimal allocation are evaluated in two more ways .",
    "first , both allocations can be substituted into the function @xmath31 to obtain a theoretical number of misclassifications expected for each allocation .",
    "moreover , one can draw a constant number of samples for each hypothesis based on the allocation vector returned by both the optimal allocation and ` quickmmctest ` .",
    "based on @xmath13 exceedances observed among @xmath12 samples drawn for each hypothesis @xmath3 , @xmath5 , we estimate its p - value as @xmath71 and classify each hypothesis based on the estimate .",
    "comparing the estimated classification to the one obtained with the known p - values allows to compute empirical numbers of misclassified hypotheses .",
    "this experiment is carried out a total of @xmath72 repetitions for both the continous optimal allocation and the one returned by ` quickmmctest ` .",
    "table [ table_comparison_misclassifications ] shows averages for @xmath73 repetitions .",
    "first , the theoretical number of misclassifications ( obtained by evaluating the function @xmath31 on each allocation ) is considerably lower for the optimal allocation than for ` quickmmctest ` .",
    "this is natural as ` quickmmctest ` was never designed to minimize the function @xmath31 whereas the optimal allocation is the minimum of @xmath31 by definition .",
    "more illustrative is therefore the number of empirical misclassifications : as shown in table [ table_comparison_misclassifications ] , ` quickmmctest ` performs considerably better in terms of empirical misclassifications and almost reaches the limit set by the optimal allocation .      , @xmath74 and @xmath75 quantiles of the number of correctly classified hypotheses for `",
    "quickmmctest ` divided by the theoretical number of correctly classified hypotheses.,scaledwidth=50.0% ]    finally , we investigate if the behavior of ` quickmmctest ` mimics the optimal allocation as the total number @xmath37 of samples to be spent increases .",
    "this is done using the fixed set of @xmath76 p - values for a varying total number of samples @xmath37 which was increased from @xmath77 to @xmath78 in @xmath79 steps .",
    "we calculate @xmath80 , @xmath74 and @xmath75 quantiles of the empirical number of correctly classified hypotheses for ` quickmmctest ` ( based on @xmath73 repetitions ) divided by the theoretical number of correctly classified hypotheses ( obtained by evaluating @xmath31 on the optimal allocation derived in section [ subsection_kuhntucker_derivation ] ) .",
    "figure [ plot_convergence ] shows that the ratio of correct classifications of ` quickmmctest ` to the ones of the optimal allocation seems to converge to one as @xmath81 .",
    "this gives additional confirmation to the observation made for figure [ plot_opt_vs_thompson ] which suggested that the allocation of samples of ` quickmmctest ` seems to resemble the continous optimal one .",
    "more precisely , the allocation returned by ` quickmmctest ` seems to behave in such a way as mimic the optimal one in terms of correctly classified hypotheses .",
    "many algorithms published in the literature are designed to evaluate multiple hypotheses using monte - carlo simulations to compensate for unknown p - values corresponding to the hypotheses under consideration .",
    "though sensible , however , it is unclear if these algorithms distribute the number of samples they draw in an optimal way in the sense that the allocation of samples minimizes the number of misclassified hypotheses .",
    "the present article is concerned with the allocation of samples that minimizes the expected number of misclassified hypotheses .",
    "we derive the optimal allocation of a finite number of samples using a kuhn - tucker condition under the assumption that the p - values are known and that the number of samples is continous .",
    "we empirically establish that a simple sampling algorithm based on thompson sampling performs asympotically optimally in the sense that its allocation of samples to each hypothesis behaves like the optimal allocation .",
    "in contrast to the optimal allocation derived using known p - values , our algorithm does not need to have knowledge of any p - value as long as it is possible to obtain samples under each null hypothesis .",
    "moreover , we show that the algorithm presented in the article mimics the optimal allocation for a finite number of samples . `",
    "quickmmctest ` therefore seems to be a suitable choice if near optimal performance is desired .",
    "agrawal , s. and goyal , n. ( 2012 ) . .",
    ", 23(39):126 .",
    "benjamini , y. and hochberg , y. ( 1995 ) . controlling the false discovery rate : a practical and powerful approach to multiple testing . , 57(1):289300 .",
    "besag , j. and clifford , p. ( 1991 ) .",
    "sequential monte carlo p - values . , 78(2):301304 .",
    "boca , s. , sinha , r. , cross , a. , moore , s. , and sampson , j. ( 2014 ) . .",
    ", 30(2):214220 .",
    "bonferroni , c. ( 1936 ) .",
    "teoria statistica delle classi e calcolo delle probabilit .",
    ", 8:362 .",
    "brinza , d. , schultz , m. , tesler , g. , and bafna , v. ( 2010 ) . . ,",
    "26(22):28562862 .",
    "chen , x. and ishwaran , h. ( 2012 ) . .",
    ", 29(1):99105 .",
    "gandy , a. and hahn , g. ( 2014 ) .",
    "est  a safe algorithm for implementing multiple monte carlo tests .",
    ", 41(4):10831101 .",
    "gandy , a. and hahn , g. ( 2015 ) . est ",
    "higher accuracy for multiple testing corrections . .",
    "guo , w. and peddada , s. ( 2008 ) . adaptive choice of the number of bootstrap samples in large scale multiple testing .",
    ", 7(1):116 .",
    "kim , s .- b .",
    ", yang , s. , kim , s .- k . ,",
    "kim , s. , woo , h. , volsky , d. , kim , s .- y . , and chu , i .- s . ( 2007 ) . .",
    ", 23(13):16971699 .",
    "kuhn , h. and tucker , a. ( 1951 ) . .",
    ", pages 481492 .",
    "lin , d. ( 2005 ) .",
    "an efficient monte carlo approach to assessing statistical significance in genomic studies .",
    ", 21(6):781787 .",
    "liu , j. , huang , j. , ma , s. , and wang , k. ( 2013 ) . .",
    ", 14(2):205219 .",
    "marschall , t. , costa , i. , canzar , s. , bauer , m. , klau , g. , schliep , a. , and schnhuth , a. ( 2012 ) . . ,",
    "28(22):28752882 .",
    "sandve , g. , ferkingstad , e. , and nygard , s. ( 2011 ) .",
    "sequential monte carlo multiple testing .",
    ", 27(23):32353241 .",
    "thompson , w. ( 1933 ) . .",
    ", 25(3/4):285294 .",
    "thulin , m. ( 2014 ) . .",
    ", 74:2638 .",
    "van wieringen , w. , van  de wiel , m. , and van  der vaart , a. ( 2008 ) . a test for partial differential expression .",
    ", 103(483):10391049 .",
    "wald , a. ( 1945 ) .",
    "sequential tests of statistical hypotheses . , 16(2):117186 .",
    "zhang , y. ( 2008 ) . .",
    ", 24(24):28252831 .",
    "we investigate one of many possible greedy algorithms which tries to compute a discrete optimal allocation for a given set of p - values .",
    "the aim of this section is to argue that , although unknown , the discrete optimal allocation is most likely of a similar form as the continous optimal solution which was derived via a @xcite condition in section [ section_optallocation ] .    for notational convenience ,",
    "we express the function @xmath26 introduced in section [ section_optallocation ] as @xmath82 for @xmath25 , where @xmath83 where @xmath84 and @xmath14 ( see section [ section_optallocation ] ) .",
    "we consider the following greedy approach to computing a discrete optimal allocation for a given vector of p - values @xmath7 .    apart from the p - values",
    ", the greedy algorithm also requires the testing threshold @xmath8 and the total number @xmath37 of samples to be allocated to the @xmath0 hypotheses under consideration . in what follows",
    ", @xmath23 denotes the indicator function .            in order to highlight the reasoning behind algorithm [ algorithm_greedy ] ,",
    "consider the behavior of the function @xmath89 for a p - value @xmath4 below and above the threshold @xmath8 as illustrated exemplarily in figure [ plot_effort_threshold ] .",
    "we used @xmath65 p - values and threshold @xmath90 .",
    "figure [ plot_effort_threshold ] displays the expected number of misclassifications , obtained by evaluating the function @xmath31 , against number of samples for a hypothesis below ( left ) and above ( right ) the threshold , where we defined that drawing @xmath91 samples yields a p - value of @xmath91 and hence a correct rejection if the hypothesis corresponding to that p - value is rejected .",
    "as shown in figure [ algorithm_greedy ] , the behavior of @xmath89 exhibits a particular structure .",
    "a rejection is obtained if a p - value estimate is below the threshold at @xmath92 .",
    "thus for a p - value below @xmath8 ( left plot ) , when using less than @xmath93 samples , only in the case when @xmath91 exceedances are observed , a p - value will be classified as rejected .",
    "drawing more samples hence only potentially increases the probability of making a false decision .",
    "when reaching @xmath94 samples , both @xmath91 or @xmath95 exceedances will lead to a rejection and hence to a correct classification .",
    "the expected number of misclassifications drops .    for a p - value above @xmath8 ( right plot )",
    ", the inverse effect happens .",
    "drawing no samples leads to a rejection ( a p - value of @xmath91 ) and thus to a sure misclassification .",
    "drawing more samples decreases the expected misclassifications as observing @xmath91 exceedances out of @xmath12 samples ( the only case in which the hypothesis will be rejected and thus misclassified ) becomes more unlikely as @xmath12 approaches @xmath94 .",
    "when reaching @xmath94 samples , both @xmath91 and @xmath95 exceedances lead to a rejection and thus to a misclassification .",
    "the expected number of misclassifications increases again .",
    "algorithm [ algorithm_greedy ] works in the following way .",
    "we greedily try to fill up a zero vector @xmath28 storing the final allocation of samples in such a way as to decrease the function @xmath26 in every step , subject to the constraint @xmath36 . in each iteration",
    ", we determine a sensible number of @xmath96 samples to be allocated to hypothesis @xmath47 .",
    "this number varies for each hypothesis : for hypotheses above the threshold , @xmath96 is determined as the smallest increase that leads to a decrease in @xmath26 . for hypotheses below the threshold ,",
    "only a jump of @xmath97 is sensible if @xmath98 or a jump of @xmath99 in the case @xmath100 : that is , we jump to the first point of the rising branches in the left plot of figure [ plot_effort_threshold ] .",
    "certain jumps might lead to a big decrease in the value of the function @xmath26 , but only at the cost of also spending ( too ) many samples on just one hypothesis .",
    "we therefore determine the decrease @xmath101 for each @xmath47 and allocate the batch of @xmath96 samples only to the one hypothesis which has the best ratio @xmath102 .",
    "algorithm [ algorithm_greedy ] is just one of many possible greedy approaches to compute a sensible discrete allocation .",
    "we tried various variants and allocation rules , all having similar behavior as algorithm [ algorithm_greedy ] and resulting in similar allocations .",
    "figure [ plot_greedy_vs_opt ] compares two allocations , a greedy discrete one computed by algorithm [ algorithm_greedy ] and the continous optimal one computed via @xcite as described in section [ subsection_solving ] .",
    "we used a p - value distribution with @xmath65 hypotheses generated from the mixture distribution introduced in section [ subsection_simulation ] with parameter @xmath66 and carried out testing at a constant ( uncorrected , that is not divided by @xmath0 ) threshold of @xmath103 .",
    "figure [ plot_greedy_vs_opt ] shows that the two allocations are qualitatively similar , in particular for the allocation of samples to hypotheses having p - values above the threshold . for p - values below the threshold ,",
    "algorithm [ algorithm_greedy ] allocates more samples than the optimal allocation .",
    "this discrepancy increases as the p - values tend to zero .",
    "however , as seen in the plot , the optimal allocation distributes fractions of a sample to low p - values .",
    "these would , for instance , be rounded up to @xmath95 sample per hypothesis , thus making the greedy discrete and the optimal continous solutions coincide .",
    "strikingly , the greedy solution does not allocate more samples than the pre - set @xmath95 initial sample to rejected hypotheses close to the threshold , whereas the continous @xcite solution allocates samples roughly symmetrically around the threshold ."
  ],
  "abstract_text": [
    "<S> multiple testing is often carried out in practice using approximated p - values obtained , for instance , via bootstrap or permutation tests . </S>",
    "<S> we are interested in allocating a pre - specified total number of samples ( that is draws from a bootstrap distribution or permutations ) to all hypotheses in order to approximate their p - values in an optimal way , in the sense that the allocation minimizes the total expected number of misclassified hypotheses . by a misclassified hypothesis </S>",
    "<S> we refer to a decision on single hypotheses which differs from the one obtained if all p - values were known analytically . </S>",
    "<S> neither using a constant number of samples per p - value estimate nor more sophisticated approaches available in the literature guarantee the computation of an optimal allocation in the above sense . </S>",
    "<S> this article derives the optimal allocation of a finite total number of samples to a finite number of hypotheses tested using the bonferroni correction . </S>",
    "<S> simulation studies show that a simple sampling algorithm based on thompson sampling asympotically mimics this optimal allocation . </S>"
  ]
}