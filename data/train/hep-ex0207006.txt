{
  "article_text": [
    "my ambitions for this conference are to recover my luggage , which went missing four days ago , and to find answers to some questions about statistical practice at belle .",
    "i suspect i m not the only one with an agenda in this area . from the point of view of the belle spokesmen",
    ", it would be far better if i could articulate workable guidelines for our use of statistical methods  rather than finding fault with our present practice case - by - case . as i hope to show , it is much easier to criticise our statistical practice than it is to suggest alternatives , although i have made some tentative steps in that direction .",
    "analyses at belle are not all of the same kind , and the `` statistical environment '' varies from one study to another . after reviewing the experiment itself ( section  [ section - belle ] ) and some general issues ( section  [ section - practice ] ) , i hope to give you a feeling for the main types of analysis , and the statistical issues in each case ( section  [ section - analyses ] ) .",
    "of particular interest are the searches for rare @xmath2-meson decays ( section  [ subsec - analyses - rare ] ) , where there is a tradeoff between `` purist '' statistical concerns and important practical issues ; and our new analysis of @xmath1 decays ( section  [ section - pipi ] ) .",
    "interpretation of this result is surprisingly difficult , due to the unusual configuration of the parameter space , as well as some features of the analysis .",
    "the first belle paper on this topic is two weeks from journal submission , so you may have the chance to influence our statistical practice in real time !",
    "the main `` point '' of belle is to test the kobayashi - maskawa model of cp - violation  @xcite , in which the phenomenon is entirely due to the irreducible complex phase of the quark mixing matrix .",
    "the simplicity of this model makes it highly predictive . in the absence of extra generations or isosinglet quarks",
    ", we have the familiar @xmath3 matrix @xmath4 ( the so - called ckm matrix ) , and unitarity gives a number of relations of the form @xmath5 .",
    "this particular `` unitarity triangle '' ( see fig .  [ figure - unitarity ] ) is especially interesting : all its interior angles @xmath6 are believed to be far from @xmath7 and @xmath8 , and may be measured using time - dependent asymmetries between @xmath9  and @xmath10decays to appropriate states . in other words : cp - violating asymmetries in these decays are expected to be large .",
    "the recent measurement of @xmath11 by belle  @xcite confirms that this is true , at least regarding @xmath12 : based on a study of @xmath13 and related decays , we found @xmath14 .",
    "( this is the first observation of a cp - violating effect outside the neutral kaon system . in a spirit of friendliness",
    "let me also cite the similar , and essentially simultaneous , result from babar  @xcite . )",
    "the @xmath1 analysis discussed in section  [ section - pipi ] is sensitive to the angle @xmath15 .    decays . in all unitarity triangles ,",
    "the angles differ from @xmath7 and @xmath8 if the km phase is nonvanishing . in _ this _ triangle",
    ", the angles are expected to be far from @xmath7 and @xmath8 , leading to readily measurable effects . ]",
    "the belle detector  @xcite is a classic solenoidal tracking detector ( @xmath16 ) with some extra features .",
    "most notable is its asymmetry , to optimize acceptance of events with a centre - of - mass boosted by @xmath17 in the lab frame .",
    "( the storage rings of kekb collide @xmath18 on @xmath19 , _",
    "i.e. _  @xmath20 , yielding @xmath21 decays or nonresonant @xmath22 , @xmath23 _ etc . _ ) the drift of the @xmath24 prior to decay is measured using a silicon vertex detector , allowing measurement of time - dependent asymmetries ( see section  [ subsec - analyses - timing ] ) .",
    "particle i d over the full momentum range for @xmath2-daughters is obtained using aerogel erenkov counters as well as the more traditional @xmath25  and time - of - flight measurements : this improves @xmath2  flavour - tagging , and allows identification of rare @xmath2  decays where we hope to find evidence of `` direct '' cp violation ( section  [ subsec - analyses - rare ] ) .",
    "the flux return is instrumented with rpcs to identify @xmath26 ( as matched tracks ) , improving the efficiency and purity of @xmath27 reconstruction , and @xmath28  ( as neutral clusters ) , allowing measurement of @xmath29 using @xmath30 and related modes .",
    "the collaboration itself is of order 250 physicists , from over 50 institutes in 12 countries .",
    "perhaps half of the analysis effort is directed towards headline studies like @xmath31 and @xmath32 , with the rest thinly spread over rare @xmath2  decays , ckm matrix elements ( _ via _ measurements of semileptonic decays ) , charm studies , @xmath33 and @xmath34 physics .",
    "most of this work proceeds through some mix of local `` specialties '' and individual initiative , with fairly light coordination from the centre . which brings us to my next point .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ in those days there was no king in israel ; everyone did what was right in his own eyes . _ + judges 21:25 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    the key to understanding statistical practice at belle is that _ there is no official policy_. partly as a result of this , our practice is inconsistent .",
    "the following is my own take on this state of affairs .",
    "* this is not nearly as bad as it sounds : * * most of our procedures _ are _ motivated , either by principle or tradition . in some places traditional methods have perhaps been mistaken for rigorous formulae , but this is a higher - order problem : one of education , not discipline . * * we do describe our procedures in our papers , and this is more important than consistency .",
    "the description is sometimes incomplete , but i hope we are becoming more sensitive to this .",
    "* there _ are _ things which should , and may change .",
    "i will mention some of them below . * in avoiding anarchy",
    ", we do not want to become an authoritarian state .",
    "the last of these points is worth stressing .",
    "most of us spend our time going about our own business , and many of us have significant freedom to _ define _ what that business is . in part this is our way of working : 250 physicists may sound like a lot , but the number of potential physics topics is vast , and individuals `` fanning out '' opportunistically is a good way to cover them .",
    "but it is a _ modus vivendi _ as well .",
    "we live with each others egos , and satisfy our own , by spending most of our time on our own affairs .",
    "prescriptive policies have a way of cutting across this , and we tend to avoid them .",
    "of course we set standards for papers ( our _ ad hoc _ paper refereeing committees are almost the only committees worthy of the name ) and areas of analysis are run by conveners , who act as facilitators and clearinghouses for information ; occasionally , we also commission work .",
    "but to write a recipe - book for statistical practice , which all published analyses were expected to follow  this would be unprecedented .",
    "i do nt think people would be happy with it , and i doubt `` the authorities '' would exert themselves to enforce it  change , if it occurs , is more likely to proceed _ via _ the winning of hearts and minds .",
    "i suspect consciousness - raising in analysis groups , and among the individuals who sit on those refereeing committees , is the key .",
    "the analyses themselves , by which i mean analyses we have written up and published ( or have under review ) , can be divided into four broad categories :    1 .   the flagship time - distribution fit analyses ( usually concerning cpv ) ; 2 .   searches for rare hadronic @xmath35 decays ; 3 .   fits over a flattish background ; 4 .",
    "systematic - dominated analyses .",
    "this is a grouping according to statistical problems , rather than common work .",
    "the second category corresponds roughly to one of our analysis groups , which does lead to a certain uniformity of method .",
    "otherwise , these categories cut across belle s administrative divisions .",
    "i will consider them in turn , with the aid of an example in each case .",
    "the unitarity angle measurements mentioned above , based on @xmath36 _ etc .",
    "_  @xcite and @xmath32  @xcite , are performed by fitting decay - time distributions . to illustrate the method",
    "i have chosen a simpler analysis , which ( for our purpose ) has the same features : a measurement of the @xmath37 mixing parameter @xmath38 , through the lifetime difference of neutral @xmath39-mesons decaying to @xmath40 ( a cp eigenstate ) and @xmath41  @xcite .",
    "after selecting @xmath42 and @xmath41 decays ( imposing particle i d and decay angle cuts , and a momentum cut to veto @xmath2-daughters ) we fit the tracks to a common vertex , and extrapolate the resulting @xmath39-momentum @xmath43 to the interaction region : this gives us the flight length and thus the decay time .",
    "thanks to our good kaon / pion separation the @xmath39-decay samples are fairly clean , so we avoid @xmath44 tagging , keeping the samples as large as possible .",
    "of course some combinatorial @xmath45 is accepted , and we estimate the probability for each candidate @xmath46 to be a true @xmath39-decay using @xmath47 where @xmath48 is the mass of the candidate , and signal and background fractions @xmath49 and @xmath50 are taken from a fit to the mass distribution of all candidates .",
    "the distributions are uncomplicated , and double - gaussian fits over linear backgrounds are sufficient for the purpose .",
    "we accept events well into the tail  out to @xmath51 in the mass  for reasons that should become clear .",
    "we then perform an unbinned maximum likelihood fit to the events , using the function @xmath52 \\nonumber\\end{aligned}\\ ] ] which we also use to terrify small children .",
    "it is much less complicated than it looks .",
    "the first and second lines are the signal and background parts respectively : the underlying time - distribution of the signal is exponential , while that of the background is modelled by a fraction ( @xmath53 ) with lifetime ( _ e.g. _  charm daughters ) , following @xmath54 , and a fraction without , following @xmath55 ; @xmath56 is a double - gaussian resolution function .",
    "the nine parameters shown are floated in the fit , so the background properties are fitted along with the signal : this is the reason for including the region @xmath57 in the fit , providing a background - rich sample which largely determines the background parameters .",
    "( in fact there are eighteen fitted quantities , because there are two functions  ( [ def - dtime - lhd ] ) : one each for @xmath41 and @xmath40 decays .",
    "our fit maximises the grand likelihood @xmath58 , replacing the @xmath40 lifetime by @xmath59 .",
    "we find a null result , by the way : @xmath60    if you look closely at the resolution term , you ll notice that the proper - time error for each event is given by @xmath61 : an event - dependent quantity",
    ". due to variations in track and @xmath39-vertex quality , the estimated vertexing and therefore proper - time errors vary from event to event , by a factor of a few .",
    "( kinematic variations also play a role . )",
    "we scale these errors by global factors @xmath62 ( for the core gaussian ; close to 1 ) and @xmath63 ( for the tail gaussian ; @xmath64 ) , but the full function @xmath56 varies event - to - event , as does the signal fraction @xmath65 .",
    "any binned fit to the data would therefore need to have multidimensional bins_many_-dimensional , for a complicated analysis like @xmath29and to avoid this , we resort to unbinned fits .",
    "and so to the statistical issues raised by the timing - distribution fits :    1 .",
    "_ how do we estimate goodness - of - fit to our timing distributions ? _",
    "while standard measures exist for binned fits , there is no accepted goodness - of - fit test for unbinned maximum likelihood .",
    "some effort has recently gone into finding a method  if indeed it s possible  @xcite . in the meantime the lack of such a method",
    "is a nuisance , since we have nontrivial resolution functions which we fit from the data .",
    "how would we know if the functional form were wrong ; and would it matter ?",
    "1 .   in the case of @xmath38",
    ", we perform extensive systematic checks by varying cuts , signal - to - background ratios and the like ; and trace some biases to their origin by turning effects on and off in our detector monte carlo .",
    "this does nt so much assure us that the fit is good , as that any variations of the fit , or problems with it , have a controlled effect on @xmath38 .",
    "2 .   for @xmath29 , we test the ( _ very _ complicated ) resolution function by using it in the measurement of @xmath2-lifetime : a simpler , and much - higher - statistics task , than the asymmetry fit .",
    "we check for biasses by fitting null - asymmetry samples which are similar to our signal : @xmath66 , for example .",
    "and we compare our results to ensembles of fits to toy monte carlo datasets ",
    "although there may be less information in this last check than we once thought  @xcite .",
    "+ this is all good and necessary , and helps us ( and our journal referees ) to sleep at night .",
    "but if a decent goodness - of - fit test existed , we would obviously want to use that _ as well _ , and i for one would be glad if someone developed such a thing . or could convince me not to worry about it .",
    "_ how should we combine our errors ? _",
    "this is a problem we have largely postponed , as our unitarity angle analyses are still statistically limited . for @xmath38 ,",
    "statistical and systematic errors are of equal magnitude , and we estimate the total error @xmath67 using the familiar @xmath68 .",
    "familiar is , of course , not the same as `` correct '' .",
    "_ how should we estimate confidence intervals ? _ for @xmath38 , what we _ do _ is to treat the @xmath67 just defined as a gaussian - distributed error .",
    "( yes , i know that s an assumption . ) for the unitarity angle analyses , confidence intervals  are a can of worms .",
    "see section  [ section - pipi ]      rare decay analyses are simpler , at least on the surface .",
    "these studies are motivated by the search for `` direct '' cp violation , _",
    "i.e. _  cp asymmetry of decay amplitudes .",
    "decays which are cabibbo , ckm or colour - suppressed , or proceed via loop diagrams , are a good place to look for direct cpv : mechanisms with different ckm structure ( such as penguins and @xmath69 tree diagrams ) can compete , with similar magnitudes ; interference can lead to cp violation . for similar reasons , `` new physics '' ( non - standard model effects ) can be expected to contribute , since the competing standard model processes are suppressed .",
    "there are many ( possible ) rare decay modes , but the analyses tend to follow the pattern established in  @xcite . as an example , let s take the somewhat simpler publication on @xmath70 and @xmath71 decays  @xcite .",
    "paper  @xcite : @xmath73 and @xmath74 projections for @xmath75 , @xmath76 and @xmath77 events .",
    "the shaded histograms show @xmath78 events while the open histograms show @xmath78 and @xmath79 combined .",
    "the superimposed curves show the fits to @xmath73 and @xmath74 ( solid ) and the background component in the fit ( dashed ) .",
    "note the negligible @xmath76 yield .",
    ", width=453,height=226 ]    after making an event selection , continuum ( _ i.e. _  @xmath80 ) backgrounds are suppressed using a likelihood ratio formed from ( i ) a fisher discriminant of event shape variables , ( ii ) the production angle of the @xmath2-candidate , and ( iii ) for @xmath81 decays , a helicity variable .",
    "a cut on the likelihood ratio gets rid of 7090% of the background while keeping most of the signal .",
    "the signal is then isolated in @xmath73 and @xmath74 ( beam - constrained mass and energy - difference ) , which exploit the constrained kinematics of @xmath82 events : the results are shown in fig .",
    "[ figure - etapk - fig3 ] for @xmath83 and @xmath84 .",
    "signal events appear in gaussian peaks at @xmath85 and @xmath86 ; continuum backgrounds follow a phase - space - like function due to argus  @xcite in @xmath73 , and a linear form in @xmath74 .",
    "( background shape parameters are set from appropriate sideband data , and cross - checked in the monte carlo simulation . )",
    "note that @xmath87 is near the edge of our sensitivity , and that we see no @xmath88 peak .",
    "we assess the significance of a yield using @xmath89 , where @xmath90 is the maximum likelihood returned by the fit ( here , an unbinned fit to @xmath91 ) , and @xmath92 is the likelihood at zero yield . for the cases",
    "@xmath93 `` significant '' : : :    we quote a _ central value _ , but no confidence interval    ( _ e.g. _  @xmath94 ) ; @xmath95 `` not significant '' : : :    we quote an _ upper limit _ , but no central value    ( _ e.g. _  @xmath96 ) .    there are some full - reporting issues here , but let s set them aside",
    ". the _ upper limit _",
    "( usually at 90% c.l . )",
    "is calculated using the notorious method of _ `` integrating the likelihood function '' _ , followed by addition of one unit of systematic error ! ( the results are shown in table  [ table - etapk - tab2 ] . ) where we measure cp - asymmetries between ( say ) @xmath97  and @xmath98  decays , intervals are constructed in the same spirit : for @xmath99 , we set a 90% c.l .",
    "interval @xmath100 .    .",
    "from the @xmath101 paper  @xcite : branching fraction ( @xmath102 ) or 90% c.l .",
    "limit , and significance ( @xmath103 ) for belle , compared with cleo  @xcite and babar  @xcite results , and theoretical expectations  @xcite .",
    "the branching fractions are in units of @xmath104 . [ cols=\"<,^,>,^,^,^\",options=\"header \" , ]      like many of you , i have little good to say about this technique . a likelihood @xmath105 for parameter(s ) @xmath106 given measurement(s",
    ") @xmath107 is nothing other than the _ probability density _",
    "@xmath108 to obtain the observed data , if the underlying parameter really were @xmath106 .",
    "it is thus a density _ in x _ , and to `` integrate '' a density in the wrong variable is confused .",
    "( try this with a gaussian @xmath109 , integrating @xmath110 for fixed @xmath107as opposed to integrating it over @xmath107and you ll see what i mean . ) and do not get me started on the addition of one unit of systematic error  at least until section  [ section - questions ] .",
    "having got that out of the way , i now want to explain why this method is not as bad as it looks :    1 .",
    "_ it is easy and fast , and can be done with information already `` in hand '' . _",
    "all you need is the likelihood function .",
    "this is important , since the typical rare decay analysis needs to be published with some urgency : either because it is a first observation , or because some issue hangs on the measurement .",
    "( @xmath111 is of this kind : there is a theory / data discrepancy which might be a first hint of something exciting ; see table  [ table - etapk - tab2 ] .",
    ") there is a kind of built - in obsolescence in these measurements too , due to continuing improvements in our luminosity : physics letters published our paper  @xcite on 4th october 2001 : nine months after that date , we will have at least eight times its data on tape .",
    "2 .   _ for branching fraction measurements",
    ", it corresponds roughly to a bayesian interval . _",
    "if we have some prior degree of belief @xmath112 concerning a parameter ( here , @xmath113 , the true branching fraction ) , then after the measurement @xmath107 we may update this belief using bayes theorem @xmath114 where @xmath115 is the likelihood function , and @xmath116 may be recovered from the normalization .",
    "the posterior probability @xmath117our updated belief about @xmath106 , following the measurement @xmath107is a density in @xmath106 by construction , and therefore _ can _ be integrated on @xmath106 ; and `` integrating the likelihood function '' is equivalent to integrating  ( [ eq - bayes ] ) if the prior probability @xmath112 is constant .",
    "now a constant function is hard to defend as a serious prior , but there is a more subtle problem with this approach , to do with the special point @xmath118 .",
    "if our prior @xmath112 is truly constant , this means we are committed in advance to the belief that the branching fraction _ does not vanish _ , since @xmath119 is a set of measure zero : @xmath120 for any finite @xmath112 .",
    "if we were deriving a proper bayesian credible interval for @xmath106 we might well assign a _",
    "delta function _ to the origin , allowing a ( say ) 10% belief that the decay is forbidden ; the posterior for @xmath118 would then be nonzero . , the point @xmath118 might lie _ outside _ the 90% interval , although navely integrating @xmath121 would never tell you that : ( [ eq - bayesian-90 ] ) always yields an upper limit . that is , ( [ eq - bayesian-90 ] ) is not a unified method for interval construction . ]",
    "the upper limit calculated _ via _",
    "@xmath122          \\left/      \\left [      { \\int_0^\\infty   { \\ensuremath{\\mathrm{d}\\mu}}\\ ,",
    "p(x | \\mu ) \\cdot p(\\mu ) / p(x ) }      \\right ]      = 0.9      \\right .",
    "\\label{eq - bayesian-90}\\ ] ] would fall , but this is just a special case of the dependence of the limit on the prior .",
    "the special point @xmath123 is benign because it coincides with the physical boundary ( fig .",
    "[ figure - branching - flatprior ] ) and is always on the _ edge _ of an interval , if it belongs to it at all . in section  [ section - pipi ]",
    ", we will see an example where this is not the case .",
    "is unphysical ; @xmath124 is a special case . for a measurement @xmath125 , `` integration of the likelihood function '' ( _ cf . _",
    "( [ eq - bayesian-90 ] ) ) over the shaded region yields an upper limit as shown.,width=453 ]    upper limits derived in this way might differ by a factor of @xmath126 from those we would obtain by a more rigorous ( bayesian ) technique . where there is already a tradition of quoting such limits , so that everyone `` knows '' what they mean ( just as we know that `` 3 sigma '' and `` 5 sigma '' do not _ really _ mean 99.7% and 99.994% confidence ) , it would be hard to justify declaring war on the method . and",
    "the frequentist alternative is messy : it would require the construction of toy monte carlos for each and every decay mode and analysis ( all of them differ subtly ) , to determine coverage  and we would probably find limits ( again ) within a factor 2 , at the price of making lots of work ( in parallel ! ) for lots of students .",
    "these analyses are ( to my mind ) more straightforward : they involve fitting a lineshape over a smooth background , or at worst , interpreting the result of a background subtraction .",
    "our analysis of prompt charmonium production  @xcite is an example . selecting @xmath127 events with centre - of - mass momentum @xmath128 , above the kinematic limit for @xmath129 , we measure the yield in the main `` on - resonance '' data , and in the smaller `` off - resonance '' sample , where @xmath130 is just below @xmath131 threshold : too low to produce an @xmath132  meson . after scaling , correction and cross - checks",
    ", we subtract the yields to find the net number of @xmath133 decays to be @xmath134 : _",
    "i.e. _  consistent with vanishing @xmath135 .",
    "the error is dominated by the uncertainty on the off - resonance yield .",
    "we assume that this  and the full error  is distributed as a gaussian , and use  ( * ? ? ?",
    "* table x ) to determine the upper limit .",
    "this allows the negative yield to be treated in a rigorous way .",
    "some approximation is involved by assuming gaussian behaviour , and in principle we could model the subtraction in a toy monte carlo , and determine the limit using likelihood - ratio ordering from first principles . in my view",
    "the utility of spending 30 seconds looking up a table , and referring readers to an accessible paper , outweighs issues of principle here .    having set an upper limit for @xmath135 , we assume that the observed prompt @xmath127 are produced directly from @xmath136@xmath137   annihilation .",
    "we look for prompt production of other charmonia , and find a significant yield for @xmath138 , but not @xmath139 : see fig .",
    "[ figure - prompt - psiprime ] . for @xmath139",
    "we set upper limits on @xmath140 using the feldman - cousins tables for gaussians : the assumption of gaussian errors is clearly reasonable .",
    "the same technique is used when treating small yields on a background in  @xcite .",
    "( upper plot ) and @xmath141 ( lower plot ) for @xmath142 , above the limit for @xmath143 decays.,width=302 ]    the search for ( factorization - forbidden ) @xmath144 decays  @xcite is unusual for belle : a @xmath2-decay analysis where we fit a peak over a large , smooth background , so statistical questions are unproblematic .",
    "( because of the inclusive nature of the decay , we can not use the @xmath145 variables to wipe away the background . )",
    "there is however an interesting question concerning systematic errors . because of the complicated ( and overlapping ) lineshapes used to fit @xmath141 , and the relatively large @xmath146 yield , the systematic error on the @xmath147 yield is substantial : @xmath148 .",
    "the systematic error @xmath149 is dominated by the choice of the fit function : we estimate the associated uncertainty using a large sample of reasonable ( and some _",
    "un_-reasonable ) variations to the fitting model .",
    "how should we _ `` combine '' _ the statistical and systematic errors in this case ?",
    "i , for one , do nt know .",
    "we _ can _ answer the following , more sharply posed question : is the yield `` significant '' even when the systematics are taken into account ? ( phys .",
    "lett . insists on `` @xmath150 '' significance before you are allowed to call something an `` observation '' . )",
    "all attempted variations to the fit gave yields with significance @xmath151 , and we take this to be the relevant test : the statement that `` the yield is inconsistent with fluctuations of the background '' does not depend on some accidental feature of the fit , but is robust .      when on the other hand systematic errors are dominant , we do not quote intervals  and questions of `` significance '' tend not to arise .",
    "an example is our measurement of @xmath152 decays  @xcite , where we find the underlying quark transition  the theoretically interesting process  to have a branching @xmath153 there are plenty of issues of interpretation in such cases ( they are _ analyses _ properly - so - called ) but they are beyond the scope of this review .",
    "as a final example , let s consider a very difficult problem : the interpretation of our new @xmath154 result  @xcite . like the @xmath29 analysis , this is a measurement of a time - dependent cp - violating asymmetry , with two differences : @xmath155 is sensitive to the unitarity angle @xmath15 ; and there may be direct cp violation in the decay .",
    "we fit @xmath156    \\label{eq - pipi - fit}\\ ] ] to the decay - time distribution for @xmath9  ( @xmath157 ) and @xmath10  ( @xmath158 ) , where @xmath159 and @xmath160 are the lifetime and mass - splitting of the eigenstates @xmath161 . the coefficients are given by @xmath162 a value @xmath163 corresponds to direct cp violation in the decay .     asymmetry analysis , with the belle measurement.,width=453 ]    the parameter space , fig .",
    "[ figure - btopipi ] , is wonderfully complicated .",
    "there are two kinds of special region : the null asymmetry point @xmath164 , and the _ line _",
    "@xmath165 , where there is no direct cpv ( @xmath166 ) . the physical boundary @xmath167 forms a ring around these regions  and the belle measurement @xmath168 , @xmath169 lies _",
    "outside it_!-decay endpoint analysis , where resolution effects can give @xmath170 . in the presence of background events , values outside",
    "the physical boundary can occur . ]",
    "if we want to determine a confidence interval in the true parameters @xmath171 , we immediately run into difficulty :    1 .",
    "_ frequentist method : _ if we study the fit using monte carlo events , we find that the fitted error on @xmath172 _ varies _ from virtual experiment to virtual experiment , by a factor of a few .",
    "so in constructing a toy monte carlo to model the fit  and determine confidence intervals  how do we generate the observed @xmath172 , given some underlying parameters @xmath171 ? 1 .",
    "if we use the _ measured _ errors , what if we `` get lucky '' and they are unusually small ?",
    "can we trust a result that says our value is `` inconsistent '' with fluctuations from @xmath173 ?",
    "2 .   if we use the _ distribution _ of errors from the full monte carlo , then the _ actual _ errors returned by the fit are never used in the analysis .",
    "it seems paradoxical to `` throw away '' a fitted error .",
    "bayesian method : _ here the community expectation is less definite than for @xmath174 , so any explicit prior would be controversial .",
    "but because of the configuration of the physically interesting points and the physical boundary , an explicit prior seems unavoidable . for suppose we tried to form a pseudo - bayesian interval by `` integrating the likelihood function '' on the physical region , expanding outwards from the measured value ( fig .  [ figure - btopipi - flatprior ] ) .",
    "we want to know if we reach the point of null asymmetry @xmath173 before or after we have exhausted ( say ) 99.7% of the integral : if the 99.7% interval does not include @xmath173 , surely we can say that we exclude it at some level  and write off the improper treatment of the prior as a minor detail ( _ cf .",
    "_ section  [ subsub - flatprior ] ) ?",
    "+ this is not possible in general , because of the special region @xmath166 .",
    "if we allow some prior probability for indirect cpv ( @xmath175 ) in the absence of direct cp violation , there is a `` delta - line function '' @xmath176 running along the @xmath177 axis . in general a credible interval",
    "will intersect this function _ before reaching @xmath173_. thus there is no way to determine the probability content of the interval without making an explicit commitment as to the prior @xmath176 .",
    "( a `` flat '' prior means @xmath178 . )",
    "i can see no way around this problem : any prior must be explicit .",
    ", showing an interval ( shaded ) constructed with a `` flat prior '' on the physical region .",
    "note that the interval intersects the special region @xmath179 before reaching the null asymmetry point @xmath173.,width=302 ]",
    "in section  [ subsec - analyses - rare ] , in all the excitement about priors , i almost forgot to notice a glaring inconsistency . we require significance @xmath180 before we will quote a central value , corresponding to a 99.7% confidence requirement  but we quote 90% c.l . upper limits !",
    "if a value falls between these two levels , we should not be able to say anything at all : in fact we are let off the hook because our interval - setting is not unified .",
    "( as noted above , the integral method  ( [ eq - bayesian-90 ] ) always gives an upper limit . ) in defence of belle , we are following community practice and expectations here , and those expectations are incoherent .",
    "my provisional idea for a way around the problem is to    * _ always _ quote the central value ; * construct 99.7% c.l .",
    "intervals in a unified manner ( _ i.e. _   going over continuously from upper limits to central intervals , the way the so - called feldman - cousins intervals  @xcite do ) ; * use these intervals in place of the @xmath180 test ; * quote 90% c.l .",
    "intervals _ as well _ , because people expect them ; * if people query the use of 3 numbers / intervals , rather than 1 , explain ; * if people _ object _ to the use of 3 numbers , resort to violence .",
    "this would be consistent , but it is a utopian scheme  and i suspect it would take a dictator to implement it ( _ cf .",
    "_  section  [ section - practice ] ) .",
    "i will try to raise consciousness on this issue at belle , but it really is a community problem , and we should try to think up some way for all of us to get to `` there '' from `` here '' . the three - values approach i ve suggested may not be the best way .",
    "note also that a unified treatment of `` significance '' and confidence intervals begs another question :      in sections  [ subsec - analyses - timing ] and  [ subsec - analyses - flattish ] i noted cases where we are able to avoid this question , but this is not general .",
    "the technique used for the rare decays ( section  [ subsec - analyses - rare ] ) is peculiar : the integration method is pseudo - bayesian , as discussed at some length ; it may not be quite so obvious , but the practice of inflating the confidence intervals by `` one sigma '' of the systematic error is pseudo - frequentist .",
    "it treats the systematic error as a nuisance parameter with range @xmath181 $ ] , and demands that our confidence interval provides coverage for all values in that region .",
    "to my mind this is almost exactly the wrong way around :    * i think our prior beliefs about branching fractions and cp violation are not of interest ( or at least , do not belong in papers ) , which suggests a frequentist approach ; whereas * our beliefs about our systematic errors surely are relevant ",
    "everyone knows they come down to a question of judgement  which suggests a bayesian approach .",
    "a complicating factor is that not all `` systematic errors '' are the same kind of thing :    * particle i d efficiencies are measured on control samples , which have statistical uncertainties : it seems reasonable to use some averaging method when assessing the effect on any final interval .",
    "* the unknown phases of resonances on dalitz plots ( for example ) are at the other extreme : we have no business making assumptions about them , and if they significantly affect a result we should require any confidence interval to provide coverage for all possible values . *",
    "the choice of parameterization for a fit function is unlike both of the previous examples .",
    "needless to say , these musings do not constitute a policy , much less a recipe .",
    "i suspect that intervals of the form @xmath100 will remain with us for some time .",
    "the consensus from the floor during this talk was that in a problem of this difficulty , rigour is essential : only the two extreme approaches make sense , _ viz .",
    "_    1 .   a frequentist calculation from first principles , and 2 .   a full , openly subjective bayesian analysis",
    "regarding the second of these , i am already convinced ( see section  [ section - pipi ] ) . as for the frequentist calculation ,",
    "i am indebted to my colleagues at the conference for some ingenious suggestions on the proper treatment of the errors .",
    "i hope to experiment with them , together with my belle colleagues , before the summer .",
    "the belle collaboration performs a large range of analyses , using a range of statistical approaches .",
    "some of the methods are open to question , although there is a clear trade - off between utility and statistical rigour in some cases .",
    "the expectations of the broader physics community also play a role . in the case of the @xmath1 analysis ,",
    "the statistical environment is unusually difficult , and rigorous ( rather than approximate ) methods are required .",
    "i would like to thank the conference organizers for arranging an instructive and entertaining programme for this meeting .",
    "in particular , i am indebted to the conference secretary linda wilkinson , for her help in recovering lost slides and other material . to my colleagues on belle , and the collaboration management : thanks for their patience with my questions and criticisms on statistical matters , and for the freedom i am habitually given to speak my mind in public .",
    "a.  ali , g.  kramer , and c .- d .",
    "lu , phys .",
    "d * 58 * ( 1998 ) 094009 ; y .- h .  chen , h .- y .",
    "cheng , b.  tseng , and k .- c .",
    "yang , phys .",
    "d * 60 * ( 1999 ) 094014 ; h .- y .",
    "cheng and k.c .",
    "yang , phys .",
    "d * 62 * ( 2000 ) 054029 ."
  ],
  "abstract_text": [
    "<S> the belle collaboration operates a general - purpose detector at the kekb asymmetric energy @xmath0 collider , performing a wide range of measurements in beauty , charm , tau and 2-photon physics . in this paper , </S>",
    "<S> the treatment of statistical problems in past and present belle measurements is reviewed . </S>",
    "<S> some open questions , such as the preferred method for quoting rare decay results , and the statistical treatment of the new @xmath1 analysis , are discussed . </S>"
  ]
}