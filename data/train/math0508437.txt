{
  "article_text": [
    "seemingly unrelated regressions ( sur ) are multivariate regression models with correlated response ( or dependent ) variables that follow a joint gaussian distribution . usually different regressions contain different covariates ( or independent variables ) and seem `` unrelated . ''",
    "however , due to the correlated response variables the regressions are only `` seemingly unrelated '' and contain valuable information about each other @xcite .",
    "sur play `` a central role in contemporary econometrics '' @xcite but also appear in other contexts @xcite .",
    "moreover , sur arise in the context of gaussian graphical models ( @xcite ; @xcite ) .",
    "the parameters of a sur model can be estimated efficiently , i.e.  with small variance , by maximizing the likelihood function , which maps the parameters to the likelihood of observing the given data .",
    "@xcite and @xcite give two popular algorithms for this maximization . in general ,",
    "however , these algorithms will not globally maximize the likelihood function , which indeed may be multimodal ; a fact neglected in the literature @xcite . @xcite demonstrated the possibility of multimodality in a study of a bivariate sur model that may have a likelihood function with five stationary points . in this paper , we use algebraic geometry to apply the approach of @xcite to more general sur models . in sections",
    "[ sec : sur ] and [ sec : mlepoly ] we give an introduction to sur and show how maximum likelihood estimation can be performed by solving a polynomial optimization problem , opening the door for tools from algebraic geometry . with these tools",
    ", we first revisit the work by @xcite , see section [ sec : revisit ] , and then obtain new results on more general sur models ( section [ sec : groebner ] ) .",
    "in particular , we identify examples of sur models , for which all stationary points of the likelihood function can be computed .",
    "in sur a family of response variables , indexed by a finite set @xmath0 , is stochastically modeled using a family of covariates , indexed by a finite set @xmath1 .",
    "all response variables and all covariates are observed on a finite set of subjects @xmath2 .",
    "we denote the cardinalities of the three sets also by @xmath0 , @xmath1 and @xmath2 , respectively .",
    "the observations can be represented by two matrices @xmath3 and @xmath4 .",
    "the matrix @xmath5 has the @xmath6-entry equal to the observation of response variable @xmath7 on subject @xmath8 , and the matrix @xmath9 has the @xmath10-entry equal to the observation of covariate @xmath11 on subject @xmath8 . for @xmath11 and @xmath7 , @xmath12 and @xmath13",
    "denote the @xmath14-th and @xmath15-th row of @xmath3 and @xmath4 , respectively . similarly , @xmath16 and @xmath17",
    ", @xmath8 , denote the @xmath18-th column of @xmath3 and @xmath4 , respectively .",
    "clearly , @xmath19 and @xmath20 comprise all observations of the @xmath14-th covariate and the @xmath15-th response variable ; @xmath16 and @xmath17 comprise all covariate and response variable observations on the @xmath18-th subject .    in this regression setting , the matrix @xmath3 is assumed to be deterministic and fixed but the matrix @xmath4 is modeled to follow a multivariate normal distribution , where the mean vector of @xmath20 , @xmath7 , is a linear combination of some @xmath19 , @xmath21 , @xmath22 = \\sum_{c\\in c_r } \\beta_{rc } x_c\\in { \\mathbb{r}}^n , \\quad r\\in r.\\ ] ] here @xmath23 is a fixed family of subsets of @xmath1 indexing the covariates involved in each one of the @xmath0 regressions .",
    "the weights @xmath24 in ( [ eq : betadef ] ) are called _",
    "regression coefficients_. setting @xmath25 if @xmath26 , we can define a matrix of regression coefficients @xmath27 .",
    "the random vectors @xmath17 , @xmath28 , are assumed to be independent with common positive definite covariance matrix @xmath29=\\sigma\\in { \\mathbb{r}}^{r\\times    r } , \\quad m\\in n.\\ ] ] letting @xmath30 the _ seemingly unrelated regressions model _ is the family of normal distributions @xmath31 here @xmath32 is the multivariate normal distribution on @xmath33 ; @xmath34 is the @xmath35 identity matrix ; @xmath36 is the kronecker product ; @xmath37 and @xmath38 are the mean and the variance parameters ; and _ the parameter space _",
    "@xmath39 is the cartesian product of the linear space @xmath40 and the cone @xmath41 of all positive definite real @xmath42 matrices .",
    "the response matrix @xmath4 is then an observation from some ( unknown ) distribution in the model , @xmath43 if @xmath44 and @xmath3 is a matrix of full rank , then with probability one the @xmath45 matrix obtained by stacking @xmath3 and @xmath4 has full rank , @xmath46 we assume ( [ eq : fullrank ] ) to hold throughout the paper .",
    "the _ probability density function _",
    "@xmath47 of the distribution @xmath48 can be written as @xmath49 \\right\\}.\\ ] ] for data @xmath4 , the _ likelihood function _ @xmath50 of the model @xmath51 is defined as @xmath52 in maximum likelihood estimation the parameters @xmath53 are estimated by @xmath54 it follows from ( [ eq : fullrank ] ) that the maximum of the likelihood function exists .",
    "we can parameterize @xmath55 by mapping a vector @xmath56 to the matrix @xmath57 with entry @xmath58 if @xmath59 and @xmath60 otherwise . define @xmath61 by @xmath62 .",
    "\\end{split}\\ ] ] clearly we can solve ( [ eq : maxl ] ) by finding @xmath63 and setting @xmath64 . the standard approach to solve ( [ eq : maxell ] ) is to solve the _ likelihood equations _",
    "@xmath65 it can be shown that ( [ eq : likeqn ] ) holds if and only if @xmath66 and @xmath67^{-1 }    a ' \\mathrm{vec}(\\sigma^{-1 } yx'),\\ ] ] where @xmath68 is a matrix of zeroes and ones that satisfies @xmath69 .",
    "in fact , each column of @xmath68 has precisely one entry equal to one and the remaining entries equal to zero .",
    "@xcite show how one solution to the likelihood equations can be obtained by alternating between solving ( [ eq : sigmamax ] ) for fixed @xmath70 and solving ( [ eq : betamax ] ) for fixed @xmath38 . here , we take a different approach that , for certain sur models , allows us to compute all solutions to the likelihood equations .    from ( [ eq : fullrank ] ) and ( [ eq : elldef ] ) , it follows that for fixed @xmath71 the function @xmath72 is strictly concave with maximizer ( [ eq : sigmamax ] ) . thus the _ profile log - likelihood function _ @xmath73 defined as @xmath74 takes on the form @xmath75 by the strict con - cavity of @xmath76 ,",
    "@xmath77 is a stationary point of @xmath78 if and only if @xmath70 is a stationary point of @xmath79 and @xmath38 satisfies ( [ eq : sigmamax ] ) ; compare ( * ? ? ?",
    "* lemma 1 ) .",
    "the same holds for @xmath80 which conveniently is a polynomial in @xmath70 .",
    "thus we can solve ( [ eq : maxell ] ) by using ( [ eq : sigmamax ] ) and solving the unconstrained polynomial program @xmath81    we try to solve ( [ eq : ming ] ) by computing the stationary points of @xmath82 , i.e. by solving the equations @xmath83 in practice the observations @xmath4 and @xmath3 are available only in finite accuracy and the partial derivatives @xmath84 , @xmath59 , are elements of the ring @xmath85 $ ] of polynomials in @xmath70 with rational coefficients .",
    "in an algebraic approach to solving polynomial equations @xcite we allow the indeterminants in the polynomial equation system ( [ eq : defgrc ] ) to be complex , i.e.   @xmath86 , where @xmath87 is the field of complex numbers .",
    "we define the _ maximum likelihood ideal _",
    "@xmath88 to be the ideal of @xmath85 $ ] that is generated by the partial derivatives @xmath84 , @xmath59 , i.e.@xmath89 compare @xcite who defines maximum likelihood ideals in a different statistical context .",
    "software like macaulay 2 and singular @xcite permits us to check whether @xmath88 is a zero - dimensional ideal . if @xmath90 , then the variety @xmath91 , i.e.  the set of common complex zeroes of the partial derivatives @xmath84 , is a finite set and all its elements can be computed using , for example , singular or also phcpack .",
    "the real points @xmath92 can then be identified and yield the stationary points of @xmath82 .",
    "@xcite study a sur model with two response variables and two covariates , in which response variable 1 is regressed only on covariate 1 , and response variable 2 only on covariate 2 .",
    "hence , @xmath93 , @xmath94 , @xmath95 , and @xmath96 .",
    "therefore , @xmath97 , and @xmath98 if @xmath37 is of the form @xmath99 using singular and the data in ( * ? ? ?",
    "* table 1 ) , we can solve ( [ eq : ming ] ) as shown in table [ tab : singularcode ] .    ' '' ''    ' '' ''    .... > ring r=0,(b(1 .. 2 ) ) , lp ; > matrix x[2][8 ] = 188,22,-46,77,-103,74,83,101 ,     .",
    "55,-216,116,-30,131,195,-311,-239 ; > matrix y[2][8 ] = 234,-5,6,182,-193,278,62,-68 ,     .                   497,-326,266,-3,93,558,-584,-224 ; >",
    "matrix b[2][2 ] = b(1),0 , 0,b(2 ) ; >",
    "poly g = det((y - b*x)*transpose(y - b*x ) ) ; > ideal ig = jacob(g ) ;    > ideal j = groebner(ig ) ; > dim(j ) ; vdim(j ) ; 0 5 > lib \" solve.lib \" ; solve(j,6 ) ; [ 1 ] :     [ 1 ] :   0.778796     [ 2 ] :   1.538029 [ 2 ] :     [ 1 ] :   1.622609     [ 2 ] :   2.034745 [ 3 ] :     [ 1 ] :   ( 1.480687-i*1.547274 )     [ 2 ] :   ( 2.16845+i*0.765283 ) [ 4 ] :     [ 1 ] :   ( 1.480687+i*1.547274 )     [ 2 ] :   ( 2.16845-i*0.765283 ) [ 5 ] :     [ 1 ] :   2.764418     [ 2 ] :   2.504006 ....    ' '' ''    as computed by dim and vdim , the maximum likelihood ideal @xmath100 is zero - dimensional and of degree five .",
    "the five points in the variety @xmath91 are computed by solve , which lists @xmath101 as first component and @xmath102 as second component .",
    "there are three real points in @xmath103 , which yield the stationary points of the likelihood function of the model @xmath51 .",
    "note that we confirm the values stated in ( * ? ? ?",
    "* table 2 with @xmath104 and @xmath105 ) .",
    "the grbner basis computed by the command groebner(ig ) has two elements that are ( i ) a quintic in @xmath102 and ( ii ) a sum of a linear function in @xmath101 and a quartic in @xmath106 .",
    "thus it follows immediately that the stationary points of @xmath82 can be found from solving a quintic ( cf .",
    "* thm.2 ) .",
    "the algebraic approach can also be applied to more general models . here",
    "we focus on sur models @xmath51 for which @xmath23 consists of disjoint sets ; in other models inclusion relations among the sets @xmath107 may be exploited ( cf . * ? ? ?",
    "more precisely , we consider models @xmath51 in which @xmath108 , @xmath109 , implies that @xmath110 for all @xmath111 and @xmath112 .",
    "then @xmath55 is a linear space of block - diagonal matrices .",
    "table [ tab : gensurdimdegree ] states the dimension and degree of the maximum likelihood ideal for seven examples including the one from section [ sec : revisit ] .",
    ".dimension and degree of maximum likelihood ideals . [ cols=\"^,^,^,^\",options=\"header \" , ]     it should also be noted that submodels of sur need not inherit unimodal likelihood functions from their parent model .",
    "for example , the bivariate sur model @xmath51 with @xmath113 is monotone , i.e.  the family @xmath23 is totally ordered by inclusion , which guarantees that the likelihood function has precisely one stationary point corresponding to the global maximum @xcite .",
    "however , the submodel induced by the restriction @xmath114 can be reexpressed in the form of the model studied in section [ sec : revisit ] by means of the linear transformation that changes response @xmath115 into @xmath116 . hence",
    ", the submodel does not always have a unimodal likelihood function .",
    "the presented algebraic approach to maximum likelihood estimation in sur permits us to compute all stationary points of the likelihood function if the maximum likelihood ideal is zero - dimensional .",
    "this is the case for three seemingly unrelated regressions models considered in this paper ( cf .",
    "table [ tab : gensurdimdegree ] ) : ( i ) the previously studied model based on @xmath117 , ( ii ) the model with @xmath118 , and ( iii ) the model with @xmath119 .",
    "additionally , interesting submodels of sur may have a zero - dimensional maximum likelihood ideal ( cf .",
    "table [ tab : submoddimdeg ] ) .",
    "the computations in singular that find all stationary points of the likelihood functions of the models with zero - dimensional maximum likelihood ideal are instantaneous for all but the model in table [ tab : submoddimdeg ] that has a maximum likelihood ideal of degree 63 .",
    "thus we advocate the use of singular or similarly capable software in statistical data analysis .    in future work",
    "it would be interesting to find reference data sets leading to likelihood functions with a large number of stationary points .",
    "moreover , the algebraic approach presented herein could be combined with regression approaches ( e.g. * ? ? ?",
    "* ; * ? ? ?",
    "* ) in order to identify larger classes of sur models for which all stationary points of the likelihood function can be computed .",
    "finally , it could be explored whether methods for global minimization of polynomials @xcite can be used to find the global maximum of sur likelihood functions .",
    "andersson , s.  a. , perlman , m.  d. , 1994 .",
    "normal linear models with lattice conditional independence restrictions . in : multivariate analysis and its applications .",
    "vol .  24 .",
    ", hayward , ca , pp . 97110 .",
    "drton , m. , andersson , s.  a. , perlman , m.  d. , 2003 .",
    "conditional independence models for seemingly unrelated regressions with incomplete data . tech . rep .",
    "431 , dept . of statistics ,",
    "university of washington .",
    "greuel , g .-",
    "m . , pfister , g. , schnemann , h. , 2001 .",
    "singular 2.0 . a computer algebra system for polynomial computations , centre for computer algebra , university of kaiserslautern , http://www.singular.uni-kl.de .",
    "parrilo , p.  a. , sturmfels , b. , 2003 .",
    "minimizing polynomial functions . in : basu , s. , gonzalez - vega , l. ( eds . ) , algorithmic and quantitative real algebraic geometry ( piscataway , nj , 2001 ) .",
    "vol .  60 of dimacs ser .",
    "discrete math .",
    "soc . , providence , ri , pp ."
  ],
  "abstract_text": [
    "<S> seemingly unrelated regressions are statistical regression models based on the gaussian distribution . </S>",
    "<S> they are popular in econometrics but also arise in graphical modeling of multivariate dependencies . in maximum likelihood estimation , </S>",
    "<S> the parameters of the model are estimated by maximizing the likelihood function , which maps the parameters to the likelihood of observing the given data . by transforming this optimization problem into a polynomial optimization problem </S>",
    "<S> , it was recently shown that the likelihood function of a simple bivariate seemingly unrelated regressions model may have several stationary points . </S>",
    "<S> thus local maxima may complicate maximum likelihood estimation . in this paper </S>",
    "<S> , we study several more complicated seemingly unrelated regression models , and show how all stationary points of the likelihood function can be computed using algebraic geometry .    </S>",
    "<S> algebraic statistics , grbner basis , maximum likelihood estimation , multivariate statistics , seemingly unrelated regressions </S>"
  ]
}