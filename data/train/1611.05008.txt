{
  "article_text": [
    "a light field can be defined as the collection of all light rays in a 3d space @xcite .",
    "one of the earliest implementations of a light field camera was presented @xcite , where a micro - lens array is placed in front of a film to capture incident light amount from different directions . while a light field , in general , can be parameterized in terms of 3d coordinates of ray positions , 2d ray directions , and physical properties of light , such as as wavelength and polarization , the independent parameters can be reduced to a four - dimensional space assuming there is no energy loss during light propagation and when only the intensity of light is considered ; such a four - dimensional representation of light field is used in many practical applications @xcite . unlike regular cameras , light field cameras capture the directional light information , which enables new capabilities , including post - capture adjustment of camera parameters ( such as focus and aperture size ) , post - capture change of camera viewpoint , and depth estimation . as a result",
    ", light field imaging is getting increasingly used in a variety of applications areas , including digital photography , microscopy , robotics , and machine vision .",
    "light field imaging systems can be implemented in variety of ways , including camera arrays @xcite , micro - lens arrays @xcite , coded masks @xcite , objective lens arrays @xcite , and gantry - based camera systems @xcite . among these different implementations ,",
    "micro - lens array ( mla ) based light field cameras offer a cost - effective approach ; and it is widely adopted in academic research as well as in commercial light field cameras @xcite .",
    "mla - based light field cameras has two limiting issues .",
    "the first one is low spatial resolution .",
    "because the imaging sensor is shared to capture both spatial and angular information , mla - based light field cameras suffer from a fundamental resolution trade - off between spatial and angular resolution .",
    "for example , the first - generation lytro camera has a sensor of around 11 megapixels , producing 11x11 angular resolution and less than 0.15 megapixel spatial resolution @xcite .",
    "the second - generation lytro camera has a sensor of 40 megapixels ; however , this large resolution capacity translates to only four megapixel spatial resolution ( with the manufacturer s decoding software ) due to the angular - spatial resolution trade - off .",
    "the second issue associated with mla - based light field cameras is narrow baseline .",
    "the distance between sub - aperture images decoded from a light field capture is very small , significantly limiting the depth estimation range and accuracy .",
    "for instance , the maximum baseline ( between the leftmost and rightmost sub - aperture images ) of a first - generation lytro camera is less than a centimeter , which may result in sub - pixel feature disparities .",
    "there are methods in the literature specifically designed to estimate disparities and depth maps for mla - based light field cameras @xcite .    to address both resolution and baseline issues , we propose a hybrid stereo imaging system that consists of a light field camera and a regular camera .",
    "the proposed imaging system is shown in figure [ fig : fig1 ] ; it has two main advantages over a single light field camera : first , high spatial resolution image captured by the regular camera is fused with low spatial resolution sub - aperture images of the light field camera to enhance the spatial resolution of each sub - aperture image ; that is , a high spatial resolution light field is obtained while preserving the angular resolution .",
    "second , the distance between the light field camera and the regular camera produces a larger baseline compared to the maximum baseline of the light field camera ; as a result , the hybrid system has a better depth estimation range and accuracy .",
    "hybrid light field imaging systems have been presented previously @xcite . unlike these previous work , where spatial resolution enhancement is the only goal , we achieve wider baseline through using a calibrated system . with wide baseline , both range and accuracy of depth estimation are improved in addition to spatial resolution enhancement . fixing cameras as a stereo system also enables offline calibration and rectification , reducing the computational cost .        in section 2",
    ", related work addressing spatial resolution and narrow baseline issues of mla - based light field cameras is provided . the proposed hybrid imaging system with resolution enhancement algorithm",
    "is explained in section 3 .",
    "experimental results on resolution enhancement and depth estimation are presented in section 4 .",
    "concluding remarks are given in section 5 .",
    "_ on low spatial resolution : _ there are various methods proposed to address the low spatial resolution issue in mla - based light field cameras .",
    "one main approach is to apply super - resolution image restoration to light field sub - aperture images .",
    "super - resolution in a bayesian framework is commonly used , for example , in @xcite with lambertian and textural priors , in @xcite with a gaussian mixture model , and in @xcite with a variational formulation .",
    "learning - based methods are adopted as well , including dictionary - based learning @xcite and deep convolutional neural networks @xcite .",
    "in addition to spatial domain super - resolution restoration , fourier - domain techniques @xcite and wave optics based 3d deconvolution methods @xcite have also been utilized .",
    "alternative to the standard mla - based light field camera design @xcite , where the mla is placed at the image plane of the main lens and the sensor is placed at the focal length of the lenslets , there is another design approach where the mla is placed to relay image from the intermediate image plane of the main lens to the sensor @xcite .",
    "this design is known as `` focused plenoptic camera . '' as in the case of the standard light field camera approach , super - resolution restoration for focused plenoptic cameras is also possible @xcite .",
    "all single - sensor light field imaging systems are fundamentally limited by the spatial - angular resolution trade - off , and the above - mentioned restoration methods have performance limitations in addition to the computational costs .",
    "another approach for improving spatial resolution is to use a hybrid two camera system , including a light field camera and a high - resolution camera , and merge the images to improve spatial resolution @xcite .",
    "dictionary - learning based techniques are adopted @xcite in this problem as well : high resolution image patches from the regular camera are extracted and stored as a high resolution patch dictionary .",
    "these high resolution patches are downsampled ; and from the downsampled pathes , low resolution features are extracted to form a low resolution patch dictionary . during super - resolution reconstruction , a low resolution image patch",
    "is enhanced through determining ( based on feature matching ) and using the corresponding high resolution patches in the dictionary . in @xcite",
    ", high resolution image is decomposed with complex steerable pyramid filters ; the depth map from the light field is upsampled using joint bilateral upsampling ; perspective shift amounts are estimated from the upsampled depth map , and these shift amounts are used to modify the phase of the decomposed high resolution image ; with the modified phases , pyramid reconstruction is applied to obtain high resolution light field .",
    "_ on narrow baseline : _ one of the most important features of light field cameras is the ability to estimate depth .",
    "however , it is known that depth accuracy and range is limited in mla - based light field cameras due to narrow baseline .",
    "the relation between baseline and depth estimation accuracy in a stereo system has been studied in @xcite . in a stereo system with focal length @xmath0 and baseline @xmath1 ,",
    "the depth @xmath2 of a point with disparity @xmath3 is obtained through triangulation as @xmath4 . with a disparity estimation error of @xmath5 ,",
    "the depth estimation error @xmath6 becomes @xcite :    @xmath7    which indicates that the depth estimation error is inversely proportional with the baseline and increases quadratically with depth .",
    "the disparity error @xmath5 is typically set to 1 , and the depth estimation error @xmath6 as a function depth can be calculated .",
    "it is also possible to set an error bound on @xmath6 and derive the maximum depth range from the above equation .    for an mla - based light field camera ,",
    "the maximum baseline is less than the size of of the main lens aperture , making depth estimation very challenging .",
    "there are methods specifically proposed for depth estimation in mla - based light field cameras .",
    "for example , in @xcite , the problem is formulated as a constrained labeling problem on epipolar plane images in a variational framework . in @xcite , ray geometry of 3d line segments",
    "is imposed as constraints on light field triangulation and stereo matching . in @xcite ,",
    "defocus and shading cues are used to improve the disparity estimation accuracy .",
    "the hybrid stereo imaging system consists of a regular camera and a light field camera as shown in figure [ fig : fig1 ] .",
    "the system has two advantages over a single light field camera : ( i ) the high - resolution image produced by the regular camera is used to improve the spatial resolution of each sub - aperture image extracted from the light field camera .",
    "that is , we obtain a light field with enhanced spatial resolution .",
    "( ii ) the large baseline between the regular camera and the light field camera results in a wider range and more accurate depth estimation capability , compared to a single light field camera .      + ( a ) ( b )       + ( a ) ( b )",
    "( c )          the prototype system includes a first - generation lytro camera and a regular camera ( avt mako g095c ) .",
    "the light field is decoded using @xcite to obtain 11x11 sub - aperture images , each with size 380x380 .",
    "the regular camera has a spatial resolution of 1200x780 pixels .",
    "the imaging system is first calibrated : the regular camera image and the light field middle sub - aperture image is calibrated ( utilizing the matlab stereo calibration toolbox ) to determine the overlapping regions between the images and rectify the regular camera image .",
    "the regular image is then photometrically mapped to the color space of the light field sub - aperture images using the histogram - based intensity matching function technique @xcite .",
    "a raw light field data and the extracted sub - aperture images are shown in figure [ fig : raw ] . in figure",
    "[ fig : photomet ] , the rectified regular camera image is shown along with a light field sub - aperture image .",
    "an illustration of the resolution enhancement process is given in figure [ fig : flowchart ] .",
    "each low - resolution ( lr ) light field sub - aperture image is bicubically interpolated to match the size of the high - resolution ( hr ) regular camera image . the optical flow between the hr image and the light field middle sub - aperture image and the optical flow between the light field middle sub - aperture and every other sub - aperture images are estimated .",
    "( we use the optical flow estimation algorithm presented in @xcite in our experiments . ) combining these optical flow estimates , motion vectors between the hr image and each light field sub - aperture image are obtained .",
    "the hr image is warped onto each light field sub - aperture image and fused to produce a high - resolution version of each sub - aperture image . as a result",
    ", a high - resolution light field is obtained .",
    "the problem of image fusion for resolution enhancement has been well studied in the literature , with applications in satellite imaging for pan - sharpening , digital camera pipelines for demosaicking , and in computational photography for multi - focus stacking @xcite . in our experiments ,",
    "we tested two basic methods for image fusion : ( i ) a wavelet - based approach @xcite , available in matlab as function _ wfuseimg _ , which essentially replaces the detail subbands of low - resolution image with the detail subbands of the high resolution image , and ( ii ) alpha blending , also available in matlab as function _ imfuse _ , which simply takes the weighted average of input images .    _ speeding up the registration process : _ we further increase the speed of registration process by using the fact that light field sub - aperture images are captured on a regular grid . instead of estimating the optical flow between the middle sub - aperture image and each of the remaining sub - aperture images",
    ", we estimate the optical flow between the middle and the leftmost , rightmost , topmost , and bottommost sub - aperture images as shown in figure [ fig : optical ] .",
    "the estimated motion vectors are interpolated for the rest of the sub - aperture images according to their relative positions within the light field . as a result",
    ", we have four within - light - field - camera optical flow estimation ( instead of 120 ) and one between - cameras optical flow estimation . in figure",
    "[ fig : difference ] , we show the difference between the regular camera image and light field sub - aperture images before and after registration . the optical flow within the light field is estimated as described above .",
    "the after - registration result shows that the registration process works well .",
    "( note that the residuals for the sub - aperture images in the aperture corners are large because of the fact that the original sub - aperture images in the corners are too dark due to vignetting . )",
    "in this section , we present our experimental results on resolution enhancement and depth estimation . all implementations are done with matlab , running on an intel i5 pc with 12 gb ram . for the resolution enhancement process ,",
    "given in figure [ fig : flowchart ] , the processing time of an entire lytro light field is about 70 seconds , in which the optical flow estimation per image pair is about 11 seconds . in figure [ fig : warped ] , we compare a light field sub - aperture image with its resolution - enhanced version .",
    "both the alpha blending and wavelet - based image fusion processes produce good results in terms of resolution enhancement .",
    "alpha blending suppresses the low - spatial - frequency color noise better than the wavelet - based approach ; this is expected because the wavelet - based approach preserves the low - frequency content of the light field images , which have more noise compared to the image obtained from the regular camera .",
    "alpha blending , on the other hand , simply averages two images , reducing the overall noise in all parts of the final image .",
    "( in all our experiments , the weights of the hr image and light field sub - aperture images are 0.55 and 0.45 , respectively , giving slightly more weight to the hr image in alpha blending . )",
    "+     + ( a ) ( b ) ( c ) +    _ refocusing : _ one of the key features of light field imaging is post - capture digital refocusing through a simple shift - and - sum procedure @xcite . in figure",
    "[ fig : refocusing ] , we show refocusing at different distances with lytro light field images and the resolution - enhanced light field sub - aperture images .",
    "it can clearly be seen that we can obtain sharper refocusing compared to the original lytro images . in figure",
    "[ fig : refocusing2 ] , we provide refocusing examples from another data set captured by our imaging system .",
    "again , the resolution - enhanced light field result in higher resolution refocusing compared to the lytro light field .",
    "+   +   +   +   +   +     + ( a ) ( b ) ( c )       +   +     +   +     + ( a ) ( b ) ( c )    _ improving depth range and accuracy : _ to demonstrate the increased depth range and improved depth estimation accuracy of our hybrid imaging system , we devised an experimental setup , where target objects ( i.e , `` lego blocks '' ) are placed in the scene starting from 40 cm away from the imaging system . in figure",
    "[ fig : lrhrdisparity ] , we show the leftmost and rightmost light field sub - aperture images as well as the regular camera image , in addition to the disparity maps , which are estimated using @xcite .",
    "the dynamic range of the disparity map for the hybrid system ( between the middle sub - aperture image and the regular camera image ) is about eight times larger than that of the light field camera ( between the leftmost and rightmost sub - aperture images ) . comparing the ranges of disparity maps and the separation of different objects from different depths",
    ", we can see that the hybrid system improves the depth estimation accuracy . in figure",
    "[ fig : lrhrdisparity](f ) , the disparities for the target object positions are plotted . for the light field camera , the disparity difference from one depth to another becomes too small beyond 100 cm , making it difficult to distinguish between different depths , and the disparities eventually become sub - pixel beyond 200 cm . on the other hand , for the hybrid system ,",
    "the disparities are large and distinguishable in the same range .       + ( a ) ( b ) ( c ) +     + ( d ) ( e ) +   + ( f ) +",
    "in this paper , we presented a hybrid imaging system that includes a light field camera and a regular camera .",
    "the system , while keeping the capabilities of light field imaging , improves both spatial resolution and depth estimation range / accuracy due to increased baseline . because the fixed stereo system allows pre - calibration and by utilizing the the fact that light field sub - aperture images are captured on a regular grid , the registration of low - resolution light field sub - aperture images and high - resolution regular camera images is simplified . with proper image registration ,",
    "even a simple image fusion , such as alpha blending , produces good results .",
    "boominathan , v. , mitra , k. , veeraraghavan , a. : improving resolution and depth - of - field of light field cameras using a hybrid imaging system . in : ieee int .",
    "conf . on computational photography ,",
    "110 ( 2014 )    broxton , m. , grosenick , l. , yang , s. , cohen , n. , andalman , a. , deisseroth , k. , levoy , m. : wave optics theory and 3d deconvolution for the light field microscope .",
    "optics express * 21 * , 25,41825,439 ( 2013 )    cho , d. , lee , m. , kim , s. , tai , y. : modeling the calibration pipeline of the lytro camera for high quality light - field image reconstruction . in : ieee int . conf . on computer vision , pp .",
    "32803287 ( 2013 )    dansereau , d.g . ,",
    "pizarro , o. , williams , s.b . : decoding , calibration and rectification for lenselet - based plenoptic cameras . in : ieee conf . on computer vision and pattern recognition ,",
    "10271034 ( 2013 )        georgiev , t. , zheng , k.c . , curless , b. , salesin , d. , nayar , s. , intwala , c. : spatio - angular resolution tradeoffs in integral photography . in : eurographics conf .",
    "on rendering techniques , pp .",
    "263272 ( 2006 )                          mitra , k. , veeraraghavan , a. : light field denoising , light field superresolution and stereo camera based refocussing using a gmm light field patch prior . in : ieee conf . on computer vision and pattern recognition workshops , pp .",
    "2228 ( 2012 )            trujillo - sevilla , j.m . , rodriguez - ramos , l.f . ,",
    "montilla , i. , rodriguez - ramos , j.m . : high resolution imaging and wavefront aberration correction in plenoptic systems .",
    "optics letters * 39 * , 50305033 ( 2014 )      veeraraghavan , a. , raskar , r. , agrawal , a. , mohan , a. , tumblin , j. : dappled photography : mask enhanced cameras for heterodyned light fields and coded aperture refocusing . in :",
    "acm trans . on graphics ,",
    "112 ( 2007 )            wilburn , b. , joshi , n. , vaish , v. , talvala , e.v .",
    ", antunez , e. , barth , a. , adams , a. , horowitz , m. , levoy , m. : high performance imaging using large camera arrays . in : acm trans . on graphics ,",
    ". 765776 ( 2005 )"
  ],
  "abstract_text": [
    "<S> light field imaging involves capturing both angular and spatial distribution of light ; it enables new capabilities , such as post - capture digital refocusing , camera aperture adjustment , perspective shift , and depth estimation . </S>",
    "<S> micro - lens array ( mla ) based light field cameras provide a cost - effective approach to light field imaging . </S>",
    "<S> there are two main limitations of mla - based light field cameras : low spatial resolution and narrow baseline . </S>",
    "<S> while low spatial resolution limits the general purpose use and applicability of light field cameras , narrow baseline limits the depth estimation range and accuracy . in this paper , we present a hybrid stereo imaging system that includes a light field camera and a regular camera . </S>",
    "<S> the hybrid system addresses both spatial resolution and narrow baseline issues of the mla - based light field cameras while preserving light field imaging capabilities .    </S>",
    "<S> light field imaging , hybrid stereo imaging </S>"
  ]
}