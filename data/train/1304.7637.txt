{
  "article_text": [
    "consider a discrete - time , @xmath0-valued random process @xmath1 defined by the recursive equation @xmath2 where @xmath3{0.90\\textwidth } \\begin{itemize } \\item[(i ) ] $ { \\varepsilon}_1 , { \\varepsilon}_2 , \\ldots$ are independent and identically distributed random elements of a measurable space $ ( \\mathbb{e } , \\mathcal{e})$ and independent of $ x_0 $ ; \\item[(ii ) ] $ \\phi$ is a measurable function from $ { \\mathbb{r}}^d \\times { \\mathbb{e}}$ to $ { \\mathbb{r}}^d$. \\end{itemize } \\end{minipage}}\\ ] ]    if the process @xmath4 happens to be stationary , it will be assumed to be defined for all integer @xmath5 .",
    "the distribution of @xmath6 is assumed to be multivariate regularly varying .",
    "the aim of the paper is to analyze the special structure of weak limits of the finite - dimensional distributions of the process conditionally on @xmath7 being large , where @xmath8 denotes the euclidean norm .",
    "more precisely , we will investigate the weak limits , called the forward tail chain , of vectors of the form @xmath9 given that @xmath7 exceeds a high threshold . if in addition the process is stationary we will extend this to find the so - called back - and - forth tail chain , which corresponds to the weak limits of vectors of the form @xmath10 given that @xmath7 is large .",
    "a close relation of these processes to multivariate regular variation of the whole process has been analyzed in @xcite . in this article , we are interested in the special form of the processes , in particular the markovian structure of both the forward and the backward process and how they necessarily determine each other .",
    "the process @xmath4 is obviously a discrete - time homogeneous markov chain . on the other hand ,",
    "every homogeneous discrete - time markov chain @xmath4 on a complete separable metric space can be represented as in  @xcite .",
    "of course , for a given markov chain @xmath4 the above representation is not unique .",
    "still , in examples , the way in which markov chains are defined is often through a recursive equation ; all examples in @xcite , for instance , are of this type .",
    "the chain is stationary if and only if the random vectors @xmath11 and @xmath6 are equal in law .    in @xcite and @xcite , excursions of a univariate markov chain over a high threshold following an extreme event are shown to behave asymptotically and under quite general conditions as a ( multiplicative ) random walk .",
    "the theory has been extended to multivariate markov chains in @xcite and to higher - order markov chains in @xcite .",
    "more recently , @xcite have analyzed the topic with a special view towards the convergence of markov kernels and added a criterion to distinguish between extreme and non - extreme states of a markov chain as the threshold rises .",
    "the random - walk representation is useful from a statistical perspective because it gives a handle on how to model the extremes of certain time series ( @xcite ) .",
    "a useful , well - investigated class of processes for which the random walk structure is quite revealing are the stationary solutions to certain stochastic difference equations , including squared ( generalized ) autoregressive conditionally heteroskedastic ( arch / garch ) processes as a special case ( @xcite ) .",
    "a limitation of the theory of @xcite , @xcite and @xcite is that it is specialized to univariate , nonnegative markov chains .",
    "similarly , @xcite only considers the upper extremes of a multivariate markov chain .",
    "when extending the theory to real - valued and higher dimensional chains , one has to keep in mind that extremes may be both positive or negative and that extreme values of @xmath12 may depend not only on @xmath13 but also on @xmath14 .",
    "the simplest case of the extension on which we will focus deals with real - valued univariate markov chains , where an extreme value of @xmath12 may depend on the sign of @xmath15 as can be observed for instance in time series of logreturns of prices of financial securities in periods of high volatility .",
    "the observation of this so - called leverage effect has lead to the formulation of asymmetric extensions of garch models ( cf .",
    ", for example , @xcite )",
    ". for such markov chains with tail switching potential , the random walk representation of excursions over high thresholds breaks down in the sense that the distribution of the multiplicative increment now depends in general on the sign of the chain on the previous step . in @xcite ,",
    "a more general representation is postulated , involving in fact four transition mechanisms rather than one , corresponding to the four cases of transitions from and to upper or lower extreme states .",
    "the novelty of this paper is two - fold : first , to explicitly state the random walk representation in the general @xmath0-valued case ; second , in the stationary case , to study the joint distribution of the forward and backward tail chain , coined the _ back - and - forth tail chain_. throughout , some remarkable simplifications in the ( univariate ) real - valued case will be studied in more detail . in particular , in the univariate case the backward tail chain is again a random walk which is in some sense dual the forward tail chain . besides the assumption that the distribution of @xmath6 is regularly varying ,",
    "the only condition is a relatively easy - to - check statement on the asymptotic behaviour of @xmath16 for large @xmath17 .    the outline of the paper is as follows .",
    "the forward tail chain of a possibly non - stationary @xmath0-valued markov chain is studied in section  [ s : forward ] . for stationary markov chains ,",
    "the tail chain can be extended to the past of the process , the backward tail chain , see section  [ s : backforth ] .",
    "section  [ s : adjoint ] describes a kind of adjoint relation between distributions which is motivated by a general property of tail processes of stationary processes . in section  [ s : bftc ] , we show that a certain class of processes , coined back - and - forth tail chains , which are derived from this adjoint distribution , form exactly the class of tail processes which arise in our markovian setting .",
    "finally , section  [ s : examples ] provides some examples to the theory , including an application to stationary solutions of ( multivariate ) stochastic difference equations .    to conclude this section ,",
    "let us fix some notations .",
    "we write @xmath18 for the positive part of @xmath19 and @xmath20 for the negative part .",
    "the transpose of a matrix @xmath21 is denoted by @xmath22 .",
    "the law of a random vector @xmath23 is denoted by @xmath24 ; weak convergence of probability measures is denoted by @xmath25 .",
    "the probability measure degenerate at a point @xmath26 is denoted by @xmath27 , and @xmath28 denotes the uniform distribution on a compact set @xmath29 .",
    "the indicator of an event @xmath21 is denoted by @xmath30 .",
    "we write @xmath31 for @xmath32 , @xmath33 for @xmath34 and @xmath35 for a vector ( of suitable dimension ) which consists of all zeros .",
    "let @xmath36 be the set of integers and @xmath37 be the set of nonnegative integers .",
    "let @xmath38 be a homogeneous markov chain as in and , not necessarily stationary .",
    "the focus of this section is on the weak limits of the finite - dimensional distributions of the process conditionally on @xmath7 being large ( theorem  [ t : forward ] ) .",
    "two conditions are required : condition  [ c : rv ] on the tails of @xmath6 , and condition  [ c : phi ] on the asymptotics of @xmath39 for large @xmath17 .",
    "see for instance @xcite for details on multivariate regular variation .",
    "[ c : rv ] the distribution of @xmath6 is multivariate regularly varying on @xmath40 , that is , there exists a non - degenerate probability measure @xmath41 on @xmath33 ( called the spectral measure ) and an @xmath42 such that @xmath43 for all borel sets @xmath44 which satisfy @xmath45 and @xmath46 .",
    "the second condition states that the function @xmath47 in is asymptotically homogeneous in @xmath26 for large values of @xmath17 .",
    "[ c : phi ] there exists a measurable map @xmath48 such that , for all @xmath49 , @xmath50 whenever @xmath51 in @xmath33 .    moreover , if @xmath52 for some @xmath53 , then also @xmath54 , where @xmath55 is a measurable subset of @xmath56 such that for all @xmath57 , @xmath58    we extend the domain of the limit function @xmath59 in to @xmath60 by setting @xmath61    [ l : generalphi ] if condition [ c : phi ] holds , then @xmath62 whenever @xmath63 and @xmath49 . if @xmath52 for some @xmath53 , then also holds for @xmath64 and @xmath57 .",
    "if @xmath63 , then both @xmath65 and @xmath66 .",
    "thus @xmath67 which , by , gives .",
    "the case @xmath68 follows from .",
    "[ t : forward ] let @xmath69 be given by . if conditions  [ c : rv ] and [ c : phi ] hold , then for every integer @xmath70 , as @xmath71 , @xmath72 with @xmath73 and @xmath74{0.90\\textwidth } \\begin{itemize } \\item[(i ) ] $ y , m_0 , { \\varepsilon}_1 , { \\varepsilon}_2 , \\ldots$ are independent with $ { \\varepsilon}_t$ as in \\eqref{e : mc:2}(i ) ; \\item[(ii ) ] $ { \\mathrm{p}}(y > y ) = y^{-\\alpha}$ for $ y \\geq 1 $ ; \\item[(iii ) ] $ \\mathcal{l}(m_0)=\\upsilon$. \\end{itemize } \\end{minipage}}\\ ] ] we call @xmath75 the _ forward tail chain of _ @xmath76 .",
    "the argument is by induction on @xmath5 .",
    "the case @xmath77 is a straightforward consequence of condition  [ c : rv ] .",
    "so let @xmath5 be a positive integer and let @xmath78 be bounded and continuous .",
    "we have to show that @xmath79      = { \\mathrm{e } } [ f(y , m_0 , \\ldots , m_t ) ] .\\ ] ] by , if @xmath80 , @xmath81 hence , @xmath82      } \\\\      & = &      { \\mathrm{e}}\\biggl [      g_x \\biggl ( \\frac{\\|x_0\\|}{x } , \\frac{x_0}{\\|x_0\\| } , \\ldots , \\frac{x_{t-1}}{\\|x_0\\| } \\biggr )      \\ , \\biggl| \\ , \\|x_0\\| > x      \\biggr ]       \\nonumber\\end{aligned}\\ ] ] where @xmath83\\ ] ] ( note that the expectation is taken with respect to the distribution of @xmath84 ) . define @xmath85.\\ ] ] by , @xmath86 = { \\mathrm{e } } [ g(y , m_0 , \\ldots , m_{t-1 } ) ] .\\ ] ] in view of the identities and , the limit relation in will follow if we can show that @xmath87      \\to { \\mathrm{e } } [ g(y , m_0 , \\ldots , m_{t-1 } ) ] \\ ] ] as @xmath71 . in turn , will follow from the induction hypothesis and an extension of the continuous mapping theorem ( * ? ? ?",
    "* theorem  18.11 ) provided @xmath88 whenever @xmath89 and @xmath90 as @xmath71 with @xmath91 ranging over a set @xmath92 with @xmath93 . from the definitions of @xmath94 and @xmath95 in and , respectively , equation   is implied by @xmath96 whenever @xmath97 and where @xmath98 and @xmath99 range over sets that receive probability one by the distributions of @xmath100 and @xmath101 , respectively . since is ensured by condition  [ c : phi ] and lemma [ l : generalphi ] , the statement follows .",
    "from now on , the process @xmath4 in and is assumed to be strictly stationary .",
    "a necessary and sufficient condition for stationarity is that @xmath102 it may be highly non - trivial to find the law for @xmath6 that solves .",
    "but even when the stationary distribution does not admit an explicit expression , its tails may in many cases be found by the theory developed originally in @xcite , @xcite and @xcite . for recent results on specific models ,",
    "see for instance @xcite , @xcite , @xcite , @xcite , and @xcite .",
    "if the process @xmath4 is stationary , then by kolmogorov s extension theorem and changing the probability space if necessary , the range of @xmath5 can without loss of generality be assumed to be the set of all integers , @xmath36 ; recall that we are interested in distributional properties only , not in almost sure properties , for instance .",
    "our aim is to extend theorem  [ t : forward ] and find the asymptotic distribution of the random vector @xmath10 conditionally on @xmath103 as @xmath104 , for all integer @xmath105 and @xmath5 ( corollary  [ cor : spectralisbftc ] ) . according to ( * ? ? ?",
    "* theorem  2.1 ) , if the underlying process is stationary , the existence of a forward tail process @xmath106 is enough to guarantee the existence of the tail process as a whole ( @xmath107 ) .",
    "[ p : bs09:2.1 ] let @xmath108 be a stationary markov chain with distribution determined by , and . if conditions  [ c : rv ] and [ c : phi ] hold , then there exists a process @xmath109 such that @xmath110 for all integer @xmath111 .",
    "this follows from our theorem [ t : forward ] and theorem 2.1 in @xcite , combined with a continuous mapping argument .",
    "we call the process @xmath109 the _ spectral ( tail ) process _ of @xmath112 , in accordance with the definition of the process @xmath113 in @xcite",
    ".    @xcite also state an important property of the limiting process .",
    "[ p : bs09:3.1 ] let @xmath108 be a stationary markov chain with distribution determined by , and and spectral process @xmath109 .",
    "then for all @xmath111 and for all bounded and measurable @xmath114 satisfying @xmath115 whenever @xmath116 , @xmath117= e\\left[f\\left(\\frac{m_0}{\\|m_s\\| } , \\ldots , \\frac{m_{s+t}}{\\|m_s\\| } \\right ) \\|m_s\\|^\\alpha{\\boldsymbol{1}}_{\\{m_s \\neq 0\\ } } \\right].\\ ] ]    it follows directly from our proposition [ p : bs09:2.1 ] and theorem 3.1 in @xcite that @xmath118= e\\left[f\\left(\\frac{m_{-s}}{\\|m_i\\| } , \\ldots , \\frac{m_{t}}{\\|m_i\\| } \\right ) \\|m_i\\|^\\alpha{\\boldsymbol{1}}_{\\{m_i \\neq 0\\ } } \\right].\\ ] ] holds for all bounded and continuous @xmath119 satisfying @xmath115 whenever @xmath120 ( instead of @xmath116 ) and all @xmath121 . we have added the indicator function on the right - hand side for greater clarity .",
    "let @xmath122 and @xmath123 be as in the statement of the proposition . apply to the indices @xmath124 to arrive at ; note that @xmath125 and that @xmath126 as soon as @xmath127 .",
    "thus , for functions @xmath123 which are additionally assumed to be continuous , the statement follows directly .    for the general case , set for abbreviation @xmath128 .",
    "furthermore , let @xmath129 denote the restriction of the law of @xmath130 to @xmath131 and let @xmath132 denote the measure on @xmath131 defined by @xmath133\\ ] ] for all bounded and continuous @xmath123 on @xmath131 .",
    "in order to show for general bounded and measurable @xmath123 with @xmath115 if @xmath116 it suffices to show that @xmath129 and @xmath132 coincide .",
    "the closed sets of @xmath134 which are bounded away from @xmath135 are a @xmath136-system generating @xmath137 .",
    "indicator functions of closed sets @xmath21 can be written as pointwise limits of continuous functions with values in @xmath138 $ ] .",
    "if @xmath21 is bounded away from @xmath135 we can choose these approximating continuous functions in such a way that they vanish on @xmath135 .",
    "thus , by dominated convergence @xmath139 for all sets @xmath21 of a generating @xmath136-system and therefore @xmath140 on the borel sets of @xmath131 ( * ? ? ?",
    "* theorem  2.2 ) , which finishes the proof .    by lemma  2.2 in @xcite",
    "it follows that the distribution of @xmath141 is uniquely determined by the distribution of @xmath142 ( and @xmath42 ) .",
    "we will use to analyze the structure of the spectral process with a special focus on the backward process @xmath143 . at the heart of the connection between the forward and backward processes",
    "is an adjoint relation between the laws of @xmath144 and @xmath145 , studied next .",
    "a special case of the equality is @xmath146= { \\mathrm{e}}\\left[f\\left(\\frac{m_0}{\\|m_1\\| } , \\frac{m_1}{\\|m_1\\| } \\right ) \\|m_1\\|^\\alpha{\\boldsymbol{1}}_{\\{m_1 \\neq 0\\ } } \\right]\\ ] ] for all @xmath147 satisfying @xmath148 whenever @xmath120 .",
    "starting from a given distribution of @xmath149 we will in the following characterize the distributions of @xmath150 which satisfy .",
    "for such an adjoint distribution to exist , the distribution @xmath149 can not be chosen arbitrarily from the distributions on @xmath151 .",
    "we therefore introduce the following set of `` admissible '' distributions .",
    "[ def : admissible ] for @xmath152 , let @xmath153 be the set of all probability measures @xmath154 on @xmath155 such that @xmath156 for every borel set @xmath44 .",
    "we call @xmath157 the set of _ admissible distributions _ for @xmath42",
    ".    note that for @xmath158 we have @xmath159 we now make the already mentioned notion of an `` adjoint '' distribution more concise .",
    "[ def : adjoint ] for @xmath158 , define a signed borel measure @xmath160 on @xmath155 by @xmath161 for borel sets @xmath44 and @xmath162 .",
    "we call @xmath160 the _ adjoint measure of @xmath154 in @xmath157_.    [ lem : adjoint ] let @xmath158 and let @xmath160 be as in definition  [ def : adjoint ] .",
    "a.   @xmath160 is a probability measure and the marginal distributions induced by @xmath154 and @xmath160 on @xmath33 are the same .",
    "b.   for every measurable function @xmath163 , @xmath164 in the sense that if one integral exists , then so does the other , and they are the same .",
    "c.   @xmath165 .",
    "d.   @xmath166 .",
    "\\(i ) by , @xmath160 is a nonnegative borel measure .",
    "let @xmath167 be a borel subset of @xmath33 .",
    "we have @xmath168 applying to the first term on the right - hand side and applying with @xmath169 to the second term on the right - hand side yields @xmath170 it follows that @xmath160 is a probability measure ( take @xmath171 ) on @xmath155 inducing the same marginal distribution on @xmath33 as @xmath154 .",
    "\\(ii ) by , equation   holds for indicator functions @xmath172 of borel subsets @xmath29 of @xmath173 .",
    "the extension to general bounded , measurable functions follows from the definition of the integral .",
    "\\(iii ) let @xmath167 be a borel subset of @xmath33 .",
    "we will apply to the function @xmath174 we find @xmath175 where we applied ( i ) in the last step .",
    "\\(iv ) let @xmath176 .",
    "we already know that @xmath177 is a probability measure on @xmath155 , that @xmath178 , and that the marginal induced by @xmath177 on @xmath33 coincides with the one of @xmath160 and thus with the one of @xmath154 .",
    "let @xmath123 be a nonnegative , measurable function on @xmath179 .",
    "define the nonnegative , measurable function @xmath95 on @xmath173 by @xmath180 we have @xmath181 by applied first to @xmath177 and @xmath123 and then to @xmath160 and @xmath95 , we have @xmath182 where we used in the last step .",
    "it follows that @xmath177 and @xmath154 coincide on @xmath173 .",
    "as @xmath177 and @xmath154 also induce the same marginal distributions on @xmath33 , it follows that they must also coincide on @xmath183 . as a consequence , @xmath177 is equal to @xmath154 .",
    "the next lemma shows that the class @xmath157 and the adjoint relation on it arise naturally in the context of regularly varying markov chains .",
    "[ l : m1 ] let @xmath108 be a stationary markov chain with distribution determined by , and .",
    "if conditions  [ c : rv ] and [ c : phi ] hold , then @xmath184 belongs to @xmath157 and its adjoint is equal to @xmath185 .    to prove admissibility",
    ", we have to show that @xmath186 \\le { \\mathrm{p } } ( m_0 \\in s ) \\ ] ] for every borel set @xmath44 .",
    "let @xmath123 be a bounded , nonnegative and continuous function on @xmath33 .",
    "we will show that @xmath187 \\le { \\mathrm{e } } [ f(m_0 ) ] .\\ ] ] equation   implies for closed sets @xmath167 because the indicator function of a closed set @xmath167 can be written as the pointwise limit of a decreasing sequence of continuous functions taking values in the interval @xmath188 $ ] . from this we arrive at for an arbitrary borel set @xmath167 by invoking an increasing sequence of closed sets @xmath189 contained in @xmath167 such that @xmath190 $ ] and @xmath191 converge to @xmath192 $ ] and @xmath193 respectively ; see for instance theorem  1.1 on p.  7 in @xcite .",
    "let @xmath194 .",
    "by stationarity of @xmath195 and by definition of the spectral process @xmath196 , we have @xmath197    & = \\lim_{x \\to \\infty } { \\mathrm{e } } [ f ( x_1 / { \\|x_1\\| } ) \\mid { \\|x_1\\| } > x ] \\\\    & \\ge \\limsup_{x \\to \\infty }     { \\mathrm{e } } [ { \\boldsymbol{1 } } _ { \\ { { \\|x_0\\| } > \\delta",
    "x \\ } } \\ , f ( x_1 / { \\|x_1\\| } ) \\mid { \\|x_1\\| } > x ] \\\\    & = \\limsup_{x \\to \\infty }     \\frac{{\\mathrm{p } } [ { \\|x_0\\| } > \\delta x ] } { { \\mathrm{p } } [ { \\|x_1\\| } > x ] } \\ , { \\mathrm{e } } [ f ( x_1 / { \\|x_1\\| } ) \\ , { \\boldsymbol{1 } } _ { \\ { { \\|x_1\\| } > x \\ } } \\mid { \\|x_0\\| } > \\delta x ] \\\\    & = \\delta^{-\\alpha } { \\mathrm{e } } [ f ( m_1 / { \\|m_1\\| } ) \\ , { \\boldsymbol{1 } } _ { \\ { y { \\|m_1\\| } > \\delta^{-1 } \\ } } ] .\\end{aligned}\\ ] ] in the last line , @xmath198 is a pareto(@xmath199 ) random variable , independent of @xmath200 .",
    "as @xmath201 by continuity of the law of @xmath198 , the last equality in the above display follows from the continuous mapping theorem",
    ".    since the distribution of @xmath202 is uniform on the interval @xmath203 , we have @xmath204 & = & \\delta^{-\\alpha } { \\mathrm{e } } [ f ( m_1 / { \\|m_1\\| } ) \\ , { \\boldsymbol{1 } } _ { \\ { \\delta^\\alpha { \\|m_1\\|}^\\alpha > y^{-\\alpha } \\ } } ] \\\\    & = & \\delta^{-\\alpha } { \\mathrm{e}}[{\\mathrm{e } } [ f ( m_1 / { \\|m_1\\| } ) \\ , { \\boldsymbol{1 } } _ { \\ { \\delta^\\alpha { \\|m_1\\|}^\\alpha > y^{-\\alpha } \\ } } |m_1 ] ] \\\\    & = & \\delta^{-\\alpha } { \\mathrm{e } } [ f ( m_1 / { \\|m_1\\| } ) \\ , \\min ( \\delta^\\alpha { \\|m_1\\|}^\\alpha , 1 ) ] \\\\    & = & { \\mathrm{e } } [ f(m_1 / { \\|m_1\\| } ) \\ , \\min ( { \\|m_1\\|}^\\alpha , \\delta^{-\\alpha } ) ] .\\end{aligned}\\ ] ] we obtain that for every @xmath194 , @xmath205 \\ge { \\mathrm{e } } [ f(m_1 / { \\|m_1\\| } ) \\ , \\min ( { \\|m_1\\|}^\\alpha , \\delta^{-\\alpha } ) ] .\\ ] ]",
    "take the limit as @xmath206 and apply the monotone convergence theorem to obtain .",
    "next we show that the adjoint of @xmath184 is equal to @xmath185 .",
    "we have to check the two equations @xmath207 , \\\\ \\label{eq : lemm2:2 }    { \\mathrm{p}}((m_0,m_{-1 } ) \\in e )    & = { \\mathrm{e}}[{\\boldsymbol{1}}_{\\mathbb{r}^d \\setminus\\{0\\}}(m_1){\\boldsymbol{1}}_e(m_1/\\|m_1\\|,m_0/\\|m_1\\|)\\|m_1\\|^\\alpha],\\end{aligned}\\ ] ] for all borel sets @xmath44 and @xmath208 . since the first component @xmath209 is common to both laws , it is sufficient to check only the second equation ,",
    ".    set @xmath210 on @xmath211 .",
    "note that @xmath212 .",
    "apply equation to @xmath123 : @xmath213 \\\\    & = { \\mathrm{e}}[f(m_0/\\|m_1\\|,m_1/\\|m_1\\|)\\|m_1\\|^\\alpha{\\boldsymbol{1}}_{\\{m_1 \\neq 0\\ } } ] \\\\    & = { \\mathrm{e}}[{\\boldsymbol{1}}_{\\mathbb{r}^d \\setminus\\{0\\}}(m_1){\\boldsymbol{1}}_e(m_1/\\|m_1\\|,m_0/\\|m_1\\|)\\|m_1\\|^\\alpha],\\end{aligned}\\ ] ] which gives , as required .",
    "[ partsimple ] the determination of the adjoint measure is particularly simple for probability measures @xmath154 such that @xmath214 since in this case @xmath215 by and @xmath160 is completely described by .",
    "[ selfadjoint ] we call a measure @xmath158 _ self - adjoint _ if @xmath216 .",
    "an example for such a distribution in the case of @xmath217 and @xmath218 is given by @xmath219 , where @xmath220 for standard normally distributed @xmath23 ( cf .",
    "example  3.2 in @xcite ) .",
    "definition  [ def : adjoint ] and lemma  [ lem : adjoint ] generalize proposition  3.1 in @xcite to the multivariate case .",
    "examples  3.23.4 in the latter reference illustrate the adjoint relation for laws on @xmath221 .",
    "we conclude the section with a multivariate example .      at the end of this section ,",
    "we give some examples which shall help to illustrate the connection between a probability measure and its adjoint measure .",
    "we will start with one - dimensional examples .",
    "the case @xmath217 is special since @xmath222 and the first marginal distribution of measures @xmath158 is necessarily discrete , which simplifies definitions and analysis . before we start with more specific examples , we will state a general principle , which often helps to determine the adjoint distribution in the one - dimensional case .",
    "let @xmath42 and @xmath223 be a probability measure on @xmath224",
    ". then for @xmath160 the relation @xmath225 holds for all @xmath226 and measurable functions @xmath123 .",
    "let @xmath226 and @xmath123 be a measurable function .",
    "then @xmath227 where , in the last equation , we have applied and to the first and second summand respectively . noting that @xmath228 gives .",
    "equation may sometimes be more convenient if written with the help of random variables . if @xmath229 and @xmath230 then reduces to @xmath231={\\mathrm{e}}[f(x/|y|)(\\sigma y)_+^\\alpha]+f(0)\\left\\{{\\mathrm{p}}(x=\\sigma)-{\\mathrm{e}}[(\\sigma y)_+^\\alpha]\\right\\}\\ ] ] for @xmath226 and measurable functions @xmath123 .",
    "[ ex : adjoint : arch ] let @xmath232 where @xmath233 and @xmath234 are independent ( univariate ) random variables with @xmath235 and @xmath236 \\leq 1 $ ]",
    ". for @xmath217 , equation reduces to @xmath237 for @xmath226 . for our example , this inequality holds since for @xmath226 : @xmath238=\\frac{1}{2}\\cdot{\\mathrm{e}}[(\\sigma z)_+^\\alpha]+\\frac{1}{2}\\cdot{\\mathrm{e}}[(\\sigma z)_-^\\alpha ] \\\\ & = & \\label{e : ex3.1:admissible } \\frac{1}{2}\\cdot{\\mathrm{e}}[|z|^\\alpha ] \\leq \\frac{1}{2}=p(\\{\\sigma\\ } \\times \\mathbb{r}).\\end{aligned}\\ ] ] therefore , @xmath158 .",
    "we will show that the adjoint measure @xmath160 shares the multiplicative structure of @xmath154 .",
    "let therefore @xmath239 and @xmath240 be two independent random variables with @xmath241 and @xmath242= { \\mathrm{e}}[f(1/z)|z|^\\alpha{\\boldsymbol{1}}_{\\{z \\neq 0\\}}]+f(0)(1-{\\mathrm{e}}[|z|^\\alpha])\\ ] ] for all measurable functions @xmath123 .",
    "for @xmath226 and a measurable function @xmath123",
    "@xmath243=e[{\\boldsymbol{1}}_{\\{\\sigma\\}}(i^\\ast)f(\\sigma z^\\ast)]\\\\ & = & p(i^\\ast = \\sigma)\\left\\{{\\mathrm{e}}[f(\\sigma / z)|z|^\\alpha{\\boldsymbol{1}}_{\\{z \\neq 0\\}}]+f(0)(1-{\\mathrm{e}}[|z|^\\alpha ] ) \\right\\}\\end{aligned}\\ ] ] by . since @xmath244",
    "this is equal to @xmath245+f(0)\\left\\{\\frac{1}{2}-\\frac{1}{2}\\cdot { \\mathrm{e}}[|z|^\\alpha]\\right\\ } \\\\ & = & \\int_{\\{-1,1\\ } \\times \\mathbb{r } \\setminus\\{0\\}}{\\boldsymbol{1}}_{\\{\\sigma\\}}(m/|m|)f\\left(s/|m|\\right)|m|^\\alpha p({\\mathrm{d}s},{\\mathrm{d}m } ) \\\\ & & + f(0)\\left\\{p(\\{\\sigma\\ } \\times \\mathbb{r})- \\int_{\\{-1,1\\ } \\times \\mathbb{r}}(\\sigma m)_+^\\alpha p({\\mathrm{d}s } , { \\mathrm{d}m})\\right\\}\\\\ & = & \\int_{\\{-1,1\\}\\times\\mathbb{r}}{\\boldsymbol{1}}_{\\{\\sigma\\}}(s^*)f(m^*)p^*({\\mathrm{d}s}^*,{\\mathrm{d}m}^*),\\end{aligned}\\ ] ] where equations and have been used .",
    "thus , @xmath246 @xmath247 @xmath248 .",
    "[ ex : adjoint:1 ] a special case arises for @xmath158 with @xmath249 .",
    "equation implies that @xmath250 , thus @xmath251 for some random variable @xmath234 on @xmath252 with @xmath253 \\leq 1 $ ] .",
    "the adjoint of @xmath154 is @xmath254 where @xmath255 is related to @xmath234 via as in the preceeding example .",
    "some examples of pairs @xmath256 are the following :    * for every @xmath199 , if @xmath257 is concentrated on @xmath258 , then @xmath259 . * if @xmath260 and @xmath234 is a unit exponential random variable , then @xmath261 is the distribution of the reciprocal of the sum of two independent unit exponential random variables . * if @xmath260 and @xmath234 is a lognormal random variable with unit expectation , then @xmath262 .",
    "all examples may be verified by applying to the respective specification of @xmath257 . except for a change of sign ,",
    "the case @xmath263 is similar to the case @xmath249 .",
    "we close the example section with a multivariate example .",
    "again , a multiplicative structure in the admissible distribution helps to simplify the derivation of the adjoint measure .",
    "[ ex : mult:1 ] let @xmath264 and let @xmath154 be the law of @xmath265 with @xmath266 , @xmath267 and @xmath177 independent , @xmath266 taking values in @xmath33 , @xmath267 a positive random variable with @xmath268 = 1 $ ] , and @xmath177 a random orthogonal @xmath269 matrix , that is @xmath270 a.s . ; also assume that the laws of @xmath266 and @xmath271 are the same ( cf .",
    "also example [ ex : kestenrde ] ) .",
    "one verifies easily that @xmath158 and that holds , so that the adjoint law @xmath160 is concentrated on @xmath272 .",
    "it may thus be derived from that for borel sets @xmath44 and @xmath273 , @xmath274.\\ ] ] if we assume in addition that @xmath266 is uniformly distributed on @xmath33 ( which readily implies @xmath275 for any law of @xmath177 ) , then @xmath276&=&{\\mathrm{e}}\\left[\\int_{\\mathbb{r}^{d \\times d } } { \\boldsymbol{1}}_s(qc){\\boldsymbol{1}}_{t}(c)p^q(dq)\\right ] \\\\ & = & { \\mathrm{e}}\\left[\\int_{\\mathbb{r}^{d \\times d } } { \\boldsymbol{1}}_s(c){\\boldsymbol{1}}_{t}(q'c)p^q(dq)\\right ] \\\\ & = & { \\mathrm{e}}[{\\boldsymbol{1}}_s(c){\\boldsymbol{1}}_{t}(q'c)]\\end{aligned}\\ ] ] and it follows from that @xmath160 is the law of @xmath277 , with @xmath278 , @xmath279 and @xmath280 independent , @xmath281 , @xmath282 , and the law of @xmath283 given by @xmath284 = { \\mathrm{e}}[f(1/r ) \\",
    ", r^\\alpha]$ ] for measurable functions @xmath123 on @xmath285 .",
    "[ ex : mult:1 ] let @xmath42 and @xmath154 be the law of @xmath286 , where @xmath287 is of the form @xmath288 , with random variable @xmath289 and @xmath267 is a random rotation matrix , i.e. @xmath290 for all @xmath291 .",
    "let @xmath292 and @xmath267 be mutually independent .",
    "assume furthermore that @xmath293<1 $ ] and @xmath293{\\mathrm{p}}(ri \\in s)\\leq { \\mathrm{p}}(i \\in s)$ ] for all borel sets @xmath44 ( cf .  also example [ ex : kestenrde ] for the latter assumption ) .",
    "in this case @xmath294={\\mathrm{e}}[y^\\alpha]p(ri \\in s)\\leq p(s \\times \\mathbb{r}^d),\\end{aligned}\\ ] ]    so @xmath158 .",
    "now , for borel sets @xmath44 and @xmath295 it follows that @xmath296 \\\\   & = & { \\mathrm{e}}[{\\boldsymbol{1}}_s(ri){\\boldsymbol{1}}_{t}(i / y)y^\\alpha]+ { \\boldsymbol{1}}_t(0)({\\mathrm{p}}(i \\in s)-{\\mathrm{e}}[y^\\alpha]{\\mathrm{p}}(ri \\in s ) ) .",
    "\\end{aligned}\\ ] ] if we assume that @xmath293=1 $ ] and @xmath297 for all borel sets @xmath298 ( again , cf .",
    "example [ ex : kestenrde ] for this assumptions ) then @xmath299.\\ ] ] being a rotation matrix , @xmath267 is almost surely invertible and @xmath300 implies that @xmath301 with @xmath241 , @xmath302 and @xmath303=e[f(1/y){\\boldsymbol{1}}_{(0 , \\infty)}(y)y^\\alpha]$ ] for all measurable functions @xmath123 with @xmath304 being pairwise independent .",
    "in this section , we will analyze a certain class of discrete - time processes which are constructed from a pair of adjoint distributions .",
    "we will see that this class of processes fulfills equation for all @xmath305 with @xmath306 .",
    "[ d : bftc ] a @xmath307-dimensional discrete - time process @xmath196 is called a _ back - and - forth tail chain _ with index @xmath42 , notation @xmath308 , if the following properties hold :    a.   @xmath184 and @xmath185 belong to @xmath157 and are adjoint ; b.   the forward process @xmath309 is a markov chain with respect to the filtration @xmath310 , @xmath311 , and the markov kernel satisfies @xmath312 c.   the backward process @xmath313 is a markov chain with respect to the filtration @xmath314 , @xmath311 , and the markov kernel satisfies @xmath315    clearly , @xmath316 is a @xmath308 if and only if @xmath317 is a @xmath308 .",
    "the distribution of a bftc(@xmath199 ) is completely determined by an admissible law of @xmath144 ( and @xmath42 ) .",
    "the fact that the distributions @xmath318 and @xmath319 are adjoint in @xmath157 implies that for every measurable function @xmath320 such that @xmath321 for all @xmath53 , we have @xmath322 \\nonumber    & = \\int _ { \\mathbb{s}^{d-1 } \\times ( { \\mathbb{r}}^d \\times \\ { 0 \\ } ) } f ( m , s ) \\ , p^\\ast({\\mathrm{d}s } , { \\mathrm{d}m } )",
    "\\nonumber \\\\     & = \\int _ { \\mathbb{s}^{d-1 } \\times ( { \\mathbb{r}}^d \\times \\ { 0 \\ } ) } f ( s / { \\|m\\| } , m / { \\|m\\| } ) \\ , { \\|m\\|}^\\alpha \\ , p({\\mathrm{d}s } , { \\mathrm{d}m } ) \\nonumber \\\\     & = { \\mathrm{e}}\\left [ f \\left ( \\frac{m_0}{{\\|m_1\\| } } , \\frac{m_1}{{\\|m_1\\| } } \\right ) \\ , { \\|m_1\\|}^\\alpha \\ , { \\boldsymbol{1 } } _ { \\ { m_1 \\ne 0 \\ } } \\right ] ,   \\label{eq : bftc : adjoint }   \\end{aligned}\\ ] ] in the sense that if one expectation exists , then so does the other , the two expectations being equal .",
    "this corresponds to equation which originally motivated the definition of an adjoint distribution .",
    "the above formula is the special case @xmath323 and @xmath77 of the following result .",
    "[ p : bftc ] let @xmath196 be a @xmath308",
    ". for all integer @xmath324 and for all measurable functions @xmath325 vanishing on @xmath326 , the @xmath327 numbers @xmath328 , \\qquad    i = 0 , \\ldots , s,\\ ] ] are all the same , in the sense that if one integral exists , then they all exist and they are equal .    for @xmath329",
    "there is nothing to prove , so assume that @xmath330 .",
    "by definition of the integral , it is sufficient to consider the case where @xmath123 is nonnegative , in which case the expectations in are always well - defined , possibly equal to infinity .",
    "_ reduction to the case @xmath331 .",
    "_ suppose first that we can show that the numbers corresponding to @xmath332 and @xmath333 in are equal , that is ( note that @xmath334 ) , @xmath335     = { \\mathrm{e}}\\biggl [ f \\biggl ( \\frac{m_{-s+1}}{{\\|m_1\\| } } , \\ldots , \\frac{m_{t+1}}{{\\|m_1\\| } } \\biggr ) \\ , { \\|m_1\\|}^\\alpha \\ , { \\boldsymbol{1 } } _ { \\ { m_1 \\ne 0 \\ } } \\biggr].\\ ] ] take arbitrary @xmath336 .",
    "note that @xmath337    = { \\mathrm{e } } [ g ( m_{-s+i } , \\ldots , m_{t+i } ) ] \\ ] ] for a measurable function @xmath338 with that vanishes as soon as its first @xmath307-tuple of arguments is zero . by applied to @xmath339 and @xmath340",
    ", we find @xmath341    = { \\mathrm{e}}\\biggl [ g \\biggl ( \\frac{m_{-s+i+1}}{{\\|m_1\\| } } , \\ldots , \\frac{m_{t+i+1}}{{\\|m_1\\| } } \\biggr ) \\ , { \\|m_1\\|}^\\alpha \\ , { \\boldsymbol{1 } } _ { \\ { m_1 \\ne 0 \\ } } \\biggr].\\ ] ] by definition of @xmath95 , if @xmath342 , then @xmath343 combine the previous three displays to see that @xmath344 \\\\",
    "= { \\mathrm{e}}\\biggl [ f \\biggl ( \\frac{m_{-s+i+1}}{{\\|m_{i+1}\\| } } , \\ldots , \\frac{m_{t+i+1}}{{\\|m_{i+1}\\| } } \\biggr ) \\ , { \\|m_{i+1}\\|}^\\alpha \\ , { \\boldsymbol{1 } } _ { \\ { m_1 \\ne 0 , m_{i+1 } \\ne 0 \\ } } \\biggr].\\end{gathered}\\ ] ] by definition of the forward chain @xmath345 , we have @xmath346 as soon as @xmath347 . as a consequence , we may the suppress the event @xmath348 in the indicator function on the right - hand side , and thus @xmath344 \\\\",
    "= { \\mathrm{e}}\\biggl [ f \\biggl ( \\frac{m_{-s+i+1}}{{\\|m_{i+1}\\| } } , \\ldots , \\frac{m_{t+i+1}}{{\\|m_{i+1}\\| } } \\biggr ) \\ , { \\|m_{i+1}\\|}^\\alpha \\ , { \\boldsymbol{1 } } _ { \\ { m_{i+1 } \\ne 0 \\ } } \\biggr].\\end{gathered}\\ ] ] we conclude that in order to show , it is enough to show .",
    "we will show by induction on @xmath330",
    ".    _ proof of if @xmath323 .",
    "_ we have to show that @xmath349     = { \\mathrm{e}}\\biggl [ f \\biggl ( \\frac{m_0}{{\\|m_1\\| } } , \\ldots , \\frac{m_{t+1}}{{\\|m_1\\| } } \\biggr ) \\ , { \\|m_1\\|}^\\alpha \\ , { \\boldsymbol{1 } } _ { \\ { m_1 \\ne 0 \\ } } \\biggr].\\ ] ] we will proceed by induction on @xmath311 .    the case @xmath77 is nothing more than the adjoint relation between the laws of @xmath149 and @xmath350 , see .",
    "let @xmath351 and let be fulfilled for @xmath352 . by the markov property , @xmath353    = { \\mathrm{e } } [ g ( m_{-1 } , \\ldots , m_{t-1 } ) ] \\ ] ] with @xmath354 as @xmath355 , we can apply the induction hypothesis , yielding @xmath356    = { \\mathrm{e } } [ g ( m_0 / { \\|m_1\\| } , \\ldots , m_t / { \\|m_1\\| } ) \\ , { \\|m_1\\|}^\\alpha \\ , { \\boldsymbol{1 } } _ { \\ { m_1 \\ne 0 \\ } } ] .\\ ] ] the defining property of a @xmath357 implies that for every @xmath358 , for every integer @xmath359 and for every nonnegative , measurable function @xmath360 on @xmath361 , @xmath362    = \\begin{cases } h(0 ) & \\text{if $ m = 0 $ , } \\\\ { \\mathrm{e } } [ h ( { \\|m\\| } m_1 ) \\mid m_0 = m / { \\|m\\| } ] & \\text{if $ m \\ne 0 $ , } \\end{cases}\\ ] ] the right - hand side not depending on the scaling constant @xmath363 nor on the time index @xmath364 .",
    "it follows that if @xmath365 , @xmath366 \\\\    & = { \\mathrm{e } } [ f ( m_0 / { \\|m_1\\| } , \\ldots , m_t / { \\|m_1\\| } , m_{t+1 } / { \\|m_1\\| } ) \\mid m_t = m_t ] .\\end{aligned}\\ ] ] we find that , on the event @xmath367 , by the markov property , @xmath368.\\end{gathered}\\ ] ] we can conclude that @xmath369    } \\\\    & = { \\mathrm{e } } [ g ( m_{-1 } , \\ldots , m_{t-1 } ) ] \\\\    & = { \\mathrm{e } } [ g ( m_0 / { \\|m_1\\| } , \\ldots , m_t / { \\|m_1\\| } ) \\ , { \\|m_1\\|}^\\alpha \\ , { \\boldsymbol{1 } } _ { \\ { m_1 \\ne 0 \\ } } ] \\\\    & = { \\mathrm{e } } [ f ( m_0 / { \\|m_1\\| } , \\ldots , m_t / { \\|m_1\\| } , m_{t+1 } / { \\|m_1\\| } ) \\ , { \\|m_1\\|}^\\alpha \\ , { \\boldsymbol{1 } } _ { \\ { m_1 \\ne 0 \\ } } ] , \\end{aligned}\\ ] ] as required .",
    "_ proof of for general @xmath330 . _",
    "the case @xmath323 was treated above .",
    "so let @xmath370 . by the markov property , we have @xmath371 = { \\mathrm{e } } [ g ( m_{-s+1 } , \\ldots , m_t ) ] \\ ] ] with @xmath372 a nonnegative , measurable function defined by @xmath373 conditionally on @xmath374 , we have @xmath375 , and thus @xmath376 too .",
    "it follows that @xmath377 . by the induction hypothesis",
    ", we therefore have @xmath378    = { \\mathrm{e } } [ g ( m_{-s+2 } / { \\|m_1\\| } , \\ldots , m_{t+1 } / { \\|m_1\\| } ) \\ , { \\|m_1\\|}^\\alpha \\ , { \\boldsymbol{1 } } _ { \\ { m_1 \\ne 0 \\ } } ] .\\ ] ] as for the forward chain in , we have for every nonnegative , measurable function @xmath360 on @xmath361 and every @xmath379 , @xmath380    = \\begin{cases } h(0 ) & \\text{if $ m = 0 $ , } \\\\ { \\mathrm{e } } [ h ( { \\|m\\| } m_{-1 } ) \\mid m_0 = m / { \\|m\\| } ] & \\text{if $ m \\ne 0 $ , } \\end{cases}\\ ] ] the right - hand side not depending on the scaling constant @xmath358 nor on the time index @xmath381 .",
    "it follows that for @xmath365 , we have @xmath382 \\\\    & = { \\mathrm{e } } [ f ( m_{-s+1 } / { \\|m_1\\| } , m_{-s+2 } / { \\|m_1\\| } , \\ldots , m_{t+1 } / { \\|m_1\\| } ) \\mid m_{-s+2 } = m_{-s+2 } ] .\\end{aligned}\\ ] ] invoking the markov property again , we conclude that @xmath383    & = { \\mathrm{e } } [ g ( m_{-s+1 } , \\ldots , m_t ) ] \\\\    & = { \\mathrm{e } } [ g ( m_{-s+2 } / { \\|m_1\\| } , \\ldots , m_{t+1 } / { \\|m_1\\| } ) \\ , { \\|m_1\\|}^\\alpha \\ , { \\boldsymbol{1 } } _ { \\ { m_1 \\ne 0 \\ } } ] \\\\    & = { \\mathrm{e } } [ f ( m_{-s+1 } / { \\|m_1\\| } , \\ldots , m_{t+1 } / { \\|m_1\\| } ) \\ , { \\|m_1\\|}^\\alpha \\ , { \\boldsymbol{1 } } _ { \\ { m_1 \\ne 0 \\ } } ] , \\end{aligned}\\ ] ] as required .",
    "this concludes the proof of proposition [ p : bftc ] .",
    "the following proposition connects bftcs and spectral processes .",
    "[ p : bftcisspectral ] let @xmath384 be an @xmath0-valued process and let @xmath385 be an @xmath0-valued bftc(@xmath386 . if @xmath387 for all @xmath70 and if @xmath388= { \\mathrm{e}}\\left[f\\left(\\frac{y_0}{\\|y_s\\| } , \\ldots , \\frac{y_{s+t}}{\\|y_s\\| } \\right ) \\|y_s\\|^\\alpha{\\boldsymbol{1}}_{\\{y_s \\neq 0\\ } } \\right]\\ ] ] for all @xmath111 and for all bounded and measurable @xmath114 satisfying @xmath115 whenever @xmath116 , then @xmath389 for all @xmath111 .",
    "the proof relies on the fact that both the process @xmath390 which satisfies and the bftc(@xmath199 ) are uniquely determined by their forward process .",
    "our proof is by induction on @xmath105 . for @xmath391 ,",
    "equation is equal to the assumption for all @xmath70 . for the induction step ,",
    "assume that holds for a fixed value of @xmath392 and all @xmath70 .",
    "let @xmath114 be a bounded continuous function .",
    "write @xmath393 with @xmath394 @xmath395 and note that @xmath396 , while the value of @xmath397 does not depend on the first coordinate of the argument . then @xmath398\\\\ & = & { \\mathrm{e}}[f_1(y_{-s } , \\dots , y_t)]+{\\mathrm{e}}[f_2(y_{-s } , \\dots , y_t ) ] \\\\ & = & { \\mathrm{e}}[f_1(y_{-s } , \\dots , y_{t})]+ { \\mathrm{e}}\\left[f_2\\left(\\frac{y_0}{\\|y_s\\| } , \\ldots , \\frac{y_{s+t}}{\\|y_s\\|}\\right ) \\|y_s\\|^\\alpha{\\boldsymbol{1}}_{\\{y_s \\neq 0\\ } } \\right ] \\\\ & = & { \\mathrm{e}}[f_1(m_{-s } , \\dots , m_{t})]+ { \\mathrm{e}}\\left[f_2\\left(\\frac{m_0}{\\|m_s\\| } , \\ldots , \\frac{m_{s+t}}{\\|m_s\\|}\\right ) \\|m_s\\|^\\alpha{\\boldsymbol{1}}_{\\{m_s \\neq 0\\ } } \\right ] , \\ ] ] where both the induction hypothesis and equations and have been used . since @xmath109 is a bftc(@xmath199 ) , we may apply proposition [ p : bftc ] for @xmath399 and @xmath400 ( note that @xmath334 ) , so that the above expression is equal to @xmath401 + { \\mathrm{e}}\\left[f_2\\left(m_{-s } , \\ldots , m_{t}\\right)\\right ] = { \\mathrm{e}}[f(m_{-s } , \\dots , m_{t})],\\ ] ] which finishes the induction step and the proof .",
    "proposition [ p : bftcisspectral ] can be read in the following way : every spectral process @xmath385 with a forward process ( meaning : @xmath402 ) which has a bftc@xmath403 structure , automatically has a bftc(@xmath199)-backward - distribution as well .",
    "this means that a markovian structure in the forward spectral process ( which may also arise in settings where the underlying process is non - markovian ) is enough to secure a markovian structure of the backward spectral process as well .",
    "[ cor : spectralisbftc ] let @xmath108 be a stationary markov chain with distribution determined by , and .",
    "then the corresponding spectral process @xmath385 is a bftc@xmath403 .",
    "we call @xmath404 the _ backward tail chain of _ @xmath405 and @xmath109 the _ tail chain of _ @xmath405 .",
    "the existence of a corresponding spectral process follows from proposition [ p : bs09:2.1 ] .",
    "furthermore , it follows from theorem [ t : forward ] that the forward process @xmath402 is equal in law to the forward process of a bftc@xmath403 . by proposition [ p : bftcisspectral ]",
    "the statement follows .    since the forward and backward tail chain of a process @xmath406",
    "are uniquely determined by the laws of @xmath149 and @xmath350 , respectively , it follows that the backward tail chain is equal in distribution to the forward tail chain if and only if the law of @xmath149 is self - adjoint ( cf .  remark [ selfadjoint ] ) .",
    "this is for example the case if the process @xmath112 fulfills the assumptions of corollary [ cor : spectralisbftc ] and is in addition a time reversible markov chain .",
    "more generally , since the existence of a forward tail process ensures joint regular variation of @xmath407 ( cf .  corollary 3.2 in @xcite ) , the resulting limiting spectral measure of the @xmath408-dimensional vector @xmath409 and the law of @xmath144 uniquely determine each other .",
    "therefore , the backward tail chain is equal in distribution to the forward tail chain if and only if the spectral measure of @xmath409 is equal to the spectral measure of @xmath410 . for @xmath217",
    "this simply means that the spectral measure of @xmath411 is symmetric .    in the univariate case ,",
    "bftcs have an additional structure which generalizes a multiplicative random walk in that the distribution of the increment depends on the sign of the process in its current state @xcite .",
    "the random walk structure of the forward tail chain was first observed in @xcite for one - sided extremes and extended to allow for both positive and negative extremes in @xcite .      as was already seen during the examples of the last section",
    ", the one - dimensional case bears some simplifications in the representation of adjoint distributions .",
    "this holds true for the whole bftc as well . in the following",
    ", we will show that in one dimension , the bftc@xmath403 @xmath385 has the remarkable property that both the forward process @xmath402 and the backward process @xmath412 have a simple random walk structure .",
    "let @xmath154 on @xmath413 with @xmath414 and adjoint @xmath415 , and let @xmath385 be a @xmath308 with @xmath416 .",
    "it then follows from definition [ d : bftc](ii)-(iii ) that @xmath417 where @xmath418{0.9\\textwidth } \\begin{itemize } \\item[(i ) ] $ m_0 , a_1 , a_{-1 } , a_2 , a_{-2 } , \\ldots , b_1 , b_{-1 } , b_2 , b_{-2 } , \\ldots$ are independent ; \\item[(ii ) ] $ { \\mathrm{p}}(m_0 = 1 ) = p(\\{1\\}\\times\\mathbb{r } ) = 1 - { \\mathrm{p}}(m_0 = -1)$ ; \\item[(iii ) ] $ { \\mathcal{l}}(a_t ) = { \\mathcal{l}}(a_1)$=${\\mathcal{l}}(m_1|m_0=1)$ , $ { \\mathcal{l}}(a_{-t } ) = { \\mathcal{l}}(a_{-1})={\\mathcal{l}}(m_{-1}|m_0=1)$ , $ { \\mathcal{l}}(b_t ) = { \\mathcal{l}}(b_1)={\\mathcal{l}}(m_1|m_0=-1)$ and $ { \\mathcal{l}}(b_{-t } ) = { \\mathcal{l}}(m_{-1}|m_0=-1)$ for $ t \\geq 1$. \\end{itemize } \\end{minipage}}\\ ] ]    the laws of @xmath419 and @xmath420 in can be expressed in terms of @xmath199 and @xmath154 through : let us therefore first assume that @xmath421 .",
    "for @xmath226 and integrable @xmath123 , @xmath422          & = & { \\mathrm{e}}[f(m_{-1})|m_0=1 ] \\\\          & = & \\displaystyle \\frac{1}{p } { \\mathrm{e}}\\biggl [ f \\biggl ( \\frac{1}{|m_1| } \\biggr ) ( m_1)_+^\\alpha \\biggr ]      +   f(0)\\biggl ( 1 - \\frac{{\\mathrm{e}}[(m_1)_+^\\alpha]}{p } \\biggr ) , \\\\[1ex ]      { \\mathrm{e } } [ f(b_{-1 } ) ]          & = & { \\mathrm{e}}[f(m_{-1})|m_0=-1 ] \\\\      & = & \\displaystyle \\frac{1}{1-p } { \\mathrm{e}}\\biggl [ f \\biggl(-\\frac{1}{|m_1| } \\biggr ) ( m_1)_-^\\alpha \\biggr ]      + f(0)\\biggl ( 1 - \\frac{{\\mathrm{e}}[(m_1)_-^\\alpha]}{1-p } \\biggr ) .",
    "\\end{array}\\ ] ]    on the other hand , if @xmath423 and @xmath424 with adjoint @xmath425 , a process @xmath426 is a @xmath308 if and only if it admits the following distributional representation : @xmath427{rcl }      m_0 & = & 1 , \\\\[1ex ]      m_{\\pm t } & = & \\prod_{i=1}^t a_{\\pm i } , \\qquad \\mbox{for $ t \\geq 1 $ } ,      \\end{array}\\ ] ] where @xmath428{0.90\\textwidth } \\begin{itemize } \\item[(i ) ] $ a_1 , a_{-1 } , a_2 , a_{-2 } , \\ldots$ are independent ; \\item[(ii ) ] $ { \\mathcal{l}}(a_t ) = \\tilde{p}$ and $ { \\mathcal{l}}(a_{-t } ) = \\tilde{p}^\\ast$ for $ t \\geq 1$. \\end{itemize } \\end{minipage}}\\ ] ] the case @xmath429 is similar to the case @xmath423 .",
    "we conclude the paper with some examples of bftcs for multivariate markov processes . for univariate examples , see @xcite .",
    "again , we start with a univariate example .    [ ex : arch ] let @xmath430 and @xmath431 where @xmath432 is euler s constant , and consider the arch(1 ) process @xmath433 where the @xmath434 are i.i.d .",
    "standard normal and @xmath435 is independent of @xmath436 for all @xmath107 . by an application of (",
    "* theorem  5 ) or ( * ? ? ?",
    "* theorem  4.1 ) to the squared series @xmath437 , a stationary solution to exists , and this stationary distribution satisfies condition  [ e : rv ] with @xmath438 and @xmath199 equal to the unique positive solution to the equation @xmath439 = 1 $ ] ; see also @xcite .",
    "condition  [ c : phi ] is easily verified with @xmath440 .",
    "the bftc is given by equations - and can be represented by @xmath441 for @xmath442 , where @xmath443 are independent random variables with @xmath435 standard normal and with the common law of the variables @xmath444 related to the standard normal distribution via @xmath445 = \\lambda^{\\alpha/2 } { \\mathrm{e } } [ f(1 / z_1 ) |z_1|^\\alpha ] , \\ ] ] for @xmath446-integrable functions @xmath123 .    [ ex : kestenrde ] let @xmath447 be i.i.d .  with @xmath448 and @xmath449 .",
    "the stationary distribution and asymptotic behavior of the corresponding random difference equation @xmath450 have been studied initially in the seminal work by @xcite .",
    "let us assume that the distribution of @xmath451 satisfies the technical , but mild assumptions of theorems  a and  b or theorem 6 in @xcite ( where the first two theorems deal with the nonnegative case , i.e.  all components of @xmath452 are nonnegative almost surely , and the last one treats the general case ) .",
    "together with results in @xcite this implies that the stationary distribution of @xmath12 for is multivariate regularly varying in the nonnegative case . in the general case",
    ", multivariate regular variation follows if @xmath453 in @xcite , equation  ( 4.8 ) , is not an integer , cf .",
    "let @xmath41 denote the spectral measure and @xmath42 the index of regular variation of the stationary distribution of @xmath12 .",
    "it can be shown that @xmath454={\\mathrm{e}}[f(c)]\\ ] ] for all bounded , continuous funtions @xmath123 on @xmath33 , where @xmath455 has distribution @xmath41 and @xmath287 is independent of @xmath266 with @xmath456 , cf .",
    "@xcite .    due to",
    "the linear structure of , theorem  [ t : forward ] applies with @xmath457 and @xmath458 where the @xmath459 are i.i.d .  with @xmath460 . in order to find the distribution of the backward tail chain note that remark  [ partsimple ] applies to this example by equation  .",
    "so the law @xmath461 of @xmath462 is given by @xmath463\\ ] ] for all borel sets @xmath464 .",
    "additional assumptions about @xmath465 allow us to simplify this characterization : let us assume that @xmath21 has a multiplicative form like in example  [ ex : mult:1 ] , i.e.  @xmath466 for a positive random variable @xmath267 with @xmath268=1 $ ] and @xmath177 is an orthogonal matrix independent of @xmath267 .",
    "we may additionally assume that @xmath267 has a density on @xmath467 and that the support of the law of @xmath177 is equal to the orthogonal group in dimension @xmath307 .",
    "in this case , the spectral measure @xmath41 is the uniform distribution on @xmath33 ( cf .",
    "@xcite , p.  390 ) , @xmath42 is the index of regular variation and @xmath468={\\mathrm{e}}\\left[f\\left(qc \\right)r^\\alpha \\right]={\\mathrm{e}}\\left[f\\left(qc \\right)\\right]{\\mathrm{e}}[r^\\alpha]={\\mathrm{e}}[f(c)]\\ ] ] holds for all bounded , continuous functions @xmath123 on @xmath33 with @xmath469 . since @xmath275 , all assumptions of example  [ ex : mult:1 ] are met and the adjoint measure @xmath461 is determined by and equal to the law of @xmath470 with @xmath471 independent , @xmath472 , @xmath473 and @xmath474 has density @xmath475 @xmath476 , where @xmath477 denotes the density of @xmath267 . thus ,",
    "both the forward and the backward tail chain have a simple multiplicative structure : @xmath478 with @xmath479 as above and @xmath480 i.i.d . with the same distribution as @xmath481 , all independent of each other and of @xmath482 .",
    "[ heavy - tailedrde ] while the preceding example dealt with random difference equations where the random increment @xmath483 has a relatively light tail [ @xcite assumes that @xmath484 , the following example deals with ar(1 ) processes where the innovations themselve are regularly varying .",
    "let @xmath485 where @xmath21 is a deterministic @xmath486-matrix and @xmath449 , @xmath107 , are i.i.d .  and multivariate regularly varying with index @xmath42 and spectral measure @xmath487 on @xmath33 . for extensions to random but light - tailed random matrices @xmath488 , see for instance @xcite .",
    "if @xmath489 for some positive integer @xmath490 , then has the stationary solution @xmath491 it has been shown in @xcite that in this case the stationary distribution of @xmath12 is multivariate regularly varying as well , with the same index @xmath199 and spectral measure @xmath492 , where @xmath493 and where @xmath494 is the spectral measure of @xmath495 , provided @xmath496 , i.e. @xmath497 for all bounded , continuous functions @xmath123 on @xmath33 ( * ? ?",
    "* example  9.3 ) . the spectral process @xmath498 in proposition  [ p : bs09:2.1 ] is of the form @xmath499 for a random integer @xmath500 with @xmath501 , @xmath502 , and a random vector @xmath503 with distribution @xmath504 for @xmath502 and borel sets @xmath505 .",
    "here , the forward tail chain has a deterministic multiplicative structure with @xmath506 and @xmath507 for @xmath508 .",
    "the backward process is markovian as well , by corollary  [ cor : spectralisbftc ] .",
    "this is also clear if one looks at and notices that @xmath509 if @xmath510 for all @xmath511 .",
    "furthermore , if @xmath512 then @xmath513 contains no more information about @xmath514 than @xmath515 does .",
    "the distribution of @xmath350 is adjoint to the one of @xmath516 . by and since @xmath506",
    ", we find , for every borel set @xmath517 , @xmath518 \\\\    & = \\frac{1}{\\sum_{k = 0}^\\infty c_k }    \\sum_{n \\ge 0 }     \\int_{\\mathbb{s}^{d-1 } }      { \\boldsymbol{1}}_e \\biggl ( \\frac{a^{n+1}s}{\\|a^{n+1}s\\| } , \\ , \\frac{a^n s}{\\|a^{n+1 } s\\| } \\biggr ) \\ ,      \\| a^{n+1 } s \\|^\\alpha \\ ,    \\lambda ( \\mathrm{d}s ) .\\end{aligned}\\ ] ] choosing @xmath519 for a borel set @xmath44 yields , upon taking complements with respect to @xmath520 and noting that @xmath521 for @xmath53 , @xmath522 in particular , @xmath523 .",
    "the backward tail chain now follows from definition  [ d : bftc](iii ) together with the distribution of @xmath350 .    in the special case that @xmath21 is invertible",
    ", we find from that @xmath524 is equal to either @xmath525 or to @xmath35 with conditional probabilities depending on @xmath526 : if @xmath527 , then @xmath528 too , while if @xmath529 , then @xmath530 to derive a concrete form of the backward markov kernel , let us assume that @xmath487 has a lebesgue density @xmath531 on @xmath33",
    ". then all measures @xmath494 and thus @xmath41 have lebesgue densities as well and gives us @xmath532 for all @xmath53 such that @xmath533 .",
    "the explicit form of the markov kernel for the backward tail chain is not easily found for the general case . in order to derive an illustrative form in a special case note first that with @xmath534 @xmath535 \\\\",
    "\\nonumber&= & \\sum_{n=0}^\\infty p_n \\int_{\\mathbb{s}^{d-1 } } f\\left(\\frac{a s}{\\|a s\\|}\\right)\\|a s\\|^\\alpha\\ , \\lambda_n ( \\mathrm{d } s ) \\\\",
    "\\nonumber&= & ( \\sum_{k=0}^\\infty c_k)^{-1 } \\sum_{n=0}^\\infty \\int_{\\mathbb{s}^{d-1 } } f\\left(\\frac{a ( a^n s/\\|a^n s\\|)}{\\|a ( a^n s/\\|a^n s\\|)\\|}\\right)\\|a ( a^n s/\\|a^n s\\|)\\|^\\alpha \\|a s\\|^\\alpha\\ , \\lambda ( \\mathrm{d } s ) \\\\",
    "\\nonumber&= & ( \\sum_{k=0}^\\infty c_k)^{-1 } \\sum_{n=0}^\\infty \\int_{\\mathbb{s}^{d-1 } } f\\left(\\frac{a^{n+1 } s}{\\|a^{n+1 } s \\|}\\right)\\|a^{n+1 } s\\|^\\alpha\\ , \\lambda ( \\mathrm{d } s ) \\\\",
    "\\nonumber&= & ( \\sum_{k=1}^\\infty c_k)^{-1 } \\left[\\sum_{n=0}^\\infty \\int_{\\mathbb{s}^{d-1 } } f\\left(\\frac{a^{n } s}{\\|a^{n } s \\|}\\right)\\|a^{n } s\\|^\\alpha\\ , \\lambda ( \\mathrm{d } s)-\\int_{\\mathbb{s}^{d-1}}f(s ) \\;\\lambda ( \\mathrm{d } s)\\right ] \\\\",
    "\\label{e : losezero}&=&{\\mathrm{e}}[f(\\theta)]-(\\sum_{k=0}^\\infty c_k)^{-1}{\\mathrm{e}}[f(\\lambda ) ] ,   \\end{aligned}\\ ] ] for all bounded continuous functions @xmath123 on @xmath33 .",
    "if we assume that @xmath21 is invertible this leads us to @xmath536 \\\\ & = & { \\mathrm{e}}\\left[{\\boldsymbol{1}}_t(a^{-1}\\theta){\\boldsymbol{1}}_s(\\theta)\\right]-(\\sum_{k=0}^\\infty c_k)^{-1}{\\mathrm{e}}\\left[{\\boldsymbol{1}}_t(a^{-1}\\lambda){\\boldsymbol{1}}_s(\\lambda)\\right],\\end{aligned}\\ ] ] for borel sets @xmath537 and @xmath44 .",
    "setting @xmath538 this implies that @xmath539 since @xmath540 for all @xmath291 . to derive a concrete form of the backward markov kernel ,",
    "let us assume that @xmath541 has a density @xmath542 on @xmath33 .",
    "then @xmath503 and @xmath209 have a density @xmath543 as well and gives us @xmath544 for all @xmath53 with @xmath545 .",
    "an analogous relation holds true if both @xmath541 and @xmath503 have a probability mass function .",
    "the authors thank richard davis and holger drees for helpful discussions . furthermore , they wish to thank the organisers , especially paul doukhan , of the workshop  extremes and risk management  which took place during september 2012 at the university of cergy - pontoise .",
    "anja janen was supported by dfg ( dfg project ja 2160/1 - 1 ) .",
    "johan segers was supported by contract `` projet dactions de recherche concertes '' no .",
    "12/17 - 045 of the `` communaut franaise de belgique '' and by iap research network grant no .",
    "p7/06 of the belgian government ( belgian science policy ) .",
    "buraczewski , d. , damek , e. , guivarch , y. , hulanicki , a. and urban , r. ( 2009 ) .",
    "tail - homogeneity of stationary measures for some multidimensional stochastic recursions _ probab .",
    "theory relat .",
    "fields _ * 145 * , 385420 .",
    "buraczewski , d. , damek , e. and mirek , m. ( 2012 ) .",
    "asymptotics of stationary solutions of multivariate stochastic recursions with heavy tailed inputs and related limit theorems .",
    "_ stoch .",
    "appl . _ * 122 * , 4267 .",
    "de haan , l. , resnick , s. i. , rootzn , h. and de vries , c. g. ( 1989 ) .",
    "extremal behaviour of solutions to a stochastic difference equation with applications to arch processes .",
    "appl . _ * 32 * , 213224 .",
    "letac , g. ( 1986 ) .",
    "a contraction principle for certain markov chains and its applications .",
    "_ random matrices and their applications : proceedings _ ( brunswick , maine , 1984 ) , 263273 . _",
    "contemp .",
    "_ , * 50 * , amer .",
    "soc . , providence , ri ."
  ],
  "abstract_text": [
    "<S> the extremes of a univariate markov chain with regulary varying stationary marginal distribution and asymptotically linear behavior are known to exhibit a multiplicative random walk structure called the tail chain . in this paper , we extend this fact to markov chains with multivariate regularly varying marginal distribution in @xmath0 . </S>",
    "<S> we analyze both the forward and the backward tail process and show that they mutually determine each other through a kind of adjoint relation . in a broader setting , it will be seen that even for non - markovian underlying processes a markovian forward tail chain always implies that the backward tail chain is markovian as well . </S>",
    "<S> we analyze the resulting class of limiting processes in detail . </S>",
    "<S> applications of the theory yield the asymptotic distribution of both the past and the future of univariate and multivariate stochastic difference equations conditioned on an extreme event . </S>"
  ]
}