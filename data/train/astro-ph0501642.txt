{
  "article_text": [
    "numerical simulations , and particularly n - body simulations , play an important rle in astrophysics and cosmology . before the advances in computer developments , it was impossible for astrophysicists to compute the evolution of a large system of particles evolving under their gravitational influence .",
    "the amount of calculation growing like @xmath0 , the direct summation for more than a modest number of particles is unimaginable . in 1941 , holmberg @xcite did a pioneering study of the tidal disturbances due to a close encounter between two nebulae .",
    "he studied the tidal deformations by reconstructing the orbits of each mass elements .",
    "he used light bulbs to represent these elements ( replacing gravitation by light ) .",
    "the power of the bulbs is proportional to the mass and the total light was measured by a photocell .",
    "each nebulae was represented by 37 light bulbs .",
    "even with this primitive but quite ingenious setup , the creation of spiral arms was detected and a good estimate of the energy loss was also provided .    during the 60 s and 70 s with the development of computers , scientists developed direct summation codes to evaluate the potential exerted on a few hundred particles . in 1970",
    ", peebles studied the collapse of a cloud of @xmath1 particles as a model of cluster formation ( see @xcite ) .",
    "six years later , white studied the collapse of @xmath2 particles with different masses . unfortunately , with these low resolution simulations , numerical artifacts ( two - body relaxation ) are important and the results from these simulations were not reliable .",
    "the first cosmological simulations were made in the mid 70 s .",
    "most of these simulations of structure formation confirm the existence of a flat spectrum of initial fluctuations .",
    "the last thirty years have seen the development of several n - body codes .",
    "each one is particularly suitable to study a specific range of dynamical problems .",
    "each algorithm has its strengths and weaknesses . in the next few paragraphs",
    ", we describe the characteristics of a few popular codes for collisionless systems , i.e. the study of internal dynamics of galaxy , interactions between galaxies and the clustering in an expanding universe @xcite .      in this algorithm ,",
    "the force is computed exactly for each particle .",
    "if the system consists of @xmath3 particles , the number of operations to evaluate the force exerted on these particles is proportional to @xmath4 .",
    "this method is flexible , but has a high computational cost and is limited to systems with @xmath5 .",
    "usually , the system is integrated using a second - order scheme like leapfrog or runge - kutta .",
    "the developers of these codes were aware of the fact that when particles were closed to each other , the acceleration becomes important and one might use multiple timesteps ( see section 3 ) in the integration scheme in order to compute the particles trajectories accurately .",
    "this method is the fastest when one has to deal with large @xmath3 .",
    "the number of computation is of order @xmath6 where @xmath7 represents the number of grid points .",
    "this method determines the force acting on each particle by evaluating the gravitational field .",
    "the trick is to associate particles to nearby point mesh .",
    "hence , each mesh point has a defined density attribute .",
    "the gravitational potential is evaluated by solving the poisson equation @xmath8 on a number of grid points within a fixed volume in space .",
    "the force on each particle is obtained via interpolation techniques .",
    "there are several ways to assigning particles to the mesh , but one must be careful with the fluctuations of the force when the particles are close to each other .",
    "the continuity of the derivatives the function used to assign particles to mesh is the first criterion .",
    "the simplest assignment scheme is the `` nearest - grid - point '' ( ngp ) scheme .",
    "the density at a mesh point is determined by the number of particles in the cell centered on the point divided by the volume of the cell . however , the forces are discontinuous and this technique is rarely used .",
    "there are other more accurate assignment schemes .",
    "two of them are the `` cloud - in - cell '' ( cic ) and `` triangular - shaped - cloud '' ( tsc ) .",
    "the former one gives a continuous force , but the first derivative is discontinuous .",
    "the latter is more accurate .",
    "it employs an interpolation function that is piecewise quadratic and each particle is assigned to a larger number of mesh points .",
    "the grid methods have been successful in simulations of clustering in an expanding universe and in studying galactic disk dynamics .",
    "however , these techniques have several limitations .",
    "first , the spatial resolution is roughly the distance between mesh points .",
    "the geometry imposed by the grid can not be adjusted to the changing shape of the system .",
    "also , the evaluation of the potential on grid points where there are no nearby particles is a waste of cpu time and a weakness of the method .",
    "the goal of a tree code is to regroup particles to reduce the number of contribution to the force acting on any particle .",
    "basically , this technique has a lower computational cost than the direct summation scheme .",
    "the calculations grow like @xmath9 .",
    "in this scheme , the contributions from nearby particles have to be summed directly , but the particles that are far away can be regrouped and replaced by a monopole term in the summation . at each step , thegrouping \" can be different because the particles move in space .",
    "hence , one must rebuild the tree at each time step .",
    "this is one drawback of the method .",
    "the first two well - known tree codes were designed by appel in 1985 and barnes & hut in 1986 .",
    "section 3 is dedicated to the barnes & hut tree code .",
    "this technique has advantages and weaknesses .",
    "first , the tree structure takes into account the shape of the system @xcite .",
    "there is no fixed geometry .",
    "second , there is no time lost in evaluating the potential in regions devoid of matter .",
    "however , this technique is slower than pm methods .",
    "also , it is more difficult to implement .    finally , the method has been particularly successful in studying the collisions between galaxies , the internal galactic structures and cosmological structures formation .",
    "the previous paragraphs introduced basic concepts related to numerical @xmath3-body techniques . in this section , we present the main physical quantities of four different spherical models used and/or discovered in numerical simulations : hernquist , nfw , plummer , and tis density profiles . for each one of them , we include the cumulative mass function , the gravitational potential and the distribution function if an approximation or analytical expression can be found .",
    "@xcite first introduces this density profile as a fit to the de vaucouleurs surface brightness profile , @xmath10 -1\\ ] ] where @xmath11 and @xmath12 represent respectively half of the total luminosity and the isophote value corresponding to it .",
    "the de vaucouleurs profile is a good fit for the surface brightness of most elliptical galaxies .",
    "it is also a good approximation for the distribution of stars in the bulge of spiral galaxies .",
    "the profile has the following shape , @xmath13 @xmath14 is the total mass of the system and @xmath15 is a scale length",
    ". the potential can be found via the poisson equation . using the preceding equation",
    ", one finds @xmath16 it is possible to express the density in function of the potential @xmath17 this enables us to evaluate analytically the distribution function ( df ) @xcite of the system , @xmath18 the solution for the hernquist s profile is @xmath19 \\ , \\label{hernquistdf}\\end{aligned}\\ ] ] where @xmath20 and @xmath21 useful approximations can be made on this distribution to find the limiting case when @xmath22 and @xmath23 . from equation  ( [ hernquist ] ) and ( [ pothernquist ] ) one can find the the velocity dispersion by solving the jeans equation . for an isotropic system [ @xmath24 where @xmath25 , @xmath26 the model provides a good fit for the de vaucouleurs @xmath27 law [ see fig . 4 in hernquist ( 1990 ) ] .",
    "its distribution function [ eq .  ( [ hernquistdf ] ) ] is found analytically .",
    "the plummer model @xcite has been widely used in numerical simulations of star cluster dynamics ( e.g. @xcite ) .",
    "it is a polytrope of index 5 given by : @xmath28^{5/2 } } \\ ; . \\label{plummer}\\ ] ] where @xmath14 represents the total mass of the cluster and @xmath29 is a scale length .",
    "the mass enclosed in a radius @xmath30 is determined by the following equation : @xmath31^{3/2 } } \\label{massplummer}\\ ] ] and the gravitational potential is given by @xmath32^{1/2 } } \\ ; .",
    "\\label{potplummer}\\ ] ] the density profile can be expressed in terms of the gravitational potential . the distribution function [ see eq .",
    "( [ distributionfunction ] ) ] can be found analytically : @xmath33    the hernquist and plummer models can be easily used as initial conditions for n - body simulations .",
    "@xcite used a simple method when it is possible to express analytically the radius in function of the mass : @xmath34    the technique needs the creation of a subroutine which generates five random numbers @xmath35 , @xmath36 , @xmath37 , @xmath38 and @xmath39 ( uniform deviate between 0 and 1 ) .",
    "assume that @xmath40 is normalized and @xmath41 , then @xmath42 ( the radius of the @xmath43 particle ) is determined by @xmath44 . in the case of the plummer model ,",
    "@xmath45 the @xmath46 , @xmath47 and @xmath48 components can be evaluated using @xmath36 and @xmath37 using the following equations : @xmath49    for the velocity , one has to evaluate the escape velocity ( @xmath50 ) at each @xmath42 .",
    "we can write @xmath51 and insert this ratio into equation  ( [ dfplummer ] ) .",
    "the probability distribution of @xmath52 is then proportional to @xmath53 ( note : the factor @xmath54 comes from the fact that we use the _ speed _ distribution instead of the velocity component distribution ) .",
    "the values of @xmath52 range between 0 and 1 and @xmath55 is always less than 0.1 . by using @xmath38 and @xmath39",
    ", we can set @xmath56 if @xmath38 and @xmath39 fulfill simultaneously the following criterion : @xmath57 the velocity components are determined using the same trick as for the position .",
    "the navarro - frenk - white ( hereafter nfw ) profile @xcite is the profile resulting from the formation of cold dark matter halos in a hierarchical clustering universe .",
    "nfw find that the halo profiles have the same shapes , independent of the halo mass , initial density fluctuation spectrum and the values of the cosmological parameters .",
    "the profile has the following shape @xcite : @xmath58 where @xmath59 is a scale radius , @xmath60 is a dimensionless density and @xmath61 corresponding to the critical density for a closed universe .",
    "the value of @xmath60 is strongly correlated with the value of the halo mass .",
    "less massive halos have higher @xmath60 , indicating a higher redshift of collapse .    from the value of the halo  concentration \" , @xmath62 ( @xmath63 is the halo radius enclosing a density equals to @xmath64 ) , it is possible to establish a relation between @xmath65 and @xmath60 : @xmath66    the velocity curve",
    "is given by : @xmath67 and the cumulative mass function is @xmath68 \\ ; .",
    "\\label{nfwcummulativemass}\\ ] ]    the gravitational potential can be found using equation  ( 2 - 22 ) in binney & tremaine and is equal to @xmath69 where @xmath70 is given by equation ( [ nfwcummulativemass ] ) .",
    "the next step is to evaluate the distribution function of the nfw profile using equation  ( [ distributionfunction ] ) .",
    "the calculation of @xmath71 shows that @xmath72 can not be expressed as a function of @xmath73 , the gravitational potential : @xmath74    for nfw , equation ( [ distributionfunction ] ) can not be solved analytically , we need to use numerical methods . however , some authors ( e.g. @xcite ) developed useful approximations for @xmath75 .",
    "@xcite proposed the following fitting formula for the isotropic df : @xmath76 where @xmath77 , @xmath78 , @xmath79 , and @xmath80 are the fitting formula parameters for isotropic models .",
    "@xmath81 is a polynomial introduced to improve the fit ( @xmath82 ) in the case of nfw , @xmath83 , @xmath84 , @xmath85 , @xmath86 , @xmath87 , @xmath88 , and @xmath89 .    in figure [ parameters ] , we give a comparison between the hernquist , plummer , and nfw profile for the mass function , density profile , and gravitational potential .",
    "the tis ( truncated isothermal sphere ) is a solution of the lane - emden equation @xmath90 where @xmath91 , @xmath92 and @xmath93 is the core radius : @xmath94 the tis model corresponds to the outcome of the collapse and virialization of a top - hat density perturbation .",
    "this model involves a non - singular , truncated isothermal sphere @xcite . for a given value of boundary pressure @xmath95 and mass @xmath96",
    ", there is a unique value of @xmath97 ( where @xmath98 - @xmath99 is the truncation radius ) which minimizes the total energy .",
    "this minimum energy solution is the unique tis solution preferred in nature as the outcome and virialization of a sphere in the presence of a fixed external pressure .",
    "the virialized object has the same total energy as the top - hat before the collapse .",
    "shapiro & iliev found that this solution implies @xmath100 .",
    "there is a useful fitting formula to equation  ( [ lane - emden ] ) that is a good approximation within several core - radii @xcite : @xmath101 for the particular tis case , @xmath102    the tis profile seems to be a better alternative to the nfw profile in many cases .",
    "@xcite showed that the projected mass density of the cluster cl 0024 + 1654 , determined by strong gravitational lensing , is well fitted by a tis sphere .",
    "they also found that a central cuspy nfw fitting profile implies a velocity dispersion which is too large by a factor of @xmath103 to be consistent with the measured velocity dispersion .",
    "it also appears that the tis model can be a good fit to the density profile of dark matter - dominated dwarf galaxies @xcite .",
    "finally , the tis solution for virialized cosmological halos reproduces fairly well the @xmath104 correlation @xcite .",
    "in fact , current data suggest that the central mass densities @xmath105 of cosmological halos in the universe are correlated with their velocity dispersion @xmath106 over a very wide range of @xmath106 @xcite . for all these reasons ,",
    "it is important to study this density profile .    the cumulative mass function for equation  ( [ approxemden ] ) @xcite is @xmath107 \\bigg\\ }   \\label{massfunctiontis}\\end{aligned}\\ ] ] and",
    "the gravitational potential is @xmath108 \\nonumber \\label{tispotential}\\end{aligned}\\ ] ]    equation  ( [ approxemden ] ) can be integrated to yield an analytical fitting formula for the tis rotation curve @xcite given by @xmath109 \\bigg\\}^{1/2 } \\label{vrotation}\\end{aligned}\\ ] ]    in summary , we have briefly introduced few basic models used in current numerical simulations of structure formation , galactic dynamics , and star clusters . in the next section ,",
    "we review the bh tree code , the @xmath3-body code we used to make these systems evolve .",
    "the barnes and hut ( hereafter bh ) tree code @xcite is the one we use for the simulations .",
    "however , we modified its structure to include a multiple timesteps integration scheme ( see section 4 ) . in this section",
    "we describe how the tree code works : its main features and basic related concepts .",
    "the bh technique is based on a hierarchical division of space into cubic cells . at the beginning of the simulation ,",
    "the particles are distributed , one by one , into the root cell .",
    "if two particles are in the same cell , then this cell is divided into eight  daughter \" cells ( an oct tree ) of equal volume ( see figs . 1 and 2 in @xcite ) .",
    "the aim of this process is to make sure that at the end of tree building step , two particles can not reside in the same cell .",
    "for each cell with subcells in it , there is an associated pseudo - particle which contains the total mass in the cell and located at the center - of - mass of the particles distribution in the cell .",
    "this building step must be repeated at each timestep because the particles move and they are no longer in the same cell .",
    "it takes usually less than 10 % of the overall cpu time to build the tree @xcite .",
    "the significant difference with direct summation methods ( see section 1.1 ) resides in the approximation made in the force calculation .",
    "we first consider the interaction between a group of particles ( represented by a cell of higher level ) and a particle .",
    "we want to use a criterion based on the size of the cell ( @xmath110 ) and the distance between the center of mass of this cell and the particle ( @xmath111 ) to verify if we can consider this group as a _ point - mass particle _ or if we need to go down to a lower level of the hierarchy and resolve its constituents .",
    "this criterion can be written as @xmath112 where @xmath113 is a free parameter called the  opening angle \" parameter . therefore , to compute the force on particle @xmath114",
    ", one needs to walk down the tree , starting by the bigger cells and check for each cell if equation  ( [ openangle ] ) is verified .",
    "if it is the case , then add the contribution of the pseudo - particle of this cell to the force exerted on @xmath114 .",
    "the result of this `` walking '' process is to reduce the number of terms in the force calculation on one particle from @xmath3 to @xmath115 .",
    "the value of @xmath113 is chosen at the beginning of the simulation .",
    "@xcite mentioned that for a large @xmath113 ( @xmath116 ) , the bh code can unintentionally include particle self - acceleration by not forcing subdivision of cells containing the particle .",
    "it is worth noting that decreasing @xmath113 from @xmath117 to @xmath118 for @xmath119 particles corresponds to increasing the cpu time by a factor @xmath120 .",
    "the range of typical values for @xmath113 is between @xmath121 and @xmath122 .",
    "this is a good compromise between accuracy and performance .",
    "the typical error for @xmath123 relative to a direct sum is @xmath124 @xcite .",
    "the error for a fixed @xmath113 decreases as @xmath3 increases .    after establishing the opening angle criterion and determining which cells need to be resolved",
    ", one needs to calculate the force exerted by either cells or close particles .",
    "the particles are represented by point masses .",
    "however , the force that two point masses exerts on each other becomes large at small distances .",
    "therefore , the velocities will change very rapidly and very short timesteps are needed in order to properly determine the motion of the particles ( see section 4 ) .",
    "we can avoid this problem if the particles are extended @xcite . to compute the force exerted by particle ( or pseudo - particle ) @xmath125 on particle @xmath126 , one can use the following formula : @xmath127 where @xmath128 is the _ softening length_.",
    "the maximum force occurs at @xmath129 .",
    "this potential is called the _ softened point - mass potential _",
    "@xcite also referred as plummer - type softening .",
    "finally , for @xmath130 and a plummer model ( see section 2.3 ) , the tree walk process and force summation take respectively @xmath131 % and @xmath132 % of the total cpu time @xcite .",
    "once the force has been evaluated for each particle , we need to update the position and velocity of the particles .",
    "we describe here two different schemes of order 2 : leapfrog , and runge - kutta .",
    "the leapfrog technique is used in the bh tree code .",
    "suppose that we know the particles positions and velocities at step @xmath133 and we want to advance the system to step @xmath134 .",
    "this can be done using a time - centered leapfrog : @xmath135 @xmath136 is the timestep .",
    "the force is computed at the beginning of the timestep and is used to extrapolate the position and velocity at respectively @xmath134 and @xmath137 .",
    "this method is similar to the leapfrog scheme .",
    "however , it requires the storage of an additional variable , namely @xmath138 .",
    "the force is determined at the center of the timestep .",
    "the position and velocity at step @xmath134 are extrapolated from the value of the force at the middle of the timestep @xcite : @xmath139 both methods give similar results .",
    "the bh tree code provides a technique for handling a large number of long - range interactions and concentrating the cpu time allowed on local interactions where more precision is needed . in this iterative process",
    ", the number of mathematical operations grows as @xmath140 .",
    "in the previous section , we described the bh tree code features .",
    "now , we introduce a multi timesteps scheme which can be inserted in a tree code algorithm .",
    "this scheme is especially useful for studies of dynamical properties of halos containing black holes , sph simulations of star formation , etc .",
    "the basic idea is that far away particles evolve less rapidly than particles closer to the dynamical center of the system .",
    "the motion of distant particles can be integrated with a longer timestep .",
    "the first thing we need to do is to evaluate the integration time for _ each _ particle .",
    "one of the most commonly used criterion is to associate the velocity and acceleration of the particle to its softening length : @xmath141 \\label{integrationtime}\\ ] ] where @xmath142 , @xmath143 , @xmath144 and @xmath145 are respectively the integration time , softening length , velocity and acceleration of particle @xmath126 .",
    "@xmath146 is a free parameter varying between @xmath147 and @xmath148 .",
    "this is the most straightforward method to estimate the integration time needed for each particle .",
    "however , we are looking for a more meaningful criterion based on the orbital period of the particles .",
    "equation  ( [ integrationtime ] ) provides a value of @xmath149 for each particle .",
    "the next step is to sort those value of @xmath142 ( @xmath150 ) and find @xmath151 and @xmath152 .",
    "we then distribute these particles into different bins , having different integration timestep .",
    "the steps are separated by a factor @xmath153 in time .",
    "if @xmath133 represents the number of bin , then : @xmath154 ( @xmath133 is round to the next integer ) .",
    "we have now a set of @xmath133 different timesteps for the @xmath3 particles .",
    "we will use the following notation for the timesteps : @xmath155 where @xmath156 represents the timestep of bin number @xmath125 .",
    "the longest timestep , namely @xmath157 corresponds to @xmath158 and the shortest one ( @xmath159 ) is @xmath160 .",
    "figure [ multi ] illustrates the distribution of timesteps for @xmath161 .      the goal of introducing a multi timesteps scheme is to reduce the number of force evaluations for the particles having a longer timestep . to integrate the motion of the particles , the barnes & hut tree code uses a leapfrog integrator in which the forces are evaluated at each half - timestep [ see previous section , eq .",
    "( 35 ) ] . in this multi timesteps scheme ,",
    "the timesteps are variable between particles and therefore , the evaluation of the force on the particles is not necessarily _ synchronized _ with the evaluation for the other ones . in figure",
    "[ multi ] , we show by red dots , when the force must be evaluated in a system of @xmath161 bins . at the beginning of the simulation ( @xmath162 ) , all the particles are synchronized .",
    "then , the code updates the position and velocity of each particles ( using the leapfrog scheme ) with an interval of @xmath163 . at @xmath164 ,",
    "only the particles of bin number 3 need a force evaluation and at @xmath165 , particles of bin 3 and 2 need a force evaluation . there is a simple criterion to check if the bin number @xmath125 needs a force evaluation .",
    "let @xmath166 represents the number of @xmath163 elapses since the beginning of the simulations , i.e. @xmath167 .",
    "the @xmath43 bin needs a force evaluation if @xmath168    it is preferable to use integers in equation  ( [ forcecriterion ] ) instead of directly comparing @xmath169 and @xmath156 because of the possible truncation errors modifying the value of @xmath169 during the simulation .      during the simulation ,",
    "it is highly probable that many particles will move from one bin to another after evaluating their integration time .",
    "for example , a particle on a very eccentric orbit will need to diminish its timestep during the closest approach and increase it near the pericenter .",
    "the multi timesteps scheme should allow particles to move from one bin to another , but not at any moment .",
    "there is a simple criterion to verify if a particle initially in bin @xmath125 can move to a bin @xmath126 .",
    "first , both bins ( @xmath126 and @xmath125 ) must be synchronized , i.e. their internal clock should indicate the same time and this time should correspond to the number of fundamental timesteps ( @xmath170 ) elapses since the beginning of the simulation .",
    "there is a simple way to evaluate the number of fundamental timesteps elapses for each bin of a set of @xmath133 bins .",
    "suppose that @xmath171 represents the number of fundamental timesteps of the @xmath43 bin .",
    "@xmath171 will be equal to @xmath166 if @xmath172 if the following expression is false then @xmath171 keeps its latest value when equation  ( [ timetotime ] ) was verified and the particle stays in the same bin .",
    "@xmath173 you have to wait until equation  ( [ movingcriterion ] ) is verified before moving a particle from one bin to another .      what happens if a particle of the fundamental bin ( in our case , bin @xmath133 ) goes from bin @xmath133 to bin @xmath134 ?",
    "following the previous argument , this can happen at each fundamental timestep .",
    "in fact , the fundamental timestep changes .",
    "it goes from @xmath174 to @xmath175 .",
    "we must then take that into account and change the number of @xmath81 for each bin .",
    "in this example , @xmath176 and @xmath177 will be equal to the previous value of @xmath178 multiplied by 2 .",
    "@xmath166 will also be modified , going from @xmath166 to @xmath179 and @xmath180 .",
    "the opposite phenomenon happens if all the particles of bin @xmath133 move to bin @xmath181 , i.e. we lose a bin .",
    "the process is exactly the same except that we divide by 2 instead of multiplying by 2 .",
    "finally , at the end of a basic timestep , i.e. if @xmath182 where @xmath183 is an integer , we allow all the particles to change from one bin to another after evaluating their integration time .",
    "figure [ multi ] ( upper panel ) illustrates the different situations examined in the previous paragraphs .",
    "in the previous three sections , we describe the theoretical aspects of the models we want to study ( section 2 ) , the tree code used ( section 3 ) and a multi timesteps scheme ( section 4 ) implemented in a leapfrog integrator [ see eq .",
    "we are interested in determining the evolution of the physical properties of the simulated systems .",
    "this section contains a brief description of the different properties of the system one can measure using the n - body results .",
    "first , the most important thing to measure when doing n - body experiments is the total energy of the whole system .",
    "the energy must be conserved .",
    "the state - of - the - art simulations are able to conserve total energy within @xmath184 .",
    "if it is not well conserved this is maybe due to a wrong choice of timesteps .",
    "the energy is calculated using the following formula : @xmath185 where @xmath186 is the distance between particle @xmath126 and @xmath125 .",
    "the evaluation of the density profile is primordial to study the dynamical properties of a system .",
    "in particular , if one studies the collisions between galaxies harboring a black hole , the profile can give serious insight about the orbits distribution in the inner few kpc .",
    "there are basically two ways of measuring the density profile for spherically symmetric systems .",
    "the first one is two divide the space into spherical bins of width @xmath187 and count the number of particles in each bin .",
    "the bin width can increase logarithmically as @xmath30 becomes large in order to have a good resolution in the center and a lower one in the outer parts of the system where nothing important happens . in this picture , the density is evaluated using the following equation : @xmath188 where @xmath189 , @xmath190 and @xmath191 are respectively the density , radius and width of bin @xmath192 ; @xmath193 represents the number of particles of mass @xmath194 in bin @xmath192 .",
    "this method has drawbacks when the number of particle is not sufficient to resolve the inner bins .",
    "some bins may be empty and others can contain not enough particles .",
    "the second method consists of sorting the particles by radius , then divide them by slices of 100 or 1000 particles , for instance , and evaluating the average radius , width and density of each slice of particles .",
    "this method avoids low resolution bins but one needs to have enough particles to get slices thin enough for a good resolution .      in the previous paragraphs , we have seen how to compute the density profile .",
    "we are now interested in its evolution .",
    "@xmath195 , @xmath196 and @xmath198 represent the radii which contains 10 % , 50% and 90% of the system mass , respectively .",
    "the measurement of these quantities gives a rough estimate of the evolution of the density profile .",
    "in the simulations , time is measured in dimensionless units .",
    "a good way to characterize the time scales is to express them in terms of the free - fall time @xmath199 this quantity represents the time needed for a homogeneous sphere of pressureless material of density @xmath72 ( where @xmath72 can be evaluated at @xmath29 = @xmath200 ) released from rest at @xmath162 to collapse to a point at @xmath201 @xcite .      to estimate the size of the cluster , one has to evaluate the components of the quadrupole tensor defined as @xmath202 where @xmath203 and @xmath190 are the mass and position relative to particle @xmath192 . the indicies @xmath126 and @xmath125 account for the vectors components .",
    "once the tensor components have been determined , one has to compute the eigenvalues @xmath204 , @xmath205 and @xmath206 .",
    "the  semi - major axes \" of the system are evaluated using the following formula : @xmath207 the ratios of the different @xmath145 give a measure of the system sphericity . if @xmath208",
    ", then the system is perfectly spherical .",
    "the velocity dispersion for a set of particles is defined as follows : @xmath209 ^ 2}{n } } \\label{veldispersion}\\ ] ] where @xmath210 is the average @xmath126-component of the velocity over the distribution and @xmath3 is the number of particles . for a spherical system ,",
    "it is useful to find @xmath211 , @xmath212 and @xmath213 . to do this",
    ", one needs to find @xmath214 , @xmath215 , and @xmath216 these three quantities can be related to @xmath30 , @xmath217 , @xmath218 , @xmath219 , @xmath220 , @xmath221 , and @xmath222 using the following relations @xmath223\\ , , \\nonumber \\\\",
    "v_{\\phi } & = & \\frac{1}{\\sqrt{x^2+y^2}}\\left(xv_y - yv_x \\right)\\ , .",
    "\\nonumber \\label{veldispersionspherical}\\end{aligned}\\ ] ] if @xmath224 then the system is isotropic .",
    "another way to measure the degree of isotropy of a system is to evaluate the anisotropy parameter @xmath146 defined as : @xmath225 where @xmath226 is the tangential velocity .",
    "if the distribution of orbits is isotropic , then @xmath227 . if the orbits become radial , then @xmath228 .",
    "for a set of perfectly circular orbits , @xmath229 .",
    "in conclusion , this short review is an tentative introduction to the basic concepts related to numerical @xmath3-body techniques in astrophysics .",
    "we introduced different codes used , physical models used and developed in numerical simulations , algorithms and measurements .",
    "we hope this document will be a useful synthesis for any beginner interested in numerical astrophysics .",
    "this document presents the various basic algorithms needed to do a study of collisionless equilibrium systems . using the techniques presented in this paper",
    ", we will study the long - term evolution of density profiles resulting from the mergers between halos containing black holes .",
    "we acknowledge the natural science and engineering research council of canada ( nserc ) for an undergraduate summer fellowship ( jrg ) and thank laurent drissen and john dubinski for useful comments during the project .",
    "we also thank joshua e. barnes for making his tree code guide and n - body codes available on his website .",
    "hm thanks the canada research chair program for support .",
    "aarseth , s.j . ,",
    "hnon , m. , wielen , r. 1974 , a&a , 37 , 183 .",
    "barnes j. , hut , p. 1986 , _ nature _ , 324 , 446 .",
    "binney , j. , tremaine , s. 1987 , _ galactic dynamics _ ,",
    "princeton university press fortin , a. 2001 _ analyse numrique pour ingnieurs _ , presses internationales polytechnique .",
    "hernquist , l. 1987 , , 64 , 715 .",
    "hernquist , l. 1990 , , 356 , 359 .",
    "holmberg , e. 1941 , , 94 , 385 .",
    "iliev , i.t .",
    "2001 , , 546 , l5 .",
    "klypin , a. 1996 , _ numerical simulations in cosmology i _ , italian physical society ( astro - ph/9605183 ) .",
    "natarajan , p. , lynden - bell , d. 1997 , , 286 , 268 .",
    "navarro , j.f . ,",
    "frenk , c.s . , white , s.d.m .",
    "1995 , , 275 , 720 .",
    "navarro , j.f . ,",
    "frenk , c.s . , white , s.d.m .",
    "1996 , , 462 , 563 .",
    "navarro , j.f . ,",
    "frenk , c.s . , white , s.d.m .",
    "1997 , , 490 , 493 .",
    "plummer , h.c .",
    "1911 , , 71 , 460 .",
    "saslaw , w.c .",
    "1985 , _ gravitational physics of stellar and galactic systems _ , cambridge university press .",
    "sellwood , j.a .",
    "1987 , , 25 , 151 .",
    "shapiro , p.r . , iliev , i.t .",
    "1999 , , 307 , 203 .",
    "shapiro , p.r . ,",
    "iliev , i.t .",
    "2000 , , 542 , l1 .",
    "shapiro , p.r . ,",
    "iliev , i.t .",
    "2002 , , 565 , l1 .",
    "widrow , l.m .",
    "2000 , , 131 , 39 .",
    "this appendix is dedicated to the description of an algorithm evaluating the number of possible two - body bound systems which can form in @xmath3-body simulations of dense star clusters .",
    "the cluster has to be dense enough so that the softening length is short to allow the formation of bound subsystems .",
    "the following algorithm is a tentative method to identify possible two - body systems in @xmath3-body files .",
    "those systems can be referred to as  binary stars \" .",
    "the binary stars finder code is an analysis tool that can identify the presence of binary systems in a dense cluster of particles . to work properly",
    ", the code needs to receive as inputs the dynamical data of the system , i.e. the position , velocity and acceleration of each particle .",
    "usually this can be done by using typical output files from n - body codes . to be able to identify correctly the formation of potential binary systems , we need to set up conditions for the formation of such systems .",
    "the first one is related to the distance between particles .",
    "suppose that particles a and b are constituents of a binary system .",
    "our first hypothesis is that : a is the closest neighbor to b and vice - versa .",
    "hence , if there is a third body in the very close vicinity of a , even closer than b , we can not consider the system formed by a and b to be a binary one .",
    "the probability that a will interact strongly with this intruder is higher than with b. the condition of reciprocal closest neighbor must be fulfilled .",
    "second , a cluster consisting of several particles will remain bound if the total energy has a negative value .",
    "this is also true for binaries .",
    "so we have to sum the energy of the two members .",
    "if the results respects this second criterion the likelihood that we have identified a real binary increases .",
    "the last condition consists of giving a certain level of  quality \" to every system who already satisfies the first two criteria .",
    "this can be achieved by determining the number of bodies that can potentially disturb the path of one or even two members of the binary systems .",
    "if these intruders are close enough to the considered system , they can break up the whole system in the next few iterations . in section a.2.3",
    ", we describe a method to reduce the problem to a single moving particle that follows a precised path around a fixed partner .",
    "the characteristics of this orbit will enable us to set up a  neighborhood of influence \" and after that to count the number of  bad \" neighbors .",
    "now the question is how does it work ? this is the object of the next section .",
    "in fact , particular features and algorithms will be discussed . also ,",
    "in the last section of this presentation document , we suggest several improvements that could be made in further versions of the code .        as we saw in the previous section ,",
    "the first criterion consists of a reciprocal closest neighbors selection . to do this",
    ", we can simply compute the distance between particle x and every other particle of the cluster and find the closest neighbor to particle x. we could repeat the process for every member of the cluster . since this calculation grows like @xmath230 , for a typical cluster of @xmath231 that represents a total number of @xmath232 mathematical operations .",
    "this method has a very high computational cost and should be avoided if possible .    instead of doing a direct calculation between each pair of particle",
    ", we can divide the volume that contains the whole system into individual cubic cells . after that",
    ", the comparisons could be made under the assumption that members of binary systems will be close to each other , i.e. members of the same or adjacent cells .",
    "hence , if we use this method the number of operations ( @xmath233 ) will grow approximately like : @xmath234 where @xmath3 represents the number of particles in the simulation and @xmath133 the number of cells .",
    "this method is called `` divide - and - conquer . ''",
    "doing it this way we can save precious cpu time .",
    "the side length of each cell should be chosen so that it is greater than a few times the average distance between particles ( to have the closest neighbor in the same cell or in an adjacent one ) . in order to have a significant gain in cpu time ,",
    "the size of the cell should be smaller than the size of the whole cluster .",
    "now what happens if the closest neighbor is not in the same cell",
    ". this could be possible if the particle ( particle a ) on which we want to identify its closest neighbor is near the walls of the cell .",
    "we can handle this kind of situations by comparing the distance between a and the closest neighbor of a in the same cell ( value called @xmath235 ) with the distance between a and the walls of the cell ( @xmath236 , where i goes from 1 to 6 - a cube has six faces ) . now if @xmath237 we must evaluate the distance for particles in the cell labelled @xmath126 .",
    "the process is repeated for adjacent cells who agree to condition ( a2 ) .",
    "figure [ division ] illustrates the previous considerations .",
    "we can repeat the same process for each one of the 26 adjacent cells of the one we consider .",
    "the second step in the identification of binary systems consists of computing the total energy of the two - body system .",
    "we can compute the total energy of the bound system by using the following formula : @xmath238 where the subscripts 1 and 2 denote body number 1 and 2 respectively .",
    "of course , the system will remain bound if @xmath239 has a negative value .",
    "the last step in the identification of binaries consists of evaluating the number of neighbors in the vicinity of the system .",
    "first , we must characterized the size of the system we are studying .",
    "figure [ twobody ] is a schematic representation of a typical two - body system .",
    "@xmath240 represents the center - of - mass position vector .",
    "we can reduce this system to a single particle moving around a fixed massive particle .",
    "the motion of this particle must obey to the specific condition : its angular momentum and energy must be the same as for the previous system and should be conserved along the path .",
    "we can evaluate the reduced angular momentum using this formula : @xmath241 where @xmath242 a is the semimajor axis of the elliptic path of the moving particle and @xmath243 is the reduced mass of the two - body system : @xmath244 for a single particle moving around a fixed one , the energy can be written as : @xmath245 and using the virial theorem : @xmath246 by replacing @xmath15 in equation ( a4 ) by its value in equation ( a7 ) , we can find the ellipse eccentricity @xmath247 : @xmath248 once the eccentricity has been evaluated , we can set the  influence \" radius to be the aphelion distance to the center - of - mass of the system .",
    "the aphelion radius is determined using the following : @xmath249 so , if the distance between a particle @xmath126 and the center of mass of the system is shorter than @xmath250 we can consider this body to be in the close vicinity ( c.v . ) of the system @xmath125 : @xmath251 where @xmath146 is a free parameter .",
    "it will probably disturb the path of one or maybe two particles .",
    "several improvements will be made in a next version of the code .",
    "currently , the code can only handle systems contained in a cubic volume . of course",
    ", we could put the whole cluster in an augmented cubic volume but there will be many empty cells and this is not really optimized .",
    "modifying the code so that systems with rectangular shape can be well - treated is a first thing to do .",
    "the current algorithm analyzes only one snapshot data of the system and evaluates the formation of binary systems",
    ". it could be really interesting if the code could integrate the motion of binaries with the data of several snapshots taken at different times . by doing this",
    ", we could be able to tell if a binary we identified previously is going to break up or not ."
  ],
  "abstract_text": [
    "<S> we present the summary of the theoretical aspects and algorithms used in an undergraduate ( jrg ) summer project based on numerical n - body simulations of collisionless systems . </S>",
    "<S> first , we review the importance of numerical n - body simulations in astrophysics . </S>",
    "<S> we introduce the different codes used and their performances . </S>",
    "<S> we then introduce four famous density profiles : hernquist , nfw , truncated isothermal sphere , and plummer . </S>",
    "<S> the history of these profiles and their dynamical properties are discussed in the third section . in the fourth section , </S>",
    "<S> we present the barnes & hut tree code , its features and performances . </S>",
    "<S> we then explain how to build and incorporate a multiple time stepping scheme in a tree code . </S>",
    "<S> the fifth section is dedicated to the different physical measurements we used to characterize the dynamics of the n - body system . </S>",
    "<S> finally , we describe the future work that will be done with these codes , mainly the study of the adiabatic growth of a black hole at the center of a spherical distribution of stars . </S>"
  ]
}