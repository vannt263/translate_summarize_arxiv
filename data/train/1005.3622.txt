{
  "article_text": [
    "many real world complex networks , including social networks  @xcite , information networks  @xcite , and biological networks  @xcite , are found to divide naturally into communities , known as groups of nodes with a higher - than - average density of edges connecting them .",
    "communities are of interest because they often correspond to functional units such as collections of web pages on a single topic .",
    "the identification of community structure has attracted much attention in various scientific fields .",
    "many methods have been proposed and applied successfully to some specific complex networks  @xcite . for reviews",
    ", the reader can refer to  @xcite .",
    "the community structure of real world networks often exhibit multiple scales  @xcite .",
    "however , the multi - scale community structure can not be uncovered directly through traditional methods .",
    "@xcite pointed out that the synchronization process reveals topological scales of networks and that the spectrum of the laplacian matrix can be used to identify such topological scales .",
    "cheng and shen  @xcite proposed the network conductance to identify the multiple topological scales through investigating the diffusion process taking place on networks . recently , in  @xcite , a general framework is proposed for the detection of community structure in multi - scale networks .    generally , the straightforward description of network topology is a high - dimensional but redundant description , where each node is taken as one dimension of the network and the edges characterize the relationship between these dimensions .",
    "the identification of community structure can be viewed as finding the most significant reduced dimensions which capture the main characteristics of network topology  @xcite .",
    "different significance levels for such dimensions correspond to the community structure with different topological scales .    in this article",
    ", we first apply the _ principal component analysis ( pca ) _ to characterize the community structure .",
    "we show that the covariance matrix behind the pca is the unbiased version of the modularity matrix  @xcite , which underlies the well - known benefit function modularity for community detection . from the perspective of dimension reduction , however , the covariance matrix only takes into account the translation and rotation transformations .",
    "these two transformations fail to deal with the heterogeneous distribution of node degree and community size . to address this problem ,",
    "a correlation matrix is proposed through introducing the rescaling transformation into the covariance matrix .",
    "theoretical analysis indicates that all these three transformations are crucial to identify the multi - scale community structure .",
    "finally , the effectiveness of the correlation matrix is demonstrated through the comparison with the covariance matrix or the modularity matrix on real world networks and artificial benchmark networks .",
    "extensive tests demonstrate that the correlation matrix is very effective at uncovering the multi - scale community structure of network and it significantly outperforms the modularity matrix or the covariance matrix , especially when the distribution of node degree are heavily heterogenous .",
    "the dimension reduction perspective opens the door to utilizing various dimension reduction techniques for the identification of community structure .",
    "a directed network is often described by its adjacency matrix @xmath0 whose element @xmath1 being @xmath2 if there exists an edge pointing to node @xmath3 from node @xmath4 , and @xmath5 otherwise .",
    "the node @xmath4 is called the tail of the edge and the node @xmath3 is called the head of the edge . the out - degree of a node is defined as @xmath6 and the in - degree is @xmath7 .",
    "we suppose that the network has @xmath8 nodes and @xmath9 edges with @xmath10 . for an undirected network ,",
    "it can be transformed into a directed one by replacing each edge with two oppositely directed edges .",
    "note that , for a self - loop edge , only one directed edge is used to replace the original undirected one .",
    "another representation for network is given by two node - edge incidence matrices with the size @xmath8 by @xmath9 , which are respectively defined as @xmath11 and @xmath12 note that the rows of @xmath13 ( or @xmath14 ) are mutually orthogonal and that the columns each sum to unity .",
    "as to this representation , @xmath8 nodes correspond to @xmath8 dimensions with the @xmath4th dimension being denoted by @xmath15 , whose @xmath4th element is @xmath2 and other elements are @xmath5 .",
    "the columns of @xmath13 or @xmath14 can be taken as @xmath8-dimensional data points distributed in the space spanned by the @xmath8 dimensions .",
    "the mean of these data points in @xmath13 is denoted by @xmath16 , where @xmath17 is the @xmath3th column of @xmath13 .",
    "similarly , we give the mean of the data points in @xmath14 as @xmath18 . according to eq .",
    "( [ eq1 ] ) and eq .",
    "( [ eq2 ] ) , we have @xmath19 and @xmath20 .",
    "now we subtract off the mean @xmath21 from each column of @xmath13 and the mean @xmath22 from each column of @xmath14 .",
    "such an operation is known as the _ translation _ transformation and makes the data points mean zero .",
    "the resulting matrices are denoted by @xmath23 and @xmath24 , where @xmath25 is the @xmath9-dimensional vector with all its elements being @xmath2 . with @xmath26 and @xmath27 ,",
    "the covariance between the @xmath4th row of @xmath13 and the @xmath3th row of @xmath14 can be calculated by @xmath28 . here , the denominator @xmath29 is used instead of @xmath9 to make the covariance be unbiased . in this way , all these covariances between the rows of @xmath13 and the rows of @xmath14 form an @xmath30 matrix @xmath31 this matrix is referred to as the _ covariance matrix of network_. its elements are @xmath32 note that the covariance matrix can be easily extended to weighted networks if we consider each weighted edge between two nodes as multiple unweighted edges connecting them .",
    "to our surprise , the covariance matrix is identical to the modularity matrix except that the denominator in the first term is @xmath29 in the covariance matrix while it is @xmath9 in the modularity matrix . in statistics ,",
    "when calculating the empirical variance from sample data points rather than the distribution itself , @xmath29 is used instead of @xmath9 to make the empirical variance be unbiased .",
    "thus the covariance matrix could be taken as the unbiased version of the modularity matrix .",
    "matrix spectral analysis provides an important technique for network division and the identification of community structure .",
    "for example , as to the laplacian matrix , the fielder s eigenvector  @xcite is well studied and widely used for two - way network partition .",
    "newman proposed to find the community structure of network using the eigenvectors of the modularity matrix  @xcite .",
    "this section aims to illustrate what is told about the community structure by the covariance matrix from the perspective of dimension reduction .",
    "it is well known that the traditional covariance matrix plays an important role in pca . by analyzing its eigenvalues and eigenvectors , the most significant directions ( or dimensions ) in terms of the variance",
    "are identified as principal components .",
    "the lesser significant ones are discarded to reduce the number of dimensions and to alleviate redundance without losing too much relevant information . in this article , the idea similar to pca is adopted to analyze the role of the covariance matrix of network at uncovering the community structure of network .    intuitively , as to networks with community structure ,",
    "the tail nodes of edges are expected to be positively correlated with the head nodes of edges  @xcite . according to the definition of covariance ,",
    "the more two variables correlate with each other , the larger the covariance between them .",
    "now the task is to find a direction along which the covariance between @xmath26 and @xmath27 reaches the maximum . without loss of generality",
    ", we use a normalized vector @xmath33 to denote such a direction .",
    "we write @xmath33 as a linear combination of the normalized eigenvectors @xmath34 of the covariance matrix @xmath35 , i.e. , @xmath36 , where the coefficients @xmath37 .",
    "since that @xmath33 is a normalized vector , we have @xmath38 and this implies that @xmath39    due to that @xmath26 and @xmath27 have zero means , the covariance between them along the direction @xmath33 can be calculated by @xmath40 where @xmath41 is the eigenvalue of @xmath35 corresponding to the eigenvector @xmath42 and we have made use of @xmath43 . without loss of generality , we assume that the eigenvalues are labeled in decreasing order @xmath44 . the task of maximizing @xmath45 can then be equated with the task of choosing the nonnegative quantities @xmath46 so as to place as much as possible of the weight in the sum ( [ eq6 ] ) in the terms corresponding to the most positive eigenvalues , and as little as possible in the terms corresponding to the most negative ones , while respecting the normalization constraint in eq .",
    "( [ eq5 ] ) .    obviously , @xmath45 reaches maximum when we set @xmath47 and @xmath48 , i.e. , the desired direction @xmath33 is parallel to the eigenvector @xmath49 .",
    "then , we turn to the next direction along which the covariance is maximized with the constraint that it is orthogonal to the obtained direction @xmath50 . according to eq .",
    "( [ eq5 ] ) and eq .",
    "( [ eq6 ] ) , such a direction is parallel to the eigenvector @xmath51 . in the similar way , it can be easily shown that all the eigenvectors of the covariance matrix @xmath35 form a set of orthogonal bases for the @xmath8-dimensional space , with these dimensions being ranked in terms of the covariance between @xmath26 and @xmath27 along them .    in the following , we will show that the community structure of network is reflected by eigenvectors of the covariance matrix of network .",
    "specifically , the eigenvectors corresponding to positive eigenvalues make positive contribution to reflect the community structure of network , and the negative ones provide information for the anticommunity structure of network . this phenomenon has been noticed by newman when studying the spectrum of the modularity matrix  @xcite .",
    "different from newman s work , we illustrate the relation between the covariance matrix and the community structure from the perspective of dimension reduction .",
    "we use @xmath52 to denote the eigenvector matrix with its columns being the normalized eigenvectors of the covariance matrix @xmath35 ranked in the descending order of the corresponding eigenvalues , which are placed on the diagonal of the diagonal matrix @xmath53 .",
    "then we have @xmath54    multiplying a vector by @xmath55 from the left - hand side means reexpressing it with respect to the new orthogonal bases comprising of the columns of @xmath52 .",
    "thus , @xmath56 and @xmath57 are respectively the new coordinates of the original sample data @xmath26 and @xmath27 with respect to the new bases .",
    "note that @xmath58 and @xmath59 are respectively the results of rotating @xmath26 and @xmath27 around the coordinate origin .",
    "thus , @xmath58 and @xmath59 both have zero mean and accordingly the matrix @xmath53 is the covariance matrix for @xmath58 and @xmath59 .",
    "all the off - diagonal elements of @xmath53 are zeroes , indicating that @xmath58 only correlates to @xmath59 along the same dimension and they are linearly independent along different dimensions .",
    "if @xmath58 and @xmath59 are positively correlated along a certain dimension , the corresponding diagonal element of @xmath53 is positive , otherwise negative .",
    "furthermore , the magnitude of the eigenvalues provides an indicative index for the significance of the dimensions to reflect the community structure of the underlying network .",
    "hereafter , we will neglect the constant multiplier @xmath60 in the covariance matrix without losing any information for the detection of the community structure .",
    "( color online ) the network of the karate club studied by zachary  @xcite .",
    "the real social fission of this network is represented by two different shapes , circle and square .",
    "different colors depict the communities at the other scale .",
    "the dashed - curve gives another alternative partition of network.,scaledwidth=48.0% ]    .[tab1]eigenvectors corresponding to the most positive and negative eigenvalues of the covariance matrix of zachary s club network [ cols=\">,>,>,>,>,>\",options=\"header \" , ]     to illustrate what is provided about the community structure of network by the covariance matrix , as an example , we analyze the covariance matrix of the zachary s karate club network  @xcite , which is widely used as a benchmark for the methods of community detection .",
    "the network and its community structure are depicted in fig .",
    "table  [ tab1 ] shows the eigenvectors corresponding to the most positive and negative eigenvalues of the covariance matrix .",
    "we can see that the real fission of the club network is exactly revealed by the signs of the components in the eigenvector corresponding to the most positive eigenvalue . as to the eigenvector corresponding to the most negative one ,",
    "its components divide the nodes into two groups with many connections lying between them , reflecting the so - called anticommunity structure .    besides the eigenvector corresponding to the most positive eigenvalue , other eigenvectors corresponding to positive eigenvalues can also be utilized to reveal the community structure of network .",
    "specifically , the components of the first @xmath61 eigenvectors are used to represent the nodes of network into @xmath61-dimensional vectors and the community structure is then uncovered through clustering the node vectors using , for example , the @xmath62-means clustering method .",
    "we have known that the original description of network topology , i.e. , eq .",
    "( [ eq1 ] ) and eq .",
    "( [ eq2 ] ) , actually uses a set of standard bases . with respect to this set of bases ,",
    "the @xmath4th node of network is represented with the coordinate vector @xmath15 whose elements are both @xmath5 but the @xmath4th one being @xmath2 .",
    "the columns of the normalized eigenvector matrix @xmath52 constitute another set of orthogonal bases , which can be obtained from the standard bases through the _ rotation _ transformation , i.e. , multiplying the standard bases with @xmath63 from the left - hand side . with respect to this new bases ,",
    "the coordinate vector of the @xmath4th node can be represented by @xmath64 , which is the projection of the original coordinate vector on the new set of bases .",
    "mathematically , the @xmath4th projected node vector @xmath65 can be denoted by @xmath66_{_{j}}=u_{ij}.\\nonumber\\ ] ] note that the covariances along different new axis direction @xmath67 between the data @xmath26 and @xmath27 vary , characterized by @xmath68 thus , for the purpose of clustering the node vectors , it is more appropriate to represent the @xmath4th node with a node vector @xmath65 with its @xmath3th component being @xmath66_{_{j}}=\\sqrt{\\lambda_{j}}u_{ij}.\\label{eq8}\\ ] ] for negative eigenvalues , the corresponding components of the node vector are complex numbers .",
    "using eq .",
    "( [ eq8 ] ) , we can partition the nodes of network into communities through clustering the node vectors @xmath65 using the @xmath62-means clustering method .",
    "however , only the eigenvectors corresponding to positive eigenvalues make positive contribution to the community structure .",
    "furthermore , the eigenvectors corresponding to the small positive eigenvalues are less significant to uncover the community structure of network .",
    "this poses a challenging problem , i.e. , the choice of the number of eigenvectors .    intuitively , as for the goal of identifying the community structure , all the eigenvectors corresponding to positive eigenvalues provide certain relevant information .",
    "this means that the number of positive eigenvalues gives an upper bound on the number of eigenvectors used . as a kind of mesoscopic structure of network",
    ", however , the community structure provides a coarse - grained description of the network topology .",
    "only the most significant structural features are maintained and the less ones are neglected . now",
    "the tricky problem is how to determine the significant ones . in this article",
    ", this problem is equivalent to the choice of the significant eigenvectors .",
    "we have known that the magnitudes of eigenvalues characterize the covariance between the data @xmath26 and @xmath27 along the direction of the corresponding eigenvectors .",
    "thus we can choose the number of significant eigenvectors according to the magnitude of eigenvalues .",
    "intuitively , the eigenvectors corresponding to larger positive eigenvalues are desired .",
    "furthermore , a large eigengap , i.e. , interval between two successive eigenvalues , provides an effective indicator to determine the appropriate number of significant eigenvectors .",
    "similar methods have been adopted in other contexts taking the advantage of the eigengap of many other types of matrix , including the adjacency matrix  @xcite , the transition matrix  @xcite , the laplacian matrix  @xcite , the modularity matrix  @xcite and the normalized laplacian matrix  @xcite .",
    "more importantly , the choice of eigenvectors with different significance levels determines the different scale of community structure .",
    "the existence of a significant scale is indicated by the occurrence of a larger eigengap in the spectrum of the covariance matrix .",
    "another important problem is the choice of the number of communities . according to eq .",
    "( [ eq8 ] ) , we know that each node of network can be represented by a @xmath61-dimensional node vector through projecting its standard coordinate vector on the directions of the @xmath61 significant eigenvectors",
    ". then the identification of community structure becomes a problem of partitioning the node vectors into groups .",
    "according to  @xcite , the number of communities is one greater than the number of orthogonal dimensions to represent these vectors , i.e. , @xmath69 is the appropriate number of community when the top @xmath61 eigenvector is adopted to obtain the projected node vectors .     the spectrum of the covariance matrix .",
    "left panel : the zachary s karate club network ; right panel : the h13 - 4 network.,scaledwidth=48.0% ]    taking the zachary s karate club network as example again , we illustrate the effectiveness of the eigengap at determining the number of significant eigenvectors and accordingly the number of communities .",
    "as shown in fig .",
    "[ fig2 ] ( left panel ) , the largest eigengap ( only the ones between positive eigenvalues are considered ) occurs between the first and second largest eigenvalues .",
    "it indicates that it is appropriate to choose only the first eigenvector and the number of communities is @xmath70 .",
    "furthermore , the resulting two communities exactly reflect the real split of the network in fig .",
    "in addition , besides the largest eigengap , two other relative larger eigengaps can be observed , one being between the second and the third eigenvalues , and the other being between the third and the forth eigenvalues . the resulting partition according to these two eigengaps are also depicted in fig .",
    "[ fig1 ] , one dividing the network into three communities separated using dashed curves , and the other dividing the network into four communities differentiated by colors .",
    "these two partitions are often the results of many community detection methods .",
    "although they are not identical to the real split of the network , they reveal certain relevant topological feature of the network at alternative scales .",
    "actually , as to a network with multi - scale community structure , each scale corresponds to a large eigengap in the spectrum of the covariance matrix .",
    "thus we can identify the multi - scale community structure using the top eigenvectors indicated by these eigengaps . as an example",
    ", we illustrate the identification of the multi - scale community structure of the h13 - 4 network , which is constructed according to  @xcite .",
    "the network has two predefined hierarchical levels .",
    "the first hierarchical level consists of @xmath71 groups of @xmath72 nodes and the second hierarchical level consists of @xmath73 groups of @xmath73 nodes . on average",
    ", each node has @xmath74 edges connecting to the nodes in the same group at the second hierarchical level and has @xmath71 edges connecting to the nodes in the same group at the first hierarchical level .",
    "this explains the name of such kind of networks .",
    "in addition , the average degree of each node is @xmath75 . according to the construction rules of the h13 - 4 network ,",
    "the two hierarchical levels constitute the different topological description of the community structure of the h13 - 4 network at different scales . as shown in fig .",
    "[ fig2 ] ( right panel ) , the largest eigengap occurs between the @xmath76th and @xmath73th largest eigenvalues , indicating that the community structure at the most significant scale corresponds to the partition dividing the nodes into @xmath73 groups .",
    "actually , the resulting communities are exactly the predefined @xmath73 groups of @xmath73 nodes in the second hierarchical level . in addition",
    ", the second largest eigengap occurs between the third eigenvalue and the forth one , indicating that the second significant topological scale corresponds to the partition dividing the network nodes into @xmath71 groups . again",
    "the resulting communities are exactly the predefined @xmath71 groups of @xmath72 nodes in the first hierarchical level .",
    "the previous section shows that the spectrum of the covariance matrix provides an promising way to reveal the multi - scale community structure of network . note that , as to the example h13 - 4 network , the nodes have approximately the same degree and the communities at a specific scale are of the same size .",
    "however , the real world networks usually have heterogenous distributions of node degree and community size .",
    "thus it will be more convincing to test the covariance matrix on networks with heterogenous distributions of node degree and community size .",
    "( color online ) the clique circle network as a schematic example .",
    "each circle corresponds to a clique , whose size is marked by its label .",
    "the cliques labeled with @xmath77 are smaller cliques with the size @xmath78 , while the cliques labeled with @xmath79 are bigger cliques with the size @xmath80 . in this article , @xmath81 and @xmath82.,scaledwidth=40.0% ]",
    "before we give such a test in the subsequent section , using a schematic network , we first illustrate the ineffectiveness of the covariance matrix to deal with the heterogeneous distributions of node degree and community size .",
    "the schematic network is often called the clique circle network as depicted in fig .",
    "[ fig3 ] . generally speaking",
    ", the intrinsic community structure corresponds to the partition where each clique is taken as a community , that is , only one intrinsic scale exists in this network .",
    "however , as shown in fig .",
    "[ fig4 ] ( left panel ) , two scales are observed when we investigate the community structure of this network using the spectrum of the covariance matrix .",
    "one scale corresponds the intrinsic scale of the network , and the other corresponds to dividing the network nodes into @xmath83 groups , which is not desired .     the spectrum of the covariance matrix ( left panel ) and the correlation matrix ( right panel ) corresponding to the clique circle network depicted in fig .",
    "the horizontal axis shows the eigenvalues of matrix and the vertical axis represents the rank index of eigenvalues in descending order.,scaledwidth=48.0% ]    to address this problem , we reconsider the formulation of the covariance matrix in section  [ sec2 ] and the spectral analysis on the covariance matrix in section  [ sec3 ] . when formulating the covariance matrix from the data defined in eq .",
    "( [ eq1 ] ) and eq .",
    "( [ eq2 ] ) , the mean is subtracted off to place the data around the coordinate origin .",
    "this is the translation transformation .",
    "when using the eigenvectors of the covariance matrix as the new orthogonal bases instead of the standard bases , the rotation transformation is adopted .",
    "these two transformations , however , both do not take into account the difference amongst the variances of the original dimensions each corresponding to a node .",
    "thus the spectrum of the covariance matrix fails to deal with the heterogeneous distribution of node degree and community size .",
    "fortunately , the possible remedy is also right here , i.e. , the rescaling transformation . through introducing the rescaling transformation into the covariance matrix",
    ", we obtain a correlation matrix , which can be formulated as @xmath84 where @xmath85 is a diagonal matrix with its diagonal elements @xmath86 being the empirical variance of the data @xmath13 along the @xmath4th standard axis direction and @xmath87 is a diagonal matrix with its diagonal elements @xmath88 being the empirical variance of the data @xmath14 along the @xmath3th standard axis direction . specifically , the elements of @xmath89 are defined as @xmath90    compared with the covariance matrix , the correlation matrix has two advantages at identifying the multi - scale community structure . on one hand , the correlation matrix can well deal with the heterogeneous distribution of node degree and community size . as shown in fig .",
    "[ fig4 ] ( right panel ) , the intrinsic scale of the clique circle network is correctly revealed by the spectrum of the correlation matrix . on the other hand , the eigenvalues of the correlation matrix",
    "themselves can provide intuitive judgements for the cohesiveness within communities and the looseness of connections among different communities . as shown in fig .",
    "[ fig4 ] , the eigenvalues lying the greater side of the largest eigengap all approach @xmath2 .",
    "this indicates that the intrinsic communities are very cohesive .",
    "meanwhile , other eigenvalues are very small , indicating the loose connectivity among these communities .",
    "specifically , through introducing the rescaling transformation into the covariance matrix , the eigenvalues of the correlation matrix are rescaled .",
    "thus , besides the eigengaps among successive eigenvalues , the eigenvalues themselves also provide indicative information of the community structure of network .",
    "this is especially important for the networks without significant topological scale . for these networks ,",
    "the eigengaps of the covariance matrix or the correlation matrix both fail to provide obvious evidence for the number of intrinsic communities . without the rescaling transformation ,",
    "the magnitude of the covariance matrix is influenced by the network size and the distribution of node degree .",
    "thus the magnitude itself can not provide useful information to determine the cohesiveness of the detected communities .",
    "as to the correlation matrix , however , the magnitude of the eigenvalues of the correlation matrix has been rescaled and thus can provide intuitive knowledge about the cohesiveness of communities and then can help us choose the desired scale with respect to specific application demands .",
    "more importantly , the eigenvalues of the correlation matrix can be compared among different networks due to that they are rescaled and thus not influenced by the network size . in the subsequent section",
    ", the effectiveness of the correlation matrix will be further demonstrated through extensive tests on artificial benchmark networks and real world networks .",
    "now we clarify the implication of the correlation matrix to the widely - used benefit function modularity for network partition .",
    "as shown in  @xcite , the modularity matrix ( the biased version of the covariance matrix used in this article ) underlies the benefit function modularity and the optimization of the modularity can be carried out using the eigenvectors of the modularity matrix . in this article",
    ", we propose to uncover the community structure using the eigenvectors of the correlation matrix , which is obtained through introducing the rescaling transformation into the covariance matrix . in this way",
    ", the benefit function for network partition actually changes .",
    "specifically , the correlation matrix provides us another benefit function for network partition .",
    "this benefit function can be formulated as @xmath91 where @xmath92 denotes a community , and @xmath93 if node @xmath4 belongs to the community @xmath92 and @xmath5 otherwise .",
    "on one hand , the benefit function @xmath94 can be directly optimized to uncover the community structure similar to the role of the modularity . on the other hand ,",
    "the rationale behind @xmath94 and the modularity are somewhat different .",
    "it is well known that the success of the modularity is partly from its considering the difference between the actual weight of the edge connecting node @xmath4 and @xmath3 and the expected weight of the edge by chance characterized usually using a null model , e.g. the configuration model . in this way",
    ", the modularity takes into account the effects from the heterogeneous node degrees .",
    "however , the difference of the variance associated with each node dimension is not taken into account in the definition of modularity .",
    "thus the modularity may be blind to smaller communities when the network has heterogeneous distribution of node degree and community size .",
    "this problem roots in the heterogeneity of network rather than the existence of an intrinsic scale ( usually depends on the size of network ) causing the resolution limit problem  @xcite of modularity in the definition of modularity .",
    "this heterogeneity - caused problem can be well dealt with by the new benefit function @xmath94 since that the underlying correlation matrix takes into account the rescaling transformation besides the translation transformation and the rotation transformation utilized in the the definition of modularity . in summary , it is inadequate to only consider the heterogeneous node degree through using a reference null model as done by the modularity . a rescaling transformation is required to combat such a drawback facing the modularity .",
    "in this section , we empirically demonstrate the effectiveness of the multi - scale community detection methods based on the spectrum of the covariance matrix and the correlation matrix through tests on the artificial benchmark networks .",
    "in addition , we apply the correlation matrix method on a variety of real world networks .",
    "we utilize the benchmark proposed by lancichinetti _",
    "et al _ in  @xcite .",
    "this benchmark provides networks with heterogeneous distributions of node degree and community size .",
    "thus it poses a much more severe test to community detection algorithms than standard benchmarks .",
    "many parameters are used to control the generated networks in this benchmark : the number of nodes @xmath95 , the average node degree @xmath96 , the maximum node degree max@xmath97{0.15cm}{0.3pt}k$ ] , the mixing ratio @xmath98 , the exponent @xmath99 of the power law distribution of node degree , the exponent @xmath100 of the power law distribution of community size , the minimum community size min@xmath97{0.15cm}{0.3pt}c$ ] , and the maximum community size max@xmath97{0.15cm}{0.3pt}c$ ] . in our tests , we use the default parameter configuration where @xmath101 , @xmath102 , max@xmath97{0.15cm}{0.3pt}k=50 $ ] , min@xmath97{0.15cm}{0.3pt}c=20 $ ] , and max@xmath97{0.15cm}{0.3pt}c=50 $ ] . to test the influence from the distribution of node degree and community size , we adopt four parameter configurations for @xmath99 and @xmath100 , respectively being @xmath103 , @xmath104 , @xmath105 and @xmath106 . by tuning the mixing ratio @xmath98 , we test the effectiveness of our method on the networks with different fuzziness of communities .",
    "the larger the parameter @xmath98 , the fuzzier the community structure of the generated network .",
    "in addition , we adopt the normalized mutual information ( nmi )  @xcite to compare the partition found by community detection methods with the answer partition . the larger the nmi , the more effective the tested method .",
    "( color online ) comparison between the correlation matrix and the covariance matrix in terms of their effectiveness at identifying the number of communities on benchmark networks with different parameter configurations . for each parameter configuration",
    ", @xmath107 generated networks are used.,scaledwidth=48.0% ]    ( color online ) comparison between the correlation matrix and the covariance matrix in terms of their effectiveness at identifying the community structure on benchmark networks with different parameter configurations .",
    "each point corresponds to an average over @xmath107 network realizations.,scaledwidth=48.0% ]    note that each benchmark network has only one intrinsic topological scale according to the construction rules .",
    "thus we only consider the largest eigengap in the spectrum of the covariance matrix and the correlation matrix .",
    "the communities are identified using the top @xmath61 eigenvectors corresponding to the eigenvalues lying the greater side of the largest eigengap .",
    "specifically , the top @xmath61 eigenvectors are projected into the node vectors according to eq .",
    "( [ eq8 ] ) , and then the communities are identified through clustering these node vectors using the @xmath62-means clustering method . note that the community number is @xmath69 .",
    "the first test focuses on whether the intrinsic scale can be correctly uncovered .",
    "we investigate this problem through judging whether the number of intrinsic communities can be correctly identified .",
    "[ fig5 ] shows the comparison between the correlation matrix and the covariance matrix ( identically the modularity matrix ) on networks with four different parameter configurations for @xmath99 and @xmath100 . when the community structure is evident , i.e. , the mixing ratio @xmath98 is smaller , both the covariance matrix and the correlation matrix are effective at identifying the correct number of communities and thus the intrinsic scale of the network .",
    "however , when the community structure becomes fuzzier with the increase of the mixing ratio @xmath98 , the performance of the covariance matrix deteriorates while the correlation matrix still achieves rather good results .",
    "even when the mixing ratio @xmath98 is larger than @xmath108 , the border beyond which communities are no longer defined in the strong sense  @xcite , the number of communities can still be accurately identified by investigating the spectrum of the correlation matrix .",
    "the second test turns to whether the intrinsic community structure can be identified .",
    "as demonstrated by the first test , the correlation matrix outperforms the covariance matrix at finding the correct number of communities .",
    "however , as to the second test , we assume that the community number has been given _ a priori _ and then we compare the effectiveness of the eigenvectors of these two matrices in terms of the nmi when comparing the answer partitions with the ones obtained by the methods based on these two matrices . as shown in fig .",
    "[ fig6 ] , these two matrices both exhibit very good performance at identifying the intrinsic community structure . by comparison",
    ", the correlation matrix outperforms the covariance matrix for all used parameter configurations .",
    "this indicates that the eigenvectors of the correlation matrix characterize the spread characteristics of network nodes better than that of the covariance matrix , especially when the community structure is fuzzier .      in the previous subsection",
    ", we have demonstrated that the correlation matrix is superior to the covariance matrix at uncovering the intrinsic topological scale of the artificial benchmark networks .",
    "now we apply the method based on the correlation matrix on real world networks .",
    "these networks are widely used to evaluate community detection methods .",
    "these networks include the zachary s karate club network  @xcite , the journal index network constructed in  @xcite , the social network of dolphin by lusseau _",
    "@xcite , the college football network of the united states  @xcite , the match network of the nba teams , the network of political books  @xcite , the network of jazz musician  @xcite , the coauthor network of network scientist presented in  @xcite , and the email network of urv  @xcite . for convenience ,",
    "these networks are respectively abbreviated to _ zachary _ , _ journal _ , _ dolphin _ , _ football _ , _ nba _ , _ polbook _ , _ jazz _ , _ netsci _ and _ email_. the test results on these networks are shown in fig .",
    "[ fig7 ] .",
    "( color online ) tests on real world networks .",
    "the vertical axis represents the length of the eigengap and the horizontal axis represents the the corresponding community number indicated by the eigengap .",
    "the shaded - circles mark the largest eigengap .",
    "note that , in order to identify the community structure , only the eigengaps between positive eigenvalues are taken into account .",
    "the vertical dashed lines are the place where the zero - valued eigenvalues occur.,scaledwidth=48.0% ]    as shown in fig .",
    "[ fig7 ] , the eigengaps of the correlation matrix are very effective at the identification of the community number and accordingly the intrinsic scale of the network . for most of these networks with known community structure , the correlation matrix can accurately uncover such community structure including the networks _ journal _ , _ dolphin _ , _ nba _ and _",
    "polbook_. for the other networks , the correlation matrix also gives very promising results for their community structure .",
    "specifically , the detected communities reflect the structural and functional characteristics of each specific network , which can be verified through checking the nodes of each community .",
    "in addition , for the last three networks , large eigengaps can be observed among the negative eigenvalues .",
    "this indicates that these networks contain anticommunity structure .",
    "actually , this phenomenon is also observed in many other real world networks , which are not included in this article .",
    "this will be discussed in our further work .",
    "in addition , we also test our method on some real world complex networks with larger size , including the protein interaction network and the word association network .",
    "however , no significant eigengap is observed in the spectrum of the covariance matrix and the correlation matrix associated with these networks .",
    "this indicates that there is no scale which is significantly superior to other scales and thus no partition of network is more desired .",
    "different from the eigenvalues of the covariance matrix , however , besides the length of the eigengaps among eigenvalues , the magnitude itself of the eigenvalues of the correlation matrix can provide us intuitive knowledge on the cohesiveness of the communities at each specific scale .",
    "generally speaking , an eigenvalue larger than @xmath108 indicates the existence of a cohesive node group , i.e. , a community .",
    "thus , according to the magnitude of eigenvalues , people can choose the topological scale or partition of network which is appropriate for their application and practical demands .",
    "in this article , we have studied the problem of detecting the multi - scale community structure in networks from the perspective of dimension reduction , i.e. , from the straightforward description taking each node as one dimension to a coarse - grained description where each dimension corresponds to a community .",
    "the main contributions of this article are as follows .",
    "firstly , the covariance matrix of network is defined to characterize the relationship between original node dimensions through the translation transformation .",
    "the covariance matrix is shown to be the unbiased version of the traditional modularity matrix , which underlies the benefit function of network partition , namely modularity . secondly ,",
    "using the rotation transformation , we recognize several reduced dimensions which are significant at reflecting the community structure of network . taking these reduced dimensions as new axis vectors , the multi - scale community structure",
    "is then identified through investigating the spectrum of the covariance matrix and projecting the nodes of network into low - dimensional node vectors .",
    "thirdly , to deal with the heterogeneous distributions of node degree and community size , the correlation matrix is proposed through introducing the rescaling transformation into the covariance matrix .",
    "extensive tests on real world and artificial networks demonstrate that the correlation matrix significantly outperforms the covariance matrix or the modularity matrix as regards revealing the multi - scale community structure of network .",
    "note that the computational efforts of the correlation matrix are essentially identical to the modularity matrix .",
    "thus we suggest to use the correlation matrix and accordingly the benefit function @xmath94 to detect the multi - scale community structure of network , especially when the network has heavily heterogeneous distribution of node degree and community size .",
    "we also hope that the readers feel encouraged to apply the correlation matrix to other real world networks and we look forward to seeing the more efficient heuristic methods to optimize the benefit function @xmath94 .",
    "in addition , we also notice that no significant scale is observed in several real world complex networks . in this case , the covariance matrix or the modularity matrix fails to provide obvious evident about the community structure .",
    "however , since the magnitude itself of the eigenvalues of the correlation matrix has indicative meaning about the cohesiveness of communities , the correlation matrix can still be used to reveal the community structure .    finally , as to traditional spectral clustering methods , the normalized laplacian matrix is also been suggested to replace the standard laplacian matrix",
    ". the basic idea of the normalized laplacian matrix is consistent to the rescaling transformation introduced in this article .",
    "compared to the heuristic normalization transformation on the standard laplacian , the rescaling transformation in this article has solid theoretical foundation from the perspective of dimension reduction , for example , the principal component analysis .",
    "thus , the work in this article might provide insights to understand the spectral clustering methods and might have important implications to the clustering problem dealing with datasets with heterogeneous cluster size .",
    "this work was funded by the national natural science foundation of china under grant number @xmath109 and @xmath110 .",
    "the authors thank alex arenas , mark newman , santo fortunato , martin rosvall , and david lusseau for providing network and other data used in this paper .",
    "d. lusseau , k. schneider , o. j. boisseau , p. haase , e. slooten , and s. m. dawson , the bottlenose dolphin community of doubtful sound features a large proportion of long - lasting associations : can geographic isolation explain this unique trait ?",
    "sociobiol . _ * 54 * 396 ( 2003 ) ."
  ],
  "abstract_text": [
    "<S> empirical studies show that real world networks often exhibit multiple scales of topological descriptions . </S>",
    "<S> however , it is still an open problem how to identify the intrinsic multiple scales of networks . in this article </S>",
    "<S> , we consider detecting the multi - scale community structure of network from the perspective of dimension reduction . according to this perspective </S>",
    "<S> , a covariance matrix of network is defined to uncover the multi - scale community structure through the translation and rotation transformations . </S>",
    "<S> it is proved that the covariance matrix is the unbiased version of the well - known modularity matrix . </S>",
    "<S> we then point out that the translation and rotation transformations fail to deal with the heterogeneous network , which is very common in nature and society . to address this problem , </S>",
    "<S> a correlation matrix is proposed through introducing the rescaling transformation into the covariance matrix . </S>",
    "<S> extensive tests on real world and artificial networks demonstrate that the correlation matrix significantly outperforms the covariance matrix , identically the modularity matrix , as regards identifying the multi - scale community structure of network . </S>",
    "<S> this work provides a novel perspective to the identification of community structure and thus various dimension reduction methods might be used for the identification of community structure . through introducing the correlation matrix , </S>",
    "<S> we further conclude that the rescaling transformation is crucial to identify the multi - scale community structure of network , as well as the translation and rotation transformations . </S>"
  ]
}