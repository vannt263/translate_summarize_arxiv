{
  "article_text": [
    "fifth - generation ( 5 g ) mobile communication systems are expected to achieve a @xmath0-fold increase in capacity , a @xmath1-fold increase in spectral and energy efficiencies , and a @xmath2-fold increase in average cell throughput @xcite .",
    "such significant enhancements can be achieved with large - scale multiple - input multiple - output ( mimo ) antenna systems , which are also referred to as `` massive mimo '' systems , e.g. , @xcite .",
    "these systems employ hundreds , or even thousands , of antennas at base stations ( bss ) to serve tens or hundreds of user terminals with the same time  frequency resources . as such , array gains",
    "are expected to grow infinitely with the number of antennas at the bss , in which case the radiated energy efficiency increases dramatically and multiuser interference is eliminated completely .    however , the high dimensionality of massive mimo systems considerably increases hardware cost and power consumption . in particular , the hardware complexity and power consumption of analog - to - digital converters ( adcs ) increase exponentially with the number of bits per sample @xcite and",
    "thus present a major obstacle .",
    "this drawback has motivated the use of low - cost low - precision adcs ( e.g. , @xmath3 bits ) for antennas , which has resulted in _",
    "quantized _ mimo systems .",
    "bits are used in modern communication systems to process received signals in the digital domain . in this paper ,",
    "the `` quantized '' mimo system specifically represents a mimo system equipped with very low - precision adcs ( e.g. , @xmath3 bits ) .",
    "] such coarse quantization leads to the failure of all communication theories , as well as signal processing techniques dedicated to high - resolution quantization @xcite .",
    "some aspects of quantized mimo systems have been studied in the literature on capacity analysis @xcite , energy efficiency analysis @xcite , feedback codebook design @xcite , data detection @xcite , and channel estimation @xcite .",
    "the current work is focused on data detection and channel estimation for quantized mimo systems .",
    "previous studies on these subject mainly assumed perfect channel state information ( csi ) at the receiver ( csir ) or considered problems in channel estimation .",
    "the use of coarse quantization greatly reduces the number of _ effective _ measurements and hinders the easier acquisition of csir in quantized mimo systems than in unquantized ones .",
    "as explained in @xcite , a one - bit quantized mimo system requires an extremely long training sequence ( e.g. , approximately @xmath4 times the number of users ) to achieve the same performance as that in a full csi case .",
    "this requirement motivates us to consider joint channel - and - data ( jcd ) estimation , in which the estimated payload data are utilized to aid channel estimation .",
    "a major advantage of jcd estimation is that relatively few pilot symbols are required to achieve equivalent channel and data estimation performances @xcite .",
    "although an improved performance with the jcd technique is expected , its performance in _ quantized _ mimo systems is not clearly understood .",
    "the most related work appears to be that in @xcite , which investigated the achievable throughput in a one - bit quantized single - input single - output ( siso ) channel using jcd estimation ( i.e. , least squares channel estimation jointly on pilot and data symbols ) .",
    "for the one - bit quantized mimo system in @xcite , the authors considered a pilot - only scheme with least - squares channel estimation , followed by data detection that utilizes the maximal - ratio combining .",
    "although high - order constellation , such as 16-qam , was found to be capable of being supported by the one - bit quantized mimo system , which outperforms the ones reported in @xcite for qpsk , the long training sequence is still a requirement .",
    "hence , the fundamental performance limits on quantized mimo systems imposed by the jcd estimation represents an interesting research topic .    in the present work , we propose a framework for analyzing the achievable performance of quantized mimo systems with jcd estimation . unlike other jcd estimation schemes based on suboptimal criteria @xcite , the bayes - optimal inference for jcd estimation is used in this work because this approach generates minimum mean square errors ( mmses ) with respect to ( w.r.t . ) the channels and data symbols . in the conference version of this work @xcite , our simulation results indicate that the bayes - optimal jcd estimator exhibits a significant advantage over pilot - only schemes in quantized mimo systems .",
    "in addition to the derivations omitted in @xcite , the main contributions of this work are summarized as follows .",
    "* to implement the bayes - optimal jcd estimator , we use a variant of belief propagation ( bp ) in approximating the marginal distributions of each data and channel component .",
    "we modify the bilinear generalized approximate message passing ( big - amp ) algorithm in @xcite and adapt it to the quantized mimo system by providing the corresponding closed - form expressions for the nonlinear steps .",
    "we refer to this scheme as the gamp - based jcd algorithm . * by performing a large - system analysis based on the replica method from statistical physics , we show the _ decoupling principle _ for the bayes - optimal jcd estimator .",
    "that is , in the large - system regime , the input output relationship of a quantized mimo system using the bayes - optimal jcd estimator is decoupled into a bank of scalar additive white gaussian noise ( awgn ) channels w.r.t .  the data symbols and channel response .",
    "this decoupling property allows the characterization of several system performances of interest in an intuitive manner .",
    "in particular , the average symbol error rate ( ser ) w.r.t .",
    "the data symbols and the average mse w.r.t .  the channel estimate for the bayes - optimal jcd estimator are determined . *",
    "finally , computer simulations are performed to verify the efficiency of the proposed gamp - based jcd algorithm and the accuracy of our analysis .",
    "the high accuracy of our results ensures the quick and efficient evaluation of the performances of quantized mimo systems .",
    "several useful observations related to system design are derived from the analysis .",
    "_ notations_throughout , for any matrix @xmath5 , @xmath6 refers to the @xmath7th entry of @xmath5 , @xmath8 denotes the transpose of @xmath5 , @xmath9 is the conjugate transpose of @xmath5 , and @xmath10 denotes its trace .",
    "also , @xmath11 denotes the identity matrix , @xmath12 is the zero matrix , @xmath13 denotes the frobenius norm , @xmath14 $ ] represents the expectation operator , @xmath15 is the natural logarithm , and @xmath16 is the signum function .",
    "in addition , a random vector @xmath17 drawn from the proper complex gaussian distribution of mean @xmath18 and covariance @xmath19 is described by the probability density function : @xmath20 where @xmath21 returns the determinant .",
    "we write @xmath22 . with @xmath23 denoting the real ( or complex ) gaussian integration measure , for an @xmath24 real valued vector @xmath17 , we have @xmath25 or @xmath26 for the complex valued vector , where @xmath27 and @xmath28 extracts the real and imaginary components , respectively .",
    "finally , @xmath29 denotes the cumulative gaussian distribution function @xcite .",
    "we consider a mimo uplink system in which a bs is equipped with @xmath30 receive antennas serving @xmath31 single - antenna users . the channel is assumed to be flat block fading , wherein the channel remains constant over @xmath32 consecutive symbol intervals ( i.e. , a block ) .",
    "the received signal @xmath33 \\in { { \\mathbb c}}^{n \\times t}$ ] over the block interval can be written in matrix form as @xmath34 where @xmath35 \\in { { \\mathbb c}}^{k \\times t}$ ] denotes the transmit symbols in the block , @xmath36\\in { { \\mathbb c}}^{n \\times k}$ ] denotes the channel matrix containing the fading coefficients between the transmit antennas and the receive antennas , @xmath37\\ \\in { { \\mathbb c}}^{n \\times t}$ ] represents the additive temporally and spatially white gaussian noise with zero mean and element - wise variance @xmath38 , and we define @xmath39 \\triangleq \\frac{1}{\\sqrt{k}}{{\\bf h}}{{\\bf x}}\\in { { \\mathbb c}}^{n \\times t}$ ] .    on the receiver side ,",
    "each received signal is down - converted into analog baseband @xmath40 and then discretized using a _ complex - valued _",
    "quantizer @xmath41 , as illustrated in figure [ fig : quantizedmimo ] . here",
    ", each complex - valued quantizer @xmath42 is defined as @xmath43 , i.e. , the real and imaginary parts are quantized separately . in practice ,",
    "a variable gain amplifier ( vga ) with an automatic gain control ( agc ) is used before the quantization to ensure that the analog baseband is within a proper range , e.g. , @xmath44 .",
    "analog baseband @xmath40 is assumed to include the agc gain and is thus in a proper range .",
    "the resulting quantized signal @xmath45 \\in { { \\mathbb c}}^{n \\times t}$ ] is therefore given by @xmath46 where the quantization is applied element - wise .    specifically , each complex - valued quantizer @xmath41 consists of two real - valued @xmath47-bit quantizers @xmath48 .",
    "each real - valued quantizer maps a real - valued input to one of the @xmath49 bins , which are characterized by the set of @xmath50 thresholds @xmath51 $ ] , such that @xmath52 . for notational convenience ,",
    "we define @xmath53 and @xmath54 .",
    "the output is assigned a value in @xmath55 $ ] when the quantizer input falls in the interval @xmath55 $ ] ( namely , the @xmath56-th bin ) . for example , the threshold of a typical uniform quantizer with the quantization step size @xmath57 is given by @xmath58 and the quantization output is assigned the value @xmath59 when the input falls in the @xmath56-th bin .. if @xmath60 , the quantization output is assigned the value @xmath61 . ]",
    "figure [ fig : quantizedmimo ] shows an example of the @xmath62-bit uniform quantizer .",
    "notice that in practice , the vga gain can be adjusted to attain the desired step size @xmath57 .",
    "the channel matrix @xmath63 needs to be estimated at the receiver ; thus , the first @xmath64 symbols of the block of @xmath32 symbols serve as the pilot sequences .",
    "the remaining @xmath65 symbols are used for data transmissions .",
    "the training and data phases are referred to as @xmath66-phase and @xmath67-phase , respectively .",
    "this setting is equivalent to partitioning @xmath68 and @xmath69 as    @xmath70,~\\mbox{with $ { { \\bf x}}_{{{\\sf t } } }   \\in { { \\mathbb c}}^{k\\times t_{{{\\sf t } } } } $ , $ { { \\bf x}}_{{{\\sf d } } }   \\in { { \\mathbb c}}^{k \\times t_{{{\\sf d } } } } $ , } \\\\",
    "{ { \\widetilde{{{\\bf y}}}}}&= \\big[{{\\widetilde{{{\\bf y}}}}}_{{{\\sf t}}}~{{\\widetilde{{{\\bf y}}}}}_{{{\\sf d } } } \\big],~\\mbox{with $ { { \\widetilde{{{\\bf y}}}}}_{{{\\sf t } } }   \\in { { \\mathbb c}}^{n \\times t_{{{\\sf t } } } } $ , $ { { \\widetilde{{{\\bf y}}}}}_{{{\\sf d } } }   \\in { { \\mathbb c}}^{n \\times t_{{{\\sf d } } } } $ } .\\end{aligned}\\ ] ]    we assume that @xmath71 ( or @xmath72 ) is composed of independent and identically distributed ( i.i.d . ) random variables @xmath73 ( or @xmath74 ) drawn from the known probability distribution @xmath75 ( or @xmath76 ) , i.e. , @xmath77 given that the pilot and data symbols should appear on constellation points uniformly , the ensemble averages of @xmath78 and @xmath79 are assumed to be zero .",
    "in addition , we let @xmath80 and @xmath81 be the transmit powers in the @xmath66-phase and @xmath67-phase , respectively , i.e. , @xmath82 and @xmath83 . for ease of notation , we refer an entry of @xmath68 to @xmath84 instead of @xmath85 or @xmath86 .",
    "therefore , we use @xmath87 and @xmath88 to denote the sets of symbol indices in the @xmath66-phase and @xmath67-phase , respectively .",
    "similarly , we assume that each entry @xmath89 is drawn from a complex gaussian distribution @xmath90 , where @xmath91 is the large - scale fading coefficient .",
    "if @xmath92 , then @xmath93 to prevent the key features of our results from being obfuscated by complex notations , we consider the case in which all the users have the same large - scale fading factor in the main text .",
    "a generalized version of our main result , in which the users have different large - scale fading factors , is presented in appendix e. this generalization can be easily achieved by plugging user index @xmath94 into @xmath91 .",
    "we consider the case in which the receiver knows the distributions of @xmath63 and @xmath68 but not their realizations . in the conventional pilot - only",
    "scheme , the receiver first uses @xmath95 and @xmath71 to generate an estimate of @xmath63 and then uses the estimated channel for estimating data @xmath72 from @xmath96 @xcite .",
    "in contrast to the pilot - only scheme , we consider jcd estimation , where the bs estimates both @xmath63 and @xmath72 from @xmath97 given @xmath71 . we will treat the problem under the framework of bayesian inference , which provides a foundation for achieving the best mse estimates @xcite .",
    "we define the likelihood , i.e. , the distribution of the received signals under ( [ eq : qsys ] ) conditional on the unknown parameters , as @xmath98 where @xmath99 when @xmath100}$ ] and @xmath101}$ ] . based on the cumulative gaussian distribution function ( see the definition in notations ) , ( [ eq : lnkelihood_each ] ) becomes @xmath102 where @xmath103 the prior distributions of @xmath68 and @xmath63 are given by ( [ eq : prox ] ) and ( [ eq : proh ] ) , respectively .",
    "the posterior probability can then be computed according to bayes rule as @xmath104 where @xmath105 is the marginal likelihood .",
    "given the posterior probability , an estimator for @xmath89 can be obtained by the posterior mean @xmath106 where @xmath107 denotes the marginal posterior probability of @xmath89 . in ( [ eq : esth ] ) , the notation @xmath108 denotes the integration over all the variables in @xmath63 except for @xmath89 .",
    "similarly , the estimator for @xmath109 for @xmath110 can be obtained by the posterior mean @xmath111 where @xmath112 is the marginal posterior probability of @xmath109 .",
    "the notation @xmath113 denotes the integration over all the variables in @xmath68 except for @xmath109 .",
    "the posterior mean estimators ( [ eq : esth ] ) and ( [ eq : estx ] ) minimize the ( bayesian ) mse @xcite defined as    [ eq : msehx ] @xmath114    where the expectation operator is w.r.t .",
    "@xmath115 ; moreover , @xmath116 $ ] and @xmath117 $ ] .",
    "we refer to ( [ eq : esth ] ) and ( [ eq : estx ] ) as the bayes - optimal estimator .    [ remark_1 ] given a _",
    "known _ pilot matrix , @xmath118 , which by definition is given by @xmath119 , we obtain @xmath120 from ( [ eq : estx ] ) ; therefore , @xmath121 . for the case of interest",
    ", we always have @xmath121 .",
    "the algorithm as well as the analytical results still work even if the pilots are unknown , and the mse can be expressed as ( [ eq : msex ] ) .      to better understand the bayes - optimal estimator , we first explain it in a simple siso system .",
    "we consider a siso version of the system ( [ eq : sys ] ) given by @xmath122 recall that @xmath123 is the additive white gaussian noise with zero mean and variance @xmath124 . after a complex - valued quantizer",
    ", @xmath125 is obtained .",
    "based on the system model ( [ eq : sys ] ) , @xmath126 should be kept . however ,",
    "to facilitate interpretation , we first let @xmath127 be a random variable with distribution @xmath128 . according to bayes rule ( [ eq : posteriorpr ] ) , the posterior probability can be computed as @xmath129 where @xmath130 is the marginal likelihood .",
    "then , from ( [ eq : esth ] ) or ( [ eq : estx ] ) , the posterior mean estimator for @xmath127 is given by @xmath131    to specify the estimator , we further assume that @xmath127 is a proper complex gaussian with mean @xmath132 and variance @xmath133 , i.e. , @xmath134 .",
    "then , we derive the estimator ( [ eq : postest_z ] ) under the two channels , unquantized and quantized , in the following examples .",
    "* example  1 * ( unquantized channel ) . in this case",
    ", we have @xmath135 and @xmath136 . using these distributions ,",
    "we obtain @xmath137 where @xmath138 , and the second equality follows the _ gaussian reproduction property _",
    "* ( a.7 ) ) .",
    "] where @xmath139 , @xmath140 , and @xmath141 .",
    "] substituting ( [ eq : post_z_num ] ) into ( [ eq : margpost_z ] ) , we obtain @xmath142 the estimator ( [ eq : postest_z ] ) , which is the mean of @xmath143 after _ rearranging _ is determined as @xmath144 the mse of the estimator , which is the variance of @xmath143 , is @xmath145    * example  2 * ( quantized channel ) . if @xmath100}$ ] and @xmath101}$ ] , then the likelihood of the quantized measurement @xmath146 is given by ( [ eq : lnkelihood_each_simple ] ) .",
    "the calculation of the posterior mean and variance in the quantized channel is technical , but it basically follows a procedure similar to that in the unquantized channel . a derivation is given in appendix a , which turns out to yield @xmath147 where    [ eq : eta_def ] @xmath148",
    "the real and imaginary parts are quantized separately , and each complex - valued channel can be decoupled into two real - valued channels .",
    "the expressions ( [ eq : hatz_realgaussian ] ) and ( [ eq : msez_realgaussian ] ) are the estimators only for the real part of @xmath127 .",
    "to facilitate notation , we have abused @xmath146 and @xmath149 in ( [ eq : hatz_realgaussian ] ) and ( [ eq : msez_realgaussian ] ) to denote @xmath150 and @xmath151 , respectively .",
    "the estimator for the imaginary part @xmath152 can be obtained analogously as ( [ eq : hatz_realgaussian ] ) and ( [ eq : msez_realgaussian ] ) , while @xmath146 and @xmath56 should be replaced by @xmath153 and @xmath154 , respectively .",
    "recall @xmath155 and @xmath156 .",
    "therefore , if @xmath157 or @xmath158 , we obtain @xmath159 , @xmath160 , and @xmath161 . additionally , for the special case of @xmath162 ( i.e. , one - bit quantizer ) , the expressions of ( [ eq : hatz_realgaussian ] ) and ( [ eq : msez_realgaussian ] ) agree with those reported in @xcite .",
    "for another extreme case of @xmath163 and @xmath164 , we return to the unquantized channel in example 1 . instead of using the procedure in example 1 ,",
    "we show how the expressions ( [ eq : postest_z ] ) and ( [ eq : postest_z_var ] ) can be obtained from ( [ eq : hatz_realgaussian ] ) and ( [ eq : msez_realgaussian ] ) .",
    "recall that @xmath165 and @xmath166 are the upper and lower bin boundary positions w.r.t .",
    "the @xmath56-th bin , respectively .",
    "let @xmath167 and @xmath168 . as @xmath163 and @xmath164 , we obtain @xmath169 , which results in @xmath170 and @xmath171 . furthermore , we obtain @xmath172 , @xmath173 , and @xmath174 . by substituting these relationships into ( [ eq : hatz_realgaussian])([eq : msez_realgaussian ] ) and applying the facts that @xmath175 , @xmath176 , and @xmath177 , we recover the same expressions as those given in ( [ eq : postest_z ] ) and ( [ eq : postest_z_var ] ) for the real part of @xmath149 . the imaginary part for @xmath149",
    "can be obtained analogously .",
    "the aforementioned example is the estimator for @xmath127 .",
    "the same concept can be easily applied to the estimate of @xmath178 or @xmath179 , if @xmath127 is replaced by @xmath178 or @xmath179 in ( [ eq : example_sys ] ) . however , if @xmath126 and both @xmath178 and @xmath179 are unknown , the complexity of the bayes - optimal estimator increases . in this case",
    ", the posterior probability in ( [ eq : margpost_z ] ) becomes @xmath180 , which involves two prior distributions for @xmath178 and @xmath179 as that in ( [ eq : posteriorpr ] ) . to implement the posterior mean estimator for @xmath178 and @xmath179 , we need the marginal posterior probabilities @xmath181 and @xmath182 , respectively . a closed form for the posterior probability @xmath183 does not appear possible .",
    "although we can resort to numerical integration to implement the estimator , the computational complexity is high .",
    "therefore , one might consider an alternative technique ; that is , the estimate of @xmath178 is performed with fixed @xmath179 and vice versa .    in the next subsection",
    ", we develop a practical algorithm for the bayes - optimal estimator in the quantized mimo system . before proceeding",
    ", we intend to provide an intuition on the algorithm .",
    "a representation of the algorithm is shown in fig .  [",
    "fig : gamp - basedjcd ] , which seems to operate in the alternative manner .",
    "conceptually , when the posterior mean and variance of @xmath127 are obtained from the quantized observation @xmath146 , we can _ reconstruct _ @xmath184 and then approximate @xmath185 as a gaussian distribution . then , the posterior mean estimator for @xmath178 ( or @xmath179 ) can be conducted through @xmath184 , which is an _ awgn",
    "_ channel rather than a quantized channel , in an alternative manner .",
    "this representation is merely for an intuition .",
    "the accurate algorithm development takes a different route .",
    "from the discussions above , the direct computations of ( [ eq : esth ] ) and ( [ eq : estx ] ) are intractable because of the high - dimensional integrals in the marginal posteriors @xmath186 and @xmath187 . to make these tractable",
    ", we first note that by combining ( [ eq : prox])([eq : lnkelihood ] ) , the posterior probability ( [ eq : posteriorpr ] ) can be factored into @xmath188 an example factor graph for ( [ eq : postfg ] ) is shown in figure  [ fig : factorgraph ] , where a square represents a factor node associated with the sub - constraint function @xmath189 in ( [ eq : postfg ] ) , whereas a circle shows a variable node associated with @xmath89 , @xmath86 , or @xmath85 .",
    "the factor graph suggests the use of the canonical sum - product algorithm to compute the marginal posterior probabilities . the algorithm uses a set of message - passing equations that go from factor nodes to variable nodes and vice versa .",
    "however , the computational complexity of the sum - product algorithm remains infeasible in the case of interest because it still involves high - dimensional integration and summation .",
    "thus , we resort to recently developed approximation algorithms : the so - called amp ( approximate message - passing ) algorithm @xcite and the generalized amp ( gamp ) algorithm @xcite . in particular , the amp algorithm , which is a variant of the sum - product algorithm , was initially proposed by donoho _",
    "et al . _",
    "@xcite to solve a linear inverse problem in the context of compressive sensing .",
    "the use of gamp in our mimo system means that given @xmath63 is known ; thus , gamp can provide a tractable method to approximate the marginal posteriors @xmath186 s .",
    "this part corresponds to addressing the message - passing equations between @xmath190 and @xmath84 , i.e. , the left - hand side of figure  [ fig : factorgraph ] . for the study ,",
    "see @xcite . more recently ,",
    "et al . _  in @xcite",
    "applied a similar gamp strategy , referred to as big - amp , to the problem of reconstructing matrices from bilinear noisy observations ( i.e. , reconstructing @xmath63 and @xmath68 from @xmath191 ) .",
    "[ ago : bigamp - jcd ]    big - amp for jcd estimation is presented in algorithm [ ago : bigamp - jcd ] for a given instantiation of the quantized observations @xmath69 , the pilot matrix @xmath71 , as well as the likelihood @xmath192 , and the variable distributions @xmath193 and @xmath194 .",
    "we refer to this scheme as the gamp - based jcd algorithm , which follows the same structure as big - amp @xcite except for the steps in dealing with the known pilots , i.e. , @xmath195 in algorithm [ ago : bigamp - jcd ] .",
    "reference @xcite presents the derivation details of big - amp .    to better understand the algorithm",
    ", we provide some intuition on each step of algorithm [ ago : bigamp - jcd ] .",
    "[ fig : gamp - basedjcd ] illustrates the structure of the algorithm . in lines 36 , an estimate @xmath196}$ ] of the matrix product @xmath197 and the corresponding variances",
    "@xmath198 are estimated .",
    "@xmath199 } $ ] and @xmath200 in lines 3 and 4 can be regarded as auxiliary variables .",
    "is a plug - in estimate of @xmath201 , whereas @xmath202 $ ] provides a refinement by introducing the `` onsager '' correction into the context of amp . for details ,",
    "see @xcite . ] the same procedure is followed in lines 1 and 2 but for the matrix product @xmath203 .",
    "given that the pilot matrix @xmath71 is known , the corresponding variances for @xmath71 are zero , i.e. , @xmath204 for @xmath205 . with @xmath204 ,",
    "we thus have plugged @xmath206 and @xmath207 into @xmath208 and @xmath209 for @xmath210 to obtain lines 1 and 2 .",
    "the posterior means @xmath211 $ ] and variances @xmath212 of @xmath213 are obtained in lines 7 and 8 using @xmath214 .",
    "subsequently , the posterior moments are used in lines 9 and 10 to compute the residual @xmath215 $ ] and the inverse residual variances @xmath216 . in lines 11 and 12 ,",
    "these residual terms are used to compute @xmath217}$ ] and @xmath218 , where @xmath219 can be interpreted as an observation of @xmath86 under an awgn channel with zero mean and a variance of @xmath220 .",
    "similarly , @xmath221 $ ] and @xmath222 , where @xmath223 can be interpreted as an observation of @xmath89 under an awgn channel with noise variance of @xmath222 , are evaluated in lines 13 and 14 .",
    "finally , the posterior mean @xmath224 $ ] and variances @xmath225 are estimated in lines 15 and 16 by taking into account the prior @xmath76 ; the same is performed for @xmath89 in lines 17 and 18 .",
    "algorithm [ ago : bigamp - jcd ] provides a high - level description of big - amp to perform jcd estimation .",
    "lines 78 , 1516 , and 1718 of algorithm [ ago : bigamp - jcd ] perform the posterior mean and variance estimators for @xmath226 , @xmath84 , and @xmath89 , respectively .",
    "a remarkable feature of the algorithm is that at each iteration , the estimates of @xmath226 , @xmath84 , and @xmath89 can separately serve as the estimators over a bank of scalar channels .",
    "next , we describe these nonlinear steps in detail . for brevity , we omit the subscript indexes @xmath227 hereafter .",
    "first , we notice that lines 78 compute the posterior mean and variance of @xmath127 ; in this computation , the expectation operator is w.r.t .",
    "@xmath228 where @xmath229 is given by ( [ eq : lnkelihood_each_simple ] ) , and @xmath230 .",
    "this process is identical to that implemented in example 2 . as a result ,",
    "lines 78 of algorithm [ ago : bigamp - jcd ] for each real - valued channel can be computed using the expressions in ( [ eq : hatz_realgaussian])([eq : msez_realgaussian ] ) .",
    "next , we discuss the nonlinear steps used to compute @xmath231 and @xmath232 in lines 1516 and 1718 of algorithm [ ago : bigamp - jcd ] . specifically , the expectations and variances in lines 15 - 16 and 17 - 18 are taken w.r.t .",
    "the marginal posterior @xmath233 these posterior probabilities are similar to those of @xmath234 , except that @xmath235 is replaced with a gaussian distribution and the corresponding priors @xmath76 and @xmath236 are used in place of @xmath128 . in fact , the former change results in an estimator that is fundamentally different from that in the case of @xmath127 . in example 1 , if @xmath235 is a gaussian distribution , then the estimator is operated in an _",
    "unquantized _ channel .",
    "that is , the estimates of @xmath178 and @xmath179 in algorithm [ ago : bigamp - jcd ] are based on awgn channels .    to specify @xmath231 , we consider the square qam constellation with @xmath237 points @xmath238 where @xmath239 is the power normalization factor .",
    "if @xmath179 is drawn from the constellation points uniformly , i.e. , @xmath240 for @xmath241 , then lines 1516 of algorithm [ ago : bigamp - jcd ] can be computed using @xmath242 where @xmath243 finally , recall that @xmath244 .",
    "then lines 1718 of algorithm [ ago : bigamp - jcd ] can be computed using @xmath245 the derivation of ( [ eq : hath_realgaussian ] ) is identical to that in example 2 .    using the above nonlinear steps ( [ eq : hatz_realgaussian])([eq : msez_realgaussian ] ) and ( [ eq : hatx_realgaussian])([eq : hath_realgaussian ] )",
    ", we implement the gamp - based jcd algorithm based on the open - source `` gampmatlab '' software suite .",
    "in this section , we present a framework to analyze the bayes - optimal jcd estimator .",
    "the key strategy for analyzing @xmath246 and @xmath247 is through the average free entropy @xmath248 where @xmath249 denotes the marginal likelihood in ( [ eq : marginalpr ] ) , that is , the partition function .",
    "aligned with the argument in @xcite , @xmath247 and @xmath246 are saddle points of the average free entropy .",
    "thus , the goal is reduced to finding ( [ eq : freeen ] ) .",
    "the analysis is based on a large - system limit , that is , when @xmath250 but the ratios @xmath251 are fixed and finite . for convenience",
    ", we simply use @xmath252 to denote this large - system limit . even in the large - system limit",
    ", the computation of ( [ eq : freeen ] ) is difficult .",
    "the major difficulty in computing ( [ eq : freeen ] ) is the expectation of the logarithm of @xmath249 , which , nevertheless , can be facilitated by rewriting @xmath253 as ] where @xmath254 is any positive random variable . ] @xmath255    the expectation operator is then transformed inside the log - function .",
    "we first evaluate @xmath256 for an integer - valued @xmath257 , and then generalize the result to any positive real number @xmath257 .",
    "this technique , called _ the replica method _",
    ", is from the field of statistical physics @xcite , which is not mathematically rigorous .",
    "nevertheless , the replica method has proved successful in a number of highly difficult problems in statistical physics @xcite and information theory @xcite .",
    "some of the results originally obtained by the replica method have been subsequently validated by other approaches ( e.g. , @xcite ) . under the assumption of @xmath252 and replica symmetry ( rs ) , an asymptotic free entropy can be obtained later in proposition [ pro_freeentropy ] .",
    "we check the accuracy of the replica - based analysis via simulations .",
    "proposition [ pro_freeentropy ] involves several new parameters .",
    "most parameters ( except for some auxiliary parameters ) of proposition [ pro_freeentropy ] can be illustrated systematically by the scalar awgn channels :    [ eq : scalch ] @xmath258    where @xmath259 , @xmath260 , and @xmath261 .",
    "we shall specify how the parameters @xmath262 and @xmath263 are related to the asymptotic free entropy later in proposition [ pro_freeentropy ] .",
    "thus far , we know that the parameters @xmath263 and @xmath262 serve as the signal - to - noise ratios ( snrs ) of the above awgn channels .",
    "the likelihoods under ( [ eq : scalch_x ] ) and ( [ eq : scalch_h ] ) are respectively given by    @xmath264    and then we get the posteriors    @xmath265    some important quantities are obtained with the posteriors . for example , the posterior mean estimators for @xmath266 and @xmath178 read    [ eq : est_xh ] @xmath267    the mses of the estimators are thus given by    [ eq : mse_xh ] @xmath268    where the expectations are taken over @xmath269 and @xmath270 , respectively . equations",
    "( [ eq : hatx_realgaussian])([eq : hath_realgaussian ] ) are explicit expressions of the above quantities .",
    "in addition , the mutual information between @xmath271 and @xmath272 reads @xcite @xmath273 and the mutual information between @xmath274 and @xmath275 is @xmath276    from ( [ eq : scalch ] ) , an inference that another scalar awgn channel w.r.t .",
    "the @xmath66-phase exists can be made , i.e. , @xmath277 where @xmath278 and @xmath279 .",
    "as the pilot is known , @xmath280 can be obtained easily following the argument in remark [ remark_1 ] ; and the mutual information between @xmath281 and @xmath282 is @xmath283 .",
    "as all the performances relating to ( [ eq : scalch_xt ] ) are trivial , we will not use ( [ eq : scalch_xt ] ) in the following discussions .",
    "[ pro_freeentropy ] as @xmath284 , the asymptotic free entropy is @xmath285 where @xmath286 @xmath287 for @xmath288 ; @xmath289 s are given by ( [ eq : mix_scalch ] ) and ( [ eq : mih_scalch ] ) ; and @xmath290 , @xmath291 . in ( [ eq : freeentropyfinal ] ) , the other parameters @xmath292 are obtained from the solutions to the fixed - point equations    [ eq : fxiedpoints ] @xmath293    where @xmath294 , and @xmath295 and @xmath296 are given by ( [ eq : mse_xh ] ) . in ( [ eq : fxiedpoints ] ) , we have defined @xmath297 with @xmath298 given by ( [ eq : psi_def ] ) and @xmath299    see appendix b.    as previously mentioned , the asymptotic mses of @xmath72 and @xmath63 are the saddle points of the free entropy .",
    "clearly , from proposition [ pro_freeentropy ] , they are @xmath296 and @xmath295 , respectively .",
    "notably , the mses are associated with the scalar awgn channels ( [ eq : scalch_x ] ) and ( [ eq : scalch_h ] ) .",
    "therefore , the performances of the quantized mimo system seem to be fully characterized by the scalar awgn channels ( [ eq : scalch ] ) .",
    "the following proposition formulates such intuition .",
    "[ pro_decoupling ] let @xmath86 , @xmath89 , @xmath300 , and @xmath301 denote the @xmath302-th and @xmath303-th entries of @xmath72 , @xmath63 , @xmath304 , and @xmath305 , respectively .",
    "as @xmath284 , the joint distribution of @xmath306 of channels ( [ eq : qsys ] ) , ( [ eq : esth ] ) , and ( [ eq : estx ] ) converges to the joint distribution of @xmath307 of the scalar channels ( [ eq : scalch_x ] ) and ( [ eq : scalch_x ] ) .",
    "see appendix c.    proposition [ pro_decoupling ] shows that , in the large - system limit , the input output of the quantized mimo system employing the bayes - optimal jcd estimator is equivalently decoupled into a bank of the scalar awgn channels ( [ eq : scalch_x ] ) and ( [ eq : scalch_h ] ) .",
    "this characteristic is known as the decoupling principle , which was introduced by @xcite for treading an _ unquantized _ mimo system with _",
    "perfect _ csir .",
    "if perfect csir is available , then we will not need ( [ eq : scalch_h ] ) for treating the channel estimation quality .",
    "notably , proposition [ pro_decoupling ] extends the decoupling principle to a general setting .",
    "in particular , we employ the jcd estimator so that the decoupled awgn channels involve not only the data symbol [ i.e , ( [ eq : scalch_x ] ) ] but also the channel response [ i.e. , ( [ eq : scalch_h ] ) ] as well .",
    "the equivalent channels ( [ eq : scalch ] ) are the scalar awgn channels , with @xmath308 and @xmath262 being the equivalent snrs . as shown in ( [ eq : fxiedpoints ] ) and ( [ eq : chi_def ] ) , the quantization effect is included in @xmath308 and @xmath262 through @xmath309 for @xmath310 .",
    "consider the extreme case of @xmath163 and @xmath164 , i.e. , the unquantized channel . in this case , the riemann sums @xmath311 in ( [ eq : chi_def ] ) becomes the riemann integral over the interval @xmath312 . applying the technique in remark  3 to ( [ eq : chi_def ] ) and evaluating the integrals",
    ", @xmath309 can be simplified to @xmath313 substituting ( [ eq : fxiedpoints ] ) for @xmath314 and @xmath315 in the denominator of ( [ eq : chi_unq ] ) , we obtain @xmath316 . the quantity in this form",
    "can be understood as the noise plus the residual interference resulting from the estimation errors of the data symbol and channel response .",
    "we focus our interest on several special cases in the following examples to obtain more insight into proposition [ pro_decoupling ] .",
    "* example  3 * ( constellation - like inputs ) .",
    "based on proposition [ pro_decoupling ] , the asymptotic mses w.r.t .",
    "@xmath72 and @xmath63 can be determined by using the mses of the scalar awgn channels ( [ eq : scalch_x ] ) and ( [ eq : scalch_h ] ) , respectively .",
    "thus , if the data symbol is drawn from a quadrature phase - shift keying ( qpsk ) constellation , then we will derive @xmath317 the ser w.r.t .",
    "@xmath72 can also be evaluated through the scalar awgn channel ( [ eq : scalch_x ] ) , which is given by @xcite @xmath318 ^ 2,\\ ] ] where @xmath319 is the q - function .",
    "in fact , all these performances w.r.t .",
    "@xmath72 can be determined on the basis of knowledge of the scalar awgn channel with snr @xmath320 .",
    "thus , if the data symbol is drawn from other square qam constellations , then the corresponding ser can be easily obtained by using the closed - form ser expression in @xcite .",
    "* example  4 * ( perfect csir ) .",
    "if the channel matrix @xmath63 is perfectly known , then the @xmath66-phase will not be required so that @xmath321 given that @xmath63 is perfectly known , @xmath322 .",
    "integrating this into ( [ eq : asyvarh ] ) , we immediately obtain @xmath323 , which yields @xmath324 in which ( [ eq : ccpqq_pcsi ] ) follows the result of @xmath325 and ( [ eq : asyvarxd ] ) . substituting ( [ eq : beta_pcsi])([eq : ccpqq_pcsi ] ) into ( [ eq : psi_def ] ) , ( [ eq : chi_def ] ) and ( [ eq : psip_def ] ) , we derive more concise expressions for @xmath326 , @xmath327 , and @xmath328 .",
    "notably , when particularizing our results to the case with the qpsk inputs , we recover the same asymptotic mse expression as given in ( * ? ? ?",
    "* ( 7 ) and ( 8) ) . more precisely , in @xcite ,",
    "the real - valued system with bpsk signal was considered . in such case ,",
    "@xmath329 in our study should be replaced with @xmath166 .",
    "* example  5 * ( pilot - only scheme ) . in the conventional pilot - only scheme ,",
    "the receiver solely uses @xmath95 and @xmath71 to generate an estimate of @xmath63 and subsequently uses the estimated channel for estimating the data @xmath72 from @xmath96 @xcite .",
    "the analysis of the asymptotic mse w.r.t .",
    "@xmath63 is the same as that in example  4 , but the roles of @xmath63 and @xmath71 are exchanged .",
    "in particular , during the @xmath66-phase , we derive @xmath330 and @xmath294 because no data symbol is involved and the pilot matrix @xmath71 is known . after substituting these parameters into ( [ eq : fxiedpoints ] ) and simplification ,",
    "we obtain the _ self - contained _ fixed - point equations @xmath331 with @xmath332 in ( [ eq : mse_h_pilotonly ] ) , @xmath295 represents the asymptotic mse w.r.t .",
    "@xmath63 for the pilot - only scheme , which is also the mse w.r.t .",
    "@xmath178 for the scalar awgn channel ( [ eq : scalch_h ] ) .",
    "notably , @xmath262 serves as the snr of the awgn channel ( [ eq : scalch_h ] ) . comparing @xmath262 in ( [ eq : q_h_pilotonly ] ) with that in ( [ eq : asyvarh ] ) , we determine that the second term of @xmath262 in ( [ eq : asyvarh ] ) is the gain achieved by data - aided channel estimation .",
    "[ cols=\"^,^,^,^,^,^,^,^\",options=\"header \" , ]     [ table : coefficientsofdelta ]    we fit the optimal step sizes for different input signals by using a first - degree polynomial equation @xmath333 where @xmath334 represents the snr in db scale to derive a general expression .",
    "the ( least squares fit ) coefficients @xmath335 are listed in table [ table : coefficientsofdelta ] .",
    "the optimal step sizes determined by using @xmath336 are also indicated by the shaded area in figure [ fig : stepsize_qpsk16qam_ser ] .",
    "we observe that , although @xmath336 is nonoptimal for each specific input , their corresponding performances remain acceptable .",
    "following the same argument , we derive the corresponding polynomial equation @xmath337 for different quantization bits , with their coefficients listed in table [ table : coefficientsofdelta ] .      comparing figures [ fig : ser_qpsk](a ) and [ fig : ser_qpsk](b ) , we observe that the loss due to no csir is small for the bayes - optimal jcd estimator .",
    "then , we discuss the performances of the bayes - optimal jcd estimator _ with _ and _ without _ the perfect csir under various system settings to obtain a better understanding on the effects of csir over the quantized mimo system .",
    "in contrast to the qpsk signals used in previous simulations , we focus on the gaussian inputs , that is , @xmath338 , in the subsequent experiments .",
    "the other system parameters are the same as that in the previous experiment , that is , @xmath339 , @xmath340 , and @xmath341 .",
    "figure  [ fig : msex_qvsunq ] shows the asymptotic mse @xmath296 for the bayes - optimal jcd estimator with and without perfect csir .",
    "the mse for the pilot - only scheme is also shown .",
    "notably , the bayes - optimal jcd estimator shows a significant improvement over the pilot - only scheme in the @xmath342  bit and unquantized cases .",
    "the gap between the bayes - optimal jcd estimator with and without perfect csir is small in the unquantized case , whereas the gap is large in the case of the @xmath342  bit quantizer . by observing the @xmath342  bit and unquantized cases",
    ", we can expect that the gap decreases with the increase in the adc resolution .    a straightforward method to reduce the gap of the @xmath342  bit case is increasing the training length .",
    "we provide the mse results for @xmath343 and @xmath344 in figure  [ fig : msex_all_jcd ] to verify this argument .",
    "however , the improvement achieved by increasing the training length is limited even if @xmath345 , leaving only @xmath346 for data .",
    "alternatively , we may consider a larger @xmath347 , but the maximum @xmath347 is limited by the coherence time .",
    "if @xmath348 and @xmath349 , then the performance of the bayes - optimal jcd estimator without perfect csir is approximately similar to the ( fundamental limit ) case with perfect csir .",
    "nevertheless , such a long coherence time is usually unavailable in practice .",
    "we developed a framework for studying the _ best _ possible estimation performance of the quantized mimo system , namely , the massive mimo system with very low - precision adcs .",
    "in particular , we used the bayes - optimal inference for the jcd estimation and achieve this estimation by applying the big - amp technique .",
    "the asymptotic performances ( e.g. , mses and sers ) w.r.t .  the channels and the payload data were derived and shown as simply characterized by scalar awgn channels .",
    "monte - carlo simulations were conducted to demonstrate the accuracy of our analytical results .",
    "the high accuracy of the analytical expressions enable us to quickly and efficiently assess the performance of the quantized mimo system .",
    "thus , we obtained the following useful guidelines for the system design :    * we showed that the asymptotic mse of the channel estimate in the conventional pilot - only scheme decreases by approximately @xmath350db for each bit added to the adcs or each doubling of training length .",
    "this finding supports the importance of the jcd technique , especially in the _ quantized _ mimo system . * the optimal step size for minimizing sers of the bayes - optimal estimator",
    "were shown to be highly different from that for minimizing the distortion of a gaussian signal and , fortunately , can be quickly determined by our analytical expressions . *",
    "the bayes - optimal estimator already exhibits the best possible estimation performance .",
    "even so , we showed that the performance gap between the bayes - optimal jcd estimator with and without perfect csir still can not be negligible in the _ quantized _ mimo system .",
    "we also discussed the ways to reduce the gap and then concluded that achieving the same performance as the full csir case in the quantized mimo system is very difficult .",
    "many potential directions for future work are available .",
    "the gamp - based jcd algorithm presented in this paper is a first step toward achieving the _ optimal _ jcd estimate under the quantized mimo system .",
    "the computational complexity of the gamp - based jcd algorithm may still be too high to be affordable in a commercial system .",
    "one possible solution is to adopt other suboptimal schemes such as linear estimators .",
    "another feasible solution is using mixed - adc receiver architecture @xcite wherein a small number of high - resolution adcs is available .",
    "thus , csir gains high accuracy and facilitates the jcd procedure . for a development in this direction ,",
    "see @xcite .",
    "in this appendix , we derive the expressions ( [ eq : hatz_realgaussian ] ) and ( [ eq : msez_realgaussian ] ) , by applying the techniques in ( * ? ? ?",
    "* chapter 3.9 ) .",
    "the derivations below are only dedicated for the real part of the estimator because the imaginary part of the estimator can be obtained analogously .",
    "note that the signal power and noise power are @xmath351 and @xmath352 , respectively , per real and imaginary part .",
    "for ease of notation , we have abused @xmath146 , @xmath127 , and @xmath132 to denote @xmath150 , @xmath353 , and @xmath354 , respectively .",
    "to get ( [ eq : hatz_realgaussian ] ) , we begin by deriving the denominator of ( [ eq : margpost_z ] ) . first , recall from ( [ eq : lnkelihood_each ] ) that if @xmath355 $ ] and @xmath356 , the likelihood is given by @xmath357 note that for the special case @xmath157 , we have @xmath53 , and the second term of ( [ eq : pout_app ] ) will disappear . substituting ( [ eq : pout_app ] ) into the denominator of ( [ eq : margpost_z ] ) , it can be shown that @xmath358 differentiating w.r.t .",
    "@xmath132 on both sides of ( [ eq : normconst ] ) yields @xmath359 where we have used @xmath360 . using ( [ eq : normconst ] ) , ( [ eq : difnormconst ] ) can be rearranged as @xmath361 where @xmath362 and @xmath363 are given by ( [ eq : eta_def ] ) . multiplying both sizes by @xmath364",
    ", we obtain the marginal posterior mean given in ( [ eq : hatz_realgaussian ] ) .",
    "similarly , ( [ eq : msez_realgaussian ] ) can be calculated by differentiating ( [ eq : normconst ] ) twice as @xmath365 which then can be rearranged as @xmath366 we also note that @xmath367 after plugging ( [ eq : dif2normconst2 ] ) and ( [ eq : hatz_realgaussian ] ) into ( [ eq : varz_def ] ) , we obtain ( [ eq : msez_realgaussian ] ) . in the above derivations , we have assumed @xmath356 . for @xmath368 ,",
    "the above derivations can be used in the same way .",
    "using the replica method , we first compute the replicate partition function @xmath369 in ( [ eq : limf ] ) , which with the definition of ( [ eq : posteriorpr ] ) can be expressed as @xmath370 where we define @xmath371 with @xmath372 and @xmath373 being the @xmath374-th replica of @xmath63 and @xmath68 , respectively , and @xmath375 and @xmath376 . here , @xmath377 are random matrices taken from the distribution @xmath378 for @xmath379 . in addition , @xmath380 denotes the integral w.r.t .  a discrete measure because the quantized output @xmath69 is a finite set . we will calculate the right - hand side of ( [ eq : sf_e1 ] ) , by applying the techniques in @xcite after additional manipulations .    to average over @xmath381",
    ", we introduce two @xmath382@xmath383 matrices @xmath384 $ ] and @xmath385 $ ] for @xmath110 whose elements are defined by @xmath386 and @xmath387 for @xmath388 , where , @xmath389 is the @xmath390th row vector of @xmath372 , and @xmath391 is the @xmath392th column vector of @xmath373 for @xmath393 or @xmath394 .",
    "the definitions of @xmath395 and @xmath396 are equivalent to @xmath397 where @xmath398 denotes dirac s delta .",
    "let @xmath399 and @xmath400 . inserting the above into ( [ eq : sf_e1 ] ) yields @xmath401 where @xmath402 using the fourier representation of the @xmath403 function via auxiliary matrices @xmath404 } \\in { { \\mathbb c}}^{(\\tau+1)\\times(\\tau+1)}$ ] , @xmath405 \\in { { \\mathbb c}}^{(\\tau+1)\\times(\\tau+1 ) } , \\forall o \\ } $ ] and performing the saddle point method for the integration over @xmath406 , we attain @xmath407 with    [ eq : saddlepoint ] @xmath408    where @xmath409 denotes the extreme value of @xmath410 w.r.t .",
    "@xmath411 ; @xmath412 @xmath413^{t}$ ] , @xmath414 $ ] .",
    "according to ( [ eq : limf ] ) , the average free entropy turns out to be @xmath415    the saddle points of @xmath416 can be found by the point of zero gradient w.r.t .  @xmath417",
    "but it is still prohibitive to get explicit expressions about the saddle points .",
    "thus , we assume that the saddle points follow the rs form @xcite as    @xmath418    in addition , the application of the central limit theorem suggests that @xmath419^t$ ] are gaussian random vectors with @xmath420 covariance matrix @xmath421 .",
    "if @xmath422 , then the @xmath423th entry of @xmath424 is given by @xmath425 as such , we set @xmath426 , which is equivalent to introducing to the gaussian random variable @xmath427 for @xmath422 as @xmath428 where @xmath429 and @xmath430 are independent standard complex gaussian random variables . with rs , the problem of seeking the extremum w.r.t .",
    "@xmath417 is reduced to seeking the extremum over @xmath431 , which can be obtained by equating the corresponding partial derivatives of the rs expression @xmath416 to zero .    to this end",
    ", we calculate the rs expression of @xmath416 by substituting these rs expressions into ( [ eq : saddlepoint1])([eq : saddlepoint3 ] ) .",
    "first , for ( [ eq : saddlepoint1 ] ) , we substitute ( [ eq : eqz ] ) and perform the expectation w.r.t .",
    "@xmath213 and integration over @xmath432 , to yield @xmath433 where we define @xmath434 and @xmath435 with @xmath436 , and @xmath437 and @xmath438 being independent _ real _ standard gaussian random variables . and @xmath430 in ( [ eq : eqz ] ) are standard `` complex '' gaussian random variables .",
    "in this paper , we process the real and imaginary parts separately .",
    "therefore , for ease of notation , we have rescaled all the observation outputs @xmath439 and @xmath440 by @xmath441 so that the real and imaginary parts of these random variables can be regarded as the standard `` real '' gaussian random variables . ] performing the expectation w.r.t .",
    "@xmath437 , ( [ eq : psib1 ] ) can be expressed as ( [ eq : psi_def ] ) .",
    "next , we move to the rs calculation of ( [ eq : saddlepoint2 ] ) . under the rs assumption , the first term of ( [ eq : saddlepoint2 ] ) can be written as @xmath442 then we decouple the first quadratic term in the exponent using the hubbard - stratonovich transformation and introducing the auxiliary vector @xmath443 , to rewrite ( [ eq : lt_rate_fun1 ] ) as @xmath444 with rs , the second term of ( [ eq : saddlepoint2 ] ) can be expressed as @xmath445 similarly , for the first and second terms of ( [ eq : saddlepoint2 ] ) , we have @xmath446    putting together ( [ eq : lt_rate_fun2])([eq : lt_rate2_fun2 ] ) , we have the rs expression of @xmath416 .",
    "the parameters @xmath431 are determined by setting the partial derivatives of @xmath416 to zeros . in doing so , as @xmath447 ,",
    "it is easy to get that @xmath448 , @xmath449 , @xmath450 , and @xmath451 . in order to obtain the more meaningful expressions for the other parameters , we introduce two scalar awgn channels given in ( [ eq : scalch ] ) and their associated parameters in section iv - a . equating the partial derivatives of @xmath416 w.r.t .",
    "@xmath452 to zeros , we obtain the fixed - point equations given in ( [ eq : fxiedpoints ] ) . finally , taking the partial derivatives of @xmath416 at @xmath453 , and applying the parameters introduced in section iv - a , we obtain ( [ eq : freeentropyfinal ] ) .",
    "consider the @xmath454-th and @xmath455-th entries of @xmath63 and @xmath72 , respectively .",
    "we will show that the joint moments of the joint distribution of @xmath456 for some indices @xmath454 and @xmath455 converges to the joint distribution of @xmath457 independent of @xmath454 and @xmath455 . following @xcite , we proceed to calculate the joint moments @xmath458 for arbitrary non - negative integers @xmath459 , @xmath460 , @xmath461 , @xmath462 , @xmath463 , @xmath464 , @xmath465 , @xmath465 . to proceed , we define @xmath466 with @xmath467 , @xmath468 and @xmath469 , @xmath470 .",
    "if we define the _ generalized _ free entropy as @xmath471 it exactly provides the joint moments of interest .    as @xmath472 and @xmath473",
    ", @xmath474 reduces to @xmath256 given in ( [ eq : sf_e1 ] ) .",
    "therefore , proceeding with the same steps as in appendix b from ( [ eq : sf_e1 ] ) to ( [ eq : sf_e3 ] ) , we get @xmath475 where @xmath476 is exactly identical to ( [ eq : saddlepoint ] ) while @xmath477 and @xmath478 should be replaced by @xmath479 thus , except for @xmath480 and @xmath481 , the rs expressions for the other parts of @xmath476 can be obtained as in appendix b. we now only need to obtain the rs expressions for @xmath482 and @xmath483 .",
    "the generalized free energy in ( [ eq : genfreeentropy ] ) becomes @xmath484 which is the joint moments of @xmath485 .",
    "consequently , the joint moment of interest is thus uniquely determined by ( [ eq : finalf_jmoment ] ) due to the carleman theorem .",
    "in this derivation , we consider the case at infinity snr , i.e. @xmath486 , and we let @xmath487 and @xmath488 without loss of generality . from ( [ eq :",
    "mse_h_pilotonly ] ) , as @xmath489 , we have @xmath490 .",
    "an application of the taylor expansion yields @xmath491 , and thus we have @xmath492 let @xmath493 .",
    "we then evaluate @xmath494 in ( [ eq : chi_pilotonly ] ) by changing the integration variable from @xmath438 to @xmath437 , which yields @xmath495 where @xmath496 as @xmath497 , @xmath498 can be approximated by @xmath499 which is a quantizer - dependent constant .",
    "using @xmath500 given in ( [ eq : chi_pilotonly ] ) and combining ( [ eq : approx_1smseh ] ) and ( [ eq : chi_pilotonly_2 ] ) , we obtain @xmath501 or ( [ eq : mse_highsnr ] ) in db scale , wherein @xmath502 .",
    "the values of @xmath503 in table [ table : coefficient_cb ] are obtained from ( [ eq : cb_val ] ) numerically .",
    "in this appendix , we extend proposition [ pro_freeentropy ] into the case where users have different large - scale fading factors @xmath504",
    ". this task can be performed by proceeding with the same steps as in appendix a , and the proof is omitted .",
    "[ pro_freeentropy_mu ] as @xmath284 , the asymptotic free entropy is @xmath511 where @xmath512 @xmath513 for @xmath288 ; @xmath514 is the mutual information between @xmath515 and @xmath516 ; @xmath517 is the mutual information between @xmath518 and @xmath519 ; and @xmath520 , @xmath521 . in ( [ eq : freeentropyfinal_mu ] ) , the other parameters @xmath522 are obtained from the solutions to the fixed - point equations      where @xmath524 , and @xmath525 and @xmath526 are the mses of the bayes - optimal estimators over ( [ eq : scalch_h_mu ] ) and ( [ eq : scalch_x_mu ] ) , respectively . in ( [ eq : fxiedpoints ] ) , we have defined @xmath527 with @xmath298 given by ( [ eq : psi_def_mu ] ) and @xmath528 .                                , `` low power analog - to - digital conversion in millimeter wave systems : impact of resolution and bandwidth on performance , '' in _ information theory and applications workshop ( ita ) _ , san diego , ca , usa , feb .",
    "2015 , pp . 191198 .      ,",
    "`` performance analysis of signal detection using quantized received signals of linear vector channel , '' in _ proc .",
    "inform . theory and its applications ( isita )",
    "_ , auckland , new zealand , dec . 2008 .",
    "h.  nishimori , _ statistical physics of spin glasses and information processing : an introduction_.1em plus 0.5em minus 0.4emser .",
    "number 111 in int .",
    "series on monographs on physics .",
    "oxford u.k .",
    ": oxford univ . press , 2001 .            , `` asymptotic analysis of spatially correlated mimo multiple - access channels with arbitrary signaling inputs for joint and separate decoding , '' _ ieee trans .",
    "inf . theory _ ,",
    "53 , no .  1 ,",
    "252268 , jan ."
  ],
  "abstract_text": [
    "<S> this paper considers a multiple - input multiple - output ( mimo ) receiver with very low - precision analog - to - digital convertors ( adcs ) with the goal of developing massive mimo antenna systems that require minimal cost and power . </S>",
    "<S> previous studies demonstrated that the training duration should be _ relatively long _ to obtain acceptable channel state information . to address this requirement , </S>",
    "<S> we adopt a joint channel - and - data ( jcd ) estimation method based on bayes - optimal inference . </S>",
    "<S> this method yields minimal mean square errors with respect to the channels and payload data . </S>",
    "<S> we develop a bayes - optimal jcd estimator using a recent technique based on approximate message passing . </S>",
    "<S> we then present an analytical framework to study the theoretical performance of the estimator in the large - system limit . </S>",
    "<S> simulation results confirm our analytical results , which allow the efficient evaluation of the performance of quantized massive mimo systems and provide insights into effective system design .    </S>",
    "<S> bayes - optimal inference , joint channel - and - data estimation , low - precision adc , massive mimo , replica method . </S>"
  ]
}