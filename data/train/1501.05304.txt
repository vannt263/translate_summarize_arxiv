{
  "article_text": [
    "the high sensitivity of the ska ( up to 50 times more sensitive than current instruments @xcite ) combined with a relatively cheap antenna design means a far more careful and detailed treatment of systematics will be required to fully exploit this telescope @xcite .",
    "the current approach to this calibration problem iteratively applies deconvolution methods such as clean @xcite , alternating with sky and instrumental modelling to determine the best - fitting , calibrated image @xcite .",
    "this provides only a point estimate of the model parameters which will in general differ from the true parameters due to random noise @xcite .",
    "a more rigorous approach is to infer the science and instrumental parameters simultaneously , deriving accurate uncertainties and correlations between them .",
    "work in this direction includes improvements on the self - calibration algorithm @xcite and some extensions to the resolve algorithm @xcite .",
    "there has also been considerable effort in this direction in producing a maximum posterior image for the data and dealing with certain calibration parameters @xcite .",
    "these works each solve specific aspects of the calibration and deconvolution problem , but so far do not explore the full posterior distribution , giving an inaccurate estimation of the uncertainties and correlations , and still rely on producing a single image ( i.e. a point estimate ) .",
    "we propose instead a new technique , called bayesian inference for radio observations ( biro ) , which is able to : include any source of instrumental uncertainty , such as ionospheric effects , pointing errors and primary beam uncertainties , jointly determine the science and instrumental parameters and provide reliable estimates of the uncertainties and correlations on these parameters , in a holistic and mathematically rigorous manner .",
    "a simultaneous analysis requires the full posterior probability distribution of the parameters , which can naturally be sampled in the bayesian formalism by using ( for example ) mcmc @xcite or nested sampling @xcite .",
    "our new technique , biro , fits models including both instrumental and science parameters directly to the raw visibility data .",
    "we use the meqtrees @xcite software , which implements the radio interferometry measurement equation ( rime ) @xcite , for the modelling of the sky and instrumental effects .",
    "this technique thus obviates the need for intermediate imaging and map - making .",
    "the rigorous statistical use of all available information allows this technique to open new discovery windows , solving previously intractable problems , and is applicable to all interferometers and problems in radio interferometry .",
    "this paper is arranged as follows : in section [ sec : bayes ] we provide an introduction to bayesian statistics and illustrate the use of the rime for modelling in the biro algorithm in section [ sec : rime ] .",
    "we then apply biro to two key simulated datasets to demonstrate its power : in section [ sec : joint ] , we jointly fit all scientific ( source flux densities ) and instrumental parameters ( pointing errors , primary beam parameters and receiver noise ) to a dataset suffering from direction - dependent instrumental effects . in section [ sec : source_sep ] , we focus on the problem of reliably distinguishing between an extended source , point source and a pair of close point sources , for sources on sub - synthesised beam scales .",
    "we conclude in section [ sec : conclusions ] .",
    "the problem of obtaining the most information possible from an incomplete dataset , such as obtained by an interferometer , is perfectly suited to the application of bayesian statistics .",
    "these allow the fitting of arbitrarily complex models to data , providing reliable uncertainty estimates for the parameters .",
    "bayes theorem allows the use of a familiar quantity , the likelihood , to answer the question one is really interested in : what is the probability of an hypothesis , given the data in hand ?",
    "this probability is known as the posterior and indicates by how much our degree of belief in the hypothesis has been updated by the new data .",
    "simple application of bayes theorem also allows a robust and intuitive way to compare models , which we will require for the second example problem in this paper .",
    "what follows here is a brief overview of bayesian theory , see @xcite for a more in - depth review .    from bayes theorem ,",
    "the probability distribution , @xmath0 , of the values of parameters @xmath1 , the quantity that is actually sought , given the data @xmath2 that are in - hand and a model @xmath3 ( hypothesis plus any assumptions ) , is : @xmath4 this is known as the posterior probability distribution .",
    "the likelihood @xmath5 , which encodes any constraints imposed by observations , is the probability distribution of the data given parameter values and a model .",
    "the prior @xmath6 includes any prior knowledge of or prejudices about the parameter values .",
    "@xmath7 is the integral of @xmath8 over all @xmath1 , not simply normalizing the posterior @xmath0 , but also allowing selection of different models by comparing their values quantitatively .",
    "this so - called evidence , @xmath7 , automatically includes an occam s razor effect , penalising models with a large number of parameters that are not preferred by the data . by computing the evidence for a range of models we can select the best model by maximising the evidence .    for this work ,",
    "the likelihood function is @xmath9,\\ ] ] where @xmath10 are the model visibilities produced by meqtrees ( see section [ sec : rime ] ) , with the parameters @xmath1 as input , @xmath11 are the data visibilities , @xmath12 is the number of data points .",
    "here we assume the uncertainties on the visibilities are gaussian and have the same value , @xmath13 , for all datapoints .",
    "the best - fitting model corresponds to maximum posterior .",
    "the inferred posterior distributions are full probability distributions rather than a summary mean / median value and a ( perhaps covariant ) uncertainty , since this represents the total inference about the problem at hand",
    ". these distributions may be highly non - gaussian , making such summary parameters inaccurate .",
    "the application of bayesian statistics allows one to marginalise out the effects of nuisance parameters , which are parameters such as the beam shape and pointing errors that are not of primary interest , but are unknown and can affect the estimates of the parameters of interest ( i.e. science parameters ) because of correlations and degeneracies . the marginalised posterior can be written as a function of the parameters of interest , @xmath14 , the nuisance parameters , @xmath15 , and the data , @xmath16 : @xmath17 where the integral is performed over the parameter space of @xmath15 .",
    "the posterior is , thanks to advances in modern computing , fairly easily determined using numerical techniques . in this paper",
    ", we use the markov chain monte carlo ( mcmc ) metropolis - hastings @xcite algorithm for the joint scientific and instrumental parameter inference example .",
    "we chose mcmc due to its simplicity and the ease with which it handles large numbers of parameters ( we have 103 parameters for the first example problem ) . for our second example , that of model selection related to source separation and extended structure , we require efficient calculation of the bayesian evidence , something provided naturally by the nested sampling algorithm .",
    "we utilise the public code multinest @xcite to determine both the parameters and the evidence for model comparison @xcite , but for a smaller set of parameters as nested sampling grows rapidly in complexity with increasing number of parameters .",
    "previous bayesian visibility analyses @xcite focused on the sky model and were not generalised to include arbitrary instrumental effects ( or were attempting to solve for a much more general sky model resulting in many more parameters , thus needing to fix instrumental parameters ) . the radio interferometry measurement equation ( rime ) @xcite provides a powerful framework to easily describe exactly what happens to a signal as it travels from source to telescope , where it is converted into voltages .",
    "the rime is a natural way to model the instrumental and scientific effects that we are inferring through our bayesian technique .",
    "for example , the rime for a single point source is given by @xmath18 where @xmath19 is the brightness matrix , which describes the sky flux distribution , @xmath20 is the jones matrix @xcite for antenna @xmath21 , containing all instrumental and atmospheric effects that interfere with the signal , @xmath22 is the jones matrix for antenna @xmath23 , @xmath3 indicates the hermitian of a matrix and @xmath24 are the visibilities , the outputs of the telescope correlator for baseline @xmath25 .",
    "the effects that interfere with the signal on its route to the output of the telescope can each be described by a jones matrix , with each effect adding a pair of jones matrices in the ` onion ' form of the rime : @xmath26    we can go a few steps further and consider the full - sky rime by integrating over the direction cosines , @xmath27 and @xmath28 : @xmath29 here , @xmath30 and @xmath31 are the jones matrices describing the geometric delay between antennas @xmath21 and @xmath23 , @xmath32 represents the _ direction - independent _ gains for antenna @xmath21 , which we set to unity for all antennas , and @xmath33 is the jones matrix containing all the _ direction - dependent _ effects for antenna @xmath21 .",
    "we focus in this paper on the more difficult to handle direction - dependent effects , but direction - independent can also be handled with our technique .",
    "as with all other jones matrices , @xmath33 can be written as a product of jones matrices , each describing a different effect . in section [ sec : joint ] , we consider both primary beam effects and pointing errors as examples of direction - dependent effects each with their own jones matrix .    the rime is implemented in the general , flexible software meqtrees @xcite , which allows us to apply it to any sky model and for any telescope .",
    "meqtrees has been useful for predicting the capabilities of future experiments and for understanding the intricacies of current telescopes . here , we go a step further and use meqtrees as the modelling step in our bayesian analysis . in order to test biro and compare it with the standard deconvolution approach , we use datasets simulated with meqtrees over which we have complete control and",
    "thus would know if we were correctly recovering the true input parameters .",
    "meqtrees takes from the user a sky model ( such as the number and distribution of sources , their fluxes , shapes etc . ) as well as instrumental details ( such as the telescope configuration , primary beam pattern , pointing errors , noise , atmospheric effects , ionospheric effects etc . ) and uses the measurement equation to produce realistic simulated visibilities that such a telescope would observe .    in order to test the validity of our technique",
    ", we only work with simulations in this paper .",
    "we use meqtrees to simulate the data and also to model the sky , to test if we recover the input parameters .",
    "meqtrees can be used to model any telescope configuration and any sky and instrumental effects that can be described with the rime . while we only concentrate on primary beam and pointing error effects in section [ sec : joint ] , in principle , a wide variety of source types and instrumental corruptions can be added in meqtrees .",
    "[ fig : flowchart ] shows a schematic overview of the biro approach . at each step in the chain of mcmc or multinest ,",
    "meqtrees is called with new values for the parameters .",
    "meqtrees then returns a visibility set that can be compared directly with the simulated data , to determine how well the parameters fit .",
    "this iterative process allows the determination of the full posterior for the parameters . we do not as yet have a public release of the biro code , but plan to in the future where we will integrate montblanc , a gpu implementation of the rime @xcite with biro .",
    "montblanc is already publicly available meaning it can be combined with any sampler to allow the user to implement biro for themselves .",
    "in this example , we use biro to jointly estimate the scientific parameters and nuisance instrumental parameters . below",
    "we describe the model and simulated dataset used , and details of the mcmc analysis , and show that the instrumental parameters studied are tightly correlated with the scientific parameters , a fact that can not be ignored when determining these parameters .",
    "we use meqtrees to simulate observations with the westerbork synthesis radio telescope ( wsrt ) @xcite , a 14-element east - west array with 25 m diameter dishes .",
    "all our wsrt simulations use an integration time of 30 seconds and a total observation time of 12 hours at a frequency of 1.4 ghz .",
    "we use a narrow bandwidth of 125khz , a single channel ( for simplicity ) and include noise with a standard deviation of 0.1 jy / visibility . at this frequency",
    ", wsrt has a field of view of 0.5 - 0.6 degrees and a synthesised beam width of around 13 arcsec fwhm ( full width at half maximum ) .",
    ", as the telescope would see it ( the colours are histogram - equalised to improve contrast ) .",
    "the image is produced directly from the visbilities and shows the typical ring structure around bright sources that is seen in interferometric data , due to the missing angular - scale information in the dataset .",
    "the rms noise in flux density is about 0.28 mjy . ]",
    "the simulated field consists of 17 unpolarised , point sources with known positions .",
    "the science goal was to determine the flux densities of these sources .",
    "we based the simulation on an existing field observed by wsrt , consisting of sources with a range of fluxes ( from @xmath34 jy ) .",
    "this is a very simple sky model , consisting only of point sources , whereas in the second example of the paper , we address modelling of extended sources .",
    "we do not explore the possibility of extended sources of arbitrary shapes , as this is out of the scope of this paper , but this should be possible using shapelets , such as employed in the existing pybdsm softwarepython blob detection and source measurement software , www.lofar.org/wiki/doku.php?id=public:user_software:pybdsm ] .",
    "the brightness matrix in eq.([eq : rime_full ] ) for an unpolarised point source is written as : @xmath35 where @xmath36 is the intensity .",
    "[ fig : field ] shows an image of the true input model without any instrumental effects , while fig .",
    "[ fig : dirty ] shows the dirty image of the sky .",
    "* beam width * + knowing the primary beam pattern is critical for any astronomical survey .",
    "current practice is to determine the primary beam pattern using a technique such as holography @xcite , then fix a beam model , without propagating any uncertainty information into the estimates of the science parameters .",
    "since the primary beam directly attenuates the flux distribution of the sky , even a small error in the beam model can lead to large biases .",
    "we thus include beam parameters in our analysis .",
    "wsrt commonly adopts a simple model for the primary beam , namely : @xmath37 , where @xmath38 is the observing frequency ( in ghz ) , @xmath39 is the distance from the pointing centre in degrees and @xmath40 is the beam factor ( in 1/ghz ) .",
    "the beam factor ( or beam width ) is known to vary slightly with frequency . as proof of concept ,",
    "we assume it is unknown , and include it as a further instrumental parameter .",
    "one could provide a more complex model for the primary beam and easily fit those parameters with this technique as well , comparing the models with the bayesian evidence .",
    "the model for the beam enters the rime of eq.([eq : rime_full ] ) as a direction - dependent jones matrix : @xmath41 where @xmath42 is the identity matrix . + * pointing errors * + pointing errors can substantially corrupt radio observations and are known to be a limiting factor in deep observations with wsrt @xcite and other telescopes .",
    "the greatest effect is on sources on the flank of the primary beam , where the gradient of the beam pattern is steep , and a small pointing error produces a larger error in apparent flux ( compared to the centre of the beam ) .",
    "since the errors can be different from antenna to antenna , this produces errors on the observed visibility amplitudes , which translates into artefacts in the image .",
    "essentially each source is ` defocussed ' in a complicated way .",
    "thus , we can immediately suspect there will be a correlation between the pointing errors and source flux densities .",
    "two prior approaches to inferring pointing errors directly from the data have hinged on maximum - likelihood estimates .",
    "these are the pointing selfcal algorithm @xcite and direct fitting with meqtrees ( smirnov 2011 ) . neither approach estimates the correlation between pointing errors and source parameters , which the bayesian approach naturally provides .",
    "we inject time - varying polynomial pointing errors for each of the 14 wsrt antennas .",
    "we use a second order polynomial for each pointing error and fit for the coefficients .",
    "a polynomial pointing error in each orthogonal direction for each antenna results in a total of 84 pointing - error parameters .",
    "the pointing errors are written as a jones matrix in eq.([eq : rime_full ] ) : @xmath43 where @xmath44 and @xmath45 are the pointing errors in the right ascension and declination direction respectively , for antenna @xmath21 .",
    "the pointing errors are taken to be time - varying polynomials , written as : @xmath46 and similarly for @xmath45 , where @xmath47 is time ( rescaled over the observation ) and @xmath48 are the coefficients we determine with mcmc . +",
    "* noise * + the noise on the visibilities is expected to be gaussian , stationary and uncorrelated .",
    "noise level can be estimated with some precision from the known system temperature , here however we show than it can also be inferred accurately directly from the data .",
    "we thus included one final parameter for the standard deviation of the noise on the visibilities .",
    "the rime for this example problem is thus : @xmath49    where @xmath50 runs from 1 to 17 over all the sources .",
    "this brings the total to 103 parameters : 17 scientific ( the flux densities of the sources ) and 86 instrumental ( 84 pointing error parameters , the beam width and the noise ) .",
    "the full model can be visualised in the bayesian factor graph of fig .",
    "[ fig : factor ] and a more detailed description of factor graphs is given in section [ sec : factor ] of the appendix .",
    "of the appendix ) of the model for the first simulated dataset .",
    "all parameters we estimate with mcmc are the constants , without any circles around them , coloured blue .",
    "the @xmath24 are the observed visibilities , which are drawn from a normal distribution of mean @xmath51 ( the unobserved , true visbilities ) and standard deviation @xmath13 , which is one of the parameters we estimate with mcmc .",
    "these ` true ' visibilities are governed by the rime , which is here simplified graphically to two components , the brightness matrix , @xmath19 , and the jones matrices of the antennas , @xmath52 .",
    "the flux densities of the 17 sources are represented by @xmath53 , which form components of @xmath19 .",
    "the coefficients of the polynomial time - varying pointing errors , @xmath54 and @xmath55 ( where @xmath56 represents the antenna number and @xmath57 is the number of polynomial coefficient ) enter the jones matrices , along with the beam width , @xmath58 . ]",
    "the initial step of our analysis was to choose an appropriate sky model in meqtrees ( specifying the brightness matrix in eq.([eq : rime_full ] ) ) and select the telescope configuration corresponding to the dataset including all known sources of interference and instrumental errors ( the jones matrices in eq.([eq : rime_full ] ) ) .",
    "we vary all the parameters within the model  the flux densities , pointing errors , beam width and noise  using mcmc .",
    "[ fig : flowchart ] illustrates how the sampling algorithm repeatedly calls meqtrees with new parameter values and evaluates the likelihood .",
    "mcmc uses the likelihood ( eq.([eq : likelihood ] ) ) to determine the best - fitting parameter values and to explore the surrounding parameter space , thus determining the uncertainties and correlations for all parameters .      due to the large volume of the parameter space",
    ", we use a standard , gradient - based optimisation algorithm to get close to the best - fitting parameter values and provide a good starting point for the mcmc .",
    "we run several chains in parallel , each of around @xmath59 steps , repeatedly computing and diagonalising the covariance matrix to improve convergence , and we test convergence using the gelman - rubin statistic @xcite .",
    "the estimated parameters and their uncertainties are determined by finding the mean and standard deviation ( using percentiles ) from the marginalised one - dimensional posterior for each parameter .",
    "for this particular setup , meqtrees takes about 0.4s for one likelihood calculation , parallelised using 4 cores of 2.2 ghz each .",
    "as 10 chains were run , 40 cores in total were used resulting in approximately 55 cpu hours for convergence per dataset .",
    "we apply a uniform prior to the pointing error parameters , restricting them to the broad range of @xmath60 arcseconds .",
    "we also restrict the beam width to be positive , and vary the noise on the visibilities in logarithmic space ( with an infinitely broad prior in log - space ) .",
    "we do not restrict the ranges of the flux densities .      to compare our technique with the standard approach",
    ", we apply clean followed by a source - extraction algorithm to determine the flux densities of the sources ( we call this combination clean+se ) , without any instrumental calibration .",
    "we do not use any calibration algorithms such as self - cal , because it would have no benefit : our dataset only has direction - dependent instrumental effects , whereas self - cal can only correct for direction - independent effects .",
    "current approaches to direction - dependent calibration are of no help here because :    1 .",
    "direction - dependent solutions ( such as peeling , or differential gains ) can in principle solve for the variable gains induced by pointing error , given a prior source model .",
    "however , this destroys information on the source , since deviations between the true sky and the prior model are completely absorbed by such gain solutions .",
    "2 .   pointing selfcal should in principle improve the clean maps and thus produce better source model estimates .",
    "however , implementations of this remain unavailable to the public .",
    "3 .   meqtrees should in principle be able to do a maximum - likelihood solution for the source parameters and pointing errors simultaneously .",
    "however , only solutions for the latter has been demonstrated to work in practice and as we have argued , a maximum - likelihood solution produces a point estimate for the parameters which may be biased due to correlations .    instead",
    ", we apply a nave clean algorithm , followed by source extraction , to compare with biro as a worst case scenario in the case of time - varying pointing errors .",
    "note that we do provide prior information on the positions of the sources to clean , in the form of clean boxes .",
    "we use the clean implementation ( specifically the cotton - schwab algorithm ) in the software package casa to image the simulated datasets .",
    "the images were made with robust weighting with a robustness parameter of @xmath61 .",
    "we did 1000 iterations of clean with a loop gain of 0.1 .",
    "interactive cleaning was performed on the visibility data twice , once with masks defined around known source positions and then with masks defined around only those sources that were found during the cleaning procedure .",
    "the source extraction was performed interactively using pybdsm to ensure that the artefacts were not wrongly identified as sources .      to illustrate fitting a model to the raw data , we plot a subset of the visibilities in fig . [",
    "fig : vis ] with the best - fit visibilities as obtained by biro .",
    "[ fig : compare ] ( with numerical details in table [ tab : clean ] ) shows the comparison between the flux densities obtained by clean+se and those by biro .",
    "the flux densities of clean+se are on average biased due to undealt - with correlations with the pointing errors and underestimated uncertainties . additionally , because of the time - varying pointing errors corrupting the data , clean+se only manages to find 5 of the 17 sources .",
    "with polynomial pointing errors included in the simulations , bright artefacts dominated the final image resulting in the weaker sources being swamped .",
    "in contrast , because these correlations are taken into account , the bayesian approach is able to recover the true flux densities for all sources and to determine error bars that include the effects of all nuisance parameters . without the instrumental errors , biro achieves similar flux estimates to clean+se .",
    "[ fig : covmat ] shows a subset of the covariance matrix between parameters and fig .",
    "[ fig : contour ] shows an example 1@xmath13 and 2@xmath13 contour plot between pairs of parameters .",
    "the key result of fig . [",
    "fig : covmat ] is that it highlights the significant and complex correlations between the pointing errors and flux densities , i.e. the instrumental and science parameters , which therefore need to be estimated jointly allowing for the correlations .",
    "the ( anti-)correlations between pointing errors and flux densities are easy to understand qualitatively .",
    "consider a source on the flank of the main lobe of the primary beam , e.g. on the half - power point .",
    "if a given antenna mispoints _ towards _ the source , the source will be subject to a higher primary beam gain , in other words , it will be perceived as brighter by all baselines involving that antenna . mispointing _",
    "away _ from the source has the opposite effect .",
    "the nature of the correlation will also strongly depend on the position of the source with respect to the pointing centre .",
    "for example , a source near the centre of the main lobe ( i.e. on a ` flat ' part of the primary beam pattern ) will correlate very weakly with pointing error , while a source on the inner flank of the first sidelobe will correlate with mispointing _ away _ rather than _",
    "towards_. since different baselines contribute to different fourier mode measurements , pointing error will also have a complicated interaction with perceived source structure .",
    "similar arguments apply to beamwidth .    deriving the exact quantitative nature of this correlation analytically",
    "is highly impractical , which is why a technique like biro proves so powerful .",
    "this covariance matrix could be used to assist in calibration , study calibration parameters or as input to future mcmc analyses on similar datasets .",
    "in this example problem , we show that biro is able , using model selection @xcite , to choose the correct model in each of three different cases , distinguishing between an extended source , an unresolved point source and two close ( sub - synthesised - beam ) sources .",
    "the sources recovered are all smaller than the synthesised beam .",
    "this is known as super - resolution and has recently been shown to be possible with compressive sensing @xcite ( and to some extent @xcite ) .",
    "here we use the bayesian evidence to determine the correct model of these sub - synthesised - beam sources , with statistical significance .",
    "although in this example problem we exclude instrumental effects , they can , in general , be included as in example 1 .",
    "the datasets for this example use the same frequency , bandwidth , integration time and noise characteristics as the dataset simulated in section [ sec : joint ] .",
    "we simulate three datasets with three different sky models with all the sources away from the phase centre : a point source , a sub - synthesised - beam extended source modelled as a gaussian and two point sources separated by the distance the size of that gaussian .",
    "no instrumental effects were included in the model - selection simulations and the beam width and noise were assumed to be known .",
    "[ fig : source_sep ] shows the input model for all three cases in the left column .",
    "the point sources are parametrized by the stokes i flux density and the position as the distance from the phase centre , along two mutually perpendicular axes , @xmath27 and @xmath28 . the extended gaussian source has three more parameters in the form of the projections of the major axis on the @xmath27 and @xmath28 axes and the ratio of the minor to major axis , defined as : @xmath62 where @xmath63 and @xmath64 are the major and minor axes of the gaussian source and @xmath65 is the position angle ( the angle of rotation of the extended source ) .",
    "[ fig : gaussian ] for a visual description .",
    "the brightness matrix of eq.([eq : rime_full ] ) for an extended gaussian is simply the product of a gaussian and the brightness matrix for a point source .",
    "the rime is simple in this example , since there are no instrumental effects apart from the usual phase shift between antennas : @xmath66 where @xmath67 is a gaussian in @xmath27 and @xmath28 for the extended source case and @xmath68 is a delta function for the one and two - source models .",
    "also in the one and two - source models , @xmath27 and @xmath28 reduce to single points @xmath69 and @xmath70 , as in eq.([eq : rime1 ] ) .    .",
    "the reader is reminded that this dataset contains no direction - independent effects that may normally cause biases in a clean analysis ; these biases are instead due entirely to the complexities in the dataset introduced by the time - varying pointing errors . ]     and 2@xmath13 probability densities are shown in dark and light colours respectively . the true ( input ) parameters are marked with a black star .",
    "the pairs of parameters are : _ upper left : _ the two highest order coefficients of the pointing error in the right ascension direction for antenna 9 .",
    "_ upper right : _ flux densities of two of the sources .",
    "_ lower left : _ the flux density of the 17th source vs the beam width . _",
    "lower right : _ the constant term from the polynomial pointing error in the right ascension direction for antenna 10 vs the flux density of the 15th source . ]     and @xmath64 are the major and minor axes of the gaussian and @xmath65 is the position angle .",
    "meqtrees uses @xmath71 , @xmath72 and @xmath73 in its parameterisation of a gaussian . ]",
    "we use multinest for calculating the bayesian evidence ( see section [ sec : bayes ] ) and meqtrees for predicting the model visibilities from the sampled source parameters from which the likelihood is computed iteratively .",
    "the likelihood is computed according to eq.([eq : likelihood ] ) .",
    "the posterior probability distributions are obtained as a by - product along with the uncertainties in the best - fit parameter values and the bayesian evidence .    for the single - point - source model ,",
    "we vary three parameters : the flux density and relative source position , @xmath27 and @xmath28 .",
    "we similarly vary the flux densities and positions of the two sources in the two - source model .",
    "the gaussian extended source model has six parameters : the flux density , position coordinates , and the shape parameters ( @xmath71 , @xmath72 , @xmath74 ) .",
    "we generate a unique , simulated dataset for each of the three cases and then fit each of the three models to them , to see if the correct model is selected in each case .",
    "multinest fits for the parameters , their uncertainties and correlations ( just as mcmc does in example 1 ) , but also returns the evidence , @xmath7 ( the probability of the data , given the hypothesis ) . by taking the ratio of evidences",
    ", one can determine whether one model is favoured over another , and by how much .",
    "the jeffrey s scale @xcite provides an intuitive way of deciding whether the evidence is strong enough to select a model , based on odds derived directly from the evidence .",
    "we use uniform priors for all the source parameters .",
    "the flux density is restricted to the range 0 to 2 jy . the position parameters are allowed to be both positive and negative in the range -@xmath75 to @xmath75 since the position is measured relative to the phase centre . for the shape parameters of the extended source , ( @xmath71 and @xmath72 ) , we allow the prior ranges to be big enough to encompass the point - spread - function ( psf ) of the interferometer and no more , since we are dealing with sub - synthesised - beam sources .",
    "this translates to a range of @xmath76 to @xmath77 for @xmath71 and -@xmath77 to @xmath77 for @xmath72 . finally , we restrict the minor - to - major axis ratio ( @xmath74 ) to be positive , but less than unity to be physically meaningful .",
    "we found that using 1000 live points achieved good results from multinest .",
    "the relative logarithmic evidences are computed for each model giving the relative confidence with which one model is preferred over another ( see table [ tab : evmatrix ] ) .",
    "we find that the correct hypothesis is selected in all cases , at odds of @xmath78:1 , @xmath79:1 and 62:1 , for the two - point - source , extended - source and single - point - source models respectively .",
    "using model selection , biro is able to select the correct model in all three cases ( the model with the highest evidence ) , showing it can perform source separation even on sub - synthesised - beam scales .",
    "we computed a ` best - fitting ' image by running meqtrees with the maximum posterior model and parameters in each of the three cases , to compare with the cleaned image ( see fig .",
    "[ fig : source_sep ] ) .",
    "we use the same clean parameters as in section [ sec : clean ] . the cleaned images ( at least in this case , without an enforced smaller beam size ) are unable to reach the sub - synthesised beam scales achievable by biro .    in fig .",
    "[ fig : crossover ] , we determine the point at which model selection fails to distinguish an extended source from a point source for different source sizes and signal - to - noise ratios ( snrs ) .",
    "any evidence lower than ` strong ' is not usually considered high enough to say either way which model is correct .",
    "perhaps obviously , at high snr extremely small sources can be detected ( around 1.0 arcseconds ) and sources become more difficult to distinguish as the snr is reduced .",
    "video [ vid : gaussian ] in the online - only content shows visually how multinest converges to the correct model , exploring the posterior as it goes , for the extended source model .",
    "each frame is an image generated using the parameters from every @xmath80 step of the chain .",
    "we have introduced the technique bayesian inference for radio observations ( biro ) , a bayesian approach to the deconvolution problem of radio interferometry . instead of making an image and then performing source extraction , biro uses mcmc or nested sampling to fit models directly to the visibility data and obtain the posterior for the parameters of interest , as well as nuisance parameters .    in the first example problem , we focused on the relationship between scientific and instrumental parameters .",
    "it was found that all parameter estimates from biro were consistent within their error bars with the true values .",
    "as well as determining the uncertainties of the parameters , biro also returns the covariance matrix between them , as a by - product of the full posterior .",
    "our work shows these correlations are complicated and non - negligible .",
    "biro effortlessly incorporates the effects of the correlations in the estimates of the marginalised uncertainties on the individual parameters , as well as providing a way to study these correlations in the form of the covariance matrix .",
    "we compared our results to a standard clean algorithm , without calibration ( since our simulated data contains _ only _ direction - dependent effects and publicly available calibration algorithms only deal with direction - independent effects ) . because of the time - varying pointing errors we introduce to the dataset , clean is only able to find 5 out of the 17 sources and returns biased flux densities for them , while biro returns unbiased flux densities for all sources .",
    "biro is also able to correctly determine the coefficients of the time - varying pointing errors , the primary beam width and the noise on the visibilities .    in the second example problem",
    ", we addressed the issue of how to determine the best sky model for the data .",
    "we worked with three models : a single point source , a gaussian extended source and two point sources . we simulated data for each of the three models and then , for each dataset , ran multinest to fit each of the three models and determine the bayesian evidence .",
    "the evidence then determines the selection of the correct model .",
    "all of the sources detected were several times smaller than the synthesised beam , hence we successfully achieved super - resolution as well as source - separation .",
    "this paper constitutes a proof of concept but more work is required before the technique can be easily applied to interferometric dataset :    1 .",
    "firstly , while using a wsrt simulation has relevance to the ska due to the similar instrumental setup , the ska will have many more antennas ( on the order of a thousand ) which will of course result in many more instrumental parameters ( and indirectly more science parameters as the source count increases with sensitivity ) .",
    "fortunately , while the number of instrumental parameters scales as the number of antennas , @xmath12 , the number of datapoints scales as the number of baselines , i.e. @xmath81(@xmath82 ) , meaning it is plausible that one could simultaneously determine the sky and instrumental parameters for large @xmath12 .",
    "while the precedent for sampling an extremely large parameter space exists @xcite , new and sophisticated sampling techniques @xcite ( which are also easily parallelised ) will be required to improve convergence in the thousand - parameter regime , especially as the non - linear nature of the modelling makes sampling inefficient ( as addressed in @xcite ) .",
    "secondly , the bayesian approach is far more computationally intensive than standard deconvolution , taking hours ( 55 cpu hours in the case of example 1 ) to converge to the correct posterior distribution .",
    "the complexity of the likelihood computation scales as the number of antennas squared ( i.e. the number of baselines ) , making an ska - like computation difficult with the current setup .",
    "however , the rime is intrinsically highly parallelisable allowing an efficient implementation of meqtrees on gpus .",
    "preliminary work on a gpu implementation indicates a speed - up of the likelihood computation of about 250 times @xcite .",
    "this means this technique can be applied to data from existing telescopes such as alma @xcite and lofar @xcite , using current computer clusters .",
    "thirdly , we need to address the problem of not knowing the sky model beforehand , which is a common difficulty when dealing with calibration but is particularly important here , as a bayesian analysis relies on a good model .",
    "there are a number of ways to tackle this issue which we hope to address in future publications . a simple , but computationally - intensive",
    ", solution would be to run several different models ( with increasing numbers of sources ) and select between them using the bayesian evidence .",
    "another possible approach is to use a deconvolution algorithm , like clean or resolve , to get an initial set of sources and then iterate between deconvolution and the best fit of biro to get a subsequently better model .",
    "a more rigorous solution would be to use an algorithm like birth - death @xcite or reversible jump @xcite mcmc , which is able to determine both the number of parameters required and the posterior for them simultaneously .",
    "a further possibility is to combine the more general approach proposed in @xcite and @xcite , that divides up the field into many ` pixels ' that are then allowed to vary , with the calibration capabilities of biro to produce estimates of the sky model .",
    "this is even more computationally challenging however but would provide a more general and robust solution .",
    "+    biro is not only useful for dealing with systematics , which will become more important as telescopes become more sensitive , but it is also a powerful technique for lending statistical strength to topical scientific questions .",
    "potential applications include : structures of black hole systems , jet emission in active galaxies , time variability of objects and radio weak lensing .",
    "biro allows a holistic way to include instrumental effects while at the same time returning the science we are interested in . by leveraging the power of bayesian statistics",
    ", biro uses all information available to get the most out of interferometric datasets .",
    "we would like to thank paul sutter for his useful referee comments .",
    "m.l . and j.z .",
    "are grateful to the south africa national research foundation square kilometre array project for financial support . m.l . acknowledges support from the university of cape town and resources from the african institute for mathematical sciences .",
    "is supported by the south african research chairs initiative of the department of science and technology and national research foundation . b.b .",
    "acknowledges funding from the south african national research foundation .",
    "i.n . acknowledges the meerkat hpc for radio astronomy programme .",
    "part of the computations were performed using facilities provided by the university of cape town s icts high performance computing team : http://hpc.uct.ac.za .",
    "this project was initiated at the superjedi mauritius conference .",
    "m.l . performed the research for the joint estimation example and wrote the majority of the paper .",
    "i.n . performed the research for the source separation problem and wrote the corresponding sections of the paper and did some clean analysis and wrote the corresponding section .",
    "j.z . assisted with the source separation research and wrote part of the paper .",
    "o.s . provided the simulated datasets and led the technical aspects of radio observation modeling .",
    "b.b . developed the original idea .",
    "n.o . performed some clean analysis .",
    "m.k . contributed to the conceptual development of ideas and provided support with the statistical methods .",
    "all authors commented on the research and edited the paper .",
    "[ references ]",
    "here we introduce bayesian factor graphs , useful tools for visualising bayesian models , which we use to describe the model of section [ sec : joint ] .",
    "we make use of the directed factor graph notation , developed in @xcite , to visualise how the parameters in our models depend on one another .",
    "table [ table : factor ] defines the graphical primitives of a factor graph .",
    "figure [ fig : factor_ex ] demonstrates the use of the factor graph notation in a simple example .    , which we suspect is normally distributed .",
    "this is modelled by a normal distribution ( represented by the factor labeled @xmath83 ) which is governed by the parameters @xmath84 and @xmath13 .",
    "these constants would be the parameters we would want to estimate with an mcmc or multinest analysis . ]"
  ],
  "abstract_text": [
    "<S> new telescopes like the square kilometre array ( ska ) will push into a new sensitivity regime and expose systematics , such as direction - dependent effects , that could previously be ignored . </S>",
    "<S> current methods for handling such systematics rely on alternating best estimates of instrumental calibration and models of the underlying sky , which can lead to inadequate uncertainty estimates and biased results because any correlations between parameters are ignored . </S>",
    "<S> these deconvolution algorithms produce a single image that is assumed to be a true representation of the sky , when in fact it is just one realisation of an infinite ensemble of images compatible with the noise in the data . </S>",
    "<S> in contrast , here we report a bayesian formalism that simultaneously infers both systematics and science . </S>",
    "<S> our technique , bayesian inference for radio observations ( biro ) , determines all parameters directly from the raw data , bypassing image - making entirely , by sampling from the joint posterior probability distribution . </S>",
    "<S> this enables it to derive both correlations and accurate uncertainties , making use of the flexible software meqtrees to model the sky and telescope simultaneously . </S>",
    "<S> we demonstrate biro with two simulated sets of westerbork synthesis radio telescope datasets . in the first </S>",
    "<S> , we perform joint estimates of 103 scientific ( flux densities of sources ) and instrumental ( pointing errors , beam width and noise ) parameters . in the second example </S>",
    "<S> , we perform source separation with biro . using the bayesian evidence </S>",
    "<S> , we can accurately select between a single point source , two point sources and an extended gaussian source , allowing for ` super - resolution ' on scales much smaller than the synthesised beam .    </S>",
    "<S> [ firstpage ]    methods : data analysis  methods : statistical  techniques : inteferometric . </S>"
  ]
}