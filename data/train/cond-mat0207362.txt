{
  "article_text": [
    "claude shannon , more than half a century ago , has introduced the modern information theory @xcite . this theory was a timely contribution to the the explosive growth of long distance communications during , or just after , war time .",
    "he studied , in a general framework , the coding strategies that allow one to send a message through a noisy channel , such that the received signal contains no error .",
    "actually , it is an easy task , if one is allowed unlimited _ information capacity _ , that is , infinite number of bits transmitted through the channel in a time unit .",
    "for instance , one could repeat the same binary signal many times . on the receiving end , taking the average or using the majority rule @xcite , the original message can be restored to any desired precision .",
    "but , unlike in academic economics literature , unlimited information resources are not available .",
    "therefore , one usually deals with the problem of minimizing the information capacity needed to transmit messages with a required degree of precision .",
    "indeed , one can code a message in an efficient way such that only a very limited amount of redundancy is needed .",
    "for this purpose , shannon proved two fundamental theorems and found a lower bound on the necessary redundancy . however",
    ", his theory does not provide a constructive method to code signals .",
    "in other words , no methods were introduced by shannon to solve the problem , except in some very special cases . since then , a number of coding methods have been built , that reach the optimal efficiency computed by shannon .",
    "indeed , much of the state - of - art of the information theory is dedicated to sophisticated coding / decoding business @xcite .",
    "the current internet era poses new challenges .",
    "nowadays , the problem does not lie in the lack of information , but in the fact that too much of it is available .",
    "one therefore has to set up methods to sort the specific information out of a highly disordered environment according to any given relevance criteria . having infinite resources , in principle one could examine in depth each available information source , selecting the relevant ones .",
    "unfortunately , one does not have such resources .",
    "many recent researches emphasize that scarcity does not affect available information any longer , but rather the capability to process it . in other words ,",
    "the most valuable good of the new economic era is _ attention _ @xcite .",
    "thus , in a finite time one can obtain at most an approximate estimate of the true relevance of all available information sources .",
    "in addition , in many common cases the quality of an information source can not be observed directly , but only through comparison with peers .",
    "for example , one can not measure the intrinsic relevance of a web page by simply observing it : most of the times , one needs a collection of other pages to compare their content , in order to choose the best .",
    "unfortunately , the results of such comparisons are often fuzzy , since a clear - cut assessment would need prohibitive amount of time and attention resources .",
    "nevertheless , a certain number of matches allows one to have an approximate estimate of the intrinsic relevance .",
    "clearly , as the number of matches is increased , the accuracy in the observation grows .    finally , the results of a search have to be presented in a shape which takes into account the human interaction .",
    "for example , new generation www search engines put a strong effort in establishing reliable _ rankings _ of relevant web pages matching any given query @xcite . instead of showing a whole rankings , some search engine provide a restriced number of matches to a query , or even a single one , as in google s `` i m feeling lucky '' option .",
    "again , this option implies a neat gain in ease at use , though it rarely corresponds to the best possible answer .    in this paper",
    "we propose a toy model of information filtering .",
    "our model deals with the problem of finding the most relevant element from a large set , in presence of a stochastic _ noise _ which prevents a perfect perception of the intrinsic quality of each item . for the sake of simplicity",
    ", we represent the quality of each item by a real number randomly drawn from a uniform distribution in the range @xmath0 $ ] .    knowing all the qualities",
    ", it would be trivial to sort the items and build a ranking : in this case , the higher the quality of an item , the higher its rank .",
    "but , as explained above , we assume that these numbers can not be accessed directly : any information can be obtained by a noisy comparisons among the items .",
    "in particular , we choose a pairwise filtering architecture , i.e. information can be gathered only by comparing pairs of items .    for a real life instance",
    ", one could think to football teams in a national league . to choose the best team",
    ", we can not restrict ourselves to examine each team and draw a judgment : many people do so , without ever reaching an ultimate answer . on the other hand",
    ", we can guess an approximate answers , using a finite number of pairwise matches .",
    "actually , the outcome of a match does not signal precisely a better intrinsic quality of one team over the other .",
    "but if a team is intrinsically better than another one , it has a greater chance of winning in a real game .",
    "if an infinite number of games was allowed , we would be able to discern the intrinsic superiority by pitting two teams against each other .    in reality",
    ", we must be content with approximate answers , using rather a limited number of comparisons ( in the soccer language , number of games ) .",
    "clearly , this introduces a design problem .",
    "the aim is to get as good an approximation using a given number of comparisons ; or , equivalently , to achieve a given level of approximation using minimalizing necessary resources . in this sense , we say our approach is a generalization of shannon s information theory .    from sport events , we learn that a different structure gives rise to a different quality of filtering . in the final round of the soccer world cup , for example , teams are disqualified after a single defeat , up to the final match .",
    "this architecture does not often yield a very good approximation of intrinsic quality ranking , because a good team defeated by a worse team will be put out of the competition .",
    "but this tree structure is the msot economical one , needing a minimal number of games .    on the other hand , in european national leagues",
    "each team plays each other .",
    "this structure yields in general a more reliable approximation of the intrinsic ranking , since more redundancy is built into the scheme , as teams are not menaced from chancy elimination .",
    "but , as in shannon information theory , more precision requires more resources , and a trade - off has to be made between the two considerations . in our metaphor ,",
    "the world cup need less time resources , usually one month , whereas many national leagues take almost a year .",
    "this example illustrates the dilemma .",
    "we study a very simple design structure which allows both elimination of low quality items , which decreases the time needed to the final selection , and a certain degree of redundancy , which provides reliability to our mechanism .",
    "the underlying structure of our filtering model is a one - dimensional lattice of @xmath1 nodes with periodic boundary conditions .",
    "time is assumed to be an integer variable @xmath2 .",
    "every node @xmath3 is attached a value @xmath4 .",
    "the starting configuration is an array @xmath5 of random variables drawn from the range @xmath0 $ ] with uniform probability : these values represent the intrinsic qualities we introduced above . at each time step",
    ", every couple of neighbors values @xmath6 for @xmath7 gives rise to a new value @xmath8 , according to the following rule : @xmath9 therefore , in a time step the whole array is updated .",
    "the periodic boundary conditions ensure that @xmath10 for all values of @xmath11 , and thus consistency of the evolution law .",
    "as the chain evolves , connected _ domains _ , i.e. regions of the lattice composed of sites occupied by the same value , emerge : high values have a greater probability to spread over neighbor sites , and low values are more likely to vanish , as described in figure [ fig0 ] .",
    "eventually , after a time @xmath12 , all sites are occupied by a single domain associated to the value @xmath13 : the process has reached a stationary state .",
    "accordingly , we call this system a _ filter _ , since it exerts a selection on the initial @xmath1 values , favoring by its dynamics the propagation of domains associated with high values .    the value @xmath13 is attached to a given site @xmath14 in the starting configuration , i.e. @xmath15 .",
    "we say that the site @xmath16 and the value @xmath17 associated with it at the beginning have been _ selected _ by the filter .",
    "we define the _ search _ time @xmath18 needed to reach the stationary state , and the @xmath19 of this filter , i.e. the rank @xmath20 of the selected value in the starting configuration .",
    "an ideal filter would select the site associated to the highest value in the starting configuration ( @xmath21 ) . due to the randomness in the initial condition and the stochastic dynamics , our filter may select a different site .",
    "we will investigate these two quantities , @xmath22 and @xmath20 , as a function of the total number of sites @xmath1 .",
    "the number of _ different _ values in the lattice monotonically decreases with time .",
    "we denote by @xmath23 the number of these domains . a relation between @xmath11 , @xmath1 and @xmath24",
    "can be derived by simple reasoning .",
    "let us assume that at time @xmath25 only @xmath24 domains remain in a chain of length @xmath1 .",
    "each of them occupies , on average , a region of size @xmath26 .",
    "therefore , @xmath25 approximately corresponds to the time needed to reach the stationary state for a filter acting over this sub - region of size @xmath26 .",
    "this reads @xmath27 by assuming @xmath28 , with @xmath29 and @xmath30 , we write @xmath31 , and replace this expression in eq . [ hier1 ] , this way , we obtain @xmath32 which implies @xmath33 and @xmath34",
    ". this rough estimate of the scaling behavior with respect to @xmath1 is confirmed by the analysis of the population dynamics of the coalescing domain walls .",
    "at time @xmath35 , there are @xmath1 domain walls , since each domain is made of a single site . as time passes by , domains vanishes .",
    "a domain vanishes when the two surrounding domain walls coalesce . by tracing all the domain walls as a function of time , following the framework of",
    "@xmath36 dimensional directed polymers , we observe a tree - like structure , whose source is in the end point of the filter process . at time",
    "@xmath11 the lattice is occupied by @xmath23 domains @xmath37 , corresponding to the values @xmath38 , with @xmath39 .",
    "let us denote by @xmath40 the position of the @xmath41-th wall between domains @xmath37 and @xmath42 .",
    "the wall between these domains performs a random walk of unitary steps whose _ drift _ @xmath43 is equal to @xmath44 . to evaluate the time @xmath45 between two subsequent coalescing along the same domain wall , when the surviving domain walls are @xmath24 , we write @xmath46 where @xmath47 is the average length of a domain , and @xmath48 is the typical speed with which a wall moves towards its neighbor , and the average",
    "is performed over the distribution of the remaining values @xmath49 at time @xmath11 .",
    "therefore @xmath50 is the probability per time step that a domain wall encounters a neighbor .",
    "since there are @xmath24 walls , the total probability of a coalescing anywhere in the lattice is @xmath51 . at each intersection ,",
    "the number of walls decreases by one , therefore we can write a differential equation for @xmath23 , @xmath52 we can give an estimate of @xmath48 by assuming that the values @xmath53 are uniformly distributed in the range @xmath54 $ ] . under this assumption , @xmath55.\\end{aligned}\\ ] ] if the remaining domains are @xmath56 , we can expand this expression in a series of powers up to the first order in @xmath57 , getting @xmath58 by replacing eq .",
    "( [ drift ] ) in eq .",
    "( [ delta ] ) , we obtain @xmath59",
    ". then , for @xmath56 , the time evolution of @xmath23 reads @xmath60 .",
    "given the assumption made on the scaling behavior of @xmath24 with respect to @xmath11 and @xmath1 , the previous equation provides us with two relations for @xmath61 and @xmath62 , which yield @xmath63 and @xmath33 . by replacing the steady state condition @xmath64 in the scaling relation of @xmath24 as a function of @xmath11 and @xmath1",
    ", we obtain @xmath65 .",
    "this gives the scaling relation @xmath66 which is confirmed by numerical simulation , as shown in fig .",
    "to compute the inefficiency of the filter , we have to estimate the rank of the finally selected value in the starting configuration .",
    "let us make some strong ( but reasonable ) approximation : ( i ) we assume that the distribution @xmath67 of the remaining @xmath68 numbers on the lattice is uniform for all times , with mean value @xmath69 and support @xmath70 $ ] .",
    "( ii ) we make a mean field approximation about the time evolution of the domains . in order to explain better hypothesis ( ii ) ,",
    "let us focus on a single domain .",
    "let @xmath71 be the value occupying a domain , @xmath72 the length of this domain , @xmath73 and @xmath74 the values occupying the neighboring domains .",
    "the time evolution of @xmath75 reads @xmath76\\ ] ] where @xmath77 we now replace in eq .",
    "( [ timev ] ) the neighboring values @xmath78 by the mean value of the distribution of remaining numbers , @xmath69 .",
    "this assumption is equivalent to considering each domain size as a biased random walk starting at position @xmath79 with an absorbing boundary at the origin ( that corresponds to the coalescence of two neighboring domain walls ) .",
    "the bias of the random walk is given by the interaction between the domain occupied by the value @xmath71 and the effective medium , which is assumed to be occupied by the value @xmath69 .",
    "in the same mean field approach , we assume that @xmath80 , which is the typical distance between two adjacent walls .",
    "such a random walk @xcite is absorbed by the boundary with probability @xmath81 if @xmath82 and probability @xmath83 otherwise . in both cases",
    ", the absorption occurs after the same typical time @xmath84 .",
    "after @xmath85 typical times ( not all equal ! ) , the mean value of the distribution is @xmath86 .",
    "in fact , in our approximation , during a typical time all domains occupied by values lower than @xmath69 have vanished , as does a fraction of the domains occupied by values higher than @xmath69 .",
    "this fraction is estimated by @xmath87 for large @xmath85 and @xmath1 .",
    "thus , we can write the time evolution ( more precisely than in the previous section ) for the number of domains after @xmath85 typical times , @xmath88 , which reads @xmath89 \\\\         & = & \\frac{1}{2 } n(m)[1 - e^{-2^{-m}n^{-1}(m)l}].\\end{aligned}\\ ] ] if we define @xmath90 and if we consider @xmath85 as a continuous variable , the last equation can be written as @xmath91 whose solution can be written in an implicit form by means of the exponential integral function @xmath92 @xmath93 there is a problem of treating the initial conditions properly .",
    "it is tempting to take the initial condition @xmath94 and therefore have formally @xmath95 .",
    "however , it is not a prudent approximation to assume the variable @xmath85 as continuous for very small values . taking the the initial condition for @xmath96 we do not know how to compute reliably the value @xmath97 .",
    "however , we found that with @xmath98 and @xmath99 , i.e. @xmath100 we match well the numerical simulations data .",
    "thus , we have the equation @xmath101 , where @xmath102 for the estimated rank @xmath20 , we have @xmath103 , for the assumptions ( i ) .",
    "let us define the reduced variable @xmath104 , @xmath105 $ ] so that we can write @xmath106 .",
    "for @xmath107 we have the equation @xmath108 , thus @xmath109 for @xmath110 we have @xmath111 ( we checked by plotting the functions that it holds well for @xmath112 larger than @xmath113 ) , so we end up with the conclusion that asymptotically for @xmath114 the rank behaves like @xmath115 however , this asymptotic regime is reached only for extremely large systems .",
    "rank @xmath112 larger than about 30 means @xmath1 larger than about @xmath116 : a number beyond any imaginable application . for smaller sizes ,",
    "up to about @xmath117 , we found approximately , by expanding the lhs of equation ( [ eq : forphic ] ) in taylor series around @xmath118 and by replacing @xmath112 by @xmath119 , @xmath120 we may compare this result with numerical results and find an excellent agreement , as shows fig .",
    "in order to improve the performance of the filter , one could follow the suggestions coming from the shannon information theory @xcite , where the addition of redundant information ( e.g. , by repeating the transmission of the message ) helps in recovering the source information . in the same approach",
    ", we could build a number @xmath61 of replicas of the initial chain , in which each site corresponds to a different value . then , by linking the @xmath61 chains together , keeping periodic boundary condition , we obtain a chain of length @xmath121 . in the same shannon s spirit , we could wonder if there exists a finite value @xmath122of @xmath61 such that the inefficiency of the filter decreases to its minimal value , and the final selected value is ( almost ) always the highest one . in the new @xmath123-chain",
    ", the first @xmath61 places in the ranking of the values are occupied by the @xmath61 replicas .",
    "therefore , if @xmath124 , the selected value is the best one attached to a replica of the original site .",
    "we have the following condition for @xmath122 , @xmath125 which has a finite solution @xmath126 , for all values of @xmath1 , which increases with @xmath1 . as a consequence ,",
    "however , the number of matches that have to be done to reach a steady state is increased as the number of sites grows from @xmath1 to @xmath121 .",
    "we denote by @xmath127 the total number of matches needed to reach a steady state in a chain of @xmath128 sites . if we assume that each match costs a unit time , the quantity @xmath129 , is analogous to the inverse of the information capacity in shannon s theory , which decrease with increasing redundancy . in the original chain of length @xmath1 , at each time step @xmath1 matches are made .",
    "then , from [ t*_l ] , we have @xmath130 .",
    "> from the definition of @xmath131 , we get the relation @xmath132",
    "we have introduced a toy model of search engine , i.e. an algorithm which elects a _ best _ element in a large set , according to some relevance criterion .",
    "such a device is gaining a growing importance in the current information - based economy : nowadays , gathering large amounts of informations is a widely affordable task ; on the other hand , selecting , examining and judging information requires a huge ( and increasing ) processing capacity , though it is necessary to exploit such available information .",
    "these algorithms face two main problems .",
    "first , the exact relevance of an item ( an information , a webpage , a people ) in the most common situations can be measured only within a certain degree of uncertainty .",
    "only an infinite available time would allow a deep knowledge about the items .",
    "second , the results have to be presented in a user - friendly manner , e.g. in ranking order . in the extreme case ,",
    "the algorithm will even yield only the _ best _ selected item .",
    "this puzzle recalls the one solved by pioneers of information theory , who dealt with the challenge of recovering the original message transmitted through a noisy channel , by knowing only the corrupted received message .",
    "they established that , even with a finite information capacity , one is able to achieve error - free communication , though they rarely constructed such algorithms .",
    "analogously , nowadays one looks for methods that are able to order large sets of items with respect to their intrinsic relevance , without having a full knowledge about them .",
    "accordingly , we assumed that the quality of each element can not be measured directly , and one can only compare elements pairwise .",
    "each element is put on a site of a linear chain with periodic boundary conditions , and can spread over neighboring sites , thus creating domains .",
    "the `` search engine '' stops when a domain occupies the whole lattice and the value attached to the domain is selected as the _ best _ one .",
    "the model is approached by applying methods issued from a directed polymers field , since its properties can be investigated by focusing on the domain walls dynamics .",
    "we analytically computed the search time and the inefficiency of the `` filter '' , and verified our results by numerical simulations .",
    "most interestingly , we found that the error made by the filter ( the intrinsic ranking of the elected item ) grows only logarithmically with respect to the number of items .",
    "moreover , we determined the minimal redundancy to be added to the filter in order to achieve full efficiency , i.e. to always select the intrinsically most relevant item in the set . in the analogy with classical information theory , this would correspond to the well - known shannon limit .",
    "the authors thank p. laureti , p. de los rios , y. manida and y. pismak for useful discussions .",
    "this work was supported by the grant agency of the czech republic , grant project no .",
    "202/01/1091 , and by the swiss national fund , grant no . 20 - 61470.00 , and by the grant agency of the czech republic , grant no .",
    "f. slanina acknowledges the financial support from the university of fribourg , switzerland ."
  ],
  "abstract_text": [
    "<S> we introduce a new kind of information theory . from a finite number of local , noisy comparisons , we want to design a robust filter such that the outcome is a high ranking number </S>",
    "<S> , both analytical and numerical results are encouraging and we believe our toy model has wide ranging implications in the future internet - based information selection mechanism .    ,    , and </S>"
  ]
}