{
  "article_text": [
    "volatility is a magnitude aiming to capture how big is the amplitude of price return fluctuations  @xcite .",
    "it is associated with the risk of holding an asset stating that the higher the volatility the riskier the market price .",
    "investors pay sometimes more attention to volatility than to the price level or the current trend of a stock .",
    "the role of volatility becomes even more crucial when trading with financial derivatives like options since the value of volatility almost fully determines the price of this sort of contracts  @xcite .",
    "however , the volatility itself is not directly observed and the financial markets and their actors lack of an unique consensus for providing its value .",
    "therefore , there is no other choice than trying to infer in some way or another the value of volatility from price time series . in practice , this means that it is necessary to first assume a model governing financial asset dynamics and second to extract volatility value from data time series under the perspective of the model dynamics considered .",
    "the physicist osborne proposed the geometric brownian motion model ( gbm ) in 1959  @xcite .",
    "the gbm difussion process drives the logarithmic price changes with a constant diffusion coefficient typically called volatility . in this case",
    ", computing market volatility first means to calculate the standard deviation of the logarithmic price changes over time periods of length @xmath0 . and ,",
    "secondly , volatility would then be the ratio between the standard deviation and the square root of @xmath0 since we are implicitly assuming the gbm difussion model .",
    "further studies in financial data have led to establish that the gbm is very incomplete  @xcite and it appears to be unable to explain quite a long list of stylized facts observed in financial markets  @xcite . specially during the last two decades , several models have been proposed with the aim of capturing ( i ) the existence of fatter tails in the log - price fluctuations , and ( ii ) the presence of non - trivial memory in the market dynamics  @xcite .",
    "a very natural improvement of the gbm is to consider volatility as a random process following another continuous time diffusion process  @xcite .",
    "the price and the hidden markov process for the volatility therefore configure a two - dimensional difussion process and the approach belongs to the so - called stochastic volatility ( sv ) modeling  @xcite .",
    "the approach is analogous to random diffusion modeling which describes dynamics of particles in random media and applicable to a large variety of phenomena in statistical physics and condensed matter  @xcite .    among the existing sv models",
    "@xcite , the most basic ones are the ornstein - uhlenbeck ( ou )  @xcite , the heston model  @xcite being in fact a feller process , and the exponential ornstein - uhlenbeck ( expou )  @xcite . with the aim of extracting volatility from financial markets data , the current work develops much further the maximum likelihood ( ml ) estimation applied to the expou model in ref .",
    "@xcite by one of us .",
    "we here extend the methodology to the ou and heston sv models but we also study some of the most important statistical features observed in financial markets  @xcite : the return and volatility probability densities ( pdf s ) , the volatility auto - correlation and the leverage correlation , and the mean first - passage time . for doing all these , we use eight daily indexes : dow jones industrial average ( dji ) , standard and poors-500 ( s&p ) , german index dax , japanese index nikkei , american index nasdaq , british index ftse-100 , spanish index ibex-35 and french index cac-40 .",
    "we also provide the method abilities of predicting future absolute value of price returns knowing today s volatility .",
    "this paper is divided into five sections . in section [ sec_stochvol ]",
    "we present the sv models and their main characteristics , while in section [ sec_maxlike ] we show the ml approach . in section [ sec_simres ]",
    "we provide results obtained from our algorithm .",
    "conclusions are left to section  [ sec_conclusions ] .",
    "the starting point of any sv model is the gbm model  @xcite @xmath1 where @xmath2 corresponds to a wiener noise ( i.e. , a zero mean and unit variance gaussian process ) , @xmath3 is a financial price or the value of an index , @xmath4 is the drift and @xmath5 is the volatility .",
    "if we define the zero - mean return @xmath6 as @xmath7 where @xmath8 is the initial time . let us note that @xmath6 assumes independent and stationary increments in the financial time series since osborne s work in 1959  @xcite . we can however rewrite eq .",
    "( [ eq_1 ] ) as follows @xmath9 the term @xmath5 was initially considered to be constant .",
    "however , most of the existing market models nowadays assumes that the term @xmath5 also called volatility is a time varying variable .",
    "sv models assume that the volatility is a hidden markov process @xmath10 where @xmath11 obeys a subordinated diffusive stochastic differential equation . under this perspective , the two - dimensional dynamics reads  @xcite @xmath12 where @xmath13 @xmath14 are wiener processes that may or not be independent . as @xmath15 is always defined as a monotonically increasing function , @xmath11 is sometimes also called volatility . as shown in tab .",
    "[ table_fgh ] , each model has its own expressions of @xmath15 , @xmath16 and @xmath17 .",
    "the proposed models in the literature change in terms of these functions but in general there is a wide consensus to consider process with a ( negative ) mean reverting force that leads the probability density function of the volatility to a stationary solution when time is sufficiently large .",
    "let us focus on the volatility estimation procedures .",
    "as a first approximation and as mentioned in the introduction , the volatility can be viewed as the standard deviation of the empirical daily zero - mean return changes @xmath18 as we are considering daily data , we are assuming discrete time increments @xmath19 and discrete return increments @xmath20 . in such a case , we are implicitly assuming the gbm provided by eq .",
    "( [ eq_3 ] ) with constant volatility in daily units .    as a second level of approximation",
    "we allow for time varying volatility . observing eq .",
    "( [ eq_3 ] ) , we now define volatility as @xmath21 and we have different volatility for different days . however , the volatility obtained has a skewed stationary probability density inconsistent with volatility modeling as discussed in refs .",
    "@xcite .",
    "a third possibility is to compute a deconvoluted volatility  @xcite @xmath22 which does not show a skewed probability density for the volatility but its greatest drawback is that estimated volatility appears to be a very noisy signal ( see for instance refs .",
    "@xcite for alternative approaches and further discussions ) .",
    "[ table_fgh ]    llll & expou & ou & heston + @xmath15 & @xmath23 & @xmath24 & @xmath25 + @xmath16 & @xmath26 & @xmath27 & @xmath27 + @xmath17 & @xmath28 & @xmath28 & @xmath29 +",
    "we here briefly present the methodology proposed in ref .",
    "@xcite that allows us to have some criteria for choosing the best values of the random realization @xmath30 . naively speaking",
    ", the method represents an improvement of the deconvoluted volatility @xmath31 estimator using a ml methodology .    to explain the procedure it is more convenient to work with the discrete time version of the model . to this end , suppose that @xmath0 is a small time step and that the driving noises in eqs .",
    "( [ eq_4])-([eq_5 ] ) can be approximated by @xmath32 where @xmath33 are independent standard gaussian processes with zero mean and unit variance .",
    "the discrete time equations of the model describing increments of @xmath6 and @xmath11 thus read @xmath34 where @xmath35 and @xmath36 . from eqs .",
    "( [ a4])([a5 ] ) , we can get @xmath37 for simplicity we assume that @xmath38 and @xmath39 are independent standard gaussians .",
    "we will discuss in section [ sec_corr ] that our methodology does not need to consider negative cross - correlation among these two gaussian variables as discussed for instance by the models studied in refs.@xcite .",
    "hence , @xmath40.\\ ] ] and this finally can be transformed into the conditional probability density function ( pdf ) @xmath41 . \\label{a10}\\end{aligned}\\ ] ] by including the jacobian of the transformation @xmath42 defined by eqs .",
    "( [ a4])-([a5 ] ) .    for a given number of realizations",
    ", the probability of the set @xmath43 for the period @xmath44 can be easily obtained .",
    "the markov property of the process ensures that one can decompose the joint pdf of this set as a chain of products between conditional pdf s @xmath45 substituting eqs .",
    "( [ a6])-([a7 ] ) into eq .",
    "( [ a10 ] ) and inserting them into eq .",
    "( [ markov ] ) , we apply the chain of products between conditional pdf s and we finally get the joint pdf @xmath46 \\nonumber",
    "\\\\ + \\ln { \\rm p}(x(t - s ) , y(t - s ) ) -\\frac{1}{2}\\sum_{\\tau = t+\\delta t - s}^{t}\\left[\\frac{x(\\tau)-x(\\tau-\\delta t)}{f(y(\\tau-\\delta t))\\delta t}\\right]^2 \\delta t \\nonumber \\\\",
    "-\\frac{1}{2}\\sum_{\\tau = t+\\delta t - s}^{t}\\left[\\frac{y(\\tau)-y(\\tau-\\delta t)}{h(y(\\tau-\\delta t))\\delta t}+ \\frac{g(y(\\tau-\\delta t))}{h(y(\\tau-\\delta t))}\\right]^2\\delta t. \\label{a11}\\end{aligned}\\ ] ]    we remind that our aim is to find a proper realization of the volatility @xmath47 given a return @xmath48 and this will be done by applying a ml procedure to variable @xmath47 . for this reason , we will be able to omit three terms in eq .",
    "( [ a11 ] ) .",
    "the first summand comes from the normalization constant of the gaussian distribution  ( [ a10 ] ) .",
    "it appears in every conditional probability density and this is the reason for the factor @xmath49 , which is the number of time steps between @xmath50 and @xmath51 .",
    "the resulting term does not depend on the realization , so that we can neglect it for a maximization with respect to the set of realizations @xmath52 .",
    "the second summand is mostly the sum of the jacobian transformations of each transition probability .",
    "stochastic volatility models assume that these @xmath53 and @xmath54 are continuous and monotonically increasing functions or even constants .",
    "because of this , we can also neglect this term in the maximization procedure .",
    "the term @xmath55 is fixed by the initial conditions of the process .",
    "we could here assume a known initial return @xmath48  which can be set to zero  and take a random @xmath56 following its stationary distribution .",
    "therefore we would have @xmath57 .",
    "had we taken another initial condition , the technique would have given equivalent results ( we have checked this by using several initial distributions ) .",
    "for this reason and in order to improve the convergence of the ml estimate we have neglected also this contribution .",
    "we can therefore write @xmath58 ^ 2 \\delta t \\nonumber\\\\   -\\frac{1}{2}\\sum_{\\tau = t+\\delta t - s}^{t}\\left[\\frac{y(\\tau-\\delta t)}{h(y(\\tau-\\delta t)}\\delta t+ \\frac{g(y(\\tau-\\delta t))}{h(y(\\tau-\\delta t))}\\right]^2\\delta t+\\cdots\\nonumber \\\\ \\label{eq_6}\\end{aligned}\\ ] ] and omit the other three terms for the reasons summarized above ( cf .",
    "( [ a11 ] ) ) .",
    "further details can be found in ref .",
    "@xcite .",
    "let us finally briefly provide an interpretation for the two remaining terms in eq .",
    "( [ eq_6 ] ) . the first term of eq .",
    "( [ eq_6 ] ) measures the return variations with respect to the volatility .",
    "we notice that the higher the fluctuations are , the lower the contribution to the probability is .",
    "the second term computes the fluctuations of the volatility with respect to the volatility of the volatility . again , the bigger this term , the lower the contribution .     computed using eq .",
    "( [ eq_11 ] ) .",
    "the other plots show estimated volatilities @xmath59 calculated for the three different models as explained in section [ sect3a ] and eq .",
    "( [ estimation ] ) . ]",
    "as mentioned above , our goal is to find a proper realization of the volatility series @xmath60 given return series @xmath61 which is directly observed and taken from empirical data .",
    "we then should however consider the following conditional probability of a single event @xmath62 and as we solely want to maximize this probability for a fixed set of returns configuring a path , the second term can be neglected and therefore maximizing eq .",
    "( [ eq_8 ] ) is equivalent to maximizing eq .",
    "( [ eq_6 ] ) . in practice",
    ", the method therefore computes different realizations of volatility variable for a given return path and ml estimation dictates that we should take the realization that makes bigger the probability given by eq .",
    "( [ eq_6 ] ) .",
    "the method filters the wiener noise @xmath63 and let us obtain an estimation @xmath64 of the hidden volatility for a given price return evolution .",
    "specifically , we have implemented an algorithm which sequentially follows the four steps :    1 .",
    "looking at eq .",
    "( [ eq_4 ] ) , we generate a simple realization of y by taking @xmath65 where @xmath66 , with @xmath67 taken from data , and @xmath68 being a zero mean and unit variance gaussian realization .",
    "we substitute @xmath69 and @xmath48 into eq .",
    "( [ eq_6 ] ) and we then compute the probability .",
    "we iterate @xmath70 times the steps 1 and 2 .",
    "we finally keep the realization that brings a higher probability in eq .",
    "( [ eq_6 ] ) and define it as @xmath64 .",
    "finally , the estimator of the volatility at time @xmath51 is @xmath71    we observe that this procedure depends on @xmath70 and @xmath72 .",
    "we have implemented the algorithm with @xmath73 and @xmath74 .",
    "we have used these values because larger time window @xmath72 and a larger number @xmath70 of iterations do not improve the quality of our estimation .",
    "we observe that @xmath31 ( cf .",
    "( [ eq_11 ] ) ) is calculated with a single computed random value @xmath30 while @xmath59 chooses an optimal value after @xmath70 iterations . as observed in fig .",
    "[ comparison_sigma ] , @xmath59 with dow jones daily data from october 1928 to july 2011 and in all studied models is less noisy than @xmath31 .",
    "the fluctuation values of the deconvoluted is three or four orders of magnitude larger than the fluctuation values of the three ml algorithms herein proposed .",
    "we also stress the fact that the sv model jointly with their parameters are chosen before starting the computation .",
    "the parameters can however be easily estimated beforehand using historical data  @xcite .",
    "see for instance refs .",
    "@xcite for alternative procedures for reconstructing volatility being more or less dependent on the volatility model chosen .",
    "some of these approaches also include the parameter estimation procedure within the volatility estimation .",
    "others are mainly devoted to capture the long term memory of the volatility .",
    "we here study the probability density of the volatility , the conditional return , the mean first passage time ( mfpt ) and the two most important correlations with time ( volatility auto - correlation and return - volatility asymmetric correlation or leverage effect ) along the three different sv models .",
    "data to perform comparisons across the different models described in sections  [ sec_behaviour]-[sec_corr ] corresponds to the dow jones daily data from october 1928 to july 2011 but section  [ sec_diffindexes ] extends the survey to other financial market indices .",
    "the parameters we use for the numerical calculations are those given in literature to reproduce the dji @xcite and they are summarized in tab .  [ table_alphamkcoef ] .",
    "llll & @xmath28 & @xmath75 & @xmath76 + ou & @xmath77 & @xmath78 & @xmath79 + heston & @xmath80 & @xmath81 & @xmath82 + expou & @xmath83 & @xmath84 & @xmath85 +       ( cf .",
    "( [ eq_11 ] ) for the dow jones data and the @xmath86 for the expou , the ou and the heston cases ( cf eqs .",
    "( [ eq_6 ] ) , ( [ estimation ] ) and table [ table_fgh ] ) .",
    "we also include theoretical stationary pdf forms for each model .",
    "the expou seems to be the one that better corroborates theoretical pdf form . ]",
    "calculated using eq .",
    "( [ eq_3 ] ) .",
    "we observe that the expou model is the one that provides worse agreement with empirical data probably because of its high sensitivity of the parameter calibration . ]    in order to compare how our algorithm works on each model , we have first calculated the probability distribution of the different volatilities . just for the sake of completeness",
    "we represent the stationary volatility probability density function ( pdf ) in fig .",
    "[ pdf_volatility ] thus showing , as expected , that the form of the curves depends on the model choice .",
    "it should be noticed that we have used the absolute value of the volatility in the case of the ou model for the whole paper .",
    "figure  [ pdf_volatility ] also shows that best agreement between theoretical curve and empirical data points corresponds to the expou case .",
    "several studies in the literature have measured volatility stationary pdf  @xcite and all of them suggest an exponential decay corresponding to a log - normal curve  @xcite or an inverse gamma distribution  @xcite at least with low frequency data . it shall however be noted that a very recent model with a two - dimensional diffusion process succeeds to provide an inverse gamma distribution  @xcite and it can be indeed interesting to apply the methodology to this new model .",
    "we also compute artificial return fluctuations @xmath87 for each model by multiplying @xmath88 with a wiener noise realization as given by eq .",
    "( [ eq_3 ] ) .",
    "doing that , we can somehow compare the daily zero - mean return pdf of the three sv models with the empirical data of daily returns @xmath87 . in fig .",
    "[ pdfsreturn ] , we observe that the peak of empirical data @xmath87 is not reproduced by any model . in fig .",
    "[ pdfsreturn ] we see that the tails of the real @xmath87 are similar to empirical data in all models .",
    "the differences among the models can be explained by the fact that the parameter estimation in each model has not been systematically optimized .",
    "we observe that the expou model is the one that provides worse agreement with empirical data .",
    "a possible reason for that might be due to the fact that the expou model has a multiplicative relation with the underlying random process @xmath47 with @xmath89 and therefore needs a really accurate calibration ( cf . tab .",
    "[ table_fgh ] ) .      ) for the three different models .",
    "all the models are shifted for better understanding . in brackets",
    ", we can find the value of the slope of the linear regression .",
    "the points represent the medians and the error bars are the first and third quartiles in the bins . ]",
    "this section aims to look for some inferred behavior in future absolute value zero - mean return based on the estimation of current value of volatility .",
    "we first consider the logarithm of eq .",
    "( [ eq_3 ] ) @xmath90 and we can now obtain the conditional median of the empirical @xmath91 given we know @xmath92 through our ml method .",
    "in such a case , we should have the following linear regression for the conditional median @xmath93 = \\ln\\sigma(t)+ct,\\ ] ] where @xmath94 is a constant .",
    "[ logdx_logsigma ] we plot this relationship using the three different models .",
    "we there however observe the slopes are not equal to 1 . in this sense ,",
    "heston and ou model have the best performance although we should take into account that the performance might be very sensitive to the efficiency of the parameter estimation procedure .",
    "that appears in eq .",
    "( [ eq_14 ] ) .",
    "the error bars correspond to the error on the slope of the regression of fig .",
    "[ logdx_logsigma ] .",
    "the data has been divided in two regimes in the case of the expou and the ou models .",
    "all the plots are also shifted for sake of readability . ]",
    "[ table_abcoef ]    llllll & expou@xmath95 & expou@xmath96 & ou@xmath95 & ou@xmath96 & heston + @xmath97 & -0.12 & -0.064 & -0.15 & -0.064 & -0.048 + @xmath98 & 0.82 & 0.72 & 0.85 & 0.67 & 0.63 +    in any case , we still have a linear regression measuring how big is going to be price fluctuation today based on yesterday s volatility level .",
    "one can go one step further and use the observed relationship between price fluctuations and volatility to forecast price changes amplitude at a longer time @xmath99 based on volatility at time @xmath51 . a reasonable modification of the conditional median given by eq .",
    "( [ eq_13 ] ) is @xmath100=\\gamma(h)\\ln\\sigma(t)+ct,\\ ] ] which was already proposed in ref .",
    "@xcite but solely applied to the expou case .",
    "we here therefore calculate @xmath101 in terms of time horizon @xmath102 for the expou , the ou and the heston cases .",
    "figure  [ gamma_logh ] shows a linear relation between @xmath101 and @xmath103 for the three cases .",
    "we therefore propose the heuristic formula @xmath104=\\left(a\\ln h+b\\right ) \\ln\\sigma(t)+ct,\\ ] ] where @xmath97 and @xmath98 are the coefficients of the regression .",
    "table [ table_abcoef ] shows the empirical values of the regression .",
    "since we also observe a distinct behavior between short and long time horizon in the cases of the expou and the ou models , we also provide two different regression parameters @xmath97 and @xmath98 .",
    "first - passage and extreme value studies have a long tradition of applications to physics , biology , chemistry , and engineering , all of them related to non equilibrium processes .",
    "this sort of events appear also to be important in the financial markets context as a valuable tool to calibrate risk in a more sophisticate manner than just providing the standard deviation .",
    "it also does represent an alternative and , in a way , improved method  @xcite to the so - called value at risk  @xcite .",
    "first - passage and other extreme value have already been analytically and empirically studied under the perspective of the here presented sv modeling  @xcite . in this section ,",
    "we focus on the mean first - passage time ( mfpt ) of the volatility which provides the average time spent by price fluctuations @xmath105 to cross a certain value @xmath106 .",
    "see ref .",
    "@xcite for a further theoretical input concerning the mfpt and the sv models herein studied .",
    "we here want to extend the analysis with the use of our ml method instead of simply taking the absolute value of price returns as was done in ref .",
    "@xcite . in order to compare different models",
    ", we have to work with the dimensionless magnitude @xmath107 where @xmath108 is the mean of the estimated volatility in the stationary limit ( @xmath109 ) .",
    "the expected stationary volatility @xcite for the expou model is @xmath110 for the ou model is @xmath111 , and for the heston model is @xmath112    the mfpt of the three models is computed with their own volatility estimation multiplied by an artificial wiener random realization @xmath30 .",
    "figure [ mfpt_dx ] compares the different results with a qualitative agreement with empirical data in all three cases .",
    "the expou case appears to be the closest to the empirical mfpt curve .",
    "figure  [ mfpt_dx ] shows that the empirical mfpt results and the three artificial ones can all of them be roughly described by @xmath113 with exponent and coefficient that changes depending whether @xmath114 or @xmath115 as also shown in ref .",
    "their values are shown in tab .",
    "[ table_exponents_dx ] .    ) .",
    "the estimated volatilities  ( [ estimation ] ) of the expou , the ou and the heston models are compared with the dow jones @xmath105 data . ]",
    "[ table_exponents_dx ]    lcccc & expou & ou & heston & dji data + @xmath114 & 1.1 & 0.8 & 1.0 & 1.3 + @xmath115 & 2.4 & 3.1 & 2.9 & 2.9 +      we now study how the ml approach keeps the main market time correlations that deeply and non - trivially involves volatility dynamics  @xcite .",
    "it is well - known that the volatility fluctuations have long memory correlation ( over a year ) and that volatility also shows negative and asymmetric cross - correlation with return changes ( over several weeks ) , i.e. the leverage effect  @xcite .",
    "however , it is not clear whether the proposed method is able to provide these two different correlations .",
    "figure  [ volatility_autocorr ] shows how the volatility autocorrelation @xmath116}\\ ] ] of each estimator is still significant for up to hundreds of days .",
    "it is important to stress that the ou and heston models by themselves do not have this long range correlation since their mathematical expressions give an exponential decay for the volatility @xmath5 in terms of a characteristic time scale @xmath117 ( see ref .",
    "@xcite and tab .",
    "[ table_fgh ] for the meaning of this parameter ) .",
    "the expou model is the only one that explains this long range effect with a cascade of exponentials  @xcite .",
    "therefore , it can be said that the long - term memory is preserved due to the ml algorithmic method herein proposed .",
    "this feature manifests the robustness and effectiveness of the proposed method beyond the choice of the sv models been used .     provided by eq .",
    "( [ eq_10 ] ) . ]",
    "we now focus on another important correlation with time .",
    "the so - called leverage effect  @xcite defined by @xmath118 measures the negative cross - correlation between price return fluctuations and volatility .",
    "reference  @xcite shows that the three models are able to mathematically describe the empirical observation only if a non - zero and negative cross - correlation between @xmath30 and @xmath119 is considered ( cf .",
    "( [ eq_5 ] ) ) .",
    "figure  [ leverage_models ] shows the leverage correlation by first obtain the estimated volatility  ( [ eq_16 ] ) @xmath59 and afterward compute the artificial return change @xmath120 by multiplying the estimated volatility by random realizations of @xmath30 .",
    "we remind that the current ml algorithmic method has not considered correlation .",
    "however , the iterative procedure of the ml method is able to naturally provide the leverage effect in the three models as shown .",
    "it is important to stress the fact that we do not need to sophisticate our models by including the cross - correlation coefficient between @xmath30 and @xmath119 since the same ml procedure naturally includes the negative correlation between these random sources . adding the effect of correlation between @xmath30 and @xmath119 represents adding more terms in eq .",
    "( [ eq_6 ] ) and making the ml approach much less efficient in computational terms .",
    "the addition of this extra term would in any case provide redundant information to the maximization process .",
    "figure  [ leverage_heston ] shows the leverage correlation of the heston model as an illustrative example .",
    "it compares ml approach with other ways of extracting volatility from data .",
    "figure  [ leverage_heston ] demonstrates that ml approach gets same results as by using @xmath121 given by eq .",
    "( [ eq_10 ] ) but it also shows how we lose the correlation if we take the deconvoluted @xmath31 given by eq .",
    "( [ eq_11 ] ) .",
    "again , the result can be considered as a proof that our methodology is coherent and self - consistent .",
    "the other two models show very similar results as can be intuited in fig .",
    "[ leverage_models ] .    ) of the expou , the ou and the heston models .",
    "volatilities are calculated using the ml method  ( [ estimation ] ) and @xmath105 is articially computed combining gaussian realizations of @xmath30 and taking the estimated volatility . ]    ) of the ml estimated volatility  ( [ estimation ] ) for the heston model compared with the deconvoluted procedure  ( [ eq_11 ] ) and the proportional volatility  ( [ eq_10 ] ) . ]      we have studied how our ml approach affects different sv models and we here would also like to verify if there is any difference between working with one stock market or another .",
    "concretely , we have computed our estimation of the volatility for the following indexes : dow jones industrial average ( dji ) ( 1928 - 2011 ) , standard and poors-500 ( s&p ) ( 1950 - 2011 ) , german index dax ( 1990 - 2011 ) , japanese index nikkei ( 1984 - 2011 ) , american index nasdaq ( 1985 - 2011 ) , british index ftse-100 ( 1984 - 2011 ) , spanish index ibex-35 ( 1993 - 2011 ) and french index cac-40 ( 1990 - 2011 ) .",
    "it is also important to stress that parameters used in each model are the ones from dow jones data and provided in tab .",
    "[ table_alphamkcoef ] so in some sense there is now no over fitting due to the fact of extracting the parameter from the same data series we are analyzing . in all cases , the resulting @xmath120 time series satisfies the stylized facts that most of financial markets have in common  @xcite .",
    "we first observe that all markets show an estimated volatility considerably less noisy than the deconvoluted one ( cf .",
    "( [ estimation ] ) and  ( [ eq_11 ] ) )",
    ". the reduction of the oscillations can be quantified by the coefficient @xmath122 whose order of magnitude depends on the stock data as shown in tab .",
    "[ table_variancescoef ] .",
    "[ table_variancescoef ]    lccc & expou & ou & heston + dji & @xmath123 & @xmath124 & @xmath125 + s&p & @xmath126 & @xmath127 & @xmath128 + dax & @xmath129 & @xmath130 & @xmath131 + nikkei & @xmath132 & @xmath133 & @xmath134 + nasdaq & @xmath135 & @xmath136 & @xmath137 + ftse-100 & @xmath138 & @xmath139 & @xmath140 + ibex-35 & @xmath141 & @xmath142 & @xmath143 + cac-40 & @xmath144 & @xmath145 & @xmath146 +    in fig .",
    "[ pdf_volatility_dif ] , we plot the volatility pdf given by the heston model for two different indexes .",
    "we notice the different width of the probability distribution of the two stocks because each market has a different volatility s range of values .",
    "we can again appreciate the reduction of the fluctuations achieved with our estimated volatility when compared with the deconvoluted volatility  ( [ eq_11 ] ) .    ) of the standard and poors-500 ( s&p ) and the ibex-35 .",
    "we plot our estimated volatility for the heston model jointly with the deconvoluted volatilities provided by eq .",
    "( [ eq_11 ] ) . ]",
    "figure  [ pdfsreturn_difst_expou ] shows the probability distribution of the artificially computed return differences with the estimated volatility of each stock . in this case , we have used the expou model .",
    "as we expected , we see that the width of the curves depend on the stock market but behavior is qualitatively similar .",
    "this also similarly occurs to the heston and ou models .     artificially computed by using eq .",
    "( [ eq_3 ] ) and by taking @xmath59  ( [ estimation ] ) .",
    "the expou model has been used in order to calculate the estimated volatility .",
    "all markets show similar aspect . ]    in order to study the extreme values of the indexes , we have calculated the mfpt for the absolute value of returns @xmath105 calculated using the estimated volatility . in top fig .",
    "[ mfptdx_difst_expou ] we have plotted the evolution of this mfpt when the model used is the expou .",
    "we observe the clear coincidence of all the stocks except the dow jones which has slightly smaller mfpt which is incidentally the market from where parameters are extracted .",
    "if we look at the the ou case as shown in fig .",
    "[ mfptdx_difst_ou ] it is the ibex stock index that shows a different behavior specially to the range of small threshold @xmath147 . this can be justified by the fact that ou model allows for negative values of volatility while ml is just considering positive values of volatility . and",
    "the results for small @xmath147 will be the ones that can be more sensitive to this fact .",
    "additionally the ibex market is the one with smallest amount of data available .",
    "the heston case shown in fig .",
    "[ mfptdx_difst_heston ] recovers the nice collapse provided by the expou model where the dji again appears slightly shifted . in any case , and for the ibex with the ou model single exception , a common pattern is observed .",
    "( [ eq_3 ] ) and  ( [ estimation ] ) ) .",
    "the estimated volatility has been computed using the expou model . ]",
    "( [ eq_3 ] ) and  ( [ estimation ] ) ) .",
    "the estimated volatility has been computed using the ou model . ]",
    "( [ eq_3 ] ) and  ( [ estimation ] ) ) .",
    "the estimated volatility has been computed using the heston model . ]    finally , we show in fig .",
    "[ leverage_dif ] that there are some stocks which manifest more leverage than others . as an example",
    ", the s&p has bigger anti correlation than the dow jones .",
    "however , the important fact is that we find leverage in all markets .",
    "the same happens with the volatility autocorrelation because although the nasdaq decays more slowly , all the stocks manifest significant autocorrelation for hundreds of days as expected  @xcite .",
    "same results are found when we take the ou and expou models instead of the heston one .",
    "it is fairly known that the volatility is one of the main quantities in finance because it is a measure of price fluctuations and it gives information related to the risk of holding an asset .",
    "however , volatility is a magnitude which is not directly observable and one then needs to assume a given market model in order to infer the volatility value .",
    "basic volatility estimation procedures have been presented and we have used a ml method that improves them since it is able to reduce noise and avoid bias in volatility signal .    we have applied the ml method by considering the most basic version of the expou , the ou and the heston sv uncorrelated models and we have compared them with the deconvoluted volatility showing big improvement in many aspects .",
    "we have observed that the fluctuations of the estimated volatility are smaller in all the models than in the deconvoluted estimation .",
    "the three models preserve the desired stationary volatility pdf for the volatility and keep the fat tail distribution for the price return changes .",
    "we have also found that all three models allow us to forecast future absolute value of returns with actual volatilities . we have also observed that the loss of forecast information has a double time scale in the expou and the ou models .    concerning the study of extreme events , we have found that our ml approach shows a nice concordance between the volatility mfpt estimated with the three sv models and the empirical mfpt .",
    "we have also focused on volatility s time correlations and we have observed that all the three models show the existence of significant volatility autocorrelation for hundreds of days although heston and ou models does not include this property beforehand . the leverage correlation that crosses volatility and price return fluctuations is also nicely described by all three models even though the ml method is not considering correlation between returns and volatility fluctuations beforehand .",
    "all of these confirm the fact that methodology is robust enough without needing to improve the sv models or to provide more efficient ways of estimating the parameters of the model .",
    "however , ml approach with alternative models with same level of sophistication like the recent model by delpini and bormetti  @xcite deserves attention in future research .",
    "finally , we have applied same method to other stock indexes .",
    "volatility s noise has been strongly reduced in all cases and we have corroborated that all the markets describe the several properties described before for the dow jones .",
    "the methodology therefore seems to be valid in a wide collection of financial market data .",
    "o. e. barndorff - nielsen , and n. shephard , _ non - gaussian ornstein - uhlenbeck - based models and some of their uses in financial economics _",
    ", journal of the royal statistical society : series b ( statistical methodology ) * 63 * ( 2001 ) 167241 .",
    "o. e. barndorff - nielsen and n. shephard , _ econometric analysis of realized volatility and its use in estimating stochastic volatility models _ , journal of the royal statistical society : series b ( statistical methodology ) * 64 * ( 2002 ) 253280 .",
    "andersen , t. bollerslev , and f.x .",
    "diebold , _ parametric and nonparametric volatility measurement _ , in : l.p .",
    "hansen and y. at - sahalia ( eds . ) , handbook of financial econometrics , amsterdam : north - holland ( 2010 ) pp . 67138 ."
  ],
  "abstract_text": [
    "<S> volatility measures the amplitude of price fluctuations . despite it is one of the most important quantities in finance , volatility is not directly observable . here </S>",
    "<S> we apply a maximum likelihood method which assumes that price and volatility follow a two - dimensional diffusion process where volatility is the stochastic diffusion coefficient of the log - price dynamics . </S>",
    "<S> we apply this method to the simplest versions of the expou , the ou and the heston stochastic volatility models and we study their performance in terms of the log - price probability , the volatility probability , and its mean first - passage time . </S>",
    "<S> the approach has some predictive power on the future returns amplitude by only knowing current volatility . </S>",
    "<S> the assumed models do not consider long - range volatility auto - correlation and the asymmetric return - volatility cross - correlation but the method still arises very naturally these two important stylized facts . </S>",
    "<S> we apply the method to different market indexes and with a good performance in all cases . </S>"
  ]
}