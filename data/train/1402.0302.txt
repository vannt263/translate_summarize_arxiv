{
  "article_text": [
    "let @xmath2 .",
    "we are interested in estimation of the mean vector @xmath3 with respect to the quadratic loss function @xmath4 .",
    "obviously the risk of @xmath5 is @xmath6 .",
    "we shall say one estimator is as good as the other if the former has a risk no greater than the latter for every @xmath3 .",
    "moreover , one dominates the other if it is as good as the other and has smaller risk for some @xmath3 . in this case",
    ", the latter is called inadmissible .",
    "note that @xmath5 is a minimax estimator , that is , it minimizes @xmath7 $ ] among all estimators @xmath8 .",
    "consequently any @xmath8 is as good as @xmath5 if and only if it is minimax .",
    "@xcite showed that @xmath5 is inadmissible when @xmath9 .",
    "@xcite explicitly found a class of minimax estimators @xmath10 with @xmath11 and @xmath12 .",
    "@xcite proposed the james - stein positive - part estimator @xmath13 with @xmath14 which dominates the james - stein estimator .",
    "a problem with the james - stein positive - part estimator is , however , that it selects only between two models : the origin and the full model .",
    "@xcite overcome the difficulty by utilizing the so - called @xmath0-norm given by @xmath15 and in fact proposed minimax estimators @xmath16 with the @xmath17-th component given by @xmath18 where @xmath19 and @xmath20 .",
    "when @xmath21 , the @xmath17-th component of the estimator with @xmath22 becomes zero .",
    "hence the choice between a full model and reduced models , where some coefficients are reduced to zero , is possible .    in this paper , we establish minimaxity of a new class of @xmath0-norm based shrinkage estimators @xmath23 with the @xmath17-th component given by @xmath24 where @xmath25 , @xmath26 , @xmath27 and @xmath28 when @xmath29 is strictly positive in , sparsity happens as in . in @xcite ,",
    "@xmath30 was assumed and the @xmath0-norm with @xmath31<2\\ ] ] was treated . from their proof , the choice of @xmath30 seemed only applicable for constructing estimators with minimaxity and sparsity simultaneously .",
    "we produce such minimax estimators based on the @xmath0-norm for all @xmath26 . as an extreme case ( @xmath32 )",
    ", we can show that @xmath33 with @xmath25 is minimax . a more general result of minimaxity , corresponding to the result of @xcite , where @xmath34 is replaced by @xmath35 in , is given in section [ sec : main_1 ] . in section [ sec : main_2 ]",
    ", the corresponding results for unknown @xmath36 are presented .",
    "in this section , we assume that @xmath36 is known and establish conditions under which estimators @xmath37 of the form @xmath38 as the @xmath17-th component , are minimax . note the shrinkage factor of , @xmath39 is symmetric with respect to @xmath40 .",
    "as shown in theorem 4 of @xcite , the shrinkage estimator with the symmetry is dominated by the positive - part estimator .",
    "hence the minimaxity of @xmath41 follows from the minimaxity of @xmath37 .",
    "recall that the risk of @xmath5 is equal to @xmath6 or finite .",
    "hence a straightforward application of schwarz s inequality shows that the risk of @xmath42 is finite if and only if @xmath43<\\infty.\\ ] ] in that case , identity states that if @xmath44 is absolutely continuous , we have @xmath45=\\sigma^2 e\\left[(\\partial/\\partial z_i)\\xi(z)\\right]\\ ] ] for @xmath46 and each expectation exists .    in this paper , we assume @xmath47 and @xmath48 is bounded , say @xmath49 for some @xmath50 . under these assumptions , follows with @xmath51 and @xmath52 in fact , we have @xmath53 and further @xmath54 by part [ lem : norm:1 ] of lemma [ lem : norm ] in appendix . since @xmath55\\leq 1/(d-2)$ ] , for @xmath56 given by we have @xmath57\\leq \\frac{m^2\\max(1,d^{(p-2 + 2\\alpha)/\\{2p(1-\\alpha)\\}})}{d-2}.\\ ] ] hence under the assumption of bounded @xmath48 , the risk of @xmath37 given by is finite .",
    "further , with an additional assumption that @xmath48 is absolutely continuous , identity given by is available for derivation of unbiased risk estimator .",
    "[ lem : stein_1 ] assume that @xmath58 is bounded and absolutely continuous and that @xmath59 .    1 .",
    "[ lem : stein_1_1 ] the risk function of the estimator @xmath37 is @xmath60     = d+e\\left[\\sum\\nolimits_{i}\\left(\\frac{|z_i|}{\\|z\\|_p}\\right)^{p-\\alpha }   \\frac{\\phi(\\|z\\|_p/\\sigma)\\psi_\\phi(z/\\sigma)}{(\\|z\\|_p/\\sigma)^2 } % \\frac{\\sum\\nolimits_{i}\\{|z_i|/\\sigma\\}^{p-\\alpha}}{\\{\\|z\\|_p/\\sigma\\}^{p+2-\\alpha } } \\right]\\end{aligned}\\ ] ] where @xmath61 2 .",
    "[ lem : stein_1_2 ] assume @xmath62 .",
    "then @xmath63 where @xmath64    from the invariance with respect to the transformation , @xmath65 , we can take @xmath66 and hence , without the loss of geniality , assume @xmath67 in the proof .",
    "[ part [ lem : stein_1_1 ] ] let @xmath68 .",
    "componentwisely we have @xmath69 for the third term of the right - hand side of , the stein identity given by is applicable .",
    "note @xmath70 then the differentiation of @xmath71 with respect to @xmath40 is given by @xmath72 and part [ lem : stein_1_1 ] follows by taking summation with respect to @xmath17 .",
    "[ part [ lem : stein_1_2 ] ] recall @xmath73 and @xmath26 . by part [ lem : norm:0 ] of lemma [ lem : norm ] in appendix , we have @xmath74 and , by part [ lem : norm:2 ] of lemma [ lem : norm ] , @xmath75 where @xmath76 with @xmath77 and @xmath78 for any @xmath17 . by applying these inequalities to , part [ lem : stein_1_2 ]",
    "follows .    by lemma [ lem : stein_1 ]",
    ", a sufficient condition for @xmath79\\leq d$ ] is @xmath80 as well as the assumption of lemma [ lem : stein_1 ] .",
    "when @xmath48 is monotone non - decreasing , we easily have a following result for minimaxity , which corresponds to the result by @xcite with @xmath81 and @xmath82 .",
    "[ thm : minimax_0 ] assume @xmath9 and @xmath83 .",
    "assume @xmath58 is absolutely continuous , monotone non - decreasing and @xmath84 where @xmath85 is given by @xmath86 under known @xmath36 , the shrinkage estimator @xmath37 , with the @xmath17-th component , @xmath87 is minimax .",
    "more generally , by the derivative , @xmath88 we have a following sufficient condition as in @xcite .",
    "[ thm : minimax ] assume @xmath9 and @xmath83 .",
    "assume @xmath58 is absolutely continuous and @xmath89 further , for all @xmath90 with @xmath91 @xmath92 is assumed to be non - decreasing .",
    "further if there exists @xmath93 such that @xmath94 , then @xmath95 is assumed equal to @xmath96 for all @xmath97 . then @xmath37 is minimax .",
    "recall that @xmath0 norm with any positive @xmath98 is available in lemma [ lem : stein_1 ] and theorem [ thm : minimax ] . as an extreme case ( @xmath32 )",
    ", we have @xmath99 and hence @xmath33 with @xmath25 is minimax .",
    "[ rem : decreasing ] the solution of @xmath100 or @xmath101 for any @xmath102 , is @xmath103 under which @xcite showed the risk of the estimator with @xmath104 is exactly equal to @xmath6 when @xmath82 and @xmath81 .",
    "actually it is related to the concept of `` near unbiasedness '' or `` approximate unbiasedness '' in the literature of scad ( smoothly clipped absolute deviation ) including @xcite .",
    "since @xmath105 is monotone decreasing and approaches @xmath1 as @xmath106 , unnecessary modeling biases are effectively avoided with @xmath105 .",
    "in this section , we assume that @xmath36 is unknown and that @xmath107 is additionally observed . we establish minimaxity result of the shrinkage estimators @xmath37 with the @xmath17-th component given by @xmath108 where @xmath109 .",
    "[ lem : stein_unknown ] assume that @xmath110 is , non - negative , bounded and absolutely continuous and that @xmath59 .",
    "then the risk function of the estimator @xmath37 is @xmath111     \\leq d+ e\\left[\\sum\\nolimits_{i}\\left\\{\\frac{|z_i|}{\\|z\\|_p}\\right\\}^{p-\\alpha } \\!\\ !",
    "\\frac{\\phi(u)}{u^2}\\left(\\psi_\\phi(u)-\\frac{2u\\phi'(u)}{n+2 } \\right)\\right]\\end{aligned}\\ ] ] where @xmath112 and @xmath113 is given by .    from the invariance with respect to the transformation , @xmath65 and @xmath114",
    ", we can take @xmath66 and hence , without the loss of generality , @xmath67 is assumed in the proof .",
    "let @xmath68 and @xmath115 .",
    "componentwisely we have @xmath116 and hence @xmath117 for the third term of the right - hand side of , the stein identity given by is applicable .",
    "by , the differentiation of @xmath118 with respect to @xmath40 is @xmath119 by the inequality and the stein identity , we have @xmath120 \\\\   & \\leq - e\\left[\\frac{\\hat{\\sigma}^2\\sum\\nolimits_{i}|z_i|^{p-\\alpha}}{v^{2-\\alpha+p } } \\phi(u ) \\left(2(d-2)-\\alpha(d-1)+2u\\frac{\\phi'(u)}{\\phi(u)}\\right)\\right ] \\\\ & = - e\\left[\\sum\\nolimits_{i}\\left\\{\\frac{|z_i|}{\\|z\\|_p}\\right\\}^{p-\\alpha}\\!\\ ! \\frac{\\phi(u)}{u^2 } \\left(2(d-2)-\\alpha(d-1)+2u\\frac{\\phi'(u)}{\\phi(u)}\\right)\\right].\\end{aligned}\\ ] ] for the second term of the right - hand side of , a well known identity for chi - square distributions ( see e.g.  @xcite ) @xmath121=\\sigma^2e\\left[n h(s)+2sh'(s)\\right]\\end{aligned}\\ ] ] for @xmath122 is applicable .",
    "the differentiation of @xmath123 with respect to @xmath124 , is @xmath125 hence , by the identity with , we have @xmath126=    e_{s|v}\\left[\\hat{\\sigma}^2\\phi(u)\\left\\{\\phi(u)-\\frac{2}{n+2}u\\phi'(u)\\right\\}\\right ] .   \\end{aligned}\\ ] ] further , by and , we have @xmath127 \\\\ & \\leq \\max(1,d^{(p+\\alpha-2)/p } )   e\\left[\\frac{\\sum\\nolimits_{i}|z_i|^{p-\\alpha}\\hat{\\sigma}^2}{v^{2-\\alpha+p } }    \\phi(u)\\left(\\phi(u)-\\frac{2}{n+2}u\\phi'(u)\\right)\\right ] \\\\ & = \\max(1,d^{(p+\\alpha-2)/p } )    e\\left [ \\sum\\nolimits_{i}\\left\\{\\frac{|z_i|}{\\|z\\|_p}\\right\\}^{p-\\alpha}\\!\\ ! \\frac{\\phi(u)}{u^2}\\left(\\phi(u)-\\frac{2}{n+2}u\\phi'(u)\\right)\\right ]   .   \\end{aligned}\\ ] ]    by lemma [ lem : stein_unknown ] , a sufficient condition for @xmath79\\leq d$ ] is @xmath128 as well as the assumptions of lemma [ lem : stein_unknown ] . when @xmath48 is monotone non - decreasing , as in theorem [ thm : minimax_0 ] for the known scale case , we easily have a following result for minimaxity .",
    "[ thm : minimax_0_unknown ] assume @xmath9 and @xmath83 .",
    "assume @xmath110 is absolutely continuous , monotone non - decreasing and @xmath129 where @xmath85 is given by .",
    "under unknown @xmath36 , the shrinkage estimator @xmath37 , with the @xmath17-th component , @xmath130 is minimax .",
    "hence theorem [ thm : minimax_0_unknown ] guarantees that theorem [ thm : minimax_0 ] remains true if @xmath36 is replaced by the estimator @xmath109 . by following @xcite and using the relation , a more general theorem corresponding to theorem [ thm : minimax ]",
    "is given as follows .",
    "[ thm : minimax_unknown ] assume @xmath9 and @xmath83 .",
    "assume @xmath110 is absolutely continuous and @xmath129 where @xmath85 is given by .",
    "further , for all @xmath131 with @xmath132 @xmath133 is assumed to be non - decreasing . further if there exists @xmath134 such that @xmath135 , then @xmath136 is assumed equal to @xmath96 for all @xmath137 .",
    "then @xmath37 is minimax .",
    "we see that theorem [ thm : minimax ] for known @xmath36 guarantees minimaxity of @xmath37 with @xmath48 which is not monotone non - decreasing . as i mentioned in remark",
    "[ rem : decreasing ] , even a monotone decreasing @xmath138 , which is the solution @xmath139 , leads minimaxity . in unknown variance case",
    ", however , the solution of @xmath139 in theorem [ thm : minimax_unknown ] , is not tractable .",
    "an alternative to @xmath138 is @xmath140 where @xmath141 by straightforward calculation , @xmath142 with @xmath143 is increasing .",
    "here we summarize some inequalities which are used in the main article .      1 .",
    "[ lem : norm:1 ] let @xmath144 . then @xmath145 2 .",
    "[ lem : norm:0 ] let @xmath146 and @xmath147 .",
    "then@xmath148 3 .",
    "[ lem : norm:2 ] let @xmath149 and @xmath150 .",
    "assume @xmath151 and @xmath78 for all @xmath17 . then @xmath152    [ part [ lem : norm:1 ] ] in the first inequality , we have @xmath153 since @xmath154 and @xmath155 . in the second inequality , let @xmath156 be a discrete random variable with the probability mass function @xmath157 . then @xmath158 \\leq \\left\\{e[x^{q / r}]\\right\\}^{r / q } = \\left\\{\\|z\\|_{q}^{q}/d\\right\\}^{r / q}=d^{-r / q}\\|z\\|_{q}^{r}\\ ] ] where @xmath159 and the inequality is from jensen s inequality .",
    "[ part [ lem : norm:0 ] ] let @xmath156 be a discrete random variable with the probability mass function @xmath160 .",
    "then we have @xmath161 , \\quad   \\frac{\\sum\\nolimits_{i=1}^d |z_i|^{q}}{d}=e[x^{q } ] , \\quad \\frac{\\sum\\nolimits_{i=1}^d |z_i|^{-r}}{d}=e[x^{-r}].\\ ] ] from the correlation inequality @xmath162 \\leq e[x^{q}]e[x^{-r}]$ ] , the inequality follows .    [ part [ lem : norm:2 ] ] let @xmath163 with @xmath164 .",
    "for any fixed @xmath165 , @xmath166 is non - increasing in @xmath34 .",
    "for @xmath167 , we have clearly @xmath168 and the equality is attained by @xmath169 . when @xmath170 , we have @xmath171 from the assumption and hence @xmath172 and @xmath173 for any @xmath165 . by the method of lagrange multiplier , @xmath174 gives the maximum value , @xmath175 ."
  ],
  "abstract_text": [
    "<S> a new class of minimax stein - type shrinkage estimators of a multivariate normal mean is studied where the shrinkage factor is based on an @xmath0 norm . </S>",
    "<S> the proposed estimators allow some but not all coordinates to be estimated by @xmath1 thereby allow sparsity as well as minimaxity . </S>"
  ]
}