{
  "article_text": [
    "this section provides a quick reference how to install share with charm on most common pc with gnu linux system , namely we assume ` gfortran ` and ` g++ ` compilers and ` cernlib ` installed .",
    "if you encounter any problems following this quick guide , please refer to section  [ sec : installation ] for detailed installation guide .    1 .   in a terminal , navigate into a folder where you want to install share with charm and download the package with the command + ` wget http://www.physics.arizona.edu/~gtshare/share/sharev3.zip ` 2 .",
    "unzip the package contents with the command ( this will create a new subfolder ` sharev3 ` ) + ` unzip sharev3.zip ` 3 .   enter the unpacked folder using + ` cd sharev3 ` + and compile share with charm using + ` make `      once share with charm is compiled , it can be run in a terminal with the command + ` ./share ` + if you have not already , it is a good idea to run the program once with the default setup .",
    "individual operations share performs during a run are specified in the file ` sharerun.data ` . without any changes to the input files after installation , the program is preset to read the provided input files and to perform a chemical non - equilibrium fit to 10 - 20% centrality data from pb  pb collisions at lhc employing only 2 free parameters",
    "@xmath9 , @xmath12  this calculation takes typically less than 10 seconds .",
    "let us show how to modify the input files in order to perform a semi - equilibrium fit to the same data set instead of the simplified full non - equilibrium .",
    "note that for the purpose of this quick start we do not explain in full detail all inputs that will appear below .",
    "changing the nature of the fit requires a few steps .",
    "we begin by changing the fit output filename ( so the old fit is not overwritten ) , than changing a parameter value , and learning how to include the parameter among those being fitted .    changing fit output file name",
    ": :    looking at the contents of ` sharerun.data ` in a text editor , the    fitting command is the following line +    ` calc   fitratios   fittestne.out ` +    it tells share to perform a fit ( ` fitratios ` ) all free parameters to    experimental data , and that the output file name is ` fit1020ne.out ` .",
    "the file is overwritten every run .",
    "so let us redirect the new output    to another file by changing this line to +    ` calc   fitratios   fittestse.out ` +    so we have both outputs for comparison .",
    "the output filename has to be    13 characters long .",
    "remember to keep two spaces between each word .",
    "setting parameter value : :    parameter values are set in ` thermo.data ` file .",
    "open it in a text    editor of your choice .",
    "chemical semi - equilibrium is defined by    @xmath13 and thus we need to change the line starting    with the parameter name , ` gamq ` , to read +    ` gamq     1 . `",
    "+    the format is such that you must remember to keep four spaces after    the parameter name and always enter a decimal point even for integer    values .",
    "the values specified in this input are either fixed parameter    values , or the initial fitted parameter values .",
    "final cross check of    fits with several different initial parameter values is advisable to    fully understand errors and fit stability , i.e. , that the fit    converges to the same minimum from different starting point(s ) in the    parameter space and that error is not underestimated .",
    "fixing / fitting a parameter : :    parameter ranges for this test run defined in ` ratioset.test ` file    ( equivalent to ` ratioset.data ` , section  [ sec : ratioset ] ) . upon opening",
    "the file in a text editor , you will notice that each parameter has a    separate line such as the following one for ` gams `    ( @xmath14 ) : +    ` gams     0.1      9 .     0.1      0 ` +    in the previous non - equilibrium fit ,",
    "` gams ` was fixed .",
    "parameter with    ` 0 ` in the last column will be kept constant at the value specified in    ` thermo.data ` file during a fit , whereas parameters with ` 1 ` in the    last column are to be changed within the allowed range ( first two    numbers on the line ) .",
    "the different value of @xmath15 we    set in the previous step will result in a new value of    @xmath14 , so let us release ` gams ` by changing the ` 0 `    to ` 1 ` on the above quoted line , so the line now reads : +    ` gams     0.1      9 .     0.1      1 `",
    "+    demanding that the program finds the best value of    @xmath14 to describe the data .    with the above modifications , running ` ./share ` again will produce a new output file with semi - equilibrium fit ( with 3 free parameters , @xmath9 , @xmath12 and @xmath14 ) obtained for the same experimental data defined in the file ` lhc1020mi.data ` .",
    "note that the resulting fit should have lower cl as other shm parameters for purpose of this example remain fixed to their optimized full non - equilibrium values .    changing experimental data point",
    ": :    every line in ` lhc1020mi.data ` contains one data point name ,    experimental value , statistical and systematic error and whether or    not this data point is fitted or only evaluated during a fit . for    example",
    ", the experimenta yield of @xmath16 is    defined on the following line : +    ` lm1115zer   prt_yield      17 .",
    "2.0          0 .            1",
    "` +    one can change the value from @xmath17 to a different one    by changing the numbers .",
    "the data point can be excluded from the fit    by changing the ` 1 ` to a ` 0 ` in the last column . similarly to fixing a    parameter above , this implies that the experimental value will not be    fitted , its theoretical value will be calculated based on the model    parameters irrespective of its experimental value .",
    "share with charm program is far more capable than the basic operation shown in this quick start guide , we refer the reader to the following 30 pages for details about program operation , input file structure , and full description of program capabilities .",
    "strong interaction reactions usually lead to high multiplicity of produced particles .",
    "a non - perturbative description of particle production has been proposed originally by fermi  @xcite based on statistical ideas and later the model was developed further by considering the reaction volume expansion and realizing that at some point during the expansion , the particle density decreases below the point , where they can interact with each other .",
    "this stage is referred to as chemical freeze - out .",
    "next important feature included the hadron resonance mass spectrum significantly increasing the number of states to be populated in the statistical approach .",
    "the hadron resonance spectrum implied that the hadronic matter could undergo a phase transition at hagedorn temperature @xmath18 into a gas of quarks .",
    "for the statistical model milestones and more detailed history , see  @xcite and other references in  @xcite .",
    "relativistic heavy - ion collisions allow us to create a fireball of matter at very high temperature and density in a laboratory .",
    "the objective of the heavy - ion collision program is to study the formation of a deconfined state of matter , the quark ",
    "gluon plasma ( qgp ) and its transition to hadronic matter .",
    "the early universe has been composed of qgp up until a few microseconds after the big bang , when quarks and gluons merged into hadrons , particles that we see around us today .",
    "creation of a small fireball of matter , where quarks and gluons are not bound , would confirm that deconfinement is a property of strong interaction vacuum state .",
    "an overview of the matter can be found for example in  @xcite .",
    "the short lifetime and the extreme conditions leave us with indirect observations of the fireball .",
    "it is challenging to identify unique probes that allow us to distinguish between a deconfined qgp and a sequence of hadron interactions leading to the final hadron state we observe experimentally .",
    "high multiplicity of produced hadrons is a characteristic feature of heavy - ion collisions irrespective of whether or not deconfined state of matter has been achieved during the collision .",
    "specific properties of the final hadron state can distinguish between the two scenarios of hadron production .",
    "for details about the differences in the final hadron state see , e.g. ,  @xcite .",
    "statistical hadronization model has been used in the past decades to describe hadron production in heavy - ion collisions at cern super proton synchrotron ( sps ) ( @xmath19 ) , rhic ( @xmath20 ) and recently at lhc ( @xmath21 ) with oftentimes great accuracy . despite the variety of shm approaches ( chemical equilibria of different flavors , post - hadronization interactions ,  )",
    "has a common evolution pattern , at some point during the evolution , the phase space of stable hadrons and resonances is populated as described by their respective statistical distributions .",
    "then , the resonances decay and thus significantly increase the yields of the daughter particles .    proper model description of the final hadron state yields information about the source of hadrons in relativistic heavy - ion collisions and its properties at the time of hadronization , the transition from the deconfined qgp phase into hadrons .",
    "we have compiled an upgraded program ` share with charm ' , which produces the final hadron yields and ratios based on intensive parameters of the particle source .",
    "we have prepared a package , that takes advantage of already implemented and thoroughly tested program sharev2 written in fortran 77 and we complement it with an external module written in c++ which adds proper description of charm hadron production according to the current status of the field including updated input data tables .    for accurate description of the final hadron spectrum , it is necessary to implement a detailed list of hadron states and their decay branching ratios .",
    "seemingly negligible assumptions about both can lead to significant differences in the results of such analysis .",
    "frequent testing and cross - checks with the particle data book  @xcite and other available programs ( see , e.g. ,  @xcite and references therein ) give us confidence , that the hadron spectrum and decay pattern of hadrons consisting of @xmath22 and @xmath5 quarks are well described in our program .",
    "our hadron mass spectrum involves all * * * * and * * * resonances .",
    "this program update introduces charm mesons depicted in figure  [ fig : charm - hadrons ] and charm baryons schematically depicted in figure  [ fig : charm - hadrons ] together with their higher mass * * * and * * * * resonances .    particles , that evaporate from a hot boiling quark  gluon ` soup ' statistically according to the accessible phase space can be described by the shm . in this scenario ,",
    "one expects the final hadron state near , but not generally in chemical equilibrium . in the case of more dynamical evolution and sudden hadronization",
    ", the final hadron state can be out of chemical equilibrium irrespective of the fireball being or not being chemically equilibrated .",
    "very slow hadronization process , in which all quark flavors have time to ( re-)equilibrate in the hadron phase , can also be described statistically , the different scenarios will be reflected by the values of model parameters .",
    "diagrams showing the 16-plets for the pseudoscalar and vector mesons on the left , where one can see non - charm mesons on the center planes , and diagrams showing the baryon 20-plets ( right ) made of @xmath0 and @xmath23 quarks , where the mass and charm content increases from the base upwards .",
    "figure derived from  @xcite.,title=\"fig:\",height=415 ] diagrams showing the 16-plets for the pseudoscalar and vector mesons on the left , where one can see non - charm mesons on the center planes , and diagrams showing the baryon 20-plets ( right ) made of @xmath0 and @xmath23 quarks , where the mass and charm content increases from the base upwards .",
    "figure derived from  @xcite.,title=\"fig:\",height=415 ]    share with charm introduces charm statistical hadronization .",
    "charmonium production , an important subtopic , has a long and colorful history .",
    "the possibility that the deconfined qgp phase is suppressing the primordial direct charmonium yield was proposed as a signature of qgp formation  @xcite . in absence of absolute normalized yields",
    "the experimental study involved consideration of relative abundance as function of centrality , @xmath24 , which result indicated the expected suppression .",
    "once absolute yield of charmonium became available it was recognized that the absolute yield could in fact be due to chemical equilibrium statistical hadronization  @xcite .",
    "the discovery that one can describe onium production near to equilibrium reintroduced the chemical equilibrium hadronization of charm hadrons  @xcite into consideration .",
    "finding the charm abundance in chemical equilibrium can be the result of an analysis performed with our program .",
    "however , we view the charm yield as arising from a long and complex evolution in qgp .",
    "charm is produced in hard parton scattering very early in the collision  @xcite .",
    "the yield of charm may evolve from its creation in the initial collision until freeze - out , see figures 35 and 36 in ref.@xcite where examples of possible evolution of chemical phase space parameter @xmath25 and charm abundance in the qgp are shown . at high matter and charm densities achieved at lhc ,",
    "charm may be depleted via annihilation considering the long fireball evolution time span , and when temperature is low enough , hadrons emerge produced in coalescence processes  @xcite .",
    "charm quarks are quite massive , about an order of magnitude above the expected freeze - out temperature . therefore , charm quarks may have on average smaller velocity of expansion than the light ( @xmath0 ) quarks and ` fall behind ' . as",
    "the size of charm particles is smaller , it is natural to assume a higher decoupling temperature @xmath8 , a feature we also introduce in this program upgrade and which called for an external charm computational module .",
    "sharev2 introduced event - by - event fluctuations of particle yields , which further enhanced the model capabilities .",
    "they can be used to , e.g. , falsify or support the shm description in case the fluctuations and yields can not be or are described by the same set of thermal parameters . they may also help decide which statistical ensemble is appropriate , and decouple the correlation of certain thermal model parameters . in the following ,",
    "we introduce grand - canonical ensemble yields and fluctuations , see section  [ sec : yieldandfluctuations ] and  [ sec : fluctuations ] .",
    "for correct evaluation of the final hadron state , one has to calculate the :    * primary particle yields at chemical freeze - out , * charm hadron decays followed by * decays of resonances .      using the standard textbook approach for grand - canonical ensemble , every hadron of species @xmath26 with energy @xmath27 populates the energy states according to fermi - dirac or bose - einstein distribution function : @xmath28 where the upper sign corresponds to fermions and the lower one to bosons .",
    "the fugacity @xmath29 of the @xmath26-th hadron species is described in detail below in section  [ sec : chemistry ] .",
    "then the hadron species @xmath26 yield will correspond to the integral of the distribution function ( eq.[eq : distribution ] ) over the phase space multiplied by the hadron spin degeneracy @xmath30 and volume @xmath12 @xmath31    the fluctuation of the yield ( eq.[eq : yield ] ) can be calculated as : @xmath32 it is more practical for numerical computation to express the above equations ( eq.[eq : yield],[eq : fluctuation ] ) as an expansion in modified bessel functions ( @xmath33 ) as @xmath34 these expansions can be calculated to any desired accuracy as long as the integrals ( eq.[eq : yield],[eq : fluctuation ] ) converge ; for bosons one has to make sure that @xmath35 , otherwise the yield integral @xmath36 diverges . for heavy ( @xmath37 ) particles , such as charm hadrons , boltzmann distribution is a good approximation , i.e. , it is sufficient to evaluate the first term of the expansion in eq .",
    "[ eq : yieldexpansion ] , which is indeed implemented in the charm module to reduce computation time at no observable loss of precision .    to evaluate the yield of hadron resonance with finite width @xmath38",
    ", one has to weigh the yield ( eq.[eq : yield ] ) by the resonance mass using the breit - wigner distribution : @xmath39 using energy independent width implies a finite probability of the resonance being formed with unrealistically small mass . to mitigate this unphysical scenario",
    ", one has to use the energy dependent resonance width .",
    "the resonance decay energy threshold is a limiting factor in the accessible energy phase space .",
    "the partial width of a decay channel @xmath40 can be well approximated by @xmath41^{l_{ij}+1/2}\\qquad \\text { for } m > m_{ij},\\ ] ] where @xmath42 is the decay channel branching ratio , @xmath43 is the decay threshold ( i.e. , sum of the decay product masses ) and @xmath44 is the angular momentum released in the decay .",
    "the total energy dependent width is then calculated using the partial widths ( eq .  [ eq : partialwidth ] ) for all decay channels of the resonance in question as @xmath45 for a resonance with a finite width , we can then replace eq .",
    "[ eq : yieldwithwidth1 ] by @xmath46 where @xmath47 is a normalization constant equal to @xmath48 eq .",
    "[ eq : yieldwithwidth2 ] is the form used in the program to evaluate hadron resonance yield whenever calculation with finite width is required .",
    "note , that yield evaluation with finite width is implemented only for hadrons with no charm constituent quark , zero width ( @xmath49 ) is used for all charm hadrons .",
    "the fugacity of hadron states affects yields of different hadrons based on their quark content .",
    "it can be calculated from the individual constituent quark fugacities . in the most general case ,",
    "for a hadron consisting of @xmath50 and @xmath51 up , down , strange and charm quarks respectively and @xmath52 and @xmath53 anti - quarks , the fugacity can be expressed as @xmath54 where @xmath55 is the phase space occupancy of flavor @xmath56 and @xmath57 is the fugacity factor of flavor @xmath56 .",
    "note , that we allow for non - integer quark content to account for states like @xmath58 meson , which is implemented as @xmath59 in agreement with  @xcite .",
    "it can be shown that for quarks and anti - quarks of the same flavor @xmath60 which reduces the number of variables necessary to evaluate the fugacity to a half .",
    "it is a common practice to take advantage of the isospin symmetry and treat the two lightest quarks ( @xmath61 ) using light quark and isospin phase space occupancy and fugacity factors which are obtained via a transformation of parameters : @xmath62 with straight forward backwards transformation @xmath63 and similarly for the fugacity factors @xmath64    chemical potentials are closely related to fugacity , one can express an associated chemical potential @xmath65 for each hadron species @xmath26 via @xmath66 it is more common to express chemical potentials related to conserved quantum numbers of the system , such as baryon number @xmath67 , strangeness @xmath5 , third component of isospin @xmath68 and charm @xmath23 : @xmath69 ( notice the inverse definition of @xmath70 , which has historical origin and is a source of frequent mistake ) .      while charm hadrons are well described by the above framework along with the other three quark flavors , we follow slightly different approach in determining the charm chemical parameters .",
    "first , we consider only symmetric charm+anti - charm pair production ( and/or annihilation ) . at lhc , for which share with charm is optimized , @xmath71 is very small and therefore the charm chemical potential is vanishing , and charm fugacity factor is effectively unity , @xmath72 .",
    "this implies that the number of charm quarks and anti - quarks is the same , @xmath73 .",
    "we determine the charm phase space occupancy @xmath25 following the approach of  @xcite , where the number of charm quarks @xmath74 is given ( as a model parameter ) and @xmath25 is found by solving @xmath75 where @xmath76 resp .",
    "@xmath77 is the sum of equilibrium yields of baryons with quark content @xmath78 and @xmath79 , resp .",
    "mesons with quark content @xmath80 and @xmath81 .",
    "for instance , @xmath82 includes @xmath83 , @xmath84 , @xmath85 , @xmath86 , etc .",
    "( note that only in the eq .",
    "[ eq : gamma_c ] , @xmath87 denotes the sum of charmonium yields , whereas @xmath6 everywhere else in the text denotes the number of charm+anti - charm quarks . )",
    "even though eq .",
    "[ eq : gamma_c ] is cubic in @xmath25 and has generally three solutions for @xmath25 , for physical values of all quantities involved , only one of the solutions is positive and real and is accepted as the value of @xmath25 .",
    "the hadronization of charm itself is a new phenomenon in the physics of heavy - ion collisions and very little is known about this process .",
    "predictions for the amount of charm created in heavy - ion collisions at lhc expect @xmath88 charm+anti - charm quark pairs created in a central pb ",
    "pb collision  @xcite .",
    "we expect this amount to be slightly modified by annihilation and not very abundant thermal production of charm quarks during the expansion of the fireball .",
    "massive charm quarks may expand slower outwards from the primary vertex of the collision . during hadronization ,",
    "they may find themselves at a point within the fireball at slightly higher temperature . in this case",
    ", charm would populate the charm hadron phase space at a temperature above that of the light flavors .",
    "we introduce the charm hadronization temperature @xmath8 and use it in eq .",
    "[ eq : yieldexpansion ] to calculate charm hadron yields and in eq .",
    "[ eq : gamma_c ] when determining the value of @xmath25 .",
    "the ratio of charm to light hadronization temperature is a newly introduced model parameter , see section  [ sec : parameters ] .      during the evaluation of hadron yields ,",
    "the program first calculates the event - by - event average yields and fluctuations at hadronization treating resonances as particles with well defined mass .",
    "these quantities are in general different from experimentally observed yields and fluctuations .",
    "the resonances decay rapidly after the freeze - out and feed lighter resonances and stable particle yields .",
    "the final stable particle yields are obtained by allowing all resonances to decay sequentially from the heaviest to the lightest and thus correctly accounting for resonance cascades .",
    "final yield of each hadron @xmath26 is then a combination of primary production and feed from resonance decays @xmath89 where @xmath90 is the probability ( branching ratio ) that particle @xmath91 will decay into particle @xmath26 .",
    "applied recursively , eq .",
    "[ eq : decayfeed ] reproduces the experimentally observed yields .    for non - charm hadrons ,",
    "all decay channels with branching ratio @xmath92 were accepted , but the higher number of charm hadron decays ( a few hundred ( ! ) in some cases ) with smaller branching ratios required to accept all decay channels with branching ratio @xmath93 .",
    "since charm hadrons in a lot of cases decay into more than three particles , a different approach in implementing them has to be used , see further in section  [ sec : hffeed ] .",
    "there is still a lot of uncertainty in charm decay channels .",
    "some of them are experimentally difficult to confirm , but required by , e.g. , the isospin symmetry and had to be added by hand for several charm hadrons .",
    "for example , a measured @xmath94 decay channel @xmath95 is complemented by the unobserved isospin symmetric channel @xmath96 with the same branching ratio .",
    "the influence of resonance feed - down on fluctuations is the following : @xmath97 the first term corresponds to the fluctuations of the mother particle @xmath91 , which decays into particle @xmath26 with branching ratio @xmath90 .",
    "@xmath98 is the number of particles @xmath26 produced in the decay of @xmath26 ( inclusive production ) so that @xmath99 . for nearly all decays of almost all resonances",
    "@xmath100 , however , there are significant exceptions to this including production of multiple @xmath101 , such as @xmath102 . the second term in eq .",
    "[ eq : decayfluct ] corresponds to the fluctuation in the yield of the mother particle ( resonance ) .      in most recent heavy - ion experiments , particle yields and fluctuations",
    "are measured in a limited kinematic domain , usually a well defined rapidity range around @xmath103 ( central rapidity ) .",
    "results are then reported per unit of rapidity , e.g. , particle yields are @xmath104 .",
    "the acceptance domain is in the boost invariant limit equivalent to a configuration space sub - volume  @xcite and it follows that both particle ratios and fluctuations satisfy : @xmath105 and the scaled variance @xmath106 of quantity @xmath107 defined as @xmath108 will be given by @xmath109    the evaluation of grand canonical ensemble ( gce ) fluctuations ( eq .  [ eq : fluctuationexpansion ] ) neglects the fluctuations of volume .",
    "these are accounted for by dividing the observed fluctuation into an extensive and intensive part as follows : @xmath110 where @xmath111 and @xmath112 can be calculated using the above equations in this section .",
    "volume fluctuations @xmath113 are difficult to describe in a model independent way and thus the suggested procedure to avoid this problem is to choose observables independent of volume fluctuations .",
    "observables for which @xmath114 are good candidates .",
    "event - by - event fluctuations of particle ratios are even better choice as they are volume fluctuation independent by construction . with a complete decay tree ,",
    "the fluctuations of particle ratios can be evaluated using the numerator s and denominator s fluctuations .",
    "however , one has to keep in mind that resonance decays produce both fluctuations and correlations , as the decays can feed both the numerator and the denominator .",
    "for the variance of a ratio of two particles @xmath115 , one should use @xmath116 the last correlation term depends on the resonance decays into both particles as @xmath117 even though @xmath118 is independent of the average system volume @xmath119 , the variance of a ratio acquires dependence on it since ratio fluctuations scale with @xmath120 .",
    "an analysis incorporating particle fluctuations should therefore include some particle yields data and system volume is strongly suggested as a free fit parameter ( see section  [ sec : parameters ] for technical details on how to accomplish this ) .    most common way to separate detector acceptance effects from physics",
    "is to evaluate the fluctuations in ` mixed ' events , where particles from distinct events are combined . by construction ,",
    "such fluctuations contain only detector acceptance effects as the particles themselves are not correlated in any other way .",
    "hence , the normalized ` static ' fluctuation @xmath121 is determined only by a trivial poisson contribution and the detector effects . in the shm , the static fluctuation is @xmath122 the correlation term , @xmath123 of the particle ratio @xmath115 in mixed events vanishes in eq .",
    "[ eq : ratiocorrelation ] and hence the fluctuation of the ratio simplifies to @xmath124 the dynamical fluctuation @xmath125 defined by @xmath126 corresponds to the difference of the directly measured fluctuation @xmath127 and the static fluctuation from mixed events @xmath121 and can be shown to be independent of detector acceptance  @xcite .",
    "this makes the @xmath125 more robust to compare with fluctuation estimates from shm .",
    "mixed event particles are uncorrelated and hence mixed event techniques can not account for detector acceptance effects while evaluating particle correlations . the eqs .",
    "[ eq : decayfeed ] and  [ eq : decayfluct ] need to use a corrected branching ratios @xmath128 , and consequently , eq .  [ eq : ratiocorrelation ] needs to be updated as well to read : @xmath129 the first correction factor we introduced , @xmath130 , correspond to the probability that particle @xmath26 will end up in the detector acceptance provided that particle @xmath91 is also inside the region .",
    "the second correction , @xmath131 , corresponds to the probability that both decay products are within the detector acceptance . for boost invariant system with full azimuthal coverage , @xmath132 , since the particles leaving the detector acceptance will be balanced by those entering it . unlike @xmath131 , which in general is @xmath133 , since for resonances outside the detector acceptance with one of the decay products entering the detector acceptance , the other can not enter it due to momentum conservation . in practice",
    ", this is necessary only at rhic ( much less at lhc ) for some weak decays , which are experimentally distinguishable from primary particles . in the program ,",
    "we offer the option to enter the correction factor @xmath131 for any resonance decay as an input parameter , see section  [ sec : weakdecays ] for details how to accomplish this .",
    "the basic structure of the program is depicted in figure  [ fig : programstructure ] .",
    "it requires a total of six input files containing list of particles , decay tree , and model parameters .",
    "the program can perform a multitude of commands , which are read at run time from the file ( ` sharerun.data ` ) .",
    "[ fig : programstructure ]    the computational and fitting block will perform commands in the run file as entered one after another generally independently of each other .",
    "each command produces an output into a separate file named by the user .",
    "the mandatory input files the user has to provide are ( default filenames listed ) :    * ` particles.data ` ( 14letter filename )  list of particle properties , * ` decays.data ` ( 11letter filename )  list of non - charm hadron decays , * ` hffeed.data ` ( constant filename )  list of inclusive branching ratios of charm hadrons , * ` thermo.data ` ( 11letter filename )  list of model parameters , * ` ratioset.data ` ( 13letter filename )  list of model parameter ranges , * ` totratios.data ` ( 14letter filename )  experimental data and physical properties requested in the output * ` sharerun.data ` ( constant filename )  the driving file with a list of commands to perform ,    and an optional input file with weak feed - down corrections    * ` weak.feed ` ( 9letter filename )  list of weak decay feed - down corrections @xmath131 , as described in section  [ sec : fluctuations ] .",
    "if the user does not specify any of the mandatory input files explicitly , the program will look for the input file with the default name and will not run correctly if any of the mandatory input files is missing . in all of these files ,",
    "the user can enter a comment by starting a line with the pound character , ` # ` .",
    "all subsequent characters after ` # ` on the line will be ignored .",
    "we will address the structure of each input files below in a separate section .",
    "it should be pointed out that all input files are read by the program as fixed format input and it is hence crucial to keep their structure including the number of characters allocated for each record ( including blank spaces between the records ) .",
    "the only exception is the charm hadron decay file ` hffeed.data ` , which can include any positive number of blank characters ( spaces or tabs ) in between the records .",
    "the thermal parameter file contains a list of parameters of the model together with their initial value .",
    "all parameter names are 4letter tags .",
    "the ` thermo.data ` file has to contain the 12 parameters as in the provided program package .",
    "we show in table  [ tab : thermodata ] the typical contents of a sample file together with the description of each parameter .",
    "the units are gev and @xmath134 , where applicable .",
    ".[tab : thermodata]structure of the ` thermo.data ` file containing thermal parameters and their respective initial values . [ cols=\"<,<,<\",options=\"header \" , ]     the possible operations are addition , subtraction , multiplication and division accomplished by using ` + , -,x,/ ` symbols respectively in between two two - digit line numbers as seen in the above example .",
    "note the necessary trailing 0 for single digit line numbers .",
    "these operations are limited to two - digit line numbers , although the input file can in general have up to 200 entries ( not counting commented lines ) . note that this feature uses implicitly recursive code , which may be compiler dependent .",
    "it has been found to work as intended on several platforms and compilers we tested share with charm on .",
    "we provide a sample data file with the program package .",
    "the systematic and statistical errors can be entered as two separate quantities in share as seen in the above example .",
    "this option is created since systematic error is not a random variable that the statistical error is .",
    "systematic error originates from the experimental setup and/or data analysis methods and it can be common to several experimental results , e.g. , the efficiency to track strange antibaryons and baryons has same systematic uncertainty , or there could be a strong ( anti)correlation , e.g. , if an observed particle track is a proton or @xmath135 is not always possible to decide , but if it is one , it can not be the other . by allowing for systematic and statistical error entry as matter of principle",
    ", we prepare for a more complete future treatment of the systematic error including an error correlation analysis .    once the systematic error correlation matrix function is known , one must discover combinations of the data which suffer least from the systematic error .",
    "the fit than involves a data set in which some of the fitted quantities have a much reduced systematic error . at present , the systematic error correlation matrix is not made available by the experimental groups .",
    "therefore , such more detailed error treatment in the fitting procedure is not included in this release of the share with charm program suite as a procedure could neither be properly set - up nor tested .",
    "in the current release of the program , if both errors are made available and have been entered separately , they will be added to obtain the total error ` error ` of the data point : ` error = stat + syst ` .",
    "we note , that as outcome of this procedure , we often see in the study of the rhic and lhc data that the overall normalization factor @xmath136 shows a large and apparently common error of all data , suggesting that all results we interpreted had as input a common systematic tracking efficiency error .",
    "share with charm allows the user to solve for a thermal parameter based on a fixed ( or experimental ) value rather than fit it .",
    "the most common application of this feature would be exact conservation of strangeness , @xmath137 , which means numerically solving for @xmath138 . in this case",
    ", @xmath138 is not a fit parameter anymore , but rather an analytical function of the other parameters constrained by the experimental data point .    in order to solve for a parameter , the ` name2 ` in the experimental data",
    "file ( ` totratios.data ` ) should be in the form ` solvexxxx ` , where ` xxxx ` is one of the fit parameters .",
    "the parameter limits set in ` ratioset.data ` still apply , every parameter solution outside of these limits is rejected .",
    "this helps rejecting unphysical solutions , such as @xmath139 .    in principle",
    ", it is possible to solve for any parameter using any data point .",
    "however , many such combinations do not have a minimum , especially if the data point does not ( or only marginally ) depend on said parameter . if minuit takes a long time ( e.g. , many iterations ) without converging to a minimum",
    ", there is a good chance that the minimization procedure will not work .",
    "it is thus advised to use this feature mainly to solve for the values of chemical potentials based on conservation laws .",
    "for instance , strangeness conservation can be assured in the system by solving for @xmath138 by using the following line in the ` totratios.data ` file requiring net strangeness @xmath140 to vanish : + ` netstrang solvelams 0 .",
    "` + the baryochemical potential in a perfectly central pb ",
    "pb ( z=82 , a=207 ) collision can be solved for using the baryon number and solving for @xmath141 : + ` netbaryon solvelamq 414 .",
    "0 . 0 . 0 `",
    "+ and the corresponding charge conservation may be imposed on the fit with : + ` netcharge solvelmi3 164 .",
    "0 . 0 . 0 `",
    "+ the ` solve ` statements have to come at the beginning of the experimental data file , otherwise the program will return an error .    an alternative to the exact solving for a parameter required by a conservation law",
    "is to require approximate conservation of a quantity . treating a conservation law as a data point allows for detector acceptance corrections . a line such as : + `",
    "netstrang totstrang 0 .",
    "1 ` + imposes strangeness conservation to within 1% . we often impose charge over baryon number conservation with the line + ` netcharge netbaryon 0.39 0.02 0 .",
    "1 ` + the choice of implementing the conservation laws analytically or approximately ( if at all ) is left to the user .",
    "it is worth noting that exact solution is a more reliable procedure , however , it can not be used very often considering the limited acceptance data from contemporary collider experiments .",
    "this file contains the instructions which are executed one by one during a program run .",
    "every line contains a separate operation , such as reading input files , assigning values to parameters , calculation of particle ratios , fitting model parameters to experimental data ( i.e. , minimizing @xmath142 ) , plotting contours and @xmath142 profiles .",
    "the program will read one line at a time and execute the command until it reaches the end of the ` sharerun.data ` file .",
    "it is imperative that the user maintains the appropriate spacing of commands and values in this file , because this file is read as a formatted input , same as most of the input files described in previous sections .",
    "any deviation from the expected number of characters may result in an unexpected behavior of the program ranging from a misinterpretation of a value to not recognizing the command at all and exiting prematurely with an error . generally , there are two spaces between keywords and numbers .",
    "we specify the expected command format wherever necessary .",
    "each command can be used multiple times with different input and output files .",
    "we shall now describe all the commands available to the user with a brief description .",
    "a typical ` sharerun.data ` file . ]      ` read therm_ini \\langle11letter filename\\rangle ` : :     +    reads the specified file corresponding to the ` thermo.data ` file    described in section  [ sec : parameters ] . `",
    "read fit_param \\langle13letter filename\\rangle ` : :     +    reads a file containing parameter ranges equivalent to the    ` ratioset.data ` file described in seciton  [ sec : ratioset ] . `",
    "read particles \\langle14letter filename\\rangle \\langle11letter filename\\rangle ` : :     +    reads the file containing list of particle properties and a second    file of corresponding decay tree .",
    "the files are considered being    equivalent to ` particles.data ` and ` decays.data ` files described in    section  [ sec : particlelist ] and  [ sec : decayfile - light ] . `",
    "read totaldata \\langle14letter filename\\rangle ` : :     +    reads experimental data file equivalent to the ` totratios.data ` file    described in section  [ sec : experimentaldata ] .      `",
    "pset \\langle4letter tag\\rangle value ` : :     +    the ` pset ` command sets the thermodynamic parameter specified by the    4letter tag to a ` value ` .",
    "a real number is expected in ` value ` , hence    decimal point is necessary even with integer values .",
    "when the    ` thermo.data ` file is read , a series of ` pset`-like commands is    performed using all parameters and values read from the file . `",
    "pfix \\langle4letter tag\\rangle ` : :     +    fixes the given model parameter to its current value . in all    subsequent commands ,",
    "this parameter will be kept fixed until released ,    or its value modified by another command .",
    "+    there are 5 additional ` tag`s that are used to control the program    options in connection with ` pfix ` .",
    "the user can choose to use    boltzmann approximation and quantum ( fermi  dirac and bose  einstein , as    appropriate ) statistics via the tags ` bltz ` and ` fdbe ` respectively .",
    "the default is quantum statistics .",
    "furthermore , one can select to use    the canonical ensemble treatment of the baryon number via ` ce_b ` tag ,    and of strangeness via ` ce_s ` tag . selecting the program default grand    canonical ensemble for both quantum numbers",
    "is done using the ` gcal `    tag . `",
    "prel \\langle4letter tag\\rangle \\langlelower limit\\rangle \\langleupper limit\\rangle \\langlestep size\\rangle ` : :     +    releases the given parameter and sets its range between the lower and    upper limits and sets its initial step size .",
    "this command is    equivalent to reading one line in the ` ratioset.data ` file .",
    "all three    numbers in the ` prel ` command are mandatory . otherwise , zeros are    assumed and any following calculation will produce unwanted results .    the required format of this command is ` ( a4,2x , a4,3x,2f7.2,f9.5 ) ` ,    i.e. , after the parameter tag , the program expects in sequence ; 3    spaces , 7 characters for parameter lower limit ( counting the decimal    point ) , 7 characters for the upper limit and 9 characters for the    initial step size .",
    "notice , that no spaces are required between the    numbers , so the following line is valid :    + .... prel   temp    0.123450.23232000.00100          tag     low     upper   step       ....    +    this example releases the hadronization temperature parameter ` temp `    setting its limits to @xmath143    and @xmath144 and the initial step    size in minimization to @xmath145 .",
    "similarly as in the above    example , the user can take advantage of the precision allowed by the    format specification of any command .",
    "it is , however , not needed very    often .      in some analysis",
    ", it may be beneficial to manipulate an experimental data point during the program run .",
    "the following two commands are used to accomplish this .    `",
    "dfit datapoint fit ? ` : :     +    switches if a data point on the ` datapoint`-th line in the    experimental data file will ( ` fit=1 ` ) or will not ( ` fit=0 ` ) be fitted    during the evaluation of subsequent commands .",
    "the format of this    command expects the keyword dfit followed by 2 spaces and 5 characters    allocated for each ` datapoint ` and ` fit ? ` .",
    "the format is    ` ( a4,2x,2i5 ) ` . `",
    "dset datapoint value error ` : :     +    set the value of a ` datapoint`-th ratio or quantity in the    experimental data file to ` value ` and its uncertainty to ` error ` .",
    "the    program expects the following format of the command ;    ` ( a4,2x , i5,2f10.5 ) ` , i.e. , 2 spaces after the keyword dset , 5    characters allocated for the ` datapoint ` number , and 10 characters for    each ` value ` and ` error ` .",
    "` calc ratiodata \\langle13letter filename\\rangle ` : :     +    calculates the value of ratios and quantities read by the read    totaldata command given the current values of thermal parameters    ( either read by the read thermo_ini , or resulting from the last    command ) .",
    "the output is written to a file with a 13letter filename    specified by the user .",
    "the output in the file has the general format    of ` ratio name1/name2 \\langlevalue\\rangle ` . in case either of ` name1 `    or ` name2 ` is zero , zero is printed as a result of the ratio . ` calc ratioplot \\langle12letter filename\\rangle \\langle4letter tag\\rangle l u p datapoint ` : :     +    this command calculates a ratio , yield or quantity specified on the    ` datapoint`-th line in the experimental data file as a function of the    thermal parameter specified by the 4letter tag .",
    "the program will vary    the parameter from ` l ` to ` h ` in ` p ` equidistant steps and record in    the output file the varying parameter values in the first and the    property values in the second column .",
    "the output file can then be used    as input to an external plotting program , such as gnuplot , paw ,    xmgrace or mongo .",
    "the format of this command is +    ` ( a4,2x , a9,2x , a12,2x , a4,2x,2f5.1,2i5 ) ` , i.e. , two spaces between each    word until the parameter tag , two spaces after the parameter tag , 5    characters reserved for each of the lower and upper limits followed by    5 characters for the number of points and last , 5 characters for the    data point number . `",
    "calc ratiocont datapoint \\langle12letter filename\\rangle \\langletag1\\rangle l1 u1 p1  ` : :     +    * `  \\langletag2\\rangle l2 u2 p2 ` * +    calculates a ratio , yield or a thermodynamic quantity as a function of    two parameters specified by ` tag1 ` and ` tag2 ` for parameter values    ranging from ` l1 ` to ` u1 ` in ` p1 ` steps for the first parameter and    from ` l2 ` to ` u2 ` in ` p2 ` steps for the second one .",
    "similar to the    above ` ratioplot ` command , the data point is referred to by its line    number ( ` datapoint ` ) in the experimental data file .",
    "( note , that    @xmath146 results in 10000 grid points to be    calculated which may take a long time . )",
    "the general format of this    command expected by the program is :    ( a4,2x , a9,i5,a12,2x , a4,2x , f5.1,2x , f5.1,2x , i3,2x , a4,2x , f5.1,2x , f5.1,2x , i3 ) +    the output is written to a file with 13letter filename specified by    the user in a 3column table and can be plotted by an external program    capable of 3d plotting . `",
    "calc fitratios \\langle13letter filename\\rangle ` : :     +    this command minimizes @xmath147 of the set of    experimental data input by the last +    ` read totaldata ` command varying parameters within ranges specified    in +    ` read fit_param ` starting with parameter initial values from +    ` read therm_ini ` .",
    "+    in our fitting procedure , we minimize the @xmath142 value    function as function of shm parameters .",
    "the @xmath142    function is the sum of squares of the relative difference between    computed yields and experimental data .",
    "@xmath148    where @xmath149 is the @xmath26th investigated    quantity with experimental error @xmath150 and    @xmath151 is the number of data points .",
    "we seek the best fit to    experimental particle yields and ratios using ` minuit `  @xcite , an    optimization package part of the cernlib computational libraries .",
    "we    evaluate the statistical significance ( also called either    @xmath152-value , or confidence level ",
    "cl ) of our fits .",
    "cl is    defined as the probability that given a correct hypothesis ( here the    shm model ) and gaussian ` noise ' experimental errors ( caution : we are    dealing with significant systematic data errors ) , @xmath142    would in repeated measurements assume a value that is at or above the    considered value  clearly , the smaller @xmath142 is , the    higher cl is , asymptotically approaching 100% .",
    "values of statistical    significance far below 50% suggest that the model is not appropriate    for the task of describing the experimental data .",
    "regarding    @xmath142 in the limit of many degrees of freedom    @xmath153 ,    it is well known that @xmath154    corresponds to cl of 50% , see figure 36.2 in pdg  @xcite . for    @xmath155",
    ", this figure shows that a    considerably lower @xmath156 is necessary to    reach cl of 50% . for more complete discussion of significance , see    pdg  @xcite section 36.2.2 .",
    "+    in case the minimization package minuit  @xcite used by share does not    find a good reliable minimum via common strategies , or the parameter    errors can not be reliably evaluated , minos subroutine is called to    evaluate the parameter errors and potentially find a better minimum .    this ,",
    "unfortunately , significantly increases the computation time .",
    "+    the output in the 13letter file provided by the user has the general    format : +    header with time and date of minimization .",
    "+    final thermal parameter values ( ` + /-",
    "' error , when fitted ) , +    followed by chemical potentials    @xmath157 +    and phase space occupancies for each flavor    @xmath158 .",
    "+    then , the detailed fit results are printed in a table format : +    ` top bottom theory exp error chiterm feed - down ` +    where top refers to the denominator and bottom to the numerator of the    quantities defined in the input file ( ` totratios.data ` ) , theory states    the model value , exp states the experimental value as given in the    input file , error is the combined statistical and systematic error ,    chiterm is the @xmath159 contribution of the data point to    the total @xmath147 defined as :    @xmath160    the @xmath159 is reported before squaring to keep the sign ,    i.e. , information about the resulting model theoretical value being    above or below the experimental data point .",
    "feed - down states the weak    decay feed - down scheme or filename used for this particular data    point .",
    "the end of the output file reports the number of degrees of    freedom , total @xmath142 , @xmath147    and statistical significance of the fit .",
    "+    at the end of each fit , two additional output files are created ,    ` charmfeedprimary.data ` and ` charmfeed.data ` .",
    "the first one contains    the primary yields of charm particles calculated by the charm module    and the second one contains particle yields after charm decays , i.e. ,    particle yields produced solely by charm .",
    "note , that these two    filenames are constant and the files get rewritten every time a fit is    performed . `",
    "calc fitnminos \\langle13letter filename\\rangle ` : :     +    this command is equivalent to the above ` fitratios ` regarding both    format of the command line and function .",
    "the only difference is that    parameter error evaluation minos  @xcite is never called . omitting the    use of minos",
    "usually saves considerable amount of computing time ,    however , errors of the resulting thermal parameters will not be    reliable and the minimum found has a higher chance of not being the    global minimum . `",
    "calc plot_data \\langle3 13letter filenames\\rangle ` : :     +    generates three files which are optimized to be graphed with an    external 2d plotting package ( gnuplot , xmgrace , paw ,  ) .",
    "the first file    contains numerical list of ratios and quantities that were fitted , the    second one contains a numerical list of ratios and quantities that    were calculated and the last one will contain experimental values with    errors . see the discussion in section  [ sec : particleratios ] on how to    choose which file a quantity should be included in .",
    "the filenames on    the command line should be separated by 2 spaces . `",
    "calc chiprofil \\langle12letter filename\\rangle tag l u p ` : :     +    this commands calculates a @xmath147 profile    of a parameter specified by the ` tag ` .",
    "the program divides the    parameter range between ` l`ower limit and ` u`pper limit in ` p `    equidistant intervals , fixes the given parameter at the boundary of    each interval ( i.e. , ` p`+1 values including ` l ` and ` u ` ) and fits    other free parameters to the data as specified in the ` ratioset.data `    file or ` pset`/`pfix`/`prel ` commands preceding this one .",
    "this    procedure is equivalent to a sequence of ` pset ` and ` calc fitratios `    commands .",
    "+    the main output of this command is the ` filename ` with ` .prof `    extension , which contains a 2column table with the given parameter    values in the first and the resulting    @xmath147 in the second column .",
    "the full    output of all performed fits is stored in a log file with ` _ _ log `    extension . for each fitted parameter , a separate file",
    "is created    containing 5 columns and has the parameter tag appended to its name .",
    "for instance , performing a temperature    @xmath147 profile with output file stored in    ` proftemplhc1 ' , the values of @xmath15 will be stored in    ` proftemplhc1_gamq ' file ( provided that @xmath15 is a    free parameter of the fit ) .",
    "the first column of each parameter file    contains values of the ` tag ` parameter ( temperature in the above    example ) , the second column the fitted parameter values    ( @xmath15 values in the above example ) , the third    contains values of an associated bulk property ( see    table  [ tab : associatedbulk ] for a details ) , the fourth column states    the @xmath147 and the last column contains    statistical significance .",
    "+    the general format of this command is    ` ( a4,2x , a9,2x , a12,2x , a4,2x,2f8.1,i5 ) ` , in other words there has to be    2 spaces between the text strings up to the ` tag ` , after which there    are 8 digits allocated for the ` l`ower limit , 8 digits for the ` u`pper    limit and 5 digits for the number of ` p`oints .",
    "+    .[tab : associatedbulk ] table of associated bulk properties with    parameters printed in the profile output files .    [ cols=\"<,<\",options=\"header \" , ]    |=======================================    |parameter tag |associated bulk property    |temp |totenergy prdensity    |norm |pressuret prdensity    |gamq |entropy_t prt_yield    |lamq |netbaryon prt_yield    |mu_b |netbaryon prt_yield    |gams",
    "|totstrang prt_yield    |lams |netstrang prt_yield    |mu_s |netstrang prt_yield    |lmi3 |netcharge prt_yield    |mui3 |netcharge prt_yield    |======================================= ` calc sigprofil \\langle12letter filename\\rangle tag l u p ` : :     +    this command is very similar to the above ` chiprofil ` in terms of both    the command format and functionality .",
    "the only difference is that in    the main output file ` \\langlefilename\\rangle.prof ` , the statistical    significance is printed in the second column rather than    @xmath147 . `",
    "calc fitprofil \\langle12letter filename\\rangle tag l u p datapoint ` : :     +    this and the next two commands allow to study the fit parameter    sensitivity to a particular data point in detail .",
    "the format of the    command is the same as the one above , except for the extra integer    ` datapoint ` identifier at the end ( line number of the data point in    the experimental data file ) .",
    "general format is    ` ( a4,2x , a9,2x , a12,2x , a4,2x,2f8.1,2i5 ) ` .",
    "the command produces a    parameter ` tag ` profile for a fitted ` datapoint ` model prediction    rather than the overall fit quality , as the previous two commands do .    for example , if ` datapoint ` corresponds to @xmath161 ratio    within the given data set , the program performs a @xmath142    profile calculation with respect to the parameter ` tag ` fixing it at    ` p ` values ranging from ` l ` to ` u ` .",
    "+    the command creates several output files , namely    ` \\langlefilename\\rangle.prof ` , which contains the values of parameter    ` tag ` in the first column and the @xmath159 term of the given    ` datapoint ` defined by eq .",
    "[ eq : chiterm ] in the second column .",
    "the    output file with ` .chi2 ` extension contains the overall    @xmath147 of the fits , and the extension    ` .stsg ` represents statistical significance of the fits .",
    "for every    fitted parameter other than ` tag ` , there is a correlation file with    extension ` _",
    "\\langletag2\\rangle ` ( e.g. , ` _ gamq ` ) created , which has the    same format and contents as for the ` chiprofil ` command above .",
    "full    output for all the fits is stored in a log file with extension    ` _ _ log ` . `",
    "calc datprofil \\langle12letter filename\\rangle tag l u p datapoint ` : :     +    this command has the same command line structure , functionality and    output files as the ` fitprofil ` command above , except the values of    the ` datapoint ` ( rather than its @xmath159 term contribution    to the overall @xmath142 of the fits ) is printed in the    output file ` \\langlefilename\\rangle.prof ` . `",
    "calc snsprofil \\langle12letter filename\\rangle tag l u p datapoint ` : :     +    same as the above two commands , except the output file    ` \\langlefilename\\rangle.prof ` now contains the _ sensitivity _ of the    given ` datapoint ` to the particular parameter ` tag ` .",
    "the sensitivity    is defined as a ratio of the data point s shm prediction for a given    parameter ` tag ` value to the shm prediction of the ` datapoint ` for the    best fit value of that parameter . `",
    "\\langle9letter filename\\rangle deviation tag1 tag2 ` : :     +    this command calculates the @xmath147 contour    for the parameters ` tag1 ` and ` tag2 ` .",
    "the program will output to the    file ` \\langlefilename\\rangle ` pairs of parameter ` tag1 ` and ` tag2 `    values that correspond to    @xmath162 .",
    "the general format of the command is    ` ( a4,2x , a9,2x , a9,1x , f4.1,2x , a4,2x , a4 ) `      the complete ` log ' for each run is saved in a file ` sharerun.out ` .",
    "this includes :    * the contents of each input file as read in by the program ( useful for input file format check ) * a list of performed operations . *",
    "minuit output .",
    "parameter correlation matrix can be found here , for example . *",
    "the content of each output file ( in the same format as in the output file )    if the program does not encounter any problems during the run , a message : + ` run terminated successfully ` , + is printed on screen and at the end of the ` sharerun.out ` file . in case",
    "an error occurs during a run , the program reports it to the user on screen .",
    "more information about the error is reported in the ` sharerun.out ` file .",
    "convergence to the very same set of best parameters can not be expected when one or more of the parameters is insensitive to any of the fitted experimental data points . in this case , the minimum of @xmath142 function is a domain in the respective parameter space , and a point in this domain is chosen in a quasi - random manner . as an example of this situation , consider the data from lhc .",
    "when fitting particle yields and ratios , one can constrain the values of chemical non - equilibrium parameters @xmath15 and @xmath14 along with @xmath163 , as these are constrained by the precisely measured numerous baryon and meson yields  @xcite . however , in the lhc environment , it is challenging to constrain the value of baryochemical potential @xmath71 .",
    "this is especially the case when fitting with charm .",
    "while a measurement of any charm hadron yield , for instance @xmath83 meson , with 10% precision constrains the charm yield to a narrow range in @xmath6 , the charm feed - down introduces additional uncertainty in the value of @xmath71 due to charm baryon production and decays .",
    "moreover , feed - down impacts hadron yields and hence the other fitted parameters adjust accordingly . in order to measure the baryochemical potential @xmath71",
    ", one would need , for example , a relative baryon ",
    "antibaryon difference measurement , @xmath164 for a baryon @xmath165 obtained with a precision comparable to the other input data .",
    "we thus advise fixing insensitive parameters to most likely values , especially when fitting charm at lhc . therefore , until additional data fixing @xmath71 becomes available , one should proceed with zero baryochemical potential , that is fix @xmath166 , in the exploration of charm effect on hadronization .",
    "we demonstrate the program capabilities by showing in figure  [ fig : charm_output ] a fit to lhc data we already characterized recently  @xcite .",
    "this data does not yet comprise any charm hadron yields and thus we can not fit here the charm yield present .",
    "the new charm module capabilities are demonstrated by adding an ad - hoc yield of charm at hadronization , @xmath167 charm plus anti - charm quarks ( 25 @xmath168 pairs ) . in order to demonstrate how",
    "physical bulk properties can be used in the fit , we require a specific hadronization conditions by fitting a bulk physical property , in this case we decided to illustrate the example by prescribing the energy density @xmath169",
    ".     sample of _ share with charm _",
    "output for a prescribed 50 @xmath170 quarks at hadronization .",
    "non - charm most central ( 0 - 5% ) lhc data used in  @xcite is fitted , charm hadron decays are injected into hadron multiplicities . we also prescribe the bulk energy density @xmath171 .",
    "note that the fit outcome is 85% confidence level for 10 degrees of freedom .",
    "( program output was reduced to fit in the figure . ) ]    we show in figure  [ fig : charm_output ] a reduced program output with final statistical parameters ( @xmath172 ) , fitted physical properties of the bulk , followed by charm baryon , charm meson and charmonium yields .",
    "the bottom of the output shows the fit quality in terms of total @xmath142 , reduced @xmath147 , and statistical significance @xmath173 .",
    "the main difference between the here presented fit and the ` standard ' fits is that nearly 50 charm hadron decays producing as many as 200 non - charm hadrons containing strangness and multi - strangeness .",
    "as the figure  [ fig : charm_output ] shows the fit is very good and converges to a relatively low temperature of @xmath174  mev .",
    "the reduction of temperature by a few mev is due to the injection of charm hadron decay products into the fitted hadron abundances .",
    "further lhc physics related use of the program is presented in our recent publications  @xcite .",
    "before you start installing share with charm , make sure you have the following installed on your system :    * fortran 77 compiler , we have tested gnu ` gfortran ` and intel ` ifort ` compilers .",
    "* c++ compiler ( including c++ standard libraries ) , we have tested gnu ` g++ ` and intel ` icpc ` compilers . * cernlib libraries .",
    "they are available in standard repositories for most gnu linux distributions , alternatively , the source code is available for download at  @xcite .",
    "debian based linux distribution ( ubuntu ,  ) users should locate and install the package ` cernlib ` from their system repository .",
    "red hat base ( fedora project , slc ,  ) can install cernlib from a rpm package available , for example , at  @xcite .",
    "the share with charm program comes in a single .zip archive labeled ` sharev3.zip ` .",
    "the package is available at _ http://www.physics.arizona.edu/~gtshare / share / share.html_. + after obtaining the program package , unpack it using the following command ( it will create a folder called ` sharev3 ` with all the files in it ) : + * ` unzip sharev3.zip ` * + the following files will be created in this directory from the archive contents .",
    "the files are enough for a ` representative ' run of share with charm .",
    "` src / sharev3.0.0.f ` : :    share source code in fortran 77 .",
    "` src / charmdistribution_v1.9.cpp ` : :    charm module source code in c++ .",
    "` decays.data ` : :    the complete particle data group decay tree of light hadrons    ( section  [ sec : decayfile - light ] ) . `",
    "hffeed.data ` : :    the complete particle data group decay tree of charm hadrons    ( section  [ sec : hffeed ] ) .",
    "` lhc1020mi.data ` : :    a representative input data files ( section  [ sec : experimentaldata ] )    containing experimental yields data for centrality bin 10 - 20% based on    data from the alice experiment as of august 2013 , see  @xcite and    references therein .",
    "` makefile ` : :    a makefile of the project , useful for program compilation , see    section  [ sec : make - compilation ] below .",
    "` particles.data ` : :    particle properties with full widths ( section  [ sec : particlelist ] ) . `",
    "partnowdt.data ` : :    particle properties with no widths ( section  [ sec : particlelist ] ) .",
    "calculations with this input file require significantly less    computational time , and the use of full widths has not yet been    justified , see for example recent comparison in  @xcite . `",
    "ratioset.data ` : :    the parameter ranges input file ( section  [ sec : ratioset ] ) . `",
    "ratioset.test ` : :    the parameter ranges input file for quick start test run . `",
    "sampleoutput ` : :    directory containing sample output files resulting from a    ` representative ' sample run with input files we provide as part of the    package . ` sharerun.data ` : :    a ` representative ' run input file ( section  [ sec : fitting ] ) including an    analysis of hadron yields at lhc presented by members of our    collaboration in  @xcite . `",
    "thermo.data ` : :    the list of model parameters ( section  [ sec : parameters ] ) . `",
    "weak.feed ` : :    a sample weak decay file ( section  [ sec : weakdecays ] ) .",
    "the recommended way to compile share with charm is to make use of the gnu ` make ` utility  @xcite , available on most gnu linux systems ( if this is not your case , proceed to section  [ sec : manualcompilation ] ) .",
    "the most common combination of available compilers is ` gfortran ` and ` g++ ` .",
    "if this is your case , after unzipping the contents of the program package into a folder , use the command    * ` make ` *    in this directory to compile the program . if you are using different compilers , edit the header of the included ` makefile ` to specify compilers available on your system . when done , use `",
    "make ` ( as above ) to compile share with charm .",
    "using ` make ` with the included makefile processes the two source files in the ` src ` folder , compiles each of them into an object file , which is stored in the ` obj ` folder and then links the object files together with cern libraries into an executable ` share ` , which is ready to be run from the command line .",
    "we provide the two most common targets in the makefile , ` all ` to compile the program and ` clean ` to remove objects and executable file .",
    "you may also need to specify the location of the cern libraries on your system in the ` makefile ` , for instance , + ` libs = -l / usr / local / cernlib/2006/lib -lstdc++  `      share with charm consists of two source code files , both located in the ` src ` subdirectory .",
    "manual compilation consists of three steps",
    ".    1 .   compiling share fortran code into an object .",
    "for example , using the gnu fortran compiler ` gfortran ` , this is done via the following command ( in the ` src ` folder ) : + * ` gfortran sharev3.0.0.f -c",
    "-o sharev3.0.0.o ` * + note the ` -c ` option to prevent linking .",
    "you may need to consult your fortran compiler documentation for equivalent command line options .",
    "2 .   compiling the charm module written in c++ is accomplished similarly to the above step , using an example command line with gnu c++ compiler ` g++ ` : + * ` g++ charmdistribution_v1.9.cpp -c -o charmdistribution_v1.9.o ` * 3 .   linking all object files with the necessary libraries into an executable binary file ` share `",
    "is accomplished using the fortran compiler used in step 1 on the following command line : + * ` gfortran sharev3.0.0.o charmdistribution_v1.9.o \\ -lstdc++",
    "-lkernlib -lmathlib -lpacklib -o share ` * + in case you compiled cern libraries manually , you may need to specify the location of the libraries on the last command line using the `",
    "-l/<cernlib location>/lib ` option in order to link them properly .",
    "if necessary , consult your compiler and cern libraries documentation for details .",
    "when all three steps are completed without errors , move ( copy ) the executable binary of share with charm ( ` share ` in the above example ) to the parent directory ( i.e. , one directory up ) where all share input files are located .",
    "the program is invoked with ` ./share ` command ( unless a different name was chosen by the user during compilation ) .",
    "the program opens the ` sharerun.data ` file located in the current directory and performs tasks specified therein .",
    "see section  [ sec : fitting ] for details on how to run the program .",
    "the provided copy of ` sharerun.data ` should produce detailed output showing the program capabilities , which can used to check correct program operation by comparing with the provided sample output in the ` sampleoutput ` directory .",
    "tests were run on both 32 and 64 bit processors with two different versions of cern libraries .",
    "differences between platforms appear when fitted parameters are not constrained by data , see section  [ sec : sensitivity ] .",
    "share with charm is an analysis tool developed specifically to study particle production in relativistic heavy - ion collisions spanning an energy range from compact baryonic matter through the entire rhic range up to top lhc energy .",
    "share with charm is particularly suitable to address the following questions ( italic font show new features of this release ) :    * what is chemical freeze - out temperature , chemical potentials , and volume ? * which quark flavors are in chemical equilibrium at hadronization and those that are not , how abundant are they ? * what are the physical bulk properties of the hadronizing fireball ?",
    "* are particle yield fluctuations compatible with hadron yields and ratios ? * _ is charm subject to statistical hadronization ? _ * _ how large is the contribution of charm hadron decays to the final light hadron yields ? _ * _ how does accounting for charm decay feed change the hadronization conditions ? _ * _ does charm hadronize at the same temperature as the light hadron freeze - out ? _",
    "the need for the new version of share with charm arises from the necessity of including charm hadrons into statistical hadronization model as they become significant in heavy - ion collision experiments at lhc energy range . in the upgraded program ,",
    "a flexible treatment of charm hadrons has been introduced , and we provide full charm hadron list and , more importantly , a full decay tree compiled to the best of current knowledge of charm decays in a procedure that assures cross - particle symmetries and consistence .    at the time of preparing this publication",
    ", there is no charm hadron yield measured at lhc . with partial measurement of the @xmath83@xmath175-spectrum",
    ", we estimate its invariant yield @xmath176 to be in the range of @xmath177 , corresponding to @xmath178 .",
    "however , in primary parton collisions a more generous result comes from scaling the total charm cross - section in @xmath179 collisions @xmath180 , which implies @xmath181  @xcite , where most of the uncertainty is inherent from the @xmath180 uncertainty .",
    "share with charm is capable of exploring both of these regions .",
    "as soon as a single charm hadron yield data becomes available , fitting this hadron using share with charm will help to constrain the total amount of charm present at hadronization allowing to cross check with the production models . with a second charm hadron yield , the difference between light and charm hadronization temperature can be constrained . and",
    "finally , with additional charm particle yields , we will be able to answer if charm hadronizes according to statistical hadronization principles .",
    "we believe that at the time of writing , share with charm is the only shm implementation capable of :    * accounting for full chemical non - equilibrium of all four quark flavors , @xmath0 and @xmath23 , * characterizing and/or fitting bulk properties of the particle source , * evaluating the produced hardon fluctuations , * quantifying the charm hadron contribution to hadron abundances ,    aside from providing the other features necessary to describe soft hadron production in relativistic heavy - ion collisions in the entire energy range .",
    "work supported by the u.s .",
    "department of energy , grants no .",
    "de - fg02 - 04er41318 ( mp , jl , jr ) and de - fg02 - 93er40764 ( gt ) .",
    "laboratoire de physique th ' eorique et hautes energies , lpthe , at university paris 6 is supported by cnrs as unit ' e mixte de recherche , umr7589 .",
    "gt acknowledges financial support received from the helmholtz international centre for fair within the framework of the loewe program ( landesoffensive zur entwicklung wissenschaftlich - konomischer exzellenz ) launched by the state of hesse .",
    "j.  kapusta , b.  muller and j.  rafelski , `` quark - gluon plasma : theoretical foundations '' , elsevier science , ( 2003 ) .",
    "g.  torrieri , s.  steinke , w.  broniowski , w.  florkowski , j.  letessier and j.  rafelski , comput .",
    "commun .   * 167 * , 229 ( 2005 ) .",
    "t.  matsui and h.  satz , phys .",
    "b * 178 * , 416 ( 1986 ) .",
    "m.  gazdzicki and m.  i.  gorenstein , phys .",
    "* 83 * , 4009 ( 1999 ) .",
    "a.  andronic , p.  braun - munzinger , k.  redlich and j.  stachel , phys .",
    "b * 571 * , 36 ( 2003 ) .",
    "a.  andronic , p.  braun - munzinger , k.  redlich and j.  stachel , j.  phys .",
    "g * 35 * , 104155 ( 2008 ) .",
    "m.  schroedter , r.  l.  thews and j.  rafelski , j.  phys .",
    "g * 27 * , 691 ( 2001 ) .",
    "g.  torrieri , s.  jeon and j.  rafelski , phys .",
    "c * 74 * , 024901 ( 2006 ) . c.  pruneau , s.  gavin and s.  voloshin , phys .",
    "c * 66 * , 044904 ( 2002 ) .",
    "fortran 77 standard , _",
    "http://www.fortran.com/f77_std/rjcnf0001.html_ , accessed 20 sept 2013 , ( or any f77 reference manual ) .",
    "m.  petran , j.  letessier , v.  petracek and j.  rafelski , arxiv:1309.6382 [ hep - ph ] , in proceedings of strangeness in quark matter 2013 , 22 - 27 july 2013 , birmingham , uk .",
    "g.  torrieri , s.  jeon , j.  letessier and j.  rafelski , comput .",
    "phys .  commun .   * 175 * , 635 ( 2006 ) .",
    "f.  james and m.  roos , comput .  phys .",
    "commun .",
    "* 10 * , 343 ( 1975 ) .",
    "m.  petran , j.  letessier , v.  petracek and j.  rafelski , phys .",
    "c * 88 * , 034907 ( 2013 ) .",
    "m.  petr , j.  letessier , v.  petrek and j.  rafelski , arxiv:1310.2551 [ hep - ph],strangeness in quark matter 2013 proceedings in press .",
    "m.  petran and j.  rafelski , phys .",
    "c * 88 * ( 2013 ) 021901 [ arxiv:1303.0913 [ hep - ph ] ] ."
  ],
  "abstract_text": [
    "<S> share with charm program ( sharev3 ) implements the statistical hadronization model description of particle production in relativistic heavy - ion collisions . given a set of statistical parameters , sharev3 program evaluates yields and therefore also ratios , and furthermore , statistical particle abundance fluctuations . </S>",
    "<S> the physical bulk properties of the particle source is evaluated based on all hadrons produced , including the fitted yields . </S>",
    "<S> the bulk properties can be prescribed as a fit input complementing and/or replacing the statistical parameters . </S>",
    "<S> the modifications and improvements in the share suite of programs are oriented towards recent and forthcoming lhc hadron production results including charm hadrons . </S>",
    "<S> this sharev3 release incorporates all features seen previously in sharev1.x and v2.x and , beyond , we include a complete treatment of charm hadrons and their decays , which further cascade and feed lighter hadron yields . </S>",
    "<S> this article is a complete and self - contained manual explaining and introducing both the conventional and the extended capabilities of share with charm . </S>",
    "<S> we complement the particle list derived from the particle data group tabulation  @xcite composed of up , down , strange @xmath0 quarks ( including resonances ) with hadrons containing charm @xmath1 quarks . </S>",
    "<S> we provide a table of the charm hadron decays including partial widths </S>",
    "<S> . the branching ratios of each charm hadron decays add to unity , which is achieved by including some charm hadron decay channels based on theoretical consideration in the absence of direct experimental information . </S>",
    "<S> a very successful interpretation of all available lhc results has been already obtained using this program .    </S>",
    "<S> statistical hadronization model , shm , quark - gluon plasma , qgp , strangeness production , charm production , hadron fluctuations , relativistic heavy - ion collisions , rhic , lhc    * new version program summary *    _ program title : _ share with charm + _ journal reference : _ </S>",
    "<S> + _ catalogue identifier : _ </S>",
    "<S> + _ licensing provisions : _ </S>",
    "<S> none + _ programming language : _ </S>",
    "<S> fortran77 , c++ + _ computer : _ pc , intel 64-bit , 3  gb ram ( not hardware dependent ) + _ operating system : _ gnu linux : ubuntu , debian , fedora ( not os dependent ) + _ ram : _ 615 mb + _ number of processors used : _ 1 ( single thread ) + _ keywords : _ share , statistical hadronization model , shm , quark - gluon plasma , qgp , strangeness production , charm production , hadron fluctuations , relativistic heavy - ion collisions , rhic , lhc + _ classification : _ 11.2 , 11.3 + _ external routines / libraries : _ standard c++ library , cernlib library + _ catalogue identifier of previous version : _ </S>",
    "<S> advdv20 + _ journal reference of previous version : _ comput.phys.commun . * 175 * ( 2006 ) 635 - 649 + _ does the new version supersede the previous version ? : _ </S>",
    "<S> yes + _ nature of problem : _ the understanding of hadron production incorporating the four @xmath2 quark flavors is essential for the understanding of the properties of quark  gluon plasma created in relativistic heavy - ion collisions in the large - hadron collider ( lhc ) energy domain . </S>",
    "<S> we describe hadron production by a hot fireball within the statistical hadronization model ( shm ) allowing for the chemical nonequilibrium of all quark flavors individually . by fitting particle abundances subject to bulk property constraints in the source </S>",
    "<S> , we find the best shm model parameters . </S>",
    "<S> this approach allows to test physical hypotheses regarding hadron production mechanisms in relativistic heavy - ion collisions , physical properties of the source at hadronization and the validity of the statistical hadronization model itself . </S>",
    "<S> the abundance of light hadrons made of @xmath3 , @xmath4 and @xmath5 constituent quarks  @xcite and their fluctuations  @xcite were the core physics contents of the prior releases sharev1.x and v2.x respectively . </S>",
    "<S> we now consider the hadronization of the heavier charm quarks , a phenomenon of relevance in the analysis of recent and forthcoming lhc results . </S>",
    "<S> we introduce bulk matter constraints such as a prescribed charge to baryon ratio originating in the initial state valance @xmath3 and @xmath4 quark content of colliding nuclei . </S>",
    "<S> more generally , all the bulk physical properties of the particle source such as energy , entropy , pressure , strangeness content and baryon number of the fireball at hadronization are evaluated and all of these can be used as fit constraints . </S>",
    "<S> the charm quark degree of freedom is handled as follows : given an input number of charm quark pairs at the time of charm chemical freeze - out , we populate charm hadron yield according to rules of statistical hadronization for a prescribed set of parameters associated with the particle source , such as bulk matter fugacities . </S>",
    "<S> a seperate charm hadronization temperature can be chosen and fitted , and as an option it is possible to make this temperature the same as the fitted hadronization temperature of @xmath0-quarks . </S>",
    "<S> charm hadron resonances decay feeding ` stable ' charm hadrons . </S>",
    "<S> these stable charm hadrons are so short - lived that within current technological detector capabilities practically all their decay products are feeding light hadron yields . </S>",
    "<S> these charm decay feeds are changing the abundances of produced hadrons in a pattern that differs from particle to particle . </S>",
    "<S> + _ solution method : _ share with charm builds in its approach upon the numerical method developed for its predecessor , share  @xcite for the evaluation of the distribution of light ( @xmath0 ) hadrons . share with charm distributes a prescribed number @xmath6 of charm @xmath7 quarks into individual charm hadrons applying statistical hadronization rules in a newly added computation module ` charm ' obtaining the yields evaluating appropriate series of bessel functions . similarly to light hadrons , the charm hadrons decays are evaluated using pre - existent tables derived from pdg listing  @xcite , proceeding from the heaviest to the lightest particle . </S>",
    "<S> the yields of each hadron are obtained using decay branching ratio tables of the mother particle yield  where data was not available , appropriate theoretical model was implemented to assure that all particles decayed with 100% probability . </S>",
    "<S> each of the resultant daughter hadron contributions is added to this @xmath0 hadron yield computed independently for the related set of shm parameters in the share module . </S>",
    "<S> the total yield is subsequently subject to the weak decays ( wd ) of strange hadrons . </S>",
    "<S> a user generated or default wd control file defines what portion of the @xmath0 particle yield decays weekly feeding other particles in turn , and which fraction given the detection capability is observed . </S>",
    "<S> once final observable hadron yields are so obtained , we compare these with the experimental data aiming in an iteration to find the best set of prescribed shm parameters for the yield of @xmath0 hadrons observed .. the charm module is associated with two new shm parameters , the charm hadronization temperature @xmath8 ( which can be defaulted to @xmath9 obtained for the other @xmath0 hadrons ) and the total yield of @xmath10 quarks , called ` ncbc ` . these and all other shm parameters are discussed in text . + _ </S>",
    "<S> reasons for the new version : _ * + since the release of sharev1 in 2004  @xcite and sharev2 in 2006  @xcite , heavy - ion collision experiments underwent major development in both detector technology and collision energy . </S>",
    "<S> the forthcoming tracker upgrade of star at bnl relativistic heavy ion collider ( rhic ) and the current tracking precision of alice at cern large hadron collider ( lhc ) require upgrades of the share program described below . in the anticipation of significant charm abundance at lhc , share with charm </S>",
    "<S> allows the study of all charm hadron production . </S>",
    "<S> charm hadron decays are particularly important because they are a significant source of multistrange hadrons . </S>",
    "<S> the introduction of charm component of the hadron spectrum into shm is crucial for correct interpretation of particle production and qgp fireball properties at hadronization in heavy - ion collisions at tev energy scale . </S>",
    "<S> share with charm is an easy - to - use program , which offers a common framework for shm analysis of all contemporary heavy - ion collision experiments for the coming years . </S>",
    "<S> + _ summary of revisions : _ * + the charm hadron mass spectrum and decays have been fully implemented in the provided program package . </S>",
    "<S> we provide a current up - to - date detailed list of charm hadrons and resonances together with their numerous decay channels within the set of fully updated input files that correspond to the present pdg status  @xcite . considering the enhanced tracking capabilities of lhc experiments and similar rhic capability , </S>",
    "<S> the default behavior of weak decay feed - down has been updated to not accept any weak feed - down unless specified otherwise by the user . </S>",
    "<S> the common framework for all contemporary heavy - ion experiments required an update of the format of the particle list and of the content to correspond to present day pdg . </S>",
    "<S> share with charm is backward compatible with the previous release , sharev2 , in terms of calculation capabilities and use of control files . </S>",
    "<S> however , share user may need to update and or add individual input file command lines in order to assure that same tasks are performed , considering that defaults , e.g. , characterizing weak decays , have been modified . furthermore quite a few interface improvements have been implemented and are described in detail further in this manual . </S>",
    "<S> they allow considerable simplification of control files . </S>",
    "<S> + _ running time : _ from a few seconds in case of calculating hadron yields and bulk properties given a prescribed set of model parameters , to @xmath11 hours in case of fitting all parameters to experimental data and calculation with finite widths . </S>",
    "<S> sample calculation provided in the program package , which demonstrates the program capabilities other than calculation with finite widths , took just under 2 hours on both 2.1 ghz cpu ( 2 mb l2 cache ) laptop and 2.5 ghz cpu ( 6 mb l2 cache ) cluster computing node . </S>",
    "<S> simple fit of model parameters to a data set ( provided as default in the package ) takes about 5 minutes . </S>",
    "<S> +    0 j.  beringer _ </S>",
    "<S> et al . _ </S>",
    "<S> [ particle data group collaboration ] , phys .  </S>",
    "<S> rev .  </S>",
    "<S> d * 86 * , 010001 ( 2012 ) .    </S>",
    "<S> g.  torrieri , s.  steinke , w.  broniowski , w.  florkowski , j.  letessier and j.  rafelski , comput .  </S>",
    "<S> phys .  </S>",
    "<S> commun .   * 167 * , 229 ( 2005 ) [ nucl - th/0404083 ] .    </S>",
    "<S> g.  torrieri , s.  jeon , j.  letessier and j.  rafelski , comput .  </S>",
    "<S> phys .  </S>",
    "<S> commun .   </S>",
    "<S> * 175 * , 635 ( 2006 ) [ nucl - th/0603026 ] . </S>"
  ]
}