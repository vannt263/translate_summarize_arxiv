{
  "article_text": [
    "due to their simplicity and intuitiveness , sketch - based interfaces have been popular for 3d shape retrieval .",
    "a standard approach is to turn the 2d-3d matching problem involved into a 2d-2d matching problem by first rendering every 3d repository model as 2d contours under multiple views and then matching the query sketch with every resulting contour .",
    "how to define effective features to represent both input sketches and 2d contours is a key challenge in sketch - based shape retrieval .",
    "we use 2d contours of models and model sketches interchangeably in the following discussion .",
    "various feature presentations ( e.g. , gist  @xcite , spherical harmonics  @xcite , eccentricity  @xcite ) have been proposed to represent both queries and model sketches _",
    "globally_. such global sketch representations are able to encode high - level shape information , but sensitive to intra - class variation and shape deformation . recently , bow representation  @xcite has been brought into the field to address this problem .",
    "this representation is based on the statistics of the local features , such as galif  @xcite and sift  @xcite , and it is proven more robust against the variations in the query and model sketches .",
    "however , approaches based on this representation may easily return locally similar but globally very different models ( figure  [ fig : motivation ] ) .",
    "this is because the local features are still defined at the pixel level , without leveraging any high - level semantics , such as the semantically meaningful _ parts _ in the sketch and the 3d models .",
    "part - level representations have been proven useful for object detection and recognition  @xcite in the computer vision community . however , existing sketch representations are still largely defined at the pixel level only . on the other hand , many techniques have been proposed to consistently decompose a set of 3d models into semantically meaningful parts  @xcite . in recent years",
    ", several techniques have also been developed to semantically segment freehand sketches , either automatically or interactively  @xcite .",
    "hence , it is interesting to explore if the use of semantic parts could lead to more discriminative sketch representations for retrieval .    in this paper , we present a new sketch representation , called _ pyramid - of - parts _",
    ", for sketch - based shape retrieval .",
    "our representation is derived from the available part - level information associated with the query sketch and the 3d repository models .",
    "we consider two ways of obtaining sketch segmentation information , manually specified and automatically obtained simply by assuming that each input stroke forms a semantic part . as the semantic segmentation of the query sketch and that of the 3d models might be different or at different levels of detail due to the multi - scale nature of objects ,",
    "we thus adapt the idea of image pyramids to encode semantic parts in a multi - scale manner .",
    "our retrieval algorithm will then compare the _ pyramid - of - parts _  of the input sketch with those of the 3d models across different scales and return the list of models ranked according to how well they match with the input sketch semantically .",
    "thanks to the _ pyramid - of - parts _ , our sketch - based shape retrieval technique outperforms the state - of - the - art techniques , which are based on either local descriptor  @xcite or global descriptor  @xcite , on two sketch datasets .",
    "we present a new sketching interface that supports the commonly used coarse - to - fine drawing practice and naturally provides semantically segmented sketches as query sketches .",
    "since our representation encodes spatial information of the query sketch , our technique often produces desired results even if only a subset of parts are depicted in a query sketch ( figure  [ fig : motivation2 ] ) and performs better than  @xcite in this task .",
    "we refer to this kind of matching based on incomplete input sketches as _ incomplete matching _ in this paper .",
    "* sketch - based shape retrieval . * this problem is often tackled by finding a repository model which rendered 2d contour ( i.e. , a silhouette rendering of the 3d model ) under a certain viewpoint best matches the query sketch .",
    "existing solutions mainly differ in the feature descriptors used to represent query / model sketches and can be largely categorized into two groups .",
    "the first group of approaches make use of global descriptors ( e.g. , @xcite ) to represent the sketch globally . however , global descriptors are sensitive to intra - class variations and shape deformation , which would bring global changes to the descriptors .",
    "global descriptors have difficulty in handling incomplete query sketches , as the missing information would also affect the global descriptors .",
    "the second group of approaches use statistics about local descriptors for sketch representation .",
    "for example , yoon et al .   represent sketches using statistics of their diffusion tensor fields , leading to a histogram of orientations .",
    "saavedra et al .",
    "represent a sketch by the hog feature of its `` key shape '' , which is an approximation of the contour with straight lines .",
    "eitz et al .",
    "adopt the bag - of - features ( bof ) model to represent a sketch as a histogram of visual words .",
    "these methods strike a balance between local and global features of 2d shapes , and are able to tolerate the inaccuracies inherent in sketches to some extent .",
    "however , since they discard spatial relationship among local descriptors , they often return unrelated shapes as similar ( figure  [ fig : motivation ] )",
    ". such spatial information of local descriptors can be captured by our proposed _ pyramid - of - parts _ , resulting in more discriminative power . moreover , there are some other methods ( e.g. , @xcite ) that directly align the query sketch to rendered model views to compute sketch - to - model distances .",
    "the main limitation of these approaches is that they usually suffer from the efficiency problem",
    ".    * sketch - based image retrieval . *",
    "sketch - based image retrieval has been under intensive research since 1990s , and many shape descriptors have been explored .",
    "( see  @xcite for a nice survey . ) among them , histograms of oriented gradients ( hog )  @xcite and shape context  @xcite have become very popular due to their simplicity , generality and discriminative power .",
    "the bof model can be built upon these local descriptors  @xcite , and the resulting feature is shown to be more tolerant to sketch variations .",
    "these shape descriptors can be extended to multi - scale , leading to , for example , multi - scale hog  @xcite and multi - sample bof  @xcite , where the sampled image patches do not have a fixed size .",
    "compared to these works , our multi - scale descriptor is defined over semantic parts in the sketch , rather than image patches which content might bear no semantic information .",
    "* part - based models .",
    "* in recent years , part - based models have been widely used in the computer vision community for the detection or recognition of objects in images . for example , felzenszwalb and huttenlocher present a pictorial structure model to encode the relationship among different body parts .",
    "more recently , felzenszwalb et al . introduce the deformable part model ( dpm ) , which is able to successfully identify complex objects .",
    "ferrari et al . proposes a @xmath0as feature for object detection , with each `` part '' constructed by linking @xmath0 roughly - straight adjacent contour segments .",
    "however , it is unclear how to apply these models designed for object detection to our shape retrieval problem",
    ".    * image pyramids . * since the pioneering works in  @xcite , pyramid methods have been extensively used for image analysis to capture the underlying patterns in multiple scales .",
    "for example , lazebnik et al .",
    "introduce the idea of spatial pyramid matching ( spm ) for natural scene categorization .",
    "spm uses features extracted in regions of different sizes , and organizes them into a spatial pyramid .",
    "this idea has been later extended and used in many applications , such as image classifications  @xcite , image matching  @xcite and 3d object recognition  @xcite .",
    "we also adopt this idea of spatial pyramid , since it is proven to be more effective than single - level approaches .",
    "however , unlike existing methods , which construct pyramids of pixels , our method constructs a pyramid of semantic parts .",
    "we assume that both the input query sketch and the 2d model contours have been pre - segmented into semantic parts . due to the multi - scale nature of objects , it is not uncommon that a query sketch and a model contour correspond to the same object but have different segmentations",
    ". it is thus important to know the scale of each part and compare parts only at the same scales .",
    "since each part does not have its corresponding label , it is challenging to form a semantically meaningful hierarchy of parts for matching .",
    "instead , we adapt the idea of image pyramids into our problem for part scale normalization .",
    "note that the query sketch and the model contours are both represented by pyramids of parts .",
    "the use of a common pyramid for both of them not only makes it possible to compare parts at the same scales but also capture the multi - scale nature of objects .",
    "although the following discussion focuses mainly on how we process input sketchs , model contours are processing in exactly the same way .",
    "* definition . * like image pyramids , a _ pyramid - of - parts _  consists of multiple scale levels , with each level containing groups of pre - segmented parts in the input sketch .",
    "each group of parts as a whole at the same level have similar scale , and upper levels have larger scales , as illustrated in figure  [ fig : grouping ] .          to generate a _ pyramid - of - parts _ , we associate each level with a set of regions in the sketch image .",
    "let @xmath1 denote a region at level @xmath2 .",
    "for example , @xmath3 , @xmath4 , @xmath5 are the nine regions at level 1 , as illustrated in figure  [ fig : grouping ] .",
    "each region corresponds to a group of parts .",
    "note that a region might be associated with zero ( e.g. , @xmath6 ) , one ( e.g. , @xmath7 ) or multiple parts ( e.g. , @xmath8 ) . parts associated with a region @xmath1 is considered as one group of parts at level @xmath2 .",
    "since groups of parts at upper levels are of larger scale , we require larger regions at upper levels .    the main criteria to determine if a part @xmath9 belongs to a region @xmath10 is to check whether @xmath9 is enclosed by @xmath10 or not .",
    "when @xmath9 is completely within @xmath10 ( e.g. , the leg part in @xmath11 in figure  [ fig : grouping ] ) , it is easy to conclude that @xmath9 should be in the group of parts associated with @xmath10 .",
    "however , the problem becomes tricky when @xmath9 covers multiple regions ( e.g. , the red arm in figure  [ fig : grouping ] covering @xmath12 and @xmath13 ) .",
    "some part may cover multiple regions at the current level mainly because it should belong to a region at an upper level .",
    "for example , the body part in figure  [ fig : grouping ] belongs to region @xmath14 , instead of @xmath13 , @xmath15 or @xmath16 .    with the above observations we determine if @xmath9 is assigned to @xmath10 by considering both the inclusion of @xmath9 inside @xmath10 and the relative size of @xmath9 to @xmath10 .",
    "specifically , we formulate the likelihood of @xmath9 belonging to @xmath10 as @xmath17 : @xmath18 where @xmath19 enforces penalty when the size of @xmath9 , denoted as @xmath20 and defined as the longer side of the bounding box of @xmath9 , is larger than @xmath21 . here",
    "@xmath22 is a parameter ( @xmath23 in our implementation ) and @xmath24 is the length of the longer size of @xmath10 . precisely , when @xmath25 , we set @xmath26 , corresponding to no penalty .",
    "otherwise , @xmath19 decreases as @xmath20 deviates from @xmath21 , which is computed as @xmath27 , and @xmath19 is clamped to 0 if it becomes negative .",
    "even if the size of @xmath9 is smaller than the size of @xmath10 , it is still possible that @xmath9 extrudes from @xmath10 , since @xmath9 is not necessarily centered at @xmath10 .",
    "we thus use @xmath28 to penalize the extrusion of @xmath9 from @xmath10 .",
    "let @xmath29 be the stroke length of @xmath9 , @xmath30 be the part of @xmath9 inside @xmath10 , and we have @xmath31 , which reaches the maximum when @xmath9 is completely inside @xmath10 .    in the end , @xmath9 is assigned to @xmath10 if @xmath32 . also , we compute a reliability value for each region to quantify the certainty of the assignments happened to this region , which in later stages is used to downplay those regions having many uncertain assignments of parts .",
    "let @xmath33 be the parts assigned to region @xmath10 , then the reliability of @xmath10 is computed as @xmath34 , where @xmath35 .",
    "each part will eventually get assigned to at least one region , because the topmost level region ( @xmath36 in figure  [ fig : grouping ] ) covers the entire image .      the _ pyramid - of - parts _",
    "feature is the concatenation of all the features extracted from all the regions . to begin with ,",
    "each of the regions in the pyramid is either empty or contains a group of parts . for empty regions ,",
    "their features are simply all zeros . for others ,",
    "their features are gabor features extracted from the groups of parts in them , as shown in figure  [ fig : gabor ] .",
    "a group is first placed in a bounding square , and then convolved with a set of gabor filters .",
    "each response is averaged by a grid ( figures  [ fig : gabor](c ) and  [ fig : gabor](d ) ) , and the outcome becomes part of the final feature ( figure  [ fig : gabor](e ) ) .",
    "the parameters of the gabor filters are different for each level of the pyramid , and is discussed in section  [ sec : experimentalsetting ] .",
    "our shape retrieval engine is built upon the _ pyramid - of - parts _",
    "feature , and the pipeline is shown in figure  [ fig : pipeline ] .",
    "as in @xcite , we take a 2d - to-2d matching approach , i.e. , matching the input sketch against all the views of all the models in database . to construct the database , we render each model for each selected view using suggestive contour  @xcite ( figure  [ fig : pipeline](b ) ) , and extract its _ pyramid - of - parts _  feature ( figures  [ fig : pipeline](d ) and  [ fig : pipeline](e ) ) . given a query sketch , its _ pyramid - of - parts _  feature will be extracted and matched against all the features in the database , after which the top matched models will be retrieved .",
    "the input query sketch consists of a set of strokes drawn by the user .",
    "the sketch is scaled such that a fixed - sized canvas ( of resolution @xmath37 in our implementation ) forms its bounding square . to extract the _ pyramid - of - parts _",
    "feature , segmentation of the sketch is required , which can be done automatically  @xcite or manually  @xcite . for maximum accuracy , here we opt for the manual approach , which is discussed in detail in section  [ sec : experimentalsetting ] .      to construct a 3d database ,",
    "we need a set of segmented 3d models .",
    "this database stores the _ pyramid - of - parts",
    "_  features of the 2d contours of each segmented models under a selected set of views .",
    "the procedure of computing the _ pyramid - of - parts _",
    "feature of a 3d model is shown in the second and third rows of figure  [ fig : pipeline ] .",
    "given a segmented 3d model , a 2d model contour is generated from a given view of the model using suggestive contours  @xcite , with the segmentation information transferred from the 3d model ( figure  [ fig : pipeline](b ) ) .",
    "the semantic parts are then processed into a _ pyramid - of - parts _  ( figure  [ fig : pipeline](c ) ) , which is used to produce the _ pyramid - of - parts _  feature ( figure  [ fig : pipeline](d ) ) following the procedures described in section  [ sec : feature ] .",
    "multiple views are used for each model , which are representative views generated using  @xcite .",
    "the view generation process starts by sampling many views uniformly distributed on the viewpoint sphere , among which 42 views covering most of the information given by the dense views are selected .      to retrieve a model , the _ pyramid - of - parts _",
    "feature of the sketch is compared with all the _ pyramid - of - parts _",
    "features in the database , and the @xmath38 nearest neighbors are returned as matches .",
    "the distance between two _ pyramid - of - parts",
    "_  features is the weighted sum of distances between the constituent gabor features in the corresponding regions .",
    "let @xmath39 be a _ pyramid - of - parts _",
    "feature , where @xmath40 is the gabor feature of region @xmath41 .",
    "( the level is not important here . )",
    "the distance of two features @xmath42 and @xmath43 is computed as : @xmath44 the weight @xmath45 is proportional to the product of region importance and reliability . for region @xmath41 ,",
    "the importance @xmath46 is set roughly proportional to the area of the region . in our 3-level implementation , and @xmath46 is set to 1 , 4 and 9 for regions at levels 1 , 2 and 3 , respectively .",
    "the reliability @xmath47 is the degree of certainty of assigning the semantic parts in @xmath41 to @xmath41 , as described in section  [ sec : grouping ] .",
    "given these quantities , the unnormalized weight @xmath48 , and the final weight @xmath49 .",
    "we have conducted four experiments , exp .  1 - 4 , to evaluate the performance of the proposed method .",
    "exp .  1 evaluates the performance when using different region subdivision strategies ( section  [ sec : regionsubdivision ] ) .",
    "exp .  2 evaluates the performance when using user - provided sketch segmentation information ( section  [ sec : fullcompare ] ) .",
    "exp .  3 evaluates the performance of a simple , automatic sketch segmentation strategy by grouping strokes ( section  [ sec : autoseg ] ) .",
    "finally , exp .  4 evaluates the performance on incomplete matching ( section  [ sec : incompletematching ] ) .",
    "* we have developed a prototype retrieval system , which we used to collect input sketches and evaluate the performance of the proposed method .",
    "the interface of the system allows users to draw three types of strokes : bounding box , segmentation and the query sketch .",
    "the user may draw these strokes in any order .",
    "the bounding box strokes represent a bounding box of the sketch , which is only useful for incomplete matching ( seciton  [ sec : incompletematching ] ) , where a bounded canvas is needed .",
    "the segmentation strokes are used to segment the query sketch into semantic parts .",
    "each segmentation stroke is a closed curve forming a _ zone _ , and each stroke of a query sketch is assigned to the zone that contains more than half of it .",
    "all the query sketch strokes assigned to one zone are assumed to form one semantic part .",
    "note that it is possible for one semantic part to lie completely within another ( e.g. , a human eye and head ) , and they can not be separated because the zone for the larger semantic part will contain that of the smaller one . in this case , a query sketch stroke will be assigned to the smaller zone only if more than half of the stroke is inside it . finally ,",
    "if there exists @xmath50 semantic parts , only @xmath51 zones are needed , and the strokes not belonging to any zone are assigned to a background zone , which also represents one semantic part .",
    "* 3d models dataset . *",
    "our 3d models come from the psb dataset  @xcite .",
    "this dataset contains 380 models in 19 categories .",
    "it contains segmentation results from different segmentation methods and we selected the segmentation results produced by randomized cut  @xcite .",
    "* sketch dataset . * with our prototype retrieval system , we collected a total of 428 complete sketches and 205 partial sketches ( see the supplemental ) .",
    "both full and partial sketches covered all 19 categories of the psb model dataset .",
    "10 users were invited to freely draw query sketches after we had shown them an example model from each category of the 3d dataset .",
    "users were asked to freely specify the segmentation strokes for their drawings .",
    "this sketch dataset is used in most of the experiments where segmentation is needed . to compare with",
    "@xcite fairly when sketch segmentation is not available , we use a subset of their sketch data , which includes 395 sketches , covering 10 of the psb model categories .",
    "other sketches used by  @xcite do not have a corresponding category in the psb model dataset and thus are discarded .",
    "* performance metrics . * to qualitatively evaluate the proposed method ,",
    "we have adopted four performance metrics : 1 ) precision - recall ; 2 ) top one ( to ) , which measures the precision of the top - one results , averaged over all queries ; 3 ) first tier ( ft ) , which measures the precision of the top @xmath50 results ( where @xmath50 is the number of ground - truth models relevant to the query ) , averaged over all queries ; and 4 ) mean average precision ( map ) , which summarizes the average precision of ranking lists for all queries .    * methods for comparison .",
    "* we mainly compared our framework with the popular bag - of - words framework ( denoted as @xmath52 )  @xcite , and the global feature based framework ( denoted as @xmath53 ) as used in  @xcite , which encodes the whole query sketch using a chosen shape descriptor ( galif in our case ) .",
    "our full method is denoted as @xmath54 .",
    "as all the methods use gabor filter somewhere , the parameters of the gabor filters for all of them in all the experiments are set to the same ( as described below ) .",
    "* parameters of the gabor filters .",
    "* gabor filters are used in all the methods compared , and the following parameters are shared among them : peak response frequency @xmath55 , frequency bandwidth @xmath56 , angular bandwidth @xmath57 , and the orientations @xmath58 are @xmath59 .",
    "the explanation of these parameters can be found in  @xcite . when averaging the gabor response ( figure  [ fig : gabor](d ) ) , the grid size needs specified . for our method , it is 2x2 , 4x4 and 6x6 for the image regions in levels 1 , 2 and 3 , respectively . for * gf * , it is 6x6 , same as the grid size used for the top - level image region in our method . for * bow * , it is 4x4 as in  @xcite .",
    "our method is based on _ pyramid - of - parts _  as illustrated in fig.[fig : pipeline ] .",
    "the default number of levels for the _ pyramid - of - parts _  is 3 and the subdivision of regions is as shown in figure  [ fig : grouping ] . in this experiment , we study the effect of using different subdivision schemes on our retrieval performance :    * without overlapping regions : we divide the sketch into four @xmath60 regions , where @xmath24 is the side length of the square region @xmath6 , as shown in figure  [ fig : evagrouping](a ) .",
    "this is denoted as @xmath61 . * using different ways of constructing level 2 regions : first , we divide the sketch into four different overlapped @xmath62 regions , as shown in figure  [ fig : evagrouping](b ) .",
    "this is denoted as @xmath63 .",
    "second , in addition to the original four regions shown in figure  [ fig : grouping](b ) , we add two new @xmath64 regions to level 2 as shown in figures  [ fig : evagrouping](c1 ) and  [ fig : evagrouping](c2 ) .",
    "this is denoted as @xmath65 . * using a different number of levels : first , we add one more level between the current levels 2 and 3 with four @xmath66 or @xmath67 regions to @xmath61 .",
    "this is denoted as @xmath68 .",
    "second , we remove one level ( level 2 ) from @xmath61 .",
    "this is denoted as @xmath69 .    in this experiment ,",
    "the region subdivision for levels 1 and 3 are fixed .",
    "figure  [ fig : groupingparampeferm ] compares the retrieval performances of the above four schemes .",
    "it shows that introducing region overlapping , adding more regions and adding more levels all help improve the performance .",
    "this is because these operations increase the amount of information in the resulting feature , improving its discriminative power .",
    "since the best performance is obtained using the scheme @xmath65 , we use it in later experiments .    ) ; ( b ) four regions with overlapping in level 2 ( i.e. , @xmath63 ) ; ( c1)(c2 ) two new regions added to level 2 ( i.e. , @xmath65 ) ; ( d ) regions of the new level added between levels 2 and 3 of ( i.e. , @xmath68 ) . ]          in this experiment , we compare our full method ( @xmath54 ) to the two competing methods , namely bag - of - words model ( @xmath52 ) and retrieval by global feature ( @xmath53 ) , over the 428 segmented sketches collected using our system .",
    "the results are shown in figure  [ fig : fullmethod ] as red , purple and black curves , respectively .",
    "we can see that our method ( @xmath54 ) has achieved the best retrieval performance on all four evaluation metrics .",
    "@xmath52  has achieved the second best average retrieval precision ( map ) , but its retrieval accuracies evaluated by to and ft are worse than those of @xmath53 .",
    "these results motivated us to investigate if it is the multi - scale nature of the _ pyramid - of - parts _ or the use of semantic parts that faciliates the better performance of @xmath54  over @xmath52  and @xmath53 .",
    "since our method adopts two main ideas , the multi - scale nature of the _ pyramid - of - parts _ or the use of semantic parts , we would like to understand how two ideas contribute to the overall retrieval performance .",
    "hence , we tested two approaches to evaluate the two ideas individually .",
    "the first approach ( denoted as @xmath70 ) skips the grouping stage , i.e. , removing the effect of multi - scale .",
    "however , as the sketches may contain different number of semantic parts , if we simply extract a gabor feature for each part , the final feature vectors will be of different lengths for different sketches , making them hard to compare .",
    "as such , to obtain a fixed - length feature vector , we still assign the semantic parts to image regions in one of the levels , but each semantic part is only assigned to one region ( the one having the highest assignment likelihood in eq .",
    "[ eq : grouping ] ) .",
    "after that , the process is the same as the full method .",
    "the second approach ( denoted as @xmath71 ) removes all the information about semantic parts but keeps the multi - scale process . to do that ,",
    "the sketch is rasterized into an image , and all segmentation information is discarded . in the grouping stage , the image patch bounded by each region is regarded as a part , which gabor feature is extracted to compose the final feature .",
    "the average retrieval performances of the two approaches on all the sketches are shown in figure  [ fig : fullmethod ] .",
    "we can see that @xmath71  performs only slightly better than @xmath53 , and @xmath70  performs much worst than @xmath53  and @xmath71 , while @xmath54  performs the best .",
    "this experiment shows that the combination of multi - scale and usage of semantic parts significantly improves the retrieval improvement than only using one of ideas . from our analyses of the results",
    ", we have also found that @xmath70  often performs better on sketches that are segmented into a small number of parts by the user , such as the lower diagram shown in figure  [ fig : motivation](a ) .",
    "the main reason is that with a small number of parts , the segmentation of the 3d models tends to correspond to the segmentation of the input sketches .        to further evaluate this point , we selected all the sketches which segmentation information provided by the users are largely consistent with that of the 3d models in the dataset .",
    "there are 96 such sketches in total .",
    "most of these sketches fall into three categories , `` cup '' , `` glass '' , and `` teddy bear '' , where the segmentation is less ambiguous .",
    "the retrieval results of these query sketches , as shown in figure  [ fig : rp2 ] , indicate that @xmath54  significantly outperforms the other methods , when the segmentation information of the input sketches is consistent with those of the 3d models .          in this experiment",
    ", we investigate how our method performs when segmentation information of the input query sketches is not available . a straightfoward approach to cope with",
    "this problem is to consider each stroke as a semantic part .",
    "this approach is denoted as @xmath72  and is evaluated here over the sketch dataset provided by  @xcite .",
    "the results are shown in figure  [ fig : pr3 ] .",
    "it is interesting to see that @xmath72  performs better than @xmath52  and @xmath53 .",
    "the reason is that users strokes tend to approximate the true segmentation to some extent .",
    "these results also indicate that @xmath54  can achieve higher performance even on sketches without user segmentation .          as the _",
    "pyramid - of - parts _",
    "feature is a collection of gabor features obtained from different image regions , it is possible to compare the _ pyramid - of - parts",
    "_  features of some local regions only .",
    "this characteristic of the _ pyramid - of - parts _",
    "feature suggests an interesting application , _ incomplete matching _",
    ", where a partially drawn query sketch can be used for model retrieval .",
    "note that incomplete matching is not exactly the same as partial matching . with partial matching",
    ", the input sketch can be matched any local region of a database model . with incomplete matching ,",
    "we may make use the location information of the drawn strokes relative to the canvas ( or the user provided bounding box ) so that the matching can be localized .    here",
    ", it may be interesting to compare our method with @xcite .",
    "although @xcite can also be used for incomplete matching , as their method computes some global statistics of local features , the comparison itself is therefore global , i.e. , comparing the global statistics of an incomplete input sketch with those of the 2d model contour of a database model . on the contrary , with our method",
    ", we may simply skip the comparison of the gabor features of those regions with no semantic parts in them .    to evaluate the performance of our method for incomplete matching , we have performed an experiment on incomplete matching .",
    "we collected 205 partial sketches covering all 19 categories of the psb model dataset .",
    "the methods for comparison include our full method ( i.e. , @xmath54 ) , our method without user segmentation but considering each stroke as a part ( i.e. , @xmath72 ) , bag - of - words model  @xcite ( i.e. , @xmath52 ) and retrieval using global features ( i.e. , @xmath53 ) . figure  [ fig : pmresult ] compares the retrieval performances of the above methods .",
    "our method outperforms the existing methods whether the segmentation information is obtained manually or automatically .",
    "this is mainly because the competing methods do not support localized matching , and they are matching the incomplete sketch to the complete model contours of the models .",
    "in this paper , we have investigated the use of semantic segmentation information to improve the performance of sketch - based 3d shape retrieval .",
    "we proposed the _ pyramid - of - parts _ to support multi - scale matching of semantic parts . with the proposed method",
    ", we have evaluated the retrieval performances with and without user - provided segmentation information .",
    "our experimental results show that the proposed method performs better than the state - of - the - art method by  @xcite in both situations .",
    "we have also compared the two methods with incomplete input sketches .",
    "our experimental results show that the proposed method performs significantly better than  @xcite ."
  ],
  "abstract_text": [
    "<S> we present a multi - scale approach to sketch - based shape retrieval . </S>",
    "<S> it is based on a novel multi - scale shape descriptor called _ pyramid - of - parts _ , which encodes the features and spatial relationship of the semantic parts of query sketches . </S>",
    "<S> the same descriptor can also be used to represent 2d projected views of 3d shapes , allowing effective matching of query sketches with 3d shapes across multiple scales . </S>",
    "<S> experimental results show that the proposed method outperforms the state - of - the - art method , whether the sketch segmentation information is obtained manually or automatically by considering each stroke as a semantic part . </S>"
  ]
}