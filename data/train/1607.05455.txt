{
  "article_text": [
    "high dimensional multivariate data is becoming increasingly prevalent , with the estimation of the covariance matrix for such data sets being an important fundamental problem .",
    "the classical estimator , i.e.  the sample covariance matrix , though , is known to be highly non - robust under longer tailed alternatives to the multivariate normal distribution , as well as being highly non - resistant to outliers in the data .",
    "consequently , there have been numerous proposals for robust alternatives to the sample covariance matrix , with one of the earliest alternatives being the @xmath0-estimators of multivariate scatter @xcite . as with the multivariate @xmath0-estimators of scatter , most of the subsequent proposals for robust estimators of multivariate scatter are affine equivariant . however , for sparse multivariate data , that is when the sample size @xmath1 is less than or not much larger than the dimension of the data @xmath2 , such estimators of scatter do not differ greatly from the sample covariance matrix , and for the case @xmath3 , they are simply proportional to the sample covariance , see @xcite .",
    "even when the distribution is normal and there are no outliers in the data set , the sample covariance matrix can still be unreliable for sparse data sets due to the large number of parameters being estimated , namely @xmath4 .",
    "consequently , one may wish to model the covariance matrix using less parameters , or one may wish to give preference to certain covariance structures and pull the estimator towards such structures via penalization or regularization techniques .",
    "traditionally , research on robust estimators of multivariate scatter have not taken these concerns into account , and the statistics literature has focused primarily on the unrestricted robust estimation of the scatter matrix . within the signal processing community ,",
    "though , there has been an increasing interest in the @xmath0-estimators of multivariate scatter @xcite and more recently an interest in developing regularized versions of them @xcite . an important mathematical contribution arising from the area of signal processing",
    "is the realization in @xcite that treating the multivariate scatter matrices as elements in a riemannian manifold and using the notion of geodesic convexity can be very useful , leading to elegant theory as well as new results .",
    "these concepts had been applied previously within the statistics literature @xcite , but only for the specific case of the distribution free @xmath0-estimator of multivariate scatter .",
    "more recently they have been used in @xcite and implicitly in the survey paper @xcite on @xmath0-functionals of multivariate scatter .",
    "the purpose of the present paper is threefold .",
    "we first review the standard riemannian geometry on the space of symmetric positive definite matrices and the notion of geodesic convexity in section  [ sec : g - convexity ] .",
    "in particular we introduce and utilize first and second order taylor expansions of such functions with respect to geodesic parametrizations .",
    "such expansions allow us to introduce sufficient conditions for a function to be geodesically convex .",
    "in addition we introduce the concept of geodesic coercivity , which is important in establishing the existence of both the @xmath0-estimators of scatter and their regularized versions . as in classical convex analysis , a real valued function on the space of symmetric positive definite matrices which is continuous , strictly geodesically convex and coercive has a unique minimizer .",
    "our second contribution is a general analysis of regularized @xmath0-estimators of multivariate scatter with respect to geodesic convexity and coercivity in section  [ sec : regularized.scatter ] .",
    "our starting point are results of @xcite and @xcite which show that the log - likelihood type functions underlying @xmath0-estimators of multivariate scatter are geodesically convex under rather general conditions .",
    "we show that various penalty functions favoring matrices which are close to the identity matrix or to multiples of the identity matrix are geodesically convex .",
    "this leads to a rather complete picture concerning existence and uniqueness of regularized @xmath0-functionals of scatter .",
    "it also provides new results on regularized sample covariance matrices when using penalty functions which are geodesically convex but not convex in the inverse of the covariance matrix .",
    "furthermore , we propose a cross - validation method for choosing a scaling parameter for the penalty function .",
    "finally , we present a general partial newton algorithm to minimize a smooth and strictly geodesically convex function in section  [ sec : algorithm ] .",
    "this algorithm is a generalization of the partial newton method of @xcite with guaranteed convergence .",
    "we illustrate this method with a numerical example in section  [ sec : example ] .",
    "all proofs and some auxiliary results are deferred to section  [ sec : proofs ] and to a supplement [ sec : auxiliary ] .",
    "we begin with some notation and a brief background review .",
    "let the space of symmetric matrices in @xmath5 be denoted by @xmath6 , and let @xmath7 stand for its subset of positive definite matrices , i.e.  symmetric matrices with eigenvalues in @xmath8 . for a distribution @xmath9 on @xmath10 with given center @xmath11 and a function @xmath12 , an @xmath0-functional of multivariate scatter can be defined as a matrix which minimizes the objective function @xmath13 \\ ,",
    "q(dx )          + \\log \\det(\\sigma)\\ ] ] over @xmath14 .",
    "when @xmath15 represents an empirical distribution , then the minimizer defines an @xmath0-estimator of scatter , and the objective function can be viewed as a generalization of the negative log - likelihood function arising from an elliptical distribution @xcite .",
    "the term @xmath16 is not needed when working with empirical distributions . in general , though , this term allows us to be able to consider distributions @xmath9 for which @xmath17 .    for continuous @xmath18 with sill @xmath19 , defined below , a minimizer @xmath14 to @xmath20",
    "is known to exist , provided no subspace contains too may data points , or specifically if the following condition holds for @xmath21 @xcite .",
    "[ [ condition1 . ] ] condition  1 .",
    "+ + + + + + + + + + + +    for all linear subspaces @xmath22 with @xmath23 , @xmath24 where @xmath25 .",
    "( note that the function @xmath18 in the present paper corresponds to @xmath26 in @xcite and other publications . )",
    "if @xmath18 is differentiable , then the critical points , and hence any minimizer , of satisfy the @xmath0-estimating equations @xmath27 where @xmath28 .",
    "furthermore , if we define @xmath29 , then the sill @xmath30 equals the limit @xmath31 whenever the latter exists .    to assure the uniqueness of a minimizer to @xmath20 or a unique solution to the @xmath0-estimating equations , further conditions on the function @xmath18 are needed .",
    "it has been know since the introduction of the @xmath0-estimators of scatter @xcite that one such sufficient condition is the following .",
    "[ [ condition2 . ] ] condition  2 .",
    "+ + + + + + + + + + + +    the function @xmath18 is differentiable , with @xmath32 being non - increasing and @xmath33 being non - decreasing and strictly increasing for @xmath34 .",
    "the proof of uniqueness given in @xcite assumes more restrictive conditions on the distribution @xmath9 than that given by condition  1 , although it is shown in @xcite that conditions  1 and 2 are sufficient for the existence of a unique solution to , i.e.  for the existence and uniqueness of the @xmath0-estimator of scatter .",
    "some common examples of @xmath0-estimators satisfying condition  2 are huber s @xmath0-estimator for which @xmath35 with tuning constants @xmath36 and @xmath37 , and the maximum likelihood estimators derived from an elliptical t - distribution on @xmath38 degrees of freedom , for which @xmath39 .",
    "the above conditions lack some intuition as to why has a unique minimum .",
    "the proofs of uniqueness given in @xcite are based on a study of the @xmath0-estimating equations .",
    "recall that for the classical case when @xmath20 corresponds to the negative log - likelihood under a @xmath2-dimensional normal distribution with mean zero and covariance @xmath40 , i.e.  when @xmath41 , then @xmath20 is strictly convex in @xmath42 and hence has a unique minimizer , namely the sample covariance matrix .",
    "for general @xmath18 , however , @xmath20 tends not to be convex in @xmath42 .",
    "important insight into the function @xmath20 has recently been given within the area of signal processing .",
    "in particular , it is shown in @xcite that if the function @xmath43 is convex in @xmath44 , then @xmath20 is geodesically convex in @xmath14 , and that if the function @xmath43 is strictly convex in @xmath44 , then @xmath20 is strictly geodesically convex in @xmath14 provided the data span @xmath10 .",
    "consequently , when condition  1 holds , then the minimizer set for @xmath20 is a geodesically convex set when @xmath43 is convex , and the minimizer is unique when @xmath43 is strictly convex . the results on geodesic convexity , or g - convexity , not only give a mathematically elegant insight into uniqueness , but they also yield more general results .",
    "for example , @xmath45 need not be differentiable . also , when @xmath45 is differentiable , then @xmath43 is ( strictly ) convex in @xmath44 if and only if @xmath33 is ( strictly ) increasing , with no additional conditions on @xmath32 being needed , i.e. @xmath32 need not be non - increasing .",
    "the notion of g - convexity also allows for the development of new results regarding minimizing @xmath46 over a g - convex subset of @xmath7 , as well as minimizing a penalized objective function when the penalty function is also g - convex . before addressing these problems , though",
    ", we provide a thorough review and present some new results on the notion of geodesic convexity .",
    "note that our objective function assumes @xmath11 to be the center of the distribution @xmath9 . in various applications in signal",
    "processing the center of @xmath9 is often known or hypothesized , and consequently all the aforementioned signal processing references presume a known center . in more traditional location - scatter problems , one could embed the location - scatter problem in dimension @xmath2 into a scatter - only problem in dimension @xmath47 as explained in @xcite .",
    "but regularization in this setting is less clear .",
    "if the location parameter is merely a nuisance parameter , then one can first center the data using an auxiliary estimate of location .",
    "alternatively , the location parameter can be removed by symmetrization , i.e.  instead of @xmath9 one considers the symmetrized distribution @xmath48 with independent random vectors @xmath49 ; see @xcite for further details .",
    "we collect a few basic ideas about positive definite matrices and their geometry . for a full treatment",
    "we refer to @xcite .",
    "the euclidean norm of a vector @xmath50 is denoted by @xmath51 . for matrices",
    "@xmath52 with identical dimensions we write @xmath53 so @xmath54 is the frobenius norm of @xmath0 .",
    "equipped with this inner product @xmath55 and norm @xmath56 , the matrix space @xmath6 is a euclidean space of dimension @xmath4 , and @xmath7 is an open subset thereof .",
    "but in the context of scatter estimation an alternative geometry turns out to be useful .",
    "let @xmath57 be the sample covariance matrix of independent random vectors @xmath58 with distribution @xmath59 with @xmath60 and @xmath14 .",
    "it is well known that @xmath61 with the identity matrix @xmath62 and a random matrix @xmath63 .",
    "the distribution of @xmath64 depends only on @xmath1 and is invariant under transformations @xmath65 with @xmath66 , the set of orthogonal matrices in @xmath67 .",
    "moreover , @xmath68 as @xmath69 .",
    "thus one could measure the distance between @xmath57 and @xmath40 by @xmath70 with the local norm @xmath71 corresponding to the local inner product @xmath72 of matrices @xmath73 .    to define a distance between two arbitrary matrices @xmath74 , we consider a smooth path @xmath0 connecting them .",
    "that means , @xmath75 \\to { { \\mathbb{r}}_{{\\rm sym},+}^{q\\times q}}$ ] is piecewise continuously differentiable with @xmath76 and @xmath77 .",
    "then we define the length of @xmath0 to be @xmath78 denoting with @xmath79 the set of nonsingular matrices in @xmath67 , one can easily verify that for any @xmath80 , the new path @xmath81 connects the matrices @xmath82 and @xmath83 and has length @xmath84 here is a well - known key result about shortest paths in @xmath7 . for the reader",
    "s convenience we provide a self - contained proof in supplement  [ sec : auxiliary ] .",
    "[ thm : geodesics ] let @xmath75 \\to { { \\mathbb{r}}_{{\\rm sym},+}^{q\\times q}}$ ] be a path connecting @xmath76 and @xmath77 .",
    "then @xmath85 with equality if , and only if , @xmath86 for some non - decreasing , piecewise continuously differentiable function @xmath87 \\to { \\mathbb{r}}$ ] with @xmath88 and @xmath89 .",
    "note that for a shortest path @xmath0 , its track @xmath90\\}$ ] does not depend on the function @xmath91 but is equal to @xmath92\\}$ ] with the special path @xmath93 \\to { { \\mathbb{r}}_{{\\rm sym},+}^{q\\times q}}$ ] given by @xmath94 .",
    "indeed @xmath95 , and the path @xmath96 has constant geodesic speed in the sense that for all @xmath97 $ ] , @xmath98    the preceding considerations involve matrix powers and logarithms . in general , a real valued function @xmath99 can be extended to a matrix - valued function @xmath100 in the following manner : let @xmath101 have spectral decomposition @xmath102 with a matrix @xmath66 of orthonormal eigenvectors of @xmath103 and a diagonal matrix @xmath104 with diagonal elements given by @xmath105 , then @xmath106 using the convention @xmath107 . if @xmath108 is defined only on @xmath109 , then we restrict @xmath103 to @xmath7 and obtain a matrix - valued function @xmath110 .",
    "so , for @xmath111 , @xmath112 and @xmath113 also , for @xmath101 , @xmath114 this is consistent with the more general definition of a matrix exponential @xmath115 which is defined for any arbitrary matrix @xmath116 .",
    "analogous to the real setting , @xmath117 is a bijection with inverse mapping @xmath118 . for @xmath119 , @xmath120",
    "hence theorem  [ thm : geodesics ] shows that a shortest path between two matrices @xmath74 is given by @xmath121 .\\ ] ] sometimes it is convenient to consider other factorizations of @xmath122 , i.e.  other square roots . if we write @xmath123 for some @xmath80 , then @xmath124 and @xmath125 .",
    "the function @xmath126 does not depend on the particular choice for @xmath127 since @xmath128 for some @xmath129 .",
    "in particular , let @xmath130 with @xmath129 and @xmath131 containing the eigenvalues of @xmath132 . then @xmath123 and @xmath133 with @xmath128 .",
    "for this choice and @xmath134 we obtain the expression @xmath135 which leads to a simple interpretation of the geodesic path from @xmath122 to @xmath136 .",
    "namely , after jointly diagonalizing @xmath122 and @xmath136 , the geodesic path corresponds to the linear path connecting the logs of the diagonal elements .",
    "[ lem : geodesic.curves ] let @xmath127 be an arbitrary matrix in @xmath79",
    ". for @xmath101 and @xmath137 let @xmath138 this defines a geodesic curve in the following sense : for arbitrary different numbers @xmath139 , a shortest path connecting @xmath140 and @xmath141 is given by @xmath142 \\ni u \\ \\mapsto \\ \\sigma((1 - u ) t_0 + u t_1 ) .\\ ] ] for @xmath143 let @xmath144 this defines a @xmath2-dimensional geodesic surface in the following sense : for arbitrary @xmath145 , a shortest path connecting @xmath146 and @xmath147 is given by @xmath142 \\ni",
    "u \\ \\mapsto \\ b d \\bigl ( \\exp((1 - u ) x_0 + u x_1 ) \\bigr ) b^\\top .\\ ] ]    [ [ local - geodesic - parametrizations . ] ] local geodesic parametrizations .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    closely related to the geodesic paths just described are the following local parametrizations of subsets of @xmath7 .",
    "for any matrix @xmath148 with @xmath80 one may write @xmath149 these parametrizations are particularly useful in connection with first and second order taylor expansions of smooth functions on @xmath7 .",
    "[ def : g - convex.sets ] a subset @xmath150 of @xmath7 is called _ geodesically convex _ ( _ g - convex _ ) if for arbitrary @xmath151 the whole geodesic path connecting them is contained in @xmath150 .",
    "that means , for @xmath152 , @xmath153 in other words , for arbitrary @xmath80 and @xmath101 such that both @xmath154 and @xmath155 belong to @xmath150 , @xmath156    [ [ examples . ] ] examples .",
    "+ + + + + + + + +    lemma  [ lem : geodesic.curves ] implies that for arbitrary @xmath80 the following sets are g - convex : @xmath157 with @xmath101 and an interval @xmath158 , and @xmath159 with a convex set @xmath160 . moreover , for any number @xmath36 , the set @xmath161 is easily shown to be g - convex .",
    "[ [ geodesic - distance . ] ] geodesic distance .",
    "+ + + + + + + + + + + + + + + + + +    the geodesic distance between two matrices @xmath74 is defined to be the length of the geodesic path connecting them , i.e. @xmath162 if , as in , we express @xmath123 and @xmath163 , then @xmath164 obviously @xmath165 with equality if , and only if , @xmath166 which is equivalent to @xmath167 . the interpretation of @xmath168 as the length of a shortest path between @xmath122 and @xmath136 implies that @xmath169 is a metric on @xmath7 . as to symmetry , @xmath170 , because any path @xmath0 from @xmath122 and @xmath136 defines a path @xmath171 from @xmath136 to @xmath122 such that @xmath172 . as to the triangle inequality , for a third matrix @xmath173 let @xmath174 be a shortest path from @xmath122 to @xmath136 and let @xmath175 be a shortest path from @xmath136 to @xmath176 .",
    "then @xmath177 defines a path from @xmath122 to @xmath176 such that @xmath178 .",
    "thus @xmath179 .",
    "tow additional facts are that @xmath180 the first equality follows from the fact that any path @xmath0 from @xmath122 to @xmath136 gives rise to the path @xmath181 from @xmath182 to @xmath183 with @xmath184 .",
    "moreover , one can easily verify that @xmath185 defines a path from @xmath186 to @xmath187 with @xmath172 .",
    "[ [ matrices - with - determinant - one . ] ] matrices with determinant one .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in connection with scale - invariant functionals , the submanifold @xmath188 of @xmath7 plays a prominent role .",
    "note that any @xmath189 may be represented as @xmath148 with @xmath190 satisfying @xmath191 , and then @xmath192 with the linear subspace @xmath193 of @xmath6 .",
    "an arbitrary matrix @xmath14 may be written as @xmath194 with @xmath195 and @xmath196 .",
    "then indeed @xmath197 this follows from a more general observation : let @xmath74 be written as @xmath198 with @xmath199 and @xmath200 . then @xmath201 and it follows from @xmath202 that @xmath203      [ def : g - convex.functions ] let @xmath204 be g - convex .",
    "a function @xmath205 is called _ geodesically convex _ ( _ g - convex _ ) if for arbitrary matrices @xmath206 and @xmath207 , @xmath208 where @xmath209 is defined as in definition  [ def : g - convex.sets ] . if the preceding inequality is strict whenever @xmath210 , the function @xmath211 is called _ strictly geodesically convex _ ( _ strictly g - convex _ ) .",
    "equivalently , @xmath205 is ( strictly ) g - convex if for arbitrary @xmath80 and @xmath212 such that both @xmath154 and @xmath213 belong to @xmath150 , @xmath214 .\\ ] ]    [ ex0 ] the function @xmath215 is geodesically convex on @xmath7 .",
    "it is even geodesically linear in the sense that @xmath216 for arbitrary @xmath80 and @xmath101 .    by means of lemma  [ lem :",
    "geodesic.curves ] one can easily derive the following result .    [",
    "lem : criteria.g - convexity ] for a function @xmath217 the following three properties are equivalent :    * ( a ) *  @xmath211 is ( strictly ) geodesically convex ;    * ( b ) *  for arbitrary @xmath80 and @xmath212 , the function @xmath218 is ( strictly ) convex ;    * ( b ) *  for arbitrary @xmath80 and @xmath219 , the function @xmath220 is ( strictly ) convex ;    * ( c ) *  for arbitrary @xmath80 , the function @xmath221 is ( strictly ) convex .",
    "obviously , property  ( b ) is a special case of property  ( b ) , because @xmath222 . on the other hand",
    "we may write @xmath212 as @xmath223 for some @xmath66 and @xmath219",
    ". then @xmath224 , whence property  ( b ) implies property  ( b ) .",
    "[ ex1 ] for any vector @xmath225 , the function @xmath226 is g - convex , and the function @xmath227 is strictly g - convex . to verify these claims we use criterion ( c ) in lemma  [ lem : criteria.g - convexity ] : for @xmath80 and @xmath143 , @xmath228 is obviously convex in @xmath229 , because @xmath230 is convex .",
    "similarly , @xmath231 this is even strictly convex in @xmath229 , because @xmath230 is strictly convex and all weights @xmath232 are strictly positive .",
    "[ exlog ] for any vector @xmath225 , the function @xmath233 is g - convex . to verify this claim we use criterion ( b ) in lemma  [ lem : criteria.g - convexity ] : for @xmath80 , @xmath219 , and @xmath137 , @xmath234 with @xmath235",
    "evaluating its second derivative gives @xmath236 and so by application of the cauchy schwartz inequality @xmath237 , with equality if and only if all the @xmath238 s are equal for those @xmath239 for which @xmath240 .",
    "furthermore , suppose that @xmath241 is g - convex , which is equivalent to @xmath242 being convex in @xmath137 , and that @xmath18 is non - decreasing .",
    "then the function @xmath243 is g - convex .",
    "this follows by expressing @xmath244 with @xmath245 and then applying the two remarks given below .",
    "[ rem : inversion ] if @xmath217 is geodesically convex , then @xmath246 defines a geodesically convex function , too .",
    "this follows essentially from the fact that @xmath247 with @xmath248 and @xmath249 .",
    "[ rem : transformation ] let @xmath217 be geodesically convex with values in an interval @xmath158 , and let @xmath250 be convex and non - decreasing .",
    "then @xmath251 defines a geodesically convex function , too . for if @xmath252 as in definition  [ def : g - convex.sets ] , then @xmath253 the function @xmath254 is even strictly g - convex if @xmath211 is strictly g - convex and @xmath108 is strictly increasing .",
    "suppose we want to minimize a g - convex function @xmath217 . as in classical convex analysis",
    ", a minimizer of @xmath211 may be characterized by means of the one - sided directional derivatives @xmath255 for @xmath80 and @xmath101 .",
    "the latter limit exists in @xmath256 , because g - convexity of @xmath211 implies convexity of @xmath257 in @xmath137 .",
    "[ lem : minimizer.g - convex ] a matrix @xmath148 with @xmath80 minimizes a g - convex function @xmath258 if , and only if , @xmath259    this lemma provides an explicit criterion to check whether a certain point @xmath40 is a minimizer of a differentiable and g - convex function on @xmath7 .",
    "but it is not clear under what conditions a minimizer has to exist . in this context a key property of @xmath211 is coercivity in the following sense .",
    "a function @xmath217 is called _ geodesically coercive _ ( _ g - coercive _ ) if @xmath260    in other words , a function @xmath217 is g - coercive if , and only if , the function @xmath261 is coercive in the usual sense , that is , @xmath262 as @xmath263 .    note that @xmath264 is equivalent to @xmath265 .",
    "various authors have realized that any continuous function @xmath211 on @xmath7 with the latter property has a compact set of minimizers , e.g.  @xcite .",
    "the following lemma and its corollary explain the relation between g - coercivity and the existence of minimizers in case of g - convex functions .",
    "in particular , the corollary shows that a continuous and strictly g - convex function has a unique minimizer if , and only if , it is g - coercive .",
    "[ lem : existence.minimizers ] let @xmath217 be a continuous and geodesically convex function .    *",
    "( i ) *  the set @xmath266 of its minimizers is a closed and geodesically convex subset of @xmath7 .",
    "it is possibly empty .    *",
    "( ii ) *  if @xmath211 is g - coercive , then @xmath266 is nonvoid and compact .    *",
    "( iii ) *  if @xmath211 fails to be g - coercive but @xmath266 is nonvoid , then @xmath266 is geodesically unbounded , that means , @xmath267    [ cor : uniqueness.minimizer ] let @xmath217 be a continuous and strictly geodesically convex function .    *",
    "( i ) *  if @xmath211 is g - coercive , it has a unique minimizer .    *",
    "( ii ) *  if @xmath211 fails to be g - coercive , it has no minimizer at all .",
    "corollary  [ cor : uniqueness.minimizer ] follows easily from lemma  [ lem : existence.minimizers ] .",
    "note that a strictly g - convex function @xmath211 can have at most one minimizer . for",
    "if @xmath268 are two different matrices with @xmath269 , then @xmath211 attains strictly smaller values along the geodesic path connecting @xmath122 and @xmath136 .",
    "since a geodesically unbounded set is necessarily infinite , a continuous and strictly g - convex function which is not g - coercive can not have a minimizer .",
    "the next lemma provides an equivalent characterization for g - coercivity :    [ lem : g - coercivity ] let @xmath217 be continuous and geodesically convex . then @xmath211 is geodesically coercive if , and only if , for any fixed @xmath212 , @xmath270      the next lemma establishes a connection between differentiability in the usual sense and differentiability with respect to local geodesic coordinates .",
    "[ lem : smoothness1 ] for a function @xmath217 the following two conditions are equivalent :    * ( s1.i ) *  @xmath211 is differentiable with gradient @xmath271 .    *",
    "( s1.ii ) *  for each @xmath80 there exists a matrix @xmath272 such that for @xmath101 , @xmath273    in case of ( s1.i - ii ) , @xmath274    in particular , a function @xmath217 is continuously differentiable if , and only if , its `` geodesic gradient ( g - gradient ) '' @xmath275 is continuous in @xmath276 .",
    "it is well - known from convex analysis that a differentiable convex function @xmath211 on @xmath277 is minimal at a certain point @xmath278 if , and only if , @xmath279 . the same is true for differentiable g - convex functions :    [ cor : minimizers.g - convex ] let @xmath217 be differentiable and geodesically convex .",
    "then for @xmath148 , @xmath80 , the following three conditions are equivalent :    * ( a ) *  @xmath40 is a minimizer of @xmath211 ;    * ( b ) *  @xmath280 ;    * ( b ) *  @xmath281 .",
    "this corollary follows directly from lemmas  [ lem : minimizer.g - convex ] and [ lem : smoothness1 ] , noting that @xmath282 for @xmath101 and @xmath80 .",
    "moreover , for different real numbers @xmath283 and @xmath284 , @xmath285 as @xmath286 .",
    "hence for differentiable and g - convex functions @xmath211 the criterion for g - coercivity in lemma  [ lem : g - coercivity ] can be reformulated as follows :    [ cor : g - coercivity ] let @xmath217 be differentiable and geodesically convex . then @xmath211 is geodesically coercive if , and only if , for any fixed @xmath212 , @xmath287 which is equivalent to @xmath288      verifying g - convexity of a function @xmath211 on @xmath7 is not trivial .",
    "many authors use direct calculations case by case @xcite or use advanced matrix inequalities @xcite .",
    "convexity of functions can be easily characterized in terms of second derivatives .",
    "the same is true for g - convexity if one uses local geodesic coordinates .",
    "[ lem : g - convexity ] let @xmath217 satisfy the following condition : for each @xmath80 there exist a matrix @xmath272 and a quadratic form @xmath289 on @xmath6 such that for @xmath101 , @xmath290 then the function @xmath211 is geodesically convex if , and only if , @xmath291 it is strictly geodesically convex if @xmath292    [ ex2 ] the function @xmath293 is geodesically convex . for if @xmath80 and @xmath101 , then @xmath294 as @xmath295 , so @xmath296 obviously , @xmath297 . but @xmath298 for all @xmath299 . to show this",
    "let @xmath223 with @xmath66 and @xmath143 .",
    "then for any integer @xmath300 , @xmath301 with @xmath302",
    ". consequently , @xmath303 unless @xmath304 .",
    "but the latter condition would be equivalent to @xmath103 being a multiple of the identity matrix .",
    "[ rem : inversion2 ] suppose that @xmath217 satisfies the second order smoothness assumption in lemma  [ lem : g - convexity ] .",
    "then @xmath246 satisfies this assumption , too : for any @xmath80 , as @xmath305 , @xmath306 with @xmath307    [ rem : transformation2 ] suppose that a function @xmath217 satisfies the second order smoothness assumption in lemma  [ lem : g - convexity ] . for @xmath36",
    "let @xmath308 then for any @xmath80 , as @xmath305 , @xmath309 with @xmath310 similarly , if @xmath311 and @xmath312 for @xmath313 , then @xmath314 with @xmath315    [ rem : orthogonal transformations ] for matrices @xmath316 , the equation @xmath317 is equivalent to @xmath318 for some orthogonal matrix @xmath319 . for any function @xmath217 satisfying the second order smoothness assumption in lemma  [ lem : g - convexity ] , @xmath320 in particular , neither the eigenvalues of @xmath275 nor the set @xmath321 change when @xmath127 is replaced with @xmath322 .    the equations for @xmath323 and @xmath324 follow from the fact that @xmath325 .",
    "thus @xmath326 coincides with @xmath327    as explained in supplement  [ sec : auxiliary ] , existence of second order taylor expansions alone does not imply twice differentiability .",
    "but this is true under an additional continuity requirement on the quadratic terms .",
    "[ lem : smoothness2 ] for a function @xmath217 the following two conditions are equivalent :    * ( s2.i ) *  @xmath211 is twice continuously differentiable with gradient @xmath328 and hessian operator @xmath329 at @xmath14 .    * ( s2.ii ) *  for each @xmath80 there exist a matrix @xmath272 and a quadratic form @xmath289 on @xmath6 such that expansion is valid .",
    "moreover , @xmath330 is continuous in @xmath331 for any fixed @xmath101 .    in case of ( s2.i - ii ) , for @xmath101 , @xmath332      sometimes we consider _ scale - invariant _ functions @xmath217 in the sense that @xmath333 if the function @xmath211 is differentiable , this property is equivalent to the following condition on its g - gradients @xmath275 : @xmath334 this follows essentially from the fact that for @xmath137 , @xmath335 as @xmath336 . if @xmath211 does even satisfy the second order smoothness assumption in lemma  [ lem : g - convexity ] , then @xmath337 because @xmath338    a scale - invariant function @xmath211 on @xmath7 is geodesically convex if , and only if , @xmath211 is geodesically convex on the g - convex submanifold @xmath339 introduced earlier . for if @xmath340 for @xmath137 with arbitrary @xmath80 and @xmath101 , then @xmath341 , and @xmath342 with @xmath343 satisfying @xmath344 and @xmath345 belonging to the subspace @xmath346 of symmetric matrices with trace @xmath11 .    to minimize a scale - invariant function @xmath211",
    ", one may restrict one s attention to matrices in @xmath347 .",
    "then the previous considerations can be adapted as follows :    [ [ a - criterion - for - strict - g - convexity . ] ] a criterion for strict g - convexity .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    suppose that @xmath217 is scale - invariant and satisfies the second order smoothness assumption of lemma  [ lem : g - convexity ] .",
    "then it is strictly geodesically convex on @xmath347 if @xmath298 for all @xmath80 and @xmath348 .",
    "[ [ minimizers - and - g - coercivity . ] ] minimizers and g - coercivity .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + +    all results of section  [ subsec : minimizers.g - coercivity ] carry over with the following modifications : we restrict our attention to matrices @xmath189 , to matrices @xmath80 with @xmath191 and to matrices @xmath349 . in particular , a matrix @xmath350 minimizes a g - convex function @xmath211 on @xmath347 if , and only if , @xmath351 a function @xmath211 is said to be geodesically coercive on @xmath347 if @xmath352 in case of a continuous and g - convex function @xmath211 , a necessary and sufficient condition for this is @xmath353",
    "we now apply the results of the previous section to the problem of regularized @xmath0-functionals and @xmath0-estimators of scatter . before doing so",
    ", we first briefly consider the non - penalized case , i.e.  minimizing @xmath354 \\ ,",
    "q(dx )          + \\log",
    "\\det(\\sigma ) .\\ ] ] in what follows we summarize various results from @xcite and @xcite in a slightly more general setting .",
    "the former paper considered only empirical distributions @xmath15 whereas the latter survey paper considered general distributions @xmath9 but only differentiable functions @xmath18 satisfying additional constraints .    throughout we assume that @xmath45 is non - decreasing and g - convex in @xmath355 , that means , @xmath356 is non - decreasing and convex in @xmath44 . in particular",
    ", @xmath18 is continuous with left- and right - sided derivatives on @xmath109 , and @xmath357 defines a non - decreasing function on @xmath358 .",
    "note that @xmath359 for @xmath44 .",
    "thus strict g - convexity of @xmath18 on @xmath109 is equivalent to @xmath360 being strictly increasing on @xmath358 .",
    "the next proposition clarifies under which conditions on @xmath18 and @xmath9 the objective function @xmath46 is well - defined for arbitrary @xmath14 . in particular , a sufficient condition for that is @xmath361 or @xmath9 having bounded support .",
    "[ prop : existence ] the integral @xmath362 is finite for arbitrary @xmath14 if , and only if , @xmath363 in case of @xmath364 being non - increasing in @xmath355 , the latter condition is equivalent to @xmath365    the following theorem regarding the g - convexity of @xmath46 follows essentially from examples [ ex0 ] and [ exlog ] plus some extra arguments , see supplement  [ sec : auxiliary ] .",
    "it is an extension of theorem  1(a ) of @xcite , who considered the case @xmath15 , and of proposition  5.4 of @xcite , who considered differentiable functions @xmath18 :    [ thm : mfunc ] under condition  , @xmath46 is continuous and geodesically convex in @xmath14 .",
    "furthermore ,    * ( a ) * suppose that @xmath45 is strictly g - convex in @xmath355 .",
    "then @xmath366 is strictly geodesically convex if , and only if , @xmath367 for any linear subspace @xmath368 of @xmath10 with @xmath369 .    *",
    "( b ) * suppose that @xmath370 for @xmath355 . then @xmath366 is strictly geodesically convex on @xmath347 if , and only if , @xmath371 for arbitrary linear subspaces @xmath372 with @xmath373 .",
    "the special function @xmath370 in part  ( b ) corresponds to the distribution - free @xmath0-estimator of scatter introduced in @xcite , and it is the setting for which geodesic convexity was first applied to @xmath0-estimation @xcite .",
    "the corresponding objective function @xmath366 is scale - invariant if @xmath374 .",
    "results on the g - coercivity of @xmath46 can be obtained by extending lemma 2.2 of @xcite from @xmath375 to general @xmath9 , see also theorem  1(b ) of @xcite and proposition  5.5 of @xcite .",
    "lemma  [ lem : g - coercivity ] allows for a complete answer in the present general framework , starting from the following proposition .",
    "[ prop : g - coercivity ] let @xmath376 with @xmath377 \\in { { \\mathbb{r}}_{\\rm orth}^{q\\times q}}$ ] and @xmath378 satisfying @xmath379 .",
    "then @xmath380 where @xmath381 and @xmath382 for @xmath383 .",
    "furthermore , @xmath384 for @xmath385 .    * ( a ) *  specifically let @xmath386 .",
    "then the previous limit may be rewritten as @xmath387    * ( b ) *  specifically let @xmath388 for @xmath355 .",
    "then @xmath389 on @xmath109 , and the previous limit may be rewritten as @xmath390    this proposition will be used later in connection with regularized scatter functionals . in the present context",
    "it implies necessary and sufficient conditions for g - coercivity in the following two settings :    * setting 0 .",
    "*  @xmath370 for @xmath355 , and @xmath374 .    * setting 1 . *  @xmath391 , @xmath392 , and @xmath9 satisfies .",
    "[ thm : g - coercivity ]    * ( a ) *  in setting  1 , @xmath366 is geodesically coercive if , and only if , @xmath393 for all linear subspaces @xmath22 with @xmath23 .",
    "if in addition @xmath360 is strictly increasing on @xmath394 , then @xmath366 has a unique minimizer .    *",
    "( b ) *  in setting  0 , @xmath366 is geodesically coercive on @xmath347 if , and only if , @xmath395 for all linear subspaces @xmath22 with @xmath396 . in this case , @xmath366 has a unique minimizer on @xmath347 .",
    "note that the condition in part  ( a ) of theorem  [ thm : g - coercivity ] is precisely condition  1 mentioned in section  [ sec : background ] .",
    "the additional assumption for uniqueness of the minimizer covers @xmath0-estimators of scatter as proposed in @xcite with functions @xmath18 which are not strictly g - convex on the whole positive half - line . in part",
    "( b ) the condition @xmath374 can be eliminated by replacing @xmath9 with @xmath397 , @xmath398 .",
    "the conclusion of part  ( b ) is well known , see @xcite and @xcite .    in connection with the algorithms introduced later",
    "we need objective functions @xmath366 which are twice continuously differentiable . in setting  0 this is the case , but setting  1 will be replaced with the following one :    * setting  2 . *",
    "@xmath18 is twice continuously differentiable on @xmath109 such that @xmath399 is strictly increasing in @xmath400 with limits @xmath401 and @xmath402 $ ] .",
    "moreover , for some constant @xmath403 , @xmath404 for all @xmath400 .",
    "[ lem : g - convexity.log.likelihood ] for @xmath80 and @xmath101 , under settings  0 and 2 , @xmath405 as @xmath295 , where @xmath406 and @xmath407 moreover , @xmath408 with equality if , and only if , @xmath409 here @xmath410 are the different eigenspaces of @xmath103 , and @xmath411 .      as noted in the introduction , most research on robust estimation of scatter",
    "has mainly centered on the unrestricted estimation of the scatter matrix .",
    "but the previous results imply that a unique minimizer of @xmath366 can only exist if @xmath412 for any proper linear subspace @xmath368 of @xmath10 .",
    "this excludes empirical distributions @xmath375 with sample size @xmath413 .",
    "some previous work on regularization does exist , with one approach being to introduce a regularization or shrinkage term to the @xmath0-estimating equations , as is done for the special function @xmath370 in @xcite and for more general @xmath0-estimates in @xcite .",
    "proving existence and/or uniqueness to regularized @xmath0-estimation equations , though , is not straightforward , and most of the work using this approach does not include conditions to insure such properties .    here , we consider a penalized objective function approach , that is we aim to minimize over @xmath14 the function @xmath414 for some tuning parameter @xmath415 and penalty function @xmath416 . for the special function @xmath370 , the empirical version of this approach has been considered in @xcite for certain g - convex penalties , although coercivity is not treated and consequently conditions for existence are not given .",
    "the empirical version is also studied in @xcite for general g - convex @xmath18-functions and general g - convex penalties , but conditions for coercivity are only given for the penalty function @xmath417 .",
    "a popular penalty function is the @xmath418 penalty on the off - diagonal elements of @xmath42 , i.e.  when @xmath419 . in the classical setting , i.e.  when",
    "@xmath46 is taken to be proportional to the multivariate normal negative log - likelihood functional , the problem of minimizing using this @xmath418 penalty is commonly referred to as a graphical lasso . for this case , as @xmath420 increases the solutions produce a path of increasing zeros in the off - diagonal elements of @xmath42 .",
    "a robust graphical lasso can be constructed by considering general @xmath46 , as has been proposed e.g.  in @xcite for the case when @xmath46 is proportional to the negative log - likelihood of an elliptical t - distribution .",
    "one drawback to this approach is that when using @xmath18-functions which yield bounded influence estimators , the function @xmath46 is not convex in @xmath42 and consequently as @xmath420 increases the solution path may not yield increasing zeros in the off - diagonal elements of @xmath42 .",
    "moreover , as shown in supplement  [ sec : auxiliary ] , this @xmath418 penalty is not g - convex .",
    "so even when @xmath46 is strictly g - convex , the uniqueness of a solution to is not guaranteed .    here , we are interested in considering for the case when both @xmath46 and @xmath421 are g - convex .",
    "obviously this implies that the penalized objective function @xmath211 is g - convex , too .",
    "moreover , if either @xmath46 or @xmath421 are strictly g - convex , then @xmath211 is strictly g - convex as well .",
    "note that these considerations apply to the special case when @xmath46 is taken to be proportional to the multivariate normal negative log - likelihood functional , i.e.  @xmath41 . for this case , @xmath46 is not only strictly convex in @xmath42 , it is also strictly g - convex in @xmath42 and hence in @xmath40 .",
    "thus , in this classical setting , in addition to penalty functions which are convex in @xmath42 , penalty functions which are g - convex in @xmath40 also ensure the uniqueness of a minimum to , provided a minimum exists .",
    "the existence of a minimizer to depends on the geodesic coercivity of @xmath422 , which in turn depends of the behavior of @xmath46 and @xmath421 as @xmath264 . for @xmath46 , proposition  [ prop : g - coercivity ] provides a complete answer , so it remains to specify and investigate the penalties @xmath421 .",
    "[ [ shrinkage - towards - i_q . ] ] shrinkage towards @xmath423 .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    functions which penalize deviations from @xmath423 are @xmath424 where @xmath425 are the eigenvalues of @xmath40 . in all three cases , @xmath426 is the unique minimizer .",
    "note that @xmath427 is just the square of the geodesic distance @xmath428 . while @xmath429 and @xmath430 satisfy the symmetry relation @xmath431 , the penalty @xmath432 is non - symmetric , penalizing very small eigenvalues more severely than very large ones .",
    "it corresponds to the kullback - leibler divergence between @xmath433 and @xmath434 and has been previously considered in @xcite . in principle",
    "one could also use the penalty @xmath435 , but from a statistical perspective this seems to be less reasonable .",
    "the next lemma summarizes the essential properties of these penalties .",
    "[ lem : all.about.pi ] for @xmath436 , the penalty function @xmath437 is twice continuously differentiable and strictly geodesically convex on @xmath7 with a unique minimum at @xmath423 .",
    "precisely , for any @xmath80 , as @xmath305 , @xmath438 with @xmath439 and @xmath440 given in the following table : @xmath441 here @xmath442 with @xmath443 \\in { { \\mathbb{r}}_{\\rm orth}^{q\\times q}}$ ] and @xmath444 , and @xmath445 with the convention @xmath446 . in particular , @xmath447 whenever @xmath448 .    moreover , if @xmath376 with @xmath66 and @xmath449 such that @xmath379 , then @xmath450 } \\infty - \\sum_{i=1}^q \\gamma_i              & \\text{if } \\ k = 1 , \\\\",
    "\\infty              & \\text{if } \\ k = 2 .",
    "\\end{cases}\\ ] ]    this lemma and theorem  [ thm : mfunc ] together show that using any of the penalties @xmath429 , @xmath451 or @xmath430 together with a g - convex function @xmath18 yields an objective function @xmath211 in which is strictly g - convex . in particular , by corollary  [ cor : uniqueness.minimizer",
    "] , has a unique minimizer or no minimizer . with @xmath429 or @xmath430 g - coercivity and thus existence of a unique minimizer",
    "is guaranteed , regardless of @xmath9 .",
    "this is in contrast to the non - regularized case for which conditions on @xmath9 are needed to insure the existence of a minimizer .",
    "shrinkage towards a different given matrix @xmath452 is obtained by replacing @xmath40 in @xmath453 with @xmath454 .",
    "[ [ shrinkage - towards - multiples - of - i_q . ] ] shrinkage towards multiples of @xmath423 .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    functions which penalize large condition numbers @xmath455 of @xmath40 are given by @xmath456 all three functions are scale - invariant with @xmath40 minimizing @xmath457 if , and only if , @xmath40 is a positive multiple of @xmath423 .",
    "moreover , @xmath458 and @xmath459 satisfy the symmetry relation @xmath460 , whereas @xmath461 penalizes relatively small eigenvalues more severely than relatively large ones .",
    "here are the main facts :    [ lem : all.about.pi ] for @xmath436 , the penalty function @xmath462 is scale - invariant , twice continuously differentiable and geodesically convex .",
    "on @xmath347 it is strictly geodesically convex with a unique minimum at @xmath423 .",
    "precisely , for any @xmath80 , as @xmath305 , @xmath463 with @xmath439 and @xmath440 given in the following table : @xmath464 here @xmath465 , @xmath466 for @xmath467 , and @xmath468 $ ] , @xmath469 , @xmath470 are defined as in lemma  [ lem : all.about.pi ] . in particular , @xmath447 whenever @xmath348 .    moreover , if @xmath376 with @xmath66 and @xmath378 such that @xmath379 and @xmath471 , @xmath472 with @xmath473 .",
    "of course one could replace any of these penalties @xmath474 with a non - decreasing convex function thereof .",
    "as pointed out in remark  [ rem : transformation ] , this would preserve geodesic convexity .    [ [ a - scale - invariant - example . ] ] a scale - invariant example .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + +    we consider the special case where @xmath370 for @xmath355 and @xmath374 .",
    "since @xmath46 is scale - invariant , it is natural to choose a penalty which is scale - invariant , too , and to treat @xmath211 as a function on @xmath347 .",
    "if @xmath475 is strictly g - convex on the latter set , then @xmath211 inherits this property .    as to g - coercivity ,",
    "let @xmath376 with @xmath476 \\in { { \\mathbb{r}}_{\\rm orth}^{q\\times q}}$ ] and @xmath378 such that @xmath477 and @xmath471 . if @xmath478 , then @xmath479 thus @xmath211 is g - coercive on @xmath347 if , and only if , @xmath480 for any subspace @xmath368 of @xmath10 with @xmath396 . if @xmath481 , then @xmath482 thus @xmath211 is g - coercive on @xmath347 if , and only if , @xmath483 for any subspace @xmath368 of @xmath10 with @xmath396 .",
    "in case of @xmath484 for any fixed @xmath348 , the function @xmath211 is g - coercive on @xmath347 without further constraints on @xmath9 .",
    "this is the case , for instance , if @xmath485 or @xmath486 for @xmath487 with a non - decreasing convex function @xmath488 such that @xmath489 as @xmath490 .",
    "explicit examples for such functions @xmath360 are @xmath491      rather than choose @xmath420 in beforehand , one can use data dependent methods for selecting @xmath420 .",
    "one possible approach is to use an oracle type estimator for @xmath420 , as is done in @xcite .",
    "such an approach is based upon minimizing the mean square error under a specific distribution with the method being dependent on the choice of the penalty @xmath475 and the @xmath18-function .",
    "a more universal approach is to use cross - validation .",
    "here we propose a leave - one - out cross validation approach for the current problem as follows .",
    "let @xmath492 denoted the empirical distribution when the @xmath239th data point is removed , and for a given @xmath420 define @xmath493 with the minimum being taken over @xmath14 .",
    "next , define an aggregate robust measure of how well @xmath494 reflects the left - out observation @xmath238 by @xmath495 the objective is to then minimize @xmath496 over @xmath497 . in practice , this would be done over over some finite set of values for @xmath420 .",
    "some examples are given in section [ sec : example ] .",
    "since the cross validation approach can be computationally intensive , we first discuss algorithms for computing the regularized @xmath0-estimators of scatter .",
    "there is a rich literature on optimization on riemannian manifolds , see @xcite and the references therein .",
    "for the special case of functions on @xmath7 , @xcite propose various fixed - point and gradient descent methods .",
    "newton - raphson algorithms would be another possibility but may be inefficient due to the high dimension of hessian operators . for the minimization of a smooth and g - convex function",
    "we propose a partial newton - raphson algorithm which is similar to a method of @xcite for pure @xmath0-functionals of scatter .",
    "while the latter method has been designed for special settings in which a certain fixed - point algorithm serves as a fallback option with guaranteed convergence , the present approach is more general .",
    "we consider a twice continuously differentiable function @xmath217 such that @xmath498 in particular , @xmath211 is strictly g - convex .",
    "furthermore we assume that @xmath211 is g - coercive , so @xmath499 exists .",
    "finally we assume that @xmath275 and @xmath330 are continuous in @xmath80 for any fixed @xmath101 .",
    "under these conditions on @xmath211 one can devise an iterative algorithm to compute the minimizer @xmath500 . according to lemma  [ lem : minimizer.g - convex ] ,",
    "this is equivalent to finding a matrix @xmath501 such that @xmath502 .",
    "[ [ algorithmic - mappings . ] ] algorithmic mappings .",
    "+ + + + + + + + + + + + + + + + + + + + +    to compute @xmath500 we iterate a certain mapping @xmath503 such that @xmath504 and @xmath505 whenever @xmath506 . if we replace the latter condition by a somewhat stronger constraint , iterating the mapping @xmath507 yields sequences with guaranteed converge to @xmath500 .",
    "[ lem : algorithm ] suppose that @xmath508 satisfies @xmath504 and @xmath509 let @xmath510 be an arbitrary starting point , and define inductively @xmath511 for @xmath512 .",
    "then @xmath513    this lemma belongs to the folklore in optimization theory . for the reader",
    "s convenience we provide its short proof in section  [ sec : auxiliary ] .",
    "[ [ construction - of - phi . ] ] construction of @xmath507 .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    let @xmath148 with @xmath80 be our current candidate for @xmath500 .",
    "note that the quadratic term @xmath330 may be rewritten as @xmath514 for a self - adjoint linear operator @xmath515 with strictly positive eigenvalues .",
    "thus a promising new candidate for @xmath500 would be @xmath516 with @xmath517 a full newton step in local geodesic coordinates .",
    "computing @xmath518 would require substantial memory and computation time , though .",
    "alternatively one could try a gradient descent step : @xmath519 with @xmath520    as a compromise between a full newton and a mere gradient step we propose a partial newton step : to this end we consider a spectral decomposition @xmath521 with an orthogonal matrix @xmath522 and a vector @xmath523 .",
    "then we define @xmath524 with @xmath525 this may be computed explicitly : since @xmath526 for a certain matrix @xmath527 , we may write @xmath528    if @xmath148 is far from @xmath500 , the matrix @xmath529 need not be better than @xmath40 itself . to avoid poor steps we introduce a simple step size correction and define finally @xmath530 with @xmath531 being the smallest integer @xmath532 such that @xmath533 for a given @xmath534 .",
    "the rationale behind this definition is the fact that @xmath535 and @xmath536 note that @xmath537 whenever @xmath281 , which is equivalent to @xmath538 .",
    "otherwise @xmath539    this algorithmic mapping @xmath507 has the desired properties , no matter how the factor @xmath127 of @xmath148 and the orthogonal matrix @xmath540 in the spectral decomposition @xmath541 are chosen .",
    "[ thm : phi ] the algorithmic mapping just defined has the properties described in lemma  [ lem : algorithm ] . moreover , if @xmath148 is sufficiently close to @xmath500 , then the number @xmath531 in the step size correction equals @xmath11 , whence @xmath542 .",
    "[ [ pseudo - code - for - phicdot . ] ] pseudo - code for @xmath543 .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    one may interpret our algorithmic mapping @xmath507 such that the factor @xmath127 of our current candidate @xmath148 for @xmath500 is replaced with a new matrix @xmath544 and @xmath545 .",
    "here is corresponding pseudo - code for the computation of @xmath546 :    @xmath547",
    "we illustrate the proposed methods in case of @xmath370 and @xmath548 the resulting functional @xmath549 is strictly g - convex and g - coercive on @xmath347 for any value @xmath415 .    precisely , we chose @xmath550 and simulated a random sample of size @xmath551 from the multivariate cauchy distribution with center @xmath11 and scatter matrix @xmath552 then we computed the minimizer @xmath553 of @xmath554 with @xmath9 being the empirical distribution of this sample for @xmath555 with @xmath556 .",
    "table  [ tab : cv.errors ] shows the resulting values @xmath496 and the following estimation errors : @xmath557 where @xmath558 , @xmath559 , and @xmath560 refers to the vector of the ordered eigenvalues of a symmetric matrix @xmath127 .",
    "note that our cross - validation criterion yields @xmath561 , which is a reasonable choice in view of the estimation errors .",
    "figure  [ fig0 ] shows a bar plot of the log - transformed eigenvalues of @xmath562 and of @xmath563 .",
    "@xmath564     ( green ) and @xmath563 ( blue).,scaledwidth=99.0% ]    this simulation was repeated 100 times , and in all cases the minimizer of @xmath496 on the given grid turned out to be @xmath565 .",
    "figure  [ fig1 ] shows box plots of @xmath496 and the estimation errors @xmath566 , @xmath567 , @xmath568 for these simulations .",
    "( upper left ) and estimation errors @xmath566 ( upper right ) , @xmath567 ( lower left ) , @xmath568 ( lower right ) versus @xmath569.,title=\"fig:\",scaledwidth=49.0% ]    ( upper left ) and estimation errors @xmath566 ( upper right ) , @xmath567 ( lower left ) , @xmath568 ( lower right ) versus @xmath569.,title=\"fig:\",scaledwidth=49.0% ]     ( upper left ) and estimation errors @xmath566 ( upper right ) , @xmath567 ( lower left ) , @xmath568 ( lower right ) versus @xmath569.,title=\"fig:\",scaledwidth=49.0% ]    ( upper left ) and estimation errors @xmath566 ( upper right ) , @xmath567 ( lower left ) , @xmath568 ( lower right ) versus @xmath569.,title=\"fig:\",scaledwidth=49.0% ]",
    "for @xmath80 and @xmath570 define @xmath571 . then @xmath572 with @xmath573 , and this implies that @xmath574 for some @xmath129 . hence @xmath575 and for @xmath97 $ ] , @xmath576 if @xmath577 , the right hand side may be simplified further and we obtain @xmath578 this may be applied to the curve @xmath579 with @xmath580 as well as to the surface @xmath581 with @xmath582 .",
    "if @xmath148 minimizes @xmath211 , then obviously has to hold true . on the other hand ,",
    "suppose that @xmath148 is not a minimizer of @xmath211 .",
    "that means , @xmath583 for some @xmath101 .",
    "but @xmath584 is a convex function of @xmath137 , so @xmath585 +    the result and its proof generalize proposition  5.5 in @xcite .",
    "recall first that for any @xmath101 , the function @xmath586 is convex with right - sided derivative @xmath587 moreover , @xmath588 is non - decreasing in @xmath137 with limit @xmath589 $ ] as @xmath490 .",
    "thus we have to show that @xmath211 is g - coercive if , and only if , @xmath590 for any @xmath212 .",
    "suppose that @xmath211 is not g - coercive .",
    "then there exists a sequence @xmath591 in @xmath6 such that @xmath592 but @xmath593 for all indices @xmath594 and some real constant @xmath150 .",
    "writing @xmath595 for a matrix @xmath596 with norm one , we may even assume that @xmath597 with @xmath598 , @xmath599 .",
    "now for any fixed @xmath600 , @xmath601 in the first and third step we used convexity of @xmath602 in @xmath137 , the second and last step rely on continuity of @xmath211 and the choice of @xmath591 .",
    "these considerations show that @xmath603 .",
    "on the other hand , suppose that @xmath211 is g - coercive .",
    "then for any @xmath212 and sufficiently large @xmath604 , @xmath605 +    by continuity of @xmath211 , the set @xmath266 is closed , and by g - convexity of @xmath211 it is g - convex .    obviously , the set @xmath266 is identical with the set of minimizers of @xmath211 on the closed set @xmath606 .",
    "if @xmath211 is also g - coercive , the set @xmath607 is even compact , and @xmath266 is a nonvoid and closed subset of @xmath607 , so it is compact itself .",
    "now suppose that @xmath211 has a minimizer @xmath608 , @xmath80 .",
    "note that g - coercivity is equivalent to @xmath609 this follows from the inequality @xmath610 which will be proved later .",
    "now suppose that @xmath211 is minimal at @xmath500 but not g - coercive .",
    "that means , there exists a sequence @xmath591 in @xmath6 with @xmath592 but @xmath611 for all indices @xmath594 and some real constant @xmath150 .",
    "writing @xmath595 for a matrix @xmath596 with norm one , we may even assume that @xmath597 with @xmath598 , @xmath599 .",
    "since @xmath612 is convex in @xmath137 , we may conclude that for any fixed @xmath600 , @xmath613 this implies that @xmath614 for all @xmath600 , so @xmath266 is geodesically unbounded .",
    "it remains to prove inequality which is related to geodesic distances . on the one hand ,",
    "@xmath615 on the other hand , @xmath616 in the last step we utilized that @xmath617 and @xmath618 have the same eigenvalues , which follows from the singular value decomposition of @xmath127 .",
    "this criterion follows from the fact that for @xmath619 , @xmath620 so @xmath621 as @xmath622 . by means of lemma  [ lem : convexity ] in supplement  [",
    "sec : auxiliary ] , this shows that @xmath257 is convex in @xmath137 , provided that @xmath623 for all @xmath137 .",
    "this convexity is strict if @xmath624 for all @xmath137 .",
    "if @xmath625 for some @xmath80 and @xmath101 , then for sufficiently small @xmath626 , @xmath627 hence @xmath628 thus @xmath257 is not convex in @xmath137 , so @xmath211 is not geodesically convex .      that @xmath426 is the unique minimizer of @xmath453 follows from the fact that @xmath629 , @xmath630 , @xmath631 and @xmath632 for @xmath633 .",
    "note first that @xmath634 satisfies the expansion @xmath635 this and remark  [ rem : inversion2 ] implies that @xmath636 while @xmath637 is given by @xmath638 .",
    "the inequality @xmath639 for @xmath448 can be proved similarly as the inequality @xmath640 in example  [ ex2 ] . in case of @xmath376 with an orthogonal matrix @xmath540 and a vector @xmath378 with non - decreasing componnents , @xmath641 as @xmath490 , unless @xmath642 .    as to @xmath451",
    ", it follows from the previous considerations and example  [ ex0 ] that @xmath643 and @xmath644 . again @xmath645 for @xmath448 . moreover , if @xmath376 as before , as @xmath490 , @xmath646}^ { } \\infty - \\sum_{i=1}^q \\gamma_i .\\ ] ]    for @xmath430 the expansion is a consequence of corollary  [ cor : penalties ] in supplement  [ sec : auxiliary ] .",
    "just note that we may write @xmath647 with @xmath648 and @xmath649 , @xmath444 , and @xmath650 moreover , @xmath651 , so @xmath652 .",
    "elementary considerations reveal that all penalty functions @xmath462 are scale - invariant .",
    "next we show that a matrix @xmath14 with eigenvalues @xmath425 minimizes @xmath474 if , and only if , @xmath653 .",
    "on the one hand , @xmath654 with equality if , and only if , @xmath655 for all indices @xmath656 .",
    "this follows from @xmath629 for arbitrary @xmath633 . in case of @xmath461 ,",
    "note that by jensen s inequality and strict concavity of @xmath657 on @xmath109 , @xmath658 with strict inequality unless all @xmath659 are identical .",
    "finally , @xmath660 with equality if , and only if , all @xmath659 are identical .",
    "next we verify the geodesic second order taylor expansions of @xmath474 .",
    "it follows from examples  [ ex0 ] and [ ex2 ] and remark  [ rem : inversion2 ] that @xmath661 and @xmath662 with @xmath465 .",
    "the considerations to example  [ ex2 ] reveal that both @xmath637 and @xmath663 are strictly positive whenever @xmath299 .",
    "the expansion for @xmath459 follows from corollary  [ cor : penalties ] with the same arguments as in the proof of lemma  [ lem : all.about.pi ] . in particular , @xmath664 with @xmath665 .",
    "concerning coercivity , let @xmath666 with @xmath667 and @xmath668 .",
    "then for @xmath669 , @xmath670 and @xmath671 as @xmath490 .",
    "this implies for @xmath487 the asserted limits of @xmath672 . for @xmath673",
    "the claim follows from @xmath674 +      our proof of theorem  [ thm : phi ] is based on two elementary inequalities for the accuracy of taylor expansions of @xmath211 which are derived in supplement  [ sec : auxiliary ] :    [ lem : remainders ] for @xmath14 and @xmath626 let @xmath675 for arbitrary @xmath148 with @xmath80 and @xmath212 , @xmath676 and @xmath677    one can deduce from continuity of @xmath330 in @xmath80 for fixed @xmath101 and @xmath6 being finite - dimensional that both @xmath678 and @xmath679 are continuous in @xmath680 , where @xmath681 .",
    "additional quantities we shall use repeatedly are @xmath682 and @xmath683 .",
    "both are continuous in @xmath40 .    for arbitrary @xmath148 , @xmath80",
    ", we can say that @xmath684 because @xmath685 and @xmath686 on the other hand , @xmath687 hence it follows from lemma  [ lem : remainders ] that for any fixed integer @xmath532 , @xmath688 note that @xmath689 is continuous in @xmath40 .",
    "moreover , for any fixed @xmath690 there is an integer @xmath691 such that @xmath692 .",
    "consequently , if @xmath40 is sufficiently close to @xmath693 , then the integer @xmath531 in @xmath694 satisfies @xmath695 , and @xmath696 this shows that @xmath697    for @xmath40 close to @xmath500 we only consider @xmath698 and utilize the second bound in lemma  [ lem : remainders ] .",
    "namely , @xmath699 consequently , @xmath700 but @xmath701 as @xmath702 and @xmath703 , so @xmath704 consequently , @xmath705 if @xmath40 is sufficiently close to @xmath500 .",
    "the next three lemmas provide expansions and inequalities for matrix exponentials and logarithms .",
    "they involve the auxiliary function @xmath706 given by @xmath707 one may also write @xmath708 with a random variable @xmath540 which is uniformly distributed on @xmath709 $ ] .",
    "convexity of the exponential function on @xmath256 and jensen s inequality imply that @xmath710      these expansions may be viewed as special cases of the daleckii - krein formula ; cf .  chapter  v of @xcite and chapter  2 of @xcite .",
    "we provide a more direct proof starting from a particular series expansion of matrix exponentials in @xcite .",
    "the explicit formula for the derivative of the exponential transform of @xmath6 implies local lipschitz constants .",
    "[ lem : lipschitz.exp.log ] for arbitrary different matrices @xmath716 , @xmath717          \\ge \\ j \\bigl ( \\lambda_{\\rm min}(a ) , \\lambda_{\\rm min}(b ) \\bigr )          \\ \\ge \\ \\min \\bigl\\ { e_{}^{\\lambda_{\\rm min}(a ) } ,              e_{}^{\\lambda_{\\rm min}(b ) } \\bigr\\ } .      \\end{cases}\\ ] ] for arbitrary different matrices @xmath718 , @xmath719          \\displaystyle          \\ge \\",
    "\\frac{1}{j \\bigl ( \\log\\lambda_{\\rm max}(a ) , \\log\\lambda_{\\rm max}(b ) \\bigr ) }          \\ \\ge \\",
    "\\min \\bigl\\ { \\frac{1}{\\lambda_{\\rm max}(a ) } ,              \\frac{1}{\\lambda_{\\rm max}(b ) } \\bigr\\ } .",
    "\\end{cases}\\ ] ]    in connection with two particular penalties we need second order taylor expansions of matrix exponentials and logarithms .",
    "in addition to the bivariate function @xmath720 these involve the trivariate function @xmath721 with @xmath722 ^ 2 : u_1 + u_2 \\le 1\\ } }          \\exp(u_0 x + u_1 y + u_2 z ) \\ , du \\qquad ( \\text{with } \\ u_0 : = 1 - u_1 - u_2 ) .\\ ] ] one may also write @xmath723 , where @xmath724 is uniformly distributed on the unit simplex of all triples @xmath725 ^ 3 $ ] with @xmath726 . again one can deduce from convexity of the exponential function and jensen s inequality that @xmath727 another useful identity which will be used later is @xmath728 for @xmath729        [ cor : penalties ] for @xmath14 let @xmath733 and @xmath734 . for arbitrary vectors",
    "@xmath649 with @xmath444 and matrices @xmath101 , as @xmath295 , @xmath735 where @xmath736 with @xmath737 , @xmath738 , and @xmath739      it is wellknown that the mapping @xmath117 is bijective with inverse function @xmath118",
    ". moreover , the exponential mapping is continuously differentiable with derivative @xmath741 at @xmath101 , where @xmath741 denotes the linear mapping @xmath742 see @xcite . by means of the spectral representation @xmath712 one",
    "may write @xmath743 since @xmath744 for arbitrary @xmath745 , this representation shows that @xmath741 is a non - singular linear transformation of @xmath6 with inverse @xmath746 by the inverse function theorem , the function @xmath118 is also continuously differentiable with @xmath747 and @xmath748 .",
    "we first prove the inequalities for @xmath749 . with @xmath750",
    "it follows from lemma  [ lem : derivatives.exp.log ] and its proof that @xmath751 writing @xmath752 with a vector @xmath444 and a matrix @xmath443 \\in { { \\mathbb{r}}_{\\rm orth}^{q\\times q}}$ ] , @xmath753 with @xmath754 . on the one hand , the latter representation of @xmath755 and",
    "imply that @xmath756 and @xmath757 consequently , @xmath758 on the other hand , the explicit representation of @xmath755 and imply that @xmath759 and @xmath760 hence @xmath761      as shown in @xcite , @xmath769 where @xmath770 is defined as in the proof of lemma  [ lem : derivatives.exp.log ] , and @xmath771 ^ 2 : u_1 + u_2 \\le 1\\ } }          \\exp(u_0 a ) \\delta \\exp(u_1 a ) \\delta \\exp(u_2 a ) \\",
    ", du\\ ] ] with @xmath772 . in the special case of a diagonal matrix @xmath773 , the matrix @xmath770 equals @xmath774 , and the matrix @xmath775 may be written as @xmath776 so @xmath777 this proves the second order taylor expansion for @xmath778 .    concerning the expansion of @xmath779 with @xmath780 , we determine a matrix @xmath781 such that @xmath782 to this end , recall that @xmath783 as @xmath784 .",
    "thus we set @xmath785 and note that @xmath786 so @xmath787 moreover , one can easily verify that @xmath788 , whence @xmath789 in other words , @xmath790 but now it follows from lemma  [ lem : lipschitz.exp.log ] and the continuity of eigenvalues that @xmath791 +    this expansion follows essentially from lemma  [ lem : derivatives.exp.log.2 ] with @xmath792 so @xmath793 , and the taylor expansion in lemma  [ lem : derivatives.exp.log.2 ] involves matrices with entries @xmath794 +    according to corollary  [ cor : g - derivatives.log ] , @xmath795 with @xmath796 in particular , since @xmath797 , @xmath798 hence @xmath799 moreover , @xmath800 with @xmath801 now we have to show that @xmath802 the inequality is just a consequence of . in case of @xmath803 ,",
    "the equation in follows from @xmath797 and @xmath804 , and here @xmath805 . in case of",
    "@xmath806 we use and obtain @xmath807        the following arguments are similar to the ones of @xcite . in case of @xmath167 ,",
    "the assertion is trivial , so we only consider the case @xmath210 . without loss of generality",
    "let @xmath814 , otherwise consider the path @xmath181 with @xmath815 .",
    "now let @xmath816 then we may write @xmath817 by virtue of the cauchy - schwarz inequality .",
    "equality holds in the latter display if , and only if , the derivative of @xmath818 is a non - negative multiple of @xmath103 for almost all @xmath819 $ ] . since @xmath818 is continuously differentiable by assumption , we may rephrase this as @xmath820 for some bounded function @xmath821 \\to [ 0,\\infty)$ ] with at most finitely many discontinuities . since @xmath822 and @xmath823 , we know that @xmath824 defines a nondecreasing , piecewise continuously differentiable function @xmath87 \\to { \\mathbb{r}}$ ] with @xmath88 , @xmath89 and @xmath825 for @xmath826 $ ] . note also that in this special case @xmath827 so @xmath828 .",
    "hence it suffices to show that for a general path @xmath0 and any @xmath819 $ ] , @xmath829 to this end we write @xmath830 with an orthogonal matrix @xmath711 \\in { { \\mathbb{r}}_{}^{q\\times q}}$ ] and a vector @xmath831 .",
    "then it follows from lemma  [ lem : derivatives.exp.log ] that @xmath832 with @xmath833 . on the other hand",
    ", @xmath834 consequently , @xmath835 +        [ lem : convexity ] let @xmath837 be a real interval and @xmath838 such that for any fixed @xmath839 there exist real numbers @xmath840 such that @xmath841 if @xmath842 for all @xmath839 , then @xmath211 is convex . if @xmath843 for all @xmath839 , then @xmath211 is strictly convex .",
    "the second order taylor expansion in lemma  [ lem : convexity ] implies that @xmath844 as @xmath622 .",
    "thus @xmath211 is differentiable with @xmath845 .",
    "however , it does _ not _ imply that @xmath211 is twice differentiable . as a counterexample",
    "consider @xmath846 and @xmath847 this function @xmath211 is obviously infinitely often differentiable on @xmath848 , and @xmath849 as @xmath622 , so @xmath850 .",
    "but for @xmath851 , the first derivative @xmath852 has no limit as @xmath853 .    .",
    "since @xmath211 is continuous , it suffices to show that for arbitrary points @xmath854 in @xmath837 and their midpoint @xmath855 , the value @xmath856 is not greater than ( strictly smaller than ) @xmath857 .",
    "note that there exists a unique quadratic function @xmath858 such that @xmath859 for @xmath860 , namely , @xmath861 with @xmath862 note also that @xmath863 for all @xmath864 .",
    "but @xmath865 is greater or equal to the minimum of @xmath866 when @xmath867 runs through @xmath868 , @xmath869 and @xmath870 with the midpoints @xmath871 and @xmath872 . for if @xmath873 , then @xmath874 , and if @xmath875 , then @xmath876 .",
    "but @xmath877 and @xmath878 together imply that @xmath879 .",
    "consequently there exist triplets @xmath880 for @xmath881 such that @xmath882 , and @xmath883 with @xmath884 and @xmath885 .",
    "in particular , the three sequences @xmath886 , @xmath887 and @xmath888 converge to the same point @xmath889 $ ] , and @xmath890 for @xmath891 .",
    "but then elementary calculations show that @xmath892 whence @xmath893 .",
    "[ lem:2nd.order.taylor ] let @xmath894 be an open subset of @xmath277 , and let @xmath895 have the following property : for each @xmath896 there exist a vector @xmath897 and a matrix @xmath898 such that @xmath899 further suppose that @xmath900 is continuous .",
    "then @xmath211 is twice continuously differentiable with @xmath901 and @xmath902 .",
    "we start with dimension @xmath903 . for @xmath904 and @xmath626 let @xmath905 be the infimum and @xmath906 the supremum of @xmath108 on @xmath907 \\cap \\omega$ ] .",
    "now we apply lemma  [ lem : convexity ] to @xmath908 and @xmath909 in place of @xmath211 and @xmath837 , respectively .",
    "note that @xmath910 where @xmath911 and @xmath912 .",
    "this shows that @xmath913 is convex and @xmath914 is concave on @xmath909",
    ". in particular , @xmath915 is non - decreasing and @xmath916 is non - increasing in @xmath917 .",
    "thus we may conclude that @xmath918\\ ] ] for @xmath919 . letting @xmath920 shows that @xmath921",
    "now we consider dimension @xmath922 .",
    "we have to show that for any point @xmath896 and any fixed unit vector @xmath923 , @xmath924 our assumption on @xmath211 and the result for the one - dimentional case imply that for arbitrary @xmath925 and @xmath926 , the function @xmath927 is twice continuously differentiable on the set @xmath928 .",
    "now for our given @xmath896 and @xmath929 with sufficiently small norms @xmath930 and @xmath931 we may write @xmath932 with @xmath933 note that @xmath934 where @xmath935 consequently , for any unit vector @xmath923 and any vector @xmath936 with sufficiently small norm @xmath937 , @xmath938 because @xmath939 if we write each term @xmath940 as @xmath941 , then elementary algebra shows that @xmath942 because @xmath943 +      if @xmath211 is differentiable , then for arbitrary @xmath14 and @xmath944 with @xmath945 , @xmath946 this implies that for @xmath80 and @xmath101 , @xmath947 as @xmath295 . hence condition  ( s1.ii ) is satisfied with @xmath948 .",
    "if @xmath211 satisfies condition  ( s1.ii ) , then for arbitrary @xmath14 and @xmath944 with @xmath945 , @xmath949 with @xmath950 as @xmath951 , whence @xmath952 as @xmath951 .",
    "thus @xmath211 is differentiable with gradient @xmath953 at @xmath40 .",
    "suppose first that @xmath211 is twice continuously differentiable .",
    "this implies that for @xmath14 and @xmath944 with sufficiently small norm @xmath954 , @xmath955 with the quadratic form @xmath956 .",
    "this implies that for @xmath80 and @xmath101 , @xmath957 as @xmath295 .",
    "hence condition  ( s2.ii ) is satisfied with @xmath958    now suppose that @xmath211 satisfies condition  ( s2.ii ) .",
    "then for arbitrary @xmath14 and @xmath944 with @xmath945 , @xmath949 with @xmath959 as @xmath951 , whence @xmath960 as @xmath951 .",
    "hence @xmath211 admits a taylor expansion with @xmath953 and @xmath961 moreover , this is continuous in @xmath14 for any fixed @xmath962 .",
    "now we may conclude from lemma  [ lem:2nd.order.taylor ] with @xmath963 and @xmath964 that @xmath211 is indeed twice continuously diffrentiable .",
    "we use essentially the same arguments as @xcite . with @xmath242",
    "we may write @xmath965 and @xmath966 for @xmath219 .",
    "since @xmath967 , we may conclude that @xmath968 with @xmath969 .",
    "this shows that condition   is sufficient for integrability of @xmath970 with respect to @xmath9 .",
    "it follows from proposition  [ prop : existence ] that @xmath46 is well - defined in @xmath256 for arbitrary @xmath14 . for",
    "any fixed @xmath979 , the inequalities @xmath980 and @xmath981 imply that @xmath982 hence , by dominated convergence , @xmath46 is continuous in @xmath14 .",
    "geodesic convexity of @xmath366 follows from examples  [ ex0 ] and [ exlog ] .",
    "now the question is under which conditions on @xmath18 , @xmath9 , @xmath80 and @xmath449 , the function @xmath983 is strictly convex on @xmath256 . with @xmath984 , @xmath398 ,",
    "one may write @xmath985 \\ , q_b(dx )          - t \\sum_{i=1}^q \\gamma_i .\\end{aligned}\\ ] ] moreover , with @xmath242 and @xmath986 for fixed @xmath851 , @xmath987 as mentioned in example  [ exlog ] , @xmath988 is convex with @xmath989 where @xmath990 . hence @xmath988 is strictly convex unless @xmath229 belongs to @xmath991 for some value @xmath992 . in the latter case , @xmath993 is linear with slope @xmath994 .",
    "as to part  ( a ) , suppose that @xmath45 is strictly g - convex in @xmath355 , which is equivalent to @xmath108 being strictly convex and strictly increasing . then @xmath995 is strictly convex unless @xmath988 is constant , i.e.  @xmath996 . consequently , @xmath997 is strictly convex in @xmath137 , unless @xmath998 . but",
    "@xmath999 implies that @xmath1000 . on the other hand ,",
    "suppose that @xmath1001 for some linear subspace @xmath22 with dimension @xmath1002 .",
    "if we choose @xmath1003 $ ] such that @xmath1004 form a basis of @xmath368 and @xmath1005})_{i=1}^q$ ] , then @xmath1006 is linear in @xmath137 .",
    "as to part  ( b ) , it suffices to consider matrices @xmath127 with @xmath191 and vectors @xmath449 with @xmath1007 .",
    "here @xmath1008 , so the function @xmath995 is strictly convex if , and only if , @xmath988 is strictly convex . the latter condition is true , unless @xmath229 lies in the union of the linear subspaces @xmath1009 , @xmath992 .",
    "hence @xmath997 is strictly convex in @xmath137 , unless @xmath1010 .",
    "the latter condition implies that @xmath1011 with @xmath1012 and @xmath1013 and @xmath994 an arbitrary number in @xmath1014 . on the other hand ,",
    "suppose that @xmath1011 for linear subspaces @xmath1015 with respective dimensions @xmath1016 such that @xmath373 .",
    "now we take @xmath1017 $ ] such that @xmath1018 , @xmath1019 and @xmath1020 .",
    "further let @xmath1021}/d - 1_{[d < i \\le d+e ] } / e$ ] .",
    "then @xmath1006 is linear in @xmath137 while @xmath1022 .",
    "we argue similarly as in the proof of proposition  5.5 in @xcite .",
    "note first that @xmath1023 with the transformed distribution @xmath1024 , @xmath398 .",
    "thus it suffices to consider the case @xmath1025 and @xmath1026 , so @xmath1027 . for real numbers @xmath1028 , @xmath1029 for any fixed @xmath219 we may write @xmath1030 , where @xmath242 and @xmath986 . as mentioned in the proof of theorem  [ thm : mfunc ]",
    ", the function @xmath995 is convex .",
    "thus @xmath1031\\ ] ] for @xmath1032 $ ] , and @xmath1033 is well - defined and non - decreasing in @xmath137 . hence by dominated convergence and monotone convergence , @xmath1034 now we partition @xmath1035 as @xmath1036 . for @xmath1037 , @xmath1038 } & \\text{if } \\",
    "\\gamma_j = 0 \\\\          0 & \\text{if } \\",
    "\\gamma_j < 0      \\end{cases}\\ ] ] and @xmath1039 as @xmath490 .",
    "hence @xmath1040 all in all we obtain the asserted limit .    with @xmath1041 we may write @xmath1042 , and all summands @xmath1043 are non - negative . hence in the special case that @xmath391 the limit equals @xmath1044 in the special case of @xmath370 for @xmath355 , @xmath389 on @xmath109 ,",
    "so the limit equals @xmath1045 +    we start with part  ( a ) . according to lemma  [ lem : g - coercivity ] and proposition  [ prop : g - coercivity ]  ( a )",
    ", @xmath366 is g - coercive on @xmath7 if , and only if , it satisfies the following inequalities : for any @xmath1046 \\in { { \\mathbb{r}}_{\\rm orth}^{q\\times q}}$ ] and @xmath449 with @xmath477 , @xmath1047 where @xmath381 and @xmath1048 , @xmath383 , and @xmath1041 . if we choose @xmath1049})_{i=1}^q$ ] for a fixed index @xmath1050 , then the left hand side of equals @xmath1051 which is positive if , and only if , @xmath1052 .",
    "note also that all differences @xmath1043 are non - negative .",
    "this shows that is satisfied for arbitrary nonzero vectors @xmath1053 with non - decreasing components if , and only if , @xmath1054 but since @xmath1055 is an arbitrary orthonormal basis of @xmath10 , these considerations show that g - coercivity of @xmath366 is equivalent to for arbitrary linear subspaces @xmath22 with @xmath23 .    by virtue of lemma  [ lem : existence.minimizers ] , g - coercivity of @xmath366 guarantees the existence of a minimizer @xmath14 of @xmath366 .",
    "it remains to be shown that this minimizer is unique in case of @xmath360 being strictly increasing on the interval @xmath1056 .",
    "if the latter interval equals @xmath358 , then the function @xmath45 is strictly g - convex in @xmath355 , so it follows from theorem  [ thm : mfunc ] and condition   for arbitrary linear subspaces @xmath368 of @xmath10 with @xmath369 that @xmath366 is strictly g - convex .",
    "hence the minimizer @xmath40 is unique , see corollary  [ cor : uniqueness.minimizer ] .",
    "now suppose that @xmath1057 for some @xmath1058 .",
    "writing @xmath148 with @xmath80 , it suffices to show that for any fixed @xmath449 , the function @xmath1059 with @xmath1060 has a unique minimum at @xmath1061 , where @xmath984 , @xmath398 . as shown in the proof of theorem  [ thm : mfunc ]",
    ", @xmath211 is convex , and optimality of @xmath148 implies that @xmath1062 .",
    "it remains to be shown that @xmath1063 recall that @xmath1064 \\ , q_b(dx )          - t \\sum_{i=1}^q \\gamma_i\\ ] ] with @xmath1065 and @xmath986 .",
    "since @xmath1066 for all @xmath355 , the function @xmath108 is convex and strictly increasing .",
    "moreover , @xmath988 is strictly convex unless @xmath229 is an eigenvector of @xmath1067 .",
    "thus @xmath211 is strictly convex , unless @xmath1068 where @xmath1069 . since @xmath1062 , strict convexity of @xmath211 implies .",
    "suppose that is true",
    ". then we may write @xmath1070 with @xmath1071 \\ , q_b(dx )          - \\dim({\\mathbb{v}}(\\gamma_o ) ) u .\\ ] ] note that @xmath1072})_{i=1}^q , \\ ] ] so each function @xmath1073 is convex with @xmath1074 .",
    "consequently it suffices to show that for any @xmath992 , @xmath1075 note that @xmath1076 for some @xmath1077 would imply that @xmath1078 for real numbers @xmath1079 .",
    "but @xmath1080 so @xmath1081 \\ , q_b(dx ) .\\ ] ] the strict monotonicity property of @xmath360 would imply that @xmath1082 for @xmath1083-almost all @xmath1084 .",
    "hence @xmath1085 a contradiction to @xmath1086 . in the latter display we used in the second and in the third step .    concerning part  ( b ) , lemma  [ lem : g - coercivity ] with the modifications mentioned in section  [ subsec : scale - invariance ] and proposition  [ prop : g - coercivity ]  ( b ) imply that @xmath366 is g - coercive on @xmath347 if , and only if , it satisfies the following inequalities : for any @xmath1046 \\in { { \\mathbb{r}}_{\\rm orth}^{q\\times q}}$ ] and @xmath449 with @xmath477 and @xmath1007 , @xmath1087 with @xmath1088 .",
    "if we choose @xmath1089})_{i=1}^q$ ] , then the left hand side of equals @xmath1090 .",
    "note also that all differences @xmath1091 are non - negative . thus is true for arbitrary vectors @xmath449 with non - decreasing components summing to zero if , and only if , @xmath1092 for @xmath1093 .",
    "hence g - coercivity of @xmath366 on @xmath347 is equivalent to for arbitrary linear subspaces @xmath22 with @xmath396 .",
    "note that g - convexity of @xmath1094 would be equivalent to g - gonvexity of @xmath1095 .",
    "now consider @xmath1096 and @xmath1097 with @xmath1098 .",
    "then @xmath1099 but for @xmath600 , the right hand side equals @xmath1100 with @xmath1101 for @xmath1102 .      by definition , the sequence @xmath1103 is non - increasing , and @xmath1104 stays in the compact set @xmath1105 .",
    "suppose @xmath1104 does not converge to @xmath500 .",
    "then there exists a subsequence @xmath1106 with limit @xmath690 .",
    "it follows from continuity of @xmath211 and monotonicity of @xmath1103 that @xmath1107 but this contradicts our assumption of @xmath507 , because @xmath1108 +    recall that for any function @xmath1109)$ ] , @xmath1110 whence @xmath1111 note that @xmath1112 defines a function @xmath1109)$ ] with @xmath1113 moreover , @xmath1114 , @xmath1115 , @xmath1116 and @xmath1117 . but @xmath1118 for some orthogonal matrix @xmath1119 , and @xmath1120 with @xmath1121 and @xmath1122 , so @xmath1123 and @xmath1124 ; see also remark  [ rem : orthogonal transformations ] . thus @xmath1125 +"
  ],
  "abstract_text": [
    "<S> as observed by auderset et al .  </S>",
    "<S> ( 2005 ) and wiesel ( 2012 ) , viewing covariance matrices as elements of a riemannian manifold and using the concept of geodesic convexity provide useful tools for studying @xmath0-estimators of multivariate scatter . in this paper </S>",
    "<S> , we begin with a mathematically rigorous self - contained overview of riemannian geometry on the space of symmetric positive definite matrices and of the notion of geodesic convexity . </S>",
    "<S> the overview contains both a review as well as new results . </S>",
    "<S> in particular , we introduce and utilize first and second order taylor expansions with respect to geodesic parametrizations . </S>",
    "<S> this enables us to give sufficient conditions for a function to be geodesically convex . </S>",
    "<S> in addition , we introduce the concept of geodesic coercivity , which is important in establishing the existence of a minimum to a geodesic convex function . </S>",
    "<S> we also develop a general partial newton algorithm for minimizing smooth and strictly geodesically convex functions . </S>",
    "<S> we then use these results to generate a fairly complete picture of the existence , uniqueness and computation of regularized @xmath0-estimators of scatter defined using additive geodescially convex penalty terms . </S>",
    "<S> various such penalties are demonstrated which shrink an estimator towards the identity matrix or multiples of the identity matrix . </S>",
    "<S> finally , we propose a cross - validation method for choosing the scaling parameter for the penalty function , and illustrate our results using a numerical example .    </S>",
    "<S> [ [ ams - subject - classifications ] ] ams subject classifications : + + + + + + + + + + + + + + + + + + + + + + + + + + + +    62h12 , 65c60 , 90c53 .    [ [ key - words ] ] key words : + + + + + + + + + +    matrix exponential function , matrix logarithm , newton - raphson algorithm , penalization , riemannian geometry , scale invariance , taylor expansion . </S>"
  ]
}