{
  "article_text": [
    "we are interested in solving nonnegative matrix factorization ( nmf ) problems with additional orthogonality constraints . given an @xmath1-by-@xmath2 nonnegative matrix @xmath3 and a factorization rank @xmath0 ( with @xmath4 ) , nmf can be formulated as follows @xmath5 i.e. , find an @xmath1-by-@xmath0 nonnegative matrix @xmath6 and an @xmath0-by-@xmath2 nonnegative matrix @xmath7 such that @xmath8 .",
    "nmf has become a very popular dimensionality reduction technique , and has been used successfully in many applications , see , e.g. , @xcite and the references therein . adding the orthogonality constraint @xmath9 leads to another problem called orthogonal nonnegative matrix factorization ( onmf ) which has tight connections with data clustering ( see section  [ equiv ] ) . in particular",
    ", empirical evidence suggests that this additional orthogonality constraint can improve clustering performance compared to standard nmf or @xmath0-means @xcite .",
    "current approaches to solve onmf problems are typically based on suitable modifications of the algorithms developed for the original nmf problem @xcite .",
    "they enforce nonnegativity of the iterates at each step , and strive to attain orthogonality at the limit ( but never attain exactly orthogonal solutions ) .",
    "in fact , dealing with matrices that are both orthogonal and nonnegative is difficult because the combination of these two properties imposes a sparsity structure that confers a combinatorial aspect to the problem ( directly related to clustering indicator matrices , see section  [ equiv ] ) , which is not easily handled by standard continuous optimization schemes .",
    "the paper is organized as follows . in section  [ equiv ]",
    ", we analyze the relationship between onmf and clustering problems and show that it is closely related to spherical @xmath0-means . based on this analysis",
    ", we develop an em - like algorithm which features a rank - one nmf problem at its core .",
    "section  [ npomf ] introduces another algorithm to perform onmf using an augmented lagrangian and a projected gradient scheme , which enforce orthogonality at each step while obtaining nonnegativity at the limit .",
    "finally , in section  [ nr ] , we experimentally show that our two new approaches perform competitively with standard onmf algorithms on text datasets and on different image decomposition problems .",
    "in this section , we briefly recall how nmf with an additional constraint is equivalent to a fundamental clustering technique : euclidean @xmath0-means @xcite .",
    "we then show that relaxing this constraint leads to onmf , which is therefore not exactly equivalent to @xmath0-means but rather to another problem closely related to spherical @xmath0-means @xcite .",
    "based on this analysis , we propose a new em - like algorithm to solve onmf problems .",
    "let @xmath10 be a nonnegative data matrix whose columns represent a set of @xmath2 points @xmath11 . solving the clustering problem means finding a set @xmath12 of @xmath0 disjoint clusters : @xmath13 @xmath14 such that each cluster @xmath15 contains objects as similar as possible to each other according to some quantitative criterion .",
    "when choosing the euclidean distance , we obtain the @xmath0-means problem , which can be formulated as follows @xcite : @xmath16 @xmath17 equivalently , we can define a binary cluster indicator matrix @xmath18 as follows : @xmath19 disjointness of clusters @xmath15 means that rows of @xmath20 are orthogonal , i.e. , @xmath21 is diagonal .",
    "therefore we can normalize them to obtain an orthogonal matrix @xmath22 ( a weighted cluster indicator matrix ) which satisfies the following condition : @xmath23 it has been shown in @xcite that the nmf problem with matrix @xmath7 satisfying condition : @xmath24 is equivalent to @xmath0-means . in fact , since @xmath7 in problem is a normalized indicator matrix which satisfies @xmath25 , we have @xmath26 which implies that , at optimality , each column @xmath27 of @xmath6 must correspond ( up to a multiplicative factor ) to a cluster centroid with @xmath28 @xmath29 .",
    "let us now define a condition weaker than : @xmath30 it can be easily checked that @xmath31 while @xmath32 .",
    "the difference between conditions and is that condition does not require the rows of @xmath7 to have their non - zero entries equal to each other .",
    "now , if we only impose the weaker condition on nmf , we obtain a relaxed version of which , by definition , corresponds to orthogonal nmf : @xmath33 in the following , we show the equivalence of problem with a particular weighted variant of the spherical @xmath0-means problem .",
    "it is well known that given a pair of solution matrices @xmath34 , one can find solutions with the same objective value @xmath35 by considering the pairs @xmath36 , where @xmath37 is any diagonal matrix with positive diagonal elements . using this property , we can put the problem in a form where each column of matrix @xmath6 has unit @xmath38-norm .",
    "this simply amounts to taking @xmath39 .",
    "therefore , is equivalent to @xmath40 now , assuming we are given the set of non - zero entries of @xmath7 ( in the form of a partitioning @xmath12 such that @xmath41 ) and the cluster directions @xmath27 ( with @xmath42 and @xmath43 ) , the optimal @xmath7 can be computed in closed form .",
    "in fact , because rows of @xmath7 are orthogonal to each other , we have , as before : @xmath44 . for each term",
    "@xmath45 , the optimal @xmath46 is given by : @xmath47 backsubstituting the optimal coefficients in , we can rewrite problem as @xmath48 since the terms @xmath49 are constants , we have that problem is finally equivalent to @xmath50 it is insightful to compare formulation of onmf with the spherical @xmath0-means problem @xcite , which is a variant of @xmath0-means where both data points and centroids are constrained to have unit norm : latexmath:[\\[\\begin{aligned } & \\min_{\\{\\pi_i , u_i\\}_{i=1}^{k } } \\sum_{i=1}^{k}\\sum_{j \\in \\pi_i}\\|\\frac{m_j}{||m_j|| } -   u_i \\|^2 \\ ; \\ ; \\text { s.t . } \\ ; \\ ;      problems and , we are maximizing the cosines of the angles between @xmath27 and the data points from the corresponding cluster .",
    "however , we observe that :    * because of coefficients @xmath52 , problem is sensitive to the norm of the data points , as opposed to spherical @xmath0-means which only depends on their direction ; * even for normalized data points ( i.e. , @xmath53 @xmath54 ) , problem is similar but not equivalent to spherical @xmath0-means because it tries to maximize _ the sum of squares _ of the cosines ( instead of their sum ) .",
    "* contrarily to problem  , spherical @xmath0-means does not require nonnegativity of @xmath27 s , although it will clearly hold at optimality when data points @xmath55 are nonnegative .",
    "to summarize , we have the following result :    for a nonnegative ( not necessarily nonnegative ) if we remove the nonnegativity constraints on matrix @xmath6 in the onmf problem and on vectors @xmath27 in problem . ] data matrix @xmath3 , the onmf problem is equivalent to the weighted variant of spherical @xmath0-means .    to illustrate the differences between these different clustering techniques ,",
    "figure 1 displays a comparison between @xmath0-means , standard spherical @xmath0-means and onmf .",
    "[ compa ]      we present here a simple em - like alternating algorithm designed to solve the onmf problem ( [ eq : jonmf ] ) based on its equivalence with the weighted variant of spherical @xmath0-means .",
    "it is very similar to the standard spherical @xmath0-means algorithm @xcite , except for the computation of cluster centroids .",
    "specifically , it starts with an initial set of centroids , either randomly chosen or supplied as initial values .",
    "it then alternates between two steps :    1 .",
    "given cluster centroids @xmath56 , choose @xmath57 assigning each point to its closest cluster : @xmath58 notice that this step is exactly equivalent to the one of standard spherical @xmath0-means @xcite .",
    "2 .   given the clustering @xmath57 ,",
    "compute the new optimal cluster centroids @xmath56 as follows .",
    "define matrix @xmath59 as the submatrix of @xmath3 containing the columns belonging to cluster @xmath15 .",
    "we have to solve problem with respect to the @xmath27 s : @xmath60 there are @xmath0 independent problems : each @xmath27 must maximize the term @xmath61 .",
    "the optimal solution @xmath62 is given by the dominant left singular vector of @xmath63 associated with the largest singular value @xmath64 of @xmath63 : @xmath65 for which we have @xmath66 .",
    "moreover , since @xmath67 , the perron - frobenius theorem guarantees that @xmath62 can always be chosen to be nonnegative .",
    "algorithm  [ algomod ] , referred to as em - onmf , implements this procedure .",
    "we will see in the last section that , despite its simplicity , it seems to work well for text clustering tasks .",
    "[ algomod ]    it is interesting to relate this with the original onmf problem : given a partitioning @xmath12 , let us denote @xmath68 the subvector containing only the positive entries of the @xmath69 row of @xmath7",
    ". then , @xmath70 so that the optimal ( @xmath27,@xmath71 ) must be an optimal solution of @xmath72 each of these problems looks for the best nonnegative rank - one approximation of a nonnegative matrix ( i.e. , a rank - one nmf problem )",
    ". this in turn can be solved by combining the eckart - young and perron - frobenius theorems : taking the first rank - one factor generated by the singular value decomposition ( svd ) ( making sure it is nonnegative in case of non - uniqueness ) leads to a minimum value for equal to @xmath73 .",
    "therefore , solving onmf amounts to finding a partitioning @xmath12 such that the sum of squares of the first singular values of submatrices @xmath63 s is maximized , i.e. , the onmf problem is equivalent to @xmath74 .",
    "in this section , we present an alternative approach to solve onmf problems . typically , onmf algorithms strictly enforce nonnegativity for each iterate while trying to achieve orthogonality at the limit .",
    "this can be done using a proper penalization term @xcite , a projection matrix formulation @xcite or by choosing a suitable search direction @xcite .",
    "we propose here a method working the opposite way : at each iteration , a ( continuous ) projected gradient scheme is used to ensure that the @xmath7 iterates are orthogonal ( but not necessarily nonnegative ) .",
    "nonnegativity constraints in the onmf formulation will be handled using the following augmented lagrangian , defined for a matrix of lagrange multipliers @xmath75 associated to the nonnegativity constraints : @xmath76 where @xmath77 is the quadratic penalty parameter .",
    "ideally , we would like to solve the lagrangian dual @xmath78 function @xmath79 is concave and its maximization ( over a convex set ) is then a convex problem , see , e.g. , @xcite .",
    "however , evaluating @xmath79 exactly ( i.e. , computing an optimal pair @xmath80 and @xmath81 ) is non - trivial and we propose here instead a simple alternating scheme to update variables @xmath6 , @xmath7 and @xmath82 :    1 .   for @xmath7 and @xmath82 fixed ,",
    "the optimal @xmath6 can be computed by solving a nonnegative least squares problem @xmath83 we use the efficient active - set method proposed in @xcite .",
    "2 .   for @xmath6 and @xmath82 fixed , we update matrix @xmath7 by means of a projected gradient scheme . computing the projection of a matrix @xmath84 onto the feasible set of orthogonal matrices , known as the stiefel manifold orthogonal matrices , i.e. , st(@xmath0,@xmath2 ) @xmath85}. ]",
    ", amounts to solving the following problem : @xmath86 whose optimal solution @xmath87 can be computed in closed form from the unitary factor of a polar decomposition of @xmath84 , see , e.g. , @xcite .",
    "our projected gradient scheme then reads : @xmath88 where the step length @xmath89 is chosen with a backtracking line search similar to that in @xcite ( step length is increased as long as there is a decrease in the objective function , and decreased otherwise ) .",
    "3 .   finally",
    ", the lagrange multipliers are updated in order to penalize the negative values of @xmath7 : @xmath90 where @xmath91 is a predefined sequence of step lengths decreasing to zero ( e.g. , @xmath92 where @xmath93 is the iterations count and @xmath94 is a constant parameter ) .",
    "this can be recognized as an ( approximate ) subgradient - type scheme @xcite ( in fact , one can check that @xmath95 is a subgradient of @xmath96 at @xmath82 when @xmath97 ) .",
    "to initialize the algorithm , we set @xmath82 to zero and choose for the columns of @xmath7 the first @xmath0 right singular vectors of the data matrix @xmath3 ( which can be obtained with svd ) , we flip its sign if the @xmath38-norm of its negative entries is larger than the @xmath38-norm of its positive entries . ] .",
    "quadratic penalty parameter @xmath77 is initially fixed to a given small value @xmath98 and then increased after each iteration .",
    "[ onpmf ] implements this procedure , which we refer to as orthogonal nonnegatively penalized matrix factorization ( onp - mf ) .",
    "initialize @xmath99 , the rows of @xmath100 with the first @xmath0 right singular vectors of @xmath3 , and @xmath101 .",
    "we observed that the term @xmath102 decreases linearly to zero ( as augmented lagrangian methods are expected to , see ( * ? ? ? * th .",
    "17.2 ) ) while @xmath103 converges to a fixed value , see figure  [ conv ] for an example on the hubble dataset ( cf .",
    "section  [ hu ] ) .",
    "a rigorous convergence proof is a topic for further research .    [ cols=\"^,^,^ \" , ]",
    "in this paper , we have studied the onmf problem and showed its equivalence with a weighted variant of spherical @xmath0-means .",
    "this led us to design a new em - like algorithm for solving onmf problems ( alg .",
    "[ emonmf ] ) . we have also proposed an alternative approach based on an augmented lagrangian method imposing orthogonality at each step while relaxing the nonnegativity constraint ( alg .",
    "[ onpmf ] ) .",
    "we finally showed on some text and image datasets that these new techniques compare favorably with existing onmf algorithms .",
    "our onp - mf algorithm is by far the most robust : it always gave very good results , the best in many cases , using only one initialization .",
    "in particular , a single ( deterministic ) run of onp - mf worked better in all image experiments than the other algorithms , despite the fact that they were allowed to keep the best solution obtained from 30 different ( random ) initializations .",
    "further work includes improving its computational efficiency , on which we are currently working using more sophisticated optimization techniques .",
    "a.  banerjee , i.  dhillon , j.  ghosh , and s.  sra , _ generative model - based clustering of directional data _ , in pro .",
    "of the ninth acm sigkdd int .",
    "conf . on knowledge discovery and data mining ( 2003 ) , pp .",
    "1928 .              c.  ding , t.  li , w.  peng , and h.  park , _ orthogonal nonnegative matrix tri - factorizations for clustering _ , in proc . of the twelfth acm sigkdd int",
    "conf . on knowledge discovery and data mining ( 2006 ) , pp .",
    "126135 .",
    "z.  guo , t.  wittman , and s.  osher , _",
    "l1 unmixing and its application to hyperspectral image enhancement _",
    "spie conf . on algorithms and technologies for multispectral , hyperspectral , and ultraspectral imagery xv ( 2009 ) .",
    "j.  kim and h.  park , _ nonnegative matrix factorization based on alternating nonnegativity constrained least squares and active set method _ , siam j. matrix analysis applications 30(2 ) ( 2008 ) , pp ."
  ],
  "abstract_text": [
    "<S> approximate matrix factorization techniques with both nonnegativity and orthogonality constraints , referred to as orthogonal nonnegative matrix factorization ( onmf ) , have been recently introduced and shown to work remarkably well for clustering tasks such as document classification . in this paper , we introduce two new methods to solve onmf . </S>",
    "<S> first , we show mathematical equivalence between onmf and a weighted variant of spherical @xmath0-means , from which we derive our first method , a simple em - like algorithm . our second method is based on an augmented lagrangian approach . </S>",
    "<S> standard onmf algorithms typically enforce nonnegativity for their iterates while trying to achieve orthogonality at the limit ( e.g. , using a proper penalization term or a suitably chosen search direction ) . </S>",
    "<S> our method works the opposite way : orthogonality is strictly imposed at each step while nonnegativity is asymptotically obtained , using a quadratic penalty . </S>",
    "<S> finally , we show that the two proposed approaches compare favorably with standard onmf algorithms on both text and image datasets . </S>"
  ]
}