{
  "article_text": [
    "the multiple descriptions ( md ) problem has been studied extensively since late 1970s , see @xcite and the references therein . in a @xmath1descriptions md setup",
    ", the encoder sends @xmath2 packets ( descriptions ) which are sent to the receiver over @xmath2 different channels . in the most general setting",
    ", it is assumed that the decoder receives a subset of the descriptions without any error and the remaining are completely lost .",
    "the decoder reconstructs the source upto a given level of distortion when a subset of the descriptions are received .",
    "the goal of the md problem is to establish the complete rate - distortion region to trade - off the encoding rates to the achievable distortions .",
    "the general setup has remained challenging and unsolved due to the intricacies of the problem in maintaining the balance between the full reconstruction quality versus quality of individual descriptions .    until recently , for general sources and distortion measures , the most recognized achievable rate - distortion region for the @xmath1channel md setup was due to venkataramani , kramer and goyal ( vkg ) @xcite , whose encoding scheme builds on the prior work for the 2-channel case by el - gamal and cover ( ec ) @xcite and zhang and berger ( zb ) @xcite .",
    "the vkg scheme involves a combinatorial number of refinement codebooks along with a single shared codebook used to control the redundancy across the descriptions .",
    "we introduced a new encoding scheme in @xcite involving ` combinatorial message sharing ' ( cms ) which differs from the vkg scheme primarily in the number of shared codebooks .",
    "the cms scheme allows for every subset of the descriptions to share a different common codebook , thereby leading to a combinatorial number of shared messages . at the time of submission of @xcite",
    ", it was not known whether the cms scheme leads to a strictly improved rate - distortion region over the vkg scheme . in this paper ,",
    "our objective is to prove by example that the new region is indeed strictly better .",
    "specifically , we show that for a binary symmetric source under hamming distortion measure , the cms scheme achieves points outside the vkg region @xmath3 .",
    "in fact , more generally , our result holds @xmath3 for any source and distortion measures for which the zb scheme achives points outside the ec scheme for the corresponding 2-descriptions problem .",
    "we note in passing that , other encoding schemes have been proposed in the literature for certain special cases ( specific sources and distortion measures ) of the @xmath1channel md setup @xcite , which achieve points outside @xmath4 .",
    "however , none of these schemes have been proven to subsume or outperform @xmath4 for general sources and distortion measures .",
    "the potential implications of our results on these coding schemes are beyond the scope of this paper . in the following section , we formally state the @xmath1channel md setup and describe the prior results due to ec @xcite , zb @xcite , vkg @xcite and the cms scheme @xcite . in section [ sec :",
    "proof - of - strict ] , we prove the strict improvement of the achievable region .",
    "we follow the notation in @xcite .",
    "a source produces @xmath5 iid copies , denoted by @xmath6 , of a generic random variable @xmath7 taking values in a finite alphabet @xmath8 .",
    "we denote @xmath9 .",
    "there are @xmath2 encoding functions , @xmath10 , which map @xmath11 to the descriptions @xmath12 , where @xmath13 for some @xmath14 .",
    "the rate of description @xmath15 is defined as @xmath16 .",
    "each of the descriptions are sent over a separate channel and are either received at the decoder error free or are completely lost .",
    "there are @xmath17 decoding functions for each possible received combination of the descriptions @xmath18 , @xmath19 , where @xmath20 takes on values on a finite set @xmath21 , and @xmath22 denotes the null set . when a subset @xmath23 of the descriptions are received at the decoder , the distortion is measured as @xmath24 $ ] for some bounded distortion measures @xmath25 defined as @xmath26 .",
    "we say that a rate - distortion tuple @xmath27 is achievable if there exit @xmath2 encoding functions with rates @xmath28 and @xmath17 decoding functions yielding distortions @xmath29 .",
    "the closure of the set of all achievable rate - distortion tuples is defined as the ` _ _ @xmath2-channel multiple descriptions rd region _ _ ' .",
    "note that , this region has @xmath30 dimensions .    in what follows , @xmath31 denotes the set of all subsets ( power set ) of any set @xmath32 and @xmath33 denotes the set cardinality .",
    "note that @xmath34 .",
    "@xmath35 denotes the set complement . for two sets @xmath36 and @xmath37",
    ", we denote the set difference by @xmath38 .",
    "we use the shorthand @xmath39 for @xmath40 and @xmath41 .",
    "@xmath39 is a set of variables , whereas @xmath41 is a single variable . ] .      )",
    "indicates ` common random variable ' .",
    "red ( @xmath42 ) indicates ` base layer random variables ' and white ( @xmath41 @xmath43 ) indicates ` refinement random variables ' .",
    "the arrow indicates the order of codebook generation.[fig : vkg ] ]    the achievable region of @xcite is denoted here @xmath4 and is described as follows .",
    "let @xmath44 be any set of @xmath45 random variables distributed jointly with @xmath7 .",
    "then , an rd tuple is said to be achievable if there exist functions @xmath46 such that:@xmath47\\label{eq : vkg}\\end{aligned}\\ ] ] @xmath48 .",
    "the closure of the achievable tuples over all such @xmath45 random variables gives @xmath4 .",
    "here , we only present an overview of the encoding scheme . the order of codebook generation of the auxiliary random variables is shown in figure [ fig : vkg ] .",
    "first , @xmath49 codewords of @xmath50 are generated using the marginal distribution of @xmath50 .",
    "conditioned on each codeword of @xmath50 , @xmath51 codewords of @xmath52 are generated according to their respective conditional densities .",
    "next , for each @xmath53 , a single codeword is generated for @xmath54 conditioned on @xmath55 @xmath56 .",
    "note that to generate the codebook for @xmath57 , we first need the codebooks for all @xmath58 and @xmath50 .    on observing a typical sequence @xmath59 , the encoder tries to find a jointly typical codeword tuple one from each codebook .",
    "codeword index of @xmath52 ( at rate @xmath60 ) is sent in description @xmath15 .",
    "along with the ` _ _ private _ _ ' messages , each description also carries a ` _ _ shared message _ _ ' at rate @xmath61 , which is the codeword index of @xmath50",
    ". hence the rate of each description is @xmath62 .",
    "vkg showed that , to ensure finding a set of jointly typical codewords with the observed sequence , the rates must satisfy ( [ eq : vkg_rate ] ) .",
    "it then follows from standard arguments ( see for example `` typical average lemma '' @xcite ) that , if the random variables also satisfy ( [ eq : vkg ] ) , then the distortion constraints are met .",
    "note that , @xmath50 is the _ only _ shared random variable . @xmath63 form the base layer random variables and all @xmath64 form the refinement layers .",
    "observe that the codebook generation follows the order : shared layer @xmath65 base layer @xmath65 refinement layer .",
    "the vkg scheme for the 2-descriptions scenario involves 4 auxiliary random variables @xmath66 and @xmath67 .",
    "the vkg region was originally derived as an extension of the ec @xcite and zb @xcite coding schemes , which were designed for the 2-descriptions scenario .",
    "the first of the two regions was by el - gamal and cover and their rate region ( denoted here by @xmath68 ) is obtained by setting @xmath69 in @xmath4 , where @xmath70 is a constant .",
    "zhang and berger ( their region is denoted here by @xmath71 ) later showed that , including the shared random variable can give strict improvement over @xmath68 .",
    "their result , while perhaps counter - intuitive at first , clarifies the fact that , a shared message among the descriptions helps to better coordinate the messages , thereby providing a strictly improved rd region , even though it introduces redundancy .",
    "we will describe their result in detail in section [ sec : proof - of - strict ] , as our example builds upon theirs . however , it is known that @xmath68 is complete for some special cases of the setup ( see for example @xcite ) .      ]    in this section , we briefly describe our cms encoding scheme in @xcite .",
    "the vkg encoding scheme employs _",
    "one _ common codeword ( @xmath50 ) that is sent in all the @xmath2 descriptions .",
    "however , when dealing with @xmath72 descriptions , restricting to a single shared message could be suboptimal .",
    "the cms scheme therefore allows for ` combinatorial message sharing ' , i.e a common codeword is sent in each ( non - empty ) subset of the descriptions . before describing the codebook generation and stating the theorem , we define the following subsets of @xmath73:@xmath74 let @xmath75 be any non - empty subset of @xmath76 with @xmath77 . we define the following subsets of @xmath78 and @xmath79:@xmath80 we also define to mean @xmath81 is subsumed in @xmath75 and @xmath82 to mean strictly subsumed.]:@xmath83    the shared random variables are denoted by ` @xmath84 ' .",
    "the base and the refinement layer random variables are denoted by ` @xmath85 ' .",
    "the codebook generation is done in an order as shown in figure [ fig : l_channel_cms ] .",
    "first , the codebook for @xmath50 is generated .",
    "then , the codebooks for @xmath86 , @xmath87 are generated in the order @xmath88 .",
    "@xmath89 codewords of @xmath90 are independently generated conditioned on each codeword tuple of @xmath91 .",
    "this is followed by the generation of the base layer codebooks , i.e. @xmath52 , @xmath92 .",
    "conditioned on each codeword tuple of @xmath93 , @xmath51 codewords of @xmath52 are generated independently . then the codebooks for the refinement layers are formed by generating a single codeword for @xmath94 conditioned on every codeword tuple of @xmath95 .",
    "observe that the base and the refinement layers in the cms scheme are similar to that in the vkg scheme , except that they are now generated conditioned on a subset of the shared codewords .",
    "the encoder employs joint typicality encoding , i.e. , on observing a typical sequence @xmath59 , it tries to find a jointly typical codeword tuple , one from each codebook .",
    "as with the vkg scheme , the codeword index of @xmath52 ( at rate @xmath60 ) is sent in description @xmath15 .",
    "however , now the codeword index of @xmath86 ( at rate @xmath96 ) is sent in _ all _ the descriptions @xmath97 .",
    "therefore the rate of description @xmath15 is:@xmath98 we next state the main result in @xcite which describes a new region for the @xmath1channel md setup achievable by the cms scheme .",
    "let @xmath99 be any set of @xmath100 random variables jointly distributed with @xmath7 .",
    "we define the quantities @xmath101 and @xmath102 as follows :    @xmath103    we follow the convention @xmath104 .",
    "let @xmath105 @xmath106 and @xmath60 @xmath107 be any set of rate tuples satisfying:@xmath108 then , the rd region for the @xmath1channel md problem contains the rates and distortions for which there exist functions @xmath46 , such that @xmath109\\label{eq : dist_condition_thm}\\end{aligned}\\ ] ] the closure of the achievable tuples over all such @xmath100 random variables is denoted by @xmath110 .",
    "observe that both the vkg and the cms schemes are same as the zb scheme for 2 descriptions scenario .",
    "note that , the total number of auxiliary random variables in the cms scheme is almost twice that in the vkg scheme ( which already is exponential in @xmath2 ) . at the time of submission of @xcite , it was yet unclear if this increase pays off with an improved achievable region . the following theorem , being the main contribution of this paper , establishes that there exists scenarios for which @xmath110 is strictly larger than @xmath4 .",
    "\\(i ) the rate - distortion region achievable by the cms scheme is always at least as large as the region achievable by the vkg region , i.e.:@xmath111 ( ii ) there exists scenarios for which the cms scheme leads to a region strictly larger than that achievable by the vkg scheme , i.e.:@xmath112 specifically , for a binary symmetric source under hamming distortion measure , the cms scheme achieves a strictly larger rate - distortion region compared to the vkg scheme @xmath3 .",
    "part ( i ) of the theorem is rather simple to prove and is a straight forward corollary of the main theorem in @xcite .",
    "it follows directly by setting @xmath113 @xmath114 such that @xmath115 in @xmath110 .",
    "we then have @xmath116 @xmath117 . substituting in ( [ eq : rate_condition_thm ] )",
    ", we get @xmath118 which is same as ( [ eq : vkg ] ) .",
    "we prove ( ii ) by considering the binary symmetric source example for which the cms scheme achieves points which can not be achieved by the vkg scheme .",
    "note that , once we prove that the cms scheme achieves a strictly larger region for some @xmath119 , then it must be true for all @xmath120 .",
    "hence to prove ( ii ) , it is sufficient for us to show that it is true for @xmath121 .",
    "however , we first include an example for @xmath122 for building intuition and understanding of the type of scenarios where the cms scheme provides strict improvement",
    ". then we will prove the result for @xmath121 .",
    "we also note that obviously scenarios exit for which @xmath123 ( for example when @xmath4 is complete @xcite ) .",
    "finding the set of all such scenarios is an interesting problem in itself and is beyond the scope of this paper . to describe our example ,",
    "we require certain results pertaining to binary multiple descriptions @xcite and successive refinement of binary sources @xcite . in what follows , we state these results .    *",
    "the zhang - berger example * : zhang and berger proved that , for the binary symmetric 2-descriptions md problem under hamming distortion measure , sending a common codeword in both the descriptions provides a strict improvement over the ec scheme .",
    "we briefly describe their result .",
    "note that the rate - distortion region has 5 dimensions denoted by @xmath124 ) .",
    "denote the rate - distortion region achievable by the ec scheme by @xmath125 and the corresponding region achievable by the zb scheme ( i.e. achieved by adding a common codeword among the two descriptions ) by @xmath126 .",
    "obviously @xmath127 , as we can always choose not to send any common codeword in the zb scheme .",
    "denote by @xmath128 the following cross section of @xmath125:@xmath129 similarly , denote by @xmath130 , the corresponding cross section of @xmath131 . to show that @xmath132 , they considered a particular joint probability mass function ( pmf ) @xmath133",
    "let us denote the achievable region associated with this pmf by @xmath134 and the corresponding cross - section ( [ eq : ec_crosssection ] ) by @xmath135 .",
    "they showed that @xmath136 such that @xmath137 .",
    "we refer the reader to @xcite for a detailed derivation and the values of @xmath138 and @xmath139 .",
    "* successive refinement * : the problem of successive refinement was first proposed by equitz and cover in @xcite and has since then been studied extensively by information theorists @xcite .",
    "the problem is motivated by scalable coding , where the encoder generates two layers of information called the base layer and the enhancement layer .",
    "the base layer provides a coarse reconstruction of the source , while the enhancement layer is used to ` refine ' the reconstruction beyond the base layer .",
    "the objective is to encode the two layers such that the distortion at both the base and the enhancement layers are optimal .",
    "this setup is shown schematically in figure [ fig : successive - refinement - setup ] .",
    "observe that , the 2-layer successive refinement region is indeed a special case ( the cross - section @xmath140 ) of the 2-descriptions md setup where the distortion constraint on one of the individual descriptions is removed .",
    "the complete rate region for successive refinement was derived in @xcite where it was shown that the ec coding scheme achieves the complete rate region .",
    "an interesting followup question is that of ` _ _ successive refinability _ _ ' of sources .",
    "assume @xmath141 , then a source is said to be successively refinable under @xmath142 if @xmath143 , the rate point @xmath144 is achievable , where @xmath145 denotes shannon s rate distortion function .",
    "this condition implies that there is no loss in describing the source in two successive parts . an important point to note",
    "is that , for a successively refinable source , when the encoder operates at @xmath146 , there is _ absolutely no redundancy _ between the two layers of information , i.e. , the _ two layers can not carry a common codeword_. we finally note that a binary symmetric source is successively refinable under hamming measure @xcite .    * proof of ( ii ) : @xmath147 * : consider a 4-descriptions md problem for a binary symmetric source ( @xmath148 ) under hamming distortion measure .",
    "the rate - distortion region consists of 19 dimensions .",
    "we denote the region achievable by the vkg scheme by @xmath149 and that achievable using the cms scheme by @xmath150 .",
    "we now consider a particular cross - section of these regions where we apply constraints only on @xmath151 and @xmath152 .",
    "we remove the constraints on all other distortions , i.e. we set @xmath153 and @xmath154 to @xmath155 .",
    "equivalently , we can think of a 4 descriptions md problem with a particular channel failure pattern , wherein only one of the following sets of descriptions can reach the decoder reliably : @xmath156 as shown in figure [ fig : example - to - demonstrate ] .",
    "we denote the set of all achievable points for this setup using the vkg and the cms schemes by @xmath157 and @xmath158 respectively .",
    "note that , this equivalent model is used simply for analysis purposes , while we are actually interested in a cross section of the general binary symmetric 4-descriptions region .",
    "observe that , with respect to the first 2 descriptions , we have a simple 2-descriptions problem and with respect to the last 2 descriptions , we have a successive refinement problem . extending the arguments of zhang and berger , we define the following infimum of @xmath157 : @xmath159 denote the corresponding infimum of @xmath158 by @xmath160 .",
    "recall that the vkg scheme forces all the descriptions to have a single common codeword .",
    "constraints @xmath161 and @xmath162 ensure that descriptions 3 and 4 carry completely complementary information , i.e. they _ can not _ carry a common codeword .",
    "is in fact redundant .",
    "just the constraint @xmath162 is sufficient to establish that descriptions 3 and 4 can not carry a common codeword . however , as a binary source is successively refinable , we can always achieve @xmath163 and hence the constraint @xmath161 gets applied implicitly once we apply @xmath162 .",
    "this implies that , the gains due to the cms scheme are not only restricted to successively refinable sources .",
    "in fact , the cms scheme can achieve points outside the vkg region for any source and distortion measure for which the zb scheme achieves points outside the ec scheme for the corresponding 2-descriptions setup . ] as vkg coding scheme forces the _ same common codeword _",
    "among all the 4 descriptions , it follows that:@xmath164 on the other hand , the cms scheme allows for distinct common codewords to be sent in each subset of the descriptions .",
    "hence , we can send a common codeword only among the two descriptions 1 and 2 while still maintaining @xmath165 .",
    "this is achieved by setting all the common random variables to @xmath70 except @xmath166 , which has joint pmf @xmath138 with @xmath167 .",
    "this allows us to achieve : @xmath168 this implies that @xmath169 and hence @xmath170 .",
    "this example clearly illustrates the freedom the cms scheme exhibits in controlling the redundancy across the messages .    * @xmath171 * : in similar lines to the 4-descriptions case , we next consider a 3-descriptions md problem for a binary symmetric source under hamming distortion measure .",
    "let the achievable regions be denote by @xmath172 and @xmath173 respectively .",
    "we consider the cross - sections of the achievable regions where we apply constraints only on @xmath174 and @xmath175 as shown in figure [ fig:3d_eg ] .",
    "we denote these cross - sections by @xmath176 and @xmath177 respectively .",
    "now consider any point @xmath178 such that @xmath179 and @xmath180 , where for two sets @xmath81 and @xmath75 , @xmath181 . from the results of zhang and berger , if @xmath179 , descriptions 1 and 2 _ must _ carry a common codeword .",
    "let the rate of the common codeword be @xmath182 .",
    "vkg scheme forces this codeword to be sent as part of @xmath183 as well . as this common codeword",
    "is received as part of both descriptions 1 and 3 , it is redundant in @xmath183 to achieve @xmath175 .",
    "this implies that @xmath184 .",
    "as there exit points in the boundary of @xmath172 which satisfy @xmath179 , the cms scheme achieves points outside the vkg scheme .",
    "hence , we have shown that for a binary symmetric source under hamming distortion measure , the cms scheme achieves a strictly larger rate - distortion region than the vkg scheme for all @xmath72 .",
    "we recently proposed a new encoding scheme for the general @xmath1channel multiple descriptions problem involving ` _ _ combinatorial message sharing _ _ ' ( cms ) which leads to a new achievable region subsuming the most well known region for this problem by venkataramani , kramer and goyal ( vkg ) @xcite for general sources and distortion measures . in this paper",
    ", we showed that there exists scenarios ( particularly for a binary symmetric source under hamming distortion measure ) for which , the new region is strictly larger than that achievable by the vkg scheme .",
    "as part of future work , we will investigate under what scenarios the cms scheme achieves the complete rd region .",
    "j. wang , j. chen , l. zhao , p. cuff , and h. permuter ,  a random variable substitution lemma with applications to multiple description coding , preprint .",
    "[ online ] .",
    "available : http://arxiv.org/abs/0909.3135 .",
    "k. viswanatha , e. akyol and k. rose , `` combinatorial message sharing for a refined multiple descriptions achievable region , '' to appear at the proceedings of ieee international symposium on information theory ( isit ) 2011 .",
    "submitted version available at : http://www.scl.ece.ucsb.edu/kumar/isit_md_sub.pdf"
  ],
  "abstract_text": [
    "<S> we recently proposed a new coding scheme for the l - channel multiple descriptions ( md ) problem for general sources and distortion measures involving ` combinatorial message sharing ' ( cms ) @xcite leading to a new achievable rate - distortion region . </S>",
    "<S> our objective in this paper is to establish that this coding scheme strictly subsumes the most popular region for this problem due to venkataramani , kramer and goyal ( vkg ) @xcite . in particular , we show that for a binary symmetric source under hamming distortion measure , the cms scheme provides a strictly larger region for all l@xmath0 . </S>",
    "<S> the principle of the cms coding scheme is to include a common message in every subset of the descriptions , unlike the vkg scheme which sends a single common message in all the descriptions . </S>",
    "<S> in essence , we show that allowing for a common codeword in every subset of descriptions provides better freedom in coordinating the messages which can be exploited constructively to achieve points outside the vkg region .    </S>",
    "<S> multiple descriptions coding , source coding , rate distortion theory </S>"
  ]
}