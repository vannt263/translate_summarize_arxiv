{
  "article_text": [
    "( rs ) codes are among the most popular error - correcting codes in communication and data storage systems .",
    "an @xmath0 rs code of length @xmath1 and dimension @xmath2 is a maximum distance separable ( mds ) linear code with minimum distance @xmath3 .",
    "rs codes have efficient hard - decision decoding ( hdd ) algorithms , such as the berlekamp - massey ( bm ) algorithm , which can correct up to @xmath4 errors .    since the discovery of rs codes @xcite",
    ", researchers have spent a considerable effort on improving the decoding performance at the expense of complexity . a breakthrough result of guruswami and sudan ( gs ) introduced an algebraic hard - decision list - decoding algorithm , based on bivariate interpolation and factorization , that can correct errors well beyond half the minimum distance of the code @xcite .",
    "nevertheless , hdd algorithms do not fully exploit the information provided by the channel output .",
    "koetter and vardy ( kv ) later extended the gs decoder to an algebraic soft - decision ( asd ) decoding algorithm by converting the probabilities observed at the channel output into algebraic interpolation conditions in terms of a multiplicity matrix @xcite .",
    "the gs and kv algorithms , however , have significant computational complexity . therefore , multiple runs of errors - and - erasures and errors - only decoding with some low - complexity algorithm , such as the bm algorithm , has renewed the interest of researchers .",
    "these algorithms use the soft - information available at the channel output to construct a set of either erasure patterns @xcite , test patterns @xcite , or patterns combining both @xcite and then attempt to decode using each pattern .",
    "techniques have also been introduced to lower the complexity per decoding trial in @xcite .",
    "other soft - decision decoding algorithms for rs codes include @xcite that use the binary expansion of rs codes to work on the bit - level . in @xcite , belief propagation is run while the parity - check matrix is iteratively adapted on the least reliable basis .",
    "meanwhile , @xcite adapts the generator matrix on the most reliable basis and uses reprocessing techniques based on ordered statistics .    in the scope of multiple errors - and - erasures decoding ,",
    "there have been several algorithms proposed that use different erasure codebooks ( i.e. , different sets of erasure patterns ) . after running the errors - and - erasures decoding algorithm multiple times , each time using one erasure pattern in the set ,",
    "these algorithms produce a list of candidate codewords , whose size is usually small , and then pick the best codeword on this list . the common idea of constructing the set of erasure patterns in these multiple errors - and - erasures decoding algorithms is to erase some of the least reliable symbols since those symbols are more prone to be erroneous .",
    "the first algorithm of this type is called generalized minimum distance ( gmd ) @xcite and it repeats errors - and - erasures decoding while successively erasing an even number of the least reliable positions ( lrps ) ( assuming that @xmath5 is odd ) . more recent work by lee and kumar @xcite proposes a soft - information successive ( multiple ) error - and - erasure decoding ( sed ) that achieves better performance but also increases the number of decoding attempts .",
    "literally , the lee - kumar s sed@xmath6 algorithm runs multiple errors - and - erasures decoding trials with every combination of an even number @xmath7 of erasures within the @xmath8 lrps .",
    "a natural question that arises is how to construct the `` best '' set of erasure patterns for multiple errors - and - erasures decoding .",
    "inspired by this , we first develop a rate - distortion ( rd ) framework to analyze the asymptotic trade - off between performance and complexity of multiple errors - and - erasures decoding of rs codes .",
    "the main idea is to choose an appropriate distortion measure so that the decoding is successful if and only if the distortion between the error pattern and erasure pattern is smaller than a fixed threshold .",
    "after that , a set of erasure patterns is generated randomly ( similar to a random codebook generation ) in order to minimize the expected minimum distortion .",
    "one of the drawbacks in the rd approach is that the mathematical framework is only valid as the block - length goes to infinity .",
    "therefore , we also consider the natural extension to a rate - distortion exponent ( rde ) approach that studies the behavior of the probability , @xmath9 , that the transmitted codeword is not on the list as a function of the block - length @xmath1 .",
    "the overall error probability can be approximated by @xmath9 because the probability that the transmitted codeword is on the list but not chosen is very small compared to @xmath9 .",
    "hence , our rde approach essentially focuses on maximizing the exponent at which the error probability decays as @xmath1 goes to infinity .",
    "the rde approach can also be considered as the generalization of the rd approach since the latter is a special case of the former when the rate - distortion exponent tends to zero . using the rde analysis",
    ", this approach also helps answer the following two questions : ( i ) what is the minimum error probability achievable for a given number of decoding attempts ( or a given size of the set of erasure patterns ) ?",
    "( ii ) what is the minimum number of decoding attempts required to achieve a certain error probability ?",
    "the rd and rde approaches are also extended beyond conventional errors - and - erasures decoding to analyze multiple - decoding for decoding schemes such as asd decoding .",
    "it is interesting to note that the rde approach for asd decoding schemes contains the special case where the codebook has exactly one entry ( i.e. , asd decoding is run only once ) . in this case",
    ", the distribution of the codebook that maximizes the exponent implicitly generates the optimal multiplicity matrix .",
    "this is similar to the line of work @xcite where various researchers solve for a multiplicity matrix that minimizes the error probability obtained by either using a gaussian approximation @xcite , applying a chernoff bound @xcite , or using sanov s theorem @xcite .",
    "finally , we propose a family of multiple - decoding algorithms based on these two approaches that achieve better performance - versus - complexity trade - off than other algorithms .",
    "the paper is organized as follows . in section  [ sec : multiplebma ] , we design an appropriate distortion measure and present a rate - distortion framework , for both the rd and rde approaches , to analyze the performance - versus - complexity trade - off of multiple errors - and - erasures decoding of rs codes .",
    "also in this section , we propose a general multiple - decoding algorithm that can be applied to errors - and - erasures decoding .",
    "then , in section  [ sec : computing - rd ] , we discuss numerical computations of rd and rde functions together with their complexity analyses which are needed for the proposed algorithm . in section  [ sec : multiple asd ] , we analyze both bit - level and symbol - level asd decoding and design distortion measures compatible with the general algorithm .",
    "a closed - form analysis of some rd and rde functions is presented in section  [ sec : closed - form - analysis - of ] .",
    "next , in section  [ sec : ext - and - gen ] , we offer some extensions that combine covering codes with random codes and also consider the case of a single decoding attempt .",
    "simulation results are presented in section  [ sec : simulation - results ] and , finally , conclusions are provided in section  [ sec : conclusion ] .",
    "in this section , we first set up a rate - distortion framework to analyze multiple attempts of conventional hard decision errors - and - erasures decoding .",
    "let @xmath10 with @xmath11 be the galois field with @xmath12 elements denoted as @xmath13 .",
    "we consider an @xmath0 rs code of length @xmath1 , dimension @xmath2 over @xmath10 .",
    "assume that we transmit a codeword @xmath14 over some channel and receive a vector @xmath15 where @xmath16 is the received alphabet for a single rs symbol . while our approach can be applied to much more general channels , our simulations focus on the additive white gaussian noise ( awgn ) channel and two common modulation formats , namely bpsk and @xmath12-qam .",
    "correspondingly , we use @xmath17 for bpsk and @xmath18 for @xmath12-qam . for each codeword index @xmath19 ,",
    "let @xmath20 be the permutation given by sorting @xmath21 in decreasing order so that @xmath22 . then , we can specify @xmath23 as the @xmath24-th most reliable symbol for @xmath25 at codeword index @xmath19 . to obtain the reliability of the codeword positions ( indices )",
    ", we construct the permutation @xmath26 given by sorting the probabilities @xmath27 of the most likely symbols in increasing order .. ] thus , codeword position @xmath28 is the @xmath19-th lrp .",
    "these above notations will be used throughout this paper .    consider @xmath29 and @xmath30 .",
    "assume that we have the probability @xmath31 written in a matrix form as follows:@xmath32_{j , i}.\\ ] ] then @xmath33 , @xmath34 , @xmath35 and @xmath36 .",
    "[ con : bmaerr - n - era](classical decoding threshold , see @xcite ) : if @xmath37 symbols are erased , a conventional hard - decision errors - and - erasures decoder such as the bm algorithm is able to correct @xmath38 errors in unerased positions if and only if @xmath39      [ def:(conv .",
    "patterns)](conventional error patterns and erasure patterns ) we define @xmath40 and @xmath41 as an error pattern and an erasure pattern respectively , where @xmath42 means that an error occurs ( i.e. , the most likely symbol is incorrect ) and @xmath43 means that the symbol at index @xmath19 is erased ( i.e. , an erasure is applied at index @xmath19 ) . @xmath44 and",
    "@xmath45 will be used to denote the random vectors which generate the realizations @xmath46 and @xmath47 , respectively .",
    "if @xmath5 is odd then the gmd algorithm corresponds to the set@xmath48 of erasure patterns .",
    "meanwhile , the sed@xmath49 uses the following set @xmath50 here , in each erasure pattern , the letters are written in increasing reliability order of the codeword positions .",
    "let us revisit the question of how to construct the best set of erasure patterns for multiple errors - and - erasures decoding .",
    "first , it can be seen that a multiple errors - and - erasures decoding succeeds if the condition ( [ eq : scbma_0 ] ) is satisfied during at least one round of decoding .",
    "thus , our approach is to design a distortion measure that converts the condition ( [ eq : scbma_0 ] ) into a form where the distortion between an error pattern @xmath46 and an erasure pattern @xmath47 , denoted as @xmath51 , is less than a fixed threshold .",
    "letter - by - letter _ distortion measure @xmath52 , the distortion between an error pattern @xmath46 and an erasure pattern @xmath47 is defined by@xmath53    [ prop : bma1]if we choose the _ letter - by - letter _ distortion measure @xmath54 , where in this case @xmath55 , as follows:@xmath56 then the condition ( [ eq : scbma_0 ] ) for a successful errors - and - erasures decoding is equivalent to@xmath57 where the distortion is less than a fixed threshold .",
    "first , we define @xmath58 to count the number of @xmath59 pairs equal to @xmath60 for every @xmath61 and @xmath62 . with the chosen distortion measure",
    ", we have @xmath63 noticing that @xmath64 and @xmath65 , the condition ( [ eq : scbma_0 ] ) for one errors - and - erasures decoding attempt to succeed becomes @xmath66 which is equivalent to @xmath67 .    next",
    ", we try to maximize the chance that this successful decoding condition is satisfied by at least one of the decoding attempts ( i.e. , @xmath67 for at least one erasure pattern @xmath47 ) .",
    "mathematically , we want to build a set @xmath68 of no more than @xmath69 erasure patterns @xmath47 that achieves the maximum @xmath70 solving this problem exactly is very difficult .",
    "however , one can observe that it is a covering problem where tries to cover the most - likely error patterns using a fixed number of spheres centered at the chosen erasure patterns .",
    "this view leads to two asymptotic solutions of the problem based on rate - distortion theory . taking this point of view",
    ", we view the error pattern @xmath46 as a source sequence and the erasure pattern @xmath47 as a reproduction sequence .          rate - distortion theory ( see ( * ? ? ?",
    "* chapter 13 ) ) characterizes the trade - off between @xmath71 and @xmath72 such that sets @xmath68 of @xmath73 reproduction sequences exist ( and can be generated randomly ) so that@xmath74<\\bar{d}.\\ ] ] under mild conditions , this implies that , for large enough @xmath1 , we have@xmath75 with high probability . here ,",
    "@xmath71 and @xmath72 are closely related to the complexity and the performance , respectively , of the decoding algorithm .",
    "therefore , we characterize the trade - off between those two aspects using the relationship between @xmath71 and @xmath72 . in this paper , we denote the rate and distortion by @xmath76 and @xmath77 , respectively , using unnormalized quantities , i.e. , @xmath78 and @xmath79 .",
    "the above - mentioned rd approach focuses on minimizing the average minimum distortion with little knowledge of how the tail of the distribution behaves . in this rde approach , we instead focus on directly minimizing the probability that the minimum distortion is not less than the predetermined threshold @xmath80 ( due to the condition ( [ eq : distorthreshold ] ) ) with the help of an error - exponent analysis .",
    "the exact probability of interest is @xmath81 that reflects how likely the decoding threshold ( [ eq : scbma_0 ] ) is going to fail . in other words ,",
    "every error pattern @xmath46 can be covered by a sphere centered at an erasure pattern @xmath47 except for a set of error patterns of probability @xmath9 .",
    "the rde analysis shows that @xmath9 decays exponentially as @xmath82 and the maximum exponent attainable is the rde function @xmath83 . throughout this paper",
    ", we denote the rate - distortion exponent by @xmath83 using unnormalized quantities ( i.e. , without dividing by @xmath1 ) and note that exponent used by other authors in @xcite is often the normalized version @xmath84 .",
    "rde analysis is discussed extensively in @xcite and it is shown that a set @xmath68 of roughly @xmath73 codewords , generated randomly using the test - channel input distribution , can be used to achieve @xmath85 .",
    "an upper bound is also given that shows , for any @xmath86 , there is a sufficiently large @xmath1 ( see @xcite ) such that @xmath87}.\\ ] ] an exponentially tight lower bound for @xmath9 can also be obtained ( see @xcite ) and it implies that the best sequence of codebooks satisfy @xmath88    [ rem : advantage]the rde approach possesses several advantages .",
    "first , the converse of the rde @xcite provides a lower bound for @xmath9 .",
    "this implies that , given an arbitrary set @xmath68 of roughly @xmath73 erasure patterns and any @xmath86 , the probability @xmath9 can not be made lower than @xmath89}$ ] for @xmath1 large enough .",
    "thus , no matter how one chooses the set @xmath68 of erasure patterns , the difference between the induced probability of error and the @xmath9 for the rde approach becomes negligible for @xmath1 large enough .",
    "second , it can help one estimate the smallest number of decoding attempts to get to a rde of @xmath90 ( or get to an error probability of roughly @xmath91 ) or , similarly , allow one to estimate the rde ( and error probability ) for a fixed number of decoding attempts .      in this subsection",
    ", we consider a generalization of the conventional error patterns and erasure patterns under the same framework to make better use of the soft information . at each index of the rs codeword , besides erasing a symbol , we also try to decode using not only the most likely symbol but also less likely ones as the hard decision ( hd ) symbol . to handle up to the @xmath92 most likely symbols at each index @xmath19 , we let @xmath93 and consider the following definition .    [ def:(patternsbma)](generalized error patterns and erasure patterns ) consider a positive integer @xmath92 smaller than the field size @xmath12 .",
    "let @xmath94 be a _",
    "generalized error pattern _ where , at index @xmath19 , @xmath95 implies that the @xmath24-th most likely symbol is correct for @xmath96 , and @xmath42 implies none of the first @xmath92 most likely symbols is correct .",
    "let @xmath97 be a _",
    "generalized erasure pattern _ used for decoding where , at index @xmath19 , @xmath98 implies that the @xmath99-th most likely symbol is used as the hard - decision symbol for @xmath100 , and @xmath43 implies that an erasure is used at that index .",
    "for simplicity , we refer to @xmath46 as the error pattern and @xmath47 as the erasure pattern like in the conventional case .",
    "now , we need to convert the condition ( [ eq : scbma_0 ] ) to the form where @xmath51 is less than a fixed threshold .",
    "proposition [ prop : bma1 ] _ _ is thereby generalized into the following proposition .",
    "[ thm : extbma-1]we choose the _ letter - by - letter _ distortion measure @xmath54 , where in this case @xmath101 , defined by @xmath102_{x,\\hat{x}}$ ] in terms of the @xmath103 ) matrix@xmath104 using this , the condition ( [ eq : scbma_0 ] ) for a successful errors - and - erasures decoding is equivalent to@xmath105    the reasoning is very similar to the proof of proposition [ prop : bma1 ] using the fact that @xmath106 and @xmath107 where @xmath108 for every @xmath109 .",
    "for each @xmath110 , we will refer to this generalized case as mbm-@xmath92 decoding .",
    "consider mbm-2 ( or top-@xmath92 decoding with @xmath111 ) . in this case , the distortion measure is given by following the matrix@xmath112    the distortion measure matrix changes slightly if we use the errors - only decoding instead of errors - and - erasures decoding . in this case , @xmath113 and the chosen letter - by - letter distortion measure is given in terms of the @xmath114 matrix obtained by deleting the first column of ( [ eq : dstmbml ] ) .",
    "when @xmath115 we consider the first and second most likely symbols as the two hard - decision symbols at each codeword position .",
    "this is similar to the chase - type decoding method proposed by bellorado and kavcic @xcite .",
    "das and vardy also suggest this approach by considering only several highest entries in each column of the reliability matrix @xmath116 for single asd decoding of rs codes @xcite .      in this section ,",
    "we propose two general multiple - decoding algorithms for rs codes . in each algorithm",
    ", one can choose either step 2a that corresponds to the rd approach or step 2b that corresponds to the rde approach .",
    "these general algorithms apply to not only multiple errors - and - erasures decoding but also multiple - decoding of other decoding schemes that we will discuss later .",
    "the common first step is designing a distortion measure @xmath54 that converts the condition for a single decoding to succeed to the form where distortion is less than a fixed threshold .",
    "after that , decoding proceeds as described below .",
    "_ step 1 : _ based on the received signal sequence , compute an @xmath117 reliability matrix @xmath118 where @xmath119_{j , i}=\\pi_{i , j}$ ] . from this , determine the probability matrix @xmath120 where @xmath121 for @xmath122 and @xmath123    _ step 2a : _ ( rd approach ) compute the rd function of a source sequence ( error pattern ) with probability of source letters derived from @xmath120 and the chosen distortion measure ( see section [ sec : computing - rd ] and section [ sec : closed - form - analysis - of ] ) . given the design rate @xmath76 , determine the optimal input - probability distribution matrix @xmath124 , for the test channel , with entries @xmath125 for @xmath122 and @xmath126    _ step 2b : _",
    "( rde approach ) given @xmath77 ( in most cases @xmath127 and the design rate @xmath76 , compute the rde function of a source sequence ( error pattern ) with probability of source letters derived from @xmath120 and the chosen distortion measure ( see section [ sec : computing - rd ] and section [ sec : closed - form - analysis - of ] ) . also determine the optimal input - probability distribution matrix @xmath124 , for the test channel , with entries @xmath125 for @xmath122 and @xmath126    _ step 3 : _ randomly generate a set of @xmath69 erasure patterns using the test - channel input - probability distribution matrix @xmath124 .",
    "_ step 4 : _ run multiple attempts of the corresponding decoding scheme ( e.g. , errors - and erasures decoding ) using the set of erasure patterns in step 3 to produce a list of candidate codewords .",
    "_ step 5 : _ use the maximum - likelihood ( ml ) rule to pick the best codeword on the list .    in algorithm",
    "a , the rd ( or rde ) function is computed on the fly , i.e. , after every received signal sequence . in practice , it may be preferable to precompute the rd ( or rde ) function based on the empirical distribution measured from the channel .",
    "we refer to this approach as algorithm b , and simulation results show a negligible difference in the performance of these two algorithms .       _ step 1 : _ transmit @xmath128 ( e.g. , @xmath129 ) arbitrary test rs codewords , indexed by time @xmath130 , over the channel and",
    "compute a set of @xmath128 @xmath117 matrices @xmath131 where @xmath132_{j , i}=\\pi_{i,\\varphi_{i}^{(t)}(j)}^{(t)}$ ] is the probability of the @xmath24-th most likely symbol at position @xmath19 during time @xmath133 . for each time",
    "@xmath133 , obtain the matrix @xmath134 from @xmath131 through a permutation @xmath135 that sorts the probabilities @xmath136 in increasing order to indicate the reliability order of codeword positions .",
    "take the entry - wise average of all @xmath128 matrices @xmath134 to get an average matrix @xmath137 .",
    "the average @xmath138 can be computed on the fly . ]",
    "the matrix @xmath137 serves as @xmath118 in algorithm a and from this , determine the probability matrix @xmath120 where @xmath121 for @xmath122 and @xmath123    _ step 2a : _ ( rd approach ) compute the rd function of a source sequence ( error pattern ) with probability of source letters derived from * @xmath120 * and the chosen distortion measure .",
    "given a design rate @xmath76 , determine the test - channel input - probability distribution matrix @xmath124 where @xmath125 for @xmath122 and @xmath126    _ step 2b : _ ( rde approach ) given @xmath77 ( in most cases @xmath127 and the design rate @xmath76 , compute the rde function of a source sequence ( error pattern ) with probability of source letters derived from @xmath120 and the chosen distortion measure .",
    "also determine the optimal test - channel input - probability distribution matrix @xmath124 where @xmath125 for @xmath122 and @xmath126    _ step 3 : _ based on the actual received signal sequence , compute @xmath27 and determine the permutation  @xmath139  that gives the reliability order of codeword positions by sorting @xmath27 in increasing order .",
    "_ step 4 : _ randomly generate a set of @xmath69 erasure patterns using the test - channel input - probability distribution matrix @xmath124 and permute the indices of each erasure pattern by the permutation @xmath140    _ step 5 : _ run multiple attempts of the corresponding decoding scheme ( e.g. , errors - and - erasures decoding ) using the set of erasure patterns in step 4 to produce a list of candidate codewords .",
    "_ step 6 : _ use the ml rule to pick the best codeword on the list .",
    "in this section , we will discuss some numerical methods to compute the rd and rde functions and the corresponding test - channel input - probability distribution matrix @xmath124 , whose entries are @xmath125 for @xmath122 and @xmath62 .",
    "these numerical methods allow us to efficiently compute the rd and rde functions discussed in the previous section for arbitrary discrete distortion measures .",
    "for some simple distortion measures , closed - form solutions are given in section [ sec : closed - form - analysis - of ] .",
    "for an arbitrary discrete distortion measure , it can be difficult to compute the rd function analytically .",
    "fortunately , for a single source @xmath141 , the blahut algorithm ( see details in @xcite ) gives an alternating minimization technique that efficiently computes the rd function which is given by@xmath142 where @xmath143 , @xmath144 , @xmath145 , and is sometimes written as @xmath146 for convenience . ]",
    "@xmath147 more precisely , given the lagrange multiplier @xmath148 that represents the slope of the rd curve at a specific point ( see ( * ? ? ?",
    "* thm 2.5.1 ) ) and an arbitrary all - positive initial test - channel input - probability distribution vector @xmath149 , the blahut algorithm shows us how to compute the rate - distortion pair @xmath150 .",
    "however , it is not straightforward to apply the blahut algorithm to compute the rd for a discrete source sequence @xmath46 ( an error pattern in our context ) of @xmath1 independent but not necessarily identical ( i.n.d . )",
    "source components @xmath151 .",
    "in order to do that , we consider the group of source letters @xmath152 where @xmath153 as a super - source letter @xmath154 , the group of reproduction letters @xmath155 where @xmath156 as a super - reproduction letter @xmath157 , and the source sequence @xmath46 as a single source .",
    "for each super - source letter @xmath158 , @xmath159 follows from the independence of source components . and @xmath160 are interchangeable .",
    "the notations @xmath161 and @xmath162 are also interchangeable . ]    while we could apply the blahut algorithm to this source directly , the complexity is a problem because the alphabet sizes for @xmath158 and @xmath163 become the super - alphabet sizes @xmath164 and @xmath165 respectively .",
    "instead , we avoid this computational challenge by choosing the initial test - channel input - probability distribution so that it can be factored into a product of @xmath1 initial test - channel input - probability components , i.e. , @xmath166 .",
    "one can verify that this factorization rule still applies after every step @xmath128 of the iterative process , i.e. , @xmath167 .",
    "therefore , the convergence of the blahut algorithm @xcite implies that the optimal distribution is a product distribution , i.e. , @xmath168 .",
    "one can also finds that , for each parameter @xmath133 , one only needs to compute the rate - distortion pair for each source component @xmath151 separately and sum them together .",
    "this is captured into the following algorithm .",
    "[ thm:(factored - blahut)](factored blahut algorithm for rd function ) consider a discrete source sequence @xmath46 of @xmath1 i.n.d .",
    "source components @xmath151 s with probability @xmath169 .",
    "given a parameter @xmath148 , the rate and the distortion for this source sequence under a specified distortion measure are given by@xmath170 where the components @xmath171 and @xmath172 are computed by the blahut algorithm with the lagrange multiplier @xmath133 .",
    "this rate - distortion pair can be achieved by the corresponding test - channel input - probability distribution @xmath173 where the component probability distribution @xmath174 .",
    "equation ( [ eq : rdit ] ) can also be derived from ( * ? ? ?",
    "* corollary 2.8.3 ) in a way that does not use the convergence property of the blahut algorithm .",
    "the original rde function @xmath83 , defined in ( * ? ? ?",
    "vi ) for a single source @xmath141 , is given by@xmath175 where @xmath176 , @xmath177 , @xmath178 , and    @xmath179    for a single source @xmath141 , given two parameters @xmath180 and @xmath148 which are the lagrange multipliers introduced in the optimization problem ( see @xcite ) , the arimoto algorithm given in ( * ? ? ?",
    "v ) can be used to compute the exponent , rate , and distortion numerically .    in the context",
    "we consider , the source ( error pattern ) @xmath46 comprises i.n.d .",
    "source components @xmath151 s .",
    "we follow the same method as in the rd function case , i.e. , by choosing the initial distribution still arbitrarily but following a factorization rule @xmath181 , and this gives the following algorithm .",
    "[ pro : factoredrde](factored arimoto algorithm for rde function ) consider a discrete source @xmath46 of i.n.d .",
    "source components @xmath151 s with probability @xmath169 .",
    "given lagrange multipliers @xmath180 and @xmath148 , the exponent , rate and distortion under a specified distortion measure are given by@xmath182where the components @xmath183 are computed parametrically by the arimoto algorithm .    though it is standard practice to compute error - exponents using the implicit form given above , this approach may provide points that , while achievable , are strictly below the true rde curve .",
    "the problem is that the true rde curve may have a slope discontinuity that forces the implicit representation to have extra points .",
    "an example of this behavior for the channel coding error exponent is given by gallager @xcite .",
    "for the i.n.d .",
    "source considered above , a cautious person could solve the problem as described and then check that the component rde functions are differentiable at the optimum point . in this work",
    ", we largely neglect this subtlety .        for each parameter @xmath184",
    "if we directly apply of the original blahut algorithm to compute the @xmath150 pair , the complexity is @xmath185 where @xmath186 is the number of iterations in the blahut algorithm .",
    "however , using the factored blahut algorithm ( algorithm [ thm:(factored - blahut ) ] ) greatly reduces this complexity to @xmath187 . in section  [ sec : proposed - algorithm ] , one of the proposed algorithms needs to compute the rd function for a design rate @xmath76 . to do this",
    ", we apply the bisection method on @xmath133 to find the correct @xmath133 that corresponds to the chosen rate @xmath76 .    *",
    "_ step  0 _ : set @xmath188 ( e.g. , @xmath189 ) * _ step  1 _ : if @xmath190 go to step 3 .",
    "else go to step 2 . *",
    "_ step  2 _ : if @xmath191 then stop .",
    "else if @xmath192 , set @xmath193 and go to step 1 . *",
    "_ step  3 _ : find @xmath133 using the bisection method to get the correct rate @xmath76 within @xmath194 .",
    "the overall complexity of computing the rd function for a design rate @xmath76 is @xmath195    now , we consider the dependence of @xmath186 on @xmath194 .",
    "it follows from @xcite that the error due to early termination of the blahut algorithm is @xmath196 .",
    "this implies that choosing @xmath197 is sufficient .",
    "however , recent work has shown that a slight modification of the blahut algorithm can drastically increase the convergence rate @xcite .",
    "for this reason , we leave the number of iterations as the separate constant @xmath186 and do not consider its relationship to the error tolerance .",
    "similarly , for each pair of parameters @xmath198 and @xmath180 , the complexity if we directly apply of the original arimoto algorithm to compute the @xmath199 pair is @xmath200 where @xmath186 is the number of iterations . instead , if the factored arimoto algorithm ( algorithm [ pro : factoredrde ] ) is employed , this complexity can also be reduced to @xmath187 . in one of our proposed general algorithms in section",
    "[ sec : proposed - algorithm ] , we need to compute the rde function for a pre - determined @xmath201 pair .",
    "we use a nested bisection technique to find the lagrange multipliers @xmath202 that give the correct @xmath76 and @xmath77 .    *",
    "_ step  0 _ : set @xmath188 and @xmath203 @xmath204e.g . ,",
    "@xmath189 and @xmath205 ) * _ step  1 _ : if @xmath206 , set @xmath193 and repeat step 1 .",
    "else go to step 2 . * _ step  2 _ : find @xmath133 using the bisection method to obtain @xmath207 within @xmath194 . if @xmath208 go to step 3 . if @xmath209 then stop .",
    "else if @xmath210 , set @xmath211 and go to step 1 .",
    "* _ step  3 _ : find @xmath212 using the bisection method to get the correct distortion @xmath77 within @xmath213 while with each @xmath212 doing the following steps * * _ step  3a _ : if @xmath214 , go to step 3c . * * _ step  3b _ : if @xmath215 , then stop . else if @xmath216 , set @xmath193 and go to step 1 .",
    "* * _ step  3c _ : find @xmath133 using the bisection method to get the correct @xmath76 within @xmath194 .",
    "the overall complexity of computing the rd function for a design rate @xmath76 is therefore @xmath217",
    "in this section , we analyze and design a distortion measure to convert the condition for successful asd decoding to a suitable form so that we can apply the general multiple - decoding algorithm to asd decoding .",
    "first , let us give a brief review on asd decoding of rs codes .",
    "let @xmath218 be a set of @xmath1 distinct elements in @xmath219 from each message polynomial @xmath220 whose coefficients are in @xmath10 , we can obtain a codeword @xmath221 by evaluating the message polynomial at @xmath222 , i.e. , @xmath223 for @xmath122 . given a received vector @xmath224 , we can compute the _ a posteriori _ probability ( app ) matrix @xmath118 as follows:@xmath225_{j , i}=\\pi_{i , j}=\\pr(c_{i}=\\alpha_{j}|r_{i})\\,\\,\\,\\mbox{for}\\,\\,1\\leq i\\leq n,1\\leq j\\leq m.\\ ] ] the asd decoding as in @xcite has the following main steps .    1 .   _ multiplicity assignment _ : use a particular multiplicity assignment scheme ( mas ) to derive an @xmath117 multiplicity matrix , denoted as @xmath226 , of non - negative integer entries @xmath227 from the app matrix @xmath118 .",
    "interpolation _ : construct a bivariate polynomial @xmath228 of minimum @xmath229 weighted degree that passes through each of the point @xmath230 with multiplicity @xmath231 for @xmath232 and @xmath233 .",
    "_ factorization _ : find all polynomials @xmath234 of degree less than @xmath2 such that @xmath235 is a factor of @xmath228 and re - evaluate these polynomials to form a list of candidate codewords .    in this paper ,",
    "we denote @xmath236 as the maximum multiplicity .",
    "intuitively , higher multiplicity should be put on more likely symbols .",
    "a higher @xmath237 generally allows asd decoding to achieve a better performance . however , one of the drawbacks of asd decoding is that its decoding complexity is roughly @xmath238 @xcite .",
    "even though there have been several reduced complexity variations and fast architectures as discussed in @xcite , the decoding complexity still increases rapidly with @xmath237 .",
    "thus , in this section we will mainly work with small @xmath237 to keep the complexity affordable .",
    "one of the main contributions of @xcite is to offer a condition for successful asd decoding represented in terms of two quantities specified as the score and the cost as follows .",
    "the score @xmath239 with respect to a codeword @xmath240 and a multiplicity matrix @xmath226 is defined as@xmath241,j}\\ ] ] where @xmath242=i$ ] such that @xmath243 .",
    "the cost @xmath244 of a multiplicity matrix @xmath226 is defined as @xmath245    [ con : asdcond](asd decoding threshold , see @xcite ) .",
    "the transmitted codeword will be on the list if@xmath246>c_{\\mathbf{m}}\\label{eq : maincond}\\ ] ] for some @xmath247 such that @xmath248    to match the general framework , the asd decoding threshold ( or condition for successful asd decoding ) should be converted to the form where the distortion is smaller than a fixed threshold .      in this subsection",
    ", we consider multiple trials of asd decoding using bit - level erasure patterns .",
    "a bit - level error pattern @xmath249 and a bit - level erasure pattern @xmath250 have length @xmath251 since each symbol has @xmath252 bits . similar to definition [ def:(conv .",
    "patterns ) ] of a conventional error pattern and a conventional erasure pattern , @xmath253 in a bit - level error pattern implies a bit - level error occurs and @xmath254 in a bit - level erasure pattern implies that a bit - level erasure is applied .",
    "we also use @xmath255 and @xmath256 to denote the random vectors which generate the realizations @xmath257 and @xmath258 , respectively .    from each bit - level erasure pattern , we can specify entries of the multiplicity matrix @xmath226 using the bit - level mas proposed in @xcite as follows : for each codeword position , assign multiplicity 2 to the symbol with no bit erased , assign multiplicity 1 to each of the two candidate symbols if there is 1 bit erased , and assign multiplicity zero to all the symbols if there are @xmath259 bits erased",
    ". all the other entries are zeros by default .",
    "this mas has a larger decoding region compared to the conventional errors - and - erasures decoding scheme .",
    "( bit - level asd decoding threshold , see @xcite ) for rs codes of rate @xmath260 , asd decoding using the bit - level mas will succeed ( i.e. , the transmitted codeword is on the list ) if@xmath261 where @xmath262 is the number of bit - level erasures and @xmath263 is the number of bit - level errors in unerased locations",
    ".    we can choose an appropriate distortion measure according to the following proposition which is a natural extension of proposition [ prop : bma1 ] in the symbol level .",
    "[ prop : bitasd]if we choose the bit - level _ letter - by - letter _ distortion measure  @xmath264  as follows@xmath265 then the condition ( [ eq : bgmdsc ] ) becomes @xmath266    the condition ( [ eq : bgmdsc ] ) can be seen to be equivalent to @xmath267 using the same reasoning as in _ _ proposition _ _ [ prop : bma1 ] .",
    "the results then follows right away .",
    "we refer the multiple - decoding of bit - level asd as m - basd .      in this subsection",
    ", we try to convert the condition for successful asd decoding in general to the form that suits our goal .",
    "we will also determine which multiplicity assignment schemes allow us to do so .",
    "( multiplicity type ) consider a positive integer @xmath268 where @xmath12 is the number of elements in @xmath269 .",
    "for some codeword position , let us assign multiplicity @xmath270 to the @xmath24-th most likely symbol for @xmath271 .",
    "the remaining entries in the column are zeros by default .",
    "we call the sequence , @xmath272 , the column _ multiplicity type _ for `` top-@xmath92 '' decoding",
    ".    first , we notice that a choice of multiplicity types in asd decoding at each codeword position has the similar meaning to a choice of erasure decisions in the conventional errors - and - erasures decoding .",
    "however , in asd decoding we are more flexible and may have more types of erasures .",
    "for example , assigning multiplicity zero to all the symbols ( all - zero multiplicity type ) at codeword position @xmath19 is similar to erasing that position . assigning the maximum multiplicity @xmath237 to one symbol corresponds to the case when we choose that symbol as the hard - decision one .",
    "hence , with some abuse of terminology , we also use the term ( generalized ) erasure pattern @xmath47 for the multiplicity assignment scheme in the asd context .",
    "each erasure - letter @xmath151 gives the multiplicity type for the corresponding column of the multiplicity matrix @xmath226 .",
    "( error patterns and erasure patterns for asd decoding ) consider a mas with @xmath273 multiplicity types .",
    "let @xmath274 be an erasure pattern where , at index @xmath19 , @xmath95 implies that multiplicity type @xmath24 is used at column @xmath19 of the multiplicity matrix @xmath226 .",
    "notice that the definition of an error pattern @xmath94 in definition [ def:(patternsbma ) ] applies unchanged here .    in our method ,",
    "we generally choose an appropriate integer @xmath275 in condition [ con : asdcond ] and design a distortion measure corresponding to the chosen @xmath275 so that the condition for successful asd decoding can be converted to the form where distortion is less than a fixed threshold .",
    "the following definition of allowable multiplicity types will lead us to the result of lemma [ lem : genasd ] and consequently , @xmath276 , as stated in corollary [ cor : ageqmu ] .",
    "also , we want to find as many as possible multiplicity types since rate - distortion theory gives us the intuition that in general the more multiplicity types ( erasure choices ) we have , the better performance of multiple asd decoding we achieve as @xmath1 becomes large .",
    "[ def : allowabletypes]the set of allowable multiplicity types for `` top-@xmath92 '' decoding with maximum multiplicity @xmath237 is defined to be if @xmath277 . ]",
    "@xmath278 we take the elements of this set in an arbitrary order and label them as @xmath279 with the convention that the multiplicity type 1 is always @xmath280 which assigns the whole multiplicity @xmath237 to the most likely symbol .",
    "the multiplicity type @xmath99 is denoted as @xmath281 .",
    "multiplicity types @xmath282 as well as any permutations of @xmath280 and @xmath283 are always in the allowable set @xmath284 .",
    "we use masd-@xmath237 to denote the proposed multiple asd decoding using @xmath284 .",
    "[ exa : masd2a]consider masd-2 where @xmath285 .",
    "we have @xmath286 which comprises four allowable multiplicity types for `` top-2 '' decoding as follows : the first is @xmath287 where we assign multiplicity 2 to the most likely symbol @xmath288 , the second is @xmath289 where we assign equal multiplicity 1 to the first and second most likely symbols @xmath288 and @xmath290 , the third is @xmath291 where we assign multiplicity 2 to the second most likely symbol @xmath290 , and the fourth is @xmath292 where we assign multiplicity zero to all the symbols at index @xmath19 ( i.e. , the @xmath19-th column of @xmath226 is an all - zero column ) .",
    "we also consider a restricted set , called masd-2a , that uses the set of multiplicity types @xmath293 .",
    "consider masd-3 . in this case , the allowable set @xmath294 consists of all the permutations of @xmath295 .",
    "we can see that the set @xmath296 consists of all permutations of @xmath297 and @xmath298 .    from now on , we assume that only allowable multiplicity types are considered throughout most of the paper . with that setting in mind ,",
    "we can obtain the following lemmas and theorems .",
    "[ lem : genasd]consider a mas(@xmath299 ) for `` top-@xmath92 '' asd decoding with multiplicity matrix @xmath226 that only uses multiplicity types in the allowable set @xmath300 .",
    "then , the score and the cost satisfy the following inequality : @xmath301    let us denote @xmath302 to count the number of positions @xmath19 that use multiplicity type @xmath99 for @xmath303 and notice that @xmath304 .",
    "we also use @xmath305 to count the number of positions @xmath19 that use multiplicity type @xmath99 where the @xmath24-th most reliable symbol @xmath306 is incorrect for @xmath307 and @xmath303 .",
    "the notation @xmath308 remains the same .",
    "notice also that @xmath309    the score and the cost can therefore be written as @xmath310,j}\\nonumber\\\\ & \\phantom{s_{\\mathbf{m}}(\\mathbf{c } ) } = \\sum_{k=1}^{t}\\sum_{j=1}^{\\ell}m_{j , k}\\chi_{j , k}\\label{eqscorechi}\\\\ & \\phantom{s_{\\mathbf{m}}(\\mathbf{c})}=\\mu\\chi_{1,1}+\\sum_{k=2}^{t}\\sum_{j=1}^{\\ell}m_{j , k}\\chi_{j , k}\\label{eqmult1 } \\\\ & \\phantom{s_{\\mathbf{m}}(\\mathbf{c})}= \\mu\\left(n-\\sum_{k=2}^{t}e_{k}-\\nu_{1,1}\\right)+\\sum_{k=2}^{t}\\sum_{j=1}^{\\ell}m_{j , k}(e_{k}-\\nu_{j , k } ) \\label{eq : score } \\end{aligned}\\ ] ] and @xmath311 where ( [ eqmult1 ] ) and ( [ eq : cost ] ) use the fact that the multiplicity type 1 is always assumed to be @xmath280 .    hence , we obtain @xmath312 and therefore , since @xmath237 and @xmath313 are non - negative , lemma [ lem : genasd ] holds if we can show @xmath314 for every @xmath315 .",
    "next , we observe that @xmath316 and @xmath317 where ( [ eqlm1_6 ] ) follows from ( [ eqlm1_4 ] ) and ( [ eqlm1_2 ] ) follows from @xmath318    from ( [ eqlm1_1 ] ) and ( [ eqlm1_2 ] ) , we have @xmath319 and this motivates our definition of allowable multiplicity types .",
    "specifically , if we choose @xmath320 in the allowable set @xmath300 , defined in ( [ eq : allowablemas ] ) , then by combining with ( [ eqlm1_3 ] ) , we obtain ( [ eqlm1_0 ] ) and this completes the proof .    [",
    "cor : ageqmu]with the setting as in lemma [ lem : genasd ] , the integer @xmath275 in condition [ con : asdcond ] must satisfy @xmath276 .    from @xmath321>c_{\\mathbf{m}}$ ] and @xmath322 in ( [ eq : maincond ] ) and ( [ eq : piecewise ] ) , we have @xmath323 and this implies that @xmath324 but , lemma [ lem : genasd ] states that @xmath325 . combining this with ( [ eqcol1 ] ) gives a contradiction unless @xmath326 .",
    "in condition [ con : asdcond ] , if we carefully design a distortion measure then for every @xmath327 the first constraint ( [ eq : maincond ] ) can be equivalently converted to the form where distortion is smaller than a fixed threshold .",
    "[ thm : genasd - allrate ] consider an @xmath0 rs code and a mas(@xmath299 ) for `` top-@xmath92 '' decoding with multiplicity matrix @xmath226 that only uses @xmath273 multiplicity types in the allowable set @xmath300 .",
    "consider an arbitrary integer @xmath276 .",
    "let @xmath328 , where in this case @xmath329 and @xmath330 , be a _",
    "letter - by - letter _ distortion measure defined by @xmath331_{x,\\hat{x}}$ ] , where @xmath332 is the @xmath333 matrix is @xmath334^{t}$ ] since multiplicity type 1 is always chosen to be @xmath335.]@xmath336 with @xmath337 for @xmath303 . then , the equation ( [ eq : maincond ] ) in condition [ con : asdcond ] is equivalent to @xmath338    and it is easy to verify that @xmath339 .",
    "first , we show that @xmath332 consists of non - zero entries .",
    "it suffices to show that @xmath340 for all @xmath341 and @xmath303 , i.e. , @xmath342 which is equivalent to @xmath343 this is true since the left hand side of ( [ eq : nonzeroentries ] ) is at least @xmath344    with the same @xmath345 as defined in the proof of lemma [ lem : genasd ] and the chosen distortion matrix @xmath332 , we have @xmath346 noting that the first column of @xmath332 is always @xmath334^{t}$ ] and @xmath347 , we obtain@xmath348 next , one can see that ( [ eq : maincond ] ) can be rewritten as@xmath349 which , by substituting @xmath350 and @xmath351 in ( [ eq : score ] ) and ( [ eq : cost ] ) , is equivalent to @xmath352    equivalently , this gives @xmath353 which in turn is equivalent to @xmath354    finally , combining ( [ eq : dxx ] ) and ( [ eq : dxx2 ] ) gives the proof .",
    "consider masd-2 for @xmath355 . in this case , the distortion matrix is@xmath356    however , condition [ con : asdcond ] also requires the second constraint ( [ eq : piecewise ] ) to be satisfied .",
    "in addition , we need to choose an integer @xmath276 in order to apply our proposed approach . therefore , we first consider the case of high - rate rs codes where if @xmath357 then the satisfaction of ( [ eq : maincond ] ) also implies the satisfaction of ( [ eq : piecewise ] ) . for the case of lower - rate rs codes",
    ", we obtain a range of @xmath275 and also propose a heuristic method to choose an appropriate @xmath275 .      in this subsection",
    ", we focus on high - rate rs codes which are usually seen in many practical applications .",
    "the high - rate constraint allows us to see that @xmath357 is essentially the correct choice .",
    "[ lem : midhighrate]consider an @xmath0 rs code with rate @xmath358 if equation ( [ eq : maincond ] ) is satisfied for @xmath357 , or equivalently , @xmath359 under the distortion measure @xmath360 then whole condition [ con : asdcond ] is satisfied and the transmitted codeword will be therefore on the list .",
    "suppose ( [ eq : maincond ] ) is satisfied for @xmath357 , i.e. , @xmath361    we will show that @xmath362 and , therefore , both ( [ eq : maincond ] ) and ( [ eq : piecewise ] ) in condition [ con : asdcond ] are satisfied for @xmath357 .",
    "firstly , using lemma [ lem : genasd ] we have @xmath363 and consequently , ( [ eqlm2_1 ] ) is implied by ( [ eqlm2_0 ] ) since@xmath364 secondly , note that ( [ eqlm2_2 ] ) holds since @xmath365 where ( [ eqlm2_3 ] ) is obtained by dropping non - negative terms and ( [ eqlm2_4 ] ) follows from the high - rate constraint @xmath366 .",
    "finally , by theorem [ thm : genasd - allrate ] , one can verify that equation ( [ eq : maincond ] ) with @xmath357 is equivalent to @xmath367 under the distortion measure @xmath360 .",
    "however , there are possibly other integers @xmath368 that can also satisfy condition [ con : asdcond ] . if we consider higher - rate rs codes , as in the following theorem , then we can claim that @xmath357 is the only such integer .",
    "[ thm : genasd ] consider an @xmath0 rs code with rate @xmath369 the integer @xmath275 in condition [ con : asdcond ] must satisfy @xmath357 and , consequently , the set of constraints ( [ eq : maincond ] ) and ( [ eq : piecewise ] ) in condition [ con : asdcond ] is equivalent to@xmath359 under the distortion measure @xmath360 .",
    "we first see that @xmath246>c_{\\mathbf{m}}\\ ] ] in ( [ eq : maincond ] ) implies @xmath370 and , with the score @xmath350 and the cost @xmath351 computed in ( [ eq : score ] ) and ( [ eq : cost ] ) , we obtain    @xmath371    this gives @xmath372 where ( [ eqthm2_5 ] ) is obtained by dropping non - negative terms .",
    "combining this inequality with the high - rate constraint implies that @xmath373 which leads to @xmath374 , i.e. @xmath375 .",
    "this , together with @xmath276 according to corollary [ cor : ageqmu ] , leave @xmath357 as the only possible choice .",
    "finally , by seeing that @xmath376 and applying lemma [ lem : midhighrate ] we conclude the proof .",
    "[ cor : for - masd]when the rd approach is used , @xmath377 is positive for @xmath378 and is zero for @xmath379 .",
    "computing @xmath380 reveals how good the distortion measure matrix is at rates close to zero ( i.e. , the erasure codebook has only one entry ) . for masd-@xmath237 , @xmath381 while for mbm-@xmath92 , @xmath382 moreover , if masd-@xmath237 uses multiplicity type @xmath383 ) then @xmath384masd-@xmath385mbm-@xmath92 ) for every @xmath299 .",
    "see appendix [ sec : appcordmax ] .",
    "consider masd-2 with distortion matrix in ( [ eq : dstmasd2 ] ) .",
    "we have @xmath386 which is less than or equal to @xmath387 for every @xmath92 .",
    "this fact can be seen in fig .",
    "[ fig : rdcurve ] which is obtained by simulation .",
    "this also predicts that , as expected , asd decoding will be superior when @xmath76 is small .      without the high - rate constraint as in theorem [ thm : genasd ]",
    ", we may not have @xmath357 . however",
    ", we can obtain a range for @xmath275 and heuristically choose the integer @xmath275 that potentially give the highest rate - distortion exponent .",
    "after that , we can also apply the algorithms proposed in section [ sec : proposed - algorithm ] with the corresponding distortion measure @xmath332 and distortion threshold @xmath388 derived in theorem [ thm : genasd - allrate ] .",
    ".example ranges of possible @xmath275 [ cols=\"^,^,^\",options=\"header \" , ]      plot of exponent @xmath389 versus @xmath275 for @xmath390 and @xmath391 with a fixed rate @xmath392 .",
    "simulations are conducted for the ( 255,127 ) rs code using bpsk over an awgn channel at @xmath393 db and @xmath394 db . ]",
    "[ h ]    the integer @xmath275 that gives the largest exponent lies in the range@xmath395    the following table [ table_2 ] presents several example ranges of @xmath275 that gives the largest exponent for some choices of @xmath237 and rs codes .",
    "simulation results also confirm our analysis .",
    "for example , in fig .",
    "[ fig : fvsa ] , @xmath396 and @xmath397 give roughly same and the largest exponents for @xmath391 while @xmath398 yields the largest exponent for @xmath390 .",
    "in fact , simulation results suggest that , typically , either @xmath357 or @xmath399 gives the best exponent .",
    "in condition [ con : asdcond ] , for lower - rate rs codes , so far we have only paid attention to ( [ eq : maincond ] ) .",
    "however , it is also required that @xmath400 or equivalently @xmath401 while it is hard to tell exactly which @xmath275 will satisfy ( [ acondt ] ) with high probability right away , we can propose a heuristic method to choose the integer @xmath275 that is likely to work .",
    "we first need the following lemma .",
    "suppose we have obtained a test - channel input - probability distribution matrix @xmath124 ( e.g. , during step 2a or step 2b in the proposed algorithms in section [ sec : proposed - algorithm ] ) and the set of erasure patterns for masd is generated independently and randomly according to @xmath124 .",
    "then , the expected score can be computed as follows:@xmath402=\\sum_{k=1}^{t}\\sum_{j=1}^{\\ell}\\sum_{i=1}^{n}m_{j , k}p_{i , j}q_{i , k}.\\label{eq : escore}\\end{aligned}\\ ] ]    the proof follows from the following equations : @xmath403= \\mathbb{e}\\left[\\sum_{k=1}^{t}\\sum_{j=1}^{\\ell}m_{j , k}\\chi_{j , k}\\right]\\label{eqes}\\\\    & \\phantom{\\mathbb{e}[s_{\\mathbf{m } } ] } =   \\sum_{k=1}^{t}\\sum_{j=1}^{\\ell}m_{j , k}\\mathbb{e}[\\chi_{j , k}]\\nonumber\\\\   & \\phantom{\\mathbb{e}[s_{\\mathbf{m } } ] } =   \\sum_{k=1}^{t}\\sum_{j=1}^{\\ell}m_{j , k}\\mathbb{e}\\left[\\sum_{i=1}^{n}\\mathbbm{1}_{\\{x_{i}=j,\\hat{x}_{i}=k\\}}\\right]\\nonumber\\\\    & \\phantom{\\mathbb{e}[s_{\\mathbf{m } } ] } =   \\sum_{k=1}^{t}\\sum_{j=1}^{\\ell}\\sum_{i=1}^{n}m_{j , k}\\pr(x_{i}=j,\\hat{x}_{i}=k)\\nonumber\\\\    & \\phantom{\\mathbb{e}[s_{\\mathbf{m } } ] } =   \\sum_{k=1}^{t}\\sum_{j=1}^{\\ell}\\sum_{i=1}^{n}m_{j , k}p_{i , j}q_{i , k}\\nonumber\\end{aligned}\\ ] ] where ( [ eqes ] ) is implied by ( [ eqscorechi ] ) .",
    "next , we propose a heuristic method to find the appropriate integer @xmath275 to work with as follows .",
    "* step 1 : start with @xmath357 , using distortion measure @xmath332 and distortion threshold @xmath388 to get the corresponding distribution matrix @xmath124 as discussed above . *",
    "step 2 : compute the expected score @xmath404 $ ] using ( [ eq : escore ] ) . if",
    "@xmath405}{k-1}\\big\\rceil = a+1 $ ] then output @xmath275 and stop .",
    "if not set @xmath406 and return to step 1 .    in simulations with small to moderate @xmath237",
    ", it is usually found that @xmath275 is either @xmath237 or @xmath407 .",
    "typically , @xmath408}{k-1}>\\mu$ ] and a unit increase of @xmath275 produces a small increase in @xmath408}{k-1}$ ] .",
    "so far , we have considered only the allowable multiplicity types in definition [ def : allowabletypes ] .",
    "it is possible to obtain better performance if we relax some constraints and allow multiplicity types to be in the relaxed set @xmath409 in this case , some theoretical results , e.g. , results in lemma 1 and theorem 2 , do not hold .",
    "however , this modification combined with the heuristic method above can improve the decoding performance , especially with large @xmath237 . specifically , we consider masd@xmath410-@xmath237 which denotes our proposed multiple asd decoding algorithm that only uses multiplicity types @xmath292 and@xmath411 of the form @xmath412 .",
    "these multiplicity types form a subset of @xmath413 .",
    "the choice of @xmath111 is suggested by observations that top-@xmath414 decoding performs almost as good as top-@xmath92 decoding for @xmath415 .",
    "the integer @xmath275 used in masd@xmath410-@xmath237 is found through the heuristic method . in fig .",
    "[ fig : fvsa-410 ] , simulations are conducted for the ( 458,410 ) rs code using bpsk over an awgn channel . for",
    "@xmath416 it can again be observed that @xmath357 gives the best exponent .",
    "more simulation results of this heuristic method can be seen in section [ sec : simulation - results ] .",
    "plot of exponent @xmath389 versus @xmath275 for @xmath417 with a fixed rate @xmath392 .",
    "the set of multiplicity types considered is the relaxed set @xmath418 .",
    "simulations are conducted for the ( 458,410 ) rs code over @xmath419 using bpsk over an awgn channel at @xmath393 db and @xmath394 db . ]",
    "for some simple distortion measures , we can compute the rd functions analytically in closed form .",
    "first , we observe an error pattern as a sequence of i.n.d .",
    "random source components .",
    "then , we compute the component rd functions at each index of the sequence and use convex optimization techniques to allocate the total rate and distortion to various components .",
    "this method converges to the solution faster than the numerical method in section [ sec : computing - rd ] .",
    "the following two theorems describe how to compute the rd functions for the simple distortion measures of proposition [ prop : bma1 ] and [ prop : bitasd ] .",
    "[ lem : onevar]consider a binary source @xmath141 where @xmath420 and @xmath421 . with the distortion measure in ( [ eq : dstfnbma ] ) ,",
    "the rate - distortion function for this source is . ]",
    "@xmath422^{+}.\\ ] ]    see appendix [ sec : applemrdmbm1 ] .",
    "[ thm:(bma - rd)](conventional errors - and - erasures `` mbm-1 '' decoding ) let @xmath423 for @xmath424 .",
    "the overall rate - distortion function is given by @xmath425^{+}\\ ] ] where @xmath426 and @xmath427 can be found be a reverse water - filling procedure ( see ( * ? ? ?",
    "* theorem 13.3.3)):@xmath428 where @xmath429 should be chosen so that @xmath430 the @xmath377 function can be achieved by the test - channel input - probability distribution@xmath431 and @xmath432    see appendix [ sec : proofthmbmard ] .",
    "[ thm:(basd - rd)](bit - level asd `` m - basd '' decoding ) let @xmath433 and @xmath434 for @xmath435 .",
    "the overall rate - distortion function in m - basd scheme is given by @xmath436^{+}\\ ] ] where @xmath437 and the distortion component @xmath438 is given by@xmath439 where @xmath440 should be chosen so that @xmath441 .",
    "the @xmath377 function can be achieved by the following test - channel input - probability distribution@xmath442 and @xmath443    [ sketch of proof ] with the distortion measure in ( [ eq : dstfnbgmd ] ) , using the method in ( * ? ? ?",
    "* chapter 2 ) we can compute the rate - distortion function components @xmath444 where @xmath445 is a lagrange multiplier such that @xmath446 for each bit index @xmath19 . then",
    ", the kuhn - tucker conditions define the overall rate allocation using the similar argument as in the proof of theorem [ thm:(bma - rd ) ] .      in this subsection",
    ", we consider the case mbm-1 whose distortion measure is given in ( [ eq : dstfnbma ] ) .",
    "we study the setup that rs codewords defined over galois field @xmath10 are transmitted over the @xmath12-ary symmetric channel ( @xmath12-sc ) which for each parameter @xmath447 can be modeled as@xmath448 here , @xmath449 ( resp .",
    "@xmath450 ) is the transmitted ( resp .",
    "received ) symbol and @xmath451 .",
    "for this channel model , we restrict our attention to the range of @xmath447 where the received symbol is the most - likely ( i.e. , @xmath452 ) .",
    "therefore , at each index @xmath19 of the codeword , the hard - decision is also the received symbol and then it is correct with probability @xmath447 .",
    "thus , we have @xmath453 for every index @xmath19 of the error pattern @xmath46 . that means , in this context we have a source @xmath46 with i.i.d .",
    "binary components @xmath151 .",
    "since the components @xmath151 s are i.i.d , we can treat each @xmath151 as a binary source @xmath141 with @xmath420 and first compute the rde function for this source @xmath141 as given by an analysis in appendix [ sec : rdeanalysis ] .",
    "based on this analysis , we obtain the following lemmas and theorems for the mbm-1 decoding algorithm of rs codes over an @xmath12-sc channel .",
    "[ lem : lemmah]let @xmath454 map @xmath455 to @xmath76 .",
    "then , the inverse mapping of @xmath456 , @xmath457\\to\\left[1-d,1-\\frac{d}{2}\\right),\\ ] ] is well - defined and maps @xmath76 to @xmath458 .",
    "@xmath459 is strictly decreasing since the derivative is negative over @xmath460 .",
    "hence , the mapping @xmath461 $ ] is one - to - one . from the analysis in appendix [ sec : rdeanalysis ]",
    ", one can also see that @xmath456 is onto .    using mbm-1 with @xmath69 decoding attempts where @xmath462 $ ] , the maximum rate - distortion exponent that can be achieved is.]@xmath463    first , note that in our context where we have a source sequence @xmath46 of @xmath1 i.i.d .",
    "source components , the rate and exponent for each source component are now @xmath464 and @xmath465 . from case 3 in appendix [ sec : rdeanalysis ] and from lemma [ lem : lemmah ] , we have @xmath466 and the theorem follows .",
    "let @xmath467 map @xmath468 $ ] to @xmath90 .",
    "then , the inverse mapping of @xmath469 , @xmath470\\rightarrow[1-d , p]\\ ] ] is well - defined and maps @xmath90 to @xmath458 .",
    "we first see that @xmath471 is a strictly convex function and achieves minimum value at @xmath472 and therefore @xmath471 is strictly decreasing over @xmath473 $ ] .",
    "thus , the mapping @xmath474\\to[0,d_{kl}(1-d\\,||\\ , p)]$ ] is one - to - one . from the analysis in appendix [ sec : rdeanalysis ]",
    ", one can also see that @xmath469 is onto .    in order to achieve a rate - distortion exponent of @xmath475",
    "$ ] , the minimum number of decoding attempts required for mbm-1 is @xmath69 where@xmath476^{+}.\\ ] ]    we also note that the rate , distortion and exponent for each source component are @xmath477 and @xmath465 respectively .",
    "combining all the cases in appendix [ sec : rdeanalysis ] , we have @xmath478^{+}\\ ] ] and the theorem follows .     performance of mbm-1(rde,11 ) and its approximation @xmath479 where @xmath90 is given in ( [ eq : computef ] ) for the ( 255,239 ) rs code over an @xmath12-sc(@xmath447 ) channel . ]    in fig . [",
    "fig : simqsc ] , we simulate the performance of mbm-1(rde,11 ) for the ( 255,239 ) rs code over an @xmath12-sc channel .",
    "one curve reflects the simulated frame - error rate ( fer ) and the other is the approximation derived from @xmath479 where @xmath90 is given in ( [ eq : computef ] ) with @xmath480 .",
    "the rd framework we use is most suitable when @xmath481 . for a finite @xmath1 ,",
    "choosing random codes for only a few lrps can be risky .",
    "we can instead use good covering codes to handle these lrps . in the scope of covering problems , one can use an @xmath92-ary @xmath482-covering code ( e.g. , a perfect hamming or golay code ) with covering radius @xmath482 to cover the whole space of @xmath92-ary vectors of the same length .",
    "the covering may still work well if the distortion measure is close to , but not exactly equal to the hamming distortion .",
    "the method of using covering codes in the lrps was proposed earlier in @xcite to choose the test patterns in iterative bounded distance decoding algorithms for binary linear block codes .    in order",
    "take care of up to the @xmath92 most likely symbols at each of the @xmath483 lrps of an @xmath0 rs , we consider an @xmath484 @xmath92-ary @xmath482-covering code whose codeword alphabet is @xmath485 then , we give a definition of the ( generalized ) error patterns and erasure patterns for this case . in order to draw similarities between this case and the previous cases",
    ", we still use the terminology `` generalized erasure pattern '' and shorten it to erasure pattern even if errors - only decoding is used . for errors - only decoding , condition [ con : bmaerr - n - era ] _ _ for successful decoding becomes@xmath486    ( error patterns and erasure patterns for errors - only decoding ) let us define @xmath94 as an error pattern where , at index @xmath19 , @xmath95 implies that the @xmath24-th most likely symbol is correct for @xmath96 , and @xmath42 implies none of the first @xmath92 most likely symbols is correct .",
    "let @xmath487 be an erasure pattern where , at index @xmath19 , @xmath488 implies that the @xmath24-th most likely symbol is chosen as the hard - decision symbol for @xmath489 .",
    "if we choose the _ letter - by - letter _ distortion measure @xmath490 defined by @xmath102_{x,\\hat{x}}$ ] in terms of the @xmath114 matrix@xmath491 then the condition for successful errors - only decoding then becomes@xmath492    it follows directly from @xmath493    if we delete the first row which corresponds to the case where none of the first @xmath92 most likely symbols is correct then the distortion measure is exactly the hamming distortion .",
    "[ [ split - covering - approach ] ] split covering approach + + + + + + + + + + + + + + + + + + + + + + +    we can break an error pattern @xmath46 into two sub - error patterns @xmath494 of @xmath483 least reliable positions and @xmath495 of @xmath496 most reliable positions .",
    "similarly , we can break an erasure pattern @xmath47 into two sub - erasure patterns @xmath497 and @xmath498 .",
    "let @xmath499 be the number of positions in the @xmath483 lrps where none of the first @xmath92 most likely symbols is correct , or @xmath500 if we assign the set of all sub - error patterns @xmath501 to be an @xmath484 @xmath482-covering code then @xmath502 because this covering code has covering radius @xmath482 .",
    "since @xmath503 in order to increase the probability that the condition ( [ eq : scpf ] ) is satisfied we want to make @xmath504 as small as possible by the use of the rd approach .",
    "the following proposition summarizes how to generate a set of @xmath69 erasure patterns for multiple runs of errors - only decoding .    in each erasure pattern ,",
    "the letter sequence at @xmath483 lrps is set to be a codeword of an @xmath484 @xmath92-ary @xmath505covering code .",
    "the letter sequence of the remaining @xmath496 mrps is generated randomly by the rd method ( see section [ sec : proposed - algorithm ] ) with rate @xmath506 and the distortion measure in ( [ eq : pfdst ] ) .",
    "since this covering code has @xmath507 codewords , the total rate is @xmath508    for a ( 7,4,3 ) binary hamming code which has covering radius @xmath509 , we take care of the @xmath414 most likely symbols at each of the 7 lrps .",
    "we see that @xmath510 is a codeword of this hamming code and then form erasure patterns @xmath511 with assumption that the positions are written in increasing reliability order .",
    "the @xmath512 sub - erasure patterns @xmath513 are generated randomly using the rd approach with rate @xmath514 .",
    "while it also makes sense to use a covering codes for the @xmath483 lrps of the erasure patterns and set the rest to be letter @xmath515 ( i.e. , chose the most likely symbol as the hard - decision ) , our simulation results shows that the performance can usually be improved by using a combination of a covering code and a random ( i.e. , generated by the rd approach ) code .",
    "more discussions are presented in section [ sec : simulation - results ] .      in this subsection",
    ", we investigate a special case of our proposed rde framework when @xmath516 ( i.e. , the set of erasure patterns consists of one pattern ) . in this case , our proposed approach is related to another line of work where one tries to design a good erasure pattern for a single bm decoding or a good multiplicity matrix for a single asd decoding @xcite .",
    "we will see that the rde approach for @xmath516 is quite similar to optimizing a chernoff bound @xcite or using the method of types @xcite .",
    "the main difference is that this approach starts from condition [ con : asdcond ] rather than its large multiplicity approximation .",
    "[ lem : rate0 ] when rate @xmath516 , the distribution matrix @xmath124 that optimizes the rde / rd function consists of only binary entries .",
    "consequently , the random codebook using the proposed rde approach ( the set of erasure patterns ) becomes a single deterministic pattern .",
    "[ sketch of proof]for each @xmath517 pair , the total rate is the sum of @xmath1 individual components as seen in proposition [ pro : factoredrde ] .",
    "therefore , the zero total rate implies all components are zero .",
    "thus , it suffices to show that if an arbitrary rate component ( denoted as @xmath76 in the proof ) is zero then the corresponding column of @xmath124 has all entries equal to @xmath518 or @xmath515 .    for the rd case ,",
    "it is well known @xcite that if @xmath516 then the distortion is given by @xmath519 where @xmath520 is the argument that achieves this minimum and the test - channel input distribution is @xmath521 computing the rde for the source distribution @xmath522 is equivalent to solving the rd problem for an appropriately tilted source distribution @xmath523 .",
    "therefore , the above property is inherited by the rde as well . in particular ,",
    "the distortion at @xmath516 is given by @xmath524 and the test - channel input distribution is supported on the singleton element that achieves this minimum .",
    "this result can also be shown directly by solving ( [ eq : rdemaxmin ] ) while dropping the rate constraint from ( [ eq : rdemaxminprd ] ) .",
    "let @xmath525 be the large deviation rate - function for the distortion when the reconstruction symbol is fixed to @xmath99 .",
    "it is well - known that this can be computed using either a chernoff bound or the method of types @xcite .",
    "both techniques result in the same function ; for @xmath526 , it is described implicitly by@xmath527    the rde function for @xmath516 is equal to@xmath528    lemma [ lem : rate0 ] shows that the reconstruction distribution must be supported on a single element .",
    "since the exponential failure probability for any fixed reconstruction symbol follows from a standard large - deviations analysis , the only remaining degree of freedom is which symbol to use .",
    "choosing the best symbol maximizes the rde .",
    "this means that the single decoding attempt with the best error - exponent can be computed as a special case of the rde approach . simplifying our proposed algorithm to use the single lagrange multiplier @xmath529 leads to an algorithm that is very similar to the one proposed in @xcite .",
    "it also seems unlikely that this new algorithm will provide any significant performance gains either in performance or complexity .",
    "a realization of rde curves at @xmath530 db for various decoding algorithms for the ( 255,239 ) rs code over an awgn channel . ]         performance of various decoding algorithms for the ( 255,239 ) rs code using 256-qam over an awgn channel . ]",
    "performance of various decoding algorithms for the ( 458,410 ) rs code over @xmath419 using bpsk over an awgn channel . ]",
    "performance of various decoding algorithms for the ( 255,127 ) rs code using bpsk over an awgn channel . ]",
    "performance of various decoding algorithms for the ( 255,191 ) rs code using 256-qam over an awgn channel . ]",
    "performance of various decoding algorithms for the ( 255,223 ) rs code using bpsk over an awgn channel . ]    in this section , we present simulation results on the performance of rs codes over an awgn channel with either bpsk or 256-qam as the modulation format .",
    "in all the figures , the curve labeled mbm-1 corresponds to standard errors - and - erasures bm decoding with multiple erasure patterns . for @xmath531 , the curves labeled mbm-@xmath92 correspond to errors - and - erasures bm decoding with multiple decoding trials using both erasures and the top-@xmath92 symbols .",
    "the curves labeled masd-@xmath237 correspond to multiple asd decoding trials with maximum multiplicity @xmath237 .",
    "the number of decoding attempts is @xmath69 where @xmath76 is denoted in parentheses in each algorithm s acronym ( e.g. , mbm-2(rd,11 ) uses the rd approach with @xmath480 while mbm-2(rde,10 ) uses the rde approach with @xmath532 ) .",
    "please note that not all the algorithms listed in this section are of the same complexity unless stated explicitly .    in fig .",
    "[ fig : rdcurve ] , the rd curves are shown for various algorithms using the rd approach at @xmath533 db where bpsk is used .",
    "for the ( 255,239 ) rs code , the fixed threshold for decoding is @xmath534 .",
    "therefore , one might expect that algorithms whose average distortion is less than @xmath535 should have a frame error rate ( fer ) less than @xmath536 .",
    "the rd curve allows one to estimate the number of decoding patterns required to achieve this fer .",
    "notice that the mbm-1 algorithm at rate @xmath518 , which is very similar to conventional bm decoding , has an expected distortion of roughly @xmath537 .",
    "for this reason , the fer for conventional decoding is close to @xmath515 .",
    "the rd curve tells us that trying roughly @xmath538 ( i.e. , @xmath539 ) erasure patterns would reduce the fer to roughly @xmath536 because this is where the distortion drops down to @xmath535 .",
    "likewise , the mbm-2 algorithm using rate @xmath480 has an expected distortion of less than @xmath540 .",
    "so we expect ( and our simulations confirm ) that the fer should be less than @xmath536 .",
    "one weakness of this rd approach is that rd describes only the average distortion and does not directly consider the probability that the distortion is greater than @xmath535 .",
    "still , we can make the following observations from the rd curve . even at high rates ( e.g. , @xmath541 )",
    ", we see that the distortion @xmath77 achieved by mbm-2 is roughly the same as mbm-3 , masd-2 , and masd-3 but smaller than masd-2a ( see example [ exa : masd2a ] ) and mbm-1 .",
    "this implies that , for this rs code , mbm-2 using the rd approach is no worse than the more complicated asd based approaches for a wide range of rates ( i.e. , @xmath542 ) .",
    "this is also true if the rde approach is used as can be seen in fig .",
    "[ fig : rdecurve ] which depicts the trade - off between rate r and exponent f for various algorithms at @xmath530 db . for this rs code ,",
    "asd based approaches have a better exponent than mbm-2 at low rates ( i.e. , small number of decoding trials ) and have roughly the same exponent for rates @xmath543 .    in fig .",
    "[ fig : berrs239 ] , a plot of the fer versus @xmath544 is shown for the ( 255,239 ) rs code over an awgn channel with bpsk as the modulation format . the conventional hdd and",
    "the gmd algorithms have modest performance since they use only one or a few decoding attempts .",
    "choosing @xmath480 allows us to make fair comparisons with sed(12,12 ) . with the same number of decoding trials , mbm-2(rd,11 ) outperforms sed(12,12 ) by @xmath545 db at fer@xmath546 .",
    "even mbm-2(rd,7 ) , with many fewer decoding trials , outperforms both sed(12,12 ) and the kv algorithm with @xmath547 . among all our proposed algorithms using the rd approach with rate @xmath480 , the mbm2-hm74(rd,11 ) achieves the best performance .",
    "this algorithm uses the hamming ( 7,4 ) covering code for the @xmath548 lrps and the rd approach for the remaining codeword positions .",
    "meanwhile , small differences in the performance among mbm-2(rd,11 ) , mbm-3(rd,11 ) , masd-2(rd,11 ) , and masd-3(rd,11 ) suggest that : ( i ) taking care of the @xmath414 most likely symbols at each codeword position is good enough for multiple decoding of this rs code and ( ii ) multiple runs of errors - and - erasures decoding is generally almost as good as multiple runs of asd decoding .",
    "recall that this result is also correctly predicted by the rd analysis .",
    "when the rde approach is used , mbm-2(rde,11 ) still has roughly the same performance as a more complex masd-3(rde,11 ) .",
    "one can also observe that these two algorithms using the rde approach achieve better performance than mbm-2(rd,11 ) and mbm2-hm74(rd,11 ) that use the rd approach .",
    "we also simulate our proposed algorithm at @xmath549 to compare with the gmd algorithm . while both mbm-2(rde,@xmath550 ) and the gmd algorithm use the same number of @xmath551 errors - and - erasures decoding attempts , mbm-2(rde,@xmath550 ) yields roughly a @xmath552 db gain .",
    "the simulation results show that , at this low rate @xmath549 , masd-3 has a larger gain over mbm-2 than at a higher rate @xmath480 .",
    "this phenomenon can be predicted in fig .",
    "[ fig : rdecurve ] where masd-3 starts to achieve a larger exponent @xmath90 at small values of @xmath76 .    to compare with the chase - type approach ( lcc ) used in @xcite , in fig .",
    "[ fig : berrs239 ] we also consider the mbm2-hm74(4 ) algorithm that uses the hamming ( 7,4 ) covering code for the @xmath548 lrps and the hard decision pattern for the remaining codeword positions .",
    "this shows that , for the ( 255,239 ) rs code , the mbm2-hm74 achieves better performance than the lcc(4 ) with the same number ( @xmath553 ) of decoding attempts . for the ( 458,410 ) rs code considered in fig .",
    "[ fig : bers458 ] , one can also observe that the group of algorithms that we propose have better performance than lcc(10 ) with the same number ( @xmath554 of decoding attempts .",
    "however , the implementation complexity of lcc(10 ) may be lower than the algorithms proposed here due to their clever techniques that reduce the decoding complexity per trial .",
    "it is also interesting to note that the method proposed here , based on covering codes and random codebook generation , is also compatible with some of the fast techniques used by the lcc decoding .",
    "we also performed simulations using qam and fig .",
    "[ fig : berrs239-qam ] shows fer versus @xmath544 performance of the same ( 255,239 ) rs code transmitted over an awgn channel with 256-qam modulation . at fer=@xmath555",
    ", our proposed algorithms mbm-2(rd,10 ) and mbm-2(rde,10 ) achieve @xmath556 db gain over sed(11,10 ) ( with the same complexity ) and also outperform kv(@xmath557 . at @xmath532 ,",
    "mbm-2 still achieves roughly the same performance as masd-3 .    in fig .",
    "[ fig : bers458 ] , a plot of the fer versus @xmath544 is shown for the ( 458,410 ) rs code that has a longer block length . in this plot ,",
    "bpsk is used as the modulation format and we also focus on rate @xmath532 . with algorithms that use the rd approach ,",
    "mbm-2(rd,10 ) still has approximately the same performance as mbm-3(rd,10 ) , masd-2(rd,10 ) , masd-3(rd,10 ) .",
    "however , when the rde approach is employed , algorithms that run multiple asd decoding attempts have a recognizable gain over algorithms that use multiple runs of bm decoding .",
    "the performance gain of the rde approach ( over the rd approach ) is small , but can be seen easily by comparing masd-3(rde,10 ) to masd-3(rd,10 ) . as a reference",
    ", we also plot the performance of kv(@xmath558 ) which corresponds to the proportional kv algorithm @xcite with the scaling factor @xmath558 .    in fig .",
    "[ fig : rs410asdm ] , the same setting is used as in fig .",
    "[ fig : bers458 ] .",
    "as can be seen in the figure , kv(@xmath547 ) achieve better performance than masd-3(rde,10 ) and mbm-2(rde,10 ) .",
    "however , by considering higher @xmath237 , our algorithms using the heuristic method masd@xmath410 - 10(rde,10 ) and masd@xmath410 - 20(rde,10 ) can outperform kv(@xmath547 ) .    to target rs codes of lower rate ,",
    "we also ran simulations of the ( 255,127 ) rs code over an awgn channel with bpsk modulation and the results can be seen in fig .",
    "[ fig : bers127 ] . while mbm-2(rde,6 ) , mbm-2(rd,6 ) , sed(7,6 ) and gmd all use the same number of about @xmath559 errors - and - erasures decoding attempts , our proposed mbm-2 algorithms outperforms the other two algorithms . as seen in the plot , masd-3(rde,6 )",
    "has quite a large gain over mbm-2(rd,6 ) which is reasonable since asd decoding is known to perform very well compared to bm decoding with low - rate rs codes . in this figure , kv(@xmath560 )",
    "denotes the proportional kv algorithm @xcite with the scaling factor @xmath560 and therefore with maximum multiplicity @xmath391 . while masd-3(rde,6 ) with @xmath559 decoding attempts outperforms kv(@xmath560 )",
    "as expected , the small gain of roughly @xmath561 db at fer=@xmath555 suggests that with low - rate rs codes , one might prefer increasing @xmath237 in a single asd decoding attempt to running multiple asd decoding attempts of a lower @xmath237 .    in fig .",
    "[ fig : berrs191qam ] , we show the fer versus @xmath562 performance for the ( 255,191 ) rs codes using 256-qam . again , our proposed algorithm mbm-2(rde,5 ) performs favorably compared to sed(6,6 ) and gmd with the same number of about @xmath563 errors - and - erasures decoding attempts . under this setup , masd-2(rde,5 ) and",
    "masd-3(rde,5 ) achieve significant gains over mbm-2(rde,5 ) .",
    "our proposed masd-3(rde,11 ) and masd-3(rde,5 ) algorithms have fairly the same performance as the proportional kv algorithm with the scaling factor @xmath564 and @xmath565 , respectively .",
    "to compare with the iterative erasure and error decoding ( ieed ) algorithm proposed in @xcite , we also conducted simulations of the ( 255,223 ) rs code over an awgn channel using bpsk and the results are shown in fig .",
    "[ fig : berrs223 ] . with the same number of about @xmath535 errors - and - erasures decoding attempts , our proposed mbm-2(rde,@xmath566 ) algorithm outperforms both the gmd and 17-ieed algorithms",
    "in fact , at fer smaller than @xmath567 , mbm-2(rde,@xmath566 ) has roughly the same performance as 32-ieed which needs to use @xmath563 decoding attempts .",
    "meanwhile , mbm-2(rde,5 ) that uses @xmath563 decoding attempts performs as good as 112-ieed where @xmath568 decoding attempts are required .",
    "a unified framework based on rate - distortion ( rd ) theory has been developed to analyze multiple decoding trials , with various algorithms , of rs codes in terms of performance and complexity .",
    "an important contribution of this paper is the connection that is made between the complexity and performance ( in an asymptotic sense ) of these multiple - decoding algorithms and the rate - distortion of an associated rd problem .",
    "based on this analysis , we propose two solutions ; the first is based on the rd function and the second on the rd exponent ( rde ) .",
    "the rde analysis shows that this approach has several advantages .",
    "firstly , the rde approach achieves a near optimal performance - versus - complexity trade - off among algorithms that consider running a decoding scheme multiple times ( see remark [ rem : advantage ] ) .",
    "secondly , it helps estimate the error probability using exponentially tight bounds for @xmath1 large enough .",
    "further , we have shown that covering codes can also be combined with the rd approach to mitigate the suboptimality of random codes when the effective block - length is not large .",
    "as part of this analysis , we also present numerical and analytical computations of the rd and rde functions for sequences of i.n.d .",
    "sources . finally , the simulation results show that our proposed algorithms based on the rd and rde approaches achieve a better performance - versus - complexity trade - off than previously proposed algorithms .",
    "one key result is that , for the @xmath569 rs code , multiple - decoding using the standard berlekamp - massey algorithm ( mbm ) is as good as multiple - decoding using more complex algebraic soft - decision algorithms ( masd ) .",
    "however , for the @xmath570 rs code , the rde approach improves the performance of masd algorithms beyond that of mbm decoding .",
    "simulations results suggest an interesting conjecture that for moderate - rate rs codes , multiple asd decoding attempts with small @xmath237 is preferred while for low - rate rs codes , a single asd decoding with large @xmath237 may be preferred .",
    "this conjecture remains open for future research .",
    "our future work will also focus on extending this framework to analyze multiple decoding attempts for intersymbol interference channels . in this case",
    ", it will be appropriate for the decoder to consider multiple candidate error - events during decoding . extending the rd and rde approaches directly to this case is not straightforward since computing the rd and rde functions for markov sources in the large distortion regime is still an open problem .",
    "another interesting extension is to use clever techniques to reuse the computations from one stage of errors - and - erasures decoding to the next in order to lower the complexity per decoding trial ( e.g. , @xcite ) .",
    "using the formula in @xcite , we have@xmath571    for mbm-@xmath92 with distortion matrix in ( [ eq : dstmbml ] ) , we have @xmath572 for @xmath573 and @xmath574 .",
    "therefore,@xmath575 since @xmath576 .",
    "similarly , for masd-@xmath237 with distortion matrix @xmath360 in ( [ eq : dstmasdmu_allrate ] ) , we have @xmath577 for @xmath303 .",
    "since multiplicity type 1 is always defined to be @xmath280 , we have @xmath578 and consequently , @xmath579 therefore , we obtain @xmath580 if masd-@xmath237 uses multiplicity type @xmath383 ) which is , for example , labeled as type @xmath273 then we have @xmath581 consequently , @xmath582 and this completes the proof .",
    "with the notation @xmath583 , according to @xcite we have @xmath584    the function @xmath377 is not defined for @xmath585 and @xmath586 for @xmath379 . for the case",
    "@xmath378 , the rate - distortion function @xmath377 is given by solving the following convex optimization problem    @xmath587    where the mutual information @xmath588 and the test - channel input probability - distribution@xmath589    we then form the lagrangian@xmath590    and the karush - kuhn - tucker ( kkt ) conditions become notation.]@xmath591    by ( * ? ? ?",
    "* lemma 1 , p. 32 ) , we only need to consider the following cases .",
    "@xmath592 case 1 : @xmath593 . in this case , we further have @xmath594 this leads to @xmath516 and @xmath595 which is a contradiction as we only consider @xmath596 .    @xmath592 case 2 : @xmath597 . in this case",
    ", we have @xmath598 this leads to @xmath516 and @xmath599 which is also a contradiction .",
    "@xmath592 case 3 : @xmath600 . in this case , we know @xmath601 and then , from @xmath602 , we obtain @xmath603 equivalently , we have@xmath604    letting @xmath605 and noticing that @xmath606 , we get @xmath607    putting this into the constraints@xmath608 we have a set of 3 equations involving 3 variables @xmath609 .",
    "solving this gives us@xmath610    therefore , we can obtain the optimizing @xmath611 and have @xmath612    hence , in all cases @xmath613^{+}$ ] and we conclude the proof .",
    "the objective here is to compute the rd function for a discrete source sequence @xmath46 of i.n.d .",
    "source components @xmath151 .",
    "first , with the notations @xmath614 and @xmath615 for @xmath616 and @xmath617 lemma [ lem : onevar ] gives us the rate - distortion components@xmath618^{+}\\ ] ] along with the test - channel input - probability distributions @xmath619 for each index @xmath19 of the codeword .",
    "the overall rate - distortion function is given by @xmath620^{+}\\end{aligned}\\ ] ] which is a convex optimization problem .",
    "using lagrange multipliers , we form the functional @xmath621 and compute the derivatives @xmath622    the kuhn - tucker condition ( see the restated version in @xcite , page 86 ) then tells us that there is @xmath623 such that @xmath624 which is equivalent to@xmath625    with the notations @xmath426 and @xmath626 , it is equivalent to @xmath627    finally , it becomes @xmath628 where @xmath629 and we conclude the proof .",
    "consider a binary single source @xmath141 with @xmath420 and @xmath630 . according to @xcite , for any admissible @xmath201 pair",
    "we can find two parameters @xmath180 and @xmath148 so that @xmath83 can be parametrically evaluated as @xmath631 where @xmath632 and @xmath633 are given in terms of optimizing @xmath634 .    for the distortion measure in ( [ eq : dstfnbma ] ) and with @xmath635",
    ", we have @xmath636 which is a convex function in @xmath637 .",
    "taking the derivative @xmath638 gives us @xmath639    in order to minimize @xmath640 over @xmath641 $ ] , we consider three following cases where the optimal @xmath642 is either on the boundary or at a point with zero gradient .",
    "@xmath592 case 1 : @xmath643 then @xmath644 . since @xmath645 convex , it is non - decreasing in the interval @xmath646 and therefore in the interval @xmath647 $ ] .",
    "thus , the optimal @xmath648 and we can also compute @xmath649    @xmath592 case 2 : @xmath650 then @xmath651 . since @xmath645 convex , it is non - increasing in the interval @xmath652 $ ] and therefore in the interval @xmath647 $ ] .",
    "thus , the optimal @xmath653 and we get @xmath654 where in this case @xmath655 .",
    "we can further see that @xmath656 $ ] and @xmath468 $ ] .",
    "@xmath592 case 3 : @xmath657 then @xmath658 . in this case , the optimal @xmath659 .",
    "we can find @xmath660 according to @xcite and then obtain @xmath661 where @xmath662 with this notation of @xmath458 , we can express @xmath663 we can see that @xmath664 .",
    "it can also be verified that , in this case , by varying @xmath212 and @xmath665 @xmath458 spans @xmath666 and @xmath76 spans @xmath667 .",
    "the authors would like to acknowledge the support of seagate through the nsf goali program and thank fatih erden and xinmiao zhang for valuable discussions on this topic .",
    "the authors are also grateful to the associate editor and anonymous reviewers for comments that improved the quality of the paper .",
    "lee and b.  v. k.  v. kumar , `` soft - decision decoding of reed - solomon codes using successive error - and - erasure decoding , '' in _ proc .",
    "ieee global telecom .",
    "_ , new orleans , la , nov . 2008 , pp . 15 .        h.  tokushige , i.  hisadomi , and t.  kasami , `` selection of test patterns in an iterative erasure and error decoding algorithm for non - binary block codes , '' _ ieice trans",
    ".  fundamentals of electronics , communications and computer sciences _ , vol .",
    "e89-a , no .",
    "11 , pp . 33553359 , nov .",
    "j.  bellorado and a.  kavi , `` low - complexity soft - decoding algorithms for reed - solomon codes - part i : an algebraic soft - in hard - out chase decoder , '' _ ieee trans .  inform .",
    "theory _ , vol .",
    "56 , no .  3 , pp .",
    "945959 , 2010 .",
    "h.  xia , h.  wang , and j.  r. cruz , `` a chase - gmd algorithm for soft - decision decoding of reed - solomon codes on perpendicular channels , '' in _ proc .",
    "ieee int .",
    ".  commun .",
    "_ , beijing , china , may 2008 , pp . 19771981",
    ".    j.  jiang and k.  r. narayanan , `` iterative soft - input - soft - output decoding of reed - solomon codes by adapting the parity - check matrix , '' _ ieee trans .",
    "theory _ , vol .",
    "52 , no .  8 , pp .",
    "37463756 , 2006 .",
    "m.  el - khamy and r.  j. mceliece , `` interpolation multiplicity assignment algorithms for algebraic soft - decision decoding of reed - solomon codes , '' _ ams - dimacs volume on algebraic coding theory and information theory _ ,",
    "68 , pp . 99120 , 2005 .",
    "h.  das and a.  vardy , `` multiplicity assignments for algebraic soft - decoding of reed - solomon codes using the method of types , '' in _ proc .",
    "ieee int .",
    "information theory _ ,",
    "seoul , korea , june 2009 , pp .",
    "12481252 .",
    "g.  matz and p.  duhamel , `` information geometric formulation and interpretation of accelerated blahut - arimoto - type algorithms , '' in _ proc .",
    "ieee inform .",
    "theory workshop _ , san antonio , tx , oct .",
    "2004 , pp . 6670 .",
    "h.  tokushige , t.  koumoto , m.  fossorier , and t.  kasami , `` selection method of test patterns in soft - decision iterative bounded distance decoding algorithms , '' _ ieice trans .",
    "fundamentals of electronics , communications and computer sciences _ , vol .",
    "e86-a , no .",
    "10 , pp . 24452451 , oct ."
  ],
  "abstract_text": [
    "<S> one popular approach to soft - decision decoding of reed - solomon ( rs ) codes is based on using multiple trials of a simple rs decoding algorithm in combination with erasing or flipping a set of symbols or bits in each trial . </S>",
    "<S> this paper presents a framework based on rate - distortion ( rd ) theory to analyze these multiple - decoding algorithms . by defining an appropriate distortion measure between an error pattern and an erasure pattern , the successful decoding condition , for a single errors - and - erasures decoding trial , </S>",
    "<S> becomes equivalent to distortion being less than a fixed threshold . </S>",
    "<S> finding the best set of erasure patterns also turns into a covering problem which can be solved asymptotically by rate - distortion theory . </S>",
    "<S> thus , the proposed approach can be used to understand the asymptotic performance - versus - complexity trade - off of multiple errors - and - erasures decoding of rs codes .    </S>",
    "<S> this initial result is also extended a few directions . the rate - distortion exponent ( rde ) </S>",
    "<S> is computed to give more precise results for moderate blocklengths . </S>",
    "<S> multiple trials of algebraic soft - decision ( asd ) decoding are analyzed using this framework . </S>",
    "<S> analytical and numerical computations of the rd and rde functions are also presented . </S>",
    "<S> finally , simulation results show that sets of erasure patterns designed using the proposed methods outperform other algorithms with the same number of decoding trials . </S>"
  ]
}