{
  "article_text": [
    "the contrast in dominant dynamical processes that characterise geophysical systems , split in orthogonal directions parallel and perpendicular to the local gravitational acceleration @xmath0 , leads to a spatial decoupling that restricts the parameter space of general spatial domains @xmath1 .",
    "meshes of geophysical domains can be built differently in these distinct directions in order to well - support the associated dynamics , with mesh characteristics on the geoid plane considered independently of those in the perpendicular direction of @xmath0 .",
    "a formal description of the heterogeneous set of constraint functions , homeomorphic mappings and topological spaces , required to fully describe geophysical model domain spatial discretisations , is developed and detailed in @xcite , of which a summary of the key outcome follows .",
    "[ constraints ] the spatial domain discretisation for a computational geophysics simulation in a domain @xmath2 , requires the constraint of    [ constraint : brep ] _ geoid boundary representation _",
    "@xmath3 , of the geoid surface @xmath4 , inclusive of the maximal extent of @xmath5 perpendicular to @xmath0 . under a homeomorphic projection @xmath6 ,",
    "this is considered as the chart @xmath7 , such that the boundary @xmath8 is described by     :",
    "t ( t ) ^2 , & & [ brep ]    an orientated vector path of the encompassing surface geoid bound defined in two - dimensionalparameter space .",
    "[ constraint : hmetric ] _ geoid element edge - length resolution metric _ for dynamics aligned locally to a geoid , described by the functional    _ h :  _ h ( ) ^2 ^ 2 . & & [ hmetric ]    [ constraint : id ] _ boundary and region identification _ , prescribed by    n_ : t n_ ( t ) , & & [ idbound ]    n_ :  n_ ( ) , & & [ idregion ]    [ constraint : surfbounds ] _ surface bounds _ , height maps defined on the surface geoid domain , described by the functions    f , g : . & & [ surfbounds ]    [ constraint : vmetric ] _ vertical element edge - length resolution metric _ for dynamics in the direction of gravitational acceleration ( e.g. buoyancy driven ) , described by the functional    _ v : _ v ( ) . & & [ vmetric ]      the spatial decoupling permits discretisation in two stages corresponding to directions parallel and perpendicular to the local gravitational acceleration ( refer to [ fig : block ] ) .",
    "firstly , the ` horizontal ' geoid surface domain discretisation problem is solved under [ constraint : brep , constraint : hmetric , constraint : id ] using the surface geoid boundary representation @xmath8  ( [ brep ] ) , geoid element edge - length metric @xmath9  ( [ hmetric ] ) , with boundary and region identifications , @xmath10  ( [ idbound ] ) and @xmath11  ( [ idregion ] ) respectively , such that @xmath12 a tessellation of @xmath7 , with identification elements .",
    "secondly , if needed , this is followed by discretisation in a direction aligned with gravitational acceleration .",
    "the [ constraint : surfbounds , constraint : vmetric ] , describing the surface bounds @xmath13 and @xmath14  ( [ surfbounds ] ) and vertical edge - length metric @xmath15  ( [ vmetric ] ) , together with the surface geoid discretisation @xmath16 [ h ] , forms a discretisation problem that is solved through the process @xmath17 to give the full domain discretisation of @xmath2 , with identification elements .      [",
    "tenet : brep ] accurate description and _ representation of arbitrary and complex boundaries _ such that they are contour - following to a degree prescribed by the metric size field , with aligned faces so forcing data is consistently applied ( @xmath8 , @xmath13 , @xmath14 ) .    [",
    "tenet : metric ] _ spatial mesh resolution _ to minimise error ; with efficient aggregation of contributing factors , ease of prototyping and experimentation of metric functions and contributing fields , over the entire extent of the bounded domain ( @xmath9 , @xmath15 ) .",
    "[ tenet : region ] accurate geometric _ specification of regions _ and _ boundary features _ ; to provide for appropriate interfacing of regions of differing physics , model coupling and parameterisation application ( @xmath11 , @xmath10 ) .",
    "[ tenet : consistent ] _ self - consistent _ , such that all contributing source data undergoes the same pre - processing , ensuring self - consistency is inherited .",
    "[ tenet : efficient ] _ efficient drafting and prototyping _ tools ,    such that user time can be focused on high - level development of the physics and initialisation of the modelled system .",
    "[ tenet : scales ] _ scalability _ , with operation on both small and large datasets , facilitating the easy manipulation and process integration , independent of data size .",
    "[ tenet : automated ] _ hierarchy of automation _",
    ", such that individual automated elements of the workflow can be brought down to a lower - level for finer - scale adjustments .",
    "[ tenet : provenance ] _ provenance _ to ensure the full workflow from initialisation to simulation and verification diagnostics are reproducible .",
    "[ tenet : standard ] _ standardisation of interaction _ to enable interoperability between both tools and scientists .    accompanying the constraints",
    ", @xcite identifies the nine attributes listed in [ fig : tenets ] as key to geophysical mesh generation processes .",
    "the functional forms [ brep , hmetric , idbound , idregion , surfbounds , vmetric ] of the unstructured meshing problem require a range of types of data , from more standard two - dimensionalraster maps , to tensors and orientated vector paths .",
    "it is a challenge to manage this heterogeneous collection of parameters ( [ tenet : efficient , tenet : provenance ] ) , such that they are handled consistently ( [ tenet : consistent ] ) and for the level of complexity that can be encountered ( [ tenet : scales , tenet : automated ] ) .",
    "this is in contrast with the structured mesh case , which requires relatively simple data of the same format as its inputs : a two - dimensionaldigital elevation map ( dem ) raster dataset supplying a two - dimensionalraster mask , for example .    , projection @xmath6 and [ constraint : brep , constraint : hmetric , constraint : id , constraint : surfbounds , constraint : vmetric ] .",
    "]        < ?",
    "xml version=1.0 encoding=utf-8 ?",
    "> < boundary_representation > < model_name > < string_value lines=``1''>chile_talcahuano</string_value > < /model_name > < global_parameters/ >",
    "< output > < projection > < string_value > latlongwgs84</string_value > < /projection > < /output > <",
    "dataset name=``gebco2014 '' > < form name=``raster '' >",
    "< source name=``opendap '' file_name=``http://ecco2.jpl.nasa.gov/ opendap / hyrax / data2/data / bathymetry / gebco2014/ gebco_2014_2d.nc''/ > < /form > < projection name=``native''/ > < region_selection name=``automatic''/ > < /dataset > < geoid_surface_representation name=``southeastpacificocean '' > < identification > < integer_value rank=``0''>9</integer_value > < /identification >",
    "< brep_component name=``southeastpacificoceancoast '' > < form name=``raster '' >",
    "< source name=``gebco2014''/ > < region > < longitude >",
    "< minimum>-77.0</minimum > < maximum>-71.0</maximum >",
    "< /longitude > < latitude > < minimum>-40.0</minimum > < maximum>-32.0</maximum > < /latitude > < /region > < contourtype name=``coastline0m''/ > < comment > simple single bounding box centred about the epicentre 35.909s 72.733w.</comment > < /form > < identification name=``coast''/ > < representation_type name=``bsplines''/ > < /brep_component > < brep_component name=``openmeridian '' > < form name=``extendtomeridian '' > < longitude > < real_value rank=``0''>-77.0</real_value > < /longitude >",
    "< /form > < identification name=``openocean''/ > < representation_type name=``bsplines''/ > < /brep_component > < boundary name=``coast '' > < identification_number > < integer_value rank=``0''>3</integer_value > < /identification_number >",
    "< /boundary > < boundary name=``openocean '' > < identification_number >",
    "< integer_value rank=``0''>4</integer_value > < /identification_number >",
    "< /boundary > < /geoid_surface_representation >",
    "< geoid_metric > ... < /geoid_metric > < validation >",
    "< test name=``brepdescription '' file_name=``data / chile_talcahuano.geo.bz2 '' > < compressed/></test >",
    "< test name=``nodenumber '' > ...",
    "< /validation > < /boundary_representation >    mesh specification in the unstructured case , with flexibility to include conforming boundaries , is much more like the initialisation of a numerical simulation model .",
    "this typically contains a heterogeneous set of functions : those defined over @xmath18 initialising or forcing full fields , together with boundary conditions defined on surfaces in @xmath19 and potentially line and point sources , or full field functions of reduced rank such as the gravitational acceleration parameter , or value of a bulk eddy viscosity , for example .",
    "mesh descriptions and constraints are only going to become more complex as simulation models include a larger range of spatial scales and physical processes .",
    "moreover , like a simulation model , unstructured mesh generation includes calculations that can be computationally demanding .",
    "the generation of conforming boundary representations is no longer a simple binary operation identifying which elements lie in the simulation domain through mask fields .",
    "similarly , the construction of domain discretisations with variable element sizes contains many more unknowns in the unstructured case than the corresponding local cell - division approaches typically used to increase spatial resolution in the structured case .    in light of this , shingletakes the approach that domain discretisation specification and generation is best considered as a model problem .",
    "formalised , the output mesh is the solution of a discretisation problem under a heterogeneous parameter space of constraints .",
    "much like numerical model input parameter specification , mesh generation is often overlooked , and a secondary consideration to the dynamical core of a numerical model .",
    "typically inputs are ad hoc , model - specific , plain text files containing name lists that are expanded as a model develops . for only but simple cases ,",
    "this leads to model interfaces ( and their associated pre- and post - processing tools ) that are difficult to maintain and simulation setups that are not easily shared and understood .",
    "this problem of model input parameter specification is considered in @xcite , together with the proposed solution spud .",
    "this provides a generalised , model - independent method of describing all constraints to a model problem , that is dynamic , easily extensible with a hierarchical context for parameters .",
    "formal grammars guide user input , minimise errors and formalise parameter specification .",
    "the options available to describe a mesh discretisation are typically defined by model interfaces .",
    "these tend to be ad hoc and unportable , tied directly to numerical simulation codes .",
    "initialisation tools then require their own implementation to interpret and write model options , which is prone to error and potential inconsistencies .",
    "existing file formats have been used , and their syntax overloaded , to describe geophysical spatial discretisations .",
    "ice sheet domains are built up using a constructive solid geometry ( csg ) approach within the comsol  @xcite multi - physics modelling environment in @xcite .",
    "the geocubit  @xcite branch of cubit developed for seismic inversion domains , and a plugin for gmsh  @xcite to enable the creation of domains bounded by paths from the global self - consistent , hierarchical , high - resolution geography ( gshhg , * ? ? ? * ) .",
    "extensions to gis ( e.g. * ? ? ?",
    "* ) enable a flexible development of geoid surface boundary representations .",
    "extensibility of these frameworks for the purposes of geophysical domain discretisation and model initialisation is limited , with for example gis frameworks being built up from working on two - dimensionalraster fields .",
    "similarly , project files associated with gis do not contain all of the information required to fully constrain a spatial discretisation problem , and moreover , it is not possible to include the high - level natural language functional descriptions proposed here . as @xcite demonstrates though , gis methods can benefit geophysical domain development , and their role is included in the schematic [ fig : process ] .",
    "use of spud enables a description of model option parameter space to be considered separately .",
    "this is constructed in a schema file , a machine readable specification of which options are expected , their type and context , and how they should be read : a formal grammar to be used to describe model constraints .",
    "the [ constraint : brep , constraint : hmetric , constraint : id , constraint : surfbounds , constraint : vmetric ] that fully describe the geophysical domain discretisation problem have been structured into a schema .",
    "a schematic of the included components and their relationship to required constraints is shown in [ fig : block ] .",
    "this is a single hierarchical and formal description of the constraint space , and more generally the options available to the user in generating a mesh . as illustrated in [ fig : process ] , it is part of shingleand is central to how components of the approach interact with brmlfiles that describe a particular meshing problem . at the simplest , highest level use of shingle , this is transparent to the user . for more advanced use and development , it provides a centralised and language - based description of the constraint space that all other parts of shingle , and the geophysical mesh generation process , depend .",
    "just like the case of a numerical model , there are a wide range of possible options in mesh generation , even when restricted to geophysical problems .",
    "the brmlschema builds on the general schema language for simulation models prepared in @xcite , to give an option - complete language for the mesh generation problem .",
    "this is exactly the type of purpose spud is intended for and other current models in development are adopting this approach to formally describe model constraint spaces , like for example the new terraferma model of @xcite .",
    "this caters for options which may be specified multiple times , at potentially varying levels of option hierarchy in multiple contexts .",
    "for example , as the block diagram of [ fig : block ] highlights , a simulation domain can contain multiple geoid surfaces @xmath8 , each with potentially multiple boundary representation components ( e.g. simple orientated polylines with identification ) .",
    "brmlis an xml language , and by nature is hierarchical and extensible . with this structure , and guided by what the schema permits ( itself representing the [ constraint : brep , constraint : hmetric , constraint : id , constraint : surfbounds , constraint : vmetric ] ) , it is easy to dynamically add , repeat , expand and remove options and groups of options whilst in context .    as an example",
    ", use of the spud framework immediately provides access to the diamond gui which enables easy editing and drafting of new domain discretisations .",
    "this gui uses the schema file ( see [ fig : process ] ) to guide navigation of the option tree . through this",
    "the gui knows to expect at least one definition of a geoid surface @xmath8 , for example , and a specification of a geoid metric @xmath9 ( and requires these from the user ) .",
    "additional geoid surfaces or more feature - rich boundary representation components are easily added and built up at a later stage , dynamically increasing the complexity of the mesh generation problem .",
    "options are structured into a hierarchical tree within the brmldescription .",
    "the grouping of [ constraint : brep , constraint : hmetric , constraint : id , constraint : surfbounds , constraint : vmetric]and decoupling ( [ sec : decoupled ] ) are naturally structured in this way , as [ fig : block ] highlights .",
    "this is much like numerical simulation model options parameters , which motivated the development of spud and adoption of an underlying xml - based language .    in some cases there",
    "exist dependencies across the option tree , and these are achieved through attribute names .",
    "for instance , the choice has been made to centralise source dataset definitions .",
    "these are named ( e.g. ` gebco2014 ' in [ fig : gui , fig : brml ] ) and this name referred back to whenever the data is required .",
    "this is also used to assign potentially multiple boundary representationcomponent sections to the same named boundary identification ( e.g. the ` coast ' and ` openocean ' named identifications of [ fig : gui , fig : brml ] ) .",
    "this also allows component boundary representationssections to be used multiple times .",
    "this is required , for example , when distinct physical regions meet at an interface ( e.g. the open ocean meets an ice sheet ) and share a boundary .",
    "the component boundary representationsection defining the interface can then be referred to out of the order defined by the hierarchy , and from potentially separate parent geoid surface representation @xmath8 ( where for instance @xmath20 and @xmath21 are setup to represent neighbouring geoid surface representations for the ocean and ice , respectively ) .",
    "domains for geophysical simulations are typically described with reference to bounding lines on orthodromes such as meridians and parallels , together with global or segments of contours such as a 0 m coastline , for example .",
    "more generally , geographic features are identified with a similar combination . the southern ocean for example ,",
    "is defined extending up from the antarctic coast to the 60s parallel , and the atlantic and indian oceans divided at the 20e meridian .",
    "this is the natural way to identify bounds for geophysical models .",
    "setting up these geographic bounds and including all features contained within in a format suitable for meshing algorithms can be a time consuming , difficult to edit and repeat , ad hoc process .",
    "shingleautomates this and from a basis of natural language definitions typically used in geophysical modelling studies .",
    "the original consistent boundary representation generation approach described in @xcite enabled sections of contours to be selected and domains extended meridionally to parallels .",
    "this has been generalised significantly to allow a wide range of arbitrary bounds described with natural language definitions .",
    "moreover these can be defined multiple times , and in context with hierarchy available within the brmldescription . in the example presented in [ fig",
    ": gui , fig : brml ] the boundary representationcan be seen to include two components : a section of the chilean coastline and a second extending the domain out to a meridian at 7w , mirroring those in the description ( ) .",
    "more flexible functional descriptions can be made within the brmlwritten directly in python .",
    "this again in a relatively readable form , using primitives such as the positions ` longitude ' and ` latitude ' , or universal transverse mercator ( utm ) coordinates ` x ' and ` y ' .",
    "this can be used to describe an arbitrary orthodrome , for example .",
    "in addition to this , the natural language basis can be supplemented with raw discrete data types such as orientated polylines from the gshhg database , mapping databases ( e.g. the uk national @xcite resource ) or those developed directly in a gis as @xcite demonstrates , bounding a domain to the complex uk coastline together with the fine man - made structures of portland harbour .",
    "the high fidelity boundary representationis not only built up from components constructed on - the - fly from functional forms referencing geographic features , but also discretised forms containing an explicit description of domain constraints , if needed ( see [ fig : process ] ) .",
    "these are available through the central dataset section of the option hierarchy ( [ fig : block ] ) , and accessed from local or distributed resources .",
    "the constraint space description developed in the brmlschema is self - describing , containing a verbose description of each option .",
    "this information can presented alongside options in the gui ( see the top right of [ fig : gui ] , for example ) or reported for any option errors occurring at run time , again from this centralised constraint space descriptor resource , the schema . in this way the schema , and as a result the gui , act as a manual , directly supporting users as mesh options are made .",
    "from the developer s perspective , this spud based approach means new features can be added with minimal code changes .",
    "the xml based structure means codes focus on patterns of options .",
    "the schema defines what expected and the code loops through the hierarchy following well - defined patterns , picking up options from a corresponding in - memory dictionary tree .    for the user , mesh generation with real fractal - like boundaries can be as simple as selecting a coastline segment by a bounding box and on the other side a bounding orthodrome , with choice of element edge - length metric ( see [ fig : chile ] ) .",
    "a complete description of the domain discretisation problem is a fundamental requirement if an accurate record of provenance is to be made , and this is provided by the brmlfile .",
    "these brmlfiles alone are themselves easily parsable xml based problem description files , human - readable with structure .",
    "this is focused on a textual natural language problem description and is lightweight as a result such that changes are easily tracked with version control systems such as git and svn .    together with the problem description , the brmlmaintains details of authors responsible for their creation , contact details , comments including timestamped notes on past changes made in development ( seen in [ fig : block , fig : gui ] ) .",
    "this is similar to the record kept within the global attribute metadata contained in netcdf headers , which is supplemented through operations performed on the data with tools such as the geospatial data abstraction library @xcite . the adcirc hydrodynamic circulation model @xcite makes a record of this type of information in its netcdf output , inherited from its initialisation namelist files .",
    "shinglerecords this information in output where possible , notably the high fidelity boundary representation , supplementing it with a record of the library release version and unique repository abbreviated commit hash .",
    "unique identifiers of other libraries are also recorded , such as the version of the meshing tool employed ( e.g. gmsh ) .",
    "data contributing to discrete domain characterisations can be large in size , difficult to distribute efficiently and computationally costly to process .",
    "the current version of the global bathymetry dataset @xcite containing only elevation is currently @xmath22 in size , for example .",
    "efforts are growing to provide a complete provenance record of numerical model simulations , with direct instructions from research funders requiring a research data management plan @xcite and in general , accountability from the public , it is important to detail data source origin and content accurately .",
    "options for the management of mesh generation source data range from :    recast data into form suitable for distribution and share with brmldescription .    distribute processed datasets with brmlirrespective of size .",
    "[ dataoption3 ] begin from a standardised raw dataset , and conduct potentially computationally demanding processing as needed .",
    "[ dataoption4 ] refer to remote repositories of source data , such that data is downloaded and processed on demand .",
    "often this data processing stage of the mesh generation process is not well - described , and difficult to reproduce , with filtering , subsampling and agglomeration operations only loosely outlined .",
    "modern data descriptors support a record of provenance ( such as the  history  field embedded in netcdf , * ? ? ?",
    "* ) , so it would be possible to record the filtering , subsampling and other processing here or within the brml .",
    "the purpose of the brmldescription of constraints is to provide an accurate description of the meshing problem .",
    "it is not the intent to reinvent new standards for data description . along this line of design , with a focus on provenance record and how data is handled , and noting the computational demands and connectivity speeds that affect [ dataoption3,dataoption4 ] above will continue to improve in the future , the approach is made to depend directly on raw , standard and potentially remote data sources .",
    "the problem of efficient access to large remotely hosted data sources is tackled by @xcite which describes opendap(open - source project for a network data access protocol ) .",
    "the protocol has since been adopted by many organisations who host servers providing opendapservices .",
    "this includes a large amount of environmental data in the global change master directory ( gcmd ) provided over opendapby nasa .",
    "other data libraries such as the noaa national oceanographic data center and british oceanographic data centre are expanding the range of data delivered over opendap .",
    "some opendapservers additionally maintain a catalogue of other servers worldwide such as the threadds host at deltares .",
    "specific numerical simulation models too have their own dedicated servers to host output such as the ocean models hycom and romshttp://megara.tamu.edu:8080 ,  http://tds.marine.rutgers.edu ] .",
    "this has typically been applied to sharing geophysical model output data in combination with the ( netcdf * ? ? ?",
    "* ) and climate and forecast ( cf , * ?",
    "* ) metadata standards @xcite , for intercomparisons and post - processing analysis .",
    "here we apply opendapto model initialisation . in shingle",
    ", this opendapnegotiation is achieved using the standard python library pydap . in this way",
    "shinglecan request fundamental operations are applied to distributed datasets before they are delivered for further processing , picking out required fields and regions of interest to reduce the size of data communicated . a description of further processing such as subsampling and filtering",
    "is then maintained in the brmland executed through standardised python wrappers to established geospatial tools such as @xcite . a reference in place for the @xcite data source hosted on the nasa / jpl ecco opendapserver",
    "is made in [ fig : brml ] , where the region of interest ( for cropping on the remote server ) is automatically established by its use further down in the tree .    keeping the brmlfocused on problem description , with references to source data ,",
    "ensures it is lightweight and portable .",
    "iterative adjustments to the mesh generation are also then made with changes to descriptions rather than data .",
    "furthermore , these are then easily managed in version control systems .",
    "this additionally ensures the verification test engine is lightweight and apart from a dependence on standard software libraries , and a connection to opendapservers , is self - sufficient and can be easily be setup and used independently .",
    "constraints built from distributed resources are encouraged , but to engage with existing mesh generation workflows and as a pragmatic solution , source files can be cached or local files used directly ( see [ fig : process ] ) .      shingleapplies the self - consistent approach to mesh generation developed in @xcite . within the brmldescription",
    "this is emphasized through a central data source definition ( seen in [ fig : block , fig : gui , fig : brml ] ) , rather than external sources brought in directly at different levels in the hierarchy and correspondingly in the generation process ( [ fig : block ] ) .",
    "it is then easier to ensure datasets and their component fields undergo the same pre - processing to generate high fidelity constraints that are consistent , and a solution spatial discretisation that is self - consistent .",
    "data used to construct the spatial domain discretisation is commonly a dem describing a surface through perturbations from a reference geoid surface ( e.g. to establish a geoid surface boundary representation ) , but is not limited to this form , with for example @xcite developing a mesh optimised to the mean track of the acc , based on currents in the southern ocean .",
    "from shingle import spatialdiscretisation , dataset , boundary # set up constraints r = spatialdiscretisation(name=northsea ) r.setprojection(utm , -3 , 52 ) # alternatively zone=30u gebco = dataset(type=raster , source=opendap , url= ...  , region=[-12,14,45,62 ] ) coast = boundary(coast , id=3 ) s = r.addsurface ( ) s.addboundarycomponent(source=gebco , contour=ocean0m , id = coast ) ... m = r.discretisation ( ) m.save(northsea.msh )    # modify boundary representation output projection import pyproj p = pyproj.proj(+proj=utm + zone=30u + ellps",
    "= wgs84 + datum = wgs84 + units = m \" ) r.setprojection(p )",
    "r.save(northsea_utm30u.brml )    # simple parameter sweep example from shingle import load r = load(weddell_sea.brml ) s = r.getsurface(southernocean ) b = s.getboundarycomponent(openparallel ) for latitude in [ float(x ) for x in xrange(-75,-65,2 ) ] : b.extendtoparallel(latitude ) b.save(weddell_sea_and_      the library libshingleis written in python and uses standard libraries for operations where possible .",
    "it can simply be used transparently through the shingleexecutable to interpret the constraints specified in brmlfile descriptions . for lower level more advanced use building up constraints for more complex setups or in prototyping natural language objects for automating the inclusion of new geographic features",
    ", interaction can be made directly with the libshinglelibrary as [ fig : process ] illustrates .    mirroring the brmlconstraint description ( overviewed in [ fig : block ] ) , the library contains natural language based objects that can be built up in code to construct components of a mesh generation problem , including boundary representations and element edge length metrics .",
    "the mesh problem can then be solved under these constructed constraints all within a python context .",
    "libshingleuses the open source python shapely library ( refer to [ fig : process ] ) to handle polyline imports and manipulations .",
    "the scientific.io library is relied on to efficiently process raster netcdf files .",
    "the homeomorphic projections to the charts required in the mesh generation process ( see * ? ? ?",
    "* ) , such as @xmath6 of [ brep ] are interpreted and managed by the proj.4 python library pyproj .",
    "geospatial operations can be made by both high - level shingleobjects , or built up with gdal operations through its python osgeo interface .",
    "although the use of external libraries may require updates to shinglein the future to maintain compatibility , this is minimal compared to the benefits of using standardised implementations ( [ tenet : standard ] ) , that have community effort to ensure ongoing support with operating systems and interaction with other software and methods .",
    "in addition to the ongoing support from standard libraries in high - level use , shinglehas been written to interact directly with external libraries .",
    "objects such as pyproj projections , gdal operations , surface and polyline descriptions can be used interchangeably with libshingle .",
    "an example bringing in a utm projection setup externally using the standard library pyproj is shown in [ fig : python](b ) .",
    "this supplements the high - level text - based natural language definitions available in the brml , and a route to adding new high - level boundary representation brmlobjects to libshingleas needed .      in developing a new application study applying a numerical simulation model",
    ", it is common to iterate on a spatial discretisation until it is optimum and fit for purpose .",
    "this involves small changes in the constraints , exploring parameter space often through a loose bisecting binary search algorithm .",
    "this process can be rigorously implemented and automated with libshingle , where modifications are guided by the schema describing the formal grammar of the constraint space through libspud .",
    "( c ) illustrates a simple template to modifying and generating a range of brmlmesh descriptions .",
    "the solution mesh discretised domains can be generated in the same way , and this could further be used to initiate numerical simulation runs .",
    "this algorithmic formulation of constraints is easily extended to enable complex operations that are difficult to achieve with other approaches .",
    "for example , the loop of [ fig : python](c ) is trivially extended to include a search algorithm exploring a parameter space to converge a domain discretisation on a required total number of nodes and hence degrees of freedom .",
    "being an xml based language , the brmldescriptions can also be simply interrogated and modified directly with standard xml libraries .",
    "this interaction is highlighted separately in [ fig : process ] .",
    "shinglehas been built with modules for high - level interactions , with established tools used in mesh generation .",
    "these are highlighted in [ fig : process ] , with a core link to the gmsh library of meshing algorithms . where possible interaction is achieved through standardised python apis , such as the @xcite for the triangle @xcite library of delaunay mesh algorithms .",
    "high fidelity boundary representation can be output in gmsh format using a specific format writer developed within a collection of writer modules prepared within shingle .",
    "similarly , fields supporting a meshed domain ( e.g. initial full - field temperature state ) can be output as unstructured vtk files , using a format writer extending standard vtk libraries .",
    "data is written and stored efficiently in an xml based data format containing blocks of binary data compressed using the zlib library .",
    "models with non - standard data formats are supported through specific format writers .",
    "this modular approach enables new format writers ( and readers ) to be added as needed . as examples ,",
    "shingleincludes modules to prepare initialisation files for the adcirc hydrodynamic circulation model and h2ocean shallow water equation model .",
    "as well as writing mesh solutions , the output writers are used for validation purposes and in the general purpose efficient prototyping ( [ tenet : efficient ] ) .",
    "output can be prepared for viewing alongside source data in geospatially valid context provided by gis frameworks , with for example the resulting mesh and discrete bounds overlaid over dems directly within gis ( see * ? ? ?",
    "this is useful for a visual evaluation of conformity , to see how well geographic features are represented . for large discretisations , visualisations tools designed specifically for efficiently handling large unstructured datasets can be employed , such as paraview , which is directly supported by shingleusing vtk .",
    "interaction at different levels is important to ensure a hierarchy of automation [ tenet : automated ] . particularly challenging meshing problems",
    "can , for example , easily be offloaded to more capable dedicated resources .    for quick visual inspection purposes , shinglecan",
    "automatically output an image of the geoid surface mesh discretisation .",
    "parallel to the writer modules , shingleincludes readers .",
    "these are used to interact with meshing libraries where needed , loading in output mesh discretisations produced by gmsh on - the - fly , for example .",
    "additionally this can be used to support a wider range of data sources and initialisation .",
    "standard data in netcdf and shapefile form can be read .",
    "readers here can import more complex heterogeneous data , including gis projects with multiple layers containing a wide range of data types , for example .      as",
    "a python library unifying boundary representationconstraint and solution , libshinglemakes it possible to incorporate complex domain discretisation of real geophysical domains in overarching model control scripts , which is where development of new cutting - edge models is headed ( see for example , * ? ? ?",
    "* ; * ? ? ?",
    "in this way the model supplements the problem constraints sent to libshingle(see [ fig : unified ] ) , dependent on numerical discretisations employed in the simulation model , and the brmlwould be truly independent of specific models , a pure description of the boundary representation , resolution and identification .",
    "moreover , interaction through the library enables models to handle the output discretisation directly as the python objects constructed by shingle , rather than an intermediate file object .",
    "as @xcite demonstrates , complex multi - model earth system models can be created and coupled , and interactively monitored , on potentially a heterogeneous array of computational resources , all coordinated from a central a python interface .",
    "libshinglebrings domain discretisation in real geometries to these type of extensible earth system modelling frameworks .",
    "a suite of verification tests are provided together with shingle , along with the automated test engine detailed in [ sec : continuousverification ] . a selection of geophysical domain discretisations described in brmlthat form part of the test examples",
    "are shown in [ fig : chile , fig : caribbean , fig : discretisations , fig : challenge ] .",
    "each test is evaluated using validation tests built into shingleand their brmldescriptions , as outlined in [ sec : self - validation ] .",
    "the test engine can be used to verify a new install , and flexibly to support iterative mesh drafting and prototyping ( [ tenet : efficient ] ) .",
    "validation of the mesh generation process is achieved in four ways .",
    "firstly , with reference to the formal grammar of the constraint space , a degree of self - validation can take place on - the - fly as mesh options are built up .",
    "following rules described in the schema , only some options are available and certain combinations permitted . unlike with namelist descriptions , or ad hoc collections of data ,",
    "the user does not need to wait until running shinglebefore receiving feedback on option validity .",
    "available options are limited dynamically following the constraints and option selections . moreover , with information from the schema on the mesh generation problem , it is possible to identify which options are required for the problem to be complete .",
    "the creation of a new brmlfile immediately requires a name , type and options to be completed for at least one geoid surface representation and a geoid metric .",
    "the gui highlights which required options remain to be completed ( see [ fig : gui ] ) .",
    "this is particularly useful to users new to mesh generation .    secondly , the required ` type ' option classifies the mesh and checks at runtime it is suitable for the intended simulation .",
    "a ` shallow water ' model requires only a surface geoid discretisation @xmath16 for example , whilst a full three - dimensionalmesh is needed in other simulation types .",
    "this is a sanity check to ensure the mesh generation problem is fully constrained for the intended purpose , beyond the fundamental [ constraint : brep , constraint : hmetric , constraint : id , constraint : surfbounds , constraint : vmetric ] .",
    "thirdly , a parsing stage following application of a meshing algorithm eliminates commonly found issues in output mesh descriptions , ensuring structural integrity .",
    "for example , additional lone , unconnected boundary elements are removed in this step to ensure the discretised output mesh is as expected .",
    "meshing algorithms do not usually possess information on underlying numerical discretisations , and it is also possible elements are generated that ` tied ' to boundary conditions , with no independent free unknowns .",
    "this type of problem in the spatial discretisation is often difficult to identify , only being picked up at runtime , or through careful visual inspection .",
    "this parsing is an opportunity to identify and process these at this stage .",
    "numerical simulation codes are sometimes accompanied with standalone mesh checking tools to support initialisation stages ( e.g. the mechchecker.f90 utility for the adcirc model ) , and visual interfaces can be used for manual inspection and editing , such as the show me tool provided alongside triangle @xcite and the gui of gmsh @xcite .",
    "this is part of the mesh generation process and , if possible , better handled automatically following [ tenet : automated ] , as proposed .",
    "lastly , the fourth approach to validation is through explicitly defined expected boundary representation and discretised mesh characteristics . like the initial consistent approach of @xcite , the intermediate high fidelity boundary representation",
    "is compared at a raw level .",
    "being a deterministic process , deviations are only expected as a result of depending on shinglelibrary version and behaviour , source data and potential opendapresponse , machine precision and the originating brmldescription . at this stage of the meshing process , this has been supplemented with a test on the area within the bounds of the high fidelity geoid boundary representation@xmath8 .    on the discretised output , the tests include simple lower and upper bounds on output geoid mesh node and element numbers , the number of boundary elements , and element circumspheres to check adherence to metric constraints .",
    "the degree of representation is examined comparing the high fidelity geoid boundary representationsurface area to its corresponding discretised form .",
    "boundary complexity is measured through the overall minkowski fractal dimension .",
    "this provides a means for users to easily specify what should be expected in the discretised output , to ensure the accuracy required in [ tenet : brep , tenet : metric , tenet : region ] . testing built in to the mesh generation process ,",
    "further automates the process .",
    "it is also important to ensure [ tenet : provenance ] : provenance , that the solution mesh is the same ( within prescribed tolerances ) as that that has been generated in the past , and potentially by others on different systems .",
    "a self - validating description provides [ tenet : standard ] : a standardisation of interaction with the descriptions themselves .",
    "users can immediately begin building on and improving the work shared by others , having been able to check the descriptions give a solution expected by the creator .",
    "this eliminates ad hoc or purely qualitative measures of conformity and reinforces the provenance record of the mesh generation process .",
    "this is important when these then form key components of critical studies , such as the coupled climate and earth system models run for internationally coordinated model intercomparisons , such as cmip and core @xcite , that form the basis of reports compiled by the ipcc .",
    "models containing unstructured meshes with conforming boundaries are now starting to be used in such large - scale international research efforts ( e.g. fesom , * ? ? ? * ) .",
    "this approach provides the full provenance , reproducibility and complete constraining descriptions of the significantly more complex spatial discretisations supported by these models .      to ensure shingleas",
    "a whole continues to behave as expected for all users and on all systems , it contains a verification test engine .",
    "this processes a suite of key meshing problems , which are then automatically evaluated following the validation tests defined in their brmldescription .",
    "since the brmldescriptions are self - validating , the addition of new tests to the suite is simply a matter of adding the problem description file to a test folder of the source code .",
    "testing is often a secondary consideration to new feature implementation , so it is important the extension of testing suite is as simple as possible .",
    "this can simply be run at the time of a new installation , following the upgrade of required libraries or the operating system , or routinely as part of a commit - hook buildbot with dedicated resources to continuously verify new code pushed to a shingledevelopment code repository ( see , for example , * ? ? ?",
    "being built on standard libraries , it could further form part of an automated wider system framework validation , for the above climate intercomparison projects , for example , reproducing the entire process from initialisation to post - processing , on demand . alternatively",
    ", the engine can be used to drive an efficient drafting and prototyping workflow ( [ tenet : efficient ] ) with updates to mesh generation problems automatically processed and tested , to support an iterative domain discretisation process .",
    "[ sec : conclusion ] this research has developed a high - level abstraction to mesh generation for domains containing complex , fractal - like coastlines that characterise those in numerical simulations of geophysical dynamics , together with a compact , shareable and necessarily complete description of the domain discretisation .",
    "the approach is designed to be accessible to a wide range of users and applications .",
    "this begins at a simple standalone gui - driven one way workflow , where users are guided through the option parameters required to constrain the domain discretisation problem .",
    "options are presented in context through the hierarchical tree structure with documentation automatically provided alongside .",
    "moreover , the use of a human readable xml format and introduction of high - level natural language based geographical objects give brmlproblem constraint descriptions that closely follow those presented in literature and shared by scientists .",
    "the example built up from the description ( ) , to brmlin [ fig : brml , fig : gui ] , followed by the construction of the high fidelity boundary representationand resulting spatial discretisation shown in [ fig : chile ] , highlights how the problem of generating a domain bounded by a complex coastline defined by a depth contour and three orthodromes , common in tsunami modelling studies , is trivially constructed and solved using shingle .",
    "this is easily built on and extended to larger and more complex problems .",
    "high - level objects automate processing of multiple , potentially complex geospatial features .",
    "brmldescriptions are easily shared and xml sections cut and pasted to combine descriptions and build up complexity .",
    "new high - level objects and processing can be prototyped directly in python to later join the core libshingleoperations library .",
    "corresponding natural language based objects are available through the python api , meaning domain discretisation can be achieved directly and purely in native python code , for complex setups , direct integration with numerical simulation codes , or interactive sessions or jupyter notebooks .",
    "both the brmlfile descriptor and modular libshingleare extensible .    extending the tsunami example shown in [ fig : chile ] , this robust and automated approach could form part of a real time warning system using unstructured spatial discretisation , with a domain created on - the - fly , centred around the earthquake epicentre , in a direct response to measurement by gps seismic monitors .",
    "recognising the domain discretisation process is becoming more challenging and more difficult to document completely , such that others can reproduce , has been central to steering this approach .",
    "progress is focused on the nine tenets of geophysical mesh generation summarised in [ fig : tenets ] .",
    "one result of this is that shingletreats the mesh generation as a model problem .",
    "strategies from numerical simulation model development have been adopted and modified to formalise the description of the heterogeneous geophysical mesh generation constraints , such that they provide an accurate and complete description ( [ tenet : brep , tenet : metric , tenet : region ] ) in a standardised language - based xml form ( [ tenet : standard ] ) .",
    "this compact text - based description easily affords a record of changes in the development of a domain discretisation ( [ tenet : provenance ] ) and through the brmlgrammar ensures it is always a complete description and therefore reproducible .",
    "the model - based approach manages the range types of parameters ( which have diversified with the use of flexible unstructured discretisations ) and supports users in their preparation , to allow for efficient drafting and prototyping ( [ tenet : efficient ] ) . with options managed in a structured hierarchical tree",
    ", complex discretisations can be built up logically ( [ tenet : automated ] ) and scaled up ( [ tenet : scales ] ) .",
    "the creation of the brmlfile boundary representationdescription is not intended to reinvent standards .",
    "it is not a new data descriptor , for orientated vector paths or two - dimensionalraster data , for example .",
    "there exist standards already that tackle these challenges well .",
    "it is rather a new problem descriptor , like those for fluidity @xcite and the terraferma model of @xcite , for fully describing the mesh generation problem specifically for geophysical model domains , following the approach that this requires solving the same types of challenges involved in numerical model setup , that makes significant progress in meeting the tenets of [ fig : tenets ] .",
    "the consistent approach of @xcite is adopted , with an emphasis on producing a self - consistent high fidelity description and resulting output domain discretisation .",
    "consistency is additionally encouraged through a centralised definition of the source data and processing in the brmldescription ( see [ fig : block , fig : gui , fig : brml ] ) .",
    "use of decentralised , distributed datasets , efficiently accessed using opendap , ensures the discretisation uses exactly the same source data on every processing instance .",
    "verification and discretisation validation is achieved at multiple points throughout the process .",
    "the formal grammar of the brml , imposed by the schema , enforces valid inputs and provides initial option checking .",
    "this framework and interaction with the schema using the libspud library additionally enables new self - validating user interfaces to be written . with expected mesh validation measures included in the brmldescriptions ,",
    "discretisations are automatically validated and continuous verification of the library is easily obtained .",
    "with the dependable , robustly verified library libshinglefor high - level abstractions for geophysical mesh generation , it is easily applied to develop interactions with other frameworks and models , such as gis , as described in @xcite .",
    "critically , with the standalone libshinglelibrary , these are easier to maintain and better insulated to api changes in other codes",
    ".    it does not immediately solve the mesh generation constraint problem in general , since numerical simulation models use a wide range of mesh types and numerical discretisations .",
    "it has however , been designed with this in mind , with low - level structures that are extensible , to accommodate additional mesh types for example , and high - level constructs that are applicable to all geophysical models . arguably the _",
    "` holy grail ' _ of domain initialisation for geophysical models , characterised by the [ constraint : brep , constraint : hmetric , constraint : id , constraint : surfbounds , constraint : vmetric]following the development [ fig : block ] , is a grouping of high - level directives describing bounds ( including key geospatial features to capture ) , required spatial resolution and source datasets that can be interpreted by any model , each dealing with the discretisation depending on the field representations within the model ( [ fig : unified ] ) . shingleprovides an extensible platform to achieve this , focusing on general , natural language based , model - independent descriptions of domain descriptions , that can be shared and used for different models .",
    "libshingleadditionally provides a means to interpret these descriptions such that this part of the process can be included in numerical simulation code , with the brmlconstraints supplemented by those imposed by the simulation model , such as specific numerical discretisation choice ( e.g. to use hexagonal over triangular prism elements ) , or ensuring a minimum degree of representation in maintained between bounds ( e.g. within narrow river channel networks ) .",
    "the shinglecomputational research software library , developed as part of this study , is available at https://github.com/shingleproject/shingle , with further information at https://www.shingleproject.org . this is accompanied by a manual , a suite of example domain discretisation brmldescriptions and the verification test engine presented in [ sec : verification ] .",
    "all components of the shinglepackage which have been under continued development since 2011 are free software , being released under the gnu general public license version 3.0 .",
    "full details of the license , including the compatible copyright notices of third party routines included in the package , are included in copying in the source distribution .",
    "the authors wish to acknowledge support from the netherlands organisation for scientific research ( nwo , grant number 858.14.061 ) , and also thank gerben de boer for discussions on opendapand its adoption within the netherlands and more generally by the wider scientific community .",
    "37 natexlab#1#1[1]`#1 ` [ 2]#2 [ 1]#1 [ 1]http://dx.doi.org/#1 [ ] [ 1]pmid:#1 [ ] [ 2]#2 , , , , , . . ,",
    ", , , . , in : . , .",
    ", , , , , . . ,",
    ", , , , , , . .",
    ", , , . . ,",
    ", , , , , , . . ,",
    ", , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , . . ,",
    ", , , , , , , , , , . . ,",
    ", , , , , , , , , , et  al . , . , in : , . , , , , , , , , , , , , , . . ,",
    ", , , , , , . . ,",
    ", , , , , . . ,",
    ", , , , , . . ,",
    ", , , , , , , , . . , . ,",
    ", , , , , , , . . ,",
    ", , , , , , , . . ,",
    ", , , , , , , , , . .",
    ", , , , , , , . .",
    ", , , , , , . . ,",
    ", , , , , , , , , , , , , , , , , , . . ,",
    ", , , . , . , , , , , , , , , , ,",
    ", , , , , , , , , , . . ,"
  ],
  "abstract_text": [
    "<S> the approaches taken to describe and develop spatial discretisations of the domains required for geophysical simulation models are commonly ad hoc , model or application specific and under - documented . </S>",
    "<S> this is particularly acute for simulation models that are flexible in their use of multi - scale , anisotropic , fully unstructured meshes where a relatively large number of heterogeneous parameters are required to constrain their full description . as a consequence , it can be difficult to reproduce simulations , ensure a provenance in model data handling and initialisation , and a challenge to conduct model intercomparisons rigorously .    </S>",
    "<S> this paper takes a novel approach to spatial discretisation , considering it much like a numerical simulation model problem of its own . </S>",
    "<S> it introduces a generalised , extensible , self - documenting approach to carefully describe , and necessarily fully , the constraints over the heterogeneous parameter space that determine how a domain is spatially discretised . </S>",
    "<S> this additionally provides a method to accurately record these constraints , using high - level natural language based abstractions , that enables full accounts of provenance , sharing and distribution . </S>",
    "<S> together with this description , a generalised consistent approach to unstructured mesh generation for geophysical models is developed , that is automated , robust and repeatable , quick - to - draft , rigorously verified and consistent to the source data throughout . </S>",
    "<S> this interprets the description above to execute a self - consistent spatial discretisation process , which is automatically validated to expected discrete characteristics and metrics .    </S>",
    "<S> [ sec : introduction ]            numerical simulation models have become a vital tool for scientists studying geophysical processes . </S>",
    "<S> mature operational models inform continuously updated short - term public weather forecasts , whilst studies of mantle dynamics and ice sheet evolution improve understanding of physical systems in relatively inaccessible locations , where data is sparse .    </S>",
    "<S> use of unstructured mesh spatial discretisations is growing in the fields of modelling geophysical systems , where it is possible to conform accurately to complex , fractal - like surfaces and vary spatial resolution to optimally capture the physical process , or multi - scale range of processes under study . </S>",
    "<S> the past few years have seen a global unstructured ocean model ( fesom , * ? ? ? </S>",
    "<S> * ) join structured studies in internationally coordinated climate studies , such the coupled model intercomparison project ( cmip , * ? ? ? </S>",
    "<S> * ; * ? ? ? </S>",
    "<S> * ) and the coordinated ocean - ice reference experiments ( core * ? ? ? </S>",
    "<S> * and accompanying studies in the _ ocean modelling _ special issue ) . </S>",
    "<S> more are in active development ( e.g. * ? ? ? </S>",
    "<S> * ) and the number of unstructured models joining these efforts  that directly contribute to reports compiled by the intergovernmental panel on climate change ( ipcc )  likely to grow . </S>",
    "<S> similarly , on smaller scales , the geometric flexibility of unstructured discretisations are being applied to reduce the need for nesting models , and in accurately applying forcings or coupling physics ( e.g. * ? ? ? </S>",
    "<S> * ) on complex and possibly dynamic , deformable physical interfaces . </S>",
    "<S> at the cusp where these efforts meet , prospects for introducing successively greater complexity in the representation of coastal seas in global ocean models are reviewed in @xcite .    the challenge ( see [ fig : challenge ] ) of constraining and fully describing an arbitrarily unstructured spatial discretisation bounded by complex , fractal - like bounds that typically characterise geophysical domains , with inhomogeneous and potentially anisotropic spatial resolution , is a significant one </S>",
    "<S> . defining the domain geoid bounds is no longer a simple case of applying a land mask to similarly regular gridded data . </S>",
    "<S> the generalised constraints are now a heterogeneous set of functions @xcite , and as a consequence are more difficult to describe . in general , </S>",
    "<S> domain discretisations are often under - described leaving it difficult to repeat simulations exactly , which particularly for the unstructured case , can have a strong influence on model output . </S>",
    "<S> not only is the description and generation process a significant challenge , but achieving this in a way that maintains a record of provenance such that simulations as a whole are reproducible , that scales and is efficient , and consistent to source data  attributes required and expected in scientific modelling studies  make this a much more difficult problem ( summarised in [ fig : tenets ] ) . </S>",
    "<S> existing , standard structured - mesh tools can not be used .    </S>",
    "<S> grid generation for geophysical models in real domains is not only becoming a significantly more complex and challenging problem to constrain and describe , but additionally in the computational processing required . as models include a greater range of spatial scales , more computational effort is required to optimise the discretisation before a simulation proceeds ( e.g. the actively developed mpas models , @xcite , strongly optimise their hexagonal prism based mesh discretisation ) . </S>",
    "<S> an increasing number of geometric degrees of freedom demand the meshing process is broken up over multiple parallel threads ( as demonstrated in * ? ? ? </S>",
    "<S> * ) , just as simulation models have evolved to run in parallel .    </S>",
    "<S> these challenges are identified in @xcite by the _ nine tenets of geophysical mesh generation _ </S>",
    "<S> , summarised in [ fig : tenets ] . </S>",
    "<S> this work takes the view that significant progress can be made towards these by approaching the mesh generation problem in the same way as a numerical simulation model .    </S>",
    "<S> simulation domains in geophysical models are typically defined with reference to geographical features . </S>",
    "<S> a tsunami simulation geoid surface domain is , for example , usually described by a length of coastline between two points ( commonly marked by longitude or latitude references ) extended out to an orthodrome . in the case of 2010 chile earthquake centred about 35.9s 72.7w ( see [ fig : chile ] ) , the domain is concisely described :    `` [ 1.0 ] ... bounded by the 0 m depth coastline from 32s to 40s , extended along parallels to the 77w meridian , + in a latitude - longitude wgs84 projection ... '' [ description ]    as part of the generalisation of domain description , this new approach interacts directly with these natural language based geographic references , structured by a formal grammar , to provide a general , model - independent and accurate description of spatial discretisation for geophysical model domains . </S>",
    "<S> this forms part of the @xcite computational research software library , that accompanies this work , providing a novel approach to describing and generating highly multi - scale boundary - conforming domain discretisations , for seamless concurrent simulation .    </S>",
    "<S> the objective of this paper is to provide :    1 .   a user - friendly , accessible and extensible framework for model - independent geophysical domain mesh generation . </S>",
    "<S> 2 .   an intuitive , hierarchical formal grammar to fully describe and share the full heterogeneous set of constraints for the spatial discretisation of geophysical model domains . 3 .   </S>",
    "<S> natural language basis for describing geophysical domain features . </S>",
    "<S> 4 .   </S>",
    "<S> self - consistent , scalable , automated and efficient mesh prototyping . </S>",
    "<S> 5 .   </S>",
    "<S> platform for iterative development that is repeatable , reproducible with a provenance history of generation .    with significant progress made through the novel approach of considering the problem much like that of a numerical simulation model problem .    the previous work @xcite developed a consistent approach to domain discretisation , with a focus on uniform processing and data sources , which further enabled the discretisation of domains not possible with standard approaches . </S>",
    "<S> additionally , it identified the complete set of heterogeneous constraints required to fully describe a mesh generation problem for the discretisation of geophysical domains . </S>",
    "<S> this work now extends and generalises this consistent approach introducing a natural language based formal grammar for a modeller to describe and share the constraints . under the formal grammar </S>",
    "<S> the description is ensured necessarily complete , such that the problem is fully constrained and is therefore reproducible . </S>",
    "<S> this employs the novel hierarchical problem descriptor framework spud @xcite which has been specifically designed to manage large and diverse option trees for numerical models . </S>",
    "<S> the formal self - describing data file is a universal , shareable description of the full constraints , written in a standard data format , presented in context through a natural hierarchical structure , readable by established open source libraries .    </S>",
    "<S> the pathways of interaction with the library have grown ( outlined in [ fig : process ] ) , such that it is accessible to a wide range of users . </S>",
    "<S> its modular library framework , with for example , geospatial operations , homeomorphic projections , meshing algorithms and model format writers are the focus of distinct modular parts , and the use of standard external libraries where possible , allows development to remain in small sections of the code base , such that develops can stay within their specialisms . </S>",
    "<S> additionally , the dictionary approach to managing option parameters taken by spud means new features can be added and exposed through interfaces , such as the diamond graphical user interface ( gui ) , without the need to pass new arguments through code functions , and similarly require small changes and only in low - level code .    </S>",
    "<S> output writers in the library prepare the solution discretisation for use in simulation codes , in cases where the output python objects can not be used directly , encouraging the use of standard formats and also supporting existing proprietary model - specific formats . </S>",
    "<S> these additionally support supplementing the spatial discretisation ( which itself includes a vector field describing mesh node coordinate locations ) with additional interpolated fields for simulation model initialisation and forcing ( [ fig : process ] ) .    through both the objects in the problem description file ( [ fig : block , fig : gui , fig : brml ] ) and those in the python library libshingle([fig : python ] ) , shingleprovides a language to combine geographic components to build up boundary representation , mesh spatial variation and identification  a high - level abstraction to the complex constraint description problem  which is then processed by the library in deterministic ( or as close to as possible ) process to accurately construct the specified mesh in a repeatable way .    </S>",
    "<S> the validation tests of @xcite have been significantly widened from the limited boundary representation tests to include expected discrete properties and metrics of the high fidelity description and resulting domain discretisation . </S>",
    "<S> these expected characteristics are prescribed as part of the self - describing problem file , such that other users can check the output is as intended . </S>",
    "<S> this self - contained description and validation is then straight - forwardly processed by the library verification engine , making it easy to add new tests .    through this approach </S>",
    "<S> , geophysical domain discretisation can be the relatively simple steps ( top of [ fig : process ] ) of using the diamond gui to choose a dataset and specify bounds using natural language objects , which is then run through the shingle executable to produce a mesh . </S>",
    "<S> this is accessible and straightforward to new users . </S>",
    "<S> more so with the suite of test cases that provide examples and easily ensure verification through a built - in test engine .    </S>",
    "<S> more advanced use can be built up in stages through the gui , with validation checks on expected mesh properties easily added to ensure reliable reproduction throughout the iterative mesh prototyping process . beyond this the xml based description </S>",
    "<S> is easily interrogated and modified with standard tools . </S>",
    "<S> lower - lever still , the natural language based objects and discretisation constraints can be accessed directly through its python library interface . </S>",
    "<S> this has grown since its first iteration reported in @xcite , where it was used to develop complex discretisations dependent on the mean position of antarctic circumpolar current ( acc ) and domains to complex grounding line positions under the floating ice shelves of antarctica . </S>",
    "<S> python plugins for qgis @xcite were developed using parts of the shinglelibrary code to demonstrate integration with geographic information systems ( gis ) in @xcite .    with mesh generation becoming a complex problem to describe and a computationally challenging process , that we argue is best handled in an approach that mirrors the development of a numerical simulation model , support and interaction with other frameworks such as gis </S>",
    "<S> is best maintained with a standalone library and a formal problem description specifically designed to constrain the general geophysical domain discretisation problem .    </S>",
    "<S> the paper is structured such that the following [ sec : meshgeneration ] sets out the challenge , reviewing the set of heterogeneous [ constraint : brep , constraint : hmetric , constraint : id , constraint : surfbounds , constraint : vmetric]required to fully describe a domain discretisation problem , and key considerations in [ fig : tenets ] . </S>",
    "<S> the natural language based brmlproblem description is introduced in [ sec : brml ] , with a consideration of source data in [ sec : data ] . </S>",
    "<S> the libshinglelibrary central to the generalised approach ( illustrated in [ fig : process ] ) is detailed in [ sec : framework ] with ways to interacting with the framework presented in [ sec : interaction ] . </S>",
    "<S> examples and validation is covered in [ sec : verification ] , with conclusions made in [ sec : conclusion ] . </S>"
  ]
}