{
  "article_text": [
    "clustering is a commonly encountered problem in many areas such as marketing , engineering , and biology , among others . in a typical clustering problem ,",
    "the goal is to group entities together according to a certain similarity measure .",
    "such a measure can be defined in many different ways , and it determines the complexity of solving the relevant clustering problem . clustering problems with the similarity measure defined by regression errors is especially challenging because it is coupled with regression .",
    "consider a retailer that needs to forecast sales at the stock keeping unit ( sku ) level for different promotional plans and mechanisms ( e.g. , 30% off the selling price ) using a linear regression model .",
    "a sku is a unique identifying number that refers to a specific item in inventory .",
    "each sku is often used to identify product , product size , product type , and the manufacturer .",
    "seasonality is an important predictor and is modeled using an indicator dummy input variable for each season , with the length of one season being one week .",
    "the usable data for each sku is limited compared to the possible number of parameters to estimate , among which the seasonality dummies compose a large proportion .",
    "more significant and useful statistical results can be obtained by clustering skus with similar seasonal effects from promotions together , and estimating seasonality dummies for a cluster instead of a single sku .",
    "however , the seasonal effects of skus correspond to regression coefficients , which can only be obtained after grouping skus with similar seasonality .",
    "a two - stage method can be used to solve such difficult clustering problems that are intertwined with regression . in the first stage ,",
    "entities are clustered based on certain approximate measures of their regression coefficients . in the second stage , regressions are performed over the resultant clusters to obtain estimates for the regression coefficients for each cluster . however , good approximate measures are difficult to obtain a priori before carrying out the regressions .",
    "a better alternative is to perform clustering and regression simultaneously , which can be achieved through cluster - wise linear regression ( clr ) , which is also referred to as `` regression clustering '' in the literature .",
    "other application areas of clr include marketing , pavement condition prediction , and spatial modeling and analysis .",
    "more details about these other application areas can be found in openshaw @xcite , desarbo and cron @xcite , desarbo @xcite , and luo and chou @xcite .",
    "the clr problem bears connection to the minimum sum - of - squares clustering ( mssc ) problem , the objective of which is to find clusters that minimize the sum of squared distances from each entity to the centroid of the cluster which it belongs to . contrary to clustering entities directly based on distances , clr generates clusters according to the effects that some independent variables have on the response variable of a preset regression model . each entity",
    "is represented by a set of observations of a response variable and the associated predictors .",
    "clr is to group entities with similar regression effects into a given number of clusters such that the overall sum of squared residuals within clusters is minimal .",
    "although the mssc problem has been extensively studied by researchers from various fields ( e.g. , statistics , optimization , and data mining ) , the work for the clr problem is limited , most of which concerns adapting the lloyd s algorithm based heuristic algorithms of the mssc problem to the clr problem .",
    "the lloyd s algorithm starts randomly from some initial partition of clusters , then calculates the centroids of clusters , and assigns entities to their closest centroids until converging to a local minimum .",
    "recently , several exact approaches have been proposed by carbonneau et al @xcite , which are discussed in detail in sections 1.1 and 2 .",
    "we tackle the problem of clustering entities based on their regression coefficients by modeling it as a generalized clr problem , in which we allow each entity to have more than one observation .",
    "we propose both a mixed integer quadratic program formulation and a set partitioning formulation for generalized clr .",
    "our mixed integer quadratic program formulation is more general than the one proposed by bertsimas and shioda @xcite , which can not be directly applied to the sku clustering problem since they assume each clustering entity to have only one observation and this assumption does not hold for the sku clustering problem .",
    "we identify a connection between the generalized clr and mssc problems , through which we prove np - hardness of the generalized clr problem .",
    "column generation is an algorithmic framework for solving large - scale linear and integer programs .",
    "vanderbeck and wolsey @xcite and barnhart _ et al . _",
    "@xcite overview column generation for solving large integer program .",
    "we design a column generation ( cg ) algorithm for the generalized clr problem using its set partitioning formulation .",
    "the corresponding pricing problem is a mixed integer quadratic program , which we show to be np - hard . to handle larger instances in the column generation framework",
    ", we also propose a heuristic algorithm , referred to as the cg heuristic algorithm .",
    "this heuristic algorithm , inspired by bertsimas and shioda @xcite , first clusters entities to a small number of groups and then performs our column generation algorithm on these groups of entities .",
    "in addition , we propose a metaheuristic algorithm , named the ga - lloyd algorithm , which uses an adapted lloyd s clustering algorithm to find locally optimal partitions and relies on the genetic algorithm ( ga ) to escape local optimums .",
    "furthermore , we introduce a two - stage approach , used frequently in practice due to its simplicity , which performs clustering first and regression second .",
    "we test our algorithms using real - world data from a large retail chain .",
    "we compare the performance of the ga - lloyd , the cg heuristic , and the two - stage algorithms on two larger instances with 66 and 337 skus , corresponding to two representative subcategories under the retailer s product hierarchy .",
    "we observe that the ga - lloyd algorithm performs much better than the two - stage algorithm .",
    "the cg heuristic algorithm is able to produce slightly better results than the ga - lloyd algorithm for smaller instances , but at the cost of much longer running time .",
    "the ga - lloyd algorithm performs the best and identifies distinctive and meaningful seasonal patterns for the tested subcategories .",
    "in addition , we find that the column generation algorithm is able to solve the sku clustering problem with at most 20 skus to optimality within reasonable computation time .",
    "we benchmark the performance of the ga - lloyd and cg heuristic algorithms against the optimal solutions obtained by the column generation algorithm to find that both algorithms obtain close to optimal solutions .",
    "the contributions of our work are as follows .    1 .   we are the first to model and solve the sku clustering problem , commonly encountered in retail predictive modeling , through generalized clr .",
    "2 .   we propose four heuristic algorithms for the generalized clr problem , including the cg heuristic algorithm , the ga - lloyd algorithm , the two - stage approach , and a variant of spth algorithm .",
    "3 .   we propose an exact column generation algorithm that enables us to evaluate the performance of the heuristic algorithms .",
    "we prove np - hardness of the generalized clr problem and np - completeness of the pricing problem of the column generation algorithm .",
    "note that the number of clusters is a parameter in the generalized clr problem that needs to be decided by user beforehand or by enumeration .",
    "although we provide comparison of models with different number of clusters for real - world data in section [ subsec_compare_seasonality ] , it is not straightforward to develop a universal rule for deciding the number of clusters .",
    "this is also a hard task for mssc and clr .",
    "the aic or bic criteria did not give a reasonable number of clusters for the data set we used for the experiment .",
    "they gave more than three times the number of hand - picked number of clusters that work in practice .",
    "hence , in this paper , we assume that the target number of clusters is given in advance .    in figure [",
    "fig : compare ] , we summarize and compare the terms in the clr , generalized clr and the sku clustering problem . while clr only has entities , generalized clr allows multiple observations per entity .",
    "the clr problem can be thought of as the generalized clr with one observation per entity .",
    "note that entity and observation in generalized clr are the sku and transactions in the sku clustering problem , respectively .",
    "+    the rest of the paper is organized as follows . in section [ sec : formulations ] , we introduce both the mixed integer quadratic program and the set partitioning formulations of the generalized clr problem . we draw the connection between the generalized clr and mssc problems , and prove np - hardness of the former through this connection . in section",
    "[ sec : algorithms ] , we present the exact column generation algorithm , the cg heuristic algorithm , the ga - lloyd heuristic algorithm , the two - stage algorithm , and a variant of the spth algorithm . the pricing problem of the column generation algorithm is shown to be np - complete . in section [ sec : experiments ] , we present numerical experiments to test the performance of all proposed algorithms .",
    "the literature review is discussed next .      to the best of authors knowledge",
    ", no previous work has been conducted that comprehensibly tackles the generalized clr problem .",
    "however , an extensive collection has been proposed for the typical clr problem , which can potentially be adapted to tackle the generalized clr problem .",
    "the algorithms proposed for the typical clr problem are mainly heuristics bearing close similarity to the algorithms for the mssc problem .",
    "for example , spth @xcite proposes an exchange algorithm which , starting from some initial clusters , exchanges two items between two clusters if a cost reduction is observed in the objective function .",
    "desarbo @xcite presents a simulated annealing method to escape local minimums .",
    "@xcite used a self organizing map to perform clusterwise regression .    on mathematical programming - based heuristics , lau _ et al .",
    "_ @xcite propose a nonlinear programming formulation that it is solved approximately using commercial solvers with no guarantee to find a global optimum .",
    "their algorithm s performance depends heavily on the initial clusters .",
    "this initial - cluster dependency is overcome by the k - harmonic means clustering algorithm proposed by zhang @xcite .",
    "moreover , bertsimas and shioda @xcite introduce a compact mixed - integer linear formulation for a slight variation of the clr problem with the sum of the absolute error as the objective .",
    "their algorithm first divides entities into a small number of clusters , and then feeds these clusters into their mixed integer program .    for exact approaches to clr ,",
    "carbonneau _ et al . _",
    "@xcite proposed a mixed logical - quadratic programming formulation by replacing big m constraints with the logical implication of the constraints .",
    "@xcite proposed an iterative algorithm based on sequencing the data and repetitive use of a branch and bound algorithm .",
    "@xcite proposed a column generation based algorithm based on @xcite and @xcite .",
    "there are two key differences between these works and the one we propose in this paper .",
    "first , we provide both a quadratic mixed - integer program formulation and a set partition formulation of the generalized clr problem .",
    "the former is a generalization of the formulation in @xcite , and the latter is the set partitioning formulation for generalized clr ( recently , carbonneau _ et al .",
    "_ @xcite have proposed a set partitioning formulation for clr ) .",
    "second , we propose two new heuristics , namely the cg heuristic algorithm and the ga - lloyd algorithm for the generalized clr problem .    there is another stream of research for the clr problem that assumes a distribution function for regression errors where each entity is assigned to each cluster with a certain probability , i.e. , using `` soft '' assignments .",
    "for example , desarbo and cron @xcite propose a finite conditional mixture maximum likelihood methodology , which assumes normal distribution for regression errors and is solved through the expectation maximization algorithm . since then , a large number of mixture regression models have been developed , including probit and logit mixture regression models as examples .",
    "@xcite compare the performance of the expectation maximization algorithms with their nonlinear programming - based algorithm .",
    "hennig @xcite investigate idenfiability of model - based clusterwise linear regression for consistent estimate of parameters .",
    "durso _ et al . _",
    "@xcite proposed to integrate fuzzy clustering and fuzzy regression . a recent work of ingrassia _",
    "et al_. @xcite uses linear @xmath0 cluster - weighted models for clustering regression .",
    "these model - based approaches allow residual variances to differ between clusters , which the least squares approaches do not allow . in the soft assignment setting , an entity can be assigned to the cluster of highest probability .",
    "we restrict the scope of our review and comparison to least squares approaches because the objective functions are different .",
    "the reader is referred to wedel and desarbo @xcite and hennig @xcite for reviews .",
    "the algorithms for the mssc problem are instructive to solving the clr problem .",
    "there are abundant papers for solving the mssc problem .",
    "hansen and jaumard @xcite survey various forms of clustering problems and their solution methods , including mssc , from a mathematical programming point of view . in their survey ,",
    "solution methods for the mssc problem include dynamic programming , branch - and - bound , cutting planes , and column generation methods .",
    "all these algorithms do not scale well to large size instances or in higher dimensional spaces .",
    "heuristics are also considered , including lloyd s like algorithms ( e.g. , k - means and h - means ) and metaheuristics such as simulated annealing , tabu search , genetic algorithms and variable neighborhood search . with respect to mathematical programming approaches , du merle _ et al .",
    "_ @xcite propose an interior point algorithm to exactly solve the mssc problem .",
    "@xcite improve the algorithm of du merle _ et al . _",
    "@xcite by exploiting the geometric characteristics of clusters , which enables them to solve much larger instances .",
    "we first provide a mixed integer quadratic formulation for the generalized clr problem .",
    "this formulation reveals a close connection between the generalized clr and mssc problems , which enables us to show that the generalized clr problem is np - hard .",
    "consider set @xmath1 of @xmath2 entities .",
    "each entity @xmath3 has @xmath4 observations of dependent variable @xmath5 , and @xmath6 independent variables @xmath7 with @xmath8 for any @xmath9 $ ] . in practice",
    "the number of entities @xmath4 depends on @xmath10 , but we do not show this dependency for improved readability .",
    "( for each integer @xmath11 we introduce @xmath12 = \\{1, ... ,g\\}$ ] . )",
    "observation @xmath13 is associated with independent variables @xmath14 .",
    "note that vectors are represented in bold symbols .",
    "we want to divide these @xmath2 entities into a partition @xmath15 of @xmath16 clusters where @xmath17 , @xmath18 for any @xmath19 , and @xmath20}c_k = [ i]$ ] .",
    "the minimum size of a cluster is @xmath21 , which is set by the user .",
    "this implies @xmath22 for any @xmath23 $ ] where @xmath24 denotes the cardinality of cluster @xmath25 .",
    "note that the number of observations pertaining to a cluster is at least @xmath26 .",
    "the minimum size constraints are imposed to ensure that there are enough observations for each cluster .",
    "further , in order to avoid regression models with zero error , we require @xmath27 .",
    "we also require @xmath28 such that there is always a feasible solution .",
    "the generalized clr problem is formulated as follows : @xmath29\\text { , } k \\in [ k]\\text { , } l \\in [ l]\\label{constraint : quadratic : regression1 } \\\\",
    "t_{il } + ( y_{il } - \\sum_{j=1}^j\\beta_{kj}x_{ijl } ) + m(1 - z_{ik } ) & \\geq   0 \\quad & & i \\in [ i]\\text { , } k \\in [ k]\\text { , } l \\in [ l]\\label{constraint : quadratic : regression2 } \\\\",
    "\\sum_{k=1}^k z_{ik } & = 1 \\quad & & i \\in [ i ] \\label{constraint : quadratic : assignment } \\\\ \\sum_{i=1}^i z_{ik } & \\geq n \\quad & & k \\in [ k ] \\label{constraint : quadratic : minimumsize }",
    "\\\\ z_{ik } & \\in \\{0,1\\ } \\quad & & i \\in [ i]\\text { , } k \\in [ k ] \\nonumber \\\\ t_{il } & \\geq 0 \\quad & & i \\in [ i]\\text { , } l \\in [ l ] \\nonumber\\\\ \\beta_{kj}&\\text{\\ unconstrained } \\quad & & k \\in [ k]\\text { , } j \\in [ j ] , \\nonumber\\end{aligned}\\ ] ] where @xmath30 is a binary variable , which is equal to one if and only if entity @xmath10 is assigned to cluster @xmath25 .",
    "value @xmath31 , referred to as big @xmath31 in the optimization literature , is a large positive constant . due to constraints and , @xmath32 is equal to the absolute error for the corresponding observation @xmath13 in the optimal solution , and @xmath33 are the regression coefficients for cluster @xmath25 , which are decision variables . the role of @xmath31 is to enforce constraints and only when they are needed ( entity @xmath10 is assigned to cluster @xmath34 ) . in detail , if @xmath35 , then we have @xmath36 , and @xmath37 , which implies @xmath38 because we are minimizing the sum of @xmath39 . if @xmath40 , constraints and require @xmath32 to be greater than a negative number , which holds trivially due to the existence of the nonnegativity constraint on @xmath32 .",
    "constraint requires that every entity is assigned to one cluster , and imposes the limit on the cardinality of each cluster .    unlike the clr problem",
    ", the generalized clr allows each entity to have more than one observation , which implies that @xmath4 can be greater than one .",
    "the mixed integer linear program formulation for the clr problem in bertsimas and shioda @xcite has @xmath4 equal to one , and does not have the cluster cardinality constraint . besides , their objective function is the sum of the absolute errors while ours is the sum of squared errors",
    ".    our sku clustering problem based on the seasonal effects can be modeled as the generalized clr problem .",
    "the entities to cluster are skus .",
    "the response variable @xmath41 corresponds to a vector of weekly sales for sku @xmath10 .",
    "the independent variables @xmath42 s include promotional predictors such as promotion mechanisms , percentage discount , and seasonal dummies for sku @xmath10 .",
    "aloise _ et al . _",
    "@xcite showed np - hardness of the mssc problem in a general dimension when the number of clusters is two .",
    "general dimension means that the size of the vectors to be clustered is not a constant but part of the input data .",
    "a similar statement can be made for the generalized clr problem with the proof available in appendix [ appendix_proof_theorems ] .",
    "[ theorem : clr ] the generalized clr problem with two clusters in a general dimension is np - hard .    with the formulation presented by  , we can solve the generalized clr problem using any commercial optimization software that can handle quadratic mixed integer programs .",
    "however , this formulation suffers from two drawbacks , which makes it intractable for large instances .",
    "the first one relates to big @xmath31 .",
    "optimality of the solution and efficiency of integer programming solvers depend on a tight value of @xmath31 . unlike multiple linear regression ,",
    "where obtaining a valid value of @xmath31 is possible @xcite , it is not trivial to calculate a valid value of @xmath31 in and for the generalized clr or clr .",
    "when @xmath40 , @xmath43 s are not from the cluster that entity @xmath10 belongs to , and the residual @xmath32 can be arbitrarily large .",
    "@xcite provide an empirical result that a big m based mip formulation for clr sometimes fails to guarantee optimality of clr for the data sets they consider .",
    "the second one involves the symmetry of feasible solutions .",
    "any permutation of clusters yields the same solution , yet it corresponds to different decision variables .",
    "symmetry unnecessarily increases the search space , and renders the solution process inefficient . to overcome the symmetry problem",
    ", we propose a set partitioning formulation , which has already been used for the clr problem in @xcite .",
    "let @xmath44 denote the set of all clusters of entities with the cardinality equal to or greater than @xmath21 , i.e. , @xmath45 , |s| \\geq n\\}$ ] .",
    "let @xmath46 equal to one if entity @xmath10 belongs to cluster @xmath47 , and equal to zero otherwise .",
    "let @xmath48 denote the cost of cluster @xmath47 , which is equal to the sum of squared errors when performing the regression over cluster @xmath47 .",
    "introducing binary variables @xmath49 the generalized clr problem can be formulated as : @xmath50 \\label{constraints : partition : assignment}\\\\ z_s & \\in \\{0,1\\}\\quad & & s \\in \\mathscr{s}.\\nonumber\\end{aligned}\\ ] ] constraint ensures that the number of clusters in the partition is @xmath16 and constraint guarantees that each entity occurs in only one cluster within the partition .",
    "the set partitioning formulation has an exponential number of binary variables .",
    "it is very challenging to solve even its linear programming relaxation because there are so many decision variables . to solve large - scale linear and integer programs ,",
    "column generation algorithms have been used in the literature .",
    "the reader is referred to vanderbeck and wolsey @xcite and barnhart _ et al . _",
    "@xcite for reviews of column generation for solving large - scale integer programs . in our work , we employ column generation to handle its linear programming relaxation . at the high level , column generation can be understood as iteratively expanding set @xmath51 ( a subset of @xmath44 ) in - by adding attractive candidate cluster @xmath47 to @xmath51 .",
    "the key challenge is how to select @xmath47 .",
    "the word column is used because adding cluster @xmath47 to @xmath51 is equivalent to adding a column in the matrix form of - .",
    "the column generation algorithm , referred to as the cg algorithm , starts by solving the restricted master problem which has the same formulation as the master problem - , but with set @xmath44 replaced by @xmath51 , a smaller subset of columns .",
    "recall that a column represents a cluster ( subset of entities @xmath52 $ ] ) .",
    "we start the algorithm with small candidate clusters rather than @xmath44 , the set of all possible subsets of @xmath52 $ ] .",
    "the algorithmic framework is presented in algorithm [ alg : exactscg1 ] , which follows the general column generation scheme . in line 1 ,",
    "the initial subset of columns in @xmath51 are randomly generated . in detail , we start from @xmath16 empty clusters",
    ". then , we randomly assign each entity to one of the @xmath16 clusters using a uniform random number .",
    "hence , after line 1 , we have @xmath16 clusters and @xmath53 for the generation procedure . in line 3 ,",
    "optimal dual variables are obtained by solving the restricted master problem and then serve as input to the pricing problem , which will be introduced hereafter , to calculate the smallest reduced cost column . in line 4 ,",
    "the pricing problem returns a column with the smallest reduced cost . in lines 5 - 10 ,",
    "if the reduced cost is nonnegative , then we conclude that the master problem is solved optimally .",
    "otherwise , we add the column with the smallest reduced cost to the restricted master problem and repeat the process .",
    "randomly generate @xmath51 ( a small subset of @xmath44 ) solve master problem  and obtain dual solution get a new cluster by solving pricing problem with input of dual solution from line 3 the algorithm is complete with the optimal partition of clusters add the cluster from line 4 to the master problem      the pricing problem can be stated as follows .",
    "let @xmath54 be the dual variable for constraint , and @xmath55 s be the dual variables for constraint .",
    "the reduced cost for cluster @xmath47 is @xmath56 , and thus the pricing problem reads : @xmath57 note that we omit the subtraction of @xmath54 in the formulation because it is a constant which does not change the optimal solution .",
    "[ th : pricingnpcomplete ] the pricing problem as stated in is np - complete .",
    "the proof is available in appendix [ appendix_proof_theorems ] . introducing binary variables @xmath58 the pricing problem",
    "can be formulated as a mixed integer quadratic program : @xmath59 \\text { , } l \\in [ l ] \\label{constraints : pricing : residual1}\\\\",
    "t_{il}+(y_{il}-\\sum_{j=1}^j\\beta_j x_{ijl})+m(1-z_i)&\\geq 0   \\text{\\ \\ } & & i \\in [ i ] \\text { , } l \\in [ l ] \\label{constraints : pricing : residual2}\\\\ \\sum_{i=1}^i z_i",
    "& \\geq n \\label{constraint : pricing : minsize } \\\\ t_{il}&\\geq 0 \\text{\\ \\ } & & i \\in [ i ] \\text { , } l \\in [ l]\\nonumber\\\\ z_i&\\in \\{0,1\\}\\text{\\ \\ } & & i \\in [ i],\\nonumber\\end{aligned}\\ ] ] where @xmath31 is a large positive constant and",
    "is assumed to be valid ( does not cut an optimal solution ) .",
    "we can use the same approach from section 2.1 to set up a valid value for @xmath31 .",
    "a feasible solution s sse can be a valid value . by using similar arguments as those for constraints and , @xmath32 is the absolute error for the corresponding observation @xmath13 in the optimal solution if @xmath60 , and it is zero otherwise .",
    "the difference from the pricing problem in @xcite is that  is based on big m constraints and is for the generalized clr , while carbonneau _",
    "@xcite used logical implications of the constraints for the clr problem .    in the column generation algorithm ,",
    " are solved .",
    "recall that reduced cost for cluster @xmath47 is @xmath56 .",
    "it is easy to see that value @xmath61 is equivalent to to the value of with @xmath62 for @xmath60 and 0 otherwise .",
    "this follows from the fact that @xmath63 and @xmath48 is modeled by variables @xmath0 .",
    "* example * let us consider a data set with 4 entities and suppose @xmath64 .",
    "then , we have    @xmath65 ,    where @xmath66 . in algorithm",
    "[ alg : exactscg1 ] , suppose we start with subset @xmath67 of @xmath44 , which is a set of initial candidate clusters .",
    "the master problem in line 3 picks the best combination of the candidate clusters that has minimum total sse .",
    "suppose we obtain @xmath68 in line 3 together with the associated dual solution .",
    "here we assume that the solution is integral , albeit this might not always be the case . in line 4 ,",
    "the pricing problem is solved to search if there exists a candidate cluster not in @xmath51 that can improve the current best solution @xmath68 .",
    "suppose the pricing problem returns @xmath69 with a negative reduced cost . in line 8 , @xmath51 is updated to @xmath70 .",
    "if the optimal solution obtained by cg is not integral , branching would have to be performed , i.e. , a fractional variable @xmath71 needs to be selected and two new problems created , the first one would impose @xmath72 and the other one @xmath73 .",
    "however , the extensive evaluation conducted on algorithm [ alg : exactscg ] revealed that no fractional solutions were provided by algorithm [ alg : exactscg ] .",
    "for this reason in the remainder we focus on column generation for solving the lp relaxation and not branching .",
    "column generation is known to exhibit the tailing - off effect and for this reason we employ stabilized column generation of du merle _ et al .",
    "_ @xcite .    the stabilized column generation algorithm for solving the clr problem",
    "is illustrated in algorithm [ alg : exactscg ] .",
    "the algorithm takes input of stabilization parameters @xmath74 and @xmath75 , and maximum allowed iterations @xmath76 . in line 1 , we start with a set @xmath77 of initial clusters of entities .",
    "the generation procedure is identical to the one in line 1 of algorithm 1 .",
    "for iteration @xmath34 , in line 3 , we solve the stabilized master problem and get the optimal solution @xmath78 and its corresponding dual solution @xmath79 , which provides input parameters for the pricing problem .",
    "the stabilized master problem additionally includes parameters @xmath80 , @xmath81 and variables @xmath82 , @xmath83 but is very similar to - .",
    "see appendix [ appendix_restricted_master_problem ] for the actual formulation . by solving the pricing problem",
    ", we get a new cluster @xmath84 in line 4 .",
    "the reduced cost corresponding to this new cluster is equal to @xmath85 , where @xmath48 is the sum of squared residuals when performing regression over this cluster , and @xmath86 if and only if @xmath60 . in lines 5 - 6 , if the reduced cost is nonnegative and @xmath82 and @xmath83 are equal to zero , then the algorithm is complete with the optimal partition of clusters defined by @xmath87",
    ". otherwise , in lines 8 - 12 , we update @xmath51 and then if the reduced cost @xmath85 is nonnegative , we update the stabilization parameters @xmath80 , and @xmath81 .",
    "@xmath88 , randomly generate @xmath77 ( a small subset of @xmath44 ) @xmath89 solve the stabilized master problem - given in appendix [ appendix_restricted_master_problem ] @xmath90 solve the pricing problem with @xmath91 @xmath92 , and * stop * @xmath93 @xmath94 @xmath95",
    "@xmath96      the numerical experiments introduced later reveal that the column generation algorithm does not scale well to problems with a large number of entities . to overcome the scalability problem",
    ", we propose a heuristic method called the cg heuristic algorithm that relies on column generation .",
    "the cg heuristic algorithm first finds a partition with a large number of clusters by neglecting the cardinality constraint . in the second step ,",
    "we combine the clusters by considering unions to obtain exactly @xmath16 clusters while obeying the cardinality constraint , which is a slight variant of column generation .",
    "we refer to the intermediate clusters from the first part , which are the input to the column generation algorithm in the second part , as groups .",
    "the algorithmic framework is presented in algorithm [ alg : cgheur ] .",
    "we require that @xmath97 since the second step is to combine @xmath98 groups into @xmath16 clusters .",
    "lines 1 - 5 represent the first step to create @xmath98 groups and line 6 represents the second step to find a solution to the original problem .",
    "line 1 follows the same procedure as line 1 of algorithm 1 , except that we have r groups instead of k. lines 2 - 5 are basic and do not need further explanations .",
    "it yields @xmath98 `` low cost '' groups . since @xmath99 ,",
    "in line 6 we combine some groups so that we end up with exactly @xmath16 clusters , each one with cardinality at least @xmath21 .",
    "this regrouping of groups is performed in an optimal way by using the column generation framework .",
    "@xmath100 randomly generate @xmath98 groups perform regression over each group @xmath101 $ ] to obtain regression coefficients @xmath102 for @xmath103 $ ] , reassign entity @xmath10 to group @xmath104 , where @xmath105 execute cg by treating each group as entity    for line 6 , we need to revise the master and pricing problems in the following way when we cluster a group of entities instead of single entities .",
    "suppose at the end of line 5 we clustered @xmath2 entities into @xmath98 groups @xmath106 , and then apply the column generation algorithm to the @xmath98 groups of entities .",
    "let @xmath107 be the set of all subsets @xmath47 of @xmath108 $ ] such that @xmath109 , and let @xmath110 if @xmath111 , and @xmath112 otherwise . to obtain the new master problem",
    ", we need to replace @xmath44 with @xmath107 and @xmath46 with @xmath113 in the master problem . in addition , the range of constraints changes to @xmath101 $ ] .",
    "we denote the dual variables of constraints in the master problem by @xmath114 , and introduce the binary decision variables @xmath115 for @xmath101 $ ] to indicate whether group @xmath116 is selected in the cluster with the minimum reduced cost . to obtain the new pricing problem",
    ", we need to replace @xmath117 s with @xmath115 s in the pricing problem .",
    "constraint is changed to @xmath118 , and the range in constraints and now becomes @xmath101 \\text { , } i \\in g_r   \\text { , } l \\in [ l]$ ] .",
    "the new pricing problem has the same number of constraints as the pricing problem ",
    ", however , it has only @xmath98 binary variables , comparing to @xmath2 such variables in the pricing problem refeq : pricing.      scientific works as those presented by maulik and bandyopadhyay @xcite and chang _ et al . _",
    "@xcite , effectively suggest to embed the concept of the lloyd s algorithm , into a genetic search metaheuristic framework to find proper clusters for the mssc clustering problem . here",
    "we discuss our proposed adaptation of the ga - based lloyd s clustering algorithms for solving the generalized clr problem .    for the lloyd s algorithm part",
    ", a vector of regression coefficients @xmath119 is used to represent cluster @xmath34 , and an entity is recursively assigned to the cluster that gives the smallest sum of squared errors for this entity .",
    "the ga part helps escape local optimal solutions .",
    "the overall algorithmic framework is outlined in algorithm [ alg : galloyd ] .",
    "k , _ maxiter _",
    ", h , @xmath120    for each @xmath121 in @xmath122 $ ] , create @xmath123 by randomly generating @xmath16 clusters randomly select parent chromosomes @xmath124 and @xmath125 using roulette wheel selection create child chromosomes @xmath126 and @xmath127 by performing crossover on @xmath124 and @xmath125 mutation on @xmath128 obtain @xmath129 and @xmath130 based on lloyd s algorithm , calculate @xmath131 and @xmath132 replace @xmath133 , @xmath134 } \\gamma(h)$ ] , with the chromosome with larger fitness among @xmath126 and @xmath127    in line 1 , we start by randomly generating @xmath135 partitions @xmath136 , each of which corresponds to @xmath16 clusters of entities with @xmath137 for @xmath138 $ ] .",
    "the generation procedure is based on a uniform random number and is the same as the one in line 1 of algorithm 1 .",
    "any randomly generated partition @xmath123 has to satisfy the constraint that @xmath139 for @xmath23 $ ] .",
    "a population @xmath140 consists of @xmath135 chromosomes , and chromosome @xmath121 is encoded as a vector @xmath141 of size @xmath142 . in any chromosome ,",
    "the first @xmath6 genes represent the regression coefficients @xmath143 for the first cluster , and the next @xmath6 genes represent the regression coefficients @xmath144 for the second cluster , and so on .",
    "the encoding of chromosome @xmath121 is illustrated in figure [ figure : encoding ] .",
    "+    the regression coefficient @xmath145 is obtained by running regression over cluster @xmath146 .",
    "the fitness @xmath147 of the chromosome @xmath121 is defined to be @xmath148    we continue by performing the following genetic operations on the population of chromosomes iteratively until the number of iterations without improvement reaches a specified maximum number _ maxiter_. first , in line 3 , we randomly select two parent chromosomes @xmath124 and @xmath125 from population @xmath140 using roulette wheel selection .",
    "chromosome @xmath121 is chosen with probability @xmath149 .",
    "second , in line 4 , we perform crossover on chromosomes @xmath124 and @xmath125 .",
    "we select a gene position as a random integer in the range of @xmath150 $ ] .",
    "we require this random integer to be no more than @xmath151 so that there is at least one gene positioned to the right of it .",
    "the portions of the chromosome lying to the right of this gene position are exchanged to produce two child chromosomes @xmath126 and @xmath127 encoded by @xmath152 and @xmath153 .",
    "the crossover operation is illustrated in figure [ figure : crossover ] .",
    "+    third , in line 5 , we perform mutation on these two child chromosomes .",
    "the mutation is performed on a child chromosome with a fixed probability @xmath154 , where @xmath154 is a parameter . a gene position with value @xmath54",
    "is randomly picked from the child chromosome using a uniform random number .",
    "after mutation , it is changed to @xmath155 with equal probability if @xmath54 is not zero . here",
    "@xmath156 is a random number with uniform distribution between zero and one .",
    "otherwise , when @xmath54 is zero , it is changed to @xmath157 with equal probability . in this way",
    ", the regression coefficients can take any real values after sufficient number of iterations .",
    "next , in line 6 , we need to decode these two mutated child chromosomes to get the partitions @xmath129 and @xmath130 of clusters they represent . to decode the child chromosome @xmath126",
    ", we assign entity @xmath10 to cluster @xmath158 for @xmath159 then , we perform regression over each cluster of @xmath129 and @xmath130 , and update the encoding of these two child chromosomes @xmath152 and @xmath153 with the resultant regression coefficients .",
    "fitness @xmath160 and @xmath161 are calculated for the child chromosomes using . in lines 6 - 7",
    ", we replace the chromosome in population @xmath140 with the smallest fitness with the child chromosome with the smaller fitness if @xmath162 } \\gamma(h)$ ] .    during the decoding step of the ga - lloyd algorithm",
    ", we may need to adjust the clusters generated in order to satisfy the minimum size constraints . if cluster @xmath163 has size smaller than @xmath21 , then we sort the entities not in @xmath163 in the increasing order of the sum of squared regression errors , and then reassign these entities in the sorted order to cluster @xmath163 until the size of @xmath163 reaches @xmath21 .",
    "we also skip each entity that would reduce the size of its original cluster below @xmath21 .",
    "when there is more than one cluster with size smaller than @xmath21 , we perform this adjustment for the smallest cluster first .      due to its simplicity , two - stage",
    "heuristic algorithms are frequently employed in practice for solving the clr problem . in the first stage ,",
    "entities are partitioned according to certain approximate measures of the regression coefficients . in the second stage",
    ", regression models are built over the resultant clusters .",
    "the clustering method for the first stage is usually problem specific .    * * stage 1 * partition @xmath2 entities ( skus ) into @xmath16 clusters .",
    "let @xmath164 $ ] be the index set of entities in cluster @xmath34 , @xmath23 $ ] . * *",
    "stage 2 * for each @xmath23 $ ] , build a regression model using entities in @xmath164 $ ] .    in this section",
    ", we describe our two stage heuristic algorithm for the sku clustering problem .",
    "recall that we are given    [ cols= \" < , < \" , ]      +    this gives a justification to evaluate algorithms for larger instances based on the gap from the target solution .",
    "however , in our experiment for larger instances , we observed that most of the proposed algorithms give a better objective function value than the target solution .",
    "hence , we did not use the target solution to evaluate the algorithms in the paper .",
    "however , the target solutions are available on the website stated in section [ sec : experiments ] .",
    "in this section , we present a stabilized version of the master problem - , referred to as restricted master problem , by applying the technique of du merle _ et al .",
    "_ @xcite . for iteration @xmath34 ,",
    "the restricted master problem is written as @xmath165 \\label{constraints : restrictedpartition : assignment}\\\\ & 0 \\leq \\boldsymbol{q}^- \\leq \\boldsymbol{\\xi}^{(k)}\\\\ & 0 \\leq \\boldsymbol{q}^+ \\leq \\boldsymbol{\\xi}^{(k ) } \\label{restr222}\\\\   & z_s \\in \\{0,1\\}\\quad & s \\in \\mathscr{s},\\nonumber\\end{aligned}\\ ] ]"
  ],
  "abstract_text": [
    "<S> cluster - wise linear regression ( clr ) , a clustering problem intertwined with regression , is to find clusters of entities such that the overall sum of squared errors from regressions performed over these clusters is minimized , where each cluster may have different variances . </S>",
    "<S> we generalize the clr problem by allowing each entity to have more than one observation , and refer to it as generalized clr . </S>",
    "<S> we propose an exact mathematical programming based approach relying on column generation , a column generation based heuristic algorithm that clusters predefined groups of entities , a metaheuristic genetic algorithm with adapted lloyd s algorithm for k - means clustering , a two - stage approach , and a modified algorithm of spth @xcite for solving generalized clr . </S>",
    "<S> we examine the performance of our algorithms on a stock keeping unit ( sku ) clustering problem employed in forecasting halo and cannibalization effects in promotions using real - world retail data from a large supermarket chain . in the sku clustering problem </S>",
    "<S> , the retailer needs to cluster skus based on their seasonal effects in response to promotions . </S>",
    "<S> the seasonal effects are the results of regressions with predictors being promotion mechanisms and seasonal dummies performed over clusters generated . </S>",
    "<S> we compare the performance of all proposed algorithms for the sku problem with real - world and synthetic data . </S>"
  ]
}