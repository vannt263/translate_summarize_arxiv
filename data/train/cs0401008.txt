{
  "article_text": [
    "these routines compute the functions @xmath0 and @xmath1 , which constitute a numerically satisfactory pair of independent solutions of the modified bessel equation of imaginary order :    @xmath11    the routine dkia computes @xmath0 and its derivative .",
    "dlia computes @xmath1 and its derivative .",
    "both routines require that a method for computing airy functions of real variable is available .",
    "the routines use algorithm 819 @xcite .",
    "the algorithm combines different methods of evaluation in different regions .",
    "comparison between the different methods ( see accompanying paper @xcite ) , together with the use of the wronskian relation , has been used to determine the accuracy of the algorithm ( see section [ sec2 ] ) .",
    "the algorithm computes either the functions @xmath0 , @xmath1 and their derivatives or scaled functions which can be used in larger regions than the unscaled functions .",
    "the scaled functions are defined in the accompanying paper @xcite ( section 3 , eqs .",
    "( 43 ) and ( 44 ) ) and in the comment lines of the algorithms .",
    "the relative accuracy of the algorithms is ( except close to the zeros of the functions ) better than @xmath7 in the @xmath12-region @xmath13 \\times [ -200,200]$ ] , better than @xmath14 in @xmath15 \\times [ -500,500]$ ] and close to @xmath9 in @xmath16 \\times [ -1500,1500]$ ] . both scaled and unscaled functions can be computed in @xmath17 but only scaled functions can be evaluated in the whole domains @xmath18 and @xmath19 without causing overflows / underflows for typical ieee machines .",
    "see the accompanying paper @xcite , section 3 .",
    "because the scaled and unscaled functions are even functions of @xmath2 , we can restrict the study to @xmath20 .    in order to determine the region of applicability of each method ,",
    "we have compared all the methods available with the non - oscillating integral representations in the accompanying paper @xcite , section 2.4 , which are expected to be valid in all the @xmath12 plane except close to @xmath21 .",
    "this is so because , as explained in @xcite , the integration paths become increasingly non - smooth as one approaches the transition line @xmath21 ( in this region , the uniform asymptotic expansions in the accompanying paper , section 2.3 , are the best option ) .",
    "the remaining approaches have little or no overlap in their regions of validity , except for the continued fraction method for the computation of @xmath0 and @xmath22 and the asymptotic expansions for large @xmath3 ; in fact , the validity region of the cf - method completely covers that of the asymptotic expansion ; therefore , the cf method is preferred over the asymptotic expansion for large @xmath3 for the computation of @xmath0 and its derivative .",
    "as we will next describe , for not too large values of @xmath2 and @xmath3 there are at least two alternative methods of computation in any region of the @xmath12 plane .",
    "this is important in order to determine the accuracy reachable by the algorithm .",
    "a second validation of the methods is provided by the wronskian relation @xmath23 which is also satisfied by the scaled functions @xmath24 , @xmath25 , @xmath26 , @xmath27 .    of course",
    ", when two different approaches are available within a given accuracy in a same region , we choose the fastest method of computation . by order of speed , from fastest to slowest we can list the different methods of computation described in @xcite as follows :    1 .",
    "series expansions and continued fraction method .",
    "2 .   asymptotic expansions .",
    "integral representations .",
    "figures 1,2 show the regions in the plane @xmath12 where the different methods are used in the routines dkia and dlia , respectively . in the first comment lines of the codes ,",
    "the explicit equations for the curves separating the different regions are given .",
    "* figure 2 .",
    "* regions of applicability of each method for the @xmath1 , @xmath28 functions . *",
    "uae * : uniform airy - type asymptotic expansion ; * i * : integral representations ; * s * : power series ; * cf * : for continued fraction and * ae * : asymptotic expansions .    both the direct comparison with integral representations as well as the wronskian check show that the unscaled and scaled functions can be computed with an accuracy better than @xmath7 in the region @xmath29\\times [ 0,200]$ ] without using integral representations .",
    "this accuracy was found to be in a good compromise with efficiency .",
    "we expect that function values outside this range will not be needed very often .",
    "as the range considered is increased , the accuracy decreases mildly , being better than @xmath30 in @xmath6 \\times [ 0,500]$ ] and close to @xmath9 in the full range of computation @xmath10\\times [ 0,1500]$ ] . of course , near the zeros of the functions",
    "( there are infinitely many of them in the oscillatory region @xmath31 ) relative accuracy loses meaning and only absolute accuracy makes sense .",
    "figure 3 shows the cpu time spent by the code in the regions @xmath32\\times [ 0,l]$ ] ; these cpu times refer to a pentium - ii 350-mhz processor running under debian - linux ; the compiler used was the gnu fortran compiler g77 .",
    "* figure 3 . * cpu times in @xmath33\\times [ 0,l]$ ] as a function of @xmath34 .",
    "it is apparent from the figure that different methods with different speeds appear as @xmath34 grows . for small @xmath34 , only series ( and the cf method for @xmath35 )",
    "are needed , which are the fastest methods .",
    "as soon as asymptotic expansions come into play the cpu times tend to increase more rapidly . for @xmath34 larger than @xmath36 the effect of",
    "the use of quadratures becomes prominent .",
    "tables 1 and 2 show the average time spent by each method of computation in microseconds , both for dkia and dlia routines . also , the percentage of use of each method is shown .",
    "these data are shown for two different regions of computation : the `` @xmath7 accuracy region '' ( @xmath8\\times [ 0,200]$ ] ) ( table 1 ) and the full range permitted by the routines ( @xmath10\\times [ 0,1500]$ ] ) ( table 2 ) .",
    "@xmath37 * table 1 . *",
    "percentage of use and average cpu times of each method in the region @xmath8\\times [ 0,200]$ ] .",
    "@xmath38 * table 2 . *",
    "percentage of use and average cpu times of each method in the region @xmath10\\times [ 0,1500]$ ] .",
    "the algorithm has been tested in several computers and operating systems ( pentium ii pc under debian linux , pentium iv laptop under windows xp , pentium iv pc under windows xp and red hat linux and solaris 8 workstation ) and several compilers ( g77 and f77 for linux and windows , digital fortan and lahey fortran for windows and the sun fortran 95 ) .",
    "in spite of the many applications of the modified bessel functions of imaginary order , the only previously published algorithm , as far as the authors know , is the code by thompson and barnett @xcite ( tb algorithm from now on ) . this code is intended for the computation of coulomb wave functions of complex order and arguments , which have as a subset modified bessel functions of complex orders .",
    "it is not surprising that , as we later discuss , the tb algorithm has limitations when computing the @xmath0 and @xmath1 functions : this is a more general algorithm than ours and it was specially designed for real parameters , although it can be applied for complex parameters too . apart from this code , there are no available algorithms in the public domain , as can be judged by browsing at gams ( guide to available mathematical software : http://gams.nist.org ) , which are able to compute @xmath0 , @xmath1 and their derivatives .",
    "as figure 4 shows , the tb algorithm ( program coulcc available from cpc library ) is inaccurate for imaginary orders and suffers from overflow and convergence problems .",
    "we have tested the program coulcc @xcite against our algorithms .",
    "figure 4 shows the comparison . at the lighter points the flag for detecting errors in coulcc was different from zero , showing that the algorithm failed to converge or suffered overflows .",
    "the rest of points show discrepancies with our code , which persist for @xmath39 accuracy and lower .",
    "of course , at the lighter points all the accuracy is lost and the problems persist for larger values of @xmath3 and @xmath2 .",
    "* figure 4 .",
    "* regions where the tb algorithm fails due to poor convergence or overflows ( light shaded points ) and points where accuracy is lost ( dark shaded points ) .",
    "the discrepancy is greater than @xmath39 in the left figure and greater than @xmath7 in the right figure .",
    "therefore , our algorithm seems to be the first accurate and efficient code which is capable of computing modified bessel functions of imaginary order with an accuracy close to full double precision in a wide domain .",
    "99 a. gil , j. segura , n.m .",
    "computing solutions of the modified bessel differential equation for imaginary orders and positive arguments .",
    "acm trans . math . soft .",
    "( submitted for publication in this same issue ) ."
  ],
  "abstract_text": [
    "<S> fortran 77 programs for the computation of modified bessel functions of purely imaginary order are presented . </S>",
    "<S> the codes compute the functions @xmath0 , @xmath1 and their derivatives for real @xmath2 and positive @xmath3 ; these functions are independent solutions of the differential equation @xmath4 . </S>",
    "<S> the code also computes exponentially scaled functions . </S>",
    "<S> the range of computation is @xmath5\\times [ -1500,1500]$ ] when scaled functions are considered and it is larger than @xmath6\\times [ -400,400]$ ] for standard ieee double precision arithmetic . </S>",
    "<S> the relative accuracy is better than @xmath7 in the range @xmath8\\times [ -200,200]$ ] and close to @xmath9 in @xmath10\\times [ -1500,1500]$ ] . </S>"
  ]
}