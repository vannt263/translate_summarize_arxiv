{
  "article_text": [
    "during the last decade , much attention has been devoted to the detection of machos ( massive astrophysical compact halo objects ) .",
    "several teams have shown that microlensing can be successfully used to detect the slight changes in the luminosity of background stars caused by the passage of a massive deflector interposed along ( or close ) the line of sight ( paczynski 1986 , alcock et al .",
    "1993 , auborg et al .",
    "1993 , udalski et al .",
    "1993 ) .",
    "the pixel lensing method was proposed and implemented by the agape collaboration to monitor simultaneously large numbers of stars and therefore increase the probability to detect the intrinsically rare microlensing events ( baillon et al . 1993 , ansari et al .",
    "a similar technique , based on image subtraction , was used by the vatt - columbia collaboration ( tomaney and crotts 1994 , tomaney 1996 ) .",
    "both techniques were successfully tested ; recently the discovery of new candidate events towards the andromeda galaxy was announced ( auriere et al . 2001 , calchi novati et al . 2002 ) .",
    "additional microlensing candidates towards andromeda were found by crotts ( 2000 ) .    in pixel lensing",
    ", the search for microlensing events is performed by monitoring the light curve of individual image pixels rather than that of individual stars . such approach , however , while ensuring an enormous gain in the statistics , poses paramount problems in resolving the lensed sources . from a computational point of view",
    ", pixel lensing requires a large number of floating point operations on each individual pixels .",
    "this leads to very large computational loads and usually prevents the real - time detection ( and possible follow - up s ) of the candidate events . in this paper",
    "we describe the new tool medea - already outlined in a preliminary and much less complete version in ( capozziello and iovane 1999 ) - which , by making use of advanced data mining techniques , allows the real time processing of pixel data .",
    "this paper is organized as follows . in the sect.2 , we give the scientific background of the microlensing theory and of the pixel lensing technique .",
    "sect.3 is devoted to a general description of the medea environment .",
    "sect.4 describes the data pre - processing and sect.5 the data processing .",
    "the analysis of the data is discussed in sect.6 , while some conclusions are drawn in sect.7 .",
    "if a massive object acting as a gravitational lens on a background source is sufficiently close to the line of sight of the observer , the light is deflected by an angle which is usually too small to produce observable multiple images and we can observe only a magnification of the flux coming from the source .",
    "the magnification factor @xmath0 is given by : @xmath1 where @xmath2 @xmath3 is the angle between the optical axis and the direction of the source , @xmath4 is the distance between the observer and the lens , @xmath5is the einstein radius , @xmath6 is the distance between the lens and the source ; @xmath7 is the distance between the observer and the source .",
    "these events , also known as microlensing , are characterized by three main features :    * * uniqueness of the event * : the probability that a microlensing events occurs twice on the same star is assumed to be zero ; * * symmetry of the light curve * : the light curve ( in point - like model of lens and source ) has to be symmetric about the maximum magnification point ; * * achromaticity of the event * : the ratio between the flux variation in different colours , @xmath8 is constant in time ( schneider , ehlers and falco 1992 ) .",
    "it is useful to stress that a differential amplification of extended sources can give rise to a chromatic , but still symmetric , lensing curve ( han et al .",
    "2000 ) . to study the case of pixel lensing ,",
    "let us start from defining the flux inside a fixed pixel as :    @xmath9    where @xmath10 is the photon flux of the star  at rest",
    " that will be lensed , @xmath11 is the photon flux coming from neighboring stars falling in the same pixel , and @xmath12 is the noise .",
    "a microlensing event implies a variation of @xmath13 with time :    @xmath14",
    "medea is structured as follows ( see fig.1 ) : ( iovane 2002 ) .",
    "i ) the advanced data acquisition ( a - daq ) unit : responsible for the data acquisition and pre - reduction .",
    "\\ii ) the control unit ( cu ) piloting the telescope control system ( tcs ) which drives the telescope following the instructions provided either by the data base control system ( dbcs ) or by the user .",
    "\\iii ) the database ( db ) unit : it is the ",
    "intelligent  part of the system where the data are stored and processed according to the simulations or previous observations ( jordan 1997 ) .",
    "\\iv ) the processing and analyzing ( p&a ) unit : platform where massive data analysis is performed .",
    "\\v ) dispatcher unit ( du ) : which automatically builds a status report on the different phases of the data flow .",
    "more in detail : statistics , plots of data and events are produced and stored by this module .",
    "moreover , in the occurrence of special events ( such as an alert or failure of the system , or a short microlensing event , for which a quick answer is needed ) this unit can reach and alert people in automatic mode thanks to an e - mail service , sms ( short message system ) and fax messages .",
    "the processing and analyzing unit consists of three main units : the data pre - processing unit ( dapp ) for astrometric alignment and for photometric and seeing correction ; the data processing unit ( dap ) for peak detection of relevant luminosity variation ; the data analysis unit ( dau ) for best fits , color correlations , @xmath15 tests , kolmogorov - smirnov tests .",
    "the a - daq unit and dapp unit are organized in a fully automatic , non interactive and on line modality .",
    "a first trigger level ( for selecting luminosity variations trough a peak detection algorithm ) is the most relevant component of dap unit .",
    "it consists of four sections : a ) peak detection procedure , b ) star detection and filtering algorithm , c ) cosmic rays filter , and d ) peak classification ( single , double , multiple peak curves ) routines .",
    "also the dap unit operates in real time , thus implying that the whole data reduction is performed while the next set of data is acquired .",
    "the second trigger level , corresponding to the selection of microlensing events , is inside the dau . during this phase",
    ", we also test whether the measured luminosity curves are compatible or not with simple lensing models    the events which pass the first trigger level and are incompatible with the simple models included in the second trigger level are studied off - line by means of interactive procedures .",
    "this study is relevant in order to understand those events which are produced by complex lensing phenomena ( such as double deflector , planetary system and so on ) , variable stars or novae and supernovae .",
    "the data pre - processing unit ( dapp )  is composed by three software modules : astrometric alignment unit , photometric correction unit , seeing correction unit .      in the astrometric alignment module , we find three hierarchical levels : the first one is responsible of the data i / o and controls the user interface , the second one controls the learning of a properly selected part of the reference image which will be compared with the other images to be aligned , while the last object performs the astrometric alignment according to the well known transformation    @xmath16    at the second level , it is possible to define a dimension for the images on which the system has to learn the pattern .",
    "in other words , the program fixes the size of the calibration windows as a function of both the density of the field and of its auto - similarity .",
    "of course , it is possible to use the full frame , but this could turn out to be computationally too heavy .",
    "the structure of the learning phase is the following :    * an automatic threshold filters the pixels having counts above a fixed treshold @xmath17 ( with @xmath18 ) ; * a clustering procedure builds pixel clusters and rejects those clusters which are either too large or too small ( compared to a test performed on the pixel area ) , or have a very irregular shape ( evaluated against the inertial momenta of the pixel cluster ) ; * the evaluation of the center of mass for each surviving cluster and of the corresponding pattern considered for the astrometric calibration .    in order to perform pattern matching , we implemented a tool ( image advanced interpreter matching ) which incorporates image understanding techniques to interpret the template information , and then uses this information to recognize the template in the image . in order to generate information about the features of a template image",
    "we have used the following information source : a ) geometric modeling of images ; b ) effective non - uniform sampling of images ; c ) extraction of template information .",
    "this algorithm is built to fulfill the following main functions :    \\1 .",
    "edge detection and clusters selection ;    \\2 .",
    "evaluation of geometrical parameters @xmath19 : cluster s area ( in pixel ) , cluster s perimeter , number of holes in each cluster , hole s area ( in pixel ) , hole s perimeter , cluster s inertial tensor ( where the luminosity plays the role of the mass ) ;    \\3 .",
    "computation of a linear function of the previous parameters for each cluster , accordingly to the formula :    @xmath20    where @xmath21    the calibration is connected with the maximum correlation between images , trough @xmath22 .",
    "in other words , we minimize :    @xmath23    where @xmath24 is the image index , while @xmath25 and @xmath26 are the cluster indexes .",
    "we evaluate the coefficients @xmath27 and @xmath28 , @xmath29 of eq.(4 ) by using a number of cluster larger than the number of calibration parameters , in correspondence of the minimum value of @xmath30 .",
    "this approach reduces the amount of information needed to characterize completely an image or pattern , thus speeding up the searching process .",
    "changes in the observing conditions are locally corrected with respect to the reference image which , by definition , we assume to be the one with the best seeing .",
    "the algorithm , which was implemented taking into account the possibility of parallel computing , corrects local fluctuations of the flux due to gradients in the image ( e.g. the effect the lunar stray light ) .",
    "the image is first divided in cells then , in addition to the pixel coordinates @xmath19 and @xmath31 , we have two cell indexes , @xmath32 and @xmath33 .",
    "moreover , we have an index to select the image , @xmath34 . in this way , in order to select the luminosity of a pixel in an image of the set we have to assign a vector with five components : @xmath35 .",
    "the mean flux value and the standard deviation are evaluated for each cell .",
    "noisy pixels , cosmic rays and bad pixels are rejected and then the mean flux and the standard deviation are again evaluated and stored . after these operations , we impose that the mean value of the flux must be equal on the compared cells",
    ".    this method does not work properly for pixels lying on the edges of the cells pixels , a good cell size is one order smaller than the original image size ( i.e. about @xmath36 ) . ] .",
    "if at the end of the analysis there is a pixel on the edge of a cell with an interesting light curve , a specific photometric alignment is performed off - line by posing the relevant pixel at the center of a new cell and then iterating the above described procedure .    in the first prototype of the pipeline",
    ", we implemented a bi - dimensional interpolation on edges , but the signal turned out to be diluted by the interpolation process thus imposing the introduction of the cell approach .",
    "2 , 3 , and 4 show the reference image , the current image , and the current image after the photometric correction .",
    "moreover , we find the grey level histograms before and after photometric calibration in fig.5 and 6 .      the real time ( in a post processing point of view )",
    "correction of the seeing is a relevant issue ( cf .",
    "sedmak 1999 ) .",
    "the analysis is performed on a cluster of pixels ( superpixel ) with a size large enough to cover the psf . in the standard pixel lensing data reduction ( ansari 1997 ,",
    "le du 2000 ) , the superpixel size is chosen to be large enough to cover the worse psf and is the same for all images .",
    "here we dynamically select the dimension of the superpixel with respect to the psf measured on some calibrators in the fields ( i.e. for each image corresponding to a given observation ) .",
    "the seeing variation factor is evaluated and defined as the ratio of the area in pixels of selected clusters between a reference image and another one .",
    "this number becomes the input to build the kernel @xmath37 of a morphing algorithm that in our case is a dilation algorithm .",
    "then if @xmath38 is the kernel and @xmath39 is the pixels matrix , the seeing corrected image @xmath40 is :    @xmath41 \\\\",
    "\\left [ j - m , j+m\\right ] \\end{array } , \\ ] ]    where @xmath42 is the kernel size for the convolution . in this procedure , the kernel is a polynomial function in @xmath43 and the superpixel can be chosen between rectangular and exagonal one ( see fig.7 ) . in figs .",
    "we show the same field in different seeing conditions .",
    "the data processing unit is made of four sub - units : star detection and filtering unit , cosmic detection and filtering unit , peak detection unit , and peak classification unit .",
    "the cosmic rays unit just switches off the saturated pixels , while the peak classification unit splits the curves in function of the number of the peaks attributing them to different classes .",
    "this component finds and rejects resolved objects inside the field . after performing several tests",
    ", we decided to work in the transformed space . in astronomical image processing",
    "the fourier transform is often used to select the main characteristics or the morphology of bright objects ( pratt 1977 , sedmak et al .",
    "if we consider the image as a function of two variables @xmath44 ,  we will be able to define a transformed image @xmath45 . in our case",
    "@xmath46 is obtained by fast fourier transforming the image @xmath47    @xmath48    where @xmath49 are the horizontal and vertical spatial frequencies .",
    "the function @xmath46 is a complex image in which the high frequencies are clustered at the center , while the low ones are located at the edges .",
    "fig.10 shows the complex image @xmath46 corresponding to the real image @xmath47 shown in fig.2 .    to select and reject the resolved objects -",
    "which correspond to low frequency signals in the transformed image - we implemented an adaptive high pass filter in the transformed space which produces an automatic thresholding in the frequencies domain . in figs .",
    "11 and 12 , we give the scheme of the filter and its effect on the complex image , while in fig.13 we show the same image antitransformed and therefore cleaned of the resolved objects .",
    "the detection of the luminosity variation in the light curve is performed by a peak detection algorithm .",
    "first of all we evaluate the background level as :    @xmath50    where @xmath12 is the number of points in the light curve ( e.g. the number of images ) , @xmath51 is the dimension of the window which we use to evaluate @xmath11 ( @xmath52 ) .",
    "we evaluate the mean value of the flux in a window running on the light curve and having a size of @xmath51 ; then we consider as background the minimum of the means and then evaluate the maximum standard deviation @xmath53 to assess its stability . before the peak detection step ,",
    "we apply a median filter on the signal in order to estimate the best peak parameter by separating pure signals from noise fluctuations .",
    "if @xmath54 represents the output sequence , i d est the filtered data , and if @xmath55 represents a subset of the input sequence @xmath56 centered on the @xmath57  element of @xmath58@xmath59    if the indexed elements outside the range of @xmath56 are equal to zero , the function gives the elements of @xmath54 by using :    @xmath60    where @xmath12 is the number of elements in the input sequence @xmath56 , and @xmath61 is the filter rank .",
    "the effects of the filter are shown in fig.14 .",
    "afterwards we perform a peak detection on the filtered signal with a polynomial ( usually of the 2@xmath62 order is enough ) linearly combined , trough a sum operator :    @xmath63    where @xmath34  is the space of peaks and the symbol @xmath64 means a sum of functions at different @xmath58 .",
    "for instance , for a 2-modal light curve , we have :    @xmath65    outputs of this routine are the parameters to be used for the fit of the light curve : i.e. the number of peaks , the location ( @xmath66 ) and the amplitude .",
    "the on - line and off - line are performed in the data analysis unit . here ,",
    "the statistical @xmath67 and kolmogorov - smirnov tests , and the evaluation of a specific quality factor are made . the color correlation among light curves is tested in different color bands at the end of the process .",
    "the on - line sub - unit can perform basic fits using the parameters derived in the peak detection phase by means of the levenberg - marquardt algorithm for non - linear fit .",
    "this sub - unit is fully automated and perform in real time the following fits :    * * paczynski test .",
    "* we consider magnification @xmath68 defined as + @xmath69 + with @xmath70 , where @xmath71 is the impact parameter at maximum magnification , @xmath72is the time of maximum magnification , and * *  * * @xmath73 is the einstein time . *",
    "* double source test .",
    "* according to the model by griest and hu ( 1992 ) there will be two @xmath66 and two @xmath74 and therefore two functions : @xmath75  and @xmath76 .",
    "consequently , let @xmath77 and @xmath78 be the flux of the two parts and the flux offset ratio @xmath79 , then the light magnification is given by : + @xmath80 + the light curve is the superposition of two light curves for point - like sources , affected by a point - like mass deflector .",
    "* * extended circular source .",
    "* this is the case of an optical system with a point - like lens and an extended circular source having radius @xmath61 and constant surface brightness .",
    "the implementation uses the model proposed by witt and mao ( witt and mao 1994 ) .",
    "medea also contains a set of tools to study more complex events ( cf . di stefano and mao 1996 , dominik 1998 , dominik 1999 ) .",
    "in particular , the events which pass the first trigger level but are not selected by the second trigger can be analyzed off - line both automatically and manually .",
    "the analysis is performed by means of the comparison with reference simulated data stored inside the database .",
    "the db events are simulated in order to test the following hypotheses : a ) double point - like lenses , and single point - like source ; b ) nova and supernova ; variable source .",
    "tools for a traditional analysis ( i.e. standard light curves analysis ) are implemented too .",
    "the second trigger consists of two selective procedures : the first one is a statistical phase , while the second one is specific for microlensing .",
    "the @xmath15 and kolmogorov - smirnov test are implemented to evaluate the quality of the tested hypotheses . for each model",
    "we consider the @xmath15 test and the @xmath81-factor of kolmogorov - smirnov test , then a quality factor m is estimated .",
    "it is defined as    @xmath82    and light curves with @xmath83 are considered as possible microlensing events .",
    "the events , passing the previous tests , are considered for the color test . the cross correlation between different colors",
    "is estimated as :    @xmath84    where the index @xmath85 is linked with pixel and @xmath12 with the point along the light curve . for @xmath86 the event",
    "is considered a good microlensing candidate .",
    "medea was specifically tailored to perform automatic microlensing search .",
    "most of the tools presented in this paper can be applied in other fields , where pipelines and data mining procedures are needed for large amounts of data .",
    "the procedures implemented in medea environment and presented in the data acquisition ( daq ) , and in the data pre - processing ( dapp ) units have been tested on simulated data and images , while the data processing ( dap ) and the data analysis ( dau ) units have been tested on a set of data collected at the 1.3 m mcgraw - hill telescope , at mdm observatory - kitt peak , in the period from the end of september to the end of december 1999 , by using the bulge of andromeda as target .",
    "the results agree with `` traditional '' pixel lensing analysis performed by the agape collaboration .",
    "the flexibility of the system allows to perform automatic , semiautomatic or researcher assisted procedures of the candidate microlensing events .",
    "common microlensing events due to single and double point - like source , or extended source are analyzed on - line and with automatic procedures , while more complex events such as double lens , novae , supernovae , variable stars or multiple deflectors system ( planetary systems ) , double point - like sources and lenses are studied off - line , either with automatic procedures ( based on the use of a database of simulated events ) , or individually with other tools . in this way",
    ", all the advantages of non - automatic procedure are kept , and also common events are automatically studied so that the researcher has only to control them . the detection of short events or events with huge main peaks and secondary ones near the first ( as in the case of planetary system ) becomes possible thanks to the real time light curve monitoring and to the dispatcher implementation .",
    "in addition , thanks to the fast- and real - time analysis , the exact knowledge of the time region in which there is a luminosity magnification gives the possibility to use larger telescopes to resolve the pixels and obtain more detailed astrophysical information on the magnified star . finally the reduction of time to spend for data analysis after data taking is a good starting point to perform lensing analysis on large field ccd data obtained in the course of specific surveys .",
    "+   + acknowledgements : the authors wish to thank slott - agape collaboration for useful suggestions and comments about lensing , and g.sedmak for suggestions about the seeing correction .",
    "this work was partly sponsored by the ministero italiano per luniversit e la ricerca scientifica e tecnologica in the framework of a cofin 2000 .",
    "g.iovane , medea : automated measure and on - line analysis in astronomy and astrophysics for very large vision machine , proceeding of nidays 2002 , pag.171 , vnu business publications , national instruments , astro - ph/0206259                              figure 1 .",
    "the medea flow chart .",
    "the dotted part ( e.g. telescope remote control , telescope remote observing ) in the control unit could be very useful if one starts to think about remote control and observations .",
    "+ figure 2 .",
    "andromeda in a good photometric condition .",
    "+ figure 3 .",
    "andromeda in a not so good photometric condition . + figure 4 .",
    "andromeda prototype image after photometric alignment .",
    "+ figure 5 .",
    "gray level histogram of two images before photometric alignment .",
    "+ figure 6 .",
    "gray level histogram of two images after photometric alignment .",
    "+ figure 7 .",
    "rectangular and exagonal superpixel frame .",
    "+ figure 8 . image with a good seeing condition ( vlt image of distant galaxies in axaf deep field by eso 2000 ) . + figure 9 .",
    "image with a worst seeing condition ( vlt image of distant galaxies in axaf deep field by eso 2000 ) . + figure 10 .",
    "fft transformed image of andromeda .",
    "+ figure 11 .",
    "the scheme of the filter in the transformed space .",
    "+ figure 12 . the filtering effect on andromeda image in transformed space .",
    "+ figure 13 .",
    "the filtering effect on andromeda image in anti - transformed space ( or real ) . + figure 14 .",
    "effect of median filter ."
  ],
  "abstract_text": [
    "<S> pixel lensing is a technique used to search for baryonic components of dark matter ( machos ) and allows to detect microlensing events even when the target galaxies are not resolved into individual stars . </S>",
    "<S> potentially , it has the advantage to provide higher statistics than other methods but , unfortunately , traditional approaches to pixel lensing are very demanding in terms of computing time . </S>",
    "<S> we present the new , user friendly , tool medea ( microlensing experiment data - analysis software for events with amplification ) . </S>",
    "<S> the package can be used either in a fully automatic or in a semi - automatic mode and can perform an on - line identification of events by means of a two levels trigger and a quasi - on - line data analysis </S>",
    "<S> . the package will find application in the exploration of large databases as well as in the exploitation of specifically tailored future surveys .    </S>",
    "<S> pacs : 95.75.mn , 95.75.pq , 98.56.ne , 98.62.sb , 95.35.+d </S>"
  ]
}