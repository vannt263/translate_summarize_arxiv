{
  "article_text": [
    "in the last decades of the 19th century w.f.r .",
    "weldon had encountered a problem while he was analysing the evolution of sea shells and collected morphological data .",
    "the distribution of this data set was not in the shape of a gaussian .",
    "this situation was unusual for those days and has brought to mind an important question : does this deviation from the gaussian stem from a data collection error or the evolution is really going on such a way ? when the problem was taken up by pearson , the story which led to the introduction of kurtosis index began . for further information",
    ", one can see @xcite and references therein .",
    "after firstly introduced by pearson in 1905 @xcite , kurtosis has became a quantity widely encountered in many textbooks .",
    "nowadays there is a perception that having a larger kurtosis value means a larger deviation from gaussian distribution .",
    "two non - gaussian distributions are compared to each other based on this perception .",
    "there are some common misconceptions like this about using kurtosis .",
    "decarlo has addressed some of these misconceptions and their explanations @xcite .",
    "various misconceptions and misunderstandings are discussed with examples not only from undergraduate level textbooks but also from graduate level ones .    in a recent work , the relation between skewness and kurtosis has been studied by cristelli _",
    "the authors have analysed three different non - gaussian data sets .",
    "two of them are taken from the global centroid - moment - tensor ( cmt ) and iside ( italian catalog ) earthquake catalogs . for the third data",
    "set , they have focused on the daily price returns from the s@xmath4p @xmath5 index . the procedure used to analyse the data sets is to divide datasets into subsamples and calculate skewness ( @xmath6 ) and kurtosis ( @xmath7 ) for each subsample window using the standard definitions of these quantities given by    @xmath8 , \\label{skewness}\\ ] ]    and    @xmath9 , \\label{kurtosis}\\ ] ]    where @xmath3 is the number of data points , @xmath10 is the mean of the sample and @xmath11 is the standard deviation .",
    "the largest dataset ( financial data ) is divided into subsamples of length @xmath12 and as clearly seen in fig .  2 of @xcite , two different scaling regimes of power - law type are observed for kurtosis versus skewness plot . in one of these regimes ,",
    "all points are clustered like a power - law with an exponent of 2 , namely ,    @xmath13    around the point @xmath14 and @xmath2 which are characteristic values of an infinite gaussian distribution .",
    "the constant term in eq .  ( [ parabol ] ) is the lower bound for the difference @xmath15 .",
    "although the shape of the distribution affects the value of the bound , pearson has found that it is approximately @xmath16 . in @xmath17",
    ", klaassen put this relation into its final form as @xmath18 , which is in eq .",
    "( [ parabol ] ) , for unimodal distributions @xcite .    outside this regime , the relation between skewness and kurtosis turns out to be a power - law with an exponent of @xmath0 .",
    "the argument given in @xcite in order to explain this behaviour is the following .",
    "if there is a sufficiently extreme event in the data set , this event dominates the summation and the contribution of other points can be considered as negligible .",
    "therefore , moments are given approximately as ,    @xmath19    @xmath20    where @xmath21 is the value of extreme event .",
    "one can easily find from eq .",
    "( [ yaklasms ] ) that @xmath22 and using this expression in eq .",
    "( [ yaklasmk ] ) , the power law relation can be obtained as    @xmath23    the value of @xmath3 is 100 for earthquakes and 250 for financial time series @xcite . at this point ,",
    "the crucial question that should be asked is whether the behaviour remains the same as @xmath3 increases .",
    "our main purpose here is to test the relation between skewness and kurtosis proposed as being universal in @xcite using very large synthetic data sets which are known to be non - gaussian .",
    "the other purpose is to find an answer to the following questions : ( i )   does larger kurtosis value between any two non - gaussian distribution always mean larger deviation from gaussian ?",
    "( ii )  if not , then how can we compare two different non - gaussian distributions and decide which one has larger deviation from gaussian ?",
    "there are different methods in the literature to generate gaussian distributions .",
    "one of the most popular and well known one is the box - muller method @xcite .",
    "on the other hand , there are many complex systems in nature which do not exhibit gaussian distributions . in the literature , there are several examples of experimental , observational and model systems in physics , biology , geophysics , economics etc which exhibit @xmath1-gaussian distributions .",
    "these distributions optimize the nonadditive entropy @xmath24 , which is defined to be @xmath25 and are known to be the basis of nonextensive statistical mechanics @xcite and recovers the standard boltzmann - gibbs entropy as a special case when @xmath26 .    if @xmath27 , @xmath1-gaussian distributions are long tailed non - gaussian distributions similar to those as observed for daily price returns of economics @xcite as well as return distributions of earthquakes @xcite . therefore , they are very good candidates to use in order for achieving our purposes explained above . these distributions are known to have finite ( infinite ) second moments for @xmath28 ( @xmath29 ) .",
    "needless to say , one will need a generalization of the box - muller method from where @xmath1-gaussian distributions can be generated .",
    "this generalization has been performed by thistleton _",
    "et al . _ in 2007 @xcite .",
    "suppose that @xmath30 and @xmath31 are independent random variables chosen from uniform distribution defined on @xmath32 .",
    "it is shown that two random variables @xmath33 and @xmath34 can be defined as    @xmath35    and each of them is a standard @xmath1-gaussian deviate characterized by a new parameter @xmath1 , which is given by @xmath36 . here",
    "@xmath37 is the @xmath1-logarithm and is defined as @xmath38 whose inverse is known as the @xmath1-exponential and is given as    @xmath39^{\\frac{1}{1-q } } , \\qquad1+(1-q)x\\geq0 , \\\\",
    "0,\\qquad\\qquad\\qquad else .",
    "\\end{array}\\right.\\ ] ]    finally , one can define @xmath1-gaussian distribution as @xmath40^{\\frac{1}{1-q}},\\ ] ] where @xmath41 is the @xmath1-mean value , @xmath42 is the @xmath1-variance , @xmath43 is the normalization factor and @xmath44 is a parameter which characterizes the width of the distribution .",
    "these parameters are defined as follows : @xmath45^{q}dx}{\\int[p(x)]^{q}dx } \\label{mq}\\ ] ]    @xmath46^{q}dx}{\\int[p(x)]^{q}dx } \\label{sigmaq}\\ ] ]    @xmath47 } { \\gamma\\left[\\frac{2-q}{1-q}\\right]}\\sqrt{\\frac{1-q}{\\pi } } , \\qquad q<1 ,   \\\\",
    "\\frac{1}{\\sqrt{\\pi } } , \\qquad\\qquad\\qquad q=1 , \\\\      \\frac{\\gamma\\left[\\frac{1}{q-1}\\right]}{\\gamma\\left[\\frac{3-q}{2(q-1)}\\right ] } \\sqrt{\\frac{q-1}{\\pi}},\\qquad 1<q<3 .",
    "\\end{array}\\right.\\ ] ]    @xmath48^{-1 }   \\qquad q\\in ( -\\infty,3).\\ ] ]    using this generalized box - muller method , one can generate arbitrarily large number of data sets for @xmath1-gaussian distributions with any @xmath1 value .",
    "the standard definitions of skewness and kurtosis have already been given in eq .",
    "( [ skewness ] ) and eq .",
    "( [ kurtosis ] ) respectively .",
    "changing the value of @xmath1 in eq.([q gaussian variables ] ) , one can simply generate @xmath1-gaussian distributions for different @xmath1 values as seen in fig .",
    "[ fig : fig1 ] .",
    "therefore , now we have all the necessary ingredients to test the proposed relation between skewness and kurtosis .",
    "we have generated @xmath1-gaussian distributions for various @xmath1 values and divided the datasets to subsamples and calculated skewness and kurtosis values for each subsample window , which is exactly the same procedure used in @xcite . in order to mimic exactly the results given in fig .  2 of @xcite , we take @xmath12 for each window and plot kurtosis as a function of skewness for @xmath1-gaussian distribution with @xmath49 in fig .  [",
    "fig : fig2 ] , where each point refers to a window .",
    "if fig .  2 of @xcite and our fig .",
    "[ fig : fig2 ] are compared , one can easily see that they are almost the same .",
    "if a zoom is made to the region very close to @xmath14 , it is seen that , for this very narrow region , data points obey a power - law relation with exponent 2 . in this regime",
    ", it seems that the distributions obtained from each window are not very far away from gaussian . in fact , even if we generate @xmath1-gaussian distribution , since the number of data points is very small , the tails of the distribution are poorly sampled whereas its central part is sampled highly .",
    "since any @xmath1-gaussian will not differ very much from gaussian at its central part , this explains why we see such a regime where the points are clustered close to @xmath14 and @xmath2 in @xmath50 plane .",
    "since we generate symmetric @xmath1-gaussian distributions , one can easily find points with zero skewness , but kurtosis values are greater than @xmath51 for all points in fig .",
    "[ fig : fig2 ] due to non - gaussianity .",
    "when extreme events happen to appear ( i.e. , data comes from the tails ) and become dominant in any window , the data point corresponding to this window in @xmath50 plane starts to move away from the @xmath14 and @xmath2 regime . as we explained in the introduction ( see eqs .",
    "( [ yaklasms ] ) - ( [ power ] ) ) , if there are sufficiently many extreme events , they dominate all the summation and the relation turns out to be another power - law with exponent @xmath0 .",
    "the dashed black line in fig .  [ fig : fig2 ] represents the power - law relation with exponent 2 ( eq .",
    "( [ parabol ] ) ) and it corresponds to the lower bound of the points in @xmath50 plane . as shown in fig .",
    "[ fig : fig2 ] , the solid blue line ( eq .",
    "( [ power ] ) ) matches quite well with the points away from this region .",
    "thus our synthetic data for @xmath49 mimics exactly the bahavior of the economics data given in @xcite if the same number of data points is used .",
    "now we are at the position to test the behaviour for different values of @xmath3 with the same @xmath1 value and also for different values of @xmath1 with the same @xmath3 in order to understand whether and how @xmath3 and @xmath1 affect the behaviour of the system in the @xmath50 plane .",
    "firstly , as shown in fig .",
    "[ fig : fig3]a , we plot kurtosis versus skewness for different @xmath3 values with the same @xmath1 value ( @xmath49 ) and it is evident that , as @xmath3 increases , kurtosis reaches higher values following the power - law regime with exponent @xmath0 . then , as shown in fig .",
    "[ fig : fig3]b , we plot the same graph , this time , for different @xmath1 values fixing @xmath3 as @xmath12 , where one can easily see that the same power - law behavior is reached for higher kurtosis values as @xmath1 increases . therefore",
    ", increasing the values of @xmath3 and @xmath1 gives the same result although the mechanisms which cause this result are different .",
    "if @xmath1 is increased , this causes the distribution to be much more long - tailed and it is possible to find the extreme events more frequently and this of course gives the same result as increasing @xmath3 , since , if you increase @xmath3 for a given @xmath1 , the possibility of finding extreme events will also increase regardless of the value of @xmath1 . as seen in fig .",
    "[ fig : fig2 ] and fig .",
    "[ fig : fig3]a , although all data in each window is selected from the same distribution ( each window is a part of the same data set ) , some windows which have frequently more data from the tails have larger kurtosis values .",
    "this result does not necessarily indicate that the distribution with larger kurtosis value is more long tailed and therefore much more far away from the gaussian .",
    "it only indicates that the contribution of tails in the summation for corresponding data set ( window ) is more than the other window .",
    "moreover , let us suppose two distributions with different @xmath1 values .",
    "if one wants to compare these distributions , exactly opposite results for different @xmath3 values can be deduced .",
    "of course , the distribution with larger @xmath1 exhibits more long - tailed distribution .",
    "therefore , normally one expects that the distribution with larger @xmath1 value has a larger kurtosis .",
    "but , since extreme events are randomly distributed in the whole data set , there is no guarantee for a good representation of the tails for any given window in this considered data set .",
    "sometimes , especially for small @xmath3 values , almost all data might come from the central part of the distribution . in fig .",
    "[ fig : fig3]b , each point represents a kurtosis and a skewness value of one window which has @xmath12 . as seen in this figure",
    ", one can find several points in the power - law region with exponent @xmath0 of the distribution for @xmath49 , whose kurtosis values are larger than all points of the power - law region with exponent 2 of the distribution for @xmath52 .",
    "as a result , if one has these two different data sets which correspond to aforementioned windows , his / her conclusion would be that the distribution with @xmath52 is closer to the gaussian than the distribution with @xmath49 .",
    "but clearly this will be an incorrect conclusion .",
    "it only indicates that the distributions are not sampled sufficiently well in order for characterizing them correctly .",
    "this problem can only be overcome by using sufficiently large @xmath3 .",
    "it is also worth mentioning that in fig .",
    "[ fig : fig3 ] the minimum of the power - law region with exponent 2 slowly increases as @xmath3 is increased for a given @xmath1 value or as the @xmath1 value of the distribution is increased for a given @xmath3 value .",
    "the next step at this point must be to check whether the kurtosis approaches a finite value for any finite @xmath3 .",
    "therefore , we plot kurtosis as a function of @xmath3 for different @xmath1-gaussians .",
    "the results of two representative cases are given in fig .",
    "[ fig : fig4 ] .",
    "it is clearly seen that the kurtosis approaches a fixed value as @xmath3 is moderately large for @xmath53 case , whereas the kurtosis does not saturate even for very large @xmath3 values like @xmath54 for @xmath52 case .",
    "we systematically checked several @xmath1-gaussian distributions with @xmath55 $ ] and observed that the kurtosis steadily increases with increasing @xmath3 and then it achieves a constant value .",
    "this value of @xmath3 at which @xmath7 saturates and also the value to which @xmath7 saturates increase with increasing @xmath1 as the distribution gets more and more distant from the gaussian .    at this point",
    ", we conjecture that the kurtosis will always reach a constant value for sufficiently large @xmath3 if @xmath56 , where the distribution has always a finite second moment .",
    "in fact , as seen in fig .  [",
    "fig : fig4]b for @xmath52 case , for larger @xmath1 values ( namely , @xmath29 ) , where the distribution exhibits infinite second moment , the @xmath3 values needed for constant kurtosis are postponed to very large values , most probably almost impossible to reach .",
    "after these findings , the plausible conclusion is that one can only compare two @xmath1-gaussian distributions using the constant values of kurtosis if @xmath28 .",
    "if the constant value of kurtosis is not obtained for a given distribution with @xmath57 $ ] or if the distribution is from the region @xmath58 $ ] , then this comparison can not be done .",
    "another question which needs to be answered is whether these two different power - law regimes are still valid for large @xmath3 for a @xmath1-gaussian with @xmath28 .",
    "to clarify this situation we plot again kurtosis as a function of skewness for @xmath59 and @xmath60 in fig .",
    "[ fig : fig5 ] .",
    "the @xmath1 is chosen as @xmath61 in order to reach the saturation of the kurtosis at an attainable @xmath3 . as seen from fig .",
    "[ fig : fig5]a , for small @xmath3 case , two regimes are still valid since the kurtosis has not yet saturated to a constant value . on the other hand , in fig .",
    "[ fig : fig5]b , for large @xmath3 case , all points in the @xmath50 plane seem to converge to a single point and both regimes seem to disappear .",
    "one might only argue that the power - law relation with exponent 2 is valid as a lower bound .",
    "symmetric @xmath62-stable levy distributions , @xmath63 , can be defined through its fourier transform @xcite    @xmath64    where @xmath62 is the levy parameter in the interval @xmath65 .",
    "the case @xmath66 corresponds to the standard gaussian . performing the inverse fourier transform",
    ", one can evaluate the levy distributions as    @xmath67    these distributions are known to exhibit infinite second moments for @xmath68 .    in order to generate @xmath62-stable levy distributions we use the matlab functions stbl given by m. veillette @xcite .",
    "for some representative @xmath62 values , levy distributions are plotted in fig .",
    "[ fig : fig6 ] . using this function",
    "one can generate arbitrarily large number of @xmath62-stable distributions which can be used in the same way that we have already done for @xmath1-gaussians .          for @xmath62-stable levy distributions ,",
    "we firstly analyze the kurtosis versus skewness behavior for small @xmath3 ( namely , @xmath12 ) in fig .",
    "[ fig : fig7 ] .",
    "the similar tendency observed also for @xmath1-gaussians is clearly evident .",
    "the power - law region with exponent 2 is followed only for a very short interval near @xmath14 , whereas the other power - law region with exponent @xmath0 is realized for the values away from @xmath14 .",
    "finally , we should check the behavior of kurtosis as a function of @xmath3 . from what we understand in the @xmath1-gaussian discussion",
    ", we must expect that , for all levy distributions with @xmath69 , kurtosis values will never reach a constant value since the second moments of these distributions are always infinite . in order to see this better",
    ", we present in fig .",
    "[ fig : fig8 ] two representative cases for one of which we plot the results of distributions very close to gaussian ( see fig .",
    "[ fig : fig8]a ) and the other is with the results of distributions far away from gaussian ( see fig .  [",
    "fig : fig8]b ) . for both cases ,",
    "it is evident that the only constant kurtosis value ( @xmath2 ) happens to be seen for @xmath66 which is the gaussian .",
    "it seems that , even if the distribution is very close to gaussian , kurtosis will never attain a constant value for a finite @xmath3 .",
    "we check the relation between skewness and kurtosis in complex dynamics proposed in @xcite using synthetic large data sets for non - gaussian distributions , namely , @xmath1-gaussian and levy distributions .",
    "our results clearly show that the relation , proposed as being universal , happens to occur only due to insufficient number of data points used in the analysis if the second moment of the distribution is finite .",
    "this is just because the original distribution is not sampled sufficiently well for small @xmath3 values .",
    "we also verify that , as @xmath3 increases , the kurtosis value also increases up to some value of @xmath3 after which it remains constant .",
    "this @xmath3 value is postponed to larger values as the non - gaussian distribution under consideration becomes more and more distant from gaussian .",
    "if the second moment of the distribution is infinite , then this @xmath3 value seems to diverge . in the light of these findings , we conclude that using kurtosis to compare two different distributions ( data sets ) might lead incorrect results if the data sets in hand are not sufficiently large for distributions with finite second moment . to do this comparison correctly",
    ", one needs to be sure about the length of the data set which allows kurtosis to become a constant .",
    "if this is not guaranteed , then one might easily misinterpret a longer tailed distribution to be much closer to gaussian compared to a shorter tailed one . on the other hand , if the distribution has infinite second moment like @xmath1-gaussians with @xmath29 and all levy distributions with @xmath69 , then it is completely irrelevant to compare these distributions using kurtosis .",
    "pearson has introduced kurtosis of a given distribution as a measure of deviation from gaussian while he was trying to understand whether a distribution was gaussian or not .",
    "most probably it will be useful to replace the reference distribution ( gaussian ) by a different one ( non - gaussian ) , which is much closer to the distribution under consideration .",
    "we are planning to discuss this issue elsewhere in the near future .",
    "we are indebted to ayse erzan for very fruitful discussions and useful remarks .",
    "this work has been supported by tubitak ( turkish agency ) under the research project number 112t083 .",
    "u.t . is a member of the science academy , istanbul , turkey ."
  ],
  "abstract_text": [
    "<S> in a recent paper [ _ m . </S>",
    "<S> cristelli , a. zaccaria and l. pietronero , phys . </S>",
    "<S> rev . </S>",
    "<S> e 85 , 066108 ( 2012 ) _ ] , cristelli _ et al . </S>",
    "<S> _ analysed relation between skewness and kurtosis for complex dynamical systems and identified two power - law regimes of non - gaussianity , one of which scales with an exponent of 2 and the other is with @xmath0 . </S>",
    "<S> finally the authors concluded that the observed relation is a universal fact in complex dynamical systems . </S>",
    "<S> here , we test the proposed universal relation between skewness and kurtosis with large number of synthetic data and show that in fact it is not universal and originates only due to the small number of data points in the data sets considered . </S>",
    "<S> the proposed relation is tested using two different non - gaussian distributions , namely @xmath1-gaussian and levy distributions . </S>",
    "<S> we clearly show that this relation disappears for sufficiently large data sets provided that the second moment of the distribution is finite . </S>",
    "<S> we find that , contrary to the claims of cristelli _ et al . _ regarding a power - law scaling regime , kurtosis saturates to a single value , which is of course different from the gaussian case ( @xmath2 ) , as the number of data is increased . on the other hand </S>",
    "<S> , if the second moment of the distribution is infinite , then the kurtosis seems to never converge to a single value . </S>",
    "<S> the converged kurtosis value for the finite second moment distributions and the number of data points needed to reach this value depend on the deviation of the original distribution from the gaussian case . </S>",
    "<S> we also argue that the use of kurtosis to compare distributions to decide which one deviates from the gaussian more can lead to incorrect results even for finite second moment distributions for small data sets , whereas it is totally misleading for infinite second moment distributions where the difference depends on @xmath3 for all finite @xmath3 . </S>"
  ]
}