{
  "article_text": [
    "the equality constrained linear least squares problem can be stated as follows : @xmath0 where @xmath1 and @xmath2 with @xmath3 , @xmath4 and @xmath5 .",
    "hereafter , the symbols @xmath6 and @xmath7 stand for the set of @xmath8 real matrices and the real vector space of dimension @xmath9 , respectively . to ensure that the lse problem has a unique solution",
    ", we need to assume that @xcite @xmath10 the first condition in implies that the linear system @xmath11 is consistent and hence that the lse problem has a solution , and vice versa ; the second one , which says that the matrix @xmath12^{t}$ ] is full column rank , guarantees that there is a unique solution to , and vice versa . here , for a matrix @xmath13 , @xmath14 denotes its transpose . throughout this paper , we assume that the conditions in always hold . in this case , the unique solution to the lse problem can be written as @xcite @xmath15 where @xmath16 with @xmath17 being the identity matrix of order @xmath9 and @xmath18 being the moore - penrose inverse of @xmath19 . when @xmath20 , i.e. , @xmath21 and @xmath22 , the lse problem reduces the classic linear least squares ( lls ) problem @xmath23 the conditions in reduce to @xmath24 being full column rank which ensures that the solution to is unique , and the solution reduces to @xmath25 .",
    "the lse problem finds many important applications in some areas .",
    "for example , we will encounter it in the analysis of large scale structures , in signal processing , and in solving inequality constrained least squares problem @xcite .",
    "so , some scholars considered its algorithms and perturbation analysis ( see e.g. , @xcite ) .",
    "an upper bound for the normwise condition number of the lse problem was presented in @xcite , and the mixed and componentwise condition numbers and their easily computable upper bounds of this problem can be derived from @xcite as the special case .    in this paper , we mainly consider the partial condition number of the lse problem when the data space @xmath26 and the solution space @xmath7 are measured by the weighted frobenius norm @xmath27 with @xmath28 , and @xmath29 , and the euclidean norm @xmath30 , respectively . as mentioned in abstract ,",
    "the partial condition number which is also called the subspace condition number @xcite is referred to the condition number of a linear function of the lse solution @xmath31 , i.e. , @xmath32 with @xmath33 ( @xmath34 ) .",
    "this kind of condition number has some advantages .",
    "for example , when @xmath35 is the identity matrix or a column vector of the identity matrix , the partial condition number will reduce to the condition number of the solution @xmath31 or of an element of the solution .",
    "cao and petzold first proposed the partial condition number for linear systems @xcite .",
    "later , it was proposed for lls problem and total least squares problem @xcite . in @xcite",
    ", the authors also provided some specific motivations for investigating this kind of condition number .",
    "the idea on the weighted frobenius norm can be traced back to gratton @xcite , who derived the normwise condition number for the lls problem based on the following weighted frobenius norm @xmath36 subsequently , this kind of norm was used for the partial condition number for the lls problem @xcite and the normwise condition number of the truncated singular value solution of a linear ill - posed problem @xcite .",
    "as pointed out in @xcite , this norm is very flexible . with it",
    ", we can monitor the perturbations on @xmath37 and @xmath38 .",
    "for example , if @xmath39 , no perturbation on @xmath37 will be permitted ; similarly , if @xmath40 , there will be no perturbation on @xmath38 allowed .",
    "obviously , the norm in is a simple generalization of the one in , and is also very flexible .",
    "there is another kind of generalization of the norm in : @xmath41 , which was used by wei et al . in @xcite for the normwise condition number of rank deficient lls problem . here",
    ", @xmath42 is a positive diagonal matrix .    like the structured linear systems and the structured lls problem",
    ", the structured lse problem arises in many applications , e.g. , in signal processing and the area of optimization @xcite .",
    "rump @xcite presented the perturbation theory for the structured linear systems with respect to normwise distances and componentwise distances .",
    "the obtained results generalized the corresponding ones in @xcite . for the structured lls problems , xu et al .",
    "@xcite considered their structured normwise condition numbers , and cucker and diao @xcite presented their structured mixed and componentwise condition numbers .",
    "in addition , the structured condition numbers for the total least squares problem were provided by li and jia in @xcite .",
    "the results in @xcite show that the structured condition number can be much tighter than the unstructured one .",
    "so , based on the study on the partial condition number , we also investigate the structured partial condition number of the structured lse problem .",
    "the rest of this paper is organized as follows .",
    "section 2 presents the expression and closed formulae of the partial condition number for the lse problem .",
    "the expression of the corresponding structured partial condition number is given in section 3 .",
    "on basis of the probabilistic spectral norm estimator by hochstenbach @xcite and the small - sample statistical condition estimation ( ssce ) method by kenney and laub @xcite , section 4 is devoted to the statistical estimates and algorithms of the results derived in sections 2 and 3 .",
    "the numerical experiments for illustrating the obtained results are provided in section 5 . before moving to the following sections , we first introduce some results on the operator vec and kronecker product , and the generalized singular value decomposition ( svd ) of a matrix pair .",
    "they will be necessary later in this paper .    for a matrix @xmath43\\in \\mathbb{r}^{m\\times n}$ ] with @xmath44 , the operator vec is defined as follows @xmath45^{t}\\in \\mathbb{r}^{mn}.\\ ] ] let @xmath46 and @xmath47 . the _ kronecker product _ between @xmath37 and @xmath19",
    "is defined by ( see , e.g. , ( * ? ? ?",
    "* chapter 4 ) ) @xmath48\\in { \\mathbb{r}^{mp \\times nq}}.\\ ] ] this definition implies that when @xmath49 and @xmath50 , i.e , when @xmath37 is a row vector and @xmath19 is a column vector , @xmath51 from ( * ? ? ?",
    "* chapter 4 ) , we have @xmath52 where @xmath53 , and @xmath54 is the _ vec - permutation matrix _ depending only on the orders @xmath55 and @xmath9 .",
    "especially , when @xmath56 , i.e. , @xmath37 is a column vector , then @xmath57 and hence @xmath58 in addition , the following result is also from ( * ? ? ?",
    "* chapter 4 ) @xmath59 where the matrices @xmath13 and @xmath60 are of suitable orders .    for the matrix pair @xmath61 in and , there exist orthogonal matrices @xmath62 and @xmath63 , and a nonsingular matrix @xmath64 such that @xmath65 where @xmath66 = \\left [ { \\begin{array}{*{20}c }     { i_{n - s } } & 0 & 0   \\\\     0 & { s_a } & 0   \\\\     0 & 0 & 0   \\\\ \\end{array } } \\right],\\quad \\lambda   = \\left [ { \\begin{array}{*{20}c }     0 & { \\lambda _ 1 }   \\\\ \\end{array } } \\right ] = \\left [ { \\begin{array}{*{20}c }     0 & { s_b } & { }   \\\\     0 & { } & { i_{s - t } }   \\\\ \\end{array } } \\right]\\ ] ] with @xmath67 and @xmath68 .",
    "this decomposition is called the generalized svd of a matrix pair ( see e.g. , @xcite , @xcite ) .",
    "when @xmath21 , the generalized svd can reduce to the svd of @xmath37 : @xmath69 where @xmath70 is orthogonal and @xmath71 with @xmath72 being the @xmath73-th singular value of @xmath37 .",
    "let @xmath74 with @xmath34 .",
    "we consider the following function @xmath75 from @xcite , it can be seen that the function @xmath76 is continuously frchet differentiable in a neighborhood of @xmath77 .",
    "thus , denoting by @xmath78 the frchet derivative of @xmath76 , and using the chain rules of composition of derivatives or from @xcite , we have @xmath79 here , @xmath80 denotes that we apply the linear function @xmath81 to the perturbation variable @xmath82 at the point @xmath77 and @xmath83 is called the residual vector .",
    "thus , according to @xcite , we have the absolute normwise condition number of @xmath76 at the point @xmath77 based on the weighted frobenius norm : @xmath84 as mentioned in section 1 , the condition number @xmath85 is called the partial condition number of the lse problem with respect to @xmath35 .    in the following ,",
    "we provide an expression of @xmath85 .",
    "the partial condition number of the lse problem with respect to @xmath35 is @xmath86 where @xmath87\\end{aligned}\\ ] ] with @xmath88    _",
    "proof_. applying the operator vec to @xmath89 and using and , we have @xmath90.\\end{aligned}\\ ] ] thus , considering and the fact that for any matrix @xmath13 , @xmath91 , @xmath92 } \\right\\|_2 } } { { \\left\\| { \\left [ { \\begin{array}{*{20}c }     { \\alpha_a { \\rm vec}(\\delta a ) }   \\\\     { \\alpha_b { \\rm vec}(\\delta b ) }   \\\\     { \\alpha_b ( \\delta b ) }   \\\\     { \\alpha_d ( \\delta d ) }   \\\\ \\end{array } } \\right ] } \\right\\|_2 } } = \\left\\| { m_{g ' } } \\right\\|_2.\\end{aligned}\\ ] ] @xmath93     setting @xmath94 and @xmath95 in , and using the property on the spectral norm that for the matrices @xmath13 and @xmath60 of suitable orders , @xmath96\\right\\|_2\\leq\\left\\|c\\right\\|_2+\\left\\|d\\right\\|_2 $ ] , we have @xmath97 which is essentially the same as the upper bound for the normwise condition number of the lse problem obtained in @xcite .",
    "note that the expression of the partial condition number @xmath85 given in theorem 2.1 contains kronecker product .",
    "this introduces some large sparse matrices .",
    "the following theorem provides a closed formula of @xmath85 without kronecker product .    a closed formula of the partial condition number @xmath85 is given by @xmath98 where @xmath99    _ proof_. noting @xmath100 and @xmath101 it suffices to obtain the expressions of @xmath102 and @xmath103 .",
    "let @xmath104 then @xmath105 by and , we have @xmath106 note that @xmath107 the last equality in the above equation follows from the generalized svd of the matrix pair @xmath108 in and the expressions on @xmath109 and @xmath110 in remark [ rmk2.2 ] below .",
    "in fact , @xmath111 x^{-1},\\quad ( ap)^{\\dag }   a = x\\left [ { \\begin{array}{*{20}c }     { i_{n - s } } & 0 & 0   \\\\     0 & 0 & 0   \\\\     0 & 0 & 0   \\\\ \\end{array } } \\right]\\sigma x^{-1}=x\\left [ { \\begin{array}{*{20}c }     i_{n - s } & 0    \\\\     0 & 0    \\\\",
    "\\end{array } } \\right ] x^{-1 } , \\end{aligned}\\ ] ] which mean that @xmath112 and hence @xmath113 .",
    "thus , by , , and , @xmath114 as a result , @xmath115    now , let @xmath116 then @xmath117 by and , we get @xmath118 and by , , , and , we get @xmath119 substituting  into gives @xmath120 from , , and , we have the desired result .",
    "@xmath93    when @xmath21 and @xmath22 , that is , when the lse problem reduces to the lls problem , @xmath121 and @xmath122 .",
    "thus , @xmath123 and hence @xmath124 which is the closed formula of the partial condition number of the lls problem .    furthermore , if @xmath35 is a column vector , i.e. , @xmath125 , then @xmath126 which is just the result given in corollary 1 in @xcite .    [ rmk2.2 ]    using the generalized svd of the matrix pair @xmath108 in , and ( 3.3 ) , ( 3.4 ) , and ( 3.15 ) in @xcite , we have @xmath127\\left ( { i_n   - \\left [ { \\begin{array}{*{20}c }     0 & 0   \\\\     { s_b^ { - 1 } } & 0   \\\\     0 & { i_{s - t } }   \\\\ \\end{array } } \\right]\\left [ { \\begin{array}{*{20}c }     0 & { s_b } & 0   \\\\     0 & 0 & { i_{s - t } }   \\\\ \\end{array } } \\right ] } \\right ) } \\right)^{\\dag }   u^{t } \\nonumber \\\\    & = & x\\left ( { \\left [ { \\begin{array}{*{20}c }     { i_{n - s } } & 0 & 0   \\\\     0 & { s_a } & 0   \\\\     0 & 0 & 0   \\\\ \\end{array } } \\right]\\left [ { \\begin{array}{*{20}c }     { i_{n - s } } & 0 & 0   \\\\     0 & 0 & 0   \\\\     0 & 0 & 0   \\\\ \\end{array } } \\right ] } \\right)^{\\dag }   u^{t }   = x\\left [ { \\begin{array}{*{20}c }     { i_{n - s } } & 0 & 0   \\\\     0 & 0 & 0   \\\\     0 & 0 & 0   \\\\ \\end{array } } \\right]u^{t}\\end{aligned}\\ ] ] and @xmath128u^{t } u\\left [ { \\begin{array}{*{20}c }     { i_{n - s } } & 0 & 0   \\\\     0 & { s_a } & 0   \\\\",
    "0 & 0 & 0   \\\\",
    "\\end{array } } \\right]x^ { - 1 } } \\right)x\\lambda ^{\\dag }   v^{t } \\nonumber \\\\    & = &   x\\left [ { \\begin{array}{*{20}c }     0 & 0 & 0   \\\\     0 & { i_t } & 0   \\\\     0 & 0 & { i_{s - t } }   \\\\ \\end{array } } \\right]\\left [ { \\begin{array}{*{20}c }     0 & 0   \\\\     { s_b^ { - 1 } } & 0   \\\\     0 & { i_{s - t } }   \\\\ \\end{array } } \\right]v^{t }   = x\\left [ { \\begin{array}{*{20}c }     0 & 0   \\\\     { s_b^ { - 1 } } & 0   \\\\     0 & { i_{s - t } }   \\\\ \\end{array } } \\right]v^{t }   = x\\lambda ^{\\dag }   v^{t}.\\end{aligned}\\ ] ] then @xmath129v^{t}=u_2\\left [ { \\begin{array}{*{20}c }     { s_as_b^ { - 1 } } & 0   \\\\     0 & 0   \\\\ \\end{array } } \\right]v^{t},\\label{2.14}\\\\ & b_a^{\\dag }   ( b_a^{\\dag }   ) ^{t }   = x\\left [ { \\begin{array}{*{20}c }     0 & 0 & 0   \\\\     0 & { s_b^ { - 2 } } & 0   \\\\     0 & 0 & { i_{s - t } }   \\\\ \\end{array } } \\right]x^{t}=x_2\\left [ { \\begin{array}{*{20}c }       { s_b^ { - 2 } } & 0   \\\\      0 & { i_{s - t } }   \\\\ \\end{array } } \\right]x^{t}_2 , \\label{2.15}\\\\ & ab_a^{\\dag }   ( b_a^{\\dag }   ) ^{t }    = u\\left [ { \\begin{array}{*{20}c }     0 & 0 & 0   \\\\     0 & { s_a s_b^ { - 2 } } & 0   \\\\     0 & 0 & 0   \\\\",
    "\\end{array } } \\right]x^{t}= u_2\\left [ { \\begin{array}{*{20}c }     { s_a s_b^ { - 2 } } & 0   \\\\     0 & 0   \\\\ \\end{array } } \\right]x^{t}_2,\\label{2.16}\\end{aligned}\\ ] ] where @xmath130 $ ] with @xmath131 and @xmath132 , and @xmath133 $ ] with @xmath134 and @xmath135 . substituting  into yields @xmath136 } \\right\\|_2 ^ 2 } } { { \\alpha _ b^2 } } } \\right)l^{t } ( x_1x_1^{t})^2 l + l^{t } ( x_1s_1x_1^{t}+x_2s_2x_2^{t } ) l   \\nonumber \\\\ & \\quad    + \\frac{1}{{\\alpha _ b^2 } } l^{t } x_1x^{t}_1 xr^{t } u_2\\left [ { \\begin{array}{*{20}c }     { s_a s_b^ { - 2 } } & 0   \\\\     0 & 0",
    "\\\\ \\end{array } } \\right]x^{t}_2 l + \\frac{1}{{\\alpha _ b^2 } } l^{t } x_2\\left [ { \\begin{array}{*{20}c }     { s_a s_b^ { - 2 } } & 0   \\\\     0 & 0",
    "\\\\ \\end{array } } \\right]u^{t}_2 rx^{t } x_1x^{t}_1 l\\label{2.17}\\end{aligned}\\ ] ] with @xmath137    in particular , when @xmath21 , the generalized svd reduces to the svd of @xmath37 . in this case ,",
    "@xmath121 and @xmath122 .",
    "hence , we have @xmath138   u^{t},\\quad b_a^{\\dag }    = 0,\\ ] ] and @xmath139 thus , @xmath140 as a result , we get a closed formula of the partial condition number of the lls problem based on the svd of @xmath37 : @xmath141 where @xmath142 is a diagonal matrix with the @xmath73-th diagonal element being @xmath143 the closed formula is just the one given in theorem 1 in @xcite , where it was derived by a different approach .",
    "suppose that @xmath144 and @xmath145 are two linear subspaces , which consist of two classes of structured matrices , respectively . from @xcite",
    ", we have that if @xmath146 and @xmath147 , then @xmath148 where @xmath149 and @xmath150 are the fixed structure matrices reflecting the structures of @xmath151 and @xmath152 , respectively , and @xmath153 and @xmath154 are the vectors of the independent parameters in the structured matrices , respectively .",
    "based on the above explanation , the structured perturbations @xmath155 and @xmath156 can be written as @xmath157 where @xmath158 and @xmath159 can be regarded as the perturbations of @xmath160 and @xmath161 , respectively .",
    "now we present the definition of the structured partial condition number of the lse problem : @xmath162 which is a natural variant of the partial condition number in . from",
    ", it follows that @xmath163 } \\right\\|_2 } } { { \\left\\| { \\left [ { \\begin{array}{*{20}c }     { \\alpha_a { \\rm vec}(\\delta a ) }   \\\\     { \\alpha_b { \\rm vec}(\\delta b ) }   \\\\     { \\alpha_b ( \\delta b ) }   \\\\     { \\alpha_d ( \\delta d ) }   \\\\ \\end{array } } \\right ] } \\right\\|_2 } } .\\end{aligned}\\ ] ] considering , we have @xmath164=\\left [ { \\begin{array}{*{20}c }     \\phi_{\\mathbb{s}_1 } & 0 & 0&0 \\\\",
    "0&\\phi_{\\mathbb{s}_2}&0&0   \\\\     0&0 & i_m&0\\\\     0&0&0&i_s\\\\ \\end{array } } \\right]\\left [ { \\begin{array}{*{20}c }     \\delta s _ 1 \\\\",
    "\\delta s_2 \\\\      { \\delta b }   \\\\       { \\delta d }   \\\\ \\end{array } } \\right].\\end{aligned}\\ ] ] substituting the above equation into yields @xmath165\\left [ { \\begin{array}{*{20}c }     { \\alpha_a ( \\delta s_1 ) }   \\\\     { \\alpha_b ( \\delta s_2 ) }   \\\\     { \\alpha_b ( \\delta b ) }   \\\\     { \\alpha_d ( \\delta d ) }   \\\\ \\end{array } } \\right ] } \\right\\|_2 } } { { \\left\\| { \\left [ { \\begin{array}{*{20}c }     \\phi_{\\mathbb{s}_1 } & 0 & 0&0 \\\\     0&\\phi_{\\mathbb{s}_2}&0&0   \\\\     0&0 & i_m&0\\\\     0&0&0&i_s\\\\ \\end{array } } \\right]\\left [ { \\begin{array}{*{20}c }     { \\alpha_a ( \\delta s_1 ) }   \\\\     { \\alpha_b ( \\delta s_2 ) }   \\\\     { \\alpha_b ( \\delta b ) }   \\\\     { \\alpha_d ( \\delta d ) }   \\\\ \\end{array } } \\right ] } \\right\\|_2 } } .\\end{aligned}\\ ] ] note that @xmath166\\left [ { \\begin{array}{*{20}c }     { \\alpha_a ( \\delta s_1 ) }   \\\\     { \\alpha_b ( \\delta s_2 ) }   \\\\     { \\alpha_b ( \\delta b ) }   \\\\     { \\alpha_d ( \\delta d ) }   \\\\ \\end{array } } \\right ] } \\right\\|_2 } } = \\left\\|\\left [ { \\begin{array}{*{20}c }     { \\alpha_a ( \\delta s_1 ) }   \\\\     { \\alpha_b ( \\delta s_2 ) }   \\\\     { \\alpha_b ( \\delta b ) }   \\\\     { \\alpha_d ( \\delta d ) }   \\\\ \\end{array } } \\right]^{t } { \\left [ { \\begin{array}{*{20}c }     \\phi_{\\mathbb{s}_1}^{t}\\phi_{\\mathbb{s}_1 } & 0 & 0&0 \\\\     0&\\phi_{\\mathbb{s}_2}^{t}\\phi_{\\mathbb{s}_2 } & 0&0 \\\\     0&0 & i_m&0\\\\     0&0&0&i_s\\\\ \\end{array } } \\right]\\left [ { \\begin{array}{*{20}c }     { \\alpha_a ( \\delta s_1 ) }   \\\\     { \\alpha_b ( \\delta s_2 ) }   \\\\     { \\alpha_b ( \\delta b ) }   \\\\     { \\alpha_d ( \\delta d ) }   \\\\ \\end{array } } \\right ] } \\right\\|_2^{1/2}\\end{aligned}\\ ] ] and the structured matrices @xmath167 and @xmath168 are column orthogonal @xcite .",
    "then @xmath169\\left [ { \\begin{array}{*{20}c }     { \\alpha_a ( \\delta s_1 ) }   \\\\     { \\alpha_b ( \\delta s_2 ) }   \\\\     { \\alpha_b ( \\delta b ) }   \\\\     { \\alpha_d ( \\delta d ) }   \\\\ \\end{array } } \\right ] } \\right\\|_2 } } = \\left\\| { \\left [ { \\begin{array}{*{20}c }     d_1 & 0 & 0&0 \\\\     0&d_2&0&0   \\\\     0&0 & i_m&0\\\\     0&0&0&i_s\\\\ \\end{array } } \\right]\\left [ { \\begin{array}{*{20}c }     { \\alpha_a ( \\delta s_1 ) }   \\\\     { \\alpha_b ( \\delta s_2 ) }   \\\\     { \\alpha_b ( \\delta b ) }   \\\\     { \\alpha_d ( \\delta d ) }   \\\\ \\end{array } } \\right ] } \\right\\|_2,\\end{aligned}\\ ] ] where @xmath170 and @xmath171 with @xmath172,\\quad w_2=\\left[\\left\\|\\phi_{\\mathbb{s}_2}(1,:)\\right\\|_2,\\cdots,\\left\\|\\phi_{\\mathbb{s}_2}(k_2,:)\\right\\|_2\\right].\\end{aligned}\\ ] ] here , the matlab notation is used .",
    "combining and implies @xmath173\\left [ { \\begin{array}{*{20}c }     d_1 & 0 & 0&0 \\\\     0&d_2&0&0   \\\\     0&0 & i_m&0\\\\     0&0&0&i_s\\\\ \\end{array } } \\right]\\left [ { \\begin{array}{*{20}c }     { \\alpha_a ( \\delta s_1 ) }   \\\\     { \\alpha_b ( \\delta s_2 ) }   \\\\     { \\alpha_b ( \\delta b ) }   \\\\     { \\alpha_d ( \\delta d ) }   \\\\ \\end{array } } \\right ] } \\right\\|_2 } } { { \\left\\| { \\left [ { \\begin{array}{*{20}c }     d_1 & 0 & 0&0 \\\\     0&d_2&0&0   \\\\     0&0 & i_m&0\\\\     0&0&0&i_s\\\\ \\end{array } } \\right]\\left [ { \\begin{array}{*{20}c }     { \\alpha_a ( \\delta s_1 ) }   \\\\     { \\alpha_b ( \\delta s_2 ) }   \\\\     { \\alpha_b ( \\delta b ) }   \\\\     { \\alpha_d ( \\delta d ) }   \\\\ \\end{array } } \\right ] } \\right\\|_2 } } .\\end{aligned}\\ ] ] then we can derive the expression of the structured partial condition number of the lse problem , which is presented in the following theorem .    the structured partial condition number of the lse problem with respect to @xmath35 and the structures @xmath151 and @xmath152 is @xmath174\\right\\|_2 , \\end{aligned}\\ ] ] where @xmath175 is given in",
    ".    [ rmk3.2 ] it is easy to verify that @xmath176\\ ] ] is column orthonormal .",
    "thus , @xmath177\\right\\|_2\\leq \\left\\| { m_{g ' } } \\right\\|_2.\\ ] ] that is , the structured partial condition number is always tighter than the unstructured one .",
    "this fact can also be seen from the definitions of these two condition numbers . as done in @xcite , it is valuable to discuss the ratio between the structured and unstructured partial condition numbers of the lse problem in detail .",
    "we wo nt go that far in this paper , and only provide a numerical example in section 5 to show that the structured partial condition number is indeed tighter than the unstructured one .",
    "when @xmath21 and @xmath22 , we have the structured partial condition number of the lls problem and its upper bound : @xmath178\\right\\|_2 \\label{3.7}\\\\ & \\leq&\\left\\|\\left [ { \\frac{{\\left ( { r^{t }   \\otimes ( l^{t } ( a^{t}a)^ { - 1 } ) } \\right)\\pi _ { mn }   - x^{t }   \\otimes ( l^{t } a^ { \\dag})}}{\\alpha_a } , \\frac{{l^{t } a^ { \\dag } } } { \\alpha_b } }   \\right]\\right\\|_2 , \\label{3.8}\\end{aligned}\\ ] ] where the upper bound is just the unstructured partial condition number of the lls problem . here , it should be pointed out that the structured condition number of the lls problem derived from by setting @xmath94 and @xmath179 is a little different from the ones in @xcite because two additional conditions are added besides the structure requirement in @xcite .",
    "we only consider the linear structures of the matrices @xmath37 and @xmath19 in this section .",
    "similarly , the linear structures of the vectors @xmath38 and @xmath180 can also be put into the partial condition number .",
    "furthermore , inspired by @xcite , exploring the structured mixed and componentwise condition numbers of the lse problem will be interesting .",
    "we will investigate this problem in the future research .",
    "we first provide a statistical estimate of the partial condition number by using the probabilistic spectral norm estimator .",
    "this estimator was proposed by hochstenbach @xcite and can estimate the spectral norm of a matrix reliably . in more detail , the analysis of the estimator in @xcite suggests that the spectral norm of a matrix can be contained in a small interval @xmath181 $ ] with high probability , where @xmath182 is the guaranteed lower bound of the spectral norm of the matrix derived by the famous lanczos bibdiagonalization method @xcite and @xmath183 is the probabilistic upper bound with probability at least @xmath184 with @xmath185 derived by finding the largest zero of a polynomial .",
    "meanwhile , we can require @xmath186 with @xmath187 being a user - chosen parameter .",
    "based on the above estimator , we can devise algorithm [ algorithmpce ] .    1 .",
    "generate a starting vector @xmath188 from @xmath189 with @xmath190 .",
    "hereafter , @xmath189 denotes the uniform distribution over unit sphere @xmath191 in @xmath192 .",
    "2 .   compute the guaranteed lower bound @xmath182 and the probabilistic upper bound @xmath183 of @xmath193 by probabilistic spectral norm estimator , where @xmath13 is given in or .",
    "3 .   estimate the partial condition number by @xmath194     in the practical implementation of algorithm [ algorithmpce ] , explicitly forming matrix @xmath13 is not necessary because what we really need is the product of a random vector with the matrix @xmath13 or @xmath195 .",
    "hence , some techniques in solving linear system can be employed to reduce the computational burden .",
    "furthermore , it is worthy to point out that algorithm [ algorithmpce ] is also applicable to estimating the partial structured condition number since it is also the spectral norm of a matrix",
    ".    now we introduce an alternative approach based on the ssce method @xcite for estimating the normwise condition number of the solution @xmath31 .",
    "denote by @xmath196 the normwise condition number of the function @xmath197 , where @xmath198s are chosen from @xmath199 and are orthogonal .",
    "then , from , we have @xmath200 the analysis based on ssce method in @xcite shows that @xmath201 is a good estimate of the normwise condition number of the lse problem . in the above expression",
    ", @xmath202 is the wallis factor with @xmath203 , @xmath204 , and @xmath205 it can be approximated by @xmath206 with high accuracy . in summary , we can propose algorithm [ algorithmssce ] .    1 .",
    "generate @xmath207 vectors @xmath208 from @xmath199 , and orthonormalize these vectors using the qr facotization .",
    "2 .   for @xmath209 ,",
    "compute @xmath210 by .",
    "approximate @xmath202 and @xmath211 by and estimate the normwise condition number by .     in algorithm [ algorithmssce ] ,",
    "@xmath210 is computed by the equation . in practice ,",
    "the computation of @xmath210 should rely on the intermediate results of the process for solving the lse problem to reduce the computational burden .",
    "just as carried out in @xcite , where the estimate is computed by using the @xmath212 factor of qr decomposition , it is better to compute @xmath210 through a formula descended from instead of if we solve the lse problem by generalized svd .",
    "in this section , we will present two numerical examples to illustrate the reliability of the statistical condition estimates proposed in section 4 and to compare the structured condition number and the unstructured one , respectively . in these two examples , we will set @xmath95 and the matrix @xmath35 be the identity matrix .",
    "[ example1 ]    similar to @xcite , we generate the example as follows .",
    "let @xmath213 , @xmath214 , and @xmath215 be unit random vectors , and set @xmath216 where @xmath217 and @xmath218 .",
    "let the solution @xmath219 be @xmath220 and the residual vector @xmath83 be a random vector of specified norm .",
    "thus , letting @xmath221 and @xmath222 gives the desired lse problem , and it is easy to check that the condition numbers of @xmath37 and @xmath19 are @xmath223 and @xmath224 , respectively .",
    "recall that for any matrix @xmath13 , its condition number @xmath225 is defined by @xmath226 .    in our numerical experiments ,",
    "we set @xmath227 , @xmath228 and @xmath229 , and choose the parameters @xmath230 , @xmath231 in algorithm [ algorithmpce ] and @xmath232 in algorithm [ algorithmssce ] . by varying the condition numbers of @xmath37 and @xmath233 , and the residual s norm @xmath234",
    ", we test the performance of algorithms [ algorithmpce ] and [ algorithmssce ] .",
    "more precisely , for each pair of @xmath235 and @xmath234 with a fixed @xmath236 , @xmath237 random lse problems are generated and used for the test .",
    "the numerical results on mean and variance of the ratios between the statistical condition estimate and the exact condition number defined as @xmath238 are reported in tables [ table1 ] .    from table",
    "[ table1 ] , one can easily find that in general both algorithms [ algorithmpce ] and [ algorithmssce ] can give reliable estimates of the normwise condition number . in comparison , algorithm [ algorithmpce",
    "] performs more stable since the variances with this algorithm are smaller in most cases .",
    "meanwhile , it should be point out that when @xmath239 , algorithm [ algorithmssce ] may give an inaccurate estimate , i.e. , the ratio may be larger than @xmath240 .",
    "this phenomenon also exists in estimating the normwise condition number of the lls problem @xcite .",
    "although the expression of @xmath85 is more complicated than that of the normwise condition number of the lls problem and the circumstances on these two problems are different , we believe that the underlying reason should be the same ; the reader can refer to @xcite for a detailed explanation .",
    ".the efficiency of statistical condition estimates with @xmath223 and @xmath224 [ cols=\"<,^,^,^,^,^,^,^,^\",options=\"header \" , ]     let @xmath37 and @xmath19 be gaussian random toeplitz matrices of order @xmath241 .",
    "this means that the entries of these two matrices are generated from standard normal distribution .",
    "analogous to example [ example1 ] , we also let the solution @xmath219 be @xmath220 and the residual vector @xmath242 be a random vector of specified norm .",
    "however , unlike example [ example1 ] , it seems impossible to restrict a specific condition number to gaussian random toeplitz matrices . in our numerical experiment , for each @xmath242 , we test @xmath243 pairs of random toeplitz matrices @xmath37 and @xmath19 .",
    "the numerical results on the ratio between @xmath244 and @xmath245 defined by @xmath246 are presented in figure [ fig1 ] , which confirms the theoretical analysis in remark [ rmk3.2 ] .     and",
    "@xmath245 , title=\"fig:\",scaledwidth=100.0%,scaledwidth=85.0% ] +    from figure [ fig1 ] , we also find that there are some points near @xmath240 , which means that the unstructured condition number can be @xmath240 times larger than the structured one .",
    "thus , it may lead to an overestimate when using the unstructured condition number to give error bounds in a structured lse problem .",
    "moreover , we also note that , for different @xmath234s , the @xmath247s seem to follow the same trend gathering in the interval @xmath248 $ ] .",
    "whereas , from numerical experiments , we verify that the @xmath247 tends to be larger as @xmath9 increases . in the numerical experiments ,",
    "we set @xmath249 and @xmath250 , and , for every @xmath9 , we test @xmath251 lse problems with random toeplitz coefficient matrices @xmath37 and @xmath19 .",
    "the numerical results are presented in figure [ fig2 ] , where the circle line denotes the mean value of @xmath247s and the solid line denotes the corresponding variances .",
    "the fact shown in the figure means that the structured condition number has more advantage compared with the unstructured one as the dimensions of coefficient matrices increase .",
    "the authors would like to thank prof .",
    "michiel e. hochstenbach for providing matlab program of the probabilistic spectral norm estimator",
    ".    99 arioli , m. , baboulin , m. , gratton s. : a partial condition number for linear least squares problems , siam j. matrix anal . appl . * 29 * , 413433 ( 2007 ) .",
    "baboulin , m. , gratton , s. : a contribution to the conditioning of the total least squares problem , siam j. matrix anal . appl . * 32 * , 685699 ( 2011 ) .",
    "baboulin , m. , gratton , s. , lacroix , r. , laub , a.j . : statistical estimates for the conditioning of linear least squares problems , lecture notes in comput .",
    "sci . * 8384 * , 124133 ( 2014 ) .",
    "barlow , j.l . ,",
    "nichols , n. k. , plemmons , r.j . :",
    "iterative methods for equality constrained least squares problems , siam j. sci .",
    "* 9 * , 892906 ( 1988 ) .",
    "bergou , e.h . ,",
    "gratton , s. , tshimanga j. : the exact condition number of the truncated singular value solution of a linear ill - posed problem , siam j. matrix anal . appl . * 35 * , 10731085 ( 2014 ) .",
    "bjrck ,  . : numerical methods for least squares problems , siam , philadelphia , pa , usa ( 1996 ) .",
    "cao , y. , petzold , l. : a subspace error estimate for linear systems , siam j. matrix anal .",
    "* 24 * , 787801 ( 2003 ) .",
    "cox , a.j . , higham , n.j . : accuracy and stability of the null space method for solving the equality constrained least squares problem , bit * 39 * , 3450 ( 1999 ) .",
    "cucker , f. , diao , h. : mixed and componentwise condition numbers for rectangular structured matrices , calcolo * 44 * , 89115 ( 2007 ) .",
    "eldn , l. : perturbation theory for the least squares problem with equality constraints , slam j. numer .",
    "17 * , 338350 ( 1980 ) .",
    "geurts , a.j . : a contribution to the theory of condition , numer . math . * 39 * , 8596 ( 1982 ) .",
    "golub , g.h . ,",
    "kahan , w. : calculating the singular values and pseudo - inverse of a matrix , j. soc .",
    "anal . * 2 * , 205224 ( 1965 ) .",
    "golub , g. , van loan , c.f . : matrix computations .",
    "johns hopkins university press , baltimore ( 2013 ) .",
    "gratton , s. : on the condition number of linear least squares problems in a weighted frobenius norm , bit * 36 * , 523530 ( 1996 ) .",
    "higham , d.j .",
    ", higham n.j . ,",
    "backward error and condition of structured linear systems , siam j. matrix anal .",
    "* 13 * , 162175 ( 1992 ) .",
    "hochstenbach , m. : probabilistic upper bounds for the matrix two - norm , j. sci",
    ". comput . * 57 * , 464476 ( 2013 ) .",
    "horn , r.a . ,",
    "johnson , c.r . : topics in matrix analysis .",
    "cambridge up , new york ( 1991 ) .",
    "kenney , c. , laub , a. : small - sample statistical condition estimates for general matrix functions , siam j. sci . comput . * 15 * , 3661 ( 1994 ) .",
    "lawson , c.l . ,",
    "hanson , r.j .",
    ": solving least squares problems , siam , philadelphia , pa ( 1995 ) .",
    ", jia , z.x . : some results on condition numbers of the scaled total least squares problem , linear algebra appl . *",
    "435 * , 674686 ( 2011 ) .",
    "li , h.y . ,",
    "wang , s. x. , yang , h. : on mixed and componentwise condition numbers for indefinite least squares problem , linear algebra appl . * 448 * , 104129 ( 2014 ) .",
    "paige , c.c .",
    ", saunders , m.a . :",
    "lsqr : an algorithm for sparse linear equations and sparse least squares , acm trans .",
    "software , * 8(1 ) * , 4371 ( 1982 ) .",
    "rice , j.r . : a theory of condition , siam j. numer .",
    "anal . * 3 * , 287310 ( 1966 ) .",
    "rump , s.m . : structured perturbations .",
    "part i : normwise distances , siam j. matrix anal .",
    "25 * , 130 ( 2003 ) .",
    "rump , s.m . : structured perturbation .",
    "part ii : componentwise distances , siam j. matrix anal .",
    "appl . * 25 * , 3156 ( 2003 ) .",
    "van loan , c.f . : generalizing the singular value decomposition , siam j. numer .",
    "* 13 * , 7683 ( 1976 ) .",
    "wei , m. : algebraic properties of the rank - deficient equality - constrained and weighted least squares problem , linear algebra appl . * 161 * , 2743 ( 1992 ) .",
    "wei , m. : perturbation theory for rank - deficient equality constrained least squares problem , siam j. numer .",
    "* 29 * , 14621481 ( 1992 ) .",
    "wei , y. , diao , h. , qiao s. : condition number for weighted linear least squares problem and its condition number , technical report cas 04 - 02-sq , department of computing and software , mcmaster university , hamilton , on , canada , 2004 .",
    "xu , w. , wei , y. , qiao , s. : condition numbers for structured least squares problems , bit * 46 * , 203225 ( 2006 ) ."
  ],
  "abstract_text": [
    "<S> in this paper , the normwise condition number of a linear function of the equality constrained linear least squares solution called the partial condition number is considered . </S>",
    "<S> its expression and closed formulae are first presented when the data space and the solution space are measured by the weighted frobenius norm and the euclidean norm , respectively . </S>",
    "<S> then , we investigate the corresponding structured partial condition number when the problem is structured . to estimate these condition numbers with high reliability , the probabilistic spectral norm estimator and the small - sample statistical condition estimation method are applied and two algorithms are devised . </S>",
    "<S> the obtained results are illustrated by numerical examples .    </S>",
    "<S> example.eps gsave newpath 20 20 moveto 20 220 lineto 220 220 lineto 220 20 lineto closepath 2 setlinewidth gsave .4 setgray fill grestore stroke grestore </S>"
  ]
}