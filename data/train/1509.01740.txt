{
  "article_text": [
    "the method of delays is a well - established technique for reconstructing the state - space dynamics of a system from scalar time - series data@xcite .",
    "the task of choosing good values for the free parameters in this procedure has been the subject of a large and active body of literature over the past few decades , e.g.,@xcite .",
    "the majority of these techniques focus on the geometry of the reconstruction . a standard method for selecting the delay @xmath0 , for instance ,",
    "is to maximize independence between the coordinates of the delay vector while minimizing overfolding and reduction in causality between coordinates@xcite ; a common way to choose an embedding dimension is to track changes in near - neighbor relationships in reconstructions of different dimensions@xcite .",
    "this heavy focus on the geometry of the delay reconstruction is appropriate when one is interested in quantities like fractal dimension and lyapunov exponents , but it is not necessarily the best approach when one is building a delay reconstruction _ for the purposes of prediction_. that issue , which is the focus of this paper , has received comparatively little attention in the extensive literature on delay reconstruction - based prediction@xcite . in the following section , we propose a robust , computationally efficient method called spithat can be used to select parameter values that maximize the shared information between the past and the future  or , equivalently , that maximize the reduction in uncertainty about the future given the current model of the past .",
    "the implementation details , and a complexity analysis of the algorithm , are covered in section  [ sec : implementation ] . in section  [",
    "sec : results ] , we show that simple prediction methods working with spi - optimal reconstructions  constructions using parameter values that follow from the spicalculations ",
    "perform better , on both real and synthetic examples , than those same forecast methods working with reconstructions that are built using the traditional methods mentioned above .",
    "finally , in section  [ sec : dataandhorizon ] we explore the utility of spiin the face of different data lengths and prediction horizons .",
    "the information shared between the past and the future is known as the excess entropy@xcite .",
    "we will denote it here by @xmath1 $ ] , where @xmath2 is the mutual information@xcite and @xmath3 and @xmath4 represent the infinite past and the infinite future , respectively .",
    "@xmath5 is often difficult to estimate from data due to the need to calculate statistics over potentially infinite random variables@xcite .",
    "while this is possible in principle , it is too difficult in practice for all but the simplest of dynamics@xcite . in any case , the excess entropy is not exactly what one needs for the purposes of prediction , since it is not realistic to expect to have the infinite past or to predict infinitely far into the future . for our purposes , it is more productive to consider the information contained in the _ recent _ past and determine how much that explains about the not - too - distant future . to that end , we define @xmath6    ~,\\end{aligned}\\ ] ] where @xmath7 is an estimate of the state of the system at time @xmath8 and @xmath9 is the state of the system @xmath10 steps in the future .",
    "this can be neatly visualized  and compared to traditional methods like time - delayed mutual information , multi - information and the so - called co - information@xcite  using the i - diagrams of yeung@xcite .",
    "figure  [ fig : mi - i - diagram ] shows an i - diagram of time - delayed mutual information for a specific @xmath0 . in a diagram like this , each circle represents the uncertainty in a particular variable .",
    "the left circle in figure  [ fig : mi - i - diagram ] , for instance , represents the average uncertainty in observing @xmath11 ( i.e. , @xmath12 $ ] , where @xmath13 is the shannon entropy@xcite ) ; similarly , the top circle represents @xmath14 $ ] or the uncertainty in the @xmath15 future observation .",
    "each of the overlapping regions represents shared uncertainty : e.g. , in figure  [ fig : mi - i - diagram ] , the shaded region represents the shared uncertainty between @xmath16 and @xmath11 .",
    "more precisely , the shaded region schematizes the quantity @xmath17 & = & h[x_{j } ] + h[x_{j-\\tau } ] - h[x_{j},x_{j-\\tau } ] \\\\    & = & h[x_{j } ] - h[x_{j}|x_{j-\\tau } ] \\\\    & = & h[x_{j-\\tau } ] - h[x_{j-\\tau}|x_{j}].\\end{aligned}\\ ] ] if the @xmath18 are trajectories in reconstructed state space , then tuning the reconstruction parameters ( e.g. , @xmath0 ) changes the size of the overlap regions  i.e . , the amount of information shared between the coordinates of the delay vector .",
    "this notion can be put into practice to select good values for those parameters .",
    "notice , for instance , that minimizing the shaded region in figure  [ fig : mi - i - diagram]that is , rendering @xmath16 and @xmath11 as independent as possible  maximizes the total uncertainty that is explained by the combined model @xmath19^t$ ] ( the sum of the area of the two circles ) .",
    "this is precisely the argument made by fraser and swinney in @xcite .",
    "however , it is easy to see from the i - diagram that choosing @xmath0 in this way does not explicitly take into account explanations of the _ future_that is , it does not reduce the uncertainty about @xmath20 .",
    "moreover , the calculation does not extend to three or more variables , where minimizing overlap is not a trivial extension of the reasoning captured in the i - diagrams .    ; ;    the obvious next step would be to explicitly include the future in the estimation procedure .",
    "one approach to this would be to work with the so - called co - information@xcite , @xmath21    ~,\\end{aligned}\\ ] ] as depicted in figure  [ fig : co - information ] , this is the intersection of @xmath22 $ ] , @xmath12 $ ] and @xmath14 $ ] .",
    "it describes the reduction in uncertainty that the _ two _ past states , together , provide regarding the future .",
    "while this is obviously an improvement over the time - delayed mutual information of figure  [ fig : mi - i - diagram ] , it does not take into account the information that is shared between @xmath23 and the future but _ not shared with the past _",
    "( i.e. , @xmath11 ) , and vice versa .",
    "the so - called multi - information , @xmath24 \\right ) - h[x_{j},x_{j-\\tau},x_{j+p } ]    ~,\\end{aligned}\\ ] ] depicted in figure  [ fig : multi - information ] addresses this shortcoming , but it also includes information that is shared between the past and the present , but not with the future .",
    "this is not terribly useful for the purposes of prediction .",
    "moreover , the multi - information overweights information that is shared between all three circles  past , present , and future  thereby artificially over - valuing information that is shared in all delay coordinates . in the context of predicting @xmath20 ,",
    "the provenance of the information is irrelevant and so the multi - information seems ill - suited to the task at hand as well .",
    "0.49    ; ; ;    0.49    ; ; ;    ; ; ;    ; ; ;    ; ; ; ;    spiaddresses all of the issues raised in the previous paragraphs . by treating the generic delay vector as a joint variable , rather than a series of single variables ,",
    "spicaptures the shared information between the past , present , and future independently ( the left and right colored wedges in figure  [ fig : mytau ] ) , as well as the information that the past and present , together , share with the future ( the center wedge ) . by choosing delay reconstruction parameters that maximize spi , then",
    ", one can explicitly maximize the amount of information that each delay vector contains about the future .    ; ;    to make all of this more concrete and tie it back to state - space prediction of dynamical systems , consider the following example : let @xmath7 be a two - dimensional delay reconstruction of the time series , @xmath25^t$ ] .",
    "in this case , spibecomes @xmath26^t;x_{t+p}]$ ] , which describes the reduction in uncertainty about the system at time @xmath27 , given the state estimate @xmath19^t$ ] .",
    "one can estimate a @xmath0 value for the purposes of reconstructing the dynamics from a given time series , for instance , by calculating spifor a range of @xmath0 and choosing the first maximum ( i.e. , minimizing the uncertainty about the @xmath15 future observation ) .",
    "one can then apply any state - space forecasting method to the resulting reconstruction in order to predict the future course of that time series . in section  [ sec : results ] , we explore that claim using lorenz s classic method of analogues@xcite , but it should be just as applicable for other predictors that utilize state - space reconstructions , such as the methods used in@xcite . notice that both the definition of spiand its use in optimizing forecast algorithms are general ideas that are easily extensible to other state estimators .",
    "for example , in the case of traditional delay - coordinate _ embedding _ , the state estimator is the @xmath28-dimensional delay vector , i.e. , @xmath29^t\\end{aligned}\\ ] ] with @xmath28 chosen to meet the appropriate theoretical requirements @xcite .",
    "we demonstrate this approach in section  [ sec : results ] .",
    "if the time series is pre - processed ( e.g. , via a kalman filter@xcite , a low - pass filter and an inverse fourier transform@xcite , or some other local linear transformation@xcite ) , the state estimator simply becomes @xmath30 where @xmath31 is the processed @xmath28-dimensional delay vector .",
    "as we demonstrate in section  [ subsubsec : computer ] , one can even use spito optimize parameter choices for forecast methods that use reconstructions that are not embeddings  i.e .",
    ", those whose dimensions do not meet the traditional requirements for preserving dynamical invariants like the lyapunov exponent .",
    "to calculate spifrom a real - valued time series , one must first symbolize those data .",
    "simple binning is not a good solution here , as it is known to cause severe bias if the bin boundaries do not create a generating partition@xcite .",
    "a useful alternative is kernel estimation @xcite , in which the relevant probability density functions are estimated via a function @xmath32 with a resolution or bandwidth @xmath33 that measures the similarity between two points in @xmath34 space .",
    "( for spi , @xmath18 would be @xmath7 and @xmath35 would be @xmath9 . ) given points @xmath36 and @xmath37 in @xmath34 , one can define : @xmath38 where @xmath39 and @xmath40 .",
    "that is , @xmath41 is the proportion of the @xmath42 pairs of points in @xmath43 space that fall within the kernel bandwidth @xmath33 of @xmath36 , i.e. , the proportion of points similar to @xmath36 .",
    "when @xmath44 is the max norm , this is the so - called box kernel .",
    "this too , however , can introduce bias@xcite and is dependent on the choice of bandwidth @xmath33 .",
    "after these estimates , and the analogous estimates for @xmath45 , are produced , they are then used directly to compute local estimates of mutual information for each point in space , which are then averaged over all samples to produce the mutual information of the time series . for more details on this procedure ,",
    "see@xcite .",
    "a better way to calculate @xmath46 $ ] and estimate spiis the kraskov - stgbauer - grassberger ( ksg ) estimator@xcite .",
    "this approach dynamically alters the kernel bandwidth to match the density of the data , thereby smoothing out errors in the probability density function estimation process . in this approach ,",
    "one first finds the @xmath47 nearest neighbor for each sample @xmath48 ( using max norms to compute distances in @xmath49 and @xmath50 ) , then sets kernel widths @xmath51 and @xmath52 accordingly and performs the pdf estimation .",
    "there are two algorithms for computing @xmath46 $ ] with the ksg estimator@xcite .",
    "the first is more accurate for small sample sizes but more biased ; the second is more accurate for larger sample sizes .",
    "we use the second of the two in this paper , as we have fairly long time series .",
    "our algorithm sets @xmath51 and @xmath52 to the @xmath49 and @xmath50 distances to the @xmath47 nearest neighbor .",
    "one then counts the number of neighbors within and on the boundaries of these kernels in each marginal space , calling these sums @xmath53 and @xmath54 , and finally calculates @xmath55 = \\psi(k ) - \\frac{1}{k}-\\langle \\psi(n_x ) + \\psi(n_y ) \\rangle + \\psi(n )    ~,\\end{aligned}\\ ] ] where @xmath56 is the digamma function and @xmath52 to the maxima of the @xmath49 and @xmath50 distances to the @xmath57 nearest neighbors . ] .",
    "this estimator has been demonstrated to be robust to variations in @xmath57 as long as @xmath58@xcite .    in this paper",
    ", we employ the java information dynamics toolkit ( jidt ) implementation of the ksg estimator@xcite .",
    "the computational complexity of this implementation is @xmath59 , where @xmath42 is the length of the time series and @xmath57 is the number of neighbors being used in the estimate . while this is more expensive than traditional binning @xmath60 )",
    ", it is bias corrected , allows for adaptive kernel bandwidth to adjust for under- and over - sampled regions of space , and is both model and parameter free ( aside from @xmath57 , to which it is very robust ) .",
    "in this section , we demonstrate how to use spito choose parameter values for delay - reconstruction forecast models .",
    "we do this for several synthetic examples , as well as for sensor data from several laboratory experiments . for the discussion that follows , we use the term `` spi - optimal '' to refer to the parameter values ( @xmath28 and @xmath0 ) that provided the best match between the forecast and the true continuation . to evaluate a forecast model",
    ", we divide the signal into two parts : the initial training signal @xmath61the first @xmath62 elements of the time series  and the test signal @xmath63 , where @xmath57 is the length of the prediction .",
    "we build a delay reconstruction from the @xmath64 ( i.e. , a sequence of points @xmath65^t$ ] ) , use it to generate a prediction @xmath66 , and then use the mean absolute scaled error@xcite to compare the prediction to the test signal : @xmath67 @xmath68 is a normalized measure : the scaling term in the denominator is the average in - sample forecast error for a random - walk prediction  which uses the previous value in the observed signal as the forecast  calculated over the training signal .",
    "that is , @xmath69 means that the prediction error in question was , on the average , smaller than the in - sample error of a random - walk forecast on the training portion of the same data .",
    "analogously , @xmath70 means that the corresponding prediction method did _ worse _ , on average , than the random - walk method .    while its comparative nature may seem odd , this error metric allows for fair comparison across varying methods , prediction horizons , and signal scales , making it a standard error measure in the forecasting literature  and a good choice for the study described in the following sections , which involve a number of very different signals .      in this section , we apply spito some standard synthetic examples , both maps ( hnon , logistic ) and flows : the classic lorenz system@xcite and the more - recent `` lorenz 96 '' atmospheric model@xcite .",
    "we construct the traces for the lorenz experiments using a standard fourth - order runge - kutta solver on the associated differential equations , with a timestep of @xmath71 , for 60,000 time steps .",
    "for the maps , we simply iterate the difference equations 60,000 times . in all cases ,",
    "we discard the first 10,000 points of each trajectory to remove transient behavior , then sample individual state variables to produce different scalar time - series data sets . we reconstruct the dynamics from those traces using different values of the dimension @xmath28 and delay @xmath0 and compute spifor each of those reconstructed trajectories .",
    "we then use lorenz s classic method of analogues ( lma ) @xcite to generate forecasts of each trace , compute their @xmath68 scores as described above , and discuss their relationships to the spivalues for the corresponding time series . for simplicity , in this initial discussion",
    "we perform a series of one - step - ahead predictions , rebuilding the model at each step . for the spicalculations",
    ", this means that we estimate @xmath72 $ ] , with @xmath73^t$ ] . in section  [ subsec : predictionhorizon ]",
    "we expand this discussion by increasing the prediction horizon ; in section  [ subsec : datalength ] , we consider the effects of the length of the traces .",
    "the lorenz 96 system@xcite is defined by a set of @xmath74 differential equations in the state variables @xmath75 : @xmath76 for @xmath77 , where @xmath78 is a constant forcing term that is independent of @xmath57 . in the following discussion we focus on two parameter sets , @xmath79 and @xmath80 , which produce low- and high - dimensional chaos , respectively .",
    "see @xcite for an explanation of this model and the associated parameters .",
    "figure  [ fig : l96n22f5spi ] shows a heatmap of the spivalues for reconstructions of a representative trajectory from this system with @xmath79 , for a range of @xmath28 and @xmath0 .",
    "not surprisingly , this image reveals a strong dependency between the values of the reconstruction parameters and the reduction in uncertainty about the near future that is provided by the reconstruction .",
    "very low @xmath0 values , for instance , produce delay vectors with highly redundant coordinates , but which provide substantial information about the future . as mentioned in the first section of this paper",
    ", standard heuristics only focus on minimizing redundancy between coordinates and choose the @xmath0 value that minimizes the mutual information between the first two coordinates in the delay vector . for this trajectory ,",
    "the approach of fraser & swinney@xcite yields @xmath81 , while standard dimension - estimation heuristics @xcite suggest @xmath82 .",
    "the spivalue for a delay reconstruction built with those parameter values is 3.463 .",
    "this is _ not _ , however , the spi - optimal reconstruction ; choosing @xmath83 and @xmath84 , for instance , results in a higher value ( @xmath85)i.e . , signficantly more reduction in uncertainty about the future .",
    "this may be somewhat counter - intuitive , since each of the delay vectors in the spi - optimal reconstruction spans far less of the data set and thus one would expect points in that space to contain _ less _ information about the future . figure  [ fig : l96n22f5spi ] suggests , however , that this in fact not the case ; rather , that uncertainty _ increases _ with both dimension and time delay .",
    "[ page : increase - with - tau ]    the question at issue in this paper is whether that reduction in uncertainty about the future correlates with improved accuracy of an lma forecast built from that reconstruction .",
    "since the spi - optimal choices maximize the shared information between the state estimator and @xmath86 , one would expect a delay reconstruction model built with those choices to afford lma the best leverage . to test that conjecture",
    ", we performed an exhaustive search with @xmath87 and @xmath88 . for each @xmath89 pair , we used lma to generate forecasts from the corresponding reconstruction , computed their @xmath68 scores , and plotted the results in a heatmap similar to the one in figure  [ fig : l96n22f5spi ] . as one would expect , the @xmath68 and spiheatmaps are generally antisymmetric .",
    "this antisymmetry breaks down somewhat for low @xmath28 and high @xmath0 , where the forecast accuracy is low even though the reconstruction contains a lot of information about the future .",
    "we suspect that this is due to a combination of overfolding ( due to too - large values of @xmath0 ) and projection ( low @xmath28 ) .",
    "even though each point in such a reconstuction may contain a lot of information about the future , the false crossings created by this combination of effects pose problems for a near - neighbor forecast strategy like lma .",
    "the improvement that occurs if one adds another dimension is consistent with this explanation .",
    "notice , too , that this effect only occurs far from the maximum in the spisurface  the area that is of interest if one is using spito choose parameter values for reconstruction models .    in general ,",
    "though , maximizing the redundancy between the state estimator and the future does appear to minimize the resulting forecast error of lma .",
    "indeed , the maximum on the surface of figure  [ fig : l96n22f5mase ] ( @xmath90 ) is exactly the minimum on the surface of figure  [ fig : l96n22f5spi ] . the accuracy of this forecast is more than five times higher ( @xmath91 ) than that of a forecast constructed with the parameter values suggested by the standard heuristics ( @xmath92 ) .",
    "note that the optima of these surfaces may be broad : i.e. , there may be _ ranges _ of @xmath28 and @xmath0 for which spiand @xmath68 are optimal , and roughly constant . in these cases",
    ", it makes sense to choose the lowest @xmath28 on the plateau , since that minimizes computational effort , data requirements , and noise effects ; see @xcite for a full discussion of this .",
    "while the results discussed in the previous paragraph do provide a preliminary validation of the claim that one can use spito select good parameter values for delay reconstruction - based forecast strategies , they only involve a single example system .",
    "similar experiments on traces from the lorenz 96 system with different parameter values @xmath80 show identical results  indeed , the heatmaps are visually indistinguishable from the ones in figure  [ fig : tauandml96 ] .",
    "figure  [ fig : tauandml63 ] shows heatmaps of spiand @xmath68 for similar experiments on the classic `` lorenz 63 '' system@xcite : @xmath93 with the typical chaotic parameter selections : @xmath94 , and @xmath95 .               as in the lorenz 96 case ,",
    "the heatmaps are generally antisymmetric , confirming that maximizing spiis roughly equivalent to minimizing @xmath68 .",
    "again , though , the antisymmetry is not perfect ; for high @xmath0 and low @xmath28 , the effects of projecting an overfolded attractor cause false crossings that trip up lma . as before , adding a dimension mitigates this effect by removing these false crossings .",
    "both the lorenz 63 and lorenz 96 plots show a general decrease in predictability for large @xmath28 and high @xmath0 , with roughly hyperbolic equipotentials dividing the colored regions .",
    "the locations and heights of these equipotentials differs because the two signals are not equally easy to predict .",
    "this matter is discussed further at the end of this section .",
    "numerical spiand @xmath68 values for lma forecasts on different reconstructions of both lorenz systems are tabulated in the top three rows of table  [ tab : mytauparams ] , along with the reconstruction parameter values that produced those results .    [ cols=\"<,^,^,^,^,^,^,^,^,^\",options=\"header \" , ]     [ tab : mytauparams ]    the data in this table bring out two important points .",
    "first , as suggested by the heatmaps , the @xmath28 and @xmath0 values that maximize spi(termed @xmath96 and @xmath97 in the table legend ) are close , or identical , to the values that minimize @xmath68 ( @xmath98 and @xmath99 ) for all three lorenz systems .",
    "this is notable because  as discussed in section  [ subsec : datalength]the former can be estimated quite reliably from a small sample of the trajectory in only a few seconds of compute time , whereas the exhaustive search that is involved in computing @xmath98 and @xmath99 for table  [ tab : mytauparams ] required close to 30 hours of cpu time per signal .",
    "a second important point that is apparent from the table is that delay reconstructions built using the traditional heuristics  the values with the @xmath13 subscript  were comparatively ineffective for the purposes of lma - based forecasting .",
    "this is notable because that is the default approach in the literature on state - space based forecasting methods for dynamical systems .",
    "a close comparison of figures  [ fig : tauandml96 ] and  [ fig : tauandml63 ] brings up another important point : some time series are harder to forecast than others .",
    "figure  [ fig : l96histcompares ] breaks down the details of the two suites of lorenz-96 experiments , showing the distribution of spiand @xmath68 values for all of the reconstructions .",
    "values for representative traces from the lorenz 96 @xmath79 and @xmath80 systems for all @xmath100 values in figures  [ fig : tauandml96 ] and  [ fig : tauandml63 ] . ]",
    "values for representative traces from the lorenz 96 @xmath79 and @xmath80 systems for all @xmath100 values in figures  [ fig : tauandml96 ] and  [ fig : tauandml63 ] . ]",
    "although there is some overlap in the @xmath101 and @xmath102 histograms  i.e .",
    ", best - case forecasts of the former are better than most of the forecasts of the latter ",
    "the @xmath101 traces generally contain less information about the future and thus are harder to forecast accurately .",
    "delay reconstruction of discrete - time dynamical systems , while possible in theory , can be problematic in practice . although the embedding theorems do apply in these cases , the heuristics for estimating @xmath28 and @xmath0 often fail .",
    "the time - delayed mutual information of @xcite , for example , may decay exponentially , without showing any clear minimum . and",
    "the lack of spatial continuity of the orbit of a map violates the underlying idea behind the method of @xcite .",
    "state space - based forecasting methods can , however , be very useful in generating predictions of trajectories from systems like this_if _ one has a reconstruction that is faithful to the true dynamics .    in view of this , it would be particularly useful if one could use spito choose embedding parameter values for maps .",
    "this section explores that notion using two canonical examples , shown in the bottom two rows of table  [ tab : mytauparams ] . for the hnon map , @xmath103 with @xmath104 and @xmath105 , the spi - optimal parameter values were @xmath83 and @xmath84 . as in the flow examples ,",
    "these were identical to the values that minimized @xmath68 .",
    "these parameter values make sense , of course ; a first - return map of the @xmath49 coordinate is effectively the hnon map , so @xmath106 $ ] is a perfect state estimator ( up to a scaling term ) .",
    "but in practice , of course , one rarely knows the underlying dynamics of the system that generated a time series , so the fact that one can choose good reconstruction parameter values by maximizing spiis notable  especially since standard heuristics for that purpose fail in this system .",
    "the same pattern holds for the logistic map , @xmath107 , with @xmath108 : the spi - optimal parameter values coincide with the minimum of the @xmath68 surface . as in the hnon example , these values ( @xmath109 and @xmath84 ) make complete sense , given the form of the map . but",
    "again , one does not always know the form of the system that generated a given time series . in the case of the logistic map ,",
    "the standard heuristics fail , but spiclearly indicates that one does not actually need to reconstruct these dynamics  rather , near - neighbor forecasting _ on the time series itself _ is the best approach .      the results in the previous section",
    "provide a preliminary verification of the conjecture that maximizing spiminimizes forecast accuracy of lma , for both maps and flows .",
    "while experiments with synthetic examples are useful , they do not call the really important aspect of that research question : whether spiis a useful way to choose parameter values for delay reconstruction - based forecasting of real - world data , where the time series are noisy and perhaps short , and one does not know the dimension of the underlying system  let alone its governing equations . in this section ,",
    "we turn our attention to that question using experimental data from two different dynamical systems : a far - infrared laser and a laboratory computer - performance experiment .",
    "a canonical test case in the forecasting literature is the so - called  dataset a \" from the santa fe institute prediction competition@xcite , which was gathered from a far - infrared laser . as in the synthetic examples in the previous section ,",
    "the spiand @xmath68 heatmaps ( figure  [ fig : maseandmytaulaser ] ) are largely antisymmetric for this signal .               again , there is a band across the bottom of each image because of the combined effects of overfolding and projection .",
    "note the resemblance between figures  [ fig : maseandmytaulaser ] and  [ fig : tauandml63 ] : the latter resemble `` smoothed '' versions of the former .",
    "it is well known@xcite that the sfi a dataset is well described by the lorenz 63 system with some added noise , so this similarity is both unsurprising and reassuring .",
    "lma forecasts using the spi - optimal reconstruction of this trace were more accurate than similar forecasts using a reconstruction built using traditional heuristics ( @xmath110 versus @xmath111 ) and only slightly worse than the optimal value ( @xmath112 ) .",
    "however , the values of @xmath113 and @xmath114 are not identical for this signal .",
    "this is because the optima in the heatmaps in figure  [ fig : maseandmytaulaser ] are bands , rather than unique points  as was the case in the synthetic examples in section  [ subsec : synthetic ] . in a situation like this ,",
    "a range of @xmath100 values are statistically indistinguishable , from the standpoint of the forecast accurary afforded by the corresponding reconstruction .",
    "the values suggested by the spicalculation ( @xmath115 and @xmath116 ) and by the exhaustive search ( @xmath117 , @xmath118 ) were all on this plateau and @xmath119 , were off the shoulder of that plateau . ] .",
    "again , it appears that one can use spito choose good parameter values for delay reconstruction - based forecasting , but sfi a is only a single trace from a fairly simple system .",
    "laboratory experiments on computer performance dynamics have shown that these high - dimensional nonlinear systems exhibit a range of interesting deterministic dynamical behaviors@xcite .",
    "both hardware and software play roles in these dynamics ; changing either one can cause bifurcations from periodic orbits to low- and high - dimensional chaos . this rich range of behavior makes computer performance dynamics an ideal final test case for this paper .",
    "collecting observations of the performance of a running computer requires some significant engineering .",
    "basically , one programs the microprocessor s onboard hardware performance monitor to observe the quantities of interest , then stops the program execution at 100,000-instruction intervals  the unit of time in these experiments  and reads off the contents of those registers .",
    "interested readers can find a detailed description of this custom measurement infrastructure in@xcite .",
    "the signals that are produced by this apparatus are scalar time - series measurements of system metrics like processor efficiency ( _ e.g. , _ ipc , which measures how many instructions are being executed , on the average , in each clock cycle ) or memory usage ( _ e.g. , _ how often the processor had to access the main memory during the measurement interval ) .    here , for conciseness , we focus on _ processor _ performance traces from two different programs , one simple and one complex , running on the same intel i7-based computer .",
    "the first is four lines of c ( col_major ) that repeatedly initializes a @xmath120 matrix in column - major order .",
    "the second is a much more complex program : the 403.gcccompiler from the spec 2006cpu benchmark suite@xcite .",
    "the performance traces of these two programs contained 147,925 points and 45,545 points , respectively .",
    "since computer performance dynamics result from a composition of hardware and software , these two experiments involve two different dynamical systems , even though the programs are running on the same computer .",
    "but since other effects could be at work  housekeeping by the operating system , etc.we repeated each experiment 15 times for a total of 30 traces .",
    "we have performed similar forecast experiments using other processor and memory performance metrics gathered during the execution of a variety of programs on several different computers @xcite .",
    "our preliminary analysis indicates that the results described in the rest of this section hold for those traces as well .",
    "as in the previous examples , heatmaps of @xmath68 and spifor the col_majortime series ( figure  [ fig : colmytau ] ) are largely antisymmetric .               and again , reconstructions using the spi - optimal parameter values allowed lma to produce highly accurate forecasts of this signal : @xmath121 , compared to the optimal @xmath122 .",
    "there are several major differences between these plots and the previous ones in this paper , though , beginning with the vertical stripes .",
    "these are due to the dominant unstable periodic orbit of period 3 in the chaotic attractor in the col_majordynamics .",
    "when @xmath0 is a multiple of this period ( @xmath123 ) , [ page:3k ] the coordinates of the delay vector are not independent , which lowers spiand makes forecasting more difficult .",
    "( there is a nice theoretical discussion of this effect in @xcite . )",
    "conversely , spispikes and @xmath68 plummets when @xmath124 , since the coordinates in such a delay vector can not share any prime factors with the period of the orbit .",
    "the band along the bottom of both images is , again , due to a combination of overfolding and projection .",
    "another difference between the col_majorheatmaps and the ones in figures  [ fig : tauandml96 ] , [ fig : tauandml63 ] , and  [ fig : maseandmytaulaser ] is the apparent overall trend : the `` good '' regions ( low @xmath68 and high spi ) are in the lower - left quadrants of those heatmaps , but in the upper - right quadrant of figure  [ fig : tauandmcol ] .",
    "this is partly an artifact of the difference in the color - map scale , which was chosen here to bring out some important details of the structure , and partly due to that structure itself",
    ". specifically , the optima of the col_majorheatmaps  the large dark red and blue regions in figures  [ fig : colmase ] and  [ fig : colmytau ] , respectively  are much broader than the ones in the earlier sections of this paper , perhaps because the signal is so close to periodic .",
    "( this was also the case to some extent in the sfi a example , for the same reason . )",
    "this geometry makes precise comparisons of spi - optimal and @xmath68-optimal parameter values somewhat problematic , as the exact optima on two almost - flat but slightly noisy landscapes may not be in the same place .",
    "indeed , the spivalues at @xmath113 and @xmath114 were within a standard error across all 15 traces of col_major .",
    "and that brings up an interesting tradeoff . for practical purposes ,",
    "what one wants is @xmath113 values that produce a @xmath68 value that is _ close to _ the optimum @xmath125 .",
    "however , the algorithmic complexity of most nonlinear time - series analysis and prediction methods scales badly with @xmath28 . in cases where the spimaximum is broad , then , one might want to choose the lowest value of @xmath28 on that plateau  or even a value that is on the _ shoulder _ of that plateau , if one needs to balance efficiency over accuracy . indeed , forecasts with @xmath83 appear to work surprisingly well for many nonlinear dynamical systems , including the col_majordata@xcite .",
    "fixing @xmath83 amounts to marginalizing the heatmaps in figure  [ fig : tauandmcol ] , which produces a cross section like the ones shown in figure  [ fig : maseandmytaucol ] .     and",
    "spifor lma forecasts of @xmath83 delay reconstructions of all 15 col_majortraces , plotted as a function of @xmath0 .",
    "the blue dashed curves show the averages across all trials ; the red dotted lines are that average @xmath126 the standard deviation . ]        and spifor lma forecasts of @xmath83 delay reconstructions of all 15 col_majortraces , plotted as a function of @xmath0 .",
    "the blue dashed curves show the averages across all trials ; the red dotted lines are that average @xmath126 the standard deviation . ]",
    "the antisymmetry between spiand @xmath68 is quite apparent in these plots ; the global maximum of the former coincides with the global minimum of the latter , at @xmath127 .",
    "the average @xmath68 score of col_majorforecasts constructed with @xmath83 and this @xmath0 value is @xmath128 .",
    "this is not much lower than the overall optimum of 0.0496a value from a forecast whose free parameters required almost six orders of magnitude more cpu time to compute . as an important aside",
    ": these results suggest that one could bypass even more of the computational effort that is involved in delay reconstruction - based forecasting by simply working in two dimensions , i.e. , by calculating spiacross a range of @xmath0s , rather than across a 2d @xmath100 space .",
    "this approach is discussed further in @xcite .",
    "the correspondence between @xmath68 and spialso holds true for other marginalizations : i.e. , the minimum @xmath68 and the maximum spioccur at the same @xmath0 value for all @xmath28-wise slices of the col_majorheatmaps , to within statistical fluctuations .",
    "the methods of @xcite and @xcite , incidentally , suggest @xmath129 and @xmath130 for these traces ; the @xmath68 of an lma forecast on such a reconstruction is 0.0530 , which is somewhat better than the best result from the @xmath83 marginalization , although still short of the overall optimum .",
    "the correspondence between @xmath131 and @xmath97 is coincidence ; for this particular signal , maximizing the independence of the coordinates happened to maximize the information about the future contained in each delay vector .",
    "the @xmath132 result is not coincidence  and quite interesting , in view of the fact that the @xmath83 forecast is so good .",
    "it is also surprising in view of the huge number of transistors  potential state variables  in a modern computer .",
    "as described in @xcite , however , the hardware and software constraints in these systems confine the dynamics to a much lower - dimensional manifold .",
    "all of these issues , and their relation to the task of prediction , are explored in more depth in @xcite .",
    "the col_majorprogram is what is known in the computer - performance literature as a `` micro - kernel''a extremely simple example that is used in proof - of - concept testing .",
    "the fact that its dynamics are so rich speaks to the complexity of the hardware ( and the hardware - software interactions ) in modern computers ; again , see @xcite for a much deeper discussion of these issues .",
    "modern computer programs are far more complex than this simple micro - kernel , of course , which begs the question : what does spitell us about the dynamics of truly complex systems like that  programs that the computer - performance community models as stochastic systems ?    for 403.gcc , the answer is , again , that spiappears to be an effective and efficient way to assess predictability . it has been shown@xcite that this time series shares little to no information with the future : i.e. , that it _ can not _ be predicted using delay reconstruction - based forecasting methods , regardless of @xmath0 and @xmath28 values .",
    "the experiments in @xcite required dozens of hours of cpu time to establish that conclusion ; spigives the same results in a few seconds , using much less data .",
    "the structure of the heatmaps for this experiment , which are shown in figure  [ fig : tauandmgcc ] , is radically different .",
    "the patterns visible in the previous @xmath68 plots , and the antisymmetry between spiand @xmath68 plots , are absent from figure  [ fig : tauandmgcc ] , reflecting the lack of predictive content in this signal .",
    "note , too , that the color maps are different in this figure .",
    "this reflects the much lower values of spifor this signal : a maximum spiof 0.7722 for 403.gcc , compared to 5.3026 for lorenz 96 with @xmath102 .",
    "indeed , the @xmath68 surface in figure  [ fig : gccmase ] never dips below 1.0 , in contrast , never exceeds @xmath133 and generally stays below 0.3 . ] .",
    "that is , regardless of parameter choice , lma forecasts of 403.gccare no better than simply using the prior value of this scalar time series as the prediction .",
    "the uniformly low spivalues in figure  [ fig : gccmytau ] are an effective indicator of this  and , again , they can be calculated quickly , from a relatively small sample of the data .",
    "it is to that issue that we turn next .",
    "in some real - world situations , it may be impractical to rebuild forecast models at every step , as we have done in the previous sections of this paper  because of computational expense , for instance , or because the data rate is very high . in these situations",
    ", one may wish to predict @xmath10 time steps into the future , then stop and rebuild the model to incorporate the @xmath10 points that have arrived during that period , and repeat .",
    "in chaotic systems , of course , there are fundamental limits on prediction horizon even if one is working with infinitely long traces of all state variables .",
    "a key question at issue in this section is how that effect plays out in forecast models that use delay reconstructions from scalar time - series data . and",
    "since real - world data sets are not infinitely long , it is important to understand the effects of data length on the estimation of spi .",
    "the quantity of data used in a delay reconstruction directly impacts the usefulness of that reconstruction .",
    "if one is interested in approximating the correlation dimension via the grassberger - procaccia algorithm , for instance , it has been shown that one needs @xmath134 data points@xcite .",
    "those bounds are overly pessimistic for forecasting , however .",
    "for example , sugihara & may  @xcite used delay - coordinate reconstructions with @xmath28 as large as seven to successfully forecast biological and epidemiological time - series data sets that contain as few as 266 points . a key challenge , then , is to determine whether one s time series _ really _ calls for as many dimensions and data points as the theoretical results require , or whether one can get away with fewer dimensions  and how much data one needs in order to figure all of that out .",
    "we claim that spiis a useful solution to those challenges .",
    "as established in the previous sections , calculations of this quantity can reveal what dimension one needs to build a good delay reconstruction for the purposes of lma forecasting of nonlinear and chaotic systems . and , as alluded to in those sections , spican be estimated accurately from a surprisingly small number of points .",
    "the experiments in this section explore that intertwined pair of claims in more depth by increasing the length of the lorenz 96 traces and testing whether the information content of the state estimator derived from standard heuristics converges to the spi - optimal estimator .",
    "figure  [ fig : mytaudata ] shows the results .     in all cases .",
    "blue circles corresponds to an embedding dimension @xmath83 , purple diamonds to @xmath135 , and red xs to @xmath82 . ]     in all cases .",
    "blue circles corresponds to an embedding dimension @xmath83 , purple diamonds to @xmath135 , and red xs to @xmath82 . ]",
    "when the data length is short , the @xmath83 state estimator had the most information about the future .",
    "this makes perfect sense ; a short time series can not fully sample a complicated object , and when an ill - sampled high - dimensional manifold is projected into a low dimensional space , infrequently visited regions of that manifold can act effectively like noise . from an information - theoretic standpoint , this would increase the effective shannon entropy rate of each of the variables in the delay vector .",
    "in the i - diagram in figure  [ fig : mytau ] , this would manifest as drifting apart of the two circles , decreasing the shaded region that one needs to maximize for effective forecasting .",
    "if that reasoning is correct , longer data lengths should fill out the attractor , thereby mitigating the spurious increase in the shannon entropy rate and allowing higher - dimensional reconstructions to outperform lower - dimensional ones .",
    "this is indeed what one sees in figure  [ fig : mytaudata ] .",
    "for both the @xmath102 and @xmath101 traces , once the signal is 2 million points long , the four - dimensional estimator has caught up to and even exceeded the two - dimensional case .",
    "note , though , that the optimal spiof the @xmath82 reconstruction model is still lower than in the @xmath83 or @xmath136 cases , even at the right - hand limit of the plots in figure  [ fig : mytaudata ] .",
    "that is , even with a time series that contains @xmath137 points , it is more effective to use a lower dimensional reconstruction to make an lma forecast .",
    "but the really important message here is that spiallows one to determine the best reconstruction parameters _ for the available data _ , which is an important part of the answer to the challenges outlined at the beginning of this section .",
    "something very interesting happens in the @xmath83 results for lorenz 96 model with @xmath101 : the spicurve reaches a maximum value around 100,000 points and stops increasing , regardless of data length .",
    "what this means is that this two - dimensional reconstruction contains as much information about the future as can be ascertained from these data , suggesting that increasing the length of the training set would not improve forecast accuracy . to explore this",
    ", we constructed lma forecasts of different - length traces ( 100,0002.2 million points ) from this system , then reconstructed their dynamics with different @xmath28 values and the appropriate @xmath97 for each case . for @xmath83 ,",
    "both spiand @xmath68 results did indeed plateau at 100,000 points  at 5.736 and 0.0809 , respectively .",
    "as before , more data does afford higher - dimensional reconstructions more traction on the prediction problem : the @xmath135 forecast accuracy surpassed @xmath83 at around 2 million points ( @xmath138 ) . in neither case , by the way , did @xmath82 catch up to either @xmath83 or @xmath135 , even at 4 million data points .",
    "of course , one must consider the cost of storing the additional variables in a higher - dimensional reconstruction model , particularly in data sets this long , so it may be worthwhile in practice to settle for the @xmath83 forecast  which is only slightly less accurate and requires only 100,000 points .",
    "this has another major advantage as well .",
    "if the time series is non - stationary , a forecast strategy that requires fewer points can adapt more quickly .",
    "so far in this paper , we have considered forecasts that were constructed one step at a time and studied the correspondence of their accuracy with one - step - ahead calculations of spi . in this section ,",
    "we consider longer prediction horizons ( @xmath10 ) and explore whether one can use a @xmath10-step - ahead version of spi  i.e .",
    ", @xmath139 $ ] , with @xmath140to choose parameter values that maximize the information contained in each delay vector about the value of the time series @xmath10 steps in the future .",
    "one would expect the spi - optimal @xmath100 values for a given time series to depend on the prediction horizon .",
    "it has been shown , for instance , that longer - term forecasts generally do better with larger @xmath0@xcite , and conversely@xcite .",
    "it makes sense that one might need to reach different distances into the past ( via the span of the delay vector ) in order to reduce the uncertainty about events that are further into the future@xcite .",
    "these effects are corroborated by spi .",
    "figure  [ fig : l22pvstau ] demonstrates this in the context of the lorenz 96 system with @xmath102 , focusing on @xmath83 for simplicity .    ) on spi of the @xmath102 lorenz 96 system for a fixed reconstruction dimension ( @xmath83 ) .",
    "the traces in the image , starting from the top , correspond to prediction horizons of @xmath141 to @xmath142 . ]",
    "the topmost trace in this figure is for the @xmath141 case  i.e .",
    ", a horizontal slice of figure  [ fig : l96n22f5spi ] made at @xmath83 .",
    "the maximum of this curve is the optimal @xmath0 value ( @xmath97 ) for this reconstruction .",
    "the overall shape of this trace reflects the monotonic increase in the uncertainty about the future with @xmath0 that is noted on page  .",
    "the other traces in figure  [ fig : l22pvstau ] show spias a function of @xmath0 for @xmath143 , down to @xmath142 at the bottom of the figure .",
    "the lower traces do not decrease monotonically ; rather , there is a slight initial rise .",
    "this is due to the point made above about the span of the delay vector : if one is predicting further into the future , it may be useful to reach further into the past .",
    "in general , this causes the optimal @xmath0 to shift to the right as prediction horizon increases , going down the plot ",
    "i.e . , longer prediction horizons require a greater @xmath0 ( cf .",
    "@xcite ) . for very long horizons , the choice of @xmath0 appears to matter very little .",
    "in particular , spiis fairly constant and quite low for @xmath144 when @xmath145i.e .",
    ", regardless of the choice of @xmath0 , there is very little information about the @xmath10-distant future in any delay reconstruction of this signal for @xmath145 .",
    "this effect should not be surprising , and it is well corroborated in the literature .",
    "however , it can be hard to know _ a priori _ , when one is confronted with a data set from an unknown system , to know what prediction horizon makes sense .",
    "spioffers a computationally efficient way to answer that question .",
    "figure  [ fig : l22mytauhorizon ] shows a similar exploration of the other side of that question : the effects of the reconstruction dimension on spi , with @xmath0 fixed at 1 .    ) on spi of the @xmath102 lorenz 96 system for a fixed time delay ( @xmath84 ) and two different reconstruction dimensions .",
    "the red line is @xmath83 and the blue is @xmath146 , the value suggested for this signal by the technique of false neighbors . ]",
    "the @xmath83 state estimator contains more information about the future for short prediction horizons .",
    "this ties back to the discussion at the end of section  [ subsubsec : computer ] : low - dimensional reconstructions can work quite well for short prediction horizons .",
    "however , figure  [ fig : l22mytauhorizon ] shows that the full reconstruction is better for longer horizons .",
    "this is not terribly surprising , since a higher reconstruction dimension allows the state estimator to capture more information about the past .",
    "finally , note that spidecreases monotonically with prediction horizon for both @xmath83 and @xmath147 .",
    "this , too , is unsurprising .",
    "pesin s relation@xcite says that the sum of the positive lyapunov exponents is equal to the entropy rate , and if there is a non - zero entropy rate , then generically observations will become increasingly independent the further apart they are .",
    "this explanation also applies to figure  [ fig : l22pvstau ] , of course , but it does _ not _ hold for signals that are wholly ( or nearly ) periodic .",
    "recall that the col_majordynamics in section  [ subsubsec : computer ] were chaotic , but with a dominant unstable periodic orbit  which had a variety of interesting effects in the results .",
    "figure  [ fig : colmytauhorizon ] explores the effects of prediction horizon on those results .    ) on spi of the col_majorfor a fixed time delay ( @xmath84 ) and two different reconstruction dimensions .",
    "the red line is @xmath83 and the blue is @xmath130 , the value suggested for this signal by the technique of false neighbors . ]    not surprisingly , there is some periodicity in the spiversus @xmath10 relationships , but not for the same reasons that caused the stripes in figure  [ fig : colmytau ] . here ,",
    "the _ peaks _ in spioccur at multiples of the period .",
    "that is , the @xmath83 state estimator can forecast with the most success when the value being predicted is in phase with the delay vector .",
    "note that this effect is far stronger for @xmath83 than @xmath147 , simply because of the instability of that periodic orbit ; the visits made by the chaotic trajectory to that orbit are more likely to be short than long .",
    "as expected , spidecays with prediction horizon  but only at first , after which it begins to rise again , peaking at @xmath148 and @xmath149 .",
    "this may be due to a second higher - order unstable periodic orbit in the col_majordynamics .    in theory",
    ", one can derive rigorous bounds on prediction horizon .",
    "the time at which @xmath7 will no longer have any information about the future can be determined by considering : @xmath150}{h[x_{j+p}]}~,\\end{aligned}\\ ] ] i.e. , the percentage of the uncertainty in @xmath9 that can be reduced by the delay vector .",
    "generically , this will limit to some small value equal to the amount of information that the delay vector contains about any arbitrary point on the attractor . given some criteria regarding how much information above the `` background '' is required of the state estimator",
    ", one could use the @xmath151 versus @xmath10 to determine the maximum practical horizon .    in practice , one can select parameters for delay reconstruction - based forecasting by explicitly including the prediction horizon in the spifunction , fixing its value at the required value , performing the same search as we did in earlier sections over a range of @xmath28 and @xmath0 , and then choosing a point on ( or near ) the optimum of that spisurface . the computational and data requirements of this calculation , as shown in section  [ subsec : datalength ] , are far superior to those of the standard heuristics used in delay reconstructions .",
    "in this paper , we have described a new metric for quantifying how much information about the future is contained in a delay reconstruction . using a number of different dynamical systems",
    ", we demonstrated a direct correspondence between the spivalue for different delay reconstructions and the accuracy of forecasts made with lorenz s method of analogues on those reconstructions . since spican be calculated quickly and reliably from a relatively small amount of data , without needing to know anything about the governing equations or the state space dynamics of the system , that correspondence is a major advantage , in that it allows one to choose parameter values for delay reconstruction - based forecast models without doing an exhaustive search on the parameter space .",
    "significantly , spi - optimal reconstructions are better , for the purposes of forecasting , than reconstructions constructed using standard heuristics like mutual information and the method of false neighbors , which can require large amounts of data , significant computational effort , and expert human interpretation .",
    "spiallows us to answer other questions regarding forecasting with theoreticaly unsound models@xcite  e.g .",
    ", why one can obtain a better forecast using a low - dimensional reconstruction than with a full embedding .",
    "it also allows one to understand bounds on prediction horizon without having to estimate lyapunov spectra or shannon entropy rates , which are difficult to obtain for arbitrary real - valued time series .",
    "that , in turn , allows one to tailor one s reconstruction parameters to the amount of available data and the desired prediction horizon  and to know if a given prediction task is just not possible .",
    "the explorations in this paper involve a simple near - neighbor forecast strategy and state estimators that are basic delay reconstructions of raw time - series data .",
    "the definition and calculation of spido not involve any assumptions about the state estimator , though , so the results presented here should also hold for other state estimators .",
    "for example , it is common in time - series prediction to pre - process one s data : for example , low - pass filtering or interpolating to produce additional points . calculating spiafter performing such an operation will accurately reflect the amount of information in that new time series  indeed , it would reveal if that pre - processing step _ destroyed _ information . and",
    "we believe that the basic conclusions in this paper extend to other state - space based forecast schemas besides lorenz s method of analogues , such as those used in @xcite  although spimay not accurately select optimal parameter values for strategies that involve post - processing the data ( e.g. , ghkss@xcite ) .",
    "we are in the process of exploring this .",
    "there are many other interesting potential ways to leverage spiin the practice of forecasting . if the spi - optimal @xmath152 , that may be a signal that the time series is undersampling the dynamics and that one should increase the sample rate .",
    "one could use spiat a finer grain to optimizing @xmath0 individually for each dimension , as suggested in  @xcite . to do this",
    ", one could define @xmath153 $ ] and then simply maximize spiusing that state estimator constrained over @xmath154 .",
    "10 url # 1`#1`urlprefixhref # 1#2#2 # 1#1                    t.  buzug , g.  pfister , optimal delay time and embedding dimension for delay - time coordinates by analysis of the global static and local dynamical behavior of strange attractors , physical review a 45 ( 1992 ) 70737084 .",
    "t.  sauer , time - series prediction by using delay - coordinate embedding , in : time series prediction : forecasting the future and understanding the past , santa fe institute studies in the sciences of complexity , santa fe , nm , 1993 .",
    "z.  alexander , t.  mytkowicz , a.  diwan , e.  bradley , measurement and dynamical analysis of computer performance data , in : proceedings of advances in intelligent data analysis ix , vol .",
    "6065 , springer lecture notes in computer science , 2010 .",
    "a.  a. tsonis , j.  b. elsner , k.  p. georgakakos , estimating the dimension of weather and climate attractors : important issues about the procedure and interpretation , journal of the atmospheric sciences 50  ( 15 ) ( 1993 ) 25492555 ."
  ],
  "abstract_text": [
    "<S> delay - coordinate reconstruction is a proven modeling strategy for building effective forecasts of nonlinear time series . </S>",
    "<S> the first step in this process is the estimation of good values for two parameters , the time delay and the embedding dimension . </S>",
    "<S> many heuristics and strategies have been proposed in the literature for estimating these values . </S>",
    "<S> few , if any , of these methods were developed with forecasting in mind , however , and their results are not optimal for that purpose . </S>",
    "<S> even so , these heuristics  intended for other applications  are routinely used when building delay coordinate reconstruction - based forecast models . in this paper </S>",
    "<S> , we propose a new strategy for choosing optimal parameter values for forecast methods that are based on delay - coordinate reconstructions . </S>",
    "<S> the basic calculation involves maximizing the shared information between each delay vector and the future state of the system . </S>",
    "<S> we illustrate the effectiveness of this method on several synthetic and experimental systems , showing that this metric can be calculated quickly and reliably from a relatively short time series , and that it provides a direct indication of how well a near - neighbor based forecasting method will work on a given delay reconstruction of that time series . </S>",
    "<S> this allows a practitioner to choose reconstruction parameters that avoid any pathologies , regardless of the underlying mechanism , and maximize the predictive information contained in the reconstruction . </S>"
  ]
}