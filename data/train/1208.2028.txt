{
  "article_text": [
    "the cosmic bulk flow is the streaming motion of the galaxies surrounding our milky way system , due to the gravitational pull of cosmic structure on large scales . in the gravitational instability paradigm , for a galaxy at position @xmath9 ,",
    "the peculiar velocity of an individual galaxy at time @xmath10 is given by @xcite @xmath11where @xmath12 is the density contrast at position @xmath9 , @xmath6 is the fractional matter density , and @xmath13 is the hubble constant .",
    "the bulk flow is normally considered as an average over a sufficiently large volume , with some window function @xmath14 , so that the above linear perturbation theory is applicable .",
    "this average is defined as @xcite @xmath15 where @xmath16 is the 3-d peculiar velocity field at time @xmath10 , defined in eq .",
    "( [ pecu_def ] ) . a complete investigation of bulk flows of nearby galaxies should measure the individual velocities of galaxies all over the observed volume .",
    "however , realistic observational techniques , such as the tully - fisher relation , only allow us to probe the radial component of the peculiar velocities of galaxies .",
    "in addition , most of the current observations can only cover a patch of sky with limited depth , leading to large uncertainties when interpreting the results .",
    "of course , none of these considerations are new .",
    "there is already a large literature on the study of the peculiar velocity field , with particularly intense activity in the early 1990s ( see overviews in * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) . investigating the relationship between velocities and densities has great potential for constraining cosmological parameters , and testing theories of gravity on large scales .",
    "however , it has long been realised that the construction of appropriate catalogues is difficult , and that systematic effects can easily overwhelm statistical noise .    in attempting to overcome these observational limitations ,",
    "there have been significant recent efforts in the community to reconstruct bulk flow moments from the limited data available , and to test their consistency with the @xmath1cdm cosmology .",
    "one of the important issues lies in determining the proper weighting for individual galaxy velocities in a catalogue in order to obtain streaming motions .",
    "some of the published studies , such as @xcite and @xcite , focus on a weighting scheme that produces the maximum likelihood estimate of the bulk flow ( see also * ? ? ?",
    "* ) , which can minimise the measurement noise . however , this weighting depends on the particular survey geometry and statistical properties , which leads to a large uncertainty when interpreting the constraints from combined data sets .",
    "@xcite proposed another method of estimating the bulk flow of galaxy peculiar velocities .",
    "they focused on the problem of how realistic surveys can be used to reconstruct the bulk flow at a given depth .",
    "they developed a minimum variance weighting method @xcite , which minimises the variance between the real data catalogue and the ideal survey , and they applied it to combined catalogues of peculiar velocity surveys .",
    "surprisingly , they found a very large bulk flow on @xmath0 scales ( @xmath17 ) towards @xmath18 , @xmath19 , which prefers a large amplitude of fluctuations ( @xmath5 ) , inconsistent with the _ wmap _ 5-year results @xcite .",
    "subsequent work has discussed a possible explanation for this large bulk flow related to pre - inflationary isocurvature perturbations @xcite .",
    "contradicting the claim in @xcite , @xcite developed a method termed the asce ( all space constrained estimate ) which reconstructs the bulk flow from an all - space 3-d velocity field to match the inverse tully - fisher relation . by applying this method , as well as the maximum likelihood method @xcite , to the spiral field @xmath20-band survey ( sfi++ survey , @xcite ) catalogue , @xcite found the bulk flow on a sphere of @xmath21 radius to be @xmath22 , towards ( @xmath23)=(@xmath24 ) , which is close to the results from the maximum likelihood method .",
    "the estimated cosmological parameters , i.e.@xmath25 , are consistent with the @xmath1cdm model . however , since @xcite only used the sfi++ data set , it is still not clear whether it is the other data sets used in @xcite which led to the significantly different results .",
    "any analysis which claims to strongly rule out the simple inflationary @xmath1cdm model deserves careful scrutiny , since a confirmed discordance would have profound consequences for our understanding of the large - scale universe .",
    "we can identify four potential problems in @xcite which may potentially skew the likelihood and bias the results .",
    "firstly , the inhomogeneous malmquist bias is not corrected for in most catalogues , for example : enear @xcite ; sn @xcite ; sc @xcite ; efar @xcite ; and willick @xcite .",
    "this deficiency can significantly bias the distance estimates .",
    "secondly , the distance errors from the tully - fisher and fundamental plane methods can be comparable to the measured velocities as the surveys go deeper , and moreover a simple model of gaussian errors is almost certainly inappropriate as systematics come to dominate the distance estimation .",
    "therefore the velocity data beyond @xmath26 become both very noisy and unreliable in assessing the bulk flow .",
    "thirdly , directly combining various catalogues with different calibration methods can also induce systematic errors and a spurious flow .",
    "finally , the assumption of a unique small scale velocity dispersion @xmath27 may be too small for some of the surveys ( e.g. sfi++ prefers @xmath28 , @xcite ) , perhaps skewing the constraints on the cosmological parameters @xmath5 and @xmath6 .",
    "the purpose of this paper is to investigate carefully the analysis presented in @xcite , and to combine each catalogue with a bayesian hyper - parameter method to test for consistency with the usual @xmath1cdm perturbation theory .",
    "as we have seen from @xcite , different statistical methods should not dramatically alter the results , so we will focus on the ` minimal variance ' scheme @xcite .",
    "a further motivation for this paper is as an extension to the velocity - gravity comparison work we have already carried out in @xcite . in that paper",
    "we compare the observational peculiar velocity data with the reconstructed velocity field from the _ iras _ pscz catalogue , and fit the linear growth rate parameter , @xmath29 . in this new paper",
    ", we do not discuss the small - scale modes , but will reconstruct the bulk motion of galaxies on distances @xmath30mpc .",
    "we will perform a direct comparison between observational data and @xmath1cdm model predictions for the bulk flow velocity , and constrain the cosmological parameters @xmath31 and @xmath32 .",
    "in addition , we will extend the minimal variance scheme suggested in @xcite and @xcite to a multishell likelihood method .",
    "furthermore , we will directly investigate the reason for the apparently large flows found in @xcite and @xcite .",
    "this paper is organised as follows .",
    "we first list the data sets used in section  [ vel_data ] , and then discuss the data selection criterion in section  [ dataselect ] . for the selected data , we correct the inhomogeneous malmquist bias for the distance estimate ( section  [ mbcorrect ] ) . in section  [ mv_scheme ] ,",
    "we first illustrate how to quantify the variance of the bulk flow at any particular depth ( section  [ mean_s_v ] ) , then we review the minimum variance weighting scheme proposed in @xcite to measure the bulk flow at a given depth ( section  [ vel_mv ] ) , and furthermore we present the likelihood function for each individual catalogue ( section  [ individual_like ] ) and the hyper - parameter approach used to combine different data sets ( section  [ vel_bayes_combine ] ) .",
    "then in section  [ result_discuss ] we compare our findings with those in @xcite .",
    "we first confirm that we can accurately reproduce the results in @xcite by adopting the same conventions ; then in section  [ bfmoment ] we show our constraints on bulk flow moments by performing the full likelihood analysis for each individual catalogue rather than the combined catalogue . in section  [ cosmologypara ] , we apply the bayesian hyper - parameter method to combine the likelihoods of different catalogues , in order to avoid the systematics that may affect the constraints .",
    "this allows us to assess the consistency of each individual catalogue , and to work out the cosmological parameters in the combined likelihood . in section  [ correlation - depth ]",
    ", we extend our likelihood analysis to consider bulk flows in multiple shells in a survey , and their covariance matrix , and we compare our findings with _ wmap _",
    "7-year best - fit values and the results from @xcite .",
    "our discussion and conclusion are summarised in section  [ vel_conclude ] .",
    "note that although @xmath33 ( @xmath34 ) is now determined with reasonable accuracy , throughout this paper we continue to adopt the convention of giving distances in units of @xmath35 for ease of comparison with previous results .",
    "we will use four different samples coming from recent peculiar velocity surveys to reconstruct the bulk flow .",
    "these samples are listed from the nearest to the most distant ( see also @xcite ) .",
    "our four samples consist of the enear catalogue @xcite , the sn catalogue @xcite , the sfi++ catalogue @xcite and the a1sn catalogue @xcite . for detailed discussion and analyses of these four samples , including their characteristic depths , typical distance errors and data compilation , we refer readers to section 3 of @xcite .",
    "we should mention that in @xcite and @xcite five other catalogues , namely sbf @xcite , sc @xcite , smac @xcite , efar @xcite and willick @xcite , were used to reconstruct the bulk flow of galaxies .",
    "in contrast to the previously described four catalogues , these samples are either very distant and therefore have large errors , or very sparse in which case the survey geometry is complicated .",
    "@xcite combined these five low - quality catalogues with the previous four higher quality catalogues to form a larger ` composite ' catalogue , and found an excess power of flow on scales of @xmath0 . however , there is potential danger in combining various catalogues with different calibration schemes .",
    "one concern is that the very distant samples with large systematics may be inducing a spurious large - scale flow .    in order to investigate this we tried to reproduce the ` excess flow ' effect by using the suspicious composite catalogue",
    "( see section  [ mv_scheme ] ) .",
    "however , in the subsequent more careful analysis , we will only use the enear , sn , a1sn and sfi++ catalogues , with the following data selection criterion and malmquist bias correction .",
    "we listed four different peculiar velocity catalogues in section  [ vel_data ] . in these catalogues , the samples beyond the @xmath36 scale",
    "are also quite sparse and suffer from large errors due to uncertainties in the distance indicators ; therefore we trim the data sets at @xmath36 in order to reconstruct the bulk flow moments accurately on the @xmath0 scale .",
    "in addition , since some of the samples in the sfi++ catalogue with @xmath37 are affected by localised non - linear structures , giving very large velocities @xcite , we excluded these high velocity samples ( @xmath38 ) from the sfi++ catalogue .",
    "the classification of the data in each catalogue is listed in table  [ tab1 ] .",
    "@lcc & @xmath39 & @xmath40 +  enear & @xmath41 & @xmath42 +  sn & @xmath43 & @xmath44 +  sfi++ & @xmath45 & @xmath46 +  a1sn & @xmath47 & @xmath48 +          in the above description of velocity catalogues , two different distance indicators , the tully - fisher relation and the fundamental plane method , have been used for determining the sfi++ and enear distances .",
    "in addition , supernova luminosities are used in calibrating the distance of the sn and a1sn catalogues .",
    "the large scatter of distance indicators suggests that objects with inferred distance @xmath49 , may come from a wide range of possible true distances .",
    "the effect usually referred to as malmquist bias @xcite is related to the probability distribution of true distance @xmath50 , given the measured distance @xmath49 with its measurement error .",
    "the desired function is @xcite @xmath51 ^ 2}{2 \\delta^{2 } } \\right ) }   { \\int^{\\infty}_{0 } dr\\ , r^{2}n(r )   \\exp\\left(- \\frac{[\\ln(r / d)]^2}{2 \\delta^{2 } } \\right ) } , \\label{mbp1}\\end{aligned}\\ ] ] where @xmath52 is the radial density distribution , and @xmath53 is the fractional distance uncertainty of distance indicators .",
    "note that for the tully - fisher and fundamental plane methods , the typical errors are around @xmath54 per cent , and for type ia supernovae , the typical error is around @xmath55@xmath56 per cent .",
    "the simplest case is _ homogeneous malmquist bias _",
    "@xcite , in which , the number density is constant , so that eq .",
    "( [ mbp1 ] ) becomes independent of density , with @xmath57 ^ 2}{2 \\delta^2}\\right)}\\right],\\end{aligned}\\ ] ] where @xmath58 is the ratio between the true distance and the measured distance .",
    "one can verify that the expectation of @xmath50 , @xmath59 .",
    "this means that even for a constant density distribution of galaxies , the distance indicator is still generally biased .",
    "this is due to the fact that , near the measured distance @xmath49 , there are more galaxies in shells of larger distance than smaller distance , so it is more probable that the true distance is greater than the measured distance i.e.  @xmath60 .",
    "however , in the more general case , the gradient of the number density is not negligible , and this either reinforces or works against the volume effect ",
    "_ inhomogeneous malmquist bias_. if the gradient of the number density is positive , there will be even more galaxies at the larger distances than in the constant density case , i.e.  the inhomogeneity reinforces the homogeneous malmquist bias ; on the other hand , if the gradient is negative , then the effective is opposite , and the inhomogeneous malmquist bias partially cancels the homogeneous malmquist bias effect .    to quantify the inhomogeneous malmquist bias correctly , we use the real - space reconstructed positions of the pscz galaxies as mass tracers to interpolate the mass density field on a cubic grid of length @xmath61 and mesh size @xmath62 , smoothed with a gaussian filter of @xmath63 .",
    "the field on the lattice is then interpolated along the line of sight to each object in the catalogue .",
    "the value of @xmath52 along the line of sight is specified at the position of @xmath64 equally - spaced points , with a binning of @xmath62 . finally , eq .  ( [ mbp1 ] )",
    "is used to predict @xmath50 from @xmath49 using a monte carlo rejection procedure .",
    "we re - examine the catalogues described in section  [ vel_data ] , and correct for malmquist bias according to eq .",
    "( [ mbp1 ] ) for the enear , sn and a1sn samples .",
    "we plot the measured distance ( before malmquist bias correction ) and corresponding true distance ( after malmquist bias correction ) in the left panel of fig .",
    "[ mbcorrect ] .",
    "one can see that removing the bias tends to place galaxies at larger distances , although the shift is not very significant .",
    "the right panel of fig .",
    "[ mbcorrect ] shows the comparison between the uncorrected and corrected line - of - sight peculiar velocities .",
    "for linear perturbation theory within the @xmath1cdm paradigm , the velocity field at any spatial point @xmath65 is directly related to the underlying density field through eq .",
    "( [ pecu_def ] ) . what we are interested in is the bulk flow moment of the velocity field in a spherical region .",
    "therefore in this section , we first calculate the mean - squared variance of the bulk flow ( in eq .",
    "( [ bulk_def ] ) ) which can be used to quantify the amplitude of the flow at different depths .",
    "then we will review the ` minimum variance ' method for weighting the data sets on different scales .",
    "finally we will present the likelihood function that can be used to constrain cosmology with the measured bulk flow .",
    "real surveys can only observe galaxies out to a particular depth @xmath66 , which means that the ` window function ' has a sharp cut - off : @xmath67 therefore , by measuring only a galaxy sample within this sphere of radius @xmath68 one can calculate the ` streaming motion ' through eq .",
    "( [ bulk_def ] ) by averaging the velocity within the sphere .",
    "the mean - squared velocity of the spherical region within radius @xmath66 is therefore ( see also @xcite)@xmath69 at the present epoch @xmath70 and @xmath71 , so today @xmath72 we expect eq .",
    "( [ vbulk1 ] ) to be useful for quantifying the non - zero velocity fluctuations of our local surroundings . for the _ wmap _ 7-year cosmological parameters @xcite , the typical bulk flow magnitude on a scale of @xmath73 from eq .",
    "( [ vbulk1 ] ) is @xmath74 .",
    "we will compare this theoretical value with the measured velocity catalogues .",
    "bulk flow estimates are essentially weighted averages of the individual velocities in a galaxy survey @xcite .",
    "previous work , such as @xcite and @xcite , focused on the estimate that minimises the uncertainties due to measurement noise , i.e.  the maximum likelihood estimation scheme , but did not make any correction for the survey geometry . thus the maximum likelihood bulk flow is obviously dependent on a given survey s particular geometry and statistical properties . on the other hand ,",
    "@xcite and @xcite instead addressed the question of how peculiar velocity data can be used to statistically estimate a more specialised quantity , the bulk flow of an ideal , densely - sampled survey with a given depth .",
    "they developed a ` minimal variance ' weighting scheme which produces an estimate of the bulk flow at any particular depth .",
    "they found an excess in the power of the bulk flow on scales of @xmath0 , which seems to exceed the @xmath1cdm predictions at the @xmath75 level . in the following",
    ", we will first review the minimum variance weighting scheme developed in @xcite and @xcite and then present the likelihood function for cosmological parameters .",
    "a realistic survey consists of @xmath76 objects on the sky having position @xmath77 and measured line - of - sight velocity @xmath78 , with measurement error @xmath79 .",
    "the measured line - of - sight velocity is assumed to have the form @xmath80 , where @xmath81 is the galaxy line - of - sight velocity in the matter rest frame , and @xmath82 is a superimposed gaussian random motion with variance @xmath83 , where @xmath84 accounts for the 1-d small - scale velocity dispersion .    given an idealised survey with bulk flow velocity @xmath85 ( @xmath86 ) at a particular depth @xmath66 , we need to determine the weight @xmath87 which makes the ` linear compression ' @xmath88 give the closest approximation of @xmath85 @xcite . at the same time",
    ", the line - of - sight velocity at position @xmath77 should take the form @xmath89 . in order for the estimator @xmath90 to give the correct amplitude of the velocity @xmath85 , i.e.  @xmath91",
    ", the weight function @xmath87 has to satisfy the following constraint :    @xmath92    we can apply the lagrange multiplier approach to minimise the average variance @xmath93 , i.e.  minimise the following quantity @xcite @xmath94 by plugging in eq .",
    "( [ ucompress ] ) , one can expand the first term and obtain @xmath95 in order to find the weight function @xmath87 that can minimise the variance , we take the derivative of the above equation and equate it to zero : @xmath96 from eq .",
    "( [ weight_func1 ] ) , one can solve for the weight function @xmath87 as @xmath97 , \\label{w_func1}\\ ] ] where @xmath98 is the covariance matrix for the measured velocity .",
    "since @xmath80 as described above , one can write the covariance matrix @xmath99 as @xmath100 since @xmath81 and @xmath82 are not correlated .",
    "the first term is the real space velocity correlation function , which is related to the matter power spectrum in fourier space , @xmath101 where the window function , @xmath102 can be calculated analytically @xcite .",
    "the correlation term @xmath103 is the average product of measured velocity @xmath104 with the ideal bulk flow moment @xmath85 .",
    "the ideal bulk flow moment @xmath85 is the average of the random velocities in an isotropic survey region .",
    "we assume that the survey is a spherical region with radius @xmath66 , therefore we generate @xmath105 random velocities in the top - hat region @xmath66 and calculate @xmath106 as @xmath107 where the line - of - sight velocity correlation @xmath108 can be calculated in the same manner as eq .",
    "( [ vel_rnrm1 ] ) .    therefore , the only unknown in eq .",
    "( [ w_func1 ] ) is the lagrange multiplier matrix @xmath109 .",
    "we can plug eq .",
    "( [ w_func1 ] ) into the constraint equation ( [ weightconstr ] ) to solve for @xmath110 : @xmath111 m_{lq}^{-1 } , \\label{vel_lambda_mat}\\]]where the matrix @xmath112 is given by @xmath113 to summarise , by simulating an ideal survey at depth @xmath66 and using eqs .",
    "( [ vel_gnm1 ] ) , ( [ vel_smup1 ] ) , ( [ vel_lambda_mat ] ) and ( [ vel_mmatrix ] ) , one can calculate the weight function @xmath87 in eq .",
    "( [ w_func1 ] ) and hence obtain the bulk flow moment at depth @xmath66 according to eq .",
    "( [ ucompress ] ) .",
    "once we obtain the bulk flow moment from the minimum variance weighting scheme , we can calculate the covariance matrix and therefore perform a full statistical analysis .",
    "the covariance matrix of @xmath90 becomes @xmath114 which can be broken down into an instrumental noise term @xmath115 and a cosmic variance term @xmath116 where the angle - averaged window function is @xmath117 this window function describes the scale in @xmath118-space that the catalogue actually probes . as an example , we plot this window function for the enear catalogue at depth @xmath73 in fig .  [ reproduce1]a .",
    "as expected , it matches the window function of enear as shown in figure 3 in @xcite perfectly well .",
    "the shape of the curves reveal that the window function decays rapidly for @xmath118 beyond @xmath119 , therefore the non - linear regime of the matter power spectrum does not contribute to the bulk flow moment ",
    "bulk flow moments reflect perturbations on large scales , @xmath120 .          given the reconstructed bulk flow moment at some depth @xmath66 and its covariance matrix @xmath121 ( [ covar1 ] ) , the likelihood of cosmological parameters @xmath122 is @xmath123 since the major effect of the constraints is on the amplitude and shape of the matter power spectrum , in the following analysis we will only vary @xmath5 and @xmath6 , while fixing the other parameters at the _ wmap _ values .",
    "we compute the bi - variate likelihood and marginalise one parameter to obtain the 1-d posteriori distribution of the other parameter .    in order to demonstrate the accurate reproduction of the results in @xcite",
    ", we use the same set of _ wmap _ 5-year best - fit parameters @xcite : @xmath124 ; @xmath125 ; @xmath126 ; @xmath127 ; @xmath128 ; plus small - scale velocity dispersion @xmath129 .",
    "we also use the approximation @xmath130 to calculate the matter power spectrum ( see appendix [ powerspectrum_form ] for comparison with the numerical result ) , as is used in @xcite . in fig .",
    "[ reproduce1 ] we show that we can accurately reproduce the window function @xmath131 ( see eq .",
    "( [ vel_w2pq ] ) ) and marginalised distribution of @xmath5 , as shown by the black line in fig .",
    "[ reproduce1]b .",
    "these curves are very close to those shown as figures  3 and 7 of @xcite .",
    "in addition , since we will not use the sbf , sc , smac , efar and willick catalogues here , we need to test whether this ` removal ' of data can substantially change the result . to do this",
    ", we use the rest of the data in the composite catalogue , i.e.  the combination of the sn , enear and sfi++ catalogues ( 4256 samples in total ) , and keep all other conventions the same as in @xcite to calculate the likelihood of @xmath31 , and we obtain the red line in fig .",
    "[ reproduce1]b . comparing with the black line",
    ", one can see that the removal of these sparse and distant samples can move the peak of the likelihood towards lower values , but a very high value of @xmath31 is still preferred compared with the _ wmap _ constraint ( dashed line ) .",
    "therefore , the excessive power in the bulk flow on @xmath0 scales is not completely driven by the inclusion of five sparse and fairly noisy samples  we need to investigate further to understand the reasons .",
    "we make the following adjustments to the model parameters in order to precisely compare the velocity field prediction with the observational data :    * we use _ wmap _ 7-year best - fit cosmological parameters @xcite to compute our prediction , i.e.  @xmath132 , @xmath133 , @xmath134 , @xmath135 and @xmath136 ; * we use the value @xmath137 for the intrinsic velocity dispersion , . ] in order to compute the covariance matrix ( eq .  ( [ noise_mat1 ] ) ) , since @xcite showed that this value is preferred for most catalogues ; * in the formula for @xmath138 , we use the numerical result from camb @xcite instead of @xmath139 to compute the power spectrum , with the difference between the numerical result and the parameterisation @xmath139 being shown in appendix  [ powerspectrum_form ] .      in @xcite ,",
    "the combined catalogue , referred to as ` composite ' is used to reconstruct the bulk flow and constrain the cosmological parameters @xmath5 and @xmath6 .",
    "they found an excess power in the bulk flow on a scale of @xmath0 , which suggests a high value of @xmath5 compared with the constraints from _ wmap _ 5-year results",
    "@xcite  see fig .",
    "[ reproduce1]b .    directly combining a variety of catalogues with different calibration methods and systematics may not be a precise way of exploring the combined constraints .",
    "another way of carrying out the combination is to first compute the likelihood of individual data sets , and then directly combine them by multiplication , i.e.@xmath140 where @xmath76 is the number of data sets .",
    "such a procedure assumes that the quoted observational random errors can be trusted , and that the two ( or more ) @xmath141 statistics have equal weights , so that @xmath142 however , when combing different data sets , one often wants to assign different weights to them .",
    "@xcite describe an approach ( see also * ? ? ?",
    "* for an earlier application of the same idea in astrophysics ) using @xmath143where the @xmath144 are ` hyper - parameters ' , which are to be evaluated in a bayesian way . here @xmath141 for each data set is @xmath145^{2}}{\\sigma_{i}^{2}},\\ ] ] where the summation is over @xmath76 measurements and @xmath79 is the error for each data point . by multiplying @xmath141 by @xmath146 , each error",
    "@xmath79 effectively becomes @xmath147 and therefore if an experiment underestimates ( or overestimates ) the systematic errors , the hyper - parameter can scale the error by using relative weights . indeed , the hyper - parameters are useful in assessing the relative weight for each different experiment .",
    "this procedure gives an objective diagnostic for revealing experiments with problematic error estimates and which therefore deserve further investigation of their systematic or random errors .",
    "it is worth clarifying that , in principle , the systematic effects could have two different components , either an overall multiplicative factor for the velocities , or else an extra contribution to the measurement noise . although the former kind of systematic effect would be appropriate for some other kinds of data ( particularly where the dominant uncertainty is a linear calibration factor ) , the effect on the peculiar velocity field is more complicated than this .",
    "we therefore focus our attention on modelling the systematics as an additional source of noise , effectively giving a different weighting of the signal - to - noise of each data set . for a discussion of related issues in other branches of astrophysics see for example @xcite and @xcite .    in the same spirit of assigning weights to each data set ,",
    "@xcite calculated the joint distribution of cosmological parameters for multiple data sets , in which the weight assigned to each is determined directly by its own statistical properties .",
    "the weights are considered in a bayesian context as a set of hyper - parameters , which are then marginalised over in order to recover the posterior distribution as a function only of the cosmological parameters of interest . in the case of a gaussian likelihood function",
    ", this marginalisation can be calculated analytically , and it is shown that the joint probability distribution , @xmath148 , when applying the hyper - parameter approach is @xmath149 where @xmath150 and @xmath151 are the number of data , covariance matrix and @xmath141 for the @xmath118th data set . in our approach ,",
    "flat priors on @xmath5 and @xmath6 are assumed .",
    "we will use eq .",
    "( [ hyper_comb ] ) to explore the use of different catalogues to constrain cosmological parameters .    once the distribution of eq .",
    "( [ hyper_comb ] ) is calculated , the hyper - parameter is already marginalised over , which means that it automatically incorporates the relative weights between each data set and combines them in an objective way . therefore ,",
    "rather than using the composite catalogue to constrain cosmology , we will first investigate the individual likelihoods for each data set , and use the joint distribution in eq .",
    "( [ hyper_comb ] ) to combine these data sets .",
    "in this section , we will perform two different analyses separately .",
    "the first one , in section  [ bfmoment ] and [ cosmologypara ] , will focus on reconstructing @xmath152 on @xmath73 scales , and use it to constrain cosmological parameters . in the second analysis",
    ", we will extend the ` minimal variance ' scheme to consider the cumulative bulk flow at different radii , and to explore the joint constraints on cosmology from all the bulk flows in different shells .",
    "we now present our results on reconstructing bulk flow moments using the minimum variance method on @xmath0 scales ( eq .  ( [ ucompress ] ) ) . in fig .",
    "[ bffig1]a , the magnitude of the bulk flow is plotted for the four different catalogues .",
    "theoretically , the magnitude of bulk flow @xmath153 follows the maxwellian distribution , i.e. @xmath154 \\frac{dv}{\\sigma_{v}},\\ ] ] where @xmath155 is the velocity dispersion parameter @xcite . we calculate it as @xmath156 , where @xmath157 is the covariance matrix ( eq .",
    "( [ covar1 ] ) ) .",
    "one can see that sfi++ provides the tightest constraint on the bulk flow magnitude ; this is because it is the largest , densest and closest to full - sky survey available at the moment .",
    "in addition , enear ( 669 samples ) and a1sn ( 153 samples ) provide roughly similar constraints on the bulk flow .",
    "this is due to the fact that although the a1sn ( first amendment supernovae catalogue ) has less data than enear , its errors ( calibrated by luminosity distance ) are much smaller than for the fundamental plane distance estimates .    in fig .",
    "[ bffig1]a , one can also see that , although there are offsets between the peaks of the likelihood for each individual catalogue , they are all quite consistent with the theoretical prediction , which is the mean - squared velocity of a @xmath0 spherical region of @xmath158 ( see section  [ mean_s_v ] ) . therefore by correcting the inhomogeneous malmquist bias and properly selecting the samples , the four catalogues show a coherent flow on @xmath0 scales of about @xmath159 .",
    "in addition , we plot the constraint on the direction of the bulk flow in fig .",
    "[ bffig1]b , and compare these directions with those found in other studies . from the figure , we can see that sfi++ provides the tightest constraint on the bulk flow direction , and the constraints on the direction of the bulk flows are consistent with each other across all catalogues .",
    "we also mark the preferred direction of the bulk flow from other published estimates .",
    "we can see that our constraints are consistent with the directions obtained from @xcite , @xcite , @xcite , and @xcite , but @xcite prefer a slightly larger value for galactic latitude .",
    "the quantitative results for the four catalogues are listed in table  [ tab2 ] .",
    "@lccc & @xmath153 [ @xmath160 & @xmath161 [ degrees ] & @xmath162 [ degrees ] +  enear & @xmath163 & @xmath164 & @xmath165 +  a1sn & @xmath166 & @xmath167 & @xmath168 +  sn & @xmath169 & @xmath170 & @xmath171 +  sfi++ & @xmath172 & @xmath173 & @xmath174 +          we now turn to cosmological parameter estimation .",
    "we first apply the likelihood function ( eq .",
    "( [ like1 ] ) ) to to each individual catalogue to calculate @xmath175 , assuming a flat prior , and then combine different catalogues by using the hyper - parameter joint likelihood function of eq .",
    "( [ hyper_comb ] ) .",
    "we show our results in fig .",
    "[ cpconstrain ] .    in fig .",
    "[ cpconstrain]a , one can see that the posterior distribution for @xmath31 is highly skewed and has a fairly long tail out to large amplitudes , which suggests that the peculiar velocity data available at the moment still can not rule out flows with large amplitude .",
    "in addition , we can see that the sn catalogue peaks near the _ wmap _",
    "7-year @xmath31 value ( @xmath176 ) , while the sfi++ catalogue prefers a slightly higher value and a1sn and enear prefer smaller ones .",
    "however , within the errors they are all quite consistent with each other , and none of them are inconsistent with the _ wmap _ value of @xmath31 .    in fig .",
    "[ cpconstrain]b , we plot the constraints on the @xmath31@xmath6 plane by using the hyper - parameter likelihood function of eq .",
    "( [ hyper_comb ] ) .",
    "one can see that the _ wmap _ best - fit value is located close to the 68% contour in the @xmath31@xmath6 plane , and therefore the hyper - parameter results are consistent with the expectation from @xmath1cdm .",
    "comparing fig .",
    "[ cpconstrain]b with figure 6 in @xcite , one can see that our contour prefers a much lower value of @xmath5 , and it is also closer to the _ wmap _ value of @xmath6 .",
    "@lccc & @xmath6 & @xmath5 & references +  sfi++ multishells & @xmath177 & @xmath178 & this study +  enear multishells & @xmath179 & @xmath180 & this study +  _ wmap _ 7-year & @xmath181 & @xmath182 & @xcite +  sfi++ asce method & @xmath183 & @xmath184 & @xcite +    in the above approach , we use the reconstructed 3-d bulk flow velocity as the ` observational data ' to constrain cosmology .",
    "we have shown that this likelihood ( eq .  ( [ like1 ] ) ) can provide a fairly strong constraint on @xmath5 , but the constraint on @xmath6 is rather weak and thus the 2-d contours of @xmath5@xmath6 do not close .",
    "this is because we use only one velocity vector ( at @xmath73 ) as a constraint and this information is not enough to provide a tight limit ( see also figure @xmath55 in @xcite ) .",
    "based on the ` minimal variance ' scheme , here we propose another method to consider the bulk flow velocities for _ all _ of the shells within a certain radius .",
    "since bulk flow velocities on different shells are highly correlated , one needs to calculate the full - covariance matrix of those bulk flow velocities .",
    "note that we will apply this method to each individual data set to assess its validity for constraining cosmological parameters .    in the step of calculating @xmath103 ( eq .",
    "( [ vel_smup1 ] ) ) , we need to simulate @xmath185 random velocities in the top - hat region @xmath66 and therefore obtain the weighting function @xmath186 for a certain shell @xmath66 .",
    "let us assume we can sample multiple shells with this method , and therefore obtain the weighting function @xmath187 and bulk flow velocity @xmath188 for each shell @xmath66 .",
    "now we can calculate the covariance matrix of @xmath188s as ( @xmath189 are two shells ) @xmath190 which can be broken down into an instrumental noise term @xmath191 and a cosmic variance term @xmath192 where the angle - averaged window function is @xmath193 note that all of the shells are correlated .",
    "suppose we have @xmath112 shells , and now we arrange the bulk flow velocities of each shell into a @xmath194 velocity vector @xmath195 , where @xmath196 runs from @xmath197 to @xmath198 .",
    "for instance , the @xmath199-direction of bulk flow in shell @xmath200 is now at the position @xmath201 in the @xmath195 vector .",
    "we do the same thing for the covariance matrix , and therefore we turn the covariance matrix @xmath202 into a @xmath203 covariance matrix @xmath204 , where the @xmath205 part contains the cosmological parameters and @xmath206 includes measurement errors . now",
    "the likelihood function for multiple shells becomes @xmath207    we apply this likelihood function to the sfi++ and enear catalogues , since they are the deeper catalogues with the broader sky - coverage .",
    "the sfi++ catalogue has a mean distance of @xmath208 and extends out to @xmath209 , whereas the enear catalogue has a mean distance @xmath210 and goes out to @xmath211 .",
    "we first trim both data sets out to @xmath212 , which leaves @xmath213 ( sfi++ ) and @xmath214 ( enear ) samples .",
    "then we calculate the weighting functions @xmath186 and bulk flow velocities @xmath215 for @xmath56 different shells of distances @xmath54@xmath216 , each with @xmath217 separation .",
    "the reason we use the bulk flows only on shells with distances greater than @xmath218 is that we would like to avoid non - linear structures on small scales .",
    "in addition , more distant objects are not very well sampled and therefore are very sparse , so we restrict our bulk flows to within the shell of @xmath219 . during the process of computation , we stick to the same conventions as listed in section  [ individual_like ]",
    ". then we calculate the covariance matrix ( eq .",
    "( [ covar2 ] ) ) and the likelihood function ( eq .  ( [ like3 ] ) ) for the @xmath56 shells , and we obtain the marginalised distribution of @xmath6 and @xmath5 , as shown in figs .",
    "[ fig : sig8omg : shell]a and [ fig : sig8omg : shell]b .",
    "the joint distribution of @xmath5@xmath6 is shown in fig .",
    "[ fig : sig8omg : shell]c .    from fig .",
    "[ fig : sig8omg : shell]a and fig .",
    "[ fig : sig8omg : shell]c , one can see that the constraint on @xmath6 becomes tighter than the previous single bulk flow constraint and its @xmath220 contour is now closed .",
    "therefore , by just using bulk flow data , one can obtain an independent constraint on the cosmological parameters .",
    "the best - fit value of _ wmap _ 7-year results , as well as the constraints obtained from @xcite are all well within the @xmath221 confidence region of the parameter space .",
    "the reason that the likelihood function for multiple shells can give a reasonably good constraint on @xmath6 , while the bulk flow at @xmath73 does not , is that the the dependence of @xmath138 on @xmath6 is a function of scale , and therefore by incorporating multiple shells , one can gain more information on perturbations at different depths .",
    "we would also like to point out that since the current peculiar velocity data are no deeper than @xmath222 , and the data beyond @xmath223 are very noisy and sparse , the @xmath56 shell bulk flows at distances of @xmath54 to @xmath224 are really the maximal information we can obtain with these catalogues .",
    "we have carefully checked that , for the data within @xmath223 , splitting into more shells of bulk flows does not improve the constraints , since these shells are highly correlated and we already have enough shells to effectively capture the scale dependence .    in addition , we should note that there is another statistical approach , the multiple moment method @xcite , which has been proposed to reconstruct the bulk flow , shear , and octupole moments of perturbations .",
    "this can be considered as an alternative method to our multishell likelihood approach .",
    "the multiple moment method used in @xcite and @xcite considers perturbations only on @xmath73 scales , but includes all moments , and they find that there is excessive power for the bulk flow , but not for the other moments .",
    "in contrast , our multishell likelihood function focuses just on the bulk flow , and it reconstructs this for shells of different distance , quantifying the full covariance matrix by calculating the correlations between shells .",
    "our multishell likelihood shows that the bulk flow is not excessive compared with @xmath1cdm predictions , and that one can obtain reliable constraints on cosmological parameters by applying the method to various peculiar velocity catalogues .",
    "we list the numerical results of our cosmological parameter constraints in table  [ tab : comp1 ] .",
    "[ cols= \" < , < , < \" , ]     in this paper , we have been investigating bulk flow measurements using various catalogues .",
    "we find results which are different to those given by @xcite , who claimed evidence for a surprisingly large bulk flow on @xmath0 scales , apparently discrepant with the @xmath1cdm prediction .",
    "in contrast , by carefully considering four selected catalogues , we find a coherent flow of about @xmath225 on a scale of @xmath0 , entirely consistent with the value expected given the _ wmap _",
    "7-year cosmological parameters .    by employing the same weighting scheme and the same conventions , we are able to accurately reproduce the results in @xcite , as shown in fig .  [ reproduce1 ] .",
    "since we focus on the sn , sfi++ and enear catalogues , we removed the other sub - catalogues from the composite catalogue , and found a slightly lower value of @xmath31 ( red line in fig .",
    "[ reproduce1]b ) , but still higher than the _ wmap _ constraint .",
    "this indicates that the high value of @xmath31 inferred from the composite catalogue is not completely driven by the five deep and sparse catalogues included ( smac , sbf , sc , efar and willick ) .    to summarise the various other issues which could be responsible for the discrepancy , in table  [ tab3 ] we list several technical points which lead to quantitatively different results .",
    "the first issue is the assumption of small - scale velocity dispersion , which goes into the calculation of the covariance matrix ( eq .",
    "( [ noise_mat1 ] ) ) .",
    "@xcite assumed a value of @xmath226 , which is too small compared to the constraint obtained by @xcite , which was closer to the @xmath227 we chose here .",
    "besides this , @xcite used an inaccurate approximation for the matter power spectrum . from fig .",
    "[ pkcompare1 ] , one can see that although this is a small effect , it has the same sign , yielding smaller flows",
    ". thus , by fitting to the observed flows , this tends to further increase the normalisation parameter @xmath5 .",
    "the second major difference lies in the inhomogeneous malmquist bias correction . in @xcite , only the sfi++ and smac catalogues",
    "were corrected for this effect . in our approach",
    ", we used the full - sky density field from the pscz catalogue to extrapolate the density @xmath52 at any spatial position , and calculate the probability of the true distance @xmath50 given the measured distance @xmath49 ( eq .  ( [ mbp1 ] ) ) .",
    "the comparison between the measured distance / velocity and true distance / velocity in fig .",
    "[ mbcorrect ] , shows that the bias tends to move galaxies to smaller distances .",
    "another difference is that we only keep the high quality samples sn , sfi++ and enear from the @xcite compilation , and we further include the recent compilation of supernovae data , i.e.the a1sn catalogue . to remove any possible bias from the distant and sparsely sampled region , we restricted our attention to @xmath228 , and to avoid the results being driven by outliers , we also limited our samples to @xmath229 .    furthermore , rather than using the composite catalogue , we combined individual sample likelihoods using the bayesian hyper - parameter technique",
    "this should avoid the possibility that inconsistent data sets may bias the result if they are assigned equal weight . from the hyper - parameter likelihood",
    ", we find the best - fit value @xmath2 .",
    "this is somewhat low and hence inconsistent with a large bulk flow .",
    "however , the uncertainty is so large that this result is still consistent with standard @xmath1cdm expectations .    finally , we proposed a multishell likelihood method , which calculates the bulk flows in all shells within a certain radius together with their covariance matrix .",
    "this multishell likelihood takes into account the scale - dependence of the matter power spectrum @xmath138 on the @xmath6 parameter , and therefore maximises the constraining power one can obtain from a data set . by applying this likelihood to the sfi++ and",
    "enear catalogues , we showed that they can provide much stronger constraints on @xmath6 and @xmath5 than the single shell ( @xmath230 ) constraint .",
    "our result also shows consistency with _ wmap _ 7-year best - fits and results from @xcite .",
    "we conclude that the apparently large bulk flow on @xmath0 scales found by @xcite may not be a genuine flow . by correcting for malmquist bias , carefully selecting samples and examining assumptions",
    ", one finds that the current peculiar velocity field catalogues are consistent with the @xmath1cdm model . on the other hand ,",
    "any claimed discrepancy is not due to the ` minimal variance ' scheme proposed by @xcite and @xcite , since in our tests , we have shown that this scheme gives consistent results .",
    "in addition , our conclusions also agree with several other independent searches for bulk flows , such as the asce method with the sfi++ catalogue @xcite , the minimal variance method with the type - ia sn data @xcite , and the luminosity function method with the 2mrs samples @xcite .",
    "it should also be pointed out that the lack of evidence for a bulk flow on @xmath73 removes some of the support for an excessive flow @xmath231 on even deeper scales @xmath232 @xcite .",
    "it seems clear that , despite extensive effort for decades , peculiar velocity catalogues remain systematics dominated . by applying different , but apparently reasonable , assumptions and statistical approaches , it is possible to find quite discrepant results using essentially the same data sets .",
    "this means that the realistic error bars are probably larger than given in many of the published studies .",
    "in addition , one should notice that there are many other methods developed to compute bulk flows that do not rely on distance indicators , such as luminosity fluctuations and fluctuations in the galaxy number density @xcite , as well as the use of the kinetic sunyaev - zeldovich effect ( e.g. @xcite ) .",
    "although they also suffer from systematic effects , these will be of a different nature and therefore such approaches can be regarded as complementary to the method discussed here .",
    "large - scale bulk flows still offer promise for constraining cosmological models , but fully realising that promise will require further improvements in the construction of catalogues , and in the control of the systematic effects which continue to plague this field .    0.1 truein    * acknowledgments : * we would like to thank michael hudson and stephen turnbull for sharing with us the first amendment supernovae compilation , and enzo branchini and george efstathiou for helpful discussions .",
    "this research was supported by the natural sciences and engineering research council of canada .",
    "yzm is supported by a cita national fellowship .",
    "to sample the @xmath5@xmath6 parameter space , we can apply a formula to generate the matter power spectrum @xmath138 .",
    "we use the following semi - analytic equation as presented in @xcite :      where @xmath234 the quantity @xmath235 here is called the power spectrum ` shape parameter ' . @xcite and @xcite used @xmath130 as an approximation on large scales . however , in fig .",
    "[ pkcompare1 ] , we can see that this approximation ( @xmath236 ) still has relatively large deviations from the numerical result from camb .      in order to demonstrate the successful reproduction of results in @xcite",
    ", we use the approximation @xmath130 in section  [ mv_scheme ] .",
    "however , since in our subsequent analysis , we need to carefully compare the numerical value of the reconstructed bulk flow moment with the expectation based on cosmological parameters , we switch to the numerical result of the @xmath138 from camb @xcite in our determination of the bulk flow moments in each individual catalogue and subsequent hyper - parameter analysis ."
  ],
  "abstract_text": [
    "<S> it has been argued recently that the galaxy peculiar velocity field provides evidence of excessive power on scales of @xmath0 , which seems to be inconsistent with the standard @xmath1cdm cosmological model . </S>",
    "<S> we discuss several assumptions and conventions used in studies of the large - scale bulk flow to check whether this claim is robust under a variety of conditions . rather than using a composite catalogue </S>",
    "<S> we select samples from the sn , enear , sfi++ and a1sn catalogues , and correct for malmquist bias in each according to the _ iras _ pscz density field . </S>",
    "<S> we also use slightly different assumptions about the small - scale velocity dispersion and the parameterisation of the matter power spectrum when calculating the variance of the bulk flow . by combining the likelihood of individual catalogues using a bayesian hyper - parameter method </S>",
    "<S> , we find that the joint likelihood of the amplitude parameter gives @xmath2 ( 68 per cent confidence region ) , which is entirely consistent with the @xmath1cdm model . </S>",
    "<S> in addition , the bulk flow magnitude , @xmath3 , and direction , @xmath4 , found by each of the catalogues are all consistent with each other , and with the bulk flow results from most previous studies . </S>",
    "<S> furthermore , the bulk flow velocities in different shells of the surveys constrain ( @xmath5 , @xmath6 ) to be ( @xmath7 ) , for sfi++ and ( @xmath8 ) for enear , which are consistent with _ wmap _ </S>",
    "<S> 7-year best - fit values . </S>",
    "<S> we finally discuss the differences between our conclusions and those of the studies claiming the largest bulk flows .    </S>",
    "<S> methods : statistical  galaxies : kinematics and dynamics distance scale  large - scale structure of universe </S>"
  ]
}