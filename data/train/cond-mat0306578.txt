{
  "article_text": [
    "game theory constitutes a powerful and versatile approach to analyze the collective behavior of adaptive agents , from humans to bacteria and firms . in particular , the _ prisoner s dilemma _",
    "( pd ) game plays in game theory a role similar to the harmonic oscillator in physics .",
    "it s been also referred to as the _ e. coli _ of social sciences , allowing a very large variety of studies .",
    "indeed , this game , developed in the early fifties , offers a very simple and intuitive approach to the problem of how cooperation emerges in societies of `` selfish '' individuals _",
    "i.e. _ individuals which pursue exclusively their own self- benefit .",
    "it was used in a series of works by robert axelrod and co - workers @xcite to examine the basis of cooperation between selfish agents in a wide variety of contexts .",
    "furthermore , mechanisms of cooperation based on the pd have shown their usefulness in political science @xcite-@xcite , economics @xcite- @xcite , international affairs @xcite-@xcite , theoretical biology @xcite-@xcite and ecology @xcite- @xcite .",
    "the pd game consists in two players , say @xmath6 and @xmath7 , each confronting two choices : cooperate ( c ) or defect ( d ) and each makes its choice without knowing what the other will do .",
    "the four possible outcomes for the interaction of agent @xmath6 with agent @xmath7 are : 1 ) they can both cooperate ( c , c ) 2 ) both defect ( d , d ) , 3 ) @xmath6 cooperates and @xmath7 defects(c , d ) and 4 ) @xmath6 defects and @xmath7 cooperates ( d , c ) . depending on the situation 1)-4 ) , the agent @xmath6 ( @xmath7 ) gets respectively : the `` reward '' @xmath8 , the `` punishment '' @xmath9 , the `` sucker s payoff '' @xmath10 ( the `` temptation to defect '' @xmath11 ) or @xmath12 .",
    "these four payoffs obey the following chain of inequalities : @xmath13 for instance the four canonical pd payoffs are : @xmath14 and @xmath15 .",
    "clearly it pays more to defect : if one of the two players defects -say @xmath6- , the other who cooperates will end up with nothing .",
    "in fact , even if agent @xmath6 cooperates , agent @xmath7 should defect , because in that case he will get @xmath11 which is larger than @xmath16 .",
    "that is , independently of what the other player does , defection d yields a higher payoff than cooperation and is the _ dominant strategy _ for rational agents .",
    "this is equivalent to say , in a more technical language that , the outcome ( d , d ) of both players is the nash equilibrium @xcite of the pd game .",
    "the dilemma is that if both defect , both do worse than if both had cooperated : both players get @xmath17 which is smaller than @xmath16 .",
    "one can assign a _ payoff matrix _",
    "m@xmath18 to the pd game given by    @xmath19    which summarizes the payoffs for _ row _ actions when confronting with _ column _ actions .",
    "the emergence of cooperation in prisoner s dilemma ( pd ) games is generally assumed to require repeated play ( and strategies such as _ tit for tat _ ( tft ) @xcite , involving memory of previous interactions ) or features ( `` tags '' ) permitting cooperators and defectors to distinguish one another @xcite .    in this work ,",
    "i consider a simple model of selfish agents , possessing neither memory nor tags , to study the self - organized cooperative states which emerge when they play an _ extended _ pd game with arbitrary payoffs , _",
    "i.e. _ payoffs which do not necessarily fulfill inequalities ( [ eq : chainpd ] ) . the taxonomy of 2x2 games ( one - shot games involving two players with two actions each ) was constructed by rapoport and guyer @xcite , and showed that there exist exactly 78 non - equivalent games .",
    "there are @xmath20 agents , with one variable assigned to each agent at the site or cell @xmath1 and at time @xmath2 : his probability of cooperation @xmath3 .",
    "pairs of agents , @xmath6 and @xmath7 , interact by playing the pd game at each time step @xmath2 .",
    "i use a mean field ( mf ) approach , in which all the spatial correlations in the system are neglected , and thus agent @xmath6 and @xmath7 are chosen at random . after playing the pd",
    "the players update their probability of cooperation @xmath21 and @xmath22 according to the same definite `` measure of success '' which does not vary with time .",
    "thus all agents follow a universal and invariant strategy defined by a measure of success plus an updating rule to transform @xmath21 and @xmath22 into @xmath23 and @xmath24 .",
    "after a transient , the system self - organizes into a state of equilibrium characterized by the average probability of cooperation @xmath4 which depend on the payoff matrix .",
    "payoff matrices can be classified into sub - categories according to their dominant strategy .",
    "let us call @xmath25 the class of those matrices such that : @xmath26 for which the dominant strategy is d. this class comprises , for instance , the canonical matrix m@xmath27 and m@xmath28 , etc .",
    "a second class @xmath29 corresponds to @xmath30 for which the dominant strategy is c , examples of this class are the matrices : m@xmath31 and m@xmath32 .",
    "the remaining matrices do not comply with equation ( [ eq : class1 ] ) or ( [ eq : class2 ] ) and produce situations , _ a priori _ , not dominated by ( d , d ) or ( c , c ) .",
    "one might wonder why bother to study matrices which imply no dilemma and are unrealistic in order to model the social behavior of the majority of individuals .",
    "there are several reasons .",
    "first , this `` unreasonable '' payoff matrices can be used by minorities of individuals which depart from the `` normal '' ones ( assumed to be neutral ) .",
    "for instance , `` antisocial '' `` always d '' individuals , which can not appreciate any advantage of cooperation , or `` altruistic '' `` always c '' individuals .",
    "second , it seems interesting to test the robustness of cooperation under changes in the payoff matrix .",
    "in particular , we will se that even payoff matrices which imply a dilemma can produce either @xmath33 or @xmath34 .",
    "third , arbitrary payoff matrices could be also of importance in other contexts different from societies .",
    "one might envisage situations in which a definite value of @xmath4 is required or is desirable in the design of a system or is the one which optimizes the functioning of a particular mechanism , etc .",
    "for example , to understand how a market of competing firms attains self - regulation . or for instance in the traffic problem , where the damage suffered from mutual d ( crash ) exceeds the damage suffered by being exploited ( turn away ) , which is more appropriately described by the so - called _ chicken game _ for which @xmath35 .",
    "fourth , we will show results for these payoff matrices which , at first glance , defy our intuition .",
    "for example , payoff matrices which , at least in principle , one would bet that favor defection and indeed produce a not so low degree of cooperation .",
    "among the weaknesses of major approaches that have been considered to answer the question about the emergence of cooperation two are often remarked .",
    "the first criticism is about the over - simplification in the behavior of agents : they either always cooperate ( c ) or always defect ( d ) .",
    "clearly , this is not very realistic .",
    "indeed , the levels of cooperation of the individuals seem to exhibit a continuous gamma of values .",
    "the second objection is concerning the deterministic nature of the algorithms which seem to fail to incorporate the stochastic component of human behavior .",
    "both problems can be overcome by assigning to each agent @xmath1 a probability of cooperation @xmath3 ( a real number in the interval [ 0,1 ] ) instead of definite behaviors like c or d. concerning the first objection , @xmath3 reflects the existence of a `` gray scale '' of levels of cooperation instead of just `` black '' and `` white '' . regarding the second objection , the proposed algorithm is clearly non deterministic : agent @xmath1 plays c with probability @xmath36 and d with probability 1-@xmath36 .",
    "now , let us describe the dynamics .",
    "the pairs of interacting partners , by virtue of the mf treatment , are chosen randomly instead of being restricted to some neighborhood .",
    "the implicit assumptions are that the population is sufficiently large and the system connectivity is high _ i.e. _ the agents display high mobility or they experiment interaction at a distance ( for instance electronic transactions ) . in this work",
    "the population of agents will be fixed to @xmath37 and the number of time steps will be of order @xmath38 in such a way that both assumptions be also consistent with the fact that agents have no memory .",
    "starting from an initial state at @xmath39 taken as @xmath40 chosen at random ( in the interval [ 0,1 ] ) for each agent @xmath1 , the system evolves by iteration during @xmath41 time steps following these procedure .    *",
    "\\1 ) _ selection of players : _ two agents , located at random positions @xmath6 and @xmath7 , are selected to interact _",
    "i.e. _ to play the pd game . *",
    "\\2 ) _ playing pairwise pd : _ the behavior , c or d , of each player @xmath1 ( @xmath1=@xmath6 or @xmath1=@xmath7 ) is decided generating a random number @xmath42 and if @xmath43 then he plays c and , conversely , if @xmath44 he plays d. * \\3 ) _ assessment of success : _ each of the two players compares his utilities @xmath45 , which is one of the four pd payoffs : @xmath16 , @xmath10 , @xmath11 or @xmath17 , with an _ estimate _ @xmath46 of his expected utilities .",
    "if @xmath47 ( @xmath48 ) the agent assumes he is doing well ( badly ) and therefore its level of cooperation is adequate ( inadequate ) . *",
    "\\4 ) _ probability of cooperation update : _ if player @xmath1 is doing well he keeps his probability of cooperation @xmath3 . on the other hand , if player @xmath1 is doing badly he decreases ( increases ) his probability of cooperation @xmath3 if he played c ( d ) choosing an uniformly distributed value between @xmath3 and 1 ( between 0 and @xmath3 ) .    in order to introduce a simple and natural estimate @xmath46 let us consider two players @xmath6 and @xmath7 which cooperate , at time @xmath2 , with probabilities @xmath21 and @xmath22 respectively ( and defect with probabilities @xmath49 and @xmath50 ) , thus the expected utilities for the player @xmath6 , @xmath51 , are given by : @xmath52 while the expected utilities for the player @xmath7 , @xmath53 , are obtained by interchanging @xmath6 and @xmath7 in the above equation .",
    "this implies that , given the average probability of cooperation @xmath54 , an arbitrary agent , say number @xmath1 , can estimate his average expected utilities as : @xmath55 however , it turns out that , in general , the value of @xmath56 is unknown by the agents . hence a simpler estimate that can be used agent @xmath1 for his expected utilities @xmath46 is obtained by replacing in equation ( [ eq : deltacap2 ] ) @xmath56(t ) by his own probability of cooperation @xmath3 : @xmath57 @xmath58 in other words , agent @xmath1 adopts the simplest possible extrapolation _",
    "i.e. _ that he is a `` normal '' individual whose probability of cooperation is representative of the average value . at time @xmath2 ) , does not change substantially the main results obtained with these naive agents . ]",
    "the rule each player follows to update his probability of cooperation is quite natural and of the type `` win - stay '' and `` lose - shift '' .",
    "that is , if the player s utilities @xmath59 are larger than his estimate he keeps his probability of cooperation . on the other hand ,",
    "if the utilities are smaller than his estimate he changes his probability of cooperation : a ) increasing it if he played d or b ) decreasing it if he played c. from eq .",
    "( [ eq : localest ] ) the update of @xmath60 is governed by the sign of @xmath61 _ i.e. _ by the following inequations : @xmath62    in the case @xmath63 ( @xmath64 ) @xmath36 is increased ( decreased ) .    in the next section",
    "we will see that the strategy which results from the combination of the proposed measure of success and update rule for @xmath36 -the steps 3 ) and 4)- , produces , for a wide variety of payoff matrices , cooperative states with @xmath65 .",
    "let us end this section with a remark about the problem addressed here and its relation with the evolution of cooperation . in this approach",
    ", there is no competition of different strategies , all the agents follow the same universal strategy which does not evolve over time .",
    "however , the system is adaptive in the sense that the probabilities of cooperation of the agents do evolve .",
    "depending on the payoffs @xmath66 and @xmath17 the system self - organizes , after a transient , in equilibrium states with values of @xmath67 ranging from 0 to 1 .",
    "the equilibrium asymptotic states can be lumped into 3 groups according to the degre of cooperation attained : _ highly cooperative _ ( @xmath68 ) , _ moderately cooperative _ ( @xmath69 ) and of _ poorly cooperative _ ( @xmath70 ) .",
    "the outcomes for any arbitrary payoff matrix m@xmath18 can be understood in terms of the updating rule for the cooperation probability and the corresponding estimate @xmath71 _ i.e. _ from the inequalities ( [ eq : inequations ] ) .",
    "the payoff matrices which imply a dilemma -those which comply with the chain of inequalities ( [ eq : chainpd])- lead either to @xmath72 or to @xmath73 . from ( [ eq : inequations ] ) it emerges that @xmath33 occurs in the case when @xmath74 has no roots in the interval ( 0,1 ] ( @xmath75 is always one of the two roots ) and @xmath34 in the opposite case",
    ".    some other matrices not belonging to class @xmath25 exhibit a tension between c and d and give rise to @xmath76 .",
    "the matrices which do not embody such trade - off produce the situations which depart most from @xmath77 .",
    "it is illustrative to consider , for a moment , the restricted subset of 24 payoff matrices obtained from permutation of the four canonical payoff values because it covers the three groups with different cooperation levels mentioned above .",
    "in fact , the system self - organizes into equilibrium states with seven values of @xmath4 : 2 matrices ( m@xmath32 and m@xmath78 ) produce @xmath79 , 2 matrices ( m@xmath28 and m@xmath80 ) produce @xmath34 .",
    "the remaining 20 matrices produce intermediate values : @xmath81 ( m@xmath82 ) , @xmath83 ( m@xmath78 ) , @xmath84 ( m@xmath85 ) , @xmath86 ( m@xmath87 ) and @xmath33 ( the other 16 matrices and among them the canonical payoff matrix ) .",
    "the 24 measures are performed over 500 simulations .",
    "1 show the average probability of cooperation for different payoff matrices vs. time for the 50,000 first time steps .    the mirror symmetry with respect to he value @xmath88 between the curves for @xmath54 corresponding to a given matrix m@xmath18 and its palindrome m@xmath89 is due to the symmetry of the game when interchanging @xmath90 and @xmath91 simultaneously with cooperators c by defectors d. that is ,    @xmath92    a particular interesting case study is provided by payoff matrix m@xmath85 with @xmath84 .",
    "this result seems , at first sight , counter - intuitive : an intermediate cooperation level attained with 0 reward ( and very low sucker s payoff ) ! nevertheless , let us show how the updating rule for the cooperation probability explains this outcome .",
    "the estimate for this matrix , given by the parabola @xmath93 plotted as a solid curve in fig.2 ( the horizontal lines at @xmath94 and @xmath95 cut the parabola at abscises @xmath96 and @xmath97 , respectively ) .",
    "the cooperation update rule tells us the agent @xmath1 increases his probability of cooperation when he plays d and gets @xmath95 if @xmath36 is less than @xmath98 , _ i.e. _ this temptation is not enough ( @xmath99 ) .",
    "on the other hand , he decreases his probability of cooperation when he plays c and gets @xmath100 , independently of the value of @xmath36 , or when he gets @xmath94 if @xmath36 is less than @xmath101 . in the remaining situations the player keeps his probability of cooperation .",
    "thus a value of @xmath4 between 0 and 0.5 is not surprising after all , rather it is the result of given the two competing probability of cooperation flows .",
    "all this analysis for payoff matrix m@xmath85 works also for any set of payoffs obeying the inequalities : @xmath102 the only thing that changes is the value of @xmath4 .",
    "we will come back over this particular payoff matrix to illustrate how @xmath103 changes under arbitrary variations of the payoffs .    _",
    "the effect of changing payoffs _    we are now going to analyze the effect of changing the payoff matrix in order to go beyond the 24 permutations of the canonical payoffs .    we have seen that the sign of @xmath104 controls the update of @xmath36 . from the definition of @xmath105 , as an estimate of utilities of agent @xmath1 , it is clear that it is bounded from above and from below by the largest and smallest of the four payoffs , respectively .",
    "thus , @xmath106 may have different signs , depending on the value of @xmath36 , only for the two intermediate payoffs .",
    "let us denote by @xmath107 the value of @xmath36 such that the estimate @xmath105 becomes equal to the larger payoff , @xmath108 the value of @xmath36 such that the estimate becomes equal to the second larger payoff , and so on .",
    "therefore , it is easy to see that the change in @xmath4 is controlled by the displacements of @xmath108 and @xmath109 ( for instance , for m@xmath85 , @xmath110 and @xmath111 ) .",
    "if @xmath108 or @xmath109 correspond to the cooperative payoffs , @xmath16 or @xmath10 , then its displacement to the right ( left ) decreases ( increases ) the proportion of c - agents for whom @xmath112 which are , on average , the ones who remain c after playing the game .",
    "this in turn decreases ( increases ) @xmath4 . on the other hand , if @xmath108 or @xmath109 correspond to the non cooperative payoffs , @xmath11 or @xmath17 , then its displacement to the right ( left ) decreases ( increases ) the proportion of d - agents for whom @xmath112 which are , on average , the ones who remain d after playing the game .",
    "this in turn increases ( decreases ) @xmath4 .",
    "the payoff matrix m@xmath85 will serve to illustrate the effect the changes in the values of the payoffs have on @xmath103 .",
    "we will proceed by modifying one of the four payoffs at a time and keeping fixed the remaining three in such a way that he chain of in - equalities ( [ eq : chain0135 ] ) is preserved .",
    "this variation of a quantity that results when the payoff @xmath113 is modified and the other three payoffs remain fixed is denoted by @xmath114 . the estimates that result from these changes are the curves shown in fig.2 .",
    "let us consider first the changes @xmath115 , produced by an increment in the sucker s payoff from @xmath94 to @xmath116 ( which transforms m@xmath85 into m@xmath117 ) , @xmath118 , produced by a decrease from @xmath94 to @xmath119 ( which transforms m@xmath85 into m@xmath120 ) . for m@xmath117",
    ", @xmath109 is the abscise of the point @xmath121 ( filled up triangle in fig .",
    "2(a ) ) and for m@xmath120 , @xmath109 is the abscise of the point @xmath122 ( filled down triangle in fig .",
    "2(a ) ) , while the corresponding @xmath108 are the abscises of the points @xmath123 ( filled triangles : up for m@xmath117 and down for m@xmath120 in fig.2(a ) ) .",
    "we can see that increasing ( decreasing ) the sucker s payoff , from @xmath94 to @xmath116 ( @xmath119 ) , produces a displacement of @xmath108 to the right ( left ) , from @xmath124 to 0.4 ( to @xmath125 ) , and of @xmath109 to the left ( right ) , from @xmath126 to 0.6 ( to 1 ) .",
    "hence , both changes point in the same direction increasing ( decreasing ) @xmath103 as can be observed in fig .",
    "3 ( dotted lines vs. solid lines ) . in other words , @xmath127 @xmath128    similarly , we denote by @xmath129 the variations produced by an increment in the punishment , from @xmath130 to @xmath131 ( which transforms m@xmath85 into m@xmath132 ) , and by @xmath133 the variations produced by a decrease in the punishment , from @xmath130 to @xmath134 ( which transforms m@xmath85 into m@xmath135 ) .",
    "for both matrices , the corresponding @xmath108 and @xmath109 are the abscises of the points @xmath123 and @xmath136 ( non filled triangles in fig.2 : up for m@xmath132 and down for m@xmath135 ) , respectively . also in fig .",
    "2(a ) we see that changing the punishment , from @xmath130 to @xmath131 ( @xmath134 ) , produces a displacement of @xmath108 to the right ( left ) , from @xmath137 to @xmath138 ( to 0.25 ) , and of @xmath109 to the right ( left ) , from @xmath126 to @xmath139 ( to 0.75 ) , hence the two changes point in opposite directions : the first tends to increase ( decrease ) @xmath103 and the second to decrease ( increase ) it . as",
    "the first displacement is larger it dominates , and the net result is an increase ( decrease ) of @xmath103 as can be observed in fig .",
    "3 ( dot - dashed lines vs. solid line ) .",
    "that is : @xmath140    @xmath141    on the other hand , let us consider the variations produced by the increment of the temptation @xmath142 , from @xmath95 to @xmath143 ( which transforms m@xmath85 into m@xmath144 ) , and by its decrease @xmath145 , from @xmath95 to @xmath146 ( which transforms m@xmath85 into m@xmath147 ) . for m@xmath144 , @xmath108 is the abscise corresponding to the point @xmath148 ( non - filled up triangle ) and for m@xmath147 , @xmath108 is the abscise of the point @xmath149 ( non - filled down triangle ) , while the corresponding @xmath109 are the abscises of the points @xmath136 ( non - filled triangles : up for m@xmath144 and down for m@xmath147 ) . in fig .",
    "2(b ) we can see that increasing ( decreasing ) the sucker s payoff , from @xmath95 to @xmath143 ( @xmath146 ) , produces a displacement of @xmath108 to the left ( right ) , from @xmath124 to 0.2 ( to 0.5 ) and of @xmath109 to the right ( left ) , from @xmath126 to 0.8 ( to @xmath150 ) .",
    "hence both changes point in the same direction decreasing ( increasing ) @xmath103 as can be observed in fig .",
    "3 ( dashed lines vs. solid line ) .",
    "that is : @xmath151 @xmath152 with a similar argument one realizes that increasing ( decreasing ) the reward @xmath100 @xmath103 decreases ( increases ) .    in summary , for payoff matrices like m@xmath85 , which obbey the chain of in - equalities ( [ eq : chain0135 ] ) , we found two expected results : a higher value of @xmath103 can be reached by increasing the sucker s payoff @xmath10 ( which makes c - agents more altruistic ) or decreasing the temptation @xmath11 ( reducing the incentives to free ride ) .",
    "additionally we found two , _ a priori _ , unexpected results : a higher value of @xmath103 can also be reached by increasing the punishment @xmath17 or decreasing the reward @xmath16 . by an inspection of fig .",
    "2(a ) the effect of an increment of @xmath17 can be understood as rising the expectations of the d - agents which in turn diminishes the fraction of agents that are satisfied after playing the game .",
    "similarly , from fig .",
    "2(b ) we can see that an decrease of @xmath16 makes the c - agents less ambitious and increase the fraction of altruists .",
    "it is worth remarking that , for the case of payoffs obeying ( [ eq : chain0135 ] ) , something which at first seems as innocent as to interchange the two non cooperative payoffs @xmath11 and @xmath17 has a dramatic consequence : it transforms a system with an intermediate level of cooperation into one with null cooperation .",
    "this can be understood by comparing the estimate ( [ eq : est0135 ] ) for payoff matrix m@xmath85 to the one for m@xmath80 which is given by @xmath153 both estimates have maximum value of @xmath17 ( 5 and 3 , respectively , at @xmath154 ) but the important difference is that in the first case @xmath17 is the maximum payoff while in second one @xmath155 .",
    "thus in this second case , only the agents which play c can do badly , and then the only possible change for @xmath36 ( according to its update rule ) is a reduction till it reaches zero value .",
    "finally , let us include a note regarding the efficiency to attain cooperative regimes .",
    "the state of maximum cooperation @xmath79 is reached for payoff matrices such that @xmath156 plus the condition that equation @xmath157 has no roots in the interval [ 0,1 ] different from @xmath158 ( which is always a root of ( [ eq : peq1 ] ) ) .",
    "this condition on the roots is because in the opposite case , when there is a root @xmath159 in - between 0 and 1 , it follows easily from the inequations ( [ eq : inequations ] ) that @xmath56 converges to the semi - sum of @xmath159 and 1 .",
    "it can be checked by elemental algebra that this is the case of , for instance , payoff matrices m@xmath32 , m@xmath78 .",
    "the success of the strategy to attain cooperative regimes for a wide variety of games ( payoff matrices ) - mainly those which implies dilemmas or clearly favor d - relies on the combination of the proposed measure of success and update rule for the probability of cooperation .",
    "basically it works by tuning the agent s cooperation guided by a trade - off between efficiency ( increase of utilities ) and equity ( indirect reciprocity ) .",
    "if the agent is doing well he maintains his probability of cooperation otherwise he changes it .",
    "when he is doing badly playing d he becomes more cooperative , _",
    "i.e. _ he increases his probability of cooperation attempting to change to behavior c and explore this alternative behavior .",
    "conversely , if he is doing badly playing c then he decreases his probability of cooperation attempting to change to behavior d and see what happen .",
    "an interesting extension of the model would be to allow competition of different strategies to promote their evolution _",
    "i.e. _ players which imitate the best - performing ones in such a way that lower scoring strategies decrease in number and the higher scoring increase .",
    "another possibility would be to allow the use of distinct payoff matrices .",
    "for instance , individuals inclined to cooperate ( defect ) might be represented by agents using the payoff matrix m@xmath82 ( m@xmath87 ) while `` neutral '' ordinary agents by those using the canonical payoff matrix m@xmath27 .",
    "this would make possible to study if mutants inclined to d can invade a group of neutral individuals or individuals inclined to c and drive out all cooperation .",
    "here i considered a mf approximation which neglects all the spatial correlations .",
    "one virtue of this simplification is that it shows the model does not require that agents interact only with those within some geographical proximity in order to sustain cooperation .",
    "playing with fixed neighbors is sometimes considered as an important ingredient to successfully maintain the cooperative regime @xcite,@xcite .",
    "however , the quality of this mf approximation depends on the nature of the system one desires to model , and varies whether one deals with human societies , viruses @xcite , cultures of bacteria @xcite or market of providers of different products .",
    "in order to consider situations in which the effect of geographic closeness can not be neglected , an alternative version of this model , might include a spatial pd game , in which individuals interact only ( or mainly ) with those within some geographical proximity . in that case , the study of spatial patterns seems an interesting issue to address .",
    "work is in progress in that direction .",
    "r. axelrod , in _ the evolution of cooperation _",
    ", basic books , new york , 1984 ; r. axelrod , in _ the complexity of cooperation _ , princeton university press 1997 .",
    "these two volumes include lots of useful references .",
    "also it is illuminating the chapter 3 of _ harnesing complexity _ by r. axelrod and m. cohen , the free press 1999 ."
  ],
  "abstract_text": [
    "<S> a simple model for cooperation between `` selfish '' agents , which play an extended version of the prisoner s dilemma(pd ) game , in which they use arbitrary payoffs , is presented and studied . </S>",
    "<S> a continuous variable , representing the probability of cooperation , @xmath0 [ 0,1 ] , is assigned to each agent @xmath1 at time @xmath2 . at each time step @xmath2 </S>",
    "<S> a pair of agents , chosen at random , interact by playing the game . </S>",
    "<S> the players update their @xmath3 using a criteria based on the comparison of their utilities with the simplest estimate for expected income . </S>",
    "<S> the agents have no memory and use strategies not based on direct reciprocity nor tags. depending on the payoff matrix , the systems self - organizes - after a transient - into stationary states characterized by their average probability of cooperation @xmath4 and average equilibrium per - capita - income @xmath5 . </S>",
    "<S> it turns out that the model exhibit some results that contradict the intuition . </S>",
    "<S> in particular , some games which - _ a priory_- seems to favor defection most , may produce a relatively high degree of cooperation . </S>",
    "<S> conversely , other games , which one would bet that lead to maximum cooperation , indeed are not the optimal for producing cooperation .    </S>",
    "<S> = -1.50 cm = 0.5 cm = 0.5 cm = 35pt    psfig.sty    _ keybords _ : complex adaptive systems , agent - based models , social systems    pacs numbers : 02.50.le , 87.23.ge , 89.65.gh , 89.75.-k </S>"
  ]
}