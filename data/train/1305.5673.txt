{
  "article_text": [
    "the construction of useful confidence sets is one of the more challenging problems in nonparametric function estimation .",
    "there are two main interrelated issues which need to be considered together , coverage probability and the expected size of the confidence set . for a fixed parameter space",
    "it is often possible to construct confidence sets which have guaranteed coverage probability over the parameter space while controlling the maximum expected size . however such minimax statements are often thought to be too conservative , and a more natural goal is to have the expected size of the confidence set reflect in some sense the difficulty of estimating the particular underlying function .",
    "these issues are well illustrated by considering confidence intervals for the value of a function at a fixed point .",
    "let @xmath0 be an observation from the white noise model @xmath1 where @xmath2 is standard brownian motion and @xmath3 belongs to some parameter space  @xmath4 .",
    "suppose that we wish to construct a confidence interval for @xmath5 at some point @xmath6 .",
    "let @xmath7 be a confidence interval for @xmath8 based on observing the process @xmath0 , and let @xmath9 denote the length of the confidence interval .",
    "the minimax point of view can then be expressed by the following : subject to the constraint on the coverage probability @xmath10 , minimize the maximum expected length @xmath11 .    as an example it is common to consider the lipschitz classes @xmath12 $ } \\bigr\\},\\qquad \\mbox{if $ 0<\\beta\\le1$}\\ ] ] and for @xmath13 @xmath14 $ } \\bigr\\},\\ ] ] where @xmath15 is the largest integer less than @xmath16 and @xmath17 .",
    "for these classes it easily follows from results of @xcite , @xcite and @xcite that the minimax expected length of confidence intervals , which have guaranteed coverage of @xmath18 over @xmath19 , is of order @xmath20 .",
    "it should , however , be stressed that confidence intervals which achieve such an expected length rely on the knowledge of the particular smoothness parameters @xmath16 and @xmath21 , which are not known in most applications .",
    "unfortunately , @xcite and @xcite have shown that the natural goal of constructing an adaptive confidence interval which has a given coverage probability and has expected length that is simultaneously close to these minimax expected lengths for a range of smoothness parameters is not in general attainable .",
    "more specifically suppose that a confidence interval has guaranteed coverage probability of @xmath22 over @xmath19 .",
    "then for any @xmath5 in the interior of @xmath23 the expected length for this @xmath5 must also be of order @xmath24 .",
    "in other words the minimax rate describes the actual rate for all functions in the class other than those on the boundary of the set .",
    "for example , in the case that a confidence interval has guaranteed coverage probability of @xmath25 over the lipschitz class @xmath26 , then even if the underlying function has two derivatives , and the first derivative smaller than  @xmath21 , the confidence interval for @xmath27 _ must _ still have expected length of order @xmath28 even though one would hope that an adaptive confidence interval would have a much shorter length of order @xmath29 . despite these very negative results there are some settings where some degree of adaptation has been shown to be possible . in particular under certain shape constraints @xcite constructed confidence bands which have a guaranteed coverage probability of at least @xmath30 over the collection of all monotone densities and which have maximum expected length of order @xmath31 for those monotone densities which are in @xmath19 for a particular choice of @xmath16 where @xmath32 .",
    "this construction relies on the selection of a tuning parameter and is thus not adaptive .",
    "dmbgen ( @xcite ) , however , does provide adaptive confidence bands with optimal rates for both isotonic and convex functions under supremum norm loss on arbitrary compact subintervals .",
    "these results are , however , still framed in terms of the maximum length over particular large parameter spaces , and the existence of such intervals raises the question of exactly how much adaption is possible .",
    "it is this question that is the focus of the present paper .    rather than considering the maximum expected length over large collections of functions , we study the problem of adaptation to each and every function in the parameter space .",
    "we examine this problem in detail for two commonly used collections of functions that have shape constraints , namely the collection of convex functions and the collection of monotone functions .",
    "we focus on these parameter spaces as it is for such shape constrained problems for which there is some hope for adaptation . within this context",
    "we consider the problem of constructing a confidence interval for the value of a function at a fixed point under both the white noise with drift model given in ( [ w.model ] ) as well as a nonparametric regression model .",
    "we show that within the class of convex functions and the class of monotone functions , it is indeed possible to _ adapt to each individual function _ , and not just to the minimax expected length over different parameter spaces in a collection .",
    "the notion of adaptivity to a single function is also discussed in lepski , mammen and spokoiny ( @xcite ) and @xcite for the related point estimation problem but in these contexts a logarithmic penalty of the noise level must be paid , and thus the notion of adaptivity is somewhat different.=1    this result is achieved in two steps .",
    "first we study the problem of minimizing the expected length of a confidence interval , assuming that the data is generated from a particular function @xmath5 in the parameter space , subject to the constraint that the confidence interval has guaranteed coverage probability over the entire parameter space .",
    "the solution to this problem gives a benchmark for the expected length which depends on the function @xmath5 considered .",
    "it gives a bound on the expected length of any adaptive interval because if the expected length is smaller than this bound for _ any _ particular function , the confidence interval can not have the desired coverage probability . in applications",
    "it is more useful to express the benchmark in terms of a local modulus of continuity , an analytic quantity that can be easily calculated for individual functions . in situations where adaptation is not possible ,",
    "this local modulus of continuity does not vary significantly from function to function .",
    "such is the case in the settings considered in @xcite .",
    "however , in the context of convex or monotone functions , the resulting benchmark does vary significantly , and this opens up the possibility for adaptation in those settings .",
    "our second step is to actually construct adaptive confidence intervals .",
    "this is done separately for monotone functions and convex functions , with similar results .",
    "for example , an adaptive confidence interval is constructed which is shown to have expected length uniformly within an absolute constant factor of the benchmark for every convex function , while maintaining coverage probability over the collection of all convex functions . in other words ,",
    "this confidence interval has smallest expected length , up to a universal constant factor , for each and every convex function within the class of all confidence intervals which guarantee a @xmath18 coverage probability over all convex functions .",
    "a similar result is established for a confidence interval designed for monotone functions .",
    "the rest of the paper is organized as follows . in section [ lowerbound ] the benchmark for the expected length at each monotone function or each convex function",
    "is established under the constraint that the interval has a given level of coverage probability over the collection of monotone functions or the collection of convex functions .",
    "section  [ procedure.sec ] constructs data driven confidence intervals for both monotone functions and convex functions and shows that these confidence intervals maintain coverage probability and have expected length within an absolute constant factor of the benchmark given in section  [ lowerbound ] for each monotone function and convex function .",
    "section  [ regression.sec ] considers the nonparametric regression model , and section  [ discussion.sec ] discusses connections of our results with other work in the literature .",
    "proofs are given in section  [ proof.sec ] .",
    "as mentioned in the , the focus in this paper is the construction of confidence intervals which have expected length that adapts to the unknown function .",
    "the evaluation of these procedures depends on lower bounds which are given here in terms of a local modulus of continuity first introduced by @xcite in the context of point estimation of convex functions under mean squared error loss .",
    "these lower bounds provide a natural benchmark for our problems .",
    "we focus in this paper on estimating the function @xmath5 at @xmath33 since estimation at other points away from the boundary is similar . for a given function class @xmath34 , write @xmath35 for the collection of all confidence intervals which cover @xmath36 with guaranteed coverage probability of @xmath37 for all functions in @xmath34 . for a given confidence interval @xmath7 , denote by @xmath9 the length of @xmath7 and @xmath38 the expected length of @xmath7 at a given function  @xmath5 .",
    "the minimum expected length at @xmath5 of all confidence intervals with guaranteed coverage probability of @xmath37 over @xmath34 is then given by=-1 @xmath39=0 a natural goal is to construct a confidence interval with expected length close to the minimum @xmath40 for every @xmath41 while maintaining the coverage probability over @xmath34 . however although @xmath40 is a natural benchmark for the expected length of confidence intervals , it is not easy to evaluate exactly . instead as a first step toward our goal , we provide a lower bound for the benchmark @xmath40 in terms of a local modulus of continuity @xmath42 introduced by @xcite . the local modulus is a quantity that is more easily computable and techniques for its analysis are similar to those given in @xcite and @xcite where a global modulus of continuity was introduced in the study of minimax theory for estimating linear functionals .",
    "see the examples in section  [ example.sec ] .    for a parameter space @xmath43 and function @xmath44 ,",
    "the local modulus of continuity is defined by @xmath45 where @xmath46 is the @xmath47 function norm .",
    "the following theorem gives a lower bound for the minimum expected length @xmath40 in terms of the local modulus of continuity @xmath42 . in this theorem and throughout the paper we write @xmath48 for the cumulative distribution function and @xmath49 for the density function of a standard normal density and set @xmath50 .",
    "[ el.bound.thm ] suppose @xmath34 is a nonempty convex set .",
    "let @xmath51 and @xmath52 .",
    "then for confidence intervals based on ( [ w.model ] ) , @xmath53 in particular , @xmath54    the lower bounds given in theorem  [ el.bound.thm ] can be viewed as benchmarks for the evaluation of the expected length of confidence intervals when the true function is  @xmath5 for confidence intervals which have guaranteed coverage probability over all of @xmath34 .",
    "the bound depends on the underlying true function @xmath5 as well as the parameter space @xmath34 .",
    "the bounds from theorem  [ el.bound.thm ] are general . in some settings",
    "they can be used to rule out the possibility of adaptation , whereas in other settings they provide bounds on how much adaptation is possible . in particular",
    "the result ruling out adaptation over lipschitz classes mentioned in the easily follows from this theorem .",
    "for example , consider the lipschitz class @xmath23 and suppose that @xmath5 is in the interior of @xmath19 .",
    "straightforward calculations similar to those given in section [ example.sec ] show that @xmath55    now consider two lipschitz classes @xmath56 and @xmath57 with @xmath58 .",
    "a  fully adaptive confidence interval in this setting would have guaranteed coverage of @xmath37 over @xmath59 and maximum expected length over @xmath60 of order @xmath61 for @xmath62 and @xmath63 .",
    "however , it follows from theorem  [ el.bound.thm ] and ( [ lip.modulus ] ) that for all confidence intervals with coverage probability of @xmath37 over @xmath64 , for every @xmath65 with @xmath66 , @xmath67 for some constant @xmath68 not depending on @xmath5 . in particular",
    "this holds for all @xmath69 and hence @xmath70 therefore it is not possible to have confidence intervals with adaptive expected length over two lipschitz classes with different smoothness parameters .    in the present paper theorem  [ el.bound.thm ]",
    "will be used to provide benchmarks in the setting of shape constraints .",
    "denote by @xmath71 and @xmath72 , respectively , the collection of all monotonically nondecreasing functions and the collection of all convex functions on @xmath73 $ ] .",
    "we shall now show that in these cases the modulus and the associated lower bounds vary significantly from function to function .",
    "we now turn to the application of the lower bound given in theorem [ el.bound.thm ] in the case of monotone functions and convex functions . here",
    "we shall evaluate the lower bound for four particular families of functions yielding different rates at which the expected length decreases to zero as the noise level decreases in contrast to the situation just described where the parameter space did not have an order constraint .",
    "two of the functions will be both monotonically nondecreasing and convex . in this case",
    "the lower bound can also be quite different depending on whether we assume the knowledge that @xmath5 is convex or monotonically nondecreasing .",
    "the key quantity that is needed in any application of theorem [ el.bound.thm ] is the local modulus .",
    "we follow the same approach as given in @xcite where a global modulus of continuity is considered for minimax estimation . in each case , for a given function @xmath5 , we first minimize the @xmath74 norm between a function @xmath75 and the function @xmath5 subject to the constraint that @xmath76 for some given value @xmath77 . from here",
    "it is easy to invert and thus maximize @xmath78 given a constraint on the @xmath74 norm between @xmath5 and @xmath79 .",
    "[ linear.ex ] as a first example consider the linear function @xmath80 where @xmath81 is a constant .",
    "this function is both monotonically nondecreasing and convex .",
    "first consider the collection of monotonically nondecreasing functions @xmath71 .",
    "we shall treat separately the case @xmath82 and the case @xmath83 . for the moment we shall take @xmath84 .",
    "suppose that @xmath85 . in this case",
    "@xmath86 and a function @xmath79 that minimizes @xmath87 subject to the constraint that @xmath88 is given by @xmath89 if @xmath90 , @xmath91 if @xmath92 , and @xmath93 if @xmath94 , where @xmath95 satisfies @xmath96 .",
    "the assumption that @xmath97 guarantees @xmath98 .",
    "we then have @xmath99 .",
    "it follows that if @xmath100 @xmath101 and consequently for @xmath102 , if @xmath84 @xmath103    in the case that @xmath83 a function @xmath79 that minimizes @xmath104 subject to the constraint that @xmath105 is given by @xmath106 if @xmath90 , @xmath91 if @xmath107 . in this case",
    "it is easy to check that @xmath108 and hence @xmath109 and hence @xmath110    we now consider the bound for the length of the confidence interval for @xmath111 belonging to the collection of convex functions . in this case",
    "we do not need to treat the cases @xmath82 and @xmath83 separately . the function @xmath79 that minimize @xmath87 subject to the constraint that @xmath79 is convex and @xmath112 is given by @xmath113 if @xmath114 and @xmath115 if @xmath116 . in this case @xmath117 .",
    "it then immediately follows that @xmath118 and so @xmath119    it is important to note that for @xmath82 the minimum expected lengths @xmath120 and @xmath121 are different , one of order @xmath122 and another of order @xmath123 , although the function @xmath111 is the same .",
    "it is also interesting to note that the expected length of the confidence for monotone functions is an increasing function of @xmath124 whereas the expected length of the confidence for convex functions does not depend on @xmath124 .",
    "since we shall show that these bounds are achievable within a constant factor it follows that the minimum expected length of the confidence interval when @xmath111 is the true function depends strongly on whether we specify that the underlying collection of functions is convex or monotone .",
    "plots illustrating shapes of functions @xmath111 and a least favorable function @xmath79 are shown as below in figure  [ fig : ex1].=1     and a least favorable function @xmath79 in example [ linear.ex ] with the constraints @xmath112 . ]",
    "[ ex2 ] as a second example which is also both monotonically nondecreasing and convex consider the function @xmath125 where @xmath126 and @xmath127 and @xmath128 are constants .",
    "we consider the cases @xmath129 and @xmath130 separately .",
    "when @xmath129 the function is piecewise linear with the change of slope at @xmath33 .",
    "in this case suppose @xmath131 .",
    "a monotonically nondecreasing function @xmath132 that minimize @xmath133 subject to the constraint that @xmath134 is given by @xmath135 if @xmath116 , @xmath136 if @xmath137 , and @xmath135 if @xmath138 , where @xmath95 satisfies @xmath139 .",
    "the constraint @xmath140 is to guarantee that such a @xmath95 exists with @xmath98 .",
    "then we have @xmath141 , and it follows that if @xmath142 , @xmath143 and consequently for @xmath144 , @xmath145    we can also give a lower bound on the expected length for this same function for confidence intervals which guarantee coverage over the class of convex functions .",
    "suppose @xmath146 . here",
    "we need to find the convex @xmath147 that minimizes @xmath148 subject to the constraints that @xmath149 .",
    "it is given by @xmath150 if @xmath151 , @xmath152 if @xmath153 and @xmath150 if @xmath154 .",
    "then @xmath155 and it follows that if @xmath156 , @xmath157 hence , for @xmath158 , @xmath159    we now turn to the case where @xmath130 .",
    "suppose @xmath160 . in this case",
    "the monotonically nondecreasing function @xmath79 that minimizes @xmath133 subject to the constraints that @xmath134 is given by @xmath135 if @xmath116 , @xmath136 if @xmath137 and @xmath135 if @xmath138 , where @xmath95 satisfies @xmath139 .",
    "as before the condition @xmath160 guarantees that @xmath95 exists with @xmath161 . in this case",
    "@xmath162 for some constant @xmath163 and @xmath164 .",
    "it follows that if @xmath165 , then @xmath166 hence , @xmath167    for a bound on the expected length of this same function for confidence intervals with coverage guaranteed over the collection of convex functions , we suppose @xmath168 . in this case",
    "the convex function @xmath147 that minimizes @xmath148 subject to the constraints that @xmath149 , is given by @xmath169 , @xmath170 , if @xmath171 and @xmath150 otherwise , where @xmath172 and @xmath173 are the intersection points of @xmath174 and the line @xmath175 .",
    "then the function @xmath147 with slope @xmath176 that minimize @xmath148 would be the least favorable function .",
    "it follows that , if @xmath177 , @xmath178 and consequently for @xmath179 , @xmath180 where @xmath181 is a constant depending on @xmath182 only .",
    "it is interesting to note that in this example the rates of convergence for @xmath183 and @xmath184 are the same for the case @xmath129 , and are different when @xmath130 .",
    "plots illustrating shapes of functions @xmath5 and a least favorable function @xmath79 are shown as below in figure  [ fig : ex2 ] .     and a least favorable function @xmath79 in example [ ex2 ] with the constraints @xmath185 . ]",
    "next we consider a function which is monotonically nondecreasing but not convex .",
    "[ ex3 ] let @xmath186 for some constant @xmath187 and @xmath188 or @xmath189 for @xmath190 suppose that @xmath191 . in this case a function @xmath79 that minimizes @xmath192 subject to the constraint that @xmath76 is given by @xmath193 if @xmath90 , @xmath91 if @xmath92 and @xmath194 if @xmath94 , where @xmath95 satisfies @xmath195 .",
    "as before the condition @xmath191 guarantees that @xmath95 exists with @xmath161 .",
    "then @xmath196 , and it follows that when @xmath197 , @xmath198 hence for @xmath199 , @xmath200 and once again it is clear that the rate at which the expected length decreases to zero depends strongly on the value of @xmath182 .",
    "as a final example we consider a function which is convex but not monotonically nondecreasing .",
    "[ ex4 ] let @xmath201 .",
    "suppose that @xmath202 . in this case",
    "the function @xmath79 that minimizes @xmath192 subject to the constraint that @xmath76 is given by @xmath203 if @xmath204 , @xmath205 if @xmath206 and @xmath193 otherwise . then @xmath207 and it follows that when @xmath208 , @xmath209 hence for @xmath210 , @xmath211 a similar minimization problem is solved in dmbgen ( @xcite ) .",
    "plots illustrating shapes of functions @xmath5 and a least favorable function @xmath79 for both examples  [ ex3 ] and  [ ex4 ] are shown in figure [ fig : ex3 - 4 ] .     and a least favorable function @xmath79 in examples [ ex3 ] and [ ex4 ] with the constraints @xmath185 . ]",
    "in this section we both construct and give an analysis of adaptive confidence intervals for monotone functions and convex functions .",
    "the procedures are easily implementable .",
    "we consider the class of monotonically nondecreasing functions and the class of convex functions .",
    "concave functions and monotonically nonincreasing functions can be handled similarly .",
    "the construction is split into two steps . in the first step a countable collection of confidence intervals",
    "is created each of which has guaranteed coverage probability .",
    "these intervals are based on a collection of pairs of linear estimators . for each interval one of the estimators",
    "has nonnegative bias and the other nonpositive bias .",
    "the one - sided control of the bias of these estimators is a key special feature in these problems and an important part of what makes it possible to adapt to every individual function .",
    "moreover for each function @xmath5 this collection has at least one interval with expected length within a constant factor of the local modulus bound given in theorem  [ el.bound.thm ] .",
    "the second step is to select from this collection a particular interval .    in the case of monotonically nondecreasing functions we take for each @xmath212 ,",
    "pairs of estimators @xmath213 and @xmath214 .",
    "then for estimating @xmath36 it is easy to check that @xmath215 has nonnegative and monotonically nonincreasing biases while @xmath216 have nonpositive and monotonically nondecreasing biases .",
    "the one - sided control of the biases of these estimators over the class of all monotonically nondecreasing functions easily allows for the construction of a confidence interval . for that we shall need the standard deviation of @xmath215 and @xmath216 . in order to give a unified treatment in both the monotone and convex case",
    "it is useful to establish a common notation .",
    "here we shall set @xmath217 .",
    "it is then easy to check that both @xmath215 and @xmath216 have a standard deviation of @xmath218 .",
    "it is then also easy to see that for each @xmath219 , the confidence interval @xmath220 given by @xmath221\\ ] ] has guaranteed coverage of @xmath37 .",
    "we should , however , note that in ( [ mcij ] ) the left endpoint of the interval may be larger than the right endpoint in which case we adopt the convention that the confidence interval is just the empty set .",
    "the length of this confidence interval is then @xmath222 .    in the case of convex functions for @xmath223 , let @xmath224 and let @xmath225 .",
    "the following lemma shows that for convex functions @xmath226 have nonnegative and monotonically nonincreasing biases and that @xmath227 have nonpositive and monotonically nondecreasing biases .",
    "[ con.lem ] for any convex function @xmath5 , @xmath228    it is also easy to check that the standard deviation of @xmath226 is equal to @xmath229 where @xmath217 and that @xmath230 has a standard deviation of @xmath231 .",
    "it then follows from the signs of the biases of @xmath232 and @xmath233 that for any given @xmath234 , @xmath235\\ ] ] gives a confidence interval with coverage probability of at least @xmath236 .",
    "we should also note once again that the left endpoint of the interval may be larger than the right endpoint in which case the confidence interval is taken to be the empty set , and so in this case the length of this confidence interval is @xmath237 .",
    "these results , for which a more formal proof is given in section [ proof.sec ] are summarized in the following proposition .",
    "[ m.cij.prop ] for every @xmath219 , the confidence interval @xmath238 defined in ( [ mcij ] ) has coverage probability of at least @xmath239 for all monotonically nondecreasing functions @xmath240 , and for every @xmath223 , the confidence interval @xmath241 defined in ( [ cisj ] ) has coverage probability of at least @xmath239 for all convex functions @xmath242 .",
    "the second stage in the construction is that of selecting from these collections of intervals the one to be used .",
    "first note that one should not select the shortest interval since the collections defined in ( [ mcij ] ) and ( [ cisj ] ) will always contain one which corresponds to the empty set .",
    "a more sensible goal is to try to select the interval with the smallest expected length or at least one which has expected length close to the smallest expected length .",
    "the approach we take here is to choose an interval for which the expected length is of the same order of magnitude as the standard deviation of the length .",
    "such an interval will always have expected length close to the shortest expected length . for the case of monotonically",
    "nondecreasing functions the selection of the interval from the countable collection in ( [ mcij ] ) can be done by creating another collection of estimators which can be used to estimate the expected length of the intervals .",
    "more specifically set @xmath243 .",
    "then for @xmath212 , @xmath244 s are independent of each other and both @xmath215 and @xmath216 are independent of @xmath245 for every @xmath246 .",
    "we should note that the estimators @xmath244 are similar to @xmath247 in that they are both differences of averages of @xmath0 to the left and right of the origin and thus estimate the average local change of the function . however @xmath248 are not independent for different @xmath234 whereas the @xmath244 are independent .",
    "it is thus natural to view the @xmath249 as a surrogate for @xmath250 with the technical advantage that they are independent .",
    "the selection of a @xmath234 for which @xmath244 has expected value close to @xmath229 will then result in a confidence interval @xmath238 close to the one with the smallest expected length .",
    "the independence properties of the @xmath244 allows us to guarantee a @xmath18 coverage probability while making this selection .",
    "more specifically the construction proceeds as follows .",
    "let @xmath251 and define the final confidence interval by @xmath252    before we turn to the analysis of this procedure we also introduce here a related confidence procedure in the convex case . here",
    "rather than introducing an independent estimate of the difference between the two estimators used in constructing the confidence interval , we proceed more directly .",
    "the basic idea is similar , but the dependence between the estimates of @xmath234 and the confidence interval constructed from this estimate requires that we adjust the original coverage level of our @xmath241 .",
    "more specifically let @xmath253 .",
    "when the expected value of @xmath254 is the same order as @xmath229 , the confidence interval @xmath241 will then be close to the one with the smallest expected length .",
    "our estimate of @xmath234 is given by an empirical version , namely @xmath255    although this estimate can be used to select the appropriate @xmath241 to use , as just mentioned , care also needs to be taken to make sure that the resulting selected interval maintains the required coverage probability . the analysis given below shows that a choice of @xmath256 in the construction of the original collection of intervals guarantees an overall coverage probability of @xmath257 .",
    "thus in the case of convex functions , we define our interval by @xmath258      in this section we present the properties of the confidence intervals @xmath259 and @xmath260 defined by ( [ m_ci ] ) and ( [ convex.ci ] ) focusing on the coverage and the expected length of these intervals .",
    "we begin with the confidence interval @xmath259 . in this case",
    "it is easy to check the coverage probability of @xmath259 by the independence of the interval @xmath238 and @xmath245 for every @xmath124 satisfying @xmath261 .",
    "the key to the analysis of the expected length is the introduction of @xmath262 where @xmath263    the analysis of the expected length relies on showing that @xmath264 is highly concentrated around @xmath262 .",
    "the concentration of @xmath264 around @xmath262 then provides a bound on the expected length of @xmath265 .",
    "these results , for which a proof is given in section  [ proof.sec ] are summarized in the following theorem .",
    "[ m.ci-el.thm ] let @xmath266 .",
    "the confidence interval @xmath259 defined in ( [ m_ci ] ) has coverage probability of at least @xmath267 for all monotonically nondecreasing functions @xmath240 and satisfies @xmath268 where @xmath269 is a constant and can be taken to be @xmath270 for all @xmath271 .",
    "[ rem1 ] the constant @xmath269 in theorem  [ m.ci-el.thm ] depends on the upper limit of @xmath257 .",
    "@xmath269 can be smaller if the upper limit on @xmath257 is reduced .",
    "for example , for common choices of @xmath272 or 0.01 , @xmath273 for @xmath274 , and @xmath275 for @xmath276 .",
    "theorem  [ m.ci-el.thm ] shows that the coverage probability is attained and also provides an upper bound on the expected length in terms of @xmath277 . in order to establish that this expected length is within a constant factor of the lower bound given in theorem  [ el.bound.thm ]",
    ", we need to provide a lower bound for @xmath278 in terms of @xmath279 .",
    "this connection is given in the following theorem .",
    "[ mel_lb ] let @xmath280 and let @xmath281",
    ". then @xmath282    combining theorems  [ m.ci-el.thm ] and  [ mel_lb ] , we have @xmath283 for all monotonically nondecreasing functions @xmath240 , where @xmath284 is a constant depending on @xmath257 only . for example , @xmath284 can be taken to be @xmath285 for @xmath272 and  @xmath286 for @xmath287 . hence , the confidence interval @xmath259 is uniformly within a constant factor of the benchmark @xmath288 for all monotonically nondecreasing functions @xmath5 and all confidence level @xmath289 .",
    "we now turn to an analysis of the properties of the confidence interval @xmath260 defined in ( [ convex.ci ] ) .",
    "the key to this analysis is the introduction of @xmath290 where @xmath291    the analysis of both the coverage probability and the expected length relies on showing that @xmath264 is highly concentrated around @xmath290 .",
    "the probability of not covering @xmath36 can be bounded by @xmath292 \\\\[-8pt ] \\nonumber & & { } + \\sum _ { l=-2}^{2 } p\\bigl ( f(0 ) \\notin \\mathrm{ci}_{j_*^c + l}\\bigr).\\end{aligned}\\ ] ] the first two terms are controlled by the high concentration of @xmath293 around @xmath290 , and the last term is controlled by proposition  [ m.cij.prop ] which bounds the coverage probability of any given @xmath234 .",
    "the concentration of @xmath264 around @xmath290 also allows control on the expected length of @xmath260 which leads to the following theorem .",
    "[ convex.ci-el.thm ] let @xmath266 .",
    "the confidence interval @xmath260 defined in ( [ convex.ci ] ) has coverage probability of at least @xmath267 for all convex @xmath5 and satisfies @xmath294 where @xmath269 is a constant and can be taken to be @xmath295 for all @xmath271 .",
    "[ rem2 ] the constant @xmath269 in theorem  [ convex.ci-el.thm ] depends on the upper limit of @xmath257 .",
    "@xmath269 can be smaller if the upper limit on @xmath257 is reduced .",
    "for example , for common choices of @xmath272 or 0.01 , @xmath296 for @xmath274 , and @xmath275 for @xmath276 .",
    "theorem  [ convex.ci-el.thm ] shows that the coverage probability is attained and also provides an upper bound on the expected length in terms of @xmath297 . as was the case for monotone functions , in order to to establish that this expected length for convex functions is within a constant factor of the lower bound given in theorem  [ el.bound.thm ] , we need to provide a lower bound for @xmath298 in terms of @xmath299 .",
    "this connection is given in the following theorem .",
    "[ el.bound2.thm ] let @xmath280 and let @xmath300 .",
    "then @xmath301    theorems  [ convex.ci-el.thm ] and  [ el.bound2.thm ] together yield @xmath302 for all convex functions @xmath242 , where @xmath303 is a constant depending on @xmath257 only . for example , @xmath303 can be taken to be @xmath304 for @xmath272 and @xmath305 for @xmath287 .",
    "hence , the confidence interval @xmath260 is uniformly within a constant factor of the benchmark @xmath306 for all convex functions @xmath5 and all confidence levels @xmath289 .",
    "we have so far focused on the white noise model . the theory presented in the earlier sections",
    "can also easily be extended to nonparametric regression .",
    "consider the regression model @xmath307 where @xmath308 and @xmath309 and where for notational convenience we index the observations from @xmath310 to @xmath311 .",
    "note that the noise level @xmath312 can be accurately estimated easily , as in hall , kay and titterington ( @xcite ) or @xcite .",
    "see also @xcite .",
    "we shall thus assume it is known in this section .",
    "then under the assumption that @xmath5 is convex or monotone , we wish to provide a confidence interval for @xmath36 .",
    "let @xmath313 .",
    "for @xmath314 define the local average estimators @xmath315 we should note that the indexing scheme is the reverse of that given for the white noise with drift process . here",
    "estimators @xmath316 ( or @xmath317 ) with small values of @xmath234 have smaller bias ( or larger bias ) and larger variance than those with larger values of @xmath234 .    as in the white noise model",
    "it is easy to check that @xmath316 has nonnegative bias and @xmath317 has nonpositive bias .",
    "simple calculations show that the variance of @xmath318 and @xmath319 are both @xmath320 , where @xmath321 .",
    "it is also important to introduce @xmath322 as in the white noise case , where @xmath323 .",
    "it is easy to check that @xmath324 , @xmath325 s are independent with each other , and both @xmath318 and @xmath326 are independent with @xmath327 for every @xmath328 .",
    "it then follows that @xmath329 $ ] has guaranteed coverage probability of at least @xmath267 over all monotonically nondecreasing functions .",
    "now set @xmath330 and define the confidence interval to be @xmath331 the properties of this confidence interval can then be analyzed in the same way as before and can be shown to be similar to those for the white noise model .",
    "in particular , the following result holds .",
    "[ mel_reg.thm ] let @xmath332 .",
    "the confidence interval @xmath333 defined in ( [ reg.mci ] ) has coverage probability of at least @xmath267 for all monotone functions @xmath5 and satisfies @xmath334 for all monotonically nondecreasing functions @xmath240 , where @xmath335 is a constant depending on @xmath257 only .      as in the monotone case , set @xmath313 .",
    "for @xmath336 define the local average estimators @xmath337 we should note that this indexing scheme is the reverse of that given for the white noise with drift process . here estimators @xmath338 with small values of @xmath234 have smaller bias and larger variance than those with larger values of @xmath234 . as in the white noise model it is easy to check that @xmath338 has nonnegative bias .",
    "it is also important to introduce an estimate which has a similar variance but is guaranteed to have nonpositive bias .",
    "the key step is to introduce @xmath339 as an estimate of the bias of @xmath338 .",
    "the following lemma gives the required properties of @xmath338 and @xmath254 .",
    "[ reg.bias.lem ] for any convex function @xmath5 , @xmath340    from ( [ reg.bias.bound2 ] ) it is clear that the biases of the estimators @xmath341 are nonnegative and monotonically nondecreasing . in addition straightforward calculations using both  ( [ reg.bias.bound1 ] ) and ( [ reg.bias.bound2 ] ) show that the estimators @xmath342 have a nonpositive and monotonically nonincreasing biases .",
    "simple calculations show that the variance of @xmath343 is @xmath344 .",
    "it then follows that @xmath345 $ ] has coverage over all convex functions .",
    "now set @xmath346 and define the confidence interval to be @xmath347 this confidence interval shares similar properties as the one for the white noise model . in particular , the following result holds .",
    "[ cel_reg.thm ] let @xmath332 .",
    "the confidence interval @xmath260 defined in ( [ reg.cci ] ) has coverage probability of at least @xmath267 for all convex function @xmath5 and satisfies @xmath348 for all convex function @xmath242 , where @xmath349 is a constant depending on @xmath257 only .",
    "the major emphasis of the paper has been to show that with shape constraints it is possible to construct confidence intervals that have expected length that adapts to individual functions . in this section",
    "we shall discuss briefly the maximum expected lengths of our procedures over lipschitz classes that are either monotone or convex in a way that is similar to that provided in dmbgen ( @xcite ) for the maximum width of a confidence band .",
    "we shall also explain how our results can be extended to the problem of estimating the value of @xmath5 at points other than @xmath33 .",
    "although the focus of the present paper has been on the construction of a confidence interval with the expected length adaptive to each individual convex or monotone function , these results do yield immediately adaptive minimax results for the expected length in the conventional sense .",
    "define @xmath350 the following results are direct consequence of theorems [ m.ci-el.thm ] and  [ convex.ci-el.thm ] .",
    "the confidence interval @xmath259 defined in ( [ m_ci ] ) satisfies @xmath351 simultaneously for all @xmath352 and @xmath353 , for some absolute constant @xmath335 .",
    "the confidence interval @xmath260 defined in ( [ convex.ci ] ) satisfies @xmath354 simultaneously for all @xmath355 and @xmath353 , for some absolute constant @xmath349 .",
    "we should note that these ranges of lipschitz classes are the only ones of interest in these cases . in particular",
    "suppose that @xmath7 is a confidence interval with guaranteed coverage over the class of monotonically nondecreasing functions .",
    "then for any @xmath13 the class @xmath19 includes the linear function @xmath356 . as shown in example  [ linear.ex ] in section  [ example.sec ] , @xmath103 hence , @xmath357 \\\\[-8pt ] \\nonumber & = & \\sup_{k}\\biggl ( 1 - \\frac{1}{\\sqrt{2\\pi } z_{\\alpha } } \\biggr ) ( 3k)^{{1}/{3}}z^{2/3}_{\\alpha}n^{-{1/3 } } = \\infty.\\end{aligned}\\ ] ]    a similar results holds for convex functions assumed to belong to @xmath19 with @xmath358 . on the other hand suppose",
    "@xmath5 is convex and assumed to belong to @xmath19 with @xmath359 .",
    "then from the assumption that @xmath5 is in @xmath19 it follows that @xmath360 .",
    "convexity then shows that @xmath361 and the maximum expected length over this class is given above .",
    "the focus of the present paper has been on the problem of estimating the value of @xmath36 .",
    "the basic development is similar for any other point @xmath362 in the interior of the interval @xmath363 $ ] unless @xmath362 is near to the boundary .",
    "more specifically for any @xmath364 we can consider estimators @xmath365 and @xmath366 where @xmath367 for monotone functions and @xmath368 where @xmath369 for convex functions .",
    "the basic theory is the same as before .    for monotonically nondecreasing functions ,",
    "the confidence interval @xmath238 is replaced by @xmath370\\ ] ] and the choice of @xmath264 is given by @xmath371 where @xmath372 .",
    "the final confidence interval is defined by @xmath373    for convex functions , the confidence interval @xmath241 is replaced by @xmath374,\\ ] ] and @xmath264 is chosen to be @xmath375 define the final confidence interval by @xmath376    the modulus of continuity defined in ( [ l.modulus ] ) is replaced by @xmath377 the earlier analysis then yields @xmath378 and @xmath379 where we now have @xmath380    finally we should note that at the boundary the construction of a confidence interval must be unbounded .",
    "for example any honest confidence interval for @xmath381 must be of the form @xmath382 ; otherwise it can not have guaranteed coverage probability .",
    "we prove the main results in this section .",
    "we shall omit the proofs for theorems  [ mel_reg.thm ] and  [ cel_reg.thm ] as they are analogous to those for the corresponding results in the white noise model .",
    "set @xmath383 .",
    "now note that @xmath384 is convex in @xmath385 for all @xmath386 .",
    "hence @xmath387 is also convex with @xmath388",
    ". for @xmath389 set @xmath390 , and it follows that @xmath391 .",
    "equation ( [ con.bias.eq ] ) follows from the fact that @xmath392 for @xmath393 , and equation ( [ con.eq ] ) follows from the fact that @xmath394 .      for any convex function @xmath5 ,",
    "let @xmath395 .",
    "then @xmath396 is convex , increasing in @xmath397 and @xmath398 .",
    "convexity of @xmath399 yields that for @xmath400 , @xmath401 note that @xmath402 and @xmath403 so @xmath404 is equivalent to @xmath405 which is the same as @xmath406 now note that for @xmath407 and @xmath408 , @xmath409 and consequently @xmath410 then ( [ aaaaa ] ) follows by taking @xmath411 and @xmath412 and then summing over @xmath413 .",
    "suppose that @xmath422 where it is known that @xmath423 $ ] .",
    "the confidence interval for @xmath424 which has guaranteed coverage over the interval @xmath423 $ ] and which minimizes the expected length when @xmath425 is given by @xmath426.\\ ] ]            now for @xmath441 , let @xmath442 .",
    "let @xmath434 be this collection of @xmath443 .",
    "now for the process @xmath444 there is a sufficient statistic @xmath445 given by @xmath446 note that @xmath445 has a normal distribution @xmath447 or more specifically @xmath448 .        for monotone functions",
    ", we have @xmath452 where @xmath453 is a standard normal random variable . because @xmath454 and @xmath455 , we have @xmath456 for convex functions , let @xmath457 .",
    "it follows from lemma  [ con.lem ] that @xmath458 , and hence we have @xmath459        note that @xmath460 because both @xmath215 and @xmath216 are independent of @xmath245 for @xmath246 , and the event @xmath461 depends only on @xmath245 for @xmath246 , then by proposition  [ m.cij.prop ] we have @xmath462    we now turn to the upper bound for the expected length .",
    "note that for @xmath463 , @xmath464 , and so we have @xmath465 it follows from @xmath466 that @xmath467 , and hence we have @xmath468 thus @xmath469 set @xmath470 for @xmath471 .",
    "then it is easy to see that @xmath472 thus @xmath473 the right - hand side is increasing in @xmath257 . through numerical calculations",
    ", we can see that , for @xmath474 , @xmath475 thus , by equation ( [ b8 ] ) , we have @xmath476      note that if @xmath477 , then @xmath478 and hence there is a @xmath479 such that we have either @xmath480 or @xmath481 . if @xmath482 , let @xmath483 and if @xmath484 , let @xmath485 then we have @xmath486 if @xmath487 , let",
    "@xmath488 then we have @xmath489 it then follows that @xmath490 and so @xmath491            to bound the coverage probability note that @xmath500 \\\\[-8pt ] \\nonumber & & { } + \\sum_{k = -2}^{2 } p\\bigl(f(0 ) \\notin \\mathrm{ci}_{j_*^c + k}\\bigr).\\end{aligned}\\ ] ] it then follows from equation ( [ too.early ] ) that @xmath501 for all @xmath266 .",
    "it is easy to verify directly that for all @xmath502 , @xmath503 .",
    "furthermore , it is easy to see that for @xmath494 , @xmath504 and so @xmath505 hence , @xmath506      we now turn to the upper bound for the expected length .",
    "note that @xmath510 hence @xmath511 \\\\[-8pt ] \\nonumber & & { } \\times\\biggl(p\\bigl ( \\hat j \\le j_*^c\\bigr ) + \\sum _ { k=1}^{\\infty } 2^{k/2 } p\\bigl(\\hat j = j_*^c + k\\bigr ) \\biggr).\\end{aligned}\\ ] ] set @xmath512 for @xmath471 .",
    "then it is easy to see that @xmath513 it then follows from ( [ too.far ] ) that @xmath514 the right - hand side is clearly increasing in @xmath257 .",
    "direct numerical calculations show that for @xmath474 , @xmath515 it then follows directly from ( [ el ] ) that @xmath516      note that if @xmath492 , then @xmath517 , and hence there is a @xmath518 satisfying @xmath519 such that @xmath520 , where @xmath521 .",
    "let @xmath79 be defined by @xmath522 there is also a @xmath79 as in the proof of lemma 5 in our other paper with @xmath523 for which @xmath524 if @xmath525 , then let @xmath526 , and then we have @xmath527 it then follows that @xmath528 and so @xmath529"
  ],
  "abstract_text": [
    "<S> adaptive confidence intervals for regression functions are constructed under shape constraints of monotonicity and convexity . </S>",
    "<S> a  natural benchmark is established for the minimum expected length of confidence intervals at a given function in terms of an analytic quantity , the local modulus of continuity . this bound depends not only on the function but also the assumed function class . </S>",
    "<S> these benchmarks show that the constructed confidence intervals have near minimum expected length for each individual function , while maintaining a given coverage probability for functions within the class . </S>",
    "<S> such adaptivity is much stronger than adaptive minimaxity over a collection of large parameter spaces .    , </S>"
  ]
}