{
  "article_text": [
    "consider a bounded subset @xmath0 of @xmath8 .",
    "we would like to find an arrangement of @xmath11 affine hyperplanes in @xmath8 that cut through @xmath0 as evenly as possible ; see figure  [ fig : tessellation ] for an illustration .",
    "the intuitive notion of an `` even cut '' can be expressed more formally in the following way : the fraction of the hyperplanes separating any pair @xmath2 should be proportional ( up to a small additive error ) to the euclidean distance between @xmath3 and @xmath4 . what is the smallest possible number @xmath12 of hyperplanes with this property ? besides having a natural theoretical appeal , this question is directly motivated by a certain problem of information theory which we will describe later .        in the beginning",
    "it will be most convenient to work with subsets @xmath0 of the unit euclidean sphere @xmath13 , but we will lift this restriction later .",
    "let @xmath14 denote the normalized geodesic distance on @xmath13 , so the distance between the opposite points on the sphere equals @xmath15 .",
    "a ( linear ) hyperplane in @xmath8 can be expressed as @xmath16 for some @xmath17 .",
    "we say that points @xmath18 are separated by the hyperplane , so we define it as @xmath19 for @xmath20 and @xmath21 for @xmath22 . ] if @xmath23 .",
    "consider a subset @xmath24 and an arrangement of @xmath11 hyperplanes in @xmath8 .",
    "let @xmath25 denote the fraction of the hyperplanes that separate points @xmath3 and @xmath4 in @xmath8 .",
    "given @xmath26 , we say that the hyperplanes provide a _",
    "@xmath27-uniform tessellation _ of @xmath0 if @xmath28    the main result of this paper is a bound on the minimal number @xmath29 of hyperplanes that provide a uniform tessellation of a set @xmath0 .",
    "it turns out that for a fixed accuracy @xmath27 , an almost optimal estimate on @xmath11 depends only on one global parameter of @xmath0 , namely the mean width .",
    "recall that the _ gaussian mean width _ of @xmath0 is defined as @xmath30 where @xmath31 is a standard gaussian random vector in @xmath8 .",
    "[ thm : tessellations ] consider a subset @xmath24 and let @xmath32 .",
    "let @xmath33 and consider an arrangement of @xmath11 independent random hyperplanes in @xmath8 uniformly distributed according to the haar measure .",
    "then with probability at least @xmath34 , these hyperplanes provide a @xmath27-uniform tessellation of @xmath0 . here and later",
    "@xmath35 denote positive absolute constants .    by the rotation invariance of the haar measure",
    ", it easily follows that @xmath36 for each pair @xmath18 .",
    "theorem  [ thm : tessellations ] states that with high probability , @xmath25 almost matches its expected value _",
    "uniformly _ over all @xmath2 .",
    "this observation highlights the principal difference between the problems studied in this paper and the classical problems on random hyperplane tessellations studied in stochastic geometry .",
    "the classical problems concern the shape of a _ specific _ cell ( usually the one containing the origin ) or certain _ statistics _ of cells ( e.g. `` how many cells have volume greater than a fixed number '' ? ) , see @xcite .",
    "in contrast to this , the concept of uniform tessellation we propose his paper concerns _ all _ cells simultaneously ; see section  [ s : cells ] for a vivid illustration .      theorem  [ thm : tessellations ] has an equivalent formulation in the context of metric embeddings .",
    "it yields that _ every subset @xmath24 can be almost isometrically embedded into the hamming cube @xmath9 with @xmath5_.    to explain this statement , let us recall a few standard notions .",
    "an @xmath37-isometry ( or almost isometry ) between metric spaces @xmath38 and @xmath39 is a map @xmath40 which satisfies @xmath41 and such that for every @xmath42 one can find @xmath43 satisfying @xmath44 .",
    "a map @xmath40 is an @xmath37-isometric embedding of @xmath45 into @xmath46 if the map @xmath47 is an @xmath37-isometry between @xmath38 and the subspace @xmath48 .",
    "it is not hard to show that @xmath45 can be @xmath49-isometrically embedded into @xmath46 ( by means of a suitable map @xmath50 ) if @xmath45 has the gromov - haussdorff distance at most @xmath37 from some subset of @xmath46 .",
    "conversely , if there is an @xmath37-isometry between @xmath45 and @xmath51 then the gromov - haussdorff distance between @xmath45 and @xmath51 is bounded by @xmath37 .    finally , recall that the hamming cube is the set @xmath9 with the ( normalized ) hamming distance @xmath52 the fraction of the coordinates where @xmath53 and @xmath54 are different .    an arrangement of @xmath11 hyperplanes in @xmath8",
    "defines a _ sign map _",
    "@xmath55 which sends @xmath56 to the sign vector of the orientations of @xmath3 with respect to the hyperplanes .",
    "the sign map is uniquely defined up to the isometries of the hamming cube .",
    "let @xmath57 be normals of the hyperplanes , and consider the @xmath58 matrix @xmath59 with rows @xmath60 .",
    "the sign map can be expressed as @xmath61 where @xmath62 denotes the vector of signs of the coordinates @xmath63 of @xmath64 .",
    "the fraction @xmath25 of the hyperplanes that separate points @xmath3 and @xmath4 thus equals @xmath65 then looking back at the definition of uniform tessellations , we observe the following fact :    [ fact : embeddings ] consider a @xmath27-uniform tessellation of a set @xmath24 by @xmath11 hyperplanes .",
    "then the set @xmath0 ( with the induced geodesic distance ) can be @xmath27-isometrically embedded into the hamming cube @xmath9 .",
    "the sign map provides such an embedding .",
    "this allows us to state theorem  [ thm : tessellations ] as follows :    [ thm : embeddings ] consider a subset @xmath24 and let @xmath32 .",
    "let @xmath66 then @xmath0 can be @xmath27-isometrically embedded into the hamming cube @xmath9 .",
    "moreover , let @xmath59 be an @xmath58 random matrix with independent @xmath67 entries .",
    "then with probability at least @xmath34 , the sign map @xmath68 is an @xmath27-isometric embedding .",
    "the image of the sign map @xmath50 in has a special meaning .",
    "when the hamming cube @xmath9 is viewed as a graph ( in which two points @xmath53 , @xmath54 are connected if they differ in exactly one coordinate ) , the image of @xmath50 defines a subgraph of @xmath9 , which is called the _ tessellation graph _ of @xmath0 .",
    "the tessellation graph has a vertex for each cell and an edge for each pair of adjacent cells , see figure  [ fig : tessellation - graph ] .",
    "notice that the graph distance in the tessellation graph equals the number of hyperplanes that separate the two cells",
    ". therefore the definition of a uniform tessellation yields :    [ fact : graph ] consider a @xmath27-uniform tessellation of a set @xmath24 .",
    "then @xmath0 is @xmath27-isometric to the tessellation graph of @xmath0 .",
    "hence we can read the conclusion of theorem  [ thm : tessellations ] as follows : _",
    "@xmath0 is @xmath27-isometric to the graph of its tessellation by @xmath11 random hyperplanes , where @xmath69_.          powerful methods to estimate the mean width @xmath6 have been developed in connection with stochastic processses .",
    "these methods include sudakov s and dudley s inequalities which relate @xmath6 to the covering numbers of @xmath0 in the euclidean metric , and the sharp technique of majorizing measures ( see @xcite ) .",
    "mean width has a simple ( and known ) geometric interpretation . by the rotational invariance of the gaussian random vector @xmath70 in",
    ", one can replace @xmath70 with a random vector @xmath71 that is uniformly distributed on @xmath13 , as follows : @xmath72 here @xmath73 are numbers that depend only on @xmath74 and such that @xmath75 and @xmath76 .",
    "we may refer to @xmath77 as the _ spherical mean width _ of @xmath0 .",
    "let us assume for simplicity that @xmath0 is symmetric with respect to the origin .",
    "then @xmath78 is the width of @xmath0 in the direction @xmath71 , which is the distance between the two supporting hyperplanes of @xmath0 whose normals are @xmath71 .",
    "the spherical mean width @xmath77 is then twice the average width of @xmath0 over all directions .",
    "our results are already non - trivial in the particular case @xmath79 . since @xmath80 ,",
    "theorems  [ thm : tessellations ] and [ thm : embeddings ] hold with @xmath81 . but more importantly",
    ", many interesting sets @xmath82 satisfy @xmath83 and therefore make our results hold with @xmath84 . in such cases",
    ", one can view the sign map @xmath85 in theorem  [ thm : embeddings ] as a dimension reduction mechanism that transforms an @xmath74-dimensional set @xmath0 into a subset of @xmath9 .",
    "a heuristic reason why dimension reduction is possible is that the quantity @xmath86 measures the _ effective dimension _ of a set @xmath24 .",
    "the effective dimension @xmath86 of a set @xmath24 is always bounded by the algebraic dimension , but it may be much smaller and it is robust with respect to perturbations of @xmath0 . in this regard ,",
    "the notion of effective dimension is parallel to the notion of effective rank of a matrix from numerical linear algebra ( see e.g. @xcite ) . with these observations in mind ,",
    "it is not surprising that the `` true '' , effective dimension of @xmath0 would be revealed ( and would be the only obstruction according to theorem  [ thm : embeddings ] ) when @xmath0 is being squeezed into a space of smaller dimension .",
    "let us illustrate dimension reduction on the example of finite sets @xmath82 .",
    "since @xmath87 ( see e.g. ( * ? ? ?",
    "* ( 3.13 ) ) ) , theorem  [ thm : embeddings ] holds with @xmath88 , and we can state it as follows .",
    "[ cor : jl ] let @xmath82 be a finite set .",
    "let @xmath26 and @xmath89 .",
    "then @xmath0 can be @xmath27-isometrically embedded into the hamming cube @xmath9 .",
    "this fact should be compared to the _ johnson - lindenstrauss lemma _ for finite subsets @xmath90 ( @xcite , see ( * ? ? ?",
    "* section  15.2 ) ) which states that if @xmath91 then @xmath0 can be lipschitz embedded into @xmath92 as follows : @xmath93 here @xmath94 is the rescaled random gaussian matrix @xmath59 from theorem  [ thm : embeddings ] . note",
    "that while the johnson - lindenstrauss lemma involves a lipschitz embedding from @xmath8 to @xmath92 , it is generally impossible to provide a lipschitz embedding from subsets of @xmath8 to the hamming cube ( if there are points @xmath95 that are very close to each other ) ; this is why we consider @xmath27-isometric embeddings .    like the johnson - lindenstrauss lemma ,",
    "corollary  [ cor : jl ] can be proved directly by combining concentration inequalities for @xmath25 with a union bound over @xmath96 pairs @xmath97 .",
    "in fact , this method of proof allows for the weaker requirement @xmath98 .",
    "however , as we discuss later , this argument can not be generalized in a straightforward way to prove theorem  [ thm : embeddings ] for general sets @xmath0 .",
    "the hamming distance @xmath25 is highly discontinuous , which makes it difficult to extend estimates from points @xmath99 in an @xmath37-net of @xmath0 to nearby points .",
    "we mentioned two nice features of uniform tessellations in facts  [ fact : embeddings ] and [ fact : graph ] .",
    "let us observe one more property : all cells of a uniform tessellation have small diameter .",
    "indeed , @xmath100 iff points @xmath99 are in the same cell , so by we have :    [ fact : cells ] every cell of a @xmath27-uniform tessellation has diameter at most @xmath27 .    with this , theorem  [ thm : tessellations ] immediately implies the following :    [ cor : cells ] consider a tessellation of a subset @xmath24 by @xmath101 random hyperplanes .",
    "then , with probability at least @xmath102 , all cells of the tessellation have diameter at most @xmath27 .",
    "this result has also a direct proof , which moreover gives a slightly better bound @xmath103 .",
    "we present this `` curvature argument '' in section  [ sec : curvature ] .",
    "so far , we only worked with subsets @xmath24 .",
    "it is not difficult to extend our results to bounded sets @xmath90 .",
    "this can be done by embedding such a set @xmath0 into @xmath104 ( the sphere in one more dimension ) with small bi - lipschitz distortion .",
    "this elementary argument is presented in section  [ sec : rn ] , and it yields the following version of theorem  [ thm : tessellations ] :    [ thm : tessellations rn ] consider a bounded subset @xmath90 with @xmath105 .",
    "let @xmath106 then there exists an arrangement of @xmath11 affine hyperplanes in @xmath8 and a scaling factor @xmath107 such that @xmath108 here @xmath25 denotes the fraction of the affine hyperplanes that separate @xmath3 and @xmath4 .",
    "[ rem : k - k ] while the quantity @xmath109 appearing in is clearly bounded by @xmath110 , it is worth noting that the quantity @xmath109 captures more accurately than @xmath6 the geometric nature of the `` mean width '' of @xmath0 .",
    "indeed , @xmath111 where @xmath112 is the distance between the two parallel supporting hyperplanes of @xmath0 orthogonal to the random direction @xmath70 , scaled by @xmath113 .",
    "the main object of our study is @xmath114 , the smallest number of hyperplanes that provide a @xmath27-uniform tessellation of a set @xmath24 .",
    "one has @xmath115 where @xmath116 denotes the covering number of @xmath0 , i.e.  the smallest number of balls of radius @xmath27 that cover @xmath0 .",
    "the upper bound in is the conclusion of theorem  [ thm : tessellations ] .",
    "the lower bound holds because a @xmath27-uniform tessellation provides a decomposition of @xmath0 into at most @xmath117 cells each of which lies in a ball of radius @xmath27 by fact  [ fact : cells ] .    to compare the upper and lower bounds in , recall sudakov s inequality ( * ? ? ?",
    "* theorem  3.18 ) that yields @xmath118 while sudakov s inequality can not be reversed in general , there are many situations where it is sharp . moreover , according to dudley s inequality ( see ( * ? ? ?",
    "* theorem 11.17 ) and ( * ? ? ?",
    "* lemma  2.33 ) ) , sudakov s inequality can always be reversed for some scale @xmath26 and up to a logarithmic factor in @xmath74 .",
    "( see also @xcite for a discussion of sharpness of sudakov s inequality . )",
    "so the two sides of are often close to each other , but there is in general some gap .",
    "we conjecture that the optimal estimate is @xmath119 so the mean width of @xmath0 seems to be completely responsible for the uniform tessellations of @xmath0 .",
    "note that the lower bound in holds in greater generality .",
    "namely , it is not possible to have @xmath120 for _ any _ decomposition of @xmath0 into @xmath117 pieces of diameter at most @xmath27 .",
    "however , from the upper bound we see that with a slightly larger value @xmath121 , _ an almost best decomposition of @xmath0 is achieved by a random hyperplane tessellation_.    in this paper we have not tried to optimize the dependence of @xmath122 on @xmath27 .",
    "this interesting problem is related to the open question on the optimal dependence on distortion in dvoretzky s theorem .",
    "we comment on this in section  [ sec : dvoretzky ] .",
    "embeddings of subsets @xmath24 into normed spaces were studied in geometric functional analysis @xcite . in particular , klartag and mendelson @xcite",
    "were concerned with embeddings into @xmath123 .",
    "they showed that for @xmath124 there exists a linear map @xmath125 such that @xmath126 one can choose @xmath59 to be an @xmath58 random matrix with gaussian entries as in theorem  [ thm : embeddings ] , or with sub - gaussian entries .",
    "schechtman @xcite gave a simpler argument for a gaussian matrix , which also works for embeddings into general normed spaces @xmath45 .",
    "in the specific case of @xmath127 , schechtman s result states that for @xmath124 one has @xmath128 this result also follows from lemma  [ lem : concentration ] below .",
    "our present work was motivated by the development of _ one - bit compressed sensing _ in @xcite where theorem  [ thm : embeddings ] is used in the following context .",
    "the vector @xmath3 represents a signal ; the matrix @xmath59 represents a measurement map @xmath129 that produces @xmath130 linear measurements of @xmath3 ; taking the sign of @xmath64 represents quantization of the measurements ( an extremely coarse , one - bit quantization ) .",
    "the problem of one - bit compressed sensing is to recover the signal @xmath3 from the quantized measurements @xmath85 .",
    "the problem of one - bit compressed sensing was introduced by boufounos and baraniuk @xcite .",
    "jacques , laska , boufounos and baraniuk @xcite realized a connection of this problem to uniform tessellations of the set of sparse signals @xmath131 , and to almost isometric embedding of @xmath0 into the hamming cube @xmath9 . for this",
    "set @xmath0 , they proved corollary  [ cor : cells ] with @xmath132 and a version of theorem  [ thm : embeddings ] for @xmath133 .",
    "the authors of the present paper analyzed in @xcite a bigger set of `` compressible '' signals @xmath134 and proved for @xmath135 a version of corollary  [ cor : cells ] with @xmath136 . since the mean widths of both sets @xmath0 and @xmath135 are of the order @xmath137 , theorem  [ thm : embeddings ] holds for these sets with @xmath138 .",
    "in other words , apart from the dependence of @xmath27 ( which is an interesting problem ) , the prior results follow as partial cases from theorem  [ thm : embeddings ] .",
    "it is important to note that theorem  [ thm : embeddings ] addresses only the theoretical aspect of one - bit compressed sensing problem , which guarantees that the quantized measurement map @xmath85 well preserves the geometry of signals .",
    "but one also faces an algorithmic challenge  how to efficiently recover @xmath3 from @xmath139 , and specifically in polynomial time .",
    "we will not touch on this algorithmic aspect here but rather refer the reader to @xcite and to our forthcoming work which is based on the results of this paper .",
    "_ locality - sensitive hashing _ is a method of dimension reduction .",
    "one takes a set of high - dimensional vectors in @xmath8 and the goal is to hash nearby vectors to the same bin with high probability .",
    "more generally , one may desire that the distance between bins be nearly proportional to the distance between the original items .",
    "there have been a number of papers which suggest to create such mappings onto the hamming cube @xcite , some of which use a random hyperplane tessellation as defined in this paper .",
    "the new challenge considered herein is to create a locality - sensitve hashing for an infinite set .",
    "let us briefly describe our proof of the results stated above . since the distance in the hamming cube @xmath9 can be expressed as @xmath140 , the hamming cube is isometrically embedded in @xmath141 . before trying to embed @xmath24 into the hamming cube as claimed in theorem  [ thm : embeddings ]",
    ", we shall make a simpler step and embed @xmath0 almost isometrically into the bigger space @xmath141 with @xmath142 .",
    "a result of this type was given by schechtman @xcite . in section  [ sec : into ell1 ] we prove a similar result by a simple and direct argument in probability in banach spaces .",
    "our next and non - trivial step is to re - embed the set from @xmath141 into its subset , the hamming cube @xmath9 . in section  [ sec : curvature ]",
    "we give a simple `` curvature argument '' that allows us to deduce corollary  [ cor : cells ] on the diameter of cells , and even with a better dependence on @xmath27 , namely @xmath103 .",
    "however , a genuine limitation of the curvature argument makes it too weak to deduce theorem  [ thm : tessellations ] this way .",
    "we instead attempt to prove theorem  [ thm : tessellations ] by an @xmath37-net argument , which typically proceeds as follows : ( a ) show that @xmath143 holds for a fixed pair @xmath2 with high probability ; ( b ) take the union bound over all pairs @xmath99 in an finite @xmath37-net @xmath144 of @xmath0 ; ( c ) extend the estimate from @xmath144 to @xmath0 by approximation .",
    "unfortunately , as we indicate in section  [ sec : soft ] the approximation step ( c ) must fail due to the discontinuity of the hamming distance @xmath25 .",
    "a solution proposed in @xcite was to choose @xmath37 so small that none of the random hyperplanes pass near points @xmath145 with high probability .",
    "this strategy was effective for the set @xmath131 because the covering number of this specific set @xmath0 has a mild ( logarithmic ) dependence on @xmath37 , namely @xmath146 .",
    "however , adapting this strategy to general sets @xmath0 would cause our estimate on @xmath11 to increase by a factor of @xmath74 .",
    "the solution we propose in the present paper is to `` soften '' the hamming distance ; see section  [ sec : soft ] for the precise notion .",
    "the _ soft hamming distance _ enjoys some continuity properties as described in lemmas  [ lem : continuity ] and [ lem : continuity l1 ] . in section  [ sec : proof tessellations ]",
    "we develop the @xmath37-net argument for the soft hamming distance .",
    "interestingly , the approximation step ( c ) for the soft hamming distance will be based on the embedding of @xmath0 into @xmath141 , which incidentally was our point of departure .      throughout the paper , @xmath147 , @xmath148 , @xmath149 , etc",
    ".  denote positive absolute constants whose values may change from line to line . for integer @xmath74 ,",
    "we denote @xmath150 = \\{1,\\ldots , n\\}$ ] .",
    "the @xmath151 norms of a vector @xmath56 for @xmath152 are defined as is not a norm on @xmath8 . ]",
    "@xmath153 : x(i ) \\ne 0 \\ } | , \\ ; \\|x\\|_1 = \\sum_{i=1}^n |x_i| , \\ ; \\|x\\|_2 = \\big ( \\sum_{i=1}^n x_i^2 \\big)^{1/2 } , \\ ; \\|x\\|_\\infty = \\max_{i \\in [ n ] } |x_i|.\\ ] ] we shall work with normed spaces @xmath154 for @xmath155 . the unit euclidean ball in @xmath8 is denoted @xmath156 and the unit euclidean sphere is denoted @xmath157 .    as usual",
    ", @xmath67 stands for the univariate normal distribution with zero mean and unit variance , and @xmath158 stands for the multivariate normal distribution in @xmath8 with zero mean and whose covariance matrix is identity @xmath159 .",
    "[ lem : concentration ] consider a bounded subset @xmath90 and independent random vectors @xmath161 in @xmath8 .",
    "let @xmath162    \\(a ) one has @xmath163",
    "\\(b ) the following deviation inequality holds : @xmath164 where @xmath165 .",
    "\\(a ) note that @xmath166 for all @xmath167 .",
    "let @xmath168 be a sequence of iid rademacher random variables .",
    "a standard symmetrization argument ( see ( * ? ? ?",
    "* lemma 6.3 ) ) followed by the contraction principle ( see ( * ? ? ? * theorem 4.12 ) ) yields that @xmath169 by the rotational invariance of the gaussian distribution , @xmath170 is distributed identically with @xmath171 where @xmath172 .",
    "therefore @xmath173 this proves the upper bound in .",
    "\\(b ) we combine the result of ( a ) with the gaussian concentration inequality . to this end",
    ", we must first show that the map @xmath174 is lipschitz where @xmath175 is considered as a matrix in the space @xmath176 equipped with frobenius norm @xmath177 ( which coincides with the euclidean norm on @xmath176 ) .",
    "it follows from two applications of the triangle inequality followed by two applications of the cauchy - schwarz inequality that for @xmath178 we have @xmath179 thus @xmath180 has lipschitz constant bounded by @xmath181 .",
    "we may now bound the deviation probability for @xmath180 using the gaussian concentration inequality ( see ( * ? ? ? * equation 1.6 ) ) as follows : @xmath182 the deviation inequality now follows from the bound on @xmath183 from ( a ) .",
    "[ rem : rmt ] one can state lemma  [ lem : concentration ] in terms of random matrices .",
    "indeed , let @xmath59 be an @xmath58 random matrix with independent @xmath67 entries .",
    "then its rows @xmath60 satisfy the assumption of lemma  [ lem : concentration ] , and we can express @xmath180 as @xmath184    using this remark for the set @xmath185 , we obtain a linear embedding of @xmath0 into @xmath160 :    [ cor : into l1 ] consider a subset @xmath186 and let @xmath26 .",
    "let @xmath187 then , with probability at least @xmath188 , the linear map @xmath189 defined as @xmath190 is a @xmath27-isometry .",
    "thus @xmath0 can be linearly embedded into @xmath141 with gromov - haussdorff distortion at most @xmath27 .",
    "let @xmath59 be the random matrix as in remark  [ rem : rmt ] .",
    "using lemma  [ lem : concentration ] for @xmath185 and noting the form of @xmath180 in , we conclude that the following event holds with probability at least @xmath188 : @xmath191    the above argument shows in fact that corollary  [ cor : into l1 ] holds for @xmath192 as we noticed in remark  [ rem : k - k ] , the quantity @xmath109 more accurately reflects the geometric meaning of the mean width than @xmath6 .    note that for the subspace @xmath193 we have from that @xmath194",
    ". then lemma  [",
    "lem : concentration ] implies that @xmath195 by rotation invariance of gaussian distribution , inequality holds for a random subspace @xmath196 in @xmath8 of given codimension @xmath197 , uniformly distributed according to the haar measure .",
    "this result recovers ( up to the absolute constant @xmath198 which can be improved ) the so - called _",
    "low m@xmath199 estimate _ from geometric functional analysis , see ( * ? ? ?",
    "* section 15.1 ) .",
    "as we emphasized in the introduction , for many sets @xmath90 one has @xmath200 .",
    "in such cases corollary  [ cor : into l1 ] works for @xmath130 .",
    "the embedding of @xmath0 into @xmath141 yields dimension reduction for @xmath0 ( from @xmath74 to @xmath201 dimensions ) .",
    "for example , if @xmath0 is a finite set then @xmath87 ( see e.g. ( * ? ? ? * ( 3.13 ) ) ) , and so corollary  [ cor : into l1 ] applies with @xmath88 .",
    "this gives the following variant of the _ johnson - lindenstrauss lemma _ : every finite subset of a euclidean space can be linearly embedded in @xmath141 with @xmath202 and with small distortion in the gromov - haussdorff metric .",
    "stronger variants of johnson - lindenstrauss lemma are known for _ lipschitz _ rather than gromov - haussdorff embeddings into @xmath123 and @xmath141 @xcite . however , for general sets @xmath0 ( in particular for any set with nonempty interior ) a lipschitz embedding into lower dimensions is clearly impossible ; still a gromov - haussdorff embedding exists due to corollary  [ cor : into l1 ] .",
    "in this section we give a short argument that leads to a version of corollary  [ cor : cells ] with a slightly better dependence of @xmath11 on @xmath27 .",
    "[ thm : cells ] consider a subset @xmath24 and let @xmath32 .",
    "let @xmath203 and consider an arrangement of @xmath11 independent random hyperplanes in @xmath8 that are uniformly distributed according to the haar measure . then , with probability at least @xmath204 , all cells of the tessellation have diameter at most @xmath27 .",
    "the argument is based on lemma  [ lem : concentration ] .",
    "if points @xmath2 belong to the same cell , then the midpoint @xmath205 also belongs to the same cell ( after normalization ) . using lemma  [ lem : concentration ] one",
    "can then show that @xmath206 . due to the curvature of the sphere , this forces the length of the interval @xmath207 to be small , which means that the diameter of the cell is small .",
    "the formal argument is below .",
    "we represent the random hyperplanes as @xmath208 , where @xmath161 are independent random vectors in @xmath8 .",
    "let @xmath209 be as in the assumptions of the theorem .",
    "we shall apply lemma  [ lem : concentration ] for the sets @xmath0 and @xmath210 and for @xmath211 , where we set @xmath212 . since the diameters of both these sets are bounded by @xmath15",
    ", we obtain that with probability at least @xmath204 the following event holds : @xmath213    assume that the event holds .",
    "consider a pair of points @xmath2 that belong to the same cell of the tessellation , which means that @xmath214.\\ ] ] to complete the proof is suffices to show that @xmath215 .",
    "this will give desired diameter @xmath27 in the euclidean metric .",
    "furthermore , since for small @xmath27 the euclidean and the geodesic distances are equivalent , the conclusion will hold for the geodesic distance as well .",
    "we shall use for @xmath216 and for the midpoint @xmath217 .",
    "clearly @xmath218 , hence @xmath219.\\ ] ] therefore we obtain from that @xmath220 - \\e \\\\    & \\ge \\frac{1}{2 } ( \\|x\\|_2-\\e + \\|y\\|_2-\\e ) - \\e    = 1 - 2\\e .",
    "\\nonumber\\end{aligned}\\ ] ] by the parallelogram law , we conclude that @xmath221 this completes the proof .      unfortunately , the curvature argument does not lend itself to proving the more general result , theorem  [ thm : tessellations ] on uniform tessellations . to see why ,",
    "suppose @xmath2 do not belong to the same cell but instead @xmath222 for some small @xmath223 .",
    "consider the set of mismatched signs @xmath224:\\ ; \\operatorname*{sign}\\ < a_i , x\\ > \\ne \\operatorname*{sign}\\ < a_i , y\\ >",
    "\\big\\ } ; \\qquad \\frac{|t|}{m } = d.\\ ] ] these signs create an additional error term in the right hand side of , which is @xmath225 by analogy with lemma  [ lem : concentration ] , we can expect that this term should be approximately equal @xmath226 .",
    "if this is true , then becomes in our situation @xmath227 , which leads as before to @xmath228 .",
    "ignoring @xmath37 , we see that the best estimate the curvature argument can give is @xmath229 rather than @xmath230 that is required in theorem  [ thm : tessellations ] .",
    "the weak point of this argument is that it takes into account the size of @xmath231 but ignores the nature of @xmath231 . for every @xmath232 ,",
    "the hyperplane @xmath208 passes through the arc connecting @xmath3 and @xmath4 .",
    "if the length of the arc @xmath14 is small , this creates a strong constraint on @xmath60 .",
    "conditioning the distribution of @xmath60 on the constraint that @xmath232 creates a bias toward smaller values of @xmath233 and @xmath234 . as a result",
    ", the conditional expected value of the error term should be smaller than @xmath235 .",
    "computing this conditional expectation is not a problem for a given pair @xmath99 , but it seems to be difficult to carry out a uniform argument over @xmath2 where the ( conditional ) distribution of @xmath60 depends on @xmath99 .",
    "we instead propose a different and somewhat more conceptual way to deduce theorem  [ thm : tessellations ] from lemma  [ lem : concentration ] .",
    "this argument will be developed in the rest of this paper .",
    "the unusual dependence @xmath236 in theorem  [ thm : cells ] is related to the open problem of the optimal dependence on distortion in the dvoretzky theorem .",
    "indeed , consider the special case of the tessellation problem where @xmath79 and @xmath237 .",
    "then lemma  [ lem : concentration ] in its geometric formulation ( see equation and corollary  [ cor : into l1 ] ) states that @xmath238 embeds into @xmath141 whenever @xmath239 , meaning that @xmath240 where @xmath241 .",
    "equivalently , there exists an @xmath74-dimensional subspace of @xmath141 that is @xmath242-euclidean , where @xmath243 .",
    "this result recovers the well known dvoretzky theorem in v.  milman s formulation ( see ( * ? ? ?",
    "* theorem 4.2.1 ) ) for the space @xmath141 , and with the best known dependence on @xmath37 .",
    "however , it is not known whether @xmath244 is the optimal dependence for @xmath141 ; see @xcite for a discussion of the general problem of dependence on @xmath37 in dvoretzky theorem .",
    "these observation suggest that we can reverse our logic .",
    "suppose one can prove dvoretzky theorem for @xmath141 with a better dependence on @xmath37 , thereby constructing a @xmath242-euclidean subspace of dimension @xmath245 with @xmath246",
    ". then such construction can replace lemma  [ lem : concentration ] in the curvature argument .",
    "this will lead to theorem  [ thm : cells ] for @xmath79 with an improved dependence on @xmath27 , namely with @xmath247 .",
    "concerning lower bounds , the best possible dependence of @xmath11 on @xmath27 should be @xmath248 , which follows by considering the case @xmath249 .",
    "this dependence will be achieved if dvoretzky theorem for @xmath141 is valid with @xmath250 .",
    "this is unknown .",
    "our proof of theorem  [ thm : tessellations ] will be based on a covering argument .",
    "a standard covering argument of geometric functional analysis would proceed in our situation as follows :    a.   show that @xmath143 with high probability for a fixed pair @xmath99 .",
    "this can be done using standard concentration inequalities .",
    "b.   prove that @xmath143 uniformly for all @xmath99 in a finite @xmath37-net @xmath144 of @xmath0 .",
    "sudakov s inequality can be used to estimate the cardinality of @xmath144 via the mean width @xmath6 .",
    "the conclusion will follow from step 1 by the union bound over @xmath251 . c.   extend the estimate @xmath143 from @xmath145 to @xmath2 by approximation .    while the first two steps are relatively standard , step ( c ) poses a challenge in our situation .",
    "the hamming distance @xmath25 is a discontinuous function of @xmath99 , so it is not clear whether the estimate @xmath143 can be extended from a pair points @xmath145 to a pair of nearby points .",
    "in fact , for some tessellations this task is impossible . figure  [ fig : non - uniform - tessellation ] shows that there exist very non - uniform tessellations that are nevertheless very uniform for an @xmath37-net , namely one has @xmath252 for all @xmath145 .",
    "the set @xmath0 in that example is a subset of the plane @xmath253 , and one can clearly embed such a set with into the sphere @xmath254 as well .",
    "\\times [ -\\frac{\\e}{2},\\frac{\\e}{2}]$ ] is very non - uniform , as all cells have diameter at least @xmath15 .",
    "the tessellation is nevertheless very uniform for the @xmath37-net @xmath255 , as @xmath256 for all @xmath145.,height=83 ]    to overcome the discontinuity problem , we propose to work with a soft version of the hamming distance .",
    "recall that @xmath11 hyperplanes are determined by their normals @xmath257 , which we organize in an @xmath58 matrix @xmath59 with rows @xmath60 .",
    "then the usual ( `` hard '' ) hamming distance @xmath25 on @xmath8 with respect to @xmath59 with can be expressed as @xmath258    consider an @xmath58 matrix @xmath59 with rows @xmath259 , and let @xmath260 .",
    "the _ soft hamming distance _",
    "@xmath261 on @xmath8 is defined as @xmath262    both positive and negative @xmath263 may be considered . for positive @xmath263",
    "the soft hamming distance counts the hyperplanes that separate @xmath99 well enough ; for negative @xmath263 it counts the hyperplanes that separate or nearly separate @xmath99 .",
    "clearly @xmath261 is a non - increasing function of @xmath263 .",
    "moreover , @xmath264    the soft hamming distance for a fixed @xmath263 is as discontinuous as the usual ( hard ) hamming distance .",
    "however , some version of continuity emerges when we allow @xmath263 to vary slightly :    [ lem : continuity ] let @xmath265 , and assume that @xmath266 , @xmath267 for some @xmath268 .",
    "then for every @xmath260 one has @xmath269    consider the events @xmath270 from the definition of the soft hamming distance . by the assumptions",
    ", we have @xmath271 , @xmath272 for all @xmath273 $ ] .",
    "this implies by the triangle inequality that @xmath274 the conclusion of the lemma follows .",
    "we are ready to state a stronger version of theorem  [ thm : tessellations ] for the soft hamming distance .",
    "[ thm : tessellations soft ] consider a subset @xmath24 and let @xmath32 .",
    "let @xmath33 and pick @xmath260 .",
    "consider an @xmath58 random ( gaussian ) matrix @xmath59 with independent rows @xmath161 . then with probability at least @xmath102 ,",
    "one has @xmath275    note that if we take @xmath276 in the above theorem , we recover theorem  [ thm : tessellations ] . however , we find it easier to prove the result for general @xmath263 , since in our argument we will work with different values of the @xmath263 for the soft hamming distance .    theorem  [ thm : tessellations soft ] is proven in the next section .",
    "we will follow the covering argument outlined in the beginning of section  [ sec : soft ] , but instead of @xmath25 we shall work with the soft hamming distance @xmath261 .      at the first step , we will check that @xmath277 with high probability for a fixed pair @xmath99 .",
    "let us first verify that this estimate holds in expectation , i.e. that @xmath278 .",
    "one can easily check that @xmath279 so we may just compare @xmath280 to @xmath281 .",
    "here is a slightly stronger result :    [ eq : edt ed ] let @xmath59 be a random gaussian matrix be as in theorem  [ thm : tessellations soft ] .",
    "then , for every @xmath260 and every @xmath18 , one has @xmath282    the first inequality follows from and jensen s inequality .",
    "to prove the second inequality , we use the events @xmath283 and @xmath284 from equations , defining the hard and soft hamming distances , respectively .",
    "it follows that @xmath285    now we upgrade lemma  [ eq : edt ed ] to an concentration inequality :    [ lem : concentration dist ] let @xmath59 be a random gaussian matrix as in theorem  [ thm : tessellations soft ] .",
    "then , for every @xmath260 and every @xmath18 , the following deviation inequality holds : @xmath286    by definition , @xmath287 has the binomial distribution @xmath288 . the parameter @xmath289 satisfies by lemma  [ eq : edt ed ] that @xmath290 a standard chernoff bound for binomial random variables states that @xmath291 see e.g. ( * ?",
    "* corollary  a.1.7 ) .",
    "the triangle inequality completes the proof .",
    "let us fix a small @xmath268 whose value will be determined later .",
    "let @xmath144 be an @xmath37-net of @xmath0 in the euclidean metric .",
    "by sudakov s inequality ( see ( * ? ? ?",
    "* theorem  3.18 ) ) , we can arrange the cardinality of @xmath144 to satisfy @xmath292 we can decompose every vector @xmath7 into a _ center _",
    "@xmath293 and a _ tail _",
    "@xmath294 so that @xmath295 we first control the centers by taking a union bound in lemma  [ lem : concentration dist ] over the net @xmath144 :    [ lem : concentration net ] let @xmath59 a random gaussian matrix be as in theorem  [ thm : tessellations soft ] .",
    "let @xmath144 be a subset of @xmath13 whose cardinality satisfies .",
    "let @xmath26 , and assume that @xmath296 let @xmath260 .",
    "then the following holds with probability at least @xmath297 : @xmath298    by lemma  [ lem : concentration net ] and a union bound over the set of pairs @xmath299 , we obtain @xmath300 where the last inequality follows by and .",
    "the proof is complete .",
    "now we control the tails @xmath301 in decomposition .",
    "[ lem : tails ] consider a subset @xmath24 and let @xmath268 .",
    "let @xmath302 consider independent random vectors @xmath161 .",
    "then with probability at least @xmath303 , one has @xmath304    let us apply lemma  [ lem : concentration ] for the set @xmath305 instead of @xmath0 , and for @xmath306 .",
    "since @xmath307 , we obtain that the following holds with probability at least @xmath308 : @xmath309 note that @xmath310 . so using the assumption on @xmath11 we conclude that the quantity in is bounded by @xmath37 , as claimed .",
    "now we establish a way to transfer the distance estimates from an @xmath37-net @xmath144 to the full set @xmath0 .",
    "this is possible by a continuity property of the soft hamming distance , which we outlined in lemma  [ lem : continuity ] .",
    "this result requires the perturbation to be bounded in @xmath311 norm .",
    "however , in our situation the perturbations are going to be bounded only in @xmath312 norm due to lemma  [ lem : tails ] .",
    "so we shall prove the following relaxed version of continuity :    [ lem : continuity l1 ] let @xmath265 , and assume that @xmath313 , @xmath314 for some @xmath268 .",
    "then for every @xmath260 and @xmath315 one has @xmath316    consider the events @xmath270 from the definition of the soft hamming distance . by the assumptions , we have @xmath317 therefore , the set @xmath224:\\ ; |\\ < a_i , x'\\ >",
    "| \\le m\\e , \\ ; |\\ < a_i ,",
    "y'\\ > | \\le m\\e \\big\\ } \\quad \\text{satisfies } \\quad |t^c| \\le 2m / m.\\ ] ] by the triangle inequality , we have @xmath318 therefore @xmath319 this proves the first inequality in .",
    "the proof of the second inequality is similar .",
    "now we are ready to combine all the pieces and prove theorem  [ thm : tessellations soft ] .",
    "to this end , consider the set @xmath0 , numbers @xmath27 , @xmath11 , @xmath263 , and the random matrix @xmath59 as in the theorem .",
    "choose @xmath320 and @xmath321 .",
    "consider an @xmath37-net @xmath144 of @xmath0 as we described in the beginning of section  [ sec : over net ] .",
    "let us apply lemma  [ lem : concentration net ] that controls the distances on @xmath144 along with lemma  [ lem : tails ] that controls the tails . by the assumption on @xmath11 in the theorem and by our choice of @xmath37 , both requirements on @xmath11 in these lemmas hold . by a union bound , with probability at least @xmath322",
    "the following event holds : for every @xmath323 and @xmath324 , one has @xmath325",
    "let @xmath2 . as we described in",
    ", we can decompose the vectors as @xmath326 the bounds in guarantee that the continuity property in lemma  [ lem : continuity l1 ] holds .",
    "this gives @xmath327 furthermore , using we have @xmath328 it follows that @xmath329 finally , by the choice of @xmath37 and @xmath330 we obtain @xmath331    a similar argument shows that @xmath332 we conclude that @xmath333 this completes the proof of theorem  [ thm : tessellations soft ] .",
    "in this section we deduce theorem  [ thm : tessellations rn ] from theorem  [ thm : tessellations ] by an elementary lifting argument into @xmath334 .",
    "we shall use the following notation : given a vector @xmath56 and a number @xmath260 , the vector @xmath335 is the concatenation of @xmath56 and @xmath263 .",
    "furthermore , @xmath336 denotes the set of all vectors @xmath337 where @xmath7 .",
    "fix a large number @xmath341 whose value will be chosen later and consider the set @xmath342 where @xmath343 denotes the spherical projection map @xmath344 .",
    "we have @xmath345 where the last inequality holds because @xmath346 by .",
    "arbitrary vectors @xmath3 and @xmath4 in @xmath0 and the corresponding vectors @xmath350 and @xmath351 in @xmath135 .",
    "let us relate the distances between @xmath294 and @xmath352 appearing in to corresponding distances between @xmath3 and @xmath4 .",
    "let @xmath353 denote normals of the hyperplanes . clearly ,",
    "@xmath294 and @xmath352 are separated by the @xmath167-th hyperplane if and only if @xmath337 and @xmath354 are .",
    "this in turn happens if and only if @xmath3 and @xmath4 are separated by the affine hyperplane that consists of all @xmath56 satisfying @xmath355 .",
    "in other words , the hyperplane tessellation of @xmath135 induces an _ affine _ hyperplane tessellation of @xmath0 , and the fraction @xmath356 of the hyperplanes separating @xmath294 and @xmath352 equals the fraction of the affine hyperplanes separating @xmath3 and @xmath4 . with a slight abuse of notation ,",
    "we express this observation as @xmath357    next we analyze the normalized geodesic distance @xmath358 , which satisfies @xmath359 denoting @xmath360 and @xmath361 and using the triangle inequality , we obtain @xmath362 note that yields that @xmath363 .",
    "it follows that @xmath364 and the same bound holds for the other two similar terms in . using this and",
    "we conclude that @xmath365 . putting this into and using the triangle inequality twice ,",
    "we obtain @xmath366    finally , we use this bound and in , which gets us @xmath367 now we can assign the values @xmath368 and @xmath369 so the right hand side of is bounded by @xmath27 , as required . note that the condition @xmath347 that we used above in order to apply theorem  [ thm : tessellations ] is satisfied by .",
    "this completes the proof of theorem  [ thm : tessellations rn ] .",
    "a. e. litvak , v. d. milman , a. pajor , n. tomczak - jaegermann , _ on the euclidean metric entropy of convex bodies _ , geometric aspects of functional analysis , 221235 , lecture notes in math .",
    ", 1910 , springer , berlin , 2007 .",
    "s. mendelson , _ a few notes on statistical learning theory_. in : advanced lectures in machine learning .",
    "edited by s.  mendelson and a.  j.  smola .",
    "lecture notes in computer science 2600 , 140 .",
    "springer , 2003 ."
  ],
  "abstract_text": [
    "<S> given a subset @xmath0 of the unit euclidean sphere , we estimate the minimal number @xmath1 of hyperplanes that generate a uniform tessellation of @xmath0 , in the sense that the fraction of the hyperplanes separating any pair @xmath2 is nearly proportional to the euclidean distance between @xmath3 and @xmath4 . </S>",
    "<S> random hyperplanes prove to be almost ideal for this problem ; they achieve the almost optimal bound @xmath5 where @xmath6 is the gaussian mean width of @xmath0 . using the map that sends @xmath7 to the sign vector with respect to the hyperplanes , we conclude that every bounded subset @xmath0 of @xmath8 embeds into the hamming cube @xmath9 with a small distortion in the gromov - haussdorff metric . since for many sets @xmath0 </S>",
    "<S> one has @xmath10 , this yields a new discrete mechanism of dimension reduction for sets in euclidean spaces .    _ </S>",
    "<S> keywords : _ embedding ; dimension reduction ; hyperplane tessellations ; mean width ; near isometry </S>"
  ]
}