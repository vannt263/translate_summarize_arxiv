{
  "article_text": [
    "the problem of rapid detection of abrupt changes in a state of a process or a system arises in a variety of applications from engineering problems ( e.g. , navigation integrity monitoring @xcite ) , military applications ( e.g. , target detection and tracking in heavy clutter @xcite ) to cyber security ( e.g. , quick detection of attacks in computer networks @xcite ) . in the present paper",
    ", we are interested in a sequential setting assuming that as long as the behavior of the observation process is consistent with a `` normal '' ( initial in - control ) state , we allow the process to continue . if the state changes , then we need to detect this event as rapidly as possible while controlling for the risk of false alarms . in other words",
    ", we are interested in designing the quickest change - point detection procedure that optimizes the tradeoff between a measure of detection delay and a measure of the frequency of false alarms .",
    "there are four conventional approaches to the optimum tradeoff problem : bayesian , generalized bayesian , multicyclic detection of changes in a stationary regime , and minimax ( see ( * ? ? ?",
    "* ch 6 ) ) . in the bayesian context , proposed by  @xcite and @xcite , the change point",
    "is assumed to be random with a geometric prior distribution , and the optimality criterion is to minimize the weighted bayes - type expected detection delay subject to an upper bound on the weighted probability of a false alarm . until the 1990s , most of the work related to the optimality issue in change detection had been done in the iid case , assuming that observations are independent and identically distributed ( iid ) with one law before the change and with another distribution after the change . in particular , in the 1960s , @xcite found an optimal bayes solution showing that a detection procedure based on thresholding the posterior probability of the change up to the current moment is strictly optimal for any value of the weighted false alarm probability .",
    "much later , in 20042006 , a general bayesian asymptotic theory of change - point detection ( for very general non - iid models and arbitrary prior distributions of the change point ) was developed by  @xcite in discrete time and  @xcite in continuous time .    by contrast , in a minimax formulation , proposed by  @xcite and @xcite , the change point is assumed to be an unknown non - random number and the goal is to minimize the worst - case delay ( with respect to the point of change ) subject to a lower bound on the mean time until false alarm .",
    "specifically , in 1971 , @xcite suggested the worst - worst - case average delay to detection measure @xmath0 that should be minimized in the class of procedures @xmath1 for which the average run length ( mean time ) to false alarm @xmath2 is not smaller than a given number @xmath3 . here",
    "@xmath4 is a generic change detection procedure ( stopping time ) , @xmath5 stands for the operator of expectation when the change point is @xmath6 ( @xmath7 corresponds to a no - change scenario ) and @xmath8 is the sigma - algebra generated by the first @xmath6 observations @xmath9 .",
    "@xcite developed an asymptotic minimax theory of change detection ( in the iid case ) as @xmath10 , proving in particular that page s cusum procedure @xcite is asymptotically first - order minimax . later in 1986 , @xcite established strict optimality of cusum for any value of the average run length to false alarm @xmath11 . in the 1980s",
    ", @xcite introduced a less pessimistic worst - case detection delay measure  maximal conditional average delay to detection , @xmath12 and found an almost optimal procedure that minimizes @xmath13 subject to the constraint on the average run length to false alarm ( i.e. , in the class @xmath14 ) as @xmath15 becomes large .",
    "pollak s idea was to modify the shiryaev ",
    "roberts statistic by randomization of the initial condition in order to make it an equalizer .",
    "pollak proved that the randomized shiryaev ",
    "roberts procedure that starts from a random point sampled from the quasi - stationary distribution of the shiryaev ",
    "roberts statistic is asymptotically nearly minimax within an additive vanishing term . since the shiryaev ",
    "roberts  pollak procedure is an equalizer , it is tempting to conjecture that it may be strictly optimal for any value of @xmath15 , which is not true , as the articles of @xcite and @xcite indicate .",
    "as we already mentioned above , in the early stages the theoretical development was focused primarily on the iid case . however , in practice the observations may be non - identically distributed and dependent .",
    "a general asymptotic minimax theory of change - point detection for non - iid models was developed by @xcite ( see also @xcite for hidden markov models with a finite state - space ) .",
    "in particular , for a low false alarm rate ( large @xmath15 ) the asymptotic minimaxity of the cusum procedure was established in @xcite .    in the iid case , the suitably standardized distributions of the stopping times of the cusum and shiryaev  roberts detection procedures are asymptotically exponential for large thresholds and fit well into the geometric distribution even for a moderate false alarm rate ( see @xcite ) . in this case",
    ", the average run length to false alarm is an appropriate measure of false alarms .",
    "however , for non - iid models the limiting distribution is not guaranteed to be exponential or even close to it . in general , we can not even guarantee that large values of the average run length to false alarm will produce small values of the maximal local false alarm probability .",
    "therefore , the average run length to false alarm is not appropriate in general , and instead it is more adequate to use the local conditional false alarm probability , as suggested in  @xcite .",
    "this issue is extremely important for non - iid models , as a discussion in @xcite shows .    in the present paper ,",
    "we pursue two objectives .",
    "first , in section  [ sec : pf ] , we introduce two novel classes of change - point detection procedures , which , instead of imposing a lower bound on the average run length to false alarm , require more adequate upper bounds on the uniform probability of false alarm or uniform conditional probability of false alarm in the spirit of works by @xcite , @xcite and @xcite .",
    "however , these classes slightly differ from those proposed in @xcite .",
    "this modification allows us to substantially relax lai s essential supremum conditions @xcite , which do not hold for certain interesting practical models .",
    "in fact , our conditions are equivalent to the uniform version of the complete convergence for the log - likelihood ratio processes , i.e. , they are related to the rate of convergence in the strong law of large numbers for the log - likelihood ratio between the `` change '' and `` no - change '' hypotheses .",
    "we concentrate on a minimax problem of minimizing pollak s maximal conditional average delay to detection defined in as well as on a pointwise problem of minimizing the conditional average delay to detection @xmath16 for every change point @xmath17 .",
    "for the sake of completeness , we also consider the other popular risks @xmath18 and @xmath19 , @xmath17 , while we strongly believe that the conditional versions @xmath16 and are more appropriate for most applications .",
    "we consider extremely general non - iid stochastic models for the observations , and it is our goal to find reasonable sufficient conditions for the observation models under which the shiryaev ",
    "roberts ( or cusum ) procedure is asymptotically optimal . to achieve the first goal we exploit the asymptotic bayesian theory of change - point detection developed by @xcite that offers a constructive and flexible approach for studying asymptotic efficiency of bayesian type procedures .",
    "it turns out that a similar method can be used for the analysis of minimax risks and that the complete convergence type conditions for the log - likelihood ratio processes proposed in  @xcite are also sufficient in the minimax setting .",
    "these sufficient conditions as well as the main results related to asymptotic optimality of the shiryaev  roberts procedure in the classes of procedures with upper bounds on the weighted false alarm probability and local false alarm probabilities are given , correspondingly , in section  [ sec : bay ] and section  [ sec : mare ] .",
    "the second objective is to find a method for verification of the required sufficient conditions in a number of particular , still very general , challenging models .",
    "the natural question is how one may check the proposed sufficient conditions and even whether there are more or less general models , except of course the iid case , for which these conditions hold . to this end , we focus on the class of data models for which one can exploit the method of geometric ergodicity for homogeneous markov processes , first proposed by @xcite and then further developed by @xcite for statistical applications .",
    "these results are presented in section  [ sec : mrk ] and show that our sufficient conditions for pointwise and minimax optimality hold for homogeneous markov ergodic processes . in section  [ sec : ex ] , these conditions are further illustrated for several examples that include autoregressive , autoregressive garch , and other models widely used in many applications , in particular for modeling of dynamics of financial indices ; see , e.g. , @xcite . all auxiliary results needed for the proofs",
    "are presented in appendix  [ a ] , and in appendix  [ b ] we give certain useful results from the geometric ergodic theory of markov processes .",
    "assume that we are able to observe a series of consecutive random variables @xmath20 , which may change statistical properties at an unknown point in time @xmath21 .",
    "we use the convention that @xmath22 is the _ last pre - change _ observation .",
    "write @xmath23 for the concatenation of the first @xmath24 observations .",
    "let @xmath25 be the joint probability density of the vector @xmath26 when the change point @xmath6 is fixed and finite and let @xmath27 stand for the pre - change joint density ( when the change never occurs ) .",
    "let @xmath28 and @xmath29 be two sequences of conditional densities of @xmath30 given @xmath31 ( @xmath32 ) , @xmath33 ) with respect to some non - degenerate sigma - finite measure @xmath34 .",
    "we are interested in the general non - iid case that @xmath35 in other words , @xmath28 and @xmath29 are the pre - change and post - change conditional densities , respectively , so that if the change occurs at time @xmath36 , then the conditional density of the @xmath37-th observation changes from @xmath38 to @xmath39 .",
    "note that the post - change densities may depend on the change point  @xmath6 , i.e. , @xmath40 for @xmath41 .",
    "we omit the superscript @xmath6 for brevity .",
    "let @xmath42 and  @xmath43 denote the probability and expectation when @xmath44 , and let @xmath45 and  @xmath46 denote the same when there is no change , i.e. , @xmath7 . obviously , the general non - iid model given by implies that under the measure  @xmath45 the conditional density of  @xmath30 given @xmath31 is @xmath47 for all @xmath48 and under  @xmath49 , for any @xmath50 , the conditional density of  @xmath30 is @xmath47 if @xmath51 and is @xmath52 if @xmath53 .    in the particular iid case ,",
    "the observed random variables @xmath54 are iid until a change with a common density @xmath55 and after the change occurs , the observations are again iid , but with another density @xmath56 .",
    "therefore , in this case , the conditional densities @xmath57 and @xmath58 in are replaced by @xmath59 and @xmath60 , respectively .",
    "a sequential detection procedure is a stopping ( markov ) time @xmath4 for an observed sequence @xmath61 , i.e. , @xmath4 is an extended integer - valued random variable , such that the event @xmath62 belongs to the sigma - algebra @xmath63 .",
    "we denote by @xmath64 the set of all stopping times .",
    "a false alarm is raised whenever the detection is declared before the change occurs , i.e. , when @xmath65 .",
    "( recall that @xmath66 is the first post - change observation . )",
    "the goal of the quickest change - point detection problem is to develop a detection procedure that guarantees a stochastically small delay to detection @xmath67 provided that there is no false alarm ( i.e. , @xmath68 ) under a given ( typically low ) risk of false alarms .",
    "let @xmath69 denote a restriction of the probability measure @xmath42 to the sigma - algebra @xmath70 .",
    "then the likelihood ratio between the hypotheses `` @xmath71 '' that the change happens at @xmath72 and `` @xmath73 '' that there is never a change ( i.e. , the radon  nikodm density @xmath74 ) can be represented in the following exponential form @xmath75 where for @xmath76 @xmath77 the process @xmath78 is the log - likelihood ratio ( llr ) process between the hypotheses @xmath79 ( @xmath80 ) and @xmath81 .    in this paper",
    ", we study the shiryaev  roberts ( sr ) procedure given by the following stopping time @xmath82 where @xmath83 is some fixed positive threshold which will be specified later .",
    "we set @xmath84 . in the iid case ,",
    "this procedure has certain interesting strict optimality properties ( see @xcite and @xcite ) .",
    "another popular change detection procedure is the cusum procedure given by the stopping time @xmath85 it may be shown that this procedure has essentially the same asymptotic performance as the sr procedure .",
    "in fact , using essentially the same line of argument , it can be proved that both procedures are first - order asymptotically optimal under the same general conditions .",
    "for this reason , we consider only the sr procedure .",
    "our main goal is to show that the sr detection procedure @xmath86 is nearly optimal in two pointwise and minimax problems described below .",
    "we will also show that this procedure is asymptotically pointwise and minimax optimal in a class of bayes - type procedures ( see section  [ sec : bay ] ) .    to describe these problems we introduce for any @xmath87 , @xmath88 and @xmath89 the following classes of change detection procedures @xmath90 and @xmath91 note that the probability @xmath92 is the probability of false alarm in the time interval @xmath93 $ ] of the length @xmath94 , which we refer to as the _ local probability of false alarm _ ( lpfa ) , and the probability @xmath95 is the corresponding _ local conditional probability of false alarm _ ( lcpfa ) .",
    "we consider two risks : _ positive part detection delay risk _ @xmath96 and _ conditional detection delay risk _ @xmath97 ( compare with ) and the following problems : the pointwise minimization , i.e. , for any @xmath17 @xmath98 and the minimax optimization @xmath99 the parameters @xmath100 and @xmath101 will be specified later .",
    "in addition , we consider a bayesian - type problem of minimizing the risks and in a class of procedures with the given weighted probability of false alarm . this problem is formulated and solved in the next section .",
    "it would be more natural to address the classes of detection procedures with the given lpfa and lcpfa defined as @xmath102 and the maximal risks @xmath103 i.e. , the optimality criteria @xmath104 as in @xcite , @xcite and @xcite .",
    "however , in this case , one requires much stronger essential supremum conditions on the tail probabilities of the log - likelihood ratio , which do not hold in certain interesting examples ( see remark  [ rem : lai ] below for details ) . for this reason",
    ", we modified these more natural optimality criteria . in the following ,",
    "we suppose that @xmath105 , @xmath106 and @xmath107 go to infinity as @xmath108 , so that for practical purposes the optimality criteria , considered in the present paper , are not too much different from the criteria . at the same time , this allows us to substantially relax the sufficient conditions for asymptotic optimality of the detection procedures .",
    "we need the following definition .",
    "[ rcomplete ] for @xmath109 and @xmath110 , we say that the normalized llr process @xmath111 converges _",
    "@xmath112completely _ to a constant @xmath113 under the probability measure @xmath42 as @xmath114 if @xmath115 if @xmath116 we say that @xmath111 converges to a constant @xmath113 _",
    "uniformly @xmath112completely _ as @xmath117 .",
    "the @xmath112complete convergence is an extension ( for @xmath118 ) of the complete convergence introduced by @xcite .",
    "it was introduced and extensively used for various hypothesis testing and change detection problems by @xcite .    in the following",
    ", we mostly deal with the case that @xmath119 . in this case",
    ", we refer to as @xmath42-complete convergence and to as _ uniform complete convergence_.    note that , for any @xmath120 , @xmath112complete convergence implies almost sure convergence of @xmath111 to @xmath113 under @xmath42 .",
    "hence it can be interpreted as a rate of convergence in the strong law of large numbers .",
    "see ( * ? ? ?",
    "* ch 2 ) for further details .",
    "we begin with considering a bayesian - type class of change detection procedures that upper - bounds a weighted probability of false alarm @xmath121 , assuming that the change point @xmath6 is a random variable independent of the observations with prior distribution @xmath122 , @xmath123 .",
    "however , instead of considering a bayes risk ( weighted average delay to detection ) @xmath124 as it was done by @xcite , we are interested in risks and , i.e. , in the optimization problems @xmath125 and @xmath126 where @xmath127 is a prespecified ( small ) number .    in what follows , for simplicity of the presentation ,",
    "assume that the prior probability distribution @xmath122 of the change point @xmath6 is geometric with the parameter @xmath128 , i.e. , @xmath129 using this distribution we introduce the probability measure on the borel @xmath130-algebra in @xmath131 as @xmath132 now , for some fixed @xmath133 , we define the following _ bayesian class _ of change - point detection procedures with the weighted pfa @xmath134 not greater that the given number @xmath135 : @xmath136 where we took into account that @xmath137 .",
    "it follows from @xcite that in the bayesian setting , when one wants to minimize the weighted average delay to detection , the asymptotically ( as @xmath138 ) optimal detection procedure in the class is the shiryaev detection procedure that raises an alarm at the first time such that the posterior probability @xmath139 exceeds threshold @xmath140 , i.e. , @xmath141 note that it is easy to show @xcite that @xmath142 for any @xmath143 .    using the llr process @xmath144 defined in",
    ", the posterior probability @xmath145 can be represented as @xmath146 $ ] , where @xmath147 therefore , the shiryaev procedure can be also written as @xmath148    note first that , as @xmath149 , the statistic @xmath150 converges to the sr statistic , @xmath151 { } \\sum_{k=1}^n e^{z_n^{k-1 } } \\ , .\\ ] ] thus , if we are interested in small values of @xmath152 , as it is the case in the following , then the behavior of the shiryaev procedure is similar to that of the sr procedure @xmath86 so long as we can define the threshold @xmath153 is such a way that @xmath154 .",
    "hence , instead of considering the procedure @xmath155 , which is shown in @xcite to be asymptotically optimal in the bayesian context with respect to the weighted average delay to detection , we will focus on the sr procedure .",
    "we do not assume any particular model or even class of models for the observations , and as a result , there is no  structure \" of the llr process .",
    "we therefore have to impose some conditions on the behavior of the llr process at least for large @xmath24 .",
    "it is natural to assume that there exists a positive finite number @xmath113 such that @xmath156 converges almost surely to @xmath113 under @xmath42 , i.e. ,    @xmath157 ) _ assume that there exists a number @xmath158 such that for any @xmath159 _",
    "@xmath160{{{\\mathsf{p}}}_{{\\mathchoice{k}{k}{\\lower.25ex\\hbox{$\\scriptstylek$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylek$}}}}-\\text{a.s . } } i \\,.\\ ] ] this is always true for iid data models with @xmath161 } f_1(x ) \\d\\mu(x)\\ ] ] being the kullback ",
    "leibler information number .",
    "it turns out that the a.s.convergence condition is sufficient for obtaining lower bounds for all positive moments of the detection delay .",
    "the following theorem establishes asymptotic lower bounds for the optimization problems and .",
    "we write @xmath162 for the class @xmath163 when the parameter @xmath164 depends on @xmath135 .",
    "[ th.sec:bay.1 ] assume that the almost sure convergence condition @xmath165 holds and in the parameter of the geometric prior distribution @xmath166 as @xmath138 . then , for any @xmath167 , @xmath168 and @xmath169    first , note that it is not difficult to prove that condition @xmath157 ) implies that for any @xmath170 and @xmath159 @xmath171{}0\\,.\\ ] ] next , it is clear that , for any @xmath159 , @xmath172 , i.e. , the assertion follows from the assertion , and hence it suffices to prove only inequality .",
    "define @xmath173 and @xmath174 , where @xmath175 .",
    "let us show that for any @xmath176 and @xmath177 @xmath178 indeed , using the change of measure trick , similarly to @xcite we obtain @xmath179    the definition of the class @xmath180 in implies that for any @xmath143 and for any @xmath181 @xmath182 i.e. @xmath183    therefore , the first term in the right side of the inequality may be estimated as @xmath184 and it goes to zero for any fixed @xmath50 . by , the second term in , @xmath185 approaches zero as @xmath186 for all @xmath176 , and we obtain . by the chebyshev inequality ,",
    "@xmath187 from we obtain immediately that for any fixed @xmath159 @xmath188 therefore , for any @xmath17 and for any small @xmath189 @xmath190 taking into account that @xmath191 as @xmath186 and letting @xmath192 , we obtain the lower bounds .",
    "hence theorem  [ th.sec:bay.1 ] .",
    "observe that the lower bounds and can be generalized for all positive moments of the detection delay @xmath193 $ ] and @xmath194^r$ ] , @xmath195 . indeed , using jensen s inequality @xmath194^r { \\geqslant}\\left[{{\\mathsf{e}}}_{{\\mathchoice{\\nu}{\\nu}{\\lower.25ex\\hbox{$\\scriptstyle\\nu$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\nu$}}}}(\\tau-\\nu)^+ \\right]^r$ ] , we immediately obtain that under the conditions of theorem  [ th.sec:bay.1 ] , for any @xmath167 , @xmath196^r\\ , { \\geqslant}\\frac{1}{i^r}\\ ] ] and analogously @xmath197\\ , { \\geqslant}\\frac{1}{i^r } \\ , .\\ ] ] since higher moments of the detection delay may also be of interest , the asymptotic lower bounds and can be useful for establishing asymptotic optimality properties of the sr procedure with respect to the risks @xmath193 $ ] and @xmath194^r$ ] for @xmath195 uniformly for all @xmath17 , as well as with respect to the maximal risks .      in order to study asymptotics for the average detection delay of the sr procedure and for establishing its asymptotic optimality , we impose the following constraint on the rate of convergence for @xmath198    @xmath199 ) _ assume that @xmath200 converges uniformly completely to @xmath201 as @xmath114 , i.e. , for any @xmath170 _",
    "@xmath202    write @xmath203 for the sr statistic and denote as @xmath204 the sr procedure when the threshold @xmath205 is selected as @xmath206 , i.e. , @xmath207    [ lem : pfasr ] the sr procedure @xmath208 given by belongs to the class @xmath180 for any @xmath209 .    note that the stopping time can be written as @xmath210}\\,e^{z^{k-1}_{{\\mathchoice{n}{n}{\\lower.25ex\\hbox{$\\scriptstylen$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylen$}}}}}\\,{\\geqslant}h(\\alpha,\\varrho)\\right\\}\\ ] ] ( see ) . obviously , @xmath211 almost surely for any @xmath212 .",
    "since by ( 2.11 ) in @xcite @xmath213 , it follows that , for any @xmath143 , @xmath214 and the proof is complete .    in what follows ,",
    "we assume that the parameter @xmath152 is a function of @xmath135 , i.e. @xmath215 , such that @xmath216    moreover , let @xmath100 be a function of @xmath135 , i.e. @xmath217 , such that @xmath218    denote as @xmath219 the sr procedure defined in when the threshold @xmath220 is selected as @xmath221 .",
    "note that if conditions hold , then @xmath222 as @xmath186 .",
    "clearly , we need the threshold to become large for small @xmath135 ; otherwise the problem is degenerate . by lemma  [ lem : pfasr ] , this choice of the threshold guarantees that @xmath223 for every @xmath224 .",
    "the following theorem identifies the asymptotic upper bounds for the risks of the sr procedure .",
    "[ th.sec:bay.2 ] * ( i ) * assume that the uniform complete convergence condition @xmath225 holds for some @xmath226 , and the parameter @xmath227 in the sr procedure satisfies conditions . then @xmath228    * ( ii ) * assume that in addition to conditions @xmath225 and , conditions hold for @xmath229",
    ". then @xmath230    proof of ( i ) .",
    "taking into account that @xmath231 , we obtain @xmath232 evidently , for any @xmath233 and any @xmath234 , the last probability can be bounded as @xmath235 and hence , for any @xmath233 , @xmath236 hereafter @xmath237 denotes the integer number less than or equal to @xmath238 .",
    "since the right - hand side does not depend on @xmath6 , we have ( for any @xmath167 and @xmath239 ) @xmath240 by condition @xmath199 ) , @xmath241 , so using condition and the fact that @xmath189 is arbitrary yields the upper bound and the assertion ( i ) follows .",
    "proof of ( ii ) . in view of inequality , for any @xmath242",
    ", @xmath243 evidently , under conditions and the right - hand side approaches @xmath244 as @xmath245 , which implies that @xmath246 as @xmath186 for all @xmath247 .",
    "since @xmath248 , inequality implies for @xmath229 satisfying conditions and the proof is complete .",
    "finally , combining theorem  [ th.sec:bay.1 ] and theorem  [ th.sec:bay.2 ] , we conclude that the sr procedure is first - order asymptotically uniformly pointwise optimal and minimax in the class @xmath162 , which is formalized in the next theorem .",
    "[ th.sec:bay.3 ] * ( i ) * assume that the uniform complete convergence condition @xmath225 holds for some @xmath226 , and the parameter @xmath227 in the sr procedure satisfies conditions . then @xmath249 and @xmath250 moreover , as @xmath186 , @xmath251 and @xmath252    * ( ii ) * assume that in addition to conditions @xmath225 and conditions hold for @xmath229 .",
    "then @xmath253 and @xmath254 moreover , as @xmath186 , @xmath255 and @xmath256    all assertions follow from theorem  [ th.sec:bay.1 ] and theorem  [ th.sec:bay.2 ] in an obvious manner .",
    "the above asymptotic optimality results can be generalized for higher moments of the detection delay if the uniform complete convergence condition @xmath199 ) is strengthened into the uniform @xmath112complete convergence condition for some @xmath195 .",
    "in particular , the following result holds true .",
    "[ th.sec:bay.rcomp ] let conditions and hold and , for some @xmath195 and all @xmath170 , @xmath257 then the sr procedure @xmath258 is first - order asymptotically uniformly pointwise optimal and minimax in the class @xmath259 with respect to the moments of the detection delay up to order @xmath260 : for all @xmath261 as @xmath186 @xmath262 & ~ \\sim~   \\inf_{{\\mathchoice{\\tau\\in \\delta(\\alpha)}{\\tau\\in \\delta(\\alpha)}{\\lower.25ex\\hbox{$\\scriptstyle\\tau\\in \\delta(\\alpha)$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\tau\\in \\delta(\\alpha)$}}}}\\ , { { \\mathsf{e}}}_{{\\mathchoice{\\nu}{\\nu}{\\lower.25ex\\hbox{$\\scriptstyle\\nu$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\nu$}}}}\\left[(\\tau-\\nu)^\\ell | \\tau>\\nu \\right ] \\\\ & \\sim~ { \\left(\\frac{|\\log \\alpha|}{i}\\right)}^\\ell \\quad \\text{for all fixed}~ \\nu { \\geqslant}0 \\end{aligned}\\ ] ] and @xmath263 ~ \\sim~",
    "\\inf_{{\\mathchoice{\\tau\\in \\delta(\\alpha)}{\\tau\\in \\delta(\\alpha)}{\\lower.25ex\\hbox{$\\scriptstyle\\tau\\in \\delta(\\alpha)$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\tau\\in \\delta(\\alpha)$}}}}\\ ,    \\sup_{{\\mathchoice{0 { \\leqslant}\\nu { \\leqslant}k^{*}_\\alpha}{0 { \\leqslant}\\nu { \\leqslant}k^{*}_\\alpha}{\\lower.25ex\\hbox{$\\scriptstyle0 { \\leqslant}\\nu { \\leqslant}k^{*}_\\alpha$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle0 { \\leqslant}\\nu { \\leqslant}k^{*}_\\alpha$}}}}\\ ,   { { \\mathsf{e}}}_{{\\mathchoice{\\nu}{\\nu}{\\lower.25ex\\hbox{$\\scriptstyle\\nu$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\nu$}}}}\\left[(\\tau-\\nu)^\\ell | \\tau>\\nu \\right]~ \\sim~ { \\left(\\frac{|\\log \\alpha|}{i}\\right)}^\\ell\\,.\\ ] ]    we give only a sketch of the proof and omit certain details . by , for all @xmath264 and for all @xmath17 , @xmath265\\ , { \\geqslant}\\frac{1}{i^r } \\ , .\\ ] ] ( this bound holds since condition obviously implies the a.s .  convergence ( @xmath266 ) , which in turn implies for all @xmath159 . )    next , using the reasoning similar to that used in the proof of proposition  [ prop : a1 ] in the appendix , which has lead to inequality , we obtain @xmath267}^r   { \\leqslant}n_0^{r } + r 2^{r-1 } \\sum_{n = n_0}^{\\infty }   n^{r-1 }    { { \\mathsf{p}}}_\\nu ( t_\\alpha > \\nu+ n ) \\ , , \\ ] ] where @xmath268 and @xmath269 . by , for any @xmath233 and @xmath270 , @xmath271 , and we obtain @xmath272}^r   & { \\leqslant}n_0^{r } + r 2^{r-1 } \\sum_{n = n_0}^{\\infty }   n^{r-1 } { { \\mathsf{p}}}_\\nu{\\left(\\vert { \\widetilde}{z}_{\\nu , n}\\vert > \\varepsilon\\right ) }   \\\\ & { \\leqslant}{\\left(1 + \\frac{\\log h_\\alpha}{i-\\varepsilon}\\right)}^r +   r 2^{r-1 } \\sum_{n=1}^{\\infty }   n^{r-1 } \\sup_{\\nu{\\geqslant}0 } { { \\mathsf{p}}}_\\nu{\\left(\\vert { \\widetilde}{z}_{\\nu , n}\\vert > \\varepsilon\\right ) } \\ , , \\end{aligned}\\ ] ] where the last term is finite due to condition and @xmath273 as @xmath186 due to condition . thus , for an arbitrary @xmath233 , @xmath274}^r   { \\leqslant}{\\left(\\frac{|\\log \\alpha|}{i-\\varepsilon}\\right)}^r(1+o(1 ) ) \\quad \\text{as}~ \\alpha\\to0,\\ ] ] and we established the asymptotic upper bound @xmath275\\ , { \\leqslant}\\frac{1}{i^r } \\quad \\text{for all}~\\nu{\\geqslant}0.\\ ] ] applying this upper bound together with the lower bound proves asymptotic relations .    the upper bound @xmath276\\ , { \\leqslant}\\frac{1}{i^r}\\ ] ] can be established similarly to , using and the fact that @xmath277 as @xmath186 ( see the proof of theorem  [ th.sec:bay.2](ii ) ) and that @xmath278^r/{{\\mathsf{p}}}_{\\nu}(t_\\alpha > \\nu ) \\ , .\\ ] ] this upper bound and the lower bound imply .    while for the sake of simplicity we consider the geometric prior distribution with the small parameter @xmath279 as @xmath138 , all the asymptotic results hold true for an arbitrary prior distribution @xmath280 such that the mean value of the change point @xmath281 approaches infinity as @xmath138 , assuming that conditions and hold with @xmath282 replaced by @xmath283 .",
    "analogous asymptotic optimality results hold for the shiryaev procedure @xmath284 defined in .",
    "the proofs are essentially similar .",
    "we now proceed with tackling the pointwise and minimax problems and in the classes of procedures with given lpfa and lcpfa .",
    "the method of establishing asymptotic optimality of the sr procedure is again based on the lower - upper bounding technique .",
    "specifically , we first obtain asymptotic lower bounds for the risk @xmath285 in the class @xmath286 and for the risk @xmath287 in the class @xmath288 , and then we show that these asymptotic lower bounds are attained for the sr procedure @xmath86 with a certain threshold @xmath289 .",
    "note that the asymptotic optimality results of the previous section are essential , since asymptotic optimality in classes @xmath286 and @xmath288 is obtained by imbedding these classes in the class @xmath290 with specially selected parameters @xmath291 and @xmath135 .      for any @xmath87 , @xmath88 and @xmath89 , define @xmath292 and @xmath293 where @xmath294    to find asymptotic lower bounds for the problems and in addition to condition @xmath157 ) we impose the following condition related to the growth of the window size @xmath106 in the lpfa :    @xmath295 _ the size of the window @xmath101 in is a function of @xmath296 , i.e. @xmath297 , such that @xmath298 where @xmath299 .",
    "_    for example , we can take @xmath300 .",
    "the following theorem establishes asymptotic lower bounds .",
    "[ th.sec:cnrsk.1 ] assume that conditions @xmath165 and @xmath295 hold .",
    "then , for any @xmath301 and @xmath17 , @xmath302 and @xmath303    by proposition  [ pr.sec:absrsk.1 ] ( see appendix  [ a ] ) , for all @xmath17 and for sufficient small @xmath304 ( for which the conditions of this proposition hold ) @xmath305 now inequality and condition @xmath306 ) imply immediately .",
    "proposition  [ pr.sec:cnrsk.1 ] ( see appendix  [ a ] ) implies that for all @xmath17 and for a sufficient small @xmath304 ( for which the conditions of this proposition hold ) @xmath307 inequality and condition @xmath306 ) imply immediately .      to establish asymptotic optimality properties of the sr procedure with respect to the risks @xmath285 ( for all @xmath17 ) and @xmath308 in the class @xmath286 we need the uniform complete convergence condition @xmath199 ) as well as the following condition .",
    "@xmath309 _ parameter @xmath100 in is a function of @xmath296 , i.e. @xmath310 , such that @xmath311 where @xmath312 .",
    "_    we can choose , for example , @xmath313    next , denote by @xmath314 the sr procedure @xmath315 defined in with the threshold @xmath316 given by @xmath317    the following theorem establishes first - order asymptotic optimality of the sr procedure @xmath314 with respect to the risks @xmath285 and @xmath308 in the class @xmath286 as @xmath108 , i.e. , @xmath314 is an asymptotic solution of the problems and as the lpfa vanishes .",
    "[ th.sec:absrsk.2 ] if conditions @xmath295 and @xmath309 hold , then , for any @xmath87 , the sr procedure @xmath314 with the threshold @xmath316 given by belongs to the class @xmath286 .",
    "if , in addition , condition @xmath225 is satisfied , then the sr procedure @xmath314 is first - order asymptotically uniformly pointwise optimal and minimax in the class @xmath286 , i.e. , @xmath318 and @xmath319 also , as @xmath108 , the following first - order asymptotic approximations hold for the pointwise and maximal risks : @xmath320 and @xmath321    by lemma  [ lem : pfasr ] , the sr procedure @xmath214 for any @xmath209 .",
    "moreover , note that the definition yields @xmath322 , i.e. , @xmath323 . using proposition  [ pr.sec:absrsk.1 ]",
    ", we obtain that @xmath324 for any @xmath87 . furthermore , condition @xmath325 ) and the definition of @xmath326 in imply directly that @xmath327 .",
    "thus , the asymptotic upper bound ( with @xmath119 ) in proposition  [ prop : a1 ] implies the following upper bound @xmath328 the asymptotic equalities and follow immediately from this upper bound and the lower bounds in theorem  [ th.sec:cnrsk.1 ] .",
    "the asymptotic expansions and are obvious .",
    "now we define @xmath329 where the function @xmath326 is defined in .    to prove asymptotic optimality in the class @xmath330 with respect to the risk @xmath331 we need the following condition .",
    "@xmath332 _ parameters @xmath100 and @xmath101 are functions of @xmath296 , i.e. @xmath310 and @xmath297 , such that @xmath333 where @xmath334 .",
    "_    we can take , for example , the parameters @xmath310 and @xmath297 as in .",
    "denote by @xmath335 the sr procedure @xmath336 defined in with the threshold @xmath337 given by @xmath338    [ th.sec:cnrsk.2 ] if conditions @xmath295 and @xmath332 hold , then , for any @xmath87 , the sr procedure @xmath339 with the threshold @xmath337 given by belongs to the class @xmath288 .",
    "assume that in addition condition @xmath225 is satisfied .",
    "then the sr procedure @xmath335 is first - order asymptotically uniformly poitwise optimal and minimax in the class @xmath330 , i.e. , @xmath340 and @xmath341 also , as @xmath108 , the following first - order asymptotic approximations hold for the pointwise and maximal risks : @xmath342 and @xmath343    by lemma  [ lem : pfasr ] , the sr procedure @xmath214 for any @xmath209 .",
    "now , note that the definition yields @xmath344 , i.e. , @xmath345 . using proposition  [ pr.sec:cnrsk.1 ]",
    ", we obtain that the stopping time @xmath346 belongs to @xmath288 for any @xmath87 .",
    "next , in view of the definition of @xmath347 in and of the form of the function @xmath326 in we obtain , using condition @xmath348 ) , that @xmath349 .",
    "thus , by ( with @xmath119 ) in proposition  [ prop : a1 ] , @xmath350 comparing to the reverse inequality implies .",
    "asymptotic approximations are obvious from and .    using inequality and condition @xmath348 ) , we obtain @xmath351 therefore , @xmath352 note that the maximal risk @xmath353 can be estimated as @xmath354 asymptotic equality with @xmath119 in proposition  [ prop : a1 ] implies that @xmath355 since , as we mentioned above , @xmath356 , we obtain the upper bound @xmath357 asymptotic equalities now follow from the upper bound and the lower bound .",
    "asymptotic approximations are obvious from and .",
    "the proof is complete .",
    "[ rem : lai ] we recall that lai s condition ( 6 ) in @xcite for the asymptotic lower bound @xmath358 in the class @xmath359 is the following : @xmath360 where the parameter @xmath113 is given in condition @xmath157 ) .",
    "clearly , condition is much stronger than the a.s .",
    "convergence condition @xmath157 ) required in theorem  [ th.sec:cnrsk.1 ] , and it does not hold in many important practical cases . also , lai s condition ( 24 ) in @xcite for asymptotic optimality of the cusum procedure in the classes @xmath14 and @xmath361 is : @xmath362 typically this condition is more difficult to check than the uniform complete convergence condition @xmath199 ) required in theorem  [ th.sec:cnrsk.2 ] , which in fact can be relaxed to @xmath363 ( see remark  [ rem : lefttail ] ) .",
    "in addition , for certain models condition does not hold , while condition @xmath199 ) holds ( see , e.g. , an example in subsection  [ ssec : laicn ] below ) . on the other hand , in the iid case condition is less stringent than @xmath199 ) .    as in theorem",
    "[ th.sec:bay.rcomp ] , the results of theorem  [ th.sec:absrsk.2 ] and theorem  [ th.sec:cnrsk.2 ] can be extended to higher moments of the detection delay by strengthening the complete convergence with the uniform @xmath112complete convergence .",
    "more specifically , the following asymptotic optimality result holds true .",
    "[ th.sec:cnrskr.2 ] assume that conditions @xmath295 and @xmath332 hold , and in addition , for some @xmath195 the uniform @xmath260-complete convergence condition is satisfied . then , for any @xmath87 , the sr procedure @xmath339 with the threshold @xmath337 given by belongs to the class @xmath288 and as @xmath108 for any @xmath364 @xmath365 & ~ \\sim~   \\inf_{\\tau\\in { { { \\mathcal{h}}}}^*\\left(\\beta , k^{*},m^{*}\\right)}\\ , { { \\mathsf{e}}}_{\\nu}\\left[(\\tau-\\nu)^\\ell | \\tau>\\nu \\right ]   \\\\    & ~ \\sim~ { \\left(\\frac{|\\log \\beta|}{i}\\right)}^\\ell \\quad \\text{for all}~\\nu{\\geqslant}0   \\end{aligned}\\ ] ] and @xmath366 & ~ \\sim~    \\inf_{\\tau\\in { { { \\mathcal{h}}}}^*\\left(\\beta , k^{*},m^{*}\\right)}\\ , \\max_{0 { \\leqslant}\\nu { \\leqslant}k^{*}_\\beta}\\ ,   { { \\mathsf{e}}}_{\\nu}\\left[(\\tau-\\nu)^\\ell | \\tau>\\nu \\right ] \\\\ & ~ \\sim~ { \\left(\\frac{|\\log \\beta|}{i}\\right)}^\\ell\\ , . \\end{aligned}\\ ] ] therefore , the sr procedure @xmath339 is first - order asymptotically uniformly pointwise optimal and also minimax in the class @xmath330 with respect to the moments of the detection delay up to order @xmath260 .    the facts that @xmath367 for any @xmath87 and that @xmath368 as @xmath108 were established in theorem  [ th.sec:cnrsk.2 ] .",
    "now , using in proposition  [ prop : a1 ] ( along with the equality @xmath369 , @xmath17 ) , we obtain the upper bound @xmath370",
    "{ \\leqslant}{\\left(\\frac{|\\log \\beta|}{i}\\right)}^r(1+o(1 ) ) \\quad \\text{as}~\\beta\\to0.\\ ] ] jensen s inequality and the lower bound yield , for any @xmath120 and @xmath17 , @xmath371 { \\geqslant}\\inf_{{\\mathchoice{\\tau\\in { { { \\mathcal{h}}}}^*\\left(\\beta , k^{*},m^{*}\\right)}{\\tau\\in { { { \\mathcal{h}}}}^*\\left(\\beta , k^{*},m^{*}\\right)}{\\lower.25ex\\hbox{$\\scriptstyle\\tau\\in { { { \\mathcal{h}}}}^*\\left(\\beta , k^{*},m^{*}\\right)$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\tau\\in { { { \\mathcal{h}}}}^*\\left(\\beta , k^{*},m^{*}\\right)$}}}}\\,{{\\mathsf{e}}}_{{\\mathchoice{\\nu}{\\nu}{\\lower.25ex\\hbox{$\\scriptstyle\\nu$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\nu$}}}}\\left[(\\tau-\\nu)^r | \\tau>\\nu \\right ] { \\geqslant}{\\left(\\frac{|\\log \\beta|}{i}\\right)}^r(1+o(1)),\\ ] ] which along with the previous upper bound proves .    to prove it suffices to show that @xmath372}{|\\log\\beta|^r } { \\leqslant}\\frac{1}{i^r } \\ , .\\ ] ] note that @xmath373 { \\leqslant}\\dfrac{\\max_{0{\\leqslant}\\nu { \\leqslant}k^{*}_\\beta}\\ ,   { { \\mathsf{e}}}_{\\nu}\\left[(t^{*}_{\\beta}-\\nu)^+]^r\\right]}{\\min_{0{\\leqslant}\\nu { \\leqslant}k^{*}_\\beta}\\,{{\\mathsf{p}}}_{\\infty}\\left(t^{*}_{{\\mathchoice{\\beta}{\\beta}{\\lower.25ex\\hbox{$\\scriptstyle\\beta$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\beta$ } } } } > \\nu \\right)},\\ ] ] where @xmath374 as a result , using in proposition  [ prop : a1 ] , we obtain @xmath375 & { \\leqslant}\\dfrac{\\sup_{0{\\leqslant}\\nu",
    "< \\infty}\\ ,   { { \\mathsf{e}}}_{\\nu}\\left[(t^{*}_{\\beta}-\\nu)^+]^r\\right]}{{{\\mathsf{p}}}_{\\infty}\\left(t^{*}_{\\beta } > k^*_\\beta \\right ) } \\\\ & = \\dfrac{(\\log h^*_\\beta /i)^r(1+o(1))}{{{\\mathsf{p}}}_{\\infty}\\left(t^{*}_{\\beta } > k^*_\\beta \\right ) } = { \\left(\\frac{|\\log \\beta|}{i}\\right)}^r(1+o(1 ) ) .",
    "\\end{aligned}\\ ] ] this obviously yields the upper bound and the proof is complete .",
    "[ rem : lefttail ] the uniform @xmath112complete convergence condition can be relaxed to the following one - sided version : for some @xmath195 and any @xmath170 @xmath376 in this case , one needs to additionally require the almost sure convergence condition @xmath157 ) , which guarantees condition in lemma  [ prop : a1 ] .",
    "in this section , we obtain certain sufficient conditions for homogeneous markov processes in order to verify condition @xmath225 for this class of processes .",
    "let @xmath377 be a time homogeneous markov process with values in a measurable space @xmath378 with the transition probability @xmath379 defined in . in the sequel ,",
    "we denote by @xmath380 the expectation with respect to this probability .",
    "in addition , we assume that this process is geometrically ergodic , i.e. ,    @xmath381 _ assume that there exist positives constants @xmath382 , @xmath383 , probability measure @xmath384 on @xmath378 and the lyapunov @xmath385 function @xmath386 with @xmath387 , such that @xmath388 _ now , for some @xmath389 , we set @xmath390 let @xmath391 be a measurable @xmath392 function such that the following integrals exist @xmath393    @xmath394 _ assume that the function @xmath391 is such that @xmath395 for all @xmath396 .",
    "_    we study the concentration properties for the process @xmath397 , or equivalently the properties of the deviation @xmath398 . similarly",
    "to , we define for some @xmath389 @xmath399    now we set @xmath400    [ pr.sec:mrk.1 ] assume that conditions @xmath381 and @xmath394 hold . then for any @xmath396 and @xmath401 , for which @xmath402 and @xmath403 , one has @xmath404",
    "note that we can represent the term @xmath405 as @xmath406    where @xmath407 to estimate the powers of the @xmath408 we need to estimate the corresponding coefficient @xmath409 from proposition  [ pr.sec:bi.1 ] ( see appendix  [ b ] ) . to this end , note that for @xmath410 @xmath411 where @xmath412 .",
    "now , by condition @xmath381 , for any @xmath413 and any @xmath414 , @xmath415 , i.e. , for any @xmath416 @xmath417 in particular , we have @xmath418 .",
    "therefore , the coefficients can be estimated as @xmath419 and by proposition  [ pr.sec:bi.1 ] we get @xmath420 , where @xmath421 is defined in .",
    "similarly , to estimate the martingale @xmath422 we make use of proposition  [ pr.sec:bi.1 ] .",
    "note that in this case the coefficient has the form @xmath423 , and it can be estimated for @xmath424 as @xmath425 taking into account jensen s inequality and the definition , we obtain that @xmath426 , and therefore , from proposition  [ pr.sec:bi.1 ] it follows that for @xmath427 , @xmath428 .",
    "therefore , taking into account that @xmath429 we obtain , for any @xmath427 , @xmath430 & { \\leqslant}\\,\\frac{4^{\\r-1}}{n^{\\r/2}}\\ , \\left((1+\\u^{*}_{{\\mathchoice{\\r}{\\r}{\\lower.25ex\\hbox{$\\scriptstyle\\r$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\r$}}}})\\,\\upsilon^{*}_{{\\mathchoice{\\r}{\\r}{\\lower.25ex\\hbox{$\\scriptstyle\\r$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\r$}}}}(x ) + |\\lambda({\\widetilde}{g})|^{\\r}\\,+ ( 8\\r)^{\\r/2}\\,g^{*}_{{\\mathchoice{\\r}{\\r}{\\lower.25ex\\hbox{$\\scriptstyle\\r$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\r$}}}}(x ) \\right)\\\\[2 mm ] & { \\leqslant}\\ , w^{*}_{{\\mathchoice{\\r}{\\r}{\\lower.25ex\\hbox{$\\scriptstyle\\r$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\r$}}}}\\ , \\frac{\\left(1+\\upsilon^{*}_{{\\mathchoice{\\r}{\\r}{\\lower.25ex\\hbox{$\\scriptstyle\\r$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\r$}}}}(x)+g^{*}_{{\\mathchoice{\\r}{\\r}{\\lower.25ex\\hbox{$\\scriptstyle\\r$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\r$}}}}(x)\\right ) } { n^{\\r/2 } } \\ , .",
    "\\end{aligned}\\ ] ] hence proposition  [ pr.sec:mrk.1 ] .",
    "as we will see later in section [ sec : ex ] , condition @xmath381 does not hold directly for some time series .",
    "for this reason , we introduce the following modification of this condition .",
    "@xmath431 _ assume that there is some integer @xmath432 such that for any @xmath433 there exist positive constants @xmath434 , @xmath435 , probability measure @xmath436 on @xmath437 and the lyapunov @xmath385 function @xmath438 with @xmath439 , such that @xmath440 _ similarly to we introduce @xmath441 and impose the following condition .",
    "@xmath442 _ assume that the function @xmath391 defined in is such that @xmath443 for all @xmath396 .",
    "_    now we set @xmath444 , where @xmath445 .",
    "[ pr.sec:mrk.1-1 ] assume that conditions @xmath431 and @xmath442 hold .",
    "then for any @xmath396 and any @xmath401 , for which @xmath446 and @xmath447 , there exists a constant @xmath448 such that @xmath449    note that the term @xmath405 can be represented as @xmath450 , where @xmath451 and @xmath422 is defined in .",
    "let now @xmath452 for some @xmath453 .",
    "thus , @xmath454 where @xmath455 . in just the same way as in the proof of proposition  [ pr.sec:mrk.1 ] , we obtain that for some constant @xmath456 @xmath457 where @xmath458 .",
    "furthermore , @xmath459 using the upper bound in this inequality , we obtain the inequality .",
    "we return to the detection problem for markov processes , assuming that the sequence @xmath377 is a markov process , such that @xmath460 is a homogeneous process with the transition ( from @xmath238 to @xmath461 ) density @xmath462 and @xmath463 is homogeneous positive ergodic with the transition density @xmath464 and the ergodic ( stationary ) distribution @xmath384 .",
    "the densities @xmath462 and @xmath464 are calculated with respect to a sigma - finite positive measure @xmath465 on @xmath466 .    in this case",
    ", we can represent the process @xmath467 defined in as @xmath468 therefore , in this case @xmath469    we now formulate the conditions that are sufficient for the main condition @xmath470 to hold in the case of markov processes .",
    "we write @xmath471 for the expectation with respect to the distribution @xmath472 .",
    "@xmath473    _ assume that there exists a set @xmath474 with @xmath475 such that _    1 .",
    "2 .   there exists @xmath385 lyapunov s function @xmath386 such that @xmath477 and @xmath478 .",
    "3 .   for some @xmath479 and @xmath480 and for all @xmath396 , @xmath481 .    @xmath482 _ assume that there exists @xmath483 such that @xmath484 where @xmath485^{\\r}$ ] and @xmath486^{\\r}$ ] . _    [ th.sec:mrk.1 ] conditions @xmath473 and @xmath482 imply condition @xmath225 with @xmath487 .",
    "note first that in the markov case @xmath488 therefore , using the fact that the process @xmath489 is homogeneous , we obtain @xmath490 where @xmath491 .",
    "note now that in view of condition @xmath473 , for any @xmath492 , @xmath493 where @xmath494 and @xmath495 .",
    "so theorem  [ th.amc.1 ] in appendix  [ b ] implies condition @xmath496 ) , and therefore , proposition  [ pr.sec:mrk.1 ] yields @xmath497 where @xmath498 is defined in .",
    "thus , using condition @xmath499 ) we obtain that @xmath500 this implies immediately that for any positive @xmath501 the sum defined in is bounded as @xmath502 hence theorem  [ th.sec:mrk.1 ] .",
    "now we obtain sufficient conditions for @xmath431 and @xmath442 . to this end , we denote by @xmath503 the conditional density of @xmath504 with respect to @xmath505 .",
    "@xmath506    _ assume that there exist an integer @xmath432 and a set @xmath474 with @xmath475 such that _    1 .",
    "there exists @xmath385 lyapunov s function @xmath386 such that @xmath477 and @xmath478 .",
    "3 .   for some @xmath479 and @xmath480 and for all @xmath396 , @xmath508 .",
    "[ th.sec:mrk.2 ] conditions @xmath506 and @xmath509 imply condition @xmath225 with @xmath487 .    first",
    ", let @xmath510 for some fixed @xmath433 .",
    "condition @xmath506 implies that for any @xmath433 the transition probability of the homogeneous markov process @xmath511 for any @xmath492 @xmath512 where @xmath494 and @xmath495 .",
    "so theorem  [ th.amc.1 ] implies condition @xmath513 ) with the same @xmath514 , @xmath515 , @xmath516 and @xmath517 for @xmath433 .",
    "hence , in this case @xmath518 and , therefore , for any @xmath396 by proposition  [ pr.sec:mrk.1-1 ] and condition @xmath499 ) for the process @xmath519 defined in we obtain that @xmath500 this implies immediately that for any @xmath170 the sum defined in is bounded as @xmath502 hence theorem  [ th.sec:mrk.2 ] .",
    "we now present several examples that illustrate the general theory developed in sections  [ sec : bay ] and [ sec : mare ] .",
    "the main goal is to verify condition @xmath470 in order to be able to apply the theorems proved in sections  [ sec : bay ] and [ sec : mare ] and establish asymptotic pointwise and minimax optimality of the sr detection procedure .",
    "this example motivates the necessity of relaxing conditions and proposed in @xcite in certain interesting problems .",
    "it shows that both conditions and do not hold , while our uniform complete convergence condition @xmath225 holds .    hereafter the prime in the vector @xmath520 denotes the transposition .",
    "consider the two dimensional autoregression ( ar ) process @xmath521 defined as @xmath522 where @xmath523 0\\ , , & \\lambda_{{\\mathchoice{2}{2}{\\lower.25ex\\hbox{$\\scriptstyle2 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle2 $ } } } } \\end{array } \\right ) \\",
    ", , \\quad a_{{\\mathchoice{k}{k}{\\lower.25ex\\hbox{$\\scriptstylek$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylek$ } } } } = \\left ( \\begin{array}{ll }   \\sigma_{{\\mathchoice{1}{1}{\\lower.25ex\\hbox{$\\scriptstyle1 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle1$}}}}\\,\\eta_{{\\mathchoice{1,k}{1,k}{\\lower.25ex\\hbox{$\\scriptstyle1,k$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle1,k$}}}}\\ , , & 0\\\\[2 mm ] 0\\ , , & \\sigma_{{\\mathchoice{2}{2}{\\lower.25ex\\hbox{$\\scriptstyle2 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle2$}}}}\\,\\eta_{{\\mathchoice{2,k}{2,k}{\\lower.25ex\\hbox{$\\scriptstyle2,k$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle2,k$ } } } } \\end{array } \\right ) \\quad\\mbox{and}\\quad \\xi_{{\\mathchoice{k}{k}{\\lower.25ex\\hbox{$\\scriptstylek$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylek$}}}}= \\left ( \\begin{array}{c }   \\xi_{{\\mathchoice{1,k}{1,k}{\\lower.25ex\\hbox{$\\scriptstyle1,k$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle1,k$}}}}\\\\[2 mm ]   \\xi_{{\\mathchoice{2,k}{2,k}{\\lower.25ex\\hbox{$\\scriptstyle2,k$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle2,k$ } } } } \\end{array } \\right)\\,.\\ ] ] here the sequences @xmath524 and @xmath525 are iid @xmath526 random variables independent of the sequence @xmath527 , which is the iid sequence of @xmath528 random vectors with @xmath529 \\rho & , \\ , 1 \\end{array } \\right)\\ ] ] and @xmath530 is some fixed number which will be specified later .",
    "it is clear that the iid random matrices @xmath531 in are such that @xmath532= \\left ( \\begin{array}{clll }   \\sigma^{2}_{{\\mathchoice{1}{1}{\\lower.25ex\\hbox{$\\scriptstyle1 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle1$}}}}\\,,&0\\,,&0\\,,&0\\\\[2 mm ] 0\\,,&0\\,,&0\\,,&0 \\\\[2 mm ] 0\\,,&0\\,,&0\\,,&0 \\\\[2 mm ] 0\\,,&0\\,,&0\\,,&\\sigma^{2}_{{\\mathchoice{2}{2}{\\lower.25ex\\hbox{$\\scriptstyle2 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle2 $ } } } } \\end{array } \\right ) \\,.\\ ] ] as to the coefficients @xmath533 , we choose them so that this matrix has the modules of its eigenvalues less than one , i.e. , @xmath534 under these conditions the process @xmath535 has the stationary distribution in @xmath536 given by @xmath537   \\zeta_{{\\mathchoice{2}{2}{\\lower.25ex\\hbox{$\\scriptstyle2 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle2 $ } } } } \\end{array } \\right ) = \\sum^{\\infty}_{{\\mathchoice{k=1}{k=1}{\\lower.25ex\\hbox{$\\scriptstylek=1 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylek=1$}}}}\\ , \\pi_{{\\mathchoice{k-1}{k-1}{\\lower.25ex\\hbox{$\\scriptstylek-1 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylek-1 $ } } } } \\,\\xi_{{\\mathchoice{k}{k}{\\lower.25ex\\hbox{$\\scriptstylek$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylek$ } } } } \\ , , \\ ] ] where @xmath538 and @xmath539 for @xmath540 .",
    "one can deduce directly that this vector , conditioned on @xmath541 , is gaussian @xmath542 with @xmath543 \\rho \\varsigma_{{\\mathchoice{12}{12}{\\lower.25ex\\hbox{$\\scriptstyle12 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle12$}}}}&,\\ , \\varsigma_{{\\mathchoice{22}{22}{\\lower.25ex\\hbox{$\\scriptstyle22 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle22 $ } } } } \\end{array } \\right ) \\,,\\ ] ] where @xmath544    note now that , conditioned on @xmath545 , the random vector @xmath505 for @xmath546 is gaussian @xmath547 with @xmath548 , where for @xmath549 @xmath550 \\rho & , \\ , 1+\\sigma^{2}_{{\\mathchoice{2}{2}{\\lower.25ex\\hbox{$\\scriptstyle2 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle2$}}}}\\,x^{2}_{{\\mathchoice{2}{2}{\\lower.25ex\\hbox{$\\scriptstyle2 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle2 $ } } } } \\end{array } \\right ) \\,.\\ ] ] so we can represent the llr as @xmath551 where for any @xmath552 @xmath553    therefore , by the ergodic theorem , @xmath554 i.e. , @xmath555 , where the vector @xmath556 is defined in .",
    "clearly , condition in this case has the following form : for any @xmath557 @xmath558 where @xmath555 .",
    "we now establish that it does not hold by showing that for some @xmath177 @xmath559 observe first that for any @xmath427 @xmath560 and that for any @xmath561 @xmath562 and @xmath563 , where @xmath564    let us show now that there exist @xmath565 and @xmath530 for which @xmath566 .",
    "if so , then taking into account lemma [ le.sec:a_ex_0 ] in appendix  [ a ] , we obtain that for come @xmath557 @xmath567 hence , follows . indeed , choosing in the parameter @xmath568 as a function of @xmath291 such that @xmath569 as @xmath570",
    ", we obtain in view of lemma [ le.sec:a_ex_1 ] in appendix  [ a ] that there exist @xmath571 and @xmath530 for which @xmath566 .",
    "this implies the inequality , and hence , condition does not hold .",
    "note that condition also does not hold .",
    "indeed , this condition in the case considered has the following form : for any @xmath557 @xmath572 if we put @xmath573 then we obtain that @xmath574 and @xmath575 for any @xmath561 and @xmath576 from @xmath577",
    ". therefore , @xmath578 . similarly to the above reasoning we obtain that for some @xmath557 @xmath579 where @xmath580 .",
    "on the other hand , our uniform complete convergence condition @xmath470 holds .",
    "indeed , as we will see in example 4 below , condition @xmath470 holds even for a more general vector ar model than .",
    "thus , the sr procedure is asymptotically minimax .",
    "consider the change of the correlation coefficient in the first - order ar model @xmath581 where @xmath582 and @xmath583 are iid not necessarily gaussian random variables with @xmath584 , @xmath585 and a known density @xmath586 such that for any @xmath427 @xmath587 we assume that the parameters @xmath588 are known . in this case the ergodic distributions for @xmath589 and @xmath489 are given by the random variables @xmath590 and @xmath591 , respectively , which are defined as @xmath592 the pre - change and post - change conditional densities are @xmath593 for all @xmath594 and @xmath595 for @xmath41 , where @xmath596 is an initial value independent of the sequence @xmath583 .",
    "note that condition implies the lower bound ( c@xmath597 ) in condition @xmath473 for any `` minorization '' set of the form @xmath598 $ ] .",
    "it is easily seen that @xmath599 and @xmath600 assume that there exist @xmath601 and @xmath602 such that @xmath603 for example , in the gaussian case ( i.e. , @xmath604 is @xmath605 gaussian density ) , @xmath606 i.e. , conditions are satisfied with @xmath607 and @xmath608    define the lyapunov function as @xmath609 obviously , @xmath610 therefore , for any @xmath611 there exist @xmath427 and @xmath480 such that condition @xmath612 ) holds with @xmath598 $ ] .",
    "let us check now condition ( @xmath613 ) .",
    "assume that there exists @xmath483 for which @xmath614 this condition implies that @xmath615 and @xmath616 .",
    "moreover , taking into account the ergodicity properties , we obtain that for any @xmath617 @xmath618 note also that under the probability @xmath619 for any @xmath424 , @xmath620 .",
    "therefore , @xmath621 , i.e. , using the last convergence in , we obtain that for some @xmath622 @xmath623 using now the first convergence in , we obtain that @xmath624 .",
    "so the upper bounds in imply condition ( @xmath613 ) . by theorem  [ th.sec:mrk.1 ] , condition @xmath199 ) holds for the model if density @xmath604 of the iid random variables @xmath583 satisfies conditions and . the kullback ",
    "leibler information number is @xmath625 where @xmath384 is the distribution of @xmath591 given in .",
    "hence , by theorem  [ th.sec:bay.3 ] and theorem  [ th.sec:cnrsk.2 ] , the sr procedure is asymptotically minimax with respect to the expected detection delays .    in the particular gaussian case where @xmath604 is @xmath526 ,",
    "the random variable @xmath626 is @xmath627 , and the kullback ",
    "leibler information number can be calculated explicitly , @xmath628 .",
    "consider now the change of the correlation coefficient in the first - order ar model with arch(1 ) errors @xcite , assuming that for @xmath427 @xmath629 where an initial value @xmath596 is independent of the sequence @xmath583 .",
    "the sequence @xmath630 is defined in with the known parameters @xmath631 such that @xmath632 . as in the model , we assume that @xmath583 are iid not necessarily gaussian random variables with @xmath584 , @xmath585 and a known density @xmath586 satisfying condition . the variance @xmath633 is known . in just the same way as in the model , we find that the pre - change and post - change conditional densities @xmath634 and @xmath635 are of the form @xmath636 where @xmath637 and @xmath638 .",
    "obviously , the property implies the lower bound ( c@xmath597 ) in condition @xmath612 ) .",
    "the function is given by @xmath639 $ ] and @xmath640    assume that there exist @xmath601 and @xmath602 such that @xmath641 for example , in the gaussian case ( i.e. , @xmath604 is standard gaussian density ) , @xmath642 i.e. , conditions are satisfied with @xmath607 .",
    "the lyapunov function is any @xmath643 function which satisfies the drift condition ( c@xmath644 ) .",
    "we set @xmath645 for @xmath646 , where @xmath647 and @xmath648 is a unique positive root of the equation @xmath649 , where @xmath650 .",
    "it is well known @xcite that if @xmath585 , then @xmath651 .",
    "direct calculations yield @xmath652 therefore , for any @xmath653 there exist @xmath427 and @xmath480 for which condition @xmath612 ) holds with @xmath598 $ ] .",
    "next , we verify condition ( @xmath613 ) . to this end , note that under the probability @xmath654 we have @xmath655 so , for any @xmath483 satisfying with @xmath602 from condition , we obtain that , for some constant @xmath622 , @xmath656 , i.e. , @xmath657 .",
    "now we check the last inequality in ( @xmath613 ) .",
    "fix @xmath658 such that @xmath659 .",
    "evidently , this is possible for sufficiently small @xmath660 .",
    "similarly to we can obtain that @xmath661 where @xmath662 .",
    "therefore , conditions @xmath295 and @xmath309 hold , and using theorem [ th.amc.1 ] in appendix  [ b ] , we obtain that for some constant @xmath622 , @xmath663 .",
    "similarly we obtain that @xmath664 , i.e. , ( @xmath613 ) is satisfied .",
    "thus , by theorem  [ th.sec:mrk.1 ] , condition @xmath199 ) holds for the model where the iid random variables @xmath583 have density @xmath586 that satisfies conditions and with @xmath602 from condition . note that in this case there exists the stationary distribution @xmath384 for @xmath665 which in the gaussian case , @xmath666 , is given by the following random variable @xmath667 where @xmath668 is an iid @xmath669 sequence independent of @xmath670 .",
    "the kullback ",
    "leibler information is @xmath671 where @xmath672    by theorem  [ th.sec:bay.3 ] and theorem  [ th.sec:cnrsk.2 ] , the sr procedure is asymptotically minimax .      consider the multivariate model in @xmath673 given by @xmath674 where @xmath675 and @xmath676 are @xmath677 random matrixes and @xmath583 is an iid sequence of gaussian random vectors @xmath678 in @xmath673 with the positive definite @xmath677 matrix @xmath679 .",
    "assume also that @xmath680 and @xmath681 are iid gaussian random matrixes @xmath682 , where the @xmath683 matrix @xmath684 is not necessary positive definite .",
    "assume , in addition , that @xmath685 $ ] , @xmath686 have the modules less than one .",
    "in this case , the processes @xmath687 and @xmath463 are ergodic with the ergodic distributions give by the vectors @xcite @xmath688 , i.e. , the invariant measures @xmath689 on @xmath673 are defined as @xmath690 for any @xmath691 . as shown in @xcite , there exists a positive definite @xmath677 matrix @xmath692 and the constant @xmath693 such that the function @xmath694 and the set @xmath695 satisfy condition ( c@xmath644 ) for any @xmath696 .",
    "the function @xmath697 can be calculated for any @xmath698 from @xmath673 as @xmath699 where @xmath700 and @xmath701 . from this",
    "we obtain that @xmath702    assume that @xmath703 note that for the model this condition holds .",
    "so under this condition @xmath704 . thus , choosing @xmath705 with @xmath706 and any fixed @xmath707 and using the jensen inequality yields condition ( @xmath708 ) .",
    "let us check now condition ( @xmath613 ) .",
    "note that under the probability @xmath709 we obtain that for any @xmath424 the vector @xmath710 is @xmath711 gaussian in @xmath673 .",
    "moreover , in view of condition @xmath712 for some positive @xmath713 .",
    "clearly , @xmath657 for any @xmath389 .",
    "we now check the last inequality in ( @xmath613 ) .",
    "first note that , as it is shown in @xcite , under our conditions @xmath714 .",
    "next , observe that under the probability @xmath619 @xmath715 so , for any @xmath716 , @xmath717 .",
    "in view of the ergodicity property we obtain that @xmath718 i.e. , @xmath719 for some positive @xmath713 .",
    "so @xmath720 for any @xmath658 for which @xmath721 .",
    "hence , by theorem  [ th.sec:mrk.1 ] , condition @xmath470 is satisfied with @xmath722 , and by theorem  [ th.sec:bay.3 ] and theorem  [ th.sec:cnrsk.2 ] the sr detection procedure is asymptotically minimax .",
    "let us now generalize the results of subsection  [ ssec : ar1cor ] for the problem of detecting the change of the correlation coefficient in the @xmath723-th order ar process , assuming that for @xmath427 @xmath724 where @xmath725 and @xmath583 are iid , not necessarily gaussian random variables with @xmath584 , @xmath585 . in the sequel we use the notation @xmath726 .",
    "the process is not markov , but the @xmath723-dimensional process @xmath727 is markov . note that for @xmath41 @xmath728 where @xmath729 1&,\\ldots,0\\\\[2 mm ] .. & \\ldots \\\\[2 mm ] 0&,\\ldots,1,0 \\end{array } \\right ) \\quad\\mbox{and}\\quad \\check{w}_{{\\mathchoice{n}{n}{\\lower.25ex\\hbox{$\\scriptstylen$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylen$}}}}=(w_{{\\mathchoice{n}{n}{\\lower.25ex\\hbox{$\\scriptstylen$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstylen$}}}},0,\\ldots,0)'\\in\\bbr^{p}\\,.\\ ] ] it is clear that @xmath730=\\,b\\,= \\left ( \\begin{array}{rc } 1&,\\ldots,0\\\\[2 mm ] .. & \\ldots \\\\[2 mm ] 0&,\\ldots,0 \\end{array } \\right ) \\,.\\ ] ] assume that all eigenvalues of the matrix @xmath731 have the modules less than one .",
    "the ergodic distribution is given by the vector @xmath732 , where @xmath733 obviously , condition ( c@xmath597 ) does not hold for the process .",
    "to fulfill this condition we replace this process by the embedded homogeneous markov process @xmath734 for some @xmath433 .",
    "this process can be represented as @xmath735 clearly , @xmath736 is gaussian with the parameters @xmath737 , where @xmath738 .",
    "one can check directly that this matrix is positive definite .",
    "define the function @xmath739 as @xmath740 where @xmath696 will be specified later .",
    "let @xmath741 and @xmath742 .",
    "obviously , @xmath743 , i.e. , @xmath744 .",
    "now we set @xmath745^{1/2}$ ] with @xmath746 and @xmath747 .",
    "next we need the minorizing measure in condition @xmath306 ) on the borel @xmath130-field in @xmath673 . to this end , we define @xmath748 for any borel set @xmath749 in @xmath673 , where @xmath750 is the lebesgue measure in @xmath673 .    finally , we show that , for any @xmath751 , the markov process satisfies condition ( @xmath752 ) .",
    "indeed , note that @xmath753 taking into account that @xmath754 we obtain that , for @xmath755 , @xmath756 .",
    "moreover , @xmath757 therefore , choosing in @xmath758 , we obtain condition @xmath506 .    condition ( @xmath613 ) can be checked in the same way as in example 2 .    by theorem  [ th.sec:mrk.2 ] , condition",
    "@xmath470 holds with @xmath759 , where @xmath760 and the matrix @xmath761 is defined in , and the sr procedure is asymptotically minimax .",
    "the work of the first author was partially supported by the russian science foundation ( research project no .",
    "14 - 49 - 00079 , national research university  mpei \" , moscow , russia ) and by the academic d.i .",
    "mendeleev fund program of the tomsk state university ( research project nu 8.1.55.2015 l ) .",
    "the work of the second author was supported in part by the u.s .",
    "air force office of scientific research under muri grant fa9550 - 10 - 1 - 0569 , by the u.s .",
    "defense advanced research projects agency under grant w911nf-12 - 1 - 0034 and by the u.s .",
    "army research office under grants w911nf-13 - 1 - 0073 and w911nf-14 - 1 - 0246 at the university of southern california , department of mathematics and at the university of connecticut , department of statistics .",
    "in this appendix , we present results needed for proofs in section  [ sec : mare ] .",
    "the following proposition establishes asymptotic properties of the sr procedure for large @xmath762 regardless of the optimality criteria .",
    "while it is being used in the proofs of asymptotic optimality of the sr procedure under considered criteria , it also interesting independently .",
    "[ prop : a1 ] let @xmath86 be the sr procedure defined in .    *",
    "( i ) * assume that there exists a positive and finite number @xmath113 such that , for all @xmath763 , the following conditions hold : @xmath764 and , for some @xmath120 , @xmath765 then @xmath766^r { \\leqslant}\\frac{1}{i^r } \\quad \\text{for all}~ \\nu { \\geqslant}0,\\ ] ] @xmath767 { \\leqslant}\\frac{1}{i^r } \\quad \\text{for all}~ \\nu { \\geqslant}0,\\ ] ] and @xmath768^r = \\frac{1}{i^r } \\ , .\\ ] ] * ( ii ) * asymptotic relations , and hold if @xmath769 * ( iii ) * if , in particular , @xmath119 , then the uniform complete convergence condition @xmath225 implies , and with @xmath119 .",
    "\\(i ) let @xmath770 .",
    "we have @xmath771}^r   & = \\int_0^\\infty r t^{r-1 } { { \\mathsf{p}}}_\\nu{\\left(t(h)-\\nu > t\\right ) } \\ , \\d t    \\nonumber \\\\ & = n_0^r + \\sum_{n=0}^{\\infty } \\int_{n_0+n}^{n_0+n+1 } r t^{r-1 }   { { \\mathsf{p}}}_\\nu ( t(h)-\\nu > t ) \\ , \\d t \\nonumber \\\\ & = n_0^r + \\sum_{n=0}^{\\infty } \\int_{n_0+n}^{n_0+n+1 } r t^{r-1 }   { { \\mathsf{p}}}_\\nu ( t(h)-\\nu >",
    "n_0+n ) \\ , \\d t \\nonumber \\\\ & = n_0^r + \\sum_{n=0}^{\\infty } [ ( n_0+n+1)^r- ( n_0+n)^r ] { { \\mathsf{p}}}_\\nu ( t(h)-\\nu > n_0+n ) \\nonumber \\\\ & = n_0^r + \\sum_{n = n_0}^{\\infty } [ ( n+1)^r - n^r ]   { { \\mathsf{p}}}_\\nu ( t(h)-\\nu > n ) \\nonumber \\\\   & { \\leqslant}n_0^{r } + \\sum_{n = n_0}^{\\infty }    r ( n+1)^{r-1 }    { { \\mathsf{p}}}_\\nu ( t(h ) > \\nu+ n ) \\nonumber   \\\\   & { \\leqslant}n_0^{r } + \\sum_{n = n_0}^{\\infty }    r 2^{r-1 } n^{r-1 }    { { \\mathsf{p}}}_\\nu ( t(h ) > \\nu+ n ) \\ , .\\end{aligned}\\ ] ] in just the same way as in , we obtain that for all @xmath167 and @xmath772 , @xmath773 hence @xmath774}^r { \\leqslant}{\\left(1+\\frac{\\log h}{i-\\varepsilon}\\right)}^r +    r2^{r-1 } \\ , \\sum_{n=1}^\\infty n^{r-1 } \\sup_{\\nu { \\geqslant}0 } { { \\mathsf{p}}}_\\nu{\\left(\\frac{1}{n } z_{\\nu+n}^\\nu < i   - \\varepsilon\\right)},\\ ] ] where , by condition , the last term on the right - hand side is finite .",
    "this immediately implies the following upper bounds for the moments of the detection delay ( for any @xmath17 ) @xmath775}^r { \\leqslant}\\limsup_{h\\to\\infty}\\ , \\frac{1}{(\\log h)^r } \\ , \\sup_{{\\mathchoice{\\nu{\\geqslant}0}{\\nu{\\geqslant}0}{\\lower.25ex\\hbox{$\\scriptstyle\\nu{\\geqslant}0 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\nu{\\geqslant}0$}}}}\\ , { { \\mathsf{e}}}_\\nu{\\left[(t(h)-\\nu)^+\\right]}^r { \\leqslant}\\frac{1}{i^r } .\\ ] ] the upper bound follows . to obtain the upper bound for the conditional risk",
    ", it suffices to observe that @xmath776 = { { \\mathsf{e}}}_{\\nu}[(t(h)-\\nu)^r]^+/{{\\mathsf{p}}}_\\infty(t(h)>\\nu)$ ] and that @xmath777 as @xmath778 for every @xmath17 .",
    "the letter follows easily from the fact that @xmath779 is a zero - mean @xmath45-martingale .",
    "define @xmath780 , where as before @xmath175 .",
    "replacing @xmath135 in the proof of theorem  [ th.sec:bay.1 ] by @xmath781 , in particular in , we obtain that , for any @xmath177 , @xmath782 by lemma  [ lem : pfasr ] , @xmath783 , and as in , we have @xmath784 .",
    "hence , @xmath785 so that the first term in goes to zero as @xmath778 for any @xmath763 and for any @xmath786",
    ". by condition , the second term also goes to zero as @xmath778 , and therefore , @xmath787 for any @xmath177 and any @xmath786 . finally , chebyshev s inequality yields @xmath788^r{\\geqslant}{{\\mathsf{e}}}_0 [ t(h)]^r { \\geqslant}m_{\\varepsilon , h}^r\\,{{\\mathsf{p}}}_0{\\left(t(h)>m_{{\\mathchoice{\\varepsilon , h}{\\varepsilon , h}{\\lower.25ex\\hbox{$\\scriptstyle\\varepsilon , h$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\varepsilon , h$}}}}\\right)},\\ ] ] so @xmath789^r { \\geqslant}{\\left(\\frac{1-\\varepsilon}{i+d}\\right)}^r\\ ] ] for arbitrary @xmath790 and @xmath786 , and we obtain the asymptotic lower bound @xmath791^r { \\geqslant}\\frac{1}{i^r } \\ , , \\ ] ] which along with the upper bound completes the proof of in ( i ) .",
    "\\(ii ) the uniform @xmath112complete convergence condition implies both conditions and , and hence , , and hold true under .",
    "\\(iii ) finally , when @xmath119 , condition is nothing but the uniform complete convergence condition @xmath225 , and hence , , and hold true with @xmath119 under @xmath225 .",
    "this completes the proof of all three assertions .",
    "the following proposition allow us to compare the classes and .",
    "[ pr.sec:absrsk.1 ] for any @xmath87 , @xmath792- 1 $ ] and @xmath793 , the following inclusions hold : @xmath794    let @xmath795 . taking in @xmath796",
    ", we obtain @xmath797 hence , @xmath798 , i.e. , the first inclusion in follows .",
    "now , if @xmath799 , then @xmath800 . therefore , taking in @xmath801 , we obtain @xmath802 i.e. , @xmath803 .",
    "hence both inclusions in are proven .",
    "the following proposition allows us to compare the classes and .",
    "[ pr.sec:cnrsk.1 ] for any @xmath87 , @xmath792- 1 $ ] and @xmath804 , the following inclusions hold : @xmath805    first we show the left inclusion .",
    "let @xmath806 . then , taking into account the inequality for any @xmath796 and using the definition of @xmath807 , we obtain that @xmath808 & { \\leqslant}\\frac{{{\\mathsf{p}}}_{{\\mathchoice{\\infty}{\\infty}{\\lower.25ex\\hbox{$\\scriptstyle\\infty$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\infty$}}}}\\left(\\tau < k^{*}\\right ) } { 1-{{\\mathsf{p}}}_{{\\mathchoice{\\infty}{\\infty}{\\lower.25ex\\hbox{$\\scriptstyle\\infty$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle\\infty$}}}}\\left ( \\tau < k^{*}\\right)}\\\\[2 mm ] & { \\leqslant}\\frac{\\alpha_{{\\mathchoice{3}{3}{\\lower.25ex\\hbox{$\\scriptstyle3 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle3$}}}}\\,(1-\\varrho_{{\\mathchoice{2,\\beta}{2,\\beta}{\\lower.25ex\\hbox{$\\scriptstyle2,\\beta$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle2,\\beta$}}}})^{-k^ { * } } } { 1-\\alpha_{{\\mathchoice{3}{3}{\\lower.25ex\\hbox{$\\scriptstyle3 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle3$}}}}\\,(1-\\varrho_{{\\mathchoice{2,\\beta}{2,\\beta}{\\lower.25ex\\hbox{$\\scriptstyle2,\\beta$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle2,\\beta$}}}})^{-k^ { * } } } = \\beta \\,,\\end{aligned}\\ ] ] i.e. , @xmath4 belongs to @xmath809 .",
    "now we show the right inclusion in .",
    "let @xmath4 be from @xmath809 . then , using the definition of the class @xmath809 in , we obtain that @xmath810 .",
    "therefore , similarly to the proof of the right inclusion in we obtain that @xmath803 , and the proof is complete .",
    "recall that @xmath811 and @xmath812 are defined in .",
    "[ le.sec:a_ex_0 ] for any @xmath557 , @xmath813    indeed , we have @xmath814 where @xmath815 . using the definition of the sequence @xmath816 in",
    ", we obtain that @xmath817 thus , @xmath818 { \\leqslant}\\sigma^{2}_1/\\lambda^{2}_1+\\sigma^{2}_2/\\lambda^{2}_2 $ ] , which implies .",
    "[ le.sec:a_ex_1 ] assume that in the parameter @xmath568 is such that @xmath819 then @xmath820    first note that for any @xmath821 the inverse matrix for can be written as @xmath822 -\\rho & , \\",
    ", 1+\\rho^{2}+\\sigma^{2}_{{\\mathchoice{1}{1}{\\lower.25ex\\hbox{$\\scriptstyle1 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle1$}}}}\\,x^{2}_{{\\mathchoice{1}{1}{\\lower.25ex\\hbox{$\\scriptstyle1 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle1 $ } } } } \\end{array } \\right)\\ ] ] and @xmath823 where @xmath824 and @xmath825 .",
    "this function can be written as @xmath826 where @xmath827 , @xmath828 , and @xmath829 . now to study the function we represent the coefficient @xmath830 as @xmath831 , where @xmath832 , @xmath833 $ ] and @xmath834 . taking into account that @xmath835 and that the random variable @xmath836 is @xmath837-conditionally gaussian with the parameters @xmath201 and @xmath838 , we obtain @xmath839 where @xmath840 .",
    "we recall that @xmath541 .",
    "now , by the bunyakovsky  cauchy ",
    "schwarz inequality , @xmath841 therefore , for any @xmath842 , @xmath843 now we calculate the expectation @xmath844 . to this end , we set @xmath845 and @xmath846 .",
    "conditioned on @xmath837 , the random variable @xmath847 is independent of @xmath848 , and @xmath847 is gaussian with the parameters @xmath849 , where @xmath850 by the bunyakovsky  cauchy ",
    "schwarz inequality , the random variable @xmath851 a.s .",
    "next , using the definitions of the random variables @xmath852 in , we obtain that @xmath853 if and only if for any @xmath854 @xmath855",
    "so , @xmath856 a.s .",
    "thus , @xmath857 & { \\geqslant}(1 + \\rho^{2}\\,\\varsigma_{{\\mathchoice{*}{*}{\\lower.25ex\\hbox{$\\scriptstyle*$ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle*$}}}})\\ ,   { { \\mathsf{e}}}\\left(\\frac{1}{1+\\sigma^{2}_{{\\mathchoice{2}{2}{\\lower.25ex\\hbox{$\\scriptstyle2 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle2$}}}}(1+\\rho^{2})\\zeta^{2}_{{\\mathchoice{2}{2}{\\lower.25ex\\hbox{$\\scriptstyle2 $ } } { \\lower0.25ex\\hbox{$\\scriptscriptstyle2$}}}}}\\vert{{{\\mathcal{g}}}}\\right)\\,,\\end{aligned}\\ ] ] and we obtain that @xmath858 i.e. , @xmath859 setting now @xmath860 , we obtain @xmath861 moreover , @xmath862 , where @xmath863 and @xmath864 $ ] . therefore ,",
    "taking into account that @xmath865 , we obtain @xmath866 this implies immediately that @xmath867 it is easy to check that @xmath868 taking into account here that @xmath869 we obtain that @xmath870 , i.e. , @xmath871 therefore , for any @xmath842 @xmath872 clearly , @xmath873 thus , using the condition of this lemma we obtain .",
    "we follow the meyn  tweedie approach @xcite .",
    "we recall some definitions from @xcite and @xcite for a homogeneous markov process @xmath879 defined on a measurable state space @xmath880 .",
    "denote by @xmath881 the transition probability of this process , i.e. , for any @xmath882 , @xmath883 the @xmath884step transition probability is @xmath885 .",
    "@xmath899 _ there exist a @xmath385 function @xmath386 , constants @xmath479 , @xmath900 and a set @xmath901 from @xmath893 such that @xmath902 and , for all @xmath396 _ , @xmath903 in this case , we call @xmath386 the _ lyapunov function",
    ". _      [ th.amc.1 ] let @xmath879 be a homogeneous markov process satisfying conditions @xmath890 and @xmath899 with the same set @xmath891 . then @xmath879 is a positive geometric ergodic process , i.e. , @xmath904 for some positive constants @xmath905 and @xmath906 which are given in @xcite .",
    "\\(2005 ) asymptotic performance of a multichart cusum test under false alarm probability constraint . in _ proceedings of the 44th ieee conference decision and control and european control conference ( cdc - ecc05 ) , seville , sp _ , 320325 .",
    "ieee , omnipress cd - rom .",
    "\\(2014 ) rapid detection of attacks in computer networks by quickest change - point detection methods . in n.  adams and",
    "n.  heard , editors , _ data analysis for network cyber - security _",
    "imperial college press , london , uk ."
  ],
  "abstract_text": [
    "<S> we consider the quickest change - point detection problem in pointwise and minimax settings for general dependent data models . </S>",
    "<S> two new classes of sequential detection procedures associated with the maximal `` local '' probability of a false alarm within a period of some fixed length are introduced . for these classes of detection procedures , </S>",
    "<S> we consider two popular risks : the expected positive part of the delay to detection and the conditional delay to detection . under very general conditions for the observations , </S>",
    "<S> we show that the popular shiryaev  roberts procedure is asymptotically optimal , as the local probability of false alarm goes to zero , with respect to both these risks pointwise ( uniformly for every possible point of change ) and in the minimax sense ( with respect to maximal over point of change expected detection delays ) . the conditions are formulated in terms of the rate of convergence in the strong law of large numbers for the log - likelihood ratios between the `` change '' and `` no - change '' hypotheses , specifically as a uniform complete convergence of the normalized log - likelihood ratio to a positive and finite number . </S>",
    "<S> we also develop tools and a set of sufficient conditions for verification of the uniform complete convergence for a large class of markov processes . </S>",
    "<S> these tools are based on concentration inequalities for functions of markov processes and the meyn  tweedie geometric ergodic theory </S>",
    "<S> . finally , we check these sufficient conditions for a number of challenging examples ( time series ) frequently arising in applications , such as autoregression , autoregressive garch , etc . </S>"
  ]
}