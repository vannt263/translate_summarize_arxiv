{
  "article_text": [
    "knowledge - base systems must typically deal with imperfection in knowledge , in particular , in the form of incompleteness , inconsistency , and uncertainty . with this motivation ,",
    "several frameworks for manipulating data and knowledge have been proposed in the form of extensions to classical logic programming and deductive databases to cope with imperfections in available knowledge .",
    "abiteboul , _ et al . _",
    "@xcite , liu @xcite , and dong and lakshmanan @xcite dealt with deductive databases with incomplete information in the form of null values .",
    "kifer and lozinskii @xcite have developed a logic for reasoning with inconsistency .",
    "extensions to logic programming and deductive databases for handling uncertainty are numerous .",
    "they can broadly be categorized into non - probabilistic and probabilistic formalisms .",
    "we review previous work in these fields , with special emphasis on probabilistic logic programming , because of its relevance to this paper .",
    "* non - probabilistic formalisms *    _ ( 1 ) fuzzy logic programming _ :",
    "this was essentially introduced by van emden in his seminal paper on quantitative deduction @xcite , and further developed by various researchers , including steger _",
    "@xcite , schmidt _",
    "_ @xcite .",
    "_ ( 2 ) annotated logic programming _ :",
    "this framework was introduced by subrahmanian @xcite , and later studied by blair and subrahmanian @xcite , and kifer and li @xcite . while blair and subrahmanian s focus was paraconsistency , kifer and li extended the framework of @xcite into providing a formal semantics for rule - based systems with uncertainty .",
    "finally , this framework was generalized by kifer and subrahmanian into the generalized annotated programming ( gap ) framework @xcite ) .",
    "all these frameworks are inherently based on a lattice - theoretic semantics .",
    "annotated logic programming has also been employed with the probabilistic approach , which we will discuss further below .    _ ( 3 ) evidence theoretic logic programming _ : this has been mainly studied by baldwin and monk @xcite and baldwin @xcite ) .",
    "they use dempster s evidence theory as the basis for dealing with uncertainty in their logic programming framework .",
    "* probabilistic formalisms *    indeed , there has been substantial amount of research into probabilistic logics ever since boole @xcite .",
    "carnap @xcite is a seminal work on probabilistic logic .",
    "fagin , halpern , and megiddo @xcite study the satisfiability of systems of probabilistic constraints from a model - theoretic perspective .",
    "gaifman @xcite extends probability theory by borrowing notions and techniques from logic .",
    "nilsson @xcite uses a  possible worlds \" approach to give model - theoretic semantics for probabilistic logic .",
    "@xcite notion of probabilistic entailment is similar to that of nilsson .",
    "some of the probabilistic logic programming works are based on probabilistic logic approaches , such as ng and subrahmanian s work on probabilistic logic programming @xcite and ng s recent work on empirical databases @xcite .",
    "we discuss these works further below .",
    "we will not elaborate on probabilistic logics any more and refer the reader to halpern @xcite for additional information .",
    "works on probabilistic logic programming and deductive databases can be categorized into two main approaches , annotation - based , and implication based .",
    "* annotation based approach * : ng and subrahmanian @xcite were the first to propose a probabilistic basis for logic programming .",
    "their syntax borrows from that of annotated logic programming @xcite , although the semantics are quite different .",
    "the idea is that uncertainty is always associated with individual atoms ( or their conjunctions and disjunctions ) , while the rules or clauses are always kept classical .    in @xcite ,",
    "uncertainty in an atom is modeled by associating a probabilistic truth value with it , and by asserting that it lies in an interval .",
    "the main interest is in characterizing how precisely we can  bound \" the probabilities associated with various atoms . in terms of the terminology of belief and doubt , we can say , following kifer and li @xcite , that the combination of belief and doubt about a piece of information might lead to an interval of probabilities , as opposed a precise probabilities .",
    "but , as pointed out in @xcite , even if one starts with precise point probabilities for atomic events , probabilities associated with compound events can only be calculated to within some exact upper and lower bounds , thus naturally necessitating intervals .",
    "but then , the same argument can be made for an agent s belief as well as doubt about a fact , they both could well be intervals . in this sense",
    ", we can say that the model of @xcite captures only the belief .",
    "a second important characteristic of this model is that it makes a conservative assumption that nothing is known about the interdependence of events ( captured by the atoms in an input database ) , and thus has the advantage of not having to make the often unrealistic independence assumption .",
    "however , by being conservative , it makes it impossible to take advantage of the ( partial ) knowledge a user may have about the interdependence among some of the events .    from a technical perspective",
    ", only annotation constants are allowed in @xcite .",
    "intuitively , this means only constant probability ranges may be associated with atoms .",
    "this was generalized in a subsequent paper by ng and subrahmanian @xcite to allow annotation variables and functions .",
    "they have developed fixpoint and model - theoretic semantics , and provided a sound and weakly complete proof procedure .",
    "_ @xcite have proposed a sound ( propositional ) probabilistic calculus based on conditional probabilities , for reasoning in the presence of incomplete information . although they make use of a datalog - based interface to implement this calculus , their framework is actually propositional . in related works ,",
    "ng and subrahmanian have extended their basic probabilistic logic programming framework to capture stable negation in @xcite , and developed a basis for dempster - shafer theory in @xcite .    * implication based approach * : while many of the quantitative deduction frameworks ( van emden @xcite , fitting @xcite , debray and ramakrishnan @xcite , etc . )",
    "are implication based , the first implication based framework for probabilistic deductive databases was proposed in @xcite .",
    "the idea behind implication based approach is to associate uncertainty with the facts as well as rules in a deductive database .",
    "sadri @xcite in a number of papers developed a hybrid method called information source tracking ( ist ) for modeling uncertainty in ( relational ) databases which combines symbolic and numeric approaches to modeling uncertainty .",
    "lakshmanan and sadri @xcite pursue the deductive extension of this model using the implication based approach .",
    "lakshmanan @xcite generalizes the idea behind ist to model uncertainty by characterizing the set of ( complex ) scenarios under which certain ( derived ) events might be believed or doubted given a knowledge of the applicable belief and doubt scenarios for basic events .",
    "he also establishes a connection between this framework and modal logic .",
    "while both @xcite are implication based approaches , strictly speaking , they do not require any commitment to a particular formalism ( such a probability theory ) for uncertainty manipulation .",
    "any formalism that allows for a consistent calculation of numeric certainties associated with boolean combination of basic events , based on given certainties for basic events , can be used for computing the numeric certainties associated with derived atoms .",
    "recently , lakshmanan and shiri @xcite unified and generalized all known implication based frameworks for deductive databases with uncertainty ( including those that use formalisms other than probability theory ) into a more abstract framework called the parametric framework .",
    "the notions of conjunctions , disjunctions , and certainty propagations ( via rules ) are parameterized and can be chosen based on the applications .",
    "even the domain of certainty measures can be chosen as a parameter . under such broadly generic conditions",
    ", they proposed a declarative semantics and an equivalent fixpoint semantics .",
    "they also proposed a sound and complete proof procedure .",
    "finally , they characterized conjunctive query containment in this framework and provided necessary and sufficient conditions for containment for several large classes of query programs .",
    "their results can be applied to individual implication based frameworks as the latter can be seen as instances of the parametric framework .",
    "conjunctive query containment is one of the central problems in query optimization in databases .",
    "while the framework of this paper can also be realized as an instance of the parametric framework , the concerns and results there are substantially different from ours . in particular , to our knowledge ,",
    "this is the first paper to address data complexity in the presence of ( probabilistic ) uncertainty .",
    "* other related work *    fitting @xcite has developed an elegant framework for quantitative logic programming based on bilattices , an algebraic structure proposed by ginsburg @xcite in the context of many - valued logic programming .",
    "this was the first to capture both belief and doubt in one uniform logic programming framework . in recent work ,",
    "lakshmanan _ et al .",
    "_ @xcite have proposed a model and algebra for probabilistic relational databases .",
    "this framework allows the user to choose notions of conjunctions and disjunctions based on a family of strategies .",
    "in addition to developing complexity results , they also address the problem of efficient maintenance of materialized views based on their probabilistic relational algebra .",
    "one of the strengths of their model is not requiring any restrictive independence assumptions among the facts in a database , unlike previous work on probabilistic relational databases @xcite . in a more recent work , dekhtyar and subrahmanian @xcite developed an annotation based framework where the user can have a parameterized notion of conjunction and disjunction . in not requiring independence assumptions , and being able to allow the user to express her knowledge about event interdependence by means of a parametrized family of conjunctions and disjunctions , both @xcite have some similarities to this paper .",
    "however , chronologically , the preliminary version of this paper @xcite was the first to incorporate such an idea in a probabilistic framework . besides , the frameworks of @xcite are substantially different from ours . in a recent work ng @xcite studies _ empirical _ databases , where a deductive database is enhanced by empirical clauses representing statistical information .",
    "he develops a model - theoretic semantics , and studies the issues of consistency and query processing in such databases .",
    "his treatment is probabilistic , where probabilities are obtained from statistical data , rather than being subjective probabilities .",
    "( see halpern @xcite for a comprehensive discussion on statistical and subjective probabilities in logics of probability . )",
    "ng s query processing algorithm attempts to resolve a query using the ( regular ) deductive component of the database . if it is not successful , then it reverts to the empirical component , using the notion of _ most specific reference class _ usually used in statistical inferences .",
    "our framework is quite different in that every rule / fact is associated with a confidence level ( a pair of probabilistic intervals representing belief and doubt ) , which may be subjective , or may have been obtained from underlying statistical data .",
    "the emphasis of our work is on ( _ i _ ) the characterization of different modes for combining confidences , ( _ ii _ ) semantics , and , in particular , ( _ iii _ ) termination and complexity issues .",
    "the contributions of this paper are as follows .",
    "* we associate a _ confidence level _ with facts and rules ( of a deductive database ) .",
    "a confidence level comes with both a _ belief _ and a _ doubt _ ( in what is being asserted ) [ see section [ motiv ] for a motivation ] .",
    "belief and doubt are subintervals of @xmath0 $ ] representing probability ranges .",
    "* we show that confidence levels have an interesting algebraic structure called _ trilattices _ as their basis ( section [ lattice ] ) .",
    "analogously to fitting s bilattices , we show that trilattices associated with confidence levels are interlaced , making them interesting in their own right , from an algebraic point of view .",
    "in addition to providing an algebraic footing for our framework , trilattices also shed light on the relationship between our work and earlier works and offer useful insights . in particular ,",
    "trilattices give rise to three ways of ordering confidence levels : the truth - order , where belief goes up and doubt comes down , the information order , where both belief and doubt go up , and the precision order , where the probability intervals associated with both belief and doubt become sharper , the interval length decreases .",
    "this is to be contrasted with the known truth and information ( called knowledge there ) orders in a bilattice . * a purely lattice - theoretic basis for logic programming",
    "can be constructed using trilattices ( similar to fitting @xcite ) . however , since our focus in this paper is probabilistic uncertainty , we develop a probabilistic calculus for combining confidence levels associated with basic events into those for compound events based on them ( section [ prob - calc ] ) . instead of committing to any specific rules for combining confidences",
    ", we propose a framework which allows a user to choose an appropriate  mode \" from a collection of available ones . *",
    "we develop a generalized framework for rule - based programming with probabilistic knowledge , based on this calculus .",
    "we provide the declarative and fixpoint semantics for such programs and establish their equivalence ( section [ prob - ddb ] ) .",
    "we also provide a sound and complete proof procedure ( section [ proof - theory ] ) . *",
    "we study the termination and complexity issues of such programs and show : ( 1 ) the closure ordinal of @xmath1 can be as high as @xmath2 in general ( but no more ) , and ( 2 ) when only _ positive correlation _",
    "is used for disjunction , the data complexity of such programs is polynomial time .",
    "our proof technique for the last result yields a similar result for van emden s framework ( section [ termination ] ) .",
    "* we also compare our work with related work and bring out the advantages and generality of our approach ( section [ termination ] ) .",
    "in this section , we discuss the motivation for our work as well as comment on our design decisions for this framework .",
    "the motivation for using probability theory as opposed to other formalisms for representing uncertainty has been discussed at length in the literature @xcite .",
    "probability theory is perhaps the best understood and mathematically well - founded paradigm in which uncertainty can be modeled and reasoned about .",
    "two possibilities for associating probabilities with facts and rules in a ddb are van emden s style of associating confidences with rules as a whole @xcite , or the annotation style of kifer and subrahmanian @xcite .",
    "the second approach is more powerful : it is shown in @xcite that the second approach can simulate the first .",
    "the first approach , on the other hand , has the advantage of intuitive appeal , as pointed out by kifer and subrahmanian @xcite . in this paper",
    ", we choose the first approach .",
    "a comparison between our approach and annotation - based approach with respect to termination and complexity issues is given in section [ termination ] .",
    "a second issue is whether we should insist on precise probabilities or allow intervals ( or ranges ) .",
    "firstly , probabilities derived from any sources may have tolerances associated with them .",
    "even experts may feel more comfortable with specifying a range rather than a precise probability .",
    "secondly , fenstad @xcite has shown ( also see @xcite ) that when enough information is not available about the interaction between events , the probability of compound events can not be determined precisely : one can only give ( tight ) bounds .",
    "thus , we associate ranges of probabilities with facts and rules .",
    "a last issue is the following .",
    "suppose ( uncertain ) knowledge contributed by an expert corresponds to the formula @xmath3 .",
    "in general , we can not assume the expert s knowledge is perfect .",
    "this means he does not necessarily know _ all _ situations in which @xmath3 holds . nor",
    "does he know _ all _ situations where @xmath3 fails to hold ( @xmath4 holds ) .",
    "he models the proportion of the situations where he knows @xmath3 holds as his _ belief _ in @xmath3 and the proportion of situations where he knows @xmath4 holds as his _",
    "doubt_. there could be situations , unknown to our expert , where @xmath3 holds ( or @xmath4 holds ) .",
    "these unknown situations correspond to the gap in his knowledge .",
    "thus , as far as he knows , @xmath3 is _ unknown _ or _ undefined _ in these remaining situations .",
    "these observations , originally made by fitting @xcite , give rise to the following definition .",
    "[ defn : cf ] ( _ confidence level _ ) denote by @xmath5 $ ] the set of all closed subintervals over @xmath6 $ ] .",
    "consider the set @xmath7 \\times { \\cal c}[0 , 1]$ ] .",
    "a _ confidence level _ is an element of @xmath8 .",
    "we denote a confidence level as @xmath9,~ [ \\gamma,\\delta]\\rangle$}}$ ] .    in our approach confidence levels",
    "are associated with facts and rules .",
    "the intended meaning of a fact ( or rule ) @xmath3 having a confidence @xmath9,~ [ \\gamma,\\delta]\\rangle$}}$ ] is that @xmath10 and @xmath11 are the lower and upper bounds of the expert s _ belief _ in @xmath3 , and @xmath12 and @xmath13 are the lower and upper bounds of the expert s _ doubt _ in @xmath3 .",
    "these notions will be formalized in section [ prob - calc ] .",
    "the following example illustrates such a scenario .",
    "( the figures in all our examples are fictitious . )",
    "consider the results of gallup polls conducted before the recent canadian federal elections .",
    "\\1 . of the people",
    "surveyed , between 50% and 53% of the people in the age group 19 to 30 favor the liberals .",
    "between 30% and 33% of the people in the above age group favor the reformists .",
    "+ 3 . between 5% and",
    "8% of the above age group favor the tories .",
    "the reason we have ranges for each category is that usually some tolerance is associated with the results coming from such polls .",
    "also , we do not make the proportion of undecided people explicit as our interest is in determining the support for the different parties .",
    "suppose we assimilate the information above in a probabilistic framework .",
    "for each party , we compute the probability that a _",
    "randomly _ chosen person from the sample population of the given age group will ( not ) vote for that party .",
    "we transfer this probability as the _ subjective _ probability that _ any _ person from that age group ( in the actual population ) will ( not ) vote for the party .",
    "the conclusions are given below , where @xmath14 says @xmath15 will vote for party @xmath16 , @xmath17-@xmath18 says @xmath15 belongs to the age group specified above .",
    "@xmath19 , @xmath20 , and @xmath21 are constants , with the obvious meaning .",
    "@xmath22 @xmath23 , [ 0.35 , 0.41]\\rangle}}{{\\mbox{$<\\hspace*{-9pt } \\rule[2pt]{80pt}{0.5pt}$ } } } $ } } $ ] @xmath17-@xmath18 .",
    "@xmath24 : @xmath25 , [ 0.55 , 0.61]\\rangle}}{{\\mbox{$<\\hspace*{-9pt } \\rule[2pt]{80pt}{0.5pt}$ } } } $ } } $ ] @xmath17-@xmath18 .",
    "@xmath26 : @xmath27 , [ 0.8 , 0.86]\\rangle}}{{\\mbox{$<\\hspace*{-9pt } \\rule[2pt]{80pt}{0.5pt}$ } } } $ } } $ ] @xmath17-@xmath18 .    as usual ,",
    "each rule is implicitly universally quantified outside the entire rule .",
    "each rule is expressed in the form @xmath28,~ [ \\gamma,\\delta]\\rangle$}}}{{\\mbox{$<\\hspace*{-9pt } \\rule[2pt]{80pt}{0.5pt}$ } } } $ } } body\\ ] ] where @xmath29 $ ] .",
    "we usually require that @xmath30 and @xmath31 . with each rule ,",
    "we have associated two intervals .",
    "@xmath32 $ ] ( @xmath33 $ ] ) is the _ belief _ ( _ doubt _ ) the expert has in the rule .",
    "notice that from his knowledge , the expert can only conclude that the proportion of people he _ knows _ favor @xmath20 or @xmath21 will not vote for @xmath19 .",
    "thus the probability that a person in the age group 19 - 30 will not vote for liberals , according to the expert s knowledge , is in the range @xmath34 $ ] , obtained by summing the endpoints of the belief ranges for reform and tories . notice that in this case @xmath35 ( or @xmath36 ) is not necessarily @xmath37 .",
    "this shows we can not regard the expert s doubt as the complement ( with respect to 1 ) of his belief .",
    "thus , if we have to model what _ necessarily _ follows according to the expert s knowledge , then we must carry both the belief and the doubt explicitly . note that this example suggests just one possible means by which confidence levels could be obtained from statistical data . as discussed before",
    ", gaps in an expert s knowledge could often directly result in both belief and doubt . in general",
    ", there could be many ways in which both belief and doubt could be obtained and associated with the basic facts . given this",
    ", we believe that an independent treatment of both belief and doubt is both necessary and interesting for the purpose of obtaining the confidence levels associated with derived facts . our approach to independently capture belief and doubt makes it possible to cope with incomplete knowledge regarding the situations in which an event is true , false , or unknown in a general setting .",
    "kifer and li @xcite and baldwin @xcite have argued that incorporating both belief and doubt ( called disbelief there ) is useful in dealing with incomplete knowledge , where different evidences may contradict each other .",
    "however , in their frameworks , doubt need not be maintained explicitly .",
    "for suppose we have a belief @xmath38 and a disbelief @xmath39 associated with a phenomenon .",
    "then they can both be absorbed into one range @xmath40 $ ] indicating that the effective certainty ranges over this set .",
    "the difference with our framework , however , is that we model what is _ known _ definitely , as opposed to what is _",
    "possible_. this makes ( in our case ) an explicit treatment of belief and doubt mandatory .",
    "fitting @xcite has shown that _ bilattices _",
    "( introduced by ginsburg @xcite ) lead to an elegant framework for quantified logic programming involving both belief and doubt . in this section , we shall see that a notion of _ trilattices _ naturally arises with confidence levels .",
    "we shall establish the structure and properties of trilattices here , which will be used in later sections .",
    "[ conf - lattice ] denote by @xmath5 $ ] the set of all closed subintervals over @xmath6 $ ] .",
    "consider the set @xmath7 \\times { \\cal c}[0 , 1]$ ] .",
    "we denote the elements of @xmath8 as @xmath9,~ [ \\gamma,\\delta]\\rangle$}}$ ] .",
    "define the following orders on this set .",
    "let @xmath41,~ [ \\gamma_{1},\\delta_{1}]\\rangle$}}$ ] , @xmath42,~ [ \\gamma_{2},\\delta_{2}]\\rangle$}}$ ] be any two elements of @xmath8 .",
    "@xmath41,~ [ \\gamma_{1},\\delta_{1}]\\rangle$ } } \\leq_t { \\mbox{$\\langle[\\alpha_{2},\\beta_{2}],~ [ \\gamma_{2},\\delta_{2}]\\rangle$}}$ ]   iff   @xmath43 , @xmath44  and   @xmath45 , @xmath46 + @xmath41,~ [ \\gamma_{1},\\delta_{1}]\\rangle$ } } \\leq_k { \\mbox{$\\langle[\\alpha_{2},\\beta_{2}],~ [ \\gamma_{2},\\delta_{2}]\\rangle$}}$ ]  iff   @xmath43 , @xmath44  and   @xmath47 , @xmath48 + @xmath41,~ [ \\gamma_{1},\\delta_{1}]\\rangle$ } } \\leq_p { \\mbox{$\\langle[\\alpha_{2},\\beta_{2}],~ [ \\gamma_{2},\\delta_{2}]\\rangle$}}$ ]  iff   @xmath43 , @xmath49  and   @xmath47 , @xmath46    some explanation is in order .",
    "the order @xmath50 can be considered the _ truth _ ordering :  truth \" relative to the expert s knowledge increases as belief goes up and doubt comes down .",
    "the order @xmath51 is the _ knowledge _ ( or information ) ordering :  knowledge \" ( the extent to which the expert commits his opinion on an assertion ) increases as both belief and doubt increase .",
    "the order @xmath52 is the _ precision _ ordering :  precision \" of information supplied increases as the probability intervals become narrower .",
    "the first two orders are analogues of similar orders in bilattices .",
    "the third one , however , has no counterpart there .",
    "it is straightforward to see that each of the orders @xmath50 , @xmath51 , and @xmath52 is a partial order .",
    "@xmath8 has a least and a greatest element with respect to each of these orders . in the following ,",
    "we give the definition of meet and join with respect to the @xmath50 order .",
    "operators with respect to the other orders have a similar definition .",
    "[ meet - join ] let @xmath53 be as defined in definition [ conf - lattice ] .",
    "then the meet and join corresponding to the truth , knowledge ( information ) , and precision orders are defined as follows .",
    "the symbols  and  denote meet and join , and the subscripts @xmath54 , @xmath55 , and @xmath56 represent truth , knowledge , and precision , respectively .",
    "@xmath41,~ [ \\gamma_{1},\\delta_{1}]\\rangle$ } } { \\mbox { $ \\otimes_t$}}{\\mbox{$\\langle[\\alpha_{2},\\beta_{2}],~ [ \\gamma_{2},\\delta_{2}]\\rangle$}}~=~$ ]    @xmath57,$ ] @xmath58\\rangle$ ] .",
    "\\2 . @xmath41,~ [ \\gamma_{1},\\delta_{1}]\\rangle$ } } { \\mbox { $ \\oplus_t$}}{\\mbox{$\\langle[\\alpha_{2},\\beta_{2}],~ [ \\gamma_{2},\\delta_{2}]\\rangle$}}~=~$ ]    @xmath59 $ ] , @xmath60\\rangle$ ] .    \\3 . @xmath41,~ [ \\gamma_{1},\\delta_{1}]\\rangle$ } } { \\mbox { $ \\otimes_k$}}{\\mbox{$\\langle[\\alpha_{2},\\beta_{2}],~ [ \\gamma_{2},\\delta_{2}]\\rangle$}}~=~$ ]    @xmath61 $ ] , @xmath60\\rangle$ ] .",
    "\\4 . @xmath41,~ [ \\gamma_{1},\\delta_{1}]\\rangle$ } } { \\mbox { $ \\oplus_k$}}{\\mbox{$\\langle[\\alpha_{2},\\beta_{2}],~ [ \\gamma_{2},\\delta_{2}]\\rangle$}}~=~$ ]    @xmath62 $ ] , @xmath58\\rangle$ ] .    \\5 . @xmath41,~ [ \\gamma_{1},\\delta_{1}]\\rangle$ } } { \\mbox { $ \\otimes_p$}}{\\mbox{$\\langle[\\alpha_{2},\\beta_{2}],~ [ \\gamma_{2},\\delta_{2}]\\rangle$}}~=~$ ]    @xmath63 $ ] , @xmath64\\rangle$ ] .",
    "\\6 . @xmath41,~ [ \\gamma_{1},\\delta_{1}]\\rangle$ } } { \\mbox { $ \\oplus_p$}}{\\mbox{$\\langle[\\alpha_{2},\\beta_{2}],~ [ \\gamma_{2},\\delta_{2}]\\rangle$}}~=~$ ]    @xmath65 $ ] , @xmath66\\rangle$ ] .    the top and bottom elements with respect to the various orders are as follows .",
    "the subscripts indicate the associated orders , as usual .",
    "@xmath67 , [ 0 , 0]\\rangle$ ] ,  @xmath68 , [ 1 , 1]\\rangle$ ] , + @xmath69 , [ 1 , 1]\\rangle$ ] ,  @xmath70 , [ 0 , 0]\\rangle$ ] , + @xmath71 , [ 1 , 0]\\rangle$ ] ,  @xmath72 , [ 0 , 1]\\rangle$ ] .",
    "@xmath73 corresponds to total belief and no doubt ; @xmath74 is the opposite .",
    "@xmath75 represents maximal information ( total belief and doubt ) , to the point of being probabilistically inconsistent : belief and doubt probabilities sum to more than 1 ; @xmath76 gives the least information : no basis for belief or doubt ; @xmath77 is maximally precise , to the point of making the intervals empty ( and hence inconsistent , in a non - probabilistic sense ) ; @xmath78 is the least precise , as it imposes only trivial bounds on belief and doubt probabilities .",
    "fitting @xcite defines a bilattice to be _ interlaced _ whenever the meet and join with respect to any order of the bilattice are monotone with respect to the other order .",
    "he shows that it is the interlaced property of bilattices that makes them most useful and attractive .",
    "we say that a trilattice is _ interlaced _ provided the meet and join with respect to any order are monotone with respect to any other order .",
    "we have    [ lem : interlaced ] the trilattice @xmath53 defined above is interlaced .",
    "* proof . * follows directly from the fact that @xmath79 and @xmath80 are monotone functions .",
    "we show the proof for just one case .",
    "let @xmath41,~ [ \\gamma_{1},\\delta_{1}]\\rangle$ } } \\leq_p { \\mbox{$\\langle[\\alpha_{3},\\beta_{3}],~ [ \\gamma_{3},\\delta_{3}]\\rangle$}}$ ] and @xmath42,~ [ \\gamma_{2},\\delta_{2}]\\rangle$ } } \\leq_p { \\mbox{$\\langle[\\alpha_{4},\\beta_{4}],~ [ \\gamma_{4},\\delta_{4}]\\rangle$}}$ ] . then    @xmath41,~ [ \\gamma_{1},\\delta_{1}]\\rangle$ } } { \\mbox { $ \\otimes$}}_t { \\mbox{$\\langle[\\alpha_{2},\\beta_{2}],~ [ \\gamma_{2},\\delta_{2}]\\rangle$ } } = $ ]    @xmath81 , [ max\\{\\gamma_1 , \\gamma_2\\ } , max\\{\\delta_1 , \\delta_2\\}]\\rangle $ ]    @xmath82,~ [ \\gamma_{3},\\delta_{3}]\\rangle$ } } { \\mbox { $ \\otimes$}}_t { \\mbox{$\\langle[\\alpha_{4},\\beta_{4}],~ [ \\gamma_{4},\\delta_{4}]\\rangle$ } } = $ ]    @xmath83 , [ max\\{\\gamma_3 , \\gamma_4\\ } , max\\{\\delta_3 , \\delta_4\\}]\\rangle$ ]    since @xmath84",
    ", we have @xmath85 , and @xmath86 . similarly , @xmath87 and @xmath88 .",
    "this implies    @xmath89,~ [ \\gamma_{1},\\delta_{1}]\\rangle$ } } { \\mbox { $ \\otimes_t$}}{\\mbox{$\\langle[\\alpha_{2},\\beta_{2}],~ [ \\gamma_{2},\\delta_{2}]\\rangle$ } } \\leq_p { \\mbox{$\\langle[\\alpha_{3},\\beta_{3}],~ [ \\gamma_{3},\\delta_{3}]\\rangle$ } } { \\mbox { $ \\otimes_t$}}{\\mbox{$\\langle[\\alpha_{4},\\beta_{4}],~ [ \\gamma_{4},\\delta_{4}]\\rangle$}}\\ ] ]    other cases are similar .",
    "trilattices are of independent interest in their own right , from an algebraic point of view .",
    "we also stress that they can be used as a basis for developing quantified / annotated logic programming schemes ( which need not be probabilistic ) .",
    "this will be pursued in a future paper .    in closing this section",
    ", we note that other orders are also possible for confidence levels .",
    "in fact , fitting has shown that a fourth order , denoted by @xmath90 in the following , together with the three orders defined above , forms an interlaced `` quadri - lattice '' @xcite .",
    "he also pointed out that this `` quadri - lattice '' can be generated as the cross product of two bilattices .",
    "intuitively , a confidence level increases according to this fourth ordering , when the precision of the belief component of a confidence level goes up , while that of the doubt component goes down .",
    "that is ,    @xmath89,~ [ \\gamma_{1},\\delta_{1}]\\rangle$ } } \\leq_f { \\mbox{$\\langle[\\alpha_{2},\\beta_{2}],~ [ \\gamma_{2},\\delta_{2}]\\rangle$ } } \\mbox { iff } \\alpha_1 \\leq \\alpha_2 , \\beta_2 \\leq \\beta_1 \\mbox { and } \\gamma_2 \\leq \\gamma_1 , \\delta_1 \\leq \\delta_2\\ ] ]    in our opinion , the fourth order , while technically elegant , does not have the same intuitive appeal as the three orders  truth , knowledge , and precision  mentioned above . hence",
    ", we do not consider it further in this paper .",
    "the algebraic properties of confidence levels and their underlying lattices are interesting in their own right , and might be used for developing alternative bases for quantitative logic programming .",
    "this issue is orthogonal to the concerns of this paper .",
    "given the confidence levels for ( basic ) events , how are we to derive the confidence levels for compound events which are based on them ? since we are working with probabilities , our combination rules must respect probability theory .",
    "we need a model of our knowledge about the interaction between events . a simplistic model studied in the literature ( see barbara _ et al .",
    "@xcite ) assumes _ independence _ between all pairs of events .",
    "this is highly restrictive and is of limited applicability .",
    "a general model , studied by ng and subrahmanian @xcite is that of _ ignorance _ : assume no knowledge about event interaction .",
    "although this is the most general possible situation , it can be overly conservative when _ some _ knowledge is available , concerning some of the events .",
    "we argue that for  real - life \" applications , no single model of event interaction would suffice . indeed , we need the ability to  parameterize \" the model used for event interaction , depending on what _ is _ known about the events themselves . in this section ,",
    "we develop a probabilistic calculus which allows the user to select an appropriate  mode \" of event interaction , out of several choices , to suit his needs .",
    "let * l * be an arbitrary , but fixed , first - order language with finitely many constants , predicate symbols , infinitely many variables , and no function symbols .",
    "we use ( ground ) atoms of * l * to represent basic events .",
    "we blur the distinction between an event and the formula representing it .",
    "our objective is to characterize confidence levels of boolean combinations of events involving the connectives @xmath91 , in terms of the confidence levels of the underlying basic events under various modes ( see below ) .",
    "we gave an informal discussion of the meaning of confidence levels in section [ motiv ] .",
    "we use the concept of _ possible worlds _ to formalize the semantics of confidence levels .",
    "[ defn : semantics ] ( _ semantics of confidence levels _ ) according to the expert s knowledge , an event @xmath3 can be true , false , or unknown .",
    "this gives rise to 3 possible worlds .",
    "let @xmath92 respectively denote _ true _ , _ false _ , and _",
    "unknown_. let @xmath93 denote the world where the truth - value of @xmath3 is @xmath94 , @xmath95 , and let @xmath96 denote the probability of the world @xmath93 then the assertion that the confidence level of @xmath3 is @xmath9,~ [ \\gamma,\\delta]\\rangle$}}$ ] , written @xmath97,~ [ \\gamma,\\delta]\\rangle$}}$ ] , corresponds to the following constraints : @xmath98 where @xmath10 and @xmath11 are the lower and upper bounds of the _ belief _ in @xmath3 , and @xmath12 and @xmath13 are the lower and upper bounds of the _ doubt _ in @xmath3 .    equation ( [ eq : possibleworlds ] ) imposes certain restrictions on confidence levels .",
    "[ defn : consistentcf ] ( _ consistent confidence levels _ ) we say a confidence level @xmath9,~ [ \\gamma,\\delta]\\rangle$}}$ ] is _ consistent _ if equation ( [ eq : possibleworlds ] ) has an answer .",
    "it is easily seen that :    [ prop : consistentcf ] confidence level @xmath9,~ [ \\gamma,\\delta]\\rangle$}}$ ] is _ consistent _ provided _ ( i ) _ @xmath30 and @xmath31 , and _",
    "( ii ) _ @xmath99 .",
    "the consistency condition guarantees at least one solution to equation ( [ eq : possibleworlds ] ) .",
    "however , given a confidence level @xmath9,~ [ \\gamma,\\delta]\\rangle$}}$ ] , there may be @xmath100 values in the @xmath32 $ ] interval for which no @xmath101 value exists in the @xmath33 $ ] interval to form an answer to equation ( [ eq : possibleworlds ] ) , and vice versa .",
    "we can `` trim '' the upperbounds of @xmath9,~ [ \\gamma,\\delta]\\rangle$}}$ ] as follows to guarantee that for each value in the @xmath32 $ ] interval there is at least one value in the @xmath33 $ ] interval which form an answer to equation ( [ eq : possibleworlds ] ) .",
    "[ defn : reducedcf ] ( _ reduced confidence level _ ) we say a confidence level @xmath9,~ [ \\gamma,\\delta]\\rangle$}}$ ] is _ reduced _ if for all @xmath102 $ ] there exist @xmath101 , @xmath103 such that @xmath100 , @xmath101 , @xmath103 is a solution to equation ( [ eq : possibleworlds ] ) , and for all @xmath104 $ ] there exist @xmath100 , @xmath103 such that @xmath100 , @xmath101 , @xmath103 is a solution to equation ( [ eq : possibleworlds ] ) .",
    "it is obvious that a reduced confidence level is consistent .",
    "[ prop : reducedcf ] confidence level @xmath9,~ [ \\gamma,\\delta]\\rangle$}}$ ] is _ reduced _ provided _ ( i ) _ @xmath30 and @xmath31 , and _",
    "( ii ) _ @xmath105 , and @xmath106 .    [ prop : reduction ] let @xmath107,~ [ \\gamma,\\delta]\\rangle$}}$ ] be a consistent confidence level .",
    "let @xmath108 and @xmath109 .",
    "then , the confidence level @xmath110 , [ \\gamma , min(\\delta,\\delta')]$ ] is a reduced confidence level .",
    "further , @xmath111 and @xmath112 are probabilistically equivalent , in the sense that they produce exactly the same answer sets to equation ( [ eq : possibleworlds ] ) .",
    "data in a probabilistic deductive database , that is , facts and rules that comprise the database , are associated with confidence levels . at the atomic level",
    ", we require the confidence levels to be consistent .",
    "this means each expert , or data source , should be consistent with respect to the confidence levels it provides .",
    "this does not place any restriction on data provided by different experts / sources , as long as each is individually consistent .",
    "data provided by different experts / sources should be combined , using an appropriate combination mode ( discussed in next section ) .",
    "we will show that the combination formulas for the various modes preserve consistent as well as reduced confidence levels .",
    "now , we introduce the various modes and characterize conjunction and disjunction under these modes .",
    "let @xmath3 and @xmath113 represent two arbitrary ground ( variable - free ) formulas .",
    "for a formula @xmath3 , @xmath114 will denote its confidence level . in the following ,",
    "we describe several interesting and natural modes and establish some results on the confidence levels of conjunction and disjunction under these modes .",
    "some of the modes are well known , although care needs to be taken to allow for the 3-valued nature of our framework .    _",
    "ignorance : _ this is the most general situation possible : nothing is assumed / known about event interaction between @xmath3 and @xmath113 . the extent of the interaction between @xmath3 and @xmath113 could range from maximum overlap to minimum overlap .",
    "independence : _ this is a well - known mode . it simply says ( non-)occurrence of one event does not influence that of the other .",
    "positive correlation : _ this mode corresponds to the knowledge that the occurrences of two events overlap as much as possible .",
    "this means the conditional probability of one of the events ( the one with the larger probability ) given the other is 1 .",
    "negative correlation : _ this is the exact opposite of positive correlation : the occurrences of the events overlap minimally .",
    "mutual exclusion : _ this is a special case of negative correlation , where we know that the sum of probabilities of the events does not exceed 1 .",
    "we have the following results .",
    "let @xmath3 be any event , and let @xmath97,~ [ \\gamma,\\delta]\\rangle$}}$ ] .",
    "then @xmath115,~[\\alpha , \\beta]\\rangle$ ] .",
    "thus , negation simply swaps belief and doubt .",
    "* follows from the observation that @xmath97,~ [ \\gamma,\\delta]\\rangle$}}$ ] implies that @xmath116 and @xmath117 , where @xmath100 ( @xmath101 ) denotes the probability of the possible world where event @xmath3 is _ true _ ( _ false _ ) .    the following theorem establishes the confidence levels of compound formulas as a function of those of the constituent formulas , under various modes .",
    "[ thm : combinations ] let @xmath3 and @xmath113 be any events and let @xmath118,~ [ \\gamma_{1},\\delta_{1}]\\rangle$}}$ ] and @xmath119,~ [ \\gamma_{2},\\delta_{2}]\\rangle$}}$ ] .",
    "then the confidence levels of the compound events @xmath120 and @xmath121 are given as follows .",
    "( in each case the subscript denotes the mode . )",
    "@xmath122    @xmath123,$ ] @xmath124 , @xmath125 @xmath126\\rangle$ ] .",
    "@xmath127 ,   [ max\\{0 , \\gamma_1 + \\gamma_2 -1\\}$ ] , @xmath128\\rangle$ ] .",
    "@xmath129 , [ 1 - ( 1 - \\gamma_1 ) \\times ( 1 - \\gamma_2 ) ,   1 - ( 1 - \\delta_1 ) \\times ( 1 - \\delta_2)]\\rangle$ ] .",
    "@xmath130 , [ \\gamma_1 \\times \\gamma_2 , \\delta_1 \\times \\delta_2]\\rangle$ ] .",
    "@xmath131 ,   [ max\\{\\gamma_1 , \\gamma_2\\ } , max\\{\\delta_1 , \\delta_2\\}]\\rangle$ ] .",
    "@xmath132 ,   [ min\\{\\gamma_1 , \\gamma_2\\ } , min\\{\\delta_1 , \\delta_2\\}]\\rangle$ ] .",
    "@xmath133    @xmath134 ,   [ min\\{1 , \\gamma_1 + \\gamma_2\\ } , min\\{1 , \\delta_1 + \\delta_2\\}]\\rangle$ ] .",
    "@xmath135    @xmath136 , [ max\\{0 , \\gamma_1 + \\gamma_2 - 1\\ } , max\\{0 , \\delta_1 + \\delta_2 - 1\\}]\\rangle$ ] .",
    "@xmath137 , [ min\\{1 , \\gamma_1+\\gamma_2\\ } , min\\{1 , \\delta_1+\\delta_2\\}]\\rangle$ ] .",
    "@xmath138 ,   [ max\\{0 , \\gamma_1 + \\gamma_2 - 1\\ } , max\\{0 , \\delta_1 + \\delta_2 - 1\\}]\\rangle$ ] .",
    "* proof . *",
    "each mode is characterized by a system of constraints , and the confidence level of the formulas @xmath139 are obtained by extremizing certain objective functions subject to these constraints .",
    "the scope of the possible interaction between @xmath3 and @xmath113 can be characterized as follows ( also see @xcite ) . according to the expert s knowledge ,",
    "each of @xmath140 can be true , false , or unknown .",
    "this gives rise to 9 possible worlds .",
    "let @xmath92 respectively denote _ true _ , _ false _ , and _",
    "unknown_. let @xmath141 denote the world where the truth - value of @xmath3 is @xmath94 and that of @xmath113 is @xmath142 , @xmath143 .",
    ", @xmath144 is the world where @xmath3 is true and @xmath113 is false , while @xmath145 is the world where @xmath3 is false and @xmath113 is unknown .",
    "suppose @xmath146 denotes the probability associated with world @xmath141 .",
    "then the possible scope of interaction between @xmath3 and @xmath113 can be characterized by the following constraints .",
    "@xmath147    the above system of constraints must be satisfied for all modes .",
    "specific constraints for various modes are obtained by adding more constraints to those in equation ( [ ign - eq ] ) . in all cases ,",
    "the confidence levels for @xmath148 and @xmath149 are obtained as follows . @xmath150,\\\\                 &    & [ min(\\sigma_{{\\mbox { $ w_{ij}$}}\\not \\models f\\circ g } { \\mbox { $ w_{ij}$ } } ) ,                        max(\\sigma_{{\\mbox { $ w_{ij}$}}\\not \\models f\\circ g } { \\mbox { $ w_{ij}$}})]\\rangle\\end{aligned}\\ ] ] where @xmath151 is @xmath152 or @xmath153 .    : _",
    "ignorance_.    the constraints for ignorance are exactly those in equation ( [ ign - eq ] ) .",
    "the solution to the above linear program can be shown to be    @xmath154,$ ] @xmath124 , @xmath125 @xmath126\\rangle$ ] , @xmath155 ,   [ max\\{0 , \\gamma_1 + \\gamma_2 -1\\}$ ] , @xmath128\\rangle$ ] .",
    "the proof is very similar to the proof of a similar result in the context of belief intervals ( no doubt ) by ng and subrahmanian @xcite .    : _",
    "independence_.    independence of events @xmath3 and @xmath113 can be characterized by the equation @xmath156 , where @xmath157 is the conditional probability of the event @xmath3 given event @xmath113 .",
    "more specifically , since in our model an event can be _ true _ , _ false _ , or _ unknown _ , ( in other words , we model belief and doubt independently ) we have : @xmath158 then the constraints characterizing independence is obtained by adding the following equations to the system of constraints ( [ ign - eq ] ) .",
    "@xmath159 the belief in @xmath160 , and doubt in @xmath161 can be easily verified from the system of constraints [ ign - eq ] and [ ind - eq ] @xmath162 to obtain the doubt in @xmath160 we need to compute the minimum and maximum of @xmath163 .",
    "it is easy to verify that : @xmath164 the belief in @xmath161 is obtained similarly ( in the dual manner . )",
    "thus , we have verified that    @xmath129 , [ 1 - ( 1 - \\gamma_1 ) \\times ( 1 - \\gamma_2 ) ,   1 - ( 1 - \\delta_1 ) \\times ( 1 - \\delta_2)]\\rangle$ ] .",
    "+ @xmath130 , [ \\gamma_1 \\times \\gamma_2 , \\delta_1 \\times \\delta_2]\\rangle$ ] .    : _ positive correlation _ :    two events @xmath3 and @xmath113 are positively correlated if they overlap as much as possible .",
    "this happens when either ( _ i _ ) occurrence of @xmath3 implies occurrence of @xmath113 , or ( _ ii _ ) occurrence of @xmath113 implies occurrence of @xmath3 . in our framework",
    "we model belief and doubt independently , and positive correlation is characterized by 4 possibilities :    \\(a ) occurrence of @xmath3 implies occurrence of @xmath113 , and non - occurrence of @xmath113 implies non - occurrence of @xmath3 .",
    "+ ( b ) occurrence of @xmath3 implies occurrence of @xmath113 , and non - occurrence of @xmath3 implies non - occurrence of @xmath113 .",
    "+ ( c ) occurrence of @xmath113 implies occurrence of @xmath3 , and non - occurrence of @xmath113 implies non - occurrence of @xmath3 .",
    "+ ( d ) occurrence of @xmath113 implies occurrence of @xmath3 , and non - occurrence of @xmath3 implies non - occurrence of @xmath113 .",
    "each of these four condition sets generates its own equations . for example , ( a ) can be captured by adding the following equations to the system of constraints [ ign - eq ] .",
    "@xmath165    hence , for condition ( a ) , the system of constraints [ ign - eq ] becomes    @xmath166    the analysis is further complicated by the fact that the confidence levels of @xmath3 and @xmath113 determine which of these cases apply , and it may be different for the lowerbound and upperbound probabilities .",
    "for example , if @xmath167 ( @xmath168 ) , then the lowerbound ( upperbound ) for belief in @xmath169 is obtained when occurrence of @xmath3 implies occurrence of @xmath113 .",
    "otherwise , these bounds are obtained when occurrence of @xmath113 implies occurrence of @xmath3 .",
    "the solution to these linear programs can be shown to be    @xmath170 ,   [ max\\{\\gamma_1 , \\gamma_2\\ } , max\\{\\delta_1 , \\delta_2\\}]\\rangle$ ] , and + @xmath132 ,   [ min\\{\\gamma_1 , \\gamma_2\\ } , min\\{\\delta_1 , \\delta_2\\}]\\rangle$ ] .",
    "a more intuitive approach to the derivation of confidence levels for conjunction and disjunction of positively correlated events is to rely on the observation that these events overlap to the maximum extent possible . in our framework",
    "it means the worlds where @xmath3 is _ true _ and those where @xmath113 is _ true _ overlap maximally , and hence , one is included in the other .",
    "similarly , since we model belief and doubt independently , the worlds where @xmath3 is _ false _ and those where @xmath113 is _ false _ also overlap maximally .",
    "the combination formulas can be derived directly using these observations .    : _ negative correlation _ :",
    "negative correlation is an appropriate mode to use whenever we know that events @xmath3 and @xmath113 overlap as little as possible .",
    "this is to be contrasted with positive correlation , where the extent of overlap is the greatest possible .",
    "mutual exclusion , is a special case of negative correlation where the sum of the probabilities of the two events does not exceed 1 . in this case",
    "the two events do not overlap at all .    in the classical framework , mutual exclusion of two events @xmath3 and @xmath113",
    "is characterized by the statement : ( _ i _ ) occurrence of @xmath3 implies non - occurrence of @xmath113 , and vice versa . on the other hand ,",
    "if the two events @xmath3 and @xmath113 are negatively correlated but not mutually exclusive , we have : ( _ ii _ ) non - occurrence of @xmath3 implies occurrence of @xmath113 , and vice versa . in case ( _ i _ ) the sum of the probabilities of the two events is at most 1 , while in case ( _ ii _ )",
    "this sum exceeds 1 and hence the two events can not be mutually exclusive . in our framework",
    "we model belief and doubt independently , and each of the above conditions translates to two conditions as follows .",
    "note that in our framework , `` not _ true _ '' means `` _ false _ or _ unknown _ '' , and `` not _ false _ '' means `` _ true _ or _ unknown _ '' .",
    "* event @xmath3 is _ true _ implies @xmath113 is not _ true _ , and vice versa .",
    "this condition generates the equation @xmath171 . *",
    "the dual of condition ( a ) , when the non - occurrence of the two events do nt overlap .",
    "event @xmath3 is _ false _ implies @xmath113 is not _",
    "false _ , and vice versa .",
    "this condition generates the equation @xmath172 .",
    "* event @xmath3 is not _ true _ implies @xmath113 is _ true _ , and vice versa .",
    "this condition generates the equations @xmath173 , @xmath174 , @xmath175 , and @xmath176 . *",
    "the dual of ( _ c _ ) , @xmath3 is not _",
    "_ implies @xmath113 is _ false _ , and vice versa , which generates the equations @xmath177 , @xmath178 , @xmath179 , and @xmath176 .",
    "similar to the case for positive correlation , the confidence levels of @xmath3 and @xmath113 determine which of these cases apply .",
    "for example , if @xmath180 , then case ( c ) should be used to determine the lowerbound for belief in @xmath181 .",
    "alternatively , and more intuitively , we can characterize negative correlation by observing that the worlds where @xmath3 is _ true _ and those where @xmath113 is _ true _ overlap minimally , and the worlds where @xmath3 is _ false _ and those where @xmath113 is _ false _ also overlap minimally .",
    "the confidences of @xmath148 and @xmath121 can be obtained using the equations , or directly from the alternative characterization :    @xmath133    @xmath134 ,   [ min\\{1 , \\gamma_1 + \\gamma_2\\ } , min\\{1 , \\delta_1 + \\delta_2\\}]\\rangle$ ]    @xmath135    @xmath136 , [ max\\{0 , \\gamma_1 + \\gamma_2 - 1\\ } , max\\{0 , \\delta_1 + \\delta_2 - 1\\}]\\rangle$ ]    : _ mutual exclusion _ :    mutual exclusion is a special case of negative correlation .",
    "the main difference is that it requires the sum of the two probabilities to be at most 1 , which is not necessarily the case for negative correlation ( see the previous case ) . in the classical framework ,",
    "if two events are mutually exclusive , their negation are not necessarily mutually exclusive .",
    "rather , they are negatively correlated . in our framework , however , one or both conditions ( _ a _ ) and ( _ b _ ) , discussed in the previous case , can hold .",
    "the appropriate condition is determined by the confidence levels of the two mutually exclusive events , and the corresponding combination formula can be obtained from the combination formulas of negative correlation .",
    "the following formulas , for example , are for mutually exclusive events @xmath3 and @xmath113 where @xmath182 ( but no other restriction ) .",
    "@xmath137 , [ min\\{1 , \\gamma_1+\\gamma_2\\ } , min\\{1 , \\delta_1+\\delta_2\\}]\\rangle$ ] . + @xmath138 ,   [ max\\{0 , \\gamma_1 + \\gamma_2 - 1\\ } , max\\{0 , \\delta_1 + \\delta_2 - 1\\}]\\rangle$ ] .    next , we show that the combination formulas for various modes preserve consistent as well as reduced confidence levels . the case for reduced confidence levels",
    "is more involved and will be presented first .",
    "the other case is similar , for which we only state the theorem .",
    "[ thm : reduced ] suppose @xmath3 and @xmath113 are any formulas and assume their confidence levels are reduced ( definition [ defn : reducedcf ] ) .",
    "then the confidence levels of the formulas @xmath148 and @xmath121 , obtained under the various modes above are all reduced .",
    "* let @xmath118,~ [ \\gamma_{1},\\delta_{1}]\\rangle$}}$ ] and @xmath119,~ [ \\gamma_{2},\\delta_{2}]\\rangle$}}$ ] .",
    "since the confidence levels of @xmath3 and @xmath113 are reduced , we have :    @xmath183 + @xmath184 + @xmath185 + @xmath186 + the consistency of the confidence levels of the combination events @xmath148 and @xmath121 in different modes as derived in theorem [ thm : combinations ] follow from the above constraints . for example",
    "let us consider    @xmath187 ,   [ max\\{\\gamma_1 , \\gamma_2\\ } , min\\{1 , \\delta_1 + \\delta_2\\}]\\rangle\\ ] ] we need to show    \\(1 ) @xmath188 + ( 2 ) @xmath189 + ( 3 ) @xmath190 + ( 4 ) @xmath191    to prove ( 1 ) : if @xmath192 then ( 1 ) holds",
    ". otherwise , assume , without loss of generality , that @xmath193 .",
    "we can write    @xmath194 + @xmath195    and hence    @xmath196    and ( 1 ) follows .",
    "inequality ( 2 ) follows easily from @xmath197 .    to prove ( 3 ) : if @xmath192 then ( 3 ) holds .",
    "otherwise , we can write    @xmath198 + @xmath199    and hence    @xmath200    and ( 3 ) follows . note that if @xmath201 then @xmath202 follows from the above constraint .    to prove ( 4 ) let @xmath203 and @xmath204 where @xmath205 . then @xmath206 .",
    "proving the consistency of the confidence levels of other combinations and other modes are similar and will not be elaborated here .",
    "[ thm : consistent ] suppose @xmath3 and @xmath113 are any formulas and assume their confidence levels are consistent ( definition [ defn : consistentcf ] ) .",
    "then the confidence levels of the formulas @xmath148 and @xmath121 , obtained under the various modes above are all consistent .",
    "* proof is similar to the previous theorem and is omitted .",
    "in this section , we develop a framework for probabilistic deductive databases using a language of probabilistic programs ( p - programs ) .",
    "we make use of the probabilistic calculus developed in section [ prob - calc ] and develop the syntax and declarative semantics for programming with confidence levels .",
    "we also provide the fixpoint semantics of programs in this framework and establish its equivalence to the declarative semantics .",
    "we will use the first - order language * l * of section [ prob - calc ] as the underlying logical language in this section .",
    "* syntax of p - programs : * a _ rule _ is an expression of the form @xmath207 , @xmath208 , where @xmath209 are atoms and @xmath210,~ [ \\gamma,\\delta]\\rangle$}}$ ] is the confidence level associated with the rule ) . ] .",
    "when @xmath211 , we call this a _ fact_. all variables in the rule are assumed to be universally quantified outside the whole rule , as usual . we restrict attention to range restricted rules , as is customary .",
    "a _ probabilistic rule _",
    "( p - rule ) is a triple @xmath212 , where @xmath213 is a rule , @xmath214 is a mode indicating how to conjoin the confidence levels of the subgoals in the body of @xmath213 ( and with that of @xmath213 itself ) , and @xmath215 is a mode indicating how the confidence levels of different derivations of an atom involving the head predicate of @xmath213 are to be disjoined .",
    "we say @xmath214 ( @xmath216 is the mode associated with the body ( head ) of @xmath213 , and call it the _ conjunctive _ ( _ disjunctive _ ) mode .",
    "we refer to @xmath213 as the underlying rule of this p - rule .",
    "when @xmath213 is a fact , we omit @xmath214 for obvious reasons .",
    "a _ probabilistic program _",
    "( p - program ) is a finite collection of p - rules such that whenever there are p - rules whose underlying rules define the same predicate , the mode associated with their head is identical .",
    "this last condition ensures different rules defining the same predicate @xmath217 agree on the manner in which confidences of identical @xmath217-atoms generated by these rules are to be combined .",
    "the notions of herbrand universe @xmath218 and herbrand base @xmath219 associated with a p - program @xmath16 are defined as usual .",
    "a p - rule is ground exactly when every atom in it is ground .",
    "the herbrand instantiation @xmath220 of a p - program is defined in the obvious manner .",
    "the following example illustrates our framework .",
    "[ medical - ex ] people are assessed to be at high risk for various diseases , depending on factors such as age group , family history ( with respect to the disease ) , etc .",
    "accordingly , high risk patients are administered appropriate medications , which are prescribed by doctors among several alternative ones .",
    "medications cause side effects , sometimes harmful ones , leading to other symptoms and diseases . here , the extent of risk , administration of medications , side effects ( caused by medications ) , and prognosis are all uncertain phenomena , and we associate confidence levels with them . the following program is a sample of the uncertain knowledge related to these phenomena .",
    "@xmath221-@xmath222 @xmath223 , [ 0.1,0.1]\\rangle}}{{\\mbox{$<\\hspace*{-9pt } \\rule[2pt]{80pt}{0.5pt}$ } } } $ } } $ ] @xmath224 , @xmath225-@xmath226 @xmath227 .",
    "@xmath228 @xmath229 , [ 0,0]\\rangle}}{{\\mbox{$<\\hspace*{-9pt } \\rule[2pt]{80pt}{0.5pt}$ } } } $ } } $ ] @xmath230-@xmath222 , @xmath231 @xmath232 .",
    "@xmath233 @xmath234 , [ 0.12,0.12]\\rangle}}{{\\mbox{$<\\hspace*{-9pt } \\rule[2pt]{80pt}{0.5pt}$ } } } $ } } $ ] @xmath230-@xmath235 .",
    "@xmath233 @xmath236 , [ 0.70,0.70]\\rangle}}{{\\mbox{$<\\hspace*{-9pt } \\rule[2pt]{80pt}{0.5pt}$ } } } $ } } $ ] @xmath237 , @xmath238-@xmath239 @xmath240 .",
    "we can assume an appropriate set of facts ( the edb ) in conjunction with the above program .",
    "for rule 1 , it is easy to see that each ground atom involving the predicate @xmath230-@xmath241 has at most one derivation . thus , a disjunctive mode for this rule will be clearly redundant , and we have suppressed it for convenience .",
    "a similar remark holds for rule 2 .",
    "rule 1 says that if a person is midaged and the disease @xmath242 has struck his ancestors , then the confidence level in the person being at high risk for @xmath242 is given by propagating the confidence levels of the body subgoals and combining them with the rule confidence in the sense of @xmath243 .",
    "this could be based on an expert s belief that the factors @xmath244 and @xmath225-@xmath245 contributing to high risk for the disease are independent .",
    "each of the other rules has a similar explanation .",
    "for the last rule , we note that the potential of a medication to cause side effects is an intrinsic property independent of whether one takes the medication .",
    "thus the conjunctive mode used there is independence .",
    "finally , note that rules 3 and 4 , defining @xmath246 , use positive correlation as a conservative way of combining confidences obtained from different derivations . for simplicity , we show each interval in the above rules as a point probability .",
    "still , note that the confidences for atoms derived from the program will be genuine intervals .",
    "* a valuation based semantics : * we develop the declarative semantics of p - programs based on the notion of valuations .",
    "let @xmath16 be a p - program .",
    "probabilistic valuation _ is a function @xmath247 which associates a confidence level with each ground atom in @xmath219 .",
    "we define the satisfaction of p - programs under valuations , with respect to the truth order @xmath50 of the trilattice ( see section [ prob - calc ] ) .",
    "we say a valuation @xmath248 _ satisfies _ a ground p - rule @xmath249 , denoted @xmath250 , provided @xmath251 @xmath252 .",
    "the intended meaning is that in order to satisfy this p - rule , @xmath248 must assign a confidence level to @xmath253 that is no less true ( in the sense of @xmath50 ) than the result of the conjunction of the confidences assigned to @xmath254 s by @xmath248 and the rule confidence @xmath111 , in the sense of the mode @xmath214 .",
    "even when a valuation satisfies ( all ground instances of ) each rule in a p - program , it may not satisfy the p - program as a whole .",
    "the reason is that confidences coming from different derivations of atoms are combined strengthening the overall confidence .",
    "thus , we need to impose the following additional requirement .",
    "let @xmath255 be a ground p - rule , and @xmath248 a valuation .",
    "then we denote by @xmath256-@xmath257 the confidence level propagated to the head of this rule under the valuation @xmath248 and the rule mode @xmath214 , given by the expression @xmath258 .",
    "let @xmath259 be the partition of @xmath220 such that ( i ) each @xmath260 contains all ( ground ) p - rules which define the same atom , say @xmath261 , and ( ii ) @xmath261 and @xmath262 are distinct , whenever @xmath263 .",
    "suppose @xmath264 is the mode associated with the head of the p - rules in @xmath260 .",
    "we denote by @xmath265-@xmath266 the confidence level determined for the atom @xmath261 under the valuation @xmath248 using the program @xmath16 .",
    "this is given by the expression @xmath267-@xmath268 .",
    "we now define satisfaction of p - programs .",
    "[ def : satisfaction ] let @xmath16 be a p - program and @xmath248 a valuation .",
    "then @xmath248 satisfies @xmath16 , denoted @xmath269 exactly when @xmath248 satisfies each ( ground ) p - rule in @xmath220 , and for all atoms @xmath270 , @xmath265-@xmath271 .",
    "the additional requirement ensures the valuation assigns a strong enough confidence to each atom so it will support the combination of confidences coming from a number of rules ( pertaining to this atom ) .",
    "a p - program @xmath16 logically implies a p - fact @xmath272 , denoted @xmath273 , provided every valuation satisfying @xmath16 also satisfies @xmath272 .",
    "we next have    let @xmath248 be a valuation and @xmath16 a p - program .",
    "suppose the mode associated with the head of each p - rule in @xmath16 is positive correlation .",
    "then @xmath269 iff @xmath248 satisfies each rule in @xmath220 .",
    "* proof*. we shall show that if @xmath256-@xmath274 for all rules @xmath275 defining a ground atom @xmath253 , then @xmath265-@xmath271 , where the disjunctive mode for @xmath253 is positive correlation .",
    "this follows from the formula for @xmath276 , obtained in theorem [ thm : combinations ] .",
    "it is easy to see that @xmath277 .",
    "but then , @xmath256-@xmath274 implies that @xmath278-@xmath279 and hence @xmath265-@xmath271 .",
    "the above proposition shows that when positive correlation is the only disjunctive mode used , satisfaction is very similar to the classical case .    for the declarative semantics of p - programs ,",
    "we need something like the  least \" valuation satisfying the program .",
    "it is straightforward to show that the class of all valuations @xmath280 from @xmath219 to @xmath8 itself forms a trilattice , complete with all the 3 orders and the associated meets and joins .",
    "they are obtained by a pointwise extension of the corresponding order / operation on the trilattice @xmath8 .",
    "we give one example . for valuations",
    "@xmath281 , @xmath282 iff @xmath283 , @xmath284 ; @xmath283 , @xmath285 .",
    "one could investigate  least \" with respect to each of the 3 orders of the trilattice . in this paper",
    ", we confine attention to the order @xmath50 .",
    "the least ( greatest ) valuation is then the valuation * false * ( * true * ) which assigns the confidence level @xmath74 ( @xmath73 ) to every ground atom .",
    "we now have    [ lem : lvaluation ] let @xmath16 be any p - program and @xmath281 be any valuations satisfying @xmath16 .",
    "then @xmath286 is also a valuation satisfying @xmath16 .",
    "in particular , @xmath287 is the least valuation satisfying @xmath16 .    *",
    "* we prove this in two steps .",
    "first , we show that for any ground p - rule + @xmath255 + whenever valuations @xmath288 and @xmath248 satisfy @xmath289 , so does @xmath286 .",
    "secondly , we shall show that for a p - program @xmath16 , whenever _ atom - conf_@xmath290 and _ atom - conf_@xmath291 , then we also have _ atom - conf_@xmath292 .",
    "the lemma will follow from this .",
    "\\(1 ) suppose @xmath293 and @xmath294 .",
    "we prove the case where the conjunctive mode @xmath214 associated with this rule is ignorance .",
    "the other cases are similar .",
    "it is straightforward to verify the following .",
    "\\(i ) @xmath295 .",
    "+ ( ii ) @xmath296 .    from ( i ) and",
    "( ii ) , we have @xmath297 , showing @xmath298 .",
    "\\(2 ) suppose @xmath281 are any two valuations satisfying a p - program @xmath16 .",
    "let @xmath299 be the set of all ground p - rules in @xmath220 whose heads are @xmath253 .",
    "let @xmath300 _ rule - conf_@xmath301 and @xmath302 _ rule - conf_@xmath303 .",
    "since @xmath304 and @xmath305 , we have that @xmath306 and @xmath307 , where @xmath215 is the disjunctive mode associated with @xmath253 .",
    "again , we give the proof for the case @xmath215 is ignorance as the other cases are similar .",
    "let @xmath308 _ rule - conf_@xmath309 .",
    "clearly , @xmath310 and @xmath311 .",
    "thus , @xmath312 and @xmath313 .",
    "it then follows that @xmath314 , which was to be shown .",
    "we take the least valuation satisfying a p - program as characterizing its declarative semantics .",
    "consider the following p - program @xmath16 .",
    "@xmath315,~[0.3,0.45]\\rangle}}{{\\mbox{$<\\hspace*{-9pt } \\rule[2pt]{80pt}{0.5pt}$ } } } $ } } ~b;~~ind,~pc)$ ] .",
    "@xmath316,~[0.1,0.2]\\rangle}}{{\\mbox{$<\\hspace*{-9pt } \\rule[2pt]{80pt}{0.5pt}$ } } } $ } } ~c;~~ign,~pc)$ ] . + 3 .",
    "@xmath317,~[0,0.1]\\rangle}}{{\\mbox{$<\\hspace*{-9pt } \\rule[2pt]{80pt}{0.5pt}$ } } } $ } } ; ~~\\_,~ind)$ ] .   4 .",
    "@xmath318,~[0.1,0.2]\\rangle}}{{\\mbox{$<\\hspace*{-9pt } \\rule[2pt]{80pt}{0.5pt}$ } } } $ } } ; ~~\\_,~ind)$ ] .    in the following",
    "we show three valuations @xmath319 , of which @xmath320 and @xmath321 satisfy @xmath16 , while @xmath322 does not .",
    "in fact , @xmath321 is the least valuation satisfying @xmath16 .",
    "@xmath323,~[0,0]\\rangle & \\langle[0.8,0.9],~[0.05,0.1]\\rangle &                   \\langle[0.5,0.9],~[0,0]\\rangle \\\\ v_2 & \\langle[0.9,1],~[0,0]\\rangle & \\langle[0.9,1],~[0,0]\\rangle &                   \\langle[0.5,0.7],~[0.1,0.4]\\rangle \\\\",
    "v_3 & \\langle[0.9,0.95],~[0,0.1]\\rangle & \\langle[0.7,0.8],~[0.1,0.2]\\rangle               &    \\langle[0.45,0.8],~[0.1,0.4]\\rangle \\end{array}$ ]    for example , consider @xmath320 .",
    "it is easy to verify that @xmath320 satisfies @xmath16 .",
    "rules 1 through 4 are satisfied by @xmath320 since :    @xmath324,~[0.3,0.45]\\rangle \\wedge_{ind }   \\langle[0.9,1],~[0,0]\\rangle =   \\langle[0.45,0.7],~[0,0]\\rangle \\le_t   \\langle[0.5,0.9],~[0,0]\\rangle$ ]    @xmath325,~[0.1,0.2]\\rangle \\wedge_{ign }   \\langle[0.8,0.9],~[0.05,0.1]\\rangle = $ ]    @xmath326,~[0.1,0.3]\\rangle \\le_t   \\langle[0.5,0.9],~[0,0]\\rangle$ ]    @xmath327,~[0,0.1]\\rangle \\le_t \\langle[0.9,1],~[0,0]\\rangle$ ]    @xmath328,~[0.1,0.2]\\rangle \\le_t \\langle[0.8,0.9],~[0.05,0.1]\\rangle$ ]    further , the confidence level of @xmath253 computed by the combination of rules 1 and 2 is also satisfied by @xmath320 , namely ,    @xmath329,~[0.3,0.45]\\rangle \\wedge_{ind }     \\langle[0.9,1],~[0,0]\\rangle )         \\vee_{pc }   ( \\langle[0.6,0.8],~[0.1,0.2]\\rangle$ ]    @xmath330,~[0.05,0.1]\\rangle ) =      \\langle[0.45,0.8],~[0,0 ] \\le_t     \\langle[0.5,0.9],~[0,0]\\rangle$ ]    * fixpoint semantics : * we associate an  immediate consequence \" operator @xmath1 with a p - program @xmath16 , defined as follows .",
    "[ tp - defn ] let @xmath16 be a p - program and @xmath220 its herbrand instantiation .",
    "then @xmath1 is a function @xmath331 , defined as follows .",
    "for any probabilistic valuation @xmath248 , and any ground atom @xmath270 , @xmath332 there exists a p - rule @xmath333 such that @xmath334 .    call a valuation @xmath248 _ consistent _ provided for every atom @xmath253 , @xmath335 is consistent , as defined in section [ lattice ] .",
    "[ thm : tpmonotone ] ( 1 ) @xmath1 always maps consistent valuations to consistent valuations .",
    "( 2 ) @xmath1 is monotone and continuous .",
    "* proof . *",
    "( 1 ) this fact follows theorem [ thm : consistent ] , where we have shown that the combination functions for all modes map consistent confidence levels to consistent confidence levels . ( 2 ) this follows from the fact that the combination functions for all modes are themselves monotone and continuous .",
    "we define bottom - up iterations based on @xmath1 in the usual manner .",
    "+ @xmath336 ( which assigns the truth - value @xmath74 to every ground atom ) .",
    "+ @xmath337 , for a successor ordinal @xmath10 .",
    "+ @xmath338 , for a limit ordinal @xmath10 .",
    "we have the following results .    [ prop : fixpoint ] let @xmath248 be any valuation and @xmath16 be a p - program",
    ". then @xmath248 satisfies @xmath16 iff @xmath339 .",
    "* proof . * _ ( only if ) .",
    "_ if @xmath248 satisfies @xmath16 , then by definition [ def : satisfaction ] , for all atoms @xmath270 , @xmath265-@xmath271 and hence @xmath339 .    _",
    "_ if @xmath339 , then by the definition of @xmath1 ( definition [ tp - defn ] ) for all atoms @xmath270 , @xmath265-@xmath271 and hence @xmath248 satisfies @xmath16 .",
    "the following theorem is the analogue of the van emden - kowalski theorem for classical logic programming .",
    "[ thm : lfplvaluation ] let @xmath16 be a p - program . then the following claims hold",
    ". + ( i ) @xmath340 the @xmath50-least valuation satisfying @xmath16 .",
    "+ ( ii ) for a ground atom @xmath253 , @xmath341 iff @xmath273 .    *",
    "* follows lemma [ lem : lvaluation ] , theorem [ thm : tpmonotone ] and proposition [ prop : fixpoint ] .",
    "proof is similar to the analogous theorem of logic programming and details are omitted .",
    "since confidences coming from different derivations of a fact are combined , we need a notion of disjunctive proof - trees .",
    "we note that the notions of substitution , unification , etc .",
    "are analogous to the classical ones .",
    "a variable appearing in a rule is _ local _ if it only appears in its body .",
    "[ dpt ] let @xmath113 be a(n atomic ) goal and @xmath16 a p - program .",
    "then a _ disjunctive proof - tree _ ( dpt ) for @xmath113 with respect to @xmath16 is a tree @xmath342 defined as follows .",
    "@xmath342 has two kinds of nodes : _ rule _ nodes and _ goal _ nodes .",
    "each rule node is labeled by a rule in @xmath16 and a substitution .",
    "each goal node is labeled by an atomic goal .",
    "the root is a goal node labeled @xmath113 .",
    "let @xmath288 be a goal node labeled by an atom @xmath253 . then",
    "every child ( if any ) of @xmath288 is a rule node labeled @xmath343 , where @xmath213 is a rule in @xmath16 whose head is unifiable with @xmath253 using the mgu @xmath344 .",
    "we assume that each time a rule @xmath213 appears in the tree , its variables are renamed to new variables that do not appear anywhere else in the tree .",
    "hence @xmath213 in the label @xmath343 actually represents a renamed instance of the rule .",
    "if @xmath288 is a rule node labeled @xmath343 , then whenever an atom @xmath345 occurs in the body of @xmath346 , @xmath288 has a goal child @xmath248 labeled @xmath345 .",
    "+ 4 . for any two substitutions",
    "@xmath347 occurring in @xmath342 , @xmath348 , for every variable @xmath349 . in other words ,",
    "all substitutions occurring in @xmath342 are compatible .    a node without children",
    "is called a leaf .",
    "a _ proper _ dpt is a finite dpt @xmath342 such that whenever @xmath342 has a goal leaf labeled @xmath253 , there is no rule in @xmath16 whose head is unifiable with @xmath253 .",
    "we only consider proper dpts unless otherwise specified .",
    "a rule leaf is a _",
    "node ( represents a database fact ) while a goal leaf is a _ failure _ node .",
    "* remarks : *    \\(1 ) the definition of disjunctive proof tree captures the idea that when working with uncertain information in the form of probabilistic rules and facts , we need to consider the disjunction of all proofs in order to determine the best possible confidence in the goal being proved .",
    "\\(2 ) however , notice that the definition does _ not _ insist that a goal node @xmath253 should have rule children corresponding to all possible unifiable rules and mgu s .",
    "\\(3 ) we assume without loss of generality that all rules in the p - program are standardized apart by variable renaming so they share no common variables .",
    "\\(4 ) a goal node can have several rule children corresponding to the same rule .",
    "that is , a goal node can have children labeled @xmath350 , where @xmath213 is ( a renamed version of ) a rule in the program .",
    "but we require that @xmath351 , @xmath352 , be distinct .",
    "\\(5 ) we require all substitutions in the tree to be compatible .",
    "the convention explained above ensures there will be no conflict among them on account of common variables across rules ( or different invocations of the same rule ) .",
    "\\(6 ) note that a dpt can be finite or infinite .",
    "\\(7 ) in a proper dpt , goal leaves are necessarily failure nodes ; this is not true in non - proper dpts .",
    "\\(8 ) a proper dpt with no failure nodes has only rule leaves , hence , it has an odd height .",
    "confidences are associated with ( finite ) dpts as follows .",
    "[ dpt - conf ] let @xmath16 be a p - program , @xmath113 a goal , and @xmath342 any finite dpt for @xmath113 with respect to @xmath16 .",
    "we associate confidences with the nodes of @xmath342 as follows .",
    "each failure node gets the confidence @xmath353,~[1,1]\\rangle$}}$ ] , the * false * confidence level with respect to truth ordering , @xmath74 ( see section [ lattice ] ) .",
    "each success node labeled @xmath343 , where @xmath213 is a rule in @xmath16 , and @xmath111 is the confidence of rule @xmath213 , gets the confidence @xmath111 .",
    "suppose @xmath288 is a rule node labeled @xmath343 , such that the confidence of @xmath213 is @xmath111 , its ( conjunctive ) mode is @xmath214 , and the confidences of the children of @xmath288 are @xmath354 .",
    "then @xmath288 gets the confidence @xmath355 .",
    "suppose @xmath288 is a goal node labeled @xmath253 , with a ( disjunctive ) mode @xmath215 such that the confidences of its children are @xmath356 .",
    "then @xmath288 gets the confidence @xmath357 .",
    "we recall the notions of identity and annihilator from algebra ( see ullman @xcite ) .",
    "let @xmath358 be any element of the confidence lattice and @xmath359 be any operation of the form @xmath360 or of the form @xmath361 , @xmath362 being any of the modes discussed in section [ prob - calc ] .",
    "then @xmath111 is an _ identity _ with respect to @xmath359 , if @xmath363 .",
    "it is an _ annihilator _ with respect to @xmath359 , if @xmath364 .",
    "the proof of the following proposition is straightforward .",
    "[ identity - annihilator ] the truth - value @xmath365,~[1,1]\\rangle$}}$ ] is an identity with respect to disjunction and an annihilator with respect to conjunction .",
    "the truth - value @xmath366,~[0,0]\\rangle$}}$ ] is an identity with respect to conjunction and an annihilator with respect to disjunction .",
    "these claims hold for all modes discussed in section [ prob - calc ] .    in view of this proposition",
    ", we can consider only dpts without failure nodes without losing any generality .",
    "we now proceed to prove the soundness and completeness theorems .",
    "first , we need some definitions .",
    "a _ branch _ @xmath345 of a dpt @xmath342 is a set of nodes of @xmath342 , defined as follows .",
    "the root of @xmath342 belongs to @xmath345 .",
    "whenever a goal node is in @xmath345 , exactly one of its rule children ( if any ) belongs to @xmath345 .",
    "finally , whenever a rule node belongs to @xmath345 , all its goal children belong to @xmath345 .",
    "we extend this definition to the subtrees of a dpt in the obvious way .",
    "a _ subbranch _ of @xmath342 rooted at a goal node @xmath113 is the branch of the subtree of @xmath342 rooted at @xmath113 .",
    "we can associate a substitution with a ( sub)branch @xmath345 as follows .",
    "( 1 ) the substitution associated with a success node labeled @xmath343 is just @xmath344 .",
    "( 2 ) the substitution associated with an internal goal node is simply the substitution associated with its unique rule child in @xmath345 .",
    "( 3 ) the substitution associated with an internal rule node @xmath288 in @xmath345 which is labeled @xmath343 is the composition of @xmath344 and the substitutions associated with the goal children of @xmath288 .    the substitution associated with a branch is that associated with its root .",
    "we say a dpt @xmath342 is _ well - formed _ if it satisfies the following conditions : ( i ) @xmath342 is proper , ( ii ) for every goal node @xmath113 in @xmath342 , for any two ( sub)branches @xmath367 of @xmath342 rooted at @xmath113 , the substitutions associated with @xmath368 and @xmath369 are distinct .",
    "the second condition ensures no two branches correspond to the same classical  proof \" of the goal or a sub - goal . without this condition ,",
    "since the probabilistic conjunctions and disjunctions are not idempotent , the confidence of the same proof could be wrongly combined giving an incorrect confidence for the ( root of the ) dpt .",
    "henceforth , we will only consider well - formed dpts , namely , dpts that are proper , have no failure nodes , and have distinct substitutions for all ( sub ) branches corresponding to a goal node , for all goal nodes .",
    "[ soundness ] [ soundness ] let @xmath16 be a p - program and @xmath113 a ( ground ) goal . if there is a finite well - formed dpt for @xmath113 with respect to @xmath16 with an associated confidence @xmath111 at its root , then @xmath370 .",
    "* proof . *",
    "first , we make the following observations regarding the combination functions of theorem [ thm : combinations ] :    \\(1 ) conjunctive combination functions ( all modes ) are monotone .",
    "+ ( 2 ) disjunctive combination functions ( all modes ) are monotone .",
    "+ ( 3 ) if @xmath3 and @xmath113 are confidence levels , then @xmath371 and @xmath372 for all conjunctive and disjunctive combination functions ( all modes ) .",
    "we prove the soundness theorem by induction on the height of the dpt .",
    "assume the well - formed dpt @xmath342 of height @xmath373 is for the goal @xmath113 .",
    "note that @xmath342 has an odd height , @xmath374 for some @xmath375 , since it is a proper dpt with no failure nodes ( see remark 7 at the beginning of this section ) .    :",
    "@xmath376 . in this case",
    "the dpt consists of the goal root labeled @xmath113 and one child labeled @xmath377 , where @xmath213 is a rule in @xmath16 whose head is unifiable with @xmath113 .",
    "note that this child node is a success leaf .",
    "it represents a fact . obviously , in the first iteration of @xmath1 , @xmath378 , where @xmath379 is the confidence level of @xmath213 .",
    "it follows from the monotonicity of @xmath1 , that @xmath380 .    :",
    "@xmath381 . assume the inductive hypothesis holds for every dpt of height @xmath382 , where @xmath383 .",
    "consider the dpt @xmath342 for @xmath113 .",
    "the root @xmath113 has rule children @xmath384 labeled @xmath385 .",
    "each @xmath384 is either a fact , or has goal children @xmath386 .",
    "consider the subtrees of @xmath342 rooted at these goal grand children of @xmath113 . by the inductive hypothesis , the confidence levels @xmath387 associated with the goal grand children @xmath388 by the dpt are less than or equal to their confidence levels calculated by @xmath1 , , @xmath389 .",
    "hence , by properties ( 1)-(3 ) above , the confidence level associated to @xmath113 by @xmath342 is less than or equal to the confidence level of @xmath113 obtained by another application of @xmath1 , @xmath390 .",
    "hence @xmath370 .",
    "note that @xmath342 must be well - formed otherwise this argument is not valid .",
    "[ completeness ] [ completeness ] let @xmath16 be a p - program and @xmath113 a goal such that for some number @xmath391 , @xmath392 .",
    "then there is a finite dpt @xmath342 for @xmath113 with respect to @xmath16 with an associated confidence @xmath111 at its root , such that @xmath393 .",
    "* let @xmath55 be the smallest number such that @xmath394 .",
    "we shall show by induction on @xmath55 that there is a dpt @xmath342 for @xmath113 with respect to @xmath16 such that the confidence computed by it is at least @xmath395 .    :",
    "this implies @xmath397,~[1,1]\\rangle$}}$ ] .",
    "this case is trivial .",
    "the dpt consists of a failure node labeled @xmath113 .    :",
    "suppose the result holds for a certain number @xmath398 .",
    "we show that it also holds for @xmath399 .",
    "suppose @xmath253 is a ground atom such that @xmath400 .",
    "now , @xmath401 there exists a rule @xmath213 such that @xmath214 is the mode associated with its body , and @xmath215 is the mode associated with its head , and there exists a ground substitution @xmath344 such that @xmath402 .",
    "consider the dpt for @xmath253 obtained as follows .",
    "let the root be labeled @xmath253 .",
    "the root has a rule child corresponding to each rule instance used in the above computation of @xmath403 .",
    "let @xmath248 be a rule child created at this step , and suppose @xmath404 is the rule instance corresponding to it and let @xmath344 be the substitution used to unify the head of the original rule with the atom @xmath253 .",
    "then @xmath248 has @xmath405 goal children with labels @xmath406 respectively . finally , by induction hypothesis",
    ", we can assume that ( i ) a dpt for @xmath254 is rooted at the node labeled @xmath254 , and ( ii ) the confidence computed by this latter tree is at least @xmath407 , @xmath408 .",
    "in this case , it readily follows from the definition of the confidence computed by a proof - tree that the confidence computed by @xmath342 is at least @xmath409 is a rule defining @xmath253 , @xmath379 is the confidence associated with it , @xmath214 is the mode associated with its head , and @xmath215 is the mode associated with its body@xmath410 .",
    "but this confidence is exactly @xmath403 .",
    "the induction is complete and the theorem follows .",
    "theorems  [ soundness ] and  [ completeness ] together show that the confidence of an arbitrary ground atom computed according to the fixpoint semantics and using an appropriate disjunctive proof tree is the same .",
    "this in turn is the same as the confidence associated according to the ( valuation based ) declarative semantics .",
    "in particular , as we will discuss in section [ termination ] , when the disjunctive mode associated with all recursive predicates is positive correlation , the theorems guarantee that the exact confidence associated with the goal can be effectively computed by constructing an appropriate finite dpt ( according to theorem [ completeness ] ) for it .",
    "even when these modes _ are _ used indiscriminately , we can still obtain the confidence associated with the goal with an arbitrarily high degree of accuracy , by constructing dpts of appropriate height .",
    "in this section , we first compare our work with that of ng and subrahmanian @xcite ( see section [ intro ] for a general comparison with non - probabilistic frameworks ) . first , let us examine the ( only )  mode \" for disjunction used by them .",
    "they combine the confidences of an atom @xmath253 coming from different derivations by taking their intersection . indeed , the bottom of their lattice is a valuation ( called  formula function \" there ) that assigns the interval @xmath0 $ ] to every atom . from the trilattice structure ,",
    "it is clear that ( i ) their bottom corresponds to @xmath78 , and ( ii ) their disjunctive mode corresponds to @xmath411 .",
    "[ problem1 ] @xmath412 : @xmath413 { \\mbox{$\\leftarrow$}}e(x , z ) : [ v_1 , v_2 ] ,   ~~$]@xmath414 $ ] . + @xmath415 : @xmath416 { \\mbox{$\\leftarrow$}}e(x , y ) : [ v_1 , v_2]$ ]",
    ". + @xmath417 : @xmath418 $ ] .",
    "+ @xmath419 : @xmath420 $ ] .",
    "+ @xmath421 : @xmath422 $ ] .",
    "this is a pf - program in the framework of ng and subrahmanian @xcite . in a pf - rule",
    "each literal is annotated by an interval representing the lower - bound and upper - bound of belief .",
    "variables can appear in the annotations , and the annotation of the head predicate is usually a function of body literals annotations .",
    "the program in this example is basically the transitive closure program , with independence as the conjunctive mode in the first rule .",
    "the disjunctive function for the @xmath56 predicate , as explained above , is interval intersection .",
    "let us denote the operator @xmath1 defined by them as @xmath423 for distinguishing it from ours .",
    "it is not hard to see that this program is inconsistent in their framework , and @xmath424would assign an empty probability range for @xmath425 .",
    "this is due to the existence of two derivations for @xmath425 , with non - overlapping intervals .",
    "this is quite unintuitive .",
    "indeed , there is a definite path ( with probability 1 ) corresponding to the edge @xmath426 .",
    "one may wonder whether it makes sense to compare this approach with ours on an example program which is inconsistent according to their semantics .",
    "the point is that in this example , there is a certain path with probability [ 1,1 ] from 1 to 2 , and an approach that regards this program as inconsistent is not quite intuitive .",
    "now , consider the p - program corresponding to the annotated program @xmath427 @xmath428 , obtained by stripping off atom annotations in @xmath429 and shifting the annotations in @xmath430 to the associated rules .",
    "also , associate the confidence level @xmath431,~[0,0]\\rangle$}}$ ] with @xmath429 . for uniformity and ease of comparison , assume the doubt ranges are all @xmath432 $ ] . as an example , let the conjunctive mode used in @xmath429 be independence and let the disjunctive mode used be positive correlation ( or , in this case , even ignorance ! ) . then @xmath433 would assign the confidence @xmath434,~[0,0]\\rangle$ ] to @xmath435 , which agrees with our intuition . our point , however , is not that intersection is a ",
    "wrong \" mode .",
    "rather , we stress that different combination rules ( modes ) are appropriate for different situations .",
    "[ problem2 ] now consider the following pf - program ( @xmath412 and @xmath415 are the same as previous example ) :    @xmath412 : @xmath413 { \\mbox{$\\leftarrow$}}e(x , z ) : [ v_1 , v_2 ] , ~~$]@xmath414 $ ]",
    ". + @xmath415 : @xmath416 { \\mbox{$\\leftarrow$}}e(x , y ) : [ v_1 , v_2]$ ]",
    ". + @xmath436 : @xmath437 $ ] .",
    "+ @xmath438 : @xmath439 $ ] .    in this case , the least fixpoint of @xmath423 is only attained at @xmath2 and it assigns the range @xmath440 $ ] to @xmath441 and @xmath425 .",
    "again , the result is unintuitive for this example . since @xmath423 is not continuous , one can easily write programs such that no reasonable approximation to @xmath424 can be obtained by iterating @xmath423 an arbitrary ( finite ) number of times .",
    "( , consider the program obtained by adding the rule @xmath442 : @xmath443~{\\mbox{$\\leftarrow$}}~p(x , y ) : [ 0,0]$ ] to @xmath444 . )",
    "notice that as long as one uses any arithmetic annotation function such that the probability of the head is less than the probability of the subgoals of @xmath412 ( which is a reasonable annotation function ) , this problem will arise .",
    "the problem ( for the unintuitive behavior ) lies with the mode for disjunction .",
    "again , we emphasize that different combination rules ( modes ) are appropriate for different situations .    now , consider the p - program corresponding to the annotated program @xmath445 , obtained in the same way as was done in example [ problem1 ] .",
    "let the conjunctive mode used in @xmath429 be independence and let the disjunctive mode be positive correlation or ignorance",
    ". then @xmath433 would assign the confidence level @xmath446~[0,0]\\rangle$ ] to @xmath435 .",
    "this again agrees with our intuition . as a last example , suppose we start with the confidence @xmath447,~[0,0]\\rangle$ ] for @xmath448 instead .",
    "then under positive correlation ( for disjunction ) @xmath449,~[0,0]\\rangle$ ] , while ignorance leads to @xmath450,~[0,0]\\rangle$ ] .",
    "the former makes more intuitive sense , although the latter ( more conservative under @xmath52 ) is obviously not wrong .",
    "also , in the latter case , the @xmath451 is reached only at @xmath2 .",
    "now , we discuss termination and complexity issues of p - programs .",
    "let the _ closure ordinal _ of @xmath1 be the smallest ordinal @xmath10 such that @xmath452 .",
    "we have the following    [ thm : ordinal ] let @xmath16 be any p - program .",
    "then the closure ordinal of @xmath1 can be as high as @xmath2 but no more .",
    "* proof . *",
    "the last p - program discussed in example [ problem2 ] has a closure ordinal of @xmath2 . since @xmath1 is continuous ( theorem [ thm : tpmonotone ] ) its closure ordinal is at most @xmath2 .",
    "[ defn : datacomplexity ] ( _ data complexity _ ) we define the _ data complexity",
    "_ @xcite of a p - program @xmath16 as the time complexity of computing the least fixpoint of @xmath1 as a function of the size of the database , the number of constants occurring in @xmath16 .",
    "it is well known that the data complexity for datalog programs is polynomial .",
    "an important question concerning any extension of ddbs to handle uncertainty is whether the data complexity is increased compared to datalog .",
    "we can show that under suitable restrictions ( see below ) the data complexity of p - programs is polynomial time .",
    "however , the proof can not be obtained by ( straightforward extensions of ) the classical argument for the data complexity for datalog . in the classical case , once a ground atom is derived during bottom - up evaluation , future derivations of it can be ignored . in programming with uncertainty , complications arise because we _ can not _ ignore alternate derivations of the same atom : the confidences obtained from them need to be combined , reinforcing the overall confidence of the atom .",
    "this calls for a new proof technique .",
    "our technique makes use of the following additional notions .",
    "define a _ disjunctive derivation tree _ ( ddt ) to be a well - formed dpt ( see section [ proof - theory ] for a definition ) such that every goal and every substitution labeling any node in the tree is ground .",
    "note that the height of a ddt with no failure nodes is an odd number ( see remark 7 at the beginning of section [ proof - theory ] ) .",
    "we have the following results .    [ ddt - bu - eval ]",
    "let @xmath16 be a p - program and @xmath253 any ground atom in @xmath219 .",
    "suppose the confidence determined for @xmath253 in iteration @xmath453 of bottom - up evaluation is @xmath111 .",
    "then there exists a ddt @xmath342 of height @xmath454 for @xmath253 such that the confidence associated with @xmath253 by @xmath342 is exactly @xmath111",
    ".    * proof . *",
    "the proof is by induction on @xmath55 .    :",
    "@xmath376 . in iteration 1",
    ", bottom - up evaluation essentially collects together all edb facts ( involving ground atoms ) and determines their confidences from the program . without loss of generality , we may suppose there is at most one edb fact in @xmath16 corresponding to each ground atom ( involving an edb predicate ) .",
    "let @xmath253 be any ground atom whose confidence is determined to be @xmath111 in iteration 1 . then there is an edb fact @xmath455 in @xmath16 .",
    "the associated ddt for @xmath253 corresponding to this iteration is the tree with root labeled @xmath253 and a rule child labeled @xmath213 .",
    "clearly , the confidence associated with the root of this tree is @xmath111 , and the height of this tree is @xmath37 ( @xmath456 , for @xmath457 .    :",
    "assume the result for all ground atoms whose confidences are determined ( possibly revised ) in iteration @xmath55 .",
    "suppose @xmath253 is a ground atom whose confidence is determined to be @xmath111 in iteration @xmath458 .",
    "this implies there exist ground instances of rules @xmath459 , @xmath460 ; @xmath461 such that ( i ) the confidence of @xmath254 @xmath462 computed at the end of iteration @xmath55 is @xmath463 ( @xmath464 ) , and ( ii ) @xmath465 @xmath466 @xmath467 @xmath468 , where  is the disjunctive mode for the predicate @xmath253 . by induction hypothesis , there are ddts @xmath469 , @xmath470 , each of height @xmath471 or less , for the atoms @xmath406 , @xmath472 which exactly compute the confidences @xmath354 , @xmath473 respectively , corresponding to iteration @xmath55 .",
    "consider the tree @xmath474 for @xmath253 by ( i ) making @xmath475 rule children of the root and ( ii ) making the @xmath469 , ( @xmath476 ) subtrees of @xmath412 ( @xmath477 ) .",
    "it is trivial to see that @xmath474 is a ddt for @xmath253 and its height is @xmath478 .",
    "further the confidence @xmath474 computes for the root @xmath253 is exactly @xmath479",
    "@xmath466 @xmath467 @xmath468 .",
    "this completes the induction and the proof .",
    "proposition [ ddt - bu - eval ] shows each iteration of bottom - up evaluation corresponds in an essential manner to the construction of a set of ddts one for each distinct ground atom whose confidence is determined ( or revised ) in that iteration .",
    "our next objective is to establish a termination bound on bottom - up evaluation .",
    "ddt branches are defined similar to those of dpt .",
    "let @xmath342 be a ddt .",
    "then a branch of @xmath342 is a subtree of @xmath342 , defined as follows .",
    "\\(i ) the root belongs to every branch .",
    "+ ( ii ) whenever a goal node belongs to a branch , exactly one of its rule children , belongs to the branch .",
    "+ ( iii ) whenever a rule node belongs to a branch , all its goal children belong to the branch .",
    "let @xmath253 be a ground atom and @xmath342 any ddt ( not necessarily for @xmath253 ) .",
    "then @xmath342 is @xmath253-non - simple provided it has a branch containing two goal nodes @xmath288 and @xmath248 such that @xmath288 is an ancestor of @xmath248 and both are labeled by atom @xmath253 .",
    "a ddt is @xmath253-simple if it is not @xmath253-non - simple .",
    "finally , a ddt is simple if it is @xmath253-simple for every atom @xmath253 .",
    "let @xmath342 be a ddt and @xmath254 be a branch of @xmath342 in which an atom @xmath253 appears .",
    "then we define the _ number of violations of simplicity _ of @xmath254 with respect to @xmath253 to be one less than the total number of times the atom @xmath253 occurs in @xmath254 .",
    "the number of violations of the simplicity of the ddt @xmath342 with respect to @xmath253 is the sum of the number of violations of the branches of @xmath342 in which @xmath253 occurs .",
    "clearly , @xmath342 is @xmath253-simple exactly when the number of violations with respect to @xmath253 is 0 .",
    "our first major result of this section follows .",
    "[ term - bound ] let @xmath16 be a p - program such that only positive correlation is used as the disjunctive mode for recursive predicates .",
    "let @xmath480a@xmath481 , and @xmath482 is any simple ddt for @xmath483 = @xmath454 , @xmath453 .",
    "then at most @xmath458 iterations of naive bottom - up evaluation are needed to compute the least fixpoint of @xmath1 .",
    "essentially , for p - programs @xmath16 satisfying the conditions mentioned above , the theorem ( i ) shows that naive bottom - up evaluation of @xmath16 is guaranteed to terminate , and ( ii ) establishes an upper bound on the number of iterations of bottom - up evaluation for computing the least fixpoint , in terms of the maximum height of any simple tree for any ground atom .",
    "this is the first step in showing that p - programs of this type have a polynomial time data complexity .",
    "we will use the next three lemmas ( lemmas  [ lem : key][lem : boundfora ] ) in proving this theorem .",
    "[ lem : key ] let @xmath484 be any ground atom , and let @xmath342 be a ddt for @xmath253 corresponding to @xmath485 , for some @xmath486 .",
    "suppose @xmath342 is @xmath345-non - simple , for some atom @xmath345 .",
    "then there is a ddt @xmath487 for @xmath253 with the following properties :    \\(i ) the certainty of @xmath253 computed by @xmath487 equals that computed by @xmath342 .",
    "+ ( ii ) the number of violations of simplicity of @xmath487 with respect to @xmath345 is less than that of @xmath342 .",
    "* proof*. let @xmath342 be the ddt described in the hypothesis of the claim .",
    "let @xmath253 be the label of the root @xmath288 of @xmath342 , and assume without loss of generality that @xmath345 is identical to @xmath253 .",
    "( the case when @xmath345 is distinct from @xmath253 is similar . )",
    "let @xmath248 be the last goal node from the root down ( e.g. in the level - order ) , which is distinct from the root and is labeled by @xmath253 . since @xmath342 corresponds to applications of the @xmath1 operator , we have the following .    (",
    "* ) every branch of @xmath248 must be isomorphic to some branch of @xmath288 which does not contain the node @xmath248 .",
    "this can be seen as follows .",
    "let @xmath488 be the iteration such that the subtree of @xmath342 rooted at @xmath248 , say @xmath489 , corresponds to @xmath490 .",
    "then clearly , every rule applicable in iteration @xmath56 is also applicable in iteration @xmath55 .",
    "this means every branch of @xmath489 constructed from a sequence of rule applications is also constructible in iteration @xmath55 and hence there must be a branch of @xmath342 that is isomorphic to such a branch .",
    "it follows from the isomorphism that the isomorphic branch of @xmath342 can not contain the node @xmath248 .",
    "associate a logical formula with each node of @xmath342 as follows .",
    "\\(i ) the formula associated with each ( rule ) leaf is * true*. + ( ii ) the formula associated with a goal node with rule children @xmath491 and associated formulas @xmath492 , is @xmath493 .",
    "+ ( iii ) the formula associated with a rule parent with goal children @xmath494 and associated formulas @xmath495 is @xmath496 .    let the formula associated with the node @xmath248 be @xmath3 . to simplify the exposition , but at no loss of generality , let us assume that in @xmath342 , every goal node has exactly two rule children . then the formula associated with the root @xmath288 can be expressed as @xmath497 .    by ( * ) above , we can see that @xmath3 logically implies @xmath498 , @xmath499 . by the structure of a ddt",
    ", we can then express @xmath498 as @xmath500 , for some formula @xmath113 . construct a ddt @xmath487 from @xmath342 by deleting the parent of the node @xmath248 , as well as the subtree rooted at @xmath248 .",
    "we claim that    ( * * ) the formula associated with the root of @xmath487 is equivalent to that associated with the root of @xmath342 .    to see this , notice that the formula associated with the root of @xmath342 can now be expressed as @xmath501 . by simple application of propositional identities",
    ", it can be seen that this formula is equivalent to @xmath502 .",
    "but this is exactly the formula associated with the root of t , which proves ( * * ) .",
    "finally , we shall show that @xmath276 , together with any conjunctive mode , satisfy the following absorption laws :    @xmath503 .",
    "+ @xmath504 .",
    "the first of these laws follows from the fact that for all modes @xmath362 we consider in this paper , @xmath505 , where @xmath50 is the lattice ordering .",
    "the second is the dual of the first .    in view of the absorption laws",
    ", it can be seen that the certainty for @xmath253 computed by @xmath487 above is identical to that computed by @xmath342 .",
    "this proves the lemma , since @xmath487 has at least one fewer violations of simplicity with respect to @xmath253 .",
    "[ lem : simple ] let @xmath342 be a ddt for an atom @xmath253 .",
    "then there is a simple ddt for @xmath253 such that the certainty of @xmath253 computed by it is identical to that computed by @xmath342 .",
    "* proof*. follows by an inductive argument using lemma [ lem : key ] .",
    "[ lem : boundfora ] let @xmath253 be an atom and @xmath506 be the maximum height of any simple ddt for @xmath253",
    ". then certainty of @xmath253 in @xmath485 is identical to that in @xmath507 , for all @xmath508 .",
    "* proof*. let @xmath342 be the ddt for @xmath253 corresponding to @xmath485 .",
    "note that height(@xmath509 .",
    "let @xmath111 represent the certainty computed by @xmath342 for @xmath253 , which is @xmath510 . by lemma [ lem : simple ]",
    ", there is a simple ddt , say @xmath487 , for @xmath253 , which computes the same certainty for @xmath253 as @xmath342 .",
    "clearly , height(@xmath511 .",
    "let @xmath112 represent the certainty computed by @xmath487 for @xmath253 , @xmath512 . by the soundness theorem , and monotonicity of @xmath1 , we can write @xmath513 .",
    "it follows that @xmath514 .",
    "now we can complete the proof of theorem [ term - bound ] .",
    "* proof of theorem [ term - bound]*. let @xmath515 be the maximum height of any simple ddt for any atom .",
    "it follows from the above lemmas that the certainty of any atom in @xmath485 is identical to that in @xmath516 , for all @xmath517 , from which the theorem follows .",
    "it can be shown that the height of simple ddts is polynomially bounded by the database size .",
    "this makes the above result significant .",
    "this allows us to prove the following theorem regarding the data complexity of the above class of p - programs .",
    "[ complexity ] let @xmath16 be a p - program such that only positive correlation is used as the disjunctive mode for recursive predicates . then its least fixpoint can be computed in time polynomial in the database size . in particular ,",
    "bottom - up naive evaluation terminates in time polynomial in the size of the database , yielding the least fixpoint .",
    "* by theorem [ term - bound ] we know that the least fixpoint model of @xmath16 can be computed in at most @xmath458 iterations where @xmath518 is the maximum height of any simple ddt for any ground atom with respect to @xmath16 ( @xmath55 iterations to arrive at the fixpoint , and one extra iteration to verify that a fixpoint has been reached . )",
    "notice that each goal node in a ddt corresponds to a database predicate .",
    "let @xmath519 be the maximum arity of any predicate in @xmath16 , and @xmath398 be the number of constants occurring in the program .",
    "notice that under the data complexity measure ( definition [ defn : datacomplexity ] ) @xmath519 is a constant .",
    "the maximum number of distinct goal nodes that can occur in any branch of a simple ddt is @xmath520 .",
    "this implies the height @xmath373 above is clearly a polynomial in the database size @xmath398 .",
    "we have thus shown that bottom - up evaluation of the least fixpoint terminates in a polynomial number of iterations .",
    "the fact that the amount of work done in each iteration is polynomial in @xmath398 is easy to see .",
    "the theorem follows .",
    "we remark that our proof of theorem [ complexity ] implies a similar result for van emden s framework . to our knowledge , this is the first polynomial time result for rule - based programming with ( probabilistic ) uncertainty .",
    "we should point out that the polynomial time complexity is preserved whenever modes other than positive correlation are associated with non - recursive predicates ( for disjunction ) . more generally , suppose @xmath521 is the set of all recursive predicates and @xmath522 is the set of non - recursive predicates in the kb , which are possibly defined in terms of those in @xmath521 .",
    "then any modes can be freely used with the predicates in @xmath522 while keeping the data complexity polynomial .",
    "finally , if we know that the data does not contain cycles , we can use any mode even with a recursive predicate and still have a polynomial time data complexity .",
    "we also note that the framework of annotation functions used in @xcite enables an infinite family of modes to be used in propagating confidences from rule bodies to heads .",
    "the major differences with our work are ( i ) in @xcite a fixed  mode \" for disjunction is imposed unlike our framework , and ( ii ) they do not study the complexity of query answering , whereas we establish the conditions under which the important advantage of polynomial time data complexity of classical datalog can be retained .",
    "more importantly , our work has generated useful insights into how modes ( for disjunction ) affect the data complexity .",
    "finally , a note about the use of positive correlation as the disjunctive mode for recursive predicates ( when data might contain cycles ) .",
    "the rationale is that different derivations of such recursive atoms could involve some amount of overlap ( the degree of overlap depends on the data ) .",
    "now , positive correlation ( for disjunction ) tries to be conservative ( and hence sound ) by assuming the extent of overlap is maximal , so the combined confidence of the different derivations is the least possible ( under @xmath50 ) .",
    "thus , it _ does _ make sense even from a practical point of view .",
    "we motivated the need for modeling both belief and doubt in a framework for manipulating uncertain facts and rules .",
    "we have developed a framework for probabilistic deductive databases , capable of manipulating both belief and doubt , expressed as probability intervals .",
    "belief doubt pairs , called confidence levels , give rise to a rich algebraic structure called a trilattice .",
    "we developed a probabilistic calculus permitting different modes for combining confidence levels of events .",
    "we then developed the framework of p - programs for realizing probabilistic deductive databases .",
    "p - programs inherit the ability to  parameterize \" the modes used for combining confidence levels , from our probabilistic calculus .",
    "we have developed a declarative semantics , a fixpoint semantics , and proved their equivalence .",
    "we have also provided a sound and complete proof procedure for p - programs .",
    "we have shown that under disciplined use of modes , we can retain the important advantage of polynomial time data complexity of classical datalog , in this extended framework .",
    "we have also compared our framework with related work with respect to the aspects of termination and intuitive behavior ( of the semantics ) .",
    "the parametric nature of modes in p - programs is shown to be a significant advantage with respect to these aspects .",
    "also , the analysis of trilattices shows insightful relationships between previous work ( ng and subrahmanian @xcite ) and ours . interesting open issues which merit further research include ( 1 ) semantics of p - programs under various trilattice orders and various modes , including new ones , ( 2 ) query optimization , ( 3 ) handling inconsistency in a framework handling uncertainty , such as the one studied here .",
    "the authors would like to thank the anonymous referees for their careful reading and their comments , many of which have resulted in significant improvements to the paper .",
    "kifer , m. , & li , a. ( 1988 ) . on the semantics of rule - based expert systems with uncertainty .",
    "gyssens , m. , paradaens , j. , & van gucht , d. ( eds ) , _",
    "conf . on database theory_. bruges ,",
    "belgium : springer - verlag lncs-326 .",
    "lakshmanan , l. v.  s. , & shiri , n. ( 1997 ) . a parametric approach to deductive databases with uncertainty . .",
    "( a preliminary version appeared in proc .",
    "workshop on logic in databases ( lid96 ) , springer - verlag , lncs-1154 , san miniato , italy ) .",
    "ng , r.  t. , & subrahmanian , v.  s. ( 1991 ) . .",
    "report umiacs - tr-91 - 49 , cs - tr-2647 .",
    "institute for advanced computer studies and department of computer science university of maryland , college park , md 20742 ."
  ],
  "abstract_text": [
    "<S> we propose a framework for modeling uncertainty where both belief and doubt can be given independent , first - class status . </S>",
    "<S> we adopt probability theory as the mathematical formalism for manipulating uncertainty . </S>",
    "<S> an agent can express the uncertainty in her knowledge about a piece of information in the form of a _ confidence level _ , consisting of a pair of intervals of probability , one for each of her belief and doubt . </S>",
    "<S> the space of confidence levels naturally leads to the notion of a _ trilattice _ , </S>",
    "<S> similar in spirit to fitting s bilattices . </S>",
    "<S> intuitively , the points in such a trilattice can be ordered according to truth , information , or precision . </S>",
    "<S> we develop a framework for _ probabilistic deductive databases _ by associating confidence levels with the facts and rules of a classical deductive database . </S>",
    "<S> while the trilattice structure offers a variety of choices for defining the semantics of probabilistic deductive databases , our choice of semantics is based on the truth - ordering , which we find to be closest to the classical framework for deductive databases . </S>",
    "<S> in addition to proposing a declarative semantics based on valuations and an equivalent semantics based on fixpoint theory , we also propose a proof procedure and prove it sound and complete . </S>",
    "<S> we show that while classical datalog query programs have a polynomial time data complexity , certain query programs in the probabilistic deductive database framework do not even terminate on some input databases . </S>",
    "<S> we identify a large natural class of query programs of practical interest in our framework , and show that programs in this class possess polynomial time data complexity , not only do they terminate on every input database , they are guaranteed to do so in a number of steps polynomial in the input database size .    </S>",
    "<S> [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] [ section ] </S>"
  ]
}