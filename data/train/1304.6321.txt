{
  "article_text": [
    "since its invention in the 1980s , the notion of treewidth has come to play a central role in an enormous number of fields , ranging from very deep structural theories to highly applied areas .",
    "an important (",
    "but not the only ) reason for the impact of the notion is that many graph problems that are intractable on general graphs become efficiently solvable when the input is a graph of bounded treewidth . in most cases ,",
    "the first step of an algorithm is to find a tree decomposition of small width and the second step is to perform a dynamic programming procedure on the tree decomposition .    in particular ,",
    "if a graph on @xmath0 vertices is given together with a tree decomposition of width @xmath4 , many problems can be solved by dynamic programming in time @xmath6 , i.e. , single - exponential in the treewidth and linear in @xmath0 .",
    "many of the problems admitting such algorithms have been known for over thirty years  @xcite but new algorithmic techniques on graphs of bounded treewidth  @xcite as well as new problems motivated by various applications ( just a few of many examples are  @xcite ) continue to be discovered . while a reasonably good tree decomposition can be derived from the properties of the problem sometimes , in most of the applications , the computation of a good tree decomposition is a challenge .",
    "hence the natural question here is what can be done when no tree decomposition is given . in other words , is there an algorithm that for a given graph @xmath1 and integer @xmath4 , in time @xmath6 either correctly reports that the treewidth of @xmath1 is at least @xmath4 , or finds an optimal solution to our favorite problem ( finds a maximum independent set , computes the chromatic number , decides if @xmath1 is hamiltonian , etc . ) ? to answer this question",
    "it would be sufficient to have an algorithm that in time @xmath6 either reports correctly that the treewidth of @xmath1 is more that @xmath4 , or construct a tree decomposition of width at most @xmath7 for some constant @xmath8 .    however , the lack of such algorithms has been a bottleneck , both in theory and in practical applications of the treewidth concept .",
    "the existing approximation algorithms give us the choice of running times of the form @xmath9 , @xmath10 , or @xmath11 , see table  [ table : tw_history ] .",
    "remarkably , the newest of these current record holders is now almost 20 years old .",
    "this `` newest record holder '' is the linear time algorithm of bodlaender  @xcite that given a graph @xmath1 , decides if the treewidth of @xmath1 is at most @xmath4 , and if so , gives a tree decomposition of width at most @xmath4 in @xmath12 time .",
    "the improvement by perkovi and reed  @xcite is only a factor polynomial in @xmath4 faster ( but also , if the treewidth is larger than @xmath4 , it gives a subgraph of treewidth more than @xmath4 with a tree decomposition of width at most @xmath4 , leading to an @xmath13 algorithm for the fundamental disjoint paths problem ) .",
    "recently , a version running in logarithmic space was found by elberfeld et al .",
    "@xcite , but its running time is not linear .",
    ".overview of treewidth algorithms . here",
    "@xmath4 is the treewidth and @xmath0 is the number of vertices of an input graph @xmath1 .",
    "each of the algorithms outputs in time @xmath14 a decomposition of width given in the approximation column . [ cols=\"^,^,^,^\",options=\"header \" , ]",
    "we now proceed to description of the description of the table @xmath15 , and then to the two tables @xmath16 and @xmath17 that handle the important component @xmath18 . the tables @xmath19 are described together with the description of realization of the corresponding queries . whenever describing the table",
    ", we argue how the table is updated during updates of the data structure , and initialized in the beginning .      in the table @xmath15 , for every node @xmath20 of the tree decomposition we store a boolean value",
    "@xmath21 $ ] equal to @xmath22 .",
    "we now show how to maintain the table @xmath15 when the data structure is updated .",
    "the table @xmath15 needs to be updated whenever the pin @xmath23 is marked or unmarked .",
    "observe , that the only nodes @xmath20 for which the information whether @xmath24 changed , are the ones on the path from @xmath25 to the root of the tree decomposition .",
    "hence , we can simply follow this path and update the values .",
    "as the tree decomposition has depth @xmath26 , this update can be performed in @xmath27 time .",
    "as when the data structure is initialized , no pin is assigned , @xmath15 is initially filled with @xmath28 .",
    "before we proceed to the description of the queries , let us describe what is the reason of introducing the pin @xmath23 . during the computation",
    ", the algorithm recursively considers smaller parts of the graph , separated from the rest via a small separator : at each step we have distinguished set @xmath29 and we consider only one connected component @xmath18 of @xmath30 .",
    "unfortunately , we can not afford recomputing the tree decomposition of @xmath18 at each recurrence call , or even listing the vertices of @xmath18 .",
    "therefore we employ a different strategy for identification of @xmath18 .",
    "we will distinguish one vertex of @xmath18 as a representative pin @xmath23 , and @xmath18 can then be defined as the set of vertices reachable from @xmath23 in @xmath30 .",
    "instead of recomputing @xmath18 at each recursive call we will simply change the pin .    in the tables , for each node @xmath20 of the tree decomposition we store entries for each possible intersection of @xmath18 with @xmath31 , and in this manner we are prepared for every possible interaction of @xmath18 with @xmath32 . in this manner ,",
    "changing the pin can be done more efficiently .",
    "information needs to be recomputed on two paths to the root in the tree decomposition , corresponding the previous and the next pin , while for subtrees unaffected by the change we do not need to recompute anything as the tables stored there already contain information about the new @xmath18 as well  as they contain information for _ every possible _",
    "new @xmath18 . as the tree decomposition is of logarithmic depth",
    ", the update time is logarithmic instead of linear .",
    "we proceed to the formal description .",
    "we store the information about @xmath18 in two special tables : @xmath16 and @xmath17 .",
    "as we intuitively explained , tables @xmath16 and @xmath17 store information on the connectivity behavior in the subtree , for every possible interaction of @xmath18 with the bag .",
    "formally , for every node of the tree decomposition @xmath20 we store an entry for every member of the family of _ signatures _ of the bag @xmath31 . a signature of the bag @xmath31 is a pair @xmath33 , such that @xmath34 are disjoint subsets of @xmath31 . clearly , the number of signatures is at most @xmath35 .",
    "let @xmath20 be a node of the tree decomposition .",
    "for a signature @xmath36 of @xmath31 , let @xmath37 and @xmath38 consists of all the vertices reachable in @xmath39 from @xmath40 or @xmath23 , providing that it belongs to @xmath41 .",
    "sets @xmath42 and @xmath38 are called _ extensions _ of the signature @xmath43 ; note that given @xmath44 and @xmath40 , the extensions are defined uniquely .",
    "we remark here that the definition of extensions depend not only on @xmath43 but also on the node @xmath20 ; hence , we will talk about extensions of signatures only when the associated node is clear from the context .",
    "intuitively , invalidity means that @xmath43 can not contain consistent information about intersection of @xmath18 and @xmath32 .",
    "the second condition says that we can not fully forget the component of @xmath23 , unless the whole @xmath38 is already forgotten .      *",
    "if @xmath43 is invalid then @xmath48[\\phi]=cardu[i][\\phi]=\\bot$ ] ; * otherwise , @xmath48[\\phi]$ ] contains an equivalence relation @xmath49 consisting of all pairs of vertices @xmath50 that are connected in @xmath51 $ ] , while @xmath52[\\phi]$ ] contains @xmath53 .",
    "note that in this definition we actually ignore the information about alignment of vertices of @xmath31 to set @xmath54 in the current state of the graph : the stored information depends only on the alignment of forgotten vertices and the signature of the bag that overrides the actual information in the current state . in this manner",
    "we are prepared for possible changes in the data structure , as after an update some other signature will reflect the current state of the graph .",
    "moreover , it is clear from this definition that during the computation , the alignment of every vertex @xmath55 in the current state of the graph is being checked only in the single node @xmath56 when this vertex is being forgotten ; we use this property heavily to implement the updates efficiently enough .",
    "we now explain how for every node @xmath20 , values in tables @xmath48 $ ] and @xmath52 $ ] can be computed using entries for the children of @xmath20 .",
    "these formulas will be crucial both for implementing updates and initialization .",
    "we consider different cases , depending on the type of node @xmath20 .      * case 2 : introduce node .",
    "* let @xmath20 be a node that introduces vertex @xmath55 , and @xmath57 be its only child .",
    "consider some signature @xmath36 of @xmath31 ; we would like to compute @xmath58[\\phi]$ ] .",
    "let @xmath59 be a natural projection of @xmath43 onto @xmath60 , that is , @xmath61 .",
    "let @xmath62[\\phi']$ ] .",
    "we consider some sub - cases , depending on the alignment of @xmath55 in @xmath43 .",
    "0.1 cm * case 2.1 : @xmath63 .",
    "* if we introduce a vertex from @xmath44 , then it follows that extensions of @xmath64 are equal .",
    "therefore , we can put @xmath48[\\phi]=c[j][\\phi']$ ] and @xmath52[\\phi]=cardu[j][\\phi']$ ] .",
    "0.1 cm * case 2.2 : @xmath65 . * in the beginning we check whether conditions of validity are not violated .",
    "first , if @xmath55 is the only vertex of @xmath40 and @xmath21={\\top}$ ] , then we simply put @xmath48[\\phi]=\\bot$ ] : condition ( ii ) of validity is violated .",
    "second , we check whether @xmath55 is adjacent only to vertices of @xmath66 and @xmath67 ; if this is not the case , we put @xmath48[\\phi]=\\bot$ ] as condition ( i ) of validity is violated .    if the validity checks are satisfied , we can infer that the extension @xmath38 of @xmath40 is extension @xmath68 of @xmath67 with @xmath55 added ; this follows from the fact that @xmath60 separates @xmath55 from @xmath69 , so the only vertices of @xmath38 adjacent to @xmath55 are already belonging to @xmath67 .",
    "now we would like to compute the equivalence relation @xmath70 out of @xmath71 .",
    "observe that @xmath70 should be basically @xmath71 augmented by connections introduced by the new vertex @xmath55 between its neighbors in @xmath60 .",
    "formally , @xmath70 may be obtained from @xmath71 by merging equivalence classes of all the neighbors of @xmath55 from @xmath67 , and adding @xmath55 to the obtained equivalence class ; if @xmath55 does not have any neighbors in @xmath67 , we put it as a new singleton equivalence class . clearly , @xmath52[\\phi]=cardu[j][\\phi']$ ] .",
    "* case 2.3 : @xmath72 .",
    "* we first check whether the validity constraints are not violated .",
    "as @xmath55 is separated from @xmath69 by @xmath60 , the only possible violation introduced by @xmath55 is that @xmath55 is adjacent to a vertex from @xmath67 .",
    "in this situation we put @xmath48[\\phi]=cardu[i][\\phi]=\\bot$ ] , and otherwise we can put @xmath48[\\phi]=c[j][\\phi']$ ] and @xmath52[\\phi]=cardu[j][\\phi']$ ] , because extensions of @xmath43 and @xmath59 are equal .      * case 3 : forget node . * let @xmath20 be a node that forgets vertex @xmath73 , and @xmath57 be its only child .",
    "consider some signature @xmath36 of @xmath31 and define extensions @xmath42 , @xmath38 for this signature .",
    "observe that there is at most one valid signature @xmath74 of @xmath60 for which @xmath75 and @xmath76 , and this signature is simply @xmath43 with @xmath73 added possibly to @xmath44 or @xmath40 , depending whether it belongs to @xmath42 or @xmath38 : the three candidates are @xmath77 , @xmath78 and @xmath79 .",
    "moreover , if @xmath43 is valid then so is @xmath59 . formally , in the following manner we can define signature @xmath59 , or conclude that @xmath43 is invalid :    * if @xmath80 , then @xmath81 ; * otherwise , if @xmath82 then @xmath83 ; * otherwise , we look into entries @xmath84[\\phi_u]$ ] and @xmath84[\\phi_0]$ ] . if * * @xmath84[\\phi_u]=c[j][\\phi_0]=\\bot$ ] then @xmath43 is invalid , and we put @xmath48[\\phi]=cardu[i][\\phi]=\\bot$ ] ; * * if @xmath84[\\phi_u]=\\bot$ ] or @xmath84[\\phi_0]=\\bot$ ] , we take @xmath85 or @xmath83 , respectively ; * * if @xmath84[\\phi_u]\\neq\\bot$ ] and @xmath84[\\phi_0]\\neq\\bot$ ] , it follows that @xmath73 must be a member of a component of @xmath86 that is fully contained in @xmath41 and does not contain @xmath23 .",
    "hence we take @xmath85 .",
    "the last point is in fact a check whether @xmath87 : whether @xmath73 is connected to a vertex from @xmath40 in @xmath32 , can be looked up in table @xmath84 $ ] by adding or not adding @xmath73 to @xmath40 , and checking the stored connectivity information .",
    "if @xmath88 or @xmath89 , we should be using the information for the signature with @xmath44 or @xmath40 updated with @xmath73 , and otherwise we do not need to add @xmath73 anywhere .    as we argued before ,",
    "if @xmath43 is valid then so does @xmath59 , hence if @xmath84[\\phi']=\\bot$ ] then we can take @xmath48[\\phi]=cardu[i][\\phi]=\\bot$ ] . on the other hand , if @xmath59 is valid , then the only possibility for @xmath43 to be invalid is when condition ( ii ) cease to be satisfied .",
    "this could happen only if @xmath83 and @xmath73 is in a singleton equivalence class of @xmath84[\\phi']$ ] ( note that then the connected component corresponding to this class needs to necessarily contain @xmath23 , as otherwise we would have @xmath85 ) .",
    "therefore , if this is the case , we put @xmath48[\\phi]=cardu[i][\\phi]=\\bot$ ] , and otherwise we conclude that @xmath43 is valid and move to defining @xmath48[\\phi]$ ] and @xmath52[\\phi]$ ] .",
    "let now @xmath90[\\phi']$ ] .",
    "as extensions of @xmath59 and @xmath43 are equal , it follows directly from the maintained invariant that @xmath70 is equal to @xmath71 with @xmath73 removed from its equivalence class .",
    "moreover , @xmath52[\\phi]$ ] is equal to @xmath91[\\phi']$ ] , possibly incremented by @xmath92 if we concluded that @xmath83 .",
    "* case 4 : join node .",
    "* let @xmath20 be a join node and @xmath93 be its two children .",
    "consider some signature @xmath36 of @xmath31 .",
    "let @xmath94 be a signature of @xmath95 and @xmath96 be a signature of @xmath97 . from the maintained invariant it follows that @xmath48[\\phi]$ ] is a minimum transitive closure of @xmath98[\\phi_1]\\cup c[j_2][\\phi_2]$ ] , or @xmath28 if any of these entries contains @xmath28 .",
    "similarly , @xmath52[\\phi]=cardu[j_1][\\phi_1]+cardu[j_2][\\phi_2]$ ] .",
    "we now explain how to update tables @xmath16 and @xmath17 in @xmath99 time .",
    "we perform a similar strategy as with table @xmath15 : whenever some vertex @xmath55 is included or removed from @xmath29 , or marked or unmarked as a pin , we follow the path from @xmath56 to the root and fully recompute the whole tables @xmath100 in the traversed nodes using the formulas presented above . at each step",
    "we recompute the table for some node using the tables of its children ; these tables are up to date since they did not need an update at all , or were updated in the previous step .",
    "observe that since the alignment of @xmath55 in the current state of the graph is accessed only in computation for @xmath56 , the path from @xmath56 to the root of the decomposition consists of all the nodes for which the tables should be recomputed .",
    "note also that when marking or unmarking the pin @xmath23 , we must first update @xmath15 and then @xmath16 and @xmath17 .",
    "the update takes @xmath101 time : re - computation of each table takes @xmath102 time , and we perform @xmath103 re - computations as the tree decomposition has depth @xmath103 .",
    "similarly , tables @xmath16 and @xmath17 can be initialized in @xmath104 time by processing the tree in a bottom - up manner : for each node of the tree decomposition , in @xmath102 time we compute its table based on the tables of the children , which were computed before .      in our data structure we store one table per each query .",
    "when describing every query , we first introduce the formal invariant on storage of table s entry , and how this stored information can be computed based on the entries for children .",
    "we then shortly discuss performing updates and initialization of the tables , as they are in all the cases based on the same principle as with tables @xmath16 and @xmath17 .",
    "queries themselves can be performed by reading a single entry of the data structure , with the exception of query finduseparator , whose implementation is more complex .",
    "we begin the description of the queries with the simplest one , namely findneighborhood .",
    "this query lists all the vertices of @xmath29 that are adjacent to @xmath18 . in the algorithm",
    "we have an implicit bound on the size of this neighborhood , which we can use to cut the computation when the accumulated list grows too long .",
    "we use @xmath105 to denote this bound ; in our case we have that @xmath106 .      * if @xmath43 is invalid then @xmath108[\\phi]=\\bot$ ] ; * otherwise @xmath108[\\phi]$ ] stores the list of elements of @xmath109 if there is at most @xmath105 of them , and @xmath110 if there is more of them .",
    "we now present how to compute entries of table @xmath112 for every node @xmath20 depending on the entries of children of @xmath20 .",
    "we consider different cases , depending of the type of node @xmath20 .",
    "for every case , we consider only signatures that are valid , as for the invalid ones we just put value @xmath28 .",
    "* case 2 : introduce node .",
    "* let @xmath20 be a node that introduces vertex @xmath55 , and @xmath57 be its only child .",
    "consider some signature @xmath36 of @xmath31 ; we would like to compute @xmath108[\\phi]=l_i$ ] .",
    "let @xmath59 be a natural intersection of @xmath43 with @xmath60 , that is , @xmath61 .",
    "let @xmath113[\\phi']=l_j$ ] .",
    "we consider some sub - cases , depending on the alignment of @xmath55 in @xmath43 .",
    "0.1 cm * case 2.1 : @xmath63 . *",
    "if we introduce a vertex from @xmath44 , we have that @xmath18-extensions of @xmath43 and @xmath59 are equal .",
    "it follows that @xmath114 should be simply list @xmath115 with @xmath55 appended if it is adjacent to any vertex of @xmath116 .",
    "note here that @xmath55 can not be adjacent to any vertex of @xmath117 , as @xmath60 separates @xmath55 from @xmath69 . hence , we copy the list @xmath115 and append @xmath55 if it is adjacent to any vertex of @xmath67 and @xmath118 . however , if the length of the new list exceeds the @xmath105 bound , we replace it by @xmath110 . note that copying the list takes @xmath119 time , as its length is bounded by @xmath105 .",
    "0.1 cm * case 2.2 : @xmath65 . *",
    "if we introduce a vertex from @xmath40 , then possibly some vertices of @xmath44 gain a neighbor in @xmath38 .",
    "note here that vertices of @xmath120 are not adjacent to the introduced vertex @xmath55 , as @xmath60 separates @xmath55 from @xmath69 .",
    "hence , we copy list @xmath115 and append to it all the vertices of @xmath44 that are adjacent to @xmath55 , but were not yet on @xmath115 . if we exceed the @xmath105 bound on the length of the list , we put @xmath110 instead . note that both copying the list and checking whether a vertex of @xmath44 is on it can be done in @xmath119 time , as its length is bounded by @xmath105 .          *",
    "case 3 : forget node .",
    "* let @xmath20 be a node that forgets vertex @xmath73 , and @xmath57 be its only child .",
    "consider some signature @xmath36 of @xmath31 .",
    "define @xmath59 in the same manner as in the forget step in the computation of @xmath16 . as extensions of @xmath43 and @xmath59",
    "are equal , it follows that @xmath108[\\phi]=t_1[j][\\phi']$ ] .",
    "* case 4 : join node .",
    "* let @xmath20 be a join node and @xmath93 be its two children .",
    "consider some signature @xmath36 of @xmath31 .",
    "let @xmath94 be a signature of @xmath95 and @xmath96 be a signature of @xmath97 .",
    "it follows that @xmath108[\\phi]$ ] should be the merge of lists @xmath122[\\phi_1]$ ] and @xmath123[\\phi_2]$ ] , where we remove the duplicates . of course",
    ", if any of these entries contains @xmath110 , we simply put @xmath110 .",
    "otherwise , the merge can be done in @xmath119 time due to the bound on lengths of @xmath122[\\phi_1]$ ] and @xmath123[\\phi_2]$ ] , and if the length of the result exceeds the bound @xmath105 , we replace it by @xmath110 .",
    "similarly as before , for every addition / removal of vertex @xmath55 to / from @xmath29 , or marking / unmarking @xmath55 as a pin , we can update table @xmath112 in @xmath124 time by following the path from @xmath56 to the root and recomputing the tables in the traversed nodes . also , @xmath112 can be initialized in @xmath125 time by processing the tree decomposition in a bottom - up manner and applying the formula for every node .",
    "note that updating / initializing table @xmath112 must be performed after updating / initializing tables @xmath15 and @xmath16 .",
    "we now move to the next query , namely finding a balanced @xmath29-separator . by lemma  [ lemma : halfhalf ] , as @xmath126 $ ] has treewidth at most @xmath4 , such a @xmath127-balanced @xmath29-separator of size at most @xmath128 always exists .",
    "we therefore implement the following query .",
    "let @xmath1 be a graph and @xmath129 .",
    "then a set @xmath130 is a balanced @xmath29-separator if and only if there exists a partition @xmath131 of @xmath132 , such that there is no edge between @xmath133 and @xmath134 for @xmath135 , and @xmath136 for @xmath137 .      [",
    "lem : comb - balanced-3coloring ] let @xmath138 be non - negative integers such that @xmath139 and @xmath140 for @xmath141 . then there exists a partition of these integers into three sets , such that sum of integers in each set is at most @xmath142 .    without loss of generality assume that @xmath143 , as otherwise the claim is trivial .",
    "we perform a greedy procedure as follows . at each time step of the procedure",
    "we have a number of sets , maintaining an invariant that each set is of size at most @xmath144 . during the procedure",
    "we gradually merge the sets , i.e. , we take two sets and replace them with their union .",
    "we begin with each integer in its own set .",
    "if we arrive at three sets , we end the procedure , thus achieving a feasible partition of the given integers .",
    "we therefore need to present how the merging step is performed .    at each step",
    "we choose the two sets with smallest sums of elements and merge them ( i.e. , replace them by their union ) . as the number of sets is at least @xmath145 ,",
    "the sum of elements of the two chosen ones constitute at most half of the total sum , so after merging them we obtain a set with sum at most @xmath144 .",
    "hence , unless the number of sets is at most @xmath146 , we can always apply this merging step .",
    "one of the implications is trivial : if there is a partition @xmath131 of @xmath147 with the given properties , then every connected component of @xmath147 must be fully contained either in @xmath148 , @xmath149 , or @xmath150 , hence it contains at most @xmath151 vertices of @xmath29 .",
    "we proceed to the second implication .",
    "assume that @xmath130 is a balanced @xmath29-separator of @xmath1 and let @xmath152 be connected components of @xmath147 . for @xmath153 , let @xmath154 .",
    "by lemma  [ lem : comb - balanced-3coloring ] , there exists a partition of integers @xmath155 into three sets , such that the sum of elements of each set is at most @xmath151 . if we partition vertex sets of components @xmath152 in the same manner , we obtain a partition @xmath131 of @xmath132 with postulated properties .",
    "lemma [ lem : balanced-3coloring ] shows that , when looking for a balanced @xmath29-separator , instead of trying to bound the number of elements of @xmath29 in each connected component of @xmath126\\setminus x$ ] separately , which could be problematic because of connectivity condition , we can just look for a partition of",
    "@xmath126 $ ] into four sets with prescribed properties that can be checked locally .",
    "this suggest the following definition of table @xmath156 .",
    "this @xmath157-tuple @xmath164 will be called the _ interface _ , and intuitively it encodes the interaction of a potential solution with the bag .",
    "observe that the set @xmath18 is not given in our graph directly but rather via connectivity information stored in table @xmath16 , so we need to be prepared also for all the possible signatures of the bag ; this is the reason why we introduce the interface on top of the signature .",
    "note however , that the number of possible pairs @xmath165 is at most @xmath166 , so for every bag @xmath31 we store @xmath166 entries .",
    "we proceed to the formal definition of what is stored in table @xmath156 . for a fixed signature @xmath36 of @xmath31 ,",
    "let @xmath167 be its extension , we say that partitioning @xmath168 of @xmath169 is an _ extension consistent _ with interface @xmath158 , if :          the query findsseparatorcan be realized in @xmath180 time by checking entries in the table @xmath181 , namely @xmath111[(\\emptyset,\\emptyset)][(\\emptyset,\\emptyset,\\emptyset,\\emptyset , m_1,m_2,m_3,x)]$ ] for all possible values @xmath182 and @xmath183 , and outputting the list contained in any of them that is not equal to @xmath28 , or @xmath28 if all of them are equal to @xmath28 .",
    "we now present how to compute entries of table @xmath156 for every node @xmath20 depending on the entries of children of @xmath20 .",
    "we consider different cases , depending of the type of node @xmath20 .",
    "for every case , we consider only signatures that are valid , as for the invalid ones we just put value @xmath28 .",
    "0.3 cm * case 1 : leaf node . *",
    "if @xmath20 is a leaf node then @xmath178[(\\emptyset,\\emptyset)][(\\emptyset,\\emptyset,\\emptyset,\\emptyset,0,0,0,0)]=\\emptyset$ ] , and all the other interfaces are assigned @xmath28 .",
    "0.3 cm    * case 2 : introduce node .",
    "* let @xmath20 be a node that introduces vertex @xmath55 , and @xmath57 be its only child .",
    "consider some signature @xmath36 of @xmath31 and an interface @xmath158 ; we would like to compute @xmath178[\\phi][\\psi]=l_i$ ] .",
    "let @xmath184 be natural intersections of @xmath185 with @xmath60 , respectively , that is , @xmath186 and @xmath187 .",
    "let @xmath188[\\phi'][\\psi']=l_j$ ] .",
    "we consider some sub - cases , depending on the alignment of @xmath55 in @xmath43 and @xmath164 .",
    "the cases with @xmath55 belonging to @xmath148 , @xmath149 and @xmath150 are symmetric , so we consider only the case for @xmath148 .    0.1 cm * case 2.1 : @xmath189 . * note that every extension consistent with interface @xmath164 is an extension consistent with @xmath190 after trimming to @xmath191 . on the other hand",
    ", every extension consistent with @xmath190 can be extended to an extension consistent with @xmath164 by adding @xmath55 to the extension of @xmath130 .",
    "hence , it follows that we can simply take @xmath192 .",
    "0.1 cm * case 2.2 : @xmath193 . *",
    "similarly as in the previous case , every extension consistent with interface @xmath164 is an extension consistent with @xmath190 after trimming to @xmath191 . on the other hand ,",
    "if we are given an extension consistent with @xmath190 , we can add @xmath55 to @xmath148 and make an extension consistent with @xmath164 if and only if @xmath55 is not adjacent to any vertex of @xmath149 or @xmath150 ; this follows from the fact that @xmath60 separates @xmath55 from @xmath69 , so the only vertices from @xmath194 , @xmath195 that @xmath55 could be possibly adjacent to , lie in @xmath60 .",
    "however , if @xmath55 is adjacent to a vertex of @xmath149 or @xmath150 , we can obviously put @xmath196 , as there is no extension consistent with @xmath164 : property that there is no edge between @xmath197 and @xmath198 is broken already in the bag .",
    "otherwise , by the reasoning above we can put @xmath192 .",
    "* case 3 : forget node .",
    "* let @xmath20 be a node that forgets vertex @xmath73 , and @xmath57 be its only child .",
    "consider some signature @xmath36 of @xmath31 , and some interface @xmath158 ; we would like to compute @xmath178[\\phi][\\psi]=l_i$ ] .",
    "let @xmath74 be the only extension of signature @xmath43 to @xmath60 that has the same extension as @xmath43 ; @xmath59 can be deduced by looking up which signatures are found valid in table @xmath16 in the same manner as in the forget step for computation of table @xmath16 .",
    "we consider three cases depending on alignment of @xmath73 in @xmath59 :    0.1 cm * case 3.1 : @xmath199 . *",
    "if @xmath73 is not in @xmath200 , then it follows that we may put @xmath201[\\phi'][\\psi']$ ] : extensions of @xmath164 consistent with @xmath164 correspond one - to - one to extensions consistent with @xmath190 .",
    "0.1 cm * case 3.2 : @xmath202 . *",
    "assume that there exist some extension @xmath168 consistent with @xmath164 .",
    "in this extension , vertex @xmath73 is either in @xmath197 , @xmath194 , @xmath195 , or in @xmath203 .",
    "let us define the corresponding interfaces :      if any of integers @xmath208 turns out to be negative , we do not consider this interface .",
    "it follows that for at least one @xmath209 there must be an extension consistent with @xmath190 : it is just the extension @xmath210 . on the other hand ,",
    "any extension consistent with any of interfaces @xmath211 is also consistent with @xmath164 .",
    "hence , we may simply put @xmath212[\\phi'][\\psi']$ ] , and append @xmath73 on the list in case @xmath213 .",
    "* case 4 : join node .",
    "* let @xmath20 be a join node and @xmath93 be its two children .",
    "consider some signature @xmath36 of @xmath31 , and an interface @xmath158 ; we would like to compute @xmath178[\\phi][\\psi]=l_i$ ] .",
    "let @xmath94 be a signature of @xmath95 and @xmath96 be a signature of @xmath97 .",
    "assume that there is some extension @xmath217 consistent with @xmath164 .",
    "define @xmath218 and @xmath219 for @xmath220 and @xmath221 ; note that @xmath222 for @xmath221 and @xmath223 .",
    "it follows that in @xmath224 , @xmath225 there are some extensions consistent with @xmath226 and @xmath227 , respectively  these are simply extension @xmath168 intersected with @xmath228 , respectively . on the other hand ,",
    "if we have some extensions in @xmath224 , @xmath225 consistent with @xmath226 and @xmath227 for numbers @xmath229 such that @xmath222 for @xmath221 and @xmath223 , then the point - wise union of these extensions is an extension consistent with @xmath230 .",
    "it follows that in order to compute @xmath114 , we need to check if for any such choice of @xmath229 we have non-@xmath28 entries in @xmath231[\\phi_1][(m_1,m_2,m_3,x , m^1_1,m^1_2,m^1_3,x^1)]$ ] and @xmath232[\\phi_2][(m_1,m_2,m_3,x , m^2_1,m^2_2,m^2_3,x^2)]$ ] .",
    "this is the case , we put the union of the lists contained in these entries as @xmath114 , and otherwise we put @xmath28 .",
    "note that computing the union of these lists takes @xmath233 time as their lengths are bounded by @xmath4 , and there is @xmath234 possible choices of @xmath229 to check .",
    "similarly as before , for every addition / removal of vertex @xmath55 to / from @xmath29 or marking / unmarking @xmath55 as a pin , we can update table @xmath156 in @xmath235 time by following the path from @xmath56 to the root and recomputing the tables in the traversed nodes .",
    "also , @xmath156 can be initialized in @xmath236 time by processing the tree decomposition in a bottom - up manner and applying the formula for every node .",
    "note that updating / initializing table @xmath156 must be performed after updating / initializing tables @xmath15 and @xmath16 .",
    "we now proceed to the next query .",
    "recall that at each point , the algorithm maintains the set @xmath237 of vertices marking components of @xmath126\\setminus ( x\\cup s)$ ] that have been already processed .",
    "a component is marked as processed when one of its vertices is added to @xmath237 .",
    "hence , we need a query that finds the next component to process by returning any of its vertices . as in the linear - time approximation algorithm",
    "we need to process the components in decreasing order of sizes , the query in fact provides a vertex of the largest component .    to implement the query",
    "we create a table similar to table @xmath16 , but with entry indexing enriched by subsets of the bag corresponding to possible intersections with @xmath130 and @xmath237 .",
    "formally , we store entries for every node @xmath20 , and for every signature @xmath238 , which is a quadruple of subsets of @xmath31 such that ( i ) @xmath239 , ( ii ) @xmath240 , ( iii ) @xmath241 .",
    "the number of such signatures is equal to @xmath242 .    for a signature @xmath238",
    ", we say that @xmath243 is the extension of @xmath43 if ( i ) @xmath167 is the extension of @xmath33 as in the table @xmath16 , ( ii ) @xmath244 and @xmath245 .",
    "we may now state what is stored in entry @xmath246[(s_i , u_i , x_i , f_i)]$ ] :    * if @xmath33 is invalid then we store @xmath28 ; * otherwise we store : * * an equivalence relation @xmath49 between vertices of @xmath247 , such that @xmath248 if and only if @xmath249 are connected in @xmath250 $ ] ; * * for every equivalence class @xmath251 of @xmath49 , an integer @xmath252 equal to the number of vertices of the connected component of @xmath250 $ ] containing @xmath251 , which are contained in @xmath41 , or to @xmath28 if this connected component contains a vertex of @xmath253 ; * * a pair @xmath254 , where @xmath255 is equal to the size of the largest component of @xmath250 $ ] not containing any vertex of @xmath253 or @xmath40 , while @xmath256 is any vertex of this component ; if no such component exists , then @xmath257 .",
    "clearly , query findnextpinmay be implemented by outputting the pair @xmath254 stored in the entry @xmath258[(\\emptyset,\\emptyset,\\emptyset,\\emptyset)]$ ] , or @xmath28 if this pair is equal to @xmath259 .",
    "we now present how to compute entries of table @xmath260 for every node @xmath20 depending on the entries of children of @xmath20 .",
    "we consider different cases , depending of the type of node @xmath20 .",
    "for every case , we consider only signatures @xmath261 for which @xmath33 is valid , as for the invalid ones we just put value @xmath28 .      * case 2 : introduce node .",
    "* let @xmath20 be a node that introduces vertex @xmath55 , and @xmath57 be its only child .",
    "consider some signature @xmath238 of @xmath31 ; we would like to compute @xmath246[\\phi]=(r_i,(m^i_k)_{k\\in r_i},(u_i , m_i))$ ] .",
    "let @xmath59 be a natural projection of @xmath43 onto @xmath60 , that is , @xmath262 .",
    "let @xmath263[\\phi']=(r_j,(m^j_k)_{k\\in r_j},(u_j , m_j))$ ] ; note that this entry we know , but entry @xmath246[\\phi]$ ] we would like to compute .",
    "we consider some sub - cases , depending on the alignment of @xmath55 in @xmath43 .",
    "0.1 cm * case 2.1 : @xmath264 . *",
    "if we introduce a vertex from @xmath265 , then the extension of @xmath43 is just the extension of @xmath59 plus vertex @xmath55 added to @xmath38 . if we consider the equivalence classes of @xmath70 , then these are equivalence classes of @xmath71 but possibly some of them have been merged because of connections introduced by vertex @xmath55 . as @xmath60 separates @xmath55 from @xmath69 , @xmath55 could only create connections between two vertices from @xmath266 .",
    "hence , we can obtain @xmath70 from @xmath71 by merging all the equivalence classes of vertices of @xmath267 adjacent to @xmath55 ; the corresponding entry in sequence @xmath268 is equal to the sum of entries from the sequence @xmath269 corresponding to the merged classes . if any of these entries is equal to @xmath28 , we put simply @xmath28 .",
    "if @xmath55 was not adjacent to any vertex of @xmath267 , we put @xmath55 in a new equivalence class @xmath251 with @xmath270 .",
    "clearly , we can also put @xmath271 .",
    "0.1 cm * case 2.2 : @xmath272 .",
    "* we perform in the same manner as in case 2.2 , with the exception that the new entry in sequence @xmath268 will be always equal to @xmath28 , as the corresponding component contains a vertex from @xmath253 .",
    "0.1 cm * case 2.3 : @xmath273 . * in this case we can simply put @xmath246[\\phi]=t_3[j][\\phi']$ ] as the extensions of @xmath43 and @xmath59 are the same with the exception of @xmath55 being included into @xmath274 and/or into @xmath42 , which does not influence information to be stored in the entry .",
    "* case 3 : forget node .",
    "* let @xmath20 be a node that forgets vertex @xmath73 , and @xmath57 be its only child .",
    "consider some signature @xmath238 of @xmath31 ; we would like to compute @xmath246[\\phi]=(r_i,(m^i_k)_{k\\in r_i},(u_i , m_i))$ ] .",
    "let @xmath243 be extension of @xmath43 .",
    "observe that there is exactly one signature @xmath275 of @xmath60 with the same extension as @xmath43 , and this signature is simply @xmath43 with @xmath73 added possibly to @xmath44 , @xmath40 , @xmath276 or @xmath277 , depending whether it belongs to @xmath42 , @xmath38 , @xmath274 , or @xmath253 .",
    "coloring @xmath59 may be defined similarly as in case of forget node for table @xmath16 ; we just need in addition to include @xmath73 in @xmath274 or @xmath253 if it belongs to @xmath130 or @xmath237 , respectively .",
    "let @xmath263[\\phi]=(r_j,(m^j_k)_{k\\in r_j},(u_j , m_j))$ ] .",
    "as the extensions of @xmath43 and @xmath59 are equal , it follows that we may take @xmath70 equal to @xmath71 with @xmath73 possibly excluded from its equivalence class .",
    "similarly , for every equivalence class @xmath278 we put @xmath279 equal to @xmath280 , where @xmath281 is the corresponding equivalence class of @xmath71 , except the class that contained @xmath73 which should get the previous number incremented by @xmath92 , providing it was not equal to @xmath28 .",
    "we also put @xmath271 except the situation , when we forget the last vertex of a component of @xmath282 $ ] : this is the case when @xmath73 is in @xmath267 and constitutes a singleton equivalence class of @xmath71 .",
    "let then @xmath283 be the corresponding entry in sequence @xmath284 .",
    "if @xmath285 , we simply put @xmath271 .",
    "else , if @xmath286 or @xmath287 , we put @xmath288 , and otherwise we put @xmath271 .      * case 4 : join node .",
    "* let @xmath20 be a join node and @xmath93 be its two children .",
    "consider some signature @xmath238 of @xmath31 ; we would like to compute @xmath246[\\phi]=(r_i,(m^i_k)_{k\\in r_i},(u_i , m_i))$ ] .",
    "let @xmath289 be a signature of @xmath95 and @xmath290 be a signature of @xmath97 .",
    "let @xmath291[\\phi_1]=(r_{j_1},(m^{j_1}_k)_{k\\in    r_{j_1}},(u_{j_1},m_{j_1}))$ ] and @xmath292[\\phi_2]=(r_{j_2},(m^{j_2}_k)_{k\\in    r_{j_2}},(u_{j_2},m_{j_2}))$ ] .",
    "note that equivalence relations @xmath293 and @xmath294 are defined on the same set @xmath247 .",
    "it follows from the definition of @xmath260 that we can put :    * @xmath70 to be the minimum transitive closure of @xmath295 ; * for every equivalence class @xmath251 of @xmath70 , @xmath279 equal to the sum of ( i ) numbers @xmath296 for @xmath297 , @xmath298 being an equivalence class of @xmath293 , and ( ii ) numbers @xmath299 for @xmath300 , @xmath301 being an equivalence class of @xmath294 ; if any of these numbers is equal to @xmath28 , we put @xmath302 ; * @xmath303 to be equal to @xmath304 or @xmath305 , depending whether @xmath306 or @xmath307 is larger ; if any of these numbers is equal to @xmath28 , we take the second one , and if both are equal to @xmath28 , we put @xmath308 .      similarly as before , for every addition / removal of vertex @xmath55 to / from @xmath29 , to / from @xmath130 , to / from @xmath237 , or marking / unmarking @xmath55 as a pin , we can update table @xmath260 in @xmath309 time by following the path from @xmath56 to the root and recomputing the tables in the traversed nodes .",
    "also , @xmath260 can be initialized in @xmath310 time by processing the tree decomposition in a bottom - up manner and applying the formula for every node .",
    "note that updating / initializing table @xmath260 must be performed after updating / initializing tables @xmath15 and @xmath16 .",
    "note that lemma  [ lemma : halfhalf ] guarantees that in fact @xmath311 $ ] contains a @xmath127-balanced separator of size at most @xmath128 .",
    "unfortunately , we are not able to find a separator with such a good guarantee on the sizes of the sides ; the difficulties are explained in section  [ sec : outline ] .",
    "instead , we again make use of the precomputed approximate tree decomposition to find a balanced separator with slightly worse guarantees on the sizes of the sides .    in the following",
    "we will also use the notion of a _ balanced separation_. for a graph @xmath1 , we say that a partition @xmath312 of @xmath313 is an @xmath314_-balanced separation of @xmath1 _ , if there is no edge between @xmath315 and @xmath49 , and @xmath316 .",
    "the _ order _ of a separation is the size of @xmath130 .",
    "clearly , if @xmath312 is an @xmath314-balanced separation of @xmath1 , then @xmath130 is an @xmath314-balanced separator of @xmath1 . by folklore",
    "[ see the proof of lemma  [ lem : halfhalfalg ] ] we know that every graph of treewidth at most @xmath4 has a @xmath317-balanced separation of order at most @xmath128 .",
    "[ [ expressing - the - search - for - a - balanced - separator - as - a - maximization - problem . ] ] expressing the search for a balanced separator as a maximization problem .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +      let @xmath1 be a graph , and @xmath318 be disjoint sets of terminals in @xmath1 .",
    "we say that a partition @xmath312 of @xmath313 is a _ terminal separation of @xmath1 of order @xmath105 _ , if the following conditions are satisfied :        pushed terminal separations are similar to important separators of marx  @xcite , and their number for fixed @xmath318 can be exponential in @xmath105",
    ". pushed terminal separations are useful for us because of the following lemma , that enables us to express finding a small balanced separator as a maximization problem , providing that some separator of a reasonable size is given .",
    "[ lem : c4vc ] let @xmath1 be a graph of treewidth at most @xmath4 and let @xmath324 be some separation of @xmath1 , such that @xmath325 . then there exists a partition @xmath326 of @xmath327 and integers @xmath328 with @xmath329 , such that if @xmath330 are @xmath331 $ ] and @xmath332 $ ] with terminals @xmath318 , then    * there exist a terminal separations of @xmath330 of orders @xmath328 , respectively ; * for any left - pushed terminal separation @xmath333 of order @xmath334 in @xmath335 and any right - pushed separation @xmath336 of order @xmath337 in @xmath338 , the triple @xmath339 is a terminal separation of @xmath1 of order at most @xmath128 with @xmath340 .    as the treewidth of @xmath1 is at most @xmath4 ,",
    "there is a separation @xmath312 of @xmath1 such that @xmath341 and @xmath342 by folklore [ see the proof of lemma  [ lem : halfhalfalg ] ] .",
    "let us set @xmath343 , @xmath344 and @xmath345 .",
    "observe that @xmath346 and @xmath347 are terminal separations in @xmath335 and @xmath338 of orders @xmath334 and @xmath337 , respectively , hence we are done with ( i ) .",
    "we proceed to the proof of ( ii ) .",
    "we claim that either @xmath358 , or @xmath359 .",
    "assume first that @xmath360 .",
    "observe that then @xmath361 .",
    "similarly , @xmath362 .",
    "the case when @xmath363 is symmetric . without loss of generality , by possibly flipping separation @xmath312 , assume that @xmath364 .",
    "let @xmath333 be any left - pushed terminal separation of order @xmath334 in @xmath335 and @xmath336 be any right - pushed terminal separation of order @xmath337 in @xmath338 . by the definition of being left- and",
    "right - pushed , we have that @xmath365 and @xmath366 . therefore , we have that @xmath367 and @xmath367 .",
    "the idea of the rest of the implementation is as follows .",
    "first , given an approximate tree decomposition of with @xmath233 in the data structure , in logarithmic time we will find a bag @xmath368 that splits the component @xmath18 in a balanced way .",
    "this bag will be used as the separator @xmath327 in the invocation of lemma  [ lem : c4vc ] ; the right part of the separation will consist of vertices contained in the subtree below @xmath368 , while the whole rest of the tree will constitute the left part .",
    "lemma  [ lem : c4vc ] ensures us that we may find some balanced separator of @xmath18 by running two maximization dynamic programs : one in the subtree below @xmath368 to identify a right - pushed separation , and one on the whole rest of the tree to find a left - pushed separation . as in all the other queries , we will store tables of these dynamic programs in the data structure , maintaining them with @xmath369 update times .      at the very beginning of the implementation of the query we read @xmath370 , which is stored in the entry @xmath371[(\\emptyset,\\emptyset)]$ ] . if it turns out that @xmath372 , we perform the following explicit construction . we apply a dfs search from @xmath23 to identify the whole @xmath18 ; note that this search takes @xmath373 time , as @xmath18 and @xmath29 are bounded linearly in @xmath4 .",
    "then we build subgraph @xmath311 $ ] , which again takes @xmath373 time .",
    "as this subgraph has @xmath233 vertices and treewidth at most @xmath4 , we may find its @xmath127-balanced separator of order at most @xmath128 in @xmath374 time using a brute - force search through all the possible subsets of size at most @xmath128 .",
    "this separator may be returned as the result of the query .",
    "hence , from now on we assume that @xmath375 .",
    "we first aim to identify bag @xmath368 in logarithmic time .",
    "the following lemma encapsulates the goal of this subsection .",
    "note that we are not only interested in the bag itself , but also in the intersection of the bag with of @xmath29 and @xmath18 ( defined as the connected component of @xmath30 containing @xmath23 ) . while intersection with @xmath29 can be trivially computed given the bag , we will need to trace the intersection with @xmath18 inside the computation .",
    "[ lem : tracing ] there exists an algorithm that , given access to the data structure , in @xmath376 time finds a node @xmath377 of the tree decomposition such that @xmath378 together with two subsets @xmath379 of @xmath368 such that @xmath380 and @xmath381 .",
    "the algorithm keeps track of a node @xmath20 of the tree decomposition together with a pair of subsets @xmath382 being the intersections of the bag associated to the current node with @xmath18 and @xmath29 , respectively .",
    "the algorithm starts with the root node @xmath383 and two empty subsets , and iteratively traverses down the tree keeping an invariant that @xmath52[(u_i , s_i)]\\geq |u|/2 $ ] .",
    "whenever we consider a join node @xmath20 with two sons @xmath93 , we choose to go down to the node where @xmath384[(u_{j_t},u_{j_t})]$ ] is larger among @xmath385 . in this manner , at each step @xmath52[(u_i , s_i)]$ ] can be decreased by at most @xmath92 in case of a forget node , or can be at most halved in case of a join node . as @xmath375 , it follows that the first node @xmath377 when the invariant @xmath52[(u_i , s_i)]\\geq |u|/2 $ ] ceases to hold , satisfies @xmath386[(u_{i_0},s_{i_0})]\\leq |u|/2 $ ] , and therefore can be safely returned by the algorithm .",
    "it remains to argue how sets @xmath387 can be updated at each step of the traverse down the tree .",
    "updating @xmath44 is trivial as we store an explicit table remembering for each vertex whether it belongs to @xmath29 .",
    "therefore , now we focus on updating @xmath18 .",
    "the cases of introduce and join nodes are trivial . if @xmath20 is an introduce node with son @xmath57 , then clearly @xmath388 .",
    "similarly , if @xmath20 is a join node with sons @xmath93 , then @xmath389 . we are left with the forget node .",
    "let @xmath20 be a forget node with son @xmath57 , and let @xmath390 .",
    "we have that @xmath391 or @xmath116 , depending whether @xmath392 or not .",
    "this information can be read from the table @xmath84 $ ] as follows :    * if @xmath84[(u_i\\cup \\{w\\},s_j)]=\\bot$ ] , then @xmath393 and @xmath116 ; * if @xmath84[(u_i , s_j)]=\\bot$ ] , then @xmath394 and @xmath391 ; * otherwise , both @xmath84[(u_i , s_j)]$ ] and @xmath84[(u_i\\cup \\{w\\},s_j)]$ ] are not equal to @xmath28 ; this follows from the fact that at least one of them , corresponding to the correct choice whether @xmath394 or @xmath393 , must be not equal to @xmath28 .",
    "observe that in this case @xmath73 is in a singleton equivalence class of @xmath84[(u_i\\cup      \\{w\\},s_j)]$ ] , and the connected component of @xmath73 in the extension of @xmath395 can not contain the pin @xmath23 .",
    "it follows that @xmath393 and we take @xmath116 .          in table",
    "@xmath396 we store entries for every node @xmath20 of the tree decomposition , for every signature @xmath36 of @xmath31 , and for every @xmath145-tuple @xmath397 , called again the _ interface _ , where        we proceed to the formal definition of what is stored in table @xmath396 .",
    "let us fix a signature @xmath36 of @xmath31 , and let @xmath167 be its extension .",
    "for an interface @xmath397 , we say that a terminal separation @xmath399 in @xmath47 $ ] with terminals @xmath400 is an _ extension consistent _ with interface @xmath397 if      then entry @xmath403[\\phi][\\psi]$ ] contains the pair @xmath404 where @xmath383 is the maximum possible @xmath405 among extensions consistent with @xmath164 , and @xmath406 is the corresponding set @xmath179 for which this maximum was attained , or @xmath28 if the signature @xmath43 is invalid or no consistent extension exists .",
    "we now present how to compute entries of table @xmath396 for every node @xmath20 depending on the entries of children of @xmath20 .",
    "we consider different cases , depending of the type of node @xmath20 .",
    "for every case , we consider only signatures that are valid , as for the invalid ones we just put value @xmath28 .      * case 2 : introduce node .",
    "* let @xmath20 be a node that introduces vertex @xmath55 , and @xmath57 be its only child .",
    "consider some signature @xmath36 of @xmath31 and an interface @xmath397 ; we would like to compute @xmath403[\\phi][\\psi]=(r_i , x^i_0)$ ] .",
    "let @xmath184 be natural intersections of @xmath185 with @xmath60 , respectively , that is , @xmath61 and @xmath407 .",
    "let @xmath408[\\phi'][\\psi']=(r_j , x^j_0)$ ] .",
    "we consider some sub - cases , depending on the alignment of @xmath55 in @xmath43 and @xmath164 . the cases with @xmath55 belonging to @xmath315 and @xmath49 are symmetric , so we consider only the case for @xmath315 .    0.1 cm * case 2.1 : @xmath189 .",
    "* note that every extension consistent with interface @xmath164 is an extension consistent with @xmath190 after trimming to @xmath191 . on the other hand",
    ", every extension consistent with @xmath190 can be extended to an extension consistent with @xmath164 by adding @xmath55 to the extension of @xmath130 .",
    "hence , it follows that we can simply take @xmath409 .",
    "0.1 cm * case 2.2 : @xmath410 . *",
    "similarly as in the previous case , every extension consistent with interface @xmath164 is an extension consistent with @xmath190 after trimming to @xmath191 . on the other hand ,",
    "if we are given an extension consistent with @xmath190 , then we can add @xmath55 to @xmath315 and make an extension consistent with @xmath164 if and only if @xmath55 is not adjacent to any vertex of @xmath49 ; this follows from the fact that @xmath60 separates @xmath55 from @xmath69 , so the only vertices from @xmath411 that @xmath55 could be possibly adjacent to , lie in @xmath60 .",
    "however , if @xmath55 is adjacent to a vertex of @xmath49 , then we can obviously put @xmath412 as there is no extension consistent with @xmath164 : property that there is no edge between @xmath315 and @xmath49 is broken already in the bag .",
    "otherwise , by the reasoning above we can put @xmath409 .",
    "* case 3 : forget node .",
    "* let @xmath20 be a node that forgets vertex @xmath73 , and @xmath57 be its only child .",
    "consider some signature @xmath36 of @xmath31 , and some interface @xmath397 ; we would like to compute @xmath403[\\phi][\\psi]=(r_i , x^i_0)$ ] .",
    "let @xmath74 be the only the extension of signature @xmath43 to @xmath60 that has the same extension as @xmath43 ; @xmath59 can be deduced by looking up which signatures are found valid in table @xmath16 in the same manner as in the forget step for computation of table @xmath16 .",
    "we consider two cases depending on alignment of @xmath73 in @xmath59 :    0.1 cm * case 3.1 : @xmath414 . *",
    "if @xmath73 is not in @xmath67 , then it follows that we may put @xmath415[\\phi'][\\psi']$ ] : extensions consistent with @xmath164 correspond one - to - one to extensions consistent with @xmath190 .",
    "0.1 cm * case 3.2 : @xmath214 . *",
    "assume that there exists some extension @xmath416 consistent with @xmath164 , and assume further that this extension is the one that maximizes @xmath405 .",
    "in this extension , vertex @xmath73 is either in @xmath417 , @xmath203 , or in @xmath411 .",
    "let us define the corresponding interfaces :      if @xmath421 turns out to be negative , we do not consider @xmath422 . for @xmath423 ,",
    "let @xmath424[\\phi'][\\psi_t]$ ] .",
    "it follows that for at least one @xmath425 there must be an extension consistent with @xmath190 : it is just the extension @xmath416 . on the other hand ,",
    "any extension consistent with any of interfaces @xmath426 is also consistent with @xmath164 .",
    "hence , we may simply put @xmath427 , and define @xmath428 as the corresponding @xmath429 , with possibly @xmath73 appended if @xmath430 . of course , in this maximum we do not consider the interfaces @xmath431 for which @xmath408[\\phi'][\\psi_t]=\\bot$ ] , and if @xmath408[\\phi'][\\psi_t]=\\bot$ ] for all @xmath423 , we put @xmath412 .",
    "* case 4 : join node .",
    "* let @xmath20 be a join node and @xmath93 be its two children .",
    "consider some signature @xmath36 of @xmath31 , and an interface @xmath397 ; we would like to compute @xmath403[\\phi][\\psi]=(r_i , x_0^i)$ ] .",
    "let @xmath94 be a signature of @xmath95 and @xmath96 be a signature of @xmath97 .",
    "assume that there is some extension @xmath416 consistent with @xmath164 , and assume further that this extension is the one that maximizes @xmath432 .",
    "define @xmath433 and @xmath219 for @xmath220 ; note that @xmath434 and @xmath223 .",
    "it follows that in @xmath224 , @xmath225 there are some extensions consistent with @xmath435 and @xmath436 , respectively  these are simply extension @xmath416 intersected with @xmath228 , respectively . on the other hand , if we have some extensions in @xmath224 , @xmath225 consistent with @xmath435 and @xmath436 for numbers @xmath437 such that @xmath223 , then the point - wise union of these extensions is an extension consistent with @xmath438 .",
    "it follows that in order to compute @xmath439 , we need to iterate through choices of @xmath437 such that we have non-@xmath28 entries in @xmath231[\\phi_1][(l , x , r , x^1)]=(r^{x^1}_{j_1},x^{j_1,x^1}_0)$ ] and @xmath232[\\phi_2][(l , x , r , x^2)]=(r^{x^1}_{j_1},x^{j_1,x^1}_0)$ ] , choose @xmath440 for which @xmath441 is maximum , and define @xmath442 .",
    "of course , if for no choice of @xmath440 it is possible , we put @xmath443 .",
    "note that computing the union of the sets @xmath444 for @xmath220 takes @xmath233 time as their sizes are bounded by @xmath4 , and there is @xmath445 possible choices of @xmath437 to check .",
    "similarly as before , for every addition / removal of vertex @xmath55 to / from @xmath29 or marking / unmarking @xmath55 as a pin , we can update table @xmath396 in @xmath446 time by following the path from @xmath56 to the root and recomputing the tables in the traversed nodes .",
    "also , @xmath396 can be initialized in @xmath447 time by processing the tree decomposition in a bottom - up manner and applying the formula for every node .",
    "note that updating / initializing table @xmath396 must be performed after updating / initializing tables @xmath15 and @xmath16 .",
    "the algorithm performs as follows .",
    "first , using lemma  [ lem : tracing ] we identify a node @xmath377 of the tree decomposition , together with disjoint subsets @xmath448 of @xmath368 , such that @xmath449 .",
    "let @xmath450 and @xmath451 .",
    "consider separation @xmath452 of @xmath311 $ ] and apply lemma  [ lem : c4vc ] to it .",
    "let @xmath453 be the partition of @xmath368 and @xmath454 be the integers with @xmath455 , whose existence is guaranteed by lemma  [ lem : c4vc ] .",
    "the algorithm now iterates through all possible partitions @xmath326 of @xmath368 and integers @xmath328 with @xmath329 .",
    "we can clearly discard the partitions where there is an edge between @xmath456 and @xmath457 . for a partition @xmath326 ,",
    "let @xmath330 be defined as in lemma  [ lem : c4vc ] for the graph @xmath311 $ ] . for a considered tuple @xmath458 , we try to find :    * a separator of a right - pushed separation of order @xmath337 in @xmath338 , and the corresponding cardinality of the right side ; * a separator of a left - pushed separation of order @xmath334 in @xmath335 , and the corresponding cardinality of the left side .    goal ( i ) can be achieved simply by reading entries @xmath459[(u_{i_0},s_{i_0})][(t_l , x_b , t_r , k')]$ ] for @xmath460 , and taking the right - pushed separation with the largest right side .",
    "we are going to present how goal ( ii ) is achieved in the following paragraphs , but firstly let us show that achieving both of the goals is sufficient to answer the query .",
    "observe that if for some @xmath326 and @xmath461 we obtained both of the separators , denote them @xmath462 , together with cardinalities of the corresponding sides , then using these cardinalities and precomputed @xmath370 we may check whether @xmath463 gives us a @xmath464-separation of @xmath311 $ ] . on the other hand , lemma  [ lem : c4vc ] asserts that when @xmath453 and @xmath465 are considered , we will find some pushed separations , and moreover any such two separations will yield a @xmath464-separation of @xmath311 $ ] .",
    "note that this is indeed the case as the sides of the obtained separation have cardinalities at most @xmath466 , since @xmath375 .",
    "we are left with implementing goal ( ii ) .",
    "let @xmath467 be @xmath335 with terminal sets swapped ; clearly , left - pushed separations in @xmath335 correspond to right - pushed separations in @xmath467 .",
    "we implement finding a right - pushed separations in @xmath467 as follows .",
    "let @xmath468 be the path from @xmath377 to the root @xmath383 of the tree decomposition .",
    "the algorithm traverses the path @xmath15 , computing tables @xmath469 $ ] for consecutive indexes @xmath470 .",
    "the table @xmath469 $ ] is indexed by signatures @xmath43 and interfaces @xmath164 in the same manner as @xmath396 .",
    "formally , for a fixed signature @xmath471 of @xmath472 with extension @xmath473 , we say that this signature is _ valid with respect to @xmath474 _ if it is valid and moreover @xmath475 . for an interface @xmath164",
    "we say that separation @xmath416 in @xmath476 $ ] with terminals @xmath400 is _ consistent with @xmath164 with respect to @xmath326 _ , if it is consistent in the same sense as in table @xmath396 , and moreover @xmath477 .",
    "then entry @xmath478[\\phi][\\psi]$ ] contains the pair @xmath404 where @xmath383 is the maximum possible @xmath405 among extensions consistent with @xmath164 with respect to @xmath326 , and @xmath406 is the corresponding set @xmath179 for which this maximum was attained , or @xmath28 if the signature @xmath43 is invalid with respect to @xmath474 or no such consistent extension exists .",
    "the tables @xmath469 $ ] can be computed by traversing the path @xmath15 using the same recurrential formulas as for table @xmath396 .",
    "when computing the next @xmath469 $ ] , we use table @xmath479 $ ] computed in the previous step and possible table @xmath396 from the second child of @xmath480 . moreover , as @xmath481 $ ] we insert the dummy table @xmath482[\\psi]$ ] defined as follows :      it is easy to observe that table @xmath484 exactly satisfies the definition of @xmath481 $ ] .",
    "it is also straightforward to check that the recurrential formulas used for computing @xmath396 can be used in the same manner to compute tables @xmath469 $ ] for @xmath485 .",
    "the definition of @xmath486 and the method of constructing it show , that the values @xmath487[(\\emptyset,\\emptyset)][(\\emptyset,\\emptyset,\\emptyset , x)]$ ] for @xmath488 , correspond to exactly right - pushed separations with separators of size exactly @xmath163 in the graph @xmath467 : insertion of the dummy table removes @xmath489 from the graph and forces the separation to respect the terminals in @xmath368 .",
    "let us conclude with a summary of the running time of the query .",
    "algorithm of lemma  [ lem : tracing ] uses @xmath376 time .",
    "then we iterate through at most @xmath490 tuples @xmath326 and",
    "@xmath461 , and for each of them we spend @xmath233 time on achieving goal ( i ) and @xmath446 time on achieving goal ( ii ) . hence",
    ", in total the running time is @xmath491 .",
    "ittai abraham , moshe babaioff , shaddin dughmi , and tim roughgarden .",
    "combinatorial auctions with restricted complements . in _ proceedings of the 13th acm conference on electronic commerce , ec 2012 _ , pages 316 , 2012 .",
    "karl  r. abrahamson and michael  r. fellows .",
    "finite automata , bounded treewidth and well - quasiordering .",
    "in n.  robertson and p.  seymour , editors , _ proceedings of the ams summer workshop on graph minors , graph structure theory , contemporary mathematics vol . 147 _ , pages 539564 .",
    "american mathematical society , 1993 .        per austrin , toniann pitassi , and yu  wu .",
    "inapproximability of treewidth , one - shot pebbling , and related layout problems . in anupam gupta , klaus jansen , jos d.  p. rolim , and rocco  a. servedio , editors , _ proceedings approx 2012 and random 2012 _ , volume 7408 of _ lecture notes in computer science _ , pages 1324 .",
    "springer verlag , 2012 .",
    "hans  l. bodlaender .",
    "dynamic programming algorithms on graphs with bounded tree - width . in timo lepist and arto",
    "salomaa , editors , _ proceedings of the 15th international colloquium on automata , languages and programming , icalp88 _ , volume 317 of _ lecture notes in computer science _ , pages 105119 .",
    "springer verlag , 1988 .",
    "hans  l. bodlaender .",
    "dynamic algorithms for graphs with treewidth 2 . in jan van leeuwen , editor , _ proceedings of the 19th international workshop on graph - theoretic concepts in computer science , wg93 _ , volume 790 of _ lecture notes in computer science _ , pages 112124 .",
    "springer verlag , 1994 .",
    "hans  l. bodlaender , marek cygan , stefan kratsch , and jesper nederlof . solving weighted and counting variants of connectivity problems parameterized by treewidth deterministically in single exponential time .",
    "report on arxiv 1211.1505 , 2012 .",
    "robert  f. cohen , s.  sairam , roberto tamassia , and j.  s. vitter .",
    "dynamic algorithms for optimization problems in bounded tree - width graphs . in giovanni",
    "rinaldi and laurence  a. wolsey , editors , _ proceedings of the 3rd conference on integer programming and combinatorial optimization , ipco93 _ , pages 99112 , 1993 .",
    "erik  d. demaine , fedor  v. fomin , mohammadtaghi hajiaghayi , and dimitrios  m. thilikos .",
    "subexponential parameterized algorithms on graphs of bounded genus and @xmath492-minor - free graphs .",
    ", 52:866893 , 2005 .",
    "michael elberfeld , andreas jakoby , and till tantau .",
    "logspace versions of the theorems of bodlaender and courcelle . in _ proceedings of the 51st annual symposium on foundations of computer science , focs 2010 _ , pages 143152 , 2010 .",
    "michael  r. fellows and michael  a. langston .",
    "an analogue of the myhill - nerode theorem and its use in computing finite - basis characterizations . in",
    "_ proceedings of the 30th annual symposium on foundations of computer science , focs89 _ , pages 520525 , 1989 .",
    "gary  l. miller and john reif .",
    "parallel tree contraction .",
    "part 1 : fundamentals . in s.",
    "micali , editor , _ advances in computing research 5 : randomness and computation _ , pages 4772 .",
    "jai press , greenwich , ct , 1989 .          rhilipped rinaudo , yann ponty , dominique barth , and alain denise .",
    "tree decomposition and parameterized algorithms for rna structure - sequence alignment including tertiary interactions and pseudoknots ( extended abstract ) . in benjamin  j. raphael and jijun tang , editors , _ proceedings of the 12th international workshop on algorithms in bioinformatics , wabi 2012 _ , volume 7534 of _ lecture notes in computer science _ , pages 149164 .",
    "springer verlag , 2012 ."
  ],
  "abstract_text": [
    "<S> we give an algorithm that for an input @xmath0-vertex graph @xmath1 and integer @xmath2 , in time @xmath3 either outputs that the treewidth of @xmath1 is larger than @xmath4 , or gives a tree decomposition of @xmath1 of width at most @xmath5 . </S>",
    "<S> this is the first algorithm providing a constant factor approximation for treewidth which runs in time single - exponential in @xmath4 and linear in @xmath0 .    </S>",
    "<S> treewidth based computations are subroutines of numerous algorithms . </S>",
    "<S> our algorithm can be used to speed up many such algorithms to work in time which is single - exponential in the treewidth and linear in the input size . </S>"
  ]
}