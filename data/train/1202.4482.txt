{
  "article_text": [
    "rational decision making by individual autonomous agents is typically formalized as maximizing a reward function via reinforcement learning @xcite .",
    "although questions remain concerning the choice of reward function , choice of optimization method , and how this approach relates ( if at all ) to human decision making , the reinforcement learning framework has been successfully applied to an enormous variety scientific and engineering problems .    in the closely related setting of a _ population _ of _ cooperating _",
    "agents we immediately encounter a basic question .",
    "what can one agent infer from the actions of another ?",
    "since some actions are invariably more important than others , communicating the relative importance of actions is crucial to effective cooperation .",
    "this paper shows , under fairly general assumptions , that taking metabolic costs into account causes agents to signal which of their actions are important and which are not .",
    "[ [ the - cortex - as - a - guided - self - organizing - system . ] ] the cortex as a guided self - organizing system .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the scenario we have in mind is the mammalian cortex , with agents corresponding to neurons .",
    "the cortex is a self - organized system of between about @xmath0 and @xmath1 neurons ( depending on the species ) that are guided by neuromodulators that signal pleasure , pain and other globally salient events .",
    "neurons communicate with each other via spiketrains  sequences of silences and spikes they receive from and transmit to @xmath2 to @xmath3 other neurons through connections called synapses .",
    "neurons learn by increasing and decreasing the efficacy of their synapses according to the timing of pre - synaptic ( input ) and post - synaptic ( output ) spikes , as well as the presence or absence of neuromodulators @xcite .",
    "the goal of the brain as a whole is to choose favorable actions for its organism in a great variety of situations .",
    "ultimately , responsibility for choosing the right action falls onto the neurons in the central nervous system .",
    "most neurons , however , interact with the environment extraordinarily indirectly  through millions or billions of other neurons  so the consequences for the organism of an individual neuron s actions are difficult to pin down . as a result",
    ", it is unclear when neurons should spike or what their spikes mean .    without further assumptions ,",
    "there is no way  _ even assuming neurons act optimally _ according to a known reward function  for another neuron to know which of its spiketrains are important and which are not since , for example , neurons can not access each other s inputs .",
    "in other words , without further assumptions there is no way for neurons to cooperate .",
    "[ [ overview - of - the - paper . ] ] overview of the paper .",
    "+ + + + + + + + + + + + + + + + + + + + + +    the key to distinguishing important from unimportant actions is that spikes and silences are not abstract , interchangeable symbols .",
    "spiking and responding to spikes carries a much higher metabolic cost than not spiking @xcite .",
    "this cost is significant since the nervous system consumes a disproportionate share of an organism s total energy budget @xcite .    in this paper",
    "we attempt to distill an essential feature of cortical computation  metabolic cost  and explore its implications for cooperative learning .",
    "formally , we consider agents that maximize rewards under metabolic constraints according to a free - energy principle following @xcite .",
    "our first result ,  [ s : inf - val ] , is that the effective information generated by an agent s actions , assuming it acts optimally , quantifies the expected subsequent reward .",
    "thus , it is not necessary to know an agent s reward function to compute the importance of its actions ; all that is needed is an accurate model of its policy .",
    "in fact , if an agent obeys a strong metabolic constraint , so that the relative frequency of its actions is tightly controlled , then both the effective information and expected reward of its actions couple tightly to metabolic cost . thus ,",
    "if all agents have the same metabolic cost profile and impose similarly strong constraints , it is possible to determine the relative importance of actions from their metabolic cost .",
    "this shows that metabolically constrained agents encode expected rewards into their outputs .",
    "intriguingly , this result may generalize to neurons in cortex , suggesting a novel approach to the neural code @xcite .    controlling the frequency of expensive actions ( spikes )",
    "also improves an agent s ability to estimate expected reward , ",
    "[ s : eve ] . in the asymptotic limit , where an agent samples from its environment exhaustively , there is no problem .",
    "however , over short time scales ( which are the norm in a rapidly reorganizing environment such as the brain ) , the expected reward does not necessarily coincide with the empirical reward estimate computed from a finite sample .",
    "it turns out that the higher the effective information generated by spikes , the more closely the empirical reward approximates the expected reward .",
    "finally ,  [ s : plasticity ] considers some implications of these results for cooperative learning .",
    "if expensive actions encode expected rewards , then agents that wish to cooperate should take advantage of this fact by privileging expensive actions in their reward functions .",
    "we introduce two minimal models of metabolically constrained learning agents whose reward functions privilege spikes .",
    "metabolic cost thus provides an organizing principle that tightly binds information , reward and approximation errors together .",
    "future work will investigate the interplay between metabolism and cooperation in more biologically realistic settings .",
    "[ [ acknowledgements . ] ] acknowledgements .",
    "+ + + + + + + + + + + + + + + + +    we thank yevgeny seldin and giulio tononi for useful discussions .",
    "[ [ unique - features - of - neurons - in - cortex . ] ] unique features of neurons in cortex .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the brain differs from many other populations of interacting agents in a number of key respects , two of which we mention here .",
    "first , by and large neurons do not die , nor are new neurons created ; the population is essentially stable .",
    "second , by and large neurons do not compete for resources , and `` successful '' neurons do not receive a significantly larger share of metabolic resources than `` unsuccessful '' neurons .",
    "we also wish to emphasize an important difference between our agents , which abstract certain features of cortical neurons , and `` agents in the wild '' .",
    "individual neurons have a negligible impact on what happens next in the brain : a single neuron has little effect the neurons it targets  each receiving inputs from thousands of other neurons  and even less effect on the rest of the brain .",
    "the inability of neurons to effectively manipulate their environment tremendously simplifies any optimization problems they may choose to solve ( by stripping out the recursive bellman aspect ) .",
    "thus , although the brain is in many ways extraordinarily complex , the problems faced by an individual neuron are simpler than those faced by autonomous agents , precisely because their ability to project power is extremely limited .",
    "[ [ neurons - as - agents . ] ] neurons as agents .",
    "+ + + + + + + + + + + + + + + + + +    the brain is modeled as a population of @xmath4 homogeneous agents , where each agent @xmath5 corresponds to a neuron .",
    "each agent follows its policy @xmath6 , where @xmath7 is the probability the agent picks action @xmath8 upon encountering situation @xmath9 .",
    "a situation is a vector @xmath10 whose entries are the actions of all the agents in the brain at the previous time step . since each neuron",
    "is only exposed to a small fraction of the brain , it ignores most entries in the vector , and so effectively the policy of agent @xmath5 is @xmath11 for some subset @xmath12 .",
    "let @xmath13 denote the probability over the situations @xmath14 , which we assume to be i.i.d .",
    "the population is exposed to a global _ neuromodulation signal _ @xmath15 that is used to communicate the performance of the population as a whole .",
    "the neuromodulation signal is drawn with probabilities @xmath16 , that is , depending on the current situation .",
    "agents are rewarded individually for their behavior using a _ reward function _",
    "@xmath17 which specifies the reward an agent obtains when it issues action @xmath18 being in situation @xmath19 and subsequently receives the neuromodulation signal @xmath20 . since individual neurons have little influence over their environment , we assume that the future situations experienced by the agent are unaffected by its output : @xmath21 where @xmath22 refers to time",
    ". clearly , this assumption fails at the population level  if populations of neurons had no effect on the brain state ( and therefore its actions ) there would be no point in them learning .",
    "nevertheless since , for example , destroying a single neuron makes essentially no difference to a brain s functioning , we argue that eq .   is a reasonable assumption _ at the individual neuron level . _",
    "the goal of any agent is to issue actions that maximize the time - averaged reward @xmath23 .",
    "define shorthand @xmath24.\\ ] ] for the expected reward conditional on a situation - action pair .",
    "[ [ spikes - are - metabolically - expensive . ] ] spikes are metabolically expensive .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    since spikes are more expensive than silences .",
    "we assume there is a function @xmath25 assigning a cost to each neuronal action , and that the reference distribution takes the form @xmath26 where @xmath27 is a positive , monotonically decreasing function chosen such that @xmath28 .",
    "agents take metabolic cost into account via a cost function penalizing deviations from the pre - specified relative action frequencies @xmath29 .",
    "if we interpret information content as resource costs , then @xmath30 measures the average extra cost the neuron pays for producing action @xmath18 with frequency @xmath31 instead of frequency @xmath32 in situation @xmath19 .",
    "we will often consider the case where neurons have two outputs : silence and a single spike . in this case",
    "we fix metabolic prior @xmath33 we will also often use the notation @xmath34 for silence and @xmath35 for a spike .",
    "[ [ the - effective - information - generated - by - an - action . ] ] the effective information generated by an action .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    to understand what agents can and do say to one another using their actions , it is useful to consider an agent as a _ communication channel _ mapping situations to actions following @xcite .",
    "the information transferred by an agent on average is the mutual information @xmath36 .",
    "however , since we are interested in the information transferred by specific actions , we introduce effective information @xcite .",
    "@xmath37 +   [ d : ei ] given an agent with policy @xmath31 and prior @xmath38 on situations , the _ effective information _ generated by action @xmath39 is @xmath40          \\,\\,\\,\\text { where } \\pi(s|a):=\\frac{\\pi(a|s)}{p(a)}\\cdot p(s),\\ ] ] and @xmath41 $ ] is the kullback - leibler divergence @xmath42:=\\sum p_i\\log\\frac{p_i}{q_i}$ ] .",
    "the expected effective information generated by an agent is mutual information : @xmath43=i_\\pi({{\\mathcal s}},{{\\mathcal a}})$ ] .",
    "effective information quantifies the information gained about @xmath14 by updating prior @xmath44 to posterior @xmath45 via bayes rule .",
    "given policy @xmath46 , effective information associates a non - negative scalar to each action available to the agent : @xmath47    an alternate approach to quantifying information transfer is local transfer entropy @xcite , which ( roughly ) computes the information transferred by a situation - action pair . since in our setup",
    "an agent only communicates actions to other agents  and not the situations causing the actions  we average over situations to obtain effective information .",
    "inspired by ideas from thermodynamics a number of authors have recently investigated the effects of information - theoretic constraints on optimization problems @xcite .",
    "this section adapts these ideas to investigate how metabolically constraining reward - maximization impacts the information content of actions .",
    "the goal of each agent is to maximize expected reward , as quantified by @xmath48 .",
    "since agents take metabolic cost into account , we introduce the following optimization problem :    @xmath37 +   [ d : opt - prob ] the optimal policy solves the constrained optimization problem @xmath49\\ ] ]    parameter @xmath50 controls the relative weight given to the reward and metabolic cost .    @xmath37 +   [ t : optimal ] the optimal policy @xmath51 , minimizing , satisfies @xmath52 where @xmath53 is the normalization constant .",
    "see appendix .",
    "theorem  [ t : optimal ] is important because it explicitly describes how the optimal policy encodes rewards into decisions .",
    "however , it is not reward but rather _ relative reward _ that determines an agents actions :    @xmath37 +   for a given @xmath50 , let the relative reward of action @xmath18 in situation @xmath19 be @xmath54    the definition is motivated by the following lemma :    * minimizing free energy with respect to rewards @xmath55 and relative rewards @xmath56 yields the same optimal policy @xmath57 * the optimal policy has functional form @xmath58    if an agent find itself in situation @xmath19 , it is the difference @xmath59 that determines which action it chooses . adding constant @xmath60 and @xmath61 makes no difference to the actions of an optimal agent since , by the assumption in eq .",
    ", individual agents can not affect the probability of situations arising in the future .",
    "the lemma says ( optimal ) agents only care about the _ relative reward _ of actions , rather than their absolute reward .",
    "@xmath37 +   [ d : importance ] the _ importance _ of action @xmath18 is the expected relative reward : @xmath62=\\sum_{s\\in{{\\mathcal s}}}\\pi(s|a)\\cdot \\bar{{{r}}}(s , a).\\ ] ]    we introduce definition  [ d : importance ] to avoid repeatedly using the cumbersome phrase `` expected relative reward '' .",
    "@xmath37 +   [ t : embed ] for an optimal policy @xmath51 , effective information quantifies the importance of an action up to a metabolic discrepancy term : @xmath63}_{\\text{expected relative reward } }          + \\underbrace{\\log \\frac{p(a)}{\\pi^*(a)}}_{\\text{metabolic discrepancy}}.\\ ] ]    writing out the definition yields @xmath64 by theorem  [ t : optimal ] , the optimal policy satisfies @xmath65 , so @xmath66          + \\log \\frac{p(a)}{\\pi^*(a)}.      \\end{aligned}\\ ] ]    theorem  [ t : embed ] is our first main result .",
    "it says that , if the frequency of actions under policy @xmath46 coincides with the metabolic prior @xmath29 , then the importance of an ( optimal ) agent s actions coincides with the effective information it generates .",
    "[ [ a - strong - metabolic - constraint . ] ] a strong metabolic constraint .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    agents `` in the wild '' , such as organisms interacting with potentially hostile environments , are forced to take or not take specific actions to avoid death .",
    "in such a scenario , there is no reason to expect a tight relationship between effective information and importance , and the metabolic discrepancy is likely to be quite large . unlike agents `` in the wild '' , neuron - like agents in cortex - like environments",
    "do not face life - or - death situations .",
    "their actions are a means of communication , and only indirect influence global outcomes .",
    "there is therefore more freedom to constrain the policies of agents since costs apply directly and neuromodulatory signals are highly indirect .",
    "let us consider the consequences of taking metabolic costs into account _ strongly _",
    "@xmath67 where @xmath68 and @xmath69 for optimal policy @xmath51 . section ",
    "[ s : plasticity ] presents two learning algorithms whose policies satisfy assumption  [ a : strongprior ] .    by theorem  [ t :",
    "embed ] , effective information quantifies the importance of actions by an optimal agent , to the extent that the frequency of its actions coincides with the metabolically determined reference distribution @xmath70 . to compute effective information , it is necessary to observe how an agent responds to different situations .",
    "neurons in the brain do not have access to each other s inputs , so computing effective information is difficult .",
    "fortunately , the next theorem shows that neurons do not need to compute the effective information generated by other neurons :    @xmath37 +   [ t : inf - cost ] suppose @xmath51 is an optimal policy for an agent satisfying assumption [ a : strongprior ] . in the deterministic limit @xmath71 , for all @xmath39",
    ", we have @xmath72}_{\\text{expected relative reward } }           = \\underbrace{\\log\\big(\\lambda\\circ c(a)\\big)}_{f(\\text{metabolic cost})}.\\ ] ]    for a deterministic policy , @xmath73 , which equals @xmath74 , see paragraph after eq .  .",
    "effective information equals importance by theorem  [ t : embed ] .",
    "the theorem says that , so long as agents share a common metabolic cost profile , effective information and importance are aligned throughout the population . as a corollary we obtain that ,",
    "so long as spikes are infrequent , relative reward is almost entirely concentrated on spikes and so silences can be ignored :    @xmath37 +   [ t : conc - rew ] suppose an agent has two actions ( silence @xmath34 and spike @xmath35 ) and satisfies assumption  [ a : strongprior ] .",
    "then the relative reward after all actions by the agent is approximately the relative reward after spiking alone : @xmath75 = \\pi(a_1)\\cdot { { \\mathbb e}}\\big[\\bar{r}_{\\pi^*}(s , a_1)\\big ]          + o\\left(\\pi(a_1)^2\\right).\\ ] ]    theorem  [ t : conc - inf ] in appendix  [ s : mi - ei ] shows that @xmath76 the corollary follows after observing that @xmath77 and , similarly , @xmath78=\\sum_{a\\in{{\\mathcal a}}}\\pi^*(a)\\cdot{{\\mathbb e}}\\big[\\bar{r}_{\\pi^*}(s , a)\\big]$ ] .",
    "theorem  [ t : inf - cost ] is our second main result .",
    "it says that when an agent strongly controls the frequency of its actions via the metabolic prior , assumption  [ a : strongprior ] , the information generated by its actions coincides _ exactly _ with their importance , which also couples tightly with their metabolic cost .",
    "moreover , by corollary  [ t : conc - rew ] , agents do not lose much by only attending to the spikes produced by other agents and ignoring the silences .",
    "this suggests agents in a population sharing a common metabolic cost profile can use metabolic cost to distinguish between more and less important actions by their neighbors .",
    "we have referred to a policy s _ expected reward _ throughout this paper . however , the expected distribution of rewards is not known ; agents can only access empirical estimates based on finite samples . in a dynamically changing environment like the cortex",
    ", it is important that neurons revise their estimates over short time frames  i.e. accurately estimate expected reward from small samples .",
    "guaranteeing the accuracy of an agent s estimate of its expected reward is critical , since the estimate determines the agent s policy .",
    "this section uses effective information to bound the difference between expected reward and its empirical estimate . in short : the tighter the metabolic constraint ",
    "i.e. the fewer the set of situations for which an agent spikes  the better the quality of its empirical reward estimate .",
    "we consider expected and empirical rewards _ after spiking _ since we are interested in the _ expected relative reward encoded in spikes_. many models of neuronal learning use correlations between spikes or the relative timing of spikes to control synaptic ( de)potentation , so that it is rewards after ( or just before ) output spikes that determine a neuron s policy @xcite .",
    "restricting attention to rewards after spiking also provides a mechanism that forces neurons to specialize by focusing on a narrow band in their input stream .    the expected and empirical rewards _ per spike",
    "_ are @xmath79 : = \\sum_{s , n}\\pi(s|a_1)\\cdot p(n|s)\\cdot{{r}}(s , a_1,n )      \\text { and}\\\\      \\hat{{{r}}}_\\pi:= \\frac{1}{t_1}\\sum_{\\{(s_t , n_t)|\\pi(s_t)=1\\ } } { { r}}\\big(s_t , a_1,n_t\\big)\\text { respectively},\\end{gathered}\\ ] ] where @xmath80 counts spikes produced by the agent during @xmath81 $ ] .",
    "let us introduce notation for computations with respect to the _ uniform prior _ @xmath82 , where @xmath83 is the total number of possible situations .",
    "let @xmath84 , @xmath85 , and @xmath86 .",
    "note that @xmath87 recovers the original definition of effective information in @xcite , which definition  [ d : ei ] generalizes .",
    "the following theorem is proved using a version of occam s razor due to seldin and tishby @xcite . without loss of generality",
    "we assume that rewards lie in @xmath88 $ ] .",
    "since only relative rewards affect the choice of optimal policy , it follows that negative rewards can be stripped out of the optimization problem by introducing an additive constant .",
    "@xmath37 +   [ t : vcr ] suppose the agent chooses a deterministic policy @xmath46 under the constraint that it spikes for a fixed fraction of situations : @xmath89 .",
    "further , suppose that situations are sampled i.i.d .",
    "then with probability at least @xmath90 , @xmath91    see appendix .",
    "the theorem implies that policies with high @xmath87 have better guarantees on their reward estimates than those with low @xmath87 since @xmath92 decreases as @xmath93 increases .    for an agent to implement the metabolic prior",
    ", it must constrain the fraction of situations @xmath94 in which it spikes .",
    "although @xmath95 , it is nevertheless the case that @xmath96 and @xmath87 covary since increasing the number of situations where an agent spikes decreases _ both _ @xmath96 and @xmath87 ; similarly , decreasing the number of situations where an agent spikes increases both @xmath96 and @xmath87 .",
    "figure  [ f : ei - bound]a plots the effective information generated by spiking against the difference between the normalized empirical and expected reward .",
    "rewards functions of the form @xmath97 were drawn randomly and the expected and empirical error for 16,000 deterministic policies with @xmath98 , @xmath38 uniform and @xmath99 were computed .",
    "policies were sampled randomly with @xmath5 , the number of situations causing the policy to spike , varying uniformly across @xmath100 $ ] .",
    "the figure shows that both normalized error and the standard error of the error decrease as @xmath96 increases .",
    "figure  [ f : ei - bound]a thus confirms that the bound in theorem  [ t : vcr ] is a reasonable guide to performance in practice .",
    "the assumption that inputs are i.i.d . is not realistic for a system of interacting agents such as cortex .",
    "we make two remarks .",
    "first , if rewards are only non - zero in the presence of neuromodulatory signals , then the assumption is more reasonable since it states that situations directly preceding neuromodulator release are i.i.d .",
    "second , similar results have recently been obtained for non - i.i.d .",
    "scenarios using pac - bayes methods @xcite  and these may be applicable to our setting .    theorem  [ t : vcr ] and the experiments in fig .",
    "[ f : ei - bound]a are our third main result .",
    "they show that the higher the effective information generated by spiking , the better an agent s empirical estimate of its expected reward after spiking .",
    "the metabolic prior , assumption  [ a : strongprior ] , thus controls the quality of an agent s empirical estimates of its expected reward .",
    "the previous sections showed that metabolically constrained agents spike in the few situations that , on the basis of their historical experience , most frequently lead to high rewards .",
    "this suggests cooperating agents should treat each other s spikes as _ intrinsically valuable_.    @xmath37 +   consider reward function @xmath101 where @xmath102 is the total number of spikes in the input , @xmath103 is the number of spikes in the output , and @xmath20 is the neuromodulatory signal .",
    "the motivation for [ e : reward ] is as follows .    1",
    ".   neuromodulatory signal @xmath20 controls the sign of the reward .",
    "positive signals are reinforced and negative avoided .",
    "2 .   agents reinforce or punish their decisions only if they actively contribute to the global outcome .",
    "active contributions are distinguished by their higher metabolic cost .",
    "term @xmath103 , which is either 0 or 1 , therefore gates the reward function . 3 .   an individual agent spiking in isolation can not impact global outcomes . a simple estimate of the impact of a _ population _ of agents is the number that spike .",
    "the _ amplitude _",
    "@xmath102 of the reward therefore reflects local spiking activity : the more spikes there are , the more likely it is that the agent belongs to a population that impacted global behavior .",
    "term @xmath102 therefore amplifies local rewards according to their likely global impact .",
    "note that learning under reward function [ e : reward ] is a population - level phenomenon due to the @xmath102 term .",
    "thus , although individual agents are unable to affect their environment , reward function [ e : reward ] encourages them to behave _ as if _ they are responsible for global outcomes , by taking responsibility for neuromodulatory signals proportionally to the size of the local spiking population they belong to .",
    "an impractical  but nonetheless instructive  learning algorithm that implements reward function [ e : reward ] is the following .",
    "@xmath37 +   [ eg : brute ] given @xmath104 , let @xmath105 .",
    "+ algorithm :    1 .",
    "samples reward estimates @xmath106 .",
    "rank elements of @xmath107 and compute @xmath108 .",
    "the optimal policy is @xmath109    brute - force optimization can be visualized as moving a window of fixed size and variable shape over the input space , searching for the configuration that maximizes reward .",
    "it implements the optimization @xmath110\\\\",
    "\\text{subject to:}&\\sum_{s}\\pi(a_1|s)\\cdot p(s)=p(a_1).\\end{aligned}\\ ] ]    reward function [ e : reward ] ensures the agent only has to search over rewards after spiking , i.e. those of the form @xmath111 , @xmath112 .    an important question , motivated by the result following from assumption  [ a : strongprior ] , is how a strong metabolic constrain affects the encoding of rewards into spikes .",
    "the expected reward ( _ not _ importance ) after spiking is @xmath113.\\ ] ]    the expected reward compresses a large amount of data  specifically , the structure of distributions @xmath114 and @xmath115  into a single number . figure  [ f : ei - bound]b shows an example , where situations are ranked according to expected reward and the policy spikes for the 15% of situations with highest reward . by construction the expected reward after spiking is much higher than after silence , so spikes encode reward . tightening the metabolic constraint , so that the policy spikes for @xmath116 of situations , increases the reward after spiking .",
    "furthermore , the variance in reward after spiking is much lower than after not spiking and , once again , tightening the metabolic constraint will tend to further decrease the variance after spiking .    thus , under tight metabolic constraints , the spikes produced by brute - force optimized policies are robust signals of high expected reward",
    ".    more generally , consider two scenarios :    * if the rewards are distributed evenly over @xmath108 , i.e. @xmath117 for all @xmath118 , then spikes are robust predictors of rewards . * if high rewards concentrate on a small subset @xmath119 of @xmath108 , i.e. @xmath120 for @xmath121 and @xmath122 , then rewards after spiking are more variable .",
    "the first scenario is preferable when agents use spikes as local estimates of expected reward : variance should be as low as possible .",
    "a simple way to ensure evenly distributed rewards after spiking is to keep @xmath108 small by forcing low @xmath123 , which ties in with the results on empirical estimates in ",
    "[ s : eve ] .",
    "brute - force optimization separates exploration and exploitation into two distinct steps . a `` softer '' algorithm that becomes more certain as it acquires more data is a modified version of @xmath124-learning @xcite",
    ":    @xmath37 +   [ eg : mq ] if the agent chooses action @xmath18 in situation @xmath19 and subsequently receives neuromodulator @xmath20 , then it updates the @xmath124-matrix by @xmath125,\\ ] ] where @xmath126 controls the rate . after updating @xmath124",
    ", the agent constructs new policy @xmath127 operation @xmath128 renormalizes the policy twice : first by @xmath129 chosen such that @xmath130 for all @xmath18 , and then by @xmath131 chosen such that @xmath132 for all @xmath19 . setting @xmath133 yields a policy that approximately implements the metabolic constraint .",
    "figure  [ f : ei - ev ] considers how effective information and expected reward covary as agents @xmath124-learn .",
    "we initialized 5000 @xmath124-learning agents with @xmath134 for @xmath135 .",
    "as the agents adapt , their policies tend to become more both more deterministic and more likely to spike in situations yielding higher rewards , so as agents adapt they both generate more effective information and more rewards after spiking .",
    "the tighter the metabolic constraint ( i.e. the lower @xmath136 ) , the higher the expected reward after spiking .",
    "thus , effective information provides a reliable guide to expected reward , even in the presence of a strong metabolic constraint .    under metabolic @xmath124-learning ,",
    "term @xmath102 in reward function [ e : reward ] uses the degree of local consensus to control the speed with which an agent learns .",
    "an important point is that both brute - force optimization and @xmath124-learning are not practical learning rules ; they simply construct lookup tables .",
    "in contrast , cortical neurons do not control the probability of spiking for individual inputs  but rather for individual synapses .",
    "when a neuron potentiates a synapse , its response to many inputs is altered .",
    "neurons thus generalize in a manner that depends on the structure of their dendritic tree .",
    "this section presented two simple implementations of metabolically constrained learning that privileges spikes .",
    "future work will investigate how populations of such learners behave .",
    "the space of possible policies that the cortex as a whole could implement is _ vast _ : it consists of millions or billions of agents each receiving inputs from thousands or tens of thousands of other agents . cutting down the size of the search space is crucial .",
    "this paper has shown that maximizing reward under strong metabolic constraints leads to a tight coupling between the metabolic cost , information content and importance of actions .",
    "this suggests that it may be useful to focus the attention of agents by _ privileging spikes _ during learning .    in summary",
    ":    1 .   agents attempt to maximize their expected reward , constrained by the metabolic cost of their actions .",
    "+ [ definition  [ d : opt - prob ] , assumption  [ a : strongprior ] ] 2 .",
    "if an agent behaves optimally then the information generated by its actions aligns with both their importance and their metabolic cost .",
    "+ [ theorem  [ t : embed ] , theorem  [ t : inf - cost ] ] 3 .",
    "the less frequently an agent uses expensive actions , the better its empirical reward aligns with importance .",
    "+ [ theorem  [ t : vcr ] , figure  [ f : ei - bound]a ] 4 .",
    "the total contribution of metabolically inexpensive actions is negligible .",
    "+ [ corollary  [ t : conc - rew ] ] 5 .   if agents share a common metabolic cost profile , then it is obvious which actions predict high reward + [ spikes , with high confidence ] 6 .",
    "_ therefore _ , agents in a cooperating population should treat costly inputs and outputs ( spikes ) as intrinsically valuable .",
    "+ [ e.g. reward function  [ e : reward ] , figure  [ f : ei - ev ] ]    an intriguing analogy is that spikes form a cortical currency which neurons use to communicate estimates of future rewards .",
    "if neurons spike too frequently , then the reward encoded in spikes drops , analogously to how inflation degrades the worth of a currency .",
    "money provides a measure of importance that agents in a market economy use to guide their behavior .",
    "if all goes well , agents with consistently contribute to the global good by performing strictly local optimizations .",
    "spikes , and more generally metabolically expensive actions , thus provide local guidelines that a populations of cooperating agents can exploit during learning",
    ".    rewarding spikes introduces a tendency towards runaway spiking ( e.g. epileptic seizures ) which needs to be controlled .",
    "lateral inhibition , which we have not discussed in this paper , is a mechanism to impose sparse activity in the brain @xcite that may play a useful role in other cooperating populations .",
    "imposing the metabolic constraint requires active effort . in the case of biological neurons",
    "it has been proposed that controlling synaptic efficacies , and so the tendency of neurons to spike , is a function of slow - wave sleep @xcite .",
    "recent experiments have found evidence in line with this hypothesis , see @xcite .",
    "the results in this paper depend on specific assumptions and model choices .",
    "however , we believe these can be relaxed without substantially changing the main message . future work will investigate the computational role of spike - timing dependent learning in cortex @xcite from this perspective , to better understand how neurons encode information and rewards into spikes .",
    "10 [ 1][#1 ]    sutton rs , barto ag : _ reinforcement learning : an introduction_. mit press 1998 .",
    "russell s , norvig p : _ artificial intelligence : a modern approach_. prentice hall , 3rd edition 2009 .",
    "dan y , poo mm : * spike timing - dependent plasticity : from synapse to perception .",
    "* _ physiol rev _ 2006 , * 86*(3):10331048 .",
    "pawlak v , wickens jr , kirkwood a , kerr jnd : * timing is not everything : neuromodulation opens the stdp gate*. _ front .",
    "syn . neurosci _ 2010 ,",
    "* 2*(146 ) .",
    "hasenstaub a , otte s , callaway e , sejnowski tj : * metabolic cost as a unifying principle governing neuronal biophysics*. _ proc natl acad sci u s a _ 2010 , * 107*(27):1232934 .",
    "attwell d , laughlin sb : * an energy budget for signaling in the grey matter of the brain*. _ j cereb blood flow metab _ 2001 , * 21*(10):113345 .",
    "tishby n , pereira f , bialek w : * the information bottleneck method*. in _ proc . of the 37-th annual allerton conference on communication , control and computing_. edited by hajek b , sreenivas r , university of illinois press 1999 .",
    "tishby n , polani d : * information theory of decisions and actions*. in _ perception - reason - action_. edited by vassilis , hussain , taylor , springer 2011 .",
    "ortega pa , braun da : * information , utility and bounded rationality*. _ the fourth conference on artificial general intelligence _ 2011 , : 269274 .",
    "rieke f , warland d , de  ruyter  van steveninck r , bialek w : _ spikes : exploring the neural code_. mit press 1997 .",
    "langford j , zhang t : * the epoch - greedy algorithm for contextual multi - armed bandits*. in _ advances in neural information processing systems _ 2007 .",
    "klyubin as , polani d , nehaniv cl : * representations of space and time in the maximization of information flow in the perception - action loop*. _ neural comp _ 2007 , * 19*(9):23872432 .",
    "balduzzi d , tononi g : * integrated information in discrete dynamical systems : motivation and theoretical framework .",
    "* _ plos comput biol _ 2008 , * 4*(6):e1000091 .",
    "balduzzi d , tononi g : * qualia : the geometry of integrated information*. _ plos comput biol _ 2009 , * 5*(8):e1000462 .",
    "lizier jt , prokopenko m , zomaya ay : * local information transfer as a spatiotemporal filter for complex systems*. _ phys rev e _ 2008 , * 77*(2 pt 2):026110 .",
    "song s , miller kd , abbott lf : * competitive hebbian learning through spike - timing - dependent synaptic plasticity*. _ nature neuroscience _ 2000 , * 3*(9 ) .",
    "seldin y , tishby n : * multi - classification by categorical features via clustering*. in _ proceedings of the 25th international conference on machine learning _ 2008 .",
    "rubin j , shamir o , tishby n : * trading value and information in mdps*. in _ decision making with imperfect decision makers_. edited by guy tv , krn m , wolpert d , springer 2011 .",
    "balduzzi d : * falsification and future performance*. in _ proceedings of solomonoff 85th memorial conference _ ,",
    "lnai , springer in press .",
    "watkins c , dayan p : * q - learning*. _ machine learning _ 1992 , * 8*:279292 .",
    "selfridge og : * pandemonium : a paradigm for learning*. in _ mechanisation of thought processes : proceedings of a symposium held at the national physics laboratory _ 1958 .",
    "olshausen ba , field dj : * sparse coding with an overcomplete basis set : a strategy employed by v1 ? * _ vision res _ 1997 , * 37*(23):331125 .",
    "olshausen ba , field dj : * sparse coding of sensory inputs*. _ curr opin neurobiol _ 2004 , * 14*(4):4817 .",
    "tononi g , cirelli c : * sleep and synaptic homeostasis : a hypothesis*. _ brain res . bull .",
    "_ 2003 , * 62*:143150 .",
    "gilestro gf , tononi g , cirelli c : * widespread changes in synaptic markers as a function of sleep and wakefulness in drosophila*. _ science _ 2009 , * 324*(5923):10912 .    vyazovskiy vv , olcese u , lazimy y , faraguna u , esser sk , williams jc , cirelli c , tononi g : * cortical firing and sleep homeostasis*. _ neuron _ 2009 , * 63*(6):86578 .",
    "maret s , faraguna u , nelson ab , cirelli c , tononi g : * sleep and waking modulate spine turnover in the adolescent mouse cortex .",
    "* _ nat neurosci _ 2011 , * 14*(11):14181420 .",
    "klampfl s , legenstein r , maass w : * spiking neurons can learn to solve information bottleneck problems and extract independent components .",
    "* _ neural comput _ 2009 , * 21*(4):911959 .",
    "[ t : optimal].@xmath37 +   _ the optimal policy satisfies @xmath137 where @xmath53 is the normalization constant .",
    "_    the proof is adapted from the information bottleneck method in @xcite .",
    "let @xmath138 be lagrange multipliers , and consider @xmath139 the derivative with respect to @xmath31 is @xmath140          -\\beta\\sum_r p(s)p(r|a , s){{r}}(s , a , r)-\\beta\\lambda(s).\\ ] ] we have that @xmath141 because @xmath13 does not depend on the choice of policy by the assumption in eq .  .",
    "rewrite the derivative as @xmath142\\ ] ] and solve for zero to obtain @xmath143 as desired .",
    "occam s razor can be paraphrased to say that the simplest hypothesis should be preferred .",
    "suppose we have a setof hypotheses @xmath144 with prior distribution @xmath145 on @xmath144 .",
    "let @xmath146 denote the complexity of hypothesis @xmath147 .",
    "let @xmath148 $ ] be a loss function . then    @xmath37 +   [ t : occam ] for any data generating distribution on @xmath149 and any prior distribution @xmath145 over @xmath144 , with a probability greater than @xmath90 over drawing an i.i.d . sample from @xmath149 of size @xmath150 , for all @xmath151 : @xmath152    see @xcite .",
    "let @xmath153 denote the set of deterministic policies , where @xmath154 .",
    "define loss function @xmath155 further , set probability distribution @xmath156 on @xmath157 .",
    "theorem  [ t : occam ] holds for any sampling distribution .",
    "in particular we may use the policy @xmath46 to restrict samples to situations that cause the agent to spike to obtain @xmath158 .",
    "it follows that @xmath159      \\text { is the expected reward and}\\\\",
    "\\hat{l}(\\pi ) = \\hat{{{r}}}_\\pi=\\frac{1}{t_1}\\sum_{\\{(s_t , n_t)| \\pi(s_t)=a_1\\ } } { { r}}\\big(s_t , a_1,n_t\\big )      \\text { is the empirical reward,}\\end{gathered}\\ ] ] where @xmath80 is the number of spike produced by the agent during @xmath81 $ ] .",
    "[ t : vcr].@xmath37 +   _ let @xmath160 denote policies that spike for exactly @xmath5 situations . given the setup above , with probability at least @xmath90 , @xmath91 _",
    "let @xmath161 denote the number of possible situations .",
    "we put the uniform prior on @xmath162 , so @xmath163 . by stirling s approximation , @xmath164 , and it follows that @xmath165 the theorem follows since @xmath166 and @xmath167 .",
    "for an agent operating under high metabolic constraints , it turns out that effective information provides a useful approximation to mutual information :    @xmath37 +   [ t : conc - inf ] suppose an agent has two actions ( silence @xmath34 and spike @xmath35 ) and produces spikes very infrequently : @xmath168",
    ". then the total information transferred by the agent is approximately the information it transfers using spikes alone : @xmath169    observe that @xmath170 thus to first order in @xmath123 , @xmath171 is of the form @xmath172 where @xmath173 .",
    "we can then compute @xmath174 & = \\int ( p+\\delta p)\\log_2\\frac{p+\\delta p}{p}\\\\      & = \\alpha\\int ( p+\\delta p)\\frac{\\delta p}{p}\\left(1-\\frac{\\delta p}{2p}\\right ) + o\\big((\\delta p)^3\\big )      = \\alpha\\int \\frac{(\\delta p)^2}{2p}+ o\\left((\\delta p)^3\\right),\\end{aligned}\\ ] ] where @xmath175 .    substituting @xmath176 and @xmath177",
    "gives @xmath178 & =      d\\big[p+\\delta p\\,\\big\\|\\,p\\big ] + o\\big(\\pi(a_1)^2\\big)\\\\      & = \\alpha\\cdot",
    "\\pi(a_1)^2\\int\\frac{\\big(p(s)-\\pi(s|a_1)\\big)}{2p(s ) }      + o\\big(\\pi(a_1)^2\\big).\\end{aligned}\\ ] ]"
  ],
  "abstract_text": [
    "<S> this paper investigates how a population of neuron - like agents can use metabolic cost to communicate the importance of their actions . </S>",
    "<S> although decision - making by individual agents has been extensively studied , questions regarding how agents should behave to cooperate effectively remain largely unaddressed . under assumptions that capture a few basic features of cortical neurons , </S>",
    "<S> we show that constraining reward maximization by metabolic cost aligns the information content of actions with their expected reward . </S>",
    "<S> thus , metabolic cost provides a mechanism whereby agents encode expected reward into their outputs . </S>",
    "<S> further , aside from reducing energy expenditures , imposing a tight metabolic constraint also increases the accuracy of empirical estimates of rewards , increasing the robustness of distributed learning . finally , we present two implementations of metabolically constrained learning that confirm our theoretical finding . </S>",
    "<S> these results suggest that metabolic cost may be an organizing principle underlying the neural code , and may also provide a useful guide to the design and analysis of other cooperating populations . </S>"
  ]
}