{
  "article_text": [
    "the problem of calculating frequentist confidence intervals and upper limits has received recently new contributions and has been subject of intense discussions ( see refs .",
    "three new methods with correct coverage ( see section  [ coverage and power ] ) have been proposed : unified approach @xcite , bayesian ordering @xcite and maximum likelihood estimator@xcite .    in this paper",
    "we consider the power of frequentist methods to reject false values of the parameter under investigation and we connect it with the physical significance of confidence intervals . in this contest the physical significance of a confidence interval is its degree of reliability .",
    "for example , an unbelievably small upper limit below the sensitivity of the experiment has negligible physical significance ( one could even argue that it has `` negative '' physical significance , since it gives misleading information to those who believe in it ) .",
    "empty confidence intervals are practically useless and physically insignificant .",
    "in section  [ coverage and power ] we review the coverage of frequentist methods and their power to reject false values of the parameter .",
    "section  [ boundary ] constitutes the main part of the paper , in which considering a non - negative parameter , we discuss the power of confidence intervals and their physical significance . in sections  [ gaussian ] and [ poisson ]",
    "we illustrate the arguments presented in section  [ boundary ] using as examples a gaussian distribution with mean @xmath0 and a poisson distribution with known background , respectively .",
    "an important property of frequentist confidence intervals is _ coverage_. a method for the calculation of confidence intervals has correct coverage if its confidence intervals with @xmath1 confidence level ( cl ) belong to a set of confidence intervals that can be obtained with a large ensemble of experiments , @xmath1 of which contain the true value of the parameter ( see , for example , refs .",
    "@xcite ) . in other words , if coverage is satisfied , a @xmath1 cl confidence interval has a probability @xmath2 to cover the true value of the parameter .",
    "confidence intervals with correct coverage can be calculated using neyman s method @xcite . in this method , @xmath1 cl confidence intervals for a quantity @xmath3",
    "are obtained through the construction of a confidence belt in the plane @xmath4@xmath3 , where @xmath4 is an appropriate estimator of @xmath3 . for each possible value of @xmath3 one",
    "calculates an acceptance interval of the estimator with integral probability @xmath2 .",
    "the union of all the acceptance intervals constitutes the confidence belt .",
    "the confidence interval resulting from a measurement of @xmath4 is given by all the values of @xmath3 whose acceptance interval include the measured value of @xmath4 ( see , for example , refs .",
    "@xcite ) .",
    "coverage , however , is not the only quantity that is important in the construction of confidence intervals .",
    "another quantity , called _ power _ , is related to the probability to reject false values of the parameter .",
    "coverage and power are connected , respectively , with the so - called _ type i _ and _ type ii _",
    "errors in testing a simple statistical hypothesis @xmath5 against a simple alternative hypothesis @xmath6 ( see ref .",
    "@xcite , section 20.9 ) :    type i error : : :    reject the null hypothesis @xmath5 when it is true .",
    "the    probability of a type i error is called _ size _ of the test and it is    usually denoted by @xmath7 .",
    "type ii error : : :    accept the null hypothesis @xmath5 when the alternative    hypothesis @xmath6 is true .",
    "the probability of a type ii    error is usually denoted by @xmath8 .",
    "the power of a test    is the probability @xmath9 to reject    @xmath5 if @xmath6 is true .",
    "a test is _",
    "most    powerful _ if its power is the largest one among all possible tests .    in neyman",
    "s method , whatever is the true value of @xmath3 , the probability that it is not included in a @xmath1 cl confidence interval is @xmath7 . from the point of view of hypothesis testing , if one considers a possible value @xmath10 of @xmath3 as a null hypothesis , @xmath5 : @xmath11 , the probability to reject @xmath10 if it is true is @xmath7 , _",
    "i.e. _ there is a probability @xmath7 to make a type i error . in other words , the acceptance interval of the estimator",
    "@xmath4 corresponding to @xmath10 is the _ acceptance region _ of the test and the complementary interval is the _ critical region _ of the test .",
    "if the measured value of @xmath4 falls in the critical region , the null hypothesis is rejected .",
    "this happens with a probability @xmath7 if the null hypothesis is true , as required by coverage .",
    "the property of coverage is not sufficient to specify uniquely how to construct the confidence belt .",
    "different frequentist methods with correct coverage follow different prescriptions for the definition of the acceptance intervals .",
    "the associated probability @xmath7 of a type i error is the same , but the probability @xmath8 of a type ii error and the corresponding power @xmath9 are different .",
    "unfortunately , the power associated with a confidence belt is not easy to evaluate , because for each possible value @xmath10 of @xmath3 considered as a null hypothesis there is no simple alternative hypothesis that allows to calculate the probability @xmath8 of a type ii error .",
    "instead , we have the alternative hypothesis @xmath6 : @xmath12 , which is composite .",
    "for each value of @xmath12 one can calculate the probability @xmath13 of a type ii error associated with a given acceptance interval corresponding to @xmath10 . a method that gives an acceptance region for @xmath10 which has the largest possible power @xmath14 if @xmath15 is true is most powerful with respect to the alternative @xmath15 .",
    "clearly , it would be desirable to find a _ uniformly most powerful _ test , _",
    "i.e. _ a test that gives an acceptance region for @xmath10 which has the largest possible power @xmath16 for any value of @xmath15 .",
    "unfortunately , the neyman - pearson lemma implies that in general a uniformly most powerful test does not exist if the alternative hypothesis is _ two - sided _ , _ i.e. _ both @xmath17 and @xmath18 are possible , and the derivative of the likelihood with respect to @xmath3 is continuous in @xmath10 ( see ref .",
    "@xcite , section 20.18 ) .",
    "nevertheless , it is possible to find a uniformly most powerful test if the class of tests is restricted in appropriate ways . a class of tests that has some merit is the class of _ unbiased _ tests , such that @xmath19 _ i.e. _ the probability of rejecting @xmath10 when it is false is at least as large as the probability of rejecting @xmath10 when it is true .",
    "the _ equal - tail _ test used in the central intervals method is unbiased and _ uniformly most powerful unbiased _ for distributions belonging to the exponential family , such as , for example , the gaussian and poisson distributions ( see ref .",
    "@xcite , section 21.31 ) .    therefore , the central intervals method , is widely used because it corresponds to a uniformly most powerful unbiased test .",
    "other methods based on asymmetric tests unavoidably introduce some bias .",
    "in some cases the central intervals method is not satisfactory .",
    "the two cases which occur often in physics are the gaussian distribution with a mean @xmath3 physically bounded to be non - negative .",
    "we consider only the case @xmath0 for simplicity . ] and the poisson distribution with mean @xmath0 and a known background . in these cases",
    "the central intervals method sometimes produces empty confidence intervals , that are physically useless . the recently proposed frequentist methods with correct coverage @xcite cure this problem considering appropriate constructions of the confidence belt that guarantee a transition from two - sided confidence intervals to upper limits near the boundary for the gaussian distribution and for small number of counts in the case of the poisson distribution . from the discussion at the end of section  [ coverage and power ] ,",
    "it is clear that these methods are biased . in particular , since the acceptance intervals shift towards lower values of the estimator , which are more likely for smallest values of @xmath3 , these methods have a bias in testing the alternatives @xmath17 . on the other hand ,",
    "these methods are more powerful than the central intervals method in the test of the alternatives @xmath18 .    near the boundary @xmath0 , where the various methods produce different results , it is clearly much more important to test the alternatives @xmath18 than the alternatives @xmath17 , which are limited . in other words",
    ", the boundary introduces an asymmetry in the importance of the @xmath18 and @xmath17 alternatives .",
    "moreover , experiments are made to search for a signal and when small signals are searched for ( small @xmath3 near the boundary @xmath0 ) , testing the alternatives @xmath18 is physically more meaningful than testing the alternatives @xmath17 . having more power in the test of the alternatives @xmath18",
    "means that values of @xmath3 smaller than the true one are less likely to be accepted , _",
    "i.e. _ the experiment is more sensitive to a possible signal .    in general the loss of power in testing",
    "@xmath10 against @xmath17 when @xmath10 is near the physical boundary leads to less stringent upper limits .",
    "if the experiment is not sensitive to values of @xmath3 near the physical boundary , it does not make any sense to test @xmath10 against @xmath17 near the boundary .",
    "hence , a loss of power for this test is actually desirable and leads to more reliable upper limits .",
    "indeed , the central intervals method , which is unbiased and has a large power in testing @xmath10 against @xmath17 near the boundary , gives practically useless upper limits .",
    "these considerations imply that a frequentist method produces upper limits which are _ physically significant _ if near the physical boundary it has a _",
    "large _ power in testing @xmath10 against @xmath18 and _ small _ power in testing @xmath10 against @xmath17 .    among the recently proposed frequentist methods with correct coverage ( unified approach @xcite , bayesian ordering @xcite , maximum likelihood estimator @xcite ) , the shift of the acceptance intervals towards lower values of the estimator is smallest in the unified approach @xcite .",
    "we will show this fact explicitly in section  [ gaussian ] for a bounded gaussian distribution , but it is true also for a poisson distribution with known background .",
    "therefore , the unified approach is the _ less powerful _ among new methods in testing @xmath3 against the alternatives @xmath20 , which are more important near the boundary than the alternatives @xmath21 , for which the unified approach has the highest power . in other words , the unified approach is less sensitive than the other methods to positive signals , because small values of @xmath3 are more likely to be accepted if the true value of @xmath3 is large .",
    "it also produces upper limits that are too stringent and unreliable from the physical point of view , because it has too much power in testing @xmath3 against the alternatives @xmath21 near the boundary .",
    "in order to illustrate the power of different methods , let us consider an observable @xmath22 with gaussian distribution around a non - negative mean @xmath3 and a standard deviation @xmath23 , assumed to be known . in this case",
    "@xmath22 is the estimator of @xmath3 ( @xmath24 ) and a measurement of @xmath22 gives a confidence interval for @xmath3 , which depend on the chosen method .",
    "figure  [ gauss - belt ] shows the 90% cl confidence belts ( @xmath25 ) for @xmath26 corresponding to four different methods : the standard central intervals method and the three new methods with correct coverage , unified approach @xcite , bayesian ordering @xcite and maximum likelihood estimator @xcite . for @xmath27",
    "all the methods produce the same results , far from the boundary @xmath0 .",
    "the central intervals method gives an empty confidence interval for @xmath28 .",
    "the other three methods give non - empty confidence intervals for any value of @xmath22 , which become upper limits for @xmath29 . for negative values of @xmath22 the unified approach give the most stringent upper limits , whereas the maximum likelihood estimator gives the upper limit @xmath30 for any value of @xmath31 . at @xmath32 , the confidence belt obtained with the maximum likelihood estimator method has discontinuous derivative of the left edge at @xmath33 , and a discontinuity of the right edge from @xmath34 to @xmath35 .",
    "the confidence belt obtained with the unified approach has discontinuous derivatives of both left and right edges at @xmath32 , where the left edge has @xmath33 and the confidence belt start to deviate from the central intervals confidence belt for decreasing @xmath22 . both left and right edges of the confidence belt obtained with the bayesian ordering are smooth for all values of @xmath22 .    for small values of @xmath3 the acceptance intervals in the unified approach , bayesian ordering and maximum likelihood estimator",
    "are increasingly shifted to the left , with respect to those in the central intervals method .",
    "hence , among these methods , the maximum likelihood estimator has highest power in testing small values of @xmath3 against larger alternatives , followed by the bayesian ordering and then by the unified approach .",
    "the order of the power of the four methods in testing small values of @xmath3 against smaller alternatives is reversed .    in order to give a quantitative illustration of the power of the four methods under consideration ,",
    "let us define the positive average power function @xmath36 for an arbitrary @xmath37 , and the negative average power function @xmath38 these two functions , for a gaussian distribution with mean @xmath0 , standard deviation @xmath26 , @xmath25 and @xmath39 , are plotted in fig .",
    "[ gauss - power ] .    from fig .",
    "[ gauss - power]a one can see that the maximum likelihood estimator method has the highest power with respect to the alternatives @xmath20 if @xmath40 .",
    "the power of the bayesian ordering method is higher than that of the unified approach and both tend to the constant power of the central intervals method for large values of @xmath3 .",
    "all methods are unbiased in testing larger alternatives ( @xmath41 ) .",
    "figure  [ gauss - power]b shows that the order of the power of the four methods is reversed when smaller alternatives are considered and only the central intervals method is unbiased . the curves in fig .",
    "[ gauss - power]b increase with increasing @xmath3 because the range @xmath42 increases with @xmath3 and values of @xmath15 far from @xmath3 lead to higher values of the power .",
    "the value of @xmath43 tends to @xmath25 for @xmath44 in all methods , because by definition @xmath45 for @xmath46 and the interval of integration in eq .",
    "( [ power - ave - minu ] ) shrinks to zero for @xmath44 . as noted in section  [ boundary ] , a small power in testing smaller alternatives is desirable in order to obtain physically reliable upper limits .",
    "let us emphasize that the arbitrary definition of the quantities in eqs.([power - ave - plus ] ) and ( [ power - ave - minu ] ) is irrelevant for the quality of our conclusions .",
    "choosing other appropriate quantities one always obtains the same classification ( central intervals , unified approach , bayesian ordering , maximum likelihood estimator ) of the four considered methods in order of increasing power to test larger alternatives and decreasing power to test smaller alternatives .",
    "in this section we discuss as another example the case of a poisson distribution of counts @xmath47 with mean signal @xmath3 and known background @xmath48 .",
    "we consider the same four methods already considered in the previous section : central intervals , unified approach @xcite , bayesian ordering @xcite and maximum likelihood estimator @xcite .",
    "since the discreteness of @xmath47 does not allow to construct exact central intervals , we follow the prescription described in ref .",
    "@xcite .",
    "figure  [ poisson - belt ] shows the 90% cl confidence belts in the four methods .",
    "one can see that for @xmath49 the maximum likelihood estimator gives a constant upper limit @xmath50 , the bayesian ordering and unified approach methods give upper limits that decrease with @xmath47 , and the central intervals method gives an empty confidence interval for @xmath51 .    because of the discreteness of @xmath47 , the acceptance intervals do not have exact integral probability @xmath2 .",
    "their integral probability @xmath52 is shown in fig .",
    "[ poisson - alp ] as a function of @xmath3 in the four considered methods .",
    "one can see that the dependence of @xmath52 from @xmath3 is very wild . as a consequence ,",
    "also the average power functions in eqs .",
    "( [ power - ave - plus ] ) and ( [ power - ave - minu ] ) are wild functions of @xmath3 . in order to obtain smoother functions of @xmath3 ,",
    "whose behaviour is not too difficult to be interpreted , we consider the ratios @xmath53 and @xmath54 .",
    "these ratios are appropriate to evidence the presence of a bias , which manifest itself when a ratio becomes less then one .    figure  [ poisson - power]a shows the ratio @xmath53 , with @xmath39 ( see eq .",
    "( [ power - ave - plus ] ) ) . in spite of the precaution to divide @xmath55 by @xmath56 , the curves still have wild jumps because of the discreteness of @xmath47 . from fig .",
    "[ poisson - power]a one can see that for most small values of @xmath3 the maximum likelihood estimator has the highest power in testing @xmath3 against larger alternatives , followed in order by bayesian ordering , unified approach and central intervals .",
    "the unified approach has higher ( or equal ) power than central intervals for @xmath57 , and smaller ( or equal ) power mfor highest values of @xmath3 .",
    "figure  [ poisson - power]b shows the ratio @xmath54 ( see eq .  ( [ power - ave - minu ] ) ) .",
    "one can see that even the central intervals method is slightly biased .",
    "this is due to the fact that , because of the discreteness of @xmath47 , it is not possible to construct exactly central acceptance intervals .",
    "[ poisson - power]b shows that central intervals and unified approach have the highest power in testing @xmath3 against smaller alternatives ( central intervals for @xmath58 and unified approach for highest values of @xmath3 ) .",
    "the maximum likelihood estimator method has the smallest power for @xmath50 .    in conclusion of this section ,",
    "we have shown with a specific example that also in the case of a poisson process with background , among the recently proposed methods with correct coverage , maximum likelihood estimator yields confidence intervals with the highest physical significance ( with the criteria discussed in section  [ boundary ] ) , followed in order by bayesian ordering and unified approach .",
    "in conclusion , we have considered the power of frequentist methods , which quantifies their capability to avoid type ii errors .",
    "we have connected the power with the physical significance of confidence intervals , _",
    "i.e. _ their degree of reliability .",
    "considering the case of a parameter bounded to be non - negative , we have shown that near the boundary a ( biased ) method that has large power in testing the parameter against larger alternatives and small power in testing the parameter against smaller alternatives produces confidence intervals ( upper limits ) that are physically more significant .",
    "we have shown that among the recently proposed frequentist methods with correct coverage ( unified approach @xcite , bayesian ordering @xcite , maximum likelihood estimator @xcite ) , the widely used unified approach yields upper limits with the smallest physical significance .",
    "the upper limits with the highest physical significance are produced by the maximum likelihood estimator method ."
  ],
  "abstract_text": [
    "<S> we consider the power to reject false values of the parameter in frequentist methods for the calculation of confidence intervals . </S>",
    "<S> we connect the power with the physical significance ( reliability ) of confidence intervals for a parameter bounded to be non - negative . </S>",
    "<S> we show that the confidence intervals ( upper limits ) obtained with a ( biased ) method that near the boundary has large power in testing the parameter against larger alternatives and small power in testing the parameter against smaller alternatives are physically more significant . considering the recently proposed methods with correct coverage , we show that the physical significance of upper limits is smallest in the unified approach and highest in the maximum likelihood estimator method . </S>",
    "<S> we illustrate our arguments in the specific cases of a bounded gaussian distribution and a poisson distribution with known background . </S>"
  ]
}