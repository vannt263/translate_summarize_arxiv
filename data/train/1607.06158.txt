{
  "article_text": [
    "this paper considers a general data assimilation filtering problem with multiple time scales . on a probability space @xmath0 with @xmath1 ,",
    "for positive integers @xmath2 we consider the @xmath3-dimensional process @xmath4;\\mathbb",
    "r^m\\times\\mathbb r^k\\times\\mathbb r^n)$ ] , which satisfies a system of stochastic differential equations ( sdes ) with @xmath5 , @xmath6 where @xmath7 , @xmath8 and @xmath9 are ( unobserved ) independent wiener processes in @xmath10 , @xmath11 and @xmath12 , respectively .",
    "one possible , interpretation in the context of financial applications , is that the vector @xmath13 is part of a continuous stream of financial data , with the hidden processes @xmath14 and @xmath15 being factors in a stochastic model , see for example @xcite .",
    "a different possible interpretation is that @xmath16 is the signal of brain activity during a seizure , as in @xcite where multiscale dynamical systems are exploited as models for seizure dynamcics .",
    "other applications include multiscale modeling in oceanography and climate modeling , see for example @xcite .",
    "initially , the model in is left unspecified , and it is with the arrival of data that we can learn the parameter value @xmath17 .",
    "we let @xmath18 denote the @xmath19-algebra generated by the data , @xmath20 , and a primary goal is to compute the maximum likelihood estimator ( mle ) . given @xmath18",
    ", we denote the log - likelihood function as @xmath21 , which we maximize to obtain the estimator @xmath22    in financial applications for example and in particular in high - frequency trading , market and limit orders need to be executed at exact moments in time with accuracy that is of the order of nano seconds .",
    "hence , an estimate such as the mle may be very accurate , but it may also require computing time that is too long for the purposes of trading .",
    "in general , it is well known that standard monte - carlo particle filters can be quite slow even without the effect of multiple scales . however , in the small-@xmath23 limit there is a significant reduction in dimension because the process @xmath24 gets ` averaged out ' by the ergodic theory , and this allows filtering for @xmath15 and inference for @xmath17 to have a faster algorithm .",
    "the novel contribution of this paper is at two levels . at the first level , we prove that the nonlinear filter for ( [ eq : model3 ] ) converges , for any parameter value of @xmath17 and under the measure parameterized by the true parameter value , with the limit being a filter of reduced dimension .",
    "we prove this result for test functions that can depend on both the slow and fast unknown components , @xmath25 and @xmath26 ; the test functions may be unbounded but we do impose moments bounds though .",
    "this result extends previous works of @xcite and @xcite . at the second level",
    ", we use the filters convergence result to prove that the mle based on the model of reduced dimension produces both consistent and asymptotically normal estimators , and we identify the limiting variance of the estimator .",
    "we apply our methodology to examples where the reduction procedure allows to use classical kalman - filter type of methods for a problem that is highly nonlinear without the small-@xmath23 asymptotics .",
    "our examples demonstrate how statistical inference for a highly nonlinear problem is reduced to statistical inference for a problem which is both linear and of reduced dimension , and hence is significantly less demanding from a computational standpoint .",
    "the rest of the paper is organized as follows . in section [ s : problemformulation ]",
    "we formulate the problem of interest in specific terms and present some preliminary well - known results that are useful throughout . in section [ s : filteringequations ] we present the filtering equations of the original problem and we derive the filters associated to the problem of reduced dimensions . in section [ s : filterconvergence ]",
    "we present our first main result on filter convergence which is the main justification for doing inference using the original available data @xmath18 but based on the model of reduced dimension . in section [ s : mle_reducedestimator ]",
    "we present our main results on parameter estimation .",
    "in particular , we prove that under appropriate conditions , the mle for the problem of reduced dimension is both consistent and asymptotically normal as @xmath27 . in section [",
    "s : example ] we consider a few examples to illustrate and supplement the theoretical results for which classical kalman filter techniques can be used .",
    "simulation data are presented to support the theoretical claims .",
    "let @xmath28 be an unknown parameter of interest which is to be estimated from data generated by ( [ eq : model3 ] ) .",
    "assuming that we observe only the @xmath29 process , we develop a consistent and asymptotically normal mle for @xmath17 .",
    "we consider the case @xmath30 , in which case @xmath31 is the fast component and @xmath32 is the slow component .",
    "we reduce the high dimensionality of the problem by looking at the @xmath33 limit and exploiting the statistical properties of the mle based on the reduced likelihood .    for the model given in , we shall write @xmath34 and @xmath35 for the infinitesimal generators of the fast process , @xmath31 , and the process @xmath32 , respectively .",
    "namely , @xmath36\\nonumber\\\\ { \\mathcal{l}^{s}}_{\\theta , x } f(u)&=g_\\theta(x , u)\\cdot d_{u}f(u)+\\frac{1}{2}\\textrm{tr}\\left[\\tau_\\theta(x , u)\\tau_\\theta^{{\\top}}(x , u)d^{2}_{u}f(u ) \\right]\\end{aligned}\\ ] ] next we pose the main condition of this paper on the growth and regularity of the coefficients of ( [ eq : model3 ] ) .",
    "such conditions guarantee that ( [ eq : model3 ] ) has a well defined strong solution , that the fast component @xmath14 is ergodic and that the slow component @xmath37 has a well - defined homogenization limit as @xmath33 in the appropriate sense .",
    "assumptions to guarantee these properties are given by @xcite for homogenization and chapter 3 of @xcite for filtering , and are stated as follows :    [ a : assumption1 ]    1 .   for ergodicity purposes we shall assume the recurrence condition @xmath38 + under this assumption the lyapunov - type condition for existence of an invariant measure associated to the fast dynamics @xmath25 of hasminskii @xcite is satisfied .",
    "2 .   to guarantee uniqueness of the invariant measure for @xmath25 , we assume that @xmath39 is non - degenerate uniformly in @xmath17 , i.e. , there exists @xmath40 such that for all @xmath41 @xmath42 3",
    ".    the functions @xmath43 and @xmath44 are @xmath45 with @xmath46 , uniformly in @xmath47 .",
    "namely , uniformly in @xmath47 , they have two bounded derivatives in @xmath48 and @xmath49 , with all partial derivatives being hlder continuous , with exponent @xmath50 , with respect to @xmath48 , uniformly in @xmath49 .",
    "we assume that @xmath51 and that there exist @xmath52 and @xmath53 such that @xmath54 5 .    for every @xmath55",
    "there exists a constant @xmath56 such that for all @xmath57 and @xmath58 , the diffusion matrix @xmath59 satisfies @xmath60 moreover , there exists @xmath61 and @xmath62 such that @xmath63 6 .",
    "@xmath64 is bounded and globally lipschitz in @xmath65 uniformly in @xmath47 .",
    "the functions @xmath66 are lipschitz continuous in @xmath47 and @xmath67 is bounded open set .    under this assumption and non - degeneracy of the diffusion coefficient @xmath68 , for fixed with @xmath69 the process @xmath70 has a unique invariant measure which we shall denote by @xmath71 . for a given function @xmath72 ,",
    "define its averaged version as @xmath73 it is a well known result that @xmath74 converges in distribution in @xmath75;\\mathbb{r}^n)$ ] to the process @xmath76 ( e.g. @xcite ) , where @xmath77 and where @xmath78 actually , due to the fact that the observation process @xmath16 has constant diffusion , condition [ a : assumption1 ] and the ergodic theorem guarantee that a stronger result holds for any @xmath47 , i.e. , for every @xmath79 @xmath80",
    "the data is contained in the filtration @xmath81 for any @xmath47 , we define a new measure @xmath82 on @xmath83 via the relationship @xmath84 under the proper assumptions @xmath85 is an exponential martingale and thus the probability measures @xmath86 and @xmath87 are absolutely continuous with respect to each other , and the distribution of @xmath88 is the same under both @xmath86 and @xmath82 .",
    "furthermore , the process @xmath89 is a @xmath90-brownian motion and is independent of @xmath88 .",
    "next , for @xmath91 that is in @xmath92 , we define the measure valued process @xmath93 acting on @xmath94 as @xmath95 \\doteq\\mathbb{e}_{\\theta}^{*}\\left [ z_t^{\\delta,\\theta}f(x^{\\delta}_{t},u^{\\delta}_{t } ) \\big |\\mathcal{y}_{t}^\\delta\\right]\\ , \\ ] ] a process which , for @xmath96 is well - known to be the unique solution ( see @xcite ) to the following equation : @xmath97&=&\\left(\\frac{1}{\\delta}\\phi^{\\delta,\\theta}_{t}[{\\mathcal{l}^{f}}_{\\theta}f ] + \\phi^{\\delta,\\theta}_{t}[{\\mathcal{l}^{s}}_{\\theta}f ]    \\right)dt + \\phi^{\\delta,\\theta}_{t}[h_{\\theta } f ] dy_s^\\delta,\\quad \\mathbb{p}_{\\theta}^ { * } \\textrm{-a.s . } \\ , \\nonumber\\\\     \\phi_0^{\\theta}[f]&= & \\mathbb e_{\\theta}f(x_0^\\delta , u_0^\\delta)\\ .\\label{eq : zakai }   \\end{aligned}\\ ] ] equation is the zakai equation for nonlinear filtering .",
    "furthermore , @xmath98 is actually an unnormalized probability measure which yields the normalized posterior expectations via the kalianpour - striebel formula , @xmath99\\doteq{\\mathbb e}_{\\theta}\\left[f(x_t^\\delta , u_t^\\delta)\\big|\\mathcal y_t^\\delta\\right]=\\frac{\\phi_t^{\\delta,\\theta}[f]}{\\phi_t^{\\delta,\\theta}[1]}\\quad \\mathbb{p}_{\\theta},\\mathbb{p}_{\\theta}^ { * } \\textrm{-a.s.}\\ .\\ ] ] if @xmath100 then we have the innovations process , @xmath101ds\\qquad\\forall t\\in[0,t]\\ .\\ ] ] the process @xmath102 is a @xmath103-brownian motion under the filtration generated by the observed @xmath29 process , but will only be observable as brownian motion if @xmath17 is equal to the true parameter value . for a suitable test function @xmath104 , the innovation process is used in the nonlinear kushner - stratonovich equation to describe the evolution of @xmath105 $ ] ,",
    "@xmath106 = \\left(\\frac 1\\delta \\pi^{\\delta,\\theta}_{t}[{\\mathcal{l}^{f}}_{\\theta } f]+\\pi^{\\delta,\\theta}_{t}[{\\mathcal{l}^{s}}_{\\theta } f ] \\right)dt+",
    "\\left(\\pi^{\\delta,\\theta}_{t}[f h_{\\theta}]-\\pi^{\\delta,\\theta}_{t}[f]\\pi^{\\delta,\\theta}_{t}[h_{\\theta}]\\right)d\\nu_t^{\\delta,\\theta}\\quad \\mathbb{p}_{\\theta}\\textrm{-a.s.}\\ ] ]    let us next consider the filtering equations of the approximating problem that is of reduced dimension . consider the ` averaged ' exponentials @xmath107 for @xmath108 , we define new posterior measures @xmath109 $ ] and @xmath110 $ ] which satisfy the stochastic evolution equations @xmath111&=&\\bar{\\phi}^{\\delta,\\theta}_{t}[\\overline{l}_{\\theta}^{s}f]dt+\\bar{\\phi}^{\\delta,\\theta}_t[\\bar{h}_{\\theta } f ]   dy^{\\delta}_t , \\quad \\bar{\\phi}^{\\delta,\\theta}_{0}[f]=\\mathbb{e}_{\\theta}f(\\bar{u}_{0})\\ , \\\\",
    "\\label{eq : avgzakailimit } d\\bar{\\phi}^{\\theta}_{t}[f]&=&\\bar{\\phi}^{\\theta}_{t}[\\overline{l}_{\\theta}^{s}f]dt+\\bar{\\phi}^{\\theta}_t[\\bar{h}_{\\theta}f ]   d\\bar{y}_t , \\quad \\bar{\\phi}^{\\theta}_{0}[f]=\\mathbb{e}_{\\theta}f(\\bar{u}_{0})\\ .",
    "\\end{aligned}\\ ] ] it is straightforward to verify with it s lemma that the ` average ' zakai equations and have solutions @xmath112&= & \\mathbb e_{\\theta}^*\\left [ f_{\\theta}(\\bar{u}_{t } ) \\bar{z}_t^{\\delta,\\theta}\\big|\\mathcal y_t^\\delta\\right ] \\ , \\\\ \\label{eq : solavgzakailimit } \\bar{\\phi}^{\\theta}_{t}[f]&= &   \\mathbb e_{\\theta}^*\\left [ f_{\\theta}(\\bar{u}_{t } ) \\bar{z}_t^{\\theta}\\big|\\mathcal{\\bar{y}}_t\\right]\\\\end{aligned}\\ ] ] we define the averaged filters as follows : @xmath113=\\frac{\\bar{\\phi}^{\\delta,\\theta}_{t}[f]}{\\bar{\\phi}^{\\delta,\\theta}_{t}[1 ] } $ ] and @xmath114=\\frac{\\bar{\\phi}^{\\theta}_{t}[f]}{\\bar{\\phi}^{\\theta}_{t}[1]}$ ] .",
    "it is easy to see that @xmath114={\\mathbb e}_{\\theta}\\left[f(\\bar{u}_t)\\big|\\mathcal{\\bar{y}}_t\\right]$ ] .",
    "we conclude this section by mentioning that , under @xmath86 , equation ( [ eq : ksformula ] ) defines a measure - valued process @xmath115 , the conditional distribution , by the formula @xmath116={\\mathbb e}_{\\theta}\\left[f(x^{\\delta}_t , u^{\\delta}_t)\\big|\\mathcal{y}^{\\delta}_t\\right]\\ .\\ ] ] similarly , we define the probability measure - valued processes @xmath117 and @xmath118 by @xmath119\\quad\\text { and } \\quad \\left(\\bar{p}_{t},f\\right)=\\bar{\\pi}_{t}[f]\\ ] ] the measure - valued process @xmath120 especially , will become handy in proving the consistency and asymptotic normality of the mle based on the reduced estimator .",
    "consider @xmath121 and define the following class of test functions @xmath122}\\mathbb{e}_{\\theta}\\left|f(x^{\\delta}_{t},u^{\\delta}_{t})\\right|^{2+\\eta}<\\infty \\right\\}.\\ ] ] then , we have the following result which is a generalization of the results of @xcite and @xcite .",
    "[ t : filterconvergence1 ] assume conditions [ a : assumption1 ] . for any @xmath123 ,",
    "the following hold uniformly in @xmath124 $ ]    1 .",
    "let @xmath125 . then , for every @xmath79 @xmath126-\\bar\\phi_t^{\\delta,\\theta}[\\bar{f}]\\right| \\geq \\varepsilon \\right)=0\\ ] ] 2 .",
    "assume that there is @xmath121 such that @xmath127 .",
    "then , @xmath105 $ ] converges in @xmath128-mean - square to @xmath129 $ ] , i.e. , @xmath130-\\bar \\pi_t^{\\delta , \\theta}[\\bar{f}]\\right)^2=0\\ .\\ ] ] additionally , we also have @xmath131-\\bar \\pi_t^{\\theta}[\\bar{f}]\\right)^2=0\\ .\\ ] ]    for @xmath132 and for the case @xmath133 this is proven in @xcite .",
    "also , for the case @xmath134 and @xmath135 , i.e. , when the model does not include the hidden slow process @xmath26 , theorem [ t : filterconvergence1 ] is proven in @xcite .",
    "hence , theorem [ t : filterconvergence1 ] extends the results of @xcite to the case @xmath127 and under parameter mismatch .",
    "we emphasize here that since we are interested in the parameter estimation , we are naturally interested in making sure that the filters converge for _ any _ parameter value under the measure parameterized by the true parameter value .",
    "the proof of this theorem is in appendix [ a : filterconvergence1 ] .",
    "theorem [ t : filterconvergence1 ] suggests that for parameter estimation , we can approximate the conditional log - likelihood @xmath136=\\log\\mathbb{e}_{\\theta}^{*}\\left [ z_t^{\\delta,\\theta } \\big |\\mathcal{y}^{\\delta}_t\\right]\\label{eq : loglikelihood}\\ ] ] by the ` reduced ' log - likelihood @xmath137=\\log \\mathbb{e}_{\\theta}^{*}\\left [ \\bar{z}_t^{\\delta,\\theta } \\big |\\mathcal{y}^{\\delta}_t\\right]\\label{eq : intermediatelikelihood}\\ ] ]    note that by lemma 3.29 in @xcite we have @xmath138\\right ) = \\int_0^t \\bar{\\pi}_s^{\\delta,\\theta}[\\bar{h}_{\\theta}]dy^{\\delta}_s -\\frac 12\\int_0^t\\left| \\bar{\\pi}_s^{\\delta,\\theta}[\\bar{h}_{\\theta}]\\right|^2ds\\ ] ]    the following condition is about regularity of @xmath139 as a function of @xmath47 .",
    "[ a : assumption4 ] there are constants @xmath140 , @xmath141 and @xmath142 , such that for any @xmath143 , @xmath144    allowing arbitrary initial conditions , the set of processes @xmath145 , @xmath146 and @xmath147 are markov - feller processes in @xmath148 , @xmath149 and @xmath150 .",
    "let @xmath151 , @xmath152 and @xmath153 be the corresponding transition functions .",
    "in order to have enough ergodicity of the averaged problem as @xmath27 we make the following assumption , see for example @xcite .",
    "the examples that will be considered in section [ s : example ] satisfy condition [ a : assumption4b ] .",
    "[ a : assumption4b ] there is a unique invariant measure @xmath154 for the transition function @xmath153 .",
    "in addition the set @xmath155 is tight and @xmath156 .",
    "we also need the following identifiability condition .",
    "[ a : assumptionidentifiability ] we assume that for any @xmath47 , any @xmath157 , @xmath1 and for every @xmath158 $ ] , one has @xmath159-\\bar{\\pi}^{\\alpha}_{t}[\\bar{h}_{\\alpha}]\\right|^{2}>0.\\ ] ]    let us define @xmath160    since we have assumed that @xmath161 is bounded , we get that @xmath162 with probability @xmath163 .",
    "we then have the following theorem :    [ t : consisitencyreducedlikelihood ] assume conditions [ a : assumption1 ] , [ a : assumption4 ] , [ a : assumption4b ] and [ a : assumptionidentifiability ] . the maximum likelihood estimator based on ( [ eq : intermediatelikelihood ] )",
    "is strongly consistent as first @xmath33 and then @xmath27 , i.e. , for any @xmath79 @xmath164    under @xmath128 , we recall that the innovations process @xmath165ds\\qquad\\forall t\\in[0,t]\\ ] ] is a @xmath166-brownian motion under the filtration generated from the observed @xmath29 process .",
    "hence , under @xmath128 we have @xmath167dy^{\\delta}_s -\\frac 12\\int_0^t\\left| \\bar{\\pi}_s^{\\delta,\\theta}[\\bar{h}_{\\theta}]\\right|^2ds\\\\ & = \\int_0^t \\left[\\bar{\\pi}_s^{\\delta,\\theta}[\\bar{h}_{\\theta}]\\cdot\\pi^{\\delta,\\alpha}_{s}[h_{\\alpha}]-\\frac 12\\left| \\bar{\\pi}_s^{\\delta,\\theta}[\\bar{h}_{\\theta}]\\right|^2\\right]ds + \\int_0^t \\bar{\\pi}_s^{\\delta,\\theta}[\\bar{h}_{\\theta } ] d\\nu_{s}\\ , \\end{aligned}\\ ] ] where @xmath168\\cdot\\pi^{\\delta,\\alpha}_{s}[h_{\\alpha}]$ ] denotes the inner product over the @xmath169 coordinates in @xmath170 .",
    "then , we have @xmath171 where we used condition [ a : assumption4 ]",
    ". the constant @xmath172 might change from line to line , but we do not indicate this in the notation . by theorem [ t : filterconvergence1 ] , we have that @xmath173-\\bar{\\pi}_s^{\\alpha}[\\bar{h}_{\\alpha}]\\right|^{2}ds=0\\ .\\label{eq : convergence1}\\ ] ] theorem [ t : filterconvergence1 ] , ( [ eq : regularityreducedlikelihood ] ) and ( [ eq : convergence1 ] ) imply by theorem 12.3 in @xcite , that we have weak convergence of the measure @xmath174 to that of @xmath175 , where @xmath176\\cdot\\bar{\\pi}^{\\alpha}_{s}[\\bar{h}_{\\alpha}]-\\frac 12\\left| \\bar{\\pi}_s^{\\theta}[\\bar{h}_{\\theta}]\\right|^2\\right)ds + \\int_0^t \\bar{\\pi}_s^{\\theta}[\\bar{h}_{\\theta } ] d\\nu_{s}\\nonumber\\\\ & = -\\frac{1}{2}\\int_0^t \\left|\\bar{\\pi}_s^{\\theta}[\\bar{h}_{\\theta}]-\\bar{\\pi}_s^{\\alpha}[\\bar{h}_{\\alpha}]\\right|^{2}ds+ \\frac{1}{2}\\int_0^t \\left|\\bar{\\pi}_s^{\\alpha}[\\bar{h}_{\\alpha}]\\right|^{2}ds+\\int_0^t \\bar{\\pi}_s^{\\theta}[\\bar{h}_{\\theta } ] d\\nu_{s}\\end{aligned}\\ ] ] hence we have @xmath177 at the same time for any @xmath121 we have @xmath178d\\nu_{s}\\right|>\\eta\\right)&\\leq\\frac{1}{\\eta^{2}t^{2}}\\mathbb{e}_{\\alpha}\\int_0^t \\left|\\bar{\\pi}_s^{\\theta}[\\bar{h}_{\\theta}]\\right|^{2}ds\\nonumber\\\\ & \\leq\\frac{1}{\\eta^{2}t}c_{0}\\nonumber\\end{aligned}\\ ] ] for some constant @xmath179 that does not depend on @xmath180 .",
    "thus , we have in @xmath181probability that @xmath182d\\nu_{s}\\right]=0\\ .\\ ] ] let us define @xmath183-\\bar{\\pi}_s^{\\alpha}[\\bar{h}_{\\alpha}]\\right|^{2}ds+ \\frac{1}{2}\\int_0^t \\left|\\bar{\\pi}_s^{\\alpha}[\\bar{h}_{\\alpha}]\\right|^{2}ds\\ , \\end{aligned}\\ ] ] and recalling condition [ a : assumption4b ] we get that there is @xmath184 such that @xmath185 hence , we obtain @xmath186 where the last computation used the identifiability condition [ a : assumptionidentifiability ] . with this",
    ", we conclude the proof of the theorem .",
    "let us study next asymptotic normality of the maximum likelihood estimator that is based on the reduced likelihood function .",
    "we have that the maximizer will be solution to the equation @xmath187 for @xmath47 .",
    "thus , the maximizer @xmath188 of that equation will satisfy the equation @xmath189\\left(dy_{s}^{\\delta}-\\bar\\pi_{s}^{\\delta,\\tilde{\\theta}}[\\bar{h}_{\\tilde\\theta}]ds\\right)=0\\ .\\label{eq : equationforreducedmle}\\ ] ] we mention here that ( [ eq : thetamle ] ) and ( [ eq : equationforreducedmle ] ) are not equivalent ; ( [ eq : thetamle ] ) contains all local minima and local maxima of @xmath190 which may be more than one .",
    "also equation may not even have a solution in @xmath161 with positive probability .",
    "next we study asymptotic normality of the mle corresponding to the reduced log - likelihood .",
    "we make the following assumption .",
    "[ a : extraconditionforclt ] there exists a strictly positive definite matrix @xmath191 such that we have in @xmath192 under the measure @xmath128 @xmath193^{\\top}\\cdot\\nabla_{\\alpha}\\bar\\pi_{s}^{\\alpha}[\\bar{h}_{\\alpha } ] ds \\ .\\ ] ]    it is clear that in the case @xmath194 that condition [ a : extraconditionforclt ] is satisfied with constant matrix @xmath195 . in section [ s :",
    "example ] a more involved example will be examined where things can be also computed explicitly in closed form . actually , @xmath191 is nothing else but the fisher information matrix . by theorem [ t : consisitencyreducedlikelihood ] ,",
    "based on smoothness of @xmath196 $ ] as a function of @xmath17 and under condition [ a : extraconditionforclt ] , asymptotic normality of the mle corresponding to the reduced log - likelihood holds . to be precise , we have the following theorem .",
    "[ t : cltreducedlikelihood ] assume conditions [ a : assumption1 ] , [ a : assumption4 ] , [ a : assumption4b ] , [ a : assumptionidentifiability ] , [ a : extraconditionforclt ] and that @xmath196 $ ] is almost surely continuous as a function of @xmath17 .",
    "the maximum likelihood estimator based on ( [ eq : intermediatelikelihood ] ) is asymptotically normal under @xmath128 , i.e. @xmath197 where @xmath191 is fisher information given by .",
    "we write @xmath198=\\nabla_{\\theta}\\bar\\pi_{s}^{\\delta,\\theta}[\\bar{h}_{\\theta}]$ ] for notational convenience . based on ( [ eq : equationforreducedmle ] ) and for @xmath199 ,",
    "we write for some @xmath200 such that @xmath201 @xmath202\\left(dy_{s}^{\\delta}-\\bar\\pi_{s}^{\\delta,\\bar{\\theta}}[\\bar{h}_{\\bar\\theta}]ds\\right)\\nonumber\\\\ & = \\int_{0}^{t}\\dot{\\bar\\pi}_{s}^{\\delta,\\bar{\\theta}}[\\bar{h}_{\\bar\\theta}]\\left(dy_{s}^{\\delta}-\\bar\\pi_{s}^{\\delta,\\alpha}[\\bar{h}_{\\alpha}]ds-(\\bar{\\theta}-\\alpha)\\dot{\\bar\\pi}_{s}^{\\delta,\\alpha^{*}}[\\bar{h}_{\\alpha^{*}}]ds\\right)\\nonumber\\\\ & = \\int_{0}^{t}\\dot{\\bar\\pi}_{s}^{\\delta,\\bar{\\theta}}[\\bar{h}_{\\bar\\theta}]dy_{s}^{\\delta } -\\int_{0}^{t}\\dot{\\bar\\pi}_{s}^{\\delta,\\bar{\\theta}}[\\bar{h}_{\\bar\\theta}]\\cdot\\bar\\pi_{s}^{\\delta,\\alpha}[\\bar{h}_{\\alpha}]ds -(\\bar{\\theta}-\\alpha)\\int_{0}^{t}\\dot{\\bar\\pi}_{s}^{\\delta,\\bar{\\theta}}[\\bar{h}_{\\bar\\theta}]\\cdot\\dot{\\bar\\pi}_{s}^{\\delta,\\alpha^{*}}[\\bar{h}_{\\alpha^{*}}]ds\\ .\\nonumber\\end{aligned}\\ ] ] after some term rearrangement , we obtain @xmath203\\cdot\\dot{\\bar\\pi}_{s}^{\\delta,\\alpha^{*}}[\\bar{h}_{\\alpha^{*}}]ds\\right)^{-1 } \\frac{1}{\\sqrt{t}}\\int_{0}^{t}\\dot{\\bar\\pi}_{s}^{\\delta,\\bar{\\theta}}[\\bar{h}_{\\bar\\theta } ] d\\nu_{s}\\nonumber\\\\ & + \\left(\\frac{1}{t}\\int_{0}^{t}\\dot{\\bar\\pi}_{s}^{\\delta,\\bar{\\theta}}[\\bar{h}_{\\bar\\theta}]\\cdot\\dot{\\bar\\pi}_{s}^{\\delta,\\alpha^{*}}[\\bar{h}_{\\alpha^{*}}]ds\\right)^{-1 } \\frac{1}{\\sqrt{t}}\\int_{0}^{t}\\dot{\\bar\\pi}_{s}^{\\delta,\\bar{\\theta}}[\\bar{h}_{\\bar\\theta}]\\cdot\\left(\\pi^{\\delta,\\alpha}_{s}[h_{\\alpha}]-\\bar\\pi_{s}^{\\delta,\\alpha}[\\bar{h}_{\\alpha}]\\right)ds\\ , \\end{aligned}\\ ] ] and by taking @xmath204 , ergodcity and theorem [ t : filterconvergence1 ] guarantee that @xmath205-\\bar\\pi_{s}^{\\delta,\\alpha}[\\bar{h}_{\\alpha}]\\right|^{2}ds&=0\\ .\\end{aligned}\\ ] ] the latter statement and condition [ a : extraconditionforclt ] guarantee us that in @xmath128-probability as first @xmath33 and then @xmath27 @xmath206\\cdot\\dot{\\bar\\pi}_{s}^{\\delta,\\alpha^{*}}[\\bar{h}_{\\alpha^{*}}]ds\\right)^{-1 } \\frac{1}{\\sqrt{t}}\\int_{0}^{t}\\dot{\\bar\\pi}_{s}^{\\delta,\\bar{\\theta}}[\\bar{h}_{\\bar\\theta}]\\cdot\\left(\\pi_{s}^{\\delta,\\alpha}[h_{\\alpha}]-\\bar\\pi_{s}^{\\delta,\\alpha}[\\bar{h}_{\\alpha}]\\right)ds\\rightarrow 0\\ .\\label{eq : limitclt1}\\end{aligned}\\ ] ] for notational convenience , let us define the random matrix @xmath207\\cdot\\dot{\\bar\\pi}_{s}^{\\delta,\\theta_{2}}[\\bar{h}_{\\theta_{2}}]ds\\ .\\ ] ] since under @xmath128 , the innovations process @xmath165ds\\qquad\\forall t\\in[0,t]\\ ] ] is a @xmath166-brownian motion , for the stochastic integral we notice that a time change gives the following equality in distribution for some brownian motion , say @xmath208 @xmath206\\cdot\\dot{\\bar\\pi}_{s}^{\\delta,\\alpha^{*}}[\\bar{h}_{\\alpha^{*}}]ds\\right)^{-1 } \\frac{1}{\\sqrt{t}}\\int_{0}^{t}\\dot{\\bar\\pi}_{s}^{\\delta,\\bar{\\theta}}[\\bar{h}_{\\bar\\theta } ] d\\nu_{s}=\\left(f^{\\delta}_{t}(\\bar{\\theta},\\alpha^{*})\\right)^{-1 } \\frac{1}{\\sqrt{t}}\\int_{0}^{t}\\dot{\\bar\\pi}_{s}^{\\delta,\\bar{\\theta}}[\\bar{h}_{\\bar\\theta}]d\\nu_{s}\\nonumber\\\\ & \\qquad=\\tilde{w}\\left(\\left(\\left(f^{\\delta}_{t}(\\bar{\\theta},\\alpha^{*})\\right)^{\\top}\\right)^{-1 } f^{\\delta}_{t}(\\bar{\\theta},\\bar{\\theta } ) \\left(f^{\\delta}_{t}(\\bar{\\theta},\\alpha^{*})\\right)^{-1}\\right)\\nonumber   \\end{aligned}\\ ] ]    since @xmath209 , theorem [ t : consisitencyreducedlikelihood ] implies that @xmath210 and hence by the almost sure continuity of @xmath198 $ ] as a function of @xmath17 and condition [ a : extraconditionforclt ] , we obtain that in @xmath128 probability as @xmath33 and then @xmath27 @xmath211 then , slutsky s theorem implies that in distribution , first as @xmath33 and then as @xmath27 , @xmath212\\cdot\\dot{\\bar\\pi}_{s}^{\\delta,\\alpha^{*}}[\\bar{h}_{\\alpha^{*}}]ds\\right)^{-1 } \\frac{1}{\\sqrt{t } } \\int_{0}^{t}\\dot{\\bar\\pi}_{s}^{\\delta,\\bar{\\theta}}[\\bar{h}_{\\bar\\theta}]d\\nu_{s}\\rightarrow n\\left(0,i^{-1}(\\alpha)\\right).\\label{eq : limitclt2}\\end{aligned}\\ ] ]    limits ( [ eq : limitclt1 ] ) and ( [ eq : limitclt2 ] ) imply then the statement of the theorem by slutsky s theorem on the combined expression .",
    "in this section we consider numerically several examples in order to illustrate the results of this paper . even though the theory of this paper has been developed under the assumption that @xmath213 is bounded",
    ", the numerical results of this section indicate that there is some degree of flexibility to this assumption and that the results should be broader applicable .",
    "let @xmath17 be a finite - dimensional parameter and consider the system of equations @xmath214 where @xmath215 and @xmath216 , @xmath217 , and @xmath218 take values in @xmath219 . without loss of generality and for presentation purposes the theory of the paper was developed for @xmath220 , but as we shall see here the same results hold with @xmath221 as long as @xmath222 is non - degenerate",
    ".    let us further assume that we know the invariant measure for @xmath25 and that it is given by @xmath223 .",
    "then , we know that the limit of ( [ eq : modelexampleprelimit ] ) in probability as @xmath33 is @xmath224    it is relatively easy to see that the diffusion coefficient @xmath222 can be viewed as a scaling factor . under @xmath128 , the process @xmath225\\}$ ] defined by the equation @xmath226ds\\right)\\qquad\\forall t\\in[0,t]\\ ] ] is a @xmath166-brownian motion under the filtration generated from the observed @xmath29 process .",
    "the maximizer satisfies @xmath227\\left(dy_{s}^{\\delta}-\\bar\\pi_{s}^{\\delta,\\tilde{\\theta}}[\\bar{h}_{\\tilde\\theta}]ds\\right)=0\\ , \\ ] ] and the fisher information turns out to be @xmath228^{\\top}\\cdot\\nabla_{\\alpha}\\bar\\pi_{s}^{\\alpha}[\\bar{h}_{\\alpha } ] ds \\ .\\ ] ]    the limiting system ( [ eq : modelexamplelimit ] ) uses the well - known kalman - bucy filter . the inference problem for the limiting linear system ( [ eq : modelexamplelimit ] ) was studied in @xcite . in @xcite ,",
    "the author develops mle estimators for @xmath17 based on ( [ eq : modelexamplelimit ] ) , i.e. using as data @xmath229 .",
    "however , the difference of our setup with the rest of the literature is that we want to estimate @xmath17 based on observations @xmath230 , which come from the multiscale model ( [ eq : modelexampleprelimit ] ) and not from the limit model ( [ eq : modelexamplelimit ] ) . of course",
    ", the limit problem is used in order to derive properties of the estimators , but the actual inference is done based on observations from the multiscale model .",
    "let us write @xmath231 , @xmath232 .",
    "notice that in the notation of section [ s : problemformulation ] we have @xmath233 and @xmath234 .",
    "let us compute the fisher information matrix @xmath191 for this model and derive the conditions under which @xmath191 is strictly positive and the model is identifiable .",
    "let us first denote @xmath235 $ ] .",
    "it is known that @xmath236 satisfies the equation @xmath237 where @xmath238 solves the ricatti equation @xmath239 next let us define @xmath240    it is easy to see that if @xmath241 , then @xmath242 for all @xmath243 , which implies that @xmath244 is a stationary solution to ( [ eq : kalman02 ] ) .",
    "if on the other hand @xmath245 then @xmath246 converges exponentially fast to @xmath244 , see section 3.1.1 of @xcite . hence , in order to simplify things , let us assume that ( [ eq : kalman01 ] ) and ( [ eq : kalman02 ] ) are in the stationary regime . in this case , if the initial distribution of @xmath247 is @xmath248,\\frac{\\sigma^{2}}{\\bar{a}^{2}(\\theta)}\\zeta(\\theta)\\right)$ ] then @xmath249,\\frac{\\sigma^{2}}{\\bar{a}^{2}(\\theta)}\\zeta(\\theta)\\right)$ ] for all @xmath243 . in this case",
    "@xmath250=\\bar{a}(\\theta)\\hat{\\bar u}_{t}$ ] will satisfy the equation @xmath251&=&-\\bar{\\beta}(\\theta)\\bar{\\pi}^{\\theta}_{t}[\\bar{h}_{\\theta}]dt+ \\zeta(\\theta)\\left(d\\bar{y}_{t}-\\bar{\\pi}^{\\theta}_{t}[\\bar{h}_{\\theta}]dt\\right)\\ .\\label{eq : averagedlinearfilter } \\ ] ]    now notice that if @xmath252 ( i.e. , the true parameter value ) , then @xmath253 defined by @xmath254dt\\right)$ ] is a @xmath128 brownian motion . in the general case",
    "@xmath250 $ ] satisfies the averaged linear sde ( [ eq : averagedlinearfilter ] ) , so when @xmath252 we have @xmath255=\\bar{\\pi}^{\\alpha}_{0}[\\bar{h}_{\\alpha}]e^{-\\bar{\\beta}(\\alpha)t}+ \\zeta(\\alpha ) \\sigma\\int_{0}^{t}e^{-\\bar{\\beta}(\\alpha)(t - s)}d\\bar{\\nu}_{s}\\ , \\ ] ] from which it is clear that @xmath256 $ ] is gaussian with invariant law @xmath257 .",
    "next , considering the derivative of @xmath250 $ ] with respect to @xmath17 , at @xmath252 we find that @xmath258 $ ] satisfies the sde @xmath259=\\left(-\\dot{\\bar{\\beta}}(\\alpha)\\bar{\\pi}^{\\alpha}_{t}[\\bar{h}_{\\alpha}]-\\kappa(\\alpha)\\dot{\\bar{\\pi}}^{\\alpha}_{t}[\\bar{h}_{\\alpha}]\\right)dt + \\dot{\\zeta}(\\alpha ) \\sigma d\\bar{\\nu}_{t}\\ , \\label{eq : kalman1}\\ ] ] and thus we obtain @xmath260=\\dot{\\bar{\\pi}}^{\\alpha}_{0}[\\bar{h}_{\\alpha}]e^{-\\kappa(\\alpha)t } -\\dot{\\bar{\\beta}}(\\alpha)\\int_{0}^{t}e^{-\\kappa(\\alpha)(t - s)}\\bar{\\pi}^{\\alpha}_{s}[\\bar{h}_{\\alpha}]ds + \\dot{\\zeta}(\\alpha)\\int_{0}^{t}e^{-\\kappa(\\alpha)(t - s ) } \\sigma d\\bar{\\nu}_{s}\\ , \\label{eq : kalman2}\\ ] ] from which fubini s theorem gives @xmath260=\\int_{0}^{t}e^{-\\kappa(\\alpha)(t - s)}\\left(\\dot{\\kappa}(\\alpha)-\\dot{\\bar{\\beta}}(\\alpha)e^{\\zeta(\\alpha)(t - s)}\\right ) \\sigma",
    "d\\bar{\\nu}_{s}+o(1)\\ .\\label{eq : kalman3}\\ ] ] hence , by direct computation using ( [ eq : kalman3 ] ) we can compute the asymptotic variance of the mle .",
    "in particular , we obtain that in @xmath128 probability @xmath261 \\right|^{2}ds\\nonumber\\\\ & = \\frac{\\dot{\\bar{\\beta}}^{2}(\\alpha)}{2\\bar{\\beta}(\\alpha)}+\\frac{\\dot{\\kappa}^{2}(\\alpha)}{2\\kappa(\\alpha)}-2\\frac{\\dot{\\bar{\\beta}}(\\alpha)\\dot{\\kappa}(\\alpha)}{\\bar{\\beta}(\\alpha)+\\kappa(\\alpha)}\\ .\\label{eq : fisherinformation}\\end{aligned}\\ ] ]    let us assume now that    [ a : assumptionlinearproblem ] for any compact @xmath262 and for any @xmath157    * @xmath263 , * @xmath264 .",
    "it is then proven in a related case in section 3.1.1 of @xcite , that in the specific example condition [ a : assumptionlinearproblem ] implies essentially condition [ a : assumptionidentifiability ] , i.e. , we have identifiability of the model , and that the asymptotic variance is strictly positive , i.e. @xmath265 .",
    "let us next present some simulation studies based on the model problem ( [ eq : modelexampleprelimit ] ) .",
    "we consider three different examples .",
    "the examples lack the boundedness of assumption on @xmath213 indicating the broader applicability of the theoretical results of this paper .",
    "let the processes be scalars @xmath266 , and consider the following example of the system in : @xmath267 a key feature of this example is that the process @xmath24 behaves like a multiplicative noise factor .",
    "figure [ fig : example1data ] shows a realization of the system for a parameterization having @xmath268 , @xmath269 , @xmath270 , along with a true @xmath271 and discrete time step @xmath272 .",
    ".,width=384 ]    in this case the invariant measure @xmath273 of the @xmath25 process with @xmath274 is that corresponding to @xmath275 .",
    "notice also that we can compute the fisher information from ( [ eq : fisherinformation ] ) in closed form and obtain @xmath276 table [ t : cltvar1 ] presents the standard error for the empirical error for estimator alongside the predicted error from the fisher information .",
    "the table shows a comparison for different values of the true parameter .",
    "@xmath17 & estimator & empirical std - err . & theoretical std.err + 0&-0.0170&0.0982&0.0900 + 1&0.9844&0.0618&0.0542 + 1.5&1.4591&0.0503 & 0.0422 +    in figure [ fig : example1hists ] we present the histograms for the three different cases of true value of the @xmath50 parameter , together with the fitted theoretical normal curve as this is given by theorem [ t : cltreducedlikelihood ]",
    "* top right : * @xmath277 . *",
    "bottom : * @xmath278.,title=\"fig:\",width=288 ] & . * top right : * @xmath277 . *",
    "bottom : * @xmath278.,title=\"fig:\",width=288 ] +      let the processes be scalars @xmath266 , and consider the following example of the system in : @xmath279 a key feature of this example is that the process @xmath24 inserts noise @xmath280 process s the rate of mean reversion .",
    "figure [ fig : example2data ] shows a realization of the system for a parameterization having @xmath268 , @xmath269 , @xmath270 , along with a true @xmath271 and discrete time step @xmath272 .",
    ".,width=384 ]    as in the case of example 1 , the invariant measure @xmath273 of the @xmath25 process with @xmath274 is that corresponding to @xmath275 .",
    "notice also that we can compute the fisher information from in closed form and obtain @xmath281     @xmath17 & estimator & empirical std - err . & theoretical std.err + 0.5&0.5396&0.2385 & 0.2303 + 1&1.0268&0.1943 & 0.1917 + 1.5&1.5346&0.1815 & 0.1734 +    table [ t : cltvar2 ] shows the estimator s standard deviation and the theoretical prediction for various values of the true parameter . in figure [",
    "fig : example2hists ] we present the histograms for the three different cases of true value of the @xmath50 parameter , together with the fitted theoretical normal curve as this is given by theorem [ t : cltreducedlikelihood ] .",
    "* top right : * @xmath277 . *",
    "bottom : * @xmath278.,title=\"fig:\",width=288 ] & . *",
    "top right : * @xmath277 .",
    "* bottom : * @xmath278.,title=\"fig:\",width=288 ] +      let the processes be scalars @xmath266 , and consider the following system :    @xmath282    where @xmath26 is a continuous time markov chain taking values in @xmath283 with transition intensity @xmath284 , that is @xmath285 this example is different from the system in because the @xmath26 process is not a diffusion ; it is comparable to the model considered in @xcite .",
    "indeed , @xmath286 is a discrete space markov chain and not a continuous diffusion , and so the theory of this paper does not apply , but we conjecture that things can be worked out to find analogous results .",
    "figure [ fig : example3data ] shows a realization and the filter for this example .",
    ".,width=384 ]    table [ t : cltvar3 ] shows the estimator s standard deviation and the theoretical prediction for various values of the true parameter , but in this case we have no close - form expression for the fisher information , so instead we have calculated it numerically .",
    "@xmath17 & estimator & empirical std - err .",
    "& numerically calculated std.err + 0.7&0.7349&0.2305&0.1917 + 1&1.0469&0.2697&0.2253 + 1.8&1.8990&0.3968&0.3058 +    then , in figures [ fig : example3hists ] we present the histograms for the three different cases of true value of the @xmath50 parameter , together with the fitted empirical normal curve . since , out theory does not cover this case , we can not provide the theoretical variance of the estimator .",
    "however , as the numerical simulations indicate , a central limit theorem is expected to hold .",
    "* top right : * @xmath277 .",
    "* bottom : * @xmath287.,title=\"fig:\",width=288 ] & . *",
    "top right : * @xmath277 .",
    "* bottom : * @xmath287.,title=\"fig:\",width=288 ] +",
    "versions of theorem [ t : filterconvergence1 ] in simpler settings have appeared in the literature in @xcite .",
    "the first main difference that theorem [ t : filterconvergence1 ] has when compared to the previous works is that under the measure parameterized by the true parameter value ( i.e. the measure under which the observations are made ) the filters will converge for _ any _ parameter value .",
    "moreover , the second main difference is that we need to prove that the convergence of the filters is for test functions in the space the space @xmath288 , whereas the results in @xcite use bounded and smooth test functions that depend only on the slow motion @xmath26 .",
    "[ l : neededergodicresult ] assume condition [ a : assumption1 ] .",
    "let us consider an independent copy of @xmath289 , which has the same law as @xmath290 , but which is independent of @xmath290 .",
    "then , we have @xmath291 and @xmath292    we will only prove the first statement as the proof of the second statement is the same .",
    "hlder inequality for @xmath293 such that @xmath294 gives @xmath295\\right)^{1/r_{2}}\\ .\\nonumber\\end{aligned}\\ ] ]      let us define the process @xmath298 by the dominated convergence theorem and the independence of pairs @xmath299 and @xmath300 , the ergodic theory applies to the joint process @xmath301 , and in particular we see that the limit of @xmath302 is @xmath303 this proves convergence in @xmath192 .",
    "convergence in @xmath304 follows again from dominated convergence theorem , since @xmath305 .",
    "it now remains to show that @xmath306^{r_{1}}\\nonumber\\\\ & \\rightarrow 0 , \\text { as } \\delta\\downarrow 0\\ .\\nonumber\\end{aligned}\\ ] ] to do this we use the elementary inequality @xmath307 hence , we get for @xmath308 such that @xmath309 and @xmath310 @xmath311 \\leq \\left(\\mathbb e_\\theta^ * |\\xi_{t}^{\\delta}|^{r_1r_{5}}\\right)^{1/r_{5}}\\left(\\mathbb e_\\theta^ * e^{r_{1}r_{6 } |\\xi_{t}^{\\delta}}|\\right)^{1/r_{6}}\\rightarrow 0 , \\text { as } \\delta\\downarrow 0,\\nonumber\\end{aligned}\\ ] ] concluding the proof of the lemma .",
    "[ l : filterconvergence3 ] let us consider bounded @xmath91 and assume condition [ a : assumption1 ] . for any @xmath47 , we have uniformly in @xmath124 $ ] @xmath312-\\phi_t^{\\delta,\\theta}[\\bar f_\\theta]\\right|^{2}\\rightarrow 0\\qquad\\hbox{as } \\delta\\rightarrow0\\ , \\ ] ]      let us consider an independent copy of @xmath315 , which has the same law as @xmath316 , but which is independent of @xmath317 .",
    "we have @xmath318-\\phi_t^{\\delta,\\theta}[\\bar f_\\theta]\\right)^2\\nonumber\\\\ & = \\mathbb e_\\theta^*\\left(\\phi_t^{\\delta,\\theta}[f-\\bar f_\\theta]\\right)^2\\nonumber\\\\ & = \\mathbb e_\\theta^*\\left[\\mathbb e_\\theta^*\\left[\\left(f(x_t^\\delta , u_t^\\delta)-\\bar f_\\theta(u_t^\\delta)\\right)\\exp\\left ( \\int_{0}^th_{\\theta}(x^{\\delta}_{s},u_s^\\delta)dy_s^\\delta-\\frac{1}{2}\\int_{0}^t\\left|h_{\\theta}(x^{\\delta}_{s},u_s^\\delta)\\right|^{2}ds    \\right)\\big|\\mathcal y_t^\\delta\\right]^2\\right]\\nonumber\\\\ & = \\mathbb e_\\theta^*\\bigg[\\mathbb e_\\theta^*\\bigg[\\big(f(x_t^\\delta , u_t^\\delta)-\\bar f_\\theta(u_t^\\delta)\\big)\\big(f(\\widetilde x_t^\\delta,\\widetilde u_t^\\delta)-\\bar f_\\theta(\\widetilde u_t^\\delta)\\big)\\nonumber\\\\ & \\times\\exp\\left ( \\int_{0}^t\\left(h_{\\theta}(x^{\\delta}_{s},u_s^\\delta)+h_{\\theta}(\\widetilde x^{\\delta}_{s},\\widetilde u_s^\\delta)\\right)dy_s^\\delta-\\frac{1}{2}\\int_{0}^t\\left(\\left|h_{\\theta}(x^{\\delta}_{s},u_s^\\delta)\\right|^{2}+\\left|h_{\\theta}(\\widetilde x^{\\delta}_{s},\\widetilde u_s^\\delta)\\right|^{2}\\right)ds    \\right)\\big|\\mathcal y_t^\\delta\\bigg]\\bigg]\\nonumber\\\\ & = \\mathbb e_\\theta^*\\bigg[\\mathbb e_\\theta^*\\bigg[\\big(f(x_t^\\delta , u_t^\\delta)-\\bar f_\\theta(u_t^\\delta)\\big)\\big(f(\\widetilde x_t^\\delta,\\widetilde u_t^\\delta)-\\bar f_\\theta(\\widetilde u_t^\\delta)\\big)\\nonumber\\\\ & \\hspace{2cm}\\times\\exp\\left ( \\int_{0}^t\\left(h_{\\theta}(x^{\\delta}_{s},u_s^\\delta)+h_{\\theta}(\\widetilde x^{\\delta}_{s},\\widetilde u_s^\\delta)\\right)dy_s^\\delta\\right.\\nonumber\\\\ & \\hspace{5cm}\\left.-\\frac{1}{2}\\int_{0}^t\\left(\\left|h_{\\theta}(x^{\\delta}_{s},u_s^\\delta)\\right|^{2}+\\left|h_{\\theta}(\\widetilde x^{\\delta}_{s},\\widetilde u_s^\\delta)\\right|^{2}\\right)ds    \\right)\\big|\\mathcal f_t^{u,\\tilde u , x,\\tilde x}\\bigg]\\bigg]\\nonumber\\\\ & = \\mathbb e_\\theta^*\\bigg[\\big(f(x_t^\\delta , u_t^\\delta)-\\bar f_\\theta(u_t^\\delta)\\big)\\big(f(\\widetilde x_t^\\delta,\\widetilde u_t^\\delta)-\\bar f_\\theta(\\widetilde u_t^\\delta)\\big)\\exp\\left(\\int_{0}^{t}h_{\\theta}(x^{\\delta}_{s},u_s^\\delta)h_{\\theta}(\\widetilde x^{\\delta}_{s},\\widetilde u_s^\\delta)ds    \\right)\\bigg ] \\nonumber\\\\ & = \\mathbb e_\\theta^ * \\bigg[\\big(f(x_t^\\delta , u_t^\\delta)-\\bar f_\\theta(u_t^\\delta)\\big)\\big(f(\\widetilde x_t^\\delta,\\widetilde u_t^\\delta)-\\bar f_\\theta(\\widetilde u_t^\\delta)\\big)\\nonumber\\\\ & \\hspace{1cm}\\times\\bigg(\\exp\\left(\\int_{0}^{t}h_{\\theta}(x^{\\delta}_{s},u_s^\\delta)h_{\\theta}(\\widetilde x^{\\delta}_{s},\\widetilde u_s^\\delta)ds\\right)-\\exp\\left(\\int_0^th_{\\theta}(\\tilde{x}_s^\\delta , \\tilde{u}_s^\\delta ) \\bar h_\\theta(\\bar   u_s)ds\\right)\\bigg)\\bigg]\\nonumber\\\\ & ~~+\\mathbb e_\\theta^*\\bigg[\\big(f(x_t^\\delta , u_t^\\delta)-\\bar f_\\theta(u_t^\\delta)\\big)\\big(f(\\widetilde x_t^\\delta,\\widetilde u_t^\\delta)-\\bar f_\\theta(\\widetilde u_t^\\delta)\\big)\\exp\\left(\\int_0^th_{\\theta}(\\tilde{x}_s^\\delta , \\tilde{u}_s^\\delta ) \\bar h_\\theta(\\bar   u_s)ds\\right)\\bigg ]",
    "\\label{eq : unnormalizedfilter0}\\ .\\end{aligned}\\ ] ] in the 2nd to last line of the above display , the term goes to zero by lemma [ l : neededergodicresult ] , @xmath319\\bigg|\\\\ & \\leq 4\\|f\\|_\\infty^2 \\mathbb e_\\theta^ * \\bigg|\\exp\\left(\\int_{0}^{t}h_{\\theta}(x^{\\delta}_{s},u_s^\\delta)h_{\\theta}(\\widetilde x^{\\delta}_{s},\\widetilde u_s^\\delta)ds\\right)-\\exp\\left(\\int_0^th_{\\theta}(\\tilde{x}_s^\\delta , \\tilde{u}_s^\\delta ) \\bar h_\\theta(\\bar   u_s)ds\\right ) \\bigg|\\\\ & \\rightarrow 0\\ , \\end{aligned}\\ ] ] and the term in the last line of the display ( [ eq : unnormalizedfilter0 ] ) goes to zero as follows ,    @xmath320\\bigg|\\\\ & \\leq 4\\|f\\|_\\infty^2 \\mathbb e_\\theta^*\\bigg|\\exp\\left(\\int_0^th_{\\theta}(\\tilde{x}_s^\\delta , \\tilde{u}_s^\\delta ) \\bar h_\\theta(\\bar   u_s)ds\\right)-\\exp\\left(\\int_0^{t-\\epsilon}h_{\\theta}(\\tilde{x}_s^\\delta , \\tilde{u}_s^\\delta ) \\bar h_\\theta(\\bar   u_s)ds\\right)\\bigg|\\\\ & + \\bigg|\\mathbb e_\\theta^*\\bigg[\\mathbb e_\\theta^*\\big[f(x_t^\\delta , u_t^\\delta)-\\bar f_\\theta(u_t^\\delta)\\big|\\mathcal f_{t-\\epsilon}^{u^{\\delta},\\bar u}\\vee\\mathcal f_t^{\\tilde u^{\\delta},\\tilde x^{\\delta}}\\big]\\big(f(\\widetilde x_t^\\delta,\\widetilde u_t^\\delta)-\\bar f_\\theta(\\widetilde u_t^\\delta)\\big)\\exp\\left(\\int_0^{t-\\epsilon}h_{\\theta}(\\tilde{x}_s^\\delta , \\tilde{u}_s^\\delta ) \\bar h_\\theta(\\bar   u_s)ds\\right)\\bigg]\\bigg|\\\\ & \\leq 4\\|f\\|_\\infty^2 \\mathbb e_\\theta^*\\bigg|\\exp\\left(\\int_0^th_{\\theta}(\\tilde{x}_s^\\delta , \\tilde{u}_s^\\delta ) \\bar h_\\theta(\\bar   u_s)ds\\right)-\\exp\\left(\\int_0^{t-\\epsilon}h_{\\theta}(\\tilde{x}_s^\\delta , \\tilde{u}_s^\\delta ) \\bar h_\\theta(\\bar   u_s)ds\\right)\\bigg|\\\\ & \\hspace{2cm}+2\\|f\\|_\\infty \\mathbb e_\\theta^*\\bigg[\\big|\\mathbb e_\\theta^*\\big[f(x_t^\\delta , u_t^\\delta)-\\bar f_\\theta(u_t^\\delta)\\big|\\mathcal f_{t-\\epsilon}^{u^{\\delta},\\bar u}\\vee\\mathcal f_t^{\\tilde u^{\\delta},\\tilde x^{\\delta}}\\big]\\big|\\exp\\left(\\int_0^{t-\\epsilon}h_{\\theta}(\\tilde{x}_s^\\delta , \\tilde{u}_s^\\delta ) \\bar h_\\theta(\\bar   u_s)ds\\right)\\bigg]\\\\ & = 4\\|f\\|_\\infty^2 \\mathbb e_\\theta^*\\bigg|\\exp\\left(\\int_0^th_{\\theta}(\\tilde{x}_s^\\delta , \\tilde{u}_s^\\delta ) \\bar h_\\theta(\\bar   u_s)ds\\right)-\\exp\\left(\\int_0^{t-\\epsilon}h_{\\theta}(\\tilde{x}_s^\\delta , \\tilde{u}_s^\\delta ) \\bar h_\\theta(\\bar   u_s)ds\\right)\\bigg|\\\\ & \\hspace{2cm}+2\\|f\\|_\\infty \\mathbb e_\\theta^*\\bigg[\\big|\\mathbb e_\\theta^*\\big[f(x_t^\\delta , u_t^\\delta)-\\bar f_\\theta(u_t^\\delta)\\big|\\mathcal f_{t-\\epsilon}^{u^{\\delta},\\bar u}\\big]\\big|\\exp\\left(\\int_0^{t-\\epsilon}h_{\\theta}(\\tilde{x}_s^\\delta , \\tilde{u}_s^\\delta ) \\bar h_\\theta(\\bar   u_s)ds\\right)\\bigg]\\\\ & \\rightarrow 4\\|f\\|_\\infty^2 \\mathbb e_\\theta^*\\bigg|\\exp\\left(\\int_0^t\\bar h_{\\theta}(\\tilde{\\bar u}_s ) \\bar h_\\theta(\\bar   u_s)ds\\right)-\\exp\\left(\\int_0^{t-\\epsilon}\\bar h_{\\theta}(\\tilde{\\bar u}_s ) \\bar h_\\theta(\\bar   u_s)ds\\right)\\bigg|\\ , \\text { as } \\delta\\downarrow 0\\end{aligned}\\ ] ]    where @xmath157 can be arbitrarily small .",
    "the limit is taken as @xmath321 , with the conditional expectation being handled in the following way : @xmath322\\\\ & = \\mathbb e_\\theta^*\\big[f(x_t^\\delta , u_t^\\delta)-\\bar f_\\theta(u_t^\\delta)\\big|\\mathcal f_{t-\\epsilon}^{u^{\\delta},\\bar u}\\big]\\qquad\\qquad\\hbox{by independence of $ ( u^{\\delta},x^{\\delta})$ from $ ( \\tilde u^{\\delta},\\tilde x^{\\delta})$,}\\\\ & = \\mathbb e_\\theta^*\\big[\\mathbb e_\\theta^*\\big[f(x_t^\\delta , u_t^\\delta)-\\bar f_\\theta(u_t^\\delta)\\big|x^\\delta_{t-\\epsilon},u^{\\delta}_{t-\\epsilon}\\big]\\big|\\mathcal f_{t-\\epsilon}^{u^{\\delta},\\bar u}\\big]\\\\ & \\rightarrow 0\\ , \\end{aligned}\\ ] ] the last convergence is due to the fact that @xmath323\\rightarrow 0 $ ] as @xmath321 for any @xmath157 because of the ergodicity implied by condition [ a : assumption1 ] . moreover , owing to condition [ a : assumption1 ] s assumptions on @xmath324 @xmath325 as @xmath326 by dominated convergence theorem .",
    "hence , the remaining term is arbitrarily small , and we conclude that all terms converge to zero with @xmath23 .",
    "[ l : boundedz ] given that @xmath213 is bounded , then for any @xmath327 we have that @xmath328}\\sup_{\\delta\\in(0,1)}\\mathbb{e}_{\\theta}^{*}|z^{\\delta,\\theta}_{t}|^{q}+   \\sup_{t\\in[0,t]}\\sup_{\\delta\\in(0,1)}\\mathbb{e}_{\\theta}|z^{\\delta,\\theta}_{t}|^{-q}<\\infty\\ .\\ ] ]    [ l : filterconvergence5 ] let us consider bounded @xmath329 and assume condition [ a : assumption1 ] . for any @xmath123",
    ", we have uniformly in @xmath124 $ ] @xmath330-\\bar\\pi_t^{\\delta,\\theta } [ f]\\right|\\rightarrow 0\\qquad\\hbox{as } \\delta\\rightarrow0\\ , \\ ] ] where @xmath331=\\bar \\phi_t^{\\delta,\\theta}[f]/\\bar \\pi_t^{\\delta,\\theta}[1]$ ] is the averaged filter given by .",
    "let us consider an independent copy of @xmath289 , which has the same law as @xmath332 , but which is independent of @xmath333 .",
    "we have @xmath334-\\bar\\phi_t^{\\delta,\\theta}[f]\\right)^2 & \\leq \\cancelto{0}{\\mathbb e_\\theta^*\\left(\\phi_t^{\\delta,\\theta}[f]-\\phi_t^{\\delta,\\theta}[\\bar f_\\theta]\\right)^2}+\\mathbb e_\\theta^*\\left(\\phi_t^{\\delta,\\theta}[\\bar f_\\theta]-\\bar\\phi_t^{\\delta,\\theta}[f]\\right)^2\\\\end{aligned}\\ ] ]    the first term of the last display goes to zero by lemma [ l : filterconvergence3 ] . for the second term we have @xmath335-\\bar\\phi_t^{\\delta,\\theta}[\\bar f_\\theta]\\right)^2\\nonumber\\\\ & = \\mathbb e_\\theta^*\\left[\\mathbb e_\\theta^*\\left[\\bar f_\\theta(u_t^\\delta)z_t^{\\delta,\\theta}-\\bar f_\\theta(\\bar u_t)\\bar z_t^{\\delta,\\theta}\\big|\\mathcal y_t^\\delta\\right]^2\\right]\\nonumber\\\\ & = \\mathbb e_\\theta^*\\left[\\mathbb e_\\theta^*\\left[(\\bar f_\\theta(u_t^\\delta ) z_t^{\\delta,\\theta}-\\bar f_\\theta(\\bar u_t ) \\bar z_t^{\\delta,\\theta})(\\bar f_\\theta(\\tilde u_t^\\delta)\\tilde z_t^{\\delta,\\theta}-\\bar f_\\theta(\\tilde{\\bar u}_t)\\tilde{\\bar z}_t^{\\delta,\\theta})\\big|\\mathcal y_t^\\delta\\right]\\right]\\nonumber\\\\ & = \\mathbb e_\\theta^*\\left[\\mathbb e_\\theta^*\\left[(\\bar f_\\theta(u_t^\\delta ) z_t^{\\delta,\\theta}-\\bar f_\\theta(\\bar u_t ) \\bar z_t^{\\delta,\\theta})(\\bar f_\\theta(\\tilde u_t^\\delta)\\tilde z_t^{\\delta,\\theta}-\\bar f_\\theta(\\tilde{\\bar u}_t)\\tilde{\\bar z}_t^{\\delta,\\theta})\\big|\\mathcal f_t^{\\delta , u,\\tilde u , x,\\tilde x}\\right]\\right]\\nonumber\\\\ & = \\mathbb e_\\theta^*\\left[\\bar",
    "f_\\theta(\\tilde u_t^\\delta)\\left[\\bar f_\\theta(u_t^\\delta)\\exp\\left(\\int_0^t h(\\tilde x_s^\\delta,\\tilde u_s^\\delta)h(x_s^\\delta , u_s^\\delta)ds\\right)-\\bar f_\\theta(\\bar u_t)\\exp\\left(\\int_0^th(\\tilde x_s^\\delta , \\tilde u_s^\\delta ) \\bar h_\\theta(\\bar u_s)ds\\right)\\right]\\right]\\nonumber\\\\ \\nonumber & \\hspace{1cm}+\\mathbb e_\\theta^*\\left[\\bar f_\\theta(\\tilde { \\bar u}_t)\\left[\\bar f_\\theta(\\bar u_t)\\exp\\left(\\int_0^t\\bar h_\\theta(\\bar u_s)\\bar h_\\theta(\\bar{\\widetilde{u}}_s)ds\\right)-\\bar f_\\theta(u_t^\\delta)\\exp\\left(\\int_0^th(x_s^\\delta , u_s^\\delta ) \\bar h_\\theta(\\tilde{\\bar u}_s)ds\\right)\\right]\\right]\\nonumber\\\\ & \\rightarrow 0 , \\text { as } \\delta\\downarrow 0\\ .\\label{eq : averagephiconvergence}\\end{aligned}\\ ] ]    the convergence in the last term is due to lemma [ l : neededergodicresult ] proceeding as in the proof of lemma [ l : filterconvergence3 ] .",
    "then , we have convergence in probability , @xmath336-\\bar\\phi_t^{\\delta,\\theta}[f]|\\geq\\epsilon)\\leq\\frac{1}{{\\epsilon}^2}\\mathbb e_\\theta^*\\left(\\phi_t^{\\delta,\\theta}[f]-\\bar\\phi_t^{\\delta,\\theta}[f]\\right)^2\\rightarrow 0 $ ] as @xmath337 for all @xmath157 .",
    "next , we notice that for @xmath338 such that @xmath294 and @xmath339 @xmath340/\\phi_t^{\\delta,\\theta}[1]-\\bar\\phi_t^{\\delta,\\theta}[f]/\\bar\\phi_t^{\\delta,\\theta}[1]\\right|^{p}= \\mathbb e^{*}_{\\theta}\\left|\\frac{\\phi_t^{\\delta,\\theta}[f]\\bar\\phi_t^{\\delta,\\theta}[1]-\\bar\\phi_t^{\\delta,\\theta}[f]\\phi_t^{\\delta,\\theta}[1]}{\\phi_t^{\\delta,\\theta}[1]\\bar\\phi_t^{\\delta,\\theta}[1]}\\right|^{p}\\nonumber\\\\ & \\leq c \\left(\\mathbb e^{*}_{\\theta}\\left|\\frac{1}{\\phi_t^{\\delta,\\theta}[1]\\bar\\phi_t^{\\delta,\\theta}[1]}\\right|^{pr_{1}}\\right)^{1/r_{1 } } \\left(\\mathbb e^{*}_{\\theta}\\left|\\phi_t^{\\delta,\\theta}[f]\\bar\\phi_t^{\\delta,\\theta}[1]-\\bar\\phi_t^{\\delta,\\theta}[f]\\phi_t^{\\delta,\\theta}[1]\\right|^{pr_{2}}\\right)^{1/r_{2}}\\nonumber\\\\ & \\leq c \\left(\\mathbb e^{*}_{\\theta}\\left|\\frac{1}{\\phi_t^{\\delta,\\theta}[1]\\bar\\phi_t^{\\delta,\\theta}[1]}\\right|^{pr_{1}}\\right)^{1/r_{1 } } \\left(\\mathbb e^{*}_{\\theta}\\left|\\phi_t^{\\delta,\\theta}[f]-\\bar\\phi_t^{\\delta,\\theta}[f]\\right|^{pr_{2}}+\\mathbb e^{*}_{\\theta}\\left|\\phi_t^{\\delta,\\theta}[1]-\\bar\\phi_t^{\\delta,\\theta}[1]\\right|^{pr_{2}}\\right)^{1/r_{2}}\\nonumber\\\\ & \\leq c \\left(\\mathbb e^{*}_{\\theta}\\left|\\frac{1}{\\phi_t^{\\delta,\\theta}[1]}\\right|^{2pr_{1}}+\\mathbb e^{*}_{\\theta}\\left|\\frac{1}{\\bar\\phi_t^{\\delta,\\theta}[1]}\\right|^{2pr_{1}}\\right)^{1/r_{1 } } \\left(\\mathbb e^{*}_{\\theta}\\left|\\phi_t^{\\delta,\\theta}[f]-\\bar\\phi_t^{\\delta,\\theta}[f]\\right|^{pr_{2}}+\\mathbb e^{*}_{\\theta}\\left|\\phi_t^{\\delta,\\theta}[1]-\\bar\\phi_t^{\\delta,\\theta}[1]\\right|^{pr_{2}}\\right)^{1/r_{2}}\\nonumber\\end{aligned}\\ ] ] where boundedness of @xmath94 was used . by combining lemma [ l : filterconvergence3 ] and ( [ eq : averagephiconvergence ] ) we get that @xmath340-\\bar\\phi_t^{\\delta,\\theta}[f]\\right|^{pr_{2}}+\\mathbb e^{*}_{\\theta}\\left|\\phi_t^{\\delta,\\theta}[1]-\\bar\\phi_t^{\\delta,\\theta}[1]\\right|^{pr_{2}}\\rightarrow 0\\end{aligned}\\ ] ] in addition , we have @xmath341}\\right|^{2pr_{1}}&\\leq \\mathbb e^{*}_{\\theta}\\left(z_t^{\\delta,\\theta}\\right)^{-2pr_{1}}=\\mathbb e^{*}_{\\theta}\\left[e^{*}_{\\theta}\\left[\\left(z_t^{\\delta,\\theta}\\right)^{-2pr_{1}}\\right]|\\mathcal f_t^ { u^{\\delta } , x^{\\delta}}\\right]\\nonumber\\\\ & = \\mathbb e^{*}_{\\theta}\\left[e^{(2p^{2}r^{2}_{1}+pr_{1})\\int_{0}^{t}|h_{\\theta}(x^{\\delta}_{s},u^{\\delta}_{s})|^{2}ds}\\right]\\nonumber\\\\ & < \\infty.\\end{aligned}\\ ] ] similarly , we can also obtain @xmath342}\\right|^{2pr_{1}}<\\infty$ ] . putting these statements together",
    "we obtain that @xmath343/\\phi_t^{\\delta,\\theta}[1]-\\bar\\phi_t^{\\delta,\\theta}[f]/\\bar\\phi_t^{\\delta,\\theta}[1]\\right|^{p}&=0.\\label{eq : ratiophis}\\end{aligned}\\ ] ]    then , by cauchy - schwartz inequality , we have @xmath344-\\bar\\pi_t^{\\delta,\\theta}[f]\\right|=\\mathbb e_{\\alpha}\\left|\\phi_t^{\\delta,\\theta}[f]/\\phi_t^{\\delta,\\theta}[1]-\\bar\\phi_t^{\\delta,\\theta}[f]/\\bar\\phi_t^{\\delta,\\theta}[1]\\right|\\nonumber\\\\ & \\leq   \\left(\\mathbb e^{*}_{\\alpha}\\left|z^{\\delta,\\alpha}_{t}\\right|^{q}\\right)^{1/q}\\left(\\mathbb e^{*}_{\\alpha}\\left|\\phi_t^{\\delta,\\theta}[f]/\\phi_t^{\\delta,\\theta}[1]-\\bar\\phi_t^{\\delta,\\theta}[f]/\\bar\\phi_t^{\\delta,\\theta}[1]\\right|^{p}\\right)^{1/p}\\nonumber\\\\   & \\leq   \\left(\\sup_{\\delta\\in(0,1)}\\left(\\mathbb e^{*}_{\\alpha}\\left|z^{\\delta,\\alpha}_{t}\\right|^{q}\\right)^{1/q}\\right)\\left(\\mathbb e^{*}_{\\theta}\\left|\\phi_t^{\\delta,\\theta}[f]/\\phi_t^{\\delta,\\theta}[1]-\\bar\\phi_t^{\\delta,\\theta}[f]/\\bar\\phi_t^{\\delta,\\theta}[1]\\right|^{p}\\right)^{1/p}\\nonumber\\\\   & \\rightarrow 0\\ , \\nonumber\\end{aligned}\\ ] ] which goes to zero as @xmath33 by lemma [ l : boundedz ] and by ( [ eq : ratiophis ] ) .",
    "the fourth line , i.e. , @xmath345/\\phi_t^{\\delta,\\theta}[1]-\\bar\\phi_t^{\\delta,\\theta}[f]/\\bar\\phi_t^{\\delta,\\theta}[1]\\right|^{p}=\\mathbb e_{\\theta}^*\\left|\\phi_t^{\\delta,\\theta}[f]/\\phi_t^{\\delta,\\theta}[1]-\\bar\\phi_t^{\\delta,\\theta}[f]/\\bar\\phi_t^{\\delta,\\theta}[1]\\right|^{p}\\ , \\ ] ] follows because both @xmath98 and @xmath346 are functionals of @xmath89 ( and no other random variable ) , and @xmath89 is a brownian motion under both measures @xmath347 and @xmath90 .",
    "let us prove just the second part of the theorem because the first part follows from a chebyshev inequality and lemma [ l : filterconvergence3 ] .",
    "we prove it first for @xmath125 .",
    "then , we prove under the assumption that there exists @xmath121 such that @xmath127 .",
    "so , let us assume that @xmath125 .",
    "we start the proof by proving first that @xmath348-\\bar \\pi_t^{\\delta , \\theta}[f]\\right)^2=0\\ .\\ ] ] letting @xmath349 , lemma [ l : filterconvergence3 ] implies convergence in @xmath350 probability , @xmath351-\\phi_t^{\\delta,\\theta}[\\bar f_\\theta]\\right|>{\\epsilon}\\right)\\leq \\frac{1}{{\\epsilon}}\\mathbb e_{\\theta}^*\\left|\\phi_t^{\\delta,\\theta}[f]-\\phi_t^{\\delta,\\theta}[\\bar f_\\theta]\\right|\\rightarrow 0\\qquad\\forall{\\epsilon}>0\\ , \\ ] ] now consider any @xmath125 , and again using a cauchy - schwartz inequality , @xmath352-\\bar{\\pi}_t^{\\delta,\\theta}[f]\\right|\\\\ \\nonumber & = \\lim_\\delta\\mathbb e_{\\alpha}\\left|\\pi_t^{\\delta,\\theta}[f]-\\bar{\\pi}_t^{\\delta,\\theta}[\\bar f_\\theta]\\right|\\\\ \\nonumber & \\leq \\lim_\\delta\\mathbb e_{\\alpha}\\left|\\pi_t^{\\delta,\\theta}[f]-\\pi_t^{\\delta,\\theta}[\\bar f_\\theta]\\right|+\\cancelto{0}{\\mathbb e_{\\alpha}\\left|\\pi_t^{\\delta,\\theta}[\\bar f_\\theta]-\\bar{\\pi}_t^{\\delta,\\theta}[\\bar f_\\theta]\\right|}\\qquad\\hbox{(by lemma \\ref{l : filterconvergence5})}\\\\ \\nonumber & = \\lim_\\delta\\mathbb e_{\\alpha}^*z_t^{\\delta,\\alpha}\\left|\\pi_t^{\\delta,\\theta}[f]-\\pi_t^{\\delta,\\theta}[\\bar f_\\theta]\\right|\\\\ \\nonumber & \\leq \\lim_\\delta\\left(\\mathbb",
    "e_{\\alpha}^*\\left(z_t^{\\delta,\\alpha}\\right)^q\\right)^{1/q}\\left(\\mathbb e_\\alpha^*\\left|\\pi_t^{\\delta,\\theta}[f]-\\pi_t^{\\delta,\\theta}[\\bar f_\\theta]\\right|^p\\right)^{1/p}\\\\ \\nonumber \\nonumber & \\leq\\underbrace{\\sup_{\\delta\\in(0,1)}\\left(\\mathbb e_{\\alpha}^*\\left(z_t^{\\delta,\\alpha}\\right)^q\\right)^{1/q}}_{<\\infty}\\lim_\\delta\\left(\\mathbb e_\\theta^*\\left|\\pi_t^{\\delta,\\theta}[f]-\\pi_t^{\\delta,\\theta}[\\bar f_\\theta]\\right|^p\\right)^{1/p}\\\\ \\label{eq : diff_converge } & = 0\\ , \\end{aligned}\\ ] ] where finiteness of @xmath353 follows from lemma [",
    "l : boundedz ] , and @xmath354-\\pi_t^{\\delta,\\theta}[\\bar f_\\theta]\\right|^p=\\lim_\\delta\\mathbb e_\\theta^*\\left|\\phi_t^{\\delta,\\theta}[f]/\\phi_t^{\\delta,\\theta}[1]-\\phi_t^{\\delta,\\theta}[\\bar f_\\theta]/\\phi_t^{\\delta,\\theta}[1]\\right|^p=0 $ ] follows as ( [ eq : ratiophis ] ) .",
    "this proves convergence in @xmath355 , and convergence in @xmath356 follows from dominated convergence because the test function @xmath94 was assumed bounded so that @xmath357-\\bar{\\pi}_t^{\\delta,\\theta}[f]\\right|^2\\leq 2 \\|f\\|_\\infty^2 $ ] .",
    "this completes the proof for @xmath125 .",
    "let us complete the proof by assuming that there exists an @xmath121 such that @xmath358 . for @xmath359",
    ", define @xmath360 and set @xmath361 .",
    "analogously define @xmath362\\doteq\\mathbb e_{\\theta}\\left[f_{n}(x_t^\\delta , u_t^\\delta)\\big|\\mathcal y_t^\\delta\\right],\\quad \\bar{f}_{n,\\theta}(u)=\\int_{\\mathcal{x}}f_{n}(x , u)\\mu_{\\theta}(x , u)dx.\\ ] ] since @xmath363 is bounded , we already know that @xmath364-\\bar \\pi_t^{\\theta}[f_{n}]\\right)^2=0 $ ] .",
    "so , it is enough to prove that @xmath365-\\pi_t^{\\delta,\\theta}[f_{n}]\\right)^2=0\\ ] ] and @xmath366-\\bar \\pi_t^{\\delta,\\theta}[f_{n}]\\right)^2=0.\\ ] ] both of these statements follow from the observation : for @xmath121 such that @xmath358 we have @xmath367 and in particular , letting @xmath368 , @xmath369 so that @xmath370 and @xmath371 , then taking the following similar set of steps as in equation we have @xmath372-\\pi_t^{\\delta,\\theta}[f_{n}]\\right|^2\\\\ \\nonumber & \\leq\\lim_{n\\rightarrow\\infty}\\limsup_{\\delta\\downarrow 0}\\mathbb e_{\\alpha}\\mathbb e_\\theta\\left[\\left|f(x_t^\\delta , u_t^\\delta)-f_n(x_t^\\delta , u_t^\\delta)\\right|^2\\big|\\mathcal y_t^\\delta\\right]\\\\ \\nonumber & \\leq\\lim_{n\\rightarrow\\infty}\\limsup_{\\delta\\downarrow 0}\\mathbb e_{\\alpha}^*z_t^{\\delta,\\alpha}\\mathbb e_\\theta\\left[\\left|f(x_t^\\delta , u_t^\\delta)-f_n(x_t^\\delta , u_t^\\delta)\\right|^2\\big|\\mathcal y_t^\\delta\\right]\\\\ \\nonumber & \\leq\\lim_{n\\rightarrow\\infty}\\limsup_{\\delta\\downarrow 0}\\left(\\mathbb e_{\\alpha}^*(z_t^{\\delta,\\alpha})^q\\right)^{1/q}\\left(\\mathbb e_\\alpha^*\\mathbb e_\\theta\\left[\\left|f(x_t^\\delta , u_t^\\delta)-f_n(x_t^\\delta , u_t^\\delta)\\right|^2\\big|\\mathcal y_t^\\delta\\right]^p\\right)^{1/p}\\\\ \\nonumber & \\leq\\lim_{n\\rightarrow\\infty}\\limsup_{\\delta\\downarrow 0}\\left(\\mathbb e_{\\alpha}^*(z_t^{\\delta,\\alpha})^q\\right)^{1/q}\\left(\\mathbb e_\\alpha^*\\mathbb e_\\theta\\left[\\left|f(x_t^\\delta , u_t^\\delta)-f_n(x_t^\\delta , u_t^\\delta)\\right|^{2p}\\big|\\mathcal y_t^\\delta\\right]\\right)^{1/p}\\\\ \\nonumber & = \\lim_{n\\rightarrow\\infty}\\limsup_{\\delta\\downarrow 0}\\left(\\mathbb e_{\\alpha}^*(z_t^{\\delta,\\alpha})^q\\right)^{1/q}\\left(\\mathbb e_\\theta^*\\mathbb e_\\theta\\left[\\left|f(x_t^\\delta , u_t^\\delta)-f_n(x_t^\\delta , u_t^\\delta)\\right|^{2p}\\big|\\mathcal y_t^\\delta\\right]\\right)^{1/p}\\\\ \\nonumber & = \\lim_{n\\rightarrow\\infty}\\limsup_{\\delta\\downarrow 0}\\left(\\mathbb e_{\\alpha}^*(z_t^{\\delta,\\alpha})^q\\right)^{1/q}\\left(\\mathbb e_\\theta\\left [ ( z_t^{\\delta,\\theta})^{-1}\\mathbb e_\\theta\\left[\\left|f(x_t^\\delta , u_t^\\delta)-f_n(x_t^\\delta , u_t^\\delta)\\right|^{2p}\\big|\\mathcal y_t^\\delta\\right]\\right]\\right)^{1/p}\\\\ & \\leq c \\lim_{n\\rightarrow\\infty}\\limsup_{\\delta\\downarrow 0}n^{-\\eta/2p^2}\\left(\\mathbb e_{\\alpha}^*\\left(z_t^{\\delta,\\alpha}\\right)^q\\right)^{1/q}\\left(\\mathbb e_\\theta ( z_t^{\\delta,\\theta})^{-q}\\right)^{1/q}\\left ( \\mathbb   e_{\\theta}\\left|f(x^{\\delta}_{t},u_t^\\delta)\\right|^{2+\\eta}\\right)^{1/p^2}\\nonumber\\\\ \\nonumber & = 0\\ .\\end{aligned}\\ ] ] the same limit can be shown for @xmath373-\\bar \\pi_t^{\\delta,\\theta}[f_{n}]\\right)^2 $ ] , but with @xmath374 and @xmath375 used instead .",
    "due to ergodicity , the proof of @xmath376-\\bar \\pi_t^{\\theta}[f]\\right|=0\\ , \\ ] ] follows similarly and thus omitted .",
    "this concludes the proof of the theorem ."
  ],
  "abstract_text": [
    "<S> we consider partially observed multiscale diffusion models that are specified up to an unknown vector parameter . </S>",
    "<S> we establish for a very general class of test functions that the filter of the original model converges to a filter of reduced dimension . </S>",
    "<S> then , this result is used to justify statistical estimation for the unknown parameters of interest based on the model of reduced dimension but using the original available data . </S>",
    "<S> this allows to learn the unknown parameters of interest while working in lower dimensions , as opposed to working with the original high dimensional system . </S>",
    "<S> simulation studies support and illustrate the theoretical results .    </S>",
    "<S> * keywords . * data assimilation , filtering , parameter estimation , homogenization , multiscale diffusions , dimension reduction . + </S>",
    "<S> * subject classifications . * 93e10 93e11 93c70 62m07 62m86 </S>"
  ]
}