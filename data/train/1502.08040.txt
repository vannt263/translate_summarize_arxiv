{
  "article_text": [
    "regular and noninvasive measurement of vital signs such as pulse rate ( pr ) , breathing rate ( br ) , pulse rate variability ( prv ) , blood oxygen level ( spo2 ) and blood pressure ( bp ) are important both in - hospital and at - home due to their fundamental role in the diagnosis of health conditions and monitoring of well - being . currently , the gold standard techniques to measure the vital signs are based on contact sensors such as ecg probes , chest straps , pulse oximeters and blood pressure cuffs .",
    "however , contact - based sensors are not convenient in all scenarios , e.g. contact sensors are known to cause skin damage in pre - mature babies during their treatment in a neonatal intensive care unit ( nicu ) .",
    "non - contact methods for vital sign monitoring using a camera has been recently shown to be feasible @xcite .",
    "being non - contact , camera - based vital sign monitoring have many applications  from monitoring newborn babies in the nicu to in - situ continuous monitoring in everyday scenarios like working in front of a computer .",
    "however , camera - based vital sign monitoring does not perform well for subjects having darker skin tones and/or under low lighting conditions as was highlighted in @xcite .",
    "furthermore , current known algorithms require a person to be nearly at rest facing a camera to ensure reliable measurements . in this paper , we address the challenge of reliable vital sign estimation for people having darker skin tones , under low lighting conditions and under different natural motion scenarios to expand the scope of camera - based vital sign monitoring .",
    "photoplethysmography ( ppg ) is an optical method to measure cardiac - synchronous blood volume change in body extremities such as the face , finger and earlobe . as the heart pumps blood , the volume of blood in the arteries and capillaries changes by a small amount in sync with the cardiac cycle .",
    "the change in blood volume in the arteries and capillaries underneath the skin leads to small change in the skin color .",
    "the goal of a camera - based vital sign monitoring system is to estimate the ppg waveform which is proportional to these small changes in skin color .",
    "vital signs such as pr , prv , spo2 and br can be derived from a well - acquired ppg waveform .    the two major challenges in estimating ppg using a camera are : ( i ) extremely low signal strength of the color - change signal , particularly for darker skin tones and/or under low lighting conditions , and ( ii ) motion artifacts due to an individual s movement in front of the camera .",
    "our main contribution in this paper is a new algorithm , labeled as _ distanceppg _ , that improves the signal strength of camera - based ppg signal estimate , with following three key contributions .    * a new method to improve the snr of camera - based ppg signal by combining the color - change signals obtained from different regions of the face using a weighted average . * a new automatic method for determining the weights based only on the video recording of the subject .",
    "the weights capture the effect of incident light intensity and blood perfusion underneath the skin on the strength of color - change signal obtained from a region . * a method to track different regions of the face separately as the person moves in front of the camera using a combination of a deformable face tracker @xcite and klt ( kanade - lucas - tomasi ) feature tracker @xcite to extract the ppg waveform under motion .    for different skin tones ( pale white to brown ) ,",
    "the distanceppg  algorithm improves the signal to noise ratio ( snr ) of the estimated ppg signal on an average by @xmath0  db compared to prior methods @xcite . particularly , the improvement in snr for non - white skin tone is @xmath1  db . we have evaluated ppg estimation under three natural motion scenarios : ( i ) reading content on screen , ( ii ) watching video , and ( iii ) talking .",
    "distanceppg  improves the snr of estimated camera ppg in these scenario by @xmath2  db on an average .",
    "further , it improves the snr of camera based ppg by as much as @xmath3  db under low lighting condition when compared to prior methods @xcite .",
    "the improvement in snr of camera - based ppg signal estimated using distanceppg  reduces the error in pulse rate estimates in various scenarios . using distanceppg ,",
    "the mean bias ( average difference between ground truth pulse oximeter  derived pr and camera - based ppg derived pr ) @xmath4 is @xmath5 beats per minute ( bpm ) with @xmath6 limit of agreement ( mean bias @xmath7 standard deviation of the difference ) between @xmath8 to @xmath9 bpm for @xmath10 subjects having skin tones ranging from fair white to brown / black .",
    "when using prior methods , the corresponding performance numbers are @xmath4 = @xmath11 with @xmath6 limit of agreement between @xmath12 to @xmath13 . under three motion scenario of reading , watching , and talking for @xmath14 subjects of varying skin tones , the mean deviation is @xmath4 = @xmath15 bpm with @xmath6 limit of agreement between @xmath16 to @xmath17 bpm using distanceppg . using prior methods , the corresponding performance numbers are @xmath18 bpm with @xmath6 limit of agreement between @xmath19 to @xmath20 bpm .",
    "further , distanceppg  reduces the root mean square error ( rmse ) in pulse rate variability estimation below @xmath21  ms for non - black skin tones using a @xmath22  fps camera .      over the past decade , several researchers have worked on measuring vital signs such as pr , prv , br , and spo2 using a camera @xcite .",
    "initially @xcite , external arrays of leds at @xmath23 nm and @xmath24 nm were used to illuminate a region of tissue for measuring pr using a monochrome cmos camera .",
    "it was shown later @xcite that pr and br can also be determined using simply a color camera and ambient illumination .",
    "the authors in @xcite found that the face is the best region to extract ppg signal because of better signal strength .",
    "they also reported that the _ green channel _ of the rgb camera perform better than red and blue channel for detecting pr and br .",
    "the fact that the green channel perform better is expected as the absorption spectra of hemoglobin ( hb ) and oxyhemoglobin ( hbo@xmath25 ) , two main constituent chromophores in blood , peaks in the region around @xmath26  nm , which is essentially the passband range of the green filters in color cameras .",
    "further in @xcite , the authors used a color webcam under ambient illumination to detect simultaneous pr , prv and br of multiple people in a video by using automatic face detection to define the face region .",
    "they used blind source separation ( bss ) to decompose the three camera channels ( red , green , blue ) into three independent source signals using independent component analysis ( ica ) algorithm , and extracted the ppg signal from one of the independent sources .",
    "more recently , authors in @xcite demonstrated that cyan , orange and green ( cog ) channels work better than red , green , and blue ( rgb ) channels of a camera for camera - based vital sign estimation .",
    "one possible explanation for better performance of cyan - orange - green ( cog ) channels could be the higher overlap between the passband of cyan ( @xmath27  nm ) , green ( @xmath28  nm ) , and orange ( @xmath29  nm ) with the peak in the absorption spectra of hb and hbo@xmath25 ( @xmath26  nm ) .",
    "most of the past work , however , did not report how camera - based ppg performs on individuals with different skin tones , under low lighting conditions , and for different motion scenarios .",
    "it is well - known that the higher amount of _ melanin _ present in darker skin tones absorbs a significant amount of incident light , and thus degrades the quality of the camera - based ppg signal , making the system ineffective for extracting vital signs in darker skin tones .",
    "recently , a pilot study conducted in nicu for monitoring pulse rate using a camera - based method showed difficulty under low lighting conditions and/or under infant motion @xcite .    to counter the motion challenge , the authors in  @xcite used automatic face detection in consecutive frames to track the face .",
    "but , they reported difficulties in continuously detecting faces under motion due to large false - negatives .",
    "another method is to compute 2d shifts in face location between consecutive frames @xcite using image correlation to model the motion . by simply computing the global 2d shifts",
    ", one can only capture the basic translation motion of face , and it is difficult to compensate for more natural motion like turning or tilting of the face , smiling or talking , generally found in in - situ scenarios .",
    "for a camera - based ppg estimation we record the video of a person facing a camera , and the objective is to develop an algorithm to estimate the underlying ppg signal @xmath30 using the recorded video .",
    "the recorded video is in the form of intensity signal @xmath31 comprising of sequences of frames @xmath32 . each frame of the video records the intensity level of the light reflected back from the face over a two dimensional grid of pixel @xmath33 in the camera sensor .",
    "if the camera sensor has multiple color channels ( e.g. red , green , blue ) , one can get separate intensity signals corresponding to each channel ( e.g. @xmath34 ) .",
    "in general , the measured intensity of any reflected light can be decomposed into two components : ( i ) intensity of illumination , and ( ii ) reflectance of the surface ( skin ) , i.e. @xmath35 the illumination intensity corresponds to the intensity of ambient or any dedicated light falling on the face . for ppg estimation , it is generally assumed that the light intensity remains same over the ppg estimation window ( typically @xmath36  sec in past works ) .",
    "the skin reflectance @xmath37 is equal to the fraction of light reflected back from the skin and consists of two level of light reflectance : ( i )  surface reflection , and ( ii )  subsurface reflection or backscattering .    a large part of the light incident on face gets reflected back from the surface of the skin , and is characterized by the skin s bidirectional reflectance distribution function ( brdf ) .",
    "remaining part of the incident light goes underneath the skin surface and is absorbed by the tissue and the chromophores ( hb , hbo@xmath25 ) present in blood inside arteries and capillaries .",
    "the volume of blood in the arteries and capillaries changes with each cardiac cycle and thus the level of absorption of light changes as well .",
    "since ppg signal , by definition , is proportional to this cardio - synchronous pulsatile blood volume change in the tissue @xcite , one can estimate ppg signal @xmath30 by estimating these small changes in subsurface light absorption .",
    "thus , the camera - based ppg signal is estimated by extracting small variations in the subsurface component of skin reflectance @xmath37 .",
    "since the incident light intensity @xmath38 is assumed to be constant over ppg estimation time window , any temporal change in the intensity of the light reflected back from the face region will be proportional to the changes in the reflectance of the skin surface @xmath37 . generally , these temporal changes in recorded intensity will be dominated by changes in surface reflection component unrelated to the underlying ppg signal of interest . as a first step for camera - based ppg estimation , one can spatially average the recorded intensity level @xmath31 over all the pixels in the face region to yield a measurement point per frame in the video @xcite .",
    "the basic idea is that by averaging the intensity signal , the incoherent changes in surface reflection component over all the pixels inside the face will cancel out , and the coherent changes in subsurface reflection component due to blood volume changes will add up to give an estimate @xmath39 .",
    "the spatially averaged intensity signal @xmath39 would be proportional to the changes in the subsurface reflectance component , and thus to the underlying ppg signal of interest .",
    "one generally filters @xmath39 signal between @xmath40  hz to @xmath14 hz ( frequency band of interest ) to extract the ppg signal .",
    "* challenge 1 : very low signal strength * : ppg signal extracted from camera video have low signal strength .",
    "this is because the skin vascular bed contains a very small amount of blood ( only @xmath41 of total blood in the body ) , and the blood volume itself experiences only a small ( @xmath42 ) change in sync with the cardiovascular pulse @xcite .",
    "thus , the change in subsurface skin reflectance due to cardio - synchronous changes in blood volume is very small . the small change in subsurface reflectance results in very small change in light intensity recorded using a camera placed at a distance . on the other hand ,",
    "the change in surface reflection component due to small movement of person is very large .",
    "for example , see figure  [ fig : roi ] where the top plot ( red ) shows recorded intensity changes in a single pixel marked on the forehead ( @xmath43 ) . when compared to the ground truth pulse oximeter  signal ( bottom , @xmath44 ) , it is clear that the raw intensity change variations in @xmath43 are unrelated to the underlying ppg signal and is dominated by a significant amount of surface reflectance changes    to estimate small changes in subsurface reflectance , a general idea used in most past work is to spatially average the recorded intensity level over the face region . for example , see the plot of @xmath39 in figure  [ fig : roi ] . clearly , @xmath39 is a better estimate of the ppg signal as is evident by comparing it with the ground truth pulse oximeter  signal ( bottom ) .",
    "the amplitude of @xmath39 is within @xmath45 in camera intensity scale ( all these signals are filtered between @xmath46 $ ]  and so they are centered around @xmath47 ) .",
    "this is at the level of the quantization step of @xmath48 bit adc present in cameras and thus camera - based ppg estimate is corrupted with large quantization noise .",
    "now , let us suppose we spatially average only the pixels within the square blocks @xmath49 marked on the face ( @xmath50  px in size ) in figure  [ fig : roi ] . by comparing the plot of @xmath51 , @xmath52 , and @xmath53",
    ", we can clearly see that there are differences in the quality of estimated color change ( or ppg ) signal from these regions ( @xmath54 is a better estimate than @xmath55 which is better than @xmath53 ) .",
    "past work has not fully exploited the fact that the quality of ppg estimates obtained from different regions of the face varies significantly across the face .",
    "strength of the ppg signal extracted from a patch of the imaged skin surface would depend on the intensity of light @xmath38 incident on that patch and on the total amount of blood volume change underneath the skin patch .",
    "the total amount of blood volume change will depend on the blood perfusion in the region , which in turn will be determined by the density of blood carrying capillaries in that region .",
    "when pixel intensity is averaged over the whole face region to get @xmath39 , one ends up also including skin patches that have very limited blood perfusion , and hence contribute more noise than signal to the overall estimate of the camera - based ppg signal .",
    "thus , there is a need for an automated method to find out which regions in the face can be used to estimate better ppg signal and which regions should be rejected because they contribute more noise than signal to the overall ppg estimate .",
    "this is a challenging task because we do not have access to the ground truth ppg signal , and thus can not determine the quality of ppg estimation from different regions in the face .",
    "further , it will also be desirable to combine the ppg signal obtained from different regions of the face in a manner that the overall estimate has maximum signal to noise ratio ( snr ) .",
    "0.35    ( img ) at ( 0,0 )   from different regions of the face using a weighted average to maximize the snr of the overall estimate of the ppg signal , @xmath43 shows the ppg signal obtained from a single pixel in the forehead ( marked in red ) for comparison .",
    ", title=\"fig:\",scaledwidth=100.0% ] ; ( text ) at ( @xmath56 ) ppg signal strength varies over different regions in the face and depends on intensity of incident light @xmath38 in the region and on the blood perfusion underneath the skin . ;    [ fig : faceroi ]       0.65    table[x = time , y = raw]result / regionppg.txt ;    ( raw_text ) at ( @xmath57 ) @xmath43 ;    [ name = face , at=(@xmath58 ) , width=3 in , height=1 in , anchor = north , xmin=-1 , xmax=20 , xtick= , ymin=-.5 , ymax=.5 , ytick=-0.25,0.25 , axis x line = none , axis y line = left , y axis line style=- , ] table[x = time , y = face]result / regionppg.txt ;    ( face_text ) at ( @xmath59 ) @xmath39 ;    [ name = ra , at=(@xmath60 ) , width=3 in , height=1 in , anchor = north , xmin=-1 , xmax=20 , xtick= , ymin=-2 , ymax=2 , ytick=-1,1 , ylabel = camera intensity scale , axis x line = none , axis y line = left , y axis line style=- , ] table[x = time , y = r1]result / regionppg.txt ;    ( ra_text ) at ( @xmath61 ) @xmath51 ;    [ name = rb , at=(@xmath62 ) , width=3 in , height=1 in , anchor = north , xmin=-1 , xmax=20 , xtick= , ymin=-2 , ymax=2 , ytick=-1,1 , axis x line = none , axis y line = left , y axis line style=- , ] table[x = time , y = r2]result / regionppg.txt ;    ( rb_text ) at ( @xmath63 ) @xmath52 ;    [ name = rc , at=(@xmath64 ) , width=3 in , height=1 in , anchor = north , xmin=-1 , xmax=20 , xtick= , ymin=-2 , ymax=2 , ytick=-1,1 , axis x line = none , axis y line = left , y axis line style=- , ] table[x = time , y = r3]result / regionppg.txt ;    ( rc_text ) at ( @xmath65 ) @xmath66 ;    [ name = ground , at=(@xmath67 ) , width=3 in , height=1 in , anchor = north , xmin=-1 , xmax=20 , axis x line = bottom , axis y line = left , y axis line style=- , ymin=-0.5 , ymax=0.5 , ytick = , xlabel = time(s ) , ] table[x = time , y = ground]result / regionppg.txt ;    ( ra_text ) at ( @xmath68 ) @xmath69 ;    * challenge 2 : motion artifact * : until this point we have assumed that the person facing the camera is static ( we will assume that the camera is static throughout this paper ) .",
    "if the person moves in front of camera , e.g. tilting , smiling , shifting , talking etc , one needs to at the very least track the whole face to extract the ppg signal . as the face is not a rigid body , in a sense that different regions within the face can move separately ( e.g. cheek muscles during talking , smiling etc )",
    ", it would be ideal to track different non - rigid regions of the face independently .    even if we could track different regions within the face faithfully ,",
    "there are other challenges in faithful ppg estimation under motion .",
    "first , most light sources have a spatial illumination variations @xmath38 , and when a tracked region moves in space , it leads to change in incident light intensity in that region over time .",
    "such changes violate the assumption that incident light intensity is constant over ppg estimation window and corrupt the ppg estimate even when the tracking works perfectly .",
    "second , even very small motion ( e.g. slight rotation ) of person s face relative to camera can lead to change in incident light direction ( from light source to skin surface ) and reflected light direction ( from skin surface to camera sensor ) .",
    "such small changes in light direction can lead to large changes in skin surface reflectance which is characterized by the highly non - linear brdf of the skin surface .",
    "this large change in surface reflectance can completely overwhelm the measurement of small changes in subsurface reflectance due to changes in blood volume in sync with the cardiac cycle ( our ppg signal ) .",
    "the fact that blood volume change underneath the skin causes very small changes in the intensity of reflected light signal @xmath31 recorded by the camera can be used to our advantage . for any region ( skin patch ) inside the face to be useful in estimating the ppg waveform , the corresponding averaged pixel intensity signal from that region should not change by very large magnitude within the ppg estimation window . any large change in intensity is mostly due to changes in incident light intensity @xmath38 or surface reflectance , and would be much larger than the intensity changes we are interested in .",
    "so , it would be wise to identify such bad regions , and reject them completely till the time they are contributing large artifacts .",
    "we first propose a camera - based ppg signal acquisition model which captures the effect of incident light intensity , surface and subsurface skin reflectance , and camera noise on ppg signal estimation . based on the proposed signal acquisition model ,",
    "we develop distanceppg  estimation algorithm that comprises of two subparts : i )  _ mrc _  ( maximum ratio combining ) algorithm to combine the average pixel intensity signal extracted from different regions of the face to improve the overall signal to noise ratio ( snr ) of the final ppg estimate , and ( ii )  _ region based motion tracking _",
    "algorithm that keeps track of different regions of the face as the person moves in front of the camera .",
    "overall steps involved in distanceppg  algorithm are shown in figure  [ fig : blockdiag ] .",
    "( step1 ) at ( 0,0 ) ; at ( @xmath70 ) * step 1 : * input : green channel video of a person , landmark points around eyes , nose , mouth in face detected ;    ( step2 ) at ( 3.3,0 ) ;    at ( @xmath71 ) * step 2 : * face is divided into seven regions , each region tracked using klt , motion modeled using rigid affine fit ;    ( step3 ) at ( 6.51,0 ) ;    at ( @xmath72 ) * step 3 : * each tracked region is divided into @xmath73x@xmath73 pixel block , avg .",
    "pixel intensity @xmath74 computed from each roi ;    ( step4 ) at ( 9.75,0 ) ;    at ( @xmath75 ) * step 4 : * goodness metric @xmath76 computed for each roi , overall camera ppg estimated using weighted average ;    ( step1.east )  ( step2.west ) ; ( step2.east )  ( step3.west ) ; ( step3.east )  ( step4.west ) ; ( @xmath77 )  ( @xmath78 )  ( @xmath79 )  ( @xmath80 )  ( @xmath77 ) ;    ( @xmath81 )  ( @xmath82 )  ( @xmath83 )  ( @xmath84 )  ( @xmath81 ) ;    at ( @xmath85 ) * region based motion tracking * ;    at ( @xmath86 ) * mrc  algorithm * ;      given the intensity signal @xmath31 of a person facing a camera , we assign the set of pixels imaging the face into many small regions of interest ( rois ) denoted by the set @xmath87 .",
    "these rois are small enough that the blood perfusion within them can be assumed to be constant .",
    "let @xmath74 be the spatial average of the intensity of the pixel within the roi @xmath88 at time @xmath89 , @xmath90 is used to index the elements of the set @xmath87 .",
    "also , the spatial illumination variation @xmath38 inside an roi @xmath88 can be assumed to be constant , and will be denoted as @xmath91 .",
    "then , @xmath74 can be modeled as    @xmath92    where @xmath91 is the incident light intensity in roi @xmath88 , @xmath93 is the strength of blood perfusion , @xmath94 is the surface reflectance from the skin in region @xmath88 , and @xmath95 is the camera quantization noise .",
    "when incident illumination @xmath91 falls on skin roi @xmath88 , a large fraction of it ( @xmath94 ) is reflected back by the skin surface and does not contain any pulsatile component related to blood volume change .",
    "some part of the incident light penetrates beneath the skin surface , and gets modulated by the pulsatile blood volume change waveform @xmath30 , due to light absorption , before reflecting back ( back - scattering ) . here , @xmath93 represent the strength of modulation of light backscattered from the subsurface due to the pulsatile blood volume change .",
    "the parameter @xmath93 will primarily depends on the average blood perfusion in the selected roi , and thus varies over different regions of the face and is also different for different individuals .",
    "the parameter @xmath93 will also depend on the wavelength of incident light since the absorption spectra of hb and hbo@xmath25 , two major chromophores present in blood , depends on wavelength of light . in this work ,",
    "we only consider camera s green channel that coincides with the peak in the absorption spectra of hb and hbo@xmath25 , this choice provides best performance in ppg estimation as was also highlighted by other researchers @xcite .",
    "so , we did not explicitly incorporate wavelength dependence of @xmath93 in the model equation .",
    "our goal is to extract @xmath30 from the measurements @xmath74 in the presence of large surface reflectance @xmath94 which constitutes a dominant portion of the signal captured by the camera sensor .",
    "quantization noise is also significant as our signal of interest @xmath30 varies by a small amount relative to the surface reflection .",
    "if the person moves in front of the camera , then all the rois in set @xmath87 need to be tracked .",
    "given the intensity signal @xmath31 of a person facing a camera , we first compute all the @xmath74 corresponding to the roi @xmath88 inside the face .",
    "each @xmath74 contain different strength of the underlying ppg signal @xmath30 , and different surface reflection component @xmath96 .",
    "then , we temporally filter all @xmath74 using a bandpass filter  @xmath46 $ ]   to reject the out of band component of skin surface reflection ( @xmath96 ) and other noise outside the band of interest to obtain @xmath97 .    based on the camera - based ppg signal acquisition model in section  [ sec :",
    "ppg_acquisition_model ] , the filtered signals from different regions of the face can be written as @xmath98 where @xmath99 represents the corresponding roi number in @xmath87 . here ,",
    "@xmath100 denote the strength of the underlying ppg signal in region @xmath88 and is determined both by the strength of modulation @xmath93 and the incident light illumination @xmath91 .",
    "further , @xmath101 denote the noise component due to the camera quantization , unfiltered surface reflection and motion artifacts .    here , @xmath102 can be considered as different channels that receive different strength of the same desired signal @xmath30 , and have different level of noise .",
    "we can combine all these different channels using a weighted average @xmath103 the weights for each channel can be determined based on the the idea of maximum ratio diversity  @xcite .",
    "the maximum ratio diversity algorithm states that the assigned weights should be proportional to the root - mean - squared ( rms ) value of the signal component , and inversely proportional to the mean - squared noise in that channel , in order to maximize the signal - to - noise ratio of the overall camera - based ppg estimate @xmath104 ; mathematically , @xmath105 as both @xmath100 and @xmath106 are unknown in our case , we need to develop an alternative method to estimate these weights @xmath76 . for ease of reference , we label @xmath76 as _ goodness metric _ for region @xmath88 from hereon .",
    "the maximum ratio diversity algorithm assumes that the signal component @xmath107 is locally coherent among all channel , i.e. there is no time delay between ppg signals extracted from different rois , and the noise component @xmath101 is uncorrelated",
    ".    generally speaking , ppg signal obtained from different regions of the skin would exhibit varying delays as the blood reaches these regions at different times .",
    "for example , there is a time lag of @xmath108 ms in ppg recorded between finger and toe @xcite .",
    "however , the time lag between the ppg signal obtained from close - by regions are small , e.g. all the regions inside the face .",
    "our own measurements show that the delay is less than @xmath109 ms between farthest point in face . as this delay falls within one sample period of normal cameras having frame rate of @xmath110  hz",
    ", we can neglect such small delays for all practical purposes , and thus the signal component @xmath107 can be considered as locally coherent .    as the amplitude of the camera - based ppg signal of interest @xmath107 is generally very small ( within 1 - 2 bits of the camera adc )",
    ", we also reject regions which have unusually large signals .",
    "large variations are mostly due to illumination change or motion artifacts .",
    "thus , we reject all regions having amplitude greater than a threshold @xmath111 . our final estimate of the ppg signal over a time window of @xmath112 sec is given by @xmath113 where @xmath114 is the indicator function , @xmath115 } \\hat{y}_i(t)$ ] , @xmath116 } \\hat{y}_i(t)$ ] is the maximum and minimum amplitude of the @xmath97 over a @xmath112 sec duration .",
    "the ppg signal @xmath30 has a fundamental frequency of oscillation equal to the pulse rate .",
    "thus , the spectral power of the ppg signal is concentrated in a small frequency band around the pr . moreover",
    ", the spectral power of the noise @xmath101 present in @xmath97 will be distributed over the passband of the filter @xmath46 $ ] . based on this spectral structure of the signal",
    ", we can estimate the goodness metric as a ratio of the power of recorded @xmath97 around the pulse rate ( pr ) to the power of the noise in the passband of the filter .",
    "let @xmath117 be the _ power spectral density _",
    "( psd ) of @xmath118 over time duration @xmath119 $ ] .",
    "then goodness metric @xmath76 can be defined as @xmath120 where @xmath121 $ ] denote a small region around the pulse rate ( pr ) of the person , and @xmath122 $ ] is the passband of the bandpass filter ( @xmath46 $ ] ) .",
    "the definition of @xmath76 depends on the pulse rate which is still unknown .",
    "a two - step process can be followed to get a coarse estimate of pulse rate .",
    "first , we assume that all the @xmath76 are equal to @xmath123 , and thus we compute a temporary coarse estimate of the ppg signal using equation  .",
    "second , we compute the frequency corresponding to the peak in the spectrum of this coarse estimate of ppg signal to get a coarse estimate of the pulse rate to be used in goodness metric definition .",
    "figure  [ fig : mrc_algorithm](a ) shows the psd of acquired ppg signal and highlights how the goodness metric is defined based on the area under the psd .",
    "figure  [ fig : mrc_algorithm](b ) shows a face with the goodness metric overlay .",
    "the goodness metric is based only on the recorded video of a person s face , and thus adapts to changes in blood perfusion for different people or changes in lighting conditions .",
    "regions shown as more red have higher goodness value , those shown in blue have lower goodness metric .",
    "figure  [ fig : mrc_algorithm](c ) shows the ppg signal extracted from four different regions marked on the face .",
    "when we compare these ppg signals with the pulse oximeter  based ground truth , it is evident that the goodness metric correctly predicts the strength of the ppg signal extracted from these regions relative to the noise power .",
    "thus , forehead ( roi 1 , goodness metric = @xmath124 ) and cheek ( roi 2 , goodness metric = @xmath125 ) regions give higher strength ppg signal estimates , whereas the region around mouth ( roi 3 , goodness = @xmath126 ) and eyes ( roi 4 , goodness = @xmath127 ) do not yield good signal .",
    "since the roi @xmath128 around eyes gives spiky signal due to eye movements , the signal amplitude in this region crossed the amplitude threshold @xmath111 .",
    "thus , the weight given to roi @xmath128 is @xmath127 , or equivalently that region is rejected by the algorithm .      in camera - based acquisition of ppg ,",
    "even a slight motion of person in front of camera can change the relative position of selected camera s roi @xmath88 and imaged skin portion . as our mrc  algorithm requires ppg extraction from all the different rois independently , we need to keep track of each selected roi on the skin surface as the person moves in front of the camera .    as a first step in tracking ,",
    "we extract landmark location from the face like location of eyes , nose , mouth and the outer boundary using a deformable face fitting algorithm described in @xcite .",
    "relative to these landmark locations , we then define seven planar regions in the face denoted by set @xmath129 for tracking  three on forehead , left and right cheek , and two on the chin .",
    "particularly , we do not include regions around the mouth and eyes , as they exhibit non - rigid motion and are difficult to track and thus causes large motion artifacts .    as a next step , to track these planar regions on the face across the video frames , we identify @xmath130 feature points inside each planar region .",
    "these feature points are selected so that they could be tracked well , and are known as _ good features to track _",
    "@xcite in computer vision literature .",
    "we then use the kanade lucas tomasi ( klt ) feature tracker @xcite to track these features across the video .",
    "afterwards , we compute a rigid affine fit for each planar region using the tracked feature points inside corresponding planar region to model its motion between consecutive frames    we use more feature points than is minimally required for a rigid affine fit ( @xmath131 feature points ) as feature tracking is generally error prone due to feature points changing appearance or disappearing from camera view due to occlusion .",
    "we use the method proposed in @xcite to automatically detect tracking failures based on the forward - backward error and do not consider erroneous points for affine model estimation . from the remaining well - tracked feature points , we use the random sample consensus ( ransac )",
    "@xcite algorithm to compute a robust estimate of affine fit by considering only the inlier points for the model , and rejecting the outliers .",
    "we then divide these seven planar regions @xmath129 on the face into many small ppg region of interest required by the mrc  algorithm .",
    "each ppg roi @xmath88 is tracked across the video frames using the estimated affine motion model of the encompassing planar region .",
    "we then combine the ppg signal from all the tracked roi using the mrc  algorithm .",
    "after every @xmath112 seconds , we reset the klt tracker and reinitialize the deformable face model .",
    "all the steps for region based motion tracking  algorithm discussed above are summarized in algorithm  [ motion ] .",
    "@xmath132 lp @xmath133 deformableface(@xmath31 ) @xmath134 defineplanerregion(lp ) @xmath135 defineppgregion(@xmath136 ) @xmath137 goodfeatures(@xmath138 ) @xmath139 trackerklt(@xmath31,@xmath140,@xmath141 ) @xmath142 affineransac(@xmath143 ) @xmath144",
    "@xmath145 @xmath146    @xmath147 * return * @xmath148      the rois inside the face region , @xmath88 , are chosen to be of the size of @xmath50 pixel block .",
    "we have experimented with other sizes such as @xmath149 , @xmath150  px , but have found @xmath50 to be the best choice in terms of overall performance for our data - set .",
    "note that the best choice of roi size may depend on camera resolution and distance of subject from the camera ( @xmath40  m for our data collection ) .",
    "we reinitialize the deformable face model and restart the klt feature tracker every @xmath151  sec .",
    "klt feature tracker is restarted because the local feature based motion tracker accumulates error over time .",
    "we have found that restarting klt feature tracker every @xmath151  sec is sufficient for faithful facial region tracking during motions like reading , watching video or talking . selecting a larger time interval @xmath112 helps in improving accuracy of goodness",
    "metric estimate , and smaller time interval helps in improving tracking performance .",
    "we balance this tradeoff by selecting @xmath152  sec when the person is relatively static , and choosing @xmath153  sec when there is motion . at the end of every @xmath151  sec ( referred as an epoch from now on ) , we combine the ppg signal from all the tracked roi using the mrc  algorithm .    within each epoch , we drop those klt features that show more than @xmath154  px of forward - backward error .",
    "further , we also reject those rigid regions @xmath129 where there are fewer than @xmath109 klt points left to track , as these regions might be undergoing excessive motion or large illumination changes , and including them will deteriorate the overall ppg estimate . for the ransac algorithm , we set the tolerance @xmath155  pixels , inlier fraction @xmath156 , and maximum number of iteration @xmath157 .",
    "if a rigid affine model can not be found by ransac within this tolerance limit , we reject that region .",
    "next , within each epoch , we filter the ppg signal obtained from well tracked roi ( @xmath88 ) using a zero - phase non - causal forward - backward bandpass filter , @xmath46 $ ] .",
    "we then reject those roi where the signal amplitude crosses the amplitude threshold @xmath158 .",
    "camera - based ppg signals are really weak , and hence they hardly cross @xmath159 value in the units of @xmath160-bit camera pixel intensity . any large change in intensity is mostly due to change in illumination or large motion artifact as discussed earlier .",
    "we then compute a coarse estimate of the pulse rate @xmath161 , by combining the ppg signals from all the remaining rois .",
    "this coarse pulse rate estimate can be erroneous at times , and so we keep track of the history of pulse rates over last @xmath128 epochs .",
    "if the current estimate of @xmath161 is off by more than @xmath162bpm , then we replace the current estimate with the median of the last four estimate .",
    "we then compute the goodness metric @xmath76 for all the remaining roi ( all regions rejected prior to this stage are given a weight @xmath163 for the current epoch ) and combine the ppg signals using the weighted average ( equation  ) .",
    "we recompute the goodness metric @xmath76 for each roi after every epoch .",
    "for comparison , we implemented known past methods for camera - based ppg estimation .",
    "the general steps taken are : ( i ) select the face regions using voila jones face detector as described in @xcite , ( ii ) extract ppg signal by first computing the spatial average of the pixel intensity within the selected face region , and then filtering ( detrending ) the estimate @xcite , ( iii ) to compensate for motion , compute the 2d shift in face between consecutive frames as described in @xcite and extracted the ppg from the tracked face region . in this sense",
    ", we have used a combination of known methods for single channel ( green ) camera - based ppg estimation algorithm for comparison with our distanceppg  algorithm .",
    "we label this combination as _ face averaging method _  from now onwards .",
    "another set of work in camera - based ppg estimation involves decomposing different camera channels ( e.g. red , green , blue ) into independent source signals using independent component analysis ( ica ) , and extracting the desired ppg signal from one of these independent sources @xcite .",
    "our proposed distanceppg  algorithm provides improvement in camera - based ppg estimate by spatially combining ppg signals from different regions of the face , and by improving upon the tracking algorithm , and uses only a single channel ( green ) of the camera . on the other hand ,",
    "ica based methods utilizes multiple camera channels ( e.g. red , green , and blue @xcite or cyan , orange , and green @xcite ) to improve the performance of camera - based ppg estimate by separating independent sources .",
    "thus , these two methods are characteristically different , and we will summarize the performance improvement provided by ica - based method and by distanceppg .      for all single channel video recording in this study , we used flea 3^^ usb 3.0 fl - u3 - 13e4m - c monochrome camera operated at @xmath22 frames per second , with a resolution of @xmath164 , and @xmath160  bits per pixel .",
    "we added a @xmath165  nm full - width half - max ( fwhm ) green filter ( fb550 - 40 from thor labs",
    "^^ ) in front of the monochrome camera .",
    "we selected green filter since the absorption spectra of hb and hbo2 peaks in this wavelength region .",
    "moreover , all commercial color camera have highest number of pixel having green filter ( bayer pattern ) . for color video recording",
    ", we used flea 3^^ usb 3.0 fl - u3 - 13e4c - c color camera operated at @xmath22 frames per second with rgb bayer pattern having a total resolution of @xmath164 , and @xmath160  bits per pixel .",
    "we used texas instruments afe4490spo2evm pulse oximeter  module to record contact - based ppg signal for comparison .",
    "it operates at a sampling rate of @xmath166 hz .",
    "the distance between camera and subject was @xmath40 m .",
    "both the camera system and the pulse - oximeter were started simultaneously , and the data is recorded in a pc workstation . all processing is done using a custom built software written in matlab . all experiments ( except the lighting experiment ) is conducted under ambient ( fluorescent ) lighting at 500 lux brightness .",
    "the main goal of the experiments reported here is to characterize and quantify the performance of the two components of our proposed distanceppg  algorithm  mrc  algorithm and region based motion tracking  algorithm , and compare them with face averaging method .",
    "we evaluate the performance by varying three main parameters of interest : ( i ) skin tone of people , ( ii ) motion , ( iii ) ambient light intensity , and quantify their effect on ppg estimation accuracy .",
    "we use the same raw video feed to evaluate our distanceppg  algorithm in comparison to face averaging method , and so performance improvements reported here are due to the proposed algorithm , and is independent of any specific hardware or camera choices we made for the evaluation .",
    "all the experiments done in this research were approved by the rice university institute review board ( protocol number : @xmath167e , approval date : @xmath168 ) .",
    "for the first experiment , we collected single channel ( green ) video data from @xmath10 subjects ( @xmath169 male , @xmath14 female ) with different skin tones ( from light , pale white to dark brown / black ) . for this experiment ,",
    "subjects were asked to face the camera and be static for a duration of @xmath165 seconds ( involuntary motions were not restricted ) .    for the second set of experiments",
    ", we collected ( single green channel ) video under three natural motion scenarios  ( i ) reading on computer , ( ii ) watching video , ( iii ) talking .",
    "the motion scenarios are representative of a general class of motion exhibit by users of tablet , phone , or laptops while facing the screen .",
    "reading scenario involves lateral movement of the head while reading text on screen .",
    "watching video also involves intermittent facial expression such as smiling , getting amazed , sad etc , apart from lateral movement of the head .",
    "talking scenario involves a lot of non - rigid movement around the jaw and the cheeks , and thus are ideal to evaluate system perform in harsh scenarios . for each of the motion scenarios , we collected @xmath108 seconds video recordings for @xmath14 subjects having different skin tones , along with their stationary video recording for baseline comparison .",
    "for the third set of experiments , we varied the illumination level from @xmath170 lux upto @xmath171 lux ( ambient light is around @xmath172 lux ) and recorded the single channel ( green ) video for a duration of @xmath165 seconds under each lighting conditions for two subjects having pale - white and brown skin tones .    for comparison with ica - based method , we collected two sets of data : ( i ) static dataset comprising of color video ( red , green , blue ) of @xmath128 subjects of varying skin tones ( only non - caucasian ) for a duration of @xmath173 seconds at @xmath166  lux illumination , ( ii ) talking dataset comprising of color video of @xmath128 subjects of varying skin tone ( non - caucasian ) , with @xmath131 subjects having @xmath166  lux illumination , and @xmath174 subject having @xmath175  lux illumination .",
    "this set is deliberately chosen to be extremely harsh ( lower light , non - caucasian skin tones , and large motion during talking ) to highlight scenario where current known algorithms ( including distanceppg ) fails , and provide dataset where future algorithms can improve .",
    "the dataset will be released in public and other researchers can access it at http://www.ece.rice.edu/\\texttildelow mk28/distanceppg / dataset/[http://www.ece.rice.edu/\\texttildelow mk28/distanceppg / dataset/ ] .      as a waveform estimation algorithm ,",
    "distanceppg   provides an estimate of the ground truth ppg waveform @xmath30 using video of a person s face .",
    "thus , we use signal - to - noise ratio ( snr ) of the estimate @xmath104 to quantify performance for comparison .",
    "the ground truth signal , @xmath30 , is recorded using a pulse oximeter  attached to subject s ear .",
    "we chose earlobe instead of finger probe because of its proximity to the face region .",
    "further , we also evaluate the performance based on the accuracy of physiological parameter like pulse rate and pulse rate variability ( i.e. beat - to - beat changes in pulse interval ) that can be extracted from ppg waveform .",
    "we report the mean error rates in estimating pr and prv using our distanceppg  algorithm and using face averaging method  under different experimental scenarios .",
    "to define the snr of the estimated ppg waveform , we used standard ppg signal obtained from pulse oximeter  connected to a person s earlobe as our ground truth signal .",
    "the ppg waveform obtained from a contact pulse oximeter  would also exhibit error due to motion and ambient light artifacts , and in that sense our choice of ground truth is a best effort choice .",
    "nonetheless , the noise present in ppg waveform acquired using a contact pulse oximeter  is orders of magnitude smaller than that obtained using a camera - based system , so our estimate of snr would still be reasonably accurate .",
    "the amplitude of the ppg signal recorded by pulse oximeter  is unrelated to the amplitude of the camera - based ppg signal as both systems have completely independent sensor architecture and analog gain stage .",
    "so , here we have developed a definition of snr which is independent of exact amplitude of these waveform .",
    "our snr metric captures how similar camera - based ppg signal is to the pulse oximeter  based ground - truth ppg signal .",
    "let @xmath176 denote the ppg acquired using pulse oximeter .",
    "let @xmath177 denote the ppg estimated from a camera - based system ( @xmath178 from previous section ) .",
    "@xmath179 here , @xmath180 is the noise in the ppg signal acquired from camera .",
    "apart from the quantization noise , @xmath180 also includes uncompensated motion artifacts .",
    "the noise present in the pulse oximeter  system is denoted as @xmath181 .",
    "let us assume that all signals are defined in the time interval @xmath119 $ ] and we use @xmath182 inner product and norms for all definitions .    the noise @xmath180 would be uncorrelated to @xmath181 as both acquisition systems are unrelated , and both noise is uncorrelated to the underlying zero mean ppg signal @xmath30 .",
    "if we assume that all signals follow ergodicity and consider integration over large time window ( @xmath112 is large ) , then @xmath183    and further , we can write @xmath184    since the signal quality of ppg derived from pulse oximeter  is reasonably good , we can assume that noise power @xmath185 is much smaller than signal power @xmath186 in the denominator .",
    "thus , @xmath187 can be approximated as @xmath188 further , if we assume that @xmath189 , we can estimate the noise present in @xmath177 as @xmath190 and , underlying signal @xmath191 can be approximated to @xmath192 which leads us to define signal to noise ration or snr simply as @xmath193    the snr measure defined in ( [ eq : snr ] ) will be used in the following sections to compare performance of distanceppg  algorithm and face averaging method  under various experimental scenarios .      to estimate the pulse rate ,",
    "we compute the spectrum of the ppg signal using fft algorithm over every @xmath109  sec window ( hamming window ) with @xmath14  sec overlap .",
    "the pulse rate is estimated as the frequency that correspond to the highest power in the estimated spectrum ( pr @xmath194  bpm ) .",
    "similarly , we obtain the reference pulse rate from synchronously acquired contact ppg .",
    "to estimate the prv or inter - beat interval ( ibi ) , we first interpolate the camera - based ppg signal with a cubic spline function to a sampling rate of @xmath166  hz ( same as the sampling rate for pulse oximeter ) .",
    "we then detect the peaks in the interpolated ppg signal using a custom algorithm for minima - detection . to avoid inclusion of artifacts due to noise or motion",
    ", we use the estimated pulse rate to reject peaks within @xmath195 time difference . the time interval between consecutive peaks",
    "are the prv ( or ibi ) .",
    "same algorithm is used to find the reference prv from synchronously acquired contact ppg .    due to the noisy estimate of ppg signal for darker skin tones and/or under large motion ( e.g. during talking ) ,",
    "some pulse beats ( peaks ) can not be detected in camera ppg signal .",
    "we determine the number of missing peaks by comparing peak location in camera ppg with the reference pulse oximeter  ppg .",
    "thus , we also report the percentage of missing peaks in the camera - based ppg signal as a performance metric associated with prv estimation , apart from the rmse of prv .",
    "0.48    table[x = ids , y = old_snr ] result / snr_static.txt ;    table[x = ids , y = mrc_snr ] result / snr_static.txt ;    0.48    table[x = time , y = old]result / raw_static_fair.txt ;    [ name = mrc , at=(@xmath196 ) , width=2.5 in , height=1 in , anchor = north , xmin=-1 , xmax=40 , xtick= , ymin=-1.5 , ymax=1.5 , ytick=-1,1 , ylabel = camera ppg scale , axis x line = none , axis y line = left , y axis line style=- , ] table[x = time , y = mrc]result / raw_static_fair.txt ;    [ name = signal , at=(@xmath197 ) , width=2.5 in , height=1 in , anchor = north , xmin=-1 , xmax=40 , axis x line = bottom , axis y line = left , y axis line style=- , ymin=-1.5 , ymax=1.5 , ytick=-1,1 , xlabel = time(s ) ] table[x = time , y = signal]result / raw_static_fair.txt ;    0.48    table[x = time , y = old]result / raw_static_medium.txt ; coordinates(-1,0 ) ; coordinates(-1,0 ) ;    [ name = mrc , at=(@xmath196 ) , width=2.5 in , height=1 in , anchor = north , xmin=-1 , xmax=40 , xtick= , ymin=-1.5 , ymax=1.5 , ytick=-1,1 , ylabel = camera ppg scale , axis x line = none , axis y line = left , y axis line style=- , ] table[x = time , y = mrc]result / raw_static_medium.txt ;    [ name = signal , at=(@xmath197 ) , width=2.5 in , height=1 in , anchor = north , xmin=-1 , xmax=40 , axis x line = bottom , axis y line = left , y axis line style=- , ymin=-1.5 , ymax=1.5 , ytick=-1,1 , xlabel = time(s ) , ] table[x = time , y = signal]result / raw_static_medium.txt ;    0.48    table[x = time , y = old]result / raw_static_brown.txt ;    [ name = mrc , at=(@xmath196 ) , width=2.5 in , height=1 in , anchor = north , xmin=-1 , xmax=40 , xtick= , ymin=-1.5 , ymax=1.5 , ytick=-1,1 , axis x line = none , axis y line = left , y axis line style=- , ] table[x = time , y = mrc]result / raw_static_brown.txt ;    [ name = signal , at=(@xmath197 ) , width=2.5 in , height=1 in , anchor = north , xmin=-1 , xmax=40 , axis x line = bottom , axis y line = left , y axis line style=- , ymin=-1.5 , ymax=1.5 , ytick=-1,1 , xlabel = time(s ) ] table[x = time , y = signal]result / raw_static_brown.txt ;    figure  [ fig : static_snr_waveform ] compares the snr and the waveform of ppg obtained using distanceppg  and face averaging method  for people having different skin tone categories  ( i ) light / fair ( @xmath128 people ) , ( ii ) medium / olive ( @xmath128 people ) , and ( iii ) brown / dark ( @xmath128 people ) .",
    "as seen in figure  [ fig : static_snr ] , on an average distanceppg  provides @xmath0  db of snr improvement for all skin tones compared to face averaging method . also , the gain in snr is more for darker skin tones ( around @xmath1  db ) .",
    "further , figure  [ fig : static_waveform_fair]-[fig : static_waveform_brown ] shows an example @xmath165  s plots of camera - based ppg estimate using both distanceppg  and face averaging method  for the three skin tone categories .",
    "when compared with ground truth signal , it is evident that camera - based ppg signal estimated using distanceppg  is more similar to the ground truth pulse oximeter  signal .",
    "0.48    table[x = mean , y = diff]result / bland_static_data_max_fair.txt ; ;    table[x = mean , y = diff]result / bland_static_data_max_medium.txt ; ;    table[x = mean , y = diff]result / bland_static_data_max_brown.txt ; ;    coordinates ( 40,-0.02 ) ( 110,-0.02 ) ; coordinates ( 40,-0.75 ) ( 110,-0.75 ) ;    at ( axis cs : 65,-1.5 ) mean @xmath198sd ; coordinates ( 40,0.72 ) ( 110,0.72 ) ;    at ( axis cs : 65,+1.5 ) mean @xmath199sd ;    0.48    table[x = mean , y = diff]result / bland_static_data_old_fair.txt ; table[x = mean , y = diff]result / bland_static_data_old_medium.txt ; table[x = mean , y = diff]result / bland_static_data_old_brown.txt ; coordinates ( 40,-0.40 ) ( 110,-0.40 ) ; coordinates ( 40,-4.5 ) ( 110,-4.5 ) ;    at ( axis cs : 65,-5.5 ) mean @xmath198sd ; coordinates ( 40,3.7 ) ( 110,3.7 ) ;    at ( axis cs : 65,+5.5 ) mean @xmath199sd ;    the improvement in snr for various skin tones reduces the error in pr estimation .",
    "figure  [ fig : stationary_bland ] shows the agreement between camera derived pr and ground truth pulse oximeter  derived pr from @xmath10 subjects of different skin tones using bland - altman plot . for ppg",
    "estimated using face averaging method , the mean bias ( average difference between ground truth pulse oximeter  derived pr and camera - based ppg derived pr ) @xmath4 = @xmath11 bpm with @xmath6 limit of agreement ( mean bias @xmath7 standard deviation of the difference ) being @xmath12 to @xmath13 bpm .",
    "using the distanceppg  reduces the error in pr estimate to @xmath200 bpm with @xmath6 limit of agreement being @xmath8 to @xmath9 bpm . for computing these statistics ,",
    "we have not included occasional extreme outliers ( error in pr @xmath201 bpm ) found in face averaging method  ( @xmath128 outliers in @xmath202 sample points ) as these outliers significantly skew the performance of face averaging method  and show it in bad light .",
    "distanceppg  algorithm did not exhibit any extreme outliers in the dataset for all skin tones and so we have reported statistics for all @xmath202 sample points .",
    "0.48    table[x = ids , y = old ] result / ibi_rmse_static.txt ; table[x = ids , y = mrv ] result / ibi_rmse_static.txt ;    0.48    table[x = ids , y = mrv ] result / missing_static.txt ; table[x = ids , y = old ] result / missing_static.txt ;    ppg signal estimated using distanceppg  shows significant improvement in the root mean squared error ( rmse ) of prv estimate .",
    "figure  [ fig : stationary_ibi ] shows the rmse of prv estimation and the corresponding percentage of missing peaks in camera - based ppg for the three skin tone categories . using distanceppg , the rmse in prv for light and medium skin tone is less than @xmath21  ms . as @xmath22  fps camera is used for recording the video , one can not expect rmse to be much lower than half the sampling interval ( @xmath203  ms ) .      0.48    table[x = ids , y = old_snr ] result / snr_motion.txt ;    table[x = ids , y = mrc_snr ] result / snr_motion.txt ;    0.48    table[x = time , y = old]result / raw_motion_read.txt ;    [ name = mrc , at=(@xmath196 ) , width=2.5 in , height=1 in , anchor = north , xmin=-1 , xmax=40 , ylabel = camera ppg scale , xtick= , ymin=-1.5 , ymax=1.5 , ytick=-1,1 , axis x line = none , axis y line = left , y axis line style=- , ] table[x = time , y = mrc]result / raw_motion_read.txt ;    [ name = signal , at=(@xmath197 ) , width=2.5 in , height=1 in , anchor = north , xmin=-1 , xmax=40 , axis x line = bottom , axis y line = left , y axis line style=- , xtick= , ymin=-1.5 , ymax=1.5 , ytick=-1,1 , ] table[x = time , y = signal]result / raw_motion_read.txt ;    [ name = motion , at=(@xmath204 ) , width=2.5 in , height=1.0 in , anchor = north , xmin=-1 , xmax=40 , ylabel = motion ( px ) , axis x line = bottom , axis y line = left , y axis line style=- , xlabel = time ( sec ) , ymin=0 , ymax=10 , ytick=0,5 , ] + [ color = black , const plot mark mid , mark size=0.5pt ] table[x = time , y = motion]result / motion_read.txt ;    0.48    table[x = time , y = old]result / raw_motion_watch.txt ; coordinates(-1,0 ) ; coordinates(-1,0 ) ; + [ color = black , const plot mark mid , mark size=0.5pt ] coordinates(-1,0 ) ;    [ name = mrc , at=(@xmath196 ) , width=2.5 in , height=1 in , anchor = north , xmin=-1 , xmax=40 , xtick= , ymin=-1.5 , ylabel = camera ppg scale , ymax=1.5 , ytick=-1,1 , axis x line = none , axis y line = left , y axis line style=- , ] table[x = time , y = mrc]result / raw_motion_watch.txt ;    [ name = signal , at=(@xmath197 ) , width=2.5 in , height=1 in , anchor = north , xmin=-1 , xmax=40 , axis x line = bottom , axis y line = left , y axis line style=- , xtick= , ymin=-1.5 , ymax=1.5 , ytick=-1,1 , ] table[x = time , y = signal]result / raw_motion_watch.txt ;    [ name = motion , at=(@xmath204 ) , width=2.5 in , height=1.0 in , anchor = north , xmin=-1 , xmax=40 , ylabel = motion ( px ) , axis x line = bottom , axis y line = left , y axis line style=- , xlabel = time ( sec ) , ymin=0 , ymax=12 , ytick=0,5 , ] + [ color = black , const plot mark mid , mark size=0.5pt ] table[x = time , y = motion]result / motion_watch.txt ;    0.48    table[x = time , y = old]result / raw_motion_talk.txt ;    [ name = mrc , at=(@xmath196 ) , width=2.5 in , height=1 in , anchor = north , xmin=-1 , xmax=40 , xtick= , ymin=-1.5 , ymax=1.5 , ytick=-1,1 , axis x line = none , axis y line = left , y axis line style=- , ] table[x = time , y = mrc]result / raw_motion_talk.txt ;    [ name = signal , at=(@xmath197 ) , width=2.5 in , height=1 in , anchor = north , xmin=-1 , xmax=40 , axis x line = bottom , axis y line = left , y axis line style=- , xtick= , ymin=-1.5 , ymax=1.5 , ytick=-1,1 , ] table[x = time , y = signal]result / raw_motion_talk.txt ;    [ name = motion , at=(@xmath204 ) , width=2.5 in , height=1.0 in , anchor = north , xmin=-1 , xmax=40 , axis x line = bottom , axis y line = left , y axis line style=- , xlabel = time ( sec ) , ymin=0 , ymax=8 , ytick=0,5 , ] + [ color = black , const plot mark mid , mark size=0.5pt ] table[x = time , y = motion]result / motion_talk.txt ;    [ fig : motion_improvement ]    figure  [ fig : motion_snr ] shows the snr improvements for four scenarios  ( i ) stationary , ( ii ) reading , ( iii ) watching video , and ( iv ) talking for @xmath14 subjects of different skin tones .",
    "distanceppg  provides on an average @xmath2db of snr improvement under various motion scenario compared to face averaging method .",
    "further , figure  [ fig : motion_waveform_reading]-[fig : motion_waveform_talking ] shows typical @xmath165  s plots of camera - based ppg estimate using both distanceppg  and face averaging method  for the three motion scenarios . when compared with ground truth signal ,",
    "it is evident that distanceppg  improves the estimate of ppg during small - medium motion ( @xmath205  px per frame ) . under large motion",
    "( @xmath206  px per frame ) , distanceppg  also suffers due to motion artifacts .    0.48    table[x = mean , y = diff]result / bland_motion_data_max_read.txt",
    "; ;    table[x = mean , y = diff]result / bland_motion_data_max_watch.txt ; ;    table[x = mean , y = diff]result / bland_motion_data_max_talk.txt ; ;    coordinates ( 40,0.48 ) ( 110,0.48 ) ; coordinates ( 40,-5.73 ) ( 110,-5.73 ) ;    at ( axis cs : 95,-20 ) mean @xmath198sd ; coordinates ( 40,6.70 ) ( 110,6.70 ) ;    at ( axis cs : 95,20 ) mean @xmath199sd ;    0.48    table[x = mean , y = diff]result / bland_motion_data_old_read.txt ; table[x = mean , y = diff]result / bland_motion_data_old_watch.txt ; table[x = mean , y = diff]result / bland_motion_data_old_talk.txt ; coordinates ( 40,7.17 ) ( 110,7.17 ) ; coordinates ( 40,-18.70 ) ( 110,-18.70 ) ;    at ( axis cs : 95,-25.5 ) mean @xmath198sd ; coordinates ( 40,33.04 ) ( 110,33.04 ) ;    at ( axis cs : 95,+40 ) mean @xmath199sd ;    the improvement in snr under various motion scenarios reduces the error in pr estimation .",
    "figure  [ fig : motion_bland ] shows the agreement between camera derived pr and ground truth pulse oximeter  derived pr from @xmath14 subjects under the three motion scenario ( reading , watching , talking ) using bland - altman plot . for ppg",
    "estimated using face averaging method , the mean bias @xmath18 bpm with @xmath6 limit of agreement between @xmath19 to @xmath20 bpm . using",
    "the mrc  reduces the error in pr estimate to @xmath207 bpm with @xmath6 limit of agreement between @xmath16 to @xmath17 bpm . note ,",
    "distanceppg  do not perform well for pr estimation under talking scenario possibly because of large non - rigid motion . for non - talking motion scenario ( reading+watching ) ,",
    "the error in pr estimate is @xmath208  bpm with @xmath6 limit of agreement being @xmath209 to @xmath210  bpm which is much better .",
    "thus , one can possibly use computer vision based activity recognition to not estimate pr during large non - rigid motion .",
    "0.48    table[x = ids , y = old ] result / ibi_rmse_motion.txt ; table[x = ids , y = mrv ] result / ibi_rmse_motion.txt ;    0.48    table[x = ids , y = mrv ] result / missing_motion.txt ; table[x = ids , y = old ] result / missing_motion.txt ;    figure  [ fig : motion_ibi ] shows the rmse in prv estimation and the corresponding percentage of missing peaks in camera - based ppg for the three motion scenario along with stationary base case .",
    "distanceppg  provides reduction in rmse of prv ( by around 1.5x ) and the percentage of missing peaks ( by atleast by 2x ) when compared to face averaging method  under motion scenarios .",
    "still , there is scope for further improvement as the rmse in prv estimate is around @xmath211  ms , and one can achieve around @xmath203  ms rmse with the @xmath22  fps camera .",
    "these errors are due to large non - rigid motion of the face during smiling , talking etc .",
    "figure  [ fig : snr_light ] shows the snr of camera - based ppg estimate under different lighting condition ( @xmath212  lux ) using both distanceppg  ( marked as squares ) and face averaging method  ( marked as circles ) for two subjects having pale white ( dashed line ) and brown skin ( solid line ) tones . on an average distanceppg  provides an snr gain of @xmath213  db for pale white person , and an snr gain of @xmath3  db for a brown skin tone person . though we tried to keep all other experimental parameter ( particularly motion ) invariant ( static in this case ) while varying the light intensity , one should not read much from the ups and downs in the plot , as they mostly are due to uncontrolled experimental variations .",
    "nonetheless , the general trend is that snr of camera - based ppg estimate increases as we increase the light intensity .",
    "this trend is more evident for distanceppg  compared to face averaging methodwhich shows that distanceppg  is more immune to such experimental variations .",
    "table [ x = light , y = snr_mrc_u1]result / snr_light.txt ; table [ x = light , y = snr_old_u1]result / snr_light.txt ; table [ x = light , y = snr_mrc_u2]result / snr_light.txt ; table [ x = light , y = snr_old_u2]result / snr_light.txt ;      for static scenario ( @xmath128 subjects having non - caucasian skin tones ) , the mean snr of camera - based ppg using distanceppg  is @xmath214  db , and using ica - based method is @xmath215  db . the mean error in pr estimation is @xmath216  bpm and rmse of prv estimation is @xmath217  ms for distanceppg , and corresponding errors for ica - based method is @xmath218  bpm and @xmath219  ms respectively .",
    "thus , the small improvement in snr ( @xmath174  db ) by using distanceppg  results in better performance in prv estimation accuracy .    for talking scenario ( @xmath131 subjects under @xmath166  lux illumination , @xmath174 subject under @xmath175  lux ) , both distanceppg  and ica - based method performs poorly , possibly because of large motion artifact which renders small ppg signal estimation difficult .",
    "the mean snr of camera - based ppg are @xmath220  db and @xmath221  db for distanceppg  and ica - based method respectively . due to such low snr ,",
    "the mean error in pulse rate suffers for both methods , and is @xmath222  bpm and @xmath223  bpm for distanceppg  and ica - based method respectively .",
    "we used goodness metric as a substitute for the signal quality or snr of the ppg signal obtained from different regions of the face . to understand how good our goodness metric substitute is",
    ", we compute scatter plot between goodness metric @xmath76 in db and snr of the ppg signal @xmath97 obtained from different roi @xmath88 inside the face .",
    "figure  [ fig : goodnesssnr ] shows this scatter plot for two subjects having white / fair and brown / dark skin tones .",
    "0.45    table[x = snr , y = goodness]result / scattersnrgoodnessuid9.txt ; table[row sep = crcr ] -80 -3 + 15 -3 + ;       0.45    table[x = snr , y = goodness]result / scattersnrgoodnessuid12.txt ; table[row sep = crcr ] -80 -3 + 15 -3 + ;    the scatter plot shows that goodness metric is a good substitute for snr in regions having goodness metric greater than @xmath224  db . for regions having lower",
    "goodness metric , goodness metric overestimates the snr .",
    "thus , we also reject regions having very low goodness metric score ( @xmath225  db or @xmath226 ) in the ppg estimation equation  . completely rejecting regions having very small goodness metric value",
    "@xmath226 slightly improve the overall snr of camera - based ppg signal ( by @xmath227  db ) .",
    "our definition of goodness metric exploited a known prior structure in photoplethysmogram signals , i.e. ppg signals are periodic with dominant frequency equal to the pulse rate , and developed a signal quality index based on the spectrum of the ppg signal extracted from a region .",
    "this signal quality index helped us propose weighted averaging algorithm to improve the snr of the overall ppg estimate .",
    "thus , we broke down the problem of robust camera - based ppg waveform estimation into two stages : ( i ) estimation of dominant frequency ( pr ) , which is a relatively easy problem , and ( ii ) robust estimation of ppg waveform by defining a new signal quality index based on the pulse rate .",
    "it is important to note that merely filtering the ppg signal in a narrow frequency band around the pulse rate ( @xmath121 $ ]  hz ) , a method generally used for weak periodic signal detection , would not give a good estimate of the ppg waveform , as the spectral band of interest for ppg signal is much wider ( @xmath46 $ ] ) . in other words , we care about the exact shape of the ppg waveform ( e.g. inter - beat - interval information , systolic and diastolic peaks etc ) , and thus we should design an estimation algorithm which preserves the shape .",
    "one may find similar opportunities and concerns in many other periodic biological signal estimation problems e.g. electrocardiogram ( ekg ) , event related potentials ( erp ) , etc .",
    "goodness metric based signal quality index developed in this paper can be expanded for these scenarios as well , particularly when one records these biological signals using sensors distributed in space and wants to develop a technique to weigh the sensor based on their signal quality .",
    "the goodness metric profile over a face depends on two factors - ( i ) spatial illumination profile over the face @xmath38 . and",
    "( ii ) strength of modulation ( @xmath93 ) of reflected light which depends on the blood perfusion profile . as the illumination profile can change over time",
    ", distanceppg  re - estimates the goodness metric every @xmath112 seconds .",
    "figure [ fig : mrc_algorithm ] of goodness metric overlay clearly shows that forehead region is best for extracting ppg signal from the face .",
    "our finding is in agreement with the findings of other researchers that forehead represent a suitable site for camera - based ppg estimation .",
    "this is because the forehead region have much better blood perfusion compared to other regions @xcite .",
    "further , it might be feasible to develop a new metric for the blood perfusion profile over the face if one can separately estimate the spatial illumination profile and compensate for it .",
    "blood flow in peripheral tissue is generally estimated using either laser doppler flowmetry or using laser speckle contrast imaging ( lsci ) techniques .",
    "camera - based blood flow monitoring , if developed , will be highly useful .",
    "the rmse of prv that we could achieve for fairer skin tones under stationary scenario is around @xmath228 ms .",
    "it is difficult to achieve something significantly below this error value using a @xmath22  fps camera - based ppg signal .",
    "this is because the time difference between two camera frames is @xmath229  ms , and thus there is an ambiguity of @xmath230  ms in peak detection .",
    "no amount of interpolation ( we interpolated camera ppg to @xmath166  hz using spline interpolation ) can completely recover the higher frequency details lost because of the low sampling rate .",
    "one solution to further reduce the rmse of prv is to use higher frame rate camera ( e.g. , @xmath231  fps ) . since maximum achievable exposure time of higher frame rate cameras",
    "would be smaller ( e.g. @xmath109  ms ) , this can reduce the amount of light entering the camera sensor , and thus the snr of the estimated camera ppg signal as well .",
    "this will make faithful pulse minima detection , an essential step for prv estimation , difficult .",
    "the algorithmic snr gain achieved due to distanceppg  can be useful here , as one can compensate the snr loss because of higher frame rate with the algorithmic snr gain due to distanceppg .",
    "pulse rate variability ( prv ) is one of the most commonly used measure in psychophysiology research , and is employed broadly as a determinant of the status of the autonomic nervous system ( ans ) @xcite .",
    "camera - based prv estimation can enable researchers to conduct large scale psychophysiological studies of statistical significance outside their lab settings .",
    "one needs to evaluate and understand the impact of error in camera - based prv on various metric of interest in psychophysiology such as high frequency ( hf ) power , low frequency ( lf ) power , lf / hf power ratio of prv , standard deviation of all normal heart period ( sdnn ) etc .",
    "this will be one of the future direction of our research .",
    "in this paper , we dived deeper into understanding the challenges involved in estimating photoplethysmogram waveform using a camera - based system .",
    "we developed a new method , distanceppg , that addresses these challenges .",
    "we evaluated our algorithm on people having diverse skin tones ( pale / white to brown / dark ) , under various lighting conditions ( @xmath170  lux to @xmath171  lux ) and natural motion scenarios , and showed significant improvement in the accuracy of vital sign ( pulse rate , pulse rate variability ) estimation .",
    "our major contribution is to develop a formal method to take into consideration differences in blood perfusion and incident light intensity in different regions of the face to improve the accuracy of vital sign estimation under difficult scenario ( e.g. dark skin tones and/or low lighting condition ) .",
    "further , we proposed a new motion - tracking algorithm which tracks different regions of the face separately , to improve performance of vital sign estimation under natural motion scenarios like reading content on computer screen , watching video , and talking over skype .",
    "we also highlighted limitations of distanceppg  algorithm , e.g. during talking scenario , where vital sign estimation accuracy suffers .",
    "the major challenge in such scenario is significant variations in skin surface reflectance component during large motion which falls in the frequency band of interest of ppg signal ( @xmath46 $ ] ) .",
    "the small changes in skin subsurface reflectance , which encodes the ppg signal , is not recoverable in presence of large in - band surface reflectance changes .",
    "thus , the general approach we adopted in distanceppg  is to reject regions undergoing large surface reflectance changes .",
    "consequently , during large motion we end up rejecting a majority of face region and thus our estimate of ppg signal was inaccurate .",
    "two popular apps for measuring non - contact pulse rate using the color change ( or ppg ) signal from a person s face are philips vital sign camera @xcite and cardiio @xcite .",
    "both these apps require users to be at rest facing the camera in a well lit environment to be effective @xcite .",
    "the distanceppg  algorithm discussed in this paper address these challenges and thus would extend the use case of mobile phone and computer apps for vital sign monitoring .",
    "we are in the process of developing a realtime pc - based application to robustly estimate ppg signal using a webcam .",
    "our future work includes porting our code to popular mobile platforms ( android / ios ) , and further improving the performance of distanceppg  under motion scenarios .",
    "this work was partially supported by nsf cns 1126478 , nsf iis-1116718 , rice university graduate fellowship , texas instruments fellowship , and texas higher education coordinating board : thecb - nharp 13308"
  ],
  "abstract_text": [
    "<S> vital signs such as pulse rate and breathing rate are currently measured using contact probes . </S>",
    "<S> but , non - contact methods for measuring vital signs are desirable both in hospital settings ( e.g. in nicu ) and for ubiquitous in - situ health tracking ( e.g. on mobile phone and computers with webcams ) . </S>",
    "<S> recently , camera - based non - contact vital sign monitoring have been shown to be feasible . </S>",
    "<S> however , camera - based vital sign monitoring is challenging for people with darker skin tone , under low lighting conditions , and/or during movement of an individual in front of the camera . in this paper , we propose distanceppg , a new camera - based vital sign estimation algorithm which addresses these challenges . </S>",
    "<S> distanceppg  proposes a new method of combining skin - color change signals from different tracked regions of the face using a weighted average , where the weights depend on the blood perfusion and incident light intensity in the region , to improve the signal - to - noise ratio ( snr ) of camera - based estimate . </S>",
    "<S> one of our key contributions is a new automatic method for determining the weights based only on the video recording of the subject . </S>",
    "<S> the gains in snr of camera - based ppg estimated using distanceppg  translate into reduction of the error in vital sign estimation , and thus expand the scope of camera - based vital sign monitoring to potentially challenging scenarios . </S>",
    "<S> further , a dataset will be released , comprising of synchronized video recordings of face and pulse oximeter  based ground truth recordings from the earlobe for people with different skin tones , under different lighting conditions and for various motion scenarios .    </S>",
    "<S> 10    w.  verkruysse , l.  o. svaasand , and j.  s. nelson , `` remote plethysmographic imaging using ambient light , '' optics express * 16 * , 2143421445 ( 2008 ) .    </S>",
    "<S> m .- z . </S>",
    "<S> poh , d.  mcduff , and r.  picard , `` advancements in noncontact , multiparameter physiological measurements using a webcam , '' ieee transactions on biomedical engineering * 58 * , 711 ( 2011 ) .    </S>",
    "<S> y.  sun , s.  hu , v.  azorin - peris , s.  greenwald , j.  chambers , and y.  zhu , `` motion - compensated noncontact imaging photoplethysmography to monitor cardiorespiratory status during exercise , '' journal of biomedical optics * 16 * , 077010 ( 2011 ) .    l.  a.  m. aarts , v.  jeanne , j.  p. cleary , c.  lieber , j.  s. nelson , s.  bambang  oetomo , and w.  verkruysse , `` non - contact heart rate monitoring utilizing camera photoplethysmography in the neonatal intensive care unit - a pilot study , '' early human development * 89 * , 943948 ( 2013 ) .    </S>",
    "<S> j.  m. saragih , s.  lucey , and j.  f. cohn , `` deformable model fitting by regularized landmark mean - shift , '' international journal of computer vision * 91 * , 200215 ( 2011 ) .    </S>",
    "<S> b.  d. lucas and t.  kanade , `` an iterative image registration technique with an application to stereo vision , '' ( 1981 ) , pp . </S>",
    "<S> 674679 .    c.  tomasi and t.  kanade , </S>",
    "<S> `` detection and tracking of point features , '' technical report mu - cs-91 - 132 , carnegie mellon university ( 1991 ) .    </S>",
    "<S> f.  p. wieringa , f.  mastik , and a.  f.  w. van  der steen , `` contactless multiple wavelength photoplethysmographic imaging : a first step toward `` spo2 camera '' technology , '' annals of biomedical engineering * 33 * , 10341041 ( 2005 ) .    </S>",
    "<S> k.  humphreys , t.  ward , and c.  markham , `` noncontact simultaneous dual wavelength photoplethysmography : a further step toward noncontact pulse oximetry , '' the review of scientific instruments * 78 * , 044304 ( 2007 ) .    </S>",
    "<S> m .- z . </S>",
    "<S> poh , d.  j. mcduff , and r.  w. picard , `` non - contact , automated cardiac pulse measurements using video imaging and blind source separation , '' optics express * 18 * , 1076210774 ( 2010 ) .    </S>",
    "<S> b.  d. holton , k.  mannapperuma , p.  j. lesniewski , and j.  c. thomas , `` signal recovery in imaging photoplethysmography , '' physiological measurement * 34 * , 14991511 ( 2013 ) .    </S>",
    "<S> d.  mcduff , s.  gontarek , and r.  picard , `` improvements in remote cardiopulmonary measurement using a five band digital camera , '' ieee transactions on biomedical engineering * 61 * , 25932601 ( 2014 ) .    </S>",
    "<S> j.  allen , `` photoplethysmography and its application in clinical physiological measurement , '' physiological measurement * 28 * , r1 ( 2007 ) .    </S>",
    "<S> s.  hu , v.  azorin - peris , and j.  zheng , `` opto - physiological modeling applied to photoplethysmographic cardiovascular assessment , '' journal of healthcare engineering * 4 * , 505528 ( 2013 ) .    </S>",
    "<S> d.  brennan , `` linear diversity combining techniques , '' proceedings of the ieee * 91 * , 331356 ( 2003 ) .    </S>",
    "<S> m.  nitzan , b.  khanokh , and y.  slovik , `` the difference in pulse transit time to the toe and finger measured by photoplethysmography , '' physiological measurement * 23 * , 8593 ( 2002 ) .    </S>",
    "<S> j.  shi and c.  tomasi , `` good features to track , '' in `` , 1994 ieee computer society conference on computer vision and pattern recognition , 1994 . </S>",
    "<S> proceedings cvpr 94 , '' ( 1994 ) , pp . </S>",
    "<S> 593600 .    </S>",
    "<S> z.  kalal , k.  mikolajczyk , and j.  matas , `` forward - backward error : automatic detection of tracking failures , '' in `` 2010 20th international conference on pattern recognition ( icpr ) , '' ( 2010 ) , pp . </S>",
    "<S> 27562759 .    </S>",
    "<S> m.  a. fischler and r.  c. bolles , `` random sample consensus : a paradigm for model fitting with applications to image analysis and automated cartography , '' commun . </S>",
    "<S> acm * 24 * , 381395 ( 1981 ) .    </S>",
    "<S> m.  fernandez , k.  burns , b.  calhoun , s.  george , b.  martin , and c.  weaver , `` evaluation of a new pulse oximeter sensor , '' american journal of critical care : an official publication , american association of critical - care nurses * 16 * , 146152 ( 2007 ) .    </S>",
    "<S> j.  a.  j. heathers , `` smartphone - enabled pulse rate variability : an alternative methodology for the collection of heart rate variability in psychophysiological research , '' international journal of psychophysiology : official journal of the international organization of psychophysiology * 89 * , 297304 ( 2013 ) </S>",
    "<S> .    philips , `` philips vital signs camera , '' http://www.vitalsignscamera.com/.    cardiio , `` cardiio , '' http://www.cardiio.com/. </S>"
  ]
}