{
  "article_text": [
    "in the last three decades , more and more large dimensional data sets appear in scientific research . when the dimension of data or the number of parameters becomes large",
    ", the classical methods could reduce statistical efficiency significantly . in order to analyze those large data sets , many new statistical techniques , such as large dimensional multivariate statistical analysis based on the random matrix theory ,",
    "have been developed . in this article , we consider the problem of testing the equality of several high dimensional mean vectors with unequal covariance matrices , which is also called multivariate analysis of variance ( manova ) problem .",
    "this problem is one of the most common multivariate statistical procedures in the social science , medical science , pharmaceutical science and genetics .",
    "for example , a kind of disease may have several treatments .",
    "in the past , doctors only concern which treatments can cure the disease , and the standard clinical cure is low dimension .",
    "however , nowadays researchers want to know whether the treatments alter some of the proteins or genes , thus then the high dimensional manova is needed .",
    "suppose there are @xmath0 groups and @xmath1 are @xmath2-variate independent and identically distributed ( i.i.d . )",
    "random samples vectors from the @xmath3-th group , which have mean vector @xmath4 and covariance matrix @xmath5 .",
    "we consider the problem of testing the hypothesis : @xmath6 notice that here we do not need normality assumption .",
    "the manova problem has been discussed intensively in the literature about multivariate statistic analysis .",
    "for example , for normally distributed groups , when the total sample size @xmath7 is considerably larger than the dimension @xmath2 , statistics that have been commonly used are likelyhood ratio test statistic @xcite , generalized @xmath8 statistic @xcite and pillai statistic @xcite .",
    "when @xmath2 is larger than the sample size @xmath9 , @xcite firstly considered this problem in the case of two sample problem .",
    "since then , more high dimensional tests have been proposed by @xcite .",
    "and recently , @xcite proposed a statistic to test the equality of multiple high - dimensional mean vectors under common covariance matrix .",
    "also , one can refer to the book @xcite for more details .",
    "the statistic of testing ( [ h ] ) we proposed in this article is motivated by @xcite and @xcite .",
    "firstly , let us review the two test statistics briefly . for @xmath10 and @xmath11 , @xcite proposed the test statistic @xmath12 and showed that under some conditions , as @xmath13 , @xmath14 and @xmath15 @xmath16 here @xmath17 and @xmath18 in addition , bai and saranadasa gave a ratio - consistent estimator of @xmath19 ( in the sense that @xmath20 ) ,  that was @xmath21    if @xmath22 , @xcite gave a test statistic @xmath23 which can be expressed as @xmath24 here and throughout this paper , the sample covariance matrix of the @xmath3-th group is denoted as @xmath25 also they proved that under some conditions @xmath26 where @xmath27 and then @xcite gave the ratio - consistent estimators of @xmath28 and @xmath29 , that were @xmath30 and @xmath31 here @xmath32 is the @xmath3-th sample mean after excluding @xmath33 and @xmath34 , and @xmath35 is the @xmath3-th sample mean without @xmath36 .    when @xmath37 , it is apparent that the test statistic proposed by @xcite reduces to the one obtained by @xcite . compared to @xcite , @xcite generalized the test to the case when @xmath38 , and used different estimators of the variance .",
    "this is indeed a significant improvement to remove the assumption @xmath39 , because such an assumption is hard to verify for high - dimensional data .",
    "thus based on these properties , we propose a statistic of testing the equality of more than two high dimensional mean vectors with unequal covariance matrices .",
    "we assume the following general multivariate model :    * @xmath40 where @xmath41 is a @xmath42 matrix for some @xmath43 such that @xmath44 , and @xmath45 are @xmath46-variate i.i.d .",
    "random vectors satisfying @xmath47 and @xmath48 , the @xmath49 identity matrix ; * @xmath50 , with @xmath51 and @xmath52 , for a positive integer @xmath53 such that @xmath54 and @xmath55 ; * @xmath56 here @xmath7 ; * @xmath57\\qquad d , l , h\\in\\{1,2,\\dots , k\\ } ; $ ] * @xmath58,\\quad d , l , h\\in\\{1,2,\\dots , k\\ } $ ] .",
    "it should be noted that all random variables and parameters here and later depend on @xmath9 . for simplicity",
    "we omit the subscript @xmath9 from all random variables except those statistics defined later .",
    "now we construct our test .",
    "consider the statistic @xmath59 when @xmath10 , apparently @xmath60 is the chen - qin test statistic .",
    "next we will calculate the mean and variance of @xmath61 . unlike the method used in @xcite",
    ", we give a much simpler procedure . from @xmath62 , we can rewrite @xmath63 as @xmath64 , where @xmath65 thus we can show immediately that @xmath66 and @xmath67 then we have the following theorem :    th1 under the assumptions ( a)-(e ) , we obtain that as @xmath68 and @xmath69 , @xmath70    it is worth noting that under @xmath71 , assumption ( e ) is trivially satisfied and @xmath72 . what is more , under @xmath73 and assumptions ( a)-(e ) , @xmath74 , where @xmath75 then theorem [ th1 ] is still true if the denominator of ( [ lim1 ] ) is replaced by @xmath76",
    "therefore , to complete the construction of our test statistic , we only need to find a ratio - consistent estimator of @xmath77 and substitute it into the denominator of ( [ lim1 ] ) .",
    "there are many estimators for @xmath77 , and in this paper we choose two of them :    th2 under the assumptions ( a)-(d ) , we obtain that as @xmath68 and @xmath69 , @xmath78 where @xmath79 @xmath80",
    "and@xmath81    under the normality assumption and are uniformly minimum variance unbiased estimators .",
    "the proof of this lemma was given in @xcite and @xcite , and we omit it in this paper .    [ leub ] under the assumptions ( a)-(d ) , we obtain that as @xmath68 and @xmath69 , @xmath78 where @xmath79 @xmath82 and @xmath83 here @xmath84 .    by assumption @xmath85 , the unbiasedness of estimators @xmath86 and @xmath87 can be easily proved and their ratio - consistency can be found in @xcite .",
    "@xcite mentioned that the computation of the estimators in lemma [ leub ] would be extremely heavy if the sample sizes are very large .",
    "thus to increase the computation speed , we simplify the estimator further to : @xmath88 where @xmath89 $ ] , @xmath90 and @xmath91 $ ] is a diagonal matrix consisting of the diagonal elements of @xmath92 . notice that for any matrix @xmath93 , the norm @xmath94 is entrywise norm , i.e. , @xmath95 and the norm @xmath96 is @xmath97 norm , i.e.",
    ", @xmath98    what is more , from a direct calculation we can show that the estimator ( [ esub2 ] ) is exactly equal to the estimator in lemma [ th2 ] .",
    "that is because , @xmath99 @xmath100 @xmath101 @xmath102 apparently , using the simplified formulas instead of the original ones can make the computation much faster .",
    "now , by combining theorem [ th1 ] and lemma [ th2 ] ( or lemma [ leub ] ) , we obtain our test statistic under @xmath71 and have the following theorem :    th3 under @xmath71 and the assumptions ( a)-(d ) , we obtain that as @xmath68 and @xmath69 , @xmath103 where @xmath104 with @xmath105 and @xmath106 given in lemma [ th2 ] or lemma [ leub ] .    when the number of groups @xmath107 is small , the hypothesis @xmath71 can be considered as a multiple hypothesis of testing each two sample . and the test for each sub - hypothesis can be tested by chen and qin ( 2010 ) .",
    "however , for each sub - hypothesis , there is a test statistic of chen and qin ( 2010 ) .",
    "the problem is how do we set up the critical value for the simultaneous test of the compound hypothesis @xmath71 . in the literature , there is a famous bonferroni correction method can be used .",
    "but it is well known that bonfferoni correction is much conservative .",
    "form this theorem , we can see that using our test , one may set up an asymptotically exact test .",
    "due to theorem [ th3 ] , the test with an @xmath108 level of significance rejects @xmath71 if @xmath109 where @xmath110 is the upper @xmath108 quantile of @xmath111 .",
    "next we will discuss the power properties of the proposed test .",
    "denote @xmath112 . from the above conclusions",
    ", we can easily obtain that @xmath113 this implies @xmath114 where @xmath115 is the standard normal distribution function .",
    "due to the fact that the commonly used likelihood ratio test performs badly when dimension is large has been considered in a lot of literature such as @xcite , the discussion of the likelihood ratio test is left out in this paper .",
    "recently , @xcite proposed a test statistic of testing the equality of mean vectors of several groups with a common unknown non - singular covariance matrix .",
    "denote @xmath116 as an @xmath117-vector with all the elements equal to one and define @xmath118 , @xmath119 and @xmath120 then it is proposed that @xmath121 where @xmath122^{-1}l(e'e)^{-1}e'y$ ] , @xmath123 $ ] , @xmath124 and @xmath125 notice that @xmath126 $ ] denotes a diagonal matrix with the same diagonal elements as the diagonal elements of matrix @xmath127 . under the null hypothesis and the condition @xmath128 with @xmath129 ,",
    "@xmath130 is asymptotically distributed as @xmath111 .",
    "that is as @xmath131 , @xmath132    in this section we compare the performance of the proposed statistics @xmath133 and @xmath130 in finite samples by simulation .",
    "notice that the data is generated from the model @xmath134 where @xmath41 is a @xmath135 such that @xmath136 . here @xmath137 and @xmath138 s are independent random variables which are distributed as one of the following three distributions : @xmath139 for the covariance matrix @xmath140 @xmath141 , we consider the following two cases :    * : @xmath142 ; * : @xmath143 , @xmath144 $ ] , @xmath145 , @xmath146 , @xmath147 , @xmath148 , @xmath149 .",
    "we first compare the convergence rates of the estimators and based on the above models , see figure [ fig1 ] and figure [ fig2 ] . here",
    "the dimension @xmath150 and the sample sizes @xmath9 are from 10 to 1000 .",
    "the results are based on 1000 replications . from these two figures",
    "we can easily find that in both cases , the une and umvue are almost the same if the data sets come from standard normal distribution .",
    "but une is much better than umvue if the data sets come from @xmath151 distribution , especially when @xmath9 is small .",
    "next let us see the performance of the estimator @xmath152 in case 1 and case 2 ( see figure [ fig3 ] and figure [ fig4 ] ) .",
    "also the dimension @xmath150 and the sample sizes @xmath153 are from 10 to 1000 .",
    "the results are based on 1000 replications . in case 1",
    ", the estimator @xmath152 performs very well at all the three distributions .",
    "however in case 2 , we find that the convergence rate of this estimator is not very fast",
    ". thus this will be one of the reasons that cause our test statistic @xmath154 to perform not well enough .     and the true value @xmath155 in case 1 , i.e. , @xmath156 . ]     and the true value @xmath155 in case 2 , i.e. , @xmath157 . ]     and the true value @xmath158 in case 1 , i.e. , @xmath159 . ]     and the true value @xmath158 in case 2 , i.e. , @xmath157 and @xmath160 .",
    "]    now we examine the attained significance level ( asl ) of the test statistics @xmath133 and @xmath130 compared to the nominal value @xmath161 , and then examine their attained power .",
    "the asl is computed as @xmath162 where @xmath163 are values of the test statistic @xmath133 or @xmath130 obtained from data simulated under @xmath71 , @xmath117 is the number of replications and @xmath164 is the @xmath165 quantile of the standard normal distribution .",
    "the attained power of the test @xmath133 and @xmath130 is also computed as @xmath166 , where @xmath167 are values of the test statistic @xmath133 or @xmath130 computed from data simulated under the alternative .    for simulation",
    ", we consider the problem of testing the equality of 3 mean vectors , that is , @xmath168 .",
    "choose @xmath169 , @xmath170 , @xmath171 , @xmath172 , where @xmath173 .",
    "for the null hypothesis , without loss of generality we choose @xmath174 .",
    "for the alternative hypothesis , we choose @xmath175 , @xmath176 and @xmath177 , where @xmath178 with @xmath179 are i.i.d .",
    "@xmath180 which denotes uniform distribution with the support @xmath181 .",
    "here in case 1 we choose @xmath182 and in case 2 we choose @xmath183 , respectively .",
    "the asl and the powers are obtained based on 10,000 replications and the @xmath184 quantile of the standard normal distribution is 1.64485 .",
    "the four tables report the asl and the power in the null hypothesis and the alternative hypothesis of the two tests . for illustration , in the tables",
    "we respectively use the estimators proposed in lemma [ th2 ] and lemma [ leub ] to obtain two different test statistics , @xmath185 and @xmath186 .",
    "it is shown in table 1 and table 3 that the asl of the proposed tests @xmath185 and @xmath186 approximate @xmath187 well in both cases , and @xmath186 is even better at nonnormal distributions . because it is shown that une is better than umvue if the data sets come from @xmath151 distribution , especially when @xmath9 is small .",
    "but the asl of test @xmath130 in case 2 performs substantially worse .",
    "in addition , in case 1 the test @xmath130 seems worse when dimension @xmath2 is much larger than the sample size @xmath188 .",
    "this is probably because @xmath130 is under common covariance matrix assumption and needs condition @xmath128 with @xmath129 to obtain the asymptotic distribution .",
    "as reported in table 2 and table 4 , the powers of the test @xmath186 perform better than @xmath130 in case 2 and worse in case 1 .",
    "but actually in case 1 , when the dimension @xmath2 and sample size @xmath188 are large , the powers of the test @xmath186 are also good enough .",
    "thus when the dimension is much larger than the sample size , or the dimension and the sample size are both large , our test statistic is recommended , as it is more stable .    ccccc|ccc|ccc     + & & & & + & & @xmath185&@xmath186&@xmath130&@xmath185&@xmath186&@xmath130&@xmath185&@xmath186&@xmath130 + 20 & 20 & 0.0578 & 0.0672 & 0.0505 & 0.0427 & 0.0643 & 0.0497 & 0.0549 & 0.0655 & 0.0531 + & 50 & 0.0626 & 0.0648 & 0.0480 & 0.0534 & 0.0605 & 0.0472 & 0.0578 & 0.0594 & 0.0489 + & 100 & 0.0630 & 0.0626 & 0.0458 & 0.0543 & 0.0614 & 0.0466 & 0.0598 & 0.0604 & 0.0476 + & 200 & 0.0606 & 0.0612 & 0.0434 & 0.0547 & 0.0635 & 0.0438 & 0.0587 & 0.0586 & 0.0441 + 50 & 20 & 0.0561 & 0.0613 & 0.0509 & 0.0383 & 0.0604 & 0.0471 & 0.0457 & 0.0632 & 0.0503 + & 50 & 0.0551 & 0.0573 & 0.0454 & 0.0444 & 0.0597 & 0.0450 & 0.0538 & 0.0572 & 0.0443 + & 100 & 0.0596 & 0.0608 & 0.0465 & 0.0528 & 0.0545 & 0.0490 & 0.0561 & 0.0578 & 0.0458 + & 200 & 0.0548 & 0.0563 & 0.0453 & 0.0528 & 0.0580 & 0.0453 & 0.0570 & 0.0578 & 0.0472 + 100 & 20 & 0.0565 & 0.0571 & 0.0524 & 0.0346 & 0.0572 & 0.0428 & 0.0477 & 0.0556 & 0.0478 + & 50 & 0.0551 & 0.0573 & 0.0468 & 0.0471 & 0.0599 & 0.0476 & 0.0506 & 0.0578 & 0.0477 + & 100 & 0.0548 & 0.0580 & 0.0468 & 0.0499 & 0.0570 & 0.0471 & 0.0524 & 0.0556 & 0.0461 + & 200 & 0.0549 & 0.0535 & 0.0456 & 0.0541 & 0.0599 & 0.0455 & 0.0521 & 0.0588 & 0.0437 + 500 & 20 & 0.0514 & 0.0549 & 0.0365 & 0.0315 & 0.0543 & 0.0351 & 0.0473 & 0.0528 & 0.0391 + & 50 & 0.0535 & 0.0553 & 0.0427 & 0.0422 & 0.0515 & 0.0434 & 0.0498 & 0.0517 & 0.0428 + & 100 & 0.0562 & 0.0511 & 0.0513 & 0.0457 & 0.0510 & 0.0423 & 0.0500 & 0.0532 & 0.0454 + & 200 & 0.0546 & 0.0518 & 0.0509 & 0.0497 & 0.0477 & 0.0473 & 0.0530 & 0.0584 & 0.0506 + 800 & 20 & 0.0516 & 0.0536 & 0.0332 & 0.0323 & 0.0535 & 0.0327 & 0.0436 & 0.0575 & 0.0325 + & 50 & 0.0480 & 0.0532 & 0.0393 & 0.0359 & 0.0543 & 0.0387 & 0.0452 & 0.0537 & 0.0392 + & 100 & 0.0462 & 0.0518 & 0.0403 & 0.0442 & 0.0528 & 0.0421 & 0.0445 & 0.0518 & 0.0421 + & 200 & 0.0531 & 0.0509 & 0.0465 & 0.0507 & 0.0524 & 0.0473 & 0.0515 & 0.0531 & 0.0490 +    ccccc|ccc|ccc     + & & & & + & & @xmath185&@xmath186&@xmath130&@xmath185&@xmath186&@xmath130&@xmath185&@xmath186&@xmath130 + 20 & 20 & 0.0941 & 0.0985 & 0.1079 & 0.0615 & 0.0931 & 0.1035 & 0.0828 & 0.0972 & 0.1031 + & 50 & 0.1673 & 0.1655 & 0.2188 & 0.1380 & 0.1630 & 0.2295 & 0.1538 & 0.1579 & 0.2191 + & 100 & 0.3111 & 0.3205 & 0.4649 & 0.3009 & 0.3180 & 0.4775 & 0.3139 & 0.3206 & 0.4678 + & 200 & 0.6710 & 0.9888 & 0.8453 & 0.6571 & 0.9902 & 0.8497 & 0.6664 & 0.9888 & 0.8529 + 50 & 20 & 0.1039 & 0.1158 & 0.1380 & 0.0748 & 0.1130 & 0.1494 & 0.0913 & 0.1147 & 0.1434 + & 50 & 0.2380 & 0.2431 & 0.3708 & 0.2102 & 0.2353 & 0.3957 & 0.2244 & 0.2372 & 0.3808 + & 100 & 0.5390 & 0.5459 & 0.7787 & 0.5218 & 0.5419 & 0.7879 & 0.5324 & 0.5446 & 0.7797 + & 200 & 0.9342 & 1.0000 & 0.9918 & 0.9344 & 1.0000 & 0.9932 & 0.9388 & 1.0000 & 0.9931 + 100 & 20 & 0.1280 & 0.1404 & 0.1843 & 0.0954 & 0.1357 & 0.2076 & 0.1154 & 0.1379 & 0.1918 + & 50 & 0.3493 & 0.3536 & 0.5712 & 0.3183 & 0.3577 & 0.6043 & 0.3433 & 0.3535 & 0.5871 + & 100 & 0.7787 & 0.7707 & 0.9574 & 0.7621 & 0.7799 & 0.9609 & 0.7774 & 0.7781 & 0.9581 + & 200 & 0.9966 & 1.0000 & 0.9999 & 0.9959 & 1.0000 & 1.0000 & 0.9965 & 1.0000 & 0.9999 + 500 & 20 & 0.2908 & 0.3120 & 0.4691 & 0.2206 & 0.2993 & 0.5203 & 0.2723 & 0.2989 & 0.4775 + & 50 & 0.8576 & 0.8690 & 0.9884 & 0.8413 & 0.8765 & 0.9937 & 0.8643 & 0.8683 & 0.9917 + & 100 & 1.0000 & 0.9998 & 1.0000 & 0.9997 & 0.9998 & 1.0000 & 1.0000 & 0.9999 & 1.0000 + & 200 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 + 800 & 20 & 0.3921 & 0.4103 & 0.6118 & 0.3028 & 0.4119 & 0.6763 & 0.3706 & 0.4001 & 0.6312 + & 50 & 0.9670 & 0.9662 & 0.9997 & 0.9547 & 0.9668 & 0.9997 & 0.9641 & 0.9681 & 0.9999 + & 100 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 + & 200 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 & 1.0000 +    ccccc|ccc|ccc     + & & & & + & & @xmath185&@xmath186&@xmath130&@xmath185&@xmath186&@xmath130&@xmath185&@xmath186&@xmath130 + 20 & 20 & 0.0723 & 0.0707 & 0.0153 & 0.0679 & 0.0788 & 0.0103 & 0.0739 & 0.0705 & 0.0120 + & 50 & 0.0688 & 0.0673 & 0.0087 & 0.0686 & 0.0657 & 0.0105 & 0.0654 & 0.0697 & 0.0084 + & 100 & 0.0708 & 0.0695 & 0.0100 & 0.0705 & 0.0730 & 0.0085 & 0.0664 & 0.0670 & 0.0096 + & 200 & 0.0695 & 0.0656 & 0.0083 & 0.0622 & 0.0710 & 0.0061 & 0.0640 & 0.0664 & 0.0104 + 50 & 20 & 0.0755 & 0.0747 & 0.0098 & 0.0815 & 0.0736 & 0.0116 & 0.0646 & 0.0755 & 0.0092 + & 50 & 0.0711 & 0.0722 & 0.0061 & 0.0676 & 0.0725 & 0.0069 & 0.0685 & 0.0735 & 0.0066 + & 100 & 0.0683 & 0.0694 & 0.0074 & 0.0623 & 0.0707 & 0.0052 & 0.0658 & 0.0695 & 0.0070 + & 200 & 0.0687 & 0.0688 & 0.0064 & 0.0673 & 0.0645 & 0.0066 & 0.0645 & 0.0709 & 0.0059 + 100 & 20 & 0.0744 & 0.0747 & 0.0086 & 0.0710 & 0.0705 & 0.0067 & 0.0745 & 0.0722 & 0.0074 + & 50 & 0.0687 & 0.0720 & 0.0067 & 0.0674 & 0.0665 & 0.0056 & 0.0744 & 0.0724 & 0.0072 + & 100 & 0.0679 & 0.0719 & 0.0056 & 0.0649 & 0.0641 & 0.0046 & 0.0752 & 0.0690 & 0.0067 + & 200 & 0.0699 & 0.0705 & 0.0057 & 0.0695 & 0.0684 & 0.0052 & 0.0673 & 0.0674 & 0.0056 + 500 & 20 & 0.0736 & 0.0710 & 0.0044 & 0.0755 & 0.0722 & 0.0048 & 0.0690 & 0.0754 & 0.0043 + & 50 & 0.0708 & 0.0714 & 0.0043 & 0.0703 & 0.0700 & 0.0043 & 0.0656 & 0.0681 & 0.0032 + & 100 & 0.0703 & 0.0705 & 0.0035 & 0.0713 & 0.0613 & 0.0019 & 0.0660 & 0.0728 & 0.0023 + & 200 & 0.0694 & 0.0692 & 0.0032 & 0.0686 & 0.0680 & 0.0030 & 0.0694 & 0.0709 & 0.0019 + 800 & 20 & 0.0730 & 0.0753 & 0.0041 & 0.0797 & 0.0797 & 0.0037 & 0.0736 & 0.0767 & 0.0032 + & 50 & 0.0680 & 0.0697 & 0.0025 & 0.0686 & 0.0738 & 0.0026 & 0.0754 & 0.0733 & 0.0026 + & 100 & 0.0686 & 0.0667 & 0.0022 & 0.0667 & 0.0651 & 0.0017 & 0.0680 & 0.0683 & 0.0017 + & 200 & 0.0705 & 0.0686 & 0.0015 & 0.0688 & 0.0678 & 0.0028 & 0.0691 & 0.0620 & 0.0016 +    ccccc|ccc|ccc     + & & & & + & & @xmath185&@xmath186&@xmath130&@xmath185&@xmath186&@xmath130&@xmath185&@xmath186&@xmath130 + 20 & 20 & 0.1952 & 0.0998 & 0.0573 & 0.1855 & 0.1998 & 0.0529 & 0.1859 & 0.1962&0.0557 + & 50 & 0.3860 & 0.1420 & 0.1377 & 0.3814 & 0.3973 & 0.1345 & 0.3927 & 0.3881 & 0.1406 + & 100 & 0.6769 & 0.2225 & 0.3454 & 0.6783 & 0.6782 & 0.3486 & 0.6864 & 0.6799 & 0.3457 + & 200 & 0.9464 & 0.7934 & 0.7498 & 0.9491 & 0.9999 & 0.7450 & 0.9516 & 0.9998 & 0.7475 + 50 & 20 & 0.2096 & 0.1111 & 0.0486 & 0.2031 & 0.2215 & 0.0500 & 0.2016 & 0.2087 & 0.0502 + & 50 & 0.4201 & 0.1583 & 0.1327 & 0.4246 & 0.4257 & 0.1326 & 0.4350 & 0.4329 & 0.1385 + & 100 & 0.7369 & 0.2442 & 0.3462 & 0.7425 & 0.7423 & 0.3588 & 0.7506 & 0.7471 & 0.3583 + & 200 & 0.9779 & 0.8457 & 0.7835 & 0.9796 & 1.0000 & 0.7763 & 0.9816 & 1.0000 & 0.7899 + 100 & 20 & 0.2148 & 0.1050 & 0.0471 & 0.2112 & 0.2230 & 0.0471 & 0.2163 & 0.2188 & 0.0458 + & 50 & 0.4575 & 0.1529 & 0.1286 & 0.4564 & 0.4583 & 0.1305 & 0.4631 & 0.4571 & 0.1292 + & 100 & 0.7860 & 0.2482 & 0.3601 & 0.7838 & 0.7839 & 0.3549 & 0.7797 & 0.7863 & 0.3482 + & 200 & 0.9899 & 0.8846 & 0.7939 & 0.9897 & 1.0000 & 0.7994 & 0.9912 & 1.0000 & 0.7949 + 500 & 20 & 0.2465 & 0.1134 & 0.0342 & 0.2430 & 0.2478 & 0.0331 & 0.2450 & 0.2460 & 0.0350 + & 50 & 0.5226 & 0.1787 & 0.1127 & 0.5220 & 0.5162 & 0.1119 & 0.5284 & 0.5198 & 0.1161 + & 100 & 0.8594 & 0.2807 & 0.3373 & 0.8624 & 0.8637 & 0.3371 & 0.8595 & 0.8619 & 0.3381 + & 200 & 0.9990 & 0.9400 & 0.8238 & 0.9995 & 1.0000 & 0.8171 & 0.9993 & 1.0000 & 0.8212 + 800 & 20 & 0.2474 & 0.1237 & 0.0290 & 0.2586 & 0.2572 & 0.0320 & 0.2579 & 0.2597 & 0.0317 + & 50 & 0.5397 & 0.1867 & 0.1063 & 0.5550 & 0.5482 & 0.1061 & 0.5466 & 0.5352 & 0.1033 + & 100 & 0.8250 & 0.2984 & 0.3359 & 0.8850 & 0.8893 & 0.3459 & 0.8855 & 0.8865 & 0.3370 + & 200 & 0.9998 & 0.9548 & 0.8152 & 0.9997 & 1.0000 & 0.8252 & 0.9996 & 1.0000 & 0.8247 +",
    "in this section we give the proof of theorem [ th1 ] .",
    "we restricted our attention to the case in which @xmath168 for simplicity and the proof for the case of @xmath189 is the same .",
    "here we use the same method as in @xcite , hence some of the derivations are omitted .",
    "the main difference is that we need to verify the asymptotic normality of @xmath190 . because it does not follow by any means that the random variable @xmath191 will converge in distribution to @xmath192 , if @xmath193 and @xmath194",
    ".    denote @xmath195 , where @xmath196 and @xmath197 we can verify that @xmath198 , @xmath199 and @xmath200 from condition ( e ) , that is , @xmath201 we get @xmath202      verify that @xmath220 = e\\big(\\sum_{i_1,i_2=1}^{j-1}\\phi_{i_1j}\\phi_{i_2j}\\big|\\mathcal{f}_{n , j-1}\\big)\\ ] ] @xmath221 @xmath222 where @xmath223 is the coefficient of @xmath224 and if @xmath225 $ ] , @xmath226 ; if @xmath227 $ ] , @xmath228 ; if @xmath229 $ ] , @xmath230 .    denote @xmath231",
    "then we have @xmath232 now consider @xmath233 ^ 2=2e(a)+e(b),\\end{aligned}\\ ] ] where @xmath234and @xmath235 the term @xmath236 can be further partitioned as @xmath237 , where @xmath238 we only compute @xmath239 here as @xmath240 and @xmath241 can be computed following the same procedure . as @xmath242 , we only need to consider @xmath243 , @xmath244 , @xmath245 and @xmath246 in these three cases : ( a ) @xmath247 ; ( b ) @xmath248 or @xmath249 ; ( c ) @xmath250 .",
    "thus we obtain that @xmath251 where @xmath252 and @xmath253 thus we obtain that @xmath254 as we can similarly get @xmath255 and @xmath256 , we conclude that @xmath257    using the same method of deriving , we have @xmath258 which together with and implies @xmath259 then we have @xmath260 therefore we obtain @xmath261 and @xmath262 which complete the proof of .      as @xmath263 note that @xmath264 the first term of last equation has the order @xmath265 which can be proved by the same procedure in last subsection .",
    "it remains to consider the second term .",
    "as proved in @xcite , we have @xmath266 and @xmath267 thus we conclude that @xmath268 then the proof of is complete .",
    "the authors would like to thank the referees for many constructive comments ."
  ],
  "abstract_text": [
    "<S> in this article , we focus on the problem of testing the equality of several high dimensional mean vectors with unequal covariance matrices . </S>",
    "<S> this is one of the most important problems in multivariate statistical analysis and there have been various tests proposed in the literature . </S>",
    "<S> motivated by @xcite and @xcite , we introduce a test statistic and derive the asymptotic distributions under the null and the alternative hypothesis . </S>",
    "<S> in addition , it is compared with a test statistic recently proposed by @xcite . </S>",
    "<S> it is shown that our test statistic performs much better especially in the large dimensional case . </S>"
  ]
}