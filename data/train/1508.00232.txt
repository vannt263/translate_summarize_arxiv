{
  "article_text": [
    "markov jump linear systems @xcite are an important class of switched systems in which the _ mode signal _ , responsible for controlling the switch among dynamic modes , is modeled by a time - homogeneous markov process . this type of systems has been widely used in multiple applications , such as robotics  @xcite , economics  @xcite , networked control  @xcite , and epidemiology  @xcite .",
    "solutions to standard controller synthesis problems for markov jump linear systems , such as state - feedback stabilization , quadratic optimal control , @xmath0  optimal control , and @xmath1  optimal control  ( see , e.g. , the monograph  @xcite ) , can be found in the literature .",
    "these works , however , are based on the unrealistic assumption that the controller has full knowledge about the mode signal at any time instant .    to overcome this limitation ,",
    "several papers investigate the effect of limited and/or uncertain knowledge about the mode signal .",
    "for example , the authors in  @xcite studied @xmath0  control of discrete - time markov jump linear systems when the state space of the mode signal is partitioned into subsets , called _ clusters _ , and the controller only knows in which cluster the mode signal is at a given time .",
    "similar studies in the context of @xmath1  control can be found in @xcite . in the extreme case of having a single mode cluster ( in other words , when one can not observe the mode ) , the authors in  @xcite investigated quadratic optimal control problems .",
    "most of the above works can be studied in a framework based on random and uncertain mode observations ( see @xcite for the description of this framework in the context of @xmath0  control ) . in a complementary line of work , we find some papers assuming that the mode signal can only be observed at particular sampling times , instead of at any time instant . in this direction , we find in the literature a variety of random sampling strategies of the mode signal .",
    "the authors in  @xcite designed almost - surely stabilizing state - feedback gains when the sampling times follow a renewal process .",
    "similarly , the authors in  @xcite derived stabilizing state - feedback gains using lyapunov - like functions under periodic observations .    in this paper , we propose a framework to design state - feedback controllers for discrete - time markov jump linear systems assuming that the mode signal can only be observed when a markov chain ( different than the one describing the mode signal ) visits a particular subset of its state space .",
    "we call this observation process _ hidden - markov _ , due to its similitude with hidden - markov processes  @xcite .",
    "we show how hidden - markov observation processes generalize many relevant cases previously studied in the literature , such as those in  @xcite . in this context",
    ", we propose a linear matrix inequalities ( lmi ) formulation to design feedback control laws for ( stochastic ) stabilization , @xmath0 , and @xmath1 control of discrete - time markov jump linear systems under hidden - markov observations of the mode signal .",
    "it is important to remark that , since the observation process is hidden - markovian , existing control synthesis methods for markov jump linear systems , such as those in  @xcite , do not apply to our case .",
    "the paper is organized as follows . in section  [ sec : prbformulation ] , we formulate the state - feedback control problem for markov jump linear systems with hidden - markovian observations of the mode signal .",
    "we show in section  [ sec : analysis ] that the resulting closed - loop system can be reduced to a standard markov jump linear system by embedding the ( possibly non - markovian ) stochastic processes relevant to the controller into an extended markov chain . in section",
    "[ sec : design ] , we derive an lmi formulation to design state - feedback gains for stabilization , @xmath0 , and @xmath1 control problems .",
    "finally , in section  [ sec : example ] , we illustrate our results with some numerical examples .",
    "the notation used in this paper is standard .",
    "let @xmath2 denote the set of nonnegative integers .",
    "let @xmath3 and @xmath4 denote the vector spaces of real @xmath5-vectors and @xmath6 matrices , respectively .",
    "by @xmath7 , we denote the euclidean norm on  @xmath3 .",
    "@xmath8 will be used to denote the probability of an event .",
    "the probability of an event conditional on another event @xmath9 is denoted by @xmath10 .",
    "expectations are denoted by @xmath11 $ ] . for a positive integer @xmath12",
    ", we define the set @xmath13 = \\{1 , \\dotsc , n\\}$ ] . for a positive integer  @xmath14 and an integer @xmath15 ,",
    "define @xmath16 as the unique integer in @xmath17 such that @xmath18 is an integer multiple of @xmath14 .",
    "when a real symmetric matrix @xmath19 is positive ( resp . , negative ) definite , we write @xmath20 ( resp . , @xmath21 ) .",
    "the notations @xmath22 and @xmath23 are then understood in the obvious way . for sets of matrices @xmath24 and @xmath25 sharing the same index set @xmath26 , we define another set of matrices @xmath27 .",
    "the symbol  @xmath28 will be used to denote the symmetric blocks of partitioned symmetric matrices .",
    "finally , indicator functions are denoted by @xmath29 .",
    "in this section , we formulate the problems under study . let @xmath5 , @xmath30 , @xmath31 , @xmath32 , and  @xmath12 be positive integers",
    ". for each @xmath33 $ ] , let @xmath34 , @xmath35 , @xmath36 , @xmath37 , and . also , let @xmath38 be the time - homogeneous markov chain taking values in  @xmath13 $ ] and having the transition probability matrix  @xmath39 .",
    "consider the markov jump linear system  @xcite : @xmath40 we call @xmath41 and @xmath42 the state and the mode of @xmath43 , respectively .",
    "the signal @xmath44 represents an exogenous disturbance , @xmath45 is the control input , and @xmath46 is the measured signal .",
    "the initial conditions are denoted by @xmath47 and @xmath48 .",
    "we will assume that @xmath49 and @xmath50 are either deterministic constants or random variables , depending on the particular control problems considered .      in this paper",
    ", we consider the situation where the controller can not measure the mode signal at every time instant . to study this case , we model the times at which the controller can observe the mode by the stochastic process @xmath51 taking values in @xmath52 .",
    "we call @xmath53 the _ observation process _ and each @xmath54 an _ observation time_. for each @xmath55 , we assume either @xmath56 or @xmath57 .",
    "it is understood that , if @xmath58 , then no observation will be performed after time  @xmath54 .    in this paper , we focus on the following class of observation processes :    [ def : hiddenmarkov ] we say that an observation process @xmath53 is _ _ hidden - markov _ _ characterizing the observation process  @xmath53 is a hidden - markov process  @xcite . ] if there exist an @xmath59 , a markov chain taking values in @xmath60 $ ] ( independent of the mode @xmath42 ) , and a function   such that @xmath61 and , for every @xmath62 , @xmath63 where the minimum of the empty set is understood to be @xmath64 .",
    "for example , if the image of @xmath65 equals the set @xmath66 , then the controller observes the mode at all time instants . on the other hand ,",
    "if @xmath65 maps into @xmath67 , then the controller never observes the mode signal .",
    "in fact , the class of hidden - markov observation processes contains many other interesting examples as will be seen below . throughout the paper ,",
    "we denote the transition probability matrix of @xmath68 by  @xmath69 . in what follows",
    ", we provide three particular examples that can be formulated as hidden - markovian observation processes :    [ ex : gechannel ] consider the case where the controller observes the mode through a gilbert - elliot channel  @xcite .",
    "this channel has two possible states : the good ( g ) and bad ( b ) states .",
    "when the channel is at the g state , it transmits the mode signal to the controller ; in contrast , when it is at state b , it does not transmit .",
    "this channel switches its state according to a markov chain , defined as follows .",
    "let @xmath70 $ ] be the transition probabilities from g to b and b to g , respectively .",
    "we can formulate this channel as a hidden - markovian observation process ( definition [ def : hiddenmarkov ] ) using the following parameters : @xmath71    our second example is closely related to the observation processes investigated in  @xcite :    [ ex : iid ] assume that , at each time instant , the controller attempts to observe the mode signal but it fails with probability @xmath72 $ ] , independently from the observations at other time instants .",
    "this observation process can be implemented as a hidden - markovian observation process using the following parameters : @xmath73 we remark that , under a similar problem setting , the authors in @xcite propose a framework for stochastic stabilization and @xmath0 control of markov jump linear systems .",
    "our last example is concerned with periodic observation with failures :    let @xmath32 be a positive integer and @xmath74 $ ] . define @xmath75 , \\quad f(\\lambda)= \\begin{cases } 1 , & \\text{if $ \\lambda = 1 $ } ,   \\\\ 0 , & \\text{otherwise . }",
    "\\end{cases}\\ ] ] then , we can see that @xmath76 is a positive integer multiple of @xmath32 with probability one and , also , @xmath77 for all @xmath62 and @xmath78 .",
    "the corresponding observation process describes the situation where the controller tries to observe the mode signal every @xmath32 time units with a probability of success @xmath79 for each observation .",
    "in particular , for @xmath80 , this observation process gives the periodic case considered in  @xcite .    in order to specify the behavior of the controller between two consecutive observation times , we introduce the following processes . given an observation process  @xmath53 , we define the stochastic process  @xmath81 by @xmath82 where @xmath83 is an integer satisfying @xmath84 for each time @xmath15 , the above defined @xmath85 represents the most recent time the controller observed the mode . we , in particular , have @xmath86 for every @xmath62 .",
    "notice that , for @xmath87 , we augment the process @xmath88 with a negative integer @xmath83 .",
    "this is because , before time @xmath89 , no observation is performed by the controller yet .",
    "this augmentation is not needed if @xmath90 , in which case we set @xmath91 as in  .",
    "we also define the stochastic process  @xmath92 taking values in @xmath13 $ ] by @xmath93 where @xmath94 is an element in @xmath13 $ ] satisfying @xmath95 \\rightarrow [ \\sigma_0 = r_0].\\ ] ]    . the observation times",
    "@xmath96 , @xmath97 , @xmath98 , @xmath99 are determined by the markov chain @xmath68 and the function @xmath100 \\to \\{0 , 1\\}$ ] given by @xmath101 if @xmath102 and @xmath103 otherwise . until the first observation time  @xmath104",
    ", the most recent observation  @xmath105 is temporarily set to @xmath106.,width=264 ]    for each @xmath15 , the random variable @xmath107 represents the most - updated information about the mode signal kept by the controller at time @xmath15 .",
    "we again notice that , by the same reason indicated above , @xmath105 is augmented by an arbitrary @xmath94 before the time instant @xmath108 ( i.e. , before the first observation is performed ) . as is the case for @xmath83 , if @xmath90 , then this augmentation is not needed and thus we set @xmath109 as in .",
    "see figure  [ fig : observation ] for an illustration of the stochastic processes described so far .    in",
    "what follows , we present the state - feedback control scheme studied in this paper .",
    "we assume that the controller has an access to the following pieces of information at each time @xmath110 : ( _ i _ ) the state variable  @xmath111 , ( _ ii _ ) the most recent observation  @xmath107 of the mode  @xmath42 , and ( _ iii _ )  the quantity  @xmath112 , which is the time elapsed since the last observation .",
    "specifically , the state - feedback controller under consideration takes the form @xmath113 where @xmath114 for each @xmath115 $ ] and @xmath116}$ ] .",
    "the first subindex of @xmath117 in , i.e. , @xmath107 , allows the gain to be reset whenever the controller observes the mode .",
    "the second subindex to @xmath118 in the second subindex of @xmath117 in to make the index  @xmath119 of @xmath120 start from @xmath121 , instead of  @xmath122 . ] of @xmath117 in allows the controller to change its feedback gain between two consecutive observation times with period @xmath14 as in @xcite , rather than keeping them to be constant .",
    "we will later see in section  [ sec : example ] that , as the period @xmath14 increases , the performance of the controller can in fact improve . throughout the paper",
    ", we will use the notation @xmath123 notice that the initial condition of @xmath124 is given by @xmath125 .",
    "we now introduce several performance measures used to evaluate the state - feedback control law  .",
    "the feedback control law applied to @xmath43 yields the following closed - loop system @xmath126 let us introduce the compact notation @xmath127 also , define @xmath128 as the set of quadruples @xmath129\\times [ m]\\times [ n]\\times [ t]$ ] such that , if @xmath130 , then @xmath131 and @xmath132 .",
    "the set @xmath128 contains all possible values that can be taken by the stochastic process @xmath133 .",
    "we denote the initial condition for @xmath133 as @xmath134 .",
    "we sometimes denote the trajectories  @xmath41 and @xmath46 of @xmath135 by @xmath136 and @xmath137 , respectively , whenever we need to clarify the initial conditions as well as the disturbance  @xmath44 .",
    "we finally remark that , by the conditions in and , @xmath138 is determined by @xmath50 , @xmath139 , @xmath94 , and @xmath140 as @xmath141    the first performance measure under consideration is mean square stability :    [ defn : ms ] we say that @xmath135 is _ mean square stable _ if there exist @xmath142 and @xmath143 such that @xmath144 \\leq c\\lambda^k { \\lvert x_0 \\rvert}^2 $ ] for all @xmath49 , @xmath138 , and @xmath110 , provided @xmath145 .    in order to define the second performance under consideration , we first need to introduce the space of square summable stochastic processes , as follows .",
    "let @xmath146 be the @xmath105-algebra generated by the random variables @xmath147 .",
    "define @xmath148 ( @xmath149 for short ) as the space of @xmath3-valued stochastic processes @xmath150 such that @xmath151 is an @xmath3-valued and @xmath146-measurable random variable each @xmath110 and , moreover , @xmath152 $ ] is finite .",
    "for @xmath153 , define its @xmath149-norm @xmath154 by @xmath155 $ ] .",
    "then , we extend the definition of the @xmath0  norm of a markov jump linear system introduced in  @xcite , as follows :    assume that @xmath138 follows the probability distribution @xmath156 . define the _",
    "@xmath0  norm _ of @xmath135 by @xmath157 where @xmath158 denotes the @xmath55th standard unit vector in @xmath159 and @xmath160 is the function defined on @xmath2 by @xmath161 and @xmath162 for @xmath78 .",
    "our third and last performance measure is the @xmath1  norm . in our context",
    ", we use the following definition , which is an extension of the one for standard markov jump linear systems  @xcite :    assume that @xmath135 is mean square stable and @xmath163 .",
    "define the _",
    "@xmath1  norm _ of @xmath135 by @xmath164    having introduced these three performance measures , we can now formulate the problems under consideration .",
    "the first problem is concerned with stochastic stabilization , which is stated as follows :    [ prb : stbl ] find a set of matrices @xmath165 , \\delta\\in[t]}\\subset \\mathbb{r}^{m\\times n}$ ] such that @xmath135 is mean square stable .    the second problem is concerned with the stabilization of the closed - loop system with an upper - bound on the @xmath0 norm . in this problem , we assume that the distributions of @xmath50 and @xmath139 are given .",
    "thus , the parameters to be designed are feedback gains @xmath117 and the distribution @xmath166 of the pair @xmath167 :    [ prb : h2 ] assume that the distributions of @xmath50 and @xmath139 are known .",
    "for a given @xmath168 , find a set of matrices @xmath165 , \\delta\\in[t]}\\subset \\mathbb{r}^{m\\times n}$ ] and a distribution @xmath166 such that @xmath135 is mean square stable and @xmath169",
    ".    given the distribution @xmath170 ( resp . , @xmath171 ) of @xmath50 ( resp . , @xmath139 ) ,",
    "using we can find @xmath156 as @xmath172 for every @xmath173 .",
    "the last problem is the stabilization of the closed - loop system with an upper - bound on the @xmath1 norm :    [ prb : hinfty ] for a given @xmath174 , find a set of matrices @xmath175 , \\delta\\in[t]}\\subset \\mathbb{r}^{m\\times n}$ ] such that @xmath135 is mean square stable and @xmath176 .",
    "we remark that @xmath135 is no longer a standard markov jump linear system , due to the nature of the processes @xmath105 and @xmath124 .",
    "therefore , we can not use any of the techniques in the literature  @xcite to synthesize a control law .",
    "in fact , we can not use existing techniques even to analyze the performance of @xmath135 .",
    "moreover , due to the generality of hidden - markov observation processes , we can not use any of the results in @xcite , recently proposed to design state - feedback control laws for markov jump linear systems with partial mode observation .",
    "in this section , we show how to analyze the closed - loop system  @xmath135 . in this direction , we reduce @xmath135 to a standard markov jump linear system by embedding stochastic processes appearing in the closed - loop system ( which are not necessarily markovian ) into an extended markov chain with a larger state space .",
    "let us begin with the following observation :    [ lem : extendedmarkov ] the stochastic process @xmath133 defined by is a time - homogeneous markov chain .",
    "moreover , its transition probabilities are given by @xmath177 for all @xmath178 and @xmath179 in @xmath128 .",
    "let @xmath180 , @xmath181 , and @xmath182 ( @xmath183 ) be arbitrary .",
    "for each @xmath55 , define the events @xmath184 and @xmath185 as @xmath186 and @xmath187 . under the assumption that @xmath188 is not the null set , we need to evaluate the conditional probability @xmath189 remark that , since @xmath190 , we have @xmath191    first , assume that @xmath192 .",
    "then , by definition  [ def : hiddenmarkov ] , an observation occurs at time  @xmath193 , i.e. , we have @xmath194 and @xmath195 .",
    "this implies that @xmath196 therefore , since @xmath197 , @xmath198 and hence @xmath199 the probability appearing in the last term of this equation can be computed as @xmath200 where we have used the fact that both @xmath42 and @xmath68 are time - homogeneous markov chains .",
    "thus , from equations , , and , we conclude that for the case of @xmath192 , @xmath201    second , consider the case where @xmath202 . in this case , the markov mode @xmath42 is not observed at time @xmath193 , hence , we have @xmath203 and @xmath204 .",
    "therefore , using equations , in the same way as we derived , we can show that @xmath205 and hence @xmath206 therefore , from equations , , and , we show that , if @xmath202 , then @xmath207    since the probabilities and do not depend on @xmath208 , letting @xmath209 and @xmath210 in and , we obtain @xmath211 for every @xmath110 .",
    "this shows that @xmath133 is a markov chain since @xmath212 are arbitrary .",
    "moreover , since the probabilities and do not depend on @xmath15 , we conclude that the markov chain @xmath133 is time - homogeneous and its transition probabilities are given by .",
    "lemma  [ lem : extendedmarkov ] states that the closed - loop @xmath135 can be represented as a markov jump linear system with its mode being the extended markov chain  @xmath133 .",
    "this observation leads us to the following definitions . for @xmath213 ,",
    "we denote the transition probabilities of the markov chain @xmath133 ( eq .   in lemma  [ lem : extendedmarkov ] ) by .",
    "then , we introduce the markov jump linear system @xmath214 where @xmath215 is the time - homogeneous markov chain taking values in @xmath216 whose transition probabilities are @xmath217 , and the matrices @xmath218 , @xmath219 , and @xmath220 are defined by @xmath221 for each @xmath222 .",
    "we sometimes denote @xmath223 and @xmath224 by @xmath225 and @xmath226 whenever we need to clarify initial conditions and disturbances @xmath227 .",
    "the next corollary of lemma  [ lem : extendedmarkov ] plays the key role in this paper .",
    "[ cor : equivalence ] assume that @xmath228 , @xmath44 and @xmath227 have the same probability distribution , and @xmath138 and @xmath229 have the same probability distribution .",
    "then , the stochastic processes @xmath230 and @xmath231 have the same probability distribution .",
    "also , under the same assumption , the stochastic processes  @xmath137 and @xmath232 have the same probability distribution .    by the assumption , the markov chains @xmath133 and",
    "@xmath215 have the same initial distribution .",
    "the chains also have the same transition probabilities from lemma  [ lem : extendedmarkov ] and the definition of @xmath215",
    ". therefore , @xmath233 and  @xmath215 have the same probability distribution . also , we notice that , by the definition of the matrices in , the system  @xmath135 admits the following representation : @xmath234 therefore , @xmath135 has the same dynamics as @xmath235 . in conclusion",
    ", the claim holds true under the assumptions stated in the corollary .    using corollary  [ cor : equivalence ]",
    ", we can characterize the performance measures of the closed - loop system  @xmath135 .",
    "the next proposition provides a characterization for mean square stability :    [ prop : stbl ] for @xmath236 and @xmath237 , define @xmath238 .",
    "then , the following statements are equivalent :    1 .",
    "[ item : stbl ] @xmath135 is mean square stable ; 2 .   [",
    "item : barstbl]@xmath235 is mean square stable ; 3 .   [",
    "item : stblcond ] there exist positive - definite matrices  @xmath239 for every @xmath237 , such that @xmath240 .",
    "the equivalence [ [ item : barstbl ] @xmath241 [ item : stblcond ] ] immediately follows from the standard theory of markov jump linear systems ( see , e.g. , @xcite ) .",
    "let us prove [ [ item : barstbl ] @xmath242 [ item : stbl ] ] .",
    "assume that @xmath235 is mean square stable . in order to show that @xmath135 is mean square stable ,",
    "let us take arbitrary @xmath243 and @xmath244 .",
    "then , by corollary  [ cor : equivalence ] and the mean square stability of @xmath245 , we can show for some @xmath142 and @xmath143 , which implies mean square stability of @xmath135 .",
    "we can prove [ [ item : stbl ] @xmath242 [ item : barstbl ] ] in the same way .",
    "the following proposition characterizes the @xmath0 norm of @xmath135 :    [ prop : h2 ] let @xmath174 be arbitrary . assume that @xmath138 and @xmath229 follow the same distribution @xmath156 .",
    "then , the following statements are equivalent :    1 .",
    "[ item:2<gamma ] @xmath135 is mean square stable and @xmath246 ; 2 .   [ item : bar2<gamma ] @xmath235 is mean square stable and @xmath247 ; 3 .",
    "[ item:2cond ] there exist a family of positive - definite matrices @xmath248 for every @xmath237 , such that @xmath249 and @xmath250 , where the set @xmath251 indexed by @xmath128 is defined as @xmath252 .",
    "the proof of the equivalence [ [ item:2<gamma ] @xmath241 [ item : bar2<gamma ] ] immediately follows from corollary  [ cor : equivalence ] .",
    "also , the equivalence  [ [ item : bar2<gamma ] @xmath241 [ item:2cond ] ] is a direct consequence of a standard result  ( * ? ? ?",
    "* proposition  4 ) in the theory of markov jump linear systems .",
    "the details are omitted .",
    "finally , the following proposition characterizes the @xmath1 norm :    [ prop : hinf ] for matrices @xmath253 , define @xmath254 .",
    "let @xmath174 be arbitrary .",
    "consider the following statements :    1 .",
    "[ item : inf < gamma]@xmath135 is mean square stable and @xmath255 ; 2 .   [",
    "item : barinf < gamma ] @xmath235 is mean square stable and @xmath256 ; 3 .",
    "[ item : infcond ] there exist matrices @xmath257 , @xmath258 , @xmath259 , and @xmath260 ( @xmath213 ) such that @xmath261 for all @xmath213 .",
    "then , [ item : inf < gamma ] and [ item : barinf < gamma ] are equivalent .",
    "moreover , [ item : infcond ] implies [ item : inf < gamma ] and [ item : barinf < gamma ] .",
    "the implication [ [ item : infcond ] @xmath242 [ item : barinf < gamma ] ] is a direct consequence of ( * ? ? ?",
    "* theorem 1 ) .",
    "let us prove [ [ item : inf < gamma ] @xmath241 [ item : barinf < gamma ] ] .",
    "it is sufficient to show @xmath262 .",
    "let @xmath263 denote the @xmath105-algebra generated by the random variables @xmath264 .",
    "define @xmath265 as the space of stochastic processes @xmath266 such that @xmath267 $ ] is finite and , for each @xmath110 , @xmath268 is an @xmath3-valued and @xmath269-measurable random variable .",
    "define the norm of  @xmath270 by @xmath271 $ ] .",
    "then , the @xmath1 norm of @xmath235 is given by @xmath272 to show that this norm equals @xmath273 , it is sufficient to show that , if @xmath274 , then @xmath275 by corollary  [ cor : equivalence ] , the only difference between both sides of the equality is the spaces  @xmath149 and @xmath265 .",
    "in other words , to complete the proof , it is sufficient to show that @xmath146 , the @xmath105-algebra generated by the random variables @xmath276 , coincides with the one generated by @xmath277 .",
    "this is obvious because @xmath107 and @xmath278 are images of @xmath279 under measurable functions .",
    "based on the performance characterizations presented in the previous section , we now propose a formulation based on linear matrix inequalities ( lmi ) to design feedback control laws for stabilization , @xmath0 , and @xmath1 control of discrete - time markov jump linear systems under hidden - markovian observations of the mode signals .",
    "the next theorem provides an lmi formulation to solve the stabilization problem stated in problem  [ prb : stbl ] :    [ thm : stblization ] assume that the matrices , @xmath280 , and @xmath281 ( @xmath282 ) satisfy the linear matrix inequality @xmath283 for every @xmath284 . for each @xmath115 $ ] and @xmath116}$ ] ,",
    "define @xmath285 then , the resulting closed - loop system @xmath135 is mean square stable .",
    "assume that @xmath286 , @xmath287 , and @xmath288 satisfy , and define @xmath117 by .",
    "our proof is based on an argument proposed in @xcite .",
    "since @xmath128 is a finite set , there exists an @xmath289 such that @xmath290 satisfies @xmath291 where we have used @xmath292 . since this inequality implies @xmath293 , we have @xmath294 .",
    "we here recall that , for a positive definite matrix @xmath295 and another matrix  @xmath296 , it holds that ( see , e.g. , @xcite ) @xmath297 .",
    "using this fact in , we obtain @xmath298 also , from , we see that @xmath299 and therefore @xmath300 is invertible .",
    "hence , we can take the schur complement of the positive - definite matrix in with respect to @xmath301 to obtain @xmath302 . applying to this inequality the operator @xmath303",
    ", we obtain .",
    "therefore , by proposition  [ prop : stbl ] , @xmath135 is mean square stable .    secondly , the next theorem provides an lmi formulation to solve the @xmath0 control problem stated in problem  [ prb : h2 ] :    [ thm : h2 ] let @xmath304 be arbitrary .",
    "assume that @xmath305 , @xmath306 , @xmath307 , @xmath308 , and @xmath309 ( @xmath310 ) satisfy the following linear matrix inequalities @xmath311 for every @xmath312 .",
    "define the feedback matrix @xmath117 by .",
    "then , the closed - loop system @xmath135 is mean square stable and satisfies @xmath246 .",
    "we remark that the ( in)equalities in theorem  [ thm : h2 ] are indeed linear with respect to the design variables .",
    "the linearity with respect to the matrix variables @xmath313 , @xmath301 , @xmath314 , and @xmath315 is obvious .",
    "the linearity with respect to @xmath166 follows from .",
    "we also remark that the constraint   makes @xmath166 a probability measure .",
    "let us prove theorem  [ thm : h2 ] .",
    "assume that @xmath174 , @xmath316 , @xmath317 , @xmath318 , @xmath319 , and @xmath320 satisfy , and let us define @xmath117 by .",
    "in the same way as in the proof of theorem  [ thm : stblization ] , there exists an @xmath289 such that @xmath321 satisfies @xmath322 applying schur complement to the matrix in the left hand side of , we obtain . applying the operator @xmath323 to this inequality yields .",
    "in addition , from it follows that .",
    "hence , we have by .",
    "therefore , by proposition  [ prop : h2 ] , @xmath135 is mean square stable and satisfies @xmath246 .",
    "finally , the next theorem provides an lmi formulation to solve the @xmath1 control problem stated in problem  [ prb : hinfty ] :    [ thm : hinftyt ] assume that @xmath304 , @xmath324 , @xmath325 , @xmath326 , @xmath319 , and @xmath327 ( @xmath178 and @xmath328 in @xmath128 ) satisfy the linear matrix inequalities @xmath329 for all @xmath178 and @xmath328 in @xmath128 .",
    "define the feedback matrix @xmath117 by .",
    "then , the closed - loop system @xmath135 is mean square stable and satisfies @xmath330 .",
    "assume that the inequalities and are satisfied by the matrices @xmath324 , @xmath325 , @xmath326 , @xmath319 , and @xmath327 .",
    "define @xmath117 by .",
    "then , implies @xmath331 by this inequality and , proposition  [ prop : hinf ] immediately shows that @xmath135 is mean square stable and satisfies @xmath255 , as desired .",
    "the objective of this section is to illustrate theorems  [ thm : h2 ] and [ thm : hinftyt ] by numerical examples .",
    "we will also demonstrate how the periodicity of the feedback gain can be used to improve the performance of the closed - loop system  @xmath135 .    in this example",
    ", we consider the markov jump linear system studied in ( * ? ? ?",
    "* example  1 ) .",
    "the system has two modes and its parameters are given by @xmath332 where @xmath333 and @xmath334 denote the @xmath335 identity matrix and the @xmath6 zero matrix , respectively .",
    "notice that the mode signal  @xmath42 is a sequence of independently and identically distributed random variables .",
    "norm of the closed - loop system @xmath135 versus the expected duration @xmath336,width=389 ]    we assume that the controller observes the mode through a gilbert - elliot channel , described in example  [ ex : gechannel ] . for simplicity in our presentation ,",
    "we let @xmath337 .",
    "notice that , whatever value @xmath79 takes , the limiting distribution of @xmath68 is the uniform distribution on the set @xmath338 ; in other words , the asymptotic frequency of the controller observing the mode signal @xmath42 is @xmath339 .",
    "in addition , the expected duration of the chain @xmath68 staying at either good or bad state depends on @xmath79 , and is equal to @xmath336 .",
    "we assume that the initial distribution @xmath171 of @xmath68 is the uniform distribution .",
    "we can use theorem  [ thm : h2 ] to design stabilizing feedback gains and the initial distribution  @xmath166 in order to achieve a small @xmath0 norm of the closed - loop system  @xmath135 by solving the following optimization problem : @xmath340 figure  [ fig : h2 ] shows the @xmath0  norms of the optimized closed - loop systems .",
    "as expected , the larger the value of the period @xmath14 , the smaller the attained @xmath0 norm .",
    "we can also see that the @xmath0 norm of the closed - loop system increases as the expected duration @xmath336 increases , although the stationary distribution of  @xmath68 does not depend on @xmath79 .",
    "we remark that this feature arising from the markov property of @xmath68 can not be captured by the framework in @xcite , where mode observations at different time instants are assumed to be independent events with identical probabilities .",
    "consider the markov jump linear system @xmath43 with the following parameters : @xmath341 from the standard theory of markov jump linear systems  @xcite , one can check that @xmath43 is not mean square stable when @xmath342 .",
    "we use the observation process with independent and identically distributed failures ( described in example  [ ex : iid ] ) .    , width=389 ]    , width=389 ]    in order to design stabilizing feedback gains achieving a small @xmath1 norm of @xmath135 , we solve the following optimization problem based on theorem  [ thm : hinftyt ] : @xmath343 figure  [ fig : hinf ] shows the @xmath1 norms of the resulting closed - loop systems for various values of period  @xmath14 and failure probability  @xmath344 . as we increase the period @xmath14 , the @xmath1 norm tends to decrease . however , notice that when @xmath344 is around @xmath345 , the @xmath1  norm attained by the controllers with @xmath346 are better than those with @xmath347 .",
    "this phenomenon can happen because @xmath348 is not an integer - multiple of @xmath349 .",
    "remark that , for @xmath350 instead of @xmath347 , such a phenomenon will not happen because the @xmath1  performance obtained by the feedback gains  @xmath351 , \\delta \\in [ 3]}$ ] with period @xmath346 is attained by the feedback gains @xmath352 with period  @xmath350 given as for every @xmath353 .",
    "we also remark that , by the same reason , the performance of the resulting closed - loop system for any integer @xmath14 is never worse than the performance for @xmath354 ( since @xmath121 divides @xmath14 ) .",
    "finally , figure  [ fig : hinfexample ] shows the sample averages of @xmath355 of the closed - loop systems for @xmath354 and @xmath347 . for the computation of the sample averages , we fix @xmath356^\\top$ ] , @xmath357 , @xmath358 , and @xmath359 . the disturbance signal is chosen as @xmath360 .",
    "we generate @xmath361 sample paths of @xmath42 and @xmath68 . using the sample paths ,",
    "we then generate @xmath361 sample paths of @xmath46 for @xmath354 and @xmath347 , respectively .",
    "we can see that the closed - loop system with @xmath347 attenuates the disturbance signal better than that with @xmath354 .",
    "in this paper , we have studied state - feedback control of markov jump linear systems with hidden - markovian observations of the mode signals .",
    "this observation model generalizes various relevant cases previously studied in the literature on markov jump linear systems , such as the cases with perfect information , no information and cluster observations of the mode signal .",
    "we have then developed an optimization framework , based on linear matrix inequalities , to design feedback gains for stabilization , @xmath0 and @xmath1  control problems .",
    "finally , we have illustrated the effectiveness of this optimization framework with several numerical examples .",
    "a.  n. vargas , w.  furloni , and j.  b. do  val , `` second moment constraints and the control problem of markov jump linear systems , '' _ numerical linear algebra with applications _",
    "357368 , 2013 .",
    "a.  p.  c. gonalves , a.  r. fioravanti , and j.  c. geromel , `` @xmath363 robust and networked control of discrete - time mjls through lmis , '' _ journal of the franklin institute _",
    "349 , pp . 21712181 , 2012 .",
    "a.  r. fioravanti , a.  p.  c. gonalves , and j.  c. geromel , `` optimal @xmath364 and @xmath362 mode - independent control for generalized bernoulli jump systems , '' _ journal of dynamic systems , measurement , and control _ , vol .",
    "136 , p. 011004 , 2014 .",
    "a.  n. vargas , e.  f. costa , and j.  b. do  val , `` on the control of markov jump linear systems with no mode observation : application to a dc motor device , '' _ international journal of robust and nonlinear control _ ,",
    "23 , pp . 11361150 , 2013 .",
    "a.  n. vargas , l.  acho , g.  pujol , e.  f. costa , j.  a.  y. ishihara , and j.  b. do  val , `` output feedback of markov jump linear systems with no mode observation : an automotive throttle application , '' _ international journal of robust and nonlinear control _",
    "doi : 10.1002/rnc.3393 .",
    "o.  l.  v. costa , m.  d. fragoso , and m.  g. todorov , `` a detector - based approach for the @xmath0 control of markov jump linear systems with partial information , '' _ ieee transactions on automatic control _ ,",
    "vol .  60 , pp .",
    "12191234 , 2015 ."
  ],
  "abstract_text": [
    "<S> in this paper , we study state - feedback control of markov jump linear systems with partial information . in particular , we assume that the controller can only access the mode signals according to a hidden - markov observation process . </S>",
    "<S> our formulation generalizes various relevant cases previously studied in the literature on markov jump linear systems , such as the cases with perfect information , no information , and cluster observations of the mode signals . in this context , we propose a linear matrix inequalities ( lmi ) formulation to design feedback control laws for ( stochastic ) stabilization , @xmath0 , and @xmath1 control of discrete - time markov jump linear systems under hidden - markovian observations of the mode signals . </S>",
    "<S> we conclude by illustrating our results with some numerical examples . </S>"
  ]
}