{
  "article_text": [
    "recently an optimal hamiltonian for a multistate network has been put forward @xcite , @xcite on the basis of information theory by maximizing the mutual information content of the system .",
    "for a two - state network , this hamiltonian equals the well - known hopfield hamiltonian extensively studied in the literature @xcite , @xcite . for a three - state network one finds a blume - emery - griffiths ( beg ) spin - glass type hamiltonian @xcite . as spin - glasses these models have been studied for some time now .",
    "thermodynamic as well as dynamic properties are discussed in the literature for disorder in both the quadratic and biquadratic interaction .",
    "many references can be found in @xcite . as a neural network model",
    "its study has been started only recently @xcite,@xcite .",
    "but it turns out already that both the maximal capacity and the basin of attraction of this network are enlarged , at least for hebb rule learning , in comparison with the standard three - state networks like , e.g. , the q - ising spin - glass models .",
    "a natural question is then whether these improved retrieval quality aspects are restricted to the use of the hebb rule or whether they are intrinsic properties of the model . in the same context",
    ", a further question is then whether we can extract a perceptron type model with an optimal performance out of this beg recurrent network .",
    "the perceptron is by now a well - known and standard model in theoretical studies and practical applications in connection with learning and generalization @xcite , @xcite , @xcite - @xcite .",
    "consequently , a number of extensions including many - state , graded response and colored perceptrons have been formulated in the literature @xcite-@xcite .",
    "the aim of this work is precisely to introduce such a beg - perceptron model and , in particular , to study its gardner optimal capacity . although the method for doing that is standard and well - know by now @xcite,@xcite its generalization to the problem at hand is highly non - trivial .",
    "nevertheless we have succeeded in obtaining a closed expression for the replica symmetric approximation to the gardner optimal capacity .",
    "the paper is organized as follows . in section 2",
    "we recall the beg hamiltonian and define the beg perceptron model .",
    "section 3 presents a closed analytic formula for the replica - symmetric gardner capacity of this model and studies its behaviour as a function of the imbedding constant and the activity .",
    "comparisons with other three - state perceptrons are made . in section 4 the stability of the replica symetric solution",
    "is studied using an extension of the de almeida - thouless analysis .",
    "the analytic form of the two replicon eigenvalues is obtained .",
    "stability is found to be broken for smaller values of the activity and for very small imbedding stabilities .",
    "section 5 presents some concluding remarks . in the appendices further technical explanations",
    "are given .",
    "consider a neural network consisting of @xmath0 neurons which can take values @xmath1 from the discrete set @xmath2 .",
    "the @xmath3 patterns to be stored in this network are supposed to be a collection of independent and identically distributed random variables ( i.i.d.r.v . ) , @xmath4 , @xmath5 with a probability distribution @xmath6 with @xmath7 the activity of the patterns so that @xmath8 given the network configuration at time @xmath9 , @xmath10 , the following dynamics is considered . the configuration @xmath11 is chosen as input .",
    "the neurons are updated according to the stochastic parallel spin - flip dynamics defined by the transition probabilities @xmath12 }          { \\sum_{s \\in \\mathcal{s } } \\exp [ - \\beta \\epsilon_i                                     ( s|{\\mbox{\\boldmath $ { \\sigma}$}}_n(t))]}\\ , .",
    "\\label{eq : trans}\\ ] ] here the energy potential @xmath13 $ ] is defined by @xmath14 =            -sh_i({{\\mbox{\\boldmath $ { \\sigma}$}}}_n(t))-s^2\\theta_i({{\\mbox{\\boldmath $ { \\sigma}$}}}_n(t ) )                \\ , , \\label{eq : energy}\\ ] ] where the following local fields in neuron @xmath15 carry all the information @xmath16 with the obvious shorthand notation for the local fields . for synaptic couplings @xmath17 and @xmath18 of the hebb - type @xmath19",
    "the corresponding neural network hamiltonian @xmath20 has been discussed recently @xcite .",
    "it has been found that the capacity and basin of attraction has been enlarged in comparison with other three - state networks .",
    "we would like to understand whether these better retrieval quality is an intrinsic property of the model .",
    "therefore , we want to answer the following question : given the set of @xmath3 patterns specified above , is there a network ( the best possible network of the beg - type ) which has these patterns as fixed points of the deterministic form of the dynamics considered above ? at zero temperature the updating rule of this dynamics ( [ eq : trans])-([eq : energy ] ) is equivalent to the gain function @xmath21 with @xmath22 the heaviside function . considering the perceptron architecture ( n inputs with couplings @xmath23 and @xmath24 and 1 output ) we say that a given pattern , @xmath25 , is stored if there exists a corresponding output @xmath26 @xmath27 with @xmath28 and @xmath29 denoting the configurations in the space of interactions .",
    "the factor @xmath30 is introduced to have the weights @xmath23 and @xmath24 of order unity .",
    "the aim is then to determine the maximal number of patterns , @xmath3 , that can be stored in the perceptron , in other words to find the maximal value of the loading @xmath31 for which couplings satisfying ( [ metastablecondition])-([cond2 ] ) can still be found . following a gardner - type analysis @xcite",
    "the fundamental quantity that we want to calculate is then the volume fraction of weight space given by @xmath32 with the characteristic function @xmath33 where @xmath34 is the imbedding stability parameter measuring the size of the basin of attraction for the @xmath35-th pattern and @xmath36 is the following normalization factor assuming spherical constraints for the couplings @xmath37 in order to perform the average over the disorder in the input patterns and the corresponding output we employ the replica technique to evaluate the entropy per site @xmath38 where @xmath39 denotes an average over the statistics of inputs @xmath40 and outputs @xmath41 , recalling ( [ distribution ] ) .",
    "in the replica approach the entropy per site @xmath42 is computed via the expression @xmath43 where @xmath44 is the @xmath45-times replicated fractional volume    @xmath46{\\bigg<\\hspace{-2mm}\\bigg<}\\prod_{\\alpha=1}^n\\prod_{\\mu=1}^p\\chi_{\\xi^\\mu_0 } ( h ^\\alpha_\\mu,\\theta ^\\alpha_\\mu;\\kappa){\\bigg>\\hspace{-2mm}\\bigg>}\\label{fracvol}\\ ] ]    whereby we can forget , since the couplings are continuous , about constant terms such as the denominator in ( [ normalization ] ) .",
    "the calculation then proceeds in a standard way although the technical details are much more complicated . for a short account",
    "we refer to appendix a. here we restrict ourselves to the following important remarks .",
    "the main order parameters appearing in the calculation are @xmath47 of course , in the replica symmetric ( rs ) approximation we are focussing upon here , @xmath48 .",
    "the first two order parameters are the overlaps between two distinct replicas for the couplings @xmath49 and @xmath50 , the third one arises from the fact that the dynamics ( [ eq : gain ] ) and , hence , also the characteristic function ( [ character ] ) , contains a second field @xmath51 , quadratic in the patterns .",
    "we remark that it describes the relative importance of the active versus the non - active neurons .",
    "actually , in the calculation @xmath52 will be the important quantity with @xmath7 the second moment of the pattern distribution , i.e. , the pattern activity .",
    "the rs optimal gardner capacity is obtained when the overlap order parameters @xmath53 and @xmath54 go to @xmath55 .",
    "it is clear that these limits have to be taken simultaneously but , in general , their rate of convergence could be different .",
    "therefore , we introduce @xmath56 where @xmath57 is a new parameter which one also needs to extremize .",
    "we expect this parameter @xmath57 to depend on the pattern distribution through the activity @xmath7 .",
    "pursuing this approach then leads to @xmath58 where @xmath59 reads    @xmath60     { \\bigg>\\hspace{-2mm}\\bigg>}_{\\xi_0 } \\label{grs2}\\ ] ]    with @xmath61 , where @xmath62 $ ] and where the integration region @xmath63 is determined by the heaviside functions appearing in the characteristic function @xmath64 defined in ( [ character ] ) .",
    "the expression ( [ grs2 ] ) for the function @xmath65 suggests that an asymptotic expansion to compute the limit @xmath66 is possible .",
    "indeed , after some tedious algebra ( see appendix b ) we find for this limit    @xmath67    with @xmath68 . the integration regions read @xmath69 and the corresponding integrands are given by @xmath70 with @xmath71 and where we remark that the @xmath72 are minimal distances between a point in the different integration regions @xmath73 and the border of @xmath63(see appendix b ) .",
    "this may allow for a possible geometrical interpretation of the gardner optimal capacity in the space of local fields as it has been suggested for the @xmath74-state clock model in @xcite .",
    "after inserting - in and extremizing numerically with respect to @xmath75 and @xmath57 , we find the results presented in figures [ figure1]-[figure2 ] . in fig .",
    "1 the capacity @xmath76 versus the activity @xmath7 is shown for several values of the imbedding stability constant @xmath34 . for bigger @xmath34 , the capacity becomes , of course , smaller . for @xmath77 ,",
    "i.e. , binary patterns , we find back the original gardner results , as we do in fig .",
    "2 showing @xmath76 as a function of @xmath34 for several values of @xmath7 .     as a function of the pattern activity @xmath7 for several values of the stability constant @xmath34 .",
    "the dots at @xmath77 refer to the optimal capacity of the two - state perceptron.,title=\"fig:\",scaledwidth=38.0% ] +    smaller activity indicating a growing presence of zero - state neurons leads to bigger capacities . of course",
    ", this does not mean a priori that also the information content of the system is increased . for completeness , we remark that the parameters @xmath78 and @xmath57 that we have extremized over , depend rather strongly but smoothly on the pattern activity .",
    "for @xmath77 we find back the two - state perceptron value for @xmath75 , i.e. @xmath79 , and @xmath80 .     as a function of the stability @xmath34 for several values of the pattern activity @xmath7 .",
    "the straight - dotted line corresponds to the optimal capacity of the two - state perpectron.,title=\"fig:\",scaledwidth=38.0% ] +    finally , in order to have an idea about the information stored into the network we plot in fig .",
    "[ figure3 ] the information content per neuron @xmath81.\\ ] ] for @xmath77 our result is again consistent with the simple perceptron result @xcite .",
    ", as a function of @xmath7 for @xmath82 ( from top to bottom),title=\"fig:\",scaledwidth=38.0% ] +    comparing with other three - state neuron perceptron models we recall that for @xmath83 and uniform patterns the @xmath84 ising perceptron can maximally reach an optimal capacity equal to @xmath85 , depending on the separation between the plateaus of the gain function ( see @xcite , @xcite ) for the precise details ) and the @xmath84 clock and potts model both reach an optimal capacity of @xmath86 @xcite,@xcite while the value for the beg perceptron found here is @xmath87 . here",
    "we have to recall that the @xmath84 ising perceptron and the beg perceptron have the same topology structure in the neurons , whereas the @xmath84 clock and potts models have a different topology .",
    "from the work of gardner @xcite we know that for the binary neuron perceptron the rs solution is marginally stable against rs breaking ( rsb ) fluctuations . from the work on multi - state q - ising neurons @xcite we know that the rs solution may be stable or unstable depending on the gain parameter , the number of spin states and the distribution of the patterns .",
    "furthermore , in general , increasing the imbedding stability parameter @xmath34 lowers the capacity and enhances the stability against rsb . using these results for the @xmath84 spin states as a guide we also expect breaking for the beg perceptron model at hand . to confirm this and find out the precise interval of @xmath7 values where breaking occurs",
    ", we generalize the de almeida - thouless analysis @xcite , @xcite .",
    "first , the hessian matrix associated with the function @xmath88 , eq . , is computed , and then the eigenvalues are determined . as usual ,",
    "two types of eigenvalues are found : longitudinal eigenvalues describing fluctuations within rs and transverse eigenvalues describing stability against rsb .",
    "we find _ four _ transversal eigenvalues each with degeneracy @xmath89 . in the limit",
    "@xmath90 they can be calculated explicitly in terms of the minimal distances occuring in ( [ mindis1])-([mindis3prim ] ) .",
    "the result reads ( for more details we refer to appendix c )    @xmath91 ^ 2}\\big\\}\\\\ & & \\hspace*{-0.5cm}\\tau_-=\\frac{1}{2(\\delta_{c}^2          -\\delta_{q}\\delta_{r})}\\big\\{\\delta_{q }          + \\delta_{r}+(\\delta_{\\widehat{q}}+\\delta_{\\widehat{r}})(\\delta_{c}^2          -\\delta_{q}\\delta_{r})-\\sqrt{4\\delta_{c}^2          + \\big[\\delta_{q}-\\delta_{r}+(\\delta_{\\widehat{q } }          -\\delta_{\\widehat{r}})(\\delta_{q}\\delta_{r}-\\delta_{c}^2)\\big]^2}\\big\\ } \\label{tmin}\\end{aligned}\\ ] ]    with the @xmath92 s given by    @xmath93    then _ two _ replicon eigenvalues , @xmath94 and @xmath95 , can be defined as @xmath96 stability of the rs solution requires that both @xmath97 . in fig .",
    "[ figure4]-[figure6 ] we present the numerical results concerning the stability analysis . in fig .",
    "[ figure4 ] the first replicon eigenvalue @xmath94 is shown as a function of @xmath7 for several values of @xmath34 .",
    "it is seen that for small values of @xmath34 this eigenvalue becomes positive for smaller values of @xmath7 and hence replica symmetry is broken .",
    "we remark that for @xmath77 our results are consistent with those of gardner @xcite .     as a function of @xmath7 for several values of @xmath34 .",
    "the dots at @xmath77 refer to the optimal capacity of the two - state perceptron.,scaledwidth=38.0% ]    fig .",
    "[ figure5 ] presents a closer view of this for @xmath83 . for @xmath98",
    "the rs solution is unstable .",
    "storing only zero - state spins , @xmath99 , or binary spins @xmath77 leads to marginal stability . as a first explanation one could remark that for increasing @xmath7 , allowing more @xmath100 states , the disorder is increased up to about a uniform distribution of patterns , @xmath101 .",
    "it is clear that for bigger @xmath34 , the stability against rsb increases .",
    "in fact for @xmath102 already no more breaking occurs .     as a function of @xmath7 for @xmath83 on a different scale .",
    "rsb occurs for smaller values of @xmath7.,scaledwidth=38.0% ]    finally , fig .",
    "6 shows that @xmath95 is always negative and , hence , plays no role in the breaking of the rs stability .",
    "as a function of @xmath7 for several values of @xmath34.,scaledwidth=38.0% ]",
    "in this work we have introduced a perceptron model based upon the recently studied blume - emery - griffiths neural network , containing ternary neurons .",
    "we have obtained an analytic formula for the replica symmetric optimal gardner capacity . for the imbedding stability constant equal to zero and uniform patterns ,",
    "e.g. , we find a bigger optimal capacity , @xmath103 , than the one for the @xmath84 ising perceptron , @xmath104 , which has the same topology structure for the neurons . since , in general , perceptrons turn out to be very useful models in connection with learning and generalization this is an interesting observation .",
    "it is also consistent with earlier results derived for the hebb rule .",
    "we have studied the stability of the replica - symmetric solution by generalizing the de almeida - thouless analysis and deriving an analytic expression for the _ two _ replicon eigenvalues that play a role in the gardner limit .",
    "breaking only occurs for small activities and very small imbedding constants , @xmath105 .",
    "this is consistent with the stability results found for the @xmath84 ising perceptrons .",
    "these results strenghten the idea that the better retrieval properties found for the blume - emery - griffiths model in comparison with the @xmath84 ising model are not restricted to the specific hebb rule but are intrinsic to the model .",
    "we would like to thank dr .",
    "p. kozlowski and t. verbeiren for critical discussions .",
    "one of us ( ipc ) especially thanks j. van mourik and j. gheerardyn for useful remarks .",
    "this work has been supported in part by the fund of scientific research , flanders - belgium .",
    "in this appendix we outline the main steps in the calculation of the n - times replicated volume ( [ fracvol ] ) extending @xcite to the case at hand . in order to perform the quenched average we use the @xmath106-function representation    @xmath107\\\\ 1=\\int_{-\\infty}^\\infty \\frac{d \\theta^\\alpha_\\mu d\\widehat{\\theta}^\\alpha_\\mu}{2\\pi}\\exp\\big[i\\widehat{\\theta}^\\alpha_\\mu\\big(\\theta^\\alpha_\\mu-\\frac{1}{\\sqrt{n}}\\sum_{j=1}^n k^\\alpha_j({\\mbox{\\boldmath $ { \\xi}$}}_j^\\mu)^2\\big)\\big]\\end{aligned}\\ ] ]    to take the local fields out of the characteristic function and obtain @xmath108 \\exp\\big[i\\sum_{\\alpha=1}^n\\sum_{\\mu=1}^p\\big(\\widehat{h}^\\alpha_\\mu h^\\alpha_\\mu+\\widehat{\\theta}^\\alpha_\\mu\\theta^\\alpha_\\mu\\big)\\big]\\nonumber\\\\ { \\bigg<\\hspace{-2mm}\\bigg<}\\prod_{\\alpha=1}^n\\prod_{\\mu=1}^p\\exp\\big[-\\frac{i\\widehat{h}^\\alpha_\\mu}{\\sqrt{n}}\\sum_{j=1}^n j_j^\\alpha\\xi^\\mu_j-\\frac{i\\widehat{\\theta}^\\alpha_\\mu}{\\sqrt{n}}\\sum_{j=1}^n   k^\\alpha_j(\\xi^\\mu_j)^2\\big]{\\bigg>\\hspace{-2mm}\\bigg>}_{\\xi_i^\\mu}{\\bigg<\\hspace{-2mm}\\bigg<}\\prod_{\\alpha=1}^n\\prod_{\\mu=1}^p\\chi_{\\xi^\\mu_0 } ( h ^\\alpha_\\mu,\\theta ^\\alpha_\\mu;\\kappa){\\bigg>\\hspace{-2mm}\\bigg>}_{\\xi_o^\\mu } \\ , .\\end{aligned}\\ ] ] introducing the order parameters ( [ orderpar])and their conjugate variables , and using the identities @xmath109\\\\ 1=\\int_{-\\infty}^\\infty \\prod_{\\alpha<\\beta}\\frac{d r_{\\alpha\\beta}d\\widehat{r}_{\\alpha\\beta}}{2\\pi i / n}\\exp\\big[\\widehat{r}_{\\alpha\\beta}\\big(nr_{\\alpha\\beta}- { \\bf k}^{\\alpha}\\cdot { \\bf k}^{\\beta}\\big)\\big]\\\\ 1=\\int_{-\\infty}^\\infty\\prod_{\\alpha=1}^n\\frac{d l^{\\alpha}d\\widehat{l}^{\\alpha}}{2\\pi /\\sqrt{n } } \\exp\\big[i\\widehat{l}^{\\alpha}\\big(\\sqrt{n}l^{\\alpha}-\\sum_{j=1}^n k^{\\alpha}_{j}\\big)\\big]\\end{aligned}\\ ] ] allows us to express the replicated fractional volume as an integral over them , viz .",
    "@xmath110\\big[\\prod_{\\alpha=1}^n \\frac{d\\widehat{e}^\\alpha}{4\\pi i}\\frac{d\\widehat{f}^\\alpha}{4\\pi i}\\big]\\big[\\prod_{\\alpha<\\beta}\\frac{d q_{\\alpha\\beta}d\\widehat{q}_{\\alpha\\beta}}{2\\pi",
    "i / n}\\frac{d r_{\\alpha\\beta}d\\widehat{r}_{\\alpha\\beta}}{2\\pi i / n}\\big]\\exp\\big[n\\phi\\big ]   \\label{volume2}\\ ] ] with @xmath88 given by @xmath111 where @xmath112\\exp\\big[i\\sum_{\\alpha=1}^n(\\widehat{h}^\\alpha h^\\alpha+\\widehat{\\theta}^\\alpha\\theta^\\alpha ) -ia\\sum_{\\alpha=1}^n\\widehat{\\theta}^\\alpha l^\\alpha -\\frac{a}{2 } \\sum_{\\alpha,\\beta=1}^n\\widehat{h}^\\alpha\\widehat{h}^\\beta q_{\\alpha\\beta}\\nonumber\\\\ & & -\\frac{a(1-a)}{2 } \\sum_{\\alpha,\\beta=1}^n\\widehat{\\theta}^\\alpha\\widehat{\\theta}^\\beta r_{\\alpha\\beta}\\big]{\\bigg<\\hspace{-2mm}\\bigg<}\\prod_{\\alpha=1}^n\\chi_{\\xi } ( h ^\\alpha,\\theta ^\\alpha;\\kappa){\\bigg>\\hspace{-2mm}\\bigg>}_{\\xi_o}\\\\ g_2=&&\\ln\\int_{-\\infty}^\\infty \\big[\\prod_{\\alpha=1}^n d j^\\alpha d k^\\alpha\\big]\\exp\\big[-\\frac{1}{2}\\sum_{\\alpha,\\beta=1}^n\\big(\\widehat{q}_{\\alpha\\beta}j^{\\alpha}j^{\\beta}+\\widehat{r}_{\\alpha\\beta } k^{\\alpha}k^{\\beta}\\big)-i\\sum_{\\alpha=1}^n\\widehat{l}^{\\alpha } k^{\\alpha}\\big]\\\\ g_3=&&\\frac{1}{2}\\sum_{\\alpha,\\beta=1}^n\\big(\\widehat{q}_{\\alpha\\beta}q_{\\alpha\\beta}+\\widehat{r}_{\\alpha\\beta}r_{\\alpha\\beta}\\big)\\end{aligned}\\ ] ]    and @xmath113 we remark that the @xmath106-function representation of the local fields has allowed us to perform the calculations until this point without using an explicit form for the characteristic function @xmath114 . using the rs ansatz @xmath88 can be simplified further and the saddle - point equations for @xmath115 become algebraic so that they can be solved explicitly , leading to the result ( [ capacity_rs2])-([grs2 ] ) .",
    "in order to compute the asymptotic expansion of ( [ grs2 ] ) we proceed as follows .",
    "we split the integral over @xmath116 into two parts , i.e. , @xmath63 determined by the heaviside function in @xmath117 , and its complement @xmath118 .",
    "the first integral gives zero contribution in the limit @xmath119 , while the second one gives a contribution of order @xmath120 .",
    "indeed , the integration over @xmath121 parametrized by @xmath53 is nothing but an exponential dirac - delta representation . whenever the peak of this delta representation lies in the region @xmath63 , which means that @xmath122 the integral results in a finite contribution .",
    "the contributions of order @xmath120 arises from the points @xmath123 .",
    "therefore , we can write @xmath124_\\xi(h_0,\\theta_0){\\bigg>\\hspace{-2mm}\\bigg>}_\\xi\\ ] ] where we have introduced the shorthand notation @xmath125_\\xi(h_0,\\theta_0)&&=\\int_{\\omega_\\xi}\\frac{dh}{\\sqrt{2\\pi(1-q ) } } \\frac{d\\theta}{\\sqrt{2\\pi(1-q)}}\\nonumber\\\\     & & \\times \\exp\\big[-\\frac{(h - h_0)^2+(\\theta-\\theta_0)^2}{2(1-q)}\\big ]           \\ , .     \\label{func1}\\end{aligned}\\ ] ] next , for a given @xmath123 the main contribution arising from the function @xmath126_\\xi(h_0,\\theta_0)$ ] is obtained for those points @xmath127 which minimize the distance @xmath128 . to calculate this minimal distance ,",
    "we split up @xmath118 into three subregions according to fig .",
    "[ figure7 ] in the case of @xmath129 @xmath130     , scaledwidth=38.0% ]    computing the minimal distances for such subregions is straightforward and leads to @xmath131 by redefining @xmath132 and @xmath133 we recover the expressions ( [ mindis1])-([mindis3 ] ) .",
    "+ we proceed analogously for the region @xmath134 .",
    "we split this region into three subregions as shown in fig .",
    "[ figure8 ]     for @xmath135 , scaledwidth=38.0% ]    @xmath136    the minimal distances are given by @xmath137}\\\\ & &   d^{{\\cal r}'_2}_{min}=h^2_{0}+\\big(\\frac{\\kappa}{\\sqrt{\\gamma a(1-a)}}+\\theta_{0}\\big)^2\\\\ & &   d^{{\\cal r}'_3}_{min}=\\frac{\\big(\\sqrt{\\gamma a(1-a)}\\theta_{0}+\\kappa-\\sqrt{a}h_{0}\\big)^2}{a[1+\\gamma(1-a)]}\\end{aligned}\\ ] ] and redefining @xmath138 we find ( [ mindis1prim])-([mindis3prim ] ) .",
    "starting from the stability matrix formed by the second derivatives of @xmath88 ( recall eq.([phifunction ] ) ) with respect to the order parameters and the conjugated variables , we find that only transverse fluctuations are relevant .",
    "@xmath142_\\xi(h_0,\\theta_0)\\big\\}^2{\\bigg>\\hspace{-2mm}\\bigg>}_{\\xi_o}\\\\ & & \\delta_r=    \\frac{\\alpha}{r^2}\\int{\\cal d}(h_0){\\cal d}(\\sqrt{\\gamma}\\theta_0-t ) { \\bigg<\\hspace{-2mm}\\bigg<}\\big\\{\\frac{1}{\\gamma}\\frac{\\partial^2}{\\partial \\theta_0 ^ 2}\\ln[1]_\\xi(h_0,\\theta_0)\\big\\}^2{\\bigg>\\hspace{-2mm}\\bigg>}_{\\xi_o}\\\\ & & \\delta_c=   \\frac{\\alpha}{qr}\\int{\\cal d}(h_0){\\cal",
    "d}(\\sqrt{\\gamma}\\theta_0-t ) { \\bigg<\\hspace{-2mm}\\bigg<}\\big\\{\\frac{1}{\\sqrt{\\gamma}}\\frac{\\partial^2}{\\partial h_0\\partial \\theta_0}\\ln[1]_\\xi ( h_0,\\theta_0)\\big\\}^2{\\bigg>\\hspace{-2mm}\\bigg>}_{\\xi_o}\\\\ & & \\delta_{\\widehat{q}}=(1-q)^2\\\\ & & \\delta_{\\widehat{r}}=(1-r)^2=\\gamma^2(1-q)^2 \\label{deltas}\\end{aligned}\\ ] ]      next , the limit @xmath143 has to be taken . using the asymptotic expansion of @xmath126_\\xi(h_0,\\theta_0)$ ] discussed in appendix",
    "b we can compute the asymptotic behavior of the coefficients @xmath144 , @xmath145 and @xmath146 . after a lot of algebra we finally arrive at the expressions ( [ delq])-([delr ] ) with the integration regions and minimal distances given by ( [ region1])-([mindis3prim ] ) . in this limit",
    ", it turns out that an analytical expression can be found for the eigenvalues .",
    "first , we notice that the determinant of the matrix remains finite in the limit .",
    "since the determinant is the product of the eigenvalues , it follows that this product is finite .",
    "two possibilities arise , either all eigenvalues are finite , or two of them tend to zero and two to infinity with the same ratio .",
    "it is not hard to prove that the first choice is incorrect .",
    "hence , two of the eigenvalues have to behave asympotically as @xmath147 .",
    "one can check that only @xmath148 is possible .",
    "this allows us to split @xmath140 into two polynomials which give the solutions around zero and around infinity .",
    "these polynomials read @xmath149[\\delta_{r}(\\delta_{\\widehat{r}}-\\lambda)-1 ] \\nonumber\\\\ -\\delta_{c}^2(\\delta_{\\widehat{q}}-\\lambda)(\\delta_{\\widehat{r}}-\\lambda ) \\nonumber\\\\ p_\\infty(\\lambda)=(\\delta_{q}-\\lambda)(\\delta_{r}-\\lambda)-\\delta_{c}^2 \\ , .\\end{aligned}\\ ] ] from these two polynomials the four eigenvalues ( [ lplus])-([tmin ] ) can be found .",
    "we remark that in the limit @xmath150 we find back the stability criteria for the original gardner capacity problem .",
    "99 d. r. dominguez carreta and e. korutcheva , phys .",
    "e * 62 * , 2620 ( 2000 ) .",
    "d. boll and t. verbeiren , phys .",
    "a * 297 * , 156 ( 2002 ) .",
    "j. hertz , a. krogh and r. g. palmer , _ introduction to the theory of neural computation _",
    "( addison - wesley , redwood city 1991 ) .",
    "b. mller , j. reinhardt and m. t. strickland , _ neural networks : an introduction _",
    "( springer , berlin 1995 ) . m. blume , v.j .",
    "emery and r.b .",
    "griffiths , phys . rev . a , * 4 * , 1071 ( 1971 ) ; m. blume , phys",
    ", * 141 * , 517 ( 1966 ) ; h.w .",
    "capel , physica * 32 * , 966 ( 1966 ) .",
    "j. m. de arajo , f. a. da costa and f. d. nobre , eur .",
    "j. b * 14 * , 661 ( 2000 ) .",
    "m. opper and w. kinzel , _ models of neural networks iii _ ed .",
    "e. domany , j. l. van hemmen and k. schulten , 151 ( springer , new - york 1996 ) .",
    "d. saad , ed._on - line learning in neural networks _",
    "( cambridge university press 1998 ) .",
    "a. engel and c. van den broeck , _ statistical mechanics of learning _",
    "( cambridge university press 2001 ) d. boll , j. busquets blanco and g. m. shim , cond - mat/0206569 , to appear in physica a. j. p. nadal and a. rau , j. phys .",
    "i france * 1 * , 1109 ( 1991 ) .",
    "f. gerl and u. krey , j. phys .",
    "a * 27 * , 7353 ( 1994 ) .",
    "d. a. khring , j. phys .",
    "france * 51 * , 145 ( 1990 ) .",
    "s. mertens , h. m. khler and s. bs , j. phys .",
    "a * 24 * , 4941 ( 1991 ) .",
    "d. boll , p. dupont and j. van mourik , europhys .",
    "lett . * 15 * , 893 ( 1991 ) .",
    "d. boll , r. khn and j. van mourik , j. phys .",
    "a * 26 * , 3149 ( 1993 ) .",
    "d. boll and r.erichsen , jr , phys .",
    "e * 59 * , 3386 ( 1999 ) d. boll and p.kozlowski , phys .",
    "e * 64 * , 011915 ( 2001 ) .",
    "e. gardner , europhys .",
    "lett . * 4 * , 481 ( 1987 ) ; j. phys .",
    "a , * 21 * , 257 ( 1988 ) .",
    "e. gardner and b. derrida , j. phys . a , * 21 * , 271 ( 1988 ) .",
    "f. gerl , k. bauer and u. krey , z. phys .",
    "b * 88 * , 339 ( 1992 ) .",
    "j.r . de almeida and d. thouless , j. phys .",
    "a , * 11 * , 983 ( 1978 ) m. mzard , g. parisi and m.a .",
    "virasoro , _ spin glass theory and beyond _ ( singapore , world scientific , 1987 ) d. boll and j. van mourik , j. phys . a * 27 * , 1151 ( 1994 ) ."
  ],
  "abstract_text": [
    "<S> a blume - emery - griffiths perceptron model is introduced and its optimal capacity is calculated within the replica - symmetric gardner approach , as a function of the pattern activity and the imbedding stability parameter . the stability of the replica - symmetric approximation is studied via the analogue of the almeida - thouless line . </S>",
    "<S> a comparison is made with other three - state perceptrons . </S>"
  ]
}