{
  "article_text": [
    "a wide range of statistical applications requires nonparametric estimation of a regression function when some of the covariates are not directly observed , but have themselves only been estimated in a  ( possibly nonparametric ) preliminary step .",
    "examples include triangular simultaneous equation models [ e.g. , @xcite , @xcite , @xcite ] , sample selection models [ @xcite ] , treatment effect models [ @xcite , @xcite ] , censored regression models [ @xcite ] , generalized roy models [ @xcite ] , stochastic volatility models [ @xcite ] and garch - in - mean models [ @xcite ] , amongst many others . in contrast to fully parametric settings [ @xcite ] , there seems to be no general theoretical results on how to derive the statistical properties of such nonparametric two - step estimators . instead",
    ", most available results in the literature typically exploit peculiarities of a specific model , and can thus not easily be transferred to other applications .    in this paper , we study the statistical properties of a nonparametric estimator @xmath0 of a conditional mean function @xmath1 when the function @xmath2 is unknown , but can be estimated from data . while we are specific about estimating @xmath3 by local linear regression [ @xcite ] to simplify technical arguments , we neither require the generated regressors @xmath4 to emerge from a specific type of model , nor do we require a specific procedure to estimate them .",
    "we only impose high - level conditions on the accuracy and complexity of the first step estimate .",
    "in particular , our main result holds irrespectively of whether the function @xmath2 is , for example , a density , a conditional mean function or a quantile regression function , or whether it is estimated by kernel methods , orthogonal series or sieves .",
    "moreover , our results are not confined to nonparametrically generated covariates , but also apply in settings where @xmath2 is estimated using parametric or semiparametric restrictions .",
    "our main result uses techniques from empirical process theory to show that the presence of generated covariates affects the first - order asymptotic properties of @xmath5 only through a _ smoothed _",
    "version of the estimation error @xmath6 .",
    "this additional smoothing typically improves the rate of convergence of the estimator s stochastic part , reducing the `` curse of dimensionality '' from estimating @xmath2 to a secondary concern in this context .",
    "it does not , however , affect the order of magnitude of the deterministic component .",
    "still , the estimator @xmath5 can have a faster overall rate of convergence than the first step estimator @xmath7 if the latter has a sufficiently small bias .",
    "we extensively illustrate the implications of our main result for the important special case that @xmath2 is the conditional mean function in an auxiliary nonparametric regression . for this setting",
    ", we derive simple and explicit stochastic expansions that can not only be used to establish asymptotic normality or the rate of consistency of the estimated regression function itself , but also study the properties of more complex estimators , in which estimation of a regression function merely constitutes an intermediate step , such as structured nonparametric models imposing additive separability [ @xcite ] .",
    "our results thus cover a wide range of models , and should therefore be of general interest .",
    "we use our techniques to study two such examples in greater detail : nonparametric estimation of a simultaneous equation model and nonparametric estimation of a censored regression model .    to the best of our knowledge , there are only few papers on nonparametric regression with estimated covariates not tailored to a specific application .",
    "@xcite derives some results for generated covariates converging at a parametric rate .",
    "@xcite uses restrictive assumptions which lead to asymptotic results that are different from the ones obtained in the present paper .",
    "@xcite considers series estimation of the functional @xmath8 indexed by @xmath9 and @xmath10 , where @xmath11 is a function space with finite integral bracketing entropy , and derives a rate of consistency uniformly over @xmath12 ; see also @xcite for a  related problem .",
    "our paper is also related to a recent literature on semiparametric estimation problems with generated covariates .",
    "@xcite consider a partial linear model with generated covariates .",
    "@xcite use pathwise derivatives to derive the influence function of semiparametric linear gmm - type estimators .",
    "@xcite provide stochastic expansions for sample means of weighted semiparametric regression residuals with potentially generated regressors , and study their application to certain index models . compared to the nonparametric problems studied in this paper , semiparametric applications typically exhibit several additional technical issues .",
    "in particular , different techniques are needed to control the magnitude of certain remainder terms .",
    "addressing these issues would require substantial refinements our results , which are not needed for the class of nonparametric problems we are focusing on . to keep the present paper more readable ,",
    "we study semiparametric estimators with generated covariates separately in @xcite .",
    "the outline of this paper is as follows . in the next section ,",
    "we describe our setup in detail .",
    "section [ sec3 ] gives some motivating examples .",
    "section [ sec4 ] establishes the asymptotic theory and states the main results . in section  [ sec5 ]",
    ", we apply our results to some of the examples given in section [ sec3 ] , thus illustrating their application in practice . finally , section [ sec6 ] concludes .",
    "all proofs are collected in the .",
    "the nonparametric regression model with generated regressors can be written as @xmath13 is a @xmath14-dimensional vector of covariates , @xmath15 and @xmath16 are unknown functions and @xmath17 is an error term that has mean zero conditional on the true value of covariates to covariates  @xmath18 .",
    "is a sufficient statistic for the covariates @xmath19 , which would imply that @xmath20 .",
    "] we assume that there is additional information available outside of the basic model  ( [ model1 ] ) such that the function  @xmath2 is identified .",
    "for example ,  @xmath2 could be ( some known transformation of ) the mean function in an auxiliary nonparametric regression , which might involve another random vector , say  @xmath21 , in addition to  @xmath22 and @xmath19 .",
    "our aim is to estimate the function @xmath23 . since @xmath2 is unobserved ,",
    "obtaining a direct estimator based on a nonparametric regression of @xmath22 on @xmath24 is clearly not feasible .",
    "we therefore consider the following two - stage procedure . in the first stage ,",
    "an estimate @xmath7 of @xmath2 is obtained .",
    "we do not require a specific estimator for this step .",
    "instead , we only impose the high - level restrictions that the estimator @xmath7 is uniformly consistent , converging at a rate specified below , and takes on values in a function class that is not too complex .",
    "depending on the nature of the function @xmath2 , these kind of regularity conditions are typically satisfied by various common nonparametric estimators , such as kernel - based procedures or series estimators , under suitable smoothness restrictions . in the second step , we then obtain our estimate @xmath0 of @xmath3 through a nonparametric regression of @xmath22 on the generated covariates @xmath4 , using local linear smoothing .",
    "that is , our estimator is given by @xmath25 obtained from @xmath26 where @xmath27 is a @xmath28-dimensional product kernel with univariate kernel function @xmath29 , and @xmath30 is a vector of bandwidths that tend to zero as the sample size @xmath31 increases to infinity .    for the later asymptotic analysis , it will also be useful to compare @xmath0 to an infeasible estimator @xmath32 that uses the true function @xmath2 instead of an estimate @xmath7 .",
    "such an estimator can be obtained by local linear smoothing of  @xmath22 versus @xmath33 , that is , it is given by @xmath34 , where @xmath35 in order to distinguish these two estimators , we refer to @xmath36 in the following as the _ real _ estimator , and to @xmath32 as the _ oracle _ estimator .",
    "our use of local linear estimators in this paper is based on the following considerations .",
    "first , in a classical setting with fully observed covariates , estimators based on local linear regression are known to have attractive properties with regard to boundary bias and design adaptivity [ see @xcite for an extensive discussion ] , and they allow a complete asymptotic description of their distributional properties . in the present setting with generated covariates ,",
    "these properties simplify the asymptotic treatment .",
    "the design adaptivity leads to a discussion of bias terms that does not require regular densities for the randomly perturbed covariates , and the complete asymptotic theory allows a clear description of how the final estimator is affected by the estimation of the covariates . on the other hand ,",
    "our assumptions on the estimation of the covariates are rather general and can be verified for a broad class of smoothing methods , including sieves and orthogonal series estimators .",
    "there are many statistical applications which involve nonparametric estimation of a regression function using nonparametrically generated covariates . in this section ,",
    "we give an overview of some of the most popular examples and explain how they fit into our framework . in section [ sec4 ] , we revisit the first three of these examples , studying their asymptotic properties in detail .",
    "a thorough treatment of the remaining examples involves several additional technical issues beyond dealing with the presence of estimated covariates , such as boundary problems , and is thus omitted for brevity .",
    "see also @xcite for an extensive discussion of semiparametric problems with generated covariates .      in many applications ,",
    "the unknown function @xmath2 is a conditional expectation function from an auxiliary nonparametric regression . as a first motivating example",
    ", we therefore consider a `` two - stage '' nonparametric regression model given by @xmath37 where @xmath38 is an unobserved error term that satisfies @xmath39 = e[\\varepsilon| r_0(s ) ] = 0 $ ] . as",
    "the structure of this example is particularly simple , it is used extensively in section  [ sec4 ] below to illustrate the application of our main result . proceeding like",
    "this is instructive , as the types of technical difficulties encountered in this example are representative for those in a wide range of other statistical applications .",
    "consider a nonparametric regression model with fixed censoring , that is , @xmath40 where @xmath41 is an unobserved mean zero error term that is assumed to be independent of the covariates @xmath42 .",
    "fixed censoring is a common phenomenon in many applications , for example , the analysis of wage data .",
    "note that the censoring threshold could be different from zero , as long as it is known .",
    "@xcite establish identification of the function @xmath43 under the tail condition @xmath44 on the distribution function @xmath45 of  @xmath41 . in particular",
    ", they show that the function @xmath43 can be written as @xmath46 where @xmath47 , @xmath48 , and @xmath49 is some suitably chosen constant .",
    "an estimate of the function @xmath43 can then be obtained from a sample analog of ( [ censest ] ) , that is , through numerical integration of a nonparametric estimate of the function @xmath50 .",
    "nonparametric estimation of @xmath51 involves nonparametrically generated regressors , and thus fits into our framework with @xmath52 and @xmath53 .",
    "covariates that are correlated with disturbance terms appear in many economic models and are denoted as endogenous .",
    "when , for example , analyzing the relationship between wages and schooling , unobserved individual characteristics like ability or motivation might affect both the outcome and the explanatory variable .",
    "a common approach is to model these quantities jointly , achieving identification by using so - called instrumental variables , that are independent of unobservables , affect the endogenous variable , but exert no direct influence on the outcome .",
    "consider , for example , the nonparametric triangular simultaneous equation model discussed in @xcite , which is of the form @xmath54 here the interest is in estimating the function @xmath55 . to achieve identification",
    ", one imposes the restrictions @xmath56 , @xmath57 and @xmath58 , which follow , for example , if the vector of exogenous covariates and instruments @xmath59 is jointly independent of the disturbances @xmath60 .",
    "now let @xmath61 . under the above assumptions , it is straightforward to show that @xmath62 where @xmath63 .",
    "the first component of this additive model could , for example , be estimated by marginal integration [ @xcite , @xcite ] , which relies on the fact that @xmath64 where @xmath65 is the probability density function of @xmath66 .",
    "implementing a sample version of ( [ eqmi ] ) requires estimating the function @xmath67 .",
    "since the residuals @xmath66 are not directly observed but must be estimated by some nonparametric method , this fits into our framework with @xmath68 and @xmath69 .",
    "an alternative to marginal integration would be an approach based on smooth backfitting [ @xcite ] .",
    "smooth backfitting estimators avoid several problems encountered by marginal integration in case of covariates with moderate or high dimension , but involves a more involved statistical analysis which is beyond the scope of the present paper .",
    "we are going to study smooth backfitting with nonparametrically generated covariates in a separate paper .",
    "dhautfoeuille and maurel ( @xcite ) consider a generalized roy model of occupational choice that is related to the previous example in the sense that it also leads to an additive regression model .",
    "let @xmath70 denote the individual s potential earnings in sector @xmath71 of an economy , @xmath72 a vector of covariates , and assume that @xmath73 , where @xmath74 are sector - specific productivity terms known by the agent but unobserved by the analyst .",
    "expected utility from working in sector @xmath75 is assumed to be @xmath76 , the sum of sector - specific expected earnings and a nonpecuniary component that depends on  @xmath42 . along with @xmath42",
    ", the analyst observes the chosen sector @xmath77 , which satisfies @xmath78 and the realized earnings @xmath79 .",
    "one object of interest in this context is the pair of functions @xmath80 . under some weak additional conditions ,",
    "@xcite show that @xmath81 for @xmath82 , which is again an additive model involving unobserved covariates , namely the conditional probabilities @xmath83 of choosing sector  @xmath28 .",
    "this setting fits into our framework in the same way as the previous example .",
    "imbens and newey ( @xcite ) consider a generalized version of the above - mentioned triangular simultaneous equation model with nonadditive disturbances : @xmath84 nonseparable models have become popular in the recent econometric literature , as they allow for substantially more general forms of unobserved heterogeneity than specifications in which the disturbance terms enter additively .",
    "the focus here is typically on averages of the function @xmath55 , such as the average structural function , @xmath85 to achieve identification , assume that the function @xmath86 is strictly monotone in its last argument , that @xmath66 is continuously distributed , and that the unobserved disturbances @xmath60 are jointly independent of @xmath87 .",
    "then it can be shown that @xmath41 and @xmath88 are independently conditional on the so - called control variable @xmath89 , where @xmath90 denotes the distribution function of @xmath91 given @xmath87 . under an additional support condition",
    ", this result implies that the asf is identified through the relationship @xmath92 where @xmath93 .",
    "since the control variable @xmath94 is unobserved and has to be estimated in order to implement a  sample analog estimator of ( [ asf ] ) , this setting also fits into the framework of this paper .",
    "in particular , nonparametric estimation of @xmath67 is covered with @xmath95 and @xmath96 .",
    "it is straightforward to show that @xmath5 consistently estimates the function @xmath3 under standard conditions . obtaining refined asymptotic properties",
    ", however , requires more involved arguments . in this section",
    ", we derive a stochastic expansion of the difference between the real and the oracle estimator , in which the leading terms are kernel - weighted averages of the first stage estimation error .",
    "this is our main result .",
    "it can be used , for example , to obtain uniform rates of consistency for the real estimator , or to prove its asymptotic normality .",
    "we demonstrate this in the next section for specific forms of @xmath2 and  @xmath7 .    throughout this section ,",
    "we use the notation that for any vector @xmath97 the value @xmath98 denotes the smallest of its elements , @xmath99 denotes the sum of its elements , @xmath100 denotes the @xmath101-dimensional subvector of @xmath102 with the @xmath75th element removed and @xmath103 for any vector @xmath104 . for ease of presentation in the following , we avoid logarithmic terms in rates of convergence ; that is , we state assumptions and results in the form @xmath105 instead of @xmath106 with @xmath107 .      in order to analyze the asymptotic properties of the local linear estimator with nonparametrically generated regressors",
    ", we make the following assumptions .",
    "[ as1 ] we assume the following properties for the data distribution , the bandwidth , and kernel function @xmath29 :    the sample observations @xmath108 are i.i.d .    the random vector @xmath33 is continuously distributed with compact support @xmath109 .",
    "its density function @xmath110 is twice continuously differentiable and bounded away from zero on @xmath109 .",
    "the function @xmath3 is twice continuously differentiable on @xmath109 .",
    "@xmath111 \\leq c$ ] almost surely for a constant @xmath112 and @xmath113 small enough .",
    "the kernel function @xmath29 is a twice continuously differentiable , symmetric density function with compact support , say @xmath114 $ ] .",
    "the bandwidths @xmath30 satisfies @xmath115 for @xmath116 and @xmath117 .",
    "most conditions in assumption [ as1 ] are standard regularity and smoothness conditions for kernel - type nonparametric regression , with the exception of assumption  [ as1](iv ) .",
    "the subexponential tails of @xmath17 conditional on @xmath19 assumed there are needed to apply certain results from empirical process theory in our proofs . such a condition is not very restrictive though .",
    "[ as2 ] the components @xmath118 and @xmath119 of @xmath120 and @xmath121 , respectively , satisfy @xmath122 for some @xmath123 and all @xmath116 .",
    "assumption [ as2 ] is a `` high - level '' restriction on the accuracy of the estimator @xmath7 .",
    "it requires each component of the estimate of the function @xmath2 to be uniformly consistent , converging at rate at least as fast as the corresponding bandwidth in the second stage of the estimation procedure .",
    "this is typically not a restrictive condition , and it allows for estimators @xmath7 that converge at a  rate slower than the oracle estimator @xmath32 .",
    "uniform rates of consistency are widely available for all common nonparametric estimators ; see , for example , @xcite for results on the nadaraya  watson , local linear and local polynomial estimators , or @xcite for series estimators .",
    "[ as3 ] there exist sequences of sets @xmath124 such that :    @xmath125 as @xmath126 for all @xmath116 .    for a constant @xmath127 and a function @xmath128 with @xmath129 ,",
    "the set @xmath130 can be covered by at most @xmath131 balls with @xmath132-radius @xmath133 for all @xmath134 , where @xmath135 , @xmath136 and @xmath132 denotes the supremum norm .",
    "assumption [ as3 ] requires the first - stage estimator @xmath7 to take values in a function space @xmath137 that is not too complex , with probability approaching 1 . here",
    "the complexity of the function space is measured by the cardinality of the covering sets .",
    "this is a typical requirement for many results from empirical process theory ; see @xcite . the second part of assumption [ as3 ] is typically fulfilled under suitable smoothness restrictions .",
    "for example , suppose that @xmath137 is the set of functions defined on some compact set @xmath138 whose partial derivatives up to order @xmath75 exist and are uniformly bounded by some multiple of @xmath139 for some @xmath140 .",
    "then assumption [ as3](ii ) holds with @xmath141 and @xmath142 [ @xcite , corollary 2.7.2 ] . for kernel - based estimators of @xmath2",
    ", one can then verify part ( i ) of assumption [ as3 ] by explicitly calculating the derivatives .",
    "consider , for example , the one - dimensional nadaraya ",
    "watson estimator @xmath143 with bandwidth of order @xmath144 .",
    "choose @xmath128 equal to @xmath119 plus asymptotic bias term .",
    "then one can check that the second derivative of @xmath145 is absolutely bounded by @xmath146 for all @xmath147 .",
    "for sieve and orthogonal series estimators , assumption [ as3](i ) immediately holds when the set @xmath137 is chosen as the sieve set or as a subset of the linear span of an increasing number of basis functions , respectively . for a discussion of entropy bounds and further references ,",
    "we refer to @xcite .",
    "[ as4 ] for any @xmath148 the conditional expectation @xmath149 with @xmath150 exists and is twice differentiable with respect to its first argument , with derivatives that are uniformly bounded in absolute value , and satisfies @xmath151 for all @xmath152 and a constant @xmath153 .",
    "assumption [ as4 ] imposes certain smoothness restrictions on the conditional expectation of @xmath154 .",
    "the term @xmath154 can be thought of as capturing the influence of the underlying covariates @xmath19 on the outcome variable @xmath22 that is not excreted through the `` index '' @xmath18 . in certain applications ,",
    "the `` index ''  @xmath18 is a sufficient statistic for the function @xmath3 , and thus @xmath155 with probability 1 . in this case ,",
    "assumption [ as4 ] is trivially satisfied .",
    "note that @xmath156 , and that @xmath157 by construction .      with the assumptions given in the previous section , we are now ready to state our main result , which is a  stochastic expansion of the real estimator @xmath158 around the oracle estimator @xmath159 . our aim is to derive an explicit characterization of the influence of the presence of generated regressors on the final estimator of the function @xmath3 .",
    "to this end , we define @xmath160 , and set @xmath161 .",
    "next , we define @xmath162 for any @xmath163 , where @xmath164 is a vector with elements @xmath165 . finally , we put @xmath166 and @xmath167 . with this notation",
    ", we can now state our main theorem .",
    "[ mainexpansion]suppose assumptions [ as1][as4 ] hold .",
    "then @xmath168 where @xmath169 with @xmath170    the two leading terms in our stochastic expansion of the real estimator  @xmath158 around the oracle estimator @xmath171 , which are accounting for the presence of generated covariates , are both smoothed versions of the first - stage estimation error @xmath172 . to see this more clearly , note that it follows from standard arguments for local polynomial smoothing that @xmath173 uniformly over @xmath174 the support of @xmath175 is a subset of  @xmath176 . in order to achieve a certain rate of convergence for the real estimator ,",
    "it is thus not necessary to have an estimator of @xmath2 that converges with the same rate or a faster one , since the asymptotic properties of the estimator using nonparametrically generated regressors only depend on a  smoothed version of the first - stage estimation error .",
    "while smoothing does not affect the order of the estimator s deterministic part , it typically reduces the variance and thus allows for less precise first - stage estimators .",
    "note that the first adjustment term is negligible in regions where the regression function is flat , since @xmath177 in this case .",
    "conversely , the impact of generated covariates is accentuated when the true regression function is steep .",
    "also note that @xmath178 when @xmath179 , as the latter implies that @xmath180 .",
    "this is a  natural condition in certain empirical applications .    in theorem [ mainexpansion ] no assumptions",
    "are made about the process generating the data for estimation of @xmath2 .",
    "in particular , nothing is assumed about dependencies between the errors in the pilot estimation and the regression errors @xmath181 .",
    "we conjecture that better rates than @xmath182 can be proven under such additional assumptions , but the results would only be specific to the respective full model under consideration .",
    "one way to extend our approach to such a setting would be to use our empirical process methods to bound the remainder term of higher order differences between @xmath183 and @xmath184 , and to treat the leading terms of the resulting higher order expansion by other , more direct methods .",
    "in this section , we apply our high - level results from section [ sec4 ] to some of the motivating examples presented in section [ sec3 ] , which are representative for the others in terms of employed techniques . assuming a specific nature of the function @xmath2 and a specific method to estimate it , explicit forms of the adjustment terms @xmath185 and @xmath186 in theorem [ mainexpansion ]",
    "can be derived in order to account for the presence of generated covariates . our focus in this section is on the practically most important case that @xmath2 is the conditional mean function in an auxiliary nonparametric regression .",
    "many other applications can be treated along the same lines .",
    "the main setting in which we illustrate the application of the stochastic expansion from theorem [ mainexpansion ] is the `` two - stage '' nonparametric regression model given by=-1 @xmath187=0 where @xmath38 is an unobserved error term that satisfies @xmath39 = e[\\varepsilon| r_0(s ) ] = 0 $ ] . for simplicity , we focus on the case that @xmath33 is a one - dimensional covariate , but generalizations to multiple generated covariates or the presence of additional observed covariates are immediate",
    ".    our strategy for deriving asymptotic properties of @xmath0 in this framework is to first provide an explicit representation for the adjustment terms @xmath185 and @xmath186 from theorem [ mainexpansion ] , which are then combined with standard results about the oracle estimator @xmath32 . for this approach",
    "it is convenient to use a  kernel - based smoother to estimate @xmath2 .",
    "since the bias of both @xmath188 and @xmath186 is of the same order as of this first - stage estimator , we propose to estimate the function @xmath2 via @xmath189th order local polynomial smoothing , which includes the local linear estimator as the special case @xmath190 .",
    "formally , the estimator is given by @xmath191 , where @xmath192 and @xmath193 is a @xmath14-dimensional product kernel built from the univariate kernel @xmath194 , @xmath195 is a vector of bandwidths , whose components are assumed to be the same for simplicity , and @xmath196 denotes the summation over all @xmath197 with @xmath198 . when @xmath2 is sufficiently smooth , the asymptotic bias of local polynomial estimators of order @xmath189 is well known to be @xmath199 uniformly over @xmath200 ( if @xmath189 is uneven ) , and can thus be controlled .",
    "a further technical advantage of using local polynomials is that the corresponding estimator admits a certain stochastic expansion under general conditions , which is useful for our proofs .",
    "we make the following assumption , which is essentially analogous to assumption [ as1 ] , except for assumption  [ as4](iii ) .",
    "this additional assumption requires higher order smoothness of the kernel , necessary to bound the @xmath75th derivative of the estimator @xmath120 .",
    "this allows us to verify complexity assumption [ as3 ] for @xmath120 .",
    "[ as5 ] we assume the following properties for the data distribution , the bandwidth and kernel function @xmath194 :    the observations @xmath201 are i.i.d . , and the random vector @xmath19 is continuously distributed with compact support @xmath202 .",
    "its density function @xmath203 is bounded and bounded away from zero on @xmath202 .",
    "it is also differentiable with a bounded derivative .",
    "the residuals @xmath38 satisfy @xmath204 for some @xmath205 .",
    "the function @xmath2 is @xmath206 times continuously differentiable on @xmath202 .",
    "the kernel function @xmath194 is a @xmath75-times continuously differentiable , symmetric density function with compact support , say @xmath114 $ ] , for some natural number @xmath207 .",
    "the bandwidth satisfies @xmath208 for some @xmath209 .    to simplify the presentation",
    ", we also assume that the function @xmath210 is strictly monotone in at least one of its arguments , which can be taken to be the last one without loss of generality .",
    "this assumption could be easily removed at the cost of a substantially more involved notation in the following results .",
    "[ as6 ] the function @xmath211 is strictly monotone in @xmath212 , and we have that @xmath213 for some twice continuously differentiable function @xmath214 .",
    "the following proposition shows that in the present context the function @xmath185 can be written as the sum of a smoothed version of the first stage estimator s bias function , a kernel - weighted average of the first - stage residuals @xmath215 , and some higher order remainder terms . for a concise presentation of the result",
    ", we introduce some particular kernel functions .",
    "let @xmath216 denote the @xmath14-dimensional equivalent kernel of the local polynomial regression estimator , given in ( [ equivkernel ] ) in the , and define the one - dimensional kernel functions @xmath217 then , with this notation , we obtain the following proposition .    [ proptwostage ] suppose that assumptions [ as1 ] and [ as4][as6 ] hold .",
    "then we have for the correction factor @xmath218 in theorem [ mainexpansion ] that @xmath219 where the terms @xmath220 and @xmath221 satisfy @xmath222 moreover , uniformly over @xmath223 , it is @xmath224 + o_p(g^{q+1})$ ] with a bounded function @xmath225 given in ( [ fsbias ] ) in the , and the term @xmath226 allows for the following expansions uniformly over @xmath223 , depending on the limit of @xmath227 :    if @xmath228 , then @xmath229    if @xmath230 , then @xmath231    if @xmath232 , then @xmath233    it should be emphasized that in all three cases of the above proposition the leading term in the expression for @xmath226 is equal to an average of the error terms @xmath234 weighted by a _",
    "one - dimensional _ kernel function , irrespective of @xmath235 .",
    "the dimension of the covariates thus affects the properties of @xmath185 only through higher - order terms .",
    "furthermore , it should be noted that one can also derive expressions of @xmath185 similar to the ones above for values of @xmath236 close to the boundary of the support .",
    "likewise these take the form of a one - dimensional kernel weighted average of the error terms @xmath234 plus a higher - order term . the corresponding kernel function",
    ", however , has a more complicated closed form varying with the point of evaluation .",
    "the following proposition establishes a result similar to proposition [ proptwostage ] for the second adjustment term @xmath186 .",
    "we again introduce a particular one - dimensional kernel function , defined as @xmath237 with @xmath238 where @xmath216 still denotes the @xmath14-dimensional equivalent kernel of the local polynomial regression estimator , given in ( [ equivkernel ] ) in the .",
    "[ proptwostage2b ] suppose that assumptions [ as1 ] and [ as4][as6 ] hold .",
    "then we have that @xmath239 where the terms @xmath240 and @xmath241 satisfy @xmath242 moreover , uniformly over @xmath223 , it is @xmath243 + o_p(g^{q+1})$ ] with a bounded function @xmath225 given in ( [ fsbias ] ) in the , and the term @xmath244 allows for the following expansion uniformly over @xmath223 : @xmath245    again , the leading term in the expression for @xmath240 is equal to an average of the error terms @xmath234 weighted by a _",
    "one - dimensional _ kernel function , and thus behaves similarly to one - dimensional nonparametric regression estimator .",
    "a  similar result could be established for regions close to the boundary of the support .",
    "note that in contrast to proposition [ proptwostage ] , the details of the result in proposition [ proptwostage2b ] do not depend on the relative magnitude of the bandwidths used in the first and second stage of the estimation procedure .    combining theorem [ mainexpansion ] and propositions [ proptwostage][proptwostage2b ] with well - known results about the oracle estimator @xmath246",
    ", various asymptotic properties of the real estimator @xmath5 can be derived . in the following corollaries we present results for the most relevant scenarios , addressing uniform rates of consistency and stochastic expansions of order @xmath247 for proving pointwise asymptotic normality .",
    "more refined expansions of higher orders such as @xmath248 , which are useful for the analysis of semiparametric problems in which @xmath3 plays the role of an infinite dimensional nuisance parameter [ e.g. , @xcite , @xcite , @xcite ] , would also be possible .",
    "we do not present such results here as they would require strong smoothness restrictions that are unattractive in applications .",
    "see @xcite for an alternative approach to controlling the influence of generated covariates in semiparametric models",
    ".    starting with considering the uniform rate of consistency , it is well known [ @xcite ] that under assumption [ as1 ] the oracle estimator satisfies @xmath249 this implies the following result .",
    "[ coratwostage]suppose that assumptions [ as1 ] , [ as4 ] and [ as5 ] hold .",
    "then @xmath250    straightforward calculations show that , under appropriate smoothness restrictions , it is possible to recover the oracle rate for the real estimator given suitable choice of @xmath251 and @xmath252 , even if the first - stage estimator converges at a  strictly slower rate .",
    "note that the rate in corollary [ coratwostage ] improves upon a  bound on the uniform rate of convergence of a two - stage regression estimator derived in @xcite for a similar setting .",
    "next , we derive stochastic expansions of @xmath5 of order @xmath247 for the case that @xmath253",
    ". such expansions immediately imply results on pointwise asymptotic normality of the real estimator .",
    "we start with the case that @xmath254 , in which the stochastic terms @xmath240 and @xmath220 are of the same order of magnitude ( other bandwidth choices will be discussed below ) . during the analysis of this setting ,",
    "it becomes clear that applying theorem [ mainexpansion ] requires @xmath255 .",
    "thus in order to use the expansion in proposition [ proptwostage](b ) , only @xmath256 is admissible ; that is , @xmath19 must be one - dimensional for the choice @xmath254 to be feasible . in this setting ,",
    "the notation for the kernel functions appearing in the stochastic expansions can be somewhat simplified .",
    "we define @xmath257 \\tilde h^\\gamma(v , x ) & = & \\int l^*\\bigl(v + s\\ , \\partial_{x}r_0^{-1}(x)\\bigr)\\,ds\\tilde\\lambda(x),\\end{aligned}\\ ] ] where @xmath258 where @xmath259 is the inverse function of @xmath2 , which exists by assumption [ as6 ] .",
    "[ corbtwostage ] suppose that assumptions [ as1 ] and [ as4][as6 ] hold with @xmath260 and @xmath261 .",
    "then the following expansions hold uniformly over @xmath223 : @xmath262 & & \\qquad = \\frac{1}{nf_r(x ) } \\sum_{i=1}^n k_h\\bigl(r_0(s_i)-x\\bigr ) \\varepsilon_i \\\\[-3pt ]   & & \\qquad \\quad { } - \\frac{1}{nf_r(x ) } \\sum_{i=1}^n \\bigl(m_0'(x ) \\tilde { j}_h\\bigl(r_0(s_i)-x , x\\bigr ) - \\tilde h_h^\\gamma\\bigl(s_i - r_0^{-1}(x),x\\bigr)\\bigr ) \\zeta_i \\\\[-3pt ]   & & \\qquad \\quad { } + \\frac{1}{2 } \\beta(x)h^2 + o_p(n^{-2/5 } ) , \\end{aligned}\\ ] ] where the bias is given by @xmath263 & & { } - \\int u^2 l(u)\\,du\\bigl(r_0^{\\prime\\prime } ( r_0^{-1}(x))m_0'(x ) - \\partial _ x[r_0^{\\prime\\prime } ( r_0^{-1}(x))\\rho(r_0^{-1}(x ) ) ] \\bigr).\\vadjust{\\goodbreak}\\end{aligned}\\ ] ] in particular , we have @xmath264 where @xmath265/f_r(x ) $ ] is the asymptotic variance .    under the conditions of the corollary , the limiting distribution of @xmath266 is generally affected by the pilot estimation step , although a qualitative description of the impact seems difficult .",
    "depending on the curvature of @xmath3 and the covariance of @xmath17 and @xmath38 , the asymptotic variance of the estimator using generated regressors can be bigger or smaller than that of the oracle estimator @xmath267 .",
    "there thus exist settings where in practice it would be preferable to base inference on the real estimator even if one was actually able to compute the oracle estimator .",
    "the next corollary considers the case that @xmath268 , and thus @xmath269 .",
    "again , applying theorem [ mainexpansion ] requires @xmath255 in this setting , and thus only @xmath256 is admissible when using proposition [ proptwostage](a ) for such a choice of bandwidths .",
    "the corollary also focuses on the special case that @xmath270 , which implies that @xmath271 with probability 1 .",
    "this condition is satisfied for certain empirical applications , such as , for example , models iv models . without this additional restriction ,",
    "an expansion of the difference @xmath272 would be dominated by the term @xmath240 , which is @xmath273 and thus converges at a _ slower _ rate than the oracle estimator .",
    "suppose that assumptions [ as1 ] , [ as4 ] and [ as5 ] hold with @xmath274 , @xmath275 and @xmath261 , and that @xmath155 with probability 1 .",
    "then the following expansion holds uniformly over @xmath223 : @xmath276 in particular , we have @xmath277 where @xmath278 is the asymptotic variance .    the limiting distribution of @xmath266 is again affected by the use of generated covariates under the conditions of the corollary . in this particular case , the form of the asymptotic variance has an intuitive interpretation : the estimator @xmath266 has the same limiting distribution as the local linear oracle estimator in the hypothetical regression model @xmath279 where @xmath280 . as in corollary [ corbtwostage ] above , depending on the curvature of @xmath3 and the covariance of @xmath17 and @xmath38 , the asymptotic variance of the estimator using generated regressors can be bigger or smaller than that of the oracle estimator @xmath267 .",
    "the next corollary discusses the case when @xmath281 .",
    "for such a choice of bandwidth , applying theorem [ mainexpansion ] requires no restrictions on the dimensionality of @xmath19 .",
    "it turns out that in this case @xmath282 , and thus the limit distribution of @xmath5 is the same as for the oracle estimator  @xmath267 .",
    "the effect exerted by the presence of nonparametrically generated regressors is thus first - order asymptotically negligible for conducting inference on @xmath3 in this case .",
    "[ corctwostage ] suppose that assumptions [ as1 ] , [ as4 ] and [ as5 ] hold with @xmath283 .",
    "then the following expansion holds uniformly over @xmath223 if @xmath284 : @xmath285 in particular , we have @xmath277 where @xmath286 is the asymptotic variance .",
    "consider estimation of the censored regression model in ( [ censor ] ) .",
    "let @xmath287 be the @xmath189th order local polynomial estimator of the conditional mean @xmath288 , and let @xmath289 be the local linear estimator of @xmath290 using the generated covariates @xmath291 .",
    "then an estimate of @xmath43 is given by @xmath292 where the constant @xmath293 is chosen large enough to satisfy @xmath294 with probability tending to one .",
    "generalizing @xcite , we consider the use of higher - order local polynomials for the first stage estimator , and allow the bandwidth used for the computation of @xmath7 and @xmath295 to be different . for presenting the asymptotic properties of @xmath296 ,",
    "let @xmath297 be the proportion of uncensored observations conditional on @xmath298 , and assume that this function is continuously differentiable and bounded away from zero on the support of @xmath42 .",
    "we then obtain the following result .",
    "[ corcens ] suppose that assumptions [ as1 ] and [ as5 ] hold with @xmath299 and @xmath300 .",
    "furthermore , suppose that @xmath301 where @xmath302 and @xmath303 are constants depending on @xmath251 , @xmath189 and @xmath14 as follows : @xmath304 under these conditions , we have that @xmath305 where @xmath306 .    the corollary is analogous to theorem 5 in @xcite .",
    "however , using our results , substantially simplifies the proof and provides insights on admissible choices of bandwidths .",
    "note that the lower bound @xmath302 is chosen such that both the bias of @xmath7 and @xmath295 tends to zero at a rate faster than @xmath307 . due to this undersmoothing",
    ", the limiting distribution of @xmath308 is centered at zero .",
    "note that the final estimator converges at the same rate as the generated regressors .",
    "this is due to the fact that the function @xmath7 is not only used to compute @xmath295 , but also determines the limits of integration in  ( [ censestimator ] ) .",
    "the `` direct '' influence of the generated regressors in the estimation of @xmath189 is asymptotically negligible in this particular application .",
    "now consider nonparametric estimation of the structural function @xmath55 in the triangular simultaneous equation model ( [ npsim1])([npsim2 ] ) using a marginal integration estimator . in order to keep the notation simple ,",
    "we restrict our attention to the arguably most relevant case with a single endogenous regressor , but allow for an arbitrary number of exogenous regressors and instruments .",
    "let  @xmath309 be the @xmath189th order local polynomial estimator of @xmath310 , and let @xmath311 be the local linear estimator of @xmath312 .",
    "the latter is computed using the generated covariates @xmath313 instead of the true residuals @xmath314 from equation ( [ npsim2 ] ) . for simplicity , we use the same bandwidth for all components of @xmath315 ; that is , we put @xmath316 for all @xmath317 .",
    "the marginal integration estimator of @xmath318 is then given by the following sample version of ( [ eqmi ] ) : @xmath319 the following result establishes the estimator s asymptotic normality .",
    "[ corsim ] suppose that assumption [ as1 ] holds with @xmath320 and @xmath321 , and that assumption  [ as5 ] holds with @xmath322 .",
    "furthermore , suppose that @xmath323 , and that @xmath324 , where @xmath302 and @xmath303 are constants depending on @xmath251 , @xmath189 and @xmath325 as follows : @xmath326 where @xmath327 . under these conditions , we have that @xmath328 where @xmath329 is a @xmath330-dimensional product kernel , and @xmath331 .    under the conditions of the corollary ,",
    "the asymptotic variance of @xmath332 is not influenced by the presence of generated regressors : if @xmath315 was replaced in ( [ marint ] ) with an oracle estimator @xmath333 using the actual disturbances @xmath314 instead of the reconstructed ones , the result would not change . also , note that the exclusion restrictions on the instruments imply that @xmath334 .",
    "therefore assumption [ as4 ] is automatically satisfied , and the adjustment term @xmath186 from theorem  [ mainexpansion ] is equal to zero and does not have to be considered for the proof .",
    "in this paper , we analyze the properties of nonparametric estimators of a regression function , when some the covariates are not directly observable , but have been estimated by a nonparametric first - stage procedure .",
    "we derive a stochastic expansion showing that the presence of generated regressors affects the limit behavior of the estimator only through a smoothed version of the first - stage estimation error .",
    "we apply our results to a number of practically relevant statistical applications .",
    "throughout the appendix , @xmath335 and @xmath336 denote generic constants chosen sufficiently large or sufficiently small , respectively , which may have different values at each appearance .",
    "furthermore , define @xmath337 .      in order to prove the statement of the theorem",
    ", we have to introduce some notation . throughout the proof of this and the following statements",
    ", we denote the unit vector @xmath338 in @xmath339 by @xmath340 .",
    "we also write @xmath341 , and put @xmath342 , @xmath343 and @xmath344 .",
    "we also define @xmath345 , and put @xmath346 , @xmath347 and @xmath348 and set @xmath349 .",
    "furthermore , define @xmath350 and note that we have @xmath351 by construction .",
    "it also holds that @xmath352 next , it follows from standard calculations that the real estimator @xmath0 can be written as @xmath353 where @xmath354 for @xmath355 , and @xmath356 ( \\hat\\alpha_b , \\hat\\beta_b ) & = & { \\operatorname{argmin}\\limits}_{\\alpha,\\beta } \\sum_{i=1}^n \\bigl(m_0(r_0(s_i ) ) - m_0(x)- m_0^{\\prime}(x)^t \\bigl(r_0(s_i ) - x\\bigr ) \\\\ & & \\hspace*{144pt } { } -\\alpha- \\beta^t \\bigl(\\hat r(s_i ) - x\\bigr)\\bigr)^2\\\\[-2pt ] & & \\hphantom{{\\operatorname{argmin}\\limits}_{\\alpha,\\beta } \\sum_{i=1}^n}{}\\times k_h\\bigl(\\hat r(s_i)-x\\bigr),\\\\[-2pt ] ( \\hat\\alpha_c , \\hat\\beta_c ) & = & { \\operatorname{argmin}\\limits}_{\\alpha,\\beta } \\sum_{i=1}^n \\bigl(-m_0^{\\prime}(x)^t\\bigl(\\hat{r}(s_i)-r_0(s_i)\\bigr ) - \\alpha-",
    "\\beta^t \\bigl(\\hat r(s_i ) - x\\bigr)\\bigr)^2 \\\\[-2pt ] & & \\hphantom{{\\operatorname{argmin}\\limits}_{\\alpha,\\beta } \\sum_{i=1}^n}{}\\times k_h\\bigl(\\hat r(s_i ) -x\\bigr ) , \\\\[-2pt ] ( \\hat\\alpha_d , \\hat\\beta_d ) & = & { \\operatorname{argmin}\\limits}_{\\alpha,\\beta } \\sum_{i=1}^n \\bigl(m_0^{\\prime}(x)^t\\bigl(\\hat{r}(s_i)-x\\bigr)- \\alpha- \\beta ^t \\bigl(\\hat r(s_i ) - x\\bigr)\\bigr)^2 \\\\[-2pt ] & & \\hphantom{{\\operatorname{argmin}\\limits}_{\\alpha,\\beta } \\sum_{i=1}^n}{}\\times k_h\\bigl(\\hat r(s_i ) -x\\bigr ) , \\\\[-2pt ] ( \\hat\\alpha_e , \\hat\\beta_e ) & = & { \\operatorname{argmin}\\limits}_{\\alpha,\\beta } \\sum_{i=1}^n \\bigl(\\rho(s_i)- \\alpha- \\beta^\\mathsf{t } \\bigl(\\hat r(s_i ) - x\\bigr)\\bigr)^2 k_h\\bigl ( \\hat r(s_i ) - x\\bigr).\\end{aligned}\\ ] ] similarly , the oracle estimator @xmath32 can be represented as @xmath357 where @xmath358 for @xmath355 , and @xmath359 ( \\tilde\\alpha_b , \\tilde\\beta_b ) & = & { \\operatorname{argmin}\\limits}_{\\alpha,\\beta } \\sum_{i=1}^n \\bigl(m_0(r_0(s_i ) ) - m_0(x)- m_0^{\\prime}(x)^t \\bigl(r_0(s_i ) -x\\bigr ) \\\\[-2pt ]   & & \\hspace*{140pt } { } - \\alpha- \\beta^t \\bigl(r_0(s_i ) - x\\bigr)\\bigr)^2 \\\\[-2pt ]   & & \\hphantom{{\\operatorname{argmin}\\limits}_{\\alpha,\\beta } \\sum_{i=1}^n}{}\\times k_h\\bigl(r_0(s_i ) -x\\bigr),\\\\[-2pt ] ( \\tilde\\alpha_c , \\tilde\\beta_c ) & = & { \\operatorname{argmin}\\limits}_{\\alpha,\\beta } \\sum_{i=1}^n \\bigl(-m_0^{\\prime}(x)^t\\bigl(\\hat r(s_i ) - r_0(s_i)\\bigr)- \\alpha - \\beta^t \\bigl(r_0(s_i )",
    "- x\\bigr)\\bigr)^2 \\\\[-2pt ]   & & \\hphantom{{\\operatorname{argmin}\\limits}_{\\alpha,\\beta } \\sum_{i=1}^n}{}\\times k_h\\bigl(r_0(s_i ) -x\\bigr ) \\\\[-2pt ] ( \\tilde\\alpha_d , \\tilde\\beta_d ) & = & { \\operatorname{argmin}\\limits}_{\\alpha,\\beta } \\sum_{i=1}^n \\bigl(m_0^{\\prime}(x)^t \\bigl(r_0(s_i ) - x\\bigr)- \\alpha- \\beta^t \\bigl(r_0(s_i ) - x\\bigr)\\bigr)^2 \\\\[-2pt ]   & & \\hphantom{{\\operatorname{argmin}\\limits}_{\\alpha,\\beta } \\sum_{i=1}^n}{}\\times k_h\\bigl(r_0(s_i ) -x\\bigr ) .",
    "\\\\[-2pt ] ( \\tilde\\alpha_e , \\tilde\\beta_e ) & = & { \\operatorname{argmin}\\limits}_{\\alpha,\\beta } \\sum_{i=1}^n \\bigl(\\rho(s_i)- \\alpha- \\beta^\\mathsf{t } \\bigl ( r(s_i ) - x\\bigr)\\bigr)^2 k_h\\bigl ( r(s_i ) - x\\bigr).\\end{aligned}\\ ] ] note that by construction , @xmath360 we now argue that @xmath361 for a proof of ( [ lemma12 ] ) note that @xmath362 and @xmath363 are given by the first elements of the vectors @xmath364 and @xmath365 , respectively . using these representations",
    ", one sees that ( [ lemma12 ] ) follows from lemmas [ lematheo1 ] and [ lembtheo1 ] below .    as a second step ,",
    "we now show that @xmath366 to prove ( [ lemma5 ] ) , put @xmath367 and @xmath368 , and write @xmath369 . with this notation , @xmath370 and @xmath371 . using lemma [ lemetheo1 ] and some results of lemma [ lemctheo1 ] , we then find that @xmath372 & & \\qquad\\!\\ !",
    "= e_1^\\mathsf{t } \\bigl(\\hat m_{h}(x)^{-1 } \\hat\\mu(x ) - m_{h}(x)^{-1 } \\mu(x ) - { \\mathbb{e } } ( m_{h}(x))^{-1}{\\mathbb{e}}\\bigl(\\hat\\mu(x ) - \\mu ( x ) \\bigr)\\bigr)\\\\[-2pt ] & & \\qquad\\!\\",
    "! = o_p\\bigl(n^{-((1/2)(1-\\eta_{+})+(\\delta-\\eta)_{\\mathrm{min}})}+ n^{-((1/2)(1-\\eta_{+})+\\delta_{\\mathrm{min } } ) } + n^{-\\kappa _ 1}\\bigr)=o_p(n^{-\\kappa_1})\\end{aligned}\\ ] ] uniformly over @xmath200 . using standard smoothing arguments",
    ", we also get that @xmath373 & = & \\frac{1}{f_r(x)}\\int\\bigl(k_h\\bigl ( \\hat r(u ) -x\\bigr ) - k_h\\bigl ( r_0(u ) -x\\bigr ) \\bigr)\\rho(u ) f_s(u)\\,dx\\,du\\\\[-2pt ] & & { } + o_p\\bigl(n^{-2\\eta_{\\mathrm{min}}-(\\delta-\\eta)_{\\mathrm{min}}}\\bigr)\\\\[-2pt ] & = & \\frac{1}{f_r(x)}\\int k'_h\\bigl ( r_0(u ) -x\\bigr ) \\bigl ( \\hat r(u)- r_0(u)\\bigr ) \\rho(u ) f_s(u)\\,dx\\,du\\\\[-2pt ] & & { } + o_p\\bigl(n^{-\\delta_{\\mathrm{min}}-(\\delta-\\eta ) _ { \\mathrm{min}}}\\bigr)+o_p(n^{-\\kappa_2})\\\\[-2pt ] & = & \\hat\\gamma(x)+ o_p(n^{-\\kappa_2})+o_p(n^{-\\kappa_3})\\end{aligned}\\ ] ] uniformly over @xmath200 .",
    "this shows the claim in ( [ lemma5 ] ) .",
    "finally , from lemmas [ lembtheo1 ] and [ lemctheo1 ] we get that @xmath374 and it is easy to see that @xmath375 taken together , the results in ( [ lemma01])([lemma6 ] ) imply the statement of the theorem .",
    "[ lematheo1 ] suppose that the conditions of theorem [ mainexpansion ] hold .",
    "then @xmath376    we only prove the first statement of the lemma .",
    "the second claim can be shown using essentially the same arguments . without loss of generality",
    ", we also assume that @xmath377 if @xmath378 the statement of the lemma follows from a direct bound .",
    "for @xmath379 large enough ( see below ) we choose @xmath380 such that @xmath381 with this choice of @xmath380 we define @xmath382 with @xmath383 for the proof of the lemma we apply a chaining argument ; compare , for example , the proof of theorem 9.1 in @xcite .",
    "now for @xmath384 , let @xmath385 be a set of functions chosen such that for each @xmath386 there exists @xmath387 such that @xmath388 .",
    "that is , the functions in  @xmath385 are the midpoints of a @xmath389-covering of @xmath390 . by assumption  [ as3 ] ,",
    "the set @xmath385 can be chosen such that its cardinality @xmath391 is at most @xmath392 .",
    "furthermore , define @xmath393 .    for @xmath394",
    "we now choose @xmath395 such that @xmath396 and @xmath397 , for all @xmath398 .",
    "we then consider the chain @xmath399 & & { } - \\delta _",
    "i(r_1^{g_n},r_1 ) + \\delta_i(r_2^{g_n},r_2),\\end{aligned}\\ ] ] where @xmath400 is the smallest integer that satisfies @xmath401 for a constant @xmath402 . with this choice of @xmath400",
    ", we obtain that for @xmath403 @xmath404 now for any @xmath405 define the constant @xmath406 .",
    "it then follows that @xmath407   & & \\qquad \\leq\\sum_{s=1}^{g_n } \\pr\\biggl(\\sup_{r_1 \\in\\bar{\\mathcal{m}}_n } \\biggl|\\frac{1}{n}\\sum_{i=1}^n \\delta_i(r_1^{s-1},r_1^s ) \\biggr|>c_a 2^{-as}n^{-\\kappa_1 } \\biggr ) \\\\[-2pt ] & & \\qquad \\leq\\sum_{s=1}^{g_n }",
    "\\ # \\bar{\\mathcal{m}}^*_{s-1,n } \\ # \\mathcal",
    "{ \\bar{m}}^*_{s , n } \\pr\\biggl(\\frac{1}{n}\\sum_{i=1}^n \\delta_i(r_1^{*,s},r_1^{**,s } ) > c_a",
    "2^{-as}n^{-\\kappa_1 } \\biggr ) \\\\[-2pt ] & & \\qquad \\quad { } + \\sum_{s=1}^{g_n } \\ # \\bar{\\mathcal{m}}^*_{s-1,n } \\ # \\mathcal { \\bar{m}}^*_{s , n } \\pr\\biggl(\\frac{1}{n}\\sum_{i=1}^n \\delta_i(\\tilde{r}_1^{*,s},\\tilde { r}_1^{**,s } ) < c_a 2^{-as}n^{-\\kappa_1 } \\biggr ) \\\\[-2pt ] & & \\qquad   = t_2 + t_3,\\end{aligned}\\ ] ] where the functions @xmath408 and @xmath409 are chosen such that @xmath410 we now show that both @xmath411 and @xmath412 tend to zero at an exponential rate : @xmath413 we only show ( [ t2 ] ) , as the statement ( [ t3 ] ) follows by essentially the same arguments . using assumption [ as3 ] ,",
    "we obtain by application of the markov inequality that @xmath414 \\\\[-8pt ] \\qquad&\\leq & c \\sum_{s=1}^{g_n } \\exp\\biggl(\\sum_j 2^{s\\alpha_j } n^{\\delta _ j\\alpha_j + \\xi_j } - \\gamma_{n , s}c_a2^{-as}n^{-\\kappa_1}\\biggr)\\nonumber\\\\ \\qquad&&\\hspace*{25pt}{}\\times\\prod_{i=1}^n { \\mathbb{e}}\\biggl ( \\exp\\biggl(\\gamma_{n , s } \\frac{1}{n}\\delta _ i(r_1^{*,s},r_1^{**,s } ) \\biggr)\\biggr),\\nonumber\\end{aligned}\\ ] ] where @xmath415 with a constant @xmath416 , small enough . now the last term on the right - hand side of ( [ s2 ] ) can be bounded as follows : @xmath417 \\\\[-8pt ] \\qquad\\qquad&\\leq&\\exp\\bigl ( c \\gamma_{n , s}^2n^{-2 } n^{\\eta_+ - 2(\\delta-\\eta ) _ { \\mathrm{min}}}2^{-2s } \\bigr),\\nonumber\\end{aligned}\\ ] ] where we have used that @xmath418 for @xmath31 large enough because of ( [ k1 ] ) . inserting ( [ s1 ] ) into ( [ s2 ] ) ,",
    "we obtain , if @xmath102 and @xmath419 were chosen sufficiently small , that @xmath420 finally , it follows from a simple argument that @xmath421 because the set @xmath422 can always be chosen such that it contains only a  single element .    from ( [ t1 ] ) , ( [ t2 ] ) ,",
    "( [ t3 ] ) and ( [ t4 ] ) , we thus obtain that @xmath423 \\\\[-8pt ] \\qquad & & \\hspace*{96pt } { } - \\frac{1}{n}\\sum_{i=1}^n k_h\\bigl(r_2(s_i)-x\\bigr)\\varepsilon_i^ * \\biggr| > cn^{-\\kappa_1 } \\biggr)\\leq\\exp(-cn^c).\\nonumber\\end{aligned}\\ ] ] now for @xmath424 choose a grid @xmath425 of @xmath109 with @xmath426 points , such that for each @xmath200 there exists a grid point @xmath427 such that @xmath428 . if @xmath429 is chosen large enough , this implies that @xmath430 for large enough @xmath31 , with probability tending to one .",
    "furthermore , it follows from ( [ t7 ] ) that @xmath431 the statement of the lemma then follows from ( [ t5])([t6 ] ) and ( [ t8])([t9 ] ) , if the constants @xmath432 and @xmath433 were chosen large enough .",
    "[ lembtheo1 ] suppose that the conditions of theorem [ mainexpansion ] hold .",
    "then @xmath434 for @xmath435 @xmath436 and @xmath437 , @xmath438 .",
    "the lemma follows from @xmath439 for @xmath440 and from @xmath441 which follows from a simple calculation .",
    "[ lemctheo1 ] suppose that the assumptions of theorem [ mainexpansion ] hold .",
    "for a random variable @xmath442 that neither depends on @xmath236 nor @xmath443 , it holds that @xmath444 i_i(x)\\bigr| \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\qquad&&\\qquad \\leq r_n n^{-2\\eta_{\\mathrm{min } } } , \\nonumber\\\\ \\label{u3 } & & \\sup_{x\\in i_r}\\biggl\\|\\frac{1}{n}\\sum_{i=1}^n k_h\\bigl(\\hat{r}(s_i ) -x\\bigr)\\hat w_i(x)\\hat w_i(x)^t \\nonumber\\\\ \\qquad & & \\qquad { } - \\frac{1}{n}\\sum_{i=1}^n k_h\\bigl(r_0(s_i ) -x\\bigr)\\tilde",
    "w_i(x)\\tilde w_i(x)^t\\biggr \\|   \\\\",
    "\\qquad&&\\qquad \\leq r_n n^{-(\\delta-\\eta)_{\\mathrm{min } } } , \\nonumber\\\\ \\label{u4 } & & \\sup_{x\\in i_r}\\biggl\\|\\frac{1}{n}\\sum_{i=1}^n k_h\\bigl(r_0(s_i ) -x\\bigr)\\tilde w_i(x)\\tilde w_i(x)^t - f_r(x ) b_k \\biggr\\|\\nonumber \\\\[-8pt ] \\\\[-8pt ] \\qquad&&\\qquad \\leq r_n \\bigl(n^{-\\eta _ { \\mathrm{min}}}+n^{-(1-\\eta_+)/2}\\sqrt{\\log n}\\bigr),\\nonumber\\end{aligned}\\ ] ] where @xmath445 is an equals one if @xmath446 lies in the support of the kernel function @xmath447 and zero otherwise , and @xmath448 is a @xmath449 diagonal matrix .",
    "claim ( [ u2 ] ) follows by a simple calculation .",
    "claim ( [ u3 ] ) is a  direct consequence of lemma [ lembtheo1 ] , and ( [ u4 ] ) follows from standard arguments from kernel smoothing theory . for the stochastic part , one makes use of lemma [ genkern ] , given in appendix [ genkern_sec ] , below .",
    "[ lemetheo1 ] suppose that the assumptions of theorem [ mainexpansion ] hold .",
    "then it holds that @xmath450\\| = o_p(n^{-\\kappa_1}),\\hspace*{-38pt}&\\\\ \\label{theo7add4}&\\displaystyle\\sup_{x\\in i_r } | \\hat\\mu(x ) | = o_p\\bigl(\\sqrt{\\log n}n^{-(1-\\eta_+)/2}\\bigr),&\\end{aligned}\\ ] ] where @xmath451 and @xmath452    for a proof of ( [ theo7add1 ] ) one proceeds as in lemma [ lematheo1 ] .",
    "claim  ( [ theo7add4 ] ) follows by classical smoothing arguments .",
    "note that we have that @xmath453 .      in order to prove proposition [ proptwostage ] , we use the fact that the local polynomial estimator satisfies a certain uniform stochastic expansion if assumption [ as4 ] holds . in order to present this result",
    ", we first have to introduce a substantial amount of further notation .",
    "for simplicity we assume @xmath454 , and we write @xmath195 for this joint value and for the vector @xmath455 .",
    "let @xmath456 be the number of distinct @xmath189-tuples @xmath457 with @xmath458 .",
    "arrange these @xmath189-tuples as a sequence in a lexicographical order ( with the highest priority given to the last position so that @xmath459 is the first element in the sequence , and @xmath460 the last element ) .",
    "let @xmath461 denote this one - to - one mapping , that is , @xmath462 , ",
    ", @xmath463 . for each @xmath464 , define a @xmath465 vector @xmath466 with its @xmath75th element given by @xmath467 , and write @xmath468 , which is a column vector of length @xmath469 .",
    "let @xmath470 and define @xmath471 .",
    "for @xmath472 , let @xmath473 and @xmath474 be two @xmath475 matrices with their @xmath476 elements , respectively , given by @xmath477_{l , m } = \\nu_{\\tau_j(l ) + \\tau_k(m ) } \\quad\\mbox{and}\\quad [ m_{nj , k}(x ) ] _ { l , m } = \\nu_{n,\\tau_j(l ) + \\tau_k(m)}(x).\\ ] ] now define the @xmath478 matrices @xmath479 and @xmath480 by @xmath481 finally , denote the first unit @xmath189-vector by @xmath482 . with this notation , it can be shown along classical lines that the local polynomial estimator @xmath7 admits the following stochastic expansion : @xmath483 \\\\[-8pt ] & & \\hspace*{28pt } { } + g^{q+1}b_n(s ) + r_n(s),\\nonumber\\end{aligned}\\ ] ] where @xmath484 , and @xmath485 is a bias term that satisfies @xmath486 to prove the proposition , define the stochastic component and the bias  term of the expansion ( [ bahadur ] ) as and @xmath487 , respectively . now",
    "the function @xmath218 can be written  as=-1 @xmath488=0 uniformly over @xmath489 .",
    "we first analyze the term @xmath221 . through the usual arguments from kernel smoothing theory",
    ", one can show for @xmath490 that @xmath491 since the function @xmath492 is continuous with respect to @xmath236 because of assumptions [ as5 ] and [ as6 ] .",
    "explicitly , we have @xmath493 next , consider the term @xmath220 .",
    "note that for @xmath490 we have that @xmath494 with @xmath495 where @xmath496 .",
    "define @xmath497 as the set that contains all @xmath498 that do not lie in a @xmath195-neighborhood of the boundary of @xmath499 .",
    "uniformly over @xmath500 , we have that @xmath501 .",
    "thus for @xmath502 , we have that @xmath503 where the function @xmath504 is equal to @xmath505 with modified kernel @xmath216 defined as @xmath506 note that @xmath216 is the _ equivalent kernel _ of the local polynomial regression estimator ; see @xcite , section 3.2.2 . for @xmath507",
    "the equivalent kernel is in fact equal to the original one , whereas @xmath508 is equal to @xmath509 times a polynomial in @xmath510 of order @xmath189 for @xmath511 , with coefficients such that its moments up to the order @xmath189 are equal to zero .",
    "the kernel @xmath512 has the same moment conditions in @xmath510 as @xmath513 but depends on @xmath457 .",
    "we now derive explicit expressions for the leading term in equation ( [ term1 ] ) for the cases ( a)(c ) of the proposition . starting with case ( a )",
    ", in which @xmath514 , it follows by substitution and taylor expansion arguments that with @xmath515 and @xmath516 @xmath517 where @xmath518 , @xmath519 and @xmath520 are intermediate values between @xmath521 and @xmath522 , @xmath523 and @xmath524 , and @xmath523 and @xmath524 , respectively .",
    "this gives an expansion for @xmath525 of order @xmath526 . for @xmath527",
    "one gets an expansion of order @xmath227 . put @xmath528 .",
    "together with lemma [ genkern ] in appendix  [ genkern_sec ] , we thus obtain that @xmath529 as claimed . to show statement ( b ) of the proposition , we rewrite the function  @xmath530 as follows : @xmath531 where @xmath532 , and @xmath518 is an intermediate value between @xmath533 and @xmath534 , and @xmath519 is an intermediate value between @xmath523 and @xmath535 .",
    "as in the proof of part ( a ) , it follows from lemma [ genkern ] in appendix [ genkern_sec ] that @xmath536 where @xmath537 uses the location independent form of the equivalent kernel @xmath216 as defined in the text in front of proposition [ proptwostage ] .",
    "this implies the desired result .",
    "now consider statement ( c ) of the proposition . in this case ,",
    "where @xmath538 , we can rewrite the function @xmath530 as follows : @xmath539 from tedious but conceptually simple taylor expansion arguments similar to the ones employed for case ( a ) , and from lemma [ genkern ] , one gets that @xmath540 where @xmath541 and @xmath542 . with @xmath543 as defined in the text , we find @xmath544 since @xmath545 , this completes our proof .      to show the result ,",
    "note that @xmath546 uniformly over @xmath200 and @xmath547 .",
    "since @xmath548 by construction , it suffices to consider the term @xmath549 . to simplify the exposition",
    ", we strengthen assumption [ as6 ] and suppose that in addition to @xmath2 all functions @xmath547 are strictly monotone with respect to their last argument , and write  @xmath550 for corresponding the inverse function that satisfies @xmath551 ( without this condition , the notation would be much more involved , as we would have to consider all regions where the functions @xmath547 are piecewise monotone with respect to the last component separately ) . using rules for integrals on manifolds , we derive the following explicit expression for @xmath552 : @xmath553 set the numerator of the above expression as @xmath554 and the denominator as @xmath555 . then clearly @xmath556 uniformly over @xmath200",
    "moreover , note that the mapping @xmath557 is hadamard differentiable at @xmath2 , with derivative @xmath558 it follows with @xmath559 that @xmath560 we evaluate the term @xmath561 , substitute the uniform expansion ( [ bahadur ] ) for @xmath172 into the explicit expression derived above , and use standard arguments from kernel smoothing theory .",
    "this gives the desired expansion for @xmath562 .",
    "the form of @xmath563 follows from the same arguments used to derive the form of @xmath564 in the proof of proposition [ proptwostage ] .",
    "the statements of these corollaries follow by direct application of proposition [ proptwostage][proptwostage2b ] and theorem [ mainexpansion ] .",
    "the statement of corollary [ coratwostage ] is immediate . for corollaries [ corbtwostage][corctwostage ]",
    ", we only have to check that the error bounds in theorem [ mainexpansion ] and proposition [ proptwostage][proptwostage2b ] are of the desired order .",
    "we only discuss how the constants @xmath565 , @xmath566 and @xmath567 can be chosen .",
    "note that all these constants have no subindex because we only consider the case @xmath568 .",
    "we apply theorem [ mainexpansion ] conditionally on the values of @xmath569 .",
    "then the only randomness in the pilot estimation comes from @xmath215 .",
    "we can decompose @xmath120 into @xmath570 , where @xmath571 is the local polynomial fit to @xmath572 , and  @xmath573 is the local polynomial fit to @xmath574 .",
    "conditionally given @xmath569 , the value of @xmath573 is fixed , and for checking assumption  [ as3 ] , we only have to consider entropy conditions for sets of possible outcomes of @xmath571 .",
    "we will show that with @xmath575 one can choose for @xmath566 and @xmath567 any value that is larger than @xmath576 or @xmath577 , respectively .",
    "note that then @xmath578 because of assumption [ as4](iii ) .",
    "it can be easily checked that we get the desired expansions in corollaries [ coratwostage ] and [ corbtwostage ] with this choices of @xmath575 ,  @xmath566 and  @xmath567 ( with  @xmath566 and  @xmath567 small enough ) . in particular note that we can make @xmath579 as close to @xmath580 as we like .",
    "it is clear that assumption [ as2 ] holds for this choice of @xmath566 .",
    "this follows by standard smoothing theory for local polynomials .",
    "compare also lemma [ genkern ] and the proof of proposition [ proptwostage ] .",
    "it remains to check assumption [ as3 ] .",
    "it suffices to check the entropy conditions for the tuple of functions @xmath581^{\\pi}\\zeta_i\\dvtx 0\\leq\\pi_+ \\leq q , \\pi_j\\geq0 $ ] for @xmath582 .",
    "this follows because we get @xmath571 by multiplying this tuple of functions with a ( stochastically ) bounded vector .",
    "we now argue that all derivatives of order @xmath75 of the functions @xmath583^{\\pi}\\zeta_i$ ] can be bounded by a variable @xmath485 that fulfills @xmath584 with probability tending to one . here",
    "@xmath585 is a number with @xmath586 .",
    "this bound holds uniformly in @xmath587 and @xmath588 .",
    "furthermore , the functions @xmath589^{\\pi}\\zeta_i$ ] can be bounded by a variable @xmath590 that fulfills @xmath591 with probability tending to one . here",
    "@xmath592 is a number with @xmath593 .",
    "again , this bound holds uniformly in @xmath587 and @xmath588 .",
    "we now consider the set of functions on @xmath202 that are absolutely bounded by @xmath594 and that have all partial derivatives of order @xmath75 absolutely bounded by @xmath595 .",
    "we argue that this set can be covered by @xmath596 balls with @xmath597-radius @xmath293 for @xmath598 . here",
    "the constant @xmath335 does not depend on @xmath594 and @xmath595 .",
    "this entropy bound shows that assumption [ as3 ] holds with these choices of @xmath565 , @xmath566 and @xmath567 . for the proof of the entropy bound",
    "one applies an entropy bound for the set of functions on @xmath202 that are absolutely bounded by @xmath599 and that have all partial derivatives of order @xmath75 absolutely bounded by @xmath599 .",
    "this set can be covered by @xmath600 balls with @xmath132-radius @xmath293 for @xmath601 .",
    "the desired entropy bound follows by rescaling of the functions .",
    "note that we have that @xmath602 .",
    "our proof has the same structure as the one provided by @xcite , but making use of theorem [ mainexpansion ] considerably simplifies some of their arguments .",
    "first , note that the restriction that @xmath603 implies that @xmath604 and @xmath605 . from a  second - order taylor expansion , we furthermore obtain that @xmath606 & & { } + \\int_{r_0(x)}^{\\lambda}\\frac{\\hat{q}(s)-q_0(s)}{q_0(s)^2}\\,ds-   \\frac{\\hat{q}'(\\bar{r}(x))}{2\\hat{q}(\\bar{r}(x))^2}\\bigl(\\hat { r}(x)-r(x)\\bigr)^2 \\\\[-2pt ] & & { } - \\int_{r(x)}^{\\lambda}\\frac{(\\hat{q}(s)-q_0(s))^2}{\\hat { q}(s)q_0(s)^2}\\,ds\\\\[-2pt ] & & { } + \\frac{(\\hat{q}(\\check{r}(x))-q_0(\\check{r}(x)))^2}{\\hat{q}(\\check{r}(x))q_0(\\check { r}(x))}\\bigl(\\hat{r}(x)-r_0(x)\\bigr)\\\\[-2pt ] & \\equiv & t_1 + t_2 + t_3 + t_4 + t_5,\\end{aligned}\\ ] ] where @xmath287 and @xmath607 are intermediate values between @xmath608 and @xmath287 .",
    "now it follows from standard arguments for local linear estimators that @xmath609 since @xmath610 . to prove the corollary , it thus only remains to be shown that the remaining four terms in the above expansion are of smaller order than @xmath611 . under the conditions of the corollary",
    ", it is easy to show with straightforward rough arguments that @xmath612 , @xmath613 and @xmath614 where the supremum and infimum are taken over @xmath615 for some @xmath616 , respectively .",
    "this directly implies that @xmath617 .",
    "now consider the term @xmath411 . from theorem [ mainexpansion ] , we obtain that @xmath618 where @xmath619 is the oracle estimator of the function @xmath189 obtained via local linear regression of @xmath620 on @xmath621 , and @xmath622 and @xmath186 are the adjustment terms that appear in the main expansion in theorem [ mainexpansion ] , with the necessary adjustments to the notation .",
    "using similar arguments as in the proof of proposition [ proptwostage][proptwostage2b ] and corollaries [ corbtwostage][corctwostage ] , and the restriction that @xmath623 , we obtain that @xmath624 & = & o_p(n^{-1/2})+o_p(h^2 ) = o_p((ng^p)^{-1/2})\\end{aligned}\\ ] ] for @xmath625 , and similarly that @xmath626 thus @xmath627 .",
    "finally , straightforward calculations show that @xmath623 also implies that @xmath628 .",
    "this completes the proof .",
    "let @xmath629 and @xmath630 , define the functional @xmath631 as @xmath632 and let @xmath633 = \\lim_{t \\to0 } ( s_n(f+th)-s_n(f))/t$ ] denote its directional derivative .",
    "one then obtains through direct calculations that for any @xmath634 with bounded second derivatives we have that @xmath635 \\|_\\infty\\\\ & & \\qquad= o ( \\|f_2-\\bar{f}_{2}\\|_\\infty^2 ) + o\\bigl(\\|f_2-\\bar{f}_{2}\\|_\\infty\\bigl\\| f_{1,a}^{(v)}-\\bar{f}_{1}^{(v)}\\bigr\\|_\\infty\\bigr ) + o(\\|f_{1,b}\\|_\\infty),\\end{aligned}\\ ] ] where @xmath636 . using the same kind of arguments as in the proof of proposition [ proptwostage ] , under the conditions of the corollary one can derive the following stochastic expansion of @xmath315 up to order @xmath637 , uniformly over @xmath638 in the @xmath639-interior of the support of @xmath640 : @xmath641 where @xmath642 .",
    "a similar , but notationally more involved expansion can be derived for values of @xmath638 in the proximity of the boundary .",
    "note that since exclusion restriction on the instruments that @xmath643 implies that @xmath644 . in the notation of theorem [ mainexpansion",
    "] , this means that @xmath645 , and hence the term corresponding to @xmath646 is equal to zero and does not need to be considered .",
    "now let @xmath647 denote the sum of the function @xmath67 and the leading term of the expansion ( [ expsi ] ) , and denote the remainder term by @xmath648 .",
    "then it follows from , for example , @xcite and the conditions on @xmath251 and @xmath252 , that @xmath649 and it follows from the same result together with lemma [ genkern ] in appendix  [ genkern_sec ] that @xmath650 & = & o_p((nh^{1+d_1})^{-{1/2}}).\\end{aligned}\\ ] ] for any fixed values @xmath651 we thus have that @xmath652 where @xmath653 t_{2,n } & = & \\frac{1}{n}\\sum_{i=1}^n \\bigl(\\hat{m}(x_1,z_1,v_i ) - m(x_1,z_1,v_i)\\bigr).\\end{aligned}\\ ] ] being a simple sample average of i.i.d .",
    "mean zero random variables , one can directly see that @xmath654 . using a stochastic expansion for @xmath655 as in the proof of proposition [ proptwostage ] , and applying projection arguments for u - statistics ,",
    "one also finds that @xmath656 . now consider the term @xmath657 . from the expansion in ( [ expsi ] )",
    ", it follows that for any fixed values @xmath651 we have that @xmath658 \\\\[-9pt ] \\qquad & & { } + o_p((nh^{1+d_1})^{-1/2})\\nonumber.\\end{aligned}\\ ] ] this in turn implies that @xmath659 using again projection arguments for u - statistics .",
    "the following auxiliary lemma states uniform rates for averages of i.i.d .",
    "mean zero random variables weighted by `` kernel - type '' expressions .",
    "it is used in the proofs of several of our results .",
    "modifications of the lemma are well known in the smoothing literature ; see , for example , @xcite .",
    "the lemma can be proved by standard smoothing arguments .",
    "one can proceed by using a markov inequality as in the proof of lemma [ lematheo1 ] , but without making use of a chaining argument .",
    "[ genkern ] assume that @xmath660 is a compact set , and @xmath661 is a kernel - type function that satisfies @xmath662 for @xmath663 for some deterministic sequence @xmath664 , and @xmath665 a continuously differentiable function , for any @xmath666 and @xmath667 .",
    "furthermore , assume that @xmath668 with @xmath669 bounded , and that @xmath670<c$ ] a.s . for a constant @xmath112 and @xmath671 small enough .",
    "then we have that @xmath672 for any deterministic sequence @xmath594 with @xmath673 .",
    "we would like to thank the associate editor and three anonymous referees for their comments ."
  ],
  "abstract_text": [
    "<S> we analyze the statistical properties of nonparametric regression estimators using covariates which are not directly observable , but have be estimated from data in a preliminary step . </S>",
    "<S> these so - called generated covariates appear in numerous applications , including two - stage nonparametric regression , estimation of simultaneous equation models or censored regression models . </S>",
    "<S> yet so far there seems to be no general theory for their impact on the final estimator s statistical properties . </S>",
    "<S> our paper provides such results . </S>",
    "<S> we derive a stochastic expansion that characterizes the influence of the generation step on the final estimator , and use it to derive rates of consistency and asymptotic distributions accounting for the presence of generated covariates .    ,    .    </S>"
  ]
}