{
  "article_text": [
    "verification is an increasingly important aspect of control system design . in particular for safety - critical systems , such as aircraft , satellites , and autonomous vehicles ,",
    "it is crucial to certify that the controllers designed for these systems will not lead to costly failures , namely that the state of the system will not reach unsafe regions of the state space .",
    "model - based verification is gaining traction as a tool for assessing safety of control systems @xcite , but is only as accurate as the model being used .",
    "an often overlooked model feature is the unavailability of the full state of the system for feedback control . in such cases a controller",
    "may be designed as if the full state were available , and then a state estimate is used in place of the actual state . in doing so , any properties",
    "the controller is designed for ( linearisation , stability , safety ) are no longer guaranteed .    for nonlinear systems , it is difficult to design feedback controllers to achieve desired performance , even when the full state is known .",
    "linear systems , on the other hand , are well - studied with an array of tools available for controller design . if possible",
    ", it is therefore desirable to feedback linearise a nonlinear system to then apply techniques from linear control theory @xcite .",
    "this technique , however , requires full knowledge of the state and no uncertainty in the model .",
    "when the state is unknown , or known only partially , an observer can be used to estimate it . for systems transformable to normal form",
    "@xcite , a nonlinear high - gain observer ( hgo ) can rapidly reconstruct the actual state because the error dynamics quickly stabilize @xcite .",
    "if the hgo output is used in place of the actual state in a feedback controller , the output feedback trajectory approximately recovers the trajectory that would arise under state feedback , after a brief transient period in which the estimation errors are large @xcite .",
    "the implication for feedback linearisable systems is that under certain conditions , linearisation ( approximately ) still holds under output feedback , and controller synthesis techniques for linear systems still apply @xcite .",
    "these results , however , typically are used only for stabilization and reference tracking objectives ( as in @xcite ) , and have not been utilized in a verification context .",
    "alternately , verification and controller synthesis with safety objectives are well - studied for fully observable systems .",
    "a common approach for nonlinear systems is to use an optimal control formulation that relies on hamilton - jacobi - bellman equations and discretization - based approximate solutions , to find the maximal set of initial conditions that lead to trajectories that do not violate safety constraints @xcite , @xcite , @xcite .",
    "feedback linearising controllers are synthesized in @xcite , using the above formulation to ensure that safety specifications are satisfied and that the controller does not saturate .",
    "controller synthesis for _ partially observable _ systems that are guaranteed to obey safety constraints ( i.e. correct - by - design control ) is much less studied . for stochastic systems , @xcite , @xcite",
    "provide an optimal control formulation to synthesize safety maximizing controllers , which use as input a probability distribution that captures any knowledge about the state of the system .",
    "an output feedback controller linked to an observer is synthesized and proven to satisfy safety specifications for linear stochastic systems in @xcite and for linear deterministic systems in @xcite .",
    "correct - by - design output feedback controllers are synthesized for a class of switched linear systems in @xcite .",
    "this work , to the best of our knowledge , is the first to synthesize controllers with safety guarantees for a class of _ nonlinear _ systems .",
    "we consider full state feedback linearisable systems in normal form , and construct a high - gain observer in order to recover the desired trajectory using output feedback . _",
    "our contributions are a ) the derivation of explicit bounds on the distance between trajectories under state feedback and trajectories under output feedback using an hgo , and b ) the synthesis of feedback linearising controllers that satisfy certain specifications ( such as stability , trajectory tracking , etc . ) that are also provably safe and do not violate any control saturation constraints .",
    "_ we achieve this by utilizing the bound we derive between trajectories to design controllers as if the state were available for feedback , and by using a more conservative safety constraint that is a function of that bound .",
    "we consider a nonlinear single - input , single - output system in normal form @xcite that is full state feedback linearizable : @xmath0 \\\\      y & = cx ,       \\end{aligned}\\ ] ] with @xmath1 the state is @xmath2 , the output is @xmath3 , and the control input is @xmath4 .",
    "any system with relative degree @xmath5 can be put into the form @xcite . for simplicity , in this work",
    "we assume that the system does not have zero dynamics , although an extension to this case is possible ( see @xcite ) .",
    "we also raise the following mild assumption on the model dynamics .",
    "[ ass3 ] the functions @xmath6 and @xmath7 are locally lipschitz continuous in @xmath8 for all @xmath9 , locally bounded over @xmath10 , and @xmath11 .",
    "@xmath12    given assumption [ ass3 ] , if the state @xmath8 were available for feedback and there were no restrictions on the magnitude of the control input , we could design a control law @xmath13 , @xmath14 to render the system linear , thus obtaining @xmath15 where @xmath16 is a reference signal .",
    "a control signal @xmath17 , however , is in general subject to a saturation condition such as @xmath18 , i.e. @xmath19 with @xmath20 $ ] .",
    "this saturation condition is imposed as follows : whenever @xmath21 lies inside the set @xmath22 , it does not saturate , but as soon as @xmath23 , it takes the value @xmath24 .",
    "if we let @xmath25 represent the controller without saturation constraints , then the actual implemented controller is defined as follows : @xmath26 further , in view of the state @xmath8 is not available to the controller as in , and the output @xmath27 must be used instead .",
    "we would therefore like to design a state estimate @xmath28 that is as close to @xmath8 as possible , in order to approximately feedback - linearise the system .",
    "we use a high - gain observer ( hgo ) of the form @xmath29 + h(\\epsilon)(y - c\\hat{x})\\ ] ] to construct an estimate of the state @xmath8 of .",
    "high - gain observers have been used for nonlinear systems because of their robustness to model uncertainty and fast convergence to the true state @xcite . the observer gain",
    "@xmath30 is a function of a positive parameter @xmath31 , and takes the form @xmath32 with the @xmath33 selected such that the polynomial @xmath34 is hurwitz ( roots in the open left half plane ) .",
    "the selection of the @xmath33 guarantees that the error dynamics , defined over the signal @xmath35 , are stable . by picking @xmath31 arbitrarily small",
    ", the error dynamics converge to zero arbitrarily quickly .",
    "however , hgos suffer from an initial peaking phenomenon before rapidly converging to the true state ( i.e. the state estimate at early stages can be very large compared to the actual state ) . as such , if the controller @xmath21 is replaced by @xmath36 , this leads to erroneous control inputs early on .",
    "one partial remedy that we employ is to saturate the controller to avoid large magnitude control inputs @xcite .",
    "we are interested in constructing feedback linearizing controllers for nonlinear systems that simultaneously satisfy both state and control input constraints ( for safety requirements and due to saturation , respectively ) , given that the state is not available for feedback .",
    "more precisely , given a set @xmath37 that we would like the system trajectory @xmath38 to remain within ( and that lies within the set @xmath10 over which assumption [ ass3 ] is valid ) , we would like to find the set of _ all _ initial states @xmath39 ( denoted as the safety - invariant set ) which , under a class of feedback linearizing controllers , generate trajectories that remain within @xmath40 and respect the control constraints @xmath19 for all @xmath41 , where @xmath42 .",
    "[ def : invariance ] the safety - invariant set @xmath43 is the set of all initial states @xmath39 that , under a given feedback controller @xmath21 , produce trajectories @xmath38 that remain within the safe set @xmath40 without violating the control constraint @xmath19 for all @xmath41 , with @xmath44 . @xmath12    we additionally raise the following assumptions on @xmath40 and the initial state @xmath39 ( the latter being non - trivial as it is required for subsequent results ) . the notation @xmath45 is used to denote the boundary of set @xmath46 .",
    "[ ass : xsafe ] the set @xmath40 is a compact set contained in @xmath10 ( from assumption [ ass3 ] ) , and @xmath47 ( so @xmath39 must lie in the interior of @xmath40 ) . @xmath12    the linearising controller @xmath21 may be designed to stabilize the system , track a given reference trajectory , etc .",
    ", and the safety - invariant set tells us from which initial states @xmath48 the trajectory must initialize to further satisfy given state and control constraints .",
    "we could as well introduce a parametrized controller @xmath49 , as in @xcite , to try and maximize the size of the safety - invariant set @xmath43 over @xmath50 .",
    "if we use a parametrized controller , however , @xmath43 will be maximal only with respect to the imposed structure on the controller that targets the other control objectives ( e.g. , linearization plus stability ) .",
    "the interest in maximizing the size of @xmath43 is motivated by the general absence of exact knowledge on @xmath39 beyond the assumption that it lies within @xmath40 , thus we seek to increase the validity of the controller we have designed over unknown initial conditions @xmath39 .",
    "once a set @xmath43 is computed ( regardless of whether it is maximized with respect to a parameter ) , we have both synthesized a controller that meets performance specifications and obtained a guarantee on its safety given the set of initial states .",
    "there are several ways to compute safety - invariant sets for dynamical systems ; here we use an approach based on reachability analysis @xcite .",
    "the safety - invariant set is the complement of the set of initial states that will eventually exit @xmath40 , and therefore we can compute the _ backwards reachable set _ starting from all states outside of @xmath40 .",
    "the set complement , @xmath51 , is propagated backwards in time through the closed loop dynamics to find the set of initial states starting inside of @xmath40 that end in @xmath51 .",
    "this can be done for a purely deterministic system ( when the reference input @xmath16 in is identically zero ) or a non - deterministic system ( reference input is allowed to vary ) . in the non - deterministic case ,",
    "the safety - invariant set may encompass trajectories that remain within @xmath40 for _ any possible _ choice of @xmath16 ( i.e. even `` adversarial '' inputs that try to drive @xmath38 outside of @xmath40 ) , or for a _ single _ , optimal input @xmath16 , that acts to keep @xmath38 within @xmath40 .",
    "for instance , the reference input @xmath16 can be treated as the parametrization constant @xmath50 of the linearising controller @xmath49 , and the safety - invariant set is then maximized with respect to @xmath16 ( while still satisfying the saturation constraints ) . for deterministic dynamics with @xmath52 , we can still parametrize the controller when there are multiple possibilities to linearise the system ( an instance is discussed in the case study ) . note that in this case we limit our focus to a _ constant _ parameter @xmath50 , whereas in the non - deterministic case @xmath16 is typically allowed to change with time , hence we consider signals @xmath53 .",
    "the backwards reachable set is computed using a hamilton - jacobi formulation ( which allows us to minimize the safety - invariant set over @xmath54 , if desired ) @xcite , and while difficult to solve exactly in practice , can be approximated using well - established discretization methods , such as those implemented in the level set toolbox @xcite .",
    "other computational approaches include viability kernel methods @xcite , which rely on propagating certain types of shapes through linear dynamics to avoid discretization .    in this work ,",
    "state @xmath8 is not available as input to function @xmath55 , so we must compute @xmath43 under the additional constraint that the control input is provided by @xmath36 , with @xmath56 the output of an hgo .",
    "the safety - invariant set computed under output feedback , rather than state feedback , will be denoted as @xmath57 .",
    "while computing reachable ( and hence safety - invariant ) sets is well established given the feedback controller @xmath21 and a possible reference signal @xmath16 , neither linearisation nor satisfaction of the control constraints are guaranteed under the output feedback controller @xmath36 , and the computation of @xmath58 becomes more difficult .",
    "first , we would need to keep track of both @xmath8 and @xmath56 , doubling the dimensionality of the system , which severely limits the applicability of discretization methods .",
    "second , we would no longer have linear closed - loop dynamics , and could not use the viability kernel methods that are suitable to higher dimensional systems so long as the dynamics are linear .",
    "it is therefore desirable to first design a controller under the assumption that the state is available for feedback , compute @xmath43 , and then _ formally relate _",
    "@xmath43 to @xmath57 under output feedback . in summary :    given a full state feedback",
    "linearisable system whose state is not fully available for control ,    1 .",
    "compute a high - gain observer that converges to the original dynamics as quickly as possible ; 2 .",
    "compute a feedback linearising controller @xmath21 ( or @xmath49 ) , and the corresponding safety - invariant set @xmath43 ( possibly maximizing @xmath43 as a function of @xmath50 ) , and quantitatively relate @xmath43 to @xmath58 under the condition that @xmath21 is replaced by @xmath36 .",
    "in order to address problem 1 , we first provide a result on the convergence of trajectories under output and state feedback , which generates an upper bound on the distance between closed - loop trajectories .",
    "we can therefore first compute @xmath43 , and use the bound between state and input trajectories to derive quantitative claims about @xmath58 .",
    "the trajectory @xmath38 under output feedback recovers the desired trajectory @xmath59 under state feedback , namely the solution of @xmath60 , provided assumptions [ ass3 ] and [ ass : xsafe ] are satisfied , and @xmath61 .",
    "this known result @xcite is typically presented in the context of feedback stabilization , and asymptotic guarantees on convergence are provided as a function of @xmath62 ( the parameter of the hgo ) . in this work , rather than only providing asymptotic results @xcite , we discuss precise upper bounds on the distance between @xmath38 and @xmath63 , as a function of @xmath31 .",
    "further , whereas @xcite shows that stability of the origin is preserved under output feedback , and gives an @xmath64 bound on the distance between trajectories based on their convergence towards the origin , we show convergence of trajectories to each other as @xmath62 without the assumption that the control law is stabilizing . note that without stability assumptions , the following result is only valid for finite time horizons @xmath65 ( we will later address the infinite horizon case ) .",
    "[ thm : trajectoryconv ] given a nonlinear system satisfying assumptions [ ass3]-[ass : xsafe ] , a time horizon @xmath65 , and a desired bound @xmath66 , there exists a parameter @xmath31 for a high - gain observer , such that @xmath67 for all @xmath41 .",
    "@xmath12    the proof follows directly from singular perturbation theory , and in particular what is known as tikhanov s theorem @xcite .",
    "we focus on characterising the bound @xmath68 exactly as a function of @xmath31 , and show that @xmath68 can be made arbitrarily small as @xmath62 . for verification purposes , however , we are more interested in the value of @xmath68 for a given @xmath31 , rather than the limiting behaviour as @xmath62 , since the earlier will establish a connection between @xmath43 and @xmath57 . note that the restriction of @xmath38 to @xmath40 means that in practice we only require @xmath69 , i.e. we do not require lipschitz or boundedness conditions on outside of @xmath40 .",
    "the relation to singular perturbation theory is seen by replacing the observer dynamics with a scaled version of the estimation error : @xmath70 we can then write @xmath71 , with @xmath72 a diagonal matrix with entries @xmath73 $ ] .",
    "the combined state and observer dynamics can then be written as @xmath74\\\\          \\epsilon\\dot{\\eta } & = \\lambda \\eta + \\epsilon b[b(x ) + a(x)g(x - d(\\epsilon)\\eta ) \\\\          & \\hspace{15mm}- b(\\hat{x } ) - a(\\hat{x})g(x - d(\\epsilon)\\eta ) ] ,           \\end{aligned}\\ ] ] with @xmath75 the system is a standard singularly perturbed system @xcite .",
    "we can think of the @xmath8 dynamics as the `` slow '' subsystem , and the @xmath76 dynamics as the `` fast '' subsystem .",
    "the design of the matrix @xmath30 for the high - gain observer in ensures that the matrix @xmath77 is stable . if we scale time through the change of variable @xmath78 , and then let @xmath79 , the subsequent boundary - layer system @xmath80 has an isolated , asymptotically stable root at @xmath81 @xcite .",
    "the reduced system that results from setting @xmath81 in is the system we would _ like _ to have ( system with state feedback designed to satisfy all the properties that we have specified ) , whose trajectory we denote by @xmath63 ( cf .",
    "notation at the beginning of this section ) .    the motivation for studying the singularly perturbed problem is as follows .",
    "first , the fast variable @xmath76 varies quickly , and is approximated by the boundary - layer system in . because of the difference in time scales , @xmath8 varies little in this period , and remains close to its initial condition @xmath39 .",
    "then , as @xmath76 has converged to its equilibrium point , the slow variable takes over , and the behaviour of @xmath8 can be approximated by the reduced system @xmath82 ( obtained with @xmath83 ) .",
    "we will formalize the amount that each variable can change during these time periods , in order to get bounds on the distance between @xmath38 and @xmath63 .",
    "here we do not provide the full proof of theorem [ thm : trajectoryconv ] , which is quite lengthy and similar to that in @xcite , but outline the necessary steps .",
    "we first make claims on the behaviour of @xmath76 , and then describe the behaviour of @xmath8 as a function of @xmath76 .    1 .",
    "because the boundary - layer system is stable , there exists a lyapunov function @xmath84 , such that @xmath85 .",
    "further , there exists a constant @xmath86 such that @xmath87 is a positively invariant set , for any @xmath88 ( @xmath89 is the lipschitz constant associated with the variable @xmath8 for @xmath90 , to be further explained shortly ) .",
    "2 .   the variable @xmath76 enters @xmath91 in finite time @xmath92 , with @xmath93 .",
    "3 .   before @xmath76 enters @xmath91 , we can pick @xmath94 , @xmath95 , such that @xmath67 , for @xmath96 .",
    "4 .   once @xmath76 enters @xmath91 , we can choose @xmath97 , @xmath98 such that @xmath67 .    without going into full details ,",
    "we can elaborate upon the bounds on @xmath99 in steps 3 ) and 4 ) above , as follows . for @xmath100 , @xmath101 and for @xmath102 , @xmath103",
    "the constants used in and are as follows .",
    "the lipschitz constant @xmath89 associated with the variable @xmath8 for @xmath90 is guaranteed to exist by assumption [ ass3 ] , since both @xmath104 and @xmath105 are lipschitz continuous in @xmath8 , and therefore @xmath90 is lipschitz in @xmath8 .",
    "constant @xmath106 is defined as @xmath107 , and @xmath108 is the lipschitz constant associated with @xmath21 defined in , which again exists by assumption [ ass3 ] .",
    "the notation @xmath109 refers to the smallest eigenvalue associated with matrix @xmath110 .",
    "we define constant @xmath111 as a bound on the initial distance between @xmath39 and @xmath112 , which we can guarantee exists if we set @xmath61 and impose assumption [ ass : xsafe ] .",
    "given a neighbourhood @xmath113 , based on assumption [ ass3 ] we claim that @xmath114\\|_2\\leq c_1,\\ ] ] for all @xmath115 .",
    "we require @xmath116 so that the neighborhood @xmath117 is contained in @xmath40 , and therefore assumption [ ass3 ] applies . finally , @xmath118 .    for a given constant @xmath68",
    ", we can pick @xmath119 small enough such that @xmath120 for @xmath121 using .",
    "we can also pick @xmath122 such that @xmath123 for @xmath102 using . by taking @xmath124 ,",
    "we guarantee that @xmath67 for all @xmath41 .",
    "the upper bound @xmath125 is required to ensure the positive invariance of @xmath91 .",
    "notice that , as @xmath62 , @xmath126 uniformly over @xmath127 .",
    "equations and therefore provide both a direct way of computing @xmath68 for a given @xmath31 ( by taking the maximum of the right hand side of both equations ) _ or _ for verifying the maximum value @xmath31 can take to achieve a desired bound @xmath68 .",
    "theorem [ thm : trajectoryconv ] is not specific to feedback linearisable systems , i.e. @xmath128 can be replaced by a more general lispchitz continuous function @xmath129 .",
    "a possibly tighter bound is available for linearizable systems with control input , because an explicit solution to is available of the form @xmath130 , and therefore can be refined .",
    "the next lemma considers the scenario when the linearising controller asymptotically stabilizes the system , and @xmath21 is given by with @xmath52 and @xmath131 chosen to stabilize @xmath132 . in this instance",
    "we can get a tighter bound on @xmath133 , because @xmath132 has negative eigenvalues , thus the quantity @xmath134 does not increase with @xmath135 .",
    "[ lem : tighterbound ] for the feedback linearizable system in satisfying assumption [ ass3 ] , high - gain observer with parameter @xmath31 , controller @xmath136 with @xmath131 chosen such that @xmath132 is stable , and time horizon @xmath137 , the upper bound on @xmath138 is given by for @xmath96 , and by @xmath139\\epsilon               \\end{gathered}\\ ] ] for @xmath140 .",
    "@xmath12    notice that the matrix @xmath141 is assumed to be diagonalisable , and if not it can be put into jordan form .",
    "then @xmath142 , with @xmath143 the matrix of ( generalised ) eigenvectors , and @xmath144 the diagonal or jordan matrix containing the eigenvalues ( with negative real part ) .",
    "the constant @xmath145 , and all other constants coincide with those in theorem [ thm : trajectoryconv ] .",
    "we can now use theorem [ thm : trajectoryconv ] ( and , by extension , lemma [ lem : tighterbound ] ) to show how to compute set @xmath58 by computing the corresponding set @xmath43 under state feedback .",
    "we first provide a finite time horizon result , which does not require any stability assumptions on the controller @xmath21 .",
    "we will denote , for a given parameter @xmath146 , the restricted set @xmath147 , where @xmath148 is the boundary of @xmath40 .",
    "[ thm : invariance ] for the feedback linearisable system satisfying assumption [ ass3 ] , the high - gain observer with parameter @xmath31 , safe set @xmath40 and control constraint @xmath22 , and given the finite time horizon @xmath137 , the safety invariant set @xmath43 , computed using state feedback , @xmath22 and @xmath149 ( with @xmath68 the bound between trajectories @xmath38 and @xmath150 provided in theorem [ thm : trajectoryconv ] ) , is an underestimate of the safety invariant set @xmath58 under output feedback for the original safe set @xmath40 . @xmath12    note that for some choices of @xmath31 , the associated @xmath68 may exceed the diameter of @xmath40 , in which case @xmath58 will be the empty set .",
    "we assume that @xmath31 can be chosen small enough , and hence @xmath68 is small enough , to render @xmath58 nonempty ( although an empty @xmath58 is also informative ) . from theorem [ thm : trajectoryconv ] , we know",
    "that for any @xmath151 , there exists a corresponding @xmath68 such that @xmath67 for all @xmath152 $ ] .",
    "therefore , for a given @xmath153 , if we can control @xmath63 to remain inside @xmath154 for @xmath152 $ ] , we guarantee that @xmath155",
    ".    we can extend theorem [ thm : invariance ] to the infinite horizon case , provided that the state feedback control law @xmath21 asymptotically stabilizes the origin , as in lemma [ lem : tighterbound ] .",
    "we again employ the control structure in with @xmath52 , and @xmath131 chosen such that @xmath132 has eigenvalues with negative real parts .",
    "[ thm : invariance2 ] for the feedback linearisable system satisfying assumptions [ ass3 ] and [ ass : xsafe ] , the high - gain observer with parameter @xmath31 , safe set @xmath40 , and control constraint @xmath22 , the infinite horizon safety - invariant set @xmath43 , computed using state feedback and constraint sets @xmath149 and @xmath22 ( @xmath68 is again the bound from theorem [ thm : trajectoryconv ] ) , is an underestimate of the safety invariant set @xmath58 under output feedback for the original constraint sets @xmath40 and @xmath22 .",
    "further , the origin remains asymptotically stable under output feedback .",
    "@xmath12    we know from theorem [ thm : invariance ] that , over a finite time horizon , we can underestimate the safety - invariant set @xmath58 by assuming state feedback and using modified constraint sets @xmath149 and @xmath22",
    ". we can extend theorem [ thm : invariance ] to the infinite horizon by constructing a positively invariant set @xmath156 , with @xmath91 the same as in theorem [ thm : trajectoryconv ] , and @xmath157 , the safety - invariant set using an asymptotically stabilizing state feedback controller and constraint sets @xmath40 and @xmath22 .",
    "we only need @xmath158 to be invariant while respecting the original constraint set @xmath40 ( if @xmath159 , then @xmath38 is guaranteed to not leave @xmath40 ) .    under state feedback ( where the control law renders the origin asymptotically stable )",
    ", there exists a lyapunov function @xmath160 for @xmath161 . by definition ,",
    "the set @xmath162 is positively invariant . for @xmath163 ,",
    "the set @xmath158 remains positively invariant under output feedback .",
    "we can show that for @xmath164 , where @xmath165 @xmath38 ( using output feedback ) will have reached @xmath158 .",
    "note that we would like to make @xmath166 as large as possible , to reduce the time it takes for @xmath38 to reach @xmath158 .",
    "therefore , after time @xmath167 , we can guarantee that @xmath168 , with @xmath159 , and that @xmath169 will remain inside @xmath170 for all @xmath171 .",
    "hence for all @xmath171 , we are guaranteed that @xmath38 does not violate the safety constraints , and @xmath36 does not violate the control constraints . before time @xmath167",
    ", we do not have the guarantee on the state constraints , and apply theorem [ thm : invariance ] over the finite time horizon @xmath172 $ ] .",
    "we compute @xmath68 as in theorem [ thm : invariance ] , using and from theorem [ thm : trajectoryconv ] , and shrink @xmath40 appropriately , then compute @xmath173 , which is the infinite horizon safety - invariant set .    in order to ensure the invariance of @xmath158 and @xmath91 , we require an upper bound on the value that @xmath31 can take . from theorem [ thm : trajectoryconv ] , we know that @xmath174 to ensure that @xmath91 is invariant . to ensure that @xmath158 is invariant and that all trajectories outside of @xmath158 enter @xmath158 in finite time requires @xmath175 , with @xmath176 and @xmath177 chosen such that @xmath178 is satisfied , while at the same time @xmath179 .",
    "the constant @xmath180 is equal to @xmath181 , and @xmath182 .",
    "therefore we require @xmath183 .",
    "the recovery of asymptotic stability of the origin can be shown in the same manner as in @xcite .    to summarize",
    ", we can compute a finite or infinite horizon safety - invariant set under output feedback with the following procedures .      *",
    "compute @xmath68 as a function of @xmath31 and time horizon @xmath137 according to and from theorem [ thm : trajectoryconv ] . *",
    "compute @xmath58 using standard reachability techniques for fully observable systems , with state constraints @xmath154 , control constraints @xmath22 , and time horizon @xmath137 .",
    "* compute @xmath43 using @xmath40 and @xmath22 . *",
    "find the largest @xmath166 such that @xmath179 .",
    "* compute @xmath167 according to . *",
    "compute @xmath68 as a function of @xmath31 and @xmath167 according to theorem [ thm : trajectoryconv ] . *",
    "compute @xmath58 using standard reachability techniques for fully observable systems , with state constraints @xmath154 , control constraints @xmath22 , and time horizon @xmath167 .",
    "the obtained set @xmath58 is the safety - invariant set for either the finite or infinite horizon using a controller designed for state feedback , but whose input is an estimate of the state produced by a high - gain observer .",
    "a simple case study that demonstrates the outlined techniques for computing @xmath58 is provided in an extended version of this paper , available at xxxxx .",
    "we consider a simple example to elucidate the synthesis of @xmath21 , the calculation of @xmath31 and @xmath184 , and the construction of @xmath43 and @xmath185 .",
    "the known double integrator has linear dynamics @xmath186 which are already in normal form .",
    "the objective is to design a feedback controller that stabilizes the system to the origin ( in this simple case the system is already linear ) .",
    "we set @xmath187 to obtain the closed - loop dynamics @xmath188 which is asymptotically stable with two complex roots under state feedback .",
    "however , we also assume that only the first state @xmath189 is available , i.e. the output is @xmath190 , and therefore implementing @xmath21 exactly is impossible .",
    "we therefore construct the following high - gain observer , in the form of : @xmath191.\\ ] ] the constants @xmath192 and @xmath193 must be chosen such that @xmath194 has negative roots : they are set to @xmath195 , and the resulting polynomial has two roots equal to @xmath196 .",
    "we further require that the state @xmath38 does not leave the region @xmath197 , and restrict the control input to the condition @xmath198 .",
    "in other words , we seek to stabilize the origin and respect the bounds @xmath40 using a saturating control law of the form with @xmath199 .",
    "we would then like to find the safety - invariant set ( as per definition [ def : invariance ] ) , which is the set of all initial states @xmath39 resulting in trajectories meeting all of the above requirements ( stability , plus state and input constraints ) .    following theorem [ thm : trajectoryconv ] , we let @xmath200 $ ] .",
    "the composed singularly perturbed system is @xmath201 with @xmath202 $ ] .",
    "notice that in this example the term @xmath203 $ ] vanishes because @xmath204 and @xmath205 .",
    "since our first objective was to stabilize to drive trajectories to the origin , we do not want an additional reference input @xmath16 .",
    "we can , however , maximize the safety - invariant set by choosing @xmath50 appropriately .",
    "we compute @xmath43 for varying @xmath50 using a hamilton - jacobi formulation and the level set toolbox , as outlined in @xcite .",
    "[ fig : statefbbeta ] shows the safety - invariant set for varying @xmath50 ( on the @xmath206-axis ) : around @xmath207 the safety - invariant set is the largest , and we therefore select the controller @xmath208 .    , for varying values of @xmath50 .",
    "]    under state feedback , the origin is asymptotically stable and there exists a lyapunov function @xmath209 satisfying @xmath210 .",
    "next , as described in theorem [ thm : invariance2 ] , we would like to find the largest set @xmath211 , with @xmath43 the safety invariant set associated with @xmath207 from fig .",
    "[ fig : statefbbeta ] .",
    "the set @xmath158 with @xmath212 is depicted inside @xmath43 in fig .",
    "[ fig : omega_c ] .",
    "the constant @xmath166 was found manually by simply testing various possibilities and visualising them , although a better way of doing this should be found for higher dimensional model instances .     using state feedback and the fixed control law @xmath213 , for @xmath214 ( in black , external curve ) and the maximal invariant set @xmath215 for @xmath216 ( in purple , smaller ellipsoid ) . ]",
    "we compute @xmath167 and @xmath92 , and then finally @xmath184 .",
    "for @xmath217 , @xmath218 seconds , @xmath219 seconds , and @xmath220 .",
    "if we instead picked @xmath221 , we could reduce @xmath184 to @xmath222 . as expected , as @xmath31 is made smaller , @xmath184 approaches 0 , and we can essentially recover the state feedback safety - invariant set . restricting @xmath31 to 0.01 , the safety - invariant set using @xmath223 is depicted in fig .",
    "[ fig : safetyofb ] , with the original safety - invariant set included for comparison .",
    "( external black line ) versus the output feedback safety invariant set , computed using @xmath223 ( internal red curve ) , for @xmath224 and @xmath220 . ]",
    "a sample trajectory of @xmath63 under state feedback is compared to the trajectory @xmath38 under output feedback with @xmath217 , starting from @xmath225 , in fig .",
    "[ fig : trajectorycompare ] .",
    "note the slight difference with @xmath38 when the trajectory initializes , which is caused by the initial transient period before @xmath92 , when the output feedback controller is saturated and the state feedback controller is not .",
    "the saturation can be seen in fig .",
    "[ fig : controller ] , which compares the state feedback control input to the output feedback control input .",
    "under state feedback ( @xmath63 ) ( blue , dashed ) versus output feedback ( @xmath38 ) ( red ) .",
    "note the initial trajectories difference over the output feedback curve , which is quickly corrected at time @xmath92 . ]    .",
    "the state feedback control inputs are in blue ( dashed ) and the output feedback inputs are in red ( solid line ) .",
    "note the initial saturation of the control inputs for the output feedback trajectory , which corresponds to the initial difference noticeable in fig .",
    "[ fig : trajectorycompare ] . after the initial saturation ,",
    "however , the control inputs quickly almost exactly coincide . ]",
    "this example highlights that not only can we use the presented approach for verification of output feedback systems , but also for the synthesis of controllers that satisfy stability and safety specifications under output feedback , which is a consequence of being able to separate state estimation and control using the high - gain observer .",
    "we can construct a controller that maximises the safety - invariant set @xmath43 under state feedback , apply the same controller to the system with output feedback , and simultaneously produce the maximal safety - invariant set under output feedback .",
    "the one drawback of course is that we do not know @xmath39 exactly , and do not necessarily know if it falls within @xmath58 .",
    "hence the need to maximize @xmath58 , and also to exploit any knowledge we may have about @xmath39 to try to ensure @xmath58 contains the region in which @xmath39 lies .",
    "the use of a high - gain observer design allows us , for a specific class of feedback linearisable models , a ) to design controllers to satisfy certain specifications ( in this work , safety ) as if the full state were available for feedback , and b ) to derive a bound on the distance between the trajectories under state and output feedback , as a function of the observer parameter @xmath31 .",
    "given this quantitative bound , if we can select @xmath31 as small as needed , we can completely recover whatever properties are satisfied under full state feedback .",
    "possible extensions include feedback linearisable systems with zero dynamics and model uncertainty , which are discussed in @xcite and are aligned with the approach discussed in this work . on the other hand , convergence of @xmath56 to @xmath8 using a high - gain observer in the presence of output disturbances ( e.g. , @xmath226 unfortunately does not hold",
    ". however , we may still be able to obtain a bound on the distance between trajectories , even if we can not claim that the bound converges to zero with time .",
    "another straightforward extension is to consider more complex temporal properties , such as reach - avoid or other ltl specifications .",
    "the difficulty of dealing with more general ltl specifications is in the construction of the state feedback controller , which typically is done by resorting to formal ( finite - state ) abstractions @xcite , possibly coupled downstream with the design of an incrementally stabilizing controller , and which may violate the lipschitz continuity assumptions required for the feedback controller in this work .",
    "h.  k. khalil and l.  praly , `` high - gain observers in nonlinear feedback control , '' _ international journal of robust and nonlinear control , special issue on high - gain observers in nonlinear feedback control _ , vol .",
    "993  1015 , 2014 .",
    "c.  tomlin , g.  j. pappas , and s.  sastry , `` conflict resolution for air traffic management : a study in multiagent hybrid systems , '' _ ieee transaction on automatic control _ , vol .",
    "43 , no .  4 , pp . 509",
    " 521 , 1998 .",
    "i.  mitchell , a.  bayen , and c.  tomlin , `` a time - dependent hamilton - jacobi formulation of reachable sets for continuous dynamic games , '' _ ieee transactions on automatic control _",
    ", vol .  50 , no .  7 , pp .",
    "947957 , 2005 .      m.  oishi , i.  mitchell , c.  tomlin , and p.  saint - pierre , `` computing viable sets and reachable sets to design feedback linearizing control laws under saturation , '' in _ ieee conference on decision and control _ , 2006 , pp .",
    "3801  3807 .",
    "o.  mickelin , n.  ozay , and r.  m. murray , `` synthesis of correct - by - construction control protocols for hybrid systems using partial state information , '' in _ american control conference _ , 2014 , pp .",
    "23052311 .",
    "j.  maidens , s.  kaynama , i.  mitchell , m.  oishi , and g.  dumont , `` lagrangian methods for approximating the viability kernel in high - dimensinoal systems , '' _ automatica _ , vol .",
    "49 , no .  7 , pp .",
    "2017  2029 , 2013 .",
    "m.  zamani , m.  esfahani , r.  majumdar , a.  abate , and j.  lygeros , `` symbolic control of stochastic systems via approximately bisimilar finite abstractions , '' _ ieee transactions on automatic control _",
    "59 , no .  12 , pp .",
    "31353150 , 2014 ."
  ],
  "abstract_text": [
    "<S> a high - gain observer is used for a class of feedback linearisable nonlinear systems to synthesize safety - preserving controllers over the observer output . a bound on the distance between trajectories under state and output feedback </S>",
    "<S> is derived , and shown to converge to zero as a function of the gain parameter of an observer . </S>",
    "<S> we can therefore recover safety properties under output feedback and control saturation constraints by synthesizing a controller as if the full state were available . </S>",
    "<S> we specifically design feedback linearising controllers that satisfy certain properties , such as stability , and then construct the associated maximal safety - invariant set , namely the largest set of all initial states that are guaranteed to produce safe trajectories over a given ( possibly infinite ) time horizon . </S>"
  ]
}