{
  "article_text": [
    "the point - agape collaboration has carried out a pixel - lensing survey of m31 using the wide field camera ( wfc ) on the 2.5 m isaac newton telescope ( int ) on la palma . over a period of three years",
    "we have monitored two fields ( each @xmath0 ) , located north and south of the m31 bulge , with the intention of discovering massive compact halo objects ( machos ) via their microlensing ( ml ) signatures and placing constraints on the mass fraction of such objects .",
    "these surveys use what is termed the  superpixel \" method , which minimizes seeing variations by combining the input of the @xmath1 array of pixels around each pixel to give a superpixel lightcurve @xcite .",
    "the reason that @xmath1 is the optimal array size has been discussed by @xcite .",
    "the first ml event resulting from this survey was reported by @xcite .",
    "this and a further three ml candidates were then presented by @xcite , one of which was argued to be a binary lens by @xcite .",
    "subsequently a more extended list of seven candidates was reported by @xcite .",
    "other experiments searching for ml in m31 with the superpixel method were agape @xcite , who obtained one candidate , slott - agape @xcite , who obtained four , and nainital @xcite , who obtained one more .    in all these surveys ,",
    "the selection of the ml candidates involved a certain amount of manual intervention .",
    "for example , in the first point - agape analysis of the full dataset ( performed in paris ) the initial steps were carried out by computer but the final steps required some selection by eye . however , in order to obtain proper statistics on the number of machos and to compare with theoretical models @xcite , one has to calculate the detection efficiency .",
    "this means that the candidate selection must be carried out objectively , so one has to develop a fully automated algorithm for this purpose .",
    "the point - agape collaboration has now carried out three automated analyses , these centering around the groups based at cambridge , zurich and london . for convenience , we refer to these as the cambridge , zurich and london `` pipelines '' .",
    "however , it should be stressed that the full point - agape collaboration contributed to all of these analyses , including members based at paris and liverpool , so there was considerable interdependence between the three pipelines .",
    "the place labels therefore merely serve as a useful shorthand .",
    "the analyses performed at cambridge and zurich have already been published @xcite and this paper contains the first presentation of the london analysis .",
    "it should be noted that the london and cambridge analyses are closely related , in that they start with the same list of variable superpixel lightcurves , but the zurich analysis starts with a different list .    besides searching for ml events ,",
    "an automated analysis can also be used to search for variable stars in m31 .",
    "a first search for variable stars in the point - agape data has been presented by @xcite , while @xcite at liverpool have used the database to look for classical novae .",
    "various methodological issues arise in automated searches for ml events and variable stars .",
    "the first step in such a search is the selection of the initial catalogue of superpixel lightcurves , which was provided by @xcite .",
    "however , one feature of the superpixel method is that any bright varying source may appear in more than one superpixel and this leads to multiple - counting of variable lightcurves .",
    "this is dealt with by retaining only the lightcurve with the highest peak flux but some  replicates \" ( as we term them ) may remain in certain circumstances .",
    "another problem is that spurious variations may be induced in a light source by nearby resolved stars ( due to either seeing or intrinsic variations ) and bad pixels .",
    "indeed resolved stars and bad pixels also generate replicates .",
    "therefore a crucial prerequisite in the production of a catalogue of  cleaned \" lightcurves is the masking of resolved stars and the removal of spurious data - points associated with various kinds of bad pixels .",
    "unfortunately , due to imperfections in the masking procedure , some bad pixels may be left unmasked and this may introduce spurious variability into lightcurves .",
    "this can increase the number of short - timescale  spike \" events but it may also reduce the number of ml candidates , since there will be extra bumps which do not fit the standard point - source point - lens lightcurve @xcite .",
    "on the other hand , if the mask is too extensive , one will inevitably lose ml candidates because the removal of good pixels will reduce the number of points on the lightcurves .",
    "any inaccuracy in the positioning of the masks will also lead to these problems . therefore",
    "a degree of compromise is involved in selecting an efficient mask and it is important to estimate the inaccuracies introduced by this compromise .",
    "these problems have been studied in detail by @xcite and are discussed in a separate paper @xcite .    even after the construction of the masks , automated searches still require a choice of the cuts used in selecting ml events from the variable lightcurves and there is considerable scope for disagreement here .",
    "although london and cambridge collaborated in the selection of the resolved star and bad pixel masks and the generation of cleaned lightcurves , the analyses thereafter were largely independent .",
    "the importance of this problem is implicit in the paper of @xcite , where candidates are grouped into three different classes , according to the severity of the cuts employed .",
    "the london list of ten candidates reported here contains two of the three  first - level \" cambridge candidates , one of their three  second - level \" candidates but ( probably ) none of their  third - level \" candidates .",
    "it is less straightforward to make a comparison with the analysis of @xcite because the zurich group used smaller masks than london and cambridge and their analysis was less automated .",
    "although one might expect the first factor to lead to more ml candidates , they also introduced extra cuts which neither london nor cambridge use , which should reduce the number of candidates .",
    "their list of six events includes the two first - level cambridge candidate also detected by london , but none of the other london or cambridge candidates .",
    "one of the purposes of this paper is to understand why these three parallel analyses of the superpixel lightcurves produce different lists of ml candidates .",
    "we do this by making a careful comparison of the various steps in the different analyses .",
    "the fact that different lists are produced does not mean that the analyses are flawed , only that there is a degree of subjectivity involved in the selection of cuts .",
    "particularly crucial is the different ways of eliminating contamination from nearby variable stars and the extent to which one encodes theoretical prejudices into the cuts imposed .",
    "for example , on the basis of prior knowledge of variables and the likely mass range of machos , zurich excluded lightcurves which vary on a timescale longer than 25 days as ml .",
    "although these arguments are plausible , cambridge and london nevertheless looked for candidate ml events over all timescales .",
    "the issue of how to optimize the selection criteria is clearly crucial .",
    "whatever criteria one uses , there are bound to be some genuine events which are eliminated and some spurious events which are included .",
    "there is therefore a trade - off between minimizing the number of false negatives ( genuine ml events which are rejected ) and false positives ( spurious ml events which are accepted ) .",
    "this has also been stressed by evans and belokurov ( 2007 ) in the context of ml searches towards the magellanic clouds .",
    "they conclude that efficiency calculations can correct for the effects of false negatives but not for the effects of false positives , so the best strategy in a ml experiment is to eschew a decision boundary altogether .",
    "instead , they advocate assigning a probability to each lightcurve , so that the ml rate can then be calculated by summing over all the probabilities .",
    "this point of view is even more pertinent in the context of automated superpixel surveys , where the exclusion of false positives and negatives is particularly problematic , so we adopt a similar philosophy here . rather than assuming that one has a definitive list of ml events and inferring an optical depth , it may therefore be more appropriate to associate a probability with each candidate , although we do not attempt to estimate such probabilities in this paper .    the uncertainty about the validity of specific candidates also impinges on the other purpose of the automated ml surveys , which is to obtain constraints on the fraction of the halo mass of m31 in the form of machos , analogous to the similar constraints which have been placed on the macho fraction in our own halo by observations of the magellanic clouds @xcite .",
    "to obtain such limits , one needs to estimate the efficiency of detecting machos in various mass ranges and this can be achieved with monte carlo simulations .",
    "constraints are then derived by comparing the model expectations with the actual number of detected ml candidates , after accounting for the pipeline selection efficiency .",
    "a first attempt at obtaining such constraints was made by @xcite , who concluded that at the 95% confidence level the macho fraction is at least 20% in the direction of m31 for lens masses in the range 0.5 - 1@xmath2 .",
    "the limit drops to 8% for 0.01@xmath2 lenses . in this paper",
    "we use monte carlo simulations to determine the constraints associated with the london pipeline .",
    "however , it must be stressed that there is an important difference between our approaches .",
    "the monte carlo used by @xcite computes the ml rate for their selection pipeline but does not employ any actual data and so does not contain real variables . on the other hand ,",
    "our code superposes artificial lightcurves with a range of ml parameters onto the data in order to determine the efficiency with which they are detected .",
    "not surprisingly , the larger number of ml candidates found by london gives weaker upper limits and stronger lower limits than those found by zurich .",
    "if we neglect the long timescale london candidates , the london and zurich limits on the macho halo fraction are comparable .",
    "indeed , they are both comparable to those obtained from the magellanic cloud observations @xcite .",
    "recently , two more ml candidates have been discovered as part of an automated superpixel survey with the cassini telescope in loiano @xcite .",
    "the status of these candidates  like that of the new london ones  is somewhat uncertain but the authors also infer constraints on the macho halo fraction by carrying out a monte carlo efficiency analysis .",
    "the rationale of their paper is therefore very similar to that of this one .",
    "it should also be noted that other groups have looked for ml in m31 using difference image analysis @xcite .",
    "this includes mega @xcite , who obtained 14 candidates , columbia - vatt @xcite , who obtained four , and wecapp @xcite , who obtained two .",
    "the plan of this paper is as follows : in section 2 we review the observations and theory of pixel lensing and discuss the construction of the variables catalogue . in section 3",
    "we describe the cuts used in the london analysis and compare these with the ones used by cambridge and zurich . in section 4",
    "we discuss the london list of ml candidates . in section 5",
    "we compare this with the lists of cambridge and zurich , as well as that of mega .",
    "in section 6 , we use monte carlo simulations to infer constraints on the halo mass fraction of m31 . in section 7",
    "we draw some general conclusions .",
    "as described by @xcite , the analysed data were taken over three seasons ( 1999 - 2001 ) in three filters ( @xmath3 ) , with the @xmath4-band monitoring being discontinued after the first year .",
    "the data analysis is described in detail in previous literature @xcite , so we only summarize it briefly here .",
    "after bias subtraction and flat - fielding , we align each frame geometrically and photometrically relative to a list of reference images taken at good seeing . in order to remove correlations in our pixel lightcurves which result from seeing variations",
    ", we then define a @xmath5 superpixel for each pixel on our detector",
    ". however , this does not eliminate such variations completely and the second stage of the seeing correction involves minimizing the residual variations via an empirically derived statistical correction applied to each frame to match it to the corresponding reference frame @xcite .",
    "once the images have been calibrated in this manner , we can deal with the superprixel lightcurves themselves .",
    "the procedure we follow to identify variable lightcurves is based on the method previously presented by @xcite . before we fit any models to the data , we run a preliminary  bump \" identification routine in the @xmath6 filter to discover the number of significant deviations on each lightcurve .",
    "a bump is defined as at least three consecutive datapoints 3@xmath7 above the baseline , followed by three consecutive datapoints within 3@xmath7 of the baseline .",
    "we use the @xmath6 filter because it is more sensitive to lightcurve variations .",
    "cambridge does not use such a routine but zurich does . for each bump in the @xmath6 filter , we calculate an associated peak likelihood value , as described by @xcite , this being a measure of the significance of each bump . for our records",
    "we also calculate the likelihood for bumps in the @xmath8 filter , since the @xmath8-band has more points in the first year .    in a ml event",
    "the images produced by the lensing effect are too small to be resolved , so one can only observe their combined flux .",
    "the resulting lightcurve is achromatic and symmetric in time .",
    "the total magnification evolves according to @xmath9 where @xmath10^{1/2}\\ ] ] is the impact parameter , i.e. the angular separation between the source and lens in units of the angular einstein radius @xmath11 @xcite .",
    "the latter is given by @xmath12^{1/2},\\ ] ] where @xmath13 is the lens mass , @xmath14 the distance of the source star and @xmath15 the distance of the lens in units of @xmath14 .",
    "( 2 ) @xmath16 is the einstein radius crossing time , @xmath17 is the time at maximum magnification and @xmath18 gives the minimum impact parameter .",
    "the classical model described above is not sufficient to describe pixel lensing in m31 . of principal concern",
    "is the fact that @xmath16 is generally inaccessible in our experiment .",
    "this is because the presence of many stars per pixel means that the flux contribution of the unlensed stars dilutes the true ml signal , so the model has to account for this .",
    "therefore the total observed flux at time @xmath19 becomes @xmath20 , where @xmath21 is the * original * flux from the star which is being microlensed and @xmath22 is the blended flux from the other sources .",
    "the observed magnification in this case is @xmath23 since @xmath16 can not always be determined , we use the observed full - width half - maximum duration instead : @xmath24 where @xmath25 and @xmath26 is the peak amplification @xcite",
    ".    c    [ tmaxvsn ]",
    "the fundamental challenge in a superpixel ml survey is to discriminate between the lensing of a star and its possible intrinsic variability .",
    "the london analysis  like that of @xcite  makes two _ global _ fits to the data , one involving ml and the other representing a variable star .",
    "( throughout this section , we will refer to this as `` our '' analysis , even though not all the authors of this paper are from london . )",
    "the ml model has 9 parameters : the einstein crossing time ( @xmath16 ) , the time of maximum magnification ( @xmath17 ) , the maximum magnification ( @xmath26 ) and two flux parameters for each of the three filters , one for the source flux ( @xmath21 ) and another for the background ( @xmath27 ) .",
    "this is an iterative procedure .",
    "we fit the @xmath8 data first , using rough estimates of the parameters as input values and minimising the @xmath28 value by using the downhill simplex method amoeba @xcite . the output of this first fit",
    "is then used as input for a combined fit for @xmath29 and ( if appropriate ) @xmath4 .",
    "using an iterative procedure reduces the risk of our fits diverging .",
    "the second model is sinusoidal , with variable phase and amplitude but with period fixed to the value corresponding to the maximum frequency returned from a lomb periodogram analysis @xcite of the lightcurve in each filter .",
    "variable lightcurves are more complicated than this , of course , but this suffices for our purposes .",
    "note that our variable model is less sophisticated than that of cambridge , as we do not remove any points from the fit during this procedure .",
    "cambridge uses the first 10 values from the lomb periodogram , whereas we only use the most significant one .",
    "each lightcurve is then matched to a _",
    "local _ ml fit .",
    "this is done to ensure that the lightcurve is not contaminated by nearby variable stars , since these may affect the baseline .",
    "this step requires a minimum number of datapoints in the @xmath8-band on either side of @xmath17 , as well as extra datapoints in either the @xmath6 or @xmath4-band .",
    "the precise requirements are specified below . performing a local fit also serves as an achromaticity test , since a good fit in at least two bands necessarily requires a good level of achromaticity .    while performing the local fit , we calculate the signal - to - noise ratio both for the points within some specified time range around the peak , @xmath30 , and outside that range , @xmath31 .",
    "the signal - to - noise is defined as @xmath32 where @xmath33 is the number of datapoints , @xmath34 is the flux associated with the @xmath6th datapoint , @xmath35 is the associated error and @xmath36 is the estimated baseline flux . as discussed below , restrictions on the values of both @xmath30 and @xmath31 must be used in selecting ml candidates .",
    "having completed the global and local ml and variable fits , and obtained the relevant parameters , we require that the lightcurves satisfy a number of cuts .",
    "our first three cuts are already implicit from the previous discussion . at each step",
    "we will indicate the fraction of lightcurves surviving from the previous cut and a summary of the steps and associated fractions is presented in table [ tab : cuts ] . from the input list of 44631 superpixel lightcurves ,",
    "we end up with ten ml candidates and these are discussed in detail in the next section .",
    "we also compare these with the cuts used by cambridge and zurich , discussing the extra cuts imposed by these groups at the end .",
    "since the cuts used by all three groups are different , we need to compare them carefully in order to assess the relative efficiency of the three pipelines .",
    "the cuts are compared in table [ tab : cuts2 ] .",
    "note that , even where the cuts overlap , they may be applied in different orders and this also makes a difference .",
    "[ tab : cuts ]    .number of rejected and surviving lightcurves after each cut of the london pipeline , together with the surviving fraction .",
    "the input catalogue contained 44631 lightcurves .",
    "[ cols=\"<,^,^,^,^,<\",options=\"header \" , ]     [ frac3 ]",
    "we have reviewed results from various automated analyses of three years of data for our pixel lensing survey of m31 .",
    "we have placed particular emphasis on the london analysis , which finds ten candidates . however , this is very dependent on our selection of cuts , so we have made a detailed comparison with the cambridge and zurich analyses .",
    "two of the london events are s3 and s4 , first reported by @xcite , and another is c2.2 , first reported by @xcite . while s3 and s4 are short timescale events , c2.2 is markedly fainter and has a longer fitted timescale .",
    "however , inspection of the frames at minimum and maximum amplification suggests that the variation is caused by real variability of the pixels themselves and not by nearby stars or ccd defects .",
    "this raises the key question of how to decide the selection criteria and how to weight them .",
    "however , the purpose of this paper has been to focus on methodological issues associated with automaticity rather than to assess the strength of any particular ml candidates . in determining optical depths and comparing with monte carlo efficiency calculations",
    ", one only needs to deal with probabilities .",
    "this is also the philosophy adopted by evans and belokurov ( 2007 ) in considering the search for ml events with neural networks .",
    "although their paper focuses on ml searches towards the magellanic clouds , because the technique has not yet been applied to m31 , the same considerations apply here . indeed",
    "the use of neural networks as an efficient , automated and objective method of detecting ml in m31 could be a useful future project .    in order to assess the efficiency of our pipeline we have performed a monte carlo analysis using an input catalogue of 256,000 simulated events . assuming a full halo , we find that the predicted number of stellar lensing events is 0.97 , in agreement with @xcite .",
    "this suggests that most of the candidate events selected by our automated pipeline are due to contamination by variables .",
    "this conclusion is also supported by the significant number of simulated events which survive our pipeline cuts when their fitted timescale disagrees with the input timescale by a factor of two or more .",
    "this is due to the inherent uncertainty associated with the superpixel method in m31 surveys in determining the true einstein crossing times and highlights the difficulties of identifying genuine ml events in m31 .    of",
    "the remaining ml candidates detected by the london pipeline , three lie outside the @xmath37 5 arcmin exclusion zone around the centre of m31 and our analysis then leads to weak limits on the number of macho lenses .",
    "however , our efficiency caclulation suggests that these are unlikely to be genuine ml events but are rather due to contamination of our sample by variables . in this case",
    ", we only have one strong candidate event , s3 , inside the exclusion zone and our macho limits are in agreement with those derived by @xcite .",
    "it must be stressed that different views have been expressed about the strength of the evidence for machos provided by the point - agape analyses . whereas @xcite have stressed that there is good evidence for machos in m31 ,",
    "@xcite have taken a contrary view .",
    "a similar controversy is associated with the lmc and smc surveys .",
    "while @xcite have argued that there is evidence that 20% of the galactic halo is in machos with @xmath38 , the results of the eros survey do not seem to support this @xcite . @xcite have also argued from their reanalysis of the lmc data that there may be no machos . however , this conclusion has been strongly contested by @xcite and this dispute emphasizes the importance of having another independent source of machos . although studies of m31 ( such as are reported in this paper ) may play a crucial role in resolving this issue , we have seen that the methodological difficulties involved in automated superpixel analyses also give scope for disagreement .",
    "this analysis was based on observations made with the int operated on the islandof la palma by the isaac newton group in the spanish observatorio del roque de los muchachos of the instituto de astrofisica de canarias .",
    "we are grateful to s. calchi - novati for helpful comments on an earlier draft of this paper and to other members of the point - agape collaboration : y. an , v. bekokurov , w. evans , p. hewett and s. smartt in cambridge ; y. giraud - heraud , m. creze , j. kaplan and c. s. stalin in paris ; and p. jetzer in zurich .",
    "y. tsapras acknowledges support from a leverhulme postdoctoral grant during the period 2002 - 2004 .",
    "99 alard c. , lupton r. h. , 1998 , apj , 503 , 325 .",
    "alcock c. et al , 2001 , apjs , 136 , 439 an j. et al , 2004 , apj , 601 , 845 ansari r. et al , 1997 , aap , 324 , 843 ansari r. et al , 2001 , aspc , 237 , 235a auriere m. et al , 2001 , apjl , 553 , l137 belokurov v. et al , 2005 , mnras , 357 , 17 calchi novati s. et al , 2002 , aap , 381 , 848 calchi novati s. et al , 2003 , aap , 405 , 851 calchi novati s. et al , 2005 , aap , 443 , 911 calchi novati s. et al , 2009 , apj , 695 , 442 - 454 darnley m. j. et al , 2004 , mnras , 353 , 571 de jong j. t. a. et al , 2004 , aap , 417 , 461 de jong j. t. a. et al , 2006 , aap , 446 , 855 evans n. w. , belokurov v. , 2007 , mnras , 374 , 365 evans n. w. , collett j. l. , 1993 , mnras , 264 , 353 griest k. , thomas c. l. , 2005 , mnras , 359 , 464 ingrosso s. et al , 2007 , a&a , 462 , 895 - 902 joshi y. c. et al , 2005 , aap , 433 , 787 kerins e. et al , 2001 , mnras , 323 , 13 kerins e. et al , 2006 , mnras , 365 , 1099 nader , mead et al , 1965 , computer journal , 7 , 308 paczyski b. , 1986 , apj , 304 , 1 paulin - henriksson s. et al , 2004 , arxiv , 8204 paulin - henriksson s. et al , 2002 , apj , 576 , l121 paulin - henriksson s. , 2002 , phd thesis , college de france paulin - henriksson s. et al , 2003 , aap , 405 , 15 press w. h. , flannery b. p. , teukolsky s.a , vetterling w.t . , 1992 , numerical recipes : the art of scientific computing . , cambridge university press rich r. m. et al , 2005 , aj , 129 , 2670 riffeser a.",
    "et al , 2003 , apjl , 599 , l17 riffeser a. et al , 2008 , apj , 684 , 1093 - 1109 tisserand p. et al , 2007 , aa , 469 , 387 uglesich r. r. et al , 2004 , apj , 612 , 877 weston m. j. , phd thesis , queen mary university of london .",
    "weston m. j. , in prep ."
  ],
  "abstract_text": [
    "<S> searching for microlensing in m31 using automated superpixel surveys raises a number of difficulties which are not present in more conventional techniques . </S>",
    "<S> here we focus on the problem that the list of microlensing candidates is sensitive to the selection criteria or `` cuts '' imposed and some subjectivity is involved in this . weakening the cuts will generate a longer list of microlensing candidates but with a greater fraction of spurious ones ; strengthening the cuts will produce a shorter list but may exclude some genuine events . </S>",
    "<S> we illustrate this by comparing three analyses of the same data - set obtained from a 3-year observing run on the int in la palma . </S>",
    "<S> the results of two of these analyses have been already reported : belokurov et al . </S>",
    "<S> ( 2005 ) obtained between 3 and 22 candidates , depending on the strength of their cuts , while calchi novati et al . </S>",
    "<S> ( 2005 ) obtained 6 candidates . </S>",
    "<S> the third analysis is presented here for the first time and reports 10 microlensing candidates , 7 of which are new . </S>",
    "<S> only two of the candidates are common to all three analyses . in order to understand why these analyses produce different candidate lists , </S>",
    "<S> a comparison is made of the cuts used by the three groups . </S>",
    "<S> particularly crucial are the method employed to distinguish between a microlensing event and a variable star , and the extent to which one encodes theoretical prejudices into the cuts . </S>",
    "<S> another factor is that the superpixel technique requires the masking of resolved stars and bad pixels . </S>",
    "<S> belokurov et al . </S>",
    "<S> ( 2005 ) and the present analysis use the same input catalogue and the same masks but calchi novati et al . </S>",
    "<S> ( 2005 ) use different ones and a somewhat less automated procedure . because of these considerations </S>",
    "<S> , one expects the lists of candidates to vary and it is not possible to pronounce a candidate a definite microlensing event . </S>",
    "<S> indeed we accept that several of our new candidates , especially the long time - scale ones , may not be genuine .    </S>",
    "<S> this uncertainty also impinges on one of the most important goals of these surveys , which is to place constraints on the macho fraction in m31 . </S>",
    "<S> such constraints depend on using monte carlo simulations to carry out an efficiency analysis for microlensing detection and the results should be relatively insensitive to the selection criteria providing the simulations employ the same cuts as the pipelines . calchi novati et al . </S>",
    "<S> ( 2005 ) have already derived the constraints associated with their analysis and we present here the constraints associated with the most recent analysis . </S>",
    "<S> the constraints are similar if we neglect our long timescale events and comparable to those found for machos in our own galaxy by earlier microlensing surveys of the magellanic clouds . however , our constraints are different from those of calchi novati et al . if we include our long timescale events .    </S>",
    "<S> [ firstpage ]    galaxies : m31 , microlensing , point - agape , dark matter  techniques : photometric  </S>"
  ]
}