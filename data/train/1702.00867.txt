{
  "article_text": [
    "quantum electrodynamics ( qed ) allows for the description of all electromagnetic processes occurring between the elementary particles of chemical systems ( e.g. , molecules ) . it is the fundamental theory of chemistry ( focusing on the dominant electromagnetic interactions and ignoring the other fundamental forces ) .",
    "if we were able to solve its equations for some chemical system with arbitrary accuracy , truly predictive results bare of almost all errors would be obtained . however , for all but the simplest systems , calculations based on qed are unfeasible .",
    "additional approximations have to be made for the calculation of an observable of interest to be available in reasonable time and with reasonable effort leading to deviations from the fundamental theory of chemistry . eventually , the number and types of approximations necessary for a feasible description of molecular systems are vast and diverse .",
    "the precise effect of such approximations ( computational models ) on observables derived from them is generally unknown and difficult to estimate for arbitrary molecules @xcite .",
    "while the procedure of uncertainty quantification for physical measurements is well established @xcite , this is not the case for results of computational models ( virtual measurements @xcite ) . by the very nature of a deterministic ( or fully converged stochastic ) calculation ,",
    "the repetition of such a calculation does not lead to an oscillation around the true result , and therefore , there is no obvious approach of reliably estimating prediction uncertainty of the computational model employed .",
    "however , the result of a computational model is incomplete without an accurate uncertainty associated with it @xcite . given a reliable uncertainty measure for a computational result",
    ", one could not only estimate the effects on observables derived from that result ( through uncertainty propagation ) , but also directly assess the quality of approximations in the model - development stage .",
    "finally , availability of prediction uncertainties would help select an appropriate computational model of sufficient accuracy for a problem at hand .",
    "it is generally assumed that performance statistics based on benchmark systems are good estimates for the prediction uncertainty of a quantum chemical method . due to the availability of large amounts of experimental and computational reference data ( for a recent review see ref .",
    "@xcite ) , benchmark studies are carried out to provide statistical quantities such as the mean absolute error ( mae ) , @xmath0 and the largest absolute error ( lae ) , @xmath1 with @xmath2 and @xmath3 being the size of the data set . here",
    ", the error @xmath4 of model @xmath5 with respect to system @xmath6 ( typically a molecule ) is defined as the difference between the calculated result @xmath7 and the experimental or computational reference @xmath8 .",
    "these summarizing statistics are then applied to estimate the prediction uncertainty of a method of choice for a system of interest .",
    "however , there is a major caveat associated with this approach : the assumption that such statistics are transferable to a system not represented in the reference data set is generally invalid . in table",
    "[ tab : maes ] the mae of common density functionals with respect to ligand dissociation energies of transition metal complexes from three previous studies are compared .",
    "the wccr10 data set @xcite consists of 10 ligand dissociation energies of large cationic transition metal complexes .",
    "the 3dbe70 database @xcite contains average bond energies of 70 transition metal compounds .",
    "the data set by furche and perdew @xcite containing 18 dissociation energies of transition metal compounds is herein abbreviated as fp06 .",
    ".mean absolute error ( mae@xmath9 ) of ligand dissociation energies ( kj / mol ) calculated with a selection of common density functionals @xmath5 taken from the literature .",
    "[ cols=\"<,>,>,>,>\",options=\"header \" , ]     the comparison of the different benchmark studies shows that the maes are strongly data set dependent . for instance , the spread of maes ranges from 17.6 to 40.6  kj / mol in the case of the tpssh density functional .    even for small systems such as metal dimers the reported statistics can vary .",
    "for example , for the dissociation energy of metal dimers the study by furche and perdew @xcite and schultz et al .",
    "@xcite report maes of 50.6 and 69.9  kj / mol , respectively .",
    "this finding is in accordance with many studies demonstrating that the accuracy of density functionals varies strongly with the chemical system @xcite , and therefore , undermining the transferability of such performance statistics . in the case of density",
    "functional theory , this lack of transferability is particularly critical to studies on transition metals since most of the benchmark data sets include only small ( unsaturated and therefore atypical ) compounds ( e.g. , transition metal hydrides such as feh ) .",
    "in addition , it can be seen from table  [ tab : maes ] that all maes are considerably large ( a result is said to be within chemical accuracy if the expected error is within @xmath10  kj / mol ) .",
    "for the wccr10 and fp06 data sets laes are reported as well ( e.g. , 83.4 and 157.3  kj / mol , respectively , for the b3lyp functional ) .",
    "mae and lae of this size are unacceptable for studies in which accurate reaction energy are of high importance . in the framework of conventional transition state theory , an error of 30 kj / mol in the barrier height of an elementary reaction step results in a reaction rate that is off by a factor of @xmath11 .",
    "lastly , it should be noted that the uncertainty within the ( experimental and computational ) reference data is generally not accounted for @xcite .    in figure",
    "[ fig : variance ] , we illustrate the system dependency of an arbitrary observable given an adequate computational model ( see section [ sec : inadequacy ] for a definition of model adequacy ) . the transferability of statistical measures such as the mae would only be valid in the ideal case of homoscedasticity ( figure [ fig : variance ] , left ) , where the prediction uncertainty is independent of the input , here , chemical space ( the space of all chemical compounds , e.g.  molecules , where small distances indicate high structural similarity ) .",
    "so far , there exists no strategy to develop approximate quantum chemical methods with system - invariant uncertainty ( homoscedasticity ) , which is not to be confused with strategies to develop systematically improvable methods ( such as the coupled cluster expansion , which still reveals systematic errors due to the truncation of the degree of excitation  even if the degree is taken to be rather high ) .",
    "consequently , we are generally faced with approximations yielding heteroscedastic results ( figure [ fig : variance ] , right ) , where the prediction uncertainty somehow depends on the nature of the chemical system .",
    "this dependency is generally unknown ( not as indicated in the right frame of figure [ fig : variance ] ) , which also implies that estimation of prediction uncertainty for data lying in the same region of the chemical space employed for model training can be unreliable .",
    "noteworthy , the hohenberg ",
    "kohn functional would , in principle , yield results with system - invariant accuracy ( for chemical systems in their electronic ground states ) , however , this is not the case in practice due to the approximations of the exchange ",
    "correlation density functional .          due to the continuous advancement in accurate and efficient black - box methods ( such as explicitly correlated coupled cluster theory , for a review see ref .",
    "@xcite ) and the increase of computational power , it is believed that these gold standard methods will , eventually , become the standard method of choice . in this case",
    ", uncertainty estimation will be less important if chemical accuracy is reached and considered sufficient .",
    "for higher accuracy also standard coupled cluster models will require rigorous error estimation .",
    "although the system size for which these methods are feasible increases due to constant method - development efforts , less accurate methods are usually chosen for feasibility reasons when a large number of calculations must be carried out .",
    "this is the case for extensive explorations of vast reaction networks @xcite , screening studies @xcite , and reactive molecular dynamics simulations @xcite .",
    "the identification and separation of sources of uncertainty is difficult , since multiple approximations of unequal accuracy are made during method development .",
    "for example , in density functional theory , the exact density functional is approximated in a rather involved way . in standard coupled cluster theory , the wave function is based on a single reference ( slater determinant ) . on the one hand , these and other sources of uncertainty may combine in an arbitrary manner and even lead to counter - intuitive total errors @xcite .",
    "for example , coincidental error compensation can lead to overestimation of prediction accuracy .",
    "this is an effect often encountered in density functional theory .",
    "for instance , the success of the b3lyp @xcite functional together with the poor 6 - 31 g * basis set @xcite is often attributed to error cancellation @xcite .",
    "error compensation was also reported for coupled cluster methods , for instance , ccsd(t ) was found to provide more accurate results than ccsdt in combination with certain one - electron basis sets @xcite . on the other hand , there are approximations ( e.g. , considering the atomic nucleus as a point charge rather than as an extended charge distribution , ignoring certain relativistic effects ) that are local ( atomic ) and cancel out for reaction energies ( or valence properties ) .    in recent work @xcite , we discussed the approximations necessary for the calculation of thermochemical properties in liquid phase .",
    "we concluded that the contribution of each approximation to the overall error is difficult to determine but necessary for meaningful conclusions from subsequent analyses such as kinetic studies .",
    "in general , one distinguishes between three main sources of uncertainty : parameter uncertainty , numerical uncertainty , and systematic errors due to inconsistent data and inadequate model approximations ( here , to the fundamental theory of chemistry , qed ) @xcite . except for stochastic models ( e.g. , monte carlo simulations ) ,",
    "numerical uncertainty is expected to be negligible and will not be discussed in the following .",
    "the remaining sources of uncertainty are elaborated on and approaches for their remedy are elucidated .      for the prediction of properties of chemical systems not included in the training of a computational model",
    ", one needs to estimate the uncertainty of its parameters in addition to their `` best '' values ( obtained from minimizing a cost function such as the sum of squared residuals ) .",
    "otherwise , one would neglect a ( potentially essential ) component in determining the prediction uncertainty of a computational model .",
    "parameter uncertainty is a result of random and systematic errors in both the reference data and the computational model under consideration ( see section [ sec : inadequacy ] ) , in particular if the number of reference data is small . only for a large number of data and a given domain of application ( e.g. , a specific volume of chemical space )",
    ", parameter uncertainty becomes negligible .",
    "parameter uncertainty can be estimated in many ways , for example , through bayesian inference @xcite or through resampling methods such as bootstrapping @xcite . in the latter case , the reference data set itself replaces the critical assumption of a parametric population distribution underlying the data ( for instance",
    ", the normal distribution is parameterized by mean and variance ) .    to obtain information on parameter uncertainty with bootstrapping ,",
    "one draws as many data points as contained in the reference set , but _ with replacement_. every such bootstrap sample will yield different parameter values compared to the original ( reference ) sample , the ensemble of which allows estimation of parameter uncertainty .",
    "assuming that systematic errors in the computational model have been eliminated ( for instance , by a posteriori corrections of its results @xcite ) , the effect of the reference set employed on the parameter distributions ( and , as a consequence thereof , parameter uncertainty ) remains to be examined .",
    "if the reference data contain systematic errors , small changes in its composition ( e.g. , removal or addition of a few data points ) may have a significant effect on mean , variance , and higher moments of the parameter distributions . a well - established method for the detection of such data inconsistencies",
    "is the jackknife @xcite , where changes in the parameter distributions are identified by removing individual data points . given a reference set comprising @xmath3 data points , one obtains @xmath3 jackknife estimates of the parameter distributions , each of them inferred from the reference set with the @xmath6-th data point removed ( @xmath12 ) .",
    "we combined the jackknife with bootstrapping to examine systematic data errors in the calibration of a prediction model for the @xmath13fe mssbauer isomer shift @xcite . the corresponding theory",
    "@xcite postulates a linear relation with the electron density at the iron nucleus , which varies due to the chemical environment in which it is embedded .",
    "we studied 44 iron complexes featuring high chemical diversity for which we calculated the electron contact density on the basis of 12 density functionals across jacob s ladder ( from local density approximations to meta - hybrid generalized gradient approximations ) .",
    "we obtained 12 data sets with pairs of experimental isomer shifts and calculated electron contact densities , which only differ in the values of the latter quantity .",
    "we identified an iron complex as potentially critical if its removal from the data set has a significant effect on the bootstrapped parameter distributions and , therefore , on the uncertainty of isomer shift predictions .",
    "noteworthy , four ( chemically dissimilar ) iron complexes were identified as potentially critical for all density functionals applied , which indicates either systematic experimental errors ( hard to validate in hindsight ) or unrepresentative molecular structures .",
    "after removal of the critical data points in our mssbauer study , we examined the effect of both composition and number of data on the ranking of density functionals , which is based on reliable prediction - uncertainty estimations . for this purpose",
    ", we created 10,000 synthetical data sets of different size ( from 5 to 1,000 data points ) with the bootstrap approach .",
    "we found that the density functional ranking is very sensitive to the specific data set when it comprises only 5 data points , still quite sensitive for 40 data points , and converges only for a large number of data points ( 1,000 ) .",
    "our study @xcite showed that conclusions about prediction uncertainty and rankings of computational models based on a single data set are sensitive to errors , and that bootstrapping is a simple and fast method to avoid them .",
    "an inadequate computational model is not able to reproduce reference data within their uncertainty range @xcite , i.e. , the model under- or overestimates the uncertainty of the reference data . underestimating prediction uncertainty",
    "is a result of overfitting , where the computational model is too flexible ( features too many parameters ) such that it does not only fit the explainable part of the reference data ( the underlying physics ) , but also its unexplainable part ( noise ) .",
    "by contrast , underfitting is caused by models which are too rigid ( possess too few parameters ) to fit the explainable part of the reference data , leading to overestimation of prediction uncertainty .",
    "moreover , model inadequacy can be divided into an explainable ( systematic ) and an unexplainable ( random ) part , which is illustrated in figure [ fig : calibration ] .",
    "for instance , most quantum chemical methods ( with the exception of multi - configurational methods ) struggle to correctly describe two hydrogen atoms at large distance .",
    "in fact , all density functionals fail to describe stretched h@xmath14 and h@xmath15 @xcite .",
    "the smoothness of the corresponding energy  distance plots ( see , for instance , figure  2 in ref .",
    "@xcite ) reveals that random model inadequacy plays a negligible role in this `` simple '' case of two nuclei .",
    "however , the fact that all of these energy  distance plots reveal a non - constant deviation from those obtained with accurate multi - configurational methods shows high significance of systematic model inadequacy . while in this special case , model inadequacy could be easily eliminated by fitting a reasonable function linking data from benchmark and approximate calculations , the situation will become much more complicated if a larger fraction of chemical space is considered .",
    "for instance , due to their complex electronic structure , molecular structures containing transition metals are challenging targets for current quantum chemical methods . despite containing adjustable empirical parameters ,",
    "many density functionals fail to achieve a statistically valid description of these systems @xcite .",
    "we showed , for example , that the parameters of a standard functional are flexible enough to be chosen to exactly reproduce each coordination energies of a data set containing large organometallic complexes @xcite .",
    "however , due to model inadequacy , there exists no unique parameter set that is equally accurate for all coordination energies in this data set at the same time .",
    "note that model inadequacy is difficult to distinguish from data inconsistency .",
    "if the reference data contain systematic errors , even high - accuracy models would not be able to reproduce the reference data .",
    "in that case , it would be the wrong decision to improve on the computational model ( high overfitting tendency ) .",
    "we showed at the example of mssbauer isomer shift prediction @xcite that application of the jackknife combined with bootstrapping on a diverse selection of model approximations ( see introduction to section [ sec : inadequacy ] ) supports unraveling the two effects ( data inconsistency and model inadequacy ) .",
    "given the reference data is corrected for inconsistencies , there are several tools at hand to tackle model inadequacy @xcite : one can improve the underlying model , reduce the domain of application , or correct predictions through a statistical calibration approach .      if the computational model at hand is systematically improvable ( as , for instance , in the case of a coupled cluster expansion ) reduction of model inadequacy is , in principle , straightforward .",
    "however , such methods are currently limited to relatively small system sizes and a few structures to be considered .    in density functional theory , model improvement",
    "is often referred to as climbing up jacob s ladder @xcite .",
    "higher rungs incorporate increasingly complex ingredients constructed from the density or the kohn  sham orbitals ( e.g. , gradient and laplacian of the electron density , kinetic energy density ) .",
    "the original proposition of a ladder is that each rung satisfies certain exact constraints ( there exist 17 of them , see the supplementary material of ref .",
    "@xcite ) and the next higher rung should be based on the previous rungs @xcite . since the exact density functional is not known and the number of known exact constraints is severely limited , systematic model improvement is not trivial .",
    "in fact , a very recent study has shown that current developments steer away from systematic model improvement and towards functionals of empirical nature lacking physical rigor @xcite .",
    "most density functional development is focused on energies , implicitly assuming that functionals producing better energies become better approximations of the exact functional .",
    "the exact functional will produce the correct energy only if the input electron density is exact as well .",
    "by contrast , peverati and truhlar @xcite argued that exact constraints can be neglected for the sake of greater flexibility in the energy fitting .",
    "however , such flexibility comes at the cost of reduced transferability ( due to overfitting , cf .",
    "introduction to section [ sec : inadequacy ] ) to both other observables and chemical systems not included in the training of the computational model . to avoid loss of model transferability , mardirossian and head - gordon",
    "suggest a validation approach where the performance of a certain density functional is assessed for a data set not involved in the training of that density functional @xcite .",
    "this way , one can successively increase model flexibility until the validation indicates a decrease of transferability ( due to an increase in the performance statistics chosen ) .",
    "composite methods such as gaussian-@xmath16 ( g-@xmath16 ) @xcite , weizmann ( w-@xmath16 ) @xcite , and heat @xcite aim for high accuracy by combining the results of several calculations .",
    "they build a hierarchy of computational thermochemistry methods which allows the calculation of molecular properties such as total atomization energies and heats of formation to a high accuracy . the w-4 method calculated atomization energies of a set of small molecules with an mae below 1  kj / mol @xcite . similarly , the heat protocol predicted enthalpies of formation with an accuracy below 1  kj / mol for 31 atoms and small molecules @xcite .",
    "these protocols rely on computationally expensive coupled cluster calculations including high excitations .",
    "the heat method applies additional calculations ( e.g. , the diagonal born ",
    "oppenheimer correction ) to be able to reproduce experimental results to higher accuracy .",
    "while the results from such methods are promising , the computational cost is far too high for large - scale applications mentioned above .",
    "errors in estimating prediction uncertainty due to model inadequacy can be eliminated not only by _ internal _ correction of a computational model ( see the examples above ) , but also through _ external _ correction of the results produced with a computational model @xcite .",
    "the simplest external corrections are linear functions , which are applied in the prediction of , for example , vibrational frequencies @xcite or mssbauer isomer shifts @xcite . in such cases , parameter inference ( calibration )",
    "can be much more efficient than internal calibration of the result - generating model .",
    "a drawback is the loss of transferability to other observables since the external calibration model corrects an expectation value of a certain observable and not its underlying wave function , which is the unique common physical ground of all observables .",
    "another way of reducing model inadequacy is by training a computational model on a smaller domain of chemical space @xcite , i.e.  a small set of similar molecules such as sugars or amino acids .",
    "for example , due to the strong approximations made during method development ( to gain efficiency ) , semi - empirical methods exhibit model inadequacy , which they attempt to remedy by introducing parameters which are then fitted to a specific data set ( for a recent review see ref .",
    "this data set comprises a selection of molecules for which the resulting method is tailored .",
    "in fact , semi - empirical methods have been reparameterized to improve their description of a single molecule @xcite .",
    "similarly , density functionals were developed for specific applications , e.g. , for kinetic studies @xcite . in figure",
    "[ fig : inadequacy ] , the effect of the domain of application on model inadequacy is illustrated by a toy model .",
    "we applied the domain - reduction approach for the development of a system - specific density functional that was derived on a sound physical basis @xcite .",
    "we re - parameterized a range - separated hybrid functional to reproduce ( computational ) energy differences between isomers of a transition - metal catalyst , which refers to a small volume of chemical space ( cf .",
    "figure [ fig : inadequacy ] ) .",
    "while the resulting functional turned out to be more accurate than any popular density functional and the error estimates were in reasonable accordance with the residuals , the effect of model inadequacy prevailed to a certain degree .",
    "the functional is unable to describe the complex electronic structure of the transition metal complexes in selected cases .",
    "one can attempt to compensate model inadequacy by a controlled increase in parameter uncertainty .",
    "this way , one can build a statistical method with prediction uncertainty representative of the model residuals ( deviation of benchmark data from model predictions ) .    in 2005 ,",
    "nrskov , sethna , jacobsen , and co - workers implemented this approach for error estimation of results from density functionals @xcite ( see also refs .",
    "@xcite ) . instead of considering only the best - fit parameters of a density functional",
    ", they assigned a conditional probability distribution to them so that a mean and a variance can be assigned to each computational result .",
    "while promising general - purpose non - hybrid density functionals were designed within this framework ( e.g.  beef - vdw @xcite and mbeef @xcite ) , the accuracy of uncertainty predictions remains unsatisfying @xcite .",
    "this limitation can be attributed to model inadequacy and the heteroscedasticity of the large domain of chemical space to which they applied the functionals .",
    "compared to improving the computational model itself , increasing parameter uncertainty is straightforward as it only requires modification of the unknown part ( parameter distributions ) of an otherwise known model .",
    "compared to external calibration ( a posteriori correction of results obtained from a computational model ) , increasing parameter uncertainty in the corresponding prediction model preserves its transferability to other observables than the reference observable ( for which model inadequacy has been corrected ) .",
    "while increased parameter uncertainty seems to be clearly favorable over model improvement when it comes to reliably estimating prediction uncertainty for any observable obtained on the basis of a given computational model , it does not resolve the issue of model inadequacy per se .",
    "for instance , in multiscale modeling where the target observable is built on a hierarchy of other observables with decreasing time and/or length scales , all uncertainties inferred at low levels ( small time / length scales ) will propagate to the final prediction uncertainty ( see section [ sec : propagation ] ) . consequently ,",
    "increasing parameter uncertainty at low levels can lead to a prediction uncertainty so large that no sensible conclusions can be drawn from it .",
    "recently , we demonstrated the sensitivity of final prediction uncertainty in multiscale modeling for the inference of kinetic reaction networks based on quantum - chemical methods @xcite .",
    "uncertainty in the electronic energy propagates to all energy contributions based on nuclear motion , to any kind of free energy , to rate constants , and to concentration fluxes of chemical species ( an incomplete but lucid list ) .",
    "the dependencies between these observables are partially exponential , which requires the minimization of systematic errors in the low - level observables ( instead of hiding them in increased parameter uncertainty ) . in such cases ,",
    "the only possible way to obtain reasonably small prediction uncertainties is the systematic improvement of methods on the different length and time scales .",
    "uncertainty propagation describes the process of transferring the uncertainty of model parameters to the uncertainty of model predictions .",
    "prediction uncertainty can be assessed through calibration against reference data .",
    "there are two types of calibration : _ internal _ calibration of a computational model ( adjustment of method - inherent parameters such as those of a density functional ) and _ external _ calibration of the results produced with a computational model @xcite .",
    "if further calibration is not necessary ( in the ideal case when systematic errors are absent ) , the observation ( reference value ) @xmath17 of a system @xmath6 including _ known _ uncertainty @xmath18 is completely determined by the essentially variance - free result @xmath7 of a computational model @xmath5 plus random error @xmath19 ( drawn from a zero - mean distribution with variance @xmath20 ) ,    @xmath21    in internal calibration , the method - inherent parameters need to be adjusted such that eq .",
    "( [ eq : prediction ] ) is fulfilled , which requires a functional form with sufficient flexibility . in external calibration",
    ", we expand the expression on the right - hand side of eq .",
    "( [ eq : prediction ] ) by building a calibration model @xmath22 around the computed results ,    @xmath23    where @xmath24 is the vector of parameters of the external calibration model .    to determine the uncertainty of a virtual measurement ( prediction ) , @xmath25 , on the basis of the computed result @xmath7 for a physical measurement _ not _ included in the training data set , we need to propagate the uncertainty of @xmath24 to that of @xmath22 .",
    "the simplest way to do so is _ linear uncertainty propagation _",
    ", where the uncertainty of the external calibration model is approximated by its first partial derivative with respect to its parameters ,    @xmath26 \\ , , \\ ] ]    where @xmath27 and @xmath28 index the @xmath29 parameters contained in @xmath24 , and @xmath30 $ ] is the @xmath31-th element of the covariance matrix of the parameters . when changing the @xmath22 terms in eq .",
    "( [ eq : propagation ] ) to @xmath7 , we obtain an expression for linear uncertainty propagation in the case of internal calibration , where @xmath24 now represents the parameters of the computational model .    if the calibration model is linear in the parameters , linear uncertainty propagation is an exact procedure . for calibration models being nonlinear in the parameters , higher derivatives of the calibration model may become necessary ,",
    "the calculation of which is often unfeasible . in those cases ,",
    "stochastic methods such as monte carlo uncertainty propagation are applied @xcite .",
    "we argued that a procedure for quantifying the uncertainty associated with computational models , in particular with quantum chemical calculations , is mandatory despite their first - principles character .",
    "otherwise , it may be difficult to draw meaningful conclusions .",
    "unfortunately , this procedure is neither well established nor straightforward .",
    "the abundance of benchmark studies reporting ( potentially misleading ) statistical measures such as the mae and lae , the hope for accurate post - hartree  fock methods to become routinely and universally applicable , and the difficulty of identifying the source of error , largely prevented the development of novel approaches for reliable error estimation .",
    "we illustrated the different sources of errors and how to tackle them .",
    "we stress that a clear differentiation between the different sources of error is critical for the effective application of countermeasures .",
    "while numerical errors can often be controlled , model inadequacy and parameter uncertainty remain a major issue in quantum chemistry . reducing model inadequacy through model improvement",
    "is a popular approach , although not straightforward for most methods . in these cases ,",
    "statistical methods need to be applied in a rigorous way . while in most cases",
    "this does not improve accuracy , it allows for reliable uncertainty predictions which are critical , especially if the error is propagated to subsequent investigations such as kinetic studies .",
    "this work has been financially supported by the schweizerischer nationalfonds ( project no .",
    "200020_169120 ) . gns gratefully acknowledges support by a phd fellowship of the fonds der chemischen industrie .",
    "80ifxundefined [ 1 ] ifx#1 ifnum [ 1 ] # 1firstoftwo secondoftwo ifx [ 1 ] # 1firstoftwo secondoftwo `` `` # 1''''@noop [ 0]secondoftwosanitize@url [ 0 ] ",
    "+ 12$12  & 12#1212_12%12@startlink[1]@endlink[0]@bib@innerbibempty @noop `` , ''  ( ) @noop _ _ ,  ed .",
    "( ,  ,  ) link:\\doibase 10.1088/0026 - 1394/41/6/003 [ * * ,   ( ) ] link:\\doibase 10.1098/rsta.2012.0476 [ * * ,   ( ) ] link:\\doibase 10.1021/ct500248h [ * * ,   ( ) ] link:\\doibase 10.1021/ct400418u [ * * ,   ( ) ] link:\\doibase 10.1063/1.2162161 [ * * , ( ) ] link:\\doibase 10.1103/physrevb.37.785 [ * * ,   ( ) ] link:\\doibase 10.1063/1.464913 [ * * ,   ( ) ] link:\\doibase 10.1103/physreva.38.3098 [ * * , ( ) ] link:\\doibase 10.1103/physrevlett.77.3865 [ * * ,   ( ) ] link:\\doibase 10.1063/1.478522 [ * * ,   ( ) ] link:\\doibase 10.1103/physrevb.54.16533 [ * * ,   ( ) ] link:\\doibase 10.1063/1.1626543 [ * * ,   ( ) ] link:\\doibase 10.1021/jp0504468 [ * * ,   ( ) ] link:\\doibase 10.1063/1.473182 [ * * ,   ( ) ] link:\\doibase 10.1063/1.481336 [ * * ,   ( ) ] link:\\doibase 10.1063/1.1493179 [ * * ,   ( ) ] link:\\doibase 10.1021/jp049908s [ * * ,   ( ) ] link:\\doibase 10.1063/1.2039080 [ * * , ( ) ] link:\\doibase 10.1021/jp0705931 [ * * ,   ( ) ] link:\\doibase    10.1021/jp509980w [ * * ,   ( ) ] link:\\doibase    10.1080/01442350600799921 [ * * ,   ( ) ] link:\\doibase 10.1021/ct400319w [ * * ,   ( ) ] link:\\doibase 10.1002/jcc.23833 [ * * , ( ) ] link:\\doibase 10.1021/ct401004r [ * * , ( ) ] link:\\doibase 10.1038/srep08009 [ * * ,   ( ) ] link:\\doibase    10.1021/acs.jctc.5b00866 [ * * ,   ( ) ] link:\\doibase 10.1039/c1ee02056k [ * * ,   ( ) ] link:\\doibase 10.1021/jz200866s [ * * ,   ( ) ] link:\\doibase 10.1021/jp004368u [ * * ,   ( ) ] link:\\doibase 10.1021/acs.jctc.5b00201 [ * * , ( ) ] link:\\doibase 10.1073/pnas.1402894111 [ * * , ( ) ] in  link:\\doibase 10.1051/metrology/20150002004 [ _ _ ] ( ,  )  p. link:\\doibase 10.1063/1.1677527 [ * * ,   ( ) ] link:\\doibase 10.1021/jo302156p [ * * ,   ( ) ] link:\\doibase 10.1063/1.2137323 [ * * , ( ) ] link:\\doibase 10.1039/c6fd00144k [ * * ,   ( ) ] @noop ( ) ,   @noop _ _ ,  ed . , information science and statistics  ( , ,  ) @noop _ _ ,  ed .",
    "( ,  ,  ) @noop @noop _ _  ( ,  ,  ) link:\\doibase 10.1021/cr200107z [ * * ,   ( ) ] link:\\doibase 10.1002/qua.24800 [ * * ,   ( ) ] @noop ( ) ,   link:\\doibase    10.1063/1.1390175 [ * * ,   ( ) ] link:\\doibase    10.1103/physrevlett.115.036402 [ * * ,   ( ) ] link:\\doibase 10.1126/science.aah5975 [ * * ,   ( ) ] link:\\doibase 10.1039/c3cp54374a [ * * ,   ( ) ] link:\\doibase 10.1063/1.4907719 [ * * , ( ) ] link:\\doibase    10.1063/1.456415 [ * * ,   ( ) ] link:\\doibase 10.1063/1.460205 [ * * ,   ( ) ] link:\\doibase 10.1063/1.477422 [ * * ,   ( ) ] link:\\doibase 10.1063/1.2436888 [ * * , ( ) ] link:\\doibase 10.1063/1.479454 [ * * ,   ( ) ] link:\\doibase    10.1063/1.1638736 [ * * ,   ( ) ] link:\\doibase 10.1063/1.2348881 [ * * ,   ( ) ] link:\\doibase    10.1063/1.1811608 [ * * ,   ( ) ] link:\\doibase 10.1021/j100010a019 [ * * ,   ( ) ] link:\\doibase 10.1063/1.1561045 [ * * ,   ( ) ] link:\\doibase 10.1021/jp052793n [ * * , ( ) ] link:\\doibase 10.1016/s0020 - 1693(02)01031 - 9 [ ,  * * ,   ( ) ] link:\\doibase    10.1002/jcc.20402 [ * * ,   ( ) ] link:\\doibase 10.1021/ic801535v [ * * ,   ( ) ] link:\\doibase 10.1021/ct100398 m [ * * ,   ( ) ] link:\\doibase 10.1021/ic4021349 [ * * , ( ) ] link:\\doibase 10.1002/qua.24375 [ * * ,   ( ) ] link:\\doibase 10.1002/wcms.1161 [ * * ,   ( ) ] link:\\doibase    10.1021/ct400224n [ * * ,   ( ) ] link:\\doibase    10.1021/jp000497z [ * * ,   ( ) ] link:\\doibase 10.1021/acs.jctc.6b00318 [ * * , ( ) ] link:\\doibase 10.1103/physrevlett.95.216401 [ * * ,   ( ) ] link:\\doibase 10.1103/physreve.68.021904 [ * * ,   ( ) ] link:\\doibase 10.1103/physrevlett.93.165501 [ * * , ( ) ] link:\\doibase 10.1007/s11244 - 012 - 9801 - 7 [ * * ,   ( ) ] link:\\doibase 10.1103/physrevb.85.235149 [ * * ,   ( ) ] link:\\doibase 10.1063/1.4870397 [ * * , ( ) ] link:\\doibase 10.1103/physrevb.91.235201 [ * * ,   ( ) ] link:\\doibase 10.1016/0097 - 8485(84)80007 - 8 [ * * ,   ( ) ]"
  ],
  "abstract_text": [
    "<S> computational models in chemistry rely on a number of approximations . </S>",
    "<S> the effect of such approximations on observables derived from them is often unpredictable . </S>",
    "<S> therefore , it is challenging to quantify the uncertainty of a computational result , which , however , is necessary to assess the suitability of a computational model . </S>",
    "<S> common performance statistics such as the mean absolute error are prone to failure as they do not distinguish the explainable ( systematic ) part of the errors from their unexplainable ( random ) part . in this paper </S>",
    "<S> , we discuss problems and solutions for performance assessment of computational models based on several examples from the quantum chemistry literature . for this purpose , </S>",
    "<S> we elucidate the different sources of uncertainty , the elimination of systematic errors , and the combination of individual uncertainty components to the uncertainty of a prediction . </S>"
  ]
}