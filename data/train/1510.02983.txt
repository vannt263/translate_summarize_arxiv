{
  "article_text": [
    "for diverse nlp classification tasks , such as sentiment and opinion mining , or text - forecasting , in which text documents are used to make predictions about measurable phenomena in the real world  @xcite , there is a need to generalize over words while simultaneously capturing relational and structural information .",
    "feature engineering for nlp learning tasks can be labor - intensive .",
    "we propose omnigraph , a novel representation that supports a continuum of features from lexical items , to syntactic dependencies , to frame semantic features .",
    "figure  [ fig : capability - feature ] illustrates a sentence , the structure of its graph , and a predictive subgraph feature our method discovers that captures semantic and syntactic dependencies ( arrows ) , semantic role information for syntactic arguments ( diamonds ) , and generalizations over lexical items ( semantic frame names , shown as rectangles ) . for machine learning with omnigraph , we use graph kernels that allow the user to control",
    "how much of the graph is explored for similarity computation .",
    "we test this approach on an extremely challenging text - forecasting problem : a polarity classification task to predict the direction of price change for publicly traded companies based on news .",
    "we also report results on an entity - driven fine - grained sentiment corpus .",
    "the ability to exploit deep semantic information in text , e.g. to distinguish the depicted scenarios and semantic roles of the entity mentions , motivates our study .",
    "we hypothesize that a general and uniform representation of linguistic information that combines multiple levels , such as semantic frames and roles , syntactic dependency structure and lexical items , can support challenging classification tasks for nlp problems .",
    "consider the following three sentences from financial news articles .",
    "- _  the accreditation renewal also the of our work with * humana * members , customers , clients , payors and health care providers by confirming our compliance with national standards for pbm services , \" william fleming , of * humana pharmacy solutions*. _    - _ `` the testing program the of the navy , * raytheon missile systems * and nasa to effectively partner on this complicated program and deliver what would have been previously unobtainable data , '' don nickison , of the nasa ames wind tunnel operations division . _    - _  the initiation of a dividend and the renewed share repurchase authorization the board and management s confidence in * symantec * s long - term business outlook and to generate significant free cash flow on a consistent basis , \" * symantec * s , james beer . _",
    "the sentences all describe a scenario in which a company executive makes a positive statement about the company s capabilities . of note ,",
    "the stock price of the three companies ( in boldface ) went up the next day .",
    "four semantic frames from framenet  @xcite , a linguistic resource that exemplifies fillmore s frame semantics @xcite , capture the commonality of a _ statement _ ( green ) from an organization _ leader _ ( blue ) that _ conveys the importance _",
    "( orange ) of _ capabilities _ ( brown ) .",
    "further , within each sentence the frames have the same syntactic dependencies in the three sentences .",
    "the feature in figure  [ fig : capability - feature ] captures the common meaning of these sentences , and is predictive in three distinct market sectors : industrials , health care and information technology .",
    "much recent work on the kinds of nlp classification tasks our experiments address , text - forecasting and fine - grained sentiment , builds on linguistically informed features or knowledge .",
    "introduce fine - grained opinion mining , using semantic role labeling to mine triples of the source , target and content of opinions applied to online news .",
    "to similarly mine opinion triples , depend more on syntax , using a suffix - tree data structure to represent syntactic relationships . instead of feature engineering , ,",
    "develop structured regularization for bow based on parse trees , topics and hierarchical word clusters to improve bow for 3 classification tasks : topic , sentiment , and text - driven forecasting .",
    "another approach to forecasting from text @xcite combines bow and the names of dependency relations to engineer features for predicting movie revenue from reviews .",
    "they devote considerable effort to feature engineering , while our approach folds feature engineering into the learning .",
    "omnigraph feature engineering is handled automatically by convolution graph kernels .",
    "convolution kernels have been used in nlp to exploit structured information using trees for parsing and tagging @xcite , text categorization @xcite , and question answering . to learn social networks , agarwal et al . use partial tree kernels on a representation with frame semantic information @xcite . the tree representation in",
    "also incorporates frame semantics , and uses subtree and subset tree kernels for the same forecasting task we pursue .",
    "in contrast to their task - specific representations , our more general omnigraph can be used for many tasks . rather than having to choose among many tree kernels ,",
    "the graph kernels we use allow users to specify the size of the graph neighborhoods to explore .",
    "studies of the effect of financial news on the market have been increasingly important since tetlock investigated the role of media in the stock market .",
    "as mentioned in , a better solution to the problem can help gain more insights to the long - lasting question in finance about how financial markets react to news  @xcite .",
    "in general , the work in nlp that uses news to predict price does well if it achieves better than 50% accuracy @xcite . report that even `` textbook models '' that uses time series data have less than 51.5% prediction accuracy .",
    "unlike many other domains , however , a higher than random accuracy can have great value in a high - volume trading strategy .",
    "work in nlp and related areas @xcite often treats stock price prediction from news as a sentiment classification problem .",
    "point out that this is consistent with the direction component of the three - part ads model @xcite .",
    "their model was shown better than bow alone on three market sectors , but there was no comparison to the majority baseline .",
    "in contrast , our omnigraph outperforms the baseline in seven out of eight market sectors and beats bow and two other benchmarks .",
    "* sentence : *  the accreditation renewal underscores the quality of our work with * humana * members , \" said * humana * s president .",
    "+    * frame semantic parse:*the accreditation renewal underscores@xmath0 the quality@xmath1 of our work with * humana * members@xmath2,\"@xmath3 said@xmath4 * humana * s president@xmath5 @xmath6 .",
    "* dependency parse : *     the & accreditation & renewal & & the & & of & our & work & with & * humana * & members , \" & & * humana * s & +    [ dep_parse ]",
    "we first introduce our data representation , then describe our learning methods .",
    "the nodes in an omnigraph encode semantic and lexical content , and the edges encode semantic and syntactic dependency relations . in section  [ sec : og ] we use an example to describe how to construct a one - sentence omnigraph .",
    "later we introduce the data instances for our learning task : omnigraph forests that represent all the sentences in the news that mention a given company on a particular day . as in",
    ", we refer to the company we make predictions about as the designated entity .      to construct a one - sentence omnigraph ,",
    "the sentence must first be assigned a frame semantic parse and a syntactic dependency parse .",
    "section [ sec : experiments ] describes the parsers we use and their performance .",
    "we use the example sentence in figure  [ fig : s1 ] to illustrate how to construct its omnigraph in figure  [ fig : semgraph_all ] .    *",
    "( 1 ) create building blocks by converting each semantic frame into a subgraph . * in frame - based semantic parsing ,",
    "the scenarios in a sentence are identified as frames , and each frame is triggered by a frame target : the lexical item that evokes the frame .",
    "the frame name and frame target become omnigraph nodes , along with the frame elements ( semantic roles ) that have been filled by sentential arguments . in figure",
    "[ fig : s1 ] , nodes with the same color correspond to a frame , its target , and its elements .",
    "four frames have been identified by the parser , and three frame elements : the message elements of the _ statement _ and _ convey_importance _ frames , the speaker element of the _ statement _ frame , and the _ capability _ and _ leadership _ frames .",
    "an edge connects a frame target and the frame it evokes ( e.g. _ said _ and _ statement _ ) , and a frame element and the frame it belongs to ( e.g. message and _ statement _ ) .",
    "figure [ fig : s1 ] shows an actual parse for a sentence in our data ; in a correct parse , the phrase _ accreditation renewal _ would fill the medium element of the _ convey_importance _ frame .",
    "we achieve good prediction performance despite such inaccuracies .    *",
    "( 2 ) add the dependency relations among frames .",
    "* frame semantic parsing identifies individual frames , but not the syntactic dependencies among frames .",
    "as shown in the dependency parse in figure  [ fig : s1 ] , we locate the frame targets , i.e. lexical items that evoke frames , and use the dependency relations among the frame targets to link the frames . in omnigraph , a dependent node points to the node it depends on , as indicated by the red arrows in figure  [ fig : semgraph_all ] .    *",
    "( 3 ) connect the designated entity to its semantic roles .",
    "* for the learning task we present here , we make predictions about a designated entity , a publicly traded company .",
    "company mentions are identified using pattern matching .",
    "all mentions of the designated entity become nodes , which are linked to the frame elements they fill , or partly fill .",
    "for example the designated entity * humana * fills the speaker role of the _ statement _ frame , and also occurs in the message element of the _ statement _ frame and the message element of the _ convey_importance _ frame .",
    "it thus has three out - degree edges .    *",
    "( 4 ) connect lexical items to frame elements they help fill .",
    "* omnigraph incorporates lexical information with one node for each lexical item in a constituent that fills a frame element .",
    "the nodes connect to the frame elements they fill .",
    "some of these edges are shown as grey dashed nodes and edges in figure  [ fig : semgraph_all ] .",
    "some edges are omitted for readability .    in sum ,",
    "omnigraph nodes are : 1 ) frame names ( boxes ) , 2 ) frame targets ( rounded boxes ) , 3 ) frame elements ( diamonds ) , 4 ) other lexical items ( dashed boxes ) , and 5 ) designated entities ( ellipses ) .",
    "an edge connects : 1 ) a frame target to its frame ; 2 ) a frame element to the frame it belongs to ; 3 ) a designated entity to the frame element it fills ; 4 ) from one frame to another where the target of the first frame is a dependent node in a dependency parse , and the target of the second frame is the dependent s head ; and 5 ) a lexical item to the frame element it helps fill .",
    "edge directions are exploited by the graph kernels we use .",
    "we selected the weisfeiler - lehman ( wl ) graph kernel @xcite for svm learning because it has a lower computational complexity compared to other graph kernels , and because it can measure similarity between graphs for different neighborhood sizes .",
    "at each degree @xmath7 of neighborhood , all nodes are relabeled with their neighborhoods , then graph similarity is measured .",
    "for example , to explore its first degree neighbors , the immediate neighborhood of the _ designated_entity _ node in figure [ fig : semgraph_all ] is used to relabel the node as _ \\{designated_entity@xmath8c.message , s.message , s.speaker}_. the wl kernel computation is based on the weisfeiler - lehman test of isomorphism @xcite , which iteratively augments the node labels by the sorted set of their neighboring node labels , and compresses them into new short labels , called multiset - labels . through neighbor augmentation , similarity between graphs is iteratively measured using dynamic programming .",
    "figure  [ fig : toy ] illustrates how to calculate the wl graph kernel between graphs    @xmath9    and    @xmath10    for degrees of neighbor up to 1 ( @xmath11=1 ) .",
    "iteration @xmath7=0 for degree of neighbor 0 ( stepsize 0 ) compares only the nodes of the original graphs .",
    "nodes with label    _ 0 _    have one match ; nodes with label    _ 1 _    have two matches .",
    "this gives a total similarity of three .",
    "the neighborhoods for each node are then augmented to compute similarity when iteration @xmath7=1 , which compares the nodes and their first degree neighbors .",
    "new labels ( i.e.    _ 3 _    ,    _ 4 _    , and    _ 5 _    ) are assigned to represent each node and its first degree neighbors , and similarity of the relabeled graphs is 2",
    ". therefore ,    @xmath12    .",
    "the wl kernel is efficient at neighborhood augmentation but there is no distinction between different node types , and node augmentation gathers up all nodes for a given degree .",
    "the 1-degree wl feature for the designated entity ( de ) node in figure [ fig : semgraph_all ] is    @xmath13de@xmath14spkr , msg , msg@xmath15    , i.e. de fills a speaker and two message elements ( one for the _ statement _ frame and the other for the _ convey_importance _ frame ) . no credit for partial",
    "matching is given when this graph instance is compared to another instance where de just fills the message element of the _ convey_importance _ frame .",
    "to allow partial matching , and to take advantage of the type information of nodes and edges , we introduce a novel graph kernel : node edge weighting ( new ) graph kernel .    like wl , new also measures subgraph similarities through neighborhood augmentation .",
    "the kernel computation can be broken down into node kernels and edge kernels .",
    "node and edge kernels are weighted kronecker delta kernels ( @xmath16 ) that return whether the two objects being compared are identical .",
    "define    @xmath17    for the weight of node    @xmath18    of feaure type    @xmath19    , node label    @xmath20    , and    @xmath21    for the weight of edge    @xmath22    with from - node of feature type    @xmath23    and to - node of feature type    @xmath24    .",
    "we have    @xmath25    , and    @xmath26    .",
    "define    @xmath27    to be the basis kernel for @xmath28-degree neighborhood ; the kernel between graph    @xmath9    and    @xmath10    is computed by recursion as in equation  [ eq : newgk ] .",
    "@xmath29    dynamic programming can be used to improve the efficiency .",
    "each entry in the dynamic programming table is a tuple of    @xmath13@xmath30@xmath15    , where    @xmath31    and    @xmath32    are nodes in graph    @xmath9    and    @xmath10    .",
    "the toy example in figure  [ fig : newgk_toy ] illustrates how to calculate the new graph kernel between graphs    @xmath9    and    @xmath10    . as with the wl kernel ,",
    "new compares different degrees of node neighborhoods up to @xmath28 degrees of neighbors , and the final kernel is a sum of all basis kernels . for @xmath28=0 , only the nodes of the original graphs are compared .",
    "nodes with labels    de    ,    msg    and    conimp    all have one match . with node weights as shown ,    @xmath33@xmath340.3@xmath350.7@xmath350.9@xmath341.9    . for",
    "@xmath28=1    , each node plus its one - degree neighbors are compared , and the relations between the nodes .",
    "path    de @xmath14 msg    has a match .",
    "with node and edge weighting ,    @xmath36@xmath340.3@xmath370.4@xmath370.7@xmath340.084    .",
    "for the same reason ,    @xmath38@xmath340.3@xmath370.4@xmath370.7@xmath370.6@xmath370.9@xmath340.045    .",
    "there is no match for three degrees of neighbors ,    @xmath39@xmath340    .",
    "each basis kernel that corresponds to different neighborhood sizes are then normalized by the maximum of the evaluation between each graph and itself .",
    "for each graph kernel    @xmath40    we have a normalized    @xmath41    :    @xmath42    this normalization ensures that a graph will always match itself with the highest value of 1 and other graphs with values between 0 and 1 .",
    "the final kernel is an interpolation of basis kernels :    @xmath43    , where    @xmath44=@xmath45    .",
    "combining basis kernels is a common problem in machine learning and several multiple kernel learning techniques have been developed to allow benefits from multiple kernels @xcite .",
    "we test the performance of omnigraph with wl and new kernels on a polarity task : to predict the direction of price change for 321 companies from eight market sectors of standard & poor s 500 index . on average , there are from 27 to 67 companies per sector .",
    "one of the biggest challenges of the financial domain is the unpredictability of the market . as noted above , use of nlp methods on news to predict price",
    "does well if it achieves better than random performance , as described in the related work .",
    "we rely on student s t to test statistical significance of classification accuracy .",
    "we use the majority class label as a baseline , which ranges from 54% to 56% , depending on the market sector . compared with three nlp benchmarks , only omnigraph beats",
    "the baseline , and results are statistically significant .",
    "the experiments use reuters news data from 2007 to 2013 for eight gics sectors .",
    "sentences that mention companies are extracted using high - precision , high - recall pattern matching on company name variants .",
    "a data instance for a company consists of an omnigraph forest representing all the sentences that mention that company on a given day . on average ,",
    "each data instance encodes from 4.11 to 7.18 sentences , and each company has an average total of from 605 to 858 sentences , depending on the sector . in work",
    "reported elsewhere , we found that we could expand the number of sentences per company using coreference by 15 - 30% , depending on the sector .",
    "the additional sentences did not , however , improve performance ( anon ) .",
    "sentences that mention companies by name tend to occur early in news articles , and are apparently more predictive .    a binary class label \\{-1 , + 1 } indicates the direction of price change on the next day after the news associated to the data instance .",
    "the one - day delay of price response to news is due to @xcite .",
    "only the instances with a price change of 2% are included in our polarity prediction task .",
    "sentences are parsed using the mst dependency parser  @xcite , which implements the eisner algorithm  @xcite for dependency parsing , and provides an efficient and robust performance . for frame semantic parsing",
    ", we use semafor @xcite , which generates state - of - the - art results on _ semeval _ benchmark datasets .    for the learning",
    ", we found that no single stepsize performed best for a given company , much less the entire data set .",
    "we select the stepsize and weights of the basis kernels for new using grid search on 80% of the data , where we use leave - one - out cross validation . the selected parameters for a given company",
    "are then used to test the average prediction performance on the 20% of held - out data .    [",
    "cols=\"^,>,^,^,^,^,<,<\",options=\"header \" , ]     we use the percentage of the majority class as the baseline , and compare the same five methods as in our previous experiment .",
    "table  [ tab : results_gfbf ] summarizes the results . on the benefactive / malefactive task",
    ", bow obtains a 10% improvement over the baseline .",
    "structured representations significantly improve over bow .",
    "semtreefwd , which incorporates the semantic frame features and a sentiment lexicon , improves the performance by another 5% .",
    "the dependency tree performance is similar to semtreefwd .",
    "omnigraph with graph kernel learning ( wl or new kernels ) performs much better .",
    "the writer attitude task is a more difficult one with a slightly lower baseline , and a much lower inter - annotator agreement  @xcite .",
    "dependency trees and semantic trees do not improve over bow .",
    "both versions of omnigraph , however , have superior performance .",
    "omnigraph with graph kernel learning exhibits superior performance over vector and tree space models in both experiments . to understand what contributes to the predictive power of omnigraph models , we use mutual information to rank features discovered by omnigraph .",
    "compared to the vector and tree representations , the graph - structured features are more expressive , and can be interpreted .",
    "figure  [ fig : sample_features ] presents six highly ranked features from our experiments . features 1 - 3 are from the financial news analytics task .",
    "feature 1 is a complex feature with frame names , frame elements , and the dependencies among frames .",
    "it generalizes over multiple sectors and predicts a positive change in price .",
    "it is the feature that corresponds to the example sentences in the introduction .",
    "feature 2 combines frame names , frame elements , a frame target , and two lexical items to capture an interesting pattern : referring to the former leader of a company predicts a negative price change .",
    "feature 3 is a 2-degree neighbor subgraph that consists of three frames and their inter - dependencies .",
    "this feature represents that the designated entity experiences a change over a time period .",
    "the feature generalizes across many different wordings , and although the feature does not directly encode direction of change , it happens that this feature rarely occurs in a negative description .",
    "it is therefore an example of a positive sentiment feature that is detected without reliance on a sentiment lexicon or on explicit polarity information .",
    "features 4 - 6 are from the _ gfbf _ experiment .",
    "feature 4 is a top ranked predictor for the benefective / malefactive task , and it predicts a positive affect toward the object .",
    "it captures the relation between the _ agent _ and the _ object _ in an _ assistance _ scenario where the _ agent _ fills the helper role and the affected _ object _ fills the benefited_party role .",
    "row 5 contains two features that are predictive in the writer attitude task .",
    "recall that a writer can have different attitudes towards the _ agent _ and the _ object_. our approach is able to distinguish different roles of different entities of interest for the same sentence , and make separate predictions .    as seen above",
    ", omnigraph is very good at modeling complex intra - sentence semantic relations .",
    "inspired by the work of , who constructed dependency parse forests for paragraphs of text , one of our future directions is to extend omnigraph to incorporate discourse information .",
    "an obvious choice would be to encode inter - sentential discourse relations as one or more new edge types to connect the omnigraphs that correspond to distinct sentences .",
    "in this study , we have presented a novel graph - based representation  omnigraph  with _ weisfeiler - lehman _ and _ node edge weighting _ graph kernel learning , for entity - driven semantic analysis of documents .",
    "this method exhibits superior performance in a text - forecasting task that uses financial news to predict the stock market performance of company mentions , and a fine - grained sentiment task .",
    "omnigraph s advantages stem from the use of semantic frames to generalize word meanings in a flexible and extensible graph structure , where rich relational linguistic information , such as dependencies among frames and lexical items , can be modeled and learned with graph kernels that make feature engineering part of the learning .",
    "the resulting graph features are able to reflect deeper semantic patterns beyond words , and to help provide insights into the problem domain . here , we applied omnigraph to two rather distinct problems to illustrate that it could potentially support a wide range of nlp classification problems . on top of omnigraph s capability of modeling complex intra - sentence semantic relations , a future direction is to model inter - sentence relations through discourse structure to form a more linguistically informed document - level representation .",
    "apoorv agarwal , sriramkumar balabsubramanian , anup kotalwar , jiehan zheng , and owen rambow .",
    "frame semantic tree kernels for social network extraction from text . in _ proceedings of the 14th conference of the european chapter of the association for computational linguistics _ , pages 211219 .",
    "francis  r. bach , gert r.  g. lanckriet , and michael  i. jordan .",
    "multiple kernel learning , conic duality , and the smo algorithm . in _ proceedings of the twenty - first international conference on machine learning _ ,",
    "icml 04 , pages 6 , new york , ny , usa . acm .",
    "collin  f. baker , charles  j. fillmore , and john  b. lowe .",
    "1998 . the berkeley framenet project . in _ proceedings of the 36th annual meeting of the acl and 17th international conference on computational linguistics - volume 1 _ , acl 98 , pages 8690 , stroudsburg , pa , usa .",
    "roy bar - haim , elad dinur , ronen feldman , moshe fresko , and guy goldstein .",
    "2011 . identifying and following expert investors in stock microblogs . in _ proceedings of the 2011 conference on empirical methods in natural language processing _ , pages 13101319 , edinburgh , scotland , uk . ,",
    "association for computational linguistics .",
    "germn  g. creamer , yong ren , yasuaki sacamoto , and jeffrey  v. nickerson .",
    "news and sentiment analysis of the european market with a hybrid expert weighting algorithm . in _",
    "socialcom13 _ , pages 391396 .",
    "dipanjan das and noah  a. smith .",
    "semi - supervised frame - semantic parsing for unknown predicates . in _ proceedings of the 49th annual meeting of the association for computational linguistics : human language technologies - volume 1 _ , hlt 11 , pages 14351444 , stroudsburg , pa , usa .",
    "association for computational linguistics .",
    "lingjia deng , yoonjung choi , and janyce wiebe .",
    "benefactive / malefactive event and writer attitude annotation . in _ proceedings of the 51st annual meeting of the association for computational linguistics ( volume 2 : short papers ) _ , pages 120125 , sofia , bulgaria , august .",
    "association for computational linguistics .",
    "ann devitt and khurshid ahmad .",
    "sentiment polarity identification in financial news : a cohesion - based approach . in _ proceedings of the 45th annual meeting of the association of computational linguistics _ , pages 984991 , prague , czech republic , june .",
    "association for computational linguistics .    jason  m. eisner .",
    "three new probabilistic models for dependency parsing : an exploration . in _ proceedings of the 16th conference on computational linguistics - volume 1 _ , coling 96 , pages 340345 , stroudsburg , pa , usa . association for computational linguistics .",
    "ronen feldman , benjamin rosenfeld , roy bar - haim , and moshe fresko .",
    "the stock sonar - sentiment analysis of stocks based on a hybrid approach . in _ proceedings of the twenty - third conference on innovative applications of artificial intelligence ,",
    "august 9 - 11 , 2011 , san francisco , california , usa_.            mahesh joshi , dipanjan das , kevin gimpel , and noah  a. smith .",
    "movie reviews and revenues : an experiment in text regression . in _ human language technologies : the 2010 annual conference of the north american chapter of the association for computational linguistics _ , pages 293296 , los angeles , california , june .",
    "association for computational linguistics .",
    "soo - min kim and eduard hovy .",
    "2006 . extracting opinions , opinion holders , and topics expressed in online news media text . in _ proceedings of the workshop on sentiment and subjectivity in text _ , sst 06 , pages 18 , stroudsburg , pa , usa .",
    "association for computational linguistics .",
    "shimon kogan , dimitry levin , bryan  r. routledge , jacob  s. sagi , and noah  a. smith .",
    "predicting risk from financial reports with regression . in _ proceedings of human language technologies : the 2009 annual conference of the north american chapter of the association for computational linguistics _ , naacl 09 , pages 272280 .",
    "association for computational linguistics .",
    "ryan mcdonald , fernando pereira , kiril ribarov , and jan haji .",
    "non - projective dependency parsing using spanning tree algorithms . in _ proceedings of the conference on human language technology and empirical methods in natural language processing _ , hlt 05 , pages 523530 , stroudsburg , pa , usa .",
    "association for computational linguistics .",
    "alessandro moschitti .",
    "2006 . making tree kernels practical for natural language learning .",
    "in _ in proceedings of the 11th conference of the european chapter of the association for computational linguistics_.      asad  b. sayeed , jordan boyd - graber , bryan rusk , and amy weinberg . 2012 .",
    "grammatical structures for word - level sentiment detection . in _ proceedings of the 2012 conference of the north american chapter of the association for computational linguistics : human language technologies _ , naacl hlt 12 , pages 667676 .",
    "association for computational linguistics .",
    "jun suzuki , tsutomu hirao , yutaka sasaki , and eisaku maeda .",
    "hierarchical directed acyclic graph kernel : methods for structured natural language data . in",
    "_ proceedings of the 41st annual meeting on association for computational linguistics - volume 1 _ , acl 03 , pages 3239 , stroudsburg , pa , usa .",
    "association for computational linguistics .",
    "felix ming  fai wong , zhenming liu , and mung chiang . 2014 .",
    "stock market prediction from wsj : text mining via sparse matrix factorization . in _",
    "2014 ieee international conference on data mining , icdm 2014 , shenzhen , china , december 14 - 17 , 2014 _ , pages 430439 .",
    "boyi xie , rebecca  j. passonneau , leon wu , and germn creamer .",
    "semantic frames to predict stock price movement . in _ proceedings of the 51st annual meeting of the association for computational linguistics ( volume 1 ) _ , pages 873883 , sofia , bulgaria , august .",
    "association for computational linguistics .",
    "dani yogatama and noah  a. smith",
    "linguistic structured sparsity in text categorization . in _ proceedings of the 52nd annual meeting of the association for computational linguistics ( volume 1 : long papers ) _ , pages 786796 , baltimore , maryland , june .",
    "association for computational linguistics .",
    "dell zhang and wee  sun lee .",
    "question classification using support vector machines . in _ proceedings of the 26th annual international acm sigir conference on research and development in informaion retrieval _ , sigir 03 , pages 2632 , new york , ny , usa . acm ."
  ],
  "abstract_text": [
    "<S> omnigraph , a novel representation to support a range of nlp classification tasks , integrates lexical items , syntactic dependencies and frame semantic parses into graphs . </S>",
    "<S> feature engineering is folded into the learning through convolution graph kernel learning to explore different extents of the graph . </S>",
    "<S> a high - dimensional space of features includes individual nodes to complex networks . in experiments on a text - forecasting problem that predicts stock price change from news for company mentions , omnigraph beats several benchmarks based on bag - of - words , syntactic dependencies , and semantic trees . </S>",
    "<S> the highly expressive features omnigraph discovers provide insights into the semantics across distinct market sectors . to demonstrate the method s generality </S>",
    "<S> , we also report its high performance results on a fine - grained sentiment corpus . </S>"
  ]
}