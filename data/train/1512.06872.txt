{
  "article_text": [
    "coaddition of observations is one of the most basic operations on astronomical images .",
    "the main objectives of coaddition are to increase the sensitivity ( depth ) of observations , to remove signal from high energy particle hits on the detector ( sometimes called cosmic rays ) , and to decrease the point spread function ( psf ) width ( e.g. , deconvolution from wavefront sensing , @xcite ; lucky imaging , @xcite ) .",
    "one question that is common for all these tasks is what is the best method to coadd the images .",
    "this of course requires a definition of what `` best '' means .    here",
    ", we assume that all observations are registered and re - sampled to the same grid ( e.g. , using swarp ; @xcite ) , and focus on the combination operation of the images .",
    "there are several common complications for image coaddition .",
    "ground - based images are often taken under variable seeing , background and transparency conditions .",
    "even some space - based observations may suffer from such problems .",
    "for example , x - ray images commonly have non - uniform psf accross the field of view .",
    "these complications make the coaddition operation less trivial than simple ( weighted ) scalar addition .",
    "coaddition is playing , and will play , a major role in ongoing and future surveys ( e.g. , sdss , @xcite ; pan - starrs , @xcite ; ptf , @xcite , des , @xcite ; lsst , @xcite ) .",
    "there are many approaches for image coaddition after the registration step .",
    "one pre - step common to many methods is to reject some of the images with the worst seeing , background or transparency .",
    "there is no sensible prescription to which images one should reject , and it is straightforward to show that this approach leads to a loss of sensitivity compared with the maximum possible . one extreme example for this process is lucky imaging @xcite , where one often discards up to 99% of the data frames .",
    "the next coaddition steps involves either weighted summation of the images , or applying partial filtering ( or deconvolution ) to each image in order to homogenize the psfs of all the images followed by coaddition .",
    "for example , @xcite recommended coadding the sdss stripe 82 images by weighted summation of the images , where the weights are of the form : @xmath1 and @xmath2 , @xmath3 , and @xmath4 . here",
    "@xmath5 is the weight applied to the image @xmath6 , @xmath7 is proportional to the product of the telescope effective area , detector sensitivity and atmospheric transparency ( i.e. , flux - based photometric zero point ) , @xmath8 is the width of the psf , and @xmath9 is the variance of all the background noise sources ( e.g. , background , readout noise ) . on the other hand @xcite adopted a similar formula but with @xmath2 , @xmath10 , @xmath4 .",
    "another example for such a weighted summation was given by @xcite who solved a numerical optimization scheme for the optimal weights in which the images should be added with .",
    "other approaches are also used .",
    "for example , some authors perform psf homogenization on all the images prior to coaddition .",
    "this is done by convolving the frames with some kernel in order to bring all the observations to have the same psf .",
    "for example , @xcite and @xcite define a median seeing psf , and then for each image find the convolution kernel that will transform the image ( via convolution ) to a median - seeing image , applying for all images , and then sum the images .",
    "this convolution kernel can be found using techniques outlined in @xcite , @xcite and @xcite .",
    "however , for images with seeing which is worse than the target seeing , the psf homogenization operation becomes a deconvolution operation , which amplifies the noise in high spatial frequencies and creates long range correlations in the noise .",
    "another issue of the psf homogenization approach is the artificial insertion of correlations between neighboring pixels . as a result ,",
    "any measurement on the data becomes more involved .",
    "for example , applying a naive matched filter with the coadd - image psf will result in an additional loss of information . in a series of several papers we will tackle the problem of optimal image coaddition . in this paper ( paper  i )",
    ", we will lay down the statistical formalism and assumptions we use for the coaddition problem .",
    "we construct a coaddition method that achieves the maximum possible signal - to - noise ratio ( @xmath0 ) for detection of non - blended faint point - like sources in the coadded image under the assumption of constant variance gaussian noise .",
    "in addition , we present a coaddition method that is optimal for photometric measurements of both faint and bright objects ( i.e. , even for sources in which the source noise is non - negligible ) .",
    "these coaddition products are the analogues of linear matched filter for ensemble of images .",
    "we note that this coaddition method , optimized for source detection , was used by @xcite to reduce the _ wise _ satellite data .",
    "however , in order to recover the sharpness of the original images they applied de - convolution after the coaddition process .",
    "it is noteworthy that linear matched filter images are smeared and their pixels are correlated .",
    "therefore , general hypothesis testing and statistical measurements on them requires knowledge and consideration of the spatial covariance matrix .",
    "this makes them non - attractive for visualization and non intuitive for performing measurements other than source detection and flux measurement ( e.g. , resolving binary stars or measuring galaxy shapes ) . in paper",
    "ii @xcite we build on the results of this paper to construct a coaddition method for the special ( but common ) case of background - dominated noise . equipped with the background - dominated noise assumption we find a simple transformation that removes the pixel correlation induced by the matched - filtering step , and makes the additive noise in all pixels uncorrelated and with equal variance .",
    "most importantly , this technique provides a sufficient statistic for _ any _ statistical measurement or decision on the data ( e.g. , source detection , flux measurement , shape measurement ) .",
    "moreover , this method conserves the information of all the spatial frequencies , and provides a psf which is typically sharper than the psf of the best image in the stack we coadd .",
    "in addition , this image is practically indistinguishable from a regular astronomical observation , and any image analysis code can be applied to it unchanged .",
    "combining all these properties together , it allows a major reduction in the amount of data products users will need in order to perform any further processing on data ( e.g. , galaxy shape measurements for weak lensing ) .",
    "last , this coaddition algorithm is fast and its implementation is trivial .    in future papers ( zackay et al .",
    ", in prep . )",
    "we apply the algorithm from paper  ii for the case of rapid imaging through the turbulent atmosphere and where the psf is either known ( through observing a reference star or using a wavefront sensor ) or unknown .",
    "we show that this method potentially provides better results than the existing approaches for the coaddition of speckle images ( e.g. , speckle interferometry , @xcite ; lucky imaging , @xcite , and its suggested improvements , e.g. , @xcite ) .",
    "the structure of this paper is as follows : in  [ sec : statisticalbackground ] , we review the statistical formalism of image coaddition and refer to some basic lemmas regarding how to combine random variables . in  [ sec : detectionfaint ] , we discuss the optimal coaddition image for faint source detection . in  [ sec : sourcephotometry ] we describe how to obtain the optimal coaddition image for photometric measurements , not restricted to faint sources . in  [ sec : theoreticalsensitivity ] , we give a simple to use formula to calculate the expected signal - to - noise ratio for source detection and psf photometry for both single images and ensembles of images . in ",
    "[ sec : weightedmedian ] , we suggest possible variants of this method , that albeit sub - optimal for source detection and photometry , are resilient to particle hits , and generalize the concept of median for images . in  [ sec : tests ] , we demonstrate our detection algorithm on simulated and real images and show it surpasses the sensitivity of current popular methods . in  [ code ] we briefly describe the code we use . finally , we summarize the important formulae and conclude in  [ sec : disc ] .",
    "denote the @xmath11th measured image , in a series of background - subtracted observations of the same position by @xmath12 .",
    "further , denote by @xmath13 the point spread function ( psf ) of the @xmath11th observation .    the statistical model for the @xmath11th image",
    "is given by : @xmath14 where @xmath15 denotes the true ( background subtracted ) sky image , @xmath7 is a scalar , representing the transparency ( same as in ",
    "[ sec : introduction ] ) , @xmath16 represents convolution , and the noise term @xmath17 has variance @xmath18 = b_j + ( f_jt)\\otimes p_j\\,,\\end{aligned}\\ ] ] where @xmath19 is the variance of all the position independent noise ",
    "the sum of the sky background variance , the read noise variance and the dark current variance . for simplicity",
    ", we assume that the gain is 1 and that the counts are measured in electrons .    in the following subsections we derive several",
    "well known important results of signal detection using hypothesis testing .",
    "the optimal detection of an attenuated signal in the presence of varying noise is reviewed in ",
    "[ subsec : examplegaussians ] . in ",
    "[ subsec : weightedaddition ] we derive a general rule for weighted addition of random variables , while in  [ subsec : matchedfilter ] we derive the well known linear matched filter solution for source detection .      in this section we review the simple problem of how to detect or measure a signal , with a known template , in data given by an ensemble of observations .",
    "we strictly assume that the signal in all observations is attenuated linearly with known attenuation coefficients , and that the noise in all the observations is gaussian .",
    "albeit simple , the solution to this problem is the key towards constructing an optimal algorithm for image coaddition .",
    "let @xmath20 be a set of independent gaussian variables with variance @xmath21 \\equiv \\sigma_j^2\\,.\\end{aligned}\\ ] ] given the null hypothesis , which states that there is no signal , and is denoted by @xmath22 , we assume : @xmath23 = 0\\,,\\end{aligned}\\ ] ] where @xmath24 $ ] denotes the expectancy of the variable @xmath25 given that the hypothesis @xmath26 is true .",
    "given the alternative hypothesis , that states there is a signal , and is denoted by @xmath27 , we assume : @xmath28 = \\mu_jt\\,.\\end{aligned}\\ ] ] here @xmath29 are known scaling factors of each observation . the log - likelihood ratio test statistic ( which is proven to be the most powerful test at any given size , and therefore optimal .",
    "see @xcite ) , is simply given by :    @xmath30    for detection purposes , i.e. , to reject the null hypothesis , the term @xmath31 can be ignored , as it does not depend on the data .",
    "however , this term is still relevant for flux measurements . simplifying and absorbing the factor of 2 into the likelihood , we get : @xmath32 the log - likelihood ratio is linear in @xmath15 , hence we can identify a sufficient statistic @xmath33 with a distribution that is independent of @xmath15 , and therefore can be used to reject the null hypothesis against the alternative hypotheses @xmath27 for all values of @xmath15 simultaneously .",
    "therefore , the optimal strategy for detection of a statistically significant signal , is to calculate @xmath34 , and check if it is above or below a certain threshold @xmath35 .",
    "the value of @xmath36 is fixed by the desired false alarm probability @xmath37 . to evaluate this threshold ,",
    "we need to calculate the expectancy and variance of @xmath34 given @xmath22 : @xmath38 = 0\\,,\\end{aligned}\\ ] ] given the independence of @xmath20 and the fact that @xmath39=\\sigma_j^2 $ ] , the variance of @xmath34 given @xmath22 is : @xmath40 = \\sum_j{\\frac{\\mu_j^2}{\\sigma_j^2}}\\equiv i\\,.\\end{aligned}\\ ] ] and the threshold is : , which is a good approximation for @xmath41 , which is the reasonable significance range for practical surveys . ]",
    "@xmath42    under the same definitions ,",
    "if we wish to get the most accurate estimator of @xmath15 , we can use the fact that the likelihood of the data can be calculated for all @xmath15 using @xmath34 ( eq . [ eq : s ] ) and @xmath43 ( eq . [ eq : i ] ) .",
    "this is because we can express the log likelihood of @xmath44 given @xmath15 by : @xmath45 where @xmath46 does not depend on @xmath15 and therefore can not influence any measurement . no matter if the bayesian or frequentist approaches are used , the likelihood of the data as a function of @xmath15 is sufficient for any further measurement or detection process . therefore , @xmath34 and @xmath43 are sufficient for any measurement or statistical decision on the set of statistics @xmath47 .      the statistics @xmath34 and @xmath43 we have derived in equations [ eq : s ] and [ eq : i ] naturally arise in a much more general setup , which is known as weighted addition of random variables .",
    "assume we have an arbitrary set of independent random variables @xmath20 and two hypotheses @xmath48 that satisfy @xmath49 = v[x_j|\\mathcal{h}_1 ] \\equiv v(x_j).\\end{aligned}\\ ] ] we can define the signal to noise ratio ( @xmath0 ) of a statistic @xmath34 with regard to the decision between @xmath22 and @xmath50 by : @xmath51 = \\frac{e(s|\\mathcal{h}_0 ) - e(s|\\mathcal{h}_1)}{\\sqrt{v(s)}}\\,.\\end{aligned}\\ ] ]    next , we can ask : what is the statistic , linear in @xmath52 , that maximizes this @xmath0 ?",
    "the solution to this problem is the following weighted mean : @xmath53 which coincides with the previously defined @xmath34 ( eq . [ eq : s ] ) .",
    "moreover , the maximal @xmath0 is @xmath54 .",
    "the detailed solution of this proplem is given in appendices [ appendixproperaddition ] and [ appendixmaxsnr ] .",
    "weighted addition extends also to the case of adding estimators .",
    "if we are given a sequence of independent measurements @xmath55 in which we assume only that @xmath56 = \\sigma_j^2 $ ] , the same set of statistics @xmath34 and @xmath43 arise , and the maximum s / n estimator for @xmath15 is : @xmath57 this simple and rigorous fact is derived in appendix [ appendixproperadditionestimators ] .",
    "the fact that this same solution repeats under many different general contexts and assumptions , allows us to derive optimal statistics to real - world astronomical problems .",
    "the first of them is the well known matched filter for source detection in single astronomical images .",
    "now that we are equipped with the simple yet robust tools for adding random variables , we can derive the standard matched filter solution for point source detection in a single image . to allow rigorous statistical analysis of source detection , we assume ( throughout the paper ) that the source we are trying to detect is well separated from other sources , which might interfere with its detection .",
    "let @xmath44 be an image such that : @xmath58 where @xmath15 is the true , background - subtracted sky image , @xmath59 is the image psf , and @xmath60 is an additive white gaussian noise term .",
    "we would like to detect , or measure , a single point source at position ( @xmath61,@xmath62 ) .",
    "each pixel coordinates ( @xmath63,@xmath64 ) in the image is an independent information source , where the psf scales the amount of flux each pixel would get .",
    "that is : @xmath65 using equation [ eq : s ] , we can write the optimal statistic for source detection at position @xmath66 for a single ] where @xmath67 .",
    "thus , we obtained the well known optimal statistic for the detection of a single source in an image with additive white gaussian noise .",
    "this solution is to convolve the image with it s reversed psf ( i.e. , cross correlation of the image with it s psf ) .",
    "this statistic is called the linear matched filter image .    due to its optimality , robustness and ease of implementation and interpretation , the linear matched filter is the method of choice for many source detection tools ( e.g. , sextractor ; @xcite ; see a review in @xcite ) .",
    "now that we have shown that using the tools outlined in  [ sec : statisticalbackground ] we get the optimal statistic for source detection in single images , we can apply these methods for source detection in an ensemble of images . before doing that it is worth while to develop an intuition on how the solution should look like . expanding the linear matched filter solution of one image to multiple images we expect the solution to be somewhat like a three dimensional linear matched filter summed over the image index axis , to get a statistic with the dimensions of an image .",
    "therefore , we expect that the solution will be simply matched filtering each image with its own psf followed by weighted summation .    for source detection , we assume that the noise is approximately gaussian and that the variance in each pixel , excluding the variance induced by the source itself , is independent of pixel position .",
    "since our null hypothesis is that there is no source , the noise induced by the source should be ignored .",
    "however , noise induced by neighboring sources can  not be ignored .",
    "therefore , our assumption that the variance is constant ( at least locally ) in the image is true only if the image is not crowded ( i.e. , confusion noise can be neglected ) .",
    "using these assumptions , we denote the variance of the @xmath11th image by : @xmath68\\ , .",
    "\\label{eq : vb}\\end{aligned}\\ ] ] here @xmath19 is the background ( or more formally the spatially invariant variance component ) of the @xmath12 image .",
    "we can now apply the machinery for coaddition of random variables developed in  [ sec : statisticalbackground ] to the problem of image coaddition .",
    "lets assume that we would like to detect a point source at position @xmath69 . in this case",
    "the model for such a point source is @xmath70 , where @xmath71 is the point source s flux and @xmath72 is a two dimensional array with @xmath73 at position @xmath69 and zero otherwise . inserting this to the model of @xmath12 we get : @xmath74 using the result from appendix [ appendixproperaddition ]",
    ", we can combine all the pixels from all the images as a list of independent statistics .",
    "therefore the optimal detection statistic for a source at position @xmath69 is : @xmath75 for simplicity @xmath63 represents the @xmath76 coordinate .",
    "using the fact that searching a source at position @xmath77 on a set of images , is exactly as searching for a source at position @xmath69 on the input images shifted by @xmath78 we get :    @xmath79    this can be written in vectorial notation as : @xmath80 where @xmath81 .",
    "we note that this could be easily computed ( using the fact that @xmath82 is a scalar ) in fourier space using the fast fourier transform : @xmath83 where the @xmath84 sign represents fourier transform , and the @xmath85 sign denotes the complex conjugate operation .",
    "we note that by putting the bar sign over the hat sign we mean that the complex conjugate operation follows the fourier transform operation .",
    "it is worth while to note that @xmath34 , the coaddition of filtered images is a log likelihood ratio image , where @xmath86 is the optimal test statistic for the existence of a source at @xmath87 . in order to find sources using @xmath34",
    ", we therefore have to search for local maxima .",
    "to decide if the source candidate is statistically significant , it is more convenient to normalize @xmath34 by it s standard deviation @xmath88 the value of each local maximum divided by the standard deviation of the noise ( eq . [ eq : s_sig ] ) is the source significance in units of standard deviations . to get @xmath34 in units of flux ( best estimate only in the context of background - noise dominated source ) , we need to normalize differently ( see eq .",
    "[ eq : properfluxestimate ] ) , to get :    @xmath89    analyzing our solution we can see that if we have only one image then the well known linear - matched filter is recovered .",
    "however , when we have more than one image , the optimal detection statistic is equivalent to applying a matched filter to each image separately , weighting the images by @xmath90 , and accumulating .",
    "this is different than the other solutions found in the literature , where you first coadd and then match filter , or perform partial filtering for homogenization , then coadd , and then match filter .",
    "the method we developed is optimal by construction , hence it will have better performance relative to other coaddition schemes .",
    "we note that with this method at hand , any additional image , no matter how poor the conditions are , will increase the sensitivity .",
    "therefore , the rejection of images becomes a damaging operation .",
    "because of the robustness of our optimality arguments , whenever the assumptions that we have made on the noise are true we expect this method to surpass the performance of all popular methods found in the literature .",
    "an important question is by how much our method improves source detection relative to other methods .",
    "the answer to this question depends on the details , like the distribution of observing conditions ( e.g. , seeing ) and the exact method we would like to compare with .",
    "we can quantify the gain of using our method , by answering a simple question : how much survey speed is being lost when a non - optimal filter is used in the case of a single image ?",
    "a single matched filter can not be adequate for multiple images with different psfs . no matter",
    "what weights are later applied in the combination of the different matched filtered images ( all with the same filter ) , the @xmath91 of the other methods can not surpass the sum of the @xmath91 in their individual pixels . given a single image with a gaussian psf with width @xmath8 , the best filter is a gaussian with width @xmath8 . in appendix",
    "[ ap : infopsflost ] we calculate the @xmath0 loss factor , when one uses a gaussian filter with a width @xmath92 .",
    "we find that the sensitivity ratio of these two cases is : @xmath93 this means that the reduction in survey speed ( or the detection information ) is : @xmath94    figure  [ fig : surveyspeed ] shows this survey speed reduction as a function of k. as expected , this function has a maximum of unity at @xmath2 . using a width which is a factor of @xmath95 ( @xmath96 ) different than the actual psf width will result in survey speed loss of about 6% ( 40% ) .",
    "therefore , given the typical distribution of seeing conditions , one should expect to obtain an improvement of between a few percents and about 25 percents in survey speed using our method , relative to e.g. , the @xcite weighted summation .",
    "another important problem in the context of astronomical image processing is measuring the flux of sources .",
    "the two leading methods for performing flux measurements are aperture photometry and psf photometry .",
    "both methods are well defined on single images . when the psf is exactly known , the method of psf photometry is the most exact since it applies an appropriate weight to each pixel before summation .",
    "aperture photometry is a good approximation that is often used when either the star is bright , the psf is unknown , or the measurement is done for sources that are not point like . in this section , we present the correct way to extend photometric measurements to ensembles of observations . in  [ subsec : psfphot ]",
    "we discuss the extension of psf photometry to ensembles of images and in  [ subsec : aperphot ] we cover aperture photometry .",
    "we note that in the case of spatially homogeneous noise variance ( i.e. , faint source ) and known psf , it is both easier and more accurate , to use the coaddition method presented in paper  ii , and then perform aperture / psf photometry .",
    "we define the optimal photometric measurement as a statistic @xmath34 such that the expectancy of the statistic is the true flux of the source and its variance is minimal .",
    "that is , @xmath97 = t\\,,$ ] and @xmath98 $ ] is minimal .",
    "this is equivalent to finding a statistic that maximizes the signal - to - noise ratio , and normalizing it to units of flux .",
    "because in the case of photometry we need to take into account the source noise , in this section we will work under the assumption that : @xmath99 where the distribution of @xmath17 is gaussian with variance @xmath18 = b_j + f_jt\\otimes p_j\\,,\\end{aligned}\\]]which does not distribute uniformly across the image , because bright stars have larger variance components .",
    "we note that we still assume that the measured source is well separated from other sources .",
    "following the same procedure we did for source detection , we get the maximum @xmath0 for the flux measurement .",
    "when measuring a point source at position @xmath69 , with true flux @xmath71 we can write : @xmath100 again , we assume every pixel is statistically independent from the others , and therefore we can apply the previously developed machinery ( eq . [ eq : properfluxestimate ] ) pixel by pixel , and get the maximal @xmath0 estimator : @xmath101    however , in order to compute this statistic , we need to know the true flux @xmath71 that we are looking for .",
    "this problem could be avoided by either :    * solving numerically for the true @xmath71 in iterations : guess @xmath102 , compute @xmath103 , and then update @xmath104 , and compute @xmath103 again with the resulting flux from the first iteration . since the first estimate of @xmath71 is an excellent first guess ,",
    "the latter is practically converged , and more iterations are unnecessary .",
    "this solution is source specific , and therefore should be implemented only if photometry of a single source is needed . *",
    "scanning the @xmath71 space logarithmically - using a slightly wrong @xmath71 does not lead to significant errors in the measurement . since the guess of @xmath71 influences only weights that are independent of the data itself",
    ", it does not introduce a bias .",
    "the standard deviation of a statistic that is calculated with a slightly wrong @xmath71 is generally very close to the optimal value .",
    "for example , using gaussian psfs with width @xmath105 pixels , @xmath106 and @xmath107 , we find that using @xmath108 which is wrong by a factor of 2 , leads to reduction of at most 1% in survey speed .",
    "this solution requires the co - addition process to produce several images ( @xmath109 , as the relevant range is from the background level up to the maximal dynamic range value .",
    "these numbers are typically only up to a factor of @xmath110 from one another ) .",
    "* aim for a specific @xmath71 .",
    "if one knows that the targets have a specific magnitude range , it is possible to use the most relevant @xmath71 .",
    "we want to stress , that the whole discussion on @xmath71 is only relevant for flux estimation of bright sources . for the detection of sources",
    ", we are not required to know @xmath108 apriori , as demonstrated in  [ sec : detectionfaint ] .",
    "the calculation of this measurement statistic can be done fast , by noticing that once @xmath71 is assumed , the calculation of the measurement statistic on all image positions can be done by convolution using the fast fourier transform ( fft ) .",
    "to gain intuitive interpretation of the psf photometry measurement statistic , it is useful to inspect the behavior of the statistic on one image . in the expression for @xmath103",
    ", we can identify the two general approximations astronomers often make in the extreme limits of the relation between the brightness of the target and the background .",
    "on the one hand , if a target is brighter than the background on many pixels , we can see that the optimal measurement statistic we obtained is similar to aperture photometry with the optimal aperture , as in the center the weights of the pixels converge to 1 . on the other hand",
    ", we see that if a target is much weaker than the background variance , the statistic converges to a matched filter on the image . when extending this to multiple images we can see that in the statistic @xmath103 , the combination of different images is rather non - trivial .      even when the psf is unknown , or when the object shape for which we perform flux measurements is poorly known ( e.g. , a galaxy ) , it is still important to combine the flux measurements from different images correctly .",
    "this is because observations in the ensemble will generally have different noise properties . for each image ,",
    "depending on the seeing conditions , source flux and its psf , one can choose the best aperture radius @xmath111 that maximizes the @xmath0 in the image ( see below ) .",
    "we can calculate from each image the aperture photometry measurement @xmath112where @xmath113 is given by : @xmath114 substituting equation  [ eq : m ] into equation  [ eq : theta ] : @xmath115 denote the source intrinsic light distribution by @xmath116 .",
    "@xmath116 satisfies : @xmath117 and @xmath118 .",
    "next , we define @xmath119 to be the fraction of the source flux within the measurement aperture .",
    "now , we can write : @xmath120 the variance of @xmath121 is : @xmath122 = \\mu_jt_0 + \\pi r_j^2\\sigma_j^2\\,.\\end{aligned}\\ ] ]    now that the problem is cast into the same form as solved in ",
    "[ sec : statisticalbackground ] , we can use the maximum @xmath0 measurement statistic ( eq.[eq : properfluxestimate ] ) to find the best estimator for aperture photometry : @xmath123    note that if the source is very strong , the term @xmath124 might dominate the noise variance @xmath125 $ ] . in that case",
    ", one needs to have a reasonable guess of the source flux @xmath71 prior to the coaddition process ( see  [ subsec : psfphot ] ) .",
    "moreover , one needs to solve for the best aperture radius @xmath111 ( that depends on @xmath71 ) .",
    "this solution can be obtained separately for each image by maximizing the squared signal to noise of @xmath126 : @xmath127 where @xmath128 denotes the value of the parameter @xmath129 for which the function @xmath130 obtains its maximum . maximizing this",
    "could be done if one has a model for @xmath131 , which could be deduced from the intrinsic size of the object measured and a rough psf model .",
    "for several reasons , including @xmath0 calculation and optimizations , it is worth while to have a formula for the @xmath0 of psf photometry over multiple images .",
    "albeit this formula is easy to derive , we are not aware of a simple analytic expression for the @xmath0 of psf photometry in the literature for either single or multiple observations .    following the previous section , we do not necessarily assume that the sources are weak compared to the sky , and therefore our measurement model is : @xmath132 where @xmath17 is gaussian with mean @xmath133 and variance @xmath18 = b_j + f_jt\\otimes p_j,\\end{aligned}\\ ] ] where @xmath134 is the background noise , and @xmath135 is the poisson noise of the source .",
    "in order to calculate the @xmath0 we refer to the fact that @xmath136 is an additive quantity .",
    "that is , for any two uncorrelated statistics @xmath137 , we can build a statistic @xmath138 such that the @xmath0 of @xmath139 satisfies @xmath140 = ( s / n)^2[s_1 ] + ( s / n)^2[s_2]\\,.\\end{aligned}\\ ] ] this fact is proven in appendix  [ appendixmaxsnr ] . using this ,",
    "all that we need to do in order to calculate the total @xmath91 of the optimal coaddition of a source with flux @xmath108 in an ensemble of images is to sum the @xmath136 over all the pixels in all the images .",
    "therefore , the @xmath136 for _ flux _ measurement ( the source noise term in the variance is irrelevant for detection purposes ) is given by : @xmath141 } dxdy } \\\\",
    "\\nonumber & = \\sum_j\\int_{-\\infty}^{\\infty}{\\frac{t_0 ^ 2f_j^2p_j^2(x , y)}{t_0f_jp_j(x , y ) + b_j } dxdy } , \\label{eq : snpsf_gen}\\end{aligned}\\ ] ]    for the sake of signal to noise calculation , it is a good enough approximation to assume that the psf is a two dimensional symmetric gaussian .",
    "rewriting the above with a gaussian psf , with width @xmath142 , and replacing the @xmath63 and @xmath64 coordinates by the radial coordinate @xmath129 this can be written as @xmath143)^{2}}{t_0f_je^{-r^{2}/(2s_j^{2})}/(2\\pi s_j^{2 } ) + b_j}2\\pi rdr}\\ , .",
    "\\end{aligned}\\ ] ] this integral has an analytic solution given by : @xmath144    in the source - noise dominated case ( @xmath145 ) , the formula simplifies to @xmath146\\ , .\\end{aligned}\\ ] ] in the background - noise dominated case ( @xmath147 ) , the @xmath91 becomes : @xmath148 we stress that this equation is correct only if the numbers @xmath71 and @xmath19 are in units of electrons .",
    "another remark is that equation  [ eq : snrformulamatchedfilter ] is actually the exact ( no approximation ) @xmath91 for the detection of a source with flux @xmath71 , because in this situation , the relevant variance should be exactly @xmath149 $ ] .",
    "therefore , by isolating @xmath71 in equation [ eq : snrformulamatchedfilter ] we can get a formula for the limiting magnitude for detection at a given @xmath0 : @xmath150",
    "a drawback of the method presented so far is that it uses the summation operator which is not resilient against outliers .",
    "outliers can be a major source of noise and often require a special treatment .",
    "the typical way outliers are dealt with is either using median coaddition , min / max rejection , or sigma clipping .",
    "the summation in either equation  [ eq : s_all ] or [ eq : s_conv ] includes weights , and in either case we may want to choose an operation which is more robust . because of the weights in equations  [ eq : s_all ] and [ eq : s_conv ] , a simple median operation is not possible .",
    "instead , one can use the weighted median estimator to replace the weighted average .",
    "the weighted median of a set of estimators @xmath151 is simply defined as the 50% weighted percentile of the normalized estimators @xmath152 , where each of the estimators is given the weight of the inverse standard deviation , @xmath153 . in a similar manner",
    ", one could apply sigma clipping to the estimators , removing estimators that deviate from the average estimated value of @xmath15 by more than 3 of its own standard deviation .",
    "it is important to note , that these operations make sense only when we measure the flux of unblended objects using the matched filtered images .",
    "note that since our method uses the matched filter image as the estimator , sharp outliers like cosmic rays or hot pixels will tend to reduce in significance ( as we are using the wrong filter for their detection ) .",
    "given the problems involved in using robust estimators , we would like to suggest a different approach , which is to identify and remove sharp outliers using image subtraction , given an artifact free image subtraction statistic .",
    "such an image subtraction algorithm can be found in @xcite . in the situation where a large number of images is coadded ( @xmath154 ) ,",
    "any outlier that will influence the final measurement must be easily visible in the subtraction image of any two images .",
    "therefore , the detection and removal of any significant outliers prior to coaddition should be possible , and probably constitutes the most accurate approach for dealing with artifacts .",
    "we will further discuss this in @xcite .",
    "to verify that our method indeed works properly and to try and identify possible problems we tested it on simulated data (  [ subsec : simulations ] ) and real data (  [ subsec : real ] ) .",
    "the actual improvement of the coaddition technique depends on the distribution of the observing conditions ( e.g. , seeing , background and transparency ) .",
    "therefore , we use parameters that roughly mimic typical observing conditions .",
    "obviously , for different surveys and use cases these parameters could vary significantly .",
    "we repeated the following simulation 100 times : we simulated 20 @xmath155pix@xmath156 images , each with 2048 stars in an equally spaced grid . for simplification",
    ", we assumed all the images have equal transparency .",
    "the seeing distribution was taken as uniform with full width at half maximum ( fwhm ) between 1.5 and 6 pixels .",
    "the background distribution was uniform between 500 to 1900e@xmath157pix@xmath158 .",
    "the point spread functions were assumed to be circular two dimensional gaussians .",
    "we adjusted the brightness of the sources to be close to the detection limit in the coadd image ( 100 photons per image , see  [ sec : theoreticalsensitivity ] ) .",
    "the images were created aligned , so no further registration was applied .",
    "next , we summed the images using various coaddition schemes .",
    "the techniques we tested are : ( i ) weighted summation of the images using the @xcite scheme ( see equation  [ eq : annis ] ) ; ( ii ) weighted summation of the images using the @xcite method ( see equation  [ eq : annis ] ) ; ( iii ) our method .",
    "we note that unlike @xcite or @xcite we did  not remove any images . to evaluate the detection @xmath0 of each method , we averaged the @xmath0 of all sources at their correct positions in the coaddition image ( using eq .",
    "[ eq : s_sig ] ) . given",
    "the number of sources simulated this average is accurate to the level of about @xmath159",
    ". we then calculated , using the specific seeing and brightness parameters of the images , the theoretically maximal @xmath0 for source detection ( eq . [ eq : snrformulamatchedfilter ] ) .    in figure",
    "[ fig : snr_distributions ] , we plot the distribution of the ratio of the obtained @xmath0 with the various methods and the theoretically calculated @xmath0 .",
    "it is clear that the method presented in this paper achieves the maximum possible @xmath0 , and that the symmetric scatter around it s value is the measurement error of the achieved @xmath0 .",
    "it is further clear that for this specific case , our method provides a @xmath160 higher @xmath0 than the method of @xcite , and a @xmath161 higher @xmath0 than @xcite .",
    "these translate to a survey speed increase of about 10% over @xcite , and 20% over @xcite .",
    "we performed several comparisons of our method with other techniques , using real data .",
    "our test data originates from the palomar transient factory ( ptf ; law et al .",
    "2009 ; rau et al . 2009 ) data release 2 .",
    "the images were obtained under various atmospheric conditions .",
    "all the images were reduced using the ptf / ipac pipeline ( laher et al . 2014 ) , and were photometrically calibrated ( ofek et al .",
    "2012 ) .",
    "we used four sets of images . for each",
    "set we prepared a deep reference image .",
    "the reference image is based on coaddition of a subset of the best images using the annis et al .",
    "( 2014 ) weights and no filtering .",
    "we also selected a subset of images which we coadded using the various techniques including : equal weights , annis et al .",
    "( 2014 ) weighting , jiang et al .",
    "( 2014 ) weighting , our optimal - detection coaddition and the optimal coaddition method described in paper  ii . in order to minimize non - linear registration effects we used a section of @xmath155pixels near the center of each field .",
    "the four sets of images , along with their selection criteria , are listed in table  [ tab : selection ] .",
    "small cutouts of the coadd images are presented in figure [ fig : coaddcomp ] .",
    "we note that it is very difficult to spot the fine differences between these images by eye and quantitative tests are required .",
    "llllll 1 & 100031 & 6 & 425 & ref .",
    "& variance@xmath1621000e@xmath157 & fwhm@xmath1624  & @xmath163 psf stars + & & & 45 & coadd & all images taken on oct , nov , dec 2012 & @xmath163 psf stars + 2 & 100031 & 6 & 425 & ref .",
    "& variance@xmath1621000e@xmath157 & fwhm@xmath1624  & @xmath163 psf stars + & & & 48 & coadd & all images taken on the first 9 days of each month in 2011 & @xmath163 psf stars + 3 & 100031 & 4 & 263 & ref . &",
    "variance@xmath1621000e@xmath157 & fwhm@xmath1624  & @xmath163 psf stars + & & & 39 & coadd & all images taken on oct , nov , dec 2012 & @xmath163 psf stars + 4 & 100031 & 4 & 263 & ref . & variance@xmath1621000e@xmath157 & fwhm@xmath1624  & @xmath163 psf stars + & & & 17 & coadd & all images taken on the first 9 days of each month in 2011 & @xmath163 psf stars    we multiply each image by its ccd gain ( to work in electron units ) .",
    "the images were coadded using sim_coadd.m ( ofek 2014 ) .",
    "this function first registers the images , using sim_align_shift.m , subtracts the background from all the images ( sim_back_std.m ) , calculates the weights ( for the various methods , weights4coadd.m ) , and estimates the psf for each image ( build_psf.m ) , and finally coadds the images .",
    "the program optionally filters each image with its psf prior to coaddition ( sim_filter.m ) .",
    "all these functions are available as part of the astronomy and astrophysics toolbox for matlab @xcite ( see additional details in  [ code ] ) .",
    "we note that the coaddition technique described in paper  ii , is implemented in sim_coadd_proper.m .    in order to compare between the various techniques ,",
    "we first run our source extraction code mextractor.m .",
    "like sextractor @xcite , this code uses linear matched filter to search for sources .",
    "however , while sextractor thresholds the filtered image relative to the standard deviation of the _ un_-filtered image , our code does the thresholding relative to the filtered image .",
    "this small , but important , difference means that our thresholding is always done in units of standard deviations , so images with different psfs can be compared easily .",
    "we set the detection threshold to @xmath164 .",
    "we note that the coadded images were always filtered using their psf .",
    "we matched the sources found in each coadded image , against sources found in the deep reference image .",
    "table  [ tab : comp ] lists the number of sources detected in each image ( @xmath165 ) , the number of sources in the reference that are matched in the coadd ( @xmath166 ) , the number of sources in the reference that are un - matched in the coadd image ( @xmath167 ) , and the number of false detections in the coadd ( @xmath168 ) .",
    "our method consistently finds more ( 3% to 12% ) real sources than other weighted - summation methods . we note that the slight increase in the number of false sources using our method is due to the effective better psf that our method has relative to regular weighted addition ( after matched - filtering ; see paper  ii ) .",
    "an image with better seeing , once matched filtered , has a larger number of uncorrelated scores , and therefore an increased amount of sources with score that is larger than some threshold .",
    "this effect is reproduced in simulations , and could be easily accounted for in the survey design by slightly increasing the threshold above which a source is declared statistically significant .",
    "it is further important to note that even if we fix the number of false positives to some constant , our method still detects more sources than the other techniques . in table",
    "[ tab : comp ] we also list the results based on the method presented in paper  ii . for source detection , the technique described in paper  ii is identical ( up to small numerical errors ) to the method discussed in this paper .",
    "however , the method described in paper  ii has several important advantages , and hence should be used whenever adequate .",
    "lllllll 1 & deep & 0 & 2433 & & & + & equal weights & 0.65 & 1136 & 1087 & 1346 & 49 + & @xcite&0.91 & 1332 & 1255 & 1178 & 77 + & @xcite&0.89 & 1299 & 1229 & 1204 & 70 + & this work & 1 & 1417 & 1324 & 1109 & 93 + & paper  ii & 1 & 1419 & 1325 & 1108 & 94 + 2 & deep & 0 & 2433 & & & + & equal weights & 0.59 & 1183 & 1085 & 1348 & 98 + & @xcite&0.93 & 1481 & 1343 & 1090 & 138 + & @xcite&0.90 & 1421 & 1301 & 1132 & 120 + & this work & 1 & 1541 & 1390 & 1043 & 151 + & paper  ii & 1 & 1542 & 1391 & 1042 & 151 + 3 & deep & 0 & 4062 & & & + & equal weights & 0.53 & 1645 & 1539 & 2523 & 106 + & @xcite&0.84 & 1955 & 1796 & 2266 & 159 + & @xcite&0.81 & 1912 & 1759 & 2303 & 153 + & this work & 1 & 2206 & 1976 & 2086 & 230 + & paper  ii & 1 & 2206 & 1976 & 2086 & 230 + 4 & deep & 0 & 4062 & & & + & equal weights & 0.83 & 2319 & 2007 & 2055 & 312 + & @xcite&0.82 & 2144 & 1981 & 2081 & 163 + & @xcite&0.92 & 2272 & 2062 & 2000 & 210 + & this work & 1 & 2401 & 2125 & 1937 & 276 + & paper  ii & 0.99 & 2400 & 2124 & 1938 & 276    next , we compared the detection @xmath136 of the sources in the various images is defined without the source - noise term in the denominator ( see eq .",
    "[ eq : snrformulamatchedfilter ] ) . ] .",
    "the reason for using @xmath136 is that it is an additive quantity , that is proportional to the survey speed and to the detection information . in order to do the comparison , we run mextractor.m again in forced - detection mode . in this mode",
    ", we provide the code with a list of positions of the sources detected in the deep reference image , and the code measures the detection significance and @xmath0 at these locations .",
    "for each one of the different coaddition methods on the subset of images we calculated the following quantity : for each star detected in the reference image , we divide its @xmath0 measured is measured by filtering the image with its psf , normalizing the filtered image by its own standard deviation , and reading the value at the local maximum that corresponds to the source . ] in a coaddition image by its s / n measured in our optimally coadded image .",
    "then , we sum the squares of these ratios , and calculate their median .",
    "this roughly gives the survey speed in each coadd image , relative to our coaddition method , and is listed in table  [ tab : comp ] ( @xmath169 ) . in these specific examples ,",
    "our method provide a factor of 17% to 47% improvement over un - weighted coaddition , and 8% to 18% improvement over the weighted addition methods .",
    "we note that this is sensitive to the exact seeing distribution of the observations and we estimate that the typical improvement will be between a few percents to 25% , relative to @xcite . finally , in figure  [ fig : sncomp ] we present , for data set 3 , the relative ratio between detection @xmath0 of individual sources in the coadded images relative to the detection @xmath0 in the optimal coadd image . again",
    ", our coaddition provides better @xmath0 both at the faint and bright ends .",
    "we note that using the techniques described in  [ sec : sourcephotometry ] , the flux measurement @xmath0 in the bright end can be further improved .     of individual sources in a coadded image relative to the optimal coaddition .",
    "our method is represented by the 1:1 line , while the @xcite and un - weighted coaddition are gray and black dots , respectively .",
    "this example is based on the third data set .",
    "[ fig : sncomp],width=321 ]",
    "the formulae we present in this paper are straight forward to code .",
    "however , most of the attention in the implementation should be given to pre - processing steps and measurements of the properties of the images .",
    "this includes estimating the background mean , the variance , the psf and cosmic ray removal .",
    "code that performs the coaddition technique suggested in this paper is available as part of the astronomy and astrophysics toolbox for matlab @xcite .",
    "this package can be used for all the image processing steps , including the de - bias , flat field correction and cosmic - ray removal . however , here we cover only the functions that are closely related to the coaddition step .",
    "table  [ tab : fun ] lists the high - level functions related to coaddition that we provide in the astronomy and astrophysics toolbox for matlab @xcite .",
    "many other low - level functions are documented in the code .",
    "these functions are under constant improvement , and we expect that versions with better performances will be available in the near future .",
    "each function has a detailed help section with examples .",
    "furthermore , a manual of the astronomy and astrophysics toolbox for matlab is also available .",
    "we note that usual implementation details like registration , resampling to the same grid , measuring the background and variance levels , and measuring / interpolating the psf , as always , require attention .",
    "however , the attention to the details required by this method is not different than that required for the successful application of other methods .",
    "below we comment on several important implementation details :    * background and variance estimation * : the background and variance in real wide field of view astronomical images can not be treated as constants over the entire field of view .",
    "therefore , we suggest to estimate them locally and interpolate . to estimate the background and variance one needs to make sure that the estimators are not biased by stars or small galaxies .",
    "our suggestion is to fit a gaussian to the histogram of the image pixels in small regions  arcsec@xmath156 blocks . ] , and to reject from the fitting process pixels with high values ( e.g. , the upper 10-percentile of pixel values ) .    *",
    "estimating the transparency * : the transparency @xmath170 of each image is simply its flux - based photometric zero point .",
    "however , one has to make sure that these zero points are measured using psf photometry rather than aperture photometry , otherwise the zero - points may depend on the seeing .    * estimating the psf * : among the complications that may affect the psf measurement are pixelization , interpolation and resampling .",
    "furthermore , the psf is likely not constant spatially and it also may change with intensity due to charge self repulsion .",
    "this specifically may lead to the brighter - fatter effect ( e.g. , walter 2015 ) .",
    "we note that the fact that one needs to estimate the psf in order to run this method should not be viewed as a drawback , as any decent method that finds sources in the image requires this step anyway .",
    "lll & coadd a list of images , using various weighting schemes .",
    "+ & the function also allows for filtering the images prior to the coaddition .",
    "+ & the function can also align the images , calculate the weights and psfs . + sim_coadd_proper.m & proper coaddition of images ( see @xcite ) .",
    "+ & the function can also align the images , calculate the weights and psfs . + & register a set of images against a reference image . + & the function assumes the images can be registered + & using an arbitrary large shift , but only a small rotation term .",
    "+ psf_builder.m & construct a psf template by re - sampling the pixels around + & selected bright / isolated stars .",
    "+ weights4coadd.m & calculate parameters required for calculation of weights for + & coaddition . including the background , its variance , estimate of the + & flux - based zero points ( i.e. , transparency ) , and measure the psf . + sim_back_std.m & estimate the spatialy - dependent background and variance of images .",
    "[ tab : fun ]",
    "we argue that popular image coaddition methods do  not achieve the maximal @xmath0 possible for source detection and photometry .",
    "we derive the optimal statistic for source detection and photometry under the assumptions that the noise is approximately gaussian and that the target is well separated from other bright sources .",
    "we show that the optimal way to coadd images for source detection is by filtering ( i.e. , cross - correlating ) each image with its psf , and then sum with weights .",
    "this method is summarized by equation  [ eq : s_conv ] ( or equivalently , eq . [ eq : s_hat ] ) . in order to find sources we need to find local maxima in the calculated score map .",
    "the significance of these sources in units of standard deviations is given by equation  [ eq : s_sig ] .",
    "we note that the computational requirements of applying the method are low , as the cross - correlation operation can be computed using the fast fourier transform ( fft ) .",
    "we also derive optimal statistics for psf photometry ( eq .  [ eq : t_psf_phot ] ) and aperture photometry ( eq .  [ eq : theta_aper_phot ] ) for an ensemble of images .",
    "finally we derive a formula to calculate the @xmath0 for psf photometry in an ensemble of images with a symmetric gaussian psf ( eq .  [ eq : snpsf_gauss ] ) . for statistical tasks other than source detection or photometric measurements",
    ", we refer readers to paper  ii in this series , in which we provide a coaddition method that is optimal for _ any _ statistical measurement or decision , under the more restrictive ( but common ) assumption of background dominated noise .",
    "we demonstrate our coaddition method for source detection on simulated images as well as on real images .",
    "our method increases the survey speed ( for faint source detection and photometry ) by between a few percents to 25% over traditional methods , both in theory and in practice .",
    "we thank avishay gal - yam , assaf horesh , frank masci , william newman , and ora zackay for discussions .",
    "this paper is based on observations obtained with the samuel oschin telescope as part of the palomar transient factory project , a scientific collaboration between the california institute of technology , columbia university , las cumbres observatory , the lawrence berkeley national laboratory , the national energy research scientific computing center , the university of oxford , and the weizmann institute of science .",
    "b.z . is grateful for receiving the clore fellowship .",
    "e.o.o . is incumbent of the arye dissentshik career development chair and is grateful for support by grants from the willner family leadership institute ilan gluzman ( secaucus nj ) , israel science foundation , minerva , weizmann - uk , and the i - core program by the israeli committee for planning and budgeting and the israel science foundation ( isf ) .",
    "here , we will show that the same statistic that was derived in ",
    "[ subsec : examplegaussians ] as an exact solution for detection of an attenuated signal in the presence of varying gaussian noise , is the solution of the much more robust question  maximizing the @xmath0 of the weighted addition of independent random variables .",
    "given a set of statistical variables , @xmath20 with two hypotheses @xmath22 and @xmath50 , with expectencies:= z_j$ ] , it is always possible to transfer the problem to hypothesis testing on @xmath171 , in which case the expectancy given the null hypothesis is again zero . ]",
    "@xmath23 = 0\\,,\\quad e[x_j|\\mathcal{h}_1 ] = \\mu_j\\,.\\end{aligned}\\ ] ] further , we assume that the variance of @xmath20 is equal under the assumption of both hypotheses .",
    "i.e , @xmath172 = v[x_j|\\mathcal{h}_1 ] = \\sigma_j^2\\,.\\end{aligned}\\ ] ]    if we know the exact distributions of the variables @xmath20 given both hypotheses , we can use the neyman - pearson lemma @xcite , which states that the optimal test statistic for the decision between @xmath22 and @xmath50 is the log - likelihood ratio test . here",
    ", we want to construct a test statistic that we can apply even when the exact distributions are unknown , but their first and second moments are known .",
    "given the fact that all the statistics are assumed to be independent , it is reasonable to assume that the correct way to combine the variables is via a linear sum ( if the distributions are known we can simply sum the difference in the log of the probablity of observing @xmath20 for each hypothesis ) .",
    "that is , we are interested in a linear statistic of the form : @xmath173    if the set of variables we have is large , so that the distribution of a weighted sum of the variables can be approximated by a gaussian distribution for both hypotheses , then the only important properties of the resulting sum are the expectancy of @xmath34 given both hypotheses , and the variance of @xmath34 given both hypotheses . moreover ,",
    "if the statistic has equal variance under both hypotheses , then there is one number that characterizes our ability to distinguish between the hypotheses , which is the squared signal - to - noise ratio : @xmath174 \\equiv \\frac{|e[s|\\mathcal{h}_0 ] - e[s|\\mathcal{h}_1]|^2}{v[s]}\\,.\\end{aligned}\\ ] ] thus , we want to find the linear combination that maximizes the @xmath0 .",
    "i.e. , find a set of weights @xmath175 such that the score in equation  [ ap : eq : s ] will have maximal @xmath0 ( equation  [ ap : eq : snr ] ) .",
    "we assume that @xmath20 , @xmath29 , and @xmath175 are complex variables ( this will become useful in future papers in the series ) . substituting \\{0,@xmath29 } as the expectancies of @xmath20 given the two hypotheses , we get : @xmath176 , where @xmath177 , the variance of @xmath34 is : @xmath178 = \\sum_j{|\\beta_j|^2\\sigma_j^2}\\,.\\end{aligned}\\ ] ] in order to maximize the squared @xmath0 with respect to @xmath175 , we equalize all the partial derivatives to zero : @xmath179\\right)}{\\partial \\beta_j } = 0\\ , , \\end{aligned}\\ ] ] which gives us : @xmath180 where the @xmath85 accent denotes complex conjugation . simplifying , we get the equation : @xmath181 noticing that multiplying all the weights @xmath175 by a constant factor does not change the @xmath0 , we can simplify further and get : @xmath182 - e[x_j|\\mathcal{h}_0]}}{v_j}\\,.\\end{aligned}\\ ] ] thus , we now have a general formula for weighted addition of random variables .",
    "we note that if the exact distributions of the random variables are known , then the optimal combination is the log - likelihood ratio test statistic .",
    "this statistic could be composed of some function of the variables themselves that is not linear .",
    "this means that the best score will be of the form @xmath183 what we have derived in this appendix , is the best linear approximation to this score , that could be derived under much less exact knowledge on the variables themselves .",
    "here , we will show that the same statistic that was derived in ",
    "[ subsec : examplegaussians ] and appendix [ appendixproperaddition ] is the solution ( up to a multiplicative constant ) of another general question : what is the maximum @xmath0 linear combination of independent estimators ?    given a set of statistics @xmath126 such that @xmath184 where @xmath29 are known complex variables , @xmath185 = 0\\ , , \\quad v[\\epsilon_j ] = \\sigma_j^2\\,.\\end{aligned}\\ ] ] we want to find the best weighted linear combination estimator @xmath186 such that @xmath187 = t\\,,$ ] and @xmath188 $ ] is minimal . calculating the expectancy of @xmath189",
    "we get : @xmath190 = \\sum_j{\\beta_j\\mu_jt}\\,,\\end{aligned}\\ ] ] while the variance of @xmath189 is : @xmath191 = \\sum_j{|\\beta_j|^2\\sigma_j^2}\\,.\\end{aligned}\\ ] ] maximizing the @xmath91 of the estimator : @xmath192 \\equiv \\frac{|e[\\theta]|^2}{v[\\theta]}\\,,\\end{aligned}\\ ] ] is equivalent to minimizing the variance of @xmath189 with respect to a fixed @xmath187 $ ] .",
    "moreover , @xmath193 $ ] is invariant to scalar multiplication of @xmath189 because : @xmath194 = \\frac{|e[\\beta\\theta]|^2}{v[\\beta\\theta ] } = \\frac{|\\beta|^2|e[\\theta]|^2}{|\\beta|^2v[\\theta ] } = ( s / n)^2[\\theta]\\,.\\end{aligned}\\ ] ] therefore , we can maximize @xmath193 $ ] with respect to all @xmath175 . after normalization",
    "the minimum variance estimator is : @xmath195    to maximize @xmath193 $ ] with respect to @xmath175 , we equalize all the partial derivatives to zero : @xmath196}{\\partial \\beta_j } = 0\\ , , \\end{aligned}\\ ] ] which gives us : @xmath197}{\\partial \\beta_j}\\frac{e[\\theta]}{v[\\theta ] } - \\frac{\\partial v(\\theta)}{\\partial \\beta_j}\\frac{e[\\theta]}{v[\\theta]^2 } = 2\\overline{\\mu_j}\\frac{e[\\theta]}{v[\\theta ] } - 2\\beta_j\\sigma_j^2\\frac{e[\\theta]}{v[\\theta]^2}\\,,\\end{aligned}\\ ] ] where the accent @xmath198 denotes complex conjugation . simplifying , we get the equation : @xmath199}{e[\\theta]}\\,.\\end{aligned}\\ ] ] because @xmath193 $ ] is invariant under multiplication by a constant factor , we get : @xmath200 adjusting the estimator to match our first requirement that @xmath187 = t$ ] we can finally write :    @xmath201",
    "in appendix [ appendixproperaddition ] we find the best way to add statistics even when we do  not know their exact distributions . here",
    "we would like to derive a closed formula for the @xmath0 of the resulting statistic .",
    "denote by @xmath202 = \\frac{|\\delta e[x_j]|^2}{v[x_j]}\\,.\\end{aligned}\\ ] ] writing the expression for the statistic @xmath34 , the maximum @xmath203 weighted addition of the variables defined in appendix [ appendixproperaddition ] : @xmath204}\\,x_j}{v[x_j]}}\\,.\\end{aligned}\\ ] ] calculating the expected difference in @xmath34 given the two different hypotheses we get : @xmath205 = e[s|\\mathcal{h}_1 ] - e[s|\\mathcal{h}_0 ] = \\sum_j{\\frac{|\\delta e[x_j]|^2}{v[x_j]}}\\,,\\end{aligned}\\ ] ] while the variance of @xmath34 is : @xmath206 = \\sum_j{\\frac{|\\delta e[x_j]|^2}{v[x_j]^2}v[x_j ] } = \\sum_j{\\frac{|\\delta e[x_j]|^2}{v[x_j]}}\\,.\\end{aligned}\\ ] ] therefore , the squared @xmath0 of @xmath34 is simply given by : @xmath207 = \\frac{\\left(\\sum_j{\\frac{|\\delta e[x_j]|^2}{v[x_j]}}\\right)^2}{\\sum_j{\\frac{|\\delta e[x_j]|^2}{v[x_j ] } } } = \\sum_j{\\frac{|\\delta e[x_j]|^2}{v[x_j ] } } = \\sum_j{\\left(s / n\\right)^2[x_j]}\\,.\\end{aligned}\\ ] ]    this means that the squared @xmath0 of a statistic which is the optimal weighted addition of a set of statistics is the sum of squared @xmath0 s of the individual statistics .",
    "this property now allows us to easily estimate the sensitivity of observations ahead of time , with an intuitive closed formula .",
    "this ( almost ) same calculation applies also for optimal weighted addition of estimators , and we omit it to prevent cumbersome repetitions .",
    "here we derive an analytic solution to the question how much sensitivity is lost in the detection process when the wrong linear matched filter is used . following previous sections , we define the measured image by : @xmath208 and assume that the source we are trying to detect is well separated from other sources .",
    "we also assume that the source we are looking for is faint relative to the background , leading to a spatially invariant noise variance : @xmath209 = \\sigma^2\\,.\\ ] ] for simplification , we assume that the psf , @xmath59 , can be approximated as a symmetric gaussian . we define @xmath210 as the width of the real psf @xmath59 , while @xmath211 is the width of the gaussian used for match filtering . denoting by @xmath212 the weight for the pixel @xmath63 , when using a kernel with width @xmath213 .",
    "now , we can calculate the @xmath91 of the statistic @xmath214 by : @xmath215   = \\frac{e[w(s_u)]^2}{v[w(s_u ) ] } =   \\frac{(\\sum_{x}{w_{x}(s_u)e[m(x)]})^{2}}{\\sum_{x}{w_{x}^{2}(s_u)v[m(x)]}}\\,.\\end{aligned}\\ ] ] substituting the psf and the match filtering kernel with the relevant gaussians , and approximating the sums with integrals , we get : @xmath216 & = \\frac{t_0 ^ 2\\frac{1 } { ( 2\\pi)^{2}s_{u}^{2}s_{r}^{2}}\\int{e^{-\\vert x\\vert^{2}/(2s_{u}^{2 } ) } e^{-\\vert x\\vert^{2}/(2s_{r}^{2 } ) } dx_{1}dx_{2 } }   } { \\sigma^2\\frac{1 } { ( 2\\pi)^{2}s_{u}^{4}}\\int{e^{-\\vert x\\vert^{2}/(s_{u}^{2 } ) }   dx_{1}dx_{2 } }    }      \\\\&= \\frac{t_0 ^ 2}{\\pi\\sigma^2 } \\frac{s_{u}^{2}}{(s_{u}^{2}+s_{r}^{2 } ) ^{2 } } = \\frac{t_0 ^ 2}{\\pi\\sigma^2s_r^2 } \\frac{s_{u}^{2}s_{r}^{2}}{(s_{u}^{2}+s_{r}^{2 } ) ^{2}}\\ , , \\label{eq : infopsflost}\\end{aligned}\\ ] ] where @xmath217 .",
    "the maximum of this function with respect to a given value of @xmath218 is obtained at @xmath219 . when substituting @xmath220 , and dividing the @xmath91 by the maximum possible , we get : @xmath221}{(s / n)^2[w(s_r)]}&= \\frac{\\frac{t_0 ^ 2}{\\pi\\sigma^2s_r^2 } \\frac{s_{u}^{2}s_r^2}{(s_{u}^{2}+s_{r}^{2 } ) ^{2}}}{\\frac{t_0 ^ 2}{\\pi\\sigma^2s_r^2 } \\frac{s_{r}^{4}}{(s_{r}^{2}+s_{r}^{2 } ) ^{2 } } }",
    "\\\\&= 4\\frac{s_u^2s_r^2}{(s_u^2 + s_r^2)^2 } = \\frac{(2k)^2}{(k^2 + 1)^2 } = \\left(\\frac{2k}{k^2 + 1}\\right)^2\\,.\\end{aligned}\\ ] ] figure  [ fig : surveyspeed ] shows a plot of the loss in survey speed when using the wrong psf , as derived above .",
    "this simple exercise gives us an idea how much sensitivity we lose when we combine images with different psfs , because when we match filter the coadded image , all images are match filtered with a single psf , that can not simultaneously be optimal to all of them ."
  ],
  "abstract_text": [
    "<S> stacks of digital astronomical images are combined in order to increase image depth . </S>",
    "<S> the variable seeing conditions , sky background and transparency of ground - based observations make the coaddition process non - trivial . </S>",
    "<S> we present image coaddition methods optimized for source detection and flux measurement , that maximize the signal - to - noise ratio ( @xmath0 ) . </S>",
    "<S> we show that for these purposes the best way to combine images is to apply a matched filter to each image using its own point spread function ( psf ) and only then to sum the images with the appropriate weights . </S>",
    "<S> methods that either match filter after coaddition , or perform psf homogenization prior to coaddition will result in loss of sensitivity . </S>",
    "<S> we argue that our method provides an increase of between a few and 25 percent in the survey speed of deep ground - based imaging surveys compared with weighted coaddition techniques . </S>",
    "<S> we demonstrate this claim using simulated data as well as data from the palomar transient factory data release 2 . </S>",
    "<S> we present a variant of this coaddition method which is optimal for psf or aperture photometry . </S>",
    "<S> we also provide an analytic formula for calculating the @xmath0 for psf photometry on single or multiple observations . in the next paper in this series </S>",
    "<S> we present a method for image coaddition in the limit of background - dominated noise which is optimal for any statistical test or measurement on the constant - in - time image ( e.g. , source detection , shape or flux measurement or star - galaxy separation ) , making the original data redundant . </S>",
    "<S> we provide an implementation of this algorithm in matlab . </S>"
  ]
}