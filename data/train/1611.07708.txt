{
  "article_text": [
    "ideas to immunize optimization problems against perturbations in model parameters arose as early as in 1970s .",
    "a worst - case model for linear optimization such that constraints are satisfied under all possible perturbations of the model parameters was proposed in @xcite .",
    "a common approach to solving this type of models is to transform the original uncertain optimization problem into a deterministic convex program . as a result ,",
    "each feasible solution of the new program is feasible for all allowable realizations of the model parameters , therefore the corresponding solution tends to be rather conservative and in many cases even infeasible . for a detailed survey ,",
    "see the recent monograph @xcite .    for traditional stochastic programming approaches ,",
    "uncertainties are modeled as random variables with known distributions . in very few cases ,",
    "analytic solutions are obtained ( see , e.g. birge and louveaux @xcite , ruszczynski and shapiro @xcite ) .",
    "these approaches may not be always applicable in practice , as the exact distributions of the random variables are usually unknown .    in the framework of robust optimization ,",
    "uncertainties are usually modeled by uncertainty sets , which specify certain ranges for the random variables .",
    "the worst - case approach is used to handle the uncertainty .",
    "it is often computationally advantageous to use the  robust \" formulation of the problem .",
    "however , the use of uncertainty sets as the possible supporting sets for the random variables is restrictive in practice ; it leads to relatively conservative solutions .",
    "the recently developed  distributionally robust \" optimization approach combines the philosophies of traditional stochastic and robust optimization ",
    "this approach does not assume uncertainty sets , but keep using the worst - case methodology . instead of requiring the shape and size of the support sets for the random variables",
    ", it assumes that the distributions of the random variables satisfying a set of constraints , often defined in terms of moments and supports .",
    "since the first two moments can usually be estimated via statistical tools , the distributionally robust model appears to be more applicable in practice .",
    "furthermore , since it takes the worst - case expected cost , it inherits computational advantages from robust optimization .",
    "due to these advantages , distributionally robust optimization has attracted more and more attention in operations research community @xcite .    in this paper , we propose a novel optimal control model with an uncertain parameter for which its exact distribution is unknown .",
    "however , it is assumed that the mean and the standard deviation of the uncertain parameter are known .",
    "the optimal control is found by minimizing the worst - case expectation with respect to all distributions in an  ambiguity set \" .",
    "both the problems with discrete probability distribution and with continuous probability distribution will be discussed .",
    "we first consider the case of discrete probability distribution , in which the min - max optimal control problem is transformed into an equivalent finite dimensional minimization problem via duality .",
    "then the necessary conditions of optimality are derived .",
    "the results for the case of discrete probability distribution are then extended to the case with one dimensional continuous stochastic variable .",
    "the control parametrization methodology is applied to parameterise the continuous stochastic variable .",
    "finally , an example is solved showing the potential application of the proposed optimal control framework and the effectiveness of the algorithm .",
    "for simplicity , we only discuss optimal control of dynamical systems with a single uncertain parameter .",
    "however , the results can be directly extended to cases involving multiple independent uncertain parameters .    to begin with ,",
    "consider a system of ordinary differential equations with an uncertain parameter as follows : @xmath1 where @xmath2 is the state vector , @xmath3 is the control vector function , and @xmath4 is an uncertain parameter .",
    "in general , the parameter @xmath5 is regarded as uniquely determined . in reality , however , this hypothesis often does not hold , since parameter @xmath5 is uncertain subject to variability .",
    "the only reliable information is that the value of the parameter falls within a certain range and that its potential values follow some statistical distribution .",
    "our interest focuses on the following distributionally robust optimal control problem . @xmath6,\\ \\ x(0)=x^0,\\label{dr - sc } \\\\&&\\ \\ \\ \\ \\ \\",
    "p\\sim f\\in \\mathcal{f}(\\mu,\\sigma^2)=\\{f:\\mathbb{e}_{f}(p)=\\mu , \\mathbb{e}_{f}(p-\\mu)^2=\\sigma^2\\ } , \\label{dr - fc } % & & \\ \\ \\ \\ \\ \\ \\mathbb{e}_{f}c(x(t_f;u , p))=0,\\label{dr - tc } \\\\ & & \\ \\ \\ \\ \\ \\ u(t)\\in u\\subset r^{n_u}.\\label{dr - uc}\\end{aligned}\\ ] ] here , @xmath7 is a compact and convex subset of @xmath8 .",
    "the difference between problem ( drocp ) and the standard optimal control problem is that the parameter @xmath5 herein is considered as a stochastic variable with distribution @xmath9 .",
    "the distribution @xmath9 , however , is not exactly known .",
    "the only knowledge , which is available , is the mean and the standard deviation of the distribution @xmath9 ; they are denoted by @xmath10 and @xmath11 , respectively .",
    "the set of all such distributions is denoted by @xmath12 . any measurable function defined in",
    "@xmath13 $ ] with values in @xmath7 is called an admissible control .",
    "let @xmath14 be the class of all such admissible controls .",
    "it is sufficient to discuss the objective function in mayer form , because the problems in bolza or lagrange form can be transformed into this form by introducing a new variable .",
    "see , e.g. , @xcite for a detailed description .    throughout this paper",
    ", we make the following assumptions .",
    "* the functions @xmath15 and @xmath16 are at least continuously differentiable with respect to all their arguments .",
    "+ * for each fixed @xmath4 , there exist positive constants @xmath17 and @xmath18 such that the following inequality holds @xmath19    from the classical differential equation theory ( see , for example , proposition 5.6.5 in @xcite ) , we recall that the system ( [ s1 ] ) admits a unique solution , @xmath20 , corresponding to each @xmath21 and @xmath22 .",
    "problem ( drocp ) can be roughly stated as : find a control @xmath21 such that the worst - case expectation from all feasible distributions is minimized over @xmath14 .",
    "obviously , problem ( drocp ) is a min - max optimal control problem .",
    "in this section , we focus on the case of discrete distributions . in this case",
    ", we will reformulate the distributionally robust optimal control as an equivalent combined optimal control and optimal parameter selection problem by using a dual transformation .",
    "we will then develop an algorithm to solve the resulting problem based on the parametric sensitivity functions and the control parametrization method .",
    "let @xmath23 be a possible value of the parameter @xmath5 , and let @xmath24 be the corresponding probability , i.e. , @xmath25 , @xmath26 .",
    "we first investigate the inner @xmath27-optimization problem , in which the value of @xmath28 is fixed . in this context",
    ", there are @xmath29 possible system trajectories due to @xmath29 different values of the parameter @xmath5 .",
    "let @xmath30 be the trajectory of system ( [ s1 ] ) with @xmath31 .",
    "when there is no confusion , @xmath30 is written as @xmath32 .",
    "each possible trajectory yields a corresponding system cost @xmath33 .",
    "the inner subproblem is to evaluate the worst - case expectation from all possible distributions , which is given as follows : @xmath34 note that the only variables to be optimized in the above inner subproblem are @xmath24 , @xmath26 .",
    "hence , the constraints ( [ dr - sc ] ) and ( [ dr - uc ] ) are not present in isp .",
    "in addition , problem ( isp ) is a linear programming , and its dual is given as follows : @xmath35 where @xmath36^{\\top } , \\qquad y:=[y_{1},y_2,y_3]^{\\top},\\nonumber\\\\ & a^i:=[1,p^i,{(p^i)}^2]^{\\top } , \\qquad i=1,2,\\cdots , m.\\nonumber\\end{aligned}\\ ] ]    there is no duality gap between the inner subproblem and its dual problem , since the feasible set of problem ( isp ) is nonempty and bounded . thus , the original problem ( drocp ) is equivalent to the following problem : @xmath37,\\ i=1,2,\\cdots , m,\\ \\ x^i(0)=x^0,\\label{d3}\\\\ % & & \\ \\ \\ \\ \\ \\",
    "c(x^i(t_f;u , p^i))=0 , \\ \\",
    "i=1,2,\\cdots , m,\\label{d4}\\\\ & & \\ \\ \\ \\ \\ \\    u\\in\\mathcal{u}.\\end{aligned}\\ ] ]    problem ( dual - drocp ) can be regarded as a combined optimal control and optimal parameter selection problem , where @xmath28 is the control function and @xmath38 is a parameter vector to be optimized .",
    "let @xmath39 and @xmath40 . combining system ( [ d3 ] ) and the scalar inequality constraints ( [ d2 ] ) to the cost function @xmath41 with multiplier functions @xmath42_{m\\times n_{x}}$ ] and multiplier vector @xmath43^{\\top}$ ] yields the lagrangian of problem ( dual - drocp ) as given below .",
    "@xmath44dt\\nonumber\\\\ & = y^{\\top}b+\\sum\\limits_{i=1}^m\\theta_i[y^{\\top}a^i - h(x^i(t_f;u , p^i))]-\\sum\\limits_{i}^{m}\\int_{0}^{t_f}\\lambda^i(t)f^idt\\nonumber\\\\ & ~+\\sum\\limits_{i}\\lambda^i(t_f)x^i(t_f)-\\sum\\limits_{i}^m\\lambda^i(0)x^i(0)-\\sum\\limits_{i}^m\\int_{0}^{t_f}\\dot{\\lambda}^i(t)x^i(t)dt,\\nonumber\\end{aligned}\\ ] ] where @xmath45 $ ] .",
    "let @xmath46 and @xmath47",
    ". then @xmath48dt\\\\ & + & \\epsilon\\sum\\limits_{i=1}^m\\lambda^i(t_f)\\delta x^i(t_f)-\\epsilon\\int_{0}^{t_f}\\sum\\limits_{i=1}^m\\dot{\\lambda}^i(t)\\delta x^i(t)dt+ o(\\epsilon).\\end{aligned}\\ ] ]    based on the fundamental variational principle @xcite , we have the necessary optimality conditions of problem ( dual - drocp ) given in the following as a theorem .",
    "[ opti ] consider problem ( dual - drocp ) .",
    "if @xmath49 is an optimal control , and @xmath50 is the corresponding state .",
    "then there exist costate functions @xmath51 $ ] , @xmath26 , and a multiplier vector @xmath52^{\\top}$ ] with @xmath53 , @xmath26 , such that    * @xmath54 ; * @xmath55 and the terminal condition @xmath56 , @xmath57 ; * @xmath58 ; * @xmath59 , @xmath26 .",
    "assume that @xmath60 is a solution of problem ( dual - drocp ) .",
    "clearly , the optimal control function , @xmath61 , for problem ( dual - drocp ) is also the optimal solution of problem ( drocp ) .",
    "then , the optimal distribution , @xmath62 , can be obtained by solving problem ( isp ) with @xmath63 .",
    "the algorithm framework for the solution of problem ( drocp ) is presented as follows .",
    "solve problem ( dual - drocp ) , denote the solution by @xmath60 ; * step 2 .",
    "for each possible parameter @xmath23 , @xmath26 , compute the optimal trajectories , @xmath64 , and the corresponding cost @xmath33 ; * step 3 .",
    "compute the optimal solution @xmath62 of problem ( isp ) by using linear programming solver .",
    "note that we can obtain the most robust optimal control @xmath61 by only solving problem ( dual - drocp ) .",
    "the corresponding `` worst '' distribution @xmath62 shall also be obtained for many practical problems . in this case , we can estimate the distribution of the performance under the most robust optimal control and the corresponding distribution of the uncertain parameter .",
    "therefore , problem ( drocp ) is solved completely by further carrying out step 2 and step 3 in the above algorithm framework .    for the above algorithm framework ,",
    "step 2 and step 3 can be computed readily .",
    "thus , the remaining problem is on how to solve problem ( dual - drocp ) .",
    "let @xmath65 be the partition grids of the time horizon @xmath13 $ ] .",
    "on the control parametrization framework , the control function @xmath66 is approximated by a piecewise constant function or a piecewise linear function , where the heights of these approximate functions are decision variables .",
    "in fact , the control function can be approximated by a linear combination of any appropriate set of basis functions .",
    "thus , problem ( dual - drocp ) is approximated as a finite - dimensional optimization problem , where the coefficients of the basis functions are regarded as decision variables . in this paper ,",
    "the control is approximated as a piecewise constant function in the form as given below :    @xmath67,\\end{aligned}\\ ] ]    where @xmath68^{\\top}\\in u$ ] , @xmath69 , @xmath70 , and @xmath71 denotes the characteristic function of @xmath72 .",
    "define @xmath73^{\\top}$ ] and @xmath74 . clearly , the control @xmath28 defined in the form of ( [ uv ] ) is one to one corresponding with the @xmath75 control parameter vector @xmath76 .",
    "let @xmath77 be the solution of system ( [ s1 ] ) corresponding to @xmath78 . with some abuse of notation ,",
    "@xmath77 is abbreviated as @xmath79 or @xmath80 when no confusion can arise .",
    "then , the parameterized problem for problem ( dual - drocp ) can be stated as given below : @xmath81,\\ i=1,2,\\cdots , m , \\",
    "x^i(0)=x^0 , \\label{dd3}\\\\   % & & \\ \\ \\ \\ \\ \\ c(x^{v , i}(t_f))=0,\\ i=1,2,\\cdots , m .",
    "\\label{dd4 } \\\\ & & \\ \\ \\ \\ \\ \\ v\\in\\mathcal{v}.\\end{aligned}\\ ] ]      problem ( discre - dual - drocp ) is essentially a finite - dimensional optimization problem , which can be solved readily by various optimization techniques . in general , the values of the objective function and the constraint functions and their respective gradients are required to be computed at each iteration of the optimization procedure .",
    "the gradient of the objective function is obvious since it is only a linear function of @xmath38 .",
    "the gradients of the constraint functions can be evaluated by solving either the adjoint equations ( see , for example , @xcite ) or the sensitivity function ( see , for example , @xcite ) . in this paper , the method based on the sensitivity function is used . the parametric sensitivity system and the gradient formulas",
    "are given in the following as a theorem .",
    "furthermore , the gradients of the constraint functions @xmath94 , @xmath26 , with respect to @xmath76 , are given by @xmath95 where @xmath96^{\\top}$ ] , and its components are given by ( [ ps ] ) .",
    "problem ( discre - dual - drocp ) differs from the standard mathematical programming problems in the sense that it involves the dynamic system ( [ dd3 ] ) and the end - point constraints ( [ dd2-new ] ) . the dynamic constraint ( [ dd3 ] ) as well as the systems of differential equations of the parametric sensitivity functions are solved by an ordinary differential equation ( ode ) solver in each iteration of the optimization procedure .",
    "the end - point constraints ( [ dd2-new ] ) are handled as follows .",
    "define @xmath97 and @xmath98",
    ". constraints ( [ dd2-new ] ) are equivalent to the following equality constraint : @xmath99 however , @xmath100 is nonsmooth in @xmath101 .",
    "standard optimization routines would have difficulties in handling this type of equality constraints . a widely used smoothing technique",
    "@xcite is to approximate @xmath102 by @xmath103    by using the quadratic penalty function , problem ( discre - dual - drocp ) is finally approximated by @xmath104,\\ i=1,2,\\cdots , m,\\label{ld3}\\\\   & & \\ \\ \\ \\ \\ \\ x^i(0)=x^0 .",
    "\\label{ld4}\\end{aligned}\\ ] ] where @xmath105 and @xmath106 is the penalty parameter .",
    "the algorithm framework for the solution of problem ( qp - dual - drocp ) , which is constructed based on algorithm 17.4 in @xcite , is stated as follows .",
    "* algorithm 3.1 *    * initialize : + choose an initial point @xmath107 .",
    "choose convergence tolerances @xmath108 and @xmath109 .",
    "choose positive constants @xmath110 , @xmath111 , @xmath112 and @xmath113 . set @xmath114 , @xmath115 ; + * repeat + * * for @xmath116 , integrate system ( [ ld3])-([ld4 ] ) together with the parametric sensitivity systems ( [ ps ] ) forward in time from 0 to @xmath117 .",
    "* * evaluate the value of the merit function @xmath118 and its gradients , denoted by @xmath119 and @xmath120 , respectively . * * if @xmath121\\|\\leq \\omega_k$ ] , where @xmath122 is the partial projection of the vector @xmath123 onto the rectangular box @xmath124 $ ] at the current point @xmath125 , defined by @xmath126 then goto ( s4 - 1 )",
    ". otherwise , goto ( s4 - 2 ) .",
    "* * if @xmath127 , goto ( s5 - 1 ) ; otherwise , goto ( s5 - 3 ) * * using a line search method to find the next point @xmath128 , replace @xmath125 by @xmath128 , and goto ( s1 ) . * * stopping criterion + if @xmath129 and @xmath121\\|\\leq \\omega_*$ ] , stop .",
    "record the approximate solution @xmath130 obtained .",
    "otherwise , goto ( s5 - 3 ) .",
    "* * tighten tolerance + set @xmath131 and goto ( s5 - 3 ) . * * increase penalty parameter + set @xmath132 , @xmath133 , @xmath134 , and goto ( s1 )",
    ".    note that since @xmath135 is an intermediate variable depending on @xmath76 and @xmath136 rather than an independent variable , the merit function @xmath118 can , in essence , be regarded as a function of @xmath76 and @xmath38 .",
    "thus , the gradient of @xmath118 only composes of the partial derivatives of @xmath118 with respect to @xmath76 and @xmath38 ; it is a vector of dimension @xmath137 .",
    "for the case of continuous distributions , the cost function @xmath138 can be considered as a function of @xmath28 and @xmath5 , because the state @xmath139 is only an intermediate variable depending on @xmath28 and @xmath5 . for a fixed @xmath28 ,",
    "the inner sub - problem is given as follows .",
    "@xmath140    to extent the results obtained for the case of discrete distributions detailed in the previous section to the case of continuous distributions , we propose a scheme for the discretization of the continuous stochastic variable based on the control parametrization method .",
    "suppose that the uncertain parameter @xmath5 is disturbed in an interval @xmath141 $ ] .",
    "let @xmath142\\rightarrow[0,\\infty)$ ] be an element of @xmath12 , i.e. , @xmath143 is a potential probability density function of @xmath5 satisfying ( [ sup - p2 ] ) and ( [ sup - p3 ] ) .",
    "let @xmath144 be a set of time points on the interval @xmath141 $ ] .",
    "denote @xmath145 by @xmath146 , @xmath147 , and @xmath148 $ ] by @xmath149 .",
    "let @xmath150 , and let @xmath151 let @xmath152 be an arbitrarily but fixed element chosen from @xmath145 .",
    "it is referred to as a characteristic element of this subinterval .",
    "when the uncertain parameter takes values in @xmath145 , it is approximated as @xmath152 in the system . as a result",
    ", the uncertain parameter interval @xmath141 $ ] is approximated as a finite set @xmath153 .",
    "moreover , the probability @xmath154 is defined as @xmath155    on the discretization of the continuous distribution , the cost function is approximated as follows : @xmath156 the same idea can be used for the constraints .",
    "thus , we can approximate the inner sub - problem ( cisp ) by the following discrete - distribution problem @xmath157    note that problem ( disp ) is the same as problem ( isp ) detailed in the previous section .",
    "that is , it is a distributionally robust optimal control problem with discrete distribution . if the above discretization method is convergent , the solution of problem ( drocp ) with continuous distribution can be approximately obtained through solving a sequence of problems with discrete distributions .",
    "therefore , we only need to verify the convergence of the above discretization scheme , which will be proved by investigating the relationships of the cost function and constraint functions between problem ( cisp ) and problem ( disp ) .    from ( [ pmf ] ) ,",
    "it is obvious that constraints ( [ sup - p1 ] ) and ( [ sup - q1 ] ) are consistent .",
    "besides , inequality ( [ sup - p4 ] ) in problem ( cisp ) also implies inequality ( [ sup - q4 ] ) in problem ( disp ) .",
    "therefore , we only need to evaluate the differences of the cost functions and the two constraints between problem ( cisp ) and problem ( disp ) .",
    "details are given in the following two theorems .",
    "[ th - x ] given @xmath21 and any @xmath158 , let @xmath159 and @xmath160 be , respectively , the solution of @xmath161\\end{aligned}\\ ] ] and the solution of @xmath162.\\end{aligned}\\ ] ] then , there exists a constant @xmath163 , which is independent of @xmath5 and @xmath152 , such that the inequality @xmath164 holds for all @xmath165 $ ] with @xmath166 defined in ( [ dp ] ) .",
    "given @xmath21 and any @xmath158 , the solution of system ( [ s1 ] ) can be expressed as @xmath167.\\ ] ] it follows that @xmath168 since @xmath169 is at least continuously differentiable with respect to @xmath5 , it also satisfies lipschitz condition in @xmath5 on @xmath141 $ ] , that is , there exists a constant @xmath170 such that @xmath171.\\end{aligned}\\ ] ] therefore , we have @xmath172\\nonumber\\end{aligned}\\ ] ] where @xmath166 is defined in ( [ dp ] ) .",
    "this complete the proof .",
    "[ th - conv ] let @xmath173 be a probability density function satisfying ( [ sup - p2 ] ) and ( [ sup - p3 ] ) and let @xmath9 be the corresponding distribution function .",
    "then , for any control @xmath21 and @xmath174 , there exists @xmath175 such that the following inequalities    * @xmath176 * @xmath177 * @xmath178    hold provided the grid size @xmath179 .",
    "\\(a ) the equality holds directly from the definition .",
    "thus , it remains to prove the validity of the inequality . from ( [ pmf ] )",
    ", we have @xmath180    \\(b ) similar to the derivation given in ( a ) , we obtain @xmath181    \\(c ) similarly , we have @xmath182\\psi(p)dp\\big|\\nonumber\\\\ \\leq & & \\displaystyle\\sum\\limits_{i=1}^m \\ \\int_{p_{i-1}}^{p_i}\\big|h(x(t_f;u , p))-h(x^i(t_f;u , p_d^i))\\big|\\psi(p)dp\\label{c-1}\\end{aligned}\\ ] ] since @xmath183 is continuously differentiable in @xmath139 , there exists , for any @xmath184 , a @xmath185 such that @xmath186 from theorem [ th - x ] , it follows that the following inequality @xmath187 holds if @xmath188 .",
    "substitute ( [ h - ineq ] ) and ( [ x - ineq ] ) into ( [ c-1 ] ) . if @xmath189 then @xmath190 let @xmath191 .",
    "then , we conclude that inequalities ( a ) , ( b ) , ( c ) hold if @xmath192 .",
    "hence , the proof is completed .    in theorem",
    "[ th - conv ] , the relationships of the cost functions and the constraints between problem ( drocp ) and its approximation problem with discrete distributions are given .",
    "note that theorem [ th - conv ] is not related to the issue of local or global optima .",
    "it holds for all controls and all feasible probability density functions , and hence also holds for global and local optima .",
    "in this section , we choose an example to illustrate the application of distributionally robust optimal control model and to test the performance of the proposed algorithm .",
    "the illustration example is a distributionally robust optimal control of a microbial fed - batch process @xcite , which is stated as follows .",
    "let @xmath193 be the concentration of biomass ( g / l ) , @xmath194 be the concentration of substrate ( g / l ) and @xmath195 be the volume of the solution ( l ) .",
    "the control system of the fed - batch process is described by @xmath196 where @xmath66 is the input control of the substrate .",
    "@xmath197 is the specific decay rate of cells , and @xmath198 is the concentration of substrate in feed medium .",
    "@xmath199 is the specific growth rate of biomass , and @xmath200 is the specific consumption rate of substrate , which are , respectively , expressed as @xmath201 in ( [ eq - mu ] ) , @xmath202 is the maximum specific growth rate , @xmath203 is the saturation constant , and @xmath204 is the critical concentration of the substrate above which cells cease to grow . in ( [ eq - mu ] ) , @xmath205 and @xmath206 are , respectively , the maintenance requirement of substrate and the maximum growth yield .",
    "the above system is a typical kinetic model used in microbial fermentation process , see , e.g. , ye et al .",
    "@xcite and zeng et al .",
    "@xcite . in general",
    ", @xmath205 is regarded to be constant during the whole fermentation process . however , it is well - known that the maintenance consumption of substrate would vary during different fermentation stages .",
    "thus , we consider @xmath205 as an uncertain parameter in this work .",
    "assume that the mean and the standard deviation of the uncertain parameter are @xmath207 and @xmath208 , respectively .",
    "the problem is to control the input @xmath66 such that the biomass at the terminal time @xmath117 is maximized . for convenience of presentation ,",
    "let @xmath209^\\top=[x , s , v]^{\\top}$ ] .",
    "define the admissible set of controls as @xmath210 with @xmath211 and @xmath212 being the minimum and maximum input rates .",
    "define @xmath213^{\\top}.\\nonumber\\end{aligned}\\ ] ] by transforming the time interval [ 0,@xmath117 ] into @xmath215 $ ] , the optimal control problem can be stated as follows : @xmath216,\\ x(0)=x^0,\\label{ocp - s1}\\\\   & & \\ \\ \\ \\ \\ \\ \\",
    "m_s\\sim f\\in \\mathcal{f}(m_\\mu , m_\\sigma^2)=\\{f:\\mathbb{e}_{f}(p)=m_\\mu ,   \\mathbb{e}_{f}(m_s - m_\\mu)^2=m_\\sigma^2\\ } , \\label{ocp - pc}\\\\ & & \\ \\ \\ \\ \\ \\ \\ u\\in\\mathcal{u}.   \\label{ocp2}\\end{aligned}\\ ] ]    in this numerical example , we set @xmath217^\\top$ ] , @xmath218 , @xmath219 , @xmath220 $ ] , @xmath221 , @xmath222 , @xmath223 , @xmath224 , @xmath225 , @xmath226 , @xmath227 , @xmath228h .    in algorithm 3.1 , even if problem ( dual - drocp ) is linear with respect to @xmath38 , we still optimize @xmath38 together with @xmath28 by using the nonlinear optimization techniques . in the numerical experiments ,",
    "the time horizon is equidistantly divided into 25 subintervals for the parameterization of the control @xmath28 .",
    "since the microbial fermentation is a relatively slow time - varying process , the partition is adequate . in the discretization of the continuous distribution of the uncertain parameter @xmath205",
    ", we choose ten characteristic elements @xmath229 over @xmath230 $ ] , where @xmath231 , @xmath232 .",
    "a good initial guess of the decision variables is important to help ensure the convergence of the algorithm .",
    "we use the following procedure to generate an initial guess : randomly generate a control @xmath28 , and for the fixed @xmath28 , the variable @xmath38 is optimized by a linear programming solver and the performance of ( qp - dual - drocp ) is computed ; the process is repeated @xmath233(=200 ) times and the pair @xmath234 with the best performance is set to be an initial guess for a run of algorithm 3.1 .",
    "it is worth mentioning that the generated initial guess , if exists , is a feasible solution of problem ( dual - drocp ) .",
    "starting from the initial guess , the proposed algorithm , which is encoded in matlab 7.0 , is implemented on an intel dual - core i5 with 2450ghz .",
    "the height of the optimal control @xmath212 at each subinterval is listed in table 1 . under the optimal input strategy and @xmath235 ,",
    "the trajectories of the biomass and the substrate are plotted in figs . 1 and 2 .",
    "after obtaining the optimal solution @xmath236 from algorithm 3.1 , we fix the control @xmath28 at @xmath212 and optimize @xmath38 again by solving problem ( dual - isp ) with linear programming solver .",
    "the optimal solution is denoted by @xmath237 .",
    "the values of the cost function at @xmath236 and @xmath238 are denoted as @xmath239 and @xmath240 , respectively .",
    "we have @xmath241 and @xmath242 .",
    "the difference between @xmath243 and @xmath240 is only 0.0985 , which reflects the effectiveness of the proposed algorithm in some degree . on the other hand",
    ", we fix the control @xmath28 at @xmath212 and optimize @xmath244 directly by solving problem ( isp ) with linear programming solver . the optimal solution of @xmath244",
    "is @xmath245^\\top$ ] .",
    "the terminal concentrations of biomass under the characteristic elements @xmath229 are @xmath246 @xmath247.$ ]    .the optimal input strategy control . [ cols=\"^,^,^,^,^,^,^,^,^,^,^,^\",options=\"header \" , ]      and @xmath205 varied from 0.8@xmath207 to 1.2@xmath207.,scaledwidth=110.0% ]     and @xmath205 varied from 0.8@xmath207 to 1.2@xmath207.,scaledwidth=110.0% ]    to illustrate the superiority of the optimal control strategy obtained from the proposed model , we simulate the system under a constant input @xmath248 .",
    "the trajectories of biomass and substrate with varied @xmath205 under this input strategy are shown in figs . 3 and 4 .",
    "a comparison of fig . 1 and fig .",
    "3 reveals that , not only the the terminal concentration of biomass under the optimal strategy is significantly higher than that under the constant control input , but also the variation of biomass concentration is much smaller than the constant one .",
    "this shows that the system under the optimal control strategy could maintain a good performance even in the `` worst '' case .     and",
    "@xmath205 varied from 0.8@xmath207 to 1.2@xmath207.,scaledwidth=110.0% ]     and @xmath205 varied from 0.8@xmath207 to 1.2@xmath207.,scaledwidth=110.0% ]",
    "this paper introduced an optimal control problem in which both the objective function and the dynamic constraint contain an uncertain parameter .",
    "since the distribution of this uncertain parameter is not exactly known , the objective function is taken as the worst - case expectation over a set of possible distributions of the uncertain parameter . to minimize the worst - case expectation over all possible distributions in an ambiguity set ,",
    "the stochastic optimal control problem is converted into a finite - dimensional optimization problem via duality and discretization .",
    "necessary conditions of optimality was derived and numerical results for an illustration example are reported .",
    "numerical results in section 5 show the success of the proposed model in producing an optimal control strategy under which a good performance is achieved .",
    "it also ensures that the variation of the performance is small subject to the changes in the value of the uncertain parameter .",
    "that is , the system is robust under the optimal control strategy obtained from the proposed model .",
    "the continuation of this work can be divided into two aspects : model aspect and algorithm aspect .",
    "the model should take more factors into account .",
    "for example , a further study could be on how to introduce proper terminal constraints or path constraints into the model . in the algorithm aspect",
    ", the current work transforms the proposed model into a combined optimal control and optimal parameter selection problem and solve it by using nonlinear optimization techniques .",
    "however , the special structure of the problem was not taken into detailed investigation .",
    "problem ( dual - drocp ) is linear with respect to the optimization vector @xmath38 but nonlinear with respect the control @xmath28 . an alternative direction optimization technique could be used to handle these two kinds of optimization variables separately .",
    "for example , the control @xmath28 can be fixed first , and the optimal solution @xmath249 is easily obtained by solving a linear programming problem .",
    "then , the control @xmath28 is regulated by some nonlinear optimization methods .",
    "the procedure is repeated until a satisfactory pair of @xmath234 is found .",
    "some stochastic techniques , such as pso method , could also be combined with the alternative direction optimization technique to regulate the control @xmath28 in the outer level of the optimization process .",
    "this work was supported by the national natural science foundation for the youth of china ( grants 11301081 , 11401073 ) , china postdoctoral science foundation ( grant no .",
    "2014m552027 ) , the fundamental research funds for central universities in china ( grant dut15lk25 ) , and provincial national science foundation of fujian ( grant no .",
    "2014j05001 ) .                                  a.e .",
    "bryson , applied optimal control : optimization , estimation and control .",
    "crc press , 1975 .",
    "k. l. teo , c. j. goh .",
    "a computational method for combined optimal parameter selection and optimal control problems with general constraints .",
    "j. austral .",
    "b. 1989(30 ) : 350 - 364 .",
    "loxton , k.l .",
    "teo , v. rehbock , et al , optimal control problems with a continuous inequality constraint on the state and the control .",
    "automatica , 2009 , 45(10 ) : 2250 - 2257 .",
    "jorge nocedal and stephen j. wright . numerical optimization .",
    "springer , 2006 ."
  ],
  "abstract_text": [
    "<S> we study an optimal control problem in which both the objective function and the dynamic constraint contain an uncertain parameter . </S>",
    "<S> since the distribution of this uncertain parameter is not exactly known , the objective function is taken as the worst - case expectation over a set of possible distributions of the uncertain parameter . </S>",
    "<S> this ambiguity set of distributions is , in turn , defined by the first two moments of the random variables involved . </S>",
    "<S> the optimal control is found by minimizing the worst - case expectation over all possible distributions in this set . </S>",
    "<S> if the distributions are discrete , the stochastic min - max optimal control problem can be converted into a convensional optimal control problem via duality , which is then approximated as a finite - dimensional optimization problem via the control parametrization . </S>",
    "<S> we derive necessary conditions of optimality and propose an algorithm to solve the approximation optimization problem . </S>",
    "<S> the results of discrete probability distribution are then extended to the case with one dimensional continuous stochastic variable by applying the control parametrization methodology on the continuous stochastic variable , and the convergence results are derived . </S>",
    "<S> a numerical example is present to illustrate the potential application of the proposed model and the effectiveness of the algorithm .    * </S>",
    "<S> ams subject classification *  34h05 @xmath0 49m25 @xmath0 49m37 @xmath0 93c41 </S>"
  ]
}