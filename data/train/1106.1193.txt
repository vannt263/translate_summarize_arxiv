{
  "article_text": [
    "in this paper we consider the following statistical problem : upon observing a  high - dimensional vector , one is interested in detecting the presence of a  sparse , possibly structured , correlated subset of components of the vector .",
    "such problems emerge naturally in numerous scenarios . the setting is closely related to gaussian signal detection in gaussian white noise , on which there is an extensive literature surveyed in @xcite . in image processing ,",
    "textures are modeled via markov random fields  @xcite , so that detecting a  textured object hidden in gaussian white noise amounts to finding an area in the image where the pixel values are correlated .",
    "similar situations arise in remote sensing based on a  variety of hardware .",
    "a  related task is the detection of space  time correlations in multivariate time series , with potential applications to finance  @xcite .",
    "we investigate the possibilities and limitations in problems of detecting correlations in a  gaussian framework .",
    "we may formulate this as a  general hypothesis testing problem as follows .",
    "an @xmath0-dimensional gaussian vector @xmath1 is observed . under the null hypothesis @xmath2 ,",
    "the vector @xmath3 is standard normal , that is , with zero mean vector and identity covariance matrix . to describe the alternative hypothesis  @xmath4 ,",
    "let @xmath5 be a  class of subsets of @xmath6 , each of size @xmath7 , indexing the possible `` contaminated '' components .",
    "one wishes to test whether there exists an @xmath8 such that @xmath9 where @xmath10 is a  given parameter .",
    "equivalently , if @xmath11 denotes the vector of observations , then @xmath12 where @xmath13 denotes the @xmath14 identity matrix and @xmath15 we write @xmath16 for the probability under @xmath2 ( i.e. , the standard normal measure in @xmath17 ) and , for each @xmath18 , @xmath19 for the measure of @xmath20 .",
    "the goal of this paper is to understand for what values of the parameters @xmath21 reliable testing is possible .",
    "this , of course , depends crucially on the size and structure of the subset class @xmath5 .",
    "we consider the following two prototypical classes :    * _ @xmath7-intervals .",
    "_ in this example , we consider the class of all intervals of size @xmath7 of the form @xmath22 modulo @xmath0for aesthetic reasons .",
    "( we call such an interval a  _ @xmath7-interval_. ) this class is the flagship of _ parametric _ classes , typical of the class of objects of interest in signal processing . * _ @xmath7-sets . _ in this example , we consider the class of all sets of size @xmath7 , that is , of the form @xmath23 where the indices are all distinct in @xmath6 .",
    "( we call such a  set a  _ @xmath7-set_. ) this class is the flagship of _ nonparametric _ classes , and may arise in multiple comparison situations .",
    "our theory , however , applies more generally to other classes , such as :    * _ @xmath7-hypercubes .",
    "_ in this example , the variables are indexed by the @xmath24-dimensional lattice , that is , @xmath25 , so that the sample size is @xmath26 , and we consider the class of all hyper - rectangles of the form @xmath27each interval modulo @xmath28of fixed size @xmath29 .",
    "this class is the simplest model for objects to be detected in images ( mostly @xmath30 in applications ) . *",
    "_ perfect matchings .",
    "_ suppose @xmath0 is a  perfect square with @xmath31 .",
    "the components of the observed vector @xmath3 correspond to edges of the complete bipartite graph on @xmath32 vertices and each set in @xmath5 corresponds to the edges of a  perfect matching .",
    "thus , @xmath33 . in this example @xmath5 has a  nontrivial combinatorial structure . *",
    "_ spanning trees .",
    "_ in another example , @xmath34 and the components of @xmath3 correspond to the edges of a  complete graph @xmath35 on @xmath36 vertices and every element of @xmath5 is a  spanning tree of @xmath35 .    as usual , a  _ test _ is a  binary - valued function @xmath37 . if @xmath38 , then the test accepts the null hypothesis @xmath2 ; otherwise @xmath2 is rejected by @xmath39 .",
    "we measure the performance of a  test based on its _ worst - case risk _ over the class of interest @xmath5 , formally defined by @xmath40 we will derive upper and lower bounds on the _ minimax risk _ @xmath41 a  standard way of obtaining lower bounds for the minimax risk is by putting a  prior on the class @xmath5 and obtaining a  lower bound on the corresponding _ bayesian risk _ , which never exceeds the worst - case risk .",
    "because this is true for any prior , the idea is to find one that is hardest ( often called _ least favorable _ ) .",
    "most classes we consider here are invariant under some group action : @xmath7-intervals are invariant under translation and @xmath7-sets are invariant under permutation .",
    "invariance considerations ( @xcite , section 8.4 ) lead us to considering the uniform prior on @xmath5 , giving rise to the following _ average risk _ : @xmath42 where @xmath43 and @xmath44 is the cardinality of @xmath5 .",
    "the advantage of considering the average risk over the worst - case risk is that we know an optimal test for the former , which , by the neyman ",
    "pearson fundamental lemma , is the likelihood ratio test , denoted @xmath45 . introducing @xmath46 for all @xmath8 , the likelihood ratio between @xmath2 and @xmath4",
    "may be written as @xmath47 and the optimal test becomes @xmath48 note that @xmath49 .",
    "the ( average ) risk @xmath50 of the optimal test is called the _ bayes risk _ and it satisfies @xmath51 note that , with the only exception of the case of spanning trees , in all examples mentioned above , the minimax and bayes risks coincide , that is , @xmath52 .",
    "this is again due to invariance ( @xcite , section 8.4 ) .",
    "( the class of spanning trees is not sufficiently symmetric for this equality to hold .",
    "however , as we will see below , even in this case , @xmath53 and @xmath54 are of the same order of magnitude . )",
    "we focus on the case when @xmath0 is large and formulate some of the results in an asymptotic language with @xmath55 though in all cases explicit nonasymptotic inequalities are available . of course",
    ", such asymptotic statements only make sense if we define a  sequence of integers @xmath56 and classes @xmath57 .",
    "this dependency in @xmath0 will be left implicit . in this asymptotic setting , we say that _ reliable _ detection is possible ( resp . , impossible ) if @xmath58 ( resp . ,",
    "@xmath59 ) as @xmath60 .    in this paper",
    "we assume that , under the alternative hypothesis , the correlation between any two variables in the `` contaminated '' set is the same .",
    "while this model has a  natural interpretation ( see lemma  [ lemrepresent ] below ) , it is clearly a  restrictive assumption .",
    "this simplification is in understanding the fundamental limits of detection ( i.e. , in obtaining lower bounds on the risk ) . at the same time",
    ", the tests we exhibit also match these lower bounds under more general correlation structures , such as @xmath61 that said , dealing with more general correlation structures remains an interesting and important challenge , relevant in the detection of textured objects in textured background , for example .",
    "the vast majority of the literature on detection is concerned with the detection of a  signal in additive ( often gaussian ) noise , which would correspond here to an alternative where @xmath62 for @xmath63 , where @xmath64 is the ( per - coordinate ) signal amplitude .",
    "we call this the _ detection - of - means _ setting .",
    "the literature on this problem is quite comprehensive .",
    "indeed , the detection of @xmath7-intervals and @xmath7-hypercubes is treated extensively in a  number of papers ; see , for example ,  @xcite . a  more general framework that includes",
    "the detection of perfect matchings and spanning trees is investigated in  @xcite , and the detection of @xmath7-sets is studied in  @xcite . in the literature on detection of parametric objects , the phrase `` correlation detection '' usually refers to the method of _ matched filters _ , which consists of correlating the observed signal with signals of interest .",
    "this is not the problem we are interested in here . while the problem of _ detection - of - correlations _ considered here is mathematically more challenging than the detection - of - means setting ,",
    "there is a  close relationship between the two . the connection is established by the representation theorem of  @xcite  stated here for the case gaussian random variables .    [ lemrepresent ]",
    "let @xmath65 be standard normal with @xmath66 for @xmath67 .",
    "then there are i.i.d .",
    "standard normal random variables , denoted @xmath68 , such that @xmath69 for all @xmath70 .",
    "thus , given @xmath71 , the problem becomes that of detecting a  subset of variables with nonzero mean ( equal to @xmath72 ) and with a  variance equal to @xmath73 ( instead of 1 ) .",
    "this simple observation will be very useful to us later on .",
    "when @xmath71 is random , the setting is similar to that of detecting a  gaussian process ( here equal to @xmath72 for @xmath74 , and equal to 0 otherwise ) in additive gaussian noise .",
    "however , the typical setting assumes that the gaussian process affects all parts of the signal  @xcite . in our setting",
    ", the signal ( the subset of correlated variables ) will be sparse .",
    "since we only have one instance of the signal @xmath3 , the problem can not be considered from the perspective of either multivariate statistics or multivariate time series .",
    "if indeed we had multiple copies of @xmath3 , we could draw inspiration from the literature on the estimation of sparse correlation matrices  @xcite , from the literature on multivariate time series  @xcite , or on other approaches  @xcite ; but this is not the case as we only observe @xmath3 .",
    "closer in spirit to our goal of detecting correlations in a  single vector of observation is the paper of  @xcite , which aims at testing whether a  gaussian random field is i.i.d . or has some markov dependency structure .",
    "their setting models communication networks and is not directly related to ours .",
    "it transpires , therefore , that @xmath75 in the detection - of - correlations setting plays a  role analogous to @xmath76 in the detection - of - means setting .",
    "while this is true to a  certain extent , the picture is quite a  bit more subtle .",
    "the detection - of - means problem for parametric classes such as @xmath7-intervals is well understood . in such cases , @xmath76  needs to be of order at least @xmath77 for reliable detection of @xmath7-intervals to be possible .",
    "this remains true in the detection - of - correlations setting , and the _ generalized likelihood ratio test _ ( _ glrt _ ) is near - optimal , just as in the detection - of - means problem ; see , for example ,  @xcite .",
    "our inspiration for considering @xmath7-sets comes from the line of research on the detection of sparse gaussian mixtures .",
    "very precise results are known on @xmath78 that make detection possible  @xcite and optimal tests have been developed , such as the `` higher criticism ''  @xcite .",
    "in fact , the recent paper  @xcite deals with heteroscedastic instances of the detection - of - means problem where the variance of the anomalous variables may be different from 1 .",
    "for example , it is known that , when @xmath79 [ resp . ,",
    "@xmath80 , @xmath76 needs to be of order at least @xmath81 [ resp .",
    ", @xmath82 for reliable detection of @xmath7-sets to be possible , and the test based on @xmath83 ( resp . , @xmath84 ) is near - optimal .",
    "though more precise results are available when @xmath85 , these can not be translated immediately to our case via the representation theorem of lemma  [ lemrepresent ] . as a  bonus ,",
    "we show that the glrt is clearly suboptimal in some regimes  see theorem  [ thmglrt - bad ] .",
    "note that in the detection - of - means problem it is not known whether the glrt has any power .",
    "this paper contains a  collection of positive and negative results about the detection - of - correlation problem described above . in section  [ seclower ]",
    "we derive lower bounds for the bayes risk .",
    "the usual route of bounding the variance of the likelihood ratio , that is very successful in the detection - of - means problem , leads essentially nowhere in our case .",
    "instead , we develop a  new approach based on lemma  [ lemrepresent ] .",
    "we establish a  general lower bound for the bayes risk in terms of the moment generating function of the size of the overlap of two randomly chosen elements of the class @xmath5 .",
    "this quantity also plays a  crucial role in the detection - of - means setting and we are able to use inequalities worked out in the literature in various examples . in section  [ secupper ]",
    "we study the performance of some simple and natural tests such as the squared - sum test  based on @xmath86 , the generalized likelihood ratio test ( glrt ) and a  goodness - of - fit ( gof ) test , as well as some variants .",
    "we show that , in the case of parametric classes such as @xmath7-intervals and @xmath7-hypercubes , the glrt is essentially optimal .",
    "the squared - sum test is shown to be essentially optimal in the case of @xmath7-sets when @xmath87 is large , while the glrt is clearly suboptimal in this regime .",
    "this is an interesting example where the glrt fails miserably .",
    "when @xmath87 is small , detection is only possible when @xmath75 is very close to @xmath88 .",
    "we show that a  simple gof test is near - optimal in this case .",
    "the analysis of tests such as the squared - sum test and the glrt involves handling quadratic forms in @xmath3 .",
    "this is technically more challenging than the analogous problem for the detection - of - means setting in which only linear functions of @xmath3 appear ( which are normal random variables ) .",
    "in this section we investigate lower bounds on the risk , which are sometimes called information bounds .",
    "first we consider the special case when @xmath5 contains only one element as this example will serve as a  benchmark for other examples .",
    "then we consider the standard method based on bounding the variance of the likelihood ratio under the null hypothesis , and show that it leads nowhere .",
    "we then develop a  new bound based on lemma  [ lemrepresent ] that has powerful implications , leading to fairly sharp bounds in a  number of examples .      as a  warm - up , and to gain insight into the problem ,",
    "consider first the simplest case where @xmath5 contains just one set , say @xmath90 . in this case , the alternative hypothesis is simple and the likelihood ratio ( neyman  pearson ) test may be expressed by @xmath91 this follows by the fact that @xmath92 which is easy to check by straightforward calculation .",
    "the next simple lemma helps understand the behavior of the bayes risk .",
    "[ lemqf ] under @xmath16 , @xmath93 is distributed as @xmath94 and under the alternative @xmath19 , it has the same distribution as @xmath95 where @xmath96 and @xmath97 denote independent @xmath98 random variables with degrees of freedom @xmath88 and @xmath99 , respectively .",
    "if @xmath100 denotes a  standard normal vector , then under @xmath2 , the quadratic form @xmath93 is distributed as @xmath101 , and under the alternative , it has the distribution of @xmath102 , since @xmath3 is distributed as @xmath103 .",
    "now , observe that for any symmetric matrix @xmath104 with eigenvalues @xmath105 , the quadratic form @xmath106 has distribution @xmath107 this follows simply by diagonalizing @xmath104 and using the rotational invariance of the standard normal distribution .",
    "the lemma follows from this simple representation and the fact that @xmath108 has eigenvalue @xmath73 with multiplicity @xmath99 , @xmath109 with multiplicity  @xmath88 , and the eigenvalue @xmath88 with multiplicity @xmath110 .",
    "now it is straightforward to analyze the bayes risk . in particular",
    ", we immediately have the following :    [ prpsimple ] if @xmath5 is a  singleton , @xmath111 if and only if @xmath112 .",
    "similarly , @xmath113 if and only if @xmath114 .",
    "suppose @xmath112 .",
    "it suffices to show that there exists a  threshold @xmath115 such that @xmath116 and @xmath117 .",
    "we use lemma  [ lemqf ] and the fact that , by chebyshev s inequality , @xmath118 for any sequence @xmath119 , and the fact that @xmath120 we choose @xmath121 and define @xmath122 . then under the null , @xmath123 and under the alternative , setting @xmath124 , @xmath125 we then conclude with the fact that , for @xmath7 large enough , @xmath126 .    if @xmath127 is bounded , the densities of the test statistic under both hypotheses have a  significant overlap and the risk can not converge to @xmath128 .",
    "the proof of the second statement is similar .",
    "clearly , the role of @xmath0 is immaterial in this specific example as the optimal test ignores all components whose indices are not in @xmath129 .      when the class @xmath5 contains more than one element , the likelihood ratio with uniform prior on @xmath5 is given by  ( [ l ] ) . a  common approach for deriving a  lower bound on the bayes risk is via an upper bound on the _ variance _ of @xmath130 under the null",
    "indeed , by the cauchy ",
    "schwarz inequality , @xmath131 - 1}}{2}.\\ ] ] therefore , an upper bound on @xmath132 -1 = { \\operatorname{var}}_0(l(x))$ ] leads to a  lower bound on @xmath53 .",
    "let @xmath133 , which is independent of @xmath8 . by fubini s theorem",
    ", we have @xmath134 where @xmath135 is defined in  ( [ z ] ) .",
    "we focus on terms of the double sum for which @xmath136 .",
    "the following result is a  straightforward consequence of the representation  ( [ sum - chi ] ) and the well - known expression for the moment generating function of  @xmath96 .",
    "[ lemchi - eig ] suppose @xmath3 is a  standard normal vector in @xmath137 and @xmath138 is an @xmath14 symmetric matrix with eigenvalues strictly less than @xmath139",
    ". then @xmath140 if @xmath138 has an eigenvalue exceeding @xmath139 , then @xmath141 .    since @xmath142 has eigenvalue @xmath143 with multiplicity @xmath7 , eigenvalue @xmath144 with multiplicity @xmath88 , and eigenvalue 0 with multiplicity @xmath145 , @xmath146 = { { \\mathbb{e}}}_0 \\exp(x^t { \\mathbf{m}}x ) = + \\infty$ ] unless @xmath147 .",
    "the implications are rather insubstantial .",
    "it only shows that , when @xmath148 with @xmath149 fixed , the bayes risk does not tend to zero .",
    "as we shall see , this lower bound is grossly suboptimal , except in the case where @xmath5 is a  singleton ( as in section  [ secsimple ] ) or does not grow in size with @xmath0 .",
    "a  refinement of this method consists in bounding the first and second _ truncated _ moments of @xmath130 , again under the null hypothesis .",
    "for example , this is the approach used in  @xcite in the detection - of - means setting for the case of @xmath7-sets to obtain sharp bounds .",
    "unfortunately , in our case this method only provides a  useful bound when the class @xmath5 is not too large ( i.e. , has size polynomial in @xmath7 ) while it does not seem to lead anywhere in the case of @xmath7-sets .",
    "the computations are quite involved and we do not provide details here , as we were able to obtain a  more powerful general bound that applies to both @xmath7-intervals and @xmath7-sets .",
    "this is presented in the next section .      in this section",
    "we derive a  general lower bound for the bayes risk . as in the detection - of -",
    "means problem  @xcite , the relevant measure of complexity is in terms of the moment generating function of the size of the overlap of two randomly chosen elements of @xmath5 . in the detection - of - means setting ,",
    "this is a  consequence of bounding the variance of the likelihood ratio .",
    "we saw in section  [ secmoment ] that this method is useless here .",
    "instead , we make a  connection between the two problems using lemma  [ lemrepresent ] .",
    "[ thmlower ] for any class @xmath5 and any @xmath150 , @xmath151 where @xmath152 and @xmath153 , with @xmath154 drawn independently , uniformly at random from @xmath5 . in particular , taking @xmath155 , @xmath156 where @xmath157 .",
    "the starting point of the proof is lemma  [ lemrepresent ] , is as described in distribution . ] which enables us to represent the vector @xmath3 as @xmath158 where @xmath159 are independent standard normal random variables .",
    "we consider now the alternative @xmath160 , defined as the alternative @xmath4 given .",
    "let @xmath161 , @xmath162 , @xmath45 [ resp .",
    ", @xmath163 , @xmath164 , @xmath165 be the risk of a  test @xmath39 , the likelihood ratio , and the optimal ( likelihood ratio ) test , for @xmath2 versus @xmath4 [ resp .",
    ", @xmath2  versus @xmath160 ] .",
    "for any @xmath167 , @xmath168 , by the optimality of @xmath169 for @xmath2 versus @xmath160",
    ". therefore , conditioning on @xmath71 , @xmath170 [ @xmath171 is the expectation with respect to @xmath172 . ]",
    "using the fact that @xmath173 for all @xmath174 , we have @xmath175 } { { \\mathbb{e}}}_0    @xmath176 } { { \\mathbb{e}}}_0    \\\\ & \\geq & { { \\mathbb{p}}}\\{|u|\\le a\\}\\biggl(1 - \\frac12 \\max_{u \\in[-a , a ] } \\sqrt{{{\\mathbb{e}}}_0",
    "l_u^2(x ) - 1}\\biggr).\\end{aligned}\\ ] ] since @xmath177 we get @xmath178 it is easy to check that @xmath179 which implies @xmath180 which concludes the proof .",
    "we now apply theorem  [ thmlower ] to a  few examples .",
    "the theorem converts the problem into a  purely combinatorial question and  @xcite offers various estimates for the moment generating function of @xmath181 which we may use for our purposes .",
    "consider first the simplest case when @xmath5 contains @xmath182 disjoint sets of size @xmath7 .",
    "[ cordisjoint ] let @xmath5 be the class of all sets of size @xmath7 . if @xmath183 then the bayes risk satisfies @xmath184 , and @xmath185 if @xmath186 or if @xmath187 .",
    "clearly , the size @xmath181 of the overlap of two randomly chosen elements of @xmath5 equals zero with probability @xmath188 and @xmath7 with probability @xmath189 .",
    "thus , @xmath190 which is bounded by @xmath88 if @xmath191 .",
    "the first part then follows from the second part of theorem  [ thmlower ] . for the second part ,",
    "we need to find @xmath192 such that @xmath193 .",
    "( note that in this case the upper bound above tends to zero . )",
    "first assume that @xmath194 . in that case , @xmath195 , so it suffices to take @xmath192 slowly enough that @xmath196 .",
    "next assume that @xmath197 . in this case , we have @xmath198 , and we simply choose @xmath192 slowly enough that @xmath199 .",
    "consider the class of all @xmath7-intervals .",
    "the situation is similar to that of nonoverlapping sets .",
    "( in fact , since this class of @xmath7-intervals contains @xmath200 $ ] nonoverlapping sets of size @xmath7 , we could immediately deduce a  lower bound via corollary  [ cordisjoint ] . )",
    "[ corkint ]",
    "let @xmath5 be the class of all @xmath7-intervals . if @xmath201 then the bayes risk satisfies @xmath184 , and @xmath185 if @xmath202 or if @xmath203 .    for two @xmath7-intervals chosen independently and uniformly at random , @xmath204 thus , @xmath205 and proceed as in the proof of corollary  [ cordisjoint ] , using the fact that @xmath206 .",
    "consider the class of all sets of size @xmath7 .",
    "[ corksets ] let @xmath5 be the class of @xmath7-sets .",
    "if @xmath207 then the bayes risk satisfies @xmath184 , and @xmath185 if either @xmath208 and @xmath209 , or @xmath210 .    by  @xcite ,",
    "proposition 3.4 , which uses negative association , @xmath211 where the last expression is bounded by @xmath212 under the postulated condition , and tends to 1 if either @xmath208 and @xmath213 , or @xmath214 and @xmath215 .",
    "first assume that @xmath208 and @xmath209 . by choosing @xmath192 slowly enough that @xmath216 we ensure that @xmath217 .",
    "next assume that @xmath218 .",
    "since @xmath219 , it suffices to take @xmath192 slowly enough that @xmath199 to ensure that @xmath220 .",
    "the result then follows from theorem [ thmlower ] .",
    "consider now the example of perfect matchings described in the . here",
    "once again , theorem  [ thmlower ] applies and implies that testing is impossible for moderate values of @xmath75 .",
    "[ cormatch ] let @xmath5 be the class of all perfect matchings .",
    "if @xmath222 , the bayes risk satisfies @xmath184 .",
    "also , @xmath185 if @xmath223 .",
    "the random variable @xmath181 for this class is considered by @xcite , who prove that @xmath224 this is bounded by @xmath212 whenever @xmath225 , which is satisfied whenever @xmath222 , and tends to 1 if @xmath226 .",
    "we then apply theorem  [ thmlower ] .",
    "a  similar argument applies for the class of all spanning trees of a  complete graph with @xmath36 vertices [ and @xmath227 edges ] as described in the .",
    "[ corsp ] let @xmath5 be the class of all spanning trees .",
    "if @xmath228 , then the bayes risk satisfies @xmath229 .",
    "we also have @xmath185 if @xmath223 .",
    "it is shown in  @xcite that @xmath230 which is bounded by @xmath231 whenever @xmath232 , which is satisfied whenever @xmath233 , and tends to 1 if @xmath226 .",
    "we then apply theorem  [ thmlower ] .",
    "we already know that the likelihood ratio test is optimal in the bayesian setting .",
    "we study here other tests for multiple reasons .",
    "first , the likelihood ratio test seems difficult to compute in most situations .",
    "second , the likelihood ratio test is heavily dependent on the prior we choose  here , the uniform distribution on the class .",
    "the third , and perhaps most important , reason is that it is difficult to obtain directly upper bounds for the ( worst - case ) risk of the likelihood ratio test whereas the tests considered below are easier to analyze and often yield near - optimal performance . whenever we obtain an upper bound for the risk of a  test that matches the lower bounds developed in the previous section",
    ", we have a  full understanding of the limitations and possibilities of detection for the particular case considered , and this is our main goal in this paper .",
    "we consider the squared - sum test , which corresponds to the anova test in the detection - of - means setting , the generalized likelihood ratio test ( glrt ) and a  goodness - of - fit ( gof ) test , as well as some variants .",
    "we say that a  test is _ near - optimal _ for a  certain setting if it achieves the information bound for that setting to first order .",
    "one of the simplest tests is based on the observation that the magnitude of the squared - sum @xmath234 may be substantially different under the null and alternative hypotheses due to the higher correlation under the latter .",
    "indeed , under @xmath16 , @xmath234 is distributed as @xmath235 , while for any @xmath236 with @xmath237 , under @xmath19 , @xmath234 has the same distribution as @xmath238 ; in fact , under the more general correlation model  ( [ model - general ] ) , this is a  ( stochastic ) lower bound .",
    "this immediately leads to the following result .",
    "[ prpsq ] let @xmath5 be an arbitrary class of sets of size @xmath7 and suppose that @xmath239 in  ( [ model - general ] ) . if @xmath240 is such that @xmath241 but @xmath242 , then the test which rejects the null hypothesis if @xmath243 has a  worst - case risk converging to zero .",
    "however , any test based on @xmath234 is powerless if @xmath209 in  ( [ model ] ) .    in corollary  [ corksets ] , we saw that reliable detection of @xmath7-sets is impossible if @xmath208 and @xmath209 .",
    "here we see that , when @xmath239 , the squared - sum test is asymptotically powerful .",
    "hence , the following statement :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ the squared - sum test is near - optimal for detecting @xmath7-sets in the regime where @xmath208 .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    on the other hand , in the regime @xmath214 , the squared - sum test is powerless even if @xmath244 .",
    "the test does not require knowledge of @xmath75 , though knowing @xmath75 allows one to choose the threshold @xmath240 in an optimal fashion ; if @xmath75 is unknown , we simply choose @xmath245 very slowly .      in this section",
    "we investigate the performance of the generalized likelihood ratio test ( glrt ) .",
    "we show that for parametric classes such as @xmath7-intervals , the test is near - optimal .",
    "however , for the nonparametric class of @xmath7-sets , the test performs poorly in some regimes .    by definition",
    ", the glrt rejects for large values of @xmath246 , or simply @xmath247 when all the sets in the class @xmath5 are of same size , since  @xmath248 only depends on the size of @xmath249 .",
    "hence , the glrt is of the form @xmath250 for some appropriately chosen @xmath251 .",
    "we immediately notice that the glrt requires knowledge of @xmath75    our analysis of the glrt is based on lemma  [ lemqf ] , which provides the distribution of the quadratic form @xmath93 under the null @xmath16 and under the alternative @xmath19 . under the null we need to control the maximum of such quadratic forms over @xmath8 , which we do using exponential concentration inequalities for chi - squared distributions .      recalling corollary  [ corkint ] , when detecting @xmath7-intervals all tests are asymptotically powerless when @xmath252 . we assume for concreteness that @xmath253 , for otherwise detecting @xmath7-intervals for very small @xmath7 has more to do with detecting @xmath7-sets .",
    "we state a  general result that applies for classes of small cardinality .",
    "[ prpglrt - small ] consider a  class @xmath5 of sets of size @xmath7 , with cardinality @xmath254 such that @xmath255 .",
    "when @xmath256 , the generalized likelihood ratio test with threshold value @xmath257 has worst - case risk tending to zero .",
    "we first bound the probability of type i error .",
    "indeed , under the null , by lemma  [ lemqf ] and its proof , we can decompose @xmath258 where @xmath259 and @xmath260 .",
    "hence , @xmath261 it is well known that the maximum of @xmath182 standard normals is bounded by @xmath262 with probability tending to 1 as @xmath263 .",
    "hence , the second term on the right - hand side is bounded by @xmath264 with high probability .",
    "for the first term , we combine the union bound and chernoff s bound to obtain , for all @xmath265 , @xmath266\\\\[-8pt ] & \\leq & n \\exp\\biggl(-\\frac{(k-1)}2 ( a~- 1 - \\log a)\\biggr ) .",
    "\\nonumber\\end{aligned}\\ ] ] using the fact that @xmath267 when @xmath268 , the right - hand side tends to zero when @xmath269 .",
    "we arrive at the conclusion that the glrt with threshold @xmath270 has probability of type i error tending to zero .",
    "now consider the alternative under @xmath271 . by lemma  [ lemqf ] and chebyshev s inequality , @xmath272 with high probability when @xmath273 .",
    "we then conclude by the fact that the right - hand side is larger than @xmath251 when @xmath273 sufficiently slowly .    comparing the performance of the glrt in proposition  [ prpglrt - small ] with the lower bound for @xmath7-intervals in corollary  [ corkint ] , we see that the glrt is near - optimal for detecting @xmath7-intervals .",
    "this is actually the case for all parametric classes we know of .",
    "consider now the example of the class of all @xmath7-sets .",
    "compared to the previous section , the situation here is different in that @xmath182 , the size of the class @xmath5 , is much larger .",
    "for example , for @xmath7-sets , @xmath274 , and therefore @xmath275 with @xmath60 .",
    "the equivalent of proposition  [ prpglrt - small ] for this regime is the following :    [ prpglrt - large ] consider a  class @xmath5 of sets of size @xmath7 , with cardinality @xmath263 such that @xmath276 . when @xmath277 , the generalized likelihood ratio test with threshold value @xmath278 has worst - case risk tending to zero .",
    "we follow the proof of proposition  [ prpglrt - small ] .",
    "the only difference is in  ( [ glrt - small - eq1 ] ) , where we now need @xmath279 and that right - hand side tends to zero when @xmath280 .",
    "choose @xmath281 , obtaining that , with high probability , @xmath282 as before , with high probability under @xmath271 , @xmath283 so we only need to check that the threshold @xmath251 is larger than the right - hand side in  ( [ glrt - large - eq1 ] ) and smaller than the right - hand side in  ( [ glrt - large - eq2 ] ) , which is the case by the assumptions we made .",
    "notice that in proposition  [ prpglrt - large ] the condition on @xmath284 implies that @xmath285 , which is much stronger than what the squared - sum test requires when @xmath208 . for @xmath7-sets ,",
    "@xmath274so that @xmath286and the requirement is that @xmath287 , which is substantially stronger than what the lower bound obtained in corollary  [ corksets ] requires .",
    "moreover , if we restrict @xmath284 to be bounded away from @xmath88 , then the glrt may be powerless .",
    "[ thmglrt - bad ] let @xmath5 be the class of all @xmath7-sets .",
    "if @xmath288 and @xmath289 , the glrt has a  bayes risk bounded away from zero .",
    "the proof is in the .    in view of theorem",
    "[ thmglrt - bad ] , the glrt is clearly suboptimal when in the situation stated there , and compares very poorly with the squared - sum test , which is asymptotically powerful if @xmath290 as seen in proposition  [ prpsq ] .",
    "we do not know of any other situation where the glrt fails so miserably .",
    "while the glrt is near - optimal for detecting objects from a  parametric class such as @xmath7-intervals , it needs knowledge of @xmath75 .",
    "however , a  simple modification solves this drawback .",
    "indeed , consider the following `` local '' squared - sum test : @xmath291 for some appropriate threshold @xmath251 .",
    "[ prplocal - sum ] consider a  class @xmath5 of sets of size @xmath7 , with cardinality @xmath254 such that @xmath255 .",
    "when @xmath292 in  ( [ model - general ] ) , the local squared - sum test with threshold @xmath293 has worst - case risk tending to zero .",
    "the proof is quite straightforward . indeed , under the null , for any @xmath249 of size @xmath7 we have @xmath294 so that @xmath295 with probability tending to 1 . under an alternative  ( [ model - general ] )",
    ", @xmath249 denoting the anomalous set of variables , we have @xmath296 when @xmath292 .",
    "specializing this result to the case of @xmath7-intervals leads to the following statement ( which ignores logarithmic factors ) :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ the localized squared - sum test is near - optimal for detecting @xmath7-intervals in the regime where @xmath297 .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    _ when @xmath7 is unknown .",
    "_ we might only know that some interval is anomalous , without knowing the size of that interval . in that case , multiple testing at each @xmath7 using the local squared - sum test yields adaptivity .",
    "computationally , this may be done effectively by computing sums in a  multiscale fashion as advocated in  @xcite .",
    "in fact , here it is enough to compute the sums over all _ dyadic _ intervals  since each interval @xmath249 contains a  dyadic interval of length at least @xmath298and this can be done in @xmath299 flops in a  recursive fashion .      by now , the parametric case is essentially solved , with the local squared - sum test being not only near - optimal but also computable in polynomial time ( in @xmath0 and @xmath7 ) for the case of @xmath7-intervals , for example . in the nonparametric case , so far , the story is not complete .",
    "we focus on the class of all @xmath7-sets . there we know that the squared - sum test is near - optimal if @xmath208 . if @xmath214 , it has no power , and we only know that the glrt works when @xmath300 , which does not match the rate obtained in corollary  [ corksets ] .",
    "worse than that , it is not clear whether computing the glrt is possible in time polynomial in @xmath301 . we now show that a  simple goodness - of - fit ( gof ) test performs ( almost ) as desired .    the basic idea is the following .",
    "let @xmath302 , where @xmath303 is the standard normal distribution function . under the null ,",
    "the @xmath304 s are i.i.d .",
    "uniform in @xmath305 . under an alternative with anomalous set denoted by @xmath249 ,",
    "the @xmath306 are closer together , especially since we place ourselves in the regime where @xmath285 .",
    "more precisely , we have the following .    [ lemclose ]",
    "suppose @xmath65 are zero - mean , unit - variance random variables satisfying @xmath307 , for all @xmath308 .",
    "let @xmath309 denote their average .",
    "then for any @xmath310 , @xmath311    let @xmath312 .",
    "elementary calculations show that @xmath313 = 1 -\\frac1k -\\frac{\\lambda}{k^2 } \\leq(1 -1/k)(1 - \\rho ) \\leq 1-\\rho.\\ ] ] by markov s inequality , we then have @xmath314 the statement follows from observing that @xmath315    the idea , therefore , is detecting unusually high concentrations of @xmath304 s , which is a  form of gof test for the uniform distribution . under a  general correlation model as in  ( [ model - general ] ) , with lemma  [ lemclose ] we see that the concentration will happen over an interval of length slightly larger than @xmath316 .",
    "this is apparent from lemma  [ lemrepresent ] under the simple correlation model ( [ model ] ) .",
    "choose an integer @xmath28 such that @xmath317 and partition the interval @xmath318 $ ] into @xmath28 bins of length @xmath319 , denoted @xmath320 .",
    "let @xmath321 be the bin counts  thus , we are computing a  histogram .",
    "then consider the following gof test : @xmath322 where @xmath251 is some threshold .",
    "[ prpgof ] consider the class @xmath5 of all @xmath7-sets in the case where @xmath323 and @xmath253 . in the gof test",
    "above , choose @xmath28 such that @xmath324 . when @xmath325 in  ( [ model - general ] ) , the resulting test with threshold @xmath326 has worst - case risk tending to zero .",
    "bernstein s inequality , applied to the binomial distribution , gives that @xmath327.\\ ] ] this and the union bound imply that , indeed , @xmath328    consider now an alternative of the form  ( [ model - general ] ) , with @xmath249 denoting the anomalous set .",
    "let @xmath329 though the set @xmath330 is random , by lemma  [ lemclose ] and the fact that @xmath331 , we have that @xmath332 define the event @xmath333 for some @xmath150 .",
    "note that , since the variance of @xmath334 is bounded by 1 , @xmath335 .",
    "define @xmath336 .",
    "on  @xmath337 , using a  simple taylor expansion , we have @xmath338 where @xmath339 denotes the standard normal density function and @xmath340 is taken sufficiently large . therefore ,",
    "when @xmath341 and @xmath337 hold , at least @xmath342 of the anomalous @xmath304 s fall in an interval of length at most @xmath343 .",
    "since such an interval is covered by at most @xmath344 bins , by the pigeonhole principle , there is a  bin that contains @xmath345 anomalous @xmath304 s . by bernstein s inequality",
    ", the same bin will also contain at least @xmath346 nonanomalous @xmath304 s ( with high probability ) , so in total this bin will contain @xmath347 points . by our choice of @xmath28 , @xmath348",
    ", so it suffices to choose @xmath192 slowly enough that @xmath349 still .",
    "then , with high probability , there is a  bin with more than @xmath251 points .    ignoring logarithmic factors , we are now able to state the following :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ the gof test is near - optimal for detecting @xmath7-sets in the regime where @xmath214 and @xmath253 . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    when @xmath350 , things are somewhat different .",
    "there , the gof test requires that @xmath351 , which is still close to optimal when @xmath352 , but far from optimal when @xmath7 is bounded ( e.g. , when @xmath353 , the exponent is 4 instead of  2 ) .",
    "indeed , when @xmath350 , @xmath28 needs to be chosen larger than @xmath0 , and bernstein s inequality is not accurate .",
    "instead , we use the simple bound @xmath354 note that bennett s inequality would also do . ( the analysis also requires some refinement showing that , with probability tending to 1 under the alternative , one cell contains at least @xmath7 points . ) note that in the remaining case , @xmath355 , the glrt is optimal up to a  logarithmic factor , since it only requires that @xmath356 , as seen in section  [ secglrt - nonparametric ] .",
    "we do not know whether a  comparable performance can be achieved by a  test that does not have access to @xmath75 .",
    "_ when @xmath7 is unknown .",
    "_ in essence , we are trying to detect an interval with a  higher mean in a  poisson count setting .",
    "as before , it is enough to look at dyadic intervals of all sizes , which can be done efficiently as explained earlier , following the multiscale ideas in  @xcite .",
    "the proof is divided into three steps .",
    "the first step formalizes the fact that we want to prove that ( under @xmath4 ) , the contaminated set has no influence ( with high probability ) on the glrt statistic .",
    "the second step exhibits a  useful high probability event .",
    "finally , in the third step we show that on this high probability event , the contaminated set has no influence on the glrt .",
    "it can easily be seen that for every @xmath249 of size @xmath7 , @xmath357 introduce the function @xmath358 defined by @xmath359 for @xmath360 . denoting , for @xmath361 and @xmath236 , the vector of components of @xmath362 belonging to @xmath249 by @xmath363 , we may write the glrt as @xmath364 note that by the symmetry of @xmath5 and the test , @xmath365 given @xmath366 , define the coupling @xmath367 as follows : @xmath368 for @xmath369 , and @xmath370 are independent for @xmath371 .",
    "note that @xmath372 . then ,",
    "no matter what the threshold @xmath251 is , we have @xmath373 in the following we show that , with probability tending to @xmath88 , we have @xmath374 which then implies that the glrt is asymptotically powerless .    by lemma  [ lemrepresent ] , there exist @xmath68 independent standard normal such that for all @xmath371 , @xmath375 using the fact that @xmath376 with high probability , with probability tending to 1 , we have @xmath377,\\ ] ] where @xmath378 and @xmath379 is any sequence such that @xmath380 .",
    "fix @xmath381 to be determined later and define @xmath382 where @xmath172 . by the fact that @xmath383 are i.i.d .",
    "standard normal , @xmath384 , so that @xmath385 if @xmath386 .",
    "when @xmath387 is bounded away from @xmath88 , this is the case if @xmath388 .    in conclusion",
    ", we proved that the event @xmath389 has a  probability that tends to @xmath88 if @xmath390 as long as @xmath387 is bounded away from 1 .",
    "we specify @xmath391 .",
    "note that , as required , @xmath387 exceeds and is bounded away from 1 .",
    "assume that we are on the event @xmath392 .",
    "first note that @xmath393\\\\[-8pt ] & = & k ( k-1 ) \\zeta^2 ( 1 - \\rho\\gamma^2 ) , \\nonumber\\end{aligned}\\ ] ] and the same holds for @xmath394 .",
    "let @xmath8 be such that @xmath395 .",
    "we want to show that there exists @xmath396 such that @xmath397 .",
    "this entails that @xmath398 , since for @xmath399 we have @xmath400 .",
    "first remark that we can assume that @xmath401 since otherwise by  ( [ eqminordered ] ) we can simply take @xmath402 . to simplify notation , we may assume that @xmath403 . by definition of @xmath392 and the fact that @xmath249 contains at least one index in @xmath404",
    ", there exist @xmath405 such that @xmath406 and @xmath407 do not appear in @xmath408 .",
    "we want to show that by replacing @xmath409 by either @xmath406 or @xmath407 , in @xmath408 , one increases the value of @xmath410 .",
    "more precisely , we want to show that @xmath411 then by induction one can show the existence of the @xmath396 described above .",
    "note that , for @xmath412 and @xmath413 , @xmath414 consider the case where @xmath415 ( the case @xmath416 can be dealt with similarly ) . since @xmath417 , it suffices to show that @xmath418 , which follows from @xmath419 this concludes the proof .",
    "we thank omiros papaspiliopoulos for his illuminating remarks and the anonymous referees for challenging us to obtain stronger results in the sparse setting and for pointing out a  mistake in proposition  [ prpgof ] ."
  ],
  "abstract_text": [
    "<S> we consider the hypothesis testing problem of deciding whether an observed high - dimensional vector has independent normal components or , alternatively , if it has a  small subset of correlated components . </S>",
    "<S> the correlated components may have a  certain combinatorial structure known to the statistician . </S>",
    "<S> we establish upper and lower bounds for the worst - case ( minimax ) risk in terms of the size of the correlated subset , the level of correlation , and the structure of the class of possibly correlated sets . </S>",
    "<S> we show that some simple tests have near - optimal performance in many cases , while the generalized likelihood ratio test is suboptimal in some important cases .    ,    .    </S>"
  ]
}