{
  "article_text": [
    "consider the problem of measuring the traffic on two links in a communication network and inferring whether the two links are carrying any common traffic  @xcite .",
    "evidently , this inference can not be made by inspecting the measurements from one of the links alone , except in the extreme situation in which that link carries no traffic at all .",
    "thus it is necessary to transport the measurements from one of the links to the other , or to transport both measurements to a third location .",
    "the measured data is potentially high - rate , however , so this transportion may require that the data be compressed .",
    "this raises the question of how to compress data when the goal is not to reproduce it _ per se _ , but rather to perform inference .",
    "a similar problem arises when inferring the speed of a moving vehicle from the times that it passes certain waypoints .",
    "these problems can be modeled mathematically by the setup depicted in fig .",
    "[ fig : fig1 ] , which we call the @xmath0-encoder general hypothesis testing problem .",
    "a vector source @xmath1 has different joint distributions @xmath2 and @xmath3 under two hypotheses @xmath4 and @xmath5 , respectively .",
    "encoder @xmath6 observes an i.i.d .",
    "string distributed according to @xmath7 and sends a message to the detector at a finite rate of @xmath8 bits per observation using a noiseless channel .",
    "the detector , which has access to an i.i.d .",
    "string distributed according to @xmath9 , makes a decision between the hypotheses .",
    "the detector may make two types of error : the type 1 error ( @xmath4 is true but the detector decides otherwise ) and the type 2 error ( @xmath5 is true but the detector decides otherwise ) .",
    "the type 1 error probability is upper bounded by a fixed value .",
    "the type 2 error probability decreases exponentially fast , say with an exponent @xmath10 , as the length of the i.i.d .",
    "strings increases .",
    "the goal is to characterize the rate - exponent region of the problem , which is the set of all achievable rate - exponent vectors @xmath11 , in the regime in which the type 1 error probability is small .",
    "this problem was first introduced by berger  @xcite ( see also @xcite ) and arises naturally in many applications . yet despite these applications , the theoretical understanding of this problem is far from complete , especially when compared with its sibling , distributed source coding , where random binning has been shown to be a key ingredient in many optimal schemes .",
    "-encoder general hypothesis testing , width=336 ]    note that if one of the variables in the set @xmath12 has a different marginal distribution under @xmath2 and @xmath3 , then one of the terminals can detect the underlying hypothesis with an exponentially - decaying type 2 error probability , even without receiving any information from the other terminals , and could communicate this decision to other terminals by broadcasting a single bit .",
    "motivated by the applications mentioned above , we shall focus our attention on the case in which the variables @xmath13 have the same marginal distibutions under both hypotheses .",
    "ahlswede and csiszr @xcite studied a special case of this problem in which @xmath14 .",
    "they presented a scheme in which the encoder sends a quantized value of @xmath15 to the detector which uses it to perform the test with the help of @xmath9 .",
    "they showed that their scheme is optimal for a `` test against independence . ''",
    "their scheme was later improved by han  @xcite and shimokawa - han - amari  @xcite . in the latter improvement ,",
    "the encoder first quantizes @xmath15 , then bins the quantized value using a slepian and wolf encoder @xcite .",
    "the detector first decodes the quantized value with the help of @xmath9 and then performs a likelihood ratio test . in this scheme ,",
    "type 2 errors can occur in two different ways : the binning can fail so that the receiver decodes the wrong codeword and therefore makes an incorrect decision , or the true codeword can be decoded correctly yet be atypically distributed with @xmath9 , again resulting in an incorrect decision .",
    "moreover , there is a tension between these two forms of error .",
    "if the codeword is a high fidelity representation of @xmath15 , then binning errors are likely , yet the detector is relatively unlikely to make an incorrect decision if it decodes the codeword correctly .",
    "if the codeword is a low fidelity representation , then binning errors are unlikely , but the detector is more likely to make an incorrect decision when it decodes correctly .    , width=364 ]",
    "[ fig : fig2 ] illustrates this tradeoff for a fixed test channel @xmath16 used for quantization .",
    "all mutual information quantities are computed with respect to @xmath17 .",
    "@xmath18 and @xmath19 are the exponents associated with type 2 errors due to binning errors and assuming correct decoding of the codeword , respectively .",
    "formulas for each are available in  @xcite . for low rates , binning errors are common and @xmath18 dominates the overall exponent . for high rates , binning errors are uncommon and @xmath19 dominates the overall exponent . to achieve the overall performance , the test channel should be chosen so that these two exponents are equal ; if they are not , then making the test channel slightly more or less noisy will yield better performance",
    "a similar tradeoff arises in the analysis of error exponents of binning - based schemes for the wyner - ziv problem  @xcite and in the design of short block - length codes for wyner - ziv or joint source - channel coding .",
    "evidently the benefit accrued from binning is reduced when one considers error exponents , as opposed to when the design criterion is vanishing error probability or average distortion , because the error exponent associated with the binning process itself may dominate the overall performance .",
    "the shimokawa - han - amari scheme uses random , unstructured binning .",
    "it is known from the lossless source coding literature that structured binning schemes can strictly improve upon unstructured binning schemes in terms of the error exponents  @xcite .",
    "thus , two questions naturally arise :    1 .",
    "is the tradeoff depicted in fig .",
    "[ fig : fig2 ] fundamental to the problem or an artifact of a suboptimal scheme ?",
    "2 .   can the scheme be improved by using structured binning ?",
    "we conclusively answer both questions and show that unstructured binning is optimal in several important cases .",
    "we begin by considering a special case of the problem that we call @xmath0-encoder hypothesis testing against conditional independence . here",
    "@xmath9 is replaced by a three - source @xmath20 such that @xmath21 induces conditional independence between @xmath22 and @xmath9 under @xmath5 .",
    "in addition , @xmath23 and @xmath24 have the same distributions under both hypotheses .",
    "this problem is a generalization of the single - encoder test against independence studied by ahlswede and csiszr @xcite ,    for this problem we provide an achievable region , based on a scheme we call quantize - bin - test , that reduces to the shimokawa - han - amari region for @xmath25 yet is significantly simpler .",
    "we also introduce an outer bound similar to the outer bound for the distributed rate - distortion problem given by wagner and anantharam @xcite .",
    "the idea is to introduce an auxiliary random variable that induces conditional independence between the sources .",
    "this technique of obtaining an outer bound has been used to prove results in many distributed source coding problems @xcite .",
    "the inner ( achievable ) and outer bounds are shown to match in three examples .",
    "the first is the case in which there is only one encoder ( @xmath25 ) .",
    "although this problem is simply the conditional version of the test against independence studied by ahlswede and csiszr  @xcite , the conditional version is much more complicated due to the necessary introduction of binning .",
    "it follows that the shimokawa - han - amari scheme is optimal for @xmath25 , providing what appears to be the first nontrivial optimality result for this scheme .",
    "this problem arises in detecting network flows in the presence of common cross - traffic that is known to the detector . here",
    "@xmath15 represents the network traffic measured at a remote location , @xmath9 is the traffic measured at the detector , and @xmath21 represents the cross - traffic .",
    "the goal is to detect the presence of common traffic beyond @xmath21 , i.e. , to determine whether @xmath21 captures all of the dependence between @xmath15 and @xmath9 .",
    "the second is a problem inspired by a result of gelfand and pinsker  @xcite .",
    "we refer to this as the gelfand and pinsker hypothesis testing against independence problem , the setup of which is shown in fig .",
    "[ fig : fig3 ] . here",
    "@xmath26 and @xmath21 are deterministic and there is a source @xmath27 which under @xmath4 is the minimum sufficient statistic for @xmath9 given @xmath28 such that @xmath29 are conditionally independent given @xmath27 .",
    "we characterize the set of rate vectors @xmath30 that achieve the centralized exponent @xmath31 .",
    "we show that the quantize - bin - test scheme is optimal for this problem .",
    "the third is the gaussian many - help - one hypothesis testing against independence problem , the setup of which is shown in fig .",
    "[ fig : fig4 ] . here",
    "the sources are jointly gaussian and there is another scalar gaussian source @xmath32 observed by the main encoder which sends a message to the detector at a rate @xmath33 .",
    "the encoder observing @xmath7 is now referred to as the helper @xmath6 .",
    "we characterize the rate - exponent region of this problem in a special case when @xmath34 are conditionally independent given @xmath27 .",
    "we use results on related source coding problem by oohama @xcite and prabhakaran _ et al .",
    "_ @xcite to obtain an outer bound , which we show is achieved by the quantize - bin - test scheme .",
    "for all three examples , we obtain the solution by observing that the relevant error exponent takes the form of a mutual information , and thereby relate the problem to a source - coding problem .",
    "this correspondence was first observed by ahlswede and csiszr @xcite .",
    "tian and chen later applied it in the context of successive refinement  @xcite .",
    "these three conclusive results enable us to answer both of the above questions . because the shimokawa - han - amari scheme is optimal for @xmath14 , the tradeoff that it entails , depicted in fig .",
    "[ fig : fig2 ] , must be fundamental to the problem .",
    "moreover , as both the shimokawa - han - amari and quantize - bin - test schemes do not use structured binning , we conclude that it is not necessary for this problem , at least in the special case considered here .    as a byproduct of our results",
    ", we obtain an outer bound for a more general class of instances of the distributed hypothesis testing problem .",
    "this is the first nontrivial outer bound for the problem , and numerical experiments show that it is quite close to the existing achievable regions in many cases .",
    "the rest of the paper is organized as follows . in section 2",
    ", we introduce the notation used in the paper .",
    "we give the mathematical formulation of the @xmath0-encoder general hypothesis testing problem in section 3 .",
    "section 4 is devoted to the @xmath0-encoder hypothesis testing against conditional independence problem .",
    "section 5 is on the special case in which there is only one encoder .",
    "the gelfand and pinsker hypothesis testing against independence problem is studied in section 6 .",
    "the gaussian many - help - one hypothesis testing against independence problem is studied on section 7 .",
    "finally , we present the outer bound for a class of the general problem in section 8 .",
    "we use upper case to denote random variables and vectors .",
    "boldface is used to distinguish vectors from scalars .",
    "arbitrary realizations of random variables and vectors are denoted in lower case . for a random variable @xmath27",
    ", @xmath35 denotes an i.i.d .",
    "vector of length @xmath36 , @xmath37 denotes its _ _ i__th component , @xmath38 denotes the _ _ i__th through _ _",
    "j__th components , and @xmath39 denotes all but the _ _ i__th component . for random variables @xmath27 and @xmath9 , we use @xmath40 and @xmath41 to denote the variance of @xmath27 and the conditional variance of @xmath27 given @xmath9 , respectively . the closure of a set @xmath42 is denoted by @xmath43 . @xmath44 denotes the cardinality of the range of a function @xmath45 .",
    "@xmath46 denotes the indicator function of an event @xmath47 .",
    "the determinant of a matrix @xmath48 is denoted by @xmath49 .",
    "the notation @xmath50 denotes @xmath51 .",
    "all logarithms are to the base 2 .",
    "@xmath52 is used to denote the positive orthant in @xmath0-dimensional euclidean space .",
    "the notation @xmath53 means that @xmath54 and @xmath21 form a markov chain in this order . for @xmath55",
    ", @xmath56 denotes the binary entropy function defined as @xmath57 all entropy and mutual information quantities are under the null hypothesis , @xmath4 , unless otherwise stated .",
    "let @xmath58 be a generic source taking values in @xmath59 , where @xmath60 and @xmath61 are alphabet sets of @xmath62 and @xmath63 , respectively .",
    "the distribution of the source is @xmath64 under the null hypothesis @xmath4 and is @xmath65 under the alternate hypothesis @xmath5 , i.e. , @xmath66 let @xmath67 be an i.i.d . sequence of random vectors with the distribution at a single stage same as that of @xmath68 .",
    "we use @xmath69 to denote the set @xmath70 . for @xmath71",
    ", @xmath72 denotes the complement set @xmath73 and @xmath74 denotes @xmath75 . when @xmath76 , we simply write @xmath77 as @xmath78 .",
    "likewise when @xmath79 , we write @xmath80 and @xmath81 as @xmath82 and @xmath83 , respectively . similar notation will be used for other collections of random variables .    as depicted in fig .",
    "[ fig : fig1 ] , the encoder @xmath6 observes @xmath84 , then sends a message to the detector using an encoding function @xmath85 @xmath86 is available at the detector , which uses it and the messages from the encoders to make a decision between the hypotheses based on a decision rule @xmath87 where @xmath88 is the acceptance region for @xmath4 . the encoders @xmath89 and the detector @xmath90 are such that the type 1 error probability does not exceed a fixed @xmath91 in @xmath92 , i.e. , @xmath93 and the type 2 error probability does not exceed @xmath94 , i.e. , @xmath95    a rate - exponent vector @xmath96 is _ achievable _ for a fixed @xmath91 if for any positive @xmath97 and sufficiently large @xmath36 , there exists encoders @xmath98 and a detector @xmath90 such that @xmath99 let @xmath100 be the set of all achievable rate - exponent vectors for a fixed @xmath91 . the _ rate - exponent region _",
    "@xmath101 is defined as @xmath102    our goal is to characterize the region @xmath101 .",
    "we start with the entropy characterization of the rate - exponent region .",
    "we shall use it later in the paper to obtain inner and outer bounds . define the set @xmath103 where @xmath104 we have the following proposition .",
    "@xmath105 .",
    "the proof of proposition 1 is a straight - forward generalization of that of theorem 1 in @xcite and is hence omitted .",
    "ahlswede and csiszr @xcite showed that for @xmath14 , the strong converse holds , i.e. , @xmath100 is independent of @xmath106 .",
    "thus , @xmath107 is essentially a characterization for both @xmath101 and @xmath100 .",
    "while we expect this to hold for the problem under investigation too , we shall not investigate it here .",
    "we next study a class of instances of the problem before returning to the general problem in section 8 .",
    "we consider a class of instances of the general problem , referred to as the @xmath0-encoder hypothesis testing against conditional independence problem , and obtain inner and outer bounds to the rate - exponent region .",
    "these bounds coincide and characterize the region completely in some cases .",
    "moreover , the outer bound for this problem can be used to give an outer bound for a more general class of problems , as we shall see later .",
    "let @xmath26 and @xmath21 be two generic sources taking values in alphabet sets @xmath108 and @xmath109 , respectively such that @xmath110 and @xmath9 are conditionally independent given @xmath21 under @xmath5 , and the distributions of @xmath111 and @xmath24 are the same under both hypotheses , i.e. , @xmath112 the problem formulation is the same as before with @xmath9 replaced by @xmath113 in it .",
    "the reason for focusing on this special case is that the relative entropy in ( 1 ) becomes a mutual information , which simplifies the analysis .",
    "let @xmath114 be the rate - exponent region of this problem . here",
    " @xmath115 \" stands for conditional independence",
    ". let @xmath116 where @xmath117 we have the following corollary as a consequence of proposition 1 .      with mutual information replacing relative entropy , the problem can be analyzed using techniques from distributed rate - distortion .",
    "in particular , both inner and outer bounds for that problem can be applied here .",
    "our inner bound is based on a simple scheme which we call the quantize - bin - test scheme . in this scheme ,",
    "encoders , as in the shimokawa - han - amari scheme , quantize and then bin their observations , but the detector now performs the test directly using the bins .",
    "the inner bound obtained is similar to the generalized berger - tung inner bound for distributed source coding @xcite .",
    "let @xmath119 be the set of finite - alphabet random variables @xmath120 satisfying        1 .   @xmath127 remains unchanged if we impose the following cardinality bound on @xmath128 in @xmath119 latexmath:[\\ ] ] where ( 61 ) follows by setting @xmath560 since entropy is a strictly concave and continuous function , @xmath121 is a nonnegative continuous function of @xmath561 .",
    "moreover , for any @xmath555 in @xmath556 , @xmath562 for all @xmath299 in @xmath563 such that @xmath564 .",
    "let @xmath565 denote the set of all such @xmath561 .",
    "define @xmath566 it now follows from lemma 8 that if @xmath567 for some @xmath17 in @xmath565 , then @xmath17 must be a point mass and hence @xmath568",
    ". therefore , @xmath569 .",
    "we next show that @xmath570 is continuous at @xmath571 .",
    "consider a nonnegative sequence @xmath572 .",
    "then there exists a sequence of distributions @xmath573 in @xmath565 such that @xmath574 now , since the set of all distributions on @xmath563 is a compact set , by considering a subsequence , we can assume without loss of generality that @xmath573 converges to @xmath17 in @xmath565 . by letting @xmath575 in ( 62 )",
    ", we obtain that @xmath576 , i.e. , @xmath17 is a point mass .",
    "therefore , @xmath568 .",
    "it now follows from ( 63 ) that @xmath577 as @xmath575 . hence , @xmath570 is continuous at @xmath571 .",
    "fix @xmath578 ( condition ( c7 ) is always true for @xmath579 ) .",
    "choose @xmath580 such that @xmath581 .",
    "set @xmath582 .",
    "let @xmath230 .",
    "define the sets @xmath583 note that @xmath584 is nonempty because @xmath585 .",
    "we now have @xmath586 which implies @xmath587 hence , @xmath588",
    "t. he and l. tong ,  detection of information flows , \" _ ieee trans .",
    "inf . theory _ ,",
    "4925 - 4945 , nov .",
    "a. agaskar , t. he , and l. tong ,  distributed detection of multi - hop information flows with fusion capacity constraints , \" _ ieee trans .",
    "58 , no . 6 , pp .",
    "3373 - 3383 , june 2010 .",
    "t. berger , ",
    "decentralized estimation and decision theory , \" in _",
    "ieee 7th spring workshop on inf . theory _ , mt .",
    "kisco , ny , sept .",
    "t. s. han and s. amari ,  statistical inference under multiterminal data compression , \" _ ieee trans .",
    "inf . theory _ ,",
    "44 , no . 6 , pp .",
    "2300 - 2324 , oct . 1998 .",
    "r. ahlswede and i. csiszr ,  hypothesis testing with communication constraints , \" _ ieee trans .",
    "inf . theory _ ,",
    "533 - 542 , july 1986 .",
    "t. s. han ,  hypothesis testing with multiterminal data compression , \" _ ieee trans .",
    "inf . theory _",
    "33 , no . 6 , pp .",
    "759 - 772 , nov .",
    "h.  shimokawa , t.  s.  han , and s. amari ,  error bound of hypothesis testing with data compression , \" in _ ieee int .",
    "proc . _ , 1994 ,",
    "d. slepian and j. k. wolf ,  noiseless coding of correlated information sources , \" _ ieee trans .",
    "inf . theory _ ,",
    "471 - 480 , july 1973 .",
    "b. g. kelly and a. b. wagner ,  reliability in source coding with side information , \" preprint .",
    "b. g. kelly , a. b. wagner , and a. vamvatsikos ,  error exponents and test channel optimization for the gaussian wyner - ziv problem , \" in _ ieee int .",
    "proc . _ , 2008 , pp .  414 - 418",
    ". b. g. kelly and a. b. wagner ,  error exponents and test channel optimization for the wyner - ziv problem , \" in _ proc .",
    "45th annual allerton conference _",
    "y.  kochman and g.  w.  wornell ,  on the excess distortion exponent of the quadratic - gaussian wyner - ziv problem , \" in _ ieee int .",
    "proc . _ , 2010 , p. 36 - 40 .",
    "i. csiszr ,  linear codes for sources and source networks : error exponents , universal coding , \" _ ieee trans .",
    "585 - 592 , july 1982 .",
    "b. g. kelly and a. b. wagner ,  improved source coding exponents via witsenhausen s rate , \" preprint .",
    "i. csiszr and j. krner ,  graph decomposition : a new key to coding theorems , \" _ ieee trans .",
    "inf . theory _",
    "1 , pp . 5 - 12 ,",
    "jan . 1981 .",
    "a. b. wagner and v. anantharam ,  an improved outer bound for multiterminal source coding , \" _ ieee trans .",
    "inf . theory _ ,",
    "1919 - 1937 , may 2008 .",
    "s. tavildar , p. viswanath , and a. b. wagner ,  the gaussian many - help - one distributed source coding problem , \" _ ieee trans .",
    "inf . theory _ ,",
    "564 - 581 , jan . 2010 .",
    "a. b. wagner , s. tavildar , and p. viswanath ,  rate region of the quadratic gaussian two - encoder source - coding problem , \" _ ieee trans .",
    "inf . theory _",
    "1938 - 1961 , may 2008 .",
    "a. b. wagner ,  on distributed compression of linear functions , \" in _ proc .",
    "46th annual allerton conference _ , 2008 , pp .",
    "1546 - 1553 .",
    "ozarow ,  on a source - coding problem with two channels and three receivers , \" _ bell sys .",
    "10 , pp . 1909 - 1921 , 1980 .",
    "h. wang and p. viswanath ,  vector gaussian multiple description with two levels of receivers , \" _ ieee trans .",
    "inf . theory _ ,",
    "401 - 410 , jan .",
    "2009 . s. i. gelfand and m. s. pinsker ,  coding of sources on the basis of observations with incomplete information , \" ( in russian ) , _ problemy peredachi informatsii _ , vol .",
    "45 - 57 , april - june 1979 .",
    "y. oohama ,  rate - distortion theory for gaussian multiterminal source coding systems with several side informations at the decoder , \" _ ieee trans .",
    "inf . theory _ ,",
    "51 , no . 7 , pp .",
    "2577 - 2593 , july 2005 . v. prabhakaran , d. tse , and k. ramchandran ,  rate region of the quadratic gaussian ceo problem , \" in _ ieee int .",
    "proc . _ , 2004 ,",
    "c. tian and j. chen ,  successive refinement for hypothesis testing and lossless one - helper problem , \" _ ieee trans .",
    "4666 - 4681 , oct . 2008 .",
    "t. berger ,  multiterminal source coding , \" in _ the information theory approach to communications _",
    "cism courses and lectures , g. longo , ed .",
    "springer - verlag , 1978 , vol .",
    "171 - 231 .",
    "s. y. tung ,  multiterminal source coding , \" ph.d .",
    "dissertation , school of electrical engineering , cornell university , ithaca , ny , may 1978 .",
    "m. gastpar ,  the wyner - ziv problem with multiple sources , \" _ ieee trans .",
    "inf . theory _",
    "11 , pp . 2762 - 2768 ,",
    "nov . 2004 .",
    "j. chen , x. zhang , t. berger , and s. b. wicker ,  an upper bound on the sum - rate distortion function and its corresponding rate allocation schemes for the ceo problem , \" _",
    "ieee j. select .",
    "areas commun .",
    "_ , vol . 22 , no . 6 , pp .",
    "977 - 987 , aug .",
    "p. viswanath ,  sum rate of a class of gaussian multiterminal source coding problems , \" in _ advances in network information theory _ , ser .",
    "dimacs in discrete mathematics and theoretical computer science , p. gupta , g. kramer , and a. j. van wijngaarden , eds .",
    "ams , 2004 , vol .",
    "a. b. wagner , b. g. kelly , and y. altu ,  the lossy one - helper conjecture is false , \" in _ proc .",
    "47th annual allerton conference _ , 2009 , pp .",
    "716 - 723 .",
    "i. csiszr and j. krner , _ information theory : coding theorems for discrete memoryless systems , _",
    "academic , new york , 1981 .",
    "j. wang , j. chen , and x. wu ,  on the minimum sum rate of gaussian multiterminal source coding : new proofs , \" in _ ieee int .",
    "proc . _ , 2009 , pp .",
    "1463 - 1467 .",
    "t. m. cover and j. a. thomas , _ elements of information theory _",
    "new york : john wiley & sons , 2005 . y. oohama , ",
    "gaussian multiterminal source coding , \" _ ieee trans .",
    "inf . theory _",
    "43 , no . 6 , pp .",
    "1912 - 1923 , nov . 1997 . c. tian and j. chen ,  remote vector gaussian source coding with decoder side information under mutual information and distortion constraints , \" _ ieee trans .",
    "inf . theory _ ,",
    "4676 - 4680 , oct .",
    "a. globerson and n. tishby ,  on the optimality of the gaussian information bottleneck curve , \" in _ hebrew univ .",
    "report _ , 2004 .",
    "s. rahman and a. b. wagner ,  vector gaussian hypothesis testing and lossy one - helper problem , \" in _ ieee int .",
    "_ , 2009 , pp .",
    "968 - 972 ."
  ],
  "abstract_text": [
    "<S> we study a hypothesis testing problem in which data is compressed distributively and sent to a detector that seeks to decide between two possible distributions for the data . </S>",
    "<S> the aim is to characterize all achievable encoding rates and exponents of the type 2 error probability when the type 1 error probability is at most a fixed value . for related problems in distributed source coding , schemes based on random binning perform well and often optimal . for distributed hypothesis testing </S>",
    "<S> , however , the use of binning is hindered by the fact that the overall error probability may be dominated by errors in binning process . </S>",
    "<S> we show that despite this complication , binning is optimal for a class of problems in which the goal is to `` test against conditional independence . '' </S>",
    "<S> we then use this optimality result to give an outer bound for a more general class of instances of the problem .    </S>",
    "<S> * keywords : * distributed hypothesis testing , binning , test against conditional independence , quantize - bin - test scheme , gaussian many - help - one hypothesis testing against independence , gelfand and pinsker hypothesis testing against independence , rate - exponent region , outer bound . </S>"
  ]
}