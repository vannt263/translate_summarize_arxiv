{
  "article_text": [
    "network analysis @xcite has gained considerable research interests in both theories @xcite and applications @xcite .",
    "a lot of recent work has been focusing on studying networks from a nonparametric perspective @xcite , following the deep advancement in exchangeable arrays @xcite . in this paper , we study the fundamental limits in estimating the underlying generating mechanism of network models , called graphon . though various algorithms have been proposed and analyzed @xcite , it is not clear whether the convergence rates obtained in these works can be improved , and not clear what the differences and connections are between nonparametric graphon estimation and classical nonparametric regression .",
    "the results obtained in this paper provide answers to those questions .",
    "we found many existing results in literature are not sharp .",
    "nonparametric graphon estimation can be seen as nonparametric regression without knowing design .",
    "when the smoothness of the graphon is small , the minimax rate of graphon estimation is identical to that of nonparametric regression .",
    "this is surprising , since graphon estimation seems to be a more difficult problem , for which the design is not observed .",
    "when the smoothness is high , we show that the minimax rate does not depend on the smoothness anymore , which provides a clear distinction between nonparametric graphon estimation and nonparametric regression .",
    "we consider an undirected graph of @xmath9 nodes .",
    "the connectivity can be encoded by an adjacency matrix @xmath10 taking values in @xmath11 . the value of @xmath12 stands for the presence or the absence of an edge between the @xmath13th and the @xmath14th nodes .",
    "the model in this paper is @xmath15 for @xmath16 , where @xmath17 .",
    "\\label{eqgraphon}\\ ] ] the sequence @xmath18 are random variables sampled from a distribution @xmath19 supported on @xmath20^n$ ] .",
    "a common choice for the probability @xmath19 is i.i.d .",
    "uniform distribution on @xmath20 $ ] . in this paper , we allow @xmath19 to be any distribution , so that the model ( [ eqgraphon ] ) is studied to its full generality . given @xmath18 , we assume @xmath21 are independent for @xmath22 , and adopt the convention that @xmath23 for each @xmath24 $ ] . the nonparametric model ( [ eqgraphon ] ) is inspired by the advancement of graph limit theory @xcite .",
    "the function @xmath25 , which is assumed to be symmetric , is called graphon .",
    "this concept plays a significant role in network analysis .",
    "since graphon is an object independent of the network size @xmath9 , it gives a natural criterion to compare networks of different sizes .",
    "moreover , model based prediction and testing can be done through graphon @xcite . besides nonparametric models , various parametric models have been proposed on the matrix @xmath26 to capture different aspects of the network @xcite .",
    "the model ( [ eqgraphon ] ) has a close relation to the classical nonparametric regression problem .",
    "we may view the setting ( [ eqgraphon ] ) as modeling the mean of @xmath12 by a regression function @xmath27 with design @xmath28 . in a regression problem , the design points @xmath28",
    "are observed , and the function @xmath29 is estimated from the pair @xmath30 . in contrast , in the graphon estimation setting , @xmath28 are latent random variables , and @xmath29 can only be estimated from the response @xmath10 .",
    "this causes an identifiability problem , because without observing the design , there is no way to associate the value of @xmath25 with @xmath31 . in this paper",
    ", we consider the following loss function : @xmath32}(\\hat { \\theta}_{ij}-\\theta_{ij})^2\\ ] ] to overcome the identifiability issue .",
    "this is identical to the loss function widely used in the classical nonparametric regression problem with the form @xmath32 } \\bigl(\\hat{f } ( \\xi_i,\\xi_j)-f(\\xi _ i,\\xi_j ) \\bigr)^2 . \\ ] ] even without observing the design @xmath28 , it is still possible to estimate the matrix @xmath26 by exploiting its underlying structure modeled by ( [ eqgraphon ] ) .",
    "we first consider @xmath26 of a block structure .",
    "this stochastic block model , proposed by @xcite , is serving as a standard data generating process in network community detection problem @xcite .",
    "we denote the parameter space for @xmath26 by @xmath33 , where @xmath0 is the number of clusters in the stochastic block model . in total , there are an order of @xmath34 number of blocks in @xmath26 .",
    "the value of @xmath35 only depends on the clusters that the @xmath13th and the @xmath14th nodes belong to .",
    "the exact definition of @xmath33 is given in section  [ secsbm ] .",
    "for this setting , the minimax rate for estimating the matrix @xmath26 is as follows .",
    "[ teominimax2 ] under the stochastic block model , we have @xmath36}(\\hat{\\theta}_{ij}- \\theta _ { ij})^2 \\biggr\\}\\asymp\\frac{k^2}{n^2}+ \\frac{\\log k}{n},\\ ] ] for any @xmath37 .",
    "the convergence rate has two terms .",
    "the first term @xmath38 is due to the fact that we need to estimate an order of @xmath34 number of unknown parameters with an order of @xmath39 number of observations .",
    "the second term @xmath3 , which we coin as the clustering rate , is the error induced by the lack of identifiability of the order of nodes in exchangeable random graph models .",
    "namely , it is resulted from the unknown clustering structure of the @xmath9 nodes .",
    "this term grows logarithmically as the number of clusters @xmath0 increases , which is different from what is obtained in literature @xcite based on lower rank matrix estimation .",
    "we also study the minimax rate of estimating @xmath26 modeled by the relation ( [ eqgraphon ] ) with @xmath29 belonging to a hlder class @xmath40 with smoothness @xmath4 .",
    "the class @xmath40 is rigorously defined in section  [ secgraphon ] .",
    "the result is stated in the following theorem .",
    "[ teominimax1 ] consider the hlder class @xmath40 , defined in section  [ secgraphon ] .",
    "we have @xmath41}(\\hat{\\theta}_{ij}-\\theta_{ij})^2 \\biggr\\}\\asymp\\cases { n^{-\\afrac{2\\alpha}{\\alpha+1 } } , & \\quad$0<\\alpha<1 $ , \\vspace*{5pt}\\cr \\displaystyle \\frac{\\log n}{n } , & \\quad$\\alpha\\geq1 $ , } \\ ] ] where the expectation is jointly over @xmath10 and @xmath18 .    the approximation of piecewise block function to an @xmath4-smooth graphon @xmath29 yields an additional error at the order of @xmath42 ( see lemma  [ lembias ] ) . in view of the minimax rate in theorem [ teominimax2 ] ,",
    "picking the best @xmath0 to trade off the sum of the three terms @xmath42 , @xmath38 , and @xmath3 gives the minimax rate in theorem  [ teominimax1 ] .",
    "the minimax rate reveals a new phenomenon in nonparametric estimation . when the smoothness parameter @xmath4 is smaller than @xmath43 , the optimal rate of convergence is the typical nonparametric rate .",
    "note that the typical nonparametric rate is @xmath44 @xcite , where @xmath45 is the number of observations and @xmath46 is the function dimension . here",
    ", we are in a two - dimensional setting with number of observations @xmath47 and dimension @xmath48 . then the corresponding rate is @xmath49 .",
    "surprisingly , in theorem  [ teominimax1 ] for the regime @xmath7 , we get the exact same nonparametric minimax rate , though we are not given the knowledge of the design @xmath28 .",
    "the cost of not observing the design is reflected in the case with @xmath5 . in this regime ,",
    "the smoothness of the function does not help improve the rate anymore .",
    "the minimax rate is dominated by @xmath6 , which is essentially contributed by the logarithmic cardinality of the set of all possible assignments of @xmath9 nodes to @xmath0 clusters .",
    "a distinguished feature of theorem  [ teominimax1 ] to note is that we do not impose any assumption on the distribution @xmath19 .    to prove theorems  [ teominimax2 ]  and  [ teominimax1 ]",
    ", we develop a novel lower bound argument ( see sections  [ secflower ]  and  [ secpflower ] ) , which allows us to correctly obtain the packing number of all possible assignments .",
    "the packing number characterizes the difficulty brought by the ignorance of the design @xmath50 in the graphon model or the ignorance of clustering structure in the stochastic block model",
    ". such argument may be of independent interest , and we expect its future applications in deriving minimax rates of other network estimation problems .",
    "our work on optimal graphon estimation is closely connected to a growing literature on nonparametric network analysis . for estimating the matrix @xmath26 of stochastic block model",
    ", @xcite viewed @xmath26 as a rank-@xmath0 matrix and applied singular value thresholding on the adjacency matrix .",
    "the convergence rate obtained is @xmath51 , which is not optimal compared with the rate @xmath1 in theorem  [ teominimax2 ] . for nonparametric graphon estimation ,",
    "@xcite considered estimating @xmath29 in a hlder class with smoothness @xmath4 and obtained the rate @xmath52 under a closely related loss function .",
    "the work by @xcite obtained the rate @xmath6 for estimating a lipschitz @xmath29 , but they imposed strong assumptions on @xmath29 .",
    "namely , they assumed @xmath53 for some constants @xmath54 , with @xmath55 . note that this condition excludes the stochastic block model , for which @xmath56 when different @xmath57 and @xmath58 are in the same cluster .",
    "local asymptotic normality for stochastic block model was established in @xcite .",
    "a  method of moment via tensor decomposition was proposed by @xcite.=-1      the paper is organized as follows . in section  [ secmain ] , we state the main results of the paper , including both upper and lower bounds for stochastic block model and nonparametric graphon estimation .",
    "section  [ secdisc ] is a discussion section , where we discuss possible generalization of the model , relation to nonparametric regression without knowing design and lower bound techniques used in network analysis .",
    "the main body of the technical proofs are presented in section  [ secproof ] , and the remaining proofs are stated in the supplementary material @xcite .      for any positive integer @xmath46",
    ", we use @xmath59 $ ] to denote the set @xmath60 . for any @xmath61 , let @xmath62 and @xmath63 .",
    "the floor function @xmath64 is the largest integer no greater than @xmath65 , and the ceiling function @xmath66 is the smallest integer no less than @xmath65 .",
    "for any two positive sequences @xmath67 and @xmath68 , @xmath69 means there exists a constant @xmath70 independent of @xmath9 , such that @xmath71 for all @xmath9 . for any @xmath72",
    ", we denote the @xmath73 norm by @xmath74}a_{ij}^2}$ ] and the inner product by @xmath75}a_{ij}b_{ij}$ ] .",
    "given any set @xmath76 , @xmath77 denotes its cardinality , and @xmath78 stands for the indicator function which takes value @xmath43 when @xmath79 and takes value @xmath80 when @xmath81 . for a metric space @xmath82 , the covering number @xmath83 is the smallest number of balls with radius @xmath84 and centers in @xmath85 to cover @xmath85 , and the packing number @xmath86 is the largest number of points in @xmath85 that are at least @xmath84 away from each other .",
    "the symbols @xmath87 and @xmath88 stand for generic probability and expectation , whenever the distribution is clear from the context .",
    "in this section , we present the main results of the paper . we first introduce the estimation procedure in section  [ secmethod ] .",
    "the minimax rates of stochastic block and nonparametric graphon estimation are stated in sections  [ secsbm ]  and  [ secgraphon ] , respectively .",
    "we are going to propose an estimator for both stochastic block model and nonparametric graphon estimation under hlder smoothness . to introduce the estimator ,",
    "let us define the set @xmath89\\rightarrow[k ] \\}$ ] to be the collection of all possible mappings from @xmath90 $ ] to @xmath91 $ ] with some integers @xmath9 and @xmath0 . given a @xmath92 , the sets @xmath93\\}$ ] form a partition of @xmath90 $ ] , in the sense that @xmath94}z^{-1}(a)=[n]$ ] and @xmath95 for any @xmath96 $ ] .",
    "in other words , @xmath97 defines a clustering structure on the @xmath9 nodes .",
    "it is easy to see that the cardinality of @xmath98 is @xmath99 . given a matrix @xmath100 , and a partition function @xmath92 , we use the following notation to denote the block average on the set @xmath101 .",
    "that is , @xmath102,\\label{eqaveab}\\ ] ] and when @xmath103 , @xmath104.\\label{eqaveaa}\\ ] ] for any @xmath105 and @xmath106 , define the objective function @xmath107}\\mathop{\\sum _ { ( i , j)\\in z^{-1}(a)\\times z^{-1}(b)}}_{i\\neq j}(a_{ij}-q_{ab})^2.\\ ] ] for any optimizer of the objective function , @xmath108 the estimator of @xmath35 is defined as @xmath109 and @xmath110 for @xmath111 .",
    "set the diagonal element by @xmath112 .",
    "the procedure ( [ eqdefthetahat ] ) can be understood as first clustering the data by an estimated @xmath113 and then estimating the model parameters via block averages . by the least squares formulation , it is easy to observe the following property .",
    "[ propestimation ] for any minimizer @xmath114 , the entries of @xmath115 has representation @xmath116 for all @xmath117 $ ] .",
    "the representation of the solution ( [ eqdefqhat ] ) shows that the estimator ( [ eqdefthetahat ] ) is essentially doing a histogram approximation after finding the optimal cluster assignment @xmath118 according to the least squares criterion ( [ eqestimator ] ) . in the classical nonparametric regression problem",
    ", it is known that a simple histogram estimator can not achieve optimal convergence rate for @xmath119 @xcite .",
    "however , we are going to show that this simple histogram estimator achieves optimal rates of convergence under both stochastic block model and nonparametric graphon estimation settings .",
    "similar estimators using the bernoulli likelihood function have been proposed and analyzed in the literature @xcite . instead of using the likelihood function of bernoulli distribution , the least squares estimator ( [ eqestimator ] ) can be viewed as maximizing gaussian likelihood .",
    "this allows us to obtain optimal convergence rates with cleaner analysis .      in the stochastic block model setting , each node @xmath24 $ ] is associated with a label @xmath120 $ ] , indicating its cluster .",
    "the edge @xmath12 is a bernoulli random variable with mean @xmath121 .",
    "the value of @xmath35 only depends on the clusters of the @xmath13th and the @xmath14th nodes .",
    "we assume @xmath26 is from the following parameter space : @xmath122^{n\\times n } : \\theta _ { ii}=0 , \\theta_{ij}=q_{ab}=q_{ba } \\\\ & & \\mbox{for } ( i , j)\\in z^{-1}(a)\\times z^{-1}(b ) \\mbox { for some } q_{ab}\\in[0,1]\\mbox { and } z\\in \\mathcal{z}_{n , k } \\bigr\\}.\\end{aligned}\\ ] ] namely , the partition function @xmath97 assigns cluster to each node , and the value of @xmath123 measures the intensity of link between the @xmath65th and the @xmath124th clusters .",
    "the least squares estimator ( [ eqestimator ] ) attains the following convergence rate for estimating @xmath26 .    [ teomain2 ] for any constant @xmath125 , there is a constant @xmath70 only depending on @xmath126 , such that @xmath32}(\\hat { \\theta}_{ij}-\\theta _ { ij})^2\\leq c \\biggl ( \\frac{k^2}{n^2}+\\frac{\\log k}{n } \\biggr),\\ ] ] with probability at least @xmath127 , uniformly over @xmath128 . furthermore , we have @xmath129}(\\hat{\\theta}_{ij}-\\theta_{ij})^2 \\biggr\\}\\leq c_1 \\biggl(\\frac{k^2}{n^2}+\\frac{\\log k}{n } \\biggr),\\ ] ] for all @xmath130 $ ] with some universal constant @xmath131 .",
    "theorem  [ teomain2 ] characterizes different convergence rates for @xmath0 in different regimes .",
    "suppose @xmath132 for some @xmath133 $ ] .",
    "then the convergence rate in theorem  [ teomain2 ] is @xmath134 $ , \\vspace*{5pt}\\cr n^{-2(1-\\delta ) } , & \\quad$\\delta\\in(1/2,1]$.}\\label{eqfenlei}\\ ] ] the result completely characterizes the convergence rates for stochastic block model with any possible number of clusters @xmath0 . depending on whether @xmath0 is small , moderate or large , the convergence rates behave differently",
    ".    the convergence rate , in terms of @xmath0 , has two parts .",
    "the first part @xmath38 is called the nonparametric rate .",
    "it is determined by the number of parameters and the number of observations of the model . for the stochastic block model with @xmath0 clusters ,",
    "the number of parameters is @xmath135 and the number of observations is @xmath136 .",
    "the second part @xmath3 is called the clustering rate .",
    "its presence is due to the unknown labels of the @xmath9 nodes .",
    "our result shows the clustering rate is logarithmically depending on the number of clusters @xmath0 . from ( [ eqfenlei ] )",
    ", we observe that when @xmath0 is small , the clustering rate dominates .",
    "when @xmath0 is large , the nonparametric rate dominates .    to show that the rate in theorem  [ teomain2 ] can not be improved , we obtain the following minimax lower bound .    [ teosbmlower ] there exists a universal constant @xmath70 , such that @xmath137}(\\hat{\\theta}_{ij}- \\theta _ { ij})^2\\geq c \\biggl(\\frac{k^2}{n^2}+ \\frac{\\log k}{n } \\biggr ) \\biggr\\ } \\geq0.8,\\ ] ] and @xmath36}(\\hat{\\theta}_{ij}- \\theta _ { ij})^2 \\biggr\\}\\geq c \\biggl(\\frac{k^2}{n^2}+ \\frac{\\log k}{n } \\biggr),\\ ] ] for any @xmath130 $ ] .",
    "the upper bound of theorem  [ teomain2 ] and the lower bound of theorem  [ teosbmlower ] immediately imply the minimax rate in theorem  [ teominimax2 ] .",
    "let us proceed to nonparametric graphon estimation .",
    "for any @xmath138 , @xmath12 is sampled from the following process : @xmath139 for @xmath24 $ ] , @xmath140 .",
    "conditioning on @xmath141 , @xmath12 is independent across @xmath142 $ ] . to completely specify the model , we need to define the function class of @xmath29 on @xmath20 ^ 2 $ ] .",
    "since @xmath29 is symmetric , we only need to specify its value on @xmath143 ^ 2 : x\\geq y\\}$ ] .",
    "define the derivative operator by @xmath144 and we adopt the convention @xmath145 .",
    "the hlder norm is defined as @xmath146 the hlder class is defined by @xmath147 where @xmath148 is the smoothness parameter and @xmath149 is the size of the class , which is assumed to be a constant .",
    "when @xmath150 $ ] , a function @xmath151 satisfies the lipschitz condition @xmath152 for any @xmath153 . in the network model , the graphon @xmath29",
    "is assumed to live in the following class : @xmath154 we have mentioned that the convergence rate of graphon estimation is essentially due to the stochastic block model approximation of @xmath29 in a hlder class .",
    "this intuition is established by the following lemma , whose proof is given in the supplementary material @xcite .",
    "[ lembias ] there exists @xmath155 , satisfying @xmath156}\\sum _ { \\{i\\neq j : z^*(i)=a , z^*(j)=b\\ } } \\bigl(\\theta_{ij}-\\bar{\\theta}_{ab } \\bigl(z^*\\bigr ) \\bigr)^2\\leq cm^2 \\biggl(\\frac{1}{k^2 } \\biggr)^{\\alpha\\wedge1},\\ ] ] for some universal constant @xmath70 .",
    "the graph limit theory @xcite suggests @xmath19 to be an i.i.d .",
    "uniform distribution on the interval @xmath20 $ ] . for the estimating procedure ( [ eqestimator ] ) to work ,",
    "we allow @xmath157 to be any distribution .",
    "the upper bound is attained over all distributions @xmath19 uniformly .",
    "combining lemma  [ lembias ] and theorem  [ teomain2 ] in an appropriate manner , we obtain the convergence rate for graphon estimation by the least squares estimator ( [ eqestimator ] ) .",
    "[ teomain1 ] choose @xmath158 .",
    "then for any @xmath125 , there exists a constant @xmath70 only depending on @xmath126 and @xmath159 , such that @xmath32}(\\hat { \\theta}_{ij}-\\theta _ { ij})^2\\leq c \\biggl(n^{-\\afrac{2\\alpha}{\\alpha+1}}+\\frac{\\log n}{n } \\biggr),\\ ] ] with probability at least @xmath160 , uniformly over @xmath161 and @xmath19 .",
    "furthermore , @xmath162}(\\hat{\\theta}_{ij}- \\theta _ { ij})^2 \\biggr\\}\\leq c_1 \\biggl(n^{-\\afrac{2\\alpha}{\\alpha+1}}+\\frac { \\log n}{n } \\biggr),\\ ] ] for some other constant @xmath131 only depending on @xmath159 .",
    "both the probability and the expectation are jointly over @xmath10 and @xmath163 .",
    "similar to theorem  [ teomain2 ] , the convergence rate of theorem [ teomain1 ] has two parts . the nonparametric rate @xmath164 , and the clustering rate @xmath6 .",
    "note that the clustering rates in both theorems are identical because @xmath165 under the choice @xmath158 .",
    "an interesting phenomenon to note is that the smoothness index @xmath4 only plays a role in the regime @xmath166 .",
    "the convergence rate is always dominated by @xmath6 when @xmath5 .    in order to show",
    "the rate of theorem  [ teomain1 ] is optimal , we need a lower bound over the class @xmath40 and over all @xmath19 . to be specific ,",
    "we need to show @xmath167}(\\hat{\\theta}_{ij}-\\theta_{ij})^2 \\biggr\\}\\geq c \\biggl(n^{-\\afrac{2\\alpha}{\\alpha+1}}+\\frac{\\log n}{n } \\biggr ) , \\label{eqweakl}\\ ] ] for some constant @xmath70 .",
    "in fact , the lower bound we obtained is stronger than ( [ eqweakl ] ) in the sense that it holds for a subset of the space of probabilities on @xmath18 .",
    "the subset @xmath168 requires the sampling points @xmath18 to well cover the interval @xmath20 $ ] for @xmath169}$ ] to be good representatives of the whole function @xmath29 . for each @xmath120 $ ] ,",
    "define the interval @xmath170 we define the distribution class by @xmath171 \\biggr)>1-\\exp \\bigl(-n^{\\delta}\\bigr ) \\biggr\\},\\ ] ] for some positive constants @xmath172 and some arbitrary small constant @xmath173 .",
    "namely , for each interval @xmath174 , it contains roughly @xmath175 observations . by applying standard concentration inequality",
    ", it can be shown that the i.i.d .",
    "uniform distribution on @xmath163 belongs to the class @xmath168 .",
    "[ teographonlower ] there exists a constant @xmath70 only depending on @xmath176 , such that @xmath177}(\\hat{\\theta}_{ij}-\\theta_{ij})^2 \\geq c \\biggl(n^{-\\afrac{2\\alpha}{\\alpha+1}}+\\frac{\\log n}{n }",
    "\\biggr ) \\biggr\\}\\geq0.8,\\ ] ] and @xmath178}(\\hat{\\theta}_{ij}-\\theta_{ij})^2 \\biggr\\ } \\geq c \\biggl(n^{-\\afrac{2\\alpha}{\\alpha+1}}+\\frac{\\log n}{n } \\biggr),\\ ] ] where the probability and expectation are jointly over @xmath10 and @xmath18 .",
    "the proof of theorem  [ teographonlower ] is given in the supplementary material @xcite .",
    "the minimax rate in theorem  [ teominimax1 ] is an immediate consequence of theorems  [ teomain1 ] and  [ teographonlower ] .",
    "the results in this paper assume symmetry on the graphon @xmath29 and the matrix @xmath26 .",
    "such assumption is naturally made in the context of network analysis .",
    "however , these results also hold under more general models .",
    "we may consider a slightly more general version of ( [ eqgraphon ] ) as @xmath179 with @xmath18 and @xmath180 sampled from @xmath19 and @xmath181 , respectively , and the function @xmath29 is not necessarily symmetric . to be specific ,",
    "let us redefine the hlder norm @xmath182 by replacing @xmath183 with @xmath20^{2}$ ] in its original definition in section  [ secgraphon ] .",
    "then we consider the function class @xmath184 the minimax rate for this class is stated in the following theorem without proof .",
    "[ teodisc1 ] consider the function class @xmath185 with @xmath186 and @xmath149 .",
    "we have @xmath187}(\\hat { \\theta}_{ij}- \\theta_{ij})^2 \\biggr\\}\\asymp\\cases { n^{-\\afrac{2\\alpha}{\\alpha+1 } } , & \\quad$0<\\alpha<1 $ , \\vspace*{5pt}\\cr \\displaystyle\\frac{\\log n}{n } , & \\quad$\\alpha\\geq1 $ , } \\ ] ] where the expectation is jointly over @xmath10 , @xmath18 and @xmath188 .",
    "similarly , we may generalize the stochastic block model by the parameter space @xmath189^{n\\times m } : \\theta_{ij}=q_{ab}\\mbox { for } ( i , j)\\in z_1^{-1}(a)\\times z_2^{-1}(b ) \\\\ & & \\mbox{with some } q_{ab}\\in[0,1 ] , z_1\\in \\mathcal{z}_{n , k}\\mbox { and } z_2\\in\\mathcal{z}_{m , l } \\bigr\\}.\\end{aligned}\\ ] ] such model naturally arises in the contexts of biclustering @xcite and matrix organization @xcite , where symmetry of the model is not assumed . under such extension , we can show that a similar minimax rate as in theorem  [ teominimax2 ] as follows .",
    "[ teodisc2 ] consider the parameter space @xmath190 and assume @xmath191 .",
    "we have @xmath192}}_{j\\in[m ] } ( \\hat{\\theta}_{ij}-\\theta _ { ij})^2 \\biggr\\}\\asymp \\frac{kl}{nm}+\\frac{\\log k}{m}+\\frac{\\log l}{n},\\ ] ] for any @xmath37 and @xmath193 .",
    "the lower bounds of theorems  [ teodisc1 ]  and  [ teodisc2 ] are directly implied by viewing the symmetric parameter spaces as subsets of the asymmetric ones . for the upper bound",
    ", we propose a modification of the least squares estimator in section  [ secmethod ] .",
    "consider the criterion function @xmath194\\times[l]}\\sum_{(i , j)\\in z_1^{-1}(a)\\times z_2^{-1}(b)}(a_{ij}-q_{ab})^2.\\ ] ] for any @xmath195 , define the estimator of @xmath35 by @xmath196\\times[m].\\ ] ] using the same proofs of theorems  [ teomain2 ] and  [ teomain1 ] , we can obtain the upper bounds .      the graphon estimation problem is closely related to the classical nonparametric regression problem .",
    "this section explores their connections and differences to bring better understandings of both problems .",
    "namely , we study the problem of nonparametric regression without observing the design .",
    "first , let us consider the one - dimensional regression problem @xmath197,\\ ] ] where @xmath18 are sampled from some @xmath19 , and @xmath198 are i.i.d .",
    "@xmath199 variables .",
    "a  nonparametric function estimator @xmath200 estimates the function @xmath29 from the pairs @xmath201 . for hlder class with smoothness",
    "@xmath4 , the minimax rate under the loss @xmath202 } ( \\hat{f}(\\xi _ i)-f(\\xi_i ) ) ^2 $ ] is at the order of @xmath203 @xcite .",
    "however , when the design @xmath204 is not observed , the minimax rate is at a constant order . to see this fact ,",
    "let us consider a closely related problem @xmath205,\\ ] ] where we assume @xmath206 .",
    "the parameter space @xmath207 is defined as a subset of @xmath20^n$ ] with @xmath208 that can only take two possible values @xmath209 and @xmath210 .",
    "it can be viewed as a one - dimensional version of stochastic block model .",
    "we can show that @xmath211}(\\hat { \\theta}_i-\\theta_i)^2 \\biggr\\ } \\asymp1.\\ ] ] the upper bound is achieved by letting @xmath212 for each @xmath24 $ ] . to see the lower bound , we may fix @xmath213 and @xmath214 .",
    "then the problem is reduced to @xmath9 independent two - point testing problems between @xmath215 and @xmath216 for each @xmath24 $ ] .",
    "it is easy to see that each testing problem contributes to an error at the order of a constant , which gives the lower bound of a constant order .",
    "this leads to a constant lower bound for the original regression problem by using the embedding technique in the proof of theorem  [ teographonlower ] , which shows that @xmath207 is a smaller space than a hlder class on a subset of @xmath90 $ ] .",
    "thus , @xmath43 is also a lower bound for the regression problem without knowing design .",
    "in contrast to the one - dimensional problem , we can show that a two - dimensional nonparametric regression without knowing design is more informative .",
    "consider @xmath217,\\ ] ] where @xmath18 are sampled from some @xmath19 , and @xmath218 are i.i.d .",
    "@xmath199 variables .",
    "let us consider the hlder class @xmath219 with hlder norm @xmath182 defined in section  [ secgeneral ] .",
    "when the design @xmath18 is known , the minimax rate under the loss @xmath220 } ( \\hat{f}(\\xi_i,\\xi_j)-f(\\xi _ i,\\xi_j ) ) ^2 $ ] is at the order of @xmath221 .",
    "when the design is unknown , the minimax rate is stated in the following theorem .",
    "consider the hlder class @xmath222 for @xmath186 and @xmath149 .",
    "we have @xmath223 } \\bigl(\\hat{f}(\\xi_i,\\xi_j)-f ( \\xi_i,\\xi_j ) \\bigr)^2 \\biggr\\ } \\\\ & & \\qquad \\asymp \\cases { n^{-\\afrac{2\\alpha}{\\alpha+1 } } , & \\quad$0<\\alpha<1 $ , \\vspace*{5pt}\\cr \\displaystyle\\frac{\\log n}{n } , & \\quad$ \\alpha\\geq1 $ , } \\ ] ] where the expectation is jointly over @xmath10 and @xmath18 .",
    "the minimax rate is identical to that of theorem  [ teominimax1 ] , which demonstrates the close relation between nonparametric graphon estimation and nonparametric regression without knowing design .",
    "the proof of this result is similar to the proofs of theorems  [ teomain1 ]  and  [ teographonlower ] , and is omitted in the paper .",
    "one simply needs to replace the bernoulli analysis by the corresponding gaussian analysis in the proof .",
    "compared with the rate for one - dimensional regression without knowing design , the two - dimensional minimax rate is more interesting .",
    "it shows that the ignorance of design only matters when @xmath5 . for @xmath224 ,",
    "the rate is exactly the same as the case when the design is known .",
    "the main reason for the difference between the one - dimensional and the two - dimensional problems is that the form of @xmath28 implicitly imposes more structure . to illustrate this point ,",
    "let us consider the following two - dimensional problem @xmath225,\\ ] ] where @xmath226 ^ 2 $ ] and @xmath227 are sampled from some distribution .",
    "it is easy to see that this is equivalent to the one - dimensional problem with @xmath39 observations and the minimax rate is at the order of a constant .",
    "the form @xmath28 implies that the lack of identifiability caused by the ignorance of design is only resulted from row permutation and column permutation , and thus it is more informative than the design @xmath227 .      a key contribution of the paper lies in the proof of theorem  [ teosbmlower ] , where we establish the lower bound @xmath228 ( especially the @xmath3 part ) via a novel construction .",
    "to better understand the main idea behind the construction , we present the analysis for a finite @xmath0 in this section . when @xmath229 , the minimax rate becomes @xmath230 . to prove this lower bound , it is sufficient to consider the parameter space @xmath33 with @xmath231",
    ". let us define @xmath232,\\ ] ] for some @xmath233 to be determined later .",
    "define the subspace @xmath234^{n\\times n } : \\theta _ { ij}=q_{z(i)z(j)}\\mbox { for some } z\\in\\mathcal{z}_{n,2 } \\bigr\\}.\\ ] ] it is easy to see that @xmath235 .",
    "with a fixed @xmath236 , the set @xmath85 has a one - to - one correspondence with @xmath237 .",
    "let us define the collection of subsets @xmath238\\}$ ] .",
    "for any @xmath239 , it induces a partition @xmath240 on the set @xmath90 $ ] .",
    "this corresponds to @xmath241 for some @xmath242 . with this observation ,",
    "we may rewrite @xmath85 as @xmath243^{n\\times n } : \\theta_{ij}=\\frac { 1}{2}\\mbox { for } ( i , j)\\in(s\\times s)\\cup \\bigl(s^c\\times s^c\\bigr ) , \\\\ & & { } \\theta_{ij } = \\frac{1}{2}+\\frac{c}{\\sqrt{n}}\\mbox { for } ( i , j)\\in\\bigl(s\\times s^c\\bigr)\\cup\\bigl(s^c\\times s \\bigr),\\mbox { with some } s\\in \\mathcal{s } \\biggr\\}.\\end{aligned}\\ ] ] the subspace @xmath85 characterizes the difficulty of the problem due to the ignorance of the clustering structure @xmath244 of the @xmath9 nodes .",
    "such difficulty is central in the estimation problem of network analysis .",
    "we are going to use fano s lemma ( proposition  [ propfano ] ) to lower bound the risk .",
    "then it is sufficient to upper bound the kl diameter @xmath245 and lower bound the packing number @xmath246 for some appropriate @xmath84 and the metric @xmath247 .",
    "using proposition  [ propprobdistance ] , we have @xmath248 to obtain a lower bound for @xmath86 , note that for @xmath249 associated with @xmath250 , we have @xmath251 where @xmath252 is the symmetric difference defined as @xmath253 . by viewing @xmath254 as the hamming distance of the corresponding indicator functions of the sets , we can use the varshamov ",
    "gilbert bound ( lemma  [ lemvg ] ) to pick @xmath255 satisfying @xmath256,\\ ] ] with @xmath257 , for some @xmath258 .",
    "hence , we have @xmath259 applying ( [ eqfanokl ] ) of proposition  [ propfano ] , we have @xmath260}(\\hat{\\theta}_{ij}- \\theta _ { ij})^2\\geq\\frac{c^2}{32n } \\biggr\\}\\geq1- \\frac{8c^2n+\\log 2}{c_1n}\\geq0.8,\\ ] ] where the last inequality holds by choosing a sufficiently small @xmath261 .",
    "note that the above derivation ignores the fact that @xmath262 for @xmath24 $ ] for the sake of clear presentation .",
    "the argument can be easily made rigorous with slight modification .",
    "thus , we prove the lower bound for a finite @xmath0 . for @xmath0 growing with @xmath9 ,",
    "a more delicate construction is stated in section  [ secpflower ] .",
    "an important application of theorems  [ teomain2 ] and  [ teomain1 ] is link prediction . the link prediction or the network completion problem",
    "@xcite has practical significances . instead of observing the whole adjacency matrix ,",
    "we observe @xmath263 for some @xmath264\\times[n]$ ] . the goal is to infer the unobserved edges .",
    "one example is the biological network .",
    "scientific study showed that only 80% of the molecular interactions in cells of yeast are known @xcite .",
    "accurate prediction of those unseen interactions can greatly reduce the costs of biological experiments . to tackle the problem of link prediction",
    ", we consider a modification of the constrained least square program , which is defined  as @xmath265 the estimator @xmath266 obtained from solving ( [ eqcompletion ] ) takes advantage of the underlying block structure of the network , and is an extension to ( [ eqestimator ] ) .",
    "the number @xmath267 can be interpreted as how likely there is an edge between @xmath13 and @xmath14 . to analyze the theoretical performance of ( [ eqcompletion ] ) ,",
    "let us assume the set @xmath268 is obtained by uniformly sampling with replacement from all edges . in other words , @xmath268 may contain some repeated elements .",
    "[ teolink - pred ] assume @xmath269 for a constant @xmath270 $ ] .",
    "for any constant @xmath125 , there exists some constant @xmath70 only depending on @xmath126 and @xmath261 such that @xmath32}(\\hat { \\theta}_{ij}-\\theta _ { ij})^2\\leq c \\biggl ( \\frac{k^2}{n^2}+\\frac{\\log k}{n } \\biggr),\\ ] ] with probability at least @xmath127 uniformly over @xmath128 for all @xmath130 $ ] .",
    "the result of theorem  [ teolink - pred ] assumes @xmath271 .",
    "for example , when @xmath272 , we only observe at most half of the edges . theorem  [ teolink - pred ]",
    "gives rate - optimal link prediction of the rest of the edges .",
    "in contrast , the low - rank matrix completion approach , though extensively studied and applied in literature , only gives a rate @xmath273 , which is inferior to that of theorem  [ teolink - pred ] .    in the case where the assumption of stochastic block model is not natural @xcite",
    ", we may consider a more general class of networks generated by a smooth graphon .",
    "this is also a useful assumption to do link prediction . using the same estimator ( [ eqcompletion ] ) with @xmath274",
    ", we can obtain the error @xmath32}(\\hat { \\theta}_{ij}-\\theta _ { ij})^2\\leq c \\biggl(n^{-\\afrac{2\\alpha}{2\\alpha+1}}+\\frac{\\log n}{n } \\biggr),\\ ] ] with probability at least @xmath160 uniformly over @xmath275 and @xmath19 , which extends theorem  [ teomain1 ] . the proof of theorem  [ teolink - pred ] is nearly identical to that of theorem  [ teomain2 ] and is omitted in the paper .",
    "the minimax rates in the paper are all studied under the @xmath73 norm , which is the frobenius norm for a matrix .",
    "it is also interesting to investigate the minimax rate under the matrix operator norm .",
    "recall that for a matrix @xmath276 , its operator norm @xmath277 is the largest singular value .",
    "[ teooperator ] for the stochastic block model @xmath33 with @xmath278 , we have @xmath279    interestingly , the result of theorem  [ teooperator ] does not depend on @xmath0 as long as @xmath278 .",
    "the optimal estimator is the adjacency matrix itself @xmath280 , whose bound under the operator norm can be derived from standard random matrix theory @xcite .",
    "the lower bound is directly implied from theorem  [ teosbmlower ] by the following argument : @xmath281\\\\[-8pt]\\nonumber & \\gtrsim & \\inf_{\\hat{\\theta}\\in\\theta_2}\\sup_{\\theta\\in\\theta_2 } \\mathbb{e}{\\vert}\\hat{\\theta}-\\theta { \\vert}_{\\mathrm{op}}^2 \\gtrsim\\inf_{\\hat{\\theta}}\\sup_{\\theta\\in\\theta_2}\\mathbb { e}{\\vert}\\hat{\\theta}-\\theta{\\vert}^2.\\end{aligned}\\ ] ] the first inequality is because @xmath207 is a smaller model than @xmath33 for @xmath278 .",
    "the second inequality is because of the fact that we can always project the estimator into the parameter space without compromising the convergence rate .",
    "then , for @xmath282 , @xmath283 is a matrix with rank at most @xmath284 , and we have the inequality @xmath285 , which gives the last inequality . finally , @xmath286 by theorem  [ teosbmlower ] implies the desired conclusion .",
    "theorem  [ teooperator ] suggests that estimating @xmath287 under the operator norm is not a very interesting problem , because the estimator does not need to take advantage of the structure of the space @xmath33 . due to recent advances in community detection , a more suitable parameter space for the problem",
    "is @xmath288 , where @xmath289^{n\\times n } : \\theta_{ii}=0 , \\max_{ij } { \\theta_{ij}}\\leq\\beta \\bigr\\}.\\ ] ] the parameter @xmath290 is understood to be the sparsity of the network because a smaller @xmath290 leads to less edges of the graph .",
    "[ teosparse - op ] for @xmath291 and @xmath278 , we have @xmath292    the lower bound of theorem  [ teosparse - op ] can be obtained in a similar way by combining the argument in ( [ eqoperator ] ) and a modified version of theorem  [ teosbmlower ] ( see the supplementary material @xcite ) .",
    "when @xmath293 , the upper bound is still achieved by the adjacency matrix , as is proved in theorem 5.2 of @xcite . for @xmath294 , one needs to replace the rows and columns that have high degrees by zeros in  @xmath295 , and the upper bound is achieved by this trimmed adjacency matrix .",
    "this was recently established in @xcite .",
    "community detection is another important problem in network analysis .",
    "the parameter estimation result established in this paper has some consequences in community detection , especially for the results under the operator norm in theorems  [ teooperator ]  and  [ teosparse - op ] .",
    "recent works in community detection @xcite show that the bound for @xmath296 can be used to derive the misclassification error of spectral clustering algorithm applied on the matrix @xmath297 .",
    "recall that the spectral clustering algorithm applies @xmath0-means to the leading singular vectors of the matrix @xmath266 .",
    "theorem [ teooperator ] justifies the use of adjacency matrix as @xmath298 in spectral clustering because of its minimax optimality under the operator norm .",
    "moreover , when the network is in a sparse regime with @xmath299 , @xcite suggests to use the trimmed adjacency matrix as @xmath266 for spectral clustering . according to theorem  [ teosparse - op ] ,",
    "the trimmed adjacency matrix is an optimal estimator of @xmath287 under the operator norm .    on the other hand ,",
    "the connection between the minimax rates under the @xmath73 norm and community detection is not that close .",
    "we illustrate this point by the case when @xmath231 .",
    "let us consider @xmath300 , then @xmath301 for some @xmath302 symmetric matrix @xmath236 and @xmath97 is the label function .",
    "suppose the within community connection probability is greater than the between community connection probability by a margin of @xmath303 .",
    "namely , assume @xmath304 .",
    "then , for the estimator @xmath305 with error @xmath306}(\\hat{\\theta}_{ij}-\\theta_{ij})^2\\leq \\varepsilon^2 $ ] , the number of mis - clustered nodes under @xmath113 is roughly bounded by @xmath307 .",
    "this is because when two nodes that have the same labels under @xmath97 are clustered into different communities or when two nodes belong to different communities are clustered into the same one , an estimation error of @xmath308 must occur .",
    "conversely , bounds on community detection can lead to an improved bound for parameter estimation . specifically , when @xmath309 and @xmath310 , @xcite show that there exists a strongly consistent estimator of @xmath97 in the sense that the misclassification error is @xmath80 with high probability . in this case",
    ", the estimation error of @xmath287 under the loss @xmath220}(\\hat{\\theta}_{ij}-\\theta_{ij})^2 $ ] can be improved to @xmath311 from @xmath230 .",
    "generally , parameter estimation and community detection are different problems of network analysis .",
    "when @xmath312}$ ] all take the same value , it is impossible to do community detection , but parameter estimation would be easy .",
    "thus , good parameter estimation result does not necessarily imply consistent community detection .",
    "general minimax rates of the community detection problem are recently established in @xcite .",
    "we present the proofs of the main results in this section .",
    "the upper bounds theorems  [ teomain2 ]  and  [ teomain1 ] are proved in section  [ secpfupper ] . the lower bound theorem  [ teosbmlower ] is proved in section  [ secpflower ] .",
    "this section is devoted to proving the upper bounds .",
    "we first prove theorem  [ teomain2 ] and then prove theorem  [ teomain1 ] .",
    "let us first give an outline of the proof of theorem  [ teomain2 ] . in the definition of the class @xmath33",
    ", we denote the true value on each block by @xmath313^{k\\times k}$ ] and the oracle assignment by @xmath155 such that @xmath314 for any @xmath138 . to facilitate the proof , we introduce the following notation . for",
    "the estimated @xmath113 , define @xmath315^{k\\times k}$ ] by @xmath316 , and also define @xmath317 for any @xmath138 .",
    "the diagonal elements @xmath318 are defined as zero for all @xmath24 $ ] . by the definition of the estimator ( [ eqestimator ] )",
    ", we have @xmath319 which can be rewritten as @xmath320 the left - hand side of ( [ eqbasic ] ) can be decomposed as @xmath321 combining ( [ eqbasic ] ) and ( [ eqleftside ] ) , we have @xmath322 the right - hand side of ( [ eqrightside ] ) can be bounded as @xmath323 using lemmas  [ lemaverage][lempartition2 ] , the following three terms : @xmath324 can all be bounded by @xmath325 with probability at least @xmath326 combining these bounds with ( [ eqtbc ] ) , ( [ eqtbc1 ] ) and ( [ eqrightside ] ) , we get @xmath327 with probability at least @xmath328 .",
    "this gives the conclusion of theorem  [ teomain2 ] .",
    "the details of the proof is stated in the later part of the section . to prove theorem  [ teomain1 ] , we use lemma  [ lembias ] to approximate the nonparametric graphon by the stochastic block model . with similar arguments above",
    ", we get @xmath329 with high probability .",
    "choosing the best @xmath0 gives the conclusion of theorem  [ teomain1 ] .    before stating the complete proofs ,",
    "let us first present the following lemmas , which bound the three terms in ( [ eq3terms ] ) , respectively .",
    "the proofs of the lemmas will be given in the supplementary material @xcite .",
    "[ lemaverage ] for any constant @xmath125 , there exists a constant @xmath70 only depending on @xmath126 , such that @xmath330 with probability at least @xmath127 .",
    "[ lempartition1 ] for any constant @xmath125 , there exists a constant @xmath70 only depending on @xmath126 , such that @xmath331 with probability at least @xmath127 .",
    "[ lempartition2 ] for any constant @xmath125 , there exists a constant @xmath70 only depending on @xmath126 , such that @xmath332 with probability at least @xmath127 .",
    "proof of theorem  [ teomain2 ] combining the bounds for ( [ eq3terms ] ) with ( [ eqtbc ] ) , ( [ eqtbc1 ] ) and ( [ eqrightside ] ) , we have @xmath333 with probability at least @xmath328 . solving the above equation",
    ", we get @xmath334 with probability at least @xmath328 .",
    "this proves the high probability bound . to get the bound in expectation",
    ", we use the following inequality : @xmath335 where @xmath336 .",
    "since @xmath337 is the dominating term , the proof is complete .    to prove theorem  [ teomain1 ] , we need to redefine @xmath338 and @xmath339 .",
    "we choose @xmath338 to be the one used in lemma  [ lembias ] , which implies a good approximation of @xmath26 by the stochastic block model . with this @xmath338 , define @xmath339 by letting @xmath340 for any @xmath117 $ ] .",
    "finally , we define @xmath341 for all @xmath138 .",
    "the diagonal elements @xmath342 are set as zero for all @xmath24 $ ] .",
    "note that for the stochastic block model , we have @xmath343 .",
    "the proof of theorem  [ teomain1 ] requires another lemma .",
    "[ lempartition3 ] for any constant @xmath125 , there exists a constant @xmath70 only depending on @xmath126 , such that @xmath344 with probability at least @xmath127 .",
    "the proof of lemma  [ lempartition3 ] is identical to the proof of lemma  [ lempartition1 ] , and will be omitted in the paper .",
    "proof of theorem  [ teomain1 ] using the similar argument as outlined in the beginning of this section , we get @xmath345 whose right - hand side can be bounded as @xmath346 to better organize what we have obtained , let us introduce the notation @xmath347 @xmath348 then , by the derived inequalities , we have @xmath349 it can be rearranged as @xmath350 by solving this quadratic inequality of @xmath351 , we can get @xmath352 by lemma  [ lembias ] , lemma  [ lemaverage ] , lemma  [ lempartition2 ] and lemma  [ lempartition3 ] , for any constant @xmath125 , there exist constants @xmath353 only depending on @xmath354 , such that @xmath355 with probability at least @xmath160 . by ( [ eqboundl ] )",
    ", we have @xmath356 with probability at least @xmath160 for some constant @xmath357 .",
    "hence , there is some constant @xmath358 such that @xmath359 with probability at least @xmath160 . when @xmath5 , we choose @xmath360 , and the bound is @xmath361 for some constant @xmath362 only depending on @xmath126 and @xmath159 . when @xmath363 , we choose @xmath364",
    ". then the bound is @xmath365 for some constant @xmath366 only depending on @xmath126 and @xmath159 .",
    "this completes the proof .",
    "this section is devoted to proving the lower bounds . for any probability measures",
    "@xmath367 , define the kullback  leibler divergence by @xmath368 .",
    "the chi - squared divergence is defined by @xmath369 . to prove minimax lower bounds , we need the following proposition .    [ propfano ]",
    "let @xmath370 be a metric space and @xmath371 be a collection of probability measures .",
    "for any totally bounded @xmath372 , define the kullback ",
    "leibler diameter and the chi - squared diameter of @xmath85 by @xmath373 then @xmath374 for any @xmath375 .",
    "inequality ( [ eqfanokl ] ) is the classical fano s inequality .",
    "the version we present here is by @xcite .",
    "inequality ( [ eqfanochi2 ] ) is a generalization of the classical fano s inequality by using chi - squared divergence instead of kl divergence .",
    "it is due to @xcite .",
    "we use it here as an alternative of assouad s lemma to get the corresponding in - probability lower bound . in this section ,",
    "the parameter is a matrix @xmath376^{n\\times n}$ ] .",
    "the metric we consider is @xmath377 let us give bounds for kl divergence and chi - squared divergence under random graph model .",
    "let @xmath378 denote the probability of @xmath379 . given @xmath380^{n\\times n}$ ]",
    ", the probability @xmath381 stands for the product measure @xmath382}p_{\\theta_{ij}}$ ] throughout this section .",
    "[ propprobdistance ] for any @xmath383^{n\\times n}$ ] , we have @xmath384\\\\[-8pt]\\nonumber \\chi^2\\bigl(\\mathbb{p}_\\theta { \\vert}\\mathbb{p}_\\theta'\\bigr ) & \\le & \\exp \\biggl(8 \\sum_{ij } \\bigl(\\theta _ { ij } - \\theta'_{ij}\\bigr)^2 \\biggr).\\end{aligned}\\ ] ]    the proposition will be proved in the supplementary material @xcite .",
    "we also need the following varshamov  gilbert bound .",
    "the version we present here is due to @xcite , lemma 4.7 .",
    "[ lemvg ] there exists a subset @xmath385 such that @xmath386,\\label{eqdefh}\\ ] ] for some @xmath387 .",
    "proof of theorem  [ teosbmlower ] by the definition of the parameter space @xmath33 , we rewrite the minimax rate as @xmath388^{k \\times k } } \\sup _ { z \\in\\mathcal{z}_{n , k}}\\mathbb{p } \\biggl\\{\\frac{1}{n^2}\\sum _ { i\\neq j}(\\hat{\\theta}_{ij}-q_{z(i)z(j)})^2 \\geq\\varepsilon^2 \\biggr\\}.",
    "\\label { eqtheta}\\end{aligned}\\ ] ] if we fix a @xmath389 , it will be direct to derive the lower bound @xmath38 for estimating  @xmath236 . on the other hand ,",
    "if we fix @xmath236 and let @xmath97 vary , it will become a new type of convergence rate due to the unknown label and we name it as the clustering rate , which is at the order of @xmath3 . in the following arguments , we will prove the two different rates separately and then combine them together to get the desired in - probability lower bound .",
    "without loss of generality , we consider the case where both @xmath175 and @xmath390 are integers .",
    "if they are not , let @xmath391 and @xmath392 . by restricting the unknown parameters to the smaller class @xmath393^{k ' \\times k'}$ ] and @xmath394",
    ", the following lower bound argument works for this smaller class .",
    "then it also provides a lower bound for the original larger class .",
    "first we fix a @xmath395 . for each @xmath120 $ ]",
    ", we define @xmath396 .",
    "let @xmath397 be the set of all binary sequences of length @xmath398 .",
    "for any @xmath399 , define a @xmath400 matrix @xmath401 by @xmath402\\quad\\mbox{and } \\nonumber\\\\[-8pt]\\\\[-8pt]\\nonumber q_{aa}^{\\omega } & = & \\tfrac{1}{2}\\qquad\\mbox{for } a\\in[k],\\end{aligned}\\ ] ] where @xmath403 is a constant that we are going to specify later .",
    "define @xmath404 with @xmath405 for @xmath138 and @xmath406 .",
    "the subspace we consider is @xmath407 . to apply ( [ eqfanochi2 ] )",
    ", we need to upper bound @xmath408 and lower bound @xmath409 . for any @xmath410 , from ( [ eqprobdistance ] ) and ( [ eqyulu ] )",
    ", we get @xmath411 } \\bigl(\\theta_{ij}^{\\omega } -\\theta_{ij}^{\\omega ' } \\bigr)^2 \\biggr ) \\nonumber\\\\[-8pt]\\\\[-8pt]\\nonumber & \\le & \\exp \\biggl ( \\frac{8n^2}{k^2}\\sum _ { a , b\\in [ k]}\\bigl(q_{ab}^{\\omega } - q_{ab}^{\\omega'}\\bigr)^2 \\biggr ) \\le\\exp\\bigl(8 c_1 ^ 2 k^2\\bigr),\\end{aligned}\\ ] ] where we choose sufficiently small @xmath403 so that @xmath412 $ ] is satisfied .",
    "to lower bound the packing number , we reduce the metric @xmath413 to @xmath414 defined in ( [ eqdefh ] ) . in view of ( [ eqyulu ] ) , we get @xmath415 by lemma  [ lemvg ] , we can find a subset @xmath416 that satisfies the following properties : ( a ) @xmath417 and ( b ) @xmath418 for any @xmath419 . from ( [ eqdistlowerbound ] ) , we have @xmath420 with @xmath421 . by choosing sufficiently small @xmath403 , together with ( [ eqrho2h ] ) , we get @xmath422 by ( [ eqfanochi2 ] ) for sufficiently large @xmath0 with some constant @xmath131 . when @xmath0 is not sufficiently large , that is , @xmath423 , then it is easy to see that @xmath311 is always the correct order of lower bound .",
    "since @xmath424 when @xmath423 , @xmath38 is also a valid lower bound for small @xmath0 .",
    "we are going to fix a @xmath236 that has the following form : @xmath425 , \\label{eqspecialq}\\ ] ] where @xmath426 is a @xmath427 matrix . by lemma  [ lemvg ] ,",
    "when @xmath0 is sufficiently large , we can find @xmath428 such that @xmath429 for all @xmath430 $ ] .",
    "fixing such @xmath431 , define @xmath432 by letting @xmath433 for @xmath434 $ ] . with such construction , it is easy to see that for any @xmath435 $ ] , @xmath436 define a subset of @xmath437 by @xmath438 , \\\\ & & { } z^{-1}(a)= \\biggl\\{\\frac{(a-1)n}{k}+1,\\ldots,\\frac { an}{k } \\biggr\\}\\mbox { for } a \\in[k/2 ] \\biggr\\}.\\end{aligned}\\ ] ] for each @xmath439 , define @xmath440 by @xmath441 for @xmath138 and @xmath442 .",
    "the subspace we consider is @xmath443 . to apply ( [ eqfanokl ] )",
    ", we need to upper bound @xmath444 and lower bound @xmath445 . by ( [ eqprobdistance ] ) , for any , @xmath446 now we are going to give a lower bound of the packing number @xmath447 with @xmath448 for the @xmath449 in ( [ eqbspecial ] ) .",
    "due to the construction of @xmath426 , there is a one - to - one correspondence between @xmath450 and @xmath451 .",
    "thus , @xmath452 for some metric @xmath453 on @xmath451 defined by @xmath454 . given any @xmath439 ,",
    "define its @xmath84-neighborhood by @xmath455 .",
    "let @xmath76 be the packing set in @xmath451 with cardinality @xmath456 .",
    "we claim that @xmath76 is also the covering set of @xmath451 with radius @xmath84 , because otherwise there is some point in @xmath451 which is at least @xmath84 away from every point in @xmath76 , contradicting the definition of @xmath456 .",
    "this implies the fact @xmath457 , which leads to @xmath458 thus , we have @xmath459 let us upper bound @xmath460 first .",
    "for any @xmath461 , by the construction of @xmath451 , @xmath462 when @xmath463 $ ] and @xmath464 for each @xmath465 $ ] .",
    "hence , @xmath466 where the last inequality is due to ( [ eqbspecial ] ) . then for any @xmath467 , @xmath468 under the choice @xmath448",
    "this implies @xmath469 now we lower bound @xmath470 .",
    "note that by stirling s formula @xmath471^{k/2 } } = \\exp \\biggl ( \\frac { 1}{2 } n\\log k + o(n\\log k ) \\biggr ) \\ge\\exp \\biggl(\\frac{1}{3 } n \\log k \\biggr).\\ ] ] by ( [ eqvratio ] ) , we get @xmath472 . together with ( [ equkld ] ) and using ( [ eqfanokl ] )",
    ", we have @xmath473 with some constant @xmath474 for sufficiently small @xmath449 and sufficiently large @xmath0 . when @xmath0 is not sufficiently large but @xmath229 , the argument in section  [ secflower ] gives the desired lower bound at the order of @xmath475 .",
    "when @xmath476 , @xmath477 is still a valid lower bound .",
    "finally , let us combine ( [ eqlowers1 ] ) and ( [ eqlowers2 ] ) to get the desired in - probability lower bound in theorem  [ teosbmlower ] with @xmath478 . for any @xmath479 , by union bound ,",
    "we have @xmath480 taking @xmath481 on both sides , and using the fact @xmath482 , we have @xmath483 for any estimator @xmath266 . plugging the lower bounds ( [ eqlowers1 ] ) and ( [ eqlowers2 ] )",
    ", we obtain the desired result .",
    "a markov s inequality argument leads to the lower bound in expectation .",
    "we want to thank zongming ma for helpful discussion on the relation between graphon estimation and link prediction , and to thank the associate editor and the referee for their constructive comments and suggestions that lead to the improvement of the paper .",
    "edoardo  m airoldi , thiago  b costa , and stanley  h chan .",
    "stochastic blockmodel approximation of a graphon : theory and consistent estimation . in",
    "_ advances in neural information processing systems _ , pages 692700 , 2013 .",
    "peter bickel , david choi , xiangyu chang , and hai zhang .",
    "asymptotic normality of maximum likelihood and its variational approximation for stochastic blockmodels .",
    "_ the annals of statistics _ , 41 ( 4 ) : 19221943 , 2013 .",
    "matan gavish , boaz nadler , and ronald  r coifman .",
    "multiscale wavelets on trees , graphs and high dimensional data : theory and applications to semi supervised learning . in _ proceedings of the 27th international conference on machine learning ( icml-10 ) _ , pages 367374 , 2010 .",
    "mark  s handcock , adrian  e raftery , and jeremy  m tantrum .",
    "model - based clustering for social networks . _ journal of the royal statistical society : series a ( statistics in society ) _ , 170 ( 2 ) : 301354 , 2007 .",
    "haiyuan yu , pascal braun , muhammed  a yildirim , irma lemmens , kavitha venkatesan , julie sahalie , tomoko hirozane - kishikawa , fana gebreab , na  li , nicolas simonis , et  al .",
    "high - quality binary protein interaction map of the yeast interactome network .",
    "_ science _ , 322 ( 5898 ) : 104110 , 2008 .",
    "xue zhang , xiaojie wang , chengli zhao , dongyun yi , and zheng xie .",
    "degree - corrected stochastic block models and reliability in networks .",
    "_ physica a : statistical mechanics and its applications _ , 393 : 553559 , 2014 ."
  ],
  "abstract_text": [
    "<S> network analysis is becoming one of the most active research areas in statistics . </S>",
    "<S> significant advances have been made recently on developing theories , methodologies and algorithms for analyzing networks . </S>",
    "<S> however , there has been little fundamental study on optimal estimation . in this paper </S>",
    "<S> , we establish optimal rate of convergence for graphon estimation . for the stochastic block model with @xmath0 clusters , we show that the optimal rate under the mean squared error is @xmath1 . </S>",
    "<S> the minimax upper bound improves the existing results in literature through a technique of solving a quadratic equation . </S>",
    "<S> when @xmath2 , as the number of the cluster @xmath0 grows , the minimax rate grows slowly with only a logarithmic order @xmath3 . </S>",
    "<S> a key step to establish the lower bound is to construct a novel subset of the parameter space and then apply fano s lemma , from which we see a clear distinction of the nonparametric graphon estimation problem from classical nonparametric regression , due to the lack of identifiability of the order of nodes in exchangeable random graph models . as an immediate application , we consider nonparametric graphon estimation in a hlder class with smoothness @xmath4 . </S>",
    "<S> when the smoothness @xmath5 , the optimal rate of convergence is @xmath6 , independent of @xmath4 , while for @xmath7 , the rate is @xmath8 , which is , to our surprise , identical to the classical nonparametric rate .    ./style / arxiv - general.cfg    , </S>"
  ]
}