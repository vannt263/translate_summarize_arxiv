{
  "article_text": [
    "the multiple - descriptions ( md ) source coding set - up describes a communications system consisting of a centralized encoder and several decoders .",
    "the encoder transmits data through a number of noiseless links .",
    "each decoder is connected to the encoder via a subset of these links .",
    "the goal is for the encoder to compress an information source and transmit it to the decoders such that the source reconstruction at each decoder meets a specific fidelity criterion .",
    "there has been an extensive amount of effort to determine the optimal rate - distortion ( rd ) region for the general md set - up , however , even in the case of two - descriptions the optimal region is not known .",
    "the best known achievable rd region for the two - descriptions set - up is due to zhang and berger @xcite . in @xcite ,",
    "the encoder utilizes a base layer which is decoded by all receivers and a refinement layer which is decoded by individual receivers .",
    "the vkg scheme proposed in @xcite generalizes the base layer idea in @xcite to cases with more than two - descriptions . the combinatorial - message - sharing ( cms ) strategy @xcite expands the method in @xcite by considering a combinatorial number of base layer codebooks which are decoded in subsets of receivers . in @xcite ,",
    "a random binning scheme was introduced which results in gains over previous known coding strategies .",
    "the method in @xcite is only applicable to symmetric sources .",
    "finally , in @xcite the ideas in @xcite and @xcite were combined to form cms with binning .",
    "it was shown that cms with binning gives gains over previous coding strategies and strictly contains them .",
    "all of these coding schemes use random codes to construct codebooks ; in this paper we propose using linear codes instead .",
    "using structured codes in communications problems has traditionally been of interest due to their practicality in comparison with randomly generated codes .",
    "korner and marton @xcite observed that in some set - ups , application of structured codes may also yield gains in terms of achievable rate - distortions .",
    "specifically they show that in a particular 3-user distributed source coding problem , involving reconstruction of a sum of two bsss , using linear codes results in a larger achievable rd region .",
    "the phenomenon was also observed in channel coding problems .",
    "it was shown in the three user interference channel @xcite and the three user broadcast channel @xcite , that employing linear codes results in gains .",
    "intuitively , the main idea behind all of these linear coding schemes is that because of their structure , linear codes can compress and transmit sums of binary rvs more efficiently than random codes . based on these observations",
    "it is expected that utilizing linear codes is also advantageous in the md problems when more than 2 descriptions are transmitted .",
    "this turns out to be indeed the case as we illustrate in the next chapters .",
    "the rest of the paper is organized as follows : section ii is allocated to explaining the cms with binning scheme . in section iii , we prove linear codes give gains over previous schemes in two different examples .",
    "section iv contains a proof that the cms with binning scheme can be improved using random codes . in section",
    "v , we provide an achievable rd region for the md problem . section vi concludes the paper .",
    "here we explain the cms with binning scheme presented in @xcite for the @xmath0-descriptions problem .",
    "* base layer construction : * for each subset @xmath1 of @xmath2 $ ] , we construct @xmath3 codebooks @xmath4 $ ] . each codebook is generated based on the probability distribution @xmath5 , independent of other codebooks .",
    "the codebook has rate @xmath6 .",
    "this codebook is to be decoded if a decoder receives at least @xmath7 descriptions from the set @xmath1 . for each description in @xmath1 ,",
    "the encoder bins the codebook at a different rate .",
    "binning is done for each description independent of other descriptions .",
    "the binning rate of codebook @xmath8 for description @xmath9 is @xmath10 .",
    "this gives bin size @xmath11 . on description @xmath12",
    ", the encoder sends the bin number of the codeword to be transmitted from @xmath8 , this requires rate @xmath10 .",
    "* refinement layer construction : * for description @xmath9 we construct @xmath13 refinement layer codebooks , @xmath14 $ ] .",
    "each codebook is generated based on @xmath15 and has rate @xmath16 .",
    "the codebook is decoded if the decoder receives description @xmath9 along with at least @xmath17 other descriptions ( i.e. the codebook is an scec sent by encoder @xmath9 ) .",
    "the codebook is binned at rate @xmath18 .    * covering bounds : * since the codebooks are generated independently , typicality requires mutual covering bounds for all subsets of random variables .",
    "+ hence for all @xmath19,j\\in[1:|a|]\\}$ ] and @xmath20,n\\in[1:l]\\}$ ] we must have : @xmath21    * packing bounds : * for decoder @xmath22 , let @xmath23 be the indices of codebooks @xmath24 decoded at @xmath22 .",
    "also let @xmath25 be the indices @xmath26 of codebooks @xmath27 decoded at @xmath22 .",
    "let @xmath28 and @xmath29 partition @xmath30 . also let @xmath31 and @xmath32 partition @xmath33 .",
    "for all such sets , we have the following packing bounds :    @xmath34",
    "in this section we present two examples showing that linear codes attain points outside of previous known achievable rd regions .",
    "figure 2 depicts the three - descriptions problem . here",
    "@xmath35 and @xmath36 are independent bsss .",
    "distortion is measured at individual decoders ( i.e. decoders 1,2 and 3 ) using hamming distortion .",
    "we choose the distortion functions for decoders 12,13 and 23 such that in a ptp setting they achieve optimal rate - distortion by receiving two independent quantizations of @xmath35 and @xmath36 , where the independent quantizations are done using binary symmetric test channels with cross over probability @xmath37 $ ] .",
    "to construct such a distortion function we use the method in @xcite .",
    "let @xmath38 be the joint probability distribution of the source along with two quantizations @xmath39 and @xmath40 where @xmath41 and @xmath42 are @xmath43 ( i.e. with @xmath44 ) and independent of all other rvs .",
    "then the distortion function between the source @xmath45 and the reconstruction @xmath46 is defined as @xmath47 here @xmath48 is chosen such that @xmath49 .",
    "also @xmath50 is an arbitrary positive constant . with this distortion function , in a ptp setting",
    "if we construct a test channel using @xmath51 , it achieves rate - distortion at @xmath52 and @xmath53 .        in the above md problem",
    ", linear codes can achieve the following rate - distortions : @xmath54    here we propose a linear coding scheme that achieves the above rates .",
    "+ * encoding : * define @xmath55 .",
    "let @xmath56 be a family of linear codes which quantize a bss to hamming distortion @xmath57 for some @xmath58 .",
    "let @xmath59 be the generator matrices for these linear codes .",
    "let @xmath60 be the quantization of @xmath61 using @xmath56 ( i.e. @xmath62 ) . also define @xmath63 to be the quantization of @xmath64 using the same code .",
    "note that since @xmath56 is a linear code , @xmath65 .",
    "the first description carries the index of @xmath60 , the second description carries the index of @xmath63 and the third description sends the index for @xmath66 in @xmath56 . + * decoding : * the first and second decoder get the index of @xmath60 and @xmath63 respectively and hence satisfy their distortion constraints .",
    "decoder 3 reconstructs @xmath66 , and it is easy to show that @xmath67 .",
    "decoder 12 receives @xmath60 and @xmath63 and hence satisfies its distortion requirements .",
    "also decoders 13 and 23 can recover @xmath63 and @xmath60 by adding @xmath66 to @xmath60 and @xmath63 respectively .",
    "one may observe the main idea in the proof is that due to the linearity of the code , @xmath66 is in the codebook , hence it can be sent on the third description with the same rate as other descriptions .",
    "now we prove that cms with binning can not achieve the above rate - distortions .",
    "we do this by assuming such a rate - distortion vector is achievable and then arriving at a contradiction .",
    "the rate - distortions in theorem 1 are not achievable using the cms with binning scheme .",
    "figure 3 shows the codebooks present in cms with binning for three descriptions .",
    "+ * step 1 : * it is straightforward to check that @xmath68 , @xmath69 , @xmath70 , @xmath71 , @xmath72 , @xmath73 , @xmath74 and @xmath75 are 0 .",
    "the intuitive reason is that decoder 1 receives the first description at optimal ptp rate - distortion , hence the first description ca nt carry any indices which are not used in decoder 1 .",
    "note that this does not mean the codebooks relating to these binning rates are empty , we can only conclude that no bin indices relating to the above codebooks are sent through the corresponding descriptions . +",
    "* step 2 : * the random variables decoded at decoder 1 and decoder 2 are independent of each other , because decoder 12 is operating optimally in a ptp communications point of view , hence any correlation between descriptions 1 and 2 would be redundant and would contradict optimality . to show this we investigate a more general situation in lemma 1 in the appendix . from lemma 1 , even if the refinement layer is included , there is no common codebook decoded at decoders 1 and 2 .",
    "hence in our situation @xmath76 . also because of the markov chain @xmath77 is not used in reconstructing the source in decoder 12 , so it can be eliminated without any loss .",
    "@xmath78 is only sent through description 3 and is only used in decoders 13 and 23 ( by the markov chain ) , so it can be combined with @xmath79 and we only keep the latter . also note that @xmath80 is not sent through any description and is only used in decoder 13 , so it can be pushed into @xmath81 without any penalty ( i.e. we replace @xmath82 with @xmath83 ) .",
    "we can eliminate @xmath84 in the same manner . + * step 3 : * note that decoder 23 is operating at ptp rate - distortion .",
    "also @xmath81 is carried by description 3 through @xmath85 but not used that decoder .",
    "so by the same arguments as before @xmath86 .",
    "using a similar argument we deduce @xmath87 . + * step 4 : * we proceed by showing that @xmath81 and @xmath88 are empty .",
    "so far it was shown that these codebooks are not transmitted through any description , however we have not shown they are empty ( i.e. they are not decoded anywhere by using their correlation with other rvs ) . intuitively since these random codewords can only be decoded in a decoder through other random variables",
    ", they must not be giving any extra information about the source . to prove the redundancy of these codebooks , consider the following packing bounds for decoders 1 , 23 and 13 : @xmath89 we add the above inequalities and subtract the mutual covering bound on all rvs .",
    "after some simplification we get @xmath90 .",
    "this imposes the markov chain @xmath91 . hence @xmath82 is not necessary for reconstructing the source at decoder 13 , which means @xmath81",
    "can be eliminated without any loss .",
    "same argument works for eliminating @xmath88 . + * step 5 : * in this step we show that @xmath92 . to see this assume @xmath93",
    "note that @xmath94 is decoded at decoder 3 , so even if description 1 did not carry the index of the codeword in @xmath95 , decoder 13 could decode @xmath94 using the third description and calculate the index . hence @xmath96 could be set to 0 without any added distortion at decoder 13 .",
    "this contradicts optimality at decoder 13 .",
    "now since @xmath97 and @xmath98 are not carried by any descriptions , we can use the same kind of argument as in the previous steps , by adding the packing bounds at decoders 1,3 and 13 and subtracting the mutual covering bound on all variables , we get that @xmath99 . + * step 6 : * we are left with four codebooks , @xmath100 and @xmath79 . note that since decoder 1 is only decoding @xmath101 we must have @xmath102 .",
    "this is deduced from the packing bound in decoder 1 : @xmath103 but @xmath104 so they are equal .",
    "the same argument gives @xmath105 .",
    "also @xmath106 and @xmath107 .",
    "we have the following packing bound at decoder 13 : @xmath108 where we have used @xmath109 from optimality at decoder 13 . adding inequality with the mutual covering bound on all variables we get : @xmath110 where in the last step we have used @xmath111 .",
    "note that @xmath112 , so the rhs in the last equality is greater than or equal @xmath113 .",
    "equality requires that @xmath114 . by the same arguments we get @xmath115 .",
    "now we use the second lemma in the appendix .",
    "let @xmath116 , @xmath117 , @xmath118 and @xmath119 in the lemma . the conditions of the lemma are indeed true , because @xmath120 , hence we ca nt have functions @xmath121 and @xmath122 which are equal with probability 1 . using the lemma",
    ", the following markov chain holds @xmath123 .",
    "recall in we used the mutual covering bound on all variables and since we proved all of the inequalities used in that part need to be equalities , the mutual covering bound is tight . also from optimality of decoder 23",
    "we get that the covering bound on @xmath124 and @xmath125 is tight .",
    "subtracting these two equalities we get @xmath126 , so we must have @xmath127 . also from the definition of @xmath128",
    "we must have @xmath129 , so @xmath130 .",
    "then we have : @xmath131 where the second equality holds since both sides are equal to @xmath113 since they give reconstructions of @xmath35 at decoders 1 and 13 .",
    "so we get @xmath132 . by lemma 2",
    ", @xmath133 holds ( take @xmath134 ) . in this case",
    ", decoder 3 can reconstruct both @xmath35 and @xmath36 with hamming distortion @xmath135 this contradicts @xmath136 . to get the reconstructions at decoder 3 ,",
    "let @xmath137 be the reconstruction of @xmath36 at decoder 13 .",
    "we have : @xmath138 so there is at least one @xmath139 such that @xmath140 .",
    "let @xmath141 be the reconstruction of z using @xmath142 and @xmath125 .",
    "by the same argument we can find a reconstruction of x.      so far we proved linear codes outperform previous random coding schemes in the three - descriptions problem .",
    "the gains are only presenting themselves due to the fact that linear codes can compress sums of binary rvs more efficiently , these are the same gains as the ones in other three - terminal communications problems .",
    "now we proceed to explain our second example .",
    "the example involves a four - descriptions problem .",
    "we believe the gains in this example point out to a new phenomenon which arises when using linear codes .",
    "the set - up is depicted in figure 4 . here",
    "@xmath35 and @xmath36 are bsss which are related to each other through a bsc@xmath143 ( i.e. @xmath144 where @xmath145 is @xmath43 and independent of @xmath35 and @xmath36 ) .",
    "we are interested in the operating point where decoder 1 reconstructs x with hamming distortion @xmath135 , decoder 4 reconstructs @xmath36 with the same distortion , the rest of the reconstructions are lossless as shown in the figure .        for the above distortions , linear codes achieve the following rates : @xmath146    we proceed by presenting a linear coding scheme which achieves the above rates and distortions .",
    "let @xmath56 and @xmath59 be defined as in the previous example .",
    "the only difference is here we assume that @xmath56 is both a good channel code for a bsc@xmath143 and a good source code for quantizing a bss to hamming distortion @xmath147 where @xmath58 .",
    "the existence of such codes can be proved using a simple shannon type argument . +",
    "* encoding : * the encooder quantizes @xmath61 using @xmath56 to @xmath148 and sends the index on description 1",
    ". it also quantizes @xmath64 using the same code to @xmath149 and sends the index on description 4 .",
    "the quantization noise at decoder 1 , @xmath150 , is sent on description 2 , also the quantization noise at decoder 4 is sent on description 3 .",
    "clearly the rates are as stated in the theorem . + * decoding : * decoder 1 and 4 are receiving their desired quantizations .",
    "decoder 12 adds the quantization @xmath151 of @xmath61 to its quantization noise to recover @xmath61 noiselessly .",
    "decoder 34 recovers @xmath64 in the same manner .",
    "decoder 23 gets the two quantization noises .",
    "it then adds the two to get @xmath152 , treating @xmath153 as noise it can decode @xmath154 since the code is a good channel code for @xmath155 and hence it can then reconstruct @xmath156 noiselessly ( the careful reader might notice with rate exactly @xmath113 the code can only be a good channel code for channels with crossover probability strictly less than @xmath135 , while there is a suitable fix to this issue , one can totally bypass it by assuming @xmath153 is @xmath157 for some small positive @xmath158 ) .",
    "note the linearity of the codebook , along with it being a good channel code and a good source code are crucial for achieving this rd vector .",
    "now we prove that cms with binning does not achieve the rates and distortions in the previous theorem .",
    "cms with binning does not achieve the rd vector in theorem 3 .",
    "again we prove the theorem by assuming the rd vector is achievable and arriving at a contradiction .",
    "the cms scheme uses 39 codebooks for the four - descriptions problem , however since in the special case which we are considering a large number of decoders are not present , the codebooks can be eliminated in a straightforward fashion + * step 1 : * any codebook which is not decoded at decoders 1,4,12,23 and 34 is redundant .",
    "for example there are no decoders receiving more than two descriptions , so any codebook which is decoded only when three or more descriptions are available is redundant .",
    "+ * step 2 : * by the same kind of argument as in lemma 1 , we can show there is nothing common decoded at decoders 12 and 34 . also by the same arguments as in step 2 of the last part , @xmath80 and @xmath159 can be eliminated . + * step 3 : * note since decoders 2 and 3 are not present , @xmath160 and @xmath161 are the same as @xmath84 and @xmath79 , so we only keep the two latter codebooks .",
    "+ * step 4 : * by the same arguments as in step 3 of the last proof @xmath78 and @xmath162 are not sent through any description . by the same type of calculations as in step 4 of the last part",
    ", they can be eliminated . + * step 5 : * the 8 remaining codebooks are @xmath101 , @xmath84 , @xmath79 , @xmath163 , @xmath164 , @xmath77 , @xmath165 and @xmath166 . in this step",
    "we eliminate the last four codebooks .",
    "we have the following packing bounds in decoders 1 and 12 : @xmath167 we add these bounds and subtract the mutual covering bound on @xmath168 and @xmath169 .",
    "after some simplification and using the fact that decoder 12 can reconstruct @xmath35 , we get that @xmath170 . also @xmath171 to see this , consider decoders 23 and 34 , if we consider them as a joint decoder , they are performing at ptp rate - distortion , but are not decoding @xmath77 , so description 2 ca nt carry this codebook , hence the codebook is not sent through any descriptions and using the same arguments as in the previous proof it can be eliminated . now after eliminating @xmath77 it is simple to eliminate @xmath164 .",
    "consider the following packing bounds at decoders 1 and 23 : @xmath172 add the two packing bounds and subtract the mutual covering bound on @xmath173 and @xmath174 to get @xmath99 ( here we use the fact that having all the variables decoded at decoders 23 and 12 we are able to reconstruct @xmath45 so @xmath175 ) .",
    "also using the same bounds in decoders 4 and 23 , we can show @xmath176 . + * step 6 : * by an argument like the one in lemma 1 we can show that considering decoders 12 and 34 we must have @xmath177 , also at decoder 12 we must have @xmath178 and at decoder 34 we get @xmath179 .",
    "taking @xmath180 in lemma 3 , the long markov chain @xmath181 must hold .",
    "we get an inner bound for @xmath182 at decoder 23 : @xmath183 where the minimum is taken over all @xmath184 for which the long markov chain is satisfied and @xmath185 give a lossless reconstruction of @xmath153 .",
    "this resembles the distributed source coding problem in @xcite . by the converse in that paper @xmath186 .",
    "so the rd vector ca nt be achieved using random codes .",
    "in this section we illustrate that cms with binning can be improved by including additional randomly generated codebooks .",
    "for example the scheme does not include a codebook which is decoded when either description 1 or both descriptions 2 and 3 are received .",
    "in the situation depicted in figure 5 , the addition of such a codebook results in a larger achievable rd region . here",
    "decoders 1 , 23 and 123 have hamming distortion constraints . the distortion constraint in decoder 2",
    "will be defined later .",
    "if decoder 2 is omitted , the example would become equivalent to the two descriptions problem discussed in @xcite by combining descriptions 2 and 3 into one description . in that paper",
    ", it was proved that the presence of a codebook decoded at all decoders would result in gains in achievable rd .",
    "let @xmath187 be the set of optimizing distributions in the zhang - berger rd region in @xcite , for a given @xmath188 , @xmath189 and @xmath190 .",
    "@xmath191 is the rv relating to the common codebook in that problem .",
    "define @xmath192 , where the minimum is taken over all @xmath193 .",
    "let @xmath194 be an rv such that : @xmath195 define $ p_{\\hat{x}_0,x}$ based on $ p_{\\hat{x}_0,x_0}$ and the markov chain $ \\hat{x}_0\\leftrightarrow x_0\\leftrightarrow x$. the distortion function at decoder 2 is defined such that $ p_{\\hat{x}_0,x}$ is an optimizing distribution for the distortion function in a ptp setting .",
    "we are interested in achieving the following rd vector : \\begin{figure}[!t ] \\centering \\includegraphics{fig5 } % where an .eps filename suffix will be assumed under latex ,   % and a .pdf suffix will be assumed for pdflatex ; or what has been declared % via \\declaregraphicsextensions .",
    "\\caption{three descriptions exmaple for cms with binning } \\label{fig4 } \\end{figure } \\begin{align } & r_1=r , r_2=i(\\hat{x}_0;x ) , r_3=r - i(\\hat{x}_0;x)\\\\ & d_1=d_{23}=d , d_2=d , d_{123}=d_0 .",
    "\\nonumber \\label{rd } \\end{align } where $ d = e_{p_{\\hat{x}_0,x}}\\big(d_{12}(\\hat{x}_0,x)\\big)$. \\theorem the above rd vector is achievable using the cms with binning scheme with the additional codebook included .",
    "\\begin{ieeeproof }   define $ c\\rq{}$ as the codebook decoded only at decoders $ 1 $ , $ 23 $ and $ 123$. let the underlying random variable for $ c\\rq{}$ be $ u\\rq{}$. define $ n_p = x_0+\\hat{x}_0 $ where the addition is modulo $ |\\mathcal{x}_0|$. the above rd vector can be achieved by taking $ u_1=x_1 $ , $ u_2=x_0+n_p$ , $ u\\rq{}=(x_0,x_2)$ , where the distribution on $ x_1 $ , $ x_2 $ and $ x_0 $ is $ p$.   \\end{ieeeproof } \\theorem the rd vector in ( 1 ) is not achievable using cms with binning .",
    "\\begin{ieeeproof } due to space limitations we only provide a summary of the proof .",
    "the common codebooks between decodes 1 and 23 are $ c_{12,1}$ , $ c_{13,1}$ and $ c_{123,1}$. furthermore since decoder 3 is not present , $ c_{123,1}$ is the same as $ c_{12,1}$ and can be eliminated .",
    "we conclude that the common rv must either be sent through $ c_{12,1}$ or $ c_{13,1}$. since decoder 2 is operating at optimal ptp rate - distortion , descriptions 2 and 3 can\\rq{}t time - share in transmitting $ x_0 $ on $ c_{12,1}$ and $ c_{13,1}$. let $ r_0 $ be the rate of the common component then by construction $ r_0\\geq i(x , x_0)$. so $ x_0 $ can\\rq{}t be transmitted on either of $ c_{12,1}$ and   $ c_{13,1}$ , which is a contradiction .",
    "% based on the structure of the problem , only codebooks $ c_{12,1 } , c_1 , c_2,c_3 , c_{23,2}$ are non - redundant in the coding scheme .",
    "since $ x_0 $ is decoded both at decoders 1 and 23 it must be carried by $ c_{12,1}$. this is not possible since decoder 2 can only receive a distorted version of $ x_0 $ at ptp rd .",
    "\\end{ieeeproof } \\section{linear coding achievable region } in this section we provide an inner bound to the achievable rd region using linear codes .",
    "\\theorem rd vectors satisfying the following bounds are achievable using linear codes .",
    "let $ v=\\{v_{(a , k)},(a , k)\\in\\mathcal{a}\\}$ and $ u=\\{u_{(k , n)},(k , n)\\in k\\}$ \\begin{align * } & h(v_\\mathcal{a},u_k|x)\\geq   \\!\\!\\ !   \\sum_{(a , j)\\in       \\mathcal{a } } {   \\!\\!\\!\\!\\!\\ !    ( q-\\rho\\rq{}_{a , j }   \\ !   -    \\",
    "!    r_{a , j})}+      \\!\\!\\!\\!\\!\\ !",
    "\\sum_{(k , n)\\in k } {     \\!\\!\\!\\!\\!\\ !     ( q-\\rho\\rq{}_{k , n }    \\ !     -     \\ !",
    "r_{k , n})}\\\\ \\\\&h(v_{\\mathcal{a}_1},u_{k_1}|v_{\\mathcal{a}_2},u_{k_2})\\leq \\!\\!\\!\\!\\ !",
    "\\sum_{(k , n)\\in k_1}{\\!\\!\\!\\!(q-\\rho\\rq{}_{k , n } +   \\rho_{k , n}-      r_{k , n})}\\\\ & \\qquad + \\sum_{(a , j)\\in \\mathcal{a}_1 } {   \\!\\!\\!\\ !   ( q-\\rho\\rq{}_{a , j } + ( \\sum_{i\\in\\underline{s}}\\rho_{a , j , i})-r_{a , j})})\\\\ & \\rho\\rq{}_{a , j}\\leq q - h(v_{a , j})\\\\ & \\rho\\rq{}_{k , n}\\leq q - h_{u_{k , n}}. \\end{align * } here $ q$ is the maximum of the cardinality of all rv\\rq{}s involved in the optimization . also $ \\underline{s}$ , $ \\mathcal{a}_{\\underline{s}}$ , $ k_{\\underline{s}}$ , $ \\mathcal{a}_1 $ , $ \\mathcal{a}_2 $ , $ k_1 $ and $ k_2 $ are defined in previous sections .     furthermore if the encoder wants to transmit the sum of two random variables $ y , z\\in \\{u_{a , j},v_{k , n}\\}$ , the following covering bound must hold :    \\begin{align * } \\max\\{r_y , r_z\\}\\geq q - h(y+z ) \\end{align * } if decoder $ \\underline{s}$ is to reconstruct $ y+z$ , then we have three cases:\\\\ case 1 : decoder $ \\underline{s}$ reconstructs both $ y$ and $ z$. in this case , in the packing bound corresponding to this decoder , $ \\rho_{y}$ is replaced with $ \\rho_{y}+t\\rho_{y+z}$ and $ \\rho_{z}$ is replaced with $ \\rho_{z}+(1-t)\\rho_{y+z}$ , where $ t\\in [ 0,1]$ and $ \\rho_{y+z}$ is the rate with which the codebook for $ y+z$ is binned .",
    "\\\\case 2 : the decoder only reconstructs y ( or z ) , in which case reconstructing $ y+z$ is the same as reconstructing $ ( y , z)$. the packing bounds are written as if $ z$ was sent to the decoder with binning rate $ \\rho_{y+z}$.   \\\\case 3 : the decoder does not reconstruct $ y$ or $ z$. in this case the packing bound is deduced by replacing $ u_\\mathcal{a}$ with $ ( y+z , u_\\mathcal{a})$.   \\remark if $ y+z$ is taken to be trivial , the above bound reduces to the cms with binning achievable region .",
    "\\remark   $ q$ , $ \\rho\\rq{}_{a , j}$ and $ \\rho\\rq{}_{k , n}$ are eliminated after the fourier - motzkin elimination and do not play a role in determining the achievable region . \\remark the above rate region can be improved upon by adding the extra codebooks mentioned in the last section , and also by allowing reconstruction of multi - variate summations of the random variables .",
    "% an example of a floating figure using the graphicx package .",
    "% note that \\label must occur after ( or within ) \\caption .",
    "% for figures , \\caption should occur after the \\includegraphics .",
    "% note that ieeetran v1.7 and later has special internal code that % is designed to preserve the operation of \\label within \\caption % even when the captionsoff option is in effect .",
    "however , because % of issues like this , it may be the safest practice to put all your % \\label just after \\caption rather than within \\caption{}. % % reminder : the \" draftcls \" or \" draftclsnofoot \" , not \" draft \" , class % option should be used if it is desired that the figures are to be % displayed while in draft mode .",
    "%       % an example of a double column floating figure using two subfigures .",
    "% ( the subfig.sty package must be loaded for this to work . ) % the subfigure \\label commands are set within each subfloat command , the % \\label for the overall figure must come after \\caption .",
    "% \\hfil must be used as a separator to get equal spacing .",
    "% the subfigure.sty package works much the same way , except \\subfigure is % used instead of \\subfloat .",
    "% % \\begin{figure*}[!t ] % \\centerline{\\subfloat[case i]\\includegraphics[width=2.5in]{subfigcase1}% % \\label{fig_first_case } } % \\hfil % \\subfloat[case ii]{\\includegraphics[width=2.5in]{subfigcase2}% % \\label{fig_second_case } } } % \\caption{simulation results } % \\label{fig_sim } % \\end{figure * } % % note that often ieee papers with subfigures do not employ subfigure % captions ( using the optional argument to \\subfloat ) , but instead will % reference / describe all of them ( a ) , ( b ) , etc .",
    ", within the main caption .",
    "% an example of a floating table .",
    "note that , for ieee style tables , the   % \\caption command should come before the table .",
    "table text will default to % \\footnotesize as ieee normally uses this smaller font for tables .",
    "% the \\label must come after \\caption as always .",
    "% % \\begin{table}[!t ] % % increase table row spacing , adjust to taste % \\renewcommand{\\arraystretch}{1.3 } % if using array.sty , it might be a good idea to tweak the value of % \\extrarowheight as needed to properly center the text within the cells %",
    "\\caption{an example of a table } % \\label{table_example } % \\centering % % some packages , such as mdw tools , offer better commands for making tables % % than the plain latex2e tabular which is used here .",
    "% \\begin{tabular}{|c||c| } % \\hline % one & two\\\\ % \\hline % three & four\\\\ % \\hline % \\end{tabular } % \\end{table }     % note that ieee does not put floats in the very first column - or typically % anywhere on the first page for that matter .",
    "also , in - text middle ( \" here \" ) % positioning is not used .",
    "most ieee journals / conferences use top floats % exclusively .",
    "note that , latex2e , unlike ieee journals / conferences , places % footnotes above bottom floats .",
    "this can be corrected via the \\fnbelowfloat % command of the stfloats package .",
    "\\section{conclusion } a new coding scheme for the general md problem was proposed .",
    "it was shown that the scheme outperforms previous known random coding schemes .",
    "an example was given illustrating that previous random coding schemes can also be improved by including additional randomly generated codebooks .",
    "% conference papers do not normally have an appendix % \\appendix % consider the set - up in figure 1 , assume $ r_1+r_2=rd_{d_{12}}(d_{12})$ where $ d_{12}$ is the distortion function at decoder 12 , $ rd_{d_{12}}$ is the ptp rate - distortion function and $ d_{12}$ is distortion at that decoder .",
    "also assume $ r_i = rd_{d_i}(d_i)$. in this situation we have the following lemma : % \\lemma    in cms with binning , with the redundant refinement layer included , at the above rate - distortion vector , we must have $ u_1\\perp u_2 $ and $ c_{12,1}=\\phi$. furthermore $ ( u_{2,1},u_{2,2},v_{12,2})\\leftrightarrow u_1,u_2 \\leftrightarrow x$. % \\begin{ieeeproof } note , in this situation $ c_{2,1},c_{2,2}$ and $ c_{12,2}$",
    "are only decoded at decoder 12 , we define a random vector $ u_0=(u_{2,1},u_{2,2},v_{12,2})$ , this is the random variable which is only decoded at decoder 12 .",
    "we have the following packing bounds : % \\begin{align } % & h(v_{12,1},u_1)\\leq h(v_{12,1 } ) \\ ! + \\ !",
    "h(u_1 ) \\ ! + \\ !",
    "\\rho_{12,1,1 } \\",
    "\\rho_1 \\ ! - \\ !",
    "r_{12,1 } \\ ! - \\ !",
    "r_1\\\\ % & h(v_{12,1},u_2)\\leq h(v_{12,1 } ) \\ ! + \\ !",
    "h(u_2 ) \\ !",
    "\\rho_{12,1,2 } \\ !",
    "\\rho_2 \\ ! - \\ !",
    "r_{12,1 } \\ ! - \\",
    "! r_2\\\\ % & h(u_0|v_{12,1},u_1,u_2)\\leq h(u_0 ) \\ ! + \\",
    "! \\rho_{0,1 \\ ! } + \\ ! \\rho_{0,2 } \\ ! - \\ !",
    "% \\end{align }    % also the covering bound : % \\begin{align } % & h(u_0,u_1,u_2,v_{12,1}|x)\\geq h(u_0)+h(u_1)+h(u_2)\\nonumber\\\\ % & \\qquad \\qquad \\qquad+h(v_{12,1})-r_0-r_1-r_2-r_{12,1 } % \\end{align } % now we add inequalities ( 1 - 3 ) and subtract the last inequality , we get : % \\begin{equation * } % i(u_1;u_2|v_{12,1})+r_{12,1}\\leq 0 % \\ ] ]    consider the set - up in figure 1 , assume @xmath196 where @xmath197 is the distortion function at decoder 12 , @xmath198 is the ptp rate - distortion function and @xmath199 is distortion at that decoder . also assume @xmath200 .",
    "in this situation we have the following lemma : in cms with binning , with the redundant refinement layer included , at the above rate - distortion vector , we must have @xmath201 and @xmath202 . furthermore @xmath203 .",
    "note , in this situation @xmath204 and @xmath77 are only decoded at decoder 12 , we define a random vector @xmath205 , this is the random variable which is only decoded at decoder 12 .",
    "we have the following packing bounds : @xmath206    also the covering bound : @xmath207 now we add inequalities ( 1 - 3 ) and subtract the last inequality , we get : @xmath208 since both elements in the lhs are positive , both must be 0 .",
    "this means @xmath202 , hence @xmath209 is constant and @xmath201 .",
    "note that in this case some calculation reveals : @xmath210 so we must have @xmath211 , which gives the desired markov chain .",
    "let a , b , c and d be rvs such that @xmath212 and @xmath213 , and also assume there is no @xmath214 for which given @xmath215 there are non - constant functions @xmath216 and @xmath217 with @xmath218 with probability 1 .",
    "then @xmath219 .",
    "this lemma is a generalization of the one in @xcite .",
    "we need to show that @xmath220 for any @xmath221 .",
    "note since functions @xmath222 and @xmath223 do not exist , it is straightforward to show that there is a finite sequence of pairs @xmath224 such that @xmath225 and @xmath226 with the property that either @xmath227 or @xmath228 and that @xmath229 . then from the first markov chain if @xmath228 , we have @xmath230 , also if @xmath231 the second markov chain gives this result .",
    "so @xmath232 is constant on all of the sequence particularly @xmath220 .",
    "we only need to show that @xmath236 , the rest of the implications of the long markov chain are either direct results of the three short markov chains or follow by symmetry . for arbitrary @xmath237",
    "we have : @xmath238    1 z. zhang , t. berger , new results in binary multiple - descriptions , information theory , ieee transactions on , vol.33 , no.4 , pp.502,521 , jul 1987 r. venkataramani , g. kramer , and v.k .",
    "goyal , multiple description coding with many channels , ieee transactions on information theory , vol .",
    "9 , pp . 21062114 , 2003 . k. viswanatha , e. akyol , and k. rose , combinatorial message sharing for a refined multiple - descriptions achievable region , in ieee international symp .",
    "on information theory .",
    "ieee , pp .",
    "13121316 . ,",
    "pradhan , r. puri , and k. ramchandran , n - channel symmetric multiple descriptions - part i:(n , k ) source - channel erasure codes , ieee transactions on information theory , vol .",
    "1 , pp . 4761 , 2004 .",
    "e. akyol , k. viswanatha , k. rose , combinatorial message sharing and random binning for multiple description coding , information theory proceedings ( isit ) , 2012 ieee international symposium on , vol .",
    "pp.1371,1375 , 1 - 6 july 2012 .",
    "j. korner and k. marton , how to encode the modulo - two sum of binary sources , ieee trans .",
    "theory , vol .",
    "2 , pp . 219221 , 1979 .",
    "a. jafarian , s. vishwanath , gaussian interference networks : lattice alignment , ieee inf .",
    "workshop , january 2010 a. padakandla , s.s .",
    "pradhan , achievable rate region for three user discrete broadcast channel based on coset codes , information theory proceedings ( isit ) , 2013 ieee international symposium on , vol .",
    ", no . , pp.1277,1281 , 7 - 12 july 2013 s.s .",
    "pradhan , j. chou , k. ramchandran , duality between source coding and channel coding and its extension to the side information case , information theory , ieee transactions on , vol.49 , no.5 , pp.1181,1203 , may 2003 a.b .",
    "wagner , b.g .",
    "kelly and y. altu , `` distributed rate - distortion with common components , '' information theory , ieee transactions on , vol.57 , no.7 , pp.4035 - 4057 , july 2011 f. shirani , s.s .",
    "pradhan , an achievable rate - distortion region for the multiple descriptions problem , available at @xmath239"
  ],
  "abstract_text": [
    "<S> a multiple - descriptions ( md ) coding strategy is proposed and an inner bound to the achievable rate - distortion region is derived . </S>",
    "<S> the scheme utilizes linear codes . </S>",
    "<S> it is shown in two different md set - ups that the linear coding scheme achieves a larger rate - distortion region than previously known random coding strategies . </S>",
    "<S> furthermore , it is shown via an example that the best known random coding scheme for the set - up can be improved by including additional randomly generated codebooks . </S>"
  ]
}