{
  "article_text": [
    "most analyses of learning algorithms assume that the algorithm starts learning from scratch when presented with a new dataset . however , in real life , it is often the case that we will use the same algorithm on many different tasks , and that information should be transferred from one task to another .",
    "for example , a key problem in pattern recognition is to learn a dictionary of features helpful for image classification : it makes perfectly sense to assume that features learnt to classify dogs against other animals can be re - used to recognize cats .",
    "this idea is at the core of _ transfer learning _ , see  @xcite and references therein .",
    "the setting in which the tasks are presented simultaneously is often referred to as _ learning - to - learn _",
    "@xcite , whereas when the tasks are presented sequentially , the term _ lifelong learning _ is often used  @xcite . in either case",
    ", a huge improvement over `` learning in isolation '' can be expected , especially when the sample size per task is relatively small .",
    "we will use the above terminologies in the paper .",
    "although a substantial amount of work has been done on the theoretical study of learning - to - learn @xcite , up to our knowledge there is no analysis of the statistical performance of lifelong learning algorithms .",
    "@xcite studied the convergence of certain optimization algorithms for lifelong learning .",
    "however , no statistical guarantees are provided .",
    "furthermore , in all the aforementioned works , the authors propose a technique for transfer learning which constrains the within - task algorithm to be of a certain kind , e.g.  regularized empirical risk minimization .",
    "the main goal of this paper is to show that it is possible to perform a theoretical analysis of lifelong learning with minimal assumptions on the form of the within - task algorithm .",
    "given a learner with her / his own favourite algorithm(s ) for learning within tasks , we propose a meta - algorithm for transferring information from one task to the next .",
    "the algorithm maintains a prior distribution on the set of representations , which is updated after the encounter of each new task using the exponentially weighted aggregation ( ewa ) procedure , hence we call it",
    "_ ewa for lifelong learning _ or ewa - ll .    a standard way to provide theoretical guarantees for online algorithms are regret bounds , which measure the discrepancy between the prediction error of the forecaster and the error of an ideal predictor .",
    "we prove that , as long as the within - task algorithms have good statistical properties , ewa - ll inherits these properties . specifically in theorem",
    "[ thm : online : w : online ] we present regret bounds for ewa - ll , in which the regret bounds for the within - tasks algorithms are combined into a regret bound for the meta - algorithm",
    ".    we also show , using an online - to - batch analysis , that it is possible to derive a strategy for learning - to - learn , and provide risk bounds for this strategy .",
    "the bounds are generally in the order of @xmath3 , where @xmath4 is the number of tasks and @xmath2 is the sample size per task .",
    "moreover , we derive in some specific situations rates in @xmath5 .",
    "these rates are novel up to our knowledge and justify the use of transfer learning with very small sample sizes @xmath2 .",
    "the paper is organized as follows . in section  [ notations ]",
    "we introduce the lifelong learning problem . in section  [ ewa - ll ]",
    "we present the ewa - ll algorithm and provide a bound on its expected regret .",
    "this bound is very general , but might be uneasy to understand at first sight .",
    "so , in section  [ applications ] we present more explicit versions of our bound in two classical examples : finite set of predictors and dictionary learning .",
    "we also provide a short simulation study for dictionary learning . at this point",
    ", we hope that the reader will have a clear overview of the problem under study .",
    "the rest of the paper is devoted to theoretical refinements : in online learning , uniform bounds are the norm rather than bounds in expectations  @xcite . in section  [ uniform ]",
    "we establish such bounds for ewa - ll .",
    "section  [ online - to - batch ] provides an online - to - batch analysis that allows one to use a modification of ewa - ll for learning - to - learn .",
    "the supplementary material include proofs ( appendix  [ proofs ] ) , improvements for dictionary learning ( appendix  [ appendix : improvement ] ) and extended results ( appendix  [ appendix - bwo ] ) .",
    "in this section , we introduce our notation and present the lifelong learning problem .",
    "let @xmath6 and @xmath7 be some sets .",
    "a predictor is a function @xmath8 , where @xmath9 for regression and @xmath10 for binary classification .",
    "the loss of a predictor @xmath11 on a pair @xmath12 is a real number denoted by @xmath13 .",
    "as mentioned above , we want to transfer the information ( a common data representation ) gained from the previous tasks to a new one .",
    "formally , we let @xmath14 be a set and prescribe a set @xmath15 of feature maps ( also called _ representations _ ) @xmath16 , and a set @xmath17 of functions @xmath18",
    ". we shall design an algorithm that is useful when there is a function @xmath19 , common to all the tasks , and task - specific functions @xmath20 such that @xmath21 is a good predictor for task @xmath22 , in the sense that the corresponding prediction error ( see below ) is small .",
    "we are now ready to describe the learning problem .",
    "we assume that tasks are dealt with sequentially .",
    "furthermore , we assume that each task dataset is itself revealed sequentially and refer to this setting as _ online - within - online _ lifelong learning .",
    "specifically , at each time step @xmath23 , the learner is challenged with a task , corresponding to a dataset @xmath24 where @xmath25 .",
    "the dataset @xmath26 is itself revealed sequentially , that is , at each inner step @xmath27 :    * the object @xmath28 is revealed , * the learner has to predict @xmath29 , let @xmath30 denote the prediction , * the label @xmath29 is revealed , and the learner incurs the loss @xmath31 .",
    "the task @xmath22 ends at time @xmath32 , at which point the prediction error is @xmath33 this process is repeated for each task @xmath22 , so that at the end of all the tasks , the average error is @xmath34 ideally , if for a given representation @xmath35 , the best predictor @xmath36 for task @xmath22 was known in advance , then an ideal learner using @xmath37 for prediction would incur the error @xmath38 hence , we define the within - task - regret of the representation @xmath35 on task @xmath22 as the difference between the prediction error and the smallest prediction error , @xmath39 the above expression is slightly different from the usual notion of regret @xcite , which does not contain the factor @xmath40 .",
    "this normalization is important in that it allows us to give equal weigths to different tasks .",
    "note that an oracle who would have known the best common representation @xmath35 for all tasks in advance would have only suffered , on the entire sequence of datasets , the error @xmath41    we are now ready to state our principal objective : we wish to design a procedure ( meta - algorithm ) that , at the beginning of each task @xmath22 , produces a function @xmath42 so that , within each task , the learner can use its own favorite online learning algorithm to solve task @xmath22 on the sequence @xmath43 .",
    "we wish to control the _ compound regret _ of our procedure @xmath44 which may succinctly be written as @xmath45 .",
    "this objective is accomplished in section [ ewa - ll ] under the assumption that a regret bound for the within - task - algorithm is available .",
    "we end this section with two examples included in the framework .",
    "[ dictionary learning ] [ exm - dic ] set @xmath46 , and call @xmath47 a _ dictionary _ , where each @xmath48 is a real - valued function on @xmath49 .",
    "furthermore choose @xmath50 to be a set of linear functions on @xmath51 , so that , for each task @xmath22 @xmath52 in practice depending on the value of @xmath53 , we can use least square estimators or lasso to learn @xmath54 . in  @xcite , the authors consider @xmath55 and @xmath56 for some @xmath57 matrix @xmath58 , and the goal is to learn jointly the predictors @xmath54 and the dictionary @xmath58 .",
    "[ finite set @xmath15 ] [ exm - rel ] we choose @xmath60 and @xmath50 any set .",
    "while this example is interesting in its own right , it is also instrumental in studying the continuous case via a suitable discretization process .",
    "a similar choice has been considered by @xcite in the multitask setting , in which the goal is to bound the average error on a prescribed set of tasks .",
    "we notice that a slightly different learning setting is obtained when each dataset @xmath61 is given all at once .",
    "we refer to this as _ batch - within - online _",
    "lifelong learning ; this setting is briefly considered in appendix  [ appendix - bwo ] . on the other hand",
    "when all datasets are revealed all at once , we are in the well - known setting of _ learning - to - learn _ @xcite . in section [ online - to - batch ] , we explain how our lifelong learning analysis can be adapted to this setting .",
    "data : :    a sequence of datasets +    @xmath62 ,    @xmath63 . associated with different learning tasks ;    the points within each dataset are also given sequentially .",
    "input : :    a prior @xmath64 , a learning parameter @xmath65    and a learning algorithm for each task @xmath22 which , for any    representation @xmath35 returns a sequence of predictions    @xmath66 and suffers a loss    @xmath67 loop : :    for @xmath68    +    i ; ;      draw @xmath69 .",
    "ii ; ;      run the within - task learning algorithm on      @xmath70 and suffer loss      @xmath71 .",
    "iii ; ;      update      @xmath72    [ al : main ]",
    "in this section , we present our lifelong learning algorithm , derive its regret bound and then specify it to two popular within - task online algorithms .",
    "our ewa - ll algorithm is outlined in algorithm [ al : main ] . the algorithm is based on the exponentially weighted aggregation procedure ( see e.g. * ? ? ? * and references therein ) , and updates a probability distribution @xmath73 on the set of representation @xmath74 before the encounter of task @xmath22 .",
    "the effect of step",
    "* iii * is that any representation @xmath35 which does not perform well on task @xmath22 , is less likely to be reused on the next task .",
    "we insist on the fact that this procedure allows the user to freely choose the within - task algorithm , which does not even need to be the same for each task .      since algorithm [ al : main ] involves a randomization strategy , we can only get a bound on the expected regret , the expectation being with respect to the drawing of the function @xmath75 at step * i * in the algorithm .",
    "let @xmath76 $ ] denote the expectation of @xmath77 when @xmath78 .",
    "note that the expected overall - average loss that we want to upper bound is then @xmath79.\\ ] ]    [ thm : online : w : online ] if , for any @xmath80 , @xmath81 $ ] and the within - task algorithm has a regret bound @xmath82 , then @xmath83   \\leq   \\inf_{\\rho } \\biggl\\ {         \\mathbb{e}_{g \\sim \\rho}\\biggl [          \\frac{1}{t }         \\sum_{t=1}^t         \\inf_{h_t\\in\\mathcal{h } }         \\frac{1}{m_t }         \\sum_{i=1}^{m_t }          \\ell\\big(h_t\\circ g(x_{t , i}),y_{t , i}\\big )        \\\\        +   \\frac{1}{t } \\sum_{t=1}^t \\beta(g , m_t )         \\biggr ]       + \\frac{\\eta c^2}{8 } + \\frac{\\mathcal{k}(\\rho,\\pi_1)}{\\eta t }   \\biggr\\ } ,   \\end{gathered}\\ ] ] where the infimum is taken over all probability measures @xmath84 and @xmath85 is the kullback - leibler divergence between @xmath84 and @xmath64 .",
    "the proof is given in appendix  [ proofs ] .",
    "some comments are in order as the bound in theorem  [ thm : online : w : online ] might not be easy to read .",
    "first , similar to standard analyses in online learning , the parameter @xmath86 is a decreasing function of @xmath4 , hence the bound vanishes as @xmath4 grows .",
    "second , corollaries are derived in section  [ applications ] that are easier to read , as they are more similar to usual regret inequalities @xcite , that is , the right hand side of the bound is of the form @xmath87 the bound in theorem [ al : main ] looks slightly different , but is quite similar in spirit .",
    "indeed , instead of an infimum with respect to @xmath35 we have an infimum on all the possible aggregations with respect to @xmath35 , @xmath88 where the remainder term depends on @xmath85 . in order to look like",
    ", we could consider a measure @xmath84 highly concentrated around the representation @xmath35 minimizing  . when @xmath15 is finite , this is a reasonable strategy and the bound is given explicitly in section  [ subsection - finite ] below .",
    "however , in some situations , this would cause the term @xmath85 to diverge . studying accurately",
    "the minimizer in @xmath84 usually leads to an interesting regret bound , and this is exactly what is done in section [ applications ] .",
    "finally note that the bound in theorem  [ thm : online : w : online ] is given in expectation . in online learning",
    ", uniform bounds are usually prefered  @xcite . in section  [ uniform ]",
    "we show that it is possible to derive such bounds under additional assumptions .",
    "we now specify the general bound in theorem [ al : main ] to two popular online algorithms which we use within tasks .",
    "the first algorithm assumes that @xmath17 is a parametric family of functions @xmath89 , and for any @xmath90 , @xmath91 is convex , @xmath92-lipschitz , upper bounded by @xmath93 and denote by @xmath94 a subgradient .",
    "data : :    a task    @xmath95 .",
    "input : :    stepsize @xmath96 , and @xmath97 .",
    "loop : :    for @xmath98 ,    +    i ; ;      predict      @xmath99 ,    ii ; ;      @xmath29 is revealed , update +      @xmath100 .    [ cor:1 ]",
    "the ewa - ll algorithm using the oga within task with step size @xmath101 satisfies @xmath83   \\leq   \\inf_{\\rho } \\biggl\\ {         \\mathbb{e}_{g \\sim \\rho}\\biggl [          \\frac{1}{t }         \\sum_{t=1}^t         \\inf_{h_t\\in\\mathcal{h } }         \\frac{1}{m_t }         \\sum_{i=1}^{m_t }          \\ell(h_t\\circ g(x_{t , i}),y_{t , i } )        \\\\        +   \\frac{bl}{t } \\sum_{t=1}^t \\sqrt{\\frac{2}{m_t } }         \\biggr ]       + \\frac{\\eta c^2}{8 } + \\frac{\\mathcal{k}(\\rho,\\pi_1)}{\\eta t }   \\biggr\\}.   \\end{gathered}\\ ] ]    apply theorem  [ thm : online : w : online ] and use the bound @xmath102 that can be found , for example , in ( * ? ? ?",
    "* corollary 2.7 ) .",
    "we note that under additional assumptions on loss functions ,  ( * ? ? ?",
    "* theorem 1 ) provides bounds for @xmath103 that are in @xmath104 .",
    "the second algorithm is based on the ewa procedure on the space @xmath105 for a prescribed representation @xmath80 .",
    "data : :    a task    @xmath62 .",
    "input : :    learning rate @xmath96 ; a prior probability distribution    @xmath106 on @xmath17 .",
    "loop : :    for @xmath98 ,    +    i ; ;      predict @xmath107 ,    ii ; ;      @xmath29 is revealed , update      @xmath108    recall that a function @xmath109 is called @xmath110-exp - concave if @xmath111 is concave .    [ cor:2 ] assume that @xmath17 is finite and that there exists @xmath112 such that for any @xmath113 , the function @xmath114 is @xmath110-exp - concave and upper bounded by a constant @xmath93 .",
    "then the ewa - ll algorithm using the ewa within task with @xmath115 satisfies @xmath83   \\leq   \\inf_{\\rho } \\biggl\\ {         \\mathbb{e}_{g \\sim \\rho}\\biggl [          \\frac{1}{t }         \\sum_{t=1}^t         \\inf_{h_t\\in\\mathcal{h } }         \\frac{1}{m_t }         \\sum_{i=1}^{m_t }          \\ell\\big(h_t\\circ g(x_{t , i}),y_{t , i}\\big )        \\\\        +    \\frac{1}{t } \\sum_{t=1}^t \\frac { \\zeta_0 \\log|\\mathcal{h}|}{m_t }         \\biggr ]       + \\frac{\\eta c^2}{8 } + \\frac{\\mathcal{k}(\\rho,\\pi_1)}{\\eta t }   \\biggr\\}.   \\end{gathered}\\ ] ]    apply theorem  [ thm : online : w : online ] and use the bound @xmath116 that can be found , for example , in ( * ? ? ?",
    "* theorem 2.2 ) .",
    "a typical example is the quadratic loss function @xmath117 .",
    "when there is some @xmath118 such that @xmath119 and @xmath120 , then the exp - concavity assumption is verified with @xmath121 and the boundedness assumption with @xmath122 .",
    "note that when the exp - concavity assumption does not hold ,  @xcite derives a bound @xmath123 with @xmath124 .",
    "moreover , pac - bayesian type bounds in various settings ( including infinite @xmath17 ) can be found in  @xcite .",
    "we refer the reader to  @xcite for a comprehensive survey .",
    "in this section , we discuss two important applications . to ease our presentation",
    ", we assume that all the tasks have the same sample size , that is @xmath125 for all @xmath22 .",
    "[ subsec : finite ]    we give details on example  [ exm - rel ] , that is we assume that @xmath15 is a set of @xmath53 functions .",
    "note that step * iii * in algorithm",
    "[ al : main ] boils down to update @xmath53 weights , @xmath126    under the assumptions of theorem [ thm : online : w : online ] , if we set @xmath127 and @xmath64 uniform on @xmath15 , @xmath128   \\leq         \\min_{1\\leq k\\leq k } \\bigg\\ {         \\frac{1}{t}\\sum_{t=1}^t         \\inf_{h_t\\in\\mathcal{h } }          \\frac{1}{m } \\sum_{i=1}^{m }          \\ell(h_t\\circ g_k(x_{t , i}),y_{t , i } )   \\\\",
    "+ \\beta(g_k , m )         \\bigg\\ }         + c\\sqrt{\\frac{\\log k}{2t}}.   \\label{example1 }   \\end{gathered}\\ ] ]    fix @xmath19 , @xmath84 as the dirac mass on @xmath35 and note that @xmath129 .",
    "we discussed in sections  [ exm : grad ] and  [ exm : ewa ] that typical orders for @xmath130 are @xmath131 , @xmath132 or @xmath133 .",
    "we state a precise result in the finite case .",
    "assume that @xmath17 is finite , that for some @xmath112 , for any @xmath113 , the function @xmath114 is @xmath110-exp - concave and upper bounded by a constant @xmath93 .",
    "then the ewa - ll algorithm using the ewa within task with @xmath115 satisfies @xmath134   \\leq   \\min_{1\\leq k \\leq k }          \\frac{1}{t }         \\sum_{t=1}^t         \\min_{h_t\\in\\mathcal{h } }         \\frac{1}{m }         \\sum_{i=1}^{m }          \\ell(h_t\\circ g_k(x_{t , i}),y_{t , i } )        \\\\",
    "+ \\frac { \\zeta_0 \\log|\\mathcal{h}|}{m }       + c\\sqrt{\\frac{\\log k}{2t}}.   \\end{gathered}\\ ] ]    in section  [ online - to - batch ] , we derive from theorem  [ thm : online : w : online ] a bound in the batch setting .",
    "as we shall see , in the finite case the bound is exactly the same as the bound on the compound regret .",
    "this allows us to compare our results to previous ones obtained in the learning - to - learn setting .",
    "in particular , our @xmath133 bound improves upon @xcite who derived an @xmath131 bound .",
    "we now give details on example  [ exm - dic ] in the linear case .",
    "specifically , we let @xmath55 , we let @xmath135 be the set formed by all @xmath57 matrices @xmath58 , whose columns have euclidean norm equal to one , and we define @xmath136 . within this subsection",
    "we assume that the loss @xmath137 is convex and @xmath138-lipschitz with respect to its first argument , that is , for every @xmath139 and @xmath140 , it holds @xmath141 .",
    "we also assume that for all @xmath142 and @xmath143 , @xmath144 .",
    "assume @xmath145 .",
    "we define the prior @xmath64 as follows : the columns of @xmath58 are i.i.d . ,",
    "uniformly distributed on the @xmath146-dimensional unit sphere .",
    "[ coro - dico ] under the assumptions of theorem [ thm : online : w : online ] , with @xmath147 , @xmath148   \\leq      \\inf_{d\\in\\mathcal{d}_k } \\biggl\\",
    "{ \\frac{1}{t } \\sum_{t=1}^t\\inf_{h_t \\in\\mathcal{h } } \\frac{1}{m}\\sum_{i=1}^{m }   \\ell\\big(\\langle h_t , d x_{t , i}\\rangle , y_{t , i}\\big )   \\\\   + \\frac{c}{4 } \\sqrt{\\frac{kd}{t } } ( \\log(t)+7 ) + \\beta(m ) \\biggr\\ } + \\frac{b\\phi}{\\sqrt{t } } \\sqrt { \\frac{1}{t }        \\sum_{t=1}^t     \\lambda_{\\max } \\left ( \\frac{1}{m }        \\sum_{i=1}^{m }     x_{t , i } x_{t , i}^t \\right )    } .\\end{gathered}\\ ] ]    the proof relies on an application of theorem  [ thm : online : w : online ] .",
    "the calculations being tedious , we postpone the proof to appendix  [ proofs ] .",
    "when we use oga within tasks , we can use corollary  [ cor:1 ] with @xmath149 and so @xmath150 for any @xmath151 .",
    "moreover , @xmath152 so theorem [ coro - dico ] leads to the following corollary .",
    "algorithm ewa - ll for dictionary learning , with @xmath153 , and using the oga algorithm within tasks , with step @xmath154 , satisfies @xmath148    \\leq      \\inf_{d\\in\\mathcal{d}_k}\\frac{1}{t } \\sum_{t=1}^t\\inf_{h_t \\in\\mathcal{h } } \\frac{1}{m}\\sum_{i=1}^{m }   \\ell\\big(\\langle h_t , d x_{t , i}\\rangle , y_{t , i}\\big )   \\\\   + \\frac{c}{4 } \\sqrt{\\frac{kd}{t } } ( \\log(t)+7 ) + \\frac{b\\phi } { \\sqrt{t } } + \\frac{\\phi   b\\sqrt{2 k}}{\\sqrt{m } } .\\end{gathered}\\ ] ]    note that the upper bound   may be lose . for example , when the @xmath28 are i.i.d . on the unit sphere",
    ", @xmath155 is close to @xmath156 . in this case , it is possible to improve the term @xmath157 employed in the calculation of the bound , we postpone the lengthy details to appendix  [ appendix : improvement ] .",
    "we implement our meta - algorithm randomized ewa in this setting .",
    "the algorithm used within each task is the simple version of the online gradient algorithm outlined in section  [ exm : grad ] .    in order to draw @xmath42 from @xmath73",
    ", we use @xmath158-steps of metropolis - hastings algorithm with a normalized gaussian proposal ( see , for example , * ? ? ?",
    "in order to ensure a short burn - in period , we use the previous drawing @xmath159 as a starting point .",
    "the procedure is given in algorithm  [ ewa - ll - d ] .",
    "data : :    as in algorithm [ al : main ] .",
    "input : :    a learning rate @xmath86 for ewa and a learning rate    @xmath160 for the online gradient . a number of steps    @xmath158 for the metropolis - hastings algorithm .",
    "start : :    draw @xmath161 .",
    "loop : :    for @xmath68    +    i ; ;      run the within - task learning algorithm @xmath70      and suffer loss @xmath71 .",
    "ii ; ;      set @xmath162 .",
    "iii ; ;      metropolis - hastings algorithm .",
    "repeat @xmath158 times      +      a : :        draw        @xmath163        and then set        @xmath164 .",
    "b : :        set @xmath165 with probability        @xmath166 \\right\\},\\ ] ]        @xmath167 remains unchanged otherwise .",
    "iv ; ;      set @xmath168 .",
    "note the bottleneck of the algorithm : in step * b * we have to compare @xmath167 and @xmath169 on the whole dataset so far .",
    "we now present a short simulation study .",
    "we generate data in the following way : we let @xmath170 , @xmath171 , @xmath172 and @xmath173 .",
    "the columns of @xmath58 are drawn uniformly on the unit sphere , and task regression vectors @xmath174 are also independent and have i.i.d .",
    "coordinates in @xmath175 $ ] .",
    "we generate the datasets @xmath26 as follows : all the @xmath28 are i.i.d . from the same distribution as @xmath174 , and @xmath176 where the @xmath177 are i.i.d . @xmath178 and @xmath179 .",
    "we compare algorithm  [ ewa - ll - d ] with @xmath180 to an oracle who knows the representation @xmath58 , but not the task regression vectors @xmath174 , and learns them using the online gradient algorithm with step size @xmath181 .",
    "notice that after each chunk of @xmath182 observations , a new task starts , so the parameter @xmath174 changes .",
    "thus , the oracle incurs a large loss until it learns the new @xmath174 ( usually within a few steps ) .",
    "this explains the `` stair '' shape of the cumulative loss of the oracle in figure  [ figure - zoom ] .",
    "figure  [ valeur - borne1 ] indicates that after a few tasks , the dictionary @xmath58 is learnt by ewa - ll : its cumulative loss becomes parallel to the one of the oracle . due to the bottleneck mentioned above , the algorithm becomes quite slow to run when @xmath22 grows . in order to improve the speed of the algorithm",
    ", we also tried algorithm [ ewa - ll - d ] with @xmath183 .",
    "there is absolutely no theoretical justification for this , however , obviously the algorithm is 10 times faster . as we can see on the red line in figure  [ valeur - borne1 ] ,",
    "this version of the algorithm still learns @xmath58 , but it takes more steps .",
    "note that this is not completely unexpected : the markov chain generated by this algorithm is no longer stationary , but it can still enjoy good mixing properties",
    ". it would be interesting to study the theoretical performance of algorithm [ ewa - ll - d ] .",
    "however , this would require considerably technical tools from markov chain theory which are beyond the scope of this paper .",
    "tasks . ]     in red and @xmath180 in blue ) and cumulative loss of the oracle . ]",
    "in this section , we show that it possible to obtain a uniform bound , as opposed to a bound in expectation as in theorem  [ thm : online : w : online ] . from a theoretical perspective",
    ", the price to pay is very low : we only have to assume that the loss function is convex with respect to its first argument .",
    "however , in practice , there is an aggregation step that might not be feasible .",
    "this is discussed at the end of the section .",
    "the algorithm is outlined in algorithm [ alg:04 ] .",
    "[ cor : online : w : online : agg ] assuming that for any @xmath184 and that the algorithm used within - task has a regret @xmath185 .",
    "assume that @xmath137 is convex with respect to its first argument .",
    "then it holds that @xmath186       + \\frac{\\eta c^2}{8 } + \\frac{\\mathcal{k}(\\rho,\\pi_1)}{\\eta t }   \\bigg\\}.   \\end{gathered}\\ ] ]    at each step @xmath22 , the loss suffered by the algorithm is @xmath187 and we can just apply theorem  [ thm : online : w : online ] .",
    "data and input : :    same as in algorithm [ al : main ] .",
    "loop : :    for @xmath68    +    i ; ;      run the within - task learning algorithm on      @xmath70 for each @xmath19      and return as predictions : @xmath188    ii ; ;      update @xmath189    [ alg:04 ]    in practice , for an infinite set @xmath15 we are not able to run simultaneously the within - task algorithm for all @xmath19 .",
    "so , we can not compute the prediction   exactly .",
    "a possible strategy is to draw @xmath158 elements of @xmath15 i.i.d . from @xmath73 ,",
    "say @xmath190 , and to replace   by @xmath191 an application of hoeffding s inequality shows for any @xmath192 , with probability at least @xmath193 , the bound in theorem  [ cor : online : w : online : agg ] will still hold , up to an additional term @xmath194 .",
    "in this section , we show how our analysis of lifelong learning can be used to derive bounds for learning - to - learn . in this",
    "setting , the tasks and their datasets are generated by first sampling task distributions @xmath195 i.i.d . from a``meta - distribution''@xmath196 , called _ environment _ by @xcite , and then for each task @xmath22 , a dataset @xmath197 is sampled i.i.d . from @xmath198 .",
    "we stress that in this setting , the entire data @xmath199 is given all at once to the learner .",
    "note that for simplicity , we assumed that all the sample sizes are the same .",
    "we wish to design a strategy which , given a new task @xmath200 and a new sample @xmath201 i.i.d . from @xmath202 , computes a function @xmath8 , that will predict @xmath113 well when @xmath203 . for this purpose",
    "we propose the following strategy :    1 .",
    "run ewa - ll on @xmath199 .",
    "we obtain a sequence of representations @xmath204 , 2 .",
    "draw uniformly @xmath205 and put @xmath206 , 3 .",
    "run the within task algorithm on the sample @xmath207 , obtaining a sequence @xmath208 of functions , 4 .",
    "draw uniformly @xmath209 and put @xmath210 .",
    "our next result establishes that the strategy leads indeed to safe predictions .",
    "[ thm : online : to : batch ] let @xmath211 be the expectation over all data pairs @xmath212 , @xmath213 , @xmath214 , @xmath203 , @xmath200 and also over the randomized decisions of the learner @xmath215 , @xmath216 and @xmath217 .",
    "then @xmath218   \\leq   \\inf_{\\rho }   \\biggl\\ {   \\mathbb{e}_{g\\sim \\rho }   \\biggl [   \\mathbb{e}_{p\\sim q } \\inf_{h\\in\\mathcal{h } }   \\mathbb{e}_{(x , y)\\sim p } \\bigl[\\ell(h\\circ g(x),y)\\bigr ] \\\\",
    "+ \\beta(g , m )   \\biggr ]   + \\frac{\\eta c^2 } { 8 } + \\frac{\\mathcal{k}(\\rho,\\pi_1)}{\\eta t }   \\biggr\\}.\\end{gathered}\\ ] ]    the proof is given in appendix  [ proofs ] .",
    "as in theorem  [ thm : online : w : online ] , the result is given in expectation with respect to the randomized decisions of the learner .",
    "assuming that @xmath137 is convex with respect to its first argument , we can state a similar result for a non - random procedure , as was done in section  [ uniform ] .",
    "details are left to the reader .    in  @xcite",
    ", the results on learning - to - learn are given with large probability with respect to the observations @xmath219 , rather than in expectation . using the machinery in ( * ? ? ? * lemma 4.1 ) we conjecture that it is possible to derive a bound in probability from theorem  [ thm : online : to : batch ] .",
    "we presented a meta - algorithm for lifelong learning and derived a fully online analysis of its regret .",
    "an important advantage of this algorithm is that it inherits the good properties of any algorithm used to learn within tasks .",
    "furthermore , using online - to - batch conversion techniques , we derived bounds for the related framework of learning - to - learn .",
    "we discussed the implications of our general regret bounds for two applications : dictionary learning and finite set @xmath15 of representations .",
    "further applications of this algorithm which may be studied within our framework are deep neural networks and kernel learning . in the latter case , which has been addressed by  @xcite in",
    "the learning - to - learn setting , @xmath220 is a feature map to a reproducing kernel hilbert space @xmath14 , and @xmath221 . in the former case , @xmath222 and @xmath223 is a multilayer network , that is a vector - valued function obtained by application of a linear transformation and a nonlinear activation function .",
    "the predictor @xmath224 is typically a linear function .",
    "the vector - valued function @xmath225 models a multilayer network with shared hidden weights .",
    "this is discussed in  @xcite , again in the learning - to - learn setting .    perhaps the most fundamental question is to extend our analysis to more computationally efficient algorithms such as approximations of ewa , like algorithm  [ ewa - ll - d ] , or fully gradient based algorithms as in  @xcite .    100 = 4em    audibert , j .- y .",
    "a randomized online learning algorithm for better variance control . in _ proc .",
    "19th annual conference on learning theory _ , pages 392407 .",
    "springer .",
    "balcan , m .- f . ,",
    "blum , a. , and vempala , s. ( 2015 ) .",
    "efficient representations for lifelong learning and autoencoding . in _ proc .",
    "28th conference on learning theory _ , pages 191210 .",
    "baxter , j. ( 1997 ) . a bayesian / information theoretic model of learning to learn via multiple task sampling .",
    ", 28(1):739 .",
    "baxter , j. ( 2000 ) . a model of inductive bias learning . ,",
    "12:149198 .",
    "catoni , o. ( 2004 ) .",
    ", volume 1851 of _ saint - flour summer school on probability theory 2001 ( jean picard ed . ) , lecture notes in mathematics_. springer - verlag , berlin .",
    "cavallanti , g. , cesa - bianchi , n. , and gentile , c. ( 2010 ) .",
    "linear algorithms for online multitask classification .",
    ", 1:29012934 .",
    "cesa - bianchi , n. and lugosi , g. ( 2006 ) . .",
    "cambridge university press .",
    "crammer , k. and mansour , y. ( 2012 ) .",
    "learning multiple tasks using shared hypotheses . in _ advances in neural information processing systems 25 _ ,",
    "pages 14751483 .",
    "gerchinovitz , s. ( 2011 ) . .",
    "phd thesis , paris 11 .",
    "gerchinovitz , s. ( 2013 ) .",
    "sparsity regret bounds for individual sequences in online linear regression . , 14(1):729769 .",
    "hazan , e. , agarwal , a. , and kale , s. ( 2007 ) .",
    "logarithmic regret algorithms for online convex optimization .",
    ", 69(2 - 3):169192 .",
    "maurer , a. ( 2005 ) .",
    "algorithmic stability and meta - learning .",
    ", 6:967994 .",
    "maurer , a. , pontil , m. , and romera - paredes , b. ( 2013 ) .",
    "sparse coding for multitask and transfer learning . in _ proc .",
    "30th international conference on machine learning _",
    ", pages 343351 .",
    "maurer , a. , pontil , m. , and romera - paredes , b. ( 2016 ) . the benefit of multitask representation learning .",
    ", 17(81):132 .",
    "mcallester , d.  a. ( 1998 ) .",
    "some pac - bayesian theorems . in _ proc .",
    "11th annual conference on computational learning theory _ , pages 230234 .",
    "pentina , a. and ben - david , s. ( 2015 ) . multi - task and lifelong learning of kernels . in _ proc .",
    "26th international conference on algorithmic learning theory _ , pages 194208 .",
    "pentina , a. and lampert , c. ( 2014 ) . a pac - bayesian bound for lifelong learning . in _ proc .",
    "31st international conference on machine learning _ , pages 991999 .",
    "robert , c. and casella , g. ( 2013 ) . .",
    "springer science & business media .",
    "ruvolo , p. and eaton , e. ( 2013 ) .",
    "ella : an efficient lifelong learning algorithm . in _ proc .",
    "30th international conference on machine learning _ , pages 507515 .",
    "shalev - shwartz , s. ( 2011 ) .",
    "online learning and online convex optimization .",
    ", 4(2):107194 .",
    "thrun , s. ( 1996 ) . is learning the n - th thing any easier than learning the first ?",
    "in _ advances in neural information processing systems _ , pages 640646 .",
    "thrun , s. and pratt , l. ( 1998 ) . .",
    "kluwer academic publishers .",
    "vapnik , v. ( 1998 ) . .",
    "it is enough to show that the ewa strategy leads to @xmath226   \\leq   \\inf_{\\rho } \\biggl\\ {         \\mathbb{e}_{g \\sim \\rho}\\left [ \\sum_{t=1}^t \\hat{l}_t(g)\\right ]         + \\frac{\\eta c^2 t}{8 } + \\frac{\\mathcal{k}(\\rho,\\pi_1)}{\\eta }   \\biggr\\}.\\ ] ] once this is done , we only have to use the assumption that the regret of the within - task algorithm on task @xmath22 is upper bounded by @xmath103 to obtain that @xmath227 and we obtain the statement of the result .",
    "it remains to prove  . to this end",
    ", we follows the same guidelines as in the proof of theorem 1 in  @xcite .",
    "first , note that @xmath228           \\pi_1({\\rm d}g ) } { \\int \\exp\\left[-\\eta \\sum_{u=1}^{t-1 } \\hat{l}_u           ( \\gamma ) \\right ] \\pi_1({\\rm d}\\gamma ) }     = \\frac{\\exp\\left[-\\eta \\sum_{u=1}^{t-1 } \\hat{l}_u ( g ) \\right ]           \\pi_1({\\rm d}g ) } { w_t}\\ ] ] where we introduce the notation @xmath229 for the sake of shortness . put @xmath230 $ ] . using hoeffding s inequality on the bounded random variable @xmath231 $ ] we have , for any @xmath22 , that @xmath232 =    \\int    \\exp\\left\\ {      \\eta ( e_t-\\hat{l}_t(g ) )     \\right\\ } \\pi_t({\\rm d } g ) \\leq \\exp\\left\\ { \\frac { c^2 \\eta^2}{8 }   \\right\\}\\ ] ] which can be rewritten as @xmath233   \\right\\ }      \\geq      \\exp\\left ( -\\frac{c^2 \\eta^2}{8 }",
    "\\right )   \\mathbb{e}_{{\\hat g}_t \\sim \\pi_t } \\left\\ { \\exp\\left [ -     \\eta \\hat{l}_t(g_t )   \\right ] \\right\\}.\\ ] ] next , we note that @xmath234   \\right\\ }    & = \\prod_{t=1}^t   \\exp\\left\\ { - \\eta \\mathbb{e}_{g_t \\sim   \\pi_t}[\\hat{l}_t(g_t ) ]   \\right\\ } \\\\    & \\geq   \\exp\\left(- \\frac{t c^2 \\eta^2}{8 } \\right ) \\prod_{t=1}^t    \\mathbb{e}_{{\\hat g}_t \\sim \\pi_t } \\left\\ { \\exp\\left [ -     \\eta \\hat{l}_t(g_t )   \\right ] \\right\\ } \\\\   & \\quad   \\quad \\text { ( using~\\eqref{hoeffding})}\\\\   & =     \\exp\\left\\ { -\\frac{t c^2 \\eta^2}{8 }   \\right\\ }   \\prod_{t=1}^t \\int    \\exp\\left\\ { -     \\eta \\hat{l}_t(g )     \\right\\ } \\pi_t({\\rm d } g )    \\\\   & = \\exp\\left\\{- \\frac{t c^2 \\eta^2}{8 }   \\right\\ }   \\prod_{t=1}^t \\int    \\frac{\\exp\\left\\ { -     \\eta \\sum_{u=1}^t \\hat{l}_u(g )     \\right\\}}{w_{t } } \\pi_1({\\rm d } g ) \\\\    & \\quad \\quad \\text { ( using~\\eqref{renorm } ) }   \\\\   & = \\exp\\left\\ { -\\frac{t c^2 \\eta^2}{8 }   \\right\\ }   \\prod_{t=1}^t \\frac{w_{t+1}}{w_{t } }   = \\exp\\left\\ { \\frac{t c^2 \\eta^2}{8 }   \\right\\ } w_{t+1}.\\end{aligned}\\ ] ] so @xmath235   & \\leq   - \\frac{\\log w_{t+1 } } { \\eta }       + \\frac{t c^2 \\eta}{8 }   \\\\   & = - \\frac{\\log \\int \\exp\\left[-\\eta \\sum_{t=1}^{t } \\hat{l}_t           ( g ) \\right ] \\pi_1({\\rm d}g ) } { \\eta }       + \\frac{t c^2 \\eta}{8}\\end{aligned}\\ ] ] and finally we use ( * ? ? ?",
    "* equation ( 5.2.1 ) ) which states that @xmath236 \\pi_1({\\rm d}g ) } { \\eta }   = \\inf_{\\rho } \\left\\ { \\mathbb{e}_{g\\sim \\rho}\\left [ \\sum_{t=1}^{t } \\hat{l}_t           ( g ) \\right ] + \\frac{\\mathcal{k}(\\rho,\\pi_1)}{\\eta } \\right\\}.\\ ] ]    let @xmath237 denote a minimizer to the optimization problem @xmath238 we apply theorem  [ thm : online : w : online ] and upper bound the infimum with respect to any @xmath84 by an infimum with respect to @xmath84 in the following parametric family @xmath239 where @xmath240 is a positive parameter . note that when @xmath240 is small , @xmath241 highly concentrates around @xmath237 , but we will show this is at a price of an increase in @xmath242 . the proof",
    "then proceeds in optimizing with respect to @xmath240 .",
    "we have that @xmath134   \\\\   \\leq   \\inf_{c }",
    "\\bigg\\ {         \\mathbb{e}_{d \\sim \\rho_{c}}\\bigg [          \\frac{1}{t }        \\sum_{t=1}^t         \\inf_{h_t\\in\\mathcal{h } }         \\frac{1}{m }        \\sum_{i=1}^{m }          \\ell(\\langle h_t , d x_{t , i}\\rangle , y_{t , i } ) +   \\beta(m )         \\bigg ]       + \\frac{\\eta c^2}{8 } + \\frac{\\mathcal{k}(\\rho_{c},\\pi_1)}{\\eta t }   \\bigg\\}.   \\end{gathered}\\ ] ] now , we have @xmath243 and @xmath244 where the first inequality follows by observing that , since @xmath245 is the uniform distribution on the unit @xmath146-sphere , the probability to be calculated is greater or equal to the ration between the volume of the @xmath246-ball with radius @xmath247 and the surface area of the unit @xmath146-sphere .",
    "so we get @xmath248 furthermore , using the notation @xmath249 we get @xmath250 under the condition on the loss , we have @xmath251 where @xmath252 denotes the frobenius norm .",
    "we obtain an upper - bound @xmath253 but then note that @xmath254 so theorem  [ oracle - type ] leads to @xmath255    -    \\inf_{d\\in\\mathcal{d}_k}\\frac{1}{t } \\sum_{t=1}^t\\inf_{h_t \\in\\mathcal{h } } \\frac{1}{m}\\sum_{i=1}^{m }   \\ell(\\langle h_t , d x_{t , i}\\rangle , y_{t , i } )   \\\\   \\leq   \\inf_{c } \\left\\ { c \\phi   b \\sqrt { \\frac{1}{t }        \\sum_{t=1}^t     \\lambda_{\\max } \\left ( \\frac{1}{m }        \\sum_{i=1}^{m }     x_{t , i } x_{t , i}^t \\right )    } +   \\frac { kd } { \\eta t } \\log(1/c )     \\right\\ } +   \\frac { 3kd } { \\eta t } + \\beta(m ) + \\frac{\\eta c^2}{8 } .\\end{gathered}\\ ] ] the choices @xmath256 and @xmath257 lead to the result .",
    "the proof relies on an application of the well - known online - to - batch trick , discussed pedagogically in section 5 page 186 in  @xcite .",
    "still , it is very cumbersome , and it is easy to get confused . for these reasons , we think it is important to write it completely .",
    "we use the following notation for any random variable @xmath258 , @xmath259 is the expectation with respect to @xmath258 .",
    "this is very important as the online - to - batch trick relies essentially on inverting the order of the random variables in the integration .",
    "we have :    @xmath260   \\\\   &   =   \\mathbb{e}_{\\mathcal{t } } \\mathbb{e}_{\\mathcal{i } } \\mathbb{e}_{p_1,\\dots , p_t } \\mathbb{e}_{(x_{j , i},y_{j , i})_{j\\leq t , i\\leq m } } \\mathbb{e}_{p } \\mathbb{e}_{(x_s , y_s)_{s\\leq m } } \\mathbb{e}_{(x , y ) } [ \\ell(\\hat{h}\\circ \\hat{g}(x),y ) ] \\\\ & =   \\frac{1}{t}\\sum_{t=1}^t    \\frac{1}{m}\\sum_{i=1}^m    \\mathbb{e}_{p_1,\\dots , p_t } \\mathbb{e}_{(x_{j , i},y_{j , i})_{j\\leq t , i\\leq m } } \\mathbb{e}_{p } \\mathbb{e}_{(x_s , y_s)_{s\\leq m } } \\mathbb{e}_{(x , y ) } [ \\ell(\\hat{h}_i^{\\hat{g}_t } \\circ \\hat{g}_t(x),y ) ] \\\\ & =   \\frac{1}{t}\\sum_{t=1}^t    \\mathbb{e}_{p_1,\\dots , p_t } \\mathbb{e}_{(x_{j , i},y_{j , i})_{j\\leq t , i\\leq m } } \\mathbb{e}_{p } \\frac{1}{m}\\sum_{i=1}^m   \\mathbb{e}_{(x_s , y_s)_{s\\leq i-1 } } \\mathbb{e}_{(x , y ) } [ \\ell(\\hat{h}_i^{\\hat{g}_t } \\circ \\hat{g}_t(x),y ) ] \\\\ & =   \\frac{1}{t}\\sum_{t=1}^t    \\mathbb{e}_{p_1,\\dots , p_t } \\mathbb{e}_{(x_{j , i},y_{j , i})_{j\\leq t , i\\leq m } } \\mathbb{e}_{p } \\frac{1}{m}\\sum_{i=1}^m   \\mathbb{e}_{(x_s , y_s)_{s\\leq i-1 } } \\mathbb{e}_{(x_i , y_i ) } [ \\ell(\\hat{h}_i^{\\hat{g}_t } \\circ \\hat{g}_t(x_i),y_i ) ] \\\\ & =   \\frac{1}{t}\\sum_{t=1}^t    \\mathbb{e}_{p_1,\\dots , p_t } \\mathbb{e}_{(x_{j , i},y_{j , i})_{j\\leq t ,",
    "i\\leq m } } \\mathbb{e}_{p } \\frac{1}{m}\\sum_{i=1}^m   \\mathbb{e}_{(x_s , y_s)_{s\\leq m } } [ \\ell(\\hat{h}_i^{\\hat{g}_t } \\circ \\hat{g}_t(x_i),y_i ) ] \\\\ & =   \\frac{1}{t}\\sum_{t=1}^t    \\mathbb{e}_{p_1,\\dots , p_t } \\mathbb{e}_{(x_{j , i},y_{j , i})_{j\\leq t , i\\leq m } } \\mathbb{e}_{p }   \\mathbb{e}_{(x_s , y_s)_{s\\leq m } } \\left [ \\frac{1}{m}\\sum_{i=1}^m \\ell(\\hat{h}_i^{\\hat{g}_t } \\circ \\hat{g}_t(x_i),y_i)\\right ] \\\\ & =   \\frac{1}{t}\\sum_{t=1}^t    \\mathbb{e}_{p_1,\\dots , p_{t-1 } } \\mathbb{e}_{(x_{j , i},y_{j , i})_{j\\leq t-1,i\\leq m } } \\mathbb{e}_{p }   \\mathbb{e}_{(x_s , y_s)_{s\\leq m } } \\left [ \\frac{1}{m}\\sum_{i=1}^m \\ell(\\hat{h}_i^{\\hat{g}_t } \\circ \\hat{g}_t(x_i),y_i)\\right ] \\\\ & =   \\frac{1}{t}\\sum_{t=1}^t    \\mathbb{e}_{p_1,\\dots , p_{t-1 } } \\mathbb{e}_{(x_{j , i},y_{j , i})_{j\\leq t-1,i\\leq m } } \\mathbb{e}_{p_t }   \\mathbb{e}_{(x_s , y_s)_{s\\leq m } } \\left [ \\frac{1}{m}\\sum_{i=1}^m \\ell(\\hat{h}_i^{\\hat{g}_t } \\circ \\hat{g}_t(x_{t , i}),y_{t , i})\\right ] \\\\ & =   \\frac{1}{t}\\sum_{t=1}^t    \\mathbb{e}_{p_1,\\dots , p_t }    \\mathbb{e}_{(x_{j , i},y_{j , i})_{j\\leq t , i\\leq m } }    \\left [ \\frac{1}{m}\\sum_{i=1}^m \\ell(\\hat{h}_i^{\\hat{g}_t } \\circ \\hat{g}_t(x_{t , i}),y_{t , i})\\right ] \\\\ & =    \\mathbb{e}_{p_1,\\dots , p_t }    \\mathbb{e}_{(x_{j , i},y_{j , i})_{j\\leq t , i\\leq m } }    \\left [ \\frac{1}{t}\\sum_{t=1}^t \\frac{1}{m}\\sum_{i=1}^m \\ell(\\hat{h}_i^{\\hat{g}_t } \\circ \\hat{g}_t(x_{t , i}),y_{t , i})\\right ] \\\\ & \\leq    \\mathbb{e}_{p_1,\\dots , p_t }    \\mathbb{e}_{(x_{j , i},y_{j , i})_{j\\leq t , i\\leq m } }    \\inf_{\\rho }    \\biggl\\ {      \\mathbb{e}_{g \\sim \\rho}\\biggl [          \\frac{1}{t }         \\sum_{t=1}^t         \\inf_{h_t\\in\\mathcal{h } }         \\frac{1}{m }         \\sum_{i=1}^{m }          \\ell(h_t\\circ g(x_{t , i}),y_{t , i } )          \\\\          & \\quad \\quad        +   \\frac{1}{t } \\sum_{t=1}^t \\beta(g , m )         \\biggr ]       + \\frac{\\eta c^2}{8 } + \\frac{\\mathcal{k}(\\rho,\\pi_1)}{\\eta t }    \\biggr\\ } \\text { , using theorem~\\ref{thm : online : w : online } , } \\\\ & \\leq    \\inf_{\\rho }    \\biggl\\ {      \\mathbb{e}_{g \\sim \\rho}\\biggl [       \\mathbb{e}_{p\\sim q }         \\inf_{h_t\\in\\mathcal{h } }       \\mathbb{e}_{(x , y)\\sim p }          \\ell(h_t\\circ g(x),y )        +    \\beta(g , m )         \\biggr ]       + \\frac{\\eta c^2}{8 } + \\frac{\\mathcal{k}(\\rho,\\pi_1)}{\\eta t }    \\biggr\\}.\\end{aligned}\\ ] ]",
    "we now state a refined version of the bounds for dictionary learning in section  [ applications ] . as pointed out in that section , while in general the bound @xmath261 is unimprovable , if the input vectors @xmath28 are i.i.d . random variables from uniform distribution on the unit sphere , then @xmath262{a.s . } { \\rm cov}(x_{t , i},x_{t , i } ) = \\frac{1}{d}i\\ ] ] where @xmath263 is the identity matrix . consequently , @xmath264{a.s . }",
    "\\frac{1}{d } .\\ ] ] we can take advantage of this fact in order to improve the term @xmath265 , but only if we assume that we know in advance that @xmath266 is not too large .",
    "this is the meaning of the following theorem .",
    "assume that we know in advance that for all @xmath23 , @xmath267 for some @xmath268 .",
    "assume the same assumptions as in theorem  [ coro - dico ] , still with @xmath147 .",
    "use within tasks algorithm  [ oga ] ( online gradient ) with a fixed gradient step @xmath269 .",
    "then we have @xmath255    -   \\inf_{g\\in\\mathcal{g}}\\frac{1}{t } \\sum_{t=1}^t\\inf_{h_t \\in\\mathcal{h } } \\frac{1}{m}\\sum_{i=1}^{m }   \\ell\\big(\\langle h_t , g x_{t , i}\\rangle , y_{t , i}\\big )   \\\\   \\leq \\frac{c}{4 } \\sqrt{\\frac{kd}{t } } ( \\log(t)+7 ) + \\frac{2 b l \\sqrt{2 k \\lambda } } { \\sqrt{m } } + \\frac{b\\phi \\sqrt{\\lambda}}{\\sqrt{t } }    .\\end{gathered}\\ ] ]    in particular , note that when @xmath270 the bound becomes @xmath271    we apply theorem  [ coro - dico ] , so we only have to upper bound the term @xmath130 for the online gradient algorithm with the prescribed step size .",
    "note that in  ( corollary 2.7 * ? ? ?",
    "* ) we actually have the following regret bound for algorithm  [ oga ] with fixed step size @xmath65 : @xmath272 by the @xmath92-lipschitz assumption on @xmath137 , @xmath273 .",
    "so we have @xmath274 consequently , @xmath275 and the choice @xmath276 leads to @xmath277",
    "in this last section of the appendix , we present an alternative approach for the batch - within - online setting discussed in section  [ notations ] . in this",
    "setting , the tasks are presented sequentially , but , for each task @xmath278 the dataset @xmath279 is presented all at once and we assume it is obtained i.i.d . from a distribution @xmath198 . unlike to the reasoning in section  [ online - to - batch ] , where we assumed that the @xmath198 were i.i.d . from a distribution @xmath196 , here we make no assumptions on the generation process underlying the @xmath198 s , which may even be adversarial chosen .      1",
    ".   nature choses @xmath198 , no assumption is made on this choice .",
    "this @xmath198 is not revealed to the forecaster .",
    "2 .   nature draws the sample @xmath280 $ ] i.i.d . from @xmath198 , and this sample is revealed to the forecaster .",
    "3 .   based on her / his current guess @xmath281 of @xmath35 and on the sample @xmath26",
    ", the forecaster has to run her / his favourite learning algorithm @xmath282 on @xmath283 to get an estimate @xmath284 based on an algorithm of his choice .",
    "note that the forecaster observes @xmath285 where @xmath286 4 .",
    "the forecaster incur the loss @xmath287 where @xmath288 .\\ ] ] unfortunately , this quantity is not known to the forecaster .    at the end of time , we are interested in a strategy such that the compound regret @xmath289 is controled .",
    "the situation is similar to the setting discussed in the core of the paper : we will propose an ewa algorithm for transfer learning , ewa - tl , for which the regret will be controlled , on the condition that the learner chooses a suitable within task algorithm . in the online case ,",
    "the within tasks algorithm was either ewa or oga .",
    "in subsection  [ wta ] we discuss briefly the within task algorithm . in subsection  [ tla ]",
    "we present the ewa - tl algorithm and its theoretical analysis .        in classification ,",
    "when @xmath137 is the 0 - 1 loss function , and for any @xmath35 , the family @xmath291 has a vapnik - chervonenkis dimension bounded by @xmath258 , then the empirical risk minimizer ( erm ) @xmath292 satisfies the above condition with @xmath293 see e.g.  ( chapter 4 , page 94 * ? ? ?",
    "similar rates can be obtained with pac - bayesian bounds  @xcite , but we postpone the details to future work .",
    "data : :    a sequence of datasets +    @xmath62 ,    @xmath63 , associated with different learning tasks ;    the datasets are revealed sequentially , but the points within each    dataset @xmath26 are revealed all at once .",
    "input : :    a prior @xmath64 , a learning parameter @xmath65    and a learning algorithm @xmath282 which satisfies  .",
    "loop : :    for @xmath68    +    i ; ;      draw @xmath69 .",
    "ii ; ;      run the within - task learning algorithm @xmath294 on      @xmath70 to get      @xmath295 .",
    "iii ; ;      update @xmath296      \\biggr\\ }      \\pi_{t-1}({\\rm d}g).\\ ] ]        [ thm : batch : w : online ] under  , and assuming that there is a constant @xmath93 such that @xmath297 , with probability at least @xmath298 , @xmath299 \\bigr ]   \\leq        \\inf_{\\rho } \\biggl\\ {      \\mathbb{e}_{g \\sim \\rho } \\left[\\frac{1}{t }        \\sum_{t=1}^t      \\inf_{h\\in\\mathcal{h } } r_t(h\\circ g )      + \\frac{4}{t}\\sum_{t=1}^t \\delta(g , m_t,\\varepsilon / t )      \\right ]      \\\\",
    "+ \\frac{\\eta   c^2}{8 } + \\frac{\\mathcal{k}(\\rho,\\pi_1)}{\\eta t } \\biggr\\}.\\end{gathered}\\ ] ]    first , follow the proof of theorem  [ thm : online : w : online ] to get : @xmath300 +   \\delta(\\tilde{g}_t , m_t,\\varepsilon / t ) \\bigr ]    \\leq      \\inf_{\\rho }",
    "\\biggl\\ { \\sum_{t=1}^t      \\mathbb{e}_{g \\sim \\rho }      \\bigl [      r_t(\\tilde{h}_t\\circ g )      + \\delta(g , m_t,\\varepsilon / t )      \\bigr ]     \\\\     + \\frac{\\eta t c^2}{8 } + \\frac{\\mathcal{k}(\\rho,\\pi)}{\\eta } \\biggr\\}.\\end{gathered}\\ ] ] so , with probability at least @xmath298 , @xmath301 \\bigr ] \\\\ &",
    "\\mathbb{e}_{\\tilde{g}_t \\sim \\pi_{t-1 } } \\bigl [ r_t(\\tilde{h}_t\\circ \\tilde{g}_t ) ] +   \\delta(\\tilde{g}_t , m_t,\\varepsilon / t ) \\bigr ]    \\\\ & \\leq      \\inf_{\\rho } \\left\\ { \\sum_{t=1}^t      \\mathbb{e}_{g \\sim \\rho }      \\bigl [      r_t(\\tilde{h}_t\\circ g )      + \\delta(g , m_t,\\varepsilon / t )      \\bigr ]     + \\frac{\\eta t c^2}{8 } + \\frac{\\mathcal{k}(\\rho,\\pi_1)}{\\eta } \\right\\ }    \\\\ & \\leq        \\inf_{\\rho } \\left\\ { \\sum_{t=1}^t      \\mathbb{e}_{g \\sim \\rho }      \\bigl [      r_t(\\hat{h}_t(g,\\mathcal{s}_t)\\circ g )      + 2 \\delta(g , m_t,\\varepsilon / t )      \\bigr]\\     + \\frac{\\eta t c^2}{8 } + \\frac{\\mathcal{k}(\\rho,\\pi_1)}{\\eta } \\right\\ }   \\\\   & \\leq \\inf_{\\rho } \\left\\ {      \\mathbb{e}_{g \\sim \\rho } \\left [ \\sum_{t=1}^t      \\inf_{h\\in\\mathcal{h } } r_t(h\\circ g )      + 4\\sum_{t=1}^t \\delta(g , m_t,\\varepsilon / t )      \\right ]     + \\frac{\\eta t c^2}{8 } + \\frac{\\mathcal{k}(\\rho,\\pi_1)}{\\eta } \\right\\}.\\end{aligned}\\ ] ]"
  ],
  "abstract_text": [
    "<S> we consider the problem of transfer learning in an online setting . </S>",
    "<S> different tasks are presented sequentially and processed by a within - task algorithm . </S>",
    "<S> we propose a lifelong learning strategy which refines the underlying data representation used by the within - task algorithm , thereby transferring information from one task to the next . </S>",
    "<S> we show that when the within - task algorithm comes with some regret bound , our strategy inherits this good property . </S>",
    "<S> our bounds are in expectation for a general loss function , and uniform for a convex loss . </S>",
    "<S> we discuss applications to dictionary learning and finite set of predictors . in the latter case , </S>",
    "<S> we improve previous @xmath0 bounds to @xmath1 where @xmath2 is the per task sample size . </S>"
  ]
}