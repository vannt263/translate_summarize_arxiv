{
  "article_text": [
    "computer hardware is increasingly being shared between multiple , potentially untrusted , programs .",
    "examples of such sharing range from cloud services where a single computer may share workloads of multiple clients via mobile phones that run multiple apps , each authored by a different developer , to web browsers displaying pages from different sites . to protect confidential or private information that some of these programs may access ,",
    "the system imposes a _ security policy _ that prevents the dissemination of such information .",
    "one threat to the security of the system are _ covert channels _  @xcite , which allow colluding programs to bypass the security policy , by transferring information over media that are not controlled by the system .",
    "a typical scenario includes two programs : a _ trojan _ program , which has access to sensitive information but is confined  @xcite by the security policy ( i.e.  prevented from sending information to arbitrary destinations ) , and a _ spy _ process that does not have access to the sensitive information but can communicate with less restrictions . using a covert channel , the trojan can send the sensitive information to the spy , which can then exfiltrate it from the system .",
    "covert channels are often classified as either _ storage _ or _ timing _ channels  @xcite .",
    "storage channels exploit the ability of one program to store data that the other program can read .",
    "timing channels , in contrast , exploit timing variations for transferring information .",
    "past research has demonstrated the possibility of completely eliminating storage channels  @xcite .    for timing channels ,",
    "the picture is not that clear .",
    "some classes of timing channels can be eliminated by ensuring deterministic timing of any externally visible effects of programs  @xcite , and mitigation strategies are often suggested for published microarchitectural channels  @xcite . however , there is currently no known method that guarantees the absence of timing channels on shared hardware .    in this paper",
    "_ we examine the degree to which it is possible to prevent timing channels on modern hardware . _",
    "specifically we look at intra - core channels , which exploit hardware state for signalling between processes or vms that time - share a processor core .",
    "this means we not only ignore channels between cores , but also between concurrent executions on a single core ( hyperthreading ) ; channels between hyperthreads are well - documented and understood  @xcite and are probably impossible to close .",
    "this is thus a fairly restricted scenario and one would expect that all channels could be trivially ( albeit expensively ) closed by flushing all cached state on a context switch , using the appropriate hardware mechanisms , so the main challenge would seem to be how to minimise the cost of the defence .",
    "however , we show reality to be different : we demonstrate that on recent arm as well as x86 processors there are channels that resist all attempts to close them by flushing the state they exploit .",
    "specifically , we implement several covert - channel techniques , including the prime+probe attack on the l1 data cache  @xcite and the l1 instruction cache  @xcite .",
    "we also implement new attacks targeting the translation lookaside buffer ( tlb ) , the branch predictor unit ( bpu ) , and the branch target buffer ( btb ) .",
    "we measure the channels created by these techniques , first without mitigations , to demonstrate the existence of the channel , and then with the use of mitigation techniques , to measure the remaining channel .",
    "our results show that some channels remain even after activating all of the available mitigation techniques .",
    "in particular , we note that the x86 does not support any instruction or documented method for clearing the state of the bpu .",
    "consequently , the branch prediction channel remains open .",
    "we further note that popular belief notwithstanding , invalidating the contents of the caches does not close all cache - based channels and that at least on intel x86 , flushing the tlb has negligible effect on the tlb channel .    in summary",
    ", we make the following contributions :    * we identify a limited scenario for investigating microarchitectural - timing - channel elimination .",
    "* we implement multiple persistent - state microarchitectural covert channels , some of which have previously only been speculated , but never implemented ( ) , identify existing mitigation techniques available in existing processors ( ) , and measure the channels with and without those mitigation techniques ( ) .",
    "our results show that on present hardware , intra - core channels remain even when using all hardware - supported flush operations .",
    "we begin by describing the relevant components of modern processors , and how they can be leveraged for timing channels .      the _ instruction set architecture _ ( isa ) is the hardware - software contract for a processor family , such as x86 or arm cortex - a .",
    "the isa specifies the functional operation of the processor , including the instructions that the processor can execute , their encoding , the available registers and their functions .",
    "while there may be some minor variations in feature support between processors in a family , the core of the isa remains invariant , allowing seamless software support across the family .",
    "the isa abstracts over a processor s implementation , which is made up from a large number of components , including functional units , caches , buses and interfaces , collectively called the _",
    "microarchitecture_. while functionally transparent , details of the microarchitecture affect the timing of operations .",
    "much of this is the result of the processor caching information in many places , in order to improve average - case execution speed .",
    "any such caches make the latency of operations dependent on execution history and thus creating the potential for timing channels .",
    "we now describe the relevant components .",
    "[ [ cpu - caches ] ] cpu caches + + + + + + + + + +    these are , in terms of their effect on timing , the most noticeable components .",
    "the caches bridge the speed gap between the processor and the much slower memory , by holding recently - accessed data or instructions .",
    "a cache is a bank of high - speed memory , typically using static random access memory ( sram ) technology , which is faster albeit more expensive than the dynamic random access memory ( dram ) technology commonly used in the main memory .",
    "faster technology and greater proximity to the processing core ( enabled by smaller size ) means that access to the cache is much faster than to the main memory .",
    "caches utilise the spatial and temporal locality of programs for reducing average access time .",
    "[ [ cache - organisation ] ] cache organisation + + + + + + + + + + + + + + + + + +    the cache is organised in _",
    "lines _ of a fixed , power - of - two size , typically ranging from 32 to 128 bytes . the line is the unit of allocation and transfer to memory , i.e.  at any time a line either is invalid or caches a size - aligned block of memory .",
    "the lowest - order bits of the address of a data item or instruction are the line offset , i.e.  they determine where the item is located within the line .",
    "caches are generally _ set associative _ , meaning that a fixed number , @xmath0 , of lines are grouped into a _ set _",
    ", where @xmath0 is the associativity of the cache ; the lines of a set are also often called _ ways_. cache content is located by hashing the address onto a set number . in most cases",
    "the hash is just the low - order address bits after stripping the offset bits . within the set ,",
    "the correct line is found by associative lookup , comparing the address bits with a _ tag _ stored in each line .",
    "if none of the tags match , the item is not in the cache ( i.e.  a cache miss ) .",
    "[ [ cache - hierarchy ] ] cache hierarchy + + + + + + + + + + + + + + +    as the speed gap between processor and memory is orders of magnitude , modern processors have a hierarchy of caches .",
    "closest to the core is the l1 cache , generally split into separate instruction and data caches , i- and d - cache , and always private to a core .",
    "further levels are unified , larger and slower , down to the _ last - level cache _ ( llc ) , which is generally shared between cores .",
    "[ [ cache - addressing ] ] cache addressing + + + + + + + + + + + + + + + +    l1 caches are frequently _ virtually addressed _ , i.e.  lookup is by virtual address of the item .",
    "all other caches are _ physically addressed_. on recent intel processors , the llc lookup uses a more complex hash rather than just the low - order address bits .",
    "the hash function is unspecified , but has been reverse - engineered  @xcite .",
    "[ [ translation - lookaside - buffer ] ] translation lookaside buffer + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the mapping from virtual to physical addresses is specified in the page table . to avoid frequent lookups , the processor caches translations in the _ tlb_.",
    "it is usually organised as a two - level cache .",
    "intel processors generally feature set - associative tlbs , while on many other architectures they are fully associative ( single set ) or a mixture ( e.g.  a fully - associative first - level and a set - associative second - level tlb on arm cortex a9 ) .",
    "intel processors also feature a separate cache for page directory entries .",
    "[ [ branch - prediction ] ] branch prediction + + + + + + + + + + + + + + + + +    to avoid pipeline stalls while processing branch instructions , processors feature a _ bpu _ , which predicts the target of branches .",
    "this allows the processor to speculatively fetch instructions following the branch . in the case of a misprediction",
    ", the speculative execution is rolled back and processing continues on the right branch .",
    "a typical bpu consists of at least two subunits : the _ btb _ and the _ history buffer_.    [ [ history - buffer ] ] history buffer + + + + + + + + + + + + + +    the history buffer aims to predict the outcome of conditional branches , i.e.  whether the branch is taken or not .",
    "prediction is typically based on the history of the specific branch , possibly with a combination of the outcomes of branches leading to it .",
    "the history buffer maintains a state machine for each branch ( or a combination of a branch and branching history ) . in the common two - bit predictor ,",
    "the predictor needs to mispredict twice in order for the prediction to change .    [",
    "[ branch - target - buffer ] ] branch target buffer + + + + + + + + + + + + + + + + + + + +    the btb caches destination addresses of unconditional and taken conditional branches .",
    "details are generally not specified by the manufacturer , but can frequently be reverse - engineered  @xcite .",
    "[ [ prefetching ] ] prefetching + + + + + + + + + + +    modern processors increase the effectiveness of the cache by predicting which memory locations will be accessed in the near future , and pre - loading these locations into the cache , a process called _",
    "prefetching_. this works best for constant - stride accesses , but modern prefetchers can deal with more complex access patterns .",
    "the exact operation of the prefetcher is generally unspecified .",
    "[ [ microarchitectural - state ] ] microarchitectural state + + + + + + + + + + + + + + + + + + + + + + + +    the microarchitectural components described above have in common that they maintain some state which is based on prior computation , either by caching raw data or instructions , or by implementing state machines that capture recent execution history .",
    "this state is functionally transparent , i.e.  it does not affect the results or outcomes of the programs . however , because this state is used to improve the performance of the program , it affects operation timing and is therefore visible through variations in the timing of program executions .",
    "[ [ timing - channels ] ] timing channels + + + + + + + + + + + + + + +    whenever this state is shared between different program executions there is a potential timing channel , as the timing of one program may depend on the execution history of another . in general",
    ", a channel will exist unless the state is either strictly partitioned between programs ( e.g.if the hardware tags the state with a program i d ) or flushed when switching the processor between programs ( context switch ) .",
    "[ [ covert - channels ] ] covert channels + + + + + + + + + + + + + + +    if those conditions are not met , then a trojan can , through its own execution , force the hardware into a particular state and a spy can probe this state by observing progress of its own execution against real time .",
    "this will constitute a covert channel , i.e.  an information flow bypassing the system s security policy .",
    "for example , the trojan can modulate its cache footprint , encoding data into the number of cache lines accessed .",
    "the spy can read out the information by observing the time taken to access each cache line . or the trojan can force the branch predictor state machine into a particular state , which the spy can sense by observing the latency of branch instructions ( and thus whether they are predicted correctly ) .",
    "the actual implementations of covert channels depend on the details of the particular microarchitectural feature they exploit .",
    "a large number of such implementations have been described , as surveyed by ge et al .",
    "@xcite .    historically , covert channels were mostly discussed within the scope of multilevel security ( mls ) systems  @xcite .",
    "such systems have users with different classification levels and the system is required to ensure that a user with a high security clearance , e.g.  a top secret classification , does not leak information to users with a lower clearance .",
    "the advent of modern software deployment paradigms , including cloud computing and app stores , increased the risk of covert channels and shifted some of the focus from military - grade systems to commercial and personal environments .",
    "covert channels break the isolation guarantees of cloud environments where workloads of several users are deployed on the same hardware .",
    "similarly , mobile devices rely on the system s security policy to ensure privacy whilst executing software of multiple , possibly untrustworthy developers .",
    "[ [ side - channels ] ] side channels + + + + + + + + + + + + +    the threat of microarchitectural channels is not restricted to environments compromised by trojans .",
    "side channel _ is a special case of a covert channel , which does not depend on a colluding trojan , but instead allows a spy program to recover sensitive information from a non - colluding _",
    "victim_. where they exist , side channels pose a serious threat to privacy and can be used to break encryption  @xcite .    in general",
    ", collusion allows better utilisation of the underlying hardware mechanism and hence covert channels tend to have much higher bandwidth than side channels based on the same microarchitectural feature ; the capacity of the covert channel is the upper bound of the corresponding side channel capacity .",
    "this means that closing covert channels implicitly eliminates side channels .",
    "for that reason we focus on covert channels in this work , as we aim to establish to which degree microarchitectural timing channels can be eliminated .",
    "we note that any timing channel that allow the spy to obtain address information from the trojan ( i.e.  which data or instructions it accesses ) can potentially establish a side channel  .",
    "[ [ p+p ] ] prime+probe + + + + + + + + + + +    prime+probe  @xcite is a specific and commonly used technique for exploiting set - associative caching elements as cache - based timing channels .",
    "it has been applied to the l1 d - cache  @xcite , l1 i - cache  @xcite , and the llc  @xcite .",
    "using the technique , the spy primes the cache by filling some of the cache sets with its own data .",
    "the trojan uses each of the sets that the spy primes to transmit one bit .",
    "for clear bits , the trojan leaves the spy s data in the set . for set bits ,",
    "the trojan replaces the spy s data with its own .",
    "the spy then probes the cache state to receive the information .",
    "it measures the time it takes to access the data it originally stored in them .",
    "a long access time indicates that some data in the cache set was replaced between the prime and the probe stages therefore the corresponding bit is set .",
    "a short access time indicates that the data is still cached thus the corresponding bit is clear .",
    "a microarchitectural timing channel can be eliminated if the underlying hardware state is either strictly partitioned or flushed .",
    "partitioning is possible , e.g.  in physically - addressed caches , using memory colouring  @xcite .",
    "this utilises the fact that in an associative cache , any particular memory location can only be cached in a specific set .",
    "the os can allocate physical memory to security domains such that they can not compete for the same cache sets .    where partitioning is not possible , e.g.  in virtually - addressed caches , such as the tlb , or where it is not possible to associate state with domains , as may be the case in the state machines used in the branch predictor or prefetcher , state must be flushed on a context switch .",
    "architectures generally provide instructions for flushing caches , but not for all of the other state .",
    "a frequently - suggested defence is injecting noise , e.g.  via random perturbations of the state  @xcite .",
    "while the approach reduces the usable capacity of channels , it can not eliminate the signal ( unless the noise anti - correlates with the transmitted signal ) and the cost of reducing the signal - noise ratio quickly becomes prohibitive  @xcite .",
    "furthermore , there are sophisticated channel implementations that are robust against noise  @xcite and covert channels have been demonstrated to work in noisy environments  @xcite .",
    "another countermeasure frequently suggested is to fuzz the clock  @xcite or to reduce its resolution  @xcite .",
    "we note that fuzzing the clock just introduces noise into the system , and thus has the same limitations as other ways of adding noise .",
    "covert channels have been implemented even in the absence of high - resolution clocks  @xcite .",
    "hence , these methods can not completely eliminate covert channels and are therefore not suitable for our purposes .",
    "our aim is not to minimise the cost of channel mitigation , but rather to establish whether they can be closed at all .",
    "we therefore use the ( costly ) brute - force approach of flushing any state that the hardware allows us to flush on each context switch .",
    "covert channels exploit shared hardware features to provide information flow between programs running in different security domains . as such they are independent of the operating system ( os ) or hypervisor separating the domains .",
    "the only role the os or hypervisor plays is in applying mitigations , trying to close the channels .",
    "therefore , the actual os or hypervisor used on the platform is of little importance , other than that it must allow implementation of the mitigations .    for our experiments we use the sel4 microkernel  @xcite , for a number of reasons .",
    "first , sel4 is a small ( about 10,000 lines of code ) and simple system , which makes it relatively easy to implement mitigations , compared to a large , complex system such as linux .",
    "furthermore , sel4 is specifically designed for use in security - critical system , and has undergone comprehensive formal verification , with proofs of implementation correctness and security enforcement  @xcite . in particular , sel4 has been proved free of storage channels  @xcite , which means any remaining channels must be timing channels , simplifying analysis of results .",
    "sel4 can be used as the basis of a general - purpose os , as a separation kernel  @xcite or as a hypervisor . in this work",
    "we use it as a separation kernel .",
    "this means that our setup contains the minimum amount of software , with our attack code running in a minimal environment directly on top of sel4 , with no actual os services .",
    "this avoids any interference from other software components .",
    "note that using sel4 as a hypervisor would expose the same microarchitectural channels , but possibly more .",
    "demonstrating channels in the separation - kernel setup implies more generality , as the same channels will exist in the virtualisation setup .",
    "in our threat model we assume that the adversary manages to executes a trojan program within a secure environment .",
    "for example , the adversary may compromise a service within the secure environment and inject the trojan s code .",
    "alternatively , the adversary may be , or may control , a corrupt developer that inserts malicious code into a software product used in the secure environment , e.g.  an app used to process private data on a smartphone . executing within the secure environment gives the trojan access to sensitive data which the adversary wants , however the security policies at the secure environment prevent data exfiltration by the trojan .    additionally , the adversary controls a spy program which executes on the same computer as the trojan , for example , in a different virtual machine .",
    "the spy is not executing within the same secure environment and consequently can communicate freely with the adversary , but it does not have access to the sensitive data .",
    "the adversary s aim is to exploit a microarchitectural covert channel in the shared hardware .",
    "if such a channel exists and is not controlled by the system , the trojan can use the channel to send the sensitive data to the spy , which can then send the data to the adversary . in this work we check whether the system can prevent the adversary from exploiting such covert channels .    as indicated in",
    ", we focus in this work on channels that can be exploited by trojan and spy time - sharing a processor core .",
    "this allows us to ignore _ transient - state _ channels  @xcite , i.e.  those that exploit the limited bandwidth of processor components .",
    "transient - state channels rely on concurrent execution of the trojan and the spy and are therefore automatically excluded in the time - sharing scenario .",
    "we thus only need to handle _ persistent - state _ channels , which rely on exhausting the storage capacity of processor elements . in a typical persistent - state channel",
    ", the spy sets the targeted component to a known state .",
    "the trojan executes , modifying the state based on the data to transmit .",
    "the spy then uses operations whose timing depends on the state of the component to measure the modifications the trojan made and recover the data .",
    "because persistent - state channels require storage in the targeted element , they often target caching elements .",
    "example of targeted elements include the data caches  @xcite , instruction caches  @xcite , tlb  @xcite , and bpu  @xcite .    as we are exploring microarchitectural channels , we ignore timing channels that are controlled by software .",
    "for example , the trojan could create a timing channel by varying its execution time before yielding the processor .",
    "we note that the system can protect against such channels by padding the execution time of the trojan following a yield  @xcite .",
    "moreover , because we investigate the processor s ability to close the channel , we only investigate channels within the processor itself .",
    "external channels , such as the dram open rows channel  @xcite , are outside the scope of this work .",
    "in this work we examine the level of support that manufacturers provide for eliminating microarchitectural timing channels in their processors . to this purpose , we implement multiple covert channels , identify the processor instructions and available information that can be used for mitigating the channels , and measure the capacity of the channel with and without the mitigation techniques .",
    "these steps are described in greater details below .      following cock et al .",
    "@xcite , we view a channel as a pipe into which a sender ( the trojan ) places _ inputs _ drawn from some set @xmath1 and which a receiver ( the spy ) observes as _ outputs _ from a set @xmath2 .",
    "both the inputs and the outputs depend on the specific covert channel used .",
    "we implement four channels , each designed to target a specific microarchitectural component . but note that as these components are not isolated from the rest of the processor , the channels are affected by components other than those targeted .",
    "we target the following channels :    * l1 data cache * this channel uses the prime+probe attack technique described in on the l1 d - cache  @xcite .",
    "the input symbols consist of numbers between 0 and the number of sets in the cache . to send a symbol @xmath3",
    ", the trojan reads data to fill cache sets @xmath4 , completely filling these sets .",
    "the spy performs the prime+probe attack by first filling the whole cache with its own data and then measuring the time to read the data from each cache set .",
    "the output symbol is the sum of the read measurements .",
    "for the implementation we adapt the l1 prime+probe attack of the mastik toolkit  @xcite to the processors we use .",
    "note that we could use a more sophisticated encoding of the input symbols to increase capacity .",
    "however , the point is not to establish the maximum channel capacity , but to investigate whether it can be closed .",
    "we therefore keep things as simple as possible .",
    "[ s : encoding ]    * l1 instruction cache * here we use the prime+probe attack on the l1 i - cache  @xcite .",
    "the approach is identical to the l1 d - cache channel , except that instead of reading data , the programs execute code in memory locations that map to specific cache sets .",
    "the implementation also uses an adaptation of the mastik code .",
    "* translation lookaside buffer * to implement a tlb - based channel , our trojan sends an input symbol consisting of a number between 0 and 128 ( the size of the arm tlb and twice the size of the x86 tlb ) . to send a symbol , @xmath3",
    ", the trojan reads a single integer from each of @xmath3 pages .",
    "the spy measures the time to access a number of pages . in order to reduce self - contention in the spy",
    ", it only accesses half of the tlb ( 64 or 32 pages , respectively )",
    ".    a more sophisticated design would take into account the structure of the tlb and aim to target the individual associative sets .",
    "as before , we opted for simplicity rather than capacity .",
    "the only prior implementation of a tlb - based channel is  @xcite , which use an intra - process tlb side channel to bypass the protection of kernel address space layout randomisation ( kaslr ) .",
    "we are not aware of any prior implementation of inter - process tlb channels and past work consider such channels infeasible because the tlb is flushed on context switch  @xcite .",
    "* branch prediction * the branch prediction channel exploits the processor s history buffer . in each time slice",
    ", the trojan sends a single - bit input symbol .",
    "both the trojan and the spy use the same channel code for sending and receiving .",
    "the code , shown in , consists of a sequence of conditional forward branches that are always taken ( line  8) .",
    "these set the history to a known state .",
    "the next code segment ( lines 1017 ) measures the time it takes to perform a branch ( line  13 ) that conditionally skips over 256 ` nop ` instructions ( line  14 ) .",
    "the branch outcome depends on the least significant bit of register ` % edi ` .",
    "the return value of the code ( register ` % eax ` ) is the measured time .    [ cols= \"",
    "> , < \" , ]     in some cases the explanation for the remaining channels is straightforward .",
    "for example , intel architectures do not support any method of clearing the state of the bpu .",
    "consequently , the branch prediction channel remains unchanged even when we enable all of the protection provided by the processor .",
    "in other cases the story is more intricate .",
    "we now look at some examples .",
    "we now continue the investigation of the arm cortex a9 l1 i - cache channel that we started in .",
    "recall that shows that even when we flush the caches , we can see a horizontal transition between two distinct distributions , indicating that a channel exists .    in the arm cortex a9 ,",
    "the distance between two addresses that map to the same cache set , known as the cache _ stride _ ( and equal to the cache size divided by associativity ) , is 8kib .",
    "clearly , the transition in occurs at 4kib , which matches the page size .",
    "this may indicate that the channel originates not from the cache itself , but from some part of the virtual memory unit , for example , from the tlb .",
    "hence , clearing the tlb can , potentially , eliminate this channel .    .",
    "[ f : cm - a9-l1i - all ] ]    .",
    "[ f : avg - a9-l1i - all ] ]    when applying all of the countermeasures available on the arm cortex a9 processor , including flushing the caches , btb and tlb and disabling the prefetcher , we get the channel matrix in .",
    "the channel is still significant , as is clearly evident from .",
    "input values smaller than 14 result in below - average output symbols , whereas symbols in the range 15 - 50 produce above - average output .",
    "while the channel matrix demonstrate the existence of a channel , it does not show the cause of the channel .",
    "one possible explanation for the channel is that the processor maintains some state that is not cleared by flushing the caches and is not deactivated when disabling the prefetcher .",
    "an alternative explanation is that the state is maintained outside the processor , for example resulting from a dram open - row channel  @xcite .    to investigate further",
    ", we look at different indicators : we use the performance monitoring unit ( pmu ) to count the l1 i - cache refill operations executed during the probe .",
    "as we have the prefetcher disabled , these refills should be independent of timing .    ]",
    "shows the results . comparing with , we see consistent variations in the range below an input value of 50 .",
    "as these refills are triggered by internal processor state , we can preclude external effects , such as dram latency .      without countermeasures , the channel that exploits this cache behaves as expected , as is evident from .    .",
    "[ f : cm - sb - l1i - none ] ]    because this is a cache channel , we can reasonably expect that invalidating the caches on the context switch would eliminate the channel .",
    "as in the case of the arm cortex a9 processor , the channel matrix with this countermeasure ( ) shows a much reduced channel . however , as on the arm cortex a9 , the channel matrix still shows horizontal variation , indicating a small but definite remaining channel .    .",
    "[ f : cm - sb - l1i - wbinvd ] ]    we further evaluate the channel when flushing the tlb and disabling the prefetcher , but a distinct channel still remains , as shown in .    .",
    "[ f : cm - sb - l1i - all ] ]      .",
    "[ f : cm - hw - l1i - none ] ]    on the haswell microarchitecture , the l1 i - cache channel is comparatively small , see .",
    "surprisingly , disabling the prefetcher _ increases _ the capacity of the channel ( ) .",
    "it seems that between sandy bridge and haswell , intel modified the prefetcher and possibly the branch predictor , leading to better masking of l1-cache latencies , thus reducing the effectiveness of the attack .    .",
    "[ f : cm - hw - l1i - pref ] ]    enabling all mitigations fails to close the channel , but still _ decreases _ it , from a capacity of 0.65b to 0.25b .",
    "the channel is clearly evident in    .",
    "[ f : cm - hw - l1i - all ] ]      ]    we now turn our attention to the branch prediction channel . recall that in the channel implementation ( ) , there are only two potential input values ,  0 and  1 , corresponding to a branch taken and not - taken .",
    "shows the distribution of output values for each of these input values both without and with mitigations .",
    "we first note that for both cases , the distribution of the output symbols for inputs 0 and  1 are clearly distinct . for the non - mitigated case ,",
    "the median output value for input 0 is 36 cycles whereas the median output for input  1 is  60 .",
    "mitigation changes the access times because code now needs to be brought from memory , rather than from the l1 i - cache .",
    "however , the output values for inputs  0 and  1 are even more apart than in the case of no mitigation , with median output values being 172 and  244 , respectively .    ]    like the sandy bridge processor , the haswell processor ( ) shows clearly distinct output distributions for the different input symbols . unlike the sandy bridge processor , on haswell we do not see such a large difference between the output values for the mitigated and the non mitigated cases .",
    "we believe that the haswell prefetches soon - to - be - executed instructions even when prefetching is disabled .      .",
    "[ f : cm - sb - tlb - none ] ]    the last channel we investigate uses the tlb . on the sandy bridge architecture , shows a very distinct channel , despite the non - global tlb entries being flushed on the context switch due to updating the ` cr3 ` register ( we run in 32-bit mode where the tlb is untagged and flushed by the hardware on each context switch ) .",
    "this is in contrast to the common belief that the tlb channel is not a threat to virtualised environments because of the mandatory flush  @xcite . for good measure , we explicitly flush global entries as well , but the effect is minimal as shown in .",
    "surprisingly , invalidating the cache does remove most of the channel , leaving only a small residual channel , as shown in .    .",
    "[ f : cm - sb - tlb - tlb ] ]    .",
    "[ f : cm - sb - tlb - wbinvd ] ]",
    "as we can see from the results , deploying all of the available method of processor state sanitisation still leaves high capacity channels .",
    "the countermeasures we deployed are often suggested for mitigating the exact channels we use  @xcite . yet , in contrast with the popular belief , we find that despite some being prohibitively inefficient  @xcite , these countermeasures fail at eliminating the channels .",
    "we further find that none of the channels is completely eliminated even when we deploy all of the available countermeasures .",
    "the capacity of the residual channels may be small , but they still exist .    .",
    "[ f : cm - sb - l1d - all ] ]    as an example , the capacity of the residual intel sandy bridge l1-d channel ( ) is 0.038 , with a potential error of up to 0.025 .",
    "that means that on average , a computationally unbounded adversary will require between 26 and 40 input symbols to transfer a single bit . with a transfer rate of 500 symbols per second ,",
    "the bandwidth of the channel is at most 19 bits per second .",
    "while such a capacity may seem small and insignificant , we note that , as we indicated earlier , we did not build the channel to achieve high capacity .",
    "consequently , further engineering is likely to better exploit the underlying source of leakage and achieve a much higher capacity .",
    "moreover , for high - security systems , even channels with capacities below one bit per second may pose a threat .",
    "for example , the orange book  @xcite recommends that channels with a bandwidth above 0.1 bits per second are audited .",
    "the main issue with these low - capacity residual channels is that we do not understand them . evidently , there is some state within the processor , but we do not know what this state is and how to manage it . consequently , there is a real possibility that better understanding of this state will enable higher - bandwidth exploits .",
    "the only way to rule out such a possibility is through understanding the root cause of the channel .",
    "in this work we investigate intra - core covert channels in modern cpus .",
    "we implemented five different covert channels and measure their capacity on two microarchitecture implementations of each of the two most popular isas , x86 and arm .",
    "we identified processor tools to mitigate these covert channels , but demonstrated that these tools are not sufficient .",
    "we find and that high - capacity channels remain in every architecture , even when implementing the most drastic ( and expensive ) countermeasures .",
    "it goes without saying that even if we were able to fully close a channel , this would not guarantee that there is no other hardware state that could be exploited , or that more sophisticated exploits of the same state would not succeed .",
    "we therefore have to conclude that , in the absence of improved architectural support for covert channel mitigation , these modern processors are not suitable for security - critical uses where a processor core is time - multiplexed between different security domains .",
    "this work only explores the tip of the iceberg .",
    "we have limited ourselves to intra - core channels in a time - sharing scenario . in doing that we ignored all transient - state covert channels attacks and all attacks that rely on state outside the processor .",
    "the inevitable conclusion is that security is a losing game until the hardware manufacturers get serious about it and provide the right mechanisms for securely managing shared processor state .",
    "this will require additions to the isa that allow any shared state to be either partitioned or flushed .",
    "we would like to thank dr stephen checkoway who helped uncovering documentation on processor functionality ."
  ],
  "abstract_text": [
    "<S> we investigate how different categories of microarchitectural state on recent arm and x86 processors can be used for covert timing channels and how effective architecture - provided mechanisms are in closing them . </S>",
    "<S> we find that in recent intel processors there is no effective way for sanitising the state of the branch prediction unit and that , contrary to often held belief , flushing the translation lookaside buffer on intel processors does nothing to mitigate attacks based on this component . we further show that in both arm and x86 architectures flushing all the hardware caches is not effective to close cache - based timing channels . </S>",
    "<S> the implication of this is that secure sharing of a processor core in these architectures is not possible , irrespective of cost .    </S>",
    "<S> = 1 </S>"
  ]
}