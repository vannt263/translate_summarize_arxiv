{
  "article_text": [
    "websites get hacked , whenever they are subject to a vulnerability that is known to the attacker , whenever they can be discovered efficiently , and , whenever the attacker has efficient means of hacking at his disposal .",
    "this combination of _ knowledge _ , _ opportunity _ , and _",
    "tools _ is quite crucial in shaping the way a group of sites receives unwanted attention by hackers .",
    "unfortunately , as an observer we are not privy to either one of these three properties .",
    "exploits are first discovered by highly skilled hackers who will use them for their own purposes for an extended period of time , as long as there is an ample supply of hackable sites that can be discovered efficiently .",
    "once the _ opportunity _ for such hacks diminishes due to exhausted supply , the appropriate vulnerabilities are often published . the available tools increase and they are added to the repertoire of popular rootkits , at the ready disposal of script kiddies who will attempt to attack the remaining sites . the increased availability of _ tools _ often offsets the reduced _ opportunity _ to yield a secondary wave of infections .    in a nutshell ,",
    "the above leads to the following statistical assumptions on how vulnerability of sites and the infectious behavior occurs .",
    "firstly , sites are only practically vulnerable once a vulnerability is discovered .",
    "second , as time passes , the propensity of an attack might increase or not , but changes in attack behavior are discrete rather than gradual .",
    "we propose a novel hazard regression model that provides a clear description of the probability a site getting hacked conditioned on its time - varying features , therefore allowing prediction tasks such as finding websites at risk , or inferential tasks such as attributing attacks to certain features as well as identifying change points of the activations of certain features to be conducted with statistical rigor .",
    "[ [ related - work . ] ] related work .",
    "+ + + + + + + + + + + + +    the primary strategy for identifying web - based malware has been to detect an active infection based on features such as small iframes  @xcite .",
    "this approach has been pursued by both academia ( e.g.  ) and industry ( e.g.  @xcite ) .",
    "@xcite propose a data driven ( linear classification ) approach to identify software packages that were being targeted by attackers to predict the security outcome of websites .",
    "hazard regression aims to estimate the chances of survival of a particular event with covariates @xmath1 , as a function of time , such as to better understand the effects of @xmath1 . instead of directly modeling the cumulative survival distribution ,",
    "people are interested in the instantaneous rate of dying of any @xmath1 at any given time @xmath2 , i.e. hazard rate @xmath3 .",
    "the density of dying at time @xmath2 is given by @xmath4 this leads to a differential equation for the survival probability with solution @xmath5    in our case , death amounts to a site being infected and @xmath3 is the rate at which such an infection occurs .",
    "an extremely useful fact of hazard regression is that it is additive .",
    "that is , if there are two causes with rates @xmath6 and @xmath7 respectively , it allows us to add the rates and this leads to @xmath8 and @xmath9 .",
    "the reason why this is desirable in our case follows from the fact that we may now model @xmath6 as the sum of attacks in a generalized linear form .",
    "most hazard regression approaches are based on the cox s propotional hazard model @xmath10  @xcite , including parametric models , and nonparametric models with baseline hazard rate @xmath11 unspecified  @xcite .",
    "the proportional assumption may not hold because of the time - varying effect of covariates  @xcite . as a result ,",
    "time - dependent effect models that allow @xmath12 as functions over time for each feature are proposed .",
    "typically people developed time functions based on fractional polynomials  @xcite , or spline functions  @xcite . due to the huge parameter space , techniques like reduced rank methods  @xcite and structured penalized methods  @xcite are studied .",
    "however those works either search for global smoothing functions or need to pre - specify knots .",
    "typically they work on tens of features .",
    "our work inspired by hacking campaigns aims to identify discrete attack behaviors .",
    "we show the optimal solutioin is a 0th order spline with knots adaptively chosen over continuous time .",
    "the blacklist may not always immediately discover whether a site has been taken over .",
    "the probability that this happens in some time interval @xmath13 $ ] is given by @xmath14 , named `` interval censoring '' . on another hand",
    ", the absence of evidence of an infection does not mean the evidence of absence .",
    "in other words , all we know is that the site survived until time @xmath15 , named `` right censoring '' . the probability is thus given by @xmath16 .",
    "time @xmath15 denotes the end of the observation . given intervals",
    "@xmath13 $ ] of likely infection for site @xmath17 , at time @xmath15 we have the following likelihood for the observed data : @xmath18 it remains to specify the hazard function @xmath3 .",
    "we do not wish to make strong parametric assumptions , but since @xmath19 is high - dimensional , estimating @xmath3 completely non - parametrically is intractable .",
    "we thus make an additive assumption and expand the hazard function into an inner product @xmath20 this is still an extremely rich class of functions as @xmath21 can be different over time and @xmath22 is allowed to be any univariate nonnegative functions over continuous time .",
    "furthermore , based on our intuition , @xmath3 is not a smoothly changing function , but can jump suddenly in response to certain events .",
    "it may not have a small or even bounded lipschitz constant .",
    "we therefore constrain complexity of the function class via total variations ( tv ) .",
    "then we can learn the model by solving the variational penalized maximum likelihood problem below : @xmath23,t\\in \\r , \\delta\\in \\r_+   \\end{aligned}\\ ] ] where @xmath24 is the indicator of censoring type for observation @xmath25 , i.e. interval - censored or right - censored ; @xmath26 is the associated censoring time ; @xmath27 is the evaluation of function @xmath28 at time @xmath2 .",
    "note that the monotone constraint is optional and can be removed to form a `` non - monotone '' model .",
    "there , only issue is that is an infinite dimensional function optimization problem and could be very hard to solve .",
    "the following theorem provides a finite set of simple basis functions that can always represent at least one of the solution to .",
    "[ thm : repre ] assume no observations are uncensored , feature @xmath21 for each user is piecewise constant over time with finite number of change points .",
    "let @xmath29 be the step function at @xmath30 .",
    "there exists an optimal solution @xmath31 of the above problem such that for each @xmath32 , @xmath33    for some set",
    "@xmath34 that collects all censoring boundaries and places where feature @xmath35 changes , and coefficient vector @xmath36 .",
    "the direct consequence of theorem  [ thm : repre ] is that we can now represent piecewise constant functions by vectors in @xmath37 and solve by solving a tractable finite dimensional fused lasso problem ( with an optional isotonic constraints ) of the form : @xmath38 where we abuse the notation to denote @xmath28 as evaluations of function @xmath28 at sorted time points in @xmath34 ; and @xmath39 is the discrete difference operator .",
    "we evaluate the out - of - sample predictive power measured by log - likelihood and conduct case studies of learned latent hazard rate on real data via domain expert s knowledge .",
    "the data used for evaluation was sourced from the work of soska et al .",
    "@xcite and was compromised as a collection of interval censored sites from backlists and right censored sites randomly sampled from .com domains  .",
    "all the sites were drawn from the wayback machine when archives were available at appropriate dates .",
    "a total of _ 49,347 _ blacklists were collected between 2011 to 2013 , include a blacklist of predominately phishing , and search redireciton attacks  @xcite .",
    "the .com zone files during the same period are randomly sampled , served as right censored sites with a total of _",
    "336,671_.    we automatically extracted raw tags and attributes from webpages , that served as features ( a total of _ 159,000 _ features ) .",
    "these tags and attributes could be like < br > , or < meta > wordpress 2.9.2</meta>. our corpus of features corresponds to a very large set of distinct and diverse software packages or content management systems .",
    "the baseline method is the classic cox proportional model ( cox )  @xcite which have been extensively used for hazard regression and survival analysis .",
    "it s parametrized based on the features with constant coeffcients over time .",
    "we use `` @xmath40 '' to denote the model penalized with @xmath41 .",
    "an experimental comparison between our models and cox on the aforementioned dataset are reported in figure  [ fig : real - convergence ] ( * left * and * right * ) .",
    "apparently the cox model underfit the data quite a bit .",
    "our `` monotone '' model allows only monotone hazard rate underfit the data a little but still significantly outperforms cox .",
    "it is well expected that `` non - monotone '' model without any constraint overfit the data severely .",
    "`` @xmath40+non - monotone '' model which is well regularized performs the best .",
    "this result clearly shows that the latent hazard rate recovered by our model is much better than the cox s model . to achieve such accuracy , our model uses only around 3 times parameter size compared with cox model .          in this section , we manually inspect the model s ability to automatically discover known security events .",
    "figure  [ fig : real - case ] ( * left * ) demonstrates some of the differences between the monotone and non - monotone models by following the hazard assigned to features that correspond to wordpress 3.5.1 . in early 2013 ,",
    "our dataset recorded a few malicious instances of wordpress 3.5.1 sites ( among some benign ones ) .",
    "these initial samples appeared to be part of a small scale test or proof of concept by the adversary to demonstrate their ability to exploit the platform .",
    "both models detect these security events and respond by assigning a non - zero hazard .",
    "following the small scale test was a lack of activity for a few weeks , during which the non - monotone model relaxes its hazard rate back down to zero , just before an attack campaign on a much larger scale is launched .",
    "this example illustrates once a vulnerability for a software package is known , that package is always at risk , even if it is not actively being exploited . on the other hand ,",
    "the non - monotone model captures the notion that adversaries tend to work in batches or attack campaigns .",
    "previous work  @xcite has shown that it is economically efficient for adversaries to compromise similar sites in large batches , and after a few attack campaigns , most vulnerable websites tend to be ignored .",
    "this phenomena is shown in figure  [ fig : real - case ] ( * left * ) where wordpress 3.2.1 was attacked in late 2011 and then subsequently ignored with the exception of a few small attacks that were likely orthogonal to the underlying software and any observable content features .",
    "it can be observed from figure  [ fig : real - case ]  ( * right * ) that a number of distinct wordpress distributions experienced a change - point in the summer of 2011 .",
    "this phenomina was present in several of the most popular versions of wordpress in the dataset including versions 2.8.5 , 2.9.2 and 3.2.1 .",
    "this type of correlation between the hazard of features corresponding to different versions of a software package is expected .",
    "this correlation often occurs when adversaries exploit vulnerabilities which are present in multiple versions of a package , or plugins and third party add - ons that share compatibility across the different packages .",
    "in this paper , we propose a novel survival analysis - based approach to model the latent process of websites getting hacked over time . the proposed model attempts to solve a variational total variation penalized optimization problem , and",
    "we show that the optimal function can be linearly represented by a set of step functions with the jump points known to as ahead of time .",
    "the results suggest that by correctly recovering the latent hazard rate , our model significantly outperforms the classic cox model .",
    "compared with known time - dependent hazard regression models , our models work on several orders of larger feature space .",
    "most importantly , identifying the changes of each feature s susceptibility over time can help people understand the latent hacking campaigns and leverage these insights to take appropriate actions .    in future",
    ", further works can be made to study the relations among potential correlated features by investigating the structures ( e.g. low rank ) of the coefficient matrix @xmath42 , or via deeper transformation .",
    "on the other hand , the same model ( variants ) can be used in many other settings to study consumer spending behaviors , marriage , animal habits and so on .",
    "borgolte , kevin , kruegel , christopher , and vigna , giovanni .",
    "delta : automatic identification of unknown web - based infection campaigns . in _",
    "acm sigsac conference on computer & communications security _ , pp .   109120 .",
    "acm , 2013 .",
    "sauerbrei , willi , royston , patrick , and look , maxime . a new proposal for multivariable modelling of time - varying effects in survival data based on fractional polynomial time - transformation . _ biometrical journal _ , 490 (",
    "3):0 453473 , 2007 ."
  ],
  "abstract_text": [
    "<S> in this paper we describe an algorithm for predicting the websites at risk in a long range hacking activity , while jointly inferring the provenance and evolution of vulnerabilities on websites over continuous time . specifically , we use hazard regression with a time - varying additive hazard function parameterized in a generalized linear form . </S>",
    "<S> the activation coefficients on each feature are continuous - time functions constrained with total variation penalty inspired by hacking campaigns . </S>",
    "<S> we show that the optimal solution is a @xmath0th order spline with a finite number of adaptively chosen knots , and can be solved efficiently . </S>",
    "<S> experiments on real data show that our method significantly outperforms classic methods while providing meaningful interpretability . </S>"
  ]
}