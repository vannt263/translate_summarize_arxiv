{
  "article_text": [
    "independent subspace analysis ( isa ) , also known as multidimensional independent component analysis @xcite , is a generalization of independent component analysis ( ica ) .",
    "isa assumes that certain sources depend on each other , but the dependent groups of sources are still independent of each other , i.e. , the independent groups are multidimensional .",
    "the isa task has been subject of extensive research @xcite . in this case",
    ", one assumes that the hidden sources are independent and identically distributed ( i.i.d . ) in time .",
    "temporal independence is , however , a gross oversimplification of real sources including acoustic or biomedical data .",
    "one may try to overcome this problem , by assuming that hidden processes are , e.g. , autoregressive ( ar ) processes .",
    "then we arrive to the ar independent process analysis ( ar - ipa ) task @xcite .",
    "another method to weaken the i.i.d .",
    "assumption is to assume moving averaging ( ma ) .",
    "this direction is called blind source deconvolution ( bsd ) @xcite , in this case the observation is a temporal mixture of the i.i.d . components .",
    "the ar and ma models can be generalized and one may assume arma sources instead of i.i.d . ones .",
    "as an additional step , the method can be extended to non - stationary integrated arma ( arima ) processes , which are important , e.g. , for modelling economic processes @xcite .    in this paper",
    ", we formulate the ar- , ma- , arma- , arima - ipa generalization of the isa tasks , when ( i ) one allows for multidimensional hidden components and ( ii ) the dimensions of the hidden processes are not known .",
    "we show that in the undercomplete case , when the number of ` sensors ' is larger than the number of ` sources ' , these tasks can be reduced to the isa task .",
    "the isa task can be formalized as follows : @xmath0\\in{\\ensuremath{\\mathbb{r}}}^{d_e } \\label{eq : e_concat}\\end{aligned}\\ ] ] and @xmath1 is a vector concatenated of components @xmath2 .",
    "the total dimension of the components is @xmath3 .",
    "we assume that for a given @xmath4 , @xmath5 is i.i.d . in time @xmath6 , and sources @xmath7 jointly independent , i.e. , @xmath8 , where @xmath9 denotes the mutual information ( mi ) of the arguments .",
    "the dimension of observation @xmath10 is @xmath11 .",
    "assume that @xmath12 , and @xmath13 is of full column rank .",
    "under these conditions , one may assume without any loss of generality that both the observed ( @xmath10 ) and the hidden ( @xmath14 ) signals are white .",
    "for example , one may apply principal component analysis ( pca ) as a preprocessing stage .",
    "then the ambiguities of the isa task are as follows @xcite : sources can be determined up to permutation and up to orthogonal transformations within the subspaces .",
    "we are to uncover the independent subspaces .",
    "our task is to find a matrix @xmath15 such that @xmath16 , @xmath17 $ ] , @xmath18 \\in { \\ensuremath{\\mathbb{r}}}^{d_e^m}$ ] , @xmath19 with the condition that components @xmath20 are independent . here",
    ", ( i ) @xmath21 denotes the @xmath22 coordinate of the @xmath23 estimated subspace , and ( ii ) @xmath24 can be chosen to be orthogonal because of the whitening assumption .",
    "this task can be solved by means of cost function that aims to minimize the mutual information between components : @xmath25 one can rewrite @xmath26 as follows : @xmath27 the first term of the r.h.s . is the ica cost function ; it aims to minimize mutual information for all coordinates .",
    "the other term is a kind of _ anti - ica _ term ; it aims to maximize mutual information within the subspaces .",
    "one may try to apply a heuristics and to optimize in order : ( 1 ) start by any infomax ica algorithm and minimize the first term of the r.h.s . in .",
    "( 2 ) apply only permutations to the coordinates such that they optimize the second term . in this second step",
    "coordinates are not changed , but may decrease further . surprisingly , this heuristics leads to the global minimum of in many cases .",
    "in other words , in many cases , ica that minimizes the first term of the r.h.s .",
    "of solves the isa task apart from the grouping of the coordinates into subspaces .",
    "this feature was observed by cardoso , first @xcite .",
    "the extent of this feature is still an open issue .",
    "nonetheless , we call it ` _ _ separation theorem _ _ ' , because for elliptically symmetric sources and for some other distribution types one can prove that it is rigorously true @xcite .",
    "( see also , the result concerning local minimum points @xcite ) .",
    "although there is no proof for general sources as of yet , a number of algorithms applies this heuristics with success @xcite .",
    "another issue concerns the computation of the second term of .",
    "if the @xmath28 dimensions of subspaces @xmath7 are known then one might rely on multi - dimensional entropy estimations @xcite , but these are computationally expensive .",
    "other methods deal with implicit or explicit pair - wise dependency estimations @xcite .",
    "interestingly , if the observations are indeed from an ica generative model , then the minimization of the pair - wise dependencies is sufficient to get the solution of the ica task according to the darmois - skitovich theorem @xcite .",
    "this is not the case for the isa task , however .",
    "there are isa tasks , where the estimation of pair - wise dependencies is insufficient for recovering the hidden subspaces @xcite .",
    "nonetheless , such algorithms seem to work nicely in many practical cases .",
    "a further complication arises if the @xmath28 dimensions of subspaces @xmath7 are not known .",
    "then the dimension of the entropy estimation becomes uncertain .",
    "methods that try to apply pair - wise dependencies were proposed to this task .",
    "one can find a block - diagonalization method in @xcite , whereas @xcite makes use of kernel estimations of the mutual information .",
    "here we shall assume that the separation theorem is satisfied .",
    "we shall apply ica preprocessing .",
    "this step will be followed by the estimation of the pair - wise mutual information of the ica coordinates .",
    "these quantities will be considered as the weights of a weighted graph , the vertices of the graph being the ica coordinates .",
    "we shall search for clusters of this graph . in our numerical studies",
    ", we make use of kernel canonical correlation analysis @xcite for the mi estimation .",
    "a variant of the ncut algorithm @xcite is applied for clustering . as a result",
    ", the mutual information within ( between ) cluster(s ) becomes large ( small ) .",
    "the problem is that this isa method requires i.i.d .",
    "hidden sources .",
    "below , we show how to generalize the isa task to more realistic sources .",
    "finally , we solve this more general problem when the dimension of the subspaces is not known .",
    "we need the following notations : let @xmath29 stand for the time - shift operation , that is .",
    "the n order polynomials of @xmath30 matrices are denoted as .",
    "let @xmath31:=({\\mathbf}{i}-{\\mathbf}{i}z)^r$ ] denote the operator of the @xmath32 order difference , where @xmath33 is the identity matrix , @xmath34 , @xmath35 .",
    "now , we are to estimate unknown components @xmath7 from observed signals @xmath10 .",
    "we always assume that @xmath14 takes the form like in and that @xmath36 is of full column rank .    1 .",
    "ar - ipa : the ar generalization of the isa task is defined by the following equations : @xmath37 , where @xmath38 is an ar(p ) process i.e , @xmath39{\\mathbf}{s}={\\mathbf}{q}{\\mathbf}{e}$ ] , , and @xmath39:={\\mathbf}{i}_{d_s}-\\sum_{i=1}^{p}{\\mathbf}{p}_{i}z^{i}\\in { \\ensuremath{\\mathbb{r}}}[z]_{p}^{d_s\\times          d_s}$ ] .",
    "we assume that @xmath39 $ ] is stable , that is @xmath40 \\neq 0)$ ] , for all @xmath41 , @xmath42 . for @xmath43",
    "this task was investigated in @xcite .",
    "case @xmath44 is treated in @xcite .",
    "the special case of @xmath45 is the isa task .",
    "ma - ipa or blind subspace deconvolution ( bssd ) task : the isa task is generalized to blind deconvolution task ( moving average task , ma(q ) ) as follows : @xmath46{\\mathbf}{e}$ ] , where @xmath47=\\sum_{j=0}^{q}{\\mathbf}{q}_j z^j \\in { \\ensuremath{\\mathbb{r}}}[z]_{q}^{d_x\\times d_e}$ ] .",
    "arma - ipa task : the two tasks above can be merged into a model , where the hidden @xmath38 is arma(p , q ) : @xmath37 , @xmath39{\\mathbf}{s}={\\mathbf}{q}[z]{\\mathbf}{e}$ ] . here",
    "@xmath39\\in { \\ensuremath{\\mathbb{r}}}[z]_{p}^{d_s\\times d_s}$ ] , @xmath47\\in { \\ensuremath{\\mathbb{r}}}[z]_{q}^{d_s\\times d_e}$ ] .",
    "we assumed that @xmath39 $ ] is stable .",
    "thus the arma process is stationary .",
    "arima - ipa task : in practice , hidden processes @xmath38 may be non - stationary .",
    "arma processes can be generalized to the non - stationary case .",
    "this generalization is called integrated arma , or arima(p , r , q ) .",
    "the assumption here is that the @xmath32 difference of the process is an arma process .",
    "the corresponding ipa task is then @xmath48\\nabla^r[z]{\\mathbf}{s}={\\mathbf}{q}[z]{\\mathbf}{e}. \\label{eq : arima}\\end{aligned}\\ ] ]",
    "we show how to solve the above tasks by means of isa algorithms .",
    "we treat the arima task .",
    "others are special cases of this one . in what follows",
    ", we assume that : ( i ) @xmath39 $ ] is stable , ( ii ) the mixing matrix @xmath49 is of full column rank , and ( iii ) @xmath47 $ ] has left inverse .",
    "in other words , there exists a polynomial matrix such that @xmath50{\\mathbf}{q}[z]={\\mathbf}{i}_{d_e}$ ] .",
    "that under mild conditions @xmath47$]-has an inverse with probability 1 @xcite ; e.g. , when the matrix @xmath51 $ ] is drawn from a continuous distribution . ]",
    "the route of the solution is elaborated here .",
    "let us note that differentiating the observation @xmath10 of the arima - ipa task in eq .",
    "in @xmath32 order , and making use of the relation , the following holds : @xmath52{\\mathbf}{x}={\\mathbf}{a}\\left(\\nabla^r[z]{\\mathbf}{s}\\right ) , \\text { and } { \\mathbf}{p}[z]\\left(\\nabla^r[z]{\\mathbf}{s}\\right)&={\\mathbf}{q}[z]{\\mathbf}{e}.\\label{eq : obs2}\\end{aligned}\\ ] ] that is taking @xmath31{\\mathbf}{x}$ ] as observations , one ends up with an arma - ipa task .",
    "assume that @xmath12 ( undercomplete case ) .",
    "we call this task uarma - ipa .",
    "now we show how to transform the uarma - ipa task to isa .",
    "the method is similar to that of @xcite where it was applied for bsd .",
    "if the above assumptions are fulfilled then in the uarma - ipa task , observation process @xmath53 is autoregressive and its innovation @xmath54={\\mathbf}{a}{\\mathbf}{q}_0{\\mathbf}{e}(t)$ ] , where @xmath55 $ ] denotes the conditional expectation value .",
    "consequently , there is a polynomial matrix such that @xmath56{\\mathbf}{x}={\\mathbf}{a}{\\mathbf}{q}_0{\\mathbf}{e}$ ] .",
    "steps of the proof :    1 .   in the uarma - ipa task the following equations hold : @xmath57{\\mathbf}{s}&={\\mathbf}{q}[z]{\\mathbf}{e } , \\label{eq : hidden1b}\\\\      { \\mathbf}{x}&={\\mathbf}{a}{\\mathbf}{s } ,      \\end{aligned}\\ ] ] or equivalently @xmath58 non - degenerate linear transformation of an arma process is also arma .",
    "thus , observation process @xmath10 is an arma process . formally : substituting @xmath59 of eq .   into eq .   and then using the pseudoinverse of matrix @xmath49 and expression @xmath60 that follows from eq .",
    ", we have @xmath61 process @xmath1 is i.i.d , so the process @xmath53 is arma .",
    "we assumed that @xmath47 $ ] has left inverse and thus @xmath14 of eq .",
    "can be expressed from @xmath38 via multiplication with a polynomial matrix .",
    "one says that @xmath14 derives from @xmath38 by causal fir filtering .",
    "the same holds for @xmath10 because of eq .  :",
    "@xmath62{\\mathbf}{s}={\\mathbf}{p}^{'}[z]({\\mathbf}{a}^{-1}{\\mathbf}{x})=({\\mathbf}{p}^{'}[z]{\\mathbf}{a}^{-1}){\\mathbf}{x}=:{\\mathbf}{p}^{''}[z]{\\mathbf}{x},\\label{eq : e - from - x - finite - past}\\ ] ] and @xmath63 denotes the degree of the polynomials .",
    "3 .   the first term of the r.h.s . of the observation @xmath10 in eq .   is a linear expression of a _",
    "finite _ history of @xmath10 .",
    "equation   implies , that the second term , except @xmath64 , also belongs to the linear hull of the finite history of @xmath10 . formally : @xmath65{\\mathbf}{x})(t - j)\\\\              & \\in { \\mathbf}{a}{\\mathbf}{q}_0{\\mathbf}{e}(t ) + \\left<{\\mathbf}{x}(t-1),{\\mathbf}{x}(t-2),\\ldots,{\\mathbf}{x}(t-\\max(p , q+n))\\right>.         \\end{aligned}\\ ] ] 4 .",
    "@xmath1 is independent of @xmath66 .",
    "consequently , observation process @xmath53 is autoregressive with innovation @xmath64 .",
    "thus , ar fit of @xmath53 can be used for the estimation of @xmath64 .",
    "this innovation corresponds to the observation of an undercomplete isa model ( @xmath12)$ ] and @xmath49 in the uarma - ipa task implies that @xmath67 is of full column rank and thus the resulting isa task is well defined .",
    "] , which can be reduced to a complete isa ( @xmath68 ) using pca .",
    "finally , the solution can be finished by any isa procedure .",
    "the reduction procedure implies that hidden components @xmath7 can be recovered only up to the ambiguities of the isa task : components of ( identical dimensions ) can be recovered only up to permutations . within each subspaces",
    ", unambiguity is warranted only up to orthogonal transformations .",
    "the steps of our algorithm are summarized in table [ tab : pseudocode ] .",
    ".pseudocode of the undercomplete arima - ipa algorithm [ cols= \" < \" , ]",
    "in this section we demonstrate the theoretical results by numerical simulations .",
    "we created a database for the demonstration : hidden sources @xmath7 are 4 pieces of 2d , 3 pieces of 3d , 2 pieces of 4d and 1 piece of 5d stochastic variables , i.e. , @xmath69 .",
    "these stochastic variables are independent , but the coordinates of each stochastic variable @xmath7 depend on each other .",
    "they form a 30 dimensional space together @xmath70 . for the sake of illustration ,",
    "3d ( 2d ) sources emit random samples of uniform distributions defined on different 3d geometrical forms ( letters of the alphabet ) .",
    "the distributions are depicted in fig .",
    "[ fig : datbase3d ] ( fig .",
    "[ fig : datbase2d ] ) .",
    "30,000 samples were drawn from the sources and they were used to drive an arima(2,1,6 ) process defined by .",
    "matrix @xmath71 was randomly generated and orthogonal .",
    "we also generated polynomial @xmath47\\in { \\ensuremath{\\mathbb{r}}}[z]_5^{60 \\times 30}$ ] and stable polynomial @xmath39 \\in { \\ensuremath{\\mathbb{r}}}[z]_1^{60 \\times 60}$ ] randomly .",
    "the visualization of the 60 dimensional process is hard to illustrate : a typical 3d projection is shown in fig .",
    "[ fig : obs3d ] .",
    "the task is to estimate original sources @xmath7 using these non - stationary observations .",
    "@xmath32-order differencing of the observed arima process gives rise to an arma process .",
    "typical 3d projection of this arma process is shown fig .",
    "[ fig : diff_obs3d ] .",
    "now , one can execute the other steps of table  [ tab : pseudocode ] and these steps provide the estimations of the hidden components @xmath72 .",
    "estimations of the 3d ( 2d ) components are provided in fig .",
    "[ fig : est3d ] ( fig .",
    "[ fig : est2d ] ) . in the ideal case ,",
    "the product of matrix @xmath73 and the matrices provided by pca and isa , i.e. , @xmath74 is a block permutation matrix made of @xmath75 blocks .",
    "this is shown in fig .",
    "[ fig : hinton ] .",
    "+      we have generated another database using the facegen animation software . in our database",
    "we had 800 different front view faces with the 6 basic facial expressions .",
    "we had thus 4,800 images in total .",
    "all images were sized to @xmath76 pixel .",
    "figure  [ fig : facedatabase ] shows samples of the database .",
    "a large @xmath77 matrix was compiled ; rows of this matrix were 1600 dimensional vectors formed by the pixel values of the individual images .",
    "the _ columns _ of this matrix were considered as mixed signals .",
    "this treatment replicates the experiments in @xcite : bartlett et al . ,",
    "have shown that in such cases , undercomplete ica finds components resembling to what humans consider facial components .",
    "we were interested in seeing the components grouped by undercomplete isa algorithm .",
    "the observed 4800 dimensional signals were compressed by pca to @xmath78 dimensions and we searched for 4 pieces of isa subspaces using the algorithm detailed in table  [ tab : pseudocode ] .",
    "the 4 subspaces that our algorithm found are shown in fig .",
    "[ fig : kernelmi ] .",
    "as it can be seen , the 4 subspaces embrace facial components which correspond mostly to mouth , eye brushes , facial profiles , and eyes , respectively .",
    "we have extended the isa task to problems where the hidden components can be ar , ma , arma , or arima processes .",
    "we showed an algorithm that can identify the hidden subspaces under certain conditions .",
    "the algorithm does not require previous knowledge about the dimensions of the subspaces .",
    "the working of the algorithm was demonstrated on an artificially generated arima process , as well as on a database of facial expressions .",
    "z.  szab , b.  pczos , and a.  lrincz .",
    "separation theorem for @xmath79-independent subspace analysis with sufficient conditions . technical report , etvs lornd university , budapest , 2006 ."
  ],
  "abstract_text": [
    "<S> recently , several algorithms have been proposed for independent subspace analysis where hidden variables are i.i.d . processes . </S>",
    "<S> we show that these methods can be extended to certain ar , ma , arma and arima tasks . </S>",
    "<S> central to our paper is that we introduce a cascade of algorithms , which aims to solve these tasks without previous knowledge about the number and the dimensions of the hidden processes . </S>",
    "<S> our claim is supported by numerical simulations . as a particular application </S>",
    "<S> , we search for subspaces of facial components . </S>"
  ]
}