{
  "article_text": [
    "we consider a nonlinear regression model with observations @xmath9 where the errors @xmath10 satisfy @xmath11 , @xmath12 and @xmath13 for @xmath14 , @xmath15 , and the true value @xmath16 of the vector of model parameter @xmath5 belongs to  @xmath7 , a compact subset of @xmath17 such that @xmath18 , the closure of the interior of  @xmath19 . in a vector notation , we write @xmath20 where @xmath21 , @xmath22 , @xmath23 , and @xmath24 denotes the @xmath25-point exact design @xmath26 . the more general nonstationary ( heteroscedastic ) case where @xmath27 can easily be transformed into the model ( [ regression - model - vector ] ) with @xmath28 via the division of @xmath29 and @xmath30 by @xmath31 .",
    "we suppose that @xmath32 is twice continuously differentiable with respect to @xmath33 for any @xmath34 , a compact subset of @xmath35 . the model is assumed to be identifiable over @xmath36 ; that is , we suppose that @xmath37    we shall denote by @xmath38 the set of design measures @xmath39 , that is , of probability measures on @xmath36 . the information matrix ( for @xmath28 ) for the design @xmath24 at @xmath5 is @xmath40 and , for any @xmath41 , we shall write @xmath42 \\bigl[\\mp\\eta(x,\\mt ) /\\mp\\mt^\\top \\bigr ] \\xi(\\d x).\\ ] ] denoting @xmath43 the empirical design measure associated with @xmath24 , with @xmath44 the delta measure at @xmath45",
    ", we have @xmath46 . note",
    "that ( [ identifiable ] ) implies the existence of a @xmath41 satisfying the least - squares ( ls ) estimability condition @xmath47    given an exact @xmath25-point design @xmath24 , the set of all hypothetical means of the observed vectors @xmath48 in the sample space @xmath49 forms the expectation surface @xmath50 . since @xmath51 is supposed to have continuous first- and second - order derivatives in @xmath52 , @xmath53 is a smooth surface in @xmath49 with a ( local ) dimension given by @xmath54 $ ] . if @xmath55 ( which means full rank ) , the model  ( [ regression - model - vector ] ) is said regular . in regular models with no overlapping of @xmath53 , that is , when @xmath56 implies @xmath57 , the ls estimator @xmath58 is uniquely defined with probability one ( w.p.1 ) .",
    "indeed , when the distributions of errors @xmath10 have probability densities ( in the standard sense ) it can be proven that @xmath59 $ ] is unique w.p.1 ; see @xcite and @xcite ( @xcite ) , page  107 .",
    "however , there is still a positive probability that the function @xmath60 has a local minimizer different from the global one when the regression model is intrinsically curved in the sense of @xcite , that is , when @xmath53 is a curved surface in @xmath49 ; see @xcite ( @xcite ) .",
    "moreover , a curved surface can `` almost overlap '' ; that is , there may exist points @xmath5 and @xmath61 in @xmath7 such that @xmath62 is large but @xmath63 is small ( or even equals zero in case of strict overlapping ) .",
    "this phenomenon can cause serious difficulties in parameter estimation , leading to instabilities of the estimator , and one should thus attempt to reduce its effects by choosing an adequate experimental design .",
    "classically , those issues are ignored at the design stage and the experiment is chosen on the basis of asymptotic local properties of the estimator .",
    "even when the design relies on small - sample properties of the estimator , like in @xcite , a nonoverlapping assumption is used [ see @xcite , pages  66 and 157 ] which permits to avoid the aforementioned difficulties .",
    "note that putting restrictions on curvature measures is not enough : consider the case @xmath64 with the overlapping @xmath53 formed by a circle of arbitrarily large radius , and thus arbitrarily small curvature ( see the example in section  [ s : motivating - ex ] below )",
    ".    important and precise results are available concerning the construction of subsets of @xmath7 where such difficulties are guaranteed not to occur ; see , for example , @xcite ( @xcite ) ; however , their exploitation for choosing adequate designs is far from straightforward .",
    "also , the construction of designs with restricted curvatures , as proposed by @xcite , is based on the curvature measures of @xcite and uses derivatives of @xmath65 at a certain @xmath5 ; this local approach is unable to catch the problem of overlapping for two points that are distant in the parameter space .",
    "other design criteria using a second - order development of the model response , or an approximation of the density of @xmath66 [ @xcite ] , are also inadequate .",
    "the aim of this paper is to present new optimality criteria for optimum design in nonlinear regression models that may reduce such effects , especially overlapping , and are at the same time closely related to classical optimality criteria like @xmath0- , @xmath1- or @xmath2-optimality ( in fact , they coincide with those criteria when the regression model is linear ) .",
    "classical optimality criteria focus on efficiency , that is , aim at ensuring a precise estimation of @xmath5 , asymptotically , provided that the model is locally identifiable at @xmath5 . on the other hand ,",
    "the new extended criteria account for the global behavior of the model and enforce identifiability .",
    "an elementary example is given in the next section and illustrates the motivation of our work .",
    "the criterion of extended @xmath0-optimality is considered in section  [ s : extended - eopt ] ; its main properties are detailed and algorithms for the construction of optimal designs are presented .",
    "sections  [ s : e - c ] and [ s : e - g ] are , respectively , devoted to the criteria of extended @xmath1-optimality and extended @xmath2-optimality .",
    "several illustrative examples are presented in section  [ s : example ] .",
    "section  [ s : extensions ] suggests some extensions and further developments and section  [ s : conclusions ] concludes .",
    "[ ex1 ] suppose that @xmath67 $ ] and that , for any design point @xmath68 $ ] , we have @xmath69 with @xmath70 a known positive constant .",
    "we take @xmath71 ; the difficulties mentioned below are even more pronounced for values of @xmath72 closer to @xmath73 .",
    "we shall consider exclusively two - point designs @xmath74 of the form @xmath75 and denote @xmath76 the associated design measure , @xmath77 $ ] .",
    "we shall look for an optimal design , that is , an optimal choice of @xmath78 $ ] , where optimality is considered in terms of information .",
    "it is easy to see that for any design @xmath76 we have @xmath79 the expectation surface is then an arc of a circle , with central angle @xmath80 ; see figure  [ f : s_eta ] for the case @xmath81 .",
    "the model is nonlinear but parametrically linear since the information matrix @xmath82 for @xmath28 ( here scalar since @xmath5 is scalar ) equals @xmath83 and does not depend on @xmath5 . also , the intrinsic curvature ( see section  [ s : example ] ) is constant and equals @xmath84 , and the model is also almost intrinsically linear if @xmath70 gets large .     for @xmath67 $ ] , @xmath85 and @xmath86 .",
    "]    any classical optimality criterion ( @xmath87- , @xmath88- , @xmath0- ) indicates that one should observe at @xmath89 , and setting a constraint on the intrinsic curvature is not possible here .",
    "however , if the true value of @xmath5 is @xmath90 and @xmath91 is large enough , there is a chance that the ls estimator will be @xmath92 , and thus very far from @xmath16 ; see figure  [ f : s_eta ] .",
    "the situation gets even worse if @xmath72 gets closer to @xmath93 , since @xmath53 then almost overlaps .",
    "now , consider @xmath94 , see ( [ h_e ] ) , with @xmath95 .",
    "for all @xmath78 $ ] , the minimum of @xmath96 with respect to @xmath97 is obtained at @xmath98 , @xmath99 $ ] is then maximum in @xmath100 $ ] for @xmath101 .",
    "this choice @xmath102 seems preferable to @xmath89 since the expectation surface @xmath53 is then a half - circle , so that @xmath103 and @xmath104 are as far away as possible . on the other hand ,",
    "as shown in section  [ s : extended - eopt ] , @xmath105 possesses most of the attractive properties of classical optimality criteria and even coincides with one of them in linear models .",
    "figure  [ f : h_x_theta]-left shows @xmath96 as a function of @xmath5 for three values of @xmath80 and illustrates the fact that the minimum of @xmath96 with respect to @xmath97 is maximized for @xmath102 .",
    "figure  [ f : h_x_theta]-right shows that the design with @xmath89 ( _ dashed line _ ) is optimal locally at @xmath106 , in the sense that it yields the fastest increase of @xmath107 as @xmath5 slightly deviates from @xmath3 . on the other hand",
    ", @xmath108 maximizes @xmath109 ( _ solid line _ ) and realizes a better protection against the folding effect of @xmath53 , at the price of a slightly less informative experiment for @xmath5 close to @xmath3 .",
    "smaller values of @xmath80 ( _ dotted line _ ) are worse than  @xmath110 , both locally for @xmath8 close to @xmath3 and globally in terms of the folding of @xmath53",
    ".    the rest of the paper will formalize these ideas and show how to implement them for general nonlinear models through the definition of suitable design criteria that can be easily optimized .",
    "( _ left _ ) and @xmath111 ( _ right _ ) as functions of @xmath67 $ ] for @xmath85 , @xmath112 ( _ dotted line _ ) , @xmath113 ( _ dashed line _ ) and @xmath101 ( _ solid line _ ) . ]",
    "take a fixed point @xmath3 in @xmath7 and denote @xmath114 where @xmath115 denotes the norm in @xmath116 ; that is , @xmath117^{1/2}$ ] for any @xmath118 .",
    "when @xmath39 is a discrete measure , like in the examples considered in the paper , then @xmath119 is simply the sum @xmath120 .",
    "the extended @xmath0-optimality criterion is defined by @xmath121 to be maximized with respect to the design measure @xmath39 .    in a nonlinear regression model @xmath122",
    "depends on the value chosen for @xmath3 and can thus be considered as a local optimality criterion . on the other hand ,",
    "the criterion is global in the sense that it depends on the behavior of @xmath123 for @xmath5 far from @xmath124 .",
    "this ( limited ) locality can be removed by considering @xmath125 instead of ( [ phi_ee ] ) , but only the case of @xmath122 will be detailed in the paper , the developments being similar for @xmath126 ; see section  [ s : maximin - extended - eopt ] .    for a linear regression model with @xmath127 and @xmath128 , for any @xmath3 and any @xmath41 , we have @xmath129 , so that @xmath130,\\ ] ] the minimum eigenvalue of @xmath131 , and corresponds to the @xmath0-optimality criterion .    for a nonlinear model with @xmath132 , the ball with center @xmath3 and radius @xmath133",
    ", direct calculation shows that @xmath134.\\ ] ] in a nonlinear regression model with larger @xmath7 , the determination of an optimum design @xmath135 maximizing @xmath136 ensures some protection against @xmath137 being small for some @xmath5 far from @xmath3 .",
    "in particular , when @xmath138 then @xmath139 if either @xmath140 is singular or @xmath141 for some @xmath142 .",
    "therefore , under the condition ( [ identifiable ] ) , @xmath135 satisfies the estimability condition  ( [ estimability ] ) at @xmath143 and is necessarily nondegenerate , that is , @xmath144 is nonsingular , when @xmath145 ( provided that there exists a nondegenerate design in @xmath38 ) .",
    "notice that ( [ ee_rho - small ] ) implies that @xmath146 $ ] when @xmath7 contains some open neighborhood of @xmath3 .",
    "in contrast with the @xmath0-optimality criterion , maximizing @xmath147 in nonlinear models does not require computation of the derivatives of @xmath32 with respect to @xmath5 at @xmath3 ; see the algorithms proposed in sections  [ s : ee - lp ] and  [ s : ee - relax ] . also note that the influence of points that are very far from @xmath3 can be suppressed by modification of the denominator of ( [ h_e ] ) without changing the relation with @xmath0-optimality ;",
    "see section  [ s : extra k ] .    before investigating properties of @xmath122 as a criterion function for optimum design in the next section , we state a property relating @xmath136 to the localization of the ls estimator @xmath66 .",
    "[ th : localization - thls ] for any given @xmath97 , the ls estimator @xmath66 given by ( [ theta_ls ] ) in the model ( [ regression - model - vector ] ) satisfies @xmath148 with @xmath149 the empirical measure associated with the design @xmath24 used to observe  @xmath48 .",
    "the result follows from the following chain of inequalities : @xmath150    note that although the bound ( [ bound - mthls ] ) is tight in general nonlinear situations ( due to the possibility that @xmath53 overlaps ) , it is often pessimistic . in particular , in the linear regression model @xmath127 , direct calculation gives @xmath151 } \\bigl\\| \\yb-\\eta _ x ( \\mt)\\bigr\\| = \\frac{\\|\\yb-\\eta_x(\\mt)\\|}{\\sqrt{n } \\sqrt{\\phi _ { ee}(\\xi _ n)}},\\ ] ] where @xmath152 is the @xmath153 matrix with @xmath154th line equal to @xmath155 .",
    "we also have @xmath156 $ ] in intrinsically linear models ( with a flat expectation surface @xmath157 ) since then @xmath158 .    in the following",
    ", we shall omit the dependence in @xmath3 and simply write @xmath136 for @xmath147 when there is no ambiguity .",
    "as the minimum of linear functions of @xmath39 , @xmath122 is _ concave _ : for all @xmath159 and all @xmath160 $ ] , @xmath161\\geq(1-\\ma)\\phi_{ee}(\\xi)+\\ma\\phi _ { ee}(\\nu)$ ] .",
    "it is also _ positively homogeneous _ : @xmath162 for all @xmath41 and @xmath163 ; see , for example , @xcite , chapter  5 .",
    "the criterion of @xmath164-efficiency can then be defined as @xmath165 where @xmath135 maximizes @xmath136 .",
    "the concavity of @xmath122 implies the existence of directional derivatives and , due to the linearity in @xmath39 of @xmath166 , we have the following ; see , for example , @xcite .    for any @xmath159 , the directional derivative of the criterion @xmath122 at @xmath39 in the direction @xmath167",
    "is given by @xmath168 where @xmath169 .",
    "note that we can write @xmath170 , where @xmath171 ^ 2 - \\| \\eta ( \\cdot,\\mt)-\\eta(\\cdot,\\mt^0)\\|_\\xi^2}{\\|\\mt-\\mt^0\\|^2}.\\ ] ] due to the concavity of @xmath122 , a necessary and sufficient condition for the optimality of a design measure @xmath135 is that @xmath172 a condition often called `` equivalence theorem '' in optimal design theory ; see , for example , @xcite .",
    "an equivalent condition is as follows .",
    "[ th : eq - ee ] a design @xmath173 is optimal for @xmath122 if and only if @xmath174 \\\\[-8pt ] \\eqntext{\\mbox{for some measure $ \\mu^ * \\in\\sm\\bigl[\\theta_e\\bigl(\\xi _ { ee}^*\\bigr)\\bigr]$},}\\end{aligned}\\ ] ] the set of probability measures on @xmath175 .",
    "this is a classical result for maximin design problems ; see , for example , @xcite , section  2.6 .",
    "we have @xmath176 } \\int _",
    "\\sx\\int_{\\theta_e(\\xi ) } \\psi_{ee}(x,\\mt , \\xi ) \\mu(\\d\\mt ) \\nu(\\d x)\\nonumber \\\\",
    "& = & \\min_{\\mu\\in\\sm[\\theta_e(\\xi ) ] } \\sup_{\\nu\\in\\xi } \\int _",
    "\\sx\\int_{\\theta_e(\\xi ) } \\psi_{ee}(x,\\mt , \\xi ) \\mu(\\d\\mt ) \\nu(\\d x ) \\nonumber \\\\ & = & \\min_{\\mu\\in\\sm[\\theta_e(\\xi ) ] } \\max_{x\\in\\sx } \\int _ { \\theta_e(\\xi ) } \\psi_{ee}(x,\\mt,\\xi ) \\mu(\\d\\mt).\\end{aligned}\\ ] ] therefore , the necessary and sufficient condition ( [ cns_ee1 ] ) can be written as ( [ cns_ee2 ] ) .",
    "one should notice that @xmath177 is generally not obtained for @xmath167 equal to a one - point ( delta ) measure , which prohibits the usage of classical vertex - direction algorithms for optimizing @xmath122 .",
    "indeed , the minimax problem ( [ * minimax ] ) has generally several solutions @xmath178 for @xmath45 , @xmath179 , and the optimal @xmath180 is then a linear combination @xmath181 , with @xmath182 and @xmath183 ; see @xcite for developments on a similar difficulty in @xmath184-optimum design for model discrimination .",
    "this property , due to the fact that @xmath122 is not differentiable , has the important consequence that the determination of a maximin - optimal design can not be obtained via standard design algorithms used for differentiable criteria .    to avoid that difficulty , a regularized version @xmath185 of @xmath122 is considered in @xcite , sections  7.7.3 and 8.3.2 , with the property that @xmath186 for any @xmath41 ( the convergence being uniform when @xmath7 is a finite set ) , @xmath122 is concave and such that @xmath187 is obtained when @xmath167 is the delta measure @xmath188 at some @xmath189 ( depending on  @xmath39 ) .",
    "however , although @xmath185 is smooth for any finite @xmath190 , its maximization tends to be badly conditioned for large @xmath190 . in the next section ,",
    "we show that optimal design for @xmath122 reduces to linear programming when @xmath7 and @xmath36 are finite .",
    "this is an important property .",
    "an algorithm based on a relaxation of the maximin problem is then considered in section  [ s : ee - relax ] for the case where @xmath7 is compact .      to simplify the construction of an optimal design ,",
    "one may take @xmath19 as a finite set , @xmath191 ; @xmath136 can then be written as @xmath192 , with @xmath166 given by ( [ h_e ] )",
    ". if the design space @xmath36 is also finite , with @xmath193 , then the determination of an optimal design measure for @xmath122 amounts to the determination of a scalar @xmath194 and of a vector of weights @xmath195 , @xmath196 being allocated at @xmath178 for each @xmath197 , such that @xmath198^\\top $ ] is maximized , with @xmath199 and @xmath200 and @xmath194 satisfying the constraints @xmath201 \\\\[-8pt ] \\nonumber \\sum_{i=1}^\\ell w_i h_i\\bigl(\\mt^{(j)}\\bigr ) & \\geq & t,\\qquad j=1,\\ldots , m,\\end{aligned}\\ ] ] where we denoted @xmath202 ^ 2}{\\|\\mt -\\mt ^0\\|^{2}}.\\ ] ] this is a linear programming ( lp ) problem , which can easily be solved using standard methods ( for instance , the simplex algorithm ) , even for large @xmath203 and @xmath204 .",
    "we shall denote by @xmath205 the solution of this problem .",
    "we show below how a compact subset @xmath7 of @xmath17 with nonempty interior can be replaced by a suitable discretized version @xmath206 that can be enlarged iteratively .",
    "suppose now that @xmath36 is finite and that @xmath7 is a compact subset of @xmath17 with nonempty interior .",
    "in the lp formulation above , @xmath207 must satisfy an infinite number of constraints : @xmath208 for all @xmath97 ; see ( [ ctlp ] ) .",
    "one may then use the method of @xcite and consider the solution of a series of relaxed lp problems , using at step @xmath209 a finite set of constraints only , that is , consider @xmath210 finite .",
    "once a solution @xmath211 of this problem is obtained , using a standard lp solver , the set @xmath212 is enlarged to @xmath213 with @xmath214 given by the constraint ( [ ctlp ] ) most violated by @xmath215 , that is , @xmath216 where with a slight abuse of notation , we write @xmath217 ; see ( [ h_e ] ) , when @xmath39 allocates mass @xmath196 at the support point @xmath218 for all @xmath154 .",
    "this yields the following algorithm for the maximization of @xmath219 .",
    "take any vector @xmath220 of nonnegative weights summing to one , choose @xmath221 , set @xmath222 and @xmath223 .",
    "compute @xmath214 given by ( [ theta_k+1 ] ) , set @xmath224 .    use a lp solver to determine @xmath225 .    if @xmath226 , take @xmath227 as an @xmath228-optimal solution and stop ; otherwise @xmath229 , return to step 1 .",
    "the optimal value @xmath230 satisfies @xmath231 at every iteration , so that @xmath232 of step 3 gives an upper bound on the distance to the optimum in terms of criterion value .",
    "the algorithm can be interpreted in terms of the cutting - plane method .",
    "indeed , from ( [ h_e ] ) and ( [ h_i ] ) we have @xmath233 for any vector of weights @xmath200 . from the definition of @xmath234 in ( [ theta_k+1 ] ) , we obtain @xmath235 so that the vector with components @xmath236 , @xmath237 , forms a subgradient of @xmath122 at @xmath238 , which we denote @xmath239 below [ it is sometimes called supergradient since @xmath122 is concave ] . each of the constraints @xmath240 used in the lp problem of step 2 , with @xmath241 , can be written as @xmath242 therefore , @xmath227 determined at step 2 maximizes the piecewise - linear approximation @xmath243 of @xmath244 with respect to the vector of weights @xmath200 , and the algorithm corresponds to the cutting - plane method of @xcite .",
    "the only difficult step in the algorithm corresponds to the determination of @xmath214 in ( [ theta_k+1 ] ) when @xmath7 is a compact set .",
    "we found that the following simple procedure is rather efficient .",
    "construct a finite grid , or a space - filling design , @xmath245 in @xmath19 .",
    "then , for @xmath246 @xmath247 the optimal value @xmath248 can then be approximated by @xmath249 when the algorithm stops ( step 3 ) .",
    "the method of cutting planes is known to have sometimes rather poor convergence properties ; see , for example , @xcite ( @xcite ) , chapter  9 , @xcite ( @xcite ) , section  3.3.2 .",
    "a significant improvement consists in restricting the search for @xmath250 at step 2 to some neighborhood of the best solution obtained so far , which forms the central idea of bundle methods ; see @xcite , @xcite ( @xcite ) , chapters  910 .",
    "in particular , the level method of @xcite ( @xcite ) , section  3.3.3 , adds a quadratic - programming step to each iteration of the cutting planes algorithm presented above ; one may refer for instance to @xcite ( @xcite ) , section  9.5.3 , for an application of the level method to design problems .",
    "notice that any linear constraint on @xmath200 can easily be taken into account in addition to those in ( [ ctlp ] ) , so that the method directly applies to optimal design with linear cost - constraints ; see , for example , @xcite ( @xcite ) , section  4.2 .",
    "consider the case where one wants to estimate a scalar function of @xmath8 , denoted by @xmath251 , possibly nonlinear .",
    "we assume that @xmath252 denote @xmath253 and consider the design criterion defined by @xmath254 to be maximized with respect to the design measure @xmath39 .    when @xmath32 and the scalar function @xmath255 are both linear in @xmath5 , with @xmath256 , we get @xmath257 ^ 2}\\ ] ] and , therefore , @xmath258^{-1}$ ] , using the well - known formula@xmath259 ; cf .",
    "@xcite ( @xcite ) , equation  ( 10.4 ) .",
    "also , for a nonlinear model with @xmath132 and a design @xmath39 such that @xmath260 has full rank , one has @xmath261^{-1},\\ ] ] which justifies that we consider @xmath262 as an _ extended @xmath1-optimality criterion_. at the same time , in a nonlinear situation with larger @xmath7 the determination of an optimal design @xmath263 maximizing @xmath264 ensures some protection against @xmath265 being small for some @xmath5 such that @xmath255 is significantly different from @xmath266 .",
    "the condition ( [ identifiable ] ) guarantees the existence of a @xmath41 such that @xmath267 , and thus the ls estimability of @xmath255 at @xmath3 for @xmath263 , that is , @xmath268 see @xcite ( @xcite ) , section  7.4.4 .",
    "when @xmath7 contains an open neighborhood of @xmath3 , then @xmath269^{-1}$ ] .    similarly to @xmath122 ,",
    "the criterion @xmath270 is concave and positively homogeneous ; its concavity implies the existence of directional derivatives .    for any @xmath159 ,",
    "the directional derivative of the criterion @xmath270 at @xmath39 in the direction @xmath167 is given by @xmath271 where @xmath272 .",
    "a necessary and sufficient condition for the optimality of @xmath273 maximizing @xmath270 is that @xmath274 , which yields an equivalence theorem similar to theorem  [ th : eq - ee ] .",
    "when both @xmath7 and @xmath36 are finite , an optimal design for @xmath275 is obtained by solving a lp problem . compared with section  [ s : ee - lp ] , we simply need to substitute @xmath276 for @xmath277 and use @xmath278 ^ 2/| g(\\mt)- g(\\mt^0)|^{2}$ ] , @xmath197 , instead of ( [ h_i ] ) .",
    "also , a relaxation method similar to that in section  [ s : ee - relax ] can be used when @xmath7 is a compact subset of @xmath17 .",
    "following the same lines as above , we can also define an extended @xmath2-optimality criterion by @xmath279 ^ 2}.\\ ] ] the fact that it corresponds to the @xmath2-optimality criterion for a linear model can easily be seen , noticing that in the model ( [ regression - model - vector ] ) with @xmath127 we have @xmath280 \\biggr \\}^{-1 } & = & \\inf_{x\\in\\sx } \\bigl[\\mathbf{f}^\\top ( x ) \\mb ^{-1}(\\xi_n ) \\mathbf{f } ( x)\\bigr]^{-1 } \\\\ & = & \\inf_{x\\in\\sx } \\inf_{\\ub\\in\\mathbb{r}^p , \\ub^\\top \\mathbf{f}(x ) \\neq0 } \\frac { \\ub^\\top \\mb(\\xi_n)\\ub}{[\\mathbf{f}^\\top ( x)\\ub]^2 } \\\\ & = & \\inf_{\\ub\\in\\mathbb{r}^p } \\frac{\\ub^\\top \\mb(\\xi_n)\\ub } { \\max_{x\\in\\sx } [ \\mathbf{f}^\\top ( x)\\ub]^2},\\end{aligned}\\ ] ] where @xmath149 denotes the empirical design measure corresponding to @xmath24 , assumed to be nonsingular , and the second equality follows from @xcite ( @xcite ) , equation ( 10.4 ) .",
    "the equivalence theorem of @xcite indicates that @xmath88- and @xmath2-optimal designs coincide ; therefore , @xmath88-optimal designs are optimal for @xmath281 in linear models .",
    "moreover , the optimum ( maximum ) value of @xmath282 equals @xmath283 with @xmath284 .    in a nonlinear model , a design @xmath285 maximizing @xmath282 satisfies the estimability condition ( [ estimability ] ) at @xmath106 . indeed , @xmath286",
    "^ 2>0 $ ] for any @xmath142 from ( [ identifiable ] ) , so that there exists some @xmath41 such that @xmath287 . therefore , @xmath288 , and @xmath289 implies that @xmath290 for all @xmath291 , that is , @xmath143 from ( [ identifiable ] ) . notice that when @xmath7 contains an open neighborhood of @xmath3 , then @xmath292 for all @xmath41 .",
    "again , directional derivatives can easily be computed and an optimal design can be obtained by linear programming when @xmath7 and @xmath36 are both finite , or with the algorithm of section  [ s : ee - relax ] when @xmath36 is finite but @xmath7 has nonempty interior .",
    "note that there are now @xmath293 inequality constraints in ( [ ctlp ] ) , given by @xmath294 where now @xmath295 ^ 2 } { [ \\eta(x,\\mt)-\\eta(x,\\mt^0 ) ] ^2}.\\ ] ] also note that in the algorithm of section  [ s : ee - relax ] we need to construct two sequences of sets , @xmath212 and @xmath296 , with @xmath213 and @xmath297 at step 2 , and ( [ theta_k+1 ] ) replaced by @xmath298 ^ 2}\\ ] ] with @xmath299 the design measure corresponding to the weights @xmath300 .",
    "we shall use the common notation @xmath301 for a discrete design measure with @xmath203 support points @xmath302 and such that @xmath303 , @xmath304 . in the three examples considered",
    ", we indicate the values of the parametric , intrinsic and total measure of curvatures at @xmath3 ( for @xmath305 ) ; see tables  [ t : expw2001 ] , [ t : c - opt - achj93 ] and [ t : kw ] .",
    "they are not used for the construction of optimal designs , and the examples illustrate the fact that they provide information on the local behavior only ( at @xmath3 ) , so that a small curvature does not mean good performance in terms of extended optimality .",
    "they are given by @xmath306 \\sum_{i , j=1}^p u_i [ \\mp^2\\eta(\\cdot,\\mt)/\\mp\\mt_i\\,\\mp\\mt_j]u_j \\|_\\xi } { \\ub^\\top \\mb(\\xi,\\mt)\\ub } , \\\\",
    "c_{\\mathrm{par}}(\\xi,\\mt ) & = & \\sup_{\\ub\\in\\mathbb{r}^p-\\{\\0b\\ } } \\frac{\\| p_\\mt \\sum_{i , j=1}^p u_i [ \\mp^2\\eta(\\cdot,\\mt)/\\mp\\mt_i\\,\\mp\\mt_j]u_j \\|_\\xi } { \\ub^\\top \\mb(\\xi,\\mt)\\ub } , \\\\",
    "c_{\\mathrm{tot}}(\\xi,\\mt ) & = & \\sup_{\\ub\\in\\mathbb{r}^p-\\{\\0b\\ } } \\frac{\\| \\sum_{i , j=1}^p u_i [ \\mp^2\\eta(\\cdot,\\mt)/\\mp\\mt_i\\,\\mp\\mt_j]u_j \\|_\\xi } { \\ub^\\top \\mb(\\xi,\\mt)\\ub } \\\\ & \\leq & c_{\\mathrm{int}}(\\xi,\\mt)+ c_{\\mathrm{par}}(\\xi,\\mt),\\end{aligned}\\ ] ] with @xmath307 the projector @xmath308 and correspond to the original measures of nonlinearity of @xcite for @xmath305 , with an adaptation to the use of a design measure @xmath39 instead of an exact design @xmath26 .",
    "the connection with the curvature arrays of @xcite is presented in @xcite , section  5.5 ; a procedure for their numerical computation is given in @xcite .",
    "all computations are performed in matlab on a biprocessor pc ( 2.5 ghz ) with 64 bits , equipped with 32 gb ram .",
    "classical optimal designs ( @xmath88- , @xmath0- and @xmath1-optimality ) are computed with the cutting - plane method ; see @xcite ( @xcite ) , section  9.5.3 ; lp problems are solved with the simplex algorithm ; we use sequential quadratic programming for the local minimization of @xmath309 that yields @xmath214 in ( [ theta_k+1_v2])-(ii ) .",
    "[ ex2 ] this example is artificial and constructed to illustrate the possible pitfall of using a local approach ( here @xmath0-optimal design ) for designing an experiment .",
    "the model response is given by @xmath310 with @xmath311 ^ 2 $ ] and @xmath312 denoting the @xmath154th component of @xmath313 .",
    "we consider local designs for @xmath314 .",
    "one may notice that the set @xmath315 is the rectangle @xmath316\\times [ 1/4,1]$ ] , so that optimal designs for any isotonic criterion function of the information matrix @xmath131 are supported on the vertices @xmath317 , @xmath318 and @xmath319 of @xmath36 .",
    "the classical @xmath88- and @xmath0-optimal designs are supported on three and two points , respectively , @xmath320    when only the design points @xmath321 and @xmath322 are used , the parameters are only locally estimable .",
    "indeed , the equations in @xmath61 @xmath323 give not only the trivial solutions @xmath324 and @xmath325 but also @xmath326 and @xmath327 as roots of two univariate polynomials of the fifth degree ( with coefficients depending on @xmath5 ) .",
    "since these polynomials always admit at least one real root , at least one solution exists for @xmath61 that is different from @xmath5 .",
    "in particular , the vector @xmath328 gives approximately the same values as @xmath3 for the responses at @xmath329 and @xmath330 .",
    "direct calculations indicate that , for any @xmath5 , the maximum of @xmath331 with respect to @xmath332 is reached for a measure supported on @xmath333 , @xmath317 , @xmath318 and @xmath319 .",
    "also , the maximum of @xmath334 ^ 2 $ ] with respect to @xmath45 is attained on the same points .",
    "we can thus restrict our attention to the design space @xmath335 .",
    "we take @xmath336\\times[-2,2]$ ] and use the algorithm of section  [ s : ee - relax ] , with the grid @xmath245 of ( [ theta_k+1_v2])-(iii ) given by a random latin hypercube design with @xmath337 points in @xmath338 ^ 2 $ ] renormalized to @xmath7 [ see , e.g. , @xcite ] , to determine optimal designs for @xmath122 and @xmath339 .",
    "when initialized with the uniform measure on the four points of @xmath36 , and with @xmath340 , the algorithm stops after 46 and 15 iterations , respectively , requiring 0.67 s and 0.28 s in total , and gives the designs @xmath341    the performances of the designs @xmath342 , @xmath343 , @xmath344 and @xmath345 are given in table  [ t : expw2001 ] .",
    "the values @xmath346 indicate that @xmath0-optimal design is not suitable here , the model being only locally identifiable for @xmath347 .",
    "the parametric , intrinsic and total measures of curvature at @xmath3 ( for @xmath28 ) are also indicated in table  [ t : expw2001 ] .",
    "notice that the values of these curvature at @xmath3 do not reveal any particular difficulty concerning @xmath347 , but that the lack of identifiability for this design is pointed out by the extended optimality criteria .",
    "@lcccccd1.3c@ & & & & & & & + @xmath348 & * 0.652 * & 0.273 & @xmath349 & 0.108 & 1.10 & 0.541 & 1.22 + @xmath347 & 0.625 & * 0.367 * & 0 & 0 & 1.19 & 0 & 1.19 + @xmath135 & 0.453 & @xmath350 & @xmath351 & @xmath352 & 3.33 & 2.69 & 4.28 + @xmath285 & 0.540 & 0.195 & @xmath353 & * 0.340 * & 1.33 & 1.26 & 1.83 +    this example is very particular and situations where the model is locally , but not globally , identifiable are much more common : in that case , ( [ identifiable ] ) is only satisfied locally , for @xmath61 in a neighborhood of @xmath5 , and one may refer , for example , to @xcite for a precise definition and examples .",
    "the lack of global identifiability would then not be detected by classical optimal design , but the maximum of @xmath122 and @xmath281 would be zero for @xmath7 large enough , showing that the model is not globally identifiable .",
    "[ ex3 ] consider the regression model ( one - compartment with first - order absorption input ) used in @xcite , @xmath354 , \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber \\mt&=&(\\mt _ 1,\\mt _ 2 , \\mt_3)^\\top , \\qquad x\\in\\mathbb{r}^+,\\end{aligned}\\ ] ] with nominal parameters @xmath355 .",
    "the @xmath88- and @xmath0-optimal designs for @xmath3 are , respectively , given by @xmath356 see @xcite .",
    "we take @xmath7 as the rectangular region @xmath357\\times[0.03 , 0.08]\\times[3 , 6]$ ] and use the algorithm of section  [ s : ee - relax ] to compute an optimal design for @xmath122 ; the grid @xmath245 of ( [ theta_k+1_v2])-(iii ) is taken as a random latin hypercube design with @xmath337 points in @xmath338 ^ 3 $ ] renormalized to @xmath7 .",
    "the number of iterations and computational time depend on @xmath204 , the number of elements of @xmath36 .",
    "for instance , when @xmath36 is the finite set @xmath358 with @xmath359 , and the required precision @xmath360 equals @xmath361 , the algorithm initialized at the uniform measure on the three points 0.2 , 1 and 23 converges after 42 iterations in about 26 s. by refining @xmath36 iteratively around the support points of the current optimal design , after a few steps we obtain @xmath362 a similar approach is used below for the construction of optimal designs for @xmath270 and in example  [ ex4 ] for @xmath122 .",
    "the performances of the designs @xmath348 , @xmath347 and @xmath135 are indicated in table  [ t : c - opt - achj93 ] .",
    "one may notice that the design @xmath135 is best or second best for @xmath363 , @xmath364 and @xmath122 among all locally optimal designs considered .",
    "=    @ld2.3 d1.3d1.3ccd2.3d2.3d1.3d1.3d1.3d1.3d1.3@ & & & & & & & & & & & & + @xmath348 & & 0.191 & 0.178 & & & 23.43 & 18.31 & 0.361 & 0.356 & 0.526 & 0 & 0.526 + @xmath347 & 8.82 & & 0.274 & & & 15.89 & 10.35 & 0.675 & 0.667 & 0.370 & 0 & 0.370 + @xmath135 & 9.05 & 0.311 & & & & 16.62 & 11.03 & 0.656 & 0.644 & 0.358 & 0 & 0.358 + @xmath365 & 0 & 0 & 0 & & 0 & 0 & 0 & 0 & 0 + @xmath366 & 0.757 & & & & & & & & & 6.51 & 0 & 6.51 + @xmath367 & 0 & 0 & 0 & 0 & 0 & & 0 & 0 & 0 + @xmath368 & 7.86 & & & & & 28.82 & & 0.157 & 0.145 & 1.12 & 0.028 & 1.12 + @xmath369 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & & 0 + @xmath370 & 4.06 & 0.162 & 0.137 & & & 6.77 & 4.36 & 0.890 & & 1.11 & 0.263 & 1.14 + @xmath371 & 11.74 & 0.191 & 0.177 & & & 23.53 & 18.43 & 0.360 & 0.355 & 0.522 & 0 & 0.522 + @xmath372 & 2.74 & & & & & 1.12 & 0.864 & & & 1.82 & 0 & 1.82",
    "+ @xmath373 & 6.71 & & & & & 35.16 & 20.31 & 0.175 & 0.175 & 0.909 & 0 & 0.909 + @xmath374 & 3.31 & 0.118 & & & & 4.37 & 3.17 & 0.937 & 0.838 & 1.82 & 0 & 1.82 + @xmath375 & 11.08 & 0.179 & 0.159 & & & 21.15 & 15.93 & 0.338 & 0.335 & 0.505 & 0.056 & 0.507 + @xmath376 & 2.18 & & & & & 0.791 & 0.644 & & & 2.12 & 0.133 & 2.13 + @xmath377 & 9.45 & 0.162 & 0.134 & & & 20.05 & 16.28 & 0.385 & 0.358 & 0.753 & 0.118 & 0.761",
    "+ @xmath378 & 6.16 & 0.149 & & & & 6.60 & 6.13 & 0.615 & 0.587 & 1.22 & 0.256 & 1.25 +    the intrinsic curvature is zero for @xmath348 , @xmath347 and @xmath379 [ since they all have @xmath380 support points ] and the parametric curvatures at @xmath3 are rather small ( the smallest one is for @xmath135 ) .",
    "this explains that , the domain @xmath7 being not too large , the values of @xmath136 do not differ very much from those of @xmath381 $ ] .",
    "consider now the same three functions of interest as in @xcite : @xmath382 is the area under the curve , @xmath383 @xmath384 is the time to maximum concentration , @xmath385 and @xmath386 is the maximum concentration , @xmath387.\\ ] ] we shall write @xmath388 and denote @xmath389 the ( locally ) optimal design for @xmath390 which maximizes @xmath391^{-1}$ ] , for @xmath392 .",
    "the @xmath393 are singular and are approximately given by @xmath394 see @xcite .    for each function @xmath395 ,",
    "we restrict the search of a design @xmath396 optimal in the sense of the criterion @xmath270 to design measures supported on the union of the supports of @xmath397 , @xmath398 and @xmath393 .",
    "we then obtain the following designs : @xmath399    the performances of @xmath400 and @xmath401 , @xmath402 , are indicated in table  [ t : c - opt - achj93 ] , together with the curvature measures at @xmath3 for @xmath401 ( which are nonsingular ) .",
    "for each function @xmath403 of interest , the design @xmath404 performs slightly worse than @xmath400 in terms of @xmath1-optimality , but contrarily to @xmath400 , it allows us to estimate the three parameters @xmath5 and guarantees good estimability properties for @xmath390 for all @xmath97 . notice that , apart from the @xmath1-optimality criteria @xmath405 , all criteria considered take the value 0 at the @xmath1-optimal designs @xmath400 .",
    "the construction of an optimal design for @xmath270 thus forms an efficient method to circumvent the difficulties caused by singular @xmath1-optimal design in nonlinear models ; see @xcite , chapters  3 and 5 .",
    "one may also refer to @xcite for alternative approaches for the regularization of singular @xmath1-optimal designs .",
    "we conclude this example with a comparison with the average - optimal designs of @xcite that aim at taking uncertainty on @xmath124 into account .",
    "consider a prior distribution @xmath406 on the two components of @xmath5 that intervene nonlinearly in @xmath32 , and let @xmath407 denote the expectation for @xmath406 .",
    "@xcite indicate that when @xmath408 equals @xmath409 uniform on @xmath410\\times[\\mt_3 ^ 0 - 1 , \\mt_3 ^ 0 + 1]$ ] , the design that maximizes @xmath411\\}$ ] is @xmath412 and the designs that minimize @xmath413 , @xmath392 , are @xmath414 when @xmath408 equals @xmath415 uniform on @xmath416\\times [ \\mt_3 ^ 0 - 4 , \\mt_3 ^ 0 + 4]$ ] , the average - optimal designs are @xmath417 their performances are indicated in the bottom part of table  [ t : c - opt - achj93 ] .",
    "notice that the average - optimal designs for the vague prior @xmath415 are supported on more than three points and thus allow model checking ; this is the case too for the two designs @xmath368 and @xmath370 .",
    "however , contrary to average - optimal design , the number of support points of optimal designs for extended optimality criteria does not seem to increase with uncertainty measured by the size of @xmath7 : for instance , when @xmath418\\times[\\mt _ 2 ^ 0 - 0.04,\\mt _ 2 ^ 0 + 0.04]\\times[\\mt_3 ^ 0 - 4 , \\mt_3 ^ 0 + 4]$ ] , the optimal design for @xmath219 is still supported on three points , approximately 0.1565 , 1.552 and 19.73 , receiving weights 0.268 , 0.588 and 0.144 , respectively .    all average - optimal designs considered yield reasonably small curvatures at @xmath3 , although larger than those for @xmath398 and @xmath419",
    ". the performances of @xmath371 and @xmath420 are close to those of @xmath421 , and the most interesting features concern designs for estimation of functions of interest @xmath422 .",
    "the designs @xmath393 can not be used if @xmath142 and are thus useless in practice .",
    "the average - optimal designs @xmath423 perform significantly worse than @xmath424 in terms of @xmath425 for @xmath426 and  3 and in terms of @xmath405 for @xmath427 and 3 . on the other hand ,",
    "the designs @xmath428 , constructed for the precise prior @xmath409 , perform significantly better than @xmath429 in terms of @xmath430 for all @xmath154 .",
    "figure  [ f : ex3 ] presents @xmath431 as a function of @xmath5 , for the three designs @xmath374 ( _ dashed line _ ) , @xmath378 ( _ dash  dotted line _ ) and @xmath432 ( _ solid line _ ) , when @xmath433 , @xmath434 ( _ left _ ) and @xmath433 , @xmath435 ( _ right _ ) .",
    "note that the projection on the last two components of @xmath5 of the set @xmath7 used for extended @xmath1-optimality is intermediate between the supports of @xmath409 and @xmath415 .",
    "although average - optimal designs @xmath436 and extended - optimal designs @xmath429 pursue different objectives , the example indicates that they show some resemblance in terms of precision of estimation of @xmath422",
    ". the situation would be totally different in absence of global identifiability for @xmath422 , a problem that would not be detected by average - optimal designs ; see the discussion at the end of example  [ ex2 ] .     as a function of @xmath5 , for @xmath437 and",
    "@xmath438 ( _ left _ ) and @xmath433 , @xmath435 ( _ right _ ) ; @xmath439 in _ dashed line _",
    ", @xmath440 in _ dash  dotted line _ and @xmath441 in _ solid line_. ]    [ ex4 ] for the same regression model ( [ model_ex7 ] ) , we change the value of @xmath3 and the set @xmath7 and take @xmath442 and @xmath443\\times[0,5]\\times[0,5]$ ] , the values used by @xcite . with these values , from an investigation based on interval analysis , the authors report that for the 16-point design @xmath444 and the observations @xmath48 given in their table  13.1 , the ls criterion @xmath445 has a global minimizer ( the value we have taken here for @xmath3 ) and two other local minimizers in @xmath7 .",
    "the @xmath88- and @xmath0-optimal designs for @xmath3 are now given by @xmath446 using the same approach as in example  [ ex3 ] , with the grid @xmath245 of ( [ theta_k+1_v2])-(iii ) obtained from a random latin hypercube design with @xmath337 points in @xmath7 , we obtain @xmath447    to compute an optimal design for @xmath281 , we consider the design space @xmath448 ( with 161 points ) and use the algorithm of section  [ s : ee - relax ] with the grid @xmath245 of ( [ theta_k+1_v2])-(iii ) taken as a random latin hypercube design with @xmath449 points .",
    "the same design space is used to evaluate @xmath339 for the four designs above . for @xmath450 , the algorithm initialized at the uniform measure on @xmath36 converges after 34 iterations in about 52 s and",
    "gives @xmath451    @lccccd3.1d2.2d3.1@ @xmath452 & @xmath453 & @xmath454 & @xmath455 & @xmath456 & & & + @xmath457 & @xmath458 & @xmath459 & @xmath460 & @xmath461 & 180.7 & 15.73 & 181.3 + @xmath348 & @xmath462 & @xmath463 & @xmath464 & @xmath465 & 58.0 & 0 & 58.0 + @xmath347 & @xmath466 & @xmath467 & @xmath468 & @xmath469 & 50.7 & 0 & 50.7 + @xmath135 & @xmath470 & @xmath471 & @xmath472 & 0.114 & 54.6 & 0 & 54.6 + @xmath285 & @xmath473 & @xmath474 & @xmath475 & * 0.244 * & 69.7 & 10.7 & 69.9 +    the performances and curvature measures at @xmath3 of @xmath457 , @xmath476 , @xmath347 , @xmath135 and @xmath285 are given in table  [ t : kw ] .",
    "the large intrinsic curvature for @xmath457 , associated with the small values of @xmath477 and @xmath478 , explains the presence of local minimizers for the ls criterion , and thus the possible difficulties for the estimation of @xmath5 .",
    "the values of @xmath219 and @xmath281 reported in the table indicate that @xmath348 , @xmath347 , @xmath135 or @xmath285 would have caused less difficulties .",
    "the criterion @xmath147 can be written as @xmath479 \\\\[-8pt ] \\nonumber & & \\hspace*{218pt}\\mbox{for all } \\mt\\in \\theta\\bigr\\}.\\end{aligned}\\ ] ] instead of giving the same importance to all @xmath5 whatever their distance to @xmath3 , one may wish to introduce a saturation and reduce the importance given to those @xmath5 very far from @xmath3 , that is , consider @xmath480 \\\\[-8pt ] \\nonumber & &   \\hspace*{255pt}\\mbox { for all } \\mt\\in\\theta \\biggr\\ } \\label { ee - equiv - k}\\end{aligned}\\ ] ] for some @xmath481 .",
    "equivalently , @xmath482 , with @xmath483.\\ ] ] as in section  [ s : ee - def ] , we obtain @xmath484 $ ] in a linear model and , for a nonlinear model with @xmath485 , @xmath486 $ ] for any @xmath481 .",
    "moreover , in a nonlinear model with no overlapping @xmath487 can be made arbitrarily close to @xmath488 $ ] by choosing @xmath489 large enough , whereas choosing @xmath489 not too large ensures some protection against @xmath490 being small for some @xmath5 far from @xmath3 .",
    "also , properties of @xmath122 such as concavity , positive homogeneity , existence of directional derivatives ; see section  [ s : ee - prop ] , remain valid for @xmath491 , for any @xmath481 .",
    "the maximization of @xmath491 forms a lp problem when both @xmath36 and @xmath7 are finite ( see section  [ s : ee - lp ] ) and a relaxation procedure ( cutting - plane method ) can be used when @xmath7 is a compact subset of @xmath17 ; see section  [ s : ee - relax ] .",
    "a similar approach can be used with extended @xmath1- and @xmath2-optimality , which gives @xmath492 with @xmath493\\ ] ] and @xmath494 ^ 2 } \\biggr ] \\biggr\\},\\ ] ] for @xmath489 a positive constant .      the criterion",
    "defined by @xmath495 see ( [ phi_ee ] ) , ( [ h_e ] ) , accounts for the global behavior of @xmath123 for @xmath97 and obliterates the dependence on @xmath3 that is present in @xmath496 .",
    "the situation is similar to that in section  [ s : extended - eopt ] , excepted that we consider now the minimum of @xmath277 with respect to two vectors @xmath5 and @xmath3 in @xmath497 .",
    "all the developments in section  [ s : extended - eopt ] obviously remain valid ( concavity , existence of directional derivative , etc . ) , including the algorithmic solutions of sections  [ s : ee - lp ] and [ s : ee - relax ] .",
    "the same is true for the worst - case versions of @xmath270 and @xmath281 , respectively , defined by @xmath498 , see ( [ h_c ] ) , and by @xmath499 ^ 2 \\ } $ ] , and for the worst - case versions of the extensions of previous section that include an additional tuning parameter @xmath489 .    note that the criterion @xmath126 may direct attention to a particularly pessimistic situation .",
    "indeed , for @xmath7 a compact set with nonempty interior and @xmath500 the lebesgue measure on @xmath7 , one may have @xmath501 for all designs @xmath39 although @xmath502 for some design @xmath503 .",
    "this corresponds to a situation where the model is structurally identifiable , in the sense that the property ( [ identifiable ] ) is generic but is possibly false for @xmath5 in a subset of zero measure ; see , for example , @xcite .",
    "example  [ ex2 ] gives an illustration .    when the three polynomial equations @xmath504 , @xmath505 , @xmath506 are satisfied , then @xmath507 for all @xmath313 .",
    "since these equations have solutions @xmath508 in @xmath509 , @xmath510 for all @xmath41 . on the other hand , @xmath511 w.p.1 . when @xmath3 is randomly drawn with a probability measure having a density with respect to the lebesgue measure on @xmath7 .    in a less pessimistic version of worst - case extended @xmath0-optimality , we may thus consider a finite set @xmath512 for @xmath3 , obtained for instance by random sampling in  @xmath7 , and maximize @xmath513 .",
    "two essential ideas have been presented .",
    "first , classical optimality criteria can be extended in a mathematically consistent way to criteria that preserve a nonlinear model against overlapping , and at the same time retain the main features of classical criteria , especially concavity .",
    "moreover , they coincide with their classical counterpart for linear models .",
    "second , designs that are nearly optimal for those extended criteria can be obtained by standard linear programming solvers , supposing that the approximation of the feasible parameter space @xmath7 by a finite set is acceptable .",
    "a relaxation method , equivalent to the cutting - plane algorithm , can be used when @xmath7 is a compact set with nonempty interior .",
    "linear constraints on the design can easily be taken into account . as a by - product",
    ", this also provides simple algorithmic procedures for the determination of @xmath0- , @xmath1- or @xmath2-optimal designs in linear models with linear cost constraints .",
    "as it is usually the case for optimal design in nonlinear models , the extended - optimality criteria are local and depend on a guessed value @xmath3 for the model parameters . however , the construction of a globalized , worst - case version enjoying the same properties is straightforward ( section  [ s : maximin - extended - eopt ] ) .    finally , we recommend the following general procedure for optimal design in nonlinear regression .",
    "( i ) choose a parameter space @xmath7 corresponding to the domain of interest for @xmath5 , select ( e.g. , randomly ) a finite subset @xmath514 in the interior of @xmath7 ; ( ii ) for each @xmath3 in @xmath514 compute an optimal design @xmath515 maximizing @xmath147 and a @xmath0-optimal design @xmath398 maximizing @xmath516 ; ( iii ) if @xmath517 is close enough to @xmath518 for all @xmath3 in @xmath519 , one may consider that the risk of overlapping , or lack of identifiability in @xmath7 , is weak and classical optimal design that focuses on the precision of estimation can be used ; otherwise , a design that maximizes @xmath520 should be preferred . when the extended @xmath2-optimality criterion @xmath521 is substituted for @xmath522 , the comparison in ( iii ) should be between @xmath523 and @xmath524 , see section  [ s : e - g ] .",
    "extended @xmath1-optimality can be used when one is interested in estimating a ( nonlinear ) function of @xmath8 , the comparison in ( iii ) should then be with @xmath1-optimality .",
    "the authors thank the referees for useful comments that helped to significantly improve the paper ."
  ],
  "abstract_text": [
    "<S> among the major difficulties that one may encounter when estimating parameters in a nonlinear regression model are the nonuniqueness of the estimator , its instability with respect to small perturbations of the observations and the presence of local optimizers of the estimation criterion .    we show that these estimability issues can be taken into account at the design stage , through the definition of suitable design criteria . </S>",
    "<S> extensions of @xmath0- , @xmath1- and @xmath2-optimality criteria are considered , which when evaluated at a given @xmath3 ( local optimal design ) , account for the behavior of the model response @xmath4 for @xmath5 far from @xmath3 . in particular , they ensure some protection against close - to - overlapping situations where @xmath6 is small for some @xmath5 far from @xmath3 . </S>",
    "<S> these extended criteria are concave and necessary and sufficient conditions for optimality ( equivalence theorems ) can be formulated . </S>",
    "<S> they are not differentiable , but when the design space is finite and the set @xmath7 of admissible @xmath8 is discretized , optimal design forms a linear programming problem which can be solved directly or via relaxation when @xmath7 is just compact . </S>",
    "<S> several examples are presented . </S>"
  ]
}