{
  "article_text": [
    "the idea of the vmc method  @xcite is simply to calculate the multidimensional integrals appearing in quantum mechanics using a monte carlo numerical integration technique .",
    "the quantity of greatest interest is the variational energy associated with a hamiltonian @xmath0 and a wave function @xmath1 , which can be written as @xmath2 where @xmath3 is the _ local energy _ depending on",
    "the @xmath4 coordinates @xmath5 of the @xmath6 electrons , and @xmath7 is the normalized probability density . for simplicity of notation",
    "we have assumed that @xmath8 is real valued ; the extension to complex @xmath8 is straightforward .",
    "the variational energy can be estimated as the average value of @xmath9 on a sample of @xmath10 points @xmath11 sampled from the probability density @xmath12 , @xmath13 in practice , the points @xmath11 are sampled using the metropolis - hastings algorithm  @xcite .",
    "the advantage of this approach is that it does not use an analytical integration involving the wave function , and thus does not impose severe constraints on the form of the wave function .",
    "the wave functions usually used in qmc are of the jastrow - slater form , @xmath14 where @xmath15 is a jastrow factor and @xmath16 is a slater determinant or a linear combination of slater determinants is a function of the spatial coordinates @xmath5 only . ] .",
    "the jastrow factor is generally of the form @xmath17 .",
    "it depends explicitly on the interparticle distances @xmath18 , allowing for an efficient description of the so - called electron `` dynamic '' correlation .    in practice , the vmc method has two types of errors :    * a _ systematic error _",
    ", due to the use of an approximate wave function ( as in other wave - function methods ) , * a _ statistical uncertainty _ , due to the sampling of finite size @xmath10 ( which is specific to monte carlo methods ) .",
    "of course , the variational energy is an upper bound of the exact ground - state energy , but the systematic error is generally unknown , since its determination requires knowing the exact solution .",
    "by contrast , the statistical uncertainty can be easily estimated by the usual statistical techniques .",
    "for this , let us examine more closely the meaning of eq .",
    "( [ elav ] ) .",
    "the average of the local energy @xmath19 on a finite sample is itself a random variable , taking different values on different samples .",
    "the central limit theorem establishes that , if @xmath20 are random variables that are _ independent _",
    "( i.e. not correlated ) and _ identically distributed _ , with finite expected value @xmath21 $ ] and finite variance , @xmath22={\\ensuremath{\\text{e}}}[(e_{\\ensuremath{\\text{l}}}-e_\\text{v})^2]$ ] , then in the large @xmath10 limit the probability distribution of the random variable @xmath23 converges ( in the mathematical sense of convergence in distribution ) to a gaussian ( or normal ) distribution of expected value @xmath21 $ ] and variance @xmath22/m$ ] ,    @xmath24 = { \\ensuremath{\\text{e}}}[e_{\\ensuremath{\\text{l } } } ] = e_\\text{v},\\ ] ]    @xmath25 = \\frac{{\\ensuremath{\\text{v}}}[e_{\\ensuremath{\\text{l}}}]}{m}.\\ ] ]    this means that @xmath19 is an _ estimator _ of @xmath26 with a statistical uncertainty which can be defined by the standard deviation of its gaussian distribution @xmath27 = \\sqrt{{\\ensuremath{\\text{v}}}\\left[\\overline{e}_{\\ensuremath{\\text{l}}}\\right]}=\\sqrt{\\frac{{\\ensuremath{\\text{v}}}[e_{\\ensuremath{\\text{l}}}]}{m}}.\\ ] ] the meaning of this standard deviation is that the desired expected value @xmath26 has a probability of 68.3% of being in the interval @xmath28 $ ] , a probability of 95.5% of being in the interval @xmath29 $ ] , and a probability of 99.7% of being in the interval @xmath30 $ ] .",
    "note that , if the variance @xmath22 $ ] is infinite but the expected value @xmath21 $ ] is finite , then the law of large numbers guarantees the convergence of @xmath19 to @xmath21 $ ] when @xmath31 but with a statistical uncertainty which is more difficult to estimate and which decreases more slowly than @xmath32 .",
    "it is important to note that the statistical uncertainty decreases as @xmath32 _ independently of the dimension of the problem_. this is in contrast to deterministic numerical integration methods for which the convergence of the integration error deteriorates with the spatial dimension @xmath33 .",
    "for example , simpson s integration rule converges as @xmath34 ( provided the integrand has up to @xmath35-order derivatives ) , so that for @xmath36 monte carlo methods are more efficient for large @xmath10 .",
    "the statistical uncertainty is reduced if the variance of the local energy @xmath22 $ ] is small . in the limit that @xmath1 is an exact eigenfunction of @xmath0 , the local energy @xmath37 becomes exact , independent of @xmath5 , and thus its variance @xmath22 $ ] and the statistical uncertainty of @xmath19 vanish .",
    "this is known as the _ zero - variance _ property . since the systematic error ( or bias ) of the variational energy @xmath38 ( where @xmath39 is the exact energy ) also vanishes in this limit",
    ", there is a zero - bias property as well . for these reasons ,",
    "a great deal of effort has been expended on developing robust and efficient wave - function optimization methods .      in practice",
    ", the probability density @xmath12 is sampled with the metropolis - hastings algorithm which provides a sequence of points @xmath11 correctly distributed according to @xmath12 but _ sequentially ( or serially ) correlated _ ( i.e. non independent ) .",
    "this is a consequence of each point being sampled from a probability distribution conditional on the previous point .",
    "one can define an _ autocorrelation time _ ( defined more precisely later ) that is roughly speaking the average time for points to decorrelate .",
    "this sequential correlation must be taken into account when using the central limit theorem for evaluating the statistical uncertainty .",
    "this is done using the _ blocking _ technique , which is described next .",
    "let us consider a sequence of @xmath10 realizations @xmath40 ( sequentially correlated ) of a random variable @xmath41 of expected value @xmath42 $ ] and of variance @xmath43 $ ] .",
    "for example , @xmath41 could be the local energy @xmath37 .",
    "we divide this sequence into @xmath44 successive blocks of @xmath45 steps each .",
    "the _ block average _",
    "@xmath46 is @xmath47 the expected value of @xmath46 is also the expected value of @xmath41 , i.e. @xmath48=e[x]$ ] , but its variance is not simply @xmath49/m_{\\ensuremath{\\text{s}}}$ ] since the variables @xmath40 are not independent .",
    "we can now define the _ global average _",
    "@xmath50 of the whole sample as the average over all the blocks of the block averages @xmath51 where @xmath52 with a math subscript",
    " @xmath53 \" indicates the block average for the @xmath54 block ( whereas @xmath46 with a roman subscript  b \" indicates the generic random variable ) .",
    "the global average @xmath50 is another random variable with the same expected value as @xmath41 , i.e. @xmath55={\\ensuremath{\\text{e}}}\\left[\\overline{x}_{\\ensuremath{\\text{b}}}\\right]={\\ensuremath{\\text{e}}}[x]$ ] .",
    "if the length of the blocks is large compared to the autocorrelation time then the block averages @xmath52 can be considered as being independent , and the variance of the global average is simply @xmath56 = \\frac{{\\ensuremath{\\text{v}}}\\left[\\overline{x}_{\\ensuremath{\\text{b}}}\\right]}{m_{\\ensuremath{\\text{b}}}},\\ ] ] which leads to the statistical uncertainty of @xmath50 @xmath57=\\sqrt{{\\ensuremath{\\text{v}}}\\left[\\overline{x}\\right ] } = \\sqrt{\\frac{{\\ensuremath{\\text{v}}}\\left[{\\overline{x}_{\\ensuremath{\\text{b}}}}\\right]}{m_{\\ensuremath{\\text{b}}}}}.\\ ] ] in practice , the statistical uncertainty on a finite sample is calculated as @xmath58 \\approx \\sqrt{\\frac{1}{m_{\\ensuremath{\\text{b}}}-1 } \\left ( \\frac{1}{m_{\\ensuremath{\\text{b } } } } \\sum_{b=1}^{m_{\\ensuremath{\\text{b } } } } { \\overline{x}_b}^2 - \\left ( \\frac{1}{m_{\\ensuremath{\\text{b } } } } \\sum_{b=1}^{m_{\\ensuremath{\\text{b } } } } \\overline{x}_b\\right)^2 \\right)},\\ ] ] where the @xmath59 term appearing instead of @xmath44 is necessary to have an unbiased estimator of the standard deviation on the sample ( see the appendix ) .",
    "it takes into account the fact that the computed variance is relative to the sample average rather than the true expected value .",
    "finally , let us examine the variance @xmath60 $ ] .",
    "since the variables @xmath40 are not independent , the expansion of @xmath60 $ ] involves the covariances between the variables @xmath61 = \\frac{1}{m_{\\ensuremath{\\text{s}}}^2 } \\sum_{k , l } { \\ensuremath{\\text{cov}}}[x_k , x_l ] = \\frac{{\\ensuremath{\\text{v}}}[x]}{m_{\\ensuremath{\\text{s } } } } + \\frac{2}{m_{\\ensuremath{\\text{s}}}^2 } \\sum_{k < l } { \\ensuremath{\\text{cov}}}[x_k , x_l ] = t_{\\ensuremath{\\text{c}}}\\frac{{\\ensuremath{\\text{v}}}[x]}{m_{\\ensuremath{\\text{s}}}},\\ ] ] defining the autocorrelation time of @xmath41 @xmath62m_{\\ensuremath{\\text{s } } } } \\sum_{k < l } { \\ensuremath{\\text{cov}}}[x_k , x_l].\\ ] ] the autocorrelation time is equal to @xmath63 in the absence of correlation between the variables , i.e. @xmath64=0 $ ] for @xmath65 , but can be large in the presence of sequential correlation .",
    "it is instructive to express the statistical uncertainty as a function of @xmath66 @xmath58=\\sqrt{t_{\\ensuremath{\\text{c}}}\\frac{{\\ensuremath{\\text{v}}}[x]}{m_{\\ensuremath{\\text{s}}}m_{\\ensuremath{\\text{b } } } } }   = \\sqrt{t_{\\ensuremath{\\text{c}}}\\frac{{\\ensuremath{\\text{v}}}[x]}{m } } , \\label{sigmaavectc}\\ ] ] where @xmath67 is the total size of the sample .",
    "the expression  ( [ sigmaavectc ] ) allows one to interpret @xmath66 as a factor giving the number of effectively independent points in the sample , @xmath68 . in practice",
    ", it is useful to calculate the autocorrelation time as @xmath69/{\\ensuremath{\\text{v}}}[x]$ ] and check whether the length of the blocks is large enough for a correct estimation of the statistical uncertainty , e.g. @xmath70 .",
    "if @xmath45 is not much greater than @xmath66 , then the statistical uncertainty @xmath71 $ ] and the autocorrelation time @xmath66 will be underestimated .    in the appendix",
    ", we further explain how to estimate the statistical uncertainty of nonlinear functions of expectation values , which often occur in practice .",
    "the calculation cost required to reach a given statistical uncertainty @xmath71 $ ] is @xmath72}{\\sigma\\left[\\overline{x}\\right]^2}\\ ] ] where @xmath73 is the calculation time per iteration .",
    "the @xmath74 ^ 2 $ ] dependence implies that decreasing the statistical uncertainty by a factor of @xmath75 requires to increase the computational time by a factor of @xmath76 .",
    "this quadratic dependence directly stems from the central limit theorem and seems unavoidable rather than @xmath77 .",
    "however , they have not been used for qmc applications , in part because in qmc the sampled distributions , for systems with more than a few electrons , are very highly peaked . ] .",
    "however , one can play with the three other parameters :    * @xmath66 depends on the sampling algorithm and on the random variable @xmath41 . for efficient algorithms such as umrigar s one  @xcite ,",
    "the autocorrelation time of the local energy is close to @xmath63 and little further improvement seems possible ; * @xmath73 is usually dominated by the cost of evaluating @xmath41 .",
    "for the local energy , the evaluation cost depends on the form of the wave function ; * @xmath43 $ ] depends on the choice of the random variable @xmath41 with its associated probability distribution , the only constraint being that the expected value @xmath42 $ ] must equal the expectation value of the observable ( otherwise , this is a biased estimator ) .",
    "the choice of a good probability distribution is usually called _",
    "importance sampling_. even for a fixed probability distribution , it is possible to use various estimators for @xmath41 , some of which have smaller variance than others , since one has the freedom to add any quantity with zero expectation value .",
    "this has been exploited to construct improved estimators for diverse observables  @xcite .",
    "there is often a compromise to be found between a low computation time per iteration @xmath73 and a low variance @xmath43 $ ] .",
    "the probability density , @xmath7 , is generally complicated and can not be sampled by direct methods such as the transformation method or the rejection method . instead",
    ", the metropolis - hastings ( or generalized metropolis ) algorithm , which can be used to sample any known probability density , is used .",
    "it employs a stochastic process , more specifically , a markov chain .",
    "[ [ stochastic - process ] ] stochastic process + + + + + + + + + + + + + + + + + +    a _ stochastic process _ represents the evolution ",
    "say in `` time ''  of a random variable .",
    "it is described by a trajectory of successive points @xmath78 , @xmath79 , ... , @xmath80 with an associated probability distribution @xmath81 .",
    "the idea of evolution in time can be made more explicit by decomposing the probability of the whole trajectory in products of the conditional probability of having a particular point knowing that all the previous points have already been realized .",
    "for example , for @xmath82 , the probability of the trajectory is @xmath83    [ [ markov - chain ] ] markov chain + + + + + + + + + + + +    a _ markov chain _ is a stochastic process for which the conditional probability for the transition to a new point @xmath11 depends only on the previous point @xmath84 @xmath85 i.e. the process `` forgets '' the way it arrived at point @xmath84 .",
    "the probability of a trajectory can thus be simply written as , e.g. for @xmath82 , @xmath86 and @xmath87 is called the transition probability from point @xmath88 to point @xmath89 .",
    "note that , in general , the transition probability can depend on time ( measured by the index @xmath90 ) .",
    "we will consider here only the case of a stationary markov chain for which the transition probability is time independent .    in the following , we will use notation corresponding to the case of states @xmath11 in a continuous space ( `` integrals '' instead of `` sums '' ) , but we will ignore the possibly subtle mathematical differences between the continuous and discrete cases , and we will often use the vocabulary of the discrete case ( e.g. , `` matrix '' ) . the transition probability matrix",
    ", @xmath91 is a _ stochastic matrix _ , i.e. , it has the following two properties :    @xmath92    @xmath93    the second property expresses the fact that the probability that a point @xmath88 is somewhere at the next step must be @xmath63 .",
    "the eigenvalues of a stochastic matrix are between @xmath94 and @xmath63 , and there is at least one eigenvalue equal to @xmath63 .",
    "the latter property is a consequence of the fact that , for a column - normalized matrix , the vector with all components equal to one is a left eigenvector with eigenvalue @xmath63 .",
    "the target probability distribution @xmath12 is sampled by constructing a markov chain converging to @xmath12 .",
    "a necessary condition is that the distribution @xmath12 is a ( right ) eigenvector of @xmath87 with the eigenvalue @xmath63 @xmath95 where the second equality simply comes from the normalization condition  ( [ normalisation ] ) .",
    "( [ balance ] ) is a _ stationarity condition _ for @xmath12 .",
    "it means that if we start from the target distribution @xmath12 then we will continue to sample the same distribution by applying the markov chain .",
    "however , we need more than that .",
    "we want that any initial distribution @xmath96 , e.g. , a delta function at some initial point , evolves to the target stationary distribution @xmath12 by repeated applications of the transition matrix @xmath97 i.e. @xmath12 must be the dominant eigenvector of @xmath91 ( the unique eigenvector of largest eigenvalue )",
    ". if the stationarity condition  ( [ balance ] ) is satisfied then this will always be the case except if @xmath91 has several eigenvectors with eigenvalue @xmath63 .",
    "one can show that the matrix @xmath91 has only one eigenvector of eigenvalue @xmath63 if @xmath91 is a primitive matrix , i.e. if there is an integer @xmath98 such that all the elements of the matrix @xmath99 are strictly positive , @xmath100 .",
    "this means that it must be possible to move between any pair of states @xmath11 and @xmath101 in @xmath102 steps .",
    "this ensures that all states can be visited , and that the markov chain converges to the unique stationary distribution @xmath12 . the markov chain is then said to be _",
    "ergodic_.    in practice , instead of imposing the stationarity condition  ( [ balance ] ) , the markov matrix is constructed by imposing the more stringent _ detailed balance _",
    "condition , @xmath103 which forces the probability flux between the two states @xmath88 and @xmath89 to be the same in both directions .",
    "this is a sufficient ( but not necessary ) condition for @xmath12 to be the stationary distribution .",
    "a markov chain satisfying condition  ( [ detailedbalance ] ) is said to be reversible .    in practice ,",
    "a markov chain is realized by a _",
    "random walk_. starting from an initial point @xmath78 ( or walker ) ",
    "i.e. a delta - function distribution @xmath104  sample the second point @xmath79 by drawing from the probability distribution @xmath105 , then a third point @xmath106 by drawing from @xmath107 , and so on . after disregarding a certain number of iterations",
    "@xmath108 corresponding to a transient phase called _ equilibration _ , the random walk samples the stationary distribution @xmath12 in the sense that @xmath109 \\approx ( 1/m ) \\sum_{k=1}^m \\delta({\\ensuremath{\\mathbf{r}}}-{\\ensuremath{\\mathbf{r}}}_k)$ ] and the averages of the estimators of the observables of interest are calculated .",
    "the rate of convergence to the stationary distribution @xmath12 and the autocorrelation times of the observables are determined by the second largest eigenvalue of the matrix @xmath91 ( see , e.g. , ref .",
    "the random walk must be sufficiently long so as to obtain a representative sample of the states making a non negligible contribution to the expected values .",
    "if the transitions between states belonging to two contributing regions of the space of states are too improbable , as may happen for example for dissociated atoms , then there is a risk that the random walk remains stuck in a region of space and seems converged , even though the true stationary distribution is not yet reached . to avoid this problem , smart choices for the transition matrix can be crucial in various applications of monte carlo methods  @xcite .    [ [ metropolis - hastings - algorithm ] ] metropolis - hastings algorithm + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in the metropolis - hastings algorithm  @xcite , one realizes a markov chain with the following random walk . starting from a point @xmath88 , a new point @xmath89",
    "is determined in two steps :    1 .",
    "a temporary point @xmath110 is proposed with the probability @xmath111 , 2 .",
    "the point @xmath110 is accepted ( i.e. @xmath112 ) with probability @xmath113 , or rejected ( i.e. @xmath114 ) with probability @xmath115    the corresponding transition probability can be written as @xmath116 or , in a single expression , @xmath117 \\delta({\\ensuremath{\\mathbf{r}}}_{{\\ensuremath{\\text{i}}}}-{\\ensuremath{\\mathbf{r}}}_{\\ensuremath{\\text{f } } } ) .",
    "\\label{ptransition}\\ ] ] the proposal probability @xmath118 is a stochastic matrix , i.e. @xmath119 and + @xmath120 , ensuring that @xmath121 fulfils the non - negativity condition  ( [ nonnegativite ] ) . the second term in eq .",
    "( [ ptransition ] ) with the delta function ensures that @xmath121 fulfils the normalization condition  ( [ normalisation ] ) .",
    "the acceptance probability is chosen so as to fulfil the detailed balance condition  ( [ detailedbalance ] ) , for @xmath122 , @xmath123 several choices are possibles . the choice of metropolis _ et al .",
    "@xcite maximizes the acceptance probability @xmath124 the acceptance probability is not a stochastic matrix , even though both the proposal and the total markov matrices are stochastic . since only the ratio @xmath125",
    "is involved in eq .",
    "( [ paccmetropolis ] ) , it is not necessary to calculate the normalization constant of the probability density @xmath12 .",
    "it is clear that the acceptance probability of eq .",
    "( [ paccmetropolis ] ) is optimal , but there is considerable scope for ingenuity in choosing a proposal probability @xmath118 that leads to a small autocorrelation time .    [",
    "[ choice - of - the - proposal - probability ] ] choice of the proposal probability + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the original paper of metropolis _ et al . _",
    "@xcite employed a symmetric proposal matrix , in which case the proposal matrix drops out of the formula for the acceptance .",
    "the advantage of having a nonsymmetric proposal matrix was pointed out by hastings  @xcite .",
    "one has a lot of freedom in the choice of the proposal probability @xmath118 .",
    "the only constraints are that @xmath118 must be a stochastic matrix leading to an ergodic markov chain and that it must be possible to efficiently sample @xmath118 with a direct sampling method .",
    "the proposal probability determines the average size of the proposed moves @xmath126 and the average acceptance rate of these moves . in order to reduce sequential correlation",
    ", one has to make moves as large as possible but with a high acceptance rate . in practice , for a given form of the proposal matrix , there is a compromise to be found between the average size of the proposed moves and the average acceptance rate .",
    "the simplest choice for @xmath118 is a distribution that is uniform inside a small cube @xmath127 centered in @xmath128 and of side length @xmath129 and zero outside @xmath130 in practice , a move according to eq .",
    "( [ ppropcube ] ) is proposed , @xmath131 where @xmath132 is a vector of @xmath4 random numbers drawn from the uniform distribution between @xmath133 and @xmath63 .",
    "the size of the cube @xmath129 can be adjusted so as to minimize the autocorrelation time of the local energy , but the latter remains large and the sampling is inefficient .",
    "clever choices use information from the distribution @xmath12 , in particular its local gradient , to guide the sampling . a choice for @xmath118 which would lead to large moves with an acceptance probability equal to @xmath63 would be @xmath134 , independently from @xmath128 , but we would then be back to the initial problem of sampling a complicated distribution @xmath12 .",
    "a good choice for @xmath118 is the green function of the fokker - planck equation in the short - time approximation @xmath135 where @xmath136 is called the _ drift velocity _ of the wave function and @xmath137 is the time step which can be adjusted so as to minimize the autocorrelation time of the local energy . in practice ,",
    "a move according to eq .",
    "( [ ppropfokker - planck ] ) is proposed @xmath138 where @xmath139 is a vector of @xmath4 random numbers drawn from the gaussian distribution of average @xmath94 and standard deviation @xmath140 .",
    "the term @xmath139 describes an isotropic gaussian diffusion process ( or wiener process ) .",
    "the term @xmath141 is a drift term which moves the random walk in the direction of increasing @xmath142 .",
    "the optimal size of the move is smaller in regions where @xmath143 is changing rapidly .",
    "for example , @xmath143 has a discontinuity at the nuclear positions .",
    "hence , it is more efficient to make smaller moves for electrons in the core than for electrons in the valence regions . in doing this",
    ", care must be taken to ensure the detailed balance condition .",
    "an elegant solution is provided in the vmc algorithm of refs .",
    "@xcite where the electron moves are made in spherical coordinates centered on the nearest nucleus and the size of radial moves is proportional to the distance to the nearest nucleus .",
    "in addition , the size of the angular moves gets larger as one approaches a nucleus .",
    "this algorithm allows one to achieve , in many cases , an autocorrelation time of the local energy close to @xmath63 .",
    "[ [ expectation - values ] ] expectation values + + + + + + + + + + + + + + + + + +    the expectation value of an operator @xmath144 can be computed by averaging the corresponding local value @xmath145 at the monte carlo points @xmath89 after the accept / reject step .",
    "a somewhat smaller statistical error can be achieved by instead averaging @xmath146 regardless of whether the proposed move is accepted or rejected .",
    "[ [ moving - the - electrons - all - at - once - or - one - by - one ] ] moving the electrons all at once or one by one ?",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    so far we have assumed that , for a many - electron system , all the electrons are moved and then this move is accepted or rejected in a single step . in fact , it is also possible to move the electrons one by one , i.e. move the first electron , accept or reject this move , then move the second electron , accept or reject this move , and so on . in this case , the transition probability for @xmath6 electrons can be formally decomposed as @xmath147 where each one - electron transition probability ( knowing that the other electrons are fixed ) is made of a proposal probability and an acceptance probability just as before .",
    "if each one - electron transition probability satisfies the stationary condition  ( [ balance ] ) , then the global transition probability satisfies it as well .",
    "moving the @xmath6 electrons one by one requires more calculation time than moving the electrons all at once , since the wave function must be recalculated after each move to calculate the acceptance probability .",
    "the calculation time does not increase by a factor of @xmath6 as one may naively think but typically by a factor of 2 if the value of the wave function is recalculated in a clever way after an one - electron move .",
    "for example , for slater determinants , one can use the matrix determinant lemma in conjunction with the sherman - morrison formula ( see , e.g. , ref .",
    "@xcite ) to efficiently recalculate the values of the determinants when only one row or column has been changed . in spite of the increase in the calculation time ,",
    "it has been repeatedly shown in the literature ( see , e.g. , refs .",
    "@xcite ) that , for systems with many electrons , moving the electrons one by one leads to a more efficient algorithm : larger moves can be made for the same average acceptance , so the points @xmath11 are less sequentially correlated and the autocorrelation time of the local energy is smaller ( by a factor larger than the one necessary for compensating the increase of the calculation time per iteration ) .",
    "while the vmc method is limited by the use of an approximate wave function @xmath1 , the idea of the dmc method  @xcite is to sample from the exact wave function @xmath148 of the ground state of the system .",
    "if we have this exact wave function @xmath148 , then the associated exact energy @xmath39 can be obtained from the mixed expectation value using the trial wave function @xmath1 , @xmath149 since @xmath148 is an eigenfunction of the hamiltonian @xmath0 .",
    "the advantage of the mixed expectation value  ( [ e0proj ] ) is that it does not require calculating the action of @xmath0 on @xmath148 .",
    "the integral in eq .",
    "( [ e0proj ] ) involves the local energy of the trial wave function , @xmath3 , and can be estimated in a similar way as in vmc by calculating the average of @xmath9 on a sample of points @xmath11 representing the mixed distribution @xmath150 .    but how to access to the exact wave function @xmath148 ?",
    "let us consider the action of the _ imaginary - time evolution operator _ ( @xmath151 ) on an arbitrary wave function such as the trial wave function @xmath1 @xmath152 where @xmath153 is for now an undetermined trial energy .",
    "using the spectral decomposition of the evolution operator ( written with the eigenstates @xmath154 and the eigenenergies @xmath155 of @xmath0 ) , we see that the limit of an infinite propagation time is dominated by the state @xmath148 with the lowest energy having a nonzero overlap with @xmath1 @xmath156 since all the other states of energies @xmath157 decay exponentially faster .",
    "the exponential @xmath158 can be eliminated by adjusting @xmath153 to @xmath39 , and we then obtain that @xmath159 becomes proportional to @xmath148 @xmath160 in position representation , eq .",
    "( [ psit ] ) is written as @xmath161 where @xmath162 is called the _ green function _ ( or the imaginary - time propagator from @xmath88 to @xmath89 ) . multiplying and dividing by @xmath163 and @xmath164 , we obtain the evolution equation of the mixed distribution @xmath165 @xmath166 where @xmath167 is the _ importance - sampling _ green function , @xmath168 i.e. @xmath167 is @xmath169 similarity transformed by the diagonal matrix that has the values of @xmath1 along the diagonal . in the limit of infinite time ,",
    "the mixed distribution becomes proportional to the target stationary distribution : @xmath170 .    in practice , an analytical expression of the green function",
    "is known only in the limit of a short propagation time , @xmath171 , where @xmath137 is a small time step , and one must thus iterate to obtain the stationary distribution @xmath172 a short - time approximation to the green function is obtained by applying the trotter - suzuki formula , @xmath173 , where @xmath174 and @xmath175 are the kinetic and potential energy operators . in position representation , this approximation leads to the following expression @xmath176 where @xmath177 is the potential energy .",
    "similarly , assuming for now that the trial wave function is of the same sign in @xmath88 and @xmath89 , i.e. @xmath178 , a short - time approximation to the importance - sampling green function is  @xcite @xmath179 where the drift velocity @xmath136 and the local energy @xmath9 were assumed constant between @xmath88 and @xmath89 .",
    "this short - time approximation implies a _ finite time - step error _ in the calculation of all observables , which should in principle be eliminated by extrapolating the results to @xmath180 ( see refs .",
    "@xcite for proofs that the time - step error vanishes in the @xmath181 limit ) .      the stochastic realization of eq .",
    "( [ frptinf ] ) is less trivial than for vmc .",
    "the green function @xmath171 is generally not a stochastic matrix , since it does not conserve the normalization of the probability density : @xmath182 .",
    "we can nevertheless write the elements of @xmath183 as the product of the corresponding elements of a stochastic matrix @xmath91 and a weight matrix @xmath184 , @xmath185 where , in the short - time approximation , @xmath186 and + @xmath187 .",
    "note that @xmath183 reduces to a stochastic matrix in the limit @xmath188 .",
    "the stochastic realization is then a weighted random walk .",
    "start from a walker at an initial position @xmath78 with a weight @xmath189 , i.e. , a distribution @xmath190 .",
    "sample the position @xmath79 of the walker at the next iteration from the probability distribution @xmath105 [ according to eq .",
    "( [ ri_to_rf ] ) ] and give it weight @xmath191 , sample the third position @xmath106 from the probability distribution @xmath107 and give it weight @xmath192 , and so on . after an equilibration phase",
    ", the random walk should sample the stationary distribution @xmath193 \\approx ( 1/m ) \\sum_{k=1}^m w_k \\delta({\\ensuremath{\\mathbf{r}}}-{\\ensuremath{\\mathbf{r}}}_k)$ ] .",
    "in reality , this procedure is terribly inefficient .",
    "because the weights @xmath194 are products of a large number of random variables , they can become very large at some iterations and very small at other iterations .",
    "consequently , the averages are dominated by a few points with large weights , even though the calculation of any point of the markov chain takes the same computational time regardless of its weight . this problem can be alleviated by keeping the product of the weights for only a finite number @xmath102 of consecutive iterations  @xcite @xmath195 however , using a finite @xmath102 introduces a bias in the sampled stationary distribution . in practice ,",
    "for an @xmath102 large enough to have a reasonably small bias , this procedure still remains inefficient .",
    "the solution is to use at each iteration @xmath90 a population of @xmath196 walkers , with positions @xmath197 and weights @xmath198 ( where @xmath199 ) , performing random walks with a _ branching or birth - death process _ designed to make the weights @xmath198 vary in only a small range from walker to walker in a given iteration , and from iteration to iteration , while still sampling the correct distribution @xmath200 \\approx ( 1/m ) \\sum_{k=1}^m \\sum_{\\alpha=1}^{m_k } w_{k,\\alpha } \\delta({\\ensuremath{\\mathbf{r}}}-{\\ensuremath{\\mathbf{r}}}_{k,\\alpha})$ ] .",
    "various unbiased variants are possible , characterized by a population size @xmath196 that either varies or is constant from iteration to iteration , and by weights @xmath198 that can either be equal or different for each walker .",
    "the simplest variant uses a varying population size @xmath196 and weights all equal to one , @xmath201 . at each iteration @xmath90 , each walker @xmath202 is replaced by @xmath203 unit - weight copies of itself , where @xmath203 is an integer equal on average to what should be the current weight @xmath204 .",
    "for example , if the walker @xmath202 should have the weight @xmath205 at iteration @xmath90 , this walker is replaced by @xmath206 copies of itself with a probability 0.7 or replaced by @xmath207 copies of itself with a probability 0.3 .",
    "more generally , @xmath208 with probability @xmath209 and @xmath210 otherwise , where @xmath211 is the nearest integer smaller than @xmath212 . if @xmath213 the walker is terminated .",
    "this procedure does not change the sampled stationary distribution .",
    "= { \\ensuremath{\\text{e}}}\\left [ \\sum_{\\alpha=1}^{m_k } m_{k,\\alpha } \\delta ( { \\ensuremath{\\mathbf{r } } } -{\\ensuremath{\\mathbf{r}}}_{k,\\alpha } ) \\right ] = { \\ensuremath{\\text{e}}}\\left [ \\sum_{\\alpha=1}^{m_{k+1 } } \\delta ( { \\ensuremath{\\mathbf{r } } } -{\\ensuremath{\\mathbf{r}}}_{k+1,\\alpha } ) \\right]$ ] , where @xmath214 are the positions of the @xmath215 walkers used for the next iteration @xmath216 obtained after making @xmath203 copies of the @xmath217 walker . ]",
    "this variant has the disadvantage that the integerization of the weights results in unnecessary duplications of walkers , leading to more correlated walkers and thus to a smaller number of statistically independent points in the sample .",
    "another disadvantage is that it leads to unnecessary fluctuations in the sum of the weights , a quantity that is relevant for computing the growth estimator of the energy .",
    "a better solution is the split - join algorithm  @xcite which limits the duplication of walkers by keeping residual noninteger weights @xmath198 . at each iteration @xmath90 , after updating the weights according to @xmath218 , each walker @xmath202 with a weight @xmath219 is split into @xmath220 walkers , each being attributed the weight @xmath221 .",
    "if walkers @xmath202 and @xmath222 each have weight @xmath223 , keep walker @xmath202 with probability @xmath224 and walker @xmath222 otherwise . in either case , the surviving walker gets weight , @xmath225 .",
    "this algorithm has the advantage that it conserves the total weight of the population of walkers @xmath226 for a given iteration .",
    "yet another possibility is the stochastic reconfiguration algorithm  @xcite , which uses a fixed population size @xmath196 , and walkers of equal noninteger weights within each iteration , though the weights of the walkers fluctuate from one iteration to the next .    to avoid the explosion or extinction of the population of walkers ( or their weights if @xmath196 is kept fixed ) , the value of @xmath153 can be adjusted during the iterations . for example",
    ", a choice for @xmath153 at iteration @xmath216 is @xmath227 where @xmath228 is an estimate of @xmath39 at iteration @xmath90 , @xmath229 is a constant , @xmath230 is the total weight of the population of walkers and @xmath231 is the target total weight . because of fluctuations , @xmath153 thus slightly varies with respect to @xmath39 during the iterations , which introduces a systematic bias on the weights and thus on the stationary distribution @xmath232 .",
    "the adjustment of @xmath153 makes @xmath232 too small in regions where @xmath233 and too large in regions where @xmath234 .",
    "both of these have the effect of raising the energy .",
    "this is called _ population - control error_. this error is generally small and decreases with increasing number of walkers as @xmath235  @xcite . besides , it is possible to eliminate almost completely this error by undoing the modification of weights introduced by the variation of @xmath153 for the last several iterations  @xcite .    in the limit of an infinitesimal time step ,",
    "the transition matrix @xmath87 has a stationary distribution @xmath236 , and the weight term @xmath237 converts this distribution into the mixed distribution @xmath238 .",
    "one can get rid of the finite time - step error in the transition matrix @xmath87 by introducing an accept / reject step as in the metropolis - hastings algorithm  @xcite .",
    "for this , the transition matrix is redefined as @xmath239 , for @xmath240 , with the proposal probability @xmath241 and the acceptance probability @xmath242 with this modification , @xmath87 has the stationary distribution @xmath236 even for a finite time step .",
    "of course , the finite time - step error persists in the term @xmath237 .",
    "since certain moves are rejected , @xmath87 corresponds now to a process of diffusion with drift with an effective time step @xmath243 .",
    "this effective time step can be estimated during the calculation from the average acceptance rate and it is consistent to use it in the term @xmath237 in place of @xmath137 . in practice , just as in vmc , it is also more efficient in dmc to move the electrons one by one , i.e. to decompose @xmath87 according to eq .",
    "( [ ponebyone ] ) .",
    "we then arrive at a dmc algorithm very similar to the vmc algorithm , with weights in addition .",
    "note , however , that since a relatively small time step must be used in dmc , the average moves are smaller than in vmc and the autocorrelation time of the local energy is larger than in vmc .",
    "the energy is calculated as the average of the local energy over the distribution @xmath244 .",
    "for @xmath10 iterations ( after the equilibration phase ) and @xmath196 walkers , we have @xmath245 just as in vmc , there is a zero - variance principle on the energy in dmc . in the limit that the trial wave function @xmath1 is an exact eigenfunction of the hamiltonian , @xmath37 is independent of @xmath5 , the weights reduce to @xmath63 , and the variance on @xmath19 vanishes .    note that for an observable @xmath144 that does not commute with the hamiltonian , the average @xmath246 over the mixed dmc distribution is an estimator of @xmath247 which is only an approximation to the exact expectation value @xmath248 with an @xmath249 error . since the average @xmath246 over the vmc distribution also has an error that is linear in @xmath250 but with a prefactor that is twice as large , an @xmath251 approximation is provided by twice the average of @xmath252 over the mixed dmc distribution minus the average of @xmath252 over the vmc distribution  @xcite . for a recent survey of exact methods for sampling the pure distribution @xmath253 ,",
    "see ref .",
    "@xcite , and for a discussion of the techniques used for calculating pure expectation values of various classes of operators see ref .",
    "@xcite .      in eq .",
    "( [ gtshorttime ] ) , we have assumed that the trial wave function @xmath8 is always of the same sign , i.e. that it does not have any nodes ( points @xmath5 so that @xmath254 ) .",
    "this is the case for the ground - state wave function of a bosonic system , and for a few simple electronic systems ( two electrons in a spin - singlet state , such as the ground state of the he atom or of the h@xmath255 molecule ) . in this case",
    ", the algorithm presented above allows one to obtain the exact energy of the system , after elimination of the finite time - step error and the population - control error .",
    "if the wave function of the fermionic ground state has nodes , then there is always at least one bosonic state of lower energy , and the true ground state of the hamiltonian is a bosonic state for which the wave function @xmath256 can be chosen strictly positive .",
    "if one applied the green function exactly , starting from the distribution @xmath236 the distribution would correctly converge to @xmath257 since the trial wave function is antisymmetric ( with respect to the exchange of two electrons ) and has a zero overlap with all the bosonic states which are symmetric .",
    "however , in reality one applies the green function using a finite sampling in position space which does not allow one to impose the antisymmetry .",
    "starting from an antisymmetric wave function @xmath1 , a small component of @xmath258 can thus appear , and it grows and eventually dominates .",
    "the distribution tends to @xmath259 and the energy formula in eq .",
    "( [ e0dmcweights ] ) only gives @xmath260 ( the positive and negative weights cancel out ) with statistical noise .",
    "even if one imposed antisymmetry and eliminated the bosonic states , e.g. by considering all electron permutations in each walker , the problem persists because different paths between the same points in this antisymmetrized space can contribute with opposite sign . since @xmath148 and @xmath261 are equally good solutions of the schrdinger equation , the algorithm would sample each with approximately equal probability , leading again to the cancellation of positive and negative weight contributions .",
    "these are different manifestations of the infamous _ fermionic sign problem_.      to avoid the sign problem in dmc , the _ fixed - node approximation _ ( fn )  @xcite is introduced .",
    "the idea is to force the convergence to a wave function approximating the fermionic ground state by fixing its nodes to be the same as those of the trial wave function @xmath8 .",
    "formally , one can define the fn hamiltonian , @xmath262 , by adding to the true hamiltonian @xmath0 infinite potential barriers at the location of the nodes of @xmath8  @xcite .",
    "the ground - state wave function of this hamiltonian is called the fn wave function @xmath263 and its energy is the fn energy @xmath264 , @xmath265 in the @xmath4-dimensional space of positions @xmath5 , the nodes of @xmath8 define hypersurfaces of dimension @xmath266 .",
    "the position space is then partitioned in nodal pockets of @xmath8 , delimited by nodal surfaces , in which the wave function has a fixed sign . in each nodal pocket , the fn wave function is the solution to the schrdinger equation satisfying vanishing boundary conditions on the nodal surface .",
    "the fn green function corresponding to the hamiltonian @xmath267 is @xmath268 and only permits moves @xmath269 inside a nodal pocket . the importance - sampling fn green function",
    ", @xmath270 also confines the moves inside a nodal pocket , and it is thus always greater or equal to zero . a short - time approximation to @xmath271 is then again given by eq .",
    "( [ gtshorttime ] ) .",
    "the stochastic algorithm previously described can thus be applied directly . thanks to the fn approximation",
    ", the weights always remain positive , and the stationary mixed distribution @xmath232 is proportional to @xmath272 .    the largest contributions to the finite time - step error come from singularities of the drift velocity @xmath273 and of the local energy @xmath9 in the green function of eq .",
    "( [ gtshorttime ] ) . since the gradient of the trial wave function @xmath274 ( and of the exact wave function ) does not generally vanish at the location of the nodes , the drift velocity @xmath143 diverges at the nodes , which leads to too large moves near the nodes for finite time steps .",
    "the drift velocity has discontinuities also at particle coalescences ( both electron - nucleus and electron - electron ) .",
    "similarly , for an approximate trial wave function @xmath8 , the local energy @xmath9 also diverges at the nodes and at particle coalescences ( unless the kato cusp conditions  @xcite are imposed ) .",
    "the finite time - step error can be greatly reduced by replacing @xmath143 and @xmath9 in the green function by approximate integrals of these quantities over the time step @xmath137  @xcite .    if importance sampling is not used , it is necessary to kill walkers that cross the nodes of @xmath1 to impose the fn boundary condition . in practice importance sampling",
    "is almost always used . in that case",
    ", it is better to reject the moves of walkers crossing the nodes , which is consistent with the fn approximation , but even this is not necessary since the number of walkers that cross the node per unit time goes to zero as @xmath181  @xcite the diffusion term dominates and can cause walkers to cross nodes .",
    "the density of walkers goes quadratically to zero near nodes and walkers that are roughly within a distance @xmath140 can cross . hence the number that cross per monte carlo step goes as @xmath275 , and so the number that cross per unit time goes to zero as @xmath140 . ] . for a finite time step ,",
    "there are node crossing events , but these are just part of the finite time - step error and in practice essentially the same time - step error is obtained whether the walkers are allowed to cross nodes or not .",
    "we may wonder whether the walkers have to sample all the nodal pockets .",
    "the tiling theorem  @xcite establishes that all the nodal pockets of the ground - state wave function of a many - electron hamiltonian with a reasonable local potential are equivalent , i.e. , the permutations of any nodal pocket are sufficient to cover the entire space .",
    "this means that , for ground - state calculations , the distribution of the walkers over the nodal pockets is irrelevant .    by applying the variational principle , it is easy to show that the fn energy is an upper bound to the exact energy @xmath276 the second equality coming from the fact that the infinite potential barriers in @xmath262 do not contribute to the expectation value since @xmath277 is zero on the nodal surface . since the wave function @xmath277 is an eigenfunction of @xmath262 , the fn energy can also be expressed using the mixed expectation value @xmath278 where the hamiltonian @xmath262 has been replaced by @xmath0 for essentially the same reason as before , viz . , both @xmath1 and @xmath277 are zero where @xmath262 is infinite . in practice ,",
    "the fn energy is thus obtained by the same energy formula  ( [ e0dmcweights ] ) .",
    "the accuracy of the dmc results with the fn approximation thus depends on the quality of the nodal surface of the trial wave function . for a trial wave function with a single slater determinant ,",
    "the error due to the fn approximation can often be large , even for energy differences .",
    "for example , for the c@xmath255 molecule , the fn error for a single - determinant trial wave function is 1.6 ev for the total energy and 0.8 ev for the dissociation energy  @xcite . in order to reduce this error",
    ", one can use several slater determinants and optimize the parameters of the wave function ( jastrow parameters , coefficients of determinants , coefficients that express the orbitals in terms of the basis functions , and exponents of the basis functions ) in vmc ( see refs .",
    "this allows one to reach near chemical accuracy ( @xmath279 1 kcal / mol ) in dmc for calculations of energy differences such as molecular atomization energies  @xcite .",
    "we often need to estimate nonlinear functions of expectation values .",
    "the simplest example is the variance , @xmath280 = { \\ensuremath{\\text{e}}}[x^2]-{\\ensuremath{\\text{e}}}[x]^2,\\ ] ] which is a quadratic function of the expectation values of two random variables @xmath281 and @xmath41 .",
    "another example is the calculation of the energy in dmc using weights [ see eq .",
    "( [ e0dmcweights ] ) ] , with simplified notation , @xmath282}{{\\ensuremath{\\text{e}}}[w]},\\ ] ] involving a ratio of two expectation values .",
    "consider a nonlinear function , @xmath283,{\\ensuremath{\\text{e}}}[y])$ ] , of two expectation values , @xmath42 $ ] and @xmath284 $ ] .",
    "the usual simple estimator of @xmath283,{\\ensuremath{\\text{e}}}[y])$ ] is @xmath285 where @xmath286 and @xmath287 are averages over a finite number of blocks @xmath44 , and @xmath52 and @xmath288 are the block averages of @xmath41 and @xmath289 , respectively [ see eq .",
    "( [ xblock ] ) ] . as discussed",
    "before , each block average is itself an average over a sufficiently large number of steps , @xmath45 , so that the block averages can be assumed to be independent of each other .",
    "the simple estimator can be justified as follows .",
    "( i ) when the law of large numbers holds , @xmath50 and @xmath290 converge , with increasing @xmath44 , almost surely to @xmath42 $ ] and @xmath284 $ ] , respectively .",
    "( ii ) hence , @xmath285 converges to @xmath283,{\\ensuremath{\\text{e}}}[y])$ ] provided that @xmath291 is continuous at the point @xmath292,{\\ensuremath{\\text{e}}}[y])$ ] .",
    "however , because @xmath291 is nonlinear , @xmath285 has a systematic error , i.e. @xmath293 \\ne f({\\ensuremath{\\text{e}}}[x],{\\ensuremath{\\text{e}}}[y])$ ] , that vanishes only in the limit of infinite sample size , @xmath294 .",
    "though not necessary , in the following , for the sake of simplicity , we assume that @xmath285 has a finite expectation value and a finite variance$ ] can be undefined when @xmath291 has a point at which it diverges , e.g. , @xmath295 . in this case , this definition of the systematic error does not have a strict meaning . in practice , this is not a problem for this @xmath291 provided that the absolute value of the expectation value of @xmath289 over a block is larger than a few times the square root of its variance , say , @xmath296| > 5 \\sqrt{v[\\overline{y_{\\ensuremath{\\text{b}}}}]}$ ] . ] .",
    "let us first consider the case of a nonlinear function @xmath297 of a single variable . by definition ,",
    "the systematic error of the estimator @xmath298 is @xmath299 - f({\\ensuremath{\\text{e}}}[x])$ ] .",
    "the systematic error can be evaluated using a second - order taylor expansion of the function @xmath298 around @xmath42 $ ] ( assuming that @xmath291 is at least a @xmath300 function in the neighborhood of @xmath42 $ ] ) @xmath301 ) + \\left ( \\frac{{\\ensuremath{\\text{d}}}f}{{\\ensuremath{\\text{d}}}x } \\right)\\ ; ( \\overline{x}-{\\ensuremath{\\text{e}}}[x ] ) + \\frac{1}{2 } \\left(\\frac{{\\ensuremath{\\text{d}}}^2 f}{{\\ensuremath{\\text{d}}}x^2 } \\right)\\ ; ( \\overline{x}-{\\ensuremath{\\text{e}}}[x])^2 + \\cdots , \\label{fx}\\ ] ] where the derivatives of @xmath291 are evaluated at @xmath42 $ ] .",
    "if we take the expectation value of this expression , the linear term vanishes @xmath302 = f({\\ensuremath{\\text{e}}}[x ] ) + \\frac{1}{2 } \\left(\\frac{{\\ensuremath{\\text{d}}}^2 f}{{\\ensuremath{\\text{d}}}x^2 } \\right)\\ ; { \\ensuremath{\\text{e}}}\\!\\left[(\\overline{x}-{\\ensuremath{\\text{e}}}[x])^2\\right ] + \\cdots . \\label{efx}\\ ] ] assuming the random variable @xmath41 has a finite variance and that the higher - order terms can be neglected , the systematic error is thus @xmath302 - f({\\ensuremath{\\text{e}}}[x ] ) \\;=\\ ; \\frac{1}{2 } \\left(\\frac{{\\ensuremath{\\text{d}}}^2 f}{{\\ensuremath{\\text{d}}}x^2 } \\right)\\ ; { \\ensuremath{\\text{v}}}[\\overline{x } ] + \\cdots \\;=\\ ; \\frac{1}{2 } \\left(\\frac{{\\ensuremath{\\text{d}}}^2 f}{{\\ensuremath{\\text{d}}}x^2 } \\right)\\ ; \\frac{{\\ensuremath{\\text{v}}}[\\overline{x}_{\\ensuremath{\\text{b}}}]}{m_{\\ensuremath{\\text{b } } } } + \\cdots . \\label{efxv}\\ ] ] hence , the estimator @xmath298 has a systematic error with a leading term proportional to @xmath303 .",
    "note that if the hypotheses ( especially the finite variance ) are not satisfied , the systematic error can decrease more slowly than @xmath304 .",
    "equation  ( [ efxv ] ) can easily be generalized to a function of several variables .",
    "for example , for two variables , the systematic error is @xmath305 - f({\\ensuremath{\\text{e}}}[x],{\\ensuremath{\\text{e}}}[y ] ) & = & \\frac{1}{2 } \\left(\\frac{\\partial^2 f}{\\partial x^2 } \\right)\\ ; \\frac{{\\ensuremath{\\text{v}}}[\\overline{x}_{\\ensuremath{\\text{b}}}]}{m_{\\ensuremath{\\text{b } } } } + \\frac{1}{2 } \\left(\\frac{\\partial^2 f}{\\partial y^2 } \\right)\\ ; \\frac{{\\ensuremath{\\text{v}}}[\\overline{y}_{\\ensuremath{\\text{b}}}]}{m_{\\ensuremath{\\text{b } } } } \\nonumber\\\\ & & +   \\left(\\frac{\\partial^2 f}{\\partial x \\partial y } \\right ) \\ ; \\frac{{\\ensuremath{\\text{cov}}}[\\overline{x}_{\\ensuremath{\\text{b}}},\\overline{y}_{\\ensuremath{\\text{b}}}]}{m_{\\ensuremath{\\text{b } } } } + \\cdots , \\label{efxy}\\end{aligned}\\ ] ] where the second - order derivatives are evaluated at @xmath292,{\\ensuremath{\\text{e}}}[y])$ ] .",
    "the leading neglected term is @xmath306 if the third moments of @xmath41 and @xmath289 are finite .",
    "the second - order derivatives in eq .",
    "( [ efxy ] ) can in practice be evaluated at @xmath307 without changing the order of the approximation .",
    "hence , an estimator for @xmath283,{\\ensuremath{\\text{e}}}[y])$ ] with an @xmath306 error is @xmath308,{\\ensuremath{\\text{e}}}[y ] ) & \\approx & f(\\overline{x},\\overline{y } ) - \\frac{1}{2 } \\left(\\frac{\\partial^2 f}{\\partial x^2 } \\right)\\ ; \\frac{{\\ensuremath{\\text{v}}}[\\overline{x}_{\\ensuremath{\\text{b}}}]}{m_{\\ensuremath{\\text{b } } } } - \\frac{1}{2 } \\left(\\frac{\\partial^2 f}{\\partial y^2 } \\right)\\ ; \\frac{{\\ensuremath{\\text{v}}}[\\overline{y}_{\\ensuremath{\\text{b}}}]}{m_{\\ensuremath{\\text{b } } } } \\nonumber\\\\ & & -   \\left(\\frac{\\partial^2 f}{\\partial x \\partial y } \\right ) \\ ; \\frac{{\\ensuremath{\\text{cov}}}[\\overline{x}_{\\ensuremath{\\text{b}}},\\overline{y}_{\\ensuremath{\\text{b}}}]}{m_{\\ensuremath{\\text{b } } } } + \\cdots , \\label{fxyfinal}\\end{aligned}\\ ] ] where the second - order derivatives are evaluated at @xmath307 .",
    "this approach is general and can be used to recover some well - known unbiased estimators .",
    "for example , let us consider the covariance of two random variables @xmath309 \\;=\\ ; { \\ensuremath{\\text{e}}}[x y]-{\\ensuremath{\\text{e}}}[x ] { \\ensuremath{\\text{e}}}[y ] \\;=\\ ; f({\\ensuremath{\\text{e}}}[x y],{\\ensuremath{\\text{e}}}[x],{\\ensuremath{\\text{e}}}[y]),\\end{aligned}\\ ] ] for which @xmath310 . in this case ,",
    "the generalization of eq .",
    "( [ efxy ] ) to three variables with @xmath311 and @xmath312 where @xmath313 and @xmath314 are @xmath10 uncorrelated realizations of @xmath41 and @xmath289 , respectively , gives @xmath315 - { \\ensuremath{\\text{cov}}}[x , y ] \\;=\\ ; - \\frac{{\\ensuremath{\\text{cov}}}[x , y]}{m } , \\label{syst2p}\\ ] ] which leads to the usual unbiased estimator for the covariance @xmath316 \\;\\approx\\ ; \\frac{m}{m -1 } \\left ( \\overline{x y}-\\overline{x } \\ ; \\overline{y } \\right ) \\;=\\ ; \\frac{1}{m-1 } \\sum_{i=1}^{m } \\left ( x_i - \\overline{x } \\right ) \\left ( y_i - \\overline{y } \\right ) . \\label{cov}\\ ] ]      first consider a function of a single variable . the statistical uncertainty of @xmath298",
    "is given by @xmath317=\\sqrt{{\\ensuremath{\\text{v}}}[f(\\overline{x})]}$ ] where the variance of @xmath298 is @xmath318 =   { \\ensuremath{\\text{e}}}\\left [ \\left(f(\\overline{x } ) - { \\ensuremath{\\text{e}}}[f(\\overline{x } ) ] \\right)^2\\right]$ ] .",
    "subtracting eq .",
    "( [ efx ] ) from eq .",
    "( [ fx ] ) gives @xmath319 = \\left(\\frac{{\\ensuremath{\\text{d}}}f}{{\\ensuremath{\\text{d}}}x } \\right)\\ ; ( \\overline{x}-{\\ensuremath{\\text{e}}}[x ] ) + \\cdots.\\ ] ] taking the square of this equation and the expectation value leads to the leading term in the variance of @xmath298 @xmath320 = \\left(\\frac{{\\ensuremath{\\text{d}}}f}{{\\ensuremath{\\text{d}}}x } \\right)^2 \\ ; { \\ensuremath{\\text{v}}}[\\overline{x } ] + \\cdots.\\ ] ] this equation can be generalized to a function of several variables .",
    "for example , for two variables , the variance of @xmath285 is @xmath321 = \\left(\\frac{\\partial f}{\\partial x } \\right)^2 \\ ; { \\ensuremath{\\text{v}}}[\\overline{x } ] + \\left(\\frac{\\partial f}{\\partial y } \\right)^2 \\ ; { \\ensuremath{\\text{v}}}[\\overline{y } ] + 2 \\left(\\frac{\\partial f}{\\partial x } \\right )   \\left(\\frac{\\partial f}{\\partial y } \\right ) { \\ensuremath{\\text{cov}}}[\\overline{x},\\overline{y } ] + \\cdots .",
    "\\label{vfxy}\\ ] ] equation  ( [ vfxy ] ) can be used for estimating the variance of @xmath285 at the cost of evaluating the variances @xmath322 $ ] and @xmath323 $ ] and the covariance @xmath324 $ ] .",
    "note however , that it can give a severe underestimate of the error if @xmath325 and @xmath326 are small and @xmath44 is not sufficiently large .",
    "there is a simple alternative for estimating the variance of @xmath291 that does not suffer from this limitation and does not require calculating covariances . consider again the case of a single variable . instead of defining the block average of @xmath291 in the obvious way , i.e. @xmath327 , we define the block average of @xmath291 as @xmath328 where @xmath329 is the running global average up to block @xmath53 @xmath330 with this definition of the block average , it is easy to check that @xmath331 i.e. we have written @xmath298 as an average of random variables @xmath332 .",
    "provided that the variance of @xmath41 is finite , the block average @xmath333 introduced in eq .",
    "( [ lin ] ) can be expanded as @xmath334)+ \\left(\\frac{{\\ensuremath{\\text{d}}}f}{{\\ensuremath{\\text{d}}}x } \\right)\\ ; ( \\overline{x}_b -{\\ensuremath{\\text{e}}}[x ] ) + \\cdots . \\label{fbinf}\\ ] ] assuming that @xmath291 has a second - order taylor expansion , the neglected term converges to zero in probability for large @xmath53 , at least as @xmath335 . therefore , according to eq .",
    "( [ fbinf ] ) , for large @xmath53 , the random variables @xmath332 converge to independent and equidistributed random variables ( since the random variables @xmath52 are ) would also lead to eq .",
    "( [ fbinf ] ) but the neglected term would not converge to zero for large @xmath53 . ] .",
    "consequently , the variance of @xmath298 can be estimated with the usual formula @xmath320 \\approx \\frac{{\\ensuremath{\\text{v}}}[\\overline{f}_b]}{m_{\\ensuremath{\\text{b } } } } \\approx \\frac{1}{m_{\\ensuremath{\\text{b}}}-1 } \\left ( \\frac{1}{m_{\\ensuremath{\\text{b}}}}\\sum_{b=1}^{m_{\\ensuremath{\\text{b } } } } \\overline{f}_b^2 - f(\\overline{x})^2\\right ) .",
    "\\label{vfxsimple}\\ ] ] this formula applies similarly for functions of several variables . the advantage of eq .",
    "( [ vfxsimple ] ) over eq .",
    "( [ vfxy ] ) for estimating the variance is that it is much simpler to implement and compute , especially for functions of many variables .",
    "the estimation of the variance can be simply updated at each block , just as for the expectation value .",
    "m.  p. nightingale and c.  j. umrigar . in d.",
    "m. ferguson , j.  i. siepmann , and d.  g. truhlar , editors , _ monte carlo methods in chemistry _ , advances in chemical physics vol .",
    "105 , page chapter 4 .",
    "wiley , ny , 1998 .",
    "k.  e. schmidt . .",
    "in l.  s. ferreira , a.  c. fonseca , and l.  streit , editors , _ models and methods in few - body physics , lecture notes in physics vol .",
    "273 _ , pages 363407 .",
    "springer , berlin heidelberg , 1987 ."
  ],
  "abstract_text": [
    "<S> we provide a pedagogical introduction to the two main variants of real - space quantum monte carlo methods for electronic - structure calculations : variational monte carlo ( vmc ) and diffusion monte carlo ( dmc ) . assuming no prior knowledge on the subject , we review in depth the metropolis - hastings algorithm used in vmc for sampling the square of an approximate wave function , discussing details important for applications to electronic systems . </S>",
    "<S> we also review in detail the more sophisticated dmc algorithm within the fixed - node approximation , introduced to avoid the infamous fermionic sign problem , which allows one to sample a more accurate approximation to the ground - state wave function . throughout this review , </S>",
    "<S> we discuss the statistical methods used for evaluating expectation values and statistical uncertainties . </S>",
    "<S> in particular , we show how to estimate nonlinear functions of expectation values and their statistical uncertainties .    </S>",
    "<S> * keywords : * quantum monte carlo , electronic - structure calculations , metropolis - hastings algorithm , fixed - node approximation , statistical methods .    </S>",
    "<S> this chapter provides a pedagogical introduction to the two main variants of real - space quantum monte carlo ( qmc ) methods for electronic - structure calculations : variational monte carlo ( vmc ) and diffusion monte carlo ( dmc ) . for more details of these methods , </S>",
    "<S> see , e.g. , refs .  @xcite . for reviews on applications of qmc methods in chemistry and condensed - matter physics , see , e.g. , refs .  </S>",
    "<S> @xcite . </S>"
  ]
}