{
  "article_text": [
    "considering the state of the art @xcite , we propose a new method for multivariate approximation which allows to interpolate large scattered data sets stably , accurately and with a relatively low computational cost .",
    "the interpolant we consider is expressed as a linear combination of some basis or kernel functions . focusing on radial basis functions ( rbfs ) ,",
    "the partition of unity ( pu ) is performed by blending rbfs as local approximants and using locally supported weight functions . with this approach",
    "a large problem is decomposed into many small problems , @xcite , and therefore in the approximation process we could work with a large number of nodes .",
    "however , in some cases , local approximants and consequently also the global one suffer from instability due to ill - conditioning of the interpolation matrices .",
    "this is directly connected to the order of smoothness of the basis function and to the node distribution .",
    "it is well - known that the stability depends on the flatness of the rbf .",
    "more specifically , if one keeps the number of nodes fixed and considers smooth basis functions , then the problem of instability becomes evident for small values of the shape parameter .",
    "of course , a basis function with a finite order of smoothness can be used to improve the conditioning but the accuracy of the fit gets worse .",
    "for this reason , the recent research is moved to the study of more stable bases .    for particular rbfs , techniques allowing to stably and accurately compute the interpolant , also in the _ flat limit _",
    "@xmath0 , have been designed in the recent years .",
    "these algorithms , named rbf - qr methods , are all rooted in a particular decomposition of the kernel , and they have been developed so far to treat the gaussian and the inverse multiquadric kernel .",
    "we refer to @xcite for further details on these methods .",
    "a different and more general approach , consisting in computing , via a truncated singular value decomposition ( svd ) stable bases , namely weighted svd ( wsvd ) bases , has been presented in @xcite .",
    "we remark that in the cases where the rbf - qr algorithms can be applied , they produce a far more stable solution of the interpolation problem .",
    "nevertheless , the present technique applies to _ any _ rbf kernel , and to any domain .    in this paper , a stable approach via the pu method , named wsvd - pu , which makes use of local wsvd bases and uses compactly supported weight functions ,",
    "is presented .",
    "thus , following @xcite , for each pu subdomain a stable rbf basis is computed in order to solve the local interpolation problem .",
    "consequently , since the local approximation order is preserved for the global fit , the interpolant results more stable and accurate .",
    "concerning the stability , we surely expect a more significant improvement in the stabilization process with infinitely smooth functions than with functions characterized by a finite order of regularity . moreover , in terms of accuracy , the benefits coming from the use of such stable bases are more significant in a local approach than in a global one .",
    "in fact , generally , while in the global case a large number of truncated terms of the svd must be dropped to preserve stability , a local technique requires only few terms are eliminated , thus enabling the method to be much more accurate .",
    "concerning the computational complexity of the algorithm , the use of the so - called block - based space partitioning data structure enables us to efficiently organize points among the different subdomains , @xcite .",
    "then , for each subdomain a local rbf problem is solved with the use of a stable basis .",
    "the main and truly high cost , involved in this step , is the computation of the svd . to avoid this drawback , techniques based on krylov space methods",
    "are employed , since they turn out to be really effective , @xcite .",
    "a complexity analysis supports our findings .",
    "the guidelines of the paper are as follows . in section [ wsvd ]",
    ", we present the wsvd bases , computed by means of the lanczos algorithm , in the general context of global approximation .",
    "such method is used coupled with the pu approach which makes use of an optimized searching procedure , as shown in section [ pum_wsvd ] .",
    "the proposed approach turns out to be stable and efficient , as stressed in section [ compl_anal_wsvd ] . in sections",
    "[ ne_lan ] and [ applicazione ] extensive numerical experiments and applications , carried out with both globally and compactly supported rbfs of different orders of smoothness , support our results .",
    "moreover , all the matlab codes are made available to the scientific community in a downloadable free software package :    http://hdl.handle.net/2318/1527447 .",
    "in subsection [ rbf_prelim ] we briefly review the main theoretical aspects concerning rbf interpolation , @xcite , while the remaining subsections are devoted to the efficient computation of the wsvd basis via krylov space methods .",
    "our goal is to recover a function @xmath1 , @xmath2 being a bounded set in @xmath3 , using a set of samples of @xmath4 on @xmath5 pairwise distinct points @xmath6 , namely @xmath7^t$ ] , @xmath8 , @xmath9 . to this end ,",
    "one considers a positive definite and symmetric kernel @xmath10 to construct an interpolant in the form @xmath11 the kernels we consider are always radial , meaning that there exist a positive _ shape parameter _ @xmath12 and a function @xmath13 such that for all @xmath14 , @xmath15 . in table",
    "[ tab_rbf ] we report a list of some strictly positive definite radial kernels with their smoothness degrees .",
    "we remark that gaussian , inverse multiquadric and mat@xmath16rn functions are globally supported and strictly positive definite in @xmath3 for any @xmath17 , whereas wendland ones are compactly supported ( whose support is @xmath18 $ ] ) and strictly positive definite in @xmath3 for @xmath19 ( see @xcite ) .",
    "ll    ' '' ''    rbf & @xmath20 +    ' '' ''    gaussian @xmath21 ( ga ) & @xmath22 +    ' '' ''    inverse multiquadric @xmath21 ( imq ) & @xmath23 +    ' '' ''    mat@xmath16rn @xmath24 ( m6 ) & @xmath25 +    ' '' ''    mat@xmath16rn @xmath26 ( m4 ) & @xmath27 +    ' '' ''    wendland @xmath24 ( w6 ) & @xmath28 +    ' '' ''    wendland @xmath26 ( w4 ) & @xmath29 +    the real coefficients @xmath30^t$ ] in are determined by solving the linear system @xmath31 , where the interpolation ( or kernel ) matrix @xmath32 is given by @xmath33 the so constructed solution @xmath34 is a function of the _ native hilbert space _ @xmath35",
    "uniquely associated with the kernel , and , if @xmath36 , it is in particular the @xmath37-projection of @xmath4 into the subspace @xmath38    although this interpolation method is known to be highly unstable in most cases being the matrix @xmath39 severely ill conditioned , it has been proven ( see @xcite ) that the interpolation operator @xmath40 is stable as an operator in the function space @xmath37 .",
    "this gap has been widely recognized to be caused by the use of the standard basis , and a lot of efforts have been made in recent years to introduce better or perfectly conditioned basis ( see @xcite for a general theoretical treatment of this topic , and @xcite for particular instances of stable basis ; for an overview see the book @xcite ) .",
    "we are interested here in the use of the _ wsvd basis _ introduced in @xcite , thanks to its flexibility with respect to the choice of the kernel @xmath41 .",
    "we recall in the following some relevant properties of this basis , while we refer to the paper @xcite for further details .    to construct a basis @xmath42 of @xmath43 it is enough to assign an invertible coefficient matrix @xmath44_{i , j=1}^n$ ] such that @xmath45 or , equivalently , an invertible value matrix @xmath46_{i , j=1}^n$ ] .",
    "the two matrices are related as @xmath47 ( see @xcite ) , and in our situation they are defined as follows ( see @xcite ) .",
    "a wsvd basis @xmath48 is a basis for @xmath49 characterized by the matrices @xmath50 is a singular value decomposition of the scaled kernel matrix @xmath51 , and @xmath52 is a diagonal matrix of positive weights .",
    "we observe that the definition uses a set of positive weights that was employed in the original formulation as cubature weights to construct the basis .",
    "nevertheless , these weights do not change the numerical behavior of the basis , hence we assume from now on @xmath53 , @xmath54 . moreover , for notational convenience , the diagonal elements of @xmath55 are denoted as @xmath56 .",
    "this basis has been introduced to mimic in a discrete sense the properties of the _ eigenbasis_. such basis is constructed starting from the operator @xmath57 , @xmath58(\\boldsymbol{x } ) = \\int_{\\omega } \\phi(\\boldsymbol{x},\\boldsymbol{y } )   f(\\boldsymbol{y } )   d\\boldsymbol{y},\\ ] ] through the following theorem ( see e.g. @xcite ) .    if the kernel @xmath41 is continuous and positive definite on a bounded set @xmath59 , the operator @xmath60 has a countable set of eigenfunctions @xmath61 and eigenvalues @xmath62 .",
    "the eigenfunctions are orthonormal in @xmath63 and orthogonal in @xmath37 with @xmath64 .",
    "moreover , the kernel can be expressed in terms of the eigencouples as @xmath65 where the series converges uniformly and absolutely .    for its use in interpolation in @xmath37 ,",
    "it is convenient to use the basis @xmath66 , that is normalized in @xmath37 . with this normalization , the basis has the following properties .",
    "the eigenbasis @xmath66 has the following properties :    a.   it is @xmath37-orthonormal , b.   it is @xmath63-orthogonal with squared norm @xmath67 , c.   @xmath68 , @xmath69 , d.   @xmath70 and @xmath71 as @xmath72 , e.   @xmath73 .",
    "as proven in @xcite , the wsvd basis enjoys the same properties when the inner product of @xmath63 is replaced with its discrete version @xmath74 , as summarized in the following statement .",
    "[ discrete properties ] the wsvd basis @xmath75 has the following properties :    a.   it is @xmath37-orthonormal , b.   it is @xmath74-orthogonal with norm @xmath76 , c.   [ double ] @xmath77 , @xmath69 , d.   @xmath78 , e.   [ discrete sum condition ] @xmath79 .",
    "since the interpolation is a @xmath37-projection , we can rewrite the interpolant @xmath34 in terms of the @xmath37-orthonormal wsvd basis as @xmath80 and , thanks to point of property [ discrete properties ] , this can be further rewritten as @xmath81 the latter form of the interpolant shows that @xmath34 is also the solution of the discrete least - squares approximation problem @xmath82 among all functions in @xmath83 . if we instead solve the minimization problem over the subspace @xmath84 , @xmath85 , we find a solution @xmath86 given by the truncation of the interpolant , i.e. , @xmath87 observe that it makes sense to consider the last minimization problem and its solution @xmath86 for some @xmath85 instead of the original interpolation problem , since in this way we leave out the portion of the subspace @xmath88 corresponding to small singular values , and this corresponds to solve the linear system by means of a low - rank approximation of the matrix @xmath39 .",
    "a detailed discussion of this approach can be found in @xcite , but we remark here that this method strictly depends on the behavior of the singular values of @xmath39 .",
    "namely , if we consider smoother rbfs , then by using instead of the standard approach a better stabilization of the interpolation process is expected .    on the other hand",
    ", this method has some disadvantages .",
    "first , it is required to compute a singular value decomposition of the ( possibly large ) kernel matrix , and in the end only a few elements of the decomposition are used .",
    "this is computationally expensive , but in the next section we explain how to overcome this problem .",
    "second , this method requires to neglect part of the information to reduce instability , and , in some cases , this removal is too big to obtain a meaningful approximant .",
    "a solution to this problem is provided by the coupling with a localization method , and it is the main topic of this paper .",
    "we present here a way to compute an approximation of the wsvd basis that makes use of the lanczos algorithm .",
    "the method is discussed in @xcite , and it aims at reducing the computational cost of the procedure by approximating the truncated svd of @xmath39 .",
    "we start by a general description of the lanczos algorithm .",
    "further details can be found in @xcite .",
    "let @xmath89 be the krylov subspace of order @xmath90 generated by the matrix @xmath39 and the vector @xmath91 .",
    "the lanczos method computes an orthonormal basis @xmath92 of @xmath93 through a gram - schmidt orthonormalization , i.e. , the lanczos basis @xmath94 , is computed by the following recurrence formula : @xmath95    letting @xmath96 the matrix having the vectors @xmath97 as columns , and letting @xmath98 be the @xmath99 tridiagonal matrix defined as @xmath100 the algorithm can be formulated in matrix form as @xmath101 where @xmath102 is the unit vector and @xmath103 is a scalar value .",
    "once we compute the matrices , the solution of the initial system can be approximated as @xmath104 , where @xmath105 is such that @xmath106 .",
    "the idea is to use the matrix @xmath107 to approximate the svd of @xmath39 , and since @xmath39 has usually a good low - rank approximation , we expect to do so with @xmath108 .",
    "specifically , let @xmath109 be a singular value decomposition of @xmath107 , where @xmath110 , @xmath111 are unitary matrices and @xmath112 with @xmath113 the diagonal matrix with singular values @xmath114 , @xmath115 on the diagonal .    since the last row of @xmath116 is the zero vector , the decomposition does not change if we remove this row and the last column of @xmath117 . thus , to simplify the notation we denote by @xmath117 the matrix without the last column , so that the decomposition becomes @xmath118 .",
    "now we want to define an approximation of the wsvd basis using the approximate svd of @xmath39 .",
    "we define a set of functions @xmath119 which shows similarities with the wsvd basis , even if it does not form a basis , since they do not span @xmath120 . anyway , with abuse of notation , we call again this set of functions a _ basis_.    the approximate wsvd basis is characterized by the matrices @xmath121 where @xmath122 is the lanczos decomposition of @xmath39 of order @xmath90 and @xmath123 is a singular value decomposition of @xmath107 .",
    "the next statement clarifies the connection between the two basis .",
    "as it is evident by construction , the basis strongly depends on the particular function @xmath124 .",
    "[ approx discrete properties ] the approximate wsvd basis @xmath125 has the following properties :    a.   it is near @xmath37-orthonormal , meaning that its @xmath37-gramian is the identity matrix plus a rank one matrix , b.   it is @xmath74-orthogonal with norm @xmath76 , c.   [ approx double ] @xmath126 if @xmath4 is the function used to construct the basis , d.   @xmath127 , e.   [ m = n ] it coincides with the wsvd basis if @xmath128 .",
    "this basis allows to solve again the least square approximation problem .",
    "namely , if @xmath36 is the function used for the lanczos algorithm , the approximant @xmath129 defined as @xmath130 minimizes the distance @xmath131 for @xmath132 , @xmath85 .",
    "moreover , thanks to property of property [ approx discrete properties ] , @xmath129 can be written in terms of @xmath37-inner products as @xmath133 note that the point of property [ approx discrete properties ] proves that @xmath134 .",
    "approximating @xmath86 with its fast computable version @xmath129 solves efficiently the problems .",
    "we will see in the following sections how to successfully couple this technique with a fast domain decomposition method .",
    "the main idea is to use the stable basis introduced in the previous section in order to generate local stable approximants and accumulate them into the global fit .",
    "let @xmath135 be an open and bounded domain , and let @xmath136 be an open and bounded covering of @xmath2 satisfying some mild overlap condition among the subdomains ( or patches ) @xmath137 .",
    "in other words , the subdomains must form a covering of the domain and , moreover , the overlap must be sufficient so that each interior point @xmath138 is located in the interior of at least one patch @xmath137 . furthermore , let us suppose that the set @xmath139 , for @xmath138 , is uniformly bounded on @xmath2 , with @xmath140 . associated with the subdomains we choose partition of unity weight functions @xmath141",
    ", i.e. a family of compactly supported , nonnegative and continuous functions subordinate to the subdomain @xmath137 , such that @xmath142 on @xmath2 and @xmath143 .",
    "in order to have a better stabilization of the global fit , our goal is to define stable approximants of the form on each subdomain @xmath137 . in other words , for each ( local ) matrix @xmath144 , i.e. the @xmath145-th interpolation matrix associated with the subdomain @xmath137 , a low - rank approximation is computed and thus the so - called wsvd - pu approximant is given by : @xmath146 where @xmath147 is a partition of unity weight function and @xmath148 . as evident",
    ", @xmath149 defines a local stable rbf approximant on @xmath137 of the form : @xmath150    according to @xcite , if we assume to have a @xmath151-stable partition of unity , then the derivatives of the weight functions satisfy @xmath152 is the diameter of @xmath137 and @xmath153 is a constant . as nonnegative functions @xmath154 , we may consider a _",
    "shepard weight _ ,",
    "i.e. , @xmath155 @xmath156 being compactly supported functions with support on @xmath137 , such as the wendland functions @xcite .    before computing the global fit by mean of local stable approximants",
    "obtained with the lanczos procedure , we briefly sketch in the sequel some relevant properties . since point of property [ approx discrete properties ] implies @xmath157 , we can recover the pu interpolant , by considering @xmath158 , i.e. : @xmath159    if the functions @xmath160 , @xmath161 , satisfy the interpolation conditions @xmath162 for each @xmath163 , then the global pu approximant inherits the interpolation property of the local interpolants , i.e. @xmath164    in order to be able to formulate error bounds , we consider the _",
    "fill distance _ @xmath165 and some further assumptions on the regularity of @xmath137 .",
    "specifically , we require that an open and bounded covering @xmath166 is _ regular _ for @xmath167 .",
    "this means to fulfill the following properties",
    "@xcite :    1 .   for each @xmath168 ,",
    "the number of subdomains @xmath169 with @xmath170 is bounded by a global constant @xmath171 ; 2 .",
    "there exists a constant @xmath172 and an angle @xmath173 such that every subdomain @xmath169 satisfies an interior cone condition with angle @xmath174 and radius @xmath175 ; 3 .",
    "the local fill distances @xmath176 are uniformly bounded by the global fill distance @xmath177 .",
    "the first property ensures that is actually a sum over at most @xmath171 summands .",
    "moreover , it is crucial for an efficient evaluation of the global approximant that only a constant number of local interpolants has to be evaluated .",
    "it follows that it should be possible to locate those @xmath171 indices in constant time .",
    "the second and third properties are significant for estimating errors of rbf interpolants .    after defining the space @xmath178 of all functions @xmath179",
    "whose derivatives of order @xmath180 satisfy @xmath181 for @xmath182 , we consider the following convergence result ( see theorem @xmath183 in @xcite or also theorem @xmath184 in @xcite ) .",
    "it is presented for strictly positive definite functions even if it holds more in general for strictly conditionally positive definite functions .",
    "let @xmath185 be open and bounded and suppose that @xmath186 .",
    "let @xmath187 be a strictly positive definite function .",
    "let @xmath166 be a regular covering for @xmath188 and let @xmath189 be @xmath190-stable for @xmath191 .",
    "then the error between @xmath192 , where @xmath193 is the native space of @xmath194 , and its pu interpolant can be bounded by : @xmath195 for all @xmath196 and all @xmath197 .      for each subdomain , in order to generate the local stable approximation matrix , the lanczos method",
    "is applied to the matrix @xmath144 and to the function values @xmath198 associated with the subdomain @xmath137 . in this way",
    "the matrix @xmath199 and the lanczos basis @xmath200 are computed for each subdomain . then , for each interpolation problem a local stable basis is formed .    by using a different stopping criterion in the lanczos algorithm , with respect to the one employed in @xcite , we can compute stable bases for a wider family of rbfs , both globally defined and compactly supported .",
    "the main problem in the lanczos procedure concerns the stopping criterion , ( see step 3 of the lanczos algorithm ) . from property [ discrete properties ] ( point ) and property [ approx discrete properties ] ( point ) a reliable one is : @xmath201 for a certain fixed tolerance @xmath202 , which is supposed to be equal for all the subdomains .",
    "we point out that , even if @xmath202 is fixed among the subdomains , the left - hand side of depends on the specific patch .",
    "moreover , supposing to have a quasi - uniform node distribution , there are no restrictions in selecting the same tolerance for all the subdomains . on the opposite , if the points are more clustered in several subdomains , one can always keep a fixed tolerance , but techniques enabling us to select suitable sizes of the different subdomains are recommended ( see e.g. @xcite ) .    from property",
    "[ approx discrete properties ] ( point ) , the fact that we impose as maximum number of iterations , in the lanczos algorit- + hm at step 2 , exactly the number of nodes in @xmath137 , i.e. @xmath203 , naturally follows .",
    "p12cm*1c 0.01 cm inputs : @xmath203 , number of data in @xmath137 ; @xmath204 , the local interpolation matrix ; 0.08 cm 2.2 cm @xmath205 , the function values associated to @xmath137 ; 0.08 cm 2.2 cm @xmath202 , the tolerance used as stopping criterion ; @xmath206 , the radial basis 0.08 cm 2.2 cm function .",
    "0.08 cm outputs : @xmath207 , the new basis in @xmath137 ; @xmath199 , the tridiagonal matrix .",
    "0.12 cm step 1 : set @xmath208 ; @xmath209 ; @xmath210 .",
    "0.12 cm step 2 : * for * @xmath211 0.08 cm 2.2 cm @xmath212 0.08 cm 2.2 cm @xmath213 0.08 cm 2.2 cm @xmath214 0.08 cm 2.2 cm @xmath215 0.12 cm 2.2 cm step 3 : * if * @xmath216 or @xmath217 0.08 cm 4.2 cm * break * 0.12 cm 2.2 cm @xmath218 +    then , once the matrix @xmath199 is found for @xmath137 the stable basis is computed by calculating the singular value decomposition of @xmath199 and a local approximant on each subdomain in the form is computed . then the local fits are accumulated into the global one .",
    "the use of stable bases by decomposing the initial problem into many small ones leads to a larger benefit in terms of accuracy than employing a global approach .",
    "in fact if one uses a global method the approximant results stable , but a large number of terms in the lanczos procedure are neglected .",
    "this surely leads to a decrease of the fit accuracy . whereas the local method turns out to be really accurate since , dealing with small problems , less terms in the computation of the basis",
    "are eliminated to preserve stability .",
    "extensive numerical experiments support our findings .",
    "the key step of the pu method consists in organizing the scattered data among the subdomains . to this aim",
    "the kd - tree partitioning structures are widely used , @xcite .",
    "however , they are not specifically implemented for the pu method .    here a novel partitioning procedure ,",
    "specifically the so - called _ block - based partitioning structure _ , built for bivariate and trivariate interpolation in order to determine the points belonging to the different pu subdomains , is considered . even if such partitioning structure is robust enough to work on 2d or 3d irregular domains , @xcite , we present such efficient technique for a scattered data set lying in the unit square , i.e. @xmath219 ^ 2 $ ] .    at first ,",
    "a partition of unity structure , composed by @xmath220 circular patches @xmath137 of radius : @xmath221 and whose centres @xmath222 , are a grid of points on @xmath2 , is generated .",
    "as in @xcite , the number of pu subdomains is chosen so that @xmath223 .",
    "this choice and lead to a reliable partition of unity structure since , in this way , patches form a covering of the domain @xmath2 .    in order to find the points belonging to the different subdomains and",
    "consequently solve , with the use of stable bases , @xmath220 small interpolation problems , we propose a new partitioning structure .",
    "it leads to a natural searching procedure that turns out to be really cheap in terms of computational complexity . to this aim",
    "we first cover @xmath2 with @xmath224 square blocks , where the number @xmath225 of blocks along one side of the unit square is : @xmath226 in this way the width of blocks is equal to the subdomain radius .",
    "this choice can appear trivial , but on the contrary it enables us to consider in the searching process an optimized number of blocks .",
    "blocks are numbered from @xmath227 to @xmath224 ( bottom to top , left to right ) .",
    "thus , with a repeated use of a quicksort routine the set @xmath228 is partitioned by the block - based partitioning structure into @xmath224 subsets @xmath229 , @xmath230 , where @xmath229 are the points stored in the @xmath190-th _ neighbourhood _ , i.e. in the @xmath190-th block and in its eight neighbouring blocks . in such framework , we are able to get an optimal procedure to find the nearest points .",
    "in fact , given a subdomain @xmath137 , whose centre belongs to the @xmath190-th block , we search for all data lying in the @xmath145-th subdomain only among those lying in the @xmath190-th neighbourhood .    the same partitioning structure , in case of compactly supported rbfs ( csrbfs ) , must be considered locally for each subdomain .",
    "in fact , in order to build the @xmath145-th stable approximation matrix , among all points lying in the @xmath145-th subdomain , only those belonging to the support of the csrbf must be considered .    among several routines which can be employed to determine the neighboring points , we choose the block - based data structure",
    "anyway , we stress that the algorithm , here proposed , works in any dimension @xmath17 , while the block - based data structure is only implemented for @xmath231 , @xcite . thus in higher dimensions such structure must be replaced by standard routines , such as kd - trees , @xcite .    for easiness of the reader ,",
    "the procedure is here described in the unit square , however , following @xcite , any extension to irregular domains is possible .",
    "since the stable wsvd - pu algorithm is characterized by the construction of local rbf stable approximants , we consider the local data sets , composed by @xmath203 points , @xmath232 .",
    "thus , the complexity of this algorithm is influenced by the following computational issues :    1 .",
    "organize by means of a partitioning structure the nodes among the subdomains , 2 .",
    "compute the stable basis on each subdomain    concerning the efficient organization of points , an extensive complexity analysis , briefly shacked in subsection [ comp_ps ] , can be found in @xcite .",
    "the cost associated to the computation of a local stable basis is investigated in subsection [ compl_lan ] .      performing the lanczos procedure on a matrix @xmath233",
    "requires @xmath234 , where @xmath190 is the number of vectors computed by the algorithm , i.e. @xmath190 is the _ good _ low rank approximation , ( a priori unknown in our case ) , @xcite .",
    "given @xmath144 the interpolation matrix defined on the @xmath137 , the lanczos method forms the matrix @xmath199 for @xmath137 after @xmath235 iterations .",
    "usually we have @xmath236 , but in some cases the maximum number of iterations @xmath203 can be reached and so , in a more general setting , @xmath237 .",
    "this routine requires : @xmath238 time complexity .",
    "thus for each subdomain the upper bound for the computational time of the lanczos procedure is given by the right - hand side of .    in case of sparse matrices , such as the ones arising from the use of csrbfs",
    ", the lanczos procedure can be performed in : @xmath239 time complexity , where @xmath240 is the number of non - zero entries .",
    "then a singular value decomposition is applied to the matrix @xmath199 .",
    "we remark that performing a singular value decomposition on a matrix @xmath241 requires @xmath242 time complexity .",
    "the singular value decomposition for each subdomain is applied to the matrix @xmath199 ; once more we stress that @xmath243 .",
    "thus for each subdomain the singular value decomposition can be performed in : @xmath244 time complexity .",
    "let us now focus on the block - based partitioning structure used to organize the @xmath5 data sites in blocks .",
    "we remark that such efficient organization of points is specifically implemented for 2d data sets .",
    "anyway , the proposed wsvd - pu algorithm is robust enough to work in any dimension @xmath17 , provided that a different partitioning structure is performed .",
    "let @xmath245 be the number of data sites belonging to a strip .",
    "the procedure used to store the points among the different subdomains is based on recursive calls to a _ quicksort _ routine which requires @xmath246 , where @xmath247 is the number of elements to be sorted .",
    "thus , letting @xmath248 the average number of points lying in a strip , the computational cost needed to organize the @xmath5 points among the different subdomains is : @xmath249    concerning the searching procedure , for each subdomain a quicksort procedure is used to order distances .",
    "thus observing that the data sites in a neighbourhood are about @xmath250 and taking into account the definitions of @xmath225 and @xmath251 , the complexity can be estimated by : @xmath252 the estimate follows from the fact that we built a partitioning structure strictly related to the size of the subdomains and ad hoc for the pu method .",
    "the same computational cost , in case of csrbfs , must be considered locally for each subdomain , to build the sparse interpolation and evaluation matrices . in such steps",
    "we usually have a relatively small number of nodes @xmath203 , with @xmath253 , where the index @xmath145 identifies the @xmath145-th subdomain .",
    "this section is devoted to point out , by means of extensive numerical simulations , stability and accuracy of the wsvd - pu interpolant . to this",
    "aim comparisons with the standard pu interpolant will be carried out .",
    "experiments are performed considering @xmath254 @xmath255 , uniformly random halton nodes , a grid of @xmath256 subdomain centres and a grid of @xmath257 evaluation points , which are contained in the unit square @xmath258 \\times [ 0 , 1]$ ] .    in order to show the high stability of the proposed method , we compute the root mean square error ( rmse ) , i.e. @xmath259 for different values of the shape parameter in the range @xmath260 $ ] . moreover , in order to point out the versatility of the proposed method , different kernels with different order of smoothness are considered , see table [ tab_1 ] .",
    "the error is computed using as test function the well - known franke s function : @xmath261+\\frac{3}{4}\\exp\\left[-\\frac{(9x_1 + 1)^2}{49}-\\frac{9x_2 + 1}{10}\\right]\\\\ & + \\frac{1}{2 } \\exp\\left[-\\frac{(9x_1 - 7)^2+(9x_2 - 3)^2}{4}\\right]-\\frac{1}{5 } \\exp\\left[-(9x_1 - 4)^2-(9x_2 - 7)^2\\right].\\end{aligned}\\ ] ]    in figure [ fig_1 ] we compare the rmses obtained by means of the wsvd - pu interpolant ( solid line ) with the ones obtained performing the classical pu method ( dashed line ) . as tolerance value in we set @xmath262 .",
    "these graphs point out that the use of the wsvd - pu local approach reveals a larger stability than the standard pu interpolant .",
    "moreover , the use of a local method enables us to improve the rmse for the optimal shape parameter in case of flat kernels , see figure [ fig_1 ] and table [ tab_1 ] .",
    "this is consistent with the fact that in a local stable method , differently from @xcite , we have to solve small linear systems and therefore few terms are neglected in .",
    "furthermore , from figure [ fig_1 ] we can note that the wsvd - pu method turns out to be more effective with flat kernels , while for more picked bases the improvement of using stable bases becomes negligible as the order of bases function decreases .",
    "thus , from our numerical experiments , we can observe three kinds of behavior depending on different rbf regularity classes .",
    "specifically , the features of such classes , which differ both in terms of stability and accuracy from the standard basis , can be summarized as :    * for @xmath21 kernels : improvement of stability and of the optimal accuracy ; * for @xmath263 kernels , with @xmath264 : improvement of stability and same optimal accuracy ; * for @xmath265 kernels : same stability and same optimal accuracy .     for @xmath266 , @xmath24 and @xmath26 kernels .",
    "the classical pu interpolant is plotted with dashed line and the wsvd - pu approximant with solid line . from left to right , top to bottom we consider the ga , imq , m6 , w6 , m4 and w4 kernels , respectively.,title=\"fig:\",width=332 ] -1.6 cm   for @xmath266 , @xmath24 and @xmath26 kernels .",
    "the classical pu interpolant is plotted with dashed line and the wsvd - pu approximant with solid line . from left to right , top to bottom we consider the ga , imq , m6 , w6 , m4 and w4 kernels , respectively.,title=\"fig:\",width=332 ] +    for @xmath266 , @xmath24 and @xmath26 kernels .",
    "the classical pu interpolant is plotted with dashed line and the wsvd - pu approximant with solid line . from left to right , top to bottom we consider the ga , imq , m6 , w6 , m4 and w4 kernels , respectively.,title=\"fig:\",width=332 ] -1.6 cm   for @xmath266 , @xmath24 and @xmath26 kernels .",
    "the classical pu interpolant is plotted with dashed line and the wsvd - pu approximant with solid line . from left to right , top to bottom we consider the ga , imq , m6 , w6 , m4 and w4 kernels , respectively.,title=\"fig:\",width=332 ] +    for @xmath266 , @xmath24 and @xmath26 kernels .",
    "the classical pu interpolant is plotted with dashed line and the wsvd - pu approximant with solid line . from left to right , top to bottom we consider the ga , imq , m6 , w6 , m4 and w4 kernels , respectively.,title=\"fig:\",width=332 ] -1.6 cm   for @xmath266 , @xmath24 and @xmath26 kernels .",
    "the classical pu interpolant is plotted with dashed line and the wsvd - pu approximant with solid line . from left to right , top to bottom we consider the ga , imq , m6 , w6 , m4 and w4 kernels , respectively.,title=\"fig:\",width=332 ]        ' '' ''    @xmath5 & method & rmse & @xmath267 & rmse & @xmath267 & rmse & @xmath267 & rmse & @xmath267 +    ' '' ''    @xmath268 & pu & @xmath269 & @xmath270 & @xmath271 & @xmath272 & @xmath273 & @xmath274 & @xmath275 & @xmath276 + & wsvd - pu & @xmath277 & @xmath270 & @xmath278 & @xmath279 & @xmath273 & @xmath274 & @xmath275 & @xmath276 +    ' '' ''    @xmath280 & pu & @xmath281 & @xmath282 & @xmath283 & @xmath272 & @xmath284 & @xmath285 & @xmath286 & @xmath287 + & wsvd - pu & @xmath288 & @xmath270 & @xmath289 & @xmath279 & @xmath290 & @xmath285 & @xmath291 & @xmath287 +    ' '' ''    @xmath292 & pu & @xmath293 & @xmath285 & @xmath294 & @xmath295 & @xmath296 & @xmath297 & @xmath298 & @xmath299 + & wsvd - pu & @xmath300 & @xmath270 & @xmath301 & @xmath272 & @xmath302 & @xmath274 & @xmath303 & @xmath276 +    moreover , since we are interested in pointing out the efficiency of the proposed wsvd - pu algorithm , in table [ tab_3 ] we also report the cpu times obtained by using our stable interpolation method with the gaussian rbf as local approximant , for each of the three different data sets .",
    "tests have been carried out on a intel(r ) core(tm ) i3 cpu m330 2.13 ghz processor .        ' '' ''",
    "@xmath5 & @xmath304 & @xmath305 & @xmath292 +    ' '' ''    @xmath306 cpu [ s ] & @xmath307 & @xmath308 & @xmath309 +",
    "in this section we focus on an application to earth s topography , which consists in approximating with our algorithm a set of real scattered data . in particular",
    ", we consider the so - called _ glacier _ data set .",
    "it is composed by @xmath310 points representing digitized height contours of a glacier , @xcite .",
    "the difference between the highest and the lowest point is @xmath311 m. such points , differently from the halton data , are not quasi - uniform .",
    "furthermore , they are distributed on an irregular domain @xmath312 ^ 2 $ ] .",
    "a 2d view of such points is plotted in figure [ fig_2 ] ( left ) . among them",
    "we select @xmath313 points for the cross - validation ( plotted in red in the left frame of figure [ fig_2 ] ) .",
    "since the nodes of the glacier data set do not cover the whole unit square , after generating an initial grid of subdomain centres in @xmath314 ^ 2 $ ] , we reduce such points taking only those lying in @xmath2 by means of the technique described in @xcite .    to obtain reliable and numerically significant results of the error , in this application",
    "it is more appropriate to use the relative rmse ( rrmse ) : @xmath315    in figure [ fig_2 ] , we show how the rrmses vary with respect to the shape parameter @xmath316 $ ] . in doing so",
    ", we consider the following kernels : ga , w6 and m4 .",
    "as already shown , the results point out once more that the proposed approach is stable and moreover turns to be effective also in applications .",
    "the errors for the optimal shape parameter @xmath12 are shown in table [ tab_2 ] .",
    "since we refer to points with highly varying densities and thus truly ill - conditioned matrices , the classical pu method does not give acceptable approximations .",
    "consequently , we do not report the errors obtained with this standard algorithm .     with ga , w6 and m4 kernels for the wsvd - pu approximant.,title=\"fig:\",width=332 ] -1.6 cm   with ga , w6 and m4 kernels for the wsvd - pu approximant.,title=\"fig:\",width=332 ]        ' '' ''    rrmse & @xmath267 & rrmse & @xmath267 & rrmse & @xmath267 +    ' '' ''    @xmath317 & @xmath318 & @xmath319 & @xmath320 & @xmath321 & @xmath320 +",
    "the first , third and fourth authors are partially supported by the university of torino through research project metodi numerici nelle scienze applicate . the second and fifth authors are partially supported by the funds of the university of padova , project cpda124755 multivariate approximation with application to image reconstruction .",
    "w. pogorzelski , integral equations and their applications .",
    "i , translated from the polish by jacques j. schorr - con , a. kacner and z. olesiak .",
    "international series of monographs in pure and applied mathematics , vol .",
    "pergamon press , oxford , 1966 .",
    "a. safdari - vaighani , a. heryudono , e. larsson , a radial basis function partition of unity collocation method for convection - diffusion equations arising in financial applications , j. sci .",
    "* 64 * ( 2015 ) , 341367 .",
    "h. wendland , fast evaluation of radial basis functions : methods based on partition of unity , in approximation theory x : wavelets , splines , and applications , c. k. chui , l. l. schumaker , j. stckler ( eds . ) , vanderbilt univ . press ,",
    "nashville , tn , 2002 , pp ."
  ],
  "abstract_text": [
    "<S> in this paper we propose a new stable and accurate approximation technique which is extremely effective for interpolating large scattered data sets . </S>",
    "<S> the partition of unity ( pu ) method is performed considering radial basis functions ( rbfs ) as local approximants and using locally supported weights . in particular , the approach consists in computing , for each pu subdomain , a stable basis . such technique , </S>",
    "<S> taking advantage of the local scheme , leads to a significant benefit in terms of stability , especially for flat kernels . </S>",
    "<S> furthermore , an optimized searching procedure is applied to build the local stable bases , thus rendering the method more efficient .    </S>",
    "<S> meshfree approximation , radial basis functions , partition of unity , scattered data interpolation , numerical stability , krylov space methods .    </S>",
    "<S> 65d05,65d15,65y20 . </S>"
  ]
}