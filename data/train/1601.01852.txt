{
  "article_text": [
    "we consider in this paper the convex minimization problem with linear constraints and a separable objective function in the form of the sum of several convex functions . for a positive integer @xmath2 , by @xmath3",
    "we denote the usual @xmath2-dimensional euclidean space .",
    "the minimization problem we consider in this paper has the form @xmath4 where @xmath5 is a proper lower semicontinuous convex function , @xmath6 is a given @xmath7 real matrix , @xmath8 is the dimension of variable @xmath9 , for @xmath10 and @xmath11 is a given vector . here , variable @xmath12 is decomposed into @xmath13 blocks , that is @xmath14",
    ".    many problems arising from image processing and machine learning can be cast into the form of model .",
    "for example , the total - variation based image denoising model @xcite , sparse representation based image restoration @xcite , lasso regression @xcite and support vector machines @xcite are special cases of problem with @xmath15 .",
    "in addition , we also refer to @xcite for some applications of model with @xmath16 .",
    "the alternating direction method of multipliers ( admm ) @xcite was originally proposed for solving problem with @xmath15 , and was recently widely used in the area of image processing @xcite . since admm requires inner iterations to solve its subproblems of admm , its linearized version ( ladmm ) was proposed and was successfully used in applications @xcite . as @xmath16 , one can directly extend the original admm ( ladmm ) to problem . without an additional assumption , however , it was recently shown in @xcite that the direct extension of admm to multi - block convex problems is not necessarily convergent , although it may work well in practice . very recently",
    ", there were some investigations @xcite on convergence of the extension of admm under some additional assumptions .",
    "some researchers dedicated to modify admm or ladmm to make it convergent .",
    "for instance , the jacobian - type admm was proposed in @xcite for parallel computing , the semi - proximal admm proposed in @xcite is for convex quadratic programming and conic programming , the gaussian back substitution technique was proposed in @xcite to make admm and ladmm converge .",
    "it was shown in @xcite the attractiveness of the gaussian back substitution technique for theoretical analysis on convergence of admm - type algorithms .",
    "however , the numerical results show that the correction step is time consuming and the admm ( ladmm ) with gaussian back substitution may require more iterations than the direct extension of admm ( ladmm ) to achieve the same objective function value .",
    "therefore , in this paper , we dedicate to establishing convergent and efficient algorithms .",
    "as shown in @xcite , the notion of proximity operators provides a useful tool for the algorithmic development due to its firmly nonexpansive property .",
    "admm was shown in @xcite a special case of the proximity algorithms .",
    "although the one - step fixed - point proximity algorithms proposed in @xcite can be applied to model directly , they do not utilize the separable property of the objective function , that is , the variable @xmath17 are updated simultaneously .",
    "in contrast , admm takes advantage of the separability of the objective function and utilizes the block - wise gauss - seidel technique .",
    "thus , in order to develop convergent algorithms for problem , we propose to develop two - step fixed - point proximity algorithms .",
    "the term two - step means that when we update values of the next step , we not only use values of the current step but also those of the previous step . in one of our previous papers @xcite , we designed a multi - step iterative scheme , introduced the notions of weakly firmly nonexpansive operators and condition - m ( semi - condition - m ) , and presented the convergence results of the multi - step scheme with the help of the notions . in this paper",
    ", we will follow the idea of @xcite to develop convergent two - step fixed - point proximity algorithms .",
    "this paper has the following contributions .",
    "first , we present a characterization of the solutions of problem by fixed - points of a proximity related operator and develop a two - step fixed - point iterative scheme based on the fixed - point equation .",
    "second , we prove convergence of the proposed iterative scheme by the notions of weakly firmly nonexpansive and condition - m proposed in @xcite .",
    "we prove that as long as the matrices involved in the scheme satisfy condition - m , which can be easily verified , the iterative scheme converges and the sequence @xmath18 generated by the proposed algorithm converges to a solution of problem .",
    "third , we analyze the convergence rate of the proposed iterative scheme .",
    "we prove that the scheme has @xmath0 ergodic convergence rate .",
    "in addition , the average of the sequence generated by the proposed scheme has @xmath0 convergence rate in the sense of the primal - dual gap .",
    "fourth , several specific convergent algorithms are designed from the iterative scheme , including the two - step implicit and explicit fixed - point proximity algorithms as well as their variants .",
    "furthermore , we apply the proposed two - step fixed - point proximity algorithm to the sparse mri reconstruction problem .",
    "numerical results show that the proposed two - step fixed - point proximity algorithm performs as efficiently as the direct extension of ladmm , which is not necessarily convergent .",
    "we organize this paper in eight sections . in section [ sec :",
    "characterization ] , we characterize the solutions of problem by fixed - points of a proximity related operator . based on this characterization , we develop in section [ sec : algorithm ] a two - step iterative scheme and prove its convergence in section [ sec : converge ] . in section [ sec : convrate ] , we analyze the convergence rate of the proposed iterative scheme .",
    "we design several specific algorithms from the iterative scheme in section [ sec : specificalg ] and apply in section [ sec : exp ] one of them to the sparse mri reconstruction problem .",
    "we conclude this paper in section [ sec : conclusion ] .",
    "in this section we present a characterization of solutions of model in terms of a system of fixed - point equations via the proximity operators of the functions involved in the objective function .",
    "the system of fixed - point equations will serve as a basis for developing iterative schemes for solving the problem .",
    "we now recall the notion of the proximity operator of a convex function . for @xmath12 and @xmath19 in @xmath3 ,",
    "we denote the standard inner product by @xmath20 , where @xmath21 and the standard @xmath22-norm by @xmath23 . by @xmath24",
    "we denote the set of symmetric positive definite matrices . for an @xmath25",
    "the @xmath26-weighted inner product is defined by @xmath27 and the corresponding @xmath26-weighted @xmath22-norm is defined by @xmath28 . for a @xmath29 matrix @xmath30 , we define @xmath31 as the largest singular value of @xmath30 . by @xmath32",
    "we denote the class of all lower semicontinuous proper convex functions @xmath33 . for a function @xmath34 ,",
    "the proximity operator of @xmath35 with respect to a given matrix @xmath36 , denoted by @xmath37 , is a mapping from @xmath3 to itself , defined for a given point @xmath38 by @xmath39 in particular , we use @xmath40 for @xmath41 .",
    "the proximity operator of a function is intimately related to its subdifferential .",
    "the subdifferential of a function @xmath35 at a given vector @xmath38 is the set defined by @xmath42 we remark that if a function @xmath43 is frchet differentiable at a point @xmath44 then @xmath45 , where @xmath46 is the frchet gradient of @xmath35 .",
    "it is shown that for any @xmath47 , @xmath48 and @xmath49 , @xmath50 for a discussion of this relation , see , e.g. , ( * ? ? ?",
    "* proposition 16.34 ) or @xcite .",
    "the proximity operator plays a crucial role in convex analysis and applications ( see , e.g. , @xcite ) .",
    "recall that operator @xmath51 is called firmly nonexpansive ( resp . ,",
    "nonexpansive ) with respect to a given matrix @xmath47 if for all @xmath52 @xmath53 we remark here that the symmetric positive definite matrix @xmath26 defines specific inner - product of the hilbert space @xmath3 and if @xmath54 we do not specify the matrix @xmath26 for simplicity . as shown in @xcite , the proximity operator of a convex function",
    "is firmly nonexpansive and is contractive when the function is strongly convex .",
    "we also need the notion of the conjugate function .",
    "the conjugate of @xmath55 is the function @xmath56 defined at @xmath49 by @xmath57 a characterization of the subdifferential of a function @xmath35 in @xmath32 is that for @xmath58 and @xmath59 @xmath60 the notion of the indicator function is also required . for a set @xmath61 ,",
    "the indicator function on @xmath62 , at point @xmath12 , is defined as @xmath63 moreover , we denote the smallest cone in @xmath3 containing @xmath62 by @xmath64 . then the relative interior of @xmath62 ( see definition 6.9 of @xcite ) is defined as @xmath65    for simplicity , let @xmath66 and @xmath67 $ ] . then , problem can be rewritten as @xmath68 where @xmath69    now , we are ready to characterize the solutions of model   with the help of and .",
    "[ propsolu ] let @xmath70 , @xmath6 an @xmath7 matrix for @xmath71 and @xmath72 .",
    "if @xmath73 is a solution of problem  , then for any @xmath74 and @xmath75 , @xmath71 , there exists a vector @xmath76 such that @xmath77 conversely , if there exist @xmath74 , @xmath75 for @xmath71 , @xmath73 and @xmath76 satisfying equations and , then @xmath12 is a solution of problem  .",
    "we prove this theorem by applying fermat s rule that a vector @xmath73 is a solution of model   if and only if the zero vector is in the subdifferential of the objective function of model   evaluated at @xmath12 .",
    "let @xmath73 be a solution of model  . from theorem 16.37 of @xcite , the chain rule of the subdifferential holds due to @xmath78 .",
    "then by fermat s rule we obtain @xmath79 for @xmath71 .",
    "thus , there exists @xmath76 such that @xmath80 and @xmath81 for @xmath71 .",
    "the last inclusion implies that for any @xmath75 , @xmath74 , @xmath82 .",
    "therefore , equation follows from . by , from @xmath80",
    ", we have that @xmath83 .",
    "hence , for any @xmath74 , we obtain that @xmath84 , which by is equivalent to equation .",
    "conversely , suppose that there exist @xmath75 , @xmath74 , @xmath76 and @xmath85 for @xmath71 satisfying the system of fixed - point equations and .",
    "the relation ensures that @xmath86 and @xmath87 . clearly",
    ", these inclusions together ensure that the relation holds .",
    "that is , the zero vector is in the subdifferential of the objective function at @xmath88 .",
    "again , by fermat s rule , @xmath89 is a solution of model  .",
    "theorem [ propsolu ] characterizes a solution of problem   in terms of the system of fixed - point equations and . through out this paper , for problem  , we assume that @xmath90 and it has at least one solution . with these assumptions and by theorem [ propsolu ] , we know that fixed - point equations and have at least one solution for any @xmath75 , @xmath71 and @xmath74 .",
    "this makes it possible for us to compute a solution of model   by developing fixed - point iterative schemes .",
    "we develop in this section a two - step iterative scheme for solving optimization problem   by using the system of fixed - point equations and .",
    "we begin with rewriting equations and in a compact form . to this end",
    ", we first introduce an operator by integrating together the @xmath91 proximity operators involved in equations and .",
    "specifically , for given @xmath70 , @xmath92 , @xmath93 , @xmath74 , @xmath71 , we define the operator @xmath94 at a vector @xmath95 as follows : @xmath96 operator @xmath97 couples all the proximity operators @xmath98 , @xmath71 and @xmath99 . in the following lemma",
    ", we show that the operator @xmath97 is the proximity operator of a new convex function @xmath100 for @xmath101 with respect to the matrix @xmath102 where @xmath103 ( resp .",
    "@xmath104 ) is a @xmath2-dimensional vector with @xmath105 ( resp .",
    "@xmath106 ) as its components for any @xmath107 .",
    "[ lemma : proc - comb ] if operator @xmath97 is defined by , then @xmath97 is the proximity operator of the function @xmath108 with respect to the matrix @xmath109 , that is , @xmath110 .",
    "here we omit the proof since one can complete it by referring to lemma 3.1 of @xcite . by lemma  [ lemma : proc - comb ] , we know that the operator @xmath97 is firmly non - expansive with respect to the matrix @xmath109 .",
    "let @xmath111with the help of the above notation , equations   and can be reformulated in a compact form @xmath112 where @xmath113 theorem  [ propsolu ] together with equation indicates that finding a solution of problem   essentially amounts to computing a fixed - point of the operator @xmath114 . as discussed at the end of section [ sec : characterization ] , the operator @xmath114 has at least one fixed - point .",
    "we next focus on developing efficient iterative schemes for finding a fixed - point of the operator .",
    "as shown in @xcite , the matrix @xmath115 is not nonexpansive due to the fact that @xmath116 .",
    "therefore , a simple fixed - point iteration @xmath117 for a given initial guess @xmath118 , may not yield a convergent sequence @xmath119 , where @xmath120 is the set of all natural numbers .",
    "our idea is to split the expansive matrix @xmath115 into several terms , as in @xcite and in @xcite . here ,",
    "we split @xmath115 as @xmath121 where @xmath122 for @xmath123 and @xmath124 .",
    "accordingly , equation is equivalent to @xmath125 thus , we propose the following two - step iterative scheme : @xmath126 we point out here that although iterative scheme is an implicit scheme for the whole vector @xmath127 , it becomes explicit by choosing @xmath128 satisfying that @xmath129 is a strictly upper triangular or lower triangular matrix .",
    "further , we assume that there exists a unique @xmath130 satisfying for any @xmath131 in the rest of this paper .",
    "we shall choose matrices @xmath132 in the next section so that iterative scheme converges .    to close this section",
    ", we remark that when @xmath133 ( in this case , @xmath134 ) , the two - step iterative scheme reduces to a one - step iterative scheme @xmath135 many efficient algorithms can be obtained from by specifying the matrix @xmath128 .",
    "the reader is referred to @xcite for details .",
    "in this section , we study the convergence of iterative scheme . by applying the notion of weakly firmly nonexpansive operators and condition - m , which were first introduced in @xcite",
    ", we prove that if the matrices @xmath132 satisfy condition - m , then the sequence @xmath136 generated from iterative scheme converges to a solution of equation  .",
    "hence , the sequence @xmath137 converges to a solution of model  .",
    "we begin with rewriting iterative scheme in an explicit way . to this end",
    ", we introduce @xmath138 .",
    "we also define @xmath139 , at @xmath140 , as @xmath141 with @xmath142 satisfying @xmath143 the operator @xmath144 is well - defined if the corresponding set @xmath145 is carefully chosen . here",
    ", the word `` well - defined '' means that there exists a unique @xmath146 satisfying for any @xmath147 . with the help of @xmath145 and @xmath144 , can be rewritten as @xmath148    now , we recall the notion of weakly firmly nonexpansive operators and condition - m , which were introduced in @xcite .",
    "[ def : wfn ] we say an operator @xmath149 is weakly firmly nonexpansive with respect to @xmath145 , if for any @xmath150 satisfying @xmath151 for @xmath152 , there holds @xmath153    next we describe the definition of condition - m .",
    "[ def ] we say a set @xmath138 of @xmath154 matrices satisfies condition - m , if the following three hypotheses are satisfied :    * @xmath124 , * @xmath155 is in @xmath156 , * @xmath157 .",
    "we also need to review a property of weakly firmly nonexpansive operators established in @xcite .",
    "[ thm : weakconve ] suppose that the operator @xmath158 is weakly firmly nonexpansive with respect to @xmath138 with @xmath159 and the set of fixed - points of @xmath160 is nonempty .",
    "let the sequence @xmath161 be generated by @xmath162 for any given @xmath163 .",
    "if @xmath145 satisfies condition - m , then @xmath161 converges .",
    "in addition , if @xmath160 is continuous , then @xmath161 converges to a fixed - point of @xmath160 .    by the above theorem , in order to ensure convergence of iterative scheme , it suffices to prove @xmath144 defined by is weakly firmly nonexpansive and continuous .",
    "we show it in the next proposition . before doing this",
    ", we define a skew - symmetric matrix @xmath164 for an @xmath165 matrix @xmath30 as @xmath166 then , @xmath167 .",
    "[ prop : tmwfn ] let @xmath70 , @xmath75 for @xmath71 and @xmath74 .",
    "let @xmath138 be a set of @xmath168 matrices and @xmath144 be defined by .",
    "if @xmath144 is well - defined , then    * @xmath144 is weakly firmly nonexpansive with respect to @xmath145 , * @xmath144 is continuous .",
    "we first prove item ( i ) .",
    "it follows from the definition of @xmath144 that for any @xmath169 satisfying @xmath170 , for @xmath152 , there holds @xmath171 according to lemma [ lemma : proc - comb ] , @xmath172 is firmly nonexpansive with respect to @xmath109 .",
    "thus , we observe that @xmath173 since @xmath174 and @xmath175 is skew - symmetric , we have @xmath176 from definition [ def : wfn ] , we get item ( i ) .",
    "we next prove item ( ii ) . from the definition of @xmath144 , for any sequence",
    "@xmath177 satisfying @xmath178 and converging to @xmath179 , we have that @xmath180 this with the continuity of @xmath172 implies that @xmath181 thus , @xmath182 , proving item ( ii ) .    we are now ready to prove convergence of the sequence generated from iterative scheme .",
    "[ thm : itr_con ] let @xmath70 , @xmath75 for @xmath71 and @xmath74 .",
    "let @xmath172 and @xmath115 be defined as and respectively , @xmath138 be a set of @xmath168 matrices and @xmath144 be defined by .",
    "let @xmath183 be generated by for given points @xmath184 .",
    "suppose that @xmath144 is well - defined .",
    "if @xmath145 satisfies condition - m , then the sequence @xmath183 converges to a fixed - point of @xmath185 , and @xmath137 converges to a solution of problem .    by the definition of @xmath144 ,",
    "operators @xmath144 and @xmath185 share the same set of fixed - points . by proposition",
    "[ prop : tmwfn ] , the operator @xmath144 is weakly firmly non - expansive with respect to @xmath145 and continuous .",
    "therefore , theorem [ thm : weakconve ] ensures that the sequence @xmath183 converges to a fixed - point of @xmath144 . by proposition [ propsolu ]",
    ", the sequence @xmath137 converges to a solution of problem .",
    "theorem  [ thm : itr_con ] shows that convergence of iterative scheme relies completely on whether the matrices set @xmath145 used in scheme satisfies condition - m .",
    "we will develop in section [ sec : specificalg ] specific convergent algorithms by generating sets of @xmath186 satisfying condition - m .",
    "in this section , we study the convergence rate of the proposed fixed - point iterative scheme .",
    "we show that the proposed algorithm has @xmath0 convergence rate in the ergodic sense and the sense of the partial primal - dual gap .",
    "we first study the convergence rate of the proposed algorithm in the ergodic sense .",
    "we prove in this subsection that the proposed iterative scheme has @xmath0 convergence in the ergodic sense . to this end",
    ", we first review a lemma presented in @xcite .",
    "[ lema : running ] if a sequence @xmath187 satisfies : @xmath188 and @xmath189 , then    * @xmath190 , * @xmath191 .",
    "the main results of this subsection are presented in the next theorem .",
    "let @xmath70 and @xmath6 an @xmath7 matrix for @xmath71 .",
    "let @xmath75 for @xmath71 and @xmath74 .",
    "let @xmath172 and @xmath115 be defined as and respectively .",
    "let the sequence @xmath192 be generated from for any given @xmath193 .",
    "suppose that @xmath144 is well - defined . if @xmath145 satisfies condition - m , then    * the sequence @xmath183 has @xmath0 convergence in the ergodic sense , that is @xmath194 * the running minimal of progress , @xmath195 , has @xmath196 convergence .    by lemma [ lema : running ] , we only need to prove @xmath197    by the definition of @xmath144 , the sequence @xmath183 generated from can also be generated by for the same given @xmath198 .",
    "since @xmath144 is weakly firmly nonexpansive with respect to @xmath145 and @xmath145 satisfies condition - m , by lemma 4.4 of @xcite , we have for any @xmath199 that @xmath200 where @xmath201 for @xmath127 a fixed - point of @xmath144 , @xmath202 and @xmath203 . by ( iii ) of condition - m , we have @xmath204",
    ". then is obtained immediately from and the fact that @xmath205 .      in this subsection",
    ", we study the convergence rate of the proposed iterative algorithm in the sense of the partial primal - dual gap .",
    "we prove that iterative scheme has @xmath0 convergence rate in the sense of the partial primal - dual gap .",
    "we first introduce the notion of the partial primal - dual gap for convex problem . to this end , we review the primal - dual formulation of problem , that is @xmath206 one can refer to @xcite for more details . for two bounded sets @xmath207 and @xmath208 , the partial primal - dual gap for problem at point @xmath209 is defined as @xmath210 we refer to @xcite for more details on the partial primal - dual gap .    in order to analyze the convergence rate of iterative scheme , we define @xmath211 by @xmath212 where @xmath108 and @xmath164 are defined as and respectively . for @xmath213 ,",
    "where @xmath214 and @xmath215 , one can check that is equivalent to @xmath216 therefore , in order to analyze the partial primal - dual gap at point @xmath217 , we only need to estimate the upper bound of @xmath218 for @xmath219 .",
    "the next lemma presents an important estimation of @xmath220 for any @xmath221 .",
    "[ lema : initialppriamaldualine ] let @xmath70 , @xmath6 an @xmath7 matrix , @xmath75 for @xmath71 and @xmath74 .",
    "let @xmath172 and @xmath115 be defined as and respectively , @xmath138 be a set of @xmath168 matrices .",
    "let @xmath222 be generated from iterative scheme",
    ". for all @xmath221 there holds @xmath223    from iterative scheme , lemma [ lemma : proc - comb ] and , we have @xmath224 due to @xmath225 , we obtain that @xmath226 by the definition of subdifferential and the convexity of @xmath108 , we have for any @xmath221 that @xmath227 since @xmath164 is skew - symmetric , the above inequality is equivalent to @xmath228 then , we obtain immediately by the definition of @xmath229 .",
    "we next study the partial primal - dual gap at @xmath230 .",
    "[ lema : ppriamaldualine ] let @xmath231 be generated from iterative scheme . under the same assumptions of lemma [ lema : initialppriamaldualine ] ,",
    "if @xmath145 satisfies condition - m , then for all @xmath221 there holds @xmath232 where @xmath155 and @xmath230 .    for simplicity",
    ", we define for @xmath233 , @xmath234 by lemma [ lema : initialppriamaldualine ] and item ( i ) of condition - m , we have @xmath235 using @xmath155 and @xmath124 , the above inequality implies that @xmath236 where @xmath237 and @xmath238 . by the relationship @xmath239 and @xmath240 for @xmath241",
    ", we obtain that @xmath242 we also have @xmath243 where the first equality is obtained by the relationship @xmath244 and the second equality holds due to @xmath245 .",
    "let @xmath246 .",
    "then it follows that for any @xmath247 , @xmath248    summing inequality from @xmath249 to @xmath250 , we have @xmath251 by applying @xmath252 for @xmath253 and @xmath249 to the last two terms of , we obtain that @xmath254 setting @xmath255 , it follows that @xmath256 due to ( iii ) of condition - m .",
    "this together with yields @xmath257 since @xmath258 is convex , we conclude that @xmath259 , which together with inequality implies .",
    "now , we are ready to present the partial primal - gap convergence rate of the proposed algorithm in the next theorem .    let @xmath231 be generated from iterative scheme . under the same assumptions of lemma [ lema : initialppriamaldualine ] ,",
    "if @xmath145 satisfies condition - m , then iterative scheme has @xmath260 convergence rate in the partial primal - dual gap sense , that is @xmath261 where @xmath262 and @xmath208 are bounded and @xmath263 .",
    "this is a direct consequence of lemma [ lema : ppriamaldualine ] and the boundedness of sets @xmath264 and @xmath265 .",
    "in this section , we derive several specific two - step algorithms from the iterative scheme by choosing specific sets of @xmath168 matrices @xmath266 which satisfy condition - m .      in this subsection",
    ", we design a class of explicit one - step algorithms , which only utilize the vectors of the current step to update the vectors of the next step . in such case ,",
    "@xmath133 and condition - m reduces to @xmath134 and @xmath267 .",
    "we begin with constructing @xmath128 .",
    "if the matrix @xmath129 is strictly upper or lower triangular , then the resulting algorithms will be explicit . by",
    ", @xmath134 can be chosen as @xmath268 or @xmath269 with @xmath270 where @xmath271 is defined by . by simple calculations",
    ", one can obtain that @xmath272 and thus @xmath273 for @xmath274 .",
    "then , iterative scheme with respect to @xmath268 and @xmath269 become , respectively , @xmath275 and @xmath276    we note that , algorithms and are actually special cases of the one - step first - order primal - dual algorithm @xcite , which solves the following optimization problem @xmath277 with @xmath278 , @xmath279 and @xmath30 an @xmath165 matrix . here , if we set @xmath280 , @xmath281 and @xmath282 defined at @xmath12 as @xmath283 , then problem is exactly the optimization problem",
    ". clearly , algorithms and are special cases of the one - step first - order primal - dual algorithm @xcite by the fact that @xmath284 .",
    "the corresponding convergence results are presented in the following theorem .",
    "let @xmath70 , @xmath6 an @xmath7 matrix , @xmath75 for @xmath71 and @xmath74 .",
    "let the sequence @xmath285 generated from or for any @xmath286 . if @xmath287 , where @xmath288 , then @xmath285 converges and the sequence @xmath289 converges to a solution of problem .",
    "we omit the proof since it can be obtained immediately by applying lemma 6.2 in @xcite and theorem [ thm : itr_con ] .",
    "to close this subsection , we remark that both algorithms and do not take advantage of the separability of function @xmath290 and vector @xmath12 .",
    "more precisely , the information of @xmath291 for @xmath292 is not used when we update @xmath293 .",
    "we dedicate the next two subsections to developing new algorithms which make use of the block - wise gauss - seidel technique to update blocks @xmath294 .      in this subsection",
    ", we propose a two - step implicit fixed - point proximity algorithm from iterative scheme .",
    "we begin with constructing the set of matrices @xmath138 by setting @xmath295 @xmath296 @xmath297 with this choice of matrices @xmath132 , noting that @xmath298 , iterative scheme leads to @xmath299 we then replace @xmath300 by @xmath301 as we update @xmath293 for @xmath71 in iterative scheme , we obtain that @xmath302    we point out the connections of the proposed algorithm with the proximal admm ( padmm ) . to this end",
    ", we introduce the augmented lagrangian function for @xmath303 the padmm for reads as @xmath304 on the other hand , by the definition of proximity operator , the proposed algorithm can be equivalently rewritten as @xmath305 we can observe that our proposed algorithm reduces to the padmm if we set @xmath306 for @xmath307 in . as shown in @xcite , convergence of admm directly applied to problem with @xmath16 is not guaranteed . also , it was shown in @xcite that padmm may not converge unless extra assumptions on @xmath308 for @xmath71 are added .",
    "however , algorithm is ensured to converge without extra assumptions on @xmath308 for @xmath71 .",
    "we next establish the convergence result of algorithm .",
    "[ prop : padmm ] let @xmath132 be defined as , and .",
    "let @xmath309 .",
    "if @xmath310 then the set @xmath186 satisfies condition - m .    clearly , we see that @xmath124 , that is , item ( i ) of condition - m holds",
    ". define @xmath155 .",
    "then @xmath311 is diagonal and symmetric . item ( ii ) of condition - m is trivial due to @xmath75 for @xmath71 and @xmath74 .",
    "we then prove the validity of item ( iii ) of condition - m .",
    "since the last @xmath312 columns and rows of @xmath313 are all zeros , we have that @xmath314 where @xmath315 . by using hypothesis",
    ", we find that @xmath316 which leads to item ( iii ) of condition - m .    the convergence results of algorithm is presented below .",
    "[ thm : specificpadmmconverge ] let @xmath70 , @xmath6 an @xmath7 matrix , @xmath75 for @xmath71 and @xmath74 .",
    "let the sequence @xmath317 be generated from the algorithm for any @xmath318 .",
    "let @xmath313 be defined as and @xmath319 .",
    "if the condition is satisfied , then the sequence @xmath289 converges to a solution of problem .    by proposition [ prop : padmm ] and theorem [ thm : itr_con ] , it suffices to prove @xmath144 is well - defined when @xmath132 are defined by , and . in this case , if @xmath320 , where @xmath321 , then @xmath322 and each @xmath323 for @xmath71 can be calculated by @xmath324 since the objective function of the above optimization problem is strongly convex , @xmath144 is well - defined .    to end this subsection , we point out that compared with algorithms and , algorithm takes advantage of the separable structure of variable @xmath12 and applies the block - wise gauss - seidel technique to blocks @xmath325 .",
    "we also note that solving the subproblems involved in may require inner iterations . in practice",
    ", it will affect the computational efficiency of the algorithm .",
    "in the next subsection , we develop an explicit two - step algorithm .",
    "as long as the proximity operators of @xmath308 for @xmath71 have closed form solutions , the algorithm can be implemented efficiently .      in this subsection",
    ", we propose a class of explicit algorithms , which apply the block - wise gauss - seidel technique to blocks @xmath326 .",
    "we begin with specifying the set of matrices @xmath145 .",
    "we set @xmath327 @xmath328 and let @xmath313 be defined as in .",
    "we can obtain an implicit algorithm by directly substituting , and into the iterative scheme . as the same as the algorithm",
    ", it implies @xmath329 as in subsection [ subsec : implicitalg ] , we replace @xmath300 by @xmath330 when we update @xmath293 for @xmath71 .",
    "this leads to the following explicit algorithm @xmath331    we point out here the relationship between the proposed algorithm and the ladmm .",
    "to this end , we first review the exact extension of ladmm to problem . for @xmath307 ,",
    "let @xmath332 defined , at @xmath333 , as @xmath334 .",
    "the direct extension of ladmm to the multi - block problem is as follows @xmath335 using the above notations and the definition of proximity operators , the algorithm can be rewritten in its equivalent form @xmath336 obviously , our proposed algorithm reduces to the ladmm if we set @xmath337 in . as mentioned in @xcite , the direct extension of ladmm to the multi - block problem",
    "is not necessarily convergent .",
    "nevertheless , the convergence of the proposed algorithm is guaranteed .",
    "next we present the convergence results of the algorithm .",
    "[ prop : ladmm ] let @xmath128 , @xmath338 and @xmath313 be defined as in , and .",
    "let @xmath339 if @xmath340 then the set @xmath186 satisfies condition - m .",
    "it is clear that item ( i ) of condition - m is satisfied .",
    ". then @xmath341 is symmetric . in light of",
    ", we have that @xmath342 . hence , item ( ii ) of condition - m holds .",
    "we next show item ( iii ) of condition - m .",
    "similar to the proof of proposition [ prop : padmm ] , @xmath314 where @xmath343 .",
    "hypothesis leads to @xmath344 this completes the proof .",
    "the following theorem regards the convergence of algorithm .",
    "let @xmath70 , @xmath6 an @xmath7 matrix , @xmath75 for @xmath71 and @xmath74 .",
    "let the sequence @xmath317 be generated from algorithm for any @xmath318 .",
    "let @xmath313 be defined as and @xmath319 .",
    "if condition is satisfied , then the sequence @xmath289 converges to a solution of problem .    by theorem [ thm : itr_con ] and proposition [ prop : ladmm ] , we only need to prove @xmath144 is well - defined . in this case , from algorithm , it is obvious that @xmath144 can be computed explicitly . therefore @xmath144 is well - defined .    to close this subsection",
    ", we remark that when the proximity operators of @xmath308 for @xmath71 have closed form solutions , the two - step algorithm may be more efficient than the two - step algorithm .",
    "this is because the two - step algorithm may require inner iterations to solve the subproblems involved , while each step of algorithm can be implemented efficiently by making use of the closed form .",
    "there is a wide variety of the choices of @xmath186 satisfying condition - m , including those of algorithms and . in this subsection ,",
    "we present other choices of @xmath186 satisfying condition - m . with these choices",
    "the two step iterative scheme reduces to a class of new algorithms , which can be viewed as variants of algorithms and . *",
    "modifications of diagonal blocks : * the diagonal blocks of @xmath338 and @xmath313 can be chosen in other ways . we only present two examples in the following . for instance , the diagonal entries of @xmath338 in can be chosen as @xmath345 with @xmath346 and correspondingly , the diagonal entries of @xmath313 in should be @xmath347 . with such a choice of @xmath186 , iterative scheme reduces to a variant of algorithm @xmath348 as a second example",
    ", the diagonal blocks of @xmath338 in can be chosen as @xmath349 .",
    "accordingly , the diagonal blocks of @xmath313 in should be @xmath350 to make @xmath124 .",
    "these matrices leads to a variant of algorithm @xmath351    * modifications of nondiagonal blocks : * we change the @xmath352-th block of @xmath128 ( defined by or ) for @xmath353 from @xmath106 to @xmath354 and keep other blocks of @xmath128 unchanged . in order to make @xmath355 symmetric ,",
    "the matrix @xmath313 should be chosen as @xmath356 multiplying the original matrix @xmath313 defined in .",
    "accordingly , the matrix @xmath338 can be determined by @xmath357 .",
    "then we can derive the following two algorithms from iterative scheme @xmath358 @xmath359    * hybrids of both algorithms : * both algorithms and share the same matrix @xmath313 . matrices @xmath128 for algorithms and are almost the same except the diagonal blocks .",
    "let @xmath360 and @xmath361 .",
    "suppose the subproblems of for @xmath293 , @xmath362 can be solved efficiently .",
    "we also assume inner iterations are required to solve the subproblems of for @xmath293 , @xmath363 .",
    "we set the @xmath364-th diagonal block of @xmath128 to be @xmath365 for @xmath362 and to be @xmath366 for @xmath363 .",
    "the nondiagonal blocks of @xmath128 are chosen to be the same as in and .",
    "we further choose the matrix @xmath313 as in .",
    "accordingly , the matrix @xmath338 is determined by @xmath357",
    ". then we obtain the following hybrid algorithm @xmath367 we point out here that convergence of the above algorithms is guaranteed .",
    "one can obtain the convergence results by verifying that the corresponding set of matrices @xmath138 satisfies condition - m and @xmath144 is well - defined .",
    "we omit the details here since the proofs are similar to those of algorithms and .",
    "in this section , we demonstrate the efficiency of the proposed two - step fixed - point proximity algorithms by applying 2sfppa to the sparse magnetic resonance imaging ( mri ) reconstruction problem @xcite",
    ". we shall compare the performances of the proposed 2sfppa with those of other ladmm - type algorithms .      for convenience of exposition",
    ", we assume that an image considered has a size of @xmath368 .",
    "the image is treated as a vector in @xmath369 in such a way its @xmath370-th pixel corresponds to the @xmath371-th component of the vector in @xmath369 .",
    "we set @xmath372 .",
    "let @xmath373 @xmath374 be a partial fourier transform matrix and @xmath375 represent the observed data .",
    "then the general form of the sparse mri reconstruction model can be written as @xmath376 where @xmath377 is a sparse - promoting function .",
    "it is well - known that superior image reconstruction can be obtained when @xmath378 is chosen to be the hybrid of total variation and the @xmath379-norm of the haar wavelet transform .",
    "denote the haar wavelet transform matrix by @xmath380 and define the @xmath381 diagonal matrix @xmath382 with @xmath383 .",
    "we turn to considering the following specific sparse mri problem @xmath384 where @xmath385 trades the total variation with sparsity of the wavelet coefficients @xmath386 .    in order to apply the proposed algorithms ,",
    "we need to reformulate problem .",
    "first , we rewrite @xmath387 to a function composed with a linear mapping . to this end",
    ", we recall the @xmath388 difference matrix @xmath389 by @xmath390 through the matrix kronecker product @xmath391 , we define the @xmath392 matrix @xmath393 by @xmath394 moreover , we define function @xmath395 at @xmath396 as @xmath397^\\top\\right\\|_2.\\ ] ] with the definition of matrix @xmath393 and the convex function @xmath398 , the ( isotropic ) total variation of an image @xmath12 can be represented by @xmath399 moreover , we define @xmath400 at @xmath401 as @xmath402 .",
    "then with help of the formula , function @xmath35 and the indicator function @xmath403 , problem can be equivalently reformulated as @xmath404 recall the dual problem of has a form of @xmath405 by the definition of the fenchel conjugate function , one can easily check that the fenchel conjugate functions in have the form @xmath406 where the sets @xmath407 and @xmath408 are defined as @xmath409\\|_2\\leq \\mu , \\forall i\\in\\mathbb{n}_d : y\\in\\mathbb{r}^{2d}\\}\\ ] ] and @xmath410 therefore , we obtain the following minimization problem @xmath411 obviously , problem is a special case of the multi - block problem with the block number @xmath412",
    ". thus we can directly apply 2sfppa to solving problem .",
    "in particular , all the proximity operators of the convex functions involved in have closed forms .",
    "more precisely , the proximity operators @xmath413 and @xmath414 are exactly the projection operator onto the sets @xmath415 and @xmath416 respectively . the proximity operator",
    "@xmath417 is just the shift operator .",
    "we describe the 2sfppa for the sparse mri model in algorithm [ alg : smri ] .    given : observed data @xmath418 in @xmath419 ; @xmath385 , @xmath420 , @xmath421,@xmath422,@xmath423 and @xmath74 initialization : @xmath424 , @xmath425 , @xmath426 , @xmath427 .",
    "step 1 : @xmath428 , + step 2 : @xmath429 , + step 3 : @xmath430 , + step 4 : @xmath431    write the output of @xmath432 from the above loop as @xmath433 .      in this subsection",
    ", we shall compare numerical results of the proposed 2sfppa with those of the jacobi - type ladmm ( jadmm ) , the ladmm and ladmm with gaussian back substitution ( ladmmg ) for the sparse mri problem .",
    "all the experiments are conducted in matlab 7.6 ( r2008a ) installed on a laptop with intel core i5 cpu at 2.5ghz , 8 g ram running windows 7 .    in the experiment",
    ", we select the @xmath434 `` shepp - logan '' phantom as the test image , see fig.1 ( a ) .",
    "the observed data @xmath418 is obtained by sampling the discrete fourier transform of the phantom along 17 pseudo - radial lines , as shown in fig.1 ( b ) .",
    "the haar wavelet transform @xmath435 is chosen to be non - decimated and thus we have that @xmath436 .",
    "we assume that the upper @xmath154 sub - matrix of @xmath437 is formed by the low - pass filter while the remaining @xmath438 sub - matrix is formed by the high - pass filters .",
    "accordingly , we set the diagonal entries of the diagonal matrix @xmath439 as follows @xmath440 we further take the regularization parameters @xmath441 throughout the test .",
    "we measure the computational efficiency of the compared algorithms by two criteria .",
    "one criterion is the relative error between values of the objective function at each iteration and the optimal function value of problem .",
    "we remark that the indicator function @xmath403 is involved in the objective function and the iterates @xmath442 may not always satisfy @xmath443 .",
    "therefore , for fair numerical comparisons we compute the following relative error @xmath444 where @xmath445 is a penalty parameter and @xmath446 denotes the optimal function value . in practice , we set @xmath447 and run the ladmm for 5000 iterations to obtain an approximation of @xmath446 .",
    "the other one is that the relative error between two successive iterates @xmath448 the quality of the reconstructed image is evaluated in terms of the peak signal - to - noise ratio ( psnr ) defined by @xmath449 where @xmath450 is the original image vector and @xmath451 is the recovered image vector .",
    "[ fig : image ]    [ cols=\"^,^ \" , ]",
    "in this paper , we study the multi - block separable convex problem , which minimizes the sum of several convex functions with linear constraints .",
    "we develop a two - step fixed - point iterative scheme for solving the problem .",
    "we prove that the iterative scheme is convergent and has the convergence rate of @xmath0 in the ergodic sense and the sense of the partial primal - dual gap , where @xmath1 denotes the iteration number .",
    "based on the iterative scheme , we propose a class of convergent two - step algorithms for the multi - block separable convex problem .",
    "convergence analysis for the specific algorithms can be carried out by verifying conditions on the matrices used to construct the algorithms . in the numerical experiments",
    ", we applied our two - step algorithms to the sparse mri problems .",
    "numerical results show that our proposed algorithms perform as efficiently as ladmm and outperform the jladmm and ladmmg .                              , _ a dual algorithm for the solution of nonlinear variational problems via finite element approximation .",
    "2(1 ) , 17 - 40 _ , computers and mathematics with applications , 2 ( 1976 ) , pp .  1740 ."
  ],
  "abstract_text": [
    "<S> multi - block separable convex problems recently received considerable attention . </S>",
    "<S> this class of optimization problems minimizes a separable convex objective function with linear constraints . </S>",
    "<S> the algorithmic challenges come from the fact that the classic alternating direction method of multipliers ( admm ) for the problem is not necessarily convergent . </S>",
    "<S> however , it is observed that admm outperforms numerically many of its variants with guaranteed theoretical convergence . </S>",
    "<S> the goal of this paper is to develop convergent and computationally efficient algorithms for solving multi - block separable convex problems . </S>",
    "<S> we first characterize the solutions of the optimization problems by proximity operators of the convex functions involved in their objective function . </S>",
    "<S> we then design a two - step fixed - point iterative scheme for solving these problems based on the characterization . </S>",
    "<S> we further prove convergence of the iterative scheme and show that it has @xmath0 convergence rate in the ergodic sense and the sense of the partial primal - dual gap , where @xmath1 denotes the iteration number . </S>",
    "<S> moreover , we derive specific two - step fixed - point proximity algorithms ( 2sfppa ) from the proposed iterative scheme and establish their global convergence . numerical experiments for solving the sparse mri problem </S>",
    "<S> demonstrate the numerical efficiency of the proposed 2sfppa .    </S>",
    "<S> multi - block separable convex problems , fixed - point proximity algorithms , two - step algorithms    90c25 , 65k05 </S>"
  ]
}