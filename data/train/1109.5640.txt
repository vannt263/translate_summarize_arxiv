{
  "article_text": [
    "we deal with the additive gaussian noise model@xmath0where @xmath1 is a uniform @xmath2 grid of pixels on the unit square , @xmath3 is the observed image brightness , @xmath4^{2}\\rightarrow \\mathbf{r}_{+}$ ] is an unknown target regression function and @xmath5 are independent and identically distributed ( i.i.d . )",
    "gaussian random variables with mean @xmath6 and standard deviation @xmath7 important denoising techniques for the model ( s1y1 ) have been developed in recent years , see for example buades , coll and morel ( 2005 @xcite ) , kervrann ( 2006 @xcite ) , lou , zhang , osher and bertozzi ( 2010 @xcite ) , polzehl and spokoiny ( 2006 @xcite ) , garnett , huegerich and chui ( 2005 @xcite ) , cai , chan , nikolova ( 2008 @xcite ) , katkovnik , foi , egiazarian , and astola ( 2010 @xcite ) , dabov , foi , katkovnik and egiazarian ( 2006 @xcite ) .",
    "a significant step in these developments was the introduction of the non - local means filter by buades , coll and morel @xcite and its variants ( see e.g. @xcite , @xcite , @xcite ) .  in these filters ,",
    "the basic idea is to estimate the unknown image @xmath8 by a weighted average of the form @xmath9where @xmath10 are some non - negative weights satisfying @xmath11 the choice of the weights @xmath12 are based essentially on two criteria : a local criterion so that the weights are as a decreasing function of the distance to the estimated pixel , and a non - local criterion which gives more important weights to the pixels whose brightness is close to the brightness of the estimated pixel ( see e.g. yaroslavsky ( 1985 @xcite ) and tomasi and manduchi ( 1998 @xcite ) ) .",
    "the non - local approach has been further completed by a fruitful idea which consists in attaching small regions , called data patches , to each pixel and comparing these data patches instead of the pixels themselves .",
    "the methods based on the non - local criterion consist of a comparatively novel direction which is less studied in the literature . in this paper we shall address two problems related to this criterion .    the first problem is how to choose data depending on weights @xmath12 in ( [ s1fx ] ) in some optimal way .",
    "generally , the weights @xmath12 are defined through some priory fixed kernels , often the gaussian one , and the important problem of the choice of the kernel has not been addressed so far for the non - local approach . although the choice of the gaussian kernel seems to show reasonable numerical performance , there is no particular reason to restrict ourselves only to this type of kernel .",
    "our theoretical results and the accompanying simulations show that another kernel should be preferred .",
    "in addition to this , for the obtained optimal kernel we shall also be interested in deriving a locally adaptive rule for the bandwidth choice .",
    "the second problem that we shall address is the convergence of the obtained filter to the true image .",
    "insights can be found in @xcite , kervrann2006optimal , @xcite and @xcite , however the problem of convergence of the non - local means filter has not been completely settled so far . in this paper , we shall give some new elements of the proof of the convergence of the constructed filter , thereby giving a theoretical justification of the proposed approach from the asymptotic point of view .",
    "our main idea is to produce a very tight upper bound of the mean square error @xmath13 in terms of the bias and variance and to minimize this upper bound in @xmath12 under the constraints @xmath14 and @xmath11 in contrast to the usual approach where a specific class of target functions is considered , here we give a bound of the bias depending only on the target function @xmath15 at hand , instead of using just a bound expressed in terms of the parameters of the class .",
    "we first obtain an explicit formula for the optimal weights @xmath16 in terms of the unknown function @xmath17 in order to get a computable filter , we estimate @xmath18 by some adaptive weights @xmath19 based on data patches from the observed image @xmath20 we thus obtain a new filter , which we call _ optimal weights _ filter . to justify theoretically our filter ,  we prove that it achieves the optimal rate of convergence under some regularity conditions on @xmath17 numerical results show that optimal weights filter outperforms the typical non - local means filter , thus giving a practical justification that the optimal choice of the kernel improves the quality of the denoising , while all other conditions are the same .",
    "we would like to point out that related optimization problems for non parametric signal and density recovering have been proposed earlier in sacks and ylvysaker ( 1978 @xcite ) , roll ( 2003 @xcite ) , roll and ljung ( 2004 @xcite ) , roll , nazin and ljung ( 2005 @xcite ) , nazin , roll , ljung and grama ( 2008 @xcite ) . in these papers",
    "the weights are optimized over a given class of regular functions and thus depend only on some parameters of the class .",
    "this approach corresponds to the minimax setting , where the resulting minimax estimator has the best rate of convergence corresponding to the worst image in the given class of images . if the image happens to have better regularity than the worst one , the minimax estimator will exhibit a slower rate of convergence than expected .",
    "the novelty of our work is to find the optimal weights depending on the image @xmath15 at hand , which implicates that our optimal weights filter automatically attains the optimal rate of convergence for each particular image @xmath17 results of this type are related to the `` oracle '' concept developed in donoho and johnstone ( 1994 donoho1994ideal ) .",
    "filters with data - dependent weights have been previously studied in many papers , among which we mention polzehl and spokoiny ( 2000 @xcite , 2003 @xcite , 2006 @xcite ) , kervrann ( 2006 kervrann2006optimal and 2007 @xcite ) .",
    "compared with these filters our algorithm is straightforward to implement and gives a quality of denoising which is close to that of the best recent methods ( see table [ table compar ] ) . the weight optimization approach can also be applied with these algorithms to improve them .",
    "in particular , we can use it with recent versions of the non - local means filter , like the bm3d ( see 2006 @xcite , 2007 @xcite ) ; however this is beyond the scope of the present paper and will be done elsewhere .",
    "the paper is organized as follows .",
    "our new filter based on the optimization of weights in the introduction in section [ sec : constr ] where we present the main idea and the algorithm .",
    "our main theoretical results are presented in section [ sec : main ] where we give the rate of convergence of the constructed estimators . in section [ sec : simulations ] , we present our simulation results with a brief analysis .",
    "proofs of the main results are deferred to section [ sec : appendix proofs ] .    to conclude this section ,",
    "let us set some important notations to be used throughout the paper .",
    "the euclidean norm of a vector @xmath21 is denoted by @xmath22 the supremum norm of @xmath23 is denoted by @xmath24 the cardinality of a set @xmath25 is denoted @xmath26 .",
    "for a positive integer @xmath27 the uniform @xmath2-grid of pixels on the unit square is defined by @xmath28each element @xmath23 of the grid @xmath1 will be called pixel .",
    "the number of pixels is @xmath29 for any pixel @xmath30 and a given @xmath31 the square window of pixels @xmath32will be called _ search window _ at @xmath33",
    "we naturally take @xmath34 as a multiple of @xmath35 ( @xmath36 for some @xmath37 ) .",
    "the size of the square search window @xmath38 is the positive integer number @xmath39 for any pixel @xmath40 and a given @xmath41 a second square window of pixels @xmath42will be called for short a _ patch window _ at @xmath23 in order to be distinguished from the search window @xmath43 like @xmath34 , the parameter @xmath44 is also taken as a multiple of @xmath35 .",
    "the size of the patch window @xmath45 is the positive integer @xmath46 the vector @xmath47 formed by the the values of the observed noisy image @xmath48 at pixels in the patch @xmath45 will be called simply _ data patch _ at @xmath49 finally , the positive part of a real number @xmath50 is denoted by @xmath51 that is@xmath52",
    "let @xmath53 be fixed . for",
    "any pixel @xmath30 consider a family of weighted estimates @xmath54 of the form @xmath55where the unknown weights satisfy @xmath56the usual bias plus variance decomposition of the mean square error gives@xmath57with@xmath58the decomposition ( [ s2ef ] ) is commonly used to construct asymptotically minimax estimators over some given classes of functions in the nonparametric function estimation . in order to highlight the difference between the approach proposed in the present paper and the previous work , suppose that @xmath15 belongs to the class of functions satisfying the hlder condition @xmath59 in this case , it is easy to see that@xmath60optimizing further the weights @xmath12 in the obtained upper bound gives an asymptotically minimax estimate with weights depending on the unknown parameters @xmath61 and @xmath62 ( for details see @xcite ) . with our approach the bias term @xmath63 will be bounded in terms of the unknown function @xmath15 itself . as a result",
    "we obtain some `` oracle '' weights @xmath12 adapted to the unknown function @xmath15 at hand , which will be estimated further using data patches from the image @xmath20    first , we shall address the problem of determining the `` oracle '' weights . with this aim denote@xmath64note that the value @xmath65 characterizes the variation of the image brightness of the pixel @xmath23 with respect to the pixel @xmath33 from the decomposition ( [ s2ef ] ) , we easily obtain a tight upper bound in terms of the vector @xmath66@xmath67where @xmath68    from the following theorem we can obtain the form of the weights @xmath12 which minimize the function @xmath69 under the constraints ( s2wx ) in terms of the values @xmath70 for the sake of generality , we shall formulate the result for an arbitrary non - negative function @xmath71 @xmath72 define the objective function @xmath73introduce into consideration the strictly increasing function@xmath74let @xmath75 be the usual triangular kernel : @xmath76    [ th weights 001]assume that @xmath71 @xmath40 , is a non - negative function",
    ". then the unique weights which minimize @xmath77 subject to ( [ s2wx ] ) are given by @xmath78where the bandwidth @xmath79 is the unique solution on @xmath80 of the equation @xmath81    theorem [ th weights 001 ] can be obtained from a result of sacks and ylvysaker @xcite . the proof is deferred to section [ sec : proof of th weights 001 ] .",
    "[ calculate a ] the value of @xmath79 can be calculated as follows .",
    "we sort the set @xmath82 in the ascending order @xmath83 , where @xmath84 .",
    "let @xmath85 and @xmath86 with the convention that @xmath87 if @xmath88 and that @xmath89 .",
    "then the solution @xmath79 of ( [ eq th weights 002 ] ) can be expressed as @xmath90 ; moreover , @xmath91 is the unique integer @xmath92 such that @xmath93 and @xmath94 if @xmath95 .",
    "the proof of the remark is deferred to section [ sec : proof of remark ] .",
    "let @xmath96 using the optimal weights given by theorem [ th weights 001 ] , we first introduce the following non computable approximation of the true image , called `` oracle '' : @xmath97where the bandwidth @xmath98 is the solution of the equation @xmath99 a computable filter can be obtained by estimating the unknown function @xmath65 and the bandwidth @xmath98 from the data as follows .",
    "let @xmath53 and @xmath41 be fixed numbers . for",
    "any @xmath30 and any @xmath100 consider a distance between the data patches @xmath101 and @xmath102 defined by @xmath103where @xmath104 , and @xmath105 .",
    "since buades , coll and morel @xcite the distance @xmath106 is known to be a flexible tool to measure the variations of the brightness of the image @xmath20 as @xmath107 we have @xmath108 if we use the approximation @xmath109 and the law of large numbers , it seems reasonable that @xmath110 but our simulations show that a much better approximation is @xmath111 the fact that @xmath112 is a good estimator of @xmath113 will be justified by convergence theorems : cf .",
    "theorems [ th adapt 001 ] and [ th adapt 002 ] of section [ sec : main ] . thus our optimal weights filter is defined by@xmath114where the bandwidth @xmath115 is the solution of the equation @xmath116 , which can be calculated as in remark [ calculate a ] ( with @xmath117 and @xmath98 replaced by @xmath112 and @xmath118 respectively ) .",
    "we end this section by giving an algorithm for computing the filter ( [ owfilter ] ) .",
    "the input values of the algorithm are the image @xmath119 @xmath120 , the variance of the noise @xmath121 and two numbers @xmath122 and @xmath123 representing the sizes of the patch window and the search window respectively .    *",
    "* algorithm : * * optimal weights filter    repeat for each @xmath124    give an initial value of @xmath125 : @xmath126 ( it can be an arbitrary positive number ) .",
    "compute @xmath127 by ( [ rho - estim ] )    /_compute the bandwidth _ @xmath118 _ _  at _ _ @xmath128    reorder @xmath129 as increasing sequence , say    @xmath130   loop from @xmath131 to @xmath123    if @xmath132    if @xmath133 then @xmath134    else quit loop    else continue loop    end loop    /_compute the estimated weights _ @xmath19 _ _  at _ _ @xmath128    compute @xmath135    /_compute the filter _ @xmath136 _ _  at _ _ @xmath128    compute @xmath137 .",
    "the proposed algorithm is computationally fast and its implementation is straightforward compared to more sophisticated algorithms developed in recent years .",
    "notice that an important issue in the non - local means filter is the choice of the bandwidth parameter in the gaussian kernel ; our algorithm is parameter free in the sense that it automatically chooses the bandwidth .",
    "the numerical simulations show that our filter outperforms the classical non - local means filter under the same conditions .",
    "the overall performance of the proposed filter compared to its simplicity is very good which can be a big advantage in some practical applications .",
    "we hope that optimal weights that we deduced can be useful with more complicated algorithms and can give similar improvements of the denoising quality . however , these investigations are beyond the scope of the present paper .",
    "a detailed analysis of the performance of our filter is given in section sec : simulations .",
    "in this section , we present two theoretical results .",
    "the first result is a mathematical justification of the `` oracle '' filter introduced in the previous section .",
    "it shows that despite the fact that we minimized an upper bound of the mean square error instead of the mean square error itself , the obtained `` oracle '' still has the optimal rate of convergence .",
    "moreover , we show that the weights optimization approach possesses the following important adaptivity property : our procedure automatically chooses the correct bandwidth @xmath79 even if the radius @xmath53 of the search window @xmath138 is larger than necessary .",
    "the second result shows the convergence of the optimal weights filter @xmath139 under some more restricted conditions than those formulated in section [ sec : constr ] . to prove the convergence , we split the image into two independent parts . from the first one ,",
    "we construct the `` oracle '' filter ; from the second one , we estimate the weights . under some regularity assumptions on the target image we are able to show that the resulting filter has nearly the optimal rate of convergence .",
    "let @xmath71 @xmath140 be an arbitrary non - negative function and let @xmath141 be the optimal weights given by ( [ eq th weights 001 ] ) . using these weights",
    "@xmath141 we define the family of estimates@xmath142depending on the unknown function @xmath143 the next theorem shows that one can pick up a useful estimate from the family @xmath144 if the the function @xmath145 is close to the `` true '' function @xmath146 i.e. if @xmath147where @xmath148 is a small deterministic error .",
    "we shall prove the convergence of the estimate @xmath144 under the local hlder condition @xmath149where @xmath150 is a constant , @xmath31 and @xmath151    in the following , @xmath152 @xmath153 denotes a positive constant , and @xmath154 @xmath155 denotes a number bounded by @xmath156 for some constant @xmath157 .",
    "all the constants @xmath158 and @xmath157 depend only on @xmath61 , @xmath159 and @xmath160 ; their values can be different from line to line .",
    "[ th oracle 001 ] assume that @xmath161 with @xmath162 , or @xmath163 with @xmath164 and @xmath165 .",
    "suppose that @xmath15 satisfies the local hlder s condition ( [ local holder cond ] ) and that @xmath166 then @xmath167    the proof will be given in section [ sec : proof of th oracle 001 ] .",
    "recall that the bandwidth @xmath34 of order @xmath168 is required to have the optimal minimax rate of convergence @xmath169 of the mean squared error for estimating the function @xmath170 of global hlder smoothness @xmath62 ( cf .",
    "e.g. @xcite ) . to better understand the adaptivity property of the oracle @xmath171",
    "assume that the image @xmath15 at @xmath128 has hlder smoothness @xmath62 ( see @xcite ) and that @xmath172 with @xmath173 which means that the radius @xmath53 of the search window @xmath138 has been chosen larger than the `` standard '' @xmath174 then , by theorem [ th oracle 001 ] , the rate of convergence of the oracle is still of order @xmath175 contrary to the global case mentioned above .",
    "if we choose a sufficiently large search window @xmath176 then the oracle @xmath177 will have a rate of convergence which depends only on the unknown maximal local smoothness @xmath62 of the image @xmath17 in particular , if @xmath62 is very large , then the rate will be close to @xmath178 which ensures good estimation of the flat regions in cases where the regions are indeed flat .",
    "more generally , since theorem [ th oracle 001 ] is valid for arbitrary @xmath179 it applies for the maximal local hlder smoothness @xmath180 at @xmath181 therefore the oracle @xmath177 will exhibit the best rate of convergence of order @xmath182 at @xmath33 in other words , the procedure adapts to the best rate of convergence at each point @xmath128 of the image .",
    "we justify by simulation results that the difference between the oracle @xmath144 computed with @xmath183 and the true image @xmath15 , is extremely small ( see table  [ table oracle ] ) .",
    "this shows that , at least from the practical point of view , it is justified to optimize the upper bound @xmath69 instead of optimizing the mean square error @xmath184 itself .",
    "the estimate @xmath185 with the choice @xmath186 will be called oracle filter . in particular for the oracle filter @xmath187 under the conditions of theorem [ th oracle 001 ] , we have@xmath188    now , we turn to the study of the convergence of the optimal weights filter . due to the difficulty in dealing with the dependence of the weights we shall consider a slightly modified version of the proposed algorithm : we divide the set of pixels into two independent parts , so that the weights are constructed from the one part , and the estimation of the target function is a weighted mean along the other part . more precisely ,",
    "assume that @xmath189 @xmath53 and @xmath190 to prove the convergence we split the set of pixels into two parts @xmath191 where @xmath192is the set of pixels with an even sum of coordinates @xmath193 and @xmath194 denote @xmath195 and @xmath196 consider the distance between the data patches @xmath197 and @xmath198 defined by @xmath199where @xmath200 an estimate of the function @xmath201 is given by @xmath202see ( [ rho - estim ] ) .",
    "define the filter @xmath203 by @xmath204where @xmath205    the next theorem gives a rate of convergence of the optimal weights filter if the parameters @xmath53 and @xmath41 are chosen properly according to the local smoothness @xmath206    [ th adapt 001 ] assume that @xmath207 with @xmath208 , and that @xmath209 suppose that function @xmath15 satisfies the local hlder condition ( [ local holder cond ] ) . then @xmath210    for the proof of this theorem see section [ sec : proof of th adapt 001 ] .",
    "theorem [ th adapt 001 ] states that with the proper choices of the parameters @xmath34 and @xmath211 , the mean square error of the estimator @xmath212 converges nearly at the rate @xmath213 which is the usual optimal rate of convergence for a given hlder smoothness @xmath150 ( cf .",
    "e.g. @xcite ) .",
    "simulation results show that the adaptive bandwidth @xmath118 provided by our algorithm depends essentially on the local properties of the image and does not depend much on the radius @xmath34 of the search window .",
    "these simulations , together with theorem [ th oracle 001 ] , suggest that the optimal weights filter ( [ owfilter ] ) can also be applied with larger @xmath214 as is the case of the `` oracle '' filter @xmath215 the following theorem deals with the case where @xmath34 is large .",
    "[ th adapt 002 ] assume that @xmath216 with @xmath217 and @xmath218 and that @xmath219 suppose that the function @xmath15 satisfies the local hlder condition ( [ local holder cond ] ) .",
    "then @xmath220    for the proof of this theorem see section [ sec : proof of th adapt 002 ] .",
    "note that in this case the obtained rate of convergence is not the usual optimal one , in contrast to theorems [ th oracle 001 ] and [ th adapt 001 ] , but we believe that this is the best rate that can be obtained for the proposed filter .",
    "the performance of the optimal weights filter @xmath221 is measured by the usual peak signal - to - noise ratio ( psnr ) in decibels ( db ) defined as@xmath222where @xmath15 is the original image , and @xmath136 the estimated one .    in the simulations , we sometimes shall use the smoothed version of the estimate of brightness variation @xmath223 instead of the non smoothed one @xmath224 it should be noted that for the smoothed versions of the estimated brightness variation we can establish similar convergence results . the smoothed estimate @xmath225 is defined by@xmath226where @xmath227 are some weights defined on @xmath228 the corresponding estimate of brightness variation @xmath229 is given by@xmath230with the rectangular kernel@xmath231we obtain exactly the distance @xmath232 and the filter described in section [ sec : constr ] .",
    "other smoothing kernels @xmath227 used in the simulations are the gaussian kernel @xmath233where @xmath234 is the bandwidth parameter and the following kernel@xmath235with the width of the similarity window @xmath236 the shape of these two kernels are displayed in figure  [ fig kernels 1 ] .    to avoid the undesirable border effects in our simulations , we mirror the image outside the image limits , that is we extend the image outside the image limits symmetrically with respect to the border . at the corners ,",
    "the image is extended symmetrically with respect to the corner pixels .",
    "( left ) and @xmath237 ( right ) with @xmath238 @xmath239.,title=\"fig : \" ]   ( left ) and @xmath237 ( right ) with @xmath238 @xmath239.,title=\"fig : \" ]       we have done simulations on a commonly - used set of images available at http://decsai.ugr.es/javier/denoise/test images/ which includes lena , barbara , boat , house , peppers . the potential of the estimation method is illustrated with the @xmath240 image `` lena '' ( figure  [ fig4](a ) ) and `` barbara '' ( figure  [ fig barbara](a ) ) corrupted by an additive white gaussian noise ( figures  [ fig4](b ) , psnr@xmath241 , @xmath242 and  [ fig barbara ] ( b ) , psnr@xmath243 , @xmath244 ) .",
    "we first used the rectangular kernel @xmath237 for computing the estimated brightness variation function @xmath245 which corresponds to the optimal weights filter as defined in section sec : constr .",
    "empirically we found that the parameters @xmath122 and @xmath123 can be fixed to @xmath246 and @xmath247 in figures  [ fig4](c ) and  [ fig barbara](c ) , we can see that the noise is reduced in a natural manner and significant geometric features , fine textures , and original contrasts are visually well recovered with no undesirable artifacts ( psnr@xmath248 for `` lena '' and psnr @xmath249 for `` barbara '' ) . to better appreciate the accuracy of the restoration process",
    ", the square of the difference between the original image and the recovered image is shown in figures  fig4(d ) and  [ fig barbara](d ) , where the dark values correspond to a high - confidence estimate .",
    "as expected , pixels with a low level of confidence are located in the neighborhood of image discontinuities . for comparison",
    ", we show the image denoised by non - local means filter in figures  [ fig4](e),(f ) and  [ fig barbara ] ( e ) , ( f ) . the overall visual impression and the numerical results",
    "are improved using our algorithm .    ' '' ''    ' '' ''    the optimal weights filter seems to provide a feasible and rational method to detect automatically the details of images and take the proper weights for every possible geometric configuration of the image . for illustration purposes ,",
    "we have chosen a series of search windows @xmath38 with centers at some testing pixels @xmath128 on the noisy image , see figure  [ fig selected ] the distribution of the weights inside the search window @xmath38 depends on the estimated brightness variation function @xmath250 @xmath72 if the estimated brightness variation @xmath251 is less than @xmath118 ( see theorem [ th weights 001 ] ) , the similarity between pixels is measured by a linear decreasing function of @xmath252 otherwise it is zero .",
    "thus @xmath118 acts as an automatic threshold . in figure  [ fig weights",
    "] , it is shown how the optimal weights filter chooses in each case a proper weight configuration .        ' '' ''    the best numerical results are obtained using @xmath253 and @xmath254 in the definition of @xmath255 in table  [ table compar ] , we compare the non - local mean filter and the optimal weights filter with different choices of the kernel : @xmath256 the best psnr values we obtained by varying the size @xmath122 of the similarity windows and the size @xmath123 of the search windows are reported in tables  [ table11 ] ( @xmath257 ) , [ table12 ] ( @xmath242 ) and [ table13 ] ( @xmath258 ) for @xmath259 note that the psnr values are close for every @xmath122 and @xmath123 and the optimal @xmath122 and @xmath123 depend on the image content .",
    "the values @xmath246 and @xmath260 seem appropriate in most cases and a smaller patch size @xmath122 can be considered for processing piecewise smooth images .",
    "we begin with some preliminary results .",
    "the following lemma can be obtained from theorem 1 of sacks and ylvisaker @xcite . for the convenience of readers ,",
    "we prefer to give a direct proof adapted to our situation .",
    "[ lemma weights]let @xmath261 be defined by ( [ def gw ] )",
    ". then there are unique weights @xmath262 which minimize @xmath261 subject to ( [ s2wx ] ) , given by @xmath263where @xmath264 and @xmath265 are determined by@xmath266    let @xmath267 be a minimizer of @xmath268 under the constraint ( [ s2wx ] ) . according to theorem 3.9 of whittle ( 1971 @xcite ) , there are lagrange multipliers @xmath269 and @xmath270 @xmath140 such that the function@xmath271is minimized at the same point @xmath272 since the function @xmath273 is strictly convex it admits a unique point of minimum .",
    "this implies that there is also a unique minimizer of @xmath268 under the constraint ( [ s2wx ] ) which coincides with the unique minimizer of @xmath274    let @xmath262 be the unique minimizer of @xmath273 satisfying the constraint ( [ s2wx ] ) .",
    "again , using the fact that @xmath273 is strictly convex , for any @xmath140 @xmath275note that in general we do not have an equality in ( [ s5kw1 ] ) .",
    "in addition , by the karush - kuhn - tucker condition , @xmath276    let @xmath277then ( [ s5kw1 ] ) becomes @xmath278    if @xmath279 then , with respect to the single variable @xmath280 the function @xmath281 attains its minimum at an interior point @xmath282 , so that we have @xmath283from this we obtain @xmath284 , so @xmath285    if @xmath286 , by ( [ s5bx ] ) , we have @xmath287 .",
    "consequently , from ( [ s5lr ] ) we have @xmath288 so that we get again@xmath289as to the conditions ( [ eq lemma w001 ] ) and ( [ eq lemma w002 ] ) , they follow immediately from the constraint ( [ s2wx ] ) and the equation ( [ lambda def ] ) .",
    "+   +   * proof of theorem [ th weights 001]*. applying lemma lemma weights with @xmath290 , we see that the unique optimal weights @xmath12 minimizing @xmath261 subject to ( [ s2wx ] ) , are given by @xmath291where @xmath98 and @xmath265 satisfy@xmath292and@xmath293since the function @xmath294is strictly increasing and continuous with @xmath295 and @xmath296 the equation @xmath297has a unique solution on @xmath80 . by ( [ eq proof th w 001 ] ) , @xmath298which together with ( [ s5wl ] ) imply ( [ eq th weights 001 ] ) and ( eq th weights 002 )",
    ".      expression ( [ def mt ] ) can be rewritten as @xmath299 since function @xmath300 is strictly increasing with @xmath301 and @xmath302 , equation ( [ eq th weights 002 ] ) admits a unique solution @xmath98 on @xmath303 , which must be located in some interval @xmath304 , @xmath305 , where @xmath306 ( see figure [ fig rho ] ) . hence the equation ( [ eq th weights 002 ] ) becomes @xmath307 where @xmath308 . from ( [ function m ] )",
    ", it follows that @xmath309    we now show that @xmath310 ( so that @xmath311 ) , where @xmath312 . to this end , it suffices to verify that @xmath313 and @xmath314 if @xmath315 .",
    "we have already seen that @xmath313 ; if @xmath315 , then @xmath316 , so that @xmath317    we finally prove that if @xmath318 and @xmath319 , then @xmath94 , so that the last equality in ( [ k star ] ) holds and that @xmath91 is the unique integer @xmath320 such that @xmath321 and @xmath94 if @xmath322 . in fact , for @xmath322 , the inequality @xmath319 implies that @xmath323 this , in turn , implies that @xmath324    ( 0,0 ) ( -150,0)(1 , 0)300 ( -150,0)(0 , 1)3 ( -150,3)0 ( -150,-10)@xmath325 ( -120,0)(0 , 1)3 ( -120,-10)@xmath326 ( -90,-10)@xmath327 ( -60,0)(0 , 1)3 ( -60,-10)@xmath328 ( -35,0 ) ( -35,3)@xmath98 ( -10,0)(0 , 1)3 ( -10,-10)@xmath329 ( 30,-10)@xmath327 ( 60,0)(0 , 1)3 ( 60,-10)@xmath330      first assume that @xmath331 recall that @xmath332 and @xmath262 were defined by ( [ def gw ] ) and ( [ eq th weights 001 ] ) .",
    "using hlder s condition ( local holder cond ) we have , for any @xmath12 , @xmath333where @xmath334 in particular , denoting @xmath335 we get@xmath336by theorem [ th weights 001 ] , @xmath337where @xmath79 is the unique solution on @xmath80 of the equation @xmath338 , with @xmath339theorem [ th oracle 001 ] will be a consequence of the following lemma .",
    "[ lm5_2]assume that @xmath340 and that @xmath341 with @xmath164 , or @xmath161 with @xmath342 then @xmath343and @xmath344where @xmath345 and @xmath346 are positive constants depending only on @xmath347 @xmath61 and @xmath348    we first prove ( [ s5hk ] ) in the case where @xmath349 , i.e. @xmath350 . then by the definition of @xmath351 we have @xmath352let @xmath353 . then @xmath354 if and only if @xmath355 .",
    "so from ( [ eq - m1 001 ] ) we get@xmath356by the definition of the neighborhood @xmath357 it is easily seen that@xmath358and@xmath359therefore , ( [ eq - m1 002 ] ) implies @xmath360from which we infer that@xmath361with @xmath362 from ( [ eq - h bar ] ) and the definition of @xmath363 , we obtain@xmath364 which prove ( [ s5hk ] ) in the case when @xmath349 .",
    "we next prove ( [ s5hk ] ) under the conditions of the lemma .",
    "if @xmath365 where @xmath366 then it is clear that @xmath367 for @xmath368 sufficiently large .",
    "therefore @xmath369 , thus we arrive at equation ( [ eq - m1 001 ] ) from which we deduce ( [ eq - h bar ] ) .",
    "if @xmath370 and @xmath371 then again @xmath372 for @xmath368 sufficiently large . therefore @xmath373 , and we arrive again at ( [ eq - h bar ] ) .",
    "we finally prove ( [ s5gw4 ] ) .",
    "denote for brevity @xmath374since @xmath367 for @xmath368 sufficiently large , we have @xmath375 and @xmath376 then it is easy to see that@xmath377since @xmath378we obtain @xmath379where @xmath346 is a constant depending on @xmath347 @xmath61 and @xmath348     +   + * proof of theorem [ th oracle 001]*. as @xmath380 we have @xmath381 hence @xmath382 so @xmath383 therefore , by lemma [ lm5_2 ] and the condition that @xmath384 , we obtain @xmath385 this gives ( [ s2ef2 ] ) .",
    "we begin with a decomposition of @xmath386 .",
    "note that @xmath387recall that @xmath388 , @xmath389 let @xmath390 be the translation mapping @xmath391 denote @xmath392 and @xmath393 since@xmath394it is easy to see that@xmath395where@xmath396with@xmath397 notice that @xmath398 then obviously @xmath399    first we prove the following lemma .",
    "[ lemma - ad2 - 001 ] suppose that the function @xmath15 satisfies the local hlder condition ( [ local holder cond ] ) .",
    "then , for any @xmath400@xmath401    by the decomposition@xmath402 + \\left [ f\\left ( y\\right ) -f\\left ( x_{0}\\right ) \\right ] + \\left [ f\\left ( x\\right ) -f\\left",
    "( t_{x_{0},x}\\left ( y\\right ) \\right ) \\right]\\ ] ]    and the inequality @xmath403 we obtain@xmath404    by the local hlder condition ( [ local holder cond ] ) this implies@xmath405which gives the upper bound .",
    "the lower bound can be proved similarly using the inequality @xmath406    we first prove a large deviation inequality for @xmath407 .",
    "[ lemma s]let @xmath407 be defined by ( [ centering ] ) .",
    "then there are two constants @xmath408 and @xmath409 such that for any @xmath410 @xmath411    denote @xmath412 since @xmath413 is a normal random variable with mean @xmath6 and variance @xmath414 , the random variable @xmath415 has an exponential moment , i.e. there exist two positive constants @xmath416 and @xmath345 depending only on @xmath347 @xmath61 and @xmath417 such that @xmath418 for any @xmath419 let @xmath420 be the cumulate generating function . by chebyshev s exponential inequality we get,@xmath421for any @xmath422 and for any @xmath423 by the - three terms taylor expansion , for @xmath424@xmath425where @xmath426 @xmath427 @xmath428 and@xmath429since , by jensen s inequality @xmath430 we obtain the following upper bound:@xmath431using the elementary inequality @xmath432 @xmath433 we have , for @xmath434 @xmath435this implies that for @xmath424@xmath436and@xmath437if @xmath438 , where @xmath346 is a positive constant , we obtain@xmath439choosing @xmath440 sufficiently small we get@xmath441for some constant @xmath442 in the same way we show that@xmath443this proves the lemma .",
    "we next prove that @xmath444 is uniformly of order @xmath445 with probability @xmath446 if @xmath34 has the order @xmath447    [ lm5_4 ] suppose that the function @xmath15 satisfies the local hlder condition ( [ local holder cond ] ) .",
    "assume that @xmath448 with @xmath449 and that @xmath209 then there exists a constant @xmath450 depending only on @xmath347 @xmath61 and @xmath121 , such that @xmath451    using lemma [ lemma s ] , there are two constants @xmath452 @xmath453 such that , for any @xmath454 satisfying @xmath455@xmath456    recall that @xmath457 leting @xmath458 and choosing @xmath459 sufficiently large we obtain @xmath460 using lemma [ lemma - ad2 - 001 ] and the local hlder condition ( local holder cond ) we have @xmath461 for @xmath462 from ( [ rho hat bound ] ) and ( [ d bound ] ) , with probability @xmath446 we have@xmath463since",
    "@xmath464 this gives the desired result .",
    "we then prove that given @xmath465 the conditional expectation of @xmath466 is of order @xmath467 with probability @xmath468    [ s5ef]suppose that the conditions of theorem [ th adapt 001 ] are satisfied .",
    "then @xmath469where @xmath157 is a constant depending only on @xmath347 @xmath61 and @xmath348    by ( [ owfilter prim ] ) and the independence of @xmath470 , we have @xmath471since @xmath472 , from ( [ eq lemma experance ] ) we get @xmath473    let @xmath474 , where @xmath475as @xmath476 minimizes the function in ( [ s3ww ] ) , from ( [ espect mse ] ) we obtain @xmath477by lemma [ lm5_4 ] , with probability @xmath478 we have @xmath479therefore by ( [ s5ef4 ] ) , with probability @xmath478 , @xmath480this gives the assertion of lemma [ lm5_6 ] , as @xmath481 and @xmath482 by lemma [ lm5_2 ] with @xmath483 instead of @xmath43    now we are ready to prove theorem [ th adapt 001]._proof of theorem [ th adapt 001 ] .",
    "_ since the function @xmath15 satisfies hlder s condition , by the definition of @xmath484 ( cf .",
    "( upper bound g1 ) ) we have@xmath485so that@xmath486denote by @xmath487 the conditional expectation in the above display and write @xmath488 for the indicator function of the set @xmath489 . then@xmath490so applying lemma [ s5ef ] , we see that @xmath491this proves theorem [ th adapt 001 ] .",
    "we keep the notations of the prevoius subsection .",
    "the following result gives a two sided bound for @xmath492    [ lemma - ad2 - 002 ] suppose that the function @xmath15 satisfies the local hlder condition ( [ local holder cond ] ) .",
    "assume that @xmath216 with @xmath165 and @xmath493 and that @xmath209 then there exists positive constants @xmath494 @xmath452",
    "@xmath453 and @xmath459 depending only on @xmath347 @xmath61 and @xmath121 , such that @xmath495and@xmath496    as in the proof of lemma [ lm5_4 ] , we have @xmath497using lemma [ lemma - ad2 - 001 ] , for any @xmath498@xmath499from ( [ rho hat bound ] ) we have@xmath500for the upper bound we have , for any @xmath400@xmath501therefore , with probability @xmath446@xmath502    for the lower bound , we have , for any @xmath400 we have@xmath503taking into account ( [ eqadxxx002 ] ) , on the set @xmath504@xmath505    therefore , with probability @xmath446@xmath506so the lemma is proved .    we then prove that given @xmath507 , the conditional expectation of @xmath466 is of order @xmath445 with probability @xmath508 .",
    "[ lemma - ad-003]suppose that the conditions of theorem [ th adapt 002 ] are satisfied .",
    "then @xmath509where @xmath157 is a constant depending only on @xmath62 , @xmath61 and @xmath121 .",
    "[ lm5_6 ]    by ( [ owfilter prim ] ) and the independence of @xmath470 , we have @xmath510since , by lemma [ lemma - ad2 - 002 ] , with probability @xmath511    @xmath512    we get ( with probability @xmath508),@xmath513a simple truncation argument , using the decomposition @xmath514gives @xmath515    from ( [ expect2 ] ) and ( [ expect3 ] ) one gets@xmath516    let @xmath474 , where @xmath517 was defined in ( [ s5ef4 ] ) .",
    "as @xmath476 minimize the function in ( [ s3ww ] ) , from ( [ espect mse ] ) we obtain @xmath518by lemma [ lemma - ad2 - 002 ] , with probability @xmath446 @xmath519therefore , with probability @xmath520 @xmath521this gives the assertion of lemma [ lm5_6 ] , as @xmath522 by lemma [ lm5_2 ] with @xmath483 instead of @xmath38 .",
    "_ proof of theorem [ th adapt 002]_. since the function @xmath15 satisfies hlder s condition , by the definition of @xmath484 ( cf .",
    "( upper bound g1 ) ) we have ( see the proof of theorem [ th adapt 001])@xmath523so that @xmath486denote by @xmath487 the conditional expectation in the above display .",
    "then @xmath524so applying lemma [ lemma - ad-003 ] , we see that @xmath525this proves theorem [ th adapt 002 ]",
    "a new image denoising filter to deal with the additive gaussian white noise model based on a weights optimization problem is proposed .",
    "the proposed algorithm is computationally fast and its implementation is straightforward .",
    "our work leads to the following conclusions .    1 .   in the non - local means filter the choice of the gaussian kernel",
    "is not justified .",
    "our approach shows that it is preferable to choose the triangular kernel .",
    "2 .   the obtained estimator is shown to converge at the usual optimal rate , under some regularity conditions on the target function . to the best of our knowledge such convergence results have not been established so far .",
    "3 .   our filter is parameter free in the sense that it chooses automatically the bandwidth parameter .",
    "our numerical results confirm that optimal choice of the kernel improves the performance of the non - local means filter , under the same conditions ."
  ],
  "abstract_text": [
    "<S> a new image denoising algorithm to deal with the additive gaussian white noise model is given . </S>",
    "<S> like the non - local means method , the filter is based on the weighted average of the observations in a neighborhood , with weights depending on the similarity of local patches . </S>",
    "<S> but in contrast to the non - local means filter , instead of using a fixed gaussian kernel , we propose to choose the weights by minimizing a tight upper bound of mean square error . </S>",
    "<S> this approach makes it possible to define the weights adapted to the function at hand , mimicking the weights of the oracle filter . under some regularity conditions on the target image </S>",
    "<S> , we show that the obtained estimator converges at the usual optimal rate . </S>",
    "<S> the proposed algorithm is parameter free in the sense that it automatically calculates the bandwidth of the smoothing kernel ; it is fast and its implementation is straightforward . </S>",
    "<S> the performance of the new filter is illustrated by numerical simulations . </S>"
  ]
}