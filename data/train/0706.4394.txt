{
  "article_text": [
    "let @xmath10 be a compact design space and let @xmath11 be the set of all designs ( i.e. , finitely supported probability measures ) on @xmath7 .",
    "for any @xmath12 , let @xmath13 denote the information matrix .",
    "suppose that there exists a design with nonsingular information matrix and let @xmath14 be the set of such designs .",
    "let @xmath15 denote a @xmath0-optimum design , that is , a measure in @xmath11 that maximizes @xmath16 , see , e.g. , @xcite .",
    "note that a @xmath0-optimum design always exists and that the @xmath0-optimum information matrix @xmath17 is unique . for any @xmath18 denote @xmath19 the variance function defined by @xmath20    the celebrated kiefer - wolfowitz equivalence theorem ( 1960 ) writes as follows .",
    "[ thm : eq ] the following three statements are equivalent :    ( i ) : :    @xmath21 is @xmath0-optimum ; ( ii ) : :    @xmath22 ; ( iii ) : :    @xmath21 minimizes    @xmath23 , @xmath24 .",
    "notice that @xmath25 hence , ( ii ) of theorem [ thm : eq ] implies that for any support point @xmath6 of the design @xmath15 ( i.e. , for a point satisfying @xmath26 ) , we have @xmath27 in the next section we show that the equality ( [ eq : sup ] ) can be used to prove that @xmath28 where @xmath29 depends on @xmath1 only via the maximum of @xmath30 over the design space @xmath31 .",
    "hence , we can test candidate support points by using any finite number of design measures @xmath32 , e.g. , those that are generated by a design algorithm on its way towards the optimum : any point that does not pass the test defined by @xmath33 of iteration @xmath34 need not be considered for further investigations and can thus be removed from the design space .",
    "for @xmath1 a design in @xmath14 denote @xmath35 , @xmath36 and @xmath37 the eigenvalues of @xmath38 . notice that @xmath39 and that the eigenvalues depend on the design @xmath1 as well as on the @xmath0-optimum information matrix @xmath40 .",
    "let @xmath6 be a support point of a @xmath0-optimum design and let @xmath41 .",
    "the equality ( [ eq : sup ] ) can be written in the form @xmath42 which implies : @xmath43 to be able to use the inequality ( [ ineq : megn ] ) , we need to derive a lower bound @xmath29 on @xmath44 that does not depend on the unknown matrix @xmath40 .    theorem [ thm : eq]-(ii ) implies @xmath45 also , @xmath46 where we used the notation @xmath47 for @xmath48 we directly obtain the lower bound @xmath49 . for @xmath50 , the lagrangian for the minimisation of @xmath44 subject to @xmath51 and @xmath52 is given by @xmath53 with @xmath54 , @xmath55 .",
    "the stationarity of @xmath56 with respect to the @xmath57 s and the kuhn - tucker conditions @xmath58 give @xmath59 for @xmath60 , with @xmath44 and @xmath61 satisfying @xmath62 the solution is thus @xmath63 and @xmath64 , @xmath60 .",
    "notice that the bound ( [ ineq : lb ] ) gives @xmath65 when @xmath48 and can thus be used for any dimension @xmath66 . by substituting @xmath29 for @xmath44 in ( [ ineq : megn ] )",
    "we obtain the following result .",
    "the inequality in @xcite uses @xmath71\\,.\\ ] ] notice , that @xmath72 for all integer @xmath66 and all @xmath73 , and that @xmath74 while @xmath75 .",
    "the new bound is thus always stronger , especially for large values of @xmath76 , i.e. when the design @xmath1 is far from being optimum .",
    "although in practice the improvement over ( [ tildeh ] ) can be marginal , see the example below , the important result here is that the bound ( [ * * ] ) can not be improved . indeed ,",
    "when @xmath48 , @xmath77 for any @xmath78 which is clearly the best possible bound .",
    "when @xmath79 , @xmath80 is the tightest lower bound on the variance function @xmath9 at a @xmath0-optimal support point @xmath81 that depends only on @xmath82 and @xmath76 , in the sense of the following theorem .    for any integer @xmath79 and any @xmath83 there",
    "exist a compact design space @xmath84 , a design @xmath1 on @xmath7 and a point @xmath85 supporting a @xmath0-optimum design on @xmath31 such that @xmath86 and @xmath87    _ proof . _",
    "denote @xmath88 and @xmath89 .",
    "let @xmath90 correspond to the @xmath34 vectors of @xmath91 of the form @xmath92 and let @xmath93 correspond to the @xmath34 vectors @xmath94 .",
    "take @xmath95 with @xmath96 , @xmath7 as the finite set @xmath97 and let @xmath1 be the uniform probability measure on @xmath98 .",
    "note that @xmath99 is a diagonal matrix with diagonal elements @xmath100,\\ldots,(h-1)/[h(m-1)]\\right)$ ] .",
    "one can easily verify that @xmath101 the uniform probability measure @xmath102 on @xmath103 is @xmath0-optimum on @xmath104 , as can be directly verified by checking ( ii ) of the equivalence theorem [ thm : eq ] . on the other hand",
    ", @xmath102 is not @xmath0-optimum on @xmath7 since @xmath105 , which implies that @xmath6 must support a @xmath0-optimum design on @xmath7 .",
    "we consider a series of problems defined by the construction of the minimum covering ellipse for an initial set of 1000 random points in the plane , i.i.d.@xmath106 .",
    "these problems correspond to @xmath0-optimum design problems for randomly generated @xmath107 , see @xcite .",
    "the following recursion can thus be used:@xmath108 where @xmath109 , @xmath110 is the weight given by the discrete design @xmath33 to the point @xmath111 and @xmath112 is the cardinality of @xmath31 at iteration @xmath34 . in the original algorithm ,",
    "@xmath113 for all @xmath34 and , initialized at a @xmath114 that gives a positive weight at each point of @xmath31 , the algorithm converges monotonically to the optimum , see @xcite and @xcite .",
    "the tests ( [ * * ] ) and ( [ tildeh ] ) can be used to decrease @xmath112 : at iteration @xmath34 , any design point @xmath115 satisfying @xmath116 $ ] , see ( [ epsilon ] , [ * * ] ) , or @xmath117 $ ] , see ( [ epsilon ] , [ tildeh ] ) , can be removed from @xmath31 .",
    "the total weight of the points that are cancelled is then reallocated to the @xmath111 s that stay in @xmath31 ( e.g. , proportionally to @xmath118 ) .",
    "figure [ f : ellips ] presents a typical evolution of @xmath112 as a function of @xmath119 for @xmath114 uniform on @xmath31 and shows the superiority of the test ( [ * * ] ) over ( [ tildeh ] ) .",
    "the improvement is especially important in the first iterations , when the design @xmath33 is far from the optimum .",
    "define @xmath120 as the number of iterations required to reach a given precision @xmath121 , @xmath122 with @xmath123 defined by ( [ epsilon ] ) .",
    "notice that from the concavity of @xmath124 we have @xmath125}{\\partial\\alpha}_{|\\alpha=0 } \\\\    & & = \\int_{\\sx } d(\\xi^{k^*(\\delta)},\\xb)\\ , \\xi^*(d\\xb ) - m",
    "< \\delta \\,.\\end{aligned}\\ ] ] table [ tb : ellips ] shows the influence on the algorithm ( [ recursion ] ) of the cancellation of points based on the tests ( [ * * ] ) and ( [ tildeh ] ) , in terms of @xmath120 , of the corresponding computing time @xmath126 , the number of support points @xmath127 of @xmath128 and the first iteration @xmath129 when @xmath33 has 10 support points or less , with @xmath130 .",
    "the results are averaged over 1000 independent problems .",
    "the values of @xmath120 and @xmath129 are rounded to the nearest larger integer , the computing time for the algorithm with the cancellation of points based on ( [ * * ] ) is taken as reference and set to 1 ( the algorithm without cancellation was at least 4.5 times slower in all the 1000 repetitions ) .",
    "although cancelling points has little influence on the number of iterations @xmath120 , is renders the iterations simpler : on average the introduction of the test ( [ * * ] ) in the algorithm ( [ recursion ] ) makes it about 30 times faster .",
    "the influence of the cancellation on the performance of the algorithm can be further improved as follows .",
    "let @xmath131 denote the subsequence corresponding to the iterations where some points are removed from @xmath31 .",
    "we have @xmath132 , the cardinality of the initial @xmath31 , and the convergence of the algorithm ( [ recursion ] ) is therefore maintained whatever the heuristic rule used at the iterations @xmath133 for updating the weights of the points that stay in @xmath31 ( provided these weights remain strictly positive ) .",
    "the following one has been found particularly efficient on a series of examples : for all @xmath134 , the set of indices corresponding to the points that stay in @xmath31 at iteration @xmath133 , replace @xmath135 by @xmath136 for some @xmath137 .",
    "a final remark is that by including the test ( [ * * ] ) in the algorithm ( [ recursion ] ) one can in general quickly identify potential support points for an optimum design . when the number @xmath138 of these points is small enough , switching to a more standard convex - programming algorithm for the optimization of the @xmath138 associated weights",
    "might then form a very efficient strategy .",
    "titterington , d. , 1976 .",
    "algorithms for computing d - optimal designs on a finite design space . in : proc . of the 1976 conference on information science and systems . dept . of electronic engineering , john hopkins university , baltimore , pp .",
    "213216 .",
    "torsney , b. , 1983 .",
    "a moment inequality and monotonicity of an algorithm . in : kortanek , k. , fiacco , a. ( eds . ) , proc .",
    "int . symp . on semi - infinite programming and applications .",
    "springer , heidelberg , pp ."
  ],
  "abstract_text": [
    "<S> we improve the inequality used in @xcite to remove points from the design space during the search for a @xmath0-optimum design . </S>",
    "<S> let @xmath1 be any design on a compact space @xmath2 with a nonsingular information matrix , and let @xmath3 be the maximum of the variance function @xmath4 over all @xmath5 . </S>",
    "<S> we prove that any support point @xmath6 of a @xmath0-optimum design on @xmath7 must satisfy the inequality @xmath8 . </S>",
    "<S> we show that this new lower bound on @xmath9 is , in a sense , the best possible , and how it can be used to accelerate algorithms for @xmath0-optimum design .    and    @xmath0-optimum design , design algorithm , support points    62k05 , 90c46 </S>"
  ]
}