{
  "article_text": [
    "future computer systems are required to scale to large volume of data that is being generated and used , with increasing capacities and dropping prices of magnetic disks .",
    "traditional das based architectures , based on parallel scsi transport , scale poorly owing to their distance , connectivity and throughput limitations and are being replaced by networked storage systems like san .",
    "figure [ fig : san ] shows a san connecting multiple servers to multiple targets .",
    "sans , where the storage devices are connected directly to a highspeed network , can provide high scalability and throughput guarantees ; sans allow any - to - anywhere access across the network , using interconnect elements such as routers , gateways , hubs and switches ; they also facilitate storage sharing between possibly heterogeneous servers to improve storage utilization and reduce downtime .",
    "entities in a san , both storage and servers , communicate using scsi commands .",
    "a sender encapsulates scsi commands over a transport protocol and sends it to one or more receivers ; receivers receive the payload , decapsulates the commands , and execute them .",
    "thus a san is defined by the transport it uses and the encapsulation standard it follows . in this lieu , there are two competing industry standards  fc and iscsi , which allow us to build sans , each based on differing transport and encapsulation standards .    the fibre channel ( fc ) is a serial interface , usually implemented with fibre - optic cable .",
    "fc standard @xcite covers the physical , link , network and transport layers of the osi network stack and also provide a scsi encapsulation protocol  fcp .",
    "fc sans , with most fcp implementations being hardware accelerated , provide better throughput guarantees . however , fc installations are costlier and are can not be deployed over long distances .",
    "fibre channel requires custom network components and is not able to take advantage of the steep technology curves and dropping costs of ip - based networks .",
    "internet scsi or iscsi @xcite is a storage networking standard that transports scsi commands over tcp / ip , essentially tunneling storage protocols on top of tcp , hence ip , to leverage the installed equipment base .",
    "this allows iscsi to be used over any tcp / ip network infrastructure with the remote device being seen by the operating system as a locally available block - level device . unlike fibre channel",
    ", iscsi can run on any network infrastructure that supports tcp / ip .",
    "a network that uses iscsi needs only one network for both storage and data traffic whereas fibre channel requires separate infrastructure for storage and data traffic .",
    "however , a response to a block - level request in iscsi may encounter a greater delay compared to fibre channel , depending on the network conditions and the location of the target .",
    "current efforts to improve end - to - end performance for tcp are taking advantage of the empirically discovered mechanism of striping data transfers across a set of parallel tcp connections between a sender and receiver to substantially increase tcp throughput .",
    "however , when multiple connections are used between the same source - target pairs , the connections themselves interact / compete with each other in non trivial ways . in order to achieve optimal throughput",
    "it is imperative that we understand these interactions and treat the connections accordingly ; failing which could lead to increased congestion and reduced throughput .        in our work ,",
    "we study the effects of using multiple tcp connections on iscsi .",
    "it was shown in @xcite that the aggregate iscsi throughput increases with the increase in number of tcp connections in an emulated wide area network .",
    "we find that the multiple tcp connections used by iscsi compete with each other and result in lesser throughput for iscsi than they are capable of .",
    "we propose a solution named fair - tcp based on tcp control block interdependence @xcite for managing tcp connections .",
    "we compare the performance of our variant with the standard tcp reno@xcite with sack@xcite , using various workloads and varying delays in an emulated wide area network .",
    "we find that for i / o intensive workloads such as sequential write to a large file , postmark and bonnie , fair - tcp provides significant performance improvements over standard tcp - reno with sack .",
    "section 2 describes the behaviour of multiple tcp connections and its effects on iscsi .",
    "the proposed solution is also outlined there .",
    "section 3 details the experimental setup , tools and benchmarks used in our experiments .",
    "section 4 presents our results with a discussion .",
    "section 5 reviews related work .",
    "section 6 concludes the paper .",
    "scsi standard assumes that the underlying transport is reliable and supports fifo ordering of commands .",
    "tcp has mechanisms to acknowledge the received tcp packets and to resend / request packets that are not acknowledged within a certain time period , effectively guaranteeing reliable and in - order delivery of packets . choosing tcp as a transport is thus a natural choice .",
    "if iscsi were defined on top of a protocol that is not reliable and in - order then iscsi would have had to provide these services by itself .",
    "iscsi initiators are usually connected to iscsi targets using multiple tcp connections .",
    "the reason is two fold : due to tcp window size restrictions and round trip times over long distances , it might not be possible for a single tcp connection to utilize the full bandwidth capacity of the underlying link ; secondly , there may also be several physical interconnects connecting the initiator and target , and it would be most desirable to aggregate and simultaneously utilize all such existing physical interconnects .",
    "as tcp does not support such aggregation , an iscsi session is therefore defined to be a collection of one or more tcp connections between the initiator and the target .",
    "many applications use multiple tcp connections between client and server for increased throughput . however these tcp connections are treated independently : most tcp implementations keep state on a per - connection basis in a structure called tcp control block ( tcb ) or an equivalent construct and each of these tcp connections are handled independently .",
    "several researchers ( @xcite , @xcite , @xcite ) have shown that concurrent connections such as these compete with each other for link bandwidth , often resulting in unfair and arbitrary sharing of bandwidth .",
    "concurrent connections do not share indications of congestion along the shared path between the sender and receiver .",
    "therefore each connection independently pushes the network to a point where packet losses are bound to happen .",
    "once the network is congested , all the competing connections reduce their transmission windows drastically , thus limiting the effective bandwidth available to the application , this results in under utilization of the shared link , and hence less aggregate throughput than the application is capable of achieving .",
    "also , it often happens that some of the connections stall due to multiple losses , while others proceed unaffected .",
    "thus concurrent tcp connections , when left without any explicit arbitration , provide neither bandwidth utilization nor fairness .",
    "some of the information in a tcb , like round - trip time ( rtt ) , is not application specific but is specific to a host ( or subnet ) .",
    "if there are multiple tcp connections between the same hosts , each will independently monitor its transmissions to estimate the rtt between the hosts .",
    "such a scheme is wasteful as it needs extra processing and memory at a tcp endpoint .",
    "an alternate scheme is to share this information between such concurrent connections .    in order to see",
    "if iscsi suffers from any of the above problems , we evaluated the performance of iscsi with multiple tcp connections .",
    "we observed traces of congestion window of each connection , for a sequential file write of 1gbyte to see if the connections are competing with each other .",
    "figure [ fig : problem1 ] shows a sample of traces of congestion window for 2 different connections in a wan environment with delay of 4ms for a period of 1.2 seconds .",
    "the congestion window was collected approximately every 10ms .",
    "figure [ fig : diff1 ] shows a sample of the difference in congestion window of the 2 connections for a period of 50 seconds .    from the traces",
    ", we can see the two connections compete for bandwidth resulting in one connection using the network more than the other .",
    "the observed mean and standard deviation for congestion window of the two connections are 3.38/2.14 and 3.38/2.13 .",
    "the observed mean and standard deviation for the difference in window sizes shown in figure [ fig : diff1 ] is 0 and 3.06 .",
    "the mean 0 in the window difference indicates that over long periods each connection gets the same amount of network bandwidth .",
    "the larger deviation in window difference compared to the deviations in each connection s window , indicates that when one connection has a large window the other connection has a smaller window .",
    "this is a very undesirable behaviour from the tcp connections which results in reduced throughput .",
    "similar patterns were observed in all traces . for the above",
    "traces the mean turnaround time was 453 ms with a standard deviation of 325ms which we try to reduce .",
    "thus we understand that the multiple connections between iscsi do compete and share the bandwidth disproportionately and underutilized the resources . in our work",
    ", we share the congestion information among the different tcp connections to reduce the command turnaround times and increase the throughput of iscsi .",
    "conn_srtt & = & ecb_srtt + conn_rttvar & = & ecb_rttvar + conn_snd_cwnd & = & ecb_snd_cwnd / ref_cnt + conn_snd_ssthresh & = & ecb_snd_ssthresh / ref_cnt +      several researchers have worked on sharing the congestion information among multiple tcp connections ( @xcite , @xcite , @xcite ) .",
    "touch @xcite proposed sharing tcp state among similar connections to improve the behaviour of a connection bundle .",
    "a bundle of tcp connections sharing tcb information is called an _",
    "ensemble_. we have implemented a congestion information sharing mechanism , fair - tcp based on touch@xcite .",
    "the tcbs of individual connections are stripped of rtt and congestion control variables .",
    "instead , they now simply contain a reference to the ensemble control block ( ecb ) , of the ensemble they are part of .",
    "fair - tcp does not support caching of tcb states , since connections in an iscsi session are persistent for a very long time , and are not reestablished frequently .",
    "figure [ fig : fair ] outlines the design of fair - tcp .",
    "fair - tcp aggregates congestion window and slow start threshold values in the ecb per ensemble .",
    "ensemble allocates fair share of available window to each connection .",
    "fair - tcp shares the round trip time information among connections of the ensemble .",
    "fair - tcp maintains a reference count of the number of connections in the ensemble .",
    "table [ table : ensembleallocation ] outlines the allocation of congestion information to connections of the ensemble .    for each window update received from a connection",
    ", the aggregate window is adjusted appropriately .",
    "the most recent value of _ srtt _ ( smoothed round trip time ) and _ rttvar _ ( round trip time variance ) reported by a connection is maintained in the ensemble .",
    "whenever a new connection is established , it is added to the corresponding ensemble without any changes to the ensemble .",
    "if there is no ensemble corresponding to that connection , a new ensemble will be created and initialized with the values from that connection .",
    "fair - tcp has been implemented on both the target and the initiator .",
    "the _ unh - iscsi _",
    "@xcite protocol implementation of initiator and target is used for all our experiments .",
    "it is designed and maintained by unh interoperability lab s iscsi consortium .",
    "the implementation consists of initiator and target drivers for linux 2.4.x and 2.6.x kernels .",
    "it supports multiple sessions between a given initiator target pair , multiple connections per session , arbitrary number of outstanding r2ts , all combinations of initialr2 t and immediatedata keys , arbitrary values of data transfer size related iscsi parameters and error recovery level 1 .    the _ nist net _",
    "@xcite network emulation tool for gnu / linux is used for introducing delays .",
    "nist net allows a gnu / linux pc set up as a router to emulate a wide variety of network conditions .",
    "the tool is designed to allow controlled , reproducible experiments for network performance sensitive / adaptive applications and control protocols in a simple laboratory setting . by operating at the ip level , nist net can emulate the critical end - to - end performance characteristics imposed by various wide area network situations ( e.g. , congestion loss ) or by various underlying subnetwork technologies .",
    "the tool allows an inexpensive pc - based router to emulate numerous complex performance scenarios , including : tunable packet delay distributions , congestion and background loss , bandwidth limitation , and packet reordering / duplication .    _",
    "@xcite is a benchmark suite that is aimed at performing a number of simple tests of hard drive and file system performance",
    ". the benchmark tests database type access to a single file ( or a set of files ) , and it tests creation , reading , and deleting of small files which can simulate the usage of programs such as squid , inn , or maildir format email .",
    "the first six tests include per - char write , block write , block rewrite , per - char read , block read and random seeks . for each test , bonnie reports the number of kilo - bytes processed per elapsed second , and the % cpu usage ( sum of user and system ) .",
    "the next 6 tests involve file create / stat / unlink to simulate some operations that are common bottlenecks on large squid and inn servers , and machines with tens of thousands of mail files in /var / spool / mail .    the _ postmark _ @xcite benchmark models",
    "the workload seen by a busy web server and is sensitive to i / o latency .",
    "the workload is meant to simulate a combination of electronic mail , netnews and web - based commerce transactions .",
    "postmark creates a large number of small files that are constantly updated .",
    "once the pool of files has been created , a specified number of transactions occur .",
    "each transaction consists of a pair of smaller transactions , i.e. create file or delete file and read file or append file .",
    "each transaction type and files it affects are chosen randomly .",
    "on completion of each run a report is generated showing metrics such as elapsed time , transaction rate , total number of files created , read size , read throughput , write size , write throughput and so on . the postmark configuration used in our experiments",
    "is listed in table [ table : postmark ] and rest of the parameters have been set to default .",
    "our experimental wan emulation testbed is illustrated in figure [ fig : testbed ] .",
    "three machines were used in our experimental setup : initiator , router and target .",
    "all the three machines were connected to a d - link dgs10008tl gigabit switch using gigabit nics .",
    "the initiator hosted a 2.6 ghz intel pentium 4 processor , 256 mbytes of ram and broadcom bcm5700 gigabit ethernet controller .",
    "it was running the linux 2.4.20 kernel .",
    "the system in which the target was hosted had a dual 866 mhz pentium iii processor , 756 mbytes ram and fibre channel host bus adapter .",
    "the target was connected to two jbods , each housing three seagate st336752fc 15k rpm disks .",
    "the target was running a linux 2.6.5 kernel for i686 .",
    "the machine designated as router hosted a hyper - threaded 2.6 ghz pentium 4 processor , 1 gb of ram and two gigabit nics ( d - link dl2k and intel 82547ei ) .    both the initiator and the target were running unh iscsi implementation . the machine designated as router between the initiator was running nist net network emulation tool to simulate a wan environment .",
    "the wan simulation was tuned in accordance with profiling information presented in vern paxson @xcite , which found that over long periods network connections suffered a 2.7% packet loss in a wide - area network .",
    "performance measurements were calculated using varying delays .",
    "socket buffer sizes on both the initiator and the target were set to 512kbytes .",
    "in all our experiments 4 tcp connections were used in a session between the initiator and the target .",
    "girish@xcite identifies that beyond 4 connections the incremental increase in throughput is very low .",
    "standard ethernet frame size of 1500 bytes was used in all experiments .",
    "we did not consider using jumbo frames , since in real systems not all components in the network path support jumbo frames .",
    "large socket buffers are necessary to achieve peak performance for networks with large bandwidth - delay products .",
    "socket buffers on both the initiator and the target were set to maximum value of 512kbytes .",
    "figure [ fig : write ] shows the performance of iscsi for a sequential file write of 1 gb with different block sizes for write system call and varying network delays .",
    "a request for _ fsync _ was made before closing the file to ensure that all the data were written to the disk .",
    "figure [ fig : write ] shows the performance of iscsi with standard reno tcp with sack ( referred to as standard tcp or tcp ) and fair - tcp implemented on top of it . as shown in the figure fair - tcp performs better than normal tcp - reno at all delays .",
    "but as the delays increase the gap narrows , this we believe is due to delays overwhelming the window management efficiency of fair - tcp",
    ".    .aggregate congestion window [ cols=\"^,^,^,^,^,^,^ \" , ]      postmark@xcite was run with 20000 initial files and 50000 transactions .",
    "figure [ fig : postmarktimes ] shows the times taken to run the postmark for standard tcp and fair - tcp . around 4 gb of data was transacted during the execution of postmark .",
    "we notice that standard tcp needs 10 - 18% more time than fair - tcp to run postmark . considering",
    "that postmark is single threaded and reads are synchronous , the performance improvement observed is mainly due to asynchronous file writes and metadata writes from the buffer cache .",
    "figure [ fig : postmarkthr ] shows the read and write throughput for standard tcp and fair - tcp .",
    "the read and write throughput improves by about 10 - 18% for fair - tcp . due to filesystem caching effects and asynchronous nature of writes , throughput for writes in all cases is better than read throughput , and decreases with increasing delays .",
    "postmark is completely single - threaded . in a normal web server",
    ", there would generally be more than one thread running at a time . to simulate the workload",
    "better we ran 10 concurrent processes of postmark , each with initial files of 2000 and 5000 transactions with the rest of the parameters as in table [ table : postmark ] .",
    "the results for the time take to complete all the postmark processes are shown in figure [ fig : parallelpostmarktimes ] .",
    "the times for multiprocess postmark are almost half that of a single process postmark for the same parameters .",
    "we observer that standard tcp needs 17 - 50% more time than fair - tcp to complete postmark execution .",
    "the performance improvement observed going from a single postmark process to multiple processes is due to several requests getting queued at the scsi level .",
    "fair - tcp has more data available at the tcp level in a multiprocess environment than in a single process and this improves the performance .",
    "figure [ fig : parallelpostmarkthr ] shows the read and write throughput in a multiprocess postmark environment for standard tcp and fair - tcp .",
    "the throughput shown are the aggregate throughput for all the 10 processes .",
    "we see that fair - tcp increases the aggregate read and write throughput by 17 - 50% over standard tcp .",
    "the kernel compile experiment involves untar , config and make of 2.4.20 linux kernel . the time taken in seconds to complete the kernel compile for various delays",
    "is shown in figure [ fig : kerneltimes ] .",
    "kernel compile is cpu intensive and generates large amounts of meta - data .",
    "fair - tcp improves the performance of kernel compile by 8 - 17% .",
    "due to increasing importance to storage scaling and reducing costs , there has been number of efforts to build efficient implementations of iscsi and evaluate various aspects of iscsi .",
    "the work in aiken@xcite evaluates the performance of iscsi in 3 different configurations , a commercial deployment of iscsi with fibre channel and iscsi storage , a san environment with software - based targets and initiators using existing hardware and in a wan emulated environment with varying delays .",
    "the authors in @xcite evaluate the performance of iscsi when used in storage outsourcing .",
    "they examine the impact of latency on application performance and how caching can be used to hide network latencies .",
    "the authors in @xcite use simulations to examine the impact of various iscsi parameters such as iscsi pdu size , maximum segment size , link delay and tcp window size .",
    "the work in @xcite examines the effect of block level request size and iscsi window size in lan , man and wan environments .",
    "the work in @xcite examines the use of various advanced tcp stacks such as fast tcp , binary increase congestion tcp ( bic - tcp ) , h - tcp , scalable tcp and high - speed tcp using simulations and a emulated wan .",
    "the authors in @xcite study the performance of iscsi in the context of synchronous remote mirroring and find that iscsi is a viable approach to cost - effective remote mirroring .",
    "the work in @xcite compares the performance of nfs and iscsi micro and macro benchmarks .",
    "the work in @xcite examines the impact of certain kernel scsi subsystem values and suggest modifications to these value for performance improvement of iscsi .",
    "@xcite proposes a caching algorithm and localization of certain unnecessary protocol overheads and observe significant performance improvements over current iscsi system .",
    "in our work , we investigated the performance of iscsi with multiple tcp connections and found that iscsi throughput suffers from competing tcp connections .",
    "we proposed a tcb information sharing method called fair - tcp based on the design of @xcite .",
    "we implemented fair - tcp for the linux kernel and compared the performance of iscsi with fair - tcp and standard tcp under different workloads .",
    "we find that fair - tcp improves the performance of iscsi significantly in i / o intensive workloads . for workloads such as single threaded read ,",
    "the scsi data generated is quite low , hence fair - tcp does do not as good as in i / o intensive workloads .",
    "s.aiken , d.grunwald , a.pleszkun and j. willeke . a performance analysis of the iscsi protocol , _ proceedings of the 20th ieee/11th nasa goddard conference on mass storage systems and technologies , 2003(msst03)_.    peter radkov , li yin , pawan goyal , prasenjit sarkar and prashanth shenoy . a performance comparison of nfs and iscsi for ip - networked storage .",
    "_ proceedings of the 3rd usenix conference on file and storage technologies , april 2004_.    dimitris xindis , michail d.flouris and angelos bilas .",
    "performance evaluation of commodity iscsi - based storage systems .",
    "_ proceedings of the 22nd ieee / 13th nasa goddard conference on mass storage systems and technologies ( msst05)_.    wee teck ng and bruce k. hillyer . obtaining high performance for storage outsourcing .",
    "_ proceedings of the 2001 acm sigmetrics international conference on measurement and modeling of computer systems , 2001_.    girish motwani , k. gopinath .",
    "evaluation of advanced tcp stacks in the iscsi environment using simulation model .",
    "_ proceedings of the 22nd ieee / 13th nasa goddard conference on mass storage systems and technologies ( msst05)_.      i. dalgic , k. ozdemir , r. velpuri , j. weber , u. kukreja and h.chen .",
    "comparative performance evaluation of iscsi protocol over metro , local and wide area networks .",
    "_ proceedings of the 21nd ieee / 12th nasa goddard conference on mass storage systems and technologies ( msst04)_.          ming zhang , yinan liu , qing ( ken ) yang .",
    "cost - effective remote mirroring using the iscsi protocol .",
    "_ proceedings of the 21nd ieee / 12th nasa goddard conference on mass storage systems and technologies ( msst04)_.                        ali r.butt , chris gniady , and y.charlie hu . the performance of kernel prefetching on buffer cache replacement algorithms .",
    "proceedings of the acm international conference on measurement & modeling of computer systems ( sigmetrics 05 ) , banff , canada , june 6 - 10 , 2005 ."
  ],
  "abstract_text": [
    "<S> scaling data storage is a significant concern in enterprise systems and storage area networks ( sans ) are deployed as a means to scale enterprise storage . </S>",
    "<S> sans based on fibre channel have been used extensively in the last decade while iscsi is fast becoming a serious contender due to its reduced costs and unified infrastructure . </S>",
    "<S> this work examines the performance of iscsi with multiple tcp connections . </S>",
    "<S> multiple tcp connections are often used to realize higher bandwidth but there may be no fairness in how bandwidth is distributed . </S>",
    "<S> we propose a mechanism to share congestion information across multiple flows in `` fair - tcp '' for improved performance . </S>",
    "<S> our results show that fair - tcp significantly improves the performance for i / o intensive workloads . </S>"
  ]
}