{
  "article_text": [
    "efficient and economical representations of anisotropic structures are essential in various areas in applied mathematics .",
    "the nature of the problems we face can be divided into two types , namely when the anisotropic structure is given explicitly and when it is given implicitly .",
    "the analysis of images and higher dimensional data with respect to directional features shall serve as an example of an explicitly given anisotropic structure , whereas the solution of hyperbolic partial differential equations often exhibits the phenomenon of shocks which can be interpreted as an implicit anisotropic structure .",
    "it is well known that wavelets are perfectly suited for providing efficient representations in the sense of sparsity for problems with a dominant isotropic regularity , at the same time being associated with a multiresolution analysis which is the key ingredient for a fast decomposition algorithm . however , when dealing with anisotropic phenomena wavelets do not perform equally well . in fact , it can be proven that wavelets do not provide optimally sparse representations .",
    "in contrast to earlier approaches such as directional wavelets @xcite , complex wavelets @xcite , ridgelets @xcite , and contourlets @xcite , the curvelets introduced by cands and donoho precisely satisfy this need , in the sense of resolving the wavefront set @xcite and the curvelet representation being optimally sparse for objects with @xmath0-singularities @xcite .",
    "also there already exist some first results on applying curvelets to hyperbolic partial differential equations by cands and demanet @xcite . however , one drawback is the lack of a multiresolution analysis associated with curvelets , and , in particular , a fast decomposition algorithm in the time domain .",
    "this raises the question about the existence of a representation system with analyzing properties as good as curvelets , but being equipped with a more `` wavelet - like '' structure in the sense of being associated with a multiresolution analysis .",
    "in fact , the discrete counterpart would then lead to finitely supported filters that allow for a mathematically justified discrete fast decomposition of discrete data .",
    "we anticipate such a representation to combine the favorable computational properties of wavelets with the main additional property to provide a means to resolve anisotropic structures efficiently .    in this paper",
    "we give a complete , positive answer to the question of the existence of such a system by introducing subdivision schemes for the recently introduced concept of shearlets , thus constructing an associated multiresolution analysis which indeed leads to a fast discrete decomposition algorithm .",
    "the directional representation system of _ shearlets _",
    "@xcite stands out for the following reason .",
    "they do not only precisely resolve the wavefront set @xcite and provide optimally sparse representations @xcite , but shearlet systems are generated by one single function which is dilated by a parabolic scaling and a shear matrix and translated in the time domain , hence form an affine system .",
    "we might even interpret the system of shearlets as being generated by a strongly continuous , irreducible , square - integrable representation of a certain group , the shearlet group @xcite .",
    "this rich mathematical structure enables , for instance , the application of coorbit theory to study smoothness spaces  so - called shearlet coorbit spaces  associated with the decay of the shearlet coefficients @xcite .",
    "we would further like to mention that one attempt to associate shearlets with a so - called generalized multiresolution analysis can be found in @xcite .",
    "however , this structure did not yield a fast decomposition due to the fact that the filters are not compactly supported and even infinitely many filters have to be employed .",
    "our approach to derive a multiresolution analysis associated with shearlets and to provide a feasible fast shearlet decomposition comprises the introduction of a new class of non - stationary bivariate subdivision schemes which incorporate directionality in a particular way .",
    "subdivision schemes provide a mathematical method to refine given coarse data while providing characterization results to ensure convergence to a continuous function , say .",
    "moreover , such schemes automatically provide _ refinable functions _ which are the basis for any multiresolution analysis as nestedness of the different levels of resolution is equivalent to the refinability of the underlying `` basis '' function .",
    "homogeneous stationary subdivision schemes have been studied extensively over the last 20 years ; for an elaborate survey we refer the reader to @xcite . recently",
    ", algebraic methods have been introduced as a means to derive characterizations of convergence and approximation order in a very natural way for multivariate subdivision ( cf .",
    "@xcite ) . on the other hand , also",
    "the conditions of homogeneity and stationarity have been released by various authors , leading to subdivision schemes where the refinement rule varies with the level of iteration or the location of refinement .",
    "however , the gain in generality always comes with the prize of a loss of structure so that there is comparatively little known about these generalizations ( see , e.g. , @xcite ) . in particular , no subdivision schemes were known so far which provide a means to adapt the subdivision process depending on directionality constraints during its performance while still ensuring convergence .",
    "the development of such subdivision schemes will be important both for construction of a shearlet multiresolution analysis as well as for opening the research area of methods for data refinement to incorporate anisotropic structures .",
    "we will show in this paper that such an adaptive directional subdivision scheme can be constructed and it will indeed lead to a shearlet multiresolution analysis and a fast shearlet decomposition .",
    "our approach to derive a non - stationary bivariate adaptive directional subdivision scheme is based on the idea to iteratively apply two subdivision schemes each of which is associated with a different direction .",
    "the two individual subdivision schemes can employ two different finitely supported filters while their respective dilation matrices are taken from the theory of shearlet systems .",
    "we would also like to mention at this point that the most natural `` directional '' operation , the rotation , can not be employed , since its action does not provide a refinement of a lattice . in contract to this observation , products of parabolic scaling and shear matrices do indeed satisfy this desirable property .",
    "the constructed subdivision scheme provides the opportunity to adaptively change the orientation of the data during the subdivision process , since in each iteration one of both single subdivision schemes can be applied . in this sense",
    ", we can visualize the subdivision process as a binary tree , in which the direction of the finer data is dependent on the branch we choose .",
    "however , for convergence we certainly need to study each branch of the tree , which requires an appropriate definition of convergence .",
    "our first key result shows that , provided the adaptive directional subdivision scheme converges , we obtain associated generalized refinement equations ( theorem [ t : refeq ] ) .",
    "these will become essential for deriving a shearlet multiresolution analysis . as a main result we then provide a complete characterization of those masks which lead to convergent adaptive directional subdivision schemes ( theorem [ t : convergence ] ) in terms of algebraic and spectral properties of the associated filters . in the proof we will make use of ideal theoretic methods which come in handy to extract `` the zero at @xmath1 '' of the two masks .    for the construction of a shearlet multiresolution analysis",
    "we employ the fact that each wavelet multiresolution analysis is associated with a convergent subdivision scheme @xcite .",
    "we introduce scaling spaces based on the previously constructed directional subdivision schemes , and then prove that these indeed provide a multiresolution analysis structure ( theorem [ t : shearletmra ] ) due to the refinement equations mentioned above .",
    "this multiresolution analysis will then provide us in a very natural way with a mathematically justified discrete fast shearlet decomposition of discrete data which is stated as algorithm [ algo : fsd ] . also here",
    "we encounter a binary tree structure , since the decomposition will be dependent on the different directions which were encoded in a binary tree structure of the subdivision process . for the construction of a shearlet multiresolution analysis and a fast shearlet decomposition , we focus on the situation of interpolatory masks .",
    "the non - interpolatory case is beyond the scope of this paper and will be studied in a forthcoming paper .",
    "the outline of the paper is the following .",
    "in section [ sec : refinement ] we briefly introduce discrete shearlet systems .",
    "we further study which directions can be attained by the action of the associated dilation matrices on @xmath2 .",
    "the new type of subdivision schemes , which we baptize _ adaptive directional subdivision schemes _ , are introduced in section [ sec : adaptive ] . in section [ sec : convergence ] we provide a complete characterization of convergence for those schemes along with the necessary ideal theoretic background .",
    "some numerical experiments on the refinement of data employing this new type of subdivision schemes are provided in section [ sec : numerics ] .",
    "we then show how the previously derived adaptive directional subdivision schemes can be used as a framework for deriving a _ shearlet multiresolution analysis _",
    "with finitely supported filters ( section [ sec : shearletmra ] ) . in section [ sec : fsd ]",
    "we employ these results to provide a _",
    "fast shearlet decomposition_.",
    "our approach towards directional refinement of the lattice @xmath3 and , later on , adaptive directional subdivision schemes is inspired by the recently introduced discrete shearlet transform @xcite , since this transform is able to precisely detect directions of singularities ( cf .",
    "@xcite ) which we will take advantage of . in order to provide a thorough motivation for our construction ,",
    "allow us to first briefly review the idea of shearlets .",
    "each shearlet system forms an affine system , i.e. , consists of dilations and translations of one single generating function @xmath4 , a so - called _ shearlet_. as dilation matrices , products of anisotropic parabolic scaling matrices and shear matrices  which coined the name `` shearlets ''  are employed . in order to define a shearlet system ,",
    "let @xmath5 , @xmath6 , and @xmath7 , @xmath8 , which are defined by @xmath9 denote a _",
    "parabolic scaling matrix _ and a _ shear matrix _ , respectively .",
    "then the _ shearlet system _ associated with a shearlet @xmath10 is given by @xmath11 the three parameters @xmath12 are interpreted in the following way : @xmath13 provides the scale , and @xmath14 and @xmath15 detect the direction and position of singularities , respectively .",
    "it is easy to construct shearlets such that forms a parseval frame for @xmath16 , for instance , by choosing @xmath17 , where @xmath18 is a discrete wavelet , i.e. , @xmath19 for @xmath20 , satisfying @xmath21 and @xmath22 \\cup [ \\frac14,1]$ ] , and @xmath23 is a bump function satisfying @xmath24 , @xmath25 $ ] , and @xmath26 for @xmath20 ( cf .",
    "the associated _ shearlet transform _",
    "@xmath27 is then defined on @xmath28 by @xmath29    in order to provide an equal treatment of the direction of the @xmath30- and @xmath31-axis , the frequency plane is split into the cone @xmath32 its by @xmath33 rotated copy , and the square centered at the origin of side length @xmath34 .",
    "the shearlet transform acts on @xmath35 and its copy as described above , while the choice of @xmath36 has to be adapted appropriately .",
    "the center square can be filled in such a way that this system also forms a parseval frame .",
    "the shearlet system in @xmath35 and its copy is usually referred to as _",
    "shearlets on the cone _ , see @xcite .",
    "the associated tiling of the frequency plane is illustrated in figure [ fig : shearletsoncone ] .",
    "the refinement matrices interesting to us for deriving a directional refinement of the lattice @xmath2 are the dilation matrices used in for @xmath37 , i.e. , the matrices @xmath38 following the philosophy of the shearlets on the cone , also the matrices @xmath39 which serve as dilation matrices for the rotated copy of @xmath35 , will be employed as refinement matrices .",
    "the matrices @xmath40 and @xmath41 not only provide the possibility to map a line to various directions , but moreover possess the property of refining the lattice @xmath3 equally at each level as it is shown in the following result .",
    "[ prop : matrixrefinement ] the following conditions hold .    1 .   for all @xmath42",
    ", we have @xmath43 2 .   for all @xmath42 ,",
    "we have @xmath44    \\(i ) the first claim is obvious . to prove the second claim ,",
    "let @xmath45 and @xmath46 .",
    "then @xmath47 which implies @xmath48 .",
    "now let @xmath49 .",
    "then choosing @xmath50 as @xmath51 and @xmath52 yields @xmath53 thus @xmath54 , which proves the claim .",
    "\\(ii ) this follows by using similar arguments as in part ( i ) .",
    "thus , when applying a sequence of matrices @xmath55 iteratively to the lattice @xmath3 , at the @xmath13th level the points @xmath56 are added to the lattice @xmath57 .",
    "this is true for an arbitrary choice of integers @xmath58 , @xmath59 .",
    "moreover , at each level this map is bijective .",
    "a similar result holds for the matrices @xmath60 , @xmath61 .",
    "let us now delve deeper into the explicit construction of the refinement by using the splitting idea of the shearlets on the cone .",
    "the overall aim is to provide a way of refinement such that the points on the @xmath31-axis  or any other line through the origin  can be moved to an arbitrary line through the origin during the refinement process .",
    "this immediately forces the refinement scheme to provide different strategies for refinement .",
    "we will see how this is can be achieved by using the matrices @xmath62 and @xmath63 even only for @xmath64 . in the sequel",
    "we will only focus on the matrices @xmath62 , @xmath65 , since the others can be treated simultaneously .    in the very first step of the refinement , we apply @xmath62 to @xmath3 for @xmath65 .",
    "application of @xmath66 does not change any directions , @xmath67 maps the @xmath31-axis to the angle bisector in the first and third quadrant of the plane , and @xmath68 has the same effect on the second and fourth quadrant . from now on ,",
    "we consider the two cases @xmath69 or @xmath70 separately . focusing on the second case ,",
    "in each step we not only derive the refinement from a coarser scale @xmath71 to a finer scale @xmath72 , but also have two different ways to achieve this , either by applying @xmath73 or by applying @xmath74 .",
    "hence , at the @xmath75th level we have applied a product of the form @xmath76 to @xmath2 , where @xmath77 for each @xmath78 . for @xmath79 , one can proceed in exactly the same way which we will , however , not work out in detail in this paper .    from now on , we will use the abbreviation @xmath80 , @xmath81 , for the index sets and will also denote by @xmath82 the set of all finite @xmath83-@xmath84sequences and by @xmath85 the space of all infinite sequences .",
    "note that @xmath86 is canonically embedded in @xmath87 by the mapping @xmath88    the main question to ask at this point concerns the possible directions this procedure allows us to map the points on the @xmath31-axis to .",
    "for this analysis , we restrict our attention to the first quadrant of the plane , since the same refinements occur in the third quadrant only in an origin - symmetric way .",
    "we first notice that the sequence of @xmath75 matrices @xmath89 we choose is completely determined by the associated sequence @xmath90 .",
    "hence this refinement scheme has the structure of a binary tree as illustrated in figure [ fig : binary ] .",
    "( 250,190)(0,0 ) ( 0,90)@xmath2 ( 15,100)(1,1)45 ( 15,90)(1,-1)45 ( 65,140)@xmath91 ( 65,40)@xmath92 ( 95,150)(2,1)45 ( 95,140)(2,-1)45 ( 95,50)(2,1)45 ( 95,40)(2,-1)45 ( 145,170)@xmath93 ( 145,113)@xmath94 ( 145,70)@xmath95 ( 145,13)@xmath96    the directions which might be obtained employing this refinement scheme are encoded in this binary tree in a special though natural way . to explore this relation ,",
    "we first compute the product of the matrices which is applied to achieve the refinement at level @xmath75 .",
    "interestingly , the following binary number appears therein .    for @xmath90 , @xmath97",
    ", we define @xmath98    using this notion we obtain the following form for a refinement matrix @xmath89 .",
    "[ lemma : productsofm ] let @xmath99 and @xmath90 .",
    "then we have @xmath100    we will prove this lemma by induction . for @xmath101 ,",
    "the claim obviously holds .",
    "now suppose that the claim is true for some @xmath102 .",
    "let @xmath103 , @xmath104 .",
    "we have to distinguish between @xmath105 , hence @xmath106 , with @xmath107 and @xmath108 , i.e. , @xmath109 , where @xmath110 which advances the induction hypothesis .",
    "let @xmath111 be a line through the origin and @xmath90 , @xmath99 .",
    "then @xmath112 denotes the slope of @xmath113 , which is again a line through the origin .",
    "we further write @xmath114 for the slope of @xmath111 .",
    "the next result computes the values of the slopes @xmath112 .",
    "let @xmath111 be a line through the origin and @xmath90 , @xmath99 .",
    "then the following relations between @xmath112 , @xmath115 and the original @xmath111 hold .    1 .",
    "if @xmath111 is a line through the origin with @xmath116 , then @xmath117 2 .   if @xmath118 , i.e. , @xmath119 , then @xmath120 where we set @xmath121",
    "3 .   if @xmath122 , i.e. , @xmath123 , then @xmath124    \\(i ) we consider the point @xmath125 . using lemma [ lemma : productsofm ] , we compute @xmath126 hence , the slope of the line @xmath113 equals @xmath127    \\(ii ) here we consider the point @xmath128 . again employing lemma [ lemma : productsofm ]",
    ", we obtain @xmath129 thus @xmath130    \\(iii ) is easily verified by noting that the point @xmath131 is mapped to @xmath132 so that the slope remains zero .",
    "our main result in this section will show that indeed the points on an arbitrary line through the origin of slope @xmath133 can be moved arbitrarily close to prescribed lines through the origin during the refinement process .",
    "[ theo : possibledirections ] let @xmath111 be a line through the origin with @xmath134 $ ] .",
    "then , for each @xmath135 $ ] and @xmath136 , there exists some @xmath97 and @xmath90 such that @xmath137    suppose @xmath111 is a line through the origin with @xmath116 .",
    "the case @xmath119 can be dealt with in a similar way .",
    "for given @xmath138 and @xmath136 , due to the denseness of rational numbers there exists some @xmath97 and @xmath90 such that @xmath139 indeed , @xmath115 can be chosen as a truncation of the binary expansion of @xmath140 .",
    "note that without loss of generality we can assume that @xmath141 since we can always enlarge @xmath75 .",
    "using these relations , we obtain @xmath142 & = & \\left|\\frac{1}{\\frac{1}{2^n s(l)}+\\sum_{j=0}^{n-1 } \\eps_{j+1 } \\ , 2^{j - n+1 } } - t\\right| = \\left|\\frac{1-t(\\frac{1}{2^n s(l)}+\\sum_{j=0}^{n-1 } \\eps_{j+1 } \\ , 2^{j - n+1})}{\\frac{1}{2^n s(l ) } + \\sum_{j=0}^{n-1 } \\eps_{j+1 } \\ , 2^{j - n+1}}\\right| \\\\[1ex ] & \\le & t \\left|\\frac{\\frac{1}{t}-\\sum_{j=0}^{n-1 } \\eps_{j+1 } \\ , 2^{j - n+1 } -\\frac{1}{2^n s(l)}}{\\frac{1}{t}-\\t{\\delta}}\\right| \\le \\left|\\frac{t^2\\t{\\delta}}{1-t\\t{\\delta}}\\right| = \\delta.\\end{aligned}\\ ] ] note that for the last equality we used @xmath143 .",
    "now let @xmath144 be defined by @xmath145 for all @xmath146 for some @xmath147 , and let @xmath148 .",
    "then there exists some @xmath97 such that @xmath149 which implies @xmath150 hence @xmath151 .    finally , let @xmath144 be defined by @xmath152 for all @xmath153 for some @xmath147 . then , for all @xmath97 , @xmath154 and hence , @xmath155    thus only employing @xmath73 and @xmath74 we can move any line arbitrarily close to any line of slope @xmath156 $ ] .",
    "this shows the range of directions we might attain ( compare figure [ fig : splittingofplane ] ) .",
    "however , we would like to mention that the change of orientation of the data induced by the subdivision scheme ( see definition [ def : adaptivesubdivision ] ) is also affected by directionality of the masks .",
    "[ theo : possibledirections2 ] let @xmath111 be a line through the origin with @xmath157 $ ] .",
    "then , for each @xmath158 $ ] and @xmath136 , there exists some @xmath97 and @xmath90 such that @xmath137    similar results as theorems [ theo : possibledirections ] and [ theo : possibledirections2 ] also hold for the matrices @xmath159 , @xmath160 .",
    "we omit to also state these results for the sake of brevity , since they are similar to the previous theorems .",
    "the results in the preceding section point out how to refine @xmath3 in a directional way such that all possible directions can be attained .",
    "dependent on whether we intend to map say the @xmath31-axis to a line with a slope contained in @xmath161 $ ] , @xmath162 $ ] , or @xmath163 $ ] , we choose to refine by using the matrices @xmath164 , @xmath165 , or @xmath166 , respectively . once the type of matrices is chosen , we iterate depending on the angle we would like to attain by using theorem [ theo : possibledirections ] , theorem [ theo : possibledirections2 ] , or the corresponding result for the matrices @xmath159 , @xmath160 . for an illustration of the different areas of lines through the origin which can be attained during the refinement process dependent on the chosen matrices we refer to figure [ fig : splittingofplane ] .",
    "( 300,180)(0,0 ) ( 70,0 ) and @xmath167 and @xmath168.,title=\"fig:\",width=226 ]   and @xmath167 and @xmath168.,title=\"fig:\",width=226 ] ( 230,150)(-1,-1)40 ( 235,155)@xmath169 ( 235,140)(cf .",
    "theorem [ theo : possibledirections ] ) ( 250,108)(-1,0)50 ( 255,104)@xmath170 ( 80,150)(1,-1)40 ( -20,155)@xmath171 ( -20,140)(cf .",
    "theorem [ theo : possibledirections2 ] ) ( 230,65)(-2,1)40 ( 235,55)@xmath172    from now on we will focus entirely on the matrices @xmath73 and @xmath74 .",
    "all following results can be derived in a similar way for @xmath165 and for @xmath166 .",
    "in this section , we finally arrive at the announced definition of a new type of subdivision schemes , based on the interaction of _ two _ `` normal '' stationary subdivision schemes , which we will study in the sequel . to that end",
    ", we choose two _ masks _ @xmath173 , @xmath70 , i.e. , _ finitely supported _",
    "sequences @xmath174 as well as the expanding scaling matrices @xmath175 , @xmath176 . these matrices can be given explicitly as @xmath177 and again we set @xmath178 , @xmath179 . also note that @xmath180 such a decomposition also exists for the iterated matrices @xmath181 , @xmath182 , @xmath99 .",
    "to formulate the next auxiliary result , we also define for @xmath179 the dyadic number @xmath183_2 = .\\eps_1 \\ldots \\eps_n : = \\sum_{j=1}^n \\eps_j \\ , 2^{-j } \\in [ 0,1].\\ ] ] with this notation at hand , we obtain the following counterpiece of lemma  [ lemma : productsofm ] .    [ lemma : productsofw ] for @xmath184 and @xmath90 , we have @xmath185_2 \\\\      0 & 2^{n }    \\end{pmatrix }    = u_\\eps \\ , w_0^n   = w_0^n v_\\eps,\\ ] ] where @xmath186_2 \\\\      0 & 1    \\end{pmatrix }    \\quad \\mbox{and } \\quad    v_\\eps =    \\begin{pmatrix }      1 & -2 \\left [ \\eps \\right]_2 \\\\ 0 & 1    \\end{pmatrix},\\ ] ] hence @xmath187 .",
    "the proof is again of inductive nature and relies on noting that @xmath188_2 \\\\      0 & 2^{n+1 }    \\end{pmatrix } =    \\begin{pmatrix }      4^{n+1 } & -4^{n+1 } \\ , 2 \\ , \\left [ \\left ( \\eps,0 \\right ) \\right]_2 \\\\      0 & 2^{n+2 }    \\end{pmatrix}\\ ] ] as well as @xmath189_2 \\\\      0 & 2^{n }",
    "\\end{pmatrix }    =    \\begin{pmatrix }      4^{n+1 } & -4^{n+1 } \\left ( 2 \\ , [ \\eps]_2 + 2^{-n } \\right ) \\\\      0 & 2^{n+1 }    \\end{pmatrix } \\\\    & = &    \\begin{pmatrix }      4^{n+1 } & -4^{n+1 } \\ , 2 \\ , \\left [ \\left ( \\eps,1 \\right ) \\right]_2 \\\\      0 & 2^{n+1 }    \\end{pmatrix}.    \\end{aligned}\\ ] ] hence , @xmath190_2 \\\\ 0 & 2^n    \\end{pmatrix }    = w_0^n \\ ,    \\begin{pmatrix }      1 & -2 [ \\eps]_2 \\\\ 0 & 1    \\end{pmatrix }    =    \\begin{pmatrix }      1 & -2^{n+1 } [ \\eps]_2 \\\\ 0 & 1    \\end{pmatrix } \\ , w_0.\\ ] ] since for @xmath191 @xmath192 also the final claim follows .",
    "note that @xmath193 , @xmath194 , and all @xmath195 are _ unimodular _ matrices , i.e. , they have an inverse in @xmath196 .",
    "a particular role will be played by the two matrices @xmath197 which satisfy @xmath198    the associated subdivision schemes are now defined as follows .",
    "the term _ adaptive _ refers to the tree - like structure , which provides various branches for subdivision , whereas the term _ directional _ refers to the directional structure which comes from the shearing process contained in the dilation matrices @xmath181 , @xmath199 .",
    "[ def : adaptivesubdivision ] let @xmath200 , @xmath70 be two masks , that is , two _ finitely supported sequences _ , and let @xmath181 , @xmath70 be defined as in .",
    "then the associated _ adaptive directional subdivision scheme of order @xmath75 _ is defined by @xmath201 where , for @xmath202 , @xmath203    note that both the mask as well as the scaling matrix of these subdivision schemes depend on the index @xmath115 .",
    "moreover , we wish to remark that these schemes can clearly be computed in a tree  like fashion by setting @xmath204    adaptive directional subdivision schemes can be considered subdivision schemes of their own , however , with a different scaling matrix .",
    "this is easily seen by means of the following example : for @xmath205 we have @xmath206    \\ , c ( \\gamma ) \\\\    & = : & \\sum_{\\gamma \\in \\z^2 } a_{\\left ( \\eps_1,\\eps_2 \\right ) }    \\left ( \\cdot - w_{\\left ( \\eps_1,\\eps_2 \\right ) } \\gamma \\right )    \\ , c ( \\gamma).\\end{aligned}\\ ] ] an inductive application of this argument immediately gives the next result .",
    "[ lemma : itermasks ] for @xmath90 , the subdivision scheme @xmath207 acts as @xmath208 where the coefficient sequences @xmath209 are recursively defined as @xmath210 .    to get a better understanding of the geometry of adaptive directional subdivision , we write @xmath211 as @xmath212 which is always possible since @xmath213 is unimodular .",
    "it then follows from repeated applications of ( [ eq : uvprops ] ) that @xmath214 this identity can be rewritten in terms of dilation operators as @xmath215 and enables us to implement the subdivision scheme @xmath216 in terms of @xmath217 and the shear operator @xmath218 .",
    "moreover , it explains the geometry of the scheme @xmath216 : first , a shearing by @xmath219 is applied to the data sequence , then the subdivision operator refines the data in the sheared direction with a higher resolution than the data in the non  sheared direction , so that the additional application of the shearing by @xmath213 does not fully compensate the initial one . in summary , this process leads to limit functions which are sheared versions of the limit function of @xmath220 and the amount of shearing is determined by when and how often @xmath216 is applied in the process .",
    "we remark that this geometry is very much in the spirit of the continuous shearlet transform , which can be regarded as applying a shearing operator , an anisotropic 2-d wavelet transform , and again a shearing operator @xcite .",
    "in this section , we shall study convergence of the previously introduced adaptive directional subdivision schemes . to that end",
    ", we introduce the _ projection operators _ @xmath221 , @xmath97 , which extract the initial segment of order @xmath75 from a sequence : @xmath222 .",
    "[ def : convergence ] the adaptive directional subdivision scheme is said to be _ convergent in @xmath223 _ , if , for any @xmath144 , there exists a nonzero uniformly continuous function @xmath224 such that @xmath225 note that this is equivalent to @xmath226    since any sequence @xmath227 can be trivially written as @xmath228 and since the subdivision operator is linear , we immediately obtain the following convolution style representation of the limit function .",
    "if the adaptive directional subdivision scheme converges for some @xmath144 then the limit function takes the form @xmath229      this definition of convergence has an immediate consequence : if the adaptive directional subdivision scheme is a convergent one , then , in particular , @xmath230 and @xmath211 must define convergent adaptive directional subdivision schemes , which follows by simply choosing @xmath231 and @xmath232 , respectively .",
    "consequently , they must both preserve constants .",
    "[ lemma : subdivisionconvergent ] if the adaptive directional subdivision scheme is convergent , then @xmath233    an alternative but equivalent definition of convergence of a adaptive directional subdivision scheme can be given in terms of function spaces instead of sequence spaces by means of test functions .",
    "a function @xmath234 is called a _ test function _",
    ", if it is compactly supported and its integer translates form a stable partition of unity , that is ,    1 .",
    "@xmath235 , 2 .",
    "there exist constants @xmath236 such that for any @xmath237 @xmath238    the most prominent examples for test functions are the tensor product b ",
    "splines so that there even exist _",
    "refinable _ test functions of arbitrary regularity . with the help of test functions",
    ", convergence can be described as follows .",
    "[ t : alterconvdesc ] the adaptive directional subdivision scheme converges if and only if for any @xmath144 there exists a nonzero uniformly continuous function @xmath239 such that @xmath240    1 .   for some test function @xmath241 .",
    "2 .   for any test function @xmath241 .    for classical subdivision , this result is due to dahmen and micchelli @xcite and we just show how it can be extended in a straightforward way to adaptive directional subdivision . to that end , let @xmath241 be any test function and recall that for any _ uniformly continuous _",
    "function @xmath242 and any expanding matrix @xmath243 the `` quasi - interpolant '' @xmath244 with the _ sampling operator _ @xmath245 , satisfies @xmath246 where @xmath247 denotes the modulus of continuity of @xmath242 . recall that @xmath248 for @xmath249 as long as @xmath242 is uniformly continuous .",
    "now , we have that @xmath250 on the other hand , @xmath251 which verifies the equivalence . since therefore convergence of the adaptive directional subdivision scheme is equivalent to holding for an arbitrary test function , this property holds for one particular test function if and only if it holds for any test function .",
    "[ t : refeq ] if the adaptive directional subdivision scheme converges , then the limit functions @xmath239 , @xmath144 , satisfy the _ refinement equation _",
    "we define the _ transition operator _ @xmath253 and note that , for @xmath237 , @xmath254 by iteration , we then find for @xmath182 that @xmath255 where @xmath256 since , for @xmath99 , @xmath257      \\left ( w_{\\eps_1 } \\cdot \\right)\\\\ & &     + \\left [ \\left",
    "( g * s_{p_{n-1 } \\widehat \\eps } \\delta \\right ) \\left (          w_{p_{n-1 } \\widehat \\eps } \\right ) * s_{\\eps_1 } \\delta \\right ]      \\left ( w_{\\eps_1 } \\cdot",
    "\\right )      \\\\      & = & \\left [ \\left ( f_{\\widehat \\eps } - \\left ( g * s_{p_{n-1 }              \\widehat \\eps } \\delta   \\right )          \\left ( w_{p_{n-1 } \\widehat \\eps }          \\right ) \\right ) * s_{\\eps_1 } \\delta \\right ]      \\left ( w_{\\eps_1 } \\cdot \\right ) + \\left ( g * s_{p_n \\eps } \\delta      \\right ) \\left ( w_{p_n \\eps } \\cdot \\right ) ,    \\end{aligned}\\ ] ] it follows that @xmath258 and the right hand side of this inequality converges to zero for @xmath259 while the left hand side is independent of @xmath75 .",
    "thus @xmath260 which is ( [ eq : refeq ] ) .      next , we give a more detailed description of the necessary condition ( [ eq : consumrule0 ] ) from lemma  [ lemma : subdivisionconvergent ] in algebraic terms . to that end , we recall the definition of the _ symbol _ of a mask @xmath261 , defined as @xmath262 as well as the _ subsymbols _ @xmath263 the symbol can be `` reconstructed '' from the subsymbols by the well  known formula @xmath264 from which the following result follows immediately , cf .",
    "@xcite .",
    "the mask @xmath173 satisfies ( [ eq : consumrule0 ] ) , the _ sum rule of order @xmath83 _ , if and only if @xmath265    for a more algebraic description , we need the notion of a _ quotient ideal_. recall that an ideal in @xmath266 , the ring of _ laurent polynomials _ in two variables , is a subset of @xmath266 that is closed under addition and multiplication by arbitrary laurent polynomials .",
    "the _ quotient ideal _ of two laurent ideals @xmath267 , is defined as @xmath268 and has the almost obvious property that @xmath269 . for any matrix @xmath270 , with column vectors",
    "@xmath271 we finally define the ideal @xmath272 and its special case @xmath273",
    ". then we have the following result from @xcite .",
    "[ t : quotid ] the mask @xmath173 satisfies ( [ eq : consumrule0 ] ) , the _ sum rule of order @xmath83 _ , if and only if @xmath274    to conveniently formulate an important consequence of this theorem , we introduce the vectors @xmath275 = \\left [    \\begin{array}{c }      z^{x_1 } - 1 \\\\ z^{x_2 } - 1    \\end{array } \\right ] , \\qquad x = \\left [ x_1,x_2 \\right ] \\in \\zz^{2 \\times 2}.\\ ] ] with this notation we have the following result .",
    "[ c : qidrep ] if the adaptive directional subdivision scheme converges , then there exist _ matrix valued masks _",
    "@xmath276 , @xmath70 such that @xmath277 \\ , a_{\\eps}^ * ( z ) = b_\\eps^ * ( z ) \\ , \\left [        z^{w_\\eps } - 1 \\right ] , \\qquad \\eps \\in \\{0,1\\}.\\ ] ]    any convergent subdivision must satisfy the sum rule of order @xmath83 for @xmath173 , @xmath70 , and so , by theorem  [ t : quotid ] , it follows for @xmath70 and @xmath278 that @xmath279 written in matrix form , this is what has been claimed .",
    "the matrix masks @xmath276 , @xmath70 , from ( [ eq : qidrep ] ) are called _ representation masks _ of @xmath173 , @xmath70 , respectively .    recall",
    "that the computation of the representation masks @xmath276 can be performed by _ reduction _ , a multivariate generalization of division with remainder , see @xcite for the term order and homogeneous versions of this process , respectively .",
    "therefore , the symbolic determination of @xmath276 can easily be done with the help of practically any computer algebra system that supports constructive polynomial ideal theory .",
    "note however , that the representation masks are _ not _ unique to the appearance of _ syzygies _ of @xmath280 $ ] , not even if an h  representation , cf .",
    "@xcite , is chosen where  in the case of @xmath281  we have the `` minimal degree '' requirements that @xmath282 see also @xcite .",
    "we continue by giving explicit bases of the quotient ideals for our specific choice of @xmath181 .",
    "this is easy for @xmath281 as all entries in this matrix are nonnegative , and indeed it is not difficult to see that @xmath283 in fact , the graded homogeneous leading terms of the above ideal basis are @xmath284 , @xmath285 and @xmath286 so that the quotient space is spanned exactly by the seven monomials @xmath287 and their number coincides with the number of joint zeros of @xmath288 .",
    "hence , by the same reasoning as in @xcite they even form a graded grbner basis , hence an h  basis of the ideal @xmath288 . recall that a subset @xmath289 of an ideal @xmath290 is called an _ h  basis _ , if any polynomial @xmath291 can be written in the form @xmath292 where @xmath293 denotes , as usual , the _ total degree _ of a polynomial .",
    "we will also use @xmath294 for the vector space of all polynomials of total degree at most @xmath75 .",
    "the situation for @xmath295 appears to be a little bit more intricate due to the appearance of a negative entry in @xmath296 .",
    "here it is helpful to recall that @xmath297 , @xmath298 , to define @xmath299 , hence also @xmath300 and to realize that @xmath301 since @xmath302 we thus obtain that @xmath303 to arrive at the somewhat surprising observation that in fact @xmath304 , we add @xmath305 to the third basis element , @xmath306 , yielding @xmath307 again , and subtract @xmath308 from the first basis element which leads to @xmath309 and therefore to the following result .",
    "[ t : quotidbasis ] the two quotient ideals @xmath310 , @xmath70 , coincide and have the h ",
    "basis representation @xmath311    the fact that @xmath312 may appear a little bit surprising at first view , since it implies that , for any finitely supported mask @xmath261 , we have @xmath313 hence the necessary `` sum rule '' condition with respect to @xmath281 is equivalent to the one with respect to @xmath296 .",
    "however , if we write @xmath314 with the unimodular matrix @xmath315 , then a simple change of the summation variable indeed gives for any @xmath316 @xmath317 and confirms ( [ eq : quotidbasis ] ) .",
    "moreover , note that theorem  [ t : quotidbasis ] gives a way to _",
    "parameterize _ the ideal of all admissible polynomial masks . indeed , for any @xmath97 we have that @xmath318 for a polynomial of this form , the decomposition with respect to @xmath281 , i.e. , the matrix polynomial @xmath319 , becomes @xmath320 since the two laurent ideals @xmath288 and @xmath321 coincide , the decomposition of @xmath322 into @xmath323 takes exactly the same form as @xmath324 in ( [ eq : b0compute ] ) .",
    "next , we rephrase the identity ( [ eq : qidrep ] ) by means of the _ backwards difference operator _ @xmath325 , defined for a sequence @xmath261 as @xmath326 \\ , a^ * ( z),\\ ] ] where @xmath327 and @xmath328 denote the unit multiindices in @xmath3 .",
    "since , in addition , any finitely supported matrix sequence @xmath329 satisfies @xmath330 where @xmath331 our quotient ideal representation ( [ eq : qidrep ] ) can equivalently be written in terms of the difference operator as @xmath332    we end this section by recalling that quotient ideal containment also characterizes the order of _ polynomial reproduction _ provided by the two masks and thus the subdivision scheme .",
    "recall that a mask @xmath261 provides polynomial reproduction of order @xmath75 , if the leading forms of all polynomial sequences are reproduced by the scheme : @xmath333 polynomial reproduction is essential for the smoothness of the refinable limit function @xcite as well as for the approximation order of the associated wavelet construction . with the methods from",
    "@xcite we can now easily describe polynomial reproduction .",
    "the directional subdivision scheme preserves polynomials of degree @xmath75 , i.e. , @xmath334 , @xmath199 , @xmath335 , if and only if @xmath336      finally , we will give a characterization of convergence of the adaptive directional subdivision scheme , like usually in terms of a ( restricted joint ) spectral radius . in this subsection , the adaptive directional subdivision scheme both for masks @xmath230 and @xmath211 as well as for their associated matrix sequences @xmath319 and @xmath337 will come into play . to distinguish both , for the first",
    ", we again employ the notation @xmath207 , @xmath199 , whereas the second adaptive directional subdivision scheme will be denoted by @xmath338 , @xmath199 .",
    "now , given two matrix masks @xmath276 , @xmath70 , their _ restricted joint spectral radius _ is defined as @xmath339 the joint spectral radius is called `` restricted '' since the supremum is not taken over all @xmath340vector valued sequences but only over the proper subset @xmath341 , see @xcite .",
    "the main result of this paragraph is now as follows .",
    "[ t : convergence ] the adaptive directional subdivision scheme based on the masks @xmath173 , @xmath342 converges if and only if @xmath343 and the representation masks @xmath276 , @xmath70 , satisfy @xmath344 .",
    "we will split the lengthy proof of theorem  [ t : convergence ] into several partial results , beginning with the sufficiency of the spectral radius condition . to that end",
    ", we will show that , starting with a particular test function @xmath241 , the sequence @xmath345 converges to a limit function for any choice of @xmath144 and any @xmath237 . indeed",
    ", we choose the test function @xmath241 to be @xmath281refinable with respect to a mask @xmath346 , that is @xmath347 such functions can be easily shown to exist , even with an arbitrary order of smoothness : pick any cardinal b ",
    "spline @xmath348 with refinement mask @xmath349 , then a double application of the refinement equation with respect to the first variable shows that the tensor product function @xmath350 ( x , y ) = \\left ( \\phi * \\phi \\right ) ( x ) \\ , \\phi(y ) = : \\psi(x ) \\ , \\phi(y)\\ ] ] is @xmath281refinable with respect to the mask @xmath351 , where @xmath352 denotes the subdivision scheme with mask @xmath349 and dilation 2 .",
    "the following lemma states a more general process .",
    "[ lemma : maskgeneration1 ] let @xmath353 be @xmath340-refinable masks , and let the mask @xmath354 be defined by @xmath355 .",
    "then the mask @xmath356 is @xmath281-refinable , and @xmath357 is @xmath296-refinable .",
    "let @xmath358 be univariate functions which are @xmath340-refinable with respect to @xmath359 , respectively ,",
    "i.e. , @xmath360 we claim that the function @xmath242 defined by @xmath361 is @xmath281-refinable with respect to @xmath230 . indeed , for @xmath362",
    ", we obtain @xmath363 \\left[\\sum_{\\alpha_2 \\in \\z } b_2(\\alpha_2 ) \\varphi_2(2 x_2 - \\alpha_2)\\right]\\\\ & = &   \\left[\\sum_{k \\in \\z } b_1(k ) \\sum_{\\alpha_1 \\in \\zz } b_1(\\alpha_1 ) \\varphi_1(4 x_1 - 2 k -\\alpha_1)\\right ] \\varphi_2(x_2)\\\\ & = &   \\left[\\sum_{k \\in \\z } b_1(k ) \\varphi_1(2 x_1 - k)\\right ] \\varphi_2(x_2)\\\\ & = &   f(x).\\end{aligned}\\ ] ] the claim concerning @xmath296-refinability of @xmath211 follows from lemma [ lemma : relationrefinability ]",
    ".    there also exists a canonical @xmath296refinable function associated to @xmath241 .",
    "[ lemma : relationrefinability ] if @xmath364 is @xmath281refinable with respect to the mask @xmath365 , then @xmath366 is @xmath296refinable with respect to the mask @xmath367 .",
    "setting @xmath366 and thus @xmath368 , we find for @xmath369 that @xmath370 hence @xmath371 is @xmath296refinable with respect to @xmath372 .",
    "the next two observation are again of a more algebraic nature .",
    "[ l : nullfactmask ] suppose that a mask @xmath261 satisfies @xmath373 for all _ constant _ sequences @xmath374 and some @xmath70 .",
    "then there exists a @xmath375 matrix mask @xmath329 such that @xmath376 .",
    "again we refer to @xcite where it has been shown that @xmath373 for all constant sequences @xmath374 if and only if @xmath377 which is in turn equivalent to the existence of a representation @xmath378,\\ ] ] which is nothing but @xmath376 .",
    "[ l : nullfactfunc ] suppose that a compactly supported function @xmath242 satisfies @xmath379 for all constant sequences , then there exists a compactly supported , continuous @xmath375 matrix function @xmath380 such that @xmath381 for all @xmath382 .",
    "for any @xmath383 ^ 2 $ ] we consider the sequence @xmath384 .",
    "since @xmath242 is compactly supported , any such sequence @xmath385 , @xmath383 ^ 2 $ ] has finite support and since @xmath242 is continuous , the map @xmath386 is a continuous one .    by assumption , @xmath387 for any @xmath30 and any constant sequence @xmath374 , hence , with the scaling matrix @xmath290 , the same methods as above yield that @xmath388 .",
    "consequently , we have that @xmath389\\ ] ] where , like @xmath385 and @xmath390 , also @xmath391 depend continuously on @xmath30 as they can be obtained by applying the orthogonal reduction process from @xcite .",
    "therefore , the function @xmath380 , defined as @xmath392 ^ 2 , \\quad \\alpha \\in \\z^2\\ ] ] has the properties claimed in the statement of the lemma .",
    "now we are in position to prove the sufficiency of the spectral radius condition which we state as a separate proposition .",
    "[ p : convergence<= ] the adaptive directional subdivision scheme based on the masks @xmath173 , @xmath342 converges , if @xmath343 and the representation masks @xmath276 , @xmath70 , satisfy @xmath344 .    for any @xmath393 , there exists , by standard properties of the ( joint ) spectral radius , a constant @xmath394 such that @xmath395 where @xmath396 .",
    "now , let @xmath144 be given and suppose first that @xmath397 .",
    "then , by the refinability of the test function @xmath241 from and lemma  [ l : nullfactmask ] which ensures the existence of a finitely supported matrix mask @xmath398 such that @xmath399 , we have that @xmath400 if on the other hand @xmath401 , by using the function @xmath402 ( cf .",
    "lemma [ lemma : relationrefinability ] ) we pass to the estimate @xmath403 for the first two terms we now make use of lemma  [ l : nullfactfunc ] to obtain that @xmath404 and @xmath405 respectively , while the third term can now be estimated as above again . in summary",
    ", we obtain that there exists a constant @xmath406 such that @xmath407 so that for @xmath408 @xmath409 in other words , the sequence @xmath410 is a cauchy sequence of continuous functions and thus must converge to a limit function for @xmath259 .",
    "convergence of the subdivision scheme then follows by standard means .",
    "the proof of the converse statement of proposition  [ p : convergence<= ] is based on the estimate @xmath411 hence , @xmath412 if we assume that the subdivision scheme converges with uniformly continuous limit function , then the right hand side converges to zero , hence also @xmath413 for @xmath259 and any @xmath414 .",
    "this , however , is not sufficient for our purposes . to show that the restricted spectral radius of @xmath415 is less than one , we have to show that @xmath416 which will be prepared in the next lemmas .",
    "here we follow the outline of a proof from @xcite and show that there exists a constant @xmath394 such that @xmath417 from which ( [ eq : s_besttoshow ] ) follows immediately .",
    "we begin with an estimate on the limit function @xmath239 .",
    "[ l : conv=>sr1 ] if @xmath230 and @xmath211 define a convergent subdivision scheme , then there exists a constant @xmath418 such that for any @xmath144 and any @xmath414 @xmath419    since , according to lemma  [ lemma : subdivisionconvergent ] , convergence implies the preservation of constant sequences by the subdivision scheme , we also have that @xmath420 and thus , for any @xmath237 , any @xmath421 and any @xmath422 with @xmath423 , @xmath424 where @xmath425 since @xmath239 is finitely supported , we have that @xmath426 . specifically , if we assume that @xmath239 is supported on @xmath427 ^ 2 $ ] , then @xmath428 as long as @xmath429 . choosing @xmath430 it follows for any @xmath431 that @xmath432 hence , @xmath433 as claimed .",
    "the next result concerns the difference between the subdivision scheme and the limit function .",
    "[ l : conv=>sr2 ] if the adaptive directional subdivision scheme based on the masks @xmath173 , @xmath70 , then there exists a constant @xmath434 such that , for any @xmath99 , we have @xmath435    we fix @xmath75 , set , for abbreviation , @xmath436 , and assume again that @xmath239 as well as @xmath230 and @xmath211 are supported on @xmath427 ^ 2 $ ] .",
    "again , we make use of the fact that @xmath437 and @xmath239 preserve constant data and obtain , for any @xmath205 and @xmath421 , that @xmath438 since @xmath439 again satisfies @xmath440 , the same judicious choice of @xmath441 as above leads to the estimate @xmath442 from which the claim follows immediately .",
    "now it is easy to complete the proof of the converse statement for convergence which we formulate in the following way .",
    "if the adaptive directional subdivision scheme based on the masks @xmath173 , @xmath342 converges then @xmath343 and the representation masks @xmath276 , @xmath70 , satisfy @xmath344 .    in lemma  [ lemma : subdivisionconvergent ]",
    ", it has already been shown that convergence implies @xmath343 .",
    "moreover , lemma  [ l : conv=>sr1 ] and lemma  [ l : conv=>sr2 ] allow us to conclude with @xmath443 that , for any @xmath237 , we have @xmath444 and since @xmath445 by convergence of the adaptive directional subdivision scheme and uniform continuity of the limit function , our prove is complete .",
    "in this section we present some numerical experiments which illustrate the ability of the developed class of subdivision schemes to adaptively change the orientation of the data .",
    "first , we recall that there exist a general way to construct masks , which are refinable with respect to the dilation matrices @xmath281 and @xmath296 , compare lemma [ lemma : maskgeneration1 ] .",
    "now let the mask @xmath446 be chosen by @xmath447 , @xmath448 , @xmath449 and @xmath450 otherwise , which coincides with the mask studied by deslauriers and dubuc @xcite .",
    "we remark that this mask yields a 2-interpolatory subdivision scheme ( compare also section [ sec : shearletmra ] ) . by lemma [ lemma : maskgeneration1 ] , we know that @xmath451 is @xmath281-refinable , and @xmath452 is @xmath296-refinable .    in figure",
    "[ fig : line ] we illustrate the refinement of the matrix @xmath453    ( 300,250)(0,0 ) ( -5,140 ) defined in after applying @xmath207 with ( a ) @xmath454 , ( b ) @xmath455 , ( c ) @xmath456 , and ( d ) @xmath457.,title=\"fig:\",width=188 ]   defined in after applying @xmath207 with ( a ) @xmath454 , ( b ) @xmath455 , ( c ) @xmath456 , and ( d ) @xmath457.,title=\"fig:\",width=188 ] ( 60,130)(a ) ( 160,140 )   defined in after applying @xmath207 with ( a ) @xmath454 , ( b ) @xmath455 , ( c ) @xmath456 , and ( d ) @xmath457.,title=\"fig:\",width=188 ]   defined in after applying @xmath207 with ( a ) @xmath454 , ( b ) @xmath455 , ( c ) @xmath456 , and ( d ) @xmath457.,title=\"fig:\",width=188 ] ( 225,130)(b ) ( -5,10 )   defined in after applying @xmath207 with ( a ) @xmath454 , ( b ) @xmath455 , ( c ) @xmath456 , and ( d ) @xmath457.,title=\"fig:\",width=188 ]   defined in after applying @xmath207 with ( a ) @xmath454 , ( b ) @xmath455 , ( c ) @xmath456 , and ( d ) @xmath457.,title=\"fig:\",width=188 ] ( 60,0)(c ) ( 160,10 )   defined in after applying @xmath207 with ( a ) @xmath454 , ( b ) @xmath455 , ( c ) @xmath456 , and ( d ) @xmath457.,title=\"fig:\",width=188 ]   defined in after applying @xmath207 with ( a ) @xmath454 , ( b ) @xmath455 , ( c ) @xmath456 , and ( d ) @xmath457.,title=\"fig:\",width=188 ] ( 225,0)(d )    and in figure [ fig : cross ] we subdivide the data given by @xmath458 in both figures we employ different iterations of the subdivision schemes @xmath220 and @xmath216 .",
    "as can clearly be seen , the application of @xmath216 increases the angle the resulting images is sheared in the @xmath30-direction , where the angle depends on the particular path in the binary tree ( see figure [ fig : binary ] ) we choose .",
    "( 300,250)(0,0 ) ( -5,140 ) defined in after applying @xmath207 with ( a ) @xmath454 , ( b ) @xmath455 , ( c ) @xmath456 , and ( d ) @xmath457.,title=\"fig:\",width=188 ]   defined in after applying @xmath207 with ( a ) @xmath454 , ( b ) @xmath455 , ( c ) @xmath456 , and ( d ) @xmath457.,title=\"fig:\",width=188 ] ( 60,130)(a ) ( 160,140 )   defined in after applying @xmath207 with ( a ) @xmath454 , ( b ) @xmath455 , ( c ) @xmath456 , and ( d ) @xmath457.,title=\"fig:\",width=188 ]   defined in after applying @xmath207 with ( a ) @xmath454 , ( b ) @xmath455 , ( c ) @xmath456 , and ( d ) @xmath457.,title=\"fig:\",width=188 ] ( 225,130)(b ) ( -5,10 )   defined in after applying @xmath207 with ( a ) @xmath454 , ( b ) @xmath455 , ( c ) @xmath456 , and ( d ) @xmath457.,title=\"fig:\",width=188 ]   defined in after applying @xmath207 with ( a ) @xmath454 , ( b ) @xmath455 , ( c ) @xmath456 , and ( d ) @xmath457.,title=\"fig:\",width=188 ] ( 60,0)(c ) ( 160,10 )   defined in after applying @xmath207 with ( a ) @xmath454 , ( b ) @xmath455 , ( c ) @xmath456 , and ( d ) @xmath457.,title=\"fig:\",width=188 ]   defined in after applying @xmath207 with ( a ) @xmath454 , ( b ) @xmath455 , ( c ) @xmath456 , and ( d ) @xmath457.,title=\"fig:\",width=188 ] ( 225,0)(d )",
    "in this section we will show how the adaptive directional subdivision schemes developed in the previous sections can be applied to derive a shearlet multiresolution analysis . for the sake of simplicity , in the computation of `` dual functions '' we will restrict ourselves to interpolatory subdivision schemes in this paper .",
    "our idea is inspired by similar ideas for the construction of a fast wavelet decomposition from interpolatory subdivision schemes @xcite .",
    "the construction of a shearlet multiresolution analysis associated with general adaptive directional subdivision schemes is beyond the scope of this paper , and will be studied in a forthcoming paper .    before constructing the scaling spaces we first need to discuss whether there exist masks @xmath230 and @xmath211 such that the subdivision schemes @xmath220 and @xmath216 are both interpolatory , respectively , which immediately implies that @xmath207 is interpolatory for each @xmath459 . to that end , we proceed by using a tensor product approach . recall that a mask @xmath230 leads to an interpolatory subdivision scheme @xmath220 provided that @xmath460 likewise does a mask @xmath211 lead to an interpolatory subdivision scheme @xmath216 provided that @xmath461 there exists a canonical way to define @xmath211 by means of the matrix @xmath213 as indicated by the following lemma ( compare also lemma [ lemma : maskgeneration1 ] ) .",
    "[ lemma : maskgeneration ] let @xmath353 be masks which satisfy @xmath462 for all @xmath463 , @xmath464 and let the mask @xmath354 be defined by @xmath465",
    ". then the mask @xmath466 satisfies , and the mask @xmath467 satisfies .    given some @xmath468",
    ", we obtain @xmath469 a similar computation shows @xmath470 .",
    "suppose we have chosen masks @xmath230 and @xmath211 so that the subdivision scheme @xmath207 is interpolatory and converges for each @xmath144 . to define the scaling functions , recall that we wrote @xmath471 for the canonical embedding of @xmath86 into @xmath87 ; the image of this embedding operation , @xmath472 thus consists of all infinite @xmath83-@xmath84sequences which contain only a finite number of nonzero components .",
    "it is worthwhile to keep in mind that the subdivision scheme @xmath473 converges for all @xmath474 if and only if @xmath230 defines a convergent subdivision scheme and hence the functions @xmath475 which will be needed to build the mra can be ensured to exist by requiring the existence of an appropriate solution of the refinement equation associated to @xmath230 .",
    "this is a much weaker condition , of course , than convergence of the @xmath207 for any @xmath476 .",
    "the _ shearlet scaling spaces _ are defined as @xmath477 and @xmath478 where @xmath479    indeed this choice of scaling spaces provides a multiresolution analysis , which is the focus of the following theorem . the main ingredient in",
    "the proof is  as it should be  the refinement equation .",
    "[ t : shearletmra ] the spaces @xmath480 create a multiresolution analysis .",
    "in particular ,    1 .   the spaces @xmath481 , @xmath482 are translation invariant , 2 .",
    "@xmath483 for all @xmath482 , and 3 .   for each @xmath97",
    ", we have @xmath484 for each @xmath70 .    statement ( i )",
    "follows immediately from the definition of @xmath481 , which is a translational completion .    to verify the nestedness property ( ii ) , we consider an arbitrary `` basis element '' @xmath485 of the form @xmath486 and make use of the refinement equation ( [ eq : refeq ] ) to verify that @xmath487 with @xmath488 , hence @xmath489 .    to verify ( iii ) we again consider a function element @xmath485 of the form .",
    "one implication follows from @xmath490 the other one can be deduced in a similar way by considering @xmath491 and showing that this yields @xmath492 for any @xmath493 .    notice that for each fixed @xmath199 , the set of functions @xmath494 , @xmath205 , can be interpreted as being derived from @xmath495 by refining with the subdivision scheme @xmath496 .",
    "since @xmath496 is interpolatory , this set of functions is linearly independent .",
    "some of the scaling functions which generate @xmath497 are plotted in figure [ fig : delta ] .",
    "the different orientations due to the application of the adaptive directional subdivision scheme to the dirac delta @xmath498 is evident .",
    "this fact forces the associated shearlet spaces to also comprise directionality , hence to react to directional behavior of the data .",
    "( 300,250)(0,0 ) ( -5,140 )   after applying @xmath207 with ( a ) @xmath499 , ( b ) @xmath500 , ( c ) @xmath456 , and ( d ) @xmath501.,title=\"fig:\",width=188 ]   after applying @xmath207 with ( a ) @xmath499 , ( b ) @xmath500 , ( c ) @xmath456 , and ( d ) @xmath501.,title=\"fig:\",width=188 ] ( 60,130)(a ) ( 160,140 )   after applying @xmath207 with ( a ) @xmath499 , ( b ) @xmath500 , ( c ) @xmath456 , and ( d ) @xmath501.,title=\"fig:\",width=188 ]   after applying @xmath207 with ( a ) @xmath499 , ( b ) @xmath500 , ( c ) @xmath456 , and ( d ) @xmath501.,title=\"fig:\",width=188 ] ( 225,130)(b ) ( -5,10 )   after applying @xmath207 with ( a ) @xmath499 , ( b ) @xmath500 , ( c ) @xmath456 , and ( d ) @xmath501.,title=\"fig:\",width=188 ]   after applying @xmath207 with ( a ) @xmath499 , ( b ) @xmath500 , ( c ) @xmath456 , and ( d ) @xmath501.,title=\"fig:\",width=188 ] ( 60,0)(c ) ( 160,10 )   after applying @xmath207 with ( a ) @xmath499 , ( b ) @xmath500 , ( c ) @xmath456 , and ( d ) @xmath501.,title=\"fig:\",width=188 ]   after applying @xmath207 with ( a ) @xmath499 , ( b ) @xmath500 , ( c ) @xmath456 , and ( d ) @xmath501.,title=\"fig:\",width=188 ] ( 225,0)(d )",
    "let @xmath502 , @xmath503 , denote a sequence of projections from @xmath504 to @xmath481 , respectively , and define the _ shearlet spaces _ as @xmath505 , @xmath503 , hence as an appropriate complement of @xmath481 in @xmath504 . in classical mra , @xmath506 is chosen as an orthogonal projection , but following the approach from @xcite , we can also use interpolation as a projection , provided that the subdivision schemes were interpolatory .      in order to establish the shearlet decomposition , we require the following two observations .    [",
    "lem : help1 ] for all @xmath199 and @xmath507 , we have @xmath508    since all the matrices",
    "@xmath195 , @xmath199 , are unimodular , we obtain @xmath509    to formulate the next result , we denote by @xmath510 the _ reversal _ operator for sequences , which maps @xmath511 to @xmath512 . moreover , we will write @xmath513 for the zero sequence in @xmath514 , @xmath515 . we can now derive the following crucial relationship between refinable functions and subdivision .",
    "[ lem : help2 ] for @xmath516 , @xmath517 , @xmath518 and @xmath507 , we have @xmath519    without loss of generality we can assume that @xmath520",
    ". then , for @xmath521 , the refinement equation gives @xmath522 this is the initial step for the inductive proof that for @xmath523 we have @xmath524 indeed , applying the refinement equation once more to , we get that @xmath525 which advances the induction hypothesis in . specifically , for @xmath526 this identity gives @xmath527 since for any @xmath518 @xmath528_2    & = & -2^{n+1 } \\ , 2^{-n+k } \\sum_{j=1}^k \\eta_{k - j } 2^{-j}\\\\    & = & -2^{k+1 } \\sum_{j=1}^k r(\\eta)_j 2^{-j}\\\\    & = & -2^{k+1 } \\left [ r(\\eta ) \\right]_2 ,    \\end{aligned}\\ ] ] we finally get the identity @xmath529 which proves the claim .",
    "now suppose we are given some data from a finely sampled function on the grid @xmath530 , say .",
    "the key idea for the decomposition of this data , dependent on different directions , is stated in the following result which is the backbone of the mra based fast discrete shearlet decomposition .",
    "we would like to mention that it relies on the fact that the masks @xmath230 and @xmath211 are chosen to be interpolatory and thus give us an explicit expression for @xmath531 .",
    "the wavelet part of such a decomposition is , as usual , related to the representatives of the quotient groups @xmath532 , @xmath199 .",
    "since for @xmath90 we have @xmath533 , all such quotient groups consist of a number of elements that depends only on the length of @xmath115 ; we will denote by @xmath534 a selection of @xmath535 representatives for @xmath536 \\}$ ] . in the sequel",
    ", we will make use of the notation @xmath537 , @xmath243 being some 2@xmath5382-matrix .",
    "[ theo : decomposition ] for @xmath507 , @xmath539 , @xmath540 and @xmath541 we have that @xmath542    the decomposition is based on the prediction ",
    "correction method which has become standard for interpolation based wavelet decomposition , in particular in connection with the so  called `` lazy wavelet '' and the associated `` lifting schemes '' @xcite .",
    "we subsample the data @xmath543 to obtain @xmath544 and make use of lemma  [ lem : help2 ] to obtain that @xmath545 this identity is then decomposed with respect to @xmath546 giving the _ prediction _ @xmath547 since the subdivision schemes were supposed to be interpolatory . comparing this with the decomposition",
    "@xmath548 we have to apply precisely the _ correction _ from .    for the special case @xmath549 and thus @xmath550 , theorem  [ theo : decomposition ]",
    "simplifies into the following form .",
    "[ cor : decomposition ] for @xmath543 , @xmath199 and @xmath97 we have that @xmath551    the decomposition is the shearlet decomposition associated with the shearlet mra : the function on the left hand side belongs to @xmath481 and is written as the sum of a function in @xmath552 and correction terms from @xmath481 that vanish at @xmath553  the _ shearlets _ in the interpolatory mra .",
    "the _ fast shearlet decomposition _ is now based on an iterative application of , where each step can be understood as filtering by means of a filter bank . to that end",
    ", we have to interpret the initial sequence @xmath554 appropriately .",
    "denoting by @xmath555 the `` sheared '' version of the refinable function @xmath556 , we form the quasi - interpolants @xmath557 these are precisely the functions which appear on the left hand side of and .",
    "it is worthwhile to note that all the functions @xmath558 are relying on the same initial data @xmath543 .",
    "the interpretation of is rather easy now if we take into account that @xmath556 was assumed to be the limit function of an interpolatory scheme , hence cardinal : @xmath559 , @xmath316 .",
    "hence , since @xmath560 we can substitute @xmath561 and use the cardinality of @xmath556 to find that @xmath562 or @xmath563 , respectively .",
    "the latter tells us that we should interpret the sequence @xmath374 as a function sampled at the grid @xmath564 , while the parameter @xmath115 determines how this data is sheared and which thus are the directions `` preferred '' by the wavelet decomposition .    for the fast decomposition",
    "we now start with @xmath565 , interpret it as in , and decompose it in two ways , namely , for @xmath566 , into @xmath567 where the coefficients @xmath568 are obtained by filtering the original sequence @xmath374 in _ both _ cases .",
    "this is the fundamental property of this decomposition algorithm : even if we decompose _ two different _ functions , @xmath558 with @xmath566 , we have to filter _ only one _ data vector to obtain the new set of scaling coefficients @xmath569 and shearlet coefficients @xmath570 .    in the next step , the sequences @xmath571 and the associated functions @xmath572 are decomposed in precisely the same way , making use of corollary  [ cor : decomposition ] again .",
    "like above , we filter @xmath573 twice to obtain new , further downsampled sequences @xmath574 and @xmath575 together with the respective shearlet coefficients @xmath576 , @xmath577 and @xmath578 , @xmath579 . in exactly the same way we obtain @xmath580 and @xmath581 as well as @xmath582 , @xmath577 and @xmath583 , @xmath579 by filtering @xmath584 .",
    "these first two steps of decomposition are illustrated in figure  [ fig : decomposition ] .",
    "0.25 mm    ( 460,180)(0,0 ) ( 220,150)(-2,-1)105 ( 230,150)(2,-1)105 ( 220,160)@xmath585 ( 60,80)@xmath586 ( 300,80)@xmath587 ( 70,70)(-1,-2)25 ( 80,70)(3,-2)80 ( 310,70)(-1,-2)25 ( 320,70)(3,-2)80 ( 0,0)@xmath588 ( 120,0)@xmath589 ( 240,0)@xmath590 ( 360,0)@xmath591    it can already be seen from figure  [ fig : decomposition ] that  like the subdivision scheme  the shearlet decomposition becomes a binary tree labeled by the directional indices @xmath115 .",
    "indeed , in general we obtain the new coefficients by the following simple filtering .    [ algo : fsd ]",
    "let @xmath571 for some @xmath199 be given .",
    "then the next level of scaling and shearlet coefficients are computed as @xmath592 eventually , this process ends up with coarsest level scaling coefficients @xmath571 , @xmath90 , and shearlet coefficients @xmath593 , @xmath594 , @xmath595 , @xmath596 which describe the deviation from the coarse data .",
    "indeed , it is now easily seen that such a decomposition must recognize `` sheared '' and thus directional components of two dimensional data since relates , for @xmath597 , the data @xmath598 with the function @xmath599 and the respective shearlet coefficients must be large where the prediction by the subdivision scheme is inaccurate , i.e. , at directional singularities .",
    "thus , the `` recipe '' is to consider the shearlet coefficients @xmath600 a precise analysis of this nevertheless fundamental aspect of directional edge detection is beyond the scope of this paper where we just want to give the framework for adaptive directional detections .",
    "it should also be clear that the adaptive directional approach is not tied to interpolatory schemes , in fact , any perfect reconstruction filter bank can be used as long as the projection and its complement can be expressed properly .",
    "we plan to address these questions as well as the numerical implementations in a further paper , however .",
    "the first author would like to thank ingrid daubechies for very inspiring discussions , and wolfgang dahmen for helpful comments on an earlier version of this paper .",
    "she especially thanks pacm at princeton university for its hospitality and support during her visit .",
    "m.  charina , c.  conti , and t.  sauer , _ @xmath601convergence of subdivision schemes : joint spectral radius versus restricted spectral radius _ , in approximation theory xi ( gatlinburg , tn , 2004 ) , m.  neamtu and l.  l.  schumaker , eds . , nashboro press , nashville , tn ( 2005 ) , 129150 .",
    "s. dahlke , g. kutyniok , p. maass , c. sagiv , h .-",
    "stark , and g. teschke , _ the uncertainty principle associated with the continuous shearlet transform , _ int .",
    "j. wavelets multiresolut .",
    "inf . process .",
    ", to appear .",
    "k. guo , g. kutyniok , and d. labate , _ sparse multidimensional representations using anisotropic dilation und shear operators , _ in wavelets und splines ( athens , ga , 2005 ) , g. chen und m.  j.  lai , eds . , nashboro press , nashville , tn ( 2006 ) , 189201 .",
    "g. kutyniok and t. sauer , _ from wavelets to shearlets and back again _ , in approximation theory xii",
    "( san antonio , tx , 2007 ) , c. k. chui , m. neamtu , and l. schumaker , eds . , nashboro press , nashville , tn , to appear .",
    "d. labate , w - q .",
    "lim , g. kutyniok , and g. weiss , _ sparse multidimensional representation using shearlets , _ in wavelets xi ( san diego , ca , 2005 ) , m. papadakis , a. f. laine und m. a. unser , eds . , spie proc .",
    "_ 5914 _ , spie , bellingham , wa ( 2005 ) , 254262 ."
  ],
  "abstract_text": [
    "<S> in this paper , we propose a solution for a fundamental problem in computational harmonic analysis , namely , the construction of a multiresolution analysis with directional components . </S>",
    "<S> we will do so by constructing subdivision schemes which provide a means to incorporate directionality into the data and thus the limit function . </S>",
    "<S> we develop a new type of non - stationary bivariate subdivision schemes , which allow to adapt the subdivision process depending on directionality constraints during its performance , and we derive a complete characterization of those masks for which these adaptive directional subdivision schemes converge . </S>",
    "<S> in addition , we present several numerical examples to illustrate how this scheme works . </S>",
    "<S> secondly , we describe a fast decomposition associated with a sparse directional representation system for two dimensional data , where we focus on the recently introduced sparse directional representation system of shearlets . </S>",
    "<S> in fact , we show that the introduced adaptive directional subdivision schemes can be used as a framework for deriving a shearlet multiresolution analysis with finitely supported filters , thereby leading to a fast shearlet decomposition . </S>"
  ]
}