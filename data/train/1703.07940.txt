{
  "article_text": [
    "most commonly used reinforcement learning ( rl ) algorithms store an estimate of what s known as the value function ( vf ) .",
    "the vf corresponds to a particular policy , and is a mapping from each state - action pair to a real value which reflects the amount of reward the agent will obtain starting from that state - action pair and following the policy in question ( sutton and barto 1998 ) . in order for an rl algorithm to perform well ( i.e. to achieve a high reward ) , it is important that the vf estimate is as accurate as possible , since it is this estimate which governs how the algorithm will update its policy .    traditional rl algorithms such as td(@xmath4 ) or @xmath5-learning can generate exact vf estimates when dealing with small state and action spaces .",
    "however , when environments are complex ( with large state or action spaces ) , applying such algorithms directly becomes too computationally demanding . as a result",
    "it is common to introduce some form of architecture with which to approximate the vf , for example a parametrised set of functions ( sutton and barto 1998 ; bertsekas and tsitsiklis 1996 ) .",
    "one issue when introducing vf approximation , however , is that the accuracy of the algorithm s vf estimate is highly dependent upon the exact form of the architecture chosen ( it may be , for example , that no element of the chosen set of parametrised functions closely fits the vf ) .    accordingly",
    ", a number of authors have explored the possibility of allowing the approximation architecture to be _ learned _ by the agent , rather than pre - set manually by the designer ",
    "see buoniu et al ( 2009 ) for an overview .",
    "what we might hope to achieve by employing such an approach is to create an rl algorithm which still has relatively low computational demands , but at the same time has increased flexibility , allowing us to apply the algorithm to a wider set of problems without needing to invest time to suitably adapt it in each case .",
    "if we assume that the approximation architecture being adapted is linear ( so that the vf is represented as a weighted sum of basis functions ) such methods are known as _",
    "basis function adaptation_.    a simple and perhaps , as yet , under - explored method of basis function adaptation involves using an estimate of the frequency with which an agent has visited certain states to determine which states to more accurately represent .",
    "such methods are `` unsupervised '' in the sense that no direct reference to the reward or to any estimate of the vf is made .",
    "the concept of using visit frequencies in an unsupervised manner is not completely new ( menache et al 2005 ; bernstein and shimkin 2010 ) however it remains relatively unexplored compared to methods which seek to measure the error in the vf estimate explicitly and to then use this error as feedback ( munos and moore 2002 ; bertsekas and yu 2009 ; di castro and mannor 2010 ; mahadevan et al 2013 ) .",
    "as we will demonstrate , however , unsupervised methods have some distinct advantages : ( a ) estimates of visit frequencies are cheap to calculate and to store , ( b ) accurate estimates of visit frequencies can be generated with fewer samples than accurate estimates of , for example , temporal differences ( which are a common form of feedback used to adapt basis functions ) , and ( c ) under suitable conditions , and applying an appropriate scoring function , such methods can in fact generate very accurate vf estimates , guaranteeing in certain cases scores arbitrarily close to zero .",
    "our overarching objective in this article is to more closely examine unsupervised methods and seek to quantify , where possible , these advantages .",
    "it is point ( c ) which is perhaps the most surprising , and it forms the substance of the article s main result . for any fixed policy you will have a stationary distribution describing the probability of being in each state .",
    "suppose ( i ) the policy and transition function for a given problem are close to deterministic , and ( ii ) the prior for the transition function is uniformly distributed ( this will be more precisely described below ) .",
    "we will show that , under these conditions , an agent which follows an arbitrary policy will , on average , tend to spend almost all of its time in a small subset of the state space .",
    "indeed , if the state space is of size @xmath0 , there is a theoretical upper bound on the average size of this subset : @xmath6 .",
    "provided we have enough basis functions to individually represent the states in this subset , unsupervised basis function adaptation methods can ensure that the vf is arbitrarily well estimated over this subset .",
    "if the scoring function we apply is weighted by the probability of visiting each state , we can then guarantee an arbitrarily low score .",
    "the implication of this is that , under these circumstances , unsupervised methods will perform _ at least as well _ as other more complex methods , but , compared to these other methods , will do so _ more cheaply _ ( in the sense of sampling required and also computational demands ) .",
    "whilst conditions ( i ) and ( ii ) encompass many important and general problems , we will also explore the potential to generalise condition ( ii ) to encompass a larger set of possible priors .",
    "we also explore these ideas experimentally .",
    "our experimental results suggest that our techniques provide a powerful advantage in many real world settings . over a set of realistic parameter settings the techniques ( when compared to fixed state aggregation )",
    "can reduce vf error by an amount in the range of @xmath7-@xmath8% . in some cases",
    "the experimental results also suggest that the assumptions required by the theory can be relaxed .",
    "as noted above , unsupervised techniques at present are relatively unexplored .",
    "menache et al ( 2005 ) provided a brief evaluation of an unsupervised algorithm ( to provide a comparison with two more complex adaptation algorithms ) in the setting of policy evaluation .",
    "berstein and shimkin ( 2009 ) examined an algorithm where a set of kernels are progressively split ( `` once - and - for - all '' ) based on the visit frequency for each kernel .",
    "their algorithm includes policy updates which incorporate knowledge of uncertainty in the vf estimate .",
    "the algorithm we propose below works in conjunction with a state aggregation approximation architecture , employing a form of `` cell - splitting '' to give state space regions more or less resolution .",
    "this bears similarities to a number of approaches examined in the literature ( the main difference in our approach is the rules under which cells are split or joined ) .",
    "moore and atkeson ( 1995 ) provide an early algorithm based on updating a state aggregation architecture , whilst whiteson et al ( 2007 ) examined a basis function construction method involving cell splitting .",
    "our analysis is new both in terms of the details of the unsupervised algorithm we outline ( it is designed so as to minimise memory requirements , in particular to ensure that space complexity is roughly of the order of the number of basis functions , whilst still permitting the approximation architecture to be continuously adapted on - line ) and in terms of the theoretical concepts we derive .    in the remainder of this section we outline the formal framework we will be using . in section",
    "[ unsupervised ] we set out the details of our algorithm ( pasa , short for `` probabilistic adaptive state aggregation '' ) which performs unsupervised basis function adaptation based on state aggregation . in section [ theoretic ]",
    "we outline our main theoretical results .",
    "finally , in section [ simulation ] we set out some empirical results designed to both support and extend the results in section [ theoretic ] .",
    "we assume that we have an agent which interacts with an environment over a sequence of iterations @xmath9 . for each @xmath10 the agent will be in a particular state to hold in the case of a continuous state space",
    ", additional assumptions would need to be introduced . ]",
    "@xmath11 ( @xmath12 ) and will take a particular action @xmath13 ( @xmath14 ) .",
    "each action is taken according to a _ policy _",
    "@xmath15 whereby the probability the agent takes action @xmath13 in state @xmath11 is denoted as @xmath16 .",
    "we are considering the problem of policy evaluation , so we will always assume that the agent s policy @xmath15 is fixed ( i.e. does not change as a function of @xmath10 ) . the _ reward function _",
    "@xmath17 is a mapping from each state - action pair @xmath18 to a real number , such that if the agent is in state @xmath11 and takes action @xmath13 , then it will receive a _ reward _ @xmath19 .",
    "the reward function is assumed to be deterministic and bounded , i.e. @xmath20 for all @xmath21 .",
    "the _ transition function _",
    "@xmath22 defines how the agent s state evolves over time .",
    "if the agent is in state @xmath11 and takes an action @xmath13 in iteration @xmath10 , then the probability it will transition to the state @xmath23 in iteration @xmath24 is given by @xmath25 . both @xmath22 and @xmath17 are taken as unknown , however we assume we are given a prior distribution for both .",
    "the _ value function _",
    "@xmath26 , which maps each of the @xmath27 state - action pairs to a real value , is defined as follows : @xmath28 where the expectation is taken over the distributions of @xmath22 and @xmath15 ( i.e. for a particular instance of @xmath22 , not over its prior distribution ) and where @xmath29 is known as a _",
    "discount factor_. we have used superscript brackets to indicate dependency on the iteration @xmath10 . initially the vf is unknown , our objective , given some @xmath15 , is to learn the vf for a particular instance of @xmath22 .",
    "assuming we are able to store an explicit real value for each state - action pair , traditional rl algorithms provide a means of estimating @xmath26 .",
    "these estimates will converge to the correct value as @xmath10 becomes large ( sutton and barto 1998 ) . in cases where @xmath0 or @xmath30 are large , though , it may be impossible to store @xmath27 real values . hence ,",
    "when dealing with such cases , it is common to employ vf approximation .",
    "once we approximate the vf , however , even if the underlying rl algorithm still converges to generate an estimate of the vf ( which is not always guaranteed ) , we can no longer rely on the estimate being arbitrarily close to the true value @xmath26 .",
    "one form of vf approximation , _ parametrised value function approximation _ , involves generating an approximation of the vf using a parametrised set of functions .",
    "the goal of the rl algorithm then becomes to find a value for the parameters so that the vf estimate is as near to the true value as possible .",
    "the approximate vf is denoted as @xmath31 , and , assuming we are approximating over the state space only and not the action space , this value is parametrised by a matrix @xmath32 of dimension @xmath33 ( where @xmath34 ) .",
    "such an approximation architecture is _ linear _ if @xmath31 can be expressed in the form @xmath35 , where @xmath36 is the @xmath37th column of @xmath32 and @xmath38 is a fixed vector of dimension @xmath1 for each pair @xmath18 .",
    "the @xmath39 distinct vectors of dimension @xmath0 given by @xmath40 are called _ basis functions_. it is common to assume that @xmath41 for all @xmath37 , in which case we have only @xmath1 distinct basis functions , and @xmath42 .",
    "a _ state aggregation _ approximation architecture  see , for example , singh et al ( 1995 ) and whiteson et al ( 2007 )  is a simple linear approximation architecture which we can define as being a mapping @xmath43 from each state @xmath11 to a _ cell _ @xmath44 ( @xmath45 ) . defining the architecture as a `` mapping '' implies that every state corresponds to exactly one cell .",
    "we will denote as @xmath46 the set of states in the @xmath47th cell . given a state aggregation approximation architecture ,",
    "the underlying rl algorithm can not distinguish states in the same cell , and hence @xmath48 will be the same for all states which are in the same cell ( @xmath32 in this context can be interpreted as a set of weights , one given to each cell - action pair ) .",
    "if we want to design an algorithm to adapt an approximation architecture , we need a means to assess how well it is doing this .",
    "a _ scoring function _ is used to assess the accuracy of a vf estimate ( and can also therefore be used to evaluate an algorithm designed to generate a vf estimate ) .",
    "many basis function adaptation algorithms use a scoring function as a form of feedback to help guide how the basis functions should be updated . in such cases",
    "it is important that the score is something which can be measured computationally .",
    "one commonly used score is the squared error in the vf estimate for each state - action , weighted by the probability of each state - action occurring ( menache et al 2005 ; bertsekas and yu 2009 ; di castro and mannor 2010 )",
    ". we will refer to this as the _ mean squared error _",
    "( mse ) : @xmath49    this is where @xmath50 is a vector of the probability of each state given the stationary distribution associated with @xmath15 ( given some fixed policy @xmath15 , the transition matrix obtained from @xmath15 and @xmath22 has a corresponding stationary distribution , provided the transition matrix is irreducible and aperiodic ) .",
    "note that the true vf @xmath26 appears in ( [ mseexact ] ) .",
    "this value , however , is unknown .",
    "therefore , another commonly used scoring function ( which , unlike mse , can be estimated empirically ) uses @xmath51 , the _ bellman operator _ , to obtain an approximation of the mse .",
    "this scoring function we denote as @xmath52 ( this is a weighted sum of what is sometimes known as the _ bellman error _ at each state - action ) : @xmath53 where : @xmath54    our results in section [ theoretic ] will be stated in relation to mse and @xmath52 .",
    "it will be crucial to all of our results that the scoring function is weighted by @xmath50 .",
    "two important comments should be made in relation to this .",
    "the first is that , whilst applying such a weighting appears natural , a scoring function does not necessarily need to be weighted by @xmath50 ( or an approximation of @xmath50 ) .",
    "there may be circumstances under which a more appropriate measure of the accuracy of a vf estimate would , for example , weight every state equally ( the most appropriate measure to use in each situation would depend on a number of complex factors ) .",
    "we acknowledge this as a limitation of the analysis in section [ theoretic ] .",
    "the second is that , in investigating unsupervised basis function adaptation methods , we are implicitly making a comparison with methods of basis function adaptation which use explicit scores as a source of feedback ( these could be called `` supervised '' methods ) . if an algorithm uses a scoring function as feedback , then ( irrespective of which scoring function is most appropriate ) it is best evaluated in terms of how well it minimises _ that particular scoring function_. the scoring function @xmath52 is an attractive choice to provide feedback for supervised methods since , by weighting the error by the probability of visiting a state , it is possible to generate an estimate of the score without knowing the probability of visiting each state .",
    "in fact , any feedback based on a scoring function which is _ not _ weighted by @xmath50 would implicitly require some way of normalising the score for each state .",
    "this in turn would require an estimate for @xmath50 , which implies that @xmath55 distinct values need to be recorded .",
    "hence , if unsupervised methods can perform comparatively well in terms of minimising probability weighted scoring functions , this is of great importance when comparing such methods to supervised alternatives .    in the definitions above both mse and @xmath52",
    "are weighted by the probability of each action occurring .",
    "we could redefine mse and @xmath52 to weight each action equally  when sampling for @xmath52 this would not be an issue computationally since @xmath15 is known to the algorithm , i.e. we can simply divide each sample by @xmath16 ( acknowledging that samples from rarely chosen actions would contribute more significantly to the variance of the estimate ) . our results in section [ theoretic ]",
    "will extend to @xmath52 under such an alternative definition .",
    "as we noted in the introduction , circumstances exist under which an agent ( adopting a random , or in some cases an arbitrary , policy ) will , on average , tend to spend almost all of its time in a relatively small subset of the state space .",
    "we examine these circumstances more closely in section [ theoretic ] .",
    "the underlying idea of pasa is to make the vf representation as detailed as possible over this relatively small subset ( whilst allowing the representation to be coarser over the remainder of the state space ) .",
    "pasa is designed to function in conjunction with a state aggregation approximation architecture , and accordingly it updates a mapping @xmath43 over time .",
    "provided this mapping converges to some fixed mapping @xmath56 ( we prove below that it will ) , then if an rl algorithm such as sarsa ( which we have used for the experiments in section [ simulation ] ) is used to update @xmath31 for the state aggregation architecture associated with @xmath56 , the estimate @xmath31 will also converge , due to the fact that sarsa , as well as many other rl algorithms , will , with a linear approximation architecture , converge for fixed policies ( bertsekas and tsitsiklis 1996 ) .",
    "we can then assess @xmath31 using our scoring function .",
    "suppose , momentarily , we have sufficient computational space to be able to generate an estimate @xmath57 of each @xmath58 ( which we could do , for example , by having @xmath0 weights and using a stochastic approximation algorithm ) .",
    "we could then design our algorithm roughly as follows : ( i ) start with an initial course set of @xmath59 cells , ( ii ) calculate @xmath60 for @xmath61 , ( iii ) split the cell with the largest value of @xmath62 , ( iv ) recalculate @xmath62 for the new @xmath63 cells , and ( v ) continue in the same fashion until we have @xmath1 cells .",
    "we could rerun this splitting process every iteration , or , if we prefer , at discrete intervals .",
    "provided @xmath58 is large for only a small set of states ( i.e. the variance of the elements of @xmath50 is high ) the resulting set of cells ( basis functions ) will tend to have a more detailed representation of the vf in areas of the state space with high stationary probability .",
    "this is the essence of how pasa works , except that , to avoid storing @xmath55 weights ( which we ve implicitly assumed is impossible ) , we instead measure the probability of visiting the @xmath64 `` base cells '' and of visiting @xmath65 additional cells ( which may change over time ) which are progressively split from these base cells .",
    "we can then estimate the probability of visiting each of the @xmath1 resulting cells by subtracting estimates from one another . the consequence , as will become apparent ,",
    "is that pasa converges to the same point as the algorithm described in the paragraph above , whilst requiring only @xmath66 space complexity .",
    "the trade off is that it may take a longer amount of time to converge , although in practical terms this difference would appear to be marginal .    before setting out how pasa works in detail ,",
    "it is worthwhile highlighting one aspect of our algorithm .",
    "note that many methods examined in the literature involve what has been termed _ basis function construction _",
    "( buoniu et al 2009 ) , where a set of basis functions are determined by an initial process `` once - and - for - all '' , which occurs prior to the agent beginning to function `` as normal ''  examples include munos and moore ( 2002 ) and whiteson et al ( 2007 ) .",
    "such methods work , for example , by progressively adding basis functions until some criteria is satisfied .",
    "the pasa algorithm falls into an alternative class of methods which have been termed _ basis function optimisation _ ( buoniu et al 2009 ) .",
    "the assumption with such methods is that there is a fixed number of basis functions which are progressively updated throughout the whole period the agent functions .",
    "this approach has the advantage of being more flexible ",
    "the basis functions can adapt to policy changes , or indeed to changes in the environment .",
    "pasa will store a vector @xmath67 of integers of dimension @xmath65 , where @xmath59 .",
    "suppose we start with a fixed partition of the state space into @xmath64 cells , indexed from @xmath68 to @xmath64 , each of which is approximately the same size .",
    "using @xmath67 we can now define a new partition by splitting ( as evenly as possible ) the @xmath69th cell in the original partition .",
    "we leave one half of the @xmath69th cell with the index @xmath69 and give the other half the index @xmath63 ( all other indices stay the same ) .",
    "taking this new partition ( consisting of @xmath63 cells ) we can create a further partition by splitting the @xmath70th cell .",
    "continuing in this fashion we will end up with a partition containing @xmath1 cells ( which gives us the mapping @xmath43 ) .",
    "we need some additional mechanisms to allow us to update @xmath67 .",
    "denote by @xmath71 the set of states in the @xmath72th cell of the @xmath37th partition ( so @xmath73 and @xmath74 ) .",
    "the algorithm will store a vector @xmath75 of real values of dimension @xmath1 ( initialised as a vector of zeroes ) .",
    "this will record the approximate frequency with which certain cells have been visited by the agent .",
    "we define a new vector @xmath76 of dimension @xmath1 accordingly : @xmath77 where @xmath78 is the _ indicator function _ for a logical statement such that @xmath79 if @xmath30 is true .",
    "we can interpret @xmath76 as follows : @xmath80 will be equal to @xmath68 if and only if the current state @xmath81 falls into any cell which has been split from the original cell @xmath82 or @xmath83 ( depending on @xmath72 ) .",
    "the resulting mapping from each state to a vector @xmath76 we denote as @xmath84 ( there is a simple mapping from each vector @xmath76 to one of the @xmath1 final cells : simply take the mapped - to cell as the highest index @xmath47 such that @xmath85 ) .",
    "we then update @xmath75 in each iteration as follows ( i.e. using a simple stochastic approximation algorithm ) : @xmath86    this is where @xmath87 $ ] is a constant step - size parameter . to update @xmath67 , at certain intervals @xmath88",
    "the pasa algorithm performs a sequence of @xmath65 operations .",
    "a temporary copy of @xmath75 is made , which we call @xmath89 .",
    "we also store an @xmath1 dimensional boolean vector @xmath90 and set each entry to zero at the start of the sequence .",
    "this keeps track of whether a particular cell has only one state , as we do nt want the algorithm to try to split singleton cells . at each stage @xmath91 of the sequence we update @xmath67 as follows ( for @xmath67 ,",
    "if multiple indices satisfy the @xmath92 function , we take the lowest index ) : @xmath93 where @xmath94 and where @xmath95 is a constant designed to ensure that a ( typically small ) threshold must be exceeded before @xmath67 is adjusted .",
    "we also , after @xmath67 , update : @xmath96    the idea behind each step in the sequence is that the non - singleton cell @xmath97 with the highest value @xmath98 ( an estimate of visit frequency which is recalculated at each step ) will be split .",
    "details of these steps , as well as the overall pasa process , are outlined in algorithm [ pasa ] .",
    "note that the algorithm calls a procedure to cells .",
    "this procedure simply updates @xmath84 and @xmath90 given the latest value of @xmath67 .",
    "it also calls a procedure , which converts the mapping @xmath84 to a mapping @xmath43 . both of these procedures are computationally very straightforward . a diagram illustrating the main steps is at figure [ cellsplit ] .",
    "@xmath99 @xmath100 @xmath101 @xmath102 @xmath103 @xmath104 @xmath105 @xmath106 @xmath107 @xmath108      pasa requires only a modest increase in computational resources compared to fixed state aggregation . in relation to time",
    "complexity , @xmath75 can be updated in parallel with the rl algorithm s update of @xmath32 ( and the update of @xmath75 would not be expected to have any greater time complexity than the update to @xmath32 if using a standard rl algorithm such as sarsa or @xmath5-learning ) .",
    "the vector @xmath67 can be updated at intervals @xmath109 ( and this update can also be run in parallel ) . in practice @xmath109",
    "can be large because this allows time for @xmath75 to converge .",
    "the mapping from state to cell has a very low order of time complexity : @xmath110 for an rl algorithm using pasa compared to a minimum of @xmath111 for @xmath1 equally sized cells .",
    "hence , pasa involves effectively no increase in time complexity .",
    "pasa does involve additional space complexity with respect to storing the vector @xmath75 : we must store @xmath1 real values .",
    "if we also store @xmath43 and @xmath84 ( as well as @xmath89 temporarily ) the overall space complexity becomes @xmath3 , although @xmath43 must also be stored for fixed state aggregation .",
    "the rl component has space complexity @xmath112 ( reflecting the @xmath33 cell - action pairs ) , so that the introduction of pasa as a pre - processing algorithm will not materially impact the overall space complexity .",
    "( note also that the space complexity of pasa is independent of @xmath30 . )    regarding sampling efficiency , two points can be made .",
    "the first is that , since visit frequencies do not depend on each individual action , reward or subsequent trajectory , they can be estimated quickly , much more quickly than , for example , temporal differences .",
    "the second point arises when we compare pasa to methods based on explicitly estimating the vf error ( supervised methods ) .",
    "once pasa has converged ( we argue below that it will ) , then the estimate @xmath31 only needs to converge _",
    "once_. in contrast , if the estimate @xmath31 is used to update the basis functions , then a new value of @xmath31 must , in principle , be generated each time there is an update to the basis functions .",
    "this could have serious consequences for the time required for the process to converge , as @xmath31 may take a very long time to generate an accurate estimate for a particular set of basis functions .",
    "this is particularly so if @xmath113 is near @xmath68 or when @xmath0 or @xmath30 are large .",
    "is large or @xmath15 heavily favours certain actions then an accurate estimate of the bellman error ( obtained , for example , using temporal differences ) will require an even larger number of samples , since rarely taken actions will have a high amount of variance . ]    in relation to the convergence properties of pasa , if we are considering a situation where @xmath15 is updated , then provided @xmath15 continues to change pasa will not converge and instead will continuously update @xmath43 .",
    "however , for fixed @xmath15 , pasa will converge in a particular sense which we now describe .",
    "our outline of pasa assumed a single fixed step - size parameter @xmath114 .",
    "for our proof below it will be easier to suppose that we have a distinct fixed step - size parameter @xmath115 for each element @xmath116 of @xmath75 , each of which we can set to a different value ( fixed as a function of @xmath10 ) .",
    "for the remainder of this section @xmath114 should be understood as referring to this vector of step - size parameters .",
    "we will say that some function of @xmath10 , @xmath117 , _ becomes @xmath118-fixed over @xmath119 after @xmath120 _ provided @xmath120 is such that , for all @xmath121 , the value @xmath122 will remain the same for all @xmath123 satisfying @xmath124 with probability at least @xmath125 ( where the probability is taken over the prior distributions for @xmath22 and @xmath17 ) .    for every @xmath126 and @xmath127 there exists @xmath114 and @xmath120 such that the mapping @xmath128 generated by pasa will become @xmath118-fixed over @xmath119 after @xmath120 .",
    "suppose that @xmath129 is a sequence of real numbers such that @xmath130 for all @xmath72 and that @xmath131 is a sequence of closed intervals on the real line such that @xmath132 for all @xmath72 .",
    "provided we have suitably specified @xmath133 , we can denote : @xmath134    for any @xmath135 , @xmath136 and @xmath137 we can set the elements @xmath138 small enough , find @xmath139 and find some @xmath140 large enough so that @xmath141 remains within the interval @xmath139 for @xmath135 iterations with probability at least @xmath142 provided @xmath140 iterations have elapsed . in this way @xmath143",
    "becomes @xmath144-fixed over @xmath135 after @xmath140 .",
    "this follows by relying on results regarding stochastic approximation algorithms with fixed step - sizes . by replacing each @xmath145 with",
    "a time scaled equivalent , so that @xmath146 , each @xmath116 will , as @xmath147 , have an associated deterministic ordinary differential equation ( ode ) with a unique solution",
    ". furthermore , the difference between each @xmath116 and this ode converges ( again as @xmath147 ) weakly in distribution to an ornstein - ulenbeck process , which has a normal stationary distribution with a scaling factor of @xmath148 ( bucklew et al 1993 ) .",
    "hence , due to the fact that each @xmath116 is bounded by the unit interval , we can select a scalar @xmath149 so that our requirement is satisfied provided @xmath150 for all @xmath61 .",
    "suppose we have chosen @xmath151 .",
    "then @xmath69 will also become @xmath144-fixed over @xmath135 after @xmath140 .",
    "this is for the following reason .",
    "suppose each @xmath98 for @xmath152 remains within an interval of size @xmath153 for @xmath154 .",
    "define @xmath155 ( taking the lowest index if this is satisfied by more than one index ) .",
    "now , for all @xmath156 such that @xmath157 , and for all @xmath158 , we have : @xmath159 which implies that @xmath69 will not change for @xmath154 ( recalling that @xmath160 is the threshold which must be exceeded before the pasa algorithm will update @xmath67 ) .",
    "we now proceed via an induction argument .",
    "we claim that , provided for all @xmath161 , @xmath162 and @xmath163 there exists @xmath164 , @xmath133 and @xmath165 such that @xmath166 and @xmath167 are @xmath163-fixed over @xmath161 after @xmath165 , then for all @xmath168 , @xmath169 and @xmath170 there exists @xmath171 , @xmath172 and @xmath173 such that @xmath174 and @xmath175 are @xmath170-fixed over @xmath168 after @xmath173 . the case for @xmath176 we have already shown .",
    "to see our claim holds , suppose we are given values for @xmath168 , @xmath169 and @xmath170 . first note that for any @xmath177 , @xmath178 we can find @xmath179 and @xmath180 such that , assuming @xmath166 remains fixed for all @xmath10 , @xmath181 will remain in an interval @xmath182 of size @xmath183 over @xmath168 iterations with probability at least @xmath184 after @xmath180 iterations have elapsed ( using the same argument as above regarding stochastic approximation algorithms with fixed step - sizes ) . by assumption , for any @xmath161 , @xmath162 and @xmath163 , we can find @xmath164 and @xmath165 so that @xmath166 will remain the same , and @xmath185 will remain in an interval of size @xmath162 , for @xmath161 iterations with probability at least @xmath186 in both cases , provided @xmath165 iterations have elapsed .",
    "accordingly we choose @xmath162 and @xmath183 such that @xmath187 , and we choose @xmath161 such that @xmath188 .",
    "hence @xmath189 will remain the same , and @xmath190 will remain in an interval of size @xmath169 , over @xmath168 iterations both with probability at least @xmath191 after @xmath192 iterations have elapsed . for any @xmath170 we can choose @xmath163 and @xmath193 so that @xmath194 , and so our claim holds .",
    "hence we can choose @xmath114 and @xmath120 such that the vector @xmath67 becomes @xmath118-fixed over @xmath119 after @xmath120 , and so the same holds for @xmath128 .",
    "we have taken care to allow the vector @xmath114 to remain fixed as a function of @xmath10 . in practical applications , fixed step - sizes",
    "will allow an agent to continue to adapt in response to , for example , changes in the environment , and we use fixed step - sizes in our experiments below .",
    "whilst in our experiments in section [ simulation ] we use only a single step - size parameter ( as opposed to a vector ) , the details of the proof point to why there may be merit in using a vector of step - size parameters as part of a more sophisticated implementation of the ideas underlying pasa ( i.e. allowing @xmath115 to take on larger values for larger values of the index @xmath47 , for @xmath195 , may allow the algorithm to converge more rapidly ) .",
    "we now set out our main theoretical results .",
    "the key idea is that , in many important circumstances , when following a fixed policy an agent will have a tendency to spend nearly all of its time in only a small subset of the state space .",
    "we can use this property to our advantage .",
    "it means that by focussing on this small area ( which is what pasa does ) we can eliminate most of the terms which significantly contribute to the expected squared vf error .",
    "the trick will be to quantify this tendency .",
    "the fact that we have adopted a cell splitting approach will be of critical importance , because it easily permits us to create cells which contain only a single state ( allowing us to estimate the vf restricted to single state - action pairs with complete accuracy ) .",
    "we must make the following assumptions : ( 1 ) @xmath22 is `` close to '' deterministic , i.e. @xmath22 , interpreted as an operator with three arguments , can expressed as follows : @xmath196 , where @xmath197 is a deterministic transition function and @xmath198 is an arbitrary transition function , and where @xmath199 is small ( what constitutes `` small '' will be made clearer below ) , ( 2 ) @xmath22 has a uniform _ prior _ distribution , in the sense that , according to our prior distribution for @xmath22 , the random vector @xmath200 is independently distributed for all @xmath21 and each random variable @xmath25 is identically distributed for all @xmath201 , and ( 3 ) @xmath15 is also `` close to '' deterministic ( i.e. the probability of taking an _ off - policy _ action is no greater than @xmath199 , where an _ on - policy _ action is the action with the highest probability for a given state , and all other actions are off - policy ) .    momentarily putting aside these assumptions",
    ", we can make the following observation .",
    "if @xmath15 and @xmath22 are deterministic , and we pick a starting state @xmath202 , then the agent will create a path through the state space and will eventually revisit a previously visited state , and will then enter a cycle .",
    "call the set of states in this path ( including the cycle ) @xmath203 and call the set of states in the cycle @xmath204 .",
    "denote as @xmath205 and @xmath206 the number of states in the path ( including the cycle ) and the cycle respectively .",
    "of course @xmath207 .",
    "if we now place the agent in a state @xmath208 ( arbitrarily chosen ) it will either create a new cycle or it will terminate on the path or cycle created from @xmath202 . call @xmath209 and @xmath210 the states in the second path and cycle ( and @xmath211 and @xmath212 the respective numbers of states , noting that @xmath213 is possible if the new path terminates on @xmath203 , and in fact that @xmath214 is also possible , if @xmath215 ) .",
    "if we continue in this manner we will have @xmath0 sets @xmath216 .",
    "call @xmath217 the union of these sets , denote as @xmath218 the number of states in @xmath217 , and call @xmath219 the number of sets @xmath220 which are not empty .",
    "we denote as @xmath165 the event that the @xmath72th path created in such a manner terminates on itself , and note that , if this does not occur , then @xmath221 . in the discussion which follows ,",
    "until stated otherwise , we assume that ( 2 ) holds .",
    "[ moments ] @xmath222 and @xmath223 .",
    "choose any state @xmath202 .",
    "we must have : @xmath224    this means that , for large @xmath0 , the expected value of @xmath206 ( over the prior distribution for @xmath22 ) can be approximately expressed , making use of stirling s approximation @xmath225 , as : @xmath226    we have also used the fact that a poisson distribution with parameter @xmath0 will , as @xmath0 becomes sufficiently large , be well approximated by a normal distribution with mean @xmath0 and standard deviation @xmath227 .",
    "hence we can replace the first and second sum in the third equality by the second and first raw moment respectively of a half normal distribution with variance @xmath0 .",
    "( the error associated with the stirling approximation is less than order @xmath68 . )    similarly for the variance , we first calculate the expectation of @xmath228 : @xmath229    as a result : @xmath230    note that the expectation can also be derived from the solution to the `` birthday problem '' : the solution to the birthday problem gives the expectation of @xmath205 , and since each cycle length ( less than or equal to @xmath205 ) has equal probability when conditioned on this total path length , we can divide the average by @xmath231 .",
    "[ genmoments ] @xmath232 and @xmath233 .",
    "we will have : @xmath234    and for the variance : @xmath235 where we have used the fact that the covariance term must be negative for any pair of lengths @xmath236 and @xmath237 , since if @xmath236 is greater than its mean the expected length of @xmath237 must decrease , and vice versa .",
    "supposing that @xmath15 and @xmath22 are no longer deterministic then we can still define the sets @xmath238 and @xmath220 for @xmath15 and @xmath22 by considering the _ most probable _ action and the _ most probable _ transition . indeed , if ( 1 ) and ( 3 ) hold , we can set @xmath199 sufficiently low so that the agent will spend an arbitrarily large proportion of its time in @xmath217 . note that if @xmath22 is deterministic , the transition matrix generated by @xmath15 and @xmath22 is not guaranteed to be irreducible or aperiodic , in which case @xmath50 may not exist .",
    "this is just a technicality , as a state distribution which is periodic but still restricted to a small number of states does not violate any of our conclusions .    the pasa algorithm ,",
    "provided @xmath1 is large enough and provided a subset of the state space has sufficiently high probability and is sufficiently small , will be such that the majority of states with high probability will be represented individually in the final set of basis functions .",
    "we can now use this fact , in conjunction with the results we ve generated above regarding the distribution of @xmath50 , to demonstrate that pasa will generate a set of basis functions which will be such that the resulting estimate @xmath239 will have an arbitrarily low error @xmath52 .",
    "[ error ] for all @xmath137 and @xmath240 , there is sufficiently large @xmath0 and sufficiently small @xmath199 such that pasa in conjunction with a suitable rl algorithm will  provided @xmath241 for some @xmath242  generate , with probability no less than @xmath142 , a vf estimate with @xmath243 .    using chebyshev s inequality , and lemmas [ moments ] and [ genmoments ] , for any @xmath242 we can choose @xmath0",
    "sufficiently high so that @xmath244 with probability no greater than @xmath144 . to see this , take @xmath245 , @xmath246 and @xmath247 .",
    "we have : @xmath248 where in the first and second inequalities we assume @xmath0 is sufficiently large so that all but the highest order terms in lemma [ genmoments ] can be ignored .",
    "since @xmath17 is bounded and @xmath249 then for any @xmath127 and @xmath0 we can also choose @xmath199 so that @xmath52 summed only over states not in @xmath217 is no greater than @xmath250 .",
    "we choose @xmath199 so that this is satisfied , but also so that @xmath251 for all elements of @xmath252 .",
    "this is possible since each such @xmath58 will be bounded from below for all @xmath253 .",
    "now provided that @xmath254 then each state in @xmath217 will eventually be in its own cell .",
    "the rl algorithm will have no error for each such state so @xmath52 will be no greater than @xmath250 .",
    "we can prove in almost identical fashion that , under the same assumptions , both ( i ) mse _ and _ ( ii ) @xmath52 redefined so that all actions are weighted equally , i.e. equation ( [ mseapprox ] ) with the factor @xmath15 removed , will similarly be arbitrarily close to zero with arbitrarily high probability .",
    "the bound on @xmath1 provided represents a significant reduction in complexity when @xmath0 starts to take on a size comparable to many real world problems , and could make the difference between a problem being tractable and intractable .",
    "it also seems likely that the bound on @xmath1 in theorem [ error ] can be improved upon ( see the discussion in section [ simulation ] ) .",
    "conditions ( 1 ) and ( 3 ) are commonly encountered in practice , in particular ( 3 ) which can be taken to reflect a `` greedy '' policy .",
    "condition ( 2 ) can be interpreted as the transition function being `` completely unknown '' ( and can be generalised somewhat , see below ) .",
    "we might ask what happens when @xmath15 is no longer generated randomly , but rather , for example , according to a process of policy iteration .",
    "it is intuitively plausible that this should typically have the effect of reducing @xmath255 .",
    "we will not offer a general proof .",
    "however note that , if for example @xmath256 states have reward of one , for @xmath257 , and all other states have reward of zero , the agent must determine a shorter path on average than a random path between each pair of such states ( otherwise its performance will be no better than a random policy ) .",
    "denote as @xmath258 the average path length between reward states determined by an agent which is updating its policy so as to increase reward . by the reasoning we ve just stated @xmath258 will not increase above a bounded value as @xmath0 increases .",
    "we can then apply the same reasoning as the random policy case to conclude that at most @xmath259 such states will be visited under such a policy on average , and that @xmath260 .    on a final related note , _ fixed _ state aggregation will _ also _ tend to have zero error if @xmath261 and all our other assumptions continue to hold .",
    "this is because the probability of more than one state falling into a cell tends to zero if the number of cells grows at a faster rate than the size of @xmath217 .",
    "of course the probability of all states falling into a unique cell increases much more slowly than is true for pasa as @xmath0 is increased .",
    "alterations can be made to the pasa algorithm ( with no impact on computational complexity ) that can remove the @xmath262 factor in theorem [ error ] .",
    "however such an alternative algorithm is more complex to describe and unlikely to perform noticeably better in a practical setting .",
    "there is some scope to extend our results beyond uniform transition function priors .",
    "some knowledge about the value of @xmath22 ( i.e. a non - uniform prior ) can have important implications for our results .",
    "if we know , for example , that @xmath263 for all @xmath264 and all @xmath37 , and @xmath265 for all @xmath37 , then @xmath266 , and lemma [ moments ] clearly does nt hold .",
    "there are , however , more general sets of priors for which the results will hold .",
    "our interest is in how the prior influences the values of the moments which we calculated ( for uniform priors ) in lemmas [ moments ] and [ genmoments ] .",
    "we again assume a deterministic transition function , and a fixed deterministic policy @xmath15 .",
    "in our discussion around uniform priors , we were also able to assume that the sequence of states @xmath267 used to generate the sets @xmath268 were selected arbitrarily . in a more general",
    "setting we may need to assume that this sequence is generated according to some specific probability distribution . since , in the discussion below , we will generally assume that the prior distribution of the transition probabilities is identical for different actions",
    ", we will be able to continue to assume that @xmath15 is arbitrary . at the expense of imposing heavier constraints on @xmath15 . ]    appealing to techniques which make use of the notion of schur convexity ( marshall et al 2011 ) , it s possible to show that , if the random vector @xmath200 is independently distributed for all @xmath21 , and @xmath269 for all @xmath270 , then , given an arbitrary policy @xmath15 , and assuming the sequence of starting states @xmath267 are distributed uniformly at random , @xmath271 and @xmath272 are minimised where the prior for @xmath22 is uniform . using this fact , theorem [ error ] can be extended to such priors ( we omit the details , though the proof uses arguments substantially equivalent to those used in theorem [ error ] ) . if we continue to assume an arbitrary policy and that the starting states are selected uniformly at random , we can consider a yet more general class of priors , using a result from karlin and rinott ( 1984 ) . their result can be used to demonstrate that , of the set of priors which satisfy the following three conditions  ( i ) that @xmath273 for all @xmath274 , ( ii ) that : @xmath275 for all @xmath276 , and ( iii ) the random vector @xmath200 is independently distributed for all @xmath21  the uniform prior will again maximise the values @xmath271 and @xmath272 . since @xmath277 , an equivalent result to theorem [ error ] ( though not necessarily with the same constant @xmath278 ) can similarly be obtained for this even larger set of priors ( we again omit the details and note that the arguments are substantially equivalent to those in theorem [ error ] ) .",
    "both these results assume a degree of similarity in the transition prior probabilities for each state .",
    "a perhaps more interesting potential generalisation is as follows .",
    "we can define a _ balanced _",
    "prior for a deterministic transition function @xmath22 as any prior such that the random vector @xmath200 is independently distributed for all @xmath21 , and we have @xmath273 , @xmath279 and @xmath280 for all @xmath274 .",
    "in essence , the prior probability of transitioning from state @xmath11 to @xmath23 is the same as transitioning in the reverse direction from @xmath23 to @xmath11 .",
    "this sort of prior would be reflective of many real world problems which incorporate some notion of a geometric space with distances , such as navigating around a grid  and as such represents an important generalisation .",
    "the difference to the uniform prior is that we now have an expectation that some states will be `` close '' to one - another , and other states will be further apart .",
    "however similar to the uniform prior there is no inherent `` flow '' creating cycles which have larger expected value than @xmath218 in the uniform case .",
    "it is not hard to conceive of examples where @xmath281 may be significantly reduced for a particular balanced prior compared to the uniform case .",
    "it would furthermore appear plausible that , amongst the set of all balanced priors , @xmath271 would be maximised for the uniform prior .",
    "indeed investigation using numerical optimisation techniques demonstrates this is the case for @xmath282 , even when a fixed arbitrary starting state is selected relative to the balanced set of transition probabilities .",
    "the techniques used for the generalisations stated above can not be used to prove a similar result for balanced priors .",
    "is maximised for all @xmath47 by a uniform prior , from which our conclusions regarding the moments follow . in the case of balanced priors",
    "such a strong result does not hold , which can be seen by , for large @xmath0 , and taking @xmath283 , comparing a uniform prior to a prior where all transitions outside of a single fixed cycle covering all @xmath0 states have probability zero , and where the prior probability of a transition in either direction along this cycle is @xmath284 .",
    "] we conjecture , based on our numerical analysis , that the uniform prior does maximise @xmath271 for all @xmath0 , which would carry the implication , since @xmath285 , that lemma [ moments ] can be used to argue @xmath286 and @xmath287 .",
    "even if this conjecture holds , we can not extend theorem [ error ] to balanced priors , which we can see with a simple example .",
    "set @xmath288 for all @xmath21 where @xmath118 is small .",
    "provided that the transition matrix associated with @xmath15 and @xmath22 is irreducible , then @xmath289 for all @xmath0 .",
    "notwithstanding that a formal result equivalent to theorem [ error ] is unavailable for balanced priors , by selecting suitable parameter values we should still be able to exploit the apparent tendency of the agent to spend a majority of the time in a small subset of the state space .",
    "the main difference is that this small subset may change slowly over time .",
    "the situation may become further altered in our favour once policy iteration is introduced , and policies are no longer random but rather target states with reward .",
    "our experimental results focus on transition functions drawn from a uniform distribution , however further research could help indicate the extent to which pasa can generate a vf estimate with low error , subject to the slightly altered dynamics introduced by balanced priors .",
    "our main objectives in this section are to : ( a ) test empirically the tendency for an agent to spend the majority of its time in a small subset of the state space , and ( b ) conduct an experimental comparison of pasa to fixed state aggregation , to demonstrate that , on average , pasa will help generate vf estimates with lower mse ( and therefore that the theoretical advantages to unsupervised basis function adaptation can be realised in a practical setting ) .      whilst the bound we placed on @xmath1 in theorem [ error ]",
    "may be of help when @xmath0 is very large , note that if we set @xmath290 ( i.e. such that we have a fifty per cent chance of being guaranteed to be able to represent every high probability state ) , then we will have @xmath291 up until the point where @xmath292 .",
    "it appears likely that the bound in theorem [ error ] is a loose bound .",
    "we conduct some simple experiments to examine how @xmath218 behaves , in particular for lower values of @xmath0 .    in figure [ empiricalc ]",
    "we report on the outcome of a sequence of @xmath293 independent trials where @xmath218 was calculated explicitly , in order to test our theoretical bounds .",
    "the results demonstrate that the estimates for @xmath281 and @xmath294 are accurate , but that the bound in lemma [ genmoments ] is ( perhaps not surprisingly ) generous . in figure [ empiricalc ]",
    "we have also run equivalent tests on a square grid world environment for all @xmath72 and @xmath37 ( the agent is forced to move in one of four directions : up , down , left or right ) .",
    "this violates the exact balanced definition , however would only serve to increase @xmath295 . ]",
    "( we have used @xmath296 , @xmath297 and @xmath298 to distinguish these values from those obtained for the uniform prior ) .",
    "this helps to reinforce the discussion around balanced transition function priors ( we can see that @xmath299 is very small compared to the uniform case , and may in fact be bounded as a function of @xmath0 , however that @xmath300 , and therefore the value @xmath298 , appears to increase linearly as a function of @xmath0 ) .    [ cols=\"^,^ \" , ]     we can also examine the empirical distribution of @xmath50 given a sample trajectory , to see the extent to which our section [ theoretic ] assumptions do indeed result in only a few states having high probability .",
    "this is worth exploring since the value of @xmath199 strictly required by theorem [ error ] may be too low to be realistic in practice ( i.e. , given a too - large value for @xmath199 , we might expect to see the stationary distribution `` leak '' to include states outside @xmath217 ) .",
    "assume that the agent follows an @xmath301-greedy policy .",
    "we define : @xmath302    hence @xmath303 is the minimum number of states required to amass a proportion @xmath304 $ ] of the total probability of the stationary state distribution ( as @xmath305 approaches @xmath68 and @xmath199 approaches @xmath306 , the value can be considered as a rough experimental equivalent of @xmath218 ) . figure [ empiricalm ] demonstrates that , when @xmath301 is held constant as @xmath0 is increased , we start to see what appears to be a linear increase in @xmath303 as a function of @xmath0 .",
    "it seems likely that this is because of leakage into states outside @xmath218 .",
    "as @xmath307 becomes smaller and @xmath301 remains the same , this leakage will become more pronounced . whilst this does nt invalidate any of the underlying principles , in a practical setting it",
    "is something to remain aware of . even where @xmath301 is reasonably high , e.g. @xmath308 , and where we require a high value of @xmath305 , e.g. @xmath309",
    ", only a reasonably small number of states is required to obtain a total probability of @xmath305 , e.g. around @xmath310% of states for @xmath311 , implying that in general we can set @xmath1 comparatively low .",
    "the implication of these results is that we expect we should be able to use pasa to effectively reduce error in the vf estimate in a practical setting ( including where @xmath0 is low , for example less than @xmath293 ) .",
    "this is what we next investigate . as a final comment , whilst we need @xmath312 to theoretically guarantee capturing every high - probability state individually , the factor of @xmath313 is not likely to be essential in a practical setting ( as it covers the worst case scenario in terms of how the high - probability states are arranged ) .",
    "we have run a series of experiments to test the performance of pasa compared with simple fixed state aggregation . before stating the results it will be helpful to make some comments first .",
    "if @xmath113 approaches @xmath68 and @xmath199 is too large as a function of @xmath113 , then we will find that all values @xmath314 will approach the same value , for any reward function @xmath17 .",
    "this is because the discounted reward is heavily weighted into the future , and due to randomness in the agent s trajectory , future reward will not be heavily impacted by each individual decision .",
    "hence , under such conditions , both mse and @xmath52 for fixed state aggregation will _ also _ tend towards arbitrarily low values . furthermore ,",
    "if , given a state aggregation architecture , the number of high probability states in each cell is large , then the average value for each state - action over each cell will also approach the same value ( this is due to the law of large numbers ) .",
    "the second point is important when calculating @xmath52 , since if @xmath43 is such that all cells are large ( and particularly if @xmath113 is close to @xmath68 ) then each estimate @xmath315 will tend to a single mean value , and @xmath52 will take on a low value ( even if mse is high , and the vf estimate is poor ) .    for these reasons",
    ", we have taken care not to set @xmath113 too close to @xmath68 ( keeping in mind the value of @xmath199 ) , and we have used mse to compare pasa to fixed state aggregation . since mse is a more accurate measure , this will only serve to strengthen the results .",
    "the only downside is that , since an exact vf estimate is impossible to calculate for large @xmath0 , we can only perform our comparison for relatively low values of @xmath0 .",
    "we then use our theoretical insights to infer that similar performance differences will exist for large @xmath0 . in all cases",
    "we have reported the square root of the mse ( as this provides a less distorted comparison ) .",
    "the two algorithms we will be comparing are pasa combined with a sarsa which we then weighted by the inverse of the probability of the action selected . such normalisation is not strictly necessary , however it allows the vf estimate for infrequently selected actions to converge more quickly .",
    "the random policy @xmath15 was chosen such that the same action @xmath13 is the `` preferred '' action ( the action taken with probability @xmath316 ) for all states in each particular cell . ]",
    "rl algorithm , and a sarsa rl algorithm with fixed state aggregation , where the cells are sized as equally as possible .",
    "it can be shown that sarsa will generate a vf estimate with minimal mse given a fixed policy and a fixed linear approximation architecture ( bertsekas and tsitsiklis 1996 ) .",
    "we have tested both algorithms with sequences of randomly generated environments ( where @xmath22 is deterministic and with a uniform prior , the prior for @xmath17 is such that the reward for each state - action pair has an independent standard normal distribution , and @xmath15 is @xmath301-greedy ) , and then estimated ( by sampling ) the mse of the estimate vf generated by the rl algorithm .    for each algorithm we ran eight separate experiments , for @xmath0 set at @xmath317 , @xmath318 , @xmath319 and @xmath293 , and for @xmath320 and @xmath321 , for @xmath322 randomly generated trials each .",
    "the running time was slightly less than seven hours for a single trial on an intel(r ) xeon(r ) cpu e5 - 4650 0 @ 2.70ghz for both algorithm variants , although this includes the time to calculate beforehand an exact solution ( to allow for mse to be calculated ) .",
    "] in all cases both algorithms were tested against an identical set of environments . for each value of @xmath0 listed above",
    "we set @xmath1 equal to @xmath8 , @xmath322 , @xmath323 and @xmath324 respectively ( and @xmath64 equal to @xmath325 , @xmath326 , @xmath327 and @xmath328 ) , guided in part by figure [ empiricalm ] and the other comments above ( but also in part heuristically ) .",
    "to approximately half @xmath1 appears to be a reliable way of ensuring that a large number of high probability states fall into a singleton cell .",
    "smaller values of @xmath64 tend to exhaust many cells in seeking to isolate ( into smaller and smaller cells ) one or two individual states , whereas greater values of @xmath64 may mean that pasa has too little control over the final set of basis functions . ]",
    "the results of these experiments are shown in table [ resultstable ] ( and figure [ timeseries ] for @xmath320 ) .",
    "the values of other parameters used were as follows : @xmath329 , @xmath330 , @xmath331 , @xmath332 and @xmath333 .    with respect to sampling the mse",
    ", we compared the vf estimate @xmath239 for each state visited to the exact @xmath26 for the policy @xmath15 , which for each experiment was calculated in advance exactly by solving the system of equations involving @xmath32 using least squares .",
    "quite a large number of iterations were used in each trial ( @xmath318 million ) .",
    "this was in part to accommodate the most complex environment ( @xmath334 ) , and also to provide clear evidence that the estimates have stabilised .",
    "such long trials are not necessary to see a significant difference between the two algorithms ( see figure [ timeseries ] ) . minimising the number of iterations required to see",
    "a strong difference between pasa and fixed state aggregation would depend on optimising parameters like @xmath160 , @xmath301 and @xmath114 subject to the choices for @xmath113 and @xmath0 .",
    "p1.3cmp0.9cmp0.4cmlllllll experiment & @xmath0 & @xmath1 & & & + & & & @xmath335 & @xmath336 & @xmath335 & @xmath336 & @xmath335 & @xmath336 + @xmath68 & * 250 * & @xmath8 & @xmath337 & @xmath338 & @xmath339 & @xmath340 & * 67.7% * & * 56.9*% + @xmath231 & * 500 * & @xmath322 & @xmath341 & @xmath342 & @xmath343 & @xmath344 & * 63.2% * & * 55.6*% + @xmath345 & * 750 * & @xmath323 & @xmath346 & @xmath347 & @xmath343 & @xmath348 & * 59.4% * & * 45.8*% + @xmath349 & * 1,000 * & @xmath324 & @xmath350 & @xmath351 & @xmath352 & @xmath353 & * 55.9% * & * 42.4*%",
    "+    we take the average mse over the last fifth of each trial .      since the theoretic results assume , for example , that @xmath114 and @xmath301 can be made arbitrarily low , in a practical setting we wo nt see mse falling to zero",
    ". however table [ resultstable ] demonstrates that , at a low computational cost , we are able to significantly reduce mse from the fixed state aggregation case .",
    "the table shows us that for @xmath320 error can be reduced by around @xmath7 to @xmath354 per cent , and for the less complex case of @xmath321 by as much as approximately @xmath326 to @xmath8 per cent .",
    "as noted above , the effect of pasa becomes slightly less pronounced as @xmath113 approaches @xmath68 ( in particular if @xmath301 is comparatively large ) .",
    "figure [ timeseries ] shows that , as @xmath0 increases , pasa can make the algorithm take slightly longer to generate a vf with low mse ( which might be expected since the pasa component needs time to converge ) , however in the longer term mse is significantly reduced .",
    "optimising parameters such as @xmath114 , @xmath301 or even the value of @xmath1 ( which we ve set well below the bound in section [ theoretic ] ) might be expected to further increase the disparity between pasa and fixed state aggregation ( the latter can not be improved since it has no parameters to adjust outside the underlying rl algorithm ) .",
    "as we noted in the introduction , whilst basis function adaptation methods have been the subject of a large amount of research recently , unsupervised methods have not received much attention ( compared to methods which seek to estimate vf error explicitly ) .",
    "this may be an oversight .",
    "as we have seen there are many circumstances reflecting real - world problems where unsupervised methods can be very effective in creating an approximation architecture , and thereby help to generate more accurate vf estimates ( both in theory and in practice ) .",
    "what distinguishes unsupervised methods from more complex alternatives , however , is their simplicity . as we have seen , an algorithm such as pasa carries only minimal additional costs ( both in terms of sampling and computational demands ) compared to the rl algorithm which it supports .",
    "it is their effectiveness combined with their low cost which , in our view , make such techniques a promising candidate for further research .    in the setting of policy improvement the advantages offered by unsupervised methods have the potential to be particularly important .",
    "each policy update requires a vf estimate ( where the vf estimate is based on the current policy ) however each policy update will change the vf ( perhaps significantly ) , requiring a new estimate .",
    "so accurately and _ efficiently _ estimating @xmath26 for each new policy @xmath15 is critical .",
    "some initial experimentation suggests that the pasa algorithm can have a significant impact on rl algorithm performance where policy updates are introduced .",
    "this should perhaps not come as a surprise given the reduced error in @xmath239 shown in section [ simulation ] .",
    "the pasa algorithm represents only a relatively naive or simplistic application of the idea of unsupervised basis function adaptation ( i.e. the idea of using visit frequency to guide which parts of the vf to represent in more detail ) .",
    "it appears likely that a number of improvements could be made to the algorithm in order to further optimise its performance .",
    "is binomially distributed , and this number will have low variance if @xmath64 is substantially lower than @xmath255 , it seems likely that , in choosing a cell to split , we could initially only consider a subset of the set of all available cells .",
    "this would potentially allow pasa to converge more quickly , and be less likely to change as a result of random fluctuation in the value of @xmath75 . ]    from a theoretical perspective the assumption around scoring functions being weighted by @xmath50 is crucial .",
    "the nature of the vf estimate generated by pasa and its associated rl algorithm is that the vf will be well estimated for states which are frequently visited under the existing policy .",
    "however this results in poorer estimates of the value of deviating from the current policy .",
    "thus , even though the expected vf error may be low , it does not immediately follow that an algorithm can use this to optimise its policy via standard policy iteration ( since the consequences of deviating from the current policy are less clearly represented ) .",
    "ultimately , however , the theoretical implications of the improved vf estimate in the context of policy iteration are complex , and would need to be the subject of further research ."
  ],
  "abstract_text": [
    "<S> when using reinforcement learning ( rl ) algorithms to evaluate a policy it is common , given a large state space , to introduce some form of approximation architecture for the value function ( vf ) . </S>",
    "<S> the exact form of this architecture can have a significant effect on the accuracy of the vf estimate , however , and determining a suitable approximation architecture can often be a highly complex task . consequently there is a large amount of interest in the potential for allowing rl algorithms to adaptively generate ( i.e. to learn ) approximation architectures .    </S>",
    "<S> we investigate a method of adapting approximation architectures which uses feedback regarding the frequency with which an agent has visited certain states to guide which areas of the state space to approximate with greater detail . </S>",
    "<S> we introduce an algorithm based upon this idea which adapts a state aggregation approximation architecture on - line .    assuming @xmath0 states , we demonstrate theoretically that  provided the following relatively non - restrictive assumptions are satisfied : ( a ) the number of cells @xmath1 in the state aggregation architecture is of order @xmath2 or greater , ( b ) the policy and transition function are close to deterministic , and ( c ) the prior for the transition function is uniformly distributed  </S>",
    "<S> our algorithm can guarantee , assuming we use an appropriate scoring function to measure vf error , error which is arbitrarily close to zero as @xmath0 becomes large . </S>",
    "<S> it is able to do this despite having only @xmath3 space complexity ( and negligible time complexity ) . </S>",
    "<S> we conclude by generating a set of empirical results which support the theoretical results .    </S>",
    "<S> example.eps gsave newpath 20 20 moveto 20 220 lineto 220 220 lineto 220 20 lineto closepath 2 setlinewidth gsave .4 setgray fill grestore stroke grestore </S>"
  ]
}