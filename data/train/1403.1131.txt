{
  "article_text": [
    "strategic interactions among individuals located on a network , be it geographical , social or of any other nature , are becoming increasingly relevant in many economic contexts . decisions made by our neighbors on the network influence ours , and",
    "are in turn influenced by their other neighbors to whom we may or may not be connected .",
    "such a framework makes finding the best strategy a very complex problem , almost always plagued by a very large multiplicity of equilibria .",
    "therefore , many researchers are devoting much effort to this problem and an increasing body of knowledge is being consolidated @xcite .    in this work",
    "we will address the issue of games of strategic substitutes and strategic complements on networks , as discussed in @xcite . in this paper , galeotti et al .",
    "considered these two types of games on a general class of networks and obtained an important reduction in the number of equilibria by going from a complete information setting to an incomplete one .",
    "they introduced incomplete information to eliminate the possible dependence of the setting in a natural way , which is having uncertainty about the identity of players neighbors , and being also uncertain about the number of connections that those neighbors will in turn have .",
    "we here aim at providing an alternative view of this problem by looking at it from a evolutionary viewpoint : focusing on two specific examples of these families of games , we implement two different dynamics for the strategies which , as we will see , may lead to different refinements of the equilibrium set .",
    "we begin with a finite set of agents @xmath0 of cardinality @xmath1 , linked together in a fixed , undirected , exogenous network .",
    "the links between agents reflect social interactions , and connected agents are said to be `` neighbors '' .",
    "the network is defined through a @xmath2 symmetric matrix @xmath3 with null diagonal , where @xmath4 means that agents @xmath5 and @xmath6 are neighbors , while @xmath7 means that they are not .",
    "we indicate with @xmath8 the set of @xmath5 s neighbors , _",
    "i.e. _ , @xmath9 , where the number of such neighbors @xmath10 is the _ degree _ of the node . each player can take one of two actions , @xmath11 with @xmath12 denoting @xmath5 s action .",
    "only pure strategies will be considered .",
    "there is a cost @xmath13 , where @xmath14 , for choosing action @xmath15 , while action @xmath16 bears no cost .    in what follows",
    "we will concentrate on two games , the best - shot game and a coordination game , as representative instances of strategic substitutes and strategic complements , respectively .",
    "we choose specific examples for the sake of being able to study analytically their dynamics . in both cases ,",
    "we consider a game in which every individual must choose independently an action in @xmath17 , in a context ( particularly for the case of substitutes ) where action 1 may be interpreted as _ cooperating _ and action 0 as not doing so  or _",
    "defecting_. to define the payoffs we introduce the following notation : @xmath18 is the aggregate action in @xmath8 and @xmath19 .",
    "[ [ strategic - substitutes - best - shot - game ] ] strategic substitutes : best - shot game + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    this game was first considered by bramoull and kranton @xcite as a model of the local provision of a public good . as stated above",
    ", we will consider the discrete version , where there are only two actions available , as in @xcite . the corresponding payoff function takes the form @xmath20 where @xmath21 is the heaviside step function @xmath22 if @xmath23 and @xmath24 otherwise .",
    "[ [ strategic - complements - coordination - game ] ] strategic complements : coordination game + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    for our second example , we will follow galeotti _ et al",
    ". _ @xcite and consider again a situation where @xmath25 is the action space , but now let the payoffs of any particular agent @xmath5 be given by @xmath26 assuming that @xmath27 , we are faced with a coordination game where , as discussed in @xcite , depending on the underlying network and the information conditions , there can generally be multiple equilibria .      within the two games we have presented above",
    ", we now consider evolutionary dynamics for the players strategies . starting with a certain fraction @xmath28 of players randomly chosen to undertake action @xmath29 , at each round",
    "@xmath30 of the game players collect their payoff @xmath31 according to their neighbors actions and the kind of game under consideration .",
    "subsequently , a fraction @xmath32 of players update their strategy .",
    "we will focus on the two games we have introduced above , but of course the evolutionary dynamics we are going to introduce are applicable to any game .",
    "we consider two different mechanisms for strategy updating :    [ [ proportional - imitation ] ] proportional imitation + + + + + + + + + + + + + + + + + + + + + +    ( pi ) @xcite .",
    "it represents a rule of imitative nature in which player @xmath5 may copy the strategy of a selected counterpart @xmath6 , which is chosen randomly among the @xmath33 neighbors of @xmath5 .",
    "the probability that @xmath5 copies @xmath6 s strategy depends on the difference between the payoffs that they obtained in the previous round of the game : @xmath34 where @xmath35 is a normalization constant that ensures @xmath36 $ ] , and @xmath37 allows for mistakes ( _ i.e. _ , copying an action that yielded less payoff in the previous round ) . note that because of the imitation mechanism of pi , the configurations @xmath38 @xmath39 and @xmath40 @xmath39 are absorbing states : the system can not escape from them and not even mistakes can re - introduce strategies , as they always involve imitation . on the other hand",
    ", it can be shown that pi is equivalent to the well - known replicator dynamics in the limit of an infinitely large , well - mixed population ( equivalently , on a complete graph ) @xcite . as was first put by schlag @xcite , the assumption that agents play a random - matching game in a large population and learn the actual payoff of another randomly chosen agent , along with a rule of action that increases their expected payoff , leads to a probability of switching to the other agent s strategy that is proportional to the difference in payoffs .",
    "the corresponding aggregate dynamics is like the replicator dynamics .",
    "see also @xcite for another interpretation of these dynamics in terms of learning .",
    "[ [ best - response ] ] best response + + + + + + + + + + + + +    ( br ) .",
    "this rule was introduced in @xcite and has been widely used in the economics literature .",
    "br describes players that are rational and choose their strategy ( myopically ) in order to maximize their payoff , assuming that their neighbors will again do what they did in the last round .",
    "this means that each player @xmath5 , given the past actions of their partners @xmath41 , computes the payoffs that she would obtain by choosing action 1 ( cooperating ) or 0 ( defecting ) at time @xmath30 , respectively @xmath42 and @xmath43 .",
    "then actions are updated as follows : @xmath44 and @xmath45 if @xmath46 . here",
    "again @xmath37 represents the probability of making a mistake , with @xmath47 indicating fully rational players .",
    "the reason to study these two dynamics is because they may lead to different results as they represent very different evolutions of the players strategies . in this respect ,",
    "it is important to mention that , in the case @xmath47 , nash equilibria are stable by definition under br dynamics and , vice - versa , any stationary state found by br is necessarily a nash equilibrium . on the contrary , with pi",
    "this is not always true : even in the absence of mistakes , players can change action by copying better - performing neighbors , also if such change leads to a decreasing of their payoffs in the next round .",
    "another difference between the two dynamics is the amount of cognitive capability they assume for the players : whereas pi refers to agents with very limited rationality , that imitate a randomly chosen neighbor on the only condition that she does better , br requires agents with a much more developed analytic ability .      with these two dynamics ,",
    "we study how the system evolves starting from an initial random distribution of strategies .",
    "we carry out our calculations in the framework of a homogeneous mean field ( mf ) approximation , which is most appropriate to study networks with homogeneous degree distribution @xmath48 like erds - rnyi random graphs @xcite .",
    "it is interesting to note that the basic assumption underlying this approach is that every player interacts with an `` average player '' that represents the actions of her neighbors .",
    "lossely speaking , this amounts to having a very incomplete information setting , in which all players know only how many other players they will engage with , and is reminiscent of that used by galeotti _",
    "et al . _ for their refinement of equilibria .",
    "however , the analogy is not perfect and therefore , for the sake of accuracy , we will not dwell any further on the matter . in any case , mf will be our setup for most of the paper .    as an extension of the results obtained in the above context , we will also study the case of highly heterogeneous networks , _",
    "i.e , _ , networks with broad degree distribution @xmath48 , such as the scale - free ones proposed in @xcite . in these cases in fact",
    "there are a number of players with many neighbors ( `` hubs '' ) and many players with only a few neighbors , and this heterogeneity may give rise to very different behaviors as compared to erds - rnyi systems . analytically , this can be done by means of the heterogeneous mean field technique ( hmf )  @xcite which generalizes , for the case of networks with arbitrary degree distribution , the equations describing the dynamical process by considering degree - block variables grouping nodes within the same degree . by resorting to this second perspective we will be able to gain insights on the effects of heterogeneity on the evolutionary dynamics of our games .",
    "as already stated , our paper belongs to the literature on strategic interactions in networks and its applications to economics .",
    "relevant papers on this topic have been contributed by angeletos and pavan @xcite , ballester et al .",
    "@xcite , bergemann and morris @xcite , bramoull et al .",
    "@xcite , calv - armengol et al .",
    "@xcite , glaeser and scheinkman @xcite , goyal and moraga - gonzalez @xcite , and vives @xcite .",
    "this paper pertains in this increasing literature and complements it with the analysis of the evolutionary dynamics ( see roca et al .",
    "@xcite for a review of the literature on evolutionary games ) in two representative games and how this dynamics leads to a refinement of the nash equilibria or to other final states .",
    "in particular , our work originates from and is closely related to galeotti et al .",
    "( 2010 ) , for they consider one - shot games with strategic complements and substitutes and model equilibria resulting from incomplete information .",
    "our approach is instead based on evolutionary selection of equilibria , and is thus complementary to theirs .",
    "we have also mentioned that one of the games we study is a discrete version of a public goods game proposed by bramoull and kranton ( 2007 ) , who opened the way to the problem of equilibrium selection in this kind of games under complete information .    on the other hand",
    ", our evolutionary approach pertains to the large body of work emanating from the nash programme @xcite . in that spirit",
    ", we will be considering the two possible situations : one dynamics , pi , that does not lead in general to nash equlibria as already mentioned , and br , that does converge to nash equilibria , an issue about which there are a number of interesting results @xcite .",
    "these dynamical views on the convergence to equilibrium refer to the case of a well - mixed population . as we are working on a network setup ,",
    "our specific perspective is close to that of boncinelli and pin @xcite .",
    "they elaborate on the literature on stochastic stability @xcite as a device that selects the equilibria that are more likely to be observed in the long run , in the presence of small errors occurring with a vanishing probability .",
    "they work from the observation by bergin and lipman @xcite that different equilibria can be selected depending on assumptions on the relative likelihood of different types of errors .",
    "thus , boncinelli and pin work with a best - response dynamics and by means of a markov chain analysis find , counterintuitively , that when contributors are the most perturbed players , the selected equilibrium is the one with the highest contribution .",
    "the techniques we use here resort to differential equations and have a more dynamical character , and we do not incorporate the possibility of having special distributions of errors , although we do consider random mistakes in the evolution of strategies as discussed above .    within this topic , our main contribution can be summarized as follows . in our basic setup of homogeneous networks ( described by the mean field approximation ) : for the best - shot game , pi leads to a stationary state in which all players play @xmath40 , _ i.e. _ , to full defection , which is obviously non - nash .",
    "this is the result also in the presence of mistakes , unless the probability of errors becomes large , in which case the stationary state is the opposite , @xmath38 , _",
    "i.e. _ , full cooperation , also non - nash . hence , pi does not lead to any refinement of the nash equilibrium structure . on the contrary",
    ", br leads to nash equilibria characterized by a finite fraction of cooperators @xmath49 , whereas , in the case when players are affected by errors , this fraction coincides with the probability of making an error as the mean degree of the network goes to infinity .",
    "the picture is different for the coordination game . in this case",
    ", pi does lead to nash equilibria , selecting the coordination in 0 below a threshold value of @xmath50 and the opposite state otherwise .",
    "this threshold is found to depend on the initial fraction @xmath28 of players choosing @xmath29 .",
    "mistakes lead to the appearance of a new possibility , an intermediate value of the fraction of players choosing 1 , and as before the initial value of this fraction governs which equilibrium is selected .",
    "br gives similar results , albeit for the fact that a finite fraction of 1 actions can also be found even without mistakes , and with mistakes the equilibria are not full 0 or 1 but there is always a fraction of mistaken players .",
    "finally , changing the analytical setting by proceeding to the heterogeneous mean field approach does not lead to any dramatic change in the structure of the equilibria for the best - shot game .",
    "interestingly , things change significantly for coordination games  when played on infinitely large scale - free networks . in this case , which is the one where the heterogeneous mean field should make a difference , equilibria with non - vanishing cooperation obtain for any value of the parameter @xmath50 .",
    "the paper is organized in five sections including this introduction .",
    "section 2 presents our analysis and results for the best - shot game .",
    "section 3 deals with the coordination game . in both cases ,",
    "the analytical framework is that of the mean field technique .",
    "after an overall analysis of global welfare presented in section 4 , section 5 presents the extensions of the results for both games within the heterogeneous mean field approach , including some background on the formalism itself . section 6 concludes .",
    "we begin by considering the case of our example of strategic substitutes when imitation of a neighbor is only possible if she has obtained better payoff than the focal player , _",
    "i.e. _ , @xmath47 in eq .",
    "( [ eq.pi ] ) . in that case , within the framework of mean field , the main result is the following :    * proposition 1 .",
    "* within the mean field formalism , under pi dynamics , when @xmath47 the final state for the population is the absorbing state with a density of cooperators @xmath51 ( full defection ) except if the initial state is full cooperation @xmath52 .    _ proof",
    "_ working in a mean field context means that individuals are well - mixed , _",
    "i.e. _ , every player interacts with average players . in this case",
    "the differential equation for the density of cooperators @xmath53 is @xmath54 the first term is the probability @xmath55 of picking a defector with a neighboring cooperator , times the probability of imitation @xmath56 .",
    "the second term is the probability @xmath57 of picking a cooperator with a neighboring defector , times the probability of imitation @xmath58 . in the best shot game",
    "a defector can not copy a neighboring cooperator ( who has lower payoff by construction ) , whereas , a cooperator will eventually copy one of her neighboring defectors ( who has higher payoff ) .",
    "hence @xmath59 and @xmath58 is equal to the payoff difference @xmath60 . since the normalization constant @xmath61 for strategic substitutes , eq .",
    "( [ eq.ss_pi ] ) becomes @xmath62 the solution , for any initial condition @xmath63 , is @xmath64^{-1},\\ ] ] hence @xmath65 for @xmath66 : the only stationary state is full defection unless @xmath52 .",
    "* remark 1 : * as discussed above , pi does not necessarily lead to nash equilibria as asymptotic , stationary states .",
    "this is clear in this case . for any @xmath68",
    "the population ends up in full defection , even if every individual player would be better off by switching to cooperation .",
    "this phenomenon is likely to arise from the substitutes or anti - coordination character of the game : in a context in which it is best to do the opposite of the other players , imitation does not seem the best way for players to decide on their actions .",
    "* proposition 2 . * within the mean field formalism , under pi dynamics , when @xmath69 the final state for the population is the absorbing state @xmath51 ( full defection ) when @xmath70 , @xmath71 when @xmath72 , and @xmath73 when @xmath74 .",
    "when the initial state is @xmath75 or @xmath52 , it remains unchanged .",
    "_ eq .  ( [ eq.ss_pi ] ) is still valid , with @xmath58 unchanged , whereas , @xmath76 . by introducing the effective cost @xmath77 we can rewrite eq .",
    "( [ eq.ss_pi_sol ] ) as : @xmath78^{-1}\\ ] ] hence @xmath65 for @xmath66 only for @xmath79 ( @xmath80 ) ; instead for @xmath81 ( @xmath72 ) then @xmath82 @xmath83 , and for @xmath84 ( @xmath74 ) then @xmath85 for @xmath66 ( cooperation is favored now ) .",
    "@xmath67    * remark 2 : * as before , pi does not drive the population to a nash equlibrium , independently of the probability of making a mistake .",
    "however , mistakes do introduce a bias towards cooperation and thus a new scenario : when their probability exceeds the cost of cooperating , the whole population ends up cooperating .",
    "we now turn to the case of the best response dynamics , which ( at least for @xmath47 ) is guaranteed to drive the system towards nash equilibria . in this scenario , we have not been able to find a rigorous proof of our main result , but we can make some approximations in the equation that support it . as we will see , our main conclusion is that , within the mean field formalism under br dynamics , when @xmath47 the final state for the population is a mixed state @xmath86 , @xmath87 , for any initial condition .",
    "indeed , for br dynamics without mistakes , the homogeneous mean field equation for @xmath88 is @xmath89+(1-\\rho)\\,q[\\pi_c>\\pi_d]\\ ] ] where the first term is the probability of picking a cooperator who would do better by defecting , and the second term is the probability of picking a defector who would do better by cooperating .",
    "this far , no approximation has been made ; however , these two probabilities can not be exactly computed and we need to estimate them .    to evaluate the two probabilities , we can recall that @xmath90 always , whereas , @xmath91 when none of the neighbors cooperates and @xmath92 otherwise .",
    "therefore , for an average player of degree @xmath93 we have that @xmath94=(1-\\rho)^k$ ] .",
    "consistently with the mean field framework we are working on , as a rough approximation we can assume that every player has degree @xmath95 ( the average degree of the network ) , so that @xmath96=1-q_{\\bar{k}}[\\pi_c<\\pi_d]=(1-\\rho)^{\\bar{k}}$ ] . thus , we have @xmath97 to go beyond this simple estimation , we can work out a better approximation by integrating @xmath94 $ ] over the probability distribution of players degrees @xmath48 .",
    "for erds - rnyi random graphs , in the limit of large populations ( @xmath98 ) , it is @xmath99 .",
    "this leads to @xmath100=e^{-\\bar{k}\\rho}$ ] and , subsequently , @xmath101    * remark 3 . *",
    "the precise asymptotical value for the density of cooperators , @xmath49 , depends on the approximation considered above . however , at least for not too inhomogeneous networks , it is to be expected that the approximations turn out to be very good and therefore the corresponding picture of the evolution of the population should be quite accurate in that case .",
    "it is interesting to note that , whatever its exact value , in both cases @xmath49 is such that the right - hand sides of eq .",
    "( [ eq.ss_br_1 ] ) and eq .",
    "( [ eq.ss_br_2 ] ) vanishes and , furthermore , @xmath49 is an attractor of the dynamics , because @xmath102 .",
    "how is the above result modified by mistakes ? when @xmath69 , eq .",
    "( [ eq.ss_br ] ) becomes : @xmath103\\{-\\rho(1-\\epsilon)+(1-\\rho)\\epsilon\\}+q[\\pi_c>\\pi_d]\\{(1-\\rho)(1-\\epsilon)-\\rho\\epsilon\\}\\nonumber\\\\ & = & q[\\pi_c<\\pi_d](-\\rho+\\epsilon)+q[\\pi_c>\\pi_d](1-\\rho-\\epsilon)\\end{aligned}\\ ] ] where the first term accounts for cooperators rightfully switching to defection and defectors wrongly selecting cooperation , while the second term accounts for defectors correctly choosing cooperation and cooperators mistaken to defection .",
    "proceeding as before , and again in the limit @xmath98 , we approximate @xmath100=e^{-\\bar{k}\\rho}$ ] , thus arriving at @xmath104 from which it is possible to find the attractor of the dynamics @xmath49 .",
    "such attractor in turn exists if @xmath105 a threshold that is bounded below by 1/2 , which would be tantamount to players choosing their action at random .",
    "therefore , all reasonable values for the probability of errors allow for equilibria .     vs the average degree @xmath95 for different values of the probability of making a mistake @xmath106 .",
    "values are obtained by numerically solving eq .",
    "( [ eq.ss_br_2_e]).,scaledwidth=50.0% ]    * remark 4 . * to gain some insight on the cooperation levels arising from br dynamics in the nash equilibria , we have numerically solved eq .",
    "( [ eq.ss_br_2_e ] ) . the values for @xmath49",
    "are plotted in fig .",
    "[ fig.ss_br_rc ] for different values of @xmath106 , as a function of @xmath95 .",
    "we observe that the larger @xmath95 , the lower the cooperation level .",
    "the intuition behind such result is that the more connections every player has , the lower the need to play 1 to ensure obtaining a positive payoff .",
    "it could then be thought that this conclusion is reminiscent of the equilibria found for best - shot games in @xcite , which are non increasing in the degree .",
    "however , this is not the case , as in our work we are considering an iterated game that can perfectly lead to high degree nodes having to cooperate . note also that this approach leads to a definite value for the density of cooperators in the nash equilibrium , but there can be many action profiles for the player compatible with that value , so multiplicity of equilibria is reduced but not suppressed .",
    "* remark 5 . * from fig .",
    "[ fig.ss_br_rc ] it is also apparent that as the likelihood of mistakes increases , the density of cooperators at equilibrium increases . note that for large values of the connectivity @xmath95 it becomes @xmath107 , in agreement with the fact that when a player has many neighbors she can assume that a fraction @xmath106 of them will cooperate even if she is already cooperating , thus turning defection into her br .",
    "we now turn to the case of strategic complements , exemplified by our coordination game . as",
    "above , we will start from the case without mistakes , and we will subsequently see how they affect the results .",
    "* proposition 3 .",
    "* within the mean field formalism , under pi dynamics , when @xmath47 the final state for the population is the absorbing state with a density of cooperators @xmath51 ( full defection ) when @xmath108 , and the absorbing state with @xmath73 when @xmath109 .",
    "in the case @xmath110 both outcomes are possible .",
    "_ still within our homogeneous mean field context , the differential equation for the density of cooperators @xmath53 is again eq .",
    "( [ eq.ss_pi ] ) .",
    "as we are in the case in which @xmath47 , we have that @xmath111/\\phi$ ] and @xmath112/\\phi=-(\\pi_c-\\pi_d)(1-q[\\pi_c>\\pi_d])/\\phi$ ] , where for strategic complements @xmath113 . given that @xmath91 and that , consistently with our mf framework , @xmath114 , we find : @xmath115 where we have introduced the values @xmath116 and @xmath117 .",
    "it is easy to see that @xmath118 is an unstable equilibrium , as @xmath119 for @xmath120 and @xmath121 for @xmath122 .",
    "therefore , we have two different cases : when @xmath109 then @xmath123 and the final state is full cooperation ( @xmath73 ) , whereas , when @xmath124 then @xmath125 and the outcome is full defection ( @xmath51 ) .",
    "when @xmath126 then @xmath127 , so both outcomes are in principle possible . @xmath67    * remark 6 .",
    "* the same ( but opposite ) intuition we discussed in remark 1 about the outcome of pi on substitute games suggests that imitation is indeed a good procedure to choose actions in a coordination setup .",
    "in fact , contrary to the case of the best - shot game , in the coordination game pi does lead to nash equilibria , and indeed it makes a very precise prediction : a unique equilibrium that depends on the initial density . turning around the condition for the separatrix , we have @xmath128 , _",
    "i.e. _ , when few people cooperate initially then evolution leads to everybody defecting , and vice versa . in any event , having a unique equilibrium ( except exactly at the separatrix ) is a remarkable achievement .",
    "* remark 7 . * in a system where players may have different degrees , while full defection is always a nash equilibrium for the coordination game , full cooperation becomes a nash equilibrium only when @xmath129 , where @xmath130 is the smallest degree in the network  which means that only networks with @xmath131 feature a fully cooperative nash equilibrium .",
    "when @xmath69 , the problem becomes much more involved and we have not been able to prove rigorously our main result . in fact , now we have @xmath111/\\phi+\\epsilon q[\\pi_c<\\pi_d]$ ] and @xmath112/\\phi+\\epsilon q[\\pi_c>\\pi_d]$ ] .",
    "( [ eq.sc_pi_sol ] ) thus becomes @xmath132)\\}\\ ] ] where we have used @xmath133\\simeq q[\\alpha\\bar{k}\\rho > c]=q[\\rho>\\rho_c]$ ] .",
    "we then have three different cases which we can treat approximately :    * when @xmath134 then @xmath135\\simeq1/2 $ ] and eq .",
    "( [ eq.sc_pi_sol_e ] ) reduces to eq .",
    "( [ eq.sc_pi_sol ] ) , _ i.e. _ , we would recover the result for the case with no mistakes . * when @xmath136 then @xmath135\\simeq1 $ ] and eq .",
    "( [ eq.sc_pi_sol_e ] ) can be rewritten as : @xmath137 with @xmath138 .",
    "this value @xmath139 leads to an unstable equilibrium ; in particular , @xmath119 for @xmath140 so that @xmath141 and hence eq .",
    "( [ eq.sc_pi_sol_e ] ) holds .",
    "* finally when @xmath142 then @xmath135\\simeq0 $ ] and eq .",
    "( [ eq.sc_pi_sol_e ] ) can be rewritten as : @xmath143 with @xmath144 .",
    "as before , @xmath145 gives an unstable equilibrium , because @xmath119 for @xmath146 so that again @xmath141 where eq .",
    "( [ eq.sc_pi_sol_e ] ) holds .",
    "* remark 8 : * in summary , the region @xmath147 becomes a finite basin of attraction for the dynamics .",
    "note that when @xmath148 then @xmath149 has no solution and @xmath150 becomes the attractor in the whole @xmath50 space .",
    "our analysis thus shows that , for a range of initial densities of cooperators , there is a dynamical equilibrium characterized by an intermediate value of @xmath53 , which is neither full defection nor full cooperation .",
    "instead , for small enough or large enough values of @xmath28 the system evolves towards the fully defective or fully cooperative nash equilibrium , respectively .    *",
    "remark 9 : * the intuition behind the result above could be that mistakes can take a number of people away from the equilibrium , be it full defection or full cooperation , and that this takes place in a range of initial conditions that grows with the likelihood of mistakes .      considering now the case of br dynamics , the case of the coordination game is no different from that of the best - shot game and we can not find rigorous proofs for our results , although we believe that we can substantiate them on firm grounds . to proceed , for this case eq .",
    "( [ eq.ss_br ] ) becomes : @xmath151\\ ] ] where we have taken into account that @xmath91 and @xmath152=1-q[\\pi_c>\\pi_d]$ ] .",
    "assuming that every node has degree @xmath95 , _ i.e. _ , a regular random network , it is clear that there must be at least @xmath153 + 1 $ ] neighboring cooperators in order to have @xmath154 .",
    "thus @xmath155=q[\\pi_c>0]=\\sum_{l=[c/\\alpha]+1}^{\\bar{k}}\\binom{\\bar{k}}{l}\\rho^l(1-\\rho)^{\\bar{k}-l}\\ ] ] and @xmath156 + 1}^{\\bar{k}}\\binom{\\bar{k}}{l}\\rho^l(1-\\rho)^{\\bar{k}-l}\\ ] ] once again , the difficulty is to show that @xmath116 is the unstable equilibrium .",
    "however , we can follow the same approach used with pi and write @xmath133\\simeq q[\\alpha\\bar{k}\\rho > c]=q[\\rho>\\rho_c]$ ] , _",
    "i.e. _ , we approximate @xmath133 $ ] as a heaviside step function with threshold in @xmath150 . we then again have three different cases as follows :    * if @xmath134 then @xmath135\\simeq 1/2 $ ] : we have @xmath157 and the attractor becomes @xmath158 . *",
    "if @xmath136 then @xmath135\\simeq 1 $ ] : we have @xmath159 and a stable equilibrium at @xmath160 . * finally if @xmath142 then @xmath135\\simeq 0 $ ] : we have @xmath161 and a stable equilibrium at @xmath162 .",
    "* remark 10 : * as we may see , for br even without mistakes equilibria with intermediate values of the density of cooperators obtain in a range of initial densities . compared to the situation with pi , in which we only found the absorbing states as equilibria , this points to the fact that more rational players would eventually converge to equilibria with higher payoffs .",
    "it is interesting to note that such equilibria could be related to those found by galeotti _",
    "@xcite in the sense that not everybody in the network chooses the same action ; however , we can not make a more specific connection as we can not detect which players choose which action  see , however , section [ sec.hmf_c_br ] below .",
    "a similar approach allows some insight on the situation @xmath163 .",
    "we start again from eq .",
    "( [ eq.ss_br_e ] ) , which now reduces to : @xmath164\\{-\\rho(1-\\epsilon)+(1-\\rho)\\epsilon\\}+q[\\pi_c>\\pi_d]\\{(1-\\rho)(1-\\epsilon)-\\rho\\epsilon\\}\\nonumber\\\\ % & = & = -(\\rho-\\epsilon)+q[\\pi_c>0](1 - 2\\epsilon)\\ ] ] approximating as before @xmath133\\simeq q[\\rho>\\rho_c]$ ] we again have the same three different cases .    *",
    "if @xmath134 then the attractor @xmath158 is unaffected by the particular value of @xmath106 . * if @xmath136 then the stable equilibrium lies at @xmath165 ; * if @xmath142 then the stable equilibrium is at @xmath166 ;    * remark 11 : * adding mistakes to br does not change dramatically the results , as it did occur with pi .",
    "the only relevant change is that equilibria for low or high densities of cooperators are never homogeneous , as there is a percentage of the population that chooses the wrong action .",
    "other than that , in this case the situation is basically the same with a range of densities converging to an intermediate amount of cooperators .",
    "having found the equilibria selected by different evolutionary dynamics , it is interesting to inspect their corresponding welfares ( measured in term of average payoffs ) .",
    "we can again resort to the mean field approximation to approach this problem .",
    "* best - shot game . * in this case the payoff of player @xmath5 is given by eq .",
    "( [ eq.ss ] ) : @xmath167 . within the mean field approximation , for a generic player @xmath5 with degree @xmath33 we can approximate the theta function as @xmath168",
    "$ ] , where the first term is the contribution given by player @xmath5 cooperating ( @xmath38 ) , whereas , the second term is the contribution of player @xmath5 defecting ( @xmath40 ) and at least one of @xmath5 s neighbors cooperating ( @xmath169 for at least one @xmath170 ) .",
    "it follows easily that : @xmath171-c\\rho\\}.\\ ] ] if @xmath172 then @xmath173 , whereas , if @xmath174 then @xmath175 . we recall that in the simple case where players do not make mistakes ( @xmath47 ) , pi leads to a stationary cooperation level @xmath176 , which corresponds to @xmath177 . on the other hand , with br the stationary value of @xmath49",
    "is given by eqn .",
    "( [ eq.ss_br_1 ] ) or ( [ eq.ss_br_2 ] ) , both leading to @xmath178 .",
    "as long as @xmath179 , it is @xmath180 ( the payoff of full cooperation ) . we thus see that under br players are indeed able to self - organize into states with high values of welfare in a non - trivial manner .",
    "* coordination game .",
    "* now player @xmath5 s payoff is given by eq .",
    "( [ eq : sc ] ) : @xmath181 .",
    "again within the mean field framework we approximate the term @xmath182 as @xmath183 , and we immediately obtain : @xmath184 @xmath185 is thus a convex function of @xmath53 , which ( considering that @xmath186 ) attains its maximum value at @xmath51 when @xmath187 , and at @xmath73 for @xmath188 . recalling that , in the simple case @xmath47 , both with pi and br there are two different stationary regimes ( @xmath189 for @xmath190 and @xmath191 for @xmath192 ) , we immediately see that for @xmath193 the stationary state @xmath73 maximizes welfare , and the same happens for @xmath194 with @xmath51 .",
    "however , in the intermediate region @xmath195 the stationary state is @xmath51 but payoffs are not optimal .",
    "in the two previous sections , we have confined ourselves to the case in which the only information about the network we use is the mean degree , _",
    "i.e. _ , how many neighbors players are going to interact with on average .",
    "however , in many cases we may consider information on details of the network , such as the degree distribution , and this is relevant as most networks of a given nature ( e.g. , social ) are usually more complex and heterogeneous than erds - rnyi random graphs .",
    "the heterogeneous mean field ( hmf )  @xcite technique is a very common theoretical tool  @xcite to deal with the intrinsic heterogeneity of networks .",
    "it is the natural generalization of the usual mean field ( homogeneous mixing ) approach to networks characterized by a broad distribution of the connectivity .",
    "the fundamental assumption underlying hmf is that the dynamical state of a vertex depends only on its degree @xmath93 . in other words ,",
    "all vertices having the same number of connections have exactly the same dynamical properties .",
    "hmf theory can be interpreted also as assuming that the dynamical process takes place on an annealed network  @xcite , _ i.e. _ , a network where connections are completely reshuffled at each time step , with the sole constraints that both the degree distribution @xmath48 and the conditional probability @xmath196 ( _ i.e. _ , the probability that a node of degree @xmath197 has a neighbor of degree @xmath93 , thus encoding topological correlations ) remain constant .    note that in the following hmf calculations we will concern ourselves with the deterministic case in which no mistakes are made ( @xmath47 ) , as otherwise the hmf equations become intractable , making it impossible to compare with the simpler mean field setup .",
    "additionally , we will always assume that our network is uncorrelated , _",
    "i.e. _ , @xmath198 .",
    "this is consistent with our minimal informational setting , meaning that it represents the most natural assumption we can make .        in this framework ,",
    "considering more complex network topologies does not change the results we found before , and we again find a final state that is not a nash equilibrium , namely full defection :    * proposition 4 . * in the hmf setting , under pi dynamics , when @xmath47 the final state for the population is the absorbing state with a density of cooperators @xmath51 ( full defection ) except if the initial state is full cooperation @xmath52 .    _",
    "proof . _ the hmf technique proceeds by building the @xmath93-block variables : we denote by @xmath199 the density of cooperators among players of degree @xmath93 .",
    "the differential equation for the density of cooperators @xmath199 is : @xmath200 the first term is the probability of picking a defector of degree @xmath93 with a neighboring cooperator of degree @xmath197 times the probability of imitation ( all summed over @xmath197 ) , whereas , the second term is the probability of picking a cooperator of degree @xmath93 with a neighboring defector of degree @xmath197 times the probability of imitation ( again , all summed over @xmath197 ) . for the best shot game , when @xmath47 , we have : @xmath201 we now introduce these values in eq .",
    "( [ eq.ss_pi_h ] ) and , using the uncorrelated network assumption , we arrive at : @xmath202[eq.ss_pi_h_2 ] where we have introduced the variable @xmath203the corresponding differential equation for @xmath204 reads @xmath205 and its solution has the same form of eq .",
    "( [ eq.ss_pi_sol ] ) : @xmath206^{-1}\\ ] ] with @xmath207 as @xmath208 .",
    "hence @xmath209 for @xmath66 which implies @xmath210 for @xmath66 and @xmath211 . @xmath67",
    "* remark 12 : * for the best - shot game with pi , the particular form of the degree distribution does not change anything .",
    "the outcome of evolution still is full defection , thus indicating that the failure to find a nash equilibrium arises from the ( bounded rational ) dynamics and not from the underlying population structure .",
    "again , this suggests that imitation is not a good procedure for the players to decide in this kind of games .      always within the deterministic scenario with @xmath47 , for the case of best response dynamics the differential equation for each of the @xmath93-block variables @xmath199",
    "has the same form as eq .",
    "( [ eq.ss_br ] ) above , where now to evaluate @xmath94 $ ] we have to consider the particular values of neighbors degrees . as before ,",
    "we consider the uncorrelated network case and introduce the variable @xmath204 from eq .",
    "( [ eq.ss_pi_h_theta ] ) .",
    "we thus have @xmath212=\\left[\\sum_{k'}(1-\\rho_k')p(k'|k)\\right]^k=(1-\\theta)^k,\\ ] ] and @xmath213+(1-\\rho_k)\\,q_k[\\pi_c>\\pi_d]=(1-\\theta)^k-\\rho_k.\\ ] ] the differential equation for @xmath204 is thus : @xmath214 whose solution depends on the form of degree distribution @xmath48 . nevertheless , the critical value @xmath215 such that the right - hand side of eq .",
    "( [ eq.ss_br_h_3 ] ) equals zero is also in this case the attractor of the dynamics .",
    "* remark 13 : * in order to assess the effect of degree heterogeneity , we have plotted in fig .",
    "[ fig.ss_br_hmf ] the numerical solution for two random graphs , an erds - rnyi graph with a homogeneous degree distribution , and a scale - free graph with a much more heterogeneous distribution @xmath216 . in both cases ,",
    "the networks are uncorrelated so our framework applies . as we can see from the plot ,",
    "the results are not very different , and they become more similar as the average degree increases .",
    "this is related on one hand to the particular form of nash equilibria for strategic substitutes , where cooperators are generally the nodes with low degree , and on the other hand to the fact that the main difference between a homogeneous and a scale - free @xmath48 lies in the tail of the distribution . in this sense",
    ", the nodes with the highest degrees ( that can make a difference ) do not contribute to @xmath215 and thus their effects on the system is negligible .     and",
    "varying @xmath217 ) : @xmath49 , vs the average degree @xmath95 , obtained by numerically solving eq .",
    "( [ eq.ss_br_h_3]),scaledwidth=50.0% ]      unfortunately , for the coordination game , working in the hmf framework is much more complicated , and we have been able to gain only qualitative but important insights on the system s features .",
    "the average payoffs of cooperating and defecting for players with degree @xmath93 are : @xmath218-c=\\alpha k\\theta - c\\ ] ] where @xmath204 is the same as defined in eq .",
    "( [ eq.ss_pi_h_theta ] ) .",
    "we then use our starting point for the hmf formalism , eq .",
    "( [ eq.ss_pi_h ] ) , where now the probabilities of imitation are : @xmath219 @xmath220/\\phi\\ ] ] once again within the assumption of an uncorrelated network , we find : @xmath221\\ ] ] in the second term we can carry out the sum over @xmath197 , which yields @xmath222 .",
    "we are now ready to write the differential equation for @xmath204 : @xmath223\\end{aligned}\\ ] ] carrying out the summation over @xmath93 in the first term ( which results again in @xmath224 ) , and relabeling @xmath197 as @xmath93 we are left with @xmath225\\nonumber\\\\ & = & \\sum_{k}kp(k)\\rho_{k}(1-\\theta)(\\alpha k\\theta - c)=(1-\\theta)\\theta\\left[\\alpha\\sum_{k}k^2p(k)\\rho_{k}-c\\bar{k}\\right].\\end{aligned}\\ ] ] finally , introducing the new variable @xmath226 we arrive at : @xmath227    * remark 14 : * while is it difficult to solve eq .",
    "( [ eq.sc_pi_h_sol ] ) in a self - consistent way , qualitative insights can be gained by defining @xmath228 . for @xmath124",
    "the stable equilibrium is @xmath229 , whereas , for @xmath109 the attractor becomes @xmath230 .",
    "the transition between the two regimes lies at @xmath110 .",
    "note that @xmath231 is basically the second momentum of the degree distribution , where each degree @xmath93 is weighted with the density @xmath199 . recalling that @xmath232 may diverge for highly heterogeneous networks ( for instance",
    ", it diverges for scale - free networks with @xmath233 ) , and that for the coordination game cooperation is more favorable for players with many neighbors ( hence @xmath234 for high @xmath93 ) , we immediately see that in these cases @xmath231 diverges as well ( as the divergence is given by nodes with high degree ) .",
    "thus , while the product @xmath235 remains finite ( and equal to @xmath13 ) , @xmath236 to compensate for the divergence of @xmath231 ( figure [ fig.sc_pi_k2 ] ) .",
    "we can conclude that , in networks with broad @xmath48 and in the limit @xmath98 , cooperation emerges also when the incentive to cooperate ( @xmath50 ) vanishes .",
    "this is likely to be related to the fact that as the system size goes to infinity , so does the number of neighbors of the largest degree nodes .",
    "this drives hubs to cooperate , thus triggering a non - zero level of global cooperation .",
    "however , if the network is homogeneous , neither @xmath232 nor @xmath231 diverge , so that @xmath237 remains finite and the fully defective state appears also in the limit @xmath98 .    ,",
    "@xmath238 and @xmath239 ) : stationary cooperation levels @xmath240 vs @xmath241 for various system sizes @xmath1 .",
    "the vertical solid line identifies the critical value of @xmath242.,scaledwidth=50.0% ]      for br dynamics , we would have to begin again from the fact that the differential equation for each of the @xmath93-block variables @xmath199 has the same form of eq .",
    "( [ eq.sc_br ] ) .",
    "we would then need to evaluate @xmath243=\\sum_{l=[c/\\alpha]+1}^k\\binom{k}{l}[\\sum_{k'}\\rho_{k'}p(k'|k)]^l[1-\\sum_{k'}\\rho_{k'}p(k'|k)]^{k - l}=\\sum_{l=[c/\\alpha]+1}^k\\binom{k}{l}\\theta^l(1-\\theta)^{k - l}$ ] . as in the homogeneous case ,",
    "such expression is difficult to treat analytically .",
    "alternatively , we can perform the approximation of setting @xmath243=q[\\alpha k\\theta > c]$ ] , _ i.e. _ , we approximate @xmath243 $ ] with a heaviside step function with threshold in @xmath244 .",
    "this leads to : @xmath245 @xmath246 and to the following self - consistent equation for the equilibrium @xmath215 : @xmath247 whose solution strongly depends on the form of degree distribution @xmath48 . indeed ,",
    "if the network is highly heterogeneous ( _ e.g. _ , a scale - free network with @xmath248 ) , it can be shown that @xmath215 is a stable equilibrium whose dependence on @xmath50 is of the form @xmath249 , _",
    "i.e. _ , there exists a non - vanishing cooperation level @xmath215 no matter how small the value of @xmath50 .",
    "however , if the network is more homogeneous ( _ e.g. _ , @xmath250 ) , @xmath215 becomes unstable and for @xmath251 the system always falls in the fully defective nash equilibria .",
    "another important characterization of such system comes from considering eq .",
    "( [ eq.sc_br_h_1 ] ) and eq .",
    "( [ eq.sc_br_h_2 ] ) : we have @xmath252 when @xmath253 and @xmath254 for @xmath255 . in this sense",
    ", we find a qualitative agreement between the features of our equilibria and those found by galeotti _",
    "@xcite , in which players actions show a monotonical , non - decreasing dependence on their degrees .",
    "in this paper , we have presented two evolutionary approaches to two paradigmatic games on networks , namely the best - shot game and a coordination game as representatives , respectively , of the wider classes of strategic substitutes and complements .",
    "as we have seen , when the available information is very little , we have been able to prove a number of rigorous results and otherwise to get good insights on the outcome of the evolution .",
    "proceeding in order of increasing cognitive demand , let us first summarize what we have learnt about pi dynamics , equivalent to replicator dynamics in a well - mixed population .",
    "for the case of the best - shot game , this dynamics has proven unable to serve as a refinement of nash equilibria , as it always leads to outcomes that are not nash equilibria . on the other hand ,",
    "the asymptotic states obtained for the coordination game are nash equilibria and constitute indeed a drastic refinement .",
    "we believe that the difference between these results arises from the fact that pi is an imitative dynamics and in a context such as the best - shot game , in which equilibria are not symmetric , this leads to players imitating others who are playing `` correctly '' in their own context but whose action is not appropriate for the imitator context . in the coordination game , where the equilibria should be symmetric ,",
    "this is not a problem and we find equilibria characterized by an homogeneous action except in a few specific situations .",
    "when going to a more demanding evolutionary rule , br does lead by construction to nash equilibria  when players are fully rational and do not make mistakes .",
    "we are then able to obtain predictions on the average level of cooperation for the best - shot game but still many possible equilibria are compatible with that value .",
    "predictions are less clear for the case of coordination , due to the fact that in an intermediate range of initial conditions equilibria with finite densities of cooperators are found .",
    "the general picture remains the same in terms of finding full defection or full cooperation for low or high initial cooperation , but this intermediate region proves much more complicated to analyze .    finally , we have probed into the issue of degree heterogeneity by considering more complex network topologies .",
    "generally speaking , the results do not change much , at least qualitatively , for any of the dynamics applied to the best - shot game .",
    "the coordination game is more difficult to deal with in this context but we were able to show that , when when the number of connections is very heterogeneous , cooperation may obtain even if the incentive for cooperation is very small . in any event , from what we have been able to learn , our results tend to indicate that the dynamics is much more relevant than the network structure in determining the result of the evolutionary process .",
    "we are thankful to antonio cabrales , sanjeev goyal and fernando vega - redondo , for their feedback on early versions of the manuscript and advice on the presentation of our results .",
    "g.c . acknowledges the swiss natural science fundation ( grant no pbfrp2_145872 ) .",
    "a.s . acknowledges support from ministerio de economa y competitividad ( mineco , spain ) through grant prodievo .",
    "99 goyal s. ( 2007 ) _ connections : an introduction to the economics of networks _ ( princeton : princeton univ . press ) .",
    "vega - redondo f. ( 2007 ) _ complex social networks_. in _ econometric society monograph series _",
    "( cambridge : cambridge univ . press ) .",
    "jackson mo ( 2008 ) _ social and economic networks _ ( princeton : princeton univ . press ) .",
    "galeotti a , goyal s , jackson mo , yariv l , vega - redondo f ( 2010 ) _ rev .",
    "_ 77 , 218 - 244 .",
    "bramoull y , kranton re ( 2007 ) _ j. econ .",
    "theory _ 135 , 478 - 494 .",
    "boncinelli l , pin p ( 2012 ) _ games econ .",
    "behav . _ 75 ( 2 ) , 538 - 554 . helbing d ( 1992 )",
    "_ physica a _ 181 , 29 - 52 ( 1992 ) .",
    "schlag k ( 1998 ) _",
    "j. econ . theory _",
    "78(1 ) , 130 - 156 .",
    "levine dk , pesendorfer w ( 2007 ) _ games econ .",
    "_ 58 , 293 - 315 .",
    "gintis h ( 2009 ) _ game theory evolving _",
    "( princeton : princeton university press ) .",
    "borgers t , sarin j ( 1997 )",
    "_ j. econ .",
    "theory _ 77 , 1 - 15 .",
    "matsui a ( 1992 ) _",
    "j. econ . theory _ 57 , 343 - 362 .",
    "blume le ( 1993 ) _ games econ .",
    "_ 5 , 387 - 424 .",
    "erds sp , rnyi a ( 1960 ) _ pub . math .",
    "inst . hung .",
    "_ 5 , 17 - 61 .",
    "barabsi al , albert r ( 1999 ) _ science _ 286 , 509 - 512 .",
    "pastor - satorras r , vespignani a ( 2001 ) _ phys .",
    "_ 86 , 3200 - 3203 . angeletos gm , pavan a ( 2007 ) _ econometrica _ 75 , 1103 - 1142 .",
    "ballester c , calv - armengol a , zenou y ( 2006 ) _ econometrica _ 74 , 1403 - 1417 .",
    "ballester c , calv - armengol a ( 2010 ) _ reg .",
    "urban econ .",
    "_ 40 , 397 - 406 .",
    "bergemann d , morris s ( 2009 ) _ rev .",
    "_ 76 , 1175 - 1204 .",
    "bramoull y , kranton r , damours m ( 2011 ) _ strategic interaction and networks _",
    "( mimeo ) .",
    "calvo - armengol a , patacchini e , zenou y ( 2009 ) _ rev .",
    "_ 76 , 1239 - 1267 .",
    "glaeser el , scheinkman ja ( 2003 ) _ non - market interactions_. in _ advances in economics and econometrics : theory and applications _ , vol .",
    "1 . goyal s , moraga - gonzalez jl ( 2001 ) _ rand j. econ .",
    "_ 32 , 686 - 707 . vives x ( 1999 ) _ oligopoly pricing : old ideas and new tools _ ( cambridge : mit press ) .",
    "roca cp , cuesta ja , snchez a ( 2009 ) _ phys .",
    "_ 6 , 208 - 249 nash jf ( 1950 ) _ non - cooperative games _ ( ph.d .",
    "dissertation , princeton university ) .",
    "mas - colell a ( 1997 ) _ bargaining games_. in hart s , mas - colell a. ( eds . ) , _ cooperation : game theoretic approaches _ ( springer - verlag ) , pp .",
    "6990 fudenberg d , levine dk ( 1998 ) _ eur .",
    "_ 42 : 631 - 639 .",
    "hart s , mas - colell a ( 2000 ) _ econometrica _ 68 , 1127 - 1150 .",
    "hart s , mas - colell a ( 2003 ) _ amer . econ .",
    "_ 93 , 1830 - 1836 .",
    "hart s ( 2011 ) _ games econ .",
    "_ 71 , 6 - 8 .",
    "blume l ( 2003 ) _ games econ .",
    "_ 44 , 251 - 271 .",
    "young hp ( 1998 ) _ individual strategy and social structure _",
    "( princeton : princeton university press ) .",
    "bergin j , lipman bl ( 1996 ) _ econometrica _ 64 , 943 - 956 .",
    "dorogovtsev sn , goltsev av , mendes jff ( 2008 ) _ rev .",
    "_ 80 , 1275 - 1335 ."
  ],
  "abstract_text": [
    "<S> we consider games of strategic substitutes and strategic complements on networks . </S>",
    "<S> we introduce two different evolutionary dynamics in order to refine their multiplicity of equilibria , and we analyse the system through a mean field approach . we find that for the best - shot game , taken as a model for substitutes , a replicator - like dynamics does not lead to nash equilibria , whereas it leads to unique equilibria ( full cooperation or full defection , depending on the initial condition and the game parameter ) for complements , represented by a coordination game . on the other hand , when the dynamics becomes more cognitively demanding in the form of a best response evolution , predictions are always nash equilibria ( at least when individuals are fully rational ) : for the best - shot game we find equilibria with a definite value of the fraction of contributors , whereas for the coordination game symmetric equilibria arise only for low or high initial fractions of cooperators . </S>",
    "<S> we also extend our study by considering complex heterogeneous topologies , and show that the nature of the selected equilibria does not change for the best - shot game . </S>",
    "<S> however for coordination games we reveal an important difference , namely that on infinitely large scale - free networks cooperation arises for any value of the incentive to cooperate . </S>"
  ]
}