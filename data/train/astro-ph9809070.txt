{
  "article_text": [
    "the wide field and planetary camera ( wfpc2 ) aboard the hubble space telescope ( hst ) , is an excellent tool for astrometric study .",
    "this is a result of its superb spatial resolution and image stability .",
    "however , the wide field ( wf ) camera produces undersampled images , and the point spread function ( psf ) of wfpc2 is complex .",
    "these properties force one to have to take special care in the data reduction process .    in the present contribution",
    "we discuss an optimal maximum - likelihood technique that is particularly well - suited for calculating centroids of point - like objects from wfpc2 data obtained in many slightly offset exposures .",
    "the same technique will be readily applicable to stis imaging data or advanced camera images .    as a working example",
    ", we present the problem of obtaining image centroids for point - like objects in the hubble deep field ( hdf ) .",
    "the expected proper motion ( pm ) @xmath0 for a point - source at distance @xmath1 , moving with transverse velocity of @xmath2 over a time interval of @xmath3 is @xmath4 on the planetary camera ( pc ) and @xmath5 on the wf camera ( the velocity , distance and time interval values are appropriate to our test problem below ) .",
    "so the hst guiding accuracy of @xmath6 arcsec rms ( corresponding to @xmath7 pc pixels and @xmath8 wf pixels ) in `` fine lock '' mode , is sufficient to measure the pms of galactic stars out to large distances , as long as accurate image centroids and a suitable reference frame can be determined to better accuracy than the expected proper motions .",
    "this jitter of 0.005 arcsec , will make the undersampled wfpc2 images fractionally wider , but it will not significantly affect image centroiding ( to better than the rms uncertainty ) , unless the jitter has a systematic direction .",
    "the wfpc2 dithering technique , where many exposures of a field are taken with slightly different pointings , offset by a few pixels , was developed as a means to eliminate the effects of ccd cosmetic defects , hot pixels and cosmic rays .",
    "it is also very useful for astrometric purposes , since the positional accuracy of each dithered frame allows the stellar image , which is undersampled in a single frame , to be resampled at several sub - pixel positions .",
    "specialized software , such as the `` drizzle '' algorithm of fruchter & hook ( 1997 ) , have been devised to stack dithered frames .",
    "taking advantage of the extra positional information , they dramatically enhance the resolution of the final stacked image .",
    "however , stacking inevitably degrades information .",
    "the resulting psf must always be more complex than that of individual frames , and given that the wpfc2 psf varies strongly as a function of position over the camera , the psf of the stacked image will also depend on the particular dither pattern adopted by the observer .",
    "these problems become more severe if one enhances the resolution of the stacked image ( with such algorithms as `` drizzle '' ) ; furthermore , the noise in the stacked image will then be spatially correlated and hence quite complex . on the other hand ,",
    "working purely with shallow individual frames is a huge waste of the depth of the data - set ( in the hdf , objects that have s / n@xmath9 in the combined 58-exposure first epoch f814w stack , correspond to @xmath10 detections in individual exposures ) .",
    "the solution to this apparent dilemma is very simple .",
    "we assume the psf in each frame ( and its variation across each frame ) is known .",
    "these psfs are best determined from the data - set under investigation . however , if there are few or no bright , isolated , unsaturated stars present in those frames , one may still be able to obtain a good approximation to the psf , if it sufficiently stable over time .",
    "this is the case for wfpc2 ; and suitable data are readily obtained from the archive .",
    "we also assume that the transformations ( and inverse transformations ) that map every point on the @xmath11th frame to a cartesian grid on the sky have been determined in advance ( using techniques such as those described below ) . a `` master frame '' , whose",
    "rows and columns are aligned with that cartesian grid is produced by stacking all the individual frames ( using the `` drizzle '' algorithm , for instance , but with resolution enhancement turned off ) . on this `` master frame '' , we search for candidate stars and photometer them ; a crowded - field photometry package such as `` allstar '' ( stetson 1994 ) is ideal for this purpose .",
    "this also yields a first estimate @xmath12 of the astrometric position on the `` master frame '' of the @xmath13th candidate point - source .",
    "these positions are transformed into the coordinate system of the @xmath11th frame to give @xmath14 .",
    "then , for each of the @xmath15 stellar candidates , we find the likelihood of the the exposure - normalized psf model in the @xmath11th frame , given the data @xmath16 in the @xmath11th frame @xmath17 , \\eqno(1)\\ ] ] where the product is performed over all uncontaminated pixels @xmath18 within a circle of radius @xmath19 of @xmath14 . contaminated pixels  by which we mean pixels on cosmetic defects , hot pixels , or pixels affected by cosmic ray impacts  are simply left out of the calculation ( we discuss below how bad pixel maps were constructed for each frame of our test data - set ) .",
    "the quantity @xmath20 is the modal sky value in an annulus with suitably chosen inner and outer radii around the @xmath13th object on frame @xmath11 .",
    "the product over all @xmath21 frames of @xmath22 , @xmath23 is the likelihood that a point - source is centered at position @xmath12 on the `` master frame '' , given all the available data . repeating this process in a fine grid of @xmath24 values in the immediate neighborhood of @xmath12 , yields the likelihood surface , and a two - dimensional maximization routine",
    "can then be used to find the position @xmath25 of the maximum of @xmath26 .",
    "the coordinate @xmath25 is then the most likely position of the center of the image .",
    "there has been no image degradation , as the data have not been tampered with ( except for initial debiassing and flat - fielding ) , and there is no loss of depth .",
    "the technique is optimal , and is especially useful for the case where rotated , optically distorted frames with different and ( or ) spatially varying psfs are to be analyzed .",
    "the important noise sources are : poisson noise in the source , poisson noise in the sky , read noise , flat - fielding errors and psf mismatching errors .",
    "when dealing with faint objects on a low sky background it will be advantageous to consider carefully the distribution of expected counts , which is why we stressed the use of the likelihood function above .",
    "however , for all the images we analyzed , the sky background was substantial , greater than 100  @xmath27 , so that the noise distribution could be reasonably modeled by a gaussian error distribution on each pixel . given this , one may then trivially compute , using the @xmath28 statistic instead of the likelihood in the computations above , the probability that the observed brightness enhancement is drawn from the same distribution as a point - source located at @xmath25 .",
    "thus , this method also provides an excellent means of discriminating point - like from extended sources , that is especially powerful at revealing objects that deviate only slightly from point - sources . again , this uses the full depth of the data - set , avoids the information degradation inherent to the stacking process , and also avoids the problems of having correlated noise .",
    "we found that a considerable improvement in @xmath28 can be achieved if the magnitude as well as the position of bright candidate point - sources are refined simultaneously .",
    "though the flux estimate did not vary from the input value by more than 0.1 magnitudes for any of the objects we measured in the test problem below , the @xmath28 probability occasionally improved by orders of magnitude .",
    "although we have not tested this technique on crowded fields , it is likely to yield accurate centroid positions if the input positions and magnitudes of all detectable stars have been carefully determined with a good crowded - field photometry package .",
    "however , one should make the following two alterations to the algorithm .",
    "first , before analyzing the @xmath13th object , one should subtract the expected counts from all other objects from each frame in the data set . and second",
    ", the objects should preferably be analyzed in order of decreasing flux .",
    "a limitation of our method is that we choose not to measure variability over the time - span of the observations in any one epoch .",
    "clearly , adding an extra parameter for each object on each frame , would make the scheme less robust .",
    "variability between epochs can be measured , however .",
    "the hdf is the deepest image yet obtained of the universe ; taken with the hubble space telescope ( hst ) in director s discretionary time in december 1995 ( williams  1996 ) , its primary aim of studying the formation an evolution of galaxies has been extremely successful .    apart from the numerous galaxies , a small number of stars were also detected in this field .",
    "however , the constraints that can be placed upon galactic structure models from these data are disappointing due to the relatively shallow limit of @xmath29 at which stars can be discriminated from the galaxies with reasonable confidence ( flynn   1996 ) . for comparison ,",
    "the limiting magnitude of the hdf in f814w is @xmath30 , so a factor of @xmath31 of survey volume would be gained if one could push star - galaxy discrimination to the faintest limit of the data .",
    "here we show that a better way to find stars at the faint limit of this data set is to observe the field in f814w in a second epoch , and calculate proper motions ( pms ) .",
    "the necessary follow - up data , taken in december 1997 , were obtained to undertake a search for high redshift supernovae ( gilliland & phillips 1998 ) .",
    "note that over the two year timespan that separates the datasets , a star @xmath32 away travelling with a transverse velocity of @xmath33 will move 0.82 wf pixels .",
    "transverse velocities of this magnitude can be expected from spheroid ( or more interestingly ) halo stars due to the large velocity dispersions of these populations .",
    "furthermore , their slow rotation about the galactic center will introduce a large apparent motion as viewed from the sun .      to apply the method outlined above",
    ", we need to know the geometrical transformations between pixel positions on each frame taken at a given epoch . to do this",
    ", we could find the centroids of objects ( stars or galaxies ) on each frame and compute transformation coefficients .",
    "however , due to optical design , wfpc2 images give a substantially distorted view of the sky , so a high order polynomial must be used to give acceptable residuals .",
    "if there are few objects on the frames for which reliable centroids can be found , this procedure will be far from robust .",
    "it is better therefore to make use of some prior information : the optical distortion of wfpc2 , as a function of wavelength , is fairly well understood .",
    "trauger   ( 1995 ) have published transformations ( a 10-coefficient bicubic polynomial in each of the @xmath34 and @xmath35 directions ) that allow one to convert ccd pixel positions , in a given passband , to a geometrically corrected frame .",
    "the accuracy of this transformation has been determined to be 0.1 pixels rms over the fields of view of the ccds .    though not necessary , the proper motion analysis is easier if one is able to construct an accurate extragalactic reference frame .",
    "ideally , one would like to use point - like sources for this purpose , as the centroid of an extended source ( which is most probably also lumpy ) is not easily defined .",
    "however , to date no qsos have been identified in the hdf .",
    "one is therefore forced to use galaxies to define the reference frame .",
    "galaxies are generally fuzzy , lumpy objects , so it is very difficult , if not perhaps impossible , to define the center of the light distribution . to circumvent this problem",
    ", the approach we take is to obtain _ differential _ measurements . only for the purpose of determining the transformations between frames , we `` un - distort '' all of the frames by applying the trauger  ( 1995 ) coefficients .",
    "bad pixels in the frames are flagged , as described below . the dither position # 6 frames ( see williams   1996 ) were chosen to define a `` reference frame '' .",
    "a first estimate of the positions of the @xmath36 brightest galaxies in the chosen `` reference frame '' is obtained using the `` find '' algorithm of `` daophot '' ( stetson 1987 ) , which fits a gaussian function to brightness enhancements in the image . however , the resulting positions are accurate to not much better than about 1 pixel . to improve this positional accuracy , we implemented the following algorithm .",
    "first , a search is performed for the local minima of the marginal density distributions along the column and row directions of a 40 pixel box centered on each input position .",
    "this is done in two iterations following the first steps of the recipe given in stetson ( 1979 ) .",
    "these local minima are found on either side of the peak , both in in the @xmath34 and @xmath35 directions , and are used to define the limits of a new box surrounding the object under study .",
    "this box will be free of the influence of brighter neighbors .",
    "the marginal density distributions in this new box are computed .",
    "the algorithm then cross - correlates the marginal density distributions of the same object on each frame .",
    "obviously , best results will be obtained if the frames being compared have approximately the same orientation angle .",
    "having determined the positional offsets for all the bright galaxies on all frames , one can proceed to find the geometric transformations that relate the frames to each other . a simple four - coefficient geometric transformation ( shift , rotation and change of scale )",
    "was found to give excellent residuals , better than @xmath37 pixels rms , between frames in the same passband .",
    "thus the trauger   model provides an accurate map of the wfpc2 optical distortion .",
    "( the fact that we are able to align the undistorted frames to better than the expected accuracy of the distortion transformations is probably a consequence of the relatively close alignment of the individual hdf frames ) .    this procedure has given us the geometric transformations between the ( undistorted ) `` reference frame '' and all other undistorted frames . however , what we really need to know are the transformations ( and inverse transformations ) between the raw ( optically distorted ) frames and the `` reference frame '' .",
    "the forward transformations are found by simply substituting the trauger  functions into the above four - coefficient geometric transformations .",
    "the inverse transformations can not be written down as a polynomial , but a non - linear newton - raphson algorithm can be used to provide the required inverse mapping .      finally , it is necessary to flag bad pixels on the raw frames .",
    "consider pixel @xmath18 on the @xmath11th frame .",
    "we find the overlap area ( using the computed geometrical transformations ) of the footprint of this pixel on all other frames in the same passband as frame @xmath11 and in the same epoch , to obtain a list of @xmath21 flux estimates ( i.e. counts per second above the sky ) at this position .",
    "the mean and standard deviation of this list are computed , after clipping the highest flux datum . given the exposure lengths and",
    "the number of frames , this datum is likely to be severely contaminated by a cosmic ray ; however , the statistical bias introduced by this clip should be negligible .",
    "the pixel is flagged as bad if the measured flux deviates from the mean flux by more than four standard deviations .",
    "this process is repeated for all pixels on all frames .",
    "the advantage of this procedure is clear : maximum spatial resolution is maintained on all frames .      as an illustration , in figure  1",
    "we show the result of applying the present technique to three sample objects on the wf2 chip using data from the first epoch hdf .",
    "the upper two panels show results relating to a fairly faint star identified by flynn  ( 1996 ) ( @xmath38 , @xmath39 ; position on hdf wf2 dither # 6 : @xmath40 , @xmath41 ) .",
    "panel ( a ) shows the likelihood contours of the centroid of this star ( in the `` reference frame '' ) , calculated using all first epoch f814w exposures .",
    "the `` star '' graph - marker shows the point @xmath25 , the most likely centroid position , while the @xmath42th contour marks the boundary of the region where the likelihood has fallen by a factor of @xmath43 from the most likely value ( so the image centroid is @xmath44 times less likely to be situated beyond the last contour than at the position of the `` star '' marker ) .",
    "the distance from the `` star '' marker to the first contour is 0.017 pixels , or 1.7  mas .",
    "panel ( b ) displays the object profile .",
    "the position @xmath25 is transformed to the correct position on the individual raw frames , @xmath45 ; for all frames @xmath11 , we plot the raw pixel data within 2 pixels of @xmath45 as a function of distance from that point .",
    "the uncertainties on individual pixel values are also indicated .",
    "the expected counts from the psf models are shown as filled circles ; that these values do not always decrease monotonically from the image center is due to non - axisymmetry in the model psfs , and to the particular way in which the dithering sampled the object .",
    "this diagram serves simply to illustrate the goodness of fit of the data to the psf ; we find that the probability that @xmath28 , for a correct model , should be less than the observed value is @xmath46 .",
    "the middle two panels display the results of applying the technique to a faint , blue star identified by flynn   ( 1996 ) ( @xmath47 , @xmath48 ; position on hdf wf2 dither # 6 : @xmath49 , @xmath50 ) .",
    "panels ( b ) and ( c ) have , respectively , similar content to panels ( a ) and ( b ) . here",
    ", the centering uncertainty has degraded to @xmath51  mas . using the @xmath28 statistic",
    ", we find @xmath52 , so this object is almost certainly not a point - source , illustrating the resolving power of our method .",
    "interestingly , other faint blue objects identified by flynn  ( 1996 ) as stars can similarly be shown to be non - stellar ; the nature of these objects will be investigated in a subsequent contribution .",
    "finally , panels ( d ) and ( e ) show the results for an object at the limit of the hdf , ( @xmath53 , no color information available ; position on hdf wf2 dither # 6 : @xmath54 , @xmath55 ) .",
    "our estimated centroiding accuracy on this extremely faint object is @xmath56  mas .",
    "many sources contribute to uncertainty in the computed centroid positions .",
    "there are `` fundamental '' uncertainties from poisson noise in the sky and in the object , from detector noise , and from the sampling .",
    "there will also be uncertainties in the flat - fielding , and in the psf determination .",
    "further sources of uncertainty , not accounted for in our model , arise from the fact that ccd pixels are not exactly square , that they are not laid out on a perfect cartesian grid , and that , at some level , every pixel has a non - uniform sensitivity over its surface .    clearly , it is desirable to determine the combined effect of all these uncertainties . to this end",
    ", we separated the first epoch f814w data at dither positions 1 - 5 and at dither positions 6 - 11 to make two sub - samples . comparing the positions of point - sources determined from the first sub - sample ( @xmath57 , say ) to those determined in the other ( @xmath58 ) , provides an internal means to measure the accuracy of the method .",
    "the hdf frames are slightly shifted and some are slightly rotated with respect to each other , so this exercise should provide a good indication of the achievable centering ( and proper motion ) accuracy for a dataset where the frames of all epochs are in close alignment .",
    "this experiment was performed on the seventy - two objects , with light profiles consistent with being point - sources with probability @xmath59 , that we detected in the hdf .",
    "the results are displayed in figure  2 .",
    "the `` star '' graph - markers show the value of @xmath60 as a function of @xmath61  magnitude .",
    "the filled circles give the expected uncertainties , as derived from the likelihood surfaces .",
    "the good agreement between these two methods of estimating the centroiding uncertainties suggests that our noise model is reasonable .",
    "clearly , it is possible to obtain quite accurate centroids ( to @xmath56  mas ) even at the very faint limit of the hdf , opening the possibility of many interesting studies .",
    "a method has been outlined for obtaining accurate point - source image centroids from wfpc2 data .",
    "it is optimal , in the sense that maximum - likelihood techniques are used to take advantage of all available positional and brightness data contained in the ccd frames .",
    "it is shown that , when applied to the hdf data - set , centroid uncertainties on the order of 2  mas are easily achieved for relatively faint stars , while stars at the limit of the data - set , near @xmath62 , may be measured with accuracies of @xmath56  mas .",
    "many interesting proper motion studies are therefore possible .",
    "further work is required to determine up to what accuracy the bulk proper motion of point - sources (  star cluster or local group galaxies ) improves as the square root of the number of sources .",
    "systematic effects must drown the signal at some level ; but judging from the present work , our 0.02 pixel limit is set by the accuracy with which we were able to fix the reference frame .",
    "the bulk proper motions of even very faint populations can therefore be measured down to at least that level of accuracy .",
    "so for projects that require proper motion measurements of very faint sources , hst imaging instruments are likely to remain highly competitive even compared to the next generation of astrometric missions such as nasa s space interferometry mission ( sim ) or esa s global astrometric interferometer for astrophysics ( gaia ) ."
  ],
  "abstract_text": [
    "<S> an optimal maximum - likelihood technique for computing point - source image centroids from many , slightly offset , ccd frames is presented . </S>",
    "<S> the method is especially useful for measuring stellar proper motions from data taken with the wide field and planetary camera aboard the hst , and also provides a means to identify very compact non - stellar sources . </S>",
    "<S> we work though the example problem of obtaining image centroids of objects in the hubble deep field .    </S>",
    "<S> = # 1to 0pt#1 = </S>"
  ]
}