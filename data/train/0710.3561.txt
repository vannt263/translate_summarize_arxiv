{
  "article_text": [
    "stochastic strategies for optimization are essential to many of the heuristic techniques used to deal with complex , unstructured global optimization problems .",
    "methods like simulated annealing @xcite and evolutionary algorithms @xcite , have proven to be valuable tools , capable of give good quality solutions at a relatively small computational effort . in spite of their success",
    ", these approaches present a major drawback , namely the absence of valid bounds on the obtained solutions .",
    "a common feature of deterministic global optimization algorithms is the progressive reduction of the domain space until the global optimum has been found with arbitrary accuracy @xcite .",
    "an analogous property for stochastic algorithms has been largely lacking . in this contribution",
    "is introduced a method for the estimation of the asymptotic probability density of a general stochastic search process in global optimization problems .",
    "the convergence of the estimated density can be clearly assessed , and with the help of this density , reliable bounds for the location of the global optimum are derived .",
    "the procedure involves linear operations only , and a well defined number of evaluations of the given cost function .",
    "the presented results indicate that by the proposed approach , regions of the search space can be discarded on a probabilistic basis .",
    "this property may be implemented in a variety of ways in order to improve existing or develop new optimization algorithms , and open the door for the construction of probabilistic optimality certificates in large scale nonlinear optimization problems .",
    "the roots of stochastic search methods can be traced back to the metropolis algorithm @xcite , introduced in the early days of scientific computing to simulate the evolution of a physical system to thermal equilibrium .",
    "this process is the base of the simulated annealing technique @xcite , which makes use of the convergence to a global minimum in configurational energy observed in physical systems at thermal equilibrium as the temperature goes to zero .",
    "the method presented in this contribution is rooted in similar physical principles as those on which simulated annealing and related algorithms @xcite are based . however , in contrast with other approaches , the proposed method considers a density of points instead of markov transitions of individual points .",
    "moreover , the main goal of the proposed approach is not the convergence to global minima as a randomness parameter is reduced , but the approximation of the probability density after an infinitely long exploration time of the search space , keeping a fixed randomness .",
    "consider the minimization of a cost function of the form @xmath0 with a search space defined over @xmath1 .",
    "a stochastic search process for this problem is modeled by    @xmath2    where @xmath3 is an additive noise with zero mean .",
    "equation ( [ langevin ] ) , known as langevin equation in the statistical physics literature @xcite , captures the basic properties of a general stochastic search strategy . under an uncorrelated gaussian noise with constant strength , eq .",
    "( [ langevin ] ) represents a search by diffusion , while a noise strength that is slowly varying in time gives a simulated annealing .",
    "notice that when choosing an external noise of infinite amplitude , the dynamical influence of the cost function over the exploration process is lost , leading to a blind search . the model given by eq.([langevin ] ) can be also interpreted as an overdamped nonlinear dynamical system composed by @xmath4 interacting particles .",
    "the temporal evolution of the probability density of such a system in the presence of an additive gaussian white noise , is described by a linear differential equation , the fokker ",
    "planck equation @xcite ,    @xmath5 + d\\frac{\\partial ^{2 } p}{\\partial x^{2}}\\end{aligned}\\ ] ]    where @xmath6 is a constant , called diffusion constant , that is proportional to the noise strength . the direct use of eq . ( [ fp ] ) for optimization or deviate generation purposes would imply the calculation of high dimensional integrals .",
    "it results numerically much less demanding to perform the following one dimensional projection of eq .",
    "( [ fp ] ) . under very general conditions ( e. g. , the absence of infinite cost values ) , the equation ( [ fp ] ) has a stationary solution over a search space with reflecting boundaries @xcite .",
    "the stationary conditional probability density satisfy the one dimensional fokker ",
    "planck equation    @xmath7    an important consequence of eq . ( [ sfp ] )",
    "is that the marginal @xmath8 can be sampled by drawing points from the conditional @xmath9 via a gibbs sampling @xcite .",
    "it is now shown how , due to the linearity of the fokker ",
    "planck equation , a particular form of gibbs sampling can be constructed , such that its not only possible to sample the marginal density , but to give an approximate analytical expression for it . from eq .",
    "( [ sfp ] ) follows a linear second order differential equation for the cumulative distribution @xmath10 ,    @xmath11    random deviates can be drawn from the density @xmath9 by the fact that @xmath12 is an uniformly distributed random variable in the interval @xmath13 $ ] .",
    "viewed as a function of the random variable @xmath14 , @xmath15 can be approximated through a linear combination of functions from a complete set that satisfy the boundary conditions in the interval of interest ,    @xmath16    choosing for instance , a basis in which @xmath17 , the @xmath18 coefficients are uniquely defined by the evaluation of eq .",
    "( [ sfpm ] ) in @xmath19 interior points . in this way",
    ", the approximation of @xmath12 is performed by solving a set of @xmath18 linear algebraic equations , involving @xmath19 evaluations of the derivative of @xmath20 .",
    "the proposed procedure is based on the iteration of the following steps :    * 1 ) * fix the variables @xmath21 and approximate @xmath15 by the use of formulas ( [ sfpm ] ) and ( [ set ] ) .    *",
    "2 ) * by the use of @xmath22 construct a lookup table in order to generate a deviate @xmath23 drawn from the stationary distribution @xmath24 .",
    "* 3 ) * update @xmath25 and repeat the procedure for a new variable @xmath26 .",
    "the iteration of the three steps above give an algorithm for the estimation of the equilibrium distribution of the stochastic search process described by eq .",
    "( [ langevin ] ) .",
    "a convergent representation for @xmath8 is obtained after taking the average of the coefficients @xmath27 s in the expansion ( [ set ] ) over the iterations . in order to see this , consider the expressions for the marginal density and the conditional distribution ,    @xmath28    @xmath29    from the last two equations follow that the marginal @xmath30 is given by the expected value of the conditional @xmath31 over the set @xmath32 ,    @xmath33 .\\end{aligned}\\ ] ]    all the information on the set @xmath32 is stored in the coefficients of the expansion ( [ set ] ) .",
    "therefore    @xmath34    where the brackets represent the average over the iterations of the density estimation procedure .",
    "previous preliminary applications of the density estimation method on the generation of suitable populations of initial points for optimization algorithms can be found in @xcite . in the next section the capabilities of the proposed algorithm for the construction of reliable probabilistic bounds",
    "is tested on several benchmark unconstrained examples and in a family of well known constrained np - hard problems .",
    "the fundamental parameters of the density estimation procedure , @xmath18 and @xmath6 , have a clear meaning , which is very helpful for their selection .",
    "the diffusion constant `` smooth '' the density .",
    "this is evident by taking the limit @xmath35 in eq .",
    "( [ sfpm ] ) , which imply an uniform density in the domain .",
    "the number of base functions @xmath18 , on the other hand , defines the algorithms capability to `` learn '' more or less complicated density structures .",
    "therefore , for a given @xmath6 , the number @xmath18 should be at least large enough to assure that the estimation algorithm will generate valid distributions @xmath15 .",
    "a valid distribution should be a monotone increasing continuos function that satisfy the boundary conditions .",
    "the parameter @xmath18 ultimately determines the computational cost of the procedure , because at each iteration a system of size @xmath36 of linear algebraic equations must be solved @xmath4 times .",
    "therefore , the user is able to control the computational cost through the interplay of the two basic parameters : for a larger @xmath6 a smoother density should be estimated , so a lesser @xmath18 can be used .",
    "the density estimation algorithm is tested on the following benchmark unconstrained problems :    schwefel : @xmath37    levy no . 5 : @xmath38    booth : @xmath39    colville : @xmath40    rosenbrock : @xmath41    for the experiments ,",
    "the following specific form of the expansion ( [ set ] ) has been used ,    @xmath42    so the size of the algebraic system of equations is @xmath19 .",
    "the linear system has been solved by a lu decomposition routine @xcite .",
    "the gradients have been calculated numerically , with two cost function evaluations per derivative . in this way",
    ", the total number of cost function evaluations per iteration goes like @xmath43 .    in fig .",
    "[ schwefel ] two different pairs @xmath44 have been considered in the study of the schwefel problem .",
    "this problem has a second best minimum at a relatively large distance of the global optimum .",
    "this is reflected on the estimated densities , but at small @xmath6 a clear distiction between the two regions is made .",
    "the schwefel problem is an example of a separable function , that is , a function given by a linear combination of terms , where each term involves a single variable .",
    "separable problems generate an uncoupled dynamics of the stochastic search described by eq .",
    "( [ langevin ] ) .",
    "because of this fact , the estimation algorithm converges in only one iteration for separable problems .",
    "the schwefel example also illustrates that the density estimation algorithm works well on functions that are not derivable in some points .",
    "this is a consequence of the finite number of gradient evaluations required by the procedure",
    ".    0.5 cm        in contrast to the schwefel function , the stochastic search process associated to the levy no .",
    "5 problem represents a coupled nonlinear dynamics . despite",
    "that this problem has about @xmath45 local minima @xcite , the estimation algorithm shows good convergence properties , as is illustrated in fig .",
    "[ levy ] .",
    "0.5 cm     0.1 cm     the two previous examples show how , once that the estimation algorithm as attained convergence , is possible to define a region of the search space in which with high probability the global optimum is located .",
    "this concept is more sistematically studied through the introduction of normalized distances .",
    "the distance normalized with respect to the search space @xmath1 between two points @xmath46 and @xmath47 is defined by    @xmath48    two measures written in terms of normalized distances are presented in the examples of figures [ booth ] , [ colville ] and [ rosen ] : * i ) * the distance between the global optimum and the point in which the density is maximum . *",
    "ii ) * the length of the @xmath49 probability interval around the point of maximum probability .    0.5 cm     0.1 cm     0.5 cm        0.5 cm        under general conditions a gibbs sampling displays geometric convergence @xcite . in the presented experiments",
    "the running time has been chosed such that the @xmath49 probability interval differ in less than @xmath50 between succesive iterations .",
    "additionally , several control runs from different and independent starting conditions have been performed , indicating convergence to the same corresponding region within the predefined accuracy .",
    "as expected for a gibbs sampling , the density appears to contract to a region of space that is independent of the staring point @xcite .",
    "the numerical realizations suggest that convergence is attained at a few hundreds of iterations for all of the examples , even for the @xmath51  dimensional rosenbrock problem , which as been reported to be difficult to solve by stochastic heuristics like genetic algorithms @xcite .",
    "the numerical experiments show that the global optimum is contained in a region close to the point of maximum probability , and that this region gets more sharp as @xmath6 decreases .",
    "a straighforward application of this behavior would be , for instance , on simulated annealing ",
    "type algorithms . starting with a large diffusion",
    "constant , search regions can be iteratively discarded . by the use of the density estimation method ,",
    "a probability measure is associated with each region . in this way",
    "the user can define a certain level of precision in the search .",
    "several statistical quantities can be readily calculated like measures of confidence , for instance probability intervals or characteristic fluctuation sizes .    because the estimation algorithm depends on linear operations only , additional nonlinearities in the cost function",
    "can be treated with essentialy the same efficiency , giving more freedom and flexibility in modeling . for instance , the application of the density estimation algorithm to constrained problems can be done in a very direct manner through the addition of suitable `` energy barriers '' ( or more precisely , `` force barriers '' ) .",
    "these barriers do nt need to be very large .",
    "their main purpose is not to define prohibited regions , but only regions with low probability .",
    "the original constrained problem is transformed to an unconstrained cost function with additional nonlinearities . of course",
    ", the design of adequate barriers may be a difficult problem ",
    "dependent task .",
    "however , at least for some problems the approach seems to be straightforward .",
    "this is illustrated on the classical np - hard knapsack problem @xcite .",
    "it is well known that many standard instances of the knapsack model can be efficiently solved by exact methods @xcite , which makes it an ideal example for experimentation with the density estimation algorithm .",
    "the knapsack problem is formulated as    @xmath52    where @xmath53 , @xmath54 and @xmath55 are positive numbers .",
    "the quadratic constraint is equivalent to the usual restriction to binary variables .",
    "the following transformation is proposed ,    @xmath56 ) } \\\\",
    "\\nonumber + k_1 \\frac { exp\\left ( b_1 [ \\sum_{n=1}^{n } w_n x_n - c ] \\right ) - 1 } { exp\\left ( -b_2 [ \\sum_{n=1}^{n } w_n x_n - c ] \\right ) + 1 } \\\\ \\nonumber s. t. \\quad 0 \\leq x_n \\leq 1,\\end{aligned}\\ ] ]    for illustrative purposes , consider the instance @xmath57 , @xmath58 , @xmath59 of the knapsack problem . by inspection ,",
    "the solution is given by @xmath60 .",
    "in fig . [ ilustkp ]",
    "typical densities produced by the estimation algorithm for this instance are shown .",
    "the selection of the parameters has been done after the performance of short runs , measuring the effects of each of the nonlinear terms .",
    "the parameters have been tuned such that : * a ) * the first nonlinear term alone produce symmetric densities peaked in the neighborhood of @xmath61 . *",
    "b ) * the addition of the second nonlinear term and the original cost function generate densities in which the configurations with maximum probabilty satisfy the @xmath62 constraint .",
    "notice that the configuration that corresponds to the global optimum has the maximum probability .",
    "0.5 cm     0.15 cm   0.15 cm     a larger example is presented in fig .",
    "the exact solution has been calculated with the branch and bound algorithm supplied in the gnu linear programming kit @xcite .",
    "the instance has been generated by taking @xmath54 uniformily distributed in an interval @xmath63 $ ] , and    @xmath64 , \\end{aligned}\\ ] ]    which imply strong linear correlations between @xmath53 and @xmath54 .",
    "instances of this kind are relevant to real management problems in which the return of an investment is proportional to the sum invested within small variations @xcite .",
    "it has been argued that these type of instances fall in a category which is close to the `` worst case '' scenario for exact algorithms @xcite . despite of that",
    ", the estimation method converge to densities in which the optimum is contained in a region with high probability .",
    "moreover , from the definition of the normalized distance , follows that the closest integers to the elements of the vector that represent the point of maximum probability differ in @xmath65 positions from the exact solution .    0.5 cm        three independent realizations of the numerical experiment over instances generated by eq .",
    "( [ instance ] ) have been performed , varying the orders of magnitude of @xmath66 and @xmath55 .",
    "the results are summarized in table 1 , indicating the number of @xmath67 flips that the normalized distances imply .",
    "@rrrrrrrrrrrrr 1c@xmath66&1c@xmath55 & 1c@xmath68&1c@xmath69 & 1c@xmath70&1c@xmath71&1c@xmath72 & 1c@xmath73&1c@xmath18&1c@xmath6 & 1cinterval gap @xmath74 & @xmath75 & @xmath74 & @xmath76 & @xmath74 & @xmath50 & @xmath77 & @xmath78 & @xmath75 & @xmath79 & @xmath80/@xmath81 @xmath82/@xmath79 @xmath75 & @xmath83 & @xmath75 & @xmath84 & @xmath74 & @xmath85 & @xmath86 & @xmath78 & @xmath75 & @xmath87 & @xmath88/@xmath89 @xmath90/@xmath91 @xmath92 & @xmath93 & @xmath92 & @xmath94 & @xmath74 & @xmath95 & @xmath86 & @xmath78 & @xmath75 & @xmath75 & @xmath96/@xmath89 @xmath97/@xmath98    it should be remarked that , although the instances of the knapsack model discussed in this section are quickly solvable by exact algorithms , no reference to the particular structure of the original problem has been used for the density estimation .",
    "in fact , the problem has been treated like a highly nonlinear cost function of @xmath99 variables .",
    "the potential benefits of the stationary density estimation algorithm as a tool for the construction of new heuristics for high dimensional global optimization problems is illustrated through the following greedy random search procedure :    \\1 ) run an iteration of the stationary density estimation algorithm .",
    "\\2 ) an initial best point is given by the global maximum of the estimated density    \\3 ) define a population of @xmath100 points .",
    "one point is the current best solution and other is the current point with maximum probability density .",
    "the remaining @xmath101 points are randomly drawn from an uniform distribution centered around the best point .",
    "for each dimension , the corresponding uniform distribution has a length equal to the typical fluctuation size given by the estimated density .",
    "\\4 ) run a downhill simplex routine .",
    "the starting conditions are given by the simplex defined by the points generated at step 3 as vertices .",
    "\\5 ) if from step 4 results a point which improves the best known objective value , then update the best point .",
    "\\6 ) run an iteration of the density estimation algorithm .",
    "\\7 ) go to step 3 .    from an evolutionary perspective , the above procedure acts at two different levels . at a short time",
    "scale finite populations evolve locally in a very greedy fashion .",
    "on the other hand , large changes on the population composition are dictated by a long time scale dynamics , which is consistent with the learned information about the global cost landscape .",
    "this information is gained through the approximation of the long term statistical density of a diffusive search process .",
    "the short time scale exploration of the solution space is dominated by the downhill simplex method , which is a deterministic search based on function evaluations of a simplex vertices @xcite . in a @xmath4 dimensional search space ,",
    "a population of @xmath100 points defined by the corresponding @xmath100 vertices evolve under simple geometric transformations , namely reflection , expansion and contraction . at each iteration ,",
    "a new trial point is generated by the image of the worst point in the simplex ( reflection ) .",
    "if the new point is better than all other vertices , the simplex expands in its direction . if the trial point improves the worst point , a reflection from the new worst point is performed .",
    "a contraction step is made when the worst point is at least as good as the reected point . in this way",
    "the simplex eventually surrounds a local minimum . in the experiments presented here ,",
    "the implementation of the downhill simplex given by @xcite has been used , with a fractional decrease of cost value of at least @xmath102 as termination criteria . a maximum of @xmath103 function evaluations in the downhill simplex routine is allowed .    from a given reference point @xmath104 , an initial simplex for each call to the downhill simplex routine",
    "is defined through the characteristic length scales @xmath105 , as @xmath106 where the @xmath107 are @xmath4 unit vectors .",
    "the estimated long term density provides a vertex ( the point with maximum likelihhood at the current stage ) and most importantly , typical fluctuation sizes , denoted by @xmath108 .",
    "these are given by the first two moments of the estimated density ,    @xmath109    due to the simple form of the expansion of the estimated density , all the integrals over the variables domain that are needed for moment calculation are performed analitically .",
    "the resulting expressions are finite sums with @xmath18 terms .",
    "the typical fluctuation sizes ( [ sigma ] ) provide a natural definition for the characteristic length scales @xmath105 , in the sense expressed in step ( 3 ) of the greedy diffusive search described above .    for illustration purposes ,",
    "consider the rosenbrock test function . in fig.[rosen2 ] are presented some plots of the beahavior of our greedy stochastic search for the rosenbrock problem of @xmath110 variables .",
    "the graphs represent the cost function values over successive iterations .",
    "four samples from a total of @xmath75 runs are plotted .",
    "the result of a version of the algorithm in which an uniform density over the search space is used instead of the estimated long term density is also plotted .",
    "the success in finding the optimum is defined by a gap size with the known global optimum lesser than @xmath85 .",
    "each run consist of @xmath75 iterations . over the total number of runs of the greedy stochastic search ,",
    "@xmath111 have been successful , and the @xmath112 of the runs outperform the search based on uniform distributions .",
    "an @xmath113 of the runs have been successful in less than @xmath114 iterations and @xmath115 in less than @xmath116 iterations . for the @xmath116 iterations cases ,",
    "an average number of @xmath117 cost function evaluations was needed .",
    "it should be remarked that the @xmath51-dimensional rosenbrock test function has been reported to be extremely difficult to solve by randomized optimization algorithms .",
    "for instance , in an experiment similar to the one presented here , it has been reported in @xcite a success rate of zero after @xmath118 function evaluations for simulated annealing , cross  entropy and model reference adaptive search . on the other hand , in @xcite",
    "is reported that genetic algorithms and scatter search methods are unable to succeed in the @xmath51-dimensional rosenbrock problem after @xmath103 cost function evaluations .",
    "0.5 cm        a more exhaustive experimentation with possible heuristics based on the stationary density estimation algorithm is in progress .",
    "the presented results strongly suggest that the proposed density estimation algorithm can be used to construct probabilistic bounds on the location of global optima for large classes of problems .",
    "the density estimation is performed in a well defined number of elementary operations . the developed theory and",
    "the numerical experiments indicate that any given desired precision on the bounds can be attained with some finite values of the basic parameters , performing a finite number of iterations .",
    "the total computational cost per iteration grows linearly with problem size .",
    "the algorithm estimates the marginal density of each separate variable , which makes it suitable for parallel implementation .",
    "these features make the proposed method a promising tool , opening the possibility of constructing probabilistic optimal certificates for large scale unstructured problems .",
    "experimentation in this direction is in progress . on the other hand ,",
    "the density estimation algorithm may be used to develop new heuristics or improve existing stochastic or deterministic algorithms .",
    "this work was partially supported by the national council of science and technology of mexico under grant conacyt j45702-a .",
    "10                                            laguna , m and mart , r _ experimental testing of advanced scatter search designs for global optimization of multimodal functions .",
    "journal of global optimization _ , 2005 journal of global optimization * 33 * 2 235 - 255 ."
  ],
  "abstract_text": [
    "<S> a method for the construction of approximate analytical expressions for the stationary marginal densities of general stochastic search processes is proposed . by the marginal densities , regions of the search space that with high probability contain the global optima </S>",
    "<S> can be readily defined . </S>",
    "<S> the density estimation procedure involves a controlled number of linear operations , with a computational cost per iteration that grows linearly with problem size .    </S>",
    "<S> _ keywords _ : stochastic search , heuristics </S>"
  ]
}