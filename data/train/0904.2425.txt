{
  "article_text": [
    "there are many situations where data from a variety of different experiments must be fitted to a single underlying theory that has many free parameters .",
    "the particular instance that led to this work is the measurement of parton distribution functions ( pdfs ) , which describe momentum distributions of quarks and gluons in the proton @xcite .    in these situations",
    ", it would be desirable to assess the consistency between the full body of data and individual subsets of it , such as data from a particular experiment , or data that rely on a particular technique , or data in which a particular kind of theoretical or experimental systematic error is suspected .",
    "it would also be desirable to characterize which parameters in the fit are determined by particular components of the input data .",
    "this paper presents a `` data set diagonalization '' ( dsd ) procedure that answers both of those desires .",
    "the quality of the fit of a theory to a set of data is measured by a quantity  @xmath0 , which in simplest form is given by @xmath1 where @xmath2 and @xmath3 represent a data point and its uncertainty , and @xmath4 is the theoretical prediction .",
    "( although ( [ eq : chisqdef ] ) is standard practice , some alternatives might be worth consideration @xcite . )",
    "the predictions @xmath4 in eq .",
    "( [ eq : chisqdef ] ) depend on a number of parameters @xmath5 . the best - fit estimate for those parameters",
    "is obtained by adjusting them to minimize @xmath0 .",
    "the uncertainty range is estimated as the neighborhood of the minimum in which @xmath0 lies within a certain `` tolerance criterion '' @xmath6 above its minimum value .",
    "if the errors in the data are random and gaussian with standard deviations truly given by @xmath3 , and the theory is without error , the appropriate @xmath6 can be related to confidence intervals by standard statistical methods .",
    "those premises do not hold in the application of interest here ; but the tolerance range can be estimated by examining the stability of the fit in response to applying different weights to subsets of the data @xcite .    sufficiently close to its minimum , @xmath0 is an approximately quadratic function of the parameters @xmath5 . using the eigenvectors of the matrix that defines that quadratic form as basis vectors in the @xmath7-dimensional parameter space",
    ", one can define new theory parameters @xmath8 which are linear combinations of the original ones @xmath9 and which transform @xmath0 into the very simple form @xmath10 formally , the transformation matrix @xmath11 can be computed by evaluating the hessian matrix @xmath12 at the minimum using finite differences , and computing its eigenvectors .",
    "the new parameters @xmath13 are then just coefficients that multiply those eigenvectors when the original coordinates @xmath5 are expressed as linear combinations of them . in the pdf application ,",
    "this straightforward procedure breaks down because the eigenvalues of the hessian span a huge range of magnitudes , which makes non - quadratic behavior complicate the finite - difference method at very different scales for different directions in parameter space .",
    "however , this difficulty can be overcome by an iterative technique @xcite that is reviewed in the appendix .",
    "the linear transformation ( [ eq : lineartrans ] ) that leads to ( [ eq : diagchi ] ) is not unique , since any further orthogonal transform of the coordinates @xmath13 will preserve that form .",
    "such an orthogonal transformation can be defined using the eigenvectors of any symmetric matrix .",
    "after this second linear transformation of the coordinates , the chosen symmetric matrix will be diagonal together with @xmath0 .",
    "the second transformation can be combined with the first to yield a single overall linear transformation of the form ( [ eq : lineartrans ] ) .",
    "thus there is a freedom to diagonalize an additional symmetric matrix while maintaining the simple form ( [ eq : diagchi ] ) for @xmath0 .",
    "that symmetric matrix can be taken from the matrix of second derivatives that appears when the variation of any function of the fitting parameters is expanded in taylor series through second order .",
    "_ thus it is possible within the quadratic approximation to diagonalize any one chosen function of the fitting parameters , while maintaining the diagonal form for @xmath0 .",
    "_ an explicit recipe for this `` rediagonalization '' procedure is given in the appendix .",
    "the freedom to diagonalize an additional quantity along with @xmath0 can be exploited in several ways :    1 .   the traditional approach in which one only diagonalizes the hessian matrix is formally equivalent to also diagonalizing the displacement distance @xmath14 from the minimum point in the space of the original fitting parameters : @xmath15 in this approach",
    ", the final eigenvectors can usefully be ordered by their eigenvalues , from `` steep '' directions in which @xmath0 rises rapidly with @xmath14 , to `` flat '' directions in which @xmath0 varies very slowly with @xmath14 .",
    "this option has been used in the iterative method that was developed for previous cteq pdf error analyses @xcite .",
    "2 .   one can diagonalize the contribution to @xmath0 from any chosen subset @xmath16 of the data .",
    "this option is the basis of the dsd procedure , which is described in the next section and applied in the rest of the paper .",
    "3 .   one can diagonalize some quantity @xmath17 that is of particular theoretical interest , such as the prediction for some unmeasured quantity . in this way",
    ", one might find that a small subset of the eigenvectors is responsible for most of the range of possibilities for that prediction , which would simplify the application of the hessian method .",
    "an example of this was given in a recent pdf study @xcite .",
    "however , there is no guarantee in general that the diagonal form will be dominated by a few directions with large coefficients ( @xmath18 and/or @xmath19 in eq .",
    "( [ eq : mainresult ] ) of the appendix ) . hence a better scheme to reduce the number of important eigenvectors",
    "might well be to simply choose the new @xmath20 along the gradient direction @xmath21 , and then to choose the new @xmath22 along the orthogonal direction that carries the largest residual variation , etc .",
    "let us diagonalize the contribution @xmath23 from some chosen subset @xmath16 of the data .",
    "that puts its contribution to the total @xmath0 into a diagonal form @xmath24 while preserving ( [ eq : diagchi ] ) , as is derived in the appendix . the contribution @xmath25 from the remainder of the data @xmath26 is then similarly diagonal .    if the parameters @xmath19 all lie in the range @xmath27 , eqs .",
    "( [ eq : diagchi ] ) and ( [ eq : newdiag ] ) can be written in the form @xmath28 these equations have an obvious interpretation that is the basis of the dsd method : _ in the new coordinates , the subset @xmath16 of the data and its complement @xmath26 take the form of independent measurements of the @xmath7 variables @xmath13 _ in the quadratic approximation .",
    "the results from eq .",
    "( [ eq : betagamma ] ) can be read as @xmath29 where @xmath30    eqs .",
    "( [ eq : centralresult1])([eq : centralresult2 ] ) provide a direct assessment of the compatibility between the subset @xmath16 and the rest of the data @xmath31 . for",
    "if gaussian statistics can be used to combine the uncertainties in quadrature , the difference between the two measurements of @xmath13 is @xmath32 this leads to a chi - squared measure of the overall difference between @xmath16 and @xmath26 along direction @xmath13 : @xmath33 ( the symmetry of ( [ eq : centralmeasurements ] ) under the interchange @xmath34 reflects the obvious symmetry @xmath35 . ) even in applications where gaussian statistics can not be assumed , the variables @xmath13 are natural quantities for testing the compatibility of @xmath16 with the rest of the data .",
    "( [ eq : centralresult1])([eq : centralresult2 ] ) also directly answer the question _ `` what is measured by the subset @xmath16 of data ? '' .",
    "_ for , provided @xmath16 is compatible with its complement , the variables @xmath13 that are significantly measured by @xmath16 are those for which the uncertainty @xmath36 from @xmath16 is less than or comparable to the uncertainty @xmath2 from @xmath26 .",
    ".ratio between @xmath36 = uncertainty from @xmath16 and @xmath2 = uncertainty from @xmath26 , for various @xmath37 . [ cols=\"^,^\",options=\"header \" , ]     -10pt    the dsd method can also be used to discover which aspects of a global fit are determined by particular subsets of the data .",
    "an example of this is illustrated by fig .",
    "[ fig : figfour ] , which shows the gluon distribution at qcd scale @xmath38 , for pdf sets corresponding to displacements @xmath39 along each eigenvector direction of the cdf+d0 fit .",
    "most of the uncertainty is seen to come from the @xmath20 and @xmath22 directions , which are the directions found above to be controlled by the jet data .",
    "this directly confirms the conclusion of @xcite that the jet data are the major source of information about the gluon distribution for @xmath40 .",
    "a `` data set diagonalization '' ( dsd ) procedure has been presented , which extends the hessian method @xcite for uncertainty analysis .",
    "the procedure identifies the directions in parameter space along which a given subset @xmath16 of data provides significant constraints in a global fit .",
    "this allows one to test the consistency between @xmath16 and the remainder of the data , and to discover which aspects of the fit are controlled by @xmath16 .",
    "the procedure involves `` rediagonalizing '' @xmath0 to obtain a new set of fitting parameters @xmath41 that are linear combinations of the original ones .",
    "the data from a given experiment or other chosen subset @xmath16 of the data and its complement @xmath26 take the form of independent measurements of these new parameters , within the scope of the quadratic approximation .",
    "the degree of consistency between @xmath16 and @xmath26 can thus be examined by standard statistical methods .",
    "the dsd method can be used to study the internal consistency of a global fit , by applying it with @xmath16 defined by each experimental data set in turn .",
    "one can also let @xmath16 correspond to subsets of the data that are suspected of being subject to some particular kind of unquantified systematic error . a full systematic study of the parton distribution fit using the new technique is currently in progress .",
    "typical applications of the new technique have been illustrated in the context of measuring parton distribution functions .",
    "the method uncovered and quantified tension between the two inclusive jet experiments , and between one of those experiments and the non - jet data , that was difficult to detect using the older methods , which are based on tracking the effect on @xmath0 for @xmath16 and @xmath26 in response to changing the weight assigned to @xmath16 @xcite .",
    "the dsd method can be also be used to identify which features of the fit are controlled by particular experiments or other subsets of the data in a complex data set . as an example of this",
    ", the jet experiments were shown to be the principal source of information on the gluon distribution in the region displayed in fig .",
    "[ fig : figfour ] .",
    "the logic is as follows : fig .",
    "[ fig : figfour ] shows that the uncertainty of the gluon distribution is dominated by eigenvector directions 1 and 2 when @xmath16 is defined as the jet data ; and the range of acceptable fits along those directions is constrained mainly by the jet data according to fig .",
    "[ fig : figtwo ] or table [ table : table5 ] .",
    "i am grateful to my late colleague and friend wu - ki tung for the pleasure of many discussions on these issues .",
    "this research was supported by national science foundation grant phy-0354838 .",
    "this appendix describes details of the procedure that simultaneously diagonalizes the coordinate dependence of @xmath0 and one additional quantity within the quadratic approximation .",
    "the procedure was first described in appendix b of @xcite , but its significance was not recognized in that paper .    the hessian method is based on the quadratic expansion of @xmath42 in the neighborhood of the minimum that defines the best fit to the data : @xmath43 where @xmath44 is the displacement @xmath45 from the minimum in the original parameter space , and the hessian matrix is defined by @xmath46 ( the hessian matrix is usually defined without the overall factor 1/2 , but the normalization used here is more convenient for present purposes . ) eq .",
    "( [ eq : app1 ] ) follows from taylor series in the neighborhood of the minimum .",
    "it contains no first - order terms because the expansion is about the minimum , and terms smaller than second order have been dropped according to the quadratic approximation .",
    "since @xmath47 is a symmetric matrix , it has a complete set of @xmath7 orthonormal eigenvectors @xmath48 : @xmath49 the eigenvalues @xmath50 are positive because the best fit must be at a minimum of @xmath0 . multiplying ( [ eq : app3a ] ) by @xmath51 and summing over @xmath52 yields @xmath53 we can define a new set of coordinates @xmath54 that describe displacements along the eigenvector directions : @xmath55 then @xmath56    any additional function @xmath17 of the original coordinates @xmath57 can also be expressed in terms of the new coordinates @xmath54 and expanded by taylor series through second order : @xmath58 the symmetric matrix @xmath59 , like @xmath47 , has a complete set of orthonormal eigenvectors @xmath60 :      from which it follows that @xmath62 defining new coordinates @xmath41 by @xmath63 now leads to @xmath64 where @xmath65 _ hence both @xmath0 and @xmath17 are diagonal in the new coordinates @xmath41 _ in the quadratic approximation .",
    "( [ eq : newdiag ] ) , which is the basis of this paper , follows immediately from ( [ eq : mainresult ] ) by choosing @xmath17 to be the contribution to @xmath0 from the subset @xmath16 of the data .    because non - quadratic behavior appears at widely different scales in different directions of the original parameter space , and because the second - derivative matrices are calculated numerically by finite differences , it is actually necessary to compute the linear transformation from the old coordinates @xmath66 to the new coordinates @xmath41 by a series of iterations @xcite .",
    "this is done as follows .",
    "the procedure described above yields a coordinate transformation @xmath11 defined by @xmath67 the coordinates @xmath41 can be treated as `` old '' coordinates and the above steps repeated to obtain a refined set of elements for the matrix @xmath11 . this process is iterated a few times to obtain the final form of the transformation .",
    "the iterative method is simple to program : each iteration begins with an estimate of the desired transformation matrix @xmath11 in ( [ eq : transform ] ) and ends with an improved version of @xmath11 .",
    "one can start with the unit matrix @xmath68 and iterate until the matrix @xmath11 stops changing .",
    "this procedure has been found to converge in all of the applications for which it has been tried .",
    "the distance moved away from the minimum in the original coordinate space is given by @xmath69 which corresponds to the choice @xmath70 in the iterative scheme .",
    "this choice produces eigenvector directions that are characterized by how rapidly @xmath0 changes in the original parameter space , leading to a clear distinction between `` steep directions '' in which @xmath0 increases rapidly with displacement in the original parameters , and `` flat directions '' in which the @xmath0 increases only slowly .",
    "the degree of steepness or flatness is measured by the eigenvalues of @xmath59 .    in the pdf analysis ,",
    "a large number of free parameters are used in order to reduce the `` parametrization error '' caused by the need to represent unknown continuous parton distribution functions by approximations having a finite number of parameters . in that application ,",
    "the logarithms of the eigenvalues of @xmath59 are found to be roughly uniformly distributed , with the smallest and largest eigenvalues having a huge ratio . as a result , the iterative method has been found to be necessary even to carry out the conventional hessian analysis , where only @xmath0 needs to be diagonalized .",
    "j.  pumplin _ et al .",
    "_ , phys .",
    "d * 65 * , 014013 ( 2001 ) [ arxiv : hep - ph/0101032 ] ; d.  stump _ et al .",
    "_ , phys .",
    "d * 65 * , 014012 ( 2001 ) [ arxiv : hep - ph/0101051 ] .",
    "m.  nadolsky _ et al .",
    "_ , phys .  rev .",
    "d * 78 * , 013004 ( 2008 ) [ arxiv:0802.0007 [ hep - ph ] ] .",
    "j.  pumplin , j.  huston , h.l .",
    "lai , wu - ki tung and c .- p .",
    "yuan , `` collider inclusive jet data and the gluon distribution , '' [ arxiv:0904.2424 [ hep - ph ] ] .    a.  d.  martin , w.  j.  stirling , r.  s.  thorne and g.  watt , arxiv:0901.0002 [ hep - ph ] .",
    "the sum of quadratic deviations in eq .",
    "( [ eq : chisqdef ] ) is the natural measure of fit quality if the experimental errors are gaussian - distributed .",
    "if they are not gaussian , alternative forms might be worth considering in which extreme values of the deviation @xmath71 are assigned more weight ( e.g. , @xmath72 ) to force the fit toward describing every data point satisfactorily ; or more likely less weight ( e.g. , @xmath73 ) to downplay the influence of extreme outlying points .",
    "j.  c.  collins and j.  pumplin , `` tests of goodness of fit to multiple data sets , '' arxiv : hep - ph/0105207 . j.  pumplin , d.  r.  stump and w.  k.  tung , phys .  rev .",
    "d * 65 * , 014011 ( 2001 ) [ arxiv : hep - ph/0008191 ] .",
    "g.  moreno _ et al .",
    "_ , phys .",
    "d * 43 * , 2815 ( 1991 ) .",
    "t.  aaltonen _ et al .",
    "_ [ cdf collaboration ] , phys .  rev .",
    "d * 78 * , 052006 ( 2008 ) [ arxiv:0807.2204 [ hep - ex ] ] .",
    "v.  m.  abazov _ et al . _",
    "[ d0 collaboration ] , phys .",
    ".  lett .",
    "* 101 * , 062001 ( 2008 ) [ arxiv:0802.2400 [ hep - ex ] ] ."
  ],
  "abstract_text": [
    "<S> the analysis of data sometimes requires fitting many free parameters in a theory to a large number of data points . </S>",
    "<S> questions naturally arise about the compatibility of specific subsets of the data , such as those from a particular experiment or those based on a particular technique , with the rest of the data . questions also arise about which theory parameters are determined by specific subsets of the data . </S>",
    "<S> i present a method to answer both of these kinds of questions . </S>",
    "<S> the method is illustrated by applications to recent work on measuring parton distribution functions . </S>"
  ]
}