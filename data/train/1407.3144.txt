{
  "article_text": [
    "_ graph analytics _ is rapidly establishing itself as a major discovery tool in such diverse application domains as road systems , social networks , natural language processing , biological pattern discovery , cybersecurity , and more .",
    "graph analytics tasks for big data networks are typically run on distributed architectures such as clusters of loosely - coupled commodity servers , where the challenge is to minimize communication overhead between processors , while each processor can store only a small fraction of the entire network .",
    "a number of computational models proposed in recent years @xcite provide excellent rigorous frameworks for studying algorithms for massive data , subject to these constraints . under this new computational paradigm ,",
    "state - of - the - art graph algorithms often do not scale up efficiently to process massive instances , since they either require superlinear memory or exhibit long critical paths resulting in a large number of communication rounds .    in this work we focus on _ graph decomposition _",
    ", which is a fundamental primitive for graph analytics as well as for several other application contexts , especially in distributed settings , where decompositions are often at the base of efficient parallel solutions .",
    "we develop an efficient parallel decomposition algorithm for partitioning the nodes of an unweighted , undirected graph into disjoint , internally connected _ clusters _ , which is able to control the maximum radius of the clusters ( the maximum distance of a node in a cluster to the cluster s center ) .",
    "similarly to other known decomposition approaches , our algorithm grows clusters from several batches of centers which are progressively selected from the uncovered nodes .",
    "however , rather than fixing the radius of each grown cluster _ a priori _ , or randomly delaying the activation of the centers , as in previous works , we activate a new batch of centers every time that the number of uncovered nodes halves , while continuing growing the clusters of previously activated centers .",
    "the idea behind such a strategy is to force more clusters to grow in poorly connected regions of the graph while keeping both the total number of clusters and the maximum cluster radius under control .    in the _",
    "metric @xmath0-center _ clustering problem  @xcite the goal is to partition an undirected graph into @xmath0 clusters so that the maximum radius of the clusters is minimized .",
    "the problem is np - hard and we are therefore interested in efficient approximations . given an @xmath1 node unweighted undirected graph , building on our parallel graph decomposition method , we obtain a randomized @xmath2-approximation algorithm to the @xmath0-center problem .",
    "the algorithm can be implemented on the mapreduce ( mr ) model of @xcite in a number of parallel rounds proportional to the maximum cluster radius using overall linear space , as long as each processing node is provided with @xmath3 local space , for any constant @xmath4 . in order to derive a more explicit bound on the parallel complexity",
    ", we analyze the maximum cluster radius , hence the number of rounds , as a function of the doubling dimension of the graph ( see definition  [ doublingdim ] ) , showing that for a graph of diameter @xmath5 and doubling dimension @xmath6 the algorithm can provide a decomposition into @xmath0 clusters with maximum cluster radius @xmath7 .",
    "next , we apply our graph decomposition strategy to a challenging problem in the context of graph analytics , namely , the approximation of the graph diameter , a global property of a graph , in a number of parallel rounds which is substantially less than the diameter itself , and using linear global space and local memory at each processor sufficient to store only a small fraction of the graph .",
    "we remark that known parallel approaches to estimating the diameter of a graph either require up to quadratic space ( e.g. , using transitive closure ) or require a number of parallel rounds which is inherently linear in the diameter ( e.g. , using straightforward parallelization of breadth - first search or neighborhood function estimations ) .    to estimate the diameter of a graph @xmath8 , we first compute a decomposition of @xmath8 of suitable granularity with our novel algorithm , and then we estimate the diameter through the diameter of the _ quotient graph _ , that is , the graph whose nodes correspond to the clusters and whose edges connect clusters containing nodes which are adjacent in @xmath8 . the granularity is chosen so that the size of the quotient graph is small enough so that its diameter can be computed using limited local memory and very few communication rounds .",
    "we show that on any unweighted , undirected connected graph @xmath8 with @xmath1 nodes and @xmath9 edges , our algorithm returns an upper bound to its diameter which is a factor @xmath2 away from the true value , with high probability .",
    "the algorithm can be implemented on the aforementioned mr model using overall linear space and @xmath3 local space , with @xmath10 , in a number of parallel rounds which is @xmath11 where @xmath12 is the doubling dimension of the graph and @xmath13 is any constant less than @xmath14 .",
    "observe that for graphs with small ( e.g. , constant ) doubling dimension , which arise in important practical realms @xcite , the number of rounds can be made asymptotically much smaller than the diameter if sufficient yet sublinear local memory is available . while a similar approach for diameter estimation has been used in the past in the external - memory setting ( see section  [ previouswork ] ) , the algorithm presented here , to the best of our knowledge , is the first linear - space distributed algorithm for the problem requiring a number of parallel rounds which is sublinear in the diameter .",
    "a very desirable feature of our algorithms is that they lend themselves to efficient practical implementations .",
    "we report on an extensive set of experiments conducted on a number of large graphs .",
    "a first batch of experiments shows the effectiveness of our decomposition strategy in minimizing the maximum cluster radius , compared against the recent parallel decomposition strategy of @xcite , while a second batch shows that the approximation obtained by our diameter approximation algorithm is in fact much smaller than the asymptotic bound , even for graphs of unknown doubling dimension ( less than twice the diameter in all tested cases ) and that the algorithm s performance compares very favorably to the one exhibited by direct competitors such as breadth - first search and the ( almost exact ) diameter estimation algorithm hadi @xcite .",
    "for graphs of very large diameter , the speed - up of our algorithm can be of orders of magnitude .",
    "the rest of the paper is organized as follows .",
    "section  [ previouswork ] summarizes relevant previous work on graph decomposition , @xmath0-center clustering , and diameter estimation .",
    "section  [ clustering ] presents our novel decomposition and discusses how it can be employed to approximate the @xmath0-center problem .",
    "section  [ diameter ] presents our decomposition - based algorithm for diameter approximation .",
    "section  [ mrimplementation ] analyzes our strategies in the mr model of @xcite .",
    "section  [ experiments ] reports on the experimental results , and , finally , section  [ conclusions ] offers some concluding remarks .",
    "parallel clustering algorithms relevant to this work have been studied in @xcite . in @xcite",
    "the notion of @xmath15-cover for a weighted graph @xmath8 is introduced , which is essentially a decomposition of the graph into nondisjoint clusters , where each node is allowed to belong to @xmath16 distinct clusters and for any two nodes at weighted distance at most @xmath17 in the graph , there is a cluster containing both .",
    "a @xmath15-cover is obtained by growing clusters of decreasing radii from successive batches of centers .",
    "the algorithm presented in @xcite is similar but returns disjoint clusters and guarantees a bound on the average number of edges between clusters . in @xcite",
    "an alternative clustering algorithm is proposed which assigns to each node @xmath18 a random time shift @xmath19 , taken from an exponential distribution with parameter @xmath20 , and grows a cluster centered at @xmath21 starting at time @xmath22 , where @xmath23 is the maximum shift , unless by that time node @xmath21 has been already covered by some other cluster .",
    "the authors show that in this fashion the graph is partitioned into clusters of maximum radius @xmath24 , with high probability , while the average number of edges between clusters , hence the size of the quotient graph , is at most @xmath25 . none of the above clustering approaches guarantees that the maximum radius of the returned clusters is ( close to ) minimum with respect to all possible decompositions of the graph featuring the same number of clusters .",
    "the related _ metric @xmath0-center _ optimization problem requires that given a set @xmath26 of @xmath1 points in a metric space , a subset @xmath27 of @xmath0 points be found so to minimize the maximum distance between any @xmath28 and @xmath29 .",
    "the problem is np - hard even if distances satisfy the triangle inequality @xcite , but polynomial - time 2-approximation sequential algorithms are known @xcite .",
    "recently , a constant - approximation mapreduce algorithm was developed in @xcite under the assumption that the distances among all @xmath30 pairs of points are given in input .",
    "the problem remains np - hard even if @xmath26 represents the set of nodes of an undirected connected graph @xmath8 , and the distance between two nodes is the length of the shortest path between them . to the best of our knowledge ,",
    "no low - depth linear - space parallel strategy that yields a provably good approximation for this important graph variant is known in the literature .    in recent years",
    ", efficient sequential algorithms for estimating the diameter of very large graphs have been devised , which avoid the costly computation of all - pairs shortest paths or the memory - inefficient transitive closure by performing a limited number of breadth - first searches ( bfs ) from suitably selected source nodes @xcite .",
    "unfortunately , due to the inherent difficulty of parallelizing bfs @xcite these approaches do not appear amenable to efficient low - depth parallel implementations .",
    "external - memory algorithms for diameter estimation which employ a clustering - based strategy similar to ours have been recently proposed in @xcite .",
    "the algorithm by @xcite basically selects @xmath0 centers at random and grows disjoint clusters around the centers until the whole graph is covered .",
    "the author shows that the diameter of the original graph can be approximated within a multiplicative factor of @xmath31 , with high probability , by computing the diameter on the quotient graph associated with the clustering with suitable edge weights . in @xcite",
    "a recursive implementation of this strategy is evaluated experimentally .",
    "this approximation ratio is competitive with our result only for polylogarithmic values of @xmath0 .",
    "however , observe that for such small values of @xmath0 the radius of the @xmath0 clusters must be within a small ( polylogarithmic ) factor of the graph diameter , and thus the parallel number of rounds can not be substantially sublinear in the diameter itself .",
    "efficient pram algorithms for approximating shortest path distances between given pairs of nodes are given in @xcite .",
    "for sparse graphs with @xmath32 , these algorithms feature @xmath33 depth , for any fixed constant @xmath34 , but incur a polylogarithmic space blow - up due to the use of the @xmath15-covers mentioned above .",
    "the algorithms are rather involved and communication intensive , hence , while theoretically efficient , in practice they may run slowly when implemented on distributed - memory clusters of loosely - coupled servers , where communication overhead is typically high .",
    "moreover , their depth is not directly related to the graph diameter .    in @xcite , an efficient algorithm , called anf ,",
    "is devised to tightly approximate the _ neighborhood function _ of a graph @xmath8 , which , for every @xmath35 , gives the number of pairs of nodes at distance at most @xmath36 in @xmath8 , and , therefore , it can be used to estimate the diameter . on a connected graph @xmath8 of diameter @xmath5 , anf executes @xmath5 iterations and maintains at each node @xmath37 a suitable succinct data structure to approximate , at the end of each iteration @xmath36 , the number of nodes at distance at most @xmath36 from @xmath37 .",
    "a mapreduce implementation of anf , called hadi , has been devised in @xcite using apache hadoop .",
    "little experimental evidence of hadi s performance on large benchmark graphs is available .",
    "however , as confirmed by our experiments ( see section  [ experiments ] ) , for large - diameter graphs hadi s strategy , even if implemented using faster engines than hadoop , runs very slowly because of the large number of rounds and the high communication volume .",
    "a very fast , multithreaded version of anf , called hyperanf , has been devised in @xcite for expensive tightly - coupled multiprocessors with large shared memories , which are not the architectures targeted by our work .",
    "let @xmath38 be an undirected connected graph with @xmath39 nodes and @xmath40 edges .",
    "for any two nodes @xmath41 let @xmath42 denote the number of edges in the shortest path between @xmath21 and @xmath37 in @xmath8 .",
    "also , for any @xmath18 and @xmath43 , let @xmath44 denote the minimum distance between @xmath21 and a node of @xmath45 .",
    "we now present an algorithm ( cluster ) that partitions @xmath26 into disjoint clusters around suitably selected nodes called _ centers _",
    ", so that the radius of each cluster , defined as the maximum distance of a cluster node from the center , is small . as in @xcite ,",
    "our algorithm activates batches of centers progressively , so to allow more clusters to cover sparser regions of the graph .",
    "however , unlike those previous works , we can show that our algorithm minimizes the maximum cluster radius , within a polylogarithmic factor , a property that later will turn out crucial for the efficiency of the diameter - approximation algorithm .",
    "a parameter @xmath46 is used to control the size of each batch of activated centers .",
    "when two or more clusters attempt to cover a node concurrently , only one of them , arbitrarily chosen , succeeds , so to maintain clusters disjoint .",
    "the algorithm s pseudocode is given below .",
    "we define a crucial benchmark for analyzing each iteration of the algorithm .",
    "let @xmath0 be an integer , with @xmath47 , and let @xmath48 be a subset of at most @xmath49 nodes .",
    "we define @xmath50    suppose that we have partially grown some clusters covering a subset @xmath51 .",
    "we know that by continuing to grow these clusters plus @xmath0 new clusters centered in uncovered nodes , @xmath52 growing steps are necessary to cover the whole graph .",
    "we have :    [ thm1 ] for any integer @xmath53 , with high probability , cluster@xmath54 computes a partition of @xmath26 into @xmath55 disjoint clusters of maximum radius @xmath56 where @xmath57 , and @xmath58 for @xmath59 .",
    "the bound on the number of clusters follows by observing that the number of clusters added in each iteration is a binomial random variable with expectation @xmath60 , and that at most @xmath61 iterations are executed overall . as for the upper bound on @xmath62 , it is sufficient to show that in the @xmath63th iteration , with @xmath64 , the radius of each cluster ( new or old ) grows by @xmath65 , with high probability",
    ". let @xmath66 be the set of nodes that at the beginning of iteration @xmath63 are already covered by the existing clusters . by construction , we have that @xmath67 and , for @xmath68 , @xmath69 .",
    "hence , @xmath70 . let @xmath71 .",
    "it is easy to verify that @xmath72 by definition of @xmath73 we know that there must exist @xmath74 nodes , say @xmath75 , such that each node of @xmath76 is at distance at most @xmath77 from either @xmath66 or one of these nodes .",
    "let us consider the partition @xmath78 where @xmath79 is the set of nodes of @xmath76 which are closer to @xmath66 than to any of the @xmath80 s , while @xmath81 is the set of nodes of @xmath76 which are closer to @xmath80 than to @xmath66 or to any other @xmath82 .",
    "let @xmath83 and note that @xmath84 therefore , we have that @xmath85 .",
    "since @xmath86 , it is easy to see that for any @xmath87 and @xmath88 , in the @xmath63th iteration a new center will be chosen from @xmath81 with probability at least @xmath89 . hence , by the union bound , we conclude that a new center will fall in every @xmath81 with @xmath87 and @xmath88 , with probability at least @xmath90 .",
    "when this event occurs , @xmath91 cluster growing steps will be sufficient to reach half of the nodes of @xmath76 ( namely , the nodes belonging to @xmath92 .",
    "the theorem follows by applying the union bound over the @xmath93 iterations .",
    "an important issue , which is crucial to assess the efficiency of the diameter approximation algorithm discussed in the next section , is to establish how much smaller is the maximum radius @xmath62 of the clusters returned by cluster with respect to the graph diameter @xmath5 , which is an obvious upper bound to @xmath62 .",
    "our analysis will express the relation between @xmath62 and @xmath5 as a function of the _ doubling dimension _ of the graph , a concept that a number of recent works have shown to be useful in relating algorithms performance to graph properties  @xcite .",
    "[ doublingdim ] consider an undirected graph @xmath38 .",
    "the _ ball of radius @xmath94 _ centered at node @xmath37 is the set of nodes at distance at most @xmath94 from @xmath37 . also , the _ doubling dimension _ of @xmath8 is the smallest integer @xmath95 such that for any @xmath96 , any ball of radius @xmath97 can be covered by at most @xmath98 balls of radius @xmath94 .",
    "the following lemma provides an upper bound on @xmath62 in terms of the doubling dimension and of the diameter of the graph @xmath8 .",
    "[ radius - bound ] let @xmath8 be a connected @xmath1-node graph with doubling dimension @xmath12 and diameter @xmath5 . for @xmath99 , with high probability , cluster@xmath54 computes a partition of @xmath26 into @xmath100 disjoint clusters of maximum radius @xmath101    let @xmath102 be the smallest maximum radius achievable by any decomposition into @xmath74 clusters .",
    "it is easy to see that each @xmath103 is a lower bound to @xmath102 , whence @xmath104 . by iterating the definition of doubling dimension starting from a single ball of radius @xmath5 containing the whole graph",
    ", one can easily argue that @xmath8 can be decomposed into ( at most ) @xmath74 disjoint clusters of radius @xmath105 .",
    "the bound on @xmath62 follows since @xmath106 .",
    "observe that for graphs with diameter @xmath107 and low ( e.g. , constant ) doubling dimension , @xmath62 becomes @xmath108 when @xmath74 is large enough . indeed , some experimental work @xcite reported that , in practice , big data networks of interest have low doubling dimension . also , for applications such as the diameter estimation discussed in the next section , it is conceivable that parameter @xmath74 be made as large as @xmath109 , for some constant @xmath4 .",
    "in fact , the gap between the graph diameter and @xmath62 can be even more substantial for irregular graphs where highly - connected regions and sparsely - connected ones coexist .",
    "for example , let @xmath8 consist of a constant - degree expander of @xmath110 nodes attached to a path of @xmath111 nodes , and set @xmath112 .",
    "it is easy to see that @xmath113 , for @xmath64 .",
    "hence , cluster@xmath54 returns @xmath114 clusters of maximum radius @xmath115 , which is exponentially smaller than the @xmath116 graph diameter .      algorithm cluster can be employed to compute an approximate solution to the @xmath0-center problem , defined as follows . given an undirected connected graph @xmath117 with unit edge weights , a set @xmath118 of @xmath0 _ centers _ is sought which minimizes the maximum distance @xmath119 in @xmath8 of any node @xmath28 from @xmath29 . as mentioned in section  [ previouswork ] this problem is np - hard . the theorem below states our approximation result .",
    "[ k - center ] for @xmath120 , algorithm cluster can be employed to yield a @xmath121-approximation to the @xmath0-center problem with unit edge weights , with high probability .",
    "fix @xmath122 so that our algorithm returns at most @xmath0 clusters with high probability , and let @xmath29 be the set of centers of the returned clusters . without loss of generality , we assume that @xmath29 contains exactly @xmath0 nodes ( in case @xmath123 , we can add @xmath124 arbitrary nodes to @xmath29 , which will not increase the value of objective function ) .",
    "let @xmath62 be the maximum radius of the clusters returned by our algorithm .",
    "as proved in lemma  [ radius - bound ] , we have that , with high probability @xmath125 .",
    "we conclude the proof by arguing that @xmath126 .",
    "consider the optimal solution to the @xmath0-center problem on the graph , and the associated clustering of radius @xmath119 .",
    "let @xmath127 be a spanning tree of the quotient graph associated with this clustering .",
    "it is easy to see that @xmath127 can be decomposed into @xmath74 subtrees of height @xmath128 each .",
    "merge the clusters associated with the nodes of each such subtree into one cluster and pick any node as center of the merged cluster .",
    "it is easy to see that every node in the graph is at distance @xmath129 from one of the picked nodes . since @xmath130",
    ", we conclude that @xmath131 , and the theorem follows .",
    "let @xmath8 be an @xmath1-node graph with @xmath132 connected components .",
    "it is easy to see that for any @xmath133 , algorithm cluster@xmath54 works correctly with the same guarantees stated in theorem  [ thm1 ] .",
    "also , observe that for @xmath134 , the @xmath0-center problem still admits a solution with noninfinite radius .",
    "given @xmath135 , we can still get a @xmath2-approximation to @xmath0-center on @xmath8 as follows .",
    "if @xmath136 we simply run cluster@xmath54 with @xmath137 as before .",
    "if instead @xmath138 we run cluster@xmath139 and then reduce the number of clusters @xmath140 returned by the algorithm to @xmath0 by using the merging technique described in the proof of theorem  [ k - center ] .",
    "it is easy to show that the approximation ratio is still @xmath2 .",
    "let @xmath8 be an @xmath1-node connected graph .",
    "as in @xcite , we approximate the diameter of @xmath8 through the diameter of the quotient graph associated with a suitable clustering of @xmath8 . for the distributed implementation discussed in the next section , the clustering will be made sufficiently coarse so that the diameter of the quotient graph can be computed on a single machine . in order to ensure a small approximation ratio ,",
    "we need a refined clustering algorithm ( cluster2 ) , whose pseudocode is given in algorithm  [ alg : cluster2 ] , which imposes a lower bound on the number of growing steps applied to each cluster , where such a number is precomputed using the clustering algorithm from section  [ clustering ] .",
    "let @xmath46 be an integral parameter .",
    "we have :    [ correctness ] for any integer @xmath53 , with high probability algorithm cluster2@xmath54 computes a partition of @xmath26 into @xmath141 clusters of radius @xmath142 , where @xmath62 is the maximum radius of a cluster returned by cluster@xmath54 .",
    "the bound on @xmath143 is immediate .",
    "let @xmath17 be the number of clusters returned by the execution of cluster@xmath54 within cluster2@xmath54 .",
    "by theorem  [ thm1 ] , we have that @xmath144 , with high probability . in what follows",
    ", we condition on this event . for @xmath145 , define @xmath146 as the smallest integer such that @xmath147 , and let @xmath148 . for @xmath149 , define the event @xmath150 `` at the end of iteration @xmath151 of the * for * loop , at most @xmath152 nodes are still uncovered '' .",
    "we now prove that the event @xmath153 occurs with high probability .",
    "observe that @xmath154 since @xmath155 clearly holds with probability one .",
    "consider an arbitrary @xmath63 , with @xmath156 , and assume that @xmath157 holds .",
    "we prove that @xmath158 holds with high probability .",
    "let @xmath66 be the set of nodes already covered at the beginning of iteration @xmath151 .",
    "since @xmath159 holds , we have that @xmath160 . clearly ,",
    "if @xmath161 then @xmath158 must hold with probability one . thus , we consider only the case @xmath162 let @xmath163 and observe that since @xmath62 is the maximum radius of a partition of @xmath8 into @xmath17 clusters , we have that @xmath164 . by the definition of @xmath77 , there exist @xmath17 nodes , say @xmath165 , such that each node of @xmath76 is at distance at most @xmath77 from either @xmath66 or one of these nodes .",
    "let us consider the partition @xmath166 where @xmath79 is the set of nodes of @xmath76 which are closer to @xmath66 than to any of the @xmath80 s , while @xmath81 is the set of nodes of @xmath76 which are closer to @xmath80 than to @xmath66 or to any other @xmath82 ( with ties broken arbitrarily ) .",
    "let @xmath167 it is easy to see that @xmath168 .",
    "since we assumed that @xmath169 , we have that for every @xmath81 with @xmath170 , @xmath171 as a consequence , since @xmath145 , a new center will be chosen from @xmath81 in iteration @xmath151 with probability at least @xmath89 . by applying the union",
    "bound we conclude that in iteration @xmath151 a new center will fall in every @xmath81 with @xmath170 , and thus the number of uncovered nodes will at least halve , with probability at least @xmath172 .    by multiplying the probabilities of the @xmath173 conditioned events",
    ", we conclude that event @xmath153 occurs with high probability .",
    "finally , one can easily show that , with high probability , in the first @xmath146 iterations , @xmath174 clusters are added and , by conditioning on @xmath153 , at the beginning of each iteration  @xmath151 , @xmath175 , @xmath176 new clusters are added to @xmath177 , for a total of @xmath178 clusters .",
    "suppose we run cluster2 on a graph @xmath8 , for some @xmath179 , to obtain a set @xmath177 of clusters of maximum radius @xmath143 .",
    "let @xmath180 denote the quotient graph associated with the clustering , where the nodes correspond to the clusters and there is an edge between two nodes if there is an edge of @xmath8 whose endpoints belong to the two corresponding clusters .",
    "let @xmath181 be the diameter of @xmath180 .",
    "we have :    [ segment ] if @xmath5 is the true diameter of @xmath8 , then @xmath182 , with high probability .",
    "let us fix an arbitrary pair of distinct nodes and an arbitrary shortest path @xmath183 between them .",
    "we show that at most @xmath184 clusters intersect @xmath183 ( i.e. , contain nodes of @xmath183 ) , with high probability .",
    "divide @xmath183 into _ segments _ of length @xmath62 , and consider one such segment @xmath185 .",
    "clearly , all clusters containing nodes of @xmath185 must have their centers belong to nodes at distance at most @xmath143 from @xmath185 ( i.e. , distance at most @xmath143 from the closest node of @xmath185 ) .",
    "recall that @xmath186 . for @xmath187 ,",
    "let @xmath188 be the set of nodes whose distance from @xmath185 is between @xmath189 and @xmath190 , and observe that any cluster intersecting @xmath185 must be centered at a node belonging to one of the @xmath188 s .",
    "we claim that , with high probability , for any @xmath191 , there are @xmath192 clusters centered at nodes of @xmath188 which may intersect @xmath185 .",
    "fix an index @xmath191 , with @xmath187 , and let @xmath193 be the first iteration of the for loop of algorithm cluster2 in which some center is selected from @xmath188 .",
    "it is easy to see that , due to the smooth growth of the center selection probabilities , the number of centers selected from @xmath188 in iteration @xmath193 and in iteration @xmath194 is @xmath173 , with high probability .",
    "consider now a center @xmath37 ( if any ) selected from @xmath188 in some iteration @xmath195 . in order to reach @xmath185 ,",
    "the cluster centered at @xmath37 must grow for at least @xmath189 steps . however , since in each iteration active clusters grow by @xmath196 steps , by the time the cluster centered at @xmath37 reaches @xmath185 , the nodes of @xmath185 have already been reached and totally covered by clusters whose centers have been selected from @xmath188 in iterations @xmath193 and @xmath194 or , possibly , by some other clusters centered outside @xmath188 . in conclusion , we have that the nodes of segment @xmath185 will belong to @xmath197 clusters , with high probability .",
    "the theorem follows by applying the union bound over all segments of @xmath183 , and over all pairs of nodes in @xmath8 .",
    "let @xmath198 .",
    "it is easy to see that @xmath199 .",
    "moreover , since @xmath186 and @xmath200 , we have from theorem  [ segment ] that @xmath201 .",
    "the following corollary is immediate .",
    "[ diam - thm ] let @xmath8 be an @xmath1-node connected graph with diameter @xmath5 .",
    "then , the clustering returned by cluster2 can be used to compute two values @xmath202 such that @xmath203 , with high probability .    in order to get a tighter approximation , as in @xcite , after the clustering",
    "we can compute the diameter @xmath204 of the following weighted instance of the quotient graph @xmath205 . specifically , we assign to each edge @xmath206 a weight equal to the length of the shortest path in @xmath8 that connects the two clusters associated with @xmath21 and @xmath37 and comprises only nodes of these two clusters .",
    "it is easy to see that @xmath207 is an upper bound to the diameter @xmath5 of @xmath8 , and @xmath208 .",
    "it is important to remark that while in @xcite the approximation factor for the diameter is proportional to the square root of the number of clusters , with our improved clustering strategy the approximation factor becomes independent of this quantity , a fact that will also be confirmed by the experiments . as we will see in the next section , the number of clusters , hence the size of the quotient graph ,",
    "can be suitably chosen to reduce the complexity of the algorithm , based on the memory resources .",
    "as a final remark , we observe that the proof of theorem  [ segment ] shows that for any two nodes @xmath209 in @xmath8 their distance @xmath210 can be upper bounded by a value @xmath211 . as a consequence , by running cluster2@xmath54 with @xmath212 and computing the @xmath213-size all - pairs shortest - path matrix of the ( weighted ) quotient graph @xmath180 we can obtain a linear - space distance oracle for @xmath8 featuring the aforementioned approximation quality , which is polylogarithmic for farther away nodes ( i.e. , nodes at distance @xmath214 .",
    "we now describe and analyze a distributed implementation of the clustering and diameter - approximation algorithms devised in the previous sections , using the mapreduce ( mr ) model introduced in @xcite .",
    "the mr model provides a rigorous computational framework based on the popular mapreduce paradigm @xcite , which is suitable for large - scale data processing on clusters of loosely - coupled commodity servers .",
    "similar models have been recently proposed in @xcite .",
    "an mr algorithm executes as a sequence of _ rounds _ where , in a round , a multiset @xmath45 of key - value pairs is transformed into a new multiset @xmath215 of pairs by applying a given reducer function ( simply called _ reducer _ in the rest of the paper ) independently to each subset of pairs of @xmath45 having the same key .",
    "the model features two parameters @xmath216 and @xmath217 , where @xmath216 is the maximum amount of global memory available to the computation , and @xmath217 is the maximum amount of local memory available to each reducer .",
    "we use  to denote a given instance of the model .",
    "the complexity of an  algorithm is defined as the number of rounds executed in the worst case , and it is expressed as a function of the input size and of @xmath216 and @xmath217 . considering that for big input instances local and global space",
    "are premium resources , the main aim of algorithm design on the model is to provide strategies exhibiting good space - round tradeoffs for large ranges of the parameter values .",
    "the following facts are proved in @xcite .",
    "[ prefixsorting ] the sorting and ( segmented ) prefix - sum primitives for inputs of size @xmath1 can be performed in @xmath218 rounds in  with @xmath219 .",
    "[ matrixmult ] two @xmath220-matrices can be multiplied in @xmath221 rounds in .",
    "we can implement the sequence of cluster - growing steps embodied in the main loops of cluster and cluster2 as a progressive shrinking of the original graph , by maintaining clusters coalesced into single nodes and updating the adjacencies accordingly .",
    "each cluster - growing step requires a constant number of sorting and ( segmented ) prefix operations on the collection of edges .",
    "moreover , the assignment of the original graph nodes to clusters can be easily maintained with constant extra overhead . by using fact  [ prefixsorting ]",
    ", we can easily derive the following result .",
    "[ clusteringmr ] cluster ( resp . ,",
    "cluster2 ) can be implemented in the  model so that , when invoked on a graph @xmath8 with @xmath1 nodes and @xmath9 edges , it requires @xmath222 rounds , where @xmath94 is the total number of cluster - growing steps performed by the algorithm .",
    "in particular , if @xmath223 , for some constant @xmath4 , the number of rounds becomes @xmath224 .",
    "the diameter - approximation algorithm can be implemented in the  model by running cluster2@xmath54 for a value of @xmath74 suitably chosen to allow the diameter of the quotient graph to be computed efficiently .",
    "the following theorem shows the space - round tradeoffs attainable when @xmath217 is large enough .",
    "[ mr - diameter ] let @xmath8 be a connected graph with @xmath1 nodes , @xmath9 edges , doubling dimension @xmath225 and diameter @xmath5 .",
    "also , let @xmath226 be two arbitrary constants . on the  model , with @xmath227 and @xmath228 , an upper bound @xmath229 to the diameter of @xmath8",
    "can be computed in @xmath230 rounds , with high probability .",
    "fix @xmath231 so that cluster2@xmath54 returns @xmath232 clusters with high probability . ( in case the number of returned clusters is larger , we repeat the execution of cluster2 . )",
    "let @xmath205 be quotient graph associated with the returned clustering . if @xmath233 , we can compute the diameter of @xmath180 in one round using a single reducer .",
    "otherwise , by employing the sparsification technique presented in @xcite we transform @xmath180 into a new graph @xmath234 with @xmath235 , whose diameter is a factor at most @xmath236 larger than the diameter of @xmath180 .",
    "the sparsification technique requires a constant number of cluster growing steps similar in spirit to those described above , which can be realized through a constant number of prefix and sorting operations .",
    "hence , the transformation can be implemented in @xmath237 rounds in . once @xmath238 is obtained ,",
    "its diameter and the resulting approximation @xmath239 to @xmath5 can be computed in one round with a single reducer .",
    "therefore , by combining the results of lemmas  [ radius - bound ] , [ correctness ] , and  [ clusteringmr ] , we have that cluster@xmath54 runs in @xmath240 rounds , and cluster2@xmath54 runs @xmath241 rounds .",
    "hence , we have that the total number of rounds for computing @xmath239 is @xmath242 . alternatively , we can set @xmath243 so to obtain a quotient graph @xmath180 with @xmath244 nodes .",
    "we can compute the diameter of the quotient graph by repeated squaring of the adjacency matrix . by applying the result of fact  [ matrixmult ] with @xmath245 and observing that @xmath246",
    ", we conclude that the computation of the quotient graph diameter requires only an extra logarithmic number of rounds . in this fashion , the total number of rounds for computing @xmath239 becomes @xmath247 .",
    "the theorem follows by noting that for both the above implementations , the quality of the approximation is ensured by corollary  [ diam - thm ] .",
    "we remark that while the upper bound on the approximation factor is independent of the doubling dimension of the graph , the round complexity is expressed as a function of it .",
    "this does not restrict the generality of the algorithm but allows us to show that for graphs with small doubling dimension , typically graphs with low expansion , the number of rounds can be made substantially smaller than the graph diameter and , in fact , this number decreases as more local memory is available for the reducers , still using linear global space .",
    "this feature represents the key computational advantage of our algorithm with respect to other linear - space algorithms , that , while yielding tighter approximations , require @xmath248 rounds .",
    "we tested our algorithms on a cluster of 16 hosts , each equipped with a 12 gb ram and a 4-core i7 processor , connected by a 10 gigabit ethernet network .",
    "the algorithms have been implemented using apache spark  @xcite , a popular engine for distributed large - scale data processing .",
    "we performed tests on several large graphs whose main characteristics are reported in table  [ tab : datasets ] .",
    "the first graph is a symmetrization of a subgraph of the twitter network obtained from the law website @xcite .",
    "the next four graphs are from the stanford large network datasets collection @xcite and represent , respectively , the livejournal social network and three road networks . the last graph is a synthetic @xmath249 mesh , which has been included since its doubling dimension is known , unlike the other graphs , and constant ( @xmath250 ) , hence it is an example of a graph where our algorithms are provably effective .",
    "we compared the quality of the clustering returned by algorithm cluster ( see section  [ clustering ] ) against that of the clustering returned by the algorithm presented in @xcite and reviewed in section  [ previouswork ] , which , for brevity , we call mpx .",
    "recall that cluster uses a parameter @xmath74 to control the number of clusters , while mpx uses ( an exponential distribution of ) parameter @xmath20 to decide when nodes are possibly activated as cluster centers , hence indirectly controlling the number of clusters .",
    "both algorithms aim at computing a decomposition of the graph into clusters of small radius , so we focused the experiments on comparing the maximum radius of the returned clusterings . however , since the minimum maximum radius attainable by any clustering is a nonincreasing function of the number of clusters , but neither algorithm is able to precisely fix such a number a priori , we structured the experiments as follows .",
    "we aimed at decomposition granularities ( i.e. , number of clusters ) which are roughly three orders of magnitude smaller than the number of nodes for small - diameter graphs , and roughly two orders of magnitude smaller than the number of nodes for large - diameter graphs .",
    "we ran mpx and cluster setting their parameters @xmath20 and @xmath74 so to obtain a granularity close enough to the desired one , and compared the maximum cluster radius obtained by the two algorithms . in order to be conservative",
    ", we gave mpx a slight advantage setting @xmath20 so to always yield a comparable but larger number of clusters with respect to cluster .",
    "table  [ tab : comparison - miller ] shows the results of the experiments for the benchmark graphs .",
    "each row reports the graph , and , for each algorithm , the number of nodes ( @xmath251 ) and edges ( @xmath252 ) of the quotient graph associated with the clustering , and the maximum cluster radius ( @xmath253 ) .",
    "the table provides a clear evidence that our algorithm is more effective in keeping the maximum cluster radius small , especially for graphs of large diameter .",
    "this is partly due to the fact that mpx starts growing only a few clusters , and before more cluster centers are activated the radius of the initial clusters is already grown large . on the other hand ,",
    "mpx is often more effective in reducing the number of edges of the quotient graph , which is in fact the main objective of the mpx decomposition strategy .",
    "this is particularly evident for the first two graphs in the table , which represent social networks , hence feature low diameter and high expansion ( thus , probably , high doubling dimension ) . in these cases ,",
    "the few clusters initially grown by mpx are able to absorb entirely highly expanding components , thus resulting in a more drastic reduction of the edges .      for the diameter approximation",
    ", we implemented a simplified version of the algorithm presented in section  [ diameter ] , where , for efficiency , we used cluster instead of cluster2 , thus avoiding repeating the clustering twice . also , in order to get a tighter approximation , we computed the diameter of the weighted variant of the quotient graph as discussed at the end of section  [ diameter ] .",
    "we performed three sets of experiments , which are discussed below .",
    "the first set of experiments aimed at testing the quality of the diameter approximation provided by our algorithm .",
    "the results of the experiments are reported in table  [ tab : diameter - approximation ] . for each graph of table  [ tab : datasets ] we estimated the diameter by running our algorithm with two clusterings of different granularities ( dubbed _ coarser _ and _ finer _ clustering , respectively ) reporting , in each case , the number of nodes ( @xmath251 ) and edges ( @xmath252 ) of the quotient graph @xmath180 , the approximation @xmath239 and the true diameter @xmath5 . since the quotient graphs turned out to be sufficiently sparse , the use of sparsification techniques mentioned in section  [ mrimplementation ] was not needed .",
    "we observe that in all cases @xmath254 and , in fact , the approximation factor appears to decrease for sparse , long - diameter graphs .",
    "also , we observe that , as implied by the theoretical results , the quality of the approximation does not seem to be influenced by the granularity of the clustering . therefore , for very large graphs , or distributed platforms where individual machines are provided with small local memory , one can resort to a very coarse clustering in order to fit the whole quotient graph in one machine , and still obtain a good approximation to the diameter , at the expense , however , of an increased number of rounds , which are needed to compute the clustering .    with the second set of experiments , we assessed the time performance of our algorithm against two competitors : hadi  @xcite , which was reviewed in section  [ previouswork ] and provides a rather tight diameter ( under)estimation ; and breadth first search ( bfs ) , which , as well known , can be employed to obtain an upper bound to the diameter within a factor two .",
    "hadi s original code , available from @xcite , was written for the hadoop framework . because of hadoop s known large overhead , for fairness , we reimplemented hadi in spark , with a performance gain of at least one order of magnitude . as for bfs",
    ", we implemented a simple and efficient version in spark .",
    "table  [ usvshadi ] reports the running times and the diameter estimates obtained with the three algorithms where , for our algorithm , we used the finer clustering granularity adopted in the experiments reported in table  [ tab : diameter - approximation ] .",
    "the figures in the table clearly show that hadi , while yielding a very accurate estimate of the diameter , is much slower than our algorithm , by orders of magnitude for large - diameter graphs .",
    "this is due to the fact that hadi requires @xmath255 rounds and in each round the communication volume is linear in the number of edges of the input graph . on the other hand bfs ,",
    "whose approximation guarantee is similar to ours in practice , outperforms hadi and , as expected , is considerably slower than our algorithm on large - diameter graphs .",
    "indeed , bfs still requires @xmath255 rounds as hadi , but its aggregate communication volume ( rather than the per round communication volume ) is linear in the number of edges of the input graph .    as remarked in the discussion following lemma",
    "[ radius - bound ] , a desirable feature of our strategy is its capability to adapt to irregularities of the graph topology , which may have a larger impact on the performance of the other strategies . in order to provide experimental evidence of this phenomenon , our third set of experiments reports the running times of our algorithm and bfs on three variants of the two small - diameter graphs ( livejournal and twitter ) obtained by appending a chain of @xmath256 extra nodes to a randomly chosen node , with @xmath257 , thus increasing the diameter accordingly , without substantially altering the overall structure of the base graph . the plots in figure  [ fig : tails ] clearly show that while the running time of our algorithm is basically unaltered by the modification , that of bfs grows linearly with @xmath258 , as expected due to the strict dependence of the bfs number of rounds from the diameter .",
    "a similar behaviour is to be expected with hadi because of the same reason .",
    "putting it all together , the experiments support the theoretical analysis since they provide evidence that the main competitive advantages of our algorithm , which are evident in large - diameter graphs , are the linear aggregate communication volume ( as in bfs ) coupled with its ability to run in a number of rounds which can be substantially smaller than @xmath5 .",
    "we developed a novel parallel decomposition strategy for unweighted , undirected graphs which ensures a tighter control on both the number of clusters and their maximum radius , with respect to similar previous decompositions .",
    "we employed our decomposition to devise parallel polylogarithmic approximation algorithms for the @xmath0-center problem and for computing the graph diameter .",
    "the algorithms use only linear overall space and , for a relevant class of graphs ( i.e. , those of low doubling dimension ) , their parallel depth can be made substantially sublinear in the diameter as long as local memories at the processing nodes are sufficiently large but still asymptotically smaller than the graph size .",
    "while the improvement of the approximation bounds and the parallel depth of our algorithms is a natural direction for further research , the extension of our findings to the realm of weighted graphs is a another challenging and relevant open problem .",
    "we are currently exploring this latter issue and have devised a preliminary decomposition strategy that , together with the number clusters and their weighted radius , also controls their hop radius , which governs the parallel depth of the computation .",
    "g.  e. blelloch , a.  gupta , i.  koutis , g.  l. miller , r.  peng , and k.  tangwongsan . near linear - work",
    "parallel sdd solvers , low - diameter decomposition , and low - stretch subgraphs . in _ spaa _ , pages 1322 , 2011 .",
    "m.  zaharia , m.  chowdhury , t.  das , a.  dave , j.  ma , m.  mccauly , m.  j. franklin , s.  shenker , and i.  stoica .",
    "resilient distributed datasets : a fault - tolerant abstraction for in - memory cluster computing . in _ nsdi _ , pages 1528 , 2012 ."
  ],
  "abstract_text": [
    "<S> we develop a novel parallel decomposition strategy for unweighted , undirected graphs , based on growing disjoint connected clusters from batches of centers progressively selected from yet uncovered nodes . with respect to similar previous decompositions , </S>",
    "<S> our strategy exercises a tighter control on both the number of clusters and their maximum radius .    </S>",
    "<S> we present two important applications of our parallel graph decomposition : ( 1 ) @xmath0-center clustering approximation ; and ( 2 ) diameter approximation . in both cases , </S>",
    "<S> we obtain algorithms which feature a polylogarithmic approximation factor and are amenable to a distributed implementation that is geared for massive ( long - diameter ) graphs . the total space needed for the computation is linear in the problem size , and the parallel depth </S>",
    "<S> is substantially sublinear in the diameter for graphs with low doubling dimension . to the best of our knowledge , </S>",
    "<S> ours are the first parallel approximations for these problems which achieve sub - diameter parallel time , for a relevant class of graphs , using only linear space . besides the theoretical guarantees , our algorithms allow for a very simple implementation on clustered architectures : we report on extensive experiments which demonstrate their effectiveness and efficiency on large graphs as compared to alternative known approaches . </S>"
  ]
}