{
  "article_text": [
    "in multiple target tracking ( mtt ) systems , targets can appear and disappear from a scene and mtt algorithms estimate this varying number of targets based on observations from sensors @xcite . in this",
    "setting , the ground truth is a set that contains the true target states and the estimate is a set that contains the estimated target states .",
    "then , it is possible that the algorithm has not estimated all the target states , leading to missed targets .",
    "it is also possible that the estimated set has false targets , i.e. , estimated targets that are not close to any of the targets in the ground truth .",
    "it is highly desired to assess and compare the performance of mtt algorithms in a mathematically sound way , which boils down to computing the similarity between the ground truth and the estimated sets . + it is important that this similarity measure is a metric in the mathematical sense such that it satisfies non - negativity , definiteness , symmetry and triangle inequality @xcite .",
    "these properties are relevant to be able to quantify the closeness between sets of objects .",
    "specifically , the need for the triangle inequality is well motivated in ( * ? ? ?",
    "* sec .   1 ) and ( * ? ? ?",
    "6.2.1 ) : if there is an estimate @xmath1 which is close to the ground truth and another estimate @xmath2 which is close to @xmath1 , then the triangle inequality ensures that the estimate @xmath2 is also close to the ground truth , which agrees with the intuition .",
    "+ the problem of designing suitable metrics between sets has been studied in the mtt literature .",
    "there are metrics such as the hausdorff metric @xcite , the wasserstein metric @xcite ( also referred to as optimal mass transfer metric in @xcite ) and the optimal sub - pattern assignment ( ospa ) @xcite metric to compute this distance between two sets of target states .",
    "it has been discussed with examples in @xcite that the hausdorff metric is insensitive to cardinality mismatches and to outliers .",
    "the wasserstein metric on the other hand handles these issues better , but it lacks a consistent physical interpretation when the states have different cardinalities , besides other non - intuitive behaviors @xcite . in @xcite ,",
    "the ospa metric was proposed to address these issues .",
    "this metric is also easily computed and has been used widely in the tracking community for performance evaluation and to obtain estimators @xcite .",
    "the ospa metric has also been adapted to handle sets of labeled targets @xcite . + even though ospa penalizes the cardinality mismatch , it fails to quantify it properly in certain scenarios .",
    "for instance , let us consider a scenario without any targets .",
    "suppose one estimator indicates that there is one target ( i.e. , a false target ) and another indicates that there are 1000 targets .",
    "in both cases , the ospa metric has the same value .",
    "so according to ospa , both estimators are equally accurate , which is counterintuitive .",
    "this issue is due to the normalization with the maximum cardinality in the ospa definition .",
    "the ospa metric without the normalization has been used in ( * ? ? ?",
    "iv ) to obtain minimum mean ospa estimate , such that the error adds over targets in the mean error .",
    "even though @xcite makes use of the unnormalized ospa as a cost function , it has not been proved that it is a metric .",
    "+ we argue that ospa possesses a second weakness related to its expression for the cardinality mismatch . in mtt ,",
    "detections , false and missed targets are more important concepts than cardinality mismatch ( * ? ? ?",
    "therefore , it seems more reasonable to develop a metric that considers the errors due to these components .",
    "instead , the ospa metric considers localization and cardinality errors , which can lead to undesirable results .",
    "for example , consider a scenario with a target in the ground truth and two estimators - one estimator reported no target and the other estimator reported a false target ( a target which is far from the real target ) .",
    "both these estimators have identical ospa metric , whereas the first estimate that only has a missed target is arguably better than the second one that has a false target in addition .",
    "+ in this paper , we propose a metric , named generalized ospa ( gospa ) . in relation to unnormalized ospa , gospa includes an additional parameter that enables us to select the cardinality mismatch cost from a range of values that also includes the one used in ospa .",
    "as desired , we show that for a specific selection of this parameter , the gospa metric is a sum of localization errors for the localized targets and a penalty for missed and false targets .",
    "+ in practice , the ground truth is not known but is modeled as a random finite set ( rfs ) @xcite .",
    "algorithm evaluation is usually performed by averaging over the error of the estimates provided by the algorithm over the measurements .",
    "this implies that the estimates are also rfss , so it is useful to have a metric that considers rfss rather than finite sets . in the literature",
    ", there is no formal treatment of this problem to our knowledge . in this paper",
    ", we fill this gap by showing that the mean gospa and root mean squared gospa are metrics for rfss of targets .",
    "this is an important result for performance evaluation and the design of estimators .",
    "+ the outline of the rest of the paper is as follows . in section  [ sec : issuenorm ] , we discuss the normalization issue in ospa and illustrate with examples , how without normalization , ospa works better in handling cardinality mismatch . in section",
    "[ sec : gospa ] , we proceed to generalize the unnormalized ospa .",
    "we also discuss the roles of the different parameters in this section . in section  [ sec : alpha2 ] , we present and argue for the most appropriate choice of the gospa metric for mtt . in section  [ sec : perf ] , we show that in the space of rfs , the mean gospa and root mean squared gospa are both metrics . in section  [ sec : ill ] , we illustrate via simulations that the proposed choice of gospa provides expected results compared to the ospa and unnormalized ospa counterparts .",
    "finally , conclusions are drawn in section  [ sec : concl ] .",
    "the main motivation for using a metric in estimation is to compare the estimates from different algorithms with the ground truth to assess their performance . to this purpose , the ospa metric",
    "was introduced in @xcite to compute the distance between finite sets of ground truth and estimates .",
    "before we review the ospa metric and discuss the normalization issues , let us first introduce the formal definition of a metric and some useful notations .",
    "a metric @xmath3 on a set @xmath4 is a function that satisfies the following properties for any @xmath5 ( * ? ? ?",
    "2.15 ) :    a.   non - negativity : @xmath6 .",
    "b.   symmetry : @xmath7 . c.   definiteness : @xmath8 @xmath9 @xmath10 .",
    "d.   triangle inequality : @xmath11 .",
    "@xmath12    we emphasize here that the triangle inequality property , despite its abstractness , has a major practical importance in algorithm assessment ( * ? ? ?",
    "suppose there are two estimates @xmath13 and @xmath14 for a ground truth @xmath15 .",
    "let us assume that according to @xmath16 , the estimate @xmath14 is close to the ground truth @xmath15 and is also close to the other estimate @xmath13 . then , according to intuition , the second estimate @xmath13 should also be close to the ground truth @xmath15 .",
    "this property is ensured by the triangle inequality property .",
    "+ the triangle inequality also has practical implications to ensure the quality of approximate optimal estimators .",
    "consider @xmath15 to be the ground truth and , @xmath14 to be the optimal estimate , according to certain criterion .",
    "let us assume that it is difficult to compute the optimal estimate @xmath14 and so we resort to an approximation @xmath13 of the optimal @xmath14 .",
    "this happens often in practice .",
    "if the triangle inequality does not hold , that would mean that even if we have a good estimate @xmath13 , close to the optimal @xmath14 , which in turn is close to the ground truth @xmath15 , it is possible that the distance from @xmath13 to the ground truth @xmath15 is high .",
    "this property is clearly not desirable .",
    "let @xmath17 denote a metric in @xmath18 such that @xmath19 is the distance between @xmath20 and let @xmath21 be the cut - off metric associated with @xmath19 ( * ? ? ?",
    "let @xmath22 be the set of all permutations in @xmath23 for any @xmath24 .",
    "any element @xmath25 is a sequence @xmath26 .",
    "[ def : ospa ] let @xmath27 and @xmath28 be finite subsets of a bounded observation window @xmath29 , where @xmath30 denotes the cardinality of a set @xmath1 . for @xmath31 and @xmath32 , ospa @xcite is defined as    & d_p^(c)(x , y ) & + & ( ( _ _ |y| _ i=1^|x| d^(c)(x_i , y_(i))^p + c^p(|y|- |x|)))^.&[eqn : ospadef ]    for @xmath33 , @xmath34 .",
    "the @xmath35-ospa is defined as    & d_^(c)(x , y )    _ _ |y| _ 1i |x| d^(c)(x_i , y_(i ) ) & |x|= |y| + c &    . & [ eqn : ospadef1 ]    the metric properties of ospa are proved in @xcite . @xmath12    the ospa metric in is viewed as a sum of two components : the localization error contributed by the term @xmath36 and the cardinality error by the term @xmath37 .",
    "we proceed to review the role of the different parameters in these error components .",
    "the parameter @xmath38 in ospa determines the severity of penalizing the outliers in the localization component .",
    "that is , for a fixed value of @xmath0 , the larger the value of @xmath38 is , the larger the pairs with large @xmath39 get penalized . also , the cardinality cost is penalized more , assuming that @xmath40 . in the limit",
    "when @xmath41 , the maximum value of the cost is @xmath0 for any cardinality mismatch .",
    "the parameter @xmath0 determines the maximum allowable localization error between a pair of points .",
    "it is also the cost for any cardinality mismatch . + computing the ospa metric is equivalent to solving a 2-d assignment problem . a close inspection of shows that the ospa metric involves finding the optimal choice of pair of points that minimizes the overall distance , given the distances for every pair of points .",
    "this problem is known as the 2-d assignment problem @xcite .",
    "solutions to 2-d assignment problems have been used extensively by the tracking community for the data association problem that arises in the measurement update step with the radar point detection measurement model @xcite .",
    "the same solution applies to computing the ospa metric .",
    "several methods exist : the modified auction algorithm @xcite , hungarian ( also known as munkres ) @xcite and the jonker - volgenant - castanon ( jvc ) @xcite algorithms .",
    "all these algorithms have an asymptotic complexity of @xmath42 with @xmath32 @xcite .      in this section",
    ", we illustrate that the normalization @xmath43 in the ospa metric can lead to counter - intuitive results .",
    "this effect can be illustrated with a simple example .",
    "[ ex:1 ] let us say the ground truth is @xmath44 and we have estimates @xmath45 from different algorithms indexed with @xmath46 .",
    "intuitively , the larger the value of @xmath47 is , the farther away we are from the ground truth and therefore , the distance metric should increase with @xmath47 .",
    "however , the ospa metric is @xmath0 for any @xmath48 . that is , according to the ospa metric all these algorithms are equally accurate , which is not the desired evaluation in mtt .",
    "@xmath12    this undesirable property of the ospa metric is due to the normalization . however , if we remove this normalization from ospa , the distance is @xmath49 , which increases with @xmath47 .",
    "this example is a clear motivation as to why the normalization should be removed from the ospa metric to evaluate mtt algorithms .",
    "we refer to the ospa metric without normalization as ` unnormalized ospa ' in the rest of this paper .",
    "the unnormalized ospa was used in ( * ? ? ?",
    "iv ) to obtain minimum mean ospa estimate , such that  the measure adds over targets rather than averaging over targets \" .",
    "however , as mentioned in the introduction , it has not been previously proved it is a metric , but we will present a proof of this as a particular case of the gospa metric introduced in the next section ..",
    "in this section , we present the generalized ospa metric to measure the distance between finite sets of targets . to be precise , this metric is a generalization of the unnormalized ospa metric .",
    "as we will see , the gospa metric contains an additional tuning parameter that considers a wider range of cardinality penalties than the ospa metric .",
    "[ def : gospa ] let @xmath27 and @xmath28 be finite subsets of @xmath18 and let @xmath50 . for @xmath31 and @xmath32 , the generalized ospa function is defined as    & d_p^(c , ) ( x , y ) & + & ( _ _ |y| _ i=1^|x| d^(c)(x_i , y_(i))^p + ( |y|- |x|))^. & [ eqn : gospadef ]    if @xmath33 , @xmath51 .",
    "+ the corresponding gospa for @xmath41 is    & d_^(c , ) ( x , y )    _ _ |y| _ 1i |x| d^(c)(x_i , y_(i ) ) & |y|= |x| + c &    . & [ eqn : gospadef1 ]    @xmath12    the gospa functions in and of definition  [ def : gospa ] are metrics",
    ".    it can be seen from the definition that the non - negativity , symmetry and definiteness holds .",
    "the triangle inequality is proved in appendix  [ app : triinproof ] .",
    "the region , where the gospa metric is defined , is over finite subsets of entire @xmath18 . on the contrary , in ospa",
    ", we require the definition of a bounded window @xmath52 , see definition  [ def : ospa ] .",
    "this bounded window @xmath53 is necessary in the triangle inequality proof of the ospa metric in which dummy points chosen outside @xmath53 are used ( * ? ? ? * app . ) . in the gospa proof in appendix  [ app : triinproof ] , we do not use the dummy points .",
    "the gospa proof includes the unnormalized ospa , and it can also be extended to ospa so that the constraint @xmath53 is not necessary , see appendix  [ app : ospaproof ] .      in gospa ,",
    "similar to ospa , it is possible to view the overall distance as the sum of localization and cardinality error components . in this subsection , we analyze this split up of gospa and discuss how the parameters @xmath0 , @xmath38 and @xmath54 influence these costs .",
    "+ the role of the parameter @xmath38 in gospa is similar to that in ospa @xcite .",
    "a large @xmath38 penalizes outliers and cardinality mismatch severely .",
    "the role of the parameter @xmath0 is partly the same as in ospa that it is the cut - off on the base distance .",
    "however , for the cardinality mismatch , the error contribution is @xmath55 in gospa compared to @xmath56 in ospa .",
    "the parameter @xmath54 determines the cardinality error in relation to the maximum localization error .",
    "+ the connection between the two parameters @xmath0 and @xmath54 to these costs is easier to analyze when we set @xmath57 . in this case , the upper bound on @xmath54 , i.e. , @xmath58 implies that the penalty for cardinality mismatch should at least be @xmath59 for every additional point in the larger set .",
    "in other words , the cost for cardinality mismatch should at least be half the maximum allowable localization error .",
    "if we make this cost smaller , we no longer have a metric as the triangle inequality is not met . on the other hand , for a localization limit @xmath0",
    ", the cardinality mismatch penalty can be set arbitrarily high by changing @xmath54 .",
    "+ we want to highlight two choices of @xmath54 .",
    "when @xmath60 , gospa reduces to unnormalized ospa , thus proving that the unnormalized ospa is a metric . as will be explained in the next section , when @xmath58 , the gospa metric can be viewed as the sum of the localization errors of the localized targets plus the error due to missed and false targets",
    "we will also argue that the penalty for cardinality mismatch ( or missed / false target ) , @xmath61 , with this selection is more suitable for mtt than @xmath62 in which the cost for cardinality mismatch is the same as the cut - off @xmath56 .",
    "in this section , we argue that the choice of @xmath63 in gospa is the most appropriate for analyzing the estimation error in multi object systems in terms of localized , missed and false targets .",
    "we also propose an alternative but equivalent description for the gospa metric for this choice of @xmath54 .",
    "this new definition decomposes the distance metric as the sum of localization error due to localized targets and the error due to missed and false targets . for the sake of discussion ,",
    "we set @xmath57 in this section ; the discussions are easily extended for any value of @xmath38 .      in an mtt",
    "setting , suppose we have a ground truth @xmath64 and estimate @xmath65 .",
    "consider two target states @xmath66 and @xmath67 , such that all the points in @xmath65 are far from @xmath15 and all the points in @xmath64 are far from @xmath13 .",
    "this implies that @xmath68 , which in turn implies @xmath69 . in this case",
    ", we argue that the target @xmath15 has been missed and that the estimator has instead presented a false target @xmath13 , and thus , both the points @xmath15 and @xmath13 are ` unlocalized ' .",
    "the value of @xmath0 determines how far away they must be to be considered unlocalized .",
    "we refer to the point @xmath15 in the ground truth as a ` missed ' target and the point @xmath13 in the estimate as a ` false ' target for apparent reasons . on the other hand",
    ", we refer to the pair @xmath70 as ` localized ' if @xmath71 and @xmath15 and @xmath13 are matched according to the optimal permutation function .",
    "+ according to ospa and gospa , the cost contribution by a pair of missed target @xmath15 and false target @xmath13 , associated to each other is @xmath72 .",
    "that is , the cost for a pair of unlocalized targets @xmath15 and @xmath13 is @xmath0 .",
    "this implies that the cost for a single unlocalized target should be @xmath59 .",
    "intuitively this should be the value independently of whether or not an unlocalized target is associated to a target in the other set , because strictly speaking we should not associate target estimates and targets that are sufficiently far from each other . however , in ospa , there is a disparity in the contribution by the unlocalized targets depending on whether they are part of the localization error component or the cardinality mismatch component in .",
    "the error contribution of an unlocalized target is @xmath59 if it is accounted for in the localization component , as there is a cost @xmath0 shared by this target and the associated unlocalized target in the other set . on the other hand ,",
    "the error contribution is @xmath0 if the unlocalized target is accounted for in the cardinality mismatch component .",
    "a similar disparity is also inherent to gospa when @xmath73 .",
    "+ we argue that @xmath58 is suitable in the gospa metric . with this choice ,",
    "the contribution to the error by a pair of unlocalized targets @xmath15 , @xmath13 with @xmath69 , is @xmath0 .",
    "this term can be split up and viewed as @xmath15 and @xmath13 contributing @xmath59 each .",
    "this is also in lines with the @xmath74 ( assuming @xmath75 ) false targets in @xmath65 that will contribute @xmath59 each .",
    "that is , any unlocalized ( missed or false ) target always contributes @xmath59 to the distance and we thus overcome the disparity inherent to other choices of @xmath54 .",
    "+ given this insight , it is fair to look at the distance between @xmath64 and @xmath65 as the sum of localization error due to the localized targets and error due to missed and false target",
    ". consequently , in the rest of this section , we use the term ` localization error ' to refer to the localization error due to the localized targets .",
    "this splitting of the error into localization error and error due to false and missed targets is illustrated in the example considered next .",
    "[ ex:2 ] consider the case where the ground truth is @xmath76 and there are two estimates @xmath77 and @xmath78 .",
    "the two estimates along with the ground truth are illustrated in figures  [ fig : adjospaeg1 ] and  [ fig : adjospaeg2 ] .",
    "clearly , besides the localization error between @xmath79 and @xmath80 , the estimate @xmath81 has a missed target @xmath82 and a false target @xmath83 , whereas @xmath84 has just a missed target .",
    "so , according to intuition , @xmath84 in figure  [ fig : adjospaeg2 ] is a better estimate than @xmath81 in figure  [ fig : adjospaeg1 ] .",
    "however , the ospa metric @xmath85 and the unnormalized ospa metric @xmath86 are @xmath87 and @xmath88 respectively for both estimates . on the contrary",
    ", the gospa metric shows a trend that agrees with the intuition , i.e. , @xmath89 is larger than @xmath90 .",
    "@xmath12      we propose an alternate expression for gospa when @xmath91 using assignment functions instead of permutation functions .",
    "now , the breakdown of the metric as the sum of localization error and the error from false and missed target is explicit , which we consider insightful . + as mentioned before , the 2d assignment functions have already been used extensively in the tracking community for the data association problems ( * ? ? ?",
    "there are several ways of representing this assignment functions , the choice of which is often based on the application .",
    "we use assignment ( also referred to as matching ) set representation ( * ? ? ?",
    "an assignment set @xmath92 between the pair of finite index sets @xmath93 and @xmath94 is a set that has the following properties :    1 .",
    "2 .   @xmath96 @xmath97 @xmath98 .",
    "@xmath99 @xmath97 @xmath100 .",
    "the second and third properties ensure that every @xmath101 and @xmath47 gets at most one assignment .",
    "let @xmath102 be the set of all such possible 2d assignment sets .",
    "we can rewrite the gospa metric for @xmath58 and @xmath31 using the 2d assignment set as @xmath103^{\\frac{1}{p}}.&\\end{aligned}\\]]@xmath12    note that the notion of cut - off metric @xmath104 is not needed in this representation .",
    "the above definition does not have an explicit cardinality mismatch term .",
    "the first term @xmath105 is the localization error and , the second term @xmath106 is the error due to the @xmath107 missed targets and @xmath108 false targets , considering @xmath64 as the ground truth .",
    "in the previous sections , we studied metrics between finite sets of targets .",
    "it was then implicitly assumed that the ground truth and the estimates are deterministic .",
    "however , mtt is often formulated as a bayesian filtering problem where the ground truth is an rfs and the estimates are sets , which depend deterministically on the observed data @xcite . for performance evaluation , in many cases , we average over several realizations of the data , so estimates are rfss as well . therefore , evaluating the performance of several algorithms is in fact a comparison between the rfs of the ground truth and the rfss of the estimates . as in the case of deterministic sets @xcite , it is highly desirable to establish metrics for rfss for performance evaluation .",
    "+ in this section , we show that the average gospa , @xmath109 $ ] is a metric between rfss .",
    "in fact , we show that a generalized version , @xmath110{{\\mathbb{e}}[{{d_{p}^{(c , \\alpha)}}}(x , y)^p]}$ ] , is a metric . the case",
    "when @xmath111 can be viewed as an extension of the root mean squared error ( rmse ) metric between random vectors ( * ? ? ?",
    "2.2 ) to rfss .",
    "+ metrics have already been proposed and studied in the context of random vectors in @xmath18 .",
    "if we have a metric in @xmath18 , we have a metric on random vectors in @xmath18 by taking the expected value ( * ? ? ?",
    "then , a natural choice is to compute the average euclidean distance , @xmath112 \\triangleq   \\int \\int \\|x - y\\|_2 f(x , y)\\ : dx\\ : dy$ ] , as a metric on random vectors , where @xmath113 is the euclidean distance and @xmath114 is the joint density between random vectors .",
    "however , a disadvantage is that it is more challenging to construct estimators based on it compared to the rmse metric , which we discuss next .",
    "+ the rmse , @xmath115}$ ] is a commonly used metric between random vectors ( * ? ? ?",
    "2.2 ) . to obtain the minimum rmse estimate in practice , it is equivalent and common to minimize the mean squared error ( mse ) @xmath116 $ ] , although the mse and squared euclidean distance @xmath117 are not metrics .",
    "+ in the rfs case , there are estimators that are obtained by minimizing the mean squared ospa @xcite for @xmath111 .",
    "this strategy is equivalent to minimizing the root mean squared ospa metric .",
    "note again , that squared ospa and mean squared ospa are not metrics , although their minimum coincides with the minimum of the root mean squared ospa .",
    "the metric property of mean ospa and root mean squared ospa has not been established in the literature .",
    "+ similar to the euclidean metric for vectors , one can use the gospa metric defined over finite sets to define metrics over rfss . following the approaches in the random vector case , root mean squared gospa and mean gospa seem like natural extensions to rfss .",
    "below , we establish that the more general case @xmath110{{\\mathbb{e}}\\left [ { { d_{p}^{(c , \\alpha)}}}(\\cdot , \\cdot)^p\\right]}$ ] is a metric for gospa , which also includes the unnormalized ospa metric .    for @xmath31 , @xmath118 and @xmath50 , @xmath110{{\\mathbb{e}}\\left [ { { d_{p}^{(c , \\alpha)}}}(x , y)^p\\right]}$ ] is a metric for any pair of rfss @xmath64 and @xmath65 .",
    "the proof of this proposition is provided in appendix  [ app : avggospa ] .",
    "thus , the above proposition proves that mean gospa ( @xmath57 ) and root mean squared gospa with ( @xmath111 ) are also metrics .",
    "one can also easily extend the proof of the proposition to show that the mean ospa and root mean squared ospa are also metrics . + for the gospa analogue of rmse , one can set @xmath111 and use euclidean distance for @xmath17 .",
    "similar to the minimum mse estimators in random vectors , one can equivalently use the mean squared gospa @xmath119 $ ] for obtaining rfs estimators .",
    "several estimates of @xmath64 are shown in figure  [ fig : meangospaillus ] . ]    in this section , we illustrate with examples how the mean gospa and root mean squared gospa metrics for @xmath63 present values that agree with the intuition compared to the ospa and unnormalized ospa metrics . we illustrate this for varying number of missed and false targets in the estimates .",
    "+ in a bayesian setting , the ground truth has a prior probability density function ( pdf ) and is observed through measurements . as previously mentioned , different estimators provide deterministic estimates based on these observed measurements",
    ". however , algorithm assessment is usually done by monte carlo simulation by averaging the errors with different measurements .",
    "this implies that ground truth and estimates are rfss and we want to determine which estimate is the closest to the ground truth . rather than providing a full simulation with prior and measurements , we assume that the ground truth and estimates are specific rfss , which are easy to visualize and are useful to illustrate the major aspects of the proposed metrics .",
    "+ we consider ground truth @xmath64 ( see figure  [ fig : truth ] ) which is a multi - bernoulli rfs composed of two independent bernoulli rfss , each with existence probability @xmath120 .",
    "the probability densities of the individual rfss are gaussian distributed with mean vectors @xmath121^\\prime$ ] and @xmath122^\\prime$ ] and identity covariance matrices . therefore , there are always two target present which are distributed independently with their corresponding pdfs . + we consider several estimate scenarios @xmath65 for this ground truth with varying number of missed and false targets .",
    "the scenarios are illustrated in figures  [ fig : gnd2 ] through  [ fig : gnd9 ] .",
    "in all the cases , the estimate @xmath65 is also a multi - bernoulli rfs ( * ? ? ? * sec .",
    "4.3.4 ) . in scenarios , where only one target in the ground truth is localized",
    ", the estimate @xmath65 includes bernoulli rfs with existence probability @xmath120 and gaussian density with mean @xmath123^{\\prime}$ ] and identity covariance matrix . in scenarios where both targets in the ground truth are localized",
    ", the estimate @xmath65 includes bernoulli rfss with existence probabilities @xmath120 and gaussian densities with mean vectors @xmath123^{\\prime}$ ] and @xmath124^{\\prime}$ ] and identity covariance matrices . in scenarios , where the estimate reports false targets ,",
    "the estimates have bernoulli rfs with gaussian density whose mean value is randomly generated away ( @xmath125 ) from the ground truth .",
    "+    [ cols=\"^,^,^ \" , ]     [ tab : res ]    let us first analyze the behavior of the different metrics for varying number of missed targets .",
    "intuitively , as one traverses across rows , the distance between the rfss should increase with increasing number of missed targets .",
    "this trend is observed with the gospa for @xmath63 and the ospa metric for both @xmath57 and @xmath111 .",
    "but , the unnormalized ospa metric shows strange behaviors when there are false targets in the scenarios ( the entries with red text in table  [ tab : res ] ) .",
    "this is explained when we look at the unnormalized ospa expression for these scenarios . if @xmath126 and @xmath127 are the number of false and missed targets , and @xmath128 and @xmath129 are the cut - off distances for the targets in the ground truth when localized , then the unnormalized ospa when @xmath130 is    d_p^(c,1)=    ( n c^p)^ & m = 2 + ( d_1^p + n c^p)^ & m = 1 + ( d_1^p + d_2^p + n c^p)^ & m = 0    .    for @xmath131 , @xmath132 takes the values @xmath133 , @xmath134 and @xmath135 respectively .",
    "clearly , for @xmath130 , @xmath132 decreases with increasing number of missed targets @xmath127 for fixed @xmath126 , which is not desirable .",
    "+ let us now analyze the behavior of the metrics for varying number of false targets . as the number of false targets increases , the metric should increase according to intuition .",
    "this intuitive trend is displayed by gospa for @xmath63 again .",
    "this trend is also observed in unnormalized ospa , even though it is not a strict increase in the metric values ( the entries with blue text in table  [ tab : res ] ) .",
    "the ospa metric on the other hand shows counter intuitive behavior as we discussed in example  [ ex:1 ] in section  [ sec : issuenorm ] .",
    "when both the targets are missed , the ospa metric is constant for varying number of false targets .",
    "also , for the case with one missed target , ospa and unnormalized ospa have the same metric values when there are no false targets and when there is one false target .",
    "this trend is similar to the behavior we observed in example  [ ex:2 ] .",
    "in this paper , we have presented the gospa metric , a generalized version of the unnormalized ospa , which allows for a range of values for the cardinality mismatch penalty .",
    "we have also argued that the gospa for @xmath58 , is the best selection for estimation in mtt to view the distance as sum of terms contributed to the localization of the localized targets and the penalty for the false and missed targets .",
    "in addition , we have extended gospa to compute metric in the space of rfss , which is what we use for performance evaluation of algorithms via simulations .",
    "we have shown that both mean gospa and root mean squared gospa are metric between rfss .",
    "in the proof , an extension of minkowski s inequality @xcite to sequences of different lengths by appending zeros to the shorter sequence is used . let us say we have two sequences @xmath136 and",
    "@xmath137 such that @xmath138 .",
    "we extend the sequence @xmath139 such that @xmath140 for @xmath141 .",
    "then , using minkowski s inequality on this extended sequence we get that    ( _ i=1^m|a_i + b_i|^p + _ i = m+1^n|b_i|^p ) ^ + ( _ i=1^m|a_i|^p)^ + ( _ i=1^n|b_i|^p ) ^ [ eqn : minfinsum ]    for @xmath142 .",
    "we use this result several times in our proof .",
    "+ we would like to prove the triangle inequality :    d_p^(c , ) ( x , y ) d_p^(c , ) ( x , z ) + d_p^(c , ) ( y , z )    for any three rfss @xmath64 , @xmath65 and @xmath143 .",
    "the proof is dealt in three cases based on the values of @xmath144 , @xmath145 and @xmath146 . without loss of generality , we assume @xmath75 in all the three cases , since gospa is symmetric in @xmath64 and @xmath65 .      for any @xmath148 ,    d_p^(c , ) ( x , y ) & & ( _ i=1^|x| d^(c)(x_i , y_(i))^p + ( |y|- |x| ) ) ^.    using the triangle inequality on the cut - off metric @xmath104 , we get that for any @xmath148 and for any @xmath149 ,    & d_p^(c , ) ( x , y ) & + & ( _ i=1^|x| ^p . & + & . + ( |y|- |x| ) ) ^ & + & ( _ i=1^|x| ^p . &",
    "+ & + ( |y|- |x| ) + 2 ( |z|- |y| ) & + & .",
    "i=|x|+ 1^|y| d^(c)(z_(i ) , y_(i))^p ) ^ & [ eqn : gospaproofi1 ] + & = ( _ i=1^|x| ^p . &",
    "+ ( |z|- |x|)+_i=|x|+ 1^|y| d^(c)(z_(i ) , y_(i))^p . &",
    "+ & . + ( |z|- |y| ) ) ^ & + & ( _ i=1^|x| d^(c)(x_i , z_(i))^p + ( |z|- |x| ) ) ^ & + & + ( _ i=1^|y| d^(c)(z_(i ) , y_(i))^p + ( |z|- |y|))^ & .    to arrive at the last inequality , minkowski s inequality in is used .",
    "since @xmath150 is a bijection , we can invert @xmath150 to arrive at    & d_p^(c , ) ( x , y ) ( _ i=1^|x| d^(c)(x_i , z_(i))^p + ( |z|- |x| ) ) ^ & + & + ( _ i=1^|y| d^(c)(z_^-1((i ) ) , y_i)^p + ( |z|- |y|))^. &    the composition @xmath151 will be a permutation on @xmath152 .",
    "lets denote this as @xmath153 .",
    "so , for any @xmath154 ,    d_p^(c , ) ( x , y ) & ( _ i=1^|x| d^(c)(x_i , z_(i))^p + ( |z|- |x| ) ) ^ & + & + ( _ i=1^|y| d^(c)(z_(i ) , y_i)^p + ( |z|- |y|))^ , &    which also holds for the @xmath155 and @xmath153 that minimizes the first and the second term in the right hand side .",
    "this proves the triangle inequality for this case .      as before , for any @xmath148 and @xmath149 ,    & d_p^(c , ) ( x , y ) & + & ( _ i=1^|x| ^p .",
    "+ ( |y|- |x| ) ) ^ & + & ( _ i=1^|x| ^p . &",
    "+ _ i=|x|+1^|z| d^(c)(z_(i ) , y_(i))^p + ( |z|- |x| ) . &",
    "+ ( |y|- |z| ) ) ^ & + & ( _ i=1^|x| d^(c)(x_i , z_(i))^p + ( |z|- |x| ) ) ^ & + & + ( _ i=1^|z| d^(c)(z_(i ) , y_(i))^p+ ( |y|- |z| ) ) ^. &    from here , we can argue similar to the case 1 and show that the triangle inequality holds .      &",
    "d_p^(c , ) ( x , y ) & + & ( _ i=1^|x| d^(c)(x_i , y_(i))^p + ( |y|- |x| ) ) ^ & + & ( _ i=1^|z| d^(c)(x_i , y_(i))^p + ( |x|- |z| ) & + & + ( |y|- |x| ) ) ^.    to get the above inequality , for @xmath158 , we have used the fact that @xmath159 when @xmath160 .",
    "d_p^(c , ) ( x , y ) & ( _ i=1^|z| ^p . &",
    "+ ( |y|- |z| ) + ( |y|- |x| ) ) ^. &    from here , the arguments are similar to the ones in the last two cases . + for the case when @xmath41 and @xmath50 , the triangle inequality follows immediately by using the result ( * ? ? ?",
    "* ): @xmath161 in the triangle inequality for @xmath162 .",
    "the proof is handled in three cases as in the gospa proof .      for any @xmath148 ,    & d_p^(c)(x , y ) & + & ^. &    we use the following result that if @xmath163 and @xmath164 , then @xmath165 ( * ? ? ? * app . ) to change the normalization to @xmath146 :    & d_p^(c)(x , y ) & + & ^ & + & ^. &    from here , one can follow the same lines of proof from in case 1 of gospa and finish the proof of this case .      to prove this case , one can use that @xmath166 along with the gospa proof in case 2 .      to prove this case",
    ", one can use that @xmath167 along with the gospa proof in case 3 .",
    "for rfs @xmath64 with the multi object density function @xmath168 and for a real valued function of rfs @xmath169 , using the set integral , the expectation of @xmath170 @xcite is :          since both @xmath172 and @xmath173 are finite valued , @xmath174 < \\infty$ ] is satisfied .",
    "definiteness , non - negativity and symmetry properties of are observed directly from the definition .",
    "note that , for metrics in the probability space , the definiteness between random variables is in the almost sure sense ( * ? ? ?",
    "the proof of the triangle inequality is sketched below .",
    "+ in the proof , we use minkowski s inequality for infinite sums and for integrals @xcite . using these minkowski s inequalities",
    ", we can show that the inequality also extends to cases that have both infinite sums and integrals as it appears in the set integrals . for real valued functions @xmath175 and",
    "@xmath176 where @xmath177 and for @xmath178 ,          and then using minkowski s inequality for infinite sums on this , we get the rhs of .",
    "+ now , we use the above results for the triangle inequality of .",
    "let us consider rfs @xmath64 , @xmath65 and @xmath143 with joint distribution @xmath179 :                  the multiple integrals and multiple sums in can be considered as one major integral and sum .",
    "so , using minkowski s inequality in for infinite sums and integrals on , we get @xmath180{{\\mathbb{e}}[{{d_{p}^{(c , \\alpha)}}}(x , y)^p]}&{{\\nonumber}}\\\\ & \\leq\\left [ \\int \\int \\int { { d_{p}^{(c , \\alpha)}}}(x , z)^p   f(x , y , z)\\delta x \\delta y \\delta z \\right]^{\\frac{1}{p}}&{{\\nonumber}}\\\\ & \\qquad + \\left [   \\int \\int \\int { { d_{p}^{(c , \\alpha)}}}(y , z)^p   f(x , y , z)\\delta x \\delta",
    "y \\delta z \\right]^{\\frac{1}{p}}&\\\\ & = \\left [ \\int \\int { { d_{p}^{(c , \\alpha)}}}(x , z)^p   f(x , z)\\delta x \\delta z \\right]^{\\frac{1}{p}}&{{\\nonumber}}\\\\ & \\qquad + \\left [ \\int \\int { { d_{p}^{(c , \\alpha)}}}(y , z)^p   f(y , z)\\delta y \\delta z \\right]^{\\frac{1}{p}},&\\end{aligned}\\ ] ] which finishes the proof of the triangle inequality ."
  ],
  "abstract_text": [
    "<S> in this paper , we present the generalized optimal sub - pattern assignment ( gospa ) metric on the space of sets of targets . </S>",
    "<S> this metric is a generalized version of the unnormalized optimal sub - pattern assignment ( ospa ) metric . </S>",
    "<S> the difference between unnormalized ospa and gospa is that , in the proposed metric , we can choose a range of values for the cardinality mismatch penalty for a given cut - off distance @xmath0 . </S>",
    "<S> we argue that in multiple target tracking , we should select the cardinality mismatch of gospa in a specific way , which is different from ospa . in this case </S>",
    "<S> , the metric can be viewed as sum of target localization error and error due to missed and false targets . </S>",
    "<S> we also extend the gospa metric to the space of random finite sets , and show that both mean gospa and root mean squared gospa are metrics , which are useful for performance evaluation .    </S>",
    "<S> ospa , multiple target tracking , metric , gospa , rfs </S>"
  ]
}