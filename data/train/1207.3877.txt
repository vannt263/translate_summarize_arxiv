{
  "article_text": [
    "the following notations are used throughout this article . the notations @xmath0^{t}$ ] and",
    "@xmath0^{h}$ ] stand for transpose and hermitian transpose , respectively . @xmath1 and @xmath2 denote the trace and the determinant of the matrix @xmath3 , respectively .",
    "the symbols @xmath4 and @xmath5 stand for the set of @xmath6 matrices and the set of @xmath7-dimensional column vectors with real entries , respectively . @xmath8 and @xmath9 denote the set of @xmath6 matrices and the set of @xmath7-dimensional column vectors with complex entries , respectively .    we introduce the following new determinant inequality .    [ theorem1 ]",
    "suppose @xmath10 and @xmath11 are positive semi - definite matrices with eigenvalues @xmath12 and @xmath13 arranged in descending order , @xmath14 is a diagonal matrix with non - negative diagonal elements @xmath15 arranged in descending order .",
    "then the following determinant inequality holds @xmath16 the above inequality becomes an equality if @xmath3 and @xmath17 are diagonal , and the diagonal elements of @xmath3 and @xmath17 are sorted in descending order and ascending order , respectively , i.e. @xmath18 , and @xmath19 .",
    "see appendix [ appa ] .",
    "the new determinant inequality can be used to solve the following optimization problem @xmath20 where @xmath21 , @xmath22 , and @xmath23 are positive definite matrices .",
    "such an optimization arises when we design the precoding matrix associated with a transmit node so as to maximize the overall channel capacity ( details of the formulation are omitted here ) .    to gain an insight into ( [ opt-3 ] ) , we reformulate the problem as follows .",
    "let @xmath24 , and @xmath25 , the objective function ( [ opt-3 ] ) can be re - expressed as @xmath26 to further simplify the problem , we carry out the svd : @xmath27 and the eigenvalue decomposition ( evd ) : @xmath28 , and @xmath29 , where @xmath30 , @xmath31 , @xmath32 , and @xmath33 are @xmath34 unitary matrices , @xmath35 , @xmath36 and @xmath37 are diagonal matrices given respectively as @xmath38 in which @xmath39 and @xmath40 denote the @xmath41-th eigenvalue associated with @xmath42 and @xmath43 , respectively . without loss of generality ,",
    "we assume that the diagonal elements of @xmath35 , @xmath36 and @xmath37 are arranged in descending order",
    ". we can rewrite ( [ equation-1 ] ) as @xmath44 where @xmath45 , and @xmath46 . resorting to ( [ equation-2 ] ) , the optimization ( [ opt-3 ] )",
    "can be transformed into a new optimization that searches for an optimal set @xmath47 , in which @xmath48 and @xmath49 are also unitary matrices @xmath50 the optimization involves searching for multiple optimization variables .",
    "nevertheless , we can , firstly , find the optimal @xmath51 given that @xmath35 is fixed . then substituting the derived optimal unitary matrices into ( [ opt-7 ] )",
    ", we determine the optimal diagonal matrix @xmath35 .",
    "optimizing @xmath51 conditional on a given @xmath35 can be formulated as @xmath52    letting @xmath53 , @xmath54 , and utilizing theorem [ theorem1 ] , the objective function ( [ opt-8 ] ) is upper bounded by @xmath55 the above inequality becomes an equality when @xmath56 and @xmath57 , where @xmath58 is an anti - identity matrix , that is , @xmath58 has ones along the anti - diagonal and zeros elsewhere .",
    "therefore the optimal solution to ( [ opt-8 ] ) is given by @xmath59 substituting the optimal @xmath51 back into ( [ opt-7 ] ) , we arrive at the following optimization that searches for optimal diagonal elements @xmath60 @xmath61 the above optimization ( [ opt-9 ] ) can be solved analytically by resorting to the lagrangian function and kkt conditions , whose details are not elaborated here .",
    "define @xmath62 , and its eigenvalues @xmath63 are arranged in descending order",
    ". then we have @xmath64 the above inequality comes from the following well - known matrix inequality @xcite : @xmath65 in which @xmath66 and @xmath67 are positive semidefinite hermitian matrices , with eigenvalues @xmath68 and @xmath69 arranged in descending order respectively .",
    "to prove ( [ theorem1:eq1 ] ) , we only need to show that the term on the right - hand side of ( [ appa : eq1 ] ) is upper bounded by @xmath70 before proceeding to prove ( [ appa : eq2 ] ) , we introduce the following inequalities for the two sequences @xmath71 and @xmath72 . @xmath73 the proof of the inequalities ( [ appa : eq3 ] ) is provided in appendix [ appb ] .",
    "the inequality relations between these two sequences can be characterized by the notion of `` multiplicative majorization '' ( also termed log - majorization ) .",
    "multiplicative majorization is a notion parallel to the concept of additive majorization . for two vectors @xmath74 and @xmath75 with elements sorted in descending order ( @xmath76 stands for the set of non - negative real numbers )",
    ", we say that @xmath77 is multiplicatively majorized by @xmath78 , denoted by @xmath79 , if @xmath80 here we use the symbol @xmath81 to differentiate the multiplicative majorization from the conventional additive majorization @xmath82 .",
    "another important concept that is closely related to majorization is schur - convex or schur - concave functions .",
    "a function @xmath83 is said to be multiplicatively schur - convex if for @xmath79 , then @xmath84 .",
    "clearly , establishing ( [ appa : eq2 ] ) is equivalent to showing the function @xmath85 is multiplicatively schur - convex for elements @xmath86\\in\\mathbb{r}^{n}_{+}$ ] arranged in descending order .",
    "this multiplicatively schur - convex property can also be summarized as follows .",
    "[ lemma1 ] for vectors @xmath74 , @xmath75 , and @xmath87 , with their elements arranged in descending order , if @xmath79 , then we have @xmath88 , i.e. @xmath89    we prove lemma [ lemma1 ] by induction . for @xmath90 , we have @xmath91[a_2+c_1 ] -[b_1+c_2][b_2+c_1 ] \\nonumber\\\\ \\stackrel{(a)}{=}&[a_1-b_1]c_1 + [ a_2-b_2]c_2 \\nonumber\\\\ \\stackrel{(b)}{\\leq}&c_2[a_1+a_2 -b_1 -b_2 ] \\stackrel{(c)}{\\leq } 0 \\label{appa : argument}\\end{aligned}\\ ] ] where @xmath92 can be easily derived by noting that @xmath93 ; @xmath94 comes from the fact that @xmath95 and @xmath96 ; @xmath97 is a result of the following inequality : @xmath98 , that is , for any two non - negative elements , if their product remains constant , then their sum increases as the two elements are further apart .",
    "now suppose that for @xmath99-dimensional vectors @xmath77 , @xmath78 and @xmath100 , the inequality ( [ lemma1:eq1 ] ) holds true . we show that ( [ lemma1:eq1 ] ) is also valid for @xmath101-dimensional vectors @xmath77 , @xmath78 and @xmath100 .",
    "from the inequalities ( [ appa : inequalities ] ) , we know that @xmath102 . for the special case where @xmath103 , it is easy to verify that the truncated vector @xmath104 $ ] is multiplicatively majorized by the truncated vector @xmath105 $ ] , i.e. @xmath106",
    ". therefore we have @xmath107 and consequently we arrive at @xmath88 given @xmath103 .",
    "now consider the general case where @xmath108 .",
    "there must be at least one index such that @xmath109 since the overall products of the two sequences @xmath110 and @xmath111 are identical and @xmath78 contain zero elements , the overall product is zero . in this case",
    ", we may not find an index such that @xmath109 .",
    "nevertheless , since we have @xmath112 for all @xmath41 , proof of ( [ lemma1:eq1 ] ) is evident . ] .",
    "without loss of generality , let @xmath113 denote the smallest index for which @xmath109 .",
    "we adopt a pairwise transformation to convert the sequence @xmath114 into a new sequence @xmath115 . specifically , the first and the @xmath113th entries of @xmath114 are updated as @xmath116 whereas other entries remain unaltered ,",
    "i.e. @xmath117 , @xmath118 . clearly , the entries @xmath119 and @xmath120 satisfy @xmath121 that is , @xmath122^t\\prec_{\\times}[b_1\\phantom{0}b_{l_1}]^t$ ] . by following the same argument of ( [ appa : argument ] ) and noting that @xmath117 , @xmath118 , we have @xmath123 where @xmath124 $ ] . our objective now is to show @xmath125 it can be easily verified that @xmath77 is multiplicatively majorized by @xmath126 , i.e. @xmath127 , by noting @xmath128 for any @xmath129 and @xmath130",
    ".    now we proceed to prove ( [ appa : eq8 ] ) .",
    "consider two different cases in ( [ appa : eq5 ] ) .    * if @xmath131 , then @xmath132 . in this case , it is easy to verify that the truncated vector @xmath133 $ ] is multiplicatively majorized by the truncated vector @xmath134 $ ] , i.e. @xmath135",
    ". therefore we have @xmath136 and consequently @xmath137 as we have @xmath132 .",
    "* for the second case where @xmath138 , we have @xmath139 .",
    "define two new vectors @xmath140 $ ] and @xmath141 $ ] . from @xmath127",
    ", we can readily verify that @xmath142 is multiplicatively majorized by @xmath143 , i.e. @xmath144 .",
    "therefore we have @xmath145 and consequently @xmath137 as we have @xmath139 .    combining ( [ appa : eq6])([appa : eq8 ] )",
    ", we arrive at ( [ lemma1:eq1 ] ) .",
    "the proof is completed here .",
    "recall the following theorem ( * ? ? ?",
    "* chapter 9 : theorem h.1 )"
  ],
  "abstract_text": [
    "<S> a new determinant inequality of positive semi - definite matrices is discovered and proved by us . </S>",
    "<S> this new inequality is useful for attacking and solving a variety of optimization problems arising from the design of wireless communication systems . </S>"
  ]
}