{
  "article_text": [
    "we consider the problem of optimizing a function @xmath0 ( the _ objective _ or _ cost _ function ) mapping @xmath1 into @xmath2 . we refer to @xmath3 as",
    "the _ model space _ , and each point in the model space , @xmath4 , is a _",
    "model_. depending on the application , the goal may be to find the global extremum of @xmath0 , a single local extremum , or a collection of local extrema . in this paper",
    "we will assume that optimization refers to minimization , whether local or global .",
    "there is no generally agreed upon characterization of what makes an optimization problem hard .",
    "hardness has to do partly with our goals  do we need a global extremum or will a good local extremum do ; partly with the structure of the function  does it have lots of local extrema , how broad are the basins associated with these extrema ; and partly with the dimensionality of the problem  exhaustive search will be infeasible except for low - dimensional problems . in many applications ,",
    "however , the function @xmath0 can not be expressed in closed form in terms of elementary functions , but can only be evaluated point - wise by computer programs .",
    "such problems arise in many fields .",
    "some of the most widely studied include the _ spin - glass _ problem , the _ traveling - salesman _ problem ( tsp ) , and the _ residual statics _ problem of exploration seismology .",
    "if the structure of function @xmath0 is unknown , optimization is fundamentally a matter of search in the model space . in order to be able to treat such a broad variety of situations , we begin with an abstract statement of a search algorithm . here",
    ", we use the notation @xmath5 to represent a population of candidate models at the time step @xmath6 .    *",
    "general search ( gs ) * @xmath7 + let @xmath8 , @xmath9 be an initial population of models , where @xmath10 and @xmath11 , @xmath12 a _ transition operator _ , and @xmath13 a stopping criterion .    1 .",
    "iteratively apply the transition operator to generate a new population of models at each iteration , so that @xmath14 2 .   repeat ( 1 ) until @xmath13 is satisfied .",
    "the final set of models @xmath15 are the output of the search .",
    "[ al : gs ]    any searching process can be considered as an evolution of a population of models ( possibly a single model ) in the @xmath16-dimensional model space .",
    "the transition operator @xmath12 is the rule that determines to which models the population evolves from the previous population . here",
    ", we assume that the transition operator @xmath12 is independent of the time step @xmath6 , which is the case in most algorithms .",
    "different optimization algorithms differ by the strategies in choosing the initial population @xmath17 and the rules of transition from one population of models to another , @xmath12 .    among the searching methods defined via algorithm  [ al : gs ]",
    ", there are two extreme strategies , _ hill - climbing _ ( hc ) and _ uniform monte carlo _ ( umc ) .",
    "hc search is a local descent search applied to a single model ( population size @xmath18 ) .",
    "an initial model @xmath19 is selected ( possibly at random ) and the transition operators @xmath20 are deterministic operators , such as conjugate gradient , quasi - newton , or downhill simplex , which follow a path downhill as far as possible . for objective functions containing more than one local extremum ( _ multi - modal _ ) , the result of hc strongly depends on the choice of the initial model @xmath21 .",
    "umc , on the other hand , selects points with uniform probability in the model space .",
    "the transition operation @xmath12 is simply the selection of new points at random and therefore makes no use of information from previous generations .",
    "thus , if there are @xmath16 parameters and each of them can take @xmath22 possible values , the probability of finding a particular model is proportional to @xmath23 for each function evaluation using umc .",
    "search strategies have been developed that yield a compromise between these two extremes ; almost all of these incorporates stochastic elements , especially in the construction of transition operators .",
    "it is important for the success of global searches that the transition operators make the best use of information provided by the current samples while avoiding being trapped in local extrema . among all these strategies ,",
    "the most widely used are _ simulated annealing _ ( sa ) @xcite , _ genetic algorithms _",
    "( ga ) @xcite and random hill - climbing ( rhc ) , to be defined shortly .",
    "sa and ga searching strategies use stochastic transition operators @xmath12 that are biased towards good samples from the previous generations .",
    "many variations of sa and ga can be found in the literature @xcite .",
    "although the asymptotic convergence results are known for both sa @xcite and ga @xcite these results are hardly useful in practice .",
    "rhc searches , on the other hand , apply deterministic transition operations @xmath12 to a randomly chosen population @xmath17 .",
    "hence rhc explores locally in multiple areas of objective functions , and the resulting samples are a set of local / global extrema .",
    "this search algorithm can be described as    * random hill climbing * @xmath24 + let the randomly chosen initial population size be @xmath25 .",
    "let the stopping criterion @xmath13 be that either gradients of all samples are reduced to the tolerance @xmath26 or the number of iterations reaches a maximum @xmath27 .",
    "let @xmath28 be a local descent search operator .    1 .",
    "choose initial models @xmath29 uniformly at random , where @xmath30 ; 2 .",
    "apply algorithm",
    "[ al : gs ] , @xmath31 .",
    "the final population contains @xmath32 distinct models , @xmath33 .",
    "[ al : rhc ]    by _ uniformly random _ we mean that each components of the initial models are chosen randomly with uniformly probability between the maximum and minimum possible values . in this paper ,",
    "all rhc numerical results use non - linear conjugate gradient as transition operators @xcite .",
    "chavent @xcite developed sufficient conditions for an objective function to be locally convex .",
    "these conditions are based on the distance @xmath34 curvature induced by the objective function on trajectories . in principle , this local convexity criterion could be generalized to global samples of an objective function , to provide a global measure of complexity .",
    "on the other hand , imagine the surface of an objective function being a high - dimensional landscape with hills and basins of different depths and widths scattered on the surface .",
    "performance of searching algorithms depends to a large extent on topographical features on this landscape .    for sa and gas , this situation",
    "is summarized heuristically by kaufmann @xcite :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  annealing works well only in landscapes in which deep energy wells also drain wide basins",
    ". it does not work well on either a random landscape or a `` golf course '' potential , which is flat everywhere except for a unique `` hole '' . in the latter case ,",
    "the landscape offers no clue to guide search . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ recombination ( in gas ) is useless on uncorrelated landscapes but useful under two conditions ( 1 ) when the high peaks are near one another and hence carry mutual information about their joint locations in genotype space and ( 2 ) when parts of the evolving system are quasi - independent of one another and hence can be interchanged with modest chances that the recombined system had the advantage of both parents .  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    in addition , since rhc uses local - descent transition operators , its performance will also be strongly influenced by topography .",
    "it has been proposed that functions can be characterized by their spatial correlation properties @xcite .",
    "several typical combinatorial optimization problems have been investigated by studying the correlation in landscapes : the tsp @xcite , graph - bipartitioning problem @xcite , and the @xmath35 model problems , a spin - glass like problem in biology @xcite . using correlation features of the objective function s landscape as a criterion",
    ", these authors study the effectiveness of particular global algorithms for certain types of landscapes .",
    "in addition , analyzing the topography of high - dimensional energy functions is important in physics and chemistry .",
    "berry and breitengraser - kunz @xcite studied topography and dynamics of multidimensional inter - atomic potential surfaces by analyzing a population of local minima , each of which has two saddle points connected to it . by connecting these samples in a certain order ,",
    "the high - dimensional function surface is represented by a series of one - dimensional lines . by looking at these one - dimensional plots ,",
    "the topography information is represented by the width and depth of the primary , secondary or tertiary basins of attractions @xcite .",
    "the structure of high - dimensional hamiltonians has also been studied by means of entropy @xcite . for an @xmath16-dimensional hamiltonian , a collection of local extrema",
    "are first found by some means .",
    "contributions of these local - minima are represented by a probability distribution @xmath36 where @xmath37 here , @xmath38 is the estimated width of the @xmath39th basin of attraction along the @xmath40th coordinate .",
    "the @xmath16-dimensional surface is then characterized by the following entropy , @xmath41    in this paper , we use a similar measure .",
    "however , we estimate @xmath42 by random hill - climbing rather than equation  [ eq : area ] .",
    "further , we base our measure not on @xmath42 itself , but rather on a related probability that takes into account of the values of the local minima .",
    "we also perform a confidence interval analysis . finally , as a concrete application",
    ", we show that this measure can be used to compute the optimal simplification of a multi - resolution analysis ( mra ) of highly non - convex seismic optimization problem .",
    "the surface topography of functions is largely associated with the number of local minima , widths of the basin of attractions associated with these minima , and relative depths of these basins .",
    "the _ basin of attraction _ associated with the @xmath39th local minimum may be loosely defined as _ the maximum volume @xmath43 in the @xmath16-dimensional model space within which all models can converge to the @xmath39th local minima after infinite number of iterations by a local descent search algorithm .",
    "_ suppose the volume of the entire model space is represented as @xmath44 , then the ratio @xmath45 is the probability of converging to the @xmath39th local minimum for a uniformly random model .",
    "the following definition serves to introduce three quantitative measures of topography : a probability associated with the relative volumes of the basins of attraction ( @xmath46 ) , a version of @xmath46 scaled by the estimated depths of the basins of attractions ( @xmath47 ) and the entropy of @xmath47 .",
    "* entropy - based topography * + let @xmath48 be bounded and have @xmath32 isolated local minima , where @xmath32 is finite .",
    "let @xmath49 be these distinct local minima , and @xmath50 be their corresponding function values .",
    "let @xmath42 be the probability that a model chosen with uniform probability in @xmath3 will converge to the @xmath39th local minimum under the action of an exact local optimization algorithm .",
    "define @xmath51 to be a probability distribution where @xmath52 where @xmath53 $ ] , @xmath54 is the value at the global minimum , @xmath55 , and @xmath56 .",
    "the entropy is defined to be , @xmath57 where the angle brackets denote the expected value with respect to the probability distribution @xmath51 .",
    "[ def : comp ]    for the entropy in definition  [ def : comp ] , it is always the case that @xmath58 .",
    "if the function is unimodal ( only one extremum ) , then @xmath59 .",
    "on the other hand , if the function has @xmath32 isolated and equally valued local extrema , then @xmath60 is @xmath61 .",
    "therefore , the entropy increases with the number of local extrema @xmath32 .    as a simple example , figure  [ f : cosines ] shows two one - dimensional functions with the same number of local minima and widths of basins of attractions ( @xmath62 ) .",
    "however , the difficulty of minimizing these functions is different : the left function has identical basins of attractions , while the one on the right has a dominant global minimum at @xmath63 and decreasingly important local minima away from the center .",
    "the entropy of definition  [ def : comp ] gives a higher @xmath60 value to that of the function on the left ( @xmath64 ) than that on the right ( @xmath65 ) .",
    ", while the function on the right has @xmath65.,width=377 ]    since the functions we are interested in can usually be evaluated only point - wise , the number of local minima @xmath32 and @xmath66 are not known .",
    "some degree of global sampling is essential in order to achieve the characterization we seek .",
    "as shown in algorithm  [ al : rhc ] , rhc explores various regions of the model space and takes initial samples down - hill to the bottom of the basins on the surface of functions .",
    "therefore , a statistical analysis of results of systematic rhc searches can be used to estimate the topographic quantities .",
    "suppose the local - descent search is ideal , i.e. all initial models converge to exact local minima , the number of models converging to each local minima from @xmath25 randomly chosen initial models has a multinomial probability distribution .",
    "if the initial models are randomly chosen under a uniform probability distribution , the probability of converging to the @xmath39th local minimum is proportional to the width of the @xmath39th basin of attraction , @xmath42 .",
    "let @xmath67 be the random variables representing the frequency of models converging to each of the local minima .",
    "for the population of @xmath25 , the joint probability density of these random variables is @xmath68 where @xmath69 . for each @xmath70 $ ]",
    ", the mean value of the random variable @xmath71 is @xmath72 = k \\ , p_i$ ] .",
    "therefore , the convergence frequency of a rhc of large population can be used to estimate the number of local minima as well as the widths of basin of attractions .",
    "hence , the estimation of the entropy measure in definition  [ def : comp ] can be defined as follows .    * entropy - based estimates * + let @xmath73 be bounded and have finite number of isolated local minima .",
    "let @xmath74 be the distinct converged models of rhc searches .",
    "let @xmath75 be the frequency distribution of the final population , and @xmath76 be their corresponding function values .",
    "define the estimated entropy @xmath77 as @xmath78    where @xmath79 is normalized to a probability distribution @xmath80 and @xmath81 in which @xmath82 and @xmath83 where @xmath84 and @xmath85 .",
    "[ def : estimates ]    definition  [ def : estimates ] is a statistical estimation of the entropy in definition  [ def : comp ] . the exact entropy @xmath60 characterizes topographical features of objective function , and hence independent of numerical computation and any searching technique .",
    "the estimation @xmath77 , however , would be influenced by numerical issues . if , for examples , the curvature of the function is nearly zero , which is equivalent to an ill - conditioned hessian matrix , gradient - based local descent searches may not converge to the exact local minima .",
    "the estimated value of @xmath77 in such a situation may be higher than the true complexity @xmath60 . in practice , however , it is often difficult to distinguish the results of such ill - conditioning from those of multi - modality .",
    "therefore , taking such numerical issues into account can represent an important aspect in the difficulty of optimization .      in this section ,",
    "we use the entropy @xmath77 to study two commonly used test functions in optimization , the rosenbrock and griewank functions .",
    "an @xmath16-dimensional rosenbrock function can be written as @xmath86 , \\label{eq : rosenbrock}\\ ] ] where @xmath87 .",
    "although unimodal , the long and narrow basin is a challenge for searching algorithms .",
    "figure  [ f : rosen2d ] shows the function surface and its contour when @xmath88 .",
    "when @xmath89 , the function is still unimodal , but it is not easy to see how the increase of dimensionality alters the difficulty of optimization .",
    "one way of studying the spatial curvature of functions is by looking at the ratio of largest and smallest eigenvalues ( _ condition number _ ) of the hessian at a point .",
    "the hessian for equation  ( [ eq : rosenbrock ] ) is a tri - diagonal matrix , @xmath90 where @xmath91 @xmath92 at the global minimum @xmath93 , the tri - diagonal matrix equation  ( [ eq : hessian ] ) becomes toeplitz except for @xmath94 and @xmath95 .",
    "the condition number of the hessian at the global minimum reaches an asymptote with increasing dimension , as shown in figure  [ f : conditions ] .",
    "figure  [ f : comp_rosen ] shows @xmath77 as a function of the number of dimensions ; it shows the same asymptotic trend as does the condition number .",
    "thus the increasing complexity for low dimensions is the result of increasing ill - conditioning of the hessian and has nothing to do with local minima .              for n - dimensional rosenbrock functions as a function of @xmath16.,width=321 ]      the griewank function",
    "is also used to test optimization algorithms @xcite : @xmath96 the cosine term makes equation  ( [ eq : griew ] ) multi - modal .",
    "figure  [ f : griew - diag ] shows a one - dimensional slice of the griewank function along the diagonal of the hypercube for dimensions @xmath97 .",
    "whitley et al .",
    "@xcite observed such slices and concluded that `` as the dimensionality increases the local optima induced by the cosine decrease in number and complexity '' .",
    "however , such pictures can be misleading since they tell us only about low - dimensional projections of the function .",
    "figure  [ f : griew - orig ] shows slices of the same functions when all but one variables are fixed to be @xmath98 . the increasing dimensionality does not change the oscillation around the global minimum at the origin",
    "therefore , studying the overall performance of high dimensional functions could be tricky .",
    "we compute @xmath77 for the griewank function with a population @xmath99 and @xmath100 models in the hyper - cube of @xmath101 .",
    "figure  [ f : griew ] shows the resulting @xmath77 for dimensions up to @xmath102 for initial populations of both @xmath99 and @xmath100 . both curves in figure  [ f : griew ]",
    "give us consistent results that the complexity of griewank function in this range increases till dimension around @xmath103 , then decreases when number of dimension continuous to increase .",
    "this result can be verified by the analysis of griewank function .",
    "therefore , using the entropy we can understand more comprehensively the dimensional - dependence of complexity of certain functions than by simply looking at hyper - planes .",
    "-dimensional griewank functions.,width=377 ]    -dimensional griewank functions .",
    "all variables but one are fixed at @xmath98.,width=377 ]     as a function of dimension @xmath16 for the griewank function with populations of @xmath99 and @xmath100.,width=377 ]",
    "next we derive confidence intervals on the entropy in definition  [ def : estimates ] .",
    "the following analysis is based on the assumption of _ ideal rhc _ , which is a special case of algorithm  [ al : rhc ] where an infinitely large @xmath27 is allowed and @xmath26 is infinitely small .",
    "first , it is easy to prove that as long as the population size @xmath25 is large enough , @xmath104 defined in equation  ( [ eq : x ] ) would be good approximation to @xmath42 for @xmath105 $ ] .",
    "we have the following theorem , the proof of which is given in the appendix .",
    "let @xmath106 be bounded and have finite number of isolated local minima .",
    "let @xmath42 be the probability of converging to the @xmath39th local minimum for a starting model chosen with uniform probability on @xmath3 .",
    "perform an ideal rhc as defined in algorithm  [ al : rhc ] with an initial population of @xmath25 .",
    "let @xmath107 and @xmath108 be related by the following equation , @xmath109 where @xmath110 has a standard - normal distribution @xmath111 .",
    "let @xmath104 be as defined in equation  ( [ eq : x ] ) .",
    "if the population @xmath25 is such that @xmath112 for any @xmath53 $ ] , we have the following ,    1 .",
    "@xmath104 has an approximate normal distribution with @xmath113 = p_i , \\label{eq : x - mean}\\ ] ] and @xmath114 2 .",
    "@xmath104 is an unbiased , consistent estimator of @xmath42 .",
    "3 .   with confidence of @xmath115 , the error associated with estimating @xmath42 from @xmath104",
    "is bounded by @xmath116    [ th : intervx ]    to get some ideas of the magnitudes of the population size and the confidence interval , here is a simple example .",
    "if for a problem as described in definition  [ def : estimates ] , we have @xmath117 .",
    "then for approximating the binomial distribution with a normal distribution , we need at least @xmath118 .",
    "[ ex : first ]    for the same problem as stated in example  [ ex : first ] , suppose a population size of @xmath119 was used in an ideal rhc , and @xmath120 of the models converged to the @xmath39th local minimum .",
    "then , @xmath121 . if we want to have @xmath122 confidence , then @xmath123 .",
    "the error bound for the estimation of @xmath42 with @xmath104 would be @xmath124 .",
    "that is , with @xmath125 confidence , we can say that @xmath126 .",
    "if , on the other hand , we want to have @xmath127 confidence for this estimation when @xmath128 , then @xmath129 .    in the following theorem , we estimate the distribution and error bound of the estimation for the entropy definition  [ def : estimates ] . the proof of the following theorem is also given in the appendix .",
    "let @xmath130 be bounded and have finite number of isolated local minima .",
    "let @xmath131 be the probability distribution in definition  [ def : comp ] , and @xmath132 .",
    "let @xmath60 be the entropy of @xmath0 ( as in definition  [ def : comp ] ) and suppose the rhc of population @xmath25 is ideal . as a result ,",
    "the initial population of models converge to different local extrema with a frequency distribution of @xmath133 .",
    "finally , let @xmath104 be defined as in equation  [ eq : x ] , and @xmath134 the estimated entropy ( as in definition  [ def : estimates ] ) . if @xmath107 and @xmath108 are defined as in equation  ( [ eq : alpha - beta ] ) , then we can prove the following statements :    1 .",
    "@xmath77 has an approximate normal distribution with @xmath135 = c_e , \\label{eq : ce_mean}\\ ] ] and @xmath136 in which @xmath137 for @xmath138 $ ] , @xmath139 is a scale factor so that @xmath140 , and @xmath141 is as defined in equation  ( [ eq : boltz ] ) .",
    "@xmath77 is an unbiased , consistent estimator of @xmath60 .",
    "3 .   let @xmath142}\\{{\\hat q}_i\\}$ ] . if the population size @xmath25 is such that @xmath143 , then with confidence of @xmath144 , the estimation error of the complexity is at most @xmath145 where @xmath146 .",
    "that is , @xmath147    [ th : confidence ]    when the number of local minima , @xmath32 , is large , the real @xmath148 may very small .",
    "then , an unrealistically large initial population size @xmath25 may be required to satisfy @xmath149 .",
    "realistically , we have to content ourselves with not being able to find all local minima in such difficult situations . if the smallest basin we found with a @xmath25-population rhc is @xmath150 and @xmath151 , there are some @xmath152 which are not found by the rhc .",
    "their corresponding @xmath153 would not be accounted for in the complexity estimation . however , the contributions of these narrow basins to the complexity are proportional to @xmath154 .",
    "since , @xmath155 , the error caused by these narrow basins will be small as long as @xmath156 is small . since @xmath157 for @xmath158 $ ] by definition , these conditions can be easily satisfied as long as these narrow basins are not global minima .",
    "we conclude this section by showing an example of the evaluation of the confidence interval for the griewank function .",
    "it is important to note that in such an analysis , it is assumed that the rhc algorithms are exact .",
    "that is , numerical effects are ignored .",
    "we want to evaluate the confidence interval for the complexity calculation of the @xmath103-dimensional griewank function shown in equation  ( [ eq : griew ] ) . in figure",
    "[ f : griew ] , we show that the complexity estimation for the population of @xmath159 is @xmath160 . using the calculated data , @xmath161 , @xmath162 , and @xmath163 , we can estimate that @xmath164 .",
    "so , with @xmath125 confidence , the error bound would be @xmath165 .",
    "therefore , we can say that the true complexity value @xmath60 is between @xmath166 and @xmath167 .",
    "in exploration seismology , `` statics '' are the time shifts in seismic reflection data caused by heterogeneous material properties in the near surface .",
    "this causes jitter in the data and degrades processing procedures designed to enhance signal - to - noise , such as averaging .",
    "it is possible to formulate an optimization procedure for these static time shifts ( the objective function being the power of the averaged data as a function of time shifts ) , but the resulting optimization problem is highly non - convex @xcite .",
    "this is illustrated in figure  [ f : data3d ] with a toy example .",
    "consider an example where we need to align three otherwise identical traces .",
    "fixing the first trace , we look for time - shifts for the second and third traces , @xmath168 , so that the sum of squares of the stacked traces ( stacking - power ) is maximized .",
    "figure  [ f : data3d ] shows an example of such a two - dimensional objective function , which has hills and basins of attractions scattered on the landscape . in practice",
    ", however , the stacking - power objective function is high - dimensional and highly multi - modal .",
    "monte carlo global optimization have become an important tool for solving large - scale statics problems @xcite .",
    "figure  [ f : data3d ] shows a statics objective function with two unknowns . in practice , however , the time - shifts of the traces are not independent .",
    "the statics of each trace are caused by the combined time distortion of near - source and near - receiver heterogeneities ( _ source - statics _ and _ receiver - statics _ ) .",
    "figure  [ f : demo_stats ] illustrates the similarity of travel paths near each source and each receiver .        the recorded reflection seismic signals are usually sorted into _ midpoints _ @xmath169 ( of the source and receiver locations ) and _ offsets _ @xmath170 ( half distance between the source and receivers ) .",
    "letting @xmath171 and @xmath172 be unknown vectors of source- and receiver - statics , this optimization problem can be formulated as @xmath173 where @xmath174 is the cross - correlation between traces ( after a correction for propagation effects known as `` normal move - out '' has been applied ) of offsets @xmath175 and @xmath176 at midpoint @xmath169 evaluated at @xmath177 and @xmath178 and @xmath179 are the source and receiver indices for midpoint @xmath169 and offset @xmath170 , respectively .",
    "the function @xmath180 in equation  ( [ eq : cross ] ) is called the _ stacking - power function_.    figure  [ f : chart ] shows the recording geometry of one example synthetic data set .",
    "this data set has @xmath181 sources , @xmath182 distinct receivers and @xmath183 traces .",
    "all traces are identical except for random source and receiver statics .",
    "these are generated by repeatedly shifting a single trace of field data .",
    "thus , the objective function of equation  ( [ eq : cross ] ) has @xmath184 unknowns .",
    "when there are no statics in the data , the global maximum of the function is at the origin ( @xmath185 ) . figure  [ f : cont_no ] shows an arbitrary 2-d hyper - planes of the stacking - power function along the @xmath186th source and @xmath181 receiver statics .",
    "we have analyzed a realistic synthetic statics problem involving some 320 seismic traces and 55 unknown static time shifts .",
    "a hyperplane through the objective function for this problem is shown in figure  [ f : cont_no ] .",
    "in addition to simply computing the entropy of this function we will show how the entropy might be used to quantitatively address issues related to the topography of functions .          rather than using monte carlo global optimization methods to solve the statics problem as in @xcite ,",
    "deng @xcite has proposed , without proof , simplifying the optimization via a multi - resolution analysis ( mra ) of the seismic traces .",
    "the idea is to use a wavelet decomposition to generate successively simpler representations of the seismic data , thereby eliminating progressively more local extrema from the objective function . to be precise , let us define a multi - resolution rhc algorithm :    * mrhc * @xmath187 + let @xmath188 be a sequence of decreasingly smooth operators to be defined below , with @xmath189 an identity operator .    1 .   let @xmath190 ; choose an initial population @xmath191 with size @xmath25 at random ; apply algorithm  [ al : rhc ] , so @xmath192 , and @xmath193 .",
    "2 .   let @xmath194 and @xmath195 ; run algorithm  [ al : rhc ] , @xmath196 .",
    "3 .   decrease the level index @xmath39 by @xmath197 , repeat @xmath198 until @xmath199 .",
    "the final set of models @xmath200 is the solution .",
    "the smoothing operators @xmath188 could be a sequence of low - pass filters with increasingly wider pass - band @xcite , or a sequence of increasingly fine wavelet operators @xcite for decomposing the input seismic data .",
    "the sequence of smoothing operators should be such that the resulting functions , @xmath201 , have the same global feature as does the objective function @xmath0 for all levels and have decreasing number of local optima when the level increases , and @xmath202 .",
    "deng @xcite showed that this could be achieved using the shift - invariant wavelet basis of saito and beylkin @xcite .",
    "we now apply the entropy - based estimation of complexity to study the multi - resolution analysis of the 55 parameter statics problem introduced in the previous section .",
    "figure  [ f : comp_stats ] shows @xmath77 as a function of the wavelet decomposition level using population @xmath159 ; the mean and one - standard deviation error bars are obtained from 32 independent calculations .",
    "results are shown for 6 levels of decomposition using a wavelet operator @xmath203 where @xmath199 is an identity operator , corresponding to use of the original data .",
    "these results indicate that for this particular problem a complexity minimum is achieved for a wavelet decomposition of level 4 .",
    "higher levels of decomposition actually increase the complexity ; presumably this results from the objective function being too flat for local optimization .",
    "thus , the complexity measure gives us a way of choosing a wavelet decomposition level to achieve optimal simplification of an objective function .     as a function of the level of wavelet decomposition.,width=377 ]",
    "we have developed a collection of simple tools for analysis of the topographic complexity of functions based on the application of local optimization to randomly chosen starting models . in particular",
    "we estimate the number of basins of attractions on the function landscape , the widths and depths of these basins and the entropy of the resulting probabilities .",
    "assuming local descent searches are ideal , we have computed the confidence intervals for the sampling error associated with this complexity measure .",
    "there are , on the other hand , several practical issues that we have neglected in this error analysis . among them",
    ", we can mention the convergence error caused by the finite computing time and the finite precision of the local descent algorithms , the criterion for clustering of converged models , and the size of the assumed smallest basin of attraction , @xmath148 .",
    "these issues can be investigated by a monte carlo analysis as shown in figure  [ f : comp_stats ] .",
    "this work is dedicated to the memory of albert tarantola .",
    "the authors thank dr .",
    "bill navidi for useful discussions and comments on a draft of this work .",
    "this work was begun while the authors were at the center for wave phenomena",
    ".    10    e.h.l .",
    "aarts and jan korst . .",
    "wiley , n.y , 1989 .",
    "becker and m.  karplus .",
    "the topography of multidimensional potential energy surfaces : theory and application of peptide structure and kinetics .",
    ", 106:14951517 , 1997 .    r.  s. berry and r.  breitengraser - kunz . topography and dynamics of multidimensional interatomic potential surface .",
    ", 74:39513954 , 1995 .    c.  bunks , f.  m. saleck , s.  zaleski , and g.  chavent .",
    "multiscale seismic waveform inversion . ,",
    "60(5):14571473 , september - october 1995 .",
    "g.  chavent . on the theory and practice of non - linear least - squares .",
    ", 14:5563 , 1991 .    t.  e. davis and j.  c. principe .",
    "a simulated annealing like convergence theory for the simple genetic algorithm . in r.  k. belew and l.b .",
    "booker , editors , _ proceedings of the fourth international conference on genetic algorithms_. morgan kaufmann publishers , san mateo , calif . ,",
    "h.  l. deng .",
    "using multi - resolution analysis to study the complexity of inverse calculations . , 1995 .",
    "h.  l. deng , w.  gouveia , and j.  a. scales .",
    "an object - oriented toolbox for studying optimization problems . in b.",
    "h. jacobsen , k.  moosegard , and p.  sibani , editors , _ inverse methods , interdisciplinary elements of methodology , computation , and applications _ , pages 320330 , berlin , germany , 1996 .",
    "springer - verlag .",
    "j.  e. dennis and r.  b. schnabel . .",
    "prentice - hall inc . , 1987 .",
    "m.  falcioni , u.  m.  b. marconi , p.  m. ginanneschi , and a.  vulpiani .",
    "complexity of the minumum engery configurations .",
    ", 75:637640 , 1995 .",
    "r.  fletcher . .",
    "john wiley & sons , 1987",
    ".    j.  e. freund . .",
    "prentice hall , englewood cliffs , new jersey , 5 edition , 1992 .",
    "d.  e. goldberg and m.  p. samtani .",
    "engineering optimization via genetic algorithms . in _ proceedings of the ninth conference on electronic computation _ , pages 471482 .",
    "b.  hajek .",
    "cooling schedules for optimal annealing .",
    ", 13:311329 , 1988 .",
    "j.  h. holland . .",
    "university of michigan press , ann harbor , mi , 1975 .",
    "s.  a. kauffman and e.  d. weinberger .",
    "the nk model of rugged fitness landscapes and its application to maturation of the immune response .",
    ", 141(2):211 , 1989 .",
    "s.  kaufmann . , chapter 2 - 3 , pages 33117 .",
    "oxford university press , new york , 1993 .",
    "s.  kirkpatrick , c.d .",
    "gelatt , and m.p .",
    "optimization by simulated annealing .",
    ", 220:671680 , 1983 .",
    "d.  h. rothman .",
    "onlinear inversion , statistical mechanics , and residual statics estimation .",
    ", 50:27972807 , 1985 .",
    "d.  h. rothman .",
    "onlinear inversion , statistical mechanics , and residual statics estimation .",
    ", 50:27972807 , 1985 .    d.  h. rothman .",
    "utomatic estimation of large residual statics corrections .",
    ", 51:332346 , 1986 .",
    "n.  saito and g.  beylkin .",
    "multiresolution representations using the auto - correlation functions of compactly supported wavelets . , 41:35853590 , 1993 .",
    "p.  f. stadler .",
    "correlation in landscapes of combinatorial optimization problems .",
    ", 20(6):479482 , nov 1992 .",
    "p.  f. stadler and r.  happel .",
    "correlation structure of the landscape of the graph - bipartitioning problem .",
    ", 25(11):31033110 , june 1992 .",
    "p.  f. stadler and w.  schnabl .",
    "the landscape of the traveling salesman problem .",
    ", 161:337344 , 1992 .",
    "a.  a. trn and a.  ilinskas . .",
    "springer - verlag , berlin , germany , 1989 .",
    "van laarhoven and e.h.l .",
    "reidel , dordrecht , 1987 .",
    "david  j. wales and janothon p.  k. doye .",
    "global optimization by basin - hopping and the lowest energy structures of lennard - jones clusters containing up to 110 atoms . , pages 51115116 , 1997 .",
    "david  j. wales , mark  a. miller , and tiffany  r. walsh .",
    "archetypcal energy landscapes . , 394:758760 , 1998 .",
    "e.  d. weinberger .",
    "correlated and uncorrelated fitness landscapes and how to tell the difference . , 63:325336 , 1990 .",
    "d.  whitley , k.  mathias , s.  rana , and j.  dzubera .",
    "building better test functions .",
    "san mateo , calif . , 1995 .",
    "morgan kaufmann publishers .",
    "* proof : * + let @xmath67 be the random variables that represent the frequency of initial models converging to each local minima . the joint probability density for random variables @xmath204 $ ] for population of @xmath25 is a multinomial distribution .",
    "the marginal distribution for each of the random variables is , @xmath205 and the corresponding statistical quantities are , @xmath206   =   k \\ ,",
    "p_i , \\;\\;\\;\\ ;",
    "var(k_i )   =   k p_i ( 1-p_i),\\ ] ] for @xmath138 $ ] .    1 .   for @xmath25 such that @xmath112 , the above binomial distribution can be approximated by a normal distribution .",
    "that is , the random variable , @xmath207 approaches to standard normal distributions @xmath208 ( theorem  * 6.8 * of @xcite ) , where @xmath104 is defined in equation  ( [ eq : x ] ) .",
    "therefore , @xmath104 has a normal distribution with the mean and variance as in equations  ( [ eq : x - mean ] ) and ( [ eq : x - variance ] ) .",
    "2 .   from equation  ( [ eq : x - mean ] )",
    ", we see that @xmath104 is an unbiased estimator of @xmath42 .",
    "since @xmath209 , we have @xmath210 therefore , @xmath211 @xmath104 is also a consistent estimator of @xmath42 for each @xmath53 $ ] .",
    "now with confidence of @xmath212 , we have @xmath213 where the value of @xmath214 can be looked up from a standard normal distribution table .",
    "+ however , we do not know @xmath42 in advance .",
    "approximating @xmath42 by @xmath104 when @xmath25 is large , we have the confidence interval for the true @xmath42 @xmath215 for @xmath70 $ ] ( theorem  * 11.6 * of @xcite ) .",
    "* proof : * + from theorem  [ th : intervx ] , we know that each random variable @xmath104 for @xmath70 $ ] has an approximate normal distribution @xmath217 when the population @xmath25 is such that @xmath218 . since @xmath219 , then @xmath79 also has an approximate normal distribution @xmath220 .",
    "since @xmath79 would be very close to @xmath153 when @xmath25 is large , we can make the following approximation , @xmath221 which is a linear function of the random variable @xmath79 .",
    "therefore , @xmath222 is also approximate normal distribution , @xmath223 & = & q_i \\ln q_i , \\\\",
    "var({\\hat q}_i \\ln { \\hat q}_i ) & = & ( 1 + \\ln q_i)^2 \\frac{c^2\\ , v^2_i \\,p_i\\ , ( 1-p_i)}{k}. \\label{eq : mean}\\end{aligned}\\ ] ]    1 .",
    "since @xmath77 is a linear combination of @xmath224 for @xmath70 $ ] , @xmath225 also has an approximate normal distribution .",
    "then , we have , @xmath226 = - \\sum_{i=1}^n e[{\\hat q}_i \\ln { \\hat q}_i ]    = - \\sum_{i=1}^n   q_i \\ln q_i = c_e,\\end{aligned}\\ ] ] and @xmath227 + for calculating @xmath228 , recall equations  ( [ eq : approx ] ) and ( [ eq : mean ] ) , @xmath229 \\\\   & = & ( 1+\\ln q_i)\\,(1 + \\ln q_j ) cov({\\hat q}_i , { \\hat q}_j ) \\\\   & = & ( 1+\\ln q_i)\\,(1 + \\ln q_j ) c^2 v_i \\ , v_j \\ ,",
    "cov(x_i , x_j).\\end{aligned}\\ ] ] we know that for a multinomial distribution , @xmath230 therefore , @xmath231 so , the variance of @xmath77 is @xmath232 2 .   from equation  ( [ eq : ce_mean ] ) , we see that this estimation is unbiased . since @xmath157 and @xmath153 is non - zero for each @xmath53 $ ] , and @xmath233 in equation  ( [ eq : ce_variance ] )",
    ", we can have @xmath234 therefore , we have @xmath235 and hence @xmath77 is a consistent estimator of @xmath60 .",
    "3 .   if the population size is large enough that @xmath236 , then with confidence of @xmath212 , the estimation error of the complexity @xmath77 is at most @xmath237 , where @xmath238 .",
    "that is , @xmath239 replacing @xmath42 with the approximation @xmath104 in @xmath240 and considering @xmath157 , we have @xmath241 since @xmath242 , it is always true that @xmath243 .",
    "we have the third result of this theorem , @xmath244"
  ],
  "abstract_text": [
    "<S> a basic issue in optimization , inverse theory , neural networks , computational chemistry and many other problems is the geometrical characterization of high dimensional functions . in inverse calculations </S>",
    "<S> one aims to characterize the set of models that fit the data ( among other constraints ) . </S>",
    "<S> if the data misfit function is unimodal then one can find its peak by local optimization methods and characterize its width ( related to the range of data - fitting models ) by estimating derivatives at this peak . on the other hand , </S>",
    "<S> if there are local extrema , then a number of interesting and difficult problems arise . </S>",
    "<S> are the local extrema important compared to the global or can they be eliminated ( e.g. , by smoothing ) without significant loss of information ? </S>",
    "<S> is there a sufficiently small number of local extrema that they can be enumerated via local optimization ? </S>",
    "<S> what are the basins of attraction of these local extrama ? can two extrema be joined by a path that never goes uphill ? can the whole problem be reduced to one of enumerating the local extrema and their basins of attraction ? for locally ill - conditioned functions , premature convergence of local optimization can be confused with the presense of local extrema . </S>",
    "<S> addressing any of these issues requires topographic information about the functions under study . </S>",
    "<S> but in many applications these functions may have hundreds or thousands of variables and can only be evaluated pointwise ( by some numerical method for instance ) . in this paper </S>",
    "<S> we describe systematic ( but generic ) methods of analysing the topography of high dimensional functions using local optimization methods applied to randomly chosen starting models . </S>",
    "<S> we provide a number of quantitative measures of function topography that have proven to be useful in practical problems along with error estimates . </S>"
  ]
}