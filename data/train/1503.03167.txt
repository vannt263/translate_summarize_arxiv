{
  "article_text": [
    "deep learning has led to remarkable breakthroughs in automatically learning hierarchical representations from images .",
    "models such as convolutional neural networks ( cnns ) @xcite , restricted boltzmann machine - based generative models @xcite , and auto - encoders @xcite have been successfully applied to produce multiple layers of increasingly abstract visual representations .",
    "however , there is relatively little work on characterizing the optimal representation of the data . while cohen _",
    "_ @xcite have considered this problem by proposing a theoretical framework to learn irreducible representations having both invariances and equivariances , coming up with the best representation for any given task is an open question .",
    "various work @xcite has been done on the theory and practice of representation learning , and from this work a consistent set of desiderata for representations has emerged : invariance , meaningfulness of representations , abstraction , and disentanglement .",
    "in particular , bengio _ et al .",
    "_ @xcite propose that a _ disentangled _ representation is one for which changes in the encoded data are sparse over real - world transformations ; that is , changes in only a few latents at a time should be able to represent sequences which are likely to happen in the real world .",
    "the `` vision as inverse graphics '' model suggests a representation for images which provides these features .",
    "computer graphics consists of a function to go from compact descriptions of scenes ( the _ graphics code _ ) to images , and this graphics code is typically disentangled to allow for rendering scenes with fine - grained control over transformations such as object location , pose , lighting , texture , and shape .",
    "this encoding is designed to easily and interpretably represent sequences of real data so that common transformations may be compactly represented in software code ; this criterion is almost identical to that of bengio _ et al .",
    "_ , and graphics codes conveniently align with the properties of an ideal representation .    recent work in inverse graphics @xcite follows a general strategy of defining a probabilistic or deterministic model with latent parameters , then using an inference or optimization algorithm to find the most appropriate set of latent parameters given the observations . recently ,",
    "@xcite moved beyond this two - stage pipeline by using a generic encoder network and a domain - specific decoder network to approximate a 2d rendering function .",
    "however , none of these approaches have been shown to automatically produce a semantically - interpretable graphics code and to learn a 3d rendering engine to reproduce images .    in this paper , we present an approach for learning interpretable _ graphics codes _ for complex transformations such as out - of - plane rotations and lighting variations . given a set of images , we use a hybrid encoder - decoder model to learn a representation that is disentangled with respect to various transformations such as object out - of - plane rotations and lighting variations . to achieve this",
    ", we employ a deep directed graphical model with many layers of convolution and de - convolution operators that is trained using the stochastic gradient variational bayes ( sgvb ) algorithm @xcite .",
    "we propose a training procedure to encourage each group of neurons in the _ graphics code _ layer to distinctly represent a specific transformation . to learn a disentangled representation , we train using data where each mini - batch has a set of active and inactive transformations , but we do not provide target values as in supervised learning ; the objective function remains reconstruction quality .",
    "for example , a nodding face would have the 3d elevation transformation active but its shape , texture and other affine transformations would be inactive .",
    "we exploit this type of training data to force chosen neurons in the _ graphics code _ layer to specifically represent active transformations , thereby automatically creating a disentangled representation .",
    "given a single face image , our model can re - generate the input image with a different pose and lighting .",
    "we present qualitative and quantitative results of the model s efficacy at learning a 3d rendering engine .",
    "as mentioned before , a number of generative models have been proposed in the literature to obtain abstract visual representations .",
    "unlike most rbm - based models @xcite , our approach is trained using back - propagation with objective function consisting of data reconstruction and the variational bound .    relatively recently , kingma _ et al . _",
    "@xcite proposed the sgvb algorithm to learn generative models with continuous latent variables . in this work , a feed - forward neural network ( encoder )",
    "is used to approximate the posterior distribution and a decoder network serves to enable stochastic reconstruction of observations . in order to handle fine - grained geometry of faces , we work with relatively large scale images ( @xmath0 pixels ) .",
    "our approach extends and applies the sgvb algorithm to jointly train and utilize many layers of convolution and de - convolution operators for the encoder and decoder network respectively .",
    "the decoder network is a function that transform a compact _ graphics code _ (  200 dimensions ) to a @xmath0 image .",
    "we propose using unpooling ( nearest neighbor sampling ) followed by convolution to handle the massive increase in dimensionality with a manageable number of parameters .",
    "recently , @xcite proposed using cnns to generate images given object - specific parameters in a supervised setting . as their approach requires ground - truth labels for the _ graphics code _ layer , it can not be directly applied to image interpretation tasks .",
    "our work is similar to ranzato _ et al . _",
    "@xcite , whose work was amongst the first to use a generic encoder - decoder architecture for feature learning .",
    "however , in comparison to our proposal their model was trained layer - wise , the intermediate representations were not disentangled like a _ graphics code _ , and their approach does not use the variational auto - encoder loss to approximate the posterior distribution .",
    "our work is also similar in spirit to @xcite , but in comparison our model does not assume a lambertian reflectance model and implicitly constructs the 3d representations .",
    "another piece of related work is desjardins _ et al . _",
    "@xcite , who used a spike and slab prior to factorize representations in a generative deep network .    in comparison to existing approaches , it is important to note that our encoder network produces the interpretable and disentangled representations necessary to learn a meaningful 3d graphics engine .",
    "a number of inverse - graphics inspired methods have recently been proposed in the literature @xcite . however , most such methods rely on hand - crafted rendering engines .",
    "the exception to this is work by hinton _",
    "_ @xcite and tieleman @xcite on _ transforming autoencoders _ which use a domain - specific decoder to reconstruct input images .",
    "our work is similar in spirit to these works but has some key differences : ( a ) it uses a very generic convolutional architecture in the encoder and decoder networks to enable efficient learning on large datasets and image sizes ; ( b ) it can handle single static frames as opposed to pair of images required in @xcite ; and ( c ) it is generative .",
    "as shown in figure [ fig : overview ] , the basic structure of the deep convolutional inverse graphics network ( dc - ign ) consists of two parts : an encoder network which captures distribution over _ graphics codes _",
    "@xmath1 given data @xmath2 and a decoder network which learns a conditional distribution to produce an approximation @xmath3 given @xmath1 .",
    "@xmath1 can be a disentangled representation containing a factored set of latent variables @xmath4 such as pose , light and shape .",
    "this is important in learning a meaningful approximation of a 3d graphics engine and helps tease apart the generalization capability of the model with respect to different types of transformations .",
    "let us denote the encoder output of dc - ign to be @xmath5 .",
    "the encoder output is used to parametrize the variational approximation @xmath6 , where @xmath7 is chosen to be a multivariate normal distribution .",
    "there are two reasons for using this parametrization : ( 1 ) gradients of samples with respect to parameters @xmath8 of @xmath7 can be easily obtained using the reparametrization trick proposed in @xcite , and ( 2 ) various statistical shape models trained on 3d scanner data such as faces have the same multivariate normal latent distribution @xcite .",
    "given that model parameters @xmath9 connect @xmath10 and @xmath11 , the distribution parameters @xmath12 and latents @xmath1 can then be expressed as : @xmath13    we present a novel training procedure which allows networks to be trained to have disentangled and interpretable representations .",
    "the main goal of this work is to learn a representation of the data which consists of disentangled and semantically interpretable latent variables .",
    "we would like only a small subset of the latent variables to change for sequences of inputs corresponding to real - world events .",
    "one natural choice of target representation for information about scenes is that already designed for use in graphics engines .",
    "if we can deconstruct a face image by splitting it into variables for pose , light , and shape , we can trivially represent the same transformations that these variables are used for in graphics applications .",
    "figure [ fig : latentslegend ] depicts the representation which we will attempt to learn .     is the azimuth of the face",
    ", @xmath14 is the elevation of the face with respect to the camera , and @xmath15 is the azimuth of the light source . [",
    "fig : latentslegend],scaledwidth=75.0% ]    to achieve this goal , we perform a training procedure which directly targets this definition of disentanglement .",
    "we organize our data into mini - batches corresponding to changes in only a single scene variable ( azimuth angle , elevation angle , azimuth angle of the light source ) ; these are transformations which might occur in the real world .",
    "we will term these the _ extrinsic _ variables , and they are represented by the components @xmath16 of the encoding .",
    "we also generate mini - batches in which the three extrinsic scene variables are held fixed but all other properties of the face change . that is , these batches consist of many different faces under the same viewing conditions and pose .",
    "these _ intrinsic _ properties of the model , which describe identity , shape , expression , etc . , are represented by the remainder of the latent variables @xmath17}$ ] .",
    "these mini - batches varying intrinsic properties are interspersed stochastically with those varying the extrinsic properties .",
    "we train this representation using sgvb , but we make some key adjustments to the outputs of the encoder and the gradients which train it .",
    "the procedure ( figure [ fig : selectivetraining ] ) is as follows .    1 .",
    "select at random a latent variable @xmath18 which we wish to correspond to one of \\{azimuth angle , elevation angle , azimuth of light source , intrinsic properties}. 2 .",
    "select at random a mini - batch in which that only that variable changes .",
    "3 .   show the network each example in the minibatch and capture its latent representation for that example @xmath19 .",
    "4 .   calculate the average of those representation vectors over the entire batch .",
    "5 .   before putting the encoder s output into the decoder ,",
    "replace the values @xmath20 with their averages over the entire batch .",
    "these outputs are `` clamped '' .",
    "calculate reconstruction error and backpropagate as per sgvb in the decoder .",
    "replace the gradients for the latents @xmath20 ( the clamped neurons ) with their difference from the mean ( see section [ targetedinvar ] ) .",
    "the gradient at @xmath18 is passed through unchanged .",
    "8 .   continue backpropagation through the encoder using the modified gradient .    since the intrinsic representation is much higher - dimensional than the extrinsic ones , it requires more training .",
    "accordingly we select the type of batch to use in a ratio of about 1:1:1:10 , azimuth : elevation : lighting : intrinsic ; we arrived at this ratio after extensive testing , and it works well for both of our datasets .",
    "this training procedure works to train both the encoder and decoder to represent certain properties of the data in a specific neuron . by clamping the output of all but one of the neurons , we force the decoder to recreate all the variation in that batch using only the changes in that one neuron s value . by clamping the gradients , we train the encoder to put all the information about the variations in the batch into one output neuron .",
    "( a ) ( b )    this training method leads to networks whose latent variables have a strong _ equivariance _ with the corresponding generating parameters , as shown in figure [ fig : gen ] .",
    "this allows the value of the true generating parameter ( e.g. the true angle of the face ) to be trivially extracted from the encoder .      by training with only one transformation at a time",
    ", we are encouraging certain neurons to contain specific information ; this is equivariance .",
    "but we also wish to explicitly _ discourage _ them from having _ other _ information ; that is , we want them to be invariant to other transformations .",
    "since our mini - batches of training data consist of only one transformation per batch , then this goal corresponds to having all but one of the output neurons of the encoder give the same output for every image in the batch .    to encourage this property of the dc - ign , we train all the neurons which correspond to the inactive transformations with an error gradient equal to their difference from the mean .",
    "it is simplest to think about this gradient as acting on the set of subvectors @xmath21 from the encoder for each input in the batch .",
    "each of these @xmath21 s will be pointing to a close - together but not identical point in a high - dimensional space ; the invariance training signal will push them all closer together .",
    "we do nt care where they are ; the network can represent the face shown in this batch however it likes .",
    "we only care that the network always represents it as still being the same face , no matter which way it s facing .",
    "this regularizing force needs to be scaled to be much smaller than the true training signal , otherwise it can overwhelm the reconstruction goal .",
    "empirically , a factor of @xmath22 works well .",
    "( a ) ( b )",
    "we trained our model on about 12,000 batches of faces generated from a 3d face model obtained from paysan _ et al . _",
    "@xcite , where each batch consists of 20 faces with random variations on face identity variables ( shape / texture ) , pose , or lighting .",
    "we used the _ rmsprop _",
    "@xcite learning algorithm during training and set the meta learning rate to be equal to @xmath23 , the momentum decay to be @xmath24 and weight decay to be @xmath25 .    to ensure that these techniques work on other types of data , we also trained networks to perform reconstruction on images of widely varied 3d chairs from many perspectives derived from the pascal visual object classes dataset as extracted by aubry _",
    "this task tests the ability of the dc - ign to learn a rendering function for a dataset with high variation between the elements of the set ; the chairs vary from office chairs to wicker to modern designs , and viewpoints span 360 degrees and two elevations .",
    "these networks were trained with the same methods and parameters as the ones above .",
    "the decoder network learns an approximate rendering engine as shown in figures ( [ fig : pose],[fig : pose_and_entangledcomparison ] ) . given a static test image",
    ", the encoder network produces the latents @xmath1 depicting scene variables such as light , pose , shape etc .",
    "similar to an off - the - shelf rendering engine , we can independently control these to generate new images with the decoder .",
    "for example , as shown in figure [ fig : pose_and_entangledcomparison ] , given the original test image , we can vary the lighting of an image by keeping all the other latents constant and varying @xmath26 .",
    "it is perhaps surprising that the fully - trained decoder network is able to function as a 3d rendering engine .",
    "( a ) ( b ) ( c )    we also quantitatively illustrate the network s ability to represent pose and light on a smooth linear manifold as shown in figure [ fig : gen ] , which directly demonstrates our training algorithm s ability to disentangle complex transformations . in these plots , the inferred and ground - truth transformation values are plotted for a random subset of the test set .",
    "interestingly , as shown in figure [ fig : gen](a ) , the encoder network s representation of azimuth has a discontinuity at @xmath27 ( facing straight forward ) .      to explore how much of a difference the dc - ign training procedure makes ,",
    "we compare the novel - view reconstruction performance of networks with entangled representations ( baseline ) versus disentangled representations ( dc - ign ) .",
    "the baseline network with entangled representations is identical in every way to the dc - ign , but was trained with sgvb without using the training procedures we propose in this paper .",
    "as in figure [ fig : pose ] , we feed each network a single input image , then attempt to use the decoder to re - render this image at different azimuth angles . to do this , we first must figure out which latent of the entangled representation most closely corresponds to the azimuth .",
    "this we do rather simply .",
    "first , we encode all images in an azimuth - varied batch using the baseline s encoder .",
    "then we calculate the variance of each of the latents over this batch .",
    "the latent with the largest variance is then the one most closely associated with the azimuth of the face , and we will call it @xmath28 . once that is found , the latent @xmath28 is varied for both the models to render a novel view of the face given a single image of that face .",
    "figure [ fig : pose_and_entangledcomparison ] shows that explicit disentanglement is critical for novel - view reconstruction .",
    "we performed a similar set of experiments on the 3d chairs dataset described above .",
    "this dataset contains still images rendered from 3d cad models of 1357 different chairs , each model skinned with the photographic texture of the real chair .",
    "each of these models is rendered in 60 different poses ; at each of two elevations , there are 30 images taken from 360 degrees around the model .",
    "we used approximately 1200 of these chairs in the training set and the remaining 150 in the test set ; as such , the networks had never seen the chairs in the test set from any angle , so the tests explore the networks ability to generalize to arbitrary chairs .",
    "we resized the images to @xmath0 pixels and made them grayscale to match our face dataset .",
    "we trained these networks with the azimuth ( flat rotation ) of the chair as a disentangled variable represented by a single node @xmath29 ; all other variation between images is undifferentiated and represented by @xmath30}$ ] .",
    "the dc - ign network succeeded in achieving a mean - squared error ( mse ) of reconstruction of @xmath31 on the test set .",
    "each image has grayscale values in the range @xmath32 $ ] and is @xmath0 pixels .    in figure",
    "[ fig : chairpose ] we have included examples of the network s ability to re - render previously - unseen chairs at different angles given a single image .",
    "for some chairs it is able to render fairly smooth transitions , showing the chair at many intermediate poses , while for others it seems to only capture a sort of `` keyframes '' representation , only having distinct outputs for a few angles .",
    "interestingly , the task of rotating a chair seen only from one angle requires speculation about unseen components ; the chair might have arms , or not ; a curved seat or a flat one ; etc .",
    "we have shown that it is possible to train a deep convolutional inverse graphics network with interpretable graphics code layer representation from static images . by utilizing a deep convolution and de - convolution architecture within a variational autoencoder formulation ,",
    "our model can be trained end - to - end using back - propagation on the stochastic variational objective function @xcite .",
    "we proposed a training procedure to force the network to learn disentangled and interpretable representations . using 3d face analysis as a working example",
    ", we have demonstrated the invariant and equivariant characteristics of the learned representations .      to scale our approach to handle more complex scenes",
    ", it will likely be important to experiment with deeper architectures in order to handle large number of object categories within a single network architecture .",
    "it is also very appealing to design a spatio - temporal based convolutional architecture to utilize motion in order to handle complicated object transformations .",
    "furthermore , the current formulation of sgvb is restricted to continuous latent variables .",
    "however , real - world visual scenes contain unknown number of objects that move in and out of frame .",
    "therefore , it might be necessary to extend this formulation to handle discrete distributions @xcite or extend the model to a recurrent setting .",
    "the decoder network in our model can also be replaced by a domain - specific decoder @xcite for fine - grained model - based inference .",
    "we hope that our work motivates further research into automatically learning interpretable representations using variants of our model .",
    "we thank thomas vetter for giving us access to the basel face model .",
    "t. kulkarni was graciously supported by the leventhal fellowship .",
    "we would like to thank ilker yildrim , max kleiman - weiner , karthik rajagopal and geoffrey hinton for helpful feedback and discussions ."
  ],
  "abstract_text": [
    "<S> this paper presents the deep convolution inverse graphics network ( dc - ign ) , a model that learns an interpretable representation of images . </S>",
    "<S> this representation is disentangled with respect to transformations such as out - of - plane rotations and lighting variations . </S>",
    "<S> the dc - ign model is composed of multiple layers of convolution and de - convolution operators and is trained using the stochastic gradient variational bayes ( sgvb ) algorithm @xcite . </S>",
    "<S> we propose a training procedure to encourage neurons in the _ graphics code _ layer to represent a specific transformation ( e.g. pose or light ) . given a single input image , our model can generate new images of the same object with variations in pose and lighting . </S>",
    "<S> we present qualitative and quantitative results of the model s efficacy at learning a 3d rendering engine . </S>"
  ]
}