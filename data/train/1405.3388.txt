{
  "article_text": [
    "in blind signal separation or blind source separation ( bss ) one assumes that a @xmath0-variate observable random vector @xmath3 is a linear mixture of @xmath0-variate latent source vector @xmath4 .",
    "the model can thus be written as @xmath5 , where the full rank @xmath6 matrix @xmath7 is so called _ mixing matrix _ and @xmath4 is a random @xmath0-vector with certain preassigned properties . the @xmath0-vector @xmath8 is a location parameter and usually considered as a nuisance parameter , since the main goal in bss is to find an estimate for an _ unmixing matrix _ @xmath9 such that @xmath10 , based on a @xmath11 data matrix @xmath12 from the distribution of @xmath3 .",
    "the bss model was formulated for signal processing and computer science applications in the early 1980 s and since then , many approaches have been suggested to solve the problem under various assumptions on @xmath4 . for an account of the early history of bss ,",
    "see @xcite .",
    "the most popular bss approach is _ independent component analysis ( ica ) _ , which assumes that @xmath13 and @xmath14 , and that the components of @xmath4 are mutually independent .",
    "the ica model is a semiparametric model as the marginal distributions of the components of @xmath4 are not specified at all . for identifiability of the parameters ,",
    "one has to assume , however , that at most one of the components is normally distributed .",
    "typical algorithms for ica use centering and whitening as preprocessing steps : write @xmath15 for the singular value decomposition ( svd ) of the mixing matrix @xmath7 . then , under the above mentioned assumptions on @xmath4 , @xmath16 and @xmath17 , and therefore @xmath18 .",
    "an iterative algorithm can then be applied to @xmath19 to find the orthogonal matrix @xmath20 .",
    "for an overview of ica from a signal processing perspective , see for example  @xcite and  @xcite .    since the late 1990 s , there has been an increasing interest in ica methods among statisticians .",
    "@xcite , for example , used two scatter matrices , @xmath21 and @xmath22 , with the independence property to solve the ica problem .",
    "we say that a @xmath23 matrix valued functional @xmath24 is a _ scatter matrix _ if it is symmetric , positive definite and affine equivariant in the sense that @xmath25 for all full - rank @xmath23 matrices @xmath26 and for all @xmath0-vectors @xmath27 .",
    "moreover , a scatter matrix @xmath24 has the _ independence property _ if @xmath28 is a diagonal matrix for all @xmath4 with independent components .",
    "an unmixing matrix @xmath9 and a diagonal matrix @xmath29 ( diagonal elements in a decreasing order ) then solve the estimating equations @xmath30 the independent components in @xmath31 are thus standardized with respect to @xmath21 and uncorrelated with respect to @xmath22 , and @xmath9 and @xmath29 can be found as eigenvector - eigenvalue solutions for @xmath32 .",
    "an example of such ica methods is the classical fobi ( fourth order blind identification ) method which uses @xmath33 and @xmath34   .\\ ] ] see  @xcite , for example .",
    "the unmixing matrix estimate @xmath35 is naturally obtained by replacing the population values by their sample counterparts .    the limiting statistical properties of several ica unmixing matrix estimates have been developed quite recently and mainly for iid data : for the limiting behavior of the unmixing matrix estimate based on two scatter matrices , see @xcite .",
    "for other recent work and different estimation procedures for ica , see for example @xcite , @xcite , @xcite , @xcite , @xcite , @xcite and @xcite .    in applications such as the analysis of medical images or signals ( eeg , meg or fmri ) and financial or geostatistical times series , the assumption of independent observations does not usually hold .",
    "nevertheless , ica has been considered in this context in  @xcite ,  @xcite ,  @xcite ,  @xcite ,  @xcite and  @xcite among others .",
    "see also @xcite for a slightly different model .",
    "apart from these results , other bss models have been developed for time series data in signal processing literature .",
    "the so called amuse ( algorithm for multiple unknown signals extraction ) and sobi ( second order blind identification ) procedures for the stationary time series bss models were suggested by  @xcite and  @xcite , respectively .",
    "@xcite provided careful analysis of the statistical properties of the amuse and so called deflation - based sobi estimates .",
    "@xcite considered methods that assume only local stationarity .    in this paper",
    "we will continue the work of @xcite and derive the statistical properties of so called symmetric sobi estimate .",
    "we will use a real eeg data example to illustrate how the theoretical results derived in this paper may be used to measure the accuracy of the unmixing matrix estimates .",
    "the structure of this paper is as follows . in section  [ sosmodel ]",
    "we introduce the blind source separation model which assumes second order stationary components . in section  [ sosfunctionals ]",
    "we recall the definition for the deflation - based sobi functional and define symmetric sobi functional using the lagrange multiplier technique .",
    "the theoretical properties of deflation - based and symmetric sobi estimators are given in general case in section  [ properties ] .",
    "further , in section  [ mainf ] the limiting distributions of the two sobi estimators will be more concretely compared under the assumption of @xmath36 processes .",
    "the theoretical results are illustrated using simulation studies in section  [ mdsec ] and a real eeg data example in section  [ eeg ] before the paper is concluded in section  [ conclusion ] .",
    "asymptotical results for the symmetric sobi estimates are proven in the appendix .",
    "we assume that the observable @xmath0-variate time series @xmath37 are distributed according to @xmath38 where @xmath8 is a @xmath0-vector , @xmath7 is a full - rank @xmath23 mixing matrix and @xmath39 is a @xmath0-variate latent time series that satisfies    * @xmath40 and @xmath41 . * @xmath42 is diagonal for all @xmath43 .",
    "example time series @xmath4 : three independent stationary ar series .",
    ", scaledwidth=80.0% ]    this is again a semiparametric model as only the moment assumptions ( a1)-(a2 ) of the time series in @xmath4 are made .",
    "the assumptions state that the @xmath0 time series in @xmath4 are weakly stationary and uncorrelated .",
    "this model is called the _ second order source separation ( sos ) model_. a model with stronger assumptions , i.e. the _ independent component time series model _ , is obtained if the condition ( a2 ) is replaced by the condition    * the @xmath0 times series in @xmath4 are mutually independent and @xmath42 is diagonal for all @xmath43 .",
    "figure  [ sources ] serves as an example of a 3-variate time series @xmath4 with three independent components , namely @xmath44 processes with coefficient vectors @xmath45 , @xmath46 and @xmath47 . the observable 3-variate time series @xmath3 consisting of three different mixtures of the latent time series in @xmath4 are shown in figure  [ data ] .",
    "given the observed time series @xmath48 , the aim is to find an estimate @xmath35 of an unmixing matrix @xmath9 such that @xmath31 has uncorrelated components . clearly , @xmath49 is an unmixing matrix for any @xmath23 matrix @xmath50 with exactly one nonzero element in each row and in each column .",
    "notice that the signs and order of the components of @xmath4 and the signs and order of the columns of @xmath7 are confounded also in the bss model .",
    "additional assumptions are therefore needed in order to study the consistency and asymptotical properties of @xmath35 .",
    "contrary to ica in the iid case , the mixing matrix may now be identifiable for any number of gaussian components . however , as we will see later in this paper , weak assumptions on the autocovariance matrices @xmath51 , @xmath52 , have to be made for the identifiability of our functionals and for the study of the asymptotic properties of corresponding estimates .",
    "time series @xmath3 : mixtures of the three independent stationary ar series in figure  [ sources ] .",
    ", scaledwidth=80.0% ]",
    "the separation of uncorrelated stationary time series can be solely based on autocovariances and cross - autocovariances of the @xmath0 time series .",
    "assume that @xmath3 follows a centered sos model with @xmath53 .",
    "this is not a restriction in our case as the asymptotical properties of the estimated autocovariances are the same for known and unknown @xmath8 .",
    "it then follows that @xmath54 assume also that , for some lag @xmath55 , the diagonal elements of the autocovariance matrix @xmath56 are distinct .",
    "an unmixing matrix functional @xmath57 is then defined as a @xmath23 matrix that satisfies @xmath58 where @xmath59 is a diagonal matrix with the same diagonal elements as in @xmath51 but in a decreasing order .",
    "( as in pca and ica , the signs of the rows of @xmath57 are not fixed in this definition . ) the components of @xmath60 are thus the components of @xmath4 in a permuted order .",
    "the permutation matrix @xmath61 remains unidentifiable .",
    "notice that @xmath57 is affine equivariant , that is , the transformation @xmath62 with a full - rank @xmath23 matrix @xmath26 induces the transformation @xmath63 .",
    "this implies that @xmath64 does not depend on the mixing matrix @xmath7 at all .",
    "the corresponding sample statistic , the so called amuse ( algorithm for multiple unknown signals extraction ) estimator , was proposed by  @xcite .",
    "figure  [ amusefig ] shows the estimated latent sources obtained with amuse , @xmath65 , from the data in figure  [ data ] .",
    "see @xcite for a recent study of the statistical properties of the amuse estimate .     obtained with amuse from @xmath3 in figure  [ data ] .",
    ", scaledwidth=80.0% ]    the drawback of the amuse procedure is the assumption that , for the chosen lag @xmath66 , the eigenvalues in @xmath51 must be distinct .",
    "this is of course never known in practice .",
    "therefore , the choice of @xmath66 may have a huge impact on the performance of the method , as only information coming from @xmath67 and @xmath68 is used . to overcome this drawback ,  @xcite proposed the sobi ( second order blind indentification ) algorithm that aims to jointly diagonalize several autocovariance matrices as follows .",
    "let @xmath69 be @xmath70 autocovariance matrices with distinct lags @xmath71 .",
    "the @xmath23 unmixing matrix functional @xmath72 is the matrix that minimizes @xmath73 under the constraint @xmath74 , or , equivalently , maximizes @xmath75 under the same constraint .",
    "here we write diag@xmath76 for a @xmath23 diagonal matrix with the diagonal elements as in @xmath77 and off@xmath78diag@xmath76 .",
    "next notice that , as @xmath74 , then @xmath79 for some orthogonal @xmath23 matrix @xmath80 .",
    "if then @xmath81 , @xmath82 , are the autocorrelation matrices , the solution for @xmath83 can be found by maximizing @xmath84 under the orthogonality constraints @xmath85 .    in the literature ,",
    "several algorithms to solve the maximization problem in  ( [ max1b ] ) are proposed : in deflation - based approach , the rows of @xmath83 are found one by one using some pre - assigned rule . in the symmetric approach ,",
    "the rows are found simultaneously .",
    "the solution @xmath79 naturally depends on the approach as well as on the concrete algorithm used in the optimization . in the following we consider deflation - based and symmetric approaches in more detail .      in the deflation - based approach ,",
    "the rows of an unmixing matrix functional @xmath72 are found one by one so that @xmath86 , @xmath87 , maximizes @xmath88 under the constraints @xmath89 , @xmath90 .",
    "recall that the kronecker delta @xmath91 as @xmath92 .    the solution @xmath86 then optimizes the lagrangian function @xmath93 where @xmath94 are the lagrangian multipliers .",
    "write @xmath95 the unmixing matrix functional @xmath9 found in this way then satisfies the following estimating equations  @xcite .",
    "[ djd ] the deflation - based unmixing matrix functional @xmath72 solves the @xmath96 estimating equations @xmath97    recall that @xmath79 with some orthogonal matrix @xmath80 and , in the deflation - based approach , the rows of @xmath83 are found one by one as well .",
    "the estimating equations then suggest the following fixed point algorithm for the deflation - based solution .",
    "after finding @xmath98 , the following two steps are repeated until convergence to get @xmath99 .",
    "@xmath100 here @xmath101 .",
    "notice that the algorithm naturally needs initial values for each @xmath102 , @xmath87 , and different initial values may change the rows of the estimate and produce them in a permuted order .",
    "therefore , for @xmath99 , one should use several randomly selected initial values to guarantee that the true maximum in ( [ max2 ] ) is attained at each stage . for a more detailed study of this algorithm ,",
    "see appendix  a in  @xcite .      in the symmetric approach ,",
    "the rows of an unmixing matrix functional @xmath72 are found simultaneously .",
    "we then consider the maximization of @xmath103 under the constraint @xmath104 .",
    "the matrix @xmath9 now optimizes the lagrangian function @xmath105 where the symmetric matrix @xmath106 contains the @xmath107 lagrangian multipliers of the optimization problem . at the solution",
    "@xmath9 we then have @xmath108 where @xmath109 is as in  ( [ t ] ) .",
    "multiplying both sides from the left by @xmath110 gives @xmath111 for @xmath112 , and @xmath113 for @xmath114 .",
    "hence the solution @xmath9 must satisfy the following estimating equations .    [ sjd ] the symmetric unmixing matrix functional @xmath72 solves the estimating equations @xmath115    time series @xmath116 obtained with symmetric sobi from @xmath3 in figure  [ data ] . ,",
    "scaledwidth=80.0% ]    notice that the exact joint diagonalization is possible only if the matrices @xmath117 have the same sets of eigenvectors .",
    "this is naturally true for the population matrices in the sos model . for estimated autocorrelation matrices from a continuous sos model ,",
    "the eigenvectors are however almost surely different .",
    "as @xmath79 , the estimating equations for @xmath80 are @xmath118 where again @xmath101 .",
    "the equations then suggest a new fixed point algorithm with the two steps @xmath119 figure  [ sobifig ] shows the estimated latent sources obtained from the data in figure  [ data ] . in the signal processing literature , there are several other algorithms available for approximate simultaneous diagonalization of @xmath70 matrices .",
    "the most popular one for sobi is based on jacobi rotations @xcite .",
    "surprisingly , our new algorithm and the algorithm based on jacobi rotations seem to yield exactly the same solutions for practical data sets .",
    "notice also that the symmetric procedure does not fix the order of the rows of @xmath83 . to guarantee that the deflation - based and symmetric procedures estimate the same @xmath83",
    ", we can reorder the rows of @xmath80 so that @xmath120",
    "in this section we derive the asymptotical properties of the two competing sobi estimates under sos model  ( [ bssmodel ] ) . we may assume without loss of generality that @xmath53 and consider the limiting properties of the deflation - based and symmetric sobi estimates based on the autocovariance matrices @xmath121 with lags @xmath122 .",
    "we then need some additional assumptions that are specific for these choices .",
    "first , we assume    * the diagonal elements of @xmath123 are strictly decreasing .",
    "assumption ( a3 ) guarantees the identifiability of the mixing matrix ( with the specified autocovariance matrices ) and fixes the order of the component time series in our model .",
    "our unmixing matrix estimate is based on the sample autocovariance matrices @xmath124 .",
    "we then further assume that the estimates of the autocovariance matrices are root-@xmath125 consistent , that is ,    * @xmath126 and @xmath127 , @xmath128 as @xmath129 .    whether ( a4 ) is true or not depends on the distribution of the latent @xmath0-variate time series @xmath4 .    for the estimated autocovariance matrices , write then @xmath130 the deflation - based and symmetric",
    "unmixing matrix estimates are obtained when the functionals are applied to estimated autocovariance matrices and , consequently , they solve the following estimating equations",
    ".    [ estimates ] the unmixing matrix estimate @xmath131 based on @xmath132 and @xmath133 solves the estimating equations @xmath134 or @xmath135    using the estimating equations and assumptions ( a1)-(a4 ) , one easily derives the following results . the first part was already proven in  @xcite . for the proof of the second part ,",
    "see the appendix .",
    "[ maintheorem ] under the assumptions ( a1)-(a4 ) we have    * the deflation - based @xmath136 , and for @xmath137 , @xmath138}{\\sum_k\\lambda_{kj}(\\lambda_{kj}-\\lambda_{ki})}+o_p(1 ) , & \\",
    "i > j,\\end{aligned}\\ ] ] * the symmetric @xmath139 , and for @xmath137 , @xmath140    } { \\sum_k ( \\lambda_{kj}-\\lambda_{ki})^2}+o_p(1 ) , & \\ i\\ne j.\\end{aligned}\\ ] ]    first note that , for @xmath126 , the limiting distribution of the diagonal element @xmath141 only depends on the limiting distribution of @xmath142 , @xmath137 .",
    "hence , the comparison of the estimates should be made only using the off - diagonal elements . also , @xmath143 and the limiting behavior of @xmath144 is therefore similar for both approaches .",
    "if the joint limiting distribution of the ( vectorized ) autocovariance matrices is multivariate normal , slutsky s theorem implies that the same is true also for the unmixing matrix estimates .",
    "[ asympn ] under the assumptions ( a1)-(a4 ) , if the joint limiting distribution of @xmath145\\ ] ] is a ( singular ) @xmath146-variate normal distribution with mean value zero , then the joint limiting distribution of @xmath147 is a singular @xmath148-variate normal distribution .    in section  [ mainf ]",
    "we consider multivariate @xmath36 processes since their autocovariance matrices have limiting joint multivariate normal distribution .",
    "so far , we have assumed that the true value of @xmath7 is @xmath149 . due to the affine equivariance of @xmath35 , the limiting distribution of @xmath150",
    "does not depend on @xmath7 .",
    "if , for @xmath126 , @xmath151 then , for any full - rank true @xmath7 , @xmath152 and @xmath153 moreover , for any true @xmath7 and @xmath154 , @xmath155 which implies that @xmath156",
    "an example of multivariate time series having a limiting multivariate normal distribution is a ma@xmath1 process . from now on we assume that @xmath157 are uncorrelated multivariate ma@xmath1 processes , that is , @xmath158 where @xmath159 are standardized iid @xmath0-vectors and @xmath160 , @xmath161 , are diagonal matrices satisfying @xmath162 .",
    "hence @xmath163 is also a multivariate ma@xmath1 process .",
    "notice that every second - order stationary process is either a linear process ( ma(@xmath2 ) ) or can be transformed to a such one using wold s decomposition .",
    "notice also that causal arma@xmath164 processes are ma@xmath1 processes ( see for example chapter  3 in @xcite ) .    for our assumptions , we need the following notation and definitions .",
    "we say that a @xmath23 matrix @xmath165 is a sign - change matrix if it is a diagonal matrix with diagonal elements @xmath166 , and @xmath167 is a @xmath23 permutation matrix if it is obtained from an identity matrix by permuting its rows and/or columns . for the iid @xmath159",
    ", we then assume that    * @xmath159 are iid with @xmath168 and @xmath169 and with finite fourth order moments , and * the components of @xmath159 are exchangeable and marginally symmetric , that is , @xmath170 for all sign - change matrices @xmath165 and for all permutation matrices @xmath167 .    assumption ( b1 )",
    "implies that @xmath171 and that @xmath172 and @xmath173 are bounded for all @xmath174 .",
    "the above assumptions also imply that the model  ( [ mamodel ] ) satisfies assumptions ( a1)-(a2 ) .      to obtain the limiting distributions of the ( symmetrized ) sample autocovariance matrices @xmath175,\\ ] ] we define @xmath176 where @xmath177 is the vector of the diagonal elements of @xmath178 , @xmath179 .",
    "the diagonal elements of @xmath180 are the autocovariances of the components of @xmath4 at lag @xmath181 .",
    "we also define the @xmath23 matrices @xmath182 , @xmath183 , with elements @xmath184 the @xmath185th element of @xmath182 is the limiting covariance of @xmath186 and @xmath187 .",
    "the following lemma is proved in @xcite .",
    "[ maasymp ] assume that @xmath188 is a multivariate @xmath36 process defined in  ( [ process ] ) that satisfies ( b1 ) and ( b2 ) . then the joint limiting distribution of @xmath189 is a singular @xmath146-variate normal distribution with mean value zero and covariance matrix @xmath190 with submatrices of the form @xmath191 where @xmath192    if we assume ( b1 ) but replace ( b2 ) by    * the components of @xmath159 are mutually independent ,    then , in this independent component model case",
    ", the joint limiting distribution of @xmath193 is again as given in lemma  [ maasymp ] but with @xmath194 for @xmath195 .",
    "if we further assume that innovations @xmath159 are iid from @xmath196 , then @xmath197 and @xmath194 for all @xmath195 , and the variances and covariances in lemma  [ maasymp ] become even more simplified .",
    "the first part of the next theorem was presented in @xcite , the second part is new .",
    "[ maasympd ] assume that @xmath188 is an observed time series from the @xmath36 process ( [ mamodel ] ) that satisfies ( b1 ) , ( b2 ) and ( a3 )",
    ". assume ( wlog ) that @xmath126 .",
    "if @xmath198 is the sobi estimate , then the limiting distribution of @xmath199 is a @xmath0-variate normal distribution with mean zero and covariance matrix    * ( deflation - based case ) @xmath200 where @xmath201 with @xmath202 , or * ( symmetric case ) @xmath203 where , for @xmath204 , @xmath205 with @xmath206 .",
    "in this section we compare asymptotic and finite - sample efficiencies of the two sobi estimates .",
    "the performance of the estimates in simulation studies can be measured using for example the minimum distance index ( mdi )  @xcite @xmath207 where @xmath208 is the matrix ( frobenius ) norm and @xmath209 the minimum distance index is invariant with respect to the change of the mixing matrix , and it is scaled so that @xmath210 .",
    "it is also surprisingly easy to compute .",
    "the smaller the mdi - value , the better is the performance .    from the asymptotic point of view",
    ", the most attractive property of the minimum distance index is that for an estimate @xmath35 with @xmath211 , the limiting distribution of @xmath212 is that of a weighted sum of independent chi squared variables with the expected value @xmath213 notice that tr@xmath214 equals the sum of the limiting variances of the off - diagonal elements of @xmath215 and therefore provides a global measure of the variation of the estimate @xmath35 .",
    "if for example pca , fobi , amuse , deflation - based sobi and symmetric sobi are used to find the latent times series based on @xmath3 given in figure  [ data ] , the minimum distance index gets the values @xmath216 respectively . as pca and fobi",
    "are solely based on the 3-variable marginal distribution of the observations , they ignore time order and temporal dependence present in data .",
    "of course , there is no reason why pca should perform well here .",
    "similarly , fobi can be used for independent time series only if the latent series have distinct kurtosis values . the failure of these two methods in this example",
    "is clearly demonstrated by their high mdi values .",
    "amuse performs better here than pca and fobi , but is still much worse than symmetric sobi .",
    "clearly the first lag is not a good choice for the separation in this example .    finally recall that , in the signal processing literature , several other indices have been proposed for the finite sample comparisons of the performance of the unmixing matrix estimates ( for an overview see for example  @xcite ) .",
    "one of the most popular performance indices , the amari index @xcite , is defined as @xmath217 - 2,\\ ] ] where @xmath218 .",
    "the index is invariant under permutations and sign changes of the rows and columns of @xmath219 .",
    "however , heterogeneous rescaling of the rows ( or columns ) on @xmath219 changes its value .",
    "therefore , for the comparisons , the rows of @xmath35 should be rescaled in a similar way .",
    "we prefer mdi , since the amari index is based on the @xmath220 norm and can not be easily related to the limiting distribution of the unmixing matrix estimate .",
    "the following four models were chosen for the comparison of the deflation - based and symmetric sobi estimates .",
    "the components of the source vectors are    * three ma(10)-series with coefficient vectors + @xmath221 , + @xmath222 and + @xmath223 , + respectively , and normal innovations , * three ar - series with coefficient vectors @xmath224 , @xmath225 and @xmath226 , respectively , and normal innovations , * three arma - series with ar - coefficient vectors @xmath227 , + @xmath228 , @xmath229 , and ma - coefficient vectors + @xmath230 , @xmath231 , + @xmath232 , respectively , and normal innovations , * three ar(1)-series with coefficients @xmath233 , @xmath234 and @xmath235 , respectively , and normal innovations .",
    "each component is scaled to unit variance . due to the affine equivariance of the estimates ,",
    "it is not a restriction to use @xmath236 in the comparisons .",
    "the asymptotic efficiency of the estimates can be compared using the sum of the limiting variances of the off - diagonal elements of @xmath215 . in table",
    "[ table1 ] , these values are listed for the symmetric and deflation - based sobi estimates , when both methods are using lags @xmath237 in all four models .",
    ".[table1]the sums of the estimated variances of selected rows of @xmath35 for the symmetric sobi estimates utilizing four candidate sets of lags . [ cols=\"<,^,^,^,^ \" , ]     as the results of table  [ table2 ] indicate , the symmetric sobi method that used autocovariance matrices with lags in set ( 2 ) gave best separation results for the three components of interest .",
    "these findings are confirmed by the time plots of separated components in figure  [ eegest ] .",
    "the good performance of symmetric sobi based on lags in set ( 2 ) is especially visible when looking at the corresponding eye blink and horizontal eye movement components .",
    "estimated eye blink ( top figure ) , horizontal eye movement ( middle figure ) and muscle activity ( bottom figure ) components of length @xmath238 , from 20001 to 30000 .",
    "the components are estimated using symmetric sobi method with lags given in sets ( 1)-(4 ) , respectively.,title=\"fig : \" ] 0.5truecm   estimated eye blink ( top figure ) , horizontal eye movement ( middle figure ) and muscle activity ( bottom figure ) components of length @xmath238 , from 20001 to 30000 .",
    "the components are estimated using symmetric sobi method with lags given in sets ( 1)-(4 ) , respectively.,title=\"fig : \" ] 0.5truecm   estimated eye blink ( top figure ) , horizontal eye movement ( middle figure ) and muscle activity ( bottom figure ) components of length @xmath238 , from 20001 to 30000 .",
    "the components are estimated using symmetric sobi method with lags given in sets ( 1)-(4 ) , respectively.,title=\"fig : \" ]",
    "symmetric sobi is a popular blind source separation method but a careful analysis of its statistical properties has been missing so far .",
    "the theoretical results for deflation - based sobi were presented only recently in @xcite .",
    "there is a lot of empirical evidence that symmetric bss methods perform better than their deflation - based competitors . in this paper",
    "we used the lagrange multiplier technique to derive estimating equations for symmetric sobi that allowed a thorough theoretic analysis of the properties of the estimate . in most cases we studied ,",
    "the limiting efficiency of the symmetric sobi estimate was better than that of the deflation - based estimate .",
    "the estimating equations also suggested a new algorithm for symmetric sobi .",
    "such an algorithm gave , in all our simulations , exactly the same results as the most popular algorithm based on jacobi rotations .",
    "in a separate paper , these and other algorithms with associated estimates are compared in various settings with different values of @xmath0 and @xmath70 .",
    "the problem corresponding to the selection of lags is still open ; only few ad - hoc guidelines are available in the literature , see for example @xcite .",
    "we followed these guidelines in our eeg data example .",
    "notice however that the results presented in this paper can be used to build a two - stage estimation procedure where , at stage 2 , the final sobi estimate is selected among all sobi estimates using their estimated efficiencies in a model determined by a preliminary sobi estimate applied at stage 1 .",
    "the results derived here can also be applied to different inference procedures , including hypothesis testing and model selection .",
    "this research was supported by the academy of finland ( grants 256291 and 268703 ) .",
    "we thank dr .",
    "jarmo hmlinen for providing us with the eeg data .",
    "a stochastic algorithm for probabilistic independent component analysis .",
    ", 125160 .",
    "( 1996 ) . a new learning algorithm for blind source separation .",
    ", 757763    ( 1997 ) . a blind source separation technique using second - order statistics .",
    ", 434444 .",
    "consistent noisy independent component analysis .",
    ", 1225 .",
    "second edition , springer - verlag , new york .",
    "efficient independent component analysis .",
    ", 28252855 .",
    "portfolio value at risk based on independent component analysis .",
    ", 594607 .",
    "a least squares version of algorithm as 211 : the f - g diagonalization algorithm . , 317321 .    ( 2010 ) . academic press ,",
    "amsterdam    ( 2011 ) .",
    "working paper 11 - 16 , statistics and econometrics series 11 , universidad carlos iii de madrid .",
    "( 2012 ) . a conditionally heteroscedastic independent factor model with an application to finacial stock returns .",
    ", 7093 .",
    "r - estimation for asymmetric independent component analysis . .",
    "independent component analysis through product density estimation . 649656 , mit press , cambridge , ma .",
    "john wiley & sons , new york .",
    "( 2010a ) .",
    "characteristics of multivariate distributions and the invariant coordinate system . , 18441853 .",
    "( 2010 ) . a new performance index for ica : properties computation and asymptotic analysis . 229236 , springer , heidelberg .",
    "semiparametrically efficient inference based on signed ranks in symmetric independent component models .",
    ", 24482476 .",
    "source separation : from dusk till dawn .",
    ", 1526 .",
    "independent component analysis involving autocorrelated sources with an application to functional magnetic resonance imaging .",
    ", 10091024 .",
    "dynamic orthogonal components for multivariate time series . , 14501463 .",
    "( 2012 ) . statistical properties of a blind source separation estimator for stationary time series . , 18651873 .",
    "bssasymp : covariance matrices of some bss mixing and unmixing matrix estimates .",
    "r package version 1.0 - 0 .",
    "http://cran.r-project.org/web/packages/bssasymp .",
    "deflation - based separation of uncorrelated stationary time series . .",
    "( 2014 ) . on robustifying some second order blind source separation methods for nonstationary time series .",
    "jade : jade and other bss methods as well as some bss performance criteria .",
    "r package version 1.9 - 91 .",
    "http://cran.r-project.org/web/packages/jade .",
    "deflation - based fastica reloaded . in the proceedings of _",
    "19th european signal processing conference 2011 ( eusipco 2011 ) _ , 18541858 .",
    "( 2011 ) . on the performance indices of ica and blind source separation . in the proceedings of _ 2011 ieee 12th international workshop on signal processing advances in wireless communications ( spawc 2011 ) _ , 486490 .",
    "scatter matrices and independent component analysis . , 175189 .",
    "further research on independent component analysis .",
    ", 9496 .",
    "independent component analysis via nonparametric maximum likelihood estimation . , 29733002 .",
    "knowledge - based gene expression classification via matrix factorization .",
    "( 15):16881697 .",
    ". recovery of correlated neuronal sources from eeg : the good and bad ways of using sobi .",
    ", 507519 .",
    "( 1990 ) . : a new blind identification algorithm .",
    ", 17841787 .",
    "* proof of theorem  [ maintheorem ] *   + ( i ) the proof for the consistency and limiting behavior of the deflation - based sobi estimate can be found in @xcite .",
    "\\(ii ) we first prove the consistency of the estimate .",
    "let @xmath239 be the compact set of all @xmath23 orthogonal matrices . for @xmath240 , write @xmath241 as @xmath242 and @xmath243 , for @xmath82 , @xmath244 under our assumptions",
    ", @xmath245 is the unique maximizer of @xmath246 in the subspace @xmath247 notice that , in this subspace @xmath239 , the order and signs of the rows of @xmath83 are fixed . for",
    "all @xmath248 , write next @xmath249 and @xmath250 clearly , @xmath251 and @xmath252 as @xmath253 .",
    "let @xmath254 be the unique maximizer of @xmath255 in @xmath256 .",
    "then @xmath257 and the convergence @xmath258 follows .",
    "thus @xmath259 also holds true .    to prove the second part of the result ( ii ) , notice that the estimating equations give @xmath260 for @xmath261 , and @xmath262 next note that @xmath263 and @xmath264 for all @xmath261 .",
    "the result then follows from equations ( [ eq1])-([eq4 ] ) ."
  ],
  "abstract_text": [
    "<S> blind source separation ( bss ) is a signal processing tool , which is widely used in various fields . </S>",
    "<S> examples include biomedical signal separation , brain imaging and economic time series applications . in bss </S>",
    "<S> , one assumes that the observed @xmath0 time series are linear combinations of @xmath0 latent uncorrelated weakly stationary time series . </S>",
    "<S> the aim is then to find an estimate for an unmixing matrix , which transforms the observed time series back to uncorrelated latent time series . in sobi </S>",
    "<S> ( second order blind identification ) joint diagonalization of the covariance matrix and autocovariance matrices with several lags is used to estimate the unmixing matrix . </S>",
    "<S> the rows of an unmixing matrix can be derived either one by one ( deflation - based approach ) or simultaneously ( symmetric approach ) . </S>",
    "<S> the latter of these approaches is well - known especially in signal processing literature , however , the rigorous analysis of its statistical properties has been missing so far . in this paper </S>",
    "<S> , we fill this gap and investigate the statistical properties of the symmetric sobi estimate in detail and find its limiting distribution under general conditions . </S>",
    "<S> the asymptotical efficiencies of symmetric sobi estimate are compared to those of recently introduced deflation - based sobi estimate under general multivariate ma@xmath1 processes . </S>",
    "<S> the theory is illustrated by some finite - sample simulation studies as well as a real eeg data example .    </S>",
    "<S> keywords : asymptotic normality ; blind source separation ; joint diagonalization ; ma(@xmath2 ) ; sobi </S>"
  ]
}