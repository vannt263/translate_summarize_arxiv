{
  "article_text": [
    "making inferences based on natural - language statements is a crucial part of true natural - language understanding , and thus has many important applications .",
    "as the field of nlp has matured , there has been a resurgence of interest in creating systems capable of making such inferences , as evidenced by the activity surrounding the ongoing sequence of `` recognizing textual entailment '' ( rte ) competitions @xcite and the aquaint knowledge - based evaluation project @xcite .",
    "the following two examples help illustrate the particular type of inference that is the focus of this paper .    1 .   ` _ we the epidemic spreadquickly _ ' 2 .   ` _ we the epidemic spreadquickly _ '",
    "a relaxation of ` _ spreadquickly _ ' is ` _ spread _ ' ; a restriction of it is ` _ spreadquicklyvia fleas _ ' . from statement",
    ", we can infer the relaxed version , ` _ we know the epidemic spread _ ' , whereas the restricted version , ` _ we know the epidemic spreadquicklyvia fleas _ ' , does not follow . but the reverse holds for statement : it entails the restricted version ` _ we doubt the epidemic spreadquicklyvia fleas _ ' , but not the relaxed version .",
    "the reason is that ` _ doubt _ ' is a _ downward - entailingoperator _ ; in other words , it allows one to , in a sense , `` reason from sets to subsets '' ( * ? ? ?",
    "downward - entailing  operatorsare not restricted to assertions about belief or to verbs .",
    "for example , the preposition ` _ without _ ' is also downward entailing : from ` _ the applicants came without payment or waivers _ ' we can infer that all the applicants came without payment .",
    "( contrast this with ` _ with _ ' , which , like ` _ know _ ' , is _",
    "upward entailing_. ) in fact , there are many downward - entailingoperators , encompassing many syntactic types ; these include explicit negations like ` _ no _ ' and ` _ never _ ' , but also many other terms , such as ` _ refuse ( to ) _ ' , ` _ preventing _ ' , ` _ nothing _ ' , ` _ rarely _ ' , and ` _ too [ adjective ] to _ ' .    as the prevalence of these operators indicates and as ( * ? ? ?",
    "92 ) states , downward entailment``plays an extremely important role in natural language '' @xcite . yet to date , only a few systems attempt to handle the phenomenon in a general way , i.e. , to consider more than simple direct negation @xcite .",
    "these systems rely on lists of items annotated with respect to their behavior in `` polar '' ( positive or negative ) environments .",
    "the lists contain a relatively small number of downward - entailingoperators , at least in part because they were constructed mainly by manual inspection of verb lists ( although a few non - verbs are sometimes also included ) .",
    "_ we therefore propose to automatically learn downward - entailingoperators  henceforth deoperatorsfor short  from data ; deriving more comprehensive lists of deoperatorsin this manner promises to substantially enhance the ability of textual - inference systems to handle monotonicity - related phenomena . _",
    "[ [ summary - of - our - approach ] ] summary of our approach + + + + + + + + + + + + + + + + + + + + + + +    there are a number of significant challenges to applying a learning - based approach .",
    "first , to our knowledge there do not exist de - operator - annotated corpora , and moreover , relevant types of semantic information are `` not available in or deducible from any public lexical database '' @xcite .",
    "also , it seems there is no simple test one can apply to all possible candidates ; ( * ? ? ?",
    "110 ) remarks , `` as a rule of thumb , assume that everything that feels negative , and everything that [ satisfies a condition described below ] , is monotone decreasing .",
    "this rule of thumb will be shown to be wrong as it stands ; but it sort of works , like any rule of thumb . ''",
    "our first insight into how to overcome these challenges is to leverage a finding from the linguistics literature , _ ladusaw s @xcite hypothesis _ ,",
    "which can be treated as a cue regarding the distribution of deoperators : it asserts that a certain class of lexical constructions known as _ negative polarity items ( npis ) _ can only appear in the scope of deoperators .",
    "note that this hypothesis suggests that one can develop an _ unsupervised _ algorithm based simply on checking for co - occurrence with known npis .",
    "but there are significant problems with applying this idea in practice , including : ( a ) there is no agreed - upon list of npis ; ( b ) terms can be ambiguous with respect to npi - hood ; and ( c ) many non - deoperatorstend to co - occur with npis as well . to cope with these issues , we develop a novel unsupervised _ distillation _ algorithm that helps filter out the noise introduced by these problems .",
    "this algorithm is very effective : it is accurate and derives many deoperatorsthat do not appear on pre - existing lists .",
    "[ [ contributions ] ] contributions + + + + + + + + + + + + +    our project draws a connection between the creation of textual entailment systems and linguistic inquiry regarding deoperatorsand npis , and thus relates to both language - engineering and linguistic concerns .    to our knowledge",
    ", this work represents the first attempt to aid in the process of _ discovering _ deoperators , a task whose importance we have highlighted above . at the very least",
    ", our method can be used to provide high - quality raw materials to help human annotators create more extensive deoperatorlists .",
    "in fact , while previous manual - classification efforts have mainly focused on verbs , we retrieve deoperatorsacross multiple parts of speech .",
    "also , although we discover many items ( including verbs ) that are not on pre - existing manually - constructed lists , the items we find occur frequently  they are not somehow peculiar or rare .",
    "our algorithm is surprisingly accurate given that it is quite resource- and knowledge - lean .",
    "specifically , it relies only on ladusaw s hypothesis as initial inspiration , a relatively short and arguably noisy list of npis , and a large unannotated corpus .",
    "it does _ not _ use other linguistic information  for example , we do not use parse information , even though c - command relations have been asserted to play a key role in the licensing of npis @xcite .",
    "we mentioned in the introduction some significant challenges to developing a machine - learning approach to discovering deoperators .",
    "the key insight we apply to surmount these challenges is that in the linguistics literature , it has been hypothesized that there is a strong connection between deoperatorsand _ negative polarity items ( npis ) _ , which are terms that tend to occur in `` negative environments '' .",
    "an example npi is ` _ anymore _ ' : one can say ` _ we do nt have those anymore _ ' but not ` _ @xmath0we have those anymore _ ' .    specifically , we propose to take advantage of the seminal hypothesis of ( * ? ? ?",
    "* influenced by @xcite , inter alia ) :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ( ladusaw ) npis only appear within the scope of downward - entailingoperators .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    this hypothesis has been actively discussed , updated , and contested by multiple parties ( * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* inter alia ) .",
    "it is not our intent to comment ( directly ) on its overall validity .",
    "rather , we simply view it as a very useful starting point for developing computational tools to find deoperators indeed , even detractors of the theory have called it `` impressively algorithmic '' ( * ? ? ? *",
    "361 ) .    first , a word about scope . for ladusaw",
    "s hypothesis , scope should arguably be defined in terms of c - command , immediate scope , and so on ( * ? ? ?",
    "but for simplicity and to make our approach as resource - lean as possible , we simply assume that potential deoperatorsoccur to the left of npis , except that we ignore text to the left of any preceding commas or semi - colons as a way to enforce a degree of locality .",
    "for example , in both ` _ by the way , we do nt have plants @xmath1 because they died _ ' and ` _ we do nt have plants @xmath1 _ ' , we look for deoperatorswithin the sequence of words ` _ we do nt have plants _ ' .",
    "we refer to such sequences in which we seek deoperatorsas _ npi contexts_.    now , ladusaw s hypothesis suggests that we can find deoperatorsby looking for words that tend to occur more often in npi contextsthan they occur overall .",
    "we formulate this as follows :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ assumption : _ for any deoperator@xmath2 , @xmath3 .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    here , @xmath4 is the number of occurrences of @xmath2 in npi contexts occurs multiple times in a single npi contextwe only count it once ; this way we `` dampen the signal '' of function words that can potentially occur multiple times in a single sentence . ]",
    "divided by the number of words in npi contexts , and @xmath5 refers to the number of occurrences of @xmath6 relative to the number of words in the corpus .",
    "an additional consideration is that we would like to focus on the discovery of _ novel _ or non - obvious deoperators .",
    "therefore , for a given candidate deoperator@xmath7 , we compute @xmath8 : the value of @xmath9 that results _ if we discard all npi contexts containing a deoperatoron a list of 10 well - known instances _ , namely , ` _ not _ ' , ` _ nt _ ' , ` _ no _ ' , ` _ none _ ' , ` _ neither _ ' , ` _ nor _ ' , ` _ few _ ' , ` _ each _ ' , ` _ every _ ' , and ` _ without _ ' .",
    "( this list is based on the list of deoperatorsused by the rte system presented in @xcite . )",
    "this yields the following scoring function : @xmath10    [ [ distillation ] ] distillation + + + + + + + + + + + +    there are certain terms that are not deoperators , but nonetheless co - occur with npis as a side - effect of co - occurring with true deoperatorsthemselves .",
    "for instance , the proper noun ` _ milken _ ' ( referring to michael milken , the so - called  junk - bond king \" ) occurs relatively frequently with the deoperator`_denies _ ' , and ` _ vigorously _ ' occurs frequently with deoperatorslike ` _ deny _ ' and ` _ oppose _ ' .",
    "we refer to terms like ` _ milken _ ' and ` _ vigorously _ ' as  piggybackers \" , and address the piggybackers problem by leveraging the following intuition : in general , we do not expect to have two deoperatorsin the same npi context .",
    "one way to implement this would be to re - score the candidates in a winner - takes - all fashion : for each npi context , reward only the candidate with the highest score @xmath11 .",
    "however , such a method is too aggressive because it would force us to pick a single candidate even when there are several with relatively close scores  and we know our score @xmath11 is imperfect .",
    "instead , we propose the following  soft \" mechanism .",
    "each sentence distributes a `` budget '' of total score 1 among the candidates it contains according to the relative scores of those candidates ; this works out to yield the following new _ distilled _ scoring function @xmath12 where @xmath13 is an npi - contextnormalizing factor and @xmath14 is the number of npi contextscontaining the candidate @xmath15 . this way , plausiblecandidatesthat have high @xmath11 scores relative to the other candidates in the sentence receive enhanced @xmath16 scores .",
    "to put it another way : apparently plausiblecandidatesthat often appear in sentenceswith multiple good candidates ( i.e. , piggybackers ) receive a low distilled score , despite a high initial score .",
    "our general claim is that the higher the distilled score of a candidate , the better its chances of being a deoperator .    [",
    "[ choice - of - npis ] ] choice of npis + + + + + + + + + + + + + +    our proposed method requires access to a set of npis .",
    "however , there does not appear to be universal agreement on such a set .",
    "@xcite mention some doubts regarding approximately 200 ( ! ) of the items on a roughly 350-item list of german npis @xcite . for english ,",
    "the `` moderately complete '' @xcite list contains two to three dozen items ; however , there is also a list of english npis that is several times longer ( * ? ? ?",
    "* written in german ) , and @xcite asserts that english should have hundreds of npis , similarly to french and dutch .",
    "we choose to focus on the items on these lists that seem most likely to be effective cues for our task .",
    "specifically , we select a subset of the lawler npis , focusing mostly on those that do not have a relatively frequent non - npi sense .",
    "an example discard is ` _ much _ ' , whose npi - hood depends on what it modifies and perhaps on whether there are degree adverbs pre - modifying it @xcite .",
    "there are some ambiguous npis that we do retain due to their frequency .",
    "for example , ` _ any _ ' occurs both in a non - npi `` free choice '' variant , as in ` _ any idiot can do that _ ' , and in an npi version .",
    "although it is ambiguous with respect to npi - hood , ` _",
    "any _ ' is also a very valuable cue due to its frequency . ) .",
    "] here is our npi list :    [ cols= \" < , < , < , < \" , ]     [ [ effect - of - distillation ] ] effect of distillation + + + + + + + + + + + + + + + + + + + + + +    in order to evaluate the importance of the distillationprocess , we study how the results change when distillationis omitted ( thus using as score function @xmath11 from equation [ un_distilled_score ] rather than @xmath16 ) . when comparing the results ( summarized in figure [ fig : bars]b ) with those of the complete system ( figure [ fig : bars]a ) we observe that the distillationindeed has the desired effect : the number of highly ranked words that are annotated as not - dedecreases after distillation",
    "this results in an increase of the precision at @xmath17 ranging from 5% to 10% ( depending on @xmath17 ) , as can be observed by comparing the height of the composite bars in the two figures .",
    "importantly , this improvement does indeed seem to stem at least in part from the distillation process handling the piggybacking problem . to give just a few examples : ` _ vigorously _ ' is pushed down from rank 48 ( undistilled scoring ) to rank 126 ( distilled scoring ) , ` _ one - day _ ' from @xmath18 to @xmath19 , ` _ vowed _ ' from @xmath20 to @xmath21 , and ` _ milken _ ' from @xmath22 to @xmath23 .",
    "it is natural to ask whether the ( expected ) decrease in precision at @xmath17 is due to the algorithm assigning relatively low scores to deoperators , so that they do not appear in the top 150 , or due to there being no more more true deoperatorsto rank .",
    "we can not directly evaluate our method s recall because no comprehensive list of deoperatorsexists .",
    "however , to get a rough impression , we can check how our system ranks the items in the largest list we are aware of , namely , the ladusaw ( implicit ) list mentioned above . of the 31 deoperatorlemmas on this list ( not including the 10 well - known deoperators ) , only 7 of those frequent enough to be considered by our algorithm are not in its top 150 outputs , and only 5 are not in the top 300",
    ". remember that we only annotated the top 150 outputs ; so , there may be many other deoperatorsbetween positions 150 and 300 .",
    "another way of evaluating our method would be to assess the effect of our newly discovered deoperatorson downstream rte system performance .",
    "there are two factors to take into account .",
    "first , the deoperatorswe discovered are quite prevalent in naturally occurring text : the 90 de(nd )  operatorsappearing in our algorithm s top 150 outputs occur in 111,456 sentences in the bllip corpus ( i.e. , in 6% of its sentences ) .",
    "second , as previously mentioned , systems do already account for monotonicity to some extent",
    " but they are limited by the fact that their deoperatorlexicons are restricted mostly to well - known instances ; to take a concrete example with a publicly available rte system : nutcracker @xcite correctly infers that ` _ we did know the disease spread _ '",
    "entails ` _ we did know the disease spread quickly _ ' but it fails to infer that ` _ we the disease spread _ ' entails ` _ we the disease spread quickly _ ' .",
    "so , systems can use monotonicity information but currently do not have enough of it ; our method can provide them with this information , enabling them to handle a greater fraction of the large number of naturally occurring instances of this phenomenon than ever before .",
    "@xcite , in describing modular approaches to textual entailment , hints that npis may be used within a negation - detection sub - component .",
    "there is a substantial body of work in the linguistics literature regarding the definition and nature of polarity items @xcite .",
    "however , very little of this work is computational .",
    "there has been passing speculation that one might want to learn polarity - inverting verbs ( * ? ? ?",
    "there have also been a few projects on the discovery of npis , which is the converse of the problem we consider .",
    "@xcite discusses some of the difficulties with corpus - based determination of npis , including `` rampant '' polysemy and the problem of `` how to determine independently which predicates should count as negative ''  a problem which our work addresses .",
    "lichte and soehn @xcite consider finding german npis using a method conceptually similar in some respects to our own , although again , their objective is the reverse of ours .",
    "their discovery statistic for single - word npis is the ratio of within - licenser - clause occurrences to total occurrences , where , to enhance precision , the list of licensers was filtered down to a set of fairly unambiguous , easily - identified items .",
    "they do not consider distillation , which we found to be an important component of our de - operator - detection algorithm .",
    "their evaluation scheme , unlike ours , did not employ a bias - compensation mechanism .",
    "they did employ a collocation - detection technique to extend their list to multi - word npis , but our independent experiments with a similar technique ( not reported here ) did not yield good results .",
    "to our knowledge , this work represents the first attempt to discover downward entailing  operators .",
    "we introduced a unsupervised algorithm that is motivated by research in linguistics but employs simple distributional statistics in a novel fashion .",
    "our algorithm is highly accurate and discovers many reasonable deoperatorsthat are missing from pre - existing manually - built lists .    since the algorithm is resource - lean",
    " requiring no parser or tagger but only a list of npis  it can be immediately applied to languages where such lists exist , such as german and romanian @xcite . on the other hand , although the results are already quite good for english , it would be interesting to see what improvements could be gained by using more sophisticated syntactic information .    for languages where npi lists are not extensive",
    ", one could envision applying an iterative co - learning approach : use the newly - derived deoperatorsto infer new npis , and then discover even more new deoperatorsgiven the new npi list .",
    "( for english , our initial attempts at bootstrapping from our initial npi list on the bllip corpus did not lead to substantially improved results . )    in practice , subcategorization is an important feature to capture . in table",
    "[ tab : pos ] , we indicate which subcategorizations are de",
    ". an interesting extension of our work would be to try to automatically distinguish particular desubcategorizations that are lexically apparent , e.g. , ` _ innocent _ ' ( not de ) vs. ` _ innocent of _ ' ( as in ` _ innocent of burglary _ ' , de ) .",
    "our project provides a connection ( among many ) between the creation of textual entailment systems ( the domain of language engineers ) and the characterization of deoperators(the subject of study and debate among linguists ) .",
    "the prospect that our method might potentially eventually be refined in such a way so as to shed at least a little light on linguistic questions is a very appealing one , although we can not be certain that any progress will be made on that front .",
    "roy bar - haim , ido dagan , bill dolan , lisa ferro , danilo giampiccolo , bernardo magnini , and idan szpektor .",
    "the second pascal recognising textual entailment challenge . in _ proceedings of the second pascal challenges workshop on recognising textual entailment _ , 2006 .",
    "roy bar - haim , jonathan berant , ido dagan , iddo greental , shachar mirkin , eyal shnarch , and idan szpektor .",
    "efficient semantic deduction and approximate matching over compact parse forests . in _ proceedings of tac _ , 2008 .",
    "david dowty .",
    "the role of negative polarity and concord marking in natural language reasoning . in mandy harvey and lynn santelmann , editors , _ proceedings of salt iv _ , pages 114144 , ithaca , new york , 1994 .",
    "cornell university .",
    "gilles fauconnier .",
    "polarity and the scale principle . in _ proceedings of the chicago linguistic society ( cls ) _ ,",
    "pages 188199 , 1975 . reprinted in javier gutierrez - rexach ( ed . ) , _ semantics : critical concepts in linguistics _ , 2003 .",
    "danilo giampiccolo , bernardo magnini , ido dagan , and bill dolan .",
    "the third pascal recognizing textual entailment challenge . in _ proceedings of the acl - pascal workshop on textual entailment and paraphrasing _ , pages 19 , 2007 .",
    "url http://www.aclweb.org/anthology/w/w07/w07-1401 .",
    "jack hoeksema . as ( of )",
    "yet . appears in _ language and cognition 3 _ , the 1992 yearbook of the research group for theoretical and experimental linguistics of the university of groningen , 1993 .",
    "http://www.let.rug.nl/hoeksema/asofyet.pdf .",
    "bill maccartney and christopher  d. manning . modeling semantic containment and exclusion in natural language inference . in _ proceedings of the 22nd international conference on computational linguistics ( coling 2008 ) _ , pages 521528 ,",
    "manchester , uk , august 2008 .",
    "coling 2008 organizing committee .",
    "url http://www.aclweb.org/anthology/c08-1066 .",
    "bernardo magnini .",
    "slides for a presentation entitled `` semantic knowledge for textual entailment '' .",
    "symposium on semantic knowledge discovery , organization and use , new york university , november 14 and 15 , 2008 .",
    "joaquin quionero candela , ido dagan , bernardo magnini , and florence dalch buc , editors .",
    "_ machine learning challenges , evaluating predictive uncertainty , visual object classification and recognizing textual entailment , first pascal machine learning challenges workshop , mlcw 2005 , southampton , uk , april 11 - 13 , 2005 , revised selected papers _ , volume 3944 of _ lecture notes in computer science ( lncs ) _",
    "springer .",
    "anke von bergen and karl von bergen .",
    "_ negative polaritt i m englischen_. gunter narr , 1993 .",
    "list extracted and compiled by manfred sailer , 2008 , http://www.sfs.uni-tuebingen.de/~fr/esslli/08/byday/english-npi.pdf ."
  ],
  "abstract_text": [
    "<S> an important part of textual inference is making deductions involving _ monotonicity _ , that is , determining whether a given assertion entails restrictions or relaxations of that assertion . </S>",
    "<S> for instance , the statement ` _ we the epidemic spreadquickly _ ' does not entail ` _ we know the epidemic spreadquicklyvia fleas _ ' , but ` _ we the epidemic spreadquickly _ ' entails ` _ we doubt the epidemic spreadquicklyvia fleas _ ' . here , </S>",
    "<S> we present the first algorithm for the challenging lexical - semantics problem of learning linguistic constructions that , like ` _ doubt _ ' , are _ </S>",
    "<S> downward entailing(de)_. our algorithm is unsupervised , resource - lean , and effective , accurately recovering many deoperatorsthat are missing from the hand - constructed lists that textual - inference systems currently use .    </S>",
    "<S> _ publication venue : _ naacl hlt 2009 </S>"
  ]
}