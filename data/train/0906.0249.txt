{
  "article_text": [
    "lattice is represented with its _ generator matrix _ @xmath0 , whose entries are real numbers .",
    "let @xmath1 and @xmath2 denote the number of rows and columns of @xmath0 respectively with @xmath3 .",
    "the rows of @xmath0 , which are @xmath4 , are called _ basis vectors _ and are assumed to be linearly independent vectors in @xmath5 .",
    "the lattice of dimension @xmath1 is defined as the set of points @xmath6 this paper is about methods to find the _",
    "closest point _ in a lattice to a given vector @xmath7 , hereafter called _ received vector , _ which requires minimization of the metric @xmath8 over all lattice points @xmath9 with @xmath10 .    in 1981",
    ", pohst @xcite suggested a way of finding the closest point in lattices , which later on was complemented by fincke and pohst in @xcite .",
    "the general method has later become known as _ sphere decoding . _",
    "the implementation details of the fincke  pohst ( fp ) enumeration method were first presented by viterbo and biglieri in @xcite . in 1999 ,",
    "viterbo and boutros applied the fp enumeration method to maximum likelihood ( ml ) detection for finite constellations @xcite . later on , agrell _ et al .",
    "_  in @xcite illustrated that the schnorr - euchner ( se ) refinement @xcite of the fp enumeration strategy improves the complexity of the sphere decoder algorithm .    during the last decade , a lot of work has been done to improve the efficiency of sphere decoder algorithms @xcite , due to the significant usage they have found in numerous types of applications . in communication theory ,",
    "the closest point problem arises in ml detection for multiple - input multiple - output ( mimo ) channels @xcite , ml sequence estimation @xcite , quantization @xcite , vector perturbation in multiuser communications @xcite , and joint detection in direct - sequence multiple access system @xcite .",
    "the closest point search algorithms can be modified to find the ml point in finite constellations @xcite , which has an important application in mimo channels . assuming a system with @xmath1 transmit and @xmath2 receive antennas , the new set of points @xmath11 is defined by replacing @xmath12 in with the finite range of integers @xmath13 the transmit set can be mapped to an @xmath14-pam constellation with @xmath15 .",
    "the received vector after an additive white gaussian noise ( awgn ) channel with double - sided noise power spectral density @xmath16 is @xmath17 where @xmath18 , @xmath7 , @xmath19 , and @xmath20 is a vector of independent and identically distributed ( i.i.d . )",
    "gaussian noise with variance @xmath16 . in this case , ml detection is equivalent to minimization of the metric @xmath8 over all possible points @xmath9 with @xmath18 . in mimo systems where usually quadrature amplitude modulation ( qam ) is used , the @xmath21-qam signal constellation can be viewed as two real - valued @xmath14-pam constellations with @xmath22 , @xmath23 , @xmath24 , and @xmath25 .    for both types of applications , lattices or finite constellations ,",
    "the calculations can be implemented based on @xmath0 , as in the original fp algorithm and its numerous refinements , notably @xcite , or based on @xmath26 @xcite .    in this paper , we draw attention to a hitherto unnoticed problem with the standard algorithms .",
    "it is illustrated that the standard sphere decoder algorithms based on fp @xcite and se @xcite enumeration strategies perform many excessive numerical operations .",
    "a method is proposed to avoid these unnecessary computations .",
    "however , the revision proposed is not related to choosing a more accurate upper bound on @xmath27 or scanning set of feasible point @xmath9 in a different order .",
    "we believe that the se strategy is the best way in this regard .",
    "our modifications instead change how lattice vectors are recursively constructed from lower - dimensional lattices ( for @xmath0-based implementations ) or how the received vector @xmath28 is recursively projected onto the basis vectors ( for @xmath29-based implementations ) , which accounts for most of the floating point calculations in sphere decoding . with the proposed methods ,",
    "not a single value would be calculated twice or remain without any use .",
    "standalone implementations of the new ( and old ) algorithms are given in fig .",
    "[ fig : algorithms ] .",
    "without loss of generality , we assume that @xmath0 is a square lower - triangular matrix with positive diagonal elements @xcite . consequently , @xmath26 is also square with positive diagonal elements .",
    "the decription of the sphere decoding principle in this section takes the @xmath29-based approach .",
    "every lattice can be divided into layers of lower - dimensional lattices .",
    "the diagonal elements of @xmath29 illustrate the distances between these layers , such that @xmath30 represents the distance between the @xmath31-dimensional layers in an @xmath32-dimensional layer .",
    "thus , @xmath33 is the distance between the lattice points in a one - dimensional layer .",
    "[ fig:1 ] illustrates an @xmath1-dimensional hypersphere with radius @xmath34 centered on a vector @xmath28 .",
    "all lattice points inside this hypersphere lie on @xmath35-dimensional layers , which are also hyperspheres .",
    "the basis vector @xmath36 is in the same direction as the hypotenuse of right triangles @xmath37 and @xmath38 , while all the other basis vectors @xmath39 lie in the subspace spanned by one of these @xmath35-dimensional layers .",
    "starting from dimension @xmath1 , the received vector @xmath40 is projected onto the lattice basis vectors @xmath41 .",
    "this is done by a simple matrix multiplication @xmath42 , where @xmath43 . for known @xmath44 and @xmath45 the corresponding range for the integer component @xmath46",
    "is @xcite @xmath47 where @xmath48 and @xmath49 denote the round up and round down operations respectively , which is also intuitively conspicuous from fig .",
    "[ fig:1 ] .",
    "[ cc][][0.75]a [ cc][][0.75]b [ cc][][0.75]c [ cc][][0.75]d [ cc][][0.75]e [ cc][][1]@xmath28 [ cc][][1]@xmath50 [ cc][][1]@xmath36 [ cc][][1]@xmath51 [ cc][][1]@xmath34 [ cc][][1]@xmath52 [ cc][][1]@xmath53 [ cc][][1]@xmath46 -dimensional hypersphere , divided into a stack of @xmath35-dimensional hyperspheres ( layers).,title=\"fig:\",width=302 ]    for each @xmath35-dimensional layer @xmath54 that is to be examined , the orthogonal displacement @xmath51 from the received vector @xmath28 to this layer is calculated , which is shown with line @xmath55 in fig .",
    "[ fig:1 ] .",
    "this displacement follows from the congruence of @xmath37 and @xmath38 : @xmath56    in order to calculate @xmath57 , which will be used later on to calculate the range of @xmath58 and the displacement @xmath59 , the received vector @xmath28 is first projected onto the examined @xmath35-dimensional layer and then to the lattice basis vectors .",
    "we use the notation @xmath60 for the projected received vector @xmath28 , where @xmath61 denotes the dimension of the layer that the received vector is projected on .",
    "thanks to the lower - triangular representation , the orthogonal projection of @xmath28 onto the @xmath35-dimensional layer currently being investigated affects only the last component of @xmath28 .",
    "thus , it is sufficient to subtract @xmath51 from the @xmath1th element of @xmath28 to obtain @xmath62 this positions @xmath60 exactly on the perpendicular vertex of @xmath38 .",
    "projecting the vector @xmath60 onto the lattice basis vectors can also be done by the multiplication @xmath63 where @xmath64 .",
    "the important element here is @xmath57 , which is the value that should be multiplied to the lattice basis vector @xmath65 to create the projected vector @xmath60 .",
    "this element determines the corresponding range for @xmath58 @xcite @xmath66 where @xmath67 and @xmath68 is the squared radius of the examined @xmath35-dimensional layer .",
    "the sphere decoder is applied recursively to search this @xmath35-dimensional layer .",
    "thereafter the next @xmath46 value in is generated and a new @xmath35-dimensional layer is searched .",
    "generalizing , the closest point in an @xmath32-dimensional layer is found by dividing the layer into @xmath31-dimensional layers , searching each of these separately , and then proceeding to the next @xmath32-dimensional layer .",
    "we will refer to this process of decreasing and increasing @xmath32 as _ moving down and up the layers , _ resp .",
    "we derive for @xmath69 @xmath70 where @xmath71 is the received vector @xmath28 projected onto an @xmath32-dimensional layer , and @xmath72 gives the coefficients of @xmath71 expressed as a linear combination of the lattice basis vectors .",
    "( in a zero - dimensional layer , which is a lattice point , @xmath73 and @xmath74 . )    assuming an @xmath32-dimensional sphere similar to fig",
    ".  [ fig:1 ] , the orthogonal displacement between the projected vector @xmath71 and the examined @xmath31-dimensional layer is @xmath75 based on a lower - triangular form and the interpretation that @xmath76 only affects the @xmath32th component of @xmath71 , for @xmath77 @xmath78 similarly , the bounds for every @xmath32-dimensional layer are @xmath79 where @xmath80 is the squared distance from the received vector @xmath28 to the projected vector @xmath81 and @xmath82 is the squared radius of the examined @xmath32-dimensional layer . hence , @xmath83 denotes the euclidean distance between the received vector @xmath28 and a potential closest point @xmath84 . finally , the range of @xmath85 for @xmath86 is @xcite @xmath87 where the _ projection value _",
    "@xmath88 is the value that should be multiplied with the lattice basis vector @xmath89 to create the projected vector @xmath71 .",
    "in this section , we claim that most of the arithmetic operations in standard sphere decoders are redundant and we propose methods to avoid them , thus increasing the decoding speed .",
    "the redundant operations are of two types : for @xmath29-based implementations , numerous quantities are calculated which are never used , and for @xmath0-based implementations , some quantities are calculated more than once . in both cases ,",
    "the source of the problem is the way the projection values are calculated .",
    "most of the numerical operations carried out in standard sphere decoders based on @xmath29 are related to the projection of the received vector @xmath28 , or its lower - dimensional counterpart , onto the lattice basis vectors as in . defining a matrix @xmath90 whose rows are @xmath91 , it follows from that all elements of this matrix are updated from the elements immediately below .",
    "however , the only values that are required in the sphere decoder algorithms are the diagonal elements @xmath88 , used in and .",
    "thus , the elements located above the diagonal of @xmath90 are not required to be calculated .",
    "they correspond to @xmath92 values that have already been calculated in previous stages of the algorithm , see .",
    "the sphere decoder proposed in @xcite always updates the first @xmath32 elements of @xmath93 simultaneously .",
    "for instance , if we are in an @xmath32-dimensional layer after computing @xmath88 , we update @xmath94 for all @xmath95 .",
    "these values may be used later to update @xmath96 for some @xmath97 after moving down the layers . but why should one project the entire vector @xmath71 to the lattice basis vectors , and calculate the @xmath94 for all @xmath95 , when they are not supposed to be used at that stage of the algorithm , and possibly not at all ?",
    "the answer to this question inspires an intelligent algorithm to manage the projection of @xmath28 and updating the @xmath98 values , based on following criteria : @xmath99 as explained in sec .",
    "[ sec:3.1 ] , we are just interested in elements located in the lower triangular form of @xmath90 .",
    "@xmath99 the last row of @xmath90 , @xmath100 , is just calculated once since there exists just a single @xmath1-dimensional layer .",
    "@xmath99 according to and , updating an element @xmath98 ( with @xmath101 ) requires knowledge of both @xmath102 and @xmath103 .",
    "@xmath99 unlike the row - wise updating method in @xcite , we propose updating @xmath90 column - wise , i.e. , updating @xmath104 for a suitable value of @xmath105 before calculating the desired value of @xmath88 .",
    "@xmath99 if we move to an @xmath32-dimensional layer , the first @xmath106 elements of @xmath93 and of other @xmath107 vectors above that row will be affected , since we are projecting the received vector @xmath28 to this new @xmath32-dimensional layer .",
    "however , the elements below @xmath93 will remain unaffected .",
    "@xmath99 our main target at each stage , when we are moving towards the lower - dimensional layers , is just to update the @xmath88 values .",
    "the other @xmath98 values for @xmath108 will be updated if and only if they are needed to calculate the @xmath88 values .",
    "@xmath99 the algorithm should track of the movement down and up the layers in order to avoid the recalculation of values that remain unchanged , see sec .",
    "[ sec:3.3 ] .    in sec .",
    "[ sec:5 ] , we demonstrate by simulations how the complexity of sphere decoder algorithms , for both lattices and finite constellations , is reduced due to the method outlined above for projecting of the received vector @xmath28 .      also in the @xmath0-based implementations , the time - consuming step is to calculate the projection values , which we denote with @xmath88 in @xmath29-based implementations , as discussed in sec .",
    "[ sec:3.1 ] , and @xmath109 in @xmath0-based implementations .    according to @xcite , which uses the same recursions as @xcite ,",
    "the projection value is calculated as @xmath110 , where @xmath111 and @xmath112 moving further down the layers in order to calculate the @xmath113 projection value for @xmath97 , one can notice that part of the sum in is already calculated and does not need to be recalculated if stored in memory .",
    "hence , we define @xmath114 for @xmath115 and @xmath116 for @xmath117 . as a result , we can calculate @xmath118 for @xmath119 and @xmath120 for @xmath117 , which requires fewer operations than .",
    "we collect the elements @xmath121 in a lower - triangular matrix @xmath122 , which is completely irrelevant to the matrix @xmath90 discussed in sec .",
    "[ sec:2 ] and [ sec:3.1 ] .",
    "however , the optimized projection method proposed in sec .  [ sec:3.1 ] to update the @xmath98 values , with some minor modifications , can be similarly applied herein to update the @xmath121 values .",
    "the changes are as follows : @xmath99 the last row of @xmath122 is the zero vector .",
    "@xmath99 according to , updating @xmath121 requires knowledge of both @xmath123 and @xmath124 values .",
    "@xmath99 if we move to an @xmath32-dimensional layer , all the elements of the @xmath32th row of @xmath122 , and of other rows above that row , will be affected , since we are investigating a new @xmath32-dimensional layer . however , the elements below that row will remain unaffected .",
    "@xmath99 our main target at each stage , when we are moving towards the lower - dimensional layers , is just to update the @xmath125 values .",
    "the other @xmath121 values for @xmath108 will be updated if and only if they are needed to calculate the @xmath125 values .",
    "@xmath99 similarly to sec .",
    "[ sec:3.1 ] , we should keep track of the movement up and down the layers .",
    "based on the preceding criteria , one can avoid starting from the @xmath1th layer and updating all @xmath126 elements located in the @xmath32th column of @xmath122 before calculating the objective @xmath125 value .",
    "while this significantly reduces the complexity of the algorithm , the memory write operations are increased .",
    "standalone representations of the old and new algorithms , @xmath0-based and @xmath29-based versions , for lattices and finite constellations , are given in fig .",
    "[ fig : algorithms ] , all based on the se enumeration strategy .",
    "the specifications are intended to be sufficiently detailed to allow a straightforward implementation , even without knowledge of the underlying theory .    as starting points , we use the @xmath0-based algorithm called `` algorithm ii '' in @xcite , labeled with 2 in fig .  [",
    "fig : algorithms ] , and the @xmath29-based algorithm `` decode '' in @xcite , here labeled with 3 .",
    "the loops have been restructured for consistency between the algorithms , but the calculations in fig .",
    "[ fig : algorithms ] are exactly the same as in @xcite .",
    "indeed , all algorithms for lattice decoding ( algorithms 1 , 3 , 5 , and 7 ) visit the same layers @xmath85 , in the same order , and return the same result @xmath127 , although they calculate different intermediate quantities .",
    "a similar note holds for decoding finite constellations ( algorithms 2 , 4 , 6 , and 8) .",
    "after the initialization , the algorithms are divided into three parts . in the first part",
    ", we move down the layers ( decrease @xmath32 ) , as long as the squared euclidean distance @xmath80 between the received vector @xmath28 and the projected vector @xmath81 is less than the squared euclidean distance @xmath44 between the received vector @xmath28 and the closest lattice point detected so far . in the second part , we move up in the hierarchy of layers ( increase @xmath32 ) as long as @xmath128 .",
    "moreover , before leaving each of these parts , we store the minimum and maximum level @xmath32 that has been visited .",
    "these values are used in the last part of the algorithm , which only belongs to the new algorithms .    the method to manage the recursive projection of @xmath93 or the calculation of @xmath121 is proposed in the last part .",
    "the value of @xmath129 for @xmath130 denotes the starting point for the recursions in and in order to update the objective @xmath88 or @xmath125 values .",
    "for instance , @xmath131 indicates that in order to update @xmath88 , we should start the projection from @xmath132th layer , where @xmath133 , and calculate @xmath98 for @xmath134 .    due to the well - documented performance gain that the se enumeration strategy brings to sphere decoders ,",
    "we apply herein the proposed refinement only to the se strategy .",
    "however , the same refinement can be applied to the original fp enumeration strategy .",
    "it is also applicable to most , or all , of the numerous sphere decoder variants , optimal as well as suboptimal , that have been developed in the last decade .",
    "herein , we evaluate the effectiveness of the proposed smart vector projection technique on the sphere decoder algorithms based on se enumeration strategy , for both lattices and finite constellations .",
    "all eight algorithms are implemented according to the pseudocode presented in fig .",
    "[ fig : algorithms ] .",
    "we base our performance comparison measure on counting the number of floating point operations ( flops ) and integer operations ( intops ) that each algorithm carries out to reach the closest lattice point .",
    "both types of operations include addition , subtraction , multiplication , division , and comparison , but not @xmath135 loop counters , whose role differs between programming languages .",
    "the @xmath136 operation is counted as a single floating point operation , and @xmath137 in sec .",
    "[ sec:5.2 ] is counted as one floating point operation for 2-pam and two for 4-pam .    to compare the complexity of two algorithms , typically an old and a new one , we generate @xmath138 random generator matrices @xmath139 , and for each @xmath140 we generate @xmath141 random",
    "received vectors @xmath142 .",
    "the same vectors are decoded using both algorithms and the number of operations @xmath143 is counted , which could be either flops or intops .",
    "the average gain with the new algorithm is reported as @xmath144      we generate the lattice generator matrices with random numbers , drawn from i.i.d .",
    "zero - mean , unit - variance gaussian distributions .",
    "the random input vectors are generated uniformly inside a voronoi region according to @xcite .",
    "our simulation results are based on averaging over @xmath145 different generator matrices .",
    "the number of input vectors @xmath141 depends on the dimension @xmath1 of the lattices .",
    "fewer input vectors are examined in high dimensions , to the extent that we ensure that the plotted curves are reasonably smooth .",
    "[ fig : flops ] compares the number of flops for the standard @xmath0- and @xmath29-based algorithms ( algorithms 1 and 3 in fig .",
    "[ fig : algorithms ] ) with the new algorithms proposed in this paper ( algorithms 5 and 7 ) .",
    "it can be seen that the @xmath0- and @xmath29-based implementations have about the same complexity , but both can be significantly improved .",
    "[ cc][][0.8]dimension [ ] [ ] [ 0.8]flops [ cc][][0.8 ] [ cc][][0.7]@xmath0-based new [ cc][][0.7]@xmath0-based old [ cc][][0.7]@xmath29-based new [ cc][][0.7]@xmath29-based old [ cc][][0.8]@xmath146 [ cc][][0.8]@xmath147 [ cc][][0.8]@xmath148 [ cc][][0.8]@xmath149 [ cc][][0.8]@xmath150 [ cc][][0.8]@xmath151 [ cc][][0.8]@xmath152 [ cc][][0.8]@xmath153 [ cc][][0.8]@xmath154 [ cc][][0.8]@xmath155 [ cc][][0.8]@xmath156 [ cc][][0.8]@xmath157 [ cc][][0.8]@xmath158 [ cc][][0.8]@xmath159   [ cc][][0.8]@xmath160   [ cc][][0.8]@xmath161   [ cc][][0.8]@xmath162   [ cc][][0.8]@xmath163   [ cc][][0.8]@xmath164   [ cc][][0.8]@xmath165     [ cc][][0.8]dimension [ ] [ ] [ 0.8]gain [ cc][][0.8 ] [ cc][][0.7]@xmath0-based flops without reduction [ cc][][0.7]@xmath0-based flops with lll reduction [ cc][][0.7]@xmath29-based flops without reduction [ cc][][0.7]@xmath29-based flops with lll reduction [ cc][][0.7]@xmath0&@xmath29-based intops without reduction [ cc][][0.7]@xmath0&@xmath29-based intops with lll reduction [ cc][][0.8]0 [ cc][][0.8]5 [ cc][][0.8]10 [ cc][][0.8]15 [ cc][][0.8]20 [ cc][][0.8]25 [ cc][][0.8]30 [ cc][][0.8]35 [ cc][][0.8]40 [ cc][][0.8]45 [ cc][][0.8]50 [ cc][][0.8]55 [ cc][][0.8]60 [ cc][][0.8]0.5   [ cc][][0.8]1   [ cc][][0.8]1.5   [ cc][][0.8]2   [ cc][][0.8]2.5   [ cc][][0.8]3   [ cc][][0.8]3.5   [ cc][][0.8]4   [ cc][][0.8]4.5     a preprocessing stage was applied to each lattice , replacing the generator matrix with another generator matrix for the same lattice via the so - called lenstra  lenstra  lovsz ( lll ) reduction @xcite .",
    "the operations needed for the reduction were not counted , since the preprocessing is only done once for each lattice , regardless of the number of received vectors .",
    "the gain with new algorithms increases linearly with dimension , while the reduction does not change the ratios substantially .",
    "the drawback is a somewhat larger number of intops , but the penalty converges to a mere 15@xmath166 increase at high dimensions . in simulations",
    "it was observed that most of the operations in the algorithms are flops , especially as the dimension increases .",
    "for instance , at dimension 60 with the old @xmath29-based algorithm , the flops are roughly 10 times more than the intops .",
    "hence , flops dominate the complexity of the algorithms and intops have a relatively small effect on the overall complexity .",
    "we also measured the running time for the algorithms . as expected , the gain increases roughly linearly with the dimension , similarly to the flops curves in fig .  [ fig:2 ] .",
    "however , the slope of the curve varies significantly between different processors and compilers , which is why we did not include running time in fig .",
    "[ fig:2 ] . at dimension 60",
    ", the gain ranged from 1.7 ( amd processor , visual c++ compiler ) to 2.7 ( intel processor , gcc compiler ) , for the @xmath29-based algorithm without reduction .",
    "we can thus safely conclude that the reduced number of operations translates into a substantial speed gain , but how much depends on the computer architecture",
    ".      the channel model in for an @xmath14-pam constellation is considered , where the average symbol energy of the constellation , @xmath167 , is calculated from the signal set @xmath168 and the snr is defined as @xmath169 , where @xmath170 is the average energy per bit and @xmath16 is the double - sided noise spectral density .",
    "[ cc][][0.8]dimension [ cc][][0.8]gain [ cc][][0.8 ] [ cc][][0.675]@xmath0-based snr=0db [ cc][][0.675]@xmath0-based snr=5db [ cc][][0.675]@xmath0-based snr=10db [ cc][][0.675]@xmath29-based snr=0db [ cc][][0.675]@xmath29-based snr=5db [ cc][][0.675]@xmath29-based snr=10db [ cc][][0.8]0 [ cc][][0.8]10 [ cc][][0.8]20 [ cc][][0.8]30 [ cc][][0.8]40 [ cc][][0.8]50 [ cc][][0.8]60 [ cc][][0.8]70 [ cc][][0.8]80 [ cc][][0.8]1   [ cc][][0.8]1.5   [ cc][][0.8]2   [ cc][][0.8]2.5   [ cc][][0.8]3   [ cc][][0.8]3.5   [ cc][][0.8]4   [ cc][][0.8]4.5   [ cc][][0.8]5     [ cc][][0.8]dimension [ cc][][0.8]gain [ cc][][0.8 ] [ cc][][0.675]@xmath0-based snr=0db [ cc][][0.675]@xmath0-based snr=5db [ cc][][0.675]@xmath0-based snr=10db [ cc][][0.675]@xmath29-based snr=0db [ cc][][0.675]@xmath29-based snr=5db [ cc][][0.675]@xmath29-based snr=10db [ cc][][0.8]0 [ cc][][0.8]5 [ cc][][0.8]10 [ cc][][0.8]15 [ cc][][0.8]20 [ cc][][0.8]25 [ cc][][0.8]30 [ cc][][0.8]35 [ cc][][0.8]40 [ cc][][0.8]45 [ cc][][0.8]50 [ cc][][0.8]1   [ cc][][0.8]1.5   [ cc][][0.8]2   [ cc][][0.8]2.5   [ cc][][0.8]3   [ cc][][0.8]3.5   [ cc][][0.8]4   [ cc][][0.8]4.5     the gain in flops is presented in figs .",
    "[ fig:5][fig:6 ] for 2-pam and 4-pam constellations , resp . , averaged over 100 random channel matrices @xmath0 with i.i.d .",
    "zero - mean , unit - variance elements .",
    "the same general conclusion as for lattices holds for finite constellations too : the new algorithms provide a substantial complexity gain , and the gain increases linearly with the dimension .",
    "however , in contrast to lattice decoding , the gains are here higher for @xmath0-based implementations .",
    "furthermore , the gains increase at low snr , and 4-pam offers slightly higher gains than 2-pam .",
    "u.  fincke and m.  pohst , `` improved methods for calculating vectors of short length in a lattice , including a complexity analysis , '' _ mathematics of computation _ , vol .",
    "44 , no . 170 , pp .",
    "463471 , apr .",
    "1985 .",
    "w.  k. ma , b.  n. vo , t.  n. davidson , and p.  c. ching , `` blind ml detection of orthogonal space - time block codes : efficient high - performance implementations , '' _ ieee trans . signal process .",
    "_ , vol .",
    "54 , no .  2 ,",
    "738751 , feb .",
    "2006 .    a.  burg , m.  borgmann , m.  wenk , m.  zellweger , w.  fichtner , and h.  blcskei , `` vlsi implementation of mimo detection using the sphere decoding algorithm , ''",
    "_ ieee j. solid - state circuits _ , vol .",
    "40 , no .  7 , pp .",
    "15661577 , july 2005 .",
    "b.  m. hochwald , c.  b. peel , and a.  l. swindlehurst , `` a vector - perturbation technique for near - capacity multiantenna multiuser communication  part ii : perturbation , '' _ ieee trans .",
    "_ , vol .",
    "53 , no .  3 , pp . 537544 ,"
  ],
  "abstract_text": [
    "<S> most of the calculations in standard sphere decoders are redundant , in the sense that they either calculate quantities that are never used or calculate some quantities more than once . a new method , which is applicable to lattices as well as finite constellations , is proposed to avoid these redundant calculations while still returning the same result . </S>",
    "<S> pseudocode is given to facilitate immediate implementation . </S>",
    "<S> simulations show that the speed gain with the proposed method increases linearly with the lattice dimension . at dimension 60 , </S>",
    "<S> the new algorithms avoid about 75 % of all floating - point operations . </S>"
  ]
}