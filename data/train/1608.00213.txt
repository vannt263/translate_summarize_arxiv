{
  "article_text": [
    "understanding collective behavior of large - scale multi - agent systems is an important question in the econophysics and the sociophysics literature @xcite . often in social and economic worlds , we find emergence and evolution of global characteristics that can not be explained in terms of fundamental properties @xcite .",
    "we find examples of particular social norms or technologies that become more popular than their competitors , which are not necessarily worse in terms of attributes .",
    "similarly , norms and opinions emerge as an equilibrium through reinforcement among the social and economic agents @xcite .",
    "leaders emerge in the political context through a complicated process of competition and interaction among millions of individuals @xcite . in this paper",
    ", we present a simple multi - agent game to study the emergence of one dominant attribute out of many potential competitors through complex and adaptive interactive processes ( @xcite;see also ref .",
    "@xcite ) .",
    "we focus on two properties of large scale interaction .",
    "one , agents can coordinate to specific choices from a number of potentially identical choices which may also be interpreted as emergence of cooperation @xcite and two , such coordination may take time to arrive at but once arrived , can be quite stable .",
    "therefore , we address the dynamic ( and potentially non - equilibrium ) process through which coordination takes place as well as the stability of the eventual equilibrium @xcite .",
    "we consider a prototype model to study this kind of situations .",
    "in particular , we consider a simple coordination game with @xmath0 agents and @xmath0 choices .",
    "individual agents aim to converge to a single universally chosen outcome ; i.e. , the game can be thought of as a _ majority game_.    in the language of game theory , this relates to the idea of equilibrium selection . in our game , there are @xmath0 possible pure strategy _ nash equilibria _ ,",
    "each of which is equally attractive to the agents .",
    "the question is how , in the absence of communication , do the agents converge to only one equilibrium ? naturally , we do not allow a central planner to dictate the solution as that would make the problem trivial as well as unrealistic .    in our model",
    ", agents play the game repeatedly and they always want to be in the majority .",
    "we first present several strategies based on _ nave learning _ that allow the agents to solve this coordination problem in a distributed manner @xcite .",
    "we next assume that the agents want to minimize their cost of experimentation , i.e. , to come up with some fixed strategy as soon as possible even if it results in not being in the absolute majority .",
    "this leads to a trade off between the degree of stability ( time to attain an approximate fixed rule of thumb ) and the efficiency of the solution i.e. , degree of coordination .",
    "we propose multiple heuristic strategies for coordination that solves the problem to different degrees .",
    "we propose a _ polya _",
    "scheme following the famous polya s urn model , which allows us to interpolate between multiple types of reinforcment learning processes @xcite .",
    "this paper is intimately related to the literature of minority game @xcite and the generalization of the minority game that goes by the name of kolkata paise restaurant ( kpr ) problem @xcite . in the minority game , there are @xmath0 agents and 2 options to choose from .",
    "the agents objective is to be in the minority .",
    "kpr problem extended this to a minority game with @xmath0 agents and @xmath0 options labeled restaurants . in spirit of ref .",
    "@xcite , multiple attempts were made to propose strategies that uses finite information sets with bounded rationality .",
    "interested readers can refer to ref .",
    "@xcite for a comprehensive review .",
    "the model we propose is the exact opposite of the multi - choice minority game .",
    "both are examples of large scale distributed coordination problems that study competing agents employing adaptive strategies with limited learning . @xcite .    in this paper , we show that agents converge to specific choices due to reinforcement learning .",
    "in particular , depending on the degree of reinforcement , agents may be get stuck to different choices creating clusters of different sizes .",
    "clustering behavior has been studied in the context of minority games @xcite . here",
    ", such behavior also implies that due to reinforcement , non - equilbrium configurations may also survive and hence , it is not necessarily a ` winner - take - all ' scenario .",
    "finally , we show that if the agents value not only coordination but also the time requirment to achieve absolute coordination , then there would be a trade - off in terms of efficiency and stability of the final solution .",
    "we consider @xmath0 agents and @xmath1 options .",
    "time is discrete and at every point of time , each agent makes a choice about which among the @xmath1 options to use .",
    "to fix the idea , one can imagine each option to represent one restaurant which an agent will visit in a time slice .",
    "therefore , each of the @xmath0 agents strategy is to choose a restaurant to visit in each time slice .",
    "any given restaurant can accommodate a maximum of @xmath0 agents in any particular time slice .",
    "the agents objective is to stay in majority , i.e. , the agents would like to move to a restaurant which has higher number of agents . in principle , @xmath0 may not be equal to @xmath1 . to impose symmetry on the problem , we assume @xmath2 , i.e. , the number of agents is equal to the number of restaurants .",
    "we also emphasize here that the game is necessarily non - cooperative and no communication is allowed among the agents .",
    "the information set for all agents is constrained to only their history and partial knowledge about past evolution of the restaurant occupancies . naturally , allowing full set of history across all restaurants to be available to the agents",
    "would immediately solve the problem as the agents can employ a strategy that in time slice 1 they choose randomly and in the next time slice , they move to the restaurant that attracted most number of agents in the first time slice . to have a non - trivial solution",
    ", we allow only partial set of history to be available to the agents .",
    "we elaborate on the specifics of the information sets for each type of strategies below .",
    "[ fig : payoff_matrix ] shows the payoff matrix for a general convergence game for two players .",
    "both players have strategies a and b i.e. , they may choose to visit either restaurant a or restaurant b. if both of them decide to visit the same restaurant ( either a or b ) , then the outcome for both would be better than if the chose different restaurants . a couple of points may be noted . this game is a simplified version of the famous _ battle of sexes _ game",
    "( see for example , @xcite for a textbook treatment ) .",
    "the battle of sexes game allows two players , in which agents aim to converge to a single restaurant although they differ in their preferences over the restaurants . in this paper",
    "we assume a multi - agent multi - choice scenario with @xmath3 agents , but assume that all agents have identical preference over the restaurants .",
    "the agents decide on their strategies based on attractiveness of a restaurant .",
    "we define attractiveness ( @xmath4 ) of a restaurant as the number of agents that have chosen that restaurant .",
    "thus attractiveness depends on the information set that the agent possess .",
    "naturally , at any given time slice , it is not possible to know how many other agents are choosing a given option .    for the sake of completeness ,",
    "we define _ nash equilibria _ for the coordination game .",
    "a nash equilibrium is defined as a strategy collection such that given every other agent s strategy each agent is weakly better off by not switching to a different strategy . for our purpose",
    "this description suffices . for a textbook description ,",
    "see @xcite . from fig .",
    "[ fig : payoff_matrix ] it can be verified that there are two pure - strategy nash equilibria , viz .",
    "both go to either restaurant @xmath4 or both go to @xmath5 . in a general @xmath0-agent game , there would be @xmath0 pure strategy nash equilbria .",
    "it may be noted that nash equilibrium is an equilibrium description and a static concept .",
    "it does not explain how one equilibrium would be chosen from many candidate equilibria in reality .",
    "so the essential question is how do agents coordinate to converge on one equilibrium out of @xmath0 possible choices , in absence of any information about what the other agents are thinking ?",
    "we specify a set of strategies below that solves this problem using finite sets of information and in certain cases , with no information about the other agents .",
    "in this section , we present a set of updating strategies that the agents may employ in the coordination game . these can be thought of as rule - of - thumb strategies . in particular",
    ", they do not exhaust all possible strategies , but provides a comprehensive set that is useful for solving the game .    in the following ,",
    "we define a strategy of an agent as a vector of probabilities that she assigns to the restaurants i.e. each of the elements of the vector would represent the probability with which she chooses one restaurant .",
    "formally , we denote the @xmath6-th agent s strategy at time slice @xmath7 as @xmath8 for @xmath9 . learning is introduced as updating the probability vector based on success of failure in the past .",
    "denotes the time of convergence with @xmath0 number of agents .",
    "the vertical bars shows standard deviation of the of simulation results . in the inset ,",
    "we plot @xmath10 as a function of the system size @xmath0 , which stabilizes around 8.5 . thus time required for convergence scales linearly with @xmath0 . ]",
    "-axis we plot the number of people in the restaurant with largest ( red ) , 2nd largest ( black ) and 3rd largest ( blue ) no . of agents . on the @xmath11-axis we plot time . ]",
    "we begin with a _ no learning _ strategy .",
    "this entails zero probability updating and represents a baseline case .",
    "this strategy has two parts .",
    "consider any generic time slice @xmath7 .",
    "first , the @xmath6-th agent ( @xmath12 ) assigns the following probability to the restaurants , @xmath13 naturally , this would lead to a randomly distributed allocation of agents across restaurants .",
    "in particular , @xcite shows that the occupancy fraction i.e. the number of restaurants occupied as a fraction of the total number @xmath0 , would be 63.5% .",
    "so the first part is far from sufficient to ensure coordination .",
    "the second part of the strategy allows the agent at time slice @xmath7 , to make a comparison between the choice made at time slice @xmath7 and the restaurant she is at time slice @xmath7 . because attractiveness depends on the number of agents in a restaurant , we denote the @xmath14-th restaurant s attractiveness at time slice @xmath7 by @xmath15 .",
    "therefore , an agent s strategy who is at restaurant @xmath16 is to go to restaurant @xmath14 if @xmath17 else , the agent stays at @xmath16 .",
    ".5 cm    [ [ information - required ] ] information required : + + + + + + + + + + + + + + + + + + + + +    the information set of the @xmath6-th agent who is at restaurant @xmath18 at the @xmath7-th time slice comprises @xmath19 and @xmath15 where @xmath14 is the outcome of random selection scheme ( eqn .",
    "[ eqn : no_learning ] ) for the @xmath6-th agent .",
    "note that it entails gathering information about the @xmath14-th restaurant that the @xmath6-th agent has not visited at time slice @xmath7 , implying that we are allowing for local information . in principle",
    ", one can imagine that the agents may have to pay a cost to gather that information .",
    "this is a point we will later take on in fuller details .    0.5 cm    [ [ results ] ] results : + + + + + + + +    we present simulation results in fig . [",
    "fig : rangeofmultipleofnforconvergence ] and fig .",
    "[ fig : evolution_of_maximum_number_of_agents_in_any_option ] . fig .",
    "[ fig : rangeofmultipleofnforconvergence ] shows the time required for absolute convergence @xmath20 i.e. the minimum number of time slices required for all agents to converge at one restaurant , as a function of the number of agents @xmath0 .",
    "it shows a linear trend with a coefficient about 8 on an average . in the inset",
    ", we show the ratio @xmath10 as a function of @xmath0 which fluctuates around 8 after an initial steep rise . in the main diagram",
    ", we also provide an estimation of the standard deviation across @xmath21 number of simulations .",
    "[ fig : evolution_of_maximum_number_of_agents_in_any_option ] shows the dominance of one restaurant over others ( we show the second and the third most populated ones ) over time in one simulation with @xmath22 . the second and",
    "the third most crowded restaurant initially starts attracting more agents before decaying completely in terms of the number of agents as the dominant one becomes absolutely dominant and attracts all agents .",
    "these results show that symmetry - breaking occurs due to stochastic choices .",
    "all restaurants start off by being equally popular .",
    "but at the end , only one of them emerges as the most popular choice and all other restaurants have no agents .      in this section",
    ", we introduce updating rules based on success and failures of the past choices .",
    "this is a direct extension of the previous strategy . at each time slice , the @xmath23th agent ( @xmath12 )",
    "makes a choice of restaurants using a probability vector @xmath24 .",
    "then she compares the attractivenesses of the chosen restaurant and the restaurant she is currently in , and moves to the one with higher attractiveness in the next time slice .",
    "finally , the @xmath6-th agent updates her probability vector based on the attractiveness .",
    "this last step of probability updating differentiates the strategy from the no learning strategy .",
    "we call this strategy _ ex - ante _ as the agents can decide whether or not to move to a chosen restaurant by gathering information about attractiveness of the current restaurant and the newly chosen one . later in sec .",
    "[ subsec : ex - post ] we study a case with ex - post updating that relaxes this assumption .",
    "we extend the strategy under consideration in multiple dimensions . in the first case ,",
    "agents reward for higher attractiveness and punishment for lower attractiveness .",
    "formally , higher attractiveness implies that the agent would assign higher weight in the probability vector and would reduce weight for restaurants with lower attractiveness .",
    "this strategy we label as _ symmetric _ in updating .    in the second case ,",
    "the agents only reward higher attractiveness .",
    "we label this strategy as _ asymmetric _ updating .",
    "further , we consider the cases where the agents are allowed to choose more than one restaurant to pick the best option .",
    "formally , the information set increases to @xmath16 choices per agent , where @xmath25 etc .",
    "naturally , setting @xmath26 makes the problem trivial .",
    "so we concentrate on cases with sufficiently small values of @xmath16 .",
    "below we describe the strategies in details .",
    "consider agent @xmath6 where @xmath12 , at any generic time slice @xmath7 .",
    "suppose she is at restaurant @xmath27 and given her probability vector @xmath8 , she probabilistically picks restaurant @xmath28 .",
    "if @xmath29 , she stays at restaurant @xmath27 .",
    "else , she moves to restaurant @xmath28 .",
    "simultaneously , the agent updates probability of restaurants @xmath28 and @xmath27 such that the one with higher attractiveness will gain in probability by a fraction ( @xmath30 ) while the other will decrease by fraction ( @xmath31 ) .",
    "naturally , the resulting sum is normalized to 1 . formally , if @xmath29 , @xmath32 if @xmath33 , @xmath34 and if @xmath35 , @xmath36 finally , probabilities are normalized : @xmath37    [ [ information - required-1 ] ] information required : + + + + + + + + + + + + + + + + + + + + +    the information set is identical to the no learning strategy for @xmath38 . for higher values of @xmath16 , we allow the agents to have more information about the occupancy of the restaurants in the previous time slice to make a comparison .",
    "[ [ results-1 ] ] results : + + + + + + + +    fig . [",
    "fig : exante_s_1 ] shows the simulation results for this strategy wih @xmath22 . on the @xmath11-axis , we plot the restaurants and on the @xmath39-axis , we plot the number of agents that goes to the restaurants @xmath40 for all restaurants i.e. for all @xmath12 .",
    "we show two snapshots .",
    "one at time slice @xmath41 5000 and the other at @xmath41 10000 .",
    "the three rows show the distribution of agents under three different information sets , @xmath42 .",
    "the first thing to notice is that the dynamics becomes considerably slow . even after 10000 time slices ( for @xmath22 )",
    ", attaining coordination is very difficult as the panels on the right in fig .",
    "[ fig : exante_s_1 ] show very clearly .",
    "however , we note that convergence is guaranteed . as an explanation ,",
    "consider a case with distribution of agents across all restaurants as ( 501,499,0, .... ,0 ) . given the current strategy ,",
    "only the first restaurant can attract agents and the second one can only lose agents however slow the process might be .",
    "the next important feature is that by increasing the information set even by limited amount ( going from @xmath38 to 2 and 3 ) drastically improves degree of coordination although the dynamics becomes slow after a certain point .",
    "for example , in the bottom row , we see that the distribution changes very slowly going from @xmath43 to @xmath44 .",
    "therefore , we see that for a long time there are clusters of agents in different restaurants before all collapse into one giant cluster i.e. absolute convergence takes place .",
    "such clustering behavior is transitory .",
    "consider agent @xmath6 at time @xmath7 in restaurant @xmath27 , probabilistically picking another restaurant @xmath28 .",
    "if @xmath29 , she stays at restaurant @xmath27 .",
    "else , she moves to restaurant @xmath28 .",
    "the asymmetric updating scheme differs from the symmetric scheme in the way she updates the probability vector @xmath8 .",
    "if there is a difference between attractiveness of the current restaurant and the probabilistically picked one , the agent assigns a higher weight to the more attractive option and reduce weight for every other restaurants .",
    "formally , if @xmath29 @xmath45 if @xmath33 , @xmath46 and if @xmath35 @xmath47 finally , probabilities are normalized : @xmath37    [ [ information - required-2 ] ] information required : + + + + + + + + + + + + + + + + + + + + +    this strategy requires exactly the same set of information as the _ symmetric _ updating strategy .    ) .",
    "we present two snapshots ( left column at @xmath48 and right column at @xmath49 ) of possible evolutions of the system with @xmath22 agents .",
    "the rows show the results for different values of the information sets , @xmath38 , @xmath50 and @xmath51 .",
    "as is evident , with increasing size of the information set , convergence occurs faster as was the case with the symmetric updating rule . ]",
    "[ [ results-2 ] ] results : + + + + + + + +    fig .",
    "[ fig : exante_s_2 ] presents the simulation results with the asymmetric updating strategy for @xmath52 .",
    "the results are comparable to the _ symmetric _ updating scheme .",
    "we see that the dynamics becomes slow .",
    "as we expand the information set from @xmath38 to 2 and 3 , convergence takes place much faster in the initial phase .",
    "but after a while , it becomes slow for all information sets .",
    "but again with sufficient number of iterations , absolute convergence takes place .",
    "= 0.1 and 0.9 and three information sets , @xmath53 and 3 .",
    "we show the evolution of the average of the maximum probability that the agents assign to any one restaurant at all time slices . with high reinforcement ( @xmath54 )",
    ", the maximum probability converges much faster than with low reinforcement ( @xmath55 ) . ]",
    "therefore , we see that for a long time there are clusters . but",
    "as with the _ symmetric _ updating , this behavior is transitory . by varying the parameter @xmath56 we studied the dynamics before convergence .",
    "[ fig : f_analysis_k_123 ] presents simulation results for two different values of @xmath56 with multiple information sets ( @xmath42 ) . in order to quantify the degree of stability before convergence ,",
    "we compute the average of the maximum probabilities that the agents assign to any restaurant . with smaller values of @xmath56 ( @xmath56 = 0.1 )",
    ", the average probability goes up very fast compared to larger values ( @xmath54 ) .",
    "also , with bigger information sets , the average of the maximum probabilities rise slower than with smaller information sets .",
    "this is consistent with the finding that coordination occurs much faster with bigger information sets , as that requires multiple switching to ensure convergence .",
    "naturally , with switching happening at a higher frequency leads to lesser reinforcements to specific restaurants .",
    "we introduce a new strategy using the poly s urn model ( @xcite ) that effectively captures reinforcement learning .",
    "let us define @xmath57 where @xmath58 is a tunable parameter taking discrete values within 0 and @xmath0 .",
    "we denote the number of times the @xmath6-th agent has visited restaurant @xmath14 before time slice @xmath7 , by @xmath59 .",
    "then the probability of choosing restaurant @xmath14 is given by @xmath60 intuitively , this is an extension of the basic _ no learning _ strategy ( which would require @xmath61 ) by embedding reinforcement learning through polya s urn model .",
    "[ [ information - required-3 ] ] information required : + + + + + + + + + + + + + + + + + + + + +    the required information set for the @xmath6-th agent is derived only from the full sequence of success of the agent at different restaurants .",
    "it is reasonable to assume that the agents keep track of their own visits .",
    "also note that at any time slice , the agent does not require any information from a restaurant that she is not visiting as was required with the earlier strategies .",
    "this is possible because there is no comparison involved .",
    "the probabilistic strategies are devised based on historical success .    )",
    "occupied as function of polya factor @xmath58 from 0 to 495 for @xmath0=500 , @xmath7=5000 .",
    "in the limit @xmath62 , there is infinite reinforcement .",
    "we can analytically show that the occupancy ratio in that case would be 63.2% . in the other limit @xmath63",
    ", it converges to the _ no learning _ strategy and hence majority problem is solved in linear time as we have shown in fig .",
    "[ fig : rangeofmultipleofnforconvergence ] . _ right panel _ : evolution of fraction of restaurants ( @xmath64 ) occupied as function of polya factor @xmath58 from 5 to 495 for @xmath0 = 500 , @xmath7 = 500 to 5000 .",
    "as is evident , for small @xmath58 the number of restaurants occupied is very small and in the other extreme , the occupancy ratio is close to 63.2% ( @xmath65 318/500 ) which corroborates earlier results . ]",
    "[ [ results-3 ] ] results : + + + + + + + +    fig . [ fig : occupancy_analysis_3d ] presents numerical results for different values of @xmath58 ( see eqn .",
    "[ eqn : phi_polya ] ) with @xmath0 = 500 and @xmath7 = 5000 . in the left panel",
    ", we show the number of restaurants occupied ( @xmath66 ) with at least one agent for different values of the factor @xmath58 and at different time slices @xmath7 .",
    "clearly when @xmath67 , the polya s scheme would converge to _ no learning _ case and absolute convergence occurs .",
    "this implies only one restaurant would be occupied .",
    "this can be seen from the figure by looking at the bars for different time slices by fixing @xmath58 = 0 . in the other extreme with @xmath68 ( for simulations",
    ", we can not set @xmath69 ) , we see that around 318 restaurants out of 500 have been occupied .",
    "this is consistent with the notion that setting the factor @xmath58 very close to @xmath0 leads to infinite reinforcement implying if an agent goes to one restaurant , she would stick there for the rest of the time slices .",
    "so effectively , the choices in the first time slice itself determines the distribution of agents across restaurants as that distribution will never change because of infinite reinforcement .",
    "it is easy to show that as the agents are starting with uniformly distributed probabilities ( @xmath70 ) , in the first time slice 63.2% of the restaurants would be occupied .",
    "we are skipping the derivation of this fraction .",
    "interested readers can refer to @xcite .",
    "one can easily verify that 318/500 is close to 63.5% and hence this validates our results .",
    "the right panel in the same figure shows the fraction of restaurants occupied i.e. @xmath71 . the results are perfectly consistent with the left panel .",
    "we also note that having @xmath69 in _ polya s scheme _",
    "( i.e. infinite reinforcement ) is identical to assuming @xmath72 in the _ asymmetric _ updating strategy .",
    "thus in the limit , these two strategies are exactly identical .",
    "this strategy allows us to interpolate between a wide spectrum of reinforcement by changing the factor @xmath58 .",
    "in particular , it allows us to cover the same range as are separately done by the _ symmetric _ and _ asymmetric _ updating strategies .      in the case of _ ex - ante knowledge _ in sec .",
    "[ subsec : ex - ante ] , we studied strategies where the agents can obtain information about the newly chosen restaurant s attractiveness and make a comparison between the chosen restaurant s and the current restaurant s attractiveness .",
    "however , this might be a costly activity to know the attractiveness of another restaurant before actually visiting it . in the present section",
    ", we study the same set of strategies where the agents can obtain information about attractiveness only after she moves to the chosen restaurant .",
    "an important distinction from the earlier cases is that the present strategy allows for _ regret_. after the agent moves to a new restaurant , she comes to know about its attractiveness and hence can not do comparison prior to switching . updating the probability vector happens the same way depending on relative attractiveness as was done in sec .",
    "[ subsec : ex - ante ] .",
    "consider agent @xmath6 where @xmath12 , at any generic time slice @xmath7 .",
    "suppose she is at restaurant @xmath27 and given her probability vector @xmath8 , she probabilistically picks restaurant @xmath28 .",
    "after knowing both @xmath73 and @xmath74 , probability vector @xmath75 is updated exactly the same way as in sec .",
    "[ subsubsec : ex - ante_sym ] . to avoid repetition",
    ", we are skipping the probability updating schemes .",
    "[ [ information - required-4 ] ] information required : + + + + + + + + + + + + + + + + + + + + +    the required information comes from the restaurants that the agent has visited . hence , there is no external information acquired .     and @xmath76 ) and asymmetric ( bottom panels , @xmath77 ) reinforcements .",
    "on the @xmath11-axis , we plot the identity of the restaurants .",
    "symmetric updating leads to higher crowding for the restaurants . ]",
    "[ [ results-4 ] ] results : + + + + + + + +    fig [ fig : expost_s_1_s_2 ] shows the simulation results in the top panels for @xmath78 and @xmath76 .",
    "we show results fr two time slices , at @xmath43 and @xmath79 . as in the earlier case",
    ", this strategy is also quite slow but eventually converges to a single restaurant in the limit . naturally , this is slower than the _ ex - ante knowledge _ case .",
    "similar to above , consider agent @xmath12 , at any generic time slice @xmath7 .",
    "suppose she is at restaurant @xmath27 and given her probability vector @xmath8 , she probabilistically picks restaurant @xmath28 .",
    "after knowing both @xmath73 and @xmath74 , probability vector @xmath75 is updated exactly the same way as in sec .",
    "[ subsubsec : ex - ante_asym ] .",
    "[ [ information - required-5 ] ] information required : + + + + + + + + + + + + + + + + + + + + +    required information comes solely form the restaurants she visited and hence no external information is acquired .",
    "[ [ results-5 ] ] results : + + + + + + + +    simulation results have been reported in the lower panels of fig .",
    "[ fig : expost_s_1_s_2 ] and fig .",
    "[ fig : fanaysis0 - 250 ] .",
    "we see that the result for distribution of agents across the restaurants are qualitatively similar to those in the case of _ symmetric _ updating except that coordination is poorer as there are many restaurants with small numbers of agents .",
    "= 0.1 and 0.9 for a system size @xmath22 .",
    "we show the evolution of the average of the maximum probability that the agents assign to any one restaurant at all time slices . with high reinforcement ( @xmath54 )",
    ", the maximum probability converges much faster than with low reinforcement ( @xmath55 ) , similar to the case of ex - ante updating strategies . ]",
    "we study the degree of stability of the transient clusters thus formed in fig .",
    "[ fig : fanaysis0 - 250 ] .",
    "for higher values of @xmath56 , the average over maximum probabilities rises quite fast compared to lower values of @xmath56 though eventually their behavior is similar .",
    "in the present section , we discuss the extent to which self - organization occurs in the multi - agent system that solves the coordination problem .      we have seen that some of the strategies especially those which require ex - ante information or knowledge can in principle be thought of as requiring some costs to be payed in order to acquire the information . also realistically",
    ", the agents might have a trade - off in terms of how quickly they can converge to a solution versus the efficiency of the solution .",
    "that is they may find it useful to be in majority , not necessarily absolute majority , at a lower time to reach the solution .",
    "a parallel theme is that initially all restaurants are identical . but with absolute convergence , only one of them emerge as the winner .",
    "this can be interpreted as how a specific social norm may emerge from multiple possibilities that are a priori equally likely .",
    "thus emergence of absolute coordination has two contributing factors that can be potentially costly .",
    "the first one is obviously the cost of lack of coordination .",
    "the second one is the cost of waiting to reach coordination .",
    "this can be most clearly seen in the clustering behavior where multiple choices survive as the agents achieve partial coordination reasonably fast .",
    "= 0.5 and 0.5 for a system size @xmath22 .",
    "top panels show evolution of coordinaiton across agents with ` ex - ante knowldge ' and bottom panels show the same with ` ex - post knowledge ' . ]",
    "we have already seen that clustering behavior can be transient but in almost all cases they are very slowly evolving .",
    "this implies that we observe clusters of agents in different restaurants for a very long time .",
    "= 1000 , @xmath80 = @xmath81 , averaged over @xmath21 parallel simluations ) .",
    "panel ( a ) : ex - ante knowledge with symmteric updating ( inset : power law fit in log - log plot ) , panel ( b ) : ex - ante knowledge with asymmteric updating , fitted with exponential distibution , panel ( c ) : ex - post knowledge with symmteric updating ( inset : log - log plot shows the discontinuity in the distribution ) , panel ( d ) : ex - post knowledge with asymmteric updating ( inset : fitted with a gamma distribution ) . ]    fig .",
    "[ fig : cluster ] shows four instances of probability density function of clusters .",
    "we tracked choices of @xmath22 agents over @xmath82 time slices .",
    "we assumed all four cases ( ex - ante , ex - post and symmetric - asymmetric ) with the previosly mentioned parameter values .",
    "the resulting probability density function has been averaged over @xmath21 number of simulations . both ex - ante and ex - post with symmetric updating rules ( panels ( a ) and ( c ) ) show strong clustring behavior whereas the other two cases show very moderately distributed clusters ( panel ( b ) : fit with exponential distribution with paramter value 4.8564 ; panel ( d ) : fit with gamma distribution with paramter values 2.7103 , 1.3834 ) .      as discussed before",
    ", the agents may have a cost to execute the strategies and hence if there are strategies that takes very long time to reach a state of absolute convergence , the agents may prefer less efficient solution i.e. smaller clusters , if that is achievable soon enough .",
    "= 500 . ]",
    "we study this trade - off in fig .",
    "[ fig : trade - off ] which plots the number of time slices required by the average over maximum probabilities to reach at least 0.8 versus the percentage of restaurants occupied .",
    "the variable in the @xmath39-axis represents the cost in terms of waiting time .",
    "the variable in the @xmath11-axis represents the cost in terms of inefficiency of the solution ( smaller percentage occupancy would be more efficient ) .",
    "we plot the trade - off by simulating a system of @xmath0 = 500 agents with the _ polya _ updating scheme ( @xmath58 = 50 , 75 , 100 , @xmath83 , 475 , 495 ) .",
    "the values on the @xmath11-axis shows the occupancy at the time slice when @xmath84 reaches 0.8 .",
    "the trade - off is clearly seen in terms of cost minimization .",
    "a lower waiting cost leads to higher occupancy and hence to inefficiency and vice versa .",
    "this is a very useful feature of the model to understand the trade - off between the waiting cost to arrive at an allocation and the accuracy of the allocation .",
    "in this paper , we study a model of distributed coordination in the context of a multi - agent , multi - choice system .",
    "we consider a game with multiple nash equilibrium all of which are equally likely .",
    "the basic problem is to find which equilibrium will materialize if the agent engage in repeated interaction and how quickly can they converge to the equilibrium .",
    "essentially , we solve the problem of equilibrium selection through distributed coordination algorithms .    we propose a number of strategies based on different types of _ nave _ learning . in particular , reinforcement learning via _ polya s urn model _ provides a very useful benchmark .",
    "we show that the system self - organizes with very slow dynamics and transient clusters . finally , we characterize a trade - off between waiting cost to attain an allocation and the accuracy of the allocation . with lower waiting costs ( stability is attained sooner ) , efficiency of the solution is low and the opposite is also true .",
    "a.  chakraborti , d.  challet , a.  chatterjee , m.  marsili , y .- c .",
    "zhang , and b.  k. chakrabarti , _ statistical mechanics of competitive resource allocation using agent - based models _ , phys .",
    ", * 552 * , 125 ( 2015 ) ."
  ],
  "abstract_text": [
    "<S> in this paper we consider a distributed coordination game played by a large number of agents with finite information sets , which characterizes emergence of a single dominant attribute out of a large number of competitors . </S>",
    "<S> formally , @xmath0 agents play a coordination game repeatedly which has exactly @xmath0 nash equilibria and all of the equlibria are equally preferred by the agents . the problem is to select one equilibrium out of @xmath0 possible equilibria in the least number of attempts . </S>",
    "<S> we propose a number of heuristic rules based on reinforcement learning to solve the coordination problem . </S>",
    "<S> we see that the agents self - organize into clusters with varying intensities depending on the heuristic rule applied although all clusters but one are transitory in most cases . finally , we characterize a trade - off in terms of the time requirement to achieve a degree of stability in strategies and the efficiency of such a solution .    </S>",
    "<S> * keywords :* majority games , adaptation , reinforcement learning , distributed coordination , self organization .    </S>",
    "<S> .5 cm    * jel code : * c72 , c63 , d61 </S>"
  ]
}