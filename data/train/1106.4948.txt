{
  "article_text": [
    "boolean networks ( bn ) have been suggested as simplified models of various biological systems , in particular for modeling gene - regulatory networks  @xcite .",
    "simplifying the state of genes by adopting a two state variable representation , , enables one to model the complex interactions between genes as arbitrary boolean functions of randomly selected variables .",
    "this model gives rise to a rich and complex behavior that has been successfully employed to gain insight into the dynamics and steady states of various gene - regulatory systems  @xcite .",
    "bn models comprise @xmath0 sites ( genes ) , each of which is represented by a binary variable .",
    "the state of each variable is determined by the states of @xmath1 randomly selected sites via a @xmath1-input boolean function .",
    "the specific @xmath1 input variables selected for each site constitutes the network topology and the selected boolean functions determine the corresponding interaction leading to the variables state . in the original formulation",
    "@xcite , both topology and boolean functions were selected uniformly from the ensemble of networks with in - degree @xmath1 per variable and @xmath2 possible boolean functions , respectively .",
    "both are considered fixed ( _ quenched _ variables ) . moreover ,",
    "the original model was deterministic and the analysis therefore focused on its periodic - orbit attractors , steady - state and their basins of attraction .",
    "while this family of networks was originally introduced to model the gene - regulatory network  @xcite , and is commonly known as random boolean networks ( rbn ) or kauffman nets , similar topologies have been employed to study network properties in other application domains , ranging from social  @xcite to genetic  @xcite and neural  @xcite networks . although the topology used is common to all these models , based on a discrete state - space and random @xmath1-variable boolean interactions , the nature of the interaction may be different for each of the models .",
    "we will refer to the general class of @xmath0-variable binary system with connectivity degree @xmath1 as the n - k model  @xcite .",
    "this abstraction of complex gene - regulatory system lends itself to analysis in terms of both their dynamics and equilibrium properties  @xcite .",
    "equilibrium analysis relies mainly on the cavity method , while the dynamics has been mostly investigated using the _ annealed approximation _",
    "@xcite due to its simplicity and success in providing accurate results in many of the models studied , especially for very large systems .",
    "the underlying approximation in this approach is that both thermal and quenched variables ( primarily the network topology ) are considered to be on equal footing and are sampled at each time step .",
    "this helps suppress emerging correlations of specific sites at different times , simplifies the analysis and gives rise to an effective methodology which works in most cases .",
    "the annealed approximation was particularly successful in large - scale systems ( @xmath3 ) ; it allows one to predict the evolution of network activity and hamming distance order parameters .",
    "the former refers to the magnetization or the proportion of states and the latter to the difference between the states of the network starting from different initial conditions .",
    "it was shown  @xcite that the annealed approximation provides accurate magnetization and hamming distance order parameter predictions for rbn ( i.e. , with uniformly sampled boolean functions ) ; however , the conditions for its applicability and validity for general n - k systems has remained unclear  @xcite . moreover , in some cases , especially in systems with memory , discrepancies have been found between results obtained via the annealed approximation and simulation results  @xcite , casting doubts on the validity of the approach for such models .",
    "the aim of the current paper is to develop further a framework for exact analysis of n - k models based on the generating functional analysis ( gfa ) framework  @xcite , which has been employed successfully in the study of various ising spin models  @xcite . the newly developed framework is then employed to determine the conditions under which the annealed approximation is valid , to investigate the possible phases of bn depending on the noise level and to demonstrate its efficacy for analyzing systems with memory , where the annealed approximation is known to break down  @xcite .",
    "we note that an alternative to the gfa method ( called the _ dynamical cavity _ method ) was recently introduced  @xcite , which we believe can be also used for the range of models studied here .",
    "section  [ section : model ] introduces the bn model while section  [ section : gfa ] describes the methodology used and its application to the current model . in section  [ section : results ] we employ the dynamical equations obtained for the order parameters to investigate the conditions under which the annealed approximation provides exact results ; a similar set of equations is then used to identify possible phases of the system and to analyze the dynamics of system with memory .",
    "finally , in section  [ section : summary ] , we summarize the results obtained and point to future research directions .",
    "some of the detailed derivations appear in dedicated appendices .",
    "the model we consider here is a recurrent boolean network which consists of @xmath0 binary variables @xmath4 interacting via boolean functions @xmath5 of exactly @xmath1 inputs . because of thermal noise , which can flip the output of a function with probability @xmath6  @xcite ,",
    "a site @xmath7 in the network is operating according to the stochastic rule @xmath8 where @xmath9 is an independent random variable from the distribution @xmath10 .",
    "the function - output @xmath11 is completely random when @xmath12 and completely deterministic when @xmath13 .",
    "averaging out the thermal noise @xmath14 in the system governed by ( [ def : algorithm ] ) gives rise to the microscopic law @xmath15 where the inverse temperature @xmath16 relates to the noise parameter @xmath6 via @xmath17 .",
    "all sites in the network are updated in parallel and given the state of the network @xmath18 at time @xmath19 , the function - outputs @xmath20 at time @xmath21 for the different sites are independent of each other .",
    "this markovian property allows us to write the probability of the microscopic path @xmath22 as a product of ( [ eq : micro ] ) over all sites and time steps .",
    "furthermore , we consider two copies of the same topology but with different initial conditions , shown in figure [ fig:1 ] , comparing the two will enable us to study the effects of initial - state perturbations . following similar arguments to those of the single network case ,",
    "the joint probability of microscopic states in the two systems are given by @xmath23\\!=\\!{\\mbox{$p$}}({\\mbox{\\boldmath$s$}}(0),{\\hat{\\mbox{\\boldmath$s$}}}(0 ) ) \\prod_{t=0}^{t_{max}-1 } { \\mbox{$p$}}({\\mbox{\\boldmath$s$}}(t\\!+\\!1)\\vert{\\mbox{\\boldmath$s$}}(t))p({\\hat{\\mbox{\\boldmath$s$}}}(t\\!+\\!1)\\vert{\\hat{\\mbox{\\boldmath$s$}}}(t)),\\label{eq : pathprob}\\end{aligned}\\ ] ] where @xmath24 .",
    "the sources of quenched disorder in our model are random boolean functions and random connections .",
    "boolean functions @xmath25 are sampled randomly and independently from the distribution @xmath26 where @xmath27 , @xmath28 and @xmath29 is the set of all @xmath1-ary boolean functions .",
    "the connectivity disorder arises from the random sampling of connections generated by selecting the @xmath30-th function and sampling exactly @xmath1 indices , @xmath31 , uniformly from the set of all possible indices @xmath32}=\\{1,\\ldots , n\\}$ ] .",
    "this gives rise to the probabilities @xmath33 } } a_{{\\textbf{i}}^\\prime}^{i}\\right]\\!\\!\\prod_{{\\textbf{i}}\\subseteq{[n]}}\\left\\{\\frac{1}{n^k}\\delta_{a_{{\\textbf{i}}}^{i};1}+(1\\!-\\!\\frac{1}{n^k})\\delta_{a_{{\\textbf{i}}}^{i};0}\\right\\}\\right\\},\\label{def : connect - disorder}\\ ] ] where @xmath34 is a normalization constant .",
    "the connectivity tensors @xmath35 define the random topology via entering into the definition of probability  ( [ eq : micro ] ) with @xmath36 being replaced by @xmath37 .",
    "other connectivity and function profiles can be easily accommodated within our framework by incorporating additional constraints into the definitions ( [ def : gate - disorder ] ) and ( [ def : connect - disorder ] ) via the appropriate delta functions .    ]",
    "to analyze the typical properties of the system governed by ( [ def : algorithm ] ) we will use the generating functional method of de dominicis  @xcite .",
    "following the prescription of  @xcite we first define the generating function @xmath38&=&\\left\\langle{\\mathrm{e}}^{-{\\mathrm{i}}\\sum_{t , i}\\{\\psi_i(t ) s_{i}(t)+{\\hat\\psi}_i(t ) \\hat{s}_{i}(t)\\}}\\right\\rangle~,\\label{eq : gf}\\end{aligned}\\ ] ] where @xmath39 denotes the average over all paths occurring in two systems governed by the joint probability ( [ eq : pathprob ] ) .",
    "the generating function ( [ eq : gf ] ) allows us to compute moments of ( [ eq : pathprob ] ) by taking partial derivatives with respect to the generating fields @xmath40 , e.g. @xmath41 $ ] .",
    "secondly , we assume that the system becomes self - averaging , i.e. all thermodynamic macroscopic properties are self - averaging , for @xmath3  @xcite and compute @xmath42}$ ] , where @xmath43 is the disorder average ; this gives rise to the macroscopic observables @xmath44}}{\\partial_{\\psi_i(t)}}\\label{def : observ}\\\\ & & c(t , s)\\!=\\!\\frac{1}{n}\\!\\sum_{i=1}^n\\overline{\\langle s_i(t)s_i(s)\\rangle}=\\lim_{{\\mbox{\\boldmath$\\psi$}},{\\hat{\\mbox{\\boldmath$\\psi$}}}\\rightarrow{\\mbox{\\boldmath$0$}}}\\!\\frac{\\!-\\!1}{n}\\!\\sum_{i=1}^n\\!\\frac{\\partial^2\\overline{\\gamma[{\\mbox{\\boldmath$\\psi$}};{\\hat{\\mbox{\\boldmath$\\psi$}}}]}}{\\partial_{\\psi_i(t)}\\partial_{\\psi_i(s)}}\\nonumber\\\\ & & c_{12}(t)\\!=\\!\\frac{1}{n}\\!\\sum_{i=1}^n\\overline{\\langle s_i(t)\\hat{s}_i(t)\\rangle}=\\lim_{{\\mbox{\\boldmath$\\psi$}},{\\hat{\\mbox{\\boldmath$\\psi$}}}\\rightarrow{\\mbox{\\boldmath$0$}}}\\!\\frac{\\!-\\!1}{n}\\!\\sum_{i=1}^n\\frac{\\partial^2\\overline{\\gamma[{\\mbox{\\boldmath$\\psi$}};{\\hat{\\mbox{\\boldmath$\\psi$}}}]}}{\\partial_{\\psi_i(t)}\\partial_{\\hat{\\psi}_i(t)}}\\nonumber\\end{aligned}\\ ] ] where @xmath45 is the network activity ( or magnetization  @xcite ) , @xmath46 is the correlation between two states of the same network and @xmath47 is the overlap between two copies of the same network which is related to the hamming distance @xmath48 via @xmath49 .    averaging the generating function ( [ eq : gf ] ) over the disorder and @xmath50 to label two copies of the same system with different noise levels or initial conditions . ] ( see appendix [ section : disorderaverage ] for details ) leads us to the saddle - point integral problem @xmath51}\\label{eq : gf - recurr - sp}\\end{aligned}\\ ] ] where @xmath52 is the macroscopic saddle - point surface @xmath53 \\nonumber\\end{aligned}\\ ] ] using the notation @xmath54 , @xmath55 , @xmath56 ; @xmath57 is an effective single - site measure @xmath58 = { \\mbox{$p$}}(s^1(0),s^2(0))\\;{\\mathrm{e}}^{-{\\mathrm{i}}\\hat{\\omega}(\\{\\mathbf{\\hat{h}}(t)\\},\\omega)+{\\mathrm{i}}\\omega-{\\mathrm{i}}\\hat{p}(\\{{\\mbox{\\boldmath$s$}}(t)\\})}\\nonumber\\\\ & & \\hspace{57mm}\\times\\prod_{t=0}^{t_{max}\\!-\\!1}\\ !",
    "\\prod_{\\gamma = 1}^{2}\\left\\{\\;{\\mathrm{e}}^{{\\mathrm{i}}\\hat{h}^{\\gamma}(t ) h^{\\gamma}(t)}\\frac{{\\mathrm{e}}^{\\beta s^\\gamma(t\\!+\\!1)h_{i}^{\\gamma}(t)}}{2\\cosh[\\beta   h_{i}^{\\gamma}(t)]}\\right\\}\\label{def : m}\\end{aligned}\\ ] ] with @xmath59 .",
    "the generating fields @xmath60 have been removed from the above as they are not needed in the remainder of this calculation . in the limit of @xmath3 the integral ( [ eq : gf - recurr - sp ] )",
    "is dominated by the extremum points of the functional @xmath52 .",
    "the functional variation of @xmath52 with respect to the order parameters @xmath61 leads us to the saddle - point equations @xmath62\\right\\rangle_{m}\\label{eq : sp1-recurr}\\\\ & & \\hat{p}(\\{{\\mbox{\\boldmath$s$}}(t)\\})={\\mathrm{i}}\\!\\sum_{i=1}^k\\sum_{\\{\\mathbf{s}_j(t)\\}}\\delta[\\{{\\mbox{\\boldmath$s$}}(t)\\};\\{{\\mbox{\\boldmath$s$}}_i(t)\\}]\\left\\{\\prod_{j\\neq i}^k p(\\{{\\mbox{\\boldmath$s$}}_j(t)\\})\\right\\}\\label{eq : sp2-recurr}\\\\ & & \\hspace{17mm}\\times\\int\\{\\mathrm d\\mathbf{\\hat{h}}(t)\\}\\;\\mathrm d\\omega\\;\\omega(\\{\\mathbf{\\hat{h}}(t)\\},\\omega ) \\;\\overline{{\\mathrm{e}}^{-{\\mathrm{i}}\\sum_{t=0}^{t_{max}\\!-\\!1}\\ !",
    "\\sum_{\\gamma = 1}^{2 }   \\hat{h}^{\\gamma } ( t)\\;\\alpha(s_{1}^{\\gamma}(t),\\ldots , s_{k}^{\\gamma}(t))-{\\mathrm{i}}\\omega}}^{\\;\\alpha }     \\nonumber\\\\ & & \\omega(\\{\\mathbf{\\hat{h}}(t)\\},\\omega)=\\left\\langle\\left[\\prod_{t=0}^{t_{max}\\!-\\!1}\\delta(\\mathbf{\\hat{h}}(t)-\\mathbf{\\hat{h}}^\\prime(t))\\right]\\delta(\\omega-\\omega^\\prime)\\right\\rangle_{m}\\label{eq : sp3-recurr}\\\\ & & \\hat{\\omega}(\\{\\mathbf{\\hat{h}}(t)\\},\\omega)\\!=\\!{\\mathrm{i}}\\!\\!\\!\\!\\sum_{\\{\\mathbf{s}_j(t)\\}}\\prod_{j=1}^k p(\\{{\\mbox{\\boldmath$s$}}_j(t)\\})\\;\\overline{{\\mathrm{e}}^{-{\\mathrm{i}}\\sum_{t=0}^{t_{max}\\!-\\!1}\\ ! \\sum_{\\gamma = 1}^{2 }   \\hat{h}^{\\gamma } ( t)\\;\\alpha(s_{1}^{\\gamma}(t),\\ldots , s_{k}^{\\gamma}(t))-{\\mathrm{i}}\\omega}}^{\\;\\alpha},\\label{eq : sp4-recurr}\\end{aligned}\\ ] ] where @xmath63 is average generated from the single - site measure  ( [ def : m ] ) . in appendix",
    "[ section : solofsp ] we show that the conjugate order parameter @xmath64 is a constant .",
    "using this result the saddle - point equation  ( [ eq : sp4-recurr ] ) in the single - site measure  ( [ def : m ] ) leads us to the main equation of this paper @xmath65\\nonumber\\\\ & & \\times \\overline{\\prod_{t=0}^{t_{max}-1}\\!\\!\\!\\!{\\mbox{$p$}}_{\\alpha}(s(t\\!+\\!1)\\vert s_{1}(t), .. ,s_{k}(t))\\;{\\mbox{$p$}}_{\\alpha}(\\hat{s}(t\\!+\\!1)\\vert \\hat{s}_{1}(t), .. ,\\hat{s}_{k}(t))}^{\\;\\alpha}.\\label{eq : m}\\end{aligned}\\ ] ] the physical meaning of  ( [ eq : m ] ) is revealed by @xmath66\\,\\delta[{\\hat{\\mbox{\\boldmath$s$}}};{\\hat{\\mbox{\\boldmath$s$}}}_i]\\rangle}$ ] , i.e. the disorder - averaged joint probability of single - spin trajectories @xmath67 and @xmath68 in the two systems . equation  ( [ eq : m ] ) can be used to compute the macroscopic observables ( [ def : observ ] ) . to demonstrate how this can be done we derive explicitly the expression for the two time correlation @xmath69 @xmath70s(t^\\prime\\!+\\!1)\\;s(t^{\\prime\\prime}\\!+\\!1)\\nonumber\\\\ & & \\times \\overline{\\prod_{t=0}^{t_{max}-1}{\\mbox{$p$}}_{\\alpha}(s(t\\!+\\!1)\\vert s_{1}(t), .. ,s_{k}(t))\\;{\\mbox{$p$}}_{\\alpha}(\\hat{s}(t\\!+\\!1)\\vert \\hat{s}_{1}(t), .. ,\\hat{s}_{k}(t))}^{\\;\\alpha}\\nonumber\\\\ & & = \\!\\!\\sum_{\\{s_{j}(t^\\prime),\\;{s}_{j}(t^{\\prime\\prime}\\}}\\!\\prod_{j=1}^{k}\\!\\left[{\\mbox{$p$}}(s_{j}(t^\\prime),{s}_{j}(t^{\\prime\\prime})\\right]\\nonumber\\\\ & & \\times \\sum_{s(t^\\prime\\!+\\!1),s(t^{\\prime\\prime}\\!+\\!1)}\\overline{{\\mbox{$p$}}_{\\alpha}(s(t^\\prime\\!+\\!1)\\vert s_{1}(t^\\prime), .. ,s_{k}(t^\\prime))\\;{\\mbox{$p$}}_{\\alpha}({s}(t^{\\prime\\prime}\\!+\\!1)\\vert { s}_{1}(t^{\\prime\\prime}), .. ,{s}_{k}(t^{\\prime\\prime}))}^{\\;\\alpha}\\nonumber\\\\ & & \\times \\;s(t^\\prime\\!+\\!1)\\;s(t^{\\prime\\prime}\\!+\\!1)=c(t^\\prime\\!+\\!1,t^{\\prime\\prime}\\!+\\!1)\\nonumber~;\\end{aligned}\\ ] ] note that many of the variables in the summation over @xmath71 are redundant , they have been introduced for methodological reasons but vanish during the derivation . carrying out a similar derivation for the other order parameters one obtains a closed set of iterative equations : @xmath72 \\overline{\\alpha(s)}^{\\;\\alpha}\\label{eq : m}\\\\ & & c(t\\!+\\!1,s\\!+\\!1)\\!=\\!f_\\alpha(m(t),m(s),c(t , s))\\nonumber\\\\ & & \\!=\\!\\tanh^2(\\beta)\\sum_{s,\\hat{s}}\\!\\prod_{j=1}^{k}\\!\\left[\\!\\frac{1\\!+\\ !",
    "s_j m(t)\\!+\\!\\hat{s}_j m(s ) \\!+\\ !",
    "\\!s_j\\hat   s_j c(t , s)}{4}\\right ] \\overline { \\alpha(s)\\;\\alpha(\\hat{s})}^{\\;\\alpha}\\label{eq : corr}\\\\&&c_{12}(t\\!+\\!1)=f_\\alpha(m(t),\\hat m(t),c_{12}(t)),\\label{eq : overlap } \\ ] ] where @xmath73 and the equation for @xmath74 is the same as ( [ eq : m ] ) .",
    "in this section , we first apply the equations  ( [ eq : m])-([eq : overlap ] ) to the recurrent boolean networks with thermal noise .",
    "we recover results of the annealed approximation for the order parameters @xmath75 and @xmath76 .",
    "however , the two - time correlation function @xmath69 , computed here for the first time , allows us to study properties of the stationary states .",
    "furthermore , the exactness of our method allows us to derive a rigorous upper bound on the noise level above which the system is always ergodic .",
    "in addition , we use the equation ( [ eq : m ] ) to study models with strong memory effects where the annealed approximation method is no longer valid .",
    "it is clear from the results ( [ eq : m])-([eq : overlap ] ) and ( [ eq : m ] ) that the evolution of all many - time single - site correlation functions is driven by the magnetization @xmath45 .",
    "a similar scenario was observed in recurrent asymmetric neural networks  @xcite which have a similar topology but uses different update functions than model ( [ def : algorithm ] ) .",
    "the asymmetric neural network model can be seen as a special case of the n - k model when only _ linear threshold boolean functions _ are used and the thermal noise enters into the system via randomness in the thresholds .",
    "furthermore , for the stationary solution @xmath77 ( @xmath78 ) the solution of @xmath79 [ here @xmath80 is the edwards - anderson order parameter , used in disordered systems  @xcite to detect the spin glass ( sg ) phase where @xmath81 and @xmath82 and @xmath83 are identical .",
    "this was also observed in asymmetric neural networks  @xcite and because of the equality @xmath84 there is only one average distance @xmath85 on the attractor  @xcite and all points in the basin of attraction uniformly cover the stationary states ( see figure [ fig:2 ] ) .    ]",
    "the annealed approximation method , where connectivities and boolean functions change at each time step of the process ( [ def : algorithm ] ) , provides _",
    "identical results _ for @xmath75 and @xmath76 to those of ( [ eq : m ] ) and ( [ eq : overlap ] )  @xcite . however , within annealed approximation the two - time correlations take the form @xmath86 , where @xmath87 , which is the solution of ( [ eq : corr ] ) _ only when networks are constructed from a single boolean function . _",
    "this result follows from the equality @xmath88 , which is clear from the equations ( [ eq : m ] ) and ( [ eq : c12example ] ) , and the fact that for a single function , in the absence of an average over @xmath89 , the joint probability of two spins in the equation ( [ eq : corr ] ) factorizes when @xmath86 .",
    "the classical annealed approximation result  @xcite for rbn , which is exact in this case  @xcite , can be easily recovered from the equations ( [ eq : m])-([eq : overlap ] ) using the property @xmath90 for all @xmath91 and @xmath92 , for all @xmath93 where the @xmath89 average is taken over all boolean functions with equal weight . in the noisy case ( @xmath94 ) , the magnetization variable @xmath95 for all @xmath96 and @xmath97 , corresponding to the stationary solution of ( [ eq : corr ] ) , has one stable solution @xmath98 for all finite @xmath99 and @xmath1 . for @xmath100 ( no noise ) , there is a transition from one stable solution @xmath101 for @xmath102 to two solutions @xmath103 ( unstable ) and @xmath98 ( stable ) for @xmath104  @xcite .",
    "an interesting question related to the ergodicity and phase transitions is whether the system  ( [ def : algorithm ] ) can retain information about its initial state in the presence of noise .",
    "this question has received a considerable attention in the works on cellular automata  @xcite and in a closely related field of fault - tolerant computation  @xcite .    the unordered paramagnetic ( pm ) phase @xmath81 , where no information is retained , is a fixed point of  ( [ eq : m ] ) only when @xmath105 .    [ prop:1 ]",
    "the point @xmath81 is a stable and unique solution of ( [ eq : m ] ) when @xmath106 for @xmath1 odd and even respectively .    to prove this we first find a boolean function @xmath107 such that @xmath108 when @xmath109 and @xmath110 when @xmath111 $ ] .",
    "it turns out that any function from the set @xmath112\\!+\\!\\delta[0;\\sum_{j=1}^k s_j]\\gamma(s)$ ] , where @xmath113 and such that @xmath114\\gamma(s)\\!=\\!0$]\\!=\\!0 $ ] throughout this paper . ]",
    "satisfies these properties . to show this we define the average @xmath115(\\cdots)$ ] and use the shorthand notations @xmath116,{\\mathbf{1}}_-[s],{\\mathbf{1}}_0[s]\\right\\}$ ] for the indicator functions @xmath117,{\\mathbf{1}}[\\sum_{j=1}^k",
    "s_j\\!<\\!0],{\\mathbf{1}}[\\sum_{j=1}^k s_j\\!=\\!0]\\}$ ] .",
    "then we compute the difference @xmath118 as follows @xmath119-\\overline{\\alpha(s)}^{\\;\\alpha}\\right\\rangle_{s\\vert m}\\label{eq : difference}\\\\ & = & \\frac{1}{4}\\left\\langle { \\mathbf{1}}_+\\left[s\\right]-{\\mathbf{1}}_-\\left[s\\right ] -\\left({\\mathbf{1}}_+\\left[s\\right]+{\\mathbf{1}}_-\\left[s\\right]+{\\mathbf{1}}_0\\left[s\\right]\\right)\\overline{\\alpha(s)}^{\\;\\alpha}\\right\\rangle_{s\\vert m}\\nonumber\\\\ & = & \\frac{1}{2}\\left\\langle { \\mathbf{1}}_+\\left[s\\right]\\frac{1}{2}(1\\!-\\!\\overline{\\alpha(s)}^{\\;\\alpha})-{\\mathbf{1}}_-\\left [ s\\right]\\frac{1}{2}(1\\!+\\!\\overline{\\alpha(s)}^{\\;\\alpha})-\\frac{1}{2}{\\mathbf{1}}_0\\left[s\\right]\\overline{\\alpha(s)}^{\\;\\alpha}\\right\\rangle_{s\\vert m}\\nonumber\\\\ & = & \\frac{1}{2}\\left\\langle { \\mathbf{1}}_+\\left[s\\right]\\overline{{\\mathbf{1}}\\left[\\alpha(s)\\!=\\!-\\!1\\right]}^{\\;\\alpha } \\!-\\!{\\mathbf{1}}_-\\left[s\\right]\\overline{{\\mathbf{1}}\\left[\\alpha(s)\\!=\\!+\\!1\\right]}^{\\;\\alpha}\\!-\\!\\frac{1}{2}{\\mathbf{1}}_0\\left[s\\right ] \\overline{\\alpha(s)}^{\\;\\alpha}\\right\\rangle_{s\\vert m}\\nonumber\\\\ & = & \\frac{1}{2}\\left(\\left[\\frac{1\\!+\\!m}{2}\\right]\\left[\\frac{1\\!-\\!m}{2}\\right]\\right)^{\\frac{k}{2}}\\bigg\\{\\sum_{s}\\left[\\frac{1\\!+\\!m}{1\\!-\\!m}\\right]^{\\frac{\\vert\\sum_{j=1}^k s_j\\vert}{2}}{\\mathbf{1}}_+\\left[s\\right]\\overline{{\\mathbf{1}}\\left[\\alpha(s)\\!=\\!-\\!1\\right]}^{\\;\\alpha}\\nonumber\\\\ & \\!-\\!&\\sum_{s}\\left[\\frac{1\\!-\\!m}{1\\!+\\!m}\\right]^{\\frac{\\vert\\sum_{j=1}^k s_j\\vert}{2 } } { \\mathbf{1}}_-\\left[s\\right]\\overline{{\\mathbf{1}}\\left[\\alpha(s)\\!=\\!+\\!1\\right]}^{\\;\\alpha}-\\frac{1}{2}\\sum_{s}{\\mathbf{1}}_0\\left[s\\right ]   \\overline{\\alpha(s)}^{\\;\\alpha}\\bigg\\},\\nonumber\\end{aligned}\\ ] ] where in the above we used the equality",
    "@xmath120=\\left[\\frac{1\\!+\\!m}{2}\\right]^{\\frac{k+\\sum_{j=1}^k s_j}{2}}\\left[\\frac{1\\!-\\!m}{2}\\right]^{\\frac{k-\\sum_{j=1}^k s_j}{2}}$ ] .",
    "let us now consider the sum @xmath121}^{\\;\\alpha } \\!-\\ !",
    "\\sum_{s}\\overline{{\\mathbf{1}}\\left[\\alpha(s)\\!=\\!-\\!1\\right]}^{\\;\\alpha}\\label{eq : zero}\\\\ & = & \\sum_{s}\\left({\\mathbf{1}}_+\\left[s\\right]+{\\mathbf{1}}_-\\left[s\\right]+{\\mathbf{1}}_0\\left[s\\right]\\right)\\left(\\overline{{\\mathbf{1}}\\left[\\alpha(s)\\!=\\!+\\!1\\right]}^{\\;\\alpha}-\\overline{{\\mathbf{1}}\\left[\\alpha(s)\\!=\\!-\\!1\\right]}^{\\;\\alpha}\\right)\\nonumber\\\\ & = & \\sum_{s}\\left(\\frac{1}{2}{\\mathbf{1}}_0\\left[s\\right]\\overline{\\alpha(s)}^{\\;\\alpha}+{\\mathbf{1}}_-\\left[s\\right]\\overline{{\\mathbf{1}}\\left[\\alpha(s)\\!=\\!+\\!1\\right]}^{\\;\\alpha}\\!-\\!{\\mathbf{1}}_+\\left[s\\right]\\overline{{\\mathbf{1}}\\left[\\alpha(s)\\!=\\!-\\!1\\right]}^{\\;\\alpha}\\right)=0.\\nonumber\\end{aligned}\\ ] ]    adding the above representation of zero to the terms inside the curly brackets in the equation ( [ eq : difference ] ) gives    @xmath122\\left[\\frac{1\\!-\\!m}{2}\\right]\\right)^{\\frac{k}{2}}\\nonumber\\\\ & & \\times\\bigg\\{\\sum_{s}\\left(\\left[\\frac{1\\!+\\!m}{1\\!-\\!m}\\right]^{\\frac{\\vert\\sum_{j=1}^k s_j\\vert}{2}}-1\\right){\\mathbf{1}}_+\\left[s\\right]\\overline{{\\mathbf{1}}\\left[\\alpha(s)\\!=\\!-\\!1\\right]}^{\\;\\alpha}\\nonumber\\\\ & \\!+\\!&\\sum_{s}\\left(1-\\left[\\frac{1\\!-\\!m}{1\\!+\\!m}\\right]^{\\frac{\\vert\\sum_{j=1}^k s_j\\vert}{2}}\\right ) { \\mathbf{1}}_-\\left[s\\right]\\overline{{\\mathbf{1}}\\left[\\alpha(s)\\!=\\!+\\!1\\right]}^{\\;\\alpha}\\bigg\\}\\label{eq : difffinal}\\end{aligned}\\ ] ]    which is clearly @xmath123 for @xmath109 and @xmath124 for @xmath111 $ ] .",
    "one can show that the function @xmath125 , which we used in the bounding procedure ( [ eq : difference])-([eq : difffinal ] ) , has the following properties : . ]",
    "( i ) @xmath126 when @xmath127 and @xmath128 when @xmath129 ( @xmath130 ) for @xmath131 ; ( ii ) for @xmath132 there exists @xmath133\\setminus\\{0\\}$ ] such that @xmath134 .",
    "< 1.5em - 1.5em plus0em minus0.5em",
    "height0.75em width0.5em depth0.25em    the consequence of proposition [ prop:1 ] is that the ordered ferromagnetic ( fm ) phase @xmath135 is a fixed point of ( [ eq : m ] ) ( if at all ) _ only _ for values of @xmath136 and @xmath1 which satisfy @xmath132 .",
    "this situation leads to the pm / fm phase boundary , depicted in the phase diagram ( figure [ fig:3 ] ) , which for @xmath137 approaches @xmath12 as @xmath138 ; this is follows from the stirling s approximation of @xmath139 .",
    "bn constructed from a single boolean function @xmath140 saturates this boundary .",
    "we note that a similar result , for odd @xmath1 only , have been conjectured using the annealed approximation and multiplexing techniques  @xcite .",
    "( 60,55 ) ( 5,0)=45 ( 7,30)@xmath6(37,19)@xmath141(30,29)@xmath142(20,35)@xmath143 ( 40,-2)@xmath1    in the original rbn model , which we have considered in the section [ section : annmodel ] , the stationary state @xmath81 , @xmath144 is for any @xmath145 . here",
    "we explore a possibility for the system ( [ def : algorithm ] ) to have the disordered pm ( @xmath81 , @xmath146 ) and two ordered fm ( @xmath135 , @xmath98 ) and sg ( @xmath81 , @xmath98 ) states . for @xmath147 , @xmath146 is a fixed point of ( [ eq : corr ] ) iff @xmath148 which occurs only for _ balanced boolean functions _ , with an equal number of @xmath149 in the output .    [ prop:2 ] for @xmath81 the point @xmath146 is a unique stable solution of ( [ eq : corr ] ) when @xmath150 .    in order to show this we first define the function @xmath151\\operatorname*{sgn}[s\\cdot\\hat{s}]$ ] which is related to the function @xmath152 via the equality @xmath153 .",
    "this property follows from the calculation @xmath154\\operatorname*{sgn}[s.\\hat{s}]\\\\ & = & \\tanh^2(\\beta)\\sum_{s}\\!\\prod_{j=1}^{k}\\!\\left[\\!\\frac{1+s_jc}{2}\\right]\\operatorname*{sgn}[\\sum_{j=1}^k s_j]=\\tanh(\\beta)f_\\chi(c).\\nonumber\\end{aligned}\\ ] ] next we define the function @xmath155\\alpha(s)\\alpha(\\hat{s})$ ] , where @xmath89 is an arbitrary balanced boolean function , and compute the difference @xmath156 using the same steps as described in the equations ( [ eq : difference])-([eq : difffinal ] ) .",
    "the result of this computation is that @xmath157 and @xmath158 on the intervals @xmath159 and @xmath160 $ ] , respectively , from which the bounds @xmath161 and @xmath162 on the same intervals follow .",
    "the behavior of @xmath163 $ ] with respect to the inverse temperature @xmath136 is the same as of @xmath152 , which we described in the proof of proposition [ prop:1 ] , but with the @xmath164 being replaced by the @xmath165 .",
    "< 1.5em - 1.5em plus0em minus0.5em height0.75em width0.5em depth0.25em    from the proposition [ prop:2 ] the case of @xmath81 , @xmath98 and finite @xmath136 occurs only ( if at all ) when @xmath166 .",
    "the resulting fm / sg phase boundary ( see figure  [ fig:3 ] ) approaches @xmath12 as @xmath167 when @xmath137 .",
    "the @xmath89-averages in equations ( [ eq : m])-([eq : corr ] ) can be computed for a uniform distribution over all balanced boolean functions to obtain @xmath95 for all @xmath96 , which implies @xmath168 .",
    "the latter has only one @xmath146 trivial solution for any finite @xmath136 and develops a second @xmath103 solution only for @xmath100 .",
    "thus , only the model ( [ def : algorithm ] ) with non - uniform distributions over the balanced boolean functions can have the critical behavior as in figure [ fig:3 ] .",
    "it is interesting that the upper bound @xmath139 computed here for @xmath1 odd is identical to the one computed for noisy boolean formulas  @xcite .",
    "a noisy boolean formula is a tree in which leaves are either boolean constants or references to arguments , internal nodes are noisy boolean functions ( for each function - input there is an error probability @xmath6 which inverts the function - output ) and the root corresponds to the formula output .",
    "the maj-@xmath1 function , which plays a prominent role in the area of fault - tolerant computation ( ftc ) as it allows to correct the errors by its majority - vote function  @xcite , saturates the bound @xmath139 .",
    "the idea to have two copies of the same system , used in this work only to study initial - states perturbations , is also useful for ftc as it allows to compare the noisy system against its noiseless counterpart  @xcite .",
    "the connection of our work with ftc stems from the fact that each site @xmath30 at time @xmath19 in our model can be associated with the output @xmath169 of a @xmath1-ary boolean formula of depth @xmath19 which computes a function of the associated initial states ( a subset of @xmath170 )  @xcite .",
    "in the presence of noise , a formula of considerable depth ( large @xmath19 ) loses all input information for @xmath131 and odd @xmath1  @xcite .",
    "this suggests that the upper bound @xmath139 , for odd @xmath1 , is more general and is valid for transitions at _ all _ @xmath75 values identifying the point where stationary states depend on the initial states and ergodicity breaks . for @xmath1 even such _ general",
    "_ threshold is not yet known .      in model  ( [ def :",
    "algorithm ] ) the state of site @xmath30 at time @xmath19 depends on its states at previous times only indirectly via the sites affected by the state of site @xmath30 at previous times .",
    "these dependencies create correlations via the directed loops in the time - space picture of bn ( as in figure  [ fig:1 ] ) , but in the limit of @xmath171 they become very weak , as was argued in previous works in this area  @xcite .",
    "this allows one to express the observables of interest ( [ def : observ ] ) in the closed form ( [ eq : m])-([eq : overlap ] ) .",
    "however , in a broad family of models , which includes the boolean networks with reversible computation  @xcite and gene networks with self - regulation  @xcite , the state of a site @xmath30 at a time @xmath21 depends directly on its state at time @xmath19 .",
    "an exemplar model with strong memory effects , which was used in  @xcite to construct a model of cell - cycle regulatory network ( @xmath172 ) of budding yeast , is of the form @xmath173\\!+\\!s_i(t)\\delta[h_i(t);2h]\\label{eq : process},\\ ] ] where @xmath174 and @xmath175 .",
    "mean - field theory ( @xmath171 ) was derived  @xcite using the annealed approximation in a variant of this model , where the interactions @xmath176 were randomly distributed @xmath177 .",
    "significant discrepancies between the theory and simulation results has been pointed out  @xcite for integer @xmath178 values ( in this case it is possible that @xmath179 ) , which was attributed to the presence of strong memory effects .",
    "refinements of the annealed approximation method improved the results obtained only slightly  @xcite but break down in most of the parameter space .",
    "this model ( [ eq : process ] ) can be easily incorporated into our theoretical framework .",
    "the result of the gfa ( [ eq : m ] ) for this process ( with thermal noise ) can be obtained by replacing the average @xmath180 by @xmath181 and the probability function @xmath182 by @xmath183\\!+\\!s(t)\\delta[h(t);2h]\\}}}{2\\cosh\\beta\\{\\operatorname*{sgn}[h(t)\\!-\\!2h]\\!+\\!s(t)\\delta[h(t);2h]\\}}\\label{def : probrtn},\\end{aligned}\\ ] ] where @xmath184 .    in the case of @xmath185 ,",
    "the probability function ( [ def : probrtn ] ) is independent of @xmath186 and equations ( [ eq : m])-([eq : overlap ] ) have the same structure as model  ( [ eq : process ] ) : the @xmath89-averages @xmath187 and @xmath188 are replaced by the averages @xmath189}^\\xi$ ] and @xmath189\\operatorname*{sgn}[\\hat h(t)\\!-\\!2h]}^\\xi$ ] , respectively .",
    "the equation for @xmath45 recovers the annealed approximation result  @xcite ( using the relation @xmath190 ) . in fig .",
    "[ fig:4](a , b ) , we plot our analytical predictions for the evolution of @xmath45 and @xmath191 against the results of monte carlo ( mc ) simulation which use ( [ eq : process ] ) .",
    "the correlation function @xmath191 , in the limit of @xmath192 , approaches the stationary solution of the overlap function ( [ eq : overlap ] ) with increasing @xmath193 as predicted ( fig .",
    "[ fig:4](b ) ) .",
    "( 350,100 ) ( 159,0 ) ) and correlation ( @xmath194 ) functions with time @xmath19 is governed by ( [ eq : process ] ) .",
    "theoretical results ( lines ) are plotted against the results of mc simulations ( symbols ) with @xmath195 .",
    "each mc data - point is averaged over 10 runs .",
    "error bars are smaller than symbol size .",
    "evolution of @xmath75 ( a ) and @xmath196 ( b ) for @xmath185 . in ( b )",
    "we plot @xmath196 for @xmath197 and @xmath198 .",
    "[ fig:4 ] , title=\"fig : \" ] ( 245,-7)@xmath19 ( 0,0 ) ) and correlation ( @xmath194 ) functions with time @xmath19 is governed by ( [ eq : process ] ) .",
    "theoretical results ( lines ) are plotted against the results of mc simulations ( symbols ) with @xmath195 .",
    "each mc data - point is averaged over 10 runs .",
    "error bars are smaller than symbol size .",
    "evolution of @xmath75 ( a ) and @xmath196 ( b ) for @xmath185 . in ( b )",
    "we plot @xmath196 for @xmath197 and @xmath198 .",
    "[ fig:4 ] , title=\"fig : \" ] ( 1,65)@xmath75 ( 85,-7)@xmath19 ( 160,65)@xmath196 ( 130,80)@xmath199(290,80)@xmath200    the situation is very different when @xmath201 . the magnetization @xmath202 , where @xmath203 is a marginal of ( [ eq : m ] ) with @xmath204 , is no longer closed as in ( [ eq : m ] ) , but depends on @xmath205 macroscopic observables ( all magnetization , all multi - time correlations ) .",
    "thus the number of macroscopic observables that determine the value of @xmath45 , or any other function computed from ( [ eq : m ] ) , grows exponentially with time .",
    "annealed approximation results  @xcite for this model when @xmath201 are only exact up to @xmath206 time steps ( the equation for @xmath207 in our approach and in  @xcite are identical ) and deviate significantly from the exact solution at later times ( fig .  [ fig:5](c ) ) . a typical evolution of the correlation function @xmath191 in the system ( [ eq : process ] ) when @xmath208 is shown in fig .",
    "[ fig:5](d ) .",
    "( 350,100 ) ( 159,0 ) ( a ) and @xmath194 ( b ) for @xmath201 . in ( b )",
    "we plot @xmath196 for @xmath209 and @xmath210 .",
    "theoretical results ( lines ) are plotted against the results of mc simulations ( symbols ) with @xmath195 .",
    "each mc data - point is averaged over 10 runs .",
    "error bars are smaller than symbol size.[fig:5 ] , title=\"fig : \" ] ( 245,-7)@xmath19 ( 0,0 ) ( a ) and @xmath194 ( b ) for @xmath201 . in ( b )",
    "we plot @xmath196 for @xmath209 and @xmath210 .",
    "theoretical results ( lines ) are plotted against the results of mc simulations ( symbols ) with @xmath195 .",
    "each mc data - point is averaged over 10 runs .",
    "error bars are smaller than symbol size.[fig:5 ] , title=\"fig : \" ] ( 1,65)@xmath75 ( 85,-7)@xmath19 ( 160,65)@xmath196 ( 130,80)@xmath199(290,80)@xmath200",
    "we applied the generating functional method to analyze the dynamics of recurrent boolean networks .",
    "the analysis resulted in a coupled set of recursive equations for a small number of macroscopic observables that provide an exact description of the dynamics in a broad range of boolean networks .",
    "based on the analysis we also showed that for a large class of models the annealed approximation does provide exact results for both magnetization and overlap order parameters ; although results for correlation between states at different times are generally incorrect . however , it turns out that in models where the state of spin at time @xmath19 depends on its state at previous times directly the annealed approximation always fails .",
    "this is due to the fact that approximation does not take into account the correlations which are very strong in such models . comparing the two transition probabilities ( [ eq : micro ] ) and ( [ def : probrtn ] ) for the processes without and with memory , respectively ,",
    "it is clear from the single - spin trajectory equation ( [ eq : m ] ) , that as soon as there is an explicit dependence of a spin on its states at previous times , an exponential ( in time ) number of macroscopic observables will be required .",
    "furthermore , also in models where this approximation works well it is useful to know the two - time correlations as it provides us with insight into properties of the stationary states .",
    "when one considers systems with thermal noise , the suggested framework provides additional new and interesting results .",
    "we have computed the noise threshold above which the system is always ergodic and critical noise levels where phase transitions occur . here",
    "the two - time correlation function is particularly useful as it allows one to compute the edwards - anderson order parameter @xmath211 , used to detect the spin - glass phase .",
    "one of the remaining questions is to provide an example of a model ( or show that it does not exists ) with a phase diagram as in figure  [ fig:3 ] .",
    "the direct computation of @xmath211 for all balanced boolean functions with @xmath212 inputs is possible for small @xmath1 but soon becomes intractable as the number of such functions grows exponentially with @xmath1 .",
    "the other important question is to find a systematic way to generate good approximations for the dynamics with strong memory effects .",
    "although the theory developed in this work can describe the dynamics of such models exactly it can be used only for relatively short times due to the rapid increase in the number of macroscopic order parameters .",
    "however , the equations of our theory can be used to check the quality of approximations used in such models in all future works and possibly serve as a starting point for such studies .",
    "the work undertaken here can be extended in a numerous ways .",
    "for instance , one can easily adapt the framework developed here to study boolean networks with inhomogeneous connectivities  @xcite and to examine different noise models  @xcite .",
    "support by the leverhulme trust ( grant f/00 250/h ) is acknowledged .",
    "34 natexlab#1#1bibnamefont # 1#1bibfnamefont # 1#1citenamefont # 1#1url # 1`#1`urlprefix[2]#2 [ 2][]#2    , * * , ( ) .    ,",
    "_ _ ( , , ) .    , , , ,",
    "* * , ( ) .    ,",
    "* * , ( ) .    , , , * * , ( ) .    , , , _ _ ( , , ) , chap . ,",
    "pp . .    , _ _ ( , , ) , vol .   of _ _ , chap .  , pp . .    , , , , , * * , ( ) .    , , , , * * , .    , * * , ( ) .    , * * , ( ) .    , * * , ( ) .    , , , * * , ( ) .    , , , * * , ( ) .    ,",
    "* * , ( ) .    , * * , ( ) .    , * * , ( ) .    , * * , ( ) .    , * * , ( ) .    , * * , ( ) .    , , , _ _ ( , , ) .    , * * , ( ) .    , * * , ( ) .    , * * , ( ) .    , , , * * , ( ) .    , * * , ( ) .    , _ _ ( , , ) , pp . .    , , ,",
    "* * , ( ) .    , , , * * , ( ) .",
    ", , , , , * * , ( ) .    , , , in _ _",
    "( ) , pp . .    , , , ( ) , .    , * * , ( ) .    , , ,",
    "* * , ( ) .",
    "in this section , we outline the calculation which takes us from the definition of generating functional ( [ eq : gf ] ) to the saddle - point integral ( [ eq : gf - recurr - sp ] ) . the starting point of this calculation",
    "is the generating functional @xmath213&=&\\sum_{\\{s_{i}^{1}(t),s_{i}^{2}(t)\\}}{\\mbox{$p$}}({\\mbox{\\boldmath$s$}}^1(0),{\\mbox{\\boldmath$s$}}^2(0))\\prod_{t\\!=\\!0}^{t_{max}\\!-\\!1}\\ !",
    "\\prod_{i=1}^n\\prod_{\\gamma = 1}^{2}\\frac{{\\mathrm{e}}^{\\beta s_{i}^\\gamma(t\\!+\\!1)h_{i}^{\\gamma}({\\mbox{\\boldmath$s$}}^\\gamma(t))}}{2\\cosh[\\beta   h_{i}^{\\gamma}({\\mbox{\\boldmath$s$}}^\\gamma(t))]}\\label{eq : gf1}\\\\ & & \\times\\exp\\left[-{\\mathrm{i}}\\sum_{t\\!=\\!0}^{t_{max}}\\sum_{i\\!=\\!1}^n\\sum_{\\gamma\\!=\\!1}^2\\psi_{i}^{\\gamma } ( t ) s_{i}^{\\gamma } ( t)\\right ] , \\nonumber\\end{aligned}\\ ] ] where in the above we have defined the field - variables @xmath214 . removing these fields from equation  ( [ eq : gf1 ] ) via the integral representations of unity @xmath215}\\right\\}\\!=\\!1\\label{def : unity}\\end{aligned}\\ ] ] gives @xmath213&=&\\sum_{\\{s_{i}^{1}(t),s_{i}^{2}(t)\\}}{\\mbox{$p$}}({\\mbox{\\boldmath$s$}}^1(0),{\\mbox{\\boldmath$s$}}^2(0))\\exp\\left[-{\\mathrm{i}}\\sum_{t\\!=\\!0}^{t_{max}}\\sum_{i\\!=\\!1}^n\\sum_{\\gamma\\!=\\!1}^2\\psi_{i}^{\\gamma } ( t ) s_{i}^{\\gamma } ( t)\\right]\\label{eq : gf2}\\\\ & & \\times\\prod_{t=0}^{t_{max}\\!-\\!1}\\ ! \\prod_{i=1}^n\\prod_{\\gamma = 1}^{2}\\left\\{\\int\\frac{\\mathrm d   h_{i}^{\\gamma}(t)\\;\\mathrm d   \\hat{h}_{i}^{\\gamma } ( t)}{2\\pi}\\;{\\mathrm{e}}^{{\\mathrm{i}}\\hat{h}_{i}^{\\gamma}(t ) h_{i}^{\\gamma}(t)}\\frac{{\\mathrm{e}}^{\\beta s_{i}^\\gamma(t\\!+\\!1)h_{i}^{\\gamma}(t)}}{2\\cosh[\\beta   h_{i}^{\\gamma}(t)]}\\right\\ } \\nonumber\\\\ & & \\times\\prod_{t=0}^{t_{max}\\!-\\!1}\\ !",
    "\\prod_{i=1}^n\\prod_{\\gamma = 1}^{2}{\\mathrm{e}}^{-{\\mathrm{i}}\\hat{h}_{i}^{\\gamma } ( t ) \\sum_{i_1,\\ldots , i_k}^n a_{i_1,\\ldots , i_k}^{i } \\alpha_i(s_{i_1}^{\\gamma}(t),\\ldots , s_{i_k}^{\\gamma}(t))}\\label{eq : disorder}.\\end{aligned}\\ ] ]    now we can average out the disorder in ( [ eq : disorder ] ) @xmath216}}\\left\\{\\sum_{a_{{\\textbf{i}}}^{i}}\\left[\\frac{1}{n^k}\\delta_{a_{{\\textbf{i}}}^{i};1}+(1-\\frac{1}{n^k})\\delta_{a_{{\\textbf{i}}}^{i};0}\\right]\\right\\}\\delta\\left[1 ; \\sum_{{\\textbf{i}}^\\prime\\subseteq{[n ] } } a_{{\\textbf{i}}^\\prime}^{i}\\right]\\nonumber\\\\ & & \\times\\sum_{\\alpha_i}{\\mbox{$p$}}(\\alpha_{i})\\prod_{i_1,\\ldots , i_k}^n{\\mathrm{e}}^{-{\\mathrm{i}}\\sum_{t=0}^{t_{max}\\!-\\!1}\\ !",
    "\\sum_{\\gamma = 1}^{2 }   \\hat{h}_{i}^{\\gamma } ( t )   a_{i_1,\\ldots , i_k}^{i } \\alpha_i(s_{i_1}^{\\gamma}(t),\\ldots , s_{i_k}^{\\gamma}(t))}\\nonumber\\\\ & & = \\frac{1}{z_a}\\ !",
    "\\prod_{i=1}^n \\prod_{{\\textbf{i}}\\subseteq{[n]}}\\left\\{\\sum_{a_{{\\textbf{i}}}^{i}}\\left[\\frac{1}{n^k}\\delta_{a_{{\\textbf{i}}}^{i};1}+(1-\\frac{1}{n^k})\\delta_{a_{{\\textbf{i}}}^{i};0}\\right]\\right\\}\\delta\\left[1 ; \\sum_{{\\textbf{i}}^\\prime\\subseteq{[n ] } } a_{{\\textbf{i}}^\\prime}^{i}\\right]\\nonumber\\\\ & & \\times\\prod_{i_1,\\ldots , i_k}^n\\overline{{\\mathrm{e}}^{-{\\mathrm{i}}\\sum_{t=0}^{t_{max}\\!-\\!1}\\ !",
    "\\sum_{\\gamma = 1}^{2 }   \\hat{h}_{i}^{\\gamma } ( t )   a_{i_1,\\ldots , i_k}^{i } \\alpha_i(s_{i_1}^{\\gamma}(t),\\ldots , s_{i_k}^{\\gamma}(t))}}^{\\;\\alpha_i}\\nonumber\\\\ & & = \\frac{1}{z_a}\\!\\left\\{\\prod_{i=1}^n\\int_{-\\pi}^{\\pi}\\frac{\\mathrm d \\omega_i}{2\\pi}{\\mathrm{e}}^{{\\mathrm{i}}\\omega_i}\\right\\}\\nonumber\\\\ & & \\times\\exp\\!\\left[\\frac{1}{n^k}\\!\\!\\sum_{i , i_1,\\ldots , i_k}^{n}\\!\\!\\overline{\\left({\\mathrm{e}}^{-{\\mathrm{i}}\\sum_{t=0}^{t_{max}\\!-\\!1}\\ ! \\sum_{\\gamma = 1}^{2 }   \\hat{h}_{i}^{\\gamma } ( t ) \\alpha_i(s_{i_1}^{\\gamma}(t),\\ldots , s_{i_k}^{\\gamma}(t))-{\\mathrm{i}}\\omega_i}\\ ! -\\!1\\right)}^{\\ ; \\alpha}\\!\\!+o(n^{-k+1})\\right]\\nonumber\\end{aligned}\\ ] ] and use this result in the generating functional  ( [ eq : gf2 ] ) to obtain @xmath217}\\label{eq : gf - recurr-1}\\\\ & & = \\sum_{\\{s_{i}^{1}(t),s_{i}^{2}(t)\\}}{\\mbox{$p$}}({\\mbox{\\boldmath$s$}}^1(0),{\\mbox{\\boldmath$s$}}^2(0))\\exp\\left[-{\\mathrm{i}}\\sum_{t\\!=\\!0}^{t_{max}}\\sum_{i\\!=\\!1}^n\\sum_{\\gamma\\!=\\!1}^2\\psi_{i}^{\\gamma } ( t ) s_{i}^{\\gamma } ( t)\\right]\\nonumber\\\\ & \\times&\\prod_{t=0}^{t_{max}\\!-\\!1}\\ ! \\prod_{i=1}^n\\prod_{\\gamma = 1}^{2}\\left\\{\\int\\frac{\\mathrm d   h_{i}^{\\gamma}(t)\\mathrm d   \\hat{h}_{i}^{\\gamma } ( t)}{2\\pi}\\;{\\mathrm{e}}^{{\\mathrm{i}}\\hat{h}_{i}^{\\gamma}(t ) h_{i}^{\\gamma}(t)}\\frac{{\\mathrm{e}}^{\\beta s_{i}^\\gamma(t\\!+\\!1)h_{i}^{\\gamma}(t)}}{2\\cosh[\\beta   h_{i}^{\\gamma}(t)]}\\right\\ } \\nonumber\\\\ & \\times&\\frac{1}{z_a}\\!\\left\\{\\prod_{i=1}^n\\int_{-\\pi}^{\\pi}\\frac{\\mathrm d \\omega_i}{2\\pi}{\\mathrm{e}}^{{\\mathrm{i}}\\omega_i}\\right\\}\\exp\\!\\big[n\\int\\{\\mathrm d\\mathbf{\\hat{h}}(t)\\}\\int_{-\\pi}^{\\pi}\\mathrm d\\omega\\nonumber\\\\ & \\times&\\frac{1}{n}\\sum_{i=1}^{n}\\left\\{\\delta(\\omega-\\omega_i)\\prod_{t=0}^{t_{max}\\!-\\!1}\\delta(\\mathbf{\\hat{h}}(t)-\\mathbf{\\hat{h}}_i(t))\\right\\}\\nonumber\\\\ & \\times&\\sum_{\\{{\\mbox{\\boldmath$s$}}_j(t)\\}}\\frac{1}{n^k}\\!\\sum_{i_1,\\ldots , i_k}^{n}\\left\\{\\prod_{t=0}^{t_{max}\\!-\\!1}\\prod_{j=1}^{k}\\delta[{\\mbox{\\boldmath$s$}}_j(t);{\\mbox{\\boldmath$s$}}_{i_j}(t)]\\right\\}\\nonumber\\\\ & \\times&\\overline{\\left({\\mathrm{e}}^{-{\\mathrm{i}}\\sum_{t=0}^{t_{max}\\!-\\!1}\\ ! \\sum_{\\gamma = 1}^{2 }   \\hat{h}^{\\gamma } ( t)\\;\\alpha(s_{1}^{\\gamma}(t),\\ldots , s_{k}^{\\gamma}(t))-{\\mathrm{i}}\\omega } -1\\right)}^{\\;\\alpha}+o(n^{-k+1})\\big]\\nonumber,\\end{aligned}\\ ] ] where in the above we have defined the vectors @xmath218 and @xmath219 . using the unity representations @xmath220}=1\\\\ & & \\int\\{\\mathrm d\\omega \\mathrm d\\hat{\\omega}\\}{\\mathrm{e}}^{{\\mathrm{i}}n\\ ! \\int\\{{\\mathrm{d}}\\mathbf{\\hat{h}}(t)\\}{\\mathrm{d}}\\omega\\hat{\\omega}(\\{\\mathbf{\\hat{h}}(t)\\},\\omega)[\\omega(\\{\\mathbf{\\hat{h}}(t)\\},\\omega)\\!-\\!\\frac{1}{n}\\sum_{i=1}^n\\left[\\prod_{t=0}^{t_{max}\\!-\\!1}\\delta(\\mathbf{\\hat{h}}(t)\\!-\\!\\mathbf{\\hat{h}}_i(t))\\right]\\delta(\\omega\\!-\\!\\omega_i)]}=1\\nonumber\\end{aligned}\\ ] ] gives @xmath217}=\\int\\{\\mathrm d p",
    "\\mathrm d\\hat{p}\\mathrm d\\omega \\mathrm d\\hat{\\omega}\\}\\nonumber\\label{eq : gf - recurr-2}\\\\ & & \\times\\exp n\\big[{\\mathrm{i}}\\sum_{\\{{\\mbox{\\boldmath$s$}}(t)\\}}\\hat{p}(\\{{\\mbox{\\boldmath$s$}}(t)\\})p(\\{{\\mbox{\\boldmath$s$}}(t)\\})+{\\mathrm{i}}\\int\\{{\\mathrm{d}}\\mathbf{\\hat{h}}(t)\\}\\;{\\mathrm{d}}\\omega\\;\\hat{\\omega}(\\{\\mathbf{\\hat{h}}(t)\\},\\omega)\\;\\omega(\\{\\mathbf{\\hat{h}}(t)\\},\\omega)\\nonumber\\\\ & & + \\int\\{\\mathrm d\\mathbf{\\hat{h}}(t)\\}\\;\\mathrm d\\omega\\;\\omega(\\{\\mathbf{\\hat{h}}(t)\\},\\omega)\\sum_{\\{\\mathbf{s}_j(t)\\}}\\left\\{\\prod_{j=1}^k p(\\{{\\mbox{\\boldmath$s$}}_j(t)\\})\\right\\ } \\\\ & & \\times\\overline{\\left({\\mathrm{e}}^{-{\\mathrm{i}}\\sum_{t=0}^{t_{max}\\!-\\!1}\\ ! \\sum_{\\gamma = 1}^{2 }   \\hat{h}^{\\gamma } ( t)\\;\\alpha(s_{1}^{\\gamma}(t),\\ldots , s_{k}^{\\gamma}(t))-{\\mathrm{i}}\\omega } -1\\right)}^{\\;\\alpha}-\\frac{1}{n}\\log z_a\\big]\\nonumber\\\\ & & \\times\\sum_{\\{s_{i}^{1}(t),s_{i}^{2}(t)\\}}{\\mbox{$p$}}({\\mbox{\\boldmath$s$}}^1(0),{\\mbox{\\boldmath$s$}}^2(0))\\exp\\left[-{\\mathrm{i}}\\sum_{t\\!=\\!0}^{t_{max}}\\sum_{i\\!=\\!1}^n\\sum_{\\gamma\\!=\\!1}^2\\psi_{i}^{\\gamma } ( t ) s_{i}^{\\gamma } ( t)\\right]\\nonumber\\\\ & & \\times\\prod_{t=0}^{t_{max}\\!-\\!1}\\ !",
    "\\prod_{i=1}^n\\prod_{\\gamma = 1}^{2}\\left\\{\\int\\frac{\\mathrm d   h_{i}^{\\gamma}(t)\\mathrm d   \\hat{h}_{i}^{\\gamma } ( t)}{2\\pi}\\;{\\mathrm{e}}^{{\\mathrm{i}}\\hat{h}_{i}^{\\gamma}(t ) h_{i}^{\\gamma}(t)}\\frac{{\\mathrm{e}}^{\\beta s_{i}^\\gamma(t\\!+\\!1)h_{i}^{\\gamma}(t)}}{2\\cosh[\\beta   h_{i}^{\\gamma}(t)]}\\right\\ } \\nonumber\\\\ & & \\times\\left\\{\\prod_{i=1}^n\\int_{-\\pi}^{\\pi}\\frac{\\mathrm d \\omega_i}{2\\pi}{\\mathrm{e}}^{{\\mathrm{i}}\\omega_i}\\right\\}{\\mathrm{e}}^{-{\\mathrm{i}}\\sum_{i=1}^n\\hat{p}(\\{{\\mbox{\\boldmath$s$}}_i(t)\\})-{\\mathrm{i}}\\sum_{i=1}^n\\hat{\\omega}(\\{\\mathbf{\\hat{h}}_i(t)\\},\\omega_i)}. \\nonumber\\end{aligned}\\ ] ] equation  ( [ eq : gf - recurr-2 ] ) gives one the saddle - point integral  ( [ eq : gf - recurr - sp ] ) if write its site - dependent part in the exponential form @xmath221\\right]\\nonumber\\label{def : mpart},\\end{aligned}\\ ] ] where the definition @xmath222\\label{def : m - recurr}\\\\ & & = { \\mbox{$p$}}(s_i^1(0),s_i^2(0))\\exp\\left[-{\\mathrm{i}}\\sum_{t\\!=\\!0}^{t_{max}}\\sum_{\\gamma\\!=\\!1}^2\\psi_{i}^{\\gamma } ( t ) s_{i}^{\\gamma } ( t)\\right]\\nonumber\\\\ & & \\times \\prod_{t=0}^{t_{max}\\!-\\!1}\\ !",
    "\\prod_{\\gamma = 1}^{2}\\left\\{\\;{\\mathrm{e}}^{{\\mathrm{i}}\\hat{h}_{i}^{\\gamma}(t ) h_{i}^{\\gamma}(t)}\\frac{{\\mathrm{e}}^{\\beta s_{i}^\\gamma(t\\!+\\!1)h_{i}^{\\gamma}(t)}}{2\\cosh[\\beta   h_{i}^{\\gamma}(t)]}\\right\\}\\nonumber\\\\ & & \\times{\\mathrm{e}}^{-{\\mathrm{i}}\\hat{\\omega}(\\{\\mathbf{\\hat{h}}_i(t)\\},\\omega_i)+{\\mathrm{i}}\\omega_i-{\\mathrm{i}}\\hat{p}(\\{{\\mbox{\\boldmath$s$}}_i(t)\\})}\\nonumber\\end{aligned}\\ ] ] is used with the shorthand @xmath223 .",
    "in this section , we show that the conjugate order - parameter function @xmath224 , which is governed by the equation ( [ eq : sp2-recurr ] ) , is a constant function . in order to do this ,",
    "we first rewrite the ( disorder - averaged ) path - probability ( [ eq : pathprob ] ) as follows    @xmath225}=\\frac{1}{z_a}{\\mbox{$p$}}({\\mbox{\\boldmath$s$}}^1(0),{\\mbox{\\boldmath$s$}}^2(0))\\label{eq : disorder - averaged - pathprob}\\\\ & & \\times\\prod_{i=1}^n\\overline{\\!\\bigg\\{\\prod_{t\\!=\\!0}^{t_{max}\\!-\\!1}\\ ! \\prod_{\\gamma = 1}^{2}\\frac{{\\mathrm{e}}^{\\beta s_{i}^\\gamma(t\\!+\\!1)\\sum_{i_1,\\ldots , i_k}^n a_{i_1,\\ldots , i_k}^{i } \\alpha_i(s_{i_1}^{\\gamma } ( t),\\ldots , s_{i_k}^{\\gamma } ( t))}}{2\\cosh[\\beta\\sum_{i_1,\\ldots , i_k}^n a_{i_1,\\ldots , i_k}^{i } \\alpha_i(s_{i_1}^{\\gamma } ( t),\\ldots , s_{i_k}^{\\gamma } ( t))]}}\\nonumber\\\\ & & \\times\\overline{\\delta\\left[1;\\!\\!\\sum_{{\\textbf{i}}^\\prime\\subseteq{[n ] } } a_{{\\textbf{i}}^\\prime}^{i}\\right]\\bigg\\}}^{\\{a_{{\\textbf{i}}}^{i}\\}}\\nonumber\\\\ & = & \\frac{1}{z_a}\\prod_{i=1}^{n}\\bigg[\\int\\{\\mathrm d \\mathbf{h}_i(t)\\;\\mathrm d \\mathbf{\\hat{h}}_i(t)\\}\\int_{-\\pi}^{\\pi}\\frac{\\mathrm d \\omega_i}{2\\pi}\\;\\overline{{\\mathrm{e}}^{{\\mathrm{i}}\\omega_i(1- \\sum_{i_1,\\ldots , i_k}^na_{i_1,\\ldots , i_k}^{i})}{\\mbox{$p$}}(s_i^1(0),s_i^2(0))}\\label{def : xi}\\\\ & & \\times\\overline{\\left\\{\\prod_{t\\!=\\!0}^{t_{max}\\!-\\!1}\\ !",
    "\\prod_{\\gamma = 1}^{2}\\;{\\mathrm{e}}^{{\\mathrm{i}}\\hat{h}_{i}^{\\gamma}(t ) [ h_{i}^{\\gamma}(t)- \\sum_{i_1,\\ldots , i_k}^n a_{i_1,\\ldots , i_k}^{i } \\alpha_i(s_{i_1}^{\\gamma } ( t),\\ldots , s_{i_k}^{\\gamma } ( t))]}\\frac{{\\mathrm{e}}^{\\beta s_{i}^\\gamma(t\\!+\\!1)h_{i}^{\\gamma}(t)}}{2\\cosh[\\beta h_{i}^{\\gamma}(t)]}\\right\\}}^{\\{a_{{\\textbf{i}}}^{i}\\}}\\nonumber\\bigg]\\\\ & = & \\frac{1}{z_a}\\prod_{i=1}^{n}\\int\\{\\mathrm d \\mathbf{h}_i(t)\\;\\mathrm d \\mathbf{\\hat{h}}_i(t)\\}\\int_{-\\pi}^{\\pi}\\frac{\\mathrm d \\omega_i}{2\\pi } \\;\\overline{\\xi_i[\\{{\\mbox{\\boldmath$s$}}_i(t),\\mathbf{h}_i(t)\\}\\vert\\{\\mathbf{\\hat{h}}_i(t)\\ } , \\omega_i]}^{\\{a_{{\\textbf{i}}}^{i}\\}},\\nonumber\\end{aligned}\\ ] ]    where in the above we have averaged out the connectivity disorder only , i.e. @xmath226}}\\left\\{\\frac{1}{n^k}\\delta_{a_{{\\textbf{i}}}^{i};1}+(1\\!-\\!\\frac{1}{n^k})\\delta_{a_{{\\textbf{i}}}^{i};0}\\right\\}(\\cdots)$ ] and the definition of single - site measure @xmath227 is clear from equation  ( [ def : xi ] ) .    in the next step ,",
    "one notes that the effect of the fourier transform @xmath228\\label{def : fourier}\\\\ & & \\times{\\mathrm{e}}^{-{\\mathrm{i}}\\sum_{t\\!=\\!0}^{t_{max}\\!-\\!1}\\ ! \\mathbf{\\hat{h}}_{i}(t).\\theta(t)-{\\mathrm{i}}\\omega_i}\\nonumber\\\\ & = & \\int\\{\\mathrm d \\mathbf{h}_i(t)\\;\\mathrm d \\mathbf{\\hat{h}}_i(t)\\}\\int_{-\\pi}^{\\pi}\\frac{\\mathrm d \\omega_i}{2\\pi}\\;{\\mathrm{e}}^{{\\mathrm{i}}\\omega_i(0- \\sum_{i_1,\\ldots , i_k}^na_{i_1,\\ldots , i_k}^{i})}{\\mbox{$p$}}(s_i^1(0),s_i^2(0 ) ) \\nonumber\\\\ & & \\times\\bigg[\\prod_{t\\!=\\!0}^{t_{max}\\!-\\!1}\\ !",
    "\\prod_{\\gamma = 1}^{2}\\;{\\mathrm{e}}^{{\\mathrm{i}}\\hat{h}_{i}^{\\gamma}(t ) [ h_{i}^{\\gamma}(t)-\\theta^\\gamma(t)- \\sum_{i_1,\\ldots , i_k}^n a_{i_1,\\ldots , i_k}^{i } \\alpha_i(s_{i_1}^{\\gamma } ( t),\\ldots , s_{i_k}^{\\gamma } ( t))]}\\nonumber\\\\ & & \\times\\frac{{\\mathrm{e}}^{\\beta s_{i}^\\gamma(t\\!+\\!1)h_{i}^{\\gamma}(t)}}{2\\cosh[\\beta h_{i}^{\\gamma}(t)]}\\bigg]\\nonumber\\\\ & = & \\left\\{\\prod_{t\\!=\\!0}^{t_{max}\\!-\\!1}\\ ! \\prod_{\\gamma = 1}^{2}\\frac{{\\mathrm{e}}^{\\beta s_{i}^\\gamma(t\\!+\\!1)\\theta^{\\gamma}(t)}}{2\\cosh[\\beta \\theta^{\\gamma}(t)]}\\right\\}\\delta\\left[0;\\sum_{i_1,\\ldots , i_k}^na_{i_1,\\ldots , i_k}^{i}\\right]{\\mbox{$p$}}(s_i^1(0),s_i^2(0)),\\nonumber\\end{aligned}\\ ] ] on the function @xmath227 is to replace the boolean function @xmath229 on site @xmath30 with a constant function @xmath230 . with this in mind",
    "we can define the average site - perturbed path - probability @xmath231_{\\vert_{\\alpha_i\\rightarrow\\theta}}}\\label{eq : pertrub - pathprob}\\\\ & = & \\frac{z_a^{-1}}{n}\\sum_{i=1}^n\\bigg\\{\\prod_{j\\neq i}^{n}\\int\\{\\mathrm d \\mathbf{h}_j(t)\\;\\mathrm d \\mathbf{\\hat{h}}_j(t)\\}\\nonumber\\\\ & & \\times\\int_{-\\pi}^{\\pi}\\frac{\\mathrm d \\omega_j}{2\\pi } \\;\\overline{\\xi_j[\\{{\\mbox{\\boldmath$s$}}_j(t),\\mathbf{h}_j(t)\\}\\vert\\{\\mathbf{\\hat{h}}_j(t)\\ } , \\omega_i]}^{\\{a_{{\\textbf{i}}}^{j}\\}}\\bigg\\}\\nonumber\\\\ & & \\times\\int\\!\\!\\{\\mathrm d \\mathbf{h}_i(t)\\;\\mathrm d \\mathbf{\\hat{h}}_i(t)\\}\\!\\!\\!\\int_{-\\pi}^{\\pi}\\!\\!\\!\\frac{\\mathrm d \\omega_i}{2\\pi } \\;\\overline{\\xi_i[\\{{\\mbox{\\boldmath$s$}}_i(t),\\mathbf{h}_i(t)\\}\\vert\\{\\mathbf{\\hat{h}}_i(t)\\ } , \\omega_i]}^{\\{a_{{\\textbf{i}}}^{i}\\}}\\nonumber\\\\ & & \\times{\\mathrm{e}}^{-{\\mathrm{i}}\\sum_{t\\!=\\!0}^{t_{max}\\!-\\!1}\\ !",
    "\\mathbf{\\hat{h}}_{i}(t).\\theta(t)-{\\mathrm{i}}\\omega_i}.\\nonumber\\end{aligned}\\ ] ] to show that the object in  ( [ eq : pertrub - pathprob ] ) indeed defines a probability measure we note that it is clearly a positive semi - definite and the normalization of  ( [ eq : pertrub - pathprob ] ) can be established as follows @xmath232_{\\vert_{\\alpha_i\\rightarrow\\theta}}}\\label{eq : unity-1}\\\\ & = & \\frac{z_a^{-1}}{n}\\sum_{i=1}^n\\bigg\\{\\prod_{j\\neq i}^{n}\\sum_{\\{\\mathbf{s}_j(t)\\}}\\int\\{\\mathrm d \\mathbf{h}_j(t)\\;\\mathrm d \\mathbf{\\hat{h}}_j(t)\\}\\nonumber\\\\ & & \\times\\int_{-\\pi}^{\\pi}\\frac{\\mathrm d \\omega_j}{2\\pi } \\;\\overline{\\xi_j[\\{{\\mbox{\\boldmath$s$}}_j(t),\\mathbf{h}_j(t)\\}\\vert\\{\\mathbf{\\hat{h}}_j(t)\\ } , \\omega_i]}^{\\{a_{{\\textbf{i}}}^{j}\\}}\\bigg\\}\\nonumber\\\\ & & \\times\\sum_{\\{\\mathbf{s}_i(t)\\}}\\int\\!\\!\\{\\mathrm d \\mathbf{h}_i(t)\\;\\mathrm d \\mathbf{\\hat{h}}_i(t)\\}\\!\\!\\!\\int_{-\\pi}^{\\pi}\\!\\!\\!\\frac{\\mathrm d \\omega_i}{2\\pi } \\;\\overline{\\xi_i[\\{{\\mbox{\\boldmath$s$}}_i(t),\\mathbf{h}_i(t)\\}\\vert\\{\\mathbf{\\hat{h}}_i(t)\\ } , \\omega_i]}^{\\{a_{{\\textbf{i}}}^{i}\\}}\\nonumber\\\\ & & \\times{\\mathrm{e}}^{-{\\mathrm{i}}\\sum_{t\\!=\\!0}^{t_{max}\\!-\\!1}\\ ! \\mathbf{\\hat{h}}_{i}(t).\\theta(t)-{\\mathrm{i}}\\omega_i}\\nonumber\\\\ & = & \\frac{1}{n}\\sum_{i=1}^n\\prod_{j\\neq i}^{n}\\overline{\\delta\\left[1;\\!\\!\\sum_{{\\textbf{i}}^\\prime\\subseteq{[n ] } } a_{{\\textbf{i}}^\\prime}^{j}\\right]}^{\\{a_{{\\textbf{i}}}^{j}\\ } } \\overline{\\delta\\left[0;\\!\\!\\sum_{{\\textbf{i}}\\subseteq{[n ] } } a_{{\\textbf{i}}}^{i}\\right]}^{\\{a_{{\\textbf{i}}}^{i}\\ } } /z_a\\nonumber\\\\ & = & \\frac{1}{n}\\sum_{i=1}^n\\prod_{j\\neq i}^{n}\\sum_{\\{a_{{\\textbf{i}}}^{j}\\}}\\prod_{{\\textbf{i}}\\subseteq{[n]}}(1\\!-\\!\\frac{1}{n^k})\\exp\\left[a_{{\\textbf{i}}}^{j}\\log\\left(\\frac{1}{n^k}(1\\!-\\!\\frac{1}{n^k})^{-1}\\right)\\right]\\delta\\left[1;\\!\\!\\sum_{{\\textbf{i}}^\\prime\\subseteq{[n ] } } a_{{\\textbf{i}}^\\prime}^{j}\\right]\\nonumber\\\\ & & \\times\\sum_{\\{a_{{\\textbf{i}}}^{i}\\}}\\prod_{{\\textbf{i}}\\subseteq{[n]}}(1\\!-\\!\\frac{1}{n^k})\\exp\\left[a_{{\\textbf{i}}}^{i}\\log\\left(\\frac{1}{n^k}(1\\!-\\!\\frac{1}{n^k})^{-1}\\right)\\right]\\delta\\left[0;\\!\\!\\sum_{{\\textbf{i}}\\subseteq{[n ] } } a_{{\\textbf{i}}}^{i}\\right]/z_a\\nonumber\\\\   & = & \\frac{1}{z_a}\\left\\{(1\\!-\\!\\frac{1}{n^k})^{n^k-1}\\right\\}^{n-1}(1\\!-\\!\\frac{1}{n^k})^{n^k}\\approx\\frac{{\\mathrm{e}}^{-n}}{z_a}\\nonumber \\ ] ] since for @xmath3 the inverse of @xmath34 in ( [ eq : unity-1 ] ) grows as @xmath233 , we conclude that @xmath234_{\\vert_{\\alpha_i\\rightarrow\\theta}}}=1 $ ] .",
    "alternatively , the calculation in  ( [ eq : unity-1 ] ) can be carried out differently using results from the appendix  [ section : disorderaverage ] : @xmath232_{\\vert_{\\alpha_i\\rightarrow\\theta}}}\\label{eq : unity-2}\\\\ & = & \\frac{z_a^{-1}}{n}\\sum_{i=1}^n\\bigg\\{\\prod_{j\\neq i}^{n}\\sum_{\\{\\mathbf{s}_j(t)\\}}\\int\\{\\mathrm d \\mathbf{h}_j(t)\\;\\mathrm d \\mathbf{\\hat{h}}_j(t)\\}\\nonumber\\\\ & & \\times\\int_{-\\pi}^{\\pi}\\frac{\\mathrm d \\omega_j}{2\\pi } \\;\\overline{\\xi_j[\\{{\\mbox{\\boldmath$s$}}_j(t),\\mathbf{h}_j(t)\\}\\vert\\{\\mathbf{\\hat{h}}_j(t)\\ } , \\omega_i]}^{\\{a_{{\\textbf{i}}}^{j},\\alpha_j\\}}\\bigg\\}\\nonumber\\\\ & & \\times\\sum_{\\{\\mathbf{s}_i(t)\\}}\\int\\!\\!\\{\\mathrm d \\mathbf{h}_i(t)\\;\\mathrm d \\mathbf{\\hat{h}}_i(t)\\}\\!\\!\\!\\int_{-\\pi}^{\\pi}\\!\\!\\!\\frac{\\mathrm d \\omega_i}{2\\pi } \\;\\overline{\\xi_i[\\{{\\mbox{\\boldmath$s$}}_i(t),\\mathbf{h}_i(t)\\}\\vert\\{\\mathbf{\\hat{h}}_i(t)\\ } , \\omega_i]}^{\\{a_{{\\textbf{i}}}^{i},\\alpha_i\\}}\\nonumber\\\\ & & \\times{\\mathrm{e}}^{-{\\mathrm{i}}\\sum_{t\\!=\\!0}^{t_{max}\\!-\\!1}\\ ! \\mathbf{\\hat{h}}_{i}(t).\\theta(t)-{\\mathrm{i}}\\omega_i}\\nonumber\\\\ & = & \\frac{1}{n}\\sum_{i=1}^n\\frac{\\int\\{\\mathrm d p \\mathrm d\\hat{p}\\mathrm d\\omega \\mathrm d\\hat{\\omega}\\}\\;{\\mathrm{e}}^{n\\psi[\\{p,\\hat{p},\\omega,\\hat{\\omega}\\}]}}{\\int\\{\\mathrm d p^\\prime \\mathrm d\\hat{p}^\\prime\\mathrm d\\omega^\\prime \\mathrm",
    "d\\hat{\\omega}^\\prime\\}\\;{\\mathrm{e}}^{n\\psi[\\{p^\\prime,\\hat{p}^\\prime,\\omega^\\prime,\\hat{\\omega}^\\prime\\}]}}\\left\\langle { \\mathrm{e}}^{-{\\mathrm{i}}\\sum_{t\\!=\\!0}^{t_{max}\\!-\\!1}\\ ! \\mathbf{\\hat{h}}_{i}(t).\\theta(t)-{\\mathrm{i}}\\omega_i}\\right\\rangle_{m_i},\\nonumber \\ ] ] where in the above @xmath235-average is generated by the site - dependent version of  ( [ def : saddle - recurr ] ) .",
    "computing the integrals in  ( [ eq : unity-2 ] ) by the saddle - point method we find that @xmath234_{\\vert_{\\alpha_i\\rightarrow\\theta}}}=\\int\\{\\mathrm d\\mathbf{\\hat{h}}(t)\\}\\;\\mathrm d\\omega\\;\\omega(\\{\\mathbf{\\hat{h}}(t)\\},\\omega)\\;{\\mathrm{e}}^{-{\\mathrm{i}}\\sum_{t\\!=\\!0}^{t_{max}\\!-\\!1}\\ !",
    "\\mathbf{\\hat{h}}(t).\\theta(t)-{\\mathrm{i}}\\omega}$ ] , where the order - parameter function @xmath236 is defined in  ( [ eq : sp3-recurr ] ) , but according to the calculation in ( [ eq : unity-1 ] ) this also equals unity .",
    "thus , by using this result in the saddle - point equation  ( [ eq : sp2-recurr ] ) , we find that the equality @xmath237 holds ."
  ],
  "abstract_text": [
    "<S> the generating functional method is employed to investigate the synchronous dynamics of boolean networks , providing an exact result for the system dynamics via a set of macroscopic order parameters . </S>",
    "<S> the topology of the networks studied and its constituent boolean functions represent the system s quenched disorder and are sampled from a given distribution . </S>",
    "<S> the framework accommodates a variety of topologies and boolean function distributions and can be used to study both the noisy and noiseless regimes ; it enables one to calculate correlation functions at different times that are inaccessible via commonly used approximations . </S>",
    "<S> it is also used to determine conditions for the annealed approximation to be valid , explore phases of the system under different levels of noise and obtain results for models with strong memory effects , where existing approximations break down . </S>",
    "<S> links between bn and general boolean formulas are identified and common results to both system types are highlighted . </S>"
  ]
}