{
  "article_text": [
    "statistical inference is the task of computing marginals ( or expectation values ) of complex multi - variate distributions . _",
    "belief propagation _ ( bp ) is a generic method for accomplishing this task quickly but approximately , when the multivariate distribution factorizes according to a sparse graphical structure .",
    "the advent of sparse graph codes and iterative bp decoding @xcite has naturally made decoding become an important case of this general problem .",
    "the present paper builds on this connection by ` importing ' an algorithm that has been recently developed in the context of approximate counting and inference @xcite .",
    "we will refer to the new algorithm as _ tree pruning _ ( tp ) _",
    "decoding_. for a number of reasons the application of this method to decoding is non - trivial .",
    "however , it is an interesting approach for the three following reasons . @xmath0",
    "it provides a sequence of decoding schemes that interpolates continuously between bp and the optimal maximum a posteriori ( map ) decoding .",
    "@xmath1 at each level of this sequence , the effect of loops of increasing length is taken into account .",
    "@xmath2 we expect that an appropriate truncation of this sequence might yield a polynomial algorithm for map decoding on general graphs of bounded degree , for low enough noise levels .",
    "preliminary numerical results are encouraging .",
    "as for bp decoding , tp decoding aims at estimating the a posteriori marginal probabilities of the codeword bits .",
    "unhappily , the relation between bp estimates and the actual marginals is in general poorly understood . in the case of random low - density parity - check ( ldpc )",
    "codes and communication over memoryless channels , density evolution allows to show that , at small enough noise level , the bp bit error probability becomes arbitrarily small if the blocklength is large enough .",
    "this implies that the distance between bp estimates and the actual marginals vanishes as well .",
    "this result is not completely satisfactory , in that it relies in a crucial way on the locally tree - like structure of sparse random graphs .",
    "this property does not hold for structured graphs , and , even for large graphs , it kicks in only at very large blocklengths .",
    "in contrast to this , the algorithm considered in this paper accounts systematically for short loops .",
    "it should therefore produce better performances , in particular in the error floor regime since this is dominated by small error events @xcite .",
    "a convenient way of understanding the difference between bp and map decoding makes use of the so - called computation tree .",
    "consider a code described by a factor graph @xmath3 whereby @xmath4 represents the variable nodes , @xmath5 the factor nodes , and @xmath6 the edges .",
    "let @xmath7 , then the corresponding computation tree denoted by @xmath8 is the tree of non - reversing walks in @xmath9 that start at @xmath10 .",
    "this gives a graph ( tree ) structure in a natural way : two nodes are neighbors if one is reached from the other adding a step .",
    "bp uses the marginal at the root of @xmath8 as an estimate for the marginal distribution at @xmath10 on the original graph @xmath9 .",
    "if @xmath9 contains short loops in the neighborhood of @xmath10 , the computation tree differs from @xmath9 in a neighborhood of the root and , as a consequence , the bp estimate can differ vastly from the actual marginal .",
    "weitz @xcite made the surprising remark that there exists a simple way of pruning the computation tree ( and fixing some of its variables ) in such a way that the resulting root marginal coincides with the marginal on @xmath9 .",
    "unhappily the size of the pruned tree , which we call the _ self - avoiding walk tree _ and denote by @xmath11 , is exponential in the size of the original graph @xmath9 . nevertheless , the tree can be truncated thus yielding a convergent sequence of approximations for the marginal at @xmath10 .",
    "the complexity of the resulting algorithm is linear in the size of the truncated tree .",
    "its efficiency depends on how sensitive is the root marginal to the truncation depth .      applying this approach to decoding linear codes",
    "poses several challenges :    1 .",
    "weitz s construction is valid only for markov random fields ( mrfs ) with pairwise interactions and binary variables .",
    "the decoding problem does not fit this framework .",
    "2 .   the original justification for truncating the self - avoiding walk tree followed the so - called ` strong spatial mixing ' or ` uniqueness ' condition .",
    "this amounts to saying that the conditional marginal at the root given the variables at depth @xmath12 , depends weakly on the values of the latter .",
    "this is ( most of the times ) false in decoding . for a ` good ' code ,",
    "the value of bit @xmath10 in a codeword is completely determined by the values of bits outside a finite neighborhood around @xmath10 .",
    "3 .   even worse , we found in numerical simulations that the original truncation procedure performs poorly in decoding",
    ".    the self - avoiding walk tree construction has already motivated several applications and generalizations in the past few months .",
    "jung and shah @xcite discussed its relation with bp , and proposed a distributed implementation .",
    "mossel and sly @xcite used it to estimate mixing times of monte carlo markov chain algorithms . finally , and most relevant to the problems listed above , nair and tetali @xcite proposed a generalization to non - binary variables and multi - variable interactions .",
    "while this generalizations does in principle apply to decoding , its complexity grows polynomially in the tree size .",
    "this makes it somewhat unpractical in the present context .    in this paper",
    "we report progress on the three points above .",
    "specifically , in section [ sec : decodingtree ] we use duality to rephrase decoding in terms of a generalized binary markov random field .",
    "we then show how to generalize the self - avoiding walk tree construction to this context . in section [ sec :",
    "truncation ] we discuss the problems arising from the original truncation procedure , and describe two procedure that show better performances .",
    "numerical simulations are presented in section [ sec : simulations ] .",
    "finally , one of the most interesting perspectives is to use tp as a tool for analyzing bp and , in particular , comparing it with map decoding .",
    "some preliminary results in this direction are discussed in section [ sec : theoretical ] .",
    "we should stress that a good part of our simulations concerns the binary erasure channel ( bec ) . from a practical point of view , tp decoding is not an appealing algorithm in this case .",
    "in fact , map decoding can be implemented in polynomial time through , for instance , gaussian elimination .",
    "the erasure channel is nevertheless a good starting point for several reasons . @xmath0",
    "comparison with map decoding is accessible .",
    "@xmath1 we can find a particularly simple truncation scheme in the erasure case .",
    "@xmath2 some subtle numerical issues that exist for general channels disappear for the bec .",
    "throughout this paper we consider binary linear codes of blocklength @xmath13 used over a binary - input memoryless channel .",
    "let bm@xmath14 , where @xmath15 is a noise parameter , denote a generic channel .",
    "assume that @xmath16 is the output alphabet and let @xmath17 denote its transition probability .    with a slight abuse of terminology we shall identify a code with a particular parity - check matrix @xmath18 that represents it , @xmath19    therefore , the code is further identified with a tanner graph @xmath20",
    "whose adjacency matrix is the parity - check matrix @xmath18 .",
    "we will denote by @xmath21 the neighborhood of function ( check ) node @xmath22 , and write @xmath23 .",
    "analogously , @xmath24 indicates the neighborhood of the variable node @xmath10 . the conditional distribution for the channel output @xmath25 given the input @xmath26 factorizes according to the graph @xmath9 ( also called factor graph ) .",
    "it follows immediately from bayes rule that @xmath27 , where @xmath28 we denote by @xmath29 the marginal distribution at bit @xmath10 . _ symbol map decoding _ amounts to the following prescription , @xmath30 both bp and tp decoders have the same structure , whereby the marginal @xmath31 is replaced by its approximation , respectively @xmath32 or @xmath33 .",
    "we call a _ generalized markov random field _ ( gmrf ) over the finite alphabet @xmath34 a couple @xmath35 , where @xmath36 is an ordinary graph over vertex set @xmath37 , and edge set @xmath38 .",
    "further @xmath39 is a set of weights indexed by edges and vertices in @xmath40 , @xmath41 , @xmath42 .",
    "notice that , unlike for ordinary mrfs , the edge weights in generalized mrfs are required to be non - negative .    given a subset @xmath43 , the _ marginal _ of the gmrf @xmath44 on @xmath45 , is defined as the function @xmath46 , with entries @xmath47 when @xmath48 , we shall omit the subscript and call @xmath49 the _ weight _ of configuration @xmath26 . more generally , the _ expectation _ of a function @xmath50 can be defined as @xmath51 notice that @xmath52 is not ( and in general can not be ) normalized . in the sequel , whenever the relevant mrf has non - negative weights and is normalizable , we shall use words ` expectation ' and ` marginal ' in the usual ( normalized ) sense .",
    "duality can be used to reformulate decoding ( in particular , the posterior marginals @xmath53 ) in terms of a gmrf .",
    "more precisely , given a code with tanner graph @xmath54 , we define a gmrf on graph @xmath55 where @xmath56 and @xmath57 , proceeding as follows .",
    "we let @xmath58 and associate variables @xmath59 to @xmath7 and @xmath60 to @xmath61 .",
    "we then introduce the weights @xmath62 although next statement follows from general duality theory , it is convenient to spell it out explicitly .",
    "the marginals of the a posteriori distribution defined in eq .",
    "( [ eq : apdistr ] ) are proportional to the ones of the gmrf defined in eq .",
    "( [ eq : gmrfdec1 ] ) and eq .",
    "( [ eq : gmrfdec2 ] ) .",
    "more precisely , we get @xmath63 $ ] .",
    "it is immediate to prove a stronger result , namely that the distribution @xmath64 is proportional to @xmath65 , where @xmath66 is defined using eq .",
    "( [ eq : gmrfdec1 ] ) and eq .",
    "( [ eq : gmrfdec2 ] ) .",
    "we have @xmath67 which is proportional to the right - hand side of eq .",
    "( [ eq : apdistr ] ) .",
    "this result , which derives from @xcite and @xcite , motivates us to extend weitz s construction to gmrfs . ) ) , while processing all graph vertices in a similar way .",
    "] this is the object of the next section .",
    "assume we are given a graph @xmath55 and a node @xmath68 .",
    "we have already described the computation tree rooted at @xmath10 , which we denote by @xmath8 .",
    "an ` extended self - avoiding walk ' ( saw ) on a graph @xmath55 , starting at @xmath68 is a non - reversing walk that never visits twice the same vertex , except , possibly , for its end - point .",
    "the ` self - avoiding walk tree ' rooted at @xmath69 is the tree of all extended self - avoiding walks on @xmath40 starting at @xmath10 .",
    "it is straightforward to see that @xmath11 is in fact a finite sub - tree of @xmath8 .",
    "its size is bounded by @xmath70 , where @xmath71 is the maximum degree of @xmath40 , and @xmath72 the node number .",
    "( 200,100 ) ( 0,0).,title=\"fig : \" ]    ( 210,250 ) ( 0,0 ) for the tanner graph of figure",
    "[ fig : tanner ] , rooted at variable node @xmath73 . in this picture , each node of the self - avoiding tree is labeled by its projection onto @xmath37 . at `",
    "terminated ' nodes we marked the value that the variable is forced to take .",
    ", title=\"fig : \" ]    as an example , figure [ fig : sawtree ] shows a saw tree for the small graph @xmath40 depicted in figure [ fig : tanner ] .",
    "( in this case , @xmath40 is the tanner graph of a repetition code of length @xmath74 . )",
    "if we denote by @xmath75 the vertex set of @xmath11 , there exists a natural projection @xmath76 that preserves edges .",
    "formally , @xmath77 maps a self - avoiding walk to its end - point .",
    "notice that @xmath11 has two types of leaf nodes : @xmath0 nodes that are leaves in the original graph @xmath40 .",
    "@xmath1 nodes that are not leaves in @xmath40 but corresponds to extended",
    "self - avoiding walks that can not be further continued .",
    "the latter case arises when the endpoint of the self - avoiding walk has already been visited ( i.e. , when a loop is closed ) .",
    "we shall refer to nodes of the second type as _ terminated _ nodes .",
    "indeed , the self - avoiding walk tree @xmath11 can be obtained from @xmath8 by the following _ termination _ procedure .",
    "imagine descending @xmath8 along one of its branches .",
    "when the same projection is encountered for the second time , terminate the branch .",
    "formally , this means eliminating all the descendants of @xmath78 whenever @xmath79 for some ancestor @xmath80 of @xmath78 .    given a gmrf @xmath35 , we can define a gmrf on @xmath11 in the usual way .",
    "namely , to any edge @xmath81 , we associate a weight coinciding with the one of the corresponding edge in @xmath40 : @xmath82 . the analogous definition is repeated for any non - terminated node : @xmath83 .",
    "finally , the choice of weight on terminated nodes makes use of the hypothesis that @xmath84 .",
    "assume that the edges of @xmath40 are labeled using a given order , e.g. , a lexicographic order .",
    "let @xmath78 be a terminated node with @xmath85 .",
    "then the self - avoiding walk corresponding to @xmath78 contains a loop that starts and ends at @xmath86 .",
    "we let @xmath87 ( respectively , @xmath88 ) if this loop quits @xmath86 along an edge of higher ( respectively , lower ) order than the one along which it enters @xmath86 .",
    "the relevance of this construction is due to weitz who considered the case of _ permissive _ binary mrfs . by this",
    "we mean that @xmath89 , @xmath90 , and , for any @xmath91 , there exists @xmath92 , such that @xmath93 for any @xmath94 with @xmath95 and @xmath96 .",
    "( the latter is referred to as the ` permissivity ' condition . )",
    "[ propo : weitz ] given a binary mrf @xmath35 , the marginal of @xmath97 with respect to @xmath35 is proportional to the root marginal on @xmath11 .",
    "the problem with non - permissive mrfs and , _ a fortiori _ , with generalized mrfs , is that the tree model @xmath11 may not admit any assignment of the variables such that all the weights @xmath98 , @xmath99 are non - negative . as a consequence",
    "the mrf on @xmath11 does not define a probability distribution and this invalidates the derivation in @xcite or @xcite .",
    "even worse , the procedure used in these papers was based in keeping track of ratios among marginals , of the form @xmath100 .",
    "when the mrf does not define a distribution , ill - defined ratios such as @xmath101 can appear .",
    "let us stress that this problem is largely due to the ` termination ' procedure described above .",
    "this in fact constrains the set of assignments with non - vanishing weight to be compatible with the values assigned at terminated nodes .    in order to apply the self - avoiding walk construction to gmrfs",
    ", we need to modify it in the two following ways .",
    "@xmath0 we add further structure to @xmath11 . for any @xmath102 , let @xmath103 be the set of its _ children _",
    "( i.e. , the set of extended self - avoiding walks that are obtained by adding one step to @xmath78 ) .",
    "then we partition @xmath104 as follows .",
    "let @xmath105 be two children of @xmath78 , and write them as @xmath106 , @xmath107 .",
    "further , let @xmath108 .",
    "then we write @xmath109 if there exists an extended self - avoiding walk of the form @xmath110 . here",
    "we are regarding @xmath78 , @xmath111 as walks on @xmath40 ( i.e. , sequences of vertices ) and we use @xmath112 to denote the concatenation of walks .",
    "it is not difficult to verify that @xmath113 is an equivalence relation .",
    "the partition @xmath114 is defined to be the partition in equivalence classes under this relation .",
    "@xmath1 we define the _ generalized root marginal _ of @xmath11 through a recursive procedure that makes it always well - defined .",
    "first notice that , if @xmath40 is a tree rooted at @xmath10 , then the marginal at @xmath10 can be computed by a standard message passing ( dynamic programming ) procedure , starting from the leaves and moving up to the root .",
    "the update rules are , for @xmath115 , @xmath116 where edges are understood to be directed towards the root . the marginal at the root",
    "is obtained by evaluating the right hand side of eq .",
    "( [ eq : upnodes ] ) with @xmath117 .",
    "the generalized root marginal is defined by the same procedure but changing eq .",
    "( [ eq : upnodes ] ) as follows .",
    "given the partition @xmath104 described above , we let @xmath118 where we define @xmath119 through a _ concatenation _",
    "let @xmath120 be the set of messages @xmath121 ordered according to the order of edges @xmath122 in @xmath40 .",
    "then we let @xmath123 the reason for calling this a ` concatenation ' follows from the remark that , with the notations above , we have @xmath124 , @xmath125 , etc .",
    "we refer to the discussion ( and proof ) below for a justification of this claim . as a consequence , the procedure in eq .",
    "( [ eq : concatenation ] ) can be described as follows : write the components of @xmath126 in sequence , and eliminate repeated entries . with this groundwork",
    ", we obtain the following generalization of weitz s result .",
    "[ propo : gmrf ] given a gmrf @xmath35 , the marginal at @xmath68 with respect to @xmath35 is equal to the generalized root marginal on @xmath11 .",
    "the proof is very similar to weitz s original proof in @xcite ; the difference is that special care must be paid to avoid ill - defined expressions .",
    "the argument consists in progressively simplifying the graph @xmath40 ( rooted at @xmath10 ) until @xmath11 is obtained .",
    "we shall represent these simplifications graphically .",
    "consider the first step , corresponding to eq .",
    "( [ eq : upnodes1 ] ) , with @xmath117 . the partition of @xmath103 in @xmath127 , @xmath128 , corresponds to a partition of of the subgraph @xmath129 ( obtained by eliminating from @xmath40 , @xmath10 as well as its adjacent vertices ) into connected components .",
    "this correspondence is depicted below ( whereby gray blobs correspond to connected sub - graphs ) .",
    "( -195,55)@xmath78 ( -95,55)@xmath130 ( -63,55)@xmath131    after factoring out the term @xmath132 , the definition of marginal in eq .",
    "( [ eq : margdef ] ) factorizes naturally on such components , leading to eq .",
    "( [ eq : upnodes1 ] )    consider now one of such components , call it @xmath133 , such as the one depicted below .",
    "the corresponding generalized root marginal is computed using the concatenation rule , specified in eq .",
    "( [ eq : concatenation ] ) .",
    "( -225,55)@xmath78 ( -165,55)@xmath134 ( -130,55)@xmath135 ( -65,53)@xmath134 ( -42,53)@xmath135 ( -67,0)@xmath136 ( -50,0)@xmath137    in order to derive this rule , first consider the graph @xmath138 obtained from @xmath133 by replacing its root @xmath78 by @xmath139 copies @xmath140 , each of degree @xmath141 ( here @xmath142 denotes the degree of vertex @xmath80 ) .",
    "each of the newly introduced vertices is adjacent to one of the edges incident on the root in @xmath133 .",
    "further @xmath140 are labeled according to the ordering ( chosen at the beginning of the reduction procedure ) on the adjacent edges .",
    "these @xmath143 nodes will be referred to as ` split nodes ' in the sequel .    from the definition of marginal in eq .",
    "( [ eq : margdef ] ) , and using the notation @xmath144 for the gmrf on @xmath145 , we have @xmath146 for @xmath147 .",
    "this identity is represented as the first equality in the figure above .",
    "next we replace the graph @xmath145 by @xmath143 copies of it , @xmath148 . with a slight abuse of notation",
    ", we re - name @xmath134 the first of the @xmath143 ` split nodes ' in @xmath149 , @xmath135 the second in @xmath150 , and so on .",
    "further we add node weights to the other ` split nodes , ' ( i.e. , the ones that remained un - named ) , either of the form @xmath151 ( forcing @xmath152 to take value @xmath136 ) or of the form @xmath153 ( forcing @xmath152 to take value @xmath137 ) .",
    "more precisely , for any @xmath154 on @xmath155 we force to @xmath136 those split nodes that come before @xmath156 , and to @xmath137 the ones that come after .    as a consequence ,",
    "if we use @xmath157 for the gmrf @xmath158 , we have @xmath159 in particular , for any @xmath160 , @xmath161 . as a consequence of this fact and of eq .",
    "( [ eq : splitting ] ) , we get @xmath162 this proves eq .",
    "( [ eq : concatenation ] ) with @xmath163 ( second equality in the last figure above ) .",
    "finally , eq .  ( [ eq : upedges ] ) follows by considering the marginal of a node of degree @xmath141 , as @xmath140 in graphs @xmath149 , @xmath164 , and expressing it in terms of the marginal of its only neighbor .",
    "this completes one full step of the procedure that breaks the loops through node @xmath10 . by recursively",
    "repeating the same steps , the graph is completely unfolded giving rise to @xmath11 .",
    "the self - avoiding walk tree @xmath11 appears as a convenient way to organize the calculation of the marginal at @xmath10 in the general case . in the case of permissive mrfs",
    "this calculation coincides with a standard marginal calculation on the tree @xmath11 .",
    "it is instructive to check this explicitly .",
    "proposition [ propo : weitz ] is a special case of proposition [ propo : gmrf ] for permissive mrfs .",
    "first notice that , for permissive mrfs , the self - avoiding walk tree construction yields a mrf on @xmath11 that defines a probability distribution ( non - negative and normalizable ) , whose marginals will be denoted as @xmath165 as well .",
    "we have to prove that , in this case , the generalized root marginal is proportional to the ordinary marginal at the root of @xmath11 .",
    "the crucial remark is that , because of permissivity , the messages are non - negative and , in particular , @xmath166 and @xmath167 .    assume , without loss of generality , that @xmath168 .",
    "we define the likelihood ratios on the @xmath11 tree @xmath169 , @xmath170 and @xmath171 .",
    "the ratio @xmath172 is defined analogously in terms of @xmath173 . equation ( [ eq : upedges ] ) then implies @xmath174 eq .",
    "( [ eq : upnodes1 ] ) yields on the other hand @xmath175 finally , using the remark that @xmath176 for @xmath177 , we get from eq .",
    "( [ eq : concatenation ] ) @xmath178 putting the last two equations together @xmath179 it is now easy to check that , eq .",
    "( [ eq : rationodes ] ) and eq .",
    "( [ eq : ratioedges ] ) coincide with the appropriate recursive definition of probability marginal ratios on @xmath11 .    proposition [ propo : gmrf ] does not yield an efficient way of computing marginals of gmrf .",
    "the conundrum is that the resulting complexity is linear in the size of @xmath11 which is in turn exponential in the size of the original graph @xmath40 . on the other hand ,",
    "it provides a systematic way to define and study algorithms for computing efficiently such a marginal .",
    "the idea , proposed first in @xcite , is to deform @xmath11 in such a way that its generalized root marginal does not change too much , but computing it is much easier .",
    "bp can be seen as an example of the approach mentioned at the end of the previous section . in this case",
    "@xmath11 is replaced by the first @xmath12 generations of the computation tree , to be denoted by @xmath180 . in this case",
    "the complexity of evaluating the generalized root marginal scales as @xmath12 rather than as @xmath181 .",
    "a different idea is to cut some of the branches of @xmath11 in such a way to reduce drastically its size .",
    "we will call _ truncation _ the procedure of cutting branches of @xmath11 .",
    "it is important to keep in mind that truncation is different from the _ termination _ of branches when a loop is closed in @xmath40 . while termination is completely defined , we are free to define truncation to get as good an algorithm as we want . in the following",
    "we shall define truncation schemes parametrized by an integer @xmath12 , and denoted as @xmath182 .",
    "we will have @xmath183 for @xmath184 , thus recovering the exact marginal by proposition [ propo : gmrf ] .    in order for the algorithm to be efficient",
    ", we need to ensure the following constraints .",
    "@xmath182 is ` small enough ' ( as the complexity of computing its generalized root marginal is at most linear in its size ) .",
    "@xmath1 @xmath182 is ` easy to construct . ' for coding applications , this second constraint is somewhat less restrictive because the tree(s ) @xmath182 can be constructed in a preprocessing stage and not recomputed at each use of the code .    in order to achieve the second goal",
    ", we must define the partition @xmath185 of children of @xmath78 according to the subtree @xmath182 used in the computation .",
    "consider two children of @xmath78 , which we denote by @xmath105 . in a similar way as for the @xmath186 in the complete tree case",
    ", we write them as @xmath106 , @xmath107 , and define @xmath187 if there exists a descendant @xmath188 of @xmath189 in @xmath182 such that @xmath190 or a descendant @xmath191 of @xmath192 such that @xmath193 . the construction of the partition @xmath194 will be different whether communication takes place over erasure or general channels .      the truncation procedure proposed in @xcite",
    "amounts to truncating all branches of @xmath11 at the same depth @xmath12 , unless they are already terminated at smaller depth .",
    "variables at depth @xmath12 ( boundary ) are forced to take arbitrary values .",
    "the rationale for this scheme comes from the ` strong spatial mixing ' property that holds for the system studied in @xcite .",
    "namely , if we denote by @xmath195 the normalized marginal distribution at the root @xmath10 given variable assignment at depth @xmath12 , we have @xmath196 uniformly in the boundary conditions @xmath197 , @xmath198 for some constants @xmath199 , @xmath200 .",
    "it is easy to realize that the condition in eq .",
    "( [ eq : ssm ] ) generically does not hold for ` good ' sparse graph codes .",
    "the reason is that fixing the codeword values at the boundary of a large tree , normally determines their values inside the same tree . in other words",
    "the tp estimates strongly depend on this boundary condition .",
    "one can still hope that some simple boundary condition might yield empirically good estimates .",
    "an appealing choice is to leave ` free ' the nodes at which the tree is truncated .",
    "this means that no node potential is added on these boundary vertices .",
    "we performed numerical simulations with this scheme on the same examples considered in the next section .",
    "the results are rather poor : unless the truncation level @xmath12 is very large ( which is feasible only for small codes in practice ) the bit error rate is typically worse than under bp decoding .      for decoding over the bec ,",
    "a simple trick improves remarkably the performances of tp decoding .",
    "first , construct a subtree of @xmath11 of depth at most @xmath12 by truncating at the deepest variable nodes whose depth does not exceed @xmath12 .",
    "the partition @xmath194 is constructed using the equivalence class of the transitive closure of @xmath201 .",
    "then run ordinary bp on this graph , upwards from the leaves towards the root , and determine all messages in this direction .",
    "if a node @xmath78 is decoded in this way , fix it to the corresponding value and further truncate the tree @xmath11 at this node .",
    "the resulting tree @xmath202 is not larger than the one resulting from fixed - depth truncation . for low erasure probabilities",
    "it is in fact much smaller than the latter .",
    "the above trick can not be applied to general bm channels .",
    "we therefore resort to the following two constructions .",
    "@xmath0 construction @xmath203 : define the distance @xmath204 between two variable nodes @xmath10 , @xmath86 to be the number of check nodes encountered along the shortest path from @xmath10 to @xmath86 .",
    "let @xmath205 be the subgraph induced of variable nodes is the one including all those check nodes that only involve variables in @xmath206 .",
    "] by variable nodes whose distance from @xmath10 is at most @xmath12",
    ". then we let @xmath207 be the _ complete _ self - avoiding walk tree for the subgraph @xmath205 .",
    "this corresponds to truncating @xmath11 as soon as the corresponding self - avoiding walk exits @xmath205 .",
    "no forcing self - potential is added on the boundary .",
    "a nice property of this scheme is that it returns the _ a posteriori _ estimate of transmitted bit @xmath208 given the channel outputs within @xmath205 , call it @xmath209 . as a consequence , many reasonable performance measures ( bit error probability , conditional entropy , etc . )",
    "are monotone in @xmath12 @xcite .    on the negative side",
    ", the size of the tree @xmath203 grows very rapidly ( doubly exponentially ) with @xmath12 at small @xmath12 .",
    "this prevented us from using @xmath210 .",
    "@xmath1 construction @xmath211 : the tree @xmath203 constructed as in the previous approach is augmented by adding some descendants to those nodes that are terminated in @xmath203 . more precisely , below any such node @xmath78 in the mentioned tree , we add the first @xmath212 generations of the computation tree .",
    "@xmath2 construction @xmath202 : we can implement a finer scheme for the general bm case .",
    "this scheme operates on @xmath202 obtained by truncating all branches of @xmath11 at the same depth @xmath12 .",
    "the description of this method is slightly lengthy .",
    "we omit the details here and choose to present the numerical results in fig .",
    "[ fig : exitcurvesconvc50bawgn ] of section [ sec : simulations ] .",
    "for communication over the bec , the implementation of tp decoding as described in section [ sec : erasuretruncation ] is satisfying .",
    "while it is simple enough for practical purpose , it permits us to depict performance curves that interpolate successfully between bp and map decoding .",
    "the binary erasure channel , which we denote by bec@xmath213 if the erasure probability is @xmath214 , is appealing for a first study for the following reasons .",
    "@xmath0 the accessibility of performance curves under map decoding allows for a careful study of the new algorithm . @xmath1",
    "the tp decoder turns out to be ` robust ' with respect to changes in the truncation method , hence simpler to study .    as an example for a generic bm channel",
    ", we shall consider the binary - input additive white gaussian noise channel with standard deviation @xmath215 , which we denote by bawgn(@xmath216 ) .",
    "let us stress that the tp decoder is not ( in general ) symmetric with respect to codewords .",
    "this complicates a little the analysis ( and simulations ) which has to be performed for uniformly random transmitted codewords .",
    "the erasure case is illustrated by three examples : a tail - biting convolutional code , the @xmath217 golay code and a sparse graph code . here",
    "the comparison is done with bp after convergence ( ` infinite ' number of iterations ) and map as implemented through gaussian elimination .",
    "tp decoder permits us to plot a sequence of performance curves , indexed by the truncation parameter @xmath12 . in all of the cases considered ,",
    "tp improves over bp already at small values of @xmath12 . as @xmath12 increases ,",
    "tp eventually comes very close to map .",
    "the gain is particularly clear in codes with many short loops , and at low noise .",
    "this confirms the expectation that , when truncated , tp effectively takes care of small ` pseudocodewords . '",
    "the first example is a memory two and rate @xmath218 convolutional code in tailbiting form with blocklength @xmath219 .",
    "the performance curves are shown in fig .",
    "[ fig : ccm2_100 ] . the tp and",
    "bp decoders are based on a periodic tanner graph associated with the tailbiting code with generator pair @xmath220 . more precisely , they are based on the graph representing the parity - check matrix with circulant horizontal pattern @xmath221 .",
    "( 260,200 ) ( 0,0 )    ( 10,10 ) and blocklength @xmath219 .",
    "black curve : bp decoding with @xmath222 .",
    "red curve : map decoding ( bp and gaussian elimination ) .",
    "blue curves : bp decoding with @xmath223 ( almost indistinguishable ) .",
    "red curves : tp decoding with @xmath223 ( truncated tree ) . , title=\"fig : \" ]    ( 12,0)(24,0)[cb]@xmath224,@xmath225,@xmath226,@xmath227,@xmath228,@xmath229,@xmath230,@xmath231,@xmath232,@xmath233,@xmath234 ( 8,12)(0,23)[rc]@xmath235,@xmath236,@xmath237,@xmath238,@xmath239,@xmath240,@xmath241,@xmath242 ( 260,12)(0,0)[l]@xmath15 ( 8,185)(0,0)[l]@xmath243}\\prob\\{\\hat{x}^{{{\\ensuremath{\\text{\\tiny tp}}}}/{{\\ensuremath{\\text{\\tiny bp}}}}/{{\\ensuremath{\\text{\\tiny map}}}}}_i(y_{[n]})\\neq x_i\\}$ ]    ( 89,125 ) ( 37,85 )    the second example is the standard ( perfect ) golay code with blocklength @xmath244 . it is shown in fig .  [",
    "fig : cgolay_23 ] .",
    "( 260,200 ) ( 0,0 )    ( 10,10 ) golay code with blocklength @xmath245 .",
    "blue curve : bp decoding with @xmath222 .",
    "black curve : map decoding ( bp and gaussian elimination ) .",
    "blue curves : bp decoding with @xmath246 .",
    "red curves : tp decoding with @xmath246 ( truncated tree ) . , title=\"fig : \" ]    ( 12,0)(24,0)[cb]@xmath224,@xmath225,@xmath226,@xmath227,@xmath228,@xmath229,@xmath230,@xmath231,@xmath232,@xmath233,@xmath234 ( 8,12)(0,23)[rc]@xmath235,@xmath236,@xmath237,@xmath238,@xmath239,@xmath240,@xmath241,@xmath242 ( 260,12)(0,0)[l]@xmath15 ( 8,185)(0,0)[l]@xmath243}\\prob\\{\\hat{x}^{{{\\ensuremath{\\text{\\tiny tp}}}}/{{\\ensuremath{\\text{\\tiny bp}}}}/{{\\ensuremath{\\text{\\tiny map}}}}}_i(y_{[n]})\\neq x_i\\}$ ]    the third example , an ldpc code with blocklength @xmath247 , is depicted in fig .  [",
    "fig : creg36_50 ] .",
    "( 260,200 ) ( 0,0 )    ( 10,10 ) ldpc code with blocklength @xmath248 .",
    "blue curve : bp decoding with @xmath222 .",
    "black curve : map decoding ( bp and gaussian elimination ) .",
    "blue curves : bp decoding with @xmath249 .",
    "red curves : tp decoding with @xmath249 ( truncated tree ) . , title=\"fig : \" ]    ( 12,0)(24,0)[cb]@xmath224,@xmath225,@xmath226,@xmath227,@xmath228,@xmath229,@xmath230,@xmath231,@xmath232,@xmath233,@xmath234 ( 8,12)(0,23)[rc]@xmath235,@xmath236,@xmath237,@xmath238,@xmath239,@xmath240,@xmath241,@xmath242 ( 260,12)(0,0)[l]@xmath15 ( 8,185)(0,0)[l]@xmath243}\\prob\\{\\hat{x}^{{{\\ensuremath{\\text{\\tiny tp}}}}/{{\\ensuremath{\\text{\\tiny bp}}}}/{{\\ensuremath{\\text{\\tiny map}}}}}_i(y_{[n]})\\neq x_i\\}$ ]      in the case of the bawgn channel , we consider a single example of code , the tail - biting convolutional code used above , and two truncation schemes , the constructions @xmath1 and @xmath2 described in section [ sec : truncationgeneral ] .    our results are shown in fig .  [",
    "fig : ccm2_50_bawgn ] and fig .",
    "[ fig : exitcurvesconvc50bawgn ] . the tp and bp decoders are based on the natural periodic tanner graph associated with the tailbiting code .",
    "we run bp a large number of iterations and check the error probability to be roughly independent of the iterations number .",
    "the map decoder is performed using bp on the single - cycle tailbiting trellis ( i.e. , bcjr on a ring @xcite ) .",
    "we observe that the two schemes @xmath211 and @xmath202 with @xmath250 outperform bp .",
    "unhappily , due to complexity constraints we were limited to small values of @xmath12 and therefore could not approach the actual map performances .",
    "( 260,200 ) ( 0,0 )    ( 10,10 ) and blocklength @xmath248 .",
    "dashed black curve : bp decoding with @xmath251 .",
    "black curve : map decoding ( wrap - around bcjr ) .",
    "blue curves : bp decoding with @xmath252 .",
    "red curves : tp decoding with @xmath250 ( truncated tree , denoted by tp(@xmath253 ) , tp decoding on a ball of radius 2 ( scheme @xmath1 with no bp processing , denoted by @xmath254 ) and , tp decoding according to scheme @xmath1 ( with parameters as indicated by @xmath255 ) . , title=\"fig : \" ]    ( 10,0)(40,0)[cb]@xmath256,@xmath257,@xmath258,@xmath259,@xmath260,@xmath261,@xmath262 ( 8,12)(0,54)[rc]@xmath239,@xmath240,@xmath241,@xmath242 ( 260,12)(0,0)[l]@xmath263 ( 258,-4)(0,0)[l](db ) ( 8,185)(0,0)[l]@xmath243}\\prob\\{\\hat{x}^{{{\\ensuremath{\\text{\\tiny tp}}}}/{{\\ensuremath{\\text{\\tiny bp}}}}/{{\\ensuremath{\\text{\\tiny map}}}}}_i(y_{[n]})\\neq x_i\\}$ ] ( 120,92 ) ( 210,117 ) ( 200,89 ) ( 170,82 )    ( 260,200 ) ( 0,0 ) ( 10,10 ) and blocklength @xmath248 .",
    "blue curve : bp decoding with @xmath251 .",
    "black curve : map decoding ( wrap - around bcjr ) .",
    "red curve : tp decoding according to scheme @xmath2 ( with parameter as indicated by @xmath264 using a suitable truncated tree ) .",
    ", title=\"fig : \" ] ( 11,0)(22,0)[cb]@xmath265,@xmath256,@xmath257,@xmath266,@xmath141,@xmath267,@xmath74,@xmath268,@xmath269,@xmath270,@xmath271,@xmath272 ( 8,12)(0,20)[rc]@xmath273,@xmath235,@xmath236,@xmath237,@xmath238,@xmath239,@xmath240,@xmath241,@xmath242 ( 260,12)(0,0)[l]@xmath263 ( 258,-4)(0,0)[l](db ) ( 8,185)(0,0)[l]@xmath243}\\prob\\{\\hat{x}^{{{{\\ensuremath{\\text{\\tiny tp}}}}}/{{{\\ensuremath{\\text{\\tiny bp}}}}}/{{\\ensuremath{\\text{\\tiny map}}}}}_i(y_{[n]})\\neq x_i\\}$ ] ( 190,114 ) ( 180,104 ) ( 170,94 )",
    "one interesting direction is to use the self - avoiding walk tree construction for analysis purposes .",
    "we think in particular of two types of developments : @xmath0 a better understanding of the relation between bp and map decoding , and @xmath1 a study of the ` inherent hardness ' of decoding sparse graph codes .    while the first point is self - explanatory , it might be useful to spend a few words on the second .",
    "the most important outcome of the theory of iterative coding systems can be phrased as follows .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ there exist families of graphs ( expanders @xcite , random @xcite ) with diverging size and bounded degree , below a certain noise level , map decoding can be achieved in linear time up to a ` small error . ' _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    we think ( a formal version of ) the same statement to be true for _ any family of graphs _ with bounded degree . this can be proved for the erasure channel .",
    "let @xmath274 be a family of tanner graphs of diverging blocklength @xmath13 , with maximum variable degree @xmath275 and check degree @xmath276 .",
    "consider communication over bec@xmath14 with @xmath277 .",
    "then , for any @xmath278 there exists a decoder whose complexity is of order @xmath279 and returning estimates @xmath280 such that @xmath281 .",
    "the decoder consists in returning the map estimate of @xmath10 given the subgraph @xmath205 and the values received therein . consider the subgraph @xmath282 of @xmath283 obtained by removing non - erased bits .",
    "the proof consists in an elementary percolation estimate on this graph , see @xcite .",
    "it is easy to see that @xmath284 is upper bounded by the probability that the connected component of @xmath282 that contains @xmath10 is not - contained in @xmath205 .",
    "this is in turn upper bounded by the number of paths between @xmath10 and a vertex at distance @xmath285 ( which is at most @xmath286 ) times the probability that one such path is completely erased ( which is @xmath287 ) .",
    "therefore , for @xmath288 and @xmath289 , we get @xmath290 the proof is completed by taking @xmath291 , and noticing that @xmath205 can be decoded in time polynomial in its size , that is polynomial in @xmath292 .",
    "the computation is repeated for each @xmath293 whence the factor @xmath13 .",
    "we think that a strengthening ( better dependence on the precision @xmath294 ) and generalization ( to other channel models ) of this result can be obtained using the self - avoiding walk tree construction .",
    "yi lu is supported by the cisco stanford graduate fellowship .",
    "cyril masson is supported by the swiss national fund postdoctoral fellowship ."
  ],
  "abstract_text": [
    "<S> ` tree pruning ' ( tp ) is an algorithm for probabilistic inference on binary markov random fields . </S>",
    "<S> it has been recently derived by dror weitz and used to construct the first fully polynomial approximation scheme for counting independent sets up to the ` tree uniqueness threshold . ' </S>",
    "<S> it can be regarded as a clever method for pruning the belief propagation computation tree , in such a way to exactly account for the effect of loops .    in this paper </S>",
    "<S> we generalize the original algorithm to make it suitable for decoding linear codes , and discuss various schemes for pruning the computation tree . </S>",
    "<S> further , we present the outcomes of numerical simulations on several linear codes , showing that tree pruning allows to interpolate continuously between belief propagation and maximum a posteriori decoding . finally , we discuss theoretical implications of the new method . </S>"
  ]
}