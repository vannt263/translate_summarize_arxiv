{
  "article_text": [
    "while this publication contains a complete proof of all the claims relevant for quantum tomography , the reader is invited to consult the more general and explicit presentation in ref .",
    "@xcite ( and soon @xcite ) .",
    "below , we provide those details of the proof of theorem  1 , which were left out in the main text .",
    "we introduce some more formal notations used in the argument .",
    "denote the trace inner product between two hermitian operators @xmath158 by @xmath159 .",
    "we assume that @xmath160 are independent , identically distributed matrix - valued random variables , with @xmath161 drawn from the @xmath3 pauli matrices with uniform probability .",
    "thus , we model the selection of the observables as a process of sampling _ with _ replacement .",
    "it is both very plausible and easily provable @xcite that drawing the observables _ without _ replacement can only yield better results .",
    "an essential tool for the proof is a non - commutative large - deviation bound from @xcite .",
    "let @xmath162 be a sum of i.i.d.matrix-valued random variables ( r.v.s ) @xmath163 .",
    "then it is shown in @xcite that for every @xmath164 we have @xmath165 \\leq 2d e^{-\\lambda t } \\bigl\\|\\ee[e^{\\lambda x}]\\bigr\\|^m.\\ ] ] it is simple to derive a bernstein - type inequality from ( [ se ] ) .",
    "indeed , assume that @xmath36 is some operator - valued random variable with which is bounded in the sense that @xmath166 with probability one and which has zero mean @xmath167=0 $ ] .",
    "recall the standard estimate @xmath168 valid for real numbers @xmath169 $ ] ( actually a bit beyond ) . from the upper bound , we get @xmath170 . from the lower bound : @xmath171       \\leq \\id + \\ee[y^2 ]      \\leq \\exp(\\ee[y^2 ] ) \\nonumber \\\\      & \\rightarrow &      \\|\\ee[e^y]\\| \\leq \\|\\exp(\\ee[y^2])\\|=\\exp(\\|\\ee[y^2]\\| ) .",
    "\\label{eqn : ysquared}\\end{aligned}\\ ] ] in order to apply ( [ eqn : ysquared ] ) to ( [ se ] ) , we set @xmath172 .",
    "the parameter @xmath157 is chosen to be @xmath173 , where @xmath174\\|$ ] .",
    "a straight - forward calculation now gives @xmath175      & \\leq &      2 d \\ , e^{-t^2/4 m \\sigma^2},\\end{aligned}\\ ] ] ( valid for @xmath176 ) .        to this end , let @xmath178 be the super - operator defined by @xmath179 we will employ eq .",
    "( [ eqn : bernstein ] ) on the r.v.s  @xmath180)$ ] , where @xmath181=\\frac1 m \\id_t$ ] . from the fact that @xmath182 is operator convex",
    ", one has @xmath183\\| \\leq \\|\\ee[y^2]\\|$ ] . to estimate the latter quantity , we bound ( using hlder s inequality ( c.f .",
    "[ bhatia , _ matrix analysis _ ] ) ) @xmath184 and hence @xmath185        & = & \\frac{n^2}{m }      \\ee\\big[(w_{a},\\p_tw_{a})\\,y\\big ]    \\\\      & \\leq & \\frac{d^2}{m } \\frac{2r}{d }       \\ee\\big[y\\big ] = \\frac{2d r}{m^2}\\,\\p_t . \\ ] ] which implies @xmath186 .",
    "the claimed eq .",
    "( [ eqn : devnormepaps ] ) directly follows by plugging this estimate of @xmath122 into the non - commutative large - deviation bound ( [ eqn : bernstein ] ) .        recall the scalar sign function @xmath191 which maps positive numbers to @xmath192 , @xmath193 to @xmath193 and negative numbers to @xmath194 .",
    "if @xmath135 is any hermitian matrix , then @xmath195 is the matrix resulting from applying the @xmath191-function to the eigenvalues of @xmath135 .",
    "note that @xmath196 and recall hlder s inequality @xcite @xmath197 for any two hermitian @xmath198 .",
    "letting @xmath199 we compute : @xmath200 ( use the `` pinching inequality '' @xcite in the first step ; ( [ eqn : trsign ] ) , ( [ eqn : holder ] ) in the second .",
    "the third step is ( [ eqn : trsign ] ) and using that @xmath189 and @xmath201 implies @xmath202 .",
    "the last estimate uses ( [ eqn : dualepaps ] ) and , once more , ( [ eqn : holder ] ) ) .      the deviation bound before eq .",
    "( 5 ) of the main text follows again from ( [ eqn : bernstein ] ) .",
    "let @xmath203 be an arbitrary matrix in @xmath44 .",
    "with @xmath204 : @xmath205 having used that @xmath206 and that the @xmath207 form an orthonormal basis . thus",
    "@xmath208 < 2d e^{-t^2 \\kappa r/4}.\\ ] ] in the proof , we use ( [ eqn : golfingepaps ] ) for @xmath209 . hence the probability of failure becomes @xmath210      in this subsection we need to assume that the paulis are sampled _ without _ replacement .",
    "all previous bounds continue to hold  see remark above .",
    "let @xmath211 be the projection operator onto @xmath212 , normalized so that @xmath213 .",
    "define @xmath214 , and note that @xmath215 .",
    "the optimization program ( 6 ) of the main text becomes @xmath216 , s.t . @xmath217 .",
    "let @xmath218 .",
    "we upper - bound @xmath219 as follows .",
    "first , @xmath220 for any feasible @xmath135 , the first term is bounded by @xmath221 , while the second term is bounded by @xmath222 . for the third term , note that for the fixed matrix @xmath223 , @xmath224 = \\gamma{\\lvert \\rho_t-\\rho \\rvert}_2 ^ 2 $ ] , so by markov s inequality , @xmath225 , with probability at least @xmath226 @xcite .",
    "thus we have @xmath227 ( where we defined @xmath228 ) .    on the other hand , we can also lower - bound @xmath219 as follows : @xmath229 . for the second term , we have @xmath230 ( we can not use markov s inequality , because here we require a bound that holds simultaneously for all @xmath41 ) .",
    "for the first term , recall from the noise - free case that @xmath231 satisfies @xmath232 with high probability , and hence we have @xmath233 .",
    "so we have @xmath234 combining the above two inequalities and rearranging , we get @xmath235    we now show that @xmath236 implies that @xmath41 must be small . with the estimate ( [ eqn : noisefeasible ] ) at our disposal , we re - visit ( [ eqn : noisefree ] ) : @xmath237 we use a crude bound @xmath238 .",
    "then , for reasonable values of the parameters ( say @xmath239 , @xmath240 , @xmath241 ) , we have @xmath242 so @xmath236 implies @xmath243          for almost - pure states ( @xmath102 ) , it is possible to obtain estimates for @xmath101 from only @xmath103 pauli expectation values without any assumptions . in this subsection , we sketch a simple scheme based on this observation : it outputs a reconstructed density matrix @xmath135 , together with a certified bound on the deviation @xmath249 .",
    "the algorithm takes two inputs : @xmath250 random pauli expectation values , and the experimentalist s estimate of the measurement precision @xmath251 @xcite .    concretely , we set @xmath102 and aim to put a bound on @xmath252 , where @xmath253 is the eigenvector of @xmath84 corresponding to the largest eigenvalue .",
    "such a bound can be obtained in terms of the _ purity _ @xmath254 .",
    "e.g.,@xmath255 ( valid for @xmath256 , which can certifiably be tested ) . estimating the purity",
    "is done in a way analogous to the proof of theorem  1 .",
    "choose @xmath21 i.i.d .",
    "random variables @xmath257 taking values in @xmath258 $ ] , and define @xmath259 . then @xmath260=\\|\\omega\\|_2 ^ 2 $ ] and thus @xmath261^{1/2}-\\delta_2 $ ] .",
    "we can bound the deviation of @xmath262 from its expected value by the standard ( commutative ) chernoff bound .",
    "one finds for the variance @xmath263 so that ( for @xmath264 $ ] ) : @xmath265       & \\leq & 2 e^{-t^2 m/(4d)},\\end{aligned}\\ ] ] choose @xmath266 for some @xmath267 to ensure that @xmath268 < e^{-\\mu}.\\end{aligned}\\ ] ] combining the previous equation with ( [ eqn : purity ] ) , we have arrived at a certified estimate for @xmath101 . +      matrix recovery using pauli measurements does lack one desirable feature : the classical post - processing ( solving the convex programs ) is more costly , compared to matrix completion @xcite .",
    "this is due to the role of sparse linear algebra in the svt ( singular value thresholding ) algorithm @xcite .",
    "the basic issue is that svt must handle matrices of the form @xmath269 . for matrix completion",
    ", @xmath269 is sparse , so basic operations such as matrix - vector multiplication take time @xmath103 ; but when we use random pauli measurements , @xmath270 is dense , and basic operations take time @xmath9 .",
    "we now describe a `` hybrid '' approach that avoids this difficulty , and works well in practice .",
    "the main observation is that for certain , carefully selected sets of pauli matrices , @xmath269 is sparse after all .",
    "any pauli matrix is of the form @xmath271 for @xmath108 .",
    "plainly , the position of the @xmath0 non - zero matrix elements of @xmath113 depends only on @xmath272 ( @xmath273 encodes only phase information ) .",
    "now choose a random subset @xmath109 of size @xmath110 , and then for all @xmath111 and @xmath112 , measure the pauli matrix @xmath113 .",
    "thus we are measuring each of the pauli strings containing only @xmath274 or identity , together with these same strings `` masked '' by applying a set of size @xmath275 of pauli strings with a pattern of @xmath276 and identity .",
    "formally , this means @xmath277 it follows that @xmath269 is sparse with only @xmath278 non - zero matrix elements .",
    "this `` hybrid method '' can be viewed as a variant of the usual matrix completion problem , where instead of sampling matrix elements independently at random , we sample groups of matrix elements determined by the random strings @xmath111 .",
    "while the hybrid algorithm works well for generic states , certain input states @xmath17 may fail to be `` incoherent enough '' w.r.t .",
    "the very specific set expectation values obtained ( c.f.@xcite ) . for example , when the eigenvectors of @xmath17 are nearly aligned with the standard basis , most of the matrix elements of @xmath17 are nearly 0 , and hence matrix completion is impossible . to avoid this problem , we suggest to perform a pseudo - random unitary @xmath279 prior to measuring the pauli matrices .",
    "one then uses the hybrid method on @xmath280 , and finally applies @xmath281 to recover @xmath17 .",
    "in particular , one can draw @xmath279 at random from an ( approximate ) unitary @xmath282-design with @xmath283",
    ". explicit constructions of such unitaries are known , and can be implemented efficiently @xcite .",
    "while we can not at this point prove rigorous guarantees for the hybrid approach , we do show below that randomization by approximate @xmath282-designs generates sufficient `` incoherence '' that the original matrix completion algorithms @xcite would work . because these algorithms call for matrix elements to be sampled from a uniform distribution , observation  [ obs - incoherence ] does not rigorously apply to the hybrid scheme .",
    "it does , however , make it _ plausible _ that pseudo - randomization overcomes incoherence problems and that guarantees for the hybrid method can be proven in the future .",
    "[ obs - incoherence ] let @xmath17 be an arbitrary state of rank @xmath1 and dimension @xmath0 , and let @xmath43 be the projector onto the support of @xmath17 .",
    "let @xmath284 , @xmath285 , denote the standard basis .",
    "let @xmath279 be drawn at random from an ( @xmath94-approximate ) unitary @xmath282-design with @xmath286 ( and @xmath287 ) , and let @xmath288 .",
    "then , with probability at least @xmath289 , the following holds : @xmath290 where @xmath291 , and @xmath292 and @xmath293 are fixed constants .",
    "this implies the incoherence conditions ( a0 ) and ( a1 ) of @xcite , specialized to the case of positive semidefinite matrices , with @xmath294 as given above and @xmath295 . combining with the results of @xcite",
    "shows that ordinary matrix completion , with matrix elements sampled independently at random , will succeed .",
    "this guarantee does not extend to the hybrid method , however .",
    "proof of observation [ obs - incoherence ] : first consider a single vector @xmath296 , and define @xmath297 .",
    "we will compute the @xmath282th moment of @xmath298 : @xmath299 & = \\ee[\\operatorname{tr}(e^{\\otimes k } { |b_1\\>}{\\<b_1|}^{\\otimes k } e^{\\otimes k } ) ] \\\\   & = \\operatorname{tr}(e^{\\otimes k } \\ee[{|b_1\\>}{\\<b_1|}^{\\otimes k } ] e^{\\otimes k } ) .",
    "\\end{split}\\ ] ]    we want to compute @xmath300 $ ] .",
    "let @xmath301 be a haar - random unit vector in @xmath302 , and let @xmath303 - \\ee[{|u_1\\>}{\\<u_1|}^{\\otimes k}].\\ ] ] by the definition of an approximate unitary @xmath282-design , every matrix element of @xmath41 has absolute value at most @xmath304 .",
    "thus @xmath305 . a well - known ( c.f .",
    "e.g.  def .  2.1 in @xcite )",
    "corollary of schur s lemma states @xmath306 = \\pi_s/\\dim(s)$ ] , where @xmath262 is the symmetric subspace of @xmath307 , @xmath308 is the projector onto @xmath262 , and @xmath309 .",
    "so we have @xmath310 = \\frac{\\pi_s}{\\dim(s ) } + \\delta.\\ ] ]    substituting in , we get : @xmath299 & = \\frac{\\operatorname{tr}e^{\\otimes k } \\pi_s}{\\dim(s ) } + \\operatorname{tr}e^{\\otimes k } \\delta \\\\   & \\leq \\frac{{\\lvert e^{\\otimes k } \\rvert}_{\\operatorname{tr } } { \\lvert \\pi_s \\rvert}}{\\dim(s ) } + { \\lvert e^{\\otimes k } \\rvert}_2 { \\lvert \\delta \\rvert}_2 \\\\   & \\leq \\frac{r^k k!}{(d+k-1)\\cdots d } + \\varepsilon\\sqrt{r^k } \\leq \\bigl(\\frac{rk}{d}\\bigr)^k . \\end{split}\\ ] ] using markov s inequality , and setting @xmath311 , we get @xmath312 \\leq \\frac{\\ee[z^k]}{t^k } \\leq \\bigl(\\frac{rk}{td}\\bigr)^k = \\frac{1}{d^2}.\\ ] ] this proves the claim for a single vector @xmath296 .",
    "now take the union bound over all the vectors @xmath313 , @xmath285 ."
  ],
  "abstract_text": [
    "<S> we establish methods for quantum state tomography based on compressed sensing . these methods are specialized for quantum states that are fairly pure , and they offer a significant performance improvement on large quantum systems . in particular , they are able to reconstruct an unknown density matrix of dimension @xmath0 and rank @xmath1 using @xmath2 measurement settings , compared to standard methods that require @xmath3 settings . </S>",
    "<S> our methods have several features that make them amenable to experimental implementation : they require only simple pauli measurements , use fast convex optimization , are stable against noise , and can be applied to states that are only approximately low - rank . </S>",
    "<S> the acquired data can be used to certify that the state is indeed close to pure , so no _ a priori _ assumptions are needed . </S>",
    "<S> we present both theoretical bounds and numerical simulations .    the tasks of reconstructing the quantum states and processes produced by physical systems </S>",
    "<S>  known respectively as quantum state and process tomography  @xcite  are of increasing importance in physics and especially in quantum information science . </S>",
    "<S> tomography has been used to characterize the quantum state of trapped ions  @xcite and an optical entangling gate  @xcite among many other implementations . </S>",
    "<S> but a fundamental difficulty in performing tomography on many - body systems is the exponential growth in the state space dimension . </S>",
    "<S> for example , to get a maximum - likelihood estimate of a quantum state of @xmath4 ions , ref .  </S>",
    "<S> @xcite required hundreds of thousands of measurements and weeks of post - processing .    </S>",
    "<S> still , one might hope to overcome this obstacle , because the vast majority of quantum states are not of physical interest . </S>",
    "<S> rather , one is often interested in states with special properties : pure states , states with particular symmetries , ground states of local hamiltonians , etc . , and </S>",
    "<S> tomography might be more efficient in such special cases  @xcite . </S>",
    "<S> in particular , consider pure or nearly pure quantum states , i.e. , states with low entropy . </S>",
    "<S> more precisely , consider a quantum state that is essentially supported on an @xmath1-dimensional space , meaning the density matrix is close ( in a given norm ) to a matrix of rank @xmath1 , where @xmath1 is small . </S>",
    "<S> such states arise in very common physical settings , e.g.  a pure state subject to a local noise process @xcite </S>",
    "<S> .    a standard implementation of tomography @xcite would use @xmath3 or more measurement settings , where @xmath5 for an @xmath6-qubit system . </S>",
    "<S> but a simple parameter counting argument suggests that @xmath7 settings could possibly suffice  a significant improvement . </S>",
    "<S> however , it is not clear how to achieve this performance in practice , i.e. , how to choose these measurements , or how to efficiently reconstruct the density matrix . </S>",
    "<S> for instance , the problem of finding a minimum - rank matrix subject to linear constraints is np - hard in general  @xcite .    </S>",
    "<S> in addition to a reduction in experimental complexity , one might hope that a post - processing algorithm which takes as input only @xmath8 numbers could be tuned to run considerably faster than standard methods . since the output of the procedure is a low - rank approximation to the density operator and only requires @xmath7 numbers be specified , it becomes conceivable that the run time scales better than @xmath9 , clearly impossible for naive approaches using dense matrices .    in this letter , we introduce a method to achieve such drastic reductions in measurement complexity , together with efficient algorithms for post - processing . </S>",
    "<S> the approach further develops ideas that have recently been studied under the label of `` compressed sensing '' . compressed sensing @xcite provides techniques for recovering a sparse vector from a small number of measurements  @xcite . here </S>",
    "<S> , sparsity means that this vector contains only a few non - zero entries in a specified basis , and the measurements are linear functions of its entries . </S>",
    "<S> when the measurements are chosen at random ( in a certain precise sense ) , then with high probability two surprising things happen : the vector is uniquely determined by a small number of measurements , and it can be recovered by an efficient convex optimization algorithm  @xcite . </S>",
    "<S> matrix completion  @xcite is a generalization of compressed sensing from vectors to matrices . here </S>",
    "<S> , one recovers certain `` incoherent '' low - rank matrices @xmath10 from a small number of matrix elements @xmath11 . </S>",
    "<S> the problem of low - rank quantum state tomography bears a strong resemblance to matrix completion . however , there are important differences . </S>",
    "<S> we wish to use measurements that can be more easily implemented in an experiment than obtaining elements @xmath12 of density matrices . </S>",
    "<S> previous results @xcite can not be applied to this more general situation . </S>",
    "<S> we would also like to avoid any unnatural incoherence assumptions crucial in prior work @xcite .    </S>",
    "<S> our first result is a protocol for tomography that overcomes both of these difficulties : it uses pauli measurements only , and it works for arbitrary density matrices . </S>",
    "<S> we prove that only @xmath13 measurement settings suffice . </S>",
    "<S> what is more , our proof introduces some new techniques , which both generalize and vastly simplify the previous work on matrix completion . </S>",
    "<S> we sketch the proof here ; a more complete version appears in @xcite . </S>",
    "<S> this provides the basic theoretical justification for our method of doing tomography .    </S>",
    "<S> we then consider a number of practical issues . in a real experiment , </S>",
    "<S> the measurements are noisy , and the true state is only approximately low - rank . </S>",
    "<S> we show that our method is robust to these sources of error . </S>",
    "<S> we also describe ways to certify that a state is nearly pure without any _ a priori _ assumptions .    </S>",
    "<S> finally , we present fast algorithms for reconstructing the density matrix from the measurement statistics based on semidefinite programming  a feature not present in earlier methods for pure - state tomography @xcite . these are adapted from algorithms for matrix completion @xcite , and they are much faster than standard interior - point solvers . reconstructing a low - rank density matrix for @xmath4 qubits takes about one minute on an ordinary laptop computer .    </S>",
    "<S> while our methods do not overcome the exponential growth in measurement complexity ( which is provably impossible for any protocol capable of handling generic pure states ) , they do significantly push the boundary of what can be done in a realistic setting . </S>",
    "<S> our techniques also apply to process tomography : to characterize an unknown quantum process @xmath14 , prepare the jamiokowski state @xmath15 , and perform state tomography on @xmath15 . </S>",
    "<S> our methods work when @xmath14 can approximately be written as a sum of only a few kraus operators , because this implies that @xmath15 has small rank .    </S>",
    "<S> [ [ matrix - recovery - using - pauli - measurements . ] ] matrix recovery using pauli measurements . </S>",
    "<S> + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we consider the case of @xmath6 spin-@xmath16 systems in an unknown state @xmath17 @xcite . </S>",
    "<S> an @xmath6-qubit pauli matrix is of the form @xmath18 , where @xmath19 . </S>",
    "<S> there are @xmath3 such matrices , labeled @xmath20 $ ] . </S>",
    "<S> the protocol proceeds as follows : choose @xmath21 integers @xmath22 $ ] at random and measure the expectation values @xmath23 . </S>",
    "<S> one then solves a convex optimization problem : minimize @xmath24 @xcite subject to @xmath25    [ lr ] let @xmath17 be an arbitrary state of rank @xmath1 . if @xmath26 randomly chosen pauli expectations are known , then @xmath17 can be uniquely reconstructed by solving the convex optimization problem ( [ eqn : feasible ] ) with probability of failure exponentially small in @xmath27 .    the proof is inspired by , but technically very different from , earlier work on matrix completion @xcite . </S>",
    "<S> our methods are more general , can be tuned to give tighter bounds , and are much more compact , allowing us to present a fairly complete argument in this letter . a more detailed presentation of this technique  covering the reconstruction of low - rank matrices from few expansion coefficients w.r.t .  </S>",
    "<S> general operator bases ( not just pauli matrices or matrix elements )  will be published elsewhere @xcite .    </S>",
    "<S> _ proof : _ here we sketch the argument and explain the main ideas ; detailed calculations are in the epaps supplement .    </S>",
    "<S> note that the linear constraints ( [ eqn : feasible ] ) depend only on the projection of @xmath17 onto the span of the measured observables @xmath28 . </S>",
    "<S> this is precisely the range of the `` sampling operator '' @xmath29 . </S>",
    "<S> ( note that @xmath30 = \\rho$ ] . ) indeed , the convex program can be written as @xmath31 s.t .  </S>",
    "<S> @xmath32 . evidently , the solution is unique if for all deviations @xmath33 away from @xmath17 either @xmath34 or @xmath35 .    </S>",
    "<S> we will ascertain this by using a basic idea from convex optimization : constructing a _ strict subgradient _ </S>",
    "<S> @xmath36 for the norm . </S>",
    "<S> a matrix @xmath36 is a strict subgradient if @xmath37 for all @xmath38 . </S>",
    "<S> the main contribution below is a method for constructing such a @xmath36 which is also in the range of @xmath39 . for </S>",
    "<S> then @xmath40 implies that @xmath41 is orthogonal to the range of @xmath39 , thus @xmath42 and the subgradient condition reads @xmath35 . </S>",
    "<S> this implies uniqueness . </S>",
    "<S> ( in fact , it is sufficient to approximate the subgradient condition in a certain sense ) .    </S>",
    "<S> let @xmath43 be the projection onto the range of @xmath17 , let @xmath44 be the space spanned by those operators whose row or column space is contained in @xmath45 . </S>",
    "<S> let @xmath46 be the projection onto @xmath44 , @xmath47 onto the orthogonal complement . </S>",
    "<S> decompose @xmath48 , the parts of @xmath41 that lie in the subspaces @xmath44 and @xmath49 . </S>",
    "<S> we distinguish two cases : _ </S>",
    "<S> ( i ) _ </S>",
    "<S> @xmath50 , and _ </S>",
    "<S> ( ii ) _ @xmath51 @xcite .    case _ </S>",
    "<S> ( i ) _ is easier . in this case , @xmath41 is well - approximated by @xmath52 and essentially we only have to show that the restriction @xmath53 of @xmath39 to @xmath44 is invertible . </S>",
    "<S> using a non - commutative large deviation bound ( see epaps supplement ) , @xmath54 < 4dr e^{-t^2\\kappa /8}\\ ] ] where @xmath55 @xcite . hence the probability that @xmath56 is smaller than @xmath57 . </S>",
    "<S> if that is not the case , one easily sees that @xmath58 , concluding the proof for this case .    </S>",
    "<S> case _ ( ii ) _ is more involved . </S>",
    "<S> a matrix @xmath59 is an _ almost subgradient _ </S>",
    "<S> @xcite if @xmath60 first , suppose such a @xmath36 exists . </S>",
    "<S> then a simple calculation ( see epaps ) using the condition _ </S>",
    "<S> ( ii ) _ shows that @xmath40 indeed implies @xmath35 as hinted at above . </S>",
    "<S> this proves uniqueness in case _ ( ii)_. the difficult part consists in showing that an almost - subgradient exists .    to this end </S>",
    "<S> , we design a recursive process ( the `` golfing scheme '' @xcite ) which converges to a subgradient exponentially fast . </S>",
    "<S> assume we draw @xmath61 batches of @xmath62 pauli observables independently at random ( @xmath63 will be chosen later ) . </S>",
    "<S> define recursively @xmath64 , @xmath65 @xmath66 . </S>",
    "<S> let @xmath67 be the sampling operator associated with the @xmath68th batch , and @xmath69 its restriction to @xmath44 . </S>",
    "<S> assume that in each run @xmath70 . </S>",
    "<S> denote the probability of this event not occurring by @xmath71 . </S>",
    "<S> then @xmath72 so that @xmath73 . </S>",
    "<S> hence , @xmath74 fulfills the first part of ( [ eqn : dual ] ) , as soon as @xmath75 . </S>",
    "<S> we turn to the second part . again using large - deviation techniques ( epaps ) we find @xmath76 with some ( high ) probability @xmath77 . </S>",
    "<S> therefore : @xmath78 which is the second part of ( [ eqn : dual ] ) .    </S>",
    "<S> lastly , we have to bound the total probability of failure @xmath79 . </S>",
    "<S> set @xmath80 , which means that @xmath81 coefficients will be sampled in total . </S>",
    "<S> a simple calculation gives @xmath82 . </S>",
    "<S> this completes the proof of our main result . </S>",
    "<S> @xmath83    in the remaining space , we address the important aspects of resilience against noise , certified tomography , and numerical performance . owing to space limitations , </S>",
    "<S> the presentation will focus on conceptual issues , with the details in  @xcite .    [ </S>",
    "<S> [ robustness - to - noise . ] ] robustness to noise . </S>",
    "<S> + + + + + + + + + + + + + + + + + + + +    realistic situations will differ from the previous case in two regards . </S>",
    "<S> first , the true state @xmath84 may not be low - rank , but only well approximated by a state @xmath17 of rank @xmath1 : @xmath85 . </S>",
    "<S> second , due to systematic and statistical noise , the available estimates for the pauli expectations are not exactly @xmath86 , but of the form @xmath87 for some matrix @xmath88 . </S>",
    "<S> assume @xmath89 ( in practical situations , @xmath90 may be estimated from the error bars associated with the individual pauli expectation values @xcite ) . in order to get an estimate for @xmath84 , choose some @xmath91 and @xmath92 , and solve the convex program @xmath93    [ robust ] let @xmath84 be an approximately low - rank state as described above . </S>",
    "<S> suppose @xmath26 randomly chosen pauli expectations are known up to an error of @xmath94 as in ( [ e : cop ] ) , and let @xmath95 be the solution of ( [ e : cop ] ) . then the difference @xmath96 is smaller than @xmath97 . </S>",
    "<S> this holds with probability of failure at most @xmath98 plus the probability of failure in theorem  1 .    </S>",
    "<S> the proof combines ideas from ref.@xcite with our argument above @xcite . </S>",
    "<S> the main difference from the noise - free case is that , instead of using @xmath99 , we must now work with @xmath100 . with this estimate , </S>",
    "<S> observation 1 follows from the noise - free proof , together with some elementary calculations ( see epaps ) . </S>",
    "<S> we remark that the above bound is likely to be quite loose ; based on related work involving the `` restricted isometry property , '' we conjecture that the robustness to noise is actually substantially stronger than what is shown here @xcite .    </S>",
    "<S> [ [ certified - tomography - of - almost - pure - states . ] ] certified tomography of almost pure states . </S>",
    "<S> + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the preceding results require an _ a priori _ promise : that the true state @xmath84 is @xmath101-close to a rank-@xmath1 state . however , when performing tomography of an unknown state , neither @xmath1 nor @xmath101 are known beforehand . </S>",
    "<S> there are a few solutions to this quandary . </S>",
    "<S> first , @xmath1 and @xmath101 may be estimated from other physical parameters of the system , such as the strength of the local noise @xcite . </S>",
    "<S> another approach is to estimate @xmath1 and @xmath101 from the same data that is used to reconstruct the state . when @xmath102 , this approach is particularly effective , in entirely assumption - free tomography : one can estimate @xmath101 , using only @xmath103 pauli expectation values </S>",
    "<S> this is because @xmath101 is related to the purity @xmath104 , which has a simple closed - form expression in terms of pauli expectation values . </S>",
    "<S> see epaps for details . </S>",
    "<S> we get :    assume that the unknown physical state is close to being pure . </S>",
    "<S> then one can find a certificate for that assumption , and reconstruct the state with explicit guarantees on the reconstruction error , from @xmath105 pauli expectation values . </S>",
    "<S> the probability of failure is exponentially small in @xmath27 .    finally , </S>",
    "<S> when the state is approximately low - rank but not nearly pure ( @xmath106 ) , one may perform tomography using different numbers of random pauli expectation values @xmath21 . </S>",
    "<S> when @xmath21 is larger than necessary ( corresponding to an over - estimate of @xmath1 ) , we are guaranteed to find the correct density matrix . when @xmath21 is too small </S>",
    "<S> , we find empirically that the algorithms for reconstructing the density matrix ( i.e. , solving the convex program ( [ eqn : feasible ] ) ) simply fail to converge .    </S>",
    "<S> [ [ a - hybrid - approach - to - matrix - recovery . ] ] a hybrid approach to matrix recovery . </S>",
    "<S> + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    here we describe a variant of our tomography method that makes the classical post - processing step ( i.e. , solving the convex program ( [ eqn : feasible ] ) to reconstruct the density matrix ) faster . </S>",
    "<S> this method also uses random pauli measurements , but they are chosen in a structured way . </S>",
    "<S> any pauli matrix is of the form @xmath107 for @xmath108 . </S>",
    "<S> we choose a random subset @xmath109 of size @xmath110 , and then for all @xmath111 and @xmath112 , measure the pauli matrix @xmath113 . </S>",
    "<S> we call this the `` hybrid method '' because it is equivalent to a certain structured matrix completion problem . </S>",
    "<S> this fact implies that certain key computations in solving the convex program ( [ eqn : feasible ] ) can be implemented in time @xmath103 rather than @xmath9 @xcite . </S>",
    "<S> however , the hybrid method is not covered by the strong theoretical guarantees shown earlier , though it does give accurate results in practice . </S>",
    "<S> for a more complete discussion , see the epaps supplement .    </S>",
    "<S> [ [ numerical - results . ] ] numerical results . </S>",
    "<S> + + + + + + + + + + + + + + + + + +    we numerically simulated both the random pauli and hybrid approaches discussed above . </S>",
    "<S> for both approaches , we used singular value thresholding ( svt )  @xcite . instead of directly solving eq .  </S>",
    "<S> ( [ e : cop ] ) , svt minimizes @xmath114 subject to @xmath115 , which is a good proxy to eq .  </S>",
    "<S> ( [ e : cop ] ) when @xmath116 dominates the second term ; the programs are equivalent in the limit @xmath117 ( provided eq .  </S>",
    "<S> ( [ e : cop ] ) has a unique solution ) @xcite . estimating the second term for typical states suggests choosing @xmath118 ; we use @xmath119 . to simulate tomography , we chose a random state from the haar measure on a @xmath120 dimensional system and traced out the @xmath1-dimensional ancilla , then applied depolarizing noise of strength @xmath121 . </S>",
    "<S> we sampled expectation values associated with randomly chosen operators as above , and added additional statistical noise ( respecting hermiticity ) which was i.i.d .   </S>",
    "<S> gaussian with variance @xmath122 and mean zero . </S>",
    "<S> we used svt and quantified the quality of the reconstruction by the fidelity and the trace distance for various values of @xmath21 , each averaged over @xmath123 simulations . </S>",
    "<S> this dependence is shown in fig .  </S>",
    "<S> [ f : fig1 ] . </S>",
    "<S> the reconstruction is remarkably high fidelity , despite severe undersampling and corruption by both depolarizing and statistical noise  @xcite . using the hybrid method with @xmath4 qubits on a rank @xmath124 state plus @xmath125 depolarizing , and statistical noise strength @xmath126 </S>",
    "<S> , we typically achieve @xmath127 fidelity reconstructions in under @xmath128 seconds on a modest laptop with @xmath129 gb of ram and a @xmath130 ghz dual - core processor using matlab  even though @xmath131 of the matrix elements remain unsampled . increasing the number of samples only improves our accuracy and speed , so long as sparsity is maintained .    </S>",
    "<S> using truly randomly chosen pauli observables ( instead of the hybrid method ) slightly increases the processing time due to the dense matrix multiplications involved : in our setup about one minute . </S>",
    "<S> however , this method achieves even better performance with respect to errors , as seen in fig .  </S>",
    "<S> [ f : fig1 ] .    </S>",
    "<S> the simulations above show that our method work for generic low rank states . </S>",
    "<S> lastly , we demonstrate the functioning of the approach in the experimental context of the state @xmath17 found in the @xmath4 ion experiment of ref .  @xcite . to exemplify the above results , we simulated physical measurements by sampling from the probability distribution computed using the born rule applied to the reconstructed state @xmath17 . </S>",
    "<S> this state is approximately low - rank , with 99% of the weight concentrated on the first @xmath132 eigenvectors . </S>",
    "<S> the standard deviation per observable was @xmath133 . </S>",
    "<S> fewer than 30% of all pauli matrices were chosen randomly . from this information , </S>",
    "<S> a rank @xmath134 approximation @xmath135 with fidelity of @xmath136 with respect to @xmath17 was found in about @xmath124 minutes on the aforementioned laptop .     for random states of @xmath137 qubits , </S>",
    "<S> so @xmath5 . </S>",
    "<S> as discussed in the text , the sampled states had rank @xmath138 , depolarizing noise of @xmath139 and gaussian statistical noise with @xmath140 . </S>",
    "<S> both the random pauli and hybrid approaches are shown . ]    [ [ discussion . ] ] discussion . </S>",
    "<S> + + + + + + + + + + +    we have presented new methods for low - rank quantum state tomography , which require only @xmath141 measurements , where @xmath1 is the rank of the unknown density matrix and @xmath0 is the hilbert space dimension . </S>",
    "<S> our methods are based on and further develop the new paradigm of compressed sensing , and in particular , matrix completion @xcite . </S>",
    "<S> we use measurements that are experimentally feasible , together with very fast classical post - processing . </S>",
    "<S> the methods perform well in practice , and are also supported by theoretical guarantees </S>",
    "<S> . it would be interesting to further flesh out the trade off between the need for measurements that can be performed easily in an experiment and the need for sparse matrices during the classical post - processing step . </S>",
    "<S> it is the hope that this work stimulates such further investigations .    </S>",
    "<S> _ acknowledgments . </S>",
    "<S> _ we thank e.  cands and y.  plan for useful discussions . </S>",
    "<S> research at pi is supported by the government of canada through industry canada and by the province of ontario through the ministry of research  & innovation . </S>",
    "<S> yl is supported by an nsf mathematical sciences postdoctoral fellowship , je by the eu ( qap , qessence , minos , compas ) and the euryi , dg by the eu ( corner ) . </S>",
    "<S> we thank the anonymous referees for many helpful suggestions .    </S>",
    "<S> 10    , no .  649 in _ lect .  </S>",
    "<S> notes phys . </S>",
    "<S> _ , m.  paris and j.  ehek , eds . , ( springer , heidelberg , 2004 ) .    </S>",
    "<S> h.  hffner _ </S>",
    "<S> et  al . _ , </S>",
    "<S> nature * 438 * , 643 ( 2005 ) .    </S>",
    "<S> j.  l.  obrien _ et  al . </S>",
    "<S> _ , nature * 426 * , 264 ( 2003 ) .    </S>",
    "<S> m.  s.  kaznady and d.  f.  v.  james , phys .  </S>",
    "<S> rev .  </S>",
    "<S> a * 79 * , 022109 ( 2009 ) .    </S>",
    "<S> g.  m.  dariano , l.  maccone , and m.  paini , j.  opt .  </S>",
    "<S> b * 5 * , 77 ( 2003 ) ; v.  v.  dodonov and v.  i.  manko , phys .  </S>",
    "<S> lett .  </S>",
    "<S> a * 229 * , 335 ( 1997 ) .    </S>",
    "<S> j .- p .  </S>",
    "<S> amiet and s.  weigert , j.  phys .  </S>",
    "<S> a * 32 * , 2777 ( 1999 ) .    </S>",
    "<S> b.  k.  natarajan , siam j.  comp .  </S>",
    "<S> * 24 * , 227 ( 1995 ) .    </S>",
    "<S> d.  donoho , ieee trans .  </S>",
    "<S> info .  </S>",
    "<S> theory * 52 * , 1289 ( 2006 ) ; e.  cands and t.  tao , ieee trans .  </S>",
    "<S> info .  </S>",
    "<S> theory * 52 * , 5406 ( 2006 ) .    </S>",
    "<S> r.  l.  kosut , arxiv:0812.4323 .    </S>",
    "<S> e.  j.  cands and b.  recht , found .  </S>",
    "<S> comp .  </S>",
    "<S> math .  </S>",
    "<S> * 9 * , 717 ( 2008 ) .    </S>",
    "<S> e.  j.  cands and t.  tao , ieee trans . </S>",
    "<S> inform . </S>",
    "<S> th . </S>",
    "<S> , arxiv:0903.1476 .    </S>",
    "<S> e.  j.  cands and y.  plan , proc .  </S>",
    "<S> ieee , in press ( 2010 ) , arxiv:0903.3131 .    </S>",
    "<S> m.  fazel , e.  cands , b.  recht and p.  parrilo , proc .  </S>",
    "<S> asilomar conf . </S>",
    "<S> ca , nov 2008 .    </S>",
    "<S> j .- f .  </S>",
    "<S> cai , e.  j.  cands , and z.  shen , arxiv:0810.3286 .    </S>",
    "<S> a.  w.  harrow and r.  a.  low , proc .  </S>",
    "<S> random 2009 , lncs * 5687 * , 548 ( 2009 ) ; d.  gross , k.  audenaert , and j.  eisert , j.  math .  phys .  * </S>",
    "<S> 48 * , 052104 ( 2007 ) .    </S>",
    "<S> the techniques easily generalize to spin-@xmath142 particles @xcite .    </S>",
    "<S> we use the usual matrix norms @xmath143 , with @xmath144 the singular values of @xmath145 . </S>",
    "<S> the last definition extends to super - operators : if @xmath146 is a super - operator , then @xmath147 is its largest singular value , or , equivalently @xmath148 ( a.k.a .  </S>",
    "<S> `` @xmath149''-norm ) .    </S>",
    "<S> if the term @xmath150 were zero , @xmath36 would be a strict subgradient .    going beyond @xcite , we bound deviations in @xmath151-norm , as opposed to @xmath129-norm . </S>",
    "<S> the former norm gives stronger results and carries an operational meaning in terms of statistical distinguishability .    </S>",
    "<S> consider a pure state of @xmath6 qubits subject to local noise that occurs with probability @xmath152 on each site . </S>",
    "<S> then the density matrix is well - approximated by a matrix of rank @xmath153 , where @xmath154 is the binary entropy of @xmath152 , and @xmath5 is the hilbert space dimension . </S>",
    "<S> when @xmath152 is small , we have @xmath155 .    </S>",
    "<S> the bounds presented here hold even for a worst - case scenario of `` adversarial '' noise . </S>",
    "<S> employing more realistic noise models ( e.g. , independent gaussian errors for each pauli expectation value ) gives rise to significantly improved estimates @xcite .    </S>",
    "<S> r.  ahlswede and a.  winter , ieee trans .  inf .  </S>",
    "<S> theory * 48 * , 569 ( 2002 ) .    </S>",
    "<S> r.  bhatia , _ matrix analysis _ </S>",
    "<S> ( springer , berlin , 1997 ) .    </S>",
    "<S> s.  becker , s.  t.  flammia , d.  gross , y .- k .  </S>",
    "<S> liu , and j.  eisert , in preparation . </S>",
    "<S> d.  gross , arxiv:0910.1879 .    </S>",
    "<S> the estimate returned by svt typically has a subnormalized trace , which we handle in an _ ad hoc _ way by renormalizing . </S>",
    "<S> a more accurate estimate can be obtained by _ debiasing _ , or by solving a reformulation of the problem in terms of @xmath156-regularized least squares @xcite .    </S>",
    "<S> d.  gross and v.  nesme , arxiv:1001.2738 ( 2010 ) .    </S>",
    "<S> a.  w.  harrow and r.  a.  low , comm . </S>",
    "<S> math . </S>",
    "<S> phys . </S>",
    "<S> , * 291 * , 257 ( 2009 ) .    using theorem  11 of @xcite , the markov bound can immediately be replace by a more sophisticated large deviation bound , which gives a probability of failure exponentially small in @xmath157 . </S>"
  ]
}