{
  "article_text": [
    "we have carried out an extensive simulation program on the set of update rules and underlying networks that we have introduced above . in",
    "what follows , we separate the discussion of the corresponding results in two main groups : imitative and non - imitative strategies .",
    "additional aspects of our numerical approach are described in si results .",
    "the five topmost sets of plots of fig .",
    "[ fig.c ] show the evolution of the level of cooperation @xmath21 ( defined as the percentage of players who cooperate in each round of the game ) , as well as the stationary probability distribution of the individual mcc parameters among the population , when different evolutionary dynamics are employed to update players behavioral traits .",
    "note that all the plots refer to the case @xmath22 ( meaning that the update takes place after each round ) .",
    "we will show only results for this choice below , because we have observed that the value of @xmath16 basically influences only the convergence rate of the system to its stationary state , but not its characteristic features . as can be seen from the plots , the final level of cooperation here is ,",
    "generally , highly dependent on the population structure , and often the final outcome is a fully defective state ( especially for a well - mixed population ) @xcite .",
    "then , as expected from non - innovative strategies , the number of profiles @xmath12 that survive at the end of the evolution is always very low and , in general , only one profile is left for every individual realization of the system .",
    "notwithstanding , the surviving profiles are very different among independent realizations ( except when the final outcome is full defection , where @xmath23 irrespectively of @xmath24 and @xmath25 ) , indicating the absence of a stationary distribution for mcc parameters , _",
    "i.e. _ , the lack of evolutionarily stable profiles",
    ". the only case in which the parameters @xmath26 and @xmath25 tend to concentrate around some stationary non - trivial values is given by games played on lattices and with unconditional imitation updating .",
    "finally , we note that , when the update rule is the voter model , the surviving profile is just picked randomly among the population ( as expected from a rule that is not meant to improve payoffs ) , and hence the cooperation level remains close on average to the value set by the initial distribution of mcc parameters . a similar behavior is observed with the fermi rule for low @xmath17 , where @xmath17 is the parameter that controls the intensity of the selection . whereas for high @xmath17 ( low temperature ) errors are unlikely to occur and players always choose the parameters that enhance their payoffs , resulting in full defection as final outcome , for low @xmath17 ( high temperature ) errors are frequent , so that mcc parameters basically change randomly and @xmath21 remains close to its initial value .",
    "it is also worth noting that proportional imitation and the fermi rule lead to very similar results , except for the parameter @xmath26 , which makes sense in view that they are very similar unless @xmath17 is very small .",
    "the fact that both the fermi rule and the death - birth update lead also to similar outcomes is probably related to those two dynamics being both error - prone , with specific features of either one showing , for instance , in the different results on lattices .",
    "nonetheless , beyond all these peculiarities of each imitative dynamics , the main conclusion of our simulation program is that this type of update schemes is not compatible with the experimental observations .",
    "note that it is not our goal to explain in detail the effects of a particular updating rule on a given population structure .",
    "however , it is possible to gain qualitative insights on the behavior of the system from rather naive considerations .",
    "take for instance scale - free networks , which feature hubs ( players with high degree ) that thus get higher payoff than average players do .",
    "if the dynamics is of imitative nature , hubs strategy is stable and tends to spread over the network : there is the possibility for a stable subset of cooperators to form around hubs @xcite .",
    "this behavior ( which can not occur in random or regular graphs , where the degree distribution is more homogeneous ) is clearly visible when the updating rule is proportional imitation .",
    "notably , the stability of the subset of cooperators is destroyed when mistakes are possible ( as with the fermi rule ) ; on the other hand , it is enhanced when the updating selects preferentially individuals with high payoffs ( as with the death - birth rule or unconditional imitation ) .",
    "in these two latter cases cooperation becomes sustainable also in lattices , as these structures naturally allow clusters of mutually connected cooperators to emerge .",
    "instead , the independence on the network observed  as we shall see  in the case of reinforcement learning is easily explained by players not even looking at each other , which makes the actual population structure irrelevant .",
    "a first general finding about this type of evolutionary rules is that , because of their own nature , they allow for a very large number of surviving mcc profiles ( @xmath27 ) , even when the parameters tend to concentrate around specific values .",
    "the bottom set of plots of fig .",
    "[ fig.c ] summarizes our results for the best response dynamics , which is the most `` rational '' of the ones that we are studying here . for this choice",
    ", the system always ends up in a fully defective state , irrespectively of the network s structure , which is the outcome that would be obtained by global maximization of the individual payoffs . in this sense , the amount @xmath28 by which parameters are shifted at each update influences only the convergence rate of the system : higher @xmath28 arrives faster to full defection ( @xmath29 ) .",
    "we then see that evolution by best response fails completely to explain any of the main experimental results .",
    "our other rule of choice in this type is reinforcement learning .",
    "we will begin by assuming that aspiration levels @xmath30 remain fixed in time .",
    "our results regarding this rule are presented in fig .",
    "[ fig.c_rl ] .",
    "when @xmath30 is midway between the punishment and reward payoffs ( @xmath31 ) we observe a stationary , non vanishing level of cooperation around 30% that does not depend on the population structure .",
    "this behavior , that is robust with respect to the learning rate @xmath32 , is in good qualitative agreement with the experimental observations @xcite .",
    "however the most remarkable outcome of this dynamic is that , contrary to all other update procedures that we have discussed so far , the values of the mcc parameters @xmath12 concentrate around some stationary , non - trivial values which are independent on the population structure and on the initial conditions of the system .",
    "indeed , we have checked that the stationary values of @xmath12 do not depend on the initial form of their distributions , and also that fixing one of these three parameters does not influence the stationary distributions of the others .",
    "more importantly , these values are compatible with the ones obtained by linear fits of the aggregate mcc behavior extracted from the experiments @xcite .",
    "reinforcement learning thus represents the only mechanism ( among those considered here ) which is able to give rise to evolutionarily stable moody conditional cooperators , while at the same time reproducing the cooperation level and the lack of network reciprocity ( note that , as we already said , the type of network on which the population sits does not affect the cooperation level ) .",
    "it is worth mentioning two other features of this dynamics .",
    "first , we have checked that the value of @xmath32 influences only the convergence rate of the system ; however , if players learn too rapidly ( @xmath33 ) then the parameters change too quickly and too much to reach stationary values  a phenomenon typical of this kind of learning algorithms .",
    "second , if we introduce in the system a fraction @xmath34 of players who always defect ( recall that full defectors coexist with moody conditional cooperators in the experiments ) , what happens is that the final cooperation level changes  it drops to 25% for @xmath35 and to 20% for @xmath36but the stationary distributions of mcc parameters are not affected .",
    "this means that reinforcement learning is able to account for the heterogeneity of the behaviors observed in the experimental populations , which is consistent with the fact that this update rule does not take into account either the payoffs or the actions of the rest of the players .",
    "further evidence for the robustness of the reinforcement learning evolutionary dynamics arises from extending our study to other aspiration levels , including dynamic ones . in general",
    ", what we observe is that the higher @xmath30 , the higher the final level of cooperation achieved .",
    "when @xmath37 players are not satisfied with the reward of mutual cooperation ; however an outcome of mutual defection leads to a great stimulus towards cooperation in the next round .",
    "this is why players parameters tend to concentrate around values that allow for a strategy which alternates cooperation and defection , and that brings to stationary cooperation levels around 50% .",
    "instead if @xmath38 , then defection - defection is a satisfactory outcome for each pair of players . in this case cooperation",
    "may thrive only on stationary networks ( where clusters of cooperator may form ) .",
    "however for a well - mixed population the final state is necessarily fully defective ( @xmath39 ) .",
    "hence we observe in this case a dependence on the network structure which is not observed in the experiments ; nonetheless , setting an aspiration level below punishment is at least questionable .",
    "therefore , unless players make very strange decisions on their expectations from the game , we find behaviors that agree qualitatively with the experiments . finally , we consider the case in which players adapt their aspiration level after each round : @xmath40 , where @xmath41 is the adaptation ( or habituation ) rate and @xmath42 .",
    "what we observe now is that the stationary level of cooperation lies around 20% , the absence of network reciprocity is recovered , and players average aspiration levels remain in the range @xmath43 .",
    "thus this case is again compatible with experimental observations , and the fact that aspiration levels of an intermediate character are selected ( corresponding to the case that better describes them ) provides a clear rationale for this choice in the preceding paragraph .",
    "a final important validation of reinforcement learning comes from studying the _ ewa _ ( experience - weighted attraction ) updating @xcite , an evolutionary dynamics that combines aspects of belief learning models ( to which best response belongs ) and of reinforcement learning .",
    "results for this choice of the updating scheme ( which are reported in si ewa ) confirm in fact that reinforcement learning is the determinant contribution which allows to achieve situations matching with empirical outcomes .",
    "understanding cooperation is crucial because all major transitions in evolution involve the spreading of some sort of cooperative behavior @xcite .",
    "in addition , the archetypical tensions that generate social dilemmas are present in fundamental problems of the modern world : resource depletion , pollution , overpopulation , and climate change .",
    "this work , inspired by experiments @xcite , aimed at finding an evolutionary framework capable of modeling and justifying real people behavior in an important class of social dilemmas  namely prisoner s dilemma games . to this end , we have studied the evolution of a population of differently - parameterized mcc whose parameters can evolve .",
    "we have considered several rules for parameters changes  both of imitative nature and innovative mechanisms , as well as rules based on payoff comparison and others based on non - economic or social factors .",
    "our research shows that reinforcement learning with a wide range of learning rates is the only mechanism able to explain the evolutionary stability of moody conditional cooperation , leading to situations that are in agreement with the experimental observations in terms of the stationary level of cooperation achieved , average values and stationary distributions of the mcc parameters , and absence of network reciprocity .",
    "note that we have considered only pd games ; however , given that in our setup players have to play the same action with all their neighbors , it is clear that our results should be related to public goods experiments ( where conditional cooperation was first observed @xcite ) .",
    "our findings thus suggest that mcc can also arise and be explained through reinforcement learning dynamics in repeated public goods games .",
    "we stress that this is a very relevant result , as for the first time to our knowledge we are providing a self - consistent picture of how people behave in pd games on networks . indeed ,",
    "starting from the observation that players do not take others payoffs into account , we find that if this behavior is to be explained in an evolutionary manner , it has to be because people learn from what they experience , and not from the information they may gather on their neighbors .",
    "such a learning process is in turn very sensible in the heavily social framework in which we as humans are embedded , and compatible with the knowledge that we have on the effects of our choices on others . on the other hand ,",
    "the evolutionary dynamics that our work eliminates as possible responsible for how we behave are , in fact , difficult to justify in the same social context , either because they would require a larger cognitive effort ( best response ) or , on the contrary , because they assume a very limited rationality that only allows to imitate without reflecting on how we have been affected by our choices .",
    "our work thus provides independent evidence that , at least in the context of human subjects interacting in pd , the observed behaviors arise mostly from learning .",
    "of course , this does not mean that other ways to update one s strategy are not possible : indeed , a large fraction of people have been observed to be full defectors , a choice they may have arrived at by considering the pd game from a purely rational viewpoint . in addition , specific individuals may behave in idiosyncratic manners that are not described within our framework here .",
    "still , as we have seen , our main result , namely that reinforcement learning explains the behavior of a majority of people and its macro - consequences ( level of cooperation , lack of network reciprocity ) would still hold true in the presence of these other people .    although a generalization of our results to other classes of social dilemma beyond pd and public goods is not straightforward , our conclusions here should guide further research on games on networks .",
    "we believe that the experimental results , to which the present work provides a firm theoretical support , allow to conclude that many of the evolutionary dynamics used in theory and in simulations simply do not apply to the behavior of human subjects and , therefore , their use should be avoided . as a matter of fact , much of the research published in the last decade by using all these update schemes is only adding confusion to an already very complicated problem .",
    "even so , our findings do not exclude the plausibility of other strategy updating in different contexts .",
    "for instance , analytical results with imitative dynamics @xcite display an agreement with experimental outcomes on dynamical networks @xcite , where it was also shown that selection intensity ( which can be thought as a measure of players rationality ) can dramatically alter the evolutionary outcome @xcite .",
    "it is also important to stress that our findings here relate to human behavior , and other species could behave differently ; for instance , it has been recently reported that bacteria improve their cooperation on a spatial structure @xcite and this could arise because of more imitative strategies. finally , a promising line of research could be to compare the distribution of values for the mcc parameters that we have obtained here with the observations on single individuals , thus going beyond the check agains aggregate data to address the issue of reproducing whole histograms .",
    "unfortunately , the data that we currently have is not good in terms of individual behavior , as observations are noisy and statistics is insufficient to assign significant values of the parameters to single participants . in this respect ,",
    "experiments specifically designed to overcome this difficulty could be a very relevant contribution to further verifying our claims .    another important suggestion arising from our research is the relevance of theoretical concepts derived within reinforcement learning to the study of games on networks . in this respect , it is very interesting to recall that a theoretical line of work based on reinforcement learning models for 2-player repeated games has received quite some attention recently @xcite . in this context",
    ", a generalized equilibrium concept has been introduced in order to explain the findings in simulations of 2-player pd @xcite , called self - correcting equilibrium : it obtains when the expected change of parameters is zero but there is a positive probability to incur into a negative as well as positive stimulus .",
    "the extension of the reinforcement learning dynamics to multiplayer pd that we have presented here points to the explanatory power of such equilibrium concepts in the framework of network games , as the level of cooperation observed in experiments is in close agreement with the predicted equilibrium .",
    "importantly , it has recently been shown that behavioral rules with intermediate aspiration levels , as the ones we find here to be relevant , are the most successful ones among all possible reactive strategies in a wide range of 2-player games @xcite .",
    "this suggests that this type of evolutionary dynamics may indeed be relevant in general .",
    "it would therefore be important to study whether or not the associated equilibrium concept is also the most important one when other types of games are played on an underlying network .",
    "if that is the case , we would have a very powerful tool to understand and predict human behavior in those situations .    *",
    "materials and methods *  agent - based simulations of the model were carried out using the following parameters : @xmath44 ( initial fraction of cooperators ) @xcite , @xmath45 , @xmath46 , @xmath47 , @xmath48 ( entries of the pd s payoff matrix , such that @xmath6 , @xmath7 and @xmath49 ) @xcite , @xmath50 and @xmath51 ( network parameters ) @xcite .",
    "the mcc behavioral parameters @xmath12 are all drawn for each player before the first round of the game from a uniform distribution @xmath52 $ ] , with the additional constraint @xmath53 to have @xmath54 .",
    "note that the particular form of the initial distribution as well as the presence of the constraint does not influence the outcome of our experiments .",
    "this work was supported by the swiss natural science fundation through grant pbfrp2_145872 , by ministerio de economa y competitividad ( spain ) through grant prodievo , by the era - net on complexity through grant resinee , and by comunidad de madrid ( spain ) through grant modelico - cm .",
    "38 dawes rm ( 1980 ) social dilemmas .",
    "_ 31:169 - 193 .",
    "maynard smith j , price gr ( 1973 ) the logic of animal conflict . _",
    "nature _ 246:15 - 18 .",
    "axelrod r ( 1984 ) the evolution of cooperation ( basic books , new york ) .",
    "hofbauer j , sigmund k ( 1998 ) evolutionary games and population dynamics ( cambridge university press ) .",
    "maynard smith j , szathmary e ( 1995 ) the major transitions in evolution ( freeman , oxford ) .",
    "hofbauer j , sigmund k ( 2003 ) evolutionary game dynamics . _",
    "_ 40:479 - 519 .",
    "szab g , fth g ( 2007 ) evolutionary games on graphs .",
    "_ 446:97 - 216 .",
    "roca cp , cuesta j , snchez a ( 2009 ) evolutionary game theory : temporal and spatial effects beyond replicator dynamics .",
    "_ 6:208 - 249 .",
    "there are indeed more sophisticated approaches , _",
    "e.g. _ , modeling strategies as evolving automata or bitstrings that can cover a large strategy space @xcite .",
    "lomborg b ( 1996 ) nucleus and shield : the evolution of social structure in the iterated prisoner s dilemma .",
    "_ american sociological review _ 61(2):278 - 307 .",
    "van veelen m , garca j , rand dg , nowak ma ( 2012 ) direct reciprocity in structured populations .",
    "natl . acad .",
    "109:9929 - 9934 .",
    "fischbacher u , gchter s , fehr e ( 2001 ) are people conditionally cooperative ?",
    "evidence from a public goods experiment .",
    "_ 71:397 - 404 .",
    "gruji j , fosco c , araujo l , cuesta ja , snchez a ( 2010 ) social experiments in the mesoscale : humans playing a spatial prisoner s dilemma .",
    "_ plos one _ 5:e13749 .",
    "gracia - lzaro c , ferrer a , ruiz g , tarancn , cuesta ja , snchez a , moreno y ( 2012 ) heterogeneous networks do not promote cooperation when humans play a prisoner s dilemma .",
    "109:10922 - 20926 .",
    "traulsen a , semmann d , sommerfeld rd , krambeck hj , milinski m ( 2010 ) human strategy updating in evolutionary games . _ proc .",
    "107:2962 - 2966 .",
    "gruji j , gracia - lzaro c , traulsen a , milinski m , cuesta ja , moreno y , snchez a ( 2013 ) a meta - analysis of experiments on prisoner s dilemmas on networks , _ submitted to epj data science_. trivers rl ( 1971 ) the evolution of reciprocal altruism . _ q. rev .",
    "_ 46:35 - 57 .",
    "sigmund k ( 2010 ) the calculus of selfishness ( princeton university press ) .",
    "axelrod r , hamilton wd ( 1981 ) the evolution of cooperation .",
    "_ science _ 211:1390 - 1396 .",
    "gruji j , cuesta ja , snchez a ( 2012 ) on the coexistence of cooperators , defectors and conditional cooperators in the multiplayer iterated prisoner s dilemma . _",
    "_ 300:299 - 308 .",
    "gruji j , eke , b , cabrales , a , cuesta ja , snchez a ( 2012 ) three is a crowd in iterated prisoner s dilemmas : experimental evidence on reciprocal behavior . _",
    "gutirrez - roig m , gracia - lzaro c , moreno y , perell j , snchez a ( 2013 ) from selfish youth to cooperative old age : transition to prosocial behavior in social dilemmas , _ in preparation_. dal b p , frechette g ( 2011 ) the evolution of cooperation in infinitely repeated games : experimental evidence . _",
    "_ 101:411 - 429 .",
    "schlag kh ( 1998 ) why imitate , and if so , how ? :",
    "a boundedly rational approach to multi - armed bandits . _",
    "j. econ . theory _ 78:130 - 156 .",
    "helbing d ( 1992 ) interrelations between stochastic equations for systems with pair interactions .",
    "_ physica a _",
    "181:29 - 52 .",
    "szab g , toke c ( 1998 ) evolutionary prisoner s dilemma game on a square lattice .",
    "e _ 58:69 - 73 .",
    "blume le ( 1993 ) the statistical mechanics of strategic interaction .",
    "_ games and economic behavior _ 5 : 387 - 424 .",
    "traulsen a , pacheco jm , imhof la ( 2006 ) stochasticity and evolutionary stability .",
    "moran pap ( 1962 ) the statistical processes of evolutionary theory ( oxford , clarendon press ) .",
    "nowak ma , may rm ( 1992 ) evolutionary games and spatial chaos .",
    "_ nature _ 359:826 - 829 .",
    "holley r , liggett tm ( 1975 ) ergodic theorems for weakly interacting infinite systems and the voter model .",
    "_ 3:643 - 663 .",
    "fehr e , gchter s ( 2000 ) fairness and retaliation : the economics of reciprocity _ j. econ .",
    "_ 14:159 - 181 .",
    "matsui a ( 1992 ) best response dynamics and socially stable strategies .",
    "_ j. econ .",
    "57 : 343 - 362 .",
    "bush r , mosteller f ( 1955 ) stochastic models of learning ( john wiliey & son , new york ) .",
    "macy mw , flache a ( 2002 ) learning dynamics in social dilemmas .",
    "99:7229 - 7236 .",
    "izquierdo ss , izquierdo lr , gotts , nm ( 2008 ) reinforcement learning dynamics in social dilemmas .",
    "_ j. artif .",
    "barabsi al , albert r ( 1999 ) emergence of scaling in random networks . _",
    "science _ 286:509 - 512 .",
    "nowak ma ( 2006 ) five rules for the evolution of cooperation . _ science _ 314:1560 - 1563 .",
    "note that the general mcc behavior includes full defectors and full cooperators as special cases : if for a given player @xmath55 , then as soon as she defects she will keep defecting until @xmath26 changes ; vice versa , if @xmath56 then as soon as she cooperates she will keep cooperating until @xmath25 changes .",
    "gmez - gardees j , campillo m , flora lm , moreno y ( 2007 ) dynamical organization of cooperation in complex networks . _",
    "_ 98:034101 .",
    "camerer c , ho th ( 1999 ) experience - weighted attraction learning in normal form games .",
    "_ econometrica _ 67:827 - 874 .",
    "wu b , zhou d , fu f , luo q , wang l , traulsen a ( 2010 ) evolution of cooperation on stochastic dynamical networks .",
    "_ plos one _ 5(6):e11187 .",
    "fehl k , van der post dj , semmann d ( 2011 ) co - evolution of behaviour and social network structure promotes human cooperation .",
    "_ ecology letters _ 14:546 - 551 .",
    "van segbroeck s , santos fc , lenaerts t , pacheco jm ( 2011 ) selection pressure transforms the nature of social dilemmas in adaptive networks .",
    "_ new journal of physics _ 13:013007 .",
    "hol fjh , galajda p , nagy k , woolthuis rg , dekker c , keymer",
    "je ( 2013 ) spaital structure facilitates cooperation in a social dilemma : empirical evidence from a bacterial community . _",
    "plos one _ 8:e77402 .",
    "erev i , roth ae ( 2001 ) simple reinforcement learning models and reciprocation in the prisoner s dilemma game .",
    "_ in _ bounded rationality : the adaptive toolbox ( mit press , cambridge ) .",
    "bendor j , mookherjee d , ray d ( 2001 ) reinforcement learning in repeated interaction games . _",
    "martnez vaquero la , cuesta ja , snchez a ( 2012 ) generosity pays in the presence of direct reciprocity : a comprehensive study of 2@xmath572 repeated games .",
    "_ plos one _ 7:e35135 .",
    "this value is close to the initial level of cooperation observed in the experiments @xcite and otherwise represents our ignorance about the initial mood of the players .",
    "these values are also close to the ones set in the experiments@xcite .",
    "we checked that our results are robust with respect to system size and link density .",
    "here we give the details of the evolutionary dynamics that we consider in order to update the mcc behavioral parameters @xmath12 .",
    "it is important to notice that , differently from the traditional approach used in game theory where players are simply described by their individual probabilities of cooperating and defecting , in our case players strategies are defined by their three mcc parameters that determine such probabilities .",
    "hence the strategy update rules traditionally employed in the literature have to be modified accordingly . for imitative rules ,",
    "a given player @xmath58 adopts a new strategy by copying all the mcc parameters from a selected counterpart @xmath59 , which is one of the @xmath60 neighbors of @xmath58 .    _ proportional imitation _  @xmath59 is chosen randomly , but the probability that @xmath58 copies @xmath59 s parameters depends on the difference between the payoffs that they obtained in the previous round of the game through the expression @xmath61 with @xmath62 $ ] to ensure @xmath63 $ ] .",
    "this rule is well known in the literature as it brings  for a large , well - mixed population  to an evolutionary equation which is equal to that of replicator dynamics .",
    "_ fermi rule _",
    " as in proportional imitation , @xmath59 is chosen randomly , but the probability that @xmath58 copies @xmath59 s parameters depends now on the payoff difference according to the fermi distribution function : @xmath64}\\ ] ] note that the fermi rules allows for mistakes : players can copy the parameters of others who are performing worse .",
    "the fermi rule has been widely used in the literature because of being analytically tractable .",
    "_ death - birth rule _",
    " player @xmath58 copies the parameters of one of her neighbors @xmath59 , or herself s , with a probability proportional to the payoffs @xmath65 where @xmath66 is the set which includes @xmath58 and her neighbors and @xmath67 to ensure @xmath63 $ ] . again with this rule a player can adopt , with low probability , the parameters of a neighbor that has done worse than herself .",
    "_ unconditional imitation _ or `` imitate the best ''  this rule makes each player @xmath58 copy the parameters of the neighbor @xmath59 with the largest payoff , provided this payoff is greater than the player s : @xmath68    _ voter model _  @xmath58 simply copies the parameters of a neighbor @xmath59 selected at random .",
    "such update rule represents an imitation mechanism of purely social nature , which thus incorporates the effect of the social pressure . for innovative rules instead :",
    "_ best response _  here every player chooses her mcc parameters as a best response to what her neighbors did in the last round .",
    "this means that each player @xmath58 , given @xmath69 from the previous round @xmath14 , computes the payoffs that she would have obtained by cooperating or defecting , respectively : @xmath70 then if in the previous round @xmath58 defected , she tries to increase the quantity @xmath71 to do so , the players uses her current value of @xmath72 as well as two `` shifted '' values @xmath73 and @xmath74 , and pick as her new @xmath75 the one that maximizes @xmath76 ( and which satisfies @xmath77 )",
    ". instead if in the previous round @xmath58 cooperated , the quantity that she tries to increase is @xmath78 to do so , she uses the current values of @xmath79 as well as the four combinations @xmath80 , @xmath81 , @xmath82 , @xmath83 , and chooses as new parameters @xmath84 the ones that maximize @xmath85 ( and which satisfy @xmath86 ) .",
    "note that we do not use exhaustive best response ( which consists in choosing the values of @xmath26 or @xmath87 that maximize @xmath76 or @xmath85 , respectively ) as it would lead immediately to @xmath88 ( _ i.e. _ , to @xmath89 ) , which is the nash equilibrium of pd games .",
    "note also that best response belongs to a family of updating rules often referred to as _",
    "belief learning _ models . according to this family of rules ,",
    "players update beliefs about what others will do based on history , and then use those beliefs to determine which strategies lead to the best outcome . best response is restrictive in considering only last round s choices to determine the strategies . while in principle more information can be used as well , we only restrict our attention to best response for three main reasons .",
    "firstly , to have a fair comparison to the other dynamics , that only use last round s information ( being it either actions or payoffs ) . secondly because , in our non - exhaustive formulation of best response , history is contained in the current values of the mcc parameters .",
    "thirdly because in pd the dominant strategy is to defect always , so that full defection becomes the final outcome whatever information is used to build beliefs about neighbors actions",
    ".    _ reinforcement learning _",
    " when learning , players use only information about their own past choices and payoffs .",
    "parameters updating takes place in three steps .",
    "first , after each round @xmath14 of the game each player @xmath58 calculates her _ stimulus _ @xmath90 as @xmath91 where @xmath92 is the current _ aspiration level _ of player @xmath58 , and the normalization of the stimulus assures @xmath93 @xmath94 .",
    "second , each player updates her mcc parameters .",
    "note however that , whereas reinforcement learning for game theory is usually modeled as a stochastic process , in our case we have to modify the classical algorithm to account for the two - step memory of moody conditional cooperators .",
    "hence the parameters updating depends on the actions chosen at time steps @xmath14 and @xmath95 .",
    "there are four cases :    1 .   if @xmath58 defected at @xmath95 and cooperated at @xmath14 , @xmath96 2 .   if @xmath58 defected at @xmath95 and defected at @xmath14 , @xmath97 3 .   if @xmath58 cooperated at @xmath95 and cooperated at @xmath14 , @xmath98 4 .",
    "if @xmath58 cooperated at @xmath95 and defected at @xmath14 , @xmath99    where @xmath100 $ ] represents the learning rate  accounting for different @xmath32s covers for both the cases of slow and fast learning .",
    "finally , player @xmath58 may adapt her aspiration level as @xmath101 , where @xmath102 is the adaptation ( or habituation ) rate .",
    "we now discuss the robustness of our results with respect to two additional features of our numerical study : spontaneous mutations of mcc parameters , as well as a different modeling of the mcc behavior .",
    "_ mutations _  spontaneous mutations of strategies ( genotypes ) represents an important aspect of evolutionary game theory , particularly in the modeling of evolving populations of life forms . in order to validate our findings against mutations ,",
    "we introduce , for each player , a probability @xmath103 that ( after every strategy updating takes place ) one of her mcc behavioral parameters , chosen randomly , varies of a quantity drawn from a normal distribution @xmath104 $ ] .",
    "such variation is yet bounded to respected the constraints @xmath105 $ ] and @xmath106 $ ] .",
    "we observe that the introduction of spontaneous mutations does not have a significant impact on the system s behavior , unless the amount ( @xmath107 ) and frequency ( @xmath103 ) of such mutations become dominant with respect to the changes of mcc parameters given by the strategy updating . in general ,",
    "the major effect of mutations is a noisier and slower evolution ( which also causes the stationary distributions of mcc parameters to remain broader and smoother ) .",
    "moreover , the consequence of imposing a constraint on mutations is that the cooperation level increases when it was originally close to zero , and decreases when it was close to one .",
    "in particular , the fully defective state becomes inaccessible because of a minimal amount of cooperation , caused by mutations , which is proportional to @xmath107 and @xmath103 .",
    "the situation which is mostly affected by mutations is games played on lattices with the death - birth rule , where cooperation becomes unstable even for small values of @xmath103 .",
    "notably , also in the presence of mutations , reinforcement learning remains the only evolutionary dynamics which can successfully reproduce all of the experimental outcomes .",
    "_ modified mcc _",
    " in this work , according to experimental inputs , we have modeled players as moody conditional cooperators .",
    "the reader should not be misled to think that this way of modeling distinguishes players from each other .",
    "in fact , @xmath108 does not represent the strategy of a defector , but just the probability of cooperating after having defected  with no reference to a hypothetical player kind .",
    "equivalently , @xmath109 is not the strategy of a cooperator , but just the probability of cooperating after having cooperated . aside from this consideration",
    ", it is indeed possible to think of introducing a dependence on observed cooperation in the probability of cooperating after having defected : @xmath110 .",
    "while this choice does not agree well with experimental evidence , it brings to an elegant symmetry between @xmath109 and @xmath111 ; moreover , the original mcc behavior can be still recovered for @xmath112 .",
    "therefore we extend our analysis to this modified mcc behavior , observing that the cooperation level @xmath21 does not change significantly with respect to what was obtained for @xmath113 , irrespectively of the update rule employed .",
    "naturally what changes is the stationary distributions of the parameter @xmath26 ( as it is now coupled with @xmath114 ) . concerning imitative dynamics ,",
    "as expected we do not observe a stationary distribution of @xmath114 ; additionally , full defection outcomes are still due to @xmath23 ( which , together with @xmath115 , makes @xmath114 irrelevant ) .",
    "for best response , still @xmath116 together with @xmath26 and @xmath25 ; remarkably , in this case also @xmath112 ( differently from @xmath24 , which remains broadly distributed ) .",
    "finally , a stationary , non - trivial distribution of @xmath114 is again obtained only with reinforcement learning .",
    "note that @xmath114 remaining finite ( but small ) in this case is probably due to the particular formulation of the learning algorithm proposed here .",
    "here we present methods and results for the ewa ( experience - weighted attraction ) updating scheme .",
    "we recall that ewa is an evolutionary dynamics that combines belief learning ( to which best response belongs ) and reinforcement learning . while the original formulation of ewa can not be trivially generalized to our mcc scenario  where multiple parameters and neighbors actions regulate the strategies",
    ", we can still reproduce the key features of the ewa updating by a simple linear combination of best response and reinforcement learning .",
    "indeed , such formulation updates the strategies exactly like the original ewa does . at the same time , since we do not aim at quantitatively reproducing experimental outcomes , we do not need to impose any initial attractors , nor any particular experience and growth rate .",
    "we thus implement the ewa dynamics as follows . for each player @xmath58",
    ", at each updating @xmath14 we compute the shift of mcc parameters given by best response and reinforcement learning , which we denote as @xmath117 and @xmath118 , respectively",
    ". then parameters are updated as : @xmath119 where @xmath120 is the mixing parameter .",
    "note that @xmath121 and @xmath122 ( as the stimulus is such that @xmath123 ) , thus for the two terms to be comparable we usually choose @xmath124 .",
    "results for the ewa updating are shown in fig .",
    "[ fig.c_ewa ] .",
    "we observe that , when the drift to full defection due to best response is not dominant ( @xmath125 ) , the cooperation level lies midway between the ones obtained separately by best response and reinforcement learning .",
    "stationary distributions of mcc parameters do exist , but they are narrower and , except for the parameter @xmath24 , concentrate on smaller values than with reinforcement learning alone .",
    "we can conclude that ewa updating brings to situations that are compatible with experimental outcomes , provided that the contribution from reinforcement learning remains dominant ."
  ],
  "abstract_text": [
    "<S> cooperative behavior lies at the very basis of human societies , yet its evolutionary origin remains a key unsolved puzzle . whereas reciprocity or conditional cooperation is one of the most prominent mechanisms proposed to explain the emergence of cooperation in social dilemmas , recent experimental findings on networked prisoner s dilemma games suggest that conditional cooperation also depends on the previous action of the player  </S>",
    "<S> namely on the ` mood ' in which the player currently is . </S>",
    "<S> roughly , a majority of people behaves as conditional cooperators if they cooperated in the past , while they ignore the context and free - ride with high probability if they did not . </S>",
    "<S> however , the ultimate origin of this behavior represents a conundrum itself . here </S>",
    "<S> we aim specifically at providing an evolutionary explanation of moody conditional cooperation . to this end </S>",
    "<S> , we perform an extensive analysis of different evolutionary dynamics for players behavioral traits  ranging from standard processes used in game theory based on payoff comparison to others that include non - economic or social factors . </S>",
    "<S> our results show that only a dynamic built upon reinforcement learning is able to give rise to evolutionarily stable moody conditional cooperation , and at the end to reproduce the human behaviors observed in the experiments .    </S>",
    "<S> cooperation and defection are at the heart of every social dilemma @xcite . while cooperative individuals contribute to the collective welfare at a personal cost , defectors choose not to . due to the lower individual fitness of cooperators arising from that cost of contribution , selection pressure acts in favor of defectors , thus making the emergence of cooperation a difficult puzzle . </S>",
    "<S> evolutionary game theory @xcite provides an appropriate theoretical framework to address the issue of cooperation among selfish and unrelated individuals . at the most elementary level , many social dilemmas can be formalized as two - person games where each player can either cooperate ( c ) or defect ( d ) . </S>",
    "<S> the _ </S>",
    "<S> prisoner s dilemma _ game ( pd ) @xcite has been widely used to model a situation in which mutual cooperation leads to the best outcome in social terms , but defectors can benefit the most individually . in mathematical terms , this is described by a payoff matrix ( entries correspond to the row player s payoffs ) @xmath0 where mutual cooperation yields the reward @xmath1 , mutual defection leads to punishment @xmath2 , and the mixed choice gives the cooperator the sucker s </S>",
    "<S> payoff @xmath3 and the defector the temptation @xmath4 . </S>",
    "<S> the essence of the dilemma is captured by @xmath5 : both players prefer any outcome in which the opponent cooperates , but the best option for both is to defect </S>",
    "<S> . in particular , the temptation to cheat ( @xmath6 ) and the fear of being cheated ( @xmath7 ) can put cooperation at risk , and according to the principles of darwinian selection , cooperation extinction is inevitable @xcite .    despite the conclusion above , cooperation is indeed observed in biological and social systems alike @xcite . </S>",
    "<S> the evolutionary origin of such cooperation hence remains a key unsolved issue , particularly because the manner in which individuals adapt their behavior  which is usually referred to as evolutionary dynamics or strategy update  is unknown a priori . </S>",
    "<S> traditionally , most of the theoretical studies in this field have built on update rules based on payoff comparison @xcite @xcite . </S>",
    "<S> while such rules fit in the framework of biological evolution , where payoff is understood as fitness or reproductive success , they are also questionable , especially from an economic perspective , as it is often the case that individuals perceive the others actions but not how much they benefit from them . indeed , experimental observations @xcite ( with some exceptions @xcite , but see also the reanalysis of those data in @xcite ) point out that human subjects playing pd or public good games do not seem to take payoffs into consideration . </S>",
    "<S> instead , they respond to the cooperation that they observe in a reciprocal manner , being more prone to contribute the more their partners do .    reciprocity @xcite has been studied in 2-player games through the concept of reactive strategies @xcite , the most famous of which is _ tit - for - tat _ </S>",
    "<S> @xcite ( given by playing what the opponent played in the previous run ) . </S>",
    "<S> reactive strategies generalize this idea by considering that players choose their action with probabilities that depend on the opponent s previous action . a further development was to consider memory - one reactive strategies @xcite , </S>",
    "<S> in which the probabilities depend on the previous action of both the focal player and her opponent . in multiplayer games , conditional cooperation , _ </S>",
    "<S> i.e. _ , the dependence of the chosen strategy on the amount of cooperation received , had been reported in related experiments @xcite and observed also for the spatial iterated pd @xcite ( often along with a large percentage of free - riders ) . </S>",
    "<S> the analysis of the two largest - scale experiment to date with humans playing an iterated multiplayer pd game on a network @xcite extended this idea by including the dependence on the focal player s previous action , giving rise to the so - called _ moody conditional cooperation _ </S>",
    "<S> ( mcc ) .    the mcc strategy can be described as follows @xcite : if in the previous round the player defected , she will cooperate with probability @xmath8 ( approximately independently of the observed cooperation ) , whereas , if she cooperated , she will cooperate again with a probability @xmath9 ( subject to the constraint @xmath10 ) , where @xmath11 is the fraction of cooperative neighbors in the previous round . </S>",
    "<S> there is ample evidence supporting this aggregate behavior , as it has been observed in at least five independent experiments : the two already quoted @xcite ; another one on multiplayer pd @xcite ; a lab - in - the - field experiment with people attending a fair in barcelona , where participants in the age range 17 - 87 behaved consistently according to the mcc strategy @xcite , and finally , in @xcite , as revealed by a recent meta - analysis of those experimental results @xcite . on the other hand </S>",
    "<S> , it could be argued that mcc behavior arises from learning processes experienced by the players . in this respect , it is true that when a number of iterations of the pd is regarded as a single supergame , repetitions of such supergame show changes in behavior @xcite . </S>",
    "<S> this is in agreement with the observations in @xcite , where two repetitions of the supergame were carried out with the same players ( experiments 1 and 2 in the reference ) , and it was found that the initial behavior was indeed different in both . </S>",
    "<S> however , analysis that exclude the first few rounds of those experiments show clear evidence for mcc behavior which , if anything , becomes even more marked in the second one . </S>",
    "<S> similar analysis were carried out in all other experiments , precisely to check for the effects of learning , finding in all cases strong evidence in support of the mcc strategy , even in @xcite , where 100 iterations of the pd were played . </S>",
    "<S> therefore , we are confident that the observation of mcc behavior is reproducible and correctly interpreted , and we believe it is a good framework to study the problem as we propose here . </S>",
    "<S> however , from the viewpoint of ultimate origins and evolutionary stability of this kind of behavior , conditional cooperation and its moody version are a puzzle themselves . for instance , theoretical results based on replicator dynamics show that the coexistence of moody conditional cooperators with free - riders is not possible beyond very small groups @xcite . additionally , whereas the strategies reported in @xcite are aggregate behaviors , it is not clear how individual mcc behavioral profiles @xmath12 evolve in time and how many evolutionarily stable profiles can exist among the players .    here </S>",
    "<S> we aim precisely at addressing these issues by developing and studying a model for the evolutionary dynamics of mcc behavioral traits . to this end </S>",
    "<S> , we perform agent - based simulations of a population consisting of @xmath13 differently - parameterized moody conditional cooperators , either on a well - mixed population or placed on the nodes of a network , who play an iterated pd game with their neighbors ( which is the same setting used in recent experiments @xcite ) and whose behavioral parameters @xmath12 are subject to a strategy update process . specifically , during each round @xmath14 of the game each player selects which action to take ( c or d ) according to her mcc traits , then plays a pd game with their neighbors  the chosen action being the same with all of them  and collects the resulting payoff @xmath15 . </S>",
    "<S> subsequently , every @xmath16 rounds players may update their mcc parameters according to a given evolutionary rule .    </S>",
    "<S> the key and novel point in this study is that we explore a large set of possible update rules for the mcc parameters , whose details are given in si materials and methods . to begin with , the first set of rules that we consider are of imitative nature , in which players simply copy the parameters from a selected counterpart . </S>",
    "<S> imitation has been related to bounded rationality or to a lack of information that forces players to copy the strategies of others @xcite . </S>",
    "<S> the rules that we consider here cover different aspects of imitation . </S>",
    "<S> thus , we study the classical imitative dynamics that are based on payoff comparison : stochastic rules as _ proportional imitation _ </S>",
    "<S> @xcite ( equivalent , for a large and well - mixed population , to the replicator dynamics @xcite ) , the _ fermi rule </S>",
    "<S> _ @xcite ( featuring a parameter @xmath17 that controls the intensity of selection , and that can be understood as the inverse of temperature or noise in the update rule @xcite ) and the _ death - birth rule _ ( inspired on moran dynamics @xcite ) , as well as the deterministic dynamics given by _ unconditional imitation _ ( also called `` imitate the best '' ) @xcite . in all these cases , players decide to copy one of their neighbors with a probability ( that may be 1 , _ </S>",
    "<S> i.e. _ , with certainty ) that depends in a specific manner on the payoffs that they and their partners obtained in the previous round of the game . to widen the scope of our analysis </S>",
    "<S> , we also analyze another imitative mechanism that is not based on payoff comparison , namely the _ voter model _ </S>",
    "<S> @xcite , in which players simply follow the social context without any strategic consideration @xcite . finally , in order to go beyond pure imitation </S>",
    "<S> , we also consider another two evolutionary dynamics which are innovative , meaning that they allow extinct strategies to be reintroduced in the population ( whereas imitative dynamics can not do that ) . </S>",
    "<S> the first one is _ </S>",
    "<S> best response _ </S>",
    "<S> @xcite , a rule that has received a lot of attention in the literature , especially in economics , and that represents a situation in which each player has enough cognitive abilities to compute an optimum strategy given what her neighbors did in the previous round . </S>",
    "<S> the second one is _ </S>",
    "<S> reinforcement learning _ </S>",
    "<S> @xcite , which instead embodies the condition of a player that uses her experience to choose or avoid certain actions based on their consequences : actions that met or exceeded aspirations in the past tend to be repeated in the future , whereas choices that led to unsatisfactory experiences are avoided . </S>",
    "<S> note that neither of these two last rules relies on the use of information on others payoffs .    with the different update schemes that we have summarized above </S>",
    "<S> , we have an ample spectrum of update rules representing most of the alternatives that have been proposed to implement evolutionary dynamics . </S>",
    "<S> the point of considering such comprehensive set is directly related to our aim : finding how evolution , in a broad sense , can give rise to situations that are compatible with the ones seen in the experiments @xcite , in terms of values and stationarity of the mcc parameters , as well as of the final level of cooperation achieved . </S>",
    "<S> additionally , we study different spatial structures determining the interactions among the players : the simple setup of a well - mixed population ( modeled by a random graph of average degree @xmath18 , rewired after each round of the game ) , as well as more complex structures  such as barabsi - albert scale free network @xcite ( with degree distribution @xmath19 ) and regular lattices with periodic boundary conditions ( where each node is connected to its @xmath20 nearest neighbors ) as used in the available experimental results . in so doing , we add another goal to our research , namely to check whether evolution can also explain the observed lack of _ network reciprocity _ </S>",
    "<S> @xcite , which is another important experimental outcome @xcite . indeed , </S>",
    "<S> experimental results show very clearly that , when it comes to human behavior , the existence of an underlying network of contacts does not have any influence on the final level of cooperation </S>",
    "<S> . therefore , any evolutionary proposal to explain the way subjects behave in the experiments must also be consistent with this additional observation . </S>"
  ]
}