{
  "article_text": [
    "by the hopfield model of a neural network we mean a dynamic system of @xmath1 interacting `` agents '' .",
    "the agents can take only two values @xmath2 , and they are connected with each other by the hebb connection matrix @xmath3 the matrix @xmath4 is @xmath5-matrix whose @xmath1-dimensional rows are the memorized patterns used for the network learning .",
    "let us consider the following meaningful problem : a network had to be taught by @xmath0-time presentations of _ the standard _ , but errors crept into the learning process and , in fact , the network was taught by @xmath0 distorted copies of the standard .",
    "what is the distortion s influence on the result of the learning ?",
    "we formalize the problem choosing the matrix @xmath4 in the form , @xmath6 the @xmath1-dimensional rows of the matrix @xmath4 , @xmath7 are treated as @xmath0 distorted copies of _ the standard _",
    "@xmath8 the real number @xmath9 is called _ the distortion parameter_.    our goal is to find out how the set of fixed points depends on the distortions of the standard ( because the set of fixed points represents the `` memory '' of the network ) . in other words ,",
    "we investigate the ability of the hopfield model to generalization @xcite in the specific case of one distorted standard .    only the first @xmath0 coordinates of the standard",
    "are distorted , and the remained @xmath10 coordinates are not distorted . the problem ( 1)-(4 ) is discussed in section 2",
    ". of course , the distortions are rather specific : for each memorized pattern only one coordinate of the standard is distorted and the value of the distortion @xmath9 is the same for all the memorized patterns . in the next sections we generalize this simple model .",
    "the asynchronous dynamics of the network is supposed .",
    "the state of the network as a whole is described by _ the configuration vector _",
    "the problem ( 1)-(4 ) will be called _ the basic model_. it was investigated in detail in @xcite .",
    "the results of @xcite are summarized in items a)-c ) .",
    "_ a necessary condition for a configuration vector to be a fixed point is that its last @xmath12 coordinates be equal to each other .",
    "_    consequently , fixed points can be chosen in the form @xmath13 here , @xmath14 is the @xmath0-dimensional part of the configuration vector @xmath15 .",
    "this @xmath0-dimensional vector will be used below .",
    "* b ) . * _ if a vector @xmath15 ( 5 ) is a fixed point , then every configuration vector of the form ( 5 ) whose distance from the standard is the same as the distance of @xmath15 is a fixed point .",
    "_    consequently , we have to divide all the set of @xmath16 vectors @xmath15 into _ classes _ @xmath17 joining vectors equidistant from the standard . for the standard",
    "@xmath18 these classes are @xmath19 the number of the classes @xmath20 is equal to @xmath21 .",
    "the number of the vectors in the class @xmath20 is equal to @xmath22 .",
    "the configuration vectors from the same class @xmath20 are the fixed points simultaneously .",
    "* c ) . *    _ when @xmath9 increases from @xmath23 to @xmath24 , in consecutive order the set of the fixed points is exhausted by the classes @xmath25 the @xmath26th rebuilding from the class @xmath27 to the class @xmath20 occurs at the point @xmath28 : @xmath29 where _",
    "@xmath30\\right)= \\left\\{\\begin{array}{cl}p,&\\mbox {   when } \\frac{p-1}{n-1}<\\frac13;\\\\ \\left[\\frac{n+p+2}4\\right],&\\mbox { when } \\frac{p-1}{n-1}>\\frac13 .",
    "\\end{array}\\right.\\eqno(8)\\ ] ] in fig.1 the graphical illustration of theorem 1 is shown .",
    "the case @xmath31 worth to be mentioned specially .",
    "here all the rebuilding points @xmath28 stick to one point , @xmath32.\\eqno(9)\\ ] ] for any @xmath9 from the left side of @xmath33 there is only one fixed point .",
    "it is the standard @xmath34 . for @xmath9 from the right side of @xmath33",
    "every configuration vector from the class @xmath35}$ ] is the fixed point ; in other words , in this region there are @xmath36}$ ] fixed points .",
    "@xmath37 the standard @xmath18 can be replaced by an arbitrary configuration vector @xmath38 in this case the memorized patterns have the form @xmath39 all the statements of items a)-c ) remain valid , but now the vectors @xmath15 ( 5 ) have the form @xmath40 thus , @xmath18 can be used as the standard without the loss of generality .",
    "@xmath41 suppose the memorized patterns are obtained from the standard @xmath18 by _ identical and simultaneous _ distortions of its @xmath42 ( but not only one ! ) coordinates , @xmath43 of course , now @xmath44 .",
    "it is not difficult to show that the fixed points have the form of the piecewise constant vectors @xmath45 as above these vectors are grouped into classes @xmath46 analogous to the classes @xmath20 ( 6 ) .",
    "the only difference is that now the value @xmath47 has to be assigned not to a separate coordinate @xmath48 , but to @xmath42 coordinates of the same name .",
    "again , the number of the vectors @xmath15 in the class @xmath46 is equal to @xmath49",
    ". then we have the generalization of the theorem 1 :    _ the value of the parameter @xmath9 corresponding to the @xmath26th rebuilding from the class @xmath50 to the class @xmath46 is _ @xmath51\\right).\\ ] ]    @xmath52 the memorized patterns ( 3 ) can be rotated as a whole .",
    "suppose the rotation matrix @xmath53 acts on the first @xmath0 coordinates of @xmath1-dimensional vectors only .",
    "then the standard takes the form @xmath54 where @xmath55 in eq.(10 ) the vector @xmath56 is the @xmath0-dimensional part of new standard @xmath57 ( the same as the vector @xmath58 in eq.(5 ) is the @xmath0-dimensional part of the vector @xmath15 ) .",
    "it is easy to see that @xmath59 .    at the same time",
    ", the memorized patterns ( 3 ) take the form @xmath60 the elements of the relevant connection matrix @xmath61 are @xmath62 and the matrix elements @xmath63 are determined by eqs.(1),(2 ) .",
    "let us suppose that the standard @xmath18 remains unchanged after the rotation : @xmath64 because the connection matrix @xmath61 coincides with the initial matrix @xmath65 , all the statements of the items a)-c ) of the basic model remain unchanged too .",
    "note , here all the first @xmath0 coordinates of the memorized patterns ( 12 ) are distorted .",
    "consequently , we succeeded in getting rid of one of the limitation of the basic model ( see introduction ) .",
    "it is well - known @xcite , that _ an energy _",
    "@xmath66 can be associated with every state @xmath67 of a network .",
    "the energy decreases during the network evolution .",
    "the fixed points are the local minima of the energy @xmath68 . a fixed point that is the global minimum of the energy",
    "is called _ the ground state _ of a network .",
    "it is not difficult to show that for the cases discussed above , all the states that are the fixed points simultaneously have the same energies . in other words , every time the set of fixed points is the ground state of the network , and there are no local extremums .",
    "this is due to the symmetry of the problems in question . when the symmetry of the problem is reduced , it is possible that different fixed points have different energies .",
    "often just the ground state is of interest , because its energy is minimal . from my point of view",
    "namely the ground state has to be treated as the result of learning .",
    "only the ground state is discussed in this section .",
    "@xmath37 let us examine the problem of the item @xmath69 from the previous section for the case when the standard @xmath18 changes due to rotation : @xmath70 again , as in the item a ) , only configuration vectors @xmath15 ( 5 ) can be the fixed points .",
    "again , the statement of the item b ) is valid , however now it is true not for all the fixed points , but for the ground state of the network only :    _ if a vector @xmath15 ( 5 ) is a ground state , then every configuration vector of the form ( 5 ) whose distance from the standard @xmath57 is the same as the distance of @xmath15 is a ground state . _    consequently , we have to divide the set of the vectors @xmath15 into classes joining the vectors that are equidistant from the standard @xmath57 . only now the vectors that are equidistant from @xmath57 are vectors @xmath15 with the same value of the cosine of the angle between @xmath0-dimensional vectors @xmath58 and @xmath56 , @xmath71 let the vectors @xmath15 be grouped into classes @xmath72 , @xmath73 where @xmath74 is the number of the different values of the cosine ( 13 ) . without loss of generality",
    "we can assume that the cosines are arranged in decreasing order , @xmath75 then it is easy to see , that @xmath76 .",
    "therefore , the cosines are negative beginning from some number @xmath26 . finally , the generalization of the theorem 1 from the item c ) is :    _ when @xmath9 increases from @xmath23 to @xmath24 , in consecutive order the ground state is exhausted by the classes @xmath77",
    "the @xmath26th rebuilding of the ground state from the class @xmath78 to the class @xmath79 occurs at the point @xmath28 , @xmath80 , \\",
    "k=1,2,\\ldots , k_{max}.\\eqno(14)\\ ] ] if @xmath81 , then @xmath82 . if @xmath83 , the rebuildings come to an end when the denominator in eq.(14 ) becomes negative ( @xmath84 ) .",
    "_    when the distortion @xmath9 belongs to the interval @xmath85 , all the configuration vectors from the class @xmath79 are the ground state of the network .",
    "but the compositions of the classes @xmath79 are determined by the values of @xmath86 ( 11 ) only . and",
    "the choice of @xmath86 is in the researcher s hand .",
    "in other words , selecting @xmath86 and the distortion parameter @xmath9 , the network with a preassigned ground state can be created .",
    "for example , let us create a network with the ground state @xmath87 at first we need to find the vector @xmath57 of the form ( 10 ) equidistant from the vectors @xmath88 and @xmath89 ( and only from these vectors ! ) .",
    "this problem has a lot of solutions .",
    "for example , we can take the vector @xmath57 in the form of @xmath90 the minimal @xmath0 satisfying this equation is equal to @xmath91 .",
    "consequently , we have @xmath92 next , @xmath93 configuration vectors @xmath15 ( 5 ) split into classes @xmath79 , which join the vectors equidistant from the found standard @xmath57 . one of these classes consists from our vectors @xmath94 and @xmath89 exactly .",
    "it is not difficult to determine the number of this class .",
    "indeed , the first four values of the cosines ( 13 ) and the relevant classes @xmath72 are : @xmath95 thus , the class @xmath96 contains the given configuration vectors @xmath97 , @xmath98 and @xmath89 only .",
    "if we take four memorized patterns of the form ( 12 ) and the distortion parameter @xmath9 inside the interval @xmath99 , the relevant network has the preassigned ground state .    to define the memorized patterns @xmath100",
    ", we need the matrix elements @xmath101 of the rotation matrix @xmath102 . this matrix transforms the vector @xmath18 into the standard @xmath57 .",
    "more exactly , it is necessary to know only the upper @xmath103-block of this matrix realizing the nontrivial part of the rotation .",
    "in other words , it is necessary to solve the problem @xmath104 this problem has a lot of solutions . for example , @xmath105 consequently , as the memorized patterns ( 12 ) @xmath106-dimensional vectors @xmath107 can be used . if @xmath9 is from the interval @xmath108 , the configuration vectors @xmath97 , @xmath98 and @xmath89 are the ground state of the hopfield network with the connection matrix ( 1 ) .",
    "the minimal @xmath1 for such a network is equal to @xmath109 , @xmath110 .",
    "this corresponds to @xmath111 .",
    "if @xmath112 , we have the equality @xmath31 , and , consequently , all the rebuilding points stick to the point @xmath33 ( see the comment to eq.(9 ) ) .",
    "@xmath41 suppose the asynchronous dynamics is defined as @xmath113 where the connection matrix @xmath65 is given by eqs.(1),(2 ) .",
    "the parameter @xmath114 is called _ the dynamic threshold _ @xcite .",
    "usually , in theoretical considerations it is used to eliminate the linear term in the energy @xmath68 ( such a term appears when we turn from the @xmath115-network to the @xmath116-network ) . apparently , the role of the dynamic threshold is much more important . in @xcite",
    "the case of @xmath117 is analyzed in details .",
    "for the sake of simplicity , here i present the results obtained for @xmath118 only .",
    "_ let @xmath119 .",
    "when @xmath114 increases from its initial zero value to infinity , in consecutive order the ground state of a network is exhausted by the classes @xmath120 the rebuilding of the ground state from the class @xmath121 to the class @xmath122 occurs when @xmath114 is equal to _ @xmath123 here , the classes @xmath20 are defined by eq.(6 ) and the rebuilding points @xmath28 are given by eq.(7 ) . in fig.2 for some values of @xmath0 and @xmath1 the phase diagram for the ground state is shown .",
    "we see that changing @xmath114 purposefully , we can change the ground state significantly .",
    "in particular , the standard @xmath124 can be done the ground state of the network .",
    "it is important to understand either this result depends on the specific form of our connection matrix , or it is more general . in other words , is it possible to choose the thresholds in the general hopfield model in such a way that memorized patterns will necessarily be its fixed points ?",
    "the positive answer seems to be very probable .",
    "@xmath52 i generalize the basic model for the case of different distortions of all the memorized patterns @xcite : @xmath125 suppose , that @xmath126 and @xmath127 is the number of positive distortions @xmath128 .",
    "theorem 3 is an analog of the statements a)-c ) from the basic model .    *",
    "a ) * _ only configuration vectors @xmath129 can be the ground state , where _ @xmath130\\right).\\ ] ]    * b ) * _ for the vector @xmath131 to be a ground state , it is necessary and sufficient to have _ @xmath132    the inequalities ( 16 ) are very useful .",
    "for example , suppose @xmath133 , and @xmath1 is so large that in eq.(16 ) the terms containing @xmath1 in the denominators can be omitted .",
    "then , the statement b ) is simplified : @xmath134 in particular , @xmath135 these statements are very interesting .",
    "namely , eqs.(17 ) and ( 18 ) connect the quality of learning with the relation between the number of presentations @xmath0 of the standard and the values of distortions . (",
    "the distortions are measured in bits . ) in particular , eq.(18 ) means that the network understands the standard @xmath136 correctly , if and only if the number of its presentations @xmath0 exceeds the maximum distortion @xmath137 .",
    "it seems , this result clarifies qualitatively why the well - known latin saying _ `` repetitio est mater studiorum '' _ is true . indeed , to be sure that a network with the hebb connection matrix understands a standard , we have to show it repeatedly . also , we must be sure that the number of presentations @xmath0 is greater than the maximal distortion @xmath137 .",
    "since usually the distortions are gaussianly distributed , the last requirement can be realized always .",
    "next , we can rewrite the inequalities ( 16 ) in the form @xmath138 where @xmath139 sometimes eqs.(19 ) are more suitable , since they relate the distortions @xmath140 with the rebuilding points @xmath28 from eq.(7 ) .",
    "when the distortions are known , with the aid of eqs.(19 ) the ground state can be easily found graphically .",
    "let us clarify the last statement with the aid of a simple example .",
    "let @xmath141 and @xmath1 is so large that @xmath142 and @xmath143 .",
    "only one of the configuration vectors @xmath144 of the form ( 15 ) can be the ground state .",
    "we make use of eq.(19 ) .",
    "we write down the necessary and sufficient conditions for each @xmath131 to be a ground state ( here @xmath145 can be omitted ) : @xmath146 next , let the rebuilding points @xmath28 and the distortions @xmath140 be located as it is shown in fig.3 . since only for @xmath147 the inequalities ( 19 ) are fulfilled , the vector @xmath148 is the ground state .",
    "we present rigorous results relating to the model ( 1)-(4 ) and its generalizations .",
    "computer simulations confirm these results .",
    "the proofs of the statements of sections 2 - 4 are in @xcite , @xcite , @xcite .",
    "a meaningful interpretation of the obtained results can be found in the same references . in the present publication",
    "we do not include this topic deliberately with the exception of `` the proof '' of the latin saying .",
    "the author is grateful to prof .",
    "alexandr ezhov for helpful discussions and to dr .",
    "inna kaganova for preparation of the manuscript .",
    "wonderful atmosphere and personal contacts with the members of workshop `` statistical physics of neural networks '' ( max - plank - institute of physics of complex systems , march 1999 , dresden , germany ) helped the author in the understanding of the obtained results .    99 j.f.fontanari .",
    "`` generalization in a hopfield network '' , _ journal de physique ( france ) _ , 1990 ,",
    "v.51 , pp.2421 - 2430 .",
    "`` high - symmetry hopfield - type neural networks '' , _ theoretical and mathematical physics _ , kluwer academic / plenum publishers , 1999 , v.118 , pp . 107 - 127 .",
    "cond - mat/9906197 .",
    "j.hertz , a.krogh , r.palmer .",
    "_ introduction to the theory of neural computation _",
    ", addison - wesley , 1991 .",
    "`` hopfield model with threshold '' , _ theoretical and mathematical physics _ ( 2001 , in press )",
    ". l.b.litinskii .",
    "( in preparation ) .      * fig.1 . * the rebuilding points @xmath28 from eq.(7 )",
    "divide the axis @xmath9 into intervals inside which the set of the fixed points belongs to different classes @xmath20 ( see theorem 1 ) .",
    "* fig.2 . *",
    "the straight lines @xmath149 from theorem 2 divide the half - plane @xmath150 into regions inside which the ground state belongs to different classes @xmath151 ; @xmath152 .",
    "* fig.3 . * the example of the location of the rebuilding points @xmath28 from eq.(7 ) and the different distortions @xmath140 from theorem 3 ."
  ],
  "abstract_text": [
    "<S> _ for the hopfield model with the hebb connection matrix we investigate the case of @xmath0 memorized patterns that are distorted copies of the same _ standard_. in other words , we try to simulate that learning always takes place by means of repeating presentations of one and the same standard , and the presentations are accompanied by distortions of the standard . </S>",
    "<S> we obtain some rigorous results relating to the dependence of the fixed points on external parameters of the problem . _    = -12.5 mm = -20 mm = 10000 = 10000 </S>"
  ]
}