{
  "article_text": [
    "many situations and processes of interest to scientists involve individuals interacting with each other , such that causes of the behavior of one individual are also indirect causes of the behaviors of other individuals ; that is , there are _ peer effects _ or _ social interactions _ @xcite .",
    "likewise , in applied work , the policies considered by decision - makers often have many of their effects through the interactions of individuals .",
    "examples of such cases are abundant . in online social networks ,",
    "the behavior of a single user explicitly and by design affects the experiences of other users in the network .",
    "if an experimental treatment changes a user s behavior , then it is reasonable to expect that this will have some effect on their friends , a perhaps smaller effect on their friends of friends , and so on out through the network . in an extreme case ,",
    "treating one individual could alter the behavior of everyone in the network .    to see the challenges this introduces ,",
    "consider what is , in many cases , a primary quantity of interest for experiments in networks  the average treatment effect  ( ate ) of applying a treatment to all units compared with applying a different ( control ) treatment to all units .",
    "let @xmath0 be a vector of length @xmath1 giving each unit s treatment assignment , so that @xmath2 is the potential outcome of interest for unit @xmath3 when @xmath0 is set to @xmath4 .",
    "then the ate is a contrast between two such treatment vectors , @xmath5,\\ ] ] where @xmath1 is the number of units and @xmath6 and @xmath7 are two treatment assignments vectors ; the prototypical case has @xmath8 and @xmath9 , the vectors of all ones and of all zeros .",
    "note that each unit s potential outcome is a function of the global treatment assignment vector @xmath0 , not just its own treatment @xmath10 .",
    "additional assumptions will thus be required for @xmath11 to be identifiable .",
    "the standard approach is to assume that each unit s response is not affected by the treatment of any other units .",
    "versions of this assumption are sometimes called the _ stable unit treatment value assumption _ ( sutva ; * ? ? ?",
    "* ) or a _ no interference _ @xcite assumption . combined with random assignment to treatment ,",
    "this suffices to identify @xmath11 .",
    "however , for many processes and situations of interest the units are interacting , and sutva becomes implausible @xcite .    rather than substituting other strong assumptions about interference",
    ", this paper considers how we can reduce bias for the ate through both the choice of experimental design and analysis when interactions among units occur along an observed network .",
    "the design of the experiment dictates how each vertex in the network ( i.e. , unit ) is assigned to a condition , and the analysis says how the observed responses are combined into estimates of causal quantities of interest .",
    "we study these methods by formalizing the process of experimentation in networks , proving sufficient conditions for bias reduction through design and analysis , and running extensive simulations .",
    "we can not consider all possible designs and analysis , but limit this work to some relatively general methods for each .",
    "we consider experimental designs that assign clusters of vertices to the same treatment ; this is _ graph cluster randomization _ @xcite .",
    "since the counterfactual situations of interest involve all vertices being in the same condition , the intuition is that assigning a vertex and vertices near it in the network into the same condition , the vertex is `` closer '' to the counterfactual situation of interest . for analysis methods , we consider methods that define _ effective treatments _ such that only units that are effectively in global treatment or global control are used to estimate the ate .",
    "for example , an estimator for the ate might only compare units in treatment that are surrounded by units in treatment with units in control that are surrounded by units in control .",
    "the intuition is that a unit that meets one of these conditions is `` closer '' to a counterfactual situation of interest .",
    "the rest of the paper is structured as follows .",
    "we briefly review some related work on experiments in networks . section [ sec : model ] presents a model of the process of experimentation in networks , including initialization of the network , treatment assignment , outcome generation , and analysis .",
    "this formalization allows us to develop theorems giving sufficient conditions for bias reduction . to develop further understanding of the magnitude of the bias and error reduction in practice , section [ sec : simulations ] presents simulations using networks generated from small - world models and then degree - corrected blockmodels .",
    "we find that graph cluster randomization is capable of dramatically reducing bias compared to independent assignment without adding `` too much '' variance .",
    "the benefits of graph cluster randomization are larger when the network has more local clustering and when social interactions are strong .",
    "if social interactions are weak or the network has little local clustering , then the benefits of the more complex graph - clustered design are reduced . finally , we found larger bias and error reductions through design than analysis : analysis strategies using neighborhood - based definitions of effective treatments does further reduce bias , but often at a substantial cost to precision such that the simple estimators were preferable in terms of error .",
    "no combination of design and analysis is expected to work well across very different situations , but these general insights from simulation can be a guide to practical real - world experimentation in the presence of peer effects .",
    "furthermore , by identifying sufficient conditions for bias reduction , we can understand when design and analysis changes will at least not increase bias .",
    "much of the literature on interference between units focuses on situations where there are multiple independent groups , such that there are interactions within , but not between , groups ( e.g. , * ? ? ? * ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "some more recent work has examined interference in networks more generally @xcite , where this between - groups independence structure can not be assumed .",
    "this prior work has largely focused on assuming restrictions on the extent of interference ( e.g. , vertices are only affected by the number of neighbors treated ) and then deriving results for designs and estimators motivated by these same assumptions . @xcite",
    "give unbiased estimators for ates under these assumptions and derive variance estimators .",
    "@xcite show that graph clustered randomization puts more vertices in the conditions required for these estimators , such that the variance of these estimators is bounded for certain types of networks .",
    "but , as noted by @xcite and as we discuss in section [ sec : implausibility ] below , the very processes expected to produce interference also make these assumptions implausible .",
    "the present work explicitly considers more realistic data generating processes that violate these restrictive assumptions .",
    "that is , in contrast to prior work , we evaluate design and analysis strategies under conditions other than those under which they have particular desirable properties ( e.g. , unbiasedness ) .",
    "instead , we settle for reducing bias and error .",
    "we consider experimentation in networks as consisting of four phases : ( i ) _ initialization _ , ( ii ) _ treatment assignment _ , ( iii ) _ outcome generation _ , and ( iv ) _",
    "estimation_. a single run through these phases corresponds to a single instance of the experimental process .",
    "treatment assignment embodies the experimental design , and the estimation phase embodies the analysis of the network experiment .",
    "these same phases , shown in figure  [ diagram ] , are implemented in our simulations in which we instantiate this process many times .",
    "initialization is everything that occurs prior to the experiment .",
    "this includes network formation and the processes that produce vertex characteristics and prior behaviors . in some cases",
    ", we may regard this initialization process as random , and so wish to understand design and analysis decisions averaged over instances of this process ; for example , we may wish to average over a distribution of networks that corresponds to a particular network formation model . in the simulations later in this paper",
    ", we generate networks from small - world models @xcite and degree - corrected blockmodels @xcite . in other cases",
    ", we may regard the outcome of this process as fixed ; for example , we may be working with a particular network and vertices with particular characteristics , which we wish to condition on in planning our design and analysis .",
    "when initialization is complete , we have a particular network @xmath12 with adjacency matrix @xmath13 .",
    "in addition to producing a graph , the initialization process could also produce a collection of vertex characteristics @xmath14 that may or may not relate to the structure of the graph , but may play a role in outcome generation .",
    "the treatment assignment phase creates a mapping from vertices to treatment conditions .",
    "we only consider a binary treatment here ( i.e. , an `` a / b '' test ) , so the mapping is from vertex to treatment or control . treatment assignment normally involves independent assignment of units to treatments , such that one unit s assignment is uncorrelated with other units assignments . in this case , each unit s treatment is a bernoulli random variable @xmath15 with probability of assignment to the treatment @xmath16 .",
    "the present work evaluates treatment assignment procedures that produce assignments with network autocorrelation .",
    "while many methods could produce such network autocorrelation , we work with graph cluster randomization , in which the network is partitioned into clusters and those clusters are used to assign treatments .",
    "let the vertices be partitioned into @xmath17 clusters @xmath18 , and define @xmath19 as mapping vertex indices to cluster indices .",
    "thus @xmath20 refers to a cluster by its index , while @xmath21 refers to the cluster containing vertex @xmath3 .    in standard graph cluster randomization ,",
    "as presented by @xcite , treatments are assigned at the cluster level , where each cluster @xmath22 is assigned a treatment @xmath23 .",
    "thus the treatments assigned to vertices are simply those assigned to their clusters , @xmath24 for some estimands and analyses , assigning all vertices in a cluster to the same treatment can make it impossible for some vertices to be observed with , e.g. , some particular number of treated peers",
    ". this can violate the requirement that all units have positive probability of assignment to all conditions .",
    "for this reason , it can be desirable to use an assignment method that allows for some vertices to be assigned to a different treatment than the rest of its cluster ; we describe such a modification in appendix [ appendix : hole_punching ] .",
    "graph cluster randomization could be applied to any mapping @xmath25 of vertices to clusters .",
    "one such mapping , which we use for the simulations reported in this paper , is formed by @xmath26-net clustering as previously considered by @xcite .",
    "an @xmath26-net in the graph distance metric is a set of vertices such that no two vertices in the set are less than @xmath26 hops of each other , and every vertex outside the set is within @xmath26 hops ( in fact , @xmath27 hops ) of a vertex in the set .",
    "an @xmath26-net can be formed by repeatedly selecting a vertex and removing it and every vertex within distance @xmath27 from the network , until all vertices have been removed .",
    "having completed this step , the population of selected vertices forms an @xmath26-net .",
    "an @xmath26-net clustering can be formed by assigning each vertex to the closest vertex in the @xmath26-net , and breaking the possible ties through some arbitrary rule .",
    "different selection and assignment rules and different values of @xmath26 correspond to different experimental designs .",
    "we compare clustered random assignment using @xmath26-nets to independent random assignment , where vertices are independently assigned to treatment and control .",
    "other mappings of vertices to clusters of interest include methods developed for community detection @xcite .",
    "many global community detection methods , such as modularity maximization @xcite , have a resolution limit such that they do not distinguish small clusters @xcite ; graph cluster randomization with these methods could then introduce too large an increase in variance for the resulting bias reduction . therefore , local clustering methods may be more appealing for graph cluster randomization . observed community membership ( e.g. , current educational institution ) or geography could also be used as this mapping .",
    "lastly , it is important to note that independent random assignment can be considered as clustered random assignment where each vertex is in its own cluster .      given the network ( along with vertex characteristics and prior behavior ) and treatment assignments , some data generating process produces the observed outcomes of interest .",
    "in the context of social networks , typically this is the unknown process by which individuals make their decisions . in this work ,",
    "we consider a variety of such processes . for our simulations , we use a known process meant to simulate decisions , in which units respond to others prior behaviors .",
    "doing so allows us to understand the performance of varied design and analysis methods , measured in terms of estimators bias and error , under varied ( although simple ) decision mechanisms . before considering these processes themselves ,",
    "we consider outcomes as a function of treatment assignment .      in the following presentation",
    ", we use the language of `` treatment response '' assumptions developed by @xcite to organize our discussion of outcome generation . consider vertices outcomes as determined by a function from the global treatment assignment @xmath28 and an independent stochastic component @xmath29 to an outcome vector @xmath30 : @xmath31 we then observe @xmath32",
    ". we can decompose this function into a function for each vertex @xmath33 we can , as we have done above , continue to write @xmath2 to refer to the outcome for vertex @xmath3 that would be observed under assignment @xmath4 ; by suppressing dependence on @xmath34 , this treats @xmath35 as a stochastic function .",
    "if vertices outcomes are not affected by others treatment assignment , then sutva is true .",
    "perhaps more felicitously , @xcite calls this assumption _ individualistic treatment response _ ( itr ) . under itr",
    "we could then consider vertices as having a function from only their own assignment to their outcome : @xmath36 one way for this assumption to hold is if the vertices do not interact .",
    "as being a function from @xmath37 rather than just @xmath38 . ]",
    "this specification of @xmath39 corresponds to the assumption that a vertex s outcome is invariant to changes in other vertices assignments .",
    "that is , for any two global assignments @xmath40 and any stochastic component @xmath29 , @xmath41 itr is a particular version of the more general notion of _ constant treatment response _",
    "( ctr ) assumptions @xcite .",
    "more generally , a ctr assumption involves establishing equivalence classes of treatment vectors by defining a function @xmath42 that maps global treatment vectors to the space @xmath43 of _ effective treatments _ for vertex @xmath3 @xcite such that @xmath44 for any two global assignments @xmath40 and any stochastic component @xmath29 . specifying the functions @xmath45 is then a general way to specify a ctr assumption .",
    "such assumptions can be described as constituting an _ exposure model _ @xcite .",
    "other ctr assumptions have been proposed that allow for some interference .",
    "@xcite simply posit different restrictions on this function , such as that a vertex s outcome only depends on its assignment and its neighbors assignments .",
    "this _ neighborhood treatment response _ ( ntr ) assumption has that , for any two global assignments @xmath40 and any stochastic component @xmath29 , @xmath46 where @xmath47 are the neighbors of vertex @xmath3 . @xcite and",
    "@xcite consider further restrictions , such as that a vertex s response only depends on the number of treated neighbors .",
    "how should we select an exposure model ?",
    "* section 3 ) suggest that we `` must use substantive judgment to fix a model somewhere between the traditional randomized experiment and arbitrary exposure models '' . however , it is unclear how substantive judgement can directly inform the selection of an exposure model for experiments in networks  at least when the vast majority of vertices are in a single connected component .",
    "interference is often expected because of peer effects : in discrete time , then the behavior of a vertex at @xmath48 is affected by the behavior of its neighbors at @xmath49 ; if this is the case , then the behavior of a vertex at @xmath48 would also be affected by the behavior of its neighbors neighbors at @xmath50 , and so forth .",
    "such a process will result in violations of the ntr assumption , and many other assumptions that would make analysis tractable .",
    "@xcite shows how some , quite specific , models of simultaneous endogenous choice can produce some restrictions on @xmath39 .",
    "since many appealing ctr assumptions are violated by the very theories that motivate the expectation of interference , it is useful to evaluate the performance of available design and analysis methods  including estimators that would be motivated by these assumptions  under outcome generating processes consistent with these theories .",
    "in particular , we now consider outcome generating processes in which vertices respond to their own treatment and the prior behavior of their neighbors .",
    "that is , peer behavior fully mediates the effects of the assignments of an ego s peers on the ego .",
    "this is notably different from @xcite and @xcite , where ego response is specified in terms of peer assignments without being mediated through peer behavior .",
    "we consider a dynamical model with discrete time steps in which a vertex s behavior at time @xmath48 , denoted by the vector @xmath51 , is a function @xmath52 of ego treatment assignment and it and its neighbors prior behaviors @xmath53 , such that @xmath54 where @xmath55 is the degree of vertex @xmath3 and @xmath56 is initialized by some prior process . that is , @xmath57 is the nonparametric structural equation ( npse ) for @xmath51 .",
    "together with the graph @xmath58 , the function @xmath57 determine the treatment response function @xmath39 .",
    "thus , this outcome generating process implies some ctr assumptions .",
    "after the first time step ( i.e. , at time 1 ) , the effective treatment for a vertex , the function @xmath59 considered earlier , maps to the space of the vertex s treatment . after the second time step , it maps to the space of the vertex s treatment and its neighbors treatment . after the third time step ( i.e. , at time 3 ) , the effective treatment is no finer than the treatment of all vertices within distance 2 . at time",
    "step @xmath48 , the effective treatment is no finer than the treatment of all vertices within distance @xmath49 .",
    "we see here that under such a dynamic outcome generating process , manski s notion of effective treatment , conceived of to limit the scope of dependence , quickly expands to encompass the full graph .",
    "many familiar models are included in the above outcome generating process . to make this more concrete , and for our subsequent simulations",
    ", we consider a model in which a vertex s behavior is a stochastic function of the mean of neighbors prior behaviors , so that behavior at some new time step @xmath48 is generated as : @xmath60 where @xmath61 is a row of the adjacency matrix and @xmath55 is the degree of vertex @xmath3 . in the case of a binary behavior , we work with @xmath62 and @xmath63 , which is a probit model .",
    "we initialize behaviors with @xmath64 . here",
    "@xmath65 is the baseline , where a negative @xmath65 determines the threshold that must be crossed for @xmath66 to be positive . setting @xmath67 determines the strength of the direct effect of the treatment , while @xmath68 is the slope for peer behavior , and therefore determines the strength of the peer effects .",
    "this process is then run up to a maximum time @xmath69 .",
    "as described above , with a small value of @xmath69 , this implies ctr assumptions .",
    "this can be interpreted as a _ noisy best response _ or _",
    "best reply _",
    "model @xcite , when vertices anticipate neighbors taking the same action in the present round as they did in the previous round .",
    "in particular , we can interpret @xmath66 as the payoff for vertex @xmath3 to adopt behavior 1 at time @xmath48 .",
    "when @xmath70 , then this is a semi - anonymous graphical game with strategic complements ( * ? ?",
    "we focus on the ate ( the average treatment effect ; @xmath11 in equation [ tau_is_ate ] ) , which is naturally of interest when considering whether a new treatment would be beneficial if applied to all units .",
    "there are many options available for estimating the ate .",
    "for example , if the relevant network is completely unknown or if peer effects are not expected , then one might use estimators for experiments without interference , such as a simple difference - in - means between the outcomes of vertices assigned to treatment and control . to clarify the sources of error in estimation , we begin with the population analogs of these quantities  i.e. , the associated estimands  and return to the estimators themselves in section [ sec : estimators ] .",
    "consider the simple difference - in - means estimand @xmath71 where the @xmath72 are mean outcomes when a vertex is in treatment and control , i.e. , @xmath73.\\ ] ] we index these quantities by both the definition of effective treatments ( itr for `` individualistic treatment response '' , as in section [ sec : treatment_response_assumptions ] ) and the experimental design @xmath74 , since the former determines the conditioning involved and the latter determines the distribution of @xmath0 over which we take expectations .",
    "when a vertex s outcome depends on the treatment assignments of others , these quantities need not equal the quantities of interest .",
    "that is , they can suffer from some estimand bias , such that @xmath75 is non - zero .",
    "each vertex assigned to treatment contributes to this bias through the difference between its expected outcome when assigned to treatment ( given the experimental design ) and what would be observed under global treatment . more generally , for some global treatment vector @xmath4",
    ", vertex @xmath3 contributes to the bias of @xmath76 through @xmath77 .",
    "$ ] if the treatment assignment of other vertices do not affect vertex @xmath3 s behavior much , then this contribution might be quite small . or this contribution could be more substantial .",
    "we are now equipped to elaborate on the intuition that graph cluster randomization puts vertices in conditions `` closer '' to the global treatments of interest and thereby reduces bias in estimates of average treatment effects , even if a vertex s outcome depends on the global treatment vector .",
    "the result below uses a linear outcome model that has as a special case the linear - in - means model , as made clear at the end of this subsection .",
    "[ prop : linear_bias_reduction_design ] assume we have a linear outcome model for all vertices @xmath78 such that @xmath79 = a_i + \\sum_{j \\in v } b_{ij } z_j\\end{aligned}\\ ] ] and further assume that @xmath80 is monotonically increasing in @xmath4 for every @xmath81 and vertex @xmath3 such that @xmath82 .    then for some mapping of vertices to clusters , the absolute bias of @xmath83 when the design @xmath74 is graph cluster randomization is less than or equal to the absolute bias when @xmath74 is independent assignment , with a fixed treatment probability @xmath84 .",
    "using the linear model for @xmath85 and the definition of @xmath11 , we have that the true ate @xmath11 is given by @xmath86 for this outcome model .",
    "under graph cluster randomization , @xmath87.\\end{aligned}\\ ] ] then under independent assignment , @xmath88 because @xmath82 , together this implies that @xmath89 , where monotonicity dictates that each side of this inequality is positive .",
    "this comparison allows seeing how , at least in this linear model , the magnitude of bias reduction from graph cluster randomization depends on the `` strength '' of the interactions within clusters .",
    "that is , this clarifies the intuition that using clusters formed from more distant vertices will not generally reduce bias as much as clusters formed from closer vertices , as is the aim of using graph partitioning methods such as @xmath26-net partitioning or community detection methods .",
    "it also highlights that when there are mainly non - zero @xmath90 s , _ ceteris paribus _",
    "large clusters result in more bias reduction ; of course , there are corresponding costs to precision .    to clarify this further , let s consider the relative bias defined by @xmath91}{\\sum_{ij } b_{ij } } - 1.\\end{aligned}\\ ] ] assume that there are @xmath92 clusters of size @xmath93 used for the graph cluster randomization .",
    "clusters of size @xmath93 will produce ntr - based estimators with bounded variance . ] under this condition , the numerator has @xmath92 terms and the denominator has @xmath94 terms .",
    "so unless there is a judicious choice of clustering , the numerator will be overwhelmed by the denominator and the estimator @xmath95 will be a dramatic underestimate of the true average treatment effect , and it s clear that @xmath96 would be even worse .",
    "in order for meaningful relative bias reduction to occur , the clustering must capture the structure of the dependence between units specified by the matrix of coefficients @xmath97 .",
    "in appendix [ appendix : balanced_linear_case ] , we derive similar intuitions from an alternative graph cluster randomization that preserves balance between the sizes of the treatment and control group .",
    "there graph cluster randomization no longer always achieves bias reduction for every clustering over independent assignment , but meaningful bias reduction is again possible and depends on how the clustering captures @xmath97 in an identical way .",
    "this linear outcome model has as special cases some other models of interest .",
    "in particular , it has as a special case the linear - in - means model , which is widely studied and used in econometrics ( e.g. , * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ?",
    "consider @xmath98 in eq .",
    "[ probit_model ] .",
    "then for @xmath99 the quantity @xmath100 $ ] is @xmath101 = \\alpha +   \\beta z_i+ \\gamma \\frac{{a}_i^ { ' } { \\mathrm{e}}^u[y_{t - 1}(z)]}{k_i}.\\end{aligned}\\ ] ] the closed form solution for @xmath102 $ ] for any @xmath103 is then given by @xmath104 = ( \\gamma { \\mathbf{d}}^{-1 } { \\mathbf{a}})^t { \\mathrm{e}}^u[y_0 ] + \\sum_{q=0}^{t-1 } ( \\gamma   { \\mathbf{d}}^{-1 } { \\mathbf{a}})^q ( \\alpha + \\beta z)\\end{aligned}\\ ] ] where @xmath105 is the diagonal matrix of inverse degrees , @xmath13 is the adjacency matrix , and @xmath106 is the vector of initial states .",
    "this is a linear outcome model with @xmath107)_i$ ] and @xmath108 .",
    "definitions of effective treatments other than itr correspond to different estimands .",
    "in particular , we can incorporate assumptions about effective treatments into equation [ tau_is_ate ] .",
    "let @xmath109\\end{aligned}\\ ] ] be the mean outcome for the global treatment @xmath4 when @xmath110 specifies the effective treatments and @xmath74 is the experimental design .",
    "then we have @xmath111 as our revised estimand for the ate .",
    "to the behavior at @xmath6 and @xmath7 . ]",
    "if the effective treatment assumption corresponding to this estimator is satisfied , then it is unbiased . as with the itr assumption , we can again describe the bias that occurs when effective treatments are incorrectly specified . for some global treatment vector @xmath4 , vertex @xmath3 contributes to the bias of @xmath112 through @xmath113,\\end{aligned}\\ ] ] where @xmath59 is the potentially incorrect ( i.e. , too coarse ) specification of effective treatments for vertex @xmath3 .",
    "considering two or more specifications of effective treatments can allow us to elaborate on the intuition that using a finer specification of effective treatments will reduce bias by comparing only vertices that are in conditions `` closer '' to the global treatments of interest .",
    "for example , the ntr assumption corresponds to finer effective treatments than the itr assumption .",
    "we also relax the ntr assumption to a fractional @xmath114-neighborhood treatment in which a vertex is considered effectively in global treated if a fraction @xmath114 of its neighbors are treated ( and the same for control ) @xcite .",
    "here we analyze functions @xmath59 such that @xmath115 just implies that for some subset of vertices @xmath116 we have that @xmath117 and that @xmath118 .",
    "these are conditions such that some subset of size @xmath119 of a set of vertices @xmath116 has treatment assignment matching that in @xmath4 , the global treatment vector of interest .",
    "the fractional neighborhood treatment response ( fntr ) assumption corresponds to such a function with @xmath120 and @xmath121 , where @xmath55 is vertex @xmath3 s degree .",
    "this has both itr and ntr as special cases with @xmath122 and @xmath123 respectively .",
    ", including the empty set . ]",
    "if we have two such functions @xmath124 and @xmath125 with the same @xmath116 , and @xmath126 implies @xmath127 , then we say that @xmath124 is _ more restrictive _ than @xmath125 .",
    "[ prop : bias_reduction_analysis ] let @xmath128 and @xmath129 be vectors of such functions where @xmath124 is more restrictive than @xmath125 for every vertex @xmath3 , and let independent random assignment be the experimental design .",
    "a sufficient condition for estimand @xmath130 to have less than or equal absolute bias than @xmath131 , where these estimands are defined by equation [ effective_treatment_tau ] , is that we have monotonically increasing responses or monotonically decreasing responses for every vertex with respect to @xmath4 .    given in appendix [ appendix : theory_analysis ] .",
    "note that the utility linear - in - means model in equation [ probit_model ] satisfies this monotonicity condition if the direct effect @xmath67 and peer effect @xmath68 are both non - negative .    what about the combination of graph cluster randomization with these neighborhood - based estimands ?",
    "as we show in appendix [ appendix : theory_analysis ] , similar arguments apply if we count up matching _",
    "clusters _ instead of vertices , but use of the ftnr estimand with graph cluster randomization is not necessarily bias reducing under monotonic responses without this modification .",
    "we now briefly discuss estimators for the estimands considered above .",
    "first , we can estimate @xmath132 with the difference in sample means @xmath133 where the @xmath134 are simple sample means , i.e. , @xmath135 } \\sum_{i=1}^n y_i \\mathbf{1}[z_i = z_i].\\ ] ] note that these estimators are again indexed by the effective treatment @xmath136 used ( i.e. , itr ) , but , unlike the estimands , they are not indexed by the design , though the design determines their distribution .",
    "we additionally distinguish these estimators by the weighting used ( discussed below ) , identifying the simple ( i.e. , unweighted ) means with  @xmath137 .",
    "if a vertex s own treatment is ignorable ( as it is under random assignment , independent or graph clustered ) , then this estimator will be unbiased for @xmath132 .",
    "more generally , there is a natural correspondence between the conditioning on @xmath115 in the estimands and the vertices whose outcomes are used in an estimator . given some specification of effective treatments @xmath110 , one could construct an estimator of the ate as a simple difference in the sample means for vertices in effective treatment and in effective control @xmath138 where we have @xmath139 } { { \\sum_{i=1}^n \\mathbf{1}[g_i(z ) = g_i(z ) ] }   } .\\ ] ] this estimator will only be unbiased for the corresponding estimand @xmath112 under certain conditions . to have an unbiased estimate of @xmath140 using the sample mean",
    "requires that @xmath141 $ ] be independent of @xmath142 $ ] , the probability vertex @xmath3 is assigned to that effective treatment .",
    "that is , the effective treatments must be ignorable .",
    "one way for the effective treatments to be ignorable is if either of these quantities is the same for all vertices .",
    "usually we would not want to assume that @xmath141 $ ] is homogeneous , and @xmath143 $ ] will not be homogeneous under many relevant effective treatments , such as neighborhood treatment response ( ntr ) , since the distribution of effective treatments for a vertex depends on network structure .",
    "as @xcite observe , high degree vertices will generally have low probability of being assigned to some kinds of `` extreme '' effective treatments , such as having all neighbors treated , while low degree vertices have a much higher probability of being in such an effective treatment",
    ".    observed effective treatments can be made ignorable by conditioning on the design @xcite or sufficient information about the vertices .",
    "the experimental design determines the probability of assignment to an effective treatment @xmath144 . in the case of graph cluster randomization and effective treatments determined by thresholds",
    ", these probabilities can be computed exactly using a dynamic program @xcite .",
    "these are generalized propensity scores that can then be used in horvitz  thompson estimators or other inverse - probability weighted estimators , such as the hajek estimator @xcite of the ate .",
    "the horvitz ",
    "thompson estimator will often suffer from excessive variance , so we focus on the hajek estimator : @xmath145}{\\pi_i(z_1)}\\right)^{-1 }   \\sum_{i=1}^n \\frac{y_i \\mathbf{1}[g_i(z ) = g_i(z_1)]}{\\pi_i(z_1 ) } \\ ; \\ ;   -   \\nonumber\\\\   & \\left(\\sum_{i=1}^n \\frac{\\mathbf{1}[g_i(z ) = g_i(z_0)]}{\\pi_i(z_0)}\\right)^{-1 }   \\sum_{i=1}^n \\frac{y_i \\mathbf{1}[g_i(z ) = g_i(z_0)]}{\\pi_i(z_0 ) } \\ ; \\ ;   \\label{hajek_estimate}\\end{aligned}\\ ] ] this estimator provides a nearly unbiased estimate of equation [ effective_treatment_tau ] .    beyond bias , we also care about the variance of the estimator as well . estimators making use only of vertices with all neighbors in the same condition",
    "will suffer from substantially increased variance , both because few vertices will be assigned to this effective treatment and because the weights in the hajek estimator will be highly imbalanced .",
    "this could motivate borrowing information from other vertices , such as by using additional modeling or , more simply , through relaxing the definition of effective treatment , such as by using the fractional relaxation of the ntr assumption ( fntr ) .",
    "the most appropriate effective treatment assumption to use for the analysis of a given experiment is not clear _ a priori_. we will consider estimators motivated by two different effective treatments in our simulations .",
    "in order to evaluate both design and analysis choices , we conduct simulations that instantiate the model of network experiments presented above . first , graph cluster randomization puts more vertices into positions where their neighbors ( and neighbors neighbors ) have the same treatment ; this is expected to produce observed outcomes `` closer '' to those that would be observed under global treatment .",
    "second , estimators using fractional neighborhood treatment restrict attention to vertices that are `` closer '' to being in a situation of global treatment .",
    "third , weighting using design - based propensity scores adjusts for bias resulting from associations between propensity of being in an effective treatment of interest and potential outcomes .",
    "each of these three changes to design and analysis is expected to reduce bias , potentially at a cost to precision . under some conditions ,",
    "we have shown above that these design and analysis methods reduce ( or at least do not increase ) bias for the ate .",
    "the goal of these simulations then is to characterize the magnitude of this bias reduction , weigh it against increases in variance , and do so specifically under circumstances that do not meet the given sufficient conditions .    for each run of the simulation",
    ", we do the following .",
    "first , we construct a small world network with @xmath146 1,000 vertices and initial degree parameter @xmath147 .",
    "we vary the rewiring probability @xmath148 , thereby producing both regular powers of the cycle ( @xmath149 ) , graphs with `` small world '' characteristics ( @xmath150 ) , graphs with many random edges and less clustering ( @xmath151 ) , and graphs with all random edges ( @xmath152 ) .",
    "the small world model of networks @xcite is notable for being able to succinctly introduce clustering into an otherwise complex distribution over random graphs , all featuring a small diameter .",
    "the clustering of the graph , typically measured by the clustering coefficient , is a measure of the extent to which adjacent vertices share many common neighbors in the graph , and many social networks , including online social networks ( e.g. , * ? ? ?",
    "* ) , have been found to exhibit a high degree of clustering as well as a small diameter .    for graph cluster randomization",
    ", we use a 3-net clustering and randomly assign each cluster in its entirety to treatment or control with equal probability .- net clustering , but generally resulted in more bias reduction but also larger variance increases , as expected by this method s resolution limit .",
    "] we compare clustered assignment to independent random assignment .",
    "we generate the observed outcomes using the probit model in equations [ probit_model ] and [ probit_model_link ] , and set the baseline as @xmath153 , making the behavior somewhat rare : @xmath154 we initialize @xmath155 for all vertices , and then run the process for all combinations of @xmath156 and @xmath157 , up to a maximum time @xmath158 .. the results were qualitatively similar . ] note that this data generating process does not satisfy the conditions for graph cluster randomization to be bias reducing given by theorem [ prop : linear_bias_reduction_design ] , since the outcome model is not linear .",
    "finally , for each simulation , we compute three estimates of the ate .",
    "the individual unweighted estimator ( or difference - in - means estimator ) @xmath159 makes no use of neighborhood information .",
    "this is the baseline to which we compare the neighborhood unweighted estimator @xmath160 and the neighborhood hajek estimator @xmath161 , both using a fractional neighborhood treatment response ( ftnr ) specification of effective treatments with @xmath162 .",
    "that is , these estimators count a vertex as being in effective treatment or effective control if at least three - fourths of its neighbors have the same assignment . with independent assignment ,",
    "the conditions for bias reduction given in theorem [ prop : bias_reduction_analysis ] from using this estimator are satisfied . with graph cluster randomization",
    ", it is not immediately obvious whether these conditions are satisfied ( it may depend on details of the network ) .    , the rewiring probability @xmath163 ( different colors ) , and the strength of the peer effect @xmath68 ( different panels ) .",
    "random assignment clustered in the network reduces bias , especially when peer effects are large relative to the baseline ( @xmath164 ) and when the network is more clustered . ]",
    "we run each of these configurations 5,000 times .",
    "we estimate the true ate with simulations in which all vertices are put in treatment or control .",
    "each configuration is run 5,000 times for the global treatment case and 5,000 times for the global control case .",
    ", the second instance of each configuration uses the same seed @xmath165 , and so on . ]",
    "we will now present the results of our simulations of the full process of network experimentation .",
    "we describe our observations in order to provide insight into how the different parts of the network experimentation process interact and contribute to the bias and precision of our experimental estimates .",
    "our evaluation metrics are bias and root mean squared error ( rmse ) of the estimated ate .",
    "first we examine the bias and mean squared error of the estimated ate for designs using graph cluster randomization compared with independent randomization . in both these cases we use",
    "the difference - in - means estimator @xmath166 .",
    "as expected , using graph cluster randomization reduces bias ( figure [ clustering_bias ] ) , especially when the peer effects and direct effects are large relative to the baseline ( @xmath164 ) , and when the network exhibits substantial clustering ( i.e. , the rewiring probability @xmath163 is small ) .",
    "reduction in bias can come with increases in variance , so it is worth evaluating methods that reduce bias also by the effect they have on the error of the estimates .",
    "we compare rmse , which is increased by both bias and variance , between graph cluster randomization and independent assignment in figure [ clustering_rmse ] . in some cases",
    ", the reduction in bias comes with a significant increase in variance , leading to an rmse that is either left unchanged or even increased .",
    "however , in cases where the bias reduction is large , this overwhelms the increase in variance , such that graph cluster randomization reduces not only bias but also rmse substantially .",
    "for example , with substantial clustering ( @xmath167 ) and peer effects ( @xmath168 ) , we observe approximately 40% rmse reduction from graph cluster randomization . while the rmse reduction is strongest under substantial clustering , if both the direct effect strength and peer effect strength are strong , we observe significant universal reductions in rmse from clustered randomization ( though to varied extents ) , regardless of the clustering structure given by @xmath163 .",
    "it is notable that even with small networks ( recall that @xmath169 ) , the bias reduction from graph cluster randomization is large enough to reduce rmse .",
    "in addition to changes in design ( i.e. , graph cluster randomization ) , we can also use analysis methods intended to account for interference .",
    "we utilize the fractional neighborhood exposure model , which means we only include vertices in the analysis if at least three - quarters of their friends were given the same treatment assignment .",
    "( i.e. , the results shown in figure  [ exposure_model_bias ] ) . ] with this neighborhood exposure model , we consider using propensity score weighting , which corresponds to the hajek estimator , or ignoring the propensities and using unweighted difference - in - means .",
    "the second estimator has additional bias due to neglecting the propensity - score weights .",
    "figure [ exposure_model_bias ] shows several combinations of design randomization procedure , exposure model , and estimator .",
    "we see that using a neighborhood - based definition of effective treatments further reduces bias , while the impact of using the hajek estimator is minimal .",
    "the low impact of the hajek estimator follows understandably from the fact that small - world graphs do not exhibit any notable variation in vertex degree , which is the principle determinant of the propensities used by the hajek estimator .",
    "thus , for small - world graphs the weights used by the hajek estimator are very close to uniform . with more degree heterogeneity expected in real networks ,",
    "the weighting of the hajek estimator will be more important , especially when these heterogeneous propensities are highly correlated with behaviors .",
    "in general , however , the change in bias from adjusting the analysis are not as striking as those from changes due to the experimental design .    using the neighborhood exposure model means that the estimated average treatment effect is based on data from fewer vertices , since many vertices may not pass the _ a priori _ condition .",
    "so the observed modest changes in bias come with increased variance , as reflected in the change in rmse compared with independent assignment without using the exposure condition ( figure [ exposure_model_rmse ] ) .",
    "+    as a check on the robustness of these results to the specific choice of network model , we also conducted simulations with a degree - corrected block model ( dcbm ; * ? ? ?",
    "* ) , which provides another way to control the amount of local clustering in a graph and to produce more variation in vertex degree .    in each simulation ,",
    "the network is generated according to a degree - corrected block model with 1,000 vertices and 10 communities .",
    "we present results for a subset of the parameter values used with the small - world networks .",
    "instead of varying the rewiring probability @xmath163 to control local clustering , we vary the expected proportion of edges that are within a community @xmath170 where vertices are assigned to one of the 10 communities uniformly at random .",
    "the distribution of expected degrees is a discretized log - normal distribution with mean 10 ( as with the small - world networks ) and variance 40 .",
    "this produces substantially more variation in degrees than the small - worlds network .",
    "each configuration is repeated 5,000 times .",
    "figure [ clustering_dcbm ] displays the change in bias and error that results from graph cluster randomization in these simulations .",
    "the bias and error reduction with the dcbm networks is not as large , for the same values of other parameters , as with the small world networks .",
    "we interpret this as a consequence of the presence of higher - degree vertices and of less local clustering , even in the simulations with high community proportion ( i.e. , @xmath171 ) . and the chosen degree distribution , the dcbm networks have an average clustering coefficient of approximately 0.095 and average transitivity of approximately 0.091 .",
    "this is similar to that of small - world networks with @xmath172 .",
    "this observed bias and error reduction is likewise comparable to that observed with those small - world networks . ]",
    "qualitative features of these results ( e.g. , bias and error reduction increase with increases in peer effects and increases in clustering ) match those from the small - world networks .",
    "figure [ exposure_model_dcbm]a displays bias as a function of both design and analysis decisions . as with the small - world networks , estimators making use of the @xmath114-fractional neighborhood exposure condition reduce bias , whether used with independent or clustered random assignment .",
    "this additional bias reduction comes at the cost of additional variance , such that , in terms of mse , estimators using the exposure condition are worse for many of the parameter values included in these simulations ( figure [ exposure_model_dcbm]b ) .",
    "recent work on estimating effects of global treatments in networks through experimentation has generally started with a particular set of assumptions about patterns of interference , such as the neighborhood treatment response ( ntr ) assumption , that make analysis tractable and then developed estimators with desirable properties ( e.g. , unbiasedness , consistency ) under these assumptions @xcite . similarly , @xcite analyzed graph cluster randomization under such assumptions .",
    "unfortunately , these tractable exposure models are also made implausible by the very processes , such as peer effects , that are expected to produce interference in the first place .",
    "therefore , we have considered what can be done about bias from interference when such restrictions on interference can not be assumed to apply in reality .    the theoretical analysis in this paper offers sufficient , but not necessary , conditions for this bias reduction through design and analysis in the presence of potentially global interference . to further evaluate how design and analysis decisions can reduce bias , we reported results from simulation studies in which outcomes are produced by a dynamic model that includes peer effects .",
    "these results suggest that when networks exhibit substantial clustering and there are both substantial direct and indirect ( via peer effects ) effects of a treatment , graph cluster randomization can substantially reduce bias with comparatively small increases in variance .",
    "significant error reduction occurred with networks of only 1,000 vertices , highlighting the applicability of these results beyond experiments on large networks .",
    "additional reductions in bias can be achieved through the specific estimators used , even though these estimators are based on incorrect assumptions about effective treatments .",
    "further work should examine how these results apply to other networks and data - generating processes . the theoretical analysis and simulations in this paper",
    "used models in which outcomes are monotonic in treatment and peer behavior .",
    "such models are a natural choice given many substantive theories , but in other cases vertices will be expected to be less likely to take an action as more peers take that action .",
    "our simulations did not include vertices characteristics ( besides degree ) and prior behaviors , which could play an important role in the bias and variance for different designs and estimators .",
    "much of the empirical literature that considers peer effects in networks , whether field experiments ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) or observational studies ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ) has aimed to estimate peer effects themselves , rather than estimating effects of interventions that work partially through peer effects ; a fruitful direction for future work would involve directly modeling the peer effects involved and then using these models to estimate effects of global treatments ( cf . * ? ? ?",
    "this could substantially expand the range of designs and analysis methods to consider .",
    "we are grateful for comments from edoardo airoldi , eytan bakshy , thomas barrios , daniel merl , cyrus samii , and participants in the statistical and machine learning approaches to network experimentation workshop at carnegie mellon university , and in seminars in the stanford graduate school of business , columbia university s department of statistics , new york university s department of politics , and uc davis s department of statistics .    33    , ( ) . .",
    "( ) . . .",
    "( ) . . .    , , ( ) .",
    ". in . .",
    "( ) . . .    , , ( ) .",
    "( ) . . .    , , , , , ( ) .",
    "( ) . . .",
    "( ) . . .",
    "( ) . . .",
    "( ) . . .",
    "( ) . . .",
    "( ) . . .",
    "( ) . . .",
    "( ) . . .",
    "( ) . . .",
    "( ) . . .",
    "( ) . . .",
    "( ) . . .",
    "( ) . . .",
    "( ) . . .",
    "( ) . . .",
    "( ) . . .",
    "( ) . . in .    , , ( ) . .",
    ".    , , ( ) . . in .",
    "( ) . . .",
    "( ) . . .",
    "we now briefly present a simple modification of graph cluster randomization that adds vertex - level randomness to the treatment assignment , such that some vertex assignments may not match their cluster assignment .",
    "we set @xmath173 @xmath174 @xmath175 the @xmath176 are independent switching variables that set @xmath10 to @xmath177 with probability @xmath178 , typically high , and flip the assignment otherwise ( `` punch a hole '' ) .",
    "that is , clusters are assigned to have their vertices predominantly in one of treatment or control .",
    "we call this modification _ hole punching _ , because it inverts the treatment condition of a small fraction of vertices , placing them in a highly isolated treatment position within their cluster",
    ". this modification could be useful for estimating differences between direct and peer effects , since it results in many vertices experiencing the direct treatment without peer effects or the peer effects without the direct treatment .",
    "it also has the appealing consequence of avoiding exact zero probabilities of assignment to some vectors @xmath0 .",
    "this is important in cases where one might want to compare outcomes as a function of number of peers assigned to the treatment ; otherwise , many of these comparisons would be between conditions that many vertices could not be assigned to .      in this appendix",
    ", we consider the linear outcome model under an alternative graph cluster randomization that enforces balance ( i.e. , equal sample sizes in treatment and control ) assume there is an even number of clusters @xmath17 , each with @xmath179 vertices .",
    "pick @xmath180 clusters at random and assign them to treatment ; assign the remaining clusters to control .",
    "[ prop : linear_bias_reduction_design_balanced ] assume we have a linear outcome model for all vertices @xmath78 such that @xmath79 = a_i + \\sum_{j \\in v } b_{ij } z_j\\end{aligned}\\ ] ] and further assume that @xmath80 is monotonically increasing in @xmath4 for every @xmath81 and",
    "vertex @xmath3 such that @xmath82 .    then for some mapping of vertices to clusters , the absolute bias of @xmath181 when @xmath74 is graph cluster randomization is less than or equal to the absolute bias when @xmath74 is independent assignment , with a fixed treatment probability @xmath84 .",
    "using the linear model for @xmath85 and the definition of @xmath11 , we have that the true ate @xmath11 is given by @xmath86 for this outcome model .",
    "under balanced graph cluster randomization , @xmath182   + \\mathbf{1}[c(i ) \\neq c(j ) ] \\left(\\frac{n_c/2 - 1}{n_c -1 } - \\frac{n_c / 2}{n_c - 1 } \\right ) \\right ] \\\\ & = \\frac{1}{n } \\sum_{ij } b_{ij } \\left [ \\mathbf{1}[c(i ) = c(j ) ]   -   \\frac{\\mathbf{1}[c(i ) \\neq c(j)]}{n_c -1 } \\right].\\end{aligned}\\ ] ] we can extend this to the case where the mapping of vertices to clusters is random : @xmath183.\\end{aligned}\\ ] ] separating out @xmath184 : @xmath185 if we have uniform probability over all cluster assignments with the same number of vertices per cluster , then for @xmath186 , @xmath187 so @xmath188 under balanced independent assignment , we just have @xmath189 , so @xmath190 because @xmath82 , together this implies that @xmath191 , where monotonicity again dictates that each side of this inequality is positive .",
    "the proof showed that clustering can reduce bias over independent assignment when preserving balance .",
    "the relative bias for graph cluster randomization that preserves balance is @xmath192   -   \\frac{\\mathbf{1}[c(i ) \\neq c(j)]}{n_c -1}\\right]}{\\sum_{ij } b_{ij } } - 1 \\\\ & = & \\left(1 + \\frac{1}{n_c - 1}\\right)\\left(\\frac{\\sum_{ij } b_{ij } \\mathbf{1}[c(i ) = c(j)]}{\\sum_{ij } b_{ij } } - 1\\right ) . \\nonumber\\end{aligned}\\ ] ] which is the same expression as the relative bias for graph cluster randomization except for the multiplicative factor in the front . for large enough @xmath17 , the relative biases will be identical , and therefore meaningful relative bias reduction occurs depending only on the clustering s relationship to the values @xmath90 , and not whether the sampling scheme preserves balance or not .      here we restate and prove theorem [ prop : bias_reduction_analysis ] from the main text .",
    "we also consider two possible extensions of this theorem to graph cluster randomization ( from independent random assignment ) , giving a counterexample for one extension and proving an analog of the theorem for the other extension .",
    "consider functions @xmath59 such that @xmath115 just implies that for some subset of vertices @xmath116 we have that @xmath117 and that @xmath118 .",
    "these are conditions such that some subset of size @xmath119 of a set of vertices has treatment assignment matching that in the global treatment vector of interest @xmath4 .",
    "the itr and ntr assumptions both are of this type , where with itr @xmath116 is the empty set and with ntr @xmath120 and @xmath193 , @xmath3 s degree .",
    "the fractional relaxation of ntr ( fntr ) is also of this type , with @xmath120 and @xmath121 .",
    "prop : bias_reduction_analysis let @xmath128 and @xmath129 be vectors of such functions where @xmath124 is more restrictive than @xmath125 for every vertex @xmath3 , and let independent random assignment be the experimental design .",
    "a sufficient condition for estimand @xmath130 to have less than or equal absolute bias than @xmath131 , where these estimands are defined by equation [ effective_treatment_tau ] , is that we have monotonically increasing responses or monotonically decreasing responses for every vertex with respect to @xmath4 .",
    "all expectations are taken with respect to independent random assignment .",
    "assume monotonically increasing responses for every vertex and select an arbitrary vertex @xmath3 .",
    "let @xmath194.\\end{aligned}\\ ] ] this quantity is the expectation of the potential outcome for @xmath3 when @xmath195 and the subset of @xmath4 corresponding to @xmath116 is set to @xmath196 .",
    "the monotonicity of @xmath85 carries over to @xmath197 .    to reduce the notation in what follows ,",
    "we define @xmath61 to be the event that @xmath198 and @xmath199 to be the event that @xmath200 .",
    "we also define @xmath201 . then @xmath202 & = & \\sum_{q \\geq l_i^a}^{|j_i| } { \\mathrm{e}}[\\tilde{y}_i | q_i(z ) = q ] p(q_i(z ) = q | a_i ) , \\nonumber\\\\ { \\mathrm{e}}[\\tilde{y}_i | \\neg a_i \\land b_i ] & = & \\sum_{q \\geq l_i^b}^{l_i^a - 1 } { \\mathrm{e}}[\\tilde{y}_i | q_i(z ) = q ] p(q_i(z ) = q | \\neg a_i \\land b_i ) .",
    "\\label{eq : conditional_exp}\\end{aligned}\\ ] ]    due to independent random assignment , conditioning on @xmath203 means uniformly sampling a @xmath196 that has @xmath16 ones and @xmath204 zeroes .",
    "consider the following process where @xmath205 . randomly select a @xmath196 with @xmath16 ones and @xmath204 zeroes .",
    "select at random a @xmath206 element and change it into a @xmath207 to create another vector @xmath208 .",
    "record both @xmath209 and @xmath210 as a pair of values .",
    "due to the monotonicity of @xmath211 , we have that @xmath212 .    in this process , @xmath196 is a uniformly sampled vector that has @xmath16 ones and @xmath204 zeroes , and @xmath208 is a uniformly sampled vector that has @xmath213 ones and @xmath214 zeroes . repeating this process an infinite number of times and using the empirical average of the @xmath209 s computes @xmath215 $ ] .",
    "similarly , the empirical average of the @xmath210 computes @xmath216 $ ] . due to",
    "the per sample inequality , this shows that @xmath215 \\leq { \\mathrm{e}}[\\tilde{y}_i | q_i(z ) = q+1]$ ] . by induction , @xmath215 \\leq { \\mathrm{e}}[\\tilde{y}_i | q_i(z )",
    "= q']$ ] when @xmath217 . combining this with eq .",
    "[ eq : conditional_exp ] ,      since the design is independent random assignment , we have that @xmath219 & = & { \\mathrm{e}}[\\tilde{y}_i | b_i ] \\nonumber\\\\ & = & { \\mathrm{e}}[\\tilde{y}_i | a_i ] p(a_i | b_i ) + e[\\tilde{y}_i | \\neg a_i \\land b_i ] p(\\neg a_i | b_i).\\end{aligned}\\ ] ] where in the second equality we have used that @xmath220 is more restrictive than @xmath221 and that the set @xmath116 is common to both @xmath220 and @xmath221 . with eq .",
    "[ eq : conditional_inequality ] , this implies @xmath219 \\leq   { \\mathrm{e}}[\\tilde{y}_i | a_i ] = { \\mathrm{e}}[y_i | a_i].\\end{aligned}\\ ] ]    since this inequality applies for all vertices @xmath3 , we therefore have that @xmath222 from which we immediately conclude that @xmath223 has less absolute bias for @xmath224 than @xmath225 .",
    "an analogous argument applies for @xmath226 , proving that @xmath227 has less absolute bias for @xmath228 , the average treatment effect .",
    "this proposition demonstrates how using more restrictive exposure conditions can be helpful in reducing bias , but the proposition just applies to independent assignment , rather than graph cluster randomization . to show why it does not hold for graph cluster randomization , we present the following counterexample with two fractional neighborhood treatment response ( fntr ) effective treatments .",
    "consider some vertex @xmath3 with no neighbors in its own cluster , and three other clusters present in its neighborhood : one cluster with 10 neighbors , one cluster with one neighbor , and another cluster with one neighbor ; call this last neighbor vertex @xmath229 .",
    "let @xmath230 when @xmath231 and @xmath232 , and let @xmath233 otherwise .",
    "let the less restrictive function @xmath234 require that at least 2 neighbors match the global treatment vector , and let the more restrictive function @xmath234 require that at least 3 neighbors match ; that is , let @xmath235 and @xmath236 .",
    "then under graph cluster randomization , we have @xmath237 \\approx 0.5 $ ] , but @xmath238 \\approx 0.6 $ ] .",
    "so using the more restrictive function actually increases bias in this somewhat extreme scenario .    while this counterexample demonstrates that using more restrictive exposure conditions of this kind is not always helpful under graph cluster randomization , we do observe bias reduction in our simulations using graph cluster randomization without meeting the sufficient conditions of the theorem .",
    "in general , we expect that for bias to increase , there must be heterogeneous effects across heterogeneously sized clusters as in the counterexample above .",
    "in fact , with a redefinition of the exposure conditions , we can provide a similar proposition that does include graph cluster randomization and also encompasses independent assignment as a special case .",
    "consider a fixed set of clusters which will be used for graph cluster randomization .",
    "let function @xmath59 , for all vertices @xmath3 , be such that @xmath115 implies that some subset of clusters @xmath116 which do not include @xmath3 we have that @xmath239 ( at least @xmath119 of the clusters in @xmath116 match the global treatment vector @xmath4 exactly ) , and @xmath118 .",
    "consider two such functions where @xmath240 is more restrictive than @xmath234 for all @xmath3 .",
    "then a sufficient condition for estimand @xmath241 to have less than or equal absolute bias than @xmath242 , where these estimands are defined by equation [ effective_treatment_tau ] , is that we have monotonically increasing responses or monotonically decreasing responses for every vertex with respect to @xmath4 .",
    "this proof is essentially the same as for theorem [ prop : bias_reduction_analysis ] except @xmath211 is redefined as @xmath243,\\end{aligned}\\ ] ] expectations are computed with respect to graph cluster randomization instead of independent treatment assignment , and references to 1 s and 0 s apply to clusters in @xmath116 .",
    "an important special case of this corollary covers the comparison of fntr with itr under graph cluster randomization , since fntr and itr can be written as cluster - level exposure conditions of this kind ."
  ],
  "abstract_text": [
    "<S> estimating the effects of interventions in networks is complicated when the units are interacting , such that the outcomes for one unit may depend on the treatment assignment and behavior of many or all other units ( i.e. , there is interference ) . </S>",
    "<S> when most or all units are in a single connected component , it is impossible to directly experimentally compare outcomes under two or more global treatment assignments since the network can only be observed under a single assignment . </S>",
    "<S> familiar formalism , experimental designs , and analysis methods assume the absence of these interactions , and result in biased estimators of causal effects of interest . while some assumptions can lead to unbiased estimators , these assumptions are generally unrealistic , and we focus this work on realistic assumptions . </S>",
    "<S> thus , in this work , we evaluate methods for designing and analyzing randomized experiments that aim to reduce this bias and thereby reduce overall error . in _ design _ , we consider the ability to perform random assignment to treatments that is correlated in the network , such as through graph cluster randomization . in _ analysis _ , we consider incorporating information about the treatment assignment of network neighbors . </S>",
    "<S> we prove sufficient conditions for bias reduction through both design and analysis in the presence of potentially global interference . through simulations of the entire process of experimentation in networks </S>",
    "<S> , we measure the performance of these methods under varied network structure and varied social behaviors , finding substantial bias and error reductions . these improvements are largest for networks with more clustering and data generating processes with both stronger direct effects of the treatment and stronger interactions between units . </S>"
  ]
}