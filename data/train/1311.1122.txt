{
  "article_text": [
    "modern portfolio theory has shown that investing in certain asset classes promising higher returns has always been linked with a higher variability ( also called volatility ) of those returns , hence resulting in increased risks for the investor .",
    "hence , it is one of the main tasks of financial engineering to accurately estimate the variability of the return of a given asset ( or portfolio of assets ) and take this figure into account in various tasks , including risk management , finding optimal portfolio strategies for a given risk aversion level , or derivatives pricing .",
    "for instance , properly estimating volatilities is essential for applying the  @xcite option pricing method ; another prominent example is the estimation of return distribution quantiles for computing value - at - risk ( var ) figures , a method which is typically recommended by international banking regulation authorities , such as the basel committee on banking supervision .",
    "this approach is also widely applied in practice in internal risk management systems of many financial institutions worldwide .    in practice ,",
    "sufficient statistical information about the past behavior of an asset s return is often not available , hence one is commonly forced to use the so - called _ square - root - of - time _ rule .",
    "essentially , this rule transforms high - frequency risk estimates ( for instance , gathered with a 1-day period over several years ) into a lower frequency @xmath0 ( like a 1-year period ) by multiplying the volatility by a factor of @xmath1 . as an illustration",
    ", the basel regulations recommend to compute the var for the ten day regulatory requirement by estimating a 1-day var and by multiplying this value by @xmath2 , where the var is the value that solves the equation @xmath3 given the density @xmath4 of the bank s return estimated probability distribution and a confidence level @xmath5 , fixed for instance to @xmath6 .",
    "it is well - known that scaling volatilities with the square - root - of - time is only accurate under a certain number of assumptions that are typically not observed in practice : according to  @xcite , returns need to be homoscedastic and conditionally serially uncorrelated at all leads , an assumption slightly weaker than the one of independently and identically distributed ( iid ) returns .",
    "danelsson and zigrand show furthermore that for the square - root - of - time rule to be correct for all quantiles and horizons implies the iid property of the zero - means returns , but also that the returns are normally distributed .    in this paper",
    ", we are interested in studying the effects of applying the square - root - of - time rule on the _ semivariance _ of a continuous jump - diffusion process . as a first step , the semivariance being a downside risk measure , we quickly recall its history and properties in the following section .",
    "downside risk measures have appeared in the context of portfolio theory in the 1950 s , with the development by  @xcite and  @xcite of decision - making tools helping to manage risky investment portfolios .",
    "@xcite showed how to exploit the averages , variances and covariances of the return distributions of assets contained in a portfolio in order to compute an efficient frontier on which every portfolio either maximizes the expected return for a given variance ( i.e. , risk level ) , or minimizes the variance for a given expected return . in the scenario of markowitz , a utility function , defining the investor s sensitivity to changing wealth and risk , is used to pick the proper portfolio on the optimal border .    on his side , @xcite was willing to derive a practical method allowing to determine the best risk - return trade - off ; as he was not convinced that it is feasible to model in practice the sensitivity to risk of a human being with a utility function , he chose to assume that an investor would prefer the investment with the smallest probability of going below a disaster level , or a target return . recognizing the wisdom of this claim",
    ", @xcite figured out two very important points , namely that only the downside risk is relevant for an investor , and that return distributions might be skewed , i.e. , not symmetrically distributed , in practice . in that spirit ,",
    "markowitz suggested to use the following variability measure , that he called a _ semivariance _ , as it only takes into account a subset of the return distribution : @xmath7 where @xmath8 denotes the density of the returns probability distribution , @xmath9 denotes a random variable distributed according to @xmath8 and @xmath10 is a return target level . if @xmath10 is equal to @xmath11 , then   is called the _ below - mean _ semivariance of @xmath9 , while if @xmath10 is arbitrary , is called the _ below - target _ semivariance of @xmath9 , where @xmath10 is defined to be the target return .",
    "in other words , only the deviations to the left of the returns distribution average , or a fixed return target are accounted for in the computations of the variability .",
    "similarly , the square root of a semivariance is called a _ semideviation _ , with analogy to the standard deviation . note that for a symmetrical , i.e. , non - skewed return distribution , the variance of a random variable @xmath9 is equal to twice its below - mean semivariance .    the  @xcite ratio is a measure of the risk - adjusted return of an asset , a portfolio or an investment strategy , that quantifies the excess return per unit of deviation ; it is defined as @xmath12}{\\sqrt{\\mathrm{var}[r_\\mathsf{a } -r_\\mathsf{b}]}},\\ ] ] where @xmath13 and @xmath14 are random variables modeling the returns of assets @xmath15 and @xmath16 , respectively . a prominent variant of the sharpe ratio , called the _ sortino ratio _ ( see  @xcite ) , is relying on the semideviation instead of the standard deviation of the returns distribution .",
    "it is well - known and easily understood that the sharpe and sortino ratios tend to give very different results for highly - skewed return distributions .    finally , we would like to note that the concept of semivariance has been generalized , resulting in the development of _ lower partial moments _ by  @xcite and  @xcite . essentially , the square is replaced by an arbitrary power @xmath17 that can freely vary : @xmath18 varying @xmath17 might help in modeling the fact that an investor is more ( through larger values of @xmath17 ) or less ( through smaller values of @xmath17 ) sensitive to risk . in this paper , we have chosen to stick to @xmath19 for simplicity reasons . in the following , we recall the concepts of jump - diffusion models .",
    "jump - diffusion models are continuous - time stochastic processes introduced in quantitative finance by  @xcite , extending the celebrated work of  @xcite on option pricing .",
    "these models are a mixture of a standard diffusion process and a jump process .",
    "they are typically used to reproduce stylized facts observed in asset price dynamics , such as mean - reversion and jumps .",
    "indeed , modeling an asset price as a standard brownian process implies that it is very unlikely that large jumps over a short period might occur , as it is sometimes the case in real life , unless for unrealistically large volatility values .",
    "hence , introducing the concept of jumps allows to take into account those brutal price variations , which is especially useful when considering risk management , for instance .",
    "various specifications have been proposed in the literature and we refer the reader to  @xcite for an extensive review . in what follows ,",
    "we consider first ( in   [ sec : generalization ] ) the standard jump - diffusion model with time invariant coefficients , constant volatility and gaussian distributed jumps .",
    "later , in   [ sec : jump_vol ] , we will also consider more elaborated stochastic processes , involving random jumps in returns and in volatility .",
    "a basic jump - diffusion stochastic process is a mixture of a standard brownian process with constant drift @xmath20 and volatility @xmath21 and of a ( statistically independent ) compound poisson process with parameter @xmath22 and whose jump size is distributed according to an independent normal law @xmath23 .",
    "more precisely , this model can be expressed as the following stochastic differential equation : @xmath24 where @xmath25 denotes the process that describes the price of a financial asset , with @xmath26 = 1 $ ] , where @xmath27 is the process drift coefficient , @xmath28 is the process variance , @xmath29 is a standard wiener process , @xmath30 is a poisson process with constant intensity @xmath31 and @xmath32 is the process generating the jump size , that together with @xmath30 forms a compound poisson process .",
    "the solution of the stochastic differential equation   is given by @xmath33 where @xmath34 is implicitly defined according to @xmath35 , and @xmath36 is the time at which the @xmath37-th jump of the poisson process occurs . if @xmath38 , the sum is zero by convention .",
    "we assume that the @xmath34 form an independent and identically normally distributed sequence with mean @xmath39 and variance @xmath40 .",
    "the log - return of @xmath25 over a @xmath41-period is defined as @xmath42 and , from  , its dynamic is given by @xmath43 the distribution of @xmath44 is an infinite mixture of gaussian distributions @xmath45 and has a density function given by @xmath46      our contributions in this paper can be summarized as follows : first of all , we derive in   [ sec : explicitform ] an explicit formula for computing the semivariance of a standard jump - diffusion process when the volatility is constant . to the best of our knowledge , it is the first time that such a formula is provided .",
    "second , we propose in   [ sec : generalization ] a generalization of the  @xcite approximation of a jump - diffusion process .",
    "indeed , the simplification brought by ball and torous is based on the fact that , during a sufficiently short time period , and assuming a small jump intensity parameter , only a single jump can occur .    by doing so , the authors want to capture large and infrequent events as opposed to frequent but small jumps",
    ". however , our analysis in   [ sec : app ] shows that limiting the jump intensity parameter may result in an underestimation of the risk ; hence , from a risk management perspective , this approach does not seem to be appropriate .",
    "it is the reason why we have preferred not to impose any arbitrary condition on the poisson process intensity parameter and to estimate it by the maximum likelihood method .",
    "our extension of the work of ball and torous also implies that more that one jump may occur during a single day . this is a consequence of the fact that , when the intensity parameter is sufficiently large , the probability of obtaining more than one jump is then not negligible anymore .",
    "the only remaining constraint that we keep in our approach is the fact that @xmath22 should be smaller than a ( large ) upper bound .",
    "however , we show in   [ subsec : charac ] that this constraint is actually not a strong limitation .",
    "third , we apply our results in   [ sec : app ] to compute an estimation of the semivariance based on the barclays us high yield index returns , showing that the standard square - root - of - time rule indeed may underestimate risk in certain periods and overestimate it in other ones . for this , we make use of a customized optimization algorithm based on differential evolution to maximize a likelihood function .",
    "last but not least , we discuss in   [ sec : jump_vol ] the extension of our work to a jump diffusion model with jumps in returns and in volatility .",
    "therein , we first recall the importance of considering random jumps in returns and in volatility . then , we describe the stochastic volatility model that we use , which is an extension of the model proposed by  @xcite .",
    "the statistical estimation of its parameters is addressed in the next section .",
    "we use in particular markov chain monte carlo ( mcmc ) methods to derive their values .",
    "we propose in   [ sub : semi ] a method to compute an annualized semideviation once the model parameters have been determined .",
    "finally , we present some experimental results .",
    "we derive in this section an explicit formula for the semivariance of a standard jump - diffusion model with time invariant coefficients , constant volatility and gaussian distributed jumps . to the best of our knowledge ,",
    "this is the first time that an explicit formula is provided for computing the semivariance .    in the following ,",
    "let us denote respectively by @xmath47 and @xmath48 the probability density function and the cumulative distribution function of a standard normal distribution @xmath49 with mean @xmath50 and variance @xmath51 , i.e. , @xmath52    [ the : semivariance ] the semivariance of the density   is given by @xmath53 where @xmath54 , @xmath55 , @xmath56 and @xmath57 .    the proof is given in appendix  [ app : proof ] .",
    "for a pure diffusion process without jump , the previous formula   simplifies to the following one .",
    "the semivariance of a pure diffusion process with drift @xmath20 and volatility @xmath21 is equal to @xmath58 where @xmath59 , @xmath60 and @xmath61 .",
    "the proof is a direct consequence of proposition  [ prop : prop0 ] given in appendix  [ app : proof ] and of the fact that   can be rewritten as @xmath62 when we consider a pure diffusion process .",
    "the task of fitting a jump - diffusion model to real - world data is not as easy at it appears , and this fact has been early recognized , see for instance  @xcite or  @xcite .",
    "essentially , the reason lies in the fact that the likelihood function of an infinite mixture of distribution can be unbounded , hence resulting in inconsistencies",
    ". however , by making some assumptions about the parameters of this model , it is possible to accurately estimate them . in the following , we present the approach of  @xcite .",
    "therein , the authors present a simplified version of a jump - diffusion process by assuming that , if the jumps occurrence rate is small , then during a sufficiently short time period only a single jump can occur . accordingly , for small values of @xmath63 , @xmath64 can be approximated by a bernoulli distribution of parameter @xmath65 , and the density of @xmath66 can then be written as @xmath67 where @xmath68 denotes the probability density function of the diffusion part ( including the drift ) , @xmath69 the probability density function of the jump intensity , and @xmath70 denotes the convolution operator . as mentioned in   [ subsec : jumpmodels ] , @xmath68 follows a normal law with mean @xmath71 and variance @xmath72 .",
    "if @xmath69 is distributed according to a normal law statistically independent of the diffusion part , then the convolution @xmath73 of @xmath68 and @xmath69 is normal with mean @xmath74 and variance @xmath75 .    for a sequence of observed log - returns @xmath76",
    ", the log - likelihood @xmath77 of the model parameters @xmath78 is obtained in a straightforward manner from   as @xmath79 and the maximum likelihood estimator @xmath80 is obtained by maximizing  .",
    "@xcite has shown that there may exist several local minima in such a mixture setting , a fact that we have also observed in the experimental setup that is the subject of the next section .",
    "while fitting the ball - torous model to real - world data ( see   [ sec : app ] for more details and explanations about our experimental setup ) using  , we have figured out that the assumption @xmath81 might easily be violated in practice .",
    "indeed , we have observed on our data that , for @xmath82 ( i.e. , @xmath83 representing one day in a 252-day trading year ) , the best obtained estimation for @xmath22 ranged into the interval @xmath84 $ ] .",
    "this means that the value @xmath65 was often nearer to @xmath51 than to @xmath50 , and this obviously questions the validity in practice of the assumption made by ball and torous , at least in our experimental setup . in the following , we propose a new methodology revolving around relaxing this assumption to a milder one , namely that @xmath85 , and we justify its use .      the methodology we describe in this section can be interpreted as an extension of the work of  @xcite . in this approach ,",
    "the authors make the assumption that @xmath63 is small , or in other words , that the expected number of jumps per @xmath83 period is very small .",
    "however , in practice , this assumption might not always be satisfied , as we observed it on our data .",
    "we propose to relax this assumption and to replace it by the milder one @xmath86 . for @xmath87 , assuming @xmath88 trading days in a year , this translates to @xmath89 : concretely , it means that on average , there is no more than a single jump per day or , equivalently , no more than 252 jumps per year . we easily agree that this milder assumption may seem arbitrary at first sight .",
    "however , we show in   [ subsec : charac ] that it is not constraining at all , since one can easily prove that a jump - diffusion process converges in distribution to a pure diffusion process for increasing values of @xmath22 .",
    "to summarize , with our methodology , we are able to fit any jump diffusion without having any strong restriction on @xmath22 , which is a major improvement in comparison to the work of  @xcite .    obviously , the reason why ball and torous decided to limit the jump rate to a small value was to capture the apparition of brutal and rare events . as a matter of fact",
    ", it is clearly more desirable on a practical point of view to be able to model rare and large downside market movements than frequent and small ones .",
    "this assumption implies small @xmath65 values , and consequently , it means that the occurrence of more than a single jump per @xmath83 period is sufficiently unlikely that it can be neglected .",
    "however , we have experimentally figured out that the semivariance computed on our relaxed model , i.e. , allowing also frequent and small jumps , may result in significantly higher values than on the model assuming that @xmath63 is small ( see figure  [ graph : sds - jump ] ) .",
    "in other words , we observed that the ball and torous model seems to underestimate the downside risk , compared to our relaxed model , at least on our data set .",
    "a direct consequence of not limiting the jumps occurrence rate @xmath90 to a small values is that the probability of having more than one jump during a single day may become not negligible when @xmath22 is large enough . by allowing more than a single jump per @xmath83 period",
    ", one can also take into account the fact that several bad news might influence the market during a trading day , i.e. , during a @xmath83 period .",
    "obviously , if @xmath83 becomes sufficiently small , maybe as small as a single second , it would be more difficult to justify in practice several jumps during a time interval .",
    "however , when discretizing the process in periods as large as a single day , we are convinced that allowing more than a single jump better reflects the reality .",
    "consequently , in the following , we will assume that up to @xmath91 jumps are possible during a time interval of @xmath83 , where @xmath92 is a _",
    "finite _ value .",
    "the probability distribution of the possible number @xmath37 of jumps that may occur during a time interval @xmath83 is then the following : @xmath93 the resulting probability distribution , that we denote by @xmath94 and which can be compared to @xmath95 in  , can be expressed as @xmath96 where @xmath97 denotes the convolution of @xmath37 density functions @xmath69 .    in what follows ,",
    "we propose ourselves to look at the approximation error of replacing a poisson law by a truncated one . for a random variable following a poisson law of parameter @xmath22",
    ", the probability of obtaining a value strictly larger than @xmath98 is given by the following function @xmath99 : @xmath100 it is easy to see that @xmath99 is an increasing function in @xmath22 .",
    "indeed , the derivative of @xmath99 is given by @xmath101 then , we have @xmath102 for @xmath103 , since @xmath104 and where @xmath105 is set to @xmath50 as @xmath106 following this observation and telescoping the sum , the derivative @xmath107 can be rewritten as @xmath108 .",
    "now , if we substitute @xmath22 by @xmath63 and assuming @xmath86 , then we can observe that the supremum in   is obtained for @xmath109 .",
    "we conclude that , assuming that @xmath110 , the probability of having more than @xmath98 jumps is upper - bounded by the following expression : @xmath111 table  [ table : bounds ] gives a numerical upper bound for the probability of obtaining values strictly larger than @xmath98 for different values of @xmath98 when @xmath86 .",
    ".upper bounds for the probabilities of obtaining more than @xmath98 jumps for a poisson law with @xmath112 . [ cols=\"<,^,>\",options=\"header \" , ]     we can observe that the semideviation sd4 obtained with a stochastic volatility model seems to be more in line with the semideviations sd2 ( based on a jump - diffusion model ) and sd3 ( based on a pure diffusion model ) rather than sd1 ( square - root - of - time rule ) . this is not very surprising since sd4 may be interpreted as a refinement of sd2 , explaining why the two analytics should not be so different .",
    "in this paper , we propose a generalization of the ball - torous approximation of a jump - diffusion process and we show how to compute the semideviation based on several jump - diffusion models .",
    "we have in particular considered a very exhaustive example based on the barclays us high yield index , whose returns show negative skewness and fat tails .",
    "it is a common practice to impose a bound on the poisson process intensity parameter to make sure that only the large accidents are captured by the jumps process .",
    "however , our analysis clearly shows that the risk may be underestimated in such a situation . without constraining the intensity parameter , the semideviation may be more than @xmath113 % larger than the one obtained by arbitrary limiting this parameter in order to capture only large jumps .",
    "we see at least two reasons why our approach should be preferred .",
    "the first one is that we do not impose any arbitrary constraint on the intensity parameter . with our method ,",
    "this parameter is determined in order to obtain the best fit to the data .",
    "jumps may occur very often in certain periods and can be very uncommon ( as rare as a few ones per year ) in others .",
    "the second reason is that imposing an arbitrary limit on the intensity parameter may result in an underestimation of the risk .",
    "capturing the risk as accurately as possible is one of the most important mission in risk management .",
    "it is the reason why the  traditional \" approach based on the work of ball and torous does not seem appropriate in our context .",
    "moreover , one of our conclusions is that the use of the square - root - of - time rule may either underestimate the risk in periods of high volatility or underestimate it in periods of lower stress .",
    "we also provide in this paper a generalization of the work of eraker , johannes and polson , who consider a jump diffusion model with stochastic volatility and jumps in returns and in volatility . as in the case where the volatility is constant ,",
    "we have extended their approach by replacing the jump bernoulli process by a more general process being able to model several accidents per day when the intensity parameter is high .",
    "the parameter estimation methods are based on mcmc methods . in particular , we have used a gibbs sampler when the conditional distributions were known and variants of the metropolis algorithm when it was not the case .",
    "we also provide a procedure to compute an annualized semideviation once the parameters of the model have been estimated .",
    "it was not possible for us to go as far as we would like to when we have considered the model with stochastic volatility with jumps in returns and in volatility .",
    "it would have been very useful to be able to do the same rolling analyses that we have performed when the volatility was kept constant .",
    "however , such analyses would have been too much time consuming from a computational point of view and it would have been complicated to automate the check of the convergence of the process that needs to be done for each period in the rolling analysis . this was clearly a limitation when we have tried to determine empirically the relationship between the daily semideviation and its annualized version .",
    "we really think that the use of the semideviation ( or semivariance ) could benefit the finance industry by providing a useful and powerful risk measure .",
    "this risk metric has been proposed a very long time ago but its difficulty to be computed and its lack of nice properties for its scaling made it hard to implement . however ,",
    "we have shown in this article that it is still possible to calculate it even when we consider very complex stochastic processes and that some useful formula for its time scaling can be derived under some mild assumptions . finally , we hope that this paper will help democratize its use in the asset management industry",
    ". +   + * disclaimer : * the views expressed in this article are the sole responsibility of the authors and do not necessarily reflect those of pictet asset management sa .",
    "any remaining errors or shortcomings are the authors responsibility .",
    "as a first step , we note the two following identities : @xmath114 the first one can be easily obtained by observing that @xmath115 and @xmath116 . then , @xmath117 for obtaining the second identity , one can proceed as follows : we note that , for a standardized normal density @xmath118 , @xmath119 . integrating by part ,",
    "we get @xmath120 we can conclude by noting that @xmath121 . those two identities are useful to prove the following result .",
    "[ prop : prop0 ] let @xmath122 , with a density function @xmath123 and let @xmath124 ; then , the semivariance of @xmath125 is given by @xmath126    by first using the change of variable @xmath127 and the identities given in  , we obtain the following straightforward development . @xmath128    taking into account that the log returns follow the density given in  , we can apply proposition  [ prop : prop0 ] on   to obtain the formula of theorem  [ the : semivariance ] .",
    "using a jump - diffusion process is a standard practice for modeling a stock price .",
    "we explain here why it is possible to use this model for a bond benchmark index , because this may seem disturbing at a first sight .",
    "indeed , the particularities of a stock and of a bond are quite different .",
    "in particular , a bond has a well - defined maturity , while it is not the case for a stock .",
    "moreover , the clean price of a bond converges to 100 at its maturity .",
    "this is the well - known bond pull - to - par effect .",
    "however , when considering a bond benchmark , most of criticisms in favor of not using an equity model in this context become irrelevant . indeed",
    ", bond benchmarks have some characteristics that are quite different from a bond .",
    "for example , they are typically rebalanced on a monthly basis and their maturity are ( almost ) kept constant , while the maturity of a bond decreases linearly with time .",
    "the bonds with the shortest maturity ( for example less than 1 year ) are automatically removed from the index .",
    "a direct consequence of holding the maturity ( almost ) constant is that the pull - to - par effect at the portfolio level is not relevant anymore .",
    "another distinction between a bond and a stock is that a bond pays coupons while a stock pays dividends .",
    "when a coupon is paid , its dirty price falls for an amount equivalent to the coupons .",
    "however , it is not necessary to model the coupon payments for bond benchmarks , since the rules they obey imply that the coupons are automatically reinvested .",
    "concretely , it means that the payment of a coupon does not impact the benchmark index .    moreover , in a diffusion model , the stock price increases exponentially if we ignore the random part of the model .",
    "this is a direct consequence of the fact the returns are not additive , but must be compounded .",
    "this also applies to a bond benchmark index where the performance is also compounded",
    ".    finally , as stock markets may experience crashes , bond markets may also suffered from extremely severe and sudden losses justifying the use of jumps in returns and in volatility .",
    "all these remarks suggest that using a jump - diffusion process to model a bond benchmark index seems to be appropriate , even though the dynamics driving bonds are different from the ones driving stocks .",
    "but at the portfolio level , and when we consider a bond benchmark with a constant maturity , there is no fundamental reason for not approximating the dynamics of the index level as if it were a stock price .",
    "our mcmc algorithm is implemented in r language and relies on the code provided by  @xcite .",
    "we have modified their implementation in order to cope with the model that we have introduced in this paper .",
    "the starting values for our algorithm were generated as follows .",
    "the volatility vector was created using a three - month rolling window .",
    "we considered as jumps absolute returns ( the absolute value of the returns ) that were above @xmath129 standard deviations above the mean ( after accounting for outliers ) . for a standardized normal distribution",
    ", @xmath129 corresponds to its @xmath130-quantile , meaning that we should expect that approximately @xmath6 of the absolute returns to be larger that this threshold .",
    "indeed , in our data , we had more than @xmath131 of the data exceeding this threshold , confirming the presence of jumps in returns .",
    "once these  accidents \" have been identified , we still need to determine the jump return size , the jump volatility size and the number of jumps that have happened . indeed , with our methodology , it is possible to have more than a single jump occurring during a specific date . provided that the jump sizes are by construction far larger than that returns observed during the days without  accidents \"",
    ", we have considered that the jump size corresponds to the observed daily returns .",
    "for example , if we have identified a jump and if the observed return is -67 bps for that date , then we consider that the jump size is the same amount .",
    "we have made a similar assumption for the volatility .",
    "so the volatility jump simply correspond to the difference in volatility between the actual estimation for a particular day and the day before .",
    "the process followed by the sum of the jump returns is a poisson compound variable with normally distributed jumps . the same for the process followed by the sum of the volatility jumps , except that the jumps are this time exponentially distributed .",
    "provided that the jumps can be negative or positive for returns but not for the volatilities ( always positive ) , it is much easier to consider the volatility to determine the number of jumps .",
    "it is the reason why we consider a compound poisson process @xmath132 for the jumps in volatility where the poisson process results in a @xmath133 and the jump sizes are exponential variables @xmath134 of parameter @xmath135 .",
    "it is easy to show that the distribution function @xmath136 of the process @xmath132 is simply given by @xmath137 where @xmath138 . if there is no jump , then @xmath139 with probability @xmath140 .",
    "a direct consequence is that the density does not exist . in order to overcome this issue",
    ", we propose to estimate @xmath22 based on the proportion of days having at least a jump .",
    "the probability of having no accident in a particular day is @xmath141 , when @xmath22 is small .",
    "from that formula , we can simply estimate @xmath22 by the ratio of days with at least one jump over the total number of days within that period .",
    "once these parameters have been estimated , we still need to determine the number of jumps occurring when an accident is detected .",
    "it is well - known that the convolution of @xmath37 iid exponential variables is given by a gamma distribution with parameters @xmath37 and @xmath22 .",
    "so , based on the observation of the jump size , we can determine the number of jumps by determining which @xmath37 gives the highest density .",
    "+ having determined the state space variables , we can now tackle the problem of estimating the model parameters .",
    "we have implemented either the gibbs sampler or metropolis - hasting depending on whether or not we knew the closed form of the parameters distributions . in order to able to compare our results with those in  @xcite and in  @xcite",
    ", we have used the same priors .",
    "note that little information is imposed through priors .",
    "they are as follows : @xmath142 , and @xmath143 .",
    "another reason for us to use parameters provided by other studies is to guarantee that the priors have been determined independently from their posterior distributions . in  @xcite",
    ", it was also shown that these priors may lead to very different posteriors when applied to s&p  500 and nasdaq  100 index returns .",
    "moreover , the main objective of our work is not to challenge the estimation of the parameters and in particular the assumptions about the priors , but merely to show that it is possible to compute a semideviation even when we consider complex stochastic processes ."
  ],
  "abstract_text": [
    "<S> the aim of this paper is to examine the time scaling of the semivariance when returns are modeled by various types of jump - diffusion processes , including stochastic volatility models with jumps in returns and in volatility . in particular , we derive an exact formula for the semivariance when the volatility is kept constant , explaining how it should be scaled when considering a lower frequency . </S>",
    "<S> we also provide and justify the use of a generalization of the ball - torous approximation of a jump - diffusion process , this new model appearing to deliver a more accurate estimation of the downside risk . </S>",
    "<S> we use markov chain monte carlo ( mcmc ) methods to fit our stochastic volatility model . for the tests , </S>",
    "<S> we apply our methodology to a highly skewed set of returns based on the barclays us high yield index , where we compare different time scalings for the semivariance . </S>",
    "<S> our work shows that the square root of the time horizon seems to be a poor approximation in the context of semivariance and that our methodology based on jump - diffusion processes gives much better results . </S>",
    "<S> +   + * keywords : * time - scaling of risk , semivariance , jump diffusion , stochastic volatility , mcmc methods </S>"
  ]
}