{
  "article_text": [
    "after several decades of intensive searches , direct detection experiments have now reached the required sensitivity to probe efficiently the parameter space associated with massive weakly interacting massive particles ( wimps ) .",
    "just a few years after the world s best exclusion limits set by the edelweiss and cdms experiments on the dark matter - nucleon elastic scattering cross section , the xenon100 experiment demonstrated that the use of xenon based technologies could actually beat germanium detectors . by pushing down the exclusion limit by almost a factor 10 on the whole dark matter ( dm ) mass range ( and with the present level of krypton purity @xcite ) , the xenon100 experiment not only could rule out values of the dm - nucleon cross section as low as @xmath2 @xmath3 for dm particle masses of @xmath4 50 gev at 90@xmath5 confidence level @xcite but could also exclude ( similarly to cdms ) some of the light dm candidates which have been hypothesised to explain cogent @xcite , dama / libra @xcite , cresst @xcite and coupp @xcite findings ( unless one relaxes some assumptions as done in e.g. @xcite even though this may not be sufficient , e.g. @xcite ) .",
    "one element of controversy in the interpretation of these results is the dependence of this limit on the scintillation efficiency of the detector ( see for example @xcite ) .",
    "a different @xmath1 energy dependence at low nuclear recoil energy could indeed change the recoil energy associated with low mass wimps and possibly lead to a different exclusion limit than published in @xcite . to address this issue",
    ", the xenon100 collaboration used a profile likelihood analysis in which @xmath1 was taken to be a nuisance parameter and its uncertainties were profiled out with a gaussian likelihood @xmath6 where @xmath7 represents the mean value of @xmath1 smoothly extrapolated to zero ( @xmath8 ) at low energy and @xmath9 , the @xmath10 confidence region .",
    "a flat behaviour of @xmath1 at low energy would then be the upper limit of the 1-sigma contour.in principle , armed with such a modelling , the collaboration accounts for uncertainties in the extrapolation of @xmath1 at low energy .",
    "this is important since the @xmath1 energy behaviour below 3 kevnr is being currently debated .",
    "however , as the xenon100 analysis is very complex and relies on many sources of uncertainties , the use of this method makes it difficult to determine what would be the real impact of a very different energy behaviour of @xmath1 ( with respect to the mean considered by the xenon100 collaboration ) on the exclusion limit if the latter was determined from new data with unprecedented precision below 3 kevnr ( or if some existing data were found to be less reliable than previously thought ) .",
    "this is particularly important in the context of light dark matter candidates ( eg .",
    "@xcite ) where small recoil energies are expected .",
    "our work is essentially motivated by the fact that some light dark matter scenarios lie very close to the xenon100 limit and should be therefore very sensitive to new measurements of @xmath1 below 3 kevnr .",
    "several of these scenarios can not be constrained by the lhc nor the measurement of the @xmath11-ray , synchrotron fluxes nor even directional detectors ( see for example @xcite ) .",
    "nuclear recoil direct detection experiments might be the only option to exclude or discover such scenarios , thus emphasising the need for a better determination of @xmath1 at low energy . in order to properly account for the lack of determination of the low energy behaviour of @xmath1 , it is necessary to make transparent the correspondence between the @xmath1 energy behaviour and the exclusion limit .",
    "therefore , here , we will not treat @xmath1 as a nuisance parameter .",
    "instead we will use directly the value of @xmath1 obtained from spline fits to the data and will not profile out the uncertainties ( due in particular to the extrapolation at low energy ) so as to quantify the effect @xmath1 has on the exclusion limit .",
    "the estimate of the uncertainties presented in this work is limited since we are not part of the collaboration .",
    "it is likely that we do not use up - to - date methods and data ( as a matter of fact new data should be published soon ) .",
    "also we base our analysis on several assumptions which are explained in the sections below . however , despite all these limitations , we could recover the exclusion limit that xenon100 collaboration has obtained and can therefore highlight the large impact the low energy behaviour of @xmath1 has on the exclusion limit .",
    "note that in this paper we focus on @xmath1 uncertainties only ; the astrophysical uncertainties will be addressed elsewhere .    in section [ leff ] , we recall the spline interpolation to @xmath1 dataset as well as the extrapolation at low energies and discuss the robustness of the fit using an extended filter formalism .",
    "we use different types of interpolation and extrapolation ( consistent with the 1-sigma contour defined by xenon100 in @xcite ) . in section [ exclu ] , we derive the exclusion limit for the mean @xmath1 interpolation and compute the exclusion limits for more extreme @xmath1 behaviour at low energies .",
    "results are given in [ sec : results ] and conclusion in [ sec : conclusion ] .",
    "the xenon100 experiment aims at detecting dark matter particles via their elastic scattering interactions with xenon nuclei in a two - phase ( liquid and gas ) time - projection chamber ( tpc ) detector .",
    "a dm signal is then expected to have two signatures .",
    "the first one , referred to as the primary scintillation signal @xmath12 , arises directly from the interaction of a dm particle with the liquid xenon and measure the scintillation light in the liquid detector . the second , referred to as @xmath13 , happens in the upper part of the detector  at the liquid - gas interface  and measures the scintillation light which results from the drift of the free electrons that originate from the ionisation of the xenon nuclei in the liquid phase after the dm interaction and which survived the recombination with ionised atoms .",
    "both signals are measured in photon - electrons units ( pe ) @xcite and are used to calibrate the detector s response to nuclear recoil events and ultimately to determine whether the experiment has actually detected dark matter events .",
    "the discrimination parameter is defined as @xmath14 events below the threshold of @xmath15 in the expected energy range are considered as potential dm events .",
    "the xenon100 experiment uses the ratio of the two signals @xmath12 and @xmath13 to discriminate between a dm and a background event so the identification of signal is actually sensitive to the primary scintillation yield of recoiling xenon nuclei in the liquid part of the detector . as the measurement of the absolute scintillation yield is difficult , the quantity that is used by the collaboration is the scintillation yield of nuclear recoils relative to that of 122 kev @xmath11 rays from a @xmath16co source .",
    "this is called the relative scintillation efficiency and is referred to as @xmath1 .",
    "the nuclear - recoil energy threshold @xmath17 ( in units of kevnr ) of a signal is then determined by both @xmath12 and @xmath1 according to the relation , @xmath18 where @xmath19 is a normalisation factor for the light - yield of the 122 kev gamma rays and @xmath20 , @xmath21 are scintillation quenching factors for electronic and nuclear recoil respectively , due to the presence of an electric field ( for xenon100 , the values used are @xmath22 and @xmath23 )",
    ".    the determination of @xmath19 and @xmath1 are therefore of utmost importance .",
    "while @xmath19 has been measured precisely to @xmath24 , there is no theoretical prediction for the energy dependence of @xmath1 .",
    "an empirical formula was obtained in @xcite by fitting the data obtained in the same reference , namely @xmath25 with @xmath26 the lindhard factor ( cf @xcite ) , @xmath27 reduction of the scintillation light yield and @xmath28 a quench factor due to bi - excitonic collisions @xcite .",
    "such an empirical fit reproduces the observation that the @xmath1 data decrease with decreasing energy and is also the assumption made by the xenon100 collaboration in @xcite in order to obtain a conservative exclusion limit . yet",
    "there are no measurement of @xmath1 at low recoil energy . besides",
    ", theoretical considerations by @xcite seem to favour a constant behaviour of @xmath1 at low energy",
    ". this would be consistent with the fit obtained by the xenon10 collaboration @xcite .",
    "the xenon100 collaboration s strategy to incorporate the uncertainties on @xmath1 is to consider @xmath1 as a nuisance parameter and profile out the uncertainties with a gaussian likelihood centred on the mean value of @xmath1 , that is the best fit .",
    "similar assumptions are made for the other parameters which enter the analysis .",
    "although this seems a robust approach , it is not very transparent . in particular",
    ", one loses the correspondence between the exclusion limit and the uncertainties on @xmath1 which arise due to a specific spline interpolation of the data and extrapolation at low energies .",
    "indeed , the 1-sigma contour for @xmath1 does not show on the exclusion curve obtained in @xcite but since these uncertainties are due to the lack of data , one does expect to be able to keep track of them . in addition , it is hard to tell whether the final exclusion curve does take into account possible changes in the knots of the interpolation .    in the following ,",
    "we therefore adopt a different strategy .",
    "we still use a profile likelihood analysis but we do not treat @xmath1 as a nuisance parameter . as a result , we can directly see the effect of the uncertainties on @xmath1 interpolation and extrapolation on the exclusion limit . we thus obtain several exclusion limits where the mean should be seen as the exclusion limit corresponding to the best fit of @xmath1 and where the edges of the contours correspond to the upper and lower parts of the @xmath1 1-sigma bands . said differently , instead of obtaining one exclusion curve which would correspond to the best fit given all the uncertainties in the analysis , we prefer to draw the exclusion curves corresponding to the mean value and 1-sigma bands of @xmath1 and let the reader marginalise by eyes the effect of @xmath1 on the exclusion curve .",
    "this approach enables us to anticipate the effect of a possible change in the physics of @xmath1 below 3 kevnr .      to overcome the lack of knowledge about the low energy behaviour of @xmath1 , it was suggested by the xenon100 collaboration to perform an interpolation of the chepel et al .",
    "@xcite , manzur et al .",
    "@xcite , plante et al . @xcite and aprile et al .",
    "@xcite @xmath1 data sets and perform an extrapolation below 3 kevnr . since older data sets ( e.g. @xcite , @xcite,@xcite,@xcite ) were disregarded in @xcite , we will only consider them to understand their impact on the @xmath1 interpolation using the nuclear - recoil band of xenon10 .",
    "this data is not considered in our fits , but does provide an interesting alternative method of determining the relative scintillation efficiency of xenon . ] .    like in @xcite , we perform a cubic spline interpolation to the four datasets previously mentioned and use five knots , placed at recoil energies of @xmath29 and @xmath30 kevnr respectively .",
    "the best - fit cubic spline is found by freely varying the y - axis positions of these knots , while minimising the least - squares @xmath31 goodness - of - fit parameter between the interpolated spline and the data ( see @xcite for a good discussion of the methodology ) .",
    "the result is shown in figure [ fig : leff ] , along with the one sigma contour , obtained by looking for the maximum and minimum y - axis positions of the knots which satisfy @xmath32 .     and @xmath30 kevnr .",
    "the uncertainty on the extrapolation is reflected in the top and bottom curves of the one sigma blue band .",
    "note that recoil energy refers specifically to nuclear - recoils here . ]",
    "the choice of the x - positions of these five knots being somewhat arbitrary , we now perform another cubic spline interpolation where we place the knots at @xmath33 , @xmath34 , @xmath35 , @xmath36 and @xmath30 @xmath37 . the translation of the lowest knot , from @xmath38 to @xmath39 , has been performed to illustrate the effect of ignoring the potentially less - reliable data below @xmath39 . as can be seen in fig .",
    "[ fig : leff_newknots ] , the greatest change due to the new knot positions ( @xmath40 kevnr and the additional knot at 75 kevnr ) appears to be the enlargement of the errors in the extrapolated region for energies below the first knot . however there are also clear alterations to the interpolation around @xmath41 .",
    "changing the knots influences the @xmath1 energy dependence .",
    "in particular , it changes the shape at high and very low energy . by adding a knot at 75 kevnr , we actually gave some weight to the single point at ( 55.2,0.268 ) which has for effect to drag the curve up around 50 kevnr .",
    "removing the knot at 5 kevnr and instead extrapolating also changes the behaviour of @xmath1 at low energy .",
    "in particular , the uncertainties on @xmath1 become larger below 10 kevnr and notably the constant extrapolation moves to higher values of @xmath1 .",
    "since there are no data - points below nuclear - recoil energies of @xmath42 there is a great uncertainty on the energy dependence of @xmath1 at low recoil energies .",
    "the empirical behaviour found in @xcite seems to imply that @xmath1 falls down to 0 at low energy in a way which would be consistent with the spline fit of @xmath1 at higher energy .",
    "however , @xcite suggests that based on the physics of xenon recoil and an understanding of both the ionisation yield and scintillation efficiency , @xmath1 should be constant below 10 kevnr .",
    "such an energy behaviour would be supported by @xcite where it is argued that the drop in the scintillation efficiency observed by @xcite could be due to the drop in sensitivity in the experiment .",
    "given the lack of data , we will perform an extrapolation of our curves at low energy as in @xcite .",
    "i.e. we adopt either a constant @xmath1 below a certain energy threshold or a drop to 0 .",
    "for this latter case , we either extend the spline fit to 1 kevnr or to 2 kevnr ( as in @xcite ) . the uncertainty on the extrapolation",
    "is reflected in the top and bottom curves of the one sigma blue band in both figs.[fig : leff ] and [ fig : leff_newknots ] .",
    "finally , we also try a sharp cut - off of @xmath1 at low energy for the bottom curve of fig.[fig : leff_newknots ] in order to obtain the most conservative limit .",
    "figures [ fig : leff ] and [ fig : leff_newknots ] show that even with slight modifications in the fitting procedure , the results for @xmath43 as a function of recoil energy can change significantly . in order to check the quality of a certain fit to the data",
    ", we employ the _ extended critical filter _",
    "formalism presented in @xcite .",
    "this formalism finds a fit to a noisy data set by making use of the error statistics of the data points as well as a gaussian prior probability distribution for the underlying curve .",
    "it is taking into account the possibility of outliers in the data , i.e.  data points with significantly underestimated error bars .",
    "this seems to be beneficial in the case of the @xmath43 measurements due to the wide spread and apparent inconsistency of the different data sets .    here",
    ", we feed the algorithm with different @xmath43-curves as mean for the gaussian prior . if the prior mean is already a sufficiently good fit to the data set , the result of the extended critical filter procedure will not deviate from it . if , on the other hand , the result of the data filtering differs from the prior mean input , it is a sign that the data prefer a different curve , even though the possibility of individual data points being outliers is accounted for .",
    "these outliers are accounted for in the algorithm by the inclusion of a correction factor for the error bar of each data point ( see @xcite for all technical details ) . by narrowing the prior probability distribution for these correction factors",
    ", we can force the algorithm to take each data point more seriously and thus find out which of the fits is most consistent with the data .    in this way",
    ", we study the quality of the two cubic spline fits shown in figs .",
    "[ fig : leff ] and [ fig : leff_newknots ] , as well as the @xmath43-curves given by the upper and lower one - sigma contours ( i.e. the edges of the blue - shaded regions in figs .",
    "[ fig : leff ] and [ fig : leff_newknots ] ) . using a reasonably wide prior for the error bar correction factors , we find that all of these curves are consistent with the data , except the top edge of the one - sigma region in fig .  [",
    "fig : leff ] .",
    "the exclusion of this one curve might , however , well be due to its behavior at large recoil energies and is likely not to be related to the extrapolation at lowest energies since the top one - sigma curve in fig .",
    "[ fig : leff_newknots ] is not excluded although it is a more extreme extrapolation . note also that the behavior at recoil energies below @xmath44 is not constrained by this analysis .    when narrowing the prior for the error bar correction factors to more and more extreme shapes , more curves are successively excluded .",
    "it can thus be determined that the central fit in fig .",
    "[ fig : leff ] is the most consistent one with the data .",
    "the multitude of @xmath43-curves that is consistent with the present data , however , clearly underlines the importance of studying their influence on the resulting exclusion curve .",
    "in fact , yet another fit can be obtained by using a constant curve as prior mean for the extended critical filter and narrowing the prior for the error bar correction factors until deviations from this constant become significant .",
    "the resulting curve is shown in fig .",
    "[ fig : ecfresult ] , along with the one - sigma contours of the two spline - fits shown in figs .",
    "[ fig : leff ] and [ fig : leff_newknots ] .     and",
    "[ fig : leff_newknots ] . ]",
    "now that we have determined the uncertainties on @xmath1 , we can compute the counting rate of dark matter events expected in the xenon100 detector and deduce an exclusion limit for a given @xmath1 .",
    "for this purpose , we use a profile likelihood ratio method and compute p - values for the signal and background , as done in @xcite after randomly simulating 10000 mock data sets based on the xenon100 data published in @xcite .      the recoil rate ( per nucleus ) is parameterised in the standard form of @xcite , @xmath45 where @xmath46 is the wimp - nucleus cross - section , @xmath47 is the nuclear recoil momentum ( with @xmath48 being the nucleus mass ) , @xmath49 is the wimp mass , @xmath50 is the wimp - nucleus reduced mass , @xmath51 is the local wimp density and @xmath52 is the wimp mean speed , given by the expression @xmath53 in the above integral , @xmath54 is the relative velocity between the earth - based detector and the wimps , with time - dependence arising from the motion of the earth around the sun , and @xmath55 is the minimum velocity for a wimp producing a nuclear - recoil of energy @xmath56 . any astrophysical uncertainties , such as dependance on the galactic wimp velocity distribution @xmath57 , will arise through this @xmath52 , and could affect the analysis . note that the standard halo model is used in the proceeding analysis and we took the average velocity over the year and multiplied the final rate by 100 days ( in accordance with @xcite where the total number of expected events assumes a run of @xmath30 days with a fiducial volume of @xmath58 kg ) .",
    "the wimp - nucleus cross - section @xmath46 can be further parameterised ( assuming spin - independent interactions , and equal coupling to protons and neutrons ) as , @xmath59 where @xmath60 is the zero - momentum - transfer cross section for wimp - nucleon interactions ( hereafter any references to cross - section will be to @xmath60 ) , @xmath61 is the atomic mass , @xmath62 is the wimp - proton reduced mass and @xmath63 is the nuclear form factor ( taken to be of the standard helm form here ) @xcite .",
    "equation can now be used to calculate the signal rate per number of photoelectrons @xmath64 in the detector : @xmath65 where @xmath66 refers to the poisson distribution @xmath67 @xcite . here",
    "@xmath68 is the expected number of photoelectrons in the detector at an energy @xmath56 and is given by the expression @xmath69 where @xmath70 gives the number of expected scintillation photons from a nuclear recoil per @xmath71 of nuclear - recoil energy @xmath56 .    in order to translate the expected rate per photoelectron @xmath72 into something comparable with data",
    ", one must factor in the finite photomultiplier resolution @xmath73 and knowledge about cut acceptance @xmath74 .",
    "this gives an expression for the rate per nuclear - recoil signal ( @xmath75 ) : @xmath76 here @xmath77 is a gaussian distribution @xmath78    it is then possible to calculate the expected number of signal events in the detector @xmath79 , by integrating @xmath80 in this case the region between @xmath81 and @xmath82 is considered .",
    "the analysis described below follows the approach presented in @xcite and centres around the application of the profile likelihood method .",
    "the analysis takes as input , both theoretical parameters , such as the expected number of signal events @xmath79 for a given wimp mass @xmath83 and cross - section @xmath46 , and a set of data - points .",
    "the so - called profile likelihood ratio for a particular dataset can be expressed as @xmath84 where here @xmath85 refers to the likelihood function maximised with respect to all parameters but @xmath46 , which is held fixed , and @xmath86 refers to the likelihood maximised with respect to all variable parameters , galactic escape velocity @xmath87 , total number of background events @xmath88 and the probabilities to be signal and background events @xmath89 and @xmath90 respectively .",
    "the quantity @xmath91 defined as @xmath92 with @xmath93 being the value of the cross - section which extremises the likelihood function measures the quality of the fit for that particular dataset and dark matter parameters ( mass and cross section ) .",
    "the larger @xmath91 is , the less signal - like these parameters are supposed to be , thus ruling out this particular value of @xmath46 for a given dark matter mass and dataset . in principle , for every mass one should test the entire range of cross section that one initially considered . here , however , we only tested values of the cross section which are relatively close to the xenon100 limit by using a step - size of @xmath94 in a range defined as @xmath95 $ ] with @xmath96 the value of the dark matter - nuclei cross section at the exclusion limit .",
    "the question of the set of data - points that should be considered for the analysis is essential . in the following",
    ", we will use both the experimental dataset given in @xcite and simulated datasets that we will generate using a monte carlo . by considering hypothetical alternate xenon100 experiments , represented by randomly simulated datasets ( see subsection[datsets ] ) ,",
    "one therefore takes into account the random nature of the experimental data . with this in mind",
    ", there should be a certain proportion of simulated datasets ( the exact value of which depends on the chosen confidence ) which provide a better fit than the actual experimental data .",
    "the log of the statistical test ( @xmath91 ) for a given dataset , dark matter mass and cross section is uniquely determined",
    ". we will refer to it as @xmath97 when using the experimental data set and @xmath91 otherwise . to a given simulated data",
    "set corresponds a certain value of @xmath91 ( for fixed dark matter parameters ) .",
    "thus , one expects a @xmath91 distribution , which can be used to define a @xmath98-value .",
    "the signal and background p - values ( @xmath99 and @xmath100 respectively ) , are defined as : @xmath101 here @xmath102 is the probability density function ( pdf ) of all the @xmath91 values from simulated datasets , under the so - called signal hypothesis @xmath103 , while @xmath104 is the pdf for the background hypothesis @xmath105 ( cf subsection [ datsets ] ) for fixed dark matter parameters . here",
    "@xmath105 refers to the electronic recoil events only while @xmath103 refers to the electronic and nuclear recoil events .    under a desired confidence of @xmath106",
    ", one defines the exclusion curve by satisfying the condition that @xmath107 for each dark matter mass . incorporating the p - value for the background hypothesis @xmath108 into the calculation of the exclusion curve enables to take into account the possibility that the background can mimic a wimp discovery signal , by explicitly requiring the chosen cross - section and dark matter mass to fit better to the signal hypothesis @xmath103 than @xmath108 .",
    "this is particularly important given the overabundance of background points compared to signal points for the xenon100 data .",
    "our likelihood function is the same as in @xcite except that we do not parameterise the uncertainty in the relative scintillation efficiency so as to make explicit the impact of @xmath1 on the exclusion limit .    like @xcite",
    ", we make use of bands to discriminate between electronic and nuclear recoils in s1-s2 space , thereby separating the signal from the background , allowing a more stringent limit to be placed on wimp mass and interaction cross - section .",
    "the likelihood function ( @xmath109 ) is given by the equation below : @xmath110 where here @xmath111 is run over each of the 23 bands ( the bands themselves are shown in figure [ fig : sg_dataset ] ) , and @xmath112 is the number of data points in band @xmath111 .    the first term parameterises uncertainty in the escape velocity @xmath87 , which is treated as a nuisance parameter here .",
    "the second term compares , using a poisson - distribution function , the number of expected data - points in each band @xmath111 for both signal and background , to the actual number of points @xmath112 . here",
    "@xmath113 is the probability for a background event to be in band @xmath111 and @xmath89 is the equivalent for signal events , as determined from calibration data .",
    "we start by defining @xmath114 as @xmath115 where @xmath116 is the number of electronic recoil data points in band j as appearing in the calibration data , @xmath117 , and then marginalise over it .",
    "similarly , before marginalisation , @xmath118 where @xmath119 is the number of nuclear recoil data points in band j as appearing in the calibration data @xmath120 .",
    "the product @xmath121 represents the expected number of signal events which fall into the nuclear recoil bands ( given a particular cross section , wimp mass and choice of @xmath1 ) .    since the expected total number of signal events @xmath79 is a function of cross - section @xmath46 , data - points in bands where @xmath122 will have the greatest effect on the best - fit @xmath46 value for a particular dataset .",
    "in particular the analysis is very sensitive to any data - points appearing in the lower bands ( see figures [ fig : sg_dataset ] and [ fig : cal_contours ] ) , where electronic recoil / background events are unlikely to occur .",
    "finally the last two terms parameterise the uncertainty in probabilities @xmath89 and @xmath113 , due to the expected poisson - variance of the number of @xmath123ambe and @xmath16co calibration data - points in each band , @xmath119 and @xmath116 ( here @xmath124 and @xmath125 are the total numbers of nuclear and electronic recoil points respectively for the calibration data ) .",
    "since simulated datasets play a vital role in determining the pdfs @xmath102 and @xmath104 , it is important to discuss their method of generation , and the uncertainties involved .    as discussed in the previous section , by defining an exclusion curve at @xmath106 ( or any value different from @xmath126 ) ,",
    "the naturally random nature of the experiment is taken into account .",
    "since the xenon100 experiment can only ever be performed once , it is possible that any observation , or non - observation , of possible signal data - points could be due , wholly or in - part , to statistical fluctuations .",
    "one seeks to improve this possibility by positing hypothetical alternate xenon100 experiments , which differ only in their sampling of the statistics .",
    "practically these alternate data - sets are represented by simulations , based on the actual experimental data @xcite .    since the simulated data should attempt to mimic that obtained by the experiment ,",
    "the data - points must be arranged on the s1-s2 plane , where s1 is equal to the number of photoelectrons observed for a particular event , and s2 represents the ionisation yield .",
    "this can be achieved with knowledge of the expected distribution of nuclear - recoils , associated with wimp signal events , and electronic - recoils , associated with background events , in s1-s2 space .",
    "such information is contained in the calibration data obtained by the xenon100 experiment , who used a @xmath16co source for samples of electronic recoils and an @xmath123ambe source for nuclear recoils .    in practice",
    "this calibration data is binned and normalised , to give a pdf for signal and background events , shown in figure [ fig : cal_contours ] . given a desired number of signal ( nuclear - recoil ) and background ( electronic - recoil ) events ,",
    "a simple monte carlo algorithm can be used to generate simulated datasets .",
    "it is possible to extend the simulation algorithm further , and improve the accuracy of the simulated datasets , by incorporating information about the wimp energy spectrum , equation , into the determination of the nuclear - recoil data - points .",
    "however , since there are very few candidate signal points seen in the data , and to avoid possible problems with bias , this extension has not been incorporated into the current analysis .",
    "even so , the uncertainty in exactly how to simulate datasets most accurately will contribute a source of uncertainty to the final exclusion curve .    the above method was used to generate @xmath127 simulated datasets , with an expected number of @xmath128 signal events ( nuclear - recoils ) and @xmath129 background events ( electronic - recoils ) , between @xmath130 and @xmath131 , as seen in the data obtained by the run of the xenon100 experiment @xcite after 100 live days of data - taking .. however the increase in sensitivity is granted at the cost of greater susceptibility to systematics , especially the @xmath132 uncertainty . ]",
    "in addition to these signal + background datasets , so - called background - only datasets were generated , with an expected number of @xmath133 background events and no signal events .",
    "a plot of one such signal+background simulated dataset is shown in figure [ fig : sg_dataset ] .",
    "the analysis itself is blind to whether a point was generated as a nuclear or electronic recoil , however the fitting of the cross - section is more sensitive to the lower bands , where fewer background events are expected . due to the abundance of electronic - recoil events compared to nuclear - recoils , determining which points are due to which is a difficult challenge , and",
    "so a clearer discrimination between signal and background only arises statistically when considering many such datasets , motivating the choice of a confidence limit other than @xmath126 for the xenon100 limit .",
    "hence , even with high statistics , the ability of the analytical tools to discriminate signal from background is limited , contributing a natural source of error to any determination of the best - fit values of the cross - section and number of background events , and so ultimately to the final exclusion curve .",
    "values of @xmath91 were calculated for each dataset under the prescription of section [ sec : stats ] .",
    "the signal+background and background - only @xmath91 values were then binned separately into two normalised histograms ( for each value of cross - section and wimp mass ) , to give the pdfs @xmath102 and @xmath104 respectively . in this way",
    ", the signal+background datasets represent the signal hypothesis @xmath103 , as they are generated under the assumption that the two candidates - signal events seen in the xenon100 data are in fact due to nuclear recoils .",
    "conversely the background - only datasets take these points to be due to background electronic - recoils , thereby coming under the background hypothesis .",
    "an example of @xmath102 , for a specific wimp mass and cross - section , is shown in figure [ fig : qsigmapdf7 ] .",
    "note that , due to wilks theorem one expects the pdf to approach a @xmath31 distribution as the number of sampled datasets increases , a trend which is indeed observed .     under the signal hypothesis , for a wimp mass of @xmath134 and @xmath135 .",
    "the pdf has been constructed using @xmath127 simulated datasets , assuming @xmath128 expected signal events and @xmath129 expected background events .",
    "the actual points of the pdf are shown as bars , while the best - fit @xmath31 distribution is shown as a black line .",
    "the blue dashed line indicates the value of @xmath91 for the real experimental dataset . ]",
    "each pdf is fitted with an analytical @xmath31 function , to speed up computation and to avoid susceptibility to statistical fluctuations at higher values of @xmath91 .",
    "the value of @xmath46 which satisfies equation is sensitive to this fit , for both @xmath102 and @xmath104 , and so any uncertainty in the best - fit @xmath31 function will contribute to the uncertainty in the final exclusion curve .",
    "the profile likelihood analysis has been performed using the best cubic spline fit to @xmath132 , along with the top and bottom edges of the one - sigma bands from figures [ fig : leff ] and [ fig : leff_newknots ] .",
    "the resulting exclusion curves are shown in figure [ fig : onesigmacurve ] .     from figure",
    "[ fig : leff ] , shown in red , along with the one sigma systematic uncertainty due to @xmath132 from the fit of figure [ fig : leff ] , in blue , and the one sigma uncertainty from the fit of figure [ fig : leff_newknots ] , in yellow .",
    "note that all exclusion curves have a natural uncertainty of @xmath136 . ]    clearly the systematic uncertainty due to the relative scintillation efficiency is appreciably large for wimp masses below @xmath137 , with the majority of the variation arising from the extrapolation - uncertainty for @xmath132 at low nuclear - recoil energies .",
    "the lower edges of the uncertainty bounds on figure [ fig : onesigmacurve ] correspond to the upper edges of the one - sigma regions on figures [ fig : leff ] and [ fig : leff_newknots ] , hence a flat extrapolation of @xmath1 at low - energies tends to result in a stronger xenon100 exclusion limit .",
    "has a sharp cut - off below 10 kev .",
    "the red plain curve is the mean fit ; the blue dotted curve represents the 1-sigma contour corresponding to the bottom curve in fig .",
    "[ fig : leff_newknots ] and the green dashed line represents the exclusion curve associated with a @xmath1 function with a sharp cut - off below 10 kev . ]    the upper curve in fig.[fig : onesigmacurve_withcutoff ] represents the most conservative exclusion limit that one can derive from the present @xmath1 data .",
    "this illustrates that the conclusion from the xenon100 collaboration is fairly robust above @xmath420 gev and uncertainties at large mass are really small , as claimed by @xcite .    in comparison to similar works such as @xcite , which analysed the first set of xenon100 data without using the profile likelihood method , our conclusions are similar , but not identical , in the low - mass region of parameter space , for the case where their cut - off of events at @xmath138 was relaxed .",
    "however , in the current analysis it is possible that the use of the profile likelihood method has changed the size of the systematic @xmath132 errors for low - masses due to increased sensitivity , in addition to the different choices of spline interpolation for @xmath132 itself , compared with @xcite .",
    "it should be noted that there are a variety of uncertainties affecting the exclusion curves from the analysis , primarily the uncertainty in fitting the @xmath31 distribution to the pdfs of @xmath91 , but also the flexibility in the actual method of dataset simulation , and the overlap of background and signal regions on the s1-s2 plane ( as discussed in section [ sec : dataset_sim ] ) .      the relative size of the variation of the xenon100 exclusion curve with @xmath132 at low masses compared to that at high masses ,",
    "can be understood in terms of the wimp recoil spectrum , an example of which is shown in figure [ fig : drde_m=5 ] , and equations to .     and cross - section of @xmath139 . from zero",
    "to @xmath140 the differential reaction rate @xmath141 changes by many orders of magnitude . ]",
    "the equation for @xmath72 has two terms in the integrand : the wimp recoil spectrum @xmath141 and a poisson distribution .",
    "the poisson term is peaked at a particular value of energy , which increases for larger numbers of photoelectrons @xmath64 .",
    "hence for a certain value of @xmath64 , there will be a region along the energy axis , of @xmath141 , which contributes most to the integral . by changing the functional form of @xmath132 , the value of the nuclear recoil energy at which the poisson distribution peaks will change ( by approximately @xmath142 for the different parameterisations considered here ) . hence for a particular value of @xmath64",
    ", the integral of equation will now receive dominant contributions from different areas of @xmath141 along the energy axis , when @xmath132 is altered .    to explain the different variation in the final exclusion curve due to @xmath132 seen at large and small wimp masses",
    ", one must compare recoil spectra . for low masses , the recoil spectrum changes rapidly at low energies ( see e.g. figure [ fig : drde_m=5 ] ) , before falling off at a few @xmath71 .",
    "however , at larger masses , the spectrum is largely constant until much higher energies before falling off ; in the case of @xmath143 the cut - off is at approximately @xmath144 .",
    "clearly , the greatest change of @xmath72 with @xmath132 will be seen for values of @xmath64 where the poisson term of equation is peaked at recoil energies where @xmath141 varies most rapidly .",
    "since the peak of the poisson in energy is at larger values for higher @xmath64 , the largest variation in @xmath72 will be seen for higher masses at high @xmath64 , while for lower masses it will be seen predominantly at low values of @xmath64 .",
    "finally , equation contains a sum of @xmath72 over all @xmath64 . for low wimp masses ,",
    "the lower values of @xmath64 , where the greatest variation due to @xmath145 occurs , dominate over the terms with larger @xmath64 .",
    "conversely for larger masses , all values of @xmath64 contribute terms of the same order to , hence there will be no dramatic change in the final result , due to the relative scintillation efficiency .    additionally , in the case of the forms of @xmath132 from figures [ fig :",
    "leff ] and [ fig : leff_newknots ] , the systematic uncertainty of the exclusion curve for low wimp masses is further amplified , relative to the higher masses , due to the larger uncertainties of @xmath132 at low energies .",
    "in this paper we have assessed the uncertainties on the xenon100 exclusion curve @xcite due to the lack of knowledge about the low energy behaviour of the scintillation efficiency of liquid xenon detector .",
    "our analysis is motivated by the existence of low mass dark matter scenarios ( below 10 gev ) which lie close to the published xenon100 limit ( see for example @xcite ) .",
    "the use of a profile likelihood analysis ( in which uncertainties on @xmath132 were profiled out ) enabled the xenon100 collaboration to obtain an exclusion limit which is free from large uncertainties @xcite .",
    "in particular , the limit on low mass wimps seems very precise while one would expect to recover at least the 1-sigma uncertainty band which accounts for the lack of determination of @xmath1 below 3 kevnr .    in order to understand this behaviour ,",
    "we have performed a similar profile likelihood analysis but did not consider @xmath1 as a nuisance parameter .",
    "instead @xmath1 is defined directly from the fits to the data .",
    "we show that the exclusion limit obtained by the xenon100 collaboration at high energy is very robust .",
    "the uncertainties on the exclusion limit due to @xmath1 are very small and all our exclusion curves are very similar to the xenon100 exclusion limit .",
    "such a conclusion was not necessarily obvious since different types of interpolation of @xmath1 data give different behaviours for @xmath1 , even at high energy .",
    "however this can be understood from our robustness of the fit analysis which shows that all spline fits at high energy are equally good . hence heavy dark matter scenarios close to the xenon100 limits will not be affected by a better determination of @xmath1 at high recoil energies .",
    "this implies that dark matter scenarios just above the xenon100 limit are probably excluded indeed ( provided that other sources of uncertainties which are not accounted for in this analysis are not too large ) and , those just below , very close to be ruled out .    at low recoil energies below 3 kevnr , even though a different behaviour has been suggested from theoretical arguments @xcite .",
    "] , our results ( cf fig.[fig : onesigmacurve ] ) show that the mean value of @xmath1 ( which is in agreement with the mean @xmath1 curve considered by the xenon100 collaboration ) gives an exclusion limit that is similar to ( although stronger than ) the xenon100 limit but a more extreme behaviour of @xmath1 at low energy ( cf the flat extrapolation or a sharp cut - off below 3 kevnr for example ) leads to a very different exclusion limit .",
    "should new data favour such a type of behaviour for @xmath1 at very low energy with unprecedented precision , the exclusion limit would be different from that presented by the xenon100 collaboration , even though such a behaviour was included in the 1- and 2-sigma contours considered for @xmath1 by the xenon100 collaboration .",
    "perhaps a reason for this discrepancy is the gaussian likelihood term which was assumed for @xmath1 in the xenon100 analysis ( and which was centred on the mean value of @xmath1 ) together with flat priors .",
    "combined with the other likelihood terms which describe the uncertainties from the analysis itself , it may be that the xenon100 maximum likelihood analysis over - fits @xmath1 and thereby suppresses alternative possibilities for this crucial quantity , leading to over confidence in excluding light dm scenarios .    in any case",
    ", since various @xmath1 fits give different exclusion limits , it seems more conservative to `` track '' the effect of different @xmath1 energy behaviour at low energy on the exclusion curve and define ( frequentists ) confidence intervals by marginalising over the different fits to @xmath1 data . with this method , one is in principle ensured not to bias the analysis towards the present best fit curve of @xmath1 since it may in fact not be the correct function to consider given the lack of data in this energy region .",
    "finally , we note that a flat behaviour of @xmath1 ( as suggested by @xcite ) at low recoil energy would actually set a stronger exclusion limit .",
    "hence the need for new measurements of @xmath1 at low energy .",
    "our analysis was based on a likelihood chosen so as to keep the current analysis as close as possible to the one done by the xenon100 collaboration @xcite , however it should be possible to improve the method in identifying wimp signals over background .",
    "if the s1-s2 plane were to be divided into a grid of bins , then , on top of the knowledge of the actual structure of the set of data - points in this space from calibration data , one could use additional knowledge of the recoil spectra for background and signal . such a spectrum",
    "is already known along the s1-axis for wimps ( equation ) , and is distinct to that from electronic recoils , which is constant for low energies @xcite .",
    "this would provide an additional method of discrimination , which would be especially important if a future run of the xenon100 experiment were to claim a discovery signal , but is difficult without more knowledge of the experimental set - up .",
    "additionally , it should be possible , in principle , to test the efficiency of a particular likelihood function in reconstructing theoretical parameters such as the cross - section from given simulated datasets , since the parameters used to generate them are known ( see @xcite for a similar discussion ) .",
    "we would like to thank michael schmidt and hendrik hoeth for their precious help .",
    "jhd is supported by a stfc studentship .",
    "g.  angloher , m.  bauer , i.  bavykina , a.  bento , c.  bucci , c.  ciemniak , g.  deuter and f.  von feilitzsch _",
    "et al . _ , arxiv:1109.0702 [ astro-ph.co ] .",
    "e.  behnke , j.  behnke , s.  j.  brice , d.  broemmelsiek , j.  i.  collar , p.  s.  cooper , m.  crisler and c.  e.  dahl _ et al .",
    "_ , phys .",
    "lett .   * 106 * , 021303 ( 2011 ) [ arxiv:1008.3518 [ astro-ph.co ] ] .",
    "m.  t.  frandsen , f.  kahlhoefer , j.  march - russell , c.  mccabe , m.  mccullough and k.  schmidt - hoberg , phys .",
    "d * 84 * ( 2011 ) 041301 [ arxiv:1105.3734 [ hep - ph ] ] . c.  mccabe , phys .",
    "d * 84 * ( 2011 ) 043525 [ arxiv:1107.0741 [ hep - ph ] ] ."
  ],
  "abstract_text": [
    "<S> in 2011 , the xenon100 experiment has set unprecedented constraints on dark matter - nucleon interactions , excluding dark matter candidates with masses down to 6 gev if the corresponding cross section is larger than @xmath0 . </S>",
    "<S> the dependence of the exclusion limit in terms of the scintillation efficiency ( @xmath1 ) has been debated at length . to overcome possible criticisms xenon100 performed an analysis in which @xmath1 was considered as a nuisance parameter and its uncertainties </S>",
    "<S> were profiled out by using a gaussian likelihood in which the mean value corresponds to the best fit @xmath1 value ( smoothly extrapolated to zero below 3 kevnr ) . </S>",
    "<S> although such a method seems fairly robust , it does not account for more extreme types of extrapolation nor does it enable to anticipate on how much the exclusion limit would vary if new data were to support a flat behaviour for @xmath1 below 3 kevnr , for example . </S>",
    "<S> yet , such a question is crucial for light dark matter models which are close to the published xenon100 limit . to answer this issue </S>",
    "<S> , we use a maximum likelihood ratio analysis , as done by the xenon100 collaboration , but do not consider @xmath1 as a nuisance parameter . </S>",
    "<S> instead , @xmath1 is obtained directly from the fits to the data . </S>",
    "<S> this enables us to define frequentist confidence intervals by marginalising over @xmath1 . </S>"
  ]
}