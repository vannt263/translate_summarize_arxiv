{
  "article_text": [
    "codes have been proven to achieve the symmetric capacity on binary - input discrete memoryless channels under a low - complexity successive cancellation ( sc ) decoding algorithm @xcite .",
    "although the polar codes asymptotically achieve the channel capacity , the performance under sc decoding is unsatisfying when the code length is of the order of kilobits .",
    "several alternative decoding schemes have been proposed to improve the finite - length performance of polar codes , such as successive cancellation list ( scl ) @xcite , successive cancellation stack ( scs)@xcite and belief propagation ( bp ) @xcite decoding algorithms .",
    "it is reported that polar codes under the crc - aided scl / scs ( ca - scl / scs ) decoding algorithms can achieve a better frame error rate ( fer ) performance than the ldpc and turbo codes when the code lengths are configured to several kilobits @xcite@xcite@xcite .",
    "therefore , polar coding is believed to be a competitive candidate in future communication systems .",
    "since the ca - scs decoding requires a large stack to store the candidate paths which leads to a high space complexity , ca - scl decoding algorithm is of more interest @xcite@xcite@xcite .",
    "nevertheless , to achieve competitive performance against ldpc or turbo codes , a moderate - sized list is required in ca - scl decoding . in that case , the computational complexity of the ca - scl decoder is still high .    as stated in @xcite , scl decoding can be regarded as a path searching procedure on the code tree . in order to reduce the complexity of scl decoding , tree - pruning technique is exploited by avoiding unnecessary path searching operations @xcite . in order to keep the fer loss in an acceptable region",
    ", @xcite computes the pruning threshold in a very conservative way .",
    "only the candidate paths with metrics much less than the maximum one are pruned .",
    "it works well when the signal - to - noise ratio ( snr ) is high , where the metric of the correct path is usually much larger than the others .",
    "however , this existing pruning technique is no longer efficient when working in the relative low snr region where the fer under decoding is about @xmath1 , while it is exactly the operating regime for cellular networks .    in this paper",
    ", we propose to compute the threshold using the sum of the survival path metrics . to evaluate",
    "how much a pruned candidate path would affect fer performance , we propose a metric upper bound of its descendants .",
    "utilizing this upper bounding technique , a dynamic threshold is further proposed .",
    "the proposed scheme deletes the redundant candidate paths as many as possible while keeping the performance deterioration in a tolerant region , thus it is much more efficient than the existing pruning scheme .",
    "the remainder of the paper is organized as follows .",
    "reviews the basics of polar coding . describes the proposed tree - pruning scheme for scl decoding .",
    "a path metric upper bound of the descendants of some given candidate path and a dynamic threshold configuration method are proposed .",
    "provides the performance and complexity analysis based on the simulation results .",
    "finally , concludes the work .",
    "in this paper , we use calligraphic characters , such as @xmath2 and @xmath3 , to denote sets , and @xmath4 to denote the number of elements in @xmath2 .",
    "we write the cartesian product of @xmath2 and @xmath3 as @xmath5 , and write the @xmath6-th cartesian power of @xmath2 as @xmath7 .",
    "further , we write @xmath8 to denote the subset of @xmath3 with elements in @xmath2 excluded .",
    "we use notation @xmath9 to denote a @xmath10-dimension vector @xmath11 and @xmath12 to denote a subvector @xmath13 of @xmath9 , @xmath14 .",
    "particularly when @xmath15 , @xmath12 is a vector with no elements in it and the empty vector is denoted by @xmath16 .",
    "we write @xmath17 to denote the subvector of @xmath9 with odd indices ( @xmath18 ; @xmath19 is odd ) .",
    "similarly , we write @xmath20 to denote the subvector of @xmath9 with even indices ( @xmath18 ; @xmath19 is even ) . for example , for @xmath21 , @xmath22 , @xmath23 and @xmath24 .",
    "further , given a index set @xmath25 , @xmath26 denote the subvector of @xmath9 which consists of @xmath27s with @xmath28 .",
    "we are given a binary - input memoryless channel @xmath29 with input alphabet @xmath30 and output alphabet @xmath3 , the channel transition probabilities are @xmath31 , @xmath32 , @xmath33 .    for code length @xmath34 , @xmath35 , and information length @xmath36 , i.e. code rate @xmath37 , polar coding over @xmath38 proposed by arikan can be described as follows :    after channel combining and splitting operations on @xmath10 independent uses of @xmath38 , we get @xmath10 successive uses of synthesized binary input channels @xmath39 , @xmath40 , with transition probabilities @xmath41 where @xmath42 and the source block @xmath43 are supposed to be uniformly distributed in @xmath44",
    ".    the reliabilities of the polarized channels @xmath45 can be evaluated by using density evolution @xcite , and is usually more evaluated efficiently by calculating bhattacharyya parameters @xcite for binary erasure channels ( becs ) or by using gaussian approximation @xcite for binary - input awgn ( biawgn ) channels .    to transmit a message block of @xmath36 bits , the @xmath36 most reliable polarized channels @xmath45 with indices",
    "@xmath28 are picked out for carrying these information bits ; a fixed bit sequence called frozen bits are transmitted over the others .",
    "the index set @xmath46 is called the information set and @xmath47 , and its complement set which is denoted by @xmath48 is called the frozen set .",
    "as mentioned in @xcite , polar codes can be decoded using successive cancellation ( sc ) decoding algorithm . in @xcite , it is further described as a path searching procedure on a decoding tree .",
    "the metric of a decoding path @xmath49 can be measured using _ a posteriori _",
    "probability @xmath50 when @xmath51 is not a wrong frozen bit , the above path metric can be recursively computed as @xmath52 @xmath53 where @xmath54 , @xmath55 , @xmath56 .",
    "thus , sc decoding can be described as a greedy search algorithm on the code tree . in each level ,",
    "only the one of two descendants with larger path metric is selected for further expansion .",
    "@xmath57    where @xmath58      the performance of sc is limited by the bit - by - bit decoding strategy .",
    "whenever a bit is wrongly determined , there is no chance to correct it in the rest of the decoding procedure .",
    "theoretically , the performance of the maximum _ a posteriori _ probability ( map ) decoding ( or equivalently ml decoding , since the inputs are assumed to be uniformly distributed ) can be achieved by traversing all the @xmath10-length decoding paths in the code tree . but this brute - force search takes exponential complexity and is impossible to be implemented for practical code lengths .",
    "two improved decoding algorithms , scl decoding and scs decoding , are proposed in @xcite and @xcite .",
    "both of these two algorithms allow more than one edge to be explored in each level of the code tree . during the scl(scs ) decoding , a set of candidate paths are obtained and stored in a list(stack ) . combining the ideas of scl and scs ,",
    "a decoding algorithm named successive cancellation hybrid ( sch ) is proposed in @xcite , which can achieve a better trade - off between computational complexity and space complexity . moreover , with the help of crc codes , polar codes decoded by these improved sc decoding algorithms are found to be capable of achieving the same or even better performance than turbo codes or ldpc codes @xcite @xcite @xcite .    among these existing improved sc decoding algorithms , benefitting from the limited requirement for the memory ,",
    "decoding is the most interesting for hardware implementation @xcite @xcite @xcite @xcite . as shown in fig .",
    "[ fig_scl ] , the processing loop of the standard scl / ca - scl decoding is as follows :    1 .   for each candidate path , calculate the path metrics of its descendant paths ; 2 .",
    "sort the metrics , and reserve at most @xmath59 paths with the larger metrics and delete the others ; 3 .",
    "if any two of the survival paths share the same parent node , then a copy operation is performed to create separate working spaces for these two paths ; 4 .   for each survival path , update the recursively ; 5 .",
    "the above loop is processed until the length of candidate paths reach @xmath10 .",
    "the candidate path with the largest path metric ( when crc embedded , the candidates which can not pass crc are dropped directly ) is picked out for the final decision .",
    "in order to reduce the computational complexity of scl decoding , a pruning operation is added after the sorting operation ( as shown in fig.[fig_scl ] ) .",
    "if the metric of some candidate path is less than a threshold , it will be directly deleted to avoid redundant path expansions and copy operations .    in this paper , we propose to use the path metric sum of the ( maximum ) @xmath59 survival candidate paths after sorting : while decoding the @xmath60-th bit , the metrics of the survival paths is @xmath61 , where @xmath62 is index set of the survival paths in the list after sorting operation , @xmath63 ; if the following inequality holds for some @xmath62 , the corresponding path is then deleted , @xmath64 where @xmath65 .",
    "particularly , if @xmath66 , then no pruning is performed when decoding this @xmath60-th bit . in the following part of this section , we ll discuss how to choose the value of @xmath67 .",
    "suppose that the correct path is still in the list after the sorting operation during decoding the @xmath60-th bit .",
    "the probability of that the @xmath68-th candidate is the correct path ( i.e. , the performance loss of deleting this path ) is computed as @xmath69      given a specific polar code , the channel property , and a tolerant fer performance loss @xmath70 , the most direct way to configure @xmath71 is through mote carlo simulation .    initially , set @xmath72 and simulate using standard ( ca-)scl decoding . during decoding the @xmath60-th bit in each frame ,",
    "the ratio of the metric of the correct path ( until the @xmath60-th bit ) @xmath73 and the sum metric of the survival paths in the list is recorded ; if the final decoding result is correct and the ratio is less than @xmath71 , then update @xmath71 with this ratio , i.e. , @xmath74 when the amount of simulated frame is large enough , the pruning operation based on ( [ eqn_prune ] ) , the fer performance loss can be very small .",
    "the monte carlo configuration is dependant on the specific snr , code length , and code rate .",
    "thus , it s quite difficult to use for practical application . for polar codes , the reliability of the polarized channels can be evaluated using gaussian approximation @xcite or some other techniques ; in other words , the probability density functions ( pdfs ) of the llrs which corresponding to the receiving bits ( conditioned on that the previous bits are correctly decoded ) can be a priori information to the decoder . in this subsection , we present a method to estimate the performance loss brought by pruning using these llr distributions ; and then , a dynamic threshold configuration method is proposed . using the proposed thresholding method ,",
    "the pruned ( ca-)scl decoding can fully utilize the tolerant performance deterioration and thus lower the computational complexity .",
    "the llr pdfs can be obtained by using density evolution or gaussian approximation @xcite .",
    "based on the pdf corresponding to a bit @xmath75 , we can define a llr region , such that the probability of the corresponding llr takes values in @xmath76 $ ] is larger than a pre - defined small probability @xmath77 , @xmath78 therefore , when decoding the @xmath60-th bit , if one candidate path has metric @xmath79 , the metric of any its descendant path @xmath80 at the @xmath68-th level has an upper bound , @xmath81 where @xmath82 .",
    "note that for bit index @xmath83 $ ] , every bit effects the value of @xmath84 to some extent , no matter it s an information bit or a frozen bit .",
    "specifically , for an information bit with relatively high reliability , i.e. , with a large @xmath85 , its impact on @xmath84 is considered negligible ; for a frozen bit , since the value of @xmath85 is relatively smaller , its impact on @xmath84 is more significant .",
    "[ fig_metricupperbound ] gives the simulation result of a @xmath86 polar code under biawgnc with snr @xmath87db .",
    "the decoding algorithm is with @xmath88 .",
    "the maximum and average values of the path metric during decoding each bit are recoded . to guarantee the inequality ( [ eqn_metricmax ] )",
    "holds with probability larger than @xmath89 , we set @xmath90 . as shown in the figure , the simulation data is well bounded by ( [ eqn_metricmax ] ) .      in this subsection ,",
    "we propose a new threshold computation method which can fully utilize the tolerant fer performance loss @xmath70 .",
    "as previously stated , pruning operation during decoding @xmath75 will cause some fer performance loss ; when expansion at level-@xmath91 on the code tree , the loss brought by the pruned path at level-@xmath60 is accumulated ,",
    "i.e. , the paths which cause performance loss during decoding @xmath92 include not only the newly pruned paths but also the descendants of the pruned paths at level-@xmath60 .",
    "thus , when decoding at level-@xmath60 on the code tree , the fer performance loss is computed based on both the newly pruned paths at level-@xmath60 and the descendants of all the previously pruned paths which would be in the list . a graphic illustration is given in fig . [ fig_ploss ] .",
    "to estimate the fer loss brought by the pruning operations , the pruned path should be recorded .",
    "let @xmath93 be the _ active _ pruned path during decoding the first @xmath60 bits , i.e. , @xmath49 .",
    "for each pruned path @xmath94 , the level index @xmath95 when it is pruned , along with the corresponding path metric @xmath96 and the estimated performance loss @xmath97 which is computed using ( [ eqn_pde ] ) , is recorded .",
    "obviously , @xmath98 . based on @xmath99 ,",
    "the maximum metric value at the @xmath60-th level of the descendants of the pruned path @xmath19 can be computed using @xmath100 in ( [ eqn_metricmax ] ) , @xmath101    the performance loss @xmath102 which is brought by the pruning operations during decoding the first @xmath60 bits is evaluated as follows :    1 .",
    "find the survival paths in the list @xmath103 which are with metrics larger than the maximum @xmath104 , @xmath105 the number of these found paths is @xmath106 ; 2 .",
    "find @xmath107 pruned records with indices @xmath108 which has the larger estimated performance losses , i.e. , for any @xmath109 and @xmath110 , we have @xmath111 , where @xmath112 .",
    "3 .   the performance loss @xmath102 is upper bounded by @xmath113    the threshold @xmath71 is determined by the tolerant performance loss @xmath70 and the loss introduced in the previous decoding process @xmath114 , @xmath115 where index set @xmath116 indicates the candidates to be pruned and is the largest subset of @xmath103 which satisfies @xmath117    after the pruning , the set of pruned records @xmath118 is updated as follows :    1 .   combing @xmath119 and the newly pruned paths which are induced by @xmath116",
    ", the obtained temporary index set is denoted by @xmath120 ; 2 .   find the @xmath59 pruned records with largest losses in @xmath120 , the result indices form the set @xmath121 , i.e. , @xmath122 , for any @xmath123 and @xmath124 , we have @xmath111 .",
    "the minimum value of the metric upper bounds of the pruned records in @xmath121 is @xmath125 4 .",
    "@xmath118 is obtained by inactivating all the records in @xmath120 with estimated metric less than @xmath126 @xmath127    note that , initially , @xmath128 .",
    "the complexity of ( ca-)scl decoding consists of three parts : the path extension ( includes the updating of path metrics ( [ equ_app_recursive1 ] ) ( [ equ_app_recursive2 ] ) and the partial - sums ) , path metric sorting , path copy , and updating .",
    "applying pruning , many redundant path extensions along with path copies are avoided .",
    "since the computational complexity to obtain a length-@xmath10 path is @xmath129 @xcite , and in the best case only one path is preserved in the list , thus the computational complexity is reduced by @xmath130 . however , calculating the threshold itself introduces additional compactions . for each information bit , the metrics of the survival paths and the pruned paths are added up to compute the threshold , thus the complexity increases with @xmath131 .",
    "thus , the computational complexity can be reduced by order of @xmath130 if the @xmath70 is set to a proper value .",
    "moreover , when one of the two descendants of a single parent path is pruned , there is no longer need for the path copy operation . in fact , it is the usual case especially when the corresponding polarized channel is with high reliability . therefore , the number of required path copies is also reduced .    as to the path metric sorting",
    ", the least reliable paths are required to be picked out when computing the threshold , so the pruning does not reduce the sorting complexity .",
    "in this section , we analyze the performance of the proposed pruned ( ca - scl ) decoding algorithm via simulation .",
    "the simulated polar code has code length @xmath132 and the code rate @xmath133 , which is constructed under @xmath134 using gaussian approximation @xcite .",
    "the information block is assumed to have @xmath135 embedded crc bits , and ca - scl decoding is applied .",
    "[ fig_bler ] shows the fer performances under different @xmath59 values and pruning techniques .",
    "[ fig_complexity ] and fig .",
    "[ fig_pathcopy ] show the corresponding average computational complexity and average number of path copies , respectively .",
    "the average computational complexity is evaluated in terms of the number of metric recursive operations , which are defined in ( [ equ_app_recursive1 ] ) and ( [ equ_app_recursive2 ] ) . here ,",
    "we pay more attention to the snr region where the fer is around @xmath1 , which is the interesting particularly , the thresholds of ` sum statistical ' is obtained by monte carlo simulation . as shown in the figures , when @xmath70 takes a relative conservative value ( compared with the fer ) , that is @xmath136 , all the pruning technique do not introduce noticeable loss in fer ; while the proposed scheme has much lower complexity than the existing scheme in @xcite . when decoding with with @xmath88 and @xmath137 , the performance is deteriorated and very close to standard with @xmath138 , while the average complexity is even lower than the standard one with @xmath139 .",
    "further , when @xmath140 , the fer performance loss is less than @xmath141db , but the complexity is reduced by @xmath142 .",
    "[ fig_debler ] compares the fer and fer loss of the proposed pruning scheme and @xcite under different target losses @xmath70 .",
    "the @xmath143 is fixed to @xmath87db .",
    "as shown in the figure , when @xmath144 , the actual fer loss is very close to the target @xmath145 ; while the actual loss of @xcite is far less than the target .",
    "that means , compared with @xcite , the proposed pruning scheme utilizes the tolerant fer loss much more efficiently , thus it is with lower complexity .",
    "in this paper , a tree - pruning technique to reduce the complexity of ( ca-)scl is proposed . during the decoding process",
    ", the candidate paths with metric less than a threshold are directly deleted to avoid redundant path extensions .",
    "based on the reliabilities of the information / frozen bits , an upper bound of the path metric is derived to estimate the deterioration brought by the pruning operation . utilizing this bound",
    ", a dynamic thresholding technique is presented .",
    "compared with a similar existing scheme @xcite , the new proposed scheme can make full use of the given tolerant performance deterioration , and is much more efficient .",
    "a. balatsoukas - stimming , m. bastani parizi , a. burg , `` llr - based successive cencellation list decoding of polar codes '' , _ ieee international conference on acoustics , speech and signal processing ( icassp ) _ , florence , italy , may 2014 ."
  ],
  "abstract_text": [
    "<S> polar codes under cyclic redundancy check aided successive cancellation list ( ca - scl ) decoding can outperform the turbo codes and the ldpc codes when code lengths are configured to be several kilobits . in order to reduce the decoding complexity , a novel tree - pruning scheme for the decoding algorithms </S>",
    "<S> is proposed in this paper . in each step of the decoding procedure , </S>",
    "<S> the candidate paths with metrics less than a threshold are dropped directly to avoid the unnecessary computations for the path searching on the descendant branches of them . </S>",
    "<S> given a candidate path , an upper bound of the path metric of its descendants is proposed to determined whether the pruning of this candidate path would affect frame error rate ( fer ) performance . by utilizing this upper bounding technique and introducing a dynamic threshold , the proposed scheme deletes the redundant candidate paths as many as possible while keeping the performance deterioration in a tolerant region , thus it is much more efficient than the existing pruning scheme . with only a negligible loss of fer performance , </S>",
    "<S> the computational complexity of the proposed pruned decoding scheme is only about @xmath0 of the standard algorithm in the low signal - to - noise ratio ( snr ) region ( where the fer under ca - scl decoding is about @xmath1 ) , and it can be very close to that of the successive cancellation ( sc ) decoder in the moderate and high snr regions .    </S>",
    "<S> polar codes , successive cancellation decoding , tree - pruning . </S>"
  ]
}