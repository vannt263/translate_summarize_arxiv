{
  "article_text": [
    "the past several years have made clear the need to better understand the behaviour in large interconnected financial systems .",
    "almost all areas of modern life are touched by a financial crisis .",
    "the recent financial crisis of @xmath0 brought into focus the networked structure of the financial world .",
    "it challenged the mathematical finance community to understand connectedness in financial systems .",
    "the understanding of systemic risk , i.e. , the risk that a large numbers of components of an interconnected financial system fails within a short time leading to the failure of the system itself , becomes an important issue to investigate .    interconnections often make a system robust , but they can also act as conduits for risk . even things that may seemingly be unrelated , may become related as risk restrictions , may for example , force a sale of one type of a well - performing asset to compensate for the poor behavior of another asset .",
    "thus , appropriate mathematical models need to be developed , in order to help in the understanding of how risk can propagate between financial objects .",
    "it is possible that initial shocks could trigger contagion effects ( e.g. , @xcite ) . examples of such shocks include : changes in interest rate values , in currencies values , changes of commodities prices , or reduction in global economic growth .",
    "then , there may be a transmission mechanism which causes other institutions in the system to be affected by the initial shock .",
    "an example of such a mechanism is financial linkages among economies .",
    "another reason could simply be investor irrationality . in either case",
    ", systemic risk causes the perceived risk - return trade - off in the economy to change .",
    "uncertainty becomes an issue and market participants fear subsequent losses in asset prices with a large dispersion in regards to the magnitude of the crisis .",
    "reduce - form point process models of correlated default are many times used ( a ) : to assess portfolio credit risk and ( b ) : to value securities exposed to correlated default risk .",
    "the workhorses of these models are counting processes . in this work",
    "we focus on using dynamic portfolio credit risk models to study large portfolio asymptotics and default clustering .",
    "large portfolio asymptotic were first studied in @xcite .",
    "the model in @xcite is a static model of a homogeneous pool and firms default independently of one another conditional on a normally distributed random variable representing a systematic risk factor .",
    "alternative distributions of the systematic factor were examined in @xcite , @xcite and the case of heterogeneous portfolios was studied in @xcite . in @xcite ,",
    "the authors extend the model of @xcite dynamically and the systematic risk factor follows a brownian motion . in @xcite , the authors study a structural model for distance to default process in a pool of names .",
    "a firm defaults when the default process hits zero . exploiting conditional independence of defaults ,",
    "@xcite and @xcite have studied the tail of the loss distribution in the static case .",
    "large deviations arguments were also used in @xcite to study stochastic recovery effects on large static pools of credit assets .",
    "reduced - form models of correlated default timing have appeared in the finance literature under different forms .",
    "@xcite take the intensity of a name as a function of the state of the names in a specified neighborhood of that name .",
    "the authors in @xcite and @xcite take the intensity to be a function of the portfolio loss and each name can be either in a good or in a distressed financial state . these papers prove law of large numbers for the portfolio loss distribution and develop gaussian approximations to the portfolio loss distribution based on central limit theorems .",
    "@xcite consider the typical behavior of a mean field system with permanent default impact .",
    "@xcite study large portfolio asymptotics for utility indifference valuation of securities exposed to the losses in the pool . in @xcite ,",
    "the authors study systematic risk via a mean field model of interacting agents . using a model of a two well potential",
    ", agents can move freely from a healthy state to a failed state .",
    "the authors study probabilities of transition from the healthy to the failed state using large deviations ideas . in @xcite",
    "the authors propose and study a model for inter - bank lending and study its stochastic stability .",
    "the authors in @xcite employ jump - diffusion models driven by hawkes processes to empirically study default clustering and the time dimension of systemic risk .",
    "@xcite proposes a hierarchical model with individual shocks and group specific shocks .",
    "the work of @xcite reviews intensity models that are governed by exogenous and endogenous markov chains .",
    "in @xcite , the authors proposed a dynamic point process model of correlated default timing in a portfolio of firms ( `` names '' ) .",
    "the model incorporates different sources of default clustering identified in recent empirical research , including idiosyncratic risks , exposure to systematic risk factors and contagion in financial markets , see @xcite , @xcite .",
    "based on the weak convergence ideas of @xcite , the authors in @xcite obtain and study formulas for the bilateral counterparty valuation adjustment of a credit default swaps portfolio referencing an asymptotically large number of entities .    the model in @xcite",
    "can be naturally understood as an interacting particle system that is influenced by an exogenous source of randomness .",
    "there is a central source of interconnections and failure of any of the components stresses the central bus , which in turn can cause the failure of other components ( a contagion effect ) .",
    "computing the distribution of the loss from default in such models tends to be a difficult task and while monte - carlo simulation methods are broadly applicable , they can be slow for large portfolios or large time horizons as it is commonly the interest in practice .",
    "mathematical and computational tools for the approximation to the distribution of the loss from default in large heterogeneous portfolios were then developed in @xcite , gaussian correction theory was developed in @xcite and analysis of tail events and most likely paths to failure via the lens of large deviations theory was then developed in @xcite .",
    "we remark here that to a large extend systemic risk refers to the tail of the distribution .",
    "the authors in @xcite combine the large pool asymptotic results of @xcite-@xcite with maximum likelihood ideas to construct tractable statistical inference procedures for parameter estimation in large financial systems .",
    "such mathematical results lead to new computational tools for the measurement and prediction of risk in high - dimensional financial networks .",
    "these tools mainly include approximations of the distribution of losses from defaults and of portfolio risk measures , and efficient computational tools for the analysis of extreme default events .",
    "the mathematical results also yield important insights into the behavior of systemic risk as a function of the characteristics of the names in the system , and in particular their interaction .",
    "financial institutions ( banks , pension funds , etc ) often hold large portfolios in order to diversify away a number of idiosyncratic effects of individual assets .",
    "deposit insurance premia depend upon meaningful models and assessment of the macroeconomic effect of the various phenomena that drive defaults .",
    "development of related mathematical and computational tools can help inform the design of regulatory policy , improve the pricing of federal deposit insurance , and lead to more accurate risk measurement at financial institutions .    in this paper",
    ", we focus on dynamic default timing models for large financial systems that fall into the category of intensity models in portfolio credit risk . based on the default timing model developed in @xcite",
    ", we address several of the issues just mentioned and that are typically of interest .",
    "the mathematical and computational tools developed allow to reach to financial related conclusions for the behavior of such large financial systems .    although the primary interest of this work is risk in financial systems , models of the type discussed in this paper are generic enough to allow for modifications that make them relevant in other domains , including systems reliability , insurance and epidemiology . in reliability ,",
    "a large system of interacting components might have a central connection , and be influenced by an external environment ( temperature , for example ) .",
    "the failure of an individual component ( which could be governed by an intensity model appropriate for the particular application ) increases the stress on the central connection and thus the other components , making the entire system more likely to fail . in insurance",
    ", the system could represent a pool of insurance policies .",
    "the effect of wildfires might , in that example , be modelled by a contagion term .",
    "systematic risk in the form of environmental conditions has an impact on the whole pool .",
    "the rest of the article is structured as follows . in section [",
    "s : model ] we describe the correlated default timing proposed in @xcite .",
    "section [ s : lln ] studies the typical behavior of the loss distribution in such portfolios as the number of names ( agents ) in the pool grow to infinity .",
    "section [ s : clt ] focuses on developing the gaussian correction theory . as we shall see there ,",
    "gaussian corrections are very useful because they make the approximations accurate even for portfolios of relatively small sizes . in section [",
    "s : ldp ] , we study the tail of the loss distribution using arguments from the large deviations theory .",
    "we also study the most likely path to systemic failure and to the development of default clusters .",
    "an understanding of the preferred paths to large default rates and the most likely path to the creation of default clusters can give useful insights into how to optimally safeguard against such events .",
    "importance sampling techniques can then be used to construct asymptotically efficient estimators for tail event probabilities , see section [ s : is ] .",
    "conclusions are in section [ s : conclusions ] . a large part of the material presented in this work , but not all , is related to recent work of the author described in @xcite , @xcite , @xcite and @xcite .",
    "one of the issues of fundamental importance in financial markets is systemic risk , which may be understood as the likelihood of failure of a substantial fraction of firms in the economy .",
    "there are a number of ways of interpreting this , but our focus will be the behavior of actual _",
    "defaults_. defaults are discrete events , so one can frame the interest within the language of point processes .",
    "empirically , defaults tend to happen in groups ; feedback and exposure to market forces ( along the lines of `` regimes '' ) tend to produce correlation among defaults .",
    "let us fix a probability space @xmath1 where all random variables will be defined",
    ". denote by @xmath2 the stopping time at which the @xmath3-th component ( or particle ) in our system fails .",
    "then , as @xmath4 , a failure time @xmath2 has intensity process @xmath5 , which satisfies @xmath6|{\\mathscr{f}}_t,\\ , \\tau^{n}>t\\ } \\approx \\lambda^{n}_t \\delta,\\ ] ] where @xmath7 is the sigma - algebra generated by the entire system up to time @xmath8 .",
    "hence , we essentially have that the process defined by @xmath9 is a martingale",
    ".    motivated by the empirical studies in @xcite and @xcite , we may model the intensity @xmath5 in such a way that it depends on three factors : a mean reverting idiosyncratic source of risk , the portfolio loss rate and a systematic risk factor .",
    "heterogeneity can be addressed by allowing the intensity parameters of each name to be different .",
    "the mean reverting character of the idiosyncratic source of risk is there to guarantee that the effect of a default in the pool has a transient effect on the default intensities of the surviving names .",
    "the dependence on the portfolio loss rate , denoted by @xmath10 is the term that is responsible for the contagious effects , whereas the systematic risk factor , denoted by @xmath11 is an exogenous source of risk . to be precise , the default intensities , @xmath5 s ,",
    "are governed by the following interacting system of stochastic differential equations ( sdes )    @xmath12    where , @xmath13 be a countable collection of independent standard brownian motions .",
    "the process @xmath14 represents the empirical failure rate in the system , i.e. , @xmath15 where by letting @xmath16 to be an i.i.d .",
    "collection of standard exponential random variables we have @xmath17    the process @xmath18 represents the systematic risk , which can be modeled to be the solution to some sde @xmath19 where @xmath20 is a standard brownian motion which is independent of the @xmath21 s and @xmath22 s .",
    "plausible models for @xmath18 could be an ornstein - uhlenbeck process or a cox - ingersoll - ross ( cir ) process .    in the case",
    "@xmath23 for all @xmath24 , one recovers the classical cir process model in credit risk , e.g. , @xcite .",
    "namely , the intensity sde extends the widely - used cir process by including two additional terms that generate correlation between failure times .",
    "the term @xmath25 induces correlated diffusive movements of the component intensities ; the process @xmath26 represents the state of the macro - economy , which affects all assets in the pool .",
    "the term @xmath27 introduces a feedback ( contagion ) effect .",
    "the standard term @xmath28 is a mean reverting term allowing the component to `` heal '' after a shock ( i.e. , a failure ) .",
    "this parsimonious formulation allows us to take advantage of the wealth of knowledge about cir - type processes .",
    "the parameter @xmath29 allows us to later on focus on rare events .",
    "the process @xmath30 of , which simply gives us the fraction of components which have already failed by time @xmath8 , affects each of the remaining components in a natural way .",
    "each failure corresponds to a dirac function in the measure @xmath31 ; the term @xmath27 thus leads to upward impulses in @xmath32 s , which leads ( via ) to sooner failure of the remaining functioning components .",
    "we might think of a central `` bus '' in a system of components .",
    "each of the components depends on this bus , which in turn sensitive to failures in the various components . in the financial application that was considered in @xcite ,",
    "this feedback mechanism is empirically observed to be an important channel for the clustering of defaults in the u.s .",
    "( see @xcite ) .    in order to allow for heterogeneity , the parameters in depend on the index @xmath3 . define the `` type '' @xmath33 for each @xmath34 and @xmath35 .",
    "the @xmath36 s take value in @xmath37 .",
    "the parameters @xmath38 are assumed to be bounded uniformly in @xmath39 .",
    "we can capture the heterogeneity of the system by defining @xmath40 and assuming that this empirical type frequency has a ( weak ) limit .",
    "in particular we make the following assumption    [ a : regularity ] we assume that @xmath41 exists in @xmath42 .",
    "proposition 3.3 in @xcite guarantees that under the assumption of an existence of a unique strong solution for the sde for @xmath11 process , the system  has a unique strong solution such that @xmath43 for every @xmath44 , @xmath24 and @xmath35 .",
    "the model  is a mean - field type model ; the feedback occurs through the empirical average of the pool of names .",
    "it is somewhat similar to certain genetic models ( most notably the fleming - viot process ; see @xcite , ( * ? ? ?",
    "* chapter 10 ) , and @xcite ) .",
    "however , as it is also demonstrated in @xcite and in @xcite , the structure of the system  presents several difficulties that bring the analysis of such systems outside the scope of the standard setup .",
    "the system  can naturally be understood as an interacting particle system .",
    "this suggests how to understand its large - scale behavior .",
    "the structure of the feedback ( the empirical average @xmath45 ) is of mean - field type ( roughly within the class of mckean - vlasov models ; see @xcite , @xcite ) .",
    "an understanding of `` typical '' behavior of a system as @xmath46 is fundamental in identifying `` atypical '' or `` rare '' events .    to formulate the law of large numbers result ,",
    "we define the empirical distribution of the @xmath47 s corresponding to the names that have survived up to time @xmath8 , as follows : @xmath48 this captures the entire dynamics of the model ( including the effect of the heterogeneities ) .",
    "we can directly calculate the failure rate from the @xmath49 s : @xmath50 let us then identify the limit of @xmath51 as @xmath46 .",
    "this is a law of large numbers ( lln ) result and it identifies the baseline `` typical '' behavior of the system . for @xmath52 ,",
    "let @xmath53 for @xmath54 .",
    "the generator @xmath55 corresponds to the diffusive part of the intensity with killing rate @xmath56 , and @xmath57 is the macroscopic effect of contagion on the surviving intensities at any given time .",
    "the operators @xmath58 and @xmath59 capture the dynamics due to the exogenous systematic risk @xmath26",
    ". then @xmath49 tends in distribution ( in the natural topology of subprobability measures on @xmath60 ) to a measure - valued process @xmath61 .",
    "letting @xmath62 for all @xmath52 , the limit @xmath61 satisfies the stochastic evolution equation @xmath63 with sufficient regularity , this is equivalent to the stochastic integro - partial differential equation ( sipde ) @xmath64 where @xmath65 denotes adjoint in the appropriate sense ( for notational simplicity , we have written to include the types as one of the coordinates ; in a heterogeneous collection in practice we would often use only @xmath56 in solving ) .",
    "we recall the rigorous statement in theorem [ t : mainlln0 ] .",
    "the sipde gives us a `` large system approximation '' of the failure rate : @xmath66 the computation of the first - order approximation suggested by the lln requires solving the sipde governing the density of the limiting measure . in @xcite a numerical method for this purpose",
    "is proposed .",
    "the method is based on an infinite system of sde s for certain moments of the limiting measure .",
    "these sdes are driven by the systematic risk process @xmath26 and a truncated system can be solved using a discretization or random ode scheme .",
    "the solution to the sde system leads to the solution to the sipde via an inverse moment problem .     on the left : comparison of distributions of failure rate @xmath67 for different @xmath68 at @xmath69 .",
    "parameter choices : @xmath70 . on the right : comparison of distribution of limiting failure rate @xmath71 for different values of the systematic risk sensitivity @xmath72 at @xmath73 parameter choices : @xmath74 .",
    ", title=\"fig : \" ] on the left : comparison of distributions of failure rate @xmath67 for different @xmath68 at @xmath69 .",
    "parameter choices : @xmath70 . on the right : comparison of distribution of limiting failure rate @xmath71 for different values of the systematic risk sensitivity @xmath72 at @xmath73 parameter choices : @xmath74 .",
    ", title=\"fig : \" ]    the approximation has significant computational advantages over a naive monte carlo simulation of the high - dimensional original stochastic system  and its accuracy is demonstrated in the left of figure [ fig : betacone ] for a specific choice of parameters .",
    "it also provides information about catastrophic failure .",
    "the tail represents extreme default scenarios , and these are at the center of risk measurement and management applications in practice .",
    "the analysis of the limiting distribution generates important insights into the behavior of the tails as a function of the characteristics of the system . for example , we see that the tail is heavily influenced by the sensitivity of a name to the variations of the systematic risk @xmath26 .",
    "the bigger the sensitivity the fatter the tail , and the larger the likelihood of large losses in the system ( see the right of figure [ fig : betacone ] ) .",
    "insights of this type can help understand the role of contagion and systematic risk , and how they interact to produce atypically large failure rates .",
    "this , in turn , leads to ways to minimize or `` manage '' catastrophic failures .",
    "let us next present the statement of the mathematical result .",
    "we denote by @xmath75 the collection of sub - probability measures ( i.e. , defective probability measures ) on @xmath60 ; i.e. , @xmath75 consists of those borel measures @xmath76 on @xmath60 such that @xmath77 .",
    "[ t : mainlln0 ] we have that @xmath78 converges in distribution to @xmath79 in @xmath80 $ ] .",
    "the evolution of @xmath79 is given by the measure evolution equation @xmath81 suppose there is a solution of the nonlinear spde @xmath82 where @xmath83 denote adjoint operators , with initial condition @xmath84 then @xmath85    we close this section , by briefly describing the method of moments that leads to the numerical computation of the loss from default .",
    "we focus our discussion on the homogeneous case and we refer the reader to @xcite for the general case .",
    "firstly , we remark that the spde ( [ eq : nonlinearspde ] ) can be supplied with appropriate boundary conditions , which as it is mentioned in @xcite , are @xmath86    secondly , it turns out that for @xmath87 , the moments @xmath88 exist almost surely . by ( [ e : firstorder ] ) is is clear that we want to compute @xmath89 .",
    "in particular , note that the limiting loss @xmath90 .    by an integration by parts and using the boundary conditions at @xmath91 and at @xmath92 , we can prove that they follow the following system of stochastic differential equations @xmath93 where @xmath94 .",
    "the system is a non - closed system since to determine @xmath95 , one needs to know @xmath96 .",
    "so , in practice one must perform a truncation at some level @xmath97 where we let @xmath98 ( that is , we use the first @xmath99 moments ) . as it is shown in @xcite one",
    "needs relatively small numbers of moments in order to compute the zero - th moment @xmath89 with good accuracy .",
    "then , by solving backwards , one computes @xmath100 and from this one gets the limiting loss distribution @xmath101",
    "the asymptotics of give via the limiting behavior of the system as the number of components becomes large . starting with that result ,",
    "the results in @xcite develop gaussian fluctuation theory analogous to the central limit theory ( see for example @xcite , @xcite , @xcite , @xcite for some related literature ) .",
    "this result provides the leading order asymptotics correction to the law of large numbers approximation developed in section [ s : lln ] . in practical terms , the usefulness of such of a result is twofold : ( a ) the approximation is accurate even for portfolios of moderate size , see @xcite , and ( b ) : one can make use of the approximation to develop tractable statistical inference procedures for the statistical calibration of such models , see @xcite .    to be more precise ,",
    "let us define the signed measure @xmath102 as @xmath46 .",
    "conditional on the exogenous systematic risk process @xmath26 , a central limit theorem applies and @xmath103 exists in an appropriate space of distributions and is gaussian .",
    "unconditionally , it may not be gaussian but is of mean zero ( since we have removed the bias @xmath61 from @xmath49 ) .",
    "the usefulness of the fluctuation analysis is that it leads to a second - order approximation to the distribution of the portfolio loss @xmath104 in large pools .",
    "the fluctuations analysis yields an approximation which improves the first - order approximation suggested by the lln , especially for smaller system sizes @xmath68 .",
    "in particular , theorem [ t : mainclt ] implies that @xmath105 for large @xmath68 .",
    "this motivates the approximation @xmath106 which then implies the following second - order approximation for the portfolio loss . @xmath107",
    "the numerical computation of the second - order approximation suggested by the fluctuation analysis is amenable to a moment method similar to that used for computing the first - order approximation ( [ e : firstorder ] ) .",
    "in addition to solving the lln sipde , we would also need to solve for the fluctuation limit .",
    "this limit is governed by a stochastic evolution equation , which gives rise to an additional system of `` fluctuation moments . ''",
    "this system is driven by the exogenous systematic risk process @xmath26 and the martingale @xmath108 in theorem [ t : mainclt ] that is conditionally gaussian given @xmath26 .",
    "left of figure [ fig : clt ] compares the approximate loss distribution with the actual loss distribution for specific parameter choices .",
    "it is evident from the numerical comparisons that the second - order approximation has increased accuracy , especially for smaller portfolios and in the tail of the distribution .",
    "the right of figure [ fig : clt ] compares for the @xmath109 and @xmath110 percent value at risk ( var ) between the actual loss , lln approximation ( [ e : firstorder ] ) , and approximation ( [ approxmain ] ) for a pool of @xmath111 names .",
    "it is also evident from the figure that the approximation for the var based on ( [ approxmain ] ) is much more accurate than the law of large numbers approximation .     on the left : comparison of approximate and actual loss distributions of failure rate @xmath67 for different @xmath68 at @xmath112 .",
    "parameter choices : @xmath113 . on the right : comparison of approximate and actual var .",
    "parameter choices : @xmath113 . in both cases",
    ", @xmath26 is an ou process with reversion speed 2 , volatility 1 , initial value 1 and mean 1 .",
    ", title=\"fig : \" ] on the left : comparison of approximate and actual loss distributions of failure rate @xmath67 for different @xmath68 at @xmath112 .",
    "parameter choices : @xmath113 . on the right : comparison of approximate and actual var .",
    "parameter choices : @xmath113 . in both cases",
    ", @xmath26 is an ou process with reversion speed 2 , volatility 1 , initial value 1 and mean 1 .",
    ", title=\"fig : \" ]    let us close this section , with a few words on the actual mathematical result .",
    "it turns out that the convergence @xmath103 happens in an appropriate weighted hilbert space , which we denote by @xmath114 , with @xmath115 and @xmath116 the appropriate weight functions , @xmath117 and @xmath118 will be its dual .",
    "such weighted sobolev spaces were introduced in @xcite and further generalized in @xcite to study stochastic partial differential equations with unbounded coefficients .",
    "these weighted spaces turn out to be convenient for the present situation , see @xcite .",
    "in order to state the convergence result , we introduce some operators .",
    "let @xmath119 and for @xmath120 , define @xmath121    then , we have the following theorem related to the fluctuations analysis .    [",
    "t : mainclt][theorem 4.1 in @xcite ] for @xmath122 large enough and for appropriate weight functions @xmath123 , the sequence @xmath124\\}_{n\\in { \\mathbb{n}}}$ ] is relatively compact in @xmath125 $ ] . for any @xmath126 , the limit accumulation point of @xmath127 , denoted by @xmath128 , is unique in @xmath129 and satisfies the stochastic evolution equation @xmath130 for any @xmath126 , where @xmath131 is a distribution - valued martingale with predictable variation process @xmath132_t=\\int_{0}^{t}\\left[{\\left \\langle}{\\mathcal{l}}_5 ( f , f),\\bar \\mu_s{\\right\\rangle}+ { \\left \\langle}{\\mathcal{l}}_6 ( f , f),\\bar \\mu_s{\\right\\rangle}+{\\left \\langle}{\\mathcal{l}}_2 f,\\bar \\mu_s{\\right\\rangle}^{2}{\\left \\langle}{\\mathcal{q}},\\bar \\mu_s{\\right\\rangle}-2{\\left \\langle}{\\mathcal{l}}_7 f,\\bar \\mu_s{\\right\\rangle}{\\left \\langle}{\\mathcal{l}}_2 f,\\bar \\mu_s{\\right\\rangle}\\right]ds.\\ ] ] conditional on the @xmath133-algebra @xmath134 that is generated by the @xmath135brownian motion , @xmath136 is centered gaussian with covariance function , for @xmath137 , given by @xmath138&={\\mathbb{e}}\\bigg[\\int_{0}^{t_1 \\wedge t_2}\\left[{\\left \\langle}{\\mathcal{l}}_5 ( f , g),\\bar \\mu_s{\\right\\rangle}+",
    "{ \\left \\langle}{\\mathcal{l}}_6 ( f , g),\\bar \\mu_s{\\right\\rangle}+{\\left \\langle}{\\mathcal{l}}_2 f,\\bar \\mu_s{\\right\\rangle}{\\left \\langle}{\\mathcal{l}}_2 g,\\bar \\mu_s{\\right\\rangle}{\\left \\langle}{\\mathcal{q}},\\bar \\mu_s{\\right\\rangle}\\right.\\nonumber\\\\ & \\hspace{1cm}\\left.-{\\left \\langle}{\\mathcal{l}}_7 g,\\bar \\mu_s{\\right\\rangle}{\\left \\langle}{\\mathcal{l}}_2 f,\\bar \\mu_s{\\right\\rangle}-{\\left \\langle}{\\mathcal{l}}_7 f,\\bar \\mu_s{\\right\\rangle}{\\left \\langle}{\\mathcal{l}}_2 g,\\bar \\mu_s{\\right\\rangle}\\right]ds\\ , \\big|\\,\\mathcal{v}_{t_1 \\vee t_2}\\bigg].\\label{eq : conditionalcovariation}\\end{aligned}\\ ] ]    it is clear that if @xmath139 for all @xmath140 , then the limiting distribution - valued martingale @xmath131 is centered gaussian with covariance operator given by the ( now deterministic ) term within the expectation in ( [ eq : conditionalcovariation ] ) .    the main idea for the derivation of ( [ eq : clt ] ) comes from the proof of the convergence to the solution of .",
    "define @xmath141 for @xmath54 .",
    "let s also assume for the moment that @xmath142 for every @xmath39 , i.e , let s neglect exposure to the exogenous risk @xmath26 and focus on contagion",
    ". then we can write the evolution of @xmath143 as @xmath144 where @xmath145 is a martingale which may change from line to line .",
    "this leads to , when @xmath142 for every @xmath39 , see @xcite .    to get the gaussian correction",
    ", we see that @xmath146 where @xmath145 is a martingale . for large @xmath68 , @xmath145 should be gaussian , in which case @xmath147 is indeed a gaussian process . putting the systematic risk process",
    "@xmath26 back into  , one recovers the result of theorem [ t : mainclt ] .",
    "once we have identified what is typical , we can study the structure of atypically large failure rates .",
    "large deviations outlines a circle of ideas and calculations for understanding the origination and transformation of rare events ( see @xcite , @xcite ) .",
    "large deviation arguments allow us to identify the `` dominant '' way that rare events will occur in complex systems .",
    "this is the feature that is being exploited in @xcite , i.e. , how different sources of stochasticity can lead to system collapse .    by the discussion in section [ s : lln ] , we have that the pool has a default rate @xmath148 at time @xmath149 .",
    "let s fix @xmath150 .",
    "then @xmath151 ; it is a _ rare event _ that the default rate in the pool exceeds @xmath152 .",
    "we want to understand as much as possible about @xmath153 .    using , the theory of large deviations",
    ", we can understand both how rare this event is , and what the `` most likely '' way is for this rare event to occur .",
    "events far from equilibrium crucially depend on how rare events propagate through the system .",
    "large deviations gives rigorous ways to understand these effects , and we want to use this machinery to understand the structure of atypically large default clusters in the portfolio .",
    "a reference for large deviations is @xcite .",
    "if we have that @xmath154 , \\text { as } n\\rightarrow\\infty\\ ] ] for some appropriate functional @xmath155 , then by the contraction principle we should have that @xmath156 , \\text { as } n\\rightarrow\\infty\\ ] ] where @xmath157 ( in other words , @xmath158 is the large deviations rate function for @xmath159 ) .",
    "this gives us the rate at which the tail of the default rate @xmath159 decays as the diversification parameter grows .",
    "more importantly , though , the variational problem gives us the _ preferred _ way which atypically large default rates occur .",
    "namely , if there is a @xmath160\\to [ 0,1]$ ] such that @xmath161 then for any @xmath162 , the gibbs conditioning principle suggests that @xmath163    insights into large deviations of  have been developed in @xcite when @xmath164 and when @xmath165 as @xmath166 .",
    "we note here that in the case @xmath165 , the large deviations principle is conditional on the systematic risk @xmath26 .",
    "such results allow us to study the comparative effect of the systematic risk process @xmath26 and of the contagion feedback on the tails of the loss distribution .    before presenting the result ,",
    "let us first investigate numerically a test case , which is indicative of the kind of results that large deviations theory can give us . apart from approximating the tail of the distribution , large deviations can give quantitative insights into the most likely path to failure of a system .    for presentation purposes and for the rest of this section",
    ", we assume that @xmath167 as @xmath168 .",
    "consider a heterogeneous test portfolio composed initially of @xmath169 names .",
    "let us assume that we can separate the names in the portfolio into three types : type a is @xmath170 of the names , type b is @xmath171 of the names and type c is @xmath172 of the names .",
    "for presentation purposes , we assume that all parameters but the contagion parameter are the same among the different types .",
    "in particular , we have the following choice of parameters .    .[parameters ] parameter values for a test portfolio composed of three types of assets .",
    "we take @xmath173 . [",
    "cols=\"<,^,^,^,^,^,^,^\",options=\"header \" , ]     it is instructive to compare the different cases , based on whether there are contagion effects in the default intensities or not . in particular , we compare two different cases , ( a ) systematic risk only : @xmath174 , and ( b ) systematic risk and contagion : @xmath175 . in each case , the time horizon is @xmath176 .    using the methods of section [ s : lln ] , one can compute that the typical loss in such a pool at time @xmath176 . if contagion effects are not present , i.e. , if @xmath177 , then the typical loss in such a portfolio at time @xmath176 is @xmath178 .",
    "if on the other hand , contagion ( feedback ) effects are present and the @xmath179 parameters take the values of table [ parameters ] , then the typical loss in such a portfolio at time @xmath176 has been increased to @xmath180 . in figure",
    "[ fig : ldp_ratefunction ] , we plot the large deviations rate functions for each of the two different cases . as we saw in the beginning of this section",
    ", the rate function governs the asymptotics of the tail of the loss distribution .",
    "notice that in every case , the rate function is convex and it becomes zero at the corresponding law of large numbers .",
    "moreover , since the contagion parameter of type a is higher than the contagion parameter for type b or c , one expects that names of type a will be more prompt to the contagious impact of defaults .",
    "indeed , after computing the rate function and the associated extremals , as defined by large deviations theory , one gets the most likely paths to failure as seen in figures [ fig : ldp1]-[fig : ldp2 ] .",
    "the @xmath181 trajectories correspond to the contagion extremals for each of the three types , whereas the @xmath182 corresponds to the systematic risk extremal .",
    "one can make two conclusions out of figures [ fig : ldp1]-[fig : ldp2 ] .",
    "the first conclusion is related to the @xmath183 extremals ( figure [ fig : ldp1 ] ) .",
    "we notice that at any given time @xmath8 , the extremal for type a is bigger than the extremal for type b , which in turn is bigger than the extremal of type c. this implies that unlikely large losses for components of type a are more likely than unlikely large losses for components of type b , which are more likely than large losses for components of type c. thus , components of type a affect the pool more than components of type b , which in turn affect the pool more than components of type c even though type a composes @xmath170 of the pool , whereas type b , composes @xmath171 of the pool and type c composes @xmath172 of the pool .",
    "the second conclusion is related to the @xmath184 extremals ( figure [ fig : ldp2 ] ) .",
    "we notice that the effect of the systematic risk is most profound in the beginning but then its significance decreases .",
    "namely , if a large cluster were to occur , the systematic risk factor is likely to play an important role in the beginning , but then the contagion effects become more important .",
    "assets of type a are likely to contribute to the default clustering effect more , followed by assets of type b and the ones that will contribute the least to the default cluster are assets of type c.    as it is also seen in the numerical experiments done in @xcite , the large deviations analysis help quantify the effect that the contagion and the systematic risk factor have on the behavior of the extremals ( the most likely path to failure ) . an understanding of the role of the preferred paths to large default rates and the most likely ways in which contagion and systematic risk combine to lead to large default rates would give useful insights into how to optimally hedge against such events .",
    "let us next proceed by motivating the development of the large deviations principle for the default timing model  that is considered in this paper .",
    "we denote scenarios , i.e. , defaults , that are not in @xmath185 $ ] by an abstract point @xmath186 not in @xmath185 $ ] and define the polish space @xmath187\\cup \\{\\star\\}\\ ] ]    to motivate things , let s first assume for simplicity that @xmath188 and that the system is homogeneous , i.e. , that @xmath189 for all @xmath3 .",
    "define @xmath190 with @xmath191 .",
    "this feller diffusion will represent the conditional intensity of a `` randomly - selected '' component of our ( homogeneous and independent ) system .",
    "define the measure @xmath192 by setting @xmath193 = 1- { \\mathbb{e}}\\left[\\exp\\left[-\\int_{0}^t   { \\lambda}_s ds\\right]\\right]\\ ] ] for all @xmath194 ; @xmath195 is the common law of the default times @xmath196 s .    in the independent case , i.e. , when @xmath197 , standard sanov s theorem @xcite , implies that @xmath198 has a large deviations principle with rate function @xmath199 if @xmath200 and @xmath201",
    "if @xmath202 ( i.e. , @xmath203 is the relative entropy of @xmath76 with respect to @xmath195 ) . by the contraction principle",
    ", the rate function for @xmath204 is @xmath205=\\varphi(t)$ for all $ t\\in[0,t]$ and $ \\nu[0,t]=\\ell$}\\rb\\label{eq : independentcaseldp}\\ ] ]    in the independent case , we can actually compute both the extremal @xmath183 that achieves the infimum and the corresponding rate function @xmath206 in closed form .",
    "assume that @xmath207\\in ( 0,1)$ ] and @xmath208 .",
    "fix @xmath209 such that @xmath210=\\ell$ ] .",
    "define @xmath211)}{\\mu_{0}[0,t ] } \\qquad \\text{and}\\qquad \\nu_{-}(a ) = \\frac{\\nu(a\\cap [ 0,t])}{\\ell}\\ ] ] for all @xmath212 $ ] .",
    "then @xmath213 and @xmath214 are in @xmath215 $ ] .",
    "we can write that @xmath216}\\rb + \\ln \\frac{\\nu\\{{\\star}\\}}{\\mu_{0}\\{{\\star}\\}}\\nu\\{{\\star}\\}\\ ] ] where @xmath217 is entropy on @xmath215 $ ] .",
    "we can minimize the @xmath217 term by setting @xmath218 , and we get that @xmath219 } + ( 1-\\ell)\\ln \\frac{1-\\ell}{\\mu_{0}\\{{\\star}\\}}\\\\ & = & \\ell \\ln \\frac{\\ell}{\\mu_{0}[0,t ] } + ( 1-\\ell)\\ln \\frac{1-\\ell}{1-\\mu_{0}[0,t]}.\\nonumber   \\end{aligned}\\ ] ] this is in fact obvious ; @xmath220 , and in this case the @xmath221 s are i.i.d .",
    "bernoulli random variables with common bias @xmath222 $ ] .",
    "the rate function @xmath223 of is the entropy of bernoulli coin flips . of more interest ,",
    "however , is the optimal path . in setting @xmath224 in",
    ", we essentially identify the optimal path @xmath225}{\\mu_{0}[0,t]},\\ ] ] where the last relation holds since we also require @xmath226 .",
    "it turns out that one can extend this result to give a generalized sanov s theorem for the case @xmath227 , where @xmath228 feeds back into the dynamics of the @xmath229 s .",
    "the case @xmath230 can be treated using a conditioning argument and the well developed theory of large deviations for small noise diffusions . for the heterogeneous case",
    ", one needs an additional variational step which minimizes over all the possible ways that losses are distributed among systems of different types . even though an explicit closed form expression for the extremals and for the corresponding rate function is no longer possible",
    ", one can still rely on numerically computing them .",
    "let us make this discussion precise .    to fix the discussion ,",
    "let us assume ( see @xcite for the general case ) that the exogenous risk @xmath26 is of ornstein - uhlenbeck type , i.e. , @xmath231    let @xmath232 be a reference brownian motion . fix a name in the pool @xmath233 and time horizon @xmath234 .",
    "the freidlin - wentzell theory of large deviations for sde s gives us a natural starting point . in the freidlin - wentzell analysis ,",
    "a dominant ode is subjected to a small diffusive perturbation ; informally , the freidlin - wentzell theory tells us that if we want to find the probability that the randomly - perturbed path is close to a reference trajectory , we should use that reference trajectory in the dynamics .",
    "this leads to the correct ldp rate function for the original sde .",
    "if we want to find the asymptotics of the probability that @xmath235 for some absolutely continuous functions @xmath183 and @xmath184 , i.e. , @xmath236,\\mathbb{r}\\right)$ ] , we should consider the stochastic hazard functions @xmath237\\\\ \\lambda_0 & = \\lambda_\\circ . \\end{aligned}\\ ] ] this will represent the conditional intensity of a `` randomly - selected '' name in our pool . define next @xmath238\\right],\\ ] ] where , we have used the superscript @xmath239 to denote the dependence on the particular type .",
    "then for every @xmath240 $ ] we have that @xmath241\\right ] = { \\mathbb{p}}{\\left\\ { } \\newcommand{\\rb}{\\right\\}}\\int_{s=0}^t \\lambda^{\\varphi,\\psi}_s ds>{\\mathfrak{e}}\\rb\\ ] ] where @xmath242 is an exponential(1 ) random variable which is independent of @xmath232 .",
    "in other words , @xmath243 is the density ( up to time @xmath149 ) of a default time whose conditional intensity is @xmath244 .",
    "in fact , due to the affine structure of the model , we have an explicit expression for @xmath243 ( see lemma 4.1 in @xcite ) .    for given trajectories",
    "@xmath183 and @xmath184 in @xmath245;{\\mathbb{r}})$ ] , define @xmath246 as @xmath247}f_{\\varphi,\\psi}^{{{\\mathsf{p}}}}(t)dt + \\delta_{{\\star}}(a){\\left\\ { } \\newcommand{\\rb}{\\right\\}}1- \\int_{0}^t f_{\\varphi,\\psi}^{{{\\mathsf{p}}}}(t)dt\\rb\\ ] ] for all @xmath248 .    at a heuristic level",
    "one can derive the large deviations principle as follows .",
    "let us assume that we can establish that @xmath249\\ ] ] and that @xmath250 also has large deviations principle in @xmath251;\\mathbb{r})$ ] with action functional @xmath252 ; i.e. , @xmath253\\ ] ] as @xmath254 .",
    "then , we should have that @xmath255.\\ ] ] in fact , the previous heuristics can be carried out rigorously and in the end one derives the following rigorous large deviations result .",
    "[ t : ldpheterogeneous2 ] consider the system defined in - with @xmath256 such that @xmath257 and let @xmath258 . under the appropriate assumptions the family @xmath259 satisfies the large deviation principle , with rate function @xmath260\\right),\\psi\\in c\\left([0,t]\\right ) , \\psi(0)= \\varphi({{\\mathsf{p}}},0)=0,\\right.\\nonumber\\\\ & \\qquad\\qquad\\left.\\bar{\\varphi}(s)=\\int_{{{\\mathcal{p}}}}\\varphi({{\\mathsf{p}}},s)u(d{{\\mathsf{p } } } ) , \\bar{\\varphi}(t)=\\ell \\right\\}\\end{aligned}\\ ] ] where if @xmath261\\right),\\psi\\in ac\\left([0,t]\\right ) , \\psi(0)=\\varphi({{\\mathsf{p}}},0)=0 $ ] , then @xmath262 and @xmath263 otherwise .",
    "here , @xmath264 is the rate function for the process @xmath265 .",
    "namely , for @xmath266;{\\mathbb{r}}\\right)$ ] with @xmath267 we have @xmath268 and @xmath269 otherwise .",
    "@xmath270 has compact level sets .",
    "if the heterogeneous portfolio is composed by @xmath271 different types of assets with homogeneity within each type , then theorem [ t : ldpheterogeneous2 ] simplifies to the following expression .    for @xmath272)$",
    "] let us define the functional @xmath273 due to the affine structure of the model , we have an explicit expression for @xmath243 ( see lemma 4.1 in @xcite ) .",
    "assume that @xmath274 of the names are of type @xmath275 with @xmath276 and @xmath277 .",
    "setting @xmath278 , we get the following simplified expression for the rate function @xmath279\\right.\\nonumber\\\\ & \\qquad\\qquad\\qquad\\left .",
    "\\varphi(t)=\\ell , \\varphi_{a_{i}}(0)=\\psi(0)=0 , \\varphi_{a_{i}},\\psi\\in ac([0,t ] ) \\textrm { for every } i=1,\\cdots , k\\right\\}.\\nonumber\\end{aligned}\\ ] ]    an optimization algorithm can then be employed to solve the minimization problem associated with @xmath270 and compute the extremals @xmath280 for @xmath281 and @xmath184 .",
    "this is the formula that the numerical example presented in figures [ fig : ldp1]-[fig : ldp2 ] was based on . in the numerical example that was considered there we had three types , i.e. , @xmath282 .",
    "the large deviations results have a number of important applications .",
    "firstly , they lead to an analytical approximation of the tail of the distribution of the failure rate @xmath104 for large systems .",
    "these approximations complement the first- and second- order approximations suggested by the law of large numbers and fluctuations analysis of sections [ s : lln ] and [ s : clt ] respectively and facilitates the estimation of the likelihood of systemic collapse .",
    "secondly , the large deviations results provide an understanding of the  preferred \" ways of collapse , which can also be used to design  stress tests \" for the system .",
    "in particular , this understanding can guide the selection of meaningful stress scenarios to be analyzed .",
    "thirdly , they can motivate the design of asymptotically efficient importance sampling schemes for the tail of the portfolio loss .",
    "we discuss some of the related issues in section [ s : is ] .",
    "suppose we want to computationally simulate @xmath283 , where @xmath151 again holds .",
    "accurate estimates of such rare - event probabilities are important in many applications areas of our system  , including credit risk management , insurance , communications and reliability .",
    "monte carlo methods are widely used to obtain such estimates in large complex systems such as ours ; see , for example , @xcite .",
    "standard monte carlo sampling techniques perform very poorly in estimating rare events ( for which , by definition , most samples can be discarded ) .",
    "importance sampling , which involves a change of measure , can be used to address this issue . in general",
    ", large deviations theory provides an optimal way to ` tilt ' measures .",
    "the variational problems identified by large deviations usually lead to measure transformations under which pre - specified rare events become much more likely , but which give unbiased estimates of probabilities of interest ; see for example @xcite .",
    "let @xmath284 be any unbiased estimator of @xmath283 that is defined on some probability space with probability measure @xmath285 .",
    "in other words , @xmath284 is a random variable such that @xmath286 , where @xmath287 is the expectation operator associated with @xmath288 . in our setting , it takes the form @xmath289 where @xmath290 is the associated radon - nikodym derivative .",
    "importance sampling involves the generation of independent copies of @xmath284 under @xmath285 ; the estimate is the sample mean .",
    "the specific number of samples required depends on the desired accuracy , which is measured by the variance of the sample mean . however , since the samples are independent it suffices to consider the variance of a single sample .",
    "because of unbiasedness , minimizing the variance is equivalent to minimizing the second moment .",
    "an application of jensen s inequality , shows that if @xmath291 then @xmath284 achieves this best decay rate , and is said to be _ asymptotically optimal_. one wants to choose @xmath285 such that asymptotic optimality is attained .    to motivates things let us assume for the moment that @xmath292 and that the system is homogeneous , i.e. , that @xmath189 for all @xmath3 . in the independent and homogeneous case ,",
    "@xmath293 are i.i.d .",
    "random variables such that for every @xmath240 $ ] @xmath294\\right]=\\int_{0}^t f_{0,0}(s)ds\\ ] ]    for notational convenience , we shall define @xmath295    it is easy to see that , @xmath296    to minimize the variance , we need to increase the probability of defaults .",
    "define    @xmath297\\label{eq : logmmt2prelimit}\\ ] ]    a simple computation shows that @xmath298    define @xmath299    clearly @xmath300 .",
    "notice that the density of a @xmath301 with respect to a @xmath302 is @xmath303\\nonumber\\\\ & = & e^{n\\left(-\\theta l^{n}_{t}+\\bar{\\lambda}(\\theta;t)\\right)}\\end{aligned}\\ ] ]    therefore , for @xmath304 fixed , the suggestion is to simulate under a new change of measure , under which @xmath305 and to return the estimator @xmath306    it is clear that this estimator is unbiased .",
    "we want to choose @xmath304 that minimizes the variance , or equivalently the second moment . for this purpose",
    ", we define the second moment @xmath307\\ ] ]    notice that @xmath308    due to convexity of @xmath309 , we have that the maximizer over @xmath310 of the lower bound is at @xmath311 such that @xmath312 . in particular , ( recall that @xmath313 ) we have @xmath314    this construction means that under the new measure , we have @xmath315 in fact , we have the following theorem .",
    "let @xmath316 such that @xmath312",
    ". then asymptotic optimality holds , in the sense that @xmath317 where @xmath223 is defined in .    by jensen s inequality",
    "we clearly have the upper bound .",
    "namely , for every @xmath310    @xmath318    now , we need to prove that the lower bound is achieved for @xmath319 , i.e. , that    @xmath320    recalling that @xmath321 and @xmath322 , we easily see that @xmath323 this concludes the proof of the theorem .    in the heterogeneous case ,",
    "i.e. if @xmath47 can be different for each @xmath39 , then @xmath324 is no longer binomial , but it is a sum of independent ( but not identically distributed ) bernoulli random variables with success probability @xmath325 indexed by @xmath3 . due to independence ,",
    "similar methods as the one described above can be used to construct asymptotically efficient importance sampling schemes in the heterogeneous case .",
    "the scheme just presented essentially amounts to a twist in the intensity of the defaults .",
    "however , in contrast to the independent case , i.e. , when @xmath326 , the situation in the general dependent case @xmath327 is more complicated .",
    "notice also if at least one one of the @xmath328 s is not zero , then the model  does not fall into the category of the doubly - stochastic models , so techniques as the ones used in @xcite do not apply .",
    "also , implementation of interacting particle schemes for markov chain models as the ones developed in @xcite do not readily apply for such intensity models .",
    "the re - sampling schemes of @xcite could apply in this setting , but one would need to construct an appropriate mimicking markov chain , something which is not clear how to do in the current setting .",
    "we briefly present here an importance sampling scheme for the case that there exists at least one @xmath329 and also applies independently of whether the systematic effects are present in the model or not .",
    "the suggested measure change essentially mimics the principal idea behind the measure change for the independent case . to be more precise ,",
    "one directly twists the intensity of @xmath324 .",
    "let @xmath330 be the arrival times of @xmath331 and notice that @xmath332 .",
    "let @xmath333 and @xmath334 be some progressively measurable twisting process . then , define the measure @xmath285 via the radon - nicodym derivative @xmath335    it is known that if @xmath336<\\infty$ ] , then @xmath285 defined by @xmath337 is a probability measure and it can be shown that @xmath338 admits @xmath339intensity @xmath340 on the interval @xmath341 .",
    "this construction gives us some freedom into choosing appropriately the twisting process @xmath342 .",
    "different choices of the twisting process @xmath342 are of course possible . for tractability purposes we restrict attention to a one - parameter family and set @xmath343    for any @xmath344 and under the measure induced by @xmath345 ,",
    "i.e. under @xmath346 , the process @xmath338 has intensity @xmath347 on @xmath341 , i.e. it amounts to an additive shift of the intensity .",
    "thus , @xmath348 is a superimposed default rate and its role is to increase the default rate in the whole portfolio .",
    "the purpose then is to optimize the limit as @xmath349 of the upper bound of the second moment of the resulting estimator over @xmath348 .",
    "this is the measure change that is investigated in @xcite , and it is shown there that there is a choice of @xmath350 for which asymptotic optimality can be established . namely , there is a choice of @xmath350 that minimizes the second moment of the estimator in the limit as @xmath349 .",
    "we refer the interested reader to @xcite for implementation details on this change of measure for related intensity models and for corresponding simulation results .",
    "we presented an empirically motivated model of correlated default timing for large portfolios .",
    "large portfolio analysis allows to approximate the distribution of the loss from default , whereas gaussian corrections make the approximation valid even for portfolios of moderate size .",
    "the results can be used to compute the loss distribution and to approximate portfolio risk measures such as value - at - risk or expected shortfall .",
    "then , large deviations analysis can help understand the tail of the loss distribution and find the most - likely paths to systemic failure and to the creation of default clusters .",
    "such results give useful insights into the behavior of systemic risk as a function of the characteristics of the names in the portfolio and can be also potentially used to determine how to optimally safeguard against rare large losses .",
    "importance sampling techniques can be used to construct asymptotically efficient estimators for tail event probabilities .",
    "the author was partially supported by the national science foundation ( dms 1312124 ) ."
  ],
  "abstract_text": [
    "<S> as it is known in the finance risk and macroeconomics literature , risk - sharing in large portfolios may increase the probability of creation of default clusters and of systemic risk . </S>",
    "<S> we review recent developments on mathematical and computational tools for the quantification of such phenomena . limiting analysis such as law of large numbers and central limit theorems allow to approximate the distribution in large systems and study quantities such as the loss distribution in large portfolios . </S>",
    "<S> large deviations analysis allow us to study the tail of the loss distribution and to identify pathways to default clustering . </S>",
    "<S> sensitivity analysis allows to understand the most likely ways in which different effects , such as contagion and systematic risks , combine to lead to large default rates . </S>",
    "<S> such results could give useful insights into how to optimally safeguard against such events .    </S>",
    "<S> * keywords . * </S>",
    "<S> systemic risk , default clustering , large portfolios , loss distribution , asymptotic methods , rare events </S>"
  ]
}