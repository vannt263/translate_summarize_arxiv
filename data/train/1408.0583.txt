{
  "article_text": [
    "the detection and identification of explosive devices has always been of particular interest to security and mine - countermeasures .",
    "one of the most popular techniques used for the purpose of detection and identification is the ground penetrating radar ( gpr ) . exploiting the energy of backscattering electromagnetic pulses measured on a boundary",
    ", the gpr allows for mapping the internal structures containing explosives . although this concept is not new , combining the gpr with quantitative imaging may significantly enhance the detection and especially identification of explosive devices",
    "this idea was recently proposed and developed in a series of publications .",
    "for example , we mention @xcite , where three - dimensional ( 3-d ) quantitative imaging of dielectric constants of targets mimicking explosives was performed using experimental backscattering measurements ; we also refer to @xcite for 1-d imaging using real data collected in the field by a forward looking radar .    in the above works ,",
    "the imaging problem was formulated as a coefficient inverse problem ( cip ) for a time dependent wave - like pde .",
    "the main question in performing quantitative imaging is as follows : _ how to find a good approximation of the solution to the corresponding cip without any advanced knowledge of a small neighborhood of this solution ? _ we call a numerical method providing such an approximation _ globally convergent_. as soon as this approximation is found , a number of conventional locally convergent methods may be used to refine that approximation , see , e.g. , chapters 4 and 5 of @xcite for a two - stage numerical procedure .",
    "it is well known that the objective functionals resulted from applying the traditional least - squares method are usually nonconvex .",
    "this fact explains existence of multiple local minima and ravines of those functionals . in turn , the latter leads to the local convergence of gradient and newton - like methods .",
    "that is , the convergence of these methods is guaranteed only if an initial approximation lies in a small neighborhood of the solution .",
    "however , from our experience working with experimental data ( see above citations ) , we have observed that such a requirement is not normally satisfied in practical situations .    in this paper",
    "we propose a new numerical method which provides the global convergence .",
    "currently there are two approaches to constructing globally convergent algorithms .",
    "they were developed in a number of publications summarized in books @xcite .",
    "in particular , the above cited works treating experimental data use the approach of @xcite .",
    "the common part of both approaches is the temporal laplace transform .",
    "let @xmath0 be the parameter in the laplace transform .",
    "we assume that @xmath1 , where @xmath2 is a large enough positive constant .",
    "then , applying the laplace transform to the time - dependent wave - like pde , one obtains a boundary value problem for a nonlinear integral differential equation .",
    "however , the main difficulty then is that the integration over the parameter @xmath3 is required on the infinite interval @xmath4 . in the convexification method @xcite that integral",
    "was truncated , and the residual was set to zero . unlike this , in @xcite the residual , i.e. , the so - called tail function \" , was approximated in an iterative process .",
    "the open question is whether it is possible to avoid such a truncation . in other words , whether it is possible to avoid a procedure of approximating the tail function .",
    "this question is addressed in the current paper .    the _ main novelty _ here is that the truncation of the infinite integral is replaced by the truncation of a series with respect to some @xmath3-dependent functions forming an orthonormal basis in @xmath5 in this way , we obtain a coupled system of nonlinear elliptic equations with respect to the @xmath6dependent coefficients of the truncated series , where @xmath7 . in addition , we construct a least squares objective functional with a carleman weight function ( cwf ) in it .",
    "the main result is formulated in theorem [ th:1 ] . given a bounded set of an arbitrary size in a certain hilbert space",
    ", one can choose a parameter of the cwf such that this functional becomes strictly convex on this set .",
    "this implies convergence of gradient methods in finding the unique minimizer of the functional on that set , if it exists , starting from any point of that set .",
    "since restrictions on the diameter of that bounded set are not imposed , we call the latter _ global convergence _ and we call that functional _ globally _ strictly convex",
    ". this idea also works in the case when the fourier transform is applied to the wave - like equation instead of the laplace transform .    to demonstrate the computational feasibility of the proposed method",
    ", we perform a limited numerical study in the 1-d case .",
    "in particular , we show numerically that if a locally convergent algorithm starts from an approximation obtained by the proposed globally convergent algorithm , then the accuracy of approximations can be significantly improved . on the other hand , if that locally convergent algorithm starts from the background medium , then it may fail to perform well .",
    "in section [ sec:2 ] we formulate our inverse problem and theorems in 3-d . in sections",
    "[ sec:3][sec:5 ] we prove these theorems . in section [ sec:1dprob ]",
    "we briefly summarize the special case of the 1-d problem .",
    "section [ sec:6 ] describes some details of the numerical implementation in the 1-d case .",
    "finally , in section [ sec : numexa ] we demonstrate the numerical performance of the proposed algorithm .",
    "below @xmath8 let @xmath9 be a convex bounded domain with a piecewise - smooth boundary @xmath10 . we define @xmath11",
    "let the function @xmath12 satisfies the following conditions@xmath13where the numbers @xmath14 and @xmath15 are given . in this paper , @xmath16 denotes hlder spaces , where @xmath17 is an integer and @xmath18 . consider the following cauchy problem@xmath19the coefficient @xmath12 represents the spatially distributed dielectric constant . here",
    "@xmath20 is normalized so that its value in the background medium , i.e. , in @xmath21 , equals @xmath22 .",
    "the function @xmath23 represents one of components of the electric field generated by an incident plane wave propagating along the @xmath24axis and excited at the plane @xmath25 where @xmath26 .",
    "the function @xmath27 is continuous and bounded which represents the time - dependent waveform of the incident plane wave .",
    "of course , the propagation of electromagnetic waves should be modeled by the maxwell s equations . however , there are two reasons for us to use the scalar equation ( [ 2.7 ] ) .",
    "the first reason is that most gpr systems provide only scalar data instead of three components of the electric field .",
    "for example , in the experiments used in @xcite only one component of the electric field was generated by the source and the detector measured only that component of the backscattering electric field .",
    "the second reason is that it was demonstrated numerically in @xcite that if the incident wave has only one non - zero component of the electric field , then this component dominates the other two .",
    "moreover , equation ( [ 2.7 ] ) approximates well the propagation of that component even in 3-d @xcite .",
    "* cip 1 : * _ suppose that conditions ( [ 2.1])([2.8 ] ) are satisfied and that the plane _",
    "@xmath28__. determine the coefficient _",
    "_ @xmath20 _ _  for _ _ @xmath29 _ _  assuming that the following function",
    "_ _ @xmath30 _ _  is known _ _",
    "@xmath31    the function @xmath30 in ( [ 2.11 ] ) models a boundary measurement .",
    "having @xmath30 , one can uniquely solve the initial value problem ( 2.7)([2.8 ] ) outside of the domain @xmath32 hence , the normal derivative is also known : @xmath33    we note that the knowledge of functions @xmath30 and @xmath34 on an infinite rather than finite time interval is not a serious restriction of our method , since the laplace transform , which we use , effectively cuts off values of these functions for large @xmath35 .",
    "in addition , if the incident plane wave is excited on a finite time interval , the scattered wave will eventually vanish , as we observed in our experiments in @xcite . in practice ,",
    "incident waves are usually excited for a short period of time .",
    "consider the laplace transform @xmath36 where @xmath3 is referred to as the pseudofrequency .",
    "we also denote by @xmath37 the laplace transform of @xmath38 .",
    "consider @xmath39 , where the number @xmath40 is large enough , so that the laplace transforms of @xmath41 and its derivatives @xmath42 converge absolutely .",
    "the number @xmath43 is defined in ( [ 2.1 ] ) .",
    "we assume that @xmath44 for all @xmath45 .",
    "define @xmath46 .",
    "then , this function satisfies the equation : @xmath47define @xmath48 note that @xmath49 tends to zero as @xmath50 the function @xmath51 is the unique solution of equation ( [ eq : w ] ) in the case @xmath52 which tends to zero as @xmath53 it is shown in theorem 3.1 of @xcite that in the case @xmath54",
    "@xmath55 = 0   \\label{1}\\]]and that the function @xmath56 can be represented in the form@xmath57furthermore , the same theorem claims that @xmath58 for all @xmath59 .",
    "thus , we assume these properties in our algorithm even if @xmath60 next , define @xmath61 . substituting @xmath62 into ( [ eq : w ] ) and keeping in mind that @xmath63 , we obtain @xmath64hence , if the function @xmath65 is known , then the coefficient @xmath20 can be computed directly using ( [ eq : c ] ) .",
    "we define @xmath66 .",
    "thus , @xmath67 note that this converges absolutely together with its derivatives with respect to @xmath68 up to the second order .",
    "the latter is true if certain non - restrictive conditions are imposed on the function @xmath69 ( see lemma 6.5.2 in @xcite ) , and we assume that these conditions are in place . hence , differentiating ( [ eq : c ] ) with respect to @xmath3 leads to the following nonlinear integral differential equation as mentioned in introduction : @xmath70 in addition , the following two boundary functions @xmath71 , @xmath72 can be derived from functions @xmath73 , @xmath74 in ( [ 2.11 ] ) and ( [ 2.12])@xmath75    we have obtained the nonlinear boundary value problem ( [ 3.10])(3.11 ) for @xmath76 if this function is found , then the coefficient @xmath12 can be easily found via backwards calculations . therefore , the central focus should be on the solution of the problem ( [ 3.10])([3.11 ] ) .",
    "we remark that functions @xmath77 are results of measurements .",
    "hence , they contain noise .",
    "although one needs to calculate the first derivative with respect to @xmath3 of functions @xmath78 , @xmath79 in order to find functions @xmath80 , @xmath81 it was observed in @xcite that this can be done in a stable way , since the laplace transform smooth out the that noise . in addition , in our numerical computation we also remove high frequency noise by truncating high order fourier coefficients in the fourier transformed data .",
    "there have been two globally convergent method proposed by our group so far @xcite .",
    "the common point of both methods is that the integral in ( 3.10 ) is written as @xmath82the function @xmath83 is called the tail function . in the method of @xcite this tail function",
    "was set to be zero , whereas in @xcite it was approximated in an iterative process .",
    "the _ key novelty _ of the method of this paper is that it does not truncate the integral over @xmath3 in ( [ 3.10 ] ) as in the above methods .",
    "instead , we represent the function @xmath84 as a series with respect to an orthonormal basis of @xmath85 . using this representation , the integral over the infinite interval @xmath86 in ( [ 3.10 ] ) can be easily computed .",
    "let @xmath87 be an orthonormal basis in @xmath88 such that @xmath89 as an example , one can consider laguerre functions as:1964 @xmath90next , we set @xmath91 it can be verified that @xmath92 hence , one can represent the function @xmath93 as@xmath94where @xmath95 is a sufficiently large integer which should be chosen in numerical experiments .",
    "consider the vector of coefficients in the truncated series ( [ 3.12 ] ) @xmath96 substituting the truncated series ( 3.12 ) into ( [ 3.10 ] ) , we obtain @xmath97to be precise , one should have @xmath98 `` instead of @xmath99 '' in ( [ eq : qn ] ) due to the truncation ( [ 3.12 ] ) .",
    "multiplying both sides of ( [ eq : qn ] ) by @xmath100 , integrating over @xmath101 and keeping in mind the fact that @xmath102 is an orthonormal basis in @xmath85 , we obtain the following system of coupled nonlinear elliptic equations : @xmath103where the numbers @xmath104 , @xmath105 , are given by @xmath106the boundary conditions for @xmath107 are obtained by substituting again the truncated series ( [ 3.12 ] ) into ( [ 3.11 ] ) . for the convenience of the following analysis , we rewrite system ( [ eq : qn2 ] ) together with the boundary conditions as the following boundary value problem with over - determined boundary conditions .",
    "note that we have both dirichlet and neumann boundary conditions @xmath108where the boundary vector functions @xmath109 are computed from the functions @xmath110 and @xmath111 , @xmath112 with @xmath113    if we can find an approximate solution of the problem ( [ 3.13])(3.14 ) , then we can find an approximation for the function @xmath114 via the truncated series ( [ 3.12 ] ) .",
    "therefore , we focus below on the method of approximating the vector function @xmath115    let @xmath116 be a vector function and @xmath117 be a hilbert space . below any statement that @xmath118 means that every component of the vector @xmath119 belongs to @xmath117 .",
    "the norm @xmath120 means@xmath121",
    "our ultimate goal is to apply this method to the inversion of experimental data of @xcite .",
    "thus , just as in these references , below @xmath122 is chosen to be a rectangular parallelepiped . without loss of generality , it is convenient to assume that @xmath123where @xmath124 is a number .",
    "thus , @xmath125 where @xmath126as in @xcite , @xmath127 is considered as the backscattering side , where the data are measured . although measurements were not performed on @xmath128 it was demonstrated in these references that assigning @xmath129does not affect the accuracy of the reconstruction via the technique of bk .",
    "this is probably because of the condition ( [ 1 ] ) .",
    "thus , we now relax conditions ( [ 3.14 ] ) , assuming that the normal derivative is given only on @xmath130 the dirichlet condition is given on @xmath131 and no boundary condition is given on @xmath132 , @xmath133    let us introduce a cwf for the laplace operator which is suitable for this domain @xmath122 and for boundary conditions ( [ 4.1 ] ) .",
    "let @xmath134 be two arbitrary numbers .",
    "let @xmath135 be two large parameters which we will choose later .",
    "then the cwf has the form @xmath136hence,@xmath137lemma [ le:1 ] establishes a carleman estimate for the operator @xmath138 in the domain @xmath122 with the weight function ( [ 4.2 ] ) .",
    "the proof of this lemma is almost identical to the proof of lemma 6.5.1 of @xcite and is therefore omitted .",
    "[ le:1 ] there exist sufficiently large numbers @xmath139 depending only on the listed parameters such that for an arbitrary function @xmath140 satisfying @xmath141 the following carleman estimate holds for all @xmath142 and with a constant @xmath143 depending only on the domain @xmath122 @xmath144    below @xmath143 denotes different constants depending only on the domain @xmath32 let @xmath145 be an arbitrary number .",
    "define the set @xmath146 of vector functions @xmath147 as @xmath148then @xmath146 is an open set in @xmath149 also , embedding theorem implies that @xmath150let @xmath151 be the number in lemma le:1 .",
    "denote @xmath152 we seek the solution @xmath147 of the problem ( [ 3.13 ] ) , ( [ 4.1 ] ) on the set @xmath146 via minimizing the following tikhonov - like cost functional with the cwf @xmath153 and with the regularization parameter @xmath154 @xmath155 ^{2}\\varphi _",
    "{ \\lambda , \\nu _ { 0}}^{2}dx+\\frac{\\alpha } { 2}\\left\\vert q\\right\\vert _ { h^{3}\\left ( \\omega \\right ) } ^{2},q\\in g\\left ( r,\\phi ,",
    "\\psi \\right ) .   \\label{4.5}\\ ] ]    [ th:1 ] there exists a sufficiently large number @xmath156 depending only on @xmath157 such that if @xmath158 and @xmath159 , then the functional @xmath160 is strictly convex on the set @xmath146 , i.e. , there exists a constant @xmath161 depending only on @xmath157 such that for all @xmath162 @xmath163where @xmath164 is the frchet derivative of the functional @xmath165 at the point @xmath166    * proof*. the existence of the frchet derivative of the functional @xmath165 is shown in the proof . everywhere below @xmath161",
    "denotes different positive constants depending only on the listed parameters .",
    "denote @xmath167 then by ( [ 4.3])@xmath168denote @xmath169 the subspace of the space @xmath170 consisting of vector functions satisfying conditions ( [ 4.6 ] ) . let @xmath171 be the @xmath172 matrix , @xmath173hence , ( [ 4.4 ] ) implies that @xmath174next , by taylor s formula @xmath175where @xmath176hence , for all @xmath177 @xmath178 ^{2 } \\\\ & = \\left [ \\delta q_{1}+f\\left ( \\nabla q_{1}\\right ) + \\delta h+f^{\\prime } \\left ( \\nabla q_{1}\\right ) \\nabla h+p\\left ( \\nabla q_{1},\\nabla h\\right ) \\right ] ^{2 } \\\\ & = \\left ( \\delta q_{1}+f\\left ( \\nabla q_{1}\\right ) \\right ) ^{2}+2\\left ( \\delta q_{1}+f\\left ( \\nabla q_{1}\\right ) \\right ) \\left [ \\delta h+f^{\\prime } \\left ( \\nabla q_{1}\\right ) \\nabla h\\right ] + \\left ( \\delta h\\right ) ^{2 } \\\\ & + 2p\\left ( \\nabla q_{1},\\nabla h\\right ) \\delta h+p^{2}\\left ( \\nabla q_{1},\\nabla h\\right ) \\\\ & + 2p\\left ( \\nabla q_{1},\\nabla h\\right ) \\left [ \\delta q_{1}+f\\left ( \\nabla q_{1}\\right ) + \\delta h+f^{\\prime } \\left ( \\nabla q_{1}\\right ) \\nabla h\\right ] . \\end{split } \\label{0}\\]]by ( [ 4.610 ] ) and the cauchy - schwarz inequality @xmath179 hence , using ( [ 4.61])([0 ] ) , we obtain@xmath180 ^{2}-\\left [ \\delta q_{1}+f\\left ( \\nabla q_{1}\\right ) \\right ] ^{2 } \\\\ & -2\\left [ \\delta q_{1}+f\\left ( \\nabla q_{1}\\right ) \\right ] \\left [ \\delta h+f^{\\prime } \\left ( \\nabla q_{1}\\right ) \\nabla h\\right ] \\geq \\frac{1}{2}\\left ( \\delta h\\right ) ^{2}-c_{1}\\left ( \\nabla h\\right ) ^{2}. \\end{split } \\label{4.6100}\\]]on the other hand,@xmath181where @xmath182 is the scalar product in @xmath149 it follows from ( [ 0 ] ) that @xmath183 \\left [ \\delta h+f^{\\prime } \\left ( \\nabla q_{1}\\right ) \\nabla h\\right ] + \\alpha \\left ( q_{1},h\\right ) _ { h^{3}\\left ( \\omega \\right ) } .   \\label{4.62}\\ ] ]    the right hand side of ( [ 4.62 ] ) is a bounded linear functional acting on the function @xmath184 hence , riesz theorem and ( [ 4.62 ] ) imply that there exists an element @xmath185 such that @xmath186 thus , the frchet derivative @xmath187 of the functional @xmath188 exists and @xmath189 by ( [ 0])([4.62 ] ) @xmath190 \\varphi _ { \\lambda , \\nu _ { 0}}^{2}dx+\\alpha \\left\\vert h\\right\\vert _ { h^{3}\\left ( \\omega \\right ) } ^{2}. \\end{split } \\label{4.7}\\]]for @xmath191 @xmath192 hence , by lemma [ le:1 ] for sufficiently large @xmath193    @xmath194 \\varphi _",
    "{ \\lambda , \\nu _ { 0}}^{2}dx\\geq c_{1}\\int\\limits_{\\omega } \\left [ \\lambda \\left\\vert \\nabla \\left ( h\\right ) \\right\\vert ^{2}+\\lambda ^{3}h^{2}\\right ] \\varphi _ { \\lambda , \\nu _ { 0}}^{2}dx \\\\ & -c_{1}\\varphi _ { \\lambda , \\nu _ { 0}}^{2}\\left ( 1/2\\right ) \\int\\limits_{\\gamma _ { 2}}\\left ( \\left\\vert",
    "\\nabla h\\right\\vert ^{2}+h^{2}\\right ) dx_{2}dx_{3 } \\\\ & \\geq c_{1}\\left\\vert q_{2}-q_{1}\\right\\vert _ { h^{1}\\left ( \\omega _ { a}\\right ) } ^{2}-c_{1}\\varphi _ { \\lambda , \\nu _ { 0}}^{2}\\left ( 1/2\\right ) \\left\\vert q_{2}-q_{1}\\right\\vert _ { h^{3}\\left ( \\omega \\right ) } ^{2}. \\end{split } \\label{4.8}\\ ] ]    by ( [ 4.21 ] ) the lower boundary of @xmath195 tends to zero as @xmath196 and also @xmath197hence , ( [ 4.7 ] ) and ( [ 4.8 ] ) imply ( [ 4.51 ] ) .",
    "@xmath198    [ co:1 ] there exists at most one vector function @xmath199 satisfying conditions ( [ 3.13 ] ) , ( 4.1 ) .",
    "* let @xmath200 suppose that there exist two vector functions @xmath162 _ _  _ _ satisfying conditions ( [ 3.13 ] ) , ( [ 4.1 ] ) .",
    "then @xmath201 on the other hand , @xmath202 hence , @xmath203 and @xmath204 are points of minimum of the functional @xmath205 hence , @xmath206 hence , repeating the proof of theorem [ th:1 ] , we obtain the following analog of ( [ 4.8 ] ) @xmath207setting in ( [ 4.9 ] ) @xmath196 and using ( [ 4.21 ] ) , we obtain @xmath208 in @xmath209 since @xmath210 is an arbitrary number , then @xmath208 in @xmath32 @xmath198",
    "it is well - known that the gradient descent method is globally convergent for functionals which are strictly convex on the entire space .",
    "however , the functional ( [ 4.5 ] ) is strictly convex only on the bounded set @xmath211 .",
    "therefore we need to prove the global convergence of this method on this set .",
    "suppose that a minimizer @xmath212 of ( [ 4.5 ] ) exists on @xmath211 . in the regularization theory @xmath212",
    "is called _ regularized solution _ of the problem ( [ 3.13 ] ) , ( [ 4.1 ] ) @xcite .",
    "theorem [ th:1 ] guarantees that such a minimizer is unique .",
    "first , we estimate in this section the distance between regularized and exact solutions , depending on the level of error in the data .",
    "next , we establish that theorem [ th:1 ] implies that the gradient descent method of the minimization of the functional ( [ 4.5 ] ) converges to @xmath212 if starting at any point of this set , i.e. , it converges globally .",
    "in addition , we estimate the distance between points of the minimizing sequence of the gradient descent method and the exact solution of the problem . in principle , global convergence of other gradient methods for the functional ( [ 4.5 ] ) can also be proved .",
    "however , we are not doing this for brevity .      following one of concepts of tikhonov for ill - posed problems ( see , e.g. , section 1.4 in @xcite ) , we assume that there exist noiseless boundary data @xmath213 and @xmath214 which correspond to the exact solution @xmath215 of the problem ( [ 3.13 ] ) , ( [ 4.1 ] ) .",
    "also , we assume that functions @xmath216 and @xmath217 at the part @xmath127 of the boundary contain an error of the level @xmath218@xmath219on the other hand , we do not assume any error in the function @xmath220 at @xmath128 see a heuristic condition ( [ 4.0 ] ) , which was justified numerically in @xcite .",
    "theorem [ th:2 ] estimates the distance between @xmath212 and @xmath215 in the norm of @xmath221 which might be sufficient for computations .",
    "note that while in theorem [ th:1 ] we have compared functions @xmath203 and @xmath204 satisfying the same boundary conditions , functions @xmath212 and @xmath215 in theorem [ th:2 ] satisfy different boundary conditions , because of the error in the data .",
    "[ th:2 ] assume that conditions of theorem th:1 hold and @xmath158 .",
    "in addition , assume that conditions ( [ 5.7 ] ) are satisfied and also @xmath222 .",
    "suppose that there exists an exact solution @xmath215 of the problem ( [ 3.13 ] ) , ( [ 4.1 ] ) and @xmath223 in addition , assume that there exists a minimizer @xmath224 of the functional @xmath225 let the number @xmath226 be so small that @xmath227let @xmath228 choose the regularization parameter @xmath229 in ( [ 4.5 ] ) as @xmath230 where @xmath231 \\in \\left ( 0,\\frac{1}{2}\\right ) .\\ ] ] then @xmath232 ( as in theorem [ th:1 ] ) and @xmath233    * proof*. denote @xmath234 in the proof of theorem [ th:1 ] the function @xmath235 satisfies zero boundary conditions ( [ 4.6 ] ) .",
    "now , however , the only zero condition for the function @xmath236 is @xmath237 still , it is obvious that one can slightly modify the proof of theorem [ th:1 ] for the case of non - zero dirichlet and neumann boundary conditions for @xmath236 at @xmath238 to do so , we take into account the second term on the left hand side of ( [ 4.20 ] ) .",
    "thus , @xmath239by ( [ 5.7 ] ) @xmath240since @xmath241 then it follows from ( 5.9 ) that one can choose @xmath242 such that @xmath243 thus , @xmath244 .",
    "it can be easily verified that the above choice @xmath245 guarantees that @xmath246 hence , ( 5.12 ) and ( [ 5.13 ] ) imply that for such @xmath247 @xmath248    next , since @xmath215 is the exact solution of the problem ( [ 3.13 ] ) , ( [ 4.1 ] ) , then @xmath249 in @xmath32 hence , ( [ 4.5 ] ) implies that @xmath250finally , since @xmath251 @xmath252 and @xmath253 then ( [ 5.14 ] ) and ( [ 5.15 ] ) imply that @xmath254 which establishes ( [ 5.10 ] ) .",
    "@xmath255      we now formulate the gradient descent method with the constant step size @xmath256 for the problem of the minimization of the functional @xmath257 for brevity we do not indicate the dependence of functions @xmath258 on parameters @xmath259 .",
    "let @xmath260 be an arbitrary point of the set @xmath261 .",
    "consider the sequence @xmath262 of the gradient descent method , @xmath263    [ th:3 ] choose parameters @xmath264 as in theorem [ th:1 ] and let @xmath265 assume that the functional @xmath165 achieves its minimal value on the set @xmath211 at a point @xmath266 consider the sequence ( [ 5.1 ] ) , in which the starting point @xmath203  is an arbitrary point of the set @xmath267 .",
    "then there exists a sufficiently small number @xmath268 and a number @xmath269 both dependent only on the listed parameters , such that the sequence ( [ 5.1 ] ) converges to the point @xmath270@xmath271 in addition , assume that there exists an exact solution @xmath272 of the problem ( 3.13 ) , ( [ 4.1 ] ) and that all conditions of theorem [ th:2 ] hold .",
    "then for all @xmath273 the following estimate holds @xmath274    * proof . *",
    "consider the nonlinear operator * *  * * @xmath275 in ( [ 3.13 ] ) .",
    "then @xmath276 where the space @xmath277 is defined as the space of vector functions @xmath278 such that@xmath279hence , the frchet derivative @xmath280 at any point @xmath281 acting on an element @xmath282 is defined as @xmath283 .",
    "let @xmath284 be the space of bounded linear operators mapping @xmath169 in @xmath285 it follows from results of section 8.2 of the book @xcite that in order to prove this theorem , we should prove first that norms @xmath286 are uniformly bounded for @xmath287 second , we should prove that the map @xmath288is lipschitz continuous on the set @xmath211 .",
    "it follows from the above that @xmath289hence , @xmath290    to prove the lipschitz continuity of the map ( [ 5.20 ] ) , we need to estimate the norm @xmath291 , for @xmath292 we have @xmath293 \\nabla h.\\]]since @xmath294 then @xmath295 \\nabla h\\right\\vert \\left ( x\\right )",
    "\\leq c_{1}\\left\\vert q_{1}-q_{2}\\right\\vert",
    "_ { h^{3}\\left ( \\omega \\right ) } \\left\\vert \\nabla h\\right\\vert \\left ( x\\right ) $ ] , @xmath296 hence , @xmath297which proves the lipschitz continuity of the map ( [ 5.20 ] ) .",
    "hence , theorem [ th:1 ] , ( [ 5.3 ] ) , ( [ 5.4 ] ) and the result of section 8.2 of the book @xcite guarantee that ( [ 5.2 ] ) holds , as long as @xmath298    we show now that ( [ 5.5 ] ) is true . since @xmath299 @xmath300 then @xmath301it follows from ( [ 4.62 ] ) that norms @xmath302 are uniformly bounded for all @xmath287 choose a sufficiently small number @xmath303 such that @xmath304hence , ( [ 5.1 ] ) and ( [ 5.6 ] ) imply that @xmath305 hence , @xmath306 thus , ( [ 5.2 ] ) is true for @xmath307 . by ( [ 5.2 ] ) and ( [ 5.50 ] ) @xmath308 next , @xmath309 hence , @xmath310suppose that @xmath311 .",
    "then ( [ 5.2 ] ) holds for these terms . by ( [ 5.1 ] ) and ( [ 5.6 ] ) @xmath312",
    "hence , @xmath313 hence , by ( [ 5.50 ] ) and the triangle inequality@xmath314hence , @xmath315 .",
    "thus , we have established that ( [ 5.5 ] ) holds , which , in turn implies ( [ 5.2 ] ) .",
    "now we prove ( [ 5.11 ] ) . using ( [ 5.10 ] ) , ( [ 5.2 ] ) and the triangle inequality , we obtain@xmath316thus , @xmath317 which is ( [ 5.11 ] ) . @xmath318",
    "in this section we consider the 1-d analog of the above cip .",
    "our motivation for considering this case is twofold .",
    "first , in some practical cases , only 1-d data are available , see , e.g. , @xcite for experimental data measured by us army research laboratory for devices mimicking explosives , which is our target application .",
    "second , since numerical computation of the 1-d problem is simple and fast , we can use it to quickly analyze influence of different parameters on the performance of the algorithm in order to choose optimal ones which may be used for the 3-d case as well .",
    "analytical results for our 1-d cip are quite similar to the 3-d case . therefore , we only briefly state them below .",
    "the forward problem in the 1-d case is @xmath319for simplicity , we choose @xmath320 , where @xmath321 is a constant , and the function @xmath12 satisfies the following analogs of conditions ( [ 2.1 ] ) @xmath322    * cip 2 . * _ suppose that in ( [ 6.1 ] ) the source location _",
    "@xmath323__. determine the function _",
    "_ @xmath20 _ _  for _ _ @xmath324 _ _  assuming that the following functions _",
    "_ @xmath325 _ _  are given__@xmath326    the cwf in the 1-d case can be chosen as @xmath327 which is different from the one in ( [ 4.2 ] ) .",
    "note that this cwf makes numerical computation more efficient . to justify the use of this cwf",
    ", we use the carleman estimate of lemma [ le:2 ] .",
    "we omit its proof , since it can be obtained via a slight modification of arguments on pages 188 , 189 of @xcite .",
    "[ le:2 ] the following carleman estimate holds for all functions @xmath328 with a number @xmath329 depending only on @xmath330 and for all @xmath331 @xmath332 \\\\ & \\geq c_{2}\\int\\limits_{0}^{b}\\left [ \\left ( u^{\\prime \\prime } \\right ) ^{2}+\\lambda \\left ( u^{\\prime } \\right ) ^{2}+\\lambda ^{3}u^{2}\\right ] \\varphi _ { \\lambda } ^{2}\\left ( x\\right ) dx , \\end{split}\\]]which implies that @xmath333 \\geq c_{2}e^{-2\\lambda b}\\left\\vert u\\right\\vert _ { h^{2}\\left ( 0,b\\right ) } ^{2}. \\label{6.6}\\ ] ]    the one - dimensional analog of the set @xmath334 in ( [ 4.3 ] ) is @xmath335where vectors @xmath336 and @xmath337 belong to @xmath338 here the neumann boundary data @xmath339 at @xmath340 is derived from the absorbing boundary condition ( abc ) @xcite , keeping in mind that @xmath341 is an out - going wave at @xmath340 , see section [ subsec : numfp ] . by embedding theorem , @xmath342   $ ] and @xmath343 } < cr,\\forall q\\in g_{1}.$ ]",
    "it follows from ( [ 6.6 ] ) that there is no need to use the regularization term in the 1-d version of the functional ( [ 4.5 ] ) .",
    "thus , we use in our numerical study the following analog of @xmath165@xmath344 ^{2}\\varphi _ { \\lambda } ^{2}\\left ( x\\right ) dx .",
    "\\label{6.9}\\ ] ]    theorem [ th:4 ] is the 1-d analog of theorem [ th:1 ] , and the proof is similar .",
    "[ th:4 ] there exists a sufficiently large number @xmath345 depending only on @xmath346 and @xmath347 such that for all @xmath348 the functional @xmath349 is strictly convex on the set @xmath346 , i.e. , there exists a constant @xmath350 depending only on @xmath346 and @xmath347 such that @xmath351where @xmath352 is the frchet derivative of the functional @xmath353 at the point @xmath166    [ re:2 ]    \\1 .",
    "although we do not need the knowledge of the vector @xmath339 in the proof of this theorem , we use this knowledge for a better stability of our numerical method .",
    "the strict convexity constant @xmath354 in ( [ 6.10 ] ) is small either for large @xmath247 or for large @xmath330 .",
    "therefore , it is expected that the functional @xmath353 is more sensitive to the change of @xmath147 near the point @xmath355 than at points far from it . in other words ,",
    "the slope of @xmath353 should be large near @xmath355 and small far away from @xmath355 .",
    "consequently , it may be hard to obtain accurate approximation of the solution far away from @xmath356 . to remedy this ,",
    "some sort of the layer stripping procedure may be used .",
    "the idea of this layer stripping procedure is that we first consider the integral over @xmath357 for a small value of @xmath358 .",
    "next , we consider the integral over @xmath359 etc . a balance between values of @xmath247 and @xmath360 should be found in numerical experiments .",
    "another option for enhancing the accuracy of the computed coefficient , which we use here , is to refine it via a gradient - based optimization method for the original time domain problem , see section [ subsec : localmethod ] .",
    "this results in a two - stage numerical procedure , see chapters 4,5 of bk for the idea of such a procedure for a different numerical method.more precisely : ( 1 ) on the first stage a globally convergent numerical method addresses the most difficult question of obtaining a point in a small neighborhood of the exact coefficient without any advanced knowledge of that neighborhood , and ( 2 ) on the second stage a locally convergent numerical method refines the solution of the first stage via starting its iteration from that point .",
    "in this section we describe details of our numerical implementation of the proposed algorithm .",
    "we also test a two - stage numerical procedure mentioned in item 2 of remark [ re:2 ] .      in numerical computation , we solve the forward problem ( [ 6.1])([6.2 ] ) in a bounded interval @xmath361 such that @xmath362 .",
    "recall that @xmath363 .",
    "we consider the case that @xmath364 and rewrite @xmath365 , where @xmath366 is the incident wave and @xmath367 is the scattered wave . the incident wave @xmath366 satisfies ( [ 6.1])([6.2 ] ) with @xmath52 and is given by the following formula @xmath368to approximate the wave propagation in the whole 1-d space @xmath369 by the problem in the bounded interval @xmath361 , we keep in mind the fact that the scattered wave is out - going in both directions .",
    "thus , we assume that the function @xmath370 satisfies the abc at @xmath371 and @xmath372 .",
    "this means that we solve the following problem for @xmath367 : @xmath373u_{tt}^{i}(x , t),(x , t)\\in ( k , d)\\times ( 0,t ) ,   \\label{eq : numfp1 } \\\\ & & u^{s}(x,0)=u_{t}^{s}(x,0)=0,\\ x\\in ( k , d ) ,   \\label{eq : numfp2 } \\\\ & & u_{x}^{s}(k , t)=u_{t}^{s}(k , t),\\ u_{x}^{s}(g , t)=-u_{t}^{s}(g , t),\\ t\\in ( 0,t ) .   \\label{eq : numfp3}\\end{aligned}\\ ] ]    in the numerical examples presented below , we choose @xmath374 , @xmath375 , @xmath376 and @xmath377 . the waveform @xmath38 of the incident wave is chosen to be @xmath378where @xmath379 and @xmath380 .",
    "the constant @xmath381 is used as the normalization factor .",
    "the problem ( [ eq : numfp1])([eq : numfp3 ] ) is solved by an explicit finite difference scheme with uniform grids in both @xmath68 and @xmath35 with step sizes of @xmath382 and @xmath383 .",
    "this results in @xmath384 grid points in space and @xmath385 points in time .    in order to simulate noisy measurements , we add additive noise of @xmath386 ( in the @xmath387 norm ) to the simulated data .",
    "consider a partition of the interval @xmath388 into @xmath389 sub - intervals by the grid points @xmath390 with @xmath391 , @xmath392 .",
    "we define the discrete unknown function @xmath393 with @xmath394 .",
    "we approximate the functional ( [ 6.9 ] ) by the following discrete version using a forward finite difference scheme @xmath395 ^{2}\\varphi _ { \\lambda } ^{2}(x_{i } ) , \\label{eq : numqn}\\]]where @xmath396for @xmath397 and @xmath398 .",
    "note that from the boundary conditions for @xmath147 , we have @xmath399hence , the unknowns to be determined are @xmath400 , @xmath397 , @xmath401 .",
    "the gradient of the functional @xmath402 can be easily derived from ( [ eq : numqn ] ) and ( [ eq : numqn2 ] ) .",
    "the first guesses @xmath403 for @xmath400 in minimizing the functional ( eq : numqn ) are chosen as @xmath404    we do not have a proof of the global strict convexity of the discrete functional ( [ eq : numqn ] ) at the moment and leave this for future work .",
    "we should mention that the spatial mesh size @xmath405 for solving the forward problem ( [ eq : numfp1])([eq : numfp3 ] ) is chosen small enough , which should be about @xmath406 of the wavelength of the incident wave , for the accuracy of the finite difference scheme .",
    "however , our numerical computation have indicated that in order to enhance the stability of the minimization of the functional ( [ eq : numqn ] ) , the grid size @xmath407 in the discretization of the function @xmath147 should not be chosen too small . in the tests below , @xmath407 is chosen to be @xmath408 .",
    "after getting the values of the coefficient @xmath20 at these grid points , we linearly interpolate it to the finer grid of size @xmath405 for a local method presented below .",
    "despite the fact that the functional ( [ 6.9 ] ) is strictly convex on the bounded set @xmath346 , our numerical tests work even without any constraints applied to the unknown coefficients .",
    "that means that we only need to solve unconstrained optimization problems .",
    "although at least the continuous counterpart ( [ 6.9 ] ) of the functional ( [ eq : numqn ] ) is guaranteed to be strictly convex on the set @xmath346 for @xmath247 large enough , we have observed numerically that the slope of @xmath402 is quite small , especially with respect to large values of @xmath409 , i.e. , for points far away from the location of measurement . due to this reason ,",
    "it is hard to obtain accurate results using the globally convergent method alone . in order to enhance the accuracy of the computed coefficient obtained by the proposed globally convergent method",
    ", we combine it with a locally convergent gradient - based method , which uses the result of the former as an initial guess .",
    "given the boundary data ( [ 6.5 ] ) , the forward problem ( [ eq : numfp1])([eq : numfp3 ] ) can be replaced with the following one : @xmath373u_{tt}^{i}(x , t),(x , t)\\in ( 0,d)\\times ( 0,t ) ,   \\notag \\\\ & & u^{s}(x,0)=u_{t}^{s}(x,0)=0,\\ x\\in ( 0,d ) ,   \\notag \\\\ & & u_{x}^{s}(0,t)=p_{2}(t)-u_{x}^{i}(0,t),\\ t\\in ( 0,t ) ,   \\notag \\\\ & & u_{x}^{s}(g , t)=-u_{t}^{s}(g , t),\\",
    "t\\in ( 0,t ) .   \\notag\\end{aligned}\\]]the coefficient @xmath410 , is determined by minimizing the following objective functional @xmath411^{2}dt+\\frac{1}{2}\\alpha \\mathcal{r}(c - c_{glob}),\\]]where @xmath412 is the coefficient computed by the globally convergent method and @xmath413 , @xmath414 , is a tikhonov - type regularization term . in our tests , we choose @xmath415 . using the adjoint equation method , it is straightforward to derive the following formula for the gradient @xmath416 of @xmath417 : @xmath418where @xmath419 is the solution to the following adjoint problem @xmath420    in the following , we call the globally convergent method as step 1 and the locally convergent method as step 2 of this hybrid algorithm . furthermore , we have observed in our numerical test that if the unknown coefficient is to be determined in a large interval @xmath388 , then the results of step 2 may not be very accurate .",
    "therefore , we propose an additional step , step 3 , as described in the following algorithm .",
    "* algorithm : *    * given the data : @xmath421 , @xmath422 , @xmath423 .",
    "choose @xmath95 laguerre s coefficients .",
    "* step 1 ( the globally convergent method ) : 1 .",
    "compute the functions @xmath424 , @xmath425 and @xmath426 , @xmath427 .",
    "2 .   find a minimizer @xmath428 of the functional ( eq : numqn ) , starting from the initial guess ( [ eq : qn_init ] ) .",
    "3 .   compute the coefficient values @xmath429 given the laguerre s coefficients @xmath428 .",
    "* step 2 ( locally convergent method ) : 1 .",
    "linearly interpolate the coefficient @xmath412 from the grid of step size @xmath407 to the grid of step size @xmath405 .",
    "2 .   compute @xmath430 , by minimizing functional ( [ eq : local1 ] ) , starting from @xmath412 as an initial guess .",
    "* step 3 ( locally convergent method applied to a reduced spatial interval ) : 1 .",
    "reduce the interval @xmath388 to @xmath431 , where @xmath360 is determined as follows @xmath432 2 .",
    "compute an update @xmath433 of the coefficient by minimizing the functional ( [ eq : local1 ] ) in @xmath431 , starting from @xmath434 as the initial guess .",
    "the choice of @xmath435 in step 3.1 means that in step 3 we refine the coefficient value only in the interval closest to the measurement location in which its value is substantially different from that of the background medium . here",
    ", @xmath436 is a truncation parameter which should be chosen in numerical experiments .",
    "the minimization problems on all steps of this algorithm are solved by the sequential quadratic programming method for unconstrained optimization problems which is implemented in matlab optimization toolbox .",
    "in this section we present a limited testing of the above algorithm for some numerically simulated data . we also compare its performance with the above locally convergent method alone using the coefficient of the homogeneous medium as the first guess . numerical results for experimental data in both 1-d and 3-d cases",
    "are under consideration and will be reported in future work .    since our target application is in imaging of an abnormal object placed in a homogeneous medium , we mainly test the proposed algorithm with a discontinuous coefficient",
    ". the locations of the discontinuities represent the location of the target .",
    "as mentioned in remarks [ re:2 ] , it is hard to obtain accurate reconstructions at locations far away from the measurement point .",
    "however , this is not a serious restriction from the practical standpoint .",
    "indeed , our experience of working with 3-d time resolved backscattering experimental data @xcite tells us that , using the so - called data propagation procedure in data pre - processing , we can approximate quite well both the distance from the measurement point to the target and the dirichlet and neumann backscattering data near the target .",
    "thus , we assume below that the target is close to the measurement point .    in the following examples ,",
    "the parameters were chosen as follows : the pseudo frequencies were @xmath437 $ ] with the integration step size in ( [ eq : qn ] ) @xmath438 .",
    "the number of laguerre s functions was @xmath439 .",
    "the coefficients @xmath247 in the cwf was @xmath440 .",
    "the regularization parameter @xmath441 and the truncation value @xmath442 .",
    "* example 1 . *",
    "consider a piecewise constant coefficient given by @xmath443,$ ] where @xmath444 is the characteristic function .",
    "figure [ fig : exa1 ] ( a ) compares the computed coefficient values of steps 1 and 2 with the exact one and figure fig : exa1 ( b ) depicts the result of step 3 . to compare with the performance of the above locally convergent method alone , we plot in figure fig : exa1 ( c ) , ( d ) the results of steps 2 and 3 , respectively , starting from the homogeneous medium as the initial guess .",
    "we can see that our hybrid algorithm provided accurate results , whereas the locally convergent method alone failed .",
    "* example 2 . * in this example , we consider another piecewise constant coefficient with a larger jump @xmath445.$ ] the results of steps 1 - 3 are shown in figure [ fig : exa2 ] . even though the jump of the coefficient is high in this case",
    ", we still can see the good accuracy of the reconstruction using our hybrid algorithm .",
    "* example 3 .",
    "* consider the exact coefficient @xmath446.$ ] this coefficient mimics the case the case when the dielectric constant of an explosive is less than the one of a homogeneous background .",
    "figure [ fig : exa3 ] shows the reconstruction results of steps 1 - 3 of the algorithm .",
    "again , we obtained an accurate reconstruction .",
    "* example 4 . *",
    "finally , we consider a continuous coefficient given by @xmath447 the results are shown in figure [ fig : exa4 ] . comparing figure [ fig : exa4 ] ( a ) with figure [ fig : exa4 ] ( c ) , one can see that the combination of step 1 and step 2 provided much better result than step 2 starting from the homogeneous medium as the first guess .",
    "however , results of step 3 of both cases are accurate .    from figure [",
    "fig : exa1 ] ( d ) and figure [ fig : exa4 ] ( d ) we see that the above locally convergent method , taking alone , is unstable in the sense that , depending on the type of the target , it provides either bad or good quality images .",
    "meanwhile , the proposed hybrid algorithm provides accurate results in all four examples .",
    "l.  beilina , energy estimates and numerical verification of the stabilized domain decomposition finite element / finite difference approach for the maxwell s system in time domain , _ central european journal of mathematics _ , 11 , 702 - 733 , 2013 .",
    "kuzhuget , l. beilina , m.v .",
    "klibanov , a. sullivan ,  l. nguyen and m.a .",
    "fiddy , blind experimental data collected in the field and an approximately globally convergent inverse algorithm , _ inverse problems _ , 28 , 095007 , 2012 .      n.  t. thnh , l.  beilina , m.  v. klibanov and m.  a. fiddy , reconstruction of the refractive index from experimental backscattering data using a globally convergent inverse method , _ siam j. sci . comp . , _ 36 , b273-b293 , 2014 .",
    "n.  t. thnh , l.  beilina , m.  v. klibanov and m.  a. fiddy , imaging of buried objects from experimental backscattering time dependent measurements using a gloobally convergent inverse algorithm , _ arxiv _ : 1406.3500v1 [ math - ph ] , 2014 ."
  ],
  "abstract_text": [
    "<S> the inverse problem of estimating dielectric constants of explosives using boundary measurements of one component of the scattered electric field is addressed . </S>",
    "<S> it is formulated as a coefficient inverse problem for a hyperbolic differential equation . after applying the laplace transform , a new cost functional </S>",
    "<S> is constructed and a variational problem is formulated . </S>",
    "<S> the key feature of this functional is the presence of the carleman weight function for the laplacian . </S>",
    "<S> the strict convexity of this functional on a bounded set in a hilbert space of an arbitrary size is proven . </S>",
    "<S> this allows for establishing the global convergence of the gradient descent method . </S>",
    "<S> some results of numerical experiments are presented .    * keywords * : coefficient inverse problem , laplace transform , carleman weight function , strictly convex cost functional , global convergence , laguerre functions , numerical experiments .    * ams classification codes : * 35r30 , 35l05 , 78a46 </S>"
  ]
}