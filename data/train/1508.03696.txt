{
  "article_text": [
    "symanzik and then nelson have pioneered the study of euclidean field theory more than forty years ago @xcite . in their approach ,",
    "measures on random paths and loops play an important role and led to further important developments such as in the work of brydges , frhlich and spencer @xcite ( see also dynkin @xcite ) . in all these papers ,",
    "a gas of closed loops is used to represent partition functions and correlation structures of random fields .",
    "the present note will be in the same spirit , but the focus will be on this random gas of loops itself as the main object of interest , rather than viewing it as a combinatorial diagrammatic tool to evaluate quantities related to fields",
    ". we will in particular focus on the role of orientation of loops and describe a particular simple property of such random configurations of unoriented loops as well as for random configurations of oriented loops .",
    "these properties are very directly related to the combinatorial features used in the aforementioned papers as well as to some features in the more recent study by le jan @xcite , who was also focusing more on properties of the occupation times of these soups . in particular , some of the observations in sections 7 and 9 in @xcite can be viewed as describing some of the features that we will try to highlight .",
    "these gases of loops , or loop - soups ( as they have been called in @xcite ) are a random poissonian ( i.e. non - interacting ) collection of random unrooted loops in a domain , that can be associated naturally to a markov process or a discrete - time markov chain ( see @xcite and the references therein ) .",
    "when one discovers the configurations of the loop - soup within a given sub - domain @xmath0 of the entire domain in which the soup is defined , one observes on the one hand loops that are entirely contained in @xmath0 ( which form a loop - soup in @xmath0 ) , and on the other hand , excursions in @xmath0 that are parts of loops that do not entirely stay in @xmath0 .",
    "note that different such excursions can belong to the same loop or not , depending on the configuration outside of @xmath0 .",
    "the markovian property that we shall discuss basically describes how to randomly complete the missing pieces into the loops i.e. it describes the conditional distribution of the loop - soup outside of @xmath0 when conditioning on these excursions of the loop - soup in @xmath0 . as we shall see",
    ", this takes a nice `` markovian form '' in two special cases :    * when one considers the loops to be oriented , and the intensity of the loop - soup to be the one that relates it to the partition function of uniform spanning trees ie . to the number of spanning trees ( and to wilson s algorithm @xcite to generate them uniformly at random ,",
    "see e.g. @xcite ) . * in the case where the chain is reversible , if one considers the loops to be unoriented , and chooses the intensity to be the one that relates the loop - soup to the gaussian free field ( for instance via their partition functions  and in fact the occupation time of a continuous - time version of the loop - soup then corresponds exactly to the square of the gff , see @xcite ) .    in those two cases , the only relevant information in order to complete the excursions in @xmath0 into loops",
    "is the family of all endpoints of the excursions on @xmath1 , and not how these endpoints are connected by the excursions within @xmath0 ( nor which excursion end - point is connected to which other by an excursion ) . in other words , the trace of the discrete loop - soup inside @xmath0 and outside of @xmath0 are conditionally independent given their trace on @xmath1 ( more precisely , given their trace on the edges between @xmath0 and the complement of @xmath0 ) .",
    "let us illustrate another instance of the spatial markov property in an impressionistic and heuristic way via the following figures .",
    "we consider a loop - soup of unoriented loops in the inside of the rectangle , of well - chosen intensity ( related to the partition function of the gff ) . in this loop - soup ,",
    "only finitely many loops do touch the two circles , and in each such loop , there are an even number of `` crossings '' from one circle to the other .",
    "the statement in the caption of figure [ f2 ] is the type of result that we will derive .",
    "to conclude this introduction , let us briefly mention that of the motivations for the present work is to explore the relation between the natural `` markovian '' structures emerging from the loop - soups with the theory of local sets for the discrete and continuous gff , as defined by schramm and sheffield in @xcite .",
    "in this section , we recall standard facts about markov loops and loup - soups , make some elementary comments about the orientation / non - orientation of loops , and we define the natural measures on markov bridges that we will need .",
    "let us consider a discrete oriented graph @xmath2 , where each vertex @xmath3 has a finite number @xmath4 of outgoing edges , so that it is possible to define simple random walk on @xmath2 ( @xmath4 is however not necessarily the same for all @xmath3 ) .",
    "note that there could be `` several '' parallel edges from a vertex @xmath3 to a vertex @xmath5 .",
    "also , as opposed to the unoriented case , the could be an edge from @xmath3 to @xmath5 but no edge from @xmath5 to @xmath3 .",
    "we say that @xmath6 for @xmath7 is a rooted loop with @xmath8 steps in @xmath2 if @xmath9 are sites of the graph , if @xmath10 and if for all @xmath11 , @xmath12 denotes an edge from @xmath13 to @xmath14 in the graph .",
    "let us notice that in the case of parallel edges in the graph , the information about which oriented edges were used are part of the information contained in the loop .",
    "we can note that the probability @xmath15 that a random walk starting from @xmath16 follows exactly this loop during its first @xmath17 steps is exactly @xmath18 .",
    "we define the measure @xmath19 on rooted loops by @xmath20 .",
    "note that this is not a probability measure ( a loop @xmath21 might for instance contain another loop as its first steps if it visits @xmath16 several times before time @xmath17 ; furthermore , we sum over all possible starting points @xmath16 in the graph ) .",
    "the quantity @xmath22 remains unchanged if one changes the root of the loop ( if one considers the loop @xmath23 instead of @xmath21 ) , which leads naturally to the definition of _ an unrooted loop @xmath24 _ as an equivalence class of rooted loops , where two loops are equivalent as soon as they are obtained from one another by rerooting .",
    "the measure @xmath25 on unrooted oriented loops is then the image of the measure @xmath19 under the mapping that maps each rooted oriented loop to its equivalence class of unrooted loops .",
    "this is the loop - measure that has been used and studied extensively in recent years , in connection with loop - erased random walks , gaussian free fields , dynkin s isomorphism theorems and in the continuous two - dimensional ( brownian ) setting , with conformal loop ensembles and sle curves , see e.g. @xcite and the references therein ) .    in many cases ,",
    "the number of different rooted loops in the same equivalence class of unrooted loops is the length @xmath26 of the loop ( one possible root per step on the loop ) .",
    "however , when a loop @xmath21 consist exactly of the concatenation of @xmath27 copies of exactly the same loop , ie , @xmath28 and @xmath21 is exactly the concatenation of @xmath29 copies of @xmath30 ( and @xmath31 is the maximal such number  note that this number is also invariant under rerooting of @xmath21 so that we can view it as a function of @xmath24 ) , then the number of rooted loops that give rise to the same unrooted loop as @xmath21 is @xmath32 .",
    "hence , the general formula for @xmath25 is @xmath33 , when @xmath21 is any loop in the equivalence class @xmath24 .    in the sequel",
    ", we will refer to loops @xmath34 ( or their equivalence class ) such that @xmath35 as single loops , and we say that the loop @xmath36 defined as the concatenation of @xmath37 copies of @xmath21 ie . as @xmath38 with @xmath39 is its @xmath37-fold multiple",
    ".      in the previous subsection , the graph was oriented , and all our loops ( rooted and unrooted ) were oriented .",
    "let us now consider an unoriented graph , where each vertex @xmath3 has a finite number @xmath4 of outgoing edges ( here a single edge from @xmath3 to @xmath3 would be counted twice , and we also allow parallel edges between two sites @xmath3 and @xmath5 ) .",
    "then the previous quantity @xmath15 remains unchanged when one changes the orientation of the loop ; indeed , if one defines the time - reversal @xmath40 , then @xmath41 .",
    "we now define an unrooted unoriented loop as the equivalence class of oriented rooted loops , where two such loops are said to be equivalent as soon as they are obtained from one another by rerooting and possibly by time - reversal . or alternatively , we say that an unrooted unoriented loop is the equivalence class of unrooted oriented loops , modulo time - reversal .",
    "we then define the measure @xmath42 on unrooted unoriented loops to be the image of @xmath43 under the mapping that maps each rooted oriented loop onto to its equivalence class of unrooted and unoriented loops .",
    "the measure @xmath42 is of course just the unoriented projection of @xmath44 .    when the time reversal @xmath45 of a rooted oriented loop @xmath21 is not in the same unrooted oriented class of loops as @xmath21",
    ", then there will be twice more rooted oriented loops in the same class @xmath46 of unoriented unrooted loops of @xmath21 than in its class @xmath47 of oriented unrooted loops , so that @xmath48 .",
    "it however can happen that @xmath21 and @xmath45 define the same oriented unrooted loop @xmath24 ( for instance when the loop @xmath21 is the concatenation of a loop with its time - reversal ) . in that case , @xmath49 .",
    "we define @xmath50 or @xmath51 depending on whether @xmath52 or not , so that @xmath53 for all @xmath54 .",
    "all the previous definitions have also straightforward counterparts and generalizations for general markov processes ( not necessarily random walks )  the processes would need to be reversible for the unoriented loops  , and in continuous time and/or in continuous space .",
    "note that as soon as one deals with continuous time , the multiplicity issues ( raised by the fact that @xmath29 is not constant ) do not exist .",
    "one fundamental example is of course the brownian loop measure that gives rise to the loop - soup , as introduced in @xcite .",
    "other examples include the brownian loops on cables systems associated to discrete graphs , as studied in @xcite .",
    "since our purpose here is to give an elementary presentation of the resampling property of loop - soups , we have opted in the present paper to state and explain things in the most transparent settings ( random walk loops on regular graphs , where all points in @xmath2 have the same number @xmath55 of outgoing edges  which we will from now on assume  , and brownian loops ) .",
    "the generalization of the proofs to continuous - time and discrete space markov processes do not require any new idea .      for a given graph",
    ", one can define simple natural random objects out of the measures on loops . for each @xmath56",
    ", one can define a poisson point process of loops , with intensity given by @xmath57 times the measure @xmath25 on loops .",
    "this is the loop - soup , as introduced in the brownian setting in @xcite and studied more recently in the discrete setting in @xcite .",
    "it is also the gas of loops that was already used in @xcite .",
    "of course , when one samples a soup of ( unrooted ) oriented loops according to the loop measure @xmath58 , and one forgets about the orientation of the loops , one gets a soup of unrooted unoriented loops with intensity @xmath59 , and conversely , one can recover the former by choosing at random the orientation of each loop . in order to avoid confusions",
    ", we will use the letters @xmath57 to denote the intensity of soups of oriented loops ( i.e. with intensity measure @xmath58 ) and @xmath60 to denote the intensity of soups of unoriented loops ( i.e. with intensity measure @xmath61 ) . the natural relation between @xmath60 and @xmath57",
    "is then @xmath62 .",
    "we will not recall all the properties of these loop - soups , but we would like to stress the following points :    * the soup of oriented loops with intensity @xmath63 is very closely related to uniform spanning trees .",
    "in particular , the loops in such a loop - soups correspond exactly to the family of loops that have been erased when performing wilson s algorithm to sample a uniform spanning tree in @xmath2 . and in this context , it is somewhat more natural to consider oriented loops .",
    "* the soup of unoriented loops with intensity @xmath64 is very closely related to the gaussian free field in @xmath2 and its square . in this context , because one looks only at the cumulated occupation times of the loops , it is in fact somewhat more natural to consider unoriented loops ( as the orientation is not needed to define the occupation time measure ) .    with this notation",
    ", the ust is related to @xmath65 and the gff to @xmath64 , and more generally , in two dimensions , in the conformal field theory language , the value of @xmath60 corresponds to the absolute value of the central charge of the corresponding models .",
    "suppose now that @xmath66 are @xmath37 different oriented unrooted loops .",
    "let @xmath67 denote the respective number of occurrences of these loops in an unrooted loop - soup with intensity @xmath58 .",
    "these are @xmath37 independent poisson random variables with respective means @xmath68 , so that @xmath69 in the special case where @xmath63 , the @xmath70 terms disappear , and we get @xmath71    similarly , if we are considering instead a loop - soup of unoriented loops with intensity @xmath42 ( ie . for @xmath64 ) , the very same formula holds , i.e. if @xmath72 are @xmath37 different unoriented loops , and if @xmath73 denote the respective number of occurrences of these loops in a soup of unrooted loops with intensity @xmath42 , then @xmath74      recall that in order to slightly simplify notations and some of our considerations , we are from now going to assume that ( both in the oriented and in the unoriented cases ) , the graph @xmath2 will be such that each site has the same number @xmath55 of outgoing edges . note that this is not really a restriction , because it is for instance always possible starting from an unoriented graph @xmath2 where each site @xmath3 has @xmath4 outgoing edges , with @xmath75 , to add @xmath76 stationary edges from @xmath3 to @xmath3 to the graph , without changing the behavior of the random walks ( and this leads to the natural way to extend the results to the case of graphs with non - constant degree ) .",
    "let us first suppose that @xmath2 is an oriented graph .",
    "consider now a subgraph @xmath77 and two points @xmath3 and @xmath5 in @xmath78 .",
    "we say that a bridge @xmath79 from @xmath3 to @xmath5 in @xmath78 is a finite nearest - neighbour path ( keeping track of the oriented edges used ) in @xmath78 starting at @xmath3 and finishing at @xmath5 .",
    "we call @xmath80 the length ( number of jumps ) of @xmath79 . a bridge from @xmath3 to @xmath3",
    "is allowed to have a zero length .",
    "suppose now that the green s function @xmath81 is positive and finite .",
    "recall that this is the mean number of visits at @xmath5 before exiting @xmath78 , by a random walk starting at @xmath3 .",
    "in other words , it is the sum over all bridges from @xmath3 to @xmath5 in @xmath78 of @xmath82 . we can therefore define a probability measure on bridges from @xmath3 to @xmath5 in @xmath78 , that assigns a probability @xmath83 to each bridge @xmath79 .",
    "suppose now that we are given @xmath84 points @xmath85 and @xmath84 points @xmath86 in @xmath78 .",
    "we say that a the family of paths @xmath87 is an ordered bridge in @xmath78 from @xmath88 onto @xmath89 if each @xmath90 is a bridge from @xmath91 to @xmath92 in @xmath78 .",
    "we also define @xmath93 and when this quantity is not equal to zero nor infinite , we define the probability measure on ordered bridges from @xmath94 to @xmath95 in @xmath78 to be obtained by taking @xmath84 independent bridges from @xmath91 to @xmath92 respectively .",
    "an unordered bridge from @xmath94 to @xmath95 is defined to be the knowledge of a permutation @xmath96 from @xmath97 and of an ordered bridge from @xmath94 to @xmath98 .",
    "we now define define a probability measure @xmath99 on unordered bridges from @xmath94 to @xmath95 in @xmath78 as follows :    1 .",
    "first sample a permutation @xmath100 so that the probability of @xmath101 is proportional to @xmath102 .",
    "2 .   then , conditionally on @xmath100 , sample the ordered bridge from @xmath94 to @xmath103 according to the probability measure on ordered bridges in @xmath78 described above .    for this to make sense",
    ", we need that for at least one @xmath96 , @xmath104 .",
    "this procedure basically samples an unordered bridge from @xmath94 to @xmath95 in such a way that the probability of a given unordered bridge is proportional to @xmath105 , where @xmath106 denote the sum of the length of the @xmath84 bridges that form the generalized bridge .",
    "mind that in the present setting , when @xmath107 say , we do count the same collection of @xmath84 bridges ( corresponding to interchanging @xmath108 and @xmath109 ) twice in our partition function , because they correspond to different permutations .",
    "let us now suppose that the graph @xmath2 is not oriented . in the previous definition ,",
    "each bridge has an implicit orientation ( from @xmath3 to @xmath5 ) .",
    "on the other hand , the image under time - reversal ( i.e. consider @xmath110 ) of the bridge probability from @xmath3 to @xmath5 in @xmath78 is exactly the bridge probability from @xmath5 to @xmath3 in @xmath78 ( note that we use here the fact that @xmath3 and @xmath5 have the same number of outgoing edges @xmath55 ) .",
    "one can therefore define the probability measure on unoriented bridges in @xmath78 joining @xmath3 and @xmath5 to be the law obtained by considering @xmath111 and then forgetting about the time - orientation .",
    "suppose now that @xmath112 are @xmath113 points in @xmath78 .",
    "an unoriented @xmath114-bridge is the knowledge of a pairing @xmath115 of @xmath116 ( this is a permutation that contains only cycles of length exactly @xmath117  and we say that @xmath118 and @xmath119 are paired  we will denote the @xmath84 pairs of @xmath115 by @xmath120 using some lexicographic rule ) , and of @xmath84 unoriented bridges joining the @xmath84 pairs @xmath121 for @xmath122 .    for each @xmath114 , we then define the measure @xmath123 on unoriented unordered @xmath114-bridges as follows :    1 .",
    "we first sample a pairing @xmath124 in such a way that the probability of a given pairing @xmath115 is proportional to @xmath125 .",
    "2 .   when @xmath126 , we then sample an @xmath84 independent ( unoriented ) bridges in @xmath78 joining the two points of each of the @xmath84 pairs @xmath121 .    again",
    ", this only makes sense if for at least one pairing @xmath115 , @xmath127 is positive .",
    "then , the definition just means that we sample a @xmath114-bridge in such a way that the probability of a given @xmath114-bridge is just proportional to @xmath105 where @xmath106 denote the sum of the length of the @xmath84 bridges that form this @xmath114-bridge .",
    "these definitions of bridges can be trivially extended to the brownian settings ( both in @xmath128-dimensional space as well as on cable systems ) , provided that no two @xmath129 s coincide ( in the unoriented bridges ) and that no @xmath130 is equal to an @xmath92 ( for the oriented bridges ) so that the green s functions involved are all finite .",
    "the only difference is that the distribution of an individual bridge from @xmath3 to @xmath5 is done in two steps :    1 .",
    "first , sample the time - length @xmath131 of the brownian bridge according to the probability measure @xmath132 , where @xmath133 is the density at @xmath5 of the law of a brownian motion at time @xmath115 , starting from @xmath3 and killed upon exiting @xmath78 .",
    "2 .   then , conditionally on @xmath131 , sample a usual brownian bridge from @xmath3 to @xmath5 and time - length @xmath131 , conditioned to stay in @xmath78 .",
    "we now describe various instances of the partial resampling properties of loop - soups , and discuss some consequences .",
    "let us suppose that @xmath2 is an oriented graph of degree @xmath55 as before , and that @xmath77 is a subgraph of @xmath2 where the green s function is finite .",
    "we are going to describe the resampling property of the soup of oriented loops with intensity @xmath63 .",
    "suppose that @xmath134 and @xmath135 are two disjoint finite set of vertices in our graph .",
    "when one considers a loop - soup in @xmath78 , then the number of loops in the loop - soup that do intersect both @xmath134 and @xmath135 is a poisson random variable @xmath136 with finite mean equal to the @xmath25-mass of the set of loops that intersect both @xmath134 and @xmath135 .",
    "we denote the family of @xmath137 loops that intersect both @xmath134 and @xmath135 by @xmath138 ( the information in @xmath138 includes how many occurrences of any given oriented unrooted loop that intersects @xmath134 and @xmath135 there are ) .",
    "we will write @xmath139 , where the chosen order of the loops in the family follows some lexicographic ( deterministic ) rule , so that the information provided by @xmath140 and @xmath141 are identical .",
    "when @xmath47 is an unrooted loop that intersects @xmath134 and @xmath135 , we can consider the finitely many portions of @xmath47 that are of the type @xmath142 with @xmath143 , @xmath144 and at least one of the @xmath145 is in @xmath134 .",
    "in other words , these are the excursions of @xmath47 away from @xmath135 that do reach @xmath134 .",
    "we allow @xmath146 , or the excursion to be the entire loop ( which happens if @xmath47 visits @xmath135 only once ) and it can also happen that the same excursion occurs several times in the same loop .    when we sample @xmath147 , we call @xmath148 the collection of all excursions of its loops",
    ". we can again decide to order them in some lexicographic predetermined deterministic way , so that we can write @xmath149 ( again , it is important that if a given piece appears several times in the loop - soup , then it appears several times in this list as well ) . note that @xmath150 because each loop that intersects @xmath134 and @xmath135 contains at least one such excursion .",
    "the pieces @xmath151 might be part of @xmath152 different loops ( in which case @xmath153 ) , but they could also be all parts of the same loop ( in which case @xmath154 ) . of course , the probability that @xmath155 is also positive .",
    "observe that one intuitive way to discover all these excursions is in fact to explore all the loops `` starting '' from their intersection points with @xmath134 , in both the positive time - direction and the negative time - direction , until reaching @xmath135 in both directions .",
    "each of the pieces @xmath156 are naturally oriented as parts of oriented loops , and we can define their respective starting points @xmath157 and endpoints @xmath158 ( note that all these points are on @xmath135 ) .",
    "the missing parts of the loops that the @xmath148 s are part of will therefore be bridges in the complement of @xmath134 , that join each of the @xmath158 s to a @xmath159 for a permutation @xmath100 ie .",
    "the missing part will be an unordered bridge @xmath160 from the vector @xmath161 to the vector @xmath162 in @xmath163 .",
    "now , the resampling result in this case goes as follows :    [ p1 ] the conditional distribution of @xmath160 given @xmath148 is exactly the unordered bridge measure @xmath164 .",
    "note that this conditional distribution is fully described by the vectors @xmath165 and @xmath166 ( ie .",
    "it depends on @xmath148 just as a function of @xmath165 and @xmath166 ) , which is one of the main features of this result .",
    "in other words , conditionally on @xmath165 and @xmath166 , @xmath148 and @xmath160 are independent .",
    "in particular , the number of actual loops that are being created by @xmath160 when one concatenates it with @xmath148 does not intervene in the conditional distribution , which is a specific feature of this @xmath63 case .",
    "let us comment on the case where @xmath167 : if one then conditions on the number of jumps of the loop - soup on each edges from a point in @xmath134 to a point of @xmath135 ( one then gets a collection @xmath168 of jumps from @xmath169 to @xmath170 ) , and on the number of jumps of the loop - soup on each edge from a point of @xmath135 to a point of @xmath134 ( one then gets a collection @xmath171 of jumps from @xmath172 to @xmath173 ) , then the conditional distribution of the missing pieces in @xmath135 and in @xmath134 are independent , and there are respectively the unordered bridge measure in @xmath135 from @xmath165 to @xmath166 ( this corresponds to @xmath160 ) , and the unordered bridge measure from @xmath174 to @xmath175 in @xmath134 ( this corresponds to @xmath148 without the first and last jumps of each excursion ) .",
    "this can be interpreted as a spatial markov property of the occupation field on oriented edges ( the random function that assigns to each oriented edge the total number of jumps of the soup along this edge ) of the @xmath63 soup of oriented loops .",
    "we will discuss this again at the end of this section .",
    "in the same spirit , we can in fact `` symmetrize '' also proposition [ p1 ] also when @xmath135 is a subset of the complement of @xmath134 .",
    "let us then define the collection of crossings @xmath176 to be the parts of the loops in the loop - soup of the type @xmath177 with @xmath178 , @xmath179 and @xmath180 .",
    "we also define @xmath181 similarly , and note that there are as many crossings from @xmath134 to @xmath135 as there are crossings from @xmath135 to @xmath134 .",
    "let @xmath165 ( resp .",
    "@xmath175 ) denote the vector of endpoints of @xmath176 ( resp .",
    "@xmath181 ) and @xmath166 ( resp .",
    "@xmath174 ) the vector of starting points of @xmath181 ( resp .",
    "@xmath176 ) .",
    "then , we can note that @xmath165 and @xmath166 are exactly the same as the ones defined in proposition [ p1 ] , while @xmath175 and @xmath174 correspond to those that one obtains when interchanging @xmath134 and @xmath135 .",
    "furthermore , @xmath176 and @xmath181 are fully determined by @xmath148 ( or alternatively by the symmetric family @xmath182 of excursions outside of @xmath134 that do reach @xmath135 ) .",
    "it follows readily from proposition [ p1 ] that :    [ p1bis ] conditionally on @xmath176 and on @xmath181 , the missing parts of the loops that they are part of ( these are the loops of the @xmath63 soup of oriented loops that intersect both @xmath134 and @xmath135 ) are described by two independent unordered bridges with conditional distributions @xmath164 and @xmath183 .",
    "note that the other loops in the loop - soup ( i.e. the loops that either do not intersect at least one of the two sets @xmath134 or @xmath135 ) are just described by a loop - soup in the complement of @xmath134 and a loop - soup in the complement of @xmath135 , that are coupled to share exactly the same loops that stay in @xmath184 .",
    "let us now prove proposition [ p1 ] .",
    "let us consider a family @xmath185 of @xmath84 excursions , such that @xmath186 and such that the @xmath84 excursions @xmath187 of @xmath185 are all different",
    ". then if @xmath188 and @xmath189 , all the loops in @xmath190 are simple , and they do occur necessarily exactly once ( and not more ) .",
    "hence , for such an @xmath190 , the probability that @xmath191 is proportional to @xmath192 where @xmath193 is the sum of the lengths of the loops in @xmath194 ( and the proportionality constant does not depend on @xmath190 ) .    on the other hand ,",
    "if @xmath94 and @xmath95 are the vector of end - points of @xmath185 , the @xmath195-probability to sample a unordered bridge that gives rise exactly to @xmath190 when concatenating it to @xmath185 is proportional to @xmath196 ( where @xmath197 is the total length of the generalized bridge ) , because there is just one permutation per bridge that works .",
    "it therefore follows immediately that conditionally on @xmath198 , the distribution of the missing bridges is indeed @xmath199 in @xmath163 .    instead of treating directly the case of multiple occurrences of the same excursions in @xmath148",
    ", we will use the following trick ( a similar idea can be used to show the fact that the loops erased during wilson algorithm do correspond exactly to an oriented loop - soup , see for instance @xcite ) .",
    "we choose a very large integer @xmath200 ( that is going to tend to infinity ) , and we decide to replace the graph @xmath2 by the graph @xmath201 , which is obtained by keeping the same set of vertices as @xmath2 , but where each edge of @xmath2 is replaced by @xmath200 copies of itself . in this way , each site has now @xmath202 outgoing edges instead of @xmath55 .",
    "there is of course a straightforward relation between random walks , loops and bridges on @xmath201 and on @xmath2 . for instance , a loop - soup ( resp .",
    "bridge , resp .",
    "excursion ) on @xmath201 is directly projected on a loop - soup ( resp .",
    "bridge , resp .",
    "excursion ) on @xmath2 .",
    "let us couple loop - soups with intensity @xmath63 in all of the @xmath201 s on the same probability space , in such a way that the projections of the loop - soups in @xmath201 onto @xmath2 ( in the sense described above ) are the same for all @xmath200 s . we fix also @xmath134 , @xmath135 , and define ( with obvious notation ) , @xmath203 , @xmath204 , @xmath205 etc .",
    "note that the vectors of extremal points @xmath165 and @xmath166 are then the same for all @xmath206 s .",
    "we can also note that the probability that some edge is used more than once in the loop - soup does tend to @xmath207 as @xmath208 .",
    "the probability that all excursions in @xmath206 are different therefore tends to @xmath209 as @xmath208 .    but conditionally on the fact that all excursions in @xmath206 are different ( applying our previous result to @xmath201 ) , we know that the conditional distribution of @xmath210 given @xmath206 is the bridge probability measure from @xmath165 to @xmath166 in @xmath211 .",
    "projecting this onto @xmath2 , we get that the conditional distribution of @xmath160 given @xmath206 ( on the event that in @xmath206 , no two excursions are the same ) is the unordered bridge measure @xmath212 in @xmath163 .",
    "if @xmath213 is the event that no two excursions of @xmath206 appear twice , we therefore get that , conditionally on @xmath214 and @xmath213 , the conditional distribution of @xmath160 is the unordered bridge measure @xmath199 in @xmath163 .",
    "we now just let @xmath208 , which concludes the proof of the proposition .",
    "let us now come back to the setting where the graph @xmath2 is unoriented .",
    "when one considers a soup of unoriented loops with intensity @xmath42 ( recall that this corresponds to @xmath64 or @xmath215 ie . to a soup of oriented loops with intensity @xmath216 where we forget the orientation of each loop ) .",
    "we denote the collection of unoriented loops that intersect both @xmath134 and @xmath135 by @xmath217 , the corresponding collection of ( unoriented ) excursions by @xmath218 and the endpoints of these @xmath152 excursions by @xmath219 .",
    "the missing parts of the ( unoriented ) loops are unoriented paths that join each @xmath220 to exactly one other @xmath221 , so that @xmath160 is an unordered @xmath222-bridge in @xmath163 .    note again that it is intuitively possible to explore the excursions @xmath223 `` starting '' from their intersections with @xmath134 in both directions , until hitting @xmath135 ( and in this way , one did yet discover the missing parts @xmath160 ) .",
    "[ p2 ] the conditional distribution of @xmath160 given @xmath148 is exactly the unordered unoriented bridge measure @xmath224 in @xmath163 .         just as in the oriented case",
    ", we stress that an important feature in this statement is that this conditional distribution is a measurable function of the vector @xmath222 ( the other information on the excursions are not needed ) .",
    "we will further comment on this in the next subsection .",
    "we will follow the same idea as in the proof of the oriented case . as in the unoriented case ,",
    "when the @xmath84 pieces @xmath225 of @xmath185 are all different , the statement is almost immediate ( for each good ordered bridge , only one pairing works in order to complete @xmath185 into @xmath190 , and the probability to complete these @xmath84 pieces into @xmath190 is therefore proportional to @xmath105 where @xmath106 is the difference between the total number of jumps in the loop - configuration and in @xmath185 ) .",
    "we then use the same trick with copying each edge a large number of times . the very same argument the works ,",
    "almost word for word .      the particular case where @xmath135 is the complement of @xmath134 is also of interest for the soup of unoriented loops .",
    "let us for instance describe how things work for the occupation times of loop - soups ( which is the main focus of the papers of le jan @xcite ) .",
    "if one then conditions on the numbers of jumps of the loop - soup on all edges between a point in @xmath134 and a point of @xmath135 ( in either direction  the loops being unoriented there is anyway no direction ) , then the conditional distribution of the parts @xmath160 in @xmath135 of the loops that intersect both @xmath134 and @xmath135 is described by proposition [ p2 ] and it is a unordered unoriented bridge in @xmath135 ( and it is in fact fully described by the knowledge of the number of jumps along the edges between @xmath134 and @xmath135 , ie .",
    "this conditional distribution is a function of these number jumps of the edges between @xmath134 and @xmath135 ) .",
    "but , the situation is symmetric and we can interchange the roles of @xmath134 and @xmath135 ; we therefore conclude that given @xmath160 and the numbers of jumps along the edges between @xmath134 and @xmath135 , the conditional distribution of @xmath182 defined to be the collection @xmath148 where one has removed the two extremal jumps of each @xmath156 ( these are the jumps between @xmath134 and @xmath135 ) , is that of an unordered unoriented bridge in @xmath134 ( and the law of this bridge is also fully described by the number of jumps between @xmath134 and @xmath135 ) .    in other words ,",
    "when one conditions on these number of jumps along the edges between @xmath134 and @xmath135 , we can enumerate these jumps ( using some deterministic lexicographic rule ) by @xmath226 where @xmath227 and @xmath228 . then , the conditional distribution of @xmath182 and @xmath160 are conditionally independent unordered bridges , respectively following the unordered bridge measures @xmath229 and @xmath230 .",
    "in particular , when adding on top of this the loop - soups in @xmath134 and the loop - soups in @xmath135 , it follows that conditionally on the occupation times ( i.e. on the number of jumps @xmath231 across each edge ) on the edges between @xmath134 and @xmath135 , the occupation times on sites and edges in @xmath134 is independent of the occupation times on sites and edges in @xmath135 .",
    "we can rephrase this property in the following sentence : the occupation time field on edges of the soup of unoriented loops for @xmath64 does satisfy the spatial markov property .",
    "we can note that if @xmath0 is a non - negative function of the occupation time field on the edges of the form @xmath232 , such that the expectation of @xmath0 ( for the @xmath64 loop - soup ) is equal to one , then if we define the new probability measure @xmath233 on occupation times on edges by @xmath234 , then the spatial markov property also holds for @xmath233 .",
    "this can be used to represent a modification of the markov chain ( ie .",
    "different walks with non - uniform jump probabilities ) .",
    "if we consider an unoriented graph , but that we interpret as an oriented graph ( each unoriented edge defines an oriented edge in each direction ) , on which we define an @xmath63 soup of oriented loops , then we can also reformulate the results of subsection [ ss2.1 ] in a similar way .",
    "more precisely , for each edge , we can define the total number of jumps @xmath235 by the soup in one direction of @xmath236 , and @xmath237 , the number of jumps in the opposite direction . then",
    ", if we define @xmath238 , this two - component occupation time field on edges of the @xmath63 soup of oriented loops satisfies the spatial markov property in the same sense as above .",
    "let us now come back to the study of the loops themselves , and not just of the cumulated occupation time of the soup .",
    "as in the oriented case , we can also ( when @xmath135 is a subset of @xmath134 ) rephrase proposition [ p2 ] in a more symmetric way , involving the crossings between @xmath134 and @xmath135 .",
    "we define @xmath239 the set of ( unoriented ) parts of loops in the @xmath64 loop - soup that join a point of @xmath134 to a point of @xmath135 and otherwise stay in the complement of @xmath240 , and we denote by @xmath222 the vector of endpoints of these crossings in @xmath135 , and by @xmath241 the set of endpoints in @xmath134 .",
    "then :    [ p3bis ] conditionally on @xmath239 , the missing parts of the unoriented loops that these crossings are part of ( these are the loops in the loop - soup that intersect both @xmath134 and @xmath135 ) are described by two independent unordered unoriented bridges with respective conditional distributions @xmath242 and @xmath229 .    figure [ bexc ] that illustrates the corresponding result in the brownian case , can also be used to illustrate this result .",
    "it is also easy to generalize proposition [ p3bis ] and proposition [ p1bis ] to more than two sets @xmath134 and @xmath135 ( and have instead @xmath17 disjoint sets @xmath243 ) .",
    "for instance , in the unoriented case , one then conditions on the set @xmath244 of all crossings from any @xmath245 to any other @xmath246 that also stay in the complement of all the other @xmath247 s .",
    "these crossings define @xmath17 vectors @xmath248 ( where @xmath249 is a list of the even number of endpoints on @xmath246 of the aforementioned crossings ) .",
    "conditionally on @xmath244 , the missing parts of the loops ( that are the loops in the loop - soup that touch at least two different @xmath246 s ) are described by @xmath17 conditionally independent unordered unoriented bridges with respective distributions @xmath250 ( where @xmath251 ) for @xmath252 .",
    "such decompositions of the loops in the soup that intersect disjoint compact sets into crossings + conditionally independent unordered bridges , can be immediately transcribed to the case of brownian loops on the cable system associated to this graph as studied in @xcite ; we leave this as a simple exercise to the reader .",
    "this is all of course closely related to the markov property of the gaussian free field , as well as to dynkin s isomorphism theorem @xcite via the relation between the square of the gff and the loop - soup ( see e.g .. @xcite and the references therein for background ) .    with such markovian - type properties in hand ,",
    "a natural next step is to define random sets that play the role of stopping times for one - dimensional markov processes . in the setting of the discrete gff ,",
    "these are the local sets as defined in @xcite , and that turned out to be very useful concepts .",
    "just as for one - dimensional stopping times , there are several possible ways to define them , depending on what precise filtration on considers . in the present case",
    "( we do here describe the definitions in the unoriented loop - soup for @xmath64 , but the oriented case would be almost identical ) , one can for instance say that :    * a random set of points @xmath253 is a stopping set for the occupation time field filtration , if for any @xmath134 , the event @xmath254 is measurable with respect to the occupation time field on all edges adjacent to @xmath134 . * a random set of points @xmath253 is a stopping set for the loop - soup filtration , if for any @xmath134 , the event @xmath254 is measurable with respect to the trace of the loop - soup on all edges adjacent to @xmath134 ( i.e. it is measurable with respect to the set of loops that are fully contained in @xmath134 and the set of excursions @xmath148 defined above , when @xmath135 is the complement of @xmath134 . * a random set of points @xmath253 is a stopping set for the loop - soup , if for any @xmath134 such that @xmath255 , conditionally on the event @xmath256 , the distribution of the loop - soup outside of @xmath134 consists of the union of an independent loop - soup in the complement @xmath135 of @xmath134 and of a set of bridges in @xmath135 , with law described as above via the end - points of the excursions @xmath148 in @xmath134 .",
    "clearly , the first definition implies the second one , which implies the third one by proposition [ p2 ] ( the third property for the first two definitions can be viewed as a `` strong markov property '' of these fields ) , but the converse is not true ( the last definition allows the use of `` external randomness '' in the definition of @xmath253 ( while the second does not ) , and the second one allows features of individual loop ( while the first does not ) .      the previous results have almost identical counterparts in the setting of oriented brownian loop - soups with intensity @xmath63 and unoriented brownian loop - soups with intensity @xmath64 .",
    "suppose that @xmath78 is an open subset of @xmath257 such that the ( dirichlet ) green s function in @xmath78 is finite ( away from the diagonal ) .",
    "suppose that @xmath134 and @xmath135 are two disjoint compact sets in @xmath78 , that are both non - polar for brownian motion ( i.e. brownian motion started away from these sets has a non - zero probability to hit them ) .",
    "then , we can again define :    1 .   the law of unordered oriented brownian bridges in @xmath163 from a finite family @xmath258 of points to another such family @xmath259 , and the law of unordered unoriented @xmath114-brownian bridges in @xmath163 from a finite family of points @xmath260 to itself",
    "( in the latter case , points of @xmath114 are paired , like in the random walk case ) .",
    "this works as long as all green s functions involved are finite ( which is the case as soon as all @xmath261 for all @xmath262 , and that @xmath263 for all @xmath264 ) .",
    "2 .   the set @xmath148 of @xmath152 oriented ( resp .",
    "unoriented ) excursions of the loops in an oriented ( resp .",
    "unoriented ) loop - soup with intensity @xmath63 ( resp .",
    "@xmath64 ) away from @xmath135 , that reach @xmath134 . in the ordered case ,",
    "we call their endpoints vector @xmath161 and their starting point vector @xmath166 , and in the unoriented case , we call @xmath265 the extremity vector .    then , the brownian counterparts of proposition [ p1 ] and of proposition [ p2 ] go as follows :    - for the soup of oriented brownian loops with @xmath63 : conditionally on @xmath148 , the missing pieces of the loops ( that the pieces @xmath148 are part of ) are distributed like an unordered brownian bridge from @xmath165 to @xmath166 in @xmath163 .",
    "- for the soup of unoriented brownian loops with @xmath64 : conditionally on @xmath148 , the missing pieces of the loops are distributed like an unordered unoriented @xmath222-brownian bridge in @xmath163 .    and as before , one can derive the more symmetric results : for instance , if @xmath134 and @xmath135 are two disjoint compact subsets of @xmath78 , we can define the crossings from @xmath134 to @xmath135 and vice - versa in the oriented case , and the crossings between @xmath134 and @xmath135 in the unoriented case .",
    "when one conditions on these crossings , one can then complete the picture with two conditionally independent unordered oriented bridges ( in the oriented case ) or by two conditionally independent unordered unoriented bridges ( in the unoriented case ) .",
    "we illustrate this result in figures [ bexc ] and [ bexc2 ] ( here we consider the oriented case , @xmath78 is the rectangle , @xmath134 is the small circle and @xmath135 the large circle ) . conditionally on the points ( and their status ",
    "square or circle depending on the orientation of the loops ) on the two circles , the three pictures in figure [ bexc2 ] are independent ( this is the oriented version of figure [ f2 ] ) .             in the context of two - dimensional continuous systems , clusters of loops in a loop - soup",
    "are interesting to study , as pointed out in @xcite ; it has been proved in @xcite that boundaries of such clusters for @xmath266 form conformal loop ensembles with parameter @xmath267 , where @xmath268 .",
    "the cle@xmath269 ( and the sle@xmath269 curves ) is also known ( see @xcite ) to be related quite directly to the gaussian free field .",
    "the role of the @xmath64-clusters of loops in the framework of cable - systems and in relation to the gaussian free field has been pointed out by lupu @xcite ( the clusters provides a direct link between the loop - soups and the gaussian free field itself , rather than just to its square ) .",
    "the present result sheds some light on the recently derived @xcite decomposition of critical @xmath270 loop - soup clusters ( for @xmath64 ) in terms of poisson point processes of brownian excursions ( we refer to @xcite for comments and questions ) .",
    "we devote now a short separate section on the case of discrete continuous - time loop - soups , that have been studied by le jan @xcite .",
    "as we shall see , in that setting , it is natural to consider the conditioned distribution of the loop - soup ( unoriented for @xmath64 ie .",
    "@xmath215 , or oriented for @xmath63 ) given the value of their local times on a given family of sites .",
    "some of the results are very closely related to dynkin s isomorphism theorem ( ie .",
    "it will be a pathwise version of a generalization of it ) .",
    "just as previously , we will describe the case of simple random walk on the graph where each point @xmath3 has the same number @xmath55 of outgoing edges , but the results can easily be generalized to the case of general markov chains .",
    "some of following considerations will be reminiscent of the arguments in @xcite ( sections 7 and 9 in particular ) . in the first subsections",
    ", we will focus on the case of unoriented loop - soups , and we will briefly indicate the similar type of results that one gets in the oriented case .    [ [ slight - reformulation - of - the - resampling - property - of - the - discrete - loop - soup ] ] slight reformulation of the resampling property of the discrete loop - soup ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~    we can start with the same setting as before , with the graphs @xmath271 and @xmath272 , the random walk on this graph killed upon hitting @xmath273 , and its green s function @xmath274 . in the previous sections , we chose for expository reasons ( as this was for instance the natural preparation for the brownian case ) to study loops in the loop - soup that visit two different sets of sites @xmath134 and @xmath135 .",
    "but in fact , the following setting is a little more natural and more general : consider now a family @xmath275 of edges of @xmath78 , and the graph @xmath276 obtained by removing these @xmath17 edges from @xmath78 .",
    "we can now sample an unoriented loop - soup ( for @xmath64 ) , and observe the numbers @xmath277 of jumps along thoses @xmath17 unoriented edges .",
    "we now want to know the conditional distribution of the entire loop - soup given this information .",
    "in particular , we would like to know how these @xmath278 jumps are hooked together into loops ( clearly , the loop - soup in @xmath276 consisting of the loops that use none of these @xmath17 edges is independent of @xmath279 ) .",
    "we can associate to @xmath280 the vector @xmath222 consisting of the @xmath281 endpoints of these jumps .",
    "once we label them , we can as before the collection @xmath160 of pairing and bridges that join them in the loop - soup .",
    "note that the bridge is allowed to contain no jump when one pairs two identical end - points .",
    "we can also define the unordered bridge measures in @xmath276 ( corresponding to paths that use no edge of @xmath282 ) as before .",
    "then , exactly as before , one can prove the following version of the resampling :      note that for some choices of family of edges @xmath284 , it can happen that an even number of endpoints of the discovered jumps are at a certain vertex where no neighboring edge is in @xmath276 . in that case",
    ", the bridge measure pairs these jumps at random and the corresponding bridge is anyway the empty bridge from @xmath3 to @xmath3 .",
    "a trivial example is of course the case where @xmath285 are all the edges of @xmath78 .",
    "then , the proposition just says that the conditional distribution of the loops given the occupation time measure is obtained by just pairing at random the incoming edges at each site .",
    "`` loops can exchange their hats uniformly at random at each site '' .",
    "this reformulation makes it clear that in the discrete time setting , the markov property of the occupation time field is really a markov property on the edges ( which is not surprising , given that the field is actually naturally defined on the edges ) .",
    "following le jan s approach @xcite , we now introduce the associated continuous - time markov chain , for each site @xmath3 , the chain stays an exponential waiting time of mean @xmath286 before jumping along one of the @xmath55 outgoing edges chosen at random ( for expository reasons , we describe this in the case where each edge has the same number of outgoing edges ) .",
    "note that we allowed stationary edges in the graph , so that the continuous - time markov chain can also `` jump '' along those ( and we can keep track of these jumps , even if they do not affect the occupation time at sites ) . as pointed out by le jan ,",
    "the loop - soup of such continuous - time loops for @xmath287 is particularly interesting , as its cumulated occupation time ( on sites ) is exactly the square of a gaussian free field on this graph ( here one may introduce one or more killing point , so that the loop - soup occupation - time is finite , and the free field with boundary value @xmath207 at this point is well - defined ) . in this",
    "setting , the loops of the discrete markov chain do correspond exactly to loops of the continuous - time chain , but the latter also contains some additional stationary loops , that just stay at one single point without jumping during their entire life - time .    when one considers a continuous - time loop and a finite set of vertices in the graph that it does visit , one can cut - out from the loops the time that it does spend at these points and obtain a finite sequence of excursions away from this set .",
    "this corresponds to the usual excursion theory of continuous - time markov processes ( an excursion from @xmath3 to @xmath5 will be a path that jumps out of @xmath3 at time @xmath207 and jumps into @xmath5 at the endpoint of the excursion ) .",
    "one can the introduce the natural excursion measure @xmath288 , which is the natural measure on set of unoriented excursions that go from @xmath3 to @xmath5 while avoiding all the points in @xmath289 ( it corresponds to the discrete excursion measure that puts a mass @xmath290 to such an excursion with @xmath17 jumps , and one then adds @xmath291 independent exponential waiting times at the @xmath292 points inside the excursions .",
    "one can view the continuous - time markov chain as the limit when @xmath293 of the discrete - time markov chain on a graph @xmath294 , where one has added to each site @xmath3 , @xmath295 stationary edges from @xmath3 to itself ( when one renormalizes time by @xmath296 , the geometric number of successive jumps along these added stationary edges from @xmath3 to @xmath3 before jumping on another edge , does converges to the exponential random variables )  this approach is for instance used in @xcite in order to derive the properties of the continuous - time chains and loop - soups from the properties of the discrete - time loop - soups .",
    "let us now consider a finite set of points @xmath297 in the graph , and for a given @xmath295 , we condition on the @xmath277 of jumps by the loop - soup along the stationary unoriented edges @xmath285 .",
    "more precisely @xmath298 will denote the total number of jumps in the loop - soup along the @xmath295 added stationary edges from @xmath3 to @xmath3 .",
    "note that because both end - points of a stationary edge are the same , these @xmath298 jumps correspond to @xmath299 jump - endpoints , that are all at @xmath300 . we can now apply proposition [ p5 ] to this case ; this describes the distribution of how to complete and hook up these @xmath278 jumps into unoriented loops in order to recover the loops in the loop - soup that they correspond to .",
    "one has to pair all these @xmath301 endpoints .",
    "mind that as @xmath295 gets large , the mass of the trivial excursion from @xmath300 to @xmath300 with zero life - time is always @xmath209 , while the mass of ( unoriented ) excursions with at least one jump along the `` non - added '' @xmath302 stationary edges neighboring these points from @xmath300 to some @xmath91 that stays away from @xmath303 during the entire positive lifetime ( if it is positive ) will be of order @xmath296 ( unless all neighbors of @xmath300 are in @xmath303 in which case this quantity is zero ) and that the set of excursions from @xmath300 to @xmath91 that visit at least one of the points of @xmath303 during its positive life - time is of the order of @xmath304 .",
    "it is a simple exercise that we safely leave to the reader to check that in the @xmath293 limit , the discrete markovian description becomes the following :    if we consider the continuous - time markov chain loop - soup and condition on the total occupation time @xmath305 at the @xmath17 points @xmath306 , then the unoriented excursions away from this set of points by the loop - soup will be distributed exactly like a poisson point process of excursions with intensity @xmath307 conditionned on the event that the number of excursions starting or ending at each of the @xmath17 points @xmath308 is even .    the particular case where the set of points @xmath309 is the whole vertex set is again of some interest : the conditional distribution of the number of unoriented jumps on the edges given the occupation time field on the vertices is a collection of independent poisson random variables with respective means @xmath310 , conditioned by the event that for all site @xmath3 , the total number of jumps on the incoming edges at @xmath3 is even .",
    "this is exactly the random current distribution associated with the ising model . for some further comments on this relation with random currents , the gff and ising , we refer to @xcite .",
    "it should be of course noted that this decomposition is closely related dynkin s isomorphism ( see @xcite and the references therein ) , except that one here conditions here on the value of the square of the gff instead of the value of the gff itself .",
    "the previous result implies ( when one only looks at occupation times and not at the loop - soup itself ) that conditionally on the value of the square of the gff at the set of points @xmath309 , the square of the value of the gff at the other points is the sum of the occupation times of the conditioned poisson point process of excursions with an independent squared gff in the remaining ( smaller ) domain .",
    "if one however conditions the gff at the @xmath17 sites to be all equal to the same value @xmath115 , then one can consider instead a graph where all these points are identified as a single point and note that when the gff on the new graph conditioned to have value @xmath115 at that point is distributed as the gff on the initial graph , conditioned to have value @xmath115 at each of the @xmath17 points .",
    "one can apply the previous statement to that new graph and note that the conditioning on the event that the number of excursions - extremities at each boundary site is even then disappears , because when there is just one such site , this number is anyway even ( each excursion from this point to itself has two endpoints ) .",
    "here it is however essential that the signs of all these values are the same ( because if one identifies them into a single point , then they will anyway correspond to the same value of the gff , not just to the same value of its square .    in summary , conditioning by the value of the square of the gff",
    "gives rise to the parity conditioning , but it is also possible to condition on the actual value of the gff and the parity conditioning becomes irrelevant when one looks at the occupation times only .",
    "note that dynkin s isomorphism then follows , because in the latter case , the conditional distribution of the square of the gff at the other points ( which is therefore the square of the gff in this smaller domain with boundary conditions given by these conditioned boundary values ) will be the sum of the contribution of the loops that only visit those points ( which is a squared gff in the remaining domain ) with the occupation time of the poisson point process of excursions , while the conditioned gff is a gff with some prescribed boundary conditions , that can be viewed as the sum of a gff in the complement of the set of marked points with the deterministic harmonic extension of these boundary values .",
    "one can follow almost word for word the same strategy to study the conditional distribution of oriented continuous - time loop - soups at @xmath311 given their cumulated local time at sites . in that case",
    ", the excursions will be oriented , and the conditional distribution of the excursions away from these points will be a poisson point process conditioned on the event that for each site , the number of incoming excursions is equal to the number of outgoing ones .    the particular case where the set of points is the whole vertex set is again interesting .",
    "the conditional distribution of the set of jumps will be independent poisson on each oriented edge , but conditioned on the fact that the number of incoming jumps at each site is going to its number of outgoing jumps .",
    "we leave all the details and further results to the interested reader",
    ".      * acknowledgements . * the support and hospitality of snf grant snf-155922 , nccr - swissmap , of the clay foundation and the isaac newton institute in cambridge ( where the present work has been carried out ) are gratefully acknowledged ."
  ],
  "abstract_text": [
    "<S> we describe simple properties of some soups of _ unoriented _ markov loops and of some soups of _ oriented _ markov loops that can be interpreted as a spatial markov property of these loop - soups . </S>",
    "<S> this property of the latter soup is related to well - known features of the uniform spanning trees ( such as wilson s algorithm ) while the markov property of the former soup is related to the gaussian free field and to identities used in the foundational papers of symanzik , nelson , and of brydges , frhlich and spencer or dynkin , or more recently by le jan . </S>"
  ]
}