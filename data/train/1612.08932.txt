{
  "article_text": [
    "high - dimensional datasets occur naturally in many areas such as computer vision , computational neuroscience , computational biology , speech analysis , localization of wireless sensor networks , graph visualization , high - dimensional data fusion , spatio - temporal data analysis to name a few . in many instances of such datasets",
    "the dimensionality is only artificially high , though each data point consists of perhaps thousands of variables , it may be described as a function of only a few underlying parameters .",
    "that is , the data points are actually samples from a low - dimensional manifold that is embedded in a high - dimensional space .",
    "the problem of manifold learning is concerned with finding low - dimensional representations of high - dimensional data .",
    "manifold learning algorithms attempt to uncover this low - dimensional representation of data .",
    "many seemingly complex systems described by high - dimensional data sets are in fact governed by a surprisingly low number of parameters .",
    "revealing the low - dimensional representation of such high - dimensional data sets not only leads to a more compact description of the data , but also enhances our understanding of the system .",
    "laplacian eigenmaps@xcite , isomap@xcite , diffusion maps @xcite , hessian eigenmaps@xcite , local tangent space alignment@xcite , locally linear embedding@xcite , continuum isomap@xcite , maximum variance unfolding@xcite , t - distributed stochastic neighborhood embedding@xcite , semidefinite embedding@xcite and more recently fast manifold learning with sdd linear systems@xcite are some examples of such mapping techniques for manifold learning .",
    "these techniques are also referred to as ` nonlinear dimensionality reduction ' techniques .      in this paper",
    "we attempt to see how well the topological structure of the dataset is preserved when we apply the fast sdd manifold learning map @xcite . to be more specific ,",
    "we look at a special setting of applying the fast sdd manifold learning map @xcite on datasets that lie on a topological circle .",
    "we would like to rigorize the reference to the term topological circle by stating that a topological circle in @xmath0 is any homeomorphic image of @xmath4 . a topological circle in @xmath0 ,",
    "is defined as a one - to - one continuous image of the map @xmath5 from a circle @xmath6 to a high - dimensional space @xmath0 denoted by @xmath7 .",
    "let s assume we were given a uniform sample of @xmath8 points lying on this continuous image of @xmath5 which is the dataset matrix .",
    "we denote this dataset by a real matrix @xmath9 . for any chosen bandwidth @xmath10 and the dataset matrix @xmath11 with data lying in @xmath0 ,",
    "we denote the fast sdd manifold learning map as @xmath12 . in order to infer whether the result of applying fast sdd manifold learning map @xcite on a discrete dataset of points in @xmath0 is a topological circle we inturn check whether the result of applying @xcite produces a set of points @xmath13 that form a polygon or not .",
    "this is motivated by that fact that with increasing number of edges a regular polygon becomes closer and closer to a circle .",
    "we therefore can infer on whether the dataset in @xmath0 lies on a topological circle or not based on whether the result obtained by the fast sdd manifold learning map is a polygon or not .",
    "one primary concern here is the fact that fast sdd manifold learning map as well as other manifold learning maps are parametrized by a scalar bandwidth parameter @xmath3 .",
    "we provide a method to optimally choose @xmath3 by minimization of a @xmath14 energy function @xmath15 that we propose .",
    "we show that for a fixed @xmath16 , the @xmath13 corresponding to a @xmath3 that takes the values close enough to @xmath17 ; lies on a polygon .",
    "this way we have a method to infer on the existence of topological circularity on any given dataset in @xmath0 by computing the minima @xmath18 of @xmath15 .",
    "in practice high - dimensional data in @xmath0 with an intrinsic circular geometric representation in a lower dimension occurs commonly in areas of computer vision and computational biology .",
    "we now refer and point to such specific use - cases in these domains .      with regards to analysis of human motion via data captured through computer vision ,",
    "the works of @xcite show intuitively that the gait is a 1-dimensional manifold which is embedded in a high dimensional visual variable space . as an example ,",
    "figure 3 in @xcite shows that computer vision data collected for modeling the task of recognizing human activities lies on 2 dimensional loop like geometries .",
    "in addition to this the human motion data naturally has an ordering associated with it as the human subject progresses from the beginning of his gait sequence towards the completion of his gait sequence in a fixed order of gait actions with respect to time .",
    "very recently , researchers studied gene expression data collected through cross - sectional and longitudinal studies for people at different stages of malaria . upon examining this data using topological data analysis @xcite they found that all patients ( hosts ) data lies on a loop or circle sitting inside of a high dimensional space . they were able to characterize the resilience of hosts to malarial infection by finding that resilient hosts tend to have their mapped data lying on small loops whereas non - resilient individuals end up getting mapped into large loops .",
    "in this setting , we assume that the points or the data are collected in an order . as we see in the motivated use - cases in previous section , or the biological experiments described later in this paper in section 9 ,",
    "this is a natural assumption in many cases . in this setting",
    ", we assume that the points in dataset @xmath11 are collected with respect to an order in @xmath4 .",
    "more rigorously , if @xmath8 points @xmath19 were uniformly sampled from it , then there exists @xmath20 so that @xmath21 where @xmath22 denotes the @xmath23-th point of @xmath11 . hence we can form a data matrix x whose @xmath23-th row is @xmath24 .",
    "note that , interchanging the order of data will do so for the rows of x.",
    "in this section we introduce the fast sdd manifold learning map @xmath13 proposed in @xcite .",
    "this recently proposed map is much faster than laplacian eigenmaps @xcite because it is based on optimization of a quadratic objective function under a linear constraint while in laplacian eigenmaps the optimization is of a quadratic objective function under a quadratic constraint .",
    "in addition to this , the solution for the fast manifold learning map can be obtained by solving a linear system of the form @xmath25 where @xmath26 happens to be a symmetric diagonally dominant ( sdd ) matrix .",
    "the solutions of such sdd linear systems can be computed very fast thereby leading to speedup involved with this fast sdd manifold learning map .    in order to be able to define the map @xmath13",
    ", we introduce three matrices : @xmath27 , @xmath28 , @xmath29 that we now define .",
    "the entries of graph laplacian matrix @xmath30 are defined using the euclidean distance between the rows @xmath31 of @xmath11 and a scalar @xmath32as :    @xmath33    note : the scalar @xmath3 in here is also referred to as kernel bandwidth @xcite .",
    "the matrix @xmath34 is given by : @xmath35    the matrix @xmath36 is a matrix with very trivial requirement of all rows being distinct ( i.e , differ by at least one entry ) and for practical purposes we choose a @xmath29 through sampling the entries @xmath37 from an i.i.d normal distribution .",
    "we finally define the map @xmath13 introduced in using @xmath38 as @xmath39 where @xmath40 denotes the moore - penrose pseudoinverse of @xmath27 .",
    "note that this map is a continuous function of the higher dimensional data set for any fixed bandwidth parameter ; in other words , for every fixed @xmath3 , @xmath41 as @xmath42 .",
    "this is an immediate consequence of the continuity of the pseudoinverse @xmath43 when the underlying matrices have constant rank @xcite , which is the case for laplacian matrices .",
    "in this section , we propose an objective function @xmath44 that , on being minimized with respect to @xmath3 gives the best bandwidth @xmath18 at the optima for the purposes of manifold learning .",
    "we support this choice of function @xmath44 through experimental results as well . in the rest of paper for ease of notation",
    "we refer to @xmath27 as @xmath45 .",
    "the proposed energy function is the sum of squares of the sides of the projected ordered data set , i.e. @xmath46 this can be written in a more compact form as : @xmath47upon substituting @xmath48 in above expression of @xmath44 we get @xmath49 ^ 2}\\ ] ] is essentially the @xmath14 based computation of perimeter of polygon formed by points in @xmath50 considered in a sequential order @xmath51 .",
    "[ [ mr ] ]    if the result of the fast sdd manifold learning map @xcite given by @xmath52 at @xmath53 that minimizes @xmath54 happens to form a polygon in @xmath1 upon connecting the resultant points in the same order as in @xmath11 , then we infer that the original dataset in @xmath0 is a topological circle .",
    "conversely , if the result of the fast sdd manifold learning map @xcite at the @xmath18 that minimizes @xmath55 does not form a polygon in @xmath1 then we infer that the original dataset in @xmath0 is not a topological circle .      in the use - cases where we need to check whether the data came from a topolgical circle in high dimension ( for example , periodic data as in the traits of the mice experiments described in section 9",
    ", we can project @xmath11 onto @xmath56 for values of sigma , build the energy function @xmath57 , and search for a mimizer of @xmath57 .",
    "if the minimizer does not exist , we conclude that the original data is not a part of a topological circle , which in return could imply non - existence of periodic patterns .",
    "the authors in @xcite provide an approach to estimate @xmath58 , the number of nearest neighbors to use in the construction of the graph laplacian .",
    "this method evaluates a given @xmath58 with respect to the preservation of @xmath58- neighborhoods in the original data .",
    "however , it is not known how a method for estimating @xmath58 can be translated into a method for estimating @xmath3 or vice versa ( the two graph construction methods exhibit different asymptotic behaviour precisely because they give rise to different ensembles of neighborhoods @xcite .",
    "the work in @xcite suggests an heuristic approach for bandwidth selection that utilizes kernel density estimation . this approach does not necessarily suggest a way to infer about the presence of topological circularity in @xmath0 and",
    "also estimates a different bandwidth @xmath59 one for each of the @xmath8 points in this formulation .",
    "@xmath60 we now state results that go towards a proof of the main result of our paper stated in section [ mr ] .",
    "from this section onwards , we orient ourselves towards a proof of the main result 5.1 . while a complete mathematical proof is still unknown to us at this moment , although will be highly desirable , we provide the proof by a mixture of theoretical computations , and experiments with data sets , both synthetic and real . since the main theorem connects two seeming different quantities - minimizer of the @xmath14 energy @xmath61 , and the topological circularity of the projection @xmath62 , we start first by showing theoretically that a minimizer of e indeed does exist in general cases of the original high dimensional dataset x. this is the subject matter of the sections 6 and 7 . after proving the existence of the minimizer",
    "we test this on several data sets by plotting @xmath63 for @xmath64 and in each case find that @xmath65 indeed corresponds to a non self - intersecting polygon in two dimensions as we shall see in the diagrams towards the end of this paper in section 8 .",
    "we then compute some derivatives with regards to our fast manifold learning map and proposed energy , that we would like to use in deriving some limit theorems in section 7 .",
    "these limit theorems will explain part of the asymptotic behavior of @xmath61 as a function of @xmath3 which is crucial in proving the main result .",
    "we now give some derivatives with regards to our fast manifold learning map and proposed energy that we would like to use in deriving some limiting theorems in rest of our paper .      in this subsection",
    "we give the derivative of @xmath66 which occurs in our map @xmath50 as it would later help us to define the derivative @xmath67 .",
    "prior to that , we first state the standard limit based definition of moore - penrose pseudoinverse and also show the commutativity of pseudoinverses using their limit based definitions .",
    "for a small @xmath68 @xmath69from this definition we have @xmath70      the derivative of @xmath71 with respect to @xmath3 where @xmath45 is defined for any @xmath72 as @xmath73is given by @xmath74    we know from the properties of moore - penrose pseudoinverse that @xmath75the rank of a graph laplacian matrix is @xmath76 as it has it s smallest eigenvalue as zero with multiplicity 1 .",
    "now the derivative of a real valued pseudoinverse matrix @xmath71which has constant rank at a point @xmath3 may be calculated in terms of derivative of @xmath45 as given in equation 4.12 of @xcite as : @xmath77 now as @xmath45 is symmetric we have @xmath78      the first derivative of our manifold learning map with respect to @xmath3 is given by @xmath79 using [ eqn : dpids ] we have @xmath80 that we substitute above to get @xmath81 + \\mathbf{a}(\\sigma)tr\\left(\\mathbf{\\gamma^t s } \\mathbf{l}^{+}(\\sigma)\\right)^2 \\frac{d\\mathbf{l}}{d\\sigma}\\mathbf{s\\gamma}}{tr(\\mathbf{\\gamma^t s a}(\\sigma))^2}\\ ] ]      the first derivative of our @xmath14 based energy function @xmath44 with respect to @xmath3 is given by @xmath82\\ ] ] the second derivative of @xmath44 is given by @xmath83\\ ] ]",
    "in this section , we show theoretically the limits of @xmath61 and its certain derivatives as @xmath3 approaches @xmath84 are finite . in the next section",
    ", we will present several experimental proofs that the limits of @xmath61 and its certain derivatives are finite also when @xmath3 approaches zero .",
    "these two results together prove that : @xmath61 is indeed bounded continuous function on @xmath85 , and hence has a global minimum .",
    "the following two properties hold true for matrix @xmath28 :    a.   @xmath86 b.   @xmath87    a.   it follows from using the fact @xmath88 that @xmath89 this implies @xmath90 now using the uniqueness of @xmath91 from the definition of moore - penrose pseudoinverse we conclude that @xmath92 . b.   on substituting the simple limit @xmath93 in the definition of @xmath94 in eqn .",
    "[ leqn ] we get @xmath95 and therefore we have @xmath96 .    the following limit over the operator norm of @xmath71 holds true : @xmath97    @xmath98    therefore , @xmath99 for @xmath100 upon substituting @xmath101 above we get @xmath102    on computing limit of this inequality we get @xmath103 .",
    "the following limits hold true for manifold learning map @xmath50 :    a.   when @xmath104 @xmath105 b.   @xmath106 c.   @xmath107    a.   @xmath108 + upon substituting @xmath109 and @xmath110 in above expression we get @xmath111 we substitute @xmath112 in the above expression and as well using the same we have @xmath113 which we also substitute above @xmath114 as @xmath104 , we have @xmath115 which follows directly from the definition of @xmath28 as @xmath116 .",
    "we substitute this in [ zlimfinal ] to obtain the required limit .",
    "b.   we have @xmath117 and therefore we have @xmath118 we substitute this in limit of eqn .",
    "[ eq : dzds ] of @xmath67 to get + @xmath119+\\mathbf{\\gamma } tr(\\mathbf{\\gamma^t s } ( \\mathbf{s}^{+})^2 \\frac{d\\mathbf{l}}{d\\sigma}\\mathbf{s\\gamma})}{tr(\\mathbf{\\gamma^t s \\gamma})^2}\\ ] ] + the derivative of the off - diagonal term @xmath120 is @xmath121 and the derivative of the diagonal term @xmath122 is @xmath123\\ ] ] from this we have @xmath124 we substitute this in equation [ dzdss ] to get our required result @xmath125 c.   we refer to the numerator of the expression of @xmath67 with @xmath126 as @xmath127 and we refer to the denominator of the expression of @xmath67 with @xmath128 as @xmath129 we have @xmath130 the derivative of @xmath128 is given below @xmath131 from equation [ dldszero ] , we have @xmath132 and therefore @xmath133 .",
    "based on these limits and the equation above we have @xmath134 the expression for @xmath135 is a sum of terms containg @xmath136 , @xmath137 and @xmath138 , each of which tend to @xmath139 as @xmath140 and therefore @xmath141 we have @xmath142 on substituting [ nonzero ] , [ zero1 ] and [ zero2 ] above we prove @xmath143 .",
    "the following limits hold true for energy @xmath44 :    a.   @xmath144 is finite",
    ". b.   @xmath145 c.   @xmath146    a.   this is immediate from the proof of theorem 1 , that expresses a limit for @xmath50 as @xmath140 , and the expression of @xmath147 in section 5",
    ". b.   the first derivative of @xmath44 is given by @xmath148\\ ] ] + as @xmath149 and @xmath105 we prove the result . c.   the second derivative of @xmath44 is given by @xmath150\\ ] ] as @xmath149 and @xmath151 and @xmath105 we prove the result .",
    "setting aside the experimental part of the proof for section 8 , we write down two algorithms , one to compute @xmath152 for a fixed dataset @xmath11 , and the next one is to test the existence of a topological circularity in @xmath11",
    ".    @xmath153 @xmath154 @xmath155 using its derivative in equation 17 , which further uses the derivatives in equation 16 , 27 and 28 .",
    "@xmath156 minimize @xmath157 , @xmath158 to get @xmath159 return @xmath159    @xmath160 @xmath11 .",
    "reject @xmath160 plot @xmath161 , and join its points in the order of @xmath8 points in @xmath11 .",
    "reject @xmath160 accept @xmath160",
    "as hinted back in section 7 , this will be the concluding section for a proof of the main result where several experiments will guarantee that the minimizer of e corresponds to a non - self intersecting polygon z(sigma ) in 2d .      in this subsection",
    "we now describe two experiments that we have conducted with our proposed @xmath44 functions on synthetic data lying on a    a.   circle b.   toroidal helix    0.5     0.5     0.5     0.5     0.5   vs. @xmath162 and @xmath163 energy and perimeter of fast manifold learning on a toroidal helix.,title=\"fig : \" ]    0.5   vs. @xmath162 and @xmath163 energy and perimeter of fast manifold learning on a toroidal helix.,title=\"fig : \" ]    3    toroidal helix , for different choices of @xmath164 , title=\"fig : \" ]     toroidal helix , for different choices of @xmath164 ]     toroidal helix , for different choices of @xmath164 ]    3    toroidal helix , for different choices of @xmath164 , title=\"fig : \" ]     toroidal helix , for different choices of @xmath164 ]     toroidal helix , for different choices of @xmath164 ]    3    toroidal helix , for different choices of @xmath164 , title=\"fig : \" ]     toroidal helix , for different choices of @xmath164 ]     toroidal helix , for different choices of @xmath164 ]    within figure 1 , in subfigure ( a ) we provide a graph of @xmath14 energy , @xmath44 ( y - axis ) with respect to varying @xmath3 ( x - axis ) for a very small @xmath165 points on a unit - circle . by perimeter , @xmath166 we refer to equation 4 computed with @xmath167 instead of @xmath168 norms in the first and second summands .",
    "the subfigure ( b ) in figure 1 provides the graph of @xmath166 for the same @xmath169 points on a unit - circle . for @xmath170 points on a unit - circle we provide graphs of @xmath44 and @xmath166 in subfigures ( c ) and ( d ) of figure 1 . within figure 2 in subfigures ( a ) and",
    "( b ) we provide @xmath44 and @xmath166 for @xmath170 points lying on a toroidal helix .",
    "by @xmath18 we refer to the minimizer of @xmath44 .",
    "we can obtain @xmath18 through gradient descent followed by a tunneling phase as detailed in algorithm 1 of this paper .",
    "gradient descent is a popular algorithm for finding a local minima while tunneling is a novel way to find a local minima better than the one obtained through gradient descent .",
    "hence , one could also apply multiple iterations of gradient descent followed by tunneling where each iteration consists of one followed by another .    in figures 3 , 4 and 5 , for @xmath11 lying on a toroidal helix , we provide @xmath50 for small choices of @xmath3 away from @xmath18 .",
    "the points are in red .",
    "we connect the points in an order @xmath171 with straight lines in black .",
    "we see that they do not form polygons when the choice of @xmath3 is away from @xmath18 . in figures 6 , 7 and 8",
    "we show corresponding geometries obtained for choices of @xmath3 around optimal @xmath18 .",
    "we show especially in figure 8 that as @xmath172 , we obtain a polygon , as there are no intersections . in figures 9 , 10 and 11",
    "we show the geometries obtained for choices of large @xmath3 away from @xmath18 again do not form a polygon .",
    "we show in the sub - figures of 8(a ) and 8(b ) that the value of @xmath173 which gives the least @xmath14 energy @xmath44 and @xmath174 perimeter @xmath166 corresponds to the @xmath3 that happens to be a non self - intersecting polygon in the resultant geometries which happens to be the case precisely in figure 14 .",
    "we also see in figures 1 and 2 that our derived limit theorems do hold true , as the graph begins to flatten out for large choices of @xmath3 , as the values go away from @xmath18 .",
    "we are also optimistic about the fact that these graphs look like weakly unimodal functions unlike them being highly non - convex for the case of the circle and toroidal helix .      in this subsection",
    ", we show some experiments with real biological data from four mice , all of which were infected by malaria and treated for cure in experiments conducted by microbiologists and immunologists @xcite at stanford university .",
    "the link to the mice dataset from the biological experiment on mice is here : http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002436#sec024 .",
    "three of the mice survived with treatment while the other did not . for each mouse",
    "we collect the data set of several characteristics for survivor mice that we intuitively believe to repeat with time , i.e. are periodic functions of time .",
    "this is because certain physical traits of subjects ( patient or mice ) show repeating pattern at beginning and end of a disease if the patient survives .",
    "this however is not the case normally for non - survivor patients as with them we do not see these physical traits to be periodic with time .",
    "for example , the red bloodcell count ( rbc ) of a mouse had a higher value in the beginning period of malaria , and then decreased as the disease got severe , and eventually increased again with the treatment and came back to normal .",
    "as another characteristic , the bacterial count was less in the beginning , but with the disease being severe , it increased and then dropped again with treatment .",
    "these periodic behaviors of certain , say @xmath175 number of physical traits with approximately or exactly equal periods of a survivor patient imply that when plotted not against time , but against each other , they will most probably form a loop structure in @xmath0 .",
    "as a model example , one can think of the pair of periodic functions @xmath176 , which form the unit circle when plotted against each other .",
    "however , if the number of traits @xmath175 is bigger than @xmath177 , it is hard to conclude from the data set whether they form a loop or not , and hence whether the patient is a survivor or not .",
    "this is where we apply our fast dimensionality reduction technique to obtain two dimensional projections for varying bandwidth @xmath3 , and check whether for the energy minimizing bandwidth mentioned in section @xmath178 , we obtain a polygon .",
    "if we do , we will conclude that the patient was survivor , otherwise non - survivor .",
    "we can obtain this energy - minimizing bandwidth by either searching through a grid of discrete choices of @xmath3 or through algorithm 1 above . as part of some pre - processing we apply lowess local regression to each variable in order to smooth the data with small smoothing parameter @xmath179 that leads to utilization of a smaller proportion of total data points while performing local regression .    in our experiments with mice data ,",
    "the number of samples ( points ) considered are @xmath180 and the number of attributes considered are @xmath181 .",
    "the four attributes are logarithm of parasite density , red blood cell count , temperature and weight of the mouse under consideration .    for survivor mouse @xmath177 , the plot of @xmath173 vs energy @xmath182 is given in figure 12 .",
    "we notice that at @xmath183 the energy @xmath182 is minimized and we show in figure 13 that the corresponding two dimensional projection @xmath184 is indeed a non self - intersecting polygon .    2         2         2         for survivor mouse @xmath185 , the energy @xmath182 vs log(bandwidth @xmath3 )",
    "is shown in figure 14 . here",
    ", @xmath186 minimizes the energy @xmath182 and we see in figure 15 that the corresponding two dimensional projection @xmath187 is indeed a non self - intersecting polygon . here",
    "the graph is nt visibly asymptotic for the survivor mouse 2 near the origin , but that s most probably caused by the lack of an ideal ( as in exact ) periodic pattern in higher dimensions .",
    "after the survivor mice experiments we now show and contrast the energy plot for the non - survivor mouse .",
    "+ quite interestingly , at @xmath182 minimizing @xmath188 when we plot @xmath189 vs @xmath190 in figure 16 , the graph looks very different than the survivor mice data , or even the energy plots obtained for synthetic data lying on a circle or a toroidal helix as shown in figures 1 and 2 , significant parts of which show convexity .",
    "the plot for the non - survivor mice is not convex and furthermore , we notice that @xmath191 minimizes the energy @xmath182 , but the corresponding @xmath192 is shown in figure 17 .",
    "we note that @xmath193 here is not a non - self intersecting polygon , and hence by our main result we conclude that the test data for the physical traints of the non - survivor mouse was not periodic with time , indicating that the mouse was not a survivor , which matches up with the fact .    finally , we would also like to state that the computation of our proposed @xmath44 only requires @xmath194 operations per choicse of @xmath3 , espe cially as they are computed on an ordered set of points . also , each column of @xmath195 can be computed in nearly @xmath196 time for each choice of @xmath3 where @xmath197 is the number of non - zero entries .",
    "this complexity is due to the fact that we can obtain the fast manifold learning map @xmath195 for any choice of @xmath3 by solving a symmetric diagonally dominant ( sdd ) linear system of equations @xcite .",
    "in this paper , we provide a test to check for circularity or periodicity in high dimensional data sets by looking at their nonlinear projections into @xmath1 given by the fast manifold learning map introduced in @xcite .",
    "there are several directions in which such tests can be generalized to .",
    "for example , if the pattern we expect in the high - dimensional data is topologically more complex but still has one dimension , for example , say as a wedge of circles , it would be interesting to see if our projection method can detect the corresponding topological structures after the nonlinear projection",
    ". another direction could be detecting topological structures with two dimensions , for example of that of a sphere or a torus , by a modification of our projection method onto two dimensions .",
    "we would also like to investigate speeding up the computations for finding the minimizer of @xmath198 as the manifold learning map @xmath50 already involves fast computations as in @xcite .",
    "coifman , s. lafon , a.b .",
    "lee , m. maggioni , b. nadler , f. warner , s. zucker .",
    "_ geometric diffusions as a tool for harmonic analysis and structure definition of data _ , proceedings of national academy of sciences , ( pnas ) , 2004 .",
    "q. weinberger and lawrence .",
    "_ unsupervised learning of image manifolds by semidefinite programming_. in proceedings of the ieee conference on computer vision and pattern recognition , 2004 .",
    "praneeth vepakomma and ahmed elgammal . _ a fast algorithm for manifold learning by posing it as a symmetric diagonally dominant linear system_. applied and computational harmonic analysis , http://dx.doi.org/10.1016/j.acha.2015.10.004 , 2015 .",
    "devanne m , wannous h , berretti s , pala p , daoudi m , del bimbo a. _ 3-d human action recognition by shape analysis of motion trajectories on riemannian manifold _ , ieee transactions on cybernetics ( journal ) , 45(7 ) pp : 1340 - 1352 , doi : 10.1109/tcyb.2014.2350774 2015      brenda y. torres , jose henrique m. oliveira , ann thomas tate , poonam rath , katherine cumnock , david s. schneider . _",
    "tracking resilience to infections by mapping disease space _ , plos biology ( journal ) , 2016 .          gene h. golub and v. pereyra . _ the differentiation of pseudo - inverses and nonlinear least squares problems whose variables separate _ , siam journal on numerical analysis , vol .",
    "413 - 432 , 1973 .",
    "rakocevic , vladimir .",
    "textiton continuity of the moore ",
    "penrose and drazin inverses , matematicki vesnik , 49 , pp . 163172 , 1997 .",
    "a. v. levy and a.montalvo , _ tunneling algorithm for the global minimization of functions _",
    ", siam journal on scientific and statistical computing , vol .",
    "15 - 29 , 1985 .",
    "b. c. cetin , j. barhen , j. w. burdick , _ terminal repeller unconstrained subenergy tunneling ( trust ) for fast global optimization _ , journal of optimization theory and applications , volume 77 , issue 1 , pp .",
    "97 - 126 , 1993 ."
  ],
  "abstract_text": [
    "<S> we provide a way to infer about existence of topological circularity in high - dimensional data sets in @xmath0 from its projection in @xmath1 obtained through a fast manifold learning map as a function of the high - dimensional dataset @xmath2 and a particular choice of a positive real @xmath3 known as bandwidth parameter . at the same time we also provide a way to estimate the optimal bandwith for fast manifold learning in this setting through minimization of these functions of bandwidth . </S>",
    "<S> we also provide limit theorems to characterize the behavior of our proposed functions of bandwidth . </S>"
  ]
}