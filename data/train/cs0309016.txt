{
  "article_text": [
    "this paper develops an algorithm to compute a desired type of nash equilibrium .",
    "furthermore we use this algorithm to show existance and uniqness of sensible nash equilibrium .",
    "our novel approach to this problem has been motivated by the number of existance algorithms .",
    "the basis of the general approach of the literature has been to rely on the geometric properties of the equilibrium .",
    "this paper is interested in computing nash equilibria that satisfy the type of nash of refinement refered to as `` trembling hand '' perfection @xcite @xcite .",
    "this paper shows that simulated annealing can be used to compute the above refinement .",
    "simulated annealing is a type of monte carlo sampling procedure that relies on markov chains to ensure its regularity conditions .",
    "most applications have mainly concentrated on problems of combinatorial optimization such as routing and packing problems , or problems from statistical pattern recognition like image processing .",
    "another well known group of algorithms for calculating perfect nash equilibria are the trace algorithms of harsanyi and selten @xcite , where an outcome for the game is selected by `` tracing '' a feasible path through a family of auxiliary games .",
    "the solution progress along the feasible path is intended to represent the way in which players adjust their expectations and predictions about the play of the game .",
    "a major limitation of the tracing procedure is that the logarithmic version of this method , does not always provide a path that traces to a perfect equilibrium .",
    "harsanyi @xcite , has argued that this problem can be resolved by eliminating all dominated pure strategies before applying the tracing procedure .",
    "however van damme @xcite constructs examples which do not rquire dominated pure strategies in which the tracing procedure yields a non - perfect equilibrium .",
    "furthermore it was suggested by van damme that the inconsistancy lies in the logarithmic control costs .",
    "games which have a control cost parameter are of normal form so that players may also choose strategies , incur depending on how well they choose to control their actions .",
    "another limitation of the tracing procedure it relies on the algeobro - geometric properties of the equilibrium .",
    "this approach has been commonly used throughout the literature for computing the equilibrium of non - cooperative games .",
    "for example the focus of lemke and howson @xcite for bimatrix games and the wilson @xcite and scarf @xcite algorithm for the @xmath0-person games has also been to utilise the fundamental geometry of games to calculate equilibrium . in general these approaches to equilibrium calculation are computationally expensive .",
    "however , within game theory there is a history of monte carlo methods being applied to solve non - cooperative games , e.g. starting with ulam @xcite in 1954 .",
    "from the view point of applying global optimization techniques to infinite games , monte carlo simulation has been used by georgobiani and torondzadze as a means of providing nash equilibria for rectangular games @xcite .",
    "this is the approach that we will be developing in this paper .",
    "this paper is organised as follows .",
    "the second section of this paper introduces the mcmc algorithm and provides some discussion of its convergence properties in terms of markov chain theory . as a starting point for this discussion the connection between mcmc sampling techniques and monte carlo sampling techniques is explored .",
    "the mcmc algorithms include the gibbs sampler and the metropolis algorithm and are often called simulated annealing .",
    "the third section of this paper will provide a characterization of these algorithms in terms of the trembling hand of trembling hand perfection . with this in mind",
    ", we provide an example of the use of simulated annealing applied to calculating nash equilibrium . in this example",
    "the solution leads to equilibria that result from trembling hand perfection .",
    "monte carlo simulation has been used extensively for solving complicated problems that defy an analytic formulation . the main idea behind monte",
    "carlo simulation is to either construct a stochastic model that is in agreement with the actual problem analytically , or to simulate the problem directly .",
    "one problem with monte carlo methods is that if the underlying probability distribution is non - standard , then the convergence of sampled stochastic process can not be assured by the slln .",
    "one way around this is to realize that a stochastic process can be generated from any process that draws its samples from the support of underlying distribution .",
    "markov chain monte carlo ( mcmc ) does this by constructing a markov chain that uses the underlying distribution as its stationary distribution .",
    "this enables the simulation of the stochastic process for non - standard distributions , while ensuring that the slln will hold .    as an illustration of the mcmc",
    "we will discuss the _ metropolis algorithm _ @xcite . in this algorithm , each iteration will comprise @xmath1 updating steps .",
    "let @xmath2 denote the state of @xmath3 at the end of the @xmath4th iteration .",
    "for step @xmath5 of iteration @xmath6 , @xmath3 is updated using the metropolis algorithm .",
    "the candidate @xmath7 is generated from a _ proposal distribution _",
    "@xmath8 , where @xmath9 denotes the value of @xmath10 after completing step @xmath11 of iteration @xmath6 , i.e. @xmath12 where the components @xmath13 have yet to be updated and components @xmath14 have already been updated .",
    "thus the proposal distribution of the @xmath5th component @xmath15 , generates a candidate for only the @xmath5th component of @xmath16 .",
    "the candidate is accepted with probability @xmath17 where @xmath18 is the full conditional distribution for @xmath3 under @xmath19 . if @xmath20 is accepted , then @xmath21 ; otherwise @xmath22 .",
    "for this reason @xmath23 is known as the _ metropolis criterion_.    one of the disadvantages of this algorithm is the complexity of the metropolis criterion _ _  _ _ @xmath24 . in practice @xmath24",
    "often simplifies considerably , particularly when @xmath25derives from a conditional independence model @xcite @xcite .",
    "however , the single component metropolis algorithm has the advantage of employing the full conditional distributions for @xmath26 and besag @xcite has shown that @xmath26 will be uniquely determined by its full conditional distribution . as a result @xmath23 will generate samples from a unique target distribution @xmath26 .",
    "an alternative approach for constructing a markov chain with a stationary distribution @xmath27 that provides a generalization of the approach suggested by metropolis et al .",
    "@xcite , has been suggested by hastings @xcite . at each point in time @xmath4 , the next state @xmath28 is chosen by first sampling a candidate point @xmath29 from a proposal distribution @xmath30 .",
    "the candidate point @xmath29 is then accepted in accordance with the criterion @xmath31 under this criterion , if the candidate point is accepted , then @xmath32 , otherwise @xmath33 . the main difference between this algorithm and the one proposed by metropolis et al .",
    "@xcite , is that the _ metropolis - hastings algorithm _ , as it is named , assumes that the proposal distributions are symmetric , i.e. @xmath34 .",
    "the metropolis - hastings algorithm is therefore ruled out for higher dimensional problems , as these problems generally have little symmetry .",
    "the main advantage of the metropolis - hastings algorithm is that proposal distribution has no impact on the decision criterion , and therefore will not impact on the convergence of this algorithm towards the stationary distribution @xmath26 .    to provide a fuller explanation , the transition kernel of the metropolis - hastings algorithm",
    "is given by @xmath35 , \\end{split}\\ ] ]    where @xmath36 is the indicator function . from @xmath37",
    ", we can see that @xmath38 this implies that @xmath39 integrating both sides of this equation , we get @xmath40 this equation states that if @xmath41 is drawn from @xmath42 , then so must @xmath43 . in other words ,",
    "once one sample value has been obtained from the stationary distribution , then all subsequent samples must be drawn from the same distribution .",
    "this is only a partial justification of the metropolis - hastings algorithm .",
    "a full proof requires that @xmath44 converges on the stationary distribution .",
    "for a heuristic justification of this result , it can be noted that this distribution will depend only on the starting value @xmath45 , therefore the proof must show that markov chain gradually forgets its starting point , and converges on a unique stationary distribution .",
    "thus , after a sufficiently long _ burn - in _ of @xmath46 iterations , points @xmath47 will be dependent sample approximations of the stationary distribution .",
    "hence the _ burn - in sample _ is usually discarded when calculating the ergodic mean for @xmath48@xmath49",
    "in this sub - section we provide an algorithm for computing a perfect equilibrium for a strategic game and show that this algorithm provides a sequence of perturbed mixed strategies that will eventually converge on perfection .",
    "the basic idea is to construct select a markov chain and then use this markov to deliver a nash equilibrium via markov chain approximation .",
    "the trick is to nominate the appropriate markov chain with the most suitable convergence properties to deliver convergence of the sequence completely mixed nash equilibria of perturbed games or @xmath50-perfect equilibria to a perfect equilibrium .",
    "this is the objective that is undertaken in this section .",
    "consider an @xmath51-person game in strategic form @xmath52 in which @xmath53 is the player set , each player @xmath54 has a finite set of pure strategies @xmath55 and a pay - off function @xmath56 mapping the set of pure strategy profiles @xmath57 into the real number line .    in the strategic game @xmath58 , for each player",
    "@xmath54 there is a set of probability measures @xmath59 that can be defined over the pure strategy set @xmath60 this is player @xmath5 s mixed strategy set .",
    "the elements of the set @xmath59 are of the form @xmath61 $ ] where @xmath62 with @xmath63 i.e. @xmath59 is isomorphic to the unit simplex .",
    "we denote the elements of the space of mixed strategy profiles @xmath64 by @xmath65 where @xmath66 . as is the convention we use the following short - hand notation @xmath67 , where @xmath68 denotes the other components of @xmath69 .    for each player @xmath5",
    ", the pay - off function @xmath70 can be extended to the domain of mixed strategy profiles @xmath71 .",
    "the pay - off function for each player @xmath54 will be defined as follows @xmath72 .",
    "a mixed strategy @xmath73 @xmath71 is * nash equilibrium * of the strategic game @xmath58 , if for all players @xmath54 and all @xmath74 @xmath75    suppose that as well there being a positive probability @xmath76 of a player @xmath5 selecting a pure strategy s@xmath77 , there is a small probability @xmath78 that the pure strategy @xmath79 will be chosen by @xmath5 out of error . in the case where player @xmath5 selects his @xmath80th pure strategy @xmath79 by mistake ,",
    "the probability of doing so is given by @xmath81 .",
    "the total probability of player @xmath5 selecting a pure strategy s@xmath82 is then given by @xmath83    it can be seen that in this case , the total probability of player @xmath5 selecting a pure strategy s@xmath77 will be bounded below by @xmath84 equating @xmath85 we can see that this condition can be rewritten as @xmath86 with @xmath87    this leads to the definition of a perturbed game @xmath88 as a finite strategic game derived from the strategic game @xmath58 , in which each player @xmath5 s mixed strategy set is the set of completely mixed strategies for player @xmath5 constrained by the probability of making an error @xmath89 a mixed strategy combination @xmath90 is a nash equilibrium of the perturbed game @xmath91 iff the following condition is satisfied @xmath92    a mixed strategy @xmath73 @xmath71 is a * perfect equilibrium * in the strategic game @xmath58 if there exists a sequence of completely mixed strategy profiles @xmath93 where @xmath94 , and for every player @xmath54 and for every @xmath95@xmath96 in terms of our definition of a perturbed game , a mixed strategy is a perfect equilibrium iff there exist some sequences @xmath97 and @xmath98 such that    1 .",
    "each @xmath99 and @xmath100 , 2 .",
    "each @xmath101 is a nash equilibrium of a perturbed game equilibrium @xmath102 , and 3 .",
    "@xmath94 where for every player @xmath54 and for every @xmath95@xmath96    an alternative definition of perfection has been made myerson ( * ? ? ?",
    "* pp 7576 ) and is based on the idea that every pure strategy in a player s set of pure strategies has associated with it a small positive probability of at least @xmath103 but on strategies that are best responses have associated probabilities greater that @xmath104 more formally , for any player @xmath54 a mixed strategy @xmath105 is an @xmath106**-perfect equilibrium * * iff it is completely mixed and @xmath107 unlike nash equilibria of perturbed games , the @xmath106-perfect equilibria of a game @xmath58 will not necessarily be one of its nash equilibria .",
    "however , myerson does show that @xmath108 will be a perfect equilibrium iff    1 .   each @xmath109 and @xmath110 , 2 .",
    "each @xmath101 is an @xmath111-perfect equilibrium of the game @xmath58 , and 3 .",
    "@xmath112 for every player @xmath113    the starting basis for the mcmc algorithm for calculating perfection will be to follow myerson by constructing a sequence of @xmath106-perfect equilibria for the strategic game @xmath58 .",
    "as stated above , we know that for the strategic game @xmath58 , @xmath114 is an @xmath106-perfect equilibrium iff for each player @xmath54 , @xmath115 is a completely mixed strategy and @xmath116    following myerson ( * ? ? ?",
    "* p 79 ) we define the following set of mixed strategies for each player @xmath54 @xmath117 where @xmath118 with @xmath119 .",
    "we then define a point - to - set mapping @xmath120 to be a family of completely mixed distributions contained in @xmath121 @xmath122    if we then define , for each player @xmath54 , a mixed strategy @xmath123 where @xmath124 then it can be seen that @xmath125 will be non - empty .",
    "as each @xmath126 will a finite collection of linear inequalities , they will also be closed convex sets . in addition",
    "each @xmath127 , by the continuity of the pay - off function @xmath128 will also be upper semi - continuous .    as a consequence the mapping @xmath129 satisfies all the conditions of the kakutani fixed point theorem .",
    "in other words there exists some completely mixed strategy @xmath130 such that @xmath131 is an @xmath106-perfect equilibrium of @xmath58 . as @xmath132 is compact , the sequence @xmath50-perfect equilibria @xmath133 @xmath69 as @xmath134 , where @xmath69 is the perfect equilibrium of @xmath58 .",
    "an alternative route to the same result can be arrived at as follows using an argument based on the convergence properties markov chain .    for any normal form game @xmath135 , it is possible to define a mcmc algorithm such that its transition probabilities will converge to a perfect equilibrium as long as the following conditions hold :    1 .",
    "if @xmath136 then accept , where @xmath137 is the tuple mixed strategies selected on the @xmath138th iteration ; 2 .   otherwise , accept if probability @xmath139 where @xmath140 ; $ ] and 3 .",
    "in addition it can be seen that for all @xmath79 and @xmath141 such that @xmath142 , @xmath143 as @xmath144 .    for each player @xmath54",
    ", there will be a collection these subsets @xmath145 of @xmath5 s pure strategy space @xmath146 .",
    "the collection of these sets will referred to as player @xmath5 s local neighborhood structure .",
    "what we would like to do is for any two pure strategies @xmath79,@xmath147 define a path from @xmath79 to @xmath148 such that @xmath149    in order to do this , we observe that the point - set mapping defined by the set @xmath150 is a collection homogenous transition probabilities @xmath146 @xmath151 further more we can see that these transition probabilities have the markov property , i.e. given the path from @xmath79 to @xmath148 such that @xmath149 the conditional probability @xmath152    we define the following generating probability for the markov chain for each player @xmath54@xmath153 where @xmath154 we now introduce the following acceptance probability @xmath155 where @xmath156 is a control parameter .",
    "this last condition implies that    1 .   if @xmath136 then accept , where @xmath137 is the tuple mixed strategies selected on the @xmath138th iteration ; 2 .",
    "otherwise , accept if probability @xmath139 where @xmath140 ; $ ] and 3 .",
    "in addition it can be seen that for all @xmath79 and @xmath141 such that @xmath142 , @xmath143 as @xmath144 .    given theses three conditions we can now see that the following will hold :    * we know that under this acceptance criterion as @xmath157 the transition probability matrix @xmath158 of the homogenous markov chain generated by the game @xmath58 will converge on a stationary distribution @xmath159 as @xmath160 .",
    "@xmath161 and as @xmath144 @xmath162 where @xmath163 ( see van laarhoven and aarts @xcite for the proof of this last statement . ) * the transition probability matrix @xmath158 satisfies myerson s definition of an @xmath106-perfect equilibria and as myerson has shown , the fixed point that this sequence converges on is also a perfect equilibrium .",
    "there are problems with viewing the existence of nash equilibria as an end in itself .",
    "the most immediate problem with this has been the possible large number of nash equilibria that can be found for any game , together with the likelihood that not all of these nash equilibria will be reasonable in some sense .",
    "one way around this is to view the decision process of each agent participating in the game from a decision theoretic perspective . from this viewpoint ,",
    "only those equilibria that can be found by backwards induction will be self - enforcing .",
    "this leads to a technique for strategy space reduction by iteratively removing strategies that lead to outcomes that are not _ strongly dominated_. as shown by kuhn ( * ? ? ?",
    "* corollary 1 ) , under the assumption of perfect information , this leads to a recursion that is equivalent to the bellman equation of dynamic programming .    an alternative to this is to construct a recursion that iteratively eliminates _ weakly dominated strategies_. however , the removal of weakly dominated strategies can lead to the elimination of strategy profiles that would otherwise provide suitable outcomes if only strongly dominated strategies were to have been removed . from the viewpoint of this paper these recursive strategy space reduction techniques",
    "can be considered to be an algorithm that reduces the size of a game , making equilibrium selection easier .",
    "however , these iterative reduction techniques becomes unwieldy once the assumption of perfect information is relaxed and information sets contain more than one node of the game tree .",
    "this has led to a number of refinements to the definition of nash equilibrium . among the first of these",
    "was the notion of _ subgame perfection _",
    "@xcite , which removes strategies that are not optimal for every subgame of a extensive game s game tree .",
    "however , selten @xcite has shown that subgame perfection can also prescribe non - optimizing behaviour at information sets that are not reached when the equilibrium is played .",
    "this is because the expected payoff for the player whose information set is not reached will not depend on their own strategy . as a result",
    "every strategy will maximize their payoff . as van damme @xcite states , that this can be removed if the equilibrium prescribes a choice , at each information set that is a singleton , that maximizes the expected payoff after the information set .",
    "the problem is that not all subgame perfect equilibria satisfying this criteria are sensible .",
    "another approach which was suggested by selten @xcite , was to eliminate `` unreasonable '' subgame perfect equilibria by allowing the possibility of `` mistakes '' or `` trembles '' on the part of decision makers .",
    "in this way , isolated information sets are removed , as every information set can now be reached with positive probability .",
    "the other advantage of trembling hand perfection is that , unlike subgame perfection , it can be applied directly to the normal form of any game .",
    "although , as van damme shows , the perfect equilibria of a game s strategic and extensive forms need not coincide .",
    "an equivalence relationship holds for only the _ agent normal form _ and extensive form of any game @xcite .",
    "this is because the agent normal form of any game views each node of the game tree , of the extensive form of the game , as a player in the game . as a consequence each player represents an information",
    "set held by the player and will have an identical payoff function to the player .    as was shown by selten @xcite , the perfect equilibria of a game s strategic and extensive forms need not coincide .",
    "however he showed that an equivalence relationship holds between the equilibria of any extensive game and its associated _ agent normal form _ @xcite .",
    "this is because the agent normal form of any game views each node of the game tree , of the extensive form of the game , as a player in the game .",
    "as a consequence each player represents an information set held by the player and will have an identical pay - off function to the player .",
    "we let @xmath164 define an extensive game consisting of a set of @xmath51 players , a game tree @xmath165 consisting of a set of nodes @xmath156 and a binary relation @xmath166 which is a partial ordering on the set of nodes . the nodes of the game tree are classified as either non - terminal or terminal according to whether or not their are succeeding nodes in the game tree . the partial ordering",
    "is used to define a path of successive nodes .",
    "the non - terminal nodes of the game tree are partitioned into the sets @xmath167 that specify the moves associated with each player , with @xmath168 being the partition associated with random moves that are not associated with any player .",
    "all of the non - terminal nodes is the information partition @xmath169 @xmath170 , where each set @xmath171 is a partition of @xmath172 into information sets , such that all nodes within an information set @xmath173 have the same number of immediate successors and path intersects an information set at most once . under the assumption of perfect information",
    "each information set @xmath173 will be a singleton .",
    "this paper will assume _ imperfect information _",
    " this implies that if the information set @xmath173 contains a node @xmath174 , player @xmath5 will not be able to distinguish other nodes contained in this information set based on information possessed when moving to @xmath175 . throughout this paper",
    "it will also be assumed that _",
    "complete information _ is present ",
    "i.e. each player has _ perfect recall _ and will remember everything from earlier in the game , including their own moves .    associated with each random move is a probability distribution @xmath69 .",
    "the payoffs associated with the set of terminal points @xmath176 of the game tree are denoted by the @xmath51-tuple @xmath177 , where each player s payoff is a function of the terminal points @xmath178 , @xmath179 . with the information partition @xmath180",
    "a choice set @xmath181 can be defined , where each @xmath182 is a partition of the union of sets of successors @xmath183 for each @xmath184 : @xmath185 .",
    "the interpretation is that if player @xmath5 takes the choice @xmath186 at information set @xmath187 @xmath188 , then if @xmath5 is at @xmath184 , the next node reached is the element of @xmath189 contained in @xmath190 . under the assumption of imperfect information and perfect recall ,",
    "a probability distribution @xmath191 is assigned on @xmath182 to each information set @xmath192 this distribution @xmath191 is a behavioural strategy , with the set of all these strategies for player @xmath5 defined by @xmath193 .",
    "the profile of all players behavioural strategies is denoted by @xmath194 , where @xmath195 is the set of all behavioural strategy combinations .",
    "the probability of a particular realization of the game @xmath196 is denoted by @xmath197 .    the definition of perfect equilibrium we will use is based selten @xcite and friedman @xcite .",
    "kuhn @xcite has shown that these behavioural and mixed strategies are realization equivalent .",
    "therefore , for an extensive form game @xmath164 we let @xmath198 define its strategic form representation , with @xmath199 denoting the set of all mixed strategy profiles . the payoff profile @xmath166 is an @xmath51-tuple , where the @xmath5th element is defined as @xmath200 a perturbed game of @xmath201 is defined by @xmath202 , where @xmath203 is a mapping that assigns to every choice in @xmath201 a positive number @xmath204 such that @xmath205 for every information set @xmath187 .",
    "an equilibrium point @xmath206 of the strategic game @xmath201 is a perfect equilibrium if @xmath206 is a limit point of a sequence @xmath207 as @xmath208 , where each @xmath209 is an equilibrium points of the associated perturbed game @xmath202 .",
    "the algorithm is constructed using a simulated annealing algorithm found in van laarhoven and aarts @xcite .",
    "the pseudo - code for this algorithm is given below :    * begin * * intitialize * ; * @xmath210 ; * repeat * * repeat * * * * perturb*(config .",
    "@xmath211 , @xmath212 ) for player 1 ; * * * if @xmath213 then accept * * * * elseif @xmath214 then accept ; * * * if accept then * update*(config .",
    "@xmath80 ) ; * * * * perturb*(config .",
    "@xmath211 , @xmath212 ) for player @xmath51 ; * * * if @xmath213 then accept * * * * elseif @xmath214 then accept ; * * * if accept then * update*(config .",
    "@xmath80 ) ; * * until * equilibrium is approached sufficiently closely * ; * * @xmath215 ; * * @xmath216 * until * stop criterion = true ; * * end    the energy function differential for this algorithm is defined as follows : @xmath217 where the @xmath218 are the expected pay - off functions for each player participating in the perturbed game .",
    "the temperature function @xmath190 controls the trembles and is updated by the decrement rule @xmath219    we apply it to the following example taken from friedman .",
    "this example is based on the three player extensive form game used by selten @xcite to illustrate the existence of perfect equilibrium .",
    "the game tree is defined as follows in figure [ tree ] @xcite .    [ tree ]",
    "this game possesses both a perfect equilibrium as well as `` non - sensical '' subgame perfect equilibria .",
    "the perfect equilibrium for this extensive form game is defined via the perturbed pay - off functions :    @xmath220    where the @xmath221 are the mixed strategies and @xmath222 are errors defined for @xmath223 . letting the errors approach zero",
    ", it can be seen that perfect equilibrium is defined by @xmath224 .",
    "the results of the simulation are shown below in figure [ payoffs ] and indicate convergence to the trembling hand perfect equilibrium .",
    "this paper has concentrated on some of the underlying theoretical mechanics of simulated annealing and how they relate to the trembling hand perfect refinement of nash equilibrium .",
    "it has been argued that the trembles that underlie global optimization by simulated annealing are analogous to the `` mistakes '' of trembling hand perfection , in that they present a means of moving from local equilibria .",
    "the main contribution of this paper has been to apply simulated annealing to solve a game that is known to possess both a perfect equilibrium and `` nonsensical '' subgame perfect equilibrium .",
    "preliminary results indicate a convergence to the perfect equilibrium , with a mixing strategy occurring for two of the three players .",
    "gilks , w.r . , richardson , s. spiegelhalter , d.j .",
    "( 1996 ) introducing markov chain monte carlo . in gilks , w.r . ,",
    "richardson , s. spiegelhalter , d.j .",
    "( eds .. ) _ markov chain monte carlo in practice _ , 119 .",
    "chapman and hall , london .",
    "roberts , g.o .",
    "( 1996 ) markov chain concepts related to sampling algorithms . in gilks , w.r . ,",
    "richardson , s. spiegelhalter , d.j .",
    "_ markov chain monte carlo in practice _ , 4557 .",
    "chapman and hall , london ."
  ],
  "abstract_text": [
    "<S> within the literature on non - cooperative game theory , there have been a number of algorithms which will compute nash equilibria . </S>",
    "<S> this paper shows that the family of algorithms known as markov chain monte carlo ( mcmc ) can be used to calculate nash equilibria . </S>",
    "<S> mcmc is a type of monte carlo simulation that relies on markov chains to ensure its regularity conditions . </S>",
    "<S> mcmc has been widely used throughout the statistics and optimization literature , where variants of this algorithm are known as simulated annealing . </S>",
    "<S> this paper shows that there is interesting connection between the trembles that underlie the functioning of this algorithm and the type of nash refinement known as trembling hand perfection . </S>",
    "<S> this paper shows that it is possible to use simulated annealing to compute this refinement .    </S>",
    "<S> * stuart mcdonald * + school of economics + the university of queensland + queensland 4072 , + australia + s.mcdonald@mailbox.uq.edu.au +    * liam wagner * + department of mathematics and + st john s college , within + the university of queensland + queensland 4072 , australia + ldw@maths.uq.edu.au    _ _ keywords:__trembling hand perfection , equilibrium selection and computation , simulated annealing , markov chain monte carlo </S>"
  ]
}