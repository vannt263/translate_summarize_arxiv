{
  "article_text": [
    "the ogle , moa and kmtnet  kmtnet ] wide - field surveys currently detect and alert in excess of 2000 microlensing events per year in the direction of the galactic bulge .",
    "these events have an average timescale of @xmath0  22 days , but individual events can be as short as a few days or as long as a few hundred .",
    "a small subset of microlensing events produce anomalous short - duration signals lasting from a few hours to a few days due to the presence of one or more planets associated with the lens - star ( which is typically an m dwarf ) .",
    "almost all the planets that have been detected and characterised via microlensing have relied on high - cadence follow - up observations from various groups that include @xmath1fun @xcite , robonet @xcite , planet @xcite and mindstep @xcite .",
    "the follow - up groups typically operate with small - field - of - view cameras , capable of observing only one event at a time , so event selection can have a significant effect on the yield of microlensing planets .",
    "the follow - up groups typically focus on two classes of events .",
    "first , @xcite have shown that , given the presence of a planet orbiting a lens star , a trajectory having a low impact parameter ( i.e. a high magnification ) is significantly more likely to intercept a central caustic and therefore produce an anomalous signal .",
    "thus events predicted to reach very high magnification are chosen for intensive observation over their peak magnification times .",
    "second , events that are observed to be undergoing an anomaly are priority targets for follow - up .",
    "unfortunately this second category of anomalous events is dominated by binary stars , rather than star - planet microlensing .    in order to select events from this category for intensive follow - up , rapid preliminary analysis of in - progress events",
    "is necessary . in this paper , we describe a new gpu - based code designed for rapid analysis of ongoing microlensing events .",
    "the layout of the paper is as follows . in section  [ section : gpu_architecture ]",
    "we describe briefly the gpu computing architecture on which the code is based . in sections  [ section :",
    "microlensing_model]-[section : refining_solutions ] we present the algorithms and implementation details .",
    "section  [ section : examples ] shows two examples of event analysis , and a summary is given in section  [ section : summary ] .",
    "a graphics processing unit ( gpu ) is a common component found in most desktop computers , but only recently has the potential of these devices for general computation been realized , in a range of disciplines from sciences to finance @xcite . by utilizing the large scale parallelization ability of gpus , increased performance",
    "can be achieved for some computational calculations if correctly incorporated .",
    "most importantly , gpu code is generally inherently scalable , and increases in the number of gpu cores per device continues to outpace developments in cpu technology ( see , for instance , @xcite ) .    for this code",
    ", we have adopted the compute unified device architecture ( cuda ) extensions to the c language , developed by nvidia corporation .",
    "a cuda - enabled device can be thought of as a grid of processing units ( cuda cores ) that can execute sets of instructions ( threads ) in parallel .",
    "blocks of up to 1024 threads ( on compute capability 2.0 ) can be coded to access an amount of shared memory , with different threads ( within a block ) able to access individual elements of an array .",
    "blocks can execute on the gpu either sequentially or in parallel , depending on their size and the number of computing cores in the device . at the device level ,",
    "groups of 32 threads within a block ( warps ) have hardware enforced parallel execution .",
    "blocks of threads and grids of blocks can have either 1- , 2- or 3-dimensional configurations ( in cuda compute capability 2.0 devices ) .",
    "additional to the shared memory ( with fast read - write performance ) , threads have access to a slower read - write access global memory , and a hardware - optimised read - only texture memory .",
    "both of these may be accessed by all threads , in all blocks of a single gpu function call .",
    "texture memory is designed to store 2- and 3-dimensional arrays , and the computing architecture is designed for very rapid access to neighbouring pixels .",
    "this allows , for instance , very fast bilinear interpolation of an image stored in texture memory .",
    "the characteristic angular scale for microlensing is the einstein radius , @xmath2 where @xmath3 is the total lens mass and @xmath4 and @xmath5 are the distances to the source and the lens respectively .",
    "the lensing equation for a point source and binary point - mass lens can be written @xmath6 where @xmath7 and @xmath8 are the masses of the individual lens components ( as a proportion of the total lens mass ) , @xmath9 and @xmath10 are their complex angular positions in the plane of the sky in units of the einstein radius @xcite .",
    "@xmath11 is the source position and @xmath12 is the image position .",
    "inversion of this equation gives a fifth - order complex polynomial for the image positions , with either 3 or 5 solutions .",
    "since surface brightness is preserved by gravitational lensing , the magnification of the source in image @xmath13 , @xmath14 where @xmath15 is the jacobian of the coordinate transformation from the source to the image plane . the total magnification is the sum of the individual image magnifications .",
    "the point - source model for a microlensing event is rarely adequate for the majority of recognised binary microlensing events . in these cases",
    ", the source tends to pass close - to , or over , a lens caustic , which serves to resolve the source . to model such events",
    ", we must use a methodology that accounts for the finite source size .",
    "the two most common algorithms for this are contour integration via stokes theorem @xcite and various refinements of ray shooting maps @xcite . in sections  [ section : coarse_grid_search]-[section : refining_solutions ] below",
    "we describe our strategy , that is based on the magnification map approach .",
    "adopting einstein - radius - normalized coordinates , set in the lens plane with the origin as the centre of mass of the lens and the lens masses lying on the @xmath9 axis , a binary microlensing event may be described by seven basic parameters : @xmath16 , the angular separation of the two lens components ; @xmath17 , the mass ratio of the lens components ; @xmath18 the distance of closest approach of the source to lens barycentre ; @xmath19 , the trajectory angle of the source measured from the positive axis that passes through both lens components ; @xmath20 the time of closest approach ; @xmath21 , the time for the source to move an angular distance of one einstein radius ; and @xmath22 , the angular source radius .",
    "the majority of ground - based microlensing photometry is derived using the difference - imaging method .",
    "the flux of a microlensing event , @xmath23 where @xmath24 is the flux of the star on the reference image , @xmath25 is the unlensed source star flux , @xmath26 is the flux due to blended objects and @xmath27 is the measured difference - image flux .",
    "the difference - flux model is therefore a linear function of the magnification , @xmath28 where @xmath29 is itself a non - linear function of the fundamental parameters @xmath30 .",
    "the first part of our modelling method is a search for viable regions of solution space in @xmath30 .    at the highest level",
    ", we set up a @xmath31 fixed grid in @xmath32 . for each @xmath33 pair",
    ", we generate a point - source magnification map , by solving the fifth - order polynomial inversion of eqn ( 2 ) for a uniform grid of source positions @xmath34 . for this calculation",
    ", each gpu thread independently computes the magnification for a given pixel in the map . the map is then convolved on the gpu , by a number of radially - symmetric source intensity profiles of different radii and fixed limb darkening ( @xmath35 ) .",
    "this produces a set of magnification maps corresponding to fixed @xmath22 values .",
    "we have adopted seven values of @xmath22 logarithmically - spaced over @xmath36 .",
    "our tests have shown that on currently available hardware it is faster to recompute these maps from scratch than to load them into memory from hard - disk storage .",
    "the magnification maps are loaded into gpu texture memory for the next stage of the analysis - a search over @xmath37 space for each given @xmath38 .      since @xmath18 is defined with respect to the centre of the binary lens , a search of trajectories in a magnification map over a grid of angles @xmath19 and impact parameters @xmath18 is liable to miss small caustic structures that are located far from the centre .",
    "these small ( planetary ) caustics can be critical in identifying binary lenses that include a low mass component . with this in mind ,",
    "we replace a search over @xmath18 with a search over fixed radial distances , @xmath39 , from the central regions of caustics .",
    "these radial distances are scaled by the sizes of the caustics , as shown in fig .",
    "[ fig : caustic_area_search_triple_a ] .",
    "search space about the caustics of a @xmath40 , @xmath41 binary .",
    "the coordinates @xmath42 are positions in the lens plane in einstein radius units relative to the mid - point of the lens masses .",
    "lens masses are marked by o symbols and the centres of the search spaces are marked by x. ]    we conduct a search over @xmath43 for a fixed grid of @xmath44 , where each @xmath44 pair is treated as a single block on the gpu .",
    "we refer to an @xmath44 pair as a _",
    "trajectory_. for this stage of the search , we use the simplex downhill method to locate a @xmath45 minimum . at each iteration of the downhill search",
    ", each gpu thread is used to compute the contribution to @xmath45 from a single observed data point . a given @xmath46 maps to a point ( @xmath47 ) on a linear trajectory defined by @xmath44 , through a given @xmath48 map .",
    "bilinear interpolation of the magnification maps stored in texture memory is used to retrieve the magnification @xmath49 for the time of each data point .",
    "there are several optimisations we make to improve the speed of the computation as follows .    1",
    ".   we use the observed peak - to - baseline magnitude range of the microlensing event to infer a minimum magnification that needs to take place in order for a trial trajectory to be a viable solution . the magnification as a function of position along a trajectory",
    "is quickly extracted from the point - source map and discarded if it does nt fulfil this minimum magnification criterion .",
    "2 .   in cases where the lightcurve is obviously near in shape to that of a single lens ( paczyski ) , we use the estimated single lens parameters as starting points for @xmath50 in the simplex .",
    "3 .   in cases where the lightcurve has , or is expected to contain , more than one peak",
    ", we reject trajectories where the point - source map contains fewer than the specified number of peaks .",
    "since we are using a fixed grid of @xmath51 , we have pre - computed a library that specifies the number of peaks in each trajectory .",
    "a peak is considered to be any point on a trajectory where the magnification gradient changes from positive to negative .",
    "4 .   in non - paczyski cases where we are able to specify the time of a single peak , @xmath20 and @xmath21",
    "are related by @xmath52 where @xmath53 is the input time of the peak from the data and @xmath54 is the distance along the trajectory of the peak from @xmath20 in units of einstein radii .",
    "@xmath54 is specified in our precomputed library . for a given trajectory",
    ", we can then adjust @xmath20 to best match the data in order to find our starting simplex parameters .",
    "the optimum situation occurs where the times of multiple peaks can be provided .",
    "this allows @xmath20 and @xmath21 to be solved analytically for each viable trajectory since , in addition to eqn .",
    "[ eqn:1_peak_alignment ] , @xmath55 where the @xmath56 are the set of specified times of peaks , and @xmath57 are the pre - computed model peak times in units of einstein radii .",
    "again , we use these values as starting points for the simplex search .",
    "the outcome of our coarse grid search is a set of viable regions of parameter space where we expect to find the global solution .",
    "[ fig : ob030235_hr_chi2_map ] shows an example of coarse - search results projected onto @xmath32 space .",
    "because of the coarseness of the @xmath58 grid , it is unreasonable to adopt the single best solution thus far found as being the likely seed for the global solution .",
    "thus we generally choose a number of local minima from the coarse search for further analysis . at this time , we adopt the three best wide solutions ( @xmath59 ) and narrow solutions ( @xmath60 ) as our seeds .     map in @xmath33 space for ogle-2003-blg-0235 .",
    "overlaid arrows show the movement from seed solutions during the mcmc search . ]",
    "to refine our seed solutions , we employ a markov chain monte carlo search . for this part of our modelling",
    ", we discard the magnification map approach and instead compute magnifications for a given set of trial parameters using an image - centred ray shooting algorithm similar to that of @xcite .",
    "the markov chain sampling is implemented in the python language with cuda c used to compute magnifications .    to implement our calculations on a gpu",
    ", we treat the epoch of each data point as a single block . within a block",
    ", we use groups of threads to perform integrations over images , with each thread corresponding to different locations on an image .",
    "initially we compute the locations of the caustics corresponding to the current @xmath38 .",
    "this information is shared with all blocks ( epochs ) .",
    "we then use 128 threads distributed over the caustic edges to establish the proximity of the source to its nearest caustic .",
    "for source - caustic distances greater than @xmath61 we use the point - source approximation for the magnification , otherwise we proceed with image - centred ray shooting calculations as follows .    again using 128 threads distributed around the source boundary and its centre , we compute image positions for these source points . resampling near the highest magnification points",
    "is performed in order to detect situations where a source is grazing a caustic .",
    "starting from the centre of each image , a polar grid is iteratively expanded until it encompasses the entire image .",
    "polar coordinates are used since images are often crescent shaped , approximately following the locus of the critical curves ( see fig .   [",
    "fig : critical_curves ] ) .",
    "tests are incorporated to detect merged images .",
    "we now integrate over each image with a weighting corresponding to the source intensity profile ( found by inverse ray shooting ) .",
    "to deal with the numerical problems introduced by the fact that the source intensity is zero at the boundaries , we follow the second - order integration scheme given by @xcite . individual threads are used as grid points for the integration and we invoke parallel summation with loop unrolling for rapid computation .      upon completion of local area mcmcs , the best solution is chosen from the chain that produced the lowest final @xmath45 model , which we regard as being close to the global minimum . from this solution",
    "the data errors are normalized by forcing @xmath45 per degree of freedom for each source of data to unity .",
    "although statistically undesirable , normalizing errors bars in this way prevents bias due to poorly - estimated uncertainties in particular data sources .",
    "we then use the sampler emcee @xcite along with cuda image - centered ray shooting to determine our final solution and parameter covariances .",
    "the inclusion of higher - order effects such as parallax and orbital motion can be incorporated in the gpu kernel to modify the source and lens positions when performing inverse ray shooting , at minimal computational cost .",
    "however , new challenges arise when incorporating these effects into a search strategy whilst maintaining high - performance .",
    "parallax ( and xallarap ) could , in principle , be added to the current grid search strategy , as they only affect the interpolated source trajectory .",
    "the inclusion of orbital motion at this stage is not possible since multiple @xmath62 magnification maps per trajectory would be required .",
    "these higher - order effects are typically only considered if necessary after the original seven parameters have been determined , at which point they are incorporated into the emcee search , which uses image - centred ray shooting .",
    "as demonstrations and verification of our code , we present results below for two well know events that have been previously analysed .",
    "this was the first microlensing event in which a planet was discovered , see @xcite .",
    "it has more recently been reanalysed by @xcite .",
    "data was taken by the ogle and moa survey telescopes that show a moderate magnification microlensing event ( @xmath63 ) that peaked at around jd 2452847 .",
    "the event shows a caustic passage that lasted for @xmath64 days from jd 2452834 . in table",
    "[ tab : modelsogl-2003-blg-0235 ] we show the solutions found by @xcite .    [ cols=\"^,^,^,^,^,^ \" , ]",
    "in this paper we have described a fast method for fitting binary gravitational microlensing events . the code is written in cuda c and python , and the computationally intensive parts are run on massively parallel gpu hardware . the code will scale naturally to higher performance as gpu technology evolves .    as part of our algorithms ,",
    "we introduce several optimisations that improve the ability to detect features due to small caustics and the speed of execution .",
    "results from our ongoing analysis of current events are reported through our website.u - lenser/ ]",
    "mda thanks the department of astronomy , university of wisconsin - madison , for hospitality during the writing of this paper .",
    "we thank nvidia corporation for supporting our work ."
  ],
  "abstract_text": [
    "<S> the rapid analysis of ongoing gravitational microlensing events has been integral to the successful detection and characterisation of cool planets orbiting low mass stars in the galaxy . in this paper </S>",
    "<S> we present an implementation of search and fit techniques on graphical processing unit hardware . </S>",
    "<S> the method allows for the rapid identification of candidate planetary microlensing events and their subsequent followup for detailed characterisation .    </S>",
    "<S> [ firstpage ]    methods : numerical , binaries : general , planetary systems , gravitational lensing : micro </S>"
  ]
}