{
  "article_text": [
    "one of the hardest challenges in modern eigenvalue computation is the numerical solution of large - scale eigenvalue problems , in particular those arising from quantum physics such as , e.g. , the anderson model of localization ( see section [ sect : anderson ] for details ) .",
    "typically , these problems require the computation of some eigenvalues and -vectors for systems which have up to several million unknowns due to their high spatial dimensions .",
    "furthermore , their underlying structure involves random perturbations of matrix elements which invalidates simple preconditioning appraoches based on the graph of the matrices .",
    "moreover , one is often interested in finding some eigenvalues and associated eigenvectors in the interior of the spectrum .",
    "the classical lanczos approach @xcite has lead to eigenvalue algorithms @xcite that are in principle able to compute these eigenvalues using only a small amount of memory .",
    "more recent work on implicitly started lanczos techniques @xcite has accelerated these methods significantly , yet to be fast one needs to combine this approach with shift - and - invert techniques , i.  e.  in every step one has to solve a shifted system of type @xmath2 , where @xmath3 is a shift near the desired eigenvalues and @xmath4 , @xmath5 is the associated matrix . in general shift - and - invert techniques",
    "converge rather quickly which is inline with the theory @xcite .",
    "still , an efficient solver is required to solve systems @xmath6 efficiently with respect to time and memory .",
    "while implicitly restarted lanczos techniques @xcite usually require to solve the system @xmath6 to maximum precision and thus are mainly suited for sparse direct solvers , the jacobi - davidsonmethod has become an attractive alternative @xcite in particular when dealing with preconditioning methods for linear systems .    until recently , sparse symmetric indefinite direct solvers were still far off from symmetric positive definite solvers and this might have been one major reason why shift - and - invert techniques were not able to compete with traditional lanczos techniques @xcite , in particular because of memory constraints . with the invention of fast matchings - based algorithms @xcite which improve the diagonal dominance of linear systems the situation has dramatically changed and the impact on preconditioning methods @xcite as well as the benefits for sparse direct solvers @xcite has been recognized .",
    "furthermore , these techniques have been successfully transferred to the symmetric case @xcite allowing modern state - of - the - art direct solvers @xcite to be orders of magnitudes faster and more memory efficient than ever , finally leading to symmetric indefinite sparse direct solvers that are almost as efficient as their symmetric positive definite counter parts . recently",
    "this approach has also been utilized to construct incomplete factorizations @xcite with similarly dramatic success . for a detailed survey on preconditioning techniques for large symmetric indefinite linear systems",
    "the interested reader should consult @xcite .",
    "in the present paper we combine the above mentioned advances with inverse - based preconditioning techniques @xcite .",
    "this allows us to find interior eigenvalues and -vectors for the anderson problem several orders of magnitudes faster than traditional algorithms @xcite while still keeping the amount of memory reasonably small .",
    "let us briefly outline our strategy",
    ". we will consider recent novel approaches in preconditioning methods for symmetric indefinite linear systems and eigenvalue problems and apply them to the anderson model . since the anderson model is a large - scale sparse eigenvalue problem in three spatial dimensions , the eigenvalue solvers we deal with",
    "are designed to compute only a few interior eigenvalues and eigenvectors avoiding a complete factorization .",
    "in particular we will use two modern eigenvalue solvers which we will briefly introduce in section [ sect : modern ] .",
    "the first one is arpack@xcite , which is a lanczos - type method using implicit restarts ( cf .",
    "section [ sect : arnoldi ] ) .",
    "we use this algorithm together with a shift - and - invert technique , i.  e.  eigenvalues and eigenvectors of @xmath7 are computed instead of those of @xmath8 .",
    "arpack  is used in conjunction with a direct factorization method and a multilevel incomplete factorization method for the shift - and - invert technique .",
    "firstly , we use the shift - and - invert technique with the novel symmetric indefinite sparse direct solver that is part of pardiso@xcite and we report extensive numerical results on the performance of this method . section [ sect : linear ] will give a short overview of the main concepts that form the pardiso  solver . secondly",
    ", we use arpack  in combination with the multilevel incomplete @xmath9 factorization package ilupack@xcite . here",
    "we present a new _ indefinite _ version of this preconditioner that is devoted to symmetrically indefinite problems and combines two basic ideas , namely ( i ) symmetric maximum weighted matchings @xcite and ( ii ) inverse - based decomposition techniques @xcite .",
    "these will be described in sections [ sect : match ] and [ sect : iterative ] .    as a second eigenvalue solver we use the symmetric version of the jacobi - davidson  method , in particular the implementation jdbsym@xcite .",
    "this newton - type method ( see section [ sect : jd ] ) is used together with ilupack@xcite . as we will see in several further numerical experiments",
    ", the synergy of both approaches will form an extremely efficient preconditioner for the anderson model that is memory efficient while at the same time accelerates the eigenvalue computations significantly : system sizes that resulted in weeks of computing time @xcite can now be computed within an hour .",
    "the anderson model of localization is a paradigmatic model describing the electronic transport properties of disordered quantum systems @xcite .",
    "it has been used successfully in amorphous materials such as alloys @xcite , semiconductors and even dna @xcite .",
    "its hallmark is the prediction of a spatial confinement of the electronic motion upon increasing the disorder  the so - called anderson _ localization _ @xcite .",
    "when the model is used in @xmath10 spatial dimensions , it exhibits a metal - insulator transition in which the disorder strength @xmath11 mediates a change of transport properties from metallic behavior at small @xmath11 via critical behavior at the transition @xmath12 and on to insulating behavior and strong localization at larger @xmath11 @xcite .",
    "mathematically , the quantum problem corresponds to a hamilton operator in the form of a real symmetric matrix @xmath8 , with quantum mechanical energy levels given by the eigenvalues @xmath13 , and the respective wave functions are simply the eigenvectors of @xmath8 , i.e.  vectors @xmath14 with real entries . with @xmath15 sites , the quantum mechanical ( stationary )",
    "schrdinger equation is equivalent to the eigenvalue equation @xmath16 , which in site representation reads as @xmath17 with @xmath18 denoting the cartesian coordinates of a site .",
    "the disorder enters the matrix on the diagonal where the entries @xmath19 correspond to a spatially varying disorder potential and are selected randomly according to a suitable distribution @xcite . here , we shall use the standard box distribution @xmath20 $ ] such that the @xmath11 parameterizes the aforementioned disorder strength .",
    "clearly , the eigenvalues of @xmath8 then lie within the interval @xmath21 $ ] . in most studies of the induced metal - insulator transition",
    ", @xmath11 ranges from @xmath22 to @xmath23 @xcite . but these values also depend on whether generalizations to random off - diagonal elements @xcite  the so - called random - hopping problem  , anisotropies @xcite or other lattice graphs @xcite are being considered .",
    "the intrinsic physics of the model is quite rich . for disorders @xmath24 ,",
    "the eigenvectors are extended , i.e.  @xmath25 is fluctuating from site to site , but the envelope @xmath26 is approximately a nonzero constant . for large disorders",
    "@xmath27 , all eigenvectors are localized such that the envelope @xmath28 of the @xmath29th eigenstate may be approximately written as @xmath30/l_n(w)$ ] with @xmath31 and @xmath32 denoting the _ localization length _ of the eigenstate . in figure [ fig - extloc_states ] ,",
    "we show examples of such states .",
    "note that @xmath33 and not @xmath14 corresponds to a physically measurable quantity and is therefore the observable of interest to physicists",
    ".     extended ( left ) and localized ( right ) wave function probabilities for the 3d anderson model with periodic boundary conditions at @xmath34 with @xmath35 and @xmath36 and @xmath37 , respectively . every site with probability @xmath38 larger than the average @xmath39",
    "is shown as a box with volume @xmath40 .",
    "boxes with @xmath41 are plotted with black edges .",
    "the color scale distinguishes between different slices of the system along the axis into the page.,title=\"fig : \" ]   extended ( left ) and localized ( right ) wave function probabilities for the 3d anderson model with periodic boundary conditions at @xmath34 with @xmath35 and @xmath36 and @xmath37 , respectively . every site with probability @xmath38 larger than the average @xmath39",
    "is shown as a box with volume @xmath40 .",
    "boxes with @xmath41 are plotted with black edges .",
    "the color scale distinguishes between different slices of the system along the axis into the page.,title=\"fig : \" ]    directly at @xmath42 , the extended states at @xmath43 vanish and no current can flow .",
    "the wave function vector @xmath14 appears simultaneously extended and localized as shown in fig.[fig - crit_state ] .",
    "plot of the electronic eigenstate at the metal - insulator transition with @xmath44 , @xmath45 and @xmath46 .",
    "the box - and - color scheme is as in fig .",
    "[ fig - extloc_states ] .",
    "note how the state _",
    "extends _ nearly everywhere while at the same time exhibiting certain _",
    "localized _ regions of higher @xmath38 values . ]    in order to numerically distinguish these three regimes , namely , localized , critical , and extended behaviors , one needs to ( i ) go to extremely large system sizes of order @xmath47 to @xmath48 and ( ii ) average over many different realizations of the disorder , i.e. , compute eigenvalues or eigenvectors for many matrices with different diagonals . in the present paper , we concentrate on the computation of a few eigenvalues and corresponding eigenvectors for the physically most interesting case of critical disorder @xmath12 and in the center of @xmath49 , i.e. , at @xmath43 , for large system sizes @xcite .",
    "since there is a high density of states for @xmath49 at @xmath50 in all cases , we have the further numerical challenge of clearly distinguishing the eigenstates in this high density region .",
    "since the mid - eighties , the preferred numerical tool to study the anderson matrix and to compute a selected set of eigenvectors , e.g.  as needed for a multifractal analysis at the transition , was provided by the cullum - willoughby implementation ( cwi ) @xcite of the lanczos algorithm .",
    "the algorithm iteratively generates a sequence of orthogonal vectors @xmath51 , @xmath52 , such that @xmath53 , with @xmath54 $ ] and @xmath55 a symmetric tridiagonal @xmath56 matrix . in exact arithmetic",
    ", the recursion @xmath57 where @xmath58 and @xmath59 are the diagonal and subdiagonal entries of @xmath55 and @xmath60 and @xmath61 is an arbitrary starting vector , is an orthogonal transformation to tridiagonal form that needs @xmath62 matrix - vector multiplications .",
    "the eigenvalues of the tridiagonal matrix @xmath55 ( ritz values ) are then simply the eigenvalues of the matrix @xmath8 and the associated ritz vectors yield the eigenvectors .    since @xmath8 is sparse and symmetric , the underlying matrix - vector multiplication on the cwi  can be programmed very efficiently , either by directly coding or appropriate sparse storage schemes  only the diagonal needs to be stored in any case . additionally , the cwi  is a lanczos implementation in which _ no reorthogonalization _ is performed .",
    "rather , spurious eigenvalues are identified by extending the set of ritz vectors to more than the @xmath63 present in exact arithmetic .",
    "typically , we find that @xmath64 is sufficient for all `` good '' eigenvalues to have replicated themselves at least twice  a further sign that the algorithm has converged .",
    "clearly , this strategy work well in the present case since the disorder destroys any symmetry - induced degeneracies .",
    "the cwi  is memory efficient and does not need elaborate reorthogonalization schemes , but does need to construct many ritz vectors which is computationally intensive .",
    "nevertheless , in 1999 cwi  was still significantly faster than more modern iterative schemes @xcite .",
    "the main reason for this surprising result lies in the indefiniteness of @xmath8 , which led to severe difficulties with solvers more accustomed to standard laplacian - type problems .",
    "when dealing with eigenvalues near a given real shift @xmath3 , the lanczos algorithm @xcite is usually accelerated when being applied to the shifted inverse @xmath7 instead of @xmath8 directly .",
    "this approach relies on the availability of a fast solution method for linear systems of type @xmath6 .",
    "however , the limited amount of available memory only allows for a small number of solution steps and sparse direct solvers also need to be memory - efficient to turn this approach into a practical method .",
    "the limited number of lanczos steps has lead to modern implicitly restarted methods @xcite which ensure that the information about the desired eigenvalues is inherited when being restarted . with increasing number of preconditioned iterative methods for linear systems @xcite ,",
    "lanczos - type algorithms have become less attractive mainly because in every iteration step the systems of type @xmath6 have to be solved to _ full _ accuracy in order to avoid false eigenvalues .",
    "in contrast to this , jacobi - davidson - like methods @xcite allow using a crude approximation of the underlying linear system .",
    "from the point of view of linear solvers as part of the eigenvalue computation , modern direct and iterative methods need to inherit the symmetric structure @xmath5 while remaining both time and memory efficient .",
    "symmetric matching algorithms @xcite have significantly improved these methods .",
    "the lanczos method for real symmetric matrices @xmath8 near a shift @xmath3 is based on computing successively orthonormal vectors @xmath65 $ ] and a tridiagonal @xmath66 matrix @xmath67 where @xmath68 is the @xmath69th unit vector in @xmath70 , such that @xmath71=[v_1,\\dots , v_k , v_{k+1}]\\underline{t_k}.\\ ] ] since only a limited number of lanczos vectors @xmath72 can be stored and since this lanczos sequence also consists of redundant information about undesired small eigenvalues , implicitly restarted lanczos methods have been proposed @xcite that use implicitly shifted @xmath73 @xcite exploiting the small eigenvalues of @xmath74 to remove them out of this sequence without ever forming a single matrix vector multiplication with @xmath7 .",
    "the new transformed lanczos sequence @xmath75=[\\tilde v_1,\\dots,\\tilde v_l,\\tilde v_{l+1}]\\underline{\\tilde t_l}\\ ] ] with @xmath76 then allows to compute further @xmath77 approximations .",
    "this approach is at the heart of the symmetric version of arpack@xcite .",
    "one of the major drawbacks of shift - and - invert lanczos algorithms is the fact that the multiplication with @xmath7 requires solving a linear system to full accuracy .",
    "in contrast to this , jacobi - davidson - like algorithms @xcite are based on a newton - like approach to solve the eigenvalue problem . like the lanczos method the search space",
    "is expanded step by step solving the correction equation @xmath78 where @xmath79 is the given approximate eigenpair and @xmath80 is the associated residual .",
    "then the search space based on @xmath81 $ ] is expanded by reorthogonalizing @xmath82 with respect to @xmath83 $ ] and a new approximate eigenpair is computed from the ritz approximation @xmath84^t a[v_k , z]$ ] . when computing several right eigenvectors , the projection @xmath85 has to be replaced by @xmath86[q , u]^t$ ] using the already computed approximate eigenvectors @xmath87 .",
    "this ensures that the new approximate eigenpair is orthogonal to those that have already been computed .",
    "the most important part of the jacobi - davidson  approach is to construct an approximate solution for ( [ correction ] ) such that @xmath88 and @xmath89 that allows a fast solution of the system @xmath90 . here",
    ", there is a strong need for robust preconditioning methods that preserve symmetry and efficiently solve sequences of linear systems with @xmath91 .",
    "if @xmath91 is itself symmetric and indefinite , then the simplified qmr method @xcite using the preconditioner @xmath92 , where @xmath93 and the system matrix @xmath94 can be used as iterative method .",
    "note that here the accuracy of the solution of ( [ correction ] ) is uncritical until the approximate eigenpair converges @xcite .",
    "this fact has been exploited in jdbsym@xcite . for an overview on jacobi - davidson  methods for symmetric matrices",
    "see @xcite .",
    "we now report on recent improvements in solving symmetric indefinite systems of linear equations that have significantly changed sparse direct as well as preconditioning methods .",
    "one key role that made these approaches successful is played by the use of symmetric matchings that we review in section [ sect : match ] .      for a long time dynamic",
    "pivoting has been a central point for nonsymmetric sparse linear solvers to gain stability .",
    "therefore , improvements in speeding up direct factorization methods were limited to the uncertainties that have arisen from using pivoting .",
    "certainly techniques like the column elimination tree @xcite have been a useful tool to predict the sparsity pattern despite pivoting .",
    "however , in the symmetric case the situation becomes more complicated since only symmetric reorderings applied to both , columns and rows , are required and no a - priori choice of pivots is given .",
    "this makes it almost impossible to predict the elimination tree in a sensible manner and the use of cache - oriented level-@xmath10 blas @xcite was impossible .    with the introduction of symmetric maximum weighted matchings @xcite as alternative to complete pivoting",
    "it is now possible to treat symmetric indefinite systems almost similar to symmetric positive definite systems .",
    "this allows the prediction of fill using the elimination tree @xcite and thus to set up the data structures that are required to predict dense submatrices ( also known as supernodes ) .",
    "this in turn means that one is able to exploit level-3 blas applied to the supernodes .",
    "consequently , the classical bunch - kaufman pivoting approach @xcite need to be performed only inside the supernodes .",
    "this approach has recently been successfully implemented in the sparse direct solver pardiso@xcite and as a major consequence , this novel approach has improved the sparse indefinite solver to become almost as efficient as its symmetric positive analogy . certainly for the anderson problem studied here ,",
    "pardiso  is about 2 orders of magnitude more efficient than previously used direct solvers @xcite .",
    "we also note that the idea of symmetric weighted matchings can be carried over to incomplete factorization methods with similar success @xcite .",
    "symmetric weighted matchings @xcite , which will be explained in detail in section [ sec : symmetric ] , can be viewed as a preprocessing step that rescales the original matrix and at the same time improves the block diagonal dominance . by this strategy ,",
    "all entries are at most one in modulus and in addition the diagonal blocks are either @xmath95 scalars @xmath96 such that @xmath97 ( in exceptional cases we will have @xmath98 ) or they are @xmath99 blocks @xmath100 symmetric reorderings to improve the results of pivoting on restricted subsets ------------------------------------------------------------------------------    in this section we will discuss weighted graph matchings as an additional preprocessing step . the motivation for weighted matching approaches is to identify large entries in the coefficient matrix @xmath8 that , if permuted close to the diagonal , permit the factorization process to identify more acceptable pivots and proceed with fewer pivot perturbations . these methods are based on maximum weighted matchings @xmath101 and improve the quality of the factor in a complementary way to the alternative idea of using more complete pivoting techniques .",
    "the idea to use a permutation @xmath102 associated with a weighted matching @xmath101 as an approximation of the pivoting order for nonsymmetric linear systems was firstly introduced by olschowka and neumaier @xcite and extended by duff and koster @xcite to the sparse case .",
    "permuting the rows @xmath103 of the sparse system to ensure a zero - free diagonal or to maximize the product of the absolute values of the diagonal entries are techniques that are now often regularly used for nonsymmetric matrices @xcite .",
    "let @xmath104 be a general matrix .",
    "the nonzero elements of @xmath8 define a graph with edges @xmath105 of ordered pairs of row and column indices .",
    "a subset @xmath106 is called a matching or a transversal , if every row index @xmath107 and every column index @xmath108 appear at most once in @xmath101 .",
    "a matching @xmath101 is called perfect if its cardinality is @xmath29 . for a nonsingular matrix at least one",
    "perfect matching exists and can be found with well known algorithms . with a perfect matching @xmath101 ,",
    "it is possible to define a permutation matrix @xmath109 with : @xmath110 as a consequence , the permutation matrix @xmath111 has nonzero elements on its diagonal .",
    "this method only takes the nonzero structure of the matrix into account .",
    "there are other approaches which maximize the diagonal values in some sense .",
    "one possibility is to look for a matrix @xmath102 , such that the product of the diagonal values of @xmath111 is maximal .",
    "in other words , a permutation @xmath3 has to be found , which maximizes @xmath112 this maximization problem is solved indirectly .",
    "it can be reformulated by defining a matrix @xmath113 with @xmath114 where @xmath115 , i.e.  the maximum element in row @xmath107 of matrix @xmath8 .",
    "a permutation @xmath3 , which minimizes @xmath116 also maximizes the product  ( [ eq:1 ] ) .",
    "the minimization problem is known as linear sum assignment problem or bipartite weighted matching problem in combinatorial optimization .",
    "the problem is solved by a sparse variant of the kuhn - munkres algorithm .",
    "the complexity is @xmath117 for full @xmath118 matrices and @xmath119 for sparse matrices with @xmath120 entries . for matrices",
    "whose associated graph fulfills special requirements , this bound can be reduced further to @xmath121 with @xmath122 .",
    "all graphs arising from finite - difference or finite - element discretizations meet these conditions  @xcite .",
    "as before , we finally get a perfect matching @xmath101 that in turn defines a nonsymmetric permutation @xmath102 .",
    "@xmath123    @xmath124 @xmath125 @xmath126    the effect of nonsymmetric row permutations using a permutation associated with a matching @xmath101 is shown in figure [ fig : unsym_perm ] .",
    "it is clearly visible that the matrix @xmath111 is now nonsymmetric , but has the largest nonzeros on the diagonal .      in the case of symmetric indefinite matrices , we are interested in symmetrically permuting @xmath129 .",
    "the problem is that zero or small diagonal elements of @xmath8 remain on the diagonal by using a symmetric permutation @xmath130 .",
    "alternatively , instead of permuting a large . ]",
    "off - diagonal element @xmath131 nonsymmetrically to the diagonal , one can try to devise a permutation @xmath132 such that @xmath133 permutes this element close to the diagonal . as a result ,",
    "if we form the corresponding @xmath128 block to @xmath134 $ ] , we expect the off - diagonal entry @xmath131 to be large and thus the @xmath128 block would from a suitable @xmath128 pivot for the supernode - bunch - kaufman factorization .",
    "an observation on how to build @xmath132 from the information given by a weighted matching @xmath101 was presented by duff and gilbert @xcite .",
    "they noticed that the cycle structure of the permutation @xmath102 associated with the nonsymmetric matching @xmath101 can be exploited to derive such a permutation @xmath132 .",
    "for example , the permutation @xmath102 from figure [ fig : unsym_perm ] can be written in cycle representation as @xmath135 .",
    "this is shown in the upper graphics in figure [ fig : sym_perm ] .",
    "the left graphic displays the cycles @xmath136 , @xmath137 and @xmath138 . if we modify the original permutation @xmath139 into this cycle permutation @xmath140 and permute @xmath8 symmetrically with @xmath141 , it can be observed that the largest elements are permuted to diagonal blocks .",
    "these diagonal blocks are shown by filled boxes in the upper right matrix .",
    "unfortunately , a long cycle would result into a large diagonal block and the fill - in of the factor for @xmath142 may be prohibitively large .",
    "therefore , long cycles corresponding to @xmath143 must be broken down into disjoint @xmath128 and @xmath127 cycles .",
    "these smaller cycles are used to define a symmetric permutation @xmath144 , where @xmath145 is the total number of @xmath128 and @xmath127 cycles .",
    "the rule for choosing the @xmath128 and @xmath127 cycles from @xmath146 to build @xmath132 is straightforward .",
    "one has to distinguish between cycles of even and odd length .",
    "it is always possible to break down even cycles into cycles of length two . for each even cycle , there are two possibilities to break it down .",
    "we use a structural metric @xcite to decide which one to take .",
    "the same metric is also used for cycles of odd length , but the situation is slightly different .",
    "cycles of length @xmath147 can be broken down into @xmath148 cycles of length two and one cycle of length one .",
    "there are @xmath147 different possibilities to do this .",
    "the resulting @xmath149 blocks will contain the matched elements of @xmath101 . however , there is no guarantee that the remaining diagonal element corresponding to the cycle of length one will be nonzero",
    ". our implementation will randomly select one element as a @xmath127 cycle from an odd cycle of length @xmath147 .",
    "@xmath8 :    @xmath142 =    @xmath8 :    @xmath133 =    a selection of @xmath132 from a weighted matching @xmath102 is illustrated in figure [ fig : sym_perm ] .",
    "the permutation associated with the weighted matching , which is sorted according to the cycles , consists of @xmath150 .",
    "we now split the full cycle of odd length three into two cycles @xmath151  resulting in @xmath152 .",
    "if @xmath132 is symmetrically applied to @xmath153 , we see that the large elements from the nonsymmetric weighted matching @xmath101 will be permuted close to the diagonal and these elements will have more chances to form good initial @xmath127 and @xmath128 pivots for the subsequent ( incomplete ) factorization",
    ".    good fill - in reducing orderings @xmath154 are equally important for symmetric indefinite systems .",
    "the following section introduces two strategies to combine these reorderings with the symmetric graph matching permutation @xmath132",
    ". this will provide good initial pivots for the factorization as well as a good fill - in reduction permutation .      in order to construct the factorization efficiently",
    ", care has to be taken that not too much fill - in is introduced during the elimination process .",
    "we now examine two algorithms for the combination of a permutation @xmath132 based on weighted matchings to improve the numerical quality of the coefficient matrix @xmath8 with a fill - in reordering @xmath154 based on a nested dissection from metis @xcite .",
    "the first method is based on compressed subgraphs and has also been used by duff and pralet in @xcite in order to find good scalings and orderings for symmetric indefinite systems .    in order to combine the permutation @xmath132 with a fill - in reducing permutation",
    ", we compress the graph of the reordered system @xmath133 and apply the fill - in reducing reordering to the compressed graph . in the compression step , the union of the structure of the two rows and columns corresponding to a @xmath128 diagonal block are built , and used as the structure of a single , compressed row and column representing the original ones .",
    "if @xmath155 is the undirected graph of @xmath8 and a cycle consists of two vertices @xmath156 , then graph compression will be done on the @xmath127 and @xmath128 cycles , which have been found using a weighted matching @xmath101 on the graph .",
    "the vertices @xmath157 are replaced with a single supervertex @xmath158 in the compressed graph @xmath159 .",
    "an edge @xmath160 between two supervertices @xmath161 and @xmath162 exists if at least one of the following edges exist in @xmath163 or @xmath164 .",
    "the fill - in reducing ordering is found by applying metis on the compressed graph @xmath159 .",
    "expansion of that permutation to the original numbering yields @xmath165 .",
    "hence all @xmath128 cycles that correspond to a suitable @xmath128 pivot block are reordered consecutively in the factor .",
    "we now present a new symmetric indefinite approximate multilevel factorization that is mainly based on three parts which are repeated in a multilevel framework in each subsystem .",
    "the components consist of ( i ) reordering of the system , ( ii ) approximate factorization using inverse - based pivoting and , ( iii ) recursive application to the system of postponed updates .",
    "the key ingredient to turn this approach into an efficient multilevel solver consists of the symmetric maximum weight matching presented in section [ sect : match ] .",
    "after the system is reordered into a representation @xmath166 where @xmath167 , @xmath168 is a diagonal matrix and @xmath169 is a permutation matrix , @xmath170 is expected to have many diagonal blocks of size @xmath95 or @xmath99 that are well - conditioned .",
    "once the diagonal block of size @xmath95 and @xmath99 are built , the associated block graph of @xmath170 is reordered by a symmetric reordering , e.  g.  amd  @xcite or metis@xcite , i.  e.@xmath171 where @xmath172 refers to the associated symmetric block permutation .      given @xmath173",
    "we compute an incomplete factorization @xmath174 of @xmath173 . to do this at step @xmath69 of the algorithm",
    "we have @xmath175 where @xmath176 is lower triangular with unit diagonal and @xmath177 is block diagonal with diagonal blocks of size @xmath178 and @xmath99 .",
    "also , @xmath179 denotes the approximate schur complement . to proceed with the incomplete factorization",
    "we perform either a @xmath95 update or a @xmath180 block update .",
    "one possible choice could be to use bunch s algorithm @xcite .",
    "this approach has been used in ref.@xcite .",
    "here we use a simple criterion based on block diagonal dominance of the leading block column . depending on the values",
    "@xmath181 we perform a @xmath99 update only if @xmath182 .",
    "the leading two columns of @xmath183 can be efficiently computed using linked lists @xcite and it is not required to have all entries of @xmath183 available .",
    "when applying the ( incomplete ) factorization @xmath0 to @xmath173 we may still encounter a situation where at step @xmath69 either @xmath184 or @xmath185 is large or even infinity .",
    "since we are dealing with an incomplete factorization we propose to use inverse - based pivoting @xcite .",
    "therefore we require in every step that @xmath186 for a prescribed bound @xmath187 .",
    "if after the update using a @xmath95 pivot ( or @xmath99 pivot ) the norm of the inverse lower triangular factor fails to be less than @xmath187 , the update is postponed and the leading rows / columns of @xmath188 , @xmath183 are permuted to the end .",
    "otherwise depending on whether a @xmath178 or a @xmath99 pivot has been selected , the entries @xmath189 become the next ( block ) column of @xmath190 and we drop these entries whenever their absolute value is less than @xmath191 for some threshold @xmath192 . for a detailed description see ref .",
    "the norm of the inverse can cheaply be estimated using a refined strategy of ref .",
    "@xcite and is part of the software package ilupack  that is now extended to the symmetric indefinite case @xcite .",
    "after the inverse - based ilu we have an approximate factorization @xmath193 and it typically does not pay off to continue the factorization for the remaining matrix @xmath194 which consists of the previously postponed updates . thus @xmath194 is now explicitly computed and the strategies for reordering , scaling and factorization are recursively applied to @xmath194 leading to a multilevel factorization .    note that in order to save memory @xmath195 is not stored but implicitly approximated by @xmath196 .",
    "in addition we use a technique called _ aggressive dropping _ that sparsifies the triangular factor @xmath190 a posteriori . to do this observe that when applying a perturbed triangular factor @xmath197 for preconditioning instead of @xmath198 we have @xmath199 we can expect that @xmath200 serves as a good approximation to @xmath198 as long as @xmath201 .",
    "if we obtain @xmath202 from @xmath190 by dropping some entry , say @xmath203 from @xmath190 , then we have to ensure that @xmath204 for some moderate constant @xmath205 , e.g. @xmath206 .",
    "to do this it is required to have a good estimate for @xmath207 available , for any @xmath208 . in principle",
    "it can be computed @xcite using @xmath209 instead of @xmath210 .",
    "last , knowing how many entries exist in column @xmath108 , we could drop any @xmath203 such that @xmath211      by construction , the computed incomplete multilevel factorization is symmetric but indefinite . for the iterative solution of linear systems using the multilevel factorization , in principle different krylov",
    "subspace solvers could be used .",
    "for example , general methods that do not explicitly use symmetry ( e.g. gmres @xcite ) or methods like symmlq @xcite which preserve the symmetry of the orginal matrix but which are only devoted for symmetric positive definite preconditioners . to fully exploit both , symmetry and indefiniteness at the same time , here",
    "the simplified qmr method @xcite is chosen .",
    "here we present numerical experiments that show that the previously outlined advances in symmetric indefinite sparse direct solvers as well as in preconditioning methods significantly accelerate modern eigenvalue solvers and allow us to gain orders of magnitude in speed compared to more conventional methods .",
    "all large scale numerical experiments for the anderson model of localization were performed on an sgi altix 3700/bx2 with 56 intel itanium2 1.6 ghz processors and 112 gb of memory .",
    "if not explicitly stated , we always used only one processor of the system and all algorithms were implemented in either c or fortran77 .",
    "all codes were compiled by the intel v8.1 compiler suite using _ ifort _ and _ icc _ with the -o3 optimization option and linked with basic linear algebra subprograms optimized for intel architectures . for completeness ,",
    "let us recall the main software packages used .",
    "* arpack is a collection of fortran77 subroutines designed to solve large scale eigenvalue problems .",
    "the eigenvalue solver has been developed at the department of computational and applied mathematics at rice university .",
    "it is available at http://www.caam.rice.edu/software/arpack .",
    "* jdbsym  is a c library implementation of the jacobi - davidson  method optimized for symmetric eigenvalue problems .",
    "it solves eigenproblems of the form @xmath16 and @xmath212 with or without preconditioning , where a is symmetric and b is symmetric positive definite .",
    "it has been developed at the computer science department of the eth zurich and is available at http://people.web.psi.ch/geus/software.html .",
    "* pardiso  is a fast direct solver package , developed at the computer science department of the university of basel and available at http://www.computational.unibas.ch/cs/scicomp/software/pardiso .",
    "* ilupack  is an algebraic multilevel preconditioning software package .",
    "this iterative solver has been developed at the mathematics department of the technical university of berlin .",
    "it is available at http://www.math.tu-berlin.de/ilupack .      in our numerical experiments",
    "we will first compare the classical cwi with the shift - and - invert lanczos method using implicit restarts .",
    "the latter is part of arpack@xcite .",
    "for the solution of the symmetric indefinite system @xmath213 we use the most recent version of sparse direct solver pardiso@xcite .",
    "this version is based on symmetric weighted matchings and uses metis as symmetric reordering strategy .",
    "the numerical results deal with the computation of @xmath214 eigenvalues of the anderson matrix @xmath8 near @xmath215 . here",
    "we state the results for the physically most interesting critical disorder strength @xmath216 ( cf .",
    "table [ tab : cpu - pardiso - cwi ] ) .",
    "as can be seen from table [ tab : cpu - pardiso - cwi ] , the pardiso - based shift - and - invert lanczos is clearly superior to the classic cwi method by at least one order of magnitude regarding computation time . despite this success , with increasing problem size the amount of memory consumed by the sparse direct solver becomes significant and numerical results @xmath63 larger than @xmath217 are skipped .",
    ".cpu times in seconds and memory requirements in gb to compute at @xmath45 five eigenvalues closest to @xmath215 of an anderson matrix of size @xmath218 with cwi and arpack - pardiso .",
    "for cwi  and @xmath219 , not all @xmath214 eigenvalues converged successfully , so the eigenvector reconstruction finished quicker , leading to apparently shorter cpu times ( @xmath220 ) .",
    "[ cols= \" > , > , > , > , > , > \" , ]     [ tab : mem - hb ]",
    "we have shown that modern approaches to preconditioning based on symmetric matchings and multilevel preconditioning methods lead to an astonishing increase in performance and available system sizes for the anderson model of localization .",
    "this approach is not only several orders of magnitudes faster than the traditional cwi approach , it also consumes only a moderate amount of memory thus allowing to study the anderson eigenproblem for significantly larger scales than ever before .",
    "let us briefly recall the main ingredients necessary for this progress : at the heart of the new approach lies the use of symmetric matchings @xcite in the preconditioning stage of the inverse - based incomplete factorization preconditioning iterative method @xcite .",
    "furthermore , the preconditioning itself is of a multi - level type , complementary to the often used full - pivoting strategies .",
    "next , the inverse - based approach is also of paramount importance to keep the fill - in at a manageable level ( see table [ tab : inverse - bound ] ) . and",
    "last , we emphasize that these results , of course , reflect our selected problem class : to compute a few of the interior eigenvalues and associated eigenvectors for a highly indefinite symmetric matrix defined by the anderson model of localization .",
    "the performance increase by several orders of magnitude ( see table [ tab : cpu - cwi - jd ] ) is solely due to our use of new and improved algorithms . combined with advances in the performance to cost ratio of computing hardware during the last 6 years period , current preconditions methods",
    "makes it possible to solve those problems quickly and easily which have been considered by far too large until recently @xcite . even for @xmath221 matrices as large as @xmath222",
    ", it is now possible within a few days to compute the interior eigenstates of the anderson problem .",
    "the success of this method indicates that it might also be successfully applied to other large - scale problems arising in ( quantum ) physics .",
    "we gratefully acknowledge discussions and implementation help from a.  croy and c.  sohrmann in the initial stages of the project .                                                                      height 2pt depth -1.6pt width 23pt , _ the jacobi  davidson algorithm for solving large sparse symmetric eigenvalue problems with application to the design of accelerator cavities _ , phd thesis , eth zrich , department informatik , institut f. wissenschaftliches rechnen , 2002 .          , _ a fast maximum - weight - bipartite - matching algorithm for reducing pivoting in sparse gaussian elimination _ , tech .",
    "report rc 21576 ( 97320 ) , ibm t. j. watson research center , yorktown heights , ny , october 1999 .                                    , _ the anderson transition and its ramifications  localisation , quantum interference , and interactions _ , springer , berlin , 2003 , ch .",
    "numerical investigations of scaling at the anderson transition , pp .  319 .        , _ on fast factorization pivoting methods for symmetric indefinite systems _ , technical report , computer science department , university of basel , switzerland , 2004 . submitted to electronic transactions on numerical analysis .      , _ the effects of unsymmetric matrix permutations and scalings in semiconductor device and circuit simulation _",
    ", ieee transactions on computer - aided design of integrated circuits and systems , 23 ( 2004 ) ."
  ],
  "abstract_text": [
    "<S> we propose efficient preconditioning algorithms for an eigenvalue problem arising in quantum physics , namely the computation of a few interior eigenvalues and their associated eigenvectors for the largest sparse real and symmetric indefinite matrices of the anderson model of localization . </S>",
    "<S> we compare the lanczos algorithm in the 1987 implementation by cullum and willoughby with the shift - and - invert techniques in the implicitly restarted lanczos method and in the jacobi - davidson method . </S>",
    "<S> our preconditioning approaches for the shift - and - invert symmetric indefinite linear system are based on maximum weighted matchings and algebraic multilevel incomplete @xmath0 factorizations . </S>",
    "<S> these techniques can be seen as a complement to the alternative idea of using more complete pivoting techniques for the highly ill - conditioned symmetric indefinite anderson matrices . </S>",
    "<S> we demonstrate the effectiveness and the numerical accuracy of these algorithms . </S>",
    "<S> our numerical examples reveal that recent algebraic multilevel preconditioning solvers can accelerative the computation of a large - scale eigenvalue problem corresponding to the anderson model of localization by several orders of magnitude .    anderson model of localization , large  scale eigenvalue problem , lanczos algorithm , jacobi  davidson algorithm , cullum  willoughby implementation , symmetric indefinite matrix , multilevel  preconditioning , maximum weighted matching    65f15 , 65f50 , 82b44 , 65f10 , 65f05 , 05c85    large - scale diagonalization techniques @xmath1 </S>"
  ]
}