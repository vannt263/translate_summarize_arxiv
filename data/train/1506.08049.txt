{
  "article_text": [
    "the groundwork for information thermodynamics was laid down by maxwell as part of his now infamous thought experiment ` maxwell s dmon '  @xcite . in the experiment , a sentient agent monitors the motion of thermal particles inside a partitioned container . by operating a small gate in the partition , fast - moving particles are allowed to move to one side of the partition while slow moving particles are allowed to move to the other side , thus heating up the first side and decreasing the overall entropy of the system .    while first conceived to elucidate the statistical subtleties of the 2^nd^ law of thermodynamics , the experiment has since sparked many debates  @xcite on the nature of the perceived violation of the 2^nd^ law .",
    "note that these violations relate to the ensemble average and are different from the temporary violations occuring on the level of individual trajectories or events  @xcite .",
    "the culmination of nearly 150 years of discussions about maxwell s dmon has been the framework of information thermodynamics  @xcite , which illuminates the profound importance of information in thermodynamics  @xcite . by including the effect of system memory  @xcite and/or information processing ( often thought to be performed by the feedback device , referred to as a ` dmon '  @xcite ) , the 2^nd^ law can be reformulated to include information entropy and used to study the operation of finite - time thermodynamic systems  @xcite such as information heat engines  @xcite .",
    "` information heat engines ' are a class of thermodynamic systems that use information processing to do thermodynamic work without the need for a change in free energy  @xcite",
    ". methods such as feedback control allow the engine to use information gained about a physical system to decrease the system entropy and hence extract useful work from the system  @xcite .",
    "this does not constitute a violation of the 2^nd^ law as it is understood that the operation of the feedback device entails an amount of entropy production at least equal and opposite to that change in the system  @xcite .",
    "a quantitative relationship between entropy and information is provided by the information thermodynamic framework , which gives the universal upper bound on the mean negative entropy production that can be obtained by feedback control  @xcite .",
    "to be precise , the ` 2^nd^ law of information thermodynamics ' states that the entropy production @xmath0 , of a system up to time @xmath1 is related to the information , @xmath2 , gained by the dmon via the inequality  @xcite @xmath3 where the angle brackets denote the ensemble average . in fact , this turns out to be a corollary of the generalised integral fluctuation theorem  @xcite ( itself a generalisation of the jarzynski equality  @xcite ) , @xmath4 this implies that for @xmath5 , @xmath6 that is , the standard integral fluctuation theorem does not hold in the presence of feedback  @xcite .",
    "these results have been experimentally verified in small systems , where thermal fluctuations have a strong influence  @xcite . in previous theoretical studies ,",
    "the quantity @xmath2 and its relation to @xmath0 has been discussed in the context of langevin equations and continuous - time markov chains  @xcite , and the mutual information between the feedback controller and the stochastic system has been considered for systems with discrete events  @xcite .    here",
    ", we study an abstract model of an ` information motor '  @xcite .",
    "the information motor discussed here is type of ratchet that is able to move a single particle against a bias using only the particle s own random motion and a feedback mechanism .",
    "specifically , this model allows us to demonstrate a method for calculating the information @xmath2 in a discrete - time feedback system and to study its fluctuation properties .",
    "the paper is structured as follows .",
    "[ sec : engines ] contains an overview of the existing information thermodynamic framework . in this section",
    "we also detail the method used for calculating the information gained ( in a single measurement ) . in sec .  [",
    "sec : model ] we describe our simple model of a maxwell s dmon type feedback system . in sec .",
    "[ sec : largedeviations ] we discuss the fluctuations of information on the level of individual trajectories and how to obtain large deviation rate functions . in sec .",
    "[ sec:2sitemodel ] we obtain exact expressions for the large deviation rate function in a two - site version of our model . in sec .",
    "[ sec : lstepmodel ] we then give a detailed approximate analysis and obtain numerical results for larger information engines . in sec .",
    "[ sec : discussion ] we conclude by summarising our results and discussing potential further work and open questions .",
    "the appendices contain further details of the two - site system and properties of individual trajectories .",
    "for simplicity s sake , let us consider a stochastic system evolving in discrete time and having states in some finite state space of size @xmath7 . the state of the system at a time @xmath8 is represented as a random variable @xmath9 with a specific realisation denoted by @xmath10 .",
    "a trajectory of the system is written @xmath11 with a specific realisation denoted by @xmath12 .",
    "the probability of a transition between states @xmath13 and @xmath14 is written as @xmath15 .    for a system subject to general feedback , we consider that the transition probabilities are determined by some other parameter referred to as the control parameter . in purely ` open - loop ' control ,",
    "the control parameter is independent of the system state .",
    "however , in the case of ` closed loop ' or ` feedback ' control , the system s evolution influences the control parameter in a closed causal loop  @xcite .    in the case of maxwell s dmon ,",
    "the dmon is identified as a feedback controller  @xcite whose activity can be described by two processes , measurement and control .",
    "the measurement is the process that allows the controller to select a control parameter to ` feed ' back into the system via the control process as described above .",
    "the measurement is represented in a similar fashion to the system trajectory , and is written as @xmath16 .",
    "the measurement @xmath17 at time @xmath8 only depends on the current state @xmath9 and so we denote , @xmath18 \\label{eq : error}\\ ] ] as the probability of obtaining outcome @xmath19 given that the system is in state @xmath10 . here",
    "we assume an injective mapping between measurement outcomes and control parameters , that is , a given measurement @xmath19 determines a unique control parameter and thus along with the departure state @xmath10 determines the probability of transitions to the next state @xmath20 ; we write this as @xmath21    the conditional distribution in   is derived from @xmath22 , the path space measure of the full process @xmath23 .",
    "this process is a markov chain on the state space given by @xmath24 and @xmath25 pairs and can be described by the transition matrix @xmath26 we also write @xmath27 $ ] and @xmath28 $ ] for the marginal distributions of the process and measurement trajectories respectively .",
    "note that , while the measurements @xmath17 are conditionally independent given the path @xmath29 , the marginal measurement process @xmath30 exhibits correlations after integrating out @xmath29 and is not a sequence of independent identically distributed ( i.i.d . )",
    "random variables . extending the definition in  @xcite , the entropy production at time @xmath8 as a function of a given trajectory @xmath31 in a feedback system",
    "is @xmath32    as mentioned above , for a system with feedback it is also necessary to quantify and study the information gained through measurement .",
    "when considering the information gained in a single measurement , we follow  @xcite and use the ` change in uncertainty ' , an information theoretic quantity that quantifies the information gained upon making an observation of some process . for a single measurement",
    "this is given by @xmath33 for all @xmath34 , where @xmath35 .",
    "\\label{eq : ysgiveny}\\ ] ]    defining @xmath36 $ ] , the denominator term in   is given by @xmath37 , \\nonumber\\\\ & = \\sum_{\\mathbf{x}_{s+1 } } \\pi_0(x_0)\\prod_{u=0}^{s}\\omega(x_u\\to x_{u+1 } { \\:\\vert\\:}y_u)p(y_u{\\:\\vert\\:}x_u ) .",
    "\\label{eq : pydef}\\end{aligned}\\ ] ] we can evaluate   by writing the sum as a matrix product , representing the terms in the sum as the elements of matrices @xmath38 we write the initial probability distribution as a vector @xmath39 and also define a summation vector of length @xmath7 , @xmath40 .",
    "we can then write @xmath41 as @xmath42    for any given series of measurements @xmath43 we can calculate @xmath41 .",
    "each of the matrices has a size @xmath44 and we must multiply @xmath1 of these matrices to calculate the information obtained up to time - step @xmath1 .",
    "eq .   can then be written as @xmath45 we will see in sec .",
    "[ sec:2sitemodel ] that this representation of @xmath46 also clarifies potential cancellation of terms in the products .",
    "here we are interested in the fluctuations of the total information gained @xmath2 , which is obtained by summing terms   along a given trajectory @xmath47 .",
    "this yields @xmath48 here we have used the conditional independence of the measurements @xmath49 , defined @xmath50 such that @xmath51 and used @xmath52 .",
    "we consider a model that abstractly resembles a recent experimental set - up involving a colloidal particle rotating in an electric field  @xcite . the experimental system demonstrated a type of particle ratchet where a field can be switched and shifted along with the motion of the particle in order to block it from moving . by ratcheting in this way , the particle s own thermal motion",
    "can be used to do work .",
    "our model is comprised of a random walk on a one dimensional lattice with a movable barrier . the random walk acts as an analogy to the colloidal particle in the experiment , with the walker s random motion modeling the thermal motion of the experimental particle .",
    "we model in discrete space , as in the real experiment there was a single coarse - grained measurement , essentially allowing the identification of discrete ` states ' .",
    "furthermore , the measurements were performed at regular intervals which allows the whole feedback process to be thought of in discrete time - steps . in our model ,",
    "the random walker moves between sites on a lattice of size @xmath7 with periodic boundary conditions and probabilities @xmath53 and @xmath54 of jumping respectively left and right at each time - step , such that @xmath55 . the random walker s motion is then described by a single parameter @xmath54 , which in the case where @xmath56 describes a system with a bias in one direction . without loss of generality , we consider @xmath57 for biased systems .",
    "we label jumps left as ` down ' , and jumps right as ` up ' as though the particle were moving in a potential .    in the spirit of the feedback process described in  @xcite , at each time - step a measurement is made of the particle position and the barrier is moved to the measured location of the particle in an attempt to prevent it from moving down .",
    "when the particle attempts to jump ` through ' the barrier , it instead remains at the same site . if the measurement is always correct , the particle can only ever jump up and so the system acts as a perfect ratchet .",
    "however , if the measurement is incorrect then the barrier will be placed incorrectly and will either not affect the particle s motion or will act as a blockade for jumps up .     or",
    "@xmath58 then the barrier influences the particle movement by preventing certain jumps as in the top and middle right . for all other measurement values",
    ", the barrier has no effect and the particle moves freely as in the bottom right.,scaledwidth=45.0% ]    the system is initialised by first choosing a site @xmath59 uniformly from the lattice sites and then performing the measurement process to obtain a @xmath60 . fig .",
    "[ fig : daemon ] is a schematic diagram of the system where the bias is represented by showing the lattice as a staircase .",
    "the three possible results of the action of the feedback device are shown , including the situation where the feedback has no effect on the particle motion .",
    "the model can be described by three parameters : the lattice size @xmath7 , the motion bias @xmath54 and the measurement accuracy @xmath61 which we define as @xmath62 the corresponding error probabilities @xmath63 are related to @xmath61 via the normalisation condition @xmath64 .",
    "the measurement error is then independent of which site @xmath13 the walker is at and all incorrect measurements ( i.e.  any @xmath65 ) are equally likely .",
    "we consider the case of ` accurate ' measurements ( @xmath66 ) as in this regime the measurements can be used to make useful inferences about the system state and the information gained through measurement can be used in the operation of the information engine .",
    "contrastingly , in the special case @xmath67 , the joint probability in   factorises and   is always zero ; no information is ever gained by the dmon and hence the system reduces to a ` lazy ' random walk .",
    "when @xmath68 it is possible for the dmon to gain information , but we do not study this regime as it is not clear in general how to utilise the information gained from a measurement device that measures wrongly more frequently than correctly .    these three parameters , @xmath54 , @xmath61 and @xmath7 completely characterise the model . at each time - step the contribution to the entropy production is given by   and is @xmath69 , where the non - zero terms correspond to successful jumps down or up and @xmath70 is the entropy produced if the particle attempts to move through the barrier .",
    "the information gained by the feedback controller is given by  .",
    "all three parameters determine the average particle current @xmath71 where positive current is in the rightward direction .",
    "our choice of parameters ( @xmath72 and @xmath73 ) can produce a positive average current ( current against the bias ) , when in the absence of feedback , zero or negative current would be expected .    as a preliminary to sec .",
    "[ sec : largedeviations ] , we numerically check the generalised integral fluctuation theorem  , show that the standard integral fluctuation theorem   does not hold , and check the equality , @xmath74 which follows from the definition  .",
    "[ fig : ifrcheck ]    , @xmath75 , @xmath76 . averaged over @xmath77 realisations .",
    "error bars indicate the standard error of mean of @xmath78 at representative points.,scaledwidth=45.0% ]    confirms these ( in)equalities at different times @xmath1 with numerical data obtained from monte carlo simulation of a biased three - site system .",
    "since the means of exponential quantities are determined by rare events , fluctuations are large as indicated by the error bars on representative points .",
    "having numerically checked the  ,   and  , we now proceed to investigate in more detail the fluctuation properties of the information gained by the dmon .",
    "the variables @xmath79 and @xmath46 are of interest , being the time - averaged information gain and instantaneous change in uncertainty , respectively . on the level of an individual trajectory",
    "there are three types of events possible , given the system dynamics , that influence @xmath46 .",
    "these are roughly described as follows ,    * correct measurements * incorrect measurements that are recognisable as such * incorrect measurements that are not recognisable as such    we observe from the analysis of trajectories in app .",
    "[ app : trajectoryanalysis ] that correct measurements yield positive amounts of information . correctly observed jumps against the bias yield more information than blocked jumps in the direction of the bias .",
    "for symmetric systems the difference in @xmath46 between jumps left and right is small .",
    "series of correct measurements yield one of two baseline values for information gain @xmath46 that correspond to jumps up and blocked jumps down ( see app .",
    "[ app : trajectoryanalysis ] ) .    if an incorrect measurement is made , then the ratio @xmath80 in eq .",
    "changes and the amount of information gained is zero if the current measurement is not compatible with the previous measurement ( e.g.  the particle looks like it has jumped ` through ' the barrier or jumped more than one site ) . a sequence of incorrect measurements can lead to negative values in information gain , interpreted as a change towards greater uncertainty of the system state .    whenever a series of incorrect measurements is made , the next series of correct measurements gains large positive amounts of information that partially retrieve the ` lost ' information of the incorrect measurements .",
    "as these correct measurements are made , the ratio @xmath80 relaxes and @xmath46 returns to a baseline value which we explain in detail in app .",
    "[ app : trajectoryanalysis ] .",
    "the information theoretic interpretation is that successive correct measurements allow the observer to infer which measurement was incorrect .",
    "however , for consistent incorrect measurements which are not detectable the information lost can not be retrieved .",
    "a discussion of this with an example is given in app .",
    "[ app : trajectoryanalysis ] .",
    "large positive deviations of @xmath79 are not generated by an accumulation of the largest values of @xmath46 as these are necessarily preceded by large negative values as described above .",
    "they are instead generated by strings of correct measurements which each generate less information than the largest values of @xmath46 .",
    "in contrast , large negative deviations are generated by sequences of incorrect measurements which happen to represent a possible system trajectory . in this case",
    "large negative values of @xmath46 can accumulate and are not compensated by subsequent large positive values . in general , since the baseline values discussed above depend on the trajectory in case of correct measurements , atypical trajectories @xmath12 also play a role in the realization of large deviations of @xmath81 .      in order to study the fluctuation properties of @xmath79 , we follow standard methods ( see , e.g.  @xcite ) and start by assuming that @xmath79 obeys a large deviation principle of the form , @xmath82 \\sim e^{-e(i)t } , \\label{eq : largedevdef}\\ ] ] as @xmath1 approaches infinity , where @xmath83 is the ` large deviation rate function '  @xcite .",
    "the rate function tells us about the fluctuation properties of the variable @xmath79 , and allows us to quantify how exponentially unlikely a given fluctuation away from the mean is , in the long - time limit .    in order to calculate the rate function , we first consider the scaled cumulant generating function ( scgf ) , @xmath84 where @xmath85 is the moment generating function ,    @xmath86\\mathrm{d}u .",
    "\\label{eq : genfn}\\ ] ]    the rate function is then the legendre - fenchel transform of the scgf @xmath87 .",
    "\\label{eq : legendrefencheltransform}\\ ] ]    by rewriting an expectation of the form  , the scgf can often be obtained as the logarithm of the principal eigenvalue of the markov transition matrix which is weighted to count the relevant quantity  @xcite .",
    "this approach can be applied if the measured quantity depends additively on transitions along a system trajectory , as is the case with particle current .",
    "equation   shows that this is in general not the case for information , since the gain in a given measurement depends on the entire measurement history up until that point .",
    "hence transitions on the enlarged state space of pairs @xmath88 can not be associated with specific values of @xmath46 .",
    "however , in the next section we show that for @xmath89 , @xmath46 can be simplified using eq .   to an expression that only depends on the departure and target states in a single transition , and the above approach can be applied by weighting the transition matrix   to count information gain leading to an exact analytical expression of the large deviation rate function .",
    "this simplification does not hold for @xmath90 , and in sec .",
    "[ sec : lstepmodel ] we describe approximate methods for obtaining the rate function by formulating a one - step markov model for the sequence of @xmath46 .",
    "for a system with two sites labeled @xmath91 and @xmath92 , the matrices used in   are @xmath93 @xmath94 corresponding to the two measurement outcomes . for this system ,",
    "the @xmath95 matrices for any @xmath7 are similarity transforms of one another and have the same spectrum . for the @xmath89 case",
    "these matrices have only one non - zero eigenvalue @xmath96 , allowing them both to be written as tensor products on the eigenspace of the corresponding eigenvector .",
    "that is , we can write @xmath97 where @xmath98 and @xmath99 are the left and right eigenvectors of @xmath95 with respect to @xmath100 . the matrices can be rewritten as @xmath101 and @xmath102    writing the matrices in this way shows that all but the final term of the upper product in   cancel with terms in the lower product , leaving an inner product between two vectors : @xmath103 @xmath104 then can take four values corresponding to the values taken by @xmath105 and @xmath19 , i.e. , @xmath106 .",
    "however , as the two @xmath95 matrices are permutations of one another , only two distinct values can be obtained , when @xmath107 or when @xmath108 .",
    "the change in information upon making a measurement in this two - site system is @xmath109 which for a given @xmath10 depends only on the previous and current measurements @xmath105 and @xmath19 . from   it",
    "can further be deduced that the process @xmath110 is simply a sequence of i.i.d .",
    "random variables .",
    "this simplification only holds for @xmath89 and is demonstrated in app .",
    "[ app : iid ] .",
    "as @xmath111 has two possible values and @xmath112 also has two possible values , @xmath46 takes four possible values",
    ". specifically , these are @xmath113 for correct measurements made after jumps in the up and down directions ( whether blocked or not ) , respectively .",
    "for the same cases followed by incorrect measurements , @xmath46 takes the values @xmath114     for different system sizes @xmath7 with @xmath75 and @xmath76 .",
    "dashed lines give theoretical values for @xmath89 as given by   and.,scaledwidth=45.0% ]    the values taken by @xmath46 can be associated with transitions on the state space @xmath115 , which is described by the transition matrix  . for @xmath89",
    "this matrix is @xmath116 the values in   and , along with the probabilities of these events occurring , given by the transition matrix  , are enough to determine the cumulative density function ( cdf ) of the random variable @xmath46 for all @xmath34 @xmath117 \\quad \\forall ~ \\delta i\\in\\mathbb{r } , \\label{eq : cdfdef}\\ ] ] which is plotted in fig .",
    "[ fig : cdfdeltais ] and compared with numerical data .",
    "it is possible to weight the markov transition matrix   with the values of @xmath46 from   and to obtain the tilted matrix , @xmath118 which has principal eigenvalue @xmath119 the logarithm of   is taken as the scgf @xmath120 and legendre transformed according to   into the rate function @xmath83 .",
    "[ fig:2siteratefn ] shows this rate function plotted with data from simulation for a two - site system . in the long - time limit",
    "the data converge well to the rate function .    , @xmath75 , and @xmath76 .",
    "the solid black line shows the theoretical curve obtained from eq .   and  .",
    "points represent data sampled at different finishing times @xmath1.,scaledwidth=45.0% ]",
    "for systems with three or more sites , the process @xmath121 is still a markov chain with a stationary state .",
    "however , unlike the @xmath89 case , the information gained in each measurement along a trajectory @xmath110 is not a sequence of i.i.d",
    ".  random variables .",
    "eq .   can not be reduced to a simpler form as the @xmath122 matrices for @xmath123 have more than one non - zero eigenvalue , and can not in general be written down in a form that allows cancellation like  .",
    "indeed , @xmath110 is also not a markov chain because each value depends on the entire trajectory @xmath124 up to that point , which is a larger object at each successive value of @xmath8 .    from simulation",
    "we that the information @xmath125 reaches linear growth after some initial transient , and so we expect the information increments @xmath46 to also converge to a stationary distribution . as the matrices used to calculate @xmath46 all have principal eigenvalue @xmath126 ( for all parameters except @xmath127 ) , the system should exhibit an exponential decay of correlations .",
    "this allows us to assume that , at long times , @xmath46 only has significant dependence on a finite number of the previous measurement outcomes / events .",
    "we numerically investigate the behaviour of @xmath46 for systems with @xmath123 , specifically we focus here on results for @xmath128 .",
    "other @xmath7 values ( larger and smaller ) do not significantly differ in their general behaviour or numerics .",
    "[ fig : cdfdeltais ] shows the cdf for @xmath46 , for various system sizes up to @xmath129 .",
    "the shape of the function and the position of the minimum , maximum and most likely intermediate values do not vary significantly .",
    "the scaling of the most likely , minimum and maximum of @xmath46 with @xmath7 is detailed in appendices  [ app : trajectoryanalysis ] and  [ sec : deltaisbehaviour ] .     against @xmath130 for @xmath128 , @xmath131 , @xmath76 to illustrate correlations as explained in the text .",
    "histograms on the axes show the density of points on the plot.,scaledwidth=45.0% ]    fig .",
    "[ fig : deltaisscatterplot ] shows a scatter plot of @xmath132 against @xmath130 for @xmath128 .",
    "independent random variables plotted this way would produce a symmetric cloud or grid of points .",
    "however this plot features diagonal patterns which correspond to correlation between the two variables .",
    "the projected probability densities are shown as histograms along the axes .",
    "the histograms suggest that @xmath46 and @xmath132 are identically distributed as expected . to verify this and understand how successive values of @xmath46 are correlated , we compute the sample autocorrelation function ( acf ) defined as @xmath133 fig .  [ fig : acfplot ]",
    "shows the acf of @xmath134 after an initial transient period for biased and unbiased cases with 95% white - noise confidence intervals .",
    "the autocorrelation functions show significant negative correlation between @xmath46 and @xmath132 , but beyond this no significant correlation .",
    "that is , the information gained at successive time - steps is anti - correlated .",
    "this is because when an incorrect measurement is made the next measurement is likely to be correct , as correct measurements are more probable , and the amount of information gained will be positive ( see app .",
    "[ app : trajectoryanalysis ] ) .",
    ". shows significant negative correlations after one time step .",
    "95% confidence intervals plotted as blue dashed lines . @xmath128 and @xmath76 in both cases.,scaledwidth=45.0% ]    while successive correct measurements do each contribute positive amounts of information , they do not differ as radically as the change from a negative to positive amount of information . fig .",
    "[ fig : acfplot ] also suggests that biased systems are less strongly anti - correlated than unbiased . in the next subsection we use the one time - step correlation and distribution of @xmath46 as grounds for constructing a single - step markov chain model of @xmath110 that we believe captures most of the relevant features .      to obtain an approximate rate function , we assume that after an initial transient , @xmath110 is described by a stationary one - step markov chain taking values in a continuous range .",
    "we define a finite state space @xmath135 by coarse - graining this range and replacing @xmath46 by its expected value in each bin . the transition matrix for this process",
    "is then obtained by binning data from a scatter plot such as fig .",
    "[ fig : deltaisscatterplot ] into these states and normalising the number of counts in each bin . to count the information gain , the new markov matrix on the state space @xmath135",
    "is then weighted with the value of @xmath46 in the target state .",
    ", @xmath131 , @xmath76 .",
    "lines show rate functions obtained from the markov approximation with different numbers of bins .",
    "the lines for 12 and 24 bins are not distinguishable at this scale .",
    "points represent data sampled at different finishing times @xmath1 .",
    "the cutoff for positive deviations is explained in the text and given in eq .  , and is represented by a vertical line.,scaledwidth=47.0% ]    the scgf ( and thus the rate function ) can then be obtained from the largest eigenvalue of this tilted transition matrix .    to check the method",
    "it can be shown that for @xmath89 , as the number of bins is increased and more data is used in the scatter plot , the method converges to the analytically obtained rate function for that case .",
    "[ fig : lsiteratefn ] shows the rate function obtained through this method for @xmath128 plotted alongside data obtained from simulation .",
    "the figure shows convergence of the estimated rate functions with increasing number of bins , which appears to be consistent with the data .",
    "this confirms the validity of the one - step markov approximation for a wide range of fluctuations .",
    "however , as can be seen in fig .",
    "[ fig : lsiteratefn ] , the data indicate a cut - off in the rate function that the markov approximation does not predict . in the next subsection",
    "we explain this feature by noting that large fluctuations of @xmath46 do not accumulate in the way that the markov model allows .      to correct the numerically obtained rate functions shown by solid lines in fig .",
    "[ fig : lsiteratefn ] we must consider the maximum possible value for @xmath79 . fig .",
    "[ fig : deltaisscatterplot ] suggests that it is possible to obtain large amounts of information on consecutive time - steps ( the top right corner of this scatter - plot has a small but non - zero population ) .",
    "however , investigation of individual trajectories of the system reveals that consecutive large positive amounts can only be obtained after consecutive large negative amounts ( see app .",
    "[ app : trajectoryanalysis ] ) .",
    "this is not reflected in the acf in fig .",
    "[ fig : acfplot ] owing to the fact that these events occur very rarely , as can be seen from the marginal histograms in fig .",
    "[ fig : deltaisscatterplot ] .",
    "the maximum value of @xmath79 is obtained by measuring correctly every time - step .",
    "this maximum value is given by @xmath136 where @xmath137 is numerically obtained from the @xmath95 matrices for that system .",
    "a discussion is included in app .  [ app : trajectoryanalysis ] .",
    "[ fig : lsiteratefn ] shows the cut - off value for an unbiased system with a black vertical line .",
    "unlikely trajectories in biased systems that always step against the bias can generate large positive deviations of @xmath79 and so the rate function cuts off at higher values .",
    "the cut - off is therefore less relevant when comparing data for biased systems to the predicted rate function .",
    "the @xmath46 process is clearly not a one - step markov chain , and the rate function obtained this way is also limited by finite sampling of transitions and limitations on the number of bins used .",
    "however , the one - step markov model gives a rate function that converges reasonably quickly with increasing number of data points and together with the cut - off , captures well the shape of the sampled data in a way that a gaussian or i.i.d .",
    "approximation would not .",
    "an @xmath138-step markov chain model might also capture this but it appears that simply including the cut - off at the maximum value is sufficient to obtain a good approximate rate function .",
    "the information gain @xmath2 is a quantity recently introduced in the analysis of feedback systems  @xcite and studied as a component in the development of information thermodynamics and information engines  @xcite .",
    "the fluctuation properties of this quantity are relevant when considering information processing in feedback devices ; the quantity of information gained is directly proportional to the work required to delete that information from the feedback device s memory .    in this paper",
    "we have studied a simple model of an information engine and obtained an exact analytical expression of the large deviation rate function for information gain @xmath2 in a two - site system . for larger systems",
    "we have shown that a one - step markov approximation captures most of the relevant details of the large deviations .",
    "we are also able to predict the cut - off of this rate function by considering the maximum amount of information that can be obtained .",
    "significantly , the one - step markov approximation allows us to easily obtain an approximation of the rate function from data by sampling the information gain at consecutive time steps .",
    "this is computationally easier than directly sampling the distribution of @xmath139 ( which requires very long times or cloning - type algorithms @xcite ) but together with the theoretically predicted cut - off seems to provide a consistent estimate of the shape of the large deviation rate function .    the rate functions obtained here demonstrate that the information gained by the measuring device in a simple markovian feedback system shows a strong asymmetry around the mean .",
    "the cut - off value for this rate function is sensitive to the dynamics of the system , namely whether the particle motion is symmetric or asymmetric .",
    "it would be of interest to study other information engines to check whether these findings are generic and to what extent the markov approximation is applicable in other systems .",
    "the large deviation rate function offers the possibility to explore detailed fluctuation relationships beyond   for @xmath2 . to obtain a detailed fluctuation relationship",
    ", care must be taken in deciding how to meaningfully time - reverse a feedback system .",
    "discussions have already alluded  @xcite to the potential difficulties in interpreting time - reversed feedback in a physically meaningful manner and there is evidently much scope for future work .",
    "this work was supported by the engineering and physical sciences research council ( epsrc ) , grant no .",
    "ep / i01358x/1 .",
    "we would also like to thank takahiro sagawa , sosuke ito , jordan horowitz and hugo touchette for helpful discussions .",
    "rjh is grateful for the hospitality of the national institute for theoretical physics ( nithep ) stellenbosch .",
    "to understand the various events that occur in the system , we plot trajectories of @xmath46 , @xmath80 , @xmath9 and @xmath17 . recall that @xmath46 is given by eq .",
    "( reproduced here for readability ) @xmath140 and hence @xmath46 will always differ from @xmath141 by @xmath142 or @xmath143 depending on whether the measurement is correct or incorrect .",
    "the value of @xmath80 is determined by the measurement trajectory itself and is not directly dependent on the trajectory @xmath12 .",
    "we observe that there are two ` baseline ' values for this ratio that are obtained when the measurements represent a possible trajectory for the particle , i.e.  the particle does not appear to jump more than one site in a single time - step and does not appear to move ` through ' the barrier .",
    "these two baseline values correspond to the particle jumping up or being blocked attempting to jump down .",
    "if the particle is blocked at site @xmath13 for successive steps starting , for example , at time @xmath144 , the probability of the correct measurement history is calculated via a matrix product as in eq .  ,",
    "@xmath145 where @xmath146 and where @xmath147 .",
    "the ratio @xmath148 entering the information gain @xmath46 ( eq .  )",
    "is then dominated by the leading eigenvalue @xmath149 of the matrices , and therefore should approach @xmath150 very quickly .",
    "recall that all matrices have the same eigenvalues since they are related by translations of rows and columns .",
    "the corresponding lower baseline value for @xmath46 is given by @xmath151    on the other hand , let us assume that the particle jumps up for successive time steps , starting in site @xmath13 at time @xmath144 , and we measure this correctly .",
    "then the probability of the measurement history @xmath152 is given by a product of matrices with increasing index @xmath153 where @xmath146 , and @xmath154 is understood with periodic boundary conditions .",
    "the successive matrices are translated by one column and one row , i.e.  @xmath155 , where the translation @xmath156 is such that @xmath157 similar to the eigenvalue case , the expression   then is dominated by vectors @xmath158 and a scale factor @xmath137 such that @xmath159 with periodic boundaries ( i.e. @xmath160 ) . so the upper baseline value for information gain @xmath46 should be given by @xmath161 where @xmath137 can be found numerically from   for any given system .",
    "[ fig : pratiounbiased ]    ) for @xmath76 .",
    "points show the value of @xmath46 for consecutive up jumps and blocked down jumps .",
    "lines show the predictions from   and  .,scaledwidth=45.0% ]    and  [ fig : pratiobiased ]     and @xmath76 .",
    "points show the value of @xmath46 for consecutive up jumps and blocked down jumps .",
    "lines show the predictions from   and  .,scaledwidth=45.0% ]    show empirical data confirming our predictions for the baseline values and demonstrate their scaling with @xmath7 in unbiased and biased systems , respectively . in an unbiased system ,",
    "the difference in @xmath80 between an up and blocked down jump shrinks with increasing @xmath7 , whereas the values are roughly constant for biased systems .",
    "[ fig : asymmetricjumpup ]    , @xmath75 , @xmath76 .",
    "the trajectory @xmath10 is given by a gold line , and measurements by square boxes .",
    "the information gain @xmath46 , given by a blue line , is always bounded above by @xmath162 given by a red line .",
    "note that these quantities have different units .",
    "note also that for @xmath10 and @xmath19 there are periodic boundary conditions between 0 and 10.,scaledwidth=45.0% ]    shows a typical section of a trajectory in a biased system .",
    "the baseline values of @xmath80 and @xmath46 for blocked down and up jumps are seen around @xmath163 and @xmath164 respectively .    whenever a measurement is made that is incompatible with previous measurements ( i.e.  the particle looks to have jumped two or more sites or moved through the barrier ) , @xmath80 changes value .",
    "isolated incorrect measurements as seen in fig .",
    "[ fig : asymmetricjumpup ] ( at time @xmath165 ) and fig .",
    "[ fig : consecutiveincorrectmeasurements ] ( at time @xmath166 ) cause @xmath80 to increase while we observe that the @xmath143 term means that @xmath167 . in the following measurements ,",
    "@xmath80 is still larger than its baseline value and as the @xmath142 contribution is small in comparison , @xmath46 is also larger than the baseline .",
    "the information theoretic interpretation of these observations is that upon making a measurement that is not compatible with the previous measurements , no new information is gained .",
    "this is because it is not clear to the observer whether the current measurement is incorrect , or the previous measurements were erroneous ( or both ) .",
    "it is only on subsequent measurements that information is gained , as more measurements allow the observer to make inferences about which measurements were incorrect .",
    "after an incorrect measurement , @xmath80 ( and hence @xmath46 ) returns quickly to a baseline value .",
    "to observe very large values of @xmath46 and instantaneously gain large amounts of information , it is necessary to first lose larger amounts of information through incorrect measurements .",
    "an example of this is shown in fig .",
    "[ fig : consecutiveincorrectmeasurements ]    , @xmath131 , @xmath76 .",
    "see fig .",
    "[ fig : asymmetricjumpup ] for details of the plot.,scaledwidth=47.0% ]    , where the large amounts of information gained between @xmath168 and @xmath169 can not balance the losses between @xmath170 and @xmath171 .",
    "hence it is not possible to gain additional information by making strategically ` wrong ' measurements , as a series of correct measurements would yield more total information .    in the case of a wrong measurement that still represents a possible trajectory for the particle , @xmath80 does not change but",
    "the @xmath143 contribution from the incorrect measurement means that @xmath46 takes a negative value .",
    "if the following measurements are correct and also compatible with the previous wrong measurement , then subsequent measurements will only gain a baseline amount of information .",
    "an example of this is shown in fig .",
    "[ fig : undetectableincorrectmeasurements ]    , @xmath131 , @xmath76 .",
    "see fig .",
    "[ fig : asymmetricjumpup ] for details of the plot.,scaledwidth=45.0% ]    . here , a wrong measurement occurs at time @xmath172 which is compatible with the previous history .",
    "subsequent measurements do not allow the observer to ascertain that any of previous measurements were incorrect and hence this information loss is not recovered .",
    "to demonstrate that @xmath46 are i.i.d .  random variables for @xmath89 , we want to show that the distribution of @xmath132 is independent of @xmath46 and identical for all @xmath8",
    "let us first assume that the system is in the state @xmath173 .",
    "the probabilities for @xmath132 taking the values in   and are as follows :    [ cols=\"^,^,^\",options=\"header \" , ]     which again by translation invariance also holds for beginning in the state @xmath174 .",
    "we can see then that the probability to obtain @xmath132 is in fact independent of the state @xmath115 of the system .",
    "in particular , it does not depend on the previous value @xmath46 .",
    "therefore , @xmath110 is indeed a sequence of i.i.d",
    ".  random variables .",
    "[ fig : maxmindeltaisplot ] shows numerical results for the maximum and minimum of @xmath46 from @xmath77 realisations up to @xmath175 for varying @xmath7 .",
    "the minimum amount of information per time - step is obtained when an incorrect measurement is made and we argue that , as in the @xmath89 case ( see eq .  ) its value is given by @xmath176 the maximum value is observed to be exactly the minimum value reflected across the lower baseline value for information gain  , i.e.  it is given by , @xmath177 this holds for all @xmath178 as shown by the numerical results in fig .",
    "[ fig : maxmindeltaisplot ]      . for @xmath181 ,",
    "the observed discrepancy is probably due to the fact that incorrect measurements are more constrained e.g.  any barrier placement in a two - site system will interfere with the particle motion ."
  ],
  "abstract_text": [
    "<S> information thermodynamics provides a framework for studying the effect of feedback loops on entropy production . </S>",
    "<S> it has enabled the understanding of novel thermodynamic systems such as the information engine which can be seen as a modern version of ` maxwell s dmon ' , whereby the feedback controller is acting as a dmon , processing information gained about the system in order to do work . here , we analyse a simple model of such an engine and provide a detailed analysis of its fluctuation properties , including the large deviations of information . </S>",
    "<S> we find an exact expression of the large deviation rate function for a two - site version of our model , and provide an approximate analysis for larger systems which is corroborated by simulation data . </S>"
  ]
}