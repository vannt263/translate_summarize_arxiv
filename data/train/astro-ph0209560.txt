{
  "article_text": [
    "power spectrum estimation and evaluation of the associated errors in the presence of incomplete sky coverage ; non - homogeneous , correlated instrumental noise ; and foreground emission is a problem of central importance for the extraction of cosmological information from the cosmic microwave background . from a bayesian point of view",
    ", power spectrum estimation involves the maximization of the posterior probability density , with error bars given by the set of cosmological parameters or power spectrum whose integrated posterior density achieves some specified level of confidence .",
    "a bayesian approach to cmb analysis for large data sets involving a direct evaluation of the likelihood is intractable due to the @xmath4 expense associated with computing the inverse of non - sparse matrices , or their determinants ( @xcite , @xcite ) .",
    "the goal of this paper is the development of alternative numerical methods , specifically monte carlo techniques , for the bayesian analysis of the cmb , including the complications of incomplete sky coverage , correlated noise and foregrounds .",
    "previous work has demonstrated that for a certain class of scanning strategies , the signal and inverse noise matrices are block diagonal .",
    "the block diagonal properties of these matrices give an exact @xmath5 bayesian method , and therefore tractable for data sets as large as will be returned from planck .",
    "the complications of this method are that it can not easily accommodate partial sky converge or precessing scan strategies .",
    "the method of @xcite computes the maximum of the likelihood through a newton raphson method .",
    "the numerical innovations of this method involve monte carlo simulations and the use of conjugate gradient descent , giving an overall expense @xmath5 .",
    "the method was proposed and numerically demonstrated in the context of uncorrelated noise , and a region of sky coverage of azimuthal symmetry , where a good preconditioner can be constructed .",
    "however , the algorithm is in fact more general , provided there is sufficient memory for storage of the needed matrices , and that conjugate gradient descent converges quickly enough ( i.e. there is a good preconditioner ) .",
    "as suggested in @xcite , we can use the ring set approach to supply preconditioners .",
    "an outstanding problem to be solved is a way of retaining the mathematical advantages of a ring set scan ( block diagonal inverse noise and signal matrices ) while accommodating partial sky coverage .",
    "the approach formulated in this paper handles the problem of partial sky coverage by embedding the data in an azimuthally symmetric region of sky , and using a monte carlo markov chain to numerically marginalize over the unobserved part . for scans close to ring sets ,",
    "we therefore inherit good preconditioners , allowing an extension of both the ring set and conjugate gradient methods to scan strategies as planned for planck .    for observations @xmath6 , where @xmath7",
    "are the cmb signal , foregrounds , and noise respectively , our approach to power spectrum estimation is motivated by the identity ( derived in appendix [ appposterioridentity ] ) @xmath8 p(s , f|\\gamma_{0},y)\\ ] ] where @xmath9 is any parameterization of conclusions ( such as the power spectrum or cosmological parameters ) , and @xmath10 is any fixed guess . the bayesian posterior ratio on the left is given as an integral over the unknown quantities which are assumed to generate the observed data .",
    "maximization of the posterior involves computing the gradient of equation [ posterioridentity ] which will be shown to depend on the expectation value of the power spectrum with respect to the random field @xmath11 , @xmath12 = \\int d(s , f ) \\",
    "c_{l}(s ) \\   p(s , f |\\gamma_{0},y)\\ ] ] we maximize the posterior ratio in equation [ posterioridentity ] by the expectation maximization algorithm ( @xcite ) which proceeds by iteratively setting @xmath13 $ ] .",
    "the algorithm converges to the posterior maximum for a uniform prior , and gives an un - biased , consistent estimator ( see appendix [ appestimator ] ) . in this paper , we focus on computation of the expectation value of the power spectrum @xmath14 $ ] given the data and some guess @xmath15 under the assumption of perfect foreground separation ( although we comment on how the approach can be generalized to include foregrounds later in the paper , and leave its numerical demonstration for future work ) .",
    "we compute the expectation value of the power spectrum @xmath14 $ ] numerically with a monte carlo approach , where we sample maps of the cmb from the probability density @xmath16 .",
    "conditioning on some estimate of the foregrounds , the method exploits the fact that @xmath17 is a gaussian random field , and therefore completely characterized by the mean field map and covariance matrix of fluctuations about that map .",
    "maps are sampled from @xmath17 by first computing the mean field map with conjugate gradient descent , and then sampling fluctuations about the mean field map from a zero mean gaussian field with covariance matrix @xmath18 ( where @xmath19 is the inverse noise matrix , and @xmath20 is the inverse covariance matrix for the cmb ) .",
    "these fluctuation maps are sampled by a linear transformation , numerically computed with conjugate gradient descent , of a spatial white noise gaussian process thereby generating maps with all the same statistical properties as samples from @xmath17 .",
    "each step of conjugate gradient descent involves a multiplication by the matrix @xmath21 , which can be done very quickly by multiplication by @xmath19 in the basis in which it is diagonal , followed by a transform to the spherical harmonic basis where @xmath22 is diagonal . for spatially uncorrelated noise and circularly symmetric beams ,",
    "we only need to transform from the pixel to the spherical harmonic domain , with an expense @xmath23 @xcite . in order to accommodate spatially",
    "correlated noise , we transform to the time domain , followed by a transform to the spherical harmonics , giving an expense @xmath24 $ ] where @xmath0 is the number of time samples , and @xmath3 depends on the convergence rate of conjugate gradient descent .",
    "including the full complications of asymmetric beams , we would need to compute a convolution on the sphere . using the convolution method of ( @xcite )",
    ", the expense of our method is @xmath25 $ ] .",
    "the computational feasibility of this method is limited by finding a numerical implementation of conjugate gradient descent which converges quickly so that the prefactor @xmath3 above is small .",
    "the strategy here is to embed the data in a region covered by an exact ring set scan , following the intuition that good preconditioners can be constructed for scan strategies close to ring sets @xcite .",
    "embedding the data in a region on the sky with no observations ( or where they have been removed ) is accommodated by numerically marginalizing over the missing observations .",
    "moreover , the same techniques can be used to marginalize over the foregrounds , and provide monte carlo estimates of the confidence intervals for cosmological parameters .",
    "the paper is organized as follows .",
    "we first review complications with a direct computation of the likelihood , and provide an overview of our approach .",
    "we then discuss a technique we call transformed white noise sampling , which allows us to sample maps representing fluctuations about the mean field map for some guess of the power spectrum .",
    "we demonstrate the method with a flat sky @xmath26 test case , including incomplete sky coverage , with uncorrelated , non - homogeneous noise .",
    "we close with a discussion of further complications encountered in real cmb experiments , and how they can be accommodated in the framework presented here .",
    "we begin with a brief review of the likelihood and complications with its computational evaluation .",
    "the data returned from an experiment is a vector in the time domain @xmath27 , which is related to the cmb signal on the sky @xmath28 through some linear mapping and additive gaussian noise , @xmath29 \\int dn '' \\ b(n',n '' ) s(n '' ) \\right ] + \\eta(t)\\ ] ] where @xmath30 is the beam of the instrument , and @xmath31 is gaussian noise , assumed to be stationary with a noise correlation matrix @xmath32 . denoting the linear mapping from time domain to the sky as @xmath33 \\int dn '' \\",
    "b(n',n'')\\ ] ] we will simply write @xmath34 .",
    "the likelihood for the power spectrum @xmath35 given the data is @xmath36 any linear transformation of the data vector will generate a gaussian form for the likelihood ( as reviewed in appendix [ applikelihoods ] ) .",
    "for example , we can transform the data to an estimate of the cmb map @xmath37 ( as discussed in detail in @xcite , @xcite ) .",
    "the covariance matrix of this map is @xmath38 & = &   c +   ( r^{t } n^{-1 } r)^{-1 } \\end{aligned}\\ ] ] which shows that the map @xmath39 can be thought of as signal @xmath22 with additive gaussian noise with covariance matrix @xmath40 .",
    "the likelihood can can equivalently be written in terms of the map @xmath41 according to @xmath42 & = & - { \\hat s}(d ) [ ( r^{t } n^{-1 } r)^{-1 }   + c ] ^{-1 } { \\hat s}(d ) - \\log \\det [ ( r^{t } n^{-1 } r)^{-1 } + c   ] \\end{aligned}\\ ] ] we can also write the likelihood in the original time domain , @xmath43\\ ] ] directly evaluating the likelihood in either the spatial or time domain results in an @xmath4 computation , as it involves inversion , or computation of the determinant , of @xmath44 $ ] or @xmath45 $ ] respectively .",
    "the computational expense is due to the fact that we do not know the eigenbasis for either of these matrices , and computing this basis is generally an @xmath4 problem .",
    "the method of @xcite solves the likelihood in the spatial domain by evaluating the determinant with a monte carlo algorithm .",
    "the method involves conjugate gradient descent to solve a linear problem , and as such involves matrix multiplication , which carries an @xmath5 expense .",
    "the method was proposed and numerically demonstrated in the context of uncorrelated noise , and a region of sky coverage of azimuthal symmetry .",
    "however , the algorithm is in fact more general , provided there is sufficient memory for storage of the needed matrices , and that conjugate gradient descent converges quickly enough ( i.e. there is a good preconditioner ) .    for a certain class of observing strategies",
    ", we can exactly compute the likelihood , and for perturbations about these cases , we can use the approximate case as a preconditioner ( as suggested in @xcite ) .",
    "the approach formulated in this paper provides a consistent way to do this , and involves a monte carlo markov chain approach to numerically marginalizing over the unobserved part of azimuthally symmetric regions of the sky .",
    "the method to be developed in this paper involves embedding the data in a region for which the signal and noise matrices have desirable properties .",
    "the likelihood for the data in the context of some model is given as an integral over the part of the embedding region which was not observed .",
    "this gives the identity for the bayesian posterior for the power spectrum or cosmological model ( denoted by @xmath9 ) , given the time domain data @xmath27 as the integral @xmath46 p(s^{(1)},s^{(2)},f|\\gamma_{0},d)\\ ] ] where we have explicitly written the cmb maps @xmath47 in terms of the part of the sky where we have data @xmath48 and the complementary region @xmath49 .",
    "for the case of full sky coverage and prior knowledge @xmath50 , the log posterior ratio is given as @xmath51\\ ] ] where the power at a given multipole order is @xmath52 for other regions with azimuthal symmetry ( an annulus or polar cap ) , the posterior ratio would involve a similar form in terms of block diagonal matrices .",
    "the simple form of the log posterior ratio for full sky coverage is one of the motivations for treating the problem of partial sky coverage as missing data , and marginalizing over it ( detailed and justified in appendix [ apppartialcoverage ] ) .      in order to estimate the power spectrum",
    ", we would like to find @xmath9 which maximizes the posterior given the noisy data .",
    "differentiating the posterior with respect to the parameters @xmath35 gives a gradient in the direction @xmath53}{c_{l}^{2}(\\gamma_{0 } ) } - \\frac{1}{c_{l}(\\gamma_{0 } ) } \\right]\\ ] ] where @xmath54 $ ] was given previously in equation [ expectation ] .",
    "an improvement of our current estimate of the power spectrum @xmath10 can then given according to a newton - raphson iterative scheme ( @xcite and @xcite ) , where our current guess is updated using an approximation to the curvature of the likelihood @xmath55 $ ] , according to @xmath56 \\left .",
    "\\frac{\\partial \\log p(\\gamma|d)}{\\partial c_{l } } \\right|_{\\gamma_{n}}\\ ] ] in appendix [ appestimator ] , it is shown that the curvature matrix is given in terms of the expectation value @xmath57   = \\int ds \\",
    "c_{l}(s ) c_{l'}(s ) \\",
    "p(s|d , \\gamma_{0})\\ ] ] in practice , we might want to avoid computing the inverse of the curvature matrix , and simply use the diagonal elements .    for this paper",
    ", we instead implemented the simpler ( although more slowly converging ) expectation maximization algorithm @xcite .",
    "this method essentially follows from jensen s inequality , giving the lower bound to the posterior @xmath58   \\left ( \\frac{1}{c_{l}(\\gamma ) } -   \\frac{1}{c_{l}(\\gamma_{0 } ) } \\right ) + \\log \\frac{c_{l}(\\gamma ) } { c_{l}(\\gamma_{0 } ) } \\right]\\ ] ] for a uniform prior , the lower bound is maximized by @xmath59 $ ] . in appendix b , we prove that this estimator iteratively converges to the maximum of the posterior , and is a consistent and unbiased estimator ( for a uniform prior ) .      in order to iteratively converge to the optimal , consistent estimator of the power spectrum , we need to compute , for any current guess of the power spectrum @xmath10 , the expectation value @xmath60 $ ] as defined in equation [ expectation ] . defining the mean field map @xmath61^{-1 } n^{-1 } y\\ ] ] and associated power spectrum estimate @xmath62 the expectation value",
    "can be written by integrating over fluctuations about the mean field map @xmath63 as @xmath64   & = & \\frac{1}{2l+1 } \\sum_{m } \\int d \\xi \\ \\langle { \\hat s } + \\xi | lm \\rangle   \\langle lm | { \\hat s } + \\xi \\rangle \\",
    "\\xi [ n^{-1 } + c^{-1}(\\gamma_{n } ) ] \\xi   } } { \\int d\\xi ' \\ e^{- \\xi ' [ n^{-1 } + c^{-1}(\\gamma_{n } ) ] \\xi '   } } \\nonumber \\\\\\end{aligned}\\ ] ] since @xmath65 = 0 $ ] , the expectation value is @xmath64   & = & c_{l}({\\hat s } ) + \\frac{1}{2l+1 } \\sum_{m } \\int d \\xi \\ \\langle   \\xi | lm \\rangle   \\langle lm |",
    "\\xi \\rangle \\ \\frac{e^{- \\xi [ n^{-1 } + c^{-1}(\\gamma_{n } ) ] \\xi   } } { \\int d\\xi ' \\ e^{- \\xi ' [ n^{-1 } + c^{-1}(\\gamma_{n } ) ] \\xi '   }   } \\end{aligned}\\ ] ] we refer to these two terms as the mean field map power spectrum estimate ( known to be biased ) and the correction term . analytically , we know that the correction term is given by @xmath66^{-1 }    matrix @xmath67^{-1}$ ] . our strategy is to compute the correction term with a monte carlo method described below .      due to the computational intractability of computing the matrix inverse @xmath68 ,",
    "our strategy is to compute the expectation value of the correction term from fluctuation maps @xmath69 sampled from the zero mean gaussian random field with covariance matrix @xmath68 .",
    "we could easily sample fluctuation maps @xmath69 if we could compute the eigenvectors and eigenvalues of the matrix @xmath70 , since in this basis the gaussian probability density for @xmath69 factors .",
    "however , computing the eigenvectors and eigenvalues is again an @xmath4 operation .    because of these difficulties , we look for an alternative way to sample maps . defining @xmath71 , we can write the log density , up to the normalization constant , as @xmath72 the transformed gaussian process has the covariance matrix @xmath73 , making it easy to sample from . specifically , we can sample maps from this gaussian process by drawing two independent white noise maps @xmath74 , and setting @xmath75 . since",
    "both white noise maps are drawn independently from a zero mean gaussian process , the resulting covariance matrix is @xmath76 =   n^{-1 } + c^{-1}$ ] ( as discussed in appendix [ appsampling ] ) .",
    "the maps with the correct statistical properties are @xmath77 , which can be solved numerically for a given map @xmath78 .",
    "a numerically stable implementation involves setting @xmath79 ( as also noted in @xcite ) , and using conjugate gradient descent to solve @xmath80 the resulting maps @xmath69 have the correct statistical properties , since @xmath81 = ( n^{-1 } + c^{-1 } ) ^{-1}$ ] ( see appendix [ appsampling ] ) , allowing us to compute the correction term to the power spectrum estimate of the mean field map as a sample average .    in order to actually sample fluctuation maps by transforming a gaussian white noise process",
    ", we need to obtain the cholesky decomposition of both the signal and noise matrices . if we have observations with uncorrelated noise on the sky , then @xmath82 is known in the spatial domain . however , the scan strategy of the instrument will result in complicated correlations , so that computing @xmath82 is intractable .",
    "the noise is simple in the time domain , which suggests that instead of choosing white noise maps in the spatial domain , we instead draw from white noise gaussian processes in the time domain , where we know @xmath82 in the fourier basis , followed by a transformation to the sky , where we can operate with the signal matrix @xmath22 .    for a realization of a white noise process in the time domain @xmath83 and a white noise map in the spatial domain @xmath84 , we can compute a fluctuation map according to @xmath85 \\xi =    c^{1/2 } \\omega + c r^{t } n^{-1/2 } \\tau\\ ] ] where @xmath82 is known in the fourier basis associated with the time domain . in appendix [ appsampling ] ,",
    "this procedure is justified with a proof that the covariance matrix of the fluctuation maps is @xmath81 = [ c^{-1}+ ( r^{t } n^{-1}_{t } r)^{-1}]^{-1}$ ] .",
    "the overall computational expense is fixed , for each iteration of the power spectrum estimate , by the expense of matrix multiplication and number of iterations needed to converge with conjugate gradient descent . in order to multiply by the matrix",
    "@xmath86 we need to :    * transform to the time domain with the matrix @xmath87 . *",
    "compute a time domain fft . *",
    "multiply by @xmath19 - this is a diagonal matrix in the time domain fourier basis * compute a time domain inverse fft . *",
    "transform back to the spatial domain with @xmath88 . *",
    "compute a spherical harmonic transform .",
    "* multiply by @xmath22 - this is a diagonal matrix in the spherical harmonic domain if the embedding region is the full sky .    for the case of circularly symmetric beams , the convolution with the beam is not needed when operating with the matrix @xmath87 or its transpose , giving an expense @xmath89 $ ] , where @xmath0 is the number of time samples , and @xmath3 is the prefactor related to the convergence rate of conjugate gradient descent . for cases where the beam is not circularly symmetric , the convolution with the beam would have to be computed , increasing the expense to @xmath90 $ ] .",
    "the simulations presented here involve the assumption of spatially uncorrelated , but non - homogeneous , noise , as shown by the upper left in figure @xmath91 .",
    "we also restrict the problem to power spectrum estimation from a small patch of sky , and neglect curvature ( and therefore work with discrete fourier basis instead of spherical harmonics ) .",
    "our goal with these numerical simulations is to demonstrate the approach in action .",
    "future work will involve numerical implementations on the sphere .",
    "a cmb power spectrum was generated using cmbfast @xcite , followed by the creation of a full sky map on the sphere using the * synfast * routine in the healpix package @xcite .",
    "a smaller patch of the sky was then selected , and projected on a rectangular grid .",
    "this map @xmath28 was taken to be the noise free map , as shown in the upper right of figure 1 .",
    "we then generated a noise map @xmath92 by selecting independently at each pixel a gaussian random number with variance scaled as shown according to the upper left of figure 1 .",
    "noise was added to the noise free map , and data then removed in a rectangular hole ( as shown in figure 1 ) .",
    "this was taken to be a simulated data set @xmath93 with partial coverage of the rectangular patch of sky .",
    "the inverse noise matrix was given in terms of the variance at the ith pixel @xmath94 as @xmath95 as an initial estimate of the power spectrum , we computed the the power spectrum of the noisy , incomplete data ( as computed in the two - dimensional fourier basis since we neglected curvature ) and subtracted the power spectrum of a single simulated noise map ( on the region of sky where we have data ) .",
    "we then iteratively adjusted the power spectrum with the expectation maximization as above until convergence .",
    "we found that preconditioning was in fact necessary to achieve a reasonable convergence rate . using the initial estimate of the power spectrum",
    "@xmath96 , and computing the diagonal elements of the inverse noise matrix in the fourier domain @xmath97 with monte carlo noise maps , gave the preconditioner @xmath98^{-1}\\ ] ] conjugate gradient descent was then used to solve the linear equations for the mean field and fluctuation maps @xmath99 { \\hat s } & = & m^{-1 } cn^{-1 } y   \\nonumber \\\\",
    "m^{-1 } [ i + cn^{-1 } ] \\xi & = & m^{-1 } \\delta\\end{aligned}\\ ] ] where @xmath100 was computed from two independently chosen spatial white noise maps @xmath74 , and @xmath82 vanished in the unobserved part of the sky , and elsewhere given by @xmath101 .",
    "the result of iterating the algorithm to convergence is shown in figure 2 .",
    "uncertainties in the power spectrum estimate were computed by monte carlo , in which new cmb maps were generated , noise added , and the algorithm run again .",
    "the methods presented above can be generalized to handle other additional problems faced in the bayesian analysis of the cmb .",
    "we do not provide numerical examples , but briefly include comments on how to use transformed white noise sampling to estimate error bars and include foregrounds .      the ability to sample maps of the cmb given some estimate of the power spectrum",
    "can be used to construct a markov chain monte carlo algorithm which converges to the bayesian posterior @xmath102 itself .",
    "previously , markov chain monte carlo techniques have been proposed for the extraction of marginal densities for cosmological parameters from approximate bayesian posterior densities for the power spectrum ( @xcite , @xcite , @xcite , @xcite )    we want to construct a transition matrix for the _ joint _ density of cmb maps and the power spectrum .",
    "this can be done by following the metropolis hastings algorithm , where we first assume detailed balance @xmath103 from the condition of detailed balance we see that @xmath104 which shows that the bayesian posterior is the marginalized equilibrium density , generated by repeatedly taking steps generated with the transition matrix @xmath105 . given any approximation to the joint density @xmath106 , repeated application of the transition matrix will reach the equilibrium density .",
    "we can construct the transition matrix as follows .",
    "we first assume the proposal density is independent of the past @xmath107 and given by @xmath108 s   } { \\tilde p}(\\gamma_{2 } | y)\\ ] ] where @xmath109 is any approximation to the bayesian posterior itself .",
    "we therefore have , as before , the conditional density @xmath110 s } } { \\int ds ' \\ e^{- ( d - rs ' ) n^{-1 } ( d - rs ' ) - s ' c^{-1}[\\gamma_{2 } ] s ' } } \\ ] ] and the marginal density for the power spectra given by our approximation @xmath109 . with this choice of proposal matrix",
    ", the acceptance matrix can be chosen to be @xmath111 = \\min \\left [ 1 , \\frac{p(\\gamma_{2 } , s_{2 } | y)}{p(\\gamma_{1 } , s_{1 } | y ) } \\frac{\\rho(\\gamma_{1},s_{1 } |   y ) } { \\rho(\\gamma_{2 } , s_{2 } |   y ) } \\right]\\ ] ] what makes this computationally tractable is that we know the ratios @xmath112 s_{2 } - \\log \\| c(\\gamma_{2 } ) \\| } q[\\gamma_{2 } ] } { e^{- ( d - rs_{1})n^{-1 } ( d - rs_{1 } ) - s_{1 } c^{-1}[\\gamma_{1 } ] s_{1 } - \\log \\| c(\\gamma_{1 } ) \\| } q[\\gamma_{1 } ] } \\ ] ] as well as @xmath113 s_{1 }   } { \\tilde p}(\\gamma_{1 } | y ) } { e^{- ( d - rs_{2 } ) n^{-1 } ( d - rs_{2 } ) - s_{2 } c^{-1}[\\gamma_{2 } ] s_{2 }    } { \\tilde p}(\\gamma_{2 } | y)}\\ ] ] which simplifies to the explicitly computable acceptance probability @xmath111 = \\min \\left [ 1 , \\frac{e^{- \\log \\| c(\\gamma_{2 } ) \\| } q[\\gamma_{2 } ] } { e^{- \\log \\| c(\\gamma_{1 } ) \\| } q[\\gamma_{1 } ] } \\frac{{\\tilde p}(\\gamma_{1 } | y ) } { { \\tilde p}(\\gamma_{2 } | y ) } \\right]\\ ] ] in summary , a single step of the markov chain involves :    * choose a new guess for the power spectrum from @xmath109 . *",
    "sample a map from @xmath114 according to * * compute the mean field map @xmath115^{-1 } r^{t } n^{-1 } y$ ] . * * for two independently sampled white noise maps in the spatial and time domains @xmath116 , compute @xmath69 as the solution to @xmath117 . * * set @xmath118 . *",
    "accept the transition @xmath119 with probability @xmath120 $ ] .",
    "* continue    for circularly symmetric beams , each step of the markov chain has expense @xmath89 $ ] , giving a total expense @xmath121 $ ] , where @xmath122 is the number of realizations of @xmath123 , and @xmath124 quantifies the `` efficiency '' of the markov chain ( suggestively denoted by @xmath125 since we intuitively expect it to vary inversely with the average acceptance probability ) .    by the efficiency of the markov chain , we mean the number of proposed moves that must be made until one is accepted .",
    "this efficiency depends entirely on how good the approximation to the posterior @xmath109 actually is .",
    "we can always write the acceptance matrix as @xmath111 = \\min \\left [ 1 , \\frac{p(s_{2 } | \\gamma_{2 } , y)}{p(s_{1 } | \\gamma_{1 } ,   y ) } \\frac{p(\\gamma_{2}| y)}{p(\\gamma_{1 } | y ) } \\frac{\\rho(s_{1 } | \\gamma_{1 }   y ) } { \\rho(s_{2 } | \\gamma_{2 }    y ) } \\frac{{\\tilde p } ( \\gamma_{1 } |",
    "y ) } { { \\tilde p}(\\gamma_{2 } |   y ) } \\right]\\ ] ] however , by construction , this is exactly @xmath111 = \\min \\left [ 1 , \\frac{p(\\gamma_{2}| y)}{p(\\gamma_{1 } | y ) } \\frac{{\\tilde p } ( \\gamma_{1 } |   y ) } { { \\tilde p}(\\gamma_{2 } |   y ) } \\right]\\ ] ] so that if our approximation was exact , the acceptance matrix is unity for all proposals , and we reduce to an expense @xmath126 $ ] .",
    "provided that we have reasonable approximations to the posterior , we can converge to the exact posterior with this method , and the use of transformed white noise sampling .",
    "we also briefly comment on some practical issues with this approach . in order to run the markov chain",
    ", we need to compute the mean field map _ for every proposed power spectrum_. while this is feasible , we can speed up the markov chain by sampling a grid of power spectra from our approximation @xmath127 , and pre - computing the mean field maps for each @xmath9 on our grid . then , for any proposed power spectrum , we can start with the initial condition for conjugate gradient descent with the closest grid point .",
    "we conclude with a brief discussion of the inclusion of foregrounds .",
    "the inclusion of the foregrounds involves sampling both cmb and foreground maps given some estimate of the cmb power spectrum and some prior for the foregrounds . for a gaussian prior for the foregrounds , the same approach to sampling",
    "can be followed .",
    "including foregrounds the data for the jth frequency channel is given by @xmath128 where @xmath129 is the mapping from the sky to the time domain for the jth frequency channel , @xmath130 is the response of the cmb at the jth frequency , and we sum over the foreground components @xmath131 . for a statistical characterization of the foregrounds @xmath132 and a guess of the cmb power spectrum @xmath9",
    ", we need to sample from the density given by ( up to normalization ) @xmath133 we need to compute the expectation value @xmath134 = \\int d(s , f ) \\",
    "c_{l}(s ) \\ p(s , f | d,\\gamma_{0 } , \\beta)\\ ]",
    "] this expectation value can be numerically computed by sampling maps @xmath135 by the time average of a markov chain with equilibrium density @xmath136 .",
    "one legitimate way to construct such a markov chain is to alternately sample maps from the conditional densities @xmath137 and @xmath138 .",
    "we briefly comment on sampling maps from each of these conditional densities .    given some estimate of the foregrounds ,",
    "we need to sample maps from the conditional density @xmath139 sampling from @xmath137 proceeds in essentially the same way as described above , but generalized for multi - frequency data .",
    "specifically , the mean field map includes the subtracted response from the foreground estimate @xmath140^{-1 } a_{0 } r^{t }   n^{-1 } ( d - af)\\ ] ] and the fluctuation maps include a time domain white noise sample for each frequency channel @xmath141 note that the covariance matrix of the fluctuations is @xmath142 = ( c^{-1 } + r^{t } a_{0 } n^{-1 } a_{0 } r)^{-1}\\ ] ] where the proof depends on the independence of the time domain white noise maps for every frequency channel .    given some estimate of the cmb ,",
    "we need to sample from the conditional density @xmath143 if the prior for the foregrounds @xmath144 is gaussian @xmath145 then we can also use transformed white noise sampling .",
    "first , we compute the mean field foreground map , @xmath146^{-1 } r^{t } a n^{-1 } ( d - a_{0 } s)\\ ] ] and then sampling fluctuations @xmath147 according to the transform of white noise samples @xmath148 multiplying by the foreground signal matrix @xmath149 is either done in the pixel or spherical harmonic basis depending on the basis in which it is sparse .",
    "if we use a non - gaussian prior ( such as the maximum entropy method , or other priors ) , then we will need to employ more general sampling techniques to sample foreground maps , such as the metropolis algorithm . in this case",
    "the needed expectation value is to be computed as the _ time average _ from a markov chain with equilibrium density @xmath150 .",
    "the fundamental hurdle to numerically implementing an exact bayesian approach to cmb analysis , including complications of partial sky coverage , correlated noise , and foregrounds , is finding efficient ways to solve the linear problem @xmath151 for any vector @xmath78 . solving",
    "the linear equation has an expense @xmath89 $ ] for circularly symmetric beams , and the algorithm provides a tractable approach provided @xmath3 can be made small enough .",
    "the strategy we presented in this paper allows the data to be embedded in an azimuthally symmetric region of the sky covered by a wandelt ring set scan , with the intuition that , provided the true scan of the instrument is close enough to the exact scan , we inherit good preconditioners .",
    "we also commented on how the method of transformed white noise sampling can be used in monte carlo markov chain for the entire bayesian posterior .",
    "the feasibility of this approach depends on a good approximation to the posterior itself .",
    "previous work has demonstrated several computationally feasible , unbiased estimates of the power spectrum and associated error covariance matrix .",
    "any of these methods could therefore be used , in principle , to give an approximate posterior , so that a markov chain approach can be used as a final consistency check .",
    "future work will incorporate the foregrounds in the algorithm presented here , generalized for multifrequency data .",
    "maximization of the likelihood of the power spectrum given the data again leads to the computation of the expectation value @xmath152 $ ] , but now the marginalization includes the foregrounds as well .",
    "if the prior for the foregrounds is gaussian , then we can also use transformed white noise sampling to sample a new foreground map while conditioning on the cmb .",
    "if the prior used is non - gaussian , other sampling schemes can be used , including gibbs sampling or the metropolis algorithm .",
    "this research was carried out at the nasa jet propulsion lab , under nasa aisrp grant , and support from the long wavelength center .",
    "we also thank eric hivon and ben wandelt for interesting discussions during the course of this work .",
    "the data returned from a cmb experiment is a vector @xmath27 in the time domain , generated from scanning the cmb signal @xmath28 and foregrounds @xmath153 on the sky and adding independent gaussian noise .",
    "the bayesian posterior is given directly as an integral over unknown quantities by @xmath154 for the case of gaussian random fields , this integral can be done analytically ( as will be discussed in appendix [ applikelihoods ] ) , but evaluation of the resulting likelihood leads to computationally intractable matrix manipulations .",
    "for any estimate @xmath10",
    "@xmath155 p(\\gamma_{0},s , f|d)\\ ] ] since we have @xmath156 this becomes @xmath157 p(s , f|\\gamma_{0},d)\\ ] ] where we have used @xmath158 . by the assumed independence of the noise ,",
    "the joint density over which we are marginalizing is @xmath159 where @xmath50 is a prior for the parameters , @xmath160 is a prior for the foregrounds , and @xmath161 is completely determined by the noise properties of the instrument , the beam , and scan strategy . given some estimate of the noise free cmb signal , the density for a new guess of the power spectrum is independent of the data , @xmath162 , as shown by @xmath163 therefore , for _ any estimate _",
    "@xmath10 , our identity now reads @xmath164 p(s , f|\\gamma_{0},d)\\ ] ] or for the likelihood ratio @xmath165 p(s , f|\\gamma_{0},d)\\ ] ]      the likelihood of the data , generally in the time domain for some experiment , is @xmath166 we first consider the case of transforming the time ordered data to a map according to the transformation @xmath37 .",
    "the likelihood is the probability density evaluated at the data .",
    "therefore , we first need to find the probability density of _ maps _ given by transforming the density for time ordered data , according to @xmath167 = \\int \\delta d \\",
    "\\delta[{\\hat s } - ( r^{t } n^{-1 } r)^{-1 } r^{t } n^{-1 } d ] \\",
    "e^{- ( d - rs)n^{-1 } ( d - rs ) } e^{-s c^{-1 } s}\\ ] ] this is equivalently @xmath168 & \\propto &   \\int \\delta d \\   \\delta[{\\hat s } - ( r^{t } n^{-1 } r)^{-1 } r^{t } n^{-1 } d ] \\",
    "e^{- ( d - rs)n^{-1 } ( d - rs ) } e^{-s c^{-1 } s } \\nonumber \\\\ & = &   \\int \\delta d \\ \\int dk \\",
    "e^{- i k \\cdot { \\hat s } } e^{+i k \\cdot ( r^{t } n^{-1 } r)^{-1 } r^{t } n^{-1 } d } \\int ds \\ e^{- ( d - rs)n^{-1 } ( d - rs ) } e^{-s c^{-1 } s } \\nonumber \\\\ & = &   \\int dk \\   e^{- i k \\cdot { \\hat s } } \\int ds \\",
    "e^{-s c^{-1 } s } \\int \\delta d \\",
    "e^{+i k \\cdot ( r^{t } n^{-1 } r)^{-1 } r^{t } n^{-1 } d } e^{- ( d - rs)n^{-1 } ( d - rs ) } \\nonumber \\\\ & = &   \\int dk \\    e^{-",
    "i k \\cdot { \\hat s }   }   \\int ds \\",
    "e^{+ i k \\cdot s   } e^{-s c^{-1 } s } \\int \\delta d \\",
    "e^{+i k \\cdot ( r^{t } n^{-1 } r)^{-1 } r^{t } n^{-1 } ( d - rs ) } e^{- ( d - rs)n^{-1 } ( d - rs ) } \\nonumber \\\\ & = &   \\int dk \\    e^{-",
    "i k \\cdot { \\hat s }   } e^{- k ( r^{t } n^{-1 } r)^{-1 } k }   \\int ds \\",
    "e^{+ i k \\cdot s   } e^{-s c^{-1 } s } \\nonumber \\\\ & = &   \\int dk \\",
    "e^{- i k \\cdot { \\hat s }   } e^{- k ( r^{t } n^{-1 } r ) ^{-1 } k }   e^{- k c k } \\nonumber \\\\ & = &   e^{- { \\hat s } [ ( r^{t } n^{-1 } r ) ^{-1 } + c   ] ^{-1 } { \\hat s } } \\end{aligned}\\ ] ] notice that there are many time series vectors which correspond to the same spatial map , since we can add any vector such that @xmath169 .",
    "this is possible since @xmath170 vanishing means that averages at the same point vanish .",
    "we can also write the likelihood in terms of the data in the original time domain . this can be done by writing the characteristic function @xmath171 which shows that @xmath172      the likelihood for the cmb given the theory for partial sky coverage can be written as the marginalization over the unobserved part of the sky . denoting the cmb @xmath173 as the cmb in the observed and unobserved regions of sky respectively , we have @xmath174 therefore",
    ", the posterior for partial sky coverage can be written @xmath175 p(f|\\beta ) \\nonumber \\\\ & = & q(\\gamma ) \\int d(s^{(1)},s^{(2)},f ) \\",
    "p(y|s^{(1)},f )   p(s^{(1)},s^{(2 ) } |\\gamma )   p(f|\\beta)\\end{aligned}\\ ] ] this gives the identity , explicitly written for arbitrary sky coverage , @xmath176 p(s^{(1)},s^{(2)},f|\\gamma_{0},y)\\ ] ] because @xmath177 is supported on the full sky , the log posterior ratio is @xmath178\\ ] ] and the conditional density from which we are to sample @xmath179 is @xmath180 this is equivalent to setting the inverse noise matrix to zero for the part of the sky where there is no data .",
    "two limiting cases of our identity involve `` no data '' and `` no noise '' . in the no data limit ,",
    "the inverse noise matrix vanishes everywhere , so that @xmath181 and the posterior is given by the prior , as shown by @xmath182 p(s   | \\gamma_{0 } ) \\nonumber \\\\ & = &   \\int ds \\",
    "\\left [ \\frac{p(s|\\gamma ) q(\\gamma)}{p(s|\\gamma_{0 } ) q(\\gamma_{0 } ) } \\right ] p(s   | \\gamma_{0 } ) \\nonumber \\\\ & = &   \\frac { q(\\gamma ) } { q(\\gamma_{0 } ) } \\int ds \\",
    "p(s|\\gamma ) \\nonumber \\\\ & = &   \\frac { q(\\gamma ) } { q(\\gamma_{0})}\\end{aligned}\\ ] ] in the noise free limit , the conditional density @xmath183 , independent of our choice of @xmath10 , so that we converge to the noise - free posterior ratio .",
    "recall the the algorithm used involves iterating @xmath184\\ ] ] and therefore the fixed point satisfies @xmath185 $ ] .",
    "we can prove that this estimator maximizes the posterior , or equivalently the log posterior .",
    "a direct calculation shows that @xmath186 \\frac{p(\\gamma|s)}{p(\\gamma_{0}|s ) } p(s|y,\\gamma_{0})\\ ] ] so that at the maximum @xmath187   p(s|y,\\gamma_{0})\\ ] ] at the maximum we therefore have @xmath188 which is identically the fixed point of the expectation maximization algorithm .",
    "therefore , the iteration converges to the maximum of the posterior ( for a uniform prior ) .      after we have computed the maximum likelihood estimator of the power spectrum ( or maximum posterior estimate ) , we want to find a confidence interval .",
    "there are several ways this confidence interval might be approximated .",
    "one approach is to compute the inverse curvature matrix of the likelihood , and take the diagonal entries as an estimate of the error bars ( refs ) .",
    "we comment below on how this can be done with the same method used to compute @xmath189 $ ] .    approximating the likelihood as",
    "a gaussian functional of the @xmath190 is equivalent to a second order taylor expansion of the log likelihood about the maximum . as",
    "before we have the identity for the likelihood @xmath191 it is more convenient to parameterize the likelihood ratio in terms of @xmath192 , so that when embedding the data on the full sky , we have @xmath193 c_{l}(s ) - \\log \\frac{\\theta_{l}(\\gamma)}{\\theta_{l}(\\gamma_{0 } ) } \\right)\\ ] ] denoting the curvature matrix of the likelihood @xmath194 \\equiv - \\frac{\\partial^{2 } \\log p(d|\\gamma ) } { \\partial c_{l } \\partial c_{l ' } } \\ ] ] we have the relation @xmath195    & = & \\frac{1}{c^{2}_{l}(\\gamma_{0 } ) } \\frac{\\partial^{2 } \\log p(d|\\gamma ) } { \\partial \\theta_{l } \\partial \\theta_{l ' } } \\frac{1}{c^{2}_{l'}(\\gamma_{0})}\\end{aligned}\\ ] ] the curvature of @xmath196 evaluated at the maximum , where @xmath197 $ ] is therefore @xmath198 - c_{l}(\\gamma_{0 } ) c_{l'}(\\gamma_{0 } ) \\right]\\end{aligned}\\ ] ] where we have defined the expectation value @xmath57   = \\int d\\xi \\    c_{l}({\\hat s } + \\xi ) c_{l'}({\\hat s } + \\xi ) \\",
    "\\xi [ n^{-1 } + c^{-1}(\\gamma_{0 } ) ] \\xi } } { \\det |n^{-1 } + c^{-1}(\\gamma_{0 } ) |}\\ ] ] this can , in principle , be computed with the conjugate gradient descent method of transforming samples from a white noise process .",
    "future work will study the accuracy and convergence properties of estimating the curvature matrix from transformed white noise sampling .",
    "the correctness of the algorithm for power spectrum estimation presented in this paper is established by proving that the covariance matrix of two linearly transformed vectors has some specific form .",
    "for simplicity of notation , we choose to denote the covariance matrix of two vectors @xmath199 as the expectation value of the outer product of the vectors @xmath200 \\equiv e[x \\otimes y]_{ij}$ ] . for two matrices @xmath201 and @xmath149 , an identity used repeatedly in computing covariance matrices is @xmath202 = a e[x \\otimes y ] b^{t}\\ ] ] which is shown simply by checking for each matrix element @xmath203_{mn } & = &   \\sum_{ij } e[a_{mi } x_{i } b_{nj } y_{j } ] \\nonumber \\\\ & = & \\sum_{ij } a_{mi } e[x_{i } y_{j } ] b^{t}_{jn}\\end{aligned}\\ ] ] one example of this identity is in computing the expectation value of maps computed from time ordered data .",
    "one form of making a map from time ordered data is given by @xmath204 as mentioned in section 2 and in @xcite . according to the identity above",
    ", the covariance matrix of this map is @xmath205 & = & ( r^{t } n^{-1 } r)^{-1 } r^{t } n^{-1 } e[d \\otimes d ]   ( r^{t } n^{-1 } ) ^{t } [ ( r^{t } n^{-1 } r)^{-1}]^{t } \\end{aligned}\\ ] ] substituting @xmath34 , this is @xmath205 & = & ( r^{t } n^{-1 } r)^{-1 } r^{t } n^{-1 } e[(rs + \\eta )   \\otimes ( rs + \\eta ) ]   n^{-1 } r   ( r^{t } n^{-1 } r)^{-1 } \\nonumber \\\\ & = & ( r^{t } n^{-1 } r)^{-1 } r^{t } n^{-1 } \\left (   r e[s \\otimes s ] r^{t }   + r e[s \\otimes \\eta ] \\right .",
    "\\nonumber \\\\ & & \\left .",
    "+ e[\\eta \\otimes s ] r^{t } + e[\\eta \\otimes \\eta ] \\right ) n^{-1 } r   ( r^{t } n^{-1 } r)^{-1 } \\nonumber \\\\ & = & ( r^{t } n^{-1 } r)^{-1 } r^{t } n^{-1 } \\left (   r c r^{t }   + n \\right ) n^{-1 } r   ( r^{t } n^{-1 } r)^{-1 } \\nonumber \\\\ & = & c + ( r^{t } n^{-1 } r)^{-1}\\end{aligned}\\ ] ] where we have used the independence of the signal and noise , and also that both are zero mean processes .",
    "this result is also proven in appendix b below using the characteristic function of the transformed time ordered data .",
    "the estimator given by the expectation maximization algorithm ( also equivalent to the maximum likelihood estimator ) is given by @xmath206 = \\int ds \\ [ s \\otimes s ]   \\ \\frac{e^{- ( y - rs ) n^{-1 } ( y -rs ) - sc^{-1 } s } } { \\int ds ' \\ e^{- ( y - rs ' ) n^{-1 } ( y -rs ' ) - s ' c^{-1 } s ' } } \\ ] ] for partial sky coverage , this is equivalent to embedding the data on the full sky and marginalizing over it @xmath206",
    "=   \\int d(s , y^{(2 ) } ) \\ [ s \\otimes s ]   \\ \\frac{e^{- ( y^{(2 ) } - s ) { \\tilde n}^{-1 } ( y^{(2 ) } - s ) } e^{- ( y - rs ) n^{-1 } ( y -rs ) - sc^{-1 } s } } { \\int d(s',y ' ) \\ e^{- ( y ' - s ' ) { \\tilde n}^{-1 } ( y ' - s ' ) } e^{- ( y - rs ' ) n^{-1 } ( y -rs ' ) - s ' c^{-1 } s ' } } \\ ] ] where we have arbitrarily chosen the full sky inverse noise matrix @xmath207\\ ] ] the expectation of the covariance matrix is then @xmath208 =   \\int dy \\ \\int d(s , y^{(2 ) } ) \\ [ s \\otimes s ]   \\ \\frac{e^{- ( y^{(2 ) } - s ) { \\tilde n}^{-1 } ( y^{(2 ) } - s ) } e^{- ( y - rs ) n^{-1 } ( y -rs ) - sc^{-1 } s } } { \\int d(s',y ' ) \\ e^{- ( y ' - s ' ) { \\tilde n}^{-1 } ( y ' - s ' ) } e^{- ( y - rs ' ) n^{-1 } ( y -rs ' ) - s ' c^{-1 } s ' } } \\ ] ] consistency of the estimator is then shown by proving that @xmath209 $ ] .    using the augmented noise matrix ( which now has an inverse on the full sky ) , we can define the mean field map @xmath210^{-1 } n^{-1 } ( y , y^{(2)})$ ] , and write @xmath211 & = & ( n^{-1 } + c^{-1})^{-1 } n^{-1 } e[y \\otimes y ] n^{-1 } ( n^{-1 } + c^{-1})^{-1 } \\nonumber \\\\ & = & c(n+c)^{-1 }   ( n+c )   ( n+c)^{-1 } c \\nonumber \\\\",
    "& = & c(n+c)^{-1 }   c\\end{aligned}\\ ] ] the expectation value of the correction is @xmath212 , so that @xmath211 & = & c ( n+c)^{-1 }   c + ( n^{-1 } + c^{-1})^{-1 } \\nonumber \\\\ & = & c(n+c)^{-1 }   c + n(n + c)^{-1 } c \\nonumber \\\\ & = & c\\end{aligned}\\ ] ] therefore , the expectation maximization algorithm converges to the maximum likelihood estimator for a uniform prior , which is also a consistent estimator for arbitrary sky coverage .",
    "as derived in section ? above , the algorithm to sample maps from the gaussian process with covariance matrix @xmath68 is    * draw @xmath213 from a white noise process . *",
    "compute @xmath214 . *",
    "compute @xmath215 with conjugate gradient descent .",
    "we can prove that for any @xmath19 , even one which does not have an inverse ( i.e. as in the case of partial coverage of the chosen embedding region ) , we have @xmath81 = ( n^{-1 } + c^{-1})^{-1}$ ] . from the above we",
    "have @xmath216\\ ] ] which gives @xmath217 & = & ( n^{-1 } + c^{-1})^{-1 } e [ ( c^{-1/2 } \\omega ' +    n^{-1/2 } \\omega ) \\otimes ( c^{-1/2 } \\omega ' +   n^{-1/2 } \\omega ) ] ( n^{-1 } + c^{-1})^{-1 } \\nonumber \\\\ & = & ( n^{-1 } + c^{-1})^{-1 }    \\left ( c^{-1/2 } e[\\omega ' \\otimes \\omega ' ] c^{-1/2 } + c^{-1/2 } e[\\omega ' \\otimes \\omega ] n^{-1/2 }   \\right .",
    "\\nonumber \\\\ & & \\left .",
    "+ n^{-1/2 } e[\\omega \\otimes \\omega ' ] c^{-1/2 } + n^{-1/2 } e[\\omega \\otimes \\omega ] n^{-1/2 }   \\right ) ( n^{-1 } + c^{-1})^{-1 } \\nonumber \\\\ & = & ( n^{-1 } + c^{-1})^{-1 }   \\left (   c^{-1 } + n^{-1 }    \\right )   ( n^{-1 } + c^{-1})^{-1 }    \\nonumber \\\\ & = & ( n^{-1 } + c^{-1})^{-1 } \\end{aligned}\\ ] ] where by independence of the two white noise maps , @xmath218 = e[\\omega ] \\otimes e[\\omega']$ ] which vanishes since the white noise process is zero mean .",
    "an important point to notice is that the matrices @xmath19 or @xmath82 can be singular in the sense that they do not have inverses on the full sky ( i.e. are generated by incomplete scanning of the sky ) .",
    "in fact @xmath219 vanishes in the null space of @xmath19 ( where we do not have data ) .    for a realization of a white noise process in the time domain @xmath83 and a white noise map in the spatial domain @xmath84 ,",
    "we compute a fluctuation map according to @xmath220\\ ] ] where @xmath82 is known in the fourier basis associated with the time domain .",
    "we can prove that the maps @xmath69 have the correct covariance matrix , @xmath81 = ( r^{t } n^{-1 } r + c^{-1})^{-1}$ ] by the direct calculation @xmath217 & = & ( r^{t } n^{-1 } r + c^{-1})^{-1 }   e [ ( c^{-1/2 } \\omega + r^{t } n^{-1/2 } \\tau ) \\otimes ( c^{-1/2 } \\omega + r^{t } n^{-1/2 } \\tau ) ] ( r^{t } n^{-1 } r + c^{-1})^{-1 } \\nonumber \\\\ & = & ( r^{t } n^{-1 } r   + c^{-1})^{-1 }    \\left ( c^{-1/2 } e[\\omega \\otimes \\omega ] c^{-1/2 } + + r^{t } n^{-1/2 } e[\\tau \\otimes \\tau ] n^{-1/2 } r \\right ) ( r^{t } n^{-1 } + c^{-1})^{-1 } \\nonumber \\\\ & = & ( r^{t } n^{-1 } r   + c^{-1})^{-1 }    \\left ( c^{-1 } + r^{t } n^{-1 }   r \\right ) ( r^{t } n^{-1 } + c^{-1})^{-1 } \\nonumber \\\\ & = & ( r^{t } n^{-1 } r   + c^{-1})^{-1 }    \\end{aligned}\\ ] ] where again , the cross terms vanish since independence gives @xmath221 = e[\\omega ] \\otimes e[\\tau]$ ] , which vanishes since both are zero mean processes .",
    "we can also find the likelihood for the data embedded in an azimuthally symmetric region covered by a ring set .",
    "as discussed in @xcite , we represent the signal on the ring set with coefficients @xmath222 , so that @xmath223 where both indices range from @xmath224",
    ". therefore , the signal on the sky , parameterized on the ring set , is given by a two - d inverse fft .",
    "for any specific power spectrum , the corresponding signal matrix on the ring set covering the embedding region is block diagonal .",
    "we denote the ring set covariance matrix @xmath225 $ ] .    given the noise free signal on the ring set @xmath226 , any observed data set is given by projecting into the sub - region where we have data , @xmath227 where @xmath228 vanishes on the regions of the ring set where we have no observations .",
    "as before we would first compute the mean field and fluctuation maps .",
    "in order to sample fluctuation maps , we would again compute , @xmath229 where @xmath83 is a time domain white noise process , @xmath84 is a spatial white noise process on the full sky , @xmath230 is the cholesky decomposition of the ring set covariance matrix .",
    "although it is possible to compute the cholesky decomposition of the ring set covariance matrix , we might instead sample @xmath231 on the full sky , and then project into the region covered by the ring set , giving maps @xmath232 .",
    "then the covariance matrix for these maps is , using the usual identity @xmath233 & = & r c^{1/2 } e[\\omega \\otimes \\omega ]   c^{1/2 } r^{t } \\nonumber \\\\ & = & r c r^{t}\\end{aligned}\\ ] ] which is the correct covariance matrix on the ring set region .",
    "the point is that we do not have to compute the cholesky decomposition of the signal matrix on the ring set , but can instead transform white noise maps with the choelsky decomposition of the full sky signal covariance matrix ( diagonal in the spherical harmonic basis ) , and then project down to the ring set region .",
    "we can construct a preconditioner as follows .",
    "define the projection from the time domain to the ring set following a wandelt scan strategy as @xmath234 .",
    "the for the same time domain noise matrix @xmath19 , we can use a preconditioner given by @xmath234 and define @xmath235^{-1}\\ ] ] it is shown in @xcite that @xmath234 is block diagonal on the ring set , so that @xmath236 can be computed in @xmath5 operations .",
    "we can then solve the linear equations for the mean field and fluctuation maps @xmath237 { \\hat s } & = &   m^{-1}t q^{t } n^{-1 } d \\nonumber \\\\ m^{-1 } [ i + t q^{t } n^{-1 } q ] \\xi & = & m^{-1 } \\left ( t^{+1/2 } \\omega + t q^{t } n^{-1/2 } \\tau \\right)\\end{aligned}\\ ] ] for scans which are close to the ring set scan the intuition is that conjugate gradient descent will converge quickly for the above equations .",
    "stompor , r. , et al . , astro - ph/0106451 .",
    "seljack , u. and zaldarriaga , m. , apj , 469 , 437 , 1996 .",
    "gorski , e.k . ,",
    "hivon , e. , and wandelt , b. , in proceedings of the mpa / eso garching conference 1998 , eds .",
    "banday , a.j . ,",
    "sheth , k. , and l. da costa .",
    "see http://www.eso.org  kgorski / healpix/    borrill , j. , phys .",
    "d59 , 027302 , 1999 .",
    "bond , j.r .",
    "et al , comput.sci.eng . 1 , 21 , 1999 .",
    "dempster , a.p . ,",
    "laird , n.m . , and rubin , d.b . , j. roy . stat",
    "b , vol . 39 , no .",
    "1 , pp . 1 - 38 , 1977 .",
    "tegmark , m. , phys .",
    "d55 , 5895 - 5907 , 1997 .",
    ", spergel , d.n . , and hinshaw , g. , apj,510 , 551 , 1999 .",
    "wandelt , b. and hansen , f. , astro - ph/0106515 , 2001 .",
    "wandelt , b. and gorski , k. , phys .",
    "rev d , 63,123002 , 2001 .",
    "bond , j.r . ,",
    "jaffe , a.h . ,",
    "knox , l. , phys .",
    "d , 57 , 2117 , 1998 .",
    "christenson , r. , et al .",
    "grav . , 18,2677 , 2001 .",
    "knox , l. , et al .",
    ", apj , 563 , l95 , 2001 .",
    "lewis , a. , and bridle , s. , astro - ph/0205436 .",
    "runbino - martin , et al . , astro - ph/0205367 .",
    "* _ figure 1 _ - the top left image shows the variance of the noise in each pixel .",
    "the black region is an unobserved `` hole '' .",
    "the upper right plot is a noise free realization , and the lower left is a mean field map given the simulated noisy data .",
    "the bottom right shows a typical fluctuation map computed with conjugate gradient descent . * _ figure 2 _ - plot showing the power spectrum estimation after @xmath238 iterations starting from a flat initial guess .",
    "the green dots represent the results of separate runs on each of 10 simulated data sets , with each shade of green representing a different run . for each data set",
    "we have produced a new noise - free map ( drawn from the theoretical power spectrum given by the solid black line ) , and added inhomogenous noise and a hole as shown in figure 1 .",
    "the initial guess used was the expected ( flat ) noise spectrum , multiplied by a random number between 0 and 1 . at low @xmath239",
    "the snr is high , and the spread in the dots is caused by noise and sample variance . at high @xmath239 , the snr is low and the spread in the dots is caused by variation in the initial guess , resulting in an upper bound as shown in the plot . also shown are sample power spectra for a single simulated data set ( light blue line ) , and noise - free map ( dark blue line ) ."
  ],
  "abstract_text": [
    "<S> power spectrum estimation and evaluation of associated errors in the presence of incomplete sky coverage ; non - homogeneous , correlated instrumental noise ; and foreground emission is a problem of central importance for the extraction of cosmological information from the cosmic microwave background . </S>",
    "<S> we develop a monte carlo approach for the maximum likelihood estimatation of the power spectrum . </S>",
    "<S> the method is based on an identity for the bayesian posterior as a marginalization over unknowns , and maximization of the posterior involves the computation of expectation values as a sample average from maps of the cosmic microwave background and foregrounds given some current estimate of the power spectrum or cosmological model , and some assumed statistical characterization of the foregrounds . </S>",
    "<S> maps of the cmb and foregrounds are sampled by a linear transform of a gaussian white noise process , implemented numerically with conjugate gradient descent . for time </S>",
    "<S> series data with @xmath0 samples , and @xmath1 pixels on the sphere , the method has a computational expense @xmath2 $ ] , where @xmath3 is a prefactor determined by the convergence rate of conjugate gradient descent . </S>",
    "<S> preconditioners for conjugate gradient descent are given for scans close to great circle paths , and the method allows partial sky coverage for these cases by numerically marginalizing over the unobserved , or removed , region . </S>"
  ]
}