{
  "article_text": [
    "in most financial institutions , the risk of their portfolios is measured by _ economic capital_. for the purpose of further risk analysis , it is necessary to decompose the portfolio - wide economic capital into the sum of risk contributions by unit exposures .",
    "this risk - redistribution process is called _ capital allocation _ , and the allocated capitals are called _ risk contributions _ ( see , e.g. , dev , 2004 ) . since it is non - trivial to allocate the economic capital in an economically meaningful way , various principles to determine the risk contributions have been proposed . among these principles ,",
    "the _ euler principle _ is one of the most well - established rule proposed in tasche ( 1999 ) .",
    "its financial justification is given from differing points of view ( e.g. , by denault , 2001 ; kalkbrener , 2005 ; tasche , 1999 ) .",
    "detailed references for rationalizing the use of the euler principle can also be found in tasche ( 2008 ) .    despite its good economic properties , actual computation of risk contributions",
    "poses theoretical and numerical difficulties , especially when the portfolio - wide risk is measured by _ value - at - risk _ ( var ) .",
    "although the explicit formula of var contributions is derived by tasche ( 2001 ) , it can rarely be calculated analytically with a very few exceptions ( such as creditrisk@xmath0 studied in tasche , 2004 ) .",
    "therefore , _",
    "monte carlo ( mc ) _ method is often used to obtain numerical solution .",
    "however , the mc estimator of var contributions suffers from significant bias caused by sample - inefficiency and inevitable numerical modification ( see , e.g. , yamai and yoshiba , 2002 for the example ) . to overcome the difficulties , several methods have been proposed in the literature .",
    "hallerbach ( 2003 ) and tasche and tibiletti ( 2004 ) proposed the approximation formulae by regarding the var contributions as the best prediction of losses given the total loss , under some model assumptions . in this paper , we call the estimator derived in such a way the _ generalized regression ( gr ) estimator_. evaluation of the approximation error caused by the model misspecification is quite difficult .",
    "furthermore , it is also challenging to find a well - fitted model among losses , to accurize the approximation .",
    "glasserman ( 2005 ) developed _ importance sampling ( is ) estimators _ in the case of credit portfolios .",
    "although the problem of sample - inefficiency is overcomed in the is method , risk models where the is technique are available are quite limited . consequently ,",
    "the is estimator can not be applied to various risk models widely used in practice .",
    "tasche ( 2009 ) proposed the _ nadaraya - watson ( nw ) estimator _ constructed by using kernel estimation method .",
    "although the nw estimator is available to most risk models , incorporation of the importance sampling technique is still indispensable to achieve efficient estimation .",
    "moreover , the asymptotic standard error of the nw estimator can not be computed easily .    in this paper",
    ", we propose a new estimator of var contributions that utilizes _ markov chain monte carlo ( mcmc ) _ method .",
    "our mcmc - based estimator is available whenever the portfolio loss model is specified by the joint density .",
    "this case contains wide varieties of risk models since the joint density can be completely specified for all models having marginal densities and copula density ( see , e.g. , yoshiba , 2013 for various examples of this type of models ) . in this case",
    ", the is technique can hardly be available , and thus the problem of estimating var contributions is generally unsettled .",
    "we study theoretical properties of our mcmc estimator , and provide a guideline for the efficient application of mcmc to our problem .",
    "the proposed estimation method is then carried out within some risk models often used in practice .",
    "for these risk models , we compare the performance of the mcmc estimator with the existing estimators .",
    "the mcmc estimator has several attractive properties .",
    "first , the mcmc estimator is consistent .",
    "since the mcmc method has an improved sample - efficieny compared with the mc method , we can expect the mcmc estimate to have much smaller bias than that of mc .",
    "second , the mcmc estimator holds asymptotic normality , and its standard error can be consistently estimated by using methods in the theory of markov chain . thanks to these features , we can construct approximated confidence interval of the true var contributions .",
    "moreover , together with the sample - efficiency of the mcmc method , we can expect that the mcmc estimator has much smaller standard error compared with the existing methods . finally , the mcmc estimator is free from model - misspecification bias , and can flexibly incorporate the feature of the underlying loss distribution into the estimation .",
    "in contrast with the gr estimator , the mcmc estimator does not use any approximation .",
    "therefore , the mcmc estimator is free from the approximation error caused by the model - misspecification .",
    "moreover , by choosing an appropriate proposal distribution of the mcmc , we can directly capture the features of the underlying loss distributions , thanks to these propertoes , the mcmc estimator can have stably good performance regardless of the underlying risk model .",
    "the key idea behind the mcmc estimator is to generate samples directly from the joint loss distribution given a rare event of interest .",
    "this approach is completely different from the crude mc method in which samples are generated from the loss distribution itself . in the mc method ,",
    "large portion of samples have to be discarded because var contributions depend only on losses given the rare event .",
    "our method , in contrast , does not waste any samples for the estimation . thanks to this difference , great sample - efficiency can be achieved in the mcmc method .",
    "how can we generate samples directly from the conditional density on the rare event ?",
    "usually it is quite difficult because our conditional density contains the density of the total loss , which is too cumbersome to compute .",
    "nevertheless , mcmc method enables us to generate their samples directly by sequentially updating the samples , without evaluating the cumbersome term on the total loss .",
    "the paper is organized as follows .",
    "section @xmath1 introduces the mathematical setting of the capital allocation problem , and explains problems for estimating var contributions with the existing estimators .",
    "section @xmath2 is devoted to the brief introduction to markov chain monte carlo method .",
    "several families of the proposal distributions are also introduced for efficient use of mcmc . in section @xmath3",
    ", we propose the mcmc estimator , that combines the mcmc method with estimation of var contributions to achieve more sample efficiency .",
    "based on the theory of mcmc , we also study some theoretical properties of our mcmc estimator .",
    "numerical results and empirical studies are presented in section @xmath4 .",
    "we demonstrate that , for widely used risk models in practice , the mcmc estimator has smaller bias and mse than those of existing estimators . through the empirical study , we provide a guideline of incorporating the mcmc method in our framework of estimating var contributions . concluding remarks , future research and potential extensions of the mcmc estimator are summarized in section @xmath5 .    throughout the paper , integration of vector - valued function",
    "is applied componentwise .",
    "let @xmath6 be the set of @xmath7-valued @xmath8 matrices and @xmath9 be the set of @xmath7-valued positive definite @xmath8 matrices .",
    "for a matrix @xmath10 , we write @xmath11 the @xmath12-th component of @xmath13 for @xmath14 and @xmath15 . for any vector @xmath16 ,",
    "write @xmath17 the @xmath18-th component of @xmath19 .",
    "throughout the paper , we consider the following portfolio loss model : @xmath20 where @xmath21 is the size of the portfolio , @xmath22 are random variables that represent the losses incurred by the exposures @xmath23 within a fixed time period .",
    "the random variable @xmath24 defined in ( @xmath25 ) stands for the portfolio - wide loss . in this paper ,",
    "a positive value of loss random variable represents a financial loss , and a negative loss is interpreted as a profit .",
    "let @xmath26 be the cumulative distribution function ( cdf ) of @xmath27 for @xmath28 , @xmath29 be the joint cdf of the random vector @xmath30 and @xmath31 be the cdf of the total loss @xmath24 .",
    "let @xmath32 be a copula of @xmath29 .",
    "by sklar s theorem ( see , e.g. , nelsen , 2013 ) , it holds that @xmath33 for any @xmath16 .",
    "this formula allows us to separate the modelling of the individual marginal losses from their dependence structure .",
    "see mcneil et al .",
    "( 2015 ) for the benefits of this copula modelling approach , and its application in financial risk management .    for the sake of argument , we impose two assumptions on the portfolio loss models @xmath34 in this paper .",
    "one assumption is @xmath35 , or @xmath36 , where @xmath37 is the support of a function @xmath38 and @xmath39 .",
    "the former case focuses on modelling pure losses and the latter on modelling profits and losses ( p&l ) .",
    "the other assumption is that , the distributions @xmath40 and @xmath32 are all absolutely continuous , i.e. they all have densities @xmath41 and @xmath42 , respectively . in other words ,",
    "we confine ourselves to continuous loss models , and discrete loss models are beyond the scope of this paper .",
    "although typical credit loss models such as the factor models ( see , e.g. , bluhm et al , 2016 ) are excluded , wide variety of loss models are still included in the sphere of our research . under the assumption of continuity",
    ", we have the density - form of the sklar s formula : @xmath43 by differentiating the both sides of @xmath44 .    as mentioned in section 1 ,",
    "computing the risk contributions is important in the framework of integrated risk management . in practice ,",
    "a two - step procedure is conducted for determining the risk contributions .",
    "first step is to compute the economic capital @xmath45 , where @xmath46 is a so - called risk measure .",
    "risk measure is a map from a loss random variable to a capital buffer that is required to cover the loss with a certain high probability .",
    "one of the most popular risk measure is the value - at - risk ( var ) , defined by @xmath47 where @xmath48 is called the _",
    "confidence level_. second step is to allocate the capital @xmath45 to the individual @xmath49-exposures according to some principle .",
    "mathematically , the capital allocation is the problem of determining the vector @xmath50 that satisfies the full allocation property : @xmath51 the euler principle solves this problem by utilizing the well - known euler rule for a function @xmath52 : @xmath53 where @xmath54 is an open set such that @xmath55 and @xmath46 is a positive homogeneous risk measure .",
    "define @xmath56 then the full alocation property ( @xmath57 ) holds for this vector ( ac@xmath58ac@xmath59 ) by taking @xmath60 in the equation ( @xmath61 ) .",
    "since var@xmath62 is positive homogeneous , the euler principle can be applied and its solution is given by @xmath63.\\ ] ] see tasche ( 2001 ) for deriving the second equality .",
    "we call this vector @xmath64 the _ var contributions_. since we focus only on this form of allocated capital in this paper , we drop the superscript `` var@xmath62 '' and simply denote the var contributions by ac@xmath65(@xmath66 ) .",
    "although its good economical properties have been reported in the literature , var contributions can not be computed easily .",
    "even when the joint density of the portfolio loss vector @xmath67 is analytically specified , theoretical computation of ac is difficult since deriving the joint distribution of @xmath68 is challenging in general . a possible numerical method to calculate the var contributions",
    "monte carlo ( mc ) _ method . in the crude mc method",
    ", we consider the _ pseudo var contributions _ , defined by @xmath69\\hspace{1mm}]\\ ] ] instead of the true ac defined in ( @xmath70 ) , for a sufficiently small @xmath71 . since the probability @xmath72)$ ] is positive , the right hand side of ( @xmath73 ) can be written by @xmath74 } ] } {      { \\mathbb{p}}(s \\in a_{\\delta } ) } \\hspace{5mm}\\mbox{where}\\hspace{5mm}a_{\\delta}=[\\mbox{var}_{p}(s)-\\delta,\\mbox{var}_{p}(s)+\\delta].\\ ] ] this expression allows us to construct the estimator of the pseudo var contributions given by @xmath75 }     } {      \\frac{1}{n}\\sum_{n=1}^{n}1_{[s^{(n)}\\in a_{\\delta } ] } } = \\frac{1}{m_{\\delta , n}}\\sum_{n=1}^{n } { \\bm{x}}^{(n ) } \\cdot 1_{[s^{(n)}\\in a_{\\delta}]},\\ ] ] where @xmath76}$ ] , @xmath77 and @xmath78 .",
    "we call @xmath79 the _",
    "mc estimator_. the mc estimator is used to estimate the true var contributions by setting @xmath80 and @xmath81 sufficiently small and large , respectively . note that this method is available only when @xmath82 since @xmath83 by absolute continuity of @xmath31 .    although we can compute the mc estimator whenever we can generate i.i.d .",
    "samples from the joint loss distribution @xmath29 , it has an inevitable bias to estimate the true var contributions .",
    "the bias of the mc estimator can be decomposed by @xmath84 where @xmath85 and @xmath86 .",
    "because we generally do not know the true ac , the second term @xmath87 can not be computed easily .",
    "therefore , the @xmath80 should be as small as possible .",
    "however , when the @xmath80 is quite small , it is difficult to maintain a sufficient sample size @xmath88 that keeps the first term @xmath89 small enough .",
    "this is because @xmath90=n\\cdot { \\mathbb{p}}(s \\in a_{\\delta})$ ] and @xmath91 is usually much less than @xmath92 .",
    "due to this trade off relation , the two parts of the bias are difficult to eliminate simultaneously .    to overcome this problem ,",
    "several estimators have been proposed in the literature .",
    "we end up this section by introducing some existing estimators and their problems .",
    "firstly , the _ nadaraya - watson ( nw ) kernel estimator _ proposed in tasche ( 2009 ) is defined by @xmath93 where @xmath94 is the kernel density and @xmath95 is the bandwidh . since",
    "this estimator is a slight modification of the mc estimator ( @xmath96 ) , it has the same problem as the mc estimator explained above .",
    "moreover , the bias and the standard error of the nw estimator ( see , e.g. hansen , 2009 for their expressions ) can not be computed easily because it requires the evaluation of the total loss density @xmath97 .",
    "secondly , glasserman ( 2005 ) developed the _ importance sampling ( is ) estimators _ to overcome the problem of sample - inefficiency . by using the is technique to increase samples",
    "whose sums belong to @xmath98 , the bias of the is estimators can be sufficiently small",
    ". however , risk models that can utilize this is technique is limited to specific credit risk models ( see , e.g. , huang et al , 2007 ; mausser and rosen , 2008 ) .",
    "unfortunately , the is estimators are hardly available in our case , where the loss model ( @xmath25 ) has a joint loss density as specified in ( @xmath99 ) .",
    "finallly , hallerbach ( 2003 ) and tasche and tibiletti ( 2004 ) constructed estimators by supposing a generalized regression model among the losses : @xmath100 where @xmath101 is a function parametrized by @xmath102 and @xmath103 is an error random vector such that @xmath104={\\bm{0}}$ ] .",
    "let @xmath105 be an estimator of @xmath106 .",
    "then we call the following form of the estimator @xmath107 the _ generalized regression ( gr ) estimator_. although this estimator is intuitive and easy to apply , it also has an inevitable bias .",
    "let @xmath108 be the true function such that @xmath109=g(v)$ ] and let @xmath110 be the minimizer of the error term @xmath103 in some sense .",
    "if @xmath105 goes to @xmath110 as @xmath111 , the bias of the gr estimator can be decomposed by @xmath112 where @xmath113 and @xmath114 .",
    "the first term @xmath115 is caused by the estimation error and the second term @xmath116 is by the misspecification of the model ( @xmath117 ) .",
    "since we do not know the true function @xmath108 in general , the second term @xmath116 is difficult to evaluate . to avoid the model - misspecification",
    ", we have to choose the family of functions @xmath118 large enough to contain @xmath108 . on the other hand , estimating the parameter @xmath106 is not as easy as in the ordinary regression model . since we usually do not have samples from @xmath119 , it is non - trivial to estimate @xmath106 by minimizing the error term @xmath103 given @xmath120 . due to these obstacles , it is generally difficult to evaluate the bias of the gr estimator .",
    "a notable exception is the case when the risk model @xmath121 follows an elliptical distribution . in this case",
    ", it holds that ( e.g. , corollary 8.43 in mcneil et al . , 2015 )",
    "@xmath122-{\\mathbb{e}}[{\\bm{x}}]=\\frac{\\mbox{cov}({\\bm{x}},s)}{\\mbox{var}(s)}\\cdot(\\mbox{var}_{p}(s)-{\\mathbb{e}}[s]).\\ ] ] therefore , the true var contributions are provided when we choose @xmath123 and @xmath124-\\frac{\\mbox{cov}({\\bm{x}},s)}{\\mbox{var}(s)}\\cdot { \\mathbb{e}}[s ] \\hspace{10 mm } { \\bm{\\beta}}_{1}^{\\ast}=\\frac{\\mbox{cov}({\\bm{x}},s)}{\\mbox{var}(s)}.\\ ] ] since this @xmath110 is the minimizer of @xmath125={\\mathbb{e}}[({\\bm{x}}-{\\bm{\\beta}}_{0}-{\\bm{\\beta}}_{1}s)^{2}]$ ] , the ordinary least squares ( ols ) estimator @xmath126 converges to @xmath110 as @xmath81 goes to infinity . as a consequence , the second term @xmath116 is zero and the first term @xmath115 can be eliminated by taking @xmath81 sufficiently large .",
    "_ markov chain monte carlo ( mcmc ) _ is a method to generate samples from a probability distribution by constructing a markov chain whose stationary distribution is the desired one . by allowing markovian type dependence within the samples , mcmc enables to simulate wide variety of distributions even if they can not be simulated directly in practice . in this section ,",
    "we briefly introduce the theory of mcmc method .",
    "we review consistency and asymptotic normality of estimators computed by markov chain . to obtain an efficient estimator , it is important to choose an appropriate proposal distribution on generating sample path of the markov chain . in section @xmath127 , we summarize the family of proposal distributions used in this paper .",
    "let @xmath128 be a set and @xmath129 be a @xmath130-algebra of subsets of @xmath7 .",
    "_ markov chain _ is a sequence of @xmath7-valued random variables @xmath131 satisfying the markov property ; @xmath132 for all @xmath133 , @xmath134 , and @xmath135 .",
    "markov chain is characterized by its stochastic kernel @xmath136 , given by @xmath137 .",
    "if there exists a probability distribution @xmath138 such that @xmath139 for all @xmath140 and @xmath134 , then the @xmath138 is called the _",
    "stationary distribution_. see , e.g. , nummelin ( 2004 ) for general theory of markov chain .",
    "markov chain monte carlo ( mcmc ) is a widely used statistical method for simulating probability distribution by generating markov chain .",
    "mcmc is often used to estimate the quantity @xmath141 for some distribution @xmath138 and a @xmath138-measurable function @xmath142 .",
    "its mcmc estimator is given by @xmath143 where @xmath144 is an @xmath81-path of the markov chain whose stationary distribution is @xmath138 . in the framework of mcmc",
    ", we call this @xmath138 the _ target distribution_. since the target distribution @xmath138 is externally determined by the problem to solve , the problem of mcmc is to find the stochastic kernel @xmath145 such that it has the stationary distribution @xmath138 .",
    "additionally , we require @xmath145 that its sample path can be generated easily .",
    "one of the most popular stochastic kernel used in practice is the _ metropolis - hastings _ ( mh ) kernel ( metropolis et al . , 1953 ; hastings , 1970 ) , defined by @xmath146 where @xmath147&\\mbox { if } \\pi({\\bm{x}})q({\\bm{x}},{\\bm{y}})>0\\\\ 0&\\mbox { otherwise } , \\end{cases}\\\\ \\\\ r({\\bm{x } } ) & = & 1- \\int p({\\bm{x } } , { \\bm{y}}){\\rm d}{\\bm{y}},\\\\\\end{aligned}\\ ] ] @xmath148 is the dirac delta function , and @xmath149 is a function such that @xmath150 is a measurable function for all @xmath151 , and @xmath152 is a probability density function ( pdf ) for all @xmath140 .",
    "this function @xmath153 is called a _",
    "proposal distribution_. it can be shown that the mh kernel has a stationary distribution @xmath138 ( tierney , 1994 ) .",
    "the great popularity of the mh kernel comes from the fact that , we can easily generate sample path of the corresponding markov chain by using the so - called _ mh algorithm _ ( see e.g. , chib and greenberg , 1995 for the simple and intuitive exposition of the algorithm ) . under the mild conditions that ( i )",
    "a vector @xmath154 is known , ( ii ) samples from @xmath155 can be generated for all @xmath140 , and ( iii ) the ratio @xmath156 can be calculated for all @xmath157 , we can generate @xmath81-sample path of the desired markov chain by the following algorithm :    1 .",
    "set @xmath158 , @xmath153 : proposal distribution , and @xmath159 + 2 .   * for * @xmath160 , + 3 .",
    "generate @xmath161 and @xmath162 + 4 .",
    "set @xmath163\\ ] ] 5 .",
    "set @xmath164}\\cdot { \\bm{x}}_{\\ast}^{(n)}+ 1_{[u>\\alpha_{n}]}\\cdot { \\bm{x}}^{(n)}\\\\\\ ] ] 6 .",
    "* end for * + 7 .",
    "return @xmath144 as an @xmath81-sample path of the markov chain with the kernel ( @xmath165 ) and the initial value @xmath166    we call @xmath167 in @xmath168 the _ acceptance probability _ at @xmath169-th iteration . based on the @xmath81-sample path @xmath144 generated in algorithm 1",
    ", we can compute the mcmc estimator @xmath170 given by @xmath171 .",
    "the mcmc estimator @xmath170 has several attractive properties such as consistency and asymptotic normality .",
    "firstly , the mcmc estimator is consistent ( see , e.g. , theorem 1 in nummelin ; 2002 ) , i.e. , @xmath172 for all @xmath138-integrable functions @xmath142 and all initial state @xmath173 .",
    "moreover , _ central limit theorem _ ( clt ) holds under some regularity conditions ( see , e.g. , chapter 17 in meyn and tweedie , 2012 ) , i.e. , @xmath174 where @xmath175 + 2\\sum_{k=1}^{\\infty}\\mbox{cov}_{\\pi}[\\hspace{1mm}h({\\bm{x}}^{(1)}),h({\\bm{x}}^{(1+k)})\\hspace{1mm}]\\hspace{6 mm } \\in ( 0,\\infty).\\ ] ] since we can rarely compute the asymptotic variance @xmath176 in real situation , we have to estimate it from the same sample path @xmath144 that we used to compute @xmath170 .",
    "one simple and popular estimator of @xmath177 is the so - called _ batch means estimator _ ( see , e.g. , geyer , 2012 ) . for the @xmath81-path of the markov chain @xmath144 ,",
    "the batch means estimator @xmath178 is defined by @xmath179[mean over the batch ] where @xmath180 are positive integers satisfying @xmath181 , and @xmath182 @xmath183 is called the batch length and @xmath184 is the number of batches . under some regularity conditions ,",
    "the batch means estimator @xmath178 converges to @xmath177 with probability 1 as @xmath185 ( see , e.g. , jones et al .",
    ", 2006 ; vats et al . , 2015 ) .",
    "by using the asymptotic relation ( @xmath186 ) and the consistency of the batch means estimator @xmath178 , we can construct an approximate 95% confidence interval of the true quantity @xmath187 , given by @xmath188 where @xmath189 .      when implementing the mcmc , an appropriate choice of the proposal function @xmath153 is necessary . when choosing @xmath153 , it is desirable that the markov chain characterized by ( @xmath165 ) theoretically holds the _ central limit theorem _ ( @xmath186 ) , and also , its asymptotic variance @xmath176 is as small as possible .",
    "since the asymptotic variance @xmath177 can rarely be calculated explicitly in real situation , we usually rely on post - implementation review , i.e. evaluating the goodness of the selected proposal distribution after performing the mcmc . in this section ,",
    "we introduce two empirical methods for checking validity of the proposal selection .",
    "we also provide some families of the proposal distributions for an appropriate choice of @xmath153 .",
    "theoretical verification of clt will be carried over into section @xmath190 .    in practice , there are two prevalent methods to check the validity of the proposal distribution ( see , e.g. , geyer , 2012 in details ) .",
    "one method is to check that the _ autocorrelation plots _ of the marginal sample paths steadily decline . for an @xmath81-sample path @xmath144 and the mcmc estimator @xmath191 , we draw plots of the sample autocorrelations @xmath192 , where @xmath193 versus the time lag @xmath194 , for @xmath28",
    ". we can expect that the asymptotic variance @xmath177 should be small if the autocorrelation plots steadily decline to zero as the lag increases .",
    "the other method is to check the _ acceptance rate _",
    ", i.e. the percentage of times a candidate is accepted . in general",
    ", extremely low acceptance rate implies that the chain tends to be stuck to one point .",
    "conversely , extremely high acceptance rate occurs when the chain moves only around the mode of the target density and does not traverse the entire support ( chib and greenberg , 1995 ) .",
    "the first situation yields high asymptotic variance , and the second gives an illusionally low asymptotic variance . to avoid such situations , it is important to check that the acceptance rate takes a moderate value .",
    "typically , proposal distribution @xmath153 is selected from a certain class of distributions . to find a suitable @xmath153 ,",
    "several classes are in order .",
    "first , if @xmath195 for some pdf @xmath196 , then the candidate @xmath197 is drawn according to the process @xmath198 and @xmath121 is the current state .",
    "we call this @xmath153 the _ random walk _ proposal distribution . in the case when @xmath196 is symmpetric around the origin , the acceptance probability @xmath168 is given simply by @xmath199 $ ] .",
    "second , when @xmath200 for some pdf @xmath196 , then the candidate @xmath197 is updated by @xmath201 since the candidate is drawn independently of the current position , this @xmath153 is called the _ independent _ proposal distribution .",
    "the two proposal distributions , the random walk and the independent proposals , are widely used due to their simplicity . however",
    ", these proposal distributions often fail to perform well when the target distribution @xmath138 is heavy - tailed . to overcome this problem",
    ", we finally introduce the _ mixed preconditioned crank - nicolson ( mpcn ) _ proposal distribution ( proposed by kamatani , 2014 ) .",
    "this proposal distribution updates the candidate according to the following process : @xmath202 where @xmath203 follows the gamma distribution with shape parameter @xmath204 and the scale parameter @xmath205 for @xmath206 $ ] and @xmath207 $ ] , and @xmath208 . note that",
    ", here we introduce the standardized version of the original mpcn in kamatani ( 2014 ) .",
    "the acceptance probability ( @xmath209 ) can be written by @xmath210.\\ ] ] the major difference of this proposal distribution from the first two simple ones is that , not only the mean but also the variance of the candidate changes with the current state @xmath121 . since the mpcn proposal distribution admits larger jumps in the tail , we can expect better acceptance rate even when @xmath138 is heavy - tailed ( see , e.g. , livingstone , 2015 for such position - dependent proposal distributions ) .",
    "we have shown that estimators constructed by mcmc has several attractive properties , such as consistency and asymptotic normality . in this section ,",
    "we propose a new estimator of var contributions , that utilizes mcmc method to achieve efficient estimation , we also show consistency and asymptotic normality of our mcmc - based estimator under a certain class of risk models .",
    "we suppose the following situation : we have an explicit form of the joint loss density @xmath67 , and thus , we can compute the quantity @xmath211 for any @xmath16 .",
    "we also can generate i.i.d .",
    "samples @xmath212 from @xmath29 up to sufficiently large @xmath81 . then , the i.i.d .",
    "samples @xmath213 from @xmath31 can be generated by taking @xmath214 for @xmath160 .",
    "on the other hand , suppose that we have neither an explicit form of the total loss density @xmath215 nor the way to compute the quantity @xmath216 for any @xmath217 .",
    "the situation described above typically occurs when we model the joint loss density @xmath67 by the copula approach , i.e. specifying the marginal loss densities @xmath218 and then specifying the copula density @xmath42 .",
    "when we use this approach , the resulting joint loss density @xmath67 is speficied by the formula @xmath219 .    under the situation above",
    ", a two - step procedure ( see , e.g. , glasserman , 2005 ) is conducted for computing the var contributions @xmath220 .",
    "the first step is to estimate var@xmath221 and the second step is to estimate the var contributions ac@xmath222 $ ] with the var@xmath221 replaced by the estimated one in the first step .",
    "estimation of the var@xmath221 in the first step is conducted by monte carlo simulation .",
    "based on the i.i.d .",
    "samples @xmath213 from @xmath31 , the estimator of var@xmath221 is given by @xmath223}$ ] , where @xmath224}$ ] is the @xmath225-th largest sample among @xmath81 samples @xmath226 .",
    "hereafter we refer to the estimate of @xmath227 as @xmath228 in short , and regard it as a constant . in the second step , we aim at estimating ac@xmath229 $ ] . according to the crude monte carlo method",
    "as explained in section 2 , the var contributions are estimated by @xmath230},\\ ] ] where @xmath77 , @xmath231 for @xmath232 , @xmath233 $ ] and @xmath76}$ ] .    as explained in section @xmath1 ,",
    "the problem of this two - step procedure is that the estimator of var contributions in the second step often has a significant bias . to address this issue",
    ", we develop a markov chain monte carlo ( mcmc)-based estimator , that achieves sample efficiency and consistency , by utilizing the mcmc method .",
    "the major difference of our mcmc - based estimator from the mc one is that , samples are generated not from the loss distribution @xmath29 itself , but from the conditional distribution of @xmath121 given the sum constraint @xmath234 .",
    "although it is almost impossible in the mc method , the mcmc enables us to realize it .",
    "we start to describe the mcmc - based estimator with reformulating the problem of computing var contributions .",
    "let @xmath235 , where @xmath236 . by the full allocation property @xmath237 , we have that @xmath238={(\\hspace{1mm}{\\mathbb{e}}[{\\bm{x}}'|s = v],\\hspace{1mm}v-{{\\bm{1}}_{d'}^{\\mbox{\\scriptsize t}}}\\cdot { \\mathbb{e}}[{\\bm{x}}'|s = v]\\hspace{1mm})^{\\mbox{\\scriptsize t}}},\\ ] ] where @xmath239 .",
    "therefore , computation of the var contributions ac=@xmath109 $ ] can be reduced to estimate the var contributions of the @xmath240-subportfolio , given by ac@xmath241 $ ] . in our method",
    ", we estimate this quantity ac@xmath242 by generating samples directly from @xmath243 .",
    "the conditional joint density of @xmath244 given @xmath234 can be written by @xmath245 where the second equation follows from a linear transformation @xmath246 . since it is difficult to evaluate the total loss density @xmath247",
    ", we can hardly generate samples directly from @xmath248 .    by taking @xmath249 , @xmath250 and @xmath251 on the discussion in section @xmath2 , our problem of estimating var contributions can be reduced to estimate @xmath252 $ ] in ( @xmath253 ) by mcmc .",
    "even though we can hardly compute @xmath248 itself , we can compute the acceptance probability ( @xmath209 ) , given by @xmath254   = \\min \\left [ \\frac { f_{{\\bm{x}}}({\\bm{y}},v-{{\\bm{1}}_{d'}^{\\mbox{\\scriptsize t}}}{\\bm{y } } ) \\cdot   q({\\bm{y}},{\\bm{x } } ) } { f_{{\\bm{x}}}({\\bm{x}},v-{{\\bm{1}}_{d'}^{\\mbox{\\scriptsize t}}}{\\bm{x } } ) \\cdot q({\\bm{x}},{\\bm{y } } ) } , \\hspace{2mm}1\\right]\\ ] ] for all @xmath255 .",
    "note that the cumbersome term @xmath247 disappears by taking the ratio of @xmath256 to @xmath257 .",
    "therefore , under some appropriate choice of the proposal function @xmath153 , we can generate @xmath81-sample path of the markov chain whose stationary distribution is @xmath251 . based on the sample path of the markov chain , we can construct the mcmc estimator @xmath170 defined by @xmath171 .",
    "its consistency follows directly from the general theory of markov chain presented in section @xmath2 .",
    "the algorithm to compute the mcmc estimator of var contributions is summarized as follows :    1 .",
    "set @xmath258 , @xmath158 , @xmath153 : proposal distribution , and @xmath259 .",
    "perform algorithm 1 for the given @xmath81 , @xmath153 , and @xmath260 to generate an @xmath81-sample path @xmath261 of a markov chain whose stationary distribution is @xmath248 .",
    "define @xmath262 and set @xmath263 to estimate var contributions ac@xmath229 $ ] .      in this section ,",
    "we provide some theoretical results to verify asymptotic normality of the mcmc estimator @xmath264 .",
    "we will see that clt holds for various risk models when we model the pure losses . on the other hand , when we model",
    "the profits & losses , theoretical justification of clt is challenging except for some special cases .",
    "we provide an example of justifying clt only when we model p&l by some elliptical distribution .",
    "when we model pure losses , i.e. @xmath35 , then the conditional distribution @xmath243 is supported on the following bounded set , called the @xmath228-_simplex _ : @xmath265 thanks to the compactness of the support , clt is verified under some mild conditions .",
    "the following theorem is a direct consequence of well - known results in the theory of mcmc .",
    "however , it clarifies the conditions on the marginal loss densities and the copula densities , that are easy to be checked in the framework of joint risk modeling with copulas .",
    "[ main theorem ] suppose that the joint distribution @xmath29 is supported on @xmath266 , and has marginal densities @xmath218 and a copula density @xmath42 .",
    "then , @xmath267-clt holds for the mcmc estimator @xmath264 of var contributions if the following @xmath268 hold :    * @xmath269^{d ' } } q({\\bm{x}},{\\bm{y}})>0 $ ] , + * @xmath270 is positive and bounded above on @xmath271 $ ] for all @xmath28 , + * @xmath272 is positive and bounded above on @xmath273)\\times\\cdots \\times f_{d}([0,v])$ ] . +    by theorem 23 in roberts and rosenthal ( 2004 ) , the @xmath267-clt holds if the markov chain is _ uniformly ergodic _ whenever @xmath274<\\infty$ ] .",
    "the moment condition is satisfied since @xmath275\\leq{\\mathbb{e}}[(x_{1}+\\cdots+x_{d})^{2}|s = v]=v^{2}<\\infty\\ ] ] for any @xmath276 .",
    "thus , it suffices to show that the markov chain is uniformly ergodic . by theorem 1.3 in mengersen and tweeide ( 1996 ) ,",
    "the markov chain is uniformly ergodic if ( and only if ) the minorization condition ( see , e.g. , rosenthal , 1995 ) holds on the whole space @xmath277 , i.e. , there exist a positive integer @xmath169 , @xmath71 and a probability measure @xmath278 such that @xmath279 for all @xmath280 , @xmath281 , where @xmath282 . by the conditions ( c2 ) , ( c3 ) , and",
    "that @xmath283^{d'}$ ] , we have that @xmath284 using @xmath285 and the condition @xmath286 , the minorization condition can be checked as follows . for any @xmath280 , define @xmath287 then for all @xmath288 , we have @xmath289d{\\bm{y}}\\\\ & & + \\int_{a\\backslash q_{{\\bm{x}}}}q({\\bm{x}},{\\bm{y}})\\cdot \\min \\left[1 , \\frac{\\pi({\\bm{y}})}{\\pi({\\bm{x}})}\\cdot \\frac{q({\\bm{y}},{\\bm{x}})}{q({\\bm{x}},{\\bm{y}})}\\right]d{\\bm{y}}\\\\ & = & \\int_{q_{{\\bm{x}}}}\\frac{\\pi({\\bm{y}})}{\\pi({\\bm{x}})}\\cdot q({\\bm{y}},{\\bm{x}})d{\\bm{y}}+\\int_{a\\backslash q_{{\\bm{x}}}}q({\\bm{x}},{\\bm{y}})d{\\bm{y}}\\\\ & \\geq&\\frac{\\epsilon}{u}\\int_{q_{{\\bm{x } } } } \\pi({\\bm{y}})d{\\bm{y}}+\\epsilon\\int_{a\\backslash q_{{\\bm{x}}}}\\frac{\\pi({\\bm{y}})}{u}d{\\bm{y}}\\\\ & = & \\frac{\\epsilon}{u } \\pi(a).\\end{aligned}\\ ] ] taking @xmath290 , @xmath291 and @xmath292 completes the proof .",
    "we will see typical situations where the conditions @xmath268 hold .",
    "firstly , the condition ( @xmath293 ) holds when , for example , @xmath195 , @xmath196 is continuous , and positive on @xmath294^{d'}$ ] .",
    "these conditions are satisfied for typical choices of @xmath196 , such as gaussian density or student s @xmath295 density .",
    "secondly , the condition @xmath296 also holds when , for example @xmath218 follow pareto distributions with the density given by @xmath297",
    "lastly , the condition ( @xmath298 ) can easily be checked for various copulas used in practice . for the use in section 4 , we especially focus on the following two examples :",
    "@xmath49-dimensional @xmath295 copula density is of the form @xmath299 where @xmath300 $ ] is a correlation matrix , @xmath301 and @xmath302 is a cdf of the student s @xmath295 distribution with degree of freedom @xmath278 .",
    "it is clear that @xmath303 satisfies the condition @xmath304 if @xmath305 for @xmath306 .",
    "@xmath49-dimensional @xmath138-rotated clayton copula has a density of the form ( yoshiba , 2013 ) @xmath307^{-\\frac{1}{\\theta}-d},\\hspace{6mm}0<\\theta<\\infty .\\ ] ] since clayton copula has a lower tail dependence , the @xmath138-rotated clayton copula has an upper tail dependence .",
    "we will see that the @xmath138-rotated clayton copula density @xmath308 satisfies the condition @xmath304 under some parameter constraint .",
    "let @xmath309 .",
    "then , for any @xmath310)$ ] , it holds that @xmath311 for all @xmath28 .",
    "thus , we have @xmath312 and also @xmath313^{-\\frac{1}{\\theta}-d } \\leq \\left [   \\sum_{j=1}^{d}(1-u_{j})^{-\\theta}-d+1   \\right]^{-\\frac{1}{\\theta}-d } \\leq 1.\\ ] ] since @xmath228 is the @xmath314-th quantile of @xmath31 , we have @xmath315 . using this inequality ,",
    "the lower bound of @xmath316 is positive if @xmath317 .",
    "putting @xmath318 and @xmath316 together , the @xmath138-rotated clayton copula density @xmath308 satisfies the condition @xmath304 when @xmath319 .",
    "in contrast to the pure - loss case , theoretical verification of clt is challenging in the case when we model p&l , i.e. @xmath320 . since the conditional distribution @xmath243 is supported on the unbounded space @xmath321 , we need a careful investigation on the tail - behavior of the conditional density @xmath248 . when the proposal distribution is mpcn",
    ", we can justify the clt of our mcmc estimator for a certain class of target distributions based on the result in kamatani ( 2016 ) . as its example , we consider the case where the underlying loss vector @xmath121 follows a multivariate student s @xmath295 distribution .",
    "[ example of multivariate student t distribution ] let @xmath322 , where @xmath323 , @xmath324 and @xmath325 .",
    "the density of the multivariate student s @xmath295 distribution is given by @xmath326 its conditional density @xmath248 can be specified as follows .",
    "firstly , let @xmath327 for simplicity .",
    "write @xmath328 for @xmath329 , @xmath330 and @xmath331 . then",
    ", it holds that @xmath332 where @xmath333 , @xmath334 , and @xmath335 . using @xmath336",
    ", we have that @xmath337 provided @xmath338 , @xmath339 follows a @xmath240-dimensional elliptical distribution with the location parameter @xmath340 , scale parameter @xmath341 and the density generator @xmath342 given by @xmath343 this type of distribution is called the _ pearson type @xmath344 distribution _ ( see e.g. , schmidt , 2002 ) .",
    "consider the mcmc estimator @xmath264 where @xmath345 and the proposal distribution @xmath153 is mpcn @xmath346 . by theorem 25 in roberts and rosenthal ( 2004 ) ,",
    "a @xmath267-clt holds if the markov chain is geometrically ergodic and @xmath274<\\infty$ ] . by proposition 3.4 in kamatani ( 2016 ) , the markov chain with mpcn proposal distribution",
    "is geometrically ergodic if @xmath347<\\infty$ ] for some @xmath71 , @xmath348 is strictly positive and continuous , and moreover , it is symmetrically regularly varying , i.e. , @xmath349 for some @xmath350 such that @xmath351 for any @xmath352 , where @xmath353 and @xmath354 .",
    "we will firstly see that all the moment conditions hold , and then , the tail condition @xmath355 is also satisfied for @xmath345 .",
    "write @xmath356 .",
    "it can be shown that @xmath108 is regularly varying ( see , e.g. , resnick , 2013 ) at @xmath357 with index @xmath358 , i.e. @xmath359 by proposition 3.7 in schmidt ( 2002 ) , @xmath360 is regularly varying with index @xmath361 .",
    "then , by karamata s theorem ( see , e.g. , resnick , 2013 , theorem 0.6 ) , @xmath362 is regularly varying with index @xmath363 .",
    "therefore , @xmath364<\\infty$ ] holds for all @xmath365 ( see , e.g. , mikosch , 1999 ) .",
    "thus all the moment conditions above are satisfied so long as @xmath323 . in elliptical case ,",
    "the tail condition @xmath355 is a direct consequence of @xmath366 . since @xmath367 for all @xmath368",
    ", it holds that @xmath369 thus , taking @xmath370 in @xmath355 yields that @xmath345 is symmetrically regularly varying . putting them together , we can find that the mcmc estimator with mpcn proposal distribution satisfies @xmath267-clt when the underlying loss vector follows multivariate student s @xmath295 distribution with @xmath323 and @xmath371 .",
    "we have shown that the mcmc estimator has various attractive properties for the estimation of var contributions . in this section ,",
    "we apply the proposed estimator to various risk models used in practice .",
    "our numerical experiment shows that the mcmc estimator has smaller bias and mean squared error ( mse ) compared with the existing estimators that have been proposed in the previous studies .",
    "then , based on some numerical results , we study how to choose an appropriate proposal distribution given risk model .      in the simulation study ,",
    "we consider four risk models which are modeled with marginal densities and copula densities .",
    "as is often done in risk management , we adopt heavy - tailed marginal distributions and copulas with tail dependence . in all risk models ,",
    "we set the size of the portfolio @xmath372 .",
    "the models are described as follows :    1 .",
    "the loss random variable @xmath27 follows pareto distribution @xmath373 with @xmath374 and @xmath375 for all @xmath306 .",
    "the loss vector @xmath376 has a @xmath138-rotated clayton copula @xmath308 with @xmath377 .",
    "@xmath27 , @xmath378 have the same marginals as in the case ( 1 ) .",
    "however , their copula is a student s @xmath295 copula @xmath303 with @xmath379 and the correlation matrix given by @xmath380 + 3 .",
    "@xmath27 follows student s @xmath295 distribution with @xmath381 , @xmath382 and @xmath383 for all @xmath306 .",
    "@xmath376 has a @xmath138-rotated clayton copula with @xmath377 .",
    "the loss random vector @xmath376 follows a multivariate student s @xmath295 distribution @xmath384 with @xmath379 , @xmath327 , and @xmath385 given by @xmath386 .",
    "the former two models ( 1 ) and ( 2 ) treat pure losses , and the latter two models ( 3 ) and ( 4 ) handle p&l . in all models ,",
    "marginal distributions have variance 2.0 .",
    "moreover , they are heavy - tailed with tail index @xmath387 .",
    "the models ( 1 ) and ( 3 ) possess homogeneous upper tail dependence with tail coefficient @xmath388 ( see , e.g. , joe , 2014 ) .",
    "the models ( 2 ) and ( 4 ) have symmetric upper , lower , and upper - lower tail dependences with tail coefficients @xmath389 , @xmath390 , @xmath391 , @xmath392 , @xmath393 , and @xmath394 .    for each risk model",
    ", we compute several estimators of var contributions @xmath395 $ ] for @xmath396 , with the @xmath397 replaced by its monte carlo estimator @xmath398}$ ] . in this",
    "setting , the condition @xmath304 in theorem @xmath399 holds in the risk models ( 1 ) and ( 2 ) since @xmath400 .",
    "also , as shown in example @xmath401 , the risk model ( 4 ) with mpcn proposal distribution satisfies clt since @xmath402 .",
    "the estimators that we study are the monte carlo ( mc ) estimator @xmath79 , nadaraya - watson ( nw ) estimator @xmath403 ( tasche , 2009 ) , generalized regression ( gr ) estimator @xmath404 ( tasche and tibiletti , 2004 ; hallerbach , 2003 ) , and the mcmc estimator @xmath264 proposed in this paper : @xmath405},\\hspace{10 mm } { \\widehat{\\mbox{ac}}^{\\mbox{\\scriptsize nw}}_{\\phi , h , n}}=\\frac {          \\sum_{n=1}^{n } { \\bm{x}}^{(n ) } \\cdot \\phi\\left(\\frac{s^{(n)}-v}{h}\\right ) } {      \\sum_{n=1}^{n}\\phi\\left(\\frac{s^{(n)}-v}{h}\\right ) } , \\ ] ] @xmath406 where @xmath407 , @xmath408 , and @xmath409 is an @xmath81-sample path of a markov chain with stationary distribution @xmath410 .    for all estimators , we fix the sample size @xmath411",
    ". other parameters of the estimators above are determined as follows .",
    "first , on the mc estimator , we set @xmath71 such that the mc sample size @xmath88 is around @xmath412 .",
    "as in glasserman ( 2003 ) , asymptotic normality @xmath413 holds for a fixed @xmath80 . using this result ,",
    "we report the estimate of @xmath414 and its approximated standard error @xmath415 for @xmath306 , where @xmath416 is the sample standard error defined by @xmath417 } } .\\ ] ] second , on the nw estimator , we choose the kernel density @xmath94 the standard normal density .",
    "we decide the bandwidth @xmath95 according to the silverman s rule of thumb @xmath418 ( silverman , 1986 ) .",
    "although asymptotic normality holds for the nw estimator , its asymptotic variance can hardly be computed because it requires the calculation of @xmath247 .",
    "therefore , we report only the estimate of @xmath419 .",
    "third , on the gr estimator , we choose @xmath420 and its coefficients are estimated by @xmath421 where @xmath422 and @xmath423 . according to the general theory of ols , it holds under some regularity conditions that @xmath424 \\hat{{\\bm{\\beta}}}_{n,1}^{(j ) }   \\\\",
    "\\end{pmatrix}- \\begin{pmatrix } { \\bm{\\beta}}_{0}^{(j ) }   \\\\[5pt ] { \\bm{\\beta}}_{1}^{(j ) }   \\\\ \\end{pmatrix } \\right ] \\rightarrow n_{2}({\\bm{0}}_{2},\\sigma_{{\\varepsilon}_{j}}^{2}q^{-1 } ) , \\hspace{6mm}\\mbox { as } \\hspace{2 mm } n \\rightarrow + \\infty\\ ] ] for @xmath306 , where @xmath425 and @xmath426 is the @xmath18-th component of @xmath427 and @xmath428 for @xmath429 and @xmath430 , respectively , @xmath431 is the @xmath18-th component of the error term @xmath103 , @xmath432 is its conditional variance given @xmath433 , and @xmath434 according to this result , we report the estimate of @xmath435 and its approximated standard error @xmath436 for @xmath306 , where @xmath437 @xmath438 and @xmath439 is the sample standard error of the @xmath18-th residuals . finally ,",
    "on the mcmc estimator , we choose different proposal distributions depending on the risk models ( 1)-(4 ) : ( 1 ) random walk proposal @xmath195 with @xmath440 , where @xmath441 , for @xmath416 defined in @xmath442 , ( 2 ) independent proposal @xmath200 , where @xmath196 is the density of the dirichlet distribution with parameters ( 0.2 , 0.28 , 0.6 ) , ( 3 ) and ( 4 ) mpcn proposal with @xmath443 , @xmath444 and @xmath445 . in the algorithm 2 , we set the initial state @xmath446 .",
    "we suppose that asymptotic normality @xmath447 holds for all risk models . also , its asymptotic variance is estimated by the batch means estimator @xmath448 defined by @xmath449 .",
    "following the recommendation of jones et al .",
    "( 2006 ) , we choose @xmath450 and @xmath451 .",
    "we report the estimate of @xmath452 and its approximated standard error @xmath453 for @xmath306 .",
    "as mentioned in section @xmath127 , the validity of the mcmc method can empirically be checked by autocorrelation plots and the acceptance rate .",
    "@xmath454 show the autocorrelation plots of the markov chains generated by algorithm 2 .",
    "-rotated clayton , ( b ) pareto + @xmath295 copula , ( c ) student s @xmath295 + @xmath138-rotated clayton , and ( d ) student s @xmath295 + @xmath295 copula .",
    "the dotted line represents @xmath455 . ]",
    "the acceptance rate of the mh algorithm in each risk model was ( 1 ) 0.556 , ( 2 ) 0.186 , ( 3 ) 0.643 , and ( 4 ) 0.757 . in fig .",
    "@xmath454 , we can observe that the autocorrelation plots steadily decline below 0.1 by the lag @xmath142 around 30 for all risk models .",
    "together with the moderate acceptance rates , we can confirm that the choice of the proposal distributions above are appropriate for all risk models .    before showing the estimation results",
    ", we check the shapes of the conditional distributions @xmath243 by plotting the markov chains generated by algorithm 2 .",
    "@xmath456 shows the contour plots of the generated markov chains .",
    "-rotated clayton , ( b ) pareto + @xmath295 copula , ( c ) student s @xmath295 + @xmath138-rotated clayton , and ( d ) student s @xmath295 + @xmath295 copula . when drawing the contour plots , we used subsamples , which are picked up every 100-th points of the original markov chains , to elliminate the dependence among samples .",
    "we plot only the first and second variables of the 3-dimensional markov chains since the last variable can be determined by the sum - constraint .",
    "the gray diagonal lines in the plots represent @xmath457 , where @xmath228 is the estimate of var@xmath221 .",
    "the contour plots approximately express the conditional distributions @xmath243 . ]    according to these plots , the features of the conditional distributions @xmath243 are summarized as follows :",
    "pareto + @xmath138-rotated clayton : _ the contour plot fig .",
    "@xmath456 ( a ) shows that @xmath243 has a unique mode at the center of the simplex .",
    "most probability of @xmath243 is concentrated around the mode , and the probability decreases as going far away from the center . also , the contour plot is almost symmetric at the diagonal line @xmath458 .",
    "_ pareto + t copula : _ unlike the case ( 1 ) , @xmath243 possesses two distinct modes near the @xmath459- and @xmath460-axes . especially near the @xmath460-axis",
    ", there is a peak around which the probability changes significantly . also , the contour plot fig .",
    "@xmath456 ( b ) is asymmetric at the diagonal line @xmath458 .",
    "3 .   _ student s t + @xmath138-rotated clayton : _ although @xmath339 can take negative values , it is supported almost on the bounded simplex as in the case ( 1 ) .",
    "the contour plot fig .",
    "@xmath456 ( c ) is unimodal and almost symmetric around @xmath458 . also , the tail of @xmath243 is apparently light .",
    "student s t + t copula : _ as discussed in section @xmath190 , the conditional distribution @xmath243 in this case follows the pearson type @xmath344 distribution given by @xmath461 . from the contour plot fig .",
    "@xmath456 ( d ) , we can observe some properties of this type of distribution , such as elliptical symmetry and tail - heaviness . unlike the case",
    "( 3 ) , @xmath339 takes large negative values beyond the bounded simplex .",
    "the results of our estimation are summarized in table @xmath462 . in the four different risk models ( 1)-(4 ) , we report the estimates , its approximated standard errors , biases , and root mse ( rmse)s of the four different estimators mc , nw , gr , and mcmc .",
    "[ table 1 ]    l@r@r@r@r@r@ c@ r@r@r + & & & & +   + & _ estimator _",
    "& @xmath463 & @xmath464 & @xmath465 & @xmath466 & & @xmath463 & @xmath465 & @xmath466 +   + _ ( 1 ) _ & + & ac@xmath467 & 11.298 & 11.550 & 11.297 & 11.258 & & 0.166 & 0.008 & 0.016 + & & ( 0.033 ) & ( 0.2859 ) & ( 0.033 ) & ( -0.007 ) & & ( 0.169 ) & ( 0.033 ) & ( 0.017 ) + & ac@xmath468 & 10.796 & 11.481 & 11.204 & 11.263 & & 0.164 & 0.008 & 0.017 + & & ( -0.469 ) & ( 0.216 ) & ( -0.061 ) & ( -0.001 ) & & ( 0.497 ) & ( 0.061 ) & ( 0.017 ) + & ac@xmath469 & 10.631 & 10.762 & 11.293 & 11.273 & & 0.167 & 0.008 & 0.016 + & & ( -0.634 ) & ( -0.503 ) & ( 0.028 ) & ( 0.008 ) & & ( 0.655 ) & ( 0.029 ) & ( 0.018 ) +   + _ ( 2 ) _",
    "& + & ac@xmath467 & 7.475 & 6.907 & 7.772 & 7.338 & & 0.247 & 0.010 & 0.050 + & & ( 0.039 , & ( -0.529 , & ( 0.336 , & ( -0.098 , & & ( 0.250 , & ( 0.034 , & ( 0.050 , + & & 0.234 ) & -0.333 ) & 0.532 ) & 0.098 ) & & 0.694 ) & 0.532 ) & 0.110 ) + & ac@xmath468 & 8.156 & 8.878 & 8.715 & 8.744 & & 0.226 & 0.010 & 0.031 + & & ( -0.649 , & ( 0.072 , & ( -0.090 , & ( -0.062 , & & ( 0.229 , & ( 0.010 , & ( 0.031 , + & & -0.526 ) & 0.196 ) & 0.033 ) & 0.062 ) & & 0.687 ) & 0.532 ) & 0.103 ) + & ac@xmath469 & 11.803 & 12.415 & 11.710 & 12.115 & & 0.142 & 0.006 & 0.030 + & & ( -0.371 , & ( 0.241 , & ( -0.463 , & ( -0.058 , & & ( 0.147 , & ( 0.033 , & ( 0.030 , + & & -0.255 ) & 0.357 ) & -0.347 ) & 0.058 ) & & 0.664 ) & 0.532 ) & 0.102 ) +   + _ ( 3 ) _ & + & ac@xmath467 & 5.919 & 6.046 & 5.921 & 5.915 & & 0.077 & 0.005 & 0.016 + & & ( 0.002 ) & ( 0.129 ) & ( 0.003 ) & ( -0.002 ) & & ( 0.077 ) & ( 0.006 ) & ( 0.016 ) + & ac@xmath468 & 5.710 & 6.009 & 5.918 & 5.940 & & 0.077 & 0.005 & 0.016 + & & ( -0.208 ) & ( 0.092 ) & ( 0.001 ) & ( 0.023 ) & & ( 0.221 ) & ( 0.006 ) & ( 0.028 ) + & ac@xmath469 & 5.638 & 5.702 & 5.913 & 5.897 & & 0.078 & 0.005 & 0.014 + & & ( -0.279 ) & ( -0.215 ) & ( -0.004 ) & ( -0.021 ) & & ( 0.290 ) & ( 0.007 ) & ( 0.025 ) +   + _ ( 4 ) _",
    "& + & ac@xmath467 & 3.028 & 3.559 & 2.989 & 3.004 & & 0.125 & 0.007 & 0.034 + & & ( 0.056 ) & ( 0.587 ) & ( 0.017 ) & ( 0.032 ) & & ( 0.136 ) & ( 0.019 ) & ( 0.046 ) + & ac@xmath468 & 3.482 & 3.053 & 3.701 & 3.687 & & 0.112 & 0.006 & 0.033 + & & ( -0.233 ) & ( -0.662 ) & ( -0.013 ) & ( -0.028 ) & & ( 0.259 ) & ( 0.015 ) & ( 0.044 ) + & ac@xmath469 & 6.526 & 6.736 & 6.682 & 6.683 & & 0.046 & 0.002 & 0.011 + & & ( -0.161 ) & ( 0.050 ) & ( -0.004 ) & ( -0.004 ) & & ( 0.167 ) & ( 0.005 ) & ( 0.011 ) +   +    the estimate is computed for the monte carlo @xmath463 , the nadaraya watson @xmath464 , the generalized regression @xmath465 , and the markov chain monte carlo @xmath466 estimators .",
    "the standard error is computed except for the nw estimator .",
    "the bias and rmse are also computed for the cases ( 1 ) , ( 3 ) , and ( 4 ) , where true var contributions are available .",
    "the sample size is @xmath411 .",
    "the proposal distributions of the mcmc estimators are ( 1 ) random walk , ( 2 ) independent , ( 3 ) mpcn , and ( 4 ) mpcn .    in the case",
    "( 2 ) , where true var contributions are not available , the range of bias and rmse are computed based on the 95% confidence interval of the true var contributions derived by the mcmc estimator @xmath470 . based on the confidence interval @xmath471 and the estimate @xmath472 , we compute the range of the bias @xmath473 .",
    "the range of rmse is computed in the same way .    in the first risk model where marginals follow pareto distributions and they have a @xmath138-rotated clayton copula ,",
    "true var contributions can be computed explicitly .",
    "the true value is obtained by allocating the total var homogeneously because the marginal distributions are homogeneous and the copula is exchangeable . in this case , we observe that the mc and the nw estimators have relatively large biases .",
    "in contrast , the gr and the mcmc estimators have smaller biases compared with the first two .",
    "the gr estimator still has some bias caused by the model - misspecification , although its standard error is quite small . in the viewpoint of mse",
    ", the mcmc estimator outperforms all the other estimators .",
    "the second risk model has the same marginal distributions as in the case ( 1 ) , but their copula is @xmath295 copula having upper - lower tail dependence .",
    "even though the true var contributions are not available in this case , we can construct its 95% confidence interval based on the mcmc estimator by using ( @xmath474 ) . based on this interval of the true value , we computed the range of the bias and rmse for other estimators .",
    "the reported ranges of bias and rmse in table @xmath462 ( 2 ) show that the mcmc estimator significantly improves the performance of other estimators . under the risk model ( 2 ) , all estimators suffer from bias caused by asymmetry and multi - modality of the conditional distribution @xmath243 as seen in fig .",
    "@xmath456 ( b ) .",
    "especially , in contrast with the good performance of the gr in the case ( 1 ) , the gr estimator has relatively large bias and rmse in this case .",
    "the third risk model examines the case where the marginal distributions are student s @xmath295 distribution and their copula is @xmath138-rotated clayton .",
    "the true var contributions can be computed similarly as in the case ( 1 ) .",
    "thanks to symmetry and uni - modality of the conditional distribution @xmath243 , all estimators remain small bias and rmse .",
    "together with the results in the cases ( 1 ) and ( 2 ) , it can be found that the gr estimator performs well so long as @xmath243 does not have irregular shape , such as asymmetry and multi - modality .",
    "also , the mcmc estimator reduces bias and rmse compared with the mc and the nw estimators .",
    "the final risk model illustrates the case where the underlying portfolio loss vector follows the multivariate student s @xmath295 distribution . in this case , the true var contributions is available by the formula @xmath475 .",
    "in such an elliptical case , the gr estimator provides a quite accurate estimate .",
    "although the conditional distribution @xmath243 is heavy - tailed as seen in fig .",
    "@xmath456 ( d ) , the mcmc estimator keeps high performance compared with the mc and the nw estimators .",
    "its bias is significantly improved compared with the mc and the nw .",
    "additionally , its standard error and rmse are also lower than those of the mc estimator .    throughout the numerical study ,",
    "the mcmc estimator provided significantly small bias and rmse regardless of the shape of the conditional distribution @xmath243 . under the case when @xmath243 is unimodal and symmetric , the gr estimator also had good performance . on the other hand , at least in our numerical study , the mc and the nw estimator had larger bias and rmse compared with other estimators .    at the end of this section ,",
    "we summarize the advantages of the mcmc estimator compared with the other estimators .",
    "first , the mcmc estimator is consistent although the other estimators are not always . as explained in section @xmath1 , the mc , the nw , and the gr estimators have biases which can not be evaluated easily . in table",
    "@xmath462 , we observed that these estimators have some biases even when their standard errors are sufficiently small .",
    "in contrast , the mcmc estimator provides the accurate estimate of the var contributions due to its consistency .",
    "together with the clt , we also can construct the confidence interval of the true var contributions .",
    "second , the mcmc estimator has great sample efficiency compared with the mc estimator .",
    "since the mcmc estimator generates sample not from @xmath29 but from @xmath243 , no sample have to be discarded .",
    "in addition , unlike the mc , there is no trade - off between the bias and the sample efficiency .",
    "thanks to these properties , the mcmc estimator can hold low standard error without increasing the bias .",
    "finally , the mcmc estimator can maintain high performance even when the conditional distribution @xmath243 has irregular shape , such as multi - modality and heavy - tailed . as compared with the results in the case ( 2 ) and others in table @xmath462",
    ", the performance of the gr estimator highly depends on the shape of @xmath243 . for the existing estimators , it is generally difficult to reflect the shape of @xmath243 to their hyper - parameters . on the other hand , for the mcmc estimator",
    ", we can directly capture the shape of @xmath243 through the proposal distribution @xmath153 . by choosing an appropriate proposal distribution @xmath153",
    ", the mcmc estimator has stably good performance regardess of the shape of @xmath243 .      in section @xmath476",
    ", we have shown that the mcmc estimator improves the performance of estimating var contributions . however , the performance of the mcmc estimator highly depends on the appropriate choice of the proposal distribution @xmath153 . additionally , the choice of proposal distribution is less apparent compared with that of hyper - parameters for the other estimators . in this section ,",
    "we firstly investigate the symptoms caused by the bad choice of @xmath153 .",
    "then , we consider how to overcome this problem based on the numerical results .",
    "bad choice of @xmath153 is largely classified into two cases .",
    "one is that , the proposal distribution @xmath153 often generates a candidate at which the probability measured by @xmath138 is quite small .",
    "this case occurs for example when the variance of @xmath153 is much larger than that of @xmath138 , or when @xmath153 does not capture the irregular shape of @xmath138 as appeared in fig .",
    "@xmath456 ( b ) . in such cases ,",
    "the markov chain moves quite slowly , yielding high asymptotic standard error of the mcmc estimator .",
    "this symptom appears as a quite low acceptance rate and high autocorrelation plots .",
    "the other case is that the proposal distribution @xmath153 generates only some parts of the whole support of the target distribution @xmath138 .",
    "this case happens for example when @xmath138 has distinct local modes and the variance of @xmath153 is so small that the chain can not pass between them . in this case",
    ", the estimate has a significant bias , although the acceptance rate and the autocorrelation plots are seemingly fine .",
    "this symptom appears as a distorted plot of the mcmc samples whose shape is clearly different from the target distribution @xmath138 .",
    "how can we detect and avoid such fallacious estimates ?",
    "first of all , as mentioned in section @xmath127 , it is indispensable to check the acceptance rate and the autocorrelation plots . additionally , it is also important to draw the plots of the generated markov chain , and compare them with the plots of the mc samples whose sums belong to @xmath233 $ ] .",
    "since such mc samples follow the distribution @xmath477 , we can recognize the distortion of the generated markov chain by comparing with the two plots of the samples . in the case of our numerical study ,",
    "@xmath478 shows the scatter plots of the mc samples whose sums belong to @xmath479 $ ] , overlaid on the scatter plots of the mcmc samples .",
    "we can check in fig . @xmath478 that the shape of the scatter plots of the mcmc samples bear striking resemblance to those of the mc samples for all risk models .    ) and the mcmc ( @xmath480 ) samples for different risk models : ( a ) pareto + @xmath138-rotated clayton , ( b ) pareto + @xmath295 copula , ( c ) student s @xmath295 + @xmath138-rotated clayton , ( d ) student s @xmath295 + @xmath295 copula .",
    "we plot the mc samples generated from @xmath29 such that their sums belong to @xmath233 $ ] . in the four risk models , the value of @xmath80 are ( 1 ) 4.8 , ( 2 ) 3.9 , ( 3 ) 2.2 , and ( 4 ) 1.7 .",
    "when drawing the scatter plots of the mcmc samples , we used subsamples , which are picked up every 100-th points among the original markov chains .",
    "we plot only the first and second variables of 3-dimensional samples since the last variable is determined by the sum - constraint .",
    "the plots of the mc , and the mcmc samples express the distribution @xmath477 and @xmath243 , respectively . ]",
    "finally , we found that dependence information of the underlying risk model is quite helpful for the selection of @xmath153 .",
    "when the copula @xmath32 of the underlying risk model represents only upper and/or lower tail dependence , then the target distribution @xmath138 is likely to be tractable .",
    "for example in the cases of risk models ( 1 ) and ( 3 ) , where the copula @xmath32 has an upper tail dependence , the contour plots fig .",
    "@xmath456 ( a ) and ( c ) show that the target distribution @xmath138 is unimodal and light - tailed",
    ". these features facilitate the estimation with mcmc since simple proposal distributions such as random walk proposal ( @xmath481 ) perform well .",
    "conversely , when the copula @xmath32 has upper - lower tail dependence , then the target @xmath138 tends to be complicated . in the cases ( 2 ) and ( 4 ) , where the copula @xmath32 has upper - lower tail dependence , the fig .",
    "@xmath456 ( b ) indicates that the @xmath138 is bimodal , and also the contour plot fig .",
    "@xmath456 ( d ) shows that the @xmath138 is heavy - tailed . in such cases , careful selection of the proposal function @xmath153",
    "is required for the good performance of the mcmc estimator .",
    "for instance , to capture the bi - modality appeared in the contour plot fig .",
    "@xmath456 ( b ) , one of the good choice of @xmath153 is an independent proposal distribution @xmath482 with @xmath196 the dirichlet distribution on the @xmath228-simplex @xmath483 . since dirichlet distribution can possess two distinct modes around the edges of the simplex , we can generate a candidate which often visits the two separated modes of the @xmath138 . in the case",
    "( 4 ) , to overcome the problem of heavy - tailedness of @xmath138 seen in the contour plot fig .",
    "@xmath456 ( d ) , it is necessary to adopt some specialized mcmc for heavy - tailed target distribution , such as mpcn @xmath346 .",
    "computing var contributions for a continuous risk model is a difficult task in general .",
    "there is no standard method since existing estimators have their own deficiencies .",
    "especially , it can be seen that the crude monte carlo estimator suffers from unavoidable bias to the true var contributions .",
    "our mcmc estimator proposed enables the consistent estimation of var contributions . its sample efficiency",
    "is significantly improved because the mcmc estimator is computed by samples generated directly from the conditional density of a portfolio loss given the sum constraint .",
    "moreover , since the mcmc estimator can capture the features of the risk model more directly than the existing estimators , it can maintain high performance even when the shape of the underlying loss distribution is far from elliptical .",
    "we showed some theoretical properties of the mcmc estimator , such as consistency and asymptotic normality .",
    "the consistency follows naturally from the construction of the estimator .",
    "we provided some conditions and example where clt holds . by the general theory of mcmc",
    ", its asymptotic variance can be consistently estimated .",
    "we numerically compared the performance of various estimators of var contributions for typical risk models used in practice .",
    "the simulation results showed that , in most risk models we considered , the mcmc estimator had smaller bias and mse compared with the existing estimators .",
    "although the mcmc estimator has good theoretical properties and numerically shows great performance , some remaining issues merit future research .",
    "firstly , although we provided guidelines to choose good proposal distribution , they are hardly applicable when the dimension of the target distribution is too high to visualize",
    ". for such high - dimensional cases , asymptotic analysis and adaptive method should be developed to chooce good proposal distribution .",
    "secondly , theoretical investigation of the conditional joint distribution given the sum constraint is still unsatisfactory .",
    "our concern mainly lies with the influence of the underlying copula of a risk model to the shape of the conditional joint distribution , such as tail behavior and multi - modality .",
    "we believe that revealing these relations helps to find a better proposal distribution in our context of estimating var contributions .",
    "finally , our mcmc method can potentially be extended to the computation of _ expected shortfall ( es ) contributions_. the es contributions can be derived as a conditional expectation of losses given that the total loss is equal to or greater than var ( see tasche , 2001 ) . due to its similar structure to the var contributions ,",
    "the es contributions can also be efficiently estimated in an analogous method proposed in this paper .",
    "this , and other potential extensions are currently being studied by us .",
    "we would like to thank paul embrechts for his valuable comments and kengo kamatani for a fruitful discussion on mcmc .",
    "our research is supported by the core - to - core program ( japan society for the promotion of science : jsps ) in keio univeristy .",
    "d. tasche .",
    "capital allocation to business units and sub - portfolios : the euler principle . in _ pillar ii in the new basel accord : the challenge of economic capital _ ( ed .",
    "a. resti ) , 423 - 453 .",
    "london : risk books , 2008 ."
  ],
  "abstract_text": [
    "<S> _ keywords : _ quantitative risk management ; value - at - risk ; economic capital ; risk allocation ; risk contributions ; var contributions ; markov chain monte carlo </S>"
  ]
}