{
  "article_text": [
    "asymptotic equivalence is a powerful concept for analysing statistical inference problems by a transfer to the analogous problem in a simpler statistical experiment . a breakthrough were the results by brown and low @xcite and nussbaum @xcite who established asymptotic equivalence of the two classical experiments , one - dimensional gaussian regression and density estimation , with an accompanying sequence of gaussian shift experiments . in this paper",
    "we consider the statistical inference for the drift in a multidimensional diffusion experiment under stationarity assumptions and prove the asymptotic equivalence with corresponding multidimensional gaussian shift and regression experiments .",
    "asymptotic equivalence results for dependent data are not very numerous , see dalalyan and rei @xcite for an overview . even for simple experiments , as the classical ones described above , results for asymptotic equivalence in the multidimensional case are very scarce .",
    "we only know of the recent work by carter @xcite who proves asymptotic equivalence for two - dimensional gaussian regression , but argues that his method fails for higher dimensions .",
    "one of the main reasons for the difficulties in transferring methods to higher dimensions is that piecewise constant approximations of the unknown functional parameter usually do not suffice anymore and higher order approximations have to be used , which creates unexpected problems .",
    "brown and zhang @xcite remark that the two classical experiments and their accompanying gaussian shift experiments are not asymptotically equivalent in the case of nonparametric classes of hlder regularity @xmath0 , where @xmath1 denotes the dimension .    the methodology we applied in @xcite to establish asymptotic equivalence for scalar diffusions relied heavily on the concept of local time . for multidimensional diffusions",
    "local time does not exist .",
    "this might explain why the statistical theory for scalar diffusions is very well developed ( see kutoyants @xcite ) , while inference problems for multidimensional diffusions are more involved and much less studied .",
    "we refer to bandi and moloche @xcite for the analysis of kernel estimators for the drift vector and the diffusion matrix and to at - sahalia @xcite for a recent discussion of applications for multidimensional diffusion processes in econometrics .",
    "in section 2 we review results for multidimensional diffusions and construct estimators for the invariant density and the drift vector .",
    "interestingly , the estimator of the invariant density converges for @xmath2 with a rate which is slower than parametric , but faster than in classical @xmath1-dimensional density estimation problems .",
    "the local equivalence result of the multidimensional diffusion experiment with an accompanying gaussian shift experiment is formulated and described in section 3 .",
    "the local neighbourhoods can be attained for drift functions in a nonparametric class of regularity @xmath3 for any dimension @xmath4 . in section 4 the corresponding equivalence with a heteroskedastic regression experiment , which does not depend on the centre of localisation ,",
    "is treated .",
    "this can be used to establish global equivalence with a single experiment , which even in the one - dimensional case can not be obtained for the gaussian shift experiment due to the absence of a variance stabilising transform , as was first noted by delattre and hoffmann @xcite .",
    "the explicit construction of a markov kernel establishing the important part of the asymptotic equivalence is presented in section 5 .",
    "the proof of the main local equivalence result is deferred to section 6 .",
    "we assume that a continuous record @xmath5 of a @xmath1-dimensional diffusion process @xmath6 is observed up to time instant @xmath7 .",
    "this diffusion process is supposed to be given as a solution of the stochastic differential equation @xmath8,\\ ] ] where @xmath9 , @xmath10 is a @xmath1-dimensional brownian motion and @xmath11 is a random vector independent of @xmath12 .",
    "we denote by @xmath13 , @xmath14 , the components of the vector valued function @xmath15 . in what follows ,",
    "we assume that the drift is of the form @xmath16 , where @xmath17 is referred to as potential .",
    "this restriction permits to use strong analytical results for the markov semigroup of the diffusion on the @xmath18-space generated by the invariant measure .    for positive constants @xmath19 and @xmath20",
    ", we define @xmath21 as the set of all functions @xmath22 satisfying for any @xmath23 @xmath24 where @xmath25 denotes the euclidian norm in @xmath26 .",
    "any such function @xmath15 is locally lipschitz - continuous .",
    "therefore equation ( [ diff ] ) has a unique strong solution , which is a homogeneous continuous markov process , cf .",
    "rogers and williams @xcite , thm .",
    "set @xmath27 and @xmath28 under condition ( [ k ] ) we have @xmath29 and the process @xmath6 is ergodic with unique invariant probability measure ( bhattacharya  ( * ? ? ?",
    "* thm .  3.5 ) ) .",
    "moreover , the invariant probability measure of @xmath6 is absolutely continuous with respect to the lebesgue measure and its density is @xmath30 . from now on",
    ", we assume that the initial value @xmath11 in ( [ diff ] ) follows the invariant law such that the process @xmath6 is strictly stationary .",
    "we denote by @xmath31 the law of this process induced on the canonical space @xmath32;\\rr^d),\\mathcal b_{c([0,t];\\rr^d)}\\big)$ ] and by @xmath33 the expectation operator with respect to this law .",
    "we write @xmath34=\\int f\\mu_b$ ] .",
    "let @xmath35 be the transition semigroup of this process on @xmath36 , that is @xmath37,\\ ; f\\in l^2(\\mu_b)=\\big\\{f:\\rr^d\\to\\rr:\\int\\!\\ !",
    "|f|^2\\mu_b<\\infty\\big\\}.\\ ] ] the transition density is denoted by @xmath38 : @xmath39 .",
    "we write @xmath40 when @xmath41 is bounded by a constant multiple of @xmath42 uniformly over the parameter values @xmath43 , that is @xmath44 using the landau symbol .",
    "similarly , @xmath45 means that @xmath40 as well as @xmath46 .",
    "we denote by @xmath47 the lebesgue measure and by @xmath48 the diameter of a borel set @xmath49 .    for any multi - index @xmath50 and @xmath51 we set @xmath52 and @xmath53 .",
    "let us introduce the hlder class @xmath54 \\hbox{for any $ \\alpha$ such that $ |\\alpha|=\\lfloor \\beta\\rfloor$ } \\end{matrix } \\bigg\\}\\ ] ] where @xmath55 is the largest integer _",
    "strictly _ smaller than @xmath56 and @xmath57 .",
    "let us assume that the potential @xmath58 lies in @xmath59 for some @xmath60 , which implies @xmath61 .",
    "furthermore , if for some constant @xmath62 we have @xmath63 then the function @xmath30 is hlder continuous of order @xmath64 in any bounded set @xmath49 , that is @xmath65 for all @xmath66 and for some constant @xmath67 .",
    "we denote by @xmath68 the set of all functions @xmath15 such that @xmath69 and ( [ deriv ] ) is fulfilled .",
    "a natural kernel estimator for the invariant density based on the observation @xmath70 is given by @xmath71 here , @xmath72 and @xmath73 is a smooth kernel function of compact support , satisfying @xmath74 and @xmath75 whenever @xmath76 8.9 ) @xmath77\\lesssim h^{2(\\beta+1)}+t^{-2}\\operatorname{var}\\big[\\int_0^t k_h(x - x_t)\\,dt\\big].\\ ] ] by analogy with the model of regression with random design , a reasonable estimator of @xmath15 is obtained by setting @xmath78 where @xmath79 is some a priori lower bound on @xmath80 , see remark  [ lowmu ] below .",
    "a similar risk analysis gives for @xmath14 : @xmath81&\\lesssim & h^{2\\beta}+\\frac1{th^d}+\\frac1{t^2}\\operatorname{var}\\big[\\int_0^t k_{h}(x - x_t)b_i(x_t)\\,dt\\big]\\nonumber\\\\ & & + \\ex_b\\big[|\\hat{\\mu}_{h , t}(x)-\\mu_b(x)|^2\\big].\\end{aligned}\\ ] ]      in order to determine the asymptotic behaviour for @xmath82 , we study the variance of general additive functionals of @xmath6 in @xmath1 dimensions .",
    "to do so , we assume that the semigroup @xmath35 enjoys the following properties .",
    "[ a1 ] there exists a @xmath83 such that for any @xmath84 and for any @xmath85 @xmath86    [ a2 ] there is a @xmath87 such that for any @xmath85 and for any pair of points @xmath23 , satisfying @xmath88 , we have @xmath89    due to remark 4.14 in chen and wang  @xcite assumption [ a1 ] is fulfilled with @xmath90 , whenever ( [ k ] ) holds .    if @xmath15 fulfills ( [ m ] ) ,",
    "then assumption [ a2 ] can be deduced from qian and zheng ( * ? ? ?",
    "3.2 ) . indeed , taking in that inequality",
    "@xmath91 and bounding the terms @xmath92 and @xmath93 respectively by @xmath94 and @xmath95 , we get the desired inequality .",
    "if moreover @xmath15 is bounded , assumption [ a2 ] is satisfied for every @xmath96 and without the term @xmath97 at the right - hand side , cf .",
    "qian _ et al . _",
    "* inequality ( 5 ) ) .",
    "[ adfunc ] let @xmath98 be a positive number and @xmath99 be a bounded , measurable function with support @xmath100 satisfying @xmath101 and @xmath102 . under assumptions [ a1 ] and [ a2 ] there exists a constant @xmath103 depending only on @xmath98 , @xmath2 and on @xmath104 and @xmath105 from assumptions [ a1 ] and [ a2 ] such that @xmath106 where @xmath107 and @xmath108    set @xmath109 .",
    "symmetry and stationarity yield @xmath110dt\\,ds\\\\ & = 2\\int_0^t\\int_0^s\\ex_b\\big[f_c(x_0)f_c(x_{s - t})\\big]dt\\,ds\\\\ & = 2\\int_0^t(t - u)\\ex_b\\big[f_c(x_0)f_c(x_{u})\\big]\\,du\\\\ & \\le 2t\\int_0^t \\big\\langle f_c , p_{b , u}f_c\\big\\rangle_{\\mu_b}\\,du.\\end{aligned}\\ ] ] let @xmath111 where the specific choice of @xmath112 is given later .",
    "then @xmath113\\cup [ d , t ] } \\big\\langle f_c , p_{b , u}f_c\\big\\rangle_{\\mu_b}\\,du \\le ( \\delta+\\rho^{-1}e^{-\\rho d})\\|f\\|_{\\mu_b}^2 \\lesssim ( \\delta+e^{-\\rho d})\\mu_b({\\cal s})\\|f\\|_\\infty^2\\ ] ] follows from @xmath114 given by assumption [ a1 ] . for moderate values",
    "@xmath115 $ ] we use @xmath116 for @xmath117 we infer from assumption [ a2 ] @xmath118 combining and and assuming @xmath119 , for @xmath120 we find @xmath121 balancing the terms , we choose @xmath122 and @xmath123 .",
    "this gives the asserted estimate because we had assumed @xmath124 .",
    "the case @xmath125 can be treated similarly .    in the case",
    "@xmath126 the bound holds with @xmath127 , cf .",
    "proposition 5.1 in dalalyan and rei @xcite .",
    "the dimensional effect is due to the singular behaviour of @xmath128 for @xmath129 .",
    "however , if the term @xmath97 is absent in assumption [ a2 ] , then in the definition of @xmath130 the term @xmath131 can be replaced by @xmath132 .",
    "this is the case when the drift is bounded .",
    "[ estrates ] if @xmath133 , the estimators given in and satisfy for @xmath134 sufficiently small the following risk estimates : @xmath135&\\lesssim h^{2(\\beta+1)}+t^{-1}\\psi_d^2(h^d),\\\\ \\ex_b\\big[|\\hat{b}_{h , t}(x)-b(x)|^2\\big]&\\lesssim h^{2\\beta}+t^{-1}h^{-d}+h^{2(\\beta+1)}+t^{-1}\\psi_d^2(h^d).\\end{aligned}\\ ] ] the rate - optimal choice @xmath136 yields the rates @xmath137^{1/2}&\\lesssim \\begin{cases } t^{-1/2}(\\log t)^2,&d=2,\\\\ t^{-(\\beta+1)/(2\\beta+d ) } , & d\\ge 3,\\end{cases}\\\\ \\ex_b\\big[|\\hat{b}_{h(t),t}(x)-b(x)|^2\\big]^{1/2}&\\lesssim t^{-\\beta/(2\\beta+d)}.\\end{aligned}\\ ] ]    the risk bound for @xmath138 follows from @xmath139 , @xmath140 and an application of proposition [ adfunc ] to the bias - variance decomposition for any @xmath134 sufficiently small .",
    "in the same way , we obtain the estimate for each @xmath141 and the rates follow by simple substitution .",
    "the convergence rates for the risk of @xmath142 are to be compared with the one - dimensional case , where the parametric rate @xmath143 is obtained , and with standard multivariate density estimation , where the corresponding rate is @xmath144 for @xmath145 observations , which is considerably larger .",
    "in contrast , the rate for @xmath146 corresponds exactly to the classical rate @xmath144 in regression or density estimation .",
    "[ lowmu ] using conditions ( [ m ] ) , ( [ k ] ) and the equality @xmath147 we find @xmath148 therefore , we can take @xmath149 as an a priori lower bound for @xmath80",
    ". moreover , due to assumption ( [ deriv ] ) the function @xmath30 is hlder continuous in @xmath150 for any @xmath151 and for any bounded set @xmath49 .",
    "therefore we do not need to modify the kernel estimators at the boundaries of @xmath152 and the inequalities of corollary  [ estrates ] hold uniformly in @xmath15 and in @xmath153 .",
    "[ supnorm ] corollary  [ estrates ] describes the rates of convergence of estimators for the local risk , that is for a pointwise loss function . to attain the local neighbourhood defined in the next section , the risk given by the sup - norm loss",
    "must be studied . in the classical problems of nonparametric estimation , the rates of convergence for",
    "the sup - norm loss on a compact set coincide up to a logarithmic factor with the local rates of convergence ( korostelev and nussbaum  @xcite , gin , koltchinskii and zinn  @xcite ) .",
    "the extension from the pointwise to the uniform loss result is usually fairly standard , but more involved and lies out of the scope of this paper .",
    "let @xmath154 be the set of functions @xmath155 such that all @xmath1 components @xmath156 of @xmath15 are in @xmath157 .",
    "we fix a function @xmath158 .",
    "our main result establishes a local asymptotic equivalence between diffusion and gaussian shift models in the local setting , that is when the parameter set is a shrinking neighbourhood of @xmath159 .",
    "@xmath160 always denotes the borel @xmath161-algebra of a topological space @xmath162 .",
    "suppose @xmath163 for some @xmath164 . for",
    "any @xmath165 let @xmath166 be the statistical experiment of observing the diffusion defined by ( [ diff ] ) with @xmath167 , that is @xmath168;\\rr^d ) , \\mathcal b_{c([0,t];\\rr^d ) } , ( \\pb_b^t)_{b\\in\\sigma}\\big).\\ ] ]    for any function @xmath169 induced by the @xmath1-dimensional process @xmath170 satisfying @xmath171 where @xmath172 and @xmath173 are independent @xmath1-variate brownian sheets , that is zero mean gaussian processes with @xmath174 where @xmath175\\}$ ] .    for @xmath176 and @xmath165",
    "let @xmath177 be the gaussian shift experiment ( [ gauss ] ) with @xmath167 , that is @xmath178    for any positive numbers",
    "@xmath179 , @xmath180 and for any hypercube @xmath49 , we define the local neighbourhood of @xmath181 @xmath182 where @xmath183 is the indicator function of the set @xmath152 .",
    "we state the main local equivalence result , which will be proved in section  [ appendix ] .",
    "the main ideas of the proof are explained in the next subsection . for the exact definition of statistical equivalence and the le cam distance",
    "@xmath184 we refer to le cam and yang  @xcite .",
    "[ th1 ] if @xmath185 and @xmath186 satisfy the conditions @xmath187 then the diffusion model is asymptotically equivalent to the gaussian shift model ( [ gauss ] ) over the parameter set @xmath188 , that is @xmath189    let us see for which hlder regularity @xmath56 on the drift an estimator can attain the local neighbourhood , that is @xmath190 and @xmath191 hold with a probability tending to one ( cf .",
    "nussbaum @xcite for this concept ) . by the rates obtained in corollary [ estrates ] , with a glance at remark  [ supnorm ] and the condition in theorem [ th1 ] ,",
    "this is the case if @xmath192 it turns out that the second condition is most binding and all three conditions are satisfied if @xmath3 .",
    "the critical regularity thus grows like @xmath193 for @xmath194 . in dimension",
    "@xmath195 we obtain the condition @xmath196 as in the result by carter @xcite for gaussian regression .",
    "whether for hlder classes of smaller regularity asymptotic equivalence fails , remains a challenging open problem .",
    "the general idea of the proof of theorem  [ th1 ] consists in discretising ( in space ) the diffusion process such that the design regularisation technique we introduced in  @xcite is applicable in spirit , even though the local time does not exist .      for any multi - index @xmath50 set @xmath197 .",
    "let us denote by @xmath198 the elements of the set @xmath199\\,:\\,v(x)=x^\\alpha\\hbox { with } |\\alpha|\\leq \\lfloor\\beta\\rfloor\\}$ ] somehow enumerated : @xmath200 .",
    "we assume that @xmath201 is a hypercube and for some @xmath202 with @xmath203 we denote by @xmath204 the elements of the grid @xmath205 .",
    "we introduce the subcubes @xmath206 , @xmath207 , where @xmath208 is the @xmath209th coordinate of @xmath210 .",
    "let us define @xmath211 which gives rise to the definition @xmath212 of the taylor approximation for @xmath15 @xmath213 and @xmath214 for @xmath215 ( @xmath216 is applied coordinate - wise ) . using this notation ,",
    "the taylor formula can be written as @xmath217 where @xmath218 satisfies @xmath219 .",
    "this implies that for @xmath220 , the estimate @xmath221 holds .",
    "we write @xmath222 for @xmath223 and we shall use equivalently @xmath224 and @xmath15 for referring to the parameter in the local neighbourhood .",
    "the log - likelihood of the experiment defined via @xmath225 is given by ( see liptser and shiryaev  ( * ? ? ?",
    "* , ( 7.62 ) ) ) @xmath226,\\end{aligned}\\ ] ] where @xmath227 and @xmath228 denotes the @xmath209th component of @xmath229 .      due to the ergodicity of @xmath6",
    "the law of the log - likelihood will for large @xmath7 be well approximated by @xmath230 where @xmath231 i.i.d . and",
    "@xmath232    since @xmath233 the process ( [ log - like ] ) ( indexed by @xmath234 ) has exactly the same law as the log - likelihood of the gaussian shift @xmath235 under suitable assumptions on the smoothness of @xmath15 , this last experiment is asymptotically equivalent to ( [ gauss ] ) .",
    "it remains to construct the random variables @xmath236 on some enlargement of the probability space @xmath237;\\rr^d ) , \\mathcal b_{c([0,t];\\rr^d)},\\pb_b^t)$ ] such that @xmath238 and @xmath239 are close as random variables .",
    "we define the stopping time @xmath240:\\|\\mathcal j_m^{-1/2}\\hat{\\mathcal j}_m(t)\\mathcal j_m^{-1/2}\\|\\geq t\\big\\}\\wedge t,\\ ] ] where the norm of a matrix @xmath152 is given by @xmath241 .",
    "let @xmath242 be a family of independent standard normal random vectors in @xmath243 , defined on an enlarged probability space such that @xmath244 and @xmath6 are independent .",
    "we set @xmath245 by definition of @xmath246 the matrix @xmath247 is nonnegative definite and its square root is well defined .",
    "[ prop2 ] under the probability measure @xmath248 the random vectors @xmath249 are independent and each @xmath239 is centred gaussian with covariance matrix @xmath250 .",
    "it suffices to show that for any sequence @xmath251 we have @xmath252 = \\exp\\bigg\\{\\frac12\\sum_{m , j}\\lambda_{mj}^t\\mathcal j_m\\lambda_{mj}\\bigg\\},\\ ] ] where the expectation is taken with respect to @xmath6 following the law @xmath253 and @xmath254 being i.i.d .",
    "standard normal in @xmath243 , independent of @xmath6 .",
    "the verification of this equality is very similar to the proof of proposition 2.13 in dalalyan and rei  @xcite and is omitted .",
    "the gaussian experiment in theorem  [ th1 ] depends on the centre @xmath159 of the neighbourhood via @xmath255 .",
    "this fact makes the passage from the local equivalence to a global equivalence difficult , especially , because even in the one - dimensional case there is no known variance stabilising transform for ( [ gauss ] ) , cf .",
    "dalalyan and rei @xcite .",
    "we propose here a method of deriving an asymptotically equivalent experiment independent of @xmath159 without using the variance stabilising transform .",
    "the idea is to discretise the gaussian shift experiment with a `` step of discretisation '' larger than @xmath256 .",
    "this method has already been used in  brown and zhao  @xcite for proving the asymptotic equivalence between regression models with random and deterministic designs .",
    "we adopt the notation from section [ outline ] .",
    "in addition , we introduce the @xmath257-matrix @xmath258^d}\\mv(x)\\mv(x)^t\\,dx,$ ] where @xmath259 is defined by ( [ mbmv ] ) . since @xmath260 is strictly positive and symmetric , the matrix @xmath261 is well defined .",
    "let @xmath262 be a subset of @xmath263 .",
    "for any @xmath264 we define @xmath265 as the experiment of observing @xmath266 for @xmath267 , where @xmath268 is a family of independent standard gaussian random vectors in @xmath243 and @xmath167 .",
    "note that the observations in this experiment are chosen from @xmath269 according to a gaussian measure . both the mean and the variance of this measure depend on the parameter @xmath15 such that the experiment is heteroskedastic .",
    "[ th2 ] if the assumptions of theorem  [ th1 ] are fulfilled and @xmath270 satisfies @xmath271 then the diffusion experiments and the heteroskedastic gaussian regression experiments are asymptotically equivalent , that is @xmath272    theorem  [ th1 ] yields the asymptotic equivalence of the experiment @xmath273 with the ( translated ) gaussian shift experiment @xmath274 let us introduce a new gaussian shift : @xmath275 since @xmath276 and @xmath277 are uniformly bounded , the difference between the drifts of @xmath278 and @xmath279 can be estimated as follows : @xmath280 therefore , the hellinger distance between the measures induced by @xmath278 and @xmath279 tends to zero as @xmath82 ( strasser  ( * ? ? ?",
    "69.8.(2 ) ) ) , provided that @xmath281 and @xmath282 .",
    "the log - likelihood of the experiment given by @xmath279 has exactly the same law as the log - likelihood of the gaussian regression @xmath283 for @xmath284 , where @xmath268 is a family of independent standard gaussian random vectors in @xmath243 and @xmath167 . by lemma  3 from brown et",
    "@xcite the square of the hellinger distance between the measures induced by the observations ( [ reg1 ] ) and ( [ reg1 ] ) , respectively , is up to a constant bounded by @xmath285 .",
    "because of @xmath286 we infer @xmath287 and the condition @xmath288 as @xmath82 implies that the hellinger distance tends to zero uniformly in @xmath289 .",
    "finally , the desired result follows by bounding the le cam distance between experiments by the supremum of the hellinger distance between the corresponding measures , see e.g. nussbaum  ( * ? ? ?",
    "* eq . ( 12 ) ) .",
    "the experiment given by  ( [ reg1 ] ) is more informative than the experiment generated by the observations @xmath290 , where @xmath291 . if we enumerate @xmath292 so that @xmath293 then @xmath294 satisfies @xmath295 with @xmath296 i.i.d",
    ". therefore the diffusion experiment @xmath297 is asymptotically more informative than the regression experiment : @xmath298    if we choose @xmath299 , @xmath300 and @xmath301 ( in view of corollary  [ estrates ] ) , the condition of theorem  [ th2 ] takes the form @xmath302 such a value @xmath303 exists if and only if @xmath304 for @xmath125 this inequality reduces to @xmath196 . for @xmath305 it is equivalent to @xmath306 .",
    "note also that the logarithmic factors in @xmath185 and @xmath186 do not affect this bound on the minimal regularity .    as mentioned in the introduction ,",
    "the result of theorem  [ th2 ] is new already in the one - dimensional case .",
    "when @xmath126 , using a @xmath307-consistent estimator of @xmath30 ( kutoyants  @xcite , @xmath308 4.2 ) , the local neighbourhood can be attained as soon as @xmath309 .",
    "taking @xmath310 and using the globalisation method developed in  @xcite , we obtain the global asymptotic equivalence of the diffusion experiment and the regression @xmath311 provided that @xmath312 with @xmath313 and the assumptions of ( * ? ? ?",
    "3.5 ) are fulfilled .",
    "the result of theorem  [ th1 ] implies in particular that there exists a markov kernel @xmath314 from @xmath237;\\rr^d),\\mathcal b_{c([0,t];\\rr^d)})$ ] to @xmath315 such that @xmath316 where @xmath317;\\rr^d)}k(x , a)\\pb_b^t(dx)$ ] for @xmath318 and @xmath319 denotes the total variation norm .",
    "the aim of this section is to construct this markov kernel explicitly .",
    "the construction is divided into two steps .",
    "first , we give the markov kernel from the diffusion experiment to a suitable multivariate gaussian regression .",
    "then we give the markov kernel from the gaussian regression to the gaussian shift experiment .",
    "an explicit markov kernel in the other direction is not known , but seems also less useful .",
    "assume that we have a path @xmath70 of the diffusion process  ( [ diff ] ) at our disposal . in what follows we use the notation introduced in section  [ outline ] with @xmath134 verifying ( [ hrate ] ) below .",
    "for any @xmath14 we denote by @xmath320 the @xmath321th coordinate of @xmath322 and define the randomisation @xmath323 where @xmath324 , @xmath250 and @xmath246 are defined by ( [ hatsigma ] ) , ( [ sigma ] ) and ( [ taum ] ) and @xmath325 is a family of independent ( and independent of @xmath70 ) standard gaussian vectors in @xmath243 .",
    "as is easily checked , the random vector @xmath326 with @xmath327 has the same law as the gaussian regression @xmath328 we prove in section  [ proof th1 ] that the total variation between the laws of @xmath244 and @xmath329 tends to zero as @xmath82 .",
    "consequently , if we denote by @xmath330 the law of @xmath331 , we obtain a markov kernel realising the asymptotic equivalence between the diffusion and the gaussian regression ( [ regr1 ] ) .    for any @xmath332 and for any @xmath333",
    ", we define the randomisation of the regression by @xmath334 where @xmath335 , @xmath336 and @xmath337 are independent @xmath1-variate brownian sheets independent of @xmath338 .",
    "let us show that @xmath339 is an equivalence mapping from the gaussian regression model ( [ regr1 ] ) to the gaussian shift model ( [ gauss ] ) .",
    "for any @xmath340 and for any @xmath14 define the multivariate analogue of a brownian bridge @xmath341 and set @xmath342 the process @xmath343 takes values in @xmath243 and can be rewritten in the form @xmath344 where @xmath345 by construction , the process @xmath346 is centred gaussian with covariance matrix @xmath347=\\int_{r(a_m , x)\\cap r(a_m,{\\bar x})}\\mv(u)\\mv(u)^t\\mu_{b^\\circ}(u)\\,du$ ] . assuming that @xmath348 are enumerated in such a way that @xmath349",
    ", one checks that @xmath350 is a @xmath1-variate brownian sheet , where @xmath351 is the first coordinate of @xmath346",
    ". therefore , the randomisation @xmath352 satisfies @xmath353 the total variation between the measures induced by ( [ phi2 ] ) and ( [ gauss ] ) is up to a constant bounded by @xmath354 , which tends to zero because of our choice of @xmath134 and the assumptions of theorem  [ th1 ] .",
    "moreover , the @xmath1-variate brownian sheets @xmath355 are independent .",
    "simple algebra shows that the two definitions ( [ phi21 ] ) and ( [ tphi2 ] ) coincide .",
    "hence the law @xmath356 of @xmath357 provides a markov kernel from the gaussian regression ( [ regr1 ] ) to the gaussian shift ( [ gauss ] ) realising the asymptotic equivalence .",
    "as we have seen in section [ outline ] , the construction of the gaussian experiment makes use of an i.i.d .",
    "family @xmath358 of standard gaussian vectors with values in @xmath243 . the canonical version of @xmath244 is defined on the measurable space @xmath359 .",
    "we prove the asymptotic equivalence by a suitable coupling , which consists in constructing probability measures @xmath360 and @xmath361 on the product space @xmath362,\\rr^d)\\times \\rr^{kmd } , \\mathcal b_{c([0,t],\\rr^d)}\\otimes \\mathcal b_{\\rr^{kmd}}\\big)\\ ] ] such that +      \\a ) define @xmath368 to be the measure induced by the pair @xmath369 , where @xmath70 is given by ( [ diff ] ) and @xmath244 is a standard gaussian vector independent of @xmath70 , that is @xmath370 with @xmath371 denoting the standard normal law on @xmath372 .",
    "then the equivalence @xmath373 follows from the equality in law of the respective likelihood processes , cf .",
    "strasser  ( * ? ? ?",
    "25.9 ) .",
    "\\b ) the measure @xmath374 is defined via @xmath375 for @xmath376,\\rr^d)}$ ] and @xmath377 with @xmath378\\ ] ] and @xmath379 because of @xmath380 these definitions yield @xmath381 and therefore @xmath382 .",
    "proposition  [ prop2 ] combined with the classical formula of the characteristic function of a gaussian vector implies that @xmath374 is a probability measure .    to prove the asymptotic equivalence of @xmath383 and @xmath384",
    ", it suffices to show that the kullback - leibler divergence between the measures @xmath385 and @xmath374 tends to zero uniformly in @xmath289 ( see the proof of thm . 2.16 in  @xcite ) . the fubini theorem yields @xmath386.\\end{aligned}\\ ] ] the girsanov formula ( liptser and shiryaev @xcite ) and the fact that the expectation of the stochastic integral is zero give @xmath387= \\ex_b\\big[\\log\\big(\\frac{\\mu_b(x_0)}{\\mu_{b^{\\circ}}(x_0)}\\big)\\big]+ \\frac12\\ex_b\\big[\\int_0^t|\\th(x_t)|^2 \\,dt\\big]\\\\ & = \\ex_b\\big[\\log\\big(\\frac{\\mu_b(x_0)}{\\mu_{b^{\\circ}}(x_0)}\\big)\\big]+ \\frac{t}2 \\,\\int_{a}\\big|\\th(x)-\\bar\\th(x)\\big|^2\\,\\mu_b(x)\\,dx\\\\ & \\quad + \\frac{t}2 \\,\\int_{a}|\\bar\\th(x)|^2\\mu_b(x)\\,dx + t \\,\\int_{a}\\bar\\th(x)^t\\big(\\th(x)-\\bar\\th(x)\\big)\\,\\mu_b(x)\\,dx.\\end{aligned}\\ ] ] similarly , we find @xmath388 = \\sum_{m=1}^m\\sum_{j=1}^d\\big(-\\frac{t}2\\ ; \\bth_{j}(a_m)^t\\mathcal j_m\\,\\bth_j(a_m)\\\\ & \\qquad\\qquad\\qquad+\\ex_b\\big[\\bth_j(a_m)^t \\int_0^{\\tau_m}\\1_{\\bc_m}(x_t)\\mv(x_t - a_m)\\,\\th_{j}(x_t)\\,dt\\big]\\big)\\\\ & \\quad = - \\frac{t}{2 } \\,\\int_{a}|\\bar\\th(x)|^2\\mu_{b^\\circ}(x)\\,dx + \\sum_{m=1}^m\\ex_b\\big[\\int_0^{\\tau_m}\\1_{\\bc_m}(x_t)|\\bar\\th(x_t)|^2\\,dt\\big]\\\\ & \\qquad\\qquad\\qquad + \\sum_{m=1}^m\\ex_b\\big[\\int_0^{\\tau_m}\\1_{\\bc_m}(x_t)\\bar\\th(x_t)^t(\\th(x_t ) -\\bar\\th(x_t))\\,dt\\big].\\end{aligned}\\ ] ] using for @xmath389 and @xmath390 the general identity @xmath391,\\ ] ] we obtain @xmath392 with @xmath393,\\\\ \\calt_2(\\th)&=&\\frac{t}2\\int_{a}|\\bar\\th(x)|^2\\big(\\mu_{b^{\\circ}}(x)-\\mu_b(x)\\big)\\,dx,\\\\ \\calt_3(\\th)&=&\\sum_{m=1}^m\\ex_b\\big[\\int_{\\tau_m}^t    \\calt_4(\\th)&=&\\frac{t}2 \\,\\int_a \\big|\\th(x)-\\bar\\th(x)\\big|^2\\,\\mu_b(x)\\,dx,\\\\ \\calt_5(\\th)&=&\\sum_{m=1}^m\\ex_b\\big[\\int_{\\tau_m}^t\\1_{\\bc_m}(x_t)\\,\\bar\\th(x_t)^t(\\th(x_t ) -\\bar\\th(x_t))\\,dt\\big].\\end{aligned}\\ ] ] the cauchy - schwarz inequality implies that @xmath394",
    "the explicit form of the invariant density @xmath30 implies that @xmath395 .",
    "the hlder assumption implies that @xmath396 and we infer @xmath397 in section [ lemmat3 ] below we prove that @xmath398 holds if @xmath270 tends to zero for @xmath82 .",
    "hence , we obtain @xmath399 consequently , the rate - optimal choice of @xmath134 is @xmath400 provided that @xmath401 , so that @xmath402 given @xmath403 . under the assumptions of the theorem we thus conclude that @xmath383 and @xmath384 are asymptotically equivalent .",
    "\\c ) it remains to verify that the statistical experiment @xmath404 defined via @xmath405 is asymptotically equivalent to the experiment @xmath384 defined via @xmath374 .",
    "we have already seen that @xmath406.\\ ] ] recall that according to proposition  [ prop2 ] the random vectors @xmath407 are independent gaussian with covariance matrix @xmath250 . therefore , the law of the log - likelihood process @xmath408 coincides with the law of the process @xmath409 .",
    "this gives the equivalence of the experiments @xmath384 and @xmath410 , where the latter experiment is defined by the observation @xmath411 to conclude , we remark that the kullback - leibler divergence between the gaussian experiments @xmath404 and @xmath410 is bounded by @xmath412 and in view of tends to zero for @xmath413 .",
    "we start by sketching how the estimate could be reduced to a purely analytical problem , using @xmath415\\label{t3decomp}\\\\ & \\quad\\le { \\lvert \\bar{b}-\\bar{b}_0 \\rvert}_\\infty^2 \\big(\\sup_m \\ex_b[t-\\tau_m]+\\sum_m \\big(\\ex_b\\bigl[\\int_{\\tau_m}^t(\\1_{\\bc_m}(x_t)-\\pb_b(\\bc_m))\\,dt\\bigr]\\big ) .",
    "\\nonumber\\end{aligned}\\ ] ] if @xmath416 is a function in the domain of the generator @xmath417 of the semigroup @xmath418 with @xmath419 , then dynkin s formula and the fact that @xmath420 is centred yield @xmath421 = \\ex_b[f(x_{\\tau_m})]\\le \\sup_{x\\in\\bc_m}f(x).\\ ] ] unfortunately , a suitably tight supremum norm estimate for @xmath422 could not be found in the literature .",
    "we therefore proceed differently and make use of the mixing properties of @xmath6 . fix some @xmath423 .",
    "since for @xmath424 the integral over @xmath425 $ ] is smaller than the integral over @xmath426 $ ] , we have @xmath427 & \\le \\delta \\mu_b(c_m)+ \\ex_b\\bigl[\\1_{\\{\\tau_m\\le t-\\delta\\}}\\int_{\\tau_m}^t \\1_{\\{x_t\\in \\bc_m\\}}\\,dt\\bigr].\\end{aligned}\\ ] ]      because of @xmath429\\subset [ ( i-1)\\delta,(i+1)\\delta]$ ] for some @xmath430 we get @xmath431 } \\int_{(i-1)\\delta}^{(i+1)\\delta}\\1_{\\bc_m}(x_s)\\,ds.\\ ] ] set @xmath432 . by separating the bias from the stochastic term , we find @xmath433 } |u_i|,\\ ] ] and by the cauchy - schwarz inequality @xmath434&\\leq \\big(\\sum_{i=1}^{\\lfloor t/\\delta\\rfloor } \\ex_b(u_i^2)\\big)^{\\frac12}=\\lfloor t/\\delta\\rfloor^{1/2}\\operatorname{var}\\bigg(\\int_{0}^{2\\delta}\\1_{\\bc_m}(x_s)\\,ds\\bigg)^{\\frac12}.\\end{aligned}\\ ] ] we conclude by an application of proposition  [ adfunc ] .",
    "we have @xmath436 = \\ex_b\\bigl[\\int_{\\delta}^t\\1_{\\{x_t\\in \\bc_m\\}}\\,\\1_{\\{\\tau_m\\leq t-\\delta\\}}\\,dt\\bigr]\\\\ & = \\mu_b(\\bc_m)\\int_\\delta^t\\pb_b^t(\\tau_m\\leq t-\\delta)\\,dt\\\\ & \\quad + \\int_{\\delta}^t\\ex_b\\bigl[\\big(\\1_{\\bc_m}(x_t)-\\mu_b(\\bc_m)\\big)\\ , \\1_{\\{\\tau_m\\leq t-\\delta\\}}\\bigr]\\,dt.\\end{aligned}\\ ] ] using the markov property of the process @xmath437 and the spectral gap inequality from assumption [ a1 ] , we infer that @xmath438\\\\ & = \\ex_b\\bigl[p_{b,\\delta}(\\1_{\\bc_m}-\\mu_b(\\bc_m))(x_{t-\\delta})\\ , \\1_{\\{\\tau_m\\leq t-\\delta\\}}\\bigr]\\\\ & \\leq \\sqrt{\\ex_b\\bigl[\\big(p_{b,\\delta}(\\1_{\\bc_m}-\\mu_b(\\bc_m))(x_{t-\\delta})\\big)^2\\bigr ] } \\\\ & = \\|p_{b,\\delta}\\1_{\\bc_m}-\\mu_b(\\bc_m)\\|_{\\mu_b}\\leq e^{-\\delta\\rho}\\sqrt{\\mu_b(\\bc_m)}.\\end{aligned}\\ ] ] this inequality completes the proof of the lemma .      note",
    "that @xmath440 is a martingale with quadratic variation matrix @xmath441 .",
    "we obtain that @xmath442=t i_k$ ] with the @xmath257-unit matrix @xmath443 and @xmath444}{(t - t)^2}\\ .\\end{aligned}\\ ] ] let @xmath445 be the diagonal matrix with @xmath446 , @xmath447 , then @xmath448 simple algebra shows that @xmath449 , @xmath450 and @xmath451^d}\\mv(u)\\mv(u)^t\\mu_{b^{\\circ}}(a_m+uh)\\,du.\\ ] ] this matrix is strictly positive definite and @xmath452 tends to zero as @xmath453 .",
    "hence , by the continuity of the matrix inversion we obtain for @xmath134 small enough @xmath454 we conclude that @xmath455 .",
    "set now @xmath456 .",
    "it is easily checked that @xmath457 each entry @xmath458 can be written as @xmath459 , where @xmath416 is a function bounded by @xmath460 and supported by @xmath461 .",
    "thus , a bias - variance decomposition combined with proposition  [ adfunc ] yields @xmath462\\lesssim t^2\\bigg(\\int_{\\bc_m}|\\mu_b(x)-\\mu_{b^{\\circ}}(x)|\\,dx\\bigg)^2+th^d\\psi_d^2(h^d)\\mu_b(\\bc_m).\\ ] ] since in view of remark  [ lowmu ] @xmath463 and @xmath464 are both of order @xmath465 and all norms in @xmath466 are equivalent , we arrive at the desired estimate .",
    "setting @xmath468 , we get @xmath469 in the same way we obtain @xmath470 . substituting all estimates into and ,",
    "we obtain @xmath471 thus choosing @xmath472 we get @xmath473 provided that @xmath474 tends to zero as @xmath82 .",
    "brown , l. d. , cai , t. t. , low , m. g. and zhang , c .- h .",
    ": asymptotic equivalence theory for nonparametric regression with random design .",
    "dedicated to the memory of lucien le cam .",
    "statist . *",
    "30*(3 ) , 688707 ( 2002 )        brown , l. d. and zhao , l. direct asymptotic equivalence of nonparametric regression and the infinite dimensional location problem .",
    "preprint ( 2003 ) , available under http://www-stat.wharton.upenn.edu/@xmath475lzhao/papers ."
  ],
  "abstract_text": [
    "<S> asymptotic local equivalence in the sense of le cam is established for inference on the drift in multidimensional ergodic diffusions and an accompanying sequence of gaussian shift experiments . </S>",
    "<S> the nonparametric local neighbourhoods can be attained for any dimension , provided the regularity of the drift is sufficiently large . </S>",
    "<S> in addition , a heteroskedastic gaussian regression experiment is given , which is also locally asymptotically equivalent and which does not depend on the centre of localisation . </S>",
    "<S> for one direction of the equivalence an explicit markov kernel is constructed .    </S>",
    "<S> * mathematics subject classification ( 2000 ) : * 62b15 , 62g05 , 62g07 , 62g20 , 62m05 . </S>"
  ]
}