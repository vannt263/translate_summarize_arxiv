{
  "article_text": [
    "analyzing whether a time series is stationary or is a non - stationary random walk ( unit root process ) in the sense that the first order differences form a stationary series is an important issue in time series analysis , particularly in econometrics .",
    "often the task is to test the unit root null hypothesis against the alternative of stationarity at a pre - specified @xmath0 level , which ensures that a decision in favor of stationarity is statistically significant .",
    "for instance , the equilibrium analysis of macroeconomic variables as established by granger ( 1981 ) and engle and granger ( 1987 ) defines an equilibrium of two random walks as the existence of stationary linear combination .",
    "when analyzing equilibrium errors of a cointegration relationship , rejection of the null hypothesis in favor of stationarity means that the decision to believe in a valid equilibrium is statistically justified at the pre - specified @xmath1 level . for an approach where cusum based residual tests are employed to test the null hypothesis of cointegration , we refer to xiao and phillips ( 2002 ) .",
    "their test uses residuals calculated from the full sample . in the present article",
    "we study sequential monitoring procedures which aim at monitoring a time series until a time horizon @xmath2 to detect stationarity as soon as possible .",
    "the question whether a time series is stationary or a random walk is also of considerable importance to choose a valid method when analyzing the series to detect trends .",
    "such procedures usually assume stationarity , see steland ( 2004 , 2005a ) , pawlak et al .",
    "( 2004 ) , huskov ( 1999 ) , huskov and slab ( 2001 ) , ferger ( 1993 , 1995 ) , among others . as shown in steland ( 2005b ) ,",
    "when using nadaraya - watson type smoothers to detect drifts the limiting distributions for the random walk case differ substantially from the case of a stationary time series .    to detect changes in a process or",
    "a misspecified model , a common approach originating in statistical quality control is to formulate an in - control model ( null hypothesis ) and an out - of - control model ( alternative ) , and to apply appropriate control charts resp .",
    "stopping times . given a time series @xmath3 a monitoring procedure with time horizon ( maximum sample size ) @xmath2",
    "is given by a stopping time @xmath4 using the convention @xmath5 , where @xmath6 , called _ control statistic _ , is a @xmath7-measurable @xmath8-valued statistic sensitive for the alternatives of interest , and @xmath9 is a measurable set such that @xmath10 has small probability under the null model and high probability under the alternative of interest . in most cases",
    "@xmath11 is of the form @xmath12 or @xmath13 for some given _ control limit _ ( critical value ) @xmath14 . to design monitoring procedures ,",
    "the standard approach is to choose the control limit to ensure that the average run length ( arl ) , @xmath15 , is greater or equal to some pre - specified value .",
    "however , controlling the significance level is a also serious concern .",
    "the results presented in this article can be used to control any characteristic of interest , although we will focus on the type i error in the sequel .    the ( weighted ) dickey - fuller control chart studied in this article",
    "is essentially based on a sequential version of the well - known dickey - fuller ( df ) unit root test , which is motivated by least squares . due to its power properties",
    "this test is very popular , although it is known that its statistical properties strongly depend on a correct specification of the correlation structure of the innovation sequence .",
    "the df test and its asymptotic properties , particularly its non - standard limit distribution have been studied by white ( 1958 ) , fuller ( 1976 ) , rao ( 1978 , 1980 ) , dickey and fuller ( 1979 ) , and evans and savin ( 1981 ) , chan and wei ( 1987 , 1988 ) , phillips ( 1987 ) , among others .",
    "we will generalize some of these results . to ensure quicker detection in case of a change to stationarity",
    ", we modify the df statistic by introducing kernel weights to attach small weights to summands corresponding to past observations .",
    "we provide the asymptotic theory for the related dickey - fuller ( df type ) processes and stopping times , also covering local - to - unity alternatives",
    ".    for correlated error terms the asymptotic distribution of the df test statistic , and hence the control limit of a monitoring procedure , depends on a nuisance parameter , which can be estimated by newey - west type estimators .",
    "we consider two approaches to deal with that problem .",
    "firstly , based on a consistent estimate of the nuisance parameter one may take the asymptotic control limit corresponding to the estimated value .",
    "secondly , following phillips ( 1987 ) one may consider appropriate transformations of the processes possessing limit distributions which no longer dependent on the nuisance parameter .",
    "a nonparametric approach called kpss test which avoids this problem , at least for i(1 ) processes , has been proposed by kwiatkowski et al .",
    "that unit root test has better type i error accuracy , but tends to be less powerful .",
    "monitoring procedures related to this approach and their merits have been studied in detail in steland ( 2006 ) .",
    "the organisation of the paper is as follows . in section  [ secmodel ]",
    "we explain and motivate carefully our assumptions on the time series model , and present the class of dickey - fuller type processes and related stopping times .",
    "the asymptotic distribution theory under the null hypothesis of a random walk is provided in section  [ ash0 ] .",
    "section  [ ash1 ] studies local - to - unity asymptotics , where the asymptotic distribution is driven by an ornstein - uhlenbeck process instead of the brownian motion appearing in the unit root case . finally , in section  [ secsim ] we compare the methods by simulations .",
    "our results work under quite general nonparametric assumptions allowing for dependencies and conditional heteroskedasticity ( garch effects ) , thus providing a nonparametric view on the parametrically motivated approach . to motivate our assumptions , let us consider the following common time series model , which is often used in applications .",
    "suppose at this end that @xmath16 is an ar(@xmath17 ) time series , i.e. , @xmath18 for starting values @xmath19 , where @xmath20 are i.i.d .",
    "error terms ( innovations ) with @xmath21 and @xmath22 , @xmath23 . assume the characteristic polynomial @xmath24 has a unit root , i.e. , @xmath25 , of multiplicity @xmath26 , and all other roots are outside the unit circle , i.e. , @xmath27 implies @xmath28 .",
    "then @xmath29 for some polynomial @xmath30 with has no roots in the unit circle implying that @xmath31 exists for all @xmath32 .",
    "we obtain @xmath33 , where @xmath34 denotes the lag operator .",
    "since @xmath35 can be inverted , we have the representation @xmath36 for coefficients @xmath37 this means , @xmath16 satisfies an ar(@xmath26 ) model with correlated errors . for the calculation of @xmath38",
    "we refer to brockwell and davis ( 1991 , sec . 3.3 . ) in particular , to analyze an ar(@xmath17 ) series for a unit root , one can work with an ar(@xmath26 ) model with correlated errors .",
    "the representation ( [ arpasar1 ] ) motivates the following time series framework which will be assumed in the sequel .",
    "suppose we are given an univariate time series @xmath39 satisfying @xmath40 where @xmath41 $ ] is a fixed but unknown parameter . concerning the error terms",
    "@xmath42 we impose the following assumptions .",
    "* @xmath42 is a strictly stationary series with mean zero and @xmath43 with the following properties : we have @xmath44 and both @xmath42 and @xmath45 satisfy a functional central limit theorem , i.e. , @xmath46 and @xmath47 as @xmath48 , for constants @xmath49 . here",
    "@xmath50 and @xmath51 denote ( standard ) brownian motions ( wiener processes ) with start in @xmath52 .",
    "* @xmath42 is a strong mixing strictly stationary times series with @xmath53 for some @xmath54 , and with mixing coefficients , @xmath55 , satisfying @xmath56    in assumption ( e1 ) and the rest of the paper @xmath57 denotes weak convergence in the space @xmath58 $ ] of all cadlag functions equipped with the skorokhod metric @xmath59 .",
    "the assumption that @xmath42 satisfies an invariance principle can be regarded as a nonparametric definition of the @xmath60 property ensuring that the partial sums converge weakly to a ( scaled ) brownian motion @xmath50 . for",
    "a parametrically oriented definition see stock ( 1994 ) .",
    "particularly , the scale parameter @xmath61 is given by @xmath62 also introduce the notations @xmath63 if the @xmath64 are uncorrelated , we have @xmath65 , and @xmath66 .    as a non - trivial example for processes satisfying ( e1 )",
    "let us consider arch processes .",
    "a time series @xmath67 satisfies arch(@xmath68 ) equations , if there exists a sequence of i.i.d .",
    "non - negative random variables , @xmath69 , such that @xmath70 where @xmath71 , @xmath72 , @xmath73 this model is often applied to model conditional heteroscedasticity of an uncorrelated sequence @xmath42 with @xmath74 for all @xmath75 , by putting @xmath76 .",
    "a common choice for @xmath77 is to assume that the @xmath77 are i.i.d . with common standard normal distribution . in giraitis",
    "et al . ( 2003 ) it has been shown that an unique and strictly stationary solution exists and satisfies @xmath78 , if @xmath79 in addition , under these conditions the functional central limit theorem ( [ fclt2 ] ) holds . the rate of decay of the coefficients @xmath80 controls the asymptotic behavior of @xmath81 . if for some @xmath82 and @xmath83 we have @xmath84 , @xmath85 , then there exists @xmath86 such that @xmath87 for @xmath88 .",
    "thus , depending on the rate of decay ( e2 ) may also holds .",
    "assumption ( e2 ) will be used to verify a tightness criterion . combined with appropriate moment conditions it implies the invariance principles ( [ fclt1 ] ) and ( [ fclt2 ] ) .",
    "we will now introduce the class of dickey - fuller processes and related detection procedures . recall that the least squares estimator of the parameter @xmath89 in model ( [ armodel ] ) is given by @xmath90 to test the null hypothesis @xmath91 , one forms the dickey - fuller ( df ) test statistic @xmath92 suppose at this point that the @xmath64 are uncorrelated . provided @xmath93 ,",
    "@xmath94 as @xmath48",
    ". however , @xmath95 has a different convergence rate and a non - normal limit distribution , if @xmath96 .",
    "it is known that @xmath97 as @xmath48 , see white ( 1958 ) , fuller ( 1976 ) , rao ( 1978 , 1980 ) , dickey and fuller ( 1979 ) , and evans and savin ( 1981 ) . recall that @xmath50 denotes standard brownian motion .",
    "based on that result one can construct a statistical level @xmath0 test , which rejects the null hypothesis @xmath91 of a unit root against the alternative @xmath98 if @xmath99 , where the critical value @xmath14 is the @xmath0-quantile of the distribution of @xmath100 . more generally , we want to construct a detection rule which provides a signal if there is some change - point @xmath101 such that @xmath102 form a random walk ( unit root process ) , and @xmath103 form an @xmath104 with dependent innovations .",
    "this means , the alternative hypothesis is @xmath105 , where @xmath106 , @xmath107 , specifies that @xmath108 where @xmath109 .",
    "however , for the calculation of the detection rule to be introduced now knowledge of a specific alternative hypothesis is not required .",
    "a naive approach to monitor a time series to check for deviations from the unit root hypothesis is to apply the df statistic at each time point using the most recent observations .",
    "a more sophisticated version of this idea is to modify the df statistic to ensure that summands in the numerator have small weight if their time distance to the current time point is large . to define such a detection rule ,",
    "let us introduce the following sequential kernel - weighted dickey - fuller ( df ) process @xmath110,\\ ] ] where @xmath111 . here and in the following we put @xmath112 for convenience .",
    "note that @xmath113 plays the role of the current time point .",
    "the non - negative smoothing kernel @xmath114 is used to attach smaller weights to summands from the distant past to avoid that such summands dominate the sum .",
    "thus , kernels ensuring that @xmath115 , @xmath116 , is decreasing are appropriate , but that property is not required .",
    "we do not use kernel weights in the denominator , since it is used to estimate a nuisance parameter .",
    "we will require the following regularity conditions for @xmath117 .",
    "* @xmath118 , @xmath119 and @xmath120 .",
    "* @xmath121 is @xmath122 with bounded derivative .",
    "* @xmath121 has bounded variation .",
    "note that it is not required to use a kernel with compact support .",
    "the parameter @xmath123 is used as a scaling constant in the kernel and defines the memory of the procedure .",
    "for instance , if @xmath124 if @xmath125 $ ] and @xmath126 otherwise , the process @xmath127 looks back @xmath128 observations .",
    "we will assume that @xmath129 for some @xmath130 .",
    "that condition ensures that the number of observations used by @xmath131 gets larger as @xmath132 increases . note that the parameter @xmath133 , which will also appear in the limit distributions , could be absorbed into the kernel @xmath114 .",
    "however , in practice one usually fixes a kernel @xmath114 and chooses a bandwidth @xmath128 relative to the time horizon @xmath2 .",
    "( [ asszeta ] ) is therefore not restrictive .      since small values of @xmath134",
    "provide evidence for the alternative that the time series is stationary , intuition suggests that the control chart should give a signal if @xmath131 is smaller than a specified control limit @xmath135 .",
    "hence , we define @xmath136 we will assume that the start of monitoring , @xmath137 , is given by @xmath138 a reasonable approach to choose @xmath14 is to control the type i error rate @xmath139 , i.e. , to ensure that @xmath140 where @xmath141 indicates that the probability is calculated assuming that @xmath16 is a random walk corresponding to the null hypothesis @xmath91 .      in the next section we will show that @xmath131 converges weakly to some stochastic process @xmath142 depending on the nuisance parameter @xmath143 and that @xmath144 converges in distribution to @xmath145 : { \\mathcal{d}}_\\vartheta(s ) < c \\ } $ ] . hence ,",
    "if @xmath14 is chosen from the asymptotic distribution via ( [ aslimitalpha ] ) , @xmath146 is a function of @xmath147 .",
    "therefore , the basic idea is to estimate @xmath147 at each time point using only past and current data , and to use the corresponding limit .",
    "our estimator for @xmath147 will be based on a newey - west type estimator , thus circumventing the problem to specify the short memory dynamics of the process explicitly .",
    "let @xmath148 and denote by @xmath149 , @xmath150 , the autocorrelation function of the time series @xmath42 . since @xmath151 if @xmath96 , we can estimate @xmath152 and @xmath153 under the null hypothesis by @xmath154 the parameter @xmath155 can now be estimated by the newey - west estimator given by @xmath156 where @xmath157 are the bartlett weights and @xmath158 is a lag truncation parameter , see newey and west ( 1987 ) . andrews ( 1991 ) studies more general weighting functions and shows that the rate @xmath159 is sufficient for consistency .",
    "the dickey - fuller control chart for correlated time series works now as follows . at each time point",
    "@xmath160 we estimate @xmath147 by @xmath161 and calculate the corresponding estimated control limit @xmath162 .",
    "a signal is given if @xmath131 is less than the estimated control limit , i.e. , we use the rule @xmath163      alternatively , one may use a transformation of @xmath131 , namely @xmath164.\\ ] ] it seems that this transformation idea dates back to phillips ( 1987 ) .",
    "we will show that for arbitrary @xmath147 the process @xmath165 converges weakly to the limit of @xmath131 for @xmath166 .",
    "consequently , if @xmath14 denotes the control limit ensuring that @xmath167 has size @xmath0 when @xmath166 , then the detection rule @xmath168 has asymptotic size @xmath0 for any @xmath147 .    in the next section we shall show that both procedures are asymptotically valid .",
    "inference on the ar parameter in the unit root case is often based on the @xmath160-statistic associated with @xmath131 , which gives rise to dickey - fuller @xmath75-processes .",
    "the dickey - fuller @xmath160-statistic , @xmath169 , associated with @xmath170 , is the standard computer output quantity when running a regression of @xmath171 on @xmath172 . for a sample @xmath173 , the statistic @xmath169 is defined as @xmath174 where @xmath175 with @xmath176 .",
    "the formula for @xmath169 motivates to scale @xmath131 analogously .",
    "hence , let us define the weighted @xmath75-type df process by @xmath177,\\ ] ] and @xmath178 .",
    "@xmath179 is a weighted version of @xmath169 calculated using the observations @xmath180 , and attaching kernel weights @xmath181 to the @xmath182th summand in the numerator .",
    "the associated detection rule for known @xmath147 is defined as @xmath183 with @xmath184 such that @xmath185 .",
    "again , it turns out that the asymptotic limit of @xmath186 depends on the nuisance parameter @xmath147 .",
    "the weighted @xmath75-type df control chart with estimated control limits is defined as @xmath187    alternatively , one can transform the process to achieve that the asymptotic limit is invariant with respect to @xmath147 .",
    "we define @xmath188.\\ ] ] we will show that the detection rule @xmath189 has asymptotic type i error equal to @xmath0 for all @xmath147 .",
    "in this section we provide functional central limit theorems for the dickey - fuller processes defined in the previous section under a random walk model assumption corresponding to the null hypothesis @xmath190 in model ( [ armodel ] ) , and the related central limit theorem for the associated stopping rules .",
    "these results can be used to design tests and detection procedures having well - defined statistical properties under the null hypothesis .",
    "we start with the following functional central limit theorem providing the limit distribution of the weighted df process @xmath191 , @xmath192",
    "$ ] , which extends phillips ( 1987 , th . 3.1 c ) .",
    "[ thbasic ] assume the time series @xmath193 satisfies model ( [ armodel ] ) with @xmath96 such that ( e1 ) and ( k1)-(k3 ) hold",
    ". then @xmath194,d)$},\\ ] ] as @xmath48 , where the stochastic process @xmath195 @xmath196 $ ] , @xmath197 , is continuous w.p . @xmath26 .",
    "note that the asymptotic limit is distribution - free if and only if @xmath198 which holds if the error terms are uncorrelated .",
    "otherwise , the distribution of @xmath142 depends sensitively on @xmath147 .    if @xmath96 we have @xmath151 and @xmath199 for all @xmath160 .",
    "this yields the representation @xmath200,\\ ] ] where the @xmath58 $ ] -valued stochastic processes @xmath201 , @xmath202 , and @xmath203 are given by @xmath204 for @xmath196 $ ] .",
    "let us first show that @xmath205 } | \\widetilde{r}_t(s ) - \\mu(s ) |",
    "\\stackrel{p}{\\to } 0,\\ ] ] as @xmath48 , where @xmath206.\\ ] ] consider @xmath207 ( [ asszeta ] ) ensures that @xmath208 } \\max_i | ( { { \\lfloor ts \\rfloor } } - i)/h - \\zeta(s - i / t ) | = o(1 ) $ ] yielding @xmath209 uniformly in @xmath210 $ ] , because @xmath114 is lipschitz continuous and of bounded variation , cf .",
    "theorem 3.3(ii ) of steland ( 2004 ) .",
    "it remains to estimate @xmath211 .",
    "the assumptions on @xmath42 ensure that @xmath212 as @xmath48 , where @xmath213 .",
    "hence , eventually for equivalent versions , we may assume that @xmath214 a.s .",
    ", for @xmath48",
    ". by ( k3 ) the stieltjes integrals @xmath215 and @xmath216 are well defined ( via integration by parts ) , and @xmath217 } \\left| \\int_0^s k ( \\zeta(s - r ) ) \\ , d z_t(r )   - \\rho \\int_0^s k ( \\zeta(s - r ) ) \\ , d b^{(2)}(r ) \\right|    \\stackrel{a.s.}{\\to } 0,\\ ] ] as @xmath48 . obviously , @xmath218 } | \\widetilde{r}_t(s ) - e \\widetilde{r}_t(s ) |      = \\sup_{s \\in [ \\kappa,1 ] } \\frac{\\sqrt{t } } { { { \\lfloor ts \\rfloor } } } \\left|        \\int_0^s k ( ( { { \\lfloor ts \\rfloor } } - { { \\lfloor tr \\rfloor } } ) /h ) d z_t(r ) \\right| \\\\      & & \\le \\sup_{s \\in [ \\kappa,1 ] } \\frac { \\rho \\sqrt{t } } { { { \\lfloor ts \\rfloor } } }              \\left| b^{(2)}(r ) k\\bigl [ \\frac { { { \\lfloor ts \\rfloor } } - { { \\lfloor tr \\rfloor } } } { h } \\bigr ] \\bigr|_{r=0}^{r = s } - \\int_0^s b^{(2)}(r ) k ( ( { { \\lfloor ts \\rfloor } } - { { \\lfloor t(dr ) \\rfloor } } ) /h )   \\right| \\\\      & & \\quad + \\sup_{s \\in [ \\kappa,1 ] } \\frac { \\sqrt{t } } { { { \\lfloor ts \\rfloor } } }              \\biggl| [ z_t(r ) - \\rho b^{(2)}(r ) ] k ( ( { { \\lfloor ts \\rfloor } } - { { \\lfloor tr \\rfloor } } ) /h              ) \\bigr|_{r=0}^{r = s } \\\\      & & \\qquad \\quad - \\int_0^s [ z_t(r ) - \\rho b^{(2)}(r ) ] k ( ( { { \\lfloor ts \\rfloor } } - { { \\lfloor   t(dr )   \\rfloor } } ) / h )      \\biggr|.\\end{aligned}\\ ] ] noting that the total variation of the functions @xmath219/h ) $ ] , @xmath210 $ ] , @xmath220 , is uniformly bounded , the right side of the above display can be estimated by @xmath221 therefore , ( [ rem1 ] ) holds true .",
    "let us now consider @xmath222 .",
    "we will first show that , up to terms of order @xmath223 , @xmath201 is a functional of @xmath224.\\ ] ] again , under the assumptions of the theorem , @xmath127 converges weakly to @xmath225 , where @xmath50 denotes brownian motion and @xmath226 is a constant . for brevity of notation let @xmath227.\\ ] ] integration by parts yields @xmath228 due to ( k2 ) the @xmath229 term is uniform in @xmath210 $ ] .",
    "next note that @xmath230 we are now in a position to verify joint weak convergence of numerator and denominator of @xmath131 .",
    "the lipschitz continuity of @xmath114 ensures that up to terms of order @xmath229 for all @xmath231 the linear combination @xmath232 is a functional of @xmath127 , and that functional is continuous .",
    "therefore , the continuous mapping theorem ( cmt ) entails weak convergence to the stochastic process @xmath233 \\\\   & & \\quad      + \\lambda_2 \\frac{\\eta^2}{s^2 } \\int_0^s b(r)^2 \\ , dr.\\end{aligned}\\ ] ] this verifies joint weak convergence of @xmath234 .",
    "hence , the result follows by the cmt .",
    "( k2 ) also ensures that @xmath235 $ ] w.p . @xmath26 .    the central limit theorem ( clt ) for the detection procedure @xmath167 , which requires knowledge of @xmath147 , appears as a corollary .",
    "[ corst ] under the assumptions of theorem  [ thbasic ] we have for any control limit @xmath236 @xmath237 : { \\mathcal{d}}_\\vartheta(s ) < c \\}\\ ] ] as @xmath48 , where @xmath238 is defined in ( [ defd ] ) .",
    "observe that by definition of @xmath167 @xmath239 } d_t(s ) \\ge c            \\leftrightarrow \\sup_{s \\in [ \\kappa , x ] } -d_t(s ) \\le -c\\ ] ] for any @xmath240 .",
    "hence it suffices to show that @xmath241 } -d_t(s ) \\le -c )      \\to p ( \\sup_{s \\in [ \\kappa , x ] } -{\\mathcal{d}}_\\vartheta(s ) \\le -c ) , \\ ] ] where @xmath142 denotes the limit process given in theorem  [ thbasic ] .",
    "using the skorokhod / dudley/ wichura representation theorem and a result due to lifshits ( 1982 ) , this fact can be shown along the lines of the proof of theorem  4.1 in steland ( 2004 ) , if @xmath236 , since @xmath235 $ ] a.s .",
    "for brevity we omit the details .",
    "let us now show consistency of the detection procedure @xmath242 , which uses estimated control limits .",
    "[ thestcl ] assume ( e1 ) and ( e2 ) , ( k1)-(k3 ) , and in addition that the lag truncation parameter , @xmath158 , of the newey - west estimator satisfies @xmath243 then the weighted dickey - fuller type control chart with estimated control limit , @xmath244 , is consistent , i.e. , @xmath245 as @xmath48 .    note",
    "that the equivalence @xmath246 } d_t(s ) / c ( \\widehat{\\vartheta } _ { { { \\lfloor ts \\rfloor } } } ) \\ge 1   $ ] implies @xmath247 }        \\frac{d_t(s)}{c ( \\widehat{\\vartheta } _ { { { \\lfloor ts \\rfloor } } } ) } < 1    \\right).\\ ] ] let us first show that the function @xmath248 is continuous . note that the process @xmath238 can be written as @xmath249 for a.s .",
    "continuous processes @xmath250 and @xmath251 not depending on @xmath147 , where particularly @xmath252 and @xmath253.\\ ] ] let @xmath254 be a sequence with @xmath255 , as @xmath256 . clearly , for each @xmath257 of the underlying probability space with @xmath258 , we have @xmath259 @xmath256",
    ". hence , @xmath208 } { \\mathcal{d}}_{\\vartheta_n}(s ) \\stackrel{d}{\\to } \\sup_{s \\in [ \\kappa,1 ] } { \\mathcal{d}}_{\\vartheta^*}(s ) $ ] , as @xmath256 .",
    "since @xmath208 } { \\mathcal{d}}_{\\vartheta^*}(s ) $ ] has a continuous density , this is equivalent to pointwise convergence of the d.f . @xmath260 } { \\mathcal{d}}_{\\vartheta_n}(s ) \\le z ) $ ] to @xmath261 } { \\mathcal{d}}_{\\vartheta^*}(s ) \\le z ) $ ] , as @xmath256 , for all @xmath116 .",
    "hence , @xmath262 as @xmath256",
    ". next we show @xmath263 as @xmath48 , in @xmath264 $ ] . since for each @xmath210 $ ] we have @xmath265 , for @xmath48 ,",
    "fidi convergence follows immediately .",
    "it remains to verify tightness .",
    "recall the definitions ( [ defnw1 ] ) and ( [ defnw2 ] ) and that @xmath266 under @xmath267 . fix @xmath268 and consider the process @xmath269 ,",
    "@xmath210 $ ] , which is a functional of @xmath270 . clearly , by the cauchy - schwarz inequality and ( e1 )",
    "@xmath271 for some @xmath54 .",
    "further , since @xmath272 and @xmath273 , the mixing coefficients @xmath274 of @xmath275 satisfy @xmath276 where @xmath277 are the mixing coefficients of @xmath42 . due to ( e1 ) we can apply yokohama ( 1980 ,  th.1 ) with @xmath278 to conclude that for @xmath279 @xmath280 now the decomposition @xmath281 and the triangle inequality yield @xmath282 since , firstly , we may assume @xmath283 , and , secondly , both @xmath284 and @xmath285 are bounded away from @xmath52 and @xmath286 for @xmath287 . consequently , @xmath288 and therefore vaart and wellner ( 1986 , ex .",
    "2.2.3 ) implies tightness of the process @xmath289 \\ } $ ] for fixed @xmath290 .",
    "note that @xmath291 . by the triangle inequality we have @xmath292",
    "yielding @xmath293 hence , @xmath294 \\ } $ ] is tight in the product space , which implies weak convergence of @xmath295 \\ } $ ] to @xmath296 . the final step is to verify @xmath297 } d_t(s ) / c ( \\widehat{\\vartheta } _ { { { \\lfloor ts \\rfloor } } } )      \\stackrel{d}{\\to } \\inf_{s \\in [ \\kappa,1 ] } { \\mathcal{d}}_\\vartheta(s ) / c ( \\vartheta ) , \\ ] ] as @xmath48 , since this implies that ( [ stern ] ) converges to @xmath298 } { \\mathcal{d}}_\\vartheta(s ) < c(\\vartheta ) ) = \\alpha $ ] , as @xmath48 . due to",
    "( [ wctheta ] ) we can conclude that @xmath299 in the product space @xmath300 ) ^2 $ ] .",
    "note that the mapping @xmath301,d ) ^2 \\to ( { \\mathbb{r } } , { \\mathcal{b } } ) $ ] given by @xmath302 } \\frac{x(s)}{c(y(s ) ) } , \\qquad x , y \\in d[\\kappa,1 ] , \\ y",
    "\\in { \\mathbb{r } } , \\ ] ] is continuous in all @xmath303)^2 $ ] . since @xmath304 $ ] w.p . @xmath26 and @xmath305 , ( [ wc2 ] ) follows .",
    "it remains to provide the related weak convergence results for the transformed process @xmath165 and its natural detection rule @xmath306 .",
    "assume ( e1),(e2 ) , and ( k1)-(k3 ) .",
    "additionally assume that the lag truncation parameter , @xmath158 , of the newey - west estimator satisfies @xmath243 then , @xmath307,d)$}\\ ] ] as @xmath48 , and for the transformed dickey - fuller type control chart we have @xmath308 as @xmath48 .",
    "particularly , the asymptotic distributions are invariant with respect to @xmath147 .    as shown above , @xmath309 as @xmath48 , which implies that @xmath310 if @xmath48 , yielding @xmath311      let us now derive ( functional ) central limit theorems for the weighted dickey - fuller @xmath75-processes and the associated detection rules .",
    "we start with the process @xmath186 under the random walk null hypothesis .",
    "[ thttype ] assume ( e1 ) , and ( k1)-(k3 )",
    ". then @xmath312,d)$}\\ ] ] as @xmath48 , where @xmath313 for @xmath196 $ ] and @xmath314 . here",
    "@xmath316 is continuous a.s .",
    "note that again the limit depends on the nuisance parameter @xmath147 and is distribution - free if and only if @xmath166 .    by definition @xmath317 where @xmath318 with @xmath319 for @xmath196 $ ] .",
    "note that for @xmath320 @xmath321 hence , we obtain @xmath322 from the proof of theorem  [ thbasic ] we know that @xmath323 } { { \\lfloor ts \\rfloor } } ^{-2 } \\sum_{t=1}^ { { { \\lfloor ts \\rfloor } } } y_{t-1}^2      = \\sup_{s \\in ( 0,1 ] } \\left ( \\frac { t } { { { \\lfloor ts \\rfloor } } } \\right)^2          \\int_0^s ( t^{-1/2 } y _ { { { \\lfloor tr \\rfloor } } } ) ^2 \\ , dr = o_p(1)\\ ] ] and @xmath323 } \\left| { { \\lfloor ts \\rfloor } } ^{-1 } \\sum_{t=1}^ { { { \\lfloor ts \\rfloor } } } \\epsilon_t y_{t-1 } \\right|     \\le \\sup_{s \\in ( 0,1 ] } \\left| { { \\lfloor ts \\rfloor } } ^{-1/2 } \\sum_{t=1}^ { { { \\lfloor ts \\rfloor } } } \\epsilon_t \\right|     \\sup_{s \\in ( 0,1 ] } | { { \\lfloor ts \\rfloor } } ^{-1/2 } y _ { { { \\lfloor ts \\rfloor } } } | = o_p(1).\\ ] ] combining these facts with @xmath324 } { { \\lfloor ts \\rfloor } } | \\widehat{\\rho } _ { { { \\lfloor ts \\rfloor } } } - 1 | = o_p(1 ) $ ] , we obtain @xmath325 where the @xmath229 term is uniform in @xmath196 $ ] . because ( e1 ) implies that @xmath326 we may apply the law of large numbers for time series ( brockwell and davis ( 1991 ) , th .",
    "7.1.1 ) and obtain , since stochastic convergence to a constant yields stochastic convergence in the skorokhod topology , @xmath327 as @xmath48",
    ". we shall now show joint weak convergence of @xmath328 , @xmath196 $ ] .",
    "let @xmath329 and consider @xmath330.\\ ] ] the proof of theorem  [ thbasic ] implies that @xmath331 as @xmath48 . due to ( [ convconst ] ) , we obtain @xmath332 as @xmath48 .",
    "therefore , the cmt implies that @xmath333 and @xmath334 as @xmath48 , yielding the assertion .",
    "we are now in the position to establish consistency of the @xmath75-type detection rule @xmath335 which uses estimated control limits .",
    "notice that theorem  [ thttype ] implies that @xmath336 is given by @xmath337 } \\widetilde{{\\mathcal{d}}}_\\vartheta(s ) < c(\\vartheta ) ) = \\alpha $ ] .",
    "assume ( e1),(e2 ) , ( k1)-(k3 ) , and additionally that the lag truncation parameter of the newey - west estimator satisfies @xmath243 then the @xmath75-type weighted dickey - fuller control chart with estimated control limits , @xmath338 , is consistent , i.e. , @xmath339 as @xmath48 .    the result is shown along the lines of the proof of theorem  [ thestcl ] , since the process @xmath316 is continuous w.p .",
    "@xmath26 , and is a continuous function of @xmath147 .    finally , for the transformed process @xmath340 and the associated control chart",
    "@xmath341 we have the following result .",
    "assume ( e1),(e2 ) , ( k1)-(k3 ) , and @xmath243 then the transformed @xmath75-type weighted df process @xmath340 , defined in ( [ deftranst ] ) , converges weakly , @xmath342,d)$},\\ ] ] as @xmath48 , and for the transformed @xmath75-type weighted df control chart we have @xmath343 particularly , the asymptotic distribution is invariant with respect to @xmath147 .",
    "note that the first term of @xmath340 converges weakly to @xmath344 , which has the form @xmath345/ [ \\int_0^s b^2(r ) \\ , dr ] ^{1/2 } $ ] .",
    "hence , the construction of the correction term is as for @xmath165 .",
    "in econometric applications , the stationary alternatives of interest are often of the form @xmath346 with @xmath347 small .",
    "to mimic this situation asymptotically , we consider a local - to - unity model where the ar parameter depends on @xmath132 and tends to @xmath348 , as the time horizon @xmath132 increases .    the functional central limit theorem given below shows that the asymptotic distribution under local - to - unity alternatives is also affected by the nuisance parameter @xmath147 .",
    "however , the term which depends on the parameter parameterising the local alternative does not depend on @xmath147 ( or @xmath349 ) . therefore ,",
    "if one takes the nuisance parameter @xmath147 into account when designing a detection procedure , we obtain local asymptotic power .",
    "let us assume that we are given an array @xmath350 of observations satisfying @xmath351 where the sequence of ar parameters @xmath352 is given by @xmath353 for some constant @xmath354 .",
    "@xmath42 is a mean - zero stationary i(0 ) process satisfying ( e1 ) . for brevity of notation @xmath355",
    "denotes in this section the process ( [ defdt ] ) with @xmath171 replaced by @xmath356",
    ".    the limit distribution will be driven by an ornstein - uhlenbeck process .",
    "recall that the ornstein - uhlenbeck process @xmath357 with parameter @xmath358 is defined by @xmath359,\\ ] ] where @xmath360 denotes brownian motion .",
    "[ thlocalunity ] assume ( e1 ) , and ( k1)-(k3 ) . under the local - to - unity model ( [ localtounity ] ) we have for the weighted dickey - fuller process @xmath361 as @xmath48 , where the a.s .",
    "@xmath362 $ ] -valued process @xmath363 is given by @xmath364 for @xmath196 $ ] , and @xmath365 . here",
    "@xmath366 denotes the ornstein - uhlenbeck process defined in ( [ defou ] ) .",
    "further , @xmath367 : { \\mathcal{d}}_\\vartheta^a(s ) < c \\ } , \\qquad    \\mbox{as $ t \\to \\infty $ } .\\ ] ]    the crucial arguments to obtain _ joint _ weak convergence of numerator and denominator of @xmath127 have been given in detail in the proof of theorem  [ thbasic ] .",
    "therefore , we give only a sketch of the proof stressing the essential differences .",
    "first , note that @xmath368 for the step function @xmath369 , @xmath370 $ ] , which has uniformly bounded variation and converges uniformly in @xmath371 to the exponential @xmath372 .",
    "hence , firstly , the stochastic stieltjes integral @xmath373 exists ( via integration by parts ) , and , secondly , by estimating the terms of the decomposition @xmath374 we see that @xmath375 as @xmath48 .",
    "next , note that in the local - to - unity model we have @xmath376 for all @xmath377 .",
    "this yields the decomposition @xmath378 where for @xmath196 $ ] @xmath379 the term @xmath380 can be treated as in the proof of theorem  [ thbasic ] , namely , @xmath381 from the proof of theorem  [ thbasic ] we know that due to ( e1 ) @xmath382 as @xmath48 .",
    "consider now @xmath383 . by definition of @xmath384",
    "we obtain @xmath385 where due to ( k2 ) the @xmath229 term is uniform in @xmath196 $ ] .",
    "hence , @xmath380 , @xmath383 , and @xmath203 are functionals of @xmath127 up to terms of order @xmath229 .",
    "consequently , joint weak convergence of @xmath386 can be shown along the lines of the proof of theorem  [ thbasic ] , and the cmt yields the result .",
    "to investigate the statistical properties of the proposed monitoring procedure we performed a simulation study .",
    "we used the following arma(1,1 ) simulation model .",
    "suppose @xmath387 where @xmath388 , @xmath389 is a sequence of independent @xmath390-distributed error terms , and @xmath89 and @xmath391 are parameters .",
    "we investigated the cases given by @xmath392 and @xmath393 .",
    "clearly , @xmath394 corresponds to the unit root null hypothesis . for @xmath395",
    "the innovation terms are uncorrelated corresponding to @xmath396 .",
    "this simulation model was also used in steland ( 2006 ) , where a monitoring procedure based on the kpss unit root test is studied in detail . since part of the parameter settings used below",
    "are identical , the results of the present numerical study can be compared with the corresponding results in steland ( 2006 ) .    to study the monitoring rules with estimated control limits critical values for a significance level of @xmath397 were taken from the limit process defined in ( [ defd ] ) with estimated nuisance parameter . to down - weight past contributions a gaussian kernel with bandwidth @xmath398 was used .",
    "the nuisance parameter @xmath147 was estimated by the newey - west estimator at time point @xmath75 with lag truncation parameter @xmath158 chosen by @xmath399 , @xmath400 .",
    "the start of monitoring , @xmath137 , affects the properties and has to be chosen carefully . for the rule @xmath244 we used @xmath401 , whereas for @xmath402 a larger value , @xmath403 , yielded better results .    to investigate the properties of the monitoring rule",
    ", we estimate empirical rejection rates of the test which rejects the unit root null hypothesis if the procedure gives a signal , the average delay , and the average conditional delay given a signal . for the detection rule @xmath244 the arl",
    "is defined by @xmath404 .",
    "we define the carl as @xmath405 .",
    "the definitions for @xmath402 are analogous .",
    "note that the conditional delay is very informative under the alternative , since it informs us how quick the method reacts if it reacts at all . in the tables",
    "average delays are given in brackets and conditional delay in parentheses .",
    "table  [ tab1 ] provides the results for the monitoring procedures @xmath244 and @xmath402 using estimated control limits .",
    "the curves @xmath184 were obtained by simulating from the limit laws .",
    "overall , @xmath406 performed well .",
    "the performance of the @xmath75-type procedure is disappointing .",
    "when inspecting the carl values , the results seem to be mysterious .",
    "e.g. when comparing the carl for @xmath407 and @xmath408 if @xmath409 , the procedure seems to misbehave . to explore the reason , figure  [ fig1 ] provides a part of the distribution of @xmath410 .",
    "it can be seen that the percentage of simulated trajectories leading to immediate detection increases considerably , but the contribution of these cases to the calculation of the carl is negligible .",
    "the other trajectories yielding a signal are hard to detect , and the signals are spread over the remaining time points with many late signals , which suffice to yield large carl values .",
    "this fact shows that a single number as the carl can not summarized the statistical behavior sufficiently .",
    "it highlights the benefit that the random walk null hypothesis can often be rejected very early .",
    "the simulation results for the control charts using transformed statistics are summarized in table  [ tab2 ] .",
    "here we used exact control limits obtained by simulation using 20,000 repetitions .",
    "comparing the transformation control statistics with these control limits yields quite accurate results if @xmath411 .",
    "the @xmath75-type version is preferable for @xmath412 .    comparing the methods @xmath244 ( using estimated control limits ) and @xmath413 ( using transformed statistics ) ,",
    "our results indicate that the more computer - intensive approach to use estimated control limits provides more accurate results .",
    "cccccc @xmath414 & + & @xmath415 & @xmath416 & @xmath417 & @xmath418 & @xmath419 +   +   + @xmath26 & @xmath420 & @xmath421 & @xmath422 & @xmath423 & @xmath424 + @xmath425 & @xmath426 & @xmath427 & @xmath428 & @xmath429 & @xmath430 + & @xmath431 & @xmath432 & @xmath433 & @xmath434 & @xmath435 + & @xmath436 $ ] & @xmath437 $ ] & @xmath438 $ ] & @xmath439 $ ] & @xmath440 $ ] + @xmath441 & @xmath442 & @xmath443 & @xmath444 & @xmath418 & @xmath445 + & @xmath446 & @xmath447 & @xmath448 & @xmath449 & @xmath450 + & @xmath451 $ ] & @xmath452 $ ] & @xmath453 $ ] & @xmath454 $ ] & @xmath455 $ ] + @xmath456 & @xmath457 & @xmath458 & @xmath459 & @xmath460 & @xmath26 + & @xmath461 & @xmath462 & @xmath463 & @xmath464 & @xmath465 + & @xmath466 $ ] & @xmath439 $ ] & @xmath467 $ ] & @xmath468 $ ] & @xmath469 $ ] +   +   + @xmath26 & @xmath470 & @xmath471 & @xmath472 & @xmath473 & @xmath474 + @xmath425 & @xmath475 & @xmath476 & @xmath477 & @xmath478 & @xmath479 + & @xmath480 & @xmath481 & @xmath482 & @xmath483 & @xmath484 + & @xmath485 $ ] & @xmath486 $ ] & @xmath487 $ ] & @xmath488 $ ] & @xmath489 $ ] + @xmath441 & @xmath490 & @xmath420 & @xmath491 & @xmath430 & @xmath26 + & @xmath492 & @xmath493 & @xmath493 & @xmath494 & @xmath495 + & @xmath496 $ ] & @xmath497 $ ] & @xmath498 $ ] & @xmath499 $ ] & @xmath500 $ ] + @xmath456 & @xmath501 & @xmath502 & @xmath503 & @xmath504 & @xmath26 + & @xmath505 & @xmath506 & @xmath492 & @xmath507 & @xmath508 + & @xmath509 $ ] & @xmath510 $ ] & @xmath511 $ ] & @xmath512 $ ] & @xmath513 $ ] +     for @xmath514 ( circles ) and @xmath408 ( crosses).,width=302 ]    cccccc @xmath414 & + & @xmath415 & @xmath416 & @xmath417 & @xmath418 & @xmath419 +   +   + @xmath26 & @xmath515 & @xmath515 & @xmath516 & @xmath517 & @xmath518 + @xmath425 & @xmath519 & @xmath516 & @xmath520 & @xmath521 & @xmath522 + & @xmath523 & @xmath524 & @xmath525 & @xmath526 & @xmath527 + & @xmath528 $ ] & @xmath529 $ ] & @xmath530 $ ] & @xmath531 $ ] & @xmath532 $ ] + @xmath441 & @xmath533 & @xmath534 & @xmath535 & @xmath536 & @xmath537 + & @xmath538 & @xmath538 & @xmath539 & @xmath461 & @xmath540 + & @xmath541 $ ] & @xmath542 $ ] & @xmath543 $ ] & @xmath544 $ ] & @xmath545 $ ] + @xmath456 & @xmath546 & @xmath547 & @xmath548 & @xmath549 & @xmath26 + & @xmath550 & @xmath551 & @xmath552 & @xmath550 & @xmath553 + & @xmath554 $ ] & @xmath555 $ ] & @xmath556 $ ] & @xmath557 $ ] & @xmath558 $ ] +   +   + @xmath26 & @xmath559 & @xmath560 & @xmath561 & @xmath562 & @xmath563 + @xmath425 & @xmath564 & @xmath565 & @xmath566 & @xmath567 & @xmath568 + & @xmath569 & @xmath570 & @xmath494 & @xmath538 & @xmath571 + & @xmath572 $ ] & @xmath573 $ ] & @xmath574 $ ] & @xmath575 $ ] & @xmath576 $ ] + @xmath441 & @xmath577 & @xmath578 & @xmath579 & @xmath580 & @xmath26 + & @xmath581 & @xmath582 & @xmath583 & @xmath584 & @xmath585 + & @xmath586 $ ] & @xmath587 $ ] & @xmath588 $ ] & @xmath589 $ ] & @xmath590 $ ] + @xmath456 & @xmath591 & @xmath592 & @xmath593 & @xmath594 & @xmath26 + & @xmath595 & @xmath596 & @xmath492 & @xmath597 & @xmath508 + & @xmath598 $ ] & @xmath599 $ ] & @xmath600 $ ] & @xmath601 $ ] & @xmath513 $ ] +",
    "the support of deutsche forschungsgemeinschaft ( sfb 475 , _ reduction of complexity in multivariate data structures _ ) is gratefully acknowledged .",
    "i thank dipl .- math .",
    "sabine teller for proof - reading .",
    "kwiatkowski , d. , phillips , p.c.b . ,",
    "schmidt , p. , and shin , y. ( 1992 ) .",
    "testing the null hypothesis of stationary against the alternative of a unit root : how sure are we that economic time series have a unit root ?",
    "_ journal of econometrics _ , * 54 * , 159 - 178 ."
  ],
  "abstract_text": [
    "<S> aiming at monitoring a time series to detect stationarity as soon as possible , we introduce monitoring procedures based on kernel - weighted sequential dickey - fuller ( df ) processes , and related stopping times , which may be called weighted dickey - fuller control charts . under rather weak assumptions , ( functional ) central limit theorems are established under the unit root null hypothesis and local - to - unity alternatives . for general dependent and heterogeneous innovation sequences </S>",
    "<S> the limit processes depend on a nuisance parameter . in this case of practical interest </S>",
    "<S> , one can use estimated control limits obtained from the estimated asymptotic law . </S>",
    "<S> another easy - to - use approach is to transform the df processes to obtain limit laws which are invariant with respect to the nuisance parameter . </S>",
    "<S> we provide asymptotic theory for both approaches and compare their statistical behavior in finite samples by simulation . + </S>",
    "<S> * keywords : * autoregressive unit root , change point , control chart , nonparametric smoothing , sequential analysis , robustness .    weighted dickey - fuller processes for detecting stationarity    ansgar steland + institute of statistics , + rwth aachen university , germany + steland@stochastik.rwth-aachen.de </S>"
  ]
}