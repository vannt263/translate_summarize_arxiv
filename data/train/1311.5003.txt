{
  "article_text": [
    "in theory , scalable quantum computation is possible if errors affecting qubits are not too strongly correlated and occur with a probability below some threshold value @xcite . if the physical error rate is below the threshold , then quantum gates protected by an error - correction code can be arranged in a fault - tolerant manner such that any quantum circuit can be efficiently simulated to any accuracy @xcite .",
    "the precise value of the threshold depends on an interplay between the effective noise in the quantum computer and the structure of the error - correction code in question , as well as the sophistication of the classical processing that accompanies the system @xcite .",
    "recently , the surface code has emerged as a promising candidate for fault - tolerant quantum computation @xcite .",
    "the surface code requires nearest - neighbor gates in two spatial dimensions with physical error rates of roughly one per cent or less , depending on the noise model .",
    "these requirements compare favorably with other codes , which may require non local gates @xcite or may have significantly lower tolerance to errors @xcite . for this reason",
    ", the surface code has underpinned several proposals for quantum computer architectures in a range of physical systems , including superconducting systems , atom - optical systems , trapped ions , quantum dots , and nitrogen - vacancy centers in diamond @xcite .",
    "this article concerns the value of the threshold error rate for the surface code .",
    "previous numerical estimates of the threshold are in general agreement , ranging from 0.57% to 1.40% per gate , depending on various assumptions @xcite",
    ". however , the use of different methods to arrive at these values makes it difficult to faithfully compare them .",
    "the threshold is an important target for experimental devices and , in part , determines the overhead of scalable quantum computation @xcite . given this and considering the increasing relevance of the surface code to the development of quantum computer architectures , it is important to clearly understand how the precise value of the threshold depends on assumptions related to the noise model , measurement circuits , and decoding algorithm .    here , through a series of numerical simulations ,",
    "we investigate how the threshold is affected by these assumptions .",
    "we estimate thresholds for several syndrome measurement circuits under a range of physically motivated noise models . in general , our results highlight the dependency of the threshold on properties of the underlying physical system . in some cases ,",
    "our results indicate that the threshold may be significantly lower than previously thought .",
    "our work complements other recent results concerning the dependency of the threshold on correlated errors caused by the presence of a bosonic bath @xcite and on the effective noise in superconducting quantum circuits @xcite .",
    "notwithstanding the recent development of several alternative decoding algorithms for topological codes @xcite , we restrict ourselves to decoding via edmonds minimum - weight perfect matching algorithm @xcite .",
    "also , we do not consider other topological codes , such as color codes @xcite , instead , referring the interested reader to the recent article of landahl _ et al .  _",
    "@xcite .     where open circles signify data qubits and closed circles signify ancillary qubits . stabilizer generators and logical operators",
    "are indicated .",
    "chains of @xmath0 and @xmath1 errors affecting data qubits will anticommute with the stabilizer generators at the endpoints , which will have eigenvalues equal to @xmath2 as indicated .",
    "end points may be obscured if chains terminate on boundaries .",
    "in general , the number of data qubits is @xmath3 . ]",
    "associated with a vertex where the order of operations is defined in relation to the ancillary qubit at that vertex .",
    "the circuit depth is eight . ]",
    "associated with a face .",
    "the circuit depth is six . ]",
    "the surface code , also known as the planar code , is a variation of kitaev s toric code @xcite .",
    "the toric code is defined over @xmath4 qubits located on the edges of a @xmath5 square lattice embedded on a two - dimensional torus , where @xmath6 is the code distance .",
    "the four - dimensional code space is the simultaneous + 1 eigenspace of the stabilizer generators @xcite , defined as @xmath7 and @xmath8 where @xmath9 is a vertex in the embedding , @xmath10 is a face in the embedding , @xmath11 refers to the four neighboring qubits , and @xmath0 and @xmath1 are the usual single - qubit pauli operators .",
    "the surface code is similarly defined , but its topology is modified from a torus to a two - dimensional plane with boundaries that alternate between open and closed faces . then , the two - dimensional code space encodes a single logical qubit @xcite .",
    "the logical pauli operators are the pair of homologically nontrivial chains of @xmath0 and @xmath1 operators that connect opposite boundaries of the same kind , which preserve the code space , as they commute with the stabilizer generators but act nontrivially on the logical qubit .",
    "although the logical pauli operators can be deformed by the stabilizer generators , their minimum length is always equal to @xmath6 .",
    "the structure of the surface code for @xmath12 is illustrated in fig .",
    "[ surface ] .",
    "universal quantum computation is achieved by manipulating the logical operators , using the techniques developed by raussendorf _",
    "et al .  _",
    "@xcite . by defining a surface code on a plane with a more complicated topology ,",
    "multiple logical qubits are introduced .",
    "the various logical operators are manipulated by deforming the topology of the surface through a series of measurements @xcite . here",
    ", we restrict our study to the case where a surface code encodes a single logical qubit . in particular , we are interested in the active process of quantum error correction , which is used to preserve the quantum information stored in the surface code . since this process is largely unchanged in the presence of additional logical qubits , our results are applicable in general .",
    "pauli errors affecting qubits in the surface code anticommute with a subset of the stabilizer generators . for example",
    ", an @xmath0 error anticommutes with the @xmath1-type stabilizer generators associated with the adjacent vertices , which will have eigenvalues equal to @xmath2 .",
    "connected chains of errors anticommute with the stabilizer generators at the end points of the chains , which may be hidden if the chains terminate on boundaries as shown in fig .",
    "[ surface ] .    in order to identify errors",
    ", we measure the eigenvalues of the stabilizer generators , giving us an error syndrome .",
    "these measurements are performed by introducing ancillary qubits as shown in fig .  [ surface ] and executing the measurement circuits shown in figs .",
    "[ sx ] and [ sz ] .",
    "the circuits require nearest - neighbor gates in two spatial dimensions and can be performed in parallel ( with one circuit for each stabilizer generator ) across the entire surface code . in general , the error syndrome may be unreliable due to errors affecting the ancillary qubits , such as measurement errors . to mitigate this ,",
    "the measurement circuits are repeated @xmath6 times , and we record when a measurement outcome changes from its previous value , which indicates that an error of some kind has occurred . an error affecting",
    "a data qubit will cause a pair of measurements separated in space to change from its previous values , whereas , an error affecting an ancillary qubit will cause a single measurement to change from its previous value and then to immediately change back again . in general , connected chains of errors can involve both kinds of errors , so the end points , indicated by the changing measurement outcomes , may be separated in both space and time .",
    "thus , the error syndrome is the entire space - time volume of these changes .",
    "since errors perturb the state of the system from the code space , error correction involves identifying a set of corrections that will restore the state to the code space while preserving the encoded quantum information .",
    "there are several algorithms to interpret or to decode the error syndrome , which , in general terms , balance accuracy ( having a high likelihood of identifying the correct homology class of the errors ) with efficiency ( capable of decoding the syndrome for large codes in a sufficiently short time ) @xcite . here",
    ", we use a decoding algorithm that identifies the most likely set of errors consistent with the error syndrome where we consider @xmath0 and @xmath1 errors separately @xcite . in the algorithm , each measurement change is represented by a node in a graph .",
    "edges between nodes are weighted to reflect the probability of the associated measurement changes being caused by a connected chain of errors .",
    "a perfect matching of the graph reveals a set of errors consistent with the error syndrome , and the minimum - weight perfect matching reveals the most likely set . from this set",
    ", an appropriate correction can be inferred .",
    "care must be taken to account for correlated errors that arise in the measurement circuits , and edges should be appropriately weighted to account for the fact that different kinds of errors ( which cause different pairs of measurement changes ) may occur with different probabilities @xcite .",
    "our aim is to determine the threshold error rate of the surface code . for physical error rates below this value ,",
    "increasing the code distance ( linearly ) will decrease the logical error rate ( exponentially ) . to determine the logical error rate as a function of the physical error rate , we perform monte carlo simulations . in each instance , a set of errors is generated based on some noise model , the error syndrome is calculated and decoded , a correction is applied , and the resulting homology class is calculated to test for the presence or absence of a logical error . for noise models in which the error syndrome is unreliable , the measurement circuits are repeated @xmath6 times before the error syndrome is decoded . in our simulations ,",
    "minimum - weight perfect matching is performed with kolmogorov s implementation @xcite of edmonds perfect matching algorithm @xcite , and we use a mersenne twister pseudo - random number generator @xcite . for each physical error rate , the logical error rate is an average of approximately @xmath13 independent instances , where we ensure that at least @xmath14 logical errors are observed per point to limit statistical uncertainty .    for a local error model , decoding of the surface code",
    "can be mapped to a three - dimensional random - plaquette gauge model on classical spins where the zero - temperature phase transition corresponds to the threshold error rate @xcite . following wang _",
    "et al .  _",
    "@xcite , the behavior of the logical error rate near the threshold corresponds to critical behavior in the spin model where the spin - correlation length @xmath15 scales according to @xmath16 where @xmath17 is some physical error rate , @xmath18 is the threshold error rate , and @xmath19 is the scaling exponent corresponding to the universality class of the model .",
    "thus , for sufficiently large @xmath6 , the logical error rate @xmath20 should follow @xmath21 allowing for systematic finite - size effects , we fit our data to a quadratic universal scaling function , @xmath22 from which we determine @xmath18 and @xmath19 .",
    "we perform simulations for odd values of @xmath6 between @xmath23 and @xmath24 where @xmath25 .",
    "violations of the scaling ansatz are discernible for the smallest codes such that the minimum code distance for strong agreement between the numerical data and the ansatz appears to be @xmath26 . to account for this ,",
    "values of @xmath18 and @xmath19 are determined from a best fit of the data for @xmath27 . in every case ,",
    "@xmath28 , indicating accurate fitting . when plotting the data in figs .",
    "[ std ] and [ bal ] , the curves for @xmath27 follow the universal scaling function in eq .",
    "( [ scaling ] ) .",
    "data for @xmath29 are included for completeness , however , the corresponding curves are independent polynomial fits that serve only as a guide for the eye .",
    "our results indicate that , for the various circuit - based noise models we consider , which introduce only short - range correlated errors , the value of @xmath19 is consistent with the universality class of the strictly local three - dimensional random - plaquette gauge model @xcite .",
    "the surface code is defined by its hard boundaries .",
    "however , it has been common to , instead , study the threshold of the toric code , which effectively has periodic boundary conditions in two spatial dimensions . here , we present results for the surface code . in this case , the measurement circuits at the boundaries of the surface code are modified to account for the omitted qubits .",
    "this changes their effective error rate from the measurement circuits in the bulk .",
    "however , we will see that the logical error rate rapidly converges to a single value at the threshold as the code distance is increased , indicating that these boundary effects are significant only for the smallest codes .",
    "this suggests that the toric code and the surface code will share the same threshold .",
    "however , because the structure of the logical operators depends on the boundary conditions , the correct boundary conditions should be used when an estimate of the logical error rate is sought for some physical error rate .",
    "lastly , the threshold is sensitive to errors that arise in the measurement circuits , which will , in turn , depend on the set of gates native to the quantum computer .",
    "we consider three cases , which are parametrized by the overall circuit depth :    1 .   _",
    "depth - eight circuits . _",
    "first , we assume the gate set consists of the preparation of state @xmath30 , the single - qubit hadamard rotation , the two - qubit controlled - not gate , and measurement in the @xmath1 basis .",
    "then , referring to the circuits in figs .",
    "[ sx ] and [ sz ] , the overall circuit depth is equal to eight . in this case",
    ", there is an asymmetry between the two measurement circuits with the longer circuit being more unreliable due to the additional gates .",
    "this causes the threshold to split into an @xmath0-error threshold and a @xmath1-error threshold .",
    "2 .   _ depth - six circuits . _",
    "second , we assume that the gate set is extended to include the preparation of state @xmath31 and measurement in the @xmath0 basis .",
    "this removes the need for the hadamard rotations in fig .",
    "[ sx ] , and so , the overall circuit depth is reduced to six .",
    "_ depth - five circuits .",
    "_ third , we assume measurement is nondestructive and prepares the ancillary qubit in a known state ( either @xmath31 and @xmath32 or @xmath30 and @xmath33 , depending on the measurement basis ) .",
    "this allows the measurement and state preparation to be combined , and so , the overall circuit depth is reduced to five .    in each of these cases ,",
    "all measurement circuits are performed in parallel and repeated @xmath6 times where identity gates are inserted whenever qubits are required to be idle . in the first case ,",
    "we give the @xmath1-error threshold , which is the lower of the two thresholds and , therefore , sets the overall threshold . in all other cases",
    ", we give the @xmath0-error threshold .",
    "these thresholds set targets for the high - level gates specified in the circuits , rather than for any lower - level physical operations . also , we have ignored gates that are not required for error correction , but which may be required to achieve universality by distillation @xcite .",
    "we begin with an idealized case in which the error syndrome of the surface code can be measured perfectly .",
    "single - qubit pauli errors are applied to data qubits with probability @xmath17 . in this case",
    ", we are effectively testing the code capacity of the surface code .",
    "because it is perfectly reliable , the error syndrome only needs to be measured once .",
    "this eliminates the timelike aspect of the decoding algorithm , and error correction is reduced to interpreting the error syndrome in two spatial dimensions .",
    "note that this simplified decoding problem can be mapped to the two - dimensional random - bond ising model on classical spins @xcite . for the code capacity noise model ,",
    "we find @xmath34 consistent with wang _",
    "et al .  _",
    "@xcite , who found @xmath35 and @xmath36 .",
    "our threshold is lower than the threshold of @xmath370.109 found for an optimal decoding algorithm @xcite but higher than the threshold of @xmath370.09 found for a renormalization - group decoding algorithm @xcite .",
    "next , we move to a case in which errors can occur on both data and ancillary qubits .",
    "single - qubit pauli errors are applied to all qubits with probability @xmath17 .",
    "this noise model neglects the propagation of errors between data and ancillary qubits in the measurement circuits but captures the essential challenge of fault - tolerant error correction where the process of error correction itself is inherently faulty . in this case",
    ", the full decoding algorithm is required to account for the unreliable error syndrome . for the phenomenological noise model ,",
    "we find @xmath38 again , this is consistent with wang _",
    "et al .  _",
    "@xcite , who found @xmath39 and @xmath40 .",
    "our threshold is lower than the threshold of @xmath370.033 found for an optimal decoding algorithm @xcite but higher than the threshold of @xmath370.0194 found for a renormalization - group decoding algorithm @xcite .",
    "next , we move to a more general noise model , assuming that all gates in the measurement circuits may introduce errors .",
    "this is the most relevant case for fault - tolerant quantum computation , although we note that the particulars of the noise model will depend on the physical system under consideration .",
    "for example , measurements may be slower and less reliable than other gates .",
    "first , we consider a so - called standard noise model .",
    "erroneous single - qubit gates occur with probability @xmath17 , acting ideally followed by a single - qubit pauli error chosen randomly from set @xmath41 .",
    "similarly , erroneous two - qubit gates occur with probability @xmath17 , acting ideally followed by a two - qubit pauli error chosen randomly from set @xmath42 .",
    "lastly , erroneous initialization and measurement each occur with probability @xmath17 , preparing or reporting the incorrect orthogonal eigenstate . under the standard noise model , for the depth - eight circuits , we find @xmath43 for the depth - six circuits , we find @xmath44 and , for the depth - five circuits , we find @xmath45 as shown in fig .",
    "[ std ] .",
    "the standard noise model is somewhat unreasonable as the qubits involved in two - qubit gates are more reliable than idle qubits .",
    "so , next , we consider a so - called balanced noise model , which ensures that idle qubits have the same probability of error as the qubits involved in two - qubit gates and accounts for the fact that measurement is only sensitive to errors in one basis .",
    "specifically , the standard noise model is modified so that erroneous single - qubit gates occur with the probability of @xmath46 and erroneous initialization and measurement occurs with the probability of @xmath47 . under the balanced noise model , for the depth - eight circuits , we find @xmath48 for the depth - six circuits , we find @xmath49 and , for the depth - five circuits , we find @xmath50 as shown in fig .",
    "[ bal ] .      in some physical systems",
    ", single - qubit gates may be significantly faster and more reliable than two - qubit gates . in this case",
    ", the threshold will depend mainly on the two - qubit controlled - not gates in the measurement circuits .",
    "we can approximate this case by modifying the standard noise model so that all single - qubit gates ( including measurement and initialization ) are perfectly reliable . in this case , we find @xmath51      next , we consider the effect of simplifying the decoding algorithm .",
    "following raussendorf _",
    "et al .  _",
    "@xcite , our decoding algorithm accounts for the relative probabilities of errors , including correlated errors , that arise in the measurement circuits .",
    "however , the threshold was previously estimated using a decoding algorithm that ignores these correlated errors @xcite .",
    "this algorithm is also based on minimum - weight matching on a graph , but the weights of edges between nodes are made to equal the rectilinear distance between those nodes , simply reflecting the minimum number of single - qubit pauli errors in a chain connecting the endpoints . without accounting for correlated errors ,",
    "the surface code corrects fewer errors than the code distance implies , negatively affecting its performance , particularly at low error rates .",
    "in fact , for @xmath23 , the code can not reliably correct even a single error . with this simplification , under the standard noise model , for the depth - six circuits , we find @xmath52 fortunately , there is no significant cost to accurately accounting for correlated errors in the surface code .",
    "similar methods exist for accounting for correlated errors in concatenated quantum error correction , also leading to significantly improved performance @xcite .",
    "lastly , we consider an interesting and closely related scheme known as topological cluster - state quantum error correction @xcite . in this scheme , the measurement circuits are simulated by a series of single - qubit measurements on a particular three - dimensional cluster state @xcite",
    ". the scheme may be more practical than the surface code in some physical systems partly due to its elegant tolerance against qubit loss , which was shown by barrett and stace @xcite .",
    "a modified depth - six circuit is required to prepare the cluster state from unentangled qubits and then to measure each qubit in the appropriate basis @xcite .",
    "however , the decoding algorithm is largely unchanged from the algorithm for the surface code . under the standard noise model",
    ", we find @xmath53 and , under the balanced noise model , we find @xmath54    [ cols=\"<,<,<\",options=\"header \" , ]",
    "it is instructive to compare our results with a range of previous estimates of the threshold .",
    "we begin by noting that it is reasonable to expect some slight variation between estimates due to different implementations of the decoding algorithm and the numerical simulations .",
    "nevertheless , for the code capacity and phenomenological noise models , our results are consistent with wang _",
    "_ @xcite . for the remaining circuit - based noise models ,",
    "our results are summarized in table [ thr ] and are compared with a range of previous estimates . of the values that can be directly compared , our results are consistent only with the estimate of the threshold for topological cluster - state error correction due to barrett and stace @xcite . beyond this result",
    ", there is some variation with our thresholds being significantly lower than those previously reported .",
    "this discrepancy appears to be independent of the particular measurement circuit , noise model , and decoding algorithm .    to investigate this discrepancy ,",
    "let us consider the definition of the logical error rate . recall that measurement circuits are repeated to account for the fact that the error syndrome is unreliable .",
    "we define the logical error rate to be the error rate per @xmath6 rounds of measurement , following raussendorf _",
    "et al .  _",
    "this definition reflects the fact that , for a roughly isotropic noise model , @xmath6 rounds are required to achieve the same protection against errors affecting ancillary qubits as against errors affecting data qubits . in other words , if we increase the code distance , then error correction takes more time , which should be accounted for when calculating the logical error rate . on the other hand , the estimates in refs .",
    "@xcite share a different definition ( also see refs .",
    "@xcite ) . according to this definition",
    ", the logical error rate is the error rate per round of measurement ( or , equivalently , the logical error rate per round is reciprocated to give the expected number of rounds until a logical error occurs ) .",
    "note that this definition is independent of the code distance @xmath6 . in both cases , for various code distances ,",
    "the logical error rate is plotted over a range of physical error rates , and the threshold is estimated to be the physical error rate for which these curves intersect .     statistical error .",
    "[ compare with fig .",
    "[ std](c ) . ] ]    let us define the logical error rate to be the error rate per round of measurement as per refs .",
    "@xcite and consider two surface codes with code distances @xmath55 and @xmath56 .",
    "for some physical error rate @xmath57 , the logical error rate of the two codes will be equal .",
    "however , if we fix the physical error rate at @xmath57 and perform @xmath6 rounds of measurement as required , then the larger surface code will be more likely to fail .",
    "in other words , according to this new definition , the two codes are equally reliable , but according to our original definition , the larger code is less reliable .",
    "the latter implies that the threshold is actually at some physical error rate @xmath58 .",
    "if @xmath11 becomes larger , then the relative difference between the two code distances becomes smaller as does the relative difference between their reliability over @xmath6 rounds of measurement .",
    "so , as @xmath59 , we may expect @xmath60 from above .",
    "this would suggest that defining the logical error rate to be the error rate per round of measurement could lead to an overestimate of the threshold .    to test this assertion ,",
    "we return to the depth - five circuits under the standard noise model . figure [ ttf ] shows the logical error rate per round of measurement as a function of the physical error rate for various code distances . as the code distance increases , the physical error rate at which consecutive curves intersect decreases . in particular",
    ", the intersection moves from physical error rates above 0.01 to approximately 0.0095 .",
    "this is roughly consistent with the data in refs .",
    "@xcite , and qualitatively similar behavior can also be seen in refs .",
    "@xcite . in ref .",
    "@xcite , the threshold was estimated to be @xmath61 from the intersection of the @xmath26 and @xmath62 curves , and in ref .",
    "@xcite , the threshold was estimated to be @xmath63 from the intersection of the @xmath64 and @xmath65 curves .",
    "the discrepancy between these two values was attributed to significant boundary effects for @xmath66 .",
    "however , our earlier simulations indicate that boundary effects are negligible for @xmath67 , pointing to another explanation for this behavior .",
    "also , in ref .",
    "@xcite , there appears to be no consistent intersection , even for @xmath68 .",
    "this implies that the threshold is actually lower than 0.009 .",
    "recall that , under the same assumptions , we found @xmath69 as shown in fig .",
    "[ std](c ) . ultimately , given the lack of error analysis in refs .",
    "@xcite , it is difficult to make a conclusive statement about the discrepancy between these estimates and our results .",
    "to summarize , we have performed a series of numerical simulations of the surface code , finding that the value of the threshold error rate varies between 0.502(1)% and 1.140(1)% per gate for typical assumptions made in studies of this kind .",
    "our results highlight the dependency of the threshold on properties of the underlying physical system .",
    "for example , having to perform additional gates to access initialization and measurement in the conjugate basis significantly reduces the threshold .",
    "similarly , the highest thresholds will only be realized if measurements ( in both the @xmath0 and @xmath1 bases ) are nondestructive or if all single - qubit gates are effectively free from noise .",
    "however , in some cases , our results indicate that the threshold may be significantly lower than previously thought .",
    "the target for experimental devices may be lower still , assuming that gates , such as the two - qubit controlled - not gate , will be composed of several physical operations .",
    "the operational error rate must also be sufficiently below the threshold to limit the overhead due to error correction .",
    "lastly , our results indicate that the threshold for topological cluster - state error correction is lower than for the surface code under an identical noise model",
    ". however , like other schemes based on cluster states , this scheme has several desirable properties that may offset this disadvantage in some physical systems , particularly systems with nondeterministic gates or systems significantly affected by qubit loss or leakage .",
    "we have limited ourselves to the question of the threshold for the surface code with decoding via edmonds minimum - weight perfect matching algorithm . naturally , there are many avenues for further work",
    ". given the recent proliferation of alternative decoding algorithms for topological codes , such as the surface code @xcite , it would be valuable to determine circuit - level thresholds for these algorithms , making it easier to understand their practical costs and benefits .",
    "it may also be possible to improve these thresholds by accounting for additional correlations present in some noise models ( for example , the correlation between @xmath0 and @xmath1 errors in depolarizing noise ) @xcite .",
    "comparing these thresholds in a consistent manner will be necessary to draw strong conclusions about the different approaches to error correction in the surface code .",
    "another important open question is the performance of the surface code at error rates well below the threshold . a greater understanding of this regime  including an understanding of how performance is affected by the introduction of additional logical qubits and nontrivial logical gates",
    " will assist in determining the true overhead of scalable quantum computation under various assumptions .",
    "this question was recently addressed by bravyi and vargo for the standard noise model @xcite .",
    "expanding their work to consider a range of noise models and decoding algorithms would be instructive .",
    "lastly , we highlight related schemes for topological quantum error correction against noise models that differ significantly from the typical models considered here . these include schemes to tolerate high rates of qubit loss @xcite and a concatenated code tailored to highly dephasing - biased noise @xcite .",
    "considering other physically motivated noise models may lead to new schemes that could underpin quantum computer architectures in the future ."
  ],
  "abstract_text": [
    "<S> the surface code is a promising candidate for fault - tolerant quantum computation , achieving a high threshold error rate with nearest - neighbor gates in two spatial dimensions . here , through a series of numerical simulations , </S>",
    "<S> we investigate how the precise value of the threshold depends on the noise model , measurement circuits , and decoding algorithm . </S>",
    "<S> we observe thresholds between 0.502(1)% and 1.140(1)% per gate , values which are generally lower than previous estimates . </S>"
  ]
}