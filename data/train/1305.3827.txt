{
  "article_text": [
    "the @xmath6  problem asks if there are three integers @xmath14 summing to @xmath15 in a given set of @xmath1 integers of magnitude @xmath16 .",
    "this problem can be easily solved in time @xmath17 .",
    "( throughout , @xmath18 and @xmath19 hide logarithmic factors . )",
    "it seems natural to believe that this problem also requires time @xmath20 , and this has been confirmed in some restricted models.@xcite the importance of this belief was brought to the forefront by gajentaan and overmars who show that the belief implies lower bounds for a number of problems in computational geometry;@xcite and the list of such reductions has grown ever since . recently ,",
    "a series of exciting papers by baran , demaine , ptracu , vassilevska , and williams set the stage for , and establish , reductions from @xmath6  to new types of problems which are not defined in terms of summation.@xcite in particular , ptracu shows that if we can list @xmath4 triangles in a graph with @xmath4 edges given as adjacency list in time @xmath21 then we can solve @xmath6  in time @xmath22.@xcite    to put this outstanding result in context we briefly review the state - of - the - art on triangle detection and listing algorithms .",
    "all the graphs in this paper are undirected and simple . given the adjacency list of a graph with @xmath4 edges , alon , yuster , and zwick show in @xcite how to determine if it contains a triangle in time @xmath23 where @xmath24 is the exponent of matrix multiplication . if @xmath25 then the bound is @xmath26 .",
    "for listing _ all _ triangles in a graph the best we can hope for is time @xmath27 , since the maximum number of triangles in graphs with @xmath4 edges is @xmath28 .",
    "there are algorithms that achieve time @xmath27 .",
    "( for example , we can first list the @xmath29 triangles going through some node of degree @xmath30 , and then the @xmath31 triangles using nodes of degree @xmath32 only . )",
    "however , to list only @xmath4 triangles conceivably time @xmath33 suffices .",
    "in fact , pagh ( personal communication 2011 ) points out an algorithm for this problem achieving time @xmath34 and , assuming that the exponent of matrix multiplication is @xmath35 , time @xmath36 .      the main result in this paper is a `` reversal '' of ptracu s aforementioned reduction from @xmath6  to listing triangles ,",
    "see corollary [ c - revpatrascu ] below .",
    "in particular , we show that solving @xmath6  in time @xmath37 for some @xmath38 would improve the aforementioned pagh s triangle - listing algorithm .",
    "( recall the latter has complexity @xmath39 assuming @xmath25 . ) before formally stating this result we would like to provide some motivation ( in addition to the obvious one of filling the landscape of reductions ) .",
    "the motivation comes from the study of variants of @xmath6  over other domains such as finite groups .",
    "building on @xcite , the paper @xcite links such variants to the exponential time hypothesis @xcite when the number of summands is `` large , '' in particular , bigger than 3 .",
    "by contrast , we focus on the problem which we call @xmath7  and which is like @xmath6  except that integer summation is replaced with bit - wise xor .",
    "so one can think of @xmath7  as asking if a given @xmath40 matrix over the field with two elements has a linear combination of length @xmath41 .",
    "this problem is likely less relevant to computational geometry , but is otherwise quite natural .",
    "similarly to @xmath0 , @xmath42 can be solved in time @xmath17 , and it seems natural to conjecture that @xmath7  requires time @xmath20 .",
    "but it is interesting to note that if we ask for _ any _ number ( as opposed to @xmath41 ) of elements that sums to @xmath15 the difference in domains translates in a significant difference in complexity : subset - sum is np - hard , whereas subset - xor can be solved efficiently via gaussian elimination . on the other hand ,",
    "subset - xor remains np - hard if the number of elements that need to sum to @xmath15 is given as part of the input.@xcite    in light of this , it would be interesting to relate the complexities of @xmath6  and @xmath7 .",
    "for example , it would be interesting to show that one problem is solvable in time @xmath43 if and only if the other is .",
    "less ambitiously , the weakest possible link would be to exclude a scenario where , say , @xmath6  requires time @xmath44 while @xmath7  is solvable in time @xmath45 .",
    "we are not even able to exclude this scenario , and we raise it as an open problem .",
    "however we manage to spin a web of reductions around @xmath6 , @xmath7 , and various problems related to triangles , a web that extends and complements the pre - existing web .",
    "one consequence is that the only way in which the aforementioned scenario is possible is that listing @xmath4 triangles requires exactly @xmath46 up to lower - order factors .",
    "[ c - weakestlink ] suppose that @xmath6  requires randomized time @xmath44 and @xmath7  is solvable in time @xmath47 , or vice versa .",
    "then , given the adjacency list of a graph with @xmath4 edges and @xmath48 triangles ( and @xmath49 nodes ) , the randomized time complexity of listing @xmath50 triangles is @xmath46 up to a factor @xmath9 for any @xmath10 .",
    "we now overview our reductions .",
    "first we build on and extend a remarkable reduction @xcite by vassilevska and williams from listing triangles to detecting triangles .",
    "their reduction worked on adjacency matrixes , and a main technical contribution of this work is an extension to adjacency lists which is needed in our subquadratic context .",
    "lemmasecondlemmarestate [ lemma - second ] suppose given the adjacency list of a graph with @xmath4 edges and @xmath51 nodes , one can decide if it is triangle - free in time @xmath52 for @xmath53 .",
    "then , given the adjacency list of a graph @xmath54 with @xmath4 edges , @xmath51 nodes and @xmath48 triangles and a positive integer @xmath3 one can list @xmath55 triangles in @xmath54 , in time @xmath56 .    for context , pagh shows a reduction from finding the set of edges involved in some triangle to listing triangles , see @xcite .",
    "next we move to reductions between @xmath6  and detecting triangles .",
    "the paghs @xcite give an algorithm to `` compute the join of three relations [ ... ] where any pair has a common attribute not shared by the third relation . ''",
    "one component of their algorithm can be phrased as a randomized reduction from detecting ( tripartite , directed ) triangles to @xmath6 .",
    "the same reduction works for @xmath7 . here",
    "our main technical contribution is to exhibit a deterministic reduction , relying on the explicit design construction by gutfreund and viola @xcite .",
    "lemmafirstlemmarestate [ lemma - first ] suppose that one can solve @xmath0 or @xmath42 on a set of size @xmath1 in time @xmath57 for @xmath58 .",
    "then , given the adjacency list of a graph with @xmath4 edges , @xmath51 nodes , one can decide if it is triangle - free in time @xmath59 .",
    "in particular , this shows that solving either @xmath6  or @xmath7  in time @xmath60 , where @xmath61 is the exponent of matrix multiplication , would improve the aforementioned triangle - detection algorithm in @xcite .    the combination of the previous two lemmas yields what we mentioned at the beginning of  [ s - our - results ] : a reversal of ptracu s reduction from @xmath6  to listing triangles .",
    "corollarymainthm[reverse ptracu ] [ c - revpatrascu ] suppose that one can solve @xmath0 or @xmath42 on a set of size @xmath1 in time @xmath2 for @xmath62 . then , given the adjacency list of a graph @xmath54 with @xmath4 edges , @xmath51 nodes and @xmath48 triangles a positive integer @xmath3 , one can list @xmath55 triangles in @xmath54 in time @xmath56 .    finally , we re - execute ptracu s reduction for @xmath7  instead of @xmath6 .",
    "our execution also avoids some technical difficulties and so is a bit simpler ; it appeared first in the manuscript @xcite .",
    "theorempatrascuxxx [ t - patrascuxxx ] suppose that given the adjacency list of a graph with @xmath4 edges and @xmath48 triangles ( and @xmath49 nodes ) one can list @xmath50 triangles in time @xmath63 for a constant @xmath62",
    ". then one can solve @xmath42 on a set of size @xmath1 in time @xmath64 with error @xmath65 for a constant @xmath66 .",
    "we now explain how we reduce listing @xmath3 triangles in a graph to detecting triangles .",
    "first we recall the strategy @xcite by vassilevska and williams that works in the setting of adjacency matrixes , as opposed to lists .    without loss of generality",
    ", we work with a tripartite graph with @xmath1 nodes per part . their recursive algorithm proceeds as follows .",
    "first , divide each part in two halves of @xmath67 nodes , then recurse on each of the @xmath68 subgraphs consisting of triples of halves .",
    "note edges are duplicated , but triangles are not .",
    "one uses the triangle - detection algorithm to avoid recursing on subproblems that do not contain triangles .",
    "the most important feature is that one keeps track , throughout the execution of the algorithm , of how many subproblems have been produced , and if this number reaches @xmath3 one stops introducing new subproblems .",
    "we next explain how to extend this idea to adjacency lists . at a high level",
    "we use the same recursive approach based on partitions and keeping track of the total number of subproblems .",
    "however in our setting partitioning is more difficult , and we resort to _ random partitioning_. each part of the graph at hand is partitioned in @xmath35 subsets by flipping an unbiased coin for each node . if we start with a graph with @xmath4 edges , each of the @xmath68 subgraphs ( induced by the @xmath68 triples of subsets ) expects @xmath69 edges .",
    "we would like to guarantee this result with high probability simultaneously for each of the @xmath68 subgraphs .",
    "for this goal we would like to show that the size of each of the @xmath68 subgraphs is concentrated around its expectation .",
    "specifically , fix a subgraph and let @xmath70 be the indicator random variable for edge @xmath71 being in the subgraph .",
    "we would like to show @xmath72 < 1/8 \\hspace{1 cm } ( \\star)\\ ] ] for some small @xmath73 . by a union bound",
    "we can then argue about all the @xmath68 subgraphs simultaneously .",
    "we conclude the proof similarly to @xcite as follows , setting for simplicity @xmath75 .",
    "each recursive step reduces the problem size by a factor @xmath76 .",
    "let @xmath77 be the number of subproblems at level @xmath78 of the recursion .",
    "the running time of the algorithm is of the order of @xmath79 where @xmath80 is the time of the triangle detection algorithm . since we recurse on @xmath81 subproblems we have @xmath82",
    "; since we make sure to never have more than @xmath3 subproblems we have @xmath83 . picking a breaking - point @xmath84 we can write the order of the time as @xmath85 which is minimized to @xmath86 for @xmath87 .",
    "we now discuss how we guarantee @xmath74 .",
    "the obstacle is that the variables @xmath70 are not even pairwise independent ; consider for example two edges sharing a node .",
    "we overcome this obstacle by introducing a first stage in the algorithm in which we list all triangles involving at least one node of high degree ( @xmath88 ) , which only costs time @xmath33 .",
    "we then remove these high - degree nodes .",
    "what we have gained is that now most pairs of variables @xmath89 are pairwise independent .",
    "this lets us carry through an argument like chebychev s inequality and in turn argue about concentration around the expectation @xmath69 .    to obtain a deterministic reduction we choose the partition from an almost 4-wise independent sample space @xcite .    [ [ organization . ] ] organization .",
    "+ + + + + + + + + + + + +    in  [ existtriangle - reducing - to - sss ] we reduce detecting triangles to @xmath6  and @xmath7 . in  [ listingtriangle - reducing - to - existtriangle ] we give the reduction from listing to detecting triangles in a graph . in the appendix , ",
    "[ reducing - xxx - to - listingtriangles ] through  [ s - reducing - to - triangles ] , we give the reduction from @xmath7  to listing triangles . in another section of the appendix ,  [ s-4-clique-6-sum ] , we show how to reduce 4-clique to @xmath90  over the the group @xmath91  thus hinting at a richer web of reductions .",
    "note that corollary [ c - weakestlink ] follows immediately from the combination of : ptracu s reduction from @xmath6  to listing triangles @xcite , our reversal ( corollary [ c - revpatrascu ] ) , and our re - execution for @xmath7  ( theorem [ t - patrascuxxx ] ) .",
    "in this section we prove lemma [ lemma - first ] , restated next .",
    "recall that all graphs in this paper are undirected ( and simple ) .",
    "still , we use ordered - pair notation for edges .",
    "a triangle is a set of @xmath41 distinct edges where each node appears twice , such as @xmath92 .",
    "the deterministic reduction relies on combinatorial designs , family of @xmath4 subsets of a small universe with small pairwise intersections .",
    "specifically we need the size of the sets to be linear in the universe size , and the bound on the intersection a constant fraction of the set size .",
    "such parameters were achieved in @xcite but with a construction running in time exponential in @xmath4 .",
    "we use the different construction computable in time @xmath33 by gutfreund and viola @xcite .",
    "@xcite [ lemma - design ] for every constant @xmath93 and large enough @xmath4 there is a family of @xmath4 sets @xmath94 such that :    \\1 ) @xmath95 ,    \\2 ) @xmath96 for @xmath97 ,    \\3 ) @xmath98 $ ] ,    \\4 ) the family may be constructed in time @xmath33 .",
    "note that by increasing @xmath99 in lemma [ lemma - design ] we can have the bound on the intersection size be an arbitrarily small constant fraction of the set size .",
    "we show how to reduce detecting directed triangles to @xmath6 .",
    "the same approach reduces detecting un - directed triangles to @xmath7  ( except that the numbers below would be considered in base 2 instead of 10 ) . to reduce detecting un - directed triangles to @xmath6",
    ", we can simply make our graphs directed by repeating each edge with direction swapped .",
    "we first review the randomized reduction , then we make it deterministic .",
    "given the adjacency list of graph @xmath100 , assign an @xmath84-bit number , uniformly and independently to each node in the graph @xmath54 , @xmath84 to be determined , i.e. @xmath101 for each edge @xmath102 let @xmath103 .",
    "return the output of @xmath0 on the set @xmath104 . if there is a triangle",
    "there are always 3 elements in @xmath105 summing to @xmath15 . otherwise , by a union bound the probability that there are such 3 elements is @xmath106 for @xmath107 .    to make the reduction deterministic , consider the family @xmath108 of @xmath49 sets from lemma [ lemma - design ] , with intersection size less than 1/5 of the set size .",
    "assign to node @xmath109 the number @xmath110 whose decimal representation has 1 in the digits that belong to @xmath111 , and 0 otherwise .    as before ,",
    "we need to show that if there are 3 numbers @xmath112 and @xmath113 in @xmath105 that sum to @xmath15 then there is a triangle in the graph .",
    "since the graph has no self loops , note that the existence of a triangle is implied by the fact that in the expression @xmath114 each of @xmath115 appears exactly once with each of the two signs .",
    "we will show the latter .",
    "first , we claim that each of @xmath115 appears the same number of times with each sign .",
    "indeed , otherwise write the equation @xmath116 and simplify equal terms .",
    "we are left with a number on one side of the equation that is non - zero in a set of digits that can not be covered by the other 5 , by the properties of the design .",
    "hence the equation can not hold .",
    "note that when performing the sums in this equation there is no carry among decimal digits . finally , we claim that no number can appear twice with the same sign . for else",
    "it is easy to see that there would be a self loop .",
    "in this section we prove lemma [ lemma - first ] again but here we use a deterministic method that avoids the constant error in the previous section .",
    "first we prove the reduction from detecting triangles to @xmath7  and later we make some changes to this reduction to make it work for @xmath6 .",
    "the main idea of the reduction is the same as before .",
    "we assign a number ( @xmath117 ) to each node of the graph ( @xmath118 ) and for each edge ( @xmath119 ) we compute @xmath120",
    ". then we run @xmath42 on the set @xmath104 .",
    "if there are three numbers in @xmath105 that xor to zero then we output that there is a triangle in the graph and otherwise we output the graph is triangle - free .",
    "the main difference is that numbers assigned to nodes are not random .",
    "the @xmath121s are chosen from a carefully constructed set @xmath122 of @xmath123-bit long numbers .",
    "@xmath122 has the property that for every @xmath124 if @xmath125 then you can partition these numbers into 3 pairs such that for every pair @xmath126 you have @xmath127 .",
    "first we show that this property will make sure that our reduction has no error then we give the construction of @xmath122 and show that it has the necessary property .",
    "assume @xmath54 has a triangle @xmath128 , then @xmath129 and we have    @xmath130    therefore the @xmath7  algorithm will return @xmath131 .",
    "now assume @xmath54 is triangle - free but the @xmath7  algorithm returns @xmath131 falsely",
    ". then there are @xmath132 such that @xmath133 by the property of @xmath122 we can partition variables in the above equation into 3 pairs such that @xmath127 and since we assigned distinct numbers to each node we can say that each node appears twice in the above equation .",
    "because @xmath54 is a simple undirected graph with no self - loops , we have discovered a triangle in @xmath54 which contradicts the assumption that @xmath54 is triangle - free .",
    "now we show how to construct @xmath122 .",
    "[ design ] a @xmath134 of size @xmath4 over a universe of size @xmath135 is a family @xmath136 of subsets of @xmath137 $ ] that satisfies : @xmath138 for every @xmath139 and @xmath140 for every @xmath141 .",
    "let us assume that for some @xmath142 , @xmath143 and @xmath144 we have a @xmath145 of size @xmath4 over the universe of size @xmath146 .",
    "consider the characteristic vector of each subset @xmath108 in this family as a binary number in @xmath122 .",
    "we know that for every two subset @xmath108 and @xmath147 in @xmath148 , @xmath149 is strictly less than @xmath150 of the size of the subsets . therefore looking at the characteristic vectors of the two subsets , less than @xmath150 of the positions have @xmath131 in both vectors .",
    "this fact gives @xmath122 the desired property : we can not have the following equation unless every number appears an even number of times .",
    "@xmath151    also note that since the universe is of size @xmath152 every number in @xmath122 is @xmath123 bit long .",
    "we use a lemma proved in [ reference ] to show that we can construct the necessary designs .",
    "[ reference ] [ lemma - design ] for every constant @xmath93 and large enough @xmath4 there is a family of @xmath153 of size @xmath4 over a universe of size @xmath154 .",
    "moreover there is a uniform @xmath155 $ ] circuit of size poly(@xmath156 ) , such that given @xmath157 computes the characteristic vector of @xmath108 .",
    "we need to set @xmath158 so the intersections of any two subset would be strictly less than @xmath150 .",
    "we can set @xmath159 and @xmath160 and by lemma [ lemma - design ] we can construct this design efficiently .    now we show how to reduce detecting triangles to @xmath6 .",
    "we will use the same design we used before and consider the characteristic vector of each subset as a decimal number in @xmath122 . here",
    "@xmath122 has the property that for every @xmath124 if @xmath161 then you can partition these numbers into 3 pairs such that for every pair @xmath126 , @xmath127 and @xmath121 is in the left - hand side of the equation and @xmath162 is in the right - hand side of the equation .",
    "like before , we assign a number @xmath163 to each node of the graph , @xmath118 . for each edge @xmath102 , we compute @xmath164 and @xmath165 .",
    "we run @xmath6  on @xmath166 .",
    "if @xmath6  finds @xmath41 numbers that sum to zero we output @xmath54 has a triangle , otherwise we output that @xmath54 is triangle - free .    using the same argument we used for the reduction to @xmath7  ,",
    "if there are no triangles in @xmath54 the property of @xmath122 will ensure that there will be no @xmath41 numbers in @xmath105 that sum to @xmath15 . on the other hand ,",
    "if @xmath54 has a triangle then our algorithm detects it .",
    "let @xmath167 be a triangle in @xmath54 then @xmath168",
    "in this section we prove lemma [ lemma - second ] , restated next .",
    "let @xmath169 denote the triangle - detection algorithm .",
    "the triangle - listing algorithm is called @xmath170 and has three stages . in stage one ,",
    "we list triangles in @xmath54 involving at least one high degree node . in this part we do not use algorithm @xmath169 . in the second stage",
    ", we create a new graph @xmath171 which is tripartite , and has the property that for each triangle in @xmath54 there uniquely correspond @xmath172 triangles in @xmath171 . in the final stage we run a recursive algorithm on @xmath171 and list @xmath173 triangles in @xmath171 which would correspond to @xmath55 triangles in @xmath54 .",
    "this recursive algorithm will make use of algorithm @xmath169 .    [ [ stage - one . ] ] stage one .",
    "+ + + + + + + + + +    we consider a node to be high degree if its degree is @xmath174 , for a parameter @xmath175 to be set later .",
    "we can list triangles involving a high degree node , if any exists , in time @xmath176 . to see this , note that we can sort the adjacency list and also make a list of high degree nodes in time @xmath177 . also note that the number of nodes with high degree is @xmath178 , because the sum of all degrees is @xmath179 .",
    "for any high degree node @xmath180 , for each edge @xmath181 we search for two edges @xmath182 and @xmath183 in the adjacency list .",
    "since the adjacency list is sorted , the search for each edge will take @xmath184 and for each high degree nodes we do this search @xmath179 times so the running time of stage one is @xmath185 . obviously at any point of this process",
    ", if the number of listed triangles reaches @xmath3 we stop .",
    "if not , we remove the high degree nodes from @xmath54 and move to the next stage .",
    "[ [ stage - two . ] ] stage two .",
    "+ + + + + + + + + +    we convert @xmath54 into a tripartite graph @xmath186 where @xmath187 and each part of @xmath188 is a copy of @xmath189 . for each edge",
    "@xmath190 in @xmath191 place in @xmath192 edge @xmath193 for any @xmath194 .",
    "a triangle in @xmath54 yields @xmath172 in @xmath171 by any choice of the indices @xmath78 and @xmath195 .",
    "a triangle in @xmath171 yields one in @xmath54 by removing the indices , using that the graph is simple .",
    "this stage takes time @xmath196 . in the next stage",
    "we look for @xmath197 triangles in @xmath171 .",
    "note that @xmath198 .",
    "[ [ stage - three . ] ] stage three .",
    "+ + + + + + + + + + + +    we partition each of @xmath199 and @xmath200 of @xmath188 randomly into two subsets , in a way specified below .",
    "now we have 8 subgraphs , where each subgraph is obtained by choosing one subsets from each of @xmath199 and @xmath200 . for each of the subgraphs",
    ", we use @xmath169 to check if the subgraph contains a triangle .",
    "if it does , we recurse on the subgraph .",
    "we recurse till the number of edges in the subgraph is smaller than a constant @xmath201 , at which point by brute force in time @xmath202 we return all the triangles in the subgraph . note that each triangle reported is unique since it only appears in one subproblem .",
    "we only need to list @xmath203 triangles in the graph , so when the number of subproblems that are detected to have at least one triangle reaches @xmath203 , we do not need to introduce more .    to bound the running time",
    ", we need to bound the size of the input for each subproblem .",
    "if the random partition above is selected by deciding uniformly and independently for each node which subset it would be in , the expected number of edges in each subgraph is @xmath69 .",
    "we introduce another parameter @xmath73 and consider the probability that all the @xmath68 subproblems are of size smaller than @xmath204 .",
    "we call these subproblems roughly balanced .    to make the reduction deterministic we choose the partition by an almost @xmath76-wise independent space @xcite .",
    "[ l - almost - indep ] there is an algorithm that maps a seed of @xmath205 bits into @xmath1 bits in time @xmath45 such that the induced distribution on any @xmath206 bits is @xmath207-close to uniform in statistical distance .",
    "claimclaimrestate [ claim-1 ] let @xmath208 .",
    "there are @xmath175 and @xmath207 such that for all sufficiently large @xmath4 , if we partitioning each of @xmath199 and @xmath200 into two subsets using an @xmath207-almost @xmath76-wise independent generator , with probability @xmath209 all the @xmath68 subgraphs induced by triples of subsets have less than @xmath210 edges .",
    "we later give the proof of this claim .",
    "to make sure that all the subproblems generated during the execution of the entire algorithm are roughly balanced , each time we partition we enumerate all seeds for the almost @xmath76-wise independent generator , and pick the first yielding the conclusion of claim [ claim-1 ] .",
    "this only costs @xmath33 time .    to analyze the running time of stage three , let @xmath77 denote the number of subproblems at level @xmath78 of the recursion .",
    "at the @xmath78th level , we run algorithm @xmath169 @xmath77 times on an input of size @xmath211 , so the running time of the recursive algorithm at level @xmath78 is @xmath212 , where @xmath213 is the running time of algorithm @xmath169 .",
    "note that @xmath214 by definition and @xmath215 because at any level we keep at most @xmath203 subproblems .",
    "pick @xmath216 .",
    "the running time of this stage is    @xmath217    @xmath218    the asymptotic growth of each sum is dominated by their value for @xmath219 .",
    "@xmath220    let @xmath221 .",
    "@xmath222    for small enough @xmath73 , @xmath223 , hence : @xmath224    finally the running time of algorithm @xmath170 is @xmath225    let us fix one of the subgraphs and call it @xmath148 and define the following random variables , @xmath226 we have @xmath227 - 1/4| \\le \\alpha $ ] and @xmath228-m/4| \\le \\alpha m$ ] .",
    "to prove the claim , we show that the probability that @xmath148 has more than @xmath210 edges is less than @xmath229 ; and by a union bound we conclude .",
    "in other words we need to show : @xmath230 \\leq 1/16.\\ ] ] by a markov bound we have , @xmath231 & \\leq e\\left[\\left(\\sum_i x_i - m/4\\right)^2\\right]/ \\left(m\\gamma\\right)^2.\\end{aligned}\\ ] ] later we bound @xmath232=o((\\alpha+\\delta)m^2)$ ] from which the claim follows .",
    "now we get the bound for @xmath232 $ ] .",
    "\\sum_i x_i\\right)/2\\right]\\\\ & \\le e\\left[\\sum_{i \\neq j } x_ix_j\\right]+e\\left[\\sum_i x_i^2\\right ] + \\frac{m^2}{16 } - \\frac{m}2 m{\\left ( \\frac14 - \\alpha \\right)}\\\\ & \\le e\\left[\\sum_{i \\neq j } x_ix_j\\right]+\\frac{m}{4 } + \\alpha m -\\frac{m^2}{16 } + m^2 \\alpha/2 \\\\ & = e\\left[\\sum_{i \\neq j } x_ix_j\\right]+ o(\\alpha m^2 ) -\\frac{m^2}{16}.\\end{aligned}\\ ] ] @xmath234 $ ] is the probability that two edges @xmath235 and @xmath236 are both in @xmath148 .",
    "if our distribution were uniform the probability would be @xmath229 for the pairs of edges that do not share a node , and @xmath237 for the pairs of edges that do share a node .",
    "let @xmath238 be the number of unordered pairs of edges that share a node .",
    "we have : @xmath239 = \\sum_{i \\neq j}e\\left[x_ix_j\\right ] \\le 2 \\rho(1/8 + \\alpha ) + 2{\\left ( \\binom{m}{2}-\\rho \\right)}(1/16+\\alpha ) \\\\",
    "\\le m^2/16 + \\rho/8 + 4\\rho \\alpha + \\alpha m^2 \\le m^2/16 + \\rho/8 + o(\\alpha m^2).\\ ] ] note @xmath240 since after stage one of the algorithm there are no nodes with degree more than @xmath241 .",
    "hence we obtain @xmath242 \\leq \\frac{m}4 + o(\\alpha + \\delta)m^2 = o(\\alpha + \\delta)m^2,\\ ] ] as desired .",
    "[ [ acknowledgments . ] ] acknowledgments .",
    "+ + + + + + + + + + + + + + + +    we are very grateful to rasmus pagh and virginia vassilevska williams for answering many questions on finding triangles in graphs .",
    "rasmus also pointed us to @xcite .",
    "we also thank siyao guo for pointing out that a step in a previous proof of lemma [ lemma - listing-3xor - hard ] was useless , and ryan williams for stimulating discussions .",
    "in this section we prove theorem [ t - patrascuxxx ] .",
    "the proof of theorem [ t - patrascuxxx ] follows the one in @xcite for @xmath0 , which builds on results in @xcite .",
    "however the proof of theorem [ t - patrascuxxx ] is a bit simpler .",
    "this is because it avoids some steps in @xcite which are mysterious to us . and because in our context we have at our disposal hash functions that are _ linear _ , while over the integers one has to work with `` almost - linearity , '' cf .",
    "@xcite .",
    "the remainder of this section is organized as follows . in ",
    "[ s - hashing ] we cover some preliminaries and prove a hashing lemma by @xcite that will be used later .",
    "the proof of the reduction in theorem [ t - patrascuxxx ] is broken up in two stages .",
    "first , in  [ s - cxxx ] we reduce @xmath42 to the problem @xmath243 which is a `` convolution '' version of @xmath42 .",
    "then in  [ s - reducing - to - triangles ] we reduce @xmath243 to listing triangles .",
    "we define next the standard hash function we will use .",
    "[ d - hash ] for input length @xmath84 and output length @xmath244 , the hash function @xmath180 uses @xmath244 @xmath84-bit keys @xmath245 and is defined as @xmath246 , where @xmath247 denotes inner product modulo @xmath35 .",
    "we note that this hash function is linear : @xmath248 for any @xmath249 , where addition is bit - wise xor .",
    "also , @xmath250 for any @xmath251 , and @xmath252 \\le 2^{-r}$ ] for any @xmath253 .",
    "before discussing the reductions , we make some remarks on the problem @xmath7 .",
    "first , for simplicity we are going to assume that the input vectors are unique .",
    "it is easy to deal separately with solutions involving repeated vectors .",
    "next we argue that for our purposes the length @xmath84 of the vectors in instances of @xmath7  can be assumed to be @xmath254 . indeed ,",
    "if @xmath255 one can use the fast walsh - hadamard transform to solve @xmath7  efficiently , just like one can use fast fourier transform for @xmath6 , cf .",
    "* exercise 30.1 - 7 ) . for @xmath7  one",
    "gets a running time of @xmath256 , where the first term comes from the fast algorithms to compute the transform , see e.g.  @xcite .",
    "( the second term accounts for preprocessing the input . )",
    "when @xmath255 , the running time is @xmath43 , i.e. , subquadratic .",
    "also , the length can be reduced to @xmath257 via hashing .",
    "specifically , an instance @xmath258 of @xmath7  is reduced to @xmath259 where @xmath260 is the hash function with range of @xmath261 bits for a randomly chosen @xmath251 .",
    "correctness follows because on the one hand if @xmath262 then @xmath263 by linearity of @xmath180 and the fact that @xmath264 always ; on the other hand if @xmath265 then @xmath266 = 1/2^r$ ] since @xmath180 maps uniformly in @xmath267 any non - zero input . hence by a union bound over all @xmath268 choices for vectors such that @xmath265 , the probability of a false positive is @xmath269 .    for the proof",
    "we need to bound the number of elements @xmath270 whose buckets @xmath271 have unusually large load . if our hash function was @xmath41-wise independent the desired bound would follow from chebyshev s inequality .",
    "but our hash function is only pairwise independent , and we do not see a better way than using a hashing lemma from @xcite that in fact relies on a weaker property , cf .  the discussion in @xcite .",
    "when hashing @xmath1 elements to @xmath272 = \\{1,2,\\ldots , r\\}$ ] , the expected load of each bucket is @xmath273 .",
    "the lemma guarantees that the expected number of elements hashing to buckets with a load @xmath274 is @xmath275 .",
    "[ lemma - barandp ] let @xmath180 be a random function @xmath276 $ ] such that for any @xmath253 , @xmath277 \\le 1/r$ ] .",
    "let @xmath148 be a set of @xmath1 elements , and denote @xmath278 .",
    "we have @xmath279 \\le 1/k.\\ ] ] in particular , the expected number of elements from @xmath148 with @xmath280 is @xmath275 .",
    "the proof of the lemma uses the following fact , whose proof is an easy application of the cauchy - schwarz inequality .",
    "[ fact - collision ] let @xmath281 $ ] be a function .",
    "pick @xmath282 independently and uniformly in @xmath283 . then @xmath284 \\ge 1/r$ ] .",
    "pick @xmath282 uniformly and independently in @xmath148 ( @xmath285 possible ) . for given @xmath180 ,",
    "let @xmath286,\\\\ q_h & : = \\pr_{x , y}[h(x ) = h(y)].\\end{aligned}\\ ] ] note we aim to bound @xmath287 \\le 1/k$ ] , while by assumption @xmath288 = \\pr_{h , x , y}[h(x ) = h(y ) ] \\le 1/r + 1/n.\\ ] ]    now let @xmath289 , and note @xmath290 .",
    "let us write @xmath291 \\pr[x \\in l_h ] + \\pr_{x , y}[h(x ) = h(y ) | x \\not \\in l_h ] \\pr[x",
    "\\not \\in l_h].\\ ] ]    the latter summand is @xmath292 .",
    "for the first summand , note @xmath293 \\pr[x \\in l_h ] = \\pr_{x , y}[h(x ) = h(y ) | x \\wedge y \\in l_h ] \\pr[x \\wedge y \\in l_h]\\ ] ] because if @xmath294 then there can not be a collision with @xmath295 .",
    "the term @xmath296 $ ] is @xmath297 by fact [ fact - collision ] .",
    "the term @xmath298 $ ] is @xmath299 .",
    "overall , @xmath300    taking expectations and recalling , @xmath301 k / n + 1/r \\le 1/r + 1/n,\\ ] ] as desired .      define the problem _",
    "convolution @xmath7 _ , denoted @xmath302 , as : given array @xmath169 of @xmath1 strings of @xmath303 bits , determine if @xmath304 + a[j ] = a[i+j]$ ] .",
    "again , sum is bit - wise xor .",
    "[ lemma - xxx - cxxx ] if @xmath302  can be solved with error @xmath65 in time @xmath305 , then so can @xmath42 .",
    "[ [ intuition . ] ] intuition .",
    "+ + + + + + + + + +    we are given an instance of 3xor consisting of a set @xmath148 of @xmath1 vectors .",
    "suppose for any @xmath306 we define @xmath307 : = x$ ] , and untouched elements of @xmath307 $ ] are set randomly so as to never participate in a solution .    now if @xmath308 then @xmath307+a[y ] = a[z ] = a[x+y]$ ] .",
    "using again @xmath308 we get @xmath307+a[y ] = a[x+y]$ ] .",
    "hence this solution will be found in c3xor .",
    "conversely a solution to c3xor corresponds to a 3xor solution , since @xmath169 is filled with elements with @xmath148 ( and random otherwise ) .",
    "this reduction is correct .",
    "but it is too slow because the size of @xmath169 may be too large .    in our second attempt",
    "we try to do as above , but make sure the vector @xmath169 is small .",
    "suppose we had a hash function @xmath309 $ ] that was both 1 - 1 and linear",
    ".    then we could let again @xmath310 : = x$ ] .    if @xmath308 then @xmath310 + a[h(y ) ] = a[h(z)]$ ] by definition . and using again @xmath308 and linearity , we get @xmath311 , and so we get @xmath310 + a[h(y ) ] = a[h(x ) + h(y)]$ ] as desired .",
    "but the problem is that there is no such hash function .",
    "( using linear algebra one sees that there is no hash function that shrinks and is both linear and 1 - 1 . )",
    "the solution is to implement the hash - function based solution , and handle the few collisions separately .",
    "use the hash function @xmath180 from definition [ d - hash ] mapping input elements of @xmath312 bits to @xmath313 bits , for a constant @xmath207 to be determined .",
    "so the range has size @xmath314 . by lemma [ lemma - barandp ] ,",
    "the expected number of elements falling into buckets with more than @xmath315 elements is @xmath316 . for each of these elements , we can easily determine in time @xmath47 if it participates to a solution .",
    "the time for this part is @xmath317 with high probability , by a markov bound .",
    "it remains to look for solutions @xmath318 where the three elements all are hashed to not - overloaded buckets .",
    "for each @xmath319 $ ] , we look for a solution where @xmath320 are respectively at positions @xmath321 of their buckets . specifically , fill an array @xmath169 of size @xmath322 as follows : put the @xmath78th ( @xmath195th , @xmath206th ) element @xmath270 of bucket @xmath323 at position @xmath324 $ ] ( @xmath325 , a[h(x)11]$ ] ) , where @xmath326 denotes the concatenation of the bit - strings @xmath323 and @xmath327 . the untouched elements of @xmath169 are set to a value large enough that it can be easily shown they can not participate in a solution .",
    "run the algorithm for c3xor on @xmath169 .",
    "if there is a solution @xmath318 , suppose @xmath320 are the @xmath78th ( @xmath195th , @xmath206th ) elements of their buckets .",
    "then for that choice of @xmath321 we have @xmath324 = x , a[h(y)10 ] = y , a[h(z)11 ]   = z$ ] , and so @xmath324 + a[h(y)10 ] = a[h(z)11]$ ] .",
    "by linearity of @xmath180 , and the choice of the vectors @xmath328 , we get @xmath329 .",
    "so this solution will be found .",
    "conversely , any solution found will be a valid solution for @xmath330 , by construction of @xmath169 .",
    "the time for this part is as follows .",
    "we run over @xmath331 choices for the indices . for each choice",
    "we run the @xmath243 algorithm on an array of size @xmath322 .",
    "if the time for the latter is @xmath332 , we can pick @xmath333 for a small enough @xmath207 so that the time is @xmath334 .",
    "( here we first amplify the error of the @xmath243 algorithm to @xmath335 by running it @xmath303 times and taking majority . )",
    "the first part only takes time @xmath336 , so overall the time is @xmath337 .",
    "consider the problem dtx of detecting in a weighted graph a triangle whose edge labels xor to @xmath15 .",
    "if dtx , on input an @xmath338 adjacency matrix of a graph on @xmath4 nodes can be solved in time @xmath339 , then c3xor can be solved in time @xmath64 , for some @xmath340 depending only on @xmath341 .    the idea is to reduce c3xor to @xmath342 instances of dtx over tripartite graphs , where each instance hard - wires @xmath343 bits of the @xmath344 bits that specify a solution , and the remaining @xmath345 bits are split up in three chunks of again @xmath343 bits , each chunk corresponding to a part of the graph .    specifically , supposing @xmath346 , write @xmath347 where @xmath348 , @xmath349 are half the @xmath350 bits of @xmath78 .    for each candidate @xmath351 of @xmath135 bits , construct the tripartite graph with parts @xmath352 where each part has @xmath342 nodes , and nodes in @xmath352 represent @xmath353 respectively .",
    "edge weights @xmath354 are : @xmath355 $ ] , + @xmath356 $ ] , + @xmath357 $ ] .    by construction",
    ", any triangle implies a solution .",
    "conversely , let @xmath358 be a solution to @xmath359 . then letting @xmath351 we get a solution to dtx",
    "each graph constructed has an adjacency matrix of size @xmath360 .",
    "if this could be solved in time @xmath361 , then taking into account the guess of @xmath206 we get a total time of @xmath64 .",
    "it is worth mentioning that although lemma [ lemma - xxx - cxxx ] shows that @xmath243 is at least as hard as @xmath42 , we can easily prove that is not any harder than @xmath42 either .",
    "[ lemma - cxxx - xxx ] if @xmath7  can be solved in time @xmath305 , then so can @xmath243 .",
    "let array @xmath169 of @xmath1 elements be the input to @xmath243 , create set @xmath362i\\   | \\",
    "\\forall i \\in [ n]\\}$ ] where @xmath363i$ ] denotes the concatenation of bit - strings of @xmath78 and @xmath364 $ ] .",
    "run @xmath42 on the set @xmath148 .",
    "it is easy to see that if @xmath365    \\text { such that } a[i]+a[j]= a[i+j ] .\\ ] ]    a similar method can be applied to reduce @xmath366 to @xmath0 .",
    "the only difference is in creating the elements of @xmath148 , @xmath3670i\\ |\\ \\forall i \\in [ n]\\}$ ] .",
    "the 0-bit in between @xmath364 $ ] and @xmath78 is to ensure that the ( possible ) final carry of the sum of the indices is not added to the sum of the elements of @xmath169 .",
    "[ lemma - listing-3xor - hard ] suppose that given the adjacency list of a graph with @xmath4 edges and @xmath48 triangles ( and @xmath49 nodes ) one can list @xmath50 triangles in time @xmath63 for a constant @xmath62 .",
    "then one can solve @xmath243 on a set of size @xmath1 with error @xmath65 in time @xmath64 for a constant @xmath66 .",
    "in fact , the hard graph instances will have @xmath368 nodes .",
    "we are given an array @xmath169 and want to know if @xmath369 + a[b ] = a[a+b]$ ] .",
    "it is convenient to work with the equivalent question of the existence of @xmath370 such that @xmath371 + a[a+b_\\ell ] = a[b]$ ] , where @xmath372 are each half the @xmath350 bits of @xmath373 .",
    "we use again the linear hash function @xmath180 . to prove lemma [ lemma - xxx - cxxx ] we hashed to @xmath374 elements .",
    "now we pick @xmath375 . by the paragraph after definition [ d - hash ] , among the @xmath376 pairs @xmath370",
    "that do not constitute a solution ( i.e. , @xmath371 + a[a+b_\\ell ] \\ne a[b])$ ] , we expect @xmath377 of them to satisfy @xmath378 ) + h(a[a+b_\\ell ] ) = h(a[b ] ) \\hspace{2 cm }   ( \\star).\\ ] ]    by a markov argument , with constant probability there are @xmath379 pairs @xmath370 that do not constitute a solution but satisfy @xmath74 .",
    "the reduction works in that case .",
    "( one can amplify the success probability by repetition . )",
    "we set up a graph with @xmath380 edges where triangles are in an easily - computable @xmath381 correspondence with pairs @xmath370 satisfying ( @xmath382 ) .",
    "we then run the algorithm for listing triangles . for each triangle in the list , we check if it corresponds to a solution for @xmath243 .",
    "this works because if the triangle - listing algorithm returns as many as @xmath4 triangles then , by above , at least one triangle corresponds to a correct solution .",
    "hence , if listing can be done in time @xmath383 then @xmath243 can be solved in time @xmath384 .",
    "we now describe the graph .",
    "the graph is tripartite .",
    "one part has @xmath385 nodes of the form @xmath386 ; another has @xmath387 nodes of the form @xmath388 ; and the last part has @xmath1 nodes of the form @xmath389 .",
    "node @xmath389 is connected to @xmath386 if @xmath390 ) = x$ ] , and to @xmath388 if @xmath391 ) = y)$ ] .",
    "nodes @xmath386 and @xmath388 are connected if , letting @xmath392 , @xmath393 ) = x+y$ ] .",
    "we now count the number of edges of the graph .",
    "edges of the form @xmath394 ( or @xmath395 ) number @xmath396 , since @xmath397 determine @xmath270 .",
    "edges @xmath398 number again @xmath396 , since for each @xmath392 and @xmath270 there is exactly one @xmath399 yielding an edge .",
    "the aforementioned 1 - 1 correspondence between solutions to @xmath243 and triangles is present by construction .",
    "in this section we prove the following connection between solving @xmath400  and @xmath90  over the group @xmath91 . although the next lemma is a simple extension of lemma [ lemma - first ] , the fact that the sum is over @xmath91 plays a crucial role in our proof .",
    "we do not see a simple way to carry through the same reduction over @xmath401 or @xmath402 .",
    "lemma4-clique [ lemma-4-clique ] suppose that one can solve @xmath403 on a set of @xmath1 elements over @xmath91 in time @xmath57 for @xmath58 and @xmath404 .",
    "then , given the adjacency list of a graph with @xmath4 edges , @xmath51 nodes , one can decide if it contains a @xmath405 in time @xmath59 .",
    "similar to the proof of lemma [ lemma - first ] , consider the family @xmath108 of @xmath49 sets from lemma [ lemma - design ] , with intersection size less than 1/11 of the set size .",
    "assign to node @xmath109 the number @xmath110 whose decimal representation has 1 in the digits that belong to @xmath111 , and 0 otherwise .",
    "we look at @xmath110 as an element in @xmath91 . for each edge",
    "@xmath102 let @xmath406 .",
    "return the output of @xmath403 on the set @xmath407 . if there is a @xmath405 in the graph",
    ", there are 4 nodes , with an edge between any 2 of them , i.e.,@xmath408 edges .",
    "the elements in @xmath105 corresponding to these 6 edges will sum to 0 .",
    "this is because every node is connected to 3 other nodes and the sum is over @xmath91 .    on the other hand ,",
    "if there are 6 elements @xmath409 and @xmath410 in @xmath105 that sum to @xmath15 , then each element @xmath411 has to appear a multiple of @xmath41 times . to see this , note that smaller than 1/11 intersection between any two subsets in @xmath108 assures that no sum of less than 13 @xmath411 can sum to 0 unless each element appears a multiple of 3 times",
    "if each @xmath411 appears exactly 3 times in the sum of 12 elements , it means we have 4 nodes each one connected to the other 3 i.e. , we have a @xmath405 in the graph .",
    "notice if there is an element @xmath110 that appears 6 times , since the graph does not have self - loops or multiple edges , we can conclude that all the other elements are distinct and appear only once .",
    "we know that the sum of @xmath172 distinct elements over @xmath91 can not be zero ( due to the properties of @xmath108 ) ."
  ],
  "abstract_text": [
    "<S> we show that if one can solve @xmath0 on a set of size @xmath1 in time @xmath2 then one can list @xmath3 triangles in a graph with @xmath4 edges in time @xmath5 . </S>",
    "<S> this is a reversal of ptracu s reduction from @xmath6  to listing triangles ( stoc 10 ) . </S>",
    "<S> our result builds on and extends works by the paghs ( pods 06 ) and by vassilevska and williams ( focs 10 ) . </S>",
    "<S> we make our reductions deterministic using tools from pseudorandomness .    </S>",
    "<S> we then re - execute both ptracu s reduction and our reversal for the variant @xmath7  of @xmath6  where integer summation is replaced by bit - wise xor . as a corollary </S>",
    "<S> we obtain that if @xmath7  is solvable in linear time but @xmath6  requires quadratic randomized time , or vice versa , then the randomized time complexity of listing @xmath4 triangles in a graph with @xmath4 edges is @xmath8 up to a factor @xmath9 for any @xmath10 .    </S>",
    "<S> we introduce the variant @xmath7  of the @xmath6  problem where summation is replaced by bit - wise xor . in an attempt to link the complexities of @xmath7  and  @xmath6 </S>",
    "<S> , we spin a web of reductions around them and various problems related to triangles , extending and complementing the pre - existing web . </S>",
    "<S> our main results are :    \\(1 ) if @xmath6  or @xmath7  on @xmath1 elements is solvable in time @xmath11 then one can detect triangles in graphs with @xmath4 edges in time @xmath12 .    </S>",
    "<S> \\(2 ) if one can detect triangles in graphs with @xmath4 edges in time @xmath12 then one can list @xmath4 triangles in time @xmath13 for any @xmath10 . </S>",
    "<S> this builds on and extends a reduction by vassilevska and williams ( focs 10 ) which works on adjacency matrices instead of lists .    </S>",
    "<S> the combination of ( 1 ) and ( 2 ) yields a reversal of ptracu s reduction from @xmath6  to listing triangles ( stoc 10 ) .    combining ptracu s reduction , our re - execution for @xmath7 , and our reversal yields : if @xmath7  is solvable in linear time but @xmath6  requires quadratic time , or vice versa , then the complexity of listing @xmath4 triangles in a graph with @xmath4 edges is @xmath8 up to a factor @xmath9 for any @xmath10 . </S>"
  ]
}