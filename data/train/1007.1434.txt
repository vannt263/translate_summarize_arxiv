{
  "article_text": [
    "testing whether a subset of covariates have any linear relationship with a quantitative response has been a staple of statistical analysis since fisher introduced the analysis of variance ( anova ) in the 1920s @xcite .",
    "fisher developed anova in the context of agricultural trials and the test has since then been one of the central tools in the statistical analysis of experiments @xcite . as a consequence ,",
    "there are countless situations in which it is routinely used , in particular , in the analysis of clinical trials @xcite or in that of cdna microarray experiments @xcite , to name just two important areas of biostatistics .    to begin with ,",
    "consider the simplest design known as the one - way layout , @xmath9 where @xmath10 is the @xmath11th observation in group @xmath12 , @xmath13 is the main effect for the @xmath12th treatment , and the @xmath14 s are measurement errors assumed to be i.i.d .",
    "zero - mean normal variables .",
    "the goal is of course to determine whether there is any difference between the treatments .",
    "formally , assuming there are @xmath0 groups , the testing problem is @xmath15 the classical one - way analysis of variance is based on the well - known @xmath16-test calculated by all statistical software packages .",
    "a characteristic of anova is that it tests for a _",
    "global _ null and does not result in the identification of which @xmath13 s are nonzero .",
    "taking within - group averages reduces the model to @xmath17 where @xmath18 and the @xmath19 s are independent zero - mean gaussian variables .",
    "if we suppose that the grand mean has been removed , so that the overall mean effect vanishes , that is , @xmath20 , then the testing problem becomes @xmath21 in order to discuss the power of anova in this setting , assume for simplicity that the variances of the error terms in ( [ eqbeta+z ] ) are known and identical , so that anova reduces to a chi - square test that rejects for large values of @xmath22 . as explained before , this test does not identify which of the @xmath23 s are nonzero , but it has great power in the sense that it maximizes the minimum power against alternatives of the form @xmath24 where @xmath25 .",
    "such an appealing property may be shown via invariance considerations ; see @xcite and @xcite , chapters 7 and 8 .",
    "a different approach to the same testing problem is to test each individual hypothesis @xmath26 versus @xmath27 , and combine these tests by applying a bonferroni - type correction .",
    "one way to implement this idea is by computing the minimum @xmath28-value and comparing it with a threshold adjusted to achieve a desired significance level .",
    "when the variances of the @xmath19 s are identical , this is equivalent to rejecting the null when @xmath29 exceeds a given threshold . from now on",
    ", we will refer to this procedure as the max test . because anova is such a well established method",
    ", it might surprise the reader  but not the specialist  to learn that there are situations where the max test , though apparently naive , outperforms anova by a wide margin .",
    "suppose indeed that @xmath30 in ( [ eqbeta+z ] ) and consider an alternative of the form @xmath31 where @xmath32 . in this",
    "setting , anova requires @xmath33 to be at least as large as @xmath34 to provide small error probabilities , whereas the max test only requires @xmath33 to be on the order of @xmath35 .",
    "when @xmath0 is large , the difference is very substantial . later in the paper , we shall prove that in an asymptotic sense , the max test maximizes the minimum power against alternatives of this form .",
    "the key difference between these two different classes of alternatives resides in the kind of configurations of parameter values which make the likelihoods under @xmath36 and @xmath37 very close . for the alternative @xmath38",
    ", the likelihood functions are hard to distinguish when the entries of @xmath39 are of about the same size ( in absolute value ) .",
    "for the other , namely , @xmath40 , the likelihood functions are hard to distinguish when there is a single nonzero coefficient equal to @xmath41 .",
    "multiple hypothesis testing with sparse alternatives is now commonplace , in particular , in computational biology where the data is high - dimensional and we typically expect that only a few of the many measured variables actually contribute to the response  only a few assayed treatments may have a positive effect .",
    "for instance , dna microarrays allow the monitoring of expression levels in cells for thousands of genes simultaneously .",
    "an important question is to decide whether some genes are differentially expressed , that is , whether or not there are genes whose expression levels are associated with a response such as the absence / presence of prostate cancer .",
    "a typical setup is that the data for the @xmath11th individual consists of a response or covariate @xmath42 ( indicating whether this individual has a specific disease or not ) and a gene expression profile @xmath43 , @xmath44 .",
    "a standard approach consists in computing , for each gene @xmath12 , a statistic @xmath45 for testing the null hypothesis of equal mean expression levels and combining them with some multiple hypothesis procedure @xcite .",
    "a possible and simple model in this situation may assume @xmath46 under the null while @xmath47 under the alternative .",
    "hence , we are in our sparse detection setup since one typically expects only a few genes to be differentially expressed . despite the form of the alternative",
    ", anova is still a popular method for testing the global null in such problems .",
    "our exposition has thus far concerned simple designs , namely , the one - way layout or sparse mean model .",
    "this paper , however , is concerned with a much more general problem : we wish to decide whether or not a response depends linearly upon a few covariates . we thus consider the standard linear model @xmath48 with an @xmath49-dimensional response @xmath50 , a data matrix @xmath51 ( assumed to have full rank ) and a noise vector , assumed to be i.i.d .",
    ". the decision problem ( [ eqtest ] ) is whether all the @xmath52 s are zero or not .",
    "we briefly pause to remark that statistical practitioners are familiar with the anova derived @xmath16-statistic  also known as the model adequacy test  that software packages routinely provide for testing @xmath36 .",
    "our concern , however , is not at all model adequacy but rather we view the test of the global null as a detection problem . in plain english , we would like to know whether there is signal or whether the data is just noise .",
    "a more general problem is to test whether a subset of coordinates of @xmath39 are all zero or not , and , as is well known , anova is in this setup the most popular tool for comparing nested models .",
    "we emphasize that our results also apply to such general model comparisons , as we shall see later .",
    "there are many applications of high - dimensional setups in which a response may depend upon only a few covariates .",
    "we give a few examples in the life sciences and in engineering ; there are , of course , many others :    * _ genetics . _",
    "a single nucleotide polymorphism ( snp ) is a form of dna variation that occurs when at a single position in the genome , multiple ( typically two ) different nucleotides are found with positive frequency in the population of reference .",
    "one then collects information about allele counts at polymorphic locations .",
    "almost all common snps have only two alleles so that one records a variable @xmath53 on individual @xmath11 taking values in @xmath54 depending upon how many copies of , say , the rare allele one individual has at location @xmath12 .",
    "one also records a quantitative trait @xmath42 .",
    "then the problem is to decide whether or not this quantitative trait has a genetic background . in order to scan the entire genome for a signal",
    ", one needs to screen between 300,000 and 1,000,000 snps .",
    "however , if the trait being measured has a genetic background , it will be typically regulated by a small number of genes . in this example",
    ", @xmath49 is typically in the thousands while @xmath0 is in the hundreds of thousands .",
    "the standard approach is to test each hypothesis @xmath55 by using a statistic depending on the least - squares estimate @xmath56 obtained by fitting the simple linear regression model @xmath57 the global null is then tested by adjusting the significance level to account for the multiple comparisons , effectively implementing a max test ; see @xcite , for example .",
    "* _ communications .",
    "_ a multi - user detection problem typically assumes a linear model of the form ( [ setting ] ) , where the @xmath12th column of @xmath58 , denoted @xmath59 , is the channel impulse response for user @xmath12 so that the received signal from the @xmath12th user is @xmath60 ( we have @xmath26 in case user @xmath12 is not sending any message ) .",
    "note that the mixing matrix @xmath58 is often modeled as random with i.i.d .",
    "entries . in a strong noise environment",
    ", we might be interested in knowing whether information is being transmitted ( some @xmath23 s are not zero ) or not . in some applications ,",
    "it is reasonable to assume that only a few users are transmitting information at any given time .",
    "standard methods include the matched filter detector , which corresponds to the max test applied to @xmath61 , and linear detectors , which correspond to variations of the anova @xmath16-test @xcite . * _ signal detection . _ the most basic problem in signal processing concerns the detection of a signal @xmath62 from the data @xmath63 where @xmath64 is white noise .",
    "when the signal is nonparametric , a popular approach consists in modeling @xmath62 as a ( nearly ) sparse superposition of waveforms taken from a dictionary @xmath58 , which leads to our linear model ( [ setting ] ) ( the columns of @xmath58 are elements from this dictionary ) .",
    "for instance , to detect a multi - tone signal , one would employ a dictionary of sinusoids ; to detect a superposition of radar pulses , one would employ a time - frequency dictionary @xcite ; and to detect oscillatory signals , one would employ a dictionary of chirping signals . in most cases ,",
    "these dictionaries are massively overcomplete so that we have more candidate waveforms than the number of samples , that is , @xmath65 .",
    "sparse signal detection problems abound , for example the detection of cracks in materials @xcite , of hydrocarbon from seismic data @xcite and of tumors in medical imaging @xcite . *",
    "_ compressive sensing .",
    "_ the sparse detection model may also arise in the area of compressive sensing @xcite , a novel theory which asserts that it is possible to accurately recover a ( nearly ) sparse signal  and by extension , a signal that happens to be sparse in some fixed basis or dictionary  from the knowledge of only a few of its random projections . in this context",
    ", the @xmath66 matrix @xmath58 with @xmath67 may be a random projection such as a partial fourier matrix or a matrix with i.i.d .",
    "entries . before reconstructing the signal",
    ", we might be interested in testing whether there is any signal at all in the first place .",
    "all these examples motivate the study of two classes of sparse alternatives :    _ sparse fixed effects model _ ( _ sfem _ ) . under the alternative",
    ", the regression vector @xmath39 has at least @xmath68 nonzero coefficients exceeding @xmath33 in absolute value .",
    "_ sparse random effects model _",
    "( _ srem _ ) . under the alternative , the regression vector @xmath39 has at least @xmath68 nonzero coefficients assumed to be i.i.d .",
    "normal with zero mean and variance @xmath69 .    in both models",
    ", we set @xmath70 , where @xmath71 is the sparsity exponent .",
    "our purpose is to study the performance of various test statistics for detecting such alternatives . and on the signs of its nonzero entries in sfem .",
    "]      to introduce our results and those of others , we need to recall a few familiar concepts from statistical decision theory . from now on",
    ", @xmath72 denotes a set of alternatives , namely , a subset of @xmath73 and @xmath74 is a prior on @xmath72 .",
    "the bayes risk of a test @xmath75 for testing @xmath76 versus @xmath77 when @xmath36 and @xmath37 occur with the same probability is defined as the sum of its probability of type i error ( false alarm ) and its average probability of type ii error ( missed detection ) .",
    "mathematically , @xmath78,\\ ] ] where @xmath79 is the probability distribution of @xmath80 given by the model ( [ setting ] ) and @xmath81 $ ] is the expectation with respect to the prior @xmath74 .",
    "if we consider the linear model in the limit of large dimensions , that is , @xmath82 and @xmath83 , and a sequence of priors @xmath84 , then we say that a sequence of tests @xmath85 is asymptotically _ powerful _ if @xmath86 .",
    "we say that it is asymptotically _ powerless _ if @xmath87 .",
    "when no prior is specified , the risk is understood as the worst - case risk defined as @xmath88    with our modeling assumptions , anova for testing @xmath76 versus @xmath89 reduces to the chi - square test that rejects for large values of @xmath90 , where @xmath91 is the orthogonal projection onto the range of @xmath58 . since under the alternative , @xmath90 has the chi - square distribution with @xmath92 degrees of freedom and noncentrality parameter @xmath93 , a simple argument shows that anova is asymptotically powerless when @xmath94 and asymptotically powerful if the same quantity tends to infinity .",
    "this is congruent with the performance of anova in a standard one - way layout ; see @xcite , who obtain the weak limit of the anova @xmath16-ratio under various settings .",
    "consider the sparse fixed effects alternative now .",
    "we prove that anova is still essentially optimal under mild levels of sparsity corresponding to @xmath95 $ ] but not under strong sparsity where @xmath96 $ ] . in the sparse mean model ( [ eqbeta+z ] ) where @xmath58 is the identity , anova is suboptimal , requiring @xmath33 to grow as a power of @xmath0 ; this is simply because ( [ anova ] ) becomes @xmath97 when all the nonzero coefficients are equal to @xmath33 in absolute value .",
    "in contrast , the max test is asymptotically powerful when @xmath33 is on the order of @xmath98 but is only optimal under very strong sparsity , namely , for @xmath99 $ ] .",
    "it is possible to improve on the max test in the range @xmath100 and we now review the literature which only concerns the sparse mean model , @xmath101 . set @xmath102 then ingster @xcite showed that if @xmath103 with @xmath104 fixed as @xmath82 , then all sequences of tests are asymptotically powerless . in the other direction , he showed that there is an asymptotically powerful sequence of tests if @xmath105 .",
    "see also the work of jin @xcite .",
    "donoho and jin @xcite analyzed a number of testing procedures in this setting , and , in particular , the higher criticism of tukey which rejects for large values of @xmath106 where @xmath107 denotes the survival function of a standard normal random variable .",
    "they showed that the higher criticism is powerful within the detection region established by ingster .",
    "hall and jin @xcite have recently explored the case where the noise may be correlated , that is , @xmath108 and the covariance matrix @xmath109 is known and has full rank . letting @xmath110",
    "be a cholesky factorization of the covariance matrix , one can whiten the noise in @xmath111 by multiplying both sides by @xmath112 , which yields @xmath113 ; @xmath114 is now white noise , and this is a special case of the linear model ( [ setting ] ) .",
    "when the design matrix is triangular with coefficients decaying polynomially fast away from the diagonal , @xcite proves that the detection threshold remains unchanged , and that a form of higher criticism still achieves asymptotic optimality .",
    "there are few other theoretical results in the literature , among which @xcite develops a locally most powerful ( score ) test in a setting similar to srem ; here , `` locally '' means that this property only holds for values of @xmath115 sufficiently close to zero .",
    "the authors do not provide any minimal value of @xmath115 that would guarantee the optimality of their method . however , since their score test resembles the anova @xmath16-test , we suggest that it is only optimal for very small values of @xmath115 corresponding to mild levels of sparsity , that is , @xmath116 .    since the submission of our paper , a manuscript by ingster , tsybakov and verzelen @xcite , also considering the detection of a sparse vector in the linear regression model , has become publicly available .",
    "we comment on differences in section [ secsparse ] .    in the signal processing literature ,",
    "a number of applied papers consider the problem of detecting a signal expressed as a linear combination in a dictionary @xcite .",
    "however , the extraction of the salient signal is often the end goal of real signal processing applications so that research has focused on estimation rather than pure detection . as a consequence ,",
    "one finds a literature entirely focused on estimation rather than on testing whether the data is just white noise or not .",
    "examples of pure detection papers include @xcite .",
    "in @xcite , the authors consider detection by matched filtering , which corresponds to the max test , and perform simulations to assess its power .",
    "the authors in @xcite assume that @xmath39 is approximately known and examine the performance of the corresponding matched filter .",
    "finally , the paper @xcite proposes a bayesian approach for the detection of sparse signals in a sensor network for which the design matrix is assumed to have some polynomial decay in terms of the distance between sensors .",
    "we show that if the predictor variables are not too correlated , there is a sharp detection threshold in the sense that no test is essentially better than a coin toss when the signal strength is below this threshold , and that there are statistics which are asymptotically powerful when the signal strength is above this threshold .",
    "this threshold is the same as that one gets for the sparse mean problem .",
    "therefore , this work extends the earlier results and methodologies cited above @xcite , and is applicable to the modern high - dimensional situation where the number of predictors may greatly exceed the number of observations .",
    "a simple condition under which our results hold is a low - coherence assumption .",
    "setup , our results apply _ regardless _ of the values of @xmath0 and @xmath49 .",
    "] let @xmath117 be the column vectors of @xmath58 , assumed to be normalized ; this assumption is merely for convenience since it simplifies the exposition , and is not essential",
    ". then if a large majority of all pairs of predictors have correlation less than @xmath118 with @xmath119 for each @xmath120 ( the real condition is weaker ) , then the results for the sparse mean model ( [ eqbeta+z ] ) apply almost unchanged .",
    "interestingly , this is true even when the ratio between the number of observations and the number of variables is negligible , that is , @xmath121 . in particular , @xmath122 is the sharp detection threshold for sfem ( sparse fixed effects model ) .",
    "moreover , applying the higher criticism , not to the values of @xmath80 , but to those of @xmath61 is asymptotically powerful as soon as the nonzero entries of @xmath39 are above this threshold ; this is true for all @xmath123 $ ] .",
    "in contrast , the max test applied to @xmath61 is only optimal in the region @xmath124 $ ] .",
    "we derive the sharp threshold for srem as well , which is at @xmath125 .",
    "we show that the max tests and the higher criticism are essentially optimal in this setting as well for all @xmath123 $ ] , that is , they are both asymptotically powerful as soon as the signal - to - noise ratio permits .    before continuing , it may be a good idea to give a few examples of designs obeying the low - coherence assumption ( weak correlations between most of the predictor variables ) since it plays an important role in our analysis :    * _ orthogonal designs .",
    "_ this is the situation where the columns of @xmath58 are orthogonal so that @xmath126 is the @xmath127 identity matrix ( necessarily , @xmath128 ) . here",
    "the coherence is of course the lowest since @xmath129 . *",
    "_ balanced , one - way designs . _ as in a clinical trial comparing @xmath0 treatments , assume a balanced , one - way design with @xmath130 replicates per treatment group and with the grand mean already removed .",
    "this corresponds to the linear model ( [ setting ] ) with @xmath131 and , since we assume the predictors to have norm  @xmath132 , @xmath133 \\in{\\mathbb{r}}^{n \\times p},\\ ] ] where each vector in this block representation is @xmath130-dimensional .",
    "this is in fact an example of orthogonal design .",
    "note that our results apply even under the standard constraint @xmath134 . * _ concatenation of orthonormal bases .",
    "_ suppose that @xmath135 and that @xmath58 is the concatenation of @xmath130 orthonormal bases in @xmath136 jointly used as to provide an efficient signal representation .",
    "then our result applies provided that @xmath137 and that our bases are mutually incoherent so that @xmath118 is sufficiently small ( for examples of incoherent bases see , e.g. , @xcite ) . *",
    "_ random designs . _ as in some compressive sensing and communications applications , assume that @xmath58 has i.i.d .",
    "normal entries with columns subsequently normalized ( the column vectors are sampled independently and uniformly at random on the unit sphere ) .",
    "such a design is close to orthogonal since @xmath138 with high probability .",
    "this fact follows from a well - known concentration inequality for the uniform distribution on the sphere @xcite .",
    "the exact same bound applies if the entries of @xmath58 are instead i.i.d .",
    "rademacher random variables .",
    "we return to the discussion of our statistics and note that the higher criticism and the max test applied to @xmath61 are exceedingly simple methods with a straightforward implementation running in @xmath139 flops .",
    "this brings us to two important points :    in the classical sparse mean model , bonferroni - type multiple testing ( the max test ) is not optimal when the sparsity level is moderately strong , that is , when @xmath140 @xcite .",
    "this has direct implications in the fields of genetics and genomics where this is the prevalent method .",
    "the same is true in our more general model and it implies , for example , that the matched filter detector in wireless multi - user detection is suboptimal in the same sparsity regime .",
    "we elaborate on this point because this carries an important message .",
    "when the sparsity level is moderately strong , the higher criticism method we propose is powerful in situations where the signal amplitude is so weak that the max test is powerless .",
    "_ this says that one can detect a linear relationship between a response @xmath80 and a few covariates even though those covariates that are most correlated with @xmath80 are not even in the model .",
    "_ put differently , if we assign a @xmath28-value to each hypothesis @xmath26 ( computed from a simple linear regression as discussed earlier ) , then _ the case against the null is not in the tail of these @xmath28-values but in the bulk _",
    ", that is , the smallest @xmath28-values may not carry any information about the presence of a signal .",
    "in the situation we describe , the smallest @xmath28-values most often correspond to true null hypotheses , sometimes in such a way that the false discovery rate ( fdr ) can not be controlled at any level below 1 ; and yet , the higher criticism has full power .",
    "though we developed the idea independently , the higher criticism applied to @xmath61 is similar to the innovated higher criticism of hall and jin @xcite , which is specifically designed for time series .",
    "not surprisingly , our results and arguments bear some resemblance with those of hall and jin @xcite .",
    "we have already explained how their results apply when the design matrix is triangular ( and , in particular , square ) and has sufficiently rapidly decaying coefficients away from the diagonal .",
    "our results go much further in the sense that ( 1 ) they include designs that are far from being triangular or even square , and ( 2 ) they include designs with coefficients that do not necessarily follow any ordered decay pattern",
    ". on the technical side , hall and jin astutely reduce matters to the case where the design matrix is banded , which greatly simplifies the analysis . in the general linear model ,",
    "it is not clear how a similar reduction would operate especially when @xmath141at the very least , we do not see a way  and one must deal with more intricate dependencies in the noise term @xmath142 .    as we have remarked earlier , we have discussed testing the global null @xmath76 , whereas some settings obviously involve nuisance parameters as in the comparison of nested models .",
    "examples of nuisance parameters include the grand mean in a balanced , one - way design or , more generally , the main effects or lower - order interactions in a multi - way layout . in signal processing ,",
    "the nuisance term may represent clutter as opposed to noise .",
    "in general , we have @xmath143 where @xmath144 is the vector of nuisance parameters , and @xmath145 the vector we wish to test .",
    "our results concerning the performance of anova , the higher criticism or the max test apply provided that the column spaces of @xmath146 and @xmath147 be sufficiently far apart .",
    "this occurs in lots of applications of interest . in the case of the balanced , multi - way design , these spaces",
    "are actually orthogonal . in signal processing , these spaces will also be orthogonal if the column space of @xmath146 spans the low - frequencies while we wish to detect the presence of a high - frequency signal .",
    "the general mechanism which allows us to automatically apply our results is to simply assume that @xmath148 , where @xmath149 is the orthogonal projector with the range of @xmath146 as null space , obeys the conditions we have for @xmath58 .",
    "the paper is organized as follows . in section  [ secortho ]",
    "we consider orthogonal designs and state results for the classical setting where no sparsity assumption is made on the regression vector @xmath39 , and the setting where @xmath39 is mildly sparse . in section [ secsparse ]",
    "we study designs in which _ most _ pairs of predictor variables are only weakly correlated ; this part contains our main results . in section [ secfull ]",
    "we focus on some examples of designs with full correlation structure , in particular , multi - way layouts with embedded constraints .",
    "section [ secnumerics ] complements our study with some numerical experiments , and we close the paper with a short discussion , namely , section [ secdiscussion ] .",
    "finally , the proofs are gathered in a supplementary file @xcite .",
    "we provide a brief summary of the notation used in the paper .",
    "set @xmath150 = \\{1,\\ldots , p\\}$ ] and for a subset @xmath151 $ ] , let @xmath152 be its cardinality .",
    "bold upper ( resp .",
    ", lower ) case letters denote matrices ( resp .",
    ", vectors ) , and the same letter not bold represents its coefficients , for example , @xmath153 denotes the @xmath12th entry of @xmath154 . for an @xmath66 matrix @xmath155 with column vectors @xmath156 , and a subset @xmath151 $ ] , @xmath157 denotes the @xmath49-by-@xmath152 matrix with column vectors @xmath158 .",
    "likewise , @xmath159 denotes the vector @xmath160 .",
    "the euclidean norm of a vector is @xmath161 and the sup - norm @xmath162 . for a matrix @xmath163 , @xmath164 , and",
    "this needs to be distinguished from @xmath165 , which is the operator norm induced by the sup norm , @xmath166 .",
    "the frobenius ( euclidean ) norm of @xmath155 is @xmath167 .",
    "@xmath168 ( resp . , @xmath169 ) denotes the cumulative distribution ( resp .",
    ", density ) function of a standard normal random variable , and @xmath107 its survival function . for brevity",
    ", we say that @xmath39 is @xmath68-sparse if @xmath39 has exactly @xmath68 nonzero coefficients .",
    "finally , we say that a random variable @xmath170 is stochastically smaller than @xmath171 , denoted @xmath172 , if @xmath173 for all scalar @xmath174 .",
    "this section introduces some results for the orthogonal design in which the columns of @xmath58 are orthonormal , that is , @xmath175 .",
    "while from the analysis viewpoint there is little difference with the case where @xmath58 is the identity matrix , this is of course a special case of our general results , and this section may also serve as a little warm - up . our first result , which is a special case of proposition [ prpmoderate - lb ] , determines the range of sparse alternatives for which anova is essentially optimal .    [ prpmoderate ]",
    "suppose @xmath58 is orthogonal and let the number of nonzero coefficients be @xmath176 with @xmath95 $ ] .",
    "in sfem ( resp . , srem ) , all sequences of tests are asymptotically powerless if @xmath177 ( resp.,@xmath178 ) .",
    "returning to our earlier discussion , it follows from ( [ anova ] ) and the lower bound @xmath179 that anova has full asymptotic power whenever @xmath180 .",
    "therefore , comparing this with the content of proposition [ prpmoderate ] reveals that anova is essentially optimal in the moderately sparse range corresponding to @xmath95 $ ] .",
    "the second result of this section is that under an @xmath66 orthogonal design , the detection threshold is the same as if @xmath58 were the identity .",
    "we need a little bit of notation to develop our results . as in @xcite , define @xmath181 and observe that with @xmath182 as in ( [ eqthreshold ] ) , @xmath183 we will also set a detection threshold for srem defined by @xmath184 with these definitions , the following theorem compares the performance of the higher criticism and the max test .",
    "[ thmortho ] suppose @xmath58 is orthogonal and assume the sparsity exponent obeys @xmath96 $ ] .    in sfem ,",
    "all sequences of tests are asymptotically powerless if @xmath103 with @xmath104 .",
    "conversely , the higher criticism applied to @xmath185 is asymptotically powerful if @xmath105 . also , the max test is asymptotically powerful if @xmath186 and powerless if @xmath187 .    in srem ,",
    "all sequences of tests are asymptotically powerless if @xmath188 .",
    "conversely , both the higher criticism and the max test applied to @xmath189 .    in the upper bounds , @xmath190 and @xmath115 are fixed while @xmath82 .    to be absolutely clear",
    ", the statements for sfem may be understood either in the worst - case risk sense or under the uniform prior on the set of @xmath68-sparse vectors with nonzero coefficients equal to @xmath191 . for srem ,",
    "the prior simply selects the support of @xmath39 uniformly at random . after multiplying the observation by @xmath192 ,",
    "matters are reduced to the case of the identity design for which the performance of the higher criticism and the max test have been established in sfem @xcite .",
    "the result for the sparse random model is new and appears in more generality in theorem [ thmmax ] .    to conclude , the situation concerning orthogonal designs is very clear . in sfem , for instance , if the sparsity level is such that @xmath193 , then anova is asymptotically optimal whereas the higher criticism is optimal if @xmath7 .",
    "in contrast , the max test is only optimal in the range @xmath5 .",
    "we begin by introducing a model of design matrices in which most of the variables are only weakly correlated .",
    "our model depends upon two parameters , and we say that a @xmath194 correlation matrix @xmath195 belongs to the class @xmath196 if and only if it obeys the following two properties :    * _ strong correlation property .",
    "_ this requires that for all @xmath197 , @xmath198 that is , _ all _ the correlations are bounded above by @xmath199 . in the limit of large @xmath0 ,",
    "this is not an assumption and we will later explain how one can relax this even further . *",
    "_ weak correlation property .",
    "_ this is the main assumption and this requires that for all @xmath12 , @xmath200 note that for @xmath201 , @xmath202 since @xmath203 . fix a variable @xmath59 .",
    "then at most @xmath204 other variables have a correlation exceeding @xmath118 with @xmath59 .",
    "our only real condition caps the number of variables that can have a correlation with any other above a threshold @xmath118 .",
    "an orthogonal design belongs to @xmath205 since all the correlations vanish . with high probability ,",
    "the gaussian and rademacher designs described earlier belong to @xmath206 with @xmath207 .",
    "the main result of this paper is that if the predictor variables are not highly correlated , meaning that the quantities @xmath118 and @xmath208 above are sufficiently small , then there are computable detection thresholds for our sparse alternatives that are very similar or identical to those available for orthogonal designs .",
    "we begin by studying lower bounds and for sfem , these may be understood either in a worst - case sense or under the prior where @xmath39 is uniformly distributed among all @xmath68-sparse vectors with nonzero coefficients equal to @xmath41 . for srem ,",
    "these hold under a prior generating the support uniformly at random .",
    "we first consider mildly sparse alternatives .",
    "[ prpmoderate - lb ] suppose that @xmath209 and let @xmath176 with @xmath95 $ ] . in sfem ( resp .",
    ", srem ) , all sequences of tests are asymptotically powerless if @xmath210 [ resp . , @xmath211 .",
    "in order to interpret this proposition , we note that @xmath118 will usually be at least as large as @xmath212 , as shown just below .",
    "in proposition [ prpmoderate - lb ] we have required that @xmath213 in order to derive sharp results .",
    "moving now to sparser alternatives , we allow for @xmath208 to increase with @xmath0 , although very slowly , while the condition on @xmath118 remains essentially the same .",
    "[ thmsp - lb ] assume the sparsity exponent obeys @xmath96 $ ] , and suppose that @xmath214 with the following parameter asymptotics : ( 1 ) @xmath215 , for all @xmath120 , and ( 2 ) @xmath216 . in sfem ( resp .",
    ", srem ) , all sequences of tests are asymptotically powerless if @xmath103 with @xmath104 [ resp . , @xmath217 .",
    "the result is essentially the same in the case of a balanced , multi - way design with the usual linear constraints .",
    "we comment on this point at the end of the proof of theorem [ thmsp - lb ] .",
    "the reader may be surprised to see that the number @xmath49 of observations does not explicitly appear in the above lower bounds .",
    "the sample size appears implicitly , however , since it must be large enough for the class @xmath218 to be nonempty .",
    "assume @xmath213 , for instance , and that @xmath219 . then by the lower bound @xcite , equation ( 12 )",
    ", we have @xmath220 for instance , @xmath221 if @xmath222 .    as a technical aside",
    ", we remark that the lower bounds hold under the strong correlation assumption @xmath223 for any @xmath224 , provided that @xmath225",
    ". we shall prove this more general statement , and the theorem is thus a special case corresponding to @xmath226 .",
    "we pause to compare with the results of the recent paper @xcite .",
    "the lower bounds in @xcite are the same as ours ( for sfem ) except that they impose slightly weaker conditions on @xmath118 . in proposition",
    "[ prpmoderate - lb ] , their condition is @xmath227 , and in theorem [ thmsp - lb ] , their condition is @xmath228 .",
    "we now turn to upper bounds and , unless stated otherwise , these assume the following models :    * for sfem , we assume that @xmath39 has a support generated uniformly at random and that its nonzero coefficients have random signs . * for srem ,",
    "we assume that @xmath39 has a support generated uniformly at random .",
    "we require that the support of @xmath39 be generated uniformly at random and , in sfem , that the signs of its coefficients be also random to rule out situations where cancellations occur , making the signal strength potentially too small ( and possibly vanish ) to allow for reliable detection .",
    "we begin by studying the performance of anova when the alternative is not that sparse .",
    "we state our result for @xmath213 in accordance with the lower bound ( proposition [ prpmoderate - lb ] ) , although the result holds when @xmath208 obeys @xmath229 for all @xmath120 .",
    "[ prpmoderate - ub ] assume that @xmath230 and let @xmath231 .",
    "* assume @xmath232 .",
    "then , in sfem , anova is asymptotically powerful ( resp .",
    ", powerless ) when @xmath233 ( resp .",
    ", @xmath234 ) .",
    "* assume @xmath235 .",
    "then , in srem , anova is asymptotically powerful ( resp . , powerless ) when @xmath236 ( resp . , @xmath234 ) .",
    "note that this holds for all values of @xmath237 .",
    "for example , consider an @xmath66 gaussian design with @xmath65 .",
    "for this design @xmath238 ( in probability ) .",
    "hence , assuming @xmath239 , proposition [ prpmoderate - ub ] says that , in sfem , the anova test is powerful when @xmath240 .",
    "we contrast this with proposition [ prpmoderate - lb ] , which says that , in the same context and assuming that @xmath241 $ ] , all methods are powerless when @xmath242 . hence , in this moderately sparse setting where @xmath95 $ ] , if one ignores the @xmath243 factor ( we do not know whether proposition [ prpmoderate - lb ] is tight ) , then one can say that anova achieves the optimal detection boundary .",
    "however , as we will see in theorems [ thmsp - ub ] , [ thmsp - ub2 ] and [ thmmax ] , anova is far from optimal in the strongly sparse case when @xmath7 .",
    "compared with proposition [ prpmoderate - lb ] , the condition on @xmath118 is substantially weaker .",
    "more importantly , there appears to be a major discrepancy when @xmath49 is negligible compared to @xmath0 because @xmath244 replaces @xmath245 .",
    "this is illusory , however , as the lower bound on @xmath118 displayed in ( [ gamma - lb ] ) implies that the condition on @xmath33 in proposition  [ prpmoderate - lb ] matches that of proposition [ prpmoderate - ub ] up to a @xmath246 factor .",
    "turning to sparser alternatives , we apply the higher criticism to @xmath61 and for @xmath247 , put @xmath248 the innovated higher criticism of hall and jin @xcite resembles @xmath249 , the main difference being that they apply a threshold to the entries of @xmath58 before multiplying by @xmath192 . here , to facilitate the analysis",
    ", we search for the maximum on a discrete grid and define @xmath250 \\cap{\\mathbb{n}}\\bigr\\}.\\ ] ]    [ thmsp - ub ] assume the sparsity exponent obeys @xmath96 $ ] and suppose that @xmath214 with the following parameter asymptotics : ( 1 ) @xmath251 , for all @xmath120 ; ( 2 ) @xmath252 and ( 3 ) @xmath253 , for all @xmath120 .    * in sfem ,",
    "the test based on @xmath254 with @xmath255 is asymptotically powerful against any alternative defined by @xmath256 with @xmath257 and @xmath258 with @xmath259 . * in srem , the test based on @xmath260 is asymptotically powerful when @xmath261 regardless of @xmath96 $ ] and without condition ( 3 ) .    in srem ,",
    "the conclusion is an immediate consequence of the behavior of the max test stated in theorem [ thmmax ] and we , therefore , omit the proof . having",
    "said this , the remarks below apply to sfem :    the condition on @xmath118 is weaker than the condition required in theorem [ thmsp - lb ] , although the two conditions get ever closer as @xmath237 approaches @xmath262 .",
    "the test based on @xmath260 is asymptotically powerful for all @xmath124 $ ] ( this test is closely related to the max test ) .",
    "other discretizations in the definition of @xmath263 would yield the same result .",
    "in fact , we believe the result holds without any discretization , but we were not able to establish this in general .",
    "however , suppose that @xmath264 and that @xmath58 is the concatenation of @xmath130 orthonormal bases .",
    "if @xmath265 , for all @xmath120 , the result holds without any discretization , meaning that rejecting for large values of @xmath266 is asymptotically powerful under the same conditions .",
    "this comes from leveraging the behavior ( under the null ) of the higher criticism  detailed in @xcite  for each basis .    while the above theorem gives relatively weak requirements on @xmath267 , it is not fully adaptive .",
    "in particular , in sfem , one requires knowledge of @xmath237 to set the search grid for the statistic @xmath263 . under a stronger condition on @xmath118",
    ", we have the following fully adaptive result for @xmath96 $ ] .",
    "[ thmsp - ub2 ] assume the sparsity exponent obeys @xmath96 $ ] and suppose that @xmath214 with the following parameter asymptotics : ( 1 ) @xmath251 , for all @xmath120 ; ( 2 ) @xmath268 , for all @xmath269 .",
    "then in sfem , the test based on @xmath270 is asymptotically powerful whenever @xmath105 .",
    "we restricted our attention to the case of strong sparsity , that is , @xmath7 , as we may cover the whole range @xmath271 $ ] by combining the anova and the higher criticism tests ( with a simple bonferroni correction ) , obtaining an adaptive test operating under weaker constraints on the coherence @xmath118 .",
    "that said , we mention that the higher criticism test is near - optimal in the setting of theorem [ thmsp - ub2 ] when , under the alternative , the nonzero coefficients are not too spread out ( restriction on the dynamic range ) and the amplitude is sufficiently large .",
    "this is the case , for instance , when all nonzero coefficients are equal to @xmath33 in absolute value with @xmath272 for some @xmath273 fixed .",
    "the paper @xcite studies three tests assuming a random design x. the first is based on @xmath274 and is studied in the nonsparse case where @xmath275 , whereas the second is based on @xmath276 .",
    "the combined test is very similar to anova and the authors obtain the equivalent of proposition [ prpmoderate - ub ] for random design matrices @xmath58 having standardized independent entries with uniformly bounded fourth moment .",
    "reference  @xcite also considers the test based on the higher criticism applied to @xmath277 and the equivalent of theorems [ thmsp - ub ] and [ thmsp - ub2 ] are established under the assumption that the design matrix @xmath58 has i.i.d .",
    "standard normal entries . averaging over a random design @xmath58 with standardized independent entries",
    "effectively reduces to an orthogonal design , resulting in much weaker ( implicit ) assumptions ; no randomness assumptions on @xmath278since this randomness is carried by @xmath58and no discretization of the thresholds in the higher criticism statistic . in stark contrast , we consider the design fixed ( although it can of course be generated in a random fashion ) .    turning our attention to the max test now , the results available for orthogonal designs remain valid under similar conditions on the matrix @xmath58 .",
    "[ thmmax ] let @xmath176 and assume that @xmath279 with the following parameter asymptotics : ( 1 ) @xmath251 , for all @xmath120 and ( 2 ) @xmath280 .    * in sfem ,",
    "the max test is asymptotically powerful if @xmath281 with @xmath282 , and asymptotically powerless if @xmath187 . * in srem",
    ", the max test is asymptotically powerful for a fixed signal level obeying @xmath261 , and asymptotically powerless if @xmath188 .",
    "the above holds for all @xmath123 $ ] .",
    "this theorem justifies the assertion made in the , which stated that one could detect a linear relationship between the response and a few covariates even though those covariates that were mostly correlated with the response were not in the model . to clarify , consider sfem and @xmath283 $ ] .",
    "then , for @xmath284 with @xmath285 , the max test is asymptotically powerless , whereas the test based on @xmath263 has full power asymptotically . in particular , in the regime in which the max test is powerless , with high probability the entry of @xmath286 which achieves the maximal magnitude corresponds to a covariate not in the support of @xmath278 .",
    "( this is explicitly demonstrated in the proof of theorem [ thmmax ] . ) in the proof , we use fine asymptotic results for the maximum of correlated normal random variables due to berman @xcite and deo @xcite .",
    "we pause here to comment on the situation in which the variance of the noise ( denoted @xmath287 ) is unknown and must be estimated . as for the identity design , the results in this section hold with @xmath80 replaced by @xmath288 with the proviso that @xmath289 is any accurate estimate with a slight upward bias to control the significance level . formally , suppose we have an estimator obeying @xmath290 and @xmath291 for all @xmath292 .",
    "we would then apply our methodology to @xmath288 . on the one hand",
    ", it follows from the monotonicity of our statistic that the asymptotic probability of type i errors is no worse than in the case of known variance since we use an estimate which is biased upward . on the other hand , consider an alternative with @xmath70 and amplitudes set to @xmath293 , @xmath105 .",
    "the gap between @xmath190 and @xmath182 is sufficient to reject the null .",
    "indeed , @xmath263 is applied to  @xmath288 , leading to a normalized amplitude equal to @xmath294 , where @xmath295 is greater than @xmath182 in the limit .",
    "( the contribution over the complement of the support of @xmath278 is negligible because @xmath296 is sufficiently small , and this is why we require @xmath291 . )",
    "the same arguments apply to the anova @xmath16-test and the max test .",
    "we mention that hall and jin @xcite discuss the same issue for the case of an orthogonal design and colored noise with a covariance that may be unknown .",
    "note that @xcite treats the case of unknown variance in detail when the design matrix @xmath58 has i.i.d .",
    "standard normal entries .",
    "we now discuss strategies for constructing estimators obeying ( [ eqconsistent ] ) .",
    "there are many possibilities and we choose to discuss a simple estimate applying in the case of strong sparsity @xmath123 $ ] , where signals are near the detection boundary , so that @xmath297 ( this is the interesting regime ) . for concreteness , assume that @xmath298 for all @xmath292 . as noted in section [ secpriorwork ] , @xmath299 has the chi - square distribution with @xmath49 degrees of freedom and noncentrality parameter @xmath300 , and , thus , @xmath301 as long as @xmath302 .",
    "now let @xmath303 slowly ( say , @xmath304 ) and define @xmath305 .",
    "this estimator obeys ( [ eqconsistent ] ) .",
    "a common assumption in multivariate statistics is that the rows of the design matrix are independent draws from the multivariate normal distribution @xmath306 .",
    "our results apply provided that @xmath307 obeys the assumptions about @xmath126 .",
    "[ corstat ] suppose the rows of @xmath58 are independent samples from @xmath306 , and @xmath308 ( the columns are normalized ) .",
    "then the conclusions of theorems [ thmsp - lb ] , [ thmsp - ub ] and [ thmmax ] are all valid , provided that @xmath309 obeys the conditions imposed on @xmath118 .",
    "we remark that if the columns are not normalized so that the rows of @xmath58 are independent samples from @xmath306 , the same result holds with a threshold @xmath33 replaced by @xmath310 .",
    "this holds because the norm of each column is sharply concentrated around @xmath311 .",
    "we consider correlation matrices which have a substantial portion of large entries . in general , the detection threshold may depend upon some fine details of @xmath58 , but we give here some representative results applying to situations of interest .",
    "we first examine the simple , yet important and useful example of constant correlation , where @xmath312 if @xmath313 , and @xmath314 if @xmath315 .",
    "is a nontrivial matter , and we refer the reader to the literature on equiangular lines ; see @xcite , for example . ]",
    "we impose @xmath316 to make sure that @xmath317 is at least positive definite as @xmath82 ( this implies that @xmath317 has full rank which in turn imposes @xmath318 ) .",
    "the balanced one - way design has this structure since it can be modeled by the matrix @xmath319,\\ ] ] where each vector in this block representation is @xmath130-dimensional . without further assumptions on @xmath39 ,",
    "this design is equivalent to ( [ one - way ] ) with the constraint @xmath320 , except for the normalization . with this definition",
    ", @xmath126 has diagonal entries equal to @xmath132 and off - diagonal entries equal to @xmath262 so we are in the setting  with @xmath321of our next result below .",
    "[ thmzeta ] suppose that @xmath322 is equal to @xmath132 if @xmath313 and @xmath118 otherwise , and that the sparsity exponent obeys @xmath96 $ ] .",
    "then without further assumption , the conclusions of theorems [ thmsp - lb ] , [ thmsp - ub ] and [ thmmax ] remain valid with the bounds on @xmath33 and @xmath115 divided by @xmath323 .",
    "the balanced , one - way design may be seen either as an orthogonal design with a linear constraint , or a constant - correlation design without any constraint .",
    "more generally , a multi - way design is easily defined as an orthogonal design with a set of linear constraints .",
    "specifically , suppose the coordinates of @xmath39 are indexed by an @xmath324-dimensional index vector , so that @xmath325\\bigr),\\qquad p = \\prod_{s=1}^m p_s.\\ ] ] we assume the design is balanced with @xmath130 replicates per cell so that @xmath131 .",
    "with any fixed order on the index set , say , the lexicographic order , the design matrix is the same as in the balanced , one - way design ( [ one - way ] ) . here , @xmath39 obeys the linear constraints @xmath326 for all @xmath327 $ ] and @xmath328 $ ] ( there are @xmath329 constraints ) . as in the balanced , one - way design , theorem [ thmortho ] applies to the balanced , multi - way design .",
    "the argument for the lower bound is at the end of the proof of theorem [ thmsp - lb ] .",
    "the proof of the upper bounds is exactly as in the case of any other orthogonal design .",
    "finally , embedding the linear constraints into the design matrix leads to a family of designs with a `` full '' correlation structure with off - diagonal elements which , in general , are not of the same magnitude unless the design is one - way .",
    "we complement our study with some numerical simulations which illustrate the empirical performance for finite sample sizes . here",
    ", @xmath58 is an @xmath66 gaussian design with i.i.d .",
    "standard normal entries , and normalized columns .",
    "we study fixed effects and investigate the performance of anova , the higher criticism and the max test .",
    "we also compare the detection limits with those available in the case of the @xmath194 identity design , since the theory developed in corollary [ corstat ] predicts that the detection boundaries are asymptotically identical ( provided @xmath49 grows sufficiently rapidly ) .    .",
    "middle column : gaussian design with @xmath330 and @xmath331 .",
    "right column : gaussian design with @xmath330 and @xmath332 .",
    "sparsity level @xmath68 is indicated below each plot . in each plot , the empirical risk ( based on @xmath333 trials ) of each method [ anova ( red bullets ) ; higher criticism ( blue squares ) ; max test ( green diamonds ) ] is plotted against @xmath190 ( note the different scales ) . ]",
    "we performed simulations with matrices of sizes @xmath334 , @xmath335 , @xmath336 and @xmath337 , various sparsity levels , and strategically selected values of @xmath190 .",
    "each data point corresponds to an average over @xmath333 trials in the case where @xmath330 , and over @xmath338 trials when @xmath339 .",
    "a new design matrix is sampled for each trial .",
    "the performance of each of the three methods is computed in terms of its best ( empirical ) risk defined as the sum of probabilities of type i and ii errors achievable across all thresholds .",
    "the results are reported in figures [ figmoderate ] and [ figlarge ] . as expected , the detection thresholds for the gaussian design are quite    .",
    "middle column : gaussian design with @xmath339 and @xmath340 .",
    "right column : gaussian design with @xmath339 and @xmath341 .",
    "sparsity level @xmath68 is indicated below each plot . in each plot , the empirical risk ( based on 500 trials ) of each method [ anova ( red bullets ) ; higher criticism ( blue squares ) ; max test ( green diamonds ) ] is plotted against @xmath190 ( note the different scales ) . ]",
    "close to those available for the identity design .",
    "the performance of anova improves very quickly as the sparsity decreases , dominating the max test with @xmath342 ; its performance also improves as @xmath49 becomes smaller , in accordance with  ( [ anova ] ) .",
    "the performance of the max test follows the opposite pattern , degrading as @xmath68 increases .",
    "interestingly , the higher criticism remains competitive across the different sparsity levels .",
    "it is possible to extend our results to setups with correlated errors , with known covariance . as discussed in section [ secintro ] , suppose @xmath343 in ( [ setting ] ) is @xmath344 .",
    "we may then whiten the noise by multiplying both sides of ( [ setting ] ) by @xmath112 , where @xmath345 is a cholesky decomposition of @xmath109 .",
    "this leads to a model of the form @xmath346 which is our problem with @xmath347 instead of @xmath58 . in some situations ,",
    "the noise covariance matrix may not be known and we refer to @xcite for a brief discussion of this issue .",
    "although several generalizations are possible , an interesting open problem is to determine the detection boundary for a given sequence of designs @xmath348 with @xmath49 and @xmath0 growing to infinity .",
    "we have seen that if most of the predictor variables are only weakly correlated , then the detection boundary is as if the predictors were orthogonal .",
    "similar conclusions for certain types of square designs in which @xmath349 are also presented in the work of hall and jin @xcite .",
    "although we introduced some sharp results in section [ secfull ] corresponding to some important design matrices , the class of matrices for which we have definitive answers is still quite limited .",
    "we hope other researchers will engage this area of research and develop results toward a general theory .",
    "we would like to thank chiara sabatti for stimulating discussions and for suggesting improvements on an earlier version of the manuscript , and ewout van den berg for help with the simulations .",
    "we also thank the anonymous referees for their inspiring comments which helped us improve the content of the paper ."
  ],
  "abstract_text": [
    "<S> testing for the significance of a subset of regression coefficients in a linear model , a staple of statistical analysis , goes back at least to the work of fisher who introduced the analysis of variance ( anova ) . </S>",
    "<S> we study this problem under the assumption that the coefficient vector is sparse , a common situation in modern high - dimensional settings . </S>",
    "<S> suppose we have @xmath0 covariates and that under the alternative , the response only depends upon the order of @xmath1 of those , @xmath2 . under moderate sparsity levels , </S>",
    "<S> that is , @xmath3 , we show that anova is essentially optimal under some conditions on the design . </S>",
    "<S> this is no longer the case under strong sparsity constraints , that is , @xmath4 . in such settings , </S>",
    "<S> a multiple comparison procedure is often preferred and we establish its optimality when @xmath5 . </S>",
    "<S> however , these two very popular methods are suboptimal , and sometimes powerless , under moderately strong sparsity where @xmath6 . </S>",
    "<S> we suggest a method based on the higher criticism that is powerful in the whole range @xmath7 . </S>",
    "<S> this optimality property is true for a variety of designs , including the classical ( balanced ) multi - way designs and more modern `` @xmath8 '' designs arising in genetics and signal processing . </S>",
    "<S> in addition to the standard fixed effects model , we establish similar results for a random effects model where the nonzero coefficients of the regression vector are normally distributed .    ,    .    </S>"
  ]
}