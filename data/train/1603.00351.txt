{
  "article_text": [
    "the hazard rate , defined as @xmath0 ( where @xmath1 is the survival function for @xmath2 and @xmath3 ) , can be critical in assessing how the risk of a disease changes over time .",
    "however , it can be difficult to estimate reliably , particularly over the course of a study with few observed failures during the follow up period and when the effects of covariates change over time .",
    "( for examples , see @xcite . )",
    "to this end , the mrh package in r ( @xcite ) has three overarching features :    1 .",
    "estimation of the hazard rate and the associated credible intervals ( as well as the corresponding survival function and cumulative hazard estimates and credible intervals ) .",
    "joint estimation of the effects of predictors incorporated under the proportional hazards ( ph ) and non - proportional hazards ( nph ) assumptions . 3 .   a  pruning \" tool that combines portions of the hazard rate that are similar , providing robust estimates through periods of sparse failures , and allowing for faster computation times .",
    "the underlying statistical approach employed in the mrh package is the multi - resolution hazard ( mrh ) model , a bayesian semi - parametric hazard rate estimator previously presented and used in @xcite , and compared to other packages in @xcite .",
    "this model for survival data is based on the polya tree methodology , and is flexibly designed for multi - resolution inference capable of accommodating periods of sparse events and varying smoothness .",
    "the mrh model accommodates both proportional and non - proportional effects of predictors over time and also uses a pruning algorithm presented in @xcite and @xcite , which performs data - driven `` pre - smoothing '' of the hazard rate by merging time intervals with similar hazard levels .",
    "pruning has been shown to increase computational efficiency and reduce overall uncertainty in hazard rate estimation in the presence of periods with smooth hazard rate and low event counts ( @xcite ) .",
    "the following sections of this manuscript are organized as follows : in section 2 we provide background on the multi - resolution hazard ( mrh ) model . in section 3",
    "we briefly discuss the tongue cancer data set we use to demonstrate the mrh package , and in section 4 we cover use of the mrh package , including fitting and plotting fitted models , pruning the prior , assessing convergence of the mcmc chains , and the effects adjustment of the prior parameters .",
    "lastly , we discuss our conclusions in section 5 .",
    "the mrh model is a bayesian , semi - parametric survival model that produces an estimate of the hazard rate and covariate effects .",
    "the mrh prior is closely related to the polya tree prior ( @xcite ) , which is an infinite , recursive , dyadic partitioning of a measurable space @xmath4 .",
    "( in practice , this process is terminated at a finite level @xmath5 . )",
    "the mrh prior is a type of polya tree in that it uses a fixed , pre - specified partition and controls the hazard level within each bin through a multi - resolution parameterization .    to facilitate the recursive dyadic partition of the multiresolution tree , we assume that @xmath6 . here",
    ", @xmath5 is an integer , set to achieve the desired time resolution , or through model selection criteria or clinical input ( for example , see @xcite ) .",
    "the hazard function is parametrized by a set of hazard increments @xmath7 . where @xmath8 represents the aggregated hazard rate over the @xmath9 time interval , ranging from @xmath10 .",
    "in standard survival analysis notation , @xmath11 , where @xmath12 is the hazard rate at time @xmath13 .",
    "the cumulative hazard , @xmath14 , is equal to the sum of all @xmath15 hazard increments , which are denoted as @xmath16 .",
    "the model then recursively splits @xmath14 at different branches via the  split parameters \" @xmath17 . here",
    ", @xmath18 is recursively defined as @xmath19 ( with @xmath20 , and @xmath21 ) .",
    "the @xmath22 split parameters , each between 0 and 1 , guide the shape of the _ a priori _ hazard rate over time .",
    "the complete hazard rate prior specification is obtained via priors placed on all tree parameters : a gamma(@xmath23 ) prior is placed on the cumulative hazard @xmath14 , and beta prior on each split parameter @xmath22 , @xmath24 .",
    "this parametrization ensures the self - consistency of the mrh prior at multiple resolutions ( @xcite ) .",
    "the basic mrh model was extended in @xcite into the hierarchical multi - resolution ( hmrh ) hazard model , capable of modeling non - proportional hazard rates in different subgroups jointly with other proportional predictor effects .",
    "the pruning methodology for combining similar hazard bins was developed in @xcite for individual hazard rates , and combined with the hmrh model in @xcite .",
    "the pruning algorithm detects consecutive time intervals where failure patterns are statistically similar , increasing estimator efficiency and reducing computing time .",
    "the resulting method produces computationally stable and efficient inference , even in periods with sparse numbers of failures , as may be the case in studies with long follow - up periods .",
    "we denote @xmath25 as the minimum of the observed time to failure or the right - censoring time for subject @xmath26 each subject belongs to one of the @xmath27 covariate strata , and within each stratum we employ the proportional hazards assumption such that : @xmath28 here , @xmath29 denotes the baseline hazard rate for treatment strata @xmath30 , @xmath31 represents the @xmath32 matrix of @xmath33 covariates ( other than those used for stratification ) for the @xmath34 patients in the stratum @xmath30 , while @xmath35 denotes the @xmath36 vector of the covariate effects .    for subject @xmath37 in stratum @xmath30 with failure time at @xmath38 ,",
    "the likelihood contribution is : @xmath39 where @xmath40 is that subject s covariate vector , @xmath41 is the baseline survival function for the stratum @xmath30 , and @xmath42 is the censoring indicator that equals 1 if subject @xmath37 had an observed failure , and 0 otherwise .",
    "thus , the log - likelihood for all @xmath43 patients in all @xmath27 strata together ( @xmath44 ) is @xmath45 where @xmath46 denotes the set of indices for subjects belonging to the stratum @xmath30 , and @xmath47 in this model , the @xmath27 hazard rates are estimated jointly with all the covariate effects .",
    "the non - proportional covariate effect is then calculated as the log of the hazard ratio between different covariate strata in each bin .",
    "the mrh prior resolution is often chosen as a compromise between the desire for detail in the hazard rate , and the number of observed ( i.e. uncensored ) failures .",
    "as the resolution increases , the number of observed failures within each bin decreases . while useful for revealing detailed patterns , a large number of intervals is a large number of model parameters , which will generally require longer computing times and may result in estimators with lower statistical efficiency ( @xcite ) .",
    "`` pruning '' starts with the full mrh tree prior , and merges adjacent bins that are constructed via the same split parameter , @xmath22 , when the hazard increments in these two bins ( @xmath48 and @xmath49 ) are statistically similar .",
    "this is inferred by testing the hypothesis @xmath50 against the alternative @xmath51 , with a pre - set type i error @xmath52 , using fisher s exact test .",
    "if the null hypothesis is not rejected , that split @xmath22 is set to @xmath53 and the adjacent hazard increments are considered equal and the time bins declared `` fused '' . the hypothesis testing can be applied to all @xmath5 levels of the tree or just a higher resolution subset of the tree . because bins are fused _ a priori _ , this method can then reduce the number of parameters sampled in the mcmc routine , possibly decreasing computation time and increasing the robustness of the estimator .",
    "estimation is performed in two steps : the pruning step and the mcmc steps .",
    "the pruning step is run only once for each of the @xmath27 hazard rates at the beginning of the algorithm as a pre - processing step in order to finalize the mrh tree priors .",
    "the @xmath54 parameters for which the null hypothesis is not rejected are set to @xmath53 with probability 1 , while the rest are estimated in the markov chain monte carlo ( mcmc ) routine .",
    "details on the mcmc routine and prior values can be found in @xcite and @xcite .",
    "to demonstrate the different features of the package , we use the  tongue \" data set available in the r data set available in the r survival package .",
    "the data set contains 80 subjects with tongue cancer who had a paraffin - embedded sample of the cancerous tissue taken at the time of surgery , with survival times recorded for each patient ( in weeks ) , as well as the tumor dna profile ( aneuploid or diploid ) ( see @xcite for details ) .",
    "the study went for 400 weeks , with a median survival time equal to 69.5 weeks ( sd = 67.3 ) , and 33.8% of the subjects were censored . between 250 and 350 weeks",
    "there were zero failures ( censored or uncensored ) , and after 200 weeks there were zero uncensored failures .",
    "this data set is also presented in @xcite and analyzed @xcite .",
    "table [ tab : summcateg ] summarizes the data in more detail .",
    ".sample characteristics of 80 patients in the  tongue \" data set found in the r survival package , stratified by tumor type .",
    "[ cols=\"^,^,^,^,^,^,^ \" , ]      the mrh package allows the user to control different properties of the mcmc chain ( i.e. the burn - in , the thinning value , and the maximum number of iterations ) .",
    "in addition , the ` estimatemrh ( ) ` routine checks for possible convergence , and can modify the properties of the mcmc chain .",
    "plots are also provided in the output folder that allow the user to assess if the chains have converged .",
    "below , we outline the different methods for fixing the properties of the mcmc chain and assessing convergence .",
    "the user may use the default values for the burn - in (  burnin \" ) , thinning value (  thin \" ) , and maximum number of iterations (  maxiter \" ) of the mcmc chains , or they may specify and fix these values . the default maximum number of mcmc iterations is set at 500,000 , with a burn - in value of 50,000 and a thinning value of 10 .",
    "however , based on evidence of chain convergence , these numbers may be changed by the routine unless otherwise specified by the user .",
    "after the first 100,000 mcmc iterations , the chains are checked for autocorrelation and evidence of convergence .",
    "( if the maximum number of iterations specified by the user is less than 100,000 , then convergence is checked when the maximum number has been reached . ) the convergence checking routine is performed via the geweke diagnostic test ( @xcite ) and the heidelberger - welch diagnostic test ( @xcite ) using the ` geweke.diag ( ) ` and ` heidel.diag ( ) ` functions available in the coda package ( @xcite ) .",
    "the convergence algorithm can be seen in the [ alg : convergence ] algorithm table .",
    "convergence    \\1 .",
    "check if thinning value is high enough to reduce autocorrelation : use ` acm ( ) ` in the coda package to test the current value of ` thin ` as well as 5 , 10 and 15 times ` thin ` .",
    "the first lag where autocorrelation disappears is the new thinning value .",
    "( note that this value can only be greater than the previous value . )",
    "set ` thin ` to the updated value .",
    "thin the stored chains .",
    "convergence check : calculate all p - values for the z - scores returned for each parameter from the ` geweke.diag ( ) ` function and calculate the results of the heidelberg - welch test .",
    "convergence reached .",
    "burn 20,000 more iterations perform convergence check again .",
    "end mcmc sampling routine .",
    "update the values of ` burnin ` and ` thin ` ( if needed ) .",
    "set ` thin ` , ` burnin ` , and stored chains to original values ( from before step # 1 ) . perform another 100,000 mcmc iterations .",
    "( or the remaining mcmc iterations needed for ` maxiter ` to be reached , whichever is smaller . )",
    "there may be instances in which the user wants to fix ` burnin ` , ` thin ` , or ` maxiter ` so that the routine does not change these values in the process of checking for convergence , and so that the user is guaranteed the mcmc chain will run ` maxiter ` times .",
    "these values can be fixed ( simultaneously or individually ) by setting the  fix.burnin \" ,  fix.thin \" , or ",
    "fix.max \" options to true .",
    "( by default , these are set to false . )",
    "in addition to the convergence checking performed by the algorithm , diagnostic figures containing trace , density , moving average ( calculated by 100 ) , and autocorrelation plots for each parameter are included in the output folder for the model .",
    "an example of these plots ( for three parameters ) can be seen in figure [ fig : convplots ] .",
    "this graphic allows to user to also assess if convergence has been reached , or if certain parameters are more problematic then others .",
    "if the routine does not detect evidence of convergence and ` maxiter ` is reached , then the following message is shown to the user :    .... warning message : in estimatemrh(surv(time , delta ) ~ nph(type ) , data = tongue , m = 4 ,   :    algorithm has not yet converged after   mcmc iterations .",
    "parameter estimates may not be reliable .   ....    in this instance",
    ", the user may want to continue running the mcmc routine using the previously sampled chain values .",
    "this can be done using the same call as the in the first model and by setting  continue.chain \" equal to true .",
    "( note that this will only work if the output folder name is the same as with the previous model .",
    "in addition , if the user specifies new thinning or burn - in values , these will be ignored  the values from the previous chain will be used instead . )",
    "if the chain is continued , the routine reads in the chains from the previous set of iterations and initializes the parameters using the last line of retained mcmc values , appending new samples to the previous existing text file store in the output folder .",
    "example code and output for this is below :    .... fit.nph.continue = estimatemrh(surv(time , delta ) ~ nph(type ) , data = tongue ,    m = 4 , maxstudytime = 400 , outfolder = ' mrhresults_nph_continue ' , maxiter = 5000 ) .... warning message : in estimatemrh(surv(time , delta ) ~ nph(type ) , data = tongue   :    algorithm has not yet converged after   mcmc iterations .",
    "parameter estimates may not be reliable .",
    "fit.nph.continue = estimatemrh(surv(time , delta ) ~ nph(type ) , data = tongue ,    m = 4 , maxstudytime = 400 , outfolder = ' mrhresults_nph_continue ' , maxiter = 50000 )     mcmc routine running .   calculating",
    "estimated runtime for 50000 iterations ...     estimated total run time is 20 minutes     to shorten the run time , re - run with fewer iterations or a smaller number of bins .   ....      to provide robust estimates of the hazard rate and covariate effects , it is common to run the mcmc routine for the same model multiple times , using the results from all chains to produce estimates and to check for convergence .",
    "the mrh package provides a number of options that allow the user to do this more easily .    in the ` estimatemrh ( ) `",
    "routine , the user can set the `` gr '' ( gelman - rubin ) option equal to true ( by default this is false ) . in doing this",
    ", the routine automatically fixes the chain parameters ( ` thin ` , ` burnin ` , and ` maxiter ` ) to what has been specified by the user in the function call , and also adjusts the initial values of the parameters to cover the parameter space .",
    "( these are necessary qualifications for the use of the gelman - rubin convergence test . )    after all mcmc chains have been sampled , ` analyzemultiple ( ) ` is available for analyzing multiple mcmc chains for the same model .",
    "the ` analyzemultiple ( ) ` function accepts multiple chains as an input parameter , and then returns to the user the estimated parameter values and @xmath52-level credible intervals and the gelman - rubin diagnostic information . within each set of chains ,",
    "the median , @xmath55%-tile , and @xmath56%-tile of the marginal posterior distribution is calculated for each parameter .",
    "then , the median of the medians and percentiles is calculated , and these are the numbers reported as the estimates and credible intervals for each parameter .",
    "example code for this is below :    .... # fit the three models separately fit.nphprune31 = estimatemrh(surv(time , delta ) ~ nph(type ) , data = tongue ,        m = 4 , maxstudytime = 400 , outfolder = ' mrhresults_nphprune31 ' , gr = true ,      prune = true , prune.levels = 3 )    fit.nphprune32 = estimatemrh(surv(time , delta ) ~ nph(type ) , data = tongue ,        m = 4 , maxstudytime = 400 , outfolder = ' mrhresults_nphprune31 ' , gr = true ,      prune = true , prune.levels = 3 )    fit.nphprune33 = estimatemrh(surv(time , delta ) ~ nph(type ) , data = tongue ,        m = 4 , maxstudytime = 400 , outfolder = ' mrhresults_nphprune31 ' , gr = true ,      prune = true , prune.levels = 3 ) ....    an examination of the initial starting values shows that the initialized values cover the parameter space ( which can be accessed with ` fit.nph1$initialvalues ` ) .    ....    # get the parameter estimates and credible intervals using all three chains .",
    "# also check for convergence using the gelman - rubin diagnostic test .",
    "results = analyzemultiple(filenames = c('mrhresults_nphprune31/mcmcchains.txt ' ,        ' mrhresults_nphprune32/mcmcchains.txt ' ,        ' mrhresults_nphprune33/mcmcchains.txt ' ) , maxstudytime = 400 ) names(results ) [ 1 ] \" hazardrate \"        \" beta \"              \" survivalcurve \"     \" cumulativehazard \" [ 5 ] \" d \"                 \" h \"                 \" rmp \"               \" gelman.rubin \"      results$gelman.rubin            scale reduction factor h00_1                          1 h00_2                          1 rmp1.0_1                       1 rmp4.2_1                       1 rmp4.3_1                       1 rmp1.0_2                       1 rmp4.1_2                       1 rmp4.3_2                       1 a_1                            1 a_2                            1 lambda_1                       1 lambda_2                       1 ....    the results of the gelman - rubin diagnostic test can be used to determine if convergence has been reached . if the scale reduction factor is  far from \" 1",
    ", then it is recommended that more iterations be performed ( using the  continue.chain \" option ) .",
    "the computation time for convergence of the mrh model may be longer than the user would like to spend waiting ( particularly in cases where the number of bins and/or the number of subjects is high ) . in these instances , the user may want to run the model as a background job , in which case the fitted model results will not be available in the console . under these circumstances ,",
    "the user can read in the mcmc chains from the output folder , convert them to an mrh object , and then may use existing functions for plotting and summarizing the chains .",
    "the only difference between the usage of the functions is that the maximum study time (  maxstudytime \" ) must be entered for accurate estimates :    .... # read in the file from the output folder mcmc.nph.prune3 = read.table('mrhresults_nph_prune3/mcmcchains.txt ' , header = true )    # convert to an mrh object   mrh.nph.prune3 = as.mrh(mcmc.nph.prune3 ) class(mrh.nph.prune3 ) [ 1 ] \" mrh \"    # summarize and plot the results ( warning occurs if maximum study time is not entered ) summary(mrh.nph.prune3 ) error in summary.mrh(mrh.nph.prune3 ) :     maximum study time ( maxstudytime ) needed for hazard rate calculation .",
    "the maximum study time can be found in the mcmcinfo.txt file in the output folder .",
    "names(summary(mrh.nph.prune3 , maxstudytime = 400 ) ) [ 1 ] \" hazardrate \"        \" beta \"              \" survivalcurve \"     \" cumulativehazard \" [ 5 ] \" d \"                 \" h \"                 \" rmp \"                 plot(mrh.nph.prune3 , maxstudytime = 400 ) ....",
    "in this manuscript , we have highlighted the main features of mrh package and demonstrated its use on the tongue cancer data set .",
    "use of the pruning tool and the accommodation of non - proportional hazards makes this package idea for estimation of right - censored survival outcomes when the number of observed failures is small and/or the follow - up period is long .",
    "there are a few other packages that provide a non- or semi - parametric estimate of the hazard rate , and that accommodate non - proportional hazards .",
    "namely , these are ` bayessurv ` ( @xcite ) , ` dppackage ` ( @xcite ) , and ` timereg ` ( @xcite ) .",
    "while these packages provide their own unique strengths to the analysis of right - censored survival data , the covariate interpretations for all three models are different than that of the mrh model : ` bayessurv ` implements aft survival models , ` lddpsurvival ( ) ` in the ` dppackage ` package estimates covariates in an anova - like fashion using a dirichlet process prior , and the ` timecox ( ) ` function in the ` timereg ` package produces cumulative covariate estimates .",
    "( for a thorough comparison of these packages , see @xcite . ) the mrh package provides a useful tool for estimation of the hazard rate and covariate effects .",
    "this work was supported by grants nsf - geo 1211668 and nsf - deb 1316334 .",
    "the project utilized the janus supercomputer , which is supported by the national science foundation ( award number cns-0821794 ) and the university of colorado - boulder .",
    "the janus supercomputer is a joint effort of the university of colorado - boulder , the university of colorado - denver , and the national center for atmospheric research .",
    "janus is operated by the university of colorado - boulder .",
    "the authors thank yuanting chen and the researchers at ncar and the reaccting project for their helpful advice and input .",
    "sickle - santanello , w.b .",
    "farrar , j.f .",
    "decenzo , s.  keyhani - rofagha , j.  klein , d.  pearl , h.  laufman , and r.v .",
    "otoole . technical and statistical improvements for flow cytometric dna analysis of paraffin - embedded tissue . , 9:594599 , 1988 .        j.  geweke ( 1992 )  evaluating the accuracy of sampling - based approaches to the calculation of  posterior moments . ,",
    "bernardo , j.o .",
    "berger , a.p .",
    "dawid and a.f.m .",
    "smith , eds ) 169 - 193 .",
    "oxford univ . press ."
  ],
  "abstract_text": [
    "<S> in this manuscript we demonstrate the analysis of right - censored survival outcomes using the mrh package in r. the mrh package implements the multi - resolution hazard ( mrh ) model ( @xcite ) , which is a polya - tree based , bayesian semi - parametric method for flexible estimation of the hazard rate and covariate effects . </S>",
    "<S> the package allows for covariates to be included under the proportional and non - proportional hazards assumption , and for robust estimation of the hazard rate in periods of sparsely observed failures via a  pruning \" tool .    _ key words : _ mrh , multi - resolution hazard , non - proportional hazards , sparse observations , survival analysis . </S>"
  ]
}