{
  "article_text": [
    "the lambert w function @xmath5 is the solution of @xmath6 , for complex @xmath7 and @xmath8 .",
    "it can be considered as the multi - branch inverse of the conformal map @xmath9 between the complex @xmath7-plane and the complex @xmath8-plane . when @xmath7 and @xmath8 are restricted to having real values",
    ", the graph of the lambert w function is as shown in figure [ fig - lamw - graph ] . for further background regarding the lambert w function ,",
    "see @xcite .",
    "some problem situations , for instance the modeling of current and voltage in diodes or solar cells , reduce to an implicit equation which can be solved explicitly by means of the lambert w function . as a simple example , consider the implicit equation @xmath10 where @xmath11 are positive real numbers , parameters of the model , and @xmath12 are real variables . )",
    "is a considerable simplification , in order to have an example in mind .",
    "the typical solar cell model has four or five parameters .",
    "see @xcite , page 14 , for instance . ]",
    "the corresponding explicit solution for @xmath13 as a function of @xmath14 is @xmath15 here @xmath16 denotes the principal branch of the natural logarithm function , and @xmath1 denotes the principal branch of the lambert w function .    a typical task might be , given values of the model parameters , to draw a graph of @xmath13 as a function of @xmath14 .",
    "for that task , it is computationally efficient to have , instead of the implicit equation ( [ eqimplicit ] ) , the explicit solution ( [ eqexplicit ] ) for @xmath13 in terms of @xmath14 and the model parameters",
    ".    another task might be to estimate the model parameter values @xmath11 which best fit experimental observations of @xmath12 pairs .",
    "for that task , one wants to have an understanding of how varying the model parameters will affect the @xmath13-@xmath14 curves .",
    "still another task might be to determine the relationships among the model parameters which correspond to having an extremum of a function of @xmath13 or @xmath14 .",
    "this task also requires an understanding of how varying the model parameters will affect the @xmath13-@xmath14 curves , but it will also be helpful if the formula utilized has partial derivatives with respect to all the parameters .",
    "the expression in equation ( [ eqexplicit ] ) is analytic , so is well - behaved with respect to its argument and the model parameters .",
    "it can be repeatedly differentiated , its extrema lie at stationary points , and so on . because one is working with real values for @xmath13 and @xmath14 and the positive real model parameters ,",
    "the argument for the lambert w function evaluation in equation ( [ eqexplicit ] ) is positive , so the principal branch of the lambert w function is being used .",
    "moreover , one is using the principal branch of the natural logarithm function .",
    "everything is single valued in this expression .",
    "however , there can be a numerical difficulty in performing computations with equation ( [ eqexplicit ] ) . making the substitutions ( coordinate changes ) @xmath17 and @xmath18 , the computations involve an evaluation of the function @xmath19    one difficulty which can arise , depending upon the computer programming language used , is numerical underflow or overflow , related to the evaluation of an exponential of @xmath4 where @xmath4 ( negative or positive ) has a large magnitude .",
    "the value of @xmath4 must therefore be restricted to the set of logarithms of floating point numbers whose exponents can be accurately represented in the arithmetic facility of the computer language .",
    "a second difficulty which can arise is that the best computer programming language for the rest of one s problem solution may not have a built - in lambert w function evaluator .    the purpose of this note is to address those two difficulties .",
    "we will describe a simple procedure , which can be implemented in any programming language with floating point arithmetic , for the robust calculation of the function @xmath20 .",
    "the procedure is valid for essentially any real value of @xmath4 which is representable in the programming language .",
    "we may consider the function @xmath21 as a transformation of the lambert w function , with a change of representation or coordinate space . for clarity",
    ", we will restrict to real arguments .",
    "we can think of @xmath22 , the principal branch of the lambert w function , as a mapping of the positive real line to itself .",
    "the function @xmath23 maps the whole real line to the positive real line , and its inverse @xmath24 , the principal branch of the natural logarithm , maps the positive real line to the whole real line . in this interpretation ,",
    "the function @xmath21 is the composition of functions @xmath25 , and it maps the whole real line to the whole real line .",
    "suppose that @xmath20 .",
    "taking exponentials ( ie , applying the function @xmath26 to both sides of the equation ) gives @xmath27 that is , using the definition of the lambert w function , @xmath28 or @xmath29 taking logarithms ( ie , applying the function @xmath30 to both sides ) gives @xmath31    equation ( [ eqyey ] ) is a simple equation structure , as simple as the lambert w defining equation structure @xmath32 in fact , equation ( [ eqyey ] ) is just equation ( [ eqwew ] ) in another coordinate system .",
    "when we are evaluating @xmath21 as the solution to equation ( [ eqyey ] ) , we are just evaluating the lambert w function .",
    "there is an important difference , however : the evaluation of @xmath3 does not involve much risk of underflow or overflow in the numerical representation of the computer language .    since @xmath33 satisfies @xmath34 , the first derivative of @xmath3 satisfies @xmath35 or @xmath36    the second derivative of @xmath3 satisfies @xmath37    figure [ fig - logwexp1 ] shows the function @xmath33 for moderate values of the argument @xmath4 , that is , for @xmath38 .",
    "figure [ fig - logwexp2 ] shows the same function for larger values of the argument @xmath4 , that is , for @xmath39 .",
    "one can see from these graphs that the function @xmath3 behaves like @xmath4 when @xmath4 is much less than 0 , and behaves like @xmath40 when @xmath4 is much more than 0 . for values of @xmath4",
    "around 0 , there is a smooth blend between the two behaviors , with @xmath41 . the function @xmath3 is strictly monotonic increasing , as it has a positive first derivative .",
    "it curves downward , as it has a negative second derivative .",
    "one can further see , from figure [ fig - logwexp2 ] , that when the range of the argument @xmath4 is large , the graph of @xmath33 looks like it has a sharp corner at the origin . actually , as figure [ fig - logwexp1 ] illustrates , the graph does not really have a sharp corner .",
    "nonetheless , at a suitable distance ( large scale ) , one has in the function @xmath42 a useful smooth function for representing a function which has a step in its derivative .",
    "in the terminology of h. kuki ( @xcite page 23 ) , the function @xmath3 is contracting .",
    "that is , @xmath43 , or @xmath44 , for all @xmath4 values in its argument domain .",
    "that means the task of finding an estimate for @xmath3 given @xmath4 is relatively stable .",
    "a slight change in @xmath4 ( noise in the input ) will produce only a slight change in @xmath3 .",
    "the only challenges in developing a formula to estimate @xmath3 , given @xmath4 , are finding an appropriate algorithm , coding the sequence of calculations to avoid unwanted cancellation , and being reasonably efficient in the number of computations performed .",
    "a suitable algorithm can be an initial estimate , followed by some number of iterations of a refinement .",
    "method is used to perform refinements because it has cubic convergence , and the derivatives involved can be calculated efficiently .    given any fixed real number @xmath4 , we wish to find a real number @xmath45 such that @xmath46 is zero .",
    "the first and second derivatives of @xmath47 are needed for halley s method .",
    "they are @xmath48 and hence are particularly easy to calculate .",
    "once one has @xmath49 from the calculation of @xmath47 , the derivatives are also at hand .",
    "it is also necessary , in order to use halley s method , that the first derivative is non - zero ; that is the case for @xmath50 .    as an initial estimate @xmath51",
    ", we choose to use @xmath52 for @xmath53 , and @xmath54 for @xmath55 . for @xmath56 , we linearly interpolate between the two values @xmath57 and 1 .",
    "this is an extraordinarily crude initial estimate , but it is sufficient , since halley s method is very robust and rapidly convergent in this application .",
    "the general iteration formula for halley s method is @xmath58 in this particular case @xmath59 and the iteration formula becomes @xmath60    the details of coding depend upon the computer language .",
    "it will be efficient to evaluate @xmath61 only once per iteration .",
    "all other computations are straightforward arithmetic .",
    "when evaluating the denominator of the adjustment in the iteration equation ( [ eqiter ] ) , there is little risk of cancellation resulting from the subtraction , as the first term in the denominator is larger than the second term .    in practice ,",
    "just a few iterations suffice to give a good result . for arguments in @xmath62 , four iterations of halley",
    "s method reduce the absolute error to less than @xmath63 .",
    "the actual coding can use a convergence criterion , based upon the desired maximum error in the estimate of function value , to determine how many iterations to perform . alternatively ,",
    "if the precision is fixed by the computer language s arithmetic representation or by the needs of the application situation , then one can determine how many iterations of the refinement will suffice , and perform only that number , omitting the final redundant iteration which verifies the convergence .",
    "this technique , due to h. kuki as seen in his algorithms for computing square root ( see @xcite , pages 49 - 50 and 135 - 136 ) , probably deserves a name . perhaps it should be called  kuki s convergence non - test \" .",
    "the author had the good fortune and honor to work for hirondo kuki in 1968 - 69 , and thanks him for his guidance , support and friendship .",
    "he also thanks s. r. valluri for an introduction to the lambert w function and the many interesting problems associated with its properties , and in particular for a stimulating discussion of the topic of this note .",
    "he thanks mark campanelli for suggesting halley s method for iterative refinement in solar cell calculations ."
  ],
  "abstract_text": [
    "<S> the function @xmath0 , where @xmath1 denotes the lambert w function , is the solution to the equation @xmath2 . </S>",
    "<S> it appears in various problem situations , for instance the calculation of current - voltage curves for solar cells . </S>",
    "<S> a direct calculation of @xmath3 may be inaccurate because of arithmetic underflow or overflow . </S>",
    "<S> we present a simple algorithm for calculating @xmath3 that is robust , in that it will work for almost all @xmath4 values which are representable in the arithmetic of one s chosen computer language . </S>",
    "<S> the algorithm does not assume that the chosen computer language implements the lambert w function .    </S>",
    "<S> * a robust approximation to + a lambert - type function * +  + ken roberts + april 8 , 2015 </S>"
  ]
}