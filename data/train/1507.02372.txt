{
  "article_text": [
    "predicting users requests has been playing an important role in operating network systems because the accurate prediction can prevent systems from wasting operational cost and optimize resource utilization .",
    "resource utilization is an especially important issue in cloud systems .",
    "one advantage of cloud systems is automatic scaling and management .",
    "therefore , the accurate prediction of the requests in the cloud systems will bring improvement in operating systems with more advanced resource management techniques .",
    "cloud systems consists of a lot of computing and network devices .",
    "thus , activating the appropriate number of devices based on the requests is an important issue in terms of saving energy .",
    "data centers consumed 91 billion kilowatt - hours of electricity in 2013 and 50 percent of that is wasted due to lack of awareness of the traffic according to [ 1 ] .",
    "this data shows how the accurate prediction of the requests will be increasingly important in the future with an indisputable increase in energy consumption of data centers . also , precise requests prediction has an effect on the performance of cloud systems .",
    "if we inactivate overfull computing or network devices for energy saving purpose , it will cause a bottleneck and delay in handling requests .",
    "there are many research that propose predicting an expected value of the requests with several methods . however , the prediction of the quantified number of requests is not the proper strategy for a stable operation of cloud systems because user requests have heavy fluctuation frequently .",
    "thus , we propose a strategy to predict parameters of the probability distribution of the requests in every regular interval instead of predicting the actual amount of requests .",
    "an advantage of predicting the probability distribution is that we can make the more flexible prediction .",
    "there are always request bursts in networks .",
    "if the system predicts a certain amount of requests based on the average of past requests , cloud systems can not prepare immediate variations of requests .",
    "however , if we are aware of the probability distribution of the requests during a given period , we are able to prevent request bursts by predicting the requests which corresponds to a high probability in the predicted probability distribution .    for the prediction , we collect the history requests data of the cloud and observe the histogram of the data . based on the histogram analysis of the data ,",
    "we decide the probability distribution model fitted to the collected data .",
    "then , we induce parameters of the probability distribution model with maximum likelihood estimation ( mle ) and save the parameter data to the prediction dataset . after we accumulate enough data for the prediction , the prediction model estimates parameters of the probability distribution with local linear regression ( llr ) by using a cyclic window approach",
    ". parameters of the probability distribution are the time - dependent data , which means the parameters are changed as time goes by .",
    "so the parameters have obvious patterns during every interval .",
    "it will reveal the same pattern during a certain period in every day or every week .",
    "so our prediction model will make the prediction by using the accumulated dataset at every same time point through several periods . in order to reflect a change in trend of the requests ,",
    "the prediction model maintains the dataset by replacing an old parameter data with the recent data .",
    "we use google cluster - trace data to test our prediction model , which is real measurements of usage requests in google cluster .",
    "one week data is employed for a training data and the following week data is used for testing in order to verify whether the prediction model is accurate .",
    "we selected random time point to start collecting data so that the prediction model can be tested in more practical environment .",
    "there are three types of data for prediction , the number of task arrivals , cpu requests , and memory requests . since various user requests are predicted and have a large variance in its values , we use mean absolute percentage error ( mape ) to normalize the error rate and assess the prediction accuracy .",
    "the rest of the paper is organized as follows .",
    "previous works are reviewed in section .",
    "we will introduce mathematical methods and the prediction algorithm in section . a system model for an experiment will be demonstrated in section and the experiment results will be shown in section .",
    "the conclusions are given in section .",
    "requests prediction in cloud system is accomplished by many researchers for the automatic scaling of systems .",
    "akindele a. bankole _",
    "et  al_. employ machine learning technique for a predictive resource provisioning in cloud [ 10 ] .",
    "their prediction model is achieved with machine learning techniques : neural network , linear regression , and support vector machine .",
    "they predict the cpu utilization , response time , and throughput based on collected data from virtual machines web servers and database servers .",
    "the prediction model generates prediction values in every given minute with machine learning techniques and measure error rate with mape and root mean squared error ( rmse ) .",
    "however , the prediction model did not show the high prediction accuracy .",
    "their results show @xmath0 prediction error at a certain point of time in predicting the cpu utilization and a @xmath1 error in the response time prediction .",
    "sedeka islam _",
    "et  al_. present more advanced machine learning techniques for predicting resource usage [ 5 ] . the error correction neural network ( ecnn ) and the linear regression techniques are employed for prediction .",
    "they included a sliding window method to reflect the current state of the system .",
    "they have generated prediction values based on window sizes and evaluated them with mape , pred(25 ) , rmse , and @xmath2prediction accuracy .",
    "the cpu utilization data is collected from the amazon ec2 cloud through the tpc - w benchmark and prediction values are generated with the ecnn and linear regression method .",
    "the prediction values of cpu utilization has around @xmath3 error rate without the sliding window and has minimum @xmath4 error rate when they employ the sliding window .",
    "many statistical approaches are also applied to the prediction in cloud .",
    "bruno lopes dalmazo _",
    "et  al_. propose the traffic prediction approach based on the statistical model where observations are weighted with poisson distribution inside a moving window [ 9 ] .",
    "they consider the past information by means of a sliding window of size @xmath5 and this window is applied by weighting the past observations according to the poisson distribution with parameter @xmath5 .",
    "dropbox trace data is employed for testing their prediction model and normalized mean square error ( nmse ) evaluation method is utilized for the error measurement .",
    "the prediction model could achieve nmse values between 0.044 and 0.112 .",
    "the prediction is ideal when nmse value is equal to zero and worse when it is greater than one .",
    "they could achieve the reasonably accurate prediction with this approach .",
    "they also suggest the traffic prediction model with a dynamic window approach [ 8 ] . the sliding window size is changed based on variance of the previous window size .",
    "the small variance indicates the predicted data is close to the meanwhile the high variance means the predicted data is spread out from the mean .",
    "so they update the window size in every prediction interval by considering the size of the variance in the previous prediction .",
    "the prediction accuracy is improved from @xmath6 to @xmath7 compared to the previous statistical model .",
    "the prediction model estimates parameters of the probability distribution of future user requests in every predetermined period .",
    "we make the assumption that user requests have obvious patterns and the patterns are repeated periodically . for example",
    ", the request pattern of all mondays will be a similar .",
    "hence , the prediction model adopts the history parameter data at the same time point in order to make a prediction about the future .",
    "we introduce three time scales for the prediction periods : pattern period ( @xmath8 ) , target period ( @xmath9 ) and utilization period ( @xmath10 ) .",
    "the @xmath8 is a cyclic interval that exhibits pattern repetition .",
    "the @xmath9 is a unit duration for which we want to make a prediction .",
    "the @xmath10 is a cyclic window that we use for predicting the activities in @xmath9 . in the example , when we intend to predict the request distribution during a certain monday by assuming the same pattern is repeated in every week .",
    "then , we can set the @xmath9 to a day and the @xmath8 to a week because we assume the pattern of a day is repeated every week .",
    "if we only use the past mondays@xmath11 data for the prediction , the @xmath10 becomes one day .",
    "since we assume patterns are repeated on the every @xmath8 , any time duration that we want to make a prediction corresponds to a certain @xmath9 on the @xmath8 .",
    "therefore , we can predict the request distribution during any time interval by corresponding them to a certain @xmath9 on the @xmath8 . for the precise prediction",
    ", we accumulate data for several @xmath8s .",
    "although patterns of the traffic distributions will be similar on the same time point in every @xmath8 , the traffic amount will be different .",
    "in other words , we can say the distribution of the traffic shows similar form in every monday , but we can not ensure that the amounts of traffic will be same . therefore , the prediction model can achieve higher prediction accuracy by accumulating data during several @xmath8s .        to implement prediction , the prediction dataset saves the past data in a @xmath12 matrix .",
    "@xmath13 represents the number of @xmath9s on the @xmath8 and @xmath14 denotes the number of @xmath8s we accumulate . in figure 3",
    ", each vertical block corresponds to saved parameters of the probability distribution in each @xmath9 during a @xmath8 .",
    "we start to stack the data from the first block of the first iteration .",
    "if we reach the @xmath15 s block , which is the last tp , we move to the second iteration and stack the data from the first block of the second iteration , which means we have saved data during a @xmath8 . when the matrix is full , we go back to the first block of the first iteration and replace the old data to reflect the tendency of recent requests .    any time duration that we want to predict the traffic distribution for can be related to a certain @xmath9 on the matrix . in order to make a prediction",
    ", we employ the @xmath10 data . in figure 3",
    ", we can see that distribution parameters of the @xmath15 can be predicted by using the @xmath16 .",
    "we can set the size of the @xmath10 depending on how many previous @xmath9s will affect to the state of the current @xmath9 .",
    "for example , if we set the @xmath10 to two days , we can say previous sunday and monday@xmath11s history parameters will affect to next monday@xmath11s traffic distribution as we can see in fig .",
    "3 .    in this paper",
    ", we forecast the number of task arrivals during each target period . the first step of prediction , the prediction model constructs a histogram of user requests in every target period to observe distributions of requests .",
    "then , it fits a probability distribution to the distribution of requests .",
    "when the probability distribution kernel is decided for fitting , we will adopt mle in order to obtain parameters of the probability distribution in every observed period and the parameters are saved on the dataset . after the dataset accumulates enough data for prediction , it is able to predict parameters of a following target period .",
    "local linear regression ( llr ) will be employed to predict parameters of the future requests .",
    "a histogram is the graphical representation of the distribution of data .",
    "we can observe frequencies and overall distribution of given data through a graphical representation .",
    "histograms of requests are constructed in every regular interval to observe the distribution of requests .",
    "after observe the histograms , the prediction model decides which of the probability distribution model will be the closest to the actual distribution of requests .",
    "mle estimates parameters of a probability distribution when there are data corresponding to the probability distribution model . our prediction model",
    "employ the poisson distribution based on the histogram observation of the experiment data . depending on accumulated request data",
    ", the prediction model will induce the poisson distribution parameter by using mle in every @xmath9 .",
    "poisson distribution has the only parameter @xmath5 . since the prediction model has data through observation , the number of task arrivals , cpu , and memory request , it is able to induce parameter @xmath5 by using mle method .",
    "if we observe n independent datasets @xmath17 , @xmath18 , @xmath19 , @xmath20 , @xmath21 @xmath22 poisson random variables , maximum likelihood function l(@xmath5 ) will be :    @xmath23    if we take log in the equation , log likelihood function becomes : @xmath24 we find maximum of @xmath5 by finding the derivative of equation : @xmath25 , which implies the @xmath5 that has closest distribution with observed histogram is : @xmath26      llr is one of the kernel smoother techniques for estimating a real value function , when no parametric model for this function is known .",
    "llr combines much of the simplicity of linear least square regressions by fitting the line about the given @xmath27 number of points with the @xmath28 number of observed points . in the prediction model , the @xmath27",
    "is corresponded to the number of @xmath9s on @xmath10s and @xmath28 is equivalent to the number of history parameters we will employ for the prediction , which is called to bandwidth . after fitting the line at every given point , the estimation functions @xmath29 are achieved as a value function with the @xmath27 numbers of values .",
    "@xmath30 be a kernel defined by :    @xmath31    the @xmath32 is a positive real valued function in ( 5 ) , which is decreasing when the distance between @xmath33 and @xmath34 increases .",
    "the @xmath34 is the given points and the @xmath33 is one of the observed data around @xmath34 . commonly used kernels include the epanechnikov , biweigh and gaussian function . for one dimension data ,",
    "least - square method is employed for obtaining function value on the @xmath34 .",
    "@xmath35    the @xmath28 is the number of history parameter near @xmath34 , that we will employ in ( 6 ) .",
    "since we obtain parameters in each @xmath36 by using mle , the minimum of @xmath37 and @xmath38 can be achieved by solving the weighted least square problem ( 6 ) .",
    "if we assume the estimation function on @xmath34 is @xmath39 , the closed form solution of the estimation function is like : @xmath40 where : @xmath41 @xmath42 @xmath43 by repeating this process about all given @xmath27 points , @xmath34 , we can get real value estimation functions @xmath44 about @xmath27 points .",
    "we describe the algorithm that predicts parameters of the probability distribution of the future target periods by using a cyclic window approach .",
    "we assume the dataset has enough past data for the prediction and determined a probability distribution model for mle",
    ". the algorithm will employ llr to predict the probability distribution parameters of the future target periods and mle for updating dataset .",
    "@xmath45,@xmath46 , @xmath13 , @xmath47 , and @xmath14 @xmath48 and @xmath49 @xmath50,@xmath51 , and @xmath52 @xmath53 , + @xmath54 @xmath55 implement llr in terms of @xmath56 @xmath57 and select @xmath58 value update databased with actual parameter @xmath59 update databased with @xmath60 @xmath61 @xmath62 @xmath63 @xmath51 @xmath64 @xmath52    the algorithm 1 obtains the predicted parameters of target period ( @xmath65 ) for the prediction and actual parameters of target period ( @xmath66 ) to update dataset at every time period .",
    "the @xmath13 means the number of @xmath9s included in a @xmath10 , which is equivalent to a window size .",
    "the @xmath47 is the number of @xmath9s during a @xmath8 .",
    "the @xmath14 represents how many cycles of @xmath8s will be stacked on the prediction dataset ( @xmath67 ) .",
    "the @xmath67 is the prediction dataset has the @xmath12 dimension .",
    "the @xmath46 means observed requests during an interval of the @xmath9 at time @xmath68 .",
    "the prediction model will obtain parameters of the @xmath9 at time @xmath68 with mle by using this data , @xmath46 .",
    "we initialize variables : @xmath68 , @xmath69 , and @xmath70 ( line 1 ) .",
    "the @xmath68 represents how many unit periods are passed after the algorithm starts and the @xmath69 is a corresponding position of the @xmath9 about time @xmath68 .",
    "since we return to the initial position on the @xmath8 when the @xmath69 reaches the end of the @xmath8 , the @xmath69 becomes a cyclic number from @xmath71 to @xmath13 .",
    "the @xmath70 is a row position on the @xmath12 @xmath67 .",
    "too much data requires the complexity of the prediction and consumes too much time for the prediction .",
    "therefore , we stack only the appropriate number of cycles on @xmath67 by replacing the old data .",
    "the @xmath70 is which row position in the @xmath67 will be updated .",
    "first , the algorithm collects the data for the prediction from the @xmath67 to the @xmath56 ( line 2 @xmath72 line 7 ) .",
    "if the position @xmath69 is less than the window size @xmath47 , we need to employ the data from the end of the @xmath67 because the @xmath69 is cyclic .",
    "so we collect the data from @xmath73 to @xmath74 columns data and from the first to @xmath75 columns of @xmath67 ( line 3 @xmath72 line 4 ) .",
    "if the @xmath69 is greater than the window size @xmath47 , we collect previous @xmath47 columns data from the point @xmath69 on the @xmath67 ( line 5 @xmath72 line 7 ) .",
    "we implement llr about the collected data , @xmath56 , and obtain the prediction value about time @xmath68 ( line 8 @xmath72 line 9 ) . in order to update the @xmath67",
    ", we need to obtain the actual probability distribution parameters of observed requests .",
    "we apply mle about the data @xmath46 and update corresponding data block in @xmath67 ( line 10 @xmath72 line 13 ) .",
    "we update the position on the @xmath67 for next prediction .",
    "we update the @xmath68 for predicting next time point ( line 14 ) .",
    "we just increase the @xmath69 if the position of the @xmath69 is still on @xmath8 .",
    "if the @xmath69 exceeds the size of @xmath8 , @xmath13 , it goes back to the initial position of the @xmath8 .",
    "we also update the @xmath70 when @xmath69 goes back to the initial position because that means one row of @xmath67 is filled with new data .",
    "the @xmath70 increases when the @xmath69 increases .",
    "however , the @xmath70 becomes one if the @xmath70 exceeds @xmath14 , which is vertical size of the matrix @xmath67 ( line 15 @xmath72 line 23 ) .",
    "the experiment is implemented with google cluster - usage traces data [ 14 ] .",
    "google cluster is a set of computing resources composed of thousands of machines .",
    "a job is composed of several tasks which can be processed separately .",
    "so each task will be a unit of a process .",
    "we consider the number of task arrivals , cpu requests , and memory requests of tasks .",
    "each task has a timestamp which represents when the task arrives at the cluster .",
    "therefore , the distribution of the number of task arrivals can be observed by using the timestamp .",
    "the cluster data also contains the cpu and memory requests of each task .",
    "the cpu requests show core counts or core - seconds / second of tasks and the memory requests represent how much bytes each task requires .",
    "the cluster starts measurement 600 seconds after the system is operated and has accumulated data for one month approximately .",
    "we select a random point to collect data for the prediction model .",
    "one weak data is sampled as a training dataset for the prediction modeling and the following week data is employed to test the accuracy of the prediction model .",
    "all experiments are conducted by matlab .",
    "basically , user requests have a regular pattern .",
    "requests increases during the daytime and weekdays more than the nighttime and weekend .",
    "we could observe some patterns by analyzing the google trace data .",
    "the start time of trace is randomly chosen in data .",
    "so we do not know what the exact date or time of measurement points . however , our assumption is arriving tasks will show regular patterns in every interval .",
    "figure 2 shows patterns of task arrivals during a week .",
    "the number of task arrivals is counted for every one hour , so we could observe how many tasks arrive at the cluster in every hour during the week .",
    "the hourly pattern shows high peaks for the first 4 hours and the last 10 hours .",
    "so we can assume daytime starts around the tenth hours from the measurement because the number of tasks is increased from the tenth hour and end at the fourth hour in figure 2 .",
    "if we see the daily pattern , the first two days and the last two days show higher requests . in the same way",
    ", we can assume weekdays start on the fourth day from the measurement by assuming requests increases during weekdays rather than the weekend .",
    "the daily pattern analysis of task arrivals presents obvious patterns of the incoming requests .",
    "therefore , the cyclic data collection should be an effective approach for the prediction .",
    "the daily pattern analysis of the cpu and memory requests also have demonstrated the similar patterns with task arrivals .",
    "the cpu and memory requests have had high requests when the number of task arrivals increases and had low requests during free periods .    according to our observation",
    ", we have decided to set the @xmath8 to one week because we could observe hourly and daily patterns of requests repeatedly during every week .      according to the experiment",
    ", we found that too short @xmath9 is not enough to observe apparent patterns of distribution of requests .",
    "thus , the @xmath9 is set to 30 minutes based on empirical observation .",
    "the prediction model predicts distribution parameters in every 30 minutes .",
    "as patterns are observed in figure 2 , the number of task arrivals show an apparent pattern depending on the time .",
    "figure 3 represents the number of task arrivals in every 30 minute during the first day . for the first 4 hours and the last 10 hours , figure 3 presents high rate of incoming tasks .",
    "histograms of each target period are different depending on the total number of task arrivals .",
    "histograms have high peaks in the more right side during the busy hours and they have high peaks in the more left side during the free hours .",
    "figure 4 is a histogram of the first hour .",
    "the first histogram exhibits the distribution of task arrivals during the first half hour and the second histogram presents the distribution of the second half hour .",
    "the first histogram has a peak in more right side than the second histogram because the cluster received higher task arrivals during the first half hour than the second half hour .",
    "this trend is similar to the poisson distribution .",
    "the poisson distribution has a high peak in the more right side when the rate parameter @xmath5 is high .",
    "therefore , the observed data will be fitted to the poisson distribution by using mle to obtain parameters of the poisson distribution in every duration .",
    "mle is employed to obtain parameters of the poisson distribution in every target period .",
    "the estimated poisson distribution are achieved about the first half hour histogram by using mle in figure 5 .",
    "the first graph shows the poisson distribution with estimated parameters and the second graph is a histogram of task arrivals during the first half hour .",
    "we can observe the estimated poisson distribution has a similar distribution with the histogram of data .",
    "the prediction model implements mle in every 30 minute and saves them to the prediction dataset .",
    "parameters are induced from the request data in every 30 minute .",
    "parameters generated at the same time point on the @xmath8 are stacked in the same column of the prediction dataset .",
    "predicted parameters are achieved by implementing llr about the corresponding @xmath10 . for example , if we implement llr about the @xmath10 including the first to the @xmath76 @xmath9 to predict the duration corresponding to @xmath76 @xmath9 , the last point value of llr function becomes the prediction value of the @xmath76 target period .",
    "prediction values are changed depending on how to set the utilization periods and how much bandwidth we adopt for llr .",
    "the bandwidth represents how many near data are included when we predict the function value of a certain point .",
    "estimation of arrival tasks , scaledwidth=40.0% ]    figure 6 represents the prediction of poisson distribution parameter @xmath5 of arriving tasks during week .",
    "since we set the @xmath9 to 30 minutes , we have 336 target periods during the week .",
    "blue points represent parameter values of training dataset in each @xmath9 and green points are parameter values of test dataset in each @xmath9 .",
    "solid lines represent parameter prediction values for different values of bandwidth .",
    "we set the @xmath10 to 25 hours in fig .",
    "4 , which means that prediction value is obtained base on the last @xmath77 hours data .",
    "parameter @xmath5 is equivalent to mean number of arrivals during 30 minutes .",
    "we can observe that the graph has a regularly repeated pattern .",
    "it has seven high peaks in the graph , which means similar patterns repeated during the week .",
    "prediction values of parameters are obtained about the cpu and memory requests as well in the same method .",
    "figure 7 is the parameter prediction of the cpu and memory requests .",
    "we obtain prediction values in the same method with task arrivals .      in order to quantify an accuracy of the prediction",
    ", we measure mean absolute percentage error ( mape ) between the prediction data and the test dataset .",
    "mape expresses an error rate as a percentage .",
    "so we can compare the prediction accuracy of task arrivals , cpu requests , and memory requests with a normalized error rate value .",
    "@xmath78    the @xmath79 is a predicted value of a target value , @xmath80 .",
    "mape value is equal to zero when the prediction model is the perfect fit to the target value and increased when the prediction is not properly fit to target values .",
    "[ fig : nrgroup ]    figure 8 is mape measurement graph of the poisson distribution parameter @xmath5 .",
    "the parameter @xmath5 has mape range between 0.3885 and 0.5194 .",
    "if we consider the ideal state of mape is zero , the prediction model has enough prediction accuracy .",
    "the prediction model could achieve a higher accuracy with the longer @xmath10 , which is equivalent the window size because increasing the @xmath10 means employing more previous data for the prediction .",
    "however , the large @xmath10 requires more complexity of a computation and consumes more time . in other words , a proper selection of the @xmath10",
    "is required to satisfy both of the prediction accuracy and the computation time .",
    "choosing the best bandwidth is also an important issue in order to reduce the prediction error .",
    "too small bandwidth causes very spiky estimates while large bandwidth leads over smoothing . if data values are spread widely , the smaller bandwidth will not acquire the higher prediction accuracy .",
    "[ fig : nrgroup ]    we compare the prediction accuracy of cyclic window learning algorithm with poisson based statistical algorithm that suggested in [ 9 ] .",
    "we selected the prediction values obtained with bandwidth 20 and compared them with the prediction result of poisson based statistical algorithm in figure 9 . in the result",
    ", we could observe that the cyclic window learning algorithm presents slightly better prediction accuracy when we employed small @xmath10s .",
    "however , the cyclic window learning algorithm could improve the performance up to 13.6@xmath81 when we employ more @xmath10s data .",
    "we propose a novel approach for the request prediction in cloud systems . instead of predicting an actual amount of requests , our prediction model estimates parameters of the probability distribution during the given period .",
    "we accumulate the historical data of the system and a cyclic window approach to utilize data with mle and llr . in the experiment with google cluster - trace data",
    ", we could ensure advanced performance of the prediction algorithm .",
    "our prediction model achieves the very low level of error rates in predicting the probability distribution parameters .",
    "s.  islam , j.  keung , k.  lee , and a.  liu , _ empirical prediction models for adaptive resource provisioning in the cloud _ , future generation computer systems , vol 28 , pp 155 - 162 .",
    "1em plus 0.5em minus 0.4emjanuary 2012 .",
    "e.  caron and f.  desprez , _",
    "forecasting for grid and cloud computing on demand resources based on pattern matching _ , proceeding on ieee cloud computing technology and science ( cloudcom ) , pp 456 - 463 .",
    "1em plus 0.5em minus 0.4emnovember 2010 .",
    "b.  l.  dalmazo , j.  p.  vilela , and m.  curado , _ onlinetraffic prediction in the cloud : a dynamic window approach _ , proceeding on ieee cloud and green computing ( cgc ) , pp 9 - 14 .",
    "1em plus 0.5em minus 0.4emaugust 2014 .",
    "b.  l.  dalmazo , j.  p.  vilela , and m.  curado , _ predicting traffic in the cloud : a statistical approach _ , proceeding on ieee cloud and green computing ( cgc ) , pp 121 - 126 .",
    "1em plus 0.5em minus 0.4emoctober 2013 .",
    "a.  a.  bankole and s.  a.  ajila , _ predicting cloud resource provisioning using machine learning techniques_,proceeding on ieee electrical and computer engineering ( ccece ) , pp 1 - 4 .",
    "1em plus 0.5em minus 0.4emmay 2013 .",
    "t.  wood , l.  cherkasova , k.  ozonat , and p.  shenoy , _ profiling and modeling resource usage of virtualized application_,proceeding of the 9th acm / ifip / usenix international conference on middleware , pp 386 - 387 .",
    "1em plus 0.5em minus 0.4emdecember 2008 .",
    "l.  lio , x.  jin , g.  min , and l.  xu , _ real - time diagnosis network anomaly based on statistical traffic analysis_,proceeding on ieee trust , security , and privacy in computing and communications ( trustcom ) , pp 264 - 270 .",
    "1em plus 0.5em minus 0.4emjune 2012 .",
    "j.  yang , c.  liu , y.  shag , z.  mao , and j.  chen , _ workload predicting based automatic scaling in service clouds_,proceeding on ieee 6th international conference on cloud computing , pp 810 - 815 .",
    "1em plus 0.5em minus 0.4emjune / july 2013 ."
  ],
  "abstract_text": [
    "<S> automatic resource scaling is one advantage of cloud systems . </S>",
    "<S> cloud systems are able to scale the number of physical machines depending on user requests . </S>",
    "<S> therefore , accurate request prediction brings a great improvement in cloud systems performance . </S>",
    "<S> if we can make accurate requests prediction , the appropriate number of physical machines that can accommodate predicted amount of requests can be activated and cloud systems will save more energy by preventing excessive activation of physical machines . also , cloud systems can implement advanced load distribution with accurate requests prediction . </S>",
    "<S> we propose an algorithm that predicts a probability distribution parameters of requests for each time interval . </S>",
    "<S> maximum likelihood estimation ( mle ) and local linear regression ( llr ) are used to implement this algorithm . </S>",
    "<S> an evaluation of the proposed algorithm is performed with the google cluster - trace data . </S>",
    "<S> the prediction is implemented about the number of task arrivals , cpu requests , and memory requests . </S>",
    "<S> then the accuracy of prediction is measured with mean absolute percentage error ( mape ) . </S>"
  ]
}