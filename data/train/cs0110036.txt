{
  "article_text": [
    "cross - validation is a generally applicable and very useful technique for many tasks often encountered in machine learning , such as accuracy estimation , feature selection or parameter tuning .",
    "it consists of partitioning a data set @xmath0 into @xmath1 subsets @xmath2 and then running a given algorithm @xmath1 times , each time using a different training set @xmath3 and validating the results on @xmath2 .",
    "cross - validation is used within a wide range of machine learning approaches , such as instance based learning , artificial neural networks , or decision tree induction . as an example of its use within decision tree induction , the cart system @xcite employs a tree pruning method that is based on trading off predictive accuracy versus tree complexity ; this trade - off is governed by a parameter that is optimized using cross - validation .",
    "while cross - validation has many advantages for certain tasks , an often mentioned disadvantage is that it is computationally expensive .",
    "indeed , @xmath1-fold cross - validation is typically implemented by running the same learning system @xmath1 times , each time on a different training set of size @xmath4 times the size of the original data set . because of this computational cost , cross - validation is sometimes avoided , even when it is agreed that the method would be useful .",
    "it is clear , however , that when ( for instance ) a specific decision tree induction algorithm is run several times on highly similar datasets , there will be redundancy in the computations .",
    "e.g. , when selecting the best test in a node of a tree , the test needs to be evaluated against each individual example in the training set . in an @xmath1-fold cross - validation",
    "each example occurs @xmath5 times as a training example , which means that each test will be evaluated on each training example @xmath5 times .",
    "the question naturally arises whether it would be possible to avoid such redundant computations , thereby speeding up the cross - validation process . in this text",
    "we provide an affirmative answer to this question .",
    "this paper is organised as follows . in section 2",
    "we focus on refinement of a single node of the tree ; we identify the computations that are prone to the kind of redundancy mentioned above , indicate how this redundancy can be reduced , and analyse to what extent performance can thus be improved . in section 3 we discuss the whole tree induction process , showing how our adapted node refinement algorithm fits in several tree induction algorithms . in section 4",
    "we present experimental results for one of these algorithms that support our complexity analysis , supporting our main claim that cross - validation can be integrated with decision tree induction in such a way that it causes only a small overhead . in section 5",
    "we briefly discuss to what extent the results generalize to other machine learning techniques , and mention the limitations of our approach . in section 6",
    "we conclude .",
    "we describe decision tree induction algorithms only in such detail as needed for the remainder of this text , for more details see quinlan ( 1993 ) or breiman et al .",
    "( 1984 ) .",
    "xxx = xxx = xxx = xxx = xxxxxx = ( @xmath6 : set of examples ) + decision tree : + @xmath7 : = optimal_test(@xmath6 ) + @xmath8 : = partition induced on @xmath6 by @xmath7 + stop_criterion(@xmath8 ) + ( info(@xmath6 ) ) +   + @xmath9 * in * @xmath8 : + @xmath10 : = grow_tree(@xmath9 ) + ( @xmath7 , @xmath11 ) +    decision trees are usually built top - down , using an algorithm similar to the one shown in figure  [ tdidt : alg ] . basically , given a data set , a node is created and a test is selected for that node . a test is a function from the example space to some finite domain ( e.g. , the value of a discrete attribute , or the boolean result of a comparison between an attribute and some constant ) .",
    "each test induces a partition of the data set ( with each test result one subset is associated ) , and typically that test is selected for which the subsets of the partition are maximally homogeneous w.r.t .",
    "some target attribute ( the `` class '' , for classification trees ) . for each subset of the partition , the procedure is repeated and the created nodes become children of the current node .",
    "the procedure stops when stop_criterion succeeds : this is typically the case when no good test can be found or when the data set is sufficiently homogeneous already . in that case the subset becomes a leaf of the tree and in this leaf information about the subset is stored ( e.g. , the majority class ) .",
    "the result of the initial call of the algorithm is the full decision tree .",
    "the refinement of a single node ( selecting the test and partitioning the data ) can in more detail be described as follows :    xxx = xxx = xxx = xxx = tests @xmath12 that can be put in the node : + examples @xmath13 in the training set @xmath6 : + update_statistics(s[@xmath12 ] , @xmath15 , target(@xmath13 ) ) + q[t ] : = compute_quality(s[t ] ) + @xmath7 : = argmax@xmath16 @xmath17 $ ] + partition @xmath6 according to @xmath7    the computation of the quality of a test @xmath12 is split into two phases here : one phase where statistics on @xmath12 are computed and stored into an array @xmath18 $ ] , and a second phase where the quality is computed from the statistics ( without looking back at the data set ) . for instance , for classification trees , phase one could compute the class distribution for each outcome of the test.$ ] is then a matrix indexed on classes and results of @xmath12 , and update_statistics(@xmath18 $ ] , @xmath15 , @xmath19 ) just increments @xmath18_{t(e),class(e)}$ ] by 1 .",
    "] quality criteria such as information gain or gain ratio @xcite can easily be computed from this in phase two . for regression , using variance as a quality criterion @xcite , a similar two - phase process can be defined : the variance can be computed from @xmath20 where the @xmath21 are the target values .",
    "now assume that the node refinement process , as described above , is repeated several times , each time on a slightly different data set @xmath22 ( i.e. , the @xmath22 have many examples in common ) .",
    "we assume here that the same set of tests is considered in all these nodes .",
    "then instead of running the process @xmath1 times , with @xmath1 the number of data sets , the following algorithm can be used :    xxx = xxx = xxx = xxx = test @xmath12 that can be put in the node + example @xmath13 in @xmath23 : + @xmath24 such that @xmath25 : + update_statistics(s[@xmath22 , @xmath12 ] , @xmath15 , target(@xmath13 ) ) + @xmath22 : + @xmath26 $ ] : = compute_quality(@xmath27 $ ] ) + * for each * @xmath22 : + @xmath28 : = argmax@xmath16 @xmath29 $ ] + * for each * _ different _ test @xmath7 among the @xmath30 : + partition @xmath31 according to @xmath7 +    this algorithm performs the same computations as running the original one once on each data set , except for two differences :    * for each test @xmath12 , each single example @xmath13 is tested only once instead of @xmath32 times , where @xmath32 is the number of data sets the example occurs in . *",
    "each single example @xmath13 is sorted into a child node @xmath33 times , instead of @xmath32 times , with @xmath33 the number of different best tests for all the data sets where the example occurred ( obviously @xmath34 ) .",
    "note that in each node of the tree multiple tests ( at most @xmath1 ) , and correspondingly multiple sets of child nodes , may now be stored instead of just one .      for an @xmath1-fold cross - validation ,",
    "each single example occurs exactly @xmath5 times as a training example .",
    "hence , the time needed to compute the statistics of all tests is reduced by a factor @xmath5 compared to running the original algorithm @xmath1 times .",
    "the time needed to sort examples into child nodes is reduced by @xmath5 if the same test is selected in all folds , otherwise a smaller reduction occurs . besides this speedup there are no changes in the computational complexity of the algorithm ( except for the extra computations involved in , e.g. , selecting elements from a two - dimensional array instead of a one - dimensional array ) .    specifically for cross - validation , the algorithm can be further improved if the employed statistics @xmath35 , for any data set @xmath0 , can be computed from the corresponding statistics of its subsets in a partition .",
    "this holds for all statistics that are essentially sums ( such as those mentioned in section  [ sec21 ] ) , since in that case @xmath36 .",
    "such statistics could also be called _",
    "additive_.    in an @xmath1-fold cross - validation , the data set @xmath0 is partitioned into @xmath1 sets @xmath2 , and the training sets @xmath22 can be defined as @xmath37 .",
    "it is then sufficient to compute statistics just for the @xmath2 ; those for the @xmath22 can be easily computed from this without further reference to the data ( first compute @xmath36 ; then @xmath38 ) .",
    "since each example occurs in exactly 1 of the @xmath2 , updating statistics has to be done only @xmath39 times instead of @xmath40 times ( with @xmath39 the number of examples ) .      in practice , cross - validation",
    "is usually performed in addition to building a tree from the whole data set : this tree is then considered to be the actual hypothesis proposed by the algorithm , and the cross - validation is done just to estimate the predictive accuracy of the hypothesis or for parameter tuning . the algorithm for efficient cross - validation can easily be extended so that it builds a tree from the whole data set in addition to the cross - validation trees ( just add a virtual fold 0 where the whole data set is used as training set ; note that @xmath41 ) . adopting this change , we obtain the algorithm in figure  [ finalalg ] . in the remainder of this text",
    "we will refer to this algorithm as the _ parallel algorithm _ , as opposed to the straightforward method of running all cross - validation folds and the actual tree induction serially ( the _ serial algorithm _ ) .",
    "xxx = xxx = xxx = xxx = \\",
    "{ @xmath0 is the set of all examples relevant for this node , + partitioned into @xmath1 subsets @xmath2 , @xmath42 .",
    "+ @xmath43 , and for @xmath44 @xmath45 } + 1 .",
    "test @xmath12 that can be put in the node + 2 .",
    "example @xmath13 in @xmath0 : + 3 .",
    "choose @xmath24 such that @xmath46 + 4 .",
    "update_statistics(@xmath47 $ ] , @xmath15 , target(@xmath13 ) ) + 5 .",
    "compute @xmath48 $ ] ( @xmath49 ) from all @xmath50 $ ] + 6 .",
    "@xmath22 : + 7 .",
    "@xmath26 $ ] : = compute_quality(@xmath27 $ ] ) + 8 .",
    "@xmath22 : + 9 .",
    "@xmath28 : = argmax@xmath16 @xmath29 $ ] + 10 .",
    "test @xmath7 among the @xmath30 : + 11 .",
    "partition @xmath31 according to @xmath7 +    at this point , we have discussed the major issues related to the refinement of a single node .",
    "the next step is to include this process into a full tree induction algorithm .",
    "this will be discussed in the next section , but first we take a look at the complexity of the node refinement step .",
    "let @xmath51 be the time for extracting relevant information from a single example ( i.e. , the example s target value and test result ) and updating the statistics matrix @xmath35 ( in other words , executing line 4 in the algorithm in figure  [ finalalg ] once ) ; @xmath52 the time needed to test an example and sort it into the correct subset during partitioning ; @xmath39 the number of examples in the data set , @xmath1 the number of folds , and @xmath53 the number of tests .",
    "then we obtain the following times for refining a single node ( the @xmath54 denote terms constant in @xmath39 ) :    * when building one tree from the full data set : @xmath55 * when performing cross - validation serially : + @xmath56 + @xmath57 * when serially building the actual tree and performing a cross - validation : + @xmath58 * when using the parallel algorithm , worst case ( all folds select different tests ) : + @xmath59 * when using the parallel algorithm , best case ( all folds select the same test ) : + @xmath60    our analysis gives rise to approximate upper bounds on the speedup factors that can be achieved .",
    "assuming large @xmath39 so that the @xmath54 terms can be ignored ( hence `` approximate '' ) , for the worst case we get @xmath61 and @xmath62 < a t_e + t_p t_p = 1 + a t_e t_p    hence the worst case speedup factor is bounded by @xmath63",
    ". it will approximate @xmath1 when a ) @xmath39 becomes large and b ) @xmath52 is small compared to @xmath64 .",
    "in the best case , where the same test is selected for all folds , we just get @xmath65 : the speedup factor approaches @xmath1 as soon as @xmath39 becomes large .",
    "another way to look at this is to observe that @xmath66 approaches one ; in other words , for large @xmath39 and a stable problem ( where small perturbations in the data do not lead to different tests being selected ) the overhead caused by performing cross - validation becomes negligible .",
    "we now describe how the above algorithms for node refinement fit in decision tree induction algorithms .",
    "first we describe the data structures , which are more complicated than when growing individual trees .",
    "next we discuss several decision tree induction techniques and show how they can exploit the above algorithms .",
    "since the parallel cross - validation algorithm builds multiple trees at the same time , we need a data structure to store all these trees together . we refer to this structure as a `` forest '' , although this might be somewhat misleading as the trees are not disjoint , but may share some parts .",
    "an example of a forest is shown in figure  [ forest : fig ] . in this figure",
    "two kinds of internal nodes are represented .",
    "the small squares represent bifurcation points , points where the trees of different folds start to differ because different tests were selected .",
    "the larger rectangles represent tests that partition the relevant data set .",
    "the way in which the trees in the forest split the data sets is illustrated by means of an example data set of 12 elements on which a three - fold cross - validation is performed .",
    "note that the memory consumption of a forest is ( roughly ) at most @xmath67 times that of a single tree ( this happens when at the root different tests are obtained for all @xmath1 folds plus the actual tree ) , which in practice is not problematic since @xmath1 usually is small .",
    "when in the following we refer to nodes in the forest , we always refer to the test nodes , making abstraction of bifurcation points .",
    "e.g. , in figure  [ forest : fig ] the root node has five children , three of which are leaves .        probably the best known approach to decision tree induction is quinlan s ( 1986 ) id3 algorithm , later developed into c4.5 @xcite .",
    "id3 basically follows the depth - first approach of figure  [ tdidt : alg ] . the simplest way to adapt an id3-like algorithm to perform cross - validation in parallel with the actual tree building , is to make it use the node refinement algorithm of figure  [ finalalg ] and call the algorithm recursively for each child node created .",
    "note that the number of such child nodes is now @xmath68 , with @xmath69 the number of different tests selected as best test in some fold and @xmath70 the number of possible results of the @xmath24-th test .    in this way",
    ", the above mentioned speedup is obtained as long as the same test is chosen in all cross - validations and in the actual tree .",
    "the more different tests are selected , the less speedup is achieved ; and when in each fold a different test is selected , the speedup factor goes to 1 ( all folds are handled separately ) . to see how this process influences the total forest induction time ,",
    "let us define @xmath71 as the average time that is needed to refine all the nodes of a single tree on level @xmath24 for a data set of size @xmath72 , and @xmath73 as the average number of different tests selected on level @xmath24 of the forest ( averaged over all nodes on that level of the forest ) .",
    "the computational complexity of the whole forest building process can then be approximated as @xmath74 for the parallel version , and , assuming that refinement time is linear in the number of examples in nodes that are to be refined ,- fold cross - validation the actual refinement time for level @xmath24 is @xmath75 . ] @xmath76 for the serial version ( we obtain @xmath77 and not @xmath78 because the @xmath1 folds have size @xmath79 ) .    thus the total speedup will be between 1 and @xmath1 , and will be higher for stable problems ( low @xmath73 ) than for unstable problems ( most @xmath73 close to @xmath67 ) .",
    "most decision tree induction algorithms assume that all data reside in main memory .",
    "when inducing a tree from a large database , this may not be realistic : data have to be loaded from disk into main memory when needed , and then for efficiency reasons it is important to minimize the number of times each example needs to be loaded ( i.e. , minimize disk access ) .",
    "to that aim alternative tree induction algorithms have been proposed @xcite that build the tree one whole level at a time , where for each level one pass through the data is required .",
    "the idea is to go over the data and for each example , update statistics for all possible tests in the node ( of the currently lowest level of the tree ) where the example belongs . for each node the best test",
    "is then selected from these statistics without more access to the data .    since in these approaches , too , the computation of the quality of tests is split up into two phases ( computing statistics from data , computing test quality from statistics ) , it is easy to see how such level - wise algorithms can be adapted .",
    "when processing one example , instead of looking up the single node in the tree where the example belongs , one should look up all the nodes in the forest where the example belongs ( for an example not yet in a leaf this is at least one node and at most @xmath5 nodes , with @xmath1 the number of folds ) and update the statistics in all these nodes .",
    "when data reside on disk , the number of examples is typically large and both @xmath51 and @xmath52 are large ( due to external data access ) .",
    "the constant terms @xmath54 then become negligible very quickly , and the speedup factor can approach @xmath1 if @xmath80 . assuming that @xmath52 and @xmath51 are comparable , this will be true as soon as @xmath81 , which in practice often holds .",
    "as soon as different tests are selected for different folds , the forest induction process bifurcates in the sense that from that point onwards different trees in the forest will be handled independently .",
    "a further optimisation that comes to mind , is removing redundancy among computations in these independently handled trees as well .    referring to figure  [ forest : fig ] , among the different branches created by a bifurcation point ( square node )",
    "there may still be some overlap with respect to the tests that will be considered in the child nodes , as well as the relevant examples .",
    "for instance , in the lower right of the forest in figure  [ forest : fig ] , in the children of the `` test b '' node one needs to consider all tests except a and b , and in the children of the test c node one needs to consider all tests except a and c. since the relevant example set for fold @xmath82 at that point ( \\{2,3,5 } ) overlaps with that of folds @xmath83 and @xmath84 ( \\{2,3,5,10,12 } ) , all tests besides @xmath85 , @xmath86 and @xmath87 will give rise to some redundant computations .    removing this redundancy as well would give rise to a more thorough redesign of the forest induction process ; it seems that for best results the depth - first tree induction method should be abandoned , and a level - wise method adopted instead . here",
    "we will not discuss this optimisation any further but focus on the above described algorithm , which is simple and compatible with both tree induction approaches and can easily be integrated in existing tree induction systems .",
    "we implemented algorithm [ finalalg ] as a module of tilde @xcite , an ilp system ( inductive logic programming @xcite ) that induces first order decision trees ; briefly , these are decision trees where a test in a node is a first order literal or conjunction , and a path from root to leaf can be interpreted as a horn clause .",
    "literals belonging to different nodes in such a path may share variables .",
    "a typical property of ilp systems in general , and tilde is no exception , is that because tests are first order conjunctions , both the number of tests and the time needed to perform a test may be large .",
    "this translates to large @xmath53 , @xmath51 and @xmath52 values in our complexity analysis , which makes it reasonable to expect a speedup factor close to @xmath1 for refinement of the top node of the tree ; and close to @xmath88 for nodes on level @xmath24 .      for these experiments we used the version of tilde as implemented within the ace data mining tool @xcite ; this version is a depth - first id3-like algorithm that keeps all data in main memory . with these experiments we aim at a better understanding of the behaviour of the parallel cross - validation process .",
    "we measure how much speedup the parallel procedure yields , compared to the serial one ; how the overhead of the parallel procedure varies with the number of folds ; and how much time is spent by both procedures on different levels of the tree .",
    "the parallel and serial procedures make use of exactly the same implementation of tilde except for the differences between parallel and serial execution as described in this text .",
    "the different procedures are compared pairwise for the following data sets :    * * sb * ( simple bongard ) and * cb * ( complex bongard ) : several artificially generated sets of so - called `` bongard '' problems @xcite ( pictures are classified according to simple geometric patterns ) .",
    "sb contains 1453 examples with a simple underlying theory , cb 1521 examples with a more complex theory . * * muta * : the mutagenesis data set @xcite , an ilp benchmark ( 230 examples ) * * asm * : a subset of 999 examples of the so - called `` adaptive systems management '' data set , kindly provided to us by perot systems nederland . * * mach * : `` machines '' , a tiny data set ( 15 examples ) described in @xcite    the number of tests in each node varied from 3 to a few hundred ( as tests are first - order clauses , their number may vary greatly even among nodes of the same tree ) .",
    "table  [ timings : tab ] compares the actual tree building time @xmath89 , the time for serially performing 10-fold cross - validation in addition to the actual tree building @xmath90 , and the time needed by the parallel algorithm @xmath91 .",
    "in addition to these , the speedup factor @xmath92 is shown as as well as the overhead caused by performing the cross - validation ( @xmath93 , similarly for @xmath94 ) . @xmath95 and @xmath94 are plotted graphically in figure  [ timings : fig ] .",
    ".[timings : tab]timings of parallel and serial execution on various data sets ( in seconds ) . [ cols=\"<,<,<,<,<,<,<\",options=\"header \" , ]     the lowest overhead is achieved for simple bongard , which has a relatively large number of examples and a simple theory .",
    "the simplicity of the true theory causes the induced trees to be exactly the same in most folds , yielding little bifurcation . for complex bongard ,",
    "the effect of bifurcation is more prominent . for asm ,",
    "a real - world data set for which a perfect theory may not exist , the overhead of cross - validation is relatively high ( but still better than for the serial algorithm ) . for machines ,",
    "the overhead is relatively large but still smaller than for the serial algorithm ; i.e. , even for small example sets the parallel algorithm yields a speedup . for mutagenesis we obtained less good results .",
    "two factors turned out to be responsible for this : instability of the trees , but also high variance in the complexity of testing examples .",
    "the latter is due to the fact that first - order queries have exponential worst - case complexity ; most of them are reasonably fast , but a very few of them may dominate the others , time - wise .",
    "such behaviour typically occurs at lower levels of the tree , as will be confirmed when we look at figure  [ nfold - fi : fig ] .",
    "figure  [ nfolds : fig ] shows how cross - validation overhead varies with the number of folds for the cb and asm data sets . the result for",
    "cb confirms our expectation that @xmath1 has a small influence on the total time , but for asm the overhead increases with increasing @xmath1 .",
    "the latter result can be understood by looking at the graphs in figure  [ nfold - fi : fig ] , where the total time spent on each level of the tree by the parallel and the serial procedure is plotted , together with the @xmath96 values as defined previously .",
    "the graphs clearly show that when @xmath69 goes up , the per - level speedup factor is reduced . for cb",
    ", this happens at a point where the total refinement time is already small , so it does not influence the overall speedup factor much ; but for asm and muta @xmath69 increases almost immediately .",
    "note that in the part where @xmath69 is high , many folds are handled independently and cross - validation becomes linear in @xmath1 , which explains the increase of the asm data in figure  [ nfolds : fig ] .",
    "it is also clear in figure  [ nfold - fi : fig ] how the time spent on some lower levels suddenly goes up ; this is the effect of stumbling upon some very complex tests .",
    "although we have studied efficient cross - validation in the context of decision trees , the principles explained here are also applicable outside this domain .",
    "for instance , rule set induction systems typically build a rule by consecutively adding a `` best '' condition to it until no further improvement occurs .",
    "similar to our forest - building algorithm , cross - validation of such rules could be performed in parallel with the construction of the actual rule set , avoiding redundant computations .",
    "it is less clear , however , how the technique could be used with models that contain only continuous parameters , such as neural networks .",
    "we obtain the greatest speedups for stable trees , where the same test is chosen in different folds . with continuous models",
    ", no computations will ever be exactly the same , hence removal of exactly redundant computations as explained here will in general not be possible .    also within decision tree induction",
    "a number of limitations exist .",
    "a first one is related to the use of continuous parameters in the tree .",
    "decision tree induction systems often construct inequality tests for continuous attributes ( e.g. , @xmath97 ) where the constant is generated from the currently relevant data . even for stable problems where the same test is usually selected for different folds",
    ", there may be small differences in the constants that make the tests look different .",
    "solving this problem requires extra optimisations .",
    "a second limitation is that the proposed techniques concern the tree building phase only .",
    "this phase is typically followed by tree post - pruning , and may be preceded by data pre - processing , such as discretization of attributes @xcite . while these other phases usually take much less time than the tree building phase , when they are not negligible and @xmath1 is large they may become the bottleneck , limiting the usefulness of our approach ( unless optimisations similar to the ones discussed here are also possible in these phases ) .",
    "we have shown that in the context of decision tree induction the benefits of cross - validation are available for a relatively low overhead , if the cross - validation is carefully integrated with the normal tree building process .",
    "comparing experimental results with an analytical estimate of this overhead , we have identified a number of disturbing factors , such as variance in test complexity ( which causes variance in the overhead ) and tree instability ( which causes the overhead to increase on average ) .",
    "these factors increase the overhead , but in all cases it was still smaller than for the serial cross - validation procedure , and in the best cases there was only a small overhead over the normal tree induction process .",
    "the ideas underlying our approach are also applicable outside the decision tree context , e.g. , for rule induction , but not immediately for induction of models that have only continuous parameters .",
    "possible further improvements to the technique include specific adaptations for handling tests with continuous values .",
    "also , the algorithms we have discussed are fairly simple versions ; the sprint system for instance @xcite is much more sophisticated with respect to the statistics it keeps , and adaptations to the system along the lines of this paper would be correspondingly complex to implement .",
    "related work includes that of moore and lee ( 1994 ) , who discuss efficient cross - validation in the context of model selection .",
    "their approach differs substantially from ours in that they obtain efficiency by quickly abandoning models that after seeing some examples have low probability of ever becoming the best model ; i.e. , they save on the number of cases a model is evaluated on during cross - validation , whereas our work focuses on removing redundancy in the model building process itself",
    ".    blockeel et al .  ( 2000 ) discuss a technique similar to the one described here .",
    "the main difference is is in the kind of redundancies that are removed ; here the redundancies arise from running the same test in different folds of a cross - validation , whereas in blockeel et al .",
    "( 2000 ) they are caused by similarities in different tests ( the tests being first - order conjunctions , which might be similar up to one literal ) .",
    "both approaches can easily be combined , and such work is in progress .",
    "the authors are a post - doctoral fellow , respectively research assistant , of the fund for scientific research of flanders ( belgium ) .",
    "they thank perot systems nederland / syllogic for providing the asm data .",
    "the cooperation between perot systems nederland and the authors was supported by the european union s esprit project 28623 ( aladin ) ."
  ],
  "abstract_text": [
    "<S> cross - validation is a useful and generally applicable technique often employed in machine learning , including decision tree induction . </S>",
    "<S> an important disadvantage of straightforward implementation of the technique is its computational overhead . in this paper </S>",
    "<S> we show that , for decision trees , the computational overhead of cross - validation can be reduced significantly by integrating the cross - validation with the normal decision tree induction process . </S>",
    "<S> we discuss how existing decision tree algorithms can be adapted to this aim , and provide an analysis of the speedups these adaptations may yield . </S>",
    "<S> the analysis is supported by experimental results . </S>"
  ]
}