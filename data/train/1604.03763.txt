{
  "article_text": [
    "in large scale machine learning applications for big data analysis , it becomes a common practice to partition the training data and store them on multiple machines that are connected via a commodity network .",
    "a typical setting of distributed machine learning is to allow these machines to train in parallel , with each machine processing its own local data .",
    "this is often referred to as _",
    "data parallelism_. in order to reduce the overall training time , it is often necessary to increase the number of machines and to minimize the communication overhead  @xcite . a major challenge is to reduce the training time as much as possible when we increase the number of machines .",
    "a practical solution requires two research directions : one is to improve the underlying system design making it suitable for machine learning algorithms ; the other is to adapt traditional single machine optimization methods to handle data parallelism .",
    "this paper focuses on the latter .    for big data machine learning on a single machine ,",
    "there are generally two types of algorithms : batch algorithms such as gradient descent or l - bfgs  @xcite , and stochastic optimization algorithms such as stochastic gradient descent and their modern variance reduced versions  @xcite . it is known that batch algorithms are relatively easy to parallelize . however , on a single machine , they converge more slowly than the modern stochastic optimization algorithms due to their high per - iteration computation costs . specifically , it has been shown that the modern stochastic optimization algorithms converge faster than the traditional batch algorithms for convex regularized loss minimization problems . the faster convergence can be guaranteed in theory and observed in practice .",
    "the fast convergence of modern stochastic optimization methods has led to studies to extend these methods to the distributed computing setting .",
    "specifically , this paper considers the generalization of stochastic dual coordinate ascent method ( sdca )  @xcite and its proximal variant  @xcite to handle distributed training using data parallelism .",
    "although this problem has been considered previously  @xcite , these earlier approaches worked with the traditional single machine dual formulation , and hence ran into difficulties when they tried to motivate and analyze the derived methods under the distributed environment .    a major contribution of this work is to introduce a new dual formulation specifically for distributed regularized loss minimization problems when",
    "data are distributed to multiple machines .",
    "this new dual formulation allows us to naturally extend the prox - sdca algorithm of @xcite to the setting of multi - machine distributed optimization that can benefit from data parallelism .",
    "moreover , the analysis of the original prox - sdca can be easily adapted to the new formulation , leading to new theoretical results .",
    "this new dual formulation can also be combined with the acceleration technique of @xcite to further improve convergence .    in the proposed formulation , each iteration of the distributed dual coordinate ascent optimization",
    "is naturally decomposed into local optimization and global optimization steps . in the local optimization step ,",
    "we allow the use of any local procedure to optimize a local dual objective function using local parameters and local data on each machine .",
    "this flexibility is similar to those of  @xcite .",
    "for example , we may use the prox - sdca method of  @xcite .",
    "we call it the local step because a computer node can perform the optimization independently without communicating with each other . in the global optimization step ,",
    "nodes communicate with each other to synchronize the local parameters and jointly update the global primal solution .",
    "this global step requires communication among the nodes .",
    "our main contributions can be summarized as follows .    *",
    "new distributed dual formulation for regularized loss minimization*. this new formulation naturally leads to a two step local - global dual alternating optimization procedure for distributed machine learning .",
    "we thus call the resulting algorithm distributed alternating dual maximization ( dadm ) . note that dadm directly generalizes the proximal extension of sdca , which can handle complex regularizations such as @xmath0-@xmath1 regularization .",
    "* new convergence analysis*. the new formulation allows us to directly generalize the analysis of proximal dual coordinate ascent method in  @xcite to the distributed setting .",
    "this is in contrast to that of cocoa@xmath2 in  @xcite , which employs a different analysis .",
    "our analysis can lead to simplified results in the commonly used mini - batch setup .",
    "* acceleration to improve convergence*. based on the new distributed dual formulation , we can naturally derive a distributed version of the accelerated sdca of  @xcite , which was shown to be effective on a single machine .",
    "we call the resulting algorithm accelerated dadm ( acc - dadm ) .",
    "the main idea is to modify the original formulation using a sequence of approximations that have stronger regularizations .",
    "we perform extensive experiments comparing the convergence behaviour and the scalability of this new method .",
    "our empirical studies show that acc - dadm can achieve faster convergence than that of the previous state - of - the - art algorithms .",
    "several generalizations of sdca to the distributed settings have been proposed in the literature , including disdca  @xcite , cocoa  @xcite , and cocoa@xmath2  @xcite .",
    "disdca is the first attempt to study distributed sdca , and it provides a basic theoretical analysis and a practical variant that behaves well empirically .",
    "nevertheless , their theoretical result only applies to a few specially chosen mini - batch local dual updates that differ from the practical method used in their experiments . in particular",
    ", they did not show that optimizing each local dual problem leads to convergence .",
    "this limitation makes the methods they analyzed inflexible .",
    "cocoa is proposed to fix the above gap between theory and practice , and it was claimed to be a framework for distributed dual coordinate ascent in that it allows any local dual solver to be used for the local dual problem , rather than the impractical choices of  @xcite .",
    "however , the convergence rate proved in cocoa was inferior to that of disdca with a special local mini - batch choice , in that the iteration complexity of cocoa is @xmath3  @xcite , which scales with the number of machines @xmath4 , while the bound of disdca  @xcite does not . moreover , the practical performance of cocoa was also inferior to the practical variant proposed in disdca with an aggressive local update .",
    "we note that the practical variant of disdca did nt have a solid theoretical guarantee at that time .",
    "cocoa@xmath2 fixed this situation and may be regarded as a generalization of cocoa .",
    "the most effective choice of the aggregation parameter leads to a version which is similar to disdca , but allows full optimization of each dual problem in their theory .",
    "according to studies in  @xcite , the resulting cocoa@xmath2 algorithm performs significantly better than the original cocoa both theoretically and empirically .",
    "the original cocoa@xmath2  @xcite can only handle problems with the @xmath0 regularization and this has been generalized to other strongly convex regularizers in  @xcite .",
    "although cocoa@xmath2 has the advantage of allowing arbitrary local solvers , the analysis requires a good approximation to solving the full dual optimization on each local machine . on the other hand , disdca with the more practical mini - batch updates that are commonly used in practice ( but only with special choices of dual updates in disdca ) has a superior theoretical bound .",
    "therefore there is still a gap between cocoa@xmath2 and disdca .",
    "this paper will remedy the above mentioned theoretical gap by providing a better analysis based on a new distributed dual formulation . using this formulation ,",
    "we can analyze procedures that can take an arbitrary local dual solver , which is like cocoa@xmath2 ; moreover , we allow the dual updates to be a mini - batch , which is like disdca .",
    "an additional benefit is that our framework can directly handle the proximal sdca formulation .",
    "the new distributed dual formulation also allows us to naturally generalize the accelerated proximal sdca method of  @xcite to the distributed setting , and our empirical results show that the accelerated method achieves superior performance .",
    "while we focus on extending sdca in this paper , we note that there are other approaches for distributed optimization .",
    "for example , there are direct attempts to parallelize stochastic gradient descent  @xcite .",
    "some of these procedures only consider multi - core shared memory situation , which is very different from the distributed computing environment investigated in this paper . in the setting of distributed computing ,",
    "data are partitioned into multiple machines and one often needs to study communication - efficient algorithms . in such cases ,",
    "one extreme is to allow full optimization on each local machine as considered in  @xcite .",
    "although this approach minimizes communication , the computational cost for each local solver can dominate the overall training . therefore in practice , it is necessary to do a trade - off by using the mini - batch update approach  @xcite .",
    "however , it s difficult for traditional mini - batch methods to design reasonable aggregation approaches to achieve fast convergence . _",
    "distributed alternating dual maximization _ ( dadm ) proposed in this work handles such trade - off by developing bounds for mini - batch dual updates , which is similar to @xcite .",
    "moreover , dadm allows other better local solvers to achieve faster convergence in practical .",
    "in this paper , we consider the following generic regularized loss minimization problem : @xmath5,\\end{aligned}\\ ] ] which is often encountered in practical machine learning problems . here",
    "we assume each @xmath6 is a @xmath7 matrix , @xmath8 is the model parameter vector , @xmath9 is a loss function defined on @xmath10 , which is associated with the @xmath11-th data point , @xmath12 is a strongly convex regularizer and @xmath13 is convex .",
    "we assume that the regularization parameter @xmath14 .",
    "we also assume that the loss functions @xmath15 are convex functions .",
    "a special case is to simply set @xmath16 . here",
    "we allow the more general formulation , which can be used to derive different distributed dual forms that may be useful for special purposes .",
    "the above optimization formulation can be specialized to a variety of machine learning problems . as an example , we may consider the @xmath1-@xmath0 regularized least squares problem , where @xmath17 for vector input data @xmath18 and real valued output @xmath19 , @xmath20 , and @xmath21 for some @xmath22 .    if we set @xmath16 , then it is well - known ( see , for example , @xcite ) that the primal problem ( [ formula : original_primal_objective ] ) has an equivalent single - machine dual form of @xmath23 , \\label{eq : dual}\\end{aligned}\\ ] ] where @xmath24 ( @xmath25 ) are dual variables , and @xmath26 is the convex conjugate function of @xmath27 , and similarly , @xmath28 is the convex conjugate function of @xmath29 .",
    "we recall that for a convex function @xmath30 , its conjugate is defined as @xmath31 .\\ ] ]    the stochastic dual coordinate ascent method , referred to as sdca in @xcite , maximizes the dual formulation by optimizing one dual variable at each iteration . throughout the algorithm ,",
    "the following primal - dual relationship is maintained : @xmath32    it is known that @xmath33 , where @xmath34 and @xmath35 are optimal solutions of the primal problem and the dual problem respectively .    it was shown in @xcite that the duality gap defined as @xmath36 , which is an upper - bound of the primal sub - optimality @xmath37 , converges to zero .",
    "moreover , a convergence rate can be established . in particular , for smooth loss functions , the convergence rate is linear .",
    "we note that sdca is suitable for optimization on a single machine due to the fact that it works with a dual formulation that is suitable for a single machine . in the following",
    ", we will generalize the single - machine dual formulation to the distributed setting , and study the corresponding distributed version of sdca .    in the distributed computing setting",
    ", we assume that the training data are partitioned and distributed to @xmath4 machines .",
    "in other words , the index set @xmath38 of the training data is divided into @xmath4 non - overlapping partitions , where each machine @xmath39 contains its own partition @xmath40 .",
    "we assume that @xmath41 , and we use @xmath42 to denote the size of the training data on the @xmath43-th machine .",
    "next , we can rewrite the primal problem ( [ formula : original_primal_objective ] ) as the following constrained minimization problem that is suitable for the multi - machine distributed setting : @xmath44 where @xmath45 represents the local primal variable on each machine @xmath43 , @xmath46 is the corresponding local primal problem and the constraints @xmath47 are imposed to synchronize the local primal variables .",
    "obviously this multi - machine distributed primal formulation ( [ formula : constrain_primal_problem ] ) is equivalent to the original primal problem ( [ formula : original_primal_objective ] ) .",
    "we note that the idea of objective splitting in ( [ formula : constrain_primal_problem ] ) is similar to the global variable consensus formulation described in  @xcite . instead of using the commonly used admm ( alternating direction method of multipliers ) that is not a generalization of , in this paper",
    "we derive a distributed dual formulation based on ( [ formula : constrain_primal_problem ] ) that directly generalizes .",
    "we further propose an algorithm called distributed alternating dual maximization ( dadm ) to solve the distributed dual formulation .",
    "one advantage of dadm over admm is that dadm does not need to solve the subproblems in high accuracy , and thus it can naturally enjoy the trade - off between computation and communication , similar to related methods such as disdca  @xcite , cocoa  @xcite and cocoa@xmath2  @xcite .",
    "to derive the distributed dual problem from , we note that each machine only needs to work with its local primal problem @xmath48 , with the corresponding dual variables @xmath49 . for single machine problems",
    ", each dual variable @xmath50 can be regarded as the lagrangian multiplier for artificially imposed constraints @xmath51 associated with each data point ( see the appendix for details ) . in addition , for each machine - based constraint @xmath47 , we introduce another dual variable @xmath52 via lagrangian multiplier .",
    "the dual variables @xmath53 allow us to pass information across multiple machines , and serve as the carriers for synchronization . using min - max formulation of lagrangian multipliers and convex min - max duality ( the detailed derivation can be found in the appendix ) , we obtain the following multi - machine distributed dual formulation for the corresponding primal problem ( [ formula : constrain_primal_problem ] ) : @xmath54 where @xmath55 represents local dual variables @xmath56 on machine @xmath43 , @xmath57 represents the dual variable that synchronizes machine @xmath43 .",
    "the term @xmath58 is the local dual objective on machine @xmath43 defined by the following formula @xmath59    we note that the parameters @xmath60 pass the global information across multiple machines .",
    "when @xmath52 is fixed , @xmath61 with respect to @xmath55 corresponds to the dual of the adjusted local primal problem : @xmath62 where the original regularizer @xmath63 in @xmath48 is replaced by the adjusted regularizer @xmath64    similar to the single machine primal - dual relationship of , we have the following local primal - dual relationship on each machine as : @xmath65 where @xmath66    moreover , we can define the global primal - dual relationship as @xmath67 where @xmath68    given any @xmath69 , it is shown in the appendix that the duality gap is non - negative : @xmath70 and the duality gap is zero only when @xmath71 is the minimizer of @xmath72 and @xmath73 maximizes the dual @xmath74 .",
    "although we allow arbitrary @xmath13 , the case of @xmath16 is of special interests .",
    "this corresponds to the conjugate function @xmath75 that is , the term @xmath76 is equivalent to imposing the constraint @xmath77 .",
    "we start with the following primal problem @xmath202 which is equivalent to the following multi - machine distributed primal formulation @xmath203 which can be further rewritten as follows : @xmath204 + h(w ) \\\\",
    "s.t \\quad & u_i = x_i^\\top w_\\ell , \\text { for all } i \\in s_\\ell \\\\ & w_\\ell = w , \\text { for all } \\ell \\in \\{1 , ... , m\\ } , \\end{split}\\end{aligned}\\ ] ] here we introduce @xmath205 dual variables @xmath206 , where each @xmath50 is the lagrange multiplier for the constraint @xmath207 , and @xmath4 dual variables @xmath60 , where each @xmath52 is the lagrange multiplier for the constraint @xmath208 .",
    "we can now introduce the primal - dual objective function with lagrangian multiplier as follows : @xmath209 + h(w ) } .\\ ] ]    define the dual objective as @xmath210 -   h^*\\left(\\sum_\\ell\\beta_\\ell\\right ) .\\ ] ] then we have @xmath211 where the minimizers are achieved when the following equations are satisfied @xmath212 for some subgradients @xmath213 , @xmath214 , and @xmath215 . [",
    "prop : duality ]    * proof*. given any set of parameters @xmath216 , we have @xmath217 + h(w)}_{a } , \\end{aligned}\\ ] ] where the minimum is achieved at @xmath218 such that @xmath219 . by eliminating @xmath220",
    "we obtain @xmath221 + h(w ) \\\\",
    "= & \\underbrace{\\min_{w } \\sum_{\\ell=1}^m\\min_{w_\\ell } \\left [ \\sum_{i \\in s_\\ell}-\\phi_i^*(-\\alpha_i ) - \\left(\\sum_{i \\in s_\\ell }   x_i \\alpha_i-\\beta_\\ell\\right)^\\top   w_\\ell+ \\lambda n_\\ell",
    "g(w_\\ell ) - \\beta_\\ell^\\top w \\right ] + h(w)}_{b } , \\end{aligned}\\ ] ] where minimum is achieved at @xmath222 such that @xmath223 . by eliminating @xmath45",
    "we obtain @xmath224 + h(w ) \\\\",
    "= & \\underbrace{\\sum_{\\ell=1}^m \\left [ \\sum_{i \\in s_\\ell}-\\phi_i^*(-\\alpha_i ) -",
    "\\lambda n_\\ell    g^*\\left(\\frac{\\sum_{i \\in s_\\ell }   x_i \\alpha_i-\\beta_\\ell}{\\lambda    n_\\ell}\\right ) \\right ] -   h^*\\left(\\sum_\\ell \\beta_\\ell\\right)}_{d(\\{\\alpha_i\\};\\{\\beta_\\ell\\ } ) } , \\end{aligned}\\ ] ] where the minimizer is achieved at @xmath71 such that @xmath225 .",
    "this completes the proof .",
    "@xmath226    given any @xmath227 , the following duality gap is non - negative : @xmath228 moreover , zero duality gap can be achieved at @xmath229 .",
    "[ prop : duality - gap ]    * proof . * given any @xmath71 , if we take @xmath230 and @xmath47 for all @xmath11 and @xmath43 , then @xmath231 for arbitrary @xmath232 .",
    "it follows from proposition  [ prop : duality ] that @xmath233 when @xmath229 , we may set @xmath234 and @xmath47 . from the first order optimality condition ,",
    "we can obtain @xmath235 if we take @xmath236 and @xmath237 , then it is not difficult to check that all equations in are satisfied .",
    "it follows that we can achieve equality in proposition  [ prop : duality ] as @xmath238 this means that zero duality gap can be achieved with @xmath239 .",
    "minimizing the primal formulation ( [ formula : constrain_primal_problem ] ) is equivalent to maximizing the dual formulation , and the latter can be achieved by repeatedly using the following alternating optimization strategy , which we refer to as dadm ( distributed alternating dual maximization ) :    * * local step * : fix @xmath52 and let each machine approximately optimize @xmath58 w.r.t @xmath55 in parallel . * * global step * : maximize the global dual objective w.r.t @xmath52 , and set the global primal parameter @xmath71 accordingly .",
    "the above steps are applied in iterations @xmath78 . at the beginning of each iteration @xmath79",
    ", we assume that the local primal and dual variables on each local machine are @xmath80 , then we seek to update @xmath81 to @xmath82 and @xmath83 to @xmath84 in the local step , and seek to update @xmath85 to @xmath86 in the global step .",
    "we note that the local step can be executed in parallel w.r.t dual variables @xmath87 . in practice , it is often useful to optimize ( [ formula : local_dual_objective ] ) approximately by using a randomly selected mini - batch @xmath88 of size @xmath89 .",
    "that is , we want to find @xmath90 with @xmath91 to approximately maximize the local dual objective as follows : @xmath92    this step is described in algorithm  [ alg : psdca_lp_mb ] .",
    "we can use any solver for this approximate optimization , and in our experiments , we use the prox - sdca of  @xcite .",
    "[ alg : psdca_lp_mb ] retrieve local parameters ( @xmath93,@xmath83 ) randomly pick a mini - batch @xmath88 approximately maximize ( [ formula : minibatch_local_objective ] ) w.r.t @xmath94 @xmath95 for all @xmath91 @xmath96    the global step is to synchronize all local solutions , which requires communication among the machines .",
    "this is achieved by optimizing the following dual objective with respect to all @xmath97 : @xmath98    it can be shown ( see the appendix ) that the solution is given by @xmath99 where @xmath100 @xmath101 is a subgradient of @xmath102 at the solution @xmath103 of @xmath104 , \\ ] ] that can achieve the first order optimality condition @xmath105 for some subgradient @xmath106 .",
    "the definition of @xmath107 implies that after each global update , we have @xmath108    since the objective for the local step on each machine only depends on the mini - batch @xmath109 ( sampled from @xmath110 ) and the vector @xmath111 , which needs to be synchronized at each global step , we know from that at each time @xmath79 , we can pass the same vector @xmath112 as @xmath111 to all nodes . in practice , it may be beneficial to pass @xmath113 instead , especially when @xmath113 is sparse but @xmath112 is dense .",
    "put things together , the local - global dadm iterations can be summarized in algorithm  [ alg : bdpdf ] .    in the special case that @xmath12 is @xmath0 regularization and @xmath13 is @xmath1 regularization",
    ", the sparsity of @xmath103 implies that @xmath114 is also sparse .",
    "this means that to perform the local optimization step , we only need to store a sparse vector @xmath111 on each machine , which is a potential advantage for choosing a non - zero @xmath13 .    in the special case of @xmath16 ,",
    "the solution of is simply @xmath115 , and the global step in algorithm  [ alg : bdpdf ] can be simplified as first aggregating updates by @xmath116 and then updating local parameters in parallel .",
    "[ alg : bdpdf ] let @xmath117 , @xmath118 , @xmath119 ( * local step * ) call an arbitrary local procedure , such as algorithm  [ alg : psdca_lp_mb ] ( * global step * ) @xmath120 compute @xmath112 according to let @xmath121 update local parameter @xmath122 @xmath123    if we consider the special case of @xmath124 , @xmath125 , and @xmath126 are identical for all @xmath127 , then the objective in problem ( [ formula : original_primal_objective ] ) has the same form as the one considered in the initial version of cocoa@xmath2  @xcite . in this case",
    ", it can be verified that the dadm procedure ( ignoring the mini - batch variation ) is equivalent to cocoa@xmath2 .",
    "therefore the algorithm presented here may be regarded as a generalization .",
    "in addition , when @xmath16 , the dadm procedure is a generalization of disdca method that only allows special choices of @xmath128 on each local machine in their analysis . our theoretical analysis does not suffer from this limitation , and our procedure allows an arbitrary dual solver on each local machine .",
    "due to the close relationship of the distributed dual formulation and the single - machine dual formulation , an analysis of dadm can be obtained by directly generalizing that of the sdca algorithm .",
    "we consider two kinds of loss functions , smooth loss functions that imply fast linear convergence and general @xmath129-lipschitz loss functions .",
    "[ def : lipschitz ] a function @xmath130 is * @xmath129-lipschitz * w.r.t @xmath131 if for all @xmath132 , we have @xmath133    [ def : smooth ] a function @xmath130 is * @xmath134-smooth * w.r.t @xmath131 if for all @xmath132 , we have @xmath135    [ def : strong_convex ] a function @xmath136 is * 1-strongly convex * w.r.t @xmath131 if for any @xmath137 , we have @xmath138    [ def : suboptimal ] let @xmath34 be the optimal solution for the primal problem @xmath72 and @xmath139 be the optimal solution for the dual problem @xmath140 , for the primal solution @xmath103 and the dual solution @xmath141 at iteration @xmath79 , we define the * primal sub - optimality * as @xmath142 and the * dual sub - optimality * as @xmath143    [ theorem : smooth_mini_batch ] assume that each @xmath27 is @xmath134-smooth w.r.t @xmath131 , @xmath29 is 1-strongly convex w.r.t @xmath131 and @xmath144 for all @xmath11 .",
    "let @xmath145 to be fixed on each machine .",
    "assume that our local procedure optimizes @xmath146 sufficiently well on each machine such that @xmath147 and @xmath148 is given by @xmath149 where @xmath150 and @xmath151 $ ] . to reach an expected duality gap of @xmath152 \\le \\epsilon_p$",
    "] , every @xmath153 satisfying the following condition is sufficient , @xmath154    theorem  [ theorem : smooth_mini_batch ] incorporates two key components : the number of machines @xmath4 and the local mini - batch size @xmath155 .",
    "when the condition number @xmath156 is relatively small , the sufficient number of iterations is dominated by the term @xmath157 . under such circumstance",
    ", we can reduce the sufficient number of iterations by increasing the number of machines @xmath4 or increasing the local mini - batch size @xmath155 .",
    "however , when the condition number @xmath156 is relatively large , it will dominate the sufficient number of iterations . to tackle this problem , we derive the accelerated version of dadm in section  [ sec : acceleration ] .",
    "[ theorem : lipschitz_mini_batch ] assume that each @xmath27 is @xmath129-lipschitz w.r.t @xmath131 , @xmath29 is 1-strongly convex w.r.t @xmath131 and @xmath144 for all @xmath11 .",
    "let @xmath145 to be fixed on each machine .",
    "assume that our local procedure optimizes @xmath146 sufficiently well on each machine such that @xmath147 for all @xmath148 given by @xmath158 where @xmath159 and @xmath160 $ ] . to reach an expected duality gap of @xmath161 \\le \\epsilon_p$ ] , every @xmath153 satisfying the following condition is sufficient , @xmath162 where @xmath163 , @xmath164 , with @xmath165 , and @xmath166 represent either the average vector or a randomly chosen vector of @xmath167 over @xmath168 respectively , such as @xmath169 .",
    "theorem  [ theorem : lipschitz_mini_batch ] includes the term @xmath170 and the condition number @xmath171 .",
    "when the condition number @xmath171 is relatively large , we can reduce the number of iterations @xmath153 by decreasing the term @xmath170 .",
    "however , a large value of the condition number can dominate the iteration number .",
    "our method is closely related to previous distributed extensions of sdca , such as disdca  @xcite , cocoa  @xcite , cocoa@xmath2  @xcite .",
    "we note that disdca did nt provide theoretical results for @xmath129-lipschitz losses . for smooth losses",
    ", our theorem  [ theorem : smooth_mini_batch ] that provides theoretical guarantees for more general local updates achieves the same iteration complexity with the one in disdca that only allows some special choices of local mini - batch updates .",
    "the theorems of cocoa@xmath2 are based on the @xmath172-approximate solution of the local procedure , which is related to the local mini - batch size @xmath155 in our theorems .",
    "assume the local procedure optimizes the local dual problem sufficiently well to let @xmath173 and the local mini - batch size @xmath155 in our method is set to the maximum @xmath126 , our bounds are similar to those of cocoa@xmath2 .",
    "however our bounds capture the contributions of local mini - batch updates more explicitly .",
    "since the bounds are derived with a special choice @xmath148 , the actual performance of the algorithm can be significantly better than what s indicated by the bounds when the local duals are better optimized .",
    "for example , we can choose prox - sdca in  @xcite as the local procedure and adopt the sequential update strategy as the local solver of cocoa@xmath2 does .",
    "this is also the one used in our experiments .",
    "theorem  [ theorem : smooth_mini_batch ] shows that when the condition number @xmath174 or @xmath171 is small , the dadm algorithm converges fast .",
    "however , the convergence may be slow when the condition number is large .",
    "in fact , we observe empirically that the basic dadm algorithm converges slowly when the regularization parameter @xmath175 is small .",
    "this is also consistent with the phenomenon of sdca for the single machine dual optimization . in this section ,",
    "we introduce the accelerated distributed alternating dual maximization algorithm ( acc - dadm ) that can alleviate the problem .",
    "the procedure is motivated by @xcite , which employs an inner - outer iteration : at every iteration @xmath79 , we solve a slightly modified objective , which adds a regularization term centered around the vector @xmath176 where @xmath177 $ ] is called the momentum parameter .    the accelerated dadm procedure can be similarly viewed as an inner - outer algorithm , where the local step serves as the inner iteration , and the global step is the outer iteration .",
    "that is , at each iteration @xmath79 , we define a modified local primal objective on each machine @xmath43 , which has the same form as the original local primal objective  , except that @xmath178 is modified to @xmath179 that is defined by @xmath180    it follows that we will need to solve a modified dual at each local step with @xmath181 replaced by @xmath182 in the local dual problem  .",
    "therefore , compared to the basic dadm procedure , nothing changes other than @xmath181 being replaced by @xmath183 at each iteration .",
    "specifically , when the number of machines @xmath4 equals @xmath184 , this algorithm reduces to the accelerated prox - sdca described in  @xcite .",
    "thus acc - dadm can be naturally regarded as the generalization of the single - machine accelerated prox - sdca .",
    "moreover , acc - dadm also allows arbitrary local procedures as dadm does .",
    "our empirical studies show that acc - dadm significantly outperforms dadm in many cases .",
    "there are two reasons .",
    "one reason is due to the use of a modified regularizer @xmath185 that is more strongly convex than the original regularizer @xmath12 when @xmath186 is much larger than @xmath175 . the other reason is closely related to the distributed setting considered in this paper .",
    "observe that in the modified local primal objective @xmath187 the first term corresponds to the original local primal objective and the second term is an extra regularization due to acceleration that constrains @xmath45 to be close to @xmath188 .",
    "the effect is that different local problems become more similar to each other , which stabilize the overall system .",
    "in this section , we apply the algorithms described in this paper to solve two binary classification problems , the hinge loss support vector machine ( svm ) and the @xmath0-@xmath1 regularized logistic regression ( lr ) .",
    "we perform experiments on four real datasets with different properties , which are extracted from the * libsvm * datasets  @xcite .",
    "table [ tab : datasets ] summarizes the properties of these datasets .",
    "0.15 in    .datasets [ cols=\"<,^,^,^,>\",options=\"header \" , ]     -0.1 in      in many machine learning applications , we often encounter some high dimensional sparse datasets , such _ rcv1 _ and _ kdd _ in our experiments . a common practice is to add @xmath1 regularization to induce sparsity . if we choose the logistic loss , then our primal optimization problem becomes @xmath189 where @xmath190 .",
    "this case corresponds to theorem  [ theorem : smooth_mini_batch ] , since the logistic loss is a smooth loss .",
    "when @xmath175 is extremely small with respect to @xmath191 , we can obtain an approximate solution to the problem with only @xmath1 regularization .",
    "for example , we set @xmath192 and @xmath193",
    ". however , the original cocoa@xmath2 runs into problems in this case since @xmath175 is extremely small .    for high dimensional data ,",
    "the communication overheads are always high , thus we recommend to perform relatively full optimization for local problems .",
    "that means choosing large @xmath194 ( such as @xmath195 ) and performing more computations on each machine .",
    "the momentum parameter @xmath196 in acc - dadm plays an important role in this case .",
    "as figure  [ fig : comp_lr_mome ] shows , we choose the primal sub - optimality , @xmath197 , as the convergence metric , where @xmath34 is the optimal primal solution .",
    "we test different choices of @xmath196 , such as @xmath198 , where @xmath199 denotes that we change @xmath196 at each iteration according to the nesterov s acceleration  @xcite as @xmath200 figure  [ fig : comp_lr_mome ] demonstrates the effect of the momentum parameter @xmath196 and shows that the choice @xmath201 outperforms other choices .",
    "in this paper we introduced a novel distributed dual formulation for regularized loss minimization problems . based on this new formulation",
    ", we studied a generalization of the single machine dual coordinate ascent method ( sdca ) , which we refer to as dadm .",
    "we have shown that the analysis of sdca can be easily generalized to establish the convergence of the new method . moreover , we have adapted the accelerated prox - sdca to the distributed setting by using this new dual formulation .",
    "numerous experiments were performed to show that the new approach improves the previous state - of - the - art in distributed dual optimization .",
    "when @xmath97 are fixed , we may define local single machine dual formulation on each machine @xmath43 with respect to @xmath55 as @xmath240 the corresponding local primal formulation is @xmath241 note that if we define @xmath242 then @xmath243 therefore with the modified regularizer @xmath244 , @xmath245 is the standard single machine dual for the regularized objective @xmath246 .    given @xmath69 , and @xmath222 such that @xmath247 .",
    "we have the following decomposition of global duality gap as the sum of local duality gaps : @xmath248 , \\ ] ] and the equality holds when @xmath249 for some subgradient @xmath215 .    * proof .",
    "* we have the decompositions @xmath250 and @xmath251 it follows that the duality gap @xmath252 +    h^*\\left(\\sum_\\ell\\beta_\\ell\\right ) + h(w ) - \\left(\\sum_\\ell \\beta_\\ell\\right)^\\top w .\\ ] ] note that the definition of convex conjugate function implies that @xmath253 and the equality holds when @xmath249 .",
    "this implies the desired result .",
    "when @xmath254 are fixed , we study the properties of the solution after @xmath255 being optimized .    given @xmath256 , let @xmath257 be the unique solution of the following optimization problem @xmath258\\ ] ] that satisfies @xmath259 for some subgradients @xmath260 and @xmath261 at @xmath262 . then @xmath263 is a solution of @xmath264 , \\ ] ] and @xmath265 [ prop : global ]    * proof .",
    "* it is easy to check using duality that for any @xmath266 and @xmath71 : @xmath267   + \\left[-b^\\top w + h(w ) \\right]\\\\ = & -\\lambda n w^\\top v + \\lambda n g(w ) + h(w ) , \\end{aligned}\\ ] ] and the equality holds if @xmath268 and @xmath269 for some subgradients .",
    "based on the assumptions , the equality can be achieved at @xmath270 and @xmath262 .",
    "this proves the desired result by noticing that @xmath271 implies that @xmath272 .",
    "@xmath226    given @xmath273 , a solution of @xmath274 can be obtained by setting @xmath275 where @xmath276 is defined in proposition  [ prop : global ] , @xmath277 moreover , if we let @xmath278 where @xmath257 is defined in proposition  [ prop : global ] , and @xmath279 then @xmath280 for all @xmath43 , and @xmath281 .\\ ] ] [ prop : global - local - dgap ]    * proof . *",
    "since @xmath273 is fixed , we know that the problem @xmath282 is equivalent to @xmath283.\\ ] ] now by using jensen s inequality , we obtain for any @xmath284 : @xmath285 in the above derivation , the last inequality has used proposition  [ prop : global ] . here",
    "the equalities can be achieved when @xmath286 for all @xmath43 , which can be obtained with the choice of @xmath287 given in the statement of the proposition . @xmath226",
    "the following result is the mini - batch version of a related result in the analysis of prox - sdca , which we apply to any local machine @xmath43 .",
    "the proof is included for completeness .",
    "[ lem : key_smooth ] assume that @xmath288 is @xmath289-strongly convex w.r.t @xmath131 ( where @xmath289 can be zero ) and @xmath28 is 1-smooth w.r.t @xmath131 .",
    "every local step , we randomly pick a mini - batch @xmath88 , whose size is @xmath290 , and optimize w.r.t dual variables @xmath291 .",
    "then , using the simplified notation @xmath292 we have @xmath293 \\ge    \\frac{s_\\ell m_\\ell}{n_\\ell}\\ , { { \\mathbb{e}}}\\ ; [ p_\\ell(w_\\ell^{(t-1)})-d_\\ell(\\alpha_{(\\ell)}^{(t-1 ) } ) ] - \\frac{s_\\ell^2 m_\\ell^2}{2\\lambda n_\\ell^2 } g_\\ell^{(t)}\\ ] ] where @xmath294 { { \\mathbb{e}}}\\ ; \\left [ \\|u_i^{(t-1)}-\\alpha_i^{(t-1)}\\|_2 ^ 2 \\right ] \\\\",
    "\\delta \\tilde{\\alpha}_i & : = \\alpha_i^{(t ) } - \\alpha_i^{(t-1 ) }   = s_\\ell ( u_i^{(t-1 ) } - \\alpha_i^{(t-1 ) } ) , \\quad \\text { for all } i \\in q_\\ell,\\end{aligned}\\ ] ] and @xmath295 $ ] .    *",
    "* since only the elements in @xmath109 are updated , the improvement in the dual objective can be written as @xmath296 where we have used the fact the @xmath28 is 1-smooth in the derivation of the inequality .    by the definition of the update in the algorithm , and the definition of @xmath297",
    "$ ] , we have @xmath298    from now on , we omit the superscript @xmath299 . since @xmath26 is @xmath289-strongly convex w.r.t @xmath131",
    ", we have @xmath300    bringing eq . into eq . , we get @xmath301 where we get the second inequality according to the fact that @xmath302 .",
    "since we choose @xmath303 , which means @xmath304 , then we obtain @xmath305 + \\sum_{i \\in q_\\ell } s_\\ell \\|u_i-\\alpha_i\\|_2 ^ 2 \\left[\\frac{\\gamma(1-s_\\ell)}{2 } - \\frac{s_\\ell m_\\ell\\|x_i\\|_{2}^2}{2 \\lambda n_\\ell } \\right ] .",
    "\\nonumber\\\\ & = \\sum_{i \\in q_\\ell } s_\\ell \\left [ \\phi_i(x_i^\\top w_\\ell ) + \\phi_i^*(-\\alpha_i ) + w_\\ell^\\top x_i \\alpha_i \\right ] + \\frac{m_\\ell}{2\\lambda n_\\ell } \\sum_{i \\in q_\\ell } s_\\ell^2 \\|u_i-\\alpha_i\\|_2 ^ 2 \\left[\\frac{\\gamma\\lambda n_\\ell ( 1-s_\\ell)}{m_\\ell s_\\ell } - \\|x_i\\|_{2}^2\\right ] . \\nonumber\\end{aligned}\\ ] ]    recall that with @xmath306 , we have @xmath307 .",
    "then we derive the local duality gap as @xmath308    then , taking the expectation of eq .",
    "w.r.t the random choice of mini - batch set @xmath109 at round @xmath79 , we obtain @xmath309\\\\ & \\ge \\frac{m_\\ell}{n_\\ell } \\sum_{i\\in s_\\ell } s_\\ell \\left [ \\phi_i(x_i^\\top w_\\ell ) + \\phi_i^*(-\\alpha_i ) + w_\\ell^\\top x_i \\alpha_i \\right ] + \\frac{m_\\ell^2}{2\\lambda n_\\ell^2 } \\sum_{i \\in s_\\ell } s_\\ell^2 \\|u_i-\\alpha_i\\|_2 ^ 2 \\left[\\frac{\\gamma\\lambda n_\\ell ( 1-s_\\ell)}{m_\\ell s_\\ell } - \\|x_i\\|_{2}^2\\right ] \\\\ & = \\frac{s_\\ell m_\\ell}{n_\\ell } \\sum_{i\\in s_\\ell } \\left [ \\phi_i(x_i^\\top w_\\ell ) + \\phi_i^*(-\\alpha_i ) + w_\\ell^\\top x_i \\alpha_i \\right ] - \\frac{m_\\ell^2}{2\\lambda n_\\ell^2 } \\sum_{i \\in s_\\ell } s_\\ell^2 \\|u_i-\\alpha_i\\|_2 ^ 2 \\left[\\|x_i\\|_{2}^2 - \\frac{\\gamma\\lambda n_\\ell      ( 1-s_\\ell)}{m_\\ell s_\\ell } \\right ] . \\ ] ] take expectation of both sides w.r.t the randomness in previous iterations , we have @xmath310 & \\ge \\frac{s_\\ell",
    "m_\\ell}{n_\\ell } { { \\mathbb{e}}}\\ ; \\left [ p_\\ell(w_\\ell ) - d_\\ell(\\alpha_{(\\ell ) } ) \\right ] - \\frac{s_\\ell^2 m_\\ell^2}{2\\lambda n_\\ell^2 } g_\\ell^{(t)},\\end{aligned}\\ ] ] where @xmath311 { { \\mathbb{e}}}\\ ; \\left [ \\|u_i-\\alpha_i\\|_2 ^ 2 \\right ] .\\end{aligned}\\ ] ] @xmath226    * proof of theorem 1 . * we will apply lemma [ lem : key_smooth ] with @xmath312 , i \\in s_\\ell .\\end{aligned}\\ ] ] recall that @xmath313 , then we have @xmath314 which implies that @xmath315 for all @xmath43 .",
    "it follows that for all @xmath43 after the local update step we have : @xmath316\\\\ & \\ge \\frac{s_\\ell m_\\ell}{n_\\ell } { { \\mathbb{e}}}\\ ; \\left [    \\tilde{p}_\\ell(w_\\ell^{(t-1)}|\\beta_\\ell^{(t-1 ) } ) -   \\tilde{d}_\\ell(\\alpha_{(\\ell)}^{(t-1)}|\\beta_\\ell^{(t-1 ) } ) \\right ] . \\end{split}\\end{aligned}\\ ] ] now we note that after the global step at iteration @xmath317 , the choices of @xmath318 and @xmath319 in dadm is according to the choice of proposition  [ prop : global ] and proposition  [ prop : global - local - dgap ] , it follows from proposition  [ prop : global - local - dgap ] that the following relationship of global and local duality gap at the beginning of the @xmath79-th iteration is satisfied : @xmath320 .\\ ] ] using this decomposition and summing over @xmath43 in , we obtain @xmath321 \\geq q { { \\mathbb{e}}}\\ ; [ p(w^{(t-1)})-d(\\alpha^{(t-1)},\\beta^{(t-1 ) } ) ] , \\ ] ] where @xmath322 since @xmath323 , we obtain @xmath324 \\geq q   { { \\mathbb{e}}}\\ ; [ p(w^{(t-1)})-d(\\alpha^{(t-1)},\\beta^{(t-1 ) } ) ] .\\ ] ]    let @xmath139 be the optimal solution of the dual problem and the dual sub - optimality @xmath325 , we know that @xmath326 .",
    "it follows that @xmath327   \\ge { { \\mathbb{e}}}[\\epsilon_d^{(t-1)}-\\epsilon_d^{(t ) } ] \\ge q { { \\mathbb{e}}}[\\epsilon_p^{(t-1 ) } ] \\ge q { { \\mathbb{e}}}[\\epsilon_d^{(t-1)}].\\end{aligned}\\ ] ]    therefore we have @xmath328   \\le { { \\mathbb{e}}}[\\epsilon_d^{(t ) } ]   \\le ( 1-q){{\\mathbb{e}}}[\\epsilon_d^{(t-1 ) } ] \\le ( 1-q)^t \\epsilon_d^{(0 ) } \\le e^{-qt } \\epsilon_d^{(0)}.\\end{aligned}\\ ] ]    to obtain an expected duality gap of @xmath329 \\le \\epsilon_p$ ] , every @xmath153 , which satisfies @xmath330 is sufficient .",
    "this proves the desired bound .",
    "now , we consider @xmath129-lipschitz loss functions , using the following the basic lemma for @xmath129-lipschitz losses from  @xcite .",
    "recall that @xmath144 , then we have @xmath340 , where @xmath165 . combining this into lemma  [ lem : key_smooth ] , we have @xmath341\\nonumber\\\\ \\ge & \\frac{s_\\ell m_\\ell}{n_\\ell } { { \\mathbb{e}}}\\ ; \\left [    \\tilde{p}_\\ell(w_\\ell^{(t-1)}|\\beta_\\ell^{(t-1 ) } ) -   \\tilde{d}_\\ell(\\alpha_{(\\ell)}^{(t-1)}|\\beta_\\ell^{(t-1 ) } ) \\right ] - \\frac{s_\\ell^2 m_\\ell^2}{2\\lambda n_\\ell^2 } g_\\ell .",
    "\\label{eq : lips_key_local_ineq}\\end{aligned}\\ ] ]    now we also note that after the global step at iteration @xmath317 , the choices of @xmath318 and @xmath319 in dadm is according to the choice of proposition  [ prop : global ] and proposition  [ prop : global - local - dgap ] , it follows from proposition  [ prop : global - local - dgap ] that the following relationship of global and local duality gap at the beginning of the @xmath79-th iteration is satisfied : @xmath320 .\\ ] ]    summing the inequality   over @xmath43 , combining with the above decomposition and bringing @xmath323 into it , we get @xmath342 \\ge q { { \\mathbb{e}}}[p(w^{(t-1 ) } ) - d(\\alpha^{(t-1 ) } , \\beta^{(t-1 ) } ) ] - \\sum_{\\ell=1}^m \\frac{q^2}{2\\lambda } g_\\ell , \\end{aligned}\\ ] ] where @xmath343 , q = \\frac{s_\\ell m_\\ell}{n_\\ell}$ ] and @xmath344 $ ] is chosen so that all @xmath345 are equal .",
    "let @xmath139 be the optimal solution for the dual problem @xmath140 , then we define the dual sub - optimality as @xmath325 . note that the duality gap is an upper bound of the dual sub - optimality , @xmath346",
    ". then   implies that @xmath347 \\le ( 1-q ) { { \\mathbb{e}}}[\\epsilon_d^{(t-1 ) } ] +   q^2 \\frac{g}{2\\lambda } , \\text { where } g = \\sum_{\\ell=1}^m g_\\ell\\ ] ]    starting from this recursion , we can now apply the same analysis of @xmath129-lipschitz loss in @xcite to obtain the following desired inequality @xmath348",
    "\\le \\frac{2g}{\\lambda(2 \\tilde{n}+t - t_0)},\\end{aligned}\\ ] ] for all @xmath349 , where @xmath163 . @xmath226"
  ],
  "abstract_text": [
    "<S> in modern large - scale machine learning applications , the training data are often partitioned and stored on multiple machines . </S>",
    "<S> it is customary to employ the `` data parallelism '' approach , where the aggregated training loss is minimized without moving data across machines . in this paper </S>",
    "<S> , we introduce a novel distributed dual formulation for regularized loss minimization problems that can directly handle data parallelism under the distributed computing environment . </S>",
    "<S> this formulation allows us to systematically derive dual coordinate optimization procedures , which we refer to as _ distributed alternating dual maximization _ ( dadm ) . </S>",
    "<S> the method extends earlier studies described in  @xcite and has a rigorous theoretical analysis . </S>",
    "<S> based on the new formulation , we also develop an accelerated dadm algorithm by generalizing the acceleration technique from  @xcite to the distributed setting . </S>",
    "<S> our empirical studies show that our novel approach significantly improves the previous state - of - the - art distributed dual coordinate optimization algorithms . </S>"
  ]
}