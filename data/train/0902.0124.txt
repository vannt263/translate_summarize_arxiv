{
  "article_text": [
    "in concrete applications for image processing , one might be interested to recover at best a digital image provided only partial linear or nonlinear measurements , possibly corrupted by noise . given the observation that natural and man - made images are characterized by a relatively small number of edges and extensive relatively uniform parts , one may want to help the reconstruction by imposing that the interesting solution is the one which matches the given data and has also a few discontinuities localized on sets of lower dimension .    in the context of compressed sensing @xcite , it has been clarified the fundamental role of minimizing @xmath0-norms in order to promote sparse solutions .",
    "this understanding furnishes an important interpretation of total variation minimization , i.e. , the minimization of the @xmath0-norm of derivatives @xcite , as a regularization technique for image restoration .",
    "several numerical strategies to perform efficiently total variation minimization have been proposed in the literature .",
    "we list a few of the relevant ones , ordered by their chronological appearance :    \\(i ) the approach of chambolle and lions @xcite by re - weighted least squares , see also @xcite for generalizations and refinements in the context of compressed sensing ;    \\(ii ) variational approximation via local quadratic functionals as in the work of vese et al .",
    "@xcite ;    \\(iii ) iterative thresholding algorithms based on projections onto convex sets as in the work of chambolle @xcite as well as in the work of combettes - wajs @xcite and daubechies et al . @xcite ;    \\(iv ) iterative minimization of the bregman distance as in the work of osher et al .",
    "@xcite ;    \\(v ) the approach proposed by nesterov @xcite and its modifications by weiss et al .",
    "@xcite .",
    "these approaches differ significantly , and it seems that the ones collected in the groups iv ) and v ) do show presently the best performances in practice",
    ". however , none of the mentioned methods is able to address in real - time , or at least in an acceptable computational time , extremely large problems , such as 4d imaging ( spatial plus temporal dimensions ) from functional magnetic - resonance in nuclear medical imaging , astronomical imaging or global terrestrial seismic tomography . for such large scale simulations we need to address methods which allow us to reduce the problem to a finite sequence of sub - problems of more manageable size , perhaps by one of the methods listed above . with this aim we introduced subspace correction and domain decomposition methods both for @xmath0-norm and total variation minimizations @xcite . due to the nonadditivity of the total variation with respect to a domain decomposition",
    "( the total variation of a function on the whole domain equals the sum of the total variations on the subdomains plus the size of the jumps at the interfaces ) , one encounters additional difficulties in showing convergence of such decomposition strategies to global minimizers .    in this paper",
    "we review concisely both nonoverlapping and overlapping domain decomposition methods for total variation minimization and we provide their properties of convergence to global minimizers .",
    "moreover , we show numerical applications in classical problems of signal and image processing , such as signal interpolation and image inpainting .",
    "we further include applications in the context of compressed sensing for recovering piecewise constant medical - type images from partial fourier ensembles @xcite .",
    "since we are interested to a discrete setting , we define the domain of our multivariate digital signal @xmath1 , @xmath2 and we consider the signal space @xmath3 , where @xmath4 for @xmath5 . for @xmath6",
    "we write @xmath7 with index set @xmath8 and @xmath9 where @xmath10 and @xmath11 .",
    "then , for @xmath12 , the @xmath13-norm is given by @xmath14 , and for @xmath15 the discrete gradient @xmath16 is given by @xmath17 with @xmath18 if @xmath19 , and @xmath20 if @xmath21 , for all @xmath22 and for all @xmath23 .",
    "the total variation of @xmath6 in the discrete setting is then defined as @xmath24 , with @xmath25 for every @xmath26 .",
    "we define the scalar product of @xmath27 as usual , @xmath28 , and the scalar product of @xmath29 as @xmath30 .",
    "further we introduce a discrete divergence @xmath31 defined , by analogy with the continuous setting , by @xmath32 ( @xmath33 is the adjoint of the gradient @xmath34 ) . in the following we denote with @xmath35 the orthogonal projection onto a closed convex set @xmath36 .      with these notation , we define the closed convex set @xmath37    we briefly recall here an algorithm proposed by chambolle in @xcite in order to compute the projection onto @xmath38 . the following semi - implicit gradient descent algorithm is given to approximate @xmath39 : choose @xmath40 , let @xmath41 and , for any @xmath42 , iterate @xmath43 for @xmath40 sufficiently small , the iteration @xmath44 converges to @xmath39 as @xmath45 ( compare ( * ? ? ? * theorem 3.1 ) ) .      given a model linear operator @xmath46",
    ", we are considering the following discrete minimization problem @xmath47 where @xmath48 is a given datum and @xmath49 is a fixed regularization parameter .",
    "note that , up to rescaling the parameter @xmath50 and the datum @xmath51 , we can always assume @xmath52 .",
    "moreover , in order to ensure existence of solutions , we assume @xmath53 . for both nonoverlapping and overlapping domain decompositions , we will consider a linear sum @xmath54 with respect to two subspaces @xmath55 , @xmath56 defined by a suitable decomposition of the physical domain @xmath57 .",
    "we restrict our discussion to two subspaces , but the analysis can be extended in a straightforward way to multiple subspaces . with this splitting",
    "we want to minimize @xmath58 by suitable instances of the following alternating algorithm : pick an initial @xmath59 , for example @xmath60 , and iterate @xmath61",
    "let us consider the disjoint domain decomposition @xmath62 and @xmath63 and the corresponding spaces @xmath64 , for @xmath65 . note that @xmath66 .",
    "it is useful to us to introduce an auxiliary functional @xmath67 , called the _ surrogate functional _ of @xmath58 : for @xmath68 and @xmath69 , assume @xmath70 and @xmath71 and define @xmath72 as it will be clarified later , the minimization of @xmath73 with respect to @xmath74 and for fixed @xmath75 is an operation which can be realized more easily than the direct minimization of the parent functional @xmath76 for the sole @xmath77 fixed .      in the following",
    "we denote @xmath78 the orthogonal projection onto @xmath79 , for @xmath65 .",
    "let us explicitely express the algorithm as follows : pick an initial @xmath80 , for example @xmath60 , and iterate @xmath81 note that we do prescribe a finite number @xmath82 and @xmath83 of inner iterations for each subspace respectively .",
    "the parallel version of the previous algorithm reads as follows : pick an initial @xmath80 , for example @xmath60 , and iterate @xmath84 note that @xmath85 is the average of the current iteration and the previous one as it is the case for successive overrelaxation methods ( sor ) in classical numerical linear algebra .",
    "let us consider the overlapping domain decomposition @xmath62 and @xmath86 and the corresponding spaces @xmath64 , for @xmath65 . note that now @xmath54 is not anymore a direct sum of @xmath55 and @xmath56 , but just a linear sum of subspaces .",
    "we define the internal boundaries @xmath87 , @xmath68 and @xmath69 ( see figure [ fig : overlap ] ) .",
    "( -140,10)(-140,10 )    ( 35,23)@xmath88 ( -22,+7 ) ( -20,20)(1,0)120 ( -20,22)(0,-1)4 ( 100,22)(0,-1)4    ( -20,0 ) ( 20,0 ) ( -100,0 ) ( -100,-2 ) ( 100,-2 )    ( 18,-15 ) ( -100,-20)(1,0)120 ( 20,-22)(0,1)4 ( -100,-22)(0,1)4 ( -45,-29)@xmath89    @xmath90      associated to the decomposition @xmath91 let us fix a partition of unity @xmath92 , i.e. , @xmath93 , @xmath94 , and @xmath95 . let us explicitely express the algorithm now as follows : pick an initial @xmath96 , for example @xmath60 , and iterate @xmath97    a few technical tricks are additionally required for the boundedness of the iterations in algorithm with respect to the nonoverlapping version .",
    "first of all the local minimizations are restricted to functions which vanish on the internal boundaries .",
    "moreover since @xmath98 is formed as a sum of local components @xmath99 which are not uniquely determined on the overlapping part , we introduced a suitable correction by means of the partition of unity @xmath92 in order to enforce the uniform boundedness of the sequences of the local iterations @xmath99 . with similar minor modifications",
    ", we can analogously formulate a parallel version of this algorithm as in .",
    "the inner iterations @xmath100 where @xmath101 is some linear constraint , are crucial for the concrete realizability of the algorithm .",
    "( note that in the case of the nonoverlapping decomposition there is no additional linear constraint , whereas for the overlapping case we ask for the trace condition @xmath102 . )",
    "such iteration can be explicitely computed @xmath103\\left ( u_j^{(n+1,\\ell)}+\\pi_{v_j}t^*(g - tu_{\\check j}-t u_j^{(n+1,\\ell ) } ) \\right .\\\\ & & \\left .",
    "\\phantom{xxxxxxxxx } + u_{\\check j } -\\eta^{(n+1,\\ell ) } \\right ) -u_{\\check j},\\end{aligned}\\ ] ] for a suitable lagrange multiplier @xmath104 which has the role of enforcing the linear constraints @xmath105 and @xmath101 ; @xmath104 can be approximated by an iterative algorithm , see ( * ? ? ?",
    "* proposition 4.6 ) for details .",
    "note that we have to implement repeatedly the projection @xmath106 for which the chambolle s algorithm is used .",
    "more efficient algorithms can also be used such as iterative bregman distance methods @xcite or nesterov s algorithm @xcite .",
    "these algorithms share common convergence properties , which are listed in the following theorem . + * theorem . *",
    "( convergence properties )    _ the algorithms , , and produce a sequence @xmath107 in @xmath108 with the following properties : _    ( i)@xmath109 for all @xmath110 ( unless @xmath111 ) ;    \\(ii ) @xmath112 ;    \\(iii ) the sequence @xmath107 has subsequences which converge in @xmath108 ; if @xmath113 is a converging subsequence , and @xmath114 is its limit , then @xmath114 is always a minimizer of @xmath58 in the case of algorithm ( overlapping case ) , whereas for algorithms , ( sequential and parallel nonoverlapping cases ) this can be ensured under certain sufficient technical conditions , see ( * ? ? ?",
    "* theorem 5.1 and theorem 6.1 ) for details .",
    "in the figure [ fig:1dnum ] , figure [ fig:2dinpainting ] , and figure [ fig : compressedsensing ] we illustrate the results of several numerical experiments , showing the successful application of algorithms and , for the restoration of 1d and 2d signals in interpolation / inpainting problems respectively , and for a compressed sensing problem .",
    "the authors acknowledge the support by the project wwtf five senses - call 2006 , _ mathematical methods for image analysis and processing in the visual arts_. m. fornasier acknowledges the financial support provided by start grant `` sparse approximation and optimization in high dimensions '' of the austrian science fund .",
    "schnlieb acknowledges the financial support provided by kaust ( king abdullah university of science and technology ) , by the wissenschaftskolleg ( graduiertenkolleg , ph.d .",
    "program ) of the faculty for mathematics at the university of vienna ( funded by the austrian science fund fwf ) , and by the ffg project _ erarbeitung neuer algorithmen zum image inpainting _ , projectnumber 813610 ."
  ],
  "abstract_text": [
    "<S> we present several domain decomposition algorithms for sequential and parallel minimization of functionals formed by a discrepancy term with respect to data and total variation constraints . </S>",
    "<S> the convergence properties of the algorithms are analyzed . </S>",
    "<S> we provide several numerical experiments , showing the successful application of the algorithms for the restoration 1d and 2d signals in interpolation / inpainting problems respectively , and in a compressed sensing problem , for recovering piecewise constant medical - type images from partial fourier ensembles . </S>"
  ]
}