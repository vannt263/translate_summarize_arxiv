{
  "article_text": [
    "for a given firm , inventory control is about dynamically adjusting ordering quantities to minimize the total long - run expected cost . in traditional models ,",
    "demand levels faced by a firm are often assumed to be random , however , with known probabilistic distributions .",
    "even the knowledge on demand distribution can often prove to be too optimistic . when the firm has just introduced a new product or when its external environment has just transitioned to a previously unfamiliar phase ( such as a severe economic downturn ) , it will not be sure of the demand patterns to be encountered .",
    "one way out is through the bayesian approach . in it ,",
    "the firm possesses a prior distribution on potential demand patterns .",
    "then , posterior understanding on demand is updated by its realized levels .",
    "inventory management taking this approach can be found in , for instance , scarf @xcite and lariviere and porteus @xcite .",
    "most other times , even a prior distribution on demand can seem far - fetched .",
    "what meager information one possesses might just be a collection of potential demand distributions .",
    "now , the concerned firm has still to make decisions based on its past observations .",
    "but its goal is no longer about catering to a specific demand distribution or even a series of posterior demand distributions .",
    "rather , its history - dependent ( henceforward called adaptive ) control policy should better yield results that are reasonably good under all potential demand distributions from the given collection .",
    "a given policy s regret under a given demand distribution and over a fixed time horizon measures the price paid for ambiguity ; namely , it registers the difference between the policy s performance and that of the best policy tailor - made for the demand distribution had it been known .",
    "a policy will be considered good when its worst regret over all demand distributions in a collection grows as slowly as possible over time . in this paper",
    "we follow the frequentist approach .",
    "this approach was pioneered in the work of robbins @xcite , lai and robbins @xcite , katehakis and robbins @xcite , and burnetas and katehakis @xcite , for allocation problems , where the main concern is on adaptively selecting the most promising population to draw from so as to maximize the total expected value of samples , or equivalently to minimize the regret due to ignorance of the distributions .",
    "later , the approach was brought to bear on adaptive markov decision processes ; see , e.g. , burnetas and katehakis @xcite . for recent work in this area we refer to burnetas et al @xcite , and cowan and katehakis @xcite , @xcite .    adaptive policies for inventory control have been considered .",
    "huh and rusmevichientong @xcite analyzed a gradient - based policy most suitable to the continuous - demand case .",
    "their policy could also be thought of as an extension of stochastic approximation ( sa ) , which started with robbins and monro @xcite and kiefer and wolfowitz @xcite .",
    "more recently , besbes and muharremoglu @xcite focused on the discrete - demand case of the repeated newsvendor problem and proposed policies with provably good performance guarantees .    in a revenue management setup , besbes and zeevi @xcite studied the dynamic setting of prices while learning demand on the fly .",
    "perakis and roels @xcite minimized the worst regret for a single - period newsvendor problem . rather than dynamic learning , they used conic optimization to deal with partial information on random demands in the form of known moments . for",
    "the newsvendor problem and its multi - period version involving nonperishable items , levi , roundy , and shmoys @xcite relied on randomly generated demand samples to reach solutions with relatively good qualities at high probabilities . in this work , demand learning was through a black box capable of turning up an arbitrary number of samples at any time , rather than through the sequence of actually encountered demand levels .",
    "we study inventory control involving the online learning of unknown demand , focusing on nonperishable items like huh and rusmevichientong @xcite and discrete - quantity analysis like besbes and muharremoglu @xcite . in many real - life situations ranging from manufacturing to retailing , nonperishability of items",
    "is an essential feature to be faced head on .",
    "also , many applications , such as the management of bulk items , dictate that demand be discrete .",
    "an adaptation to huh and rusmevichientong s @xcite policy could work for the discrete - demand case , as demonstrated in the repeated - newsvendor analysis in their section 3.4 .",
    "however , further adaption seems needed for the nonperishable - inventory case ; see  ( [ lala ] ) and  ( [ lalala ] ) later in our simulation study .",
    "to the best of our knowledge , our theoretical performance guarantees on an adaptive inventory policy involving unknown demand of discrete nonperishable items have made original contributions .",
    "we adopt a very simple and natural policy , the one that always orders , as much as possible , to the critical newsvendor quantile corresponding to the empirical demand distribution .",
    "the optimal ordering quantity for a newsvendor problem involving holding cost @xmath4 , backlogging or effective lost sales cost @xmath5 , and known demand distribution @xmath6 , is the @xmath7-quantile of the distribution @xmath6 , where @xmath1 . by the beginning of period @xmath8",
    ", the empirical distribution @xmath9 one has about demand is defined by the frequencies of various demand levels reached in periods @xmath10 .",
    "the heuristic policy advocates ordering up to the @xmath7-quantile of @xmath9 in every period @xmath8 .",
    "it has been considered by besbes and muharremoglu @xcite .",
    "our nonperishable - inventory variant needs to further ensure that items left over from earlier periods are accounted for .",
    "this is a difficult point that requires quite careful treatments .",
    "we analyze two cases . in the first case in which the @xmath7-quantile estimation of none of the demand distributions considered is overly sensitive to small errors ,",
    "we show that the worst regret will be bounded by a time - invariant constant .",
    "though the flat rate over time is impressive , the result can be faulted by its requirement on the unknown distribution s behavior around its @xmath7-quantile .",
    "we thus go on to the second , more involved , case where all potential demand distributions are allowed .",
    "given any @xmath3 , we show that the worst regret over all distributions will not grow faster than the rate @xmath2 . in view of the @xmath11-sized lower",
    "bound achieved at lemma 4 of besbes and muharremoglu @xcite , this is almost the best one could hope for .",
    "our derivation invokes large - deviation and information - theoretic results such as sanov s theorem and pinsker s inequality , as well as innate features of empirical distributions and inventory control .",
    "methodological advances might find applications elsewhere .",
    "our simulation study indicates the high likelihood with which the worst regret grows at the @xmath11-rate .",
    "thus , it remains as a future research item whether the @xmath3 in our upper bound can be removed .",
    "the study also shows that the newsvendor - based policy compares favorably with the adaptation to huh and rusmevichientong s @xcite sa - based policy .",
    "this is expected , as the former uses more information about past demand realizations . through the study",
    ", we also confirm that the underlying distribution s separation from @xmath7 plays a prominent role in determining the regret generated by the newsvendor - based policy .",
    "the remainder of the paper is organized as follows .",
    "section  [ easy ] introduces notation , problem formulation , and the newsvendor - based policy . the time - invariant bound with demand restriction around @xmath7",
    "is given in section  [ 1bd ] , while the slower - over - time bound without any demand restriction is derived in section  [ 2bd ] .",
    "we present results of our simulation study in section  [ computation ] .",
    "the paper is concluded in section  [ conclusions ] .",
    "we consider a multi - period inventory control problem in which unsatisfied demand is either backlogged or lost . also , items are nonperishable so that those unsold in one period are carried over to the next period .",
    "demand @xmath12 in each period @xmath13 is a random draw from a distribution with discrete support @xmath14 , where @xmath15 is some positive integer .",
    "a generic distribution is representable by a vector @xmath16 in the @xmath15-dimensional simplex within @xmath17 : @xmath18^{\\bar d+1}|\\sum_{d=0}^{\\bar d } f(d)=1\\}.\\ ] ] we use @xmath19 to denote the cumulative distribution function ( cdf ) associated with any given @xmath20 .",
    "it satisfies @xmath21 for @xmath22 .",
    "we suppose production cost is linear at a unit rate @xmath23 .",
    "the concerned planning horizon constitutes periods @xmath24 . in the terminal period @xmath0",
    ", the firm will gain @xmath25 if it has @xmath26 leftover items and will need to pay @xmath27 if @xmath28 .",
    "also , assume strictly positive holding cost rate @xmath4 and strictly positive backlogging or effective lost sales cost rate @xmath5 . in the backlogging case , @xmath5 is usually in the same order of magnitude as @xmath4 ; whereas , in the lost sales case , @xmath5 is in the order of an item s profit margin and normally significantly greater than @xmath4 .",
    "when the firm orders up to @xmath29 and experiences demand @xmath30 in each period @xmath31 , its total cost in the backlogging case will be @xmath32.\\ ] ] since the first term in the above is not affected by the decision sequence @xmath33 , we shall focus on the latter inventory - related cost term . in the lost sales case , the same conclusion can be reached when @xmath5 is an item s profit margin plus the actual per - item lost sales cost ; see huh and rusmevichientong @xcite",
    ".    given @xmath34 , @xmath35 , and real - valued function @xmath36 defined on @xmath37 , we use @xmath38 $ ] to represent the average of @xmath39 when each @xmath40 is independently sampled from distribution @xmath6 : @xmath41\\equiv\\sum_{d_1=0}^{\\bar d}\\cdots\\sum_{d_t=0}^{\\bar d}f(d_1)\\times\\cdots\\times f(d_t)\\times g(d_1, ... ,d_t).\\ ] ] for subset @xmath42 , we understand @xmath43 $ ] by @xmath44 $ ] .",
    "note that @xmath45=\\mathbb{e}_f[{\\bf 1}(d_t\\leq d)]=\\sum_{d'=0}^{d}f(d')=f_f(d).\\ ] ]    define @xmath46 for every @xmath34 and @xmath47 , so that @xmath48=\\sum_{d=0}^{\\bar d } f(d)\\cdot(h\\cdot(y - d)^++b\\cdot(d - y)^+)\\\\ & = h\\cdot\\sum_{d=0}^{y-1}f_f(d)+b\\cdot\\sum_{d = y}^{\\bar d-1}(1-f_f(d ) ) .",
    "\\end{array}\\ ] ] it is the single - period average cost under order - up - to level @xmath49 .",
    "let @xmath50 be the minimum cost in one period under @xmath6 .",
    "suppose @xmath51 is an order - up - to level that achieves the one - period minimum .",
    "then , when facing a @xmath0-period horizon , an optimal policy will be to repeatedly order up to this level .",
    "thus , the minimum cost over @xmath0 periods is @xmath52 .    a salient feature of our current problem , however , is that @xmath6 is not known beforehand .",
    "so instead of any @xmath6-dependent policy , we seek a good @xmath6-independent policy which takes advantage of demand levels observed in the past .",
    "an adaptive policy @xmath53 is such that , for @xmath35 , each @xmath54 is a function of the historical demand vector @xmath55}\\equiv ( d_1, ... ,d_{t-1})\\in \\{0,1, ...",
    ",\\bar d\\}^{t-1}$ ] . under it ,",
    "the @xmath0-period total average cost is @xmath56})-d_t)^+ + b\\cdot ( d_t - y_t({\\bf d}_{[1,t-1]}))^+]=\\sum_{t=1}^t \\mathbb{e}_f[q_f(y_t({\\bf d}_{[1,t-1]}))],\\ ] ] where the second equality comes from the independence between @xmath57}$ ] and @xmath58 .",
    "now define @xmath0-period regret @xmath59 of using the adaptive policy @xmath60 against the unknown distribution @xmath6 : @xmath61}))]-q^*_f\\cdot t.\\ ] ] here , the ultimate goal should be that of identifying adaptive policies @xmath60 that prevent @xmath59 from growing too fast in @xmath0 under all or at least most @xmath6 s within @xmath62 .",
    "we concentrate on one policy inspired by an optimal @xmath51 when @xmath6 is known . from  ( [ def0 ] )",
    ", we see that necessary and also sufficient conditions for optimality of any @xmath49 are @xmath63 and @xmath64 let @xmath1 be the famous newsvendor parameter that lies in @xmath65 .",
    "for @xmath34 , let @xmath66 be the associated newsvendor order - up - to level , so that @xmath67 by definition , @xmath68 and hence @xmath69 by  ( [ cond1 ] ) ; also , @xmath70 and hence @xmath71 by  ( [ cond2 ] ) .",
    "therefore , @xmath72 , meaning that @xmath66 is an optimal order - up - to level for the one - period problem when @xmath6 is known . now with @xmath6 unknown , we might adopt level @xmath73 where @xmath74 is a good estimate of @xmath6 after observing demand vector @xmath75}$ ] . .",
    "the prime candidate for @xmath74 is the empirical distribution @xmath9 . for @xmath76 , define @xmath77 by @xmath78 , so that for every @xmath79 , @xmath80 each @xmath9 has its corresponding cdf @xmath81 .",
    "both @xmath9 and @xmath82 are certainly functions of the past demand vector @xmath83}\\equiv ( d_1,d_2, ... ,d_{t-1})$ ] . however , for notational simplicity we have refrained from making this dependence explicit .",
    "our heuristic policy applies the newsvendor formula to the empirical demand distribution .",
    "it lets the firm order nothing in period 1 ; that is , @xmath84 . for any @xmath76",
    ", it advises the firm to order up to @xmath85 in period @xmath8 , in which @xmath86    for simplicity , we have not made the dependence of @xmath29 and @xmath87 on @xmath83}$ ] explicit . nor have we used the full @xmath88}$]-dependent notation on @xmath89 .",
    "this will apply to the remainder of the paper . for the lost sales case",
    ", we need to guarantee that @xmath90 and hence enhance  ( [ yt - def ] ) to @xmath91 .",
    "however , the current heuristic through  ( [ newsboy ] ) has ensured that @xmath92 .",
    "so the same  ( [ yt - def ] ) can still be used . of course",
    ", a typical @xmath7 for the backlogging case might be around @xmath93 , whereas a typical @xmath7 for the lost sales case might be close to 1 .    our main purpose is to show that the @xmath6-blind and yet adaptive policy @xmath60 described by  ( [ yt - def ] ) and  ( [ newsboy ] ) will incur regret @xmath59 as defined by  ( [ r - def ] ) that is slow - growing in the planning length @xmath0 for most or even all @xmath6 s among @xmath62 .",
    "the requirement of @xmath94 in  ( [ yt - def ] ) , as necessitated by our nonperishable - inventory setting , renders decisions made over different periods more entangled with one another .",
    "along with the discrete - demand setup , this substantially complicates the problem s analysis .",
    "we first establish a bound for @xmath59 when there are guarantees on the distances between the @xmath95 values and the critical value @xmath7 . by  ( [ r - def ] ) and  ( [ yt - def ] ) , @xmath96 where @xmath97-q^*_f\\cdot t,\\ ] ] and , since @xmath84 by design and hence @xmath98 , @xmath99.\\ ] ] it might be said that @xmath100 represents the price paid for the regrettable fact that the policy @xmath60 was not designed with the particular distribution @xmath6 in mind ; meanwhile , @xmath101 captures the additional cost due to the nonperishability of items .",
    "we find it convenient to bound @xmath100 and @xmath101 separately .",
    "due to @xmath66 s definition in  ( [ yf - def ] ) , we must have @xmath102 ; for otherwise , @xmath66 could be made even smaller .",
    "now there are two cases , with    case 1 : @xmath103 ; and ,    case 2 : @xmath104 .",
    "we concentrate on case 1 first .",
    "let us use @xmath105 $ ] to denote the bernoulli distribution where the chance for 1 is @xmath106 and that for 0 is @xmath107 .",
    "then , the numbers @xmath108 and @xmath109 represent two bernoulli distributions .",
    "use @xmath110 and @xmath111 for the empirical distributions of @xmath112 and @xmath113 , respectively , both recording frequencies of 1 s in the first @xmath114 bernoulli draws .",
    "one important observation is that @xmath115=\\mathbb{p}_f[\\hat f_{t-1}(y^*_{f,\\beta}-1)\\geq \\beta]=\\mathbb{p}_{\\alpha_{f,\\beta}}[\\hat \\alpha_{t-1}\\geq \\beta],\\\\ \\mathbb{p}_f[\\hat f_{t-1}^{\\;-1}(\\beta)\\geq y^*_{f,\\beta}+1]=\\mathbb{p}_f[\\hat f_{t-1}(y^*_{f,\\beta})<\\beta]=\\mathbb{p}_{\\gamma_{f,\\beta}}[\\hat \\gamma_{t-1}<\\beta ] .",
    "\\end{array}\\right.\\ ] ] by a special version of sanov s theorem ( dembo and zeitouni @xcite , ( 2.1.12 ) ) , we have upper bounds for right - hand sides above : @xmath116\\leq t^2\\cdot\\exp(-(t-1)\\cdot\\inf_{x\\in [ \\beta,1]}\\mbox{d}_{kl}(x||\\alpha_{f,\\beta})),\\\\ \\mathbb{p}_{\\gamma_{f,\\beta}}[\\hat \\gamma_{t-1}<\\beta]\\leq t^2\\cdot\\exp(-(t-1)\\cdot\\inf_{x\\in [ 0,\\beta)}\\mbox{d}_{kl}(x||\\gamma_{f,\\beta } ) ) , \\end{array}\\right.\\ ] ] respectively , where @xmath117 i.e. , the relative entropy or kullback - leibler divergence between bernoulli distributions @xmath118 and @xmath119 .",
    "since @xmath120 is known to be convex with minimum achieved at @xmath119 ( cover and thomas @xcite , theorems 2.6.3 and 2.7.2 ) , @xmath121}\\mbox{d}_{kl}(x||\\alpha_{f,\\beta})=\\mbox{d}_{kl}(\\beta||\\alpha_{f,\\beta})>0,\\\\ \\inf_{x\\in [ 0,\\beta)}\\mbox{d}_{kl}(x||\\gamma_{f,\\beta})=\\mbox{d}_{kl}(\\beta||\\gamma_{f,\\beta})>0 .",
    "\\end{array}\\right.\\ ] ] now @xmath122    combining  ( [ ineq1 ] ) to  ( [ kappa - def ] ) , we have both @xmath123 $ ] and @xmath124 $ ] being bounded from above by @xmath125 . in view of  ( [ newsboy ] ) ,",
    "@xmath126\\vee\\mathbb{p}_f[\\hat y_t\\geq y^*_{f,\\beta}+1]\\leq \\min\\{t^2\\cdot\\exp(-\\kappa_{f,\\beta}\\cdot(t-1)),1\\}.\\ ] ] we can identify a large enough @xmath127 , so that for @xmath128 , both @xmath129 and @xmath130    now @xmath100 as given in  ( [ def1 ] ) can be bounded .",
    "[ 1-bound ] under case 1 , it is true that @xmath131    all proofs of this section can be found in appendix  [ appendix1 ] .",
    "proposition  [ 1-bound ] demonstrates that there is a @xmath0-independent bound for @xmath100 ; however , the constant is heavily dependent on the relative positioning between the unknown distribution @xmath6 and the parameter @xmath7 .",
    "it conveys the same message as besbes and muharremoglu s @xcite theorem 2 on the repeated newsvendor problem . for our case involving nonperishable items , we still need a bound on @xmath101 defined in  ( [ def2 ] ) . for this purpose ,",
    "suppose @xmath132 .    [ 2-bound ] under case 1",
    ", it is true that @xmath133    the proof revolves around bounding @xmath134 $ ] for @xmath8 large enough .",
    "when case 2 occurs , let @xmath135 be such that @xmath136 from  ( [ cond1 ] ) , we see that @xmath137 so instead of @xmath138 $ ] , we need only to estimate @xmath139 $ ] . but according to  ( [ ineq1 ] ) , this is the same as @xmath140 $ ] for @xmath141 . now",
    "due to  ( [ posi ] ) , @xmath142 .",
    "so the same bounds as in propositions  [ 1-bound ] and  [ 2-bound ] can be established .",
    "a definition suitable for both cases is that @xmath143    now we can achieve an upper bound for @xmath59 , regardless of the case we are in . for any @xmath34 ,",
    "define @xmath6 s separation from @xmath7 by @xmath144 given @xmath145 , define @xmath146 to be the collection of @xmath6 s with guaranteed lower bounds on both @xmath147 and @xmath148 : @xmath149 it turns out that @xmath59 has an upper bound that is uniform across @xmath150 .    [ newsboy - up ] for any @xmath145 , there is a positive constant @xmath151 so that @xmath152    theorem  [ newsboy - up ] shows that the regret @xmath59 is bounded from above by a constant independent of time @xmath0 , so long as there are known lower bounds on both @xmath153 and @xmath148 , the separation between @xmath6 and @xmath7 . between the two requirements",
    ", the first one appears more reasonable as @xmath15 can always be the highest level that demand can ever reach .",
    "the second requirement , on the other hand , straddles between both demand distributions and cost parameters .",
    "it seems far - fetched to exclude a priori distributions @xmath6 satisfying @xmath154 from consideration .",
    "due to the shortcoming inherent in the previous bound , we feel compelled to derive a bound on @xmath59 that requires no prior knowledge on @xmath6 , let alone its relative positioning with respect to the cost parameter @xmath7 .",
    "the new analysis involves sanov s theorem which offers a large - deviational bound on the difference between an empirical distribution and its generating distribution , pinsker s inequality which connects two distances between distributions , markov s inequality , and innate properties of the inventory management problem .",
    "let @xmath155 be the relative entropy or kullback - leibler divergence between distributions @xmath36 and @xmath6 in @xmath62 , so that @xmath156 sanov s theorem ( dembo and zeitouni @xcite , ( 2.1.12 ) ) states that , for any set @xmath157 of the demand space @xmath62 that is closed in the euclidean metric , @xmath158\\leq",
    "t^{\\bar d+1}\\cdot\\exp(-(t-1)\\cdot\\inf_{g\\in g}\\mbox{d}_{kl}(g||f)).\\ ] ] let @xmath159 be the total variation between distributions @xmath6 and @xmath36 ; i.e. , @xmath160 which also equals @xmath161 .",
    "pinsker s inequality ( cover and thomas @xcite , lemma 11.6.1 ) specifies that @xmath162    with the absence of any prior knowledge on the @xmath34 , we can manage to obtain a @xmath2-bound on the @xmath100 defined in  ( [ def1 ] ) for any @xmath3 .",
    "due to  ( [ newsboy ] ) , the key is to show that @xmath163 will converge to 0 quickly . in view of the sanov property  ( [ ssnv ] ) , this will be achievable if we can show that @xmath164 will be small when @xmath36 and @xmath6 are close by .",
    "this is when pinsker s inequality  ( [ pinsker ] ) and other properties related to the inventory management problem , such as the optimality of @xmath66 to @xmath165 and the linearity of @xmath166 in the distance between @xmath6 and @xmath36 , will be useful .",
    "the final form of the bound comes from the estimation of certain summations through integrations .",
    "[ 1-bound - hp ] for any @xmath3 , there are positive constants @xmath167 and @xmath168 , so that @xmath169    all proofs of this section can be found in appendix  [ appendix2 ] . the current result is ultimately about bounding the two sums @xmath170 and @xmath171 simultaneously for a sequence @xmath172 ; see  ( [ abv ] ) in our proof .",
    "the @xmath2-sized rate comes from our choice of @xmath173 to balance the two terms .",
    "if we remove @xmath3 , the first sum will give a @xmath11-sized rate but the second sum will fail to achieve a below-@xmath0 rate .",
    "this is why we can attain the @xmath2-sized rate for an arbitrarily small @xmath3 but never the exact @xmath11-sized rate .",
    "next , we obtain a bound in the same order of magnitude for @xmath101 as defined by  ( [ def2 ] ) .",
    "let us first get some more understanding on the entity . from  ( [ yt - def ] ) , we see that @xmath174 there is a latest @xmath175 so that @xmath176 which occurs exactly when @xmath177 and @xmath178    inspired by the above , we define random variables @xmath179 and @xmath180 in an iterative fashion as follows .",
    "first , let @xmath181 .",
    "now for some @xmath182 , suppose @xmath183 has been settled .",
    "then , let @xmath184 be the first @xmath8 after @xmath183 so that @xmath185 if such a @xmath186 can be identified . if not , mark the latest @xmath187 as @xmath188 and let @xmath189 .",
    "for any @xmath8 , let @xmath190 be the largest @xmath191 .",
    "this @xmath190 can serve as the earlier @xmath175 satisfying  ( [ critical ] ) and  ( [ reit ] ) that corresponds to @xmath8 . note that @xmath190 along with @xmath192 are independent of @xmath58 .",
    "so by  ( [ def2 ] ) , as well as  ( [ great ] ) to  ( [ notso ] ) , @xmath193.\\ ] ] now we are in a position to derive the bound .",
    "[ 2-bound - hp ] for any @xmath3 , there exist positive constants @xmath194 and @xmath195 so that @xmath196    this is the most difficult result of the paper .",
    "we will exploit the observations made from  ( [ expp ] ) to  ( [ ee74 ] ) to the fullest extent , with the basic understanding that the actual order - up - to level @xmath29 will be @xmath197 for some @xmath198 .",
    "we are tasked to show that the term @xmath199 can be bounded . for @xmath200",
    ", we divide the proof into two cases , the one with @xmath201 and the other one with @xmath202 .    in the former large-@xmath203 case",
    ", demand will accumulate over time with a guaranteed speed and @xmath204 will occur ever more surely as @xmath205 increases .",
    "then , for the minority case where @xmath205 is small , by exploiting natures of the empirical distribution and the newsvendor formula , we can come up with bounds related to @xmath206 .",
    "especially important is the observation that @xmath207 only if @xmath208 see  ( [ dada ] ) later .",
    "we will end up with a trade - off already encountered in the proof of proposition  [ 1-bound - hp ] ; see  ( [ chicago ] ) in the proof .",
    "this is the source of the @xmath2-sized growth rate .",
    "however , the constants will grow as @xmath203 shrinks , because it takes ever longer for demand to accumulate .",
    "therefore , we seek a different approach for the latter small-@xmath203 case , when @xmath209 .",
    "this is the time when @xmath210 because @xmath211 .",
    "we utilize the fact that @xmath212 is the bare minimum for @xmath213 .",
    "but the latter will be true only if both @xmath214 and for some @xmath215 , both @xmath216 and @xmath217 .",
    "for all @xmath203 s in the interval @xmath218 , we achieve a uniform bound in the order of @xmath219 , which is dominated by the one obtained in the first case .    besides sanov s theorem and pinsker s inequality , the proof also exploits markov s inequality in bounding @xmath220 $ ] , which , through  ( [ yf - def ] ) to  ( [ newsboy ] ) , is the chance for the portion of earlier demand levels at or exceeding @xmath221 to be greater than @xmath222 .",
    "combining propositions  [ 1-bound - hp ] and  [ 2-bound - hp ] , we get a bound for @xmath59 that is not tangled up with how @xmath6 positions with @xmath7 .    [ newsboy - up - hp ] for any @xmath3 , there are positive constants @xmath223 and @xmath224 so that @xmath225    the constants involved can depend on the problem s parameters @xmath4 , @xmath5 , and @xmath15 .",
    "however , they are uniform across all @xmath6 s in @xmath62 . for the repeated newsvendor problem , besbes and muharremoglu @xcite has already shown a @xmath11-sized lower bound ( lemma 4 , with @xmath226 replaced by @xmath227 in its ( c-8 ) ) .",
    "the example used for the bound involves distributions @xmath6 with small separations from @xmath7 but in opposite directions . according to  ( [ yt - def ] )",
    ", the current case merely adds the restriction @xmath228})\\geq",
    "y_{t-1}({\\bf d}_{[1,t-2]})-d_{t-1}$ ] to the adaptive policy considered .",
    "so the lower bound can be no better .    in view of this , the above is almost the best one can hope for .",
    "huh and rusmevichientong s @xcite sa - based policy was shown to have a @xmath11-sized bound when ordering quantities are discrete .",
    "but the analysis was done for the repeated - newsvendor setting . the policy s adaptation to the nonperishable - item setting , as to occur in  ( [ lala ] ) and",
    "( [ lalala ] ) , appears to be more complicated .",
    "its full analysis awaits further research .",
    "in the study , we fix @xmath229 and @xmath230 . we let @xmath5 s variation drive changes in @xmath1 . smaller @xmath7 values are suitable for the backlogging case and larger @xmath7 values the lost sales case . at each parameter combination , we randomly generate @xmath231 distributions @xmath6 in @xmath62 uniformly . within each run",
    "@xmath232 , particularly , let @xmath233 be independent random variables uniformly distributed on @xmath234 $ ] .",
    "rank them so that @xmath235 also , let @xmath236 and @xmath237 .",
    "we create @xmath238 so that @xmath239    under each @xmath6 out of the @xmath240 possibilities , we test policies @xmath241 for @xmath242 periods on @xmath243 sample paths of demand levels . in each period @xmath8 on the @xmath244th path",
    ", we generate a random variable @xmath245 uniformly distributed on @xmath234 $ ] .",
    "then , let demand @xmath30 in that period be the only @xmath79 that satisfies @xmath246 let @xmath247 be the order - up - to level in period @xmath8 under policy @xmath241 .",
    "we use the following as an approximation to the policy s expected regret by time @xmath8 : @xmath248\\},\\ ] ] where @xmath249 stands for average over the @xmath243 demand paths .    for any @xmath250 , we let @xmath251 be the conditional value at risk at the @xmath252-quantile of the @xmath240 regrets @xmath253 .",
    "for instance , @xmath254 would stand for the average of the top 50 highest @xmath255 values , where each is the regret of policy @xmath241 under the designated @xmath7 value by time @xmath256 , out of the @xmath231 randomly generated @xmath6 s .",
    "also , @xmath257 would be the average of all the @xmath255 s of @xmath6 s sampled from all over @xmath62 .",
    "in addition , @xmath258 would be the worst average regret found over the @xmath231 randomly generated distributions @xmath6 .",
    "suppose policy @xmath241 is the @xmath60 studied earlier .",
    "then , when @xmath240 and @xmath259 both approach @xmath260 and @xmath252 approaches 100% , the value @xmath251 will approach @xmath261 , the focal point of theorem  [ newsboy - up - hp ] , at the particular @xmath7 .",
    "since @xmath259 is finite , each @xmath253 is merely an approximation of the regret @xmath262 .",
    "moreover , the finiteness of @xmath240 means that the @xmath6 in @xmath62 generating the worst regret will most likely be missed .",
    "nevertheless , the @xmath251 values will yield insights into regrets stemming from policies @xmath241 .",
    "we mainly test two policies @xmath241 , with @xmath263 and 1 , respectively .",
    "policy 0 is our newsvendor - based one defined through  ( [ yt - def ] ) and  ( [ newsboy ] ) .",
    "policy 1 is adapted from the sa - based one proposed by huh and rusmevichientong @xcite to the current nonperishable - inventory setting .",
    "it still follows  ( [ yt - def ] ) , although its generation of the @xmath87 s is different from  ( [ newsboy ] ) . for the latter , let @xmath264 .",
    "there is also an auxiliary process @xmath265 . in the beginning ,",
    "@xmath266 . then for @xmath76 , @xmath267 where @xmath268    we have considered policy 2 , which uses both  ( [ yt - def ] ) and the definition of the @xmath172 sequence .",
    "the policy is inspired by both stochastic approximation and derman s @xcite up - and - down idea . instead of  ( [ newsboy ] ) or  ( [ lala ] ) and  ( [ lalala ] )",
    ", it uses the following for its updating of @xmath87 : @xmath269 however , our simulation study indicates that policy 2 is not competitive against either of the previous two policies , except when @xmath7 is close to 0.5 , at which time it is better than policy 1 in some occasions .",
    "so we omit presenting its performances .    at various @xmath252 and @xmath7 values , and at different @xmath8 points",
    ", we compare @xmath251 among policies . at various @xmath7 values",
    ", we can evaluate @xmath251 for policies @xmath263 and 1 at times @xmath270 , @xmath271 , @xmath272 , @xmath273 and @xmath252 values at 0% , 95% , and 99.9% . except for scaling differences",
    ", we find the basic findings do not depend much on @xmath7 . in figures  [ fig1 ] to  [ fig09 ] , we just present results at the three @xmath7 values of 0.1 , 0.5 , and 0.9 . instead of @xmath8 , we have used @xmath274 as our horizontal axis .",
    "values when @xmath275     values when @xmath276     values when @xmath277    from these figures , we can observe that policy 0 generates much smaller regrets , in both average and worst senses , than policy 1 .",
    "this should be anticipated , as policy 0 utilizes more information regarding past observations than policy 1 .",
    "we also see that regrets for both policies grow at approximately the rate of @xmath274 . in figure",
    "[ fig5aa ] , we provide a close - up for policy 0 at @xmath278 . here",
    ", we have sampled @xmath279 demand distributions , made measurements at time points @xmath280 , and tried @xmath281 , @xmath282 , @xmath283 , and @xmath284 .",
    "values when @xmath276    to understand what roles the distributions separations from @xmath7 have played in the formation of regrets , let us define @xmath285 as the average of the separations @xmath148 , as defined by  ( [ ag - def ] ) and  ( [ small - def ] ) , from among the @xmath286 distributions @xmath6 with the worst regrets . for instance , @xmath287 would be the average of the @xmath148 s among the 500 @xmath6 s which give the worst @xmath255 by time @xmath256 , out of the @xmath279 randomly generated @xmath6 s .",
    "in figure  [ fig5a ] , we present @xmath285 for policies @xmath263 and 1 at times @xmath288 , @xmath252 values at 0% , 95% , 99.9% , and 99.99% , and @xmath278 . pictures at other @xmath7 values look similar .",
    "values when @xmath276    at @xmath281 , the values @xmath289 are flat when @xmath8 changes , because it is always the average of the @xmath279 @xmath290 s . from figure  [ fig5a",
    "] , we also see that @xmath291 is decreasing in @xmath252 at large enough @xmath8 s .",
    "this is consistent with theorem  [ newsboy - up ] , showing that , in the long run , the selection of distributions @xmath6 with large regrets will gravitate toward those with small separations from @xmath278 .",
    "in contrast , @xmath292 seems to receive no clear influence from @xmath252 .",
    "we can also introduce an inseparability index @xmath293 to indicate how difficult it is to separate demand distributions @xmath6 from @xmath7 .",
    "suppose @xmath294 with @xmath295 has been identified .",
    "then , in the place of  ( [ replacable ] ) , we generate @xmath296 so that @xmath297 and generate @xmath298 so that @xmath299 all other steps are the same as before .",
    "our previous case happens when @xmath203 is set at the default value 0 .",
    "when @xmath203 grows , there will be more chance that the generated @xmath6 has a smaller separation from @xmath7 .",
    "we can define @xmath300 as the @xmath252-quantile of the @xmath240 regrets @xmath253 , but this time with the @xmath6 s generated under the given @xmath203 using  ( [ rep1 ] ) and  ( [ rep2 ] ) instead of  ( [ replacable ] ) .",
    "the previous @xmath251 is just @xmath301 . in figure",
    "[ f - g ] , we show @xmath302 for policies @xmath263 and 1 at @xmath252 values 0% , @xmath282 , and @xmath283 , and @xmath203 values at 0 , 0.5 , 0.9 , 0.95 , 0.99 , 0.995 , and 0.999 .",
    "values when @xmath278 and @xmath303    figure  [ f - g ] shows that @xmath304 is decreasing with @xmath203 .",
    "this is consistent with our earlier observation that smaller separations seem to help improve the performance of policy 1 . at the same time",
    ", the increase of @xmath203 does not make policy 0 significantly worse .",
    "this seems to suggest a slow rise of the constant bound in theorem  [ newsboy - up ] when the smallest allowed level of separation @xmath305 dwindles . for this to be reconcilable with the @xmath274-sized rise in regret as indicated by both theorem  [ newsboy - up - hp ] and figure  [ fig5aa ]",
    ", we will need the `` leading '' separation for policy 0 to decrease over time .",
    "this has somewhat been confirmed by figure  [ fig5a ] .",
    "in regret bounds for a newsvendor - based adaptive policy , we have contributed to inventory control involving unknown demand of discrete nonperishable items .",
    "currently , our analysis relies on knowledge of the maximum per - period demand @xmath15 .",
    "also , our universal bound is related to a strictly positive parameter @xmath305 .",
    "both deserve more attention .",
    "in addition , the newsvendor - based policy requires higher observability of historical demand levels than other policies , say the sa - based one .",
    "this makes it ill suited to situations involving demand censoring .",
    "furthermore , we have not touched on realistic features like nonzero setup costs or lead times .",
    "so a great deal awaits to be done in future research .    99    besbes , o. and a. zeevi .",
    "dynamic pricing without knowing the demand function : risk bounds and near - optimal algorithms . _ operations research _ , * 57 * , pp .",
    "1407 - 1420 .",
    "besbes , o. and a. muharremoglu . 2013 . on implications of demand censoring in the newsvendor problem . _ management science _ , * 59 * , pp . 1407 - 1424 .",
    "burnetas , a.n . and m.n .",
    "optimal adaptive policies for sequential allocation problems . _ advances in applied mathematics _ , * 17 * , pp .",
    "122 - 142 .",
    "burnetas , a.n . and m.n .",
    "optimal adaptive policies for markov decision processes .",
    "_ mathematics of operations research _ , * 22 * , pp .",
    "222 - 255 .",
    "burnetas , a.n .",
    "kanavetas , o. and m.n . katehakis .",
    "asymptotically optimal multi - armed bandit policies under a cost constraint , preprint arxiv:1509.02857 .",
    "cowan , w. and m.n .",
    "asymptotically optimal sequential experimentation under generalized ranking , preprint arxiv:1510.02041 .",
    "cowan , w. and m.n .",
    "asymptotic behavior of minimal - exploration allocation policies : almost sure , arbitrarily slow growing , regret , preprint arxiv:1505.02865 .",
    "cover , t.m . and",
    "thomas . 2006 .",
    "_ elements of information theory , 2nd edition_. wiley - interscience , new york .",
    "dembo , a. and o. zeitouni .",
    "large deviations techniques and applications , 2nd edition_. springer , heidelberg .",
    "derman , c. 1957 .",
    "non - parametric up - and - down experimentation .",
    "_ annals of mathematical statistics _ , * 28 * , pp .",
    "795 - 798 .",
    "huh , w.t . and p. rusmevichientong . 2009 . a non - parametric asymptotic analysis of inventory planning with censored demand . _ mathematics of operations research _ , * 34 * , pp .",
    "103 - 123 .",
    "katehakis , m.n .",
    "and h. robbins .",
    "sequential choice from several populations .",
    "_ proceedings of the national academy of sciences _ , * 92 * , pp . 8584 - 8585 .",
    "kiefer , j. and j. wolfowitz .",
    "stochastic estimation of the maximum of a regression function .",
    "_ annals of mathematical statistics _ , * 23 * , pp .",
    "462 - 466 .",
    "lai , t.l .",
    "and h. robbins .",
    "asymptotically efficient adaptive allocation rules . _",
    "advances in applied mathematics _ , * 6 * , pp . 4 - 22 .",
    "lariviere , m.a . and e.l . porteus .",
    "1999 . stalking information : bayesian inventory management with unobserved lost sales . _ management science _ , * 43 * , pp .",
    "346 - 363 .",
    "levi , r. , r.o .",
    "roundy , and d.b . shmoys .",
    "provably near - optimal sampling - based policies for stochastic inventory control models . _",
    "mathematics of operations research _ , * 32 * , pp .",
    "821 - 839 .",
    "perakis , g. and g. roels . 2008 .",
    "regret in the newsvendor model with partial information . _ operations research _ , * 56 * , pp .",
    "188 - 203 .",
    "robbins , h. 1952 . some aspects of the sequential design of experiments .",
    "_ bulletins of american mathematical society _ , * 58 * , pp .",
    "527 - 535 .",
    "robbins , h and s. monro , s. 1951 . a stochastic approximation method .",
    "_ annals of mathematical statistics _ , * 22 * , pp . 400 - 407 .",
    "scarf , h. 1959 .",
    "bayes solutions of the statistical inventory problem .",
    "_ annals of mathematical statistics _ , * 30 * , pp . 490 - 508 .",
    "* appendices *",
    "* proof of proposition  [ 1-bound ] : * combining  ( [ def0 ] ) and  ( [ def1 ] ) , we have @xmath306-\\mathbb{e}_f[(y^*_{f,\\beta}-d_t)^+]\\}\\\\ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;+ b\\cdot\\sum_{t=1}^{t } \\{\\mathbb{e}_f[(d_t-\\hat y_t)^+]-\\mathbb{e}_f[(d_t - y^*_{f,\\beta})^+]\\}. \\end{array}\\ ] ] when @xmath307 , @xmath308 whereas , when @xmath309 , @xmath310 plugging these into  ( [ okkk ] ) , we obtain @xmath311\\cdot\\mathbb{e}_f[(y-\\max\\{y^*_{f,\\beta},d_t\\})^+]\\\\ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;+b\\cdot\\sum_{t=1}^t \\sum_{y=0}^{y^*_{f,\\beta}-1 } \\mathbb{p}_f[\\hat y_t = y]\\cdot\\mathbb{e}_f[(\\min\\{y^*_{f,\\beta},d_t\\}-y)^+ ] , \\end{array}\\ ] ] which is below @xmath312\\vee \\mathbb{p}_f[\\hat y_t\\leq y^*_{f,\\beta}-1]$ ] . therefore , @xmath313\\vee",
    "\\mathbb{p}_f[\\hat y_t\\leq y^*_{f,\\beta}-1],\\ ] ] which , due to  ( [ useful1 ] ) to  ( [ aha1 ] ) , is below the desired upper bound .   +   * proof of proposition  [ 2-bound ] : * combining  ( [ def0 ] ) and  ( [ def2 ] ) , we have @xmath314 + b \\cdot\\sum_{t=3}^{t}\\mathbb{e}_f[(d_t - y_t)^+-(d_t-\\hat y_t)^+].\\ ] ] note @xmath315 from  ( [ yt - def ] ) .",
    "so in view of both  ( [ ineq10 ] ) and the fact that @xmath316 , @xmath317.\\ ] ] but this is further below @xmath318 $ ] . hence , @xmath319.\\ ] ] so the key is to bound @xmath320 $ ] for @xmath321 .",
    "however , @xmath322 = \\mathbb{p}_f[y_{t+1}\\geq \\hat{y}_{t+1}+1|\\hat{y}_{t+1}=y^*_{f,\\beta}]\\cdot\\mathbb{p}_f[\\hat{y}_{t+1}=y^*_{f,\\beta}]\\\\ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;+\\mathbb{p}_f[y_{t+1}\\geq \\hat{y}_{t+1}+1 |\\hat{y}_{t+1 }",
    "\\neq y^*_{f,\\beta}]\\cdot\\mathbb{p}_f[\\hat{y}_{t+1 } \\neq y^*_{f,\\beta}]\\\\ \\;\\;\\;\\;\\;\\;\\leq \\mathbb{p}_f[y_{t+1}\\geq y^*_{f,\\beta}+1]+\\mathbb{p}_f[\\hat y_{t+1}\\leq y^*_{f,\\beta}-1]+\\mathbb{p}_f[\\hat y_{t+1}\\geq y^*_{f,\\beta}+1 ] . \\end{array}\\ ] ] thus , from  ( [ useful1 ] ) to  ( [ aha1 ] ) , @xmath323 \\leq \\mathbb{p}_f[y_{t+1}\\geq y^*_{f,\\beta}+1]+\\exp(-\\frac{\\kappa_{f,\\beta}\\cdot(t-\\tau_{f,\\beta})}{2}).\\ ] ] meanwhile , @xmath324 = \\mathbb{p}_f[y_{t+1}\\geq y^*_{f,\\beta}+1|y_{t}\\geq y^*_{f,\\beta}+1]\\cdot \\mathbb{p}_f[y_{t}\\geq y^*_{f,\\beta}+1]\\\\ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;+\\mathbb{p}_f[y_{t+1}\\geq y^*_{f,\\beta}+1|y_{t}\\leq y^*_{f,\\beta}]\\cdot\\mathbb{p}_f[y_{t}\\leq y^*_{f,\\beta}]\\\\ \\;\\;\\;\\;\\;\\;\\leq\\mathbb{p}_f[y_{t}-d_{t}\\geq y^*_{f,\\beta}+1|y_{t}\\geq y^*_{f,\\beta}+1]\\cdot \\mathbb{p}_f[y_{t}\\geq y^*_{f,\\beta}+1]\\\\ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;+\\mathbb{p}_f[\\hat{y}_{t+1}\\geq y^*_{f,\\beta}+1| y_{t}\\geq y^*_{f,\\beta}+1]\\cdot \\mathbb{p}_f[y_{t}\\geq y^*_{f,\\beta}+1]\\\\ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;+\\mathbb{p}_f[\\hat{y}_{t+1}\\geq y^*_{f,\\beta}+1| y_{t}\\leq y^*_{f,\\beta}]\\cdot \\mathbb{p}_f[y_{t}\\leq y^*_{f,\\beta}]\\\\ \\;\\;\\;\\;\\;\\;=\\mathbb{p}_f[y_{t}-d_{t}\\geq y^*_{f,\\beta}+1|y_{t}\\geq y^*_{f,\\beta}+1]\\cdot \\mathbb{p}_f[y_{t}\\geq y^*_{f,\\beta}+1]+\\mathbb{p}_f[\\hat{y}_{t+1}\\geq y^*_{f,\\beta}+1 ] , \\end{array}\\ ] ] where the first equality is an identity , the first inequality comes from  ( [ yt - def ] ) , and the next equality is another identity when combining the previous two terms . note @xmath325 or @xmath326 , and the latter would have occurred for sure when @xmath327 . concerning part of the first term in the above , as @xmath328 , @xmath329\\leq \\mathbb{p}_f[d_t\\leq \\bar d - y^*_{f,\\beta}-1]=f_f(\\bar d - y^*_{f,\\beta}-1).\\ ] ] also in view of  ( [ useful1 ] ) to  ( [ aha1 ] )",
    ", we have from  ( [ 19 ] ) and  ( [ 191 ] ) that @xmath330\\leq f_f(\\bar d - y^*_{f,\\beta}-1)\\cdot\\mathbb{p}_f[y_{t}\\geq y^*_{f,\\beta}+1]+\\frac{\\exp(-\\kappa_{f,\\beta}\\cdot(t-\\tau_{f,\\beta})/2)}{2}.\\ ] ] because @xmath132 , @xmath331 so for @xmath332 , we have the iterative relation @xmath330\\leq ( 1-\\epsilon_f)\\cdot \\mathbb{p}_f[y_t\\geq y^*_{f,\\beta}+1]+\\frac{\\exp(-\\kappa_{f,\\beta}\\cdot(t-\\tau_{f,\\beta})/2)}{2}.\\ ] ] noting that @xmath333\\leq 1 $ ] , we obtain @xmath330\\leq ( 1-\\epsilon_f)^{t-\\tau_{f,\\beta}+1}+\\frac{1}{2}\\cdot\\sum_{s=0}^{t-\\tau_{f,\\beta}}(1-\\epsilon_f)^{t-\\tau_{f,\\beta}-s}\\cdot\\exp(-\\frac{\\kappa_{f,\\beta}\\cdot s}{2}).\\ ] ] summing over @xmath334 , we obtain @xmath335 \\leq   \\frac{1-\\epsilon_f}{\\epsilon_f}+\\frac{1}{2\\epsilon_f\\cdot(1-\\exp(-\\kappa_{f,\\beta}/2))}.\\ ] ]    combining  ( [ kooo ] ) ,  ( [ 18 ] ) , and  ( [ 20 ] ) , we obtain @xmath336\\\\ & \\;\\;\\;\\;\\;\\;+h\\bar d\\cdot\\sum_{t=\\tau_{f,\\beta}}^{+\\infty}\\exp(-\\kappa_{f,\\beta}\\cdot(t-\\tau_{f,\\beta})/2)\\\\ & \\leq h\\bar d\\cdot\\tau_{f,\\beta}+h\\bar d\\cdot\\sum_{t=\\tau_{f,\\beta}}^{+\\infty}\\mathbb{p}_f[y_{t+1}\\geq y^*_{f,\\beta}+1]+ h\\bar d/(1-\\exp(-\\kappa_{f,\\beta}/2 ) ) , \\end{array}\\ ] ] which is below the desired upper bound .",
    "+   * proof of theorem  [ newsboy - up ] : * putting  ( [ regret0 ] ) as well as propositions  [ 1-bound ] and  [ 2-bound ] together , we can obtain an upper bound for @xmath59 : @xmath337 for @xmath338 , we already have @xmath339 by the definition in  ( [ delta - def ] ) .",
    "also , note that @xmath340 is convex with minimum achieved at @xmath118 ( cover and thomas @xcite , theorems 2.6.3 and 2.7.2 ) .",
    "so in view of  ( [ kappa - def ] ) ,  ( [ ag - def ] ) , and  ( [ small - def ] ) , @xmath341 which is further greater than @xmath342 due to @xmath6 s membership in the @xmath343 defined by  ( [ delta - def ] ) . we can define @xmath344 for @xmath345 in the same fashion in which @xmath127 is defined for @xmath346 ; namely , through  ( [ aha2 ] ) and  ( [ aha1 ] ) .",
    "clearly , @xmath347 .",
    "since  ( [ qqq ] ) is decreasing in @xmath147 , @xmath346 , and increasing in @xmath127 , we can replace them by , respectively , @xmath305 , @xmath345 , and @xmath344 .",
    "the new right - hand side would constitute the desired @xmath151 .",
    "* proof of proposition  [ 1-bound - hp ] : * for @xmath348 , note that @xmath164 can be written as @xmath349+[q_g(y^*_{g,\\beta})-q_g(y^*_{f,\\beta})]+[q_g(y^*_{f,\\beta})-q_f(y^*_{f,\\beta})].\\ ] ] while the first and third terms can be made small when @xmath6 and @xmath36 are close , the second term is always negative due to @xmath350 s optimality when the underlying demand distribution is @xmath36 .",
    "let us investigate how small the first and third terms can be .",
    "for any @xmath47 , @xmath351(y - d)+b\\cdot\\sum_{d = y+1}^{\\bar d } [ f(d)-g(d)](d - y)\\\\ & \\leq ( h\\vee b)\\cdot\\bar d\\cdot \\mid\\mid f - g\\mid\\mid_1=2\\cdot ( h\\vee b)\\cdot\\bar d\\cdot\\delta_v(f , g ) .",
    "\\end{array}\\ ] ] in view of the discussion around  ( [ discuss ] ) , @xmath352 through pinsker s inequality  ( [ pinsker ] ) , we see that  ( [ pre - p ] ) will become @xmath353 note  ( [ def0 ] ) also leads to @xmath354    for a fixed @xmath355 , consider @xmath356",
    ". then  ( [ ssnv ] ) will result with @xmath357\\leq t^{\\bar d+1}\\cdot\\exp(-\\varepsilon\\cdot(t-1)).\\ ] ] consider @xmath100 defined at  ( [ def1 ] ) . by  ( [ newsboy ] ) , we have @xmath358-q_f(y^*_{f,\\beta})\\}.\\ ] ] let @xmath172 be a sequence of positive constants .",
    "we then see that @xmath100 is below @xmath359\\cdot \\mathbb{e}_f[q_f(y^*_{\\hat f_{t-1},\\beta})-q_f(y^*_{f,\\beta})|\\mbox{d}_{kl}(\\hat f_{t-1}||f)<\\varepsilon_t]\\\\ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;+\\mathbb{p}_f[\\mbox{d}_{kl}(\\hat f_{t-1}||f)\\geq\\varepsilon_t]\\cdot \\mathbb{e}_f[q_f(y^*_{\\hat f_{t-1},\\beta})-q_f(y^*_{f,\\beta})|\\mbox{d}_{kl}(\\hat f_{t-1}||f)\\geq\\varepsilon_t]\\}\\\\ \\;\\;\\;\\;\\;\\;\\leq ( h\\vee b)\\cdot \\bar d\\cdot\\sum_{t=1}^t [ 2\\sqrt{2\\varepsilon_t}+t^{\\bar d+1}\\cdot\\exp(-\\varepsilon_t\\cdot ( t-1 ) ) ] , \\end{array}\\ ] ] where the inequality comes from  ( [ pinsker - son ] ) to  ( [ sanov - son ] ) .",
    "suppose @xmath173 for some @xmath360 . plugging this into  ( [ abv ] ) , we get @xmath361 where @xmath362 since @xmath363 is decreasing in @xmath8 , @xmath364 note that @xmath365 is positive , increasing first , and decreasing next .",
    "so @xmath366 since @xmath367 , we have @xmath368 being below @xmath369\\\\ \\;\\;\\;\\;\\;\\;\\leq 2e\\cdot \\int_1^{+\\infty } t^{\\bar d+1}\\cdot \\exp(-t^{2\\epsilon})\\cdot dt , \\end{array}\\ ] ] where @xmath370 is the natural logarithmic base .",
    "letting @xmath371 and hence @xmath372",
    ", we obtain @xmath373 meanwhile , for @xmath374 , integral by parts has @xmath375 equal to @xmath376 which is below an @xmath252-dependent constant . combining  ( [ ok1 ] ) to  ( [ ok3 ] )",
    ", we see that @xmath368 is below an @xmath305-dependent constant .",
    "together with  ( [ ko1 ] ) and  ( [ ko2 ] ) , we see that for any @xmath360 , there are constants @xmath167 and @xmath168 for the intended bound to be true .",
    "furthermore , by adopting @xmath377 and @xmath378 for @xmath379 , the inequality can be maintained for every @xmath3 .",
    "+      consider the first case with @xmath380 $ ] .",
    "for any positive integer @xmath382 , we show how @xmath383 $ ] can be bounded . by the definition of the @xmath183 s around  ( [ notso ] ) , @xmath384 since both @xmath385 and @xmath386 are between 0 and @xmath15 ,",
    "the above necessitates that @xmath387 this is only possible when there are at least @xmath388 zeros among the @xmath389 demand levels @xmath390 .",
    "when @xmath391 , the latter event s chance under @xmath6 with @xmath392 is , by the binomial formula , @xmath393 which is less than @xmath394 .",
    "there exists @xmath395 so that when @xmath396 , the aforementioned term will decrease with @xmath397 . for @xmath398",
    ", we can thus deduce that @xmath399<(\\tau_t+1)^{\\bar d}\\cdot ( 1-\\gamma)^{\\tau_t-\\bar d+1}.\\ ] ]    each of the terms in  ( [ ee74 ] ) is between 0 and @xmath400 .",
    "so by  ( [ critical ] ) and  ( [ import - bound ] ) , @xmath401\\\\ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;+(t-2)\\cdot ( h\\bar d+b\\bar d)\\cdot ( \\tau_t+1)^{\\bar d}\\cdot ( 1-\\gamma)^{\\tau_t-\\bar d+1}. \\end{array}\\ ] ] the above right - hand side can be written as @xmath402 where for @xmath403 , @xmath404 .",
    "\\end{array}\\ ] ] by  ( [ yf - def ] ) and  ( [ newsboy ] ) , we have @xmath405 only if @xmath406 also , due to the nature of the empirical distribution as illustrated in  ( [ emp ] ) , @xmath407 therefore , @xmath405 only if @xmath408 an inequality alluded to earlier in  ( [ dada - o ] ) . on the other hand ,  ( [ def0 ] ) has that , for @xmath409 , @xmath410 now by  ( [ joke ] ) ,  ( [ dada ] ) , and  ( [ 77o ] ) , @xmath411 is less than @xmath412 $ ] , where @xmath413 in general , @xmath414 noting in turn that @xmath415 , which is less than @xmath416 due to pinsker s inequality  ( [ pinsker ] ) , we also have @xmath417 . \\end{array}\\ ] ] so for a sequence @xmath172 ,",
    "@xmath418\\cdot\\mathbb{p}_f[\\mbox{d}_{kl}(\\hat f_{t-1}||f)\\leq\\varepsilon_t]\\\\ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;+(h+b)\\cdot\\sum_{t=\\tau+2}^t\\mathbb{e}_f[z_t|\\mbox{d}_{kl}(\\hat f_{t-1}||f)>\\varepsilon_t]\\cdot\\mathbb{p}_f[\\mbox{d}_{k}(\\hat f_{t-1}||f)>\\varepsilon_t ] , \\end{array}\\ ] ] which by  ( [ sanov - son ] ) ,  ( [ gen ] ) , and  ( [ impotent ] ) , is less than @xmath419.\\ ] ] the situation we face is very similar to  ( [ abv ] ) except for the @xmath420-term .",
    "so as in proposition  [ 1-bound - hp ] , for any @xmath3 , there are constants @xmath421 , @xmath422 , and @xmath423 so that @xmath424 note the @xmath423-term stems from the @xmath420-term in  ( [ chicago ] ) . in view of  ( [ okkk0 ] ) and  ( [ kkko ] ) , @xmath425 when @xmath382 is above the @xmath426 defined right after  ( [ bazaj ] )",
    "otherwise , we have almost the same inequality , albeit with the last term replaced by @xmath427 . choose @xmath382 appropriately , say @xmath428 .",
    "then , as long as @xmath0 is large enough , say greater than some @xmath429 , we can ensure that @xmath430 is above @xmath426 .",
    "very importantly , just because @xmath431 $ ] , we can make sure that the last term , regardless whether @xmath430 is below or above @xmath426 , is always bounded from above by a positive constant @xmath432 .",
    "thus , @xmath433 however , as long as @xmath0 is large enough , the @xmath2-sized term will dominate all other terms .",
    "a constant term can certainly cover the case when @xmath0 is not that large .",
    "therefore , positive constants @xmath434 and @xmath195 exist for the intended inequality @xmath435 since @xmath436 can be used for cases with @xmath437 , we can have the intended bound , namely , @xmath438 as long as @xmath203 stays above @xmath439 .",
    "we now turn to the second case with @xmath381 . from  ( [ ee74 ] ) , @xmath101 is equal to @xmath440\\cdot \\mathbb{p}_f[l(t)=s]\\\\ \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\leq ( h\\bar d+b\\bar d)\\cdot\\sum_{t=3}^t\\max_{s=2}^{t-1}\\mathbb{p}_f[\\hat y_s - d_s-\\cdots - d_{t-1}\\geq 1 ] , \\end{array}\\ ] ] in which the inequality is attributable to the facts that @xmath441\\leq 1 $ ] and that @xmath442 for @xmath443 , which is easy to see from  ( [ def0 ] ) . but @xmath444\\leq",
    "\\mathbb{p}_f[\\hat y_s\\geq 1]\\wedge ( \\sum_{d=1}^{\\bar d}\\mathbb{p}_f[\\hat y_s\\geq d]\\cdot \\mathbb{p}_f[d_s+\\cdots+d_{t-1}\\leq d-1]).\\ ] ] meanwhile , by  ( [ newsboy ] ) and the current range of @xmath203 , @xmath445=\\mathbb{p}_f[\\hat f_{s-1}(0)<\\beta]\\leq \\mathbb{p}_f[\\delta_v(f,\\hat f_{s-1})>1-\\beta-\\gamma],\\ ] ] which , due to pinsker s inequality  ( [ pinsker ] ) , is below @xmath446 $ ] .",
    "but by sanov s  ( [ ssnv ] ) , the latter is below @xmath447 .",
    "thus , @xmath448\\leq s^{\\bar d+1}\\cdot\\exp(-2\\cdot(1-\\beta-\\gamma)^2\\cdot(s-1)).\\ ] ] now for @xmath215 , let @xmath449 .",
    "our setup is such that @xmath450 .",
    "again due to  ( [ newsboy ] ) , @xmath451=\\mathbb{p}_f[\\hat f_{s-1}(d-1)<\\beta]=\\mathbb{p}_f[\\sum_{\\tau=1}^{s-1}{\\bf 1}(d_\\tau\\geq d)>(1-\\beta)\\cdot ( s-1)].\\ ] ] note that @xmath452 are independent bernoulli random variables with mean @xmath453 , and hence @xmath454 is a binomial random variable with mean @xmath455 .",
    "so by markov s inequality , the rightmost term in  ( [ lucky ] ) is below @xmath456}{(1-\\beta)\\cdot(s-1)}=\\frac{\\gamma_d}{1-\\beta}.\\ ] ] therefore , @xmath457\\leq \\frac{\\gamma_d}{1-\\beta}.\\ ] ] also , it is easy to see that @xmath458\\leq ( 1-\\gamma_d)^{t - s}.\\ ] ]    combining  ( [ loose - c ] ) ,  ( [ a22 ] ) ,  ( [ okko ] ) , and  ( [ a330 ] ) , we obtain @xmath459\\\\ \\;\\;\\;\\leq \\max_{s=2}^{t-1}[s^{\\bar d+1}\\cdot \\exp(-2\\cdot(1-\\beta-\\gamma)^2\\cdot(s-1))]\\wedge\\\\   \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\wedge[\\sum_{d=1}^{\\bar d}(\\gamma_d/(1-\\beta))\\cdot ( 1-\\gamma_d)^{t - s } ] .",
    "\\end{array}\\ ] ] consider @xmath460 .",
    "there exists a @xmath461 so that for any @xmath462 , the function @xmath463 will decrease with @xmath8 , and also @xmath464 note also that @xmath465 for @xmath466 .",
    "next , consider @xmath467 .",
    "note that @xmath468,\\ ] ] and @xmath469.\\ ] ] so the @xmath5-maximizing @xmath470 is @xmath471 .",
    "plugging back , we have @xmath472 note that @xmath473 , the natural logarithmic base which is above 2 .",
    "so when @xmath397 is large enough , say greater than some @xmath474 , the above will be below @xmath475 .    for @xmath476",
    ", the upper bound in  ( [ joye ] ) is further bounded by a constant plus @xmath477 which , according to the above from  ( [ azaza ] ) to  ( [ bzaza ] ) , is below @xmath478.\\ ] ] but this is smaller than @xmath479,\\ ] ] which has a constant - plus-@xmath219 bound .",
    "so , there exist positive constants @xmath423 and @xmath480 so that @xmath481 for any @xmath466 . now between  ( [ intended ] ) and  ( [ tendin ] ) , only the former has to be used when @xmath482 is made large enough .",
    "we therefore have the intended bound ."
  ],
  "abstract_text": [
    "<S> inventory control with unknown demand distribution is considered , with emphasis placed on the case involving discrete nonperishable items . </S>",
    "<S> we focus on an adaptive policy which in every period uses , as much as possible , the optimal newsvendor ordering quantity for the empirical distribution learned up to that period . </S>",
    "<S> the policy is assessed using the regret criterion , which measures the price paid for ambiguity on demand distribution over @xmath0 periods . when there are guarantees on the latter s separation from the critical newsvendor parameter @xmath1 , a constant upper bound on regret can be found . without any prior information on the demand distribution , </S>",
    "<S> we show that the regret does not grow faster than the rate @xmath2 for any @xmath3 . in view of a known lower bound , this is almost the best one could hope for . </S>",
    "<S> simulation studies involving this along with other policies are also conducted .    </S>",
    "<S> * keywords : * inventory control ; newsvendor ; critical quantile ; empirical distribution ; large deviation ; information theory </S>"
  ]
}