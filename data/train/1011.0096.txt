{
  "article_text": [
    "pattern recognition ( or classification or discrimination ) is about predicting the unknown nature of an observation : an observation is a collection of numerical measurements , represented by a vector @xmath2 belonging to some measurable space @xmath3 .",
    "the unknown nature of the observation is denoted by @xmath4 belonging to a measurable space @xmath5 . in pattern recognition ,",
    "the goal is to create a measurable map @xmath6 ; @xmath7 which represents one s prediction of @xmath4 given @xmath2 .",
    "the error of a prediction @xmath7 when the true value is @xmath4 is measured by @xmath8 , where the loss function @xmath9 . for simplicity , we suppose @xmath10 . in a probabilistic",
    "setting , the distribution @xmath11 of the random variable @xmath12 describes the probability of encountering a particular pair in practice .",
    "the performance of @xmath13 , that is how the predictor can predict future data , is measured by the risk @xmath14 . in practice ,",
    "we have access to @xmath15 independent , identically distributed ( @xmath16 ) random pairs @xmath17 sharing the same distribution as @xmath18 called the learning sample and denoted @xmath19 . a learning algorithm @xmath20 is trained on the basis of @xmath19 .",
    "thus , @xmath20 is a measurable map from @xmath21 to @xmath5 .",
    "@xmath22 is predicted by @xmath23 the performance of @xmath24 is measured by the conditional risk called the generalization error denoted by @xmath25 $ ] with @xmath26 independent of @xmath27 and with the following equivalent notation for the conditional expectation of @xmath28 given @xmath22 : @xmath29 . in the following , if there is no ambiguity , we will also allow the notation @xmath30 instead of @xmath31 .",
    "notice that @xmath32 is a random variable measurable with respect to @xmath19 .",
    "an important question is : _ the distribution @xmath11 of the generating process being unknown , can we estimate how good a predictor trained on a learning sample of size @xmath15 is ?",
    "in other words , can we estimate the generalization error @xmath32 ? _",
    "this fundamental statistical problem is referred to ",
    "choice and assessment of statistical predictions  @xcite .",
    "many estimates have been proposed , among them the resubstitution estimate ( or training estimate ) .",
    "the predictor is trained using the entire learning sample @xmath19 , and an estimate of the prediction is obtained by running the same learning process through the predictor and comparing predicted and actual responses .",
    "thus , the resubstitution estimate @xmath33 can severely underestimate the bias .",
    "it can even drop to zero for some machine learning even though the generalization error is nonzero ( for example , the @xmath34nearest neighbor ) .",
    "the difficulty arises from the fact that the learning sample is used both for training and testing . in order",
    "to get rid of this downward bias , the estimation of the generalization error based on sample reuse have been favored among practitioners .",
    "quoting @xcite : _ probably the simplest and most widely used method for estimating prediction error is cross - validation_. however , the role of cross - validation estimator , denoted by @xmath35 , is far from being well understood in a general setting . in particular",
    ", the following problems remain partially solved : ",
    "is @xmath36 a good estimator of the generalisation error ?  ,  how should one choose @xmath0 in a @xmath0-fold cross - validation  or  does cross - validation outperform the resubstitution error ?  .",
    "the purpose of this paper is to give a partial answer to the first two questions .",
    "we introduce our * main result * for symmetric cross - validation procedures .",
    "we divide the learning sample into two samples : the training sample and the test sample , to be defined below .",
    "we denote by @xmath37 the percentage of elements in the test sample such that @xmath38 is an integer . for empirical risk minimizers over a class of predictors with finite vc - dimension @xmath39 , to be defined below , we have the following concentration inequality , for all @xmath40 : @xmath41    with    * @xmath42 * @xmath43    the term @xmath44 is a vapnik - chernovenkis - type bound controlled by the size of the training sample @xmath45 whereas the term @xmath46 is the minimum between a hoeffding - type term controlled by the size of the test sample @xmath47 , a polynomial term controlled by the size of the training sample .",
    "as the percentage of observations in the test sample @xmath37 increases , the @xmath46 term decreases but the @xmath48 term increases .",
    "the difference from the previous results on estimation of @xmath32 is in the following :    * our bounds for intensive cross - validation procedures ( i.e. @xmath0-fold cross - validation or leave-@xmath49-out cross - validation ) are not worse than those for hold - out cross - validation . * our inequalities not only",
    "depend on the percentage of observations in the learning sample @xmath37 but also on the precise type of cross - validation procedure : this is why we can discriminate between @xmath0-fold cross - validation and hold - out cross - validation even if @xmath37 is the same .",
    "* we show that the size of the test sample does not need to grow to infinity for the cross - validation procedure to be consistent for the estimation of the generalization error .    using these probability bounds",
    ", we can then deduce that the expectation of the difference between the generalization error and the cross - validation estimate @xmath50 is of order @xmath51 .",
    "as far as @xmath50 is concerned , we can define a splitting rule : the percentage of elements @xmath37 in the test sample should be proportional to @xmath52 , i.e. the larger the class of predictors is , the smaller the test sample in the cross - validation should be .",
    "the paper is organized as follows . in the next section ,",
    "we give a short review of literature .",
    "we detail the main cross - validation procedures and we summarize the previous results for the estimation of generalization error . in section 3 , we introduce the main notations and definitions .",
    "finally , in section 4 , we introduce our results , in terms of concentration inequalities . in companion papers",
    ", we will show that in some cases , the cross - validation estimate can outperform the training estimate and prove that cross - validation can work out with infinite vc - dimension predictor .",
    "the cross - validation @xmath36 includes leave - one - out cross - validation , @xmath0-fold cross - validation , hold - out cross - validation ( or split sample ) , leave-@xmath53-out cross - validation ( or monte carlo cross - validation or bootstrap cross - validation ) . in leave - one - out cross - validation ,",
    "a single sample of size @xmath15 is used .",
    "each member of the sample in turn is removed , the full modeling method is applied to the remaining @xmath54 members , and the fitted model is applied to the hold - backmember .",
    "an early ( 1968 ) application of this approach to classification is that of @xcite .",
    "@xcite gave perhaps the first application in multiple regression and @xcite sketches other applications .",
    "however , this special form of cross - validation has well - known limitations , both theoretical and practical , and a number of authors have considered more general multifold cross - validation procedures @xcite ; @xcite ; @xcite ; @xcite ; @xcite ; @xcite ; @xcite ; @xcite ; @xcite ; @xcite ; @xcite ) .",
    "the @xmath0-fold procedure divides the learning sample into @xmath0 equally sized  folds .",
    "then , it produces a predictor by training on @xmath55 folds and testing on the remaining fold .",
    "this is repeated for each fold , and the observed errors are averaged to form the @xmath0-fold estimate . leave-@xmath49-out",
    "cross - validation is a more elaborate and expensive version of cross - validation that involves leaving out all possible subsamples of @xmath49 cases . in the split - sample method or",
    "hold - out , only a single subsample ( the training sample ) is used to estimate the generalization error , instead of @xmath0 different subsamples ; i.e. , there is no crossing .",
    "intuitively , there is a tradeoff between bias and variance in cross - validation procedures .",
    "typically , we expect the leave - one - out cross - validation to have a low bias ( the generalization error of a predictor trained on @xmath54 pairs should be close to the generalization error of a predictor trained on the @xmath15 pairs ) but a high variance .",
    "leave - one - out cross - validation often works well for estimating generalization error for continuous loss functions such as the squared loss , but it may perform poorly for discontinuous loss functions such as the indicator loss . on the contrary , @xmath0-fold cross - validation or leave-@xmath49-out cross - validation are expected to have a higher bias but a smaller variance due to resampling .    with the exception of @xcite , theoretical investigations of multifold cross - validation procedures",
    "have first concentrated on linear models ( @xcite;@xcite;@xcite ) .",
    "results of @xcite and @xcite are discussed in section 3 .",
    "the first finite sample results are due to @xcite and concern @xmath0-local rules algorithms under leave - one - out and hold - out cross - validation .",
    "more recently , @xcite derived finite sample results for the hold - out , @xmath56fold and leave - one - out cross - validations for finite vc  algorithms in the realisable case ( the generalization error is zero ) .",
    "but the bounds for @xmath56fold cross - validation are @xmath0 times worse than for hold - out cross - validation .",
    "@xcite have emphasized when @xmath56fold can out perform hold - out cross - validation in a particular case of @xmath0-fold predictor .",
    "@xcite has extended such results in the case of stable algorithms for the leave - one - out cross - validation procedure .",
    "@xcite also derived results for hold - out cross - validation for vc algorithms without the realisable assumption .",
    "however , the bounds obtained are ",
    "sanity check bounds  in the sense that they are not better than classical vapnik - chernovenkis s bounds .",
    "@xcite derived finite sample results for the distance between the cross - validation estimate and a special benchmark and proved asymptotic results for the relation between the cross - validation risk and the generalization error .",
    "to our knowledge , bounds for intensive cross - validation procedures are missing .",
    "this might be due to the lack of independence between the crossing terms of the cross - validated estimate @xcite .",
    "we introduce here useful definitions to define the various cross - validation procedures .",
    "first , we define binary vectors , i.e. @xmath57 is a vector of size @xmath15 , such that for all @xmath58 and @xmath59 . consequently , knowing the binary vector , we can define the subsample associated with it : @xmath60 .",
    "the weighted empirical error of @xmath61 is denoted by @xmath62 and defined by : @xmath63for @xmath64 , with @xmath65 the binary vector of size @xmath15 with @xmath66 at every coordinate , we will use the simpler notation @xmath67 . for a predictor trained on a subsample ,",
    "we define : @xmath68    with the previous notations , notice that the predictor trained on the learning sample @xmath69can be denoted by @xmath70",
    ". we will allow the simpler notation @xmath71 .",
    "the learning sample is divided into two disjoint samples : the training sample of size @xmath45 and the test sample of size @xmath47 , where @xmath37 is the percentage of elements in the test sample . to represent the training sample , we define a random binary vector @xmath72 of size @xmath15 independent of @xmath19 .",
    "@xmath72 is called the training vector .",
    "we define the test vector by @xmath73 to represent the test sample .",
    "the distribution of @xmath72 characterizes all the cross - validation procedures described in the previous section . using our notations",
    ", we can now define the cross - validation estimator .    with the previous notations ,",
    "the generalized cross - validation error of @xmath74 denoted by @xmath36 is defined by the conditionnal expectation of @xmath75 with respect to the random vector @xmath72 given @xmath19 : @xmath76    we will give here some examples of distributions of @xmath72 to show that we retrieve cross - validation procedures described previously .",
    "suppose @xmath77 is a integer .",
    "the @xmath0-fold procedure divides the data into @xmath0 equally sized  folds .",
    "it then produces a predictor by training on @xmath0 - 1 folds and testing on the remaining fold .",
    "this is repeated for each fold , and the observed errors are averaged to form the @xmath0-fold estimate .",
    "@xmath78    we provide another popular example : the leave - one - out cross - validation . in leave - one - out cross - validation , a single sample of size @xmath15 is used .",
    "each member of the sample in turn is removed , the full modeling method is applied to the remaining @xmath54 members , and the fitted model is applied to the hold - backmember .",
    "@xmath79    we denote by @xmath80 the minimal generalization error attained among the class of predictors @xmath81 , @xmath82 . in the sequel , we suppose that @xmath74 is an empirical risk minimizer over the class @xmath81 .",
    "for simplicity , we suppose the infimum is attained i.e. @xmath83 .",
    "notice that @xmath80 is a parameter of the unknown distribution @xmath84 whereas @xmath32 is a random variable .",
    "at last , recall the definitions of :    let @xmath85 be a collection of measurable sets .",
    "for @xmath86 @xmath87 , let @xmath88 be the number of differents sets in @xmath89    the n - shatter coefficient of @xmath85 is @xmath90    that is , the shatter coefficient is the maximal number of different subsets of @xmath15 points that can be picked out by the class of sets @xmath85 .",
    "let @xmath85 be a collection of sets with @xmath91 the largest integer @xmath92 for which @xmath93 is denoted by @xmath39 , and it is called the vapnik - chernovenkis dimension ( or vc dimension ) of the class @xmath85 .",
    "if @xmath94 for all n , then by definition @xmath95    a class of predictors @xmath81 is said to have a finite vc - dimension @xmath39 if the dimension of the collection of sets @xmath96\\}$ ] is equal to @xmath39 , where @xmath97 .",
    "in the sequel , we suppose that the training sample and the test sample are disjoint and that the number of observations in the training sample and in the test sample are respectively @xmath45 and @xmath47 .",
    "moreover , we suppose also that the @xmath74 is an empirical risk minimizer on a sample with finite vc - dimension @xmath39 and @xmath99 a loss function bounded by @xmath66 . we also suppose that the predictors are symmetric according to the training sample , i.e. the predictor does not depend on the order of the observations in @xmath19",
    ". eventually , the cross - validation are symmetric i.e. @xmath100 does not depend on @xmath101 , this excludes the hold - out cross - validation .",
    "* we denote these hypotheses by @xmath98 .",
    "*    we will show upper bounds of the kind @xmath102 with @xmath40 .",
    "the term @xmath44 is a vapnik - chernovenkis - type bound whereas the term @xmath46 is a hoeffding - like term controlled by the size of the test sample @xmath47 .",
    "this bound gives can be interpreted as a quantitative answer to the bias - variance trade - off question . as the percentage of observations in the test sample @xmath37 increases ,",
    "the @xmath46 term decreases but the @xmath44 term increases .",
    "notice that this bound is worse than the vapnik - chernovenkis - type bound and thus can be called a  sanity - check bound  in the spirit of @xcite .",
    "even though these bounds are valid for almost all the cross - validation procedures , their relevance depends highly on the percentage @xmath37 of elements in the test sample ; this is why we first classify them according to @xmath37 . at last ,",
    "notice that our bounds can be refined using chaining arguments .",
    "however , this is not the purpose of this paper .      the first result deals with large test samples , i.e. the bounds are all the better if @xmath47 is large .",
    "note that this result excludes the hold - out cross - validation because it does not make a symmetric use of the data .",
    "[ largets1]suppose that @xmath98 holds .",
    "then , we have for all @xmath103 , @xmath104    with    * @xmath105 * @xmath106    first , we begin with a useful lemma ( for the proof , see appendices )    [ ch1:lemme1 ]    under the assumption of proposition [ largets1 ] , we have for all @xmath107@xmath108and symmetrically    @xmath109    * proof of proposition [ largets1 ] .",
    "*    recall that @xmath74 is based on empirical risk minimization .",
    "moreover , for simplicity , we have supposed the infimum is attained _",
    "i.e. _ @xmath83 .",
    "define @xmath110 .",
    "we have by splitting according to @xmath111 : @xmath112    notice that @xmath113 .",
    "intuitively , @xmath114 corresponds to the variance term and is controlled in some way by the resampling plan . on the contrary , in the general setting , @xmath115 , and @xmath116",
    "is the bias term and measures the discrepancy between the error rate of size @xmath15 and of size @xmath117    the first term @xmath114 can be bounded via hoeffding s inequality , as follows    @xmath118    then , by jensen s inequality , we have @xmath119thus , for @xmath120 fixed vectors , we have by linearity of expectation and the i.i.d assumption    @xmath121    finally , by lemma 1 in @xcite since @xmath122 and the conditional independence :",
    "@xmath123    the second term may be treated by introducing the optimal error @xmath80 which should be close to @xmath32 ,    @xmath124    using the supremum and the fact that @xmath125 is an empirical risk minimizer , we obtain : @xmath126    then , since @xmath127 and by definition of @xmath74 , we deduce @xmath128    thus , by lemma [ ch1:lemme1 ] , we get @xmath129    recall the following result ( see e.g. @xcite ) @xmath130thus , we finally obtain    @xmath131    @xmath132    next , we obtain    [ largets]suppose that @xmath98 holds",
    ". then , we have , for all @xmath103 , @xmath133    * proof *    first , the following lemma holds ( for the proof , see appendices ) ,    [ lemme1 ]    suppose that @xmath98 holds , then we have @xmath134    thus ,",
    "@xmath135    @xmath132    using the two previous results , we have a concentration inequality for the absolute error @xmath136 ,    suppose that @xmath98 holds .",
    "then , we have , for all @xmath40 , @xmath137    with    * @xmath138 * @xmath106    with the previous concentration inequality , we can bound from above the expectation of @xmath139 :    [ cor : l1-largets]suppose that @xmath98 holds . then , we have , @xmath140    * proof . *",
    "this is a direct consequence of the following lemma :    [ ch1:lem esperance ] let @xmath141 be a nonnegative random variable .",
    "let @xmath142 nonnegative real such that @xmath143 .",
    "suppose that for all @xmath103 @xmath144 .",
    "then : @xmath145    @xmath132      the previous bound is not relevant for all small test samples ( typically leave - one - out cross - validation ) since we are not assured that the variance term converges to @xmath146 ( in leave - one - out cross - validation , @xmath147 ) .",
    "however , under @xmath98 , cross - validation with small test samples works also , as stated in the next proposition .",
    "[ smallts]suppose that @xmath98 holds .",
    "then , we have , for all @xmath103 , @xmath148 with    * @xmath149 * @xmath150    for small test samples , we get the same conclusion but the rate of convergence for the term @xmath114 is slower than for large test samples : typically @xmath151 against @xmath152    * proof .",
    "*    now , we get by splitting according to @xmath111 : @xmath153    first , from the proof of proposition [ largets ] , we have @xmath154    secondly , notice that @xmath155 . to control @xmath114",
    ", we will need the following lemma ( for the proof see appendices ) which says that if a bounded random variable @xmath141 is centered and is nonpositive with small probability then it is nonnegative with also small probability .",
    "[ ch1:monlemme ]    if @xmath156 and @xmath157 .",
    "then for all @xmath158 we get @xmath159    moreover , we have since @xmath160 by lemma [ lemme1 ]    @xmath161    using lemma [ ch1:lemme1 ] , it follows :    @xmath162    applying lemmas [ ch1:monlemme ] and inequality [ eq : shatter ] allows to conclude .",
    "@xmath132    we have the following complementary but not symmetrical result :    [ smallts]suppose that @xmath98 holds .",
    "then , we have for all @xmath103 , @xmath163    * proof .",
    "*    we have since @xmath164 :    @xmath135    @xmath132    from this result , we deduce that ,    suppose that @xmath98 holds .",
    "then , we have for all @xmath40 , @xmath137    * @xmath42 * @xmath165    eventually , we get    [ largets]suppose that @xmath98 holds . then , we have : @xmath166    we just need lemma [ ch1:lem esperance ] and the following simple lemma    let @xmath141 a nonnegative random variable bounded by @xmath66 , @xmath167 a real such that @xmath168 , for all @xmath103 . then , @xmath169    @xmath132    eventually , collecting the previous results , we can summarize the previous results for upper bounds in probability with the following theorem :    [ thm : sym ]    suppose that @xmath98 holds .",
    "then , we have for all @xmath40 , @xmath170    with    * @xmath171 * @xmath172    an interesting consequence of this proposition is that the size of the test is not required to grow to infinity for the consistency of the cross - validation procedure in terms of convergence in probability .      for @xmath0-fold cross - validation",
    ", we can simply use the previous bounds together .",
    "thus , we get    [ k - fold ] suppose that @xmath98 holds .",
    "then , we have for all @xmath103 , @xmath173    with    * @xmath174 * @xmath175    since @xmath176 , notice the previous bound can itself be bounded by    @xmath177    in fact , the bound for the variance term @xmath178 can be improved by averaging the @xmath0 training errors .",
    "this step emphasizes the interest of @xmath0-fold cross - validation against simpler cross - validation .",
    "[ k - fold ] suppose that @xmath98 holds .",
    "then , in the case of the @xmath0-fold cross - validation procedure , we have for all @xmath103 : @xmath179    thus , averaging the observed errors to form the @xmath0-fold estimate improves the term @xmath39 from @xmath180to @xmath181 .",
    "this result is important since it shows why intensive use of the data can be very fruitful to improve the estimation rate .",
    "another interesting consequence of this proposition is that , for a fixed precision @xmath182 , the size of the test is not required to grow to infinity for the exponential convergence of the cross - validation procedure . for this , it is sufficient that the size of the test sample is larger than a fixed number @xmath183 .    * proof . *    recall that the size of the training sample is @xmath184 , and the size of the test sample is then @xmath38 . for this proposition , we have @xmath185    we are interested in the behaviour of @xmath186 ) which is a sum of @xmath187 terms in the case of the @xmath0-fold cross - validation .",
    "the difficulty is that these terms are neither independent , nor even exchangeable .",
    "we have in mind to apply the results about the sum of independent random variables .",
    "for this , we need a way to introduce independence in our samples . in the same time",
    ", we do not want to lose too much information .",
    "for this , we will introduce independence by using by using the supremum .",
    "we have ,    @xmath188    now , we have a sum of @xmath189 i.i.d terms : @xmath190 , with @xmath191 .    however , we have an extra piece of information : an upper bound for the tail probability of these variables , using the concentration inequality due to @xcite .    @xmath192    with @xmath193 ) @xmath194 and @xmath195 .    in fact , summing independent bounded variables with exponentially small tail probability gives us a better concentration inequality than the simple sum of independent bounded variables .    to show this",
    ", we proceed in three steps :    1 .",
    "the @xmath196-hlder norms of each variable is uniformly bounded by @xmath197 , 2 .",
    "the laplace transform of @xmath198 is smaller than the laplace transform of some particular normal variable , 3 .   using chernoff s method",
    ", we obtain a sharp concentration inequality .    1 .   first step ( for the proof , see appendices ) , we prove + [ lem : subgaussian ] + let @xmath22 a random variable ( bounded by @xmath199 with subgaussian tail probability @xmath200 for all @xmath40 with @xmath201 and @xmath202",
    ". then , there exists a constant @xmath203 such that , for every integer @xmath196 , @xmath204with @xmath205 .",
    "second step ( see exercise 4 in @xcite ) , we have + [ lem : holder ] + if there exists a constant @xmath203 , such that for every integer @xmath196 @xmath206then we have @xmath207 3 .   third step , we have the result using chernoff s method .",
    "+ [ lem : chernoff ] + if , for some @xmath208 , @xmath209 , we have : @xmath210then if @xmath211 are i.i.d .",
    ", we have:@xmath212    putting lemma [ lem : subgaussian ] [ lem : holder ] lem : chernoff together , we eventually get :    @xmath213    @xmath132    symmetrically , we obtain :    suppose that @xmath98 holds .",
    "then , in the case of the @xmath0-fold cross - validation procedure , we have for all @xmath103 @xmath214    eventually , we have a control on the absolute deviation    [ ch1:thm kfold ] suppose that @xmath98 holds . then , in the case of the @xmath0-fold cross - validation procedure , we have for all @xmath215 , @xmath216    with    * @xmath217 *   @xmath218 @xmath219      for hold - out cross - validation , the symmetric condition that for all @xmath101 , @xmath220 is independent of @xmath101 is no longer valid . indeed , in the hold - out cross - validation ( or split sample )",
    ", there is no crossing again .    in the next proposition",
    ", we suppose that the training sample and the test sample are disjoint and that the number of observations in the learning sample and in the test sample are still respectively @xmath45 and @xmath47 .",
    "moreover , we suppose also that the predictors @xmath74 are empirical risk minimizers on a class @xmath81 with finite @xmath39-dimension @xmath39 and @xmath99 a loss function bounded by @xmath66 . * we denote these hypotheses by @xmath221 . *    we get the following result    [ holdout]suppose that @xmath221 holds . then , we have for all @xmath40 ,    @xmath222    with    * @xmath223 * @xmath224    * proof .",
    "* we just have to follow the same steps as in proposition [ thm : sym ] .",
    "but in the case of hold - out cross - validation , notice that    @xmath225    moreover , the lemma [ ch1:monlemme ] is no longer valid , since @xmath226 .",
    "@xmath227      we base the next discussion on upperbounds , so the following heuristic arguments are questionable if the bounds are loose .",
    "one can wonder : what is the use of averaging again over the different folds of the @xmath0-fold cross - validation , which is time consuming ? as far as the expected errors are concerned , the upper bounds are the same for crossing cross - validation procedures and for hold - out cross - validation . but suppose we are given a level of precision @xmath182 , and we want to find an interval of length @xmath228 with maximal confidence .",
    "then notice that @xmath229 .",
    "thus if @xmath37 is constant , @xmath230 : the term @xmath116 will be much greater for hold - out based on large learning size . on the contrary , if the learning size is small , then the term @xmath116 is smaller for non crossing procedure for a given @xmath37 .",
    "this might due to the absence of resampling .",
    "regarding the variance term @xmath231 , we need the size of the test sample to grow to infinity for the consistency of the hold - out cross - validation . on the contrary , for crossing cross - validation",
    ", the term @xmath114 converges to @xmath146 whatever the size of the test is .      if we consider the @xmath232 error , the upper bounds are the same for crossing cross - validation procedures and for other cross - validation procedures .",
    "but if we look for the interval of length @xmath228 with maximal confidence , then notice that @xmath233 ( with @xmath234 defined respectively in theorems [ ch1:thm kfold ] , [ thm : sym ] ) if the number of elements in the training sample @xmath47 is constant and large enough .",
    "thus , if the learning size is large enough , the @xmath114 term is much smaller for the @xmath0-fold cross - validation , thanks to the crossing .",
    "the expression of the variance term @xmath114 depends on the percentage of observations @xmath37 in the test sample and on the type of cross - validation procedure .",
    "we have thus a control of the variance term depending on @xmath235        we can define the estimation curve ( in probability or in @xmath232 norm ) which gives for each cross - validation procedure and for each @xmath37 the estimation error .",
    "let @xmath40 : @xmath236with @xmath44 and @xmath46 defined in theorem [ thm : sym ] .",
    "this can be done with the expectation of the absolute of deviation or with the probability upper bound if the level of precision is @xmath182 .",
    "@xmath237    with @xmath238 and @xmath239 defined as in proposition cor : l1-largets .",
    "we say that the estimation curve in probability experiences a phase transition when the convergence rate @xmath240  changes .",
    "the estimation curve experiences at least one transition phase .",
    "the transition phases just depend on the class of predictors and on the sample size . on the contrary of the learning curve , the transition phases of the estimation curve are independent of the underlying distribution .",
    "the different transition phases define three different regions in the values of @xmath37 the percentage of observations in the test sample .",
    "this three regions emphasize the different roles played by small test sample cross - validation , large test samples cross - validation and @xmath0-fold cross - validation .",
    "the estimation curve gives a hint for this simple but important question : how should one choose the cross - validation procedure in order to get the best estimation rate ?",
    "how should one choose @xmath0 in the @xmath0-fold cross - validation ?",
    "the quantitative answer of theses questions is the @xmath241 of the estimation curve @xmath242 .",
    "that is in probability    @xmath243    or in @xmath244 norm :    @xmath245    as far as the @xmath232 norm is concerned , we can derive a simple expression for the choice of @xmath37 .",
    "indeed , if we use chaining arguments in the proof of proposition [ ch1:lemme1 ] , that is : there exists a universal constant @xmath246 such that @xmath247 ( for the proof , see e.g. @xcite ) .",
    "the proposition cor : l1-largets thus becomes :    suppose that @xmath98 holds",
    ". then , there exists a universal constant @xmath246 such that : @xmath248    we can then minimize the last expression in @xmath37 .",
    "after derivation , we obtain @xmath249 .",
    "thus , the larger the vc - dimension is , the larger the training sample should be . since it may be difficult to find an explicit constant , one may try to solve : @xmath250 .",
    "we obtain then a computable rule @xmath251    another interesting issue is : knowing the number of observations @xmath252 and the class of predictors , we can now derive an optimal minimal @xmath253-confidence interval , together with the cross - validation procedure .",
    "we look at the values @xmath254 such that the upperbound @xmath255 is below the threshold @xmath256 .",
    "then , we select the couple @xmath257 among those values for which @xmath182 is minimal . on figure [ fig : splitting ] , we fix a choice of @xmath258 .",
    "we observe that , for values of @xmath15 between @xmath259 and @xmath260 and for small vc - dimension , a choice of @xmath261 , i.e. the ten - fold cross - validation , seems to be a reasonable choice .",
    "van der laan et al.(2004 ) allen , d. m. ( 1968 ) the relationship between variable selection and data augmentation and a method for prediction .",
    "_ technometrics _ , 16 , 125 - 127 .",
    "arlot , s. ( 2007 ) .",
    "model selection by resampling penalization .",
    "_ submitted to colt_.    bengio , y. and grandvalet , y. ( 2004 ) .",
    "no unbiased estimator of the variance of k - fold cross - validation .",
    "_ journal of machine learning research _ 5 , 1089 - 1105 .",
    "biswas , s. markatou , m. , tian , h. , and hripcsak , g. ( 2005 ) .",
    "analysis of variance of cross - validation estimators of the generalization error .",
    "_ journal of machine learning research _ , vol .",
    "6 , 1127 - 1168 .",
    "breiman , l. , friedman , j.h . , olshen , r. and stone , c.j .",
    "classification and regression trees .",
    "the wadsworth statistics probability series_. wadsworth international group .",
    "breiman , l. and spector , p. ( 1992 ) .",
    "submodel selection and evaluation in regression : the x - random case _ international statistical review _ , 60 , 291 - 319 .",
    "blum , a. , kalai , a. , and langford , j. ( 1999 ) . beating the hold - out : bounds for k - fold and progressive cross - validation .",
    "_ proceedings of the international conference on computational learning theory_.    bousquet , o. and elisseef , a. ( 2001 ) .",
    "algorithmic stability and generalization performance _ in advances in neural information processing systems _ 13 : proc . nips2000 .",
    "bousquet , o. and elisseef , a. ( 2002 ) .",
    "stability and generalization .",
    "_ journal of machine learning research _ , 2:499 - 526 .",
    "burman , p. ( 1989 ) . a comparative study of ordinary cross - validation , v - fold cross - validation and the repeated learning - testing methods . _ biometrika _ , 76:503 514 .",
    "devroye , l. , gyorfi , l. and lugosi , g. ( 1996 ) . a probabilistic theory of pattern recognition .",
    "number 31 in _ applications of mathematics_. springer .",
    "devroye , l. and wagner , t. ( 1979 ) .",
    "distribution - free performance bounds for potential function rules .",
    "_ ieee trans .",
    "inform . theory _ , vol.25 , pp .",
    "601 - 604 .",
    "devroye , l. and wagner , t. ( 1979 ) .",
    "distribution - free inequalities for the deleted and holdout error estimates .",
    "_ ieee transactions on information theory _ , vol.25(5 ) , pp .",
    "601 - 604 .",
    "dudoit , s. and van der laan , m.j .",
    "asymptotics of cross - validated risk estimation in model selection and performance assessment .",
    "_ technical report _ 126 , division of biostatistics , university of california , berkeley .",
    "dudoit , s. , van der laan , m.j . , keles , s. , molinaro , a.m. , sinisi , s.e . and teng , s.l .",
    "loss - based estimation with cross - validation : applications to microarray data analysis .",
    "_ sigkdd explorations , microarray data mining special issue_.    van der laan , m.j . , dudoit , s. and van der vaart , a. ( 2004),the cross - validated adaptive epsilon - net estimator , _ statistics and decisions _ , 24 373 - 395 .",
    "geisser , s. ( 1975 ) .",
    "the predictive sample reuse method with applications .",
    "_ journal of the american statistical association _ , 70:320328 .",
    "gyrfi , l .",
    "kohler , m. and krzyzak , m. and walk , h. ( 2002a ) . _ a distribution - free theory of nonparametric regression_. springer - verlag , new york .",
    "hastie , t. , tibshirani , r. and friedman , j.h .",
    "the elements of statistical learning : data mining , inference , and prediction .",
    "springer - verlag .",
    "hoeffding , w. ( 1963 ) .",
    "probability inequalities for sums of bounded random variables",
    ". _ journal of the american statistical association _ , 58 , 13?30 .",
    "holden , s.b .",
    "cross - validation and the pac learning model .",
    "_ research note _ rn/96/64 , dept . of cs , univ .",
    "college , london .",
    "holden , s.b .",
    "pac - like upper bounds for the sample complexity of leave - one - out cross validation . _ in proceedings of the ninth annual acm workshop on computational learning theory _ , pages 41 50 .",
    "kearns , m. and ron , d. ( 1999 ) .",
    "algorithmic stability and sanity - check bounds for leave - one - out cross - validation .",
    "_ neural computation _ , 11:1427 1453 .",
    "kearns , m. ( 1995 ) .",
    "a bound on the error of cross validation , with consequences for the training - test split . _ in advances in neural information processing systems 8_. the mit press .",
    "kearns , m. j. , mansour , y. , ng , a. and ron , d. ( 1995 ) .",
    "an experimental and theoretical comparison of model selection methods .",
    "_ in proceedings of the eighth annual acm workshop on computational learning theory _ , pages 21 30 . to appear in machine learning , colt95 special issue",
    "kutin , s. ( 2002 ) .",
    "extensions to mcdiarmid s inequality when differences are bounded with high probability . _ technical report _",
    ", department of computer science , the university of chicago . in preparation .",
    "kutin , s. and niyogi , p. ( 2002).almost - everywhere algorithmic stability and generalization error .",
    "_ uncertainty in artificial intelligence ( uai ) _ , august 2002 , edmonton , canada .",
    "lachenbruch , p.a . and",
    "mickey , m. ( 1968 ) .",
    "estimation of error rates in discriminant analysis",
    ". _ technometricslm68 _ estimation of error rates in discriminant analysis .",
    "_ technometrics _ , 10 , 1 - 11 .",
    "li , k - c .",
    "asymptotic optimality for cp , cl , cross - validation and generalized cross - validation : discrete index sample .",
    "_ annals of statistics _",
    ", 15:958975 .",
    "lugosi , g. ( 2003 ) .",
    "concentration - of - measure inequalities presented at _ the machine learning summer school 2003 _ , australian national university , canberra ,    mccarthy , p. j. ( 1976 ) . the use of balanced half - sample replication in crossvalidation studies .",
    "_ journal of the american statistical association _ , 71 : 596604 .",
    "mcdiarmid , c. ( 1989 ) . on the method of bounded differences .",
    "_ in surveys in combinatorics",
    "_ , 1989 ( norwich , 1989 ) , pages 148 188 .",
    "cambridge univ . press ,",
    "cambridge .",
    "mcdiarmid , c. ( 1998 ) . concentration . in probabilistic methods for algorithmic discrete mathematics , pages 195 248 .",
    "springer , berlin .",
    "picard , r.r . and",
    "cook , r.d .. (1984 ) .",
    "cross - validation of regression models .",
    "_ journal of the american statistical association _ , 79:575583 .",
    "ripley , b. d. ( 1996 ) .",
    "pattern recognition and neural networks . _ cambridge university press _ , cambridge , new york .",
    "shao , j. ( 1993 ) .",
    "linear model selection by cross - validation .",
    "_ journal of the american statistical association _ , 88:486494 .",
    "stone , m. ( 1974 ) .",
    "cross - validatory choice and assessment of statistical predictions .",
    "_ journal of the royal statistical society b _ , 36 , 111?147 .",
    "stone , m. ( 1977).asymptotics for and against cross - validation .",
    "_ biometrika _ , 64 , 29?35 .",
    "vapnik , v. and chervonenkis , a. ( 1971 ) . on the uniform convergence of relative frequencies of events to their probabilities . _",
    "theory of probability and its applications _",
    ", 16 , 264?280 .",
    "van der vaart , a. w. and wellner , j. ( 19936 . weak convergence and empirical _ processes_. springer - verlag , new york .",
    "vapnik , v. n. and chervonenkis , a. y. ( 1971 ) . on the uniform convergence of relative frequencies of events to their probabilities . _",
    "theory of probability and its applications _ , 16(2):264280 .",
    "vapnik , v. ( 1982 ) .",
    "estimation of dependences based on empirical data .",
    "springer - verlag .",
    "vapnik , v. ( 1995 ) .",
    "the nature of statistical learning theory .",
    "springer .",
    "vapnik , v. ( 1998 ) . statistical learning theory .",
    "john wiley and sons inc .",
    ", new york . a wiley - interscience publication .",
    "yang , y. ( 2007 ) .",
    "consistency of cross validation for comparing regression procedures .",
    "_ accepted by annals of statistics_.    zhang , p. ( 1993 ) .",
    "model selection via multifold cross - validation .",
    "_ annals of statistics _ , 21:299313 .",
    "zhang , t. ( 2001 ) . a leave - one - out cross validation bound for kernel methods with applications in learning .",
    "_ 14th annual conference on computational learning theory _ - springer .",
    "we recall three very useful results . the first one , due to @xcite , bounds the difference between the empirical mean and the expected value .",
    "the second one , due to @xcite , bounds the supremum over the class of predictors of the difference between the training error and the generalization error . the last one is called the bounded differences inequality @xcite .      [ @xcite ]",
    "let @xmath81 a class of predictors with finite vc - dimension and @xmath99 a loss function bounded by @xmath66 .",
    "then for all @xmath158@xmath265 with @xmath193)@xmath266 and if @xmath267 @xmath268)@xmath269 and @xmath270              @xmath276 \\right| \\\\ & \\leq \\sup_{\\substack { x_{1},\\ldots , x_{i},\\ldots , x_{n }   \\\\ x_{i}^{^{\\prime } } } } \\mathbb{e}_{v_{n}^{tr}}\\left| \\sup_{\\phi \\in \\mathcal{c}}(\\widehat{r}_{v_{n}^{tr}}(\\phi ) -r(\\phi ) ) -\\sup_{\\phi \\in \\mathcal{c}}(\\widehat{r}_{v_{n}^{tr}}^{^{\\prime } } ( \\phi ) -r(\\phi ) ) \\right| \\\\ & \\text{by jensen 's inequality } \\\\ & \\leq \\sup_{\\substack { x_{1},\\ldots , x_{i},\\ldots , x_{n }   \\\\ x_{i}^{^{\\prime } } } } \\mathbb{e}_{v_{n}^{tr}}\\sup_{\\phi \\in \\mathcal{c}}|\\widehat{r}_{v_{n}^{tr}}(\\phi ) -\\widehat{r}_{v_{n}^{tr}}^{^{\\prime } } ( \\phi ) | \\\\ & \\text{since } |\\sup f-\\sup g|\\leq \\sup |f - g| \\\\ & \\leq \\frac{1}{n}.\\end{aligned}\\ ] ]"
  ],
  "abstract_text": [
    "<S> in this article , we derive concentration inequalities for the cross - validation estimate of the generalization error for empirical risk minimizers . in the general setting , we prove sanity - check bounds in the spirit of @xcite _ bounds showing that the worst - case error of this estimate is not much worse that of training error estimate _ . </S>",
    "<S> general loss functions and class of predictors with finite vc - dimension are considered . </S>",
    "<S> we closely follow the formalism introduced by @xcite to cover a large variety of cross - validation procedures including leave - one - out cross - validation , @xmath0-fold cross - validation , hold - out cross - validation ( or split sample ) , and the leave-@xmath1-out cross - validation .    </S>",
    "<S> in particular , we focus on proving the consistency of the various cross - validation procedures . </S>",
    "<S> we point out the interest of each cross - validation procedure in terms of rate of convergence . </S>",
    "<S> an estimation curve with transition phases depending on the cross - validation procedure and not only on the percentage of observations in the test sample gives a simple rule on how to choose the cross - validation . </S>",
    "<S> an interesting consequence is that the size of the test sample is not required to grow to infinity for the consistency of the cross - validation procedure .    </S>",
    "<S> keywords : cross - validation , generalization error , concentration inequality , optimal splitting , resampling . </S>"
  ]
}