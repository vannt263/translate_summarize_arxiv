{
  "article_text": [
    "there exists an ever - growing trend in high ( or `` big '' ) dimensional data processing to design new procedures ( or to simplify existing ones ) using linear dimensionality reduction ( ldr ) methods in order to get faster or memory - efficient algorithms .",
    "provided this reduction does not bring too much distortion between the initial data space and the `` reduced '' domain , as often allowed by the intrinsic `` low - dimensionality '' properties of the input data , many techniques , such as nearest - neighbor search in big databases @xcite , classification @xcite , regression @xcite , filtering @xcite , manifold processing @xcite or compressed sensing @xcite can be developed in this reduced domain with controlled loss of accuracy , as well as stability with respect to data corruption ( _ e.g. _ , noise ) .",
    "most often , those ldr tools rely on defining a random projection matrix ( sometimes called _ sensing _ matrix ) with fewer rows @xmath7 than columns @xmath13 , whose multiplication with data represented as a set of vectors in @xmath14 provides a reduced representation ( or _ sketch _ ) of the latter .",
    "this is the scheme implicitly promoted for instance by the celebrated johnson - lindenstrauss ( jl ) lemma for finite sets of vectors @xmath15 , _",
    "i.e. _ , with @xmath16 @xcite . this cornerstone result and its subsequent developments @xcite showed that , given a resolution @xmath17 , if @xmath18 where @xmath19 is the cardinality of @xmath20 and @xmath21 is a general constant , then a random matrix @xmath22 whose entries are independently and identically distributed ( ) as a centered sub - gaussian distribution with unit variance defines an isometric mapping that preserves pairwise - distances between points in @xmath20 up to a multiplicative distortion @xmath23 .",
    "in other words , @xmath24 defines an @xmath23__-isometry _ _ between @xmath25 and @xmath26 , _",
    "i.e. _ , with high probability , for all @xmath27 , @xmath28 equivalently , one observes that keeping the probability of success constant with respect to the random generation of @xmath24 and inverting the requirement linking @xmath7 and @xmath23 , such an isometry has a distortion @xmath23 decaying as @xmath29 when @xmath7 increases , _",
    "i.e. _ , this distortion vanishes when @xmath30 is large .",
    "notice that variants of this embedding result exist with different `` input / output '' norms ; see , _",
    "e.g. _ , @xcite for a unified treatment over a family of _ interpolation _ norms including @xmath6 and @xmath5 as special cases .",
    "the jl lemma has been later generalized to any subsets @xmath31 , not only finite , whose typical `` dimension '' can be considered as small with respect to @xmath13 ( see , _",
    "e.g. _ , @xcite ) .",
    "in other words , as soon as @xmath32 displays some internal structure that makes it somehow parametrisable with much fewer parameters than @xmath13 , as for the set of sparse or compressible signals , the set of low - rank matrices , signal manifolds , or a set given as a union of low - dimensional subspaces , an @xmath23-isometry like   can be defined for all pairs of vectors in @xmath32 .",
    "this is for instance the essence of the restricted isometry property ( rip ) and its link with the jl lemma , where holds with high probability for all @xmath33-sparse vectors provided @xmath34 @xcite .",
    "however , these embeddings have one strong limitation . except in very specific situations , such as for discrete sub - gaussian random matrices @xmath24 ( _ e.g. _ , bernoulli ) and finite sets @xmath32 ,",
    "the set @xmath35 is not finite .",
    "an infinite number of bits is thus required if one needs to store , process or transmit @xmath36 without information loss for any possible @xmath37 . moreover , knowing how many bits are required to represent such projections is also important theoretically for assessing and measuring the level of information contained in the reduced data space or for improving specific data retrieval and processing algorithms .",
    "additionally , if this measure of information can be achieved , nothing prevents us to take @xmath38 , as the sought `` dimensionality reduction '' can be aimed at minimizing the number of bits rather than the dimensionality @xmath7 .",
    "for instance , @xcite defines locality - sensitive hashing ( lsh ) as a procedure to turn data vectors into quantized _ hashes _ that preserve locality , so that close vectors induce , with high probability , close hashes .",
    "however , this method is specifically designed for boosting nearest - neighbor searches over a finite set of vectors and not to define an isometry similar to  .    as a more practical solution ,",
    "the embedding realized by a random projection @xmath24 is often followed by a scalar quantization procedure , _",
    "e.g. _ , with a uniform scalar quantizer @xmath39 with resolution @xmath40 , applied componentwise on the image of @xmath24 .",
    "a direct impact of this sequence of operations is to induce a new additive distortion in   related to @xmath41 , as discussed in @xcite . indeed , assuming @xmath24 respects   for all @xmath42 and @xmath43 in a certain subset @xmath31 , given a uniform quantizer  @xmath44 of resolution @xmath40 applied componentwise on vectors of @xmath45 we would have @xmath46 for all @xmath47 , which involves @xmath48 for any @xmath49 .",
    "therefore , a simple manipulation of provides @xmath50 in other words , as described in sec .",
    "[ sec : framework ] , the quantized mapping @xmath51 defines now a _",
    "quasi - isometric _ embedding between @xmath52 and @xmath53 .    however , while displays a constant additive distortion , several works in this context have observed that such an additive error actually decays as @xmath7 increases .",
    "first , when distances in the reduced space are measured with the @xmath5-norm and when @xmath54 is combined with a _",
    "_ dithering _ _ and  eq .  ) . ] , a quasi - isometry similar to holds with high probability for all vectors in a _",
    "set @xmath55 @xcite .",
    "the additive distortion reads then @xmath56 for some absolute constant @xmath57 and this error also decays as @xmath58 , as does the multiplicative error @xmath23 .",
    "second , when combined with universal quantization @xcite , _",
    "i.e. _ , with a periodic scalar quantizer @xmath54 , an exponential decay of this distortion as @xmath7 grows can be reached ; for the moment , this has been proved only for sparse signal sets .",
    "finally , recent works related to 1-bit compressed sensing ( cs ) have shown that for a quantization @xmath54 reduced to a sign operator ( _ i.e. _ , @xmath59 ) the angular distance between any pair of vectors of a low - dimensionality set @xmath32 is close to the hamming distance of their mappings up to an additive error decaying as @xmath60 for some @xmath61 .",
    "this is true for random gaussian matrices and for the set of sparse signals @xcite , for any sets with `` low dimensionality '' as measured by their gaussian mean width @xcite ( see below ) and even for sub - gaussian random matrices provided the projected vectors are not `` too sparse '' @xcite , _ i.e. _ , for vectors whose @xmath62-norm is much smaller than their @xmath6-norm .",
    "* contributions : * considering these last observations , the main results of this paper show that : +    * quasi - isometric embeddings can be obtained with high probability from scalar ( dithered ) quantization after linear random projection ; for such embeddings both multiplicative and additive distortions co - exist when , as in @xcite , distances between mapped vectors are measured with the @xmath5-norm - distance . ] ; * random sensing matrices for such embeddings are allowed to be generated from symmetric sub - gaussian distributions provided embedded vector differences are not `` too sparse '' ( as in the 1-bit case  @xcite ) ; * the results above actually hold with high probability for _ any _ subset @xmath32 of @xmath14 as soon as @xmath7 is large compared to its typical dimension , _",
    "i.e. _ , to its squared gaussian mean width . * with high probability , the biggest distance separating two _ consistent _ vectors in @xmath32 ( _ i.e. _ , characterized by identical quantized mappings ) , that is what we call the _ consistency width _ , decays when @xmath7 increases at a faster rate than what could be predicted by using just the implications of a quasi - isometry .",
    "this extends to any set @xmath32 the works of @xcite , that were valid only for sparse signals ; * for particular _ structured _ sets , _",
    "e.g. _ , the set of ( bounded ) sparse vectors or the set of ( bounded ) low - rank matrices , the minimal values of @xmath7 necessary to specify a quantized embedding or a small consistency width can be strongly reduced compared to those required for a general set ;    moreover , we aim at optimizing whenever it is possible the requirements on @xmath7 ( _ e.g. _ , with respect to @xmath23 and @xmath41 ) that guarantee those results .",
    "* methodology : * as an important aspect of our developments , we study the conditions for obtaining quasi - isometric embeddings of any bounded subsets @xmath31 into @xmath63 . following key procedures established in other works @xcite , the typical dimension of these sets",
    "is measured by the _",
    "gaussian mean width _ , _",
    "i.e. _ , @xmath64 with @xmath65 .",
    "this quantity , also known as gaussian complexity , has been recognized as central for instance in characterizing random processes @xcite , shrinkage estimators in signal denoising and high - dimensional statistics @xcite , linear inverse problem solving with convex optimization @xcite or classification efficiency for randomly projected signal sets @xcite .",
    "more specifically , the minimal number of measurements @xmath7 necessary to induce , with high probability , an @xmath66-isometric embedding of any subset @xmath67 into @xmath45 from sub - gaussian random projections is known to be proportional to @xmath68 @xcite . therefore , since @xmath69 for some finite set @xmath32 , we recover the condition defining the johnson - lindenstrauss lemma by imposing latexmath:[$m \\gtrsim",
    "\\log    @xmath33-sparse vectors in an orthonormal basis ( onb ) @xmath71 , @xmath72 , which characterizes the conditions of the restricted isometry property ( rip ) for sub - gaussian random matrices @xcite . the interested reader can find a summary of the main properties of the gaussian mean width in table  [ tab : gaussian - mean - width - prop ] , with explicit references to their origin .",
    "this table could be helpful also to keep trace of these properties while reading our proofs .    in our developments ,",
    "we sometimes complete the characterization of sets provided by the gaussian mean width with another important measure : the kolmogorov @xmath23-entropy of a set @xmath31 that we denote @xmath73 @xcite .",
    "this is defined as the logarithm of the size of the smallest @xmath23-net of @xmath32 , _",
    "i.e. _ , a set @xmath74 such that any vector of @xmath32 can not be farther than @xmath23 from its closest vector in @xmath75 . by the sudakov inequality",
    ", this entropy is connected to the gaussian mean width as @xmath76 .",
    "however , in specific cases this last inequality is too loose with respect to @xmath23 .",
    "as summarized in @xcite , this is the case of the _ structured sets _",
    "@xmath32 defined hereafter , for which this work will provide separated and tighter results .",
    "[ def : structured - set ] a bounded set @xmath31 with diameter @xmath77 is _ structured _ iff there exists a quantity @xmath78 , independent of @xmath79 , for which we have both    [ eq : structured - set - prop ] @xmath80    for any @xmath81 , where @xmath82 is the _ local set _ of @xmath32 of radius @xmath83 .",
    "for instance , if @xmath84 is a subspace of @xmath14 , a union of subspaces ( such as the set @xmath85 of @xmath33-sparse signals in an orthonormal basis or in a redundant dictionary @xmath86 of @xmath14 ) , the set of rank-@xmath87 matrices @xmath88 in @xmath89 , or even the set of group - sparse signals , then @xmath84 is a _ cone _ , _",
    "i.e. _ , @xmath90 for any @xmath91 , and the set @xmath92 is structured for any diameter @xmath93 @xcite .    indeed ,",
    "focusing first on , if @xmath84 is one of the sets listed above , @xmath94 is also a cone and @xmath95",
    ". therefore @xmath96 . this last quantity is easily bounded since @xmath97 often shares the same structure than @xmath84 , _",
    "e.g. _ , @xmath98 if @xmath99 , and in fact @xmath100 showing that @xmath78 can be set to @xmath101 in  .",
    "second , for , the komogorov entropy of such a set @xmath84 can often be tightly bounded by decomposing it into a union of subspaces or subdomains restricted to @xmath102 , so that a global @xmath23-net of small cardinality could be reached by the union of the @xmath23-nets of all of these subparts  @xcite , _ i.e. _ , justifying the bound @xmath103 . actually , concerning",
    ", it occurs that for all the structured sets listed above we have that either @xmath104 or both @xmath105 and @xmath106 have the same simplified closed - form upper bound , _",
    "e.g. _ , they are both upper bounded by @xmath107 when  @xmath99 .",
    "thus , due to the observations made above , we will consider that @xmath108 can be bounded similarly to the actual gaussian mean width @xmath109 of the normalized set @xmath110 , _ i.e. _ , with the same simplified upper bound .",
    "an example of this fact for the set of bounded @xmath33-sparse vectors is provided at the end of sec .",
    "[ sec : proofs ] .",
    ".useful properties of the gaussian mean width .",
    "if not otherwise noted , all sets are subsets of  @xmath14 .",
    "@xmath111 : ( p[p : w - dialk ] ) is obtained by a simple use of the jensen and cauchy - schwartz inequalities , ( p[p : w - trans ] ) is a simple consequence of the triangular inequality and of @xmath112 .",
    "[ cols= \" < , < , < \" , ]     * paper organization : * the rest of the paper is structured as follows . in sec .  [",
    "sec : framework ] , we define the construction of our quantized sub - gaussian random mapping . additionally , this section characterizes the sub - gaussianity of its linear ingredient , _",
    "i.e. _ , its random projection matrix , and its interplay with the `` anti - sparse '' nature of the mapped vectors . we also formalize and motivate the main objectives of the paper , _",
    "e.g. _ , explaining the shape and the origins of the targeted quasi - isometric embedding with its two specific distortions .",
    "[ sec : main - results ] provides the main results of this work , namely , _",
    "( i ) _ the possibility to create with high probability a quasi - isometric sub - gaussian embedding from our quantized mapping ( prop .",
    "[ prop : main - result ] ) , and _",
    "( ii ) _ a study of this mapping s _ consistency width _ behavior ( prop .",
    "[ prop : consistency - width ] ) .",
    "[ sec : discussions ] discusses those two propositions , analyzing them in a few specific settings in comparison with related works in the fields of dimensionality reduction and 1-bit compressed sensing .",
    "[ sec : nec - dither ] questions the necessity of dithering in the mapping @xmath113 and shows that , from an appropriate counterexample , our results do not hold in full generality without such a dither .",
    "finally , sec .",
    "[ sec : proofs ] and sec .",
    "[ sec : proof - consistency - width ] contain the proofs of prop .",
    "[ prop : main - result ] and prop .",
    "[ prop : consistency - width ] , respectively , the auxiliary lemmas being demonstrated in appendix .    [ [ conventions ] ] conventions : + + + + + + + + + + + +    we find useful to summarize here our mathematical notations .",
    "domain dimensions are denoted by capital roman letters , _",
    "e.g. _ , @xmath114 vectors and matrices are associated to bold symbols , _",
    "e.g. _ , @xmath22 or @xmath49 , while lowercase light letters are associated to scalar values .",
    "the identity matrix in @xmath115 reads @xmath116 while @xmath117\\in\\{0,1\\}$ ] is the indicator function of a set @xmath118 .",
    "an `` event '' is a set whose definition depends on the realization of some random variables , _",
    "e.g. _ , if @xmath119 is a random variable , the event @xmath120 has probability @xmath121 $ ] .",
    "the @xmath122 component of a vector ( or of a vector function ) @xmath123 reads either @xmath124 or @xmath125 , and the vector @xmath126 may refer to the @xmath127 element of a set of vectors .",
    "the set of indices in @xmath128 is @xmath129=\\{1,\\,\\cdots , d\\}$ ] .",
    "the cardinality of a finite set @xmath130 reads @xmath131 . for any @xmath132 , the @xmath133-norm of @xmath123 is @xmath134 with @xmath135 .",
    "the `` @xmath136-norm '' of a vector @xmath137 is @xmath138 , with @xmath139 the support of @xmath123 .",
    "the @xmath140-sphere in @xmath141 is @xmath142 while the unit ball is denoted @xmath143 .",
    "the diameter of a bounded set @xmath144 is written @xmath145 .",
    "the set of @xmath33-sparse signals in @xmath14 is defined as @xmath146 while the set of @xmath33-sparse signals in an orthonormal basis ( onb ) @xmath147 , _ i.e. _ , with @xmath148 , reads @xmath149 .",
    "the positive thresholding function is defined by @xmath150 for any  @xmath151 . for @xmath152 , @xmath153 ( resp .",
    "@xmath154 ) is the largest ( smallest ) integer smaller ( greater ) than @xmath155 .",
    "a random matrix @xmath156 is a @xmath157 matrix with entries distributed as @xmath158 given the distribution parameters @xmath159 of @xmath160 ( _ e.g. _ , @xmath161 or @xmath162)$ ] ) .",
    "a random vector in @xmath163 following @xmath164 is defined by @xmath165 . given two random variables @xmath166 and @xmath167 , the notation @xmath168 means that @xmath166 and @xmath167 have the same distribution .",
    "since our developments do not focus on sharp bounds , we denote by @xmath169 or @xmath170 ( possibly large ) constants whose value can change between lines . in a few places , for simplicity , we write @xmath171 if there exists a constant @xmath57 such that @xmath172 , and correspondingly for @xmath173 .",
    "moreover , @xmath174 means that @xmath171 and @xmath175 .",
    "finally , for asymptotic relations , we use the common landau family of notations , _",
    "i.e. _ , the symbols @xmath176 , @xmath177 and @xmath159  @xcite .",
    "in this work , given a quantization resolution @xmath2 , we focus on the interaction between a random projection of @xmath14 into @xmath45 and the following uniform ( dithered ) quantizer , for some @xmath178 and @xmath179 , _",
    "e.g. _ , for the quantizer mentioned in the introduction with @xmath180 and @xmath181 . ]",
    "@xmath182 , applied componentwise on vectors in @xmath45 .",
    "in other words , for some random matrix @xmath183 whose distribution is specified below , we study the properties of the mapping @xmath184 with @xmath185 where @xmath186)$ ] is a uniform _ dithering _ that stabilizes the action of @xmath54 @xcite .",
    "we specialize the mapping on projection ( or sensing ) matrices @xmath24 with entries independently and identically drawn from a symmetric _ sub - gaussian _ distribution .",
    "we recall that a random variable ( ) @xmath166 is sub - gaussian if its _ sub - gaussian norm _ ( or @xmath187-norm ) @xcite @xmath188 is finite . examples of sub - gaussian s are gaussian , bernoulli , uniform or bounded s , as @xmath189 sub - gaussian s are endowed with several interesting properties described , _",
    "e.g. _ , in @xcite .",
    "their tail is for instance bounded as the one of a gaussian , _",
    "i.e. _ , there exists a @xmath57 such that for all @xmath190 and for a sub - gaussian @xmath166 , @xmath191 moreover , since @xmath192 , centering @xmath166 has no effect on its sub - gaussianity .    by a slight abuse of notation ,",
    "we denote collectively the distributions of _ symmetric _ sub - gaussian with zero expectation , unit variance and finite sub - gaussian norm @xmath193 by @xmath194 , with @xmath195 from .",
    "this means that if @xmath196 , we do not fully specify the pdf of @xmath166 but we know that @xmath166 is centered , has unit variance and sub - gaussian norm @xmath193 .    in this context , for a sub - gaussian random matrix @xmath197 , each row @xmath198 is also _ isotropic _ , _ i.e. _ , for all @xmath199 $ ] and all @xmath137 , @xmath200 however , conversely to the gaussian case where @xmath201 for @xmath202 and @xmath203 ( since @xmath204 ) , we do not necessarily have @xmath205 for @xmath206 and some absolute constant @xmath57 .    as will be clear below",
    ", we must anyway determine the deviations to this last equality .",
    "interestingly , as noted in  @xcite , any sub - gaussian random vector @xmath207 satisfies @xmath208 for some constant @xmath209 depending only the distribution of @xmath210 . while we have obviously @xmath211 if @xmath212 , it is possible to bound this constant in full generality .",
    "indeed , up to a simple change of variable @xmath213 in the integral , is sustained by the berry - esseen central limit theorem ( as described in a simplified form in ( * ? ? ?",
    "* theorem 4.2 ) ) .",
    "this result shows basically that , for @xmath214 , the lhs of is bounded by @xmath215 for @xmath216 .",
    "this means that @xmath217 for any @xmath210 .",
    "notice , however , that this bound can be loose for many sub - gaussian distributions .",
    "thanks to assumption , we can establish the behavior of the _ first absolute moment _",
    "function @xmath218 since @xmath219 for any @xmath166 and using jensen s inequality , we indeed observe  that @xmath220 @xmath221 for all @xmath137 . the last property , which is also considered in 1-bit cs with non - gaussian projections @xcite , is key for characterizing quantized embeddings from sub - gaussian projections .",
    "having now fully described the elements composing our random quantized mapping @xmath222 , we formally address the objectives defined in the introduction by observing `` when '' , _",
    "i.e. _ , under which conditions with respect to @xmath7 , there exist two small distortions @xmath223 such that the pseudo - distance @xmath224 is involved in the quasi - isometric relation @xmath225 for all pair of vectors taken in a general subset @xmath31 .    in particular , we aim to control the distortions @xmath226 and @xmath227 with respect to @xmath7 , @xmath13 , the non - gaussian nature of @xmath24 ( _ i.e. _ , through @xmath193 and @xmath228 ) , the typical dimension of @xmath32 ( _ i.e. _ , its gaussian mean width ) and possible additional requirements on @xmath42 and @xmath43 .",
    "let us justify and comment the specific form taken by .",
    "first , @xmath229 is associated to a @xmath5-distance in the image of @xmath113 . as detailed in sec .",
    "[ sec : proofs ] , this choice establishes an equivalence between the evaluation of @xmath229 and a specific counting procedure , _",
    "i.e. _ , a count of the number of quantization _ thresholds _ separating each components of the randomly - projected vectors .",
    "however , it is not clear if our developments can be extended to a @xmath6-based pseudo - distance , even if this holds , with additional distortion , in the case of gaussian random projections and for finite sets @xmath32 @xcite ( see sec .  [",
    "sec : discussions ] ) .",
    "second , as explained in the introduction , a special case where both non - zero @xmath226 and @xmath227 appear specifies the constant @xmath230 in .",
    "when @xmath231 , @xcite has proved a quantized version of the johnson lindenstrauss ( jl ) lemma showing that for a finite set @xmath232 of size @xmath233 , provided @xmath234 , one has @xmath235 for all pairs @xmath27 with a probability at least @xmath236 . as a direct impact of the loss of information induced by the quantization",
    ", we also observe here that @xmath113 realizes a _ quasi - isometric _ mapping between @xmath237 and @xmath238 with @xmath239 and @xmath240 .    finally , as will be clearly established in sec .",
    "[ sec : quasi - isometric - embed ] , the anti - sparse nature of @xmath241 must be involved in the characterization of the right - hand side of   in the case of a general sub - gaussian matrix @xmath24 .",
    "indeed , let us consider a matrix with i.i.d .",
    "bernoulli distributed random entries , _ i.e. _ , @xmath242 with @xmath243 for all @xmath244 and @xmath245 , the vectors @xmath246 and @xmath247 and assume @xmath248 , _",
    "e.g. _ , with @xmath249 and @xmath250 .",
    "then , taking @xmath251 , we clearly have @xmath252 and @xmath253 , so that @xmath254 and @xmath255",
    ". consequently , if is expected to hold on any pair of vectors in @xmath32 , inserting @xmath42 and @xmath43 inside it gives @xmath256 . this limits our hope to have @xmath257 as small as we want by , _",
    "e.g. _ , increasing @xmath7 .",
    "in fact , between the two distortions , it is actually @xmath227 that should depend on the configuration of @xmath258 . as proved in app .",
    "[ sec : absol - expect - dith ] , @xmath259).\\ ] ] therefore , by definition of @xmath54 , from the independence of each component of @xmath222 and using the law of total expectation over @xmath260 and @xmath24 we have @xmath261 with @xmath210 and @xmath262)$ ] . from the assumption ( [ eq : one - moment - sg - antisparse ] ) and given @xmath263 , we then observe that @xmath264 for all vectors @xmath42 and @xmath43 such that @xmath241 belongs to the set @xmath265 this last set amounts to considering vectors that are not `` too sparse '' , _",
    "i.e. _ , if @xmath266 then @xmath267 , which determines our notation @xmath268 as opposed to @xmath269",
    ". however , the converse is not true and @xmath270 .",
    "since belonging to @xmath268 prevents sparsity , we say that a vector @xmath271 is an _ anti - sparse _ vector of level @xmath272 .",
    "actually states that , for vectors",
    "@xmath273 , the expectation of @xmath274 is close to the one obtained with gaussian random projections , _",
    "i.e. _ , close to the expectation @xmath275 associated to @xmath211 .",
    "thus , if we expect to show that , for all vectors @xmath42 and @xmath43 in @xmath32 , @xmath274 concentrates around @xmath275 , we must take into account the anti - sparse nature of the difference @xmath241 , _",
    "i.e. _ , we would need enforcing this vector to belong to @xmath268 for a sufficiently large  @xmath276 .    combining these three observations , and anticipating over the next section",
    ", we can now refine the meaning of  .",
    "we are actually going to show that , if @xmath7 is bigger than some @xmath277 growing with the typical dimension of @xmath32 and decreasing with @xmath23 ( see sec .  [",
    "sec : main - results ] ) , then , with high probability , @xmath278 for all @xmath248 and @xmath279 .    _ remark : _ as will be cleared later , our developments benefit of the tools and techniques developed in @xcite where it is shown that , for a 1-bit mapping @xmath280 such that @xmath281 with a random gaussian matrix @xmath282 , and for the normalized hamming distance @xmath283 $ ] , one has , provided @xmath284 and with probability exceeding @xmath236 , that for all @xmath285 , @xmath286 our extension to non - gaussian sensing matrices is also inspired by similar developments realized in @xcite for binary mappings and other generalized linear models .",
    "in regards to the context explained in the previous section , our first main result can be stated as follows .",
    "[ prop : main - result ] given @xmath2 , @xmath287 , @xmath288 , a bounded subset @xmath31 and a sub - gaussian distribution @xmath289 respecting for @xmath290 , there exist some values @xmath291 , only depending on @xmath193 , such that , if @xmath292 for a general set @xmath32 , or @xmath293 for structured sets @xmath32 ( see def .",
    "[ def : structured - set ] for the definition of @xmath294 ) , such as the set of bounded @xmath33-sparse signals or the one of bounded rank-@xmath87 matrices , then , for @xmath295 , a dithering @xmath296)$ ] and the associated quantized mapping @xmath297 , we have with probability at least @xmath298 and for all pairs @xmath285 with @xmath279 , @xmath299 in the gaussian case , _",
    "i.e. _ , for @xmath231 , the conditions remain the same and is simplified with @xmath300 , _",
    "i.e. _ , there is no additional requirement on the anti - sparse nature of @xmath241 in   since @xmath276 can be set to 1 and @xmath301 .    in prop .",
    "[ prop : main - result ] , as shown in sec .",
    "[ sec : framework ] , the constant part @xmath302 of the multiplicative distortion appearing in both sides of is unavoidable in the case of non - gaussian projections ( with @xmath303 ) .",
    "actually , we can show that this distortion can not decay faster than @xmath304 for non - gaussian ( but sub - gaussian ) random matrices when the level of anti - sparsity @xmath276 of @xmath305 increases . to see this ,",
    "it is sufficient to study @xmath274 for an asymptotically large @xmath7 , _ i.e. _ , @xmath306 by the law of large numbers , and to observe how the relative error between @xmath306 and @xmath307 behaves when that level @xmath276 increases .",
    "taking @xmath251 by simplicity , notice first that , from the observation made in , @xmath308 where @xmath309 and @xmath310 was introduced in .",
    "let us then take @xmath42 and @xmath43 such that the vector @xmath311 is equal to 1 on its first @xmath276 components and zero elsewhere , _",
    "i.e. _ , @xmath312 . in this case and",
    "if @xmath24 is a random bernoulli matrix , @xmath313 is actually twice the _ mean absolute deviation _",
    "( mad ) of a binomial distribution @xmath314 with @xmath276 degrees of freedom and success probability @xmath315 since @xmath316 and @xmath317 a bernoulli random variable such that @xmath318 , and @xmath319 .",
    "however , from @xcite we can show that ( see app .",
    "[ app : bin - bound ] for details ) @xmath320 for @xmath321 .",
    "consequently , for our choice of @xmath322 such that @xmath323 , this shows that @xmath324 and proves that , even if we reached an asymptotic regime in @xmath7 , a multiplicative distortion between @xmath274 and @xmath325 would remain , and this one could decay faster than @xmath326 when @xmath276 increases .",
    "it is therefore unclear if our decay in @xmath327 is optimal .    to conclude this section ,",
    "let us observe that prop .",
    "[ prop : main - result ] improves a proof of existence of a quantized embedding given in ( * ? ? ?",
    "* theorem 1.10 ) where it was showed that , provided @xmath328 , there exists an arrangement of @xmath7 affine hyperplanes in @xmath14 and a scaling factor @xmath329 such that @xmath330 where @xmath331 denotes the fraction of affine hyperplanes that separate the two vectors @xmath42 and @xmath43 .    for reasons explained in sec .",
    "[ sec : proofs ] , each element @xmath332 appearing in @xmath333 actually counts the number of parallel affine hyperplanes in @xmath14 normal to @xmath198 and far apart by @xmath41 , with a dithering that randomly displaces the origin .",
    "therefore , prop .",
    "[ prop : main - result ] basically constructs , in a random fashion , an arrangement of @xmath7 such parallel hyperplane bundle , _",
    "i.e. _ , in @xmath7 different directions @xmath334\\}$ ] . considering a gaussian matrix @xmath24 ( with @xmath300 ) , we have therefore proved that there with a minimal @xmath7 that grows like @xmath335 rather than @xmath336 when @xmath23 decays ( as expressed in ) .",
    "this is even reduced to @xmath337 for pairs of vectors taken in a structured set .      as a second important result",
    ", we optimize the decay law ( as @xmath7 increases ) of the distance of any pair of vectors @xmath248 whose difference is `` not too sparse '' when those are mapped by @xmath222 on the same quantization point in @xmath338 , _",
    "i.e. _ , when they are _",
    "we refer to this distance as the _ consistency width _ of @xmath222 .",
    "this width could be characterized from prop .",
    "[ prop : main - result ] when @xmath339 , which provides @xmath340 ( or @xmath10 if @xmath32 is a structured set ) for large @xmath7 respecting   ( resp . ) , @xmath41 fixed and @xmath341 small .",
    "however , focusing on the conditions guaranteeing the consistency of @xmath42 and @xmath43 , and considering all quantities fixed but @xmath7 , our result below reaches the improved decay @xmath342 for a general set @xmath32 and @xmath343 for a structured one .",
    "we prove the following proposition in sec .",
    "[ sec : proof - consistency - width ] .",
    "[ prop : consistency - width ] let us take a quantization resolution @xmath344 , an accuracy @xmath287 , a sub - gaussian distribution @xmath194 respecting for @xmath290 , @xmath345 such that @xmath346 and a bounded subset @xmath347 of @xmath14",
    ". for a value @xmath57 depending only on @xmath193 , provided @xmath348 for a general set @xmath32 , or @xmath349 for a structured set @xmath32 , the map @xmath113 defined in with @xmath295 and @xmath350)$ ] is such that , with probability exceeding @xmath351 , @xmath352 for all @xmath353 with @xmath354 . in the gaussian case , _",
    "i.e. _ , for @xmath231 , the conditions above remain the same with @xmath300 , _",
    "i.e. _ , with no additional requirement on the anti - sparse nature of @xmath241 in  .    unfortunately , we were unable to produce a convincing counter example of a pair of vectors both with difference not in @xmath268 and failing to meet under the conditions of prop .",
    "[ prop : consistency - width ] .",
    "therefore , it is not clear if the condition @xmath273 is an artifact of the proof or if removing it could worsen then dependence in @xmath23 in .",
    "before delving into the proofs of prop .  [",
    "prop : main - result ] and prop .  [ prop : consistency - width ] ( see sec .  [",
    "sec : proofs ] and sec .",
    "[ sec : proof - consistency - width ] , respectively ) , let us discuss their meaning and limitations , providing also some perspectives for future works .    * on the impact of the diameter of structured sets : * for the structured sets considered in the introduction , it is known that if the linear embedding holds with high probability for all @xmath355 with some distortion @xmath17 , then , since is homogeneous , a simple rescaling argument proves that the same relation actually holds for all points in @xmath356 , or equivalently for all points in the cone @xmath84 if @xmath357  @xcite .",
    "in particular , since such a linear embedding occurs with high probability for sub - gaussian random matrices provided @xmath358 @xcite , this requirement remains unchanged for reaching the embedding of vectors in @xmath84 .",
    "obviously , in the case of a quantized embedding such as , the non - linear nature of @xmath54 prevents this rescaling argument from holding .",
    "however , an interesting phenomenon occurs anyway in this case through the requirements and of prop .",
    "[ prop : main - result ] and prop .",
    "[ prop : consistency - width ] , respectively .",
    "indeed , we see there that the diameter of the set @xmath32 has only a logarithmic impact on the minimal value of @xmath7 needed for these propositions to hold , since @xmath294 does not depend on the diameter of @xmath32 ( see def .",
    "[ def : structured - set ] and the subsequent explanations ) .",
    "this really slow increase approaches the scale - invariant requirement obtained by linear embedding of structured sets , and is anyway strikingly slower than the quadratic amplification of the minimal number of measurements provided by and in the case of a general set @xmath32 , as involved by ( p[p : w - hom ] ) when @xmath32 is expanded like @xmath359 for @xmath360 .",
    "* mitigating the anti - sparsity requirement : * for both propositions , we can be concerned by the restriction that the vector difference must be `` not too sparse '' , _",
    "i.e. _ , for @xmath353 there must be a sufficiently big @xmath276 , either for having @xmath361 and minimizing the distortion @xmath362 in , or for satisfying @xmath346 in prop .",
    "[ prop : consistency - width ] .",
    "however , in certain cases , it is possible to adapt the sensing matrix as to increase this @xmath276 .    indeed , assuming without loss of generality that the vectors @xmath363 are expected to be `` too sparse '' only in @xmath364 when the sensing matrix is non - gaussian ( _ i.e. _ , @xmath303 ) , we can always `` rotate '' , @xmath365 is a rotation only if its determinant is @xmath366 . ]",
    "@xmath32 with an onb @xmath367 of @xmath14 so that elements of @xmath368 with @xmath369 have a higher anti - sparse degree than those of @xmath370 , _",
    "i.e. _ , @xmath371 possibly trying to maximize the left hand side in the selection of @xmath367 .    therefore , while the requirements imposed on @xmath7 in prop .",
    "[ prop : main - result ] and prop .",
    "[ prop : consistency - width ] are unchanged between @xmath32 and @xmath84 in prop .",
    "[ prop : main - result ] ( by the invariance ( p[p : w - invort ] ) of @xmath372 in table  [ tab : gaussian - mean - width - prop ] ) and since @xmath373 for @xmath374 and @xmath375 , `` rotating '' @xmath32 with @xmath367 helps to lighten the condition imposed on @xmath258 .",
    "moreover , this rotation is of course equivalent to directly build a sensing matrix @xmath376 to quasi - isometrically embed the set @xmath32 with the mapping @xmath377 . actually , in the case where @xmath378 as above , a good choice for @xmath367 is the dct basis , _",
    "i.e. _ , using the incoherence of those two bases that prevents a sparse signal to be sparse in the frequency domain , also taking advantage of the fast fft - based matrix - vector multiplication offered by the dct . notice , however , that the procedure above can not work if @xmath32 is expected to generate differences of vectors that are sparse in different bases , _",
    "e.g. _ , a union of incoherent bases such as @xmath379 and the dct basis .",
    "in such a case , it could be hard to maximize the right - hand side of   over @xmath367 .",
    "interestingly , a similar procedure to the one described above has been developed recently in ( * ? ? ?",
    "* theorem 2.3 ) in the context of fast circulant binary embeddings of finite sets of vectors .",
    "the requirement on the anti - sparse nature of the mapped vectors is there mitigated by taking @xmath367 as the product of a hadamard transform with a diagonal matrix with random rademacher entries , which can provably reduce the _ coherence _",
    "@xmath380 of too sparse @xmath123 with high probability .",
    "* intrinsic `` anti - sparse '' distortion limit : * we can notice that for non - gaussian random measurements , the term @xmath381 in is actually lower bounded .",
    "this is simply due to the relation @xmath382 , which implies @xmath383 whatever the properties of the vector @xmath384 .",
    "consequently , @xmath385 which limits our hope to tighten the multiplicative error of quantized non - gaussian quasi - isometric embeddings , except if one considers asymptotic regimes where @xmath13 can be considered as being much larger than @xmath386 .",
    "* distortion regimes : * as already noticed in @xcite , prop .",
    "[ prop : main - result ] allows us to distinguish different regimes of the quasi - isometric embedding .",
    "if @xmath387 , the quantization operator tends to the identity function and converges to a @xmath388 variant of the rip generalized to any sets @xmath32 and to sub - gaussian random matrices , as characterized in @xcite for general sets and in @xcite for sparse signal sets only . for @xmath389 the embedding becomes purely quasi - isometric and , keeping the context defined in prop .",
    "[ prop : main - result ] , involves @xmath390 for some absolute constant @xmath57 .",
    "however , in this case , the quantization becomes essentially binary .",
    "in fact , it is exactly binary for random matrices whose entries are generated from a bounded symmetric sub - gaussian distribution , _",
    "i.e. _ , from @xmath391 with @xmath392 for some @xmath393 . in this case , since @xmath32 is assumed bounded , for all @xmath394 , @xmath395 and the components of @xmath396 with @xmath397)$ ] can only take two values , _ e.g. _ , @xmath398 if @xmath399 . moreover , if @xmath400 is unbounded and @xmath399 , its sub - gaussian nature is so that the fraction of quantized measurements that do not belong to @xmath401 can be made arbitrarily close to 0 when @xmath41 increases . in conclusion , similarly to @xcite , we have basically defined a one - bit quantized embedding that preserves the norm of the projected vectors , as opposed to the mapping @xmath402 that loses this information @xcite .",
    "notice there that the role of our dithering can be compared to the one of the threshold inserted in the sign quantization in  @xcite .",
    "conversely to that work , however , we do not provide any algorithm to reconstruct a signal from its quantized mapping by @xmath222 .",
    "* towards an @xmath66 quasi - isometric embedding ?",
    "* it is not clear if prop .",
    "[ prop : main - result ] could be turned into a quasi - isometric embedding between @xmath52 and @xmath53 . as said earlier , for gaussian random matrices and for finite sets @xmath32",
    ", an approximate quasi - isometric embedding can be found by integrating a non - linear distortion of the @xmath6-distance , _ i.e. _ , in for @xmath300 , @xmath403 is replaced by @xmath404 for some non - decreasing function @xmath405 .",
    "interestingly , @xmath406 for @xmath407 and @xmath408 for @xmath409 , so that for small @xmath41 or large @xmath329 , @xmath410 . therefore , as soon as @xmath411 , we get approximately a @xmath66 quasi - isometric embedding .",
    "knowing if this extends to any subset @xmath32 and to sub - gaussian random matrices is left for a future work .    * reconstructing low - complexity vectors from quantized compressive observation ? * beyond the mere analysis of the quasi - isometric properties of our quantized mapping and closer to the context of quantized compressed sensing",
    ", this paper does not say anything on the reconstruction algorithms that could be developed for recovering a signal @xmath42 from its observations @xmath412 . a few algorithms exist for realizing this operation , some when @xmath41 is small compared to the expected dynamic of @xmath413 @xcite , others in the 1-bit cs setting @xcite .",
    "however , for the first category , their stability ( or convergence ) does not rely on a quasi - isometric embedding property but rather on the restricted isometry property @xcite or on variations involving other norms @xcite . in future research",
    ", it will be appealing to find a proof of the instance optimality of those algorithms , _",
    "e.g. _ , for the basis pursuit dequantizer ( bpdq ) , using the quasi - isometry property promoted by prop .",
    "[ prop : main - result ] , even if recent interesting results show that an optimal `` non - rip '' proof can be developed for bpdq @xcite .    *",
    "extension to fast and universal quantized embeddings ?",
    "* we conclude this section by mentioning that it would be useful to prove prop .  [",
    "prop : main - result ] for structured random matrices , _",
    "e.g. _ , for random fourier or random hadamard ensembles  @xcite , as recently obtained in @xcite for the binary embedding of finite sets .",
    "this would lead to a fast computation of quantized mappings , with potential application in nearest - neighbor search for databases of high - dimensional signals .",
    "an open question is also the possibility to extend this work to universally - quantized embeddings  @xcite , _ i.e. _ , taking a periodic quantizer  @xmath54 in .",
    "this could potentially lead to quasi - isometric embeddings with ( exponentially ) decaying distortions on vectors sets with small gaussian width and using sub - gaussian random matrices .",
    "considering the main results of this paper , namely prop .  [",
    "prop : main - result ] and prop .",
    "[ prop : consistency - width ] , we could ask ourselves if a quantized mapping that would not include a dithering could also verify and under equivalent conditions on @xmath7 and on the anti - sparse nature of @xmath241 for any vectors @xmath414 in  @xmath32 .",
    "the answer is , however , negative in full generality , _ i.e. _ , it is possible to define a quantized and undithered map @xmath415 for some appropriate quantizer resolution @xmath41 and sub - gaussian random matrix @xmath24 that is _ incompatible _ with the definition of a quasi - isometric embedding with arbitrarily small additive distortion or with an arbitrarily small consistency width .    to see this , let us set @xmath251 , @xmath416 ( applied componentwise defined in sec .",
    "[ sec : framework ] .",
    "we thus prefer to select @xmath54 as a rounding operation for the sake of clarity . ] ) , and take @xmath24 to be a bernoulli random matrix , _",
    "i.e. _ , @xmath417",
    ". given the value @xmath418 associated to the distribution of @xmath24 , we also set arbitrarily an integer @xmath276 such that @xmath419 .",
    "in fact , we can compute that @xmath420 for a bernoulli , so that @xmath421 from the bound given in sec .",
    "[ sec : framework ] .",
    "therefore , @xmath422 certainly works .",
    "we then define two @xmath276-sparse vectors @xmath423 with @xmath123 equal to 1 on it first @xmath276 components and 0 elsewhere , and @xmath424 for some fixed @xmath425 . clearly , when @xmath426 these two vectors belong to the structured set @xmath427 with @xmath428 .",
    "moreover , from our definition of @xmath276 , the difference vector @xmath429 is adjustably `` anti - sparse '' since it lies in @xmath268 with @xmath430 .",
    "interestingly , @xmath123 and @xmath431 are also consistent with respect to @xmath113 since @xmath432 .",
    "this is due to the nature of quantization ( _ i.e. _ , a rounding to the closest integer ) and to the fact that both @xmath433 and @xmath434 .",
    "let us now assume , as involved by prop .",
    "[ prop : main - result ] , that for @xmath435 , it is possible to find @xmath7 arbitrarily large before @xmath436 so that , with high probability and for all @xmath248 with @xmath279 , @xmath437 with the constant @xmath57 defined in .    however , by taking the consistent vectors @xmath438 and @xmath439 , this inequality leads by construction to @xmath440 in other words , since @xmath441 @xmath442 which is a clear contradiction .",
    "we can similarly show that the same pair of consistent vectors @xmath438 and @xmath443 is incompatible with prop .  [ prop : consistency - width ] as then the consistency width can not be arbitrarily small , even for asymptotically large @xmath7 .    _ remark : _ interestingly , the counter - example above is easily hijacked to show that it is impossible for the un - dithered quantized mapping @xmath444 to respect the following property for an arbitrarily small @xmath17 and provided @xmath7 is large enough , @xmath445 where @xmath446 are some universal constants , @xmath447 is any positive function vanishing on equal inputs ( _ e.g. _ , a norm , a pseudo - norm or any metric ) and @xmath448 is any monotonically decreasing function with @xmath449 .",
    "however , if @xmath54 is replaced by a sign operator as in @xcite , then the known binary @xmath23-stable embedding ( or b@xmath23se ) relates the _ angular _ distance between @xmath42 and @xmath43 to the hamming distance of their mappings , _",
    "i.e. _ , two distances that are equal to zero in our counter - example above , which removes the contradiction .    _",
    "remark : _ the question whether dithering is necessary in the special case of a quantized mapping with a gaussian random matrix @xmath24 remains open .",
    "the architecture of this proof is inspired by the one developed in @xcite for characterizing a 1-bit random mapping @xmath450 , @xmath451 . as will be clear below , some of the ingredients developed there had of course to be adapted to the specificities of @xmath113 and of our scalar quantization .",
    "compared to @xcite we have also paid attention to optimize the dependency of @xmath7 to the desired level of distortions induced by  @xmath113 in  .",
    "[ prop : main - result ] is proved as a special case of a more general proposition based on a `` softer '' variant of @xmath229 .",
    "this new pseudo - distance is established as follows . defining the random mapping @xmath452 ,",
    "with @xmath453 its @xmath122 component , we observe that for any @xmath454 , @xmath455,\\ ] ] with the _ distinct sign event _ @xmath456 . in words",
    ", for each @xmath199 $ ] , the sum over @xmath457 above simply counts the number of thresholds in @xmath458 separating @xmath459 and @xmath460 on the real line , since @xmath461 $ ] is equal to 1 for those and  0 for any other thresholds .",
    "notice that the decomposition also justifies the observation made at the end of sec .",
    "[ sec : consistency - width ] , namely the existence of uniform random tessellations of @xmath14 .",
    "indeed , from the definition of @xmath113 , for each @xmath199 $ ] , @xmath462 $ ] also counts the number of parallel affine hyperplanes @xmath463 , all normal to @xmath198 and @xmath464 far apart , separating @xmath42 and @xmath465 .",
    "in other words , @xmath14 is here tessellated with multiple so - called `` hyperplane wave partitions '' @xmath466\\}$ ] @xcite with random orientations , periods and dithered origin .     for @xmath467 .",
    "_ on the top _ , @xmath468 and forbidden areas determined by @xmath469",
    "are created when counting the number of thresholds @xmath470 separating @xmath471 and @xmath472 .",
    "for instance , for an additional point @xmath473 as on the figure , @xmath474 but @xmath475 as @xmath476 lies in one forbidden area .",
    "_ on the bottom _ figure , @xmath477 and threshold counting procedure operated by @xmath478 is relaxed .",
    "now @xmath479 counts the number of limits ( in dashed ) of the green areas determined by @xmath469 , recording only one per thresholds @xmath470 , that separate @xmath471 and @xmath472 . here , for @xmath480 as on the figure , @xmath481 but @xmath482 .",
    "]    based on this observation , and as a generalization of an equivalent distance given in ( * ? ? ?",
    "5 ) for binary mappings , we introduce for some @xmath483 the new pseudo - distance @xmath484,\\ ] ] by defining the set @xmath485 the pseudo - distance @xmath486 is a non - increasing function of @xmath155 , with @xmath487 and @xmath488 the behavior of @xmath486 is best understood by introducing the one - dimensional distance @xmath489\\ \\in\\ \\delta { \\mathbb}n,\\quad { \\rm for}\\ a , b\\in{\\mathbb}r,\\ ] ] so that @xmath490 fig .",
    "[ fig : dt - behav ] explains how @xmath479 evolves for positive and negative @xmath155 , observing that , for each @xmath491 , @xmath492 determines forbidden or relaxed areas around the thresholds @xmath470 separating @xmath471 and @xmath472 and counted by @xmath479 . moreover , the next lemma , proved in app .",
    "[ sec : proof - lemma - bounded - dbar ] , provides a first evaluation of the impact of the distance `` softening '' , by observing that , essentially , @xmath479 is not very far from both @xmath493 and @xmath494 for @xmath495 close to @xmath155 .",
    "[ lem : bounded - dbar ] for any @xmath467 and @xmath496 , @xmath497    as announced above , we aim now at proving the next proposition whose special case @xmath498 leads to prop .",
    "[ prop : main - result ] .",
    "[ prop : main - relaxed - result ] given @xmath2 , @xmath287 , @xmath483 , @xmath499 , a bounded subset @xmath31 and a sub - gaussian distribution @xmath289 respecting for @xmath290 , there exist some values @xmath500 , only depending on @xmath193 , such that , if @xmath501 with @xmath502 the kolmogorov @xmath503-entropy of @xmath32 and the local set @xmath504 for @xmath505 , then for @xmath295 , a dithering @xmath296)$ ] , and the associated mapping @xmath113 defined in , we have with probability exceeding @xmath506 that for all pairs @xmath285 with @xmath279 , @xmath507    the proof sketch of prop .  [ prop : main - relaxed - result ] is as follows : _ ( i ) _ given @xmath508 , we first show that the @xmath509 concentrates with high probability around @xmath325 up to a systematic bias @xmath510 due to the sub - gaussian nature of @xmath24 and controlled by the anti - sparse level of @xmath511 ; _ ( ii ) _ we take a finite covering of @xmath32 by a @xmath503-net @xmath512 ( for @xmath505 ) and we extend the concentration of @xmath509 to all vectors of @xmath513 by union bound ; _ ( iii ) _ we show that the softened pseudo - distance @xmath486 is sufficiently continuous in a neighborood of each pair of vectors in @xmath513 , which then allows us to extend to all pair of vectors in @xmath32 , as stated by prop .",
    "[ prop : main - relaxed - result ] .",
    "[ [ i - concentration - of - mathcaldtboldsymbolxboldsymboly ] ] _",
    "( i ) concentration of @xmath509 : _",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    given a fixed pair @xmath514 , we show that @xmath509 concentrates around its mean by bounding its sub - gaussian norm as defined in . from , @xmath515 with the @xmath7 random variables @xmath516 for @xmath244 . however , the sum of @xmath517 independent sub - gaussian random variables @xmath518 is approximately invariant under rotation @xcite , which means that @xmath519 therefore , from  , we find @xmath520    as shown in the following lemma ( proved in app .",
    "[ sec : proof - lemma - subgaussian - dt ] by using lemma  [ lem : bounded - dbar ] ) @xmath521 can be upper bounded ( and with it , the sub - gaussian norm of @xmath509 ) .",
    "[ lem : subgaussian - dt ] let us take @xmath210 and @xmath262)$ ] .",
    "for a fixed @xmath483 , the random variable @xmath522 is sub - gaussian with @xmath187-norm bounded by @xmath523 moreover , @xmath524 with @xmath525 if @xmath526 .",
    "consequently , from and , @xmath527 is itself sub - gaussian with @xmath528 .",
    "therefore , from the tail bound , there exists a @xmath57 such that for any  @xmath81 @xmath529 { \\leqslant}2 \\exp\\big(- c \\epsilon^2 m\\big).\\ ] ] since @xmath530 and @xmath531 for all @xmath532 $ ] , provides @xmath533 for some constant @xmath534 , and @xmath535    { \\leqslant}2 \\exp\\big(- c \\epsilon^2 m\\big).\\ ] ]    [ [ ii - extension - to - a - covering - of - mathcalk ] ] _ ( ii ) extension to a covering of @xmath32 : _ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    given a radius @xmath505 to be specified later , let @xmath513 an @xmath503-net of @xmath32 , _",
    "i.e. _ , a finite vector set such that for any @xmath37 there exists a @xmath536 with @xmath537 . in particular ,",
    "any vectors @xmath285 can then be written as @xmath538 for some @xmath539 and @xmath540 .",
    "we also assume that the size of @xmath513 is minimal so that , by definition , @xmath541 , with @xmath542 the _ kolmogorov @xmath503-entropy _ of @xmath32 .",
    "since there are no more than @xmath543 distinct pairs of vectors in @xmath513 , given @xmath483 , a standard union bound over shows that there exist some constant @xmath544 such that , if @xmath545 @xmath546\\nonumber\\\\ \\label{eq : concent - dt - cover - set } & \\textstyle{\\geqslant}\\ 1\\ , -\\ , |{\\mathcal}g_\\eta|^2 \\exp\\big(- c\\epsilon^2 m\\big)\\ { \\geqslant}\\ 1 - 2 \\exp\\big(- c''\\epsilon^2 m\\big).\\end{aligned}\\ ] ]    [ [ iii - extension - to - mathbbrn - by - continuity - of - mathcaldt ] ] _ ( iii ) extension to @xmath14 by continuity of @xmath486 : _ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we can extend the event characterized in to all pairs of vectors in @xmath32 by analyzing the continuity property of @xmath486 in a limited neighborhood around the considered vectors .",
    "we propose here to analyze this continuity with respect to @xmath6-perturbations of those vectors , as compared to @xmath5-perturbations in @xcite .",
    "as will be clearer later , this allows us to reach a better control over @xmath7 with respect to @xmath23 .",
    "[ lem : continuity - l2-dt ] let @xmath547 .",
    "we assume that @xmath548 , @xmath549 for some @xmath550",
    ". then for every @xmath483 and @xmath551 one has @xmath552    the proof is given in app .",
    "[ sec : app - proof - cont - l2-perturb ] .",
    "interestingly , the following proposition proved in app .",
    "[ sec : proof - prop - small - resid - l2 ] shows that @xmath553 and @xmath554 can indeed be bounded uniformly for all @xmath555 .",
    "[ lem : small - resid - l2 ] let @xmath556 be bounded , _",
    "i.e. _ , @xmath557 and assume @xmath558 . then , for some @xmath57 , if @xmath559 for @xmath560 and with probability at least @xmath561 , we have for all @xmath562 @xmath563 _ i.e. _ , @xmath564 .    for the sake of simplicity , we consider below the sub - gaussian parameter @xmath193 as fixed and integrate it in explicit or hidden constants , as in the notations `` @xmath565 '' or `` @xmath566 '' .",
    "noting that @xmath567 and using a union bound over and , we get that if @xmath568 with probability higher than @xmath569 , for all @xmath539 and all @xmath570 , @xmath571 for some @xmath500 depending only on @xmath193 .",
    "therefore , for any @xmath248 , using sequentially , , the upper bound given in lemma  [ lem : continuity - l2-dt ] and provides @xmath572 however , given @xmath210 , using jensen s inequality , the reverse triangular inequality and  , we find @xmath573 moreover , @xmath574 , so that , @xmath575 if @xmath279 , then induces @xmath576 and assuming  @xmath577 , there exists a @xmath57 such that @xmath578    taking @xmath579 and @xmath580 , which gives @xmath581 and",
    "@xmath582 , we find for another @xmath57 @xmath583    similarly , using , , the lower bound given in lemma  [ lem : continuity - l2-dt ] and , we obtain @xmath584 finally , we have thus shown that there exist some @xmath291 such that for @xmath585 with probability at least @xmath586 the bound @xmath587 holds for all @xmath588 , which finishes the proof of prop .",
    "[ prop : main - relaxed - result ] .    as mentioned earlier , prop .",
    "[ prop : main - result ] is thus obtained by simplifying the requirement appearing in prop .  [",
    "prop : main - relaxed - result ] .",
    "first , for a general bounded set @xmath32 , since the sudakov inequality in ( p[p : w - suda ] ) provides @xmath589 , noticing that @xmath590 and that ( p[p : w - setinc ] ) and ( p[p : w - setdiff ] ) provide @xmath591 , we deduce that holds if @xmath592 as imposed in .",
    "second , in the case of a quantized embedding of the structured sets defined in the introduction ( see def .  [",
    "def : structured - set ] ) , we can even reach a much weaker condition on @xmath7 . indeed , for such a set @xmath32 with @xmath593 , from   and the definition of @xmath294",
    ", we have for any @xmath594 @xmath595 so that , from  , the right - hand side of can be bounded as @xmath596 this explains the simpler requirement   needed for structured sets in prop .",
    "[ prop : main - result ] .",
    "_ example : _ let us conclude this section by deducing an upper bound on @xmath597 for the set @xmath598 ( with @xmath599 ) of bounded @xmath33-sparse vectors in an orthonormal basis @xmath600 of @xmath14 .",
    "we first notice that since @xmath601 by invariance over the orthogonal group @xmath602 ( see ( p[p : w - invort ] ) in table  [ tab : gaussian - mean - width - prop ] ) and from ( p[p : w - spars ] ) , @xmath603 moreover , the kolmogorov entropy is also invariant under @xmath602 , _",
    "i.e. _ , @xmath604 and it is known that ( see , _",
    "e.g. _ , @xcite ) @xmath605 by using stirling s bound .",
    "this shows that @xmath606 with @xmath607 . additionally , since @xmath85 is invariant under dilation , @xmath608 and @xmath609 showing again , by matching with  , that we have @xmath610 .",
    "this confirms that @xmath105 has the same upper bound than @xmath106 .",
    "therefore , for the structured set @xmath32 of bounded @xmath33-sparse vectors , ( and therefore ) is then satisfied  if @xmath611",
    "using the context defined in prop .",
    "[ prop : consistency - width ] and for @xmath7 satisfying , we are going to show the contraposition of , _",
    "i.e. _ , that with probability at least @xmath612 for some @xmath57 and for all @xmath285 with @xmath613 , having @xmath614 involves @xmath615 , or equivalently that @xmath616 from the definition of @xmath229 in .",
    "the proof sketch is a follows .",
    "first , for some @xmath505 , we create a finite @xmath503-covering of the set @xmath617 of vector pairs whose difference belongs to @xmath268 .",
    "second , in order to show  , we leverage the continuity of the pseudo - distance @xmath486 under @xmath6-perturbations ( lemma  [ lem : continuity - l2-dt ] ) , as it happens that all points of @xmath618 are obtained by @xmath6-perturbations of the @xmath503-covering and that , moreover , those perturbations are stable under projections by @xmath24 ( lemma [ lem : small - resid - l2 ] ) . finally , we adjust @xmath503 and some additional parameters to show that , with high probability , the softened distance @xmath619 , for some @xmath155 depending on @xmath503 , is large enough over all pairs @xmath620 of the covering compatible with  @xmath621 , hence inducing .",
    "let us define the set @xmath622 .",
    "we introduce a minimal @xmath503-net @xmath623 of @xmath618 with @xmath624 to be specified later , such that for all @xmath625 , there exists a @xmath626 with @xmath627 which also involves @xmath537 and @xmath628 .",
    "the size of this minimal @xmath503-net is bounded as @xmath629 . indeed , by the semi - additivity of the kolmogorov entropy (",
    "* theorem 2 ) , @xmath617 involves that @xmath630 for any @xmath631 .",
    "since a @xmath632-net of @xmath633 can be obtained by the product @xmath634 , with @xmath635 and @xmath636 a @xmath637-net covering of @xmath32 , we obtain @xmath638 .    as for the proof of prop .",
    "[ prop : main - result ] in sec .",
    "[ sec : proofs ] , by construction , all @xmath639 can also be written as @xmath640 with @xmath641 , @xmath642 .",
    "notice that we have also @xmath643 , since @xmath644 and @xmath645 .",
    "as stated by lemma  [ lem : small - resid - l2 ] , the diameter of the _ local set _",
    "@xmath646 is stable with respect to random projections . since @xmath567",
    ", there exist indeed two values @xmath647 , only depending on the sub - gaussian norm @xmath193 , such that if @xmath648 and @xmath649 , we have with probability at least @xmath650 , @xmath651 therefore , @xmath652 and @xmath653 under the same conditions .    moreover , if the previous event occurs , then , lemma  [ lem : continuity - l2-dt ] for @xmath498 shows that for any @xmath551 , @xmath654    consequently , for reaching @xmath655 as expressed in , since @xmath656 involves @xmath657 , the proof can be deduced if we can guarantee that , for all @xmath658 with @xmath659 , the probability that @xmath660 tends ( exponentially ) to one with @xmath7 .",
    "let us upper bound the corresponding probability of failure .",
    "we can first observe the following result on a fixed pair of vectors .",
    "this one is proved in app .",
    "[ sec : proof - lemma - prob - bound - qdist - gtr - r ] .",
    "[ lem : prob - bound - qdist - gtr - r ] let @xmath661 be in @xmath14 with @xmath662 for some @xmath345 and @xmath663 for @xmath664 . for @xmath40 , @xmath468 , @xmath665 $ ] , @xmath295 , @xmath666)$ ] and the pseudo - distance @xmath486 defined in , we have @xmath667 { \\leqslant}\\exp(-\\frac{(mp - r)^2}{2mp}),\\ ] ] with @xmath668 $ ] , @xmath669 and @xmath262)$ ] . moreover , if @xmath670 , @xmath671    from the discrete nature of @xmath486 , the previous lemma ( with @xmath155 set to @xmath672 ) shows that for a fixed pair of vectors @xmath673 holds with probability at least @xmath674 . moreover ,  if @xmath675 we have @xmath676 therefore , setting @xmath677 , gives @xmath678 { \\geqslant}1 - \\exp(-\\frac{(mp - r)^2}{2mp } ) > 1 - 2\\exp(-\\frac{mp}{8}),\\ ] ] if , from , @xmath679 thus , we have to adjust @xmath680 and @xmath503 in order to satisfy .",
    "noting that @xmath681 if @xmath682 , _ i.e. _ , that we can set @xmath683 in lemma  [ lem : prob - bound - qdist - gtr - r ] , this adjustment can be done from by imposing @xmath684  in @xmath685 a solution is to set , for some @xmath686 and @xmath93 to be specified later , @xmath687 and @xmath688 . then @xmath689 so that @xmath690 fixing @xmath691 and @xmath692 , a few estimations show finally that @xmath693 proving that for our choice of parameters , _",
    "i.e. _ , for @xmath694 and @xmath695 , can be satisfied since @xmath684 . moreover , for this choice of parameters , provides @xmath696    we are now ready to complete the proof . using the previous developments , defining @xmath697 with @xmath698 fixed as above and @xmath699 as explained before , by a simple union bound there exist some constants @xmath500 such that if @xmath700 then the event @xmath701 holds with probability at least @xmath702    remembering that for having the diameter of @xmath646 must remain small under random projections by @xmath24 ( as stated in ) , so by imposing , we find again by union bound that for some other constants @xmath500 , if @xmath703 then , with probability at least @xmath704 , for all @xmath285 with @xmath273 and @xmath621 , combined with provides @xmath705 as requested at the beginning .",
    "we conclude the proof by simplifying the general condition .",
    "first , for a general bounded set @xmath32 , sudakov inequality ( p.  [ p : w - suda ] ) and sec .",
    "[ sec : proofs ] provide @xmath706 and @xmath707 , so that holds if @xmath708 for another constant @xmath21 .",
    "second , if the set @xmath32 is structured , then , from   and the same simplifications used for prop .",
    "[ prop : main - relaxed - result ] to reach prop .",
    "[ prop : main - result ] , the right - hand side of   can be bounded  by @xmath709 with @xmath710 , which explains the requirement .",
    "we wish to gladly thank holger rauhut and sjoerd dirksen for interesting and enlightening discussion on quantized random projections during a short stay end of january 2015 in rwth aachen university , and jerry veeh ( auburn university , al , usa ) for interesting discussions on the error bounds of the stirling s approximation , as deduced in his lecture notes @xcite , and for having pointed out the work @xcite .",
    "we also thank valerio cambareri ( uclouvain , belgium ) for interesting discussions on quantized embeddings and for his advices on the writing of this  paper .",
    "this short appendix proves the equality @xmath711).\\ ] ] denoting @xmath712 , @xmath713 , @xmath714 and @xmath715 , since @xmath716 for any @xmath717 and @xmath718 , we can always write @xmath719 with @xmath720 . without loss of generality , we can assume that the @xmath166 is positive , _",
    "i.e. _ , @xmath721 ( just flip the role of @xmath722 and @xmath723 if this is not the case ) . moreover , since @xmath724 , @xmath725 and @xmath726 therefore , @xmath727 if @xmath728 , then @xmath729 .",
    "let us consider now the case @xmath730 .",
    "if @xmath731 , then @xmath732 since @xmath733 , _ i.e. _ , @xmath734 since @xmath735 . consequently ,   provides @xmath736 . when @xmath737 , @xmath738 , _",
    "i.e. _ , @xmath739 , and we get @xmath740 . in summary ,",
    "@xmath741 in all cases , which proves the result .",
    "we start by observing that @xmath742 - { { \\mathbb}i}[{{\\mathcal}f^s(a - k\\delta , b - k\\delta)}]\\big|\\\\      & \\textstyle { \\leqslant}\\sum_{k\\in{\\mathbb}z } { { \\mathbb}i}[{{\\mathcal}h^{t , s}(a - k\\delta , b - k\\delta)}]\\end{aligned}\\ ] ] with @xmath743 for @xmath744 , @xmath745 and @xmath746 , while for @xmath747 , @xmath748 .",
    "moreover , a careful piecewise analysis made on the different sign combinations for @xmath495 and @xmath155 show that @xmath749\\ } \\cup \\{|b| \\in [ r_-,r_+]\\}$ ] with @xmath750 and @xmath751 equals to @xmath752 if @xmath753 and 0 otherwise .",
    "consequently , writing @xmath754 , @xmath755\\ } \\cup      \\{|b - k\\delta|\\in [ r_-,r_+]\\}\\big]\\\\ & { \\leqslant}\\ 2 \\delta ( \\tfrac{2r}{\\delta } + 2 ) = 4 ( |t - s| + \\delta ) .",
    "\\end{aligned}\\ ] ] moreover , if @xmath756 , since then @xmath757 and @xmath758 , @xmath759 { \\leqslant}2 \\delta ( \\tfrac{2|t|}{\\delta }      + 1 ) = 4|t| + 2\\delta,\\ ] ] and we find @xmath760",
    "let us define @xmath761 with the two s @xmath762 and @xmath763 . from , @xmath764 .",
    "moreover , from the approximate rotational invariance property , @xmath765 is sub - gaussian with @xmath766 , and using lemma  [ lem : bounded - dbar ] and the bound @xmath767 , we find @xmath768 which demonstrates the sub - gaussianity of @xmath769 .    for the expectation , writing @xmath770 and @xmath771 with @xmath772 and @xmath773 , by jensen s inequality and the law of total expectation , we find @xmath774 however , reusing some elements of the proof of lemma  [ lem : bounded - dbar ] and considering @xmath775 fixed , @xmath776\\\\ & \\textstyle{\\leqslant}\\delta\\,\\sum_{k\\in{\\mathbb}z } { \\mathbb}e_\\xi{{\\mathbb}i}\\big[\\{|a'+\\xi - k\\delta|{\\leqslant}|t|\\}\\big ] + \\delta\\,\\sum_{k\\in{\\mathbb}z } { \\mathbb}e_\\xi{{\\mathbb}i}\\big[\\{|b'+\\xi - k\\delta|{\\leqslant}|t|\\}\\big ] .",
    "\\end{aligned}\\ ] ] moreover , since @xmath262)$ ] , @xmath777&\\textstyle=\\sum_{k\\in{\\mathbb}z}\\int_0^\\delta{{\\mathbb}i}\\big[\\{|a'+s - k\\delta|{\\leqslant}|t|\\}\\big]\\,{\\mathrm{d}}s\\\\ & = \\textstyle\\int_{{\\mathbb}r } { { \\mathbb}i}\\big[\\{|a'+s|{\\leqslant}|t|\\}\\big ] { \\mathrm{d}}s\\ = \\ 2|t| ,   \\end{aligned}\\ ] ] which provides also @xmath778 = 2|t|$ ] .",
    "consequently , since these two quantities do not depend on @xmath775 , we find @xmath779 , @xmath780 , and @xmath781 .",
    "we adapt the proof of lemma 5.5 in @xcite to both @xmath6-perturbations ( instead of @xmath5 ones ) of @xmath782 and @xmath783 , and to the context of uniform dithered quantization instead of 1-bit ( sign ) quantization . by assumption",
    ", we have @xmath548 and @xmath549 .",
    "therefore , the set @xmath784 : |({\\boldsymbol}\\phi { \\boldsymbol}x')_i| { \\leqslant}\\eta \\sqrt p , |({\\boldsymbol}\\phi { \\boldsymbol}y')_i| { \\leqslant}\\eta \\sqrt p\\}\\ ] ] is such that @xmath785 as @xmath786 . considering the definition of @xmath469 in , we have , for all @xmath787 and any @xmath717 , @xmath788 with @xmath789 .    denoting @xmath790",
    ", we find @xmath791\\\\ & { \\leqslant}\\textstyle \\tfrac{\\delta}{m } \\sum_{i\\in t } \\sum_{k\\in{\\mathbb}z } { { \\mathbb}i}[{\\mathcal}f_i^{t}({\\boldsymbol}x_0 + { \\boldsymbol}x',{\\boldsymbol}y_0 + { \\boldsymbol}y ' , k\\delta ) ] + \\tfrac{\\delta}{m } \\sum_{i\\in t^{{\\tt c } } } \\sum_{k\\in{\\mathbb}z } { { \\mathbb}i}[{\\mathcal}f_i^{t+\\eta\\sqrt p - a_i}({\\boldsymbol}x_0 + { \\boldsymbol}x',{\\boldsymbol}y_0 + { \\boldsymbol}y ' , k\\delta)]\\\\    & { \\leqslant}\\textstyle \\tfrac{\\delta}{m } \\sum_{i\\in t } \\sum_{k\\in{\\mathbb}z } { { \\mathbb}i}[{\\mathcal}f_i^{t}({\\boldsymbol}x_0 + { \\boldsymbol}x',{\\boldsymbol}y_0 + { \\boldsymbol}y ' , k\\delta ) ] + \\tfrac{\\delta}{m } \\sum_{i\\in t^{{\\tt c } } } \\sum_{k\\in{\\mathbb}z } { { \\mathbb}i}[{\\mathcal}f_i^{t}({\\boldsymbol}x_0 + { \\boldsymbol}x',{\\boldsymbol}y_0 + { \\boldsymbol}y ' , k\\delta)]\\\\    & \\qquad\\textstyle + \\tfrac{1}{m } \\sum_{i\\in t^{{\\tt c } } } \\delta\\sum_{k\\in{\\mathbb}z } \\big|{{\\mathbb}i}[{\\mathcal}f_i^{t+\\eta\\sqrt p - a_i}({\\boldsymbol}x_0 + { \\boldsymbol}x',{\\boldsymbol}y_0 + { \\boldsymbol}y ' , k\\delta ) ] - { { \\mathbb}i}[{\\mathcal}f_i^{t}({\\boldsymbol}x_0 + { \\boldsymbol}x',{\\boldsymbol}y_0 + { \\boldsymbol}y ' , k\\delta)]\\big|.\\end{aligned}\\ ] ] using to bound the last sum of the last expression and since , by definition of @xmath792 , @xmath793 for @xmath794 , we find @xmath795 however , @xmath796 and since @xmath797 for all @xmath152 , we find @xmath798 which provides the lower bound of .    for the upper bound , @xmath799\\\\ & { \\geqslant}\\textstyle \\tfrac{\\delta}{m } \\sum_{i\\in t } \\sum_{k\\in{\\mathbb}z } { { \\mathbb}i}[{\\mathcal}f_i^{t}({\\boldsymbol}x_0 + { \\boldsymbol}x',{\\boldsymbol}y_0 + { \\boldsymbol}y ' , k\\delta ) ] + \\tfrac{\\delta}{m } \\sum_{i\\in t^{{\\tt c } } } \\sum_{k\\in{\\mathbb}z } { { \\mathbb}i}[{\\mathcal}f_i^{t-\\eta\\sqrt p+a_i}({\\boldsymbol}x_0 + { \\boldsymbol}x',{\\boldsymbol}y_0 + { \\boldsymbol}y ' , k\\delta)]\\\\    & { \\geqslant}\\textstyle { { \\mathcal}d}^{t}({\\boldsymbol}x_0 + { \\boldsymbol}x',{\\boldsymbol}y_0 + { \\boldsymbol}y')\\\\    & \\qquad\\textstyle - \\tfrac{1}{m } \\sum_{i\\in t^{{\\tt c } } } \\delta\\sum_{k\\in{\\mathbb}z } \\big|{{\\mathbb}i}[{\\mathcal}f_i^{t}({\\boldsymbol}x_0 + { \\boldsymbol}x',{\\boldsymbol}y_0 + { \\boldsymbol}y ' , k\\delta ) ] - { { \\mathbb}i}[{\\mathcal}f_i^{t-\\eta\\sqrt p+a_i}({\\boldsymbol}x_0 + { \\boldsymbol}x',{\\boldsymbol}y_0 + { \\boldsymbol}y ' , k\\delta)]\\big|,\\end{aligned}\\ ] ] and , as above , the last sum can be upper - bounded by @xmath800 using .",
    "we use here a similar proposition of mendelson with @xmath801 @xcite . ] _ et al . _ in @xcite for subsets of @xmath802 that we lift to subsets of @xmath803 thank to some tools developed in @xcite for other purposes .",
    "we fix @xmath804 and form the set @xmath805 with @xmath806 . as @xmath807 , we know from ( * ? ? ?",
    "* theorem 2.1 ) that for @xmath808 , @xmath809 and @xmath810 , @xmath811 { \\leqslant}\\exp(-c \\tfrac{\\epsilon^2 m}{\\alpha^4}).\\ ] ] however , for @xmath812 and @xmath813 , as observed similarly in @xcite , @xmath814 since , for all @xmath815 , @xmath816 , _",
    "i.e. _ , @xmath817 .",
    "therefore , fixing @xmath818 , if @xmath819 , with probability at least @xmath820 , we have , for all @xmath815 , @xmath821 where @xmath822 , @xmath823 is the last column of @xmath824 and using the fact that @xmath825 since @xmath826 .",
    "therefore , replacing @xmath155 by its value , we find with the same probability , @xmath827 for all @xmath815 , _",
    "i.e. _ , @xmath828 .",
    "from the relation @xmath829 established in sec .  [ sec : proofs ] between @xmath486 and @xmath830 defined in , and associated to the vectorial mapping @xmath831 whose components are independent , we reach the bound with the cdf of a binomial distribution : since @xmath832{\\leqslant}&\\textstyle\\ { \\mathbb}p\\big[\\,\\big|\\{j \\in [ m]:\\ ,   d^t({\\phi^{^{_{\\!\\xi}}\\!}}_i({\\boldsymbol}u ) , { \\phi^{^{_{\\!\\xi}}\\!}}_i({\\boldsymbol}v ) ) \\neq 0\\}\\big| { \\leqslant}r\\big]\\\\ = & \\textstyle\\ \\sum_{k=0}^{r } { m\\choose k } p^k ( 1-p)^{m - k},\\end{aligned}\\ ] ] chernoff s inequality can upper bound this binomial cdf with @xmath833 { \\leqslant}\\exp(-\\frac{(mp - r)^2}{2mp}).\\ ] ]    let us now lower bound @xmath834 . defining @xmath835 and @xmath836 , the action of dithering @xmath837)$ ] allows us to compute easily that , @xmath838 = { \\mathbb}e \\min\\big(1 , \\delta^{-1 } ( |{\\boldsymbol}\\varphi^{\\top}{{\\boldsymbol}w}|-2t)_+\\big).\\ ] ] in order to avoid any further singularity when @xmath839 , we can benefit from the fact that @xmath132 and work with this slightly looser bound : @xmath840 moreover , with @xmath841 , @xmath842 so that @xmath843 where @xmath844 and @xmath845 .",
    "we can upper bound @xmath846 from our assumptions on the sub - gaussian vector @xmath210 : @xmath847 where the last inequalities rely on assumption ( setting @xmath848 ) and on the fact that @xmath312 .",
    "moreover , for lower - bounding @xmath849 in , we observe that @xmath850 for @xmath851 .",
    "therefore , defining @xmath852 and integrating by parts , we find @xmath853 where in the last inequality we used jensen s inequality and the convexity of @xmath854 .",
    "it is easy to see that @xmath855 so that @xmath856 finally , @xmath857 the last expression providing if @xmath858 .",
    "this small section establishes a lower bound on the approximation error of the mad @xmath859 of a binomial random variable @xmath860 by a fraction of its standard deviation @xmath861 when @xmath862 increases is well known ( see _ e.g. _ , @xcite ) .",
    "specifically , we want to prove that @xmath863 for some absolute constant @xmath21 and all @xmath864 .",
    "we start from the stirling s approximation of the factorial with an error bound due to r.  w.  gosper  @xcite and redeveloped more clearly in @xcite ( see also @xcite for a similar bound ) : @xmath865 however , de moivre gave the following exact formula for @xmath866 @xcite , @xmath867 therefore , applying on this formula and using @xmath868 for @xmath869 , we find for @xmath864 @xmath870 or equivalently @xmath871 with @xmath321 , which provides the result .",
    "m.  a. davenport , j.  n. laska , p.  t. boufounos , and r.  g. baraniuk . a simple proof that random matrices are democratic . technical report , rice university ece department technical report tree-0906 , houston , tx , november 2009 .",
    "s.  rane , p.  t. boufounos , and a.  vetro . quantized embeddings : an efficient and universal nearest neighbor method for cloud - based image retrieval . in _ proc .",
    "spie applications of digital image processing xxxvi _ , san diego , ca , august 25 - 19 2013 ."
  ],
  "abstract_text": [
    "<S> under which conditions and with which distortions can we preserve the pairwise - distances of low - complexity vectors , _ </S>",
    "<S> e.g. _ , for _ structured sets _ such as the set of sparse vectors or the one of low - rank matrices , when these are mapped ( or embedded ) in a finite set of vectors ?    </S>",
    "<S> this work addresses this general question through the specific use of a quantized and dithered random linear mapping which combines , in the following order , a sub - gaussian random projection in @xmath0 of vectors in @xmath1 , a random translation , or _ dither _ , of the projected vectors and a uniform scalar quantizer of resolution @xmath2 applied componentwise .    </S>",
    "<S> thanks to this quantized mapping we are first able to show that , with high probability , an embedding of a bounded set @xmath3 in @xmath4 can be achieved when distances in the quantized and in the original domains are measured with the @xmath5- and @xmath6-norm , respectively , and provided the number of quantized observations @xmath7 is large before the square of the `` gaussian mean width '' of @xmath8 . in this case , we show that the embedding is actually _ quasi - isometric _ and only suffers of both multiplicative and additive distortions whose magnitudes decrease as @xmath9 for general sets , and as @xmath10 for structured set , when @xmath7 increases . </S>",
    "<S> second , when one is only interested in characterizing the maximal distance separating two elements of @xmath8 mapped to the same quantized vector , _ </S>",
    "<S> i.e. _ , the `` consistency width '' of the mapping , we show that for a similar number of measurements and with high probability this width decays as @xmath11 for general sets and as @xmath12 for structured ones when @xmath7 increases . finally , as an important aspect of our work </S>",
    "<S> , we also establish how the non - gaussianity of sub - gaussian random projections inserted in the quantized mapping ( _ e.g. _ , for bernoulli random matrices ) impacts the class of vectors that can be embedded or whose consistency width provably decays when @xmath7 increases . </S>"
  ]
}