{
  "article_text": [
    "communities of co - occuring species may be described as `` clustered '' if species in the community tend to be close phylogenetic relatives of one another , or `` overdispersed '' if they are distant relatives  @xcite . to define these terms",
    "we need a function that measures the phylogenetic relatedness of a set of species , and also a point of reference for how this function should behave in the absence of ecological and evolutionary processes .",
    "one such function is the mean pairwise distance ( @xmath0 ) ; given a phylogenetic tree @xmath1 and a subset of species @xmath2 that are represented by leaf nodes of @xmath1 , the @xmath0 of the species in @xmath2 is equal to average cost of all possible simple paths that connect pairs of nodes in @xmath2 .    to decide",
    "if the value of the @xmath0 for a specific set of species @xmath2 is large or small , we need to know the average value ( expectation ) of the @xmath0 for all sets of species in @xmath1 that consist of exactly @xmath5 species . to judge how much larger or smaller",
    "is this value from the average , we also need to know the standard deviation of the @xmath0 for all possible sets of @xmath6 species in @xmath1 . putting all these values together ,",
    "we get the following index that expresses how clustered are the species in @xmath2  @xcite : @xmath7    where @xmath8 is the value of the @xmath0 for @xmath2 in @xmath1 , and @xmath9 and @xmath10 are the expected value and the standard deviation respectively of the @xmath0 calculated over all subsets of @xmath6 species in @xmath1 .    in a previous paper we presented optimal algorithms for computing the expectation and the standard deviation of the @xmath0 of a phylogenetic tree @xmath1 in @xmath3 time , where  @xmath4 is the number of the edges of @xmath1  @xcite .",
    "this enabled exact computations of these statistical moments of the @xmath0 on large trees , which were previously infeasible using traditional slow and inexact resampling techniques .",
    "however , one important problem remained unsolved ; quantifying our degree of confidence that the @xmath11 value observed in a community reflects non - random ecological and evolutionary processes .",
    "this degree of confidence is a statistical @xmath12 value , that is the probability that we would observe an @xmath11 value as extreme or more so if the community were randomly assembled .",
    "traditionally , estimating @xmath12 is accomplished by ranking the observed @xmath0 against the distribution of randomized @xmath0 values  @xcite .",
    "if the @xmath0 falls far enough into one of the tails of the distribution ( generally below the 2.5 percentile or above the 97.5 percentile , yielding @xmath13 ) , the community is said to be significantly overdispersed or significantly clustered .",
    "however , this approach relies on sampling a large number of random subsets of species in @xmath1 , and recomputing the @xmath0 for each random subset .",
    "therefore , this method is slow and imprecise .",
    "we can approximate the @xmath12 value of an observed @xmath11 by assuming a particular distribution of the possible @xmath0 values and evaluating its cumulative distribution function at the observed @xmath0 . because the @xmath11 measures the difference between the observed values and expectation in units of standard deviations , this yields a very simple rule if we assume that possible @xmath0 values are normally distributed : any @xmath11 value larger than @xmath14 or smaller than @xmath15 is significant .",
    "unfortunately , the distribution of @xmath0 values is often skewed , such that this simple rule will lead to incorrect @xmath12 value estimates  @xcite .",
    "of particular concern , this skewness introduces a bias towards detecting either significant clustering or significant overdispersion  @xcite .",
    "calculating this skewness analytically would enable us to remove this bias and improve the accuracy of @xmath12 value estimates obtained analytically .",
    "however , so far there has been no result in the related literature that shows how to compute this skewness value .    hence , given a phylogenetic tree @xmath1 and an integer @xmath6",
    "there is the need to design an efficient and exact algorithm that can compute the skewness of the @xmath0 for @xmath6 species in @xmath1 .",
    "this would provide the last critical piece required for the adoption of a fully analytical and efficient approach for analysing ecological communities using the @xmath0 and the @xmath11 .",
    "[ [ our - results ] ] our results + + + + + + + + + + +    in the present work we tackle the problem of computing efficiently the skewness of the @xmath0 . more specifically , given a tree @xmath1",
    "that consists of @xmath4 edges and a positive integer @xmath6 , we prove that we can compute the skewness of of the @xmath0 over all subsets of @xmath6 leaf nodes in @xmath1 optimally , in @xmath3 time . for the calculation of this skewness value",
    "we consider that every subset of exactly @xmath6 species in @xmath1 is picked uniformly out of all possible subsets that have @xmath6 species .",
    "the main contribution of this paper is a constructive proof that leads straightforwardly to an algorithm that computes the skewness of the @xmath0 in @xmath3 time .",
    "this is clearly very efficient , especially if we consider that it outperforms the best algorithms that are known so far for computing lower - order statistics for other phylogenetic measures ; for example the most efficient known algorithm for computing the variance of the popular phylogenetic distance ( @xmath16 ) runs in @xmath17 time  @xcite .",
    "more than that , we prove how we can compute in @xmath3 time several quantities that are related with groups of paths in the given tree ; these quantities can be possibly used as building blocks for computing efficiently the skewness ( and other statistical moments ) of phylogenetic measures that are similar to the @xmath0 .",
    "such an example is the measure which is the equivalent of the @xmath0 for computing the distance between two subsets of species in @xmath1  @xcite .",
    "the rest of this paper is , in its entirety , an elaborate proof for computing the skewness of the @xmath0 on a tree @xmath1 in @xmath3 time . in the next section",
    "we define the problem that we want to tackle , and we present a group of quantities that we use as building blocks for computing the skewness of the @xmath0 .",
    "we prove that all of these quantities can be computed in linear time with respect to the size of the input tree . in section  [ sec::mpd_proof ]",
    "we provide the main proof of this paper ; there we show how we can express the value of the skewness of the @xmath0 in terms of the quantities that we introduced earlier .",
    "the proof implies a straightforward linear time algorithm for the computation of the skewness as well .",
    "[ [ definitions - and - notation ] ] definitions and notation + + + + + + + + + + + + + + + + + + + + + + + +    let @xmath1 be a phylogenetic tree , and let @xmath18 be the set of its edges .",
    "we denote the number of the edges in @xmath1 by @xmath4 , that is @xmath19 . for an edge @xmath20",
    ", we use @xmath21 to indicate the weight of this edge .",
    "we use @xmath22 to denote the set of the leaf nodes of @xmath1 .",
    "we call these nodes the _ tips _ of the tree , and we use @xmath23 to denote the number of these nodes .",
    "since a phylogenetic tree is a rooted tree , for any edge @xmath20 we distinguish the two nodes adjacent to @xmath24 into a _ parent _ node and a _ child _ node ; among these two , the parent node of @xmath24 is the one for which the simple path from this node to the root does not contain @xmath24 .",
    "we use @xmath25 to indicate the set of edges whose parent node is the child node of @xmath24 , which of course implies that @xmath26 . we indicate the edge whose child node is the parent node of @xmath24 by @xmath27 . for any edge @xmath20 ,",
    "tree @xmath28 is the subtree of @xmath1 whose root is the child node of edge @xmath24 .",
    "we denote the set of tips that appear in @xmath28 as @xmath29 , and we denote the number of these tips by @xmath30 .    given any edge @xmath20 , we partition the edges of @xmath1 into three subsets .",
    "the first subset consists of all the edges that appear in the subtree of @xmath24 .",
    "we denote this set by @xmath31 .",
    "the second subset consists of all edges @xmath32 for which @xmath24 appears in the subtree of @xmath33 .",
    "we use @xmath34 to indicate this subset . for the rest of this paper",
    ", we define that @xmath35 , and that @xmath36 .",
    "the third subset contains all the tree edges that do not appear neither in @xmath31 , nor in @xmath34 ; we indicate this subset by @xmath37 .",
    "for any two tips @xmath38 , we use @xmath39 to indicate the simple path in @xmath1 between these nodes .",
    "of course , the path @xmath39 is unique since @xmath1 is a tree .",
    "we use @xmath40 to denote the cost of this path , that is the sum of the weights of all the edges that appear on the path .",
    "let @xmath41 be a tip in @xmath22 and let @xmath24 be an edge in @xmath18 .",
    "we use @xmath42 to represent the cost of the shortest simple path between @xmath41 and the child node of @xmath24 . therefore ,",
    "if @xmath43 this path does not include @xmath24 , otherwise it does . for any subset @xmath44 of the tips of the tree @xmath1",
    ", we denote the set of all pairs of elements in @xmath2 , that is the set of all combinations that consist of two distinct tips in @xmath2 , by @xmath45 . given a phylogenetic tree @xmath1 and a subset of its tips @xmath44 , we denote the mean pairwise distance of @xmath2 in @xmath1 by @xmath46 .",
    "let @xmath47 .",
    "this measure is equal to : @xmath48      let @xmath1 be a phylogenetic tree that consists of @xmath4 edges and @xmath23 tips , and let @xmath6 be a positive integer such that @xmath49 .",
    "we use @xmath50 to denote the skewness of the @xmath0 on @xmath1 when we pick a subset of @xmath6 tips of this tree with uniform probability . in the rest of this paper",
    "we describe in detail how we can compute @xmath50 in @xmath51 time , by scanning @xmath1 only a constant number of times .",
    "based on the formal definition of the concept of skewness , the value of @xmath50 is equal to : @xmath52 \\hfill\\notag\\\\[.2em ] & = \\frac{e_{r \\in \\mathrm{sub}(s , r)}[\\ensuremath{\\mathrm{mpd}}^3(\\mathcal{t},r)]-3 \\cdot \\ensuremath{\\mathrm{var}}(\\mathcal{t},r)^2-\\ensuremath{\\mathrm{expec}}(\\mathcal{t},r)^3}{\\ensuremath{\\mathrm{var}}(\\mathcal{t},r)^3 } \\ , \\label{eq::skewness_basic } \\end{aligned}\\ ] ] where @xmath53 and @xmath54 are the expectation and the variance of the @xmath0 for subsets of exactly @xmath6 tips in @xmath1 , and @xmath55 $ ] denotes the function of the expectation over all subsets of exactly @xmath6 tips in @xmath22 . in a previous paper",
    ", we showed how we can compute the expectation and the variance of the @xmath0 on @xmath1 in @xmath51 time  @xcite .",
    "therefore , in the rest of this work we focus on analysing the value @xmath56 $ ] and expressing this quantity in a way that can be computed efficiently , in linear time with respect to the size of @xmath1 .    to make things more simple",
    ", we break the description of our approach into two parts ; in the first part , we define several quantities that come from adding and multiplying the costs of specific subsets of paths between tips of the tree .",
    "we also present how we can compute all these quantities in @xmath51 time in total by scanning @xmath1 a constant number of times . then , in section  [ sec::mpd_proof ] , we show how we can express the skewness of the @xmath0 on @xmath1 based on these quantities , and hence compute the skewness in @xmath51 time as well .",
    "next we provide the quantities that we want to consider in our analysis ; these quantities are described in table  [ tab::quantities ] .    for any tip @xmath57 , we define that @xmath58 , and @xmath59 , where @xmath24 is the edge whose child node is @xmath41 .",
    "the proof of the following lemma is provided in the full version of this paper .",
    "[ le::fast_quantities ] given a phylogenetic tree @xmath1 that consists of @xmath4 edges , we can compute all the quantities that are presented in table  [ tab::quantities ] in @xmath51 time in total .",
    "in the previous section we defined the problem of computing the skewness of the @xmath0 for a given phylogenetic tree @xmath1 . given a positive integer @xmath49 ,",
    "we showed that to solve this problem efficiently it remains to find an efficient algorithm for computing @xmath56 $ ] ; this is the mean value of the cube of the @xmath0 among all possible subsets of tips in @xmath1 that consist of exactly @xmath6 elements .",
    "to compute this efficiently , we introduced in table  [ tab::quantities ] ten different quantities which we want to use in order to express this mean value . in lemma  [ le::fast_quantities ]",
    "we proved that these quantities can be computed in @xmath51 time , where @xmath4 is the size of @xmath1 .",
    "next we prove how we can calculate the value for the mean of the cube of the @xmath0 based on the quantities in table  [ tab::quantities ] .",
    "in particular , in the proof of the following lemma we show how the value @xmath56 $ ] can be written analytically as an expression that contains the quantities in table  [ tab::quantities ] .",
    "this expression can then be straightforwardly evaluated in @xmath51 time , given that we have already computed the aforementioned quantities  .",
    "the expectation of the cube of the @xmath0 is equal to : + @xmath60 = \\frac{8}{r^3(r-1)^3 } \\ \\ \\cdot \\\\ & e_{r \\in \\mathrm{sub}(s , r ) } \\left [ \\sum_{{\\{u , v\\}\\in\\delta(r ) } } \\hspace{0.05 in } \\sum_{{\\{x , y\\}\\in\\delta(r ) } } \\hspace{0.05in}\\sum_{{\\{c , d\\}\\in\\delta(r ) } } cost(u , v)\\cdot cost(x , y)\\cdot cost(c , d)\\right].\\end{aligned}\\ ] ] from the last expression we get : @xmath61\\nonumber \\\\[.2em ] & = \\hspace{-.7em}\\sum_{{\\{u , v\\}\\in\\delta(s ) } } \\sum_{{\\{x , y\\}\\in\\delta(s ) } } \\sum_{{\\{c , d\\}\\in\\delta(s ) } } \\!\\!cost(u,\\!v)\\!\\cdot \\!cost(x,\\!y ) \\!\\cdot \\!cost(c , d ) \\ \\",
    "\\nonumber\\\\[.2em ] & \\ \\",
    "e_{r \\in \\mathrm{sub}(s , r)}[ap_{\\!r}(u,\\!v , x , y , c , d)]\\,,\\label{eq::first_big_sum}\\end{aligned}\\ ] ] where @xmath62 is a random variable whose value is equal to one in the case that @xmath63 , otherwise it is equal to zero .",
    "for any six tips @xmath64 , which may not be all of them distinct , we use @xmath65 to denote the number of distinct elements among these tips .",
    "let @xmath66 be an integer , and let @xmath67 denote the @xmath68-th falling factorial power of @xmath66 , which means that @xmath69 .",
    "for the expectation of the random variables that appear in the last expression it holds that : @xmath70    = \\frac{(r)_{\\theta(u , v , x , y , c , d)}}{(s)_{\\theta(u , v , x , y , c , d ) } } \\label{eq::apr_theta}\\end{aligned}\\ ] ] notice that in  ( [ eq::apr_theta ] ) we have @xmath71 . the value of the function @xmath72 can not be smaller than two in the above case because we have that @xmath73 , @xmath74 , and @xmath75 .",
    "thus , we can rewrite ( [ eq::first_big_sum ] ) as : @xmath76 hence , our goal now is to compute a sum whose elements are the product of costs of triples of paths .",
    "recall that for each of these paths , the end - nodes of the path are a pair of distinct tips in the tree .",
    "although the end - nodes of each path are distinct , in a given triple the paths may share one or more end - nodes with each other .",
    "therefore , the distinct tips in any triple of paths may vary from two up to six tips .",
    "indeed , in ( [ eq::second_big_sum ] ) we get a sum where the triples of paths in the sum are partitioned in five groups ; a triple of paths is assigned to a group depending on the number of distinct tips in this triple . in  ( [ eq::second_big_sum ] ) the sum for each group of triples is multiplied by the same factor @xmath77 , hence we have to calculate the sum for each group of triples separately .",
    "however , when we try to calculate the sum for each of these groups of triples we see that this calculation is more involved ; some of these groups of triples are divided into smaller subgroups , depending on which end - nodes of the paths in each triple are the same . to explain this better",
    ", we can represent a triple of paths schematically as a graph ; let @xmath78 be three pairs of tips in @xmath1 . as mentioned already , the tips within each pair are distinct , but tips between different pairs can be the same .     and ( b ) an example of the tripartite graph induced by the triplet of its tip pairs @xmath79",
    "@xmath80 @xmath81 , where @xmath82 . the dashed lines in the graph distinguish the partite subsets of vertices ; the vertices of each partite subset correspond to tips of the same pair.,width=192 ]    we represent the similarity between tips of these three pairs as a graph of six vertices .",
    "each vertex in the graph corresponds to a tip of these three pairs .",
    "also , there exists an edge in this graph between two vertices if the corresponding tips are the same .",
    "thus , this graph is tripartite ; no vertices that correspond to tips of the same pair can be connected to each other with an edge .",
    "hence , we have a tripartite graph where each partite set of vertices consists of two vertices  see fig .",
    "[ fig::example_graph ] for an example .    for any triple of pairs of tips @xmath83 , @xmath84 ,",
    "@xmath85 we denote the tripartite graph that corresponds to this triple by @xmath86 $ ] .",
    "we call this graph the _ similarity _ graph of this triple . based on the way that similarities may occur between tips in a triple of paths , we can partition the five groups of triples in  ( [ eq::second_big_sum ] ) into smaller subgroups .",
    "each of these subgroups contains triples whose similarity graphs are isomorphic . for a tripartite graph that consists of three partite sets of two vertices each",
    ", there can be eight different isomorphism classes .",
    "therefore , the five groups of triples are partitioned into eight subgroups .",
    "figure  [ fig::isomorphisms ] illustrates the eight isomorphism classes that exist for the specific kind of tripartite graphs that we consider . since we refer to isomorphism classes , each of the graphs in fig .",
    "[ fig::isomorphisms ] represents the combinatorial structure of the similarities between three pairs of tips , and it does not correspond to a particular planar embedding , or ordering of the tips .",
    "let @xmath87 be any isomorphism class that is illustrated in figure  [ fig::isomorphisms ] .",
    "we denote the set of all triples of pairs in @xmath88 whose similarity graphs belong to this class by @xmath89 .",
    "more formally , the set @xmath89 can be defined as follows : @xmath90 \\textrm { and } g[u , v , x , y , c , d ] \\textrm { belongs to class $ x$ in figure~\\ref{fig::isomorphisms } } \\ }   \\ .\\end{aligned}\\ ] ] we introduce also the following quantity : @xmath91 hence , we can rewrite  ( [ eq::second_big_sum ] ) as follows : @xmath92 & +   3 \\cdot \\frac{(r)_4}{(s)_4}\\cdot \\ensuremath{\\mathrm{trs}}(e ) + 6 \\cdot \\frac{(r)_4}{(s)_4 } \\cdot \\ensuremath{\\mathrm{trs}}(f ) + 6 \\cdot \\frac{(r)_5}{(s)_5 } \\cdot \\ensuremath{\\mathrm{trs}}(g ) + 6 \\cdot \\frac{(r)_6}{(s)_6 } \\cdot \\ensuremath{\\mathrm{trs}}(h )   \\label{eq::le_big_sum}\\end{aligned}\\ ] ] notice that some of the terms @xmath93 in  ( [ eq::le_big_sum ] ) are multiplied with an extra constant factor .",
    "this happens for the following reason ; the sum in @xmath94 counts each triple once for every different combination of three pairs of tips .",
    "however , in the triple sum in  ( [ eq::second_big_sum ] ) some triples appear more than once .",
    "for example , every triple that belongs in class @xmath95 appears three times in  ( [ eq::second_big_sum ] ) , hence there is an extra factor three in front of @xmath96 in  ( [ eq::le_big_sum ] ) .    to compute efficiently @xmath56 $ ] , it remains to compute efficiently each value @xmath94 for every isomorphism class @xmath87 that is presented in figure  [ fig::isomorphisms ] .",
    "next we show in detail how we can do that by expressing each quantity @xmath94 as a function of the quantities that appear in table  [ tab::quantities ] .    for the triples that correspond to the isomorphism class @xmath97 we have : @xmath98 for @xmath96 we get : +   +",
    "the quantity @xmath99 is equal to : @xmath100   = & \\frac{1}{6 }",
    "\\sum_{e \\in e } w_e   \\sum_{u \\in s(e ) } \\hspace{0.05 in } \\sum_{v \\in s - s(e ) } \\hspace{0.05 in } \\sum_{x \\in s \\setminus \\{u , v\\ } } cost(u , x)\\cdot cost(x , v ) \\ .",
    "\\label{eq::nasty_0 }    \\end{aligned}\\ ] ] for any @xmath20 we have that : @xmath101   & = \\sum_{u \\in s(e ) } \\hspace{0.05 in } \\sum_{v \\in s \\setminus \\{u\\ } } \\hspace{0.05 in }    \\sum_{x \\in s \\setminus \\{u , v\\ } } cost(u , x ) \\cdot cost(x , v ) \\label{eq::nasty_1a } \\\\[0.2em ] & - 2 \\sum_{\\{u , v\\}\\in\\delta(s(e))}\\hspace{0.05 in } \\sum_{x \\in s \\setminus \\{u , v\\ } } cost(u , x ) \\cdot cost(x , v ) \\ .\\tag{\\ref{eq::nasty_1a}b } \\label{eq::nasty_1b}\\end{aligned}\\ ] ] the first of the two sums in  ( [ eq::nasty_1a ] ) can be written as : @xmath102      & = \\sum_{u \\in s(e ) } \\hspace{0.05 in } \\sum_{v \\in s \\setminus \\{u\\ } } \\hspace{0.05 in } \\sum_{x \\in s \\setminus \\{u , v\\ } } cost(u , v ) \\cdot cost(v , x ) \\nonumber \\\\[0.2em ]      & = \\sum_{u \\in s(e ) } \\hspace{0.05 in } \\sum_{v \\in s \\setminus \\{u\\ } } ( cost(u , v ) \\cdot \\ensuremath{\\mathrm{tc}}(v ) - cost^2(u , v ) ) \\nonumber \\\\[0.2em ]      & = \\sum_{u \\in s(e ) } \\ensuremath{\\mathrm{sm}}(u ) - \\ensuremath{\\mathrm{sq}}(u ) \\ .\\end{aligned}\\ ] ] according to lemma  [ le::main_lemma ] , we can compute @xmath103 and @xmath104 for all tips @xmath57 in linear time with respect to the size of @xmath1 . given these values , we can compute @xmath105 for every edge @xmath20 in @xmath1 with a single bottom - up scan of the tree . for any edge @xmath24 in @xmath18 ,",
    "the second sum in  ( [ eq::nasty_1b ] ) is equal to : @xmath106 & = \\sum _ { \\{u , v\\ } \\in \\delta(s(e ) ) } \\hspace{0.05 in } \\sum _ { x \\in s(e ) \\setminus \\{u , v\\ } }   cost(u , x ) \\cdot cost(x , v ) \\label{eq::nasty_2a } \\\\[0.2em ] & + \\sum _ { \\{u , v\\ } \\in \\delta(s(e ) ) } \\hspace{0.05 in } \\sum _ { x \\in s \\setminus s(e ) }   cost(u , x ) \\cdot cost(x , v ) \\ .",
    "\\tag{\\ref{eq::nasty_2a}b}\\label{eq::nasty_2b}\\end{aligned}\\ ] ] we can express the first sum in  ( [ eq::nasty_2a ] ) as : @xmath107 & = \\frac{1}{2 }   \\sum _ { u \\in s(e ) } \\left ( \\sum_{v \\in s(e ) \\setminus \\ { u \\ } } cost(u , v ) \\right)^2   - \\frac{1}{2 } \\sum_{u \\in s(e ) } \\sum_{v\\in s(e ) \\setminus \\{u\\ } } cost^2(u , v ) \\nonumber \\\\[0.2em ] & = \\frac{1}{2 }",
    "\\ensuremath{\\mathrm{qd}}(e )   - \\frac{1}{2 } \\sum_{u \\in s(e ) } \\sum_{v\\in s(e ) \\setminus \\{u\\ } } cost^2(u , v )   \\ . \\label{eq::nasty_25}\\end{aligned}\\ ] ] the last sum in  ( [ eq::nasty_25 ] ) is equal to : @xmath108 the value of the sum @xmath109 can be computed for every edge @xmath24 in @xmath3 time in total as follows ; for every tip @xmath57 we store @xmath104 together with this tip , and then scan bottom - up the tree adding those values that are in the subtree of each edge .",
    "for the remaining part of  ( [ eq::nasty_2b ] ) we get : @xmath110    & = \\sum _ { \\{u , v\\ } \\in \\delta(s(e ) ) } \\hspace{0.05 in } \\sum _ { x \\in s \\setminus s(e ) } \\left ( cost(u , e ) + cost(x , e ) \\right ) \\left ( cost(v , e ) + cost(x , e ) \\right ) \\nonumber \\\\[0.2em ]   & = \\sum _ { \\{u , v\\ } \\in \\delta(s(e ) ) } \\hspace{0.05 in } \\sum _ { x \\in s \\setminus s(e ) } cost(u , e ) \\cdot cost(v , e ) \\nonumber \\\\[0.2em ]   & + \\sum _ { \\{u , v\\ } \\in \\delta(s(e ) ) } \\hspace{0.05 in } \\sum _ { x \\in s \\setminus s(e ) } cost(x , e ) \\cdot ( cost(u , e)+ cost(v , e ) ) \\nonumber \\\\[0.2em ]   & + \\sum _ { \\{u , v\\ } \\in \\delta(s(e ) ) } \\hspace{0.05 in } \\sum _ { x \\in s \\setminus s(e ) } cost^2(x , e )   \\ .",
    "\\label{eq::nasty_4}\\end{aligned}\\ ] ] the first sum in  ( [ eq::nasty_4 ] ) is equal to : @xmath111 for the second sum in  ( [ eq::nasty_4 ] ) we have : @xmath112   = & \\big(s(e)-1\\big)\\!\\!\\sum_{x \\in s \\setminus s(e ) } \\!\\!cost(x , e ) \\cdot \\ensuremath{\\mathrm{tc_{sub}}}(e )   = \\big(s(e)-1\\big ) \\cdot \\ensuremath{\\mathrm{tc_{sub}}}(e ) \\cdot \\big(\\ensuremath{\\mathrm{pc}}(e ) - \\ensuremath{\\mathrm{tc_{sub}}}(e ) \\big)\\ , .",
    "\\label{eq::nasty_6}\\end{aligned}\\ ] ] the last sum in  ( [ eq::nasty_4 ] ) can be written as : @xmath113 combining the analyses that we did from ( [ eq::nasty_0 ] ) up to ( [ eq::nasty_7 ] ) we get : @xmath114 & + ( s-2s(e)+1 ) \\cdot \\ensuremath{\\mathrm{tc_{sub}}}^2(e )   - \\frac{2s - 2\\cdot s(e)+ s(e)(s(e)-1)}{2 } \\cdot \\ensuremath{\\mathrm{sq_{sub}}}(e ) \\nonumber \\\\[0.2em ] & + ( s(e)-1 ) \\cdot \\ensuremath{\\mathrm{tc_{sub}}}(e ) \\cdot \\ensuremath{\\mathrm{pc}}(e ) + \\frac{s(e)(s(e)-1)}{2 } \\cdot \\ensuremath{\\mathrm{psq}}(e)\\ ; .\\end{aligned}\\ ] ] the value of @xmath115 can be expressed as : @xmath116   & = \\frac{1}{6 } \\cdot \\sum_{u \\in s } \\ensuremath{\\mathrm{tc}}^3(u ) + \\frac{2}{3 } \\cdot \\ensuremath{\\mathrm{cb}}(\\mathcal{t } ) - \\frac{1}{2 } \\cdot \\ensuremath{\\mathrm{sq}}(u ) \\cdot \\ensuremath{\\mathrm{tc}}(u )   \\ .\\end{aligned}\\ ] ] for @xmath117 we get : @xmath118   & = \\sum _ { \\{u , v\\ } \\in \\delta(s ) } cost^2(u , v ) ( \\ensuremath{\\mathrm{tc}}(\\mathcal{t } ) - \\ensuremath{\\mathrm{tc}}(u ) - \\ensuremath{\\mathrm{tc}}(v ) + cost(u , v ) ) \\\\[0.2em ]   & =   \\ensuremath{\\mathrm{tc}}(\\mathcal{t } ) \\sum _ { e \\in e } w_e \\cdot \\ensuremath{\\mathrm{tc}}(e )   - \\sum_{u \\in s } \\left ( \\ensuremath{\\mathrm{sq}}(u ) \\cdot \\ensuremath{\\mathrm{tc}}(u ) \\right ) + \\ensuremath{\\mathrm{cb}}(\\mathcal{t } ) \\ .\\end{aligned}\\ ] ] we can rewrite @xmath119 as follows : @xmath120   & = \\!\\sum _ { \\{u , v\\ } \\in \\delta(s ) } cost(u , v ) \\cdot \\ensuremath{\\mathrm{tc}}(u ) \\cdot \\ensuremath{\\mathrm{tc}}(v ) - \\ensuremath{\\mathrm{cb}}(\\mathcal{t } ) - 3 \\cdot \\ensuremath{\\mathrm{trs}}(c ) \\\\[0.6em ]   & =   \\sum _ { e \\in e } w_e \\cdot \\ensuremath{\\mathrm{mult}}(e ) - \\ensuremath{\\mathrm{cb}}(\\mathcal{t } ) - 3 \\cdot \\ensuremath{\\mathrm{trs}}(c ) \\ .\\end{aligned}\\ ] ] for the value of @xmath121 we have : @xmath122 & - \\ensuremath{\\mathrm{tc}}(u ) -\\ensuremath{\\mathrm{tc}}(v ) - \\ensuremath{\\mathrm{tc}}(x ) + cost(u , v ) + cost(u , x ) + cost(v , x ) \\bigg ) \\ . \\label{eq::case_g}\\end{aligned}\\ ] ] we now break the sum in  ( [ eq::case_g ] ) into five pieces and express each piece of this sum in terms of the quantities in table  [ tab::quantities ] .",
    "the first piece of the sum is equal to : @xmath123    & =   \\frac{1}{2 } \\cdot \\ensuremath{\\mathrm{tc}}(\\mathcal{t } )   \\sum_{u \\in s}\\ensuremath{\\mathrm{tc}}^2(u ) - \\sum _ { \\ { u , v\\ } \\in \\delta(s ) } cost^2(u , v)\\\\[.6em ]     & = \\frac{1}{2 } \\cdot \\ensuremath{\\mathrm{tc}}(\\mathcal{t } )   \\sum_{u \\in s}\\ensuremath{\\mathrm{tc}}^2(u ) - \\sum_{e \\in e } w_e \\cdot \\ensuremath{\\mathrm{tc}}(e ) \\ . \\end{aligned}\\ ] ] the second piece that we take from the sum in  ( [ eq::case_g ] ) can be expressed as : @xmath124 = & -\\frac{1}{2 } \\sum _ { \\{u , v\\ } \\in \\delta(s ) } cost(u , v ) \\left ( \\ensuremath{\\mathrm{tc}}(u ) + \\ensuremath{\\mathrm{tc}}(v ) - 2 \\cdot cost(u , v ) \\right )   \\left ( \\ensuremath{\\mathrm{tc}}(u ) + \\ensuremath{\\mathrm{tc}}(v ) \\right ) \\nonumber \\\\[.2em ] = & -\\frac{1}{2 } \\sum _ { \\{u , v\\ } \\in \\delta(s ) } cost(u , v ) \\big ( \\ensuremath{\\mathrm{tc}}^2(u ) + \\ensuremath{\\mathrm{tc}}^2(u ) + 2 \\cdot \\ensuremath{\\mathrm{tc}}(u ) \\cdot \\ensuremath{\\mathrm{tc}}(v ) \\nonumber \\\\ & -2\\cdot cost(u , v ) \\cdot \\big(\\ensuremath{\\mathrm{tc}}(u ) + \\ensuremath{\\mathrm{tc}}(v)\\big ) \\big ) \\nonumber \\\\[.2em ] = & -\\frac{1}{2 } \\sum_{u \\in s } \\ensuremath{\\mathrm{tc}}^3(u ) -   \\sum _ { \\{v , x\\ } \\in \\delta(s ) } cost(v , x ) \\cdot \\ensuremath{\\mathrm{tc}}(v ) \\cdot \\ensuremath{\\mathrm{tc}}(x ) \\nonumber \\\\ & + \\sum _ { \\{y , z\\ } \\in \\delta(s ) } cost^2(y , z ) \\big ( \\ensuremath{\\mathrm{tc}}(y ) + \\ensuremath{\\mathrm{tc}}(z ) \\big ) \\nonumber \\\\[.2em ] = & -\\frac{1}{2 } \\sum_{u \\in s } \\ensuremath{\\mathrm{tc}}^3(u ) - \\sum _ { e \\in e } w_e \\cdot \\ensuremath{\\mathrm{mult}}(e ) + \\sum _ { u \\in s } \\ensuremath{\\mathrm{sq}}(u ) \\cdot \\ensuremath{\\mathrm{tc}}(u ) \\ . \\label{eq::case_g_2}\\end{aligned}\\ ] ] the next piece that we select from  ( [ eq::case_g ] ) is equal to : @xmath125 = & -\\frac{1}{2 } \\sum _ { u \\in s } \\ensuremath{\\mathrm{tc}}(u ) \\cdot \\ensuremath{\\mathrm{sm}}(u ) + \\frac{1}{2 } \\sum _ { \\{u , v\\ } \\in \\delta(s ) } cost^2(u , v ) \\left ( \\ensuremath{\\mathrm{tc}}(u ) + \\ensuremath{\\mathrm{tc}}(v ) \\right ) \\nonumber \\\\[.2em ] = & \\frac{1}{2 } \\sum _ { u \\in s }   \\ensuremath{\\mathrm{tc}}(u ) \\big(\\ensuremath{\\mathrm{sq}}(u ) -   \\ensuremath{\\mathrm{sm}}(u ) \\big )   \\ .   \\label{eq::case_g_3}\\end{aligned}\\ ] ] for the fourth piece of the sum in  ( [ eq::case_g ] ) we get : @xmath126 = & \\frac{1}{2 } \\cdot \\ensuremath{\\mathrm{trs}}(b )    =   \\frac{1}{2 } \\sum _ { u \\in s } \\ensuremath{\\mathrm{sq}}(u ) \\cdot \\ensuremath{\\mathrm{tc}}(u ) - \\ensuremath{\\mathrm{cb}}(\\mathcal{t } ) \\ . \\label{eq::case_g_4}\\end{aligned}\\ ] ] the last piece of the sum in  ( [ eq::case_g ] ) can be expressed as : @xmath127   = & \\frac{1}{2 } \\sum _ { \\{u , v\\ } \\in \\delta(s ) } cost(u , v ) \\sum_{x \\in s \\setminus \\{u , v\\ } }   \\left ( cost^2(u , x ) + cost^2(v , x ) \\right ) + 3\\cdot \\ensuremath{\\mathrm{trs}}(c ) \\nonumber \\\\[0.1 in ]   = & \\frac{1}{2 } \\sum _ { \\{u , v\\ } \\in \\delta(s ) } cost(u , v )   \\left ( \\ensuremath{\\mathrm{sq}}(u ) + \\ensuremath{\\mathrm{sq}}(v ) - 2 \\cdot cost^2(u , v ) \\right ) + 3 \\cdot \\ensuremath{\\mathrm{trs}}(c )   \\nonumber \\\\[0.1 in ]   = & \\frac{1}{2 } \\sum_{u \\in s } \\ensuremath{\\mathrm{sq}}(u ) \\cdot \\ensuremath{\\mathrm{tc}}(u ) -   \\ensuremath{\\mathrm{cb}}(\\mathcal{t } )   + 3 \\cdot \\ensuremath{\\mathrm{trs}}(c ) \\ . \\label{eq::case_g_5}\\end{aligned}\\ ] ] combining our analyses from ( [ eq::case_g ] ) up to ( [ eq::case_g_5 ] ) we get : @xmath128 & + \\frac{1}{2 } \\sum_{u \\in s}\\ensuremath{\\mathrm{tc}}(u)\\!\\cdot\\!\\big ( 5\\cdot \\ensuremath{\\mathrm{sq}}(u)\\!-\\!\\ensuremath{\\mathrm{sm}}(u)-\\!\\ensuremath{\\mathrm{tc}}^2(u ) \\big ) -2 \\cdot\\!\\ensuremath{\\mathrm{cb}}(t)+\\!3\\!\\cdot\\!\\ensuremath{\\mathrm{trs}}(c)\\,.\\end{aligned}\\ ] ] we can express @xmath129 using the values of the other isomorphism classes : @xmath130 & - \\ensuremath{\\mathrm{trs}}(a ) - 3 \\cdot \\ensuremath{\\mathrm{trs}}(b ) - 6 \\cdot\\!\\ensuremath{\\mathrm{trs}}(c ) - 6 \\cdot \\ensuremath{\\mathrm{trs}}(d ) \\\\[0.1 in ]   & - 3 \\cdot \\ensuremath{\\mathrm{trs}}(e ) -6 \\cdot \\ensuremath{\\mathrm{trs}}(f )   - 6 \\cdot \\ensuremath{\\mathrm{trs}}(g ) \\nonumber \\\\[0.1 in ] & = \\frac{1}{6 } \\cdot \\ensuremath{\\mathrm{tc}}^3(\\mathcal{t } ) -   \\frac{1}{6 } \\cdot \\ensuremath{\\mathrm{trs}}(a ) - \\frac{1}{2 } \\cdot \\ensuremath{\\mathrm{trs}}(b )   - \\ensuremath{\\mathrm{trs}}(c ) - \\ensuremath{\\mathrm{trs}}(d )   \\\\[0.1 in ] & -\\frac{1}{2 } \\cdot \\ensuremath{\\mathrm{trs}}(e )   - \\ensuremath{\\mathrm{trs}}(f ) - \\ensuremath{\\mathrm{trs}}(g ) \\ .\\end{aligned}\\ ] ] we get the value of @xmath56 $ ] by plugging into ( [ eq::le_big_sum ] ) the values that we got for all eight isomorphism classes of triples . for any isomorphism class @xmath87",
    "we showed that the value @xmath94 can be computed by using the quantities in table  [ tab::quantities ] .",
    "the lemma follows from the fact that each quantity that appears in this table is used a constant number of times for computing value @xmath94 for any class @xmath87 , and since we showed that we can precompute all these quantities in @xmath3 time in total .",
    "let @xmath1 be a phylogenetic tree that contains @xmath23 tips , and let @xmath6 be a natural number with @xmath49 .",
    "the skewness of the mean pairwise distance on @xmath1 among all subsets of exactly @xmath6 tips of @xmath1 can be computed in @xmath3 time .    according to the definition of skewness , as it is also presented in  ( [ eq::skewness_basic ] ) , we need to prove that we can compute in @xmath3 time the expectation and the variance of the @xmath0 , and the value of the expression @xmath56 $ ] . in a previous paper we showed that the expectation and the variance of the @xmath0 can be computed in @xmath3 time . by combining this with lemma  [ le::main_lemma ] we get the proof of the theorem .",
    "10 [ 1]`#1 ` cooper , n . ,",
    "rodrguez , j . ,",
    "purvis , a . : a common tendency for phylogenetic overdispersion in mammalian assemblages . in : proceedings of the royal society b : biological sciences , vol .",
    "275 , pp . 20312037"
  ],
  "abstract_text": [
    "<S> the phylogenetic mean pairwise distance ( @xmath0 ) is one of the most popular measures for computing the phylogenetic distance between a given group of species . </S>",
    "<S> more specifically , for a phylogenetic tree @xmath1 and for a set of species @xmath2 represented by a subset of the leaf nodes of @xmath1 , the @xmath0 of @xmath2 is equal to the average cost of all possible simple paths in @xmath1 that connect pairs of nodes in @xmath2 .    among other phylogenetic measures , </S>",
    "<S> the @xmath0 is used as a tool for deciding if the species of a given group @xmath2 are closely related . to do this , it is important to compute not only the value of the @xmath0 for this group but also the expectation , the variance , and the skewness of this metric . </S>",
    "<S> although efficient algorithms have been developed for computing the expectation and the variance the @xmath0 , there has been no approach so far for computing the skewness of this measure .    in the present work </S>",
    "<S> we describe how to compute the skewness of the @xmath0 on a tree @xmath1 optimally , in @xmath3 time ; here @xmath4 is the size of the tree @xmath1 . </S>",
    "<S> so far this is the first result that leads to an exact , let alone efficient , computation of the skewness for any popular phylogenetic distance measure . </S>",
    "<S> moreover , we show how we can compute in @xmath3 time several interesting quantities in @xmath1 that can be possibly used as building blocks for computing efficiently the skewness of other phylogenetic measures . </S>"
  ]
}