{
  "article_text": [
    "over the past decades , multi - electrode recordings ( taketani and baudry , 2006 ) have unveiled the nature of the activity of populations of neural cells in various systems , such as the vertebrate retina ( schnitzer and meister , 2003 ) , cortical cultures ( tang et al , 2008 ) , or the prefrontal cortex ( peyrache et al , 2009 ) .",
    "the observation of substantial correlations in the firing activities of neurons has raised fundamental issues on their functional role ( romo , hernandez , zainos and salinas , 2003 ; averbeck , latham and pouget , 2006 ) . from a structural point of view ,",
    "a challenging problem is to infer the network and the strengths of the functional interactions between the neural cells from the spiking activity ( fig .",
    "[ fig-1]a ) .",
    "powerful inference procedures are needed , capable to handle massive data sets , with millions of spikes emitted by tens or hundreds of neurons .",
    "a classical approach to infer functional neural connectivity is through the study of pairwise cross - correlations ( perkel , gerstein and moore , 1967 ; aersten and gerstein , 1985 ) .",
    "the approach was applied in a variety of neural systems , including the auditory midbrain of the grassfrog ( epping and eggermont , 1987 ) , the salamander retina ( brivanlou , warland and meister , 1998 ) , the primate and rat prefrontal cortex ( constantidinidis , franowicz and goldman - raking , 2001 ; fujisawa , amarasingham , harrison and buzsaki , 2008 ) .",
    "other approaches , capable of taking into account network - mediated effects , were proposed based on concepts issued from statistics and graph theory ( seth and edelman , 2007 ; dahlhaus , eichler and sandkhler , 1997 ; sameshima and baccal , 1999 ; jung , nam and lee , 2010 ) , information theory ( bettencourt , stephens , ham and gross , 2007 ) , or statistical physics ( schneidman , berry , segev and bialek , 2006 ; shlens et al , 2006 ) .",
    "an alternative approach is to assume a particular dynamical model for the spike generation .",
    "the generalized linear model , which represents the generation of spikes as a poisson process with a time - dependent rate is a popular framework ( brown , nguyen , frank , wilson and solo , 2001 ; truccolo et al , 2005 ; pillow et al , 2008 ) . the integrate - and - fire ( if ) model , where spikes are emitted according to the dynamics of the membrane potential is another natural candidate ( gerstner and kistler , 2002 ; jolivet , lewis and gerstner , 2004 ) .",
    "the problem of estimating the model parameters ( external current , variance of the noise , capacitance and conductance of the membrane ) of a single stochastic if neuron from the observation of a spike train has received a lot of attention ( paninski , pillow and simoncelli , 2004 ; pillow et al .",
    ", 2005 ; mullowney and iyengar , 2008 ; lansky and ditlevsen , 2008 ) .",
    "few studies have focused on the inference of interactions in an assembly of if neurons ( makarov , panetsos and de feo , 2005 ) .",
    "recently , we proposed a bayesian algorithm to infer the interactions in a network of stochastic perfect integrators when the synaptic integration is instantaneous and the noise is vanishingly small ( cocco , leibler and monasson , 2009 ) .    in the present work we introduce a bayesian algorithm to infer the couplings and the external currents in an assembly of leaky if neurons , and in presence of moderate input noise ( fig .",
    "[ fig-1]a ) .",
    "the computational time grows as the product of the number of recorded spikes , and the square of the number of neurons .",
    "we validate the algorithm on synthetic data , and apply it to real recordings of the ganglion cell activity in the salamander retina , presented with natural visual stimuli , and in the absence of stimulus ( spontaneous activity ) .",
    "in the leaky integrate - and - fire ( lif ) model , the membrane potential @xmath4 of neuron @xmath5 at time @xmath6 obeys the first - order differential equation , @xmath7 where @xmath8 and @xmath9 are , respectively , the capacitance and conductance of the membrane .",
    "the ratio @xmath10 is the membrane leaking time .",
    "@xmath11 is the synaptic current coming from the other neurons and entering the neuron @xmath5 at time @xmath6 : @xmath12 where @xmath13 is the strength of the connection from neuron @xmath14 onto neuron @xmath5 ( figure [ fig-1]a ) ; @xmath15 is the time at which neuron @xmath14 fires its @xmath16 spike .",
    "we assume that synaptic inputs are instantaneously integrated , _",
    "i.e. _ that the synaptic integration time is much smaller than all the other time scales , including @xmath17 .",
    "our method for inferring the interactions relies on this assumption , and should be modified in the presence of synaptic integration kernels with temporal filtering .",
    "@xmath18 is a constant external current flowing into neuron @xmath5 ( fig .",
    "[ fig-1]a ) , and @xmath19 is a fluctuating current , modeled as a gaussian noise process : @xmath20 , @xmath21 .",
    "the noise standard deviation , @xmath22 , has here the dimension of a current times the square root of a time .",
    "an alternative definition would consist in rescaling @xmath22 with a time dependent factor , _",
    "e.g. _ @xmath23 ; our definition allows us to reach the perfect integrator limit ( @xmath24 ) while keeping @xmath22 fixed .",
    "the neuron @xmath5 remains silent as long as @xmath25 remains below a threshold potential @xmath26 .",
    "if the threshold is crossed at some time @xmath27 , _ i.e. _ @xmath28 , then a spike is emitted , and the potential is reset to its resting value : @xmath29 .",
    "the dynamics then resumes following ( [ ode ] ) .",
    "let @xmath30 and @xmath31 denote the sets of , respectively , the interactions and currents .",
    "let @xmath32 $ ] be the time at which neuron @xmath5 emits its @xmath16 spike ; @xmath33 is the duration of the recording .",
    "how can we infer the interactions and currents from the observation of the spiking activity ?",
    "consider the raster plots in fig .",
    "[ fig-1]b . in pattern @xmath34",
    ", the timings of the spikes of neuron 1 do not seem to be correlated to the activity of neuron 2 .",
    "hence , we may guess that there is no interaction from neuron 2 to neuron 1 ( @xmath35 ) . in pattern @xmath36 ,",
    "a spike of neuron 1 is likely to follow a spike of neuron 2 , which suggests that the interaction @xmath37 is positive .",
    "conversely , in pattern @xmath38 , it seems that the firing of neuron 2 hinders the firing of neuron 1 , which indicates that @xmath37 has a negative value .",
    "this crude reasoning can be made mathematically rigorous in the framework of statistical inference ( cover and thomas , 2006 ) .",
    "let us define the likelihood @xmath39 of a set of spiking times , @xmath40 , given @xmath41 and @xmath42 . according to bayes rule the most likely couplings and currents , @xmath43 and @xmath44 , given the set of spiking times @xmath45 can be inferred through the maximization of @xmath39 .",
    "due to the statistical independence of the noises @xmath46 from neuron to neuron , the likelihood @xmath47 of @xmath48 given @xmath49 can be written as the product of first - passage time ( fpt ) probabilities , @xmath50 here @xmath51 denotes the probability that @xmath25 crosses @xmath26 for the first time at time @xmath52 , starting from @xmath53 at time @xmath54 and conditioned to the inputs from the other neurons at times @xmath55 , with @xmath56 . as the synaptic integration is instantaneous , an incoming spike from neuron @xmath14 results in a ( positive or negative ) jump of the potential @xmath25 by @xmath57 ; @xmath51 can therefore be interpreted as the fpt density probability for a one - dimensional ornstein - uhlenbeck process with a time - dependent force .",
    "it is important to stress that the presence of the products over the spike intervals in ( [ prodfpt ] ) does not entail that the spiking times are independent .",
    "consider now the potential @xmath4 during the inter - spike interval ( isi ) @xmath58 $ ] .",
    "the boundary conditions are @xmath59 ( reset of the potential right after a spike ) , and @xmath60 ( condition for firing ) . at intermediate times",
    ", the potential can take any value smaller than @xmath26 .",
    "the logarithm of the probability of a dynamical path ( time course ) of the potential over the @xmath16 isi of neuron @xmath5 is , after multiplication by the variance @xmath61 of the noise , @xmath62&= & -\\frac 1{2 } \\int _ { t_{i , k}}^{t_{i , k+1 } } dt\\ \\eta_i(t)^2 \\\\&= & -\\frac 1{2 } \\int _ { t_{i , k}}^{t_{i , k+1 } } dt\\ \\left [ c\\,\\frac{d v_i}{dt}(t ) + g\\ , v_i(t ) -i_i^{syn } ( t)-i_i\\right]^2 \\ , \\nonumber\\end{aligned}\\ ] ] according to the gaussian nature of the noise @xmath19 and to the dynamical equation of the lif ( [ ode ] ) .",
    "while no exact expression is known for @xmath51 , it can be analytically approximated by the contribution of the most probable dynamical path for the potential , @xmath63 ( paninski , 2006 ) .",
    "this approximation becomes exact when the standard deviation @xmath22 of the noise is small .",
    "the idea is to replace the distribution of paths for the potential @xmath4 with a single , most likely path @xmath63 , which we call optimal .",
    "we now explain how to derive @xmath64 through the condition that the log  probability @xmath65 ( [ pathint2 ] ) is maximal .",
    "let us assume first that @xmath66 .",
    "then , the derivative of @xmath65 in ( [ pathint2 ] ) with respect to @xmath64 must vanish , which gives @xmath67 we now turn this second order differential equation for the optimal potential into a first order differential equation at the price of introducing a new function , @xmath68 , and a new first order differential equation for this function .",
    "it is straightforward to check that the solution of @xmath69 is a solution of the optimization equation ( [ optima ] ) if @xmath70 fulfills @xmath71 where @xmath17 is the membrane leaking time .",
    "the similarity between eqns ( [ ode ] ) and ( [ optimb ] ) allows us to interpret @xmath72 as a current noise .",
    "however , this noise is no longer stochastic , but rather it follows the deterministic path solution of ( [ 2.8 ] ) .",
    "we will , therefore , in the following refer to @xmath70 as the optimal noise .",
    "@xmath70 corresponds to the most likely value the noise takes given the set of spiking times . solving ( [ 2.8 ] )",
    "shows that the optimal noise is an exponential function of the time : @xmath73 where @xmath74 is a constant , which we call noise coefficient .",
    "it may happen that the optimal potential only reaches the threshold without actually crossing it at intermediate times .",
    "when this is the case , the optimal potential equals @xmath75 and its derivative with respect to the time vanishes .",
    "the expression for the optimal noise can be then read from ( [ optimb ] ) , and is given by @xmath76 equation ( [ eq2 ] ) ensures that the potential does not cross the threshold value at a time @xmath77 .    despite their apparent simplicity , eqns ( [ optimb],[eq1],[eq2 ] )",
    "are not easy to solve , due mainly to the interplay between the two regimes , @xmath78 and @xmath79 , mentioned above . the determination of @xmath64 was achieved numerically by paninski for a single neuron ( paninski , 2006 ) .",
    "we now sketch the procedure to determine @xmath64 rapidly , even for tens of neurons .",
    "the procedure relies on the search for contacts , that is , times at which the optimal potential touches the threshold .",
    "there are two types of contacts : contacts coinciding with a synaptic input ( the potential touches the threshold at time @xmath15 ) , and contacts arising in between two inputs . in the absence of leakage ,",
    "only the former type of contacts matter , and a search procedure to locate those isolated - time contacts was proposed by cocco , leibler and monasson ( 2009 ) . in the presence of leakage ,",
    "both types of contacts have to be taken into account .",
    "the search procedure is more complex , and is explained below .",
    "[ fig - fluctuphi ] [ fig - compar - optpath ] [ fig - scheme ]    we assume in this section that the couplings and currents are known . consider neuron @xmath5 at time @xmath80 $ ] , where @xmath81 is the index of the isi .",
    "the initial and final conditions for the optimal potential are : @xmath82 and @xmath83 . in between",
    ", @xmath84 obeys the lif evolution equation ( [ optimb ] ) with an optimal ` noise ' @xmath68 .",
    "@xmath70 can be interpreted as a non - stochastic , external , time - dependent current to be fed into the neuron in order to drive its potential from 0 to @xmath26 , given the synaptic couplings .",
    "the expressions for the optimal ` noise ' are given by ( [ eq1 ] ) when @xmath85 , and ( [ eq2 ] ) when the optimal potential @xmath64 is equal to the threshold value .",
    "when @xmath64 reaches the threshold at a time coinciding with an incoming spike , the coefficient @xmath74 in ( [ eq1 ] ) may abruptly change through an _ active contact _ ; the notion of active contact is illustrated in the simple case of a neuron receiving a single spike in appendix [ illustration ] .",
    "the potential @xmath64 may also touch the threshold without crossing it , and the noise may remain constant over some time interval ; we call such an event _ passive contact_. that the potential can brush , or remain at the threshold level without producing a spike is made possible by the @xmath86 limit .",
    "we will discuss later on the validity of this calculation , and how to modify it when the noise standard deviation , @xmath22 , does not vanish .",
    "both types of contacts are shown in fig .",
    "[ fig - scheme]a .",
    "let us explain how the positions of active and passive contacts can be determined .",
    "let @xmath87 be the emission times of the spikes arriving from the neurons interacting with @xmath5 during the time interval @xmath88 $ ] , and @xmath89 the corresponding synaptic strengths and @xmath90 can apparently arrive at the same time ; if so , we consider , based on model ( [ ode ] ) and ( [ defisyn ] ) , that a single input of amplitude @xmath91 enters the neuron . ] .",
    "let @xmath92 be the initial value of the potential , and @xmath93 be the index of the first input spike .",
    "if the time is small enough the optimal potential is surely below the threshold value . according to ( [ eq1 ] )",
    "the optimal noise is an exponential with noise coefficient @xmath74 , and the optimal potential is obtained by solving ( [ optimb ] ) with the result , @xmath94 where @xmath95 is the heaviside function .",
    "it is tempting to look for the value of @xmath74 such that a spike is emitted at time @xmath96 , defined by the implicit equation @xmath97 .",
    "however , the corresponding potential might not be below threshold at all intermediate times @xmath98 .",
    "instead , we look for the smallest noise capable of driving the potential from its initial value @xmath99 into contact with the threshold : @xmath100 as the potential ( [ defv ] ) is a monotonically increasing function of @xmath74 , a value of the noise smaller than @xmath101 would not be able to bring the potential to the threshold and to trigger a spike at any time , while a value larger than @xmath101 would violate the condition that the potential can not cross the threshold on the time interval @xmath98 , see appendices [ seccp - sec ] and [ seccp2 ] .",
    "we denote by @xmath102 the time at which the threshold is reached : @xmath103 . the solution to the minimization problem ( [ defnoise ] )",
    "can be found following the procedure described below . briefly speaking , the procedure identifies candidates for the contact points , selects the best one , and is iterated until the isi is completed .    *",
    "_ active candidates : _ we first consider the possibility that the contact time @xmath104 coincides with a synaptic input .",
    "we therefore calculate for each @xmath105 , the root @xmath106 of the implicit equation @xmath107 .",
    "the smallest of those @xmath108 noise coefficients is called @xmath109 . * _ passive candidates : _ we then consider the case where the contact time @xmath104 may not be simultaneous to any input , but rather fall between two successive spikes . for each @xmath110 , we look for a noise coefficient @xmath111 and a contact time @xmath112 $ ] fulfilling the set of coupled equations @xmath113 , expressing that the potential reaches and does not cross the threshold .",
    "these two equations can be solved analytically , see expressions ( [ etap ] ) and ( [ etap2 ] ) in appendix [ secgnon ] .",
    "we call @xmath114 the smallest noise coefficient corresponding to those possible passive contacts . *",
    "_ selection of the best candidate : _ if @xmath115 , the contact is active and takes place at time @xmath116 for a certain @xmath117 comprised between @xmath118 and @xmath119 ( fig .",
    "[ fig - scheme]a ) . the optimal potential and noise in the time interval @xmath120 $ ]",
    "are given by , respectively , eqns ( [ defv ] ) and ( [ eq1 ] ) with @xmath121 . if @xmath122 , the contact is passive , and takes place in the time interval @xmath123 $ ] for a certain @xmath124 comprised between @xmath118 and @xmath119 .",
    "the potential will remain equal the threshold , and the noise will remain constant according to ( [ eq2 ] ) over a finite time interval @xmath125 $ ] , after which both @xmath64 and @xmath70 resume their course ( fig .",
    "[ fig - scheme]a ) .",
    "@xmath126 is the smallest delay allowing the potential to be in active contact with the threshold at a later time @xmath127 , with @xmath128 .",
    "the correctness of this statement is ensured by the fact that there can be at most one passive contact between two active contacts ( appendix [ secgnon ] ) ; hence , a passive contact is necessarily followed by an active contact ( or by the spike at the end of the isi ) . for every integer @xmath129 comprised between @xmath130 and @xmath119 , we calculate analytically the delay @xmath131 such that the potential reaches the threshold in @xmath132 , see eqn ( [ eqdeltac ] ) in appendix [ secgnon ] ; the smallest among those delays and the corresponding value of @xmath129 are , respectively , @xmath133 and @xmath117 . * _ iteration : _ we are left with the calculation of @xmath70 and @xmath64 on the remaining part of the inter - spike interval , @xmath134 $ ] .",
    "to do so , we iterate the previous steps .",
    "we first update @xmath135 , @xmath136 , @xmath137 in ( [ defv ] ) , and look for the lowest noise producing a new contact over the interval @xmath138 $ ] using ( [ defnoise ] ) again . the procedure is repeated until the whole inter - spike time interval is exhausted .    as a result a sequence of values for @xmath101 is built , each value corresponding to the noise coefficient ( [ defnoise ] ) between two successive active contact points .      the lif dynamical equation ( [ ode ] ) involves quantities , such as the membrane potential , the membrane conductance , the input current , which have different physical units .",
    "a straightforward algebra shows that ( [ ode ] ) is equivalent to the following differential equation , @xmath139 which involves only dimensionless variables ( denoted with overbars ) : @xmath140 the noise has zero mean , and covariance @xmath141 , where @xmath142 intuitively , we expect that the potential @xmath4 will not depart much from the optimal path @xmath64 , and , hence , that our inference algorithm will be accurate if the dimensionless standard deviation of the noise , @xmath143 , is small .",
    "we illustrate this claim on the simple case of a neuron receiving a few inputs from two other neurons during two inter - spike intervals ( isi ) of length @xmath144 , see fig .",
    "[ fig - compar - optpath]b .",
    "the times of the input spikes were randomly chosen , once for all , before the simulations started .",
    "then , we numerically integrated the lif equation for the potential ( [ ode ] ) for @xmath145 random realizations of the noise @xmath146 .",
    "the realizations such that the neuron spiked twice , with isis falling in the range @xmath147\\times \\tau$ ] were considered as successful .",
    "the number of successful realizations was comprised between @xmath148 and @xmath149 , depending on the noise level , @xmath22 .",
    "we show in fig .",
    "[ fig - compar - optpath]b the paths of the potential and of the noise , averaged over successful realizations , and compare them to the optimal potential , @xmath150 , and noise , @xmath151 .",
    "as expected the agreement is very good for small @xmath22 .",
    "we now make this observation quantitative .",
    "consider the @xmath16 inter - spike interval @xmath58 $ ] of neuron @xmath5 .",
    "the optimal potential @xmath64 is the time - course followed by the lif membrane potential @xmath4 in the @xmath152 limit . when the noise variance is not vanishing",
    ", the potential @xmath4 can slightly deviate from the optimal path ( fig .",
    "[ fig - fluctuphi]c ) .",
    "deviations are null at the extremities of the inter - spike interval due to the boundary constraints on the potential . a measure of the magnitude of the fluctuations of the potential is thus given by the variance of @xmath153 at the middle of the isi , _ i.e. _ @xmath154 ( fig .",
    "[ fig - fluctuphi]c ) .",
    "this variance can be calculated when the constraint that the fluctuating potential @xmath155 does not cross the threshold at times @xmath156 is relaxed , see appendix [ app - corrections ] .",
    "we obtain @xmath157 where @xmath17 is the membrane leaking time . as expected , if @xmath158 is small , so are the fluctuations of the potential around the optimal path .    however , the reverse statement is false .",
    "consider , for instance , the case of a perfect integrator , for which the dimensionless @xmath158 ( [ defnounit ] ) is virtually infinite . sending @xmath159 in ( [ result - fluctu ] )",
    ", we obtain @xmath160 hence , the relative fluctuations of the potential are small if the typical amplitude of the electrical charge entering the neuron during the isi due to the noise , @xmath161 , is small compared to the total charge @xmath162 necessary to reach the threshold from the rest state .",
    "it is interesting to note that this statement applies to the lif , too .",
    "whatever the level of the noise , @xmath143 , the relative fluctuations of the potential ( [ result - fluctu ] ) can be made small if the duration of the isi is short enough compared to the membrane leaking time , @xmath17 .      for large values of @xmath22 ,",
    "a discrepancy between the optimal potential and the potential obtained in simulations appears ( fig .",
    "[ fig - pro]b ) .",
    "a general observation is that the optimal potential calculated by the fixed threshold procedure can get very close to @xmath26 , while the true potential stays further away from the threshold to avoid premature firing . to further illustrate this effect ,",
    "consider a system of two if neurons , 1 and 2 , both fed with an external current .",
    "in addition , neuron 1 receives positive inputs from neuron 2 ( @xmath163 ) , and neuron 2 is independent from the activity of neuron 1 ( @xmath164 ) . in presence of a strong noise",
    ", the optimal potential calculated from the fixed threshold procedure quickly reaches a stationary value close to @xmath26 , while the random potential obtained from simulations fluctuates around a much lower level ( fig .",
    "[ fig - pro]e ) .",
    "the presence of a strong noise biases the membrane potential to lower values to prevent early spiking . a heuristic approach to reproduce this bias",
    "consists in decreasing the threshold from @xmath26 to a time- and context - dependent value , @xmath165 .",
    "we now explain how this moving threshold , @xmath165 , is determined .",
    "consider first a neuron with no synaptic input , fed with an external current @xmath166 , during the inter - spike interval @xmath58 $ ] .",
    "we call @xmath167 the probability that the potential , taking value @xmath168 at time @xmath169 , remains below the threshold at any larger time @xmath6 , with @xmath170 .",
    "this probability depends on the current @xmath166 , and can be expressed for an arbitrary level of noise , @xmath22 , as a series of parabolic cylinder functions ( alili , patie and pedersen , 2005 ) .",
    "figure [ fig - pro]d show @xmath171 as a function of @xmath168 for some characteristic values of the parameters .",
    "the probability of survival , @xmath171 , sharply decreases to zero when @xmath168 gets close to the threshold , @xmath172 .",
    "we model this outcome by the following approximation , which involves a new , effective threshold @xmath165 : we consider that the processes starting from a value of the potential @xmath173 will not survive for a time delay @xmath174 . in other words , the true threshold , @xmath26 , is changed into a moving threshold , which is a function of the current @xmath166 , the time @xmath174 , and the parameters @xmath175 . a simple way to define @xmath165 is to look at the intersection of the tangent line to @xmath171 in @xmath172 with , say , the @xmath176 line to @xmath177 have been tried , do not qualitatively affect the results presented later in this article . ] ; the resulting expression for @xmath165 is given in appendix [ essai2 ] .",
    "figure [ fig - pro]e shows the output of the moving threshold procedure on the simple 2-neuron system described above .",
    "the optimal potential , pushed down by the moving threshold @xmath165 is much lower than in the fixed threshold approach and in much better agreement with the random realization of the membrane potential . more details are given in section [ secsubmt ] .    to account for the existence of synaptic inputs",
    ", we may choose the parameter @xmath166 entering the calculation of @xmath171 and @xmath178 to be the value of the effective current @xmath179 , rather than the external current @xmath18 itself .",
    "here , @xmath180 is the average firing rate , defined as the number of spikes fired by neuron @xmath14 divided by the duration @xmath33 .",
    "contrary to the external current @xmath18 , the effective current @xmath181 takes into account the ( average ) input current coming from other neurons .",
    "this choice was done in the numerical experiments reported in the results section . to further speed up the calculations",
    ", we derive the value of @xmath165 for discrete - values delays @xmath174 only ; in a discrete interval , @xmath165 is kept to a constant value .",
    "alternative heuristic approaches to deal with the presence of moderate noise can be proposed . in appendix [ essai2 ]",
    "we introduce a cost - function for the effective current , whose effect is also to decrease the optimal potential .",
    "these approaches are effective when the optimal potential calculated by the fixed threshold procedure quickly saturates to a level close to @xmath26 . more precisely , we expect the moving threshold procedure to be efficient if the membrane leaking time is smaller or comparable to the isi , and the leaking current , @xmath182 , is larger or equal to the external current , @xmath166 .",
    "the fixed or moving threshold procedures allow us to calculate the optimal paths for the potential and the noise , given the couplings and currents .",
    "knowledge of those paths gives us also access to the logarithm of the likelihood @xmath47 in the @xmath152 limit , @xmath183 = -\\frac 12 \\sum _ { i ,",
    "k } \\int _ { t_{i , k } } ^{t_{i , k+1 } } dt \\ , \\eta_i^*(t)^2\\end{aligned}\\ ] ] since @xmath184 in ( [ deflpcc ] ) involves the sum over different neurons , the maximization over the couplings @xmath13 and the current @xmath18 of neuron @xmath5 can be done independently of the other couplings @xmath185 and currents @xmath186 ( @xmath187 ) .",
    "formally , we are left with @xmath1 independent inferences of the most likely couplings and current for a single neuron , in presence of the spikes emitted by the @xmath188 other neurons . as a consequence neurons ` decouple ' in the inverse problem : the couplings @xmath13 and the current @xmath18 of neuron @xmath5 can be inferred independently of the other couplings @xmath185 and currents @xmath186 ( @xmath187 ) .",
    "@xmath65 defined in ( [ pathint2 ] ) is a negative - semidefinite quadratic function of its arguments @xmath189 .",
    "it is thus a concave function of the couplings and the currents .",
    "this property holds for @xmath184 ( [ deflpcc ] ) ( boyd and vandenberghe , 2004 ) . in order to infer the most likely current @xmath18 and couplings @xmath13 , we start from an arbitrary initial value _ e.g. _ @xmath190 .",
    "the full path of the optimal noise , @xmath68 , over all the inter - spike intervals @xmath81 of neuron @xmath5 , is calculated following the above procedure .",
    "we then update the couplings and the current using the newton - raphson method to maximize @xmath191 , _",
    "i.e. _ to minimize the integral of the squared optimal noise , see ( [ deflpcc ] ) .",
    "convergence follows from the concavity property stated above .",
    "the procedure requires the expressions for the gradient and the hessian matrix of @xmath191 with respect to the couplings @xmath13 and the current @xmath18 , which can be calculated exactly from ( [ deflpcc ] ) and ( [ defv ] ) .",
    "note that @xmath191 is piecewise continuously twice - differentiable ; while the gradient is continuous for all @xmath13 and @xmath18 , the hessian matrix is bounded and negative , and may discontinuously jump due to a change of the contact points .",
    "knowledge of the hessian matrix is also important to determine how reliable are the values of the inferred parameters .",
    "when the variance of the noise , @xmath192 , vanishes the inferred parameters can not deviate from their most likely values .",
    "however , for small but non zero @xmath22 , deviations are possible .",
    "the reason is that the corrections to the log - likelihood @xmath184 , to the lowest order in the noise variance @xmath61 , do not depend on the current and interactions ( appendix [ app - corrections ] ) . ] .",
    "the probability for such deviations can be estimated from the expansion of @xmath184 around its maximum .",
    "we introduce for each neuron @xmath5 , the @xmath1-dimensional vector @xmath193 whose components are : @xmath194 , and @xmath195 for @xmath196 .",
    "the multiplication of the current by the membrane leaking time ensures that all components can be expressed in units of a coupling .",
    "similarly we call @xmath197 the vector obtained when the current and couplings take their most likely values , that is , maximize @xmath184 .",
    "let us call @xmath198 the hessian matrix of @xmath184 .",
    "the parameters @xmath199 are normally distributed around their most likely values , with a covariance matrix given by @xmath200 ^{-1}_{j , j ' } \\ .\\ ] ] in particular , the error bars on the inferred parameters are given by the diagonal elements of the inverse of @xmath201 .",
    "note that , if the value of @xmath22 is not known , formulas ( [ fluch ] ) and ( [ flucov ] ) can still be used to compare the error bars between each other .",
    "as the entries of @xmath201 scale linearly with the duration @xmath33 of the recording , or , more precisely , the number @xmath0 of recorded spikes the uncertainty on the inferred parameters will decrease as @xmath202 .",
    "a detailed spectral analysis of @xmath203 in the case of weak couplings , reported in appendix [ aeigen ] , shows that the largest eigenvalue , @xmath204 , is related to the fluctuations of the effective current , @xmath205 where @xmath206 is the average firing rate of neuron @xmath14 , calculated over the time scale @xmath207 preceding a spike of neuron @xmath5 .",
    "the smallest eigenvalue , @xmath208 , corresponds to the fluctuations of the current @xmath18 alone . in other words ,",
    "the uncertainty on the inferred value for @xmath181 is much smaller than the one on the current @xmath18 .",
    "the intermediate eigenmodes describe correlated fluctuations of the couplings .",
    "explicit expressions for the largest and smallest eigenvalues , @xmath209 and @xmath208 , are derived in appendix  [ aeigen ] .",
    "when a small change of @xmath41 and @xmath210 causes a modification of the set of contact points the second derivative of @xmath184 may be discontinuous .",
    "a simple illustration is provided by the the case of a single input , whose log - likelihood @xmath184 is reported in appendix [ illustration ] .",
    "if the maximum is located at , or very close to the boundary dividing two or more sets of contacts , the value of the hessian matrix will depend on the direction along which the maximum @xmath211 is approached .",
    "this phenomenon is also encountered in the analysis of real data , see section [ sec - inf - neg ] .",
    "in this section , we test our inference procedure on synthetic data generated from networks with known interactions and currents . we compare the results obtained from our two inference algorithms , the fixed and moving threshold procedures , respectively defined in sections [ sec - algo ] and [ sec - beyond ] .",
    ".5 cm    [ fig - error ]    we first consider @xmath1 ( ranging from 20 to 160 ) neurons , with no leakage ( @xmath212 ) .",
    "the neurons are uncoupled ( @xmath213 for @xmath214 ) , and fed with identical currents ( @xmath215 for all @xmath5 ) .",
    "the choice of the noise variance , @xmath61 , is specified later .",
    "the lif equation is solved numerically , using a fourth - order runge - kutta integration scheme .",
    "we choose the elementary time step to be @xmath216 sec , while the average duration of the isi is @xmath148 to @xmath217 longer . for each realization of the noise , the simulation is run until a set of @xmath218 spikes is generated .",
    "we then use the first @xmath0 spikes in this set to infer the currents and the couplings ( not fixed to zero _ a priori _ ) with the fixed threshold procedure .",
    "the algorithm stops if the log - likelihood @xmath184 increases by less than @xmath219 after an iteration of the newton - raphson procedure .",
    "alternatively , the algorithm may halt when the overall change in the couplings and current becomes smaller than a certain _ a priori _ bound .",
    "figures [ fig - time]a&b show how the running time scales with , respectively , the number @xmath0 of spikes , and the number @xmath1 of neurons . the empirically found scaling , @xmath220 , can be understood as follows .",
    "consider one neuron , say , @xmath5 .",
    "the number of spikes of neuron @xmath5 is , on average , equal to @xmath221 , where @xmath33 is the duration of the recording and @xmath222 is the average firing rate .",
    "the number of contact points , @xmath223 , is found to scale as the number of spikes , @xmath224 .",
    "the calculation of the contribution to the hessian @xmath225 coming from the interval between two successive contact points of @xmath226 takes @xmath227 time .",
    "the total calculation of @xmath225 thus requires @xmath228 operations over the time required for the inversion of the hessian matrix is equal to @xmath229 , and is generally much larger than one .",
    "the reason is that the number of parameters to be inferred , @xmath1 , has to be smaller than the number of constraints over the optimal potential , @xmath223 . for the real data analyzed in section [ sec - real ]",
    ", we have @xmath230 and @xmath231 for , respectively , dark and natural movie data sets . ] . the loop over the neuron index , @xmath5 ,",
    "gives an extra ( multiplicative ) factor @xmath1 .",
    "the running time of the moving threshold algorithm grows as @xmath232 , too .",
    "however the proportionality constant is generally higher than for the fixed threshold procedure , due to the extra computational burden to calculate @xmath165 . for fixed",
    "@xmath1 and @xmath0 , the running times of both procedures increase with the number of contacts , _",
    "e.g. _ when the membrane conductance @xmath9 increases .",
    "this effect is described in section [ sec - real ] .",
    "we define the inference errors as the root mean square of the difference between the inferred parameters , @xmath233 and the true values , @xmath234 : @xmath235 together with a similar definition for the effective current , @xmath236 , with @xmath237 replaced with the inferred value for @xmath238 .",
    "the inference errors depend on the dimensionless noise ratio , changing the value of the current @xmath166 amounts to changing the time - scale of the evolution of the potential in ( [ ode ] ) .",
    "hence , the errors @xmath239 depend on the parameters @xmath240 through the value of @xmath241 only ( as long as @xmath242 ) .",
    "] , @xmath243 figure [ fig - error]c shows the inference errors found for different noise ratios @xmath241 , and their dependence on the number @xmath0 of spikes , in the absence of membrane leakage . for small data sets ,",
    "the inference error is mainly due to the imperfect sampling .",
    "as the number @xmath0 of spikes increases , @xmath244 decreases as @xmath202 , as expected from section [ sec - accuracy ] .",
    "when @xmath0 is very large , the errors saturate to a residual value , @xmath245 . the presence of the residual error @xmath246 results from the dominant - path approximation done in our calculation of the likelihood @xmath47 .",
    "the value of @xmath245 decreases with @xmath241 as expected .",
    "the cross - over between the sampling - dominated and residual error regimes takes place for a certain value of the number of spikes , @xmath247 . both @xmath247 and @xmath245",
    "depend on the observable , _ i.e. _ @xmath248 , and on the noise ratio @xmath241 . with the values of @xmath0",
    "reached in the simulations , the onset of the cross - over is clearly visible for @xmath249 , can be guessed for @xmath166 , and is not observable for @xmath250 .",
    "the existence of a cross - over , and an estimate of @xmath247 can be derived from the discussion of section [ sec - accuracy ] .",
    "when @xmath0 is large , the _ a posteriori _ distribution of the inferred parameter , @xmath251 or @xmath250 , becomes gaussian , with a variance @xmath252 where @xmath253 is the eigenvalue of the hessian matrix of @xmath184 attached to the fluctuations of the parameter @xmath254 .",
    "the inference error sums up contributions coming from both the sampling fluctuations and the residual error .",
    "the cross - over takes place when both contributions are comparable , @xmath255 , that is , for @xmath256 figure  [ fig - error]c confirms that @xmath247 diminishes with @xmath22 ( or @xmath241 ) , and is much smaller for @xmath249 than for @xmath166 ( as expected from the dependence on the eigenvalue @xmath253 ) ; moreover , the residual error on the couplings is extremely small ( or might be even zero ) .",
    "as a conclusion , our inference algorithm is very accurate in the absence of membrane leakage . with @xmath148 spikes per neuron only and @xmath257 , for instance , the errors on the currents and on the couplings are , respectively , @xmath258 and @xmath259 . even in the presence of strong noise ( @xmath260 ) , and with the same number of spikes per neuron , the errors on the effective currents and on the couplings are less than 1% .",
    ".3 cm    [ fig - error - inf - true ] [ fig - coupled ] [ fig - mb0 ] [ fig - mb ] [ fig - negpos ]    we now study the ability of the algorithm to infer the interactions between coupled neurons .",
    "to do so , we consider random connection graphs built in the following way ( bollobas , 2001 ) .",
    "we start from a complete oriented graph over @xmath1 neurons , and erase each one of the @xmath261 link with probability @xmath262 , independently of each other .",
    "the removal process is not symmetric : the link @xmath263 may be removed , while the connection @xmath264 is preserved . at the end of the construction process , the average number of outgoing ( or incoming ) neighbors of a neuron is @xmath265 .",
    "each existing connection is then assigned a synaptic weight , uniformly at random over the interval @xmath266 $ ] .",
    "all neurons receive the same external current @xmath166 .",
    "in addition , the membrane conductance , @xmath9 , is now different from zero .",
    "the values of @xmath267 , and @xmath22 are chosen so that the network remains below saturation .",
    "we have also performed simulations where the interaction graph is drawn as above , but each neuron @xmath5 is chosen to be either excitatory or inhibitory with equal probabilities .",
    "the outgoing interactions from @xmath5 have all the same sign , and random amplitudes in @xmath268 $ ] .",
    "the performance of our inference algorithms are qualitatively similar for both models .",
    "figure [ fig - errorvsp]a shows the error on the couplings inferred with the fixed threshold algorithm , @xmath269 , as a function of the fraction @xmath270 of connections , for three values of the membrane conductance over current ratio .",
    "the error roughly increases as @xmath271 , that is , the number of connections in the network .",
    "this scaling suggests that much of the inference error is due to non - zero couplings .",
    "this finding agrees with fig .",
    "[ fig - error]c , which showed that the inferred interactions between uncoupled neurons was very small in the @xmath212 case . to better understand the performance of the algorithm",
    ", we compare in fig .",
    "[ fig - error - inf - true]c the inferred interactions @xmath13 with their true values for the 1560 oriented pairs @xmath264 of a randomly drawn network of @xmath272 neurons , with @xmath273 and @xmath274 .",
    "when the ratio @xmath275 is small compared to unity , the quality of the inference is very good ( fig .",
    "[ fig - error - inf - true]c-1 ) . for larger ratios @xmath275",
    "the inferred couplings are still strongly correlated with their true values , but are approximately rescaled by an overall factor @xmath276 , corresponding to the average slope of the linear regression in fig .",
    "[ fig - error - inf - true]c-2 .",
    "as @xmath275 increases , this factor decreases and the inference error grows ( fig .  [ fig - errorvsp]a ) .",
    "figure  [ fig - coupled]b shows that the inference error on the interactions increases not only with @xmath275 but also with the noise ratio @xmath241 . for large values of @xmath241 ,",
    "the network can sustain activity even when @xmath277 , and the inference error can take large values ( upper curve in fig .",
    "[ fig - coupled]b ) . in this regime , the couplings found by the fixed threshold algorithm become small , and the inferred current @xmath18 gets close to @xmath278 .",
    "the corresponding potential @xmath84 rises sharply , in a time @xmath17 , to a value slightly below threshold , @xmath279 , with small fluctuations due to the synaptic inputs .",
    "this phenomenon can be seen in fig .",
    "[ fig - mb0]d , which compares the optimal potential of a neuron for two different values of membrane conductance . as discussed in the methods section ,",
    "this behavior is a consequence of the @xmath86 limit taken in the calculation of the optimal potential ; when @xmath22 , or @xmath241 , is not small , the potential is unlikely to stay close to the threshold for a long time without producing a spike , see fig .",
    "[ fig - compar - optpath]b . in the next paragraph",
    ", we analyze the results of the moving threshold inference procedure .    as a conclusion ,",
    "zero couplings are perfectly inferred , while the amplitude of large ( positive or negative ) interactions can be underestimated by the fixed threshold algorithm , especially so when the noise is strong .",
    "however , the relative ordering of the interactions is essentially preserved by the inference procedure .",
    "the moving threshold procedure was tested in fig .",
    "[ fig - pro]e on an asymmetric system of two if neurons ( @xmath280 ) in the presence of a strong noise , see description in caption and section [ sec - beyond ] .",
    "while the fixed threshold procedure erroneously inferred that both interactions vanish , the moving threshold correctly inferred the sign and the order of the magnitude of the coupling : @xmath281 .",
    "the inferred currents were within 10% of their true values .",
    "these results were obtained from a large number @xmath0 of spikes to avoid finite-@xmath0 effects .",
    "the synthetic data used in fig .",
    "[ fig - coupled]b were generated with two different values of the noise ratio , @xmath241 .",
    "we estimate the relative fluctuations of the potential around the optimal path , averaged over all the inter - spike intervals in the data set , using formula ( [ result - fluctu ] ) , and find @xmath282 for all values of @xmath275 comprised between .9 and 1.25 .",
    "hence , the relative fluctuations can not be neglected when @xmath283 .",
    "figure [ fig - coupled]b shows the inference error obtained from the moving threshold algorithm as a function of the membrane conductance for that value of the noise ratio . not surprisingly , the moving threshold procedure is more accurate than the fixed threshold algorithm .    in the moving threshold algorithm , the optimal potential is constrained to remain below a certain threshold , @xmath178 , which depends on the time preceding the next spike and on the effective current @xmath181 .",
    "figure [ fig - mb]e shows the values of the moving threshold @xmath178 and of the optimal potential @xmath284 for a few spike intervals of the same neuron as in fig .  [ fig - mb0]d .",
    "as expected , the value of @xmath84 lies substantially further away from the threshold @xmath26 than in the fixed threshold procedure .",
    "in addition , fig .",
    "[ fig - mb]e shows a random realization of the potential @xmath4 , obtained through numerical integration of the lif differential equation ( [ ode ] ) , for the same neuron @xmath5 .",
    "although @xmath25 is stochastic , the comparison of several inter - spike intervals indicates that @xmath84 and @xmath4 are in fair statistical agreement .",
    "to investigate in more details the origin of the inference error on the couplings for large values of @xmath241 and @xmath275 , we plot in fig .",
    "[ fig - negpos]c the inferred values of the interaction @xmath13 vs. the true value for every pairs @xmath264 of a randomly drawn network of @xmath272 neurons .",
    "the interactions inferred by the fixed threshold algorithm are about ten times smaller than their true values ( fig .",
    "[ fig - negpos]c-3 ) .",
    "the use of the moving threshold procedure leads to a spectacular improvement for positive - valued couplings ( fig .",
    "[ fig - negpos]c-4 ) .",
    "while positive couplings are accurately inferred , the magnitude of negative couplings is often overestimated .",
    "these negative couplings are responsible for most of the error @xmath244 in fig .",
    "[ fig - coupled]b . from the bayesian point of view ,",
    "when @xmath17 is smaller than the average isi , negative - valued couplings are indeed intrinsically harder to infer than positive - valued ones .",
    "a positive input drives the potential closer to the threshold , which strongly reduces the isi .",
    "conversely , a negative input drives the potential down , and a spike is unlikely to occur before the potential first relaxes to its average level @xmath285 after a time of the order of @xmath17 .",
    "hence , the influence of a negative input is hardly seen in the increase of the isi when @xmath17 is smaller than the average isi .",
    "we present an analytical calculation supporting this argument in section  [ sec - inf - neg ] .",
    "we now apply our algorithm to multi - electrode recordings of the ganglion cell activity of the salamander retina .",
    "two data sets were considered .",
    "the first one , hereafter referred to as dark ( data courtesy of m. meister ) , reports the spontaneous activity of 32 neurons for 2,000 seconds , and consists of @xmath286 spikes ( schnitzer and meister , 2003 ) . in the second experiment , referred to as natural movie ( data courtesy of m. berry ) , a retina was presented a 26.5 second - long movie , repeated 120 times , and the activity of 40 neurons was registered for the whole duration of 3,180 seconds ( schneidman , berry , segev and bialek , 2006 ) .",
    "natural movie includes @xmath287 spikes .",
    "the firing rates , averaged over the population of recorded neurons , have similar values in the two data sets : @xmath288 spikes / sec in dark , @xmath289 spikes / sec in natural movie .",
    "these two data sets were analyzed in a previous work ( cocco , leibler and monasson , 2009 ) with the perfect integrator model ( @xmath212 ) and the fixed threshold algorithm . in this section",
    "we extend the analysis to the case of the lif model and use both the fixed and moving threshold approaches . in particular we show that the lif model is capable of inferring the asymmetry of the interactions , which is seen in the cross - correlograms but was not obtained with the perfect integrator model .",
    "moreover we discuss error bars on the inferred couplings and the fact that strong negative interactions are more difficult to infer than positive - valued couplings .",
    "we stress that the couplings we infer _ a priori _",
    "depend on the stimulus .",
    "cocco , leibler and monasson ( 2009 ) have studied how the interactions inferred with the perfect integrator model depended on the stimulus based on the analysis of two recordings on the same retina , namely the spontaneous activity and random flickering squares . an alternative approach to disentangle stimulus - induced and structural contributions to the couplings",
    "would be to consider a time- and stimulus - dependent external current @xmath290 ( section [ realistic ] ) .",
    "the value of the membrane leaking time @xmath17 strongly affects the number of contacts and the running time of the algorithm .",
    "it takes about 40 seconds to infer the currents and the interactions from either dark or natural movie when @xmath291 sec with one core of a 2.8 ghz intel core 2 quad desktop computer , and about 10 times longer when @xmath292 msec .",
    "the number of passive contacts of the optimal potential computed by the fixed threshold procedure quickly decreases as @xmath17 increases .",
    "it is divided by @xmath293 when the membrane leaking time increases from @xmath294  msec to @xmath295  sec for both data sets . in comparison ,",
    "the number of active contacts is less sensitive to the value of @xmath17 .",
    "we find that the ratio of the number of contacts per neuron and per second over the average firing rate takes similar values for both data sets .",
    "for @xmath296 msec , this ratio is @xmath297 for dark , and @xmath298 for natural movie . the number of passive contacts is smaller with the moving threshold algorithm , while the number of active contacts remains rather unchanged compared to its value with the fixed threshold procedure . on the overall ,",
    "the running time of the moving threshold procedure is higher due to the calculation of the time - dependent threshold @xmath165 .",
    "knowledge of the variance of the noise is required for the moving threshold algorithm .",
    "the value of @xmath22 could , in principle , be determined from experimental measures of the fluctuations of the synaptic current , but is unknown for the two recorded data sets available to us .",
    "we choose @xmath22 so that the relative fluctuations of the potential around the optimal path @xmath284 are less than @xmath299 .",
    "we compute these fluctuations by averaging ( [ result - fluctu ] ) over all isi and all neurons @xmath5 in the population .",
    "the corresponding value of the dimensionless standard deviation of the noise ( [ defnounit ] ) are : for dark , @xmath300 for , respectively , @xmath301 msec ; for natural movie , @xmath302 for , respectively , @xmath301 msec .",
    "figure [ fig - amplitude]a shows the average value of the current and of the interaction strength as a function of the membrane leaking time . as expected with the fixed threshold inference procedure , we find that the average value of the couplings decreases as @xmath17 gets small .",
    "this effect varies from neuron to neuron : the closer @xmath18 is to @xmath278 , the smaller are the couplings @xmath13 . to compare the matrices of couplings",
    "@xmath303 inferred with the fixed threshold algorithm for different values of @xmath17 , we use the correlation coefficient ( hubert and baker , 1979 ) @xmath304 where @xmath305 identical matrices correspond to @xmath306 , and uncorrelated matrices give @xmath307 .",
    "@xmath308 is independent of the scale of the coupling matrices @xmath250 and @xmath90 , _ i.e. _",
    "@xmath309 for any @xmath310 ; therefore , @xmath308 is sensitive to the relative amplitudes of the couplings @xmath90 and @xmath250 and not to their absolute differences . we choose @xmath250 to be the coupling matrix in the absence of leakage and @xmath90 to be the coupling matrix for a given @xmath17 . the value of @xmath308 as a function of @xmath17 is shown in fig .",
    "[ fig - compar - j]b . even for @xmath311 msec",
    ", the coupling matrix is substantially similar to the one obtained with the perfect integrator model ( @xmath312 for dark , @xmath313 for natural movie ) . despite the overall change in the amplitude of the inferred couplings , the relative ordering of the couplings with the pair indices @xmath314",
    "is largely independent of @xmath17 , especially so for dark .",
    "however , for specific pairs of neurons , the interactions may strongly depend on @xmath17 .",
    "such a dependence effect will be illustrated in section [ sec - symmetry ] , and can be related to the temporal structure of the corresponding cross - correlograms .",
    ".2 cm .2 cm .3 cm .2 cm    [ fig - compar - j ] [ fig - fm ] [ fig - scaling - tau ] [ fig - latency ]    the average value of the interactions calculated by the moving threshold algorithm does not decrease when @xmath17 gets smaller , and is larger than the one obtained from the fixed threshold procedure ( fig .",
    "[ fig - amplitude]a ) . to better understand this discrepancy",
    ", we compare in fig .",
    "[ fig - fm]c the interactions inferred with both algorithms for every pairs of neurons in the dark and natural movie data sets when @xmath315 msec .",
    "the agreement between both procedures is very good for positive and strong couplings .",
    "couplings which are slightly positive with the fixed threshold procedure generally have a larger value with the moving threshold procedure .",
    "this offset is responsible for the differences in the average values of the interactions found in fig .",
    "[ fig - amplitude]a .",
    "in addition , in natural movie , negative - valued couplings often have a stronger amplitude with the moving threshold procedure .",
    "we find , in both approaches , a few negative and very strong couplings .",
    "the amplitude of those extreme couplings increases very quickly as the membrane leaking time decreases .",
    "the emergence of strong negative interactions with the lowering of @xmath17 can be related to the presence of long latencies between the emission of spikes .",
    "we define the latency of neuron @xmath5 with respect to neuron @xmath14 as the smallest delay between a spike emitted by @xmath14 and a later spike fired by @xmath5 , @xmath316 a large value of the latency of neuron @xmath5 with respect to @xmath14 is interpreted by the inference procedure as the consequence of a strongly inhibiting coupling from @xmath14 to @xmath5 .",
    "however , the effect of a synaptic input of amplitude @xmath13 on the potential @xmath25 of the neuron @xmath5 decays exponentially with the ratio of the time elapsed from the input over the membrane leaking time .",
    "hence , to keep the latency fixed while @xmath17 is changed , the strong and negative interaction must change accordingly , @xmath317 where the constant has a negative value .",
    "figure  [ fig - scaling - tau]d shows the negative couplings @xmath13 vs. the latencies of the corresponding pairs @xmath314 divided by @xmath17 , for three values of @xmath17 .",
    "the outcome suggests that relation ( [ jtau ] ) is indeed correct , see fig .",
    "[ fig - scaling - tau]d and its caption .",
    "the above mechanism explains why strongly negative couplings are less frequent in dark than in natural movie . for @xmath318 msec , there are 10 interactions ( out of 1560 ) smaller than @xmath319 in natural movie , and none ( out of 992 ) in dark . for @xmath311 msec",
    ", these two numbers are equal to , respectively , 23 and 1 .",
    "figure [ fig - latency]e shows the histograms of latencies for both data sets . in natural movie , we find 17 pairs with latencies larger than 25 msec . in dark , only one pair @xmath314 has a latency larger than 25 msec .",
    "the corresponding interaction , @xmath13 , is the only one smaller than @xmath319 for @xmath311 msec .      as discussed in the methods section , the uncertainty on the inferred parameters",
    "can be obtained from the hessian matrix of @xmath184 , that is , from the curvature of the log - likelihood around its maximum .",
    "to quantify those uncertainties , we use the following procedure .",
    "assume for instance we want to know how reliable is the inferred value , @xmath320 , of the interaction @xmath321 from neuron @xmath322 to neuron @xmath5 .",
    "we fix @xmath321 to an arbitrary value , and maximize @xmath323 ( [ deflpcc ] ) over all the couplings @xmath13 with @xmath324 and over the current @xmath18 .",
    "the outcome is a function of @xmath321 , which we denote by @xmath325 and call marginal log - likelihood .",
    "@xmath326 has , by definition , a maximum in @xmath327 .",
    "its second derivative in the maximum , @xmath328 , is related to the error bar @xmath329 on the interaction through , see ( [ fluch ] ) and ( [ flucov ] ) , @xmath330 the same procedure can obviously be used to obtain the error bar on the current @xmath18 .",
    "we now illustrate this approach on the natural movie data set , and one arbitrarily chosen neuron , @xmath331 .",
    "three interactions , representative of , respectively , positive , weak , and negative couplings , were singled out among the 39 couplings incoming onto neuron  1 .",
    "figure [ fig - curvature]a shows the marginal log - likelihoods @xmath332 , @xmath333 , and @xmath334 , in addition to @xmath335 .",
    "for all four parameters , the marginal likelihoods can be approximated with parabolas in the vicinity of their maxima .",
    "estimating the second derivatives from those best quadratic fits and using ( [ eb09 ] ) , we obtain @xmath336 where @xmath158 is the dimensionless noise level defined in ( [ defnounit ] ) .",
    "hence , the error bars on the couplings and currents have very similar values .",
    "this common value depends on the noise level , @xmath143 .",
    "as discussed in the next section  [ sec - amplitude ] , @xmath143 is expected to be close to , or smaller than unity when @xmath337 msec .",
    "consequently , the value for @xmath338 is compatible with zero , while the interactions @xmath339 and @xmath340 are non zero , with 99.9999% confidence .    a closer inspection of fig .",
    "[ fig - curvature]a shows that the quality of the quadratic fit of @xmath325 is excellent for @xmath339 and @xmath340 , but less so for @xmath341 and @xmath338 . for the latter parameters",
    ", it seems that the curvature of @xmath325 takes two different values , depending on whether the maximum is approached from the left of from the right .",
    "this phenomenon results from the piece - wise structure of the @xmath184 function , see methods section .",
    "a practical consequence is that the errors @xmath342 and @xmath343 are not evenly distributed around zero ; for instance @xmath338 is more likely to be larger than @xmath344 than it is to be smaller .",
    "-2 cm -4.2 cm 9.cm + 9.cm    [ fig - tfpt ]    note that strong , negative interactions may be harder to infer than positive - valued couplings , a phenomenon already underlined by aersten and gerstein ( 1985 ) .",
    "the underlying intuition is that the duration of the isi is less affected by an inhibitory input than by an excitatory input when the membrane leaking time , @xmath17 , is small compared to the average value of the isi .",
    "we now present an analytical argument supporting this intuition . consider a neuron , fed with an external current @xmath166 and with noise variance equal to @xmath61 . assume a synaptic input of amplitude @xmath250 is received at time @xmath345 .",
    "we call @xmath346 the average value of the time at which the neuron will emit a spike ; the calculation of @xmath346 can be done using a series of parabolic cylinder functions ( alili , patie and pedersen 2005 ) . figures [ fig - tfpt]b&c shows that the dependence of @xmath346 on @xmath250 is much weaker for negative - valued @xmath250 than for positive couplings . as the set of spiking times is the only information we have at our disposal , the difficulty in inferring negative couplings is intrinsic to the bayesian approach , and can not be circumvented by any particular algorithm .",
    ".5 cm    [ fig - coefficient_r ] [ fig - symmetry ]    the dependence of the symmetry of couplings upon the membrane leaking time @xmath17 can be understood , to some extent , from the structure of the cross - correlograms , that is , the histograms @xmath347 of the delays @xmath348 between the times of the spikes fired by the two neurons @xmath349 in each pair .",
    "to do so , we consider two pairs of neurons in dark , called pairs @xmath350 and @xmath351 .",
    "figure [ fig - rapportj]a shows the cross - correlograms @xmath352 and @xmath353 .",
    "pair @xmath350 is characterized by a positive peak in @xmath354 , centered in @xmath345 , and of width @xmath293 msec .",
    "pair @xmath351 exhibits a positive peak of correlations , of the same width , but centered around @xmath355  msec .",
    "we plot in fig .",
    "[ fig - rapportj]b the symmetry ratios of the interactions in the pairs , @xmath356 and @xmath357 .",
    "we find that @xmath358 is , to a large extent , independent of @xmath17 .",
    "conversely , @xmath359 sharply decreases with decreasing @xmath17 and is close to zero when @xmath311 msec , which coincides with the typical delay in the cross - correlogram @xmath353 shown in fig .",
    "[ fig - rapportj]a .",
    "we conclude that the inference procedure is capable of capturing the directionality of the interaction between the neurons 1 and 22 , if @xmath17 is small enough .",
    "this results shed some light on the correspondence between the interactions inferred within the lif model and within the ising model ( schneidman , berry , segev and bialek , 2006 ; shlens et al , 2006 ) .",
    "couplings inferred with the perfect integrator model for dark are in good agreement with the ising interactions , when the time is binned into windows of width @xmath360 msec ( cocco , leibler and monasson , 2009 ) . by construction ,",
    "the ising model produces symmetric interactions from the pair - wise correlations of the activities , averaged of the binning window . in the absence of leakage , the integrate - and - fire inference algorithm hardly distinguishes between a post - synaptic and pre - synaptic firing pattern , and produces rather symmetric couplings .",
    "but as @xmath17 decreases , the lif couplings may become strongly asymmetric ( fig .",
    "[ fig - rapportj]b ) . in this case",
    ", the correspondence between the ising and lif couplings breaks down .",
    "the same phenomenon was observed in natural movie , where delays in the cross - correlograms are even stronger .",
    "in this article , we have presented a procedure to infer the interactions and currents in a network of leaky integrate - and - fire neurons from their spiking activity .",
    "the validity of the procedure was established through numerical tests on synthetic data generated from networks with known couplings .",
    "we have also applied our algorithm to real recordings of the activity of tens of ganglion neurons in the salamander retina . though our algorithm is limited to moderate noise levels and instantaneous synaptic integration",
    ", it is fast and can , to our knowledge , handle much bigger data sets than the existing inference methods for the stochastic if model .",
    "it is our intention to make this algorithm available to the neurobiology community in a near future .",
    "cross - correlation analysis ( perkel , gerstein and moore , 1967 ; aersten and gerstein , 1985 ) consists in studying the distribution of delays between the spikes of neurons in a pair .",
    "this approach has been used to characterize the connections between neurons ( amplitude , time - scale , dependence on distance ) , or their dynamical evolution ( fujisawa , amarasingham , harrison and buzsaki , 2008 ) . the analysis",
    "do not require any combinatorial processing of the activity of a large part of the neural assembly . as a result",
    ", the approach is not limited to small networks .",
    "however , cross - correlation analysis may find difficult to separate direct correlations from indirect correlations modulated through interactions with neurons in the surrounding network ( ostojic , brunel and hakim , 2009 ; cocco , leibler and monasson , 2009 ) , or due to common inputs ( constantidinidis , franowicz and goldman - rakic , 2001 ; trong and rieke , 2008 ) .    in statistical approaches",
    "a widely - used concept is the one of causality ( seth and edelman , 2007 ) .",
    "a causal interaction exists from neuron @xmath5 to neuron @xmath14 if the knowledge of the activity of @xmath5 helps predict the firing of @xmath14 beyond what can be achieved from the activity of @xmath14 alone . in practice",
    ", causal relationships are detected through linear multivariate statistical regressions ( sameshima and baccal , 1999 ) , and may overlook non - linear dependencies .",
    "causal analysis have also difficulties in evaluating the strength of the interactions .    maximum entropy models , which deduce interactions from pairwise correlations only , have been shown to accurately reproduce higher - order correlations between neurons in the vertebrate retina ( schneidman , berry , segev and bialek , 2006 ; shlens et al , 2006 ; cocco , leibler and monasson , 2009 ) .",
    "these models , however , suffer from some limitations .",
    "interactions are constrained to be symmetric , and temporal correlations are partially discarded ( marre , el boustani , frgnac and destexhe , 2009 ) . in addition",
    "obtaining the interactions from the correlations may be computationally very hard for large networks , though efficient approximate algorithms have recently been developed ( cocco and monasson , 2010 ) .",
    "generalized linear models ( glm ) , which represents the generation of spikes as a poisson process with a time - dependent rate , have been applied to various neural systems ( brown , nguyen , frank , wilson and solo , 2001 ; truccolo et al , 2005 ; pillow et al , 2008 ) .",
    "the inference of parameters in the glm framework is apparently easier to solve than for if models , which has made the glm framework very attractive . whether glm are better than if models to account for real neural activity , regardless of the computational complexity of both inference framework , is an important issue ( gertsner and naud , 2009 ) .",
    "we hope that our work , which makes possible to apply the if model to large data sets , will help to answer this question .",
    "approaches to infer model parameters in the if framework have been so far capable of processing a very limited number of neurons or of spikes .",
    "pillow et al .",
    "( 2005 ) inferred the model parameters of one stochastic if neuron based on a 50 second - long recording with a procedure tolerating any level of noise ; makarov , panetsos and de feo ( 2005 ) inferred the connections between 5 deterministic if neurons from a 60 second - long synthetic spike train . in comparison",
    "we have analyzed a 3180-second long recording of the activity of 40 neurons .",
    "the running time of our procedure increases as @xmath361 , where @xmath33 is the duration of the recording and @xmath222 is the average firing rate .",
    "recently , koyama and paninski ( 2009 ) have proposed a numerical procedure for calculating the optimal potential and inferring the interactions . in their approach",
    ", the time is discretized into many time - bins of small duration @xmath362 , and the values of the optimal potentials at those discrete times can be found by means of the interior - point method for discrete constrained optimization problems .",
    "the running time of the procedure , @xmath363 , is approximately @xmath364 times larger than ours . in practice",
    ", @xmath222 is of the order of 1 to 10 hz , while the discretization time , @xmath362 , is of the order of 1 msec ; hence , @xmath364 ranges from 100 to 1000 .",
    "however , this order of magnitude does not take into account the existence of multiplicative constants ; a comparative test of the two approaches on the same synthetic or real data would be useful to accurately estimate their running times .",
    "furthermore , the algorithm introduced by koyama and paninski can easily incorporate the presence of temporal filtering in the interactions .",
    "our procedure is , in its present form , valid when the integration kernel is instantaneous only ; considering other synaptic kernels would require _ ad hoc _ modifications to the expressions of the optimal noise and potential and to the search procedure for contacts .",
    "one of the major assumptions in our approach is that the synaptic integration time , @xmath365 , is vanishingly small . in practice , @xmath366 does not vanish , but might often be smaller than the membrane leaking time , @xmath17 , and the average isi .",
    "assume that neuron @xmath5 , whose potential @xmath25 is close to the threshold @xmath26 , receives a spike at time @xmath6 from another neuron , @xmath14 , through a strongly excitatory connection @xmath367 .",
    "then , neuron @xmath5 will reach the threshold level after having received a charge @xmath368 , smaller than @xmath13 . as a consequence",
    ", large positive interactions can be underestimated when the latency of neuron @xmath5 from neuron @xmath14 ( [ deflat ] ) is smaller than @xmath369 .    to compensate for this effect",
    "we could introduce a time - dependent value for the interaction , @xmath370 where @xmath371 is the closest firing time of neuron @xmath5 .",
    "hence the effective interaction @xmath372 is equal to its nominal value @xmath13 only if the synaptic current has enough time to enter the neuron @xmath14 , and is a fraction of @xmath13 otherwise",
    ". the modified procedure will be correct as long as @xmath373 .",
    "if the synaptic and membrane time - scales are comparable , one needs to take into account the complete shape of the synaptic integration kernel , @xmath374 .",
    "choosing simple enough integration synaptic kernel , such as the piece - wise linear function @xmath375 if @xmath376 or @xmath377 , @xmath378",
    "if @xmath379 , could lead to tractable dynamical equations for the optimal potential and noise .",
    "the resolution of those equations is left for future work .",
    "the inference procedure that we have introduced here can be extended to include realistic features such as a refractory period , @xmath380 .",
    "to do so , we restrict the sum in ( [ defv ] ) to the spikes @xmath129 entering the neuron @xmath5 at times larger than @xmath381 .",
    "we have run the modified inference procedure on the recordings of the retinal activity , for values of @xmath380 ranging from 2 to 5 milliseconds .",
    "the couplings did not change much with respect to the values found with @xmath382 .",
    "note that the introduction of a propagation delay @xmath383 in the synaptic interaction is straightforward , as long as the integration kernel remains a dirac distribution ( centered in @xmath383 ) .",
    "bounds on the values of the couplings and currents _ e.g. _ to prevent the exponential growth of negative interactions with the leaking conductance can naturally be introduced through a prior distribution . as an example , assume that the interactions @xmath13 take values in @xmath384 $ ] .",
    "then , one could maximize @xmath385 instead of the log - likelihood @xmath184 alone , where @xmath386 if @xmath387 , 0 if @xmath388 , @xmath389 if @xmath390 and @xmath391 is a large positive coefficient .",
    "we have assumed , throughout this work , that the values of @xmath9 and @xmath26 were known . in practical situations , while the orders of magnitudes are known , the precise values of these parameters should be inferred , and could depend on the neuron @xmath5 .",
    "the inference procedure could be modified to update the values of @xmath392 and @xmath393 at the same time as the synaptic couplings @xmath13 and the current @xmath18 .",
    "the number of parameters to infer ( per neuron ) would simply increase from @xmath1 to @xmath394 , and the running time should not increase too much .      nowadays , multi - electrode experiments can record a few tens , or hundreds of neurons .",
    "to which extent do the interactions inferred from this sub - population coincide with the interactions one would find from the knowledge of the whole population activity ?",
    "the question does not arise in cross - correlation analysis : the correlation between the firing activities of two neurons is obviously independent of whether a third neuron is recorded or not .",
    "however the issue must be addressed as soon as a collective model for generating the activity is assumed , such as the coupled lif models studied here .",
    "a detailed analysis suggests that the interaction between a pair of neurons is not affected by the activity of other neurons distant by more than @xmath395 m in the case of spontaneous activity ( cocco , leibler and monasson , 2009 ) .",
    "the electrode array should be at least twice longer and wider than @xmath396 , and should be dense enough to capture all the neurons on the recorded area .",
    "it is estimated that about 10% of the ganglion cells are registered in the dark experiment , compared to more than 80% with the denser but smaller electrode array used in the natural movie experiment ( segev , puchalla and berry , 2005 ) .",
    "it would thus be very interesting to repeat our study on other multi - electrode recordings , with sufficiently large and dense arrays .",
    "taking into account the stimulus @xmath0 in the inference process would also be interesting .",
    "to do so , we could add a stimulus - induced current , @xmath397 , to ( [ ode ] ) . a simple expression for this",
    "current would be @xmath398 , where @xmath399 is a kernel similar to the one used in generalized linear models ( pillow et al , 2008 ) .",
    "the expression of the current - dependent term in the potential @xmath400 ( [ defv ] ) should be modified accordingly , while the noise - dependent term would remain unchanged .",
    "it is important to note that the search procedure for contacts presented in section [ sec - algo ] would remain valid .",
    "however , the expressions of the noise coefficient , the contact time and the duration of a passive contact given in appendix [ secgnon ] for the case of a constant current @xmath166 should be rederived and would depend on the precise temporal structure of the stimulus - induced current @xmath401 .",
    "* acknowledgment : * this work originates from a collaboration with s. leibler , whom we thank for numerous and fruitful discussions .",
    "we thank c. barbieri for a critical reading of the manuscript .",
    "we acknowledge the hospitality of the rockefeller university , where this work was initiated .",
    "partial funding was provided by the agence nationale de la recherche under contract 06-jcjc-051 .",
    "[ seccp ]    in this appendix , we justify the prescriptions in the search for active contacts presented in section [ sec - algo ] . for the sake of simplicity we restrict to the @xmath212 case ( no membrane leakage )",
    "; the extension to non - zero @xmath9 is briefly discussed in appendix [ secgnon ] .",
    "we consider a neuron @xmath5 , and call @xmath108 the number of spikes received by this neuron during its @xmath16 inter - spike interval @xmath402 $ ] .",
    "the arrival times are @xmath403 , and the corresponding synaptic strengths are @xmath89 . to lighten notations",
    "we hereafter omit the index @xmath5 of the neuron .      to understand the key notion of contact , we first consider the simple case of a neuron receiving no spike during the inter - spike interval @xmath405 $ ] .",
    "the optimal noise is constant according to ( [ 2.8 ] ) .",
    "equation ( [ optimb ] ) then shows that the optimal potential is a linear function of the time , which is fully determined from the boundary conditions @xmath406 .",
    "we obtain @xmath407 this solution is correct since the potential remains below the threshold at all times @xmath408 .",
    "let us now assume now that the neuron receives one input from another neuron , of strength @xmath409 at time @xmath4100;t[$ ] .",
    "the effect of the input is a discontinuous jump of the potential at time @xmath411 and of size @xmath412 , shown in fig .",
    "[ fig - sol1 ] . repeating the calculation above",
    ", we obtain the following expressions for the optimal potential and noise @xmath413 where @xmath95 is the heaviside function : @xmath414 if @xmath415 , 0 otherwise .",
    "this solution is sketched in fig .",
    "[ fig - sol1]a .",
    "it is valid when the potential @xmath416 remains below the threshold at all times .",
    "we call this situation case a. as @xmath416 is a piece - wise linear function we only need to check that @xmath417 and @xmath418 are both smaller than @xmath26 .",
    "the two conditions are fulfilled provided that @xmath419 what happens when the above condition is violated ?",
    "let us consider first @xmath420 ( referred to as case b hereafter ) .",
    "then @xmath416 exceeds the threshold @xmath26 before the input enters the neuron . to prevent the potential from crossing the threshold at time @xmath411 , the true optimal noise , @xmath421 ,",
    "should be smaller than @xmath422 .",
    "but , if @xmath423 , the potential could not reach @xmath26 when the neuron emits its spike at time @xmath33 according to the very definition of @xmath424 !",
    "the only way out is that @xmath425 takes two different values corresponding to the two sub - intervals @xmath426 and @xmath427t_1;t]$ ] , which we call , respectively , @xmath428 and @xmath429 .",
    "we expect @xmath430 .",
    "the noise can change value in @xmath431 through ( [ optimc ] ) only if the potential reaches the threshold in @xmath411 .",
    "we find that @xmath432 from the boundary conditions @xmath433 , and @xmath434 from the boundary conditions @xmath435 .",
    "this solution is drawn in fig .",
    "[ fig - sol1]b .",
    "it is important to stress that the above solution is based on the capability of the noise to abruptly change its value when the potential touches the threshold in @xmath431 . a detailed study of the behavior of the noise close to such ` contact points ' proving that this is indeed the case is postponed to appendix [ seccp - sec ] .",
    "finally , we turn to case c corresponding to @xmath436 . in this case",
    "the input is so excitatory that the noise has to be negative to prevent the neuron from emitting a spike at a time @xmath437 . as in case b",
    ", the potential reaches the threshold in @xmath431 to allow the noise to change its value after the input has entered the neuron .",
    "we find @xmath438 according to the boundary conditions @xmath439 .",
    "right after the spike has been received , the potential has reached its threshold value , and will keep to this value until a spike is emitted at time @xmath33 , hence @xmath440 this solution is drawn in fig .",
    "[ fig - sol1]c .",
    "we now give the values of log - likelihoods @xmath184 corresponding to the cases listed above .",
    "the value of @xmath184 can be calculated from the knowledge of the optimal noise @xmath101 through ( [ deflpcc ] ) . in the case of @xmath404 spike , we find , using ( [ illm0 ] ) with @xmath441 , @xmath442 the optimal current",
    "is then inferred by maximizing @xmath443 with the result @xmath444 , which corresponds to a vanishing value for the optimal noise , as expected .",
    "when @xmath445 spike is received by the neuron , the log - likelihood @xmath184 has three distinct expressions corresponding to the case a , b , c discussed in section [ illustration ] .",
    "the resulting expression is ( with @xmath446 ) : @xmath447 the log - likelihood @xmath184 is a continuous and convex function of its argument .",
    "the first derivatives of @xmath184 are continuous in @xmath448 , but the second derivatives are not .",
    "the noise coefficient @xmath74 in ( [ eq1 ] ) are constant over the time interval separating two active contacts .",
    "the value of @xmath74 may however change upon the crossing of an active contact .",
    "the scope of this section is to show that the noise right after the contact can take _ any value _",
    "larger than the noise immediately before the contact .",
    "this monotonicity property justifies the search for the minimal noise coefficient done in ( [ defnoise ] ) , see appendix [ seccp2 ] .    to show that the noise always increases through an active contact",
    ", we consider that the synaptic integration is not instantaneous , but takes place over a finite albeit small time , @xmath369 .",
    "we thus replace the expression for the current @xmath449 in ( [ defisyn ] ) with @xmath450 where @xmath13 is the strength of the connection from neuron @xmath14 onto neuron @xmath5 , and @xmath451 is is the memory kernel of the integration of synaptic entries ( top panel in fig .",
    "[ fig - cont ] ) .",
    "we assume that @xmath451 vanishes for @xmath452 and for @xmath453 where the integration time @xmath369 is independent of the pair @xmath314 .",
    "in addition , @xmath454 is positive , and its integral over the interval @xmath455 $ ] is equal to unity .",
    "we consider the case of a single incoming spike , as in section [ illustration ] .",
    "we want to show that , in the @xmath456 limit , the only constraint linking the values @xmath457 and @xmath458 of the optimal noise , respectively , before and after a spike entering at @xmath411 , is @xmath459 , as we have found for a single incoming input in cases b and c. to do so , we assume that the time of synaptic integration @xmath365 is small but _ finite _ , and consider case b. the dynamics of @xmath150 and @xmath101 can be divided in several steps , whose numbered are reported on fig .",
    "[ fig - cont ] :    1 .",
    "prior to the input , _",
    "i.e. _ at times @xmath460 , the optimal noise @xmath457 is constant and the optimal potential @xmath150 is a linear function of the time , with slope @xmath461 , as shown in fig .",
    "[ fig - cont](left ) .",
    "2 .   a strongly negative input of amplitude @xmath462 is then received by the neuron between times @xmath411 and @xmath463 .",
    "the derivative of the potential now decreases with the time until it vanishes at time @xmath102 defined through @xmath464 3 .   if the value of @xmath457 is chosen so that @xmath465 , the potential tangentially reaches the threshold at @xmath102 ( contact point ) .",
    "then , the potential remains constant and equal to @xmath26 .",
    "the noise obeys eqn .",
    "( [ eq2 ] ) and , therefore , increases until it reaches the prescribed value , @xmath466 , at time @xmath467 such that @xmath468 see bottom panel in fig .",
    "[ fig - cont](left ) .",
    "4 .   then the potential starts decreasing from its threshold value through eqn .",
    "( [ optimb ] ) , and reaches a minimum in @xmath469 , solution of the same equation ( [ bes ] ) as @xmath470 , see fig .",
    "[ fig - cont](top left ) .",
    "5 .   at later times",
    "the derivative of the potential is positive from eqn .",
    "( [ optimb ] ) , and increases until time @xmath471 , coinciding with the end of the synaptic integration .",
    "6 .   at times larger than @xmath471 ,",
    "the potential keeps growing with a constant slope equal to @xmath472 .",
    "in the @xmath473 limit , all times @xmath474 tend to the same value , that is , the time @xmath411 .",
    "more precisely , as the slope of @xmath454 is of the order of @xmath475 ( in absolute value ) , and @xmath476 are finite ( @xmath477 ) , then for @xmath478 , @xmath479 differ from each other by @xmath480 .",
    "hence the change in the potential @xmath150 between @xmath470 and @xmath471 equals @xmath481 .",
    "we conclude that , for @xmath482 the potential becomes a discontinuous function of time with a discontinuity @xmath412 .",
    "in addition , the noise @xmath101 can also jump abruptly from its value @xmath457 at @xmath483 to any _ larger _ value @xmath466 at time @xmath484 since the maximum of @xmath454 tends to infinity when @xmath482 .",
    "note that the drawing of fig .",
    "[ fig - cont](left ) tacitly assumes that @xmath485 . a hypothetic scenario would be that the noise exactly compensates the synaptic input for a longer time interval ( including the top of @xmath454 ) , while the potential would remain equal to @xmath26 . in this case",
    ", the peak value of the noise would be @xmath486 .",
    "the contribution to the integral ( [ deflpcc ] ) would be of the order of @xmath487 and would diverge in the @xmath482 limit .",
    "hence this possibility is precluded .",
    "the above discussion is straightforwardly extended to case c. the optimal potential and noise are sketched in fig .",
    "[ fig - cont](right ) .",
    "note that the contact interval spreads beyond @xmath488 $ ] in this case . in the generic case of more than one incoming spikes ,",
    "the contact interval is restricted to @xmath489 $ ] as in case b. the noise can also discontinuously change from its value @xmath490 before the contact to any larger value , @xmath466 , after the contact .",
    "we now consider the general case of @xmath108 input spikes .",
    "let @xmath492 be , respectively , the initial value of the potential and the index of the first input spike .",
    "we define the piece - wise linear function solution of ( [ optimb ] ) for a constant noise @xmath74 , @xmath493 we are looking for the smallest value of the noise coefficient @xmath74 capable of bringing the potential @xmath494 from its initial value @xmath495 to the threshold .",
    "the contact time , @xmath102 , coincides with an entering spike , _",
    "i.e. _ @xmath496 for some @xmath497 . if @xmath498 then the optimal potential is @xmath499 throughout the inter - spike interval @xmath500 $ ] , and the problem is solved . if @xmath501 , @xmath127 is the first active contact point of the potential . @xmath101 and @xmath502 are , respectively , the optimal noise and potential on the interval @xmath120 $ ] .    the correctness of the above statement can be established using a proof by contradiction .",
    "* assume that the optimal noise , @xmath503 , is smaller than @xmath101 on some sub - interval of @xmath504 $ ] .",
    "remark that the potential @xmath168 in ( [ defvlin ] ) is an increasing function of the noise , @xmath505 for all @xmath506 . by virtue of ( [ monoto ] ) and the definition of @xmath101",
    ", @xmath507 can not touch the threshold at any time so the noise is constant throughout the interval @xmath504 $ ] .",
    "hence no active contact can take place at time @xmath102 . as @xmath101 is the minimal value of the noise which can drive the potential into contact with the threshold over @xmath500 $ ]",
    ", we conclude that @xmath507 can not cross the threshold at any time @xmath508 .",
    "the neuron can therefore not spike at time @xmath96 . *",
    "conversely , suppose that the optimal noise is equal to @xmath509 on the interval @xmath510 $ ] with @xmath511 , and takes another value on the interval @xmath512 $ ] . as the change of noise can take place only through an active contact , and the change is necessarily positive ( section [ seccp - sec ] )",
    ", we have @xmath513 . applying ( [ monoto ] ) to the interval @xmath512 $ ] , we have @xmath514 adding the value of the optimal potential in @xmath515 to both members of the previous inequality , we find @xmath516 where the last inequality comes from ( [ monoto ] ) .",
    "but , by definition of @xmath101 , @xmath517 .",
    "hence , we find that the optimal potential in @xmath102 is above threshold , which can not be true",
    ".    the optimal noise and potential on the remaining part @xmath518 $ ] of the inter - spike interval can be determined iteratively .",
    "we replace @xmath519 with @xmath127 and @xmath99 with @xmath26 if @xmath520 or @xmath521 if @xmath522 in ( [ defvlin ] ) , and look for the lowest noise producing a new contact point over the interval @xmath523 $ ] .",
    "the procedure is repeated until the whole interval is exhausted . this way an increasing sequence of noise values is obtained ,",
    "each corresponding to the slope of the optimal potential between two successive contact points .",
    "when the membrane leaking conductance is non zero , some change have to be brought to the above calculation of the optimal noise and potential . first , in the absence of inputs , the noise is no longer constant , but rather it is an exponentially increasing ( in absolute value ) function of the time ( [ eq1 ] ) .",
    "similarly , the potential @xmath150 itself is not a linear function of the time as in ( [ lp ] ) , but is a linear combination of @xmath524 with appropriate coefficients , see ( [ defv ] ) .",
    "the main conclusion of appendix [ seccp ] still holds : the difference between the noise values just after and before an active contact point , coinciding with a synaptic input , is always positive ( fig .",
    "[ fig - scheme]a ) .",
    "consequently , the procedure of section [ sec - algo ] , _ i.e. _ the iterative search for the active contact points and the minimal noise coefficient @xmath151 , defined through ( [ defnoise ] ) , remains unchanged .",
    "note that some care must be taken to translate the statement about the growth of the noise to the values of the noise coefficients .",
    "consider for instance two successive contact times , @xmath6 and @xmath525 , and call @xmath74 , @xmath526 the corresponding noise coefficients . that the noise is larger at time @xmath525 than at time",
    "@xmath6 implies that @xmath527 , but does not imply that @xmath526 is larger than @xmath74 .",
    "case , where the noise and the noise coefficient coincide . ]    there exists , however , a major difference between the @xmath212 and @xmath528 cases .",
    "when @xmath529 , the optimal potential is not guaranteed to be a monotonous function of the time , as shown in fig .",
    "[ passc ] . for given values of @xmath530 , and of the times and the amplitudes of the synaptic inputs",
    ", the optimal potential @xmath150 may touch the threshold at an intermediate time , @xmath102 .",
    "such a situation is called passive contact .",
    "it is important to note that the value of the optimal noise during a passive contact is , according to eqn .",
    "( [ eq2 ] ) , equal to @xmath531 .",
    "as the optimal noise is a monotonous function of the time between two active contacts , see eqn ( [ eq1 ] ) , the value @xmath531 can be crossed at most once : there is at most one passive contact in between two successive active ones . to be more precise ,",
    "there are at most @xmath532 passive contacts in an inter - spike interval with @xmath533 active contacts .",
    "to decide the existence of a passive contact in an interval @xmath500 $ ] , we look for a solution of the two coupled equations expressing that the optimal potential touches the threshold without crossing it , @xmath534 the solutions of these equations give the noise coefficient @xmath111 and the contact time @xmath102 at which the optimal potential reaches the threshold value ( fig .",
    "[ passc ] ) .",
    "the solution can be calculated analytically , with the following result .",
    "let us call @xmath99 the value of the potential of the neuron at time @xmath535 . for each @xmath536",
    "we define @xmath537 where the summation runs overs the spikes entering the neuron between times @xmath519 and @xmath102 .",
    "a passive contact takes place in the interval @xmath538 $ ] if :    @xmath539 : :    @xmath531 and @xmath540 have the same    sign ; @xmath539 : :    the noise coefficient @xmath541 is smaller than the    lowest noise coefficient corresponding to all the possible active    contacts at times @xmath542 , with    @xmath543 ; @xmath539 : :    the corresponding contact time @xmath544 \\ , \\ ] ]    where @xmath545 is given by ( [ etap ] ) , lies in the    correct interval : @xmath546 ; @xmath539 : :    the optimal potential can reach again the threshold at a later time ,    coinciding with an input spike or with the end of the inter - spike    interval .",
    "we call @xmath547 the duration of the    active contact such that the potential reaches @xmath26 at    time @xmath548 , starting from @xmath26 at time    @xmath549 , see fig .",
    "[ passc ] . the analytical    expression for the duration of the passive contact allowing the    potential to be in active contact at time",
    "@xmath548 is    @xmath550 \\right\\}\\ .\\ ] ]    where    @xmath551 we must have    @xmath552 for at least one value    of @xmath553 .",
    "when all the conditions are fulfilled , a passive contact is present .",
    "the duration of the contact , @xmath133 , merely plays the role of a latency time after which the potential @xmath150 resumes its course ( fig  [ passc ] ) .",
    "we can check that @xmath150 is an increasing function of @xmath554 .",
    "the optimal value of @xmath554 will therefore be equal to the smallest possible value of @xmath555 , for the very same reason that we had to chose the minimal noise when looking for active contacts , see example in fig .",
    "[ passc ] .    to end this appendix",
    ", we give the expression for the log - likelihood @xmath184 ( [ deflpcc ] ) for an interval including a passive contact between two active contacts .",
    "gathering the contributions to the integral of the squared optimal noise coming from the three intervals @xmath504 $ ] , @xmath556 $ ] , and @xmath557 $ ] , we obtain @xmath558 - \\exp \\big[-2(t_c - t_0)/\\tau\\big ]   } { 2}\\right\\}\\ .\\ ] ] differentiation of @xmath184 with respect to the current and couplings gives the expressions for the gradient and hessian matrix needed for the newton - raphson method .",
    "the expressions are easy to obtain but are lengthy , and thus we do not reproduce them .",
    "in this appendix , we analyze the eigenmodes and eigenvalues of the hessian matrix of the log - likelihood @xmath184 , and relate the eigenmodes to the fluctuations of the effective current , @xmath181 , of the current , @xmath18 , and of the couplings , @xmath13 .",
    "consider two successive spikes emitted by neuron @xmath5 and the optimal potential @xmath84 on the time interval @xmath559 $ ] .",
    "when the couplings @xmath13 vanish and passive contacts are absent , @xmath64 does not enter into contact with the threshold at times @xmath560 . by continuity , this statement remains true if the couplings @xmath13 have very small amplitudes . in this regime ,",
    "the stochastic process undergone by the potential is simply the ornstein - uhlenbeck process with a time - varying force , and the expression for @xmath184 ( [ deflpcc ] ) is exactly given by @xmath561 where @xmath562 and @xmath563 the hessian matrix of @xmath564 , attached to neuron @xmath5 , is the @xmath565 matrix ( [ fluch ] ) with elements @xmath566 @xmath225 is a positive matrix according to ( [ fluch2 ] ) . to study its spectrum",
    "let us first consider the case of very weak leakage ( very large @xmath17 ) . in this limit ,",
    "calling @xmath567 the duration of the @xmath16 isi of neuron @xmath5 , we have @xmath568 let us define the firing rate @xmath569 of neuron @xmath570 in the @xmath16 isi of neuron @xmath5 , and @xmath571 .",
    "we obtain @xmath572 where @xmath33 is the duration of the recording .",
    "the right hand side of the above equation can be interpreted as the covariance matrix of the rates @xmath569 , where each isi of neuron @xmath5 is weighted proportionally to its duration . for vanishing couplings ,",
    "these instantaneous rates are decoupled from neuron to neuron .",
    "hence , @xmath573 fluctuates around the average firing rate @xmath180 ( number of the spikes fired by neuron @xmath14 , divided by @xmath33 ) , with a variance we denote by @xmath574 .",
    "this statement holds for @xmath575 ; in addition we define @xmath576 . neglecting terms of the order of @xmath577",
    ", we end up with the following approximation for the hessian matrix , @xmath578 which becomes exact in the limit of infinitely long recordings .",
    "the matrix @xmath225 is the sum of a rank one matrix plus a diagonal matrix . for small values of @xmath22 ,",
    "the fluctuations of the firing rates , represented by the @xmath579 s , are expected to be small compared to the product of any two average firing rates .",
    "we immediately deduce that the largest eigenvector of the matrix , @xmath580 , has components @xmath581 for all @xmath582 .",
    "the associated eigenvalue , @xmath209 , is given by @xmath583 where @xmath0 is the total number of spikes .",
    "if the neurons have quantitatively similar firing rates @xmath584 , then @xmath585 .",
    "the probability density of vector @xmath586 is @xmath587 \\ .\\ ] ] a fluctuation @xmath588 around the most likely values for the current and the couplings , and along vector @xmath580 , will change the log - likelihood by @xmath589 hence the effective current @xmath181 is associated to the largest eigenmode , and is the parameter requiring the least number of data to be inferred .",
    "we now look for the smallest eigenvalue , @xmath590 .",
    "numerical investigations suggest that the associated eigenvector , @xmath591 , correspond to fluctuations of the current @xmath18 only .",
    "we thus assume that the components of @xmath591 are : @xmath592 , and @xmath593 with @xmath594 .",
    "the eigensystem we need to solve is @xmath595 according to ( [ eqt2 ] ) and ( [ eqt1 ] ) , we have , for all @xmath570 , @xmath596 inserting this expression for the components @xmath597 of the eigenvector into ( [ eqt1 ] ) , we obtain @xmath598 if all neurons have quantitatively similar firing rates , @xmath599 , and variances , @xmath600 , we obtain @xmath601 . according to ( [ epsj7 ] ) , the components @xmath602 of the eigenvector are very small , @xmath603 , for all @xmath575 . hence @xmath591 is localized on its current component only . a fluctuation @xmath588 , where the @xmath604 s are chosen to be orthogonal to all the other eigenmodes of @xmath225 , modifies the log - likelihood by @xmath605 we conclude that the current @xmath18 is the hardest parameter to infer , _ i.e. _ the one requiring the largest number of data .",
    "when the membrane leaking time becomes of the order of , or smaller than the average isi duration , the above calculation has to be modified . from a qualitative point of view",
    ", the average firing rate @xmath606 must now be defined as the mean number of spikes emitted by the neuron @xmath14 in a time - window of duration @xmath17 preceding a spike of neuron @xmath5 , divided by @xmath17 , see ( [ deffjitau ] ) .",
    "the eigenvector of @xmath225 with largest eigenvalue @xmath209 is still given by @xmath607 , with @xmath608 , and @xmath609 again , these fluctuations are associated to the effective current , with the newly defined average firing rates @xmath610 .",
    "as @xmath17 gets smaller and smaller , all the rates @xmath180 with @xmath575 become smaller and smaller compared to @xmath610 , and the effective current @xmath181 gets closer and closer to the true current @xmath18 .",
    "obviously , the inference of the synaptic coupling @xmath13 is possible if the firing rate @xmath180 defined on a time - window of duration @xmath17 preceding a spike of neuron @xmath5 is much larger than @xmath611 .",
    "in this appendix , we derive formula ( [ result - fluctu ] ) for the fluctuations of the potential around its optimal value at the mid - point of the isi . a useful formulation for @xmath51 in ( [ prodfpt ] ) can be given in terms of a path integral over the potential , @xmath612\\right ) \\ .",
    "\\nonumber\\end{aligned}\\ ] ] the measure @xmath613 in the path - integral ( [ pathint ] ) is restricted to the potentials @xmath4 remaining smaller than the threshold @xmath26 at all times @xmath6 .",
    "the upper bound @xmath614 means that the integral is performed over all the values of the potential smaller than @xmath26 at time @xmath615 , while @xmath616 is constrained to be zero .",
    "we introduce the dimensionless variable @xmath617 to represent the time - dependent fluctuation of the potential ( fig .",
    "[ fig - fluctuphi]c ) . according to ( [ pathint ] ) and ( [ pathint2 ] ) , the log probability density of a path - fluctuation @xmath618 on the inter - spike interval @xmath58 $ ] is , after multiplication by @xmath61 , @xmath619 \\nonumber \\\\ & = & { \\cal l}[v^*_i(t ) ; k,{\\cal t},{\\cal j},{\\cal i } ] + \\frac{v_{th}^2}{2 } \\int _ { t_{i , k}}^ { t_{i , k+1 } } dt'\\ ;   \\int _ { t_{i , k}}^ { t_{i , k+1}}dt\\ ; \\psi_i(t ' ) \\ ;   \\frac{\\delta ^2{\\cal l}}{\\delta v_i^*(t ' ) \\,\\delta v_i^*(t ) } \\ ; \\psi_i(t ) + o(\\psi _",
    "i^3 ) \\nonumber \\\\ & = & l^*({\\cal t}|{\\cal j},{\\cal i } ) - \\frac{v_{th}^2}{2 } \\int _ { t_{i , k}}^ { t_{i , k+1 } } dt\\ ; \\psi_i(t )   \\bigg [ -c^2 \\frac{d^2}{dt^2 } + g^2 \\bigg ] \\psi_i(t ) + o(\\psi _",
    "i^3 ) \\ , \\end{aligned}\\ ] ] up to an additive term independent of @xmath620 .",
    "note that we have used the optimality condition ( [ optima ] ) to exclude terms linear in @xmath620 in ( [ pathint3 ] ) .",
    "we now want to perform the path integral over the fluctuations @xmath618 in ( [ pathint ] ) .",
    "when @xmath22 is small we may discard the cubic and higher order terms in @xmath620 . the boundary condition on @xmath620",
    "are @xmath621 : the values of the potential @xmath4 are constrained right after and before the emission of a spike , and , hence , can not fluctuate ( fig .",
    "[ fig - fluctuphi]c ) .",
    "we therefore write the fluctuations @xmath618 as the following fourier series , @xmath622 where the @xmath623 are stochastic coefficients .",
    "the integral on the last line of ( [ pathint3 ] ) can be calculated with the result @xmath624 \\psi_i(t )   = \\frac{\\rho\\,(cv_{th})^2}{4\\tau}\\sum _ { n\\ge 1}\\big[1+\\left ( \\frac{n\\pi } \\rho\\right)^2\\big]\\ ,   \\psi_n^2   \\ , \\ ] ] where @xmath625 is the duration of the isi measured in units of the membrane leaking time .",
    "hence , if we relax the constraint that the fluctuating potential should remain below threshold at all times , the @xmath623 s are independent gaussian variables with zero means and variances @xmath626 where @xmath158 is defined in ( [ defnounit ] )",
    ". we may now calculate the variance of @xmath620 at the mid - point of the isi , see fig .",
    "[ fig - fluctuphi]c , @xmath627 ^ 2\\right > = \\sum _ { p\\ge 0 } \\lambda_{2p+1 } \\ .\\ ] ] summing up the series over @xmath270 in ( [ pathint5 ] ) gives expression ( [ result - fluctu ] ) .",
    "in section [ sec - beyond ] we explain that the value of the moving threshold , @xmath165 , is estimated from the intersection of the tangent to the probability of survival in @xmath172 with the @xmath176 line .",
    "hence , @xmath628 the slope of @xmath171 can be expressed in terms of a series of parabolic cylinder functions ( alili , patie and perdersen , 2005 ) , @xmath629 where @xmath630 denotes the derivative of weber s function of order @xmath631 , @xmath632 , with respect to its argument @xmath633 .",
    "the normalization coefficients are @xmath634 the orders @xmath635 , @xmath636 , are the roots of the equation ( mei and lee , 1983 ) @xmath637 with @xmath638 .",
    "the gap between successive levels , @xmath639 , is larger than 1 .",
    "note that the contributions from high orders @xmath635 decay exponentially with @xmath640 in ( [ expressfpt ] ) .",
    "hence , in practice , the summation can be carried out over a finite number of terms .",
    "the moving threshold procedure was designed to take into account the effects of a moderate noise level , @xmath22 .",
    "an alternative approximate procedure consists in subtracting to the log - likelihood a cost - function preventing the current , or the effective current from getting too close to @xmath278 . for a quantitative treatment consider a single neuron in the absence of synaptic input , for which @xmath51 can be calculated under the form of a series of parabolic cylinder functions , see above .",
    "we denote by @xmath641 the approximation to @xmath51 obtained when taking into account the optimal path only .",
    "we define the cost - energy function @xmath642 \\ .\\ ] ] for the current @xmath166 .",
    "we show in fig .",
    "[ fig-4 ] the shape of @xmath643 for different values of @xmath9 , @xmath22 , and the inter - spike interval @xmath174 . as expected from above",
    ", this cost function is essentially flat when @xmath644 , and is repulsive when @xmath645 .",
    "the repulsion is strong when the inter - spike interval , @xmath174 , the membrane conductance , @xmath9 , and the noise standard deviation , @xmath22 , are large .    in presence of synaptic inputs , we approximate the non - perturbative corrections by subtracting @xmath646 to our log - likelihood , where @xmath647 is the number of spikes of neuron @xmath5 , and @xmath181 its effective current .",
    "this simple approximation preserves the concavity of the log - likelihood and is computationally simple since @xmath643 has to be calculated only once for each step and neuron .",
    "simulations show that the performance of the inference algorithm with the cost function @xmath643 is quantitatively similar to the one obtained with the moving threshold procedure .",
    "jolivet r , lewis tj , gertsner w ( 2004 ) generalized integrate - and - fire models of neuronal activity approximate spike trains of a detailed model to a high degree of accuracy .",
    "_ j. neurophysiol . _ * 92 * : 959 .",
    "koyama s , paninski l ( 2009 ) efficient computation of the maximum a posteriori path and parameter estimation in integrate - and - fire and more general state - space models .",
    "makarov va , panetsos f , de feo o ( 2005 ) a method for determining neural connectivity and inferring the underlying network dynamics using extracellular spike recordings . _",
    "j. neurosci .",
    "methods _ * 144 * : 265 .                                            truccolo w , eden u , fellows m , donoghue j , brown e ( 2005 ) a point process framework for relating neural spiking activity to spiking history , neural ensemble , and extrinsic covariate effects",
    ". _ j. neurophysiol . _ * 93 * : 1074 ."
  ],
  "abstract_text": [
    "<S> we present two bayesian procedures to infer the interactions and external currents in an assembly of stochastic integrate - and - fire neurons from the recording of their spiking activity . </S>",
    "<S> the first procedure is based on the exact calculation of the most likely time courses of the neuron membrane potentials conditioned by the recorded spikes , and is exact for a vanishing noise variance and for an instantaneous synaptic integration . </S>",
    "<S> the second procedure takes into account the presence of fluctuations around the most likely time courses of the potentials , and can deal with moderate noise levels . </S>",
    "<S> the running time of both procedures is proportional to the number @xmath0 of spikes multiplied by the squared number @xmath1 of neurons . </S>",
    "<S> the algorithms are validated on synthetic data generated by networks with known couplings and currents . </S>",
    "<S> we also reanalyze previously published recordings of the activity of the salamander retina ( including from 32 to 40 neurons , and from @xmath2 to @xmath3 spikes ) . </S>",
    "<S> we study the dependence of the inferred interactions on the membrane leaking time ; the differences and similarities with the classical cross - correlation analysis are discussed . </S>"
  ]
}