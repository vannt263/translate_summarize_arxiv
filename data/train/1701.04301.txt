{
  "article_text": [
    "signal reconstruction problems are encountered in many engineering fields .",
    "compressed sensing ( cs ) @xcite aims to reconstruct a sparse signal with a high - dimension space from a low - dimension measurement space .",
    "significant attention has been given to the usage of @xmath3-norm minimization because it is capable of recovering sparse signal with a computational cost of the polynomial complexity .",
    "however , this approach is still generally far from optimal @xcite .    given that the prior distribution of the signal is used , the bayesian inference offers an optimal recovery approach in the minimum mean square error ( mmse ) perspective although its exact execution is computationally difficult in most cases @xcite .",
    "approximate message passing ( amp ) , which is based on the gaussian approximations of loopy belief propagation , is a tractable and less complex alternative , and it has attracted considerable attention for such problems @xcite .",
    "unfortunately , amp and its generalization , gamp @xcite , are fragile in terms of the choice of matrix , and can perform poorly outside the special case of zero - mean , i.i.d . , sub - gaussian matrix .",
    "@xcite developed a signal recovery ( sr ) algorithm under _ linear _ measurements called turbo - sr with partial discrete fourier transform ( dft ) as the sensing matrix .",
    "subsequently liu et al .",
    "@xcite proposed the generalized turbo - sr ( gturbo - sr ) to address _ non - linear _ measurements .",
    "ma and li @xcite further proposed the orthogonal amp ( oamp ) algorithm for general sensing matrices but under linear measurements .",
    "in contrast to suboptimal developments along this line , such as amp and gamp , turbo - sr , gturbo - sr , and oamp are optimal and have excellent convergence properties .",
    "the state evolutions of the three algorithms agree perfectly with those predicted by the theoretical replica method .",
    "however , these algorithms only consider either the partial dft sensing matrix or the linear measurements .    the purpose of this paper is to develop a novel algorithm for bayesian sr with a much broader class of sensing matrices under non - linear measurements .",
    "we employ an advanced mean field method known as the expectation consistent ( ec ) approximation developed in statistical mechanics @xcite and machine learning @xcite .",
    "recently ,  vector amp \" which is presented in @xcite , can be interpreted as an instance of the generalized ec ( gec ) @xcite algorithm .",
    "our wok is inspired by @xcite .",
    "specifically , we present the gec - sr to recover sparse signal from nonlinear measurements , especially from low - resolution quantized output , which has been of particular interest in recent years . we show that the performance of our gec - sr is superior to  initial gec \" @xcite because of different update manner .",
    "when partial dft matrix is considered , the gec - sr is reduced to gturbo - sr @xcite .",
    "in addition , we give the state evolution ( se ) analysis and show that the analytical se of the gec - sr is consistent with that obtained by the replica method .",
    "this consistency indicates the optimality of the gec - sr for non - linear measurements with general sensing matrices .    _ notations_for any matrix @xmath2 , @xmath4 is the conjugate transpose of @xmath2 , and @xmath5 denotes the traces of @xmath2 .",
    "in addition , @xmath6 is the identity matrix , @xmath7 is the zero matrix , @xmath8 is the diagonal matrix whose diagonal equals @xmath9 , @xmath10 is the @xmath11-dimensional all - ones vector , and @xmath12 is the diagonalization operator , which returns a constant vector containing the average diagonal elements of @xmath13 . in addition ,",
    "@xmath14 and @xmath15 denote componentwise vector division and vector multiplication , respectively ; and @xmath16 , @xmath17 , and @xmath18 represent the expectation , variance , and covariance operators , respectively . a random vector @xmath19 drawn from the proper complex gaussian distribution of mean @xmath20 and covariance @xmath21",
    "is described by the probability density function : @xmath22 we use @xmath23 to denote the real gaussian integration measure @xmath24 and we use @xmath25 to denote the complex gaussian integration measure .",
    "finally , @xmath26 denotes the cumulative gaussian distribution function .",
    "we consider the generalized linear model ( glm ) where a @xmath27-dimensional random vector @xmath28 is observed through a linear output @xmath1 , followed by a componentwise , probabilistic measurement channel @xmath29 where @xmath30 is a known transform matrix .",
    "the sparse signal @xmath0 is assumed to be i.i.d . with the @xmath11th entry of @xmath0 following the bernoulli - gaussian distribution : @xmath31 where @xmath32 is the dirac function , and the variance of each @xmath33 is normalized , that is , @xmath34 .",
    "we denote the measurement ratio by @xmath35 ( i.e. , the number of measurements per variable ) .",
    "in addition , for ease of notation , we define @xmath36      in this study , we are interested in the measurements acquired through the complex - valued quantizer @xmath37 . specifically , each complex - valued quantizer @xmath37 consists of two real - valued @xmath38-bit quantizers @xmath39 , which is defined as @xmath40 therefore , the resulting quantized signal @xmath41 is provided by @xmath42 where @xmath43 represents the additive gaussian noise .",
    "the output is assigned the value @xmath44 when the quantizer input falls in the corresponding interval @xmath45 $ ] ( namely , the @xmath46-th bin ) . for example , the quantized output of a typical uniform quantizer with a quantizer step size @xmath47 is given by @xmath48 and the associated lower and upper thresholds are given by @xmath49    we suppose that each entry of @xmath0 is generated from a distribution ( 2 ) independently , that is , @xmath50 .",
    "the componentwise , probabilistic measurement channel is given by @xmath51 where @xmath52",
    "in this section , we present the gec - sr .",
    "the block diagram of the gec - sr is illustrated in figure [ gec - diagram ] , which consists of three modules : modules a , b and c. module a computes the posterior mean and variance of @xmath19 , module c constrains the estimation into the linear space @xmath53 , and module b computes the posterior mean and variance of @xmath0 .",
    "these procedures follow a circular manner , that is , @xmath54 .",
    "in addition , each module uses the turbo principle in iterative decoding , that is , each module passes the extrinsic messages to its next module .",
    "the gec - sr is different from the gturbo - sr @xcite and `` initial gec '' @xcite .",
    "we will discuss their differences in the following subsections .",
    "nonlinear measurements @xmath41 , sensing matrix @xmath2 , likelihood @xmath55 , and prior distribution @xmath56 . + recovered signal @xmath57 .",
    "+ @xmath58 , @xmath59 , @xmath60 , @xmath61 , and @xmath62 .    1 .",
    "compute the posterior mean and covariance of @xmath19 + [ eq27 ] @xmath63 + compute the extrinsic information of @xmath19 + [ eq28 ] @xmath64 2 .",
    "compute the mean and covariance of @xmath0 from the linear space + [ eq29 ] @xmath65 + compute the extrinsic information of @xmath0 + [ eq30 ] @xmath66 3 .   compute the mean and covariance of @xmath0 + [ eq31 ] @xmath67",
    "+ compute the extrinsic information of @xmath0 + [ eq32 ] @xmath68 4 .",
    "compute the mean and covariance of @xmath19 from the linear space + [ eq33 ] @xmath69 + compute the extrinsic information of @xmath19 + [ eq34 ] @xmath70    the recovered signal @xmath57 .",
    "algorithm 1 specifies the iterative procedure of the gec - sr . in algorithm 1 ,",
    "the posterior mean and the variance of @xmath19 and @xmath0 are obtained from ( [ eq27 ] ) and ( [ eq31 ] ) , respectively .",
    "we take the expectation and variance in ( [ eq31a ] ) and ( [ eq31b ] ) with respect to the posterior probability @xmath71 where @xmath72    we can calculate the expectation and variance on each entry of @xmath0 separately because the prior @xmath56 is separable , and thus we omit index @xmath11 in the following expressions . using the gaussian reproduction property @xcite , we can obtain the explicit componentwise expression @xmath73 where @xmath74    similarly , the posterior mean and variance of @xmath19 in ( [ eq27a ] ) and ( [ eq27b ] ) are taken with respect to the posterior @xmath75 the mean and variance can also be computed in a componentwise manner .",
    "( [ eq27a ] ) and ( [ eq27b ] ) are nonlinear because of the quantization , and their explicit expressions are provided in @xcite .    under the linear constraint @xmath1",
    ", the estimation of the posterior mean and covariance matrix of @xmath0 are obtained in ( [ eq29b ] ) and ( [ eq29a ] ) with the corresponding posterior probability @xmath76 the posterior mean and covariance matrix of @xmath19 can be obtained in ( [ eq33 ] ) following the linear space of @xmath1 .      in the introduction",
    ", we mention that our work is inspired by the `` initial gec '' algorithm from @xcite , which considers the standard linear measurement and glm",
    ". however , our algorithm is different from the initial gec in terms of the update manner . in the gec - sr",
    ", we first estimate @xmath19 from the nonlinear measurements @xmath41 followed by estimating the signal @xmath0 using the prior information from module c , whereas the initial gec estimates @xmath0 and @xmath19 simultaneously . in addition , before computing the mean and covariance of @xmath19 in ( [ eq33c ] ) and ( [ eq33d ] ) , we compute the mean and covariance of @xmath0 once again in ( [ eq33a ] ) and ( [ eq33b ] ) . because of these modifications , the gec - sr algorithm converges faster than initial gec and can agree perfectly with the theoretical se analysis that predicted by the replica method .",
    "we will show the theoretical se analysis in the next section .",
    "gturbo - sr @xcite is a promising algorithm to recover sparse signals from nonlinear measurements , and the idea uses the turbo principle in iterative decoding to compute the extrinsic messages of @xmath0 and @xmath19 . a visual examination of the gec - sr shows many similarities with the gturbo - sr in terms of the iterative approach . in particular , the posterior probabilities of @xmath0 and @xmath19 in the gec - sr are identical to those in the gturbo - sr .",
    "similarly , the computation of extrinsic information in the gec - sr is also identical to the one in the gturbo - sr .",
    "however , gturbo - sr only considers the sensing matrix @xmath2 as a partial dft matrix , while general matrices can be applied in the gec - sr .",
    "if we replace @xmath2 by a partial dft matrix in the gec - sr , the gec - sr is reduced to the gturbo - sr .",
    "in this section , we show the se equations of the gec - sr . from the statistical mechanics perspective , the iterative procedure of the gec - sr is equivalent to finding the saddle points of the free energy defined by @xmath77 the calculation of @xmath78 is very difficult .",
    "fortunately , the replica method from statistical physics provides a highly sophisticated procedure to address this calculation . in the calculation",
    ", we use the assumptions that @xmath79 while keeping @xmath80 fixed and finite .",
    "only the final analytical results in proposition 1 are shown because of space limitation .",
    "proposition 1 involves several new parameters .",
    "most parameters ( except for some auxiliary parameters ) can be illustrated systematically by a scalar channel @xmath81 where @xmath82 .",
    "the mmse estimate of ( [ eq34 ] ) is given by @xmath83 where @xmath84 and @xmath85 .",
    "we define the mmse of this estimator as @xmath86 where the expectation is taken over the joint distribution @xmath87 .",
    "if @xmath88 follows the bernoulli - gaussian distribution ( [ eq2 ] ) , @xmath89 can be obtained explicitly @xcite @xmath90 for ease of expressions , we define two auxiliary equations : @xmath91 where @xmath92 is the eigenvalues of @xmath93 , the expectation with respect to @xmath92 is defined by @xmath94 , @xmath95 will be given in proposition 1 , and @xmath96 have been defined in ( [ eq : defpxpz ] ) .",
    "in addition , we denote @xmath97 .",
    "the saddle points of the free energy can be obtained by @xmath98 @xmath99    as @xmath100 , @xmath101 converges to a saddle point of the free energy .",
    "the above iterative expressions also correspond to the ses of the gec - sr in algorithm 1 .",
    "in particular , @xmath102 represents the mse of @xmath103 .    if @xmath2 is obtained by the random selection of a set of rows from the standard dft matrix , then @xmath2 is the row - orthogonal matrix with eigenvalues @xmath104 for @xmath105 . by combining all the coupled equations ,",
    "we finally obtain @xmath106 the above iterative equations agree with those in the gturbo - sr @xcite .",
    "in this section , we conduct numerical experiments to verify the accuracy of our analytical results . in all the cases , we consider the recovery @xmath0 from the quantized output @xmath41 constructed from ( [ eq10 ] ) , where @xmath0 is drawn i.i.d . , zero - mean bernoulli - gaussian with @xmath107 . the noise level @xmath108 is set as @xmath109 . the metric mse is defined as @xmath110 we use the typical uniform quantizer with quantization step size @xmath111 , where @xmath38 is the quantization resolution .",
    "the simulation results are obtained by averaging over @xmath112 realizations .",
    "are set as @xmath113 $ ] with @xmath114 , @xmath115 , and @xmath116 .",
    ", width=336 ]        figure [ fig.sim.gec ] plots the average mses achieved by the gec - sr and the theoretical result derived by the replica method under a general matrix .",
    "we constructed @xmath117 from the singular value decomposition @xmath118 , where unitary matrices @xmath119 and @xmath120 are drawn uniformly with respect to the haar measure .",
    "the singular values are set as @xmath113 $ ] with @xmath114 , @xmath115 , and @xmath116 .",
    "figure [ fig.sim.se ] shows the corresponding mses of algorithm 1 , gturbo - sr @xcite , and initial gec @xcite with partial dft sensing matrix under different quantization levels . for comparison",
    ", the simulation scenarios completely follow those presented in @xcite , where the system parameters are set as follows : @xmath121 , @xmath122 , and @xmath123 .",
    "the figure clearly demonstrates that the gec - sr is identical to the gturbo - sr when partial dft is considered , and the se analysis precisely predicts the per iteration performance . in addition , the gec - sr is superior to the initial gec because of the different update manner .",
    "in this paper , we developed a computationally feasible signal recovery approximation scheme called gec - sr for nonlinear measurements affected by quantization .",
    "we showed that the performance of the gec - sr is superior to initial gec for general sensing matrices , and the gec - sr is reduced to gturbo - sr for partial dft sensing matrices .",
    "finally , we presented the se analysis to precisely describe the asymptotic behavior of the gec - sr algorithm .",
    "y.  shiraki and y.  kabashima , `` typical reconstruction limits for distributed compressed sensing based on @xmath124 minimization and bayesian optimal reconstruction , '' _",
    "j. statist .",
    "_ , no .  5 , p.  p05029 , 2015 .",
    "f.  krzakala , m.  mzard , f.  sausset , y.  sun , and l.  zdeborov , `` probabilistic reconstruction in compressed sensing : algorithms , phase diagrams , and threshold achieving matrices , ''",
    "_ j. statist .",
    "_ , no .  8 , p.  p08009 , 2012 .        t.  liu , c.  k. wen , s.  jin , and x.  you , `` generalized turbo signal recovery for nonlinear measurements and orthogonal sensing matrices , '' in _ proc . ieee int",
    "inf . theory ( isit ) _ , pp .",
    "28832887 , jul .",
    "2016 .",
    "a.  fletcher , m.  sahraee - ardakan , s.  rangan , and p.  schniter , `` expectation consistent approximate inference : generalizations and convergence , '' in _ proc .",
    "theory ( isit ) _ , pp .  190194 , jul .",
    "2016 . c.  e. rasmussen and c.  k.  i. williams , _",
    "gaussian processes for machine learning_. cambridge , ma , usa : mit press , 2006 .",
    "c.  k. wen , c.  j. wang , s.  jin , k.  k. wong , and p.  ting , `` bayes - optimal joint channel - and - data estimation for massive mimo with low - precision adcs , '' _ ieee trans . signal process .",
    "_ , vol .  64 , no .  2 , pp .",
    "25412556 , may 2016 ."
  ],
  "abstract_text": [
    "<S> in this paper , we propose a generalized expectation consistent signal recovery algorithm to estimate the signal @xmath0 from the nonlinear measurements of a linear transform output @xmath1 . </S>",
    "<S> this estimation problem has been encountered in many applications , such as communications with front - end impairments , compressed sensing , and phase retrieval . </S>",
    "<S> the proposed algorithm extends the prior art called generalized turbo signal recovery from a partial discrete fourier transform matrix @xmath2 to a class of general matrices . </S>",
    "<S> numerical results show the excellent agreement of the proposed algorithm with the theoretical bayesian - optimal estimator derived using the replica method .    </S>",
    "<S> compressed sensing , signal recovery , quantization , state evolution , replica method . </S>"
  ]
}