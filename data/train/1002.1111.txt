{
  "article_text": [
    "the bayesian approach  @xcite to inference plays an increasingly important role in particle physics research .",
    "this is due , in part , to a better understanding of bayesian reasoning within the field and the concomitant abating of the frequentist / bayesian debate .",
    "moreover , the small but growing number of successful applications provide concrete examples of how the bayesian approach fares in practice .    in spite of these successes",
    "the specification of priors in a principled way remains a conceptual and practical hurdle .",
    "in the so - called subjective bayesian approach  @xcite , one is invited to elicit the prior based on one s actual beliefs about the unknown parameters in the problem .",
    "if one has well - understood information , for example based on subsidiary measurements or simulation studies , one can encode this partial information in an evidence - based prior  @xcite .",
    "such priors generally occasion little or no controversy . on the other hand ,",
    "if one knows little about a given parameter , or if one prefers to act as if one knows little , then it is far from clear how one ought to encode this minimal information in a prior probability .",
    "since there is , in fact , no unique way to model prior ignorance , a viewpoint has evolved in which this lack of knowledge is represented by one s willingness to _ adopt _ a standard prior for certain parameters  @xcite , just as one has adopted a standard for quantities such as length and weight . in this spirit ,",
    "our field adopted as a convention a uniform ( flat ) prior for unknown cross sections and other parameters ( see for example ref .",
    "@xcite ) , mainly because this prescription is simple to implement and seems to embody laplace s principle of insufficient reason .",
    "unfortunately , uniform priors are both conceptually and practically flawed .",
    "the conceptual difficulty is with their justification : lack of knowledge about a parameter @xmath0 implies lack of knowledge about any one - to - one transform @xmath1 of @xmath0 , and yet a prior distribution that is uniform in @xmath0 will not be so in @xmath1 if the transform is non - linear .",
    "the practical problem is that careless use of uniform priors can lead to improper posteriors , that is , posteriors whose integrals are infinite and which can therefore not be used to assign meaningful probabilities to subsets of parameter space .",
    "an example of this pathology is found in a common method for reporting the exclusion of a new physics signal , where one estimates an upper limit from a posterior distribution for the signal s production cross section . when constructed from a poisson probability mass function for the observations , a flat prior for the signal cross section , and a truncated gaussian prior for the signal acceptance ,",
    "this posterior is actually improper .",
    "however , for small acceptance uncertainties the divergence of the upper limit is often concealed by the inevitable truncation of numerical computations  @xcite .",
    "the specification of priors that encode minimal information is of such importance in practice that a large body of literature exists describing attempts to construct priors that yield results with provably useful characteristics .",
    "these priors are typically arrived at using formal rules . in this paper , therefore , we refer to them as _ formal priors _",
    "@xcite to distinguish them from evidence - based priors .",
    "many such formal rules exist  @xcite . in this paper",
    "we study , and then recommend , a rule which is arguably the most successful : that developed by bernardo  @xcite and berger and bernardo  @xcite .",
    "formal priors constructed according to the bernardo - berger rule are called _ reference priors _ , a somewhat unfortunate name given that the term reference prior is sometimes used as a synonym for what we have called a formal prior .",
    "reference priors have been shown to yield results with several desirable properties , all of which should appeal to particle physicists . therefore , in principle such priors could be a foundation for bayesian inference in particle physics research",
    ". however , reference priors and the associated methods collectively referred to as reference analysis  @xcite have yet to enter the field in a significant way .",
    "the purpose of this paper is to initiate this process by applying the bernardo - berger method to a familiar , but important class of problems , namely that of calculating posterior densities for signal cross sections .    in the next section",
    "we describe the general goals of reference prior construction and show how these are implemented via the concept of missing information . for simplicity",
    "we limit that discussion to one - parameter problems .",
    "section  [ inclpartinfo ] then considers the treatment of nuisance parameters about which prior information is available .",
    "examples of such parameters include detector calibration constants , background contaminations , geometrical acceptances , and integrated luminosities .",
    "we describe two methods for handling these parameters , depending on the type of information that is available about them .",
    "these methods are then applied to counting experiments with uncertain background contamination and effective luminosity . in the simplest cases we have obtained analytical expressions for the marginal posterior for the quantity of interest . for the general case",
    "we have developed a numerical algorithm .",
    "some appealing properties of these posteriors are examined in sec .",
    "[ validationstudies ] . in sec .",
    "[ singletop ] the reference prior methodology is applied to a recent measurement of the production cross section for single top quarks at the tevatron .",
    "final comments are presented in sec .",
    "[ finalcomments ] .",
    "in 1979 , bernardo  @xcite introduced a formal rule for constructing what he called a reference prior .",
    "the goal was to construct a prior which , in a sense to be made precise , contained as little information as possible relative to the statistical model under consideration .",
    "by statistical model he meant a representation of the entire experimental design , including the probability distribution of the data , the sampling space , and the stopping rule .",
    "hence , by construction reference priors depend on all these aspects of a statistical model , and so will inferences derived from data with the help of a reference prior .",
    "this may seem to violate the so - called _ likelihood principle _",
    "@xcite , according to which all the information about unknown model parameters obtainable from an experiment is contained in the likelihood function , i.e. the probability distribution of the data , evaluated at the observations and viewed as a function of the parameters .",
    "while this is formally true , it should be kept in mind that the likelihood principle applies after data have been observed , whereas reference priors are constructed at the experimental design stage .",
    "their purpose is to approximate a consensus of opinions that is suitable for scientific communication .",
    "this is generally unproblematic in large - sample situations , where posterior inferences are dominated by the likelihood function . in small sample cases",
    "however , results obtained with reference priors should be considered preliminary , and a careful study should be conducted of the degree to which inferences about the physics model underlying the observations can be trusted .",
    "this can be achieved by examining the sensitivity of the results to changes in the prior , and subsequently assessing the need for additional observations .",
    "reference priors have several desirable properties , including    1 .",
    "_ generality : _ a well - defined algorithm exists to create a reference prior for almost any type of estimation problem , and the resulting posterior is proper ; 2 .",
    "_ invariance : _ given a one - to - one map from a parameter @xmath2 to a parameter @xmath3 , applying the reference prior construction separately to @xmath2 and @xmath3 yields posteriors that are related by the correct transformation law , @xmath4 ; 3 .",
    "_ sampling consistency : _ the posterior densities from an ensemble of experiments tend to cluster around the true values of the parameters ; and 4 .",
    "_ coherence : _ inferences derived from reference priors avoid marginalization paradoxes .",
    "marginalization paradoxes  @xcite arise in multiparameter problems when a posterior density can be calculated in different ways that ought to give the same answer but do not ( see fig .  [",
    "fig : mparadox ] ) .",
    "be a dataset modeled by the probability density @xmath5 , where @xmath2 and @xmath3 are unknown parameters , and consider the following two paths to a posterior density for @xmath2 . in path  1 , we use a formal prior @xmath6 to construct the joint posterior for @xmath2 and @xmath3 , and then integrate out @xmath3 .",
    "suppose that the result of this operation only depends on the data @xmath7 through the statistic @xmath8 ; this gives us @xmath9 .",
    "for path  2 , assume further that the sampling distribution of @xmath8 only depends on @xmath2 .",
    "we can then directly construct a posterior for @xmath2 , say @xmath10 .",
    "a marginalization paradox occurs if @xmath11 regardless of the choice of prior @xmath12 in path  2 .",
    "[ fig : mparadox ] , width=566 ]    this incoherence does not happen with subjective or evidence - based priors because these priors are always proper . with formal priors",
    "however , it can only be avoided by allowing the joint prior for all the parameters in a given statistical model to depend on the quantity of interest .",
    "this is in fact what the reference prior construction does . for a simple illustration ,",
    "consider @xmath13 measurements @xmath14 from the normal model with unknown mean @xmath15 and standard deviation @xmath0 .",
    "the likelihood function is : @xmath16 where @xmath17 and @xmath18 .",
    "when @xmath15 is the quantity of interest , the reference prior derived from this likelihood is @xmath19 .",
    "restricting the remaining calculations to the case @xmath20 for convenience , the joint reference posterior for @xmath15 and @xmath0 is then : @xmath21 integrating out @xmath0 yields the marginal @xmath15-posterior , which is a cauchy distribution with location parameter @xmath22 and scale parameter @xmath23 .",
    "suppose however that our interest lies in the standardized mean @xmath24 . in a non - reference approach",
    "one would perform the transformation @xmath25 in eq .   and integrate out @xmath0 in order to obtain the marginal @xmath2-posterior .",
    "the latter only depends on the data through the statistic @xmath26 : @xmath27     \\;=\\;p(\\theta\\,|\\,t ) , \\label{eq : phipost}\\ ] ] where @xmath28 is the error function .",
    "furthermore , the sampling distribution of @xmath8 turns out to depend on @xmath2 only and is a noncentral student s @xmath8 distribution for one degree of freedom and with noncentrality parameter @xmath2 : @xmath29 .",
    "\\label{eq : tsamplingdis}\\ ] ] it is clear that there exists no prior ( no function of @xmath2 only ) that , multiplied by the likelihood  , leads to the posterior  . hence the marginalization paradox : someone who is only given the data value of the statistic @xmath8 will be able to make inferences about the parameter @xmath2 , but these inferences are guaranteed to disagree with those previously made by the bayesian who had access to the full dataset .",
    "resolution of this paradox hinges on the realization that lack of information about @xmath15 is not the same as lack of information about @xmath2 .",
    "therefore , the choice of which quantity is of interest must be done _ before _ calculating the prior . since",
    "reference priors are derived from the likelihood function , the latter must first be expressed in terms of the relevant parameters , @xmath2 and @xmath0 : @xmath30 applying the reference algorithm to this likelihood while treating @xmath2 as the quantity of interest yields the prior @xmath31 , which is very different from the prior @xmath19 obtained by treating @xmath15 as the quantity of interest .",
    "the resulting reference posterior suffers no marginalization problems .",
    "further details about this example can be found in refs .",
    "@xcite .",
    "our discussion of marginalization also helps to clarify the behavior of reference posteriors under transformations in the multiparameter setting .",
    "reference posteriors are invariant under one - to - one transformations of the parameter of interest , but not under transformations that redefine the parameter of interest by mixing in one or more nuisance parameters . however , redefining the nuisance parameters is permitted .",
    "suppose for example that @xmath32 is the parameter of interest , @xmath33 the nuisance parameter(s ) , and consider an invertible transformation of the form @xmath34 , where @xmath35 is a function of both @xmath32 and @xmath33 .",
    "then the reference posterior for @xmath32 is unchanged by the transformation .",
    "reference priors on unbounded parameter spaces are usually improper , which invalidates the application of bayes theorem . to circumvent this problem",
    "one introduces a nested sequence of compact subsets @xmath36 of the parameter space @xmath37 , such that @xmath38 as @xmath39 . given an improper prior @xmath40 , its restriction to @xmath41 will be proper , so that bayes theorem can be applied to construct the corresponding restricted posterior @xmath42 .",
    "the unrestricted posterior for the entire parameter space is then defined by the limit of the @xmath42 as @xmath39 .",
    "the practical justification for this procedure is that one often knows the shape , but not the size , of the physical region of parameter space where the prior has nonzero weight . as",
    "this size is typically very large , the limiting posterior can be viewed as an approximation to the posterior on the physical region .",
    "interestingly , the limiting posterior can also be obtained by direct , formal application of bayes theorem to the improper prior @xmath40 , provided the marginal distribution of the data , @xmath43 is finite .",
    "it can then be shown that the restricted posteriors @xmath42 converge _ logarithmically _ to their limit @xmath44 : @xmath45\\;=\\;0,\\ ] ] where @xmath46\\;\\equiv\\ ; \\int\\!q(\\theta)\\,\\log\\frac{q(\\theta)}{p(\\theta)}\\,d\\theta\\ ] ] is the kullback - leibler divergence between @xmath47 and @xmath48 .",
    "this divergence is a parametrization - independent , non - negative measure of the separation between two densities ; it is zero if and only if the densities are identical .",
    "unfortunately , pointwise logarithmic convergence is not enough to avoid inferential inconsistency in some special cases  @xcite , so that a stronger form of convergence is needed , _ expected _ logarithmic convergence : @xmath49\\bigr\\}\\;=\\;0,\\ ] ] where the expectation is taken with respect to the marginal density @xmath50 .",
    "the above discussion motivates the following terminology  @xcite .",
    "given a statistical model on a parameter space @xmath37 , a _",
    "standard prior _ is a strictly positive and continuous function on @xmath37 that yields a proper posterior .",
    "permissible prior _ is a standard prior for which the posterior is the expected logarithmic limit of a sequence of posteriors defined by restriction to compact sets .",
    "reference priors make use of the notion of expected intrinsic information . for one observation from a model @xmath51 , the expected intrinsic information about the value of @xmath2 when the prior is @xmath40 is given by the functional @xmath52 \\bigr\\}. \\label{eq : xii}\\ ] ] the more informative the observation , the greater the expected separation between the posterior and the prior . the larger this separation , the greater the expected intrinsic information @xmath53 .",
    "thus , @xmath53 measures the amount of information about the value of @xmath2 that might be expected from one observation when the prior is @xmath40 .",
    "suppose next that we make @xmath54 independent observations @xmath55 from the model @xmath51 .",
    "the definition of expected intrinsic information can be generalized to include all @xmath54 observations : @xmath56 \\bigr\\ } , \\label{eq : xii2}\\ ] ] where the expectation is a @xmath54-dimensional integral over @xmath57 weighted by : @xmath58\\;\\pi(\\theta)\\,d\\theta.\\ ] ] as the sample size @xmath54 grows larger , one expects the amount of information about @xmath2 to increase , and in the limit @xmath59 , the true value of @xmath2 would become exactly known . in this sense , the limit @xmath60 represents the _ missing _ information about @xmath2 when @xmath40 is the prior .",
    "this concept of missing information is central to the construction of reference priors .",
    "the goal of reference analysis is to contruct a prior that maximizes the missing information .",
    "this maximization can not be done directly however , because @xmath61 typically diverges . to avoid this problem ,",
    "one first constructs the prior @xmath62 that maximizes @xmath63 , and then takes the limit of @xmath62 as @xmath59 .",
    "additional care is required when the parameter space @xmath37 is unbounded , since in that case the prior that maximizes @xmath63 is often improper , and @xmath63 is undefined for improper priors .",
    "the solution is to define reference priors via their restrictions on arbitrary compact subsets @xmath41 of @xmath37 .",
    "thus one is led to the formal definition of a reference prior for @xmath2 as any permissible prior @xmath64 that satisfies the so - called maximizing missing information ( mmi ) property , namely that @xmath65 \\;\\ge\\;0 \\label{eq : refdef}\\ ] ] for any compact set @xmath41 and candidate prior @xmath40 , where @xmath66 and @xmath67 are the renormalized restrictions of @xmath68 and @xmath69 to @xmath41 . a candidate prior is a standard prior that incorporates any prior knowledge about @xmath2 .",
    "a key result is the following constructive definition of the reference prior @xmath64  @xcite , @xmath70\\ ,                  dx_{(k)}\\right\\ } , \\label{eq : refformula}\\end{aligned}\\ ] ] where @xmath71 is an arbitrary fixed point in @xmath37 , @xmath72 is any continuous , strictly positive function , such as @xmath73 , and @xmath74 is the probability model for a sample of @xmath54 independent observations .",
    "we emphasize that this constructive definition only guarantees that the mmi property   is satisfied .",
    "the permissibility part of the reference prior definition must be separately verified .",
    "however , the proponents of reference priors view the mmi property as considerably more important than permissibility  @xcite , and also believe that it would be highly unusual for a prior satisfying the mmi property to fail permissibility  @xcite ( counter - examples are known , but they are rather exotic ) .",
    "a further useful result that we shall exploit is that , when certain regularity conditions are met  essentially those that guarantee asymptotic normality of the posterior  the reference prior for models with one continuous parameter reduces to the well - known jeffreys prior  @xcite , @xmath75 } , \\label{eq : jpr}\\ ] ] where the expectation is taken with respect to the sampling model @xmath76 . in general the analytical derivation of reference priors",
    "can be extremely challenging . however , eq",
    ".   is amenable to numerical integration  @xcite .",
    "we emphasize that the definition and results described in this section apply only to the case where the model of interest depends on a single parameter .",
    "a generalization to the multi - parameter case has been formulated and shown to have the properties listed at the beginning of sec .",
    "[ sec : refpriors ]  @xcite .",
    "we shall not describe it here however , except for when evidence - based priors are specified for the additional parameters .",
    "this is a very common situation in high energy physics , and will be discussed next .",
    "the reference prior algorithm described in sec .",
    "[ sec : refprior ] pertains to models containing no nuisance parameters . in practice , however , every non - trivial problem must contend with such parameters and the reference prior algorithm must be generalized accordingly . in this paper",
    "we restrict our attention to nuisance parameters for which partial information is available , which is often the case in practice .    depending on the type of partial information that is available",
    ", there are two plausible ways one might choose to incorporate nuisance parameters @xmath3 into the calculation of the reference priors for a parameter of interest @xmath2  @xcite :    method 1 : : :    assume that we are given a marginal prior @xmath77 for    the nuisance parameters ; compute the conditional reference prior    @xmath78 for the interest parameter    given a fixed value of @xmath3 ; the full prior is then    @xmath79 ; method 2 : : :    assume that we are given a conditional prior    @xmath80 for the nuisance parameter given    the interest parameter ; marginalize the probability model    @xmath81 with respect to @xmath3 in    order to obtain    @xmath82 ,    and compute the reference prior @xmath64 for the    marginalized model ; the full prior is then    @xmath83",
    ".    in many high energy physics measurements there are often sound reasons for assuming that the nuisance parameter is independent of the parameter of interest .",
    "information about a detector energy scale , for example , is typically determined separately from the measurement of interest , say of a particle mass , and is therefore considered to be independent _ a priori _ from one s information about the particle s mass . when an experimenter is willing to make this assumption , he or she can declare that @xmath84 and use method 2 .",
    "when this assumption does not seem fully justified , and it is too difficult to elicit the @xmath2 dependence of @xmath80 , then it will seem preferable to use method 1 , which only requires knowledge of the marginal prior @xmath77 .",
    "when one is unsure of which method to use , one should use both , and treat the results as part of a test of robustness .",
    "an important practical advantage of method 1 is that the conditional reference prior is computed once and for all , for a given model , and can be used with any evidence - based prior for the nuisance parameters .",
    "in contrast , for method 2 the reference prior must be computed anew every time the priors for the nuisance parameters change . on the other hand , since method 2 reduces the problem to one involving a single parameter , the reference prior algorithm reduces to jeffreys rule  , which is typically easier to implement .    in the next section",
    "we introduce the basic model studied in this paper , and follow with the application of methods  1 and  2 to that model .",
    "a very common model for high energy physics measurements is the following .",
    "a number of events @xmath85 is observed by some apparatus , and it is assumed that @xmath85 is poisson distributed with mean count @xmath86 , where @xmath0 is the rate of a physics signal process , typically the cross section , which we detect with an effective integrated luminosity @xmath87  that is , the integrated luminosity scaled by the signal efficiency , and @xmath15 is a background contamination .",
    "thus , @xmath0 is the parameter of interest , whereas @xmath87 and @xmath15 are nuisance parameters for which we usually have partial information . for",
    "physical reasons none of these three parameters can be negative .",
    "we write the likelihood for this model as @xmath88 information about @xmath87 and @xmath15 usually comes from a variety of sources , such as auxiliary measurements , monte carlo simulations , theoretical calculations , and evidence - based beliefs ( for example , some sources of background contributing to @xmath15 may be deemed small enough to ignore , and some physics effects on @xmath87 , such as gluon radiation , may be believed to be well enough reproduced by the simulation to be reliable `` within a factor of 2 '' ) .",
    "it is therefore natural to represent that information by an evidence - based prior . here",
    "we will assume that @xmath87 and @xmath15 are independent of @xmath0 and that their prior factorizes as a product of two gamma densities : @xmath89 where @xmath90 , @xmath91 , @xmath92 , and @xmath93 are known constants , related to the means @xmath94 , @xmath95 and coefficients of variation @xmath96 , @xmath97 by : @xmath98 the built - in assumption that @xmath87 and @xmath15 are uncorrelated is clearly an approximation , since they share a dependence on the integrated luminosity , which is itself uncertain .",
    "there are two ways of interpreting this prior .",
    "the first one is appropriate when information about @xmath87 and @xmath15 comes from one or more non - experimental sources , such as monte carlo studies and theoretical calculations , and takes the form of a central value plus an uncertainty .",
    "since the @xmath87 and @xmath15 components of the prior are each modeled by a two - parameter density , one can fix the shape of this density in each case by matching its mean with the central value of the corresponding measurement and its standard deviation with the uncertainty .",
    "it will then be necessary to check the robustness of the final analysis results to reasonable changes in this procedure .",
    "for example , one may want to replace the gamma distribution by a log - normal or truncated gaussian one , and the mean by the mode or median .",
    "the second interpretation of prior   follows from the analysis of two independent , auxiliary poisson measurements , in which the observed number of events is @xmath92 for the effective luminosity and @xmath93 for the background .",
    "the expected numbers of events in these auxiliary measurements are @xmath99 and @xmath100 , respectively . for a poisson likelihood with mean @xmath99",
    "the reference prior coincides with jeffreys prior and is proportional to @xmath101 . given a measurement @xmath92 ,",
    "the posterior will then be a gamma distribution with shape parameter @xmath102 and scale parameter @xmath103 .",
    "a similar result holds for the background measurement . in this manner",
    "the prior   is obtained as a joint reference posterior from two auxiliary measurements .",
    "the problem we are interested in is finding a prior for @xmath0 , about which either little is known or one wishes to act as if this is so .",
    "this section serves two purposes : to illustrate the analytical algorithm for computing reference priors and to apply method  1 to model  .    in method 1  @xcite",
    ", we find first the conditional reference prior @xmath104 and then multiply by the evidence - based prior @xmath105 to construct the full prior @xmath106 . as will be illustrated in sec .",
    "[ validationstudies ] , the single - count model is regular enough to warrant using jeffreys rule in the first step of the calculation of @xmath104 .",
    "we therefore apply eq .   to the @xmath0 dependence of the likelihood  , while holding @xmath87 and @xmath15 constant ; this yields : @xmath107 }      \\;\\propto\\ ; \\frac{\\epsilon}{\\sqrt{\\epsilon\\,\\sigma+\\mu}}. \\label{eq : pij}\\ ] ] this prior is clearly improper with respect to @xmath0 and is therefore only defined up to a proportionality constant .",
    "however , this constant could very well depend on @xmath87 and @xmath15 , since we kept these parameters fixed in the calculation .",
    "it is important to obtain this dependence correctly , as examples have shown that otherwise inconsistent bayes estimators may result .",
    "reference  @xcite proposes a compact subset normalization procedure .",
    "one starts by choosing a nested sequence @xmath108 of compact subsets of the parameter space @xmath109 , such that @xmath110 and the integral @xmath111 of @xmath112 over @xmath113 is finite .",
    "the conditional reference prior for @xmath0 on @xmath114 is then @xmath115 to obtain the conditional reference prior on the whole parameter space , one chooses a fixed point @xmath116 within that space and takes the limit of the ratio @xmath117 by taking the limit in this ratio form , one avoids problems arising from @xmath111 becoming infinite as @xmath39 .",
    "the theory of reference priors currently does not provide guidelines for choosing the compact sets @xmath41 , other than to require that the resulting posterior be proper .",
    "in most cases this choice makes no difference and one is free to base the choice of compact sets on considerations of simplicity and convenience .",
    "however , we have found that some care is required with the single - count model . indeed , suppose we make the plausible choice @xmath118,\\ ; \\epsilon\\in[0,v_{\\ell}],\\ ; \\mu\\in[0,w_{\\ell}]\\bigr\\ } , \\label{eq : cset1}\\ ] ] where @xmath119 , @xmath120 , and @xmath121 are increasing sequences of positive constants . if we use these sets in applying eqs .   and   to the prior",
    ", we obtain : @xmath122 although this prior is still improper with respect to @xmath0 , its dependence on @xmath87 is different from that of the conditional jeffreys prior , eq .  .",
    "this demonstrates the potential importance of the compact subset normalization . the prior in eq .",
    "has a serious problem however .",
    "suppose that the @xmath87 marginal of our evidence - based prior for @xmath87 and @xmath15 is @xmath123 .",
    "it is then easy to verify that the resulting posterior is improper , since its @xmath87 marginal has the non - integrable form @xmath124 .",
    "the cause of this problem is the choice of compact sets  .",
    "fortunately it is not difficult to find a sequence of compact sets that will provide a proper posterior .",
    "indeed , the @xmath0 dependence of the prior   suggests that the compact sets should be based on the parametrization @xmath125 rather than @xmath126  @xcite .",
    "we therefore set : @xmath127,\\;\\epsilon\\in[1/v_{\\ell},v_{\\ell}],\\ ;   \\mu\\in[0,w_{\\ell}]\\bigr\\ } , \\label{eq : ncs2}\\ ] ] where @xmath128 , @xmath129 , and @xmath130 are as before . again using eqs .",
    ", , and  , we now find : @xmath131 which is identical to jeffreys prior for this problem and yields well - behaved posteriors . for future use",
    ", the subscript @xmath132 on the left - hand side indicates that this reference prior was obtained with method  1 .",
    "we now have all the ingredients needed to calculate the marginal reference posterior @xmath133 for the cross section @xmath0 : the likelihood  , the marginal nuisance prior  , and the conditional reference prior  . for calculating posterior summaries in terms of intervals and upper limits it is convenient to express the result as a tail probability : @xmath134 where @xmath135 is the incomplete beta function , and @xmath136 .",
    "in contrast with method  1 , method  2 requires from the start that we specify the evidence - based prior for the effective integrated luminosity @xmath87 and the background contamination  @xmath15 .",
    "furthermore , this specification must be done conditionally on the signal rate @xmath0 .",
    "as mentioned earlier , we will use expression   for this prior .",
    "the next step in the application of method  2 is to marginalize the probability model   with respect to @xmath87 and @xmath15 : @xmath137              & \\;=\\;\\iint \\frac{(\\epsilon\\sigma+\\mu)^{n}}{n!}\\ ;                    e^{-\\epsilon\\sigma-\\mu}\\ ;                    \\frac{a(a\\epsilon)^{x-\\frac{1}{2}}}{\\gamma(x+\\frac{1}{2})}\\ ;                    e^{-a\\epsilon}\\ ;                    \\frac{b(b\\mu)^{y-\\frac{1}{2}}}{\\gamma(y+\\frac{1}{2})}\\ ;                    e^{-b\\mu}\\;d\\epsilon\\,d\\mu,\\nonumber\\\\[2 mm ]              & \\;=\\;\\left[\\frac{a}{a+\\sigma}\\right]^{x+\\frac{1}{2}}\\ ;                    \\left[\\frac{b}{b+1}\\right]^{y+\\frac{1}{2}}\\ ; s_{n}^{0}(\\sigma ) , \\label{eq : marginalmodel}\\end{aligned}\\ ] ] where @xmath138^{n - k}\\ ; \\left[\\frac{\\sigma}{a+\\sigma}\\right]^{k},\\ ] ] and the binomial coefficients are expressed in terms of gamma functions to accomodate noninteger values of their arguments .",
    "finally , the reference prior algorithm must be applied to the marginalized model @xmath139 . as in the case of method 1 , the conditions for applying jeffreys rule are satisfied here ; we therefore obtain : @xmath140^{2 } }       { ( a+\\sigma)^{x+5/2}\\;s_{n}^{0}(\\sigma)}}. \\label{eq : pir2}\\ ] ] we will use the notation @xmath141 to refer to the marginal reference prior for @xmath0 obtained with method  2 .",
    "note that the compact subset argument invoked in the construction of the method  1 reference prior is not needed here because all the parameters other than @xmath0 have already been eliminated by marginalization .    for method  2 the marginal reference posterior for @xmath0",
    "is proportional to the product of the marginal data probability distribution   and the marginal reference prior  : @xmath142 the normalization of @xmath143 must be obtained numerically .",
    "an important generalization of the single - count model is obtained by considering @xmath144 replications of the latter ; the likelihood is : @xmath145 to obtain the method  1 reference prior for this model , we first calculate jeffreys prior for @xmath0 , while keeping @xmath146 and @xmath147 fixed : @xmath148 this prior is improper , requiring us to apply the compact subset normalization described in sec .",
    "[ method1singlecount ] . using a straightforward generalization of the nested compact sets of eq .",
    ", we find that the correct reference prior is identical to jeffreys prior .    in order to apply method  2",
    ", we need to specify a proper conditional prior for the @xmath149 and @xmath150 given @xmath0 .",
    "neglecting correlations , we set : @xmath151 the marginalized data probability distribution @xmath152 is then a product of expressions of the form  , one for each count @xmath153 .    here",
    "we no longer attempt to obtain analytical expressions for the method  1 and  2 reference posteriors .",
    "instead , we use the numerical algorithms described below .",
    "in this section we describe numerical algorithms that can be used to compute method  1 or  2 reference posteriors for the single- and multiple - count poisson likelihoods discussed in the previous sections .    for method",
    "1 the algorithm starts by generating @xmath154 triplets from the `` flat - prior posterior '' , i.e. the posterior obtained by setting @xmath155 ( line  3 in the pseudo - code below ) ; the correct reference prior @xmath156 is then computed at lines  47 and is used at line  9 to weight the generated @xmath0 values so as to produce the reference posterior :    =  =  =  = set @xmath157 to the array of observed event numbers .",
    "+ for @xmath158 : + generate @xmath159 . + for @xmath160 : + generate @xmath161 .",
    "+ calculate @xmath162/d\\sigma_{i}^{2}$ ] by numerical differentiation .",
    "+ average the @xmath163 values of @xmath164/d\\sigma_{i}^{2}$ ] obtained + at line 6 , and take the square root .",
    "this yields a numerical + approximation to the conditional jeffreys prior @xmath165 .",
    "+ histogram the @xmath166 values generated at line 3 , weighting them by + @xmath167 .",
    "this yields @xmath168 , the @xmath0-marginal prior .",
    "+ histogram the @xmath166 values generated at line 3 , weighting them by + @xmath165 .",
    "this yields @xmath169 , the @xmath0-marginal posterior .",
    "+    although not required for the calculation of the reference posterior , an approximation to the reference prior is provided at line  8 . by construction",
    "this approximation is only reliable for @xmath0 values in the bulk of the flat - prior posterior .",
    "the generation step at line  3 is done via a markov chain monte carlo procedure  @xcite .",
    "the particular choice of sampling distribution for the generated @xmath170 triplets is motivated by the desire to obtain weights with reasonably small variance at steps 8 and 9 .",
    "however , the flat - prior posterior @xmath171 is not always proper with respect to @xmath170 . when @xmath172 ( single - count model ) , it is improper if @xmath173 .",
    "propriety can then be restored by multiplying the flat - prior posterior by @xmath87 and correspondingly adjusting the weights at steps 8 and 9 .",
    "another feature of the above algorithm is that it does not implement the compact subset normalization . in the cases that we examined , this procedure made no difference , but this may not be true for more general problems than those our code seeks to solve .",
    "unfortunately the current lack of guidelines in the choice of compact sets limits our ability to address this issue in the code .",
    "the algorithm for method  2 has a simpler structure , since all it does is apply jeffreys rule to a marginalized likelihood @xmath174 provided by the user .",
    "the calculation does not require random sampling of the parameters and is done at fixed @xmath0 values .",
    "for a given @xmath0 , the reference prior @xmath141 is obtained by monte carlo averaging , over an ensemble of vectors @xmath175 generated from @xmath176 , of an accurate numerical approximation of the second derivative of the negative log - likelihood  @xcite .",
    "as already pointed out , method 2 does not require a compact subset normalization procedure .",
    "the reference posterior is thus proportional to the product of @xmath174 and @xmath141 , and the normalization with respect to @xmath0 must be determined numerically .",
    "we have performed a number of studies to validate inferences from the single - count model , using both the numerical algorithms described in sec .",
    "[ numericalalgorithm ] and analytical expressions we obtained for the marginal method-1 and  2 posteriors for @xmath0 .",
    "to recapitulate , we have two reference priors for this model : @xmath177 \\pi_{r2}(\\sigma,\\epsilon,\\mu ) & \\;=\\ ; \\pi_{r2}(\\sigma)\\ ;                                       \\pi(\\epsilon,\\mu\\,|\\,\\sigma),\\end{aligned}\\ ] ] and we have assumed that @xmath178 at eq .  .",
    "as explained in sec .",
    "[ inclpartinfo ] , this extra assumption affects only the definition of @xmath179 , which therefore incorporates more information than @xmath180 . in the present section we study and compare the properties of these two reference priors . to begin",
    ", we show some example prior and posterior @xmath0 marginals in fig .",
    "[ fig : priormethod12 ] .    .",
    "right : marginal method-1 and 2 posteriors for 0 , 1 , and 4 observed events , together with the posteriors obtained from a flat prior .",
    "the @xmath87 and @xmath15 priors have a mean of 1 and a 20% coefficient of variation ( corresponding to @xmath181 and @xmath182 in eq .  ) . here and in subsequent plots , the units of @xmath0 are arbitrary but consistent with those of @xmath87 ; e.g. , if the latter is expressed in pb@xmath183 , then @xmath0 is given in pb so that , like @xmath15 , the product of @xmath87 and @xmath0 is dimensionless .",
    "[ fig : priormethod12],title=\"fig:\",width=264 ] . right : marginal method-1 and 2 posteriors for 0 , 1 , and 4 observed events , together with the posteriors obtained from a flat prior .",
    "the @xmath87 and @xmath15 priors have a mean of 1 and a 20% coefficient of variation ( corresponding to @xmath181 and @xmath182 in eq .  ) . here and in subsequent plots ,",
    "the units of @xmath0 are arbitrary but consistent with those of @xmath87 ; e.g. , if the latter is expressed in pb@xmath183 , then @xmath0 is given in pb so that , like @xmath15 , the product of @xmath87 and @xmath0 is dimensionless . [",
    "fig : priormethod12],title=\"fig:\",width=264 ]    as expected , posteriors corresponding to a small observed number of events favor small cross sections , and posteriors derived from flat priors put less weight on small cross sections than reference posteriors .",
    "our derivations of the two reference prior methods made use of jeffreys rule . as pointed out in sec .",
    "[ sec : refprior ] , this approach assumes that some regularity conditions are satisfied , such that the resulting posterior is asymptotically normal .",
    "we now wish to verify this assumption with a graphical example . if one adopts the objective bayesian view that the parameters @xmath0 , @xmath87 , and @xmath15 have true values , then the asymptotic limit can be defined as the result of a large number @xmath184 of replications of the measurement , in the limit where that number goes to infinity . for the case where each measurement replication @xmath153 consists of a number of events",
    "@xmath185 drawn from a probability mass function @xmath186 , the reference posterior has the form : @xmath187 and the reference prior @xmath188 is calculated from the combined likelihood for the @xmath184 measurements ; it can also be calculated from a single one of these likelihood functions , since it follows from their constructive definition   that reference priors are independent of sample size . for method 1 the prior",
    "is given by the product of eqs .   and  , and the likelihood component @xmath186 by eq .  .",
    "replicating the measurement @xmath184 times is then equivalent to making a single measurement with a poisson likelihood whose mean is @xmath184 times the original mean , and whose observation is the sum of the @xmath184 original observations @xmath185 .",
    "this property of poisson measurements simplifies the calculations considerably . for method  2 the prior",
    "is given by eq .   and the likelihood by eq .  .",
    "in this case no simplification obtains when considering multiple replications , and numerical calculations must use explicitly the full product of likelihood functions .",
    "is the number of measurement replications and @xmath189 is the observed number of events summed over all replications .",
    "[ fig : m12qq],title=\"fig:\",width=264 ]   is the number of measurement replications and @xmath189 is the observed number of events summed over all replications .",
    "[ fig : m12qq],title=\"fig:\",width=264 ]    figure  [ fig : m12qq ] illustrates the calculations with the help of so - called q - q plots , where recentered quantiles from the reference posterior for @xmath0 are plotted against standard normal quantiles .",
    "the posterior quantiles @xmath190 are recentered according to @xmath191 , where the posterior mean @xmath192 and standard deviation @xmath193 are numerically estimated .",
    "for method  1 we set the true values of @xmath0 , @xmath87 , and @xmath15 to @xmath194 .",
    "we then randomly generate a sequence of 100 independent measurements from the probability mass function   and use the subsequences with @xmath195 , @xmath196 , and @xmath197 to produce the curves in the left panel . for method  2 we set the true value of @xmath0 to 1 and give the priors for @xmath87 and @xmath15 each a mean of 1 and a coefficient of variation of 20% .",
    "measurements are then generated from the probability mass function   in order to compute the curves in the right panel .",
    "both panels clearly show that the respective reference posteriors approach a gaussian shape as the number of measurement replications increases .",
    "given the almost negligible difference between method-1 and 2 posteriors exhibited in fig .",
    "[ fig : priormethod12 ] , and the fact that our analytical results for method  1 are computationally more tractable than those for method  2 , our considerations in the remainder of this section will focus exclusively on method  1 .    among the reference prior properties listed in sec .",
    "[ sec : refpriors ] , the ones of generality , invariance , and coherence are true by construction .",
    "the property of sampling consistency needs more elaboration however , since bayesian inferences do not generally coincide with exact frequentist ones , and a proper evaluation requires first of all the specification of an ensemble of experiments .",
    "a well - known property of bayesian posterior intervals constructed from a proper prior is that their coverage is exact when averaged over the prior  @xcite .",
    "this is an immediate consequence of the law of total probability .",
    "indeed , given a parameter @xmath2 with proper prior @xmath40 , and a measurement @xmath198 , the prior - averaged frequentist coverage of a @xmath199 bayesian credibility interval @xmath200 can be written as : @xmath201 \\,=\\,\\mathbb{p}(\\theta\\in r(x ) ) \\,=\\,\\mathbb{e}_{m}[\\mathbb{p}(\\theta\\in r(x)\\,|\\,x ) ] \\,=\\,\\mathbb{e}_{m}(1-\\alpha)\\,=\\,1-\\alpha,\\ ] ] where the first expectation is over the prior @xmath40 and the second one over the marginal sampling distribution @xmath202 .",
    "when @xmath40 is a reference prior , and especially when it is improper , there is no natural metric over which the coverage can be averaged",
    ". the only sensible approach in that case is to study the coverage pointwise , i.e. as a function of the true value of @xmath2 . since the single- and multiple - count models discussed in this paper combine an improper prior for the parameter of interest @xmath0 with proper priors for the nuisance parameters @xmath146 and @xmath147 , we will study interval coverage for a fixed value of @xmath0 , but averaged over @xmath203 .",
    "our interest is in how this coverage evolves toward the asymptotic limit .",
    "as before , we take this limit in the sense of an ever - increasing number @xmath184 of experiment replications . for a given value of @xmath184 ,",
    "the posterior is formed as in eq .   and",
    "its coverage is computed .    .",
    "the solid lines indicate the nominal credibility .",
    "[ fig : m1coverage_xl],title=\"fig:\",width=264 ] .",
    "the solid lines indicate the nominal credibility .",
    "[ fig : m1coverage_xl],title=\"fig:\",width=264 ]    figure  [ fig : m1coverage_xl ] shows the coverage of 95% credibility upper limits and 68% credibility central intervals as a function of @xmath184 . as the latter increases , the coverage converges to the credibility , confirming the sampling consistency of the method .",
    "finally , we examine the behavior of reference posterior upper limits on @xmath0 as a function of the expected background @xmath95 ( defined in eq .  )",
    "when the observed number of events @xmath13 is small . for comparison ,",
    "when @xmath204 and there are no uncertainties on signal efficiency and background , frequentist upper limits decrease linearly with background . from a bayesian point of view",
    "this result is surprising . indeed ,",
    "when zero events are observed the likelihood function factorizes exactly into background and signal components , indicating that the experiment _ actually _ performed can be analyzed as the combination of two independent experiments , one to measure background and the other signal .",
    "if , in addition , signal and background are _ a priori _ independent , then posterior inferences about signal will be independent of background .",
    "in particular , upper limits on @xmath0 will be constant as a function of @xmath95 , not linearly decreasing .",
    "the reference priors entangle signal and background however , so that upper limits will not be exactly constant .",
    "the @xmath204 case is illustrated in fig .",
    "[ fig : m1ul_meanbg ] for two values of the relative uncertainties on background and signal efficiency .    .",
    "the relative uncertainty on the background and on the effective luminosity is 20% for the left plot and 50% for the right one .",
    "[ fig : m1ul_meanbg],title=\"fig:\",width=264 ] .",
    "the relative uncertainty on the background and on the effective luminosity is 20% for the left plot and 50% for the right one .",
    "[ fig : m1ul_meanbg],title=\"fig:\",width=264 ]    for @xmath205 the likelihood function still factorizes approximately since @xmath206 for @xmath207 .",
    "thus upper limits will flatten out at large @xmath95 , as seen in fig .",
    "[ fig : m1ul_meanbg ] .",
    "a comparison of the left and right panels in that figure also shows that upper limits increase with the uncertainty on background and signal efficiency , as expected .",
    "in this section , we demonstrate the computational feasibility of the methods described above by applying them to the recent measurement of the single top cross section by the d0 and cdf collaborations  @xcite .",
    "both collaborations use the same form of likelihood function  a product of poisson distributions over multiple bins of a multivariate discriminant , the same form of evidence - based priors , namely truncated gaussians , and flat priors for the cross section  @xcite . as a realistic example",
    ", we construct the reference prior for the cross section using one of the data channels considered by d0 .",
    "d0 partitioned their data into 24 channels , defined by lepton flavor ( electron or muon ) , jet multiplicity ( two , three , or four ) , number of @xmath91-tagged jets ( one or two ) , and two data collection periods .",
    "the discriminant distribution is shown in fig .  3 of ref .",
    "@xcite . here",
    "we consider the electron , two - jet , single - tag channel from one of the data taking periods .",
    "the discriminant distribution contains about 500 counts spread over 50 bins , with a maximum bin count of about 40 .     of data .",
    "for comparison we show the posterior density computed using a flat prior ( dotted curve ) .",
    "[ fig : d0results],title=\"fig:\",width=264 ]   of data . for comparison",
    "we show the posterior density computed using a flat prior ( dotted curve ) .",
    "[ fig : d0results],title=\"fig:\",width=264 ]    we model information about the effective integrated luminosity @xmath87 and the background @xmath15 for each bin with the help of the gamma priors of eq .  .",
    "these evidence - based priors describe the uncertainty due to the finite statistics of the monte carlo simulations .",
    "we do not include systematic uncertainties in this example .",
    "figure  [ fig : d0results](a ) shows a comparison of the reference prior for the cross section using methods 1 ( the histogram ) and 2 ( the dashed curve ) .",
    "the jaggedness of the method 1 prior reflects the fluctuations due to the markov chain monte carlo  @xcite sampling of the parameters .",
    "the increased jaggedness at large @xmath0 is due to the fact that the numerical algorithm samples from the flat - prior posterior , whose density rapidly decreases in this region .",
    "it is noteworthy that the priors computed using the two methods are very similar for this particular example .",
    "this is also reflected in the similarity of the posterior densities , shown in fig .",
    "[ fig : d0results](b ) . in principle fluctuations in the calculated posterior can be made arbitrarily small by increasing the size of the monte carlo sample . for reference ,",
    "[ fig : d0results](b ) also shows the posterior density using a flat prior for the cross section .",
    "an obvious conclusion can be drawn : when the dataset is large , here of order 500 events , the precise form of the reference prior is not important .",
    "however , for small datasets  which is typical of searches for new or rare phenomena , one should expect the form of the prior to matter .",
    "it is then important to use a prior with provably useful properties , such as the ones enumerated in sec .",
    "[ sec : refpriors ] .",
    "our main purpose in this paper was to propose a set of formal priors with properties that make them attractive for use in the analysis of high energy physics data . aside from the theoretical properties of invariance , coherence and sampling consistency",
    ", the reference prior method has three important practical advantages : ( 1 ) priors can be defined for almost any problem , regardless of the complexity of the likelihood function and the number of nuisance and interest parameters , ( 2 ) in contrast with flat priors , reference priors have so far always yielded proper posteriors , and ( 3 ) reference priors are computationally tractable , as shown by the single - top example .",
    "here we have limited our numerical investigations to the class of likelihood functions that are derived from poisson probability mass functions .",
    "for this class the method-1 reference prior agrees with jeffreys rule . for other classes",
    "the compact subset normalization argument may introduce a difference .",
    "a possible generalization of our treatment is to unbinned likelihoods .",
    "since our method-1 and 2 numerical algorithms make no assumptions about the likelihood function , they can be generalized to the unbinned case .",
    "however , the method-1 algorithm does not implement the compact subset normalization and is therefore only applicable to cases where this procedure makes no difference .",
    "method  2 requires no compact subset normalization but makes an extra assumption about the conditional nuisance prior .    for problems that involve a single continuous parameter or that can be reduced to this case by a method-2-type integration , ref .",
    "@xcite proposes a numerical algorithm that is based directly on eq .   and is therefore very general .",
    "however we found that this algorithm presents some difficulties for the complicated likelihood functions used in high energy physics .",
    "one difficulty is the round - off error in the product of large numbers of probability densities .",
    "another difficulty is the assessment of the convergence of the integrals in the formula , and of the convergence of the finite - sample priors to the reference prior .",
    "another possible generalization is to problems with more than one parameter of interest , as for example in the measurement of the individual single top production cross sections in the @xmath208 and @xmath8 channels .",
    "for this situation the reference prior algorithm requires one to sort the parameters of interest by order of importance  @xcite , and the results may depend on this ordering .",
    "a possible interpretation of this dependence is that it is a measure of the robustness of the result to the choice of prior .",
    "this is an area that requires more study .      finally , we note that the main ideas underlying the construction of reference priors , namely generality , reparametrization invariance , coherence , and sampling consistency , have motivated the development of methods for summarizing reference posteriors via point estimates , intervals , and hypothesis tests .",
    "this subfield of objective bayesianism is known as reference analysis  @xcite .",
    "we thank the d0 collaboration for its support of this work and for granting us permission to use a channel of its single top data .",
    "we also thank the members of the cms statistics committee for many useful discussions .",
    "this work was supported in part by the u.s .",
    "department of energy under grant nos .",
    "de - fg02 - 91er40651 , de - fg02 - 04er41305 , and de - fg02 - 95er40896 .",
    "99 c.  p.  robert , _ the bayesian choice : from decision - theoretic foundations to computational implementation _",
    "( springer , new york , 2007 ) , 2nd ed . ; e.  t.  jaynes , _ probability theory : the logic of science _ , edited by g.  l.  bretthorst ( cambridge university press , cambridge , 2003 ) ; a.  ohagan , _ kendall s advanced theory of statistics , volume 2b : bayesian inference _ ( edward arnold , london , 1994 ) ; h.  jeffreys , _ theory of probability _ ( oxford university press , oxford , 1961 ) , 3rd ed .      for a discussion of different types of informative priors , see e.g. d.  r.  cox , in _ proceedings of the phystat lhc workshop on statistical issues for lhc physics _ , edited by h.  b.  prosper , l.  lyons , and a.  de  roeck , cern yellow report cern-2008 - 001 ( 2008 ) , pp .  3 - 7 .",
    "there is no agreement on what to call such priors . in the literature",
    "one finds many names : objective , non - subjective , non - informative , minimally - informative , default , neutral , conventional , reference .",
    "however , we prefer the term formal prior because it reflects the manner in which they are constructed .",
    "j.  o.  berger and j.  m.  bernardo , in _",
    "bayesian statistics 4 _ , edited by j.  m.  bernardo , j.  o.  berger , a.  p.  dawid , and a.  f.  m.  smith ( oxford university press , oxford , 1992 ) , pp .",
    "35 - 60 , http://www.uv.es/~bernardo/1992valencia4ref.pdf .",
    "a.  birnbaum , j. amer .",
    "assoc . * 65 * , 402 ( 1962 ) ; j.  o.  berger and r.  l.  wolpert , _ the likelihood principle _ , vol . 6 of _ lecture notes  monograph series _ ( institute of mathematical statistics , hayward , california , 1988 ) , 2nd ed .",
    "the improper posterior pathology mentioned in the introduction disappears when data are collected in more than one channel or bin .",
    "the cdf and d0 single - top analyses are therefore unaffected by this problem ."
  ],
  "abstract_text": [
    "<S> bayesian inferences in high energy physics often use uniform prior distributions for parameters about which little or no information is available before data are collected . </S>",
    "<S> the resulting posterior distributions are therefore sensitive to the choice of parametrization for the problem and may even be improper if this choice is not carefully considered . here </S>",
    "<S> we describe an extensively tested methodology , known as reference analysis , which allows one to construct parametrization - invariant priors that embody the notion of minimal informativeness in a mathematically well - defined sense . </S>",
    "<S> we apply this methodology to general cross section measurements and show that it yields sensible results . </S>",
    "<S> a recent measurement of the single top quark cross section illustrates the relevant techniques in a realistic situation . </S>"
  ]
}