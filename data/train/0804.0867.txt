{
  "article_text": [
    "fix @xmath6 and @xmath7 . given a graph @xmath0 ,",
    "let @xmath8 be the graph whose vertex set is the set of all copies of @xmath9 in @xmath0 , in which two vertices are adjacent if the corresponding copies of @xmath9 share at least @xmath10 vertices .",
    "starting from a random graph @xmath4 , our aim is to study percolation in the corresponding graph @xmath11 , i.e. , to find for which values of @xmath12 there is a ` giant ' component in @xmath11 , containing a positive fraction of the vertices of @xmath11 .    for @xmath13",
    ", this question was proposed by dernyi , palla and vicsek  @xcite , motivated by the study of ` communities ' in real - world networks , but independent of the motivation , we consider it to be an extremely natural question in the theory of random graphs .",
    "indeed , it is perhaps the most natural example of dependent percolation arising out of the model @xmath14 .",
    "as we shall see in a moment , it is not too hard to guess the answer ; simple heuristic derivations based on the local analysis of @xmath11 were given in  @xcite and by palla , dernyi and vicsek  @xcite .",
    "( for a survey of related work see  @xcite . ) note , however , that @xmath11 may well have many more than @xmath15 edges , so @xmath11 is not well approximated by a graph with independence between different edges : there is simply not enough information in @xmath14 .",
    "thus it is not surprising that it requires significant work to pass from local information about @xmath11 to global information about the giant component .",
    "nonetheless , it turns out to be possible to find exactly the threshold for percolation , for all fixed @xmath2 and @xmath10 .",
    "given @xmath16 , let @xmath17 so @xmath18 is @xmath19 times the expected number of @xmath9s containing a given copy of @xmath20 .",
    "intuitively , this corresponds to the average number of new @xmath20s reached in one step from a given @xmath20 , so we expect percolation if and only if @xmath21 .",
    "since @xmath22 , we have @xmath23 if and only if @xmath24 we shall focus our attention on @xmath12 in this range .",
    "in addition to finding the threshold for percolation , we shall also describe the asymptotic proportion of @xmath9s in the giant component in terms of the survival probability of a certain branching process . set @xmath25 .",
    "given @xmath26 , let @xmath27 have a poisson distribution with mean @xmath28 .",
    "let @xmath29 be the galton ",
    "watson branching process which starts with a single particle in @xmath30 , in which each particle in @xmath31 has children in @xmath32 independently of the other particles and of the history , and in which the distribution of the number of children of a given particle is given by @xmath33 .",
    "let @xmath34 denote the probability that @xmath35 does not die out .",
    "then a simple calculation shows that @xmath36 satisfies the equation @xmath37 from standard branching process results , @xmath36 is the largest solution to this equation , @xmath38 is a continuous function of @xmath39 , and @xmath40 if and only if @xmath39 , the expected number of children of each particle , is strictly greater than @xmath41 .",
    "let @xmath42 denote the union of @xmath43 independent copies of the branching process @xmath35 described above , and let @xmath44 denote the survival probability of @xmath42 , so @xmath45 .",
    "our main result is that when @xmath23 , the largest component of @xmath11 contains whp a fraction @xmath46 of the vertices of @xmath11 , where @xmath18 is defined by . here , as usual , an event holds _ with high probability _ , or whp , if its probability tends to @xmath41 as @xmath47 .",
    "let @xmath48 denote the expected number of copies of @xmath9 in @xmath14 , i.e. , the expected number of vertices of @xmath11 .",
    "let us write @xmath49 for the number of vertices in the @xmath50th largest component of a graph @xmath0 .",
    "[ th1 ] fix @xmath51 , and let @xmath5 be chosen so that @xmath23 , where @xmath18 is defined by",
    ". then , for any @xmath52 , whp we have @xmath53 and @xmath54 .",
    "it is well known that @xmath55 is concentrated around its mean @xmath56 whenever @xmath57 , so theorem  [ th1 ] simply says that the largest component of @xmath11 contains a fraction @xmath46 of the vertices whp .",
    "the extension to the case where @xmath58 or @xmath59 is essentially trivial , and will be discussed in subsection  [ ss_ext ] .",
    "we shall prove theorem  [ th1 ] in two stages , considering the subcritical case in the next subsection , and the supercritical case in subsection  [ ss_lb ] .",
    "very roughly speaking , to handle the subcritical case ( and to prove the upper bound on the giant component in the supercritical case ) we shall show _ approximate _ domination of a suitable component exploration in @xmath11 by the branching process @xmath60 , @xmath61 . due to the dependence in the model",
    ", we have to be very careful exactly how we explore @xmath11 to make this argument work . for the upper bound we first show ( by approximate local coupling with the branching process ) that roughly the right number of vertices are in large components , even if @xmath12 is reduced slightly , i.e. , even if we omit some edges",
    ". then we use a multi - round ` sprinkling ' argument , putting back the omitted edges in several rounds , and showing that it is very likely that the sprinkled edges join these large components .",
    "the details of both arguments turn out to be less simple that one might like .",
    "we shall start by considering the subcritical case , proving the following much stronger form of theorem  [ th1 ] in this case .",
    "[ th1l ] let @xmath7 and @xmath52 be given .",
    "there is a constant @xmath62 such that , if @xmath5 is chosen so that @xmath63 for all large enough @xmath64 , then @xmath65 whp .",
    "since the event @xmath66 , considered as a property of the underlying graph @xmath0 , is an increasing event , we may assume without loss of generality that @xmath67 for every @xmath64 .",
    "thus holds .",
    "fixing a set @xmath68 of @xmath2 vertices of @xmath4 , we shall show that , given that @xmath68 forms a complete graph in @xmath0 , the probability that the corresponding component @xmath69 of @xmath11 has size more than @xmath70 is at most @xmath71 , provided @xmath72 is large enough . since",
    "the probability that @xmath68 forms a complete graph in @xmath0 is @xmath73 , while there are @xmath74 possibilities for @xmath68 , it then follows that @xmath75 .    from now on we condition on @xmath68 forming a @xmath9 in @xmath4 .",
    "the strategy is to show domination of a natural component exploration process by the branching process described earlier .",
    "we shall show essentially that the average number of new @xmath76s reached from a given @xmath76 in @xmath0 via @xmath9s in @xmath0 is at most @xmath77 , though there will be some complications .    in outline ,",
    "our exploration of the component @xmath78 proceeds as follows . at each stage",
    "we have a set @xmath79 of _ reached _ vertices of @xmath0 , starting with @xmath68 ; we also keep track of a set @xmath80 of _ reached _ edges , initially the edges spanned by @xmath68 . at the end of stage @xmath81 of our exploration , @xmath80 will consist of all edges of @xmath82 $ ] . within @xmath79",
    ", every @xmath20 is labelled as either ` tested ' or ` untested ' .",
    "we start with all @xmath43 @xmath20s in @xmath68 marked as untested .",
    "the exploration stops when there are no untested @xmath20s .    as long as there are untested @xmath20s",
    ", we proceed as follows .",
    "pick one , @xmath83 , say .",
    "one by one , test each set @xmath84 of @xmath2 vertices",
    "with @xmath85 to see whether all edges induced by @xmath84 are present in @xmath0 .",
    "if so , we add any new vertices to @xmath79 , i.e. , we set @xmath86 .",
    "we now add all edges of @xmath84 not present in @xmath79 to @xmath80 ; we call these edges _ regular_. any new @xmath87 formed in @xmath80 are marked as untested . note that any such @xmath20 must contain at least one vertex of @xmath88 , and",
    "hence must lie entirely inside @xmath84 .",
    "next , we test all edges between @xmath79 and @xmath89 to see if they are present in @xmath0 , adding any edge found to @xmath80 , and marking any new @xmath20s formed as untested .",
    "edges added during this operation are called _",
    "exceptional_. at this point , we have revealed the entire subgraph of @xmath0 induced by @xmath90 , i.e. , we have @xmath91)$ ] .",
    "we then continue through our list of possible sets @xmath84 containing @xmath83 , omitting any set @xmath84 contained in the now larger set @xmath90 .",
    "once we have considered all possible @xmath92 , we mark @xmath83 as tested , and continue to another untested @xmath20 , if there is one .",
    "the algorithm described above can be broken down into a sequence of steps of the following form . at the @xmath50th step ,",
    "we test whether all edges in a certain set @xmath93 are present in @xmath4 ; the future path of the exploration depends only on the answer to this question , not on which particular edges are missing if the answer is no .",
    "although this is wasteful from an algorithmic point of view , it is essential for the analysis .",
    "we write @xmath94 for the event @xmath95 .",
    "after @xmath50 steps , we will have ` uncovered ' a set @xmath96 of edges ( called @xmath80 above ) .",
    "the set @xmath96 consists of the edges spanned by @xmath68 together with the union of those sets @xmath97 for which @xmath98 holds .",
    "the event that the algorithm reaches a particular state , i.e. , receives a certain sequence of answers to the first @xmath50 questions , is of the form @xmath99 , where @xmath100 is an up - set , and @xmath101 is a down - set , formed by the intersections of various @xmath102 .",
    "the key point is that @xmath103 is a _ principal _ up - set , so @xmath104 may be regarded as a down - set @xmath105 in the product probability space @xmath106 with the appropriate measure .",
    "hence , for any @xmath107 disjoint from @xmath96 , the conditional probability that @xmath108 holds given the current state of the algorithm is @xmath109 where @xmath110 is the event in @xmath111 corresponding to @xmath108 , and the inequality follows from harris s lemma  @xcite applied in @xmath111 .",
    "let us write @xmath112 for the number of new @xmath20s found as a result of adding regular edges when testing the @xmath50th @xmath20 , @xmath113 , say ; we shall deal with exceptional edges separately in a moment . recall that we add regular edges when we find a new @xmath9 with at most @xmath114 and at least @xmath41 vertex outside the current vertex set @xmath79 .",
    "let @xmath115 be a constant such that @xmath116 .",
    "when testing @xmath113 , there are at most @xmath117 possibilities for new @xmath9s with @xmath114 vertices outside the current @xmath79 . given the history , by each such @xmath9 is present with probability at most @xmath118 , so the number of such @xmath9s we find is stochastically dominated by the binomial distribution @xmath119 , and hence , for @xmath64 large , by a poisson distribution with mean @xmath120 .",
    "[ here we use the fact that a poisson distribution with mean @xmath121 dominates a binomial @xmath122 , which , as pointed out to us by svante janson , follows immediately from the same statement for @xmath123 . ]    for @xmath124 , we may also find new @xmath9s containing @xmath113 together with @xmath125 other vertices of the current set @xmath79 , and hence with only @xmath126 vertices outside @xmath79 . assuming @xmath127 ,",
    "say , the number of possibilities for a fixed @xmath125 is crudely at most @xmath128 , and each of these tests succeeds with probability at most @xmath129 .",
    "a simple calculation shows that @xmath130 is at most @xmath131 for some @xmath132 , so the expected number of @xmath9s of this type is at most @xmath133 , say .",
    "moreover , the distribution of the number found is stochastically dominated by a poisson distribution with mean @xmath134 .    each @xmath9 we find consisting of @xmath126 new vertices and @xmath135 old vertices , @xmath136 , generates @xmath137 new @xmath20s , where @xmath25 .",
    "it follows that , given the history , the conditional distribution of @xmath138 is stochastically dominated by a poisson distribution with mean @xmath139 which is at most @xmath140 if @xmath64 is large enough .",
    "turning to exceptional edges , we claim that the @xmath125th exceptional edge added creates at most @xmath141 new @xmath20s ; all we shall use about this bound is that it depends only on @xmath125 , @xmath2 and @xmath10 , not on @xmath64 .",
    "indeed , we add exceptional edges immediately after adding a @xmath9 that includes a certain set @xmath142 of new vertices . at this point",
    ", the degree in @xmath80 ( the uncovered edges ) of every vertex in @xmath142 is exactly @xmath3 .",
    "we now add one or more exceptional edges joining @xmath142 to @xmath79 .",
    "any such edge @xmath143 has one end , @xmath144 , say , in @xmath142 . if @xmath143 is the @xmath125th exceptional edge in total , then just after adding @xmath143 the vertex @xmath144 has degree at most @xmath145 .",
    "any new @xmath20s involving @xmath143 consist of @xmath144 together with @xmath146 neighbours of @xmath144 , so there are at most @xmath141 such @xmath20s .",
    "assuming @xmath147 , the number of potential exceptional edges associated to a new @xmath9 is at most @xmath148 , where , as usual , @xmath149 means that there is a constant @xmath150 such that @xmath151 .",
    "it follows that , for fixed @xmath152 , the probability that we find at least @xmath152 such edges at a given step is @xmath153 .",
    "furthermore , the probability that we find @xmath125 exceptional edges in total during the first @xmath154 steps is @xmath155 , since there are @xmath156 possibilities for the set of at most @xmath125 steps at which we might find them .",
    "let us choose a constant @xmath157 so that @xmath158 ( here , @xmath159 would do ; the stronger bound is useful later ) , and let @xmath160 be the ` bad ' event that we find more than @xmath157 exceptional edges in the first @xmath154 steps .",
    "then we have @xmath161 .",
    "as long as @xmath160 does not hold , we create at most @xmath162 new @xmath20s when adding exceptional edges in the first @xmath154 steps ; let us note for later that we also create at most @xmath163 @xmath9s when adding exceptional edges .",
    "we view our exploration as a set of branching processes : we start one process for each of the initial @xmath20s . whenever we add a @xmath20 in the normal way ,",
    "we view it as a child of the @xmath20 we were testing .",
    "when we add a @xmath20 as a result of adding an exceptional edge , we view it as the root of a new process .",
    "as long as @xmath147 holds , from   the branching processes we construct are stochastically dominated by independent copies @xmath164 of the galton ",
    "watson process @xmath35 described earlier , where @xmath165 .",
    "if @xmath160 does not hold , then we start in total at most @xmath166 processes in the first @xmath154 steps .",
    "recall that the offspring distribution in @xmath35 is given by @xmath167 , where @xmath27 has a poisson distribution with mean @xmath28 , so @xmath168 . here , @xmath169 .",
    "since @xmath167 has an exponential upper tail , it follows from standard branching process results that there is a constant @xmath170 such that the probability that the total size of @xmath164 exceeds @xmath171 is at most @xmath172 for any @xmath173 . taking @xmath72 large enough",
    ", it follows that with probability @xmath174 , each of @xmath175 has size at most @xmath176 .",
    "if this event holds and @xmath160 does not hold , then our exploration dies having reached a total of at most @xmath70 vertices .",
    "hence , the probability that @xmath69 contains more than @xmath177 vertices of @xmath4 is @xmath178 .    at this point",
    "the proof of theorem  [ th1l ] is almost complete : we have shown that whp , any component of @xmath11 involves @xmath9s meeting at most @xmath70 vertices of @xmath4 . to complete the proof",
    ", it is an easy exercise to show that if @xmath179 for some @xmath132 , then whp any @xmath70 vertices of @xmath14 span at most @xmath180 copies of @xmath9 , for some constant @xmath181 .",
    "alternatively , note that the number of @xmath9s found involving new vertices is at most the final number of vertices reached , while all other @xmath9s are formed by the addition of exceptional edges , and if @xmath160 does not hold , then , arguing as for the bound on the number of @xmath76s formed by adding exceptional edges , the number of @xmath9s so formed is bounded by a constant .    in the proof above",
    ", subcriticality only came in at the end , where we used it to show that the branching processes @xmath164 were very likely to die ; in the supercritical case , the proof gives a domination result that we shall state in a moment .",
    "for this , the order in which we test the @xmath20s matters  we proceed in rounds , in round @xmath182 testing the @xmath43 initial @xmath20s , and then in round @xmath183 testing all @xmath20s created during round @xmath50 .",
    "let @xmath184 be the bipartite incidence graph corresponding to @xmath11 : the vertex classes are @xmath185 , the set of all @xmath9s in @xmath11 , and @xmath186 , the set of all @xmath20s .",
    "two vertices are joined if one of the corresponding complete graphs is contained in the other .",
    "given a vertex @xmath187 of @xmath188 , let @xmath189 denote the number of @xmath20s whose graph distance in @xmath188 from @xmath190 is at most @xmath191 . if @xmath190 is the vertex of @xmath188 corresponding to the complete subgraph on @xmath68 , then after @xmath50 rounds of the above algorithm we have certainly reached all @xmath192 @xmath20s within distance @xmath191 of @xmath190 .",
    "the domination argument in the proof of theorem  [ th1l ] thus also proves the lemma below , in which @xmath193 is a constant depending only on @xmath2 and @xmath10 , @xmath175 are independent copies of our galton ",
    "watson branching process as above , and @xmath194 denotes the total number of particles in the first @xmath81 generations of @xmath175 .",
    "[ ub ] let @xmath115 be fixed , let @xmath5 satisfy , and let @xmath68 be a fixed set of @xmath2 vertices of @xmath4 .",
    "condition on @xmath68 spanning a complete graph in @xmath0 , and let @xmath190 be the corresponding vertex of @xmath188 . then we may couple the random sequence @xmath195 with @xmath193 independent copies @xmath164 of @xmath196 so that with probability @xmath197 we have @xmath198 for all @xmath81 such that @xmath199 .",
    "@xmath200    we finish this subsection by presenting a consequence of a much simpler version of the domination argument above .",
    "if we are prepared to accept a larger error probability , we may abandon the coupling the first time an exceptional edge appears . as shown above , the probability that we find any exceptional edges within @xmath156 steps is at most @xmath131 for some @xmath132 . abandoning our coupling if this happens ,",
    "we need only consider the original @xmath43 branching processes , one for each copy of @xmath20 in @xmath68 .",
    "in other words , we may compare our neighbourhood exploration process with the branching process @xmath42 , @xmath201 , which starts with @xmath43 particles in generation @xmath182 , and in which , as in @xmath35 , the offspring distribution for each particle is given by @xmath202 times a poisson distribution with mean @xmath28 .",
    "[ ubc ] let @xmath115 be fixed , let @xmath5 satisfy , and let @xmath68 be a fixed set of @xmath2 vertices of @xmath4 .",
    "condition on @xmath68 spanning a complete graph in @xmath0 , and let @xmath190 be the corresponding vertex of @xmath188 . then there is a constant @xmath132 such that we may couple the random sequence @xmath195 with @xmath203 so that , with probability at least @xmath204 , we have @xmath205 for all @xmath81 such that @xmath199 , where @xmath206 is the number of particles in generation @xmath81 of @xmath207 , and @xmath208 .    in the next subsection we shall show that when @xmath21 , the graph @xmath11 does contain a giant component , and moreover that this giant component is of about the right size ; lemma  [ ubc ] will essentially give us the upper bound , but we have to work a lot more for the lower bound .      recall that @xmath55 , the number of @xmath9s in @xmath14 , is certainly concentrated about its mean @xmath48 . for the moment , we concentrate on the case where holds ; we return to larger @xmath12 later .",
    "one bound in theorem  [ th1 ] is easy , at least in expectation : lemma  [ ubc ] gives an upper bound on the expected size of the giant component .",
    "in fact , it gives much more , namely an upper bound on the expected number of vertices in ` large ' components .",
    "it is convenient to measure the size of a component by the number of @xmath20s rather than the number of @xmath9s .",
    "let @xmath209 denote the number of vertices of @xmath11 whose component in the bipartite graph @xmath188 contains at least @xmath150 vertices of @xmath186 , i.e. , at least @xmath150 copies of @xmath20 .",
    "[ ll1 ] let @xmath5 be chosen so that @xmath18 is constant , and let @xmath52 be fixed .",
    "for any @xmath210 tending to infinity we have @xmath211 if @xmath64 is large enough .",
    "we may assume without loss of generality that @xmath212 . from standard branching process results , for any fixed @xmath39 , the probability that @xmath42 contains at least @xmath150 particles but does not survive forever tends to @xmath182 as @xmath213 .",
    "thus , @xmath214 .",
    "fix a set @xmath68 of @xmath2 vertices of @xmath4 , and condition on @xmath68 forming a @xmath9 in @xmath0 , which we denote @xmath190 .",
    "let @xmath201 where , for the moment , @xmath115 is constant . since @xmath215",
    ", lemma  [ ubc ] tells us that the probability @xmath216 that the component of @xmath190 in @xmath188 contains at least @xmath217 @xmath20s is at most @xmath218 . letting @xmath219 and using continuity of @xmath220",
    ", it follows that @xmath221 as @xmath47 .",
    "since @xmath222 is simply @xmath223 , this proves the lemma .    as in bollobs ,",
    "janson and riordan  @xcite , for example , a simple variant of lemma  [ ubc ] also gives us a second moment bound .",
    "[ ll2 ] let @xmath5 be chosen so that @xmath18 is constant , and let @xmath52 be fixed .",
    "for any @xmath210 tending to infinity we have @xmath224 .",
    "the expected number of pairs of overlapping @xmath9s in @xmath4 is @xmath225 which , by a standard calculation , is @xmath226 . hence , it suffices to bound the expected number of pairs of vertex disjoint @xmath9s each in a ` large ' component .",
    "we may do so as in the proof of lemma  [ ll1 ] , using a variant of lemma  [ ubc ] in which we start with two disjoint @xmath9s , and explore from each separately , abandoning each exploration if it reaches size at least @xmath227 , and abandoning both if they meet , an event of probability @xmath228 .",
    "let us turn to our proof of the heart of theorem  [ th1 ] , namely the lower bound . in proving this we may assume that @xmath21 is constant .",
    "we start with a series of simple lemmas .",
    "let @xmath68 be a set of @xmath2 vertices of @xmath4 , and let @xmath229 be the event that @xmath68 spans a @xmath9 in @xmath0 .",
    "let @xmath230 be the event that @xmath11 contains a tree @xmath231 with @xmath232 vertices , one of which , @xmath190 , is the clique corresponding to @xmath68 , with the following additional property : ordering the vertices of @xmath231 so that the distance from the root @xmath190 is increasing , each corresponding @xmath9 meets the union of all earlier @xmath9s in exactly @xmath10 vertices .",
    "equivalently , the union of the cliques in @xmath231 contains exactly @xmath233 vertices of @xmath0 .",
    "recall that @xmath234 is defined by .",
    "[ el ] fix @xmath52 , and let @xmath235 be chosen so that @xmath18 is a constant greater than @xmath41 .",
    "if @xmath64 is large enough , then @xmath236 .",
    "throughout we condition on @xmath229 , writing @xmath190 for the corresponding vertex of @xmath11 .",
    "we start by marking all @xmath43 copies of @xmath20 in @xmath68 as untested ; we shall then explore part of the component of @xmath11 containing the vertex @xmath190 corresponding to @xmath68 . at the @xmath50th step in our exploration , we consider an untested copy @xmath113 of @xmath20 , and test for the presence of certain @xmath9s consisting of @xmath113 plus exactly @xmath114 ` new ' vertices not so far reached in our exploration .",
    "for each such @xmath9 we find , we mark the @xmath25 new @xmath20s created as untested ; having found all such @xmath9s , we mark @xmath113 as tested .",
    "we abandon our exploration if there is no untested @xmath113 left , or if we reach more than @xmath237 @xmath9s .",
    "note that the total number of vertices reached is exactly @xmath238 plus @xmath114 times the number of @xmath9s found , so if we find more than @xmath237 @xmath9s , then @xmath239 holds .",
    "the exploration above corresponds to the construction of @xmath43 random rooted trees whose vertices are the @xmath113 , in which the children of @xmath113 are the new @xmath20s created when testing @xmath113 .",
    "the number of children of @xmath113 is @xmath240 , where @xmath112 is the number of @xmath9s we find when testing @xmath113 .",
    "let @xmath241 be a constant to be chosen later .",
    "let @xmath242 be a sequence of iid poisson random variables with mean @xmath243 .",
    "our aim is to show that as long as we have found at most @xmath237 copies of @xmath9 in total , the conditional distribution of @xmath112 given the history may be coupled with @xmath244 so that @xmath245 holds with probability @xmath246 , for some @xmath132 .",
    "the galton ",
    "watson branching process @xmath247 defined by @xmath242 is supercritical , and so survives forever with probability @xmath248 .",
    "it then follows that @xmath239 holds with probability at least @xmath249 .",
    "using continuity of @xmath220 and choosing @xmath250 small enough , the conclusion of the lemma follows .    in order to establish the coupling above",
    ", we must be a little careful with the details of our exploration . at step @xmath50 , before testing @xmath113 , we will have a certain set @xmath251 of reached vertices , consisting of all vertices of all @xmath9s found so far , and a certain set @xmath252 of ` dirty ' vertices .",
    "the remaining vertices are ` clean ' ; we write @xmath253 for the set of these vertices . at the start",
    ", @xmath68 is our initial set of @xmath2 vertices , while @xmath254 and @xmath255 .",
    "we test @xmath113 as follows : for each @xmath256 , let @xmath257 be the event that all @xmath10 possible edges joining @xmath258 to @xmath113 are present in @xmath4 .",
    "first , for every vertex @xmath256 , we test whether @xmath257 holds , writing @xmath259 for the set of @xmath256 for which @xmath257 does hold .",
    "we then look for copies of @xmath260 inside @xmath261 $ ] , writing @xmath192 for the maximum number of vertex disjoint copies . taking a particular set of @xmath192 disjoint copies ,",
    "we then add each of the corresponding @xmath9s to our component , defining @xmath262 appropriately .",
    "we then set @xmath263 , and @xmath264 .",
    "the structure of the algorithm guarantees the following : given the state at time @xmath50 , all we know about the edges between @xmath251 and @xmath253 is that certain sets of @xmath10 edges are not all present : more precisely , we know exactly that none of the events @xmath265 holds , for @xmath256 and @xmath266 .",
    "let @xmath267 , a random variable . having found @xmath259",
    ", it follows that the edges within @xmath259 are untested , so each is present with its unconditional probability , and @xmath261 $ ] has the distribution of the random graph @xmath268 .",
    "let @xmath269 be a very small constant to be chosen below .",
    "let @xmath270 be the event that @xmath271 .",
    "we shall show in a moment that @xmath270 holds with very high ( conditional ) probability , given the history ; first , let us see how this enables us to complete the proof . if @xmath270 does hold , then the conditional expected number of @xmath260s in @xmath261 $ ] is exactly @xmath272 .",
    "provided we choose @xmath273 small enough , this expectation is at least @xmath274 , where @xmath275 .",
    "since @xmath276 , by a result of bollobs  @xcite , the number @xmath277 of @xmath260s in @xmath261 $ ] is asymptotically poisson with mean @xmath278 .",
    "indeed , @xmath277 may be coupled with a poisson distribution @xmath279 with mean @xmath280 so that @xmath281 holds with probability @xmath246 .",
    "furthermore , by the first moment method , with probability @xmath246 , the graph @xmath261 $ ] does not contain two @xmath260s sharing a vertex , so @xmath282 .",
    "it remains only to prove that @xmath270 does indeed hold with high conditional probability .",
    "recall that at the start of stage @xmath50 , all we know about the edges between @xmath253 and @xmath251 is that none of the events @xmath265 , @xmath283 , @xmath266 holds .",
    "this information may be regarded as a separate condition @xmath284 for each @xmath256 , where @xmath285 depends only on edges between @xmath258 and @xmath251 .",
    "given this information , the events @xmath257 are independent , and each holds with probability @xmath286 .",
    "now @xmath257 is an up - set and @xmath284 is a down - set , so @xmath287 . hence ,",
    "whatever @xmath288 is , the conditional probability that @xmath289 is exponentially small . since @xmath290 , and we stop after at most @xmath237 steps , we may thus assume in what follows that @xmath291 .    regarding the sets @xmath292 , @xmath293 , as fixed , and forgetting our present conditioning , if all we assume about the edges from @xmath258 to @xmath251 is that @xmath257 holds , i.e. , that all edges from @xmath258 to @xmath113 are present , then each @xmath265 , @xmath266 , has conditional probability @xmath294 .",
    "recalling that we abandon our exploration after at most @xmath237 steps , it follows that @xmath295 if @xmath64 is large enough .",
    "hence @xmath296 .",
    "in other words , @xmath297 .",
    "this trivially implies that @xmath298 , i.e. , that @xmath299 .    it follows that @xmath300 stochastically dominates a binomial distribution with parameters @xmath288 and @xmath301 .",
    "since @xmath291 ,",
    "we get the required lower bound on @xmath300 , completing the proof .    let @xmath142 denote the number of @xmath9s in @xmath4 for which the corresponding event @xmath302 holds , and let @xmath303 be the number of @xmath9s in _ large _ components of @xmath11 , that is , components containing at least @xmath237 copies of @xmath20 .",
    "if @xmath68 spans a @xmath9 for which @xmath302 holds , then by definition the corresponding component of @xmath11 contains a tree with at least @xmath237 vertices ; furthermore , exploring this tree from the root , for each new vertex we find @xmath304 new @xmath76s .",
    "hence the component is large , so @xmath305 .",
    "[ start ] fix @xmath52 , and let @xmath235 be chosen so that @xmath18 is a constant greater than @xmath41",
    ". then @xmath306 holds whp .    fixing a set @xmath68 of @xmath2 vertices of @xmath4 ,",
    "recall that @xmath229 is the event that @xmath68 spans a @xmath9 in @xmath0 .",
    "we have @xmath307 , which is at least @xmath308 by lemma  [ el ] .",
    "as noted above , @xmath305 always holds .",
    "thus @xmath309 . but",
    "@xmath310 by lemma  [ ll2 ] .",
    "hence @xmath311 , which implies that @xmath142 is concentrated around its mean .",
    "furthermore , @xmath312 , so we have @xmath313 , and the result follows .",
    "it is perhaps interesting to note that there is an alternative proof of the bounds on @xmath314 given in lemma  [ start ] , using the a sharp - threshold result of friedgut  @xcite instead of the second moment method .",
    "let us briefly outline the argument . let @xmath103 be the event that the number @xmath303 of @xmath9s in large components satisfies @xmath315",
    ". in the light of the expectation bound given by lemma  [ ll1 ] , it suffices to prove that @xmath103 holds whp .",
    "we view @xmath103 as an event in the probability space @xmath14 , in which case it is clearly increasing and symmetric .",
    "we shall consider @xmath316 , the probability that @xmath317 has the property @xmath103 .",
    "when we do so , we keep the definition of @xmath103 fixed , i.e. , the definition of @xmath103 refers ( via @xmath18 and @xmath56 ) to @xmath12 , not to @xmath318 .",
    "fix @xmath115 such that @xmath319 .",
    "applying lemma  [ el ] with @xmath318 reduced by an appropriate constant factor , we find that @xmath320 , which is at least @xmath321 if we choose @xmath318 correctly .",
    "since @xmath314 is bounded by the total number of @xmath9s , which is very unlikely to be much larger than its mean @xmath56 , it follows that @xmath316 is bounded away from zero .",
    "since @xmath322 is a constant larger than @xmath41 , if @xmath103 has a sharp threshold , we have @xmath323 as required .",
    "otherwise , theorem 1.2 of friedgut  @xcite applies .",
    "we conclude that there is a constant @xmath72 such that @xmath324 , where @xmath325 is the event that a fixed copy of @xmath326 is present in @xmath4 . of course , conditioning on @xmath325 is equivalent to simply adding the edges of @xmath326 to @xmath0 .",
    "hence , whp , @xmath14 has the property that after adding a particular copy of @xmath326 to @xmath0 , the event @xmath103 holds .",
    "but the expected number of @xmath9s in @xmath327 that share at least @xmath10 vertices with a @xmath9 in @xmath327 not present in @xmath0 turns out to be less that @xmath328 for some @xmath132 .",
    "hence , @xmath327 contains at most @xmath329 such @xmath9s whp .",
    "whenever this holds , removing the edges of @xmath326 from @xmath0 splits existing components into at most @xmath329 new components .",
    "it follows that @xmath0 has whp at most @xmath330 fewer @xmath9s in large components that @xmath327 .",
    "since @xmath327 has property @xmath103 whp , it follows that @xmath0 has the same property with a slightly increased @xmath331 whp .    at this point",
    ", we have shown that whp we have the ` right ' number of @xmath9s in ` large ' components ; it remains to show that in fact almost all such @xmath9s are in a single giant component . in the special case @xmath332 , @xmath333 , i.e. , when @xmath11 is simply @xmath14",
    ", there are many simple ways of showing this , most of them based on ` sprinkling ' of one form or another : following the original approach of erds and rnyi  @xcite to the study of the giant component of @xmath14 , one chooses @xmath318 slightly smaller than @xmath12 , and views @xmath14 as obtained from @xmath317 by ` sprinkling ' in a few extra edges . using independence of the sprinkled edges from @xmath317 , it is easy to show that whp the sprinkled edges join up almost all large components of @xmath317 into a single giant component . unfortunately , most of these approaches do not carry over to the present setting ; the essential problem is that , depending on the parameters , @xmath11 may well have many more vertices than @xmath14 .",
    "in fact , it may have many more than @xmath15 vertices .",
    "approaches such as forming an auxiliary graph on the large components , joining two if they are connected by sprinkled edges , and then comparing this graph to @xmath334 for suitable @xmath335 and @xmath318 , do not seem to work : here @xmath335 is much larger than @xmath64 , and there is not nearly enough independence for such a comparison to be possible .",
    "for the same reason , we can not count cuts between largish components , and estimate the number not joined by sprinkled edges : we may have many more than @xmath336 cuts , while the probability that a given cut is not joined will certainly be at least @xmath337 .",
    "fortunately , we can get another version of the sprinkling argument to work : the key result is the following rather ugly lemma . in stating this we write @xmath338 for @xmath339 , so @xmath340 is equivalent to @xmath341 .",
    "we write @xmath342 for @xmath343 .",
    "[ sprinkle ] fix constants @xmath52 and @xmath344 , let @xmath345 be any graph on @xmath346 $ ] , and let @xmath347 list all components of the corresponding graph @xmath348 that contain one or more @xmath9s in @xmath345 with property @xmath302 .",
    "suppose that    1 .",
    "[ a1 ] between them the @xmath253 contain at least @xmath349 copies of @xmath9 in @xmath345 , 2 .",
    "[ a2 ] no single @xmath253 contains all but @xmath350 copies of @xmath9 in @xmath345 , 3 .",
    "[ a3 ] @xmath345 contains at most @xmath351 copies of @xmath9 , 4 .",
    "[ a4 ] for @xmath352 we have @xmath353 where @xmath354 is the number of pairs of @xmath9s in @xmath345 sharing exactly @xmath355 vertices , and 5 .   [ a5 ]",
    "no vertex of @xmath345 lies in more than @xmath356 copies of @xmath9 in @xmath345 .",
    "set @xmath357 , let @xmath358 be a random graph on the same vertex set as @xmath345 , and let @xmath359 be the graph @xmath8 derived from @xmath360 .",
    "then , for any fixed @xmath50 , the probability that there is some @xmath125 such that @xmath253 and @xmath361 are contained in a common component of @xmath362 is at least @xmath363 , for some constant @xmath364 depending only on @xmath365 and @xmath331 .    in other words , roughly speaking , and ignoring all the conditions for a moment , sprinkling in extra edges with density @xmath366 is enough to give any given ` large ' component of @xmath348 at least probability @xmath363 of joining up with another such component , for some @xmath367 that does not depend on @xmath64 .",
    "we shall prove lemma  [ sprinkle ] later ; first , we show that theorem  [ th1 ] follows .",
    "let @xmath5 be chosen so that @xmath234 is constant and @xmath21 .",
    "it suffices to show that for any @xmath52 , @xmath368 holds whp : letting @xmath369 , implies that @xmath370 , while lemma  [ ll1 ] immediately implies that @xmath371 .",
    "together , these two statements imply that @xmath372 , which is what the first statement of theorem  [ th1 ] claims . for the second",
    ", we simply observe that the same argument gives @xmath373 .    to establish ,",
    "let us choose @xmath374 so that @xmath375 . from continuity of @xmath220 , we can choose such a @xmath318 with @xmath376 . by lemma",
    "[ start ] , applied with @xmath318 in place of @xmath12 and @xmath377 in place of @xmath331 , whp at least @xmath378 copies of @xmath9 in @xmath317 have property @xmath302 ; let @xmath379 be ( the vertex sets of ) @xmath380 such copies .",
    "let @xmath381 , and let @xmath382 be independent copies of @xmath383 that are also independent of @xmath384 , with the vertex sets of @xmath382 and of @xmath345 identical .",
    "set @xmath385 , and note that @xmath386 has the distribution of the random graph @xmath387 for some @xmath388 . since @xmath389 if @xmath64 is large enough , we have @xmath390 if @xmath64 is large enough , so we may couple @xmath386 and @xmath14 so that the latter contains the former .",
    "hence , it suffices to prove that whp there is a single component of @xmath391 containing at least @xmath392 of the @xmath2-cliques @xmath393 .",
    "as the reader will have guessed , we shall sprinkle in edges in @xmath231 rounds , applying lemma  [ sprinkle ] successively with each pair @xmath394 in place of @xmath395 , and @xmath396 in place of @xmath331 . as noted above , by lemma",
    "[ start ] , whp @xmath345 contains at least @xmath397 copies of @xmath9 with property @xmath302 .",
    "we may assume that @xmath398 , in which case @xmath399 .",
    "since the event that @xmath251 has property @xmath302 is increasing , and @xmath400 for all @xmath81 , whp the first assumption of lemma  [ sprinkle ] holds for @xmath345 and hence for all @xmath401 .",
    "if the second assumption fails at some point , then we are done : @xmath401 and hence @xmath402 already contains a single component containing at least @xmath403 copies of @xmath9 , as required .",
    "the remaining assumptions are down - set conditions , bounding the number of copies of certain subgraphs in @xmath401 from above .",
    "standard results tell us that @xmath14 satisfies these conditions whp if we choose @xmath365 large enough ; it follows that whp @xmath386 and hence every @xmath401 does too .    from the comments above",
    ", we may assume that the conditions of lemma  [ sprinkle ] are satisfied at each stage .",
    "suppose that after @xmath81 rounds , i.e. , @xmath81 applications of lemma  [ sprinkle ] , the sets @xmath393 are now contained in @xmath404 components @xmath405 of @xmath406 . by lemma",
    "[ sprinkle ] , each @xmath253 has a constant probability @xmath367 of joining up with some other @xmath361 in each round , so after @xmath407 further rounds , the probability that a particular @xmath253 has not joined some other @xmath361 is at most @xmath408 .",
    "it follows that with probability @xmath409 , after @xmath407 rounds every @xmath253 has joined some other @xmath361 .",
    "if this holds , the number @xmath410 of components containing @xmath393 is now at most @xmath411 .",
    "hence , after @xmath412 sets of @xmath407 rounds , either an assumption is violated , or there is a single component containing all @xmath251 . but as shown above , there is only one assumption that can be violated with probability bounded away from zero , and if this assumption is violated at some stage , we are already done .",
    "it remains only to prove lemma  [ sprinkle ] .",
    "we assume without loss of generality that @xmath413 .",
    "let @xmath414 .",
    "since @xmath415 contains a @xmath9 with property @xmath302 , @xmath415 contains at least @xmath150 distinct copies of @xmath20 , each lying in a @xmath9 in @xmath415 .",
    "let @xmath416 be @xmath150 such copies .    from assumptions  [ a1 ] and",
    "[ a2 ] , @xmath417 between them contain at least @xmath350 copies of @xmath9 .",
    "the set @xmath418 has size @xmath419 , and so , using assumption  [ a5 ] , meets at most @xmath420 copies of @xmath9 in @xmath345 .",
    "it follows that we may find @xmath421 copies @xmath422 of @xmath9 in @xmath417 such that each @xmath423 is vertex disjoint from @xmath68 .",
    "( we round @xmath424 up to the nearest integer , but omit this irrelevant distraction from the formulae . )",
    "it suffices to show that with probability bounded away from zero , there is a path of @xmath9s in @xmath362 joining some @xmath113 to some @xmath423 .",
    "we shall do this using the second moment method . for this , it helps to count only paths with a simple form .    by a _",
    "potential @xmath2-path _ we mean a sequence @xmath425 of sets of @xmath2 vertices of @xmath345 with the following properties : @xmath185 contains some @xmath113 , all other vertices of @xmath426 lie outside @xmath68 ( and hence outside @xmath113 ) , @xmath427 coincides with some @xmath423 , and for @xmath428 , @xmath79 consists of @xmath114 vertices outside @xmath429 together with @xmath10 vertices of @xmath430 , not all of which lie in @xmath431 .",
    "a potential @xmath2-path starting at @xmath113 and ending at @xmath423 contains exactly @xmath432 vertices outside @xmath433 : starting with @xmath113 we add @xmath114 new vertices for each set @xmath79 in the path , but this count includes the vertices of @xmath423 .",
    "it follows that the number of potential @xmath2-paths joining @xmath113 to @xmath423 is @xmath434 , so the total number of potential @xmath2-paths is @xmath435 .",
    "a potential @xmath2-path @xmath436 joining @xmath113 to @xmath423 is a _ @xmath2-path _ if all edges contained in each @xmath79 but not in @xmath113 or @xmath423 are present in @xmath358 .",
    "note that any potential @xmath2-path contains exactly @xmath437 such edges : for each @xmath81 there are @xmath438 edges spanned by @xmath79 but by no earlier @xmath439 , but this count includes all edges of @xmath423 .",
    "let @xmath440 denote the number of @xmath2-paths .",
    "if any @xmath2-path is present , then some @xmath113 is joined to some @xmath423 in the graph @xmath362 formed from @xmath441 , so it suffices to show that @xmath442 is bounded away from zero .",
    "since each potential @xmath2-path is present with probability exactly @xmath443 , we have @xmath444 now the bracket raised to the power @xmath2 in the last line above is @xmath445 by definition of @xmath338 , while @xmath446 .",
    "thus we have @xmath447 .",
    "since , crudely , @xmath448 , while @xmath449 and @xmath357 , we have @xmath450 .    it remains to estimate the second moment of @xmath440 .",
    "for this , it turns out to be easier to consider a related random variable @xmath451 .    a _",
    "potential free @xmath2-path _ is defined exactly as a potential @xmath2-path , except that we omit the condition that @xmath427 coincides with some @xmath423 .",
    "it is easy to see that the fraction of potential free @xmath2-paths that are potential @xmath2-paths is exactly @xmath452 .",
    "free @xmath2-path _ is a potential free @xmath2-path in which all edges except those contained in the starting set @xmath113 are present in @xmath453 .",
    "note that there are @xmath454 such edges , so each potential free @xmath2-path is an actual free @xmath2-path with probability @xmath455 .",
    "let @xmath451 denote the number of free @xmath2-paths .",
    "it follows that @xmath456    for @xmath457 , let @xmath354 denote the number of ordered pairs of copies of @xmath9 in @xmath345 sharing exactly @xmath355 vertices , and let @xmath458 denote the number of such pairs lying entirely outside @xmath68 .",
    "let @xmath459 denote the number of ordered pairs of @xmath2-paths whose destinations ( final sets @xmath427 ) share exactly @xmath355 vertices , and @xmath460 the number of ordered pairs of free @xmath2-paths with this property . among ordered pairs @xmath461 of potential free @xmath2-paths whose destinations share @xmath355 vertices , the fraction of pairs in which @xmath462 and @xmath463 are also potential @xmath2-paths is exactly @xmath464 moreover , this statement remains true if we restrict our attention to pairs @xmath461 with a certain number of common edges .",
    "indeed , under any sensible assumption on @xmath461 , the pair @xmath465 of destinations of a random pair @xmath461 is uniform on all pairs of @xmath2-sets in @xmath346\\setminus v_0 $ ] sharing @xmath355 vertices .    given a pair of paths with destinations sharing @xmath355 vertices , for both paths to be present as free @xmath2-paths requires the presence of @xmath466 more edges in @xmath0 than required by their presence as @xmath2-paths .",
    "it follows that @xmath467 by assumption  [ a4 ] we have @xmath468 for @xmath469 .",
    "this also holds for @xmath470 by assumption  [ a3 ] , and hence also for @xmath471 .",
    "hence , for @xmath457 , @xmath472 since @xmath473 and @xmath474 , it follows immediately that @xmath475 .",
    "we claim that @xmath476 .",
    "recalling from that @xmath477 , it then follows that @xmath478 , and hence that @xmath442 is bounded away from zero .    to evaluate @xmath479",
    ", we could argue from the fact that free @xmath2-paths are balanced in a certain sense , but rather than make this precise , it turns out to be easier to simply use our coupling results from subsection  [ ss_ub ] .    we may evaluate @xmath451 , and hence @xmath480 , as follows .",
    "start with our set @xmath68 of ` reached ' vertices , namely @xmath481 . also , mark @xmath416 as untested copies of @xmath20 .",
    "now explore as in the proofs of theorem  [ th1l ] and lemma  [ ub ] , except that we only look for new vertices outside @xmath68 ; note that our edge probability is now @xmath366 rather than @xmath482 , so the corresponding branching process is strongly subcritical .",
    "we stop the exploration after @xmath2 ` rounds ' , in the terminology of lemma  [ ub ] ; of course it may well die earlier .",
    "we consider three cases .",
    "firstly , let @xmath483 be the event that in the exploration just described , we find no exceptional edges . since @xmath484 , and the total size of the relevant branching processes is also @xmath156 whp , we have @xmath485 for some @xmath132 depending only on @xmath2 and @xmath10 .",
    "when @xmath483 holds , we obtain a coupling of our exploration with @xmath150 independent copies of the branching process @xmath35 , where @xmath486 .",
    "if @xmath483 holds , the number of @xmath9s reached in the final round is equal to @xmath487 , where @xmath488 is the number of particles in generation @xmath2 of the combined branching process , and we divide by @xmath25 since we add @xmath202 copies of @xmath20 for each @xmath9 we find .    now from standard branching process results , @xmath489 , recalling that @xmath490 is the number of edges of @xmath345 in a free @xmath2-path .",
    "it follows that @xmath491 .",
    "we claim that there is a constant @xmath84 such that the chance of finding more than @xmath84 exceptional edges is @xmath492 . to see this",
    ", first note that the probability that a poisson random variable with mean at most @xmath41 exceeds @xmath227 is of order @xmath493 .",
    "hence , with probability @xmath494 , the first @xmath2 generations of @xmath495 copies of @xmath35 contain at most @xmath496 particles  simply crudely bound the number of children of each particle by @xmath227 . now arguing as in the proof of theorem  [ th1l ] , given that we have reached @xmath156 vertices , the chance of finding an exceptional edge is at most @xmath131 for some @xmath132 .",
    "hence , the chance of finding @xmath84 such edges within the first @xmath156 steps is @xmath497 which is @xmath492 if we pick @xmath84 large enough .",
    "but if we find no more than @xmath84 exceptional edges within @xmath156 steps , and the first @xmath2 generations of @xmath498 branching processes have total size @xmath156 , then ( recalling that we stop after @xmath2 rounds ) , our coupling succeeds , with @xmath499 branching processes as the upper bound .",
    "let @xmath160 be the event that we do find more than @xmath84 exceptional edges , so @xmath500 . the number of pairs of free @xmath2-paths present in the complete graph on @xmath501 is easily seen to be at most @xmath502 , so we have @xmath503",
    ".    finally , let @xmath504 .",
    "if @xmath505 holds then , as above , with very high probability we have reached @xmath156 vertices in our exploration .",
    "the picture given by our exploration may be complicated by the exceptional edges , but @xmath156 vertices in any case contain @xmath156 ( pairs of ) free @xmath2-paths , so we have @xmath506 .",
    "putting it all together , @xmath507 . from we",
    "thus have @xmath476 .",
    "as noted earlier it follows that @xmath478 , and thus that @xmath442 is bounded away from 0 , as required .      in the previous subsections we focused on the `",
    "approximately critical ' case , where @xmath12 is chosen so that the expected number of other @xmath9s adjacent to ( i.e. , sharing at least @xmath10 vertices with ) a given @xmath9 is of order @xmath41 . in more standard percolation contexts , one can make this assumption without loss of generality ; using monotonicity it follows that the fraction of vertices in the largest component tends to @xmath182 or @xmath41 outside this range of @xmath12 .",
    "here we do not have such simple monotonicity , because the number of vertices of @xmath11 changes as @xmath12 varies .",
    "however , it is still easy to deduce results for values of @xmath12 outside the range @xmath341 from those for @xmath12 inside this range .    for @xmath508 ,",
    "this is essentially trivial ; since the property of @xmath0 corresponding to @xmath8 containing a component of size at least @xmath70 is monotone , theorem  [ th1l ] together with concentration of the number of @xmath9s trivially implies that the largest component of @xmath11 contains whp a fraction @xmath228 of the vertices of @xmath11 , as long as @xmath509 , the expected number of vertices of @xmath11 , grows faster than @xmath227 . when @xmath56 grows slower than @xmath227 ( or indeed than @xmath510 ) , by estimating the expected number of cliques sharing one or more vertices it is very easy to check that whp @xmath11 contains no edges , and thus no giant component ( as long as @xmath56 does tend to infinity ) .",
    "to handle the case @xmath511 , we use a slightly different argument .",
    "let @xmath142 denote the number of pairs of vertex disjoint cliques in @xmath14 that lie in the same component of @xmath11 .",
    "let @xmath341 .",
    "since the expected number of pairs of cliques in @xmath14 sharing one or more vertices is @xmath226 , theorem  [ th1 ] shows that @xmath512 , considering only pairs in the giant component .",
    "fix two disjoint sets @xmath185 , @xmath186 of @xmath2 vertices of @xmath14 , and let @xmath513 be the probability that @xmath185 and @xmath186 are joined in @xmath11 given that @xmath185 and @xmath186 are cliques in @xmath14 .",
    "then we have @xmath514 .",
    "hence , whenever @xmath515 , we have @xmath516 .    now @xmath513 is the probability of an increasing event ( in the product space corresponding to the @xmath517 possible edges outside @xmath68 , @xmath185 ) , and is hence an increasing function of @xmath12 . since @xmath518 as @xmath59",
    ", it follows that @xmath519 if @xmath520 .",
    "thus , the expected number of unconnected pairs of cliques in @xmath11 is @xmath226 whenever @xmath511 .",
    "since the number of cliques is concentrated around @xmath56 , it follows that whp almost all vertices of @xmath11 lie in a single component .",
    "dernyi , palla and vicsek  @xcite suggest that for @xmath13 , ` at the critical point ' , i.e. , when @xmath521 , the largest component in @xmath11 contains roughly @xmath64 vertices of @xmath11 , i.e. , roughly @xmath64 @xmath2-cliques .",
    "this is based both on computer experiments , and on the heuristic that at the critical point , the giant component in random graphs is roughly ` treelike ' .",
    "this latter heuristic seems extremely weak : there is no reason why a treelike structure in @xmath11 can not contain many more than @xmath64 @xmath2-cliques .",
    "indeed , one would not expect whether or not two @xmath2-cliques share a single vertex to play much role in the component structure of @xmath11",
    ".    it would be interesting to know whether the observation of @xcite is in fact correct , but there are several problems .",
    "firstly , the question is not actually that natural : why chose exactly this value of @xmath12 ? in @xmath14 , it is natural to take @xmath522 ( or @xmath523 ; it turns out not to matter ) as ` the ' critical probability , since in this case one has at the beginning a very good approximation by an exactly critical branching process .",
    "however , in general there is a scaling window within which , for example , the largest and second largest components are comparable in size . for @xmath14",
    "the window is @xmath524 ; see bollobs  @xcite and uczak  @xcite ; see also the book  @xcite . for other random graph models , establishing the behaviour of the largest component in and around the scaling window can be very difficult ; see , for example , ajtai , komls and szemerdi  @xcite , bollobs , kohayakawa and uczak  @xcite , and borgs , chayes , van der hofstad , slade and spencer  @xcite .    in general",
    ", one would expect that inside the scaling window , the largest component would have size of order @xmath525 , where @xmath142 is the ` volume ' , which here would presumably be @xmath526 .",
    "note that this need not contradict the experimental results of dernyi , palla and vicsek  @xcite : it may simply be that their choice of @xmath12 is ( slightly ) outside the window .    unfortunately , due to the dependence in the model , it seems likely to be extremely difficult to establish results about the scaling window , or about the behaviour at @xmath521 .",
    "the problem is that there are @xmath228 errors in the branching process approximation discussed above that appear right from the beginning . on the one hand , for @xmath13 ,",
    "as soon as we find a new @xmath9 sharing @xmath3 vertices with an earlier @xmath9 , there is a probability of order @xmath12 that a single extra ` exceptional ' edge is present forming a @xmath527 , and thus forming extra @xmath528s from which we need to explore at the next step . in the other direction , after even one step of our exploration , we have tested whether any vertex @xmath258 not so far reached is joined to all vertices in certain @xmath528s .",
    "the negative information that @xmath258 is not so joined reduces the probability that @xmath258 is joined to any new @xmath528 slightly ; in fact by a factor of @xmath529 for each @xmath528 previously tested . to study the scaling window , or",
    "the behaviour at @xmath521 or at @xmath530 , say , one would presumably need to understand the net effect of these positive and negative deviations from the branching process to an accuracy much higher than the size of each effect .",
    "this seems a tall order even for the first few steps in the branching process , let alone when the component has grown to size @xmath531 or even @xmath532 .",
    "in the rest of the paper we consider several variants of the clique percolation problem discussed above . in most cases where we can prove results , the proofs are minor modifications of those above ,",
    "so to avoid trying the reader s patience too far we shall only briefly indicate the changes .      given @xmath533 and @xmath534 ,",
    "let @xmath535 be the random directed graph on @xmath346 $ ] in which each of the @xmath536 possible directed edges is present with probability @xmath12 , independently of the others .",
    "thus doubled edges are allowed : edges @xmath537 and @xmath538 may both be present ( though this will turn out to be irrelevant ) , and the simple graph underlying @xmath535 has the distribution of @xmath539 .",
    "let @xmath540 be a fixed orientation of @xmath9 ; for the moment we shall take @xmath540 to be @xmath541 , that is , @xmath9 with a linear order : @xmath542 $ ] and @xmath543 . given a directed graph @xmath544 ,",
    "let @xmath545 denote the set of all copies of @xmath540 in @xmath544 . to be totally formal",
    ", we may take @xmath546 to be the set of all subsets of @xmath547 edges of @xmath544 that form a graph isomorphic to @xmath540 .",
    "if a given set @xmath83 of @xmath2 vertices of @xmath544 contains double edges , then it may span several copies of @xmath540 , while if @xmath83 spans no double edges it spans at most one copy of @xmath540 .",
    "( for orientations @xmath540 with automorphisms , the latter statement would not be true if we considered injective homomorphisms from @xmath540 .",
    "this is the reason for the somewhat fussy definition of a ` copy ' of @xmath540 . )    for @xmath7 , let @xmath548 be the graph formed from @xmath544 as follows : let the vertex set of @xmath549 be @xmath545 , and join two vertices if the corresponding copies of @xmath540 share at least @xmath10 vertices .",
    "note that two copies may share @xmath2 vertices ( if double edges are involved ) ; this will turn out to be irrelevant .",
    "our aim now is to study the emergence ( as @xmath12 varies ) of a giant component in @xmath550 , the graph @xmath549 defined on the copies of @xmath540 in @xmath535 .",
    "we start by restricting our attention to @xmath551 . with @xmath13 , the study of this model",
    "was proposed by palla , farkas , pollner , dernyi and vicsek  @xcite , who predicted a critical point of @xmath552 .",
    "as we shall see , this prediction is correct .",
    "let us consider the component exploration in @xmath550 analogous to that in @xmath11 described in section  [ sec_cv ] .",
    "the typical case is that we are looking for new @xmath541s containing a given @xmath553 , say @xmath83 , consisting of @xmath83 together with @xmath114 new vertices .",
    "as before , we expect to find a roughly poisson number of such new @xmath541s , but now the mean is slightly different : in addition to choosing a set @xmath142 of @xmath114 new vertices , we must consider the @xmath554 linear orders on @xmath555 consistent with the order we already have on @xmath83",
    ". given @xmath142 and such an order , the probability that this particular @xmath541 is present is then @xmath118 as before .",
    "as in the undirected case , each new @xmath541 we find typically gives rise to @xmath25 new @xmath553s to explore from in the next step .",
    "let @xmath556 be given by @xmath557 the proof of theorem  [ th1 ] goes through _ mutatis mutandis _ to give the result below .",
    "one can also obtain analogues of the undirected results for the cases @xmath558 and @xmath559 ; we omit these for brevity .      note that the function @xmath220 appearing here is the same function as in theorem  [ th1 ] , but now evaluated at @xmath563 rather than at @xmath18 . in particular , @xmath564 if and only if @xmath565 , and the critical point is given by the solution to @xmath566 . in the special case @xmath13 , we have @xmath567 , so the critical point is exactly as predicted by palla , farkas , pollner , dernyi and vicsek  @xcite .",
    "as the proof really follows that of theorem  [ th1 ] very closely , we only briefly describe the differences .",
    "the argument in subsection  [ ss_ub ] is essentially unmodified ; it is still true that the first @xmath568 ` exceptional ' edges give rise to the addition of @xmath568 extra @xmath553s , arguing as before using the total degree of new vertices , rather than in- or out - degree , say .    for the lower bound",
    ", we can argue much of the time using the underlying undirected graph @xmath0 rather than @xmath569 .",
    "indeed , when exploring from a @xmath553 @xmath113 , say , we let @xmath259 be the set of ` clean ' vertices joined in @xmath0 to every vertex of @xmath113 .",
    "we then look for undirected @xmath2-cliques in @xmath261 $ ] . arguing as before , the number we find can be coupled to agree ( up to a negligible error term ) with a poisson distribution with the appropriate mean , now @xmath570 .",
    "moreover , as before , we may assume that the @xmath2-cliques we find are vertex disjoint . only at this point",
    "do we check the orientations of the @xmath438 new edges involved in each @xmath2-clique ; the probability that we find one of the @xmath554 orientations that gives a @xmath541 extending @xmath113 is @xmath571 , so the number of such @xmath541s that we do find may be closely coupled to a poisson distribution with mean @xmath563 as required .",
    "we now turn out attention to the phase transition in the graph @xmath550 defined on the copies of @xmath540 in @xmath535 , where @xmath540 is some non - transitive orientation of @xmath9 .",
    "perhaps surprisingly , it turns out that something genuinely new happens in this case .",
    "let @xmath572 , @xmath573 , let @xmath540 be the orientation of @xmath574 shown in figure  [ fig1 ] , and let @xmath550 be defined as before .",
    "when exploring a component of @xmath550 , suppose that we have found a certain copy of @xmath540 , and are looking for new copies containing a particular subgraph @xmath83 of order @xmath575 .",
    "there are now four separate cases , although one can combine them in pairs .",
    "first suppose the vertex set of @xmath83 is @xmath576 , so @xmath83 is an oriented triangle .",
    "if we find a vertex @xmath258 joined to @xmath424 , @xmath363 and @xmath577 , there are six combinations of orientations of @xmath578 , @xmath579 and @xmath580 that lead to a copy of @xmath540 : either two edges are oriented towards @xmath258 and one away , in which case @xmath258 plays the role of @xmath150 in the new copy of @xmath540 , or two are oriented away from @xmath258 and one towards , in which case @xmath258 plays the role of @xmath424 .",
    "the same holds if @xmath581 , since @xmath83 is again an oriented triangle .    in the other two cases ,",
    "@xmath83 is a linearly ordered triangle , and either @xmath258 sends edges to the top two vertices of @xmath83 and receives an edge from the bottom one , and so plays the role of @xmath577 , or @xmath258 sends an edge to the top vertex and receives edges from the bottom two , playing the role of @xmath363 .",
    "suppose more generally that @xmath540 is an orientation of @xmath9 in which no two vertices are equivalent ( the orientation in figure  [ fig1 ] has this property ) .",
    "let @xmath582 be the @xmath2-by-@xmath2 matrix whose @xmath583th entry is the number of ways of orienting the edges from a new vertex @xmath258 to @xmath584\\setminus\\{j\\}$ ] such that @xmath585 forms a graph isomorphic to @xmath540 with @xmath258 playing the role of vertex @xmath50 .",
    "for example , with @xmath540 as in figure  [ fig1 ] , numbering the vertices in the order @xmath150 , @xmath424 , @xmath363 , @xmath577 , we have @xmath586 let us say that a copy in @xmath544 of a subgraph of @xmath540 induced by @xmath3 vertices is of _ type @xmath125 _ if it is formed by omitting the vertex @xmath125 . also , let us say that a copy of @xmath540 found in our exploration by adding a new vertex @xmath258 to a subgraph of @xmath540 with @xmath3 vertices is of _ type @xmath50 _ if the new vertex corresponds to vertex @xmath50 of @xmath540 .",
    "then , towards the start of our exploration , the expected number of type @xmath50 copies of @xmath540 we reach from a type @xmath125 subgraph is @xmath587 .",
    "when we continue the exploration , each type @xmath50 copy of @xmath540 gives rises to one new subgraph of each type other than @xmath50 , and this gives us our branching process approximation .",
    "for the formal statement , less us pass to the general case @xmath7 .",
    "for simplicity , the reader may prefer to consider only graphs @xmath540 such that all @xmath43 sets of @xmath114 vertices of @xmath540 are non - equivalent , so that when we extend an @xmath10 vertex graph to a graph isomorphic to @xmath540 we can identify which @xmath114 vertices of @xmath584 $ ] the new vertices correspond to . in general , we may resolve ambiguous cases arbitrarily .",
    "( one could instead collapse the corresponding types in the branching process , but this complicates the description . )",
    "let @xmath202 be the @xmath43-by-@xmath43 matrix defined as follows : given two @xmath10-element subsets @xmath365 and @xmath588 of @xmath584 $ ] , let @xmath83 be the subgraph of @xmath540 induced by the vertices in @xmath365 , and consider a set @xmath142 of @xmath114 ` new ' vertices joined to each other and to all vertices in @xmath365 .",
    "let @xmath589 be the number of ways of orienting these new edges so that @xmath590 forms a copy of @xmath540 , and the new vertices correspond to @xmath584\\setminus b$ ] . for @xmath13",
    ", this generalizes the definition above .",
    "let @xmath591 be the multi - type galton ",
    "watson branching process in which each particle has a type from @xmath592}{\\ell}$ ] , started with one particle of each type , in which children of a particle of type @xmath365 are generated as follows : first generate independent poisson random variables @xmath593 , @xmath594}{\\ell}$ ] , with @xmath595 .",
    "then generate @xmath596 children of each type @xmath597 .",
    "let @xmath598 denote the survival probability of @xmath599 .",
    "the proof of theorem  [ th1_d ] extends very easily to prove the following result .",
    "[ th1_mt ] fix @xmath51 and an orientation @xmath540 of @xmath9 , and let @xmath5 be chosen so that @xmath600",
    ". then , for any @xmath52 , whp we have @xmath601 where @xmath602 is the expected number of copies of @xmath540 in @xmath535 .",
    "@xmath200    theorem  [ th1_mt ] is rather unwieldy , but it is not too hard to extract the critical point .",
    "indeed , in @xmath599 the expected number of type-@xmath588 children of a particle of type @xmath365 is @xmath603 , where @xmath604 , with @xmath605 the identity matrix and @xmath157 the matrix with all entries @xmath41 . from elementary branching process results , the critical value of @xmath12 is thus given by the solution to @xmath606 where @xmath607 is the maximum eigenvalue of @xmath608 .",
    "note that this is consistent with theorem  [ th1_d ] : taking @xmath540 to be @xmath541 , that is , @xmath9 with a transitive order , it is easy to check that @xmath609 for every @xmath610}{\\ell}$ ] .",
    "indeed , we must choose one of the @xmath611 possible orders on the new vertices . then the relative order of the new and old vertices",
    "is determined by the fact that the new vertices should play the role of @xmath584\\setminus b$ ] in the resulting @xmath541 .",
    "it follows that @xmath440 is the @xmath43-by-@xmath43 matrix with all entries equal to @xmath612 , so @xmath613    to give a non - trivial application of theorem  [ th1_mt ] , let @xmath540 be the orientation of @xmath574 shown in figure  [ fig1 ]",
    ". then @xmath202 is given by , so we have @xmath614 it follows that @xmath607 , which may be found as twice the maximum eigenvalue of a 2-by-2 matrix , is equal to @xmath615 , so the critical @xmath12 is @xmath616 .      in this subsection",
    "we return to unoriented graphs , and consider another natural notion of adjacency for copies of @xmath9 in a graph @xmath0 : given a parameter @xmath617 , two @xmath9s are considered adjacent if they are vertex disjoint and there are at least @xmath10 edges of @xmath0 from one to the other .",
    "( one could omit the disjointness condition ; much of the time this will make little difference . insisting on this condition simplifies the picture slightly . )",
    "let @xmath618 be the corresponding graph on the copies of @xmath9 in @xmath0 , and let @xmath619 be the graph obtained in this way from @xmath14 .",
    "for this notion of adjacency , the most natural special case to consider is @xmath333 ; the other extreme case , @xmath620 , of course corresponds to considering copies of @xmath621 sharing @xmath2 vertices .",
    "it turns out that we can fairly easily determine the percolation threshold in @xmath622 for those parameters @xmath623 for which , near the threshold , there are ` not too many ' copies of @xmath9 in @xmath14 ; more precisely , there are @xmath624 copies .",
    "this always includes the case @xmath333 .",
    "let @xmath625 be given by @xmath626 and , as before , let @xmath627 be the expected number of copies of @xmath9 in @xmath14 , so @xmath628 .",
    "let @xmath629 denote a galton ",
    "watson branching process in which the offspring distribution is poisson with mean @xmath39 , started with a single particle , and let @xmath630 denote the survival probability of @xmath629 .",
    "note that @xmath631 is the asymptotic size ( number of vertices ) in the largest component of @xmath632 .",
    "note that there is a choice of @xmath5 satisfying the conditions of theorem  [ th_e ] if and only if @xmath638 .",
    "indeed , the main force of theorem  [ th_e ] is to establish that in this case , the threshold for percolation in @xmath622 is at the solution @xmath338 to @xmath639 , which satisfies @xmath640 , with the constant given by .",
    "as in section  [ sec_cv ] , the proof of theorem  [ th_e ] will give an @xmath641 bound in the subcritical case , as well as an @xmath642 bound on the 2nd largest component in the supercritical case .",
    "the former applies also for @xmath643 , but only under the assumption that @xmath636 , i.e. , well below what is presumably the critical point in this case .",
    "one can also extrapolate to the highly supercritical case as in subsection  [ ss_ext ] . here",
    "one needs the condition @xmath636 only for the starting value of @xmath12 , and",
    "the conclusion is that for @xmath644 and any @xmath12 with @xmath511 one has , as expected , almost all vertices of @xmath622 in a single component .",
    "we start with the upper bound .",
    "let us call a copy of @xmath9 in @xmath14 _ isolated _ if it shares no vertices with any other copies of @xmath9 .",
    "let @xmath142 and @xmath202 denote the number of isolated and non - isolated copies of @xmath9 in @xmath14 . by a standard calculation ,",
    "the probability that a given copy of @xmath9 is not isolated is @xmath645 , so @xmath646 , and whp we have @xmath647 .",
    "more precisely , we may choose some @xmath648 so that the event @xmath160 that @xmath649 has probability @xmath228 . since the number of copies of @xmath9 in @xmath14 is concentrated about its mean , choosing @xmath217 suitably , the event @xmath483 that @xmath650 also holds whp .",
    "let @xmath651 list the vertex sets of all isolated copies of @xmath9 in @xmath14 , and @xmath652 those of all non - isolated copies .",
    "we condition on @xmath142 , @xmath202 , and the sequences @xmath653 and @xmath654 .",
    "we assume that @xmath655 holds ; we may do so since @xmath656 .",
    "let @xmath325 denote one of the specific events we condition on , and let @xmath657 denote the set of all edges lying within some @xmath113 or @xmath658 , and @xmath659 the set of all @xmath660 remaining potential edges of @xmath0 .",
    "let us call a non - empty set @xmath661 _ forbidden _ if by adding zero of more edges of @xmath657 to @xmath662 one can form a @xmath9 ; we write @xmath663 for the collection of forbidden sets .",
    "the event @xmath325 may be represented as the intersection of an up - set condition @xmath103 , that every edge in @xmath657 is present in @xmath14 , and a down - set condition @xmath101 , that no forbidden set is present in @xmath659 .",
    "note that @xmath101 may be regarded as a down - set in @xmath664 .    for the moment , we condition only on @xmath103 . to be pedantic ( while , at the same time , committing the common abuse of using the same notation for a random variable and its possible values ) , we fix sequences @xmath653 and @xmath654 consistent with @xmath655 , and condition on the event @xmath665 . since we are conditioning only on the presence of a fixed set of edges , every edge of @xmath659 is present independently with probability @xmath12 .",
    "let @xmath188 be the auxiliary graph with vertex set @xmath666 $ ] in which @xmath50 and @xmath125 are joined if @xmath113 and @xmath292 are joined by at least @xmath10 edges .",
    "the probability @xmath318 of this event satisfies @xmath667 since , given @xmath103 , @xmath188 has exactly the distribution of @xmath668 , it follows from the classical result of erds and rnyi  @xcite that whp the largest component of @xmath188 has order within @xmath669 of @xmath670 . note that this corresponds to the desired number of @xmath9s in the largest component @xmath72 of @xmath622 .",
    "the problem is that we have not yet conditioned on @xmath101 , or allowed for the possible presence of non - isolated @xmath9s in @xmath72 .    to prove the upper bound in we",
    "must account for the non - isolated @xmath9s .",
    "let us say that @xmath113 and @xmath671 form a _",
    "bad pair _ if they are joined by @xmath10 edges in @xmath14 .",
    "given @xmath103 , the probability of this event is exactly @xmath318 , so the expected number of bad pairs @xmath672 is @xmath673 .",
    "similarly , @xmath658 and @xmath671 form a bad pair if they are vertex disjoint , and joined by at least @xmath10 edges .",
    "the expected number of bad pairs @xmath674 is at most @xmath675 .",
    "let @xmath676 be the graph on @xmath677 $ ] defined in the natural way : two vertices are joined if the corresponding copies of @xmath9 are disjoint and joined by at least @xmath10 edges .",
    "we have shown that @xmath678 , which is exactly the number of bad pairs , has expectation @xmath679 .",
    "it is well known that for @xmath39 fixed , the giant component in @xmath680 is _ stable upwards _ , in the sense that adding @xmath681 vertices and edges can not increase its size by more than @xmath681 .",
    "indeed , this follows from the qualitative form of the distribution of the small components : for details , see , for example , theorem 3.9 of bollobs , janson and riordan  @xcite , where the corresponding result is proved for a more general model .",
    "( this result also shows ` downwards stability ' , which we do not need here .",
    "downwards stability is much harder to prove : luczak and mcdiarmid  @xcite established this for the erds ",
    "rnyi model ; in  @xcite , their argument is extended to the more general model considered there . ) applying this stability result to @xmath188 , we deduce that , given @xmath103 , we have @xmath682 . for any @xmath335",
    ", we have @xmath683 where the inequality is from harris s lemma applied in @xmath664 . since @xmath684 is exactly the graph @xmath622 , the upper bound in follows .",
    "turning to the lower bound , we may now ignore the complications due to non - isolated @xmath9s , and confine our attention to @xmath188 .",
    "however , we must now show that conditioning on @xmath101 , which tends to decrease @xmath685 , does not do so too much .",
    "we shall use the same type of argument as in the proof of lemma  [ el ] : exploring @xmath188 step by step , we shall show that conditioning on @xmath101 does not decrease the probability of finding an edge in @xmath188 by showing that finding an edge in @xmath188 would not decrease the probability of @xmath101 much",
    ". there will be some complications due , for example , to the possible presence of @xmath9s made up of edges in @xmath4 corresponding to edges in @xmath188 .",
    "as before , we shall condition on @xmath653 and @xmath654 , assuming that @xmath655 holds , i.e. , that @xmath686 and @xmath687 .",
    "in fact , we shall impose a further condition .",
    "let @xmath688 be the event that there is a vertex of @xmath14 in more than @xmath407 copies of @xmath9 , noting that whether or not @xmath688 holds is determined by the sequences @xmath653 and @xmath654 .",
    "since @xmath689 , it is easy to check that @xmath690 : we omit the standard calculation which is based on the fact that @xmath9 is strictly balanced , so having found a moderate number of @xmath9s containing a given vertex @xmath258 does not significantly increase the chance of finding a further such @xmath9 .    from now on we condition on the sequences @xmath653 and @xmath654 , assuming as we may that @xmath691 holds . defining @xmath665 and @xmath692 as before ,",
    "this is again equivalent to conditioning on @xmath99 . as",
    "before , since we fix @xmath653 and @xmath654 , the event @xmath103 is simply the event that every edge in the fixed set @xmath693 is present in @xmath14 .",
    "note for later that , since @xmath688 does not hold , we have @xmath694 for every @xmath695 , where @xmath696 is the number of edges of @xmath657 incident with @xmath258 .",
    "let @xmath697 be the @xmath698 possible edges of @xmath188 , listed in an arbitrary order .",
    "we now describe an algorithm that reveals a subgraph @xmath699 of @xmath188 . during step @xmath152 , @xmath700",
    ", we shall test whether @xmath701 is present in @xmath188 , except that if @xmath701 , together with some previously discovered edges of @xmath699 , would form a cycle in @xmath699 , or would cause the degree of some vertex of @xmath699 to exceed @xmath407 , then we omit step @xmath152 .",
    "step @xmath152 consists of a series of sub - steps : in each we consider one of the @xmath702 sets @xmath605 of @xmath10 potential edges of @xmath4 whose presence would give rise to the edge @xmath701 in @xmath188 , and test whether all edges in @xmath605 are present in @xmath0 .",
    "if such a test succeeds , we add @xmath701 to @xmath699 , and omit further tests for the same @xmath701 , i.e. , continue to step @xmath703 .",
    "suppose that we have reached the @xmath81th sub - step of the algorithm described above , and let @xmath704 be the set of @xmath10 potential edges of @xmath0 whose presence we are about to test for .",
    "we claim that , given the history , the conditional probability that all edges in @xmath605 are is present is @xmath705 .",
    "more precisely , let @xmath706 be the union of all sets @xmath707 , @xmath708 , which we found to be present , and let @xmath709 . also , let @xmath710 be the set of sets @xmath707 , @xmath708 , found to be absent , and let @xmath711 be the event that no @xmath712 is present in @xmath713 . recalling that we start by conditioning on @xmath99 , the algorithm reaches its particular present state if and only if @xmath714 holds , so",
    "our precise claim is that for any @xmath115 , if @xmath64 is large enough , then for any possible @xmath715 , @xmath716 and @xmath711 we have @xmath717    before proving , let us see that the theorem  [ th_e ] follows .",
    "let @xmath718 be the union of @xmath699 and all edges @xmath701 which we omitted to test .",
    "assuming , we always have @xmath719 indeed , if @xmath701 is omitted , the conditional probability above is @xmath41 by definition ; otherwise , we apply to the @xmath702 sub - steps associated to @xmath701 .",
    "now tells us that for @xmath64 large enough , @xmath718 stochastically dominates @xmath720 , say .",
    "taking @xmath250 small enough , it follows that whp @xmath721    if @xmath722 , then we only omit step @xmath152 if adding @xmath701 would create a cycle , so in this case @xmath699 is the union of one spanning tree for each component of @xmath188 , and all edges of @xmath718 join vertices of @xmath699 that are already joined by paths in @xmath699 .",
    "hence @xmath723 . as noted earlier , given only @xmath103 , the graph @xmath188 has exactly the distribution of @xmath668 .",
    "since @xmath103 is a principal up - set , and @xmath101 is a down - set , it follows that the distribution of @xmath188 given @xmath99 , which is what we are considering here , is stochastically dominated by that of @xmath668 . since @xmath724",
    ", it follows that whp @xmath722 , so whp @xmath725 .",
    "since @xmath726 , this together with gives the lower bound in , completing the proof of theorem  [ th_e ] .",
    "it remains only to prove .",
    "let us start by observing that @xmath727 can not contain any forbidden set @xmath728 , i.e. , that the set @xmath729 contains no @xmath9 other than @xmath730 .",
    "this is true of @xmath731 since we condition on @xmath101 , and we are assuming that the present state of the algorithm is a possible one .",
    "suppose then that adding @xmath715 to @xmath731 creates a new copy @xmath84 of @xmath9 , and let the edge @xmath701 we are testing be @xmath583 .",
    "now @xmath706 contains edges between @xmath732 and @xmath733 if and only if we have already found the edge @xmath734 in @xmath699 .",
    "if @xmath84 meets three or more of the @xmath732 , then @xmath735 would contain a triangle , which is impossible by definition of the algorithm .",
    "this leaves only the case that @xmath84 meets exactly two sets @xmath732 , which must be @xmath113 and @xmath292 .",
    "but then the only edges of @xmath727 between @xmath113 and @xmath292 are those of @xmath715",
    ". now @xmath84 contains at least @xmath3 edges between these sets , while @xmath736 , so there is no such @xmath9 .",
    "there are two types of conditioning in , that on @xmath737 and that on @xmath738 .",
    "the first type is trivial , since @xmath737 is simply the event that every edge in @xmath731 is present .",
    "let @xmath739 .",
    "then we may as well work in @xmath740 , the product probability measure on @xmath741 in which each edge is present with probability @xmath12 .",
    "let @xmath742 and let @xmath743 be the event that none of the ` forbidden ' sets in @xmath744 is present , so @xmath745 .",
    "also , let @xmath746 be the event that all edges in @xmath715 are present , noting that @xmath747 .",
    "then is equivalent to @xmath748 the key idea is to split @xmath744 into two sets , @xmath749 and @xmath750 , the first consisting of those @xmath662 that intersect @xmath715 , and the second those that do not .",
    "it turns out that we can ignore the ones that do not .",
    "more precisely , let @xmath751 be the event that no @xmath752 is present , and @xmath753 the event that no @xmath754 is present , so @xmath755",
    ".    we may rewrite in any of the following forms , which are step - by - step trivially equivalent : ( we drop the superscript @xmath440 at this point , since the events we are now considering are in any case independent of edges outside @xmath440 )        we shall prove by simply ignoring the conditional probability on the right , showing that @xmath758 this clearly implies , and hence , from the argument above , implies .",
    "let @xmath759 be the complement of @xmath751 , so our aim is to show that @xmath760 .",
    "now @xmath761 is again an event of a very simple form , that a certain particular set @xmath715 of edges is present .",
    "since @xmath759 is an up - set while @xmath753 is a down - set , applying harris s lemma in @xmath762 , it follows that @xmath763 so it suffices to prove that @xmath764 .    at this point",
    "we have eliminated all non - trivial conditioning ; all that is left is counting .",
    "indeed , @xmath765 recalling , there are two contributions to the sum above .",
    "the first is from sets @xmath766 corresponding to sets @xmath767 , i.e. , to failed tests for previous @xmath707 . by definition of @xmath749",
    ", we have such an @xmath766 if and only if @xmath768 , in which case @xmath707 and @xmath715 correspond to the same potential edge @xmath701 of @xmath188 .",
    "but then there are at most @xmath769 possibilities for @xmath707 , and for each we have @xmath770 , so the contribution to is @xmath771 .",
    "the remaining terms come from @xmath772 with @xmath728 and with @xmath773 , i.e. , with @xmath774 . recalling that @xmath662 is a set of edges that , together with @xmath657 , would create a @xmath9",
    ", it thus suffices to show that @xmath775 where the sum runs over all copies of @xmath9 on @xmath776 containing at least one edge from @xmath715 .",
    "now @xmath699 has maximum degree at most @xmath407 by the definition of our algorithm .",
    "hence @xmath777 for every @xmath695 . using it follows that the graph @xmath1 on @xmath776 formed by the edges in @xmath729 has maximum degree at most @xmath778 , say .",
    "this is all we shall need to prove .",
    "let @xmath244 be the contribution to the sum in from copies @xmath84 of @xmath9 such that @xmath779 has exactly @xmath50 components ( including trivial components of size @xmath41 ) .",
    "since @xmath84 must contain an edge of @xmath780 , we have @xmath781 .",
    "let @xmath782 , and set @xmath783 it is easy to check that for @xmath781 we have @xmath784 : there are @xmath10 choices for ( one of the ) edges of @xmath715 to include , then picking vertices one by one , either @xmath64 choices if we start a new component of @xmath779 , or at most @xmath785 if we do not . finally , if @xmath779 has @xmath50 components , then considering the case where these components are all complete , by convexity @xmath786 is maximized if the components have sizes @xmath787 , so @xmath788 .",
    "for @xmath413 we may improve our estimate slightly : since @xmath1 does not contain @xmath9 , we gain at least a factor of @xmath12 , so @xmath789 .",
    "now @xmath790 , so this contribution to is negligible . to handle the remaining cases ,",
    "note that @xmath791 so @xmath792 increases as @xmath50 increases .",
    "hence the maximum of @xmath793 for @xmath794 is attained either at @xmath795 or at @xmath796 .",
    "now @xmath797 , and it is easy to check that this is @xmath228 . indeed , since @xmath635 we have @xmath798 , and since @xmath799 we have that @xmath800 is a constant negative power of @xmath64 .    at the other end of the range , @xmath801 , and we have @xmath802 .",
    "thus both @xmath803 and @xmath804 are @xmath228 , which gives @xmath805 for @xmath794 .",
    "thus @xmath806 proving .",
    "this was all that remained to prove the theorem .",
    "it is natural to wonder whether theorem  [ th_e ] can be extended . for @xmath333 ,",
    "the picture is complete : defining @xmath338 by @xmath807 , since @xmath808 we have @xmath809 whenever @xmath341 .",
    "as noted earlier , percolation in @xmath622 for @xmath511 follows by monotonicity arguments .",
    "we conclude this paper by briefly considering the graph @xmath812 obtained from @xmath14 by taking one vertex for each copy of some fixed graph @xmath188 with @xmath813 , and joining two vertices if these copies share at least @xmath10 vertices , where @xmath7 .",
    "ones first guess might be that the results in section  [ sec_cv ] extend at least to regular graphs @xmath188 without much difficulty , but this turns out to be very far from the truth .",
    "in fact , it seems that almost all cases are difficult to analyze .",
    "we start with the most interesting end of the range , where @xmath13 , as in the original question of dernyi , palla and vicsek  @xcite . to keep things simple ,",
    "let @xmath188 be the cycle @xmath814 . for @xmath815 ,",
    "@xmath814 is complete , so this case is covered in section  [ sec_cv ] .",
    "the case of @xmath816 is already interesting : when moving from one copy of @xmath816 to another , we may change opposite vertices essentially independently of each other .",
    "the appropriate exploration is thus as follows : suppose we have reached a @xmath816 with vertex set @xmath817 , where each of @xmath818 and @xmath462 is a pair of opposite vertices .",
    "furthermore , suppose we reached this @xmath816 from another @xmath816 containing @xmath818 .",
    "then we continue by replacing @xmath818 by some other pair @xmath463 of common neighbours of @xmath462 .",
    "suppose that @xmath819 ; in particular , set @xmath820 .",
    "the number @xmath279 of common neighbours of @xmath462 outside @xmath818 has essentially a poisson distribution with mean @xmath821 .",
    "the number of choices for @xmath822 is @xmath823 , which has expectation @xmath824",
    "so we believe the critical point will be when this expectation is @xmath41 , i.e. , at @xmath825 of course , it is not clear that the branching process approximation we have implicitly described is a good approximation to the component exploration process . however , it is not hard to convince oneself that this is the case , at least at first .",
    "the key point is that when we have not yet reached many vertices , the chance of finding a new vertex adjacent to three or more reached vertices is very small .",
    "hence the sets of common neighbours of two pairs @xmath826 and @xmath827 are essentially independent , even if @xmath826 and @xmath827 share a vertex .",
    "we have not checked the details , but we expect that it is not hard to show rigorously that @xmath338 is indeed the threshold in this case , although unforeseen complications are of course conceivable .    taking things further , one might expect the argument above to work for @xmath828 , say , but in fact it breaks down after one step .",
    "suppose we start from @xmath829 and first replace @xmath150 , @xmath424 and @xmath363 by other suitable vertices .",
    "then we have sets @xmath365 , @xmath588 and @xmath72 of candidates for @xmath150 , @xmath424 , and @xmath363 .",
    "the problem is at the next step : the possibilities for @xmath830 , @xmath831 , @xmath832 associated to different triples @xmath833 are far from independent : for triples @xmath834 and @xmath835 , the choices for @xmath830 are exactly the same .",
    "in fact , not only can we not prove a result for any @xmath814 , @xmath836 , but we do not even have a conjecture as to the correct critical probability , although this is clearly of order @xmath837 .",
    "although @xmath816 is the simplest non - complete example , cycles turn out not to be the easiest generalization : it is almost certainly not hard to adapt the outline argument above to complete bipartite graphs @xmath838 .",
    "if @xmath839 , then setting @xmath840 , and letting @xmath841 denote a poisson random variable with mean @xmath842 , the critical point should be given by the solution to @xmath843 generalizing .",
    "if @xmath844 , the situation is a little different , as alternate steps in the exploration have different behaviour .",
    "suppose that @xmath845 , and set @xmath846 . then @xmath847 and @xmath848 , so on average a set of @xmath152 vertices has many common neighbours , and so lies in many copies of @xmath838 , while a typical set of @xmath355 vertices has no common neighbours .",
    "starting from a given @xmath838 , with vertex classes @xmath849 and @xmath83 of sizes @xmath850 and @xmath851 , let @xmath231 denote the set of common neighbours of @xmath849",
    ". then @xmath852 , and @xmath853 will be concentrated near @xmath854 . replacing @xmath83 by any of the other @xmath855 subsets @xmath856 of @xmath231 of size @xmath355 ,",
    "since sets of size @xmath355 have few common neighbours , the most likely way the exploration will continue is that some @xmath856 will have one common neighbour @xmath144 outside @xmath849 .",
    "then for each vertex @xmath857 of @xmath849 we reach a new @xmath838 with @xmath849 replaced by @xmath858 . for each @xmath856",
    "we expect to find around @xmath848 such vertices @xmath144 , so overall the average number of new choices for @xmath859 is @xmath860 , and we expect the critical point to be given by @xmath861 where @xmath39 satisfies @xmath862 ; we have not checked the details .",
    "finally , since the case @xmath13 seems too hard in general , one could consider the other extreme @xmath333 .",
    "this is much easier , though also less interesting .",
    "if @xmath188 is strictly balanced , it is very easy to see that the critical point occurs when @xmath863 , where @xmath18 is the expected number of copies of @xmath188 containing a given vertex @xmath258 . for non - balanced @xmath188 things",
    "are a little more complicated : having found a ` cloud ' of copies of @xmath188 containing a single copy of the ( for simplicity unique ) densest subgraph @xmath684 of @xmath188 , one next looks for a second cloud meeting the current cloud , and the critical point should be when the expected number of clouds meeting a given cloud is @xmath41 .",
    "this type of argument can probably be extended to @xmath864 , at least if we impose the natural condition in this case that our copies of @xmath188 should share an edge , rather than just two vertices . beyond this",
    ", the whole question seems very difficult .                  c.  borgs , j.t .",
    "chayes , r.  van der hofstad , g.  slade and j.  spencer , random subgraphs of finite graphs . i. the scaling window under the triangle condition , _ random structures algorithms _ * 27 * ( 2005 ) , 137184 ."
  ],
  "abstract_text": [
    "<S> dernyi , palla and vicsek introduced the following dependent percolation model , in the context of finding communities in networks . </S>",
    "<S> starting with a random graph @xmath0 generated by some rule , form an auxiliary graph @xmath1 whose vertices are the @xmath2-cliques of @xmath0 , in which two vertices are joined if the corresponding cliques share @xmath3 vertices . </S>",
    "<S> they considered in particular the case where @xmath4 , and found heuristically the threshold function @xmath5 above which a giant component appears in @xmath1 . here </S>",
    "<S> we give a rigorous proof of this result , as well as many extensions . </S>",
    "<S> the model turns out to be very interesting due to the essential global dependence present in @xmath1 . </S>"
  ]
}