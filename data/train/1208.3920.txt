{
  "article_text": [
    "the generalized additive model(gam ) is a typical regression model , in which the relationship between the one - dimensional response @xmath1 and the multidimensional explanatory @xmath2 is modeled by a link function @xmath3 , as follows : @xmath4)=\\eta(\\vec{x})=\\eta_1(x_1)+\\cdots+\\eta_d(x_d),\\ ] ] where each @xmath5 is a univariate regression function .",
    "if @xmath1 has a gaussian distribution , then @xmath6 is the identity function and , hence , @xmath7 $ ] .",
    "additionally , the gam can specify a distribution such as a bernoulli , poisson or gamma distribution . in gams ,",
    "the purpose is often to estimate @xmath8 .",
    "the parametric and the nonparametric estimation techniques of @xmath8 have been established by several authors ( see hastie et al .",
    "( 1990 ) and wood ( 2006 ) ) . in this paper , @xmath8 is estimated via the penalized spline method .",
    "penalized splines were introduced by osullivan ( 1986 ) and eilers and marx ( 1996 ) , and are recognized as an efficient technique for gams . applications and theories of penalized splines in gams have been widely discussed , including by aerts et al .",
    "( 2002 ) and ruppert et al .",
    "( 2003 ) .    to construct the estimator of @xmath9 s , a repetition update method , the so - called backfitting algorithm , is often used . however",
    ", when the response has a non - gaussian distribution , such as a bernoulli or poisson distribution , the overall estimation procedure becomes complicated and its computation time grows , because the estimators are obtained by using a blend of backfitting and the fisher - scoring algorithm .",
    "on the other hand , marx and eilers ( 1998 ) proposed a new penalized spline estimator without backfitting algorithms , which is denoted as the ridge corrected penalized spline estimator ( rcps ) .",
    "we will briefly describe the rcps as we will focus on it later .",
    "the penalized spline estimator is obtained based on maximization of the penalized log - likelihood .",
    "however , it appears difficult to obtain the maximizer of the penalized log - likelihood @xmath10 as the hessian of @xmath10 is not invertible .",
    "the rcps is constructed based on the maximization of @xmath11 , which is @xmath10 plus an additional ridge penalty .",
    "since the hessian of @xmath11 is invertible , the maximizer of @xmath11 can be obtained via the fisher - scoring algorithm .",
    "thus , it is easy to construct the rcps .    in univariate models(@xmath12 ) , hall and opsomer ( 2005 ) , claeskens et al .",
    "( 2009 ) , kauermann et al .",
    "( 2009 ) and wang et al .",
    "( 2011 ) researched the asymptotic properties of penalized spline estimators .",
    "recently , yoshida and naito ( 2012 ) worked on the asymptotic distribution of penalized splines in an additive model .",
    "in contrast , horowitz and mammen ( 2004 ) , linton ( 2000 ) and yu et al .",
    "( 2008 ) studied the asymptotics for the kernel estimator in a gam .",
    "however , the asymptotic results for penalized spline estimators in gams have not yet been sufficiently developed like they have been for their applications .    in this paper ,",
    "the asymptotics for penalized splines in a gam are discussed .",
    "our main purpose is to establish the asymptotic normality of the rcps .",
    "kauermann et al .",
    "( 2009 ) showed the asymptotic normality of the penalized spline estimator in generalized linear models(glm ) .",
    "hence , the results in this paper generalize the results of kauermann et al .",
    "furthermore , penalized spline smoothing can be linked to mixed models(see lin and zhang ( 1999 ) and ruppert et al .",
    "( 2003 ) ) . in generalized additive mixed models ( gamm ) ,",
    "the penalized quasi likelihood method ( pql ) is an efficient method for obtaining the estimator and predictor .",
    "we also show the asymptotic normality of the pql fit .    this paper is organized as follows . in section 2 ,",
    "the gam is defined and the rcps is constructed by the fisher - scoring algorithm .",
    "section 3 shows the asymptotic normality of the rcps .",
    "section 4 states the asymptotics for the pql fits in a gamm . in section 5 , the applications of the approximate confidence interval are addressed .",
    "section 6 provides a numerical study to validate the asymptotic normality of the rcps .",
    "related discussions and issues for future research are addressed in section 7 , and proofs for theoretical results are given in the appendix .",
    "for the dataset @xmath13 , consider an exponential family of the generalized additive model with a canonical link function @xmath14 where @xmath15 is a @xmath16-variate explanatory variable , @xmath17 is an unknown natural parameter which has the additive formation @xmath18 where @xmath9 s is an unknown univariate function , @xmath19 is a dispersion parameter , and @xmath20 and @xmath21 are known functions .",
    "the canonical link function indicates @xmath22 , which leads to @xmath23=g^{-1}(\\eta(\\vec{x}_i))=c^\\prime(\\eta(\\vec{x}_i))$ ] and @xmath24= \\phi c^{\\prime\\prime}(\\eta(\\vec{x}_i ) ) $ ] , where @xmath25 and @xmath26 are the first and second derivatives of @xmath20 .",
    "more general settings concerned with the link function were clarified by mccullagh and nelder ( 1989 ) . in this paper , for the natural parameter @xmath27 , we assume that @xmath28=0 ( j=1,\\cdots , d)$ ] to ensure the identifiability of @xmath9 . for simplicity , we hereafter ignore the role of the dispersion parameters in ( [ model1 ] ) and set @xmath29 , thus denoting @xmath30 .    our purpose is to estimate @xmath9 using nonparametric spline methods .",
    "we now prepare the @xmath0-spline model @xmath31}(x)b_{k , j},\\ \\",
    "j=1,\\cdots , d\\ ] ] as an approximation to @xmath32 , where @xmath33}(x)(k =- p+1,\\cdots , k_{n})$ ] are the @xmath34th @xmath0-spline functions defined recursively as @xmath35}(x)&= & \\left\\ { \\begin{array}{cc } 1 , & \\kappa_{k-1}<x\\leq \\kappa_k,\\\\ 0 , & { \\rm otherwise } , \\end{array } \\right .",
    "\\\\ b_k^{[p]}(x)&=&\\frac{x-\\kappa_{k-1}}{\\kappa_{k+p-1}-\\kappa_{k-1}}b_k^{[p-1]}(x)+\\frac{\\kappa_{k+p}-x}{\\kappa_{k+p}-\\kappa_{k}}b_{k+1}^{[p-1]}(x),\\end{aligned}\\ ] ] where @xmath36 are knots and @xmath37 s is an unknown parameter .",
    "some fundamental properties of @xmath0-splines were detailed by de boor ( 2001 ) .",
    "we will write @xmath33}(x)=b_k(x)$ ] unless we specify the degree of @xmath0-splines , because we will mainly focus on the @xmath34th @xmath0-spline from now on .",
    "the suggested density of @xmath38 is defined as @xmath39 where @xmath40 , @xmath41 , @xmath42 and @xmath43 . using the estimator @xmath44 of @xmath45 ,",
    "the estimator of @xmath46 can be defined as @xmath47      to estimate @xmath48 , we prepare the log - likelihood @xmath49 where @xmath50 , @xmath51 , @xmath52 , @xmath53 $ ] , and @xmath54",
    ". it is known that the spline estimator obtained by maximization of the log - likelihood tends to display wiggle behavior. hence , we consider using the penalized spline estimator to obtain a smooth curve .",
    "define the penalized log - likelihood as follows @xmath55 where @xmath56 is the smoothing parameter @xmath57 , the @xmath58th matrix @xmath59 is the @xmath60th difference matrix , which is given by marx and eilers ( 1998 ) and @xmath61 $ ] . in general , the maximizer of ( [ pen1 ] ) is obtained by the fisher - scoring algorithm . as in the typical problem of spline methods in a gam ,",
    "however , the hessian of @xmath62 is not invertible and so the fisher - scoring method is not usable directly . to overcome this singularity problem , we can use backfitting algorithms ( see hastie and tibshirani ( 1990 ) ) .",
    "however , the overall algorithm becomes complicated and the computation grows ( see section 1 ) .",
    "these problems were discussed by marx and eilers ( 1998 ) .",
    "we will next review the ridge corrected penalized spline estimator .",
    "marx and eilers ( 1998 ) proposed a nice estimation method for @xmath48 without using a backfitting algorithm for penalized splines in the gam context .",
    "they defined the ridge corrected penalized log - likelihood as @xmath63 where @xmath64 .",
    "let @xmath65 be the maximizer of ( [ pen ] ) , which can be obtained directly via the fisher - scoring method since the hessian of @xmath66 is invertible .",
    "the gradient @xmath67 and hessian @xmath68 of @xmath66 are obtained with @xmath69z-\\frac{1}{n}q_m(\\lambda_n)-\\frac{\\gamma_n}{n } i,\\end{aligned}\\ ] ] where @xmath70 and @xmath71 are @xmath72-vectors defined in the same manner as @xmath73 .",
    "the @xmath74-step iterated estimator @xmath75 of @xmath48 can be written as @xmath76 where @xmath77 $ ] .",
    "as @xmath78 , @xmath75 converges to @xmath79 if the initial @xmath80 is appropriately chosen .",
    "the rcps of @xmath46 can be obtained as @xmath81 . in the next section ,",
    "we discuss the asymptotic properties of @xmath82^t$ ] .",
    "here , we list some assumptions regarding the asymptotics of the penalized spline estimator . +",
    "* assumptions *    1 .   the explanatory @xmath83 is distributed as @xmath84 on @xmath85^d$ ] , where @xmath85^d$ ] is the @xmath16-variate unit cube .",
    "2 .   for @xmath86 , @xmath87 and @xmath88 .",
    "the knots for the @xmath0-spline basis are equidistantly located with @xmath89 and the number of knots satisfies @xmath90 .",
    "4 .   for the non - singularity of @xmath68",
    ", @xmath91 is chosen such that @xmath92 .",
    "the smoothing parameters @xmath93 are positive sequences such that @xmath94 is larger than the maximum eigenvalue of @xmath95 .",
    "lastly , @xmath96 , where @xmath97 .    for a random variable @xmath98 , @xmath99 $ ] and @xmath100 $ ] denote the conditional expectation and variance of @xmath98 given @xmath101 , respectively . define the @xmath102th square matrix @xmath103 , where the @xmath104-th component is @xmath105^d } c^{\\prime\\prime}(\\eta(\\vec{x}))b_{-p+i}(x_k)b_{-p+j}(x_k)dp(\\vec{x}).\\end{aligned}\\ ] ] using this , we get @xmath106 . let @xmath107\\right\\ } \\label{b0}\\end{aligned}\\ ] ] and let @xmath108 .",
    "the asymptotic bias of @xmath109 can be written as @xmath110-\\eta_j(x_j)=e[\\hat{\\eta}_j(x_j)|\\vec{x}_n]-\\eta_{j0}(x_j)+\\eta_{j0}(x_j)-\\eta_j(x_j).\\ ] ] in the following proposition [ app ] , the difference @xmath111 is asymptotically evaluated .",
    "the asymptotics for @xmath112 can be shown in the following theorem [ mv ] by using the taylor expansion of @xmath113 around @xmath114 ( see lemma [ ex ] in the appendix ) , the properties of a partitioned matrix of @xmath68 and its asymptotic results .",
    "[ app ] under the assumptions , for @xmath115 @xmath116 where @xmath117 @xmath118 is the indicator function of an interval @xmath119 and @xmath120 is the @xmath34th bernoulli polynomial .",
    "[ mv ] under the assumptions , for @xmath115 @xmath121-\\eta_j(x_j ) & = & b_{j , a}(x_j)+b_{j,\\lambda}(x_j)+o_p(k_n^{-(p+1)})+o_p(\\lambda_{jn}k_n^{1-m}n^{-1}),\\\\ v[\\hat{\\eta}_j(x_j)|\\vec{x}_n ] & = & \\frac{1}{n}\\vec{b}(x_j)^t\\gamma_j(\\lambda_{jn})^{-1}\\gamma_j(0)\\gamma_j(\\lambda_{jn})^{-1}\\vec{b}(x_j)(1+o_p(1))\\\\ & = & o_p(k_n / n),\\\\ cov(\\hat{\\eta}_i(x_i),\\hat{\\eta}_j(x_j))&=&o_p(n^{-1}),\\end{aligned}\\ ] ] where @xmath122 is given in proposition [ app ] , @xmath123    in theorem [ mv ] , the influence of @xmath124 appears to be of only negligible order .",
    "in actuality , we can use very small @xmath124 as long as @xmath68 is nonsingular .",
    "for example , marx and eilers ( 1998 ) used @xmath125 .",
    "thus , it is understood that the influence of @xmath124 is small theoretically and numerically . from theorem [ mv ] , the conditional mean squared error(mse ) of @xmath109 can be obtained as follows .    under the same assumption as theorem [ mv ] , it follows that @xmath126=e[\\{\\hat{\\eta}_j(x_j)-\\eta_j(x_j)\\}^2|\\vec{x}_n]=o_p\\left(k_n^{-2(p+1)}+\\lambda_{jn}^2k_n^{2(1-m)}n^{-2}\\right)+o_p(k_nn^{-1 } ) . } \\end{aligned}\\ ] ] furthermore , the rate of convergence of the mse of @xmath109 becomes @xmath127 by taking @xmath128 , @xmath129 .",
    "compared with the kernel estimator , the asymptotic order of mse of the rcps is the same as that of the local @xmath34th polynomial estimator when @xmath34 is odd and the number of knots in the spline methods and the bandwidth @xmath130 in the kernel methods are connected by @xmath131(see opsomer ( 2000 ) ) .",
    "lyapunov s condition of the central limit theorem yields the asymptotic normality of @xmath82^t$ ] .",
    "[ clt ] suppose there exists @xmath132 such that @xmath133<\\infty$ ] .",
    "furthermore , we assume @xmath128 and @xmath134 .",
    "then , under the assumptions , for any fixed point @xmath135 , as @xmath136 , @xmath137 \\stackrel{d}{\\longrightarrow}n_d\\left (   \\vec{0 } , \\psi\\right),\\end{aligned}\\ ] ] where for @xmath86 , @xmath138 , and @xmath139 $ ] with @xmath140    the proof of theorem [ clt ] is almost the same as that of theorem 2 of yoshida and naito ( 2012 )",
    ". the asymptotic order of the bias and variance of the rcps in theorem [ mv ] allows us to satisfy lyapunov s condition for @xmath82^t$ ] .",
    "we note that an approximate pointwise confidence interval of @xmath46 can be constructed by using the asymptotic distributional result of @xmath109 .",
    "however , the asymptotic bias and variance of @xmath109 contain unknown variables and , hence , these should be estimated .",
    "for example , we replace @xmath114 and @xmath141 with @xmath79 and @xmath142 , respectively , where @xmath143 $ ] . furthermore ,",
    "as it is the pilot estimator of the @xmath144th derivative of @xmath9 , we can utilize the @xmath144th derivative of the rcps @xmath145 with @xmath146 or higher degree splines .",
    "thus , we can construct the estimator @xmath147 and @xmath148 of @xmath149 and @xmath150 , respectively .",
    "consequently , we obtain an approximate confidence interval of @xmath46 by the following corollary .",
    "[ inter ] under the same assumption as theorem [ clt ] , a @xmath151 asymptotic confidence interval of @xmath46 at any fixed point @xmath152 is @xmath153,\\ ] ] where @xmath154 is the @xmath155th normal percentile .",
    "* remark 1 *  we see from the proof of theorem [ mv ] that the asymptotic form of @xmath109 can be written as @xmath156 under the same assumption as theorem [ clt ] , where @xmath157 is the @xmath158th @xmath102-subvector of @xmath159 . from ( 2.8 ) of kauermann et al .",
    "( 2009 ) , we see that @xmath109 and the penalized spline estimator based on the dataset @xmath160 in glm have the same asymptotic form .",
    "thus , ( [ asrcps ] ) indicates that the asymptotic results of the rcps in the gam include those in the glm . note that in glm(@xmath12 ) , we do not need to use the ridge penalty because the hessian of the penalized log - likelihood of @xmath48 is strictly convex .",
    "* remark 2 *  claeskens et al .",
    "( 2009 ) showed the asymptotic bias and variance of the penalized spline estimator in a regression model with @xmath12 .",
    "they studied the asymptotics for penalized splines in the following two asymptotic scenarios : ( a ) the value @xmath161 appeared in their paper , less than 1 , and ( b ) @xmath162 . in our setting , assumption 5 guarantees case ( a ) and so theorem [ mv ] can be seen as the general version of theorem 2 ( a ) of claeskens et al .",
    "( 2009 ) with respect to the model and dimension of covariates . if @xmath94 is equal or smaller than the maximum eigenvalue of @xmath163 , the asymptotics for the penalized spline estimator in the gam will be demonstrable , such as in theorem 2 ( b ) of claeskens et al .",
    "( 2009 ) .",
    "* remark 3 *  from theorem [ clt ] , it is understood that @xmath82^t$ ] are asymptotically mutually independent . wand ( 1999 ) showed the asymptotic independence of the kernel estimator in additive models .",
    "hence the penalized spline estimator and the kernel estimator have the same asymptotic property .",
    "the asymptotic independence of the joint distribution of @xmath82^t$ ] gives some justification for corollary [ inter ] , in which the approximate confidence interval is constructed based on the asymptotic result of the marginal distribution of @xmath109 .",
    "* remark 4 *  clearly , the penalized spline estimator can also be obtained via the backfitting algorithm .",
    "the asymptotic normality of the backfitting estimator can be shown , although it is not discussed in this paper . in additive models ,",
    "yoshida and naito ( 2012 ) derived the asymptotic normality of the penalized spline estimator obtained by the backfitting algorithm .",
    "* remark 5 *  theorems in this section have been shown for the rcps with common @xmath164 in each covariate .",
    "when we construct @xmath109 using different @xmath164 in each @xmath158 , the asymptotic normality of the rcps can also be shown .",
    "in other words , for @xmath109 with @xmath165 which satisfy @xmath166 ( @xmath167 ) , theorems [ mv ] and [ clt ] hold .",
    "in this section , we discuss the penalized spline estimator in relation to mixed models .",
    "we consider model ( [ model1 ] ) again with @xmath46 approximated by a @xmath34th truncated spline model : @xmath168 where @xmath169 .",
    "we assume that the random vector @xmath170 has density @xmath171 with @xmath172 , and @xmath173 and @xmath174 are independent for @xmath175 .",
    "hence , @xmath176^t$ ] distributes @xmath177 , where @xmath178 $ ] .",
    "let @xmath179 , \\quad",
    "r_j= \\left [ \\begin{array}{ccc } ( x_{1j}-\\kappa_{1})^p_+ & \\cdots & ( x_{1j}-\\kappa_{k_n-1})^p_+ \\\\   \\vdots & \\ddots & \\vdots \\\\ ( x_{nj}-\\kappa_{1})^p_+ & \\cdots & ( x_{nj}-\\kappa_{k_n-1})^p_+ \\end{array } \\right],\\end{aligned}\\ ] ] @xmath180 $ ] , @xmath181 $ ] , @xmath182 , @xmath183^t$ ] and @xmath184^t$ ] . the suggested joint density of @xmath185 can be written as @xmath186\\frac{1}{\\sqrt{(2\\pi)^{d } |\\sigma_u|}}\\exp\\left[-\\frac{1}{2}\\vec{u}^t \\sigma_u^{-1}\\vec{u}\\right]\\\\ & = & \\exp\\left[\\vec{y}^t ( s\\vec{\\theta})-\\vec{1}^t c(s\\vec{\\theta})+\\vec{1}^t h(\\vec{y})\\right]\\frac{1}{\\sqrt{(2\\pi)^d |\\sigma_u|}}\\exp\\left[-\\frac{1}{2}\\vec{\\theta}^t \\theta \\vec{\\theta}\\right],\\end{aligned}\\ ] ] where @xmath187 $ ] and @xmath188 $ ] . as a convenient method of obtaining the estimator @xmath189 of @xmath190 and the predictor @xmath191 of @xmath192 , the pql is often used",
    ". in the pql context ,",
    "for given @xmath193 , @xmath194 is defined as the maximizer of @xmath195 where @xmath196 is not dependent on @xmath190 and @xmath192 .",
    "let @xmath197 .",
    "then , the pql fit of @xmath46 is defined as @xmath198 , where @xmath199^t$ ] .",
    "we show the asymptotic distribution of @xmath200^t$ ] . in order to achieve the asymptotic normality of",
    "the pql fits , we consider the equivalence result between the @xmath0-spline model and the truncated spline model . by the fundamental property of the @xmath0-spline function ,",
    "there exists a @xmath102th invertible matrix @xmath201 such that @xmath202 .",
    "then we obtain @xmath203 and @xmath204 where @xmath205 $ ] and @xmath206 .",
    "furthermore , @xmath207 can be rewritten as @xmath208 where @xmath209 $ ] .",
    "here we have used the fact that @xmath210 .",
    "claeskens et al .",
    "( 2009 ) clarified the equality @xmath211 . by showing the asymptotic distribution of the maximizer @xmath212^t$ ] of @xmath213",
    ", we obtain the asymptotic normality of @xmath200^t$ ] , where @xmath214    [ cltpql ] suppose there exists @xmath132 such that @xmath215<\\infty$ ] and @xmath216 . under @xmath128 and @xmath217 , for any fixed point @xmath218 , as @xmath136 , @xmath219 \\stackrel{d}{\\longrightarrow}n_d\\left (   \\vec{0 } , \\psi_p\\right),\\end{aligned}\\ ] ] where @xmath220 , @xmath122 is that given in proposition 1 , @xmath221 @xmath222 $ ] and @xmath223    * remark 6 *  if we use @xmath224 , the results of theorem [ clt ] are asymptotically equivalent to those of theorem [ cltpql ] by replacing @xmath56 with @xmath225 .",
    "* remark 7 *  it should be noted that the maximum likelihood method or the restricted maximum likelihood method can be utilized for estimating @xmath226 by using pseudo data .",
    "these methods and estimation algorithm based on the fisher - scoring algorithm are detailed by breslow and clayton ( 1993 ) and by ruppert et al .",
    "we apply the approximate confidence interval of each covariate @xmath46 to real datasets . in all examples , @xmath227 is adopted .",
    "the number of knots and the smoothing parameters are chosen via generalized cross - validation . as a pilot estimator of @xmath228 in @xmath149",
    ", we utilize the 4th derivative of the rcps with a 5th degree @xmath0-spline model . to see the behavior of @xmath109 ,",
    "the partial residual plots @xmath229 for each @xmath230 are displayed ( see cook and dabrera ( 1998 ) and landwehr et al .",
    "( 1984 ) ) .",
    "the kyphosis data set had 81 rows and 4 columns , representing data of children who have had corrective spinal surgery .",
    "this data is available in the software r ( package @xmath231 ) . for this data ,",
    "the logistic model @xmath232}{1+\\exp[\\eta_1(x_{i1})+\\cdots+\\eta_3(x_{i3})]}\\right),\\ \\ i=1,\\cdots,81\\end{aligned}\\ ] ] is assumed , where @xmath38 is a factor with levels absent(0 ) or present(1 ) indicating whether a kyphosis was present ( 1 ) after the operation , @xmath233 is the age in months , @xmath234 is the number of vertebrae involved and @xmath235 is the number of the first ( topmost ) vertebra operated on .",
    "we construct the rcps with @xmath125 and the approximate confidence intervals for each @xmath46 .    in fig .",
    "[ kyphosis ] , for @xmath236 , the rcps @xmath109 , the 99@xmath237 approximate pointwise confidence interval @xmath238,\\end{aligned}\\ ] ] and the partial residual are all illustrated . for comparison ,",
    "@xmath239(standard error ) : @xmath240,\\ j=1,2,3\\end{aligned}\\ ] ] are also superimposed . in all covariates ,",
    "smooth intervals are obtained .",
    "marx and eilers ( 1998 ) illustrated the rcps and @xmath239(standard error ) for the same dataset in fig.4 of their paper .",
    "our results and theirs are similar . however , our interval is wiggles a bit because the asymptotic bias is corrected in each covariate .",
    "approximate confidence interval(solid ) , @xmath241(standard error ) ( dot - dashed line ) and the partial residuals .",
    "the left , middle and right panels are for @xmath242 , @xmath243 and @xmath244 , respectively .",
    "[ kyphosis],title=\"fig:\",width=170,height=170 ]   approximate confidence interval(solid ) , @xmath241(standard error ) ( dot - dashed line ) and the partial residuals .",
    "the left , middle and right panels are for @xmath242 , @xmath243 and @xmath244 , respectively .",
    "[ kyphosis],title=\"fig:\",width=170,height=170 ]   approximate confidence interval(solid ) , @xmath241(standard error ) ( dot - dashed line ) and the partial residuals .",
    "the left , middle and right panels are for @xmath242 , @xmath243 and @xmath244 , respectively .",
    "[ kyphosis],title=\"fig:\",width=170,height=170 ]      this data set contained air pollution and mortality data for the city of milan , italy , over 3652 consecutive days ( i.e. , 10 consecutive years : 1st january , 1980 to 30th december , 1989 ) .",
    "the original data is available on the web site of ruppert et al .",
    "the relationship between the number of deaths in a day and some explanatory variables is modeled as follows @xmath245,\\ \\ i=1,\\cdots,102,\\end{aligned}\\ ] ] where @xmath38 is the total number of deaths in a day , @xmath233 is the number of days since 31st december , 1979 , @xmath234 the mean daily temperature in degrees celcius , @xmath235 is the relative humidity , @xmath246 is a measure of sulfur dioxide levels ( so2 ) in ambient air and @xmath247 is the total amount of suspended particles ( tsp ) in ambient air .",
    "all of these have been measured on public holidays within the 3652 days , giving a sample size of @xmath248 .",
    "we constructed the rcps of @xmath46 and the 99@xmath237 approximate confidence intervals . in fig .",
    "[ air ] , the rcps , the @xmath249 approximate confidence intervals , @xmath250(standard error ) and the partial residual for each @xmath251 are illustrated .",
    "we see that the effect of @xmath147 is somewhat large for all covariates .",
    "approximate confidence interval , @xmath241(standard error ) and the partial residuals .",
    "[ air],title=\"fig:\",width=170,height=151 ]   approximate confidence interval , @xmath241(standard error ) and the partial residuals .",
    "[ air],title=\"fig:\",width=170,height=151 ]   approximate confidence interval , @xmath241(standard error ) and the partial residuals .",
    "[ air],title=\"fig:\",width=170,height=151 ] +   approximate confidence interval , @xmath241(standard error ) and the partial residuals .",
    "[ air],title=\"fig:\",width=170,height=151 ]   approximate confidence interval , @xmath241(standard error ) and the partial residuals .",
    "[ air],title=\"fig:\",width=170,height=151 ]",
    "in this section , we validate theorem [ clt ] numerically by simulation . the true natural parameter utilized in the simulation",
    "is defined as @xmath252 , where @xmath253 , @xmath254 and @xmath255 .",
    "the design points @xmath256 are created by @xmath257 = \\left [ \\begin{array}{ccc } ( 1+\\rho+\\rho^2)^{-1}&0&0\\\\ 0&(1 + 2\\rho)^{-1}&0\\\\ 0&0&(1+\\rho+\\rho^2)^{-1 } \\end{array } \\right ] \\left [ \\begin{array}{ccc } 1&\\rho&\\rho^2\\\\ \\rho&1&\\rho\\\\ \\rho^2&\\rho&1 \\end{array } \\right ] \\left [ \\begin{array}{c } z_{i1}\\\\ z_{i2}\\\\ z_{i3 } \\end{array } \\right],\\end{aligned}\\ ] ] where @xmath258 are generated independently from @xmath259 , the uniform distribution on @xmath85 $ ] .",
    "we prepared two types of the design , with ( i ) @xmath260 and ( ii ) @xmath261 .",
    "then , the true functions are corrected to satisfy @xmath28=0 $ ] in each ( i ) and ( ii ) .",
    "the response @xmath38 is generated from @xmath262}{1+\\exp[\\eta_1(x_{i1})+\\eta_2(x_{i2})+\\eta_3(x_{i3})]}\\right),\\ \\ i=1,\\cdots , n .",
    "\\label{ber1}\\end{aligned}\\ ] ]    our purpose is to compare the density of @xmath263 and the kernel density estimate of the simulated @xmath264 , as well as the density of @xmath265 and the kernel density estimate of the simulated @xmath266^t$ ] , @xmath267^t$ ] and @xmath268^t$ ] to validate theorem [ clt ] , where @xmath269 = \\sqrt{\\frac{n}{k_n } } \\left [ \\begin{array}{c } \\displaystyle\\frac{\\hat{\\eta}_1(x_1)-\\eta_1(x_1)-\\widehat{{\\rm bias}}_1(x_1)}{\\hat{\\psi}_1(x_1)}\\\\ \\displaystyle\\frac{\\hat{\\eta}_2(x_2)-\\eta_2(x_2)-\\widehat{{\\rm bias}}_2(x_2)}{\\hat{\\psi}_2(x_2)}\\\\ \\displaystyle\\frac{\\hat{\\eta}_3(x_3)-\\eta_3(x_3)-\\widehat{{\\rm bias}}_3(x_3)}{\\hat{\\psi}_3(x_3 ) } \\end{array } \\right ] .",
    "\\label{2norm}\\end{aligned}\\ ] ] here , @xmath270 @xmath271 . for @xmath236 , @xmath147",
    "is constructed using the same method as that in the previous section .",
    "the bandwidth discussed by sheather and jones ( 1991 ) is utilized for kernel density estimates .",
    "the simulation algorithm described as follows :    1 .   for @xmath236 and @xmath272 , generate @xmath273 from ( i ) or ( ii ) .",
    "2 .   generate the data @xmath274 from ( [ ber1 ] ) .",
    "3 .   calculate @xmath275 at a fixed point @xmath276 .",
    "4 .   calculate the values of ( [ 2norm ] ) .",
    "iterate from step 2 to step 4 , 10000 times",
    "draw the kernel density estimate of @xmath277 and @xmath278 and compare with the density of @xmath263 .",
    "draw the kernel density estimate of @xmath279^t$ ] , @xmath280^t$ ] and @xmath281^t$ ] , and compare with the density of @xmath265 .    to construct @xmath275",
    ", we utilize the cubic @xmath0-spline ( @xmath282 ) and the second difference matrix ( @xmath283 ) .",
    "furthermore @xmath284 , @xmath285 , @xmath286 and @xmath287 are used .",
    "the ridge parameter is chosen as @xmath288 .",
    "the sample sizes are set at @xmath289 and @xmath290 .    in fig .",
    "[ log.simu ] , the density estimate of ( [ 2norm ] ) with ( i ) , and the densities of the normal distribution are shown .",
    "as the sample size increases , the asymptotic normality of the rcps in theorem [ clt ] can be observed numerically .",
    "we see from ( 1,1 ) , ( 2,2 ) and ( 3,3 ) panels that the density estimate becomes close to 0 when @xmath290 . when @xmath289 , a large correlation between @xmath291 and @xmath292 can be observed .",
    "however , as @xmath72 increases , the correlation becomes small .",
    "the results with the correlated design ( ii ) are drawn in fig .",
    "[ log.simu.cor ] .",
    "the density estimate of @xmath293 appears to be far from @xmath263 , even when @xmath290 .",
    "however , we also find that @xmath294^t$ ] tends to become close to @xmath265 as @xmath136 .",
    "we have confirmed that the density estimate with @xmath295 tends to become close to the normal distribution as @xmath72 increases , though this is not shown in this paper .",
    "however , the speed of convergence of the density estimate with the poisson model was somewhat slower than with the bernoulli model .    , @xmath294^t$ ] and the density of @xmath263 and @xmath296 with the bernoulli model and an uncorrelated design . for @xmath297 ,",
    "the @xmath298 panels are the density estimates of @xmath291 for @xmath289(dot - dashed ) and @xmath290(dashed ) , and the density of @xmath263(solid ) .",
    "the ( 2,1 ) , ( 3,1 ) and ( 3,2 ) panels are the density estimates of @xmath279^t$ ] , @xmath280^t$ ] and @xmath281^t$](dashed ) for @xmath289 and the density of @xmath296(solid ) .",
    "the ( 1,2 ) , ( 1,3 ) and ( 2,3 ) panels are the density estimates of @xmath279^t$ ] , @xmath280^t$ ] and @xmath281^t$](dashed ) for @xmath290 and the density of @xmath296(solid ) . in each panel ,",
    "the contour lines of @xmath296 are the same as that of the density estimate .",
    "[ log.simu],title=\"fig:\",width=170,height=170 ] , @xmath294^t$ ] and the density of @xmath263 and @xmath296 with the bernoulli model and an uncorrelated design . for @xmath297 ,",
    "the @xmath298 panels are the density estimates of @xmath291 for @xmath289(dot - dashed ) and @xmath290(dashed ) , and the density of @xmath263(solid ) .",
    "the ( 2,1 ) , ( 3,1 ) and ( 3,2 ) panels are the density estimates of @xmath279^t$ ] , @xmath280^t$ ] and @xmath281^t$](dashed ) for @xmath289 and the density of @xmath296(solid ) .",
    "the ( 1,2 ) , ( 1,3 ) and ( 2,3 ) panels are the density estimates of @xmath279^t$ ] , @xmath280^t$ ] and @xmath281^t$](dashed ) for @xmath290 and the density of @xmath296(solid ) . in each panel ,",
    "the contour lines of @xmath296 are the same as that of the density estimate .",
    "[ log.simu],title=\"fig:\",width=170,height=170 ] , @xmath294^t$ ] and the density of @xmath263 and @xmath296 with the bernoulli model and an uncorrelated design . for @xmath297 ,",
    "the @xmath298 panels are the density estimates of @xmath291 for @xmath289(dot - dashed ) and @xmath290(dashed ) , and the density of @xmath263(solid ) .",
    "the ( 2,1 ) , ( 3,1 ) and ( 3,2 ) panels are the density estimates of @xmath279^t$ ] , @xmath280^t$ ] and @xmath281^t$](dashed ) for @xmath289 and the density of @xmath296(solid ) .",
    "the ( 1,2 ) , ( 1,3 ) and ( 2,3 ) panels are the density estimates of @xmath279^t$ ] , @xmath280^t$ ] and @xmath281^t$](dashed ) for @xmath290 and the density of @xmath296(solid ) . in each panel ,",
    "the contour lines of @xmath296 are the same as that of the density estimate .",
    "[ log.simu],title=\"fig:\",width=170,height=170 ] + , @xmath294^t$ ] and the density of @xmath263 and @xmath296 with the bernoulli model and an uncorrelated design .",
    "for @xmath297 , the @xmath298 panels are the density estimates of @xmath291 for @xmath289(dot - dashed ) and @xmath290(dashed ) , and the density of @xmath263(solid ) .",
    "the ( 2,1 ) , ( 3,1 ) and ( 3,2 ) panels are the density estimates of @xmath279^t$ ] , @xmath280^t$ ] and @xmath281^t$](dashed ) for @xmath289 and the density of @xmath296(solid ) .",
    "the ( 1,2 ) , ( 1,3 ) and ( 2,3 ) panels are the density estimates of @xmath279^t$ ] , @xmath280^t$ ] and @xmath281^t$](dashed ) for @xmath290 and the density of @xmath296(solid ) . in each panel ,",
    "the contour lines of @xmath296 are the same as that of the density estimate .",
    "[ log.simu],title=\"fig:\",width=170,height=170 ] , @xmath294^t$ ] and the density of @xmath263 and @xmath296 with the bernoulli model and an uncorrelated design . for @xmath297 ,",
    "the @xmath298 panels are the density estimates of @xmath291 for @xmath289(dot - dashed ) and @xmath290(dashed ) , and the density of @xmath263(solid ) .",
    "the ( 2,1 ) , ( 3,1 ) and ( 3,2 ) panels are the density estimates of @xmath279^t$ ] , @xmath280^t$ ] and @xmath281^t$](dashed ) for @xmath289 and the density of @xmath296(solid ) .",
    "the ( 1,2 ) , ( 1,3 ) and ( 2,3 ) panels are the density estimates of @xmath279^t$ ] , @xmath280^t$ ] and @xmath281^t$](dashed ) for @xmath290 and the density of @xmath296(solid ) . in each panel , the contour lines of @xmath296 are the same as that of the density estimate .",
    "[ log.simu],title=\"fig:\",width=170,height=170 ] , @xmath294^t$ ] and the density of @xmath263 and @xmath296 with the bernoulli model and an uncorrelated design . for @xmath297 ,",
    "the @xmath298 panels are the density estimates of @xmath291 for @xmath289(dot - dashed ) and @xmath290(dashed ) , and the density of @xmath263(solid ) .",
    "the ( 2,1 ) , ( 3,1 ) and ( 3,2 ) panels are the density estimates of @xmath279^t$ ] , @xmath280^t$ ] and @xmath281^t$](dashed ) for @xmath289 and the density of @xmath296(solid ) . the ( 1,2 ) , ( 1,3 ) and ( 2,3 ) panels are the density estimates of @xmath279^t$ ] , @xmath280^t$ ] and @xmath281^t$](dashed ) for @xmath290 and the density of @xmath296(solid ) . in each panel",
    ", the contour lines of @xmath296 are the same as that of the density estimate .",
    "[ log.simu],title=\"fig:\",width=170,height=170 ] + , @xmath294^t$ ] and the density of @xmath263 and @xmath296 with the bernoulli model and an uncorrelated design . for @xmath297 ,",
    "the @xmath298 panels are the density estimates of @xmath291 for @xmath289(dot - dashed ) and @xmath290(dashed ) , and the density of @xmath263(solid ) .",
    "the ( 2,1 ) , ( 3,1 ) and ( 3,2 ) panels are the density estimates of @xmath279^t$ ] , @xmath280^t$ ] and @xmath281^t$](dashed ) for @xmath289 and the density of @xmath296(solid ) .",
    "the ( 1,2 ) , ( 1,3 ) and ( 2,3 ) panels are the density estimates of @xmath279^t$ ] , @xmath280^t$ ] and @xmath281^t$](dashed ) for @xmath290 and the density of @xmath296(solid ) . in each panel ,",
    "the contour lines of @xmath296 are the same as that of the density estimate .",
    "[ log.simu],title=\"fig:\",width=170,height=170 ] , @xmath294^t$ ] and the density of @xmath263 and @xmath296 with the bernoulli model and an uncorrelated design . for @xmath297 ,",
    "the @xmath298 panels are the density estimates of @xmath291 for @xmath289(dot - dashed ) and @xmath290(dashed ) , and the density of @xmath263(solid ) .",
    "the ( 2,1 ) , ( 3,1 ) and ( 3,2 ) panels are the density estimates of @xmath279^t$ ] , @xmath280^t$ ] and @xmath281^t$](dashed ) for @xmath289 and the density of @xmath296(solid ) .",
    "the ( 1,2 ) , ( 1,3 ) and ( 2,3 ) panels are the density estimates of @xmath279^t$ ] , @xmath280^t$ ] and @xmath281^t$](dashed ) for @xmath290 and the density of @xmath296(solid ) . in each panel ,",
    "the contour lines of @xmath296 are the same as that of the density estimate .",
    "[ log.simu],title=\"fig:\",width=170,height=170 ] , @xmath294^t$ ] and the density of @xmath263 and @xmath296 with the bernoulli model and an uncorrelated design . for @xmath297 ,",
    "the @xmath298 panels are the density estimates of @xmath291 for @xmath289(dot - dashed ) and @xmath290(dashed ) , and the density of @xmath263(solid ) .",
    "the ( 2,1 ) , ( 3,1 ) and ( 3,2 ) panels are the density estimates of @xmath279^t$ ] , @xmath280^t$ ] and @xmath281^t$](dashed ) for @xmath289 and the density of @xmath296(solid ) .",
    "the ( 1,2 ) , ( 1,3 ) and ( 2,3 ) panels are the density estimates of @xmath279^t$ ] , @xmath280^t$ ] and @xmath281^t$](dashed ) for @xmath290 and the density of @xmath296(solid ) . in each panel ,",
    "the contour lines of @xmath296 are the same as that of the density estimate .",
    "[ log.simu],title=\"fig:\",width=170,height=170 ] +    , @xmath294 $ ] and the density of @xmath263 and @xmath296 with the bernoulli model and the correlated design .",
    "the description of each panel is the same as in fig .",
    "[ log.simu ] .",
    "[ log.simu.cor],title=\"fig:\",width=170,height=170 ] , @xmath294 $ ] and the density of @xmath263 and @xmath296 with the bernoulli model and the correlated design .",
    "the description of each panel is the same as in fig .",
    "[ log.simu ] .",
    "[ log.simu.cor],title=\"fig:\",width=170,height=170 ] , @xmath294 $ ] and the density of @xmath263 and @xmath296 with the bernoulli model and the correlated design .",
    "the description of each panel is the same as in fig .",
    "[ log.simu ] .",
    "[ log.simu.cor],title=\"fig:\",width=170,height=170 ] + , @xmath294 $ ] and the density of @xmath263 and @xmath296 with the bernoulli model and the correlated design .",
    "the description of each panel is the same as in fig .",
    "[ log.simu ] .",
    "[ log.simu.cor],title=\"fig:\",width=170,height=170 ] , @xmath294 $ ] and the density of @xmath263 and @xmath296 with the bernoulli model and the correlated design .",
    "the description of each panel is the same as in fig .",
    "[ log.simu ] .",
    "[ log.simu.cor],title=\"fig:\",width=170,height=170 ] , @xmath294 $ ] and the density of @xmath263 and @xmath296 with the bernoulli model and the correlated design .",
    "the description of each panel is the same as in fig .",
    "[ log.simu ] .",
    "[ log.simu.cor],title=\"fig:\",width=170,height=170 ] + , @xmath294 $ ] and the density of @xmath263 and @xmath296 with the bernoulli model and the correlated design .",
    "the description of each panel is the same as in fig .",
    "[ log.simu ] .",
    "[ log.simu.cor],title=\"fig:\",width=170,height=170 ] , @xmath294 $ ] and the density of @xmath263 and @xmath296 with the bernoulli model and the correlated design .",
    "the description of each panel is the same as in fig .",
    "[ log.simu ] .",
    "[ log.simu.cor],title=\"fig:\",width=170,height=170 ] , @xmath294 $ ] and the density of @xmath263 and @xmath296 with the bernoulli model and the correlated design .",
    "the description of each panel is the same as in fig .",
    "[ log.simu ] .",
    "[ log.simu.cor],title=\"fig:\",width=170,height=170 ] +",
    "this paper showed the asymptotic normality of the penalized spline estimator in the gam .",
    "the results of this paper generalize theorem 1 of kauermann et al .",
    "( 2009 ) and theorem 2 of yoshida and naito ( 2012 ) .",
    "the main tools used to prove our theorems were the spline approximation theories and the asymptotic properties of the band matrices . by applying their properties , the asymptotics for penalized splines in other models",
    "can be investigated for further study .    in spline smoothing , the determination of smoothing parameters is very important .",
    "many researchers have addressed this problem by using grid search methods , such as mallow s @xmath299 , cross - validation and generalized cross - validation . since the computation time of a grid search is dramatically increased when @xmath300",
    ", more direct methods would be a useful area of study",
    ". it may be possible to discuss the selection of smoothing parameters based on the asymptotic properties in this paper .    in recent years",
    ", the so - called high - dimensional additive models characterized by @xmath301 \" have been studied by many authors such as meier et al .",
    "( 2009 ) , huang et al .",
    "( 2010 ) and fan et al .",
    "these previous works are based on unpenalized @xmath0-spline estimators .",
    "although it is beyond the scope of this paper , the asymptotics for penalized splines in high dimensional additive models would be interesting to explore .",
    "for a matrix @xmath302 , if @xmath303 , then it is written as @xmath304 .",
    "when @xmath305 is vector , it is written as @xmath306 .",
    "we define @xmath307 $ ] , @xmath308 , @xmath309 and @xmath310 . in the sequel , we use @xmath311 .",
    "[ g1 ] @xmath312 , @xmath313 and @xmath314 satisfy @xmath315 , @xmath316 and @xmath317 .",
    "let @xmath318 be @xmath319 matrix .",
    "assume that as @xmath320 , @xmath321 .",
    "then , under the assumptions , @xmath322 , @xmath323 and @xmath324",
    ".        lemma [ g1 ] can be proven by the properties of the integral of @xmath0-spline basis and the inverse of band matrices detailed in claeskens et al .",
    "( 2009 ) and yoshida and naito ( 2012 ) .",
    "then , assumption 5 of this paper indicates that the case @xmath330 of claeskens et al .",
    "the proof of lemma [ g2 ] is addressed in yoshida and naito ( 2012 ) by induction for @xmath16 .",
    "lemma [ g3 ] can be shown from the derivative property of @xmath0-spline model : @xmath331}(x)^t k_n^m\\delta_m\\vec{b}$ ] .",
    "the above equality and proposition 1 yield @xmath332}(x)^t k_n^m\\delta_m\\vec{b}_{j0}=\\eta_j^{(m)}(x)(1+o(1))$ ] .",
    "since the asymptotic order of @xmath332}(x)^t k_n^m\\delta_m\\vec{b}_{j0}$ ] and each component of @xmath333 are the same as @xmath334 , lemma [ g3 ] holds .",
    "the details are clarified in section 2 of claeskens et al .",
    "( 2009 ) .",
    "we use the taylor expansion of @xmath113 around @xmath114 , giving @xmath336 where @xmath337 $ ] and @xmath338 .",
    "therefore , @xmath339 can be written as @xmath340 where @xmath341 $ ] .",
    "furthermore , for @xmath272 , the taylor expansion yields @xmath342z(\\vec{x}_i)^t\\omega(\\hat{\\vec{b}}-\\vec{b}_0),\\end{aligned}\\ ] ] where @xmath343 .",
    "hence from proposition 1 , we obtain @xmath344\\\\ & = & \\operatorname{diag}[c^{(3)}(\\eta(\\vec{x}_i))z(\\vec{x}_i)^t\\omega(\\hat{\\vec{b}}-\\vec{b}_0)](1+o(1))\\\\ & \\equiv & r(\\hat{\\vec{b}}).\\end{aligned}\\ ] ]    for simplicity , we rewrite @xmath345 and @xmath346 . then ( [ ex21 ] ) can be written as @xmath347 we now prove @xmath348 from ( [ ex22 ] ) , the left hand side of ( [ purp1 ] ) can be evaluated as @xmath349 first we show the asymptotic order of @xmath350 .",
    "the @xmath351th component of @xmath350 can be written by ( [ ex22 ] ) as @xmath352 by calculating the expectation and the square root of variance of each component of @xmath353 , we obtain with lemma [ g3 ] @xmath354 therefore lemma [ g2 ] yields that for @xmath355^d$ ] , @xmath356 since @xmath357 is bounded near @xmath27 for @xmath358^d$ ] , we have with tedious but easy calculation that @xmath359^d}\\left|c^{(3)}(\\eta(\\vec{z}))z(\\vec{z})^t\\omega\\left\\{h^{-1}g+h^{-1}\\left(\\frac{1}{n}z^t r(\\hat{\\vec{b}})z\\right)(\\hat{\\vec{b}}-\\vec{b}_0)\\right\\}\\right|(1+o(1))\\nonumber\\\\ & & = o_p\\left(\\frac{\\lambda_nk_n^{1-m}}{n}+\\sqrt{\\frac{k_n}{n}}\\right).\\label{rcal}\\end{aligned}\\ ] ] then lemmas [ g1 ] and [ g2 ] and ( [ rcal ] ) yield @xmath360 further we get with simple calculation @xmath361 this implies ( [ purp1 ] ) and completes the proof .",
    "@xmath362      barrow and smith ( 1978 ) showed that for @xmath86 , there exists @xmath363 such that @xmath364 let @xmath365 , @xmath366 , @xmath367 and @xmath368 .",
    "we now prove that @xmath369 since the asymptotic order of @xmath370 and that of @xmath371 are the same , if ( [ pur ] ) is satisfied , we obtain for any @xmath152 , @xmath372 hence proposition 1 holds .    from the definition of @xmath114",
    ", we have @xmath373 \\leq   \\frac{1}{n}\\sum_{i=1}^n e\\left[\\left.\\log \\frac{f(y_i|\\vec{x}_i,\\eta)}{f(y_i|\\vec{x}_i,\\vec{b}^*)}\\right|\\vec{x}_n\\right],\\label{ineq}\\end{aligned}\\ ] ] where @xmath374 . the taylor expansion to @xmath375 around @xmath376 yields @xmath377\\\\ & & = \\frac{1}{n}\\sum_{i=1}^n\\left[c^\\prime(\\eta(\\vec{x}_i))\\{\\eta(\\vec{x}_i)-\\eta^*(\\vec{x}_i)\\}-\\{c(\\eta(\\vec{x}_i))-c ( \\eta^*(\\vec{x}_i))\\}\\right]\\nonumber\\\\ & & = \\frac{1}{2n}\\sum_{i=1}^n\\left[\\{\\eta(\\vec{x}_i)-\\eta^*(\\vec{x}_i)\\}^2c^{\\prime\\prime } ( \\eta(\\vec{x}_i))(1+o(1))\\right]\\nonumber\\\\ & & = \\frac{1}{2n}\\sum_{i=1}^n\\left[b_{a}(\\vec{x}_i)^2c^{\\prime\\prime } ( \\eta(\\vec{x}_i)(1+o(1))\\right]\\\\ & & = o(k_n^{-2(p+1)}).\\end{aligned}\\ ] ] therefore we obtain @xmath378 , by which @xmath373 & = & \\frac{1}{n}\\sum_{i=1}^n\\left[\\{\\eta(\\vec{x}_i)-\\eta_{0}(\\vec{x}_i)\\}^2c^{\\prime\\prime } ( \\eta(\\vec{x}_i))(1+o(1))\\right]\\nonumber\\\\ & = & \\frac{1}{n}(\\vec{\\eta}-z\\vec{b}_0)^t w ( \\vec{\\eta}-z\\vec{b}_0 ) , \\label{b0def}\\end{aligned}\\ ] ] where @xmath379 $ ] and @xmath380 .",
    "it is easy to show that @xmath114 satisfies @xmath381 since @xmath114 is the minimizer of ( [ b0def ] ) .",
    "further , from the definition of @xmath382 , we have @xmath383 where @xmath384 .",
    "hence , we obtain @xmath385 by noting @xmath53 $ ] , the @xmath74th component of first @xmath102 block of @xmath386 can be calculated as @xmath387(1+o(1))\\nonumber\\\\ & = & \\sum_{j=1}^d \\int_{[0,1]^d } c^{\\prime\\prime}(\\eta(\\vec{x}))b_{-p+k}(x_{1})b_{j , a } ( x_{j})dp(\\vec{x})(1+o(1))\\nonumber\\\\ & = & o(k_n^{-(p+2)}).\\label{brsp}\\end{aligned}\\ ] ] here the last equality in ( [ brsp ] ) can be obtained by mimicking the proof of lemma 10 of agarwal and studden ( 1980 ) .",
    "similarly since the row sum of @xmath388 has an order @xmath389 , we get ( [ dist2 ] ) as @xmath390 from lemma [ g1 ] , we have @xmath391",
    ". therefore @xmath392 and ( [ pur ] ) can be proven .",
    "@xmath362    to complete the proof of theorem 1 , first we will obtain ( a ) the asymptotic form of @xmath393 . and then ( b ) we will derive the asymptotic form of @xmath394 $ ] and @xmath395 $ ] .",
    "similar argument will be applied to @xmath396      first we aim to show ( a ) . from lemma [ ex ] , we obtain @xmath397 where @xmath398 let @xmath399 and let @xmath400 . then , @xmath401 can be written by using @xmath402 as @xmath403 = \\left [ \\begin{array}{cc } m_{d-1}&r^t\\\\ r&\\lambda_{d,\\gamma } \\end{array } \\right],\\label{mmat1}\\end{aligned}\\ ] ] where @xmath404 $ ] . from the result of partitioned matrix ( see , horn and johnson ( 1985 ) ) , we have @xmath405,\\end{aligned}\\ ] ] where @xmath406 .",
    "let @xmath407 and @xmath408 be the first @xmath409th subvector and last @xmath102th subvector of @xmath159 .",
    "then , @xmath410\\\\ & = & \\left [ \\begin{array}{cc } m^{-1}_{d-1}+m^{-1}_{d-1}r^t v^{-1}rm^{-1}_{d-1}&-m^{-1}_{d-1}r^t v^{-1}\\\\ -v^{-1}rm^{-1}_{d-1}&v^{-1 } \\end{array } \\right ] \\left [ \\begin{array}{c } g_{(-d)}(\\vec{b}_0,\\lambda_n,\\gamma_n)\\\\ g_d(\\vec{b}_0,\\lambda_n,\\gamma_n ) \\end{array } \\right]\\\\ & & \\quad + r_n(\\hat{\\vec{b}}),\\end{aligned}\\ ] ] from which we have @xmath411 where @xmath412 and @xmath413 is last @xmath102th subvector of @xmath414 .    in following , we shall start to show ( b ) .",
    "the expectation of @xmath415 can be written as @xmath416 & = & \\lambda_{d,\\gamma}^{-1}e[g_d(\\vec{b}_0,\\lambda_n,\\gamma_n)|\\vec{x}_n ] + e[v_n(\\vec{b}_0)|\\vec{x}_n]+e[r_{d , n}(\\hat{\\vec{b}})|\\vec{x}_n].\\end{aligned}\\ ] ] first , @xmath417=o_p(\\lambda_nk_n^{1-m}n^{-1})$ ] is satisfied . in the sequel , because @xmath418 & = & \\frac{1}{n}\\sum_{i=1}^n e\\left[\\left.\\frac{\\partial}{\\partial \\vec{b } } \\log f(y_i|x_i,\\vec{b}_0)\\right|\\vec{x}_n\\right]=0,\\end{aligned}\\ ] ] we have with lemma [ g3 ] @xmath419&=&e[g(\\vec{b}_0,0,0)|\\vec{x}_n]-\\frac{1}{n}q_m(\\lambda_n)\\vec{b}_0-\\frac{\\gamma_n}{n } \\vec{b}_0\\\\ & = & o_p\\left(\\frac{\\lambda_nk_n^{-m}}{n}\\vec{1}\\right).\\end{aligned}\\ ] ] from lemmas [ g1 ] and [ g2 ] , on the other hand , we obtain @xmath420 therefore we have with straightforward calculation @xmath421\\\\ & & = -v^{-1}rm^{-1}_{d-1}e[g_{(-d)}(\\vec{b}_0,\\lambda_n,\\gamma_n)]+\\left\\{v^{-1}-\\lambda_{d,\\gamma , n}^{-1}\\right\\}e[g_d(\\vec{b}_0,\\lambda_n,\\gamma_n)]\\\\ & & = o_p\\left(k_n\\frac{1}{k_n^2}k_n\\frac{\\lambda_nk_n^{-m}}{n}\\vec{1}\\right ) + o_p\\left(\\frac{\\lambda_nk_n^{-(m+1)}}{n}\\vec{1}\\right)\\\\ & & = o_p\\left(\\frac{\\lambda_nk_n^{-m}}{n}\\vec{1}\\right).\\end{aligned}\\ ] ]    above calculations are combined into @xmath422 & = & -\\frac{\\lambda_{dn}}{n}\\lambda_{d,\\gamma}^{-1}\\delta_m^\\prime \\delta_m\\vec{b}_{d0}-\\frac{\\gamma_n}{n}\\lambda_{d,\\gamma , n}^{-1}\\vec{b}_{d0}+o_p\\left(\\frac{\\lambda_nk_n^{1-m}}{n}\\vec{1}\\right)\\\\ & = & -\\frac{\\lambda_{dn}}{n}\\gamma_d(\\lambda_{dn})^{-1}\\delta_m^\\prime \\delta_m\\vec{b}_{d0}+o_p\\left(\\frac{\\lambda_nk_n^{1-m}}{n}\\vec{1}\\right).\\end{aligned}\\ ] ] here we have used the fact @xmath423 and @xmath424 .",
    "hence , we finally obtain @xmath425 & = & e[\\vec{b}(x_d)^t ( \\hat{\\vec{b}}_d-\\vec{b}_{d0})|\\vec{x}_n]\\\\ & = & b_{d,\\lambda}(x_d)+o_p(\\lambda_nk_n^{1-m}n^{-1}).\\end{aligned}\\ ] ] this implies that the first assertion of theorem [ mv ] .",
    "the variance of @xmath426 can be written as @xmath427 & = & \\vec{b}(x_d)^t\\lambda_{d,\\gamma}^{-1}v[g_d(\\vec{b}_0,\\lambda_n,\\gamma_n)|\\vec{x}_n]\\lambda_{d,\\gamma}^{-1}\\vec{b}(x_d)(1+o_p(1)).\\end{aligned}\\ ] ] since it is easy to find that the conditional variance of @xmath428 can be shown to be @xmath429 . by noting @xmath430 = \\frac{1}{n^2}z_d^t v[\\vec{y}|\\vec{x}_n]z_d=\\frac{1}{n^2}z_d^t w",
    "z_d=\\frac{1}{n}g_{d } + o_p((k_n / n)^{-1}\\vec{1}\\vec{1}^t),\\end{aligned}\\ ] ] we have the second assertion as @xmath431\\\\ & & = \\frac{1}{n}\\vec{b}(x_d)^t\\lambda_{d,\\gamma}^{-1}g_{d } \\lambda_{d,\\gamma}^{-1}\\vec{b}(x_d)(1+o_p(1))\\\\ & & = \\frac{1}{n}\\vec{b}(x_d)^t\\gamma_d(\\lambda_{dn})^{-1 } \\gamma_d(0 ) \\gamma_d(\\lambda_{dn})^{-1}\\vec{b}(x_d)(1+o_p(1)).\\end{aligned}\\ ] ] also it is easily confirmed by straightforward calculation with lemma [ g1 ] that for @xmath432 , @xmath433 this completely the proof .",
    "let @xmath434^t$ ] and let @xmath435 be the maximizer of @xmath436 with respect to @xmath437 , where @xmath438 and let @xmath439 .",
    "then the asymptotic normality of @xmath440^t$ ] can be obtained by the same manner to the proof of theorem [ clt ] with @xmath224 .",
    "similar to lemma [ ex ] , @xmath441 can be written as @xmath442 where @xmath443 $ ] and @xmath444 is the remainder .",
    "then lemma [ g2 ] yields @xmath445 , by which @xmath446 .",
    "this leads to theorem [ cltpql ] ."
  ],
  "abstract_text": [
    "<S> this paper discusses asymptotic theory for penalized spline estimators in generalized additive models . the purpose of this paper is to establish the asymptotic bias and variance as well as the asymptotic normality of the penalized spline estimators proposed by marx and eilers ( 1998 ) . </S>",
    "<S> furthermore , the asymptotics for the penalized quasi likelihood fit in mixed models are also discussed .    </S>",
    "<S> * keywords * asymptotic normality , @xmath0-spline , generalized additive model , mixed model , penalized spline . </S>"
  ]
}