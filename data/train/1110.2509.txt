{
  "article_text": [
    "the rapid increase in the number of astronomical data sets and even faster increase of overall data volume demands a new paradigm for the scientific exploitation of optical and near - infrared imaging surveys .",
    "historical surveys have been digitized ( poss and its southern counterpart ) or are in the process of being digitized . in recent years surveys",
    "have been performed which cover hundreds or thousands of square degrees up to the whole sky ( sdss , 2mass , cfhtls , etc . ) .",
    "many more are in progress or coming up with increasing spatial resolution , depth , and survey areas ( omegacam on vst , vircam on vista , pan - starrs , lsst , etc . ) .",
    "the data rate of existing surveys is rapidly approaching _ terabytes _ per night , leading to survey volumes well into the _ petabyte _ regime and the new surveys will add many tens of petabytes to this .",
    "hundreds of terabytes of data will start entering the system when eso s omegacam camera starts operations in chile in late-2011 .",
    "several large surveys plan to use the  information system to manage their data : the 1500 deg@xmath0  survey , the vesuvio survey of nearby superclusters , the omegawhite white dwarf binary survey and the omegatrans search for transiting variables .",
    "quality control is typically one of the largest challenges in the chain from raw data of the `` sensor networks '' to scientific papers .",
    "it requires an environment in which all non - manual qualification is automated and the scientist can graphically inspect where needed by easily going back and forth through the data ( the pixels ) and metadata ( everything else ) of the whole processing chain for large numbers of data products .",
    "the full quality control mechanisms are treated in complete detail in the  quality control paper @xcite .",
    "the really novel aspect of this new paradigm is the long - term preservation of the raw data and the ability of re - calibrating it to the requirements of new science cases .",
    "the data of the majority of these surveys is fully public : any astronomer is entitled to a copy of the data . therefore the same survey data is used for not only science cases within the original plan , but many new science cases the original designers of the survey were not planning to do themselves or did not foresee . to be able to do this",
    "successfully requires that everyone is provided access to detailed information on the existing calibration procedures and resulting quality of the data at every stage of the processing , that is , have access to the data and the metadata , including process configuration at every step in the chain from raw data to final data products .    in this paper",
    "we describe the reduction of data in the  information system , generally referred to as the  ( hereafter ` awe ` ) . the processing of data from both the wfi and omegacam instruments has been used to qualify the pipeline , the results of which have been or will be included in separate publications , for example @xcite .",
    "the remainder of this section briefly describes some key concepts of ` awe `  covered in detail elsewhere : previously in @xcite and more currently in @xcite .",
    "sections  [ sec : calib ]  and  [ sec : image ] describe how an instrument is calibrated and how science data is processed .",
    "finally , sect .",
    "[ sec : summa ] presents the summary .",
    "context is the primary tool of project managers in ` awe ` .",
    "each _ process target _",
    "( i.e. , the result of some processing step , see sect .",
    "[ sec : objec ] ) in ` awe `  is created at a specific privilege level .",
    "privilege levels are analogous to the permission levels of a unix / linux file system ( e.g. , privilege levels 1 , 2 , 3 map loosely to permission levels user , group , other ) . to allow access to their desired set of objects , users can set their privilege level and their project .",
    "this concept of _ context _ is completely about visibility of the objects in ` awe `  and nothing else .",
    "proprietary data is protected from access by all but authorized users and undesirable data can be hidden for any purpose ( e.g. , to use project - specific calibrations instead of general ones ) .",
    "all processing is done within this framework , allowing complete control over what is processed and how , and how it is _ published _ between project groups and to the world .",
    "visibility for processing targets is not only governed by the privilege level , but also by validity .",
    "three properties dictate validity :    1 .   `",
    "is_valid `  manual validity flag 2 .",
    "` quality_flags `  automatic validity flag 3 .",
    "_ timestamps _  validity ranges in time ( for calibrations only )    determining what needs to be processed and how is indicated by setting any or all of the above flags .",
    "for instance , obviously poor quality data can be flagged by setting its ` is_valid ` flag to 0 , preventing it from ever being processed automatically .",
    "the calibrations used are determined by their _ timestamps _ ( which calibrations are valid for the given data ? ) and the quality of processed data by the automatic setting of its ` quality_flag ` ( is the given data good enough ? ) .",
    "good quality data can then be flagged for promotion ( ` is_valid ` @xmath1 ) and eventually promoted in privilege by its creator ( published from level 1 to 2 ) so it can be seen by the project manager who will decide if it is worthy to be promoted once again ( published from level 2 to 3 or higher ) to be seen by the greater community .",
    "` awe `  uses its federated database to link all data products to their progenitors ( dependencies ) , creating a full data lineage of the entire processing chain .",
    "this allows creation of complete data provenance for any data item in the system at any time .",
    "raw data is linked to the final data product via database links within the _ data object _ , allowing all information about any piece of data to be accessed instantly .",
    "see @xcite for a detailed description of the ` awe ` s data lineage implementation .",
    "this data linking uses the power of object - oriented programming to create this framework in a natural and transparent way .",
    "illustrating their inheritance relationship to each other .",
    "the classes without color do not appear in the previous figure , but are nonetheless part of the hierarchy and are shown for clarity .",
    "every target inherits from ` dbobject `  ( a database object ) , but only those with associated bulk data ( typically a file stored on a dataserver ) inherit from ` dataobject ` .",
    ", width=355 ]      ` awe `  uses the advantages of object - oriented programming ( oop ) to process data in the simplest and most powerful ways .",
    "in essence , it turns the aforementioned _ data objects _ into oop _",
    "objects _ , called _ process targets _ ( or ` processtarget`s ) , that are instances of classes with attributes and methods that can be inherited ( see fig .  [ fig : targe ]  and  [ fig : class ] for an overview of an  object model ) .",
    "each of these ` processtarget `  instances knows of all of its local and linked metadata , and knows how to process itself .",
    "each persistent attribute of an object is linked to metadata or to another object that itself contains links to its own metadata .",
    "the code for ` awe `  is written in , a programming language highly suitable for oop .",
    "consequently ,  _ classes _ are associated with the various conventional calibration images , data images , and other derived data products .",
    "for example , in ` awe ` , bias exposures become _ instances _ of the ` rawbiasframe `  class , and twilight ( sky ) flats become instances of the ` rawtwilightflatframe`class . these instances of classes",
    "are the `` objects '' of oop .    for the remainder of this document",
    ", the class names of objects , their properties , and methods will be in ` teletype ` font for more clear identification .",
    "the most unique aspect of ` awe `  is its ability to process data based on the final desired result to an arbitrary depth .",
    "in other words , the data is _ pulled _ from the system by the user .",
    "the desired result is the _ target _ to be processed , and the framework used is called _",
    "target processing_. target processing uses methods similar to those found in the unix / linux ` make ` utility .",
    "when a target is requested , its dependencies are checked to see if they are _ up - to - date_. if there is a newer dependency or if the requested target does not exist , the target is ( re)made . this process is recursive and is an example of _",
    "backward chaining_.      at the base of ` awe `  target processing is the concept of _ backward chaining_. contrary to the typical case of forward chaining ( e.g. , ` objectn ` is processed into ` objectn+1 ` is processed into ` objectn+2 ` , etc . ) . `",
    "awe `  database links allow the dependency chain to be examined from the intended target ( even if it does not yet exist ) all the way back to the raw data .",
    "the above scenario would then look like : if ` targetm ` is up - to - date , check if ` targetm-1 ` is up - to - date ; if ` targetm-1 ` is up - to - date , check if ` targetm-2 ` is up - to - date ; etc . ,",
    "processing as necessary until ` targetm ` ( and all targets it depends on ) exists and is up - to - date .",
    "this is the ` awe `  implementation of backward chaining that is used in target processing ( see fig .",
    "[ fig : targe ] for an example with astronomical data ) .      as mentioned earlier , conventional astronomical calibration images / products as well as science products",
    "are collectively referred to as _ process targets _ and inherit from the ` processtarget `  class .",
    "each ` processtarget `  has an associated _ processing parameters _ object , an instance of a class named after the respective process target class ( e.g. , ` sometarget.sometargetparameters ` ) which stores configurable parameters that guide the processing or reprocessing of that target .",
    "those ` processtarget`s that use external programs in their derivation may have additional objects associated with them which contain the configuration of the external program that was used .",
    "these processing parameters are stored in an object linked to the ` processtarget `  for comparison by the system and to allow the all persons involved in survey operations to discover which settings resulted in the best data reduction .          ` awe `  combines all of the above concepts into a coherent archiving and processing system .",
    "all the information about a particular instrument and its calibration and processing history is stored in the federated database within the object - oriented data model with full linking of the data lineage .",
    "the values of the process parameters of all objects in the dependency chain and all the results of the integrated ( and manual ) quality controls of the _ target _ of interest ( regardless of visibility or existence ) are used to determine if that _",
    "target _ can or should be ( re)built and how .",
    "this data pulling is the heart of ` awe `  and is called _ target processing _ ( see fig .  [",
    "fig : tproc ] and http://process.astro-wise.org/ ) .      as mentioned earlier , ` awe `  does not provide as the ultimate end of the processing chain a static data release .",
    "the system allows for survey data to be reprocessed for any reason and for any purpose . if a newer , better calibration is made , or if a different purpose requires a different processing technique , the data can be easily reprocessed .",
    "this is only possible when the raw survey data is retained in its original form . in ` awe",
    "` raw data is always preserved .",
    "target processing does not use static information to determine what gets processed how . as seen in all the previous sections , all the survey data ,",
    "its dependency linkages and processing parameters are all reviewed to allow any target to be ( re)processed on - demand as needed .",
    "all these dependencies create a built - in workflow , automatically processing only those targets that need it .",
    "this on - the - fly ( re)processing is the hallmark of the ` awe `  information system .",
    "the philosophy of ` awe `  is to share improved insight in calibrations . in ` awe ` , calibration scientists can , over time , have many versions of calibration results at their disposal . from this",
    "they determine ( subtle ) long term trends in instrument , telescope and atmospheric behaviour and can collaborate to improve the calibration procedures for that instrument in ` awe `  accordingly .",
    "the _ complete observational system _ ( generally termed `` the instrument '' for simplicity ) eventually becomes calibrated over its full operational period as opposed to a series of individual nights calibrated from data in a limited time window .",
    "[ fig : calib ] shows the schematic view of the pixel calibrations pipeline .",
    "this gives an overview of the flow of the pixel calibrations to be described in the coming sections .",
    "it is continued in the photometric pipeline schematic in fig .",
    "[ fig : photo ] .    .",
    "the recipes , also called ` tasks ` , used to produce various ` processtarget`s are indicated in each box ( with their data product in parentheses ) and described in the various sections .",
    "the arrows connecting them indicate the direction of processing .",
    "note that the sections with the hatched boxes are optional branches in this pipeline , and the arrow at the end leads to the beginning of the photometric pipeline schematic in fig .  [ fig : photo ] .",
    "also note , in order to simplify this diagram , the ` gainlinearity ` , ` darkcurrent `  and ` nightskyflatframe`objects have been omitted .",
    ", width=445 ]    .",
    "the recipes , also called ` tasks ` , used to produce various ` processtarget`s are indicated in each box ( with their data product in parentheses ) and described in the various sections .",
    "the arrows connecting them indicate the direction of processing .",
    "note that the sections with the hatched boxes are optional branches in this pipeline , and the input follows from the pixel calibrations pipeline shown in fig .",
    "[ fig : calib ] .",
    ", width=445 ]    in the ` awe ` , calibration objects have a set validity range in time or per frame object that depends upon the calibration object ( the defaults are specified per calibration object in table  [ tab : valid ] below ) . the default validity time range ( ` timestamp_start ` to ` timestamp_end ` ) can be altered on the command - line using context methods ( see sect .  [",
    "sec : conte ] ) , or via the calts web - service ( see fig .  [",
    "fig : calts ] ) .        .",
    "default validities of calibration ` processtarget`s . all time spans are centered on local midnight of the day the source observations were taken unless otherwise indicated . [ cols=\"<,<\",options=\"header \" , ]      the most basic outcome of the image pipeline is the ` reducedscienceframe ` .",
    "conventional de - trending steps are performed when making this frame :    1 .",
    "overscan correction and trimming 2 .",
    "subtraction of the ` biasframe ` 3 .",
    "division by the ` masterflatframe ` 4 .",
    "scaling and subtraction of a ` fringeframe `  if indicated 5 .",
    "multiplication by an ` illuminationcorrectionframe `  if indicated 6 .",
    "creation of the individual weight image 7 .",
    "computation of the image statistics    please note that :    * the overscan correction can be a null correction ( i.e. , no modification of the pixel values ) * the illumination correction step ( i.e. , application of a photometric flat field ) has had a sextractor - created background removed and then reapplied after the multiplication , and the correction only occurs when requested and if a suitable ` illuminationcorrectionframe `  exists      in addition to the effects of hot and cold pixels , individual images may be contaminated by saturated pixels , cosmic ray events , and satellite tracks . for purposes of subsequent analysis and image combination , affected pixels unique to each image need to be assigned a weight of zero in that image s weight map .",
    "since the variance is inversely proportional to the gain , which is proportional to the flatfield , the weight is given by : @xmath2 where @xmath3 is the weight of a given pixel , @xmath4 is the gain of a given pixel ( taken from the flat field ) , and the rest of the members are binary maps where good pixels have a value of 1 and bad pixels have a value of 0 .",
    "these maps are , respectively , a ` hotpixelmap ` , a ` coldpixelmap ` , a ` saturatedpixelmap ` , a ` cosmicmap ` , and a ` satellitemap ` , the last three being calculated directly from the ` reducedscienceframe `  after detrending .",
    "saturated pixels are pixels whose counts exceed a certain threshold .",
    "in addition , saturation of a pixel may lead to _",
    "dead _ neighbouring pixels , whose counts lie below a lower threshold . these upper and lower thresholds are defined and stored in the object .",
    "two programs may be used to detect cosmic ray events :    1 .",
    "* sextractor * can be run with a special filter that is only sensitive to cosmic - ray - like signal .",
    "this requires a ` retina ' filter , which is a neural network that uses the relative signal in neighboring pixels to decide if a pixel is a cosmic .",
    "a retina filter , called cosmic.ret is provided .",
    "run sextractor with ` filter_name = cosmic.ret ` , to run sextractor in comic ray detection mode .",
    "this results in a so - called segmentation map , recording the pixels affected by cosmic ray events .",
    "this segmentation can be used to assign a weight of zero to these pixels .",
    "* cosmicfits * is designed as a stand - alone program to detect cosmic ray events .    in the ` awe ` , the sextractor method is the preferred cosmic ray event detection method .",
    "linear features can be detected using a _ hough transform _",
    "algorithm , which is used to find satellite tracks .",
    "see @xcite for more information about the hough transform .",
    "a point @xmath5 defines a curve in hough space @xmath6 , where : @xmath7 corresponding to lines with slopes @xmath8 , passing at a distance @xmath9 from the origin .",
    "this means that different points lying on a straight line in image space , will correspond to a single point ( @xmath10 ) in hough space .",
    "the algorithm then creates a hough image from an input image , by adding a hough curve for each input pixel which lies above a given threshold . this hough image ( effectively a histogram of pixels corresponding to possible lines )",
    "is clipped , and transformed back into a pixelmap , masking lines with too many contributing pixels .",
    "the parameters from the astrometric solution are used during the regridding process and their creation has already been discussed in sect .",
    "[ sec : astro ] .",
    "the parameters from the photometric solution are used during the coaddition process and their creation has already been discussed in sect .",
    "[ sec : photo ] .",
    "regridding and co - adding are done using the swarp program . before images are co - added , they are resampled to a predefined pixel grid ( see sect .",
    "[ sec : skygr ] ) .",
    "by co - adding onto a simple coordinate system , characterized by the projection ( tangential , conic - equal - area ) , reference coordinates , reference pixel , and pixel scale , the distortions recorded by the astrometric solution are removed from the images . to this end",
    "a set of projection centers is defined , at 1 degree separation and pixel scale of 0.2 arcsec .",
    "a ` reducedscienceframe `  resampled to this grid is called a ` regriddedframe ` .",
    "the background of the image can be calculated and subtracted at this time , if desired .",
    "after the ` regriddedframe`s are made , it is only a matter of applying the photometry of each frame and stacking the result .",
    "this process creates a ` coaddedregriddedframe ` .",
    "one point of great importance in considering the coadded data is its pixel units .",
    "the units are fluxes relative to the flux corresponding to magnitude=0 .",
    "in other words , the magnitude @xmath11 corresponding to a pixel value @xmath12 is : @xmath13    the value @xmath14 of a pixel in the ` coaddedregriddedframe `  is computed from all overlapping pixels _",
    "i _ in the input ` regriddedframe`s according to this formula : @xmath15 where @xmath16 is the pixel value in the ` regriddedframe ` , @xmath17 is calculated from the zeropoint , and @xmath18 where @xmath19 is the value of the pixel in the input weight image .",
    "a ` weightframe `  is created as well .",
    "the value @xmath20 of the pixel in the weight frame for the coadd is : @xmath21      in ` awe ` , source information from processed frames can be stored in the database in the form of ` sourcelist`s .",
    "these are simply a transcription of a sextractor - derived catalog values ( position , ellipticity , brightness , etc . ) into the database .",
    "normally , the catalog was derived from a processed frame existing in the system , but this is not a requirement .",
    "arbitrary sextractor catalogs meeting a minimum content criteria can be ingested as well .",
    "this is how large survey results and reference catalogs are brought into the system .",
    "these ` sourcelist`s can be used for a variety of purposes such as astrometric and photometric correction , but are normally an end product of the image pipeline storing key quantities about the sources in question for further analysis .",
    "multiple ` sourcelist`s can be combined into an ` associatelist ` , and later into another ` sourcelist `  via the ` combinedlist `  machinery .",
    "multiple ` sourcelist`s can be spatially combined ( via ra and dec values ) and stored in the database via the ` associatelist `  class .",
    "the association is done in the following way :    1 .",
    "the area of overlap of the two ` sourcelist`s is calculated .",
    "if there is no overlap no associating will be done .",
    "2 .   the sources in one ` sourcelist `  are paired with sources in the other if they are within a certain association radius .",
    "default radius is 5@xmath22 .",
    "the pairs get an unique associate i d ( aid ) and are stored in the ` associatelist ` .",
    "a filter is used to select only the closest pairs .",
    "finally the sources which are not paired with sources in the other list and are inside the overlapping area of the two ` sourcelist `  are stored in the ` associatelist `  as singles .",
    "they too get an unique aid .    very important is the type of association being done .",
    "one of three types : chain , master or matched , will be done . in a _ chain",
    "_ association , all subsequent ` sourcelist`s are matched to the previous ` sourcelist `  to find pairs , in a _",
    "association , they are always matched with the first ` sourcelist ` , and in a _ matched _ association , all ` sourcelist`s are matched with all other ` sourcelist`s .",
    "the development and implementation of the  optical pipeline has been described .",
    "this pipeline uses the  : an information system designed to integrate hardware , software and human resources , data processing , and quality control in a coherent system that provides an unparalleled environment for processing astronomical data at any level , be it an individual user or a large survey team spread over many institutes and/or countries .",
    "the  is built around an object - oriented programming ( oop ) model using where each data product is represented by the instantiation of a particular type of object .",
    "the processability and quality of these data objects ( ` processtarget`s ) is moderated by built - in attributes and methods that know , for each individual type of object or oop class , how to process or qualify itself .",
    "all progenitor and derived data products are transparently linked via the database , providing an uninterrupted path between completely raw and fully processed data .",
    "this data lineage and provenance allows for a type of processing whereby the pipeline used for a given set of data is created _ on - the - fly _ for that particular set of data , where the unix ` make ` metaphor is employed to chain backward though the data , processing only what needs to be processed ( target processing ) .",
    "this allows unparalleled efficiency and data transparency for reprocessing the data when necessary , as the raw data is always available when newer techniques become available .",
    "calibration of data follows the usual routes , but has been optimized for processing of omegacam calibration data meant for detrending survey data . in this process",
    ", data is processed and reprocessed as more and more knowledge of the instrument system ( from the optics through detector chain ) is acquired .",
    "this effectively calibrates the instrument , leaving the data simply to be processed without the need of users find or qualify their own calibrations .",
    "various attributes of calibration objects ( validity , quality , valid time ranges ) transparently determine which calibrations are best to be used for any data .",
    "processing parameters are set and can be reset as desired .",
    "these parameters are retained as part of the calibration object and guarantee that a given object can be reprocessed to obtain the same result or be _ tweaked _ to improve the result .",
    "the processing of science data is governed by the same validity , quality , valid time range , and processing parameter mechanism that is used for calibration data .",
    "the calibration pipeline starts with a ` readnoise `  object created from ` rawbiasframe`s that is used to determine a clipping limit for ` biasframe `  creation .",
    "a ` gainlinearity`object can be processed from a special set of ` rawdomeflatframe`s taken for the purpose . from this result , both the gain ( in @xmath23adu ) and the detector linearity can be determined .",
    "a master ` biasframe `  is created from a set of ` rawbiasframe`s to remove 2-dimensional additive structure in detectors .",
    "the ` darkcurrent `  is measured for quality control of the detectors , but is not applied to the pixels .",
    "bad pixels in a given detector can be found from the ` biasframe `  and a flat field image .",
    "these are termed ` hotpixelmap `  and ` coldpixelmap ` , respectively .",
    "flat field creation in  can be very simple or very complex . on the simple side , a single set of ` rawdomeflatframe`s or ` rawtwilightflatframe`s",
    "can be combined with outlier rejection and normalized to the median . on the complex side ,",
    "high spatial frequencies can be taken from the ` domeflatframe`and the low spatial frequencies from the ` twilightflatframe ` .",
    "in addition , a ` nightskyflatframe `  can be added to improve this result . for an additional refinement to the flat field correction for redder filters ,",
    "a ` fringeframe `  can be created .",
    "astrometric calibration starts with extraction of sources from individual ` reducedscienceframe`s .",
    "the source positions are matched to those in an astrometric reference catalog ( e.g. , usno - a2.0 ) and all the positional differences minimized with the ldac programs .",
    "this _ local _ solution can then be further refined by adding overlap information from a dither to form a _",
    "astrometric solution .",
    "astrometric solutions are always stored for each ` reducedscienceframe `  individually .",
    "photometric calibration also starts with source extraction ( as a ` photsrccatalog ` ) and positional association .",
    "then , the magnitudes of the associated sources are compared to those in a photometric reference catalog ( e.g. , landolt ) and the mean of the kappa - sigma - clipped values results in a zeropoint for a given detector for the night in question .",
    "the extinction can be derived from multiple such measurements , the results of both being stored in a ` photometricparameters`object . as an optional refinement to the photometric zeropoint",
    ", a photometric super flat can be constructed by fitting magnitude differences as a function of radius across the whole detector block .",
    "the result of this is stored in an ` illuminationcorrectionframe `  object .",
    "the image pipeline takes all the calibrations from ` biasframe `  through ` masterflatframe `  to transform a ` rawscienceframe `  into a ` reducedscienceframe ` .",
    "this includes trimming the image after applying the overscan correction , subtracting the ` biasframe ` , dividing by the ` masterflatframe ` , and applying the ` fringeframe `  and ` illuminationcorrectionframe `  if necessary .",
    "the ` weightframe `  is constructed by taking the ` hotpixelmap `  and ` coldpixelmap `  and combining them with a ` saturatedpixelmap ` , a ` satellitemap ` , a ` cosmicmap ` , and optionally a ` illuminationcorrectionframe ` .",
    "these are all applied to the ` masterflatframe `  to create the final ` weightframe ` .",
    "next , the ` astrometricparameters `  is applied to the ` reducedscienceframe `  in creating the ` regriddedframe ` , and the ` photometricparameters `  is applied to multiple ` regriddedframe`s to form a ` coaddedregriddedframe ` .",
    "lastly , the sources from one ` coaddedregriddedframe `  can be extracted into a ` sourcelist`and associated with other ` sourcelist`s to form an ` associatelist`object .",
    "this last is the final output of the image pipeline and can combine information from multiple filters on the same part of the sky into one data product .",
    "using ` awe ` , the  survey team has begun processing each week s worth of data taken at the vst ( more than half a terabyte ) in a single night .",
    "the part of the data that requires it ( bad quality or validity ) is reprocessed nightly as necessary to gain the required insight into the different aspects of the calibration process : detrending calibrations , astrometric calibrations , and photometric calibrations .",
    "the  is a unique multi - purpose pipeline for astronomical surveys .",
    "all required tools ( ingestion , processing , quality control , and publishing ) are integrated in an intuitive and transparent way .",
    "it has already been used to process archive wfi@2.2 m , megacam@cfht ( cfhtls ) , and vircam@vista data in pseudo - survey mode in preparation for its main task : processing , vesuvio , omegawhite , and omegatrans survey data from the newly commissioned omegacam@vst .",
    "tables [ tab : grid1 ] & [ tab : grid2 ] describe a grid on the sky for projection and co - addition purposes in a condensed format .",
    "it contains 95 strips as function of decreasing declination ( @xmath24 ) . for each strip the size in degrees and the number of @xmath25 fields per strip",
    "the last column contains the overlap between fields in % . by mirroring the grid along the equator one obtains a grid for the northern hemisphere .",
    "the combination of the grids for both hemispheres is a grid for the entire sky .",
    "lcccr * strip*&*@xmath26 [ @xmath27*&*size [ @xmath27*&*fields / strip*&*overlap [ % ] * + 1 & 0.00&360.00&378&5.0 2 & 0.96&359.95&378&5.0 3 & 1.91&359.80&378&5.1 4 & 2.87&359.55&378&5.1 5 & 3.83&359.20&377&5.0 6 & 4.79&358.74&376&4.8 7 & 5.74&358.19&375&4.7 8 & 6.70&357.54&374&4.6 9 & 7.66&356.79&373&4.510 & 8.62&355.94&372&4.511 & 9.57&354.99&371&4.512&10.53&353.94&370&4.513&11.49&352.79&369&4.614&12.45&351.54&368&4.715&13.40&350.19&367&4.816&14.36&348.75&366&4.917&15.32&347.21&365&5.118&16.28&345.57&363&5.019&17.23&343.84&361&5.020&18.19&342.01&359&5.021&19.15&340.08&357&5.022&20.11&338.06&355&5.023&21.06&335.95&353&5.124&22.02&333.74&350&4.925&22.98&331.43&347&4.726&23.94&329.04&344&4.527&24.89&326.55&341&4.428&25.85&323.97&338&4.329&26.81&321.31&335&4.330&27.77&318.55&332&4.231&28.72&315.70&329&4.232&29.68&312.77&326&4.233&30.64&309.74&323&4.334&31.60&306.64&320&4.435&32.55&303.44&317&4.536&33.51&300.16&314&4.637&34.47&296.80&311&4.838&35.43&293.35&308&5.039&36.38&289.83&304&4.940&37.34&286.22&300&4.841&38.30&282.53&296&4.842&39.26&278.76&292&4.743&40.21&274.91&288&4.844&41.17&270.99&284&4.845&42.13&266.99&280&4.946&43.09&262.92&276&5.047&44.04&258.78&272&5.148&45.00&254.56&267&4.949&45.96&250.27&262&4.750&46.91&245.91&257&4.5    lcccr * strip*&*@xmath26 [ @xmath27*&*size [ @xmath27*&*fields / strip*&*overlap [ % ] * + 51&47.87&241.48&252 & 4.452&48.83&236.99&247 & 4.253&49.79&232.43&242 & 4.154&50.74&227.80&237 & 4.055&51.70&223.11&232 & 4.056&52.66&218.36&227 & 4.057&53.62&213.54&222 & 4.058&54.57&208.67&217 & 4.059&55.53&203.74&212 & 4.160&56.49&198.75&207 & 4.161&57.45&193.71&202 & 4.362&58.40&188.61&197 & 4.463&59.36&183.46&192 & 4.764&60.32&178.26&187 & 4.965&61.28&173.01&182 & 5.266&62.23&167.71&176 & 4.967&63.19&162.36&170 & 4.768&64.15&156.97&164 & 4.569&65.11&151.54&158 & 4.370&66.06&146.06&152 & 4.171&67.02&140.54&146 & 3.972&67.98&134.98&140 & 3.773&68.94&129.39&134 & 3.674&69.89&123.76&128 & 3.475&70.85&118.09&122 & 3.376&71.81&112.39&116 & 3.277&72.77&106.66&110 & 3.178&73.72&100.90&104 & 3.179&74.68 & 95.11 & 98 & 3.080&75.64 & 89.30 & 92 & 3.081&76.60 & 83.46 & 86 & 3.082&77.55 & 77.59 & 80 & 3.183&78.51 & 71.71 & 74 & 3.284&79.47 & 65.80 & 68 & 3.385&80.43 & 59.88 & 62 & 3.586&81.38 & 53.94 & 56 & 3.887&82.34 & 47.98 & 50 & 4.288&83.30 & 42.01 & 44 & 4.789&84.26 & 36.03 & 38 & 5.590&85.21 & 30.04 & 32 & 6.591&86.17 & 24.05 & 26 & 8.192&87.13 & 18.04 & 19 & 5.393&88.09 & 12.03 & 13 & 8.194&89.04 & 6.02 & 7&16.495&89.90 & 0.63 & 1 & -    astro - wise is an on - going project which started from a fp5 rtd programme funded by the ec action `` enhancing access to research infrastructures '' .",
    "this work is supported by fp7 specific programme `` capacities - optimising the use and development of research infrastructures '' .",
    "special thanks to francisco valdes for his constructive comments .",
    "mwebaze , j. , boxhoorn , d. & valentijn , e. : astro - wise : tracing and using lineage for scientific data processing .",
    "nbis , 2009 international conference on network - based information systems , p.475 ( 2009 )    valentijn , e.a . ,",
    "mcfarland , j.p . ,",
    "snigula , j. , begeman , k.g . ,",
    "boxhoorn , d.r . ,",
    "rengelink , r. , helmich , e. , heraudeau , p. , kleijn , g.v . ,",
    "vermeij , r. , vriend , w .- j . , tempelaar , m.j . ,",
    "deul , e. , kuijken , k. , capaccioli , m. , silvotti , r. , bender , r. , neeser , m. , saglia , r. , bertin , e. , mellier , y. : astro - wise : chaining to the universe .",
    "asp conference series , vol .",
    "376 , p.491 ( 2007 )"
  ],
  "abstract_text": [
    "<S> we have designed and implemented a novel way to process wide - field astronomical data within a distributed environment of hardware resources and humanpower . </S>",
    "<S> the system is characterized by integration of archiving , calibration , and post - calibration analysis of data from raw , through intermediate , to final data products . </S>",
    "<S> it is a true integration thanks to complete linking of data lineage from the final catalogs back to the raw data . </S>",
    "<S> this paper describes the pipeline processing of optical wide - field astronomical data from the wfi and omegacam instruments using the  information system ( the  or simply ` awe ` ) . </S>",
    "<S> this information system is an environment of hardware resources and humanpower distributed over europe . ` </S>",
    "<S> awe `  is characterized by integration of archiving , data calibration , post - calibration analysis , and archiving of raw , intermediate , and final data products . </S>",
    "<S> the true integration enables a complete data processing cycle from the raw data up to the publication of science - ready catalogs . </S>",
    "<S> the advantages of this system for very large datasets are in the areas of : survey operations management , quality control , calibration analyses , and massive processing . </S>"
  ]
}