{
  "article_text": [
    "many statistical models seek , given a set of observed data , to find the _ hidden _",
    "( unobserved ) data which best explains these observations . in this paper",
    "we consider graphical models ( both directed and undirected ) , a broad class that includes many useful models , such as hidden markov models ( hmms ) , pairwise - hidden markov models , hidden tree models , markov random fields , and some language models ( background on graphical models will be given in section  [ subsect : graphicalmodels ] ) .",
    "these graphical models relate the hidden and observed data probabilistically , and a natural problem is to determine , given a particular observation , what is the most likely hidden data ( which is called the _ explanation _ ) .",
    "these models rely on parameters that are the probabilities relating the hidden and observed data .",
    "any fixed values of the parameters determine a way to assign an explanation to each possible observation .",
    "this gives us a map , called an _ inference function _",
    ", from observations to explanations .",
    "an example of an inference function is the popular  _ did you mean _ \" feature from ` google ` , which could be implemented as a hidden markov model , where the observed data is what we type into the computer , and the hidden data is what we were meaning to type .",
    "graphical models are frequently used in these sorts of probabilistic approaches to machine learning , pattern recognition , and artificial intelligence ( see @xcite for an introduction ) .",
    "inference functions for graphical models are also important in computational biology ( * ? ? ?",
    "* section  1.5 ) , from where we originally drew inspiration for this paper .",
    "for example , consider the _ gene - finding functions _ , which were discussed in ( * ? ? ?",
    "* section 5 ) . these inference functions ( corresponding to a particular hmm )",
    "are used to identify gene structures in dna sequences .",
    "an observation in such a model is a sequence of nucleotides in the alphabet @xmath0 , and an explanation is a sequence of @xmath1 s and @xmath2 s which indicate whether the particular nucleotide is in a gene or is not .",
    "we seek to use the information in the observed data ( which we can find via dna sequencing ) to decide on the hidden information of which nucleotides are part of genes ( which is hard to figure out directly ) .",
    "another class of examples is that of sequence alignment models ( * ? ? ?",
    "* section 2.2 ) . in such models ,",
    "an inference function is a map from a pair of dna sequences to an optimal alignment of those sequences .",
    "if we change the parameters of the model , which alignments are optimal may change , and so the inference functions may change .",
    "a surprising conclusion of this paper is that there can not be _ too many _",
    "different inference functions , though the parameters may vary continuously over all possible choices .",
    "for example , in the homogeneous binary hmm of length 5 ( see section  [ subsect : graphicalmodels ] for some definitions ; they are not important at the moment ) , the observed data is a binary sequence of length 5 , and the explanation will also be a binary sequence of length 5 . at first glance , there are @xmath3 possible maps from observed sequences to explanations .",
    "in fact , christophe weibel has computed that only @xmath4 of these possible maps are actually inference functions @xcite . indeed , for an arbitrary graphical model",
    ", the number of possible maps from observed sequences to explanations is , at first glance , doubly exponential in the size of the model .",
    "the following theorem , which we call the _ few inference functions theorem _ , states that , if we fix the number of parameters , the number of inference functions is actually bounded by a polynomial in the size of the model .",
    "[ th : fif ] let @xmath5 be a fixed positive integer . consider a graphical model with @xmath5 parameters ( see definitions [ def : dgm ] and [ def : ugm ] for directed and undirected graphs , respectively ) .",
    "let @xmath6 be the _ complexity _ of the graphical model , where complexity is given by definitions [ m - dgm ] and [ m - ugm ] , respectively .",
    "then , the number of inference functions of the model is @xmath7 .    as we shall see , the complexity of a graphical model is often linear in the number of vertices or edges of the underlying graph .",
    "different inference functions represent different criteria to decide what is the most likely explanation for each observation . a bound on",
    "the number of inference functions is important because it indicates how badly a model may respond to changes in the parameter values ( which are generally known with very little certainty and only guessed at ) .",
    "also , the polynomial bound given in section  [ sec : the_fif_theorem ] suggests that it might be feasible to precompute all the inference functions of a given graphical model , which would yield an efficient way to provide an explanation for each given observation .",
    "this paper is structured as follows . in section  [ sec : prelim ] we introduce some preliminaries about graphical models and inference functions , as well as some facts about polytopes . in section  [ sec : the_fif_theorem ] we prove theorem  [ th : fif ] . in section  [ sec : lower_bound ] we prove that our upper bound on the number of inference functions of a graphical model is sharp , up to a constant factor , by constructing a family of hmms whose number of inference functions asymptotically matches the bound . in section  [ sec : seq_align ] we show that the bound is also asymptotically tight on a model for sequence alignment which is actually used in computational biology .",
    "in particular , this bound will be quadratic on the length of the input dna sequences .",
    "we conclude with a few remarks and possible directions for further research .",
    "a _ statistical model _ is a family of joint probability distributions for a collection of discrete random variables @xmath8 , where each @xmath9 takes on values in some finite state space @xmath10 .",
    "graphical model _ is represented by a graph where each vertex @xmath11 corresponds to a random variable @xmath9 .",
    "the edges of the graph represent the dependencies between the variables .",
    "there are two major classes of graphical models depending on whether @xmath12 is a directed or an undirected graph .",
    "we start by discussing _ directed graphical models _ , also called _ bayesian networks _ , which are those represented by a finite directed acyclic graph @xmath12 .",
    "each vertex @xmath11 has an associated probability map @xmath13^{{\\left\\lvert\\sigma_i\\right\\rvert}}.\\ ] ]    given the states of each @xmath14 such that @xmath15 is a parent of @xmath11 , the probability that @xmath11 has a given state is independent of all other vertices that are not descendants of @xmath11 , and this map @xmath16 gives that probability .",
    "in particular , we have the equality @xmath17_{\\rho_i}\\right),\\end{aligned}\\ ] ] where @xmath18 are the parents of @xmath11 .",
    "sources in the digraph ( which have no parents ) are generally given the uniform probability distribution on their states , though more general distributions are possible .",
    "see ( * ? ? ?",
    "* section 1.5 ) for general background on graphical models .",
    "[ ex : hmm ] the hidden markov model ( hmm ) is a model with random variables @xmath19 and @xmath20 .",
    "edges go from @xmath21 to @xmath22 and from @xmath21 to @xmath23 .    generally , each @xmath21 has the same state space @xmath24 and each @xmath23 has the same state space @xmath25 .",
    "an hmm is called _ homogeneous _ if the @xmath26 , for @xmath27 , are identical and the @xmath28 are identical . in this case , the @xmath26 each correspond to the same @xmath29 matrix @xmath30 ( the _ transition matrix _ ) and the @xmath28 each correspond to the same @xmath31 matrix @xmath32 ( the _ emission _ matrix ) .    in the example , we have partitioned the variables into two sets . in general graphical models , we also have two kinds of variables : observed variables @xmath33 and hidden variables @xmath34 .",
    "generally , the observed variables are the sinks of the directed graph , and the hidden variables are the other vertices , but this does not need to be the case . to simplify the notation , we make the assumption , which is often the case in practice , that all the observed variables take their values in the same finite alphabet @xmath25 , and that all the hidden variables are on the finite alphabet @xmath24 .",
    "notice that for given @xmath24 and @xmath25 the homogeneous hmms in this example depend only on a fixed set of parameters , @xmath35 and @xmath36 , even as @xmath37 gets large .",
    "these are the sorts of models we are interested in .",
    "[ def : dgm ] a _ directed graphical model with @xmath5 parameters _ , @xmath38 , is a directed graphical model such that each probability @xmath39_{\\rho_i}$ ] in ( [ eqn : pi - dgm ] ) is a monomial in @xmath38 .    in what follows",
    "we denote by @xmath40 the number of edges of the underlying graph of a graphical model , by @xmath37 the number of observed random variables , and by @xmath41 the number of hidden random variables .",
    "the observations , then , are sequences in @xmath42 and the explanations are sequences in @xmath43 .",
    "let @xmath44 and @xmath45 .    for each observation @xmath46 and",
    "hidden variables @xmath47 , @xmath48 is a monomial @xmath49 in the parameters @xmath38 .",
    "then for each observation @xmath50 , the observed probability @xmath51 is the sum over all hidden data @xmath47 of @xmath48 , and so @xmath51 is the polynomial @xmath52 in the parameters @xmath38 .    [ m - dgm ] the _ complexity _ , @xmath6 , of a directed graphical model is the maximum , over all @xmath46 , of the degree of the polynomial @xmath53 .    in many graphical models , @xmath6 will be a linear function of @xmath37 , the number of observed variables .",
    "for example , in the homogeneous hmm , @xmath54 .",
    "note that we have not assumed that the appropriate probabilities sum to 1 .",
    "it turns out that the analysis is much easier if we do not place that restriction on our probabilities . at the end of the analysis",
    ", these restrictions may be added if desired ( there are many models in use , however , which never place that restriction ; these can no longer be properly called `` probabilistic '' models , but in fact belong to a more general class of `` scoring '' models which our analysis also encompasses ) .",
    "the other class of graphical models are those that are represented by an undirected graph .",
    "they are called _ undirected graphical models _ and are also known as _ markov random fields_. as for directed models , the vertices of the graph @xmath12 correspond to the random variables , but the joint probability is now represented as a product of local functions defined on the maximal cliques of the graph , instead of transition probabilities @xmath16 defined on the edges .",
    "recall that a _ clique _ of a graph is a set of vertices with the property that there is an edge between any two of them .",
    "a clique is _ maximal _ if it can not be extended to include additional vertices without losing the property of being a clique ( see figure  [ fig : cliques ] ) .",
    "each maximal clique @xmath55 of the graph @xmath12 has an associated _ potential function _ @xmath56 given the states @xmath57 of each @xmath14 such that @xmath15 is a vertex in the clique @xmath55 , if we denote by @xmath58 the vector of such states , then @xmath59 is a nonnegative real number .",
    "we denote by @xmath60 the set of all maximal cliques @xmath55 .",
    "then , the joint probability distribution of all the variables @xmath9 is given by @xmath61 where @xmath62 is the normalization factor @xmath63 obtained by summing over all assignments of values to the variables @xmath64 .",
    "the value of the function @xmath59 for each possible choice of the states @xmath65 is given by the parameters of the model .",
    "we will be interested in models in which the set of parameters is fixed , even as the size of the graph gets large .",
    "[ def : ugm ] an _ undirected graphical model with @xmath5 parameters _ ,",
    "@xmath38 , is an undirected graphical model such that each probability @xmath59 in ( [ eqn : pi - ugm ] ) is a monomial in @xmath38 .    as in the case of directed models",
    ", the variables can be partitioned into observed variables @xmath33 ( which can be assumed to take their values in the same finite alphabet @xmath25 ) and hidden variables @xmath34 ( which can be assumed to be on the finite alphabet @xmath24 ) . for each observation @xmath46 and hidden variables @xmath47 , @xmath66 is a monomial @xmath49 in the parameters @xmath38 .",
    "then for each observation @xmath50 , the observed probability @xmath51 is the sum over all hidden data @xmath47 of @xmath48 , and so @xmath67 is the polynomial @xmath52 in the parameters @xmath38 .",
    "[ m - ugm ] the _ complexity _ , @xmath6 , of an undirected graphical model is the maximum , over all @xmath46 , of the degree of the polynomial @xmath53 .",
    "it is usually the case for undirected models , as in directed , that @xmath6 is a linear function of @xmath37 .      for fixed values of the parameters ,",
    "the basic inference problem is to determine , for each given observation @xmath46 , the value @xmath68 of the hidden data that maximizes @xmath69 .",
    "a solution to this optimization problem is denoted @xmath70 and is called an _ explanation _ of the observation @xmath46 .",
    "each choice of parameter values @xmath71 defines an _ inference function _ @xmath72 from the set of observations @xmath42 to the set of explanations @xmath43 .",
    "it is possible that there is more than one value of @xmath70 attaining the maximum of @xmath73 . in this case , for simplicity , we will pick only one such explanation , according to some consistent tie - breaking rule decided ahead of time .",
    "for example , we can pick the least such @xmath70 in some given total order of the set @xmath43 of hidden states .",
    "another alternative would be to define inference functions as maps from @xmath42 to subsets of @xmath43 .",
    "this would not affect the results of this paper , so for the sake of simplicity , we consider only inference functions as defined above .",
    "it is interesting to observe that the total number of maps @xmath74 is @xmath75 , which is doubly - exponential in the length @xmath37 of the observations .",
    "however , the vast majority of these maps are not inference functions for any values of the parameters . before our results ,",
    "the best upper bound in the literature is an exponential bound given in ( * ? ? ?",
    "* corollary 10 ) .",
    "theorem  [ th : fif ] gives a polynomial upper bound on the number of inference functions of a graphical model .",
    "here we review some facts about convex polytopes , and we introduce some notation . recall that a polytope is a bounded intersection of finitely many closed halfspaces , or equivalently , the convex hull of a finite set of points .",
    "for the basic definitions about polytopes we refer the reader to  @xcite .    given a polynomial @xmath76 , its _",
    "newton polytope _ , denoted by @xmath77 , is defined as the convex hull in @xmath78 of the set of points @xmath79 .",
    "for example , if @xmath80 , then its newton polytope @xmath77 is given in figure  [ fig : newton ] .",
    "given a polytope @xmath81 and a vector @xmath82 , the set of all points in @xmath83 at which the linear functional @xmath84 attains its maximum determines a _ face _ of @xmath83 .",
    "it is denoted @xmath85 faces of dimension 0 ( consisting of a single point ) are called _ vertices _ , and faces of dimension 1 are called _",
    "edges_. if @xmath5 is the dimension of the polytope , then faces of dimension @xmath86 are called _",
    "let @xmath83 be a polytope and @xmath87 a face of @xmath83 .",
    "the _ normal cone _ of @xmath83 at @xmath87 is @xmath88    the collection of all cones @xmath89 as @xmath87 runs over all faces of @xmath83 is denoted @xmath90 and is called the of @xmath83 .",
    "thus the normal fan @xmath90 is a partition of @xmath91 into cones .",
    "the cones in @xmath90 are in bijection with the faces of @xmath83 , and if @xmath92 than the linear functional @xmath93 is maximized on @xmath87 .",
    "figure  [ fig : normal ] shows the normal fan of the polytope from figure  [ fig : newton ] .",
    "the _ minkowski sum _ of two polytopes @xmath83 and @xmath94 is defined as @xmath95 figure  [ fig : minksum ] shows an example in 2 dimensions .",
    "the newton polytope of the map @xmath96 is defined as the minkowski sum of the individual newton polytopes of its coordinates , namely @xmath97 .",
    "the _ common refinement _ of two or more normal fans is the collection of cones obtained as the intersection of a cone from each of the individual fans . for polytopes @xmath98 , the common refinement of their normal fans",
    "is denoted @xmath99 .",
    "the following lemma states the well - known fact that the normal fan of a minkowski sum of polytopes is the common refinement of their individual fans ( see ( * ? ? ?",
    "* proposition 7.12 ) or ( * ? ? ?",
    "* lemma 2.1.5 ) ) :    [ lem : sum_refinement ] @xmath100 .",
    "we finish with a result of gritzmann and sturmfels that will be useful later .",
    "it gives a bound on the number of vertices of a minkowski sum of polytopes .",
    "[ thm : non - parallel ] let @xmath98 be polytopes in @xmath78 , and let @xmath101 denote the number of non - parallel edges of @xmath102 .",
    "then the number of vertices of @xmath103 is at most @xmath104    note that this bound is independent of the number @xmath105 of polytopes .",
    "for fixed parameters , the inference problem of finding the explanation @xmath70 that maximizes @xmath73 is equivalent to identifying the monomial @xmath106 of @xmath107 with maximum value . since the logarithm is a monotonically increasing function , the desired monomial also maximizes the quantity @xmath108 where we replace @xmath109 with @xmath11 .",
    "this is equivalent to the fact that the corresponding point @xmath110 maximizes the linear expression @xmath111 on the newton polytope @xmath112 .",
    "thus , the inference problem for fixed parameters becomes a linear programming problem .",
    "each choice of the parameters @xmath113 determines an inference function .",
    "if @xmath114 is the vector in @xmath78 with coordinates @xmath115 , then we denote the corresponding inference function by @xmath116 for each observation @xmath50 , its explanation @xmath117 is given by the vertex of @xmath112 that is maximal in the direction of the vector @xmath118 .",
    "note that for certain values of the parameters ( if @xmath118 is perpendicular to a positive - dimensional face of @xmath112 ) there may be more than one vertex attaining the maximum .",
    "it is also possible that a single point @xmath110 in the polytope corresponds to several different values of the hidden data . in both cases",
    ", we pick the explanation according to the tie - breaking rule determined ahead of time",
    ". this simplification does not affect the asymptotic number of inference functions .",
    "different values of @xmath119 yield different directions @xmath118 , which can result in distinct inference functions .",
    "we are interested in bounding the number of different inference functions that a graphical model can have .",
    "theorem  [ th : fif ] gives an upper bound which is polynomial in the size of the graphical model .",
    "in other words , extremely few of the @xmath120 functions @xmath74 are actually inference functions .",
    "we use the notation @xmath121 to indicate that @xmath122 .",
    "similarly @xmath123 means that @xmath124 , and @xmath125 denotes that @xmath126 belongs to both @xmath127 and @xmath128 .    before proving theorem  [ th : fif ] ,",
    "observe that usually @xmath6 , the complexity of the graphical model , is linear in @xmath37 .",
    "for example , in the case of directed models , consider the common situation where @xmath6 is bounded by @xmath40 , the number of edges of the underlying graph ( this happens when each edge `` contributes '' at most degree 1 to the monomials @xmath49 , as in the homogeneous hmm ) .",
    "in most graphical models of interest , @xmath40 is a linear function of @xmath37 , so the bound becomes @xmath129 .",
    "for example , the homogeneous hmm has @xmath54 .    in the case of undirected models , if each @xmath59 is a parameter of the model , then @xmath130 is a product of potential functions for each maximal clique of the graph , so @xmath6 is bounded by the number of maximal cliques , which in many cases is also a linear function of the number of vertices of the graph .",
    "for example , this is the situation in language models where each word depends on a fixed number of previous words in the sentence .    in the first part of the proof we will reduce the problem of counting inference functions to the enumeration of the vertices of a certain polytope .",
    "we have seen that an inference function is specified by a choice of the parameters , which is equivalent to choosing a vector @xmath131 .",
    "the function is denoted @xmath132 , and the explanation @xmath117 of a given observation @xmath46 is determined by the vertex of @xmath112 that is maximal in the direction of @xmath118 .",
    "thus , cones of the normal fan @xmath133 correspond to sets of vectors @xmath118 that give rise to the same explanation for the observation @xmath46 .",
    "non - maximal cones ( i.e. , those contained in another cone of higher dimension ) correspond to directions @xmath118 for which more than one vertex is maximal . since ties are broken using a consistent rule , we disregard this case for simplicity .",
    "thus , in what follows we consider only maximal cones of the normal fan .",
    "let @xmath134 be another vector corresponding to a different choice of parameters ( see figure [ fig : inf_fct ] ) . by the above reasoning , @xmath135 if and only if @xmath118 and @xmath136 belong to the same cone of @xmath133 .",
    "thus , @xmath137 and @xmath138 are the same inference function if and only if @xmath118 and @xmath136 belong to the same cone of @xmath133 for all observations @xmath50 .",
    "consider the common refinement of all these normal fans , @xmath139 .",
    "then , @xmath137 and @xmath138 are the same function exactly when @xmath118 and @xmath136 lie in the same cone of this common refinement .",
    "( left column ) and @xmath138 ( right column ) .",
    "each row corresponds to a different observation .",
    "the respective explanations are given by the marked vertices in each newton polytope .",
    "[ fig : inf_fct],scaledwidth=60.0% ]    this implies that the number of inference functions equals the number of cones in @xmath140 by lemma  [ lem : sum_refinement ] , this common refinement is the normal fan of @xmath141 , the minkowski sum of the polytopes @xmath112 for all observations @xmath46 .",
    "it follows that enumerating inference functions is equivalent to counting vertices of @xmath142 . in the remaining part of the proof we give an upper bound on the number of vertices of @xmath142 .",
    "note that for each @xmath46 , the polytope @xmath112 is contained in the hypercube @xmath143^d$ ] , since by definition of @xmath6 , each parameter @xmath144 appears in @xmath107 with exponent at most @xmath6 . also , the vertices of @xmath112 have integral coordinates , because they are exponent vectors .",
    "polytopes whose vertices have integral coordinates are called _",
    "lattice polytopes_. it follows that the edges of @xmath112 are given by vectors where each coordinate is an integer between @xmath145 and @xmath6 .",
    "there are only @xmath146 such vectors , so this is an upper bound on the number of different directions that the edges of the polytopes @xmath112 can have .",
    "this property of the newton polytopes of the coordinates of the model will allow us to give an upper bound on the number of vertices of their minkowski sum @xmath142 .",
    "the last ingredient that we need is theorem  [ thm : non - parallel ] . in our case",
    "we have a sum of polytopes @xmath112 , one for each observation @xmath50 , having at most @xmath146 non - parallel edges in total .",
    "hence , by theorem  [ thm : non - parallel ] , the number of vertices of @xmath142 is at most @xmath147 as @xmath6 goes to infinity , the dominant term of this expression is @xmath148 thus , we get an @xmath7 upper bound on the number of inference functions of the graphical model .    in the next section",
    "we will show that the bound given in theorem  [ th : fif ] is tight up to a constant factor .",
    "as before , we fix @xmath5 , the number of parameters in our model .",
    "the few inferences function theorem tells us that the number of inference functions is bounded from above by some function @xmath149 , where @xmath150 is a constant ( depending only on @xmath5 ) and @xmath6 is the complexity of the model . here we show that that bound is tight up to a constant , by constructing a family of graphical models whose number of inference functions is at least @xmath151 , where @xmath152 is another constant . in fact , we will construct a family of hidden markov models with this property . to be precise",
    ", we have the following theorem .",
    "[ thm : lowerbound ] fix @xmath5 .",
    "there is a constant @xmath153 such that , given @xmath154 , there exists an hmm of length @xmath37 , with @xmath5 parameters , @xmath155 hidden states , and @xmath156 observed states , such that there are at least @xmath157 distinct inference functions .",
    "( for this hmm , @xmath6 is a linear function of @xmath37 , so this also gives us the lower bound in terms of @xmath6 ) .    in section [ subsect : prooflowerbound ]",
    "we prove theorem [ thm : lowerbound ] .",
    "this proof requires several lemmas that we will meet along the way , and these lemmas will be proved in section [ subsect : lemmaslowerbound ] .",
    "lemma [ lemma : fullset ] , which is interesting in its own right as a statement in the geometry of numbers is proved in  @xcite .",
    "given @xmath37 , we first construct the appropriate hmm , @xmath158 , using the following lemma .",
    "[ lemma : anhmm ] given @xmath154 , there is an hmm , @xmath158 , of length @xmath37 , with @xmath5 parameters , @xmath155 hidden states , and 2 observed states , such that for any @xmath159 with @xmath160 , there is an observed sequence which has one explanation if @xmath161 and another explanation if @xmath162 .",
    "this means that , for the hmm @xmath158 , the decomposition of ( log-)parameter space into inference cones includes all of the hyperplanes @xmath163 such that @xmath159 with @xmath160 .",
    "call the arrangement of these hyperplanes @xmath164 it suffices to show that the arrangement @xmath165 consists of at least @xmath157 chambers ( full dimensional cones determined by the arrangement ) .",
    "there are @xmath166 ways to choose one of the hyperplanes from @xmath165 , for some constant @xmath167 .",
    "therefore there are @xmath168 ways to choose @xmath86 of the hyperplanes ; their intersection is , in general , a 1-dimensional face of @xmath165 ( that is , the intersection is a ray which is an extreme ray for the cones it is contained in ) .",
    "it is quite possible that two different ways of choosing @xmath86 hyperplanes give the same extreme ray .",
    "the following lemma says that some constant fraction of these choices of extreme rays are actually distinct .",
    "[ lemma : numextremerays ] fix @xmath5 . given @xmath37 ,",
    "let @xmath165 be the hyperplane arrangement consisting of the hyperplanes of the form @xmath169 with @xmath159 and @xmath170 .",
    "then the number of 1-dimensional faces of @xmath165 is @xmath171 , for some constant @xmath172 .",
    "each chamber will have a number of these extreme rays on its boundary .",
    "the following lemma gives a constant bound on this number .",
    "[ lemma : extremeraysperchamber ] fix @xmath5 .",
    "given @xmath37 , define @xmath165 as above .",
    "each chamber of @xmath165 has at most @xmath173 extreme rays .",
    "conversely , each ray is an extreme ray for at least @xmath1 chamber .",
    "therefore there are at least @xmath174 chambers , and theorem [ thm : lowerbound ] is proved .",
    "@xmath175 +   +    in proving lemma [ lemma : numextremerays ] , we will need one more lemma .",
    "this lemma is interesting in its own right as a probabilistic statement about integer lattices , and so is proved in a companion paper @xcite .",
    "given a set @xmath176 of integer vectors , @xmath177 is a linear subspace of @xmath91 and @xmath178 is a sublattice of @xmath179 .",
    "we say that @xmath180 is _ primitive _ if @xmath180 is a @xmath181-basis for the lattice @xmath178 .",
    "equivalently , a set @xmath180 is primitive if and only if it may be extended to a @xmath181-basis of all of @xmath179 ( see @xcite ) .    we imagine picking each vector in @xmath180 uniformly at random from some large box in @xmath91 . as the size of the box approaches infinity ,",
    "the following lemma will tell us that the probability that @xmath180 is primitive approaches @xmath182 where @xmath183 and @xmath184 is the riemann zeta function @xmath185 .",
    "[ lemma : fullset ] let @xmath5 and @xmath101 be given , with @xmath186 . for @xmath154 , @xmath187 , and @xmath188 , let @xmath189 . for",
    "a given @xmath37 , choose integers @xmath190 uniformly ( and independently ) at random from the set @xmath191 .",
    "let @xmath192 and let @xmath193 .    if @xmath194 is bounded by a polynomial in @xmath37 , then , as @xmath37 approaches infinity , the probability that @xmath180 is a primitive set approaches @xmath182 where @xmath184 is the riemann zeta function @xmath185 .",
    "when @xmath195 , this lemma gives the probability that a @xmath5-tuple of integers are relatively prime as @xmath196 . for @xmath197 ,",
    "this is a classic result in number theory ( see @xcite ) , and for @xmath198 , this was proven in @xcite .",
    "note also that , if @xmath199 and we choose @xmath180 of size @xmath101 , then the probability that @xmath180 is primitive ( i.e. , that it is a basis for @xmath179 ) approaches zero .",
    "this agrees with the lemma in the sense that we would expect the probability to be @xmath200 but @xmath201 does not converge .",
    "given @xmath5 and @xmath37 , define a length @xmath37 hmm with parameters @xmath202 , as follows .",
    "the observed states will be s and c ( for `` start of block , '' and `` continuing block , '' respectively ) .",
    "the hidden states will be @xmath203 , @xmath204 , @xmath205 , and @xmath206 , for @xmath207 ( think of @xmath203 and @xmath204 as `` start of the @xmath208th block '' and @xmath205 and @xmath206 as `` continuing the @xmath208th block '' ) .",
    "here is the idea of what we want this hmm to do : if the observed sequence has s s in position 1 , @xmath209 , @xmath210 , @xmath211 , and @xmath212 and c s elsewhere , then there will be only two possibilities for the sequence of hidden states , either @xmath213 or @xmath214 we will also make sure that @xmath215 has a priori probability @xmath216 and @xmath217 has a priori probability 1 . then @xmath215 is the explanation if @xmath218 and @xmath217 is the explanation if @xmath162 . remember that we are not constraining our probability sums to be 1 .",
    "a very similar hmm could be constructed that obeys that constraint , if desired . to simplify notation",
    "it will be more convenient to treat the transition probabilities as parameters that do not necessarily sum to one at each vertex , even if this forces us to use the term ",
    "probability \" somewhat loosely .    here is how we set up the transitions / emmisions .",
    "let @xmath203 and @xmath204 , for @xmath207 , all emit s with probability 1 and c with probability 0 .",
    "let @xmath205 and @xmath206 emit c with probability 1 and s with probability 0 .",
    "let @xmath203 , for @xmath188 , transition to @xmath205 with probability @xmath144 and transition to everything else with probability 0 .",
    "let @xmath219 transition to @xmath220 with probability @xmath1 and to everything else with probability 0 .",
    "let @xmath204 , for @xmath207 , transition to @xmath206 with probability @xmath1 and to everything else with probability 0 .",
    "let @xmath205 , for @xmath221 , transition to @xmath205 with probability @xmath144 , to @xmath222 with probability @xmath223 , and to everything else with probability 0 .",
    "let @xmath220 transition to @xmath220 with probability @xmath1 , and to everything else with probability 0 .",
    "let @xmath206 , for @xmath188 transition to @xmath206 with probability @xmath1 , to @xmath222 with probability @xmath1 , and to everything else with probability 0 .",
    "let @xmath224 transition to @xmath224 with probability @xmath1 and to everything else with probability 0 .",
    "starting with the uniform probability distribution on the first hidden state , this does exactly what we want it to : given the correct observed sequence , @xmath215 and @xmath217 are the only explanations , with the correct probabilities .",
    "we are going to pick @xmath86 vectors @xmath225 which correspond to the @xmath86 hyperplanes @xmath226 that will intersect to give us extreme rays of our chambers .",
    "we will restrict the region from which we pick each @xmath227 .",
    "let @xmath228 for @xmath229 , where @xmath230 is the @xmath208th standard basis vector .",
    "let @xmath231 . for @xmath229 , we will choose @xmath227 such that @xmath232 note that @xmath233 , so there are observed sequences which give us the hyperplanes @xmath234 . note also that there are @xmath235 choices for the @xmath236-tuple of vectors @xmath237 . to prove this lemma",
    ", we must then show that a positive fraction of these actually give rise to distinct extreme rays @xmath238 .",
    "first , we imagine choosing the @xmath239 uniformly at random in the range given by ( [ eqn : c1 ] ) , this probability distribution meets the condition in the statement of lemma [ lemma : fullset ] , as @xmath37 approaches infinity .",
    "therefore , there is a positive probability that @xmath240 and this probability approaches @xmath241    second , we look at all choices of @xmath227 such that ( [ eqn : c1 ] ) and ( [ eqn : c2 ] ) hold",
    ". there are @xmath171 of these , for some constant @xmath172 .",
    "we claim that these give distinct extreme rays @xmath242 .",
    "indeed , say that @xmath239 and @xmath243 are both chosen such that ( [ eqn : c1 ] ) and ( [ eqn : c2 ] ) hold and such that @xmath244 we will argue that @xmath239 and @xmath243 are `` so close '' that they must actually be the same .",
    "let @xmath245 , for @xmath246 be given .",
    "we will prove that @xmath247 . since @xmath248",
    "we know that @xmath249 is in @xmath250 , and therefore @xmath251 let @xmath252",
    ". then @xmath253 by condition ( [ eqn : c1 ] ) for @xmath239 and @xmath243 , and @xmath254 for some @xmath255 , by condition ( [ eqn : c2 ] ) for @xmath239 .",
    "we must show that @xmath256 . by reordering indices and possibly considering @xmath257",
    ", we may assume that @xmath258 , for some @xmath105 , @xmath259 , and @xmath260 is maximal over all @xmath261 , @xmath262 .",
    "examining the first coordinate of @xmath263 , we have that @xmath264 \\ \\ \\ \\ \\text { ( using $ b^{(i)}=(1,\\ldots,1)-\\frac{1}{2}e_i$ ) } \\\\ & \\le \\frac{n}{d}\\big[\\alpha_1+\\cdots+\\alpha_{d-1}-\\frac{1}{2}\\alpha_1+(d-1)s\\alpha_1\\big].\\end{aligned}\\ ] ] negating and dividing by @xmath265 , @xmath266 similarly , examining the @xmath267-st coordinate of @xmath263 , we have @xmath268\\\\ & \\ge \\frac{n}{d}\\big[\\alpha_1+\\cdots+\\alpha_{d-1}-\\frac{1}{2}\\alpha_{k+1}-(d-1)s\\alpha_1\\big],\\end{aligned}\\ ] ] and so @xmath269 adding the equations ( [ eq:1 ] ) and ( [ eq:2 ] ) , @xmath270 and so , since @xmath231 , @xmath271 therefore , since @xmath272 , we have that @xmath273 and so @xmath274 . since @xmath260 was maximal over all @xmath261 , we have that @xmath256 .",
    "therefore @xmath247 , and the lemma follows .",
    "suppose @xmath275 , and suppose @xmath276 for @xmath277 and @xmath246 , are such that @xmath278 , @xmath279 , and the @xmath280 rays @xmath281 are the extreme rays for some chamber .",
    "then , since @xmath275 , there are some @xmath208 and @xmath282 such that @xmath283 for @xmath246 and @xmath284 ( i.e. , all of the coordinates in all of the vectors have the same parity )",
    ". then let @xmath285 for @xmath246 .",
    "then @xmath286 and @xmath287 , and the ray @xmath288 is in the chamber , which is a contradiction .",
    "in this section we give an application of theorem  [ th : fif ] to a basic model for sequence alignment .",
    "sequence alignment is one of the most frequently used techniques in determining the similarity between biological sequences . in the standard instance of the sequence alignment problem , we are given two sequences ( usually dna or protein sequences ) that have evolved from a common ancestor via a series of mutations , insertions and deletions .",
    "the goal is to find the best alignment between the two sequences .",
    "the definition of  best \" here depends on the choice of scoring scheme , and there is often disagreement about the correct choice . in _",
    "parametric sequence alignment _",
    ", this problem is circumvented by instead computing the optimal alignment as a function of _ variable _ scores .",
    "here we consider one such scheme , in which all matches are equally rewarded , all mismatches are equally penalized and all spaces are equally penalized .",
    "efficient parametric sequence alignment algorithms are known ( see for example  ( * ? ? ?",
    "* chapter  7 ) ) .",
    "here we are concerned with the different inference functions that can arise when the parameters vary . for a detailed treatment on the subject of sequence alignment ,",
    "we refer the reader to @xcite .    given two strings @xmath289 and @xmath290 of lengths @xmath291 and @xmath292 respectively , an _ alignment _",
    "is a pair of equal length strings @xmath293 obtained from @xmath294 by inserting dashes `` @xmath295 '' in such a way that there is no position in which both @xmath296 and @xmath297 have a dash .",
    "match _ is a position where @xmath296 and @xmath297 have the same character , a _ mismatch _ is a position where @xmath296 and @xmath297 have different characters , and a _ space _ is a position in which one of @xmath296 and @xmath297 has a dash . a simple scoring scheme consists of two parameters @xmath298 and @xmath299 denoting mismatch and space penalties respectively .",
    "the reward of a match is set to @xmath1 .",
    "the score of an alignment with @xmath300 matches , @xmath301 mismatches , and @xmath302 spaces is then @xmath303 .",
    "observe that these numbers always satisfy @xmath304 .",
    "this model for sequence alignment can be translated into a probabilistic model , and is a particular case of a so - called pair hidden markov model .",
    "the problem of determining the highest scoring alignment for given values of @xmath298 and @xmath299 is equivalent to the inference problem in the pair hidden markov model , with some parameters set to functions of @xmath298 and @xmath299 , or to @xmath2 or @xmath1 . in this",
    "setting , an observation is a pair of sequences @xmath305 , and the number of observed variables is @xmath306 .",
    "an explanation is then an optimal alignment , since the values of the hidden variables indicate the positions of the spaces .    in the rest of this chapter",
    "we will refer to this as the _ @xmath156-parameter model for sequence alignment_. note that it actually comes from a @xmath307-parameter model where the reward for a match has , without loss of generality , been set to @xmath1 .",
    "the newton polytopes of the coordinates of the model are defined in a @xmath307-dimensional space , but in fact they lie on a plane , as we will see next .",
    "thus , the parameter space has only two degrees of freedom .    for each pair of sequences @xmath46 ,",
    "the newton polytope of the polynomial @xmath107 is the convex hull of the points @xmath308 whose coordinates are the number of mismatches , spaces , and matches , respectively , of each possible alignment of the pair .",
    "this polytope lies on the plane @xmath304 , so no information is lost by considering its projection onto the @xmath309-plane instead .",
    "this projection is just the convex hull of the points @xmath310 giving the number of mismatches and spaces of each alignment . for any alignment of sequences of lengths @xmath291 and @xmath292 , the corresponding point @xmath310 lies inside the square @xmath311 ^ 2 $ ] , where @xmath306 .",
    "therefore , since we are dealing with lattice polygons inside @xmath311 ^ 2 $ ] , it follows from theorem  [ th : fif ] that the number of inference functions of this model is @xmath312 .",
    "next we show that this quadratic bound is tight , even in the case of the binary alphabet .",
    "[ prop : tight_binary ] consider the @xmath156-parameter model for sequence alignment for two observed sequences of length @xmath37 and let @xmath313 be the binary alphabet . then",
    ", the number of inference functions of this model is @xmath314 .",
    "the above argument shows that @xmath315 is an upper bound on the number of inference functions of the model , for some constant @xmath150 . to prove the proposition",
    ", we will argue that there is some constant @xmath152 such that there are at least @xmath316 such functions .",
    "since the two sequences have the same length , the number of spaces in any alignment is even . for convenience , we define @xmath317 and @xmath318 , and we will work with the coordinates @xmath319 and the parameters @xmath298 and @xmath320 . the value @xmath321 is called the number of insertions ( half the number of spaces ) , and @xmath320 is the insertion penalty .",
    "for fixed values of @xmath298 and @xmath320 , the explanation of an observation @xmath305 is given by the vertex of @xmath112 that is maximal in the direction of the vector @xmath322 . in this model",
    ", @xmath112 is the convex hull of the points @xmath319 whose coordinates are the number of mismatches , insertions and matches of the alignments of @xmath289 and @xmath290 .",
    "the argument in the proof of theorem  [ th : fif ] shows that the number of inference functions of this model is the number of cones in the common refinement of the normal fans of @xmath112 , where @xmath46 runs over all pairs of sequences of length @xmath37 in the alphabet @xmath25 .",
    "since the polytopes @xmath112 lie on the plane @xmath323 , it is equivalent to consider the normal fans of their projections onto the @xmath324-plane .",
    "these projections are lattice polygons contained in the square @xmath311 ^ 2 $ ] .",
    "we denote by @xmath325 the projection of @xmath112 onto the @xmath324-plane .",
    "we will construct a collection of pairs of binary sequences @xmath305 so that the total number of different slopes of the edges of the polygons @xmath112 is @xmath326 .",
    "this will imply that the number of cones in @xmath327 is @xmath326 , where @xmath46 ranges over all pairs of binary sequences of length @xmath37 .",
    "we claim that for any positive integers @xmath328 and @xmath329 with @xmath330 and @xmath331 , there exists a pair @xmath46 of binary sequences of length @xmath37 such that @xmath325 has an edge of slope @xmath332 .",
    "this will imply that the number of different slopes created by the edges of the polygons @xmath325 is @xmath326 .",
    "thus , it only remains to prove the claim .",
    "given positive integers @xmath328 and @xmath329 as above , let @xmath333 , @xmath334 .",
    "assume first that @xmath335 .",
    "consider the sequences @xmath336 where @xmath337 indicates that the symbol @xmath2 is repeated @xmath338 times .",
    "let @xmath305 .",
    "then , it is not hard to see that the polygon @xmath325 for this pair of sequences has four vertices : @xmath339 , @xmath340 , @xmath341 and @xmath342 .",
    "the slope of the edge between @xmath343 and @xmath344 is @xmath345 .    if @xmath346 , we just append @xmath347 to both sequences @xmath289 and @xmath290 . in this case , the vertices of @xmath325 are @xmath348 , @xmath349 , @xmath350 , @xmath351 and @xmath352 .     in their alignment polytope . [",
    "fig : binary_slope],title=\"fig:\",scaledwidth=35.0% ] in their alignment polytope .",
    "[ fig : binary_slope],title=\"fig:\",scaledwidth=35.0% ]    note that if @xmath353 is even , the construction can be done with sequences of length @xmath354 by taking @xmath355 , @xmath356 .",
    "figure  [ fig : binary_slope ] shows the alignment graph and the polygon @xmath325 for @xmath357 , @xmath358 .    in most cases ,",
    "one is interested only in those inference functions that are biologically meaningful . in our case ,",
    "meaningful values of the parameters occur when @xmath359 , which means that mismatches and spaces are penalized instead of rewarded .",
    "sometimes one also requires that @xmath360 , which means that a mismatch should be penalized less than two spaces .",
    "it is interesting to observe that our construction in the proof of proposition  [ prop : tight_binary ] not only shows that the total number of inference functions is @xmath326 , but also that the number of biologically meaningful ones is still @xmath326 .",
    "this is because the different rays created in our construction have a biologically meaningful direction in the parameter space .",
    "an interpretation of theorem  [ th : fif ] is that the ability to change the values of the parameters of a graphical model does not give as much freedom as it may appear .",
    "there is a very large number of possible ways to assign an explanation to each observation .",
    "however , only a tiny proportion of these come from a consistent method for choosing the most probable explanation for a certain choice of parameters . even though the parameters can vary continuously",
    ", the number of different inference functions that can be obtained is at most polynomial in the number of edges of the model , assuming that the number of parameters is fixed .    in the case of sequence alignment",
    ", the number of possible functions that associate an alignment to each pair of sequences of length @xmath37 is doubly - exponential in @xmath37 .",
    "however , the number of functions that pick the alignment with highest score in the @xmath156-parameter model , for some choice of the parameters @xmath298 and @xmath299 , is only @xmath314 .",
    "thus , most ways of assigning alignments to pairs of sequences do not correspond to any consistent choice of parameters .",
    "if we use a model with more parameters , say @xmath5 , the number of inference functions may be larger , but still polynomial in @xmath37 , namely @xmath129 .",
    "having shown that the number of inference functions of a graphical model is polynomial in the size of the model , an interesting next step would be to find an efficient way to precompute all the inference functions for given models .",
    "this would allow us to give the answer ( the explanation ) to a query ( an observation ) very quickly .",
    "it follows from this chapter that it is computationally feasible to precompute the polytope @xmath142 , whose vertices correspond to the inference functions",
    ". however , the difficulty arises when we try to describe a particular inference function efficiently .",
    "the problem is that the characterization of an inference function involves an exponential number of observations .",
    "the authors are grateful to graham denham , lior pachter , carl pomerance , bernd sturmfels , and ravi kannan for helpful discussions .",
    "the first author was partially supported by the j. william fulbright association of spanish fulbright alumni ."
  ],
  "abstract_text": [
    "<S> directed and undirected graphical models , also called bayesian networks and markov random fields , respectively , are important statistical tools in a wide variety of fields , ranging from computational biology to probabilistic artificial intelligence . </S>",
    "<S> we give an upper bound on the number of inference functions of any graphical model . </S>",
    "<S> this bound is polynomial on the size of the model , for a fixed number of parameters , thus improving the exponential upper bound given by pachter and sturmfels  @xcite . </S>",
    "<S> we also show that our bound is tight up to a constant factor , by constructing a family of hidden markov models whose number of inference functions agrees asymptotically with the upper bound . </S>",
    "<S> finally , we apply this bound to a model for sequence alignment that is used in computational biology .    </S>",
    "<S> keywords : graphical models , hidden markov models , inference functions , polytopes , sequence alignment . </S>"
  ]
}