{
  "article_text": [
    "detection of temporal firing patterns among groups of neurons is an important task in neuroscience as such patterns may be indicative of functional cell assemblies or microcircuits present in the underlying neural tissue @xcite .",
    "analysis methods such as the two - tape algorithm of abeles and gerstein @xcite have been developed to discover repeating occurrences of precise firing sequences in simultaneous recordings from multiple neurons .",
    "the two - tape algorithm has been used to assess precisely timed activity patterns _ in vivo _",
    "@xcite , in slices _ in vitro _",
    "@xcite , and recently in cultures of dissociated cortical neurons @xcite .",
    "the two - tape algorithm , as well as alternative methods for identifying spike coincidences such as the unitary event detection algorithm of grun @xcite , determines statistical significance of the discovered patterns under a null hypothesis of independence among the neurons @xcite . in this paper , we present a significance test that allows `` weak interactions '' to be included in the null hypothesis by characterizing the strength of influence among neurons in terms of a conditional probability , which is a very natural way to think about synaptic interactions between neurons ) .",
    "let us write a 3-neuron pattern as @xmath0 , denoting a firing sequence where @xmath1 is followed by @xmath2 after a delay of @xmath3 and @xmath2 is followed by @xmath4 after a delay of @xmath5 .",
    "most methods count the occurrences of this pattern by essentially finding correlations among time shifted spike trains from @xmath1 , @xmath2 , and @xmath4 .",
    "there are also many methods to determine the statistical significance of these patterns based on how many times they occur ( see @xcite and references therein ) .",
    "to assess whether a given number of repetitions of the pattern is significant , one generally employs a null hypothesis that assumes that all neurons spike as ( possibly inhomogeneous ) poisson processes and that different neurons are independent .",
    "based on this one can analytically calculate a bound on the number of repetitions required to make a pattern significant in the sense of being able to reject the null hypothesis at a given level of confidence .",
    "there are also methods to assess significance through empirical means @xcite . in these methods ,",
    "one generates many surrogate data streams of spike trains by systematically perturbing the spikes in the original data and then assesses significance of a pattern by noting the difference in counts ( or in any other statistic derived from such correlation counts ) for these patterns in the original data and in the surrogate streams . in these `` jitter '' methods , often the implicit null hypothesis is also independence .",
    "when a sequential firing pattern like @xmath0 is declared as significant by any of these methods , the underlying idea is that we can conclude that @xmath1 , @xmath2 , and @xmath4 influence each other in a sequential fashion because we are able to reject the null hypothesis of independence .",
    "however , these methods do not say anything about the `` strength of influence '' among neurons @xmath1 , @xmath2 , and @xmath4 .",
    "we present a method for analyzing statistical significance of sequential firing patterns that also allows rank ordering of significant patterns in terms of the strength of influence among participating neurons .",
    "thus our method extends the currently available techniques of significance analysis .",
    "we represent the strength of influence of @xmath1 on @xmath2 by the conditional probability that @xmath2 would fire after the delay @xmath3 given that @xmath1 has fired now , which we denote as @xmath6",
    ". our null hypothesis is then stated in terms of a bound on all such pairwise conditional probabilities and we develop a statistical significance test for rejecting the null hypothesis . by changing the parameter of the null hypothesis ( which is the bound on the conditional probability ) , we are able to see which patterns are significant at different levels of strength of influence .",
    "another interesting consequence of our approach is that since the null hypothesis is stated in terms of bounds on pairwise conditional probabilities , our null hypothesis includes not only all models of independent neurons but also some models of dependent or interacting neurons .",
    "this is more general than what is available in current methods . intuitively , declaring a pattern like @xmath0 as significant should mean that we can conclude that there are `` strong '' causative connections from @xmath1 to @xmath2 and from @xmath2 to @xmath4 with the indicated delays . hence rejecting a null hypothesis that includes not only independent neuron models but also models of neurons that are `` weakly '' dependent is more appropriate .",
    "our method specifies these `` weak interactions '' in terms of bounds on conditional probabilities .",
    "the rest of the paper is organized as follows . in section  [ sec : meth ] we present our significance test .",
    "we first explain our composite null hypothesis and then develop a test of significance . in section",
    "[ sec : results ] we demonstrate the effectiveness of the method through computer simulations . spike trains are generated by a network of neurons modeled as interdependent inhomogeneous poisson processes . we show that our method rank orders significant patterns .",
    "surprisingly , it is also quite effective in situations where some of the assumptions of our theoretical analysis are not valid .",
    "we conclude the paper in section  [ sec : diss ] with potential extensions and a discussion of strengths and weaknesses .",
    "* correlation count *    for simplicity of exposition , we first explain the method for a sequential firing pattern of only two neurons .",
    "consider a pattern @xmath7 .",
    "suppose we find the number of repetitions of this pattern in the data using simple correlation as follows .",
    "let @xmath8 denote all time instants at which there is a spike from any neuron in the data .",
    "let @xmath9 where for any neuron @xmath10 , @xmath11 if there is a spike from @xmath10 at time @xmath12 and zero otherwise .",
    "note that @xmath13 is simply a correlation integral which counts the number of spikes from @xmath1 that are followed by @xmath2 with a delay of exactly @xmath14 units , and hence counts the number of repetitions of our pattern .",
    "if we want to allow for some small random variations in the delay we can define the indicator variable @xmath15 to take value 1 if there is a spike in a time interval of length @xmath16 centered around @xmath12 .",
    "( for example , we can take @xmath16 to be the time resolution in our measurements ) . from now on we assume that delays are always over some such small intervals .",
    "there are many methods to calculate correlation counts , for example the two - tape algorithm of gerstein and abeles @xcite and some of its recent variations @xcite .",
    "most current methods for detecting serial firing patterns rely on such correlations . since the focus of this paper is on statistical significance ( and not on computational efficiency )",
    ", we simply assume that one can calculate such counts for pairs of neurons and for various delays @xmath14 of interest .",
    "the question then , is `` how large should the count be to conclude that the pattern represents a `` strong '' influence of @xmath1 on @xmath2 ? ''",
    "since we want to address this question in a classical hypothesis testing framework , we need to choose a null hypothesis that includes as many models as possible of interdependent neurons without any `` strong '' influences between pairs of neurons .",
    "then , if we can calculate ( or bound ) the probability under the null hypothesis that @xmath13 is above a threshold , we get a test of statistical significance .",
    "as stated earlier , we want the null hypothesis to contain a parameter to denote the strength of influence so that we can rank order all significant patterns .",
    "* strength of influence as conditional probability *    we propose that the strength of influence between any pair of neurons can be characterized in terms of a conditional probability .",
    "let @xmath17 denote the conditional probability that @xmath2 will fire at time @xmath14 ( or more precisely , in a time interval @xmath18 $ ] ) given that @xmath1 has fired at time zero .",
    "if , for example , there is a strong excitatory connection from @xmath1 to @xmath2 , this probability would be large .",
    "if , on the other hand , @xmath1 and @xmath2 are independent then @xmath17 would be the same as the unconditional probability of @xmath2 firing in an interval of length @xmath16 .",
    "( for example , if we take that @xmath19 and the average firing rate of @xmath2 is @xmath20 , then this unconditional probability would be about 0.02 ) .",
    "we note here that this conditional probability is well defined even if the two neurons are not directly connected through a single synapse .",
    "if the pair is directly connected , then @xmath14 can be a typical mono - synaptic delay ; otherwise @xmath14 can be a multiple of the mono - synaptic delay . in either case ,",
    "our task is to find whether a pattern with a specific value for @xmath14 is significant .",
    "this conditional probability is a good scale on which to say whether the influence of @xmath1 on @xmath2 is `` strong '' .",
    "our main assumption here is that this conditional probability is not time dependent .",
    "that is , the probability that @xmath2 fires in an interval @xmath21 $ ] given that @xmath1 has fired at @xmath12 is the same for all @xmath12 for the time period of observations that we are analyzing .",
    "some recent analysis of spike trains from neural cultures @xcite suggests that such an assumption is justified . note that this assumption does not require the firing rates of neurons to not be time - varying . as a matter of fact ,",
    "one of the main mechanisms by which this conditional probability is realized is by having a spike from @xmath1 affect the rate of firing by @xmath2 for a short duration of time .",
    "thus , the neurons would have time - varying firing rates even when the conditional probability is not time - varying .",
    "our assumption is only that every time @xmath1 spikes , it has the same chance of eliciting a spike from @xmath2 after a delay of @xmath14 , i.e. there are no appreciable changes in synaptic efficacies during the period in which the data is gathered .    when analyzing the significance of repeating serial patterns , what we are interested in is hypothesizing causative chains .",
    "hence the strength of a pattern should be related to the propensity that a spike from @xmath1 has on eliciting a spike from @xmath2 , which can be conveniently represented by the conditional probability of @xmath2 spiking given that @xmath1 has spiked . in all serial firing patterns of interest ,",
    "the constancy of delays in multiple repititions are important .",
    "hence we defined the conditional probability with respect to a specified delay .",
    "capturing influences among neurons through this conditional probability allows us to formulate an interesting compound null hypothesis in terms of a bound on these probabilities .",
    "* compound null hypothesis *    now we propose the following _ compound _ null hypothesis . any model of interacting neurons",
    "is in our null hypothesis if it satisfies : @xmath22 for all neurons @xmath23 and a set of specified delays @xmath14 , where @xmath24 is a user - chosen constant .",
    "the exact mechanism by which a spike output by @xmath1 affects the spiking of @xmath2 is immaterial here . whatever be the mechanism ,",
    "if the resulting conditional probability is less than @xmath24 then that model would be included .",
    "thus our compound null hypothesis includes many models of interdependent neurons where whether or not a neuron spikes can depend on actual spikes of other neurons ( unless we choose @xmath24 to be very small ) .",
    "the idea is that we choose an @xmath24 based on how strong we want the influences to be before we agree to say there is a causative influence of @xmath1 on @xmath2 .",
    "for example , as given earlier , with @xmath19 , and an average rate of firing of @xmath20 , the conditional probability is 0.02 if the neurons are independent .",
    "so , if we choose @xmath25 , it means that we agree to call an influence strong if the conditional probability is twenty times what you would see if the neurons were independent .",
    "more importantly , if we have a test of significance for this null hypothesis , then by varying @xmath24 we can rank order different significant patterns in terms of the strength of influence .    * significance test *    to get a test for statistical significance we need to calculate a bound on the probability that",
    ", under this null hypothesis , the count @xmath13 is above a given threshold . for this , consider the following stochastic model .",
    "suppose @xmath26 is the total time duration of the data and let the random variable @xmath27 denote the total number of spikes by neuron @xmath1 during this time .",
    "define @xmath28 where @xmath29 are independent and identically distributed 0 - 1 random variables with @xmath30 = p \\ \\ \\ ( = 1 - \\mbox{prob}[x_i=0 ] ) .",
    "\\label{eq : xis}\\ ] ] if we take @xmath31 , it is easy to see that @xmath32 is a random variable equivalent to @xmath13 since every time there is a spike from @xmath1 , with probability @xmath33 a spike from @xmath2 would follow with the appropriate delay .",
    "also , per our assumption , every time @xmath1 spikes a spike from @xmath2 with the appropriate delay occurs with the same probability regardless of @xmath2 s spike history .",
    "this implies that the @xmath29 in the definition of @xmath32 can be assumed to be _ independent and identically distributed_.    now we assume that the spiking of @xmath1 is poisson .",
    "( note that we are _ not _ assuming that spiking by @xmath2 is poisson and , more importantly , as per our null model the spiking process of @xmath2 is not independent of that of @xmath1 . )",
    "is poisson , the spiking of @xmath2 would not be poisson if there is sufficient influence of @xmath1 on @xmath2 .",
    "also , in section [ sec : results ] we show empirically that our hypothesis testing method is effective even in cases when @xmath1 is not poisson . ]",
    "then the random variable @xmath32 is such that we are accumulating a random variable @xmath29 every time an event of a poisson process happens .",
    "this implies that , since the @xmath29 are 0 - 1 random variables , @xmath32 is also a poisson random variable ( * ? ? ?",
    "* ch.2.5 ) . and",
    "suppose that we classify each spike as type - y with probability @xmath33 and as type - n with probability @xmath34 .",
    "then it can be shown that the sequence of type - y spikes ( and also the type - n spikes ) would constitute a poisson process . here",
    ", the classification of each @xmath1 spike is dependent on whether or not there is a spike from @xmath2 after the appropriate delay and is independent of everything else . ]",
    "the mean and variance of @xmath32 are given by ( * ? ? ?",
    "* ch.2.5 ) @xmath35 \\ : e[x_i ] \\nonumber \\\\ \\mbox{var}(s_{ab } ) & = & e[n_a(l ) ] e[x_i^2 ] \\end{aligned}\\ ] ] let the rate of the poisson process for @xmath1 be @xmath36 .",
    "then , @xmath37 = l \\lambda_a$ ] . since , @xmath38 = e[x_i^2 ] = p$ ] , @xmath32 is a poisson random variable with expectation ( and variance ) @xmath39 .",
    "* computing the threshold *    let @xmath40 be a poisson random variable with mean @xmath41 .",
    "suppose the allowed type  i error in our hypothesis test is @xmath42 .",
    "let @xmath43 be the smallest number satisfying @xmath44 \\leq \\alpha .",
    "\\label{eq : test}\\ ] ] given @xmath42 and @xmath41 , we can calculate the @xmath43 needed to satisfy the above using the poisson distribution . for a poisson random variable , the probability on the lhs of eq .",
    "( [ eq : test ] ) is monotonically increasing with @xmath41 as long as @xmath45 .",
    "we know that @xmath32 is poisson with mean @xmath46 .",
    "under our null hypothesis , we have @xmath47 . hence , if we take @xmath48 and calculate the @xmath43 needed to satisfy eq .",
    "( [ eq : test ] ) , then we have , under our null hypothesis , @xmath49 \\leq \\alpha .",
    "\\label{eq : test - fn}\\ ] ] since , as discussed earlier , the random variable @xmath32 represents the count @xmath13 , the above @xmath43 is the threshold on the count to reject our null hypothesis and hence conclude that the pattern found is significant .",
    "the test of statistical significance is as follows .",
    "_ let @xmath24 be the bound on conditional probability that we chose for our null hypothesis .",
    "let @xmath42 be the allowed type  i error .",
    "let @xmath36 be the rate of firing for the first neuron in the pattern .",
    "set @xmath48 .",
    "using the cumulative distribution of a poisson random variable with parameter @xmath41 , we calculate the @xmath43 needed to satisfy eq .",
    "( [ eq : test ] ) .",
    "this @xmath43 is the threshold on the count of the pattern for us to be able to reject the null hypothesis and declare the pattern to be significant .",
    "_    to calculate this threshold , we need @xmath36 .",
    "this is easily estimated from the data as the average rate of firing for neuron @xmath1 .",
    "a simple parametric study shows that the threshold @xmath43 is well - behaved ( see fig .",
    "[ fig : thresh ] ) .    ) for @xmath50=2,3,4,5 and 6-neuron patterns with @xmath42=0.01 . _ a : _ threshold as a function of pattern strength for @xmath51 and @xmath52 . _",
    "b : _ threshold as a function of firing rate for @xmath53 and @xmath52 .",
    "_ c : _ threshold as a function of data length for @xmath51 and @xmath54 .",
    "we can see that the threshold is a smooth function of all parameters .",
    "the shape of the threshold curves are similar for other values of type  i error . ]    * extending to longer patterns *    here we explain how the signficance test can be extended to patterns involving more than two neurons .",
    "suppose we are considering the pattern @xmath0 .",
    "we assume we get the count of @xmath55 by taking 3-point correlations .-",
    "point correlations like this for all possible @xmath50-tuples of patterns is computationally expensive .",
    "for this reason , such correlation counts are obtained only for patterns of length 3 or 4 in most cases .",
    "here we are only explaining how our test can be extended to assess significance of longer patterns provided we can get such correlation counts . ] as before we define @xmath56 as a sum of 0 - 1 random variables @xmath29 .",
    "now , we want @xmath29 to be 1 if the spike by @xmath1 is first followed by @xmath2 and then by @xmath4 with the indicated delays .",
    "hence we take @xmath33 to be @xmath57 .",
    "is correct if all influence of @xmath1 on @xmath4 comes only through @xmath2 .",
    "this is a reasonable assumption if we want significant patterns to represent a chain of triggering events .",
    "in such a case , @xmath56 would be same as @xmath55 .",
    "even if there are other paths for @xmath1 to influence @xmath4 , this value of @xmath33 would represent a lower bound on the probability of the pattern occurring at any spike from @xmath1 .",
    "hence , with this @xmath33 , @xmath56 would be less than @xmath55 and hence the threshold on the count calculated using this @xmath56 would be sufficient in a hypothesis testing framework .",
    "] under the null hypothesis , each of these conditional probabilities are less than @xmath24 . hence ,",
    "if we calculate the @xmath43 as needed in eq .",
    "( [ eq : test ] ) with @xmath58 , then we get the needed threshold on the counts for this pattern .",
    "now the method can easily be generalized to a pattern involving @xmath50 neurons .",
    "let the first neuron in the pattern be @xmath1 .",
    "then we calculate the threshold @xmath43 needed using eq .",
    "( [ eq : test ] ) with @xmath59 .",
    "the main point of the above analysis is that if the first neuron in a chain is poisson then the counts of the pattern would be poisson even if the other neurons in the chain are not poisson . as a matter of fact ,",
    "when the relevant conditional probabilities are high , the other neurons would not be poisson .",
    "it was observed earlier @xcite that the correlation counts can be assumed to be poisson even when the neurons have time - varying rates and hence are not strictly poisson ( but may be inhomogenous poisson ) .",
    "the analysis presented here can be viewed as a theoretical justification for this observation .",
    "* spike train simulator *    in this section , we present results from computer simulations to demonstrate the effectiveness of our method .",
    "we used a simulator for generating spike data from a network of 25 interconnected neurons labeled @xmath1 through @xmath60 as shown in fig .",
    "[ fig : network ] .",
    "there were four chains , each four neurons in length , with strong connections in the network ( g - m - r - d , i - s - c - e , w - o - l - v , and p - a - t - k ) .",
    "the spiking of each neuron was an inhomogeneous poisson process whose background firing rate of @xmath20 was modulated at time intervals of @xmath19 based on input received from neurons to which it was connected .",
    "each synapse interconnecting neurons was characterized by a delay which was an integral multiple of @xmath16 and a strength in terms of a conditional probability . using the notation from section [ sec : meth ] ,",
    "the connections in the four chains were specified as follows ( delays in @xmath61 ) :    @xmath62    so among the four chains , the conditional probabilites ranged from 0.2 to 0.8 ( with g - m - r - d being the weakest and p - a - t - k being the strongest ) and the synaptic delays were between 2 and 5 @xmath61 .",
    "in some simulations the network also had many other interconnections in addition to the chains , where we connected each neuron to 25% of all the other neurons randomly .",
    "as stated earlier , with a @xmath20 average firing rate the unconditional probability of a neuron firing in @xmath16 is about 0.02 .",
    "hence we chose the strength ( again in terms of conditional probabilities ) of these random connections as uniformly distributed over the range @xmath63 $ ] , which is a factor of 2 on either side of the case of independence . _ note that this means that the firing rate of a neuron ( under the influence of random synapses ) varies over the range of @xmath64 to @xmath65 where @xmath66 is the nominal background firing rate_. the synaptic delays for the random connections were uniformly distributed between 2 and 5 @xmath61 .",
    "all neurons also had a refractory period of @xmath67 .",
    "further details on the simulator can be found in appendix b.    * first neuron and pattern characteristics *    we conducted simulations that verified the result derived in section [ sec : meth ] that the occurrences of a pattern are poisson - distributed when the first neuron in the pattern spikes according to a poisson process . to do this we simulated the 25-neuron network shown in fig .",
    "[ fig : network ] for 100 seconds without any random connections . since the only connections among neurons were the four chains ( g - m - r - d , i - s - c - e , w - o - l - v , p - a - t - k ) , the spiking of the first neuron in each pattern ( @xmath68 , @xmath69 , @xmath70 , @xmath71 ) should approximately follow a poisson process .",
    "( even here the spiking of the first neurons are not exactly poisson - distributed since they have a refractory period of 1 ms . however , since this refractory period is small compared to the interspike intervals when firing at @xmath20 , the deviations from the poisson firing due to the refractory period are small ) .",
    "we repeated the simulation 5,000 times obtaining the counts of @xmath70 and the counts of the pattern w - o - l - v . in fig .",
    "[ fig : charpois ] we show the histogram of these counts compared to a poisson distribution with the rate parameter set as the sample mean for each count .",
    "the variance - to - mean ratio , or the fano factor , for the count of @xmath70 is 0.97 .",
    "since the fano factor of a poisson random variable is 1 this indicated that the first neuron was approximately poisson , and indeed a @xmath72 goodness - of - fit test failed to reject a null hypothesis of poisson ( p - value>0.05 , test performed following the guidelines in @xcite ) .",
    "the theory developed in section [ sec : meth ] tells us that when the first neuron in a pattern is approximately poisson the count of the pattern will also be approximately poisson , and our empirical results confirmed this ( w - o - l - v fano factor 1.01 , @xmath72 goodness - of - fit test p - value>0.05 ) .",
    "then we repeated the simulations this time allowing random connections between all neurons with 25% connectivity .",
    "we can see in fig .",
    "[ fig : charnonpois ] that when there are random connections in the network the first neuron in the pattern ( @xmath70 ) and the pattern itself ( w - o - l - v ) are no longer approximately poisson - distributed ( fano factor 2.66 and 1.51 for @xmath70 and w - o - l - v respectively ) . the @xmath72 goodness - of - fit test rejects the null hypothesis that these counts are poisson ( @xmath70 : p - value<0.01 , w - o - l - v : p - value<0.01 ) .",
    "although the theory behind our significance thresholds assumes the first neuron spikes according to a poisson process , we will now demonstrate empirically that even when the first neuron is not poisson - distributed ( due to random connections present in the network ) we are still able to rank order the relative strength of patterns effectively using our significance thresholds .",
    "the strengths and delays in the chains are as follows ( denoted neuron 1[delay , strength]-neuron 2 ) : g[2,0.2]-m[3,0.2]-r[4,0.2]-d , i[5,0.4]-s[4,0.4]-c[3,0.4]-e , w[3,0.6]-o[5,0.6]-l[2,0.6]-v , and p[4,0.8]-a[2,0.8]-t[5,0.8]-k .",
    "all neurons in the network have a background firing rate of @xmath73 and a refractory period of @xmath67 . in simulations we update the firing rate of each neuron every @xmath19 . ]    , @xmath74 , refractory period @xmath67 , 5,000 replications .",
    "_ a : _ red curve is the poisson distribution with @xmath66 equal to the mean count of @xmath70 in the samples .",
    "the count of @xmath70 appears to be approximately poisson . _",
    "b : _ red curve is the poisson distribution with @xmath66 equal to the mean count of w - o - l - v in the samples .",
    "the count of w - o - l - v appears to be approximately poisson . ]    , @xmath52 , refractory period @xmath67 , 5,000 replications .",
    "_ a : _ red curve is the poisson distribution with @xmath66 equal to the mean count of @xmath70 in the samples .",
    "the count of @xmath70 deviates from poisson . _",
    "b : _ red curve is the poisson distribution with @xmath66 equal to the mean count of w - o - l - v in the samples .",
    "the count of w - o - l - v deviates from poisson . ]    * rank ordering of signficant patterns *    even when the pattern counts are not poisson - distributed ( as for the simulations shown in fig .",
    "[ fig : charnonpois ] ) , we are still able to rank order the relative strengths of the patterns as shown in fig . [",
    "fig : rankorder ] .",
    "we also see that the line showing the threshold count corresponding to @xmath75 is able to distinguish the counts of pattern g - m - r - d from the `` maximum '' of random 4-neuron pattern counts not involving any of the neurons in the four chains .    , 1,000 replications . _",
    "a : _ maximum random 4-neuron pattern counts ( not involving any neurons in the four chains ) ; pattern g - m - r - d counts ( strength 0.2 ) ; threshold for @xmath75 . _",
    "b : _ i - s - c - e ( strength 0.4 ) , w - o - l - v ( strength 0.6 ) , and p - a - t - k ( strength 0.8 ) pattern counts ; thresholds for @xmath76 . ]",
    "* data requirements *    to determine how much data is required to rank order we simulated the network with random connections to all neurons ( again with 25% connectivity ) for various lengths of time , and for each data length compared the counts of the patterns to the thresholds corresponding to @xmath24 values which are 0.1 greater than and 0.1 less than the known connection strength of the chain producing the pattern .",
    "we found that the amount of data needed to achieve the desired resolution depends on the chain strength .",
    "we can see from fig .",
    "[ fig : datasuff ] that for pattern g - m - r - d ( strength 0.2 ) around 60 seconds of data is sufficient , while for patterns i - s - c - e , w - o - l - v , and p - a - t - k ( strengths 0.4 , 0.6 , and 0.8 ) we need as little as 15 to 25 seconds of data .",
    "the data requirements are also dependent on firing rate , and with @xmath77 we find that 300 seconds of data is sufficient for the weakest pattern ( g - m - r - d ) .",
    "we then used this firing rate and data length to demonstrate how our techniques can enhance the significance analysis of counts obtained using the two - tape algorithm of @xcite .     and @xmath78 percentile out of 1,000 replications . ]",
    "* enhanced significance analysis of two - tape algorithm counts *    abeles and gerstein @xcite provide a formula for calculating the expected number of patterns of a particular description that will occur @xmath79 times in data of length @xmath26 if the neurons spike according to independent poisson processes . based on this formula , if we had 25 independent spike trains and 300 seconds of data we would expect to find 3.86 patterns of complexity ( length ) four that repeat at least twice ( with @xmath77 , @xmath19 , and the total time span between the spikes of the first and fourth neuron constrained to be @xmath80 or less ) . when we ran a simulation with these parameters and then mined the data with the two - tape algorithm we found six 4-neuron patterns that repeated twice or more and satisfied the temporal constraint .",
    "again following @xcite , we calculated that this is not a statistically significant excess of patterns for a poisson random variable with a mean of 3.86 ( p - value>0.05 ) .",
    "however if it had been , since it is a small number of patterns each pattern could be investigated further by the experimenter to determine which particular patterns out of the six are actually of interest . on the other hand ,",
    "if the number of patterns found is large ( and statistically significant ) it is not practical to designate all patterns of that description as candidates for further investigation . to illustrate this",
    ", we repeated the simulation but instead of having independent neurons we had chains of connected neurons as shown in fig .",
    "[ fig : network ] , as well as random connections between all neurons with 25% connectivity as described previously .",
    "this time when we mined with the two - tape algorithm we found 3,870 4-neuron patterns that repeated at least twice .",
    "here we need some additional criteria to select which of these individual patterns are most likely to be significant and the best candidates for further analysis .",
    "abeles and gerstein @xcite remarked that this selection process is very important , and called for future research to be conducted in this area to devise selection methods beyond their suggested strategy of repeating their analysis procedure for different subgroupings of the patterns ( with the hopes of finding a smaller group of patterns that is significant which can then be investigated further to find the individual patterns responsible ) .",
    "our framework of a compound null hypothesis based on conditional probabilities can be very useful as the selection criteria . by having different values for @xmath24 in the null hypothesis",
    ", we can ask what patterns are significant at what value of @xmath24 and thus rank order patterns according to their relative strength .",
    "we demonstrate this in fig .",
    "[ fig : mining4node ] as our thresholds at various @xmath24 are able to separate the three strongest patterns ( i - s - c - e , w - o - l - v , and p - a - t - k ) from the rest based on the counts obtained using the two - tape algorithm .",
    "we also see that when mining with a threshold of @xmath75 there are a considerable number of false positives ( i.e. there are other 4-neuron patterns that are more frequent than g - m - r - d , our weakest pattern ) .",
    "this is due to subpatterns ( e.g. p - a - t ) of the stronger patterns being very frequent , and as a consequence 4-neuron patterns such as p - a - t - x occur frequently even if there is no strong connection between t and x. future work will address this issue .    , @xmath81 ) with the two - tape algorithm .",
    "there were 3,870 4-neuron patterns that repeated more than twice .",
    "we plot the logarithm of how often each pattern repeated , and also plot our threshold for statistical significance of 4-neuron patterns for various @xmath24 . ]",
    "in this paper we proposed a method of assessing significance of serial firing patterns using correlation counts as the statistic .",
    "there are two attractive features of this method .",
    "first , we can rank order significant patterns in terms of their relative `` strength '' . for this",
    "we represent the strength of influence of @xmath1 on @xmath2 by the conditional probability that @xmath2 fires after a prescribed delay following @xmath1 .",
    "we state our composite null hypothesis in terms of a parameter @xmath24 which is an upper bound on all such pairwise conditional probabilities .",
    "this allows us to rank order significant patterns in terms the value of @xmath24 at which the pattern ( which has a given number of repetitions ) is no longer significant .",
    "the second interesting feature of the method follows from this structure of our composite null hypothesis .",
    "since we now include many models of interdependent neurons ( as long as all the relevant conditional probabilities are less than @xmath24 ) , rejecting such a null hypothesis is intuitively more satisfying .",
    "when we declare a pattern such as @xmath0 as significant , we can conclude that a spike by @xmath1 has a `` strong '' influence in eliciting a spike from @xmath2 with delay @xmath3 and a spike from @xmath4 after a further delay of @xmath5 . here",
    "`` strong '' would denote that the relevant conditional probability is greater than @xmath24 .",
    "thus , our idea of casting the null hypothesis in terms of a bound on conditional probabilities allows for a richer level of analysis .    * computational considerations *",
    "we have given a simple test of statistical significance for deciding whether or not to reject the null ( under a given confidence level ) based on the counts calculated through simple multi - point correlations .",
    "as said earlier , the motivation is that such correlations are what are presently used for detecting such patterns .    at this point one",
    "may wonder whether there is any need for the test of significance that we presented , given that we formulate our null hypothesis in terms of conditional probabilities .",
    "the correlations counts @xmath13 as defined here would directly lead to an estimate of the conditional probability , @xmath17 .",
    "hence , one can estimate the conditional probability and check whether it is less than @xmath24 .",
    "while it is true that we can directly get an estimate of the conditional probability , to get the required confidence intervals on the estimate , we once again need to use similar kind of assumptions as here and hence , theoretically , the testing procedure is not irrelevant .",
    "but there are other reasons why this approach is better than estimating all conditional probabilities",
    ".    first , our test will directly give the threshold needed for the count , given any pattern .",
    "thus , we need not actually obtain the true correlation count which is required if we want to estimate the conditional probability .",
    "we only need to ascertain whether a pattern occurs more than some number of times .",
    "many of the algorithms for detecting patterns use the correlations in this way and it leads to better computational efficiency .",
    "there is a second and more interesting reason why our approach could be beneficial . in general , obtaining correlation counts or ascertaining whether a pattern occurs a given number of times is computationally intensive .",
    "if we want to look for long patterns , the number of candidate patterns increases exponentially and , furthermore , the multi - point correlation is difficult to compute",
    ". however , there may be other more appealing ways to count what may be called the frequency of a pattern .",
    "the correlation count we considered here counts _ all _ occurrences of the relevant pattern .",
    "suppose we want to count only those occurrences such that the time span of one occurrence does not overlap with that of any other occurrence .",
    "let us call such occurrences _ non - overlapped _",
    "occurrences of the pattern .",
    "( this means , e.g. , if the spike sequence is @xmath82 , then we count only one occurrence rather than two ) .",
    "there are very efficient algorithms based on data mining techniques for obtaining all patterns whose counts in terms of maximum possible number of non - overlapped occurrences are above a threshold @xcite .",
    "these algorithms are also computationally efficient in discovering very long patterns involving more than ten neurons @xcite .",
    "it appears possible to extend this type of statistical significance analysis to such counts also . also , even when finding correlations , it is possible to tackle the combinatorial explosion in candidates ( when we are looking for long patterns ) by using similar data mining methods if we can put a bound on the count and decide that we are interested in only those patterns above this count .",
    "we will be addressing these issues in our future work .",
    "it is in terms of such generality that the approach presented here is interesting .",
    "* strengths and weaknesses of the method *    the strength of the approach is that we can accommodate dependence between neurons and conclude that some pattern is significant only if it represents strong influences among the set of neurons . since this strength of influence is controlled by a parameter in the null hypothesis , we can rank order different significant patterns by varying this parameter .    however , the weakness of the specific test proposed here is that we need to assume that the first neuron in the chain is poisson .",
    "the assumption was needed to conclude that the pattern counts would be poisson . in",
    "most of the currently available methods , one also assumes poisson processes in the null hypothesis .",
    "in general , if the variations in the rate of firing of a neuron are small ( which would be the case if all synapses into the neuron are very weak ) then the poisson assumption is likely to be a good approximation .",
    "thus , the assumption is not restrictive if we know that some neuron is necessarily the first in a chain .",
    "however , it is not always possible to have such knowledge . in spite of the assumption of poissonness of the first neuron",
    ", we feel that the approach presented here is interesting and useful .",
    "* summary *    in this paper we suggested an analytical method to assess the statistical significance of sequential firing patterns with constant delays between successive neurons .",
    "the main methods of detecting such patterns depend on multi - point correlations .",
    "our method can be used to find thresholds on such correlation counts for deciding on the significance of the patterns .",
    "our main motivation is to have a method that can rank order significant patterns in terms of the strength of influence among the neurons constituting the pattern . for this",
    "we suggested that the influence of @xmath1 on @xmath2 can be denoted in terms of the conditional probability of @xmath2 firing after a prescribed delay given that @xmath1 has fired .",
    "our compound null hypothesis is then stated in terms of an upper bound on all such pairwise conditional probabilities .",
    "this upper bound is a parameter of the null hypothesis and by varying it we can compare different significant patterns in terms of the strength they represent .",
    "this feature is very novel in relation to the current methods of significance analysis .",
    "another important consequence of our approach is that the null hypothesis now admits many models of interdependent neurons also in addition to the usual case of independence .",
    "hence our approach to significance analysis is more general .    through extensive simulation experiments we demonstrated the effectiveness of the method .",
    "the method is seen to work well and is seen to be able to rank order different patterns in terms of their strengths even when our assumption in the theoretical analysis , namely that the first neuron in the chain is poisson , is not valid .",
    "the method presented can assess significance of sequential firing patterns only when the underlying influences are excitatory .",
    "this is because the significance test is stated in terms of a lower bound on the correlation count . using a similar null hypothesis where we assume that the conditional probability is much smaller than the case under independence",
    ", it may be possible to find how low the correlation count should be for us to conclude that there are significant inhibitory influences .",
    "this needs further investigation .    as we have pointed out there are some weaknesses in the approach .",
    "one is the assumption that the first neuron in the sequence is poisson .",
    "the other is the computational problems involved in finding correlation counts when one wants to detect interactions among a large group of neurons .",
    "there are some efficient algorithms based on data mining techniques which find somewhat different counts but are computationally very efficient for discovering patterns involving large numbers of neurons @xcite .",
    "we will be addressing the issue of extending the analysis presented here to such counts in our future work .",
    "[ cols=\"^,^\",options=\"header \" , ]     [ tab : tab1 ]",
    "* simulation model *    here we describe the simulator used for generating spike data from a network of interconnected neurons .",
    "the spiking of each neuron is an inhomogeneous poisson process whose rate of firing is updated at time intervals of @xmath16 .",
    "the neurons are interconnected by synapses and each synapse is characterized by a delay ( which is in integral multiples of @xmath16 ) and a weight which is a real number .",
    "all neurons also have a refractory period .",
    "the rate of the poisson process is varied with time as follows : @xmath83 where @xmath84 is the firing rate of @xmath85 neuron at time @xmath86 , and @xmath87 are two parameters .",
    "@xmath88 is the total input into @xmath85 neuron at time @xmath86 and it is given by @xmath89 where @xmath90 is the output of @xmath91 neuron ( as seen by the @xmath85 neuron ) at time @xmath86 and @xmath92 is the weight of synapse from @xmath91 to @xmath85 neuron .",
    "@xmath90 is taken to be the number of spikes by the @xmath91 neuron in the time interval @xmath93 $ ] where @xmath94 represents the synaptic delay ( in units of @xmath16 ) for the synapse from @xmath95 to @xmath96 .",
    "we build the network in the following manner . the parameter @xmath97 is chosen based on the dynamic range of firing rates that we need to span . the parameter @xmath98 is determined by specifying the background spiking rate .",
    "this is the firing rate of the neuron under zero input .",
    "( we normally keep the same background firing rate for all neurons ) . specifying this rate fixes @xmath98 by using ( [ eq : lambda - update ] ) .",
    "the network has many random interconnections with low weight values and a few strong interconnections with large weight values . for the random connections we connect each neuron to some percentage of all the other neurons randomly .",
    "the weight values for these random connections are uniformly distributed over a suitable range .",
    "we specify all weights in terms of the conditional probabilities they represent . given a conditional probability , we first calculate the needed instantaneous firing rate so that probability of at least one spike in the @xmath16 interval is equal to the specified conditional probability . then using ( [ eq : lambda - update ] ) and ( [ eq : input ] ) we calculate the value of @xmath92 needed so that the receiving neuron ( @xmath96 ) reaches this instantaneous rate given that the sending neuron ( @xmath95 ) spikes once in the appropriate interval and assuming that input into the receiving neurons from all other neurons is zero . in our simulations , we specify the range of random weight values as well as the values of strong weights in terms of the equivalent conditional probabilities .    we then generate a spike train by simulating all the inhomogeneous poisson processes where rates are updated every @xmath16 time instants .",
    "we also have a fixed refractory period for all neurons , so that once a neuron is fired we will not let it fire until the refractory period is over .",
    "we note here that the background firing rate as well as the effective conditional probabilities in our system would have some small random variations .",
    "as said above , we fix @xmath98 so that on zero input the neuron would have the background firing rate .",
    "however , all neurons would have synapses with randomly selected other neurons and the weights of these synapses are also random . hence , even in the absence of any strong connections , the firing rates of different neurons keep fluctuating around the background rate that is specified .",
    "since we choose random weights from a zero mean distribution , in an expected sense we can assume the input into a neuron to be zero and hence the average rate of spiking would be the background rate specified .",
    "we also note that the way we calculate the effective weight for a given conditional probability is also approximate and we chose it for simplicity . if we specify a conditional probability for the connection from @xmath1 to @xmath2 , then , the method stated earlier fixes the weight of connection so that the probability of @xmath2 firing at least once in an appropriate interval given that @xmath1 has fired is equal to this conditional probability _ when all other input into @xmath2 is zero_. but since @xmath2 would be getting small random input from other neurons also , the effective conditional probability would also be fluctuating around the nominal value specified .",
    "further , even if the random weights have zero mean , the fluctuations in the conditional probability may not have zero mean due to the nonlinear sigmoidal relationship in ( [ eq : lambda - update ] ) .",
    "the nominal conditional probability value determines where we operate on this sigmoid curve and that determines the bias in the excursions in conditional probability for equal fluctuations in either directions in the random input into the neurons .",
    "we consider this as some more noise in the system and have shown through simulation that our method of significance analysis is still effective .",
    "we thank debprakash patnaik for providing his java implementation of the two - tape algorithm and dr .",
    "vijay nair for helpful discussions .",
    "j. le feber , w.  l.  c.  rutten , j.  stegenga , p.  s.  wolters , g.  j.  a.  ramakers and j. van pelt .",
    "conditional firing probabilities in cultured neuronal networks : a stable underlying structure in widely varying spontaneous activity patterns .",
    ", 4:5467 , 2007 ."
  ],
  "abstract_text": [
    "<S> repeated occurrences of serial firing sequences of a group of neurons with fixed time delays between neurons are observed in many experiments involving simultaneous recordings from multiple neurons . </S>",
    "<S> such temporal patterns are potentially indicative of underlying microcircuits and it is important to know when a repeatedly occurring pattern is statistically significant . </S>",
    "<S> these sequences are typically identified through correlation counts , such as in the two - tape algorithm of abeles and gerstein @xcite . in this paper </S>",
    "<S> we present a method for deciding on the significance of such correlations by characterizing the influence of one neuron on another in terms of conditional probabilities and specifying our null hypothesis in terms of a bound on the conditional probabilities . </S>",
    "<S> this method of testing significance of correlation counts is more general than the currently available methods since under our null hypothesis we do not assume that the spiking processes of different neurons are independent . </S>",
    "<S> the structure of our null hypothesis also allows us to rank order the detected patterns in terms of the strength of interaction among the neurons constituting the pattern . </S>",
    "<S> we demonstrate our method of assessing significance on simulated spike trains involving inhomogeneous poisson processes with strong interactions , where the correlation counts are obtained using the two - tape algorithm @xcite . </S>"
  ]
}