{
  "article_text": [
    "let @xmath1 and @xmath2 be @xmath3-dimensional random vectors with discrete or continuous distributions @xmath4 and @xmath5 , respectively . in information theory and statistics , there are various generalizations of shannon entropy ( see shannon , 1948 ) , characterizing uncertainty in @xmath4 and @xmath5 , for example , the rnyi entropy ( rnyi , 1961 , 1970 ) , @xmath6and the ( differentiable ) variability for approximate record matching in random databases @xmath7where @xmath8 , are densities of @xmath4 and @xmath5 , respectively ( see seleznjev and thalheim , 2003 , 2008 )",
    ". henceforth we use @xmath9 to denote the natural logarithm of @xmath10 . more generally , for non - negative integers @xmath11 and @xmath12",
    ", we consider _ rnyi entropy functionals _",
    "@xmath13and for the discrete case , @xmath14 and @xmath15 , @xmath16i.e .",
    ", @xmath17 .",
    "then , for example , the rnyi entropy @xmath18 and the variability @xmath19",
    ". let @xmath20 and @xmath21 be mutually independent samples of independent and identically distributed ( i.i.d.)observations from @xmath4 and @xmath5 , respectively .",
    "we consider the problem of estimating the entropy - type functionals @xmath22 and related characteristics for @xmath4 and @xmath5 from the samples @xmath20 and @xmath21 .",
    "various entropy applications in statistics ( e.g. , classification and distribution identification problems ) and in computer science and bioinformatics ( e.g. , average case analysis for random databases , approximate pattern and image matching ) are investigated in , e.g. , kapur ( 1989 ) , kapur and kesavan ( 1992 ) , leonenko et al .",
    "( 2008 ) , szpankowski ( 2001 ) , seleznjev and thalheim ( 2003 , 2008 ) , thalheim ( 2000 ) , baryshnikov et al .",
    "( 2009 ) , and leonenko and seleznjev ( 2010 ) .",
    "some average case analysis problems for random databases with entropy characteristics are investigated also in demetrovics et al .",
    "( 1995 , 1998a , 1998b ) .    in our paper",
    ", we generalize the results and approach proposed in leonenko and seleznjev ( 2010 ) , where the quadratic rnyi entropy estimation is studied for one sample .",
    "we consider properties ( consistency and asymptotic normality ) of kernel - type estimators based on the number of coincident ( or @xmath23-close ) observations in @xmath3-dimensional samples for more general class of entropy - type functionals .",
    "these results can be used , e.g. , in evaluating of asymptotical confidence intervals for the corresponding rnyi entropy functionals .",
    "note that our estimators of entropy - type functionals are different form those considered by kozachenko and leonenko ( 1987 ) , tsybakov and van der meulen ( 1996 ) , leonenko et al .",
    "( 2008 ) , and baryshnikov et al .",
    "( 2009 ) ( see leonenko and seleznjev , 2010 , for a discussion ) .",
    "first we introduce some notation . throughout the paper ,",
    "let @xmath1 and @xmath2 be independent random vectors in @xmath24 with distributions @xmath4 and @xmath5 , respectively .",
    "for the discrete case , @xmath14 and @xmath15 . in the continuous case ,",
    "let the distributions be with densities @xmath25 and @xmath26 , respectively .",
    "let @xmath27 denote the euclidean distance in @xmath24 and @xmath28 an @xmath29-ball in @xmath24 with center at @xmath10 , radius @xmath29 , and volume @xmath30 , @xmath31 .",
    "denote by @xmath32 the @xmath29-ball probability @xmath33we write @xmath34 for the indicator of an event @xmath35 , and @xmath36 for the cardinality of a finite set @xmath37 .",
    "next we define the following estimators of @xmath38 when @xmath39 and @xmath40 are non - negative integers .",
    "let the i.i.d .",
    "samples @xmath41 and @xmath42 be from @xmath43 and @xmath44 , respectively . denote @xmath45 , @xmath46 , and say that @xmath47 if @xmath48 and let @xmath49 , as @xmath47 .    for an integer @xmath50 ,",
    "denote by @xmath51 the set of all @xmath50-subsets of @xmath52 . for @xmath53 , @xmath54 , and @xmath55 ,",
    "define @xmath56 i.e. , the indicator of the event that all elements in @xmath57 and @xmath58 are @xmath23-close to @xmath59 .",
    "note that by conditioning we have @xmath60 say , the @xmath23-coincidence probability .",
    "let a generalized @xmath0-statistic for the functional @xmath61 be defined as @xmath62 where the symmetrized kernel @xmath63 and by definition , @xmath64 is an unbiased estimator of @xmath65 .",
    "define for discrete and continuous distributions @xmath66 let @xmath67 and @xmath68 denote convergence in distribution and in probability , respectively .",
    "the paper is organized as follows . in section [",
    "se : main ] , we consider estimation of rnyi entropy functionals for discrete and continuous distributions . in section [ se : app ] , we discuss some applications of the obtained estimators in average case analysis for random databases ( e.g. , for join optimization with approximate matching ) , in pattern and image matching problems , and for some distribution identification problems .",
    "several numerical experiments demonstrate the rate of convergence in the obtained asymptotic results .",
    "section [ se : proofs ] contains the proofs of the statements from the previous sections .",
    "in the discrete case , set @xmath69 , i.e. , exact coincidences are considered .",
    "then @xmath64 is an unbiased estimator of the @xmath23-coincidence probability @xmath70 let @xmath71 and @xmath72 and @xmath73 , an estimator of @xmath74",
    ". denote by @xmath75 , an estimator of @xmath76 .",
    "* remark . * instead of @xmath77 in the definition of a truncated estimator , a sequence @xmath78 @xmath79 as @xmath80 , can be used ( cf .",
    "leonenko and seleznjev , 2010 ) .",
    "the next asymptotic normality theorem for the estimator @xmath64 follows straightforwardly from the general @xmath0-statistic theory ( see , e.g. , lee , 1990 , koroljuk and borovskich , 1994 ) and the slutsky theorem .",
    "[ th : disc ] if @xmath81 , then @xmath82      in the continuous case , denote by @xmath83 an estimator of @xmath38 .",
    "let @xmath84 and @xmath85 .",
    "henceforth , assume that @xmath86 as @xmath47 .",
    "for a sequence of random variables @xmath87 , we say that @xmath88 as @xmath89 if for any @xmath90 and @xmath91 large enough there exists @xmath92 such that @xmath93 , i.e. , the family of distributions of @xmath94 , is tight , and for a numerical sequence @xmath95 , say , @xmath96 as @xmath89 if @xmath97 as @xmath89 .",
    "the following theorem describes the consistency and asymptotic normality properties of the estimator @xmath98 .",
    "[ thm : main ] let @xmath99 and @xmath100 be bounded and continuous or with a finite number of discontinuity points .",
    "@xmath101 and @xmath102 as @xmath47 , and hence if @xmath103 as @xmath47 , then @xmath98 is a consistent estimator of @xmath38 .    if @xmath104 as @xmath47 and @xmath81 , then",
    "@xmath105    in order to evaluate the functional @xmath38 , we denote by @xmath106 @xmath107 , a linear space of bounded and continuous in @xmath108 functions satisfying @xmath109-hlder condition if @xmath110 or if @xmath111 with continuous partial derivatives satisfying @xmath112-hlder condition with constant @xmath35 . furthermore , let @xmath113 and define @xmath114 .",
    "it follows from theorem [ thm : main ] and slutsky s theorem that @xmath115 is a consistent estimator of the asymptotic variance @xmath74 .",
    "denote by @xmath116 , an estimator of @xmath76 .",
    "let @xmath117 be a slowly varying function .",
    "we obtain the following asymptotic result .",
    "[ th : asbias ] let @xmath118.(i ) then the bias @xmath119.(ii ) if @xmath120 and @xmath121 , then @xmath122 ( iii ) if @xmath123 and @xmath124 and @xmath125 , then @xmath126",
    "let tables ( in a _ relational database _ ) @xmath127 and @xmath128 be matrices with @xmath129 and @xmath130 i.i.d .",
    "random tuples ( or records ) , respectively .",
    "one of basic database operations , _ join _ , combines two tables into a third one by matching values for given columns ( attributes ) .",
    "for example , the join condition can be the equality ( equi - join ) between a given pairs of attributes ( e.g. , names ) from the tables .",
    "joins are especially important for tieing together pieces of disparate information scattered throughout a database ( see , e.g. , kiefer et al .  2005 , copas and hilton , 1990 , and references therein ) .",
    "for the approximate join , we match @xmath23-close tuples , say , @xmath131 , with a specified distance , see , e.g. , seleznjev and thalheim ( 2008 ) .",
    "a set of attributes @xmath132 in a table @xmath133 is called an @xmath23-key ( test ) if there are no @xmath23-close sub - tuples @xmath134 .",
    "knowledge about the set of tests ( @xmath23-keys ) is very helpful for avoiding redundancy in identification and searching problems , characterizing the complexity of a database design for further optimization , see , e.g. , thalheim ( 2000 ) . by joining a table with itself ( self - join )",
    "we identify also @xmath23-keys and key - properties for a set of attributes for a random table ( seleznjev and thalheim , 2003 , leonenko and seleznjev , 2010 ) .",
    "the cost of join operations is usually proportional to the size of the intermediate results and so the joining order is a primary target of join - optimizers for multiple ( large ) tables , thalheim ( 2000 ) .",
    "the average case approach based on stochastic database modelling for optimization problems is proposed in seleznjev and thalheim ( 2008 ) , where for random databases , the distribution of the @xmath23-join size @xmath135 is studied . in particular , with some conditions it is shown that the average size @xmath136 that is the asymptotically optimal ( in average ) pairs of tables are amongst the tables with maximal value of the functional @xmath137 ( variability ) and the corresponding estimators of @xmath137 can be used for samples @xmath138 and @xmath139 from @xmath127 and @xmath128 , respectively . for discrete distributions , similar results from theorem th : disc for @xmath140 can be applied .",
    "image retrieval and registration fall in the general area of pattern matching problems , where the best match to a reference or query image @xmath141 is to be found in a database of secondary images @xmath142 the best match is expressed as a partial re - indexing of the database in decreasing order of similarity to the reference image using a similarity measure . in the context of image registration , the database corresponds to an infinite set of transformed versions of a secondary image , e.g. , rotation and translation , which are compared to the reference image to register the secondary one to the reference .",
    "let @xmath1 be a @xmath3-dimensional random vector and let @xmath143 and @xmath144 denote two possible densities for @xmath1 . in the sequel , @xmath1 is a feature vector constructed from the query image and a secondary image in an image database and @xmath143 and @xmath144 are densities , e.g. , for the query image features and the secondary image features , respectively , say , image densities . when the features are discrete valued the @xmath143 and @xmath144 are probability mass functions .    the basis for entropy methods of image matching is a measure of similarity between image densities .",
    "a general entropy similarity measure is the rnyi @xmath145-divergence , also called the rnyi @xmath145-relative entropy , between @xmath143 and @xmath144@xmath146when the density @xmath143 is supported on a compact domain and @xmath144 is uniform over this domain , the rnyi @xmath109-divergence reduces to the rnyi @xmath109-entropy",
    "@xmath147    another important example of statistical distance between distributions is given by the following nonsymmetric bregman distance ( see , e.g. , pardo , 2006 ) @xmath148dx , \\qquad s \\neq 1,\\ ] ] or its symmetrized version @xmath149= \\frac{1}{s-1}\\int_{r^d } [ p(x)-q(x)][p(x)^{s-1}-q(x)^{s-1}]dx.\\ ] ] for @xmath150 , we get the second order distance @xmath151 ^ 2 dx.\\ ] ] now , for an integer @xmath152 , applying theorem [ main ] and [ th : asbias ] one can obtain an asymptotically normal estimator of the rnyi @xmath152-entropy and a consistent estimator of the bregman distance .",
    "for a positive definite and symmetric matrix @xmath153 , @xmath154 , define the constants @xmath155 and @xmath156 among all densities with mean @xmath157 and covariance matrix @xmath153 , the rnyi entropy @xmath158 , @xmath159 is uniquely maximized by the density ( costa et al .",
    "2003 ) @xmath160 with support @xmath161 the distribution given by @xmath162 belongs to the class of _ student - r _ distributions .",
    "let @xmath163 be a class of @xmath3-dimensional density functions @xmath143 , @xmath164 , with positive definite covariance matrix . by the procedure described in leonenko and seleznjev ( 2010 ) , the proposed estimator of @xmath158 can be used for distribution identification problems , i.e. , to test the null hypothesis @xmath165 _ is a sample from a student - r distribution of type _ against the alternative @xmath166 _ is a sample from any other member of @xmath163_.      * example 1 .",
    "* figure [ fg : ex1 ] shows the accuracy of the estimator for the cubic rnyi entropy @xmath167 of discrete distributions in theorem [ th : disc ] , for a sample from a @xmath3-dimensional bernoulli distribution and @xmath91 observations , @xmath168 , @xmath169 with bernoulli @xmath170-i.i.d .",
    "components , @xmath171 . here",
    "the coincidence probability @xmath172 and the rnyi entropy @xmath173 .",
    "the histogram for the normalized residuals @xmath174 @xmath175 are compared to the standard normal density , @xmath176 .",
    "the corresponding qq - plot and p - values for the kolmogorov - smirnov ( 0.4948 ) and shapiro - wilk ( 0.7292 ) tests also support normality hypothesis for the obtained residuals .",
    "-dimensional distribution ; @xmath168 , @xmath170-i.i.d .",
    "components , @xmath171 , sample size @xmath177 .",
    "standard normal approximation for the empirical distribution ( histogram ) for the normalized residuals , @xmath178.,scaledwidth=85.0% ]    * example 2 .",
    "* figure [ fg : ex2 ] illustrates the performance of the approximation for the differentiable variability @xmath179 in theorem [ th : asbias ] , for two one - dimensional samples from normal distributions @xmath180 and @xmath181 , with the sample sizes @xmath182 , respectively . here the variability @xmath183 .",
    "the normalized residuals are compared to the standard normal density , @xmath184 .",
    "the qq - plot and p - values for the kolmogorov - smirnov ( 0.9916 ) and shapiro - wilk ( 0.5183 ) tests also support the normal approximation .",
    ", @xmath181 , @xmath185 .",
    "standard normal approximation for the empirical distribution ( histogram ) for the normalized residuals , @xmath186.,scaledwidth=85.0% ]    * example 3 .",
    "* figure [ fg : ex3 ] shows the accuracy of the normal approximation for the cubic rnyi entropy @xmath167 in theorem [ th : asbias ] , for a sample from a bivariate gaussian distribution with @xmath187-i.i.d .",
    "components , and @xmath188 observations . here",
    "the rnyi entropy @xmath189 .",
    "the histogram , qq - plot , and p - values for the kolmogorov - smirnov ( 0.2107 ) and shapiro - wilk ( 0.2868 ) tests allow to accept the hypothesis of standard normality for the residuals , @xmath190 .",
    "components ; sample size @xmath191 .",
    "standard normal approximation for the empirical distribution ( histogram ) for the normalized residuals , @xmath190.,scaledwidth=85.0% ]    * example 4 .",
    "* figure [ fg : ex4 ] demonstrates the behaviour of the estimator for the quadratic bregman distance @xmath192 for two exponential distributions @xmath193 , and @xmath194 , with rate parameters @xmath195 , respectively , and equal sample sizes . here the bregman distance @xmath196 .",
    "the empirical mean squared error ( mse ) based on 10000 independent simulations are calculated for different values of @xmath91 .     and @xmath197 , @xmath198 .",
    "the empirical mse obtained for the @xmath0-statistic estimator with @xmath199 , for different values of a.,width=321 ]",
    "assume that @xmath99 and @xmath100 are bounded and continuous or with a finite number of discontinuity points .",
    "let @xmath200 . then @xmath201    _ proof : _ we have @xmath202 where @xmath203 .",
    "it follows by definition that @xmath204 as @xmath205 , for all continuity points of @xmath99 and @xmath100 , and that the random variable @xmath206 is bounded .",
    "hence , the bounded convergence theorem implies @xmath207 @xmath208__proof of theorem [ thm : main ] : _ _ @xmath209 note that for @xmath210 , @xmath211 we use the conventional results from the theory of @xmath0-statistics ( see , e.g. , lee , 1990 , koroljuk and borovskich , 1994 ) . for @xmath212 and @xmath213 , define @xmath214 and @xmath215 let @xmath216 and @xmath217 have @xmath218 and @xmath219 elements in common , respectively . by properties of @xmath0-statistics , we have @xmath220 and @xmath221 from we get that @xmath222 , which is a finite linear combination of @xmath223 , where @xmath224 when @xmath225 or @xmath226 , the triangle inequality implies that @xmath227 and since @xmath228 and @xmath229 , it follows by conditioning and from lemma 1 that @xmath230 we conclude that @xmath231 now , for @xmath232 and @xmath233 we obtain @xmath234 for some constant @xmath235 .",
    "hence , from , , , and we get that @xmath236 as @xmath47 .",
    "moreover , it follows from lemma 1 that @xmath237 as @xmath238 , so when @xmath103 , then @xmath239 and the assertion follows . _",
    "( ii ) _ let @xmath240 the h - decomposition of @xmath98 is given by @xmath241 where @xmath242 the terms in are uncorrelated , and since @xmath243 and @xmath244 , we obtain from that @xmath245 where @xmath246 , and @xmath247 note that @xmath248 = @xmath249 @xmath250 so if @xmath251 , @xmath252 , then , , and imply that @xmath253 . in particular , for @xmath254 , @xmath255 by symmetry , we have from @xmath256 let @xmath10 be a continuity point of @xmath99 and @xmath100 . then , changing variables @xmath257 and the bounded convergence theorem give @xmath258 from we get that @xmath259 and hence @xmath260 and similarly , @xmath261 let @xmath262 . then @xmath263 . it follows from and that @xmath264 , and hence @xmath265 , @xmath164 .",
    "similarly , we have that @xmath266 , @xmath164 . therefore , @xmath267 and @xmath268 are bounded random variables .",
    "hence , from , , and the bounded convergence theorem we obtain @xmath269 let @xmath270 , @xmath271 , and observe that , for @xmath272 , @xmath273 @xmath274 where the last equality follows from the boundedness of @xmath267 .",
    "the lindeberg - feller theorem ( see , e.g. , theorem 4.6 , durrett , 1991 ) gives that @xmath275 and similarly @xmath276 .",
    "hence , by independence we get that @xmath277 so from and slutsky s theorem , @xmath278 this completes the proof .",
    "@xmath208__proof of theorem [ th : asbias ] : _ _ the proof is similar to that of the corresponding result in leonenko and seleznjev ( 2010 ) so we give the main steps only .",
    "first we evaluate the bias term @xmath279 .",
    "let @xmath280 be an auxiliary random vector uniformly distributed in the unit ball @xmath281 , say , @xmath282 . then by definition",
    ", we have @xmath283 where @xmath284 it follows by definition that @xmath285 where @xmath286 and @xmath287 are polynomials in @xmath288 , and @xmath289 .",
    "now the boundedness of @xmath99 and @xmath100 and the hlder condition for the continuous differentiable cases imply @xmath290 , @xmath291 , by ( i ) and theorem [ main ] , we have @xmath292 now for some @xmath293 and any @xmath92 and large enough @xmath294 , we obtain @xmath295 and the assertion ( ii ) follows .",
    "similarly for @xmath296 .",
    "the third author is partly supported by the swedish research council grant 2009 - 4489 and the project `` digital zoo '' funded by the european regional development fund .",
    "the second author is partly supported of the commissions the european communities grant pirses - ga 2008 - 230804 `` marie curie actions '' .",
    "demetrovics , j. , katona , g.o.h . , mikls , d. , seleznjev , o. , thalheim , b. : the average length of keys and functional dependencies in ( random ) databases . in : proc .",
    "icdt95 eds : g.  gottlob and m.  vardi , ln in comp.sc .",
    "springer : berlin * 893 * ( 1995 ) 266279"
  ],
  "abstract_text": [
    "<S> numerous entropy - type characteristics ( functionals ) generalizing rnyi entropy are widely used in mathematical statistics , physics , information theory , and signal processing for characterizing uncertainty in probability distributions and distribution identification problems . </S>",
    "<S> we consider estimators of some entropy ( integral ) functionals for discrete and continuous distributions based on the number of epsilon - close vector records in the corresponding independent and identically distributed samples from two distributions . </S>",
    "<S> the estimators form a triangular scheme of generalized @xmath0-statistics . </S>",
    "<S> we show the asymptotic properties of these estimators ( e.g. , consistency and asymptotic normality ) . </S>",
    "<S> the results can be applied in various problems in computer science and mathematical statistics ( e.g. , approximate matching for random databases , record linkage , image matching ) .    </S>",
    "<S> = 3.5 ex    _ ams 2000 subject classification : _ </S>",
    "<S> 94a15 , 62g20    _ keywords : _ entropy estimation , rnyi entropy , @xmath0-statistics , approximate matching , asymptotic normality </S>"
  ]
}