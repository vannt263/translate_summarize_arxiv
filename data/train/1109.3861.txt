{
  "article_text": [
    "the penetration of radiation into an optically thick distribution of gas is a feature of many astrophysical systems , ranging from scales as small as those of circumstellar disks to those as large as the damped lyman-@xmath3 absorbers observed along the sightlines to many quasars .",
    "numerical modelling of the propagation of radiation through the gas can greatly aid our efforts to understand the astrophysics of these systems , but frequently proves to be computationally challenging , owing to the high dimensionality of the problem . in the common case in which we have no useful spatial symmetries to exploit and wish to solve for the properties of the radiation field within @xmath4 different frequency bins ,",
    "the computational cost of determining the full spatial and angular distribution of the radiation field is of order @xmath5 , where @xmath0 is the number of resolution elements ( e.g.  grid cells in an eulerian simulation , or particles in a smoothed particle hydrodynamics [ sph ] model ) , and where we have assumed that the desired angular resolution is comparable to the spatial resolution . for static problems , where the gas distribution is fixed and we need only to solve for the properties of the radiation field at a single point in time , it is currently possible to solve the full radiative transfer problem numerically even for relatively large values of @xmath0 ( see e.g. * ? ? ?",
    "* who post - process the results of an sph simulation with @xmath6 ) . however , if one is interested in dynamical problems , where the gas distribution is not fixed and the gas and radiation significantly influence one another , then the cost of solving for the radiation field after every single hydrodynamical timestep can easily become prohibitively large ( for a detailed discussion , see @xcite ) .",
    "for this reason , it is useful to look for simpler , more approximate techniques for treating the radiation that have a much lower computational cost , and that can therefore be used within hydrodynamical simulations without rendering these simulations overly expensive .",
    "one common simplification that nevertheless has a reasonably broad range of applicability is to ignore the re - emission of incident radiation within the gas . making this simplification means that rather than solving the full transfer equation , @xmath7 along multiple rays through the gas , where @xmath8 is the specific intensity at a frequency @xmath9 , @xmath10 and @xmath11 are the emissivity and opacity at the same frequency , and @xmath12 is the path length along the ray",
    ", one can instead solve the simpler equation , @xmath13 equation  [ full_rt ] has the formal solution @xmath14 where @xmath15 is the specific intensity of the radiation field at the start of the ray ( e.g.  at the edge of a gas cloud ) , @xmath16 is the source function , and @xmath17 is the optical depth along the ray .",
    "if @xmath18 and the optical depth is not too large , then it is reasonable to neglect the integral term , in which case we can write @xmath8 as @xmath19 which is the formal solution to equation  [ simple_rt ] . by making this approximation",
    ", we therefore reduce the problem to one of determining optical depths along a large number of rays .",
    "often , this problem can then be further reduced to one of determining the column density of some absorber ( e.g.  dust ) along each ray .",
    "unfortunately , although these simplifications make the problem easier to handle numerically , they do not go far enough , as the most obvious technique for calculating the column densities  integrating along each ray  still has a computational cost that scales as @xmath2 and hence is impractical in large simulations .",
    "this motivates one to look for computationally cheaper methods for determining the angular distribution of column densities seen by each resolution element within a large numerical simulation .    in this paper",
    ", we introduce a computationally cheap and acceptably accurate method for computing these column densities , suitable for use within simulations of self - gravitating gas that utilize a tree - based solver for calculating gravitational forces .",
    "our method , which we dub , makes use of the large amount of information on the density distribution of the gas that is already stored within the tree structure to accelerate the calculation of the required column density distributions .    in the next section ,",
    "we give a description of how our algorithm works , starting with a overview of how tree - based gravity solvers work in section [ overview ] , and then showing how it is possible to implement the  method in section [ implement ] .",
    "we then present two stringent tests of the algorithm in section [ tests ] , both of which are typical of the conditions found in contemporary simulations of star formation .",
    "we discuss some of the potential applications of the  method in section [ applications ] . in section [ performance ] , we give an overview of the computational efficiency of this scheme , and we summarise this paper in section [ summary ] .",
    "schematic diagram showing how the tree is constructed and used for the gravitational force calculation .",
    "a 3d oct - tree splits each parent node into eight daughter nodes , but in this 2d representation , we show only four of these nodes .",
    "the black lines show the boundaries of the tree nodes that would be constructed for the given ensemble of particles , shown as blue dots .",
    "the regions shaded in red denote the nodes that would be used to calculate the gravitational force as seen by the large blue and orange particle at the bottom of the diagram .",
    "note that in the case where the nodes being used contain only one particle ( a ` leaf ' node ) , the position of the particle itself is used to calculate the gravitational force arising from that node.,width=249 ]     schematic diagram illustrating the  concept . during the tree",
    "walk to obtain the gravitational forces , the projected column densities of the tree nodes ( the boxes shown on the right ) are mapped onto a spherical grid surrounding the particle for which the forces are being computed ( the `` target '' particle , shown on the left ) .",
    "the tree already stores all of the information necessary to compute the column density of each node , the position of the node in the plane of the sky of the target particle , and the angular extent of the node .",
    "this information is used to compute the column density map at the same time that the tree is being walked to calculate the gravitational forces . provided that the tree is already employed for the gravity calculation , the information required to create the @xmath20 steradian map of the column densities can be obtained for minimal computational cost . ]",
    "tree - based gravity solvers ( e.g. @xcite ) have long been a standard feature of @xmath0-body and smoothed particle hydrodynamics codes ( e.g. @xcite ) .",
    "more recently , their accuracy and speed has also seen them adopted in grid - based codes @xcite . in this paper , we describe a method whereby the information stored in the gravitational tree can be used to construct a @xmath20 steradian map of the column density . by constructing this map at the same time",
    "as the tree is being `` walked '' to determine the gravitational forces , we can minimize the amount of additional communication necessary between cpus holding different portions of the tree . since the structure of the tree , and how it is walked , will be important for our discussion",
    ", we will first give a brief overview of how a tree - based gravity solver works .",
    "for the purpose of this discussion , we consider a solver based on an oct - tree , as used in e.g.  the gadget sph code @xcite , although we note that solvers based on other tree structures , such as binary trees , do exist ( e.g.  the binary tree employed by @xcite , which later found its way into other high profile studies , such as @xcite and @xcite ) .",
    "a tree - based solver starts by constructing a tree , splitting the computational volume up into a series of nested boxes , or ` nodes ' .",
    "the ` root ' node is the largest in the hierarchy and contains all of the computational points in the simulation",
    ". this large ` parent ' node is then split up into eight smaller ` daughter ' nodes as shown in figure  [ fig : tree ] .",
    "the daughter nodes are further refined ( becoming parents themselves ) until each tree node contains only one particle ( illustrated in figure  [ fig : tree ] by the blue dots ) .",
    "these smallest nodes at the very bottom of the hierarchy are typically termed ` leaves ' . at each point in the hierarchy , the tree stores the information about the contents of the parent node ( including its position , mass and size ) that will be needed during the gravitational force calculation .",
    "once the construction of the tree is complete , each particle is located in a leaf node situated at the bottom of a nested hierarchy of other nodes .",
    "once the tree is built , it can then be `` walked '' to get the gravitational forces .",
    "the idea behind the speed - up offered by the tree gravity solver over direct summation is very simple : any region of structured mass that is far away can be well approximated as a single , unstructured object , since the distances to each point in the structure are essentially the same . strictly , this is only true if the angular size of the structure is small , and so tree - codes tend to adopt an angle , rather than a distance , for testing whether or not structures can be approximated .",
    "this angle is often referred to as the `` opening angle '' of the tree , and we will denote it hereafter as .    to walk the tree to obtain the gravitational force on a given particle ,",
    "the algorithm starts at the root node and opens it up , testing whether the daughter nodes subtend an angle of less than .",
    "if the angle is smaller than , the properties of the daughter nodes ( mass , position , centre of mass ) are used to calculate their contribution to the force . as such",
    ", any substructure within the daughter nodes is ignored , and the mass inside in the nodes is assumed to be uniformly distributed within their boundaries .",
    "if one or more of these nodes subtends an angle larger than , the nodes are opened and the process is repeated on their daughter nodes , and so on , until nodes are found that appear smaller than . to increase the accuracy of the force calculation , the nodes often store multipole moments that account for the fact that the node is not a point mass , but rather a distributed object that subtends some finite angle ( e.g. see @xcite ) .",
    "these moments are calculated during the tree construction , for all levels of the node hierarchy except the leaves , since these are either well approximated as point masses  as is the case for a stellar @xmath0-body calculation  or are sph particles , which have their own prescription for how they are distributed in space @xcite .",
    "the above method is sketched in figure [ fig : tree ] , which shows the tree structure in black , and the nodes , marked in red , that would be used to evaluate the gravitational force on the large blue particle with the orange highlight . in the cases where the nodes are leaves ( containing only a single particle ) , the position of the particle itself is used . as the total number of force calculations",
    "can be substantially decreased in comparison to the number required when using direct summation , tree - based gravity solvers offer a considerable speed - up at the cost of a small diminution in accuracy .",
    "@xcite showed that for a distribution of @xmath0 self - gravitating particles , the computational cost of a tree - based solver scales as @xmath21 , compared to the @xmath22 scaling associated with direct summation .",
    "they also showed that the multipole moments allowed quite large opening angles , with  values as large as 0.5 radians resulting in errors of less than a percent .",
    "our  method makes use of the fact that each node in the tree stores the necessary properties for constructing a column density map .",
    "the mass and size of the node can be used to calculate the column density of the node , and its position and apparent angular size allow us to determine the region on the sky that is covered by the node .",
    "note also that column density , just like the total gravitational force , is a simple sum over the contributing material , meaning that it is independent of the order in which the contributions are gathered .",
    "just as the tree allows us to construct a force for each particle , we can also sum up the column density contributions of the nodes to create a @xmath20 steradian map of the column density during the tree - walk .",
    "a schematic diagram of how this works is shown in figure [ fig : treecoldia ] . the target particle  the one currently walking the tree , and for which the map is being created  is shown as the large dark blue particle on the left . around it",
    "we show the spherical grid onto which the column densities are to be mapped .",
    "we see that the tree nodes , shown on the right , subtend some angle @xmath23 ( which is less than some adopted ) , and cover different pixels on the spherical grid . during the tree",
    "walk , the  method simply maps the projection of the nodes onto the pixels for the particle being walked .",
    "schematic showing the overlap between a pixel on the sph particle s _ healpix _ sphere , and the tree node .",
    "the angular size of the pixels and nodes are denoted by @xmath24 and @xmath25 , respectively , and the distances between their centres are given by the orthogonal angles @xmath26 and @xmath27 .",
    "the diagram shows the case when the angle subtended by the tree node is greater than that of the pixels , and the two possible situations that can arise : a ) the pixel and tree node only partially overlap , and b ) the pixel is entirely covered by the tree node . in the former case , we work out the mass in the overlapping area , and convert it to a column density contribution by smearing it over the pixel s area . in the latter case",
    ", the pixel just obtains the full column density of the node . in the case where the angle subtended by the pixels is greater than the tree node ( not shown here ) , then obviously the tree node can also become totally covered by the pixel . in this case , the full mass of the node is smeared out over the pixel s area to define the column density contribution .",
    "full details of how the mapping is done in this implementation are given in section [ implement].,width=307 ]     illustration showing how the nodes and pixels are assumed to interact in our implementation of the  algorithm .",
    "for each tree node , a new co - ordinate system is created , in which the node s position vector is the @xmath28-axis .",
    "the angular distance between the node centres , can then be described by two orthogonal angles , @xmath26 and @xmath27 , which allows us to define an overlap area @xmath29 .",
    "note that nodes and pixels have an area @xmath30 and @xmath31 respectively .",
    "full details are given in section [ implement].,width=307 ]      the details of exactly how the nodes are mapped onto the grid depends on how accurate one needs the column density information to be .",
    "however , it should be noted that the tree structure is only an approximate representation of the underlying gas structure : it distributes the mass in a somewhat larger volume than is actually the case , and as a result , sharp edges tend to be displaced to the boundary of node . as such , column densities from the tree will always be approximate , and so a highly accurate mapping of the node column density projections is computationally wasteful . in",
    "what follows , we will describe a simple implementation of  that is both reasonably accurate while at the same time requiring minimal computational cost .",
    "our mapping of the tree nodes to the pixels makes a number of assumptions regarding the shape and projection of the nodes and the pixels .",
    "these are :    * the tree nodes are always seen as squares in the sky , regardless of their actual orientation . *",
    "the nodes are assumed to overlap the pixels as shown in figure [ fig : nodepro ] , such that we can define the overlapping region based on simple orthogonal co - ordinates in the plane of the sky .",
    "* we use the _ healpix _ algorithm @xcite to compute pixels that are equidistant on the sphere s surface and that have equal areas .",
    "we show a schematic diagram of the way the nodes are assumed to overlap in figure [ fig : pixdia ] .",
    "the tree nodes are taken to be squares with side length @xmath25 and likewise , the pixels onto which the column densities mapped are assumed to be squares with side length @xmath24 . as shown in the diagram , these dimensions are assumed to be equivalent to the angles subtended by the nodes and the pixels .",
    "overlap requires that @xmath32 and @xmath33 if this is the case , the lengths , @xmath34 and @xmath35 describing the overlapping area are then given by @xmath36 and @xmath37 when the pixels have a smaller angular extent than the nodes ( i.e.  @xmath38 ) , or @xmath39 and @xmath40 when the nodes have a smaller angular extent than the pixels ( i.e.  @xmath41 ) . by taking the minimum of the expression @xmath42 and either the node or pixel side length , we account for situations such as those shown in the right - hand panel in figure  [ fig : pixdia ] , in which either the pixel is totally covered by the node , or the node is totally contained within the pixel .",
    "we can then calculate the contribution of the node to the pixel s column density from @xmath43    this expression is formed by considering the mass in the overlapping area given by @xmath44 .",
    "if the pixel is totally covered by the node , then it gets the full column density of the node .",
    "if the pixel is only partially covered by the node , then the mass in the overlapping region is smeared out over the area of the pixel , to create a new column density . if the node is totally contained within the pixel , then obviously all the mass from the node is smeared out over the pixel s area .",
    "clearly , the ability of @xmath23 and @xmath45 to describe the overlapping area breaks down near the poles , with the extreme case where a pixel directly over either of the poles can not be described by a @xmath35 . to account for this",
    ", we move to a co - ordinate system in which the tree node s position vector , @xmath46 describes a new @xmath28-axis ( @xmath47 ) , such that the node is always located at ( 1 , 0 , 0 ) . to define the other two axis ( the new @xmath48 and @xmath49 axis ) ,",
    "we first define a control vector , @xmath50 , that is close to the node s position vector , displaced by a small amount in @xmath23 and @xmath45 . for the displacement we choose ( somewhat arbitrarily ) that @xmath23 decreases by @xmath51 for @xmath52 and increases by @xmath53 for @xmath54 , and that @xmath45 always increases by @xmath53",
    "we then define the new axis vectors from : @xmath55 @xmath56 @xmath57 @xmath58 the pixel unit vectors @xmath59 are then rotated into this co - ordinate system simply by taking the scalar product with each of the axes : @xmath60 @xmath61 @xmath62 a schematic diagram of how the pixels and nodes are defined in this new coordinate system is given in figure [ fig : nodepro ] . the angular distances @xmath63 and @xmath64 can then be defined simply from : @xmath65 and , @xmath66 to increase the speed of the algorithm , these inverse trigonometric functions can be made into look - up tables .    it should be noted that after this rotation , the pixels  and even the tree node itself  are in general _ not _ aligned as they appear in figure [ fig : nodepro ] . in the above coordinate transform , the control vector @xmath50 determines how the new coordinate vectors @xmath67 and @xmath68 are orientated with respect to the new x axis , @xmath69 ( that is , how @xmath67 and @xmath68 are rotated _ around _",
    "@xmath69 ) .",
    "in fact , it should also be stressed that the _ healpix _ pixels are not aligned as in figure [ fig : nodepro ] _ before _ the rotation , but in fact appear more diamond shaped ( as one can see in the maps in figures 5 - 9 ) .",
    "we found that the exact rotation is typically unimportant for the mapping , provided the angular resolution in the map is not significantly smaller than the opening angle used during the tree - walk .",
    "we discuss this further in section [ tests ] .    in our discussion",
    "so far , we have referred only to ` nodes ' , and their properties , but it should be stressed that some of the nodes will be ` leaves ' . in our implementation , the leaves are sph particles , and as was mentioned above , it is customary to use the particle properties directly when evaluating the gravitational forces ( or in our case , the column density ) . as such",
    ", we adopt the exact particle position when considering the leaf nodes . however",
    ", although sph particles have non - uniform radial column density profiles , we do not take this into account in our  implementation , but rather treat the sph particles in the same manner as the other nodes , by assuming that they have a uniform column density , and project a square in the sky , rather than a circle . as our node to pixel mapping is based around mass conservation ( the concept behind equation [ sigmaadd ] ) , we can not simply use the smoothing length @xmath70 to define the square ( so @xmath71 in gadget  2 , or @xmath72 for the definition of @xmath70 in most other sph codes ) , but instead have to define @xmath73 to conserve area , giving , @xmath74 our motivation for treating the sph particles in this way , is that working out the true fraction of the sph particle s mass that falls within the pixels is computationally expensive , requiring a numerical integration over the overlapping areas , since the pixel and the sph particle have quite different shapes .",
    "our choice of the _ healpix _ method of pixelating the spheres around the sph particles was motivated by two main factors .",
    "first , the pixels in the _ healpix _ mapping are equal area , which simplifies any comparisons of the pixel properties between different maps .",
    "second , the equal - area property means that increasing the pixel number is equivalent to increasing the angular resolution of the map _ everywhere on the sphere_. this is not the case with the traditional latitude - longitude discretisation , for example , in which the pixels at the poles have a significantly smaller area than their counterparts at the equator .",
    "finally , for our sph code , we use the publicly available code gadget  2 @xcite , which uses an oct - tree .",
    "for this project , where we need to have control over the opening angle @xmath75 to show how it affects the results , we adopt the standard barnes and hut opening criterion @xcite rather than the ` relative error ' criterion suggested by @xcite .",
    "in this section we apply the  algorithm to two very different types of test problem . in the first case , we consider a gas cloud that is an isolated sphere , with conditions similar to the dense cores found in the pipe nebula @xcite . for the second test problem , we consider a cloud that is a model of a turbulent molecular cloud , which is representative of the environment in which prestellar cores form .",
    "these two different set - ups are typical of those used in contemporary simulations of star and cluster formation .    in what follows",
    ", we will use hammer projections to display the @xmath76 steradian maps of column densities seen from given locations within the cloud .",
    "there are four types of map that we will show .",
    "the first is the ` true ' column density map obtained by summing up the contribution from every single sph particle in the simulation . for this type of map",
    ", it is customary to take into account the radial density profile of the sph particles , as described by their smoothing kernel .",
    "however since this is not done in the  implementation we choose not to do this here for the sph maps .",
    "instead we assume that each sph particle has a constant column density defined simply by its mass , and radial extent ( that is , the particle s smoothing length ) .",
    "the second type of map is the ` pixel - averaged ' map , whereby we pixelate the ` true ' map into a set number of _ healpix _ pixels , by averaging over the points from the hammer projection that lie inside each pixel .",
    "this type of map provides a more useful measure than the ` true ' maps , as the results of  are also stored on _ healpix _ grids . as such ,  could be said to be working perfectly if it can recover the same column densities as those shown in the ` pixel - averaged ' maps .",
    "the third type of map is simply the column density map produced by .",
    "finally , our last type of map describes the error in the  method .",
    "we define a fractional error @xmath77 for each pixel @xmath78 by @xmath79 where @xmath80 is the column density of pixel @xmath78 in the ` pixel - averaged ' map , and @xmath81 is the column density in pixel @xmath78 recovered by .    in our tests , we will also explore the two intrinsic resolutions that are at play in our implementation of .",
    "the first is the number of pixels in the _ healpix _ sphere that surrounds the sph particles , which represents the ability of the sph particle to record the column density information that comes from the tree walk .",
    "the second resolution at play is the opening angle , @xmath75 , as this determines how accurately the tree is forced to look at the structure in the cloud .",
    "together these determine the accuracy and level of detail that is present in the  map .",
    "the column density hammer projections for a particle sitting on the edge of a centrally condensed sphere .",
    "the upper left panel shows the column density projection from all sph particles in the simulation volume .",
    "the other panels then show the same @xmath20 steradian map pixelated into 48 , 192 , and 768 _ healpix _ pixels .",
    "the pixel values are simply averages of hammer projection points that lie inside each pixel s boundary.,width=326 ]     the maps recovered by our  implementation , for the column density distribution shown in figure  [ spheretrue ] .",
    "the maps are shown for two different measures of the resolution : the opening angle , @xmath75 , of the tree ( a measure of how well  can ` see ' the cloud ) , and the number of pixels in the healpix map ( a measure of how accurately s results are stored).,width=326 ]      in the first test problem , we consider a particle located at the edge of a spherical , isothermal cloud with a mean mass density of @xmath82 g@xmath83 , a temperature of 10  k and a mass of 1.33 .",
    "the cloud is modelled with 10,000 sph particles , and hence the mass resolution is comparable to that used in contemporary models of cluster formation ( e.g. @xcite ) .",
    "the cloud is gravitationally unbound , but confined by an external pressure of @xmath84 and has been allowed to settle into hydrostatic equilibrium .",
    "it centrally condenses into a stable bonnor - ebert sphere @xcite with a central density of @xmath85 g@xmath83 and an outer density of @xmath86 g@xmath83 at a radius of 0.09 pc .",
    "the column density map of the sky , as seen by the particle at the edge , is shown in hammer projections in figure [ spheretrue ] . in this figure",
    ", we show the ` true ' column density map , as calculated from the individual sph particles that make up the cloud , and also the map pixelated into 48 , 192 , and 768 _ healpix _ pixels to create the ` pixel - averaged ' maps described above . on the left - hand side of the hammer projections",
    "one can see the high column density of the centrally condensed core of the sphere , and on the right - hand side of each map one can see the edge of the sphere , and the empty void beyond .",
    "although such a simple cloud geometry may seem trivial , it actually represents a stringent test of the  algorithm .",
    "first , the tree itself is made up of a series of boxes , and so the intrinsic geometries of the cloud and tree are quite different .",
    "second , we would expect that the rapidly evolving gradient in the column densities  associated with the sharp edge of the cloud  will be difficult for the tree to capture , as the edges of the nodes will tend to be in a different place , as discussed above .    despite these difficulties , the algorithm is able to capture the main features of the cloud fairly well .",
    "figure [ spheretreecol ] shows the  representation of the sky maps given in figure [ spheretrue ] for two different tree opening angles , @xmath87 and @xmath88 .",
    "we can see that the column density towards the centre of the cloud is well represented , and that the maps have the same overall features as those in figure [ spheretrue ] : high column density on one side , and a fairly sharp decline on the other side where the column density falls to zero .",
    "although the images in figure [ spheretreecol ] give an idea of the structure and boundaries that  is able to reproduce , it is difficult to gauge the quantitative accuracy of the method . a better representation is shown in figure [ sphereerror ] , where we plot the relative error in the  maps .",
    "here we see that the error is typically less than 10 percent when the column density is high , but can be as large as around 100 percent when the column density is low , or approaching zero . the high error ( around 50 percent ) in the middle of the map ( and the outer extremities ) comes from the fact that the boundaries of the tree nodes are not necessarily aligned with the edge of the particle distribution . as we increase s ability to see the structure in the cloud , by reducing the opening angle , we see that the error at the boundary decreases .",
    "overall , the best representation of the cloud s boundary ( and indeed the cloud itself ) is found in the 48 pixel map that was run with a tree opening angle of 0.3 .",
    "this is unsurprising , as the low resolution of the pixel - averaged map is also unable to capture the sharp fall in the column density at the cloud s boundary , while at the same time the smaller opening angle ensures that the pixels on the boundary are not assigned mass that belongs to further inside the cloud .    in general , we see that the smaller opening angles tend to produce better maps for a given pixellation .",
    "this is expected , since as the opening angle is reduced , the properties of the tree nodes become closer to the actual distribution of the particles .",
    "this is most obviously apparent in the 768 pixel map , where we see that the map obtained for @xmath88 contains artefacts from the underlying boxy structure of the tree , while the @xmath87 map is much smoother . in the maps with a lower number of pixels ,",
    "these features are not so apparent as the structure of tree is more smeared out .",
    "perhaps a more useful measure of the ability of  to sample its surroundings is the error in the average column density in the map , as given in table [ meancol ] . for the spherical cloud set - up",
    ", we find that the average column is between 4.2 and 7 percent higher than the average in the true map , with the lowest resolution run ( @xmath88 , n@xmath89 = 48 ) having the largest overall error , and the highest resolution run ( @xmath87 , n@xmath89 = 768 ) having the lowest error .",
    "the fact that these errors are so low reflects the fact that the mean is dominated by the high column density regions , which are recovered well by  in all the resolutions we study .",
    "the relative error ( computed according to equation [ frac_error ] ) based on the difference between the maps shown in figure [ spheretreecol ] and the pixellated maps shown in figure [ spheretrue].,width=326 ]     the column density sky - map as seen by a low - density particle in a turbulent molecular cloud simulation . as in figure [ spheretrue ] , the upper - left panel is obtained by adding up the contributions from all sph particles in the computational volume ( excluding the particle from which the sky is viewed ) .",
    "the other panels then show a ` pixel - averaged ' view of the cloud , as would be seen if we only had 48 , 192 and 768 pixels in our map.,width=326 ]     the left - hand panels show the  maps for the turbulent cloud set - up shown in figure [ turbtrue ] , for 48 , 192 and 768 pixels in the map .",
    "all maps were produced using a tree opening angle @xmath87 .",
    "the right - hand panels show the relative error in the  maps.,width=326 ]    .a summary of the mean column densities in the cloud models presented in sections [ sec : spheretest ] and [ sec : turbtest ] , for both the true map ( the first line ) and each of the  maps . for the  results we give the number of pixels used in the column density map ( n@xmath89 ) , the opening angle of the tree ( @xmath75 ) , and the percentage error compared to the true map from the sph particles .",
    "note that due to the way the pixel - averaged maps are obtained ( see section [ tests ] ) , their average column density is identical to that in the full sph map , and so we do not include it here . [ cols=\"^,^,^,^,^ \" , ]     [ scaling ]",
    "although the parallel efficiency of gadget 2 for this problem is not particularly high to begin with , it is clear that the use of  does not have very much influence on the scaling , suggesting that the additional communications overhead is not a significant problem in comparison to the inherent difficulties involved in properly load - balancing a simulation of this type .    however , as with any computational method , there are drawbacks to our approach .",
    "one of the main downsides of the  method is that it can introduce a significant memory overhead",
    ". the exact memory requirements of  can vary considerably , depending on the type of tree employed by the code , how the column density information is being used , and whether the code is parallelized using the message passing interface ( mpi ) protocol , or using the openmp protocol . in gadget  2 for example  a code that is mpi parallelized  copies of the sph particles on a given cpu are sent to all the other cpus to get the contributions to the gravitational force from the particles that reside there .",
    "an implementation in gadget  2 must then store two copies of the column density map for each particle : one that is broadcast to the other cpus to pick up their contributions , and one that resides on the home cpu that collects the local contributions and stores the final total .",
    "other tree codes parallelized using mpi work differently , sending the necessary information _ from _ the other cpus to the cpu with the target particle , requiring that only one map be stored per particle .",
    "in fact , if the column density map is only needed once  for example , to compute a mean extinction  then only the particle currently walking the tree needs a column density map . in this case",
    "the information stored in the map can be used at the end of particle s walk , and the map can then be cleared in preparation to be re - used in the next particle s tree - walk . so depending on the application , and on the code , the memory requirements for  can be anywhere from one map per parallel task , to two maps per particle .",
    "we have present a new tree - based technique for obtaining a full @xmath76 steradian map of the column densities at every location in numerical fluid simulations .",
    "the method piggy - backs on a tree - based gravitational force calculation , by making use of the information that is already stored in the tree  namely the mass , position , and size of the tree nodes  to construct a map of the column density distribution in the sky as seen by each fluid element .",
    "as the underlying algorithm is based on the tree , the method inherits the same @xmath90 scaling as the tree code .",
    "the fact that the method makes use of physical quantities that are already stored in the tree means that it is simple to implement , and requires only minimal modification to the underlying tree algorithm . in the case where the tree has been parallelised ,",
    "we find that the inclusion of   does not significantly affect the parallel scaling of the code .    in this paper",
    ", we describe a simple implementation of  that we find to yield column density maps that are accurate to better than 10 percent on average . in this implementation  which in our case was made within the publicly available sph code gadget 2 @xcite ",
    "we adopt the _ healpix _ @xcite pixelisation scheme to define the pixellated map in which the column densities for each particle are stored .    as an example application of",
    "we show how the method can be used to calculate the dust heating of prestellar cores by the interstellar radiation field .",
    "the results are compared with those from the monte carlo radiative transfer code radmc-3d . comparing our lowest resolution  results",
    " 48 pixels in the @xmath76 steradian _ healpix _ map and a tree opening angle of 0.5  to a 20 million photon packet radmc-3d calculation , we find that the two methods yield radial dust temperature profiles that agree to within 0.5k .",
    "we also discuss some other applications in which we expect  to be useful , such as the attenuation of uv radiation and its effect on the chemical and thermal balance of molecular clouds or the x - ray heating of the intergalactic medium .",
    "we would like to thank mordecai - mark mac low , tom abel , gabriel aorve , and lszl szcs , for many interesting discussions regarding the  method , and help with assembling the final manuscript .",
    "the authors acknowledge financial support from the landesstiftung baden - wrrtemberg via their program internationale spitzenforschung ii ( grant p - ls - spii/18 ) , from the german bundesministerium fr bildung und forschung via the astronet project star format ( grant 05a09vha ) , from the dfg under grants no .",
    "kl1358/10 and kl1358/11 , and via the sfb 881 `` the milky way galaxy '' , as well as from a frontier grant of heidelberg university sponsored by the german excellence initiative .",
    "the simulations reported on in this paper were primarily performed using the _ kolob _ cluster at the university of heidelberg , which is funded in part by the dfg via emmy - noether grant ba 3706 ."
  ],
  "abstract_text": [
    "<S> we present _ treecol _ , a new and efficient tree - based scheme to calculate column densities in numerical simulations . knowing the column density in any direction at any location in space is a prerequisite for modeling the propagation of radiation through the computational domain . </S>",
    "<S> _ treecol _ therefore forms the basis for a fast , approximate method for modelling the attenuation of radiation within large numerical simulations . </S>",
    "<S> it constructs a _ </S>",
    "<S> healpix _ sphere at any desired location and accumulates the column density by walking the tree and by adding up the contributions from all tree nodes whose line of sight contributes to the pixel under consideration . in particular when combined with widely - used tree - based gravity solvers the new scheme requires little additional computational cost . in a simulation with @xmath0 resolution elements , the computational cost of _ treecol _ scales as @xmath1 , instead of the @xmath2 scaling of most other radiative transfer schemes . </S>",
    "<S> _ treecol _ is naturally adaptable to arbitrary density distributions and is easy to implement and to parallelize , particularly if a tree structure is already in place for calculating the gravitational forces . </S>",
    "<S> we describe our new method and its implementation into the sph code gadget  2 . </S>",
    "<S> we discuss its accuracy and performance characteristics for the examples of a spherical protostellar core and for the turbulent interstellar medium . </S>",
    "<S> we find that the column density estimates provided by _ </S>",
    "<S> _ are on average accurate to better than 10 percent . in another application , </S>",
    "<S> we compute the dust temperatures for solar neighborhood conditions and compare with the result of a full - fledged monte carlo radiation - transfer calculation . </S>",
    "<S> we find that both methods give very similar answers . </S>",
    "<S> we conclude that _ treecol _ provides a fast , easy to use , and sufficiently accurate method of calculating column densities that comes with little additional computational cost when combined with an existing tree - based gravity solver .    </S>",
    "<S> methods : numerical  radiative transfer </S>"
  ]
}