{
  "article_text": [
    "hypothesis testing , first introduced by wald @xcite , is one of the most classical and well - studied problems of sequential analysis with applications in areas such as industrial quality control , signal detection , design of clinical trials , etc @xcite . in the last two decades",
    ", there has been an intense interest in the _ decentralized _ ( or _ distributed _ ) formulation of the problem @xcite-@xcite . in this setup , the sequentially acquired information for decision making is distributed across a number of sensors and is transmitted to a global decision maker ( fusion center ) , which is responsible for making the final decision .",
    "the main difference in the decentralized version of the problem is that the sensors are required to _ quantize _ their observations before transmitting them to the fusion center ; in other words , the sensors must send to the fusion center messages that belong to a _ finite alphabet _ @xcite .",
    "this requirement is imposed by the need for data compression , smaller communication bandwidth and robustness of the sensor network , which are crucial issues in application areas such as signal processing , mobile and wireless communication , multisensor data fusion , internet security , robot networks and others @xcite .",
    "depending on the _ local memory _ that the sensors possess and whether there exists _ feedback _ from the fusion center , veeravalli et .",
    "@xcite proposed five different configurations for the sensor network . in the same work",
    ", the authors found the optimal decentralized test -under a bayesian setting- in the case of full feedback and local memory restricted to past decisions .",
    "moreover , under a bayesian setting , the case of no feedback and no local memory was treated in @xcite while the case of full local memory with no feedback in @xcite,@xcite . however , in the last two cases no exactly optimal decentralized test has been discovered ( see @xcite for a review ) .    in this work",
    ", we assume that the alphabet consists of two letters for all sensors , i.e. we allow the communication of only 1-bit messages . moreover",
    ", we do not use any feedback and we consider the configuration of _ partial _ local memory @xcite . specifically",
    ", we assume that at each time instant each sensor has access to the value of a summary statistic -that summarizes its previous observations- and uses this value , together with its current observation , in order to send a quantized signal to the fusion center . under this configuration , an ( order-1 )",
    "asymptotically optimal scheme was suggested by mei @xcite under a bayesian setting .",
    "most schemes in the literature of decentralized detection require _ synchronous _ communication of the sensors with the fusion center .",
    "however , forcing distant sensors to communicate with the fusion center concurrently can be a very challenging practice .",
    "thus , it is important to develop and analyze schemes where this communication protocol is _",
    "asynchronous_. examples of asynchronous schemes can be found in @xcite and @xcite .",
    "taking into account this consideration , we suggest that the sensors communicate with the fusion center asynchronously but also _ at random times_. in particular , we suggest that the times instants at which sensor @xmath0 communicates with the fusion center be _ stopping times _ that depend on the observed information at sensor @xmath0 .",
    "we call this type of sampling _ adapted_.    a special case of adapted sampling is the _ lebesgue _ ( or _ level - triggered _ ) sampling which induces , naturally , a _ 1-bit _ communication between sensors and the fusion center . lebesgue sampling combined with a sequential probability ratio test at the fusion center give rise to a detection structure known as decentralized sequential probability ratio test ( d - sprt ) introduced by hussain in @xcite , in a discrete time context",
    ". however , hussain did not provide any theoretical support for this test nor evidence that it is efficient in any sense .",
    "our main contribution in this work consists in formulating and providing proof of asymptotic optimality of the d - sprt , under both the discrete and the continuous time setup .",
    "our asymptotic optimality result turns out to be stronger as compared to the scheme proposed in @xcite , with simulation experiments corroborating our theoretical findings .",
    "the case of continuous time observations , which we analyze in section iv , is clearly an idealization , since in practice we can not record the sensor observations continuously .",
    "however , studying the problem under such a setup allows us to isolate the loss in efficiency due to discrete sampling of the underlying processes at the sensors .",
    "this provides valuable insight that leads to more efficient sampling schemes in the more realistic case of discrete time observations .",
    "this paper is organized as follows : sectioni contains the introduction . in sectionii",
    ", we formulate the sequential hypothesis testing problem for the discrete and continuous time case under a centralized and decentralized setup .",
    "moreover , we introduce the concept of adapted sampling and emphasize on lebegsue sampling and the d - sprt . in sectioniii",
    "we recall the main optimality results for the centralized formulation since these tests serve as a point of reference for their decentralized counterparts .",
    "sectioniv presents the asymptotic optimality properties of d - sprt in the context of continuous time and continuous path observations while in sectionv we develop the same results , at the expense of a more involved analysis , for the discrete time case . in this section",
    "we also examine the notion of oversampling that `` reconciles '' the behavior of the discrete time d - sprt with its continuous time version and provides some important design observations .",
    "finally , in sectionvi we conclude our work .",
    "suppose that we have a sensor network consisting of @xmath1 sensors as depicted in fig.[fig:1 ] .",
    "each sensor @xmath0 observes _ sequentially _ a realization of a stochastic process @xmath2 with distribution @xmath3 .",
    "we assume that the processes @xmath4 are independent and we denote by @xmath5 the filtration generated by @xmath6 , where @xmath7 .",
    "we also denote with @xmath8 the probability measure of @xmath9 and by @xmath10 the filtration generated by this vector process . from the assumption of independence across sensors , we have : @xmath11 .",
    "consider now the following two hypotheses for the probability measure @xmath8 : @xmath12 where @xmath13 and @xmath14 are _ known _ probability measures .",
    "thus @xmath15 are two _ simple _ hypotheses . for simplicity",
    "we also assume that each pair @xmath16 contains mutually absolutely continuous measures , therefore we can define the `` local '' log - likelihood ratio process at each sensor @xmath0 and for each time instant @xmath17 , as follows @xmath18 moreover , due to the independence of observations across sensors , we can write the `` global '' log - likelihood ratio @xmath19 in the sensor network as the sum of its local components , i.e. @xmath20    although the sensors observe sequentially the processes @xmath6 , they are allowed to communicate information to the fusion center _ only at a sequence of discrete times_. in particular , we assume that the fusion center receives sequentially from each sensor @xmath0 the data @xmath21 at a _ strictly increasing _ sequence of time instants @xmath22 .",
    "each @xmath23 is an @xmath24-adapted stopping time with @xmath25 and @xmath26 and @xmath27 .",
    "we call this communication scheme _ adapted sampling _ and we refer to the stopping times @xmath28 as the _ sampling times _ in sensor @xmath0 .",
    "each @xmath29 constitutes a summary of the acquired information @xmath30 up to time @xmath23 and , as we mentioned in the introduction , it takes values in a finite alphabet .",
    "here we are going to assume that this set is _",
    "binary_. we should also emphasize that we do not consider any feedback scheme from the fusion center towards the sensors .",
    "adapted sampling clearly implies _ asynchronous _ communication between the sensors and the fusion center at _ random _ time instants .",
    "thus , the number of samples sent from sensor @xmath0 to the fusion center up to any time instant @xmath17 is random and in general different for each sensor . we should mention that adapted sampling is a general framework that can incorporate various sampling mechanisms already used in the literature , in particular :    * when @xmath31 , adapted sampling reduces to _ canonical deterministic sampling _ with constant sampling period @xmath32 , common to all sensors .",
    "* when @xmath33 is a sequence of i.i.d .",
    "random variables , _ independent _ of the observation process @xmath34 , adapted sampling becomes _ independent random sampling_. for example , if the intersampling periods @xmath35 are independent and exponentially distributed with the same mean , we recover the sampling scheme suggested in @xcite . * when the sampling times _ depend _ on the observed sequence and are given by the following recursion @xmath36 where @xmath37 are proper thresholds , then we call the resulting scheme _ lebesgue _ ( or _ level - triggered _ ) sampling .",
    "although not evident at first , we should emphasize that the fusion center is the recipient not only of the data sequences @xmath21 but also of the sampling times @xmath28 that may carry information which is relevant to the hypothesis testing problem .",
    "consequently , for each sensor @xmath0 , let us define the sequence of _ intersampling periods _",
    "@xmath38 where @xmath39 .    in parallel to the communication activity the fusion center , at each time instant @xmath17 , uses all the received data up to time @xmath17 , in order to make a decision whether to continue or stop receiving additional data . in the latter case",
    "it proceeds to make a final decision between the two hypotheses .    under a _",
    "decentralized setup _ , denote with @xmath40 the number of pairs @xmath41 received by the fusion center from sensor @xmath0 up to ( and including ) time @xmath17 .",
    "we can now define the filtration @xmath42 for the fusion center where @xmath43 is the @xmath44-algebra generated by all pairs @xmath41 received up to time @xmath17 . the fusion center based on this time increasing information can use an @xmath45-adapted stopping time @xmath46 to decide about stopping or continuing sampling . after stopping it also uses an @xmath47-measurable decision function @xmath48 to select one of the two hypotheses .    under the _ centralized setup _ the fusion center gains access to the _ entire _ information acquired by the sensors up to time @xmath17 .",
    "consequently , if @xmath49 is the corresponding filtration with @xmath50 denoting the @xmath44-algebra generated by all acquired information up to time @xmath17 then , the fusion center can use an @xmath51-adapted stopping time @xmath46 and an @xmath52-measurable decision function @xmath53 to stop sampling and provide a decision between the two hypotheses .    under both , the centralized and the decentralized formulation ,",
    "our intention is to define the pair @xmath54 optimally .",
    "following wald @xcite , for any @xmath55 , we define the class of sequential tests for which the type - i and type - ii error probabilities are below the two levels @xmath56 respectively , that is , @xmath57 we can now define the following constrained optimization problem .    given @xmath55 such that @xmath58 ,",
    "find a sequential test @xmath59 so that @xmath60= \\inf_{(t , d_{t } ) \\in { { \\mathscr{c}}}_{\\alpha,\\beta } } \\ , { { \\sf e}}_{j}[t ] , \\ ; \\ ; j=0,1.\\ ] ]    if we seek the test among the @xmath51-adapted schemes we refer to the optimum centralized version whereas if we limit ourselves to @xmath45-adapted tests then we obtain the optimum decentralized procedure . note that we attempt to find a _",
    "test that _ simultaneously _ minimizes two different criteria ( the expected decision delay under the two hypotheses ) .",
    "it was wald s remarkable insight that led first to conjecture @xcite and then prove @xcite that a test with such extraordinary optimality property indeed exists .",
    "let us also introduce a second problem , proposed by liptser and shiryaev @xcite , which constitutes a slight variant of problem1 .",
    "given @xmath55 such that @xmath58 , find a sequential test @xmath59 , so that@xmath61&=\\inf_{(t , d_{t } ) \\in { { \\mathscr{c}}}_{\\alpha,\\beta } } ( -{{\\sf e}}_0 [ u_{t}]),\\\\ { { \\sf e}}_{1 } [ u_{{\\mathscr{t}}}]&=\\inf_{(t , d_{t } ) \\in { { \\mathscr{c}}}_{\\alpha,\\beta } } { { \\sf e}}_{1 } [ u_{t } ] .",
    "\\end{split}\\ ] ]    recalling that @xmath62 is the running log - likelihood ratio of the two probability measures , it is clear that the two expectations @xmath63 $ ] and @xmath64 $ ] give rise to nonnegative and increasing functions of time .",
    "these two time functions constitute , in information theory , a popular divergence measure known as the kullback - leibler ( k - l ) divergence .",
    "this interesting information theoretic criterion reduces to the usual average detection delay when the signals are i.i.d .",
    "( in discrete time ) or brownian motions with constant drift ( in continuous time ) .",
    "it is clear that any decentralized scheme is bound to be inferior in performance to the optimum centralized test .",
    "this is true for two major reasons .",
    "first because a decentralized test has access to less information ( @xmath21 being a summary of @xmath34 ) but also because of loss in _ time resolution _ ( @xmath28 being a sampled version of the actual time @xmath17 ) . the main goal of our current work is to find decentralized schemes where this performance loss can be quantified and propose methods for controlling it .    regarding the decentralized version of problem1 and 2 we must emphasize that the way it is stated , it is assumed that the sampling / quantization policy , namely the mechanism by which the pairs @xmath65 are generated from the observation sequence @xmath34 , is already specified . of course one might extend both problems by including an additional minimization over the sampling / quantization policy as well , thus optimizing all parts of the decentralized test .",
    "finding however optimum , per se , decentralized tests that solve the extended version of the two problems turns out to be an extremely challenging task .",
    "for this reason we focus on suboptimum procedures .",
    "to assess the quality of any decentralized test , since the optimum decentralized test is not available , we can compare it against the _ centralized _ optimum scheme which is known in several important cases .",
    "we are in particular interested in _ asymptotically optimum _ tests . if @xmath66 denotes the stopping time corresponding to the optimum centralized test that solves problem1 or 2 and @xmath46 the stopping time of a decentralized ( or even centralized ) competitor , then we distinguish the following degrees of asymptotic optimality , @xmath67 and @xmath68 .",
    "if @xmath69 is a parameter that tends to 0 or @xmath70 and @xmath71 functions of @xmath69 then @xmath72 means that @xmath73 is uniformly bounded away from 0 and @xmath70 ; @xmath74 that the same ratio is bounded away from @xmath70 and @xmath75 that @xmath76 as @xmath69 tends to 0 or @xmath70 . ]",
    ":    we will say that a test is _ asymptotically optimal of order-1 _ , if for @xmath77 and as @xmath78 , we have @xmath79}{{{\\sf e}}_{j}[{\\mathscr{t}}]}=1+o(1),~\\text{or}~ \\frac{{{\\sf e}}_{j}[u_{t}]}{{{\\sf e}}_{j}[u_{{\\mathscr{t}}}]}=1+o(1),\\ ] ] for problems1 and 2 respectively .",
    "we will say that a test is _ asymptotically optimal of order-2 _ , if for @xmath77 and as @xmath78 , we have @xmath80-{{\\sf e}}_{j}[{\\mathscr{t}}]=o(1),~\\text{or}~ { { \\sf e}}_{j}[u_{t}]-{{\\sf e}}_{j}[u_{{\\mathscr{t}}}]=o(1),\\ ] ] for problems1 and 2 respectively .",
    "finally , even though we will not consider this form of asymptotic optimality here , we define a test to be _ asymptotically optimal of order-3 _ , if for @xmath77 and as @xmath78 , we have @xmath81-{{\\sf e}}_{j}[{\\mathscr{t}}]=o(1),~\\text{or}~ { { \\sf e}}_{j}[u_{t}]-{{\\sf e}}_{j}[u_{{\\mathscr{t}}}]=o(1).\\ ] ] it is clear that order-3 optimality is stronger than order-2 which is stronger than order-1 .",
    "indeed order-2 implies order-1 because expected delays and k - l divergences increase without bound as @xmath78 .    in order to establish any form of asymptotic optimality ,",
    "it is evident from the previous definitions that we need to recall the major results of the optimum centralized theory .",
    "the optimization problems defined in ( [ wald_crit1 ] ) and are associated with the well celebrated sequential probability ratio test ( sprt ) proposed by wald @xcite , which is defined as follows @xmath82 where @xmath83 are two thresholds and @xmath66 is the first time the global log - likelihood ratio process @xmath19 leaves the open interval @xmath84 .",
    "the decision function @xmath85 on the other hand is an @xmath86-measurable random variable , according to which @xmath87 ( @xmath88 ) is accepted if the lower ( upper ) threshold is first crossed .",
    "the two thresholds @xmath89 are selected so that the two error probability constraints in ( [ cab ] ) are satisfied with equality .    in _ continuous time _",
    "shiryaev @xcite considered the following hypothesis testing problem @xmath90 where @xmath91 is a @xmath1-dimensional wiener process and @xmath92 are constant drifts .",
    "the local log - likelihood ratio is equal to @xmath93 and by summing the local components we can compute @xmath94 and apply the sprt which is optimum in the sense of problem1 and problem2 .    in the brownian motion case , we have also exact formulas for the optimum performance",
    ". specifically @xmath95= \\frac{2}{\\|\\mu\\|^2}{\\mathcal{h}}(\\alpha , \\beta);~~{{\\sf e}}_{1}[{\\mathscr{t}}]= \\frac{2}{\\|\\mu\\|^2}{\\mathcal{h}}(\\beta , \\alpha),\\ ] ] where @xmath96 . the two thresholds that guarantee that the two error probability constraints are satisfied with equality are given by @xmath97    a significantly richer class of hypothesis testing problems was proposed by liptser and shiryaev @xcite that involves it processes .",
    "in particular @xmath98 where , as before @xmath99 is a @xmath1-dimensional wiener process and @xmath100 is a @xmath1-dimensional @xmath101-adapted process satisfying is a martingale .",
    "alternative , more relaxed conditions that guarantee the martingale property can be found in ( * ? ? ?",
    "* page 199 ) . ]",
    "@xmath102 < \\infty , \\end{split } \\label{assum}\\ ] ] for all @xmath103 .",
    "the local log - likelihood ratio @xmath104 takes the form @xmath105 which again allows for the computation of @xmath94 and the application of sprt .",
    "it is also interesting to mention that , in this particular case , the k - l divergence can be equivalently written as @xmath106&={{\\sf e}}_{0}\\left [ \\int_{0}^t 0.5\\|\\mu_s\\|^2 \\ , ds \\right]\\\\ { { \\sf e}}_1[u_t]&={{\\sf e}}_{1}\\left [ \\int_{0}^t 0.5\\|\\mu_s\\|^2 \\ , ds \\right ] , \\end{split}\\ ] ] which clearly reveals the nonnegative and time increasing nature of this alternative criterion . as proven in @xcite , under this more general setup , sprt is optimum in the sense defined by problem2 delivering the following optimal performance @xmath107 = { \\mathcal{h}}(\\alpha , \\beta);~~ { { \\sf e}}_{1 } [ u_{{\\mathscr{t } } } ] = { \\mathcal{h}}(\\beta , \\alpha),\\ ] ] with the thresholds @xmath89 defined according to , for the two constraints in ( [ cab ] ) to be satisfied with equality .    in _ discrete time _ , sprt is known to be optimum in the sense of problem1 and problem2 when the vector sequence @xmath108 with @xmath109 is i.i.d .  with independent components under both hypotheses .",
    "in particular under the two hypotheses we have @xmath110 where @xmath111 denotes the cdf of the data acquired by sensor @xmath0 when hypothesis @xmath112 is true and `` @xmath113 '' means `` distributed according to '' . for this case",
    "the local log - likelihood ratio takes the form @xmath114 and by summing over @xmath0 we can compute the global log - likelihood ratio and apply the sprt .",
    "the proof of optimality of sprt was first offered by wald and wolfowitz in @xcite .",
    "in fact this proof constitutes the first optimality result of sequential analysis .",
    "we can now make the following remarks :    * the sprt has also been proven to be optimal in the case where the @xmath34 are independent homogeneous poisson processes @xcite .",
    "this problem however is not particularly interesting under the decentralized setup since an arrival at a sensor can be signaled to the fusion center using simply one bit of information . * in discrete time , sprt is known to be optimum only in the i.i.d",
    "unfortunately no analog to the it class result for problem2 has been developed so far .    from the optimum centralized theory",
    "we conclude that in order to apply the sprt we need the global log - likelihood ratio @xmath62 or more precisely its local components @xmath115 coming from the sensors .",
    "our goal in the next sections will be to propose efficient _ approximations _ for these processes that will replace them in the definition of sprt thus giving rise to an sprt - like test .",
    "the efficiency of this test will then be compared against the optimum sprt in order to assess its asymptotic optimality .",
    "since we are in the continuous time case , @xmath17 is real taking values in @xmath116 .",
    "let us assume , but without for the moment explaining how , that the fusion center is capable of reproducing _ exactly _ the local log - likelihood ratio @xmath117 at the sampling instants @xmath118 , by using only the received information @xmath21 from sensor @xmath0 .",
    "it then makes sense to approximate @xmath104 between sampling times with its most recently reproduced value . in order to write this more formally ,",
    "we recall that @xmath40 denotes the number of samples transmitted by sensor @xmath0 up to time @xmath17 . thus",
    ", at time @xmath17 , @xmath119 is the most recent sampling time and @xmath120 the most recently reproduced log - likelihood value .",
    "our suggestion is to approximate @xmath94 with @xmath121 .",
    "we emphasize that we have exact equality between @xmath122 and @xmath104 at @xmath118 , because we assume that the fusion center is capable of reproducing exactly the corresponding log - likelihood ratio at the sampling times @xmath28 .",
    "then , the fusion center can produce an approximation @xmath123 for the global log - likelihood ratio @xmath94 by summing the available local approximations @xmath124 unlike the local approximation @xmath122 which is exact at @xmath118 , the global approximation @xmath123 can be exactly equal to @xmath94 at a sampling instant only if all sensors transmit synchronously , otherwise @xmath94 and @xmath123 will be different .    replacing now @xmath19 with @xmath125 in the definition of sprt in ( [ sprt ] ) , we obtain an sprt - like test of the form @xmath126 where again the thresholds @xmath127 are selected to satisfy the error probability constraints with equality .",
    "the test we just described constitutes the fusion center policy we propose under the decentralized setup .",
    "let us now explain how the fusion center can make an exact reproduction of the local log - likelihood ratios .",
    "of course the simplest way the fusion center can reproduce the log - likelihood ratio , is by receiving the corresponding value directly from the sensor .",
    "however this would require a communication protocol that is not limited to 1-bit information .",
    "the interesting point is that , after careful consideration , the 1-bit communication constraint can be satisfied in the case of lebesgue sampling .",
    "recalling that @xmath28 denotes the sequence of sampling times for sensor @xmath0 , we have that the local log - likelihood ratio at time @xmath23 can be written as @xmath128 , \\label{reproduce}\\ ] ] suggesting that the fusion center only needs the increments @xmath129 in order to recover the exact value @xmath130 at the sampling instant @xmath23 . when @xmath115 has",
    "_ continuous paths _ and we adopt the lebesgue sampling scheme then we observe that these increments can take only upon the two values @xmath131 or @xmath132 , since the process @xmath133 will hit at the time of sampling one of the two thresholds , due to path continuity . by assuming that the values @xmath134 are selected before hand and are made available to the fusion center , it then becomes easy to communicate the exact value of the increment @xmath129 by simply transmitting the following 1-bit information @xmath135 the fusion center , using the sequence @xmath21 and , can reproduce @xmath104 exactly at the sampling times and then form @xmath123 which is required in the sprt - like test defined in .",
    "actually with this particular communication protocol it is possible to update directly the test statistic @xmath123 , without passing through the local statistics @xmath122 .",
    "indeed the fusion center , every time it receives the 1-bit information @xmath29 from sensor @xmath0 , it must simply add to the existing @xmath123 either @xmath131 or @xmath132 depending on @xmath29 being 0 or 1 respectively .",
    "this observation suggests that the process @xmath136 is _ piecewise constant _ exhibiting jumps every time the fusion center receives information from one or more sensors .",
    "lebesgue sampling in conjunction with the stopping and decision mechanism defined in gives rise to the decentralized sequential probability ratio test .",
    "this is in fact the continuous time version of the scheme suggested in @xcite and constitutes the test that will be in the center of our attention .",
    "we emphasize that the d - sprt is a valid _ decentralized _ sequential test since communication is limited to 1-bit data . before examining the optimality characteristics of the d - sprt ,",
    "let us identify certain important properties of this detection structure :    * lebesgue sampling at each sensor can be seen as a local _ repeated _ sprt with thresholds @xmath134 . using and",
    "one can also prove that @xmath137 consequently , for the update of the estimate @xmath123 , the fusion center uses the log - likelihood ratio of the received bits @xmath29 .",
    "* the local thresholds @xmath134 control the average intersampling period which is an increasing function of these two parameters . recalling that we have two different hypotheses ,",
    "we understand that the average intersampling period will depend on the true hypothesis .",
    "if we require the two average periods to have specific prescribed values then , using ( or if we want to specify the k - l divergence ) and , we can uniquely identify the local thresholds for the brownian motion or the it process case .",
    "in other data models , the two thresholds can be specified using simulations . * from the definition of the lebesgue sampling scheme it is easy to see that @xmath138 , suggesting that latexmath:[\\[\\label{c }    thus , at any time @xmath17 , the `` approximate '' log - likelihood ratio @xmath140 differs from the `` true '' log - likelihood ratio @xmath141 at most by the constant @xmath142 . * as we argued above @xmath136 is piecewise constant .",
    "assuming it is right continuous with left limits , the difference @xmath143 expresses the possible jump in the process at time @xmath17 .",
    "the largest in absolute value jump occurs when all sensors communicate at the same time and transmit data of the same sign .",
    "it is easy to verify that the maximal jump can also be bounded by @xmath144 where @xmath142 is defined in .",
    "* we recall that , in addition to the data sequence @xmath21 , each sensor transmits indirectly to the fusion center the sequence @xmath145 of intersampling periods . as we argued before , the pairs",
    "@xmath41 constitute the complete set of information received by the fusion center generating the filtration @xmath45 .",
    "it is also evident that the statistics of @xmath41 differ under each hypothesis suggesting that both components of the pair may carry information about the true hypothesis .",
    "we realize however that d - sprt makes use only of the data @xmath21 ignoring completely the intersampling periods @xmath146 .",
    "even though this information dropout inflicts a performance loss , it turns out that it is practically advantageous .",
    "indeed any efficient use of the pair @xmath41 would require the knowledge ( or computation ) of the corresponding joint pdf under the two hypotheses .",
    "unfortunately , this is possible only for the brownian motion model @xcite and , even in this case , it is in the form of a complicated series expansion .",
    "let us now establish a strong asymptotic optimality property for d - sprt in continuous time .",
    "this is the goal of our next theorem .",
    "[ th:1 ] suppose that @xmath147 is the d - sprt test defined in , with thresholds @xmath148 selected to satisfy the error probability constraints in ( [ cab ] ) with equality , then @xmath149 furthermore , d - sprt is asymptotically optimum of order-2 in the case of problem1 and problem2 with brownian motion signals with constant drifts and in the case of problem 2 with it processes .    to prove , we apply a change of measures and use , this yields @xmath150\\\\   & = { { \\sf e}}_{0 } \\left [ e^{\\tilde{u}_{\\tilde{{\\mathscr{t}}}}+(u_{\\tilde{{\\mathscr{t}}}}-\\tilde{u}_{\\tilde{{\\mathscr{t } } } } ) } { \\mathbbm{1}_{\\{\\tilde{u}_{\\tilde{{\\mathscr{t } } } } \\leq -\\tilde{a}\\ } } } \\right ] \\leq e^{-\\tilde{a}+ c } , \\end{split}\\ ] ] which proves the first inequality in .",
    "similarly we can show the second inequality .    for order-2 optimality",
    ", we are going to prove only the case of it processes and problem2 , since this reduces to problem1 in the case of brownian motions with constant drifts .",
    "according to the second relation in , under hypothesis @xmath151 we need to prove that @xmath152)-(-{{\\sf e}}_0[u_{{\\mathscr{t}}}])=o(1).\\ ] ] note that the left hand side in is always nonnegative since the sprt , by being optimum , delivers the smallest k - l divergence .",
    "consequently what is left to show is that the difference can be upper bounded by a constant .",
    "recall that @xmath136 is piecewise constant therefore stopping can occur only with a jump .",
    "according to the jumps of this process can not exceed the bound @xmath142 defined in . before stopping ,",
    "the process @xmath123 takes values in the interval @xmath153 consequently , after stopping , we have @xmath154 . using this observation , and , we can write @xmath155&={{\\sf e}}_0 [ \\tilde{u}_{\\tilde{{\\mathscr{t}}}}+(u_{\\tilde{{\\mathscr{t}}}}-\\tilde{u}_{\\tilde{{\\mathscr{t}}}})]\\\\ & \\ge ( -\\tilde{a}-c)-c\\ge-|\\log\\beta|-3c . \\end{split } \\label{eq : lastlast}\\ ] ]    from we have that the performance of the sprt , as @xmath78 , satisfies @xmath156 = |\\log\\beta| + \\alpha|\\log\\beta|+o(1)$ ] .",
    "normally @xmath157 and @xmath158 are selected to have the same order of magnitude yielding @xmath159 , however for the validity of our theorem we can even tolerate cases where @xmath160 , that is , cases where @xmath157 and @xmath158 are of drastically different orders of magnitudes ( e.g.  @xmath161 ) . consequently , assuming that @xmath157 and @xmath158 converge to 0 so that @xmath162 , if in we replace @xmath163 with the optimal sprt performance , this proves under @xmath151 .",
    "adopting similar arguments for the upper threshold @xmath164 , we can prove under @xmath88 .",
    "this concludes the proof .",
    "we now present a simulation experiment in the context of problem1 with continuous time observations defined as in .",
    "specifically , each sensor observes a standard wiener process under @xmath151 and a brownian motion with a constant drift under @xmath88 .",
    "we consider the case of @xmath165 sensors with the two constant drifts under @xmath88 to have the values @xmath166 .",
    "sensors and testing between @xmath167 brownian motions with drift 0 and @xmath168 brownian motions with drift 1 . ]",
    "we compare the d - sprt against the continuous time ( centralized ) sprt , the discrete time ( centralized ) sprt and mei s @xcite decentralized test .",
    "the last two test are applied to discrete time data that are generated with canonical deterministic sampling . for the comparison to be fair , we must equate the average intersampling periods of the lebesgue sampling with the constant period @xmath169 of the canonical deterministic sampling . selecting the local thresholds to have values @xmath170 ,",
    "yields @xmath171={{\\sf e}}_{1}[\\tau^i_{1}]=3.0464 $ ] which must also become the value for the period of the deterministic sampling , namely @xmath172 . in fig.[fig:2 ] we can see that the distance between the d - sprt and the optimal performance remains bounded , which agrees with the order-2 asymptotic optimality result of theorem[th:1 ] .",
    "mei s scheme on the other hand , known to be order-1 asymptotically optimum ( see @xcite ) , exhibits performance that slowly diverges from the optimum .",
    "the other important conclusion that we can draw from our graph is that the d - sprt exhibits a distinct performance improvement over the discrete time sprt which is applied after canonical deterministic sampling .",
    "we recall that this algorithm is optimum in discrete time but under the continuous time setup it is asymptotically optimum of order-2 .",
    "as we argued in the introduction , lebesgue sampling is preferable to canonical deterministic sampling from a practical point of view since it does not require synchronization .",
    "motivated by our simulations we can also _ conjecture _ that , even under the centralized setup , this form of sampling delivers better performance than canonical deterministic sampling .",
    "we consider the same formulation as in sectioniv only now time @xmath17 is discrete with @xmath173 . at each sensor @xmath0 ,",
    "the process @xmath34 is i.i.d .  under the two hypotheses with corresponding cdfs @xmath174 .",
    "denoting with @xmath175 the local log - likelihood ratio of the sample @xmath176 and assuming that @xmath177 , in other words that the two densities are not equal with probability 1 , we have that the global log - likelihood ratio @xmath94 is given by @xmath178 when this definition of @xmath94 is used in , the corresponding sprt is optimum in the sense of problem1 and 2 , provided that the two thresholds @xmath89 are selected to satisfy the probability constraints in ( [ cab ] ) with equality .",
    "we recall that , in discrete time , apart the i.i.d .",
    "case , there is no other data model for which we know the solution for problem2 ( i.e.  there is no equivalent to the it processes case ) .",
    "the centralized sprt will again become the point of reference for any decentralized test , it is therefore necessary to quantify its performance . unfortunately in discrete time there are no exact expressions as in continuous time , we therefore need to resort to asymptotic formulas and bounds . for the performance of sprt we have ( * ? ?",
    "* page 21 ) the following lower bounds @xmath179 & \\ge{\\mathcal{h}}(\\alpha,\\beta)=|\\log\\beta|+o(1),\\\\ { { \\sf e}}_{1}[u_{{\\mathscr{t } } } ] & \\ge{\\mathcal{h}}(\\beta,\\alpha)=|\\log\\alpha|+o(1 ) , \\end{split}\\ ] ] which replace the exact equalities of the continuous time and continuous path case depicted in .",
    "let us now introduce a very important element in our analysis which will allow us to connect the discrete with the continuous time version presented in the previous section .",
    "we will assume that the `` size '' of all local log - likelihood ratios can be quantified , in an order of magnitude sense , by a finite parameter @xmath180 .",
    "normally @xmath181 , meaning that we regard the corresponding log - likelihood ratios as being of nominal size",
    ". here however we would like to include an additional dimension into our analysis by relating the size of the log - likelihood ratio to the error levels @xmath56 .",
    "if for example the samples @xmath34 are generated by sampling a continuous time process , then @xmath180 can be directly related to the sampling period .",
    "our goal is to show that , for sufficiently `` small '' samples , _ d - sprt enjoys the same order-2 asymptotic optimality property as its continuous time counterpart_. the actual size @xmath180 that can assure this interesting result , as we will show , decreases to 0 , but at a _ much lower rate _ than the two error levels @xmath56 .",
    "this suggests that with small changes in @xmath180 ( coming for instance from a mild _ oversampling _ of a continuous time process ) we can obtain significant performance gains .",
    "it is clear that our intention is to apply the same d - sprt scheme we introduced in the continuous time case , namely lebesgue sampling combined with an sprt - like test where we approximate properly the global log - likelihood ratio @xmath94 .",
    "unfortunately this transfer from the continuous to discrete time is not as straightforward as one might expect .",
    "the main reason is that with lebesgue sampling we are no longer able to reproduce exactly the local log - likelihood ratios at the sampling times because of the _ overshoot effect _ occurring at the local sprt .",
    "this rather unfortunate difference is responsible for a substantial complication in the corresponding discrete time analysis .",
    "the overshoot is of course directly related to the size of the local log - likelihood ratio of each sample . since for our analysis",
    "the overshoot plays a very important role , it is more convenient with @xmath180 to capture the overshoot size and then , through proper conditions , to examine how @xmath180 relates to the log - likelihood ratio .    finally , in order to avoid unnecessary complications , we will limit ourselves to the case where the two error levels @xmath56 decrease to 0 at the same rate , meaning that the ratio @xmath182 is uniformly bounded away from 0 and @xmath70 ( or according to our definitions @xmath183 ) .      in each sensor @xmath0 , the lebesgue sampling scheme defined in ,",
    "produces a sequence @xmath28 of @xmath24-adapted stopping times , only now , due to the overshoot effect , the local sprt statistic @xmath133 does not necessarily hit the two thresholds .",
    "consequently the information sent over the channel can express only the _ side _ by which the statistic @xmath129 exits the interval @xmath184 , more precisely @xmath185 which is the equivalent of .    to this end",
    "it is only natural to ask how the fusion center should utilize the sequence @xmath21 . in the continuous time and continuous path case ,",
    "we recall that the fusion center , in view of , uses the log - likelihood ratio of the received bits @xmath29 to update the estimate @xmath123 . consequently",
    ", in discrete time it seems only natural to use the same idea and define ( as was also originally suggested in @xcite ) the following two quantities for each sensor @xmath186 both values @xmath187 can be precomputed either by simulations or numerically and made known to the fusion center .    as we argued above , we are interested in the sequence of overshoots @xmath188 , where @xmath189 the maximal average overshoot size is a parameter that plays a very important role in our analysis . we define it as @xmath190,\\ ] ] and we know @xcite that it is finite if @xmath191<\\infty,~j=0,1,~i=1,\\ldots , k$ ]",
    ".    in the continuous time and continuous path case , since there is no overshoot , the thresholds @xmath134 coincide with the quantities @xmath187 .",
    "in discrete time this is no longer true .",
    "the next lemma quantifies their relative size .",
    "[ lem:01 ] let @xmath37 denote the thresholds for the local sprt and @xmath187 be defined as in , then @xmath192    the proof is presented in the appendix .",
    "the fusion center , every time it receives an information bit @xmath29 updates its existing statistic @xmath123 by either adding @xmath193 when @xmath194 or @xmath195 when @xmath196 .",
    "recalling that @xmath40 denotes the number of bits transmitted by sensor @xmath0 up to time @xmath17 , we can write for the d - sprt statistic that @xmath197 where @xmath198 the k - l information numbers of the sequence @xmath199 play also an important role in our analysis . we have the following estimates depicted in the next lemma .    [ lem:02 ] for the k - l information numbers of the sequence @xmath199 we can write @xmath200\\ge\\frac{{\\underline{\\delta}_{i}}(e^{{\\overline{\\delta}_{i}}}-1)+{\\overline{\\delta}_{i}}(e^{-{\\underline{\\delta}_{i}}}-1)}{e^{{\\overline{\\delta}_{i}}}-e^{-{\\underline{\\delta}_{i}}}}>0\\\\ i_1^i&={{\\sf e}}_1[\\lambda_n^i]\\ge\\frac{{\\underline{\\delta}_{i}}(e^{-{\\underline{\\delta}_{i}}}-1)+{\\overline{\\delta}_{i}}(e^{{\\overline{\\delta}_{i}}}-1)}{e^{{\\overline{\\delta}_{i}}}-e^{-{\\underline{\\delta}_{i}}}}>0 . \\end{split}\\ ] ] additionally , if @xmath201 in such a way that @xmath202 is bounded away from 0 and @xmath70 ( i.e. @xmath203 ) , the previous expressions simplify to @xmath204    the proof is presented in the appendix .",
    "the analysis of the classical sprt algorithm relies on wald s ( second ) identity . in order to be able to analyze the d - sprt",
    ", it turns out that we need an equivalent result .",
    "the next lemma introduces a version of wald s second identity that is suitable for our needs .",
    "[ lem:1 ] let @xmath28 denote the sequence of sampling times generated by the lebesgue sampling scheme in sensor @xmath0 .",
    "consider a sequence @xmath205 of i.i.d .",
    "random variables where each @xmath206 is a function of the samples @xmath207 acquired by the sensor during the @xmath208th intersampling period and assume @xmath209<\\infty$ ] .",
    "if @xmath46 denotes any @xmath51-adapted stopping time which is a.s .",
    "finite with finite expectation and @xmath210 is the number of sampling times @xmath23 occurred up to and including time @xmath46 then , for @xmath77 we have @xmath211={{\\sf e}}_j[\\zeta_1^i]({{\\sf e}}_j[m_{t}^i]+1).\\ ] ]    the proof is presented in the appendix .",
    "one might wonder why is it necessary to set the upper limit in to @xmath212 instead of the classical @xmath210 we encounter in wald s original identity .",
    "unfortunately if the upper limit is replaced by @xmath210 then in the proof ( specifically in ) the random variable @xmath206 will be combined with @xmath213 instead of @xmath214 . as it turns out , these two quantities are not necessarily independent",
    "as is the case between @xmath206 and @xmath214 and therefore wald s identity can not be assured .",
    "if we change the upper limit to @xmath215 then we can write two useful estimates that are an immediate consequence of lemma[lem:1 ] and are presented , without proof , in the next corollary .",
    "[ cor:1 ] let @xmath216 and @xmath210 be as in lemma[lem:1 ] , then    i ) . for @xmath217",
    "we have @xmath218\\le{{\\sf e}}_j[\\zeta_1^i]({{\\sf e}}_j[m_{t}^i]+1).\\ ] ]    ii ) .",
    "if @xmath205 is a sequence with @xmath219 for all @xmath208 , then @xmath220-{{\\sf e}}_j[\\zeta_1^i]{{\\sf e}}_j[m_{t}^i]\\right|\\le 2m.\\ ] ]    unlike in continuous time , due to the overshoot effect , there is now an accumulation of errors which results in the difference @xmath221 being unbounded and no longer limited by a constant .",
    "however , by properly selecting the local thresholds , we will see that we can force this difference grow at a much slower pace than each of its components @xmath222 . in turn",
    "this possibility will allow us to prove interesting asymptotic optimality properties for the d - sprt in discrete time .",
    "since the difference of the two statistics plays a crucial role in our analysis with the next lemma we obtain an estimate of its size .",
    "[ lem:2 ] if @xmath188 is the sequence of overshoots generated by the the lebesgue sampling mechanism at sensor @xmath0 , then for any @xmath51-adapted stopping time @xmath46 we have @xmath223\\le\\max_i{{\\sf e}}_j[|\\eta_1^i|]\\left(\\frac{|{{\\sf e}}_j[\\tilde{u}_t]|+2c'}{\\min_i i_j^i}+k\\right)+c,\\ ] ] where @xmath224 and @xmath225 .",
    "the proof makes use of corollary1 and it is presented in the appendix .      we have concluded the presentation of the background material that is necessary for establishing our main optimality results . before going to the next theorem that introduces a key estimate for the performance of d - sprt , we would like to introduce an additional quantity that expresses the order of magnitude of the local thresholds .",
    "we will assume that there exists a quantity @xmath226 such that for all @xmath0 we have @xmath227 and @xmath228 .",
    "this is necessary , because in order to establish the desired asymptotic optimality property , at some point we will require the local thresholds to tend to infinity . with this assumption",
    "all local thresholds increase at the same rate . after this clarification we can now state out next key theorem .",
    "[ th:2 ] let @xmath229 denote that stopping times for the centralized sprt and d - sprt respectively , we then have the following estimate for the thresholds of d - sprt @xmath230 additionally , for @xmath77 , we can write @xmath231    the proof is very technical and it is presented in sufficient detail in the appendix .",
    "we note that is the analog of in discrete time .",
    "in fact it constitutes a better approximation than but at the expense of a ( significantly ) more involved proof .",
    "inequality refers to the difference of the k - l divergences between the sprt stopping time @xmath66 and the d - sprt stopping time @xmath232 . since we are in the i.i.d .",
    "case we know that the k - l divergence is proportional to the expected delay and the proportionality factor is simply the k - l information number .",
    "theorem[th:2 ] will be the starting point for establishing our asymptotic optimality results .",
    "let us continue by first attempting to recover the continuous time analog .",
    ": continuous time corresponds to `` high sampling '' or , in our terminology , to a size @xmath180 tending to 0 .",
    "the question of course is what should the rate of convergence of @xmath180 towards 0 be , in order to assure the desired form of asymptotic optimality .",
    "assuming @xmath233 , in other words that the local thresholds are of the order of a nominal constant , we realize from that we need @xmath234 to reduce the right hand side in into a quantity of the order of a constant .",
    "in other words , as we decrease the two error probabilities @xmath56 we also need to decrease the size of the overshoot .",
    "what is however worth emphasizing is that the rate by which the size of the overshoot needs to go to 0 is _ much slower _ than the rate of the error probabilities .",
    "this suggests that a small change in @xmath180 corresponds to a significant change in the error probabilities .",
    ": of course the most crucial question is what happens if @xmath180 is considered nominal and we are allowed to play with the size @xmath226 of the local thresholds .",
    "it is clear that in this case overly small local thresholds will induce frequent communication with the fusion center thus resulting in rapid error accumulation due to the overshoot effect .",
    "if we go through the proof of theorem[th:2 ] we realize that this part is captured by the first term in the right hand side of .",
    "if on the other hand we use overly large local thresholds then this will generate long detection delays due to infrequent communication with the fusion center and to coarse time resolution .",
    "this part is captured by the second term in .",
    "clearly there is a compromising value for the local threshold size @xmath226 that can optimize the performance of the test .    attempting to discover the best threshold ,",
    "consider the ratio @xmath235-{{\\sf e}}_j[{\\mathscr{t}}]}{{{\\sf e}}_j[{\\mathscr{t}}]}&=\\frac{|{{\\sf e}}_j[u_{\\tilde{{\\mathscr{t}}}}]-{{\\sf e}}_j[u_{{\\mathscr{t}}}]|}{|{{\\sf e}}_j[u_{{\\mathscr{t}}}]|}\\\\ & \\le\\frac{\\theta}{\\theta(\\delta)}+\\frac{\\theta(\\delta)}{|\\log\\alpha|}. \\end{split}\\ ] ] if we set @xmath181 and let @xmath236 but at a rate such that @xmath237 then the right hand side of tends to 0 establishing order-1 asymptotic optimality .",
    "after some simple reasoning we can deduce that the best choice is @xmath238 which equates the two terms in , yielding @xmath239-{{\\sf e}}_j[{\\mathscr{t}}]}{{{\\sf e}}_j[{\\mathscr{t}}]}\\le\\theta\\left(\\frac{1}{\\sqrt{|\\log\\alpha}|}\\right).\\ ] ] the optimal value we obtained for @xmath226 is the optimum local threshold size , expressed in an `` order of magnitude '' form . observe also that the convergence rate to 0 of the right hand side in the previous expression is of the same order as the one obtained in @xcite .",
    "if we are now allowed to play with both , the size @xmath180 of the overshoot but also the local threshold size @xmath226 , then our previous result can be ameliorated significantly . indeed from we can see that the optimum size for @xmath226 is now @xmath240 which yields @xmath239-{{\\sf e}}_j[{\\mathscr{t}}]}{{{\\sf e}}_j[{\\mathscr{t}}]}\\le\\theta\\left(\\sqrt{\\frac{\\theta}{|\\log\\alpha|}}\\right).\\ ] ] selecting @xmath180 to tend to 0 as a function of the error probability @xmath157 makes the right hand side of the previous expression to tend to zero faster than @xmath241 .",
    "this theoretical result has a very useful practical implication .",
    "specifically , we deduce that by selecting samples which generate smaller sized overshoots , results in a d - sprt performance improvement .",
    "as we will see in our simulations , this important characteristic is not enjoyed by mei s decentralized scheme @xcite .      before going to our simulations",
    "let us find a way to relate the overshoot size @xmath242 $ ] to the log - likelihood ratio @xmath243 of a sample .",
    "since our processes are stationary , we will consider only the case @xmath244 . recall that @xmath245 , therefore @xmath246 note now that we can write @xmath247 where @xmath248 using these definitions the overshoot takes the form @xmath249 from which we can easily deduce that @xmath250\\le{{\\sf e}}_0[-(u_{\\underline{\\tau}_1^i}^i+{\\underline{\\delta}_{i}})]+ { { \\sf e}}_1[u_{\\overline{\\tau}_1^i}^i-{\\overline{\\delta}_{i}}].\\ ] ] from ( * ? ? ?",
    "* theorem3 ) we have for @xmath251 that @xmath252&\\le\\left[\\frac{r+2}{r+1}\\frac{{{\\sf e}}_0[|\\ell_1^i|^{r+1}]}{|{{\\sf e}}_0[\\ell_1^i]|}\\right]^{1/r}\\\\ \\sup_{{\\overline{\\delta}_{i}}>0}{{\\sf e}}_1[u_{\\overline{\\tau}_1^i}^i-{\\overline{\\delta}_{i}}]&\\le\\left[\\frac{r+2}{r+1}\\frac{{{\\sf e}}_1[|\\ell_1^i|^{r+1}]}{|{{\\sf e}}_1[\\ell_1^i]|}\\right]^{1/r } , \\end{split}\\ ] ] where we have used the fact that for a nonnegative random variable @xmath253 and any @xmath251 we have @xmath254\\le({{\\sf e}}[x^r])^{1/r}$ ] .",
    "we would like to point out that with @xmath255 is the most common selection for fabricating bounds for the overshoot ( see @xcite ) .",
    "unfortunately this value does not always produce upper bounds that tend to 0 when the corresponding log - likelihood size tends to 0 .",
    "this is the reason why we had to resort to this more general form of upper bound .",
    "we illustrate our ideas by performing a simulation experiment with @xmath165 sensors , each one observing a brownian motion .",
    "the hypothesis testing problem we would like to solve is in the context of the problem defined in , that is , under @xmath151 we have a standard wiener process in each sensor while under @xmath88 a brownian motion with constant drift @xmath256 .",
    "we select the two drifts to be equal to 1 , that is , @xmath166 .",
    "the continuous time processes are sampled using canonical deterministic sampling with a sampling period @xmath169 , thus generating the discrete time sequence of normally distributed samples @xmath34 in each sensor . clearly under @xmath151",
    "we have that @xmath257 whereas @xmath258 under the alternative hypothesis @xmath88 .",
    "the size of our samples is a function of the sampling period @xmath169 and tends to 0 as @xmath259 .",
    "let us use to verify that the overshoot tends to 0 as well .",
    "forming the log - likelihood ratio we find @xmath260 and computing the upper bound in for @xmath255 yields @xmath261 which , clearly , does not converge to 0 when @xmath259 .",
    "if however we select @xmath262 then the upper bound turns out to be @xmath263 which tends to 0 with @xmath169 .",
    "consequently @xmath264 can play the role of @xmath180 .",
    "we compare the discrete time d - sprt with the optimal discrete time sprt and also with the test suggested by mei in @xcite , which is asymptotically optimal of order-1 . to confirm the close connection of the d - sprt to the size of the samples ( or the overshoot ) , we have selected two values for the sampling period , namely @xmath265 and 0.1 . for the local thresholds we also considered two values , specifically @xmath266 and 2 .",
    "sensors and testing between @xmath167 normal @xmath267 and @xmath168 normal @xmath268 random variables with ( a ) @xmath269 and ( b ) @xmath270 . ]",
    "0.2 cm     sensors and testing between @xmath167 normal @xmath267 and @xmath168 normal @xmath268 random variables with ( a ) @xmath269 and ( b ) @xmath270 . ]",
    "fig.[fig:3 ] depicts the k - l divergence of the competing schemes .",
    "we recall that in this case the k - l divergence is proportional to the expected detection delay .",
    "the reason that we decided to present the former measure instead of the latter is because the k - l divergence is independent of the size of the samples while the detection delay varies drastically with this quantity ( smaller samples tend to need more time to reach the same threshold ) .",
    "we observe that d - sprt exhibits a notable performance improvement when we go from the value @xmath265 to @xmath270 .",
    "this is in complete accordance with our previous analysis since @xmath270 generates likelihood ratios and overshoots of smaller size than @xmath265 .",
    "the optimum sprt on the other hand and mei s scheme are relatively insensitive to this change of size in the samples . for d - sprt , it is basically the error accumulation expressed though the difference @xmath271 that improves as we use smaller @xmath169 , incurring an overall performance improvement .",
    "what is also worth emphasizing for the d - sprt is that the communication frequency ( expressed in continuous time ) between the sensors and the fusion center _ stays relatively unchanged _ under both values of @xmath169 while in the other two schemes it increases by a factor of 10 .",
    "finally , in fig.[fig:3 ] we can also observe that the performance of the d - sprt , as a function of the local threshold value @xmath272 , is not monotone . indeed , case @xmath273 is better than @xmath233 for smaller values of @xmath157 .",
    "additionally , the error probability values where @xmath273 prevails are increasing with the size of the samples .",
    "this performance can be explained by our analysis .",
    "we recall that the optimum local threshold is @xmath274 suggesting that the error probability where any specific @xmath226 is optimum is roughly @xmath275 .",
    "consequently , a larger threshold delivers better performance at a smaller error probability and this value is an increasing function of the size @xmath180 of the samples .",
    "we have presented and rigorously analyzed a decentralized scheme for sequential hypothesis testing .",
    "the detection structure relies on a local sprt implemented at each sensor which is used for random sampling of the observed data stream .",
    "this sampling scheme naturally induces a 1-bit communication protocol between the sensors and the fusion center which is asynchronous , a very practically desirable characteristic . by performing a detailed analysis",
    "we were able to prove interesting asymptotic optimality properties for the proposed test and reveal its ability to improve performance when oversampling is used at the sensor level .",
    "overall , our decentralized detection method exhibits performance that can be very close to the optimum centralized test , outperforming other decentralized tests of the literature .",
    "_ proof of lemma[lem:01 ] _ : to prove the lemma note that @xmath276.\\ ] ] since @xmath277\\le e^{-{\\underline{\\delta}_{i}}},\\ ] ] this proves . for , using jensen s inequality in , we can write @xmath278\\ge e^{-{\\underline{\\delta}_{i}}}e^{-{\\mathscr{d}}}\\ ] ] where @xmath279\\\\ & = \\frac{{{\\sf e}}_0[-(u_{\\tau_n^i}^i - u_{\\tau_{n-1}^i}^i+{\\underline{\\delta}_{i}}){\\mathbbm{1}_{\\{u_{\\tau_n^i}^i - u_{\\tau_{n-1}^i}^i\\le-{\\underline{\\delta}_{i}}]\\ } } } ] } { { { \\sf p}}_0(u_{\\tau_n^i}^i - u_{\\tau_{n-1}^i}^i\\le-{\\underline{\\delta}_{i}})}\\\\ & = \\frac{{{\\sf e}}_0[-(u_{\\tau_n^i}^i - u_{\\tau_{n-1}^i}^i+{\\underline{\\delta}_{i}}){\\mathbbm{1}_{\\{u_{\\tau_n^i}^i - u_{\\tau_{n-1}^i}^i\\le-{\\underline{\\delta}_{i}}]\\ } } } ] } { 1-{{\\sf p}}_0(u_{\\tau_n^i}^i - u_{\\tau_{n-1}^i}^i\\ge{\\overline{\\delta}_{i}})}\\\\ & \\le\\frac{\\theta}{1-e^{-{\\overline{\\delta}_{i } } } } , \\end{split}\\ ] ] where in the last inequality we used the fact that the numerator is an overshoot and therefore bounded by @xmath180 and in the denominator we used wald s approximation ( which provides an upper bound ) for the error probability of the local sprt exiting from the wrong side . replacing the bound for @xmath280 in , taking the logarithm and recalling",
    "we conclude @xmath281 assuming that @xmath132 is bounded away from 0 , the previous right hand side becomes @xmath282 and proves the lemma .",
    "_ proof of lemma[lem:02 ] _ : let us prove the first inequality in .",
    "note that @xmath283=\\frac{{\\underline{\\lambda}_{i}}(e^{{\\overline{\\lambda}_{i}}}-1)+{\\overline{\\lambda}_{i}}(e^{-{\\underline{\\lambda}_{i}}}-1)}{e^{{\\overline{\\lambda}_{i}}}-e^{-{\\underline{\\lambda}_{i}}}}>0.\\ ] ] by direct differentiation we can verify that the function @xmath284 is monotonically increasing in both its arguments , when @xmath285 .",
    "consequently from , namely that @xmath187 exceed @xmath134 respectively , we immediately deduce the final inequality .",
    "proving is straightforward .",
    "_ proof of lemma[lem:1 ] _ : for simplicity we drop the subscript @xmath286 that refers to the true hypothesis .",
    "we observe that @xmath287={{\\sf e}}\\left[\\sum_{n=1}^\\infty\\zeta_n{\\mathbbm{1}_{\\{m_{t}^i\\ge n-1\\}}}\\right].\\ ] ] note that @xmath288 . by recalling that @xmath289 is an @xmath24-adapted stopping time",
    ", this suggests that it is also @xmath51-adapted . because of the latter observation we can assess that the event @xmath290 is @xmath291-measurable ( since @xmath292 is @xmath293-measurable , this being true even if @xmath294 is an @xmath51-adapted stopping time ) .",
    "consequently @xmath206 is independent of @xmath214 .",
    "interchanging summation and expectation and using independence in , we immediately obtain the desired equality .",
    "the careful reader will of course argue that we can not interchange summation and integration so freely . indeed this is absolutely true .",
    "we can however write @xmath295 and for each component the interchange is possible requiring only @xmath296<\\infty$ ] and @xmath297<\\infty$ ] , which of course is satisfied iff @xmath298<\\infty$ ] , for the lemma to be true",
    ".    _ proof of lemma[lem:2 ] _ : to prove note that @xmath299 . using",
    "we observe that we can write @xmath300 . now",
    "note that if @xmath129 exits from the lower end then @xmath301-\\lambda_n^i|=|[u_{\\tau_n^i}^i - u_{\\tau_{n-1}^i}^i]+{\\underline{\\lambda}_{i}}|\\le|[u_{\\tau_n^i}^i - u_{\\tau_{n-1}^i}^i]+{\\underline{\\delta}_{i}}|$ ] , with the last inequality coming from .",
    "similarly if @xmath129 exits from the upper end then @xmath301-\\lambda_n^i|\\le|[u_{\\tau_n^i}^i - u_{\\tau_{n-1}^i}^i]-{\\overline{\\delta}_{i}}|$ ] . in both cases",
    "we see that @xmath301-\\lambda_n^i|\\le|\\eta_n^i|$ ] , with @xmath302 the overshoot defined in .",
    "consequently we can further upper bound using the overshoot . replacing @xmath17 with",
    "@xmath46 then taking expectation and using from corollary[cor:1 ] , we obtain @xmath303&\\le{\\underline{\\delta}_{i}}+{\\overline{\\delta}_{i}}+{{\\sf e}}[|\\eta_n^i|]({{\\sf e}}[m_t^i]+1)\\\\ & \\le{\\underline{\\delta}_{i}}+{\\overline{\\delta}_{i}}+\\max_i{{\\sf e}}[|\\eta_n^i|]({{\\sf e}}[m_t^i]+1 ) . \\end{split}\\ ] ] summing over @xmath0 yields @xmath304\\le\\max_i{{\\sf e}}[|\\eta_n^i|]\\left(\\sum_{i=1}^k{{\\sf e}}[m_t^i]+k\\right)+c.\\ ] ]    using now we can write @xmath305=-{{\\sf e}}_0\\left[\\sum_{n=1}^{m_t^i}\\lambda_n^i \\right]\\ge-{{\\sf e}}_0[\\lambda_n^i]{{\\sf e}}_0[m_t^i]-2({\\underline{\\lambda}_{i}}+{\\overline{\\lambda}_{i}}),\\ ] ] where for the last inequality we used of corollary[cor:1 ] and the fact that @xmath306 .",
    "since by definition @xmath307 $ ] is the k - l information number for the random sequence @xmath199 we strengthen the inequality by minimizing over @xmath0 . summing the result over @xmath0 yields",
    "@xmath308\\ge(\\min_i i_o^i)\\sum_{i=1}^k{{\\sf e}}_0[m_t^i]-2c'\\ ] ] solving for the sum and replacing in yields the desired inequality under @xmath151 .",
    "similar proof applies under @xmath88 .",
    "_ proof of theorem[th:2 ] _ : the proof of this theorem is very challenging . in fact , as we will see , the most important part is demonstrating the validity of the estimates in .",
    "we recall that in the synchronous case , at _ each _ time instant @xmath17 , we have information arriving at the fusion center from all sensors .",
    "this scenario can be easily described through i.i.d .",
    "statistics across time .",
    "here however , due to the asynchronous communication , this is no longer as straightforward .    in order to solve this problem ,",
    "let us concentrate on one sensor ( say @xmath0 ) .",
    "we know that this sensor sends the sequence of bits @xmath21 to the fusion center but also , indirectly , the sequence of intersampling periods @xmath145 .",
    "the sequence of pairs @xmath65 is adequate to fully describe sensor s @xmath0 transmission activity to the fusion center . note that these pairs are i.i.d .  across time and",
    "independent across sensors .",
    "let us denote with @xmath309 the joint pdf of the pair @xmath41 where , as usual , @xmath77 refers to the true hypothesis .",
    "we recall that @xmath310 since @xmath29 is a 1-bit information .",
    "we can now write the joint pdf as @xmath311 where @xmath312 is the probability that sensor @xmath0 transmits the bit @xmath313 under hypothesis @xmath112 .",
    "similarly @xmath314 is the pdf of @xmath315 at sensor @xmath0 _ given _ that @xmath313 under hypothesis @xmath112 .",
    "for example @xmath316 denotes the pdf of the intersampling period _ given _ that the local sprt exits from the lower end .",
    "the marginal pdf of the intersampling periods @xmath315 is simply @xmath317    suppose now that we are at time @xmath17 and that the fusion center observes @xmath318 data pairs coming from sensor @xmath0 .",
    "we have that @xmath319 where @xmath320 .",
    "let us now define the likelihood of the following event : `` up to time @xmath17 , the fusion center observes the following @xmath318 pairs @xmath321 '' . using the independence of the pairs across time",
    ", we can write @xmath322\\left(\\prod_{n=1}^kp_j^i(z_n^i,\\delta_n^i)\\right){\\mathbbm{1}_{\\{\\tau_k^i\\le t\\ } } } , \\end{split}\\ ] ] where @xmath323 is the cdf of @xmath315 and @xmath324 is the marginal pdf defined in .",
    "the previous likelihood can be decomposed as follows @xmath325\\prod_{n=1}^kg_j^i(\\delta_n^i|z_n^i){\\mathbbm{1}_{\\{\\tau_k^i\\le t\\}}}\\right ) .",
    "\\end{split}\\ ] ] the first part is the likelihood of the 1-bit data @xmath326 and the second the likelihood of the intersampling periods @xmath327 _ conditioned _ on the 1-bit data @xmath326 .",
    "if @xmath328 denotes the @xmath44-algebra generated by the pairs @xmath65 received up to time @xmath17 , then the likelihood ratio between the two probability measures for sensor @xmath0 can be written as @xmath329 where @xmath330\\prod_{n=1}^kg_j^i(\\delta_n^i|z_n^i){\\mathbbm{1}_{\\{\\tau_k^i\\le t\\ } } } \\end{split}\\ ] ] expresses the likelihood of the intersampling periods conditioned on the 1-bit data , under hypothesis @xmath112 .",
    "combining all sensors and using their independence , we end up with the following likelihood ratio that refers to the complete information @xmath331 received by the fusion center until time @xmath17 @xmath332 with @xmath333 denoting the _ likelihood ratio _ of the intersampling periods conditioned on the 1-bit data , namely @xmath334 we are now in a position to prove .",
    "consider the first inequality .",
    "we have @xmath335\\\\ & = { { \\sf e}}_0[e^{\\tilde{u}_{\\tilde{{\\mathscr{t}}}}}\\times   { \\mathscr{l}}_{\\tilde{{\\mathscr{t}}}}{\\mathbbm{1}_{\\{\\tilde{u}_{\\tilde{{\\mathscr{t}}}}\\le-\\tilde{a}\\ } } } ] \\le e^{-\\tilde{a}}{{\\sf e}}_0 [ { \\mathscr{l}}_{\\tilde{{\\mathscr{t } } } } ] = e^{-\\tilde{a}}. \\end{split}\\ ] ] the last equality is true because @xmath336&={{\\sf e}}_0\\left[{{\\sf e}}_0\\left [ { \\mathscr{l}}_{\\tilde{{\\mathscr{t}}}}|z_1 ^ 1,\\ldots , z_{m^1_{\\tilde{{\\mathscr{t}}}}}^1,\\ldots , z_1^k,\\ldots , z_{m^k_{\\tilde{{\\mathscr{t}}}}}^k\\right]\\right]\\\\ & = { { \\sf e}}_0\\left[{{\\sf e}}_1\\left[1|z_1 ^ 1,\\ldots , z_{m^1_{\\tilde{{\\mathscr{t}}}}}^1,\\ldots , z_1^k,\\ldots , z_{m^k_{\\tilde{{\\mathscr{t}}}}}^k\\right]\\right]=1 .",
    "\\end{split}\\ ] ] this proves the first inequality .",
    "the second can be proven in an analogous way .    to prove the second part of the theorem ,",
    "namely , again we consider the inequality under @xmath151 .",
    "note that @xmath337\\ge{{\\sf e}}_0[\\tilde{u}_{\\tilde{{\\mathscr{t}}}}]-{{\\sf e}}_0[|u_{\\tilde{{\\mathscr{t}}}}-\\tilde{u}_{\\tilde{{\\mathscr{t}}}}|].\\ ] ] using from lemma[lem:2 ] the inequality becomes @xmath338\\ge(1+\\phi){{\\sf e}}_0[\\tilde{u}_{\\tilde{{\\mathscr{t}}}}]-c-2\\phi c'-k\\max_i{{\\sf e}}_0[|\\eta_n^i|],\\ ] ] where @xmath339)/(\\min_i i_0^i)$ ] .",
    "as in the continuous time case , we have @xmath340 and using we can write @xmath341 which also implies @xmath342\\ge-|\\log\\beta|-c'$ ] . replacing the latter in results in @xmath343+|\\log\\beta|\\hskip-2.1cm&\\\\ & \\ge-\\phi|\\log\\beta|-(1 + 3\\phi)c'-c - k\\max_i{{\\sf e}}_0[|\\eta_n^i| ]",
    ". \\end{split}\\ ] ] if we replace , in the left hand side of the previous inequality , @xmath163 with the optimum performance @xmath156 $ ] , because of , we strengthen the inequality obtaining @xmath344)-(-{{\\sf e}}_0[u_{{\\mathscr{t}}}])\\\\ & ~~~\\le\\phi|\\log\\beta|+(1 + 3\\phi)c'+c+k\\max_i{{\\sf e}}_0[|\\eta_n^i|]+o(1 ) .",
    "\\end{split}\\ ] ]    note now that @xmath345 and for the overshoot we have @xmath346\\le\\theta$ ] . in our analysis",
    "we consider @xmath226 to be , either of the order of a constant or to tend to infinity and @xmath180 to be either of the order of a constant or to tend to 0 . because of this assumption and lemma[lem:01 ] we have @xmath187 that are @xmath347 meaning that @xmath348 . because of lemma[lem:02 ] , we conclude that @xmath349 , consequently @xmath350 . substituting these order of magnitudes in yields @xmath351)-(-{{\\sf e}}_0[u_{{\\mathscr{t}}}])\\hskip-2.5cm&\\\\ & = \\frac{\\theta}{\\theta(\\delta)}|\\log\\beta|+\\theta(\\delta)+o(\\theta)+o(1 ) .",
    "\\end{split}\\ ] ] finally due to the relative size of @xmath226 and @xmath180 we can also conclude that @xmath352 which proves the desired version of the inequality .",
    "similar steps can be applied to prove the theorem under hypothesis @xmath88 ."
  ],
  "abstract_text": [
    "<S> we present a test for the problem of decentralized sequential hypothesis testing , which is asymptotically optimum . by selecting a suitable sampling mechanism at each sensor , communication between sensors and fusion center </S>",
    "<S> is asynchronous and limited to 1-bit data . </S>",
    "<S> the proposed sprt - like test turns out to be order-2 asymptotically optimum in the case of continuous time and continuous path signals , while in discrete time this strong asymptotic optimality property is preserved under proper conditions . </S>",
    "<S> if these conditions do not hold , then we can show optimality of order-1 . </S>",
    "<S> simulations corroborate the excellent performance characteristics of the test of interest .    </S>",
    "<S> fellouris and moustakides : decentralized sequential hypothesis testing    sequential hypothesis testing , sprt , decentralized detection . </S>"
  ]
}