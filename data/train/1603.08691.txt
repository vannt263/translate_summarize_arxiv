{
  "article_text": [
    "when analysing the ( co)variation of a real random function @xmath5 over a continuous compact domain @xmath6 , it can be broadly said that one may distinguish two layers of variation .",
    "the first is _",
    "amplitude variation_. this is the `` classical '' variation that one would also encounter in multivariate analysis , and refers to the stochastic fluctuations around a mean level , usually encoded in its covariance kernel , at least up to second order . in short , this is variation `` in the @xmath1-axis . ''",
    "the second layer of variation is a non - linear variation peculiar to continuous domain stochastic processes , and is rarely  if ever  encountered in multivariate analysis .",
    "it arises as the result of random changes ( or deformations ) in the time scale ( or the spatial domain ) of definition of the process .",
    "it can be conceptualised as a composition of the stochastic process with a random transformation acting on its domain , or as variation `` in the @xmath2-axis , '' typically referred to as a _ warp function_. the terminology on amplitude / phase variation is adapted from trigonometric functions , which may vary in amplitude or phase .",
    "phase variation arises quite naturally in the study of random phenomena where there is no absolute notion of time or space , but every realisation of the phenomenon evolves according to a time - scale that is intrinsic to the phenomenon itself , and ( unfortunately ) unobservable .",
    "processes related to physiological measurements ( such as growth curves , neuronal signals , or brain images ) , are usual suspects , where phase variability arises at the level of individual ( see the extensive discussion in ramsay and silverman @xcite ) ; but examples abound in diverse fields of application of stochastic processes , perhaps quite prominently in environmental sciences ( e.g. , sampson and guttorp @xcite , and references therein ) and pattern recognition ( for instance , handwriting analysis , e.g. , ramsay @xcite , or speech analysis , e.g. , hadjipantelis , aston and evans @xcite ) .",
    "natural as the confluence of these two types of variation may be , failing to recognise and correct for their entanglement can obscure or even entirely distort the findings of a statistical analysis of the random function ( see section  [ sec : fda ] ) .",
    "consequently , it is an important problem to be able to separate the two , thus correctly accounting for the distinct contribution of each .",
    "if one is able to only observe a single realisation of the random function @xmath7 in question , the separation problem is not well - defined unless further modelling assumptions are introduced .",
    "for example , one could assume that a process should be stationary or otherwise have some invariance property in the @xmath2-domain that is measurably perturbed by the phase variation ; and attempt to unwarp it on the basis of this assumption .",
    "such models can be found in the analysis of random fields ( see , e.g. , sampson and guttorp @xcite , anderes and stein @xcite , anderes and chatterjee @xcite ) , and of points processes alike ( see , e.g. , schoenberg @xcite , senoussi , chadoef and allard @xcite ) .    in the field of functional data analysis , however , one has the good fortune of being able to observe multiple i.i.d .",
    "realisations @xmath8 of the random function in question . when this is the case , one may attempt to separate phase and amplitude variation under less stringent assumptions  in fact in a nonparametric fashion . indeed , there is a substantial amount of work on this topic in the field of functional data , as the problem is in some sense one of the distinguishing characteristics of fda as compared to multivariate statistics ( see section  [ sec : fda ] ) .",
    "the purpose of this paper is to investigate the problem of separation of amplitude and phase variation in the case where one observes multiple realisations @xmath9 of _ random point processes _ rather than _",
    "random functions_. though the study of multiple realisations of point processes has been considered prior to the emergence of fda ( see , e.g. , karr @xcite ) , treating realisations of point processes as individual data objects within a functional data analysis context is a more recent development offering important advantages ; a key paper is that of wu , mller and zhang @xcite ( also see chiou and mller @xcite and chiang , wang and huang @xcite ) .",
    "such data may be an object of interest in themselves ( see , e.g. , wu , mller and zhang @xcite , arribas - gil and mller @xcite , wu and srivastava @xcite ) but may also arise as landmark data in an otherwise classical functional data analysis ( see , e.g. , gasser and kneip @xcite , arribas - gil and mller @xcite ) .",
    "the recent surge of interest is exemplified in an upcoming discussion paper by wu and srivastava @xcite , whose discussion documents early progress and challenges in the field .",
    "one of the main complications arising in the point process case is that a point processes , when viewed as a single _ datum _ , is a discrete random measure .",
    "the nature of such a datum gives rise to different sets of challenges as compared to fda .",
    "their ambient space is not a vector space , so point process variation  whether due to amplitude or phase  is intrinsically non - linear , calling for an analysis either via a suitable transformation , or via consideration of an alternative space where their covariation structure can be suitably analysed .",
    "nevertheless , this special nature can be seen as a blessing , rather than a curse , as the case of point processes enjoys important advantages that considerably simplify the analysis relative to more general functions .",
    "specifically , we argue that the problem of amplitude and phase variation in point process data admits a _ canonical _ framework through the theory of optimal transportation of measure . indeed",
    ", we show that this formulation follows unequivocally when employing the classical phase variation assumptions of functional data analysis to the point process case ( section  [ sec : phase_principles ] , assumptions [ classical_assumptions ] ) .",
    "these are proven to be _ equivalent _ to a geometrical characterisation of the problem by means of geodesic variation around a frchet mean with respect to the wasserstein metric ( section  [ sec : geometry ] , proposition  [ prop : assumptions ] ) .",
    "we show that the special nature of the problem in the case of point processes renders it identifiable ( section  [ sec : geometry ] , proposition  [ prop : uniqueness ] ) and also allows for the elucidation of what `` over '' and `` under '' registering means , through a notion of _ unbiased registration _",
    "( section  [ sec : optimality ] ) .",
    "we construct easily implementable _ nonparametric _ estimators that separate amplitude and phase ( section  [ sec : estimation ] ) and develop their asymptotic theory , establishing consistency in a genuinely nonparametric framework ( section  [ sec : asymptotics ] , theorem  [ thm : consistency ] ) even under sparse sampling ( remark  [ sparse_remark ] ) . in the special case of cox processes",
    "( randomly warped poisson processes , see section  [ sec : cox ] ) , we derive rates of convergence ( theorem  [ thm : rate ] ) , and provide conditions for @xmath4-consistency .",
    "we also obtain a central limit theorem for the estimator of the structural mean ( theorem  [ thm : asynorm ] ) , which shows our estimator attains the optimal rate under dense sampling and allows for uncertainty quantification ( remark  [ rem : uq ] ) .",
    "the finite sample performance methodology is illustrated by means of examples in section  [ sec : examples ] , and a simulation study in the supplementary material @xcite .",
    "in order to motivate our framework for modelling amplitude and phase variation in point processes , we first revisit the case of functional data , that is , @xmath10 independent realisations of a random element of @xmath11 $ ] , say @xmath12 ; i=1,\\ldots , n\\}$ ] .",
    "one typically understands _ amplitude variation _ as corresponding to linear stochastic variability in the observations . that is , assuming that the mean function is @xmath13 $ ]",
    ", amplitude variation enters the model through @xmath14 where the @xmath15 are mean zero i.i.d .",
    "stochastic processes with covariance kernel @xmath16 , typically assumed to be continuous ( equivalently , @xmath17 are assumed continuous in mean square ) . in this setup , the covariation structure of @xmath18 can be probed by means of the karhunen  love expansion , @xmath19 the optimal fourier representation of @xmath18 in the ortho - normal system of eigenfunctions of @xmath20 .",
    "the equality is understood in @xmath21mean square , uniformly in @xmath2 .",
    "this expansion explains the term _ amplitude variation _ : @xmath18 varies about @xmath22 by random amplitude oscillations of the functions @xmath23 .",
    "a key feature of this expansion is the separation of the stochastic component ( in the countable collection @xmath24 ) and the functional component ( in the deterministic collection @xmath23 ) .    on the other hand ,",
    "_ phase variation _ is understood as the presence of non - linear variation .",
    "heuristically , this means that there is an initial random change of time scale , followed by amplitude variation , yielding _ time - warped _",
    "curves @xmath25 , @xmath26 \\\\[-8pt ] \\nonumber & = & \\mu \\bigl(t_i^{-1}(x ) \\bigr)+\\sum_{n=1}^{\\infty } { \\xi_n } { \\varphi_n \\bigl(t_i^{-1}(x ) \\bigr)}.\\end{aligned}\\ ] ] the warp functions @xmath27\\rightarrow[0,1]$ ] are typically assumed to be random _ increasing functions _ independent of the @xmath17 and with @xmath28=x$ ] .",
    "consequently , one has @xmath29 & = & \\mu \\bigl(t^{-1}(x ) \\bigr)=\\widetilde{\\mu}(x);\\\\",
    "\\operatorname{cov } \\bigl\\{\\widetilde { y}(x ) , \\widetilde{y}(y ) \\bigr\\ } & = & \\mathbb{e } \\bigl[\\kappa \\bigl(t^{-1}(x),t^{-1}(y ) \\bigr ) \\bigr ] + \\operatorname{cov } \\bigl\\{\\widetilde{\\mu } ( x),\\widetilde{\\mu}(y ) \\bigr\\},\\end{aligned}\\ ] ] and thus notices that the right - hand side of equation ( [ gaussian_warping ] ) is no longer interpretable as the karhunen ",
    "love expansion of @xmath30 [ the @xmath31 are _ not _ eigenfunctions of the covariance kernel @xmath32 .",
    "indeed , if one ignores phase variation , and proceeds to analyse the @xmath30 s by their own karhunen ",
    "love expansion , the analysis will be seriously distorted : the eigenfunctions will be more diffuse and less interpretable ( owing to the effect of attempting to capture horizontal variation via vertical variation , i.e. , local features by global expansions ) and the spectral decay of the covariance operator will be far slower ( requiring the retention of a larger number of components in an eventual principal component analysis ) .",
    "the data will then usually come in the form of discrete measurements on a grid @xmath33 $ ] subject to additive white noise of variance @xmath34 , @xmath35 assuming of course that the @xmath36 are continuous .",
    "the problem of separation of amplitude and phase variation can now be seen as that of recovering the @xmath37 and @xmath36 from the data @xmath38 , and therefore separating phase variation ( fluctuations of  @xmath37 ) and amplitude variation ( fluctuations of @xmath36 ) . doing so successfully depends on the nature of @xmath39 ( e.g. , to guarantee identifiability ) , the crystallisation of which is a matter of assumption .",
    "specifically , more assumptions are needed further to monotonicity and the expected value being the identity .",
    "indeed , there does not appear to be a single universally accepted formulation . in landmark registration , for example ,",
    "the @xmath39 are estimated by assuming that clearly defined landmarks ( such as local maxima of the curves or their derivatives ) be optimally aligned across curves ( gasser and kneip @xcite ; see also gervini and gasser @xcite for a more flexible setup ) .",
    "template methods iteratively register curves to a template , minimising an overall discrepancy ; the template is then updated , for example , starting from the overall mean ( wang and gasser @xcite ; ramsay and li @xcite ) .",
    "moment - based registration proceeds by an alignment of the moments of inertia of the curves ( james  @xcite ) .",
    "pairwise separation proceeds by iteratively registering pairs of observations by means of a penalised sums of square criterion , and takes advantage of a moment assumption on @xmath39 being the identity on average to derive a global alignment ( tang and mller @xcite ) .",
    "approaches of a semi - parametric flavour assume a functional form for @xmath39 that is known , except for a finite dimensional parameter , and proceed by likelihood methods in a random - effects type setup ( rnn @xcite ; gervini and gasser  @xcite ) .",
    "principal components based registration registers the data so that the resulting curves have a parsimonious representation by means of a principal components analysis ( the `` least second eigenvalue '' principle ; kneip and ramsay  @xcite ) .",
    "elastic registration defines a metric between curves that is invariant under joint elastic deformation of two curves by the same warp function , and registers by means of computing averages with respect to this metric ( tucker , wu and sriastava @xcite ) .",
    "multiresolution methods have also been proposed , leading to the notion of `` warplets '' ( claeskens , silverman and slaets @xcite ) . in recent work ,",
    "marron et al .",
    "@xcite consider comparisons between different registration techniques .",
    "the literature is very rich , and a more in - depth review would be beyond the scope of the present paper",
    ". however , we note that a key conceptual aspect that recurs in several different estimation approaches in the literature is the postulate that a registration procedure should attempt to _ minimise phase variability ( a fit criterion ) _ subject to the constraint that the _ registration maps ought to be smooth and as close to the identity map as possible ( a regularity / parsimony criterion)_. with these key assumptions and principles in mind , we now turn to consider the case of point process data , and see how these ideas might be adapted .",
    "let @xmath40 be a point process on @xmath41 $ ] , viewed as a random discrete measure , with the property that @xmath42 . defining its mean measure as @xmath43 on the collection of borel sets @xmath44 of @xmath41 $ ] , we may understand amplitude variation as being encoded in the _ covariance measure _ , @xmath45-\\lambda(a)\\lambda(b),\\ ] ] a signed radon measure over borel subsets of @xmath41 ^ 2 $ ] .",
    "the covariance measure captures the second order fluctuations of @xmath46 around its mean value @xmath47 , as well as their dependence on the corresponding fluctuations of @xmath48 around @xmath49 .",
    "it naturally generalises the notion of a covariance operator for functional data to the case of point process data . without loss of generality",
    ", we may assume that @xmath47 is renormalised to be a probability measure . in the absence of phase variation , estimation of the covariation structure of @xmath40 on the basis of @xmath10 i.i.d .",
    "realisations @xmath50 can be carried out by means of the empirical versions of @xmath51 and @xmath20 , @xmath52 these are both strongly consistent ( in the sense of weak convergence of measures with probability 1 ) as @xmath53 , and in fact one has the usual central limit theorem in that @xmath54 converges in law to a centred gaussian random measure on @xmath41 $ ] with covariance measure @xmath20 ( see , e.g. , karr @xcite , proposition  4.8 ) .",
    "phase variation may be introduced by direct analogy to the functional case .",
    "assuming that @xmath27\\rightarrow[0,1]$ ] are i.i.d .",
    "random homeomorphisms , warped versions of the @xmath50 can be defined as @xmath55 with @xmath56 the push - forward of @xmath57 through @xmath37 .",
    "it is natural to assume that the collection @xmath58 is independent of the collection @xmath3 . defining the random measures @xmath59",
    ", one also observes that the conditional mean and covariance measures of @xmath57 given @xmath37 are @xmath60 in analogy to the functional case .",
    "furthermore , if @xmath61 is mean - square continuous ( equivalently , if @xmath62 $ ] is continuous ) , we have an expansion similar to that of equation ( [ uniform_convergence_kl ] ) for the compensated process , and the warped compensated process @xmath63 where @xmath64 are the eigenfunctions of @xmath65,[0,t ] \\}$ ] , in analogy with equation ( [ gaussian_warping ] ) .",
    "the task of separation of amplitude and phase variation amounts to constructing estimators @xmath66 and @xmath67 of the random maps @xmath37 and of the unwarped ( registered ) point processes @xmath3 , respectively , on the basis of @xmath68 .",
    "phase variation is then attributed to the @xmath66 and amplitude variation to the @xmath67 . as with the case of random curves ,",
    "if consistent separation is to be achievable , we will need to impose some basic assumptions on the precise stochastic and analytic nature of the @xmath69 .",
    "these will come in the form of _ unbiasedness _ and _",
    "regularity_.    [ classical_assumptions ] the maps @xmath27\\rightarrow[0,1]$ ] are i.i.d .",
    "random homeomorphisms distributed as @xmath39 , independently of the point processes @xmath3 . the random map @xmath39 satisfies the following two conditions :    _ unbiasedness _ : @xmath70=x$ ] almost everywhere on @xmath41 $ ] .",
    "_ regularity _ : @xmath39 is monotone increasing almost surely .",
    "assumption ( a1 ) asks that the average time change @xmath70 $ ] be the identity : on average , the `` objective '' time - scale should be maintained , so that time is not overall sped up or slowed down .",
    "now , since @xmath39 is already a homeomorphism , it is bound to be monotone , either increasing or decreasing . the regularity assumption ( a2 )",
    "asks that @xmath39 represent a proper warping of time ( time change ) : if ( a2 ) were to fail , we would have a time reversal , which is rather problematic in most applied settings .",
    "indeed , these assumptions are arguably _ sine qua non _ in the classical fda phase variation literature , perhaps supplemented with further conditions as discussed earlier .",
    "we will now see that now such further conditions are unnecessary in the point process case , as they _ derive _ from the basic assumptions ( a1 ) and  ( a2 ) .",
    "though our unbiasedness and regularity assumptions stem from first principles related to warping , they in fact are fully compatible with an elegant geometrical interpretation of phase variation  indeed one that opens the way for its consistent separation .",
    "one may consider the space of all diffuse probability measures on @xmath41 $ ] as a metric space , endowed with the so - called @xmath71-wasserstein distance ( also known as mallows distance , or earth - mover s distance ) , @xmath72 where @xmath73 is the collection of mappings @xmath74\\rightarrow[0,1]$ ] such that @xmath75 .",
    "the metric @xmath76 is related to the so - called monge problem of optimally transferring the mass of @xmath22 onto @xmath77 , with the cost of transferring a unit of mass from @xmath2 to @xmath1 being equal to their squared distance , @xmath78 . in the case of diffuse measures",
    "@xmath79 , the infimum in equation ( [ wasserstein_definition ] ) is attained at a unique map @xmath80 that is explicitly given by @xmath81 where @xmath82 , @xmath83 are the cumulative distribution functions corresponding to the two measures , and @xmath84 is the quantile function @xmath85:f_\\nu(y)\\geq p\\}$ ] ( see villani @xcite , chapter  7 ; bickel and freedman @xcite ) . consequently , the optimal map @xmath39 inherits the regularity properties of the measures @xmath86 and @xmath77 , and does not require any further regularising assumptions .",
    "for example , if both measures admit continuous densities strictly positive on @xmath41 $ ] , then @xmath39 is a homeomorphism , but further smoothness assumptions on the densities will carry over to smoothness properties of the optimal maps .    when equipped with the metric @xmath76 ,",
    "the space of all diffuse probability measures on @xmath41 $ ] is a _ length space _ ( also known as _ inner metric space _ ) , and the optimal monge maps @xmath39 , known as optimal transport maps , generate the geodesic structure of this space .",
    "specifically , given any diffuse pair @xmath79 , there is a unique geodesic curve @xmath87\\}$ ] with endpoints @xmath22 and @xmath77 that is explicitly given by @xmath88_{\\#}\\mu,\\qquad t\\in[0,1],\\ ] ] where @xmath39 is the optimal coupling map of @xmath22 and @xmath77 , and @xmath89 is the identity mapping  @xcite , equation ( 5.11 ) .",
    "the following proposition demonstrates how this optimal transportation geometry is inextricably linked with the first principles of phase variation , as encapsulated in assumptions ( a1 ) and ( a2 ) .",
    "[ prop : assumptions ] let @xmath51 have strictly positive density with respect tolebesgue measure on @xmath41 $ ] .",
    "a random map @xmath90\\rightarrow[0,1]$ ] satisfies assumptions and , if and only if it satisfies assumptions and as stated below :    _ unbiasedness _ : given any diffuse probability measure @xmath91 on @xmath41 $ ] , we have @xmath92    _ regularity _ : whenever @xmath93 , for some homeomorphism @xmath74\\rightarrow[0,1]$ ] , it must be that @xmath94    in the optimal transportation geometry , the equivalent assumptions ( b1 ) and ( b2 ) have a clear - cut interpretation .",
    "assumption ( b2 ) implies that the conditional means @xmath95 of the warped processes correspond to perturbations of the structural mean measure @xmath51 along geodesics ( see figure  [ fig : geometry ] ) .",
    "furthermore , in the presence of ( b2 ) , assumption ( b1 ) stipulates that these geodesic perturbations are `` zero mean '' in that the structural mean measure @xmath51 is a frchet mean of the @xmath96 , @xmath97 notice how these assumptions also mimic the additional estimation principles encountered in the phase variation of functional data ( as discussed in the end of section  [ sec : fda ] ) : we ask that the warp maps be such that _ phase variability around the structural mean be minimised our unbiasedness assumption _ subject to the constraint that the _ registration maps deviate as least as possible from the identity map our regularity assumption _ . in this case , however , these principles are _ equivalent _ to the basic assumptions , and do not have to be added as supplementary .",
    "furthermore , the following proposition establishes that if @xmath51 is a frchet mean of each @xmath96 , then it is the unique such fr ' echet mean .",
    "our assumptions , therefore , suffice to guarantee identifiability of the structural mean ( and hence , of the warping maps ) .",
    "we note that the cumulative distribution function of @xmath98 is strictly increasing almost surely , as a composition of two such functions .",
    "[ prop : uniqueness ] let @xmath99 be a diffuse random probability measure on @xmath41 $ ] with a strictly increasing cdf almost surely .",
    "then the minimiser of the functional @xmath100 defined over probability measures @xmath91 on @xmath41 $ ] , exists and is unique .",
    "one should note that postulating that @xmath101 induces phase variation of the conditional mean measure relative to the structural mean measure , @xmath102 .",
    "this is _ not _ equivalent to phase variation at the level of the _ conditional mean density _ , say @xmath103 , relative to the _ structural mean density _ , say @xmath104 .",
    "indeed , if @xmath102 then @xmath105f_{\\lambda } \\bigl(t^{-1}(x ) \\bigr ) , \\qquad   x\\in[0,1].\\ ] ] thus , our framework can not be equivalent to a model that directly models phase variation at the level of densities , by postulating ( say ) that @xmath106 .",
    "in such a model , phase variation immediately induces further amplitude variation , as the lack of a correcting factor @xmath107 means that the new density is no longer a probability density , and thus the total measure of @xmath41 $ ] varies as a result of the variation of @xmath39 ( an overall amplitude variation effect ) .",
    "an example of phase variation at the level of densities is the model of wu and srivastava @xcite , where the smoothed point processes are viewed as random density functions .",
    "these are then registered by employing the ( extended ) fisher  rao metric , using the algorithm of srivastava et al . @xcite .",
    "the authors of @xcite argue that the fisher  rao approach consistently recovers phase variation for models of the type @xmath108 , where @xmath109 is a deterministic function , @xmath110 is a real random variable , and @xmath39 is the phase map . in the particular case where phase variation is of densities ,",
    "the model for the densities becomes @xmath111 comparing the last two displayed equations , we see that the two setups are compatible when the @xmath39 are assumed to be linear maps . in this case , unless @xmath112 almost surely , our two conditions ( a1 ) and ( a2 ) can not be consolidated : if we require @xmath70=x$ ] , for a non - trivial random map ( i.e. , @xmath113>0 $ ] ) , then @xmath39 can not be an almost surely strictly increasing homeomorphism on the finite interval @xmath41 $ ] .",
    "whether phase variation is formalised at the level of measure or density is to some extent a modelling decision .",
    "however , it is worth pointing out that if we wish to understand phase variation as the result of a _ non - linear deformation of the underlying space _ ( e.g. , a smooth deformation of the coordinate system ) , then the model postulating @xmath102 appears to be the natural choice .      just as gaussian processes are the archetypal ones in the analysis of functional data , poisson processes are so when it comes to point processes .",
    "it is hence worth to briefly consider the effect of phase variation as encoded in ( a1 ) and ( a2 ) [ and their equivalent versions ( b1 ) and ( b2 ) ] on a poisson process .",
    "assume that @xmath40 is a poisson point process with mean measure @xmath114 , and let @xmath101 be the warped process , as before .",
    "then , for any disjoint borel sets @xmath115 , the random variables @xmath116 are independent conditional on the random warp map @xmath39 .",
    "this is because @xmath117 must also be disjoint borel sets , combined with the fact that @xmath118 , with @xmath40 being poisson .",
    "furthermore , for any @xmath119 , @xmath120=\\mathbb{p } \\bigl[\\pi \\bigl(t^{-1}(a ) \\bigr)=k|t \\bigr]=e^{-\\lambda(t^{-1}(a))}\\frac{\\lambda ^{k}(t^{-1}(a))}{k!}.\\ ] ] in other words , conditional on @xmath39 , the process @xmath121 is poisson with mean measure @xmath122 .",
    "this establishes that @xmath101 is distributionally equivalent to a _",
    "cox process _ with directing random measure @xmath123 .",
    "consequently , our model for phase variation reduces to asking that the law of the warped point process is that of a cox process , where the random directing measure @xmath99 is non - linearly varying with a frchet mean ( with respect to the wasserstein distance ) equal to the structural mean .",
    "thus , in the poissonian case , the compounding of phase and amplitude variation can be viewed as _",
    "double stochasticity _ : the phase variation is attributed to the random directing measure , and the amplitude variation is attributed to the poisson fluctuations conditional on the directing measure .",
    "it is worth comparing this with the framework introduced by wu , mller and zhang @xcite , where point processes are modelled as cox processes whose driving log - densities are linearly varying functional data .",
    "armed with the intuition furnished by the geometrical interpretation of our assumptions , we may now formulate an estimation strategy .",
    "since the structural mean measure @xmath51 is the frchet mean of the random measures @xmath124 in the wasserstein metric , the natural estimator of @xmath51 would be the _ empirical fr ' echet  wasserstein mean _ of @xmath125 .",
    "of course , the true @xmath126 are unobservable , and instead we observe the point processes @xmath127 .",
    "however , since @xmath128 a sensible strategy is to use proxies ( estimates ) of the @xmath129 constructed on the basis of @xmath130 , and attempt to use these to approximate the empirical frchet ",
    "wasserstein mean .",
    "our procedure will follow the steps :    estimate the random measures @xmath96 .",
    "this may be done , for example , by carrying out classical density estimation on each @xmath131 , viewed as a point process with mean measure @xmath96 .",
    "call these estimators @xmath132 , with corresponding cumulative distribution functions @xmath133 .",
    "estimate @xmath51 by the empirical frchet mean of @xmath134 ( with respect to the wasserstein metric @xmath76 ) .",
    "we call this estimator the _ regularised frchet  wasserstein _ mean , and denote it by @xmath135 , with corresponding cumulative distribution function @xmath136 .    estimate each @xmath37 by the corresponding optimal transportation map of @xmath135 onto @xmath132 . in light of the discussion in the previous section , this is given by @xmath137 .",
    "equivalently , one may estimate the registration maps by @xmath138 .",
    "register the point processes by pushing them forward through the registration maps , @xmath139    of these steps , the last poses no difficulty once the first three have been carried out .",
    "we consider these in more detail in the following three subsections .    before doing so , we comment on how these estimators are modified in the case where the true mean measure is not a probability measure . in this case , the true measure , say @xmath22 , can always be written as @xmath140 , where @xmath141)$ ] and @xmath51 is a probability measure .",
    "the parameter @xmath142 can be easily estimated ( consistently ) by @xmath143)$ ] and the remaining estimators can be constructed by normalising the @xmath132 to be probability measures ( see , e.g. , section  [ sec : lambdaestimation ] ) .      the probability measures @xmath96 can be estimated by various means ; here we will employ kernel density estimation . for @xmath144 , let @xmath145 , with @xmath146 a smooth symmetric probability density function strictly positive throughout the real line and such that @xmath147 .",
    "let @xmath148 be the corresponding distribution function , @xmath149 .",
    "we consider the following smoothing procedure on a set of points @xmath150 . for @xmath151",
    "$ ] , construct a diffuse probability measure @xmath152 on @xmath41 $ ] with the strictly positive density @xmath153,}\\end{aligned}\\ ] ] where @xmath154 and @xmath155 .",
    "indeed , integration gives @xmath156 the intuition behind this construction is the following .",
    "first , we smooth the dirac measure @xmath157 by the kernel @xmath146 around @xmath1 , and restrict it to @xmath41 $ ] ; this yields a measure with total mass @xmath158 .",
    "then we construct the two one - sided versions of @xmath146 around @xmath1 with total masses @xmath159 and @xmath160 , respectively , and again restrict them to @xmath41 $ ] .",
    "the remaining mass , @xmath161 , is distributed uniformly across @xmath41$]it does not really matter what we do with this mass , and we could have re - distributed it in any diffuse way .",
    "finally , we construct the estimator @xmath162 \\bigr ) , \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\eqntext{(\\widehat\\lambda_i= \\mbox{lebesgue measure if } m_i=0),}\\end{aligned}\\ ] ] where the @xmath163 are the points corresponding to @xmath164 .",
    "our construction was slightly more complicated than usual in order to : ( 1 ) ensure that @xmath132 is everywhere positive on @xmath41 $ ] ; and , ( 2 ) allow us to suitably bound the wasserstein distance between the smoothed measure and the discrete measure @xmath165)$ ] .",
    "both these properties will be instrumental in our theoretical results . indeed , regarding ( 2 ) , we have the following .    [ smoothing_bound ] in the notation of the current section ,",
    "when @xmath166)>0 $ ] and @xmath167 , we have the bound @xmath168 \\bigr ) \\bigr ) \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber & & \\qquad\\le3 \\sigma^2 + 4\\max \\bigl(\\psi(-1/\\sqrt\\sigma),1-\\psi(1/\\sqrt\\sigma ) \\bigr).\\end{aligned}\\ ] ]      given our discussion in section  [ sec : geometry ] , it makes sense to use an @xmath169-estimation approach in order to construct an estimator for @xmath51 .",
    "since @xmath51 arises as a minimum of the population functional @xmath170 $ ] , with @xmath171 , we would like to define an estimator by minimising the sample functional @xmath172 unfortunately , the @xmath126 are unobservable , so that they need to be replaced by their estimators ( [ hatlambda ] ) , leading to the proxy functional @xmath173 if this functional has a unique minimum , then this is the sample fr ' echet mean of the @xmath174 .",
    "this type of optimisation problem rarely admits a closed - form solution .",
    "gangbo and wich @xcite have considered this in the form of a multi - coupling problem , and agueh and carlier @xcite in the barycentric formulation given above . they provide general results on existence and uniqueness ( not restricted to the 1-dimensional case ) , and characterising equations .",
    "remarkably , in the 1-dimensional case , these yield an explicit solution .",
    "this can also be determined directly , using elementary arguments : by our assumption on @xmath175 being homeomorphisms and @xmath51 being diffuse , we know that the measures @xmath126 are diffuse measures supported on @xmath41 $ ] with probability 1 .",
    "it follows that ( see , e.g. , villani @xcite , theorem  2.18 ) @xmath176 with @xmath177 the usual norm on @xmath11 $ ] .",
    "therefore , if there exists an optimum of @xmath178 and this optimum is a valid quantile function , it must be that the probability measure corresponding to this quantile function is an optimum of @xmath179 .",
    "indeed , @xmath180 does admit a unique minimum @xmath181 given by the empirical mean of the @xmath182 , @xmath183 furthermore , @xmath181 is non - decreasing and continuous , since each of the @xmath184 is so .",
    "it is therefore a valid quantile function [ clearly @xmath185 and @xmath186 .",
    "we conclude that @xmath179 attains a unique minimum at the measure @xmath187 that is , the probability measure with cumulative distribution function @xmath188 .",
    "once the conditional mean measures @xmath126 and the structural mean measure @xmath51 have been estimated , we automatically get the estimators for the warp and registration maps , respectively , @xmath189 note here that if @xmath39 is the optimal transportation map of @xmath22 onto @xmath77 , the change of variables formula immediately implies that @xmath190 is the optimal transportation map of @xmath77 onto @xmath22 .      as was foretold in the end of section  [ sec : phase_principles ] , the estimation of the warp / registration maps did not require additional smoothness constraints ( and by means of tuned penalties ) on @xmath39 .",
    "since @xmath191 , we immediately note that the estimated maps will be as regular as the estimators of @xmath51 and @xmath96 are , or equivalently , as smooth as the @xmath192 .",
    "it follows that the smoothness of the estimated maps will be directly inherited from any smoothness constraints we place on the estimated mean and conditional mean measures , and will not require the addition of any further smoothness penalties .",
    "note that our geometrical framework essentially induces a loss function in the estimation problem for the structural mean , @xmath193 where @xmath194 is a candidate estimator of @xmath51 . under this loss function",
    ", one can consider the class of _ unbiased estimators of the structural mean _",
    "( in the general sense of lehmann @xcite ) , that is , estimators @xmath195 satisfying @xmath196 for all diffuse measures @xmath51 and @xmath91 on @xmath41 $ ] .",
    "a _ biased _",
    "estimator @xmath197 would be such that for some measure @xmath91 , @xmath198 thus , using a biased estimator in order to estimate the warp functions , may ( on average ) occasionally produce registrations that appear to be `` successful '' in the sense that the residual phase variation is small ; but on the other hand , they would be registering to the wrong reference measure ( a bias - variance tradeoff ) .",
    "it would thus appear that _ unbiasedness _ is a reasonable requirement in this setup , protecting us against overfitting ( or `` over - registering , '' to be more precise ) .",
    "interestingly , unbiased estimators can be characterised in terms of their quantile functions ; in particular , the empirical frchet mean of @xmath125 is unbiased .",
    "[ prop : unbiasedness][prop : umvue ] let @xmath199 be i.i.d .",
    "random probability measures on @xmath41 $ ] with positive density with respect to lebesgue measure .",
    "let @xmath51 be their ( unique ) frchet mean in the wasserstein metric .",
    "a random measure @xmath200 is unbiased for @xmath51 if and only if its expected quantile function is the quantile function of @xmath51 , that is , @xmath201 for almost any @xmath2 .",
    "in particular , the ( unique ) empirical fr ' echet  wasserstein mean of @xmath199 is an unbiased estimator of @xmath51 .",
    "we can thus interpret our regularised frchet ",
    "wasserstein estimator @xmath202 as _ approximately unbiased _ , since it is a proxy for the unobservable empirical frchet ",
    "wasserstein mean .",
    "we now turn to establishing the consistency of the estimators constructed in the previous section , and the rate of convergence of the estimator of the structural mean . in the functional case , as encapsulated in equation  ( [ eq : functional_sampling ] ) , one would need to assume that the number of observed curves , @xmath10 , as well as the number of sampled observations per curve , @xmath203 , diverge .",
    "similarly , we will need to construct a framework for asymptotics where the number of point processes @xmath10 , and the number of points per observed ( warped ) point process , @xmath204 , diverge . to allow for this",
    ", we shall assume that the processes @xmath3 are infinitely divisible .",
    "[ thm : consistency ] let @xmath51 be a diffuse probability measure whose support is @xmath41 $ ] , and let @xmath205 be a triangular array of row independent and identically distributed infinitely divisible point processes with mean measure @xmath206 , with @xmath207 a scalar .",
    "let @xmath208 be independent and identically distributed random homeomorphisms on @xmath41 $ ] , stochastically independent of @xmath209 , and satisfying assumptions and relative to @xmath51 .",
    "let @xmath210 , and @xmath211 .",
    "( we shall suppress the dependency on @xmath10 , but we notice that , by construction , @xmath96 does not depend on @xmath10 . ) if @xmath212 and @xmath213 as @xmath214 , then :    the conditional mean measure estimators of section  [ sec : lambdaestimation ] ( constructed with bandwidth @xmath215 ) are wasserstein - consistent , @xmath216    the regularised frchet  wasserstein estimator of the structural mean measure ( as described in section  [ sec : lambdaestimation ] ) is strongly wasserstein - consistent , @xmath217    the warp functions and registration maps estimators of section  [ sec : warp_estimation ] are uniformly consistent , @xmath218 } \\bigl|\\widehat{t}_i(x)-t_i(x ) \\bigr|\\stackrel{p } { \\longrightarrow}0\\quad\\mbox{and}\\quad\\sup_{x\\in[0,1 ] } \\bigl| \\widehat{t}_i^{-1}(x)-t_i^{-1}(x ) \\bigr| \\stackrel{p } { \\longrightarrow}0\\nonumber\\\\ \\eqntext{\\mbox{as } n\\uparrow\\infty , \\forall i.}\\end{aligned}\\ ] ]    the registration procedure in equation ( [ eq : registration ] ) is wasserstein - consistent , @xmath219)},\\frac { \\pi_i}{\\pi _ i([0,1 ] ) } \\biggr)\\stackrel{p } { \\longrightarrow}0 \\qquad\\mbox{as } n\\uparrow\\infty , \\forall i.\\ ] ]    under the additional conditions that @xmath220 and @xmath221 ) ] ^4<\\infty $ ] , the convergence in ( 1 ) , ( 3 ) and ( 4 ) holds almost surely .",
    "[ sparse_remark ] the assumption that @xmath213 is only needed in order to avoid empty point processes .",
    "it requires that the number of observed processes should not grow too rapidly relative to the mean number of points observed per process .",
    "this condition can be compared to similar conditions relating the number of discrete observations per curve in classical fda . in a sense , it separates the so - called sparse from the dense sampling regime ( see also wu , mller and zhang @xcite ) and shows that even sparse designs lead to consistency .",
    "notice that no assumption on the precise rate of convergence of @xmath222 to 0 is required , and in particular its decay is independent of @xmath223 .",
    "indeed , @xmath222 can even be random ( e.g. , sample dependent ) , provided it converges to zero in probability ( see also remark  [ rem : sigmarates ] ) .",
    "any ( cluster ) poisson process is infinitely divisible , so that this assumption is not overly restrictive , and allows for the phase varying point process to be of cox type , as discussed in section  [ sec : cox ] ( as a matter of fact , a point process is infinitely divisible if and only if its finite dimensional distributions are infinitely divisible ; see daley and vere - jones @xcite , section  10.2 , for a detailed discussion ) .",
    "it allows us to mathematically translate the increasing expected number of points per process , to a sort of `` i.i.d . ''",
    "sampling framework more similar to the classical fda one .    in conclusion ( 4 )",
    ", the random quantity @xmath224)=\\pi _ i([0,1])$ ] is the number of points observed for the _ _ i__th process .",
    "normalisation by this factor is a technicality ensuring that the quantities involved are probability measures ( or else the wasserstein distance would not be well - defined ) .",
    "the actual distance @xmath225)},\\frac{\\pi_i}{\\pi _ i([0,1 ] ) } ) $ ] only depends on the point patterns themselves , and not on the normalisation .    in the case of cox processes ,",
    "when the processes are poisson prior to warping , if we impose a mild constraint on the decay rate of @xmath226 , we can also establish rates of convergence of the estimator @xmath227 of the structural mean measure @xmath51 .",
    "[ thm : rate ] assume the conditions of theorem  [ thm : consistency ] , and suppose in addition that the processes @xmath228 are poisson .",
    "if the kernel @xmath148 used for the smoothing has a finite fourth moment @xmath229 , then @xmath227 satisfies @xmath230{\\tau_n } } \\biggr ) + o_{\\mathbb{p } } \\biggl ( \\frac{1}n\\sum_{i=1}^n \\sigma_i^{(n ) } \\biggr).\\ ] ] here , @xmath231 is the bandwidth used for constructing @xmath232 , and it is assumed that @xmath233 in probability .",
    "the first term corresponds to the phase variation , the standard @xmath234 rate resulting from the approximation of a theoretical expectation by a sample mean .",
    "the second term corresponds to the amplitude variation .",
    "the third term corresponds to the bias incurred by the smoothing .",
    "theorem  [ thm : rate ] allows us to conclude that for @xmath235 and @xmath236 we have @xmath4-consistency when dealing with cox processes , attaining the optimal rate under dense sampling .",
    "indeed , even more can be said in the dense sampling regime :    [ thm : asynorm ] in addition to the conditions of theorem  [ thm : rate ] , assume that @xmath237 , @xmath238 and that the density of @xmath51 is bounded below by a strictly positive constant .",
    "then @xmath227 is asymptotically gaussian , in the sense that @xmath239 \\bigr),\\ ] ] where @xmath240 is the optimal transport map from @xmath51 to @xmath227 , @xmath241\\rightarrow[0,1]$ ] is the identity map and @xmath242 is a mean - square continuous gaussian process with covariance kernel @xmath243 for @xmath39 a random warp map distributed as the @xmath208 .",
    "[ rem : uq ] since we have uniformly consistent estimators of the maps @xmath244 , we can construct an empirical estimate of @xmath245 , which would allow us to carry out uncertainty quantification on our structural mean estimate ( for example in the form of pointwise confidence intervals of its cdf ) .",
    "[ rem : sigmarates ] the statements allow the bandwidth @xmath231 to be random .",
    "it follows from lemma  [ lem : havepoints ] that the ( minimal ) number of points is of the order @xmath246 .",
    "consequently , if one chooses the bandwidth by @xmath247)^{-\\alpha}$ ] for some @xmath248 , then with probability one , @xmath249 .",
    "the condition @xmath250 then translates to @xmath251 , which automatically holds for @xmath252 due to the independent assumption that @xmath237 . under rosenblatt",
    "s rule @xmath253 , one needs the stronger requirement @xmath254 for asymptotic normality to hold .",
    "proof of proposition  [ prop : assumptions ] we begin by showing that conditions ( a2 ) and ( b2 ) are equivalent in their own right",
    ". then we will show that subject to ( b2 ) being true , conditions ( a1 ) and ( b1 ) are equivalent . in the language of optimal transportation , condition ( b2 )",
    "requires that @xmath39 should be the optimal transport map between the diffuse measure @xmath51 and @xmath255 . by brenier s theorem ( @xcite , theorem  2.12 ) , it must be that @xmath39 is monotone increasing ( as the gradient of a convex function on @xmath41 $ ] ) , and thus ( a2 ) is implied .",
    "conversely , assume that ( a2 ) holds true .",
    "we know that there is a unique optimal map between @xmath51 and @xmath122 by @xmath51 being diffuse . by brenier s theorem , this map must be monotone increasing , and hence it must be @xmath39 itself .",
    "this implies ( b2 ) .",
    "consider now condition ( b1 ) , which stipulates that given @xmath91 a diffuse measure with everywhere positive density @xmath41 $ ] , we have @xmath256 in the presence of ( b2 ) , we know that @xmath39 is an optimal map .",
    "it follows that the left - hand side is @xmath257 keeping this in mind , we focus on the right - hand side . since @xmath91 is absolutely continuous , it can be written as @xmath258 , for some monotone increasing function @xmath259 , and in fact @xmath259 is the optimal plan between @xmath51 and @xmath91 ( since any two diffuse measures have a unique optimal map , which must be monotone increasing ) .",
    "it follows that @xmath260 now we note that @xmath261 , since @xmath39 is increasing , and thus @xmath262 ; similarly , @xmath259 is increasing too , so @xmath263 .",
    "consequently , @xmath264 where @xmath104 is the density of @xmath51 , which we assumed earlier to be positive everywhere on @xmath41 $ ] .",
    "now we change variables , setting @xmath265 , and observing that @xmath266 , we have @xmath267 as a result of our calculations , we see that , in the presence of ( b2 ) , condition ( b1 ) is equivalent to @xmath268 for all monotone increasing functions @xmath259 , where the last equality follows from tonelli s theorem . the last condition is satisfied if and only if @xmath70=x$ ] , @xmath51-almost everywhere . thus , when @xmath51 has positive density with respect to lebesgue measure everywhere on @xmath41 $ ] , we have established that , if ( b2 ) holds , then ( a1 ) is equivalent to ( b1 ) .",
    "this completes the proof .",
    "proof of proposition  [ prop : uniqueness ] since @xmath99 is diffuse and strictly positive , we may re - express the functional of interest as @xmath269 = \\mathbb e \\biggl[\\int_0 ^ 1\\bigl|{f}_\\lambda^{-1}(x)-f^{-1}_{\\gamma } ( x)\\bigr|^2 \\,dx \\biggr ] = \\mathbb e\\bigl\\|{f}_\\lambda^{-1}-f^{-1}_{\\gamma } \\bigr\\|^2_{l^2},\\ ] ] with @xmath177 the usual @xmath71 norm . therefore ,",
    "if there exists an optimum of @xmath270 \\bigr)\\ ] ] and this optimum is a valid quantile function , it must be that the probability measure corresponding to this quantile function is an optimum of @xmath271 .",
    "indeed , @xmath272 does admit a unique minimum given by @xmath273 $ ] , @xmath274 $ ] , which we claim is a valid quantile function .",
    "note first that @xmath275 is , in fact , a proper inverse of the continuous , strictly increasing mapping @xmath276)$ ] .    since @xmath277 and @xmath278 almost surely , we have @xmath279 and @xmath280 .    if @xmath281 , then @xmath282 almost surely .",
    "consequently,@xmath283\\le \\mathbb { e}[f_{\\lambda}^{-1}(y)]$ ] also , proving that @xmath284 is non - decreasing .",
    "if @xmath285 in @xmath41 $ ] , then @xmath286 almost surely .",
    "since @xmath287 is bounded by 1 , the bounded convergence theorem implies that @xmath288\\rightarrow\\mathbb{e}[x]$ ] , proving that @xmath289 is continuous at @xmath2 ( and hence everywhere in @xmath41 $ ] by arbitrary choice of @xmath2 ) .",
    "proof of proposition  [ prop : umvue ] requiring an estimator @xmath146 to be unbiased translates to @xmath290 since @xmath71 is a linear space , and using tonelli s theorem to exchange expectation and integration , the unbiasedness condition is equivalent to requiring that @xmath291 = f^{-1}_{\\lambda}(x ) \\qquad\\mbox{almost everywhere}.\\ ] ] to show that this is indeed the case for the empirical wasserstein mean @xmath200 , we note that @xmath292 and so , by proposition  [ prop : assumptions ] , it follows that @xmath293 = \\mathbb{e}_{\\lambda } \\bigl[t_i \\bigl(f^{-1}_{\\lambda}(x ) \\bigr ) \\bigr ] = f^{-1}_{\\lambda}(x ) , \\qquad i=1,\\ldots , n\\ ] ] almost everywhere on @xmath41 $ ] . since @xmath294 ( see section  [ sec : lambdaestimation ] ) , @xmath295=f^{-1}_{\\lambda } ( x)$ ] also holds a.e . , and the unbiasedness of @xmath200 has been established .",
    "proof of lemma  [ smoothing_bound ] the squared wasserstein distance is bounded by the cost of sending all the mass in @xmath296 to @xmath297 .",
    "the squared distance between @xmath298 and @xmath157 is @xmath299 the reason we needed the one - sided kernels in addition to the standard two - sided one is that either @xmath159 or @xmath160 can be large ( e.g. , if @xmath300 , then @xmath301 ) , but they can not both be large simultaneously .",
    "indeed , when @xmath302 , we have @xmath303 and when @xmath304 , @xmath305 .",
    "when @xmath167 , at least one of these possibilities holds , and since @xmath306 , this implies that @xmath307 this bound holds for any @xmath151 $ ] , and the conclusion follows .    in order to prove theorem  [ thm : consistency ] , we first need to eliminate the possibility of having empty point processes ( this is the only reason we assume @xmath213 ) .",
    "to this aim , we will use a seemingly unrelated technical result for binomial distributions .",
    "[ lem : cherbin ] let @xmath308 , then @xmath309    for any @xmath310 , we have @xmath311^\\tau,\\end{aligned}\\ ] ] where @xmath312 .",
    "a straightforward calculation shows that this is minimised when @xmath313",
    ". the objective value at this point , @xmath314 , must be smaller than the objective value at @xmath315 , which is 1 .",
    "[ lem : havepoints ] if @xmath213 , then there exists a constant @xmath316 , depending only on the distribution of the @xmath40 s , such that @xmath317)}{\\tau_n } \\ge c_\\pi\\qquad \\mbox{a.s.}\\ ] ] in particular , there are no empty point processes , so the normalisation is well - defined .",
    "let us denote for simplicity by @xmath318 ( @xmath319 a point process that follows the same infinitely divisible distribution as @xmath320 , but with mean measure @xmath321 .",
    "let @xmath322 be the probability that @xmath323 has no points ( clearly , @xmath324 , since @xmath323 has one point in average ) .",
    "it follows from the infinite divisibility that for any rational @xmath325 , the probability that @xmath318 has no points is @xmath326 . by a continuity argument ,",
    "this can be extended to any real value of @xmath325 : indeed , the laplace functional of @xmath323 takes the form ( kallenberg @xcite , chapter  6 ) @xmath327 = \\exp \\biggl(-\\int \\bigl(1-e^{-\\rho f } \\bigr)\\,d\\mu(\\rho ) \\biggr ) , \\qquad f\\in f \\bigl([0,1 ] \\bigr),\\ ] ] where @xmath328 $ ] is the set of borel measurable functions",
    "@xmath329\\to \\mathbb r_+$ ] , and @xmath22 is a radon measure on the set @xmath330)$ ] .",
    "it follows that @xmath331 , the laplace functional of @xmath318 , is @xmath332 when @xmath325 is rational , which simply corresponds to multiplying @xmath22 by the scalar @xmath325 . by considering the measure @xmath333 for any real @xmath325",
    ", we obtain @xmath334 for any value of @xmath325 .",
    "the laplace functional completely determines the distribution of the process ; in particular , the probability of @xmath335 having no points is obtained as the limit @xmath336 by the bounded convergence theorem , where @xmath337 for the constant function @xmath338",
    ".    denote the total number of points by @xmath339)$ ] , and assume momentarily that the @xmath223 s are integers .",
    "then @xmath340 is the sum of @xmath223 i.i.d .",
    "integer valued random variables @xmath341 , each having a probability of @xmath324 to equal zero .",
    "( in the poisson case , @xmath342 . )",
    "each @xmath341 is larger than @xmath343 , which follows a bernoulli distribution with parameter @xmath344 , and @xmath345 .",
    "it follows that for any @xmath203 , @xmath346 since @xmath347 are i.i.d . across @xmath348 ,",
    "specifying @xmath349 and applying lemma  [ lem : cherbin ] yields @xmath350^n \\le1- \\bigl(1- \\beta^{\\tau_n } \\bigr)^n \\\\ & \\le&1- \\bigl(1-n\\beta^{\\tau_n } \\bigr),\\end{aligned}\\ ] ] by the bernoulli inequality @xmath351 ( valid for @xmath352 and @xmath10 integer ; easily proved by induction on @xmath10 ) .",
    "the right - hand side is @xmath353 for @xmath354 .",
    "since @xmath355 and @xmath356 , we have @xmath357 as @xmath358 so this is smaller than @xmath359 for sufficiently large @xmath10 . by the borel ",
    "cantelli lemma , the result holds for @xmath360 .    if @xmath223 is not an integer , then @xmath347 is the sum of @xmath361 ( the largest integer @xmath362 ) i.i.d .",
    "random variables @xmath341 with probability @xmath363 to equal zero . letting @xmath364 and observing that @xmath365 for any @xmath366 and any @xmath203 [ or that @xmath367 , we obtain @xmath368 we still have @xmath357 and since @xmath369\\to1 $ ] , any @xmath370 will qualify .",
    "thus , the lemma holds with @xmath360 .",
    "as the proof shows , the condition @xmath213 can be slightly weakened to @xmath371 and the lower bound equals 9.75 in the poisson case .",
    "proof of theorem  [ thm : consistency ] maintaining the notation @xmath372)=\\widetilde\\pi _ i([0,1])$ ] , we begin by proving ( 1 ) . without loss of generality , assume that @xmath223 takes integer values [ otherwise , work with @xmath373 , the greatest integer smaller than @xmath223 , that is , replace @xmath223 by @xmath373 and @xmath96 by @xmath374 .",
    "let @xmath348 be a fixed integer .",
    "since the processes @xmath3 are infinitely divisible , it is clear that the @xmath127 must be so too .",
    "consequently , we note that a single realisation of a point process with mean measure @xmath375 is equivalent in law to a superposition of @xmath223 independent and identically distributed processes @xmath376 , each with mean @xmath96 .",
    "we can assume that @xmath377 are constructed as the push - forward through @xmath37 of independent and identically distributed point processes @xmath378 with mean measure @xmath51 , that are independent of @xmath37 .",
    "it follows that as @xmath358 , ( e.g. , karr @xcite , chapter  4 ) @xmath379 with `` @xmath380 '' denoting weak convergence of measures .",
    "since @xmath381 , it follows by slutsky s theorem that @xmath382 as @xmath41 $ ] is compact , we conclude that this last convergence also holds in wasserstein distance @xcite , theorem  7.12 , in probability . noting that by ( [ eq : wasssmooth ] ) and since @xmath383 as @xmath358 , @xmath384 an application of the triangle inequality shows that @xmath385 , establishing claim ( 1 ) . for convergence almost surely",
    ", we fix @xmath386 $ ] and set @xmath387 \\bigr)-\\lambda _ i \\bigl([0,a ] \\bigr),\\qquad   j=1,\\ldots,\\tau_n.\\ ] ] one sees that @xmath388 , where @xmath389 and @xmath390 \\bigr ) - f _ { \\ # } \\lambda \\bigl([0,a ] \\bigr ) \\biggr ] ^ 4,\\nonumber\\\\   \\eqntext{f\\in\\operatorname{hom}[0,1 ] ; q_j\\in m_r,}\\end{aligned}\\ ] ] ( where @xmath391 is the collection of radon measures on @xmath41 $ ] endowed with the topology of weak convergence , and @xmath392 $ ] is the space of homeomorphisms of @xmath41 $ ] endowed with the supremum norm ) is a measurable function ( since it is continuous ) .",
    "it is also integrable because @xmath393)\\le1 $ ] and @xmath394)]^4\\le\\mathbb e[q_j^{(n)}([0,1])]^4<\\infty$ ] by the hypothesis .",
    "since the arguments of @xmath395 are independent , the proof of @xcite , lemma  6.2.1 , can be adapted to show that @xmath396=g(t_i)$ ] , where ( with a slight abuse of notation ) @xmath397 = \\int dq_1\\int dq_2\\cdots\\int dq_k\\varphi(q_1 , \\ldots , q_k , f),\\nonumber\\\\    \\eqntext{f\\in\\operatorname{hom}[0,1].}\\end{aligned}\\ ] ] the same idea shows that for each @xmath398 , @xmath399&= & \\int dq_j{t_i}_\\#q_j \\bigl([0,a ] \\bigr ) - { t_i}_\\#\\lambda \\bigl([0,a ] \\bigr)\\\\ & = & \\lambda \\bigl(t_i^{-1 } \\bigl([0,a ] \\bigr ) \\bigr ) - \\lambda \\bigl(t_i^{-1 } \\bigl([0,a ]",
    "\\bigr ) \\bigr ) = 0.\\end{aligned}\\ ] ] in words , conditional on @xmath400 , @xmath401 are mean zero independent and identically distributed random variables .",
    "one readily verifies that ( see the proof of @xcite , theorem  2.3.5 , for the details ) @xmath402 & = & \\sum_{j=1}^{\\tau_n}\\mathbb e \\bigl[x_{nj}^4| \\sigma(t_i ) \\bigr ] + \\sum _ { j < l}\\mathbb e \\bigl[x_{nj}^2x_{nl}^2| \\sigma(t_i ) \\bigr]\\\\ & = & \\tau_n\\mathbb e \\bigl[x_{11}^4| \\sigma(t_i ) \\bigr ] + 3 \\tau_n(\\tau_n-1)\\mathbb e \\bigl[x_{11}^2x_{12}^2| \\sigma(t_i ) \\bigr].\\end{aligned}\\ ] ] taking again expected values and applying markov s inequality , @xmath403 \\le\\frac{\\mathbb e[s_n^4]}{{\\varepsilon}^4\\tau_n^4}= \\frac{\\mathbb\\tau_n \\mathbb e[x_{11}^4 ] + 3\\tau_n(\\tau_n-1)\\mathbb e[x_{11}^2x_{12}^2]}{{\\varepsilon}^4\\tau_n^4}.\\ ] ] the numerator is finite , and the sum over @xmath10 of the right - hand side converges when @xmath404 . as @xmath405 is arbitrary , @xmath406 by the borel ",
    "cantelli lemma .    repeating this argument countably many times",
    ", we have @xmath407)}{\\tau_n}-\\lambda _ i \\bigl([0,a ] \\bigr ) \\to0 \\mbox { for any rational } a \\biggr)=1.\\ ] ] if @xmath408 is irrational , choose @xmath409 rational .",
    "we have the inequalities @xmath410)}{\\tau_n}-\\lambda_i \\bigl([0,a ] \\bigr ) & \\le & \\frac { \\widetilde\\pi_i([0,b_k])}{\\tau_n}-\\lambda_i \\bigl([0,b_k ] \\bigr)+\\lambda _ i \\bigl([0,b_k ] \\bigr)-\\lambda_i \\bigl([0,a ] \\bigr ) ; \\\\ \\frac{\\widetilde\\pi_i([0,a])}{\\tau_n}-\\lambda_i \\bigl([0,a ] \\bigr ) & \\ge & \\frac { \\widetilde\\pi_i([0,a_k])}{\\tau_n}-\\lambda_i \\bigl([0,a_k ] \\bigr)+\\lambda _ i \\bigl([0,a_k ] \\bigr)-\\lambda_i \\bigl([0,a ] \\bigr),\\end{aligned}\\ ] ] from which one concludes that almost surely , for any @xmath366 , @xmath411 ) & \\le&\\liminf_{n\\to\\infty } \\frac{\\widetilde\\pi_i([0,a])}{\\tau_n } - \\lambda_i \\bigl([0,a ] \\bigr ) \\le\\limsup _ { n\\to\\infty}\\frac{\\widetilde\\pi_i([0,a])}{\\tau_n } - \\lambda _",
    "i \\bigl([0,a ] \\bigr)\\\\ & \\le&\\lambda_i\\bigl((a , b_k]\\bigr).\\end{aligned}\\ ] ] letting @xmath412 , we see that convergence holds for any continuity point @xmath408 of @xmath96 . but",
    "@xmath96 is a continuous measure by construction .",
    "one then easily shows the almost sure analogue of ( [ eq : llnforpi ] ) ( take @xmath413 ) and concludes ( 1 ) as above .",
    "in order to prove ( 2 ) , we note that @xmath51 being a minimiser of the functional @xmath170 $ ] implies that it must be the unique such minimiser ( this follows by proposition  [ prop : uniqueness ] ) , since @xmath102 is diffuse and everywhere positive on @xmath41 $ ] , and @xmath39 is a homeomorphism . to establish the purported convergence , we therefore study the convergence of @xmath414 to @xmath169 , both viewed as being defined over @xmath330)$ ] , the space of probability measures supported on @xmath41 $ ] . using the triangle inequality , we may interject the functionals @xmath415 that is , the empirical functional assuming that the @xmath96 could be observed ; and @xmath416 ( which is well - defined for @xmath10 sufficiently large by lemma  [ lem : havepoints ] ) , and write @xmath417 we shall show that each of the three terms in the right - hand side converges to 0 uniformly .    for any three probability measures @xmath22 , @xmath77 , @xmath418 on @xmath41 $ ] , one has @xmath419",
    "^ 2)}\\int _ { [ 0,1]}\\int_{[0,1]}{|x - y|^2 }",
    "{ \\theta(dx\\times dy ) } \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber & \\le&\\sup_{x , y\\in [ 0,1]}|x - y|^2=1 ; \\\\ \\label{eq : uniflip}\\bigl|d^2(\\mu,\\rho)-d^2(\\nu,\\rho)\\bigr|&=&\\bigl|d(\\mu , \\rho)+d(\\nu,\\rho)\\bigr|\\bigl|d(\\mu,\\rho)-d(\\nu,\\rho)\\bigr| \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber & \\le&2d(\\nu,\\mu),\\end{aligned}\\ ] ] and consequently @xmath420 the right - hand side is independent of @xmath91 and converges to 0 by application of ( [ eq : wasssmooth ] ) .    similarly , @xmath421)}\\bigl|m_n(\\gamma)-m_n^*(\\gamma)\\bigr| \\le\\frac{2}n\\sum_{i=1}^nd \\biggl",
    "( \\lambda_i,\\frac{\\widetilde\\pi _ i}{n_i } \\biggr ) = \\frac{2}n\\sum _ { i=1}^nx_{ni } = 2\\overline x_n.\\ ] ] now @xmath422 is a function of @xmath37 and @xmath423 , so by construction they are i.i.d . across @xmath348 . setting @xmath424",
    ", we obtain mean zero random variables that are i.i.d . across @xmath348 and @xmath425 because @xmath426 by ( [ eq : defl ] ) . applying the argument in  @xcite , theorem  2.3.5 , again , one obtains @xmath427 + 3n(n-1)\\mathbb e [ y_{ni}^2 ] } { { \\varepsilon}^4n^4}\\le\\frac { 3}{{\\varepsilon}^4n^2}.\\ ] ] by the borel ",
    "cantelli lemma and arbitrariness of @xmath428 , we have @xmath429 . but",
    "@xmath430 as @xmath358 by ( [ eq : llnforpi ] ) , and the bounded convergence theorem yields @xmath431=\\mathbb e[x_{n1}]\\to0 $ ] .",
    "turning to the term @xmath432 , we remark that the strong law of large numbers yields @xmath433 for all @xmath91 . to upgrade to uniform convergence over @xmath91 ,",
    "observe that by ( [ eq : uniflip ] ) , both @xmath434 and @xmath169 are 2-lipschitz . by compactness of @xmath330)$ ] , given @xmath428 , we can choose an @xmath405-cover @xmath435 . for any @xmath91 , we have @xmath436 for some @xmath398 , so @xmath437 taking @xmath358 , then @xmath438 , we conclude @xmath439 summarising , we have established that @xmath440 .",
    "let @xmath441 be a minimiser of @xmath442 .",
    "by compactness of @xmath330)$ ] , @xmath443 , for some subsequence and some @xmath22 .",
    "then @xmath444 by the uniform convergence and continuity of @xmath442 and @xmath169 . since @xmath445 , we get @xmath446 , which , by uniqueness of @xmath51 as a minimiser of @xmath169 , implies that @xmath447 .",
    "this establishes @xmath448 with respect to the wasserstein distance .    to prove part ( 3 ) , let @xmath449 , @xmath450 , @xmath451 and @xmath452 denote the distribution functions of @xmath51 , @xmath96 , @xmath227 and @xmath132 , respectively , restricted to @xmath41 $ ] .",
    "since @xmath449 and @xmath450 are continuous functions , we have @xmath453 and @xmath454 pointwise on @xmath41 $ ] ( either in probability or almost surely , depending on the assumptions ) . furthermore , all these functions are strictly increasing and continuous , thus invertible .",
    "our goal is to show @xmath455.\\ ] ] lemma  [ lem : pointwisetouniform ] below shows that it will suffice to establish pointwise convergence , as uniform convergence will immediately follow in our current setup . to this aim",
    ", we remark that since @xmath450 is continuous on a compact set , it maps closed sets to closed sets . being a bijection , this implies that @xmath456 is continuous as well .",
    "we proceed by showing that @xmath457 for @xmath458 ( this is obvious when @xmath459 ) .",
    "let @xmath2 be the unique number such that @xmath460 and let @xmath428 .",
    "then @xmath461 so that @xmath462 , at least for @xmath10 large .",
    "similarly , @xmath463 for @xmath10 large and , @xmath405 being arbitrary , we conclude that @xmath464 .    by lemma  [ lem : pointwisetouniform ] ,",
    "@xmath465 converges uniformly to @xmath456 on @xmath41 $ ] , where the latter is ( uniformly ) continuous .",
    "given @xmath428 , let @xmath200 such that @xmath466 .",
    "when @xmath10 is large , @xmath467 and @xmath468 .",
    "then , for any @xmath469 $ ] , @xmath470 , whence @xmath471 in other words , @xmath472 for any large enough @xmath10 , and ( 3 ) is proven .",
    "since the functions @xmath473 and @xmath37 are again strictly increasing , it also follows that @xmath474 converges to @xmath475 uniformly .",
    "now , we turn to part ( 4 ) . recall that @xmath476 it follows that @xmath477 is a transport plan of @xmath478 onto @xmath479 .",
    "consequently , @xmath480}\\bigl|\\widehat{t}^{-1}_i \\bigl(t_i(x ) \\bigr)-x\\bigr|^2.\\ ] ] note , however , that since @xmath481 $ ] , @xmath218}\\bigl|\\widehat{t}^{-1}_i \\bigl(t_i(x ) \\bigr)-x\\bigr|&=&\\sup_{x\\in [ 0,1]}\\bigl| \\widehat{t}^{-1}_i \\bigl(t_i",
    "\\bigl(t_i^{-1}(x ) \\bigr ) \\bigr)-t_i^{-1}(x)\\bigr|\\\\ & = & \\sup_{x\\in [ 0,1]}\\bigl|\\widehat{t}^{-1}_i(x)-t^{-1}_i(x)\\bigr|,\\end{aligned}\\ ] ] and the latter converges to zero in probability ( or almost surely , depending on the assumptions ) as @xmath53 from part ( 3 ) .    the following elementary result is stated without proof .",
    "[ lem : pointwisetouniform ] let @xmath482\\to{\\mathbb{r}}$ ] be non - decreasing and converge pointwise to a continuous limit function @xmath449 .",
    "then the convergence is uniform .",
    "proof of theorem  [ thm : rate ] let @xmath441 be the minimiser of the empirical functional @xmath483 . for a probability measure @xmath484)$ ] , denote its quantile function @xmath485)$ ] by @xmath486 .",
    "then @xcite , theorem  2.18 , says that @xmath109 is an isometry : @xmath487 .",
    "now @xmath488 these are i.i.d .",
    "mean zero random elements in @xmath71 , whose norm is bounded by 1 .",
    "therefore , the above expression converges in distribution to a gaussian limit @xmath489 with @xmath490 as @xmath491 . in particular , @xmath492    the error resulting from approximating @xmath441 by @xmath227 , the minimiser of @xmath442 , is @xmath493 which , by the triangle inequality , is bounded by @xmath494 where @xmath495 .",
    "the first term on the right - hand side corresponds to the amplitude variation , while the second corresponds to the smoothing bias .",
    "the third term was introduced to accommodate empty processes .",
    "the inequality follows from the convention that @xmath496 is lebesgue measure when @xmath497 and the distance between any two measures is no larger than one .",
    "this term is negligible by lemma  [ lem : havepoints ] : @xmath498 so this term `` converges '' to 0 at any rate .",
    "denote the distances of the amplitude variation by @xmath499 $ ] . for fixed @xmath10 , @xmath422",
    "are i.i.d . across @xmath348 . since @xmath500 we seek to find the rate at which @xmath501 vanishes .",
    "let @xmath502 denote the 1-wasserstein distance",
    ". then equations ( 7.4 ) and ( 2.48 ) in villani @xcite and fubini s theorem imply that @xmath503 ) } \\biggr ) = \\int _ 0 ^ 1\\mathbb e \\biggl\\vert \\lambda_1 \\bigl([0,t ] \\bigr ) - \\frac{\\widetilde{\\pi } _",
    "1^{(n)}([0,t])}{n_1^{(n)}}\\biggr \\vert s_{n1}\\,dt \\\\ & = & \\int _ 0 ^ 1\\mathbb e\\vert b_t\\vert\\,dt,\\end{aligned}\\ ] ] where @xmath504 is defined by the above equation .",
    "let @xmath505 $ ] be fixed . since @xmath506 is a cox process with random mean measure @xmath507 , conditional on @xmath507 and on",
    ", @xmath504 follows a centred renormalised binomial distribution ; @xmath508 with @xmath509)$ ] .",
    "since @xmath504 is centred , the conditional expectation of @xmath510 equals its conditional variance , @xmath511 ( or 0 if @xmath512 ) .",
    "this bound is independent of @xmath507 , so we conclude that @xmath513 .",
    "now @xmath514 follows a poisson distribution with parameter @xmath223 .",
    "note that if @xmath515 then @xmath516 , which can be seen by applying the inequality @xmath517 for @xmath518 : @xmath519 thus , taking expected values again , we conclude that @xmath520 so that the integrand above is @xmath521 .",
    "it follows that @xmath522 and so @xmath523 .",
    "summarising , the amplitude variation is of order at most @xmath524 .    as for the smoothing bias",
    ", it has been shown in the proof of theorem  [ thm : consistency ] that each of the summands is bounded by @xmath525 , where @xmath526 if ( the distribution corresponding to ) @xmath148 has tails of order @xmath527 , then the first summand above dominates , so that @xmath528 for some finite constant @xmath529 and all @xmath530 , and @xmath531 the result now follows from @xmath532 .",
    "proof of theorem  [ thm : asynorm ] the conditions of the theorem imply that @xmath533 converges weakly to 0 , so that @xmath534 where @xmath489 is the gaussian process defined above .",
    "so the first statement follows from slutsky s theorem .",
    "the assumption that the density of @xmath51 is positively bounded below implies that @xmath535 satisfies the hypothesis of lemma  [ lem : composition ] stated after the end of the proof , so that right composition is continuous on @xmath11 $ ] . by the continuous mapping theorem @xmath536\\circ f_\\lambda{\\stackrel{\\mathrm{d}}{\\to}}\\mathit{gp}\\circ f_\\lambda,\\ ] ] where @xmath240 is the optimal map from @xmath51 to @xmath227 .",
    "now @xmath537 is also the weak limit of the process @xmath538 where @xmath37 is the random warp function from @xmath51 to @xmath96 .",
    "since these are i.i.d .",
    "elements in @xmath71 , we see that the covariance of @xmath242 is @xmath539 , that is , the kernel is @xmath540 = { \\operatorname{cov}}\\bigl(t(s),t(t ) \\bigr),\\qquad s , t\\in[0,1].\\ ] ] it easily follows from @xmath541 that @xmath242 is a gaussian process .",
    "[ lem : composition ] let @xmath542\\to[0,1]$ ] be strictly increasing piecewise continuously differentiable .",
    "suppose that the derivative of @xmath543 is bounded below by @xmath544 .",
    "then the composition from the right @xmath545 from @xmath546 $ ] takes values in @xmath546 $ ] and it is @xmath547-lipschitz .    since composition from the right is linear , it is sufficient to prove continuity around zero .",
    "this follows from the change of variables formula @xmath548 since @xmath549 .",
    "the statement for @xmath550 holds trivially without any assumptions on @xmath542\\to[0,1]$ ] .",
    "in order to illustrate the estimation framework put forth in the previous sections , we consider two scenarios involving warped poisson processes ( equivalently , cox processes , see section  [ sec : cox ] ) .",
    "more detailed simulations , including comparisons with the fisher  rao approach @xcite , may be found in the supplementary material @xcite .",
    "we first introduce a flexible mixture class of warp maps that provably satisfies assumptions ( a1 ) and ( a2 ) .",
    "this can be seen as an extension of the class considered by wang and gasser in @xcite .",
    "let @xmath366 be an integer and define @xmath551\\to[0,1]$ ] by @xmath552 these are strictly increasing smooth functions satisfying @xmath553 and @xmath554 for any @xmath366",
    ". plots of @xmath555 for @xmath556 are presented in figure  [ fig : sinwarps](a ) .",
    "these maps can be made random by replacing @xmath366 by an integer - valued random variable @xmath6 . if the distribution of @xmath6 is symmetric ( around 0 ) , then it is straightforward to see that @xmath557 = x \\qquad \\forall x\\in[0,1].\\ ] ] this discrete family of random maps can be made continuous by means of mixtures : for @xmath558 let @xmath559 be i.i.d .",
    "integer - valued symmetric random variables , and @xmath560 be the order statistics of @xmath561 i.i.d .",
    "uniform random variables on @xmath41 $ ] , independent of @xmath559 .",
    "the random map @xmath562 \\\\[-8pt ] \\eqntext{x\\in[0,1],}\\end{aligned}\\ ] ] satisfies assumptions ( a1 ) and ( a2 ) .",
    "the parameter @xmath563 can be seen as controlling the _ variance _ of @xmath39 : the larger @xmath563 is , the more variables are being averaged , and so a law of large numbers effect yields maps that deviate only slightly from the identity [ see figure  [ fig : sinwarps](b ) and [ fig : sinwarps](c ) ] .     for @xmath564 ; realisations of @xmath39 defined as in equation ( [ eq : sinewarps ] ) with @xmath565 and @xmath566 where @xmath567 is poisson with mean 3 , and @xmath568=\\mathbb{p}[v_2=-1]=1/2 $ ] , independently of @xmath567 ; realisations of @xmath39 defined as in equation ( [ eq : sinewarps ] ) with @xmath569 and @xmath570 as in . ]",
    "we first focus on a scenario where assumptions ( b1 ) and ( b2 ) hold true .",
    "we consider a structural mean measure that is a mixture of three independent components : two gaussian distributions ( of unit variance ) , restricted to the interval @xmath571 $ ] , and a beta background with parameters @xmath572 , restricted on the interval @xmath573 $ ] .",
    "we wish to discern the two clear modes ( located at @xmath574 ) , but these may be smeared by phase variation .",
    "the structural mean density is @xmath575 + \\frac{\\varepsilon } { 24 } \\beta_{1.5,1.5 } \\biggl(\\frac{x+12}{24 } \\biggr),\\ ] ] where @xmath395 denotes a standard gaussian density , @xmath576 is the @xmath577 density , and @xmath578 is the strength of the background .",
    "we generated 30 independent poisson processes with this structural mean measure and @xmath579 , and warped them by means of 30 independent warp maps @xmath175 , obtaining 30 warped point processes [ figure  [ fig : bidendist](c ) ] .",
    "the warp maps @xmath580 are affinely transformed versions of the maps shown in figure  [ fig : sinwarps](b ) according to the mapping @xmath581 in order to re - scale their support to @xmath571 $ ] . recall that the warp maps in figure  [ fig : sinwarps](b ) were generated using the definition in equation ( [ eq : sinewarps ] ) , taking @xmath565 and @xmath570 are i.i.d .",
    ", distributed as @xmath582 , where @xmath567 is poisson with mean 3 , and @xmath568=\\mathbb{p}[v_2=-1]=1/2 $ ] , independently of @xmath567 .",
    "these correspond to rather violent phase variation , as can be seen by the plots of the conditional density / distribution of the warped processes given the corresponding @xmath37 in figure  [ fig : bidendist](a ) and [ fig : bidendist](b ) .     in solid black ; their corresponding distribution functions , with the structural mean distribution function in solid black ; thirty cox processes , constructed as follows : first we generate @xmath478 as i.i.d .",
    "poisson processes with mean density @xmath583 , then we warp them by forming @xmath584 , where @xmath39 are the maps appearing in figure [ fig : sinwarps ] . ]",
    "using the 30 warped spike trains depicted in figure  [ fig : bidendist](c ) , we construct the `` regularised fr ' echet  wasserstein '' estimator as described in section  [ sec : estimation ] .",
    "a slight deviation is that we use a gaussian kernel with bandwidth chosen by unbiased cross validation , rather than the special kernels developed for the asymptotic theory ( with no essential effect on finite sample performance ) .",
    "we thus obtain estimates of the warp maps @xmath585 ( using the definitions in section  [ sec : warp_estimation ] ) , depicted in figure  [ fig4](b ) , which can be used to register the point processes ( figure  [ registration_plots_bimodal ] ) .",
    "the final estimate of the structural mean distribution function ( the regularised frchet  wasserstein estimator ) is depicted in figure  [ fig4](a ) , and contrasted with the true structural cdf , as well as with the naive estimate produced by ignoring warping and averaging the empirical distributions across trains .",
    "we notice that the regularised frchet ",
    "wasserstein estimator performs quite well at discerning the two modes of the structural mean measure , in contrast with the naive estimator which seems to fail to resolve them .",
    "this effect is more clearly portrayed in figure  [ fig4](c ) , which plots kernel estimators of structural mean density constructed using the original ( warped ) point processes , and the registered point processes .",
    "it is important to remark that the minor fluctuations in the density estimate observed are _ not _ related to our method of estimation , but are due to the sampling variation of the spike trains ( i.e. , they are not intrinsic to our registration procedure , but to the kernel density estimation procedure ) , and could be reduced by more careful choice of bandwidth .",
    "figure  [ bimodal_replications ] presents the sampling variation of the regularised frchet ",
    "wasserstein estimator , and contrasts it with the sampling variation of the naive arithmetic estimator for 20 independent replications of the same experiment .",
    "we notice that the naive estimator is clearly biased in the neighbourhoods around the two peaks , and appears to fluctuate around a straight line .",
    "in contrast , the smoothed frchet mean  though presenting fluctuations around the two peaks  appears approximately unbiased .",
    "indeed , its variation is very clearly not fluctuation around a line  to the contrary it suggests two clear elbows in the cdf , which correspond to the two peaks .",
    "are residual curves , centred at @xmath586 ) ; the estimated warp functions ; kernel estimates of the density function of the true structural mean , based on the original spike trains , and on the registered spike trains . ]",
    "are residual curves , centred at @xmath586 . ]",
    "it is also interesting to note that the empirical frchet mean was observed to be insensitive to the choice of the bandwidth parameter used in the construction of the estimated conditional mean measures @xmath496 .",
    "of course , the warp functions @xmath587 themselves ( and hence the registered processes ) would depend on this parameter , since these couple @xmath496 and @xmath588and while the latter is insensitive to the choice of bandwidth parameter , the former is clearly not .",
    "further simulations carried out in the supplementary material @xcite reaffirm these findings for different `` sample sizes '' @xmath589 and choices of smoothing parameter . furthermore , numerical comparisons also carried out in the supplement suggest that fr ' echet  wasserstein registration outperforms fisher  rao registration ( carried out as in @xcite at the level of cdfs ) , in terms of how close the registered processes are to the original point processes ( prior to warping ) , where `` closeness '' is measured by means of the @xmath590 distance of the ordered points .",
    "this is not surprising given our unbiasedness considerations ( proposition  [ prop : umvue ] ) , since the fisher  rao estimator is generally not @xmath76-unbiased .",
    "we now treat a second scenario that somewhat deviates from our model assumptions , because it involves linear warp functions .",
    "consequently , phase variation can also be seen at the level of densities ( see section  [ sec : measures_vs_densities ] ) .",
    "consider the family of triangular densities of support length @xmath591 and height @xmath592 , and their corresponding distribution functions ( see figure  [ fig : lineardendist ] ) @xmath593    our example will consist in phase varying poisson processes , with structural mean distribution equal to @xmath594 ( i.e. , the triangular distribution function with @xmath595 ) . to this aim ,",
    "let @xmath596 be a random variable valued in @xmath597 $ ] , so that the random measures have a common support @xmath598 $ ] , but they are not strictly positive there . following the same steps as in the proof of proposition  [ prop : uniqueness ] , it can be seen that the random measure with distribution function @xmath599 has a unique theoretical frchet mean with distribution function @xmath600}$ ] , in the sense that for all distribution functions @xmath601}$ ] , we have ( allowing for a slight abuse of notation ) @xmath602},f_{h } ) ] < \\mathbb{e } [ d^2 ( g , f_{h } ) ] $ ] ( note that proposition  [ prop : uniqueness ] and its proof remain valid as long as the measures have no atoms ; they do not need to be strictly increasing ) .",
    "the warp map corresponding to an @xmath596 is @xmath603 , and it is not a homeomorphism of @xmath89 ( unless @xmath595 ) , thus violating our assumptions ( see section  [ sec : measures_vs_densities ] ) . to construct our phase - varying point processes ,",
    "we generate 30 i.i.d .",
    "copies @xmath604 of a random variable @xmath596 following the mixture of uniform distributions @xmath605+(1-\\alpha)\\mathcal u[0.35,3]$ ] , where @xmath606 is chosen so that @xmath607=1 $ ] .",
    "then we generate 30 poisson processes , with cumulative mean measure @xmath608 [ i.e. , @xmath595 , see figure  [ fig : lineardendist](c ) ] , @xmath579 , and warp them by the maps @xmath609 .",
    "this yields 30 cox processes , each with a realised directing measure @xmath610 , respectively , where the @xmath611 have distribution functions @xmath612 [ depicted in figure  [ fig : lineardendist](b ) ] .",
    "the resulting warped spike trains are displayed in figure  [ fig : lineardendist](c ) .",
    ", with @xmath613 in solid black ; their corresponding distribution functions @xmath614 , with @xmath594 in solid black ; thirty cox processes , constructed as follows : first , we generate @xmath478 as i.i.d .",
    "poisson processes with mean density @xmath613 , then we warp them by forming @xmath615 . ]    assuming that the parametric form of the model is unknown to us , we carry out the separation of amplitude and phase variation nonparametrically , as described in section  [ sec : estimation ] .",
    "we smooth each spike train using a gaussian kernel with bandwidth chosen by unbiased cross validation to obtain the estimators @xmath616 ( strictly speaking , not in line with our discussion in section  [ sec : lambdaestimation ] , but this has no practical effect ) , estimate the warp functions @xmath585 , as described in section  [ sec : warp_estimation ] , and produce a registration of the point processes using these ( figure  [ registration_plots_triangular ] ) .",
    "we see that these warp functions [ figure  [ fig8](b ) ] are indeed nearly linear ( besides numerical instabilities at the boundary of the domain ) . the regularised frchet ",
    "wasserstein mean of @xmath617 is depicted in figure  [ fig8](a ) , contrasted with the arithmetic mean and the true structural mean .",
    "note that the regularised frchet  wasserstein mean is supported on a subset of the domain , as is the true structural mean ; by contrast , the arithmetic mean is supported almost on the entire domain , which is visible in figure  [ fig8](a ) , where it has left - and - right tails that persist . though both the regularised frchet  wasserstein and the arithmetic mean perform well near the point of symmetry of the structural mean ( which is to be expected , at least for the arithmetic mean , since the location of the structural measure is invariant to the warp action ) , the regularised frchet ",
    "wasserstein mean estimates the support and tails of the structural measure visibly better .",
    "these observations are more clearly depicted in the residual plots contained in figure  [ triangle_replications ] , where the residual curves of the deviation between the arithmetic / frchet means and the estimand are considered , for 20 independent repetitions of the same simulation experiment .",
    "it is seen in that diagram that the arithmetic mean is clearly biased , especially near the boundaries of the support of the true structural mean .",
    "are residual curves , centred at @xmath618 . ]    to gauge the effectiveness of the registration carried out , we also constructed kernel estimators of the density of the structural mean , based on the original ( warped ) point processes , and on the registered ( aligned ) point processes .",
    "these are shown in figure  [ fig8](c ) .",
    "they illustrate that the density estimate based on the raw data overestimates the mode as well as the tails of the true density , whereas the density estimate based on the registered data fits both the bulk and the tails of the  density quite nicely . as in the previous example",
    ", the minor fluctuations of these density estimates are not intrinsic to our registration procedure , but to the kernel density estimation procedure .",
    "stability of the estimated structural mean cdf with respect to the smoothing parameter was also observed in this example , and persisted in additional simulations ( presented in the supplementary material @xcite ) , where different sample sizes were also considered .",
    "simulation comparisons showed that also in this scenario our approach performs at least as well as the fisher  rao approach in terms of registration of the point processes .",
    "we have introduced a framework formalising the confounding of amplitude and phase variation in point process data , and demonstrated how this can be used for their consistent nonparametric separation on the basis of independent realisations thereof .",
    "the key ingredient of our approach was the observation that for the point process warping problem , the classical functional data assumptions on warp functions are equivalent to the geometry of the monge problem of optimal transportation .",
    "a particularly attractive aspect of the present framework is that it yields an identifiable setup , with a clear notion of over / under registration through the concept of bias .",
    "indeed , we prove that consistent estimation of the warp functions _ is _ possible in our framework for point process data , circumventing the so - called `` pinching effect '' ( see , e.g. , kneip and ramsay @xcite , section  2.4 ) even under very sparse sampling regimes ( remark  [ sparse_remark ] ) .",
    "furthermore , our consistency results present some appealing features : there is no finite - dimensional parameterisation , and the unknown warp functions and measures are allowed to be genuinely functional , that is , infinite dimensional ( contrary to , say tang and mller @xcite ; gervini and gasser  @xcite ; rnn @xcite ) ; though the consistency of the warp functions is in the uniform metric , there is no need for the introduction of additional smoothness penalties on the warp functions , and no tuning parameter needs be selected to impose this ( the regularity is inherited directly from the underlying regularity of the structural and conditional mean point process measures themselves ; in the functional case , this corresponds to the regularity of the curves themselves ) ; consistency is established with reference to a population , that is , the number of `` individuals '' ( processes ) is allowed to grow along with the `` density of their sampling '' ( with a clearly identified relationship between the two ) , instead of establishing consistency conditional on the sample ( i.e. , with a fixed number of curves , assuming only that the density of sampling for each curve increasing , with no reference to a more general `` curve population , '' as in , e.g. , kneip and engel @xcite , wang and gasser @xcite , and gervini and gasser @xcite ) . in our experience , when consistency results are given in the functional warping literature , they typically feature at least one of these restrictions .",
    "we do not mention these characteristics as a claim to superiority , but rather point them out as a special feature of the problem in the point process case , afforded by the optimal transportation geometry ( since the very warping process is inextricably linked with the metric structure of the space ) .",
    "nevertheless , it is interesting to note that the functional form of the warp function estimator ( [ warping_estimator ] ) is strikingly similar with the pairwise synchronisation estimator of tang and mller @xcite , equation ( 7 ) .",
    "further to consistency , we are able to obtain detailed rates of convergence . these show @xmath4-consistency and a central limit theorem in the special case of warped poisson processes ( cox processes ) under dense sampling .",
    "these can serve as a basis for uncertainty quantification , but also indicate that our estimator can attain the optimal rate of convergence under dense sampling .",
    "though we have demonstrated that the optimal transportation geometry is canonical if warping occurs at the level of the spike train observations ( at the level of measures ) , it is possible to introduce warping at the level of the density of the underlying mean measure ( see section  [ sec : measures_vs_densities ] ) . in such a framework",
    ", there are options other than the optimal transportation geometry that be may better suited for the formalisation of the warping problem .",
    "for example , in the case of functional data , tucker , wu and srivastava @xcite attack the warping problem by imbedding the data in a quotient space modulo warp functions .",
    "this is done by employing a fisher  rao - type metric , which is invariant with respect to the action of a warping group .",
    "recent work by wu and srivastava @xcite extends their approach to the case of spike trains , by smoothing the spike trains and considering them as densities in the fisher  rao space .",
    "this geometry may be more natural than the optimal transportation one to model phase variation at the level of densities .",
    "a natural question for further work is that of _ multivariate phase variation_. for example , is the `` canonicity '' of the optimal transportation framework preserved , and can one fruitfully proceed in a similar manner ?",
    "the key challenge in this case is that , in the case of measures on subsets of @xmath619 , @xmath620 , evaluation of the empirical frchet mean in closed form is impossible ( see , e.g. , agueh and carlier @xcite ) .",
    "approximations can be sought , for example , via gaussian assumptions ( cuturi and doucet @xcite ) or via reduction to several 1d problems ( bonneel et al .",
    "@xcite ) . indeed ,",
    "during the final preparation of this manuscript , we became aware of interesting independent work in parallel by boissard , leguic and loubes @xcite , who consider the problem of estimating wasserstein barycentres for measures on @xmath619 , and define `` admissible '' groups of deformations that mimic the 1d case , thus allowing for consistent estimation and evaluation of the sample barycentre by calculating successive means between pairs ( i.e. , by an iterated barycentre ) .",
    "finally , it should be mentioned that once phase and amplitude variation have been separated , they could each be subjected to a further analysis of their own .",
    "the amplitude variation clearly would be analysed by means of _ linear pca _ tools , along the lines described in section  [ sec : amp_pp ] . on the other hand",
    ", the phase variation can be analysed by making further use of the geometrical properties described in section  [ sec : geometry ] : for instance , via tangent space pca ( see , e.g. , boissard , leguic and loubes @xcite ) or via geodesic pca ( see , e.g. , bigot et al .",
    "indeed , the form of the limiting covariance function in our central limit theorem ( theorem  [ thm : asynorm ] ) suggests that strong connections can be established between wasserstein pca methodology and the separation of amplitude and phase variation .",
    "this paper grew out of work presented at the mathematical biosciences institute ( ohio state university ) , during thehttp://mbi.osu.edu / event/?id=162[``statistics of time warping and phase variation '' ] workshop , november2012 .",
    "we wish to acknowledge the stimulating environment offered by the institute .",
    "we are grateful to an associate editor and three referees for their insightful and constructive comments .",
    "the paper has genuinely improved as a result of the review process ."
  ],
  "abstract_text": [
    "<S> we develop a canonical framework for the study of the problem of registration of multiple point processes subjected to warping , known as the problem of separation of amplitude and phase variation . </S>",
    "<S> the amplitude variation of a real random function @xmath0\\}$ ] corresponds to its random oscillations in the @xmath1-axis , typically encapsulated by its ( co)variation around a mean level . </S>",
    "<S> in contrast , its phase variation refers to fluctuations in the @xmath2-axis , often caused by random time changes . </S>",
    "<S> we formalise similar notions for a point process , and nonparametrically separate them based on realisations of i.i.d . </S>",
    "<S> copies @xmath3 of the phase - varying point process . </S>",
    "<S> a key element in our approach is to demonstrate that when the classical phase variation assumptions of functional data analysis ( fda ) are applied to the point process case , they become equivalent to conditions interpretable through the prism of the theory of optimal transportation of measure . </S>",
    "<S> we demonstrate that these induce a natural wasserstein geometry tailored to the warping problem , including a formal notion of bias expressing over - registration . within this framework </S>",
    "<S> , we construct nonparametric estimators that tend to avoid over - registration in finite samples . </S>",
    "<S> we show that they consistently estimate the warp maps , consistently estimate the structural mean , and consistently register the warped point processes , even in a sparse sampling regime . </S>",
    "<S> we also establish convergence rates , and derive @xmath4-consistency and a central limit theorem in the cox process case under dense sampling , showing rate optimality of our structural mean estimator in that case .    </S>",
    "<S> ./style / arxiv - general.cfg </S>"
  ]
}