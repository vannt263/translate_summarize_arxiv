{
  "article_text": [
    "point estimation is the most popular forms of statistical inference ( see lehmann and casella @xcite ) .",
    "we introduce in this paper a new statistical point estimation approach which found be useful in special practical situations such as truncated and grouped and censored data .",
    "the data are said to be truncated when measuring devices fail to report observations below and/or above certain readings .",
    "for example , truncated data frequently arise in the statistical analysis of astronomical observations ( see efron and petrosian @xcite ) and in medical data ( see klein and zhang @xcite ) , and if the truncation is ignored this can cause considerable bias in the estimation .",
    "there exists in the literature many approaches of estimation from `` incomplete data '' such as maximum likelihood based approach of the em algorithm ( hartley @xcite , dempster et _ al _ @xcite ) , or nonparametric methods such as kaplan - meier ( kaplan and meier @xcite ) or lynden - bell estimators ( lynden - bell @xcite ) .",
    "the purpose of the present paper is to investigate another approach which consists on combining two new methods of estimation and to apply it in the fixed type i censored or grouped and censored data situations .    in the first method",
    ", we remark that in estimation problems we deal in general with three functions : a theoretical probability law @xmath0 of a random variable @xmath1 depending on a parameter @xmath2 ( real or vector valued ) , an empirical distribution @xmath3 constructed from a sample of observations drawn from the random variable @xmath1 and an estimation @xmath4 ( from an estimation @xmath5 of @xmath2 ) obtained through the empirical law @xmath6 the empirical distribution @xmath7is considered as a representative distribution of @xmath8 but in practice it is reduced to only few of its characteristics such as the mean and variance . the variational aspect of @xmath3 is often neglected while its importance .",
    "we can easily find , for instance , two distributions having the same support , mean and variance while their variations differ significantly , or conversely having the same variations but their supports and characteristic parameters are different . but",
    "two probability distributions with same support and same variations in each subset of the support are necessarily the same .",
    "we introduce then a new distance which measures the difference between variations of two distributions on a finite number of points and to use it for estimation purposes by the method of minimum distance .",
    "since the new measure is not equivalent to classical ones it will give new insights that could not be investigated by classical distances .    in the second method , we remark that the empirical distribution arising from a sample of observations can be viewed in fact as a conditional distribution as it is built from the knowledge of the data",
    ". it will be then an estimation of the theoretical conditional distribution with respect to the observations before being an estimation for the parent distribution .",
    "this theoretical conditional distribution is represented by the auxiliary distribution introduced in this paper . to determine this distribution in discrete case , we have simply to take the conditional distribution with respect to the observed values and we proceed analogously for the continuous case .",
    "it should be noted that in discrete case it is known as the truncated distribution which is the conditional distribution given a truncation ( see for example shaw @xcite ) but it is presented here in a general framework .",
    "we have to deal with two discrete probability distributions having the same finite support , a theoretical distribution and its empirical representation with respect to the observations .",
    "the parameters of the former are those of the parent distribution and the aim is to estimate them from the first instead of the parent one as commonly used .",
    "we use classical tools such as the method of moments or maximum likelihood principle .",
    "the setting that seems to us most suitable for illustrating our approach is the one of truncated or grouped and censored data . in usual practical problems",
    ", truncation can be on left or right or in either situations , and the `` cut off '' can be deterministic or random . in our approach",
    ", the truncation may be on any part of the range of the distribution so that the setting is more general .",
    "also , classical approaches for truncated data are in general custom - made depending on specific problems and distributions , or subjective based methods . instead , our approach is quite general and might be used in any situation where the underlying complete data come from a known family of distributions .",
    "we confine ourselves as a first presentation to fixed type i and grouped and censored data .",
    "in the subsequent section , we propose a variational distance between probability distributions . in section 3",
    ", we define a truncation of data and associated empirical and theoretical distributions and we use two different methods for estimation from truncation , a first method using minimum of the new distance introduced in this paper and a second method based on traditional tools of estimations such as the method of maximum likelihood . in section 4 , we present the new approach and we illustrate the procedure by three examples : a binomial probability law , a normal distribution and a gamma density function .",
    "we present also a basic feature of the new approach which prove the accuracy of the method and some illustrative examples . in section 5 ,",
    "we give some elements of comparison with the classical approach of estimation . in section 6",
    ", we list some perspectives of the new approach : model selection from truncated data using the new distance , estimation of the first trial value in the celebrate _ em _ algorithm for incomplete data in the case of truncation and merged normal distributions , a goodness of fit test based on the new distance , decision making about the quality of estimations and data . finally , concluding remarks are made some pointing to other possible extensions and applications .",
    "as is usual , given a sample of @xmath9 independent and identically distributed observations , @xmath10 drawn from an unknown discrete random variable @xmath11 falling in a discrete family of probability laws @xmath12 depending on a parameter @xmath2 ( real or vector valued ) , i.e. , @xmath13 one can summarize the sample into @xmath14 couples @xmath15 @xmath16 where the @xmath17 are the different values taken by the sample and @xmath3 is the empirical law @xmath18 where @xmath19 represents the absolute frequency of the value @xmath20",
    "@xmath21    usually , it is hoped that @xmath22 in a certain probabilistic sense .",
    "but if the empirical distribution arises from truncated data , we do not hope in general having @xmath23 for the values @xmath24 in the support of @xmath25 since the complete sample size @xmath9 is usually not reported .",
    "however , we expect reasonably to have approximately@xmath26 for any points in its support , only if the sample has serious irregularities .",
    "introduce the following _ distance _ _ of _ _ proportional variations _ between @xmath0 and @xmath3@xmath27 it turns out that this new distance , as we will show , measures the variations between probability distributions .    in continuous case also , any sample @xmath28 is summarized into @xmath14 couples @xmath29 @xmath30 @xmath31 .",
    "this can be done uniquely , by grouping for example the sample in classes where the @xmath17 are the mid - classes ( or class means ) and @xmath32 where @xmath3 is an empirical density estimator , or the data is presented in a grouped and censored form .",
    "the proportional variational distance @xmath33 in this case , between the density @xmath34 of @xmath11 and its empirical law @xmath25 is thus defined as ( [ dv1 ] ) .",
    "one of its main powerful feature is that when using traditional distances we have to use the sample size @xmath9 through the expression of @xmath35 where @xmath36 is the size of class intervals ; but sometimes , as for truncated data situations where measuring devices fail to report even the number of sample points in certain ranges , then the real size @xmath9 is not known , but a truncated sample size @xmath37 is instead used . using the ratios",
    "@xmath38 will clear up the effect of the truncated sample size which can lead to considerable bias in the estimation .",
    "note that @xmath33 possesses the properties of symmetry and triangle inequality .",
    "but in the identity property @xmath39 the equality between @xmath40 and @xmath41 must be understood in the sense that @xmath40 and @xmath41 have the same variations on the points @xmath24 and @xmath42 it should be stressed that this new measure is not equivalent to classical ones and should then give new insights and information about other characteristics and features of probability distributions .    from now on @xmath40 shall represent a theoretical probability law in both discrete or continuous cases and @xmath3 shall represent the corresponding empirical law in both cases .",
    "denote by @xmath43 the set of _ atoms _ of @xmath40 or _",
    "support_. let @xmath44 be the @xmath45algebra generated by sets @xmath46 where the @xmath47 are the borel sets of @xmath48 and @xmath49 for all @xmath50 we have @xmath51where @xmath52 is the lebesgue measure on @xmath48 . in discrete case , we have @xmath53    for all",
    "@xmath54 we set @xmath55 @xmath56 and @xmath57 let @xmath58 @xmath59 and @xmath60 the probability space @xmath61 represents the space of samples of size @xmath9 from the random variable @xmath62 we omit the subscript @xmath9 in @xmath63 for notational convenience and shall denote the sample space as @xmath64      we will discuss now the measure theoretic aspect of the new distance introduced above .",
    "let @xmath65 and @xmath66 two probability measures defined on the same measurable space @xmath67 , @xmath40 and @xmath41 their respective probability densities , not necessarily with respect to the same measure and @xmath68 an event of this space .",
    "we say that @xmath40 and @xmath41 have the same variation on @xmath68 , if the respective restrictions of @xmath40 and @xmath41 on @xmath68 , define the same probability measure on @xmath68 endowed with the sigma algebra traces of @xmath44 on @xmath68 .",
    "let @xmath40 and @xmath41 two probability distributions positive and defined on a part @xmath68 not reduced to only one element .",
    "if in any point @xmath69 of @xmath70 , we have : @xmath71 then we say that @xmath40 and @xmath41 have same variations on @xmath68 .",
    "let @xmath40 be a density of a probability measure @xmath65 and @xmath68 an event such that @xmath72 .",
    "the restriction of @xmath40 on @xmath68 and the conditional distribution of @xmath40 with respect to @xmath68 define the same probability measure on @xmath68 and consequently they have the same variations on @xmath73    let @xmath40 and @xmath41 two probability distributions and @xmath68 an event on which they are strictly positive . if @xmath68 is discrete and not reduced to only one element , and one of the distributions @xmath40 and @xmath41 being discrete and the other may not be discrete , we call distance in variations between @xmath40 and @xmath41 on @xmath68 the quantity:@xmath74 if @xmath68 is an interval of @xmath48 and , @xmath40 and @xmath41 are probability densities on @xmath48 , with respect to lebesgue measure @xmath52 on @xmath48 , we call distance in variations between @xmath40 and @xmath41 on @xmath68 , the quantity:@xmath75    let be given a classical distance @xmath76 between two functions @xmath40 and @xmath41 which associates for points @xmath24 and @xmath77 from the intersection of their domain of definitions , the quantity @xmath78    we have the following properties for the distance @xmath79**1 .",
    "* * @xmath80 the converse is not always true.*2 .",
    "* let @xmath3 be a kernel density estimation .",
    "then @xmath81 in probability.*3 .",
    "* let @xmath40 and @xmath41 be two functions defined on @xmath48 and @xmath82 satisfying:@xmath83 if@xmath84 where @xmath52 is the lebesgue measure on @xmath48 , then@xmath85    * 1 .",
    "* follows directly from the definitions of @xmath76 and @xmath86**2 .",
    "* * follows from the fact @xmath87 in probability ( see parzen @xcite ) , then @xmath81 in the same probabilistic notion of convergence.*3 .",
    "* fix @xmath88 we have @xmath89 for all @xmath90 this implies that@xmath91 we deduce that @xmath92 and the result follows .",
    "the truncated data specification , or generally _ incomplete data , _ implies the existence of two sample spaces @xmath93 and @xmath94 , such that the complete sample space is given by @xmath95 the observed data @xmath96  where @xmath37 is the truncated sample size , are a realization from @xmath93 and the unobserved data @xmath97 where @xmath9 is the complete unknown sample size , are from @xmath98 the complete data @xmath99 is known only through the observed data @xmath100 ( see dempster , laird and rubin @xcite for further explanations about incomplete data specification)_. _    consider a sample of observations @xmath28 drawn from a theoretical probability law @xmath101 depending on a parameter @xmath102 as usual , the data are summarized , in discrete or continuous cases ( as shown in section 2 ) , into @xmath14 couples @xmath103 @xmath16 and let @xmath104 a part from the set @xmath105 @xmath106 which we will call _ truncation .",
    "_ the observed data is summarized by a truncation @xmath107 and an empirical estimation @xmath108 and assume that the unobserved data is also summarized by a set @xmath109 and @xmath110    the structure of the new distance @xmath33 allows the following decomposition property:@xmath111 the following proposition is typical for the new distance and is useful for using the minimum of distance @xmath86    let be given a truncated data @xmath112 with corresponding empirical estimation @xmath113 then @xmath114 in probability .",
    "we have from proposition 1 that @xmath115 in probability .",
    "then , from the decomposition property ( [ dec ] ) we obtain @xmath116 in probability .",
    "define the empirical distribution @xmath4 corresponding to a given truncation @xmath117 by:@xmath118{c}\\widetilde{f}_{i}\\text { \\ \\ \\ \\ if \\ \\ } x = u_{i},\\text { \\ \\ } i=1, ... ,m,\\\\ 0\\text { \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ otherwise , \\ \\ \\ \\ \\ \\ \\ \\ \\ } \\end{array } \\right.\\ ] ] where the @xmath119 satisfy the following set of proportional allocation equations @xmath120 for @xmath121 and @xmath122    define the following auxiliary distribution from @xmath101 which is akin to the proportional allocation procedure for missing values ( see hartley @xcite).@xmath123{c}\\dfrac{f(x,\\theta)}{f(u_{1},\\theta)+f(u_{2},\\theta)+ ... +f(u_{m},\\theta)}\\text { \\ \\ \\ \\ if \\ \\ } x = u_{i},\\text { \\ \\ } i=1,",
    "... ,m,\\\\ 0\\text { \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ otherwise \\ } \\end{array } \\right .",
    "\\label{auxil}\\ ] ]    if the truncation is random , that is , there exists a random variable @xmath124 such that we observe , for example , the random variable @xmath11 only if @xmath125 or @xmath126 then the probability law used in ( [ auxil ] ) is replaced by the conditional law of @xmath11 with respect to @xmath127 or @xmath128 respectively .",
    "the auxiliary distribution @xmath129 was found be useful for estimation problems in truncated data .",
    "indeed , it is well known in classical estimation from truncated data ( see hartley @xcite ) that missing values could be recovered by `` proportional allocation '' procedures , then the auxiliary distribution @xmath130 which is already based on proportional allocation , will be an intuitive and natural tool for estimation purposes from truncated data .",
    "the function @xmath129 is a theoretical probability distribution depending on the same parameters of those of @xmath40 .",
    "it has also the same _ support _ as that of @xmath131    we call @xmath4 and @xmath132 the empirical and theoretical distributions of a given truncation @xmath133 from a sample of observations @xmath134",
    "we will use mainly two methods of estimation .",
    "the first method is a minimum distance estimation using the metric @xmath33 between the empirical and theoretical distributions @xmath3 and @xmath135 the second is similar to traditional ones such as the method of substitution or maximum likelihood principle , by considering @xmath4 as an empirical estimation of @xmath136 the first is based on variational difference between distributions and the second in the sense of an euclidean difference and hence they treat different aspects of the sample of observations .",
    "if for a given data they give different estimations , we can not suspect the approaches but we can say that the data do not restore in a coherent way all aspects of the probability distribution from which it emanated . if on the other hand they give significantly the same estimations we can assert that the estimation is credible since through different aspects it has given the same distribution .",
    "that is the distribution which fits the best the empirical distribution .",
    "practically , we propose to calculate the estimations by the two methods and take the second one since based on maximum likelihood principle of good known theoretical properties .",
    "we use then the first as a tool of decision on whether the estimation is credible or not . the estimation",
    "will then be considered as credible in cases where the two methods give approximately the same estimation .",
    "let @xmath137 a sample with @xmath138 @xmath139 with@xmath140 @xmath141 where @xmath142 is a borel set of @xmath48 such that @xmath143 for all @xmath144    the family ( [ fam1 ] ) is very rich , one finds there , for example , the family of the normal laws , and the family of the laws of poisson .",
    "we assume that the support @xmath142 does not depend on @xmath145 denote by @xmath146 the estimator by the minimum of metric @xmath33 between the empirical and theoretical distributions @xmath147 ( based on a sample of size @xmath9 ) and @xmath101 that is@xmath148 this estimator falls into the class of m - estimators .",
    "using well known theorems on the convergence of m - estimators ( see for example amemiya @xcite ) we will prove that @xmath149 converges in probability to the true parameter .",
    "let @xmath137 be a sample from the family of distributions ( [ fam1 ] ) .",
    "if the set of natural parameters @xmath150 is covex and the true parameter @xmath2 is an interior point of @xmath151 then the estimator @xmath149 by the minimum of the distance of variations @xmath33 converges in probability to the true parameter @xmath152 i.e.,@xmath153    since we search for a minimum of the criterion function @xmath154 it suffices to show , under the assumptions of the family ( [ fam1 ] ) and the convexity of the set @xmath151 that @xmath155 seen as a function of @xmath2 is a convex function ( see amemiya @xcite ) .",
    "hence , this reduces the problem to the convexity of@xmath156 for @xmath157 with @xmath158 , and @xmath159 we have@xmath160 \\left (   t_{k}(y_{i})-t_{k}(y_{j})\\right )   \\right\\ }   -a_{ij}\\right\\vert\\ ] ] where @xmath161 and assume that @xmath162 and @xmath163we have from the convexity of the exponential function that@xmath164",
    "\\left (   t_{k}(y_{i})-t_{k}(y_{j})\\right )   \\right\\ }    & \\leq\\lambda\\exp\\left\\ {   \\sum_{k=1}^{s}\\theta_{k}^{(1)}\\left (   t_{k}(y_{i})-t_{k}(y_{j})\\right )   \\right\\ } \\\\ &   + \\mu\\exp\\left\\ {   \\sum_{k=1}^{s}\\theta_{k}^{(2)}\\left (   t_{k}(y_{i})-t_{k}(y_{j})\\right )   \\right\\ }   , \\end{aligned}\\ ] ] then@xmath165   \\left (   t_{k}(y_{i})-t_{k}(y_{j})\\right )   \\right\\ } -a_{ij}\\leq\\]]@xmath166@xmath167   + \\]]@xmath168   .\\ ] ] introducing the absolute value we get@xmath160 \\left (   t_{k}(y_{i})-t_{k}(y_{j})\\right )   \\right\\ }   -\\left (   \\lambda + \\mu\\right )   a_{ij}\\right\\vert\\]]@xmath169@xmath170 hence @xmath171 is a convex function of @xmath152 which implies the convexity of @xmath155 seen as a function of @xmath2 and then the convergence in probability of the minimum of distance @xmath33 estimator .",
    "we firstly begin in a general situation , that of the one - parameter exponential family , to show how to use the procedure explained below in the case of the new method .",
    "consider the one - parameter exponential family with density@xmath172,\\ ] ] where @xmath2 is the parameter , @xmath124 a statistic , @xmath173 a function of @xmath24 and @xmath174 is a function of the parameter @xmath2 .",
    "let us use the maximum likelihood principle .",
    "consider a sample of observations @xmath28 from which we derive the support @xmath175 we then construct the auxiliary distribution from the support @xmath117 , expressed in the following form@xmath176}{\\sum_{i=1}^{k}k(y_{i})\\times\\exp[\\theta t(y_{i})-a(\\theta)]}.\\ ] ] we have to maximize the likelihood function given in our case by@xmath177 without loss of generality , we assume that the class intervals are the same . then , we have@xmath178}{{\\displaystyle\\sum\\limits_{i=1}^{k } } k(y_{i})\\times\\exp[\\theta t(y_{i})-a(\\theta)]}\\right ]   , \\ ] ] taking the derivative and solving the score equation on @xmath2 we obtain an estimator of the parameter @xmath2 satisfying the relation@xmath179 the later result may be obtained directly by the method of moments , but we have presented the maximum likelihood method since it is widely used in statistical inference .",
    "in order to test the performance of the proposed approach , we use synthetic data sets which were generated by simulation from three examples of probability law : binomial law , normal density and a gamma distribution .",
    "the examples were selected from various simulation studies from different family of probability distributions and the two methods have shown their effectiveness and never deviate significantly from the true parameter .",
    "the reason for using synthetic data sets is that the true parameters for the synthetic datasets are known and the accuracy of results obtained by using the two new methods can be compared .",
    "* binomial distribution .",
    "* we generated a synthetic data set of size @xmath180 from a binomial law @xmath181 with @xmath182 and @xmath183 and denote by @xmath184 its probability mass function .",
    "the data are summarized in the following table .",
    "* table 1 .",
    "*    [ c]ccccccccc@xmath17 & @xmath185 & @xmath186 & @xmath187 & @xmath188 & @xmath189 & @xmath190 & @xmath191 & @xmath192 + @xmath193 & @xmath194 & @xmath195 & @xmath196 & @xmath197 & @xmath198 & @xmath199 & @xmath200 & @xmath190 +    our aim is to estimate the parameter @xmath201 with the knowledge of @xmath182 , from different truncation of data .    for illustrating the two methods ,",
    "consider the truncation @xmath202 with truncated sample size @xmath203 we have then a truncation proportion of @xmath204 @xmath205 in data .",
    "for the first method , we have to search the value of the parameter @xmath206 which minimizes the distance @xmath154 that is:@xmath207    using computer algebra package , we obtain the result @xmath208    for the second method , the empirical distribution @xmath4 given the truncation @xmath209 is given by @xmath210 @xmath211 , @xmath212 @xmath213 and @xmath214 if @xmath215    the auxiliary distribution @xmath216 is given by:@xmath217 by the method of substitution , the estimation of @xmath206 is obtained by solving the equation:@xmath218 using a computer algebra package we obtain the result @xmath219 .    in the following table",
    "we present the estimations @xmath220 from the first method using minimum distance approach using the distance @xmath33 , and @xmath221 from the auxiliary distribution , of the parameter @xmath201 for known @xmath222 according to the truncation @xmath133 considered .    * table 2 . * the estimations @xmath220 and @xmath221 by the new approach of the parameter @xmath206    of the binomial probability law @xmath181 with @xmath223 and known @xmath182 .",
    "[ c]cccccc & & truncated & proportion of & & + @xmath224 & @xmath117 & sample size @xmath37 & truncation @xmath66 @xmath225 & @xmath226 & @xmath221 + @xmath186 & @xmath227 & @xmath180 & @xmath185 & @xmath228 & @xmath229 + @xmath187 & @xmath230 & @xmath231 & @xmath232 & @xmath233 & @xmath234 + @xmath188 & @xmath235 & @xmath236 & @xmath237 & @xmath238 & @xmath239 + @xmath189 & @xmath240 & @xmath241 & @xmath194 & @xmath233 & @xmath234 + @xmath190 & @xmath242 & @xmath243 & @xmath244 & @xmath245 & @xmath239 + @xmath191 & @xmath246 & @xmath247 & @xmath248 & @xmath233 & @xmath229 + @xmath192 & @xmath249 & @xmath250 & @xmath251 & @xmath252 & @xmath253 + @xmath254 & @xmath255 & @xmath256 & @xmath257 & @xmath233 & @xmath258 + @xmath259 & @xmath260 & @xmath261 & @xmath262 & @xmath233 & @xmath263 + @xmath264 & @xmath265 & @xmath266 & @xmath267 & @xmath245 & @xmath245 + @xmath268 & @xmath269 & @xmath270 & @xmath271 & @xmath228 & @xmath228 + @xmath272 & @xmath273 & @xmath274 & @xmath275 & @xmath233 & @xmath234 + @xmath276 & @xmath277 & @xmath278 & @xmath279 & @xmath280 & @xmath281 + @xmath282 & @xmath283 & @xmath284 & @xmath285 & @xmath229 & @xmath252 + @xmath194 & @xmath286 & @xmath287 & @xmath288 & @xmath289 & @xmath233 + @xmath290 & @xmath291 & @xmath292 & @xmath293 & @xmath294 & @xmath295 + @xmath296 & @xmath297 & @xmath298 & @xmath299 & @xmath300 & @xmath263 + @xmath244 & @xmath301 & @xmath302 & @xmath303 & @xmath304 & @xmath305 +    as previously said , the two estimations by the new approach , @xmath226 and @xmath306 are accurate in all cases and close to each other .",
    "furthermore , the truncation proportion has no effect on the quality of estimations .",
    "the two estimations are also not sensitive to small cell probabilities as for truncations including the value @xmath307 it should be noted that the classical estimation by maximum likelihood without truncation is @xmath308 and considering our approach we obtained the estimations @xmath309 for the first method and @xmath310 for the second.*normal distribution .",
    "* consider a sample of size @xmath311 drawn from a normal population with mean @xmath312 and standard deviation @xmath313 consider the data falling in @xmath268 fixed class intervals as shown in the following table , with mid - classes @xmath314 and absolute frequencies @xmath193**table 3.**@xmath315{cccccccccccc}\\hline $ ] y_i@xmath316 - 2.581@xmath316 - 2.06@xmath316 - 1.533@xmath316 - 1.009@xmath316 - 0.485@xmath3160.039@xmath3170.563@xmath3161.086@xmath3161.610@xmath3162.134@xmath3162.658@xmath318n_i@xmath3165@xmath3168@xmath31623@xmath31648@xmath31671@xmath31689@xmath31672@xmath31643@xmath31625@xmath31610@xmath3176@xmath319    the number of bins can be selected from an optimal procedure developed by birg and rozenholc @xcite .",
    "let the following table where we estimate simultaneously @xmath320 and @xmath321 by the minimum distance procedure with @xmath322 .",
    "we denote the estimations by @xmath323 and @xmath324 in each line of the table the estimates are made starting from the table of frequencies based on the observations indicated in the first column .",
    "the truncated sample size is denoted by @xmath325 we have then a truncation proportion of @xmath326 in data .    * table 4 . *",
    "[ c]ccccc@xmath327 & @xmath37 & @xmath328 & @xmath329 & @xmath330 + @xmath331 & @xmath311 & @xmath185 & @xmath332 & @xmath333 + @xmath334 & @xmath335 & @xmath189 & @xmath336 & @xmath337 + @xmath338 & @xmath339 & @xmath340 & @xmath341 & @xmath342 + @xmath343 & @xmath344 & @xmath345 & @xmath346 & @xmath347 + @xmath348 & @xmath349 & @xmath276 & @xmath350 & @xmath351 + @xmath352 & @xmath353 & @xmath354 & @xmath346 & @xmath355 + @xmath356 & @xmath357 & @xmath358 & @xmath359 & @xmath360 + @xmath361 & @xmath362 & @xmath363 & @xmath364 & @xmath365 + @xmath366 & @xmath367 & @xmath368 & @xmath369 & @xmath370 + @xmath371 & @xmath372 & @xmath373 & @xmath346 & @xmath347 + @xmath374 & @xmath375 & @xmath376 & @xmath377 & @xmath378 + @xmath379 & @xmath380 & @xmath381 & @xmath382 & @xmath383 +    in practice , the bins are in fact chosen after obtaining the truncated sample so the results should be more efficient , but this does not affect the preceding results obtained after grouping the whole sample and truncate from the bins since the aim is to give some feel about the accuracy of the estimations . also we can avoid grouping the observations by considering empirical frequencies obtained from kernel density estimations .",
    "consider a sample of size @xmath384 drawn from a gamma distribution @xmath385 with density given by@xmath386 and parameters @xmath387 and @xmath388 consider the data falling in @xmath290 fixed class intervals as shown in the following table , with mid - classes @xmath314 and absolute frequencies @xmath389    * table 5 . *",
    "@xmath315{ccccccccccc}\\hline $ ] u_i@xmath3165.89@xmath3168.72@xmath31611.56@xmath31614.39@xmath31617.23@xmath31620.06@xmath31622.89@xmath31725.73@xmath31628.56@xmath31631.39@xmath318n_i@xmath31611@xmath31640@xmath31660@xmath316108@xmath316118@xmath316104@xmath316100@xmath31674@xmath31663@xmath31753@xmath390    [ c]cccccc@xmath391 & @xmath392 & @xmath393 & @xmath394 & @xmath395 & @xmath396 + @xmath397 & @xmath398 & @xmath268 & @xmath190 & @xmath188 & @xmath187 +    in the following table we show the estimations @xmath399 from the minimum of distance @xmath33 and @xmath400 by the second method for the parameter @xmath401 with known @xmath402 according to the truncation @xmath117 considered .    * table 6 . * the estimations @xmath399 and @xmath400 by the new approach of the parameter @xmath403    of the gamma probability distribution @xmath385 with @xmath404 and known @xmath387 .",
    "[ c]cccccc@xmath224 & @xmath117 & @xmath37 & @xmath66 @xmath225 & @xmath399 & @xmath405 + @xmath186 & @xmath406 & @xmath384 & @xmath185 & @xmath407 & @xmath408 + & @xmath409 & & & & + @xmath187 & @xmath410 & @xmath411 & @xmath412 & @xmath413 & @xmath414 + & @xmath415 & & & & + @xmath188 & @xmath416 & @xmath417 & @xmath418 & @xmath419 & @xmath420 + @xmath189 & @xmath421 & @xmath422 & @xmath423 & @xmath424 & @xmath425 + @xmath190 & @xmath426 & @xmath427 & @xmath264 & @xmath428 & @xmath429 + @xmath191 & @xmath430 & @xmath431 & @xmath194 & @xmath432 & @xmath433 + @xmath192 & @xmath434 & @xmath435 & @xmath436 & @xmath437 & @xmath438 + @xmath254 & @xmath439 & @xmath440 & @xmath441 & @xmath442 & @xmath407 + @xmath259 & @xmath443 & @xmath444 & @xmath445 & @xmath446 & @xmath447 + @xmath264 & @xmath448 & @xmath449 & @xmath450 & @xmath451 & @xmath452 + @xmath268 & @xmath453 & @xmath454 & @xmath455 & @xmath456 & @xmath457 + @xmath272 & @xmath458 & @xmath459 & @xmath460 & @xmath461 & @xmath462 + @xmath276 & @xmath463 & @xmath464 & @xmath465 & @xmath456 & @xmath442 + @xmath282 & @xmath466 & @xmath467 & @xmath468 & @xmath407 & @xmath469 + @xmath194 & @xmath470 & @xmath471 & @xmath472 & @xmath473 & @xmath474 + @xmath290 & @xmath475 & @xmath476 & @xmath477 & @xmath478 & @xmath479 + @xmath296 & @xmath480 & @xmath481 & @xmath482 & @xmath407 & @xmath483 + @xmath244 & @xmath484 & @xmath485 & @xmath486 & @xmath487 & @xmath488 + @xmath489 & @xmath490 & @xmath491 & @xmath492 & @xmath493 & @xmath494 + @xmath495 & @xmath496 & @xmath497 & @xmath498 & @xmath474 & @xmath499 +    the estimations from the two methods are also accurate in this case of gamma distribution for the parameter @xmath500 here also the truncation proportion does not affect the quality of estimations .",
    "when we consider the complete data , the classical estimation is @xmath501 and the two new estimations are @xmath502 and @xmath503    as it was noticed in the examples above , the two methods lead to approximately the same estimation results",
    ". nevertheless , if the two estimations are significantly different , it seems related to the quality of the selected data .",
    "an important feature of this new approach is that the quality of estimations is uninfluenced by the truncation proportion",
    ". the following section will give further insights of the new approach .",
    "the preceding results have shown the effectiveness of the new approach and worked well in simulation experiments .",
    "furthermore , the proposition below will give an insight of a major feature of the new approach by considering the one parameter exponential family .",
    "we will prove that for all truncation considered formed by more than two points , from a sample of observations ; if the ratios of the relative frequencies of the @xmath314 are equal to the theoretical ones , then we may obtain the true value of the parameter .",
    "we may conjecture that when considering an arbitrary law of probability depending on @xmath504 parameters , such that we have a truncation composed by @xmath505 points having exact empirical ratios of the relative frequencies then we obtain the true values of the @xmath504 parameters .    consider a probability distribution @xmath40 from the one - parameter exponential family with density@xmath172 , \\label{expo - fam}\\ ] ] where @xmath506 is the parameter , @xmath124 a statistic , @xmath173 a function of @xmath24 and @xmath174 is a function of the parameter @xmath145 assume that we wish to estimate the parameter @xmath145",
    "if we consider a truncation having two points * * @xmath24 * *  * * and @xmath77 * *  * * with empirical frequencies * * @xmath507  and @xmath508 * *  * * satisfying * * @xmath509 , then , using the approach considered here , we obtain the true value of @xmath145    \\1 .",
    "if we consider the minimum of distance @xmath33 the result is immediate.2 .",
    "consider now the second method to estimate @xmath320 .",
    "consider two values @xmath24 and @xmath77 from the exponential family with density given by ( [ expo - fam])@xmath510 with @xmath5 being the estimation by the new approach , and assume that their empirical frequencies @xmath507  and @xmath508 are such that@xmath511 we obtain@xmath512 then , we solve on @xmath2 the following equation:@xmath513@xmath514 after straightforward algebra we obtain@xmath515 yielding the true value @xmath516 the proof is complete .",
    "note that the frequencies @xmath507 and @xmath508 need not be exact , that is @xmath507 may be different from @xmath34 and also @xmath517 but we require only that their ratio is equal to the theoretical one @xmath518    * examplesbinomial distribution .",
    "* consider again the binomial distribution @xmath181 with @xmath182 and @xmath223 and assume @xmath9 is known and we wish to estimate @xmath519 assume we have the following truncation with only two points @xmath520 the exact ratio of their probability distribution is given by @xmath521 which is a rational value that will simplify the example .",
    "choose the absolute frequencies of the two values considered as being @xmath522 and @xmath523 for the values @xmath524 and @xmath525 respectively , in order for having @xmath526 using the first approach , that of the minimum of distance @xmath154 we have to solve@xmath527   , \\ ] ] and we get the true value @xmath528 .    using the second method we have to solve the following equation on @xmath206@xmath529 and we obtain also the exact result @xmath530**gamma distribution .",
    "* * consider the gamma probability distribution @xmath385 with @xmath531 and @xmath532 assume that @xmath533 is known and we wish to estimate @xmath500 consider the truncation @xmath534 with @xmath535 and @xmath536 .",
    "we have the following value of the ratio @xmath537 ( the result is an approximate result since for probability density functions it is difficult to get an exact rational value but we will show that the estimations are very close to the true value ) .",
    "consider the absolute frequencies @xmath538 ( or @xmath539 ) and @xmath540 for the values @xmath535 and @xmath536 respectively .",
    "we have then @xmath541 using the minimum of distance @xmath154 we have to solve@xmath542@xmath543   , \\ ] ] and we get the result @xmath544    from the second method , we compute @xmath545 and solve on @xmath403 the following equation@xmath546@xmath547 the result is @xmath548    now assume that the parameters @xmath533 and @xmath403 are unknown and show how to jointly estimate them using the new approach .",
    "since now there are two unknown parameters , we need to have three points from the support , so consider @xmath549 , @xmath550 and @xmath551 with their corresponding absolute frequencies @xmath552 and @xmath553 we have to find @xmath533 and @xmath403 which minimize the distance @xmath33 that is @xmath554 the result is @xmath555 and @xmath556",
    "our aim here is not to give a detailed comparison study which needs to be investigated thoroughly , but only some elements of appreciation .",
    "a major feature which characterizes this new approach from the others is that when we have exact ratios of frequencies we obtain the true parameter and when their difference from the theoretical ratios decrease the quality of estimation increase even if we are using only a part from the sample of observations .",
    "this is not the case for classical approaches . in classical approaches ,",
    "quality considerations are only viewed through mean properties of estimators or their asymptotic behaviour . by combining the two proposed methods we have in fact a point criterion .",
    "another characteristics is that the proportion of truncation has any effect on the quality of estimations .",
    "the first method uses a well known method of minimum distance but with a new one which has an important advantage of being symmetric , the property of which many traditional distances do not have .",
    "however , the estimations are obtained in this case implicitly so it is difficult to find explicit expressions and study their properties to compare them with classical ones . using the new distance",
    "we hope having fast convergent estimators since we expect that the influence of the errors in the frequencies will be slight in the new approach as we are using ratios of frequencies .",
    "consider now the second method of the new approach .",
    "we use classical procedures of estimation such as the maximum likelihood principle using the auxiliary distribution .",
    "we may obtain the estimators and study their properties as commonly used and then preserves the advantages of classical methods .",
    "in classical approach , given a sample , the estimation of certain parameters such as the mean and variance do not change according to the family of parent distributions .",
    "the latter information is not used and this disadvantages the approach . however , in the new approach the estimations of the mean and variance change according to the distribution from which the data emanated .",
    "the following two examples show the effectiveness of using the auxiliary distribution.*example .",
    "* consider the following frequency table :    * table 7 . *",
    "[ c]cccc@xmath557 & @xmath187 & @xmath188 & @xmath558 + @xmath193 & @xmath559 & @xmath560 & @xmath9 + @xmath561 & @xmath562 & @xmath563 & @xmath186 +    any sample of observations that satisfies the preceding frequency table may belong from one of the following distributions:@xmath564{c}\\frac{x}{6}\\\\ 0 \\end{array}\\begin{array } [ c]{c}if\\text { } x\\in\\left\\ {   1,2,3\\right\\ }   , \\\\ otherwise , \\end{array } \\right .",
    "\\text { \\ \\ or \\ \\",
    "} g_{2}\\left (   x\\right )   = \\left\\ { \\begin{array } [ c]{c}\\frac{x-1}{6}\\\\ 0 \\end{array}\\begin{array } [ c]{c}if\\text { } x\\in\\left\\ {   2,3,4\\right\\ }   , \\\\ otherwise .",
    "\\end{array } \\right.\\ ] ] the decision for determining which of the two distributions is more appropriate for table 7 , depends intuitively on the values @xmath559 and @xmath560 ( or @xmath507 and @xmath508 ) .",
    "however , if we use the classical maximum likelihood , we obtain that the samples of observations were generated from distribution @xmath565 whatever the values of @xmath559 and @xmath566 that is:@xmath567 we will show by using the new approach that the decision is more relevant .",
    "determine first the auxiliary distributions , @xmath565 and @xmath568 , based on the truncation @xmath569 , for @xmath570 and @xmath571 respectively .",
    "we obtain@xmath572{c}2/5\\\\ 3/5\\\\ 0 \\end{array}\\begin{array } [ c]{c}\\text { \\ \\ } if\\text { \\ \\ } x=2,\\\\ \\text { \\ \\ } if\\text { \\ \\ } x=3,\\\\ otherwise , \\end{array } \\right .",
    "\\text { \\ \\ and \\ \\ } h_{2}(x)=\\left\\ { \\begin{array } [ c]{c}1/3\\\\ 2/3\\\\ 0 \\end{array}\\begin{array } [ c]{c}\\text { \\ \\ } if\\text { \\ \\ } x=2,\\\\ \\text { \\ \\ } if\\text { \\ \\ } x=3,\\\\ otherwise .",
    "\\end{array } \\right.\\ ] ] by using the maximum likelihood for @xmath565 and @xmath568 , we have to decide according to the quantities @xmath573 and @xmath574 solving the following inequality @xmath575 which is equivalent to @xmath576 where @xmath577 we obtain @xmath578 if @xmath579 the data were generated from @xmath571 and if @xmath580 , the data were generated from @xmath581 we can not make any decision about the case @xmath582**example . *",
    "* consider a binomial distribution with parameters @xmath583 and @xmath206 is unknown , from which we consider some samples of observations of size 15 given in table 8 by their absolute frequencies and chosen in order for having @xmath584    * table 8 . *",
    "[ c]|c|ccccc|cc| & & + samples & @xmath185 & @xmath186 & @xmath187 & @xmath188 & @xmath189 & @xmath585 & @xmath586 + @xmath186 & @xmath192 & @xmath254 & @xmath185 & @xmath185 & @xmath185 & @xmath587 & @xmath588 + @xmath187 & @xmath259 & @xmath190 & @xmath185 & @xmath186 & @xmath185 & @xmath587 & @xmath589 + @xmath188 & @xmath259 & @xmath189 & @xmath187 & @xmath185 & @xmath185 & @xmath587 & @xmath590 + @xmath189 & @xmath264 & @xmath188 & @xmath186 & @xmath186 & @xmath185 & @xmath587 & @xmath591 + @xmath190 & @xmath264 & @xmath189 & @xmath185 & @xmath185 & @xmath186 & @xmath587 & @xmath592 + @xmath191 & @xmath272 & @xmath185 & @xmath187 & @xmath185 & @xmath186 & @xmath587 & @xmath593 + @xmath192 & @xmath276 & @xmath185 & @xmath185 & @xmath185 & @xmath187 & @xmath587 & @xmath594 +    it is clear that the information given by the samples are not the same , nevertheless the classical estimation method gives us the same estimation @xmath595 if we use the second method of the new approach , we have to solve the following equation for each sample:@xmath596 where @xmath597 is the corresponding auxiliary distribution .",
    "the estimations given by the new method differ from sample to another as shown in the latest column of table 8 , which is natural since each sample provides a different information about the parent distribution .",
    "we can also use the minimum of distance @xmath33 and we get also the same conclusion .",
    "the fact that the distance @xmath33 is a metric allow to propose various applications of this new measure .",
    "we can use it for model selection amongst different probability families .",
    "we choose two or more possible candidate parametric families of distributions , and for each alternative family , estimate the parameters to select a specific candidate .",
    "determine the distance between the specific candidate and the empirical distribution using the new metric @xmath86 finally , select the family which yields the minimum distance .",
    "in view of the new approach this can also be done in case of truncated data as opposed to classical approaches ( see for example cox @xcite , @xcite ) , taylor and jakeman @xcite ) for model selection which can be used , from the best of our knowledge , only for complete data .    to investigate this perspective thoroughly , samples of various sizes from known distributions should be simulated , and the method for model selection applied , we can score the selection as correct or not after repeating the process a large number of times",
    ", the probability of correct selection could be estimated according to a given sample size .",
    "we can also use the new distance in cases where classical goodness of fit tests can not reject two candidate families .",
    "we can choose the one which yields the minimum of distance @xmath86    in the following examples , we shall select , in the first , between binomial distributions from truncated data . in the second example , we select between a weibull and a gamma distributions from right truncated data.*selection from binomial distributions .",
    "* we simulated @xmath598 samples of size @xmath599 from a binomial distribution @xmath600 and each time we retained only the observations belonging from @xmath601 with their frequencies .",
    "then we tried to identify the law simulated starting from the corresponding table of frequencies .",
    "we used the distance @xmath33 to select between the original distribution of each simulated sample and the distribution @xmath602 and we score the selection as correct if the distance between the empirical distribution and the original one is less than with the alternative one @xmath603 the correct distribution was selected @xmath604 .",
    "conversely , we simulated @xmath598 samples of size @xmath599 from a binomial distribution @xmath602 and we select with @xmath600 , the correct distribution was selected @xmath605**selection between weibull and gamma distributions . * * we simulated @xmath598 samples of size @xmath606 from the weibull distribution @xmath607 and we truncated them on right by considering only observations above the cut - off @xmath608 . each truncated sample was summarized into @xmath268 classes .",
    "we selected between @xmath607 and the gamma distribution @xmath609 the distance @xmath33 has selected the correct distribution , that is @xmath610 @xmath611    we can also find , before selecting between distribution , the best fit from the family of gamma distributions",
    "@xmath612 of the truncated data from a given probability density say @xmath613 we have then to solve an optimization problem of finding the minimum of a function of two variables , @xmath614 where @xmath3 is the empirical distribution and @xmath615 , using well known methods such as lavenberg - marquardt using a computer algebra package .",
    "also it should be better to choose the number of bins for each truncated sample by an optimal procedure , for example that of birg and rozenholc @xcite .",
    "the initial starting value is of great importance in convergence behaviour of algorithms such as _ em _ algorithm .",
    "usually , as for the latter , the initial trial value is guessed .",
    "surprisingly , we will show that our procedure gives an estimation of the starting value instead of having to guess .",
    "the approach will be illustrated by the following classical example which was the basis of the _ em _ algorithm.*example of hartley ( 1958 ) revisited . *",
    "hartley @xcite used an algorithmic procedure to estimate the parameter of a poisson distribution from data on the pollution of a sort of seeds by the presence of noxious weed seeds quoted from snedecor @xcite and truncated them by missing the frequencies of the values @xmath185 and @xmath186 as shown in the following table 9 ( table 1 in hartley @xcite )    * table 9 . *    [ c]cccccccccccvalues & missing & @xmath185 & @xmath186 & & & & & & & + & observed & & & @xmath187 & @xmath188 & @xmath189 & @xmath190 & @xmath191 & @xmath192 & @xmath259 + frequencies @xmath193 & & & & @xmath616 & @xmath290 & @xmath244 & @xmath259 & @xmath188 & @xmath190 & @xmath186 +    hartley @xcite has guessed the frequencies of the missing values @xmath185 and @xmath186 by taking @xmath617 and @xmath618 and after 4 steps of his algorithmic procedure , which has been the basis of the well known em algorithm for incomplete data ( dempster , laird and rubin @xcite ) , has reached the estimation @xmath619 ( see table 1 p.177 hartley @xcite ) .",
    "using the second method , we get the estimation @xmath620 and by proportional allocation procedure we can see that the frequencies we get are @xmath621 and @xmath622 which are close to the guessed values . using the distance",
    "@xmath33 we obtain the estimation @xmath623 and by removing the last value which has a small frequency @xmath624 we obtain a better result @xmath625 which are also appreciable as starting values since in practice the true parameter is unknown.*initial trial value for mixture normal populations .",
    "* we shall present an application of the previous method used for truncated data in the situation where we have a mixture population of two normal distributions . in classical methods , we use the merged distribution * * @xmath626 * * and we estimate the parameters @xmath627 @xmath628 and @xmath629 * * using for example the em algorithm which is based on maximizing the complete likelihood of the merged distribution by an algorithmic procedure from a guessed initial trial value .",
    "however , the problem of occurrence of several local maxima is well - known for the setting of em algorithm . also , seidel , mosler and alker @xcite pointed out that the likelihood - ratio test in mixture models depends on the choice of the initial trial value for the em algorithm .",
    "if the initial trial value is close to the true value it is clear that the algorithm will converge in few steps to the true local maximum .",
    "we will show that using the new approach we get an accurate estimated initial trial value .",
    "assume we have a merged sample from two samples of observations of sizes @xmath559 and @xmath560 from two normal distributions @xmath630 and @xmath631 , with @xmath632 . by assuming that @xmath633 and @xmath634 are known , our aim is to estimate the means @xmath628 and @xmath635 and also the merging proportion @xmath636 of each population .    we will use a method based on truncations . the main idea being to split the range of the merged sample into three suitably chosen parts",
    "a central part where the observations are highly merged , a left and right truncated parts where the observations become mainly from one of the distributions considered .",
    "if for example @xmath637 , then to estimate @xmath628 we have to use the chosen right truncated part ( left truncation @xmath117 ) .",
    "the procedure is summarized as follows :    * 1 .",
    "* we compute the sample mean @xmath638 of the merged observations .",
    "* 2 . * for determining the location of the two means @xmath628 and @xmath629 , we compute the empirical standard deviation @xmath639 of the observations less than @xmath640 and @xmath641 for those that are greater .",
    "assume that @xmath642 , in this case if @xmath643 then we deduce that @xmath628 is situated on the left of @xmath638 .",
    "otherwise , it will be assumed to be on its right .",
    "we follow the same idea for the case @xmath644 if @xmath645 we pass directly to the third step .",
    "assume that @xmath628 is on the left .",
    "it is well known that for a normal distribution @xmath646 we have @xmath647 m-\\sigma , m+\\sigma\\right [   ) $ ] @xmath648 we hope that on the left of @xmath649 the number of observations generated from @xmath650 is negligible , and on the right of @xmath651 the number of observations generated from @xmath652 is also negligible .",
    "hence , to estimate @xmath628 , we consider only the part of observations situated on the left of @xmath653 , and to estimate @xmath629 we consider the part situated on the right of @xmath654    the following example will provide some feel for the accuracy of the procedure.*example .",
    "* we consider the case where @xmath655 consider two samples of observations generated from @xmath652 and @xmath656 where @xmath657 and @xmath658 , with known @xmath659 and sizes @xmath660 and @xmath661 we combine them to obtain a merged sample of size @xmath662 we have chosen the distributions in such a way that the histogram ( fig.1 ) of the merged sample does not show directly the existence of a mixture of two distributions .  when  the histogram of the merged population is bimodal the situation is more easier , since when taking a suitably left ( or right ) part we get more accurate estimation from the situation that this part will have a negligible number of observations from the second distribution .",
    "figure1-conf.eps    fig 1 .",
    "merged histogram of two normal distributions @xmath663 and @xmath664    it should be stressed that the histogram is one modal and does not show at first glance any mixture situation . following the steps of the procedure",
    "we begin by calculating the mean of the resulting merged sample and we obtain @xmath665 . since the standard deviations are assumed to be equal then we compute directly @xmath666 by grouping the observations on the left of @xmath667 ( which constitute the chosen right truncated part ) in @xmath192 classes we obtain the following table :    * table 10 . *",
    "[ c]ccccccc@xmath314 & @xmath668 & @xmath669 & @xmath670 & @xmath671 & @xmath672 & @xmath673 + @xmath193 & @xmath186 & @xmath188 & @xmath191 & @xmath296 & @xmath674 & @xmath675 +    using the distance @xmath33 we obtain for all the truncation @xmath676 and by deleting @xmath677 we get the value @xmath678    the sample mean of the observations on the left of @xmath667 is given by @xmath679 using the second method we have to solve on @xmath320 the following formula@xmath680   + u_{2}\\times\\exp\\left [   \\frac{-\\left (   u_{2}-m\\right )   ^{2}}{2\\sigma^{2}}\\right ]   + ... + u_{k}\\times\\exp\\left [   \\frac{-\\left ( u_{k}-m\\right )   ^{2}}{2\\sigma^{2}}\\right ]   } { \\exp\\left [   \\frac{-\\left ( u_{1}-m\\right )   ^{2}}{2\\sigma^{2}}\\right ]   + \\exp\\left [   \\frac{-\\left ( u_{2}-m\\right )   ^{2}}{2\\sigma^{2}}\\right ]   + ... + \\exp\\left [   \\frac{-\\left ( u_{k}-m\\right )   ^{2}}{2\\sigma^{2}}\\right ]   } = \\overline{u}_{l}. \\label{m2}\\ ] ] we obtain the estimation @xmath681 by deleting the first value @xmath677 which has a weak frequency @xmath682 that is using the truncation @xmath683 ( we compute again @xmath684 ) we obtain a better estimation @xmath685 which is very close to the true value @xmath657 .    to estimate @xmath635 we consider the part situated on the right of @xmath686 grouping the observations on the right of @xmath687 ( which constitute the chosen right part ) in @xmath192 classes we obtain the following table :    * table 11 . *",
    "[ c]ccccccc@xmath314 & @xmath688 & @xmath689 & @xmath690 & @xmath691 & @xmath692 & @xmath693 + @xmath193 & @xmath694 & @xmath354 & @xmath194 & @xmath259 & @xmath192 & @xmath188 +    using the distance @xmath33 for all the truncation we get @xmath695 the sample mean of the observations on the right part is given by @xmath696 using formula ( [ m2 ] ) with @xmath697 , we obtain the result @xmath698 deleting the extreme values @xmath677 and @xmath699 we obtain @xmath700    the mixture proportion @xmath636 can easily be estimated using the formula @xmath701    considering the estimations obtained , which are close to the true values of @xmath628 and @xmath635 it is clear that the em algorithm will converge fastly to the unique solutions .",
    "we can obtain empirical quantile estimations of @xmath33 using montecarlo or bootstrapping technics , and use them in a test of goodness of fit for a specified probability distribution .",
    "we simulate @xmath702 samples of the same size from the specified probability distribution and calculate the distances @xmath703 we can then estimate the asymptotic distribution of @xmath33 by@xmath704 consequently , for a sample of the same size we compute @xmath705 and we reject the hypothesis that it belongs from the specified distribution if @xmath706 for a given level of significance @xmath707    the values @xmath708 may be obtained from the empirical distribution function @xmath709 of the sample .",
    "the fact that the new measure @xmath33 is not equivalent to classical ones means that it treats other aspects not investigated by the latter .",
    "this may open new perspectives such as making decision about the accuracy of an estimation in cases where the classical and new estimations are close to each others . in cases where the classical estimation and the new one using @xmath33 are significantly different",
    "then we can say that the sample of observations considered does not restore coherently all necessary information about the parent distribution from which it emanated .",
    "in the foregoing study , we have presented a new statistical point estimation method which found be useful in truncated and grouped and censored data situations .",
    "a new distance between probability distributions was introduced .",
    "it measures the difference between the variations of two given probability distributions .",
    "we introduced an auxiliary distribution based on a truncation , from a chosen family of probability distributions .",
    "this new distribution will have the same parameters to estimate as the parent one .",
    "we use then statistical methods to estimate the parameters of the random variable under study using the empirical and new auxiliary distribution in the region that captures the data , from which we determine the corresponding parent distribution .",
    "the later is the estimation by the new method . using the new distance introduced we also estimate by the minimum distance approach and use the resulting estimation as a control on the accuracy of estimation obtained by the former method .",
    "we have obtained a result which states that if we have to estimate the parameter of a probability distribution from the one parameter exponential family , then it suffices to have two points with exact ratio of frequencies , that is equal to the theoretical one expressed by the ratio of the value of the probability distribution on these two points , to obtain the true value of the parameter .",
    "we have conjectured that if we have in general @xmath504 parameters , then it suffices to have @xmath505 points with exact ratios of their frequencies to obtain the @xmath504 true parameters exactly .",
    "the later result need to be proved rigorously in a general setting for other distributions than the class considered .",
    "a large comparative study between the classical and new methods should also be investigated .",
    "we presented some perspectives of the new approach such as model selection from truncated data using the new distance , estimation of the first trial value in the celebrate _ em _ algorithm in the case of truncation and for mixture of two normal populations , a test of goodness of fit based on the new distance , decision making about the quality of estimations and data .",
    "klein , j. p. and zhang , m. j. ( 1996 ) .",
    "statistical challenges in comparing chemotherapy and bone marrow transplantation as a treatment for leukemia , _ lifetime data : models in reliability and survival analysis , n.p .",
    "jewel , 175 - 185 . _"
  ],
  "abstract_text": [
    "<S> we propose a new approach for estimating the parameters of a probability distribution . </S>",
    "<S> it consists on combining two new methods of estimation . </S>",
    "<S> the first is based on the definition of a new distance measuring the difference between variations of two distributions on a finite number of points from their support and on using this measure for estimation purposes by the method of minimum distance . for the second method , </S>",
    "<S> given an empirical discrete distribution , we build up an auxiliary discrete theoretical distribution having the same support of the first and depending on the same parameters of the parent distribution of the data from which the empirical distribution emanated . </S>",
    "<S> we estimate then the parameters from the empirical distribution by the usual statistical methods . in practice </S>",
    "<S> , we propose to compute the two estimations , the second based on maximum likelihood principle of known theoretical properties , and the first being as a control of the effectiveness of the obtained estimation , and for which we prove the convergence in probability , so we have also a criterion on the quality of the information contained in the observations . </S>",
    "<S> we apply the approach to truncated or grouped and censored data situations to give the flavour on the effectiveness of the approach . we give also some interesting perspectives of the approach including model selection from truncated data , estimation of the initial trial value in the celebrate _ em _ algorithm in the case of truncation and merged normal populations , a test of goodness of fit based on the new distance , quality of estimations and data .    </S>",
    "<S> key words and phrases : em algorithm , minimum distance , model selection from truncated data , point estimation , truncated data , grouped and censored data . </S>"
  ]
}