{
  "article_text": [
    "it is well known that bayesian model selection with improper within - model prior distributions is not well - defined , owing to the presence of an arbitrary multiplicative constant in each term of the marginal likelihood function . recently @xcite it has been shown how this problem can be overcome",
    "if one replaces negative log - likelihood ( the _ log score _ ) by another , homogeneous , proper scoring rule @xcite  since then the arbitrary constants do not enter into the formulae .",
    "that paper considered the case of continuous variables and , in particular , the hyvrinen scoring rule @xcite , and showed that this approach will generally lead to consistent selection of the correct model .",
    "the above approach can not be applied directly when the data are discrete , since then we need to use scoring rules specifically adapted to the discrete case , as characterised in @xcite . here",
    "we investigate , by example , such a discrete data problem .",
    "in particular we consider the problem of distinguishing between the poisson and the negative binomial distributions .",
    "simulations indicate that the method will again deliver consistent selection of the true model .",
    "let @xmath0 be a discrete sample space endowed with a structure whereby with each @xmath1 is associated a _ neighbourhood _",
    "@xmath2 , containing @xmath3 . in @xcite",
    "it was shown how to define a _ proper local scoring rule _",
    "@xmath4 on @xmath0 , where @xmath5 , and @xmath6 is a distribution over @xmath7 .",
    "the rule is _ proper _ if , for all @xmath6 , @xmath8 is minimised for @xmath9 , and _ local _ if @xmath4 depend on @xmath6 only through the probabilities it assigns to points in @xmath10 . under a condition on the neighbourhoods",
    ", we can define an undirected graph @xmath11 on @xmath0 such that we can take @xmath12 just when @xmath3 and @xmath13 are identical or are adjacent in @xmath11",
    ". then all proper local scorings can be characterised , and ( on excluding the log score , yielding what are termed _ key local _ proper scoring rules ) any of these will be _ homogeneous _ in the sense that its value is unchanged when all probabilities in @xmath10 are scaled by the same positive constant .    in particular , suppose the sample space @xmath7 is the set @xmath14 of non - negative integers , and we regard @xmath3 and @xmath13 as neighbours if and only if they differ by at most 1 .",
    "it is shown in @xcite that a key local scoring rule adapted to this structure has the form @xmath15 where , for each @xmath16 , @xmath17 , @xmath18 is a concave function on @xmath19 , and the first term in is absent if @xmath20 .",
    "it is clear from the way in which ratios enter that such a scoring rule is homogeneous .",
    "the cumulative score based on an independent and identically distributedsample @xmath21 in which the frequency of @xmath13 is @xmath22 @xmath23 is @xmath24 with @xmath25 .",
    "if for example we wished to fit the poisson model @xmath26 , we might estimate @xmath27 by minimising the total empirical score @xmath28    in the sequel we shall use the special case of with @xmath29 this gives the scoring rule @xmath30{lr }        m^{-1}\\left\\{{p(1)}/{p(0)}\\right\\}^m & ( x=0)\\\\                                             & \\quad\\\\        \\{m(m-1)\\}^{-1}\\left[(m-1)(x+1)^a\\left\\{{p(x+1)}/{p(x)}\\right\\}^m\\right.\\\\        { } \\quad\\quad\\quad\\quad\\quad\\quad\\quad\\left .",
    "- mx^a\\left\\{{p(x)}/{p(x-1)}\\}\\right)^{m-1}\\right ] & ( x > 0 ) .",
    "\\end{array }    \\right.\\ ] ]",
    "let @xmath31 be a finite or countable class of statistical models for the same observable @xmath32 .",
    "each @xmath33 is a parametric family , with parameter @xmath34 , a @xmath35-dimensional euclidean space ; when @xmath36 obtains , with parameter value @xmath37 , then @xmath38 has distribution @xmath39 , with density function ( probability mass function ) @xmath40 . having observed data @xmath41",
    ", we wish to make inference about which model @xmath33 ( and possibly which parameter - value @xmath37 ) actually generated the data .",
    "the bayesian approach assigns , within each model @xmath36 , a prior distribution @xmath42 , with density @xmath43 say , for its parameter @xmath37 . the associated _ predictive distribution _",
    "@xmath44 of @xmath38 ( given only the validity of model @xmath36 , but no information on its parameter ) has density function @xmath45 any function over @xmath31 proportional to @xmath46 ( considered as a function of @xmath36 , for fixed @xmath3 ) supplies the _ marginal likelihood _ function , @xmath47 , based on data @xmath48 . in typical asymptotic scenarios , selection of the model maximising @xmath47 , or , equivalently , minimising the _ log score _",
    "@xmath49 , will consistently select the true model @xcite .",
    "`` objective '' bayesian inference attempts to use standardised within - model priors @xmath42 intended to represent `` prior ignorance '' . in many applications ,",
    "such an `` ignorance prior '' for @xmath37 is not a genuine distribution , but rather an `` improper '' @xmath50-finite but not finite measure , with a `` density '' @xmath43 that does not have a finite integral and so can not be normalised to be a proper probability density .",
    "typically one writes @xmath51 , where @xmath52 is a given non - integrable function and the constant of proportionality is not specified . even without that specification ,",
    "this allows mechanical computation of a formal within - model-@xmath36 posterior density @xmath53 , by application of bayes s formula : @xmath54 .",
    "this will often yield an integrable function and hence the possibility of normalisation to supply a genuine probability density",
    ".    however things do not work out so well when we turn to model selection .",
    "we have , for each model @xmath36 , @xmath55 where @xmath56 is the unspecified proportionality constant .",
    "this formally leads to the marginal likelihood function @xmath57 but since this involves the unspecified constants @xmath56 , which could vary arbitrarily with @xmath36 , it is no longer meaningful to compare models by means of their marginal likelihoods .",
    "a way round this problem was proposed in @xcite : instead of attempting to minimise the log score @xmath49 , we replace that with another proper scoring rule @xmath58 . and",
    "if that scoring rule is homogeneous , it will simply not involve the unspecified constant @xmath56 . in @xcite a detailed analysis of this approach was conducted for the case of continuous data and the hyvrinen scoring rule , and it was shown that it will typically deliver consistent selection of the true model .",
    "we shall investigate empirically , for a simple example , the validity of the above results when generalised to the case of discrete data .",
    "we shall use the scoring rule , and apply this to the choice between a poisson and a negative binomial model . for this purpose",
    "we first need to compute , for each of these models separately , the appropriate score .",
    "consider the poisson model @xmath59 : @xmath60 with conjugate prior @xmath61 : @xmath62 for propriety we require @xmath63 , @xmath64 .    the predictive distribution @xmath6 has density function @xmath65 with @xmath66 .",
    "then @xmath67 , and so @xmath68      suppose now we have @xmath69 independent and identically distributed observations @xmath70 from the above poisson distribution .",
    "we can apply the above score in two different ways :    1 .",
    "apply direct to the sufficient statistic .",
    "2 .   apply prequentially to all observations .",
    "the sufficient statistic is @xmath71 , with distribution @xmath72 .",
    "so the score computed this way is simply obtained from and on replacing @xmath3 by @xmath73 and @xmath74 by @xmath75 .",
    "this gives @xmath76 where @xmath77 .",
    "now suppose we have already observed @xmath78 .",
    "the posterior distribution of @xmath79 is @xmath80 so the predictive distribution of @xmath81 , given the previous observations @xmath78 , is obtained from and on replacing @xmath3 with @xmath82 , @xmath83 with @xmath84 , and @xmath85 with @xmath86 .",
    "the incremental contribution to the prequential score is thus given by : @xmath87 with @xmath88 .",
    "the total prequential score is obtained by summing this from @xmath89 to @xmath69 .",
    "the usual improper prior is the formal limit with @xmath90 . in this case and become : @xmath91 note that the score is well - defined even when all observations are @xmath92 , in which case the posterior is improper .    for the prequential version , we obtain , from and : @xmath93 an alternative improper prior is the jeffreys prior , having @xmath94 , @xmath95 , which is easily handled similarly .",
    "now we consider an alternative model , the negative binomial @xmath96 , having @xmath97 with conjugate prior @xmath98 : @xmath99 for propriety we require @xmath100 , @xmath101 .",
    "the predictive density is @xmath102 then @xmath103 and so we have : @xmath104.\\end{aligned}\\ ] ]      again , we can handle multiple observations either by restricting to the sufficient statistic , or by cumulating the prequential score .",
    "the sufficient statistic is @xmath71 , with distribution @xmath105 .",
    "so the score computed this way is simply obtained from and on replacing @xmath3 by @xmath73 and @xmath106 by @xmath107 .",
    "this gives @xmath108.\\end{aligned}\\ ] ]      now suppose we have already observed @xmath78 .",
    "the posterior distribution of @xmath109 is @xmath110    so the predictive density of @xmath81 , given the previous observations @xmath78 , is obtained from and on replacing @xmath3 with @xmath82 , @xmath111 with @xmath112 , and @xmath113 with @xmath114 .",
    "the incremental contribution to the prequential score is thus given by :    @xmath115.\\end{aligned}\\ ] ]    the total prequential score is obtained by summing this from @xmath89 to @xmath69 .",
    "the usual improper prior is the formal limit with @xmath116 . in this case and become :    @xmath117    the score is well - defined even when all observations are @xmath92 , in which case the posterior is improper .    for the prequential version , we obtain , from and :    @xmath118.\\\\    \\label{eq : preqnegbinomform1}\\quad\\end{aligned}\\ ] ]",
    "the total prequential score is obtained by summing this from @xmath89 to @xmath69 .",
    "again , similar expressions can be found using the improper jeffreys prior , which has @xmath119 , @xmath120 .",
    "we generated observations from either the poisson distribution with @xmath121 , @xmath122 , or the negative binomial distribution with @xmath123 , @xmath124 .",
    "these both have variance @xmath125 , the former having mean @xmath125 , and the latter mean @xmath126 .",
    "we used , as the scoring rule , the special case of having @xmath127 , namely @xmath128    for each generating distribution we computed the excess of the cumulative prequential score for the wrong model over that for the correct model .",
    "these differences are shown , as a function of increasing data , in figures  [ fig : poissfig ] and [ fig : nbfig ] respectively .",
    "each figure displays 10 sample sequences generated from the indicated distribution , as well as the average taken over a sample areof 100 sequences .    in each case",
    "we see a clear linear upward trend , supporting the expectation of consistent model selection , although even with 1000 observations there is a non - negligible probability of a negative value , giving a misleading preference for the wrong model .    ]    ]",
    "we have extended the bayesian model selection methodology of @xcite to apply to problems with discrete data .",
    "we have conducted a simulation study to compare poisson and negative binomial distributions .",
    "the results suggest that the method will consistently select the correct model as the number of data points increases .",
    "philip dawid s research was supported through an emeritus fellowship from the leverhulme trust ."
  ],
  "abstract_text": [
    "<S> we consider the problem of choosing between parametric models for a discrete observable , taking a bayesian approach in which the within - model prior distributions are allowed to be improper . in order to avoid the ambiguity in the marginal likelihood function in such a case </S>",
    "<S> , we apply a homogeneous scoring rule . for the particular case of distinguishing between poisson and negative binomial models , we conduct simulations that indicate that , applied prequentially </S>",
    "<S> , the method will consistently select the true model . + </S>",
    "<S> * keywords : * consistent model selection ; homogeneous score ; discrete data ; prequential    = 1 </S>"
  ]
}