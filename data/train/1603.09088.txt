{
  "article_text": [
    "the most sensitive aspect of both bayesian and non - bayesian statistics certainly is the reliance on a probabilistic model since even bayesian non - parametrics relies on a highly concentrated modelling in a functional space . considering the issue of misspecification from within bayesian analysis is therefore a major undertaking that has been curiously overlooked in the past , to the point that it shows up in negative like a missing link in the field . assessing",
    "the goodness of fit of a given model or exploring the consequences of working with a misspecified model have been little studied so far and there certainly is no theoretical or methodological corpus that can be acknowledged as a reference .",
    "bayesian robustness definitely was a keyword in the 80 s @xcite but the field somewhat dwindled along the year , presumably overtaken [ as already pointed out by the authors ] by the mcmc tsunami that allowed for much more ambitious modelling and the incorporation of higher variability through hierarchical structures and priors @xcite , although this may constitute a wishful reinterpretation of the past .",
    "another possible reason is that the complex mathematics involved in the formal representation of the robustness desiderata quickly got intractable . in any case ,",
    "bayesian robustness was mostly concerned with reducing the impact of the prior modelling , i.e. , it was understood in terms of robustness against the prior rather than against the model .",
    "( a different approach is adopted in @xcite , who considers a second type of priors intended to assess the performances of the original priors , with limited applicability . )    in this paper , the authors aim at providing robust inference against possible misspecifications of the sampling model also , producing empirical and methodological perspectives on the issue .",
    "this attempt is most commendable and we hope it will induce others to enlarge and deepen the work in this direction . in particular , we think there is some degree of urgency in solving the conundrum of the major ",
    "big data \" challenge , namely the impossible derivation of a complete statistical model with high dimension or complex data structures ( which differs from the  tall data \" case where the sheer size of the data hinders standard algorithms , see , e.g. , @xcite ) .",
    "we like very much the idea that robustness should be targeted to a specific decision and thus firmly set within a decision - theoretic framework .",
    "the paper starts with a refreshingly modern review on robustness in this context and then advances two types of propositions towards evaluating robustness of bayesian procedures and possibly proposing a more robust procedure .",
    "however , we find the empirical assessment that results from the approach somewhat too tentative and too inconclusive to provide a guidance to practitioners .",
    "it indeed appears that expanding the framework beside binary decisions faces considerable difficulties .",
    "we thus suggest below that more ( involved ) non - parametric procedures should be developed towards this goal . in our opinion ,",
    "one of the most challenging foundations of the paper is the involvement of the action @xmath0 in the construction of the reference prior , which does not appear natural or acceptable to us , because the coherence of the bayesian perspective does not seem to transfer to this approach .",
    "first , we want to point out that , in the specific and important setting of discrete decision spaces , and in particular for binary decisions , the propositions of the authors make a lot of sense",
    ". we are thus genuinely curious as to how these ideas could extent to infinite and continuous decision spaces .",
    "while we are similarly strongly inclined towards a decision - theoretic approach to statistics and hence definitely sympathetic to the perspective adopted in the paper , we also think one should keep in mind the unfortunately ignored remark by herman rubin @xcite that model densities and loss functions are only utilised through the product prior x likelihood x loss in bayesian decision theory .",
    "hence , in this sense , prior and loss are indistinguishable beyond this product .",
    "this reference is meant to support the point that both sampling and prior densities _ and _ losses should be assessed via a robustness filter , rather than solely examining the prior x likelihoo x loss term under the robustness magnifying glass . there",
    "exist rationality arguments and the like about the choice of a loss function @xcite , but since most parameters are a by - product [ of possibly strong relevance ] of defining a model , rather than enjoying an existence of their own , it is difficult not to think of the loss function as being linked to the model ( mis-)specification . in particular , this is why we do not see how  changing the likelihood changes the interpretation of the prior \" ( p.6 ) is such a  thorny issue \" ( p.6 ) .",
    "the notion of loss robustness is only alluded to in the conclusion of the paper and we hope it can be considered much further in parallel with the current assessment of the model .",
    "obviously there is no free lunch and it is necessary to accept some of the hypotheses to be able to give meaningful conclusions .",
    "our point is that the approaches seem to make a lot of sense for decisions belonging to a finite space , but may be less so or at least not so obvious sense in continuous cases .",
    "the authors build and study semi - local measures of robustness , in the sense that the impact of the decision is evaluated on a neighbourhood of the posterior distribution . as nicely reviewed in their section 2",
    ", this idea is not new and kullback - leibler neighbourhoods had already been considered in a series of papers .",
    "the key justification in the present paper , for kullback - leibler neighbourhoods is in theorem 4.2 , where some notion of coherency is invoked .",
    "the authors build their approach from three principles .",
    "it is hard to disagree with these three principles laid out for d - open methods .",
    "however their approach based on the kullback - leibler neighbourhoods raises a few issues .",
    "the result produced in theorem 4.1 indicates that the least favourable prior involves the exponential of the loss : this is not surprising given earlier works by the authors like @xcite .",
    "what sounds rather confusing while being central to the theme of the paper is the fact that each possible action @xmath0 induces a different prior or rather distribution in the parameter space . to understand this peculiar incorporation of the decision @xmath0 in the least favourable model ( or in posterior distribution )",
    "means that the least favourable decision is twice _ a posteriori _ : it is indeed an update after both having observed the data and taken an action @xmath0 .",
    "this proposal makes complete sense when evaluating the action , but it gets difficult to understand its meaning when proposing a new action . in other words , it seems to run against the grain of bayesian principles .",
    "the persistence of the indexing in @xmath0 of the notions and notations throughout the paper thus remains quite puzzling to us .",
    "( similar puzzlement is attached with the impact of the monte carlo variability on the final decision , as discussed in section 4.3 . )    besides , the least favourable posteriors only enjoy an implicit expression since the lagrange multiplier @xmath1 are non explicit and it is difficult to understand how they behave with @xmath0 and @xmath2 .",
    "more puzzling even is the fact that if the posterior distribution is extremely concentrated , as would happen in the context of large data sets , the kullback - leibler neighbourhood , for a fixed radius @xmath2 , will be very small giving a ( probably ) fake impression of robustness . to illustrate this ,",
    "consider the case where the posterior distribution is close to @xmath3 with @xmath4 large ( in other words the posterior distribution verifies a bernstein - von mises theorem ) . to understand the impact on @xmath5 consider also the case where @xmath6",
    ". then @xmath7 with @xmath8 and @xmath9 and it is easy to see that when @xmath10 , @xmath11 while if @xmath12 , @xmath13 . in the latter case @xmath14 while in the former case , @xmath15 and the difference between @xmath16 and @xmath17 is of the same order as the risk under @xmath18 when @xmath19 and is of smaller order than the risk when @xmath20 . unless @xmath2 becomes quite large , the decision @xmath0 that minimises @xmath16 is approximately @xmath21 .",
    "this behaviour does suggest that the posterior leads to a robust inference , while it could well be that the model is strongly mis - specified .",
    "such a difficulty appears to be a consequence of using kullback - leibler neighbourhoods since @xmath22 neighbourhoods might have led to a different behaviour , although this is far from certain .",
    "this naturally drives us to question the relevance of the coherence requirement of theorem 4.2 . while the coherence requirement was quite natural in @xcite , towards building the likelihood , here it is unclear why the same result should be obtained directly or after having first observed a subset of observations @xmath23 and constructed a least favourable prior @xmath24 , prior to observing the rest of the observations .",
    "we feel that @xmath25 solely exists after observing @xmath26 and that it solely makes sense in this very context .",
    "we can not fathom an equivalent to this result in standard decision - theoretical point estimation .",
    "this is presumably due to the fact that , for a continuum of actions , there is not much appeal in considering a continuum of priors .",
    "it is however difficult to evaluate the relevance or importance of this coherence constraint . once again , generalising to a continuous action space seems delicate without further guidance .",
    "is the parameter @xmath27 itself or rather its estimate @xmath28 as in section 4.2 remains a puzzle to us as the notation @xmath27 in this section seems to be used with this double meaning , which makes the outcome questionable . ]",
    "the advantage of using the kullback - leibler divergence is that it is mathematically convenient up to a certain point , but it does not necessarily make sense from a statistical viewpoint : e.g. , is there a model likelihood _ and _ a prior associated with _ every single _ distribution contained within this neighbourhood ?",
    "presumably so , given that this only has to hold for a fixed value of the sample @xmath26 . and is the least favourable distribution a true posterior for all samples @xmath26 ?",
    "presumably not , unless one accepts  data - dependent priors \" .",
    "it may prove to be the most delicate aspect of the paper , namely that the calibration of the evaluation is highly dependent on how far from the reference value we allow the posteriors to drift and that we have no clear idea of the meaning of the resulting neighbourhood at the end of section 4.1 .",
    "it seems to us that one of the reasons it is so difficult to calibrate @xmath2 is that kullback - leibler neighbourhoods are rather abstract objects .",
    "thus one can not resort to intuition or subjective knowledge in the calibration process .",
    "the discussion by the authors in the conclusion of this paper broaches upon this very point . in some specific settings ,",
    "it should be possible to create neighbourhoods by looking at some quantity of interest and setting bounds or limits on the posterior values or variability for this quantity .",
    "an alternative would be to resort to an abc @xcite type of robustness where only posteriors that have the ability to predict the actual data ( or the original optimal decision ) are allowed within the corresponding neighbourhood . while this approach is only vaguely defined , and may be delicate to implement in practice",
    ", it carries a most natural kind of proximity .    as a side remark ,",
    "we appreciate the notion of evaluating the impact of single observations on the inference , as it creates a decision - based outlier and leverage assessment perspective , but we remain unsure as to what one can conclude about the appropriateness of the model from the divergence measure , the more because it looks terribly similar to an harmonic mean estimator @xcite !    in connection with this remark , and even before we reached the short section 4.2.3 , the introduction of @xmath29-admissible actions reminded us of @xmath30-minimax procedures mostly studied in the 1980 s and early 1990 s .",
    "this notion did not attract a large flock of followers at the time , because it is quite delicate to figure out whether or not a procedure is @xmath30-minimax .",
    "however , once we read section 4.2.3 , we got somewhat confused as we could not see how the action enters the choice of the minimax prior . nor",
    "why it should .- minimax problem by considering a collection of posterior rather than priors .",
    "while this makes complete sense from a conditioning perspective , it does not necessarily lead to coherent answers since the least favourable priors are then data dependent . ] clearly , @xmath29-admissibility as defined here is a much more convoluted notion that not only involves the range of acceptable priors but also a new least favourable prior and the optimal decision under the original prior , which somewhat constitutes the centre of the kullback - leibler ball .",
    "may be fraught with danger as the kullback proximity does not guarantee tail behaviour and hence finite variance .",
    "hence , using the importance weights to calibrate the kullback neighbourhood can not be suggested without further assessment . ]",
    "the various proposals of section 4.2 highlight the links between the proposed approach and other proposals for robust inference , but they also suggest that the calibration of @xmath2 can only be achieved on a case by case basis .",
    "the non - parametric approach via ( e.g. ) dirichlet priors is somewhat of an expected if welcomed thread . for one thing , it sounds more genuine for inferential purposes , when compared with the call to kullback - leibler neighbourhoods .",
    "this is particularly compelling when considering a candidate posterior as the functional parameter of the dirichlet ( hyper ) prior  although the denomination of  prior \" clashes with the fact that the dirichlet process is centred at the posterior @xmath18. looking at the variability or distribution of the loss under a dirichlet process centred at the posterior distribution constitutes quite an interesting and elegant proposal , but we wonder about the type of _ neighbourhoods _ of the posterior distributions thus induced .",
    "( we also appreciate the monte carlo convenience offered by the dirichlet process representation described in section 4.3.1 )    how do these `` neighbourhoods '' compare to the kullback - leibler neighbourhoods of the first part ?",
    "indeed bayesian non - parametrics suffer from the drawback that functional priors are almost irremediably concentrated on very small regions of the functional space and thus do not necessarily reflect much of a range of possible posteriors .",
    "obviously , in a nonparametric framework , the notion of neighbourhood is much more loose than in the parametric case .",
    "one can envision them as soft versus hard neighbourhoods by analogy to soft versus hard thresholding . while the authors state in section 4.3.2 that an action optimal under the functional parameter of the dirichlet prior will remain optimal ( in expectation ) under the random measure distributed from this dirichlet , this may constitute a second - tier property in that it only stands in expectation .",
    "we find the proposition of studying the probability of changing the optimal decision particularly relevant , in particular in the context of discrete and finite decision spaces .",
    "in fact , we are not quite sure of what happens or would happen in the context of continuous decisions .",
    "indeed , in this latter case , @xmath31 also follows a dirichlet process centred at the posterior distribution of @xmath31 .",
    "hence , if @xmath32 is the @xmath33-th quantile of @xmath31 under the posterior @xmath18 , then @xmath34 , which depends only on @xmath35 and on the mass of the dirichlet process @xmath36 . there is no dependence whatsoever on @xmath18 , which seems to imply it presents little interest .",
    "thus , we wonder which relevant quantities could be produced in continuous settings towards a better understanding of the variability of the loss function under deviations from the posterior .",
    "while the authors have already uncovered several interesting new avenues for exploring bayesian robustness , we want to point out yet another avenue associated with the notion of penalised complexity ( pc ) priors , as proposed by @xcite , in fact , we think penalised complexity is eminently relevant to the robustness issue as this perspective tackles the prior specification side covered in section 2.2 .",
    "the starting point for @xcite modelling is a base model , out of which possibly robust extensions can be constructed .",
    "while there is no automated derivation of the base model , it corresponds to the operational model mentioned in the current paper .",
    "@xcite further rely on a functional distance from the base and make the quite natural proposal of setting a prior on the distance from the base .",
    "although there is no decision - theoretic aspect to be found in this proposal , an extension in this direction is certainly feasible .    in conclusion",
    ", we commend the authors for this foray into bayesian robustess and for producing such a novel perspective . formalising this aspect of bayesian analysis is absolutely essential for methodological and practical purposes , even when not required by foundational arguments .",
    "we also recognise that the proposals made in the paper are mostly exploratory , rather than directive , primarily aiming at representing the variability of the bayesian output when some of its components are uncertain or misspecified . once again",
    ", this represents an important step in the rational and objective evaluation of bayesian procedures and we congratulate the authors for initiating such a path .",
    "some of the proposals made therein may require further investigation in terms of bayesian coherence , but they open a different perspective on how to envision bayesian decision making from a braoder viewpoint .",
    "the main bulk of those comments were written during the bayesian week workshop held at cirm , luminy , france , march 1 - 4 , 2016 , in a most supportive and serene working environment .",
    "we thank the organisers of this meeting for this great opportunity .",
    "we are also grateful to peter green for his remarkable patience and to the editorial team for helpful suggestions towards the final version of this discussion .",
    "chopin , n. and robert , c. ( 2007 ) .",
    "comments on ` estimating the integrated likelihood via posterior simulation using the harmonic mean identity ( with discussion ) ' . in _",
    "bayesian statistics 8 _ ( o.  u.  p. bernardo , j. m. et al .",
    "( eds ) , ed . ) .",
    "371416 .",
    "robert , c. and casella , g. ( 2010 ) .",
    "a history of markov chain monte carlo  subjective recollections from incomplete data . in _ handbook of markov chain monte carlo : methods and applications _ ( s.  brooks , a.  gelman , x.  meng and g.  jones , eds . ) .",
    "chapman and hall , new york . arxiv0808.2902 ."
  ],
  "abstract_text": [
    "<S> this note discusses watson and holmes ( 2016 ) and their proposals towards more robust bayesian decisions . while we acknowledge and commend the authors for setting new and all - encompassing principles of bayesian robustness , and we appreciate the strong anchoring of those within a decision - theoretic referential , we remain uncertain as to which extent such principles can be applied outside binary decisions . </S>",
    "<S> we also wonder at the ultimate relevance of kullback - leibler neighbourhoods to characterise robustness and favour extensions along non - parametric axes . </S>"
  ]
}