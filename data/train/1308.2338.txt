{
  "article_text": [
    "the compression of continuous - valued sources remains one of the most well - studied ( and practically valuable ) research directions in information theory .",
    "given the increased importance of voice , video and other multimedia , all of which are typically `` analog '' in nature , the value associated with low - complexity algorithms to compress continuous - valued data is likely to remain significant in the years to come .    for discrete - valued `` finite alphabet '' , both the associated coding theorem @xcite and practically - meaningful coding schemes",
    "are now well known .",
    "trellis based quantizers @xcite are the first to achieve the rate distortion tradeoff , but with encoding complexity scaling exponentially with the constraint length .",
    "later , matsunaga and yamamoto @xcite show that a low density parity check ( ldpc ) ensemble , under suitable conditions on ensemble structure , can achieve the rate distortion bound using an optimal decoder .",
    "further , @xcite shows that low density generator matrix ( ldgm ) codes , as the dual of ldpc codes , with suitably irregular degree distributions , empirically perform close to the shannon rate - distortion bound with message - passing algorithms .",
    "more recently , polar codes @xcite , are the first provably rate distortion limit achievable codes with low encoding and decoding complexity @xcite .    in the case of analog sources , although both practical coding schemes as well as theoretical analysis is very heavily studied , a very limited literature exists that connects theory with low - complexity codes in practice .",
    "the most relevant literature in this context is on lattice compression and its low - density constructions @xcite , although this literature is somewhat limited in scope and application .    in the domains of image compression and speech coding , laplacian and exponential distributions",
    "are widely adopted as natural models of correlation between pixels and amplitude of voice @xcite .",
    "exponential distribution is also fundamental in characterizing continuous - time markov processes @xcite .",
    "although the rate distortion functions for both have been known for decades , there is still a gap between theory and existing low - complexity coding schemes for them .",
    "some schemes have been proposed , primary for the medium to high distortion regime , such as markov chain monte carlo ( mcmc ) based approach @xcite .",
    "our general understanding of low - complexity coding schemes , particular for the low - distortion regime , remains limited .    in this paper , we present an expansion coding scheme for both exponential and laplacian sources , which not only performs well in the low distortion regime , but",
    "also can be implemented with low encoding and decoding complexity .",
    "previously , our work in @xcite considers the dual problem of expansion coding for the channel coding case , where exponential noise channels are converted to coding over a set of parallel ( and independent ) discrete channels .",
    "further , adopting capacity achieving codes to the resulting parallel channels , expansion coding is shown to achieve the channel capacity at high snr with low complexity .",
    "for source coding , we utilize a similar approach here .",
    "consider expanding exponential and laplace sources into binary sequences , and coding over the resulting set of parallel discrete sources . by carefully choosing the parameters for each of the parallel lossy compression problems ,",
    "we show that the achievable rates for original source approaches the rate distortion limit , in ratio , in the low distortion regime .",
    "the rest of paper is organized as follows .",
    "the next section describes the background of source coding problem . in section iii and vi , we present the main results of this paper , expansion coding technique for exponential and laplacian source , respectively",
    ". the paper concludes with a discussion section .",
    "consider an i.i.d .",
    "source @xmath0 .",
    "a @xmath1-rate distortion code consists of an encoding function @xmath2 , where @xmath3 , and a decoding function @xmath4 , which codes @xmath5 to an estimate @xmath6 .",
    "then , a rate and distortion pair @xmath7 is said to be achievable if there exists a sequence of @xmath1-rate distortion codes with @xmath8\\leq d$ ] .",
    "the rate distortion function @xmath9 is the infimum of such rates , and by shannon s theorem @xcite , we have : @xmath10\\leq d}i(x;\\hat{x}).\\label{fun : rate_distortion_theorem}\\ ] ]      the intuition underlying expansion coding originates from decomposability property of exponential random variables , where it can be expressed as summation of a set of independent discrete - valued random variables .",
    "the following lemma crystallizes this concept :    [ lem : exponential_expansion ] let @xmath11 s be independent bernoulli random variables , and their distribution is given by parameters @xmath12 .",
    "then , the random variable @xmath13 is exponentially distributed with mean @xmath14 , if and only if the choice of @xmath15 is given by @xmath16    proof is given in @xcite and @xcite , and follows from the memoryless property of exponential distribution . for completeness , we provide the proof in appendix  [ sec : appa ] .",
    "a set of typical numerical values of @xmath17s by fixing @xmath18 is shown in fig .",
    "[ fig : exp_prob ] .",
    "it is evident that @xmath17 approaches @xmath19 for the  higher \" levels and approaches @xmath20 for what we refer to as  lower \" levels .",
    "hence , the primary non - trivial levels within which coding is meaningful are the so - called  middle \" ones , which provides the basis for truncating the number of levels to a finite value without a significant loss in performance .     for different levels with @xmath18 .",
    "consider an i.i.d .",
    "exponential source @xmath0 , i.e. omitting index @xmath21 , the probability density function is given by @xmath22 where @xmath23 is the parameter of exponential distribution , i.e. @xmath24=1/\\lambda$ ] .",
    "distortion measure of concern is one - sided error distortion , i.e. @xmath25    this setup is equivalent to @xcite , where another distortion measure is considered .",
    "[ lem : exp_rate_distortion ] the rate distortion function for exponential source with one - sided error distortion is given by @xmath26 moreover , the optimal conditional distribution to achieve the limit is given by @xmath27    proof is given in @xcite , and it is based on the observation that among the ensemble of all probability density functions with positive support set and mean constraint , exponential distribution maximizes the differential entropy . by designing a test channel from @xmath28 to @xmath29 , with additive noise distributed as exponential with parameter @xmath30 , both",
    "the infimum mutual information and optimal conditional distribution can be characterized .",
    "details can be found in appendix  [ sec : appb ] .",
    "using lemma [ lem : exponential_expansion ] , we can reconstruct exponential distribution with parameter @xmath23 by a set of discrete bernoulli random variables .",
    "in particular , the expansion of exponential source over levels ranging from @xmath31 to @xmath32 can be expressed as @xmath33 where @xmath34 are bernoulli random variables with parameter @xmath35 the expansion will perfectly approximate exponential source by letting @xmath36 . consider a similar expansion of the source estimate , i.e. @xmath37 where @xmath38 is resulting bernoulli random variable with parameter @xmath39 .    using the concept of expansion , the original problem of coding for a continuous source",
    "can be translated to a problem of coding for a set of independent binary sources . in other words ,",
    "the original optimization problem over all possible continuous densities has been converted to another one with finite parameters .",
    "this transformation , although seemingly obvious , is valuable as we already have powerful coding schemes over discrete sources achieving rate distortion limits with low complexity . in particular , we design two schemes for the binary source coding problem at each level .",
    "we formulate each level as the binary source coding problem under the following one - sided distortion constraint : @xmath40    denoting the distortion at level @xmath41 as @xmath42 , an asymmetric test channel ( z - channel ) from @xmath43 to @xmath44 can be constructed , where @xmath45 then , it is straightforward to get @xmath46 , and the achievable rate is given by @xmath47    due to the decomposability property as stated previously , the coding scheme provided will be over a set of parallel discrete levels indexed by @xmath48 correspondingly .",
    "thus , by adopting rate distortion limit achieving codes over each level , our expansion coding scheme readily achieves the following result :    [ thm : exp_rate_1 ] for an exponential source , expansion coding achieves the rate distortion pair given by @xmath49 for any @xmath50 , and @xmath51 $ ] for @xmath52 , where @xmath53 is given by .",
    "see appendix  [ sec : appc ] .",
    "note that , the last two terms in are distortion resulting from the truncation ( of the levels ) and vanish in the limit of large number of levels .",
    "in later parts of this section , we characterize the number of levels required in order to bound the resulting distortion within a constant gap .      in the scheme above",
    ", we formulate each level as a z - channel such that @xmath54 .",
    "however , it is not necessary to have this relationship to guarantee @xmath55 . to this end",
    ", we introduce successive coding scheme , where encoding and decoding start from the highest level @xmath32 to the lowest . at a certain level @xmath41 ,",
    "if all higher levels are decoded as @xmath56 for @xmath57 , then we must model level @xmath41 as binary source coding with a one - sided distortion ( test channel is z - channel ) .",
    "otherwise , we formulate this level as binary source coding with symmetric distortion ( test channel is binary symmetric channel ) .",
    "in particular for the later case , the distortion is hamming distortion , i.e. @xmath58    denoting the equivalent distortion at level @xmath41 as @xmath42 , i.e. @xmath59=d_l$ ] , then the symmetric test channel from @xmath60 to @xmath61 could be formulated as @xmath62 hence , the achievable rate at level @xmath41 is given by @xmath63    based on these observations , we have the following achievable result :    [ thm : exp_rate_2 ] for exponential source , applying successive coding , expansion coding achieves the rate distortion pair given by @xmath64,\\label{eqn : r2}\\\\ d^{(2)}&=\\sum_{l =- l_1}^{l_2}2^ld_l+o ( 2^{-l_2}/\\lambda)+o(2^{-l_1}),\\label{eqn : d2}\\end{aligned}\\ ] ] for any @xmath50 , and @xmath51 $ ] for @xmath52 .",
    "here , @xmath53 is given by , and @xmath65 denotes the probability that all higher levels are encoded as equivalent and its value is given by @xmath66    see appendix  [ sec : appd ] .    in this sense ,",
    "the achievable pairs in theorem  [ thm : exp_rate_1 ] and [ thm : exp_rate_2 ] are both given by optimization problems over a set of parameters @xmath67 .",
    "however , the problems are not convex , and effective theoretical analysis or numerical calculation can not be adopted here for an optimal solution .",
    "but , by a heuristic choice of @xmath42 , we can still get a good performance",
    ". inspired from the fact that the optimal scheme models noise as exponential with parameter @xmath30 in test channel , we design @xmath68    we note that higher levels get higher priority and lower distortion with this choice , which is consistent with the intuition .",
    "then , the proposed expansion coding scheme provably approaches the rate distortion function for the whole distortion within a small constant gap .",
    "[ thm : exp_bound ] for any @xmath69 $ ] , there exists a constant @xmath70 , such that for @xmath71 , the achievable rate pairs obtained from expansion coding schemes are both within @xmath72 bit gap to shannon rate distortion function , i.e. @xmath73 @xmath74 where @xmath75 and @xmath76 are given by and respectively , with a choice of @xmath42 as in",
    ".    see appendix  [ sec : appe ] .",
    "numerical results showing achievable rates along with the rate distortion limit are plotted in fig .",
    "[ fig : exp_rate ] .",
    "it is evident that both forms of expansion coding perform within a constant gap of the limit .",
    "theorem  [ thm : exp_bound ] showcases that this gap is bounded by a constant . here ,",
    "numerical results show that the gap is not necessarily as wide as predicted by the analysis .",
    "specially in the low distortion region , the gap is numerically found to correspond to 0.24 bit and 0.43 bit for each coding scheme respectively .    .",
    "@xmath9 ( red - solid ) is rate distortion limit ; @xmath77 ( purple - dotted ) is the achievable rate given by theorem  [ thm : exp_rate_1 ] ; @xmath78 ( blue - dashed ) is the achievable rate given by theorem  [ thm : exp_rate_2 ] . ]",
    "in this section , we focus on laplacian source coding . consider another i.i.d .",
    "exponential source @xmath79 , i.e. omitting index @xmath21 , the probability density function is given by @xmath80 where @xmath23 is the parameter of laplace distribution , i.e. @xmath81=1/\\lambda$ ] .",
    "distortion measure here is absolute value error distortion , i.e. @xmath82    [ lem : laplace_rate_distortion ] the rate distortion function for laplacian source with parameter @xmath23 with absolute error distortion is given by @xmath26 moreover , the optimal conditional distribution is @xmath83    the proof is given by @xcite , where the noise in test channel is given by laplacian with parameter @xmath30 .",
    "see also appendix  [ sec : appf ] .      by noting that laplacian is two - sided exponential , the expansion of source and estimate over levels ranging from @xmath31 to @xmath32 can be expressed as @xmath84 where @xmath85 and @xmath86 represent the sign of @xmath87 and @xmath88 correspondingly , both random variables uniformly distributed from @xmath89 .    in a manner similar to exponential source coding case",
    ", expansion reduces the original problem to coding for a set of independent binary sources .",
    "however , particularly for laplacian case , we let @xmath90 , i.e. using 1 bit to perfectly recover the sign bit , and then for other levels , we formulate each as a binary source coding with hamming distortion .",
    "in particular , for level @xmath41 , we design a symmetric test channel from @xmath60 to @xmath61 , where the cross probability is given by @xmath91 then , the achievable rate at level @xmath41 is given by @xmath92 we have the following result .",
    "[ thm : laplace_rate ] for laplacian source @xmath29 , expansion coding , where the estimate @xmath28 is constructed as in , achieves the rate distortion pair @xmath7 with @xmath93,\\label{fun : laplace_achievable_rate}\\ ] ] for any @xmath50 and @xmath42 such that @xmath94\\leq d$ ] .",
    "the absolute value error distortion @xmath94 $ ] can not be written as simple weighted sum of hamming distortions from each level .",
    "in fact , we have to use an induction method to characterize the complicated relation .",
    "denote @xmath95,\\label{fun : d_k}\\end{aligned}\\ ] ] for any @xmath96 , which represents the accumulative absolute value distortion up to level @xmath97 .",
    "* initialization : at level @xmath31 , @xmath98 * induction : for levels @xmath99 , + @xmath100    to this end , the expansion based coding scheme can be clearly expressed as an optimization problem with variables @xmath67 , but not convex .",
    "we have to step back to heuristically choose the value of @xmath42s in order to get a suboptimal result .",
    "more precisely , for an aiming distortion @xmath101 , we construct a set of distortions @xmath42 at each level , @xmath102 then by theorem [ thm : laplace_rate ] and iterative algorithm to calculate the real distortion @xmath103 , we are ready to claim that the rate distortion pair @xmath104 is achievable , where @xmath105,\\\\ d^{(1)}&=\\mathcal{d}_{l_2}.\\end{aligned}\\ ] ]    evidently , this coding scheme may not behave well at high distortion region , since @xmath77 is at least 1 . in the high - distortion regime , precisely compressing the sign bit seems inefficient . to this end",
    ", a time sharing scheme is utilized to reduce the gap in high distortion region .",
    "more precisely , for any @xmath106 $ ] , we compress @xmath107 fraction of source sequences into codeword 0 , then the following rate distortion pair is found to be achievable : @xmath108    the following theorem provides an upper bound on rate distortion gap of expansion coding scheme .",
    "[ thm : laplace_bound ] for any @xmath69 $ ] , with a choice of @xmath42 in and @xmath109 , the achievable rate distortion pairs @xmath104 and @xmath110 obtained from expansion schemes above are within @xmath111 bit gap to shannon rate distortion function , i.e. @xmath112    see appendix  [ sec : appg ] .",
    "we find that the expansion coding scheme is provably within 1 bit constant gap of the rate distortion function . here",
    ", the calculation of @xmath77 is fairly tight , however , the upper bound on @xmath75 could prove to be loose , especially in low distortion region .",
    "since the calculation of @xmath75 from @xmath42s is non - trivial , it is hard to characterize the extent to which the overall distortion is overestimated by the bound .",
    "thus , we turn to numerical results to find this gap to be 0.52 bits in the low distortion regime ( shown in fig .",
    "[ fig : rate ] ) .    .",
    "@xmath9 ( red - solid ) is rate distortion limit ; @xmath77 ( purple - dotted ) is achievable rate using expansion coding : and @xmath78 ( blue - dashed ) is achievable rate using expansion coding and time sharing . ]",
    "expansion coding enables construction of  good \" lossy compression codes for exponential and laplacian sources using discrete - valued parallel source codes . theoretical analysis and numerical results",
    "illustrate that expansion coding performs within a constant gap of the rate distortion limit , and therefore , approaches the rate distortion limit in ratio , in the low distortion regime .",
    "one significant benefit from expansion coding is coding complexity . as indicated in theoretical analysis , approximately @xmath113 number of levels are sufficient for the coding scheme as presented and studied in the paper .",
    "thus , by choosing ",
    "good \" low complexity codes within each level ( such as source coding with polar codes @xcite , @xcite ) , the overall complexity of the coding scheme can be easily characterized , resulting in a low - complexity net code for the original continuous - valued source coding problem .",
    "although the paper focuses primarily on binary expansion case , our results can be generalized to @xmath114-array expansion case , with similar performance guarantees .",
    "moreover , we focus on exponential and laplacian sources due to their decomposable property .",
    "as we can imagine , all decomposable distributions can be treated in a similar way to result in parallel problems . even for indecomposable distributions , such as a gaussian",
    ", the expansion coding scheme presents a means of developing low - complexity coding schemes for these types of sources .    1 [ 1]#1 url@samestyle [ 2]#2 [ 2]l@#1=l@#1#2 t. m. cover and j. a. thomas , _ elements of information theory_. 1em plus 0.5em minus 0.4emnew york : wiley , 1991 .",
    "a. j. viterbi and j. k. omura , `` trellis encoding of memoryless disctretime sources with a fidelity criterion , '' _ ieee trans . on inf .",
    "20 , no .  3 , pp .",
    "325332 , 1974 .",
    "y. matsunaga and h. yamamoto , `` a coding theorem for lossy data compression by ldpc codes , '' _ ieee trans . on inf .",
    "theory _ , vol .",
    "49 , no .  9 , pp . 22252229 , 2003 .",
    "m. j. wainwright , e. maneva , and e. martinian , `` lossy source compression using low - density generator matrix codes : analysis and algorithms , '' _ ieee trans . on inf .",
    "56 , no .  3 , pp .",
    "13511368 , 2010 .",
    "e.  arikan , `` channel polarization : a method for constructing capacity - achieving codes for symmetric binary - input memoryless channels , '' _ ieee trans . on inf .",
    "theory _ , vol .",
    "55 , no .  7 , pp . 30513073 , jul .",
    "s.  b.  korada and r.  l.  urbanke , `` polar codes are optimal for lossy source coding , '' _ ieee trans . on inf .",
    "56 , no .  4 , pp . 17511768 , apr . 2010 .",
    "r.  zamir , `` lattices are everywhere . '' _ proc .",
    "2009 ieee information theory and applications workshop _ , san diego , california , feb .",
    "r.  g. gallager , _ information theory and reliable communication_.1em plus 0.5em minus 0.4emjohn wiley & sons , inc . , 1968 .",
    "s.  verd , `` the exponential distribution in information theory , '' _ problems of information transmission _ , vol .",
    "32 , no .  1 ,",
    "8695 , jan .- mar .",
    "d.  baron , and t.   weissman , `` an mcmc approach to universal lossy compression of analog sources , '' _ ieee trans . on signal processing _ ,",
    "60 , no .",
    "10 , pp . 52305240 , 2012 .",
    "o.  o.  koyluoglu , k.  appaiah , h.  si , and s.  vishwanath , `` expansion coding : achieving the capacity of an aen channel , '' in _ proc .",
    "2012 ieee international symposium on information theory ( isit 2012 ) _ , boston , massachusetts , u.s.a .",
    "g.  marsaglia , `` random variables with independent binary digits , '' _ ann . math .",
    "_ , vol .  42 , no .  6 , pp . 19221929 , 1971 .",
    "w.  h.  r.  equitz , and t.  m.  cover , `` successive reinformence of information , '' _ ieee trans . on inf .",
    "37 , no .  2 ,",
    "269274 , mar .",
    "the `` if '' part follows by extending the one given in @xcite , which considers the expansion of a truncated exponential random variable . we show the result by calculating the moment generating function of @xmath115 . using the assumption that @xmath116 are mutually independent , we have @xmath117          = \\prod_{l=-\\infty}^{\\infty}{\\mbox{\\bb e}}\\left[e^{t2^l b_l}\\right].\\nonumber\\end{aligned}\\ ] ] note that for any @xmath118 , @xmath119= \\frac{e^{t2^l}}{1+e^{\\lambda 2^l}}+\\left(1-\\frac{1}{1+e^{\\lambda 2^l}}\\right ) = \\frac{1+e^{(t-\\lambda ) 2^l}}{1+e^{-\\lambda 2^l}}.\\nonumber\\end{aligned}\\ ] ] then , using the fact that for any constant @xmath120 , @xmath121 we can obtain the following for @xmath122 , @xmath123 = \\lim_{n\\rightarrow\\infty}\\prod_{l=0}^{n}\\frac{1+e^{(t-\\lambda ) 2^l}}{1+e^{-\\lambda 2^l } }",
    "= \\frac{1-e^{-\\lambda}}{1-e^{t-\\lambda}}.\\label{eqn : part1}\\end{aligned}\\ ] ] and , similarly , for the negative part , we have @xmath124 which further implies that @xmath125 = & \\lim_{n\\rightarrow\\infty}\\frac{1-e^{t-\\lambda}}{1-e^{(t-\\lambda)2^{-n}}}\\frac{1-e^{-\\lambda2^{-n}}}{1-e^{-\\lambda}}\\nonumber\\\\ = & \\frac{\\lambda(1-e^{t-\\lambda})}{(\\lambda - t)(1-e^{-\\lambda})}. \\label{eqn : part2}\\end{aligned}\\ ] ]    thus , finally for any @xmath122 , combining equations  ( [ eqn : part1 ] ) and  ( [ eqn : part2 ] ) , we get @xmath126 the observation that this is the moment generation function for an exponentially distributed random variable with parameter @xmath23 concludes the proof .    the independence relationships between levels in `` only if '' part can be simply verified using memoryless property of exponential distribution . here",
    "we just need to show the parameter for bernoulli random variable at each level .",
    "observe that for any @xmath118 , @xmath127 using cdf of exponential distribution , we obtain @xmath128 putting this back to ( [ fun : exp ] ) we have @xmath129",
    "note that maximum entropy theorem tells us the distribution maximizing differential entropy over all probability densities @xmath130 on support set @xmath131 satisfying @xmath132 @xmath133 is exponential distribution with parameter @xmath23 .",
    "based on this result , by noting @xmath134\\leq d$ ] ie equivalent to say @xmath55 and @xmath135\\leq d$ ] , we have @xmath136)\\nonumber\\\\              & \\geq \\log(\\frac{e}{\\lambda})-\\log(ed)\\nonumber\\\\              & = -\\log ( \\lambda d).\\nonumber\\end{aligned}\\ ] ] obviously , we need @xmath137 to be exponentially distributed and independent with @xmath28 as well . more specifically , we can design a test channel from @xmath28 to @xmath29 with additive noise @xmath138 distributed as exponential with parameter @xmath30 , which gives ( [ fun : exp_optimal_conditional ] ) .",
    "due to decomposability of exponential distribution , the levels after expansion are independent , hence , the achievable rate in this theorem is straightforward to get . on the other hand , for the calculation of distortion , we have @xmath139\\nonumber\\\\      & = \\sum_{l =- l_1}^{l_2}2^ld_l + \\sum_{l = l_2 + 1}^{\\infty } 2^lp_l+\\sum_{l=-\\infty}^{-l_1 - 1}2^lp_l\\nonumber\\\\      & \\leq \\sum_{l =- l_1}^{l_2}2^ld_l + \\sum_{l = l_2 + 1}^{\\infty } 2^{-l}/\\lambda + \\sum_{l=-\\infty}^{-l_1 - 1}2^l\\nonumber\\\\      & \\leq \\sum_{l",
    "=- l_1}^{l_2}2^ld_l + 2^{-l_2}/\\lambda+2^{-l_1},\\nonumber\\end{aligned}\\ ] ] which gives the result of the theorem .",
    "by the design of coding scheme , if all higher levels are decoded as equivalence , then they must be encoded with one - sided distortion .",
    "recall that for @xmath140-channel , we have @xmath141 hence , due to independence of expanded levels , @xmath142 then , at each level , the achievable rate is @xmath143 with probability @xmath65 and is @xmath144 otherwise .",
    "thus , we have the expression of @xmath145 given by the theorem .",
    "without loss of generality , we assume @xmath18 for simplicity in the proof . the proof of the theorem is based on an asymptotic result from @xcite , which is restated without proof as follow .",
    "@xmath146 by noting that @xmath42 is also the parameter of expanded exponential distribution at level @xmath41 , but with a different mean , we have @xmath147 where @xmath148 .",
    "this result shows values of @xmath149 are right - shifted version of @xmath150 by @xmath151 positions . using this fact , together with equation ( [ fun : exponential_lemma_1 ] ) and ( [ fun : exponential_lemma_2 ] ) , we have @xmath152 = & \\sum_{l =- l_1}^{l_2}h(p_l)-\\sum_{l =- l_1+\\gamma}^{l_2+\\gamma}h(p_l)\\nonumber\\\\ = & \\sum_{l =- l_1}^{-l_1+\\gamma-1}h(p_l)-\\sum_{l = l_2 + 1}^{l_2+\\gamma}h(p_l)\\nonumber\\\\   \\leq & \\gamma.\\label{fun : proof_part1}\\end{aligned}\\ ] ] moreover , note that @xmath153 we want to bound this for two cases :    * for @xmath154 , by using the fact that function @xmath155 is convex and increasing on @xmath156 , we have @xmath157.\\label{proof : exp_part1}\\end{aligned}\\ ] ] then , by noting that @xmath158 for any @xmath159 , we get @xmath160 putting equation ( [ proof : exp_part1 ] ) and ( [ proof : exp_part2 ] ) back to ( [ proof : exp_first_result ] ) , we have @xmath161\\nonumber\\\\ \\leq & 2\\log e(p_l - d_l).\\nonumber\\end{aligned}\\ ] ] further by noting that for @xmath162 , @xmath163 and combining with the fact that @xmath164 , we have @xmath165 * on the other hand , for @xmath166 , similarly we have @xmath167,\\label{proof : exp_part3}\\end{aligned}\\ ] ] and @xmath168 putting equation ( [ proof : exp_part3 ] ) and ( [ proof : exp_part4 ] ) back to ( [ proof : exp_first_result ] ) , we have @xmath169\\nonumber\\\\ \\leq & 2\\log e\\cdot d_l.\\nonumber\\end{aligned}\\ ] ] note that for @xmath166 , @xmath170 then , @xmath171    collecting all the pieces together , we have @xmath172\\nonumber\\\\      & \\overset{\\text{(a)}}{\\leq } \\gamma + \\sum_{l =-",
    "l_1}^{l_2 } \\left [ h(d_l)-(1-p_l+d_l)h\\left(\\frac{d_l}{1-p_l+d_l}\\right)\\right]\\nonumber\\\\      & \\overset{\\text{(b)}}{\\leq } r(d)+\\sum_{l =- l_1}^{-\\gamma } 2^{l+\\gamma-1}+\\sum_{l=-\\gamma+1}^{l_2}2^{-l-\\gamma}\\nonumber\\\\      & \\leq r(d)+4\\log e,\\label{fun : proof_part3}\\end{aligned}\\ ] ] where inequality ( a ) comes from , and ( b ) comes from and . finally , by noting the fact from theorem  [ thm : exp_rate_1 ] that @xmath173 and that rate distortion function is convex and decreasing , we have @xmath174 relating this to , we have @xmath175 which completes the proof for @xmath77 and @xmath75 by choosing @xmath176 .",
    "for the other part of the theorem , @xmath78 and @xmath76 , observe that @xmath177 hence , for any @xmath178 , we have @xmath179 thus , by noting @xmath78 is a convex combination of @xmath144 and @xmath143 at each level , we have @xmath180 . combing with the observation that @xmath181 , we have @xmath182 .",
    "maximum entropy theorem tells us laplace distribution with parameter @xmath23 has the maximum differential entropy @xmath183 over all probability densities @xmath130 on support set @xmath184 satisfying @xmath185 @xmath186 based on this result , it is evident to note that @xmath187 where we have used the fact that @xmath94\\leq d$ ] .",
    "obviously , we need @xmath137 to be laplace distributed and independent with @xmath28 as well .",
    "more specifically , we can design a test channel from @xmath28 to @xmath29 with additive noise @xmath138 distributed as laplace with parameter @xmath30 , as shown in ( [ fun : lap_optimal_conditional ] ) .",
    "we assume @xmath18 without loss of generality . from the proof of theorem  [ thm : exp_bound ] , we have already seen : @xmath188\\leq \\gamma,\\ ] ] where @xmath189 .",
    "moreover , note that @xmath190\\leq d.\\nonumber\\end{aligned}\\ ] ] combining the pieces together , it is evident to see @xmath191+\\log d^{(1)}\\leq 1.\\nonumber\\end{aligned}\\ ] ] on the other hand , @xmath110 is obtained by convex combination of @xmath104 and @xmath192 , thus , we also have @xmath193 ."
  ],
  "abstract_text": [
    "<S> a general method of source coding over expansion is proposed in this paper , which enables one to reduce the problem of compressing an analog ( continuous - valued source ) to a set of much simpler problems , compressing discrete sources . </S>",
    "<S> specifically , the focus is on lossy compression of exponential and laplacian sources , which is subsequently expanded using a finite alphabet prior to being quantized . due to decomposability property of such sources , the resulting random variables post expansion are independent and discrete . </S>",
    "<S> thus , each of the expanded levels corresponds to an independent discrete source coding problem , and the original problem is reduced to coding over these parallel sources with a total distortion constraint . </S>",
    "<S> any feasible solution to the optimization problem is an achievable rate distortion pair of the original continuous - valued source compression problem . </S>",
    "<S> although finding the solution to this optimization problem at every distortion is hard , we show that our expansion coding scheme presents a good solution in the low distrotion regime . </S>",
    "<S> further , by adopting low - complexity codes designed for discrete source coding , the total coding complexity can be tractable in practice . </S>"
  ]
}