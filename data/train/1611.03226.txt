{
  "article_text": [
    "programming of graphics processing units ( gpus ) found on heterogeneous computing platforms has required the use of opencl or cuda until the last few years . even though the basic usage of these languages can be considered rather straightforward , tapping the full computational potential of the platform , including all general purpose processors ( gpps ) and the gpu simultaneously ,",
    "is a very complex task that requires specialized expertise .    to this end ,",
    "the research community has invested considerable effort in the development of programming frameworks @xcite that would relieve the programmer from the task of writing low - level code for optimized data transfers between the gpps and gpu and valid synchronization between computations .",
    "existing frameworks have found kahn process networks @xcite or dataflow abstractions @xcite to be suitable for simplifying the programming effort .",
    "unfortunately , even the most advanced programming frameworks have restrictions that limit their applicability to a certain class @xcite of ( signal processing ) applications , or fail to provide significant performance advantage @xcite when compared to manually written opencl or cuda programs .",
    "this paper addresses one of the fundamental limitations of existing solutions by introducing a novel dataflow - flavored programming framework that allows executing dynamic data rate applications on opencl / gpu devices . in the experiments",
    "it is shown that this feature allows up to a 5@xmath0 increase in application throughput .    in detail , the proposed framework features :    * an abstraction for expressing applications as a network of dataflow actors , * concurrent execution of gpp and gpu mapped actors , * support for executing dataflow actors with dynamic data rates , also on the gpu , * support for applications with initial ( delay ) tokens .",
    "the functionality of the framework is demonstrated by benchmarking two applications , video motion detection and dynamic predistortion filtering , and by comparing the results to the well - known dal framework @xcite .",
    "the rest of this paper is organized as follows : section  [ sec : background ] introduces the dataflow abstraction and presents related work , section  [ sec : proposed ] details the central contributions of this work , section  [ sec : experiments ] presents experimental evaluation of the proposed approach , section  [ sec : discussion ] discusses the results , and section  [ sec : conclusion ] concludes the paper .",
    "in the dataflow abstraction @xcite , applications are composed of _ actors _ that perform computations on data that is quantized into _ tokens_. each actor is created when the application is launched , and is terminated when the whole application has finished .",
    "actors acquire tokens from their input _ ports _ and produce computation results to their output ports .",
    "token communication between actors is handled by channels that have an order - preserving fifo ( first - in - first - out ) behavior .",
    "an actor ( see fig .  [",
    "fig : actor ] ) performs a computation by _ firing _ , which can include consuming tokens from input ports at the beginning of the firing , and producing tokens to the actor output ports at the end of the firing .",
    "a central feature of the dataflow abstraction is that computations are triggered by the availability of data , in contrast to , for example , time - triggered abstractions @xcite .    in literature ,",
    "a wide variety of dataflow models of computation ( moc ) have been presented .",
    "one of the most important factors that differentiate a dataflow moc from another concerns the token communication _ rates _ when an actor reads from , or writes to , a channel to which it connects . in this sense ,",
    "the most restricted dataflow moc is _ homogeneous synchronous dataflow _ ( hsdf )",
    "@xcite , where an actor must read exactly one token from each of its input ports and produce exactly one token to each of its output ports on each firing .",
    "_ synchronous dataflow _ ( sdf ) @xcite is slightly more expressive as it allows token rates larger than one , as is _ cycle - static dataflow _ ( csdf ) @xcite that goes beyond sdf by allowing tokens rates to vary in repetitive cycles .",
    "the aforementioned mocs ( hsdf , sdf , csdf ) are restricted in the sense that they disallow _ data dependent _ changes to the token rates , which is a required feature as , for example , video decoders @xcite and software defined radio applications @xcite introduce behavior that can not be captured by static data rates . to achieve this , _ dynamic dataflow _ mocs",
    "are required .",
    "examples of dynamic dataflow mocs are _ boolean dataflow _ ( bdf ) @xcite , _ enable - invoke dataflow _ ( eidf )",
    "@xcite and _ dataflow process networks _ ( dpn ) @xcite that allow port token rates to change at application run time .",
    "some formulations @xcite also allow interpreting kahn process networks ( kpn ) @xcite as a kind of a dynamic dataflow moc .",
    "the proposed framework is based on dynamic dataflow , and the essential features of its computation model are presented next , following the notation adopted from @xcite .",
    "that has two input ports and one output port . ]      in the proposed framework an application is described as a network @xmath1 , where @xmath2 is a set of actors and @xmath3 is a set of fifo communication channels that interconnect the actors .",
    "each actor @xmath4 may have 0 or more input ports @xmath5 and zero or more output ports @xmath6 .",
    "if an actor @xmath7 has zero input ports it is called a _ source actor _ , and if it has zero output ports it is called a _ sink actor_.    each fifo channel @xmath8 has an associated token rate @xmath9}$ ] , where @xmath10 is a positive integer .",
    "if actor @xmath7 is connected to fifo channel @xmath11 ( where @xmath12 is the index number of the fifo ) through its output port @xmath13 , the output port adopts the token rate @xmath10 of the fifo buffer .",
    "same applies for input ports . both reads and writes to channels are",
    "_ blocking _ , such that the execution of the reading ( writing ) actor stalls until sufficient tokens are ( space is ) available .",
    "an actor @xmath7 may be _ static _ or _",
    "dynamic_. dynamic actors have one _ control input port _ and _ regular ports_. a control port always has a fixed token rate of 1 ( and hence , the fifo to which it connects , must also have a token rate of 1 ) , whereas a regular port of a dynamic actor may have two token rates : 0 and @xmath10 , where @xmath10 is the token rate of the fifo channel @xmath14}$ ] to which @xmath15 connects .",
    "for static actors , on the other hand , each input @xmath16 and output @xmath13 port of @xmath7 always has a single fixed token rate inherited from the fifo @xmath11 to which it connects .",
    "figure  [ fig : actor ] depicts an example of this .",
    "dynamic actor @xmath7 is connected to three fifo channels : @xmath17 , @xmath18 and @xmath19 through its ports @xmath20 , @xmath21 and @xmath22 .",
    "fifos @xmath17 , @xmath18 and @xmath19 have token rates of 1 , 1 , and 2 , respectively .",
    "port @xmath20 is the control port of actor @xmath7 , denoted with a `` c '' in the figure .",
    "values of the tokens consumed from the control port set the token rate of input port @xmath21 to either 0 or 1 , however the mapping of control token port values to token rates of @xmath21 is left unspecified here .    when the dynamic actor @xmath7 fires , it first consumes one token from its control port .",
    "then , based on the token value of the consumed control port token , the token rate of each regular input port and regular output port @xmath23 of @xmath7 is fixed to either 0 or @xmath10 ( @xmath10 being adopted from the associated fifo @xmath9}$ ] ) _ for the duration of this firing_. after fixing the token rates , actor @xmath7 consumes tokens from each input port @xmath5 that has a non - zero token rate for the duration of this firing . based on the tokens consumed from the input ports , @xmath7 performs computations and finally produces tokens to each output port @xmath6 that has a non - zero token rate .",
    "any fifo buffer @xmath8 that is _ not _ connected to a control port is allowed to have 0 or 1 _ initial tokens _ ( delays ) irrespective of the token rate @xmath9}$ ] .",
    "initial tokens are data that is present in fifo buffers before any actor @xmath24 has fired , and is normally used to model feedbacks in signal processing systems , for example , in infinite impulse response ( iir ) filters .",
    "it is necessary to point out that the computation model described above can not be reduced to single - rate dataflow ( hsdf ) due to the allowed presence of initial tokens .",
    "also , the described model bears resemblance to boolean dataflow @xcite , however a more detailed analysis of the similarities and differences must be presented elsewhere due to limitations in presentation space .",
    "a number of programming frameworks targeting heterogeneous platforms have emerged in the last few years .",
    "the frameworks described in @xcite , @xcite and @xcite represent task - based programming approaches , where tasks are spawned , executed and finished , and their interdependencies are expressed as a directed acyclic graph .",
    "the proposed approach , in contrast , is based on actors that are created once at initialization and run as independent entities , communicating with each other until termination of the application .",
    "a recent article @xcite presents a framework that enables deploying applications written in the streamit language @xcite to gpus .",
    "compared to this work , the significant difference is that the streamit language heeds the sdf moc that does not allow data dependent execution paths or dynamic data rates , whereas the proposed framework allows dynamic data rates as described above .",
    "the same restriction of dynamic data rates also applies to two recent works @xcite that discuss deployment of rvc - cal dataflow programs to heterogeneous architectures .",
    "the dal framework @xcite is based on kahn process networks and also has an extension @xcite for targeting heterogeneous systems with opencl enabled devices . in terms of opencl / gpu acceleration",
    "this framework is limited to the sdf moc that disallows dynamic data rates .",
    "this section provides an overview of the proposed framework : subsection  [ ssec : actors ] explains how the programmer expresses actors for the proposed framework , subsection  [ ssec : channels ] describes the proposed inter - actor communications techniques , subsection  [ ssec : concurrency ] details the implementation of concurrency and finally subsection  [ ssec : toolchain ] gives an overview of the concrete framework implementation .      in the proposed framework",
    "each actor consists of the mandatory _ fire _ function , and optional _ init _ , _ control _ , and _ finish _ functions .",
    "the _ fire _ function describes the actor s behavior upon firing and comprises the reading of regular input ports , computation and writing to regular output ports .",
    "the optional _ init _ and _ finish _ functions are only executed once on application initialization and termination , and are mainly useful for source and sink actors to start and end interfacing with i / o . the _ control _",
    "function is only required for dynamic actors and is executed once for each firing of the actor , right before invoking the _ fire _ function .",
    "the _ control _",
    "function is responsible for setting the data rates of regular ports .    at design time",
    "the programmer chooses whether the actor is going to be executed on an opencl / gpu device or on one of the general purpose cores .",
    "depending on the choice , the actor functionality is written either in opencl c , or in the conventional c language .",
    "the proposed framework provides a minimal api that essentially provides functions for inter - actor communication , such as ` fifowritestart ` , ` fifowriteend ` , etc .",
    "this formulation , where actors consist of _ init _ , _ fire _ , and _ finish _ functions is identical to the dal @xcite framework .",
    "however , the _ control _ function , especially required for enabling dynamic data rate actors on opencl / gpu devices , is specific to this framework .",
    "the _ control _",
    "function takes one control token as its input and is required to set the data rate ( to 0 or @xmath10 as defined in subsection  [ ssec : ourmodel ] ) of each regular input and regular output port for the duration of one firing .",
    "the proposed framework does not impose limitations regarding the mapping of control token values to the token rates of ports .",
    "a communication channel in the proposed framework connects exactly one output port of an actor to exactly one input port of another actor , heeding fifo behavior .",
    "in contrast to other ( e.g. @xcite ) programming frameworks , the token capacity of a communication channel @xmath25 can not be arbitrarily chosen by the programmer , but is exactly specified as @xmath26 where @xmath10 is the token rate , and @xmath27 is the size ( e.g. in bytes ) of one token of fifo @xmath25 .    as a communication channel @xmath25 assumes to receive @xmath10 new tokens on each write , and to output @xmath10 tokens on each read , we see that a regular channel ( the _ otherwise _ case in eq .",
    "1 ) is essentially a double buffer that allows simultaneous reading and writing to the channel .",
    "however , for channels that contain an initial ( delay ) token , the channel is implemented as a slightly more complex buffer that implements a specific access pattern to enable simultaneous reads and writes to the channel .",
    "this is depicted in fig .",
    "[ fig : triplebuffer ] with an example case of @xmath28 .    at application initialization",
    "the initial token in the channel , displayed with @xmath29 in fig .",
    "[ fig : triplebuffer ] resides in buffer slot 0 .",
    "the first write to the channel occupies slots 1 ... 4 , whereas the first read consumes tokens from slots 0 ... 3 and so forth .",
    "the third write to the channel reaches the end ( slot 12 ) of the buffer , followed by an explicit data copy from slot 12 to slot 0 , and the access pattern starts to repeat .",
    "it is important to note that the access pattern is repetitive and can be generalized to any token rate @xmath30 .",
    "looking at fig .",
    "[ fig : triplebuffer ] , it is evident that this solution is not minimal in terms of memory footprint , but it was chosen as it offers 1 ) uncompromized throughput and 2 ) transparency to the application programmer .",
    "conventional ring buffers were considered inadequate , as opencl / gpus offer the best combination of performance and ease of programming when input and output data to kernels is provided as contiguous arrays .    the memory footprint overhead of this solution is slightly more than 50% ( depending on the token rate ) when compared to regular double buffers .",
    "essentially the same triple - buffer solution can also be generalized to 2 or more delay tokens , however due to limits in presentation space the generalization is omitted here .",
    "the proposed framework has been designed to enable maximally parallel operation .",
    "parallelism is based on threading , such that each actor runs on an operating system ( os ) thread of its own , regardless whether the actor is targeted to opencl / gpu devices or to one of the general purpose cores .",
    "each actor thread is created once at application startup , and is canceled after the application has terminated .",
    "similar to the dal framework @xcite , synchronization of data exchange over fifo channels is based on _ mutex _ locks and blocking communication : if an actor attempts to read a channel that has less tokens than the actor requires , the reading actor blocks until sufficient data is available . on one hand , this enables very efficient multiprocessing , but on the other hand makes the moc somewhat more restricted than e.g. that of dpns @xcite .    as each and every actor is instantiated as a separate thread using the gnu / linux _ pthreads _ library , the scheduling of actor firings ( heeding data availability ) is left to the os .",
    "if the programmer so chooses , the framework allows fixing of actors to specific gpp cores , otherwise the os chooses the core on which an actor firing is executed .",
    "it is necessary to state that alternatively to the adopted os threading based concurrency , it would also have been possible to build concurrency and synchronization on top of opencl events , however this would have limited the applicability to platforms where both the gpps and gpus have opencl drivers .",
    "the adopted os threading based solution , however , is beneficial due to its backwards compatibility : with this solution it is possible to jointly synchronize and run also non - opencl compatible gpps with gpus .",
    "[ fig : framework ] depicts a hierarchical view of the proposed framework .",
    "the implementation of the framework is written as a c library with an api that is called by the actors and by the actor network description .",
    "the actors that constitute the application are expressed as c functions , or as opencl kernels for opencl compatible targets , whereas the actor network is defined with a c function .",
    "p3.0cmp0.7cmp0.7cmp1.0cmp1.0 cm framework & dal & prop . &",
    "dal & prop .",
    "+ _ target _ & mc & mc & heterog . & heterog .",
    "+ motion detection & 0.77 & 0.85 & 3.69 & 3.46 + dynamic predistortion & 11.5 & 11.5 & _ n / a _ & 11.5 +    p0.8cmp5.5cmp6.6cmp3.2 cm tag & gpps & gpu & operating system + carrizo & amd pro a12 - 8800b ( 2.1 ghz , 4 cores ) & amd radeon r7 , opencl 2.0 , driver 15.30.3 & ubuntu 14.04 , g++ 4.8.4 + i7 & intel core i7 - 4770 ( 3.4 ghz , 4 cores ) & amd radeon hd 7750 , opencl 1.2 , driver 15.20.3 & ubuntu 14.04 , g++ 4.8.4 +",
    "to validate the functionality and performance of the proposed framework , two applications were benchmarked on two different heterogeneous platforms that are described in table  [ table : platforms ] .",
    "the carrizo chip features an integrated graphics processor , a solution that minimizes the data transfer times between the gpu and the gpp cores .",
    "the other platform , i7 , represents a traditional solution where gpp cores communicate with the gpu over a pci express bus and thus the data transfer times between the gpp and gpu are non - negligible .",
    "the dal framework @xcite was used as a reference , and the code of the two applications was adapted from the proposed framework to dal with minimal required changes .",
    "the dal platform only allows fixed actor - to - core mappings , whereas the proposed framework also allows letting the os to select the best core for execution , an option called _ free mapping _ in the results .",
    "the first application used in our experiments is 8-bit grayscale video motion detection that consists of five actors , as shown in fig .",
    "[ fig : video ] . the source and",
    "sink actors are always executed on gpp cores and are essentially responsible for reading and writing data from / to mass storage .",
    "the gauss actor performs 5@xmath05 pixels gaussian filtering on the input data , followed by the thres actor that subtracts consecutive frames and performs pixel thresholding against a fixed constant value .",
    "to avoid exceeding frame boundaries the gauss actor skips filtering for two pixel rows in the frame top and frame bottom .",
    "finally , the med actor performs 5-pixel median filtering to reduce noise from the generated motion map .",
    "one of the communication channels between the gauss and thres actors bears a dot in fig .  [",
    "fig : video ] and depicts an initial token .",
    "the initial token is a one - frame delay that enables the functionality of consecutive frame subtraction .    to enable comparison with previous works , the frame size used was 320@xmath0240 , which resulted in the token size being 76800 bytes . in gpp - only execution the token rate on all channels",
    "was kept at one , as increasing the token rate did not have a measurable performance effect .",
    "gpu acceleration was applied to motion detection by mapping the gauss , thres and med actors to the gpu .",
    "total amount of memory used for buffers is shown in table  [ table : buffers ] for each configuration .",
    "the motion detection application is essentially the same as the one used in our previous work @xcite , however re - written for the proposed framework . in @xcite the functionality of thres and med actors was implemented in a single actor .",
    "dynamic predistortion ( dpd ) filtering ( fig .",
    "[ fig : dpd ] ) was used as the second application test case .",
    "the algorithm is used in wireless communications to mitigate transceiver impairments , and to a great extent consists of parallel 10-tap fir filters .",
    "functionally , the filter is identical to the one presented in our previous work @xcite , but the actor descriptions have been rewritten for the proposed framework .",
    "dpd significantly differs from the motion detection application in the sense that it features actors with dynamic data rates : fig .",
    "[ fig : dpd ] shows the configuration ( c ) actor that at run - time periodically reconfigures the poly ( p ) and adder ( a ) actors to select which set of the fir filters is used to process the input signal .",
    "the reconfiguration period was set to once every 65536 samples , and the number of active filter actors is allowed to change arbitrarily between 2 and 10 .",
    "the run time reconfiguration used here is defined by an external input and can not be modeled e.g. by the csdf moc .",
    "the dpd application computes on complex floating point numbers , which were represented as a pair of single precision floats . to this end , all edges in fig .",
    "[ fig : dpd ] _ inside _ the `` gpu '' box represent a pair of edges , one for the real part and one for the imaginary part .",
    "hence , the total number of fifo channels is 46 in this application .",
    "p1.2cmp0.7cmp0.7cmp0.7cmp1.3cmp1.3 cm framework & dal & prop . & prop . & dal & prop .",
    "+ _ target _ & mc & mc & mc & heterog . & heterog . + _ mapping _ & fixed & fixed & free & - & - + carrizo & 400 & 485 & 486 & 2915@xmath31 & 4614 + i7 & 872 & 1138 & 1135 & 4320@xmath31 & 6063 +    [ t ]    p1.2cmp0.7cmp0.7cmp0.7cmp1.3cmp1.3 cm framework & dal & prop . & prop . &",
    "dal & prop .",
    "+ _ target _ & mc & mc & mc & heterog . & heterog . + _ mapping _ & fixed & fixed & free & - & - + carrizo & 5.5 & 7.1 & 8.8 & _ n / a _ & 47.4 + i7 & 21.1 & 30.4 & 32.8 & _ n / a _ & 83.8 +      results for executing the motion detection and dpd applications on the proposed framework , and the reference framework dal @xcite are presented in table  [ table : motion ] and table  [ table : dpd ] .    on both platforms the gpu - accelerated version of motion detection invoked a gpu driver issue on the dal framework",
    "when the token rate was increased beyond 1 .",
    "to enable benchmarking , the problem was circumvented by using 640x480 frames with token rate 1 instead of 320x240 frames with token rate 4 on gpu - accelerated dal experiments .",
    "this alternative setting left the number of computations and opencl work dimensions identical , and hence the results are directly comparable to other results in table  [ table : motion ] .    for the motion detection application the proposed framework provided a performance advantage of 20% compared to dal on the 4 processors of the carrizo platform , and there was no evident performance difference between fixed and free actor - to - core mappings . using the proposed framework , on this platform the gpu provided a considerable 9.5@xmath0 speedup compared to the best multicore - only results . comparing the gpu - accelerated programs , the proposed approach was 58% faster than dal .    on the i7 platform multicore - only",
    "execution yielded 30% higher throughput on the proposed framework than on dal .",
    "when gpu - accelerated programs are compared , the proposed framework was 40% faster than dal .    for the dpd application",
    "the proposed framework yielded a 29% speedup over dal with fixed actor - to - core mapping on carrizo multicore - only .",
    "the speedup gap increased to 60% when the mapping was left to be decided by the underlying os . on the proposed framework , the use of gpu acceleration provided a speedup of 5.4@xmath0 compared to best multicore results , _ whereas on the dal platform gpu acceleration was not possible as the dal framework does not support dynamic data rate actors on the gpu . _    on the i7 platform",
    "the dpd application executed 44% faster on the proposed framework ( fixed mapping ) than on dal when only the multicore chip was used .",
    "the gap further increased to 55% when the actor - to - core mapping was left to be decided by the os .",
    "finally , gpu acceleration enabled by the proposed framework yielded a 2.6@xmath0 speedup compared to the best multicore results .",
    "the results presented in section  [ ssec : results ] illustrate that the proposed framework    * provides 20%-60% higher throughput than the reference framework , and * enables executing applications with dynamic dataflow behavior on the gpu .",
    "from the viewpoint of the application programmer , dal and the proposed framework are to a great extent similar , differing mainly in the way actors are written for gpu targets . in dal , it is in principle possible to write an actor in c language and have it executed by the framework either on gpps or on the gpu without code modifications , however such actors are restricted to static data rates . at the moment the proposed approach requires an actor to be written in opencl c for gpu execution .",
    "it is necessary to state that although the proposed approach overcomes dal in terms of performance , dal provides a number of features that are unavailable in the proposed framework , such as targeting distributed systems , error - resilience via spare core allocation and support for multiple simultaneous applications .",
    "one of the limitations of the proposed framework is that an actor port may have at maximum two different data rates .",
    "the consequence of this restriction is that for applications such as dynamic predistortion , where the data path is arbitrarily changing at run time , the token rate must for the dynamic part of the network be kept at 1 , otherwise the network has a risk of deadlocking .",
    "hence , for future development of the framework the most clear direction is relaxation of token rate restrictions without sacrificing the efficiency of the framework . in the same vein , it is mandatory to present a formal definition of the framework s model of computation and analyze its properties to e.g. identify necessary conditions for avoiding the possibility of deadlock .",
    "another likely direction of future work is to make the api compatible with dal .",
    "this would have two benefits : 1 ) applications from the dal repository could directly be executed on the proposed framework , and 2 ) it would be possible to write programs for the proposed framework using the rvc - cal dataflow language by means of the open rvc - cal compiler dal backend @xcite .",
    "we have presented a novel dataflow - flavored framework for efficient programming of heterogeneous multicore platforms . compared to the state - of - the - art , the proposed framework pioneers in enabling the execution of dynamic dataflow actors on gpu devices .",
    "claims on the proposed framework s efficiency and features have been demonstrated with two applications , video motion detection and dynamic predistortion filtering .",
    "experiments have shown that the proposed framework provides 20% to 60% higher throughput compared to the well - known dal framework . moreover ,",
    "the proposed framework is capable of gpu - accelerating actors that have dynamic data rates , a feature that was measured to improve throughput up to 5@xmath0 .",
    "this work was funded by academy of finland project unicode .",
    "l.  schor , a.  tretter , t.  scherer , and l.  thiele , `` exploiting the parallelism of heterogeneous systems using dataflow graphs on top of opencl , '' in _ ieee symposium on embedded systems for real - time multimedia ( estimedia ) _ , 2013 , pp .",
    "a.  sbrlea , y.  zou , z.  budimlc , j.  cong , and v.  sarkar , `` mapping a data - flow programming model onto heterogeneous platforms , '' in _ acm sigplan / sigbed international conference on languages , compilers , tools and theory for embedded systems ( lctes ) _ , 2012 , pp .",
    "6170 .",
    "w.  lund , s.  kanur , j.  ersfolk , l.  tsiopoulos , j.  lilius , j.  haldin , and u.  falk , `` execution of dataflow process networks on opencl platforms , '' in _ euromicro international conference on parallel , distributed and network - based processing ( pdp ) _",
    ", 2015 , pp . 618625 .",
    "l.  schor , i.  bacivarov , d.  rai , h.  yang , s .- h .",
    "kang , and l.  thiele , `` scenario - based design flow for mapping streaming applications onto on - chip many - core systems , '' in _ international conference on compilers , architectures and synthesis for embedded systems ( cases ) _ , 2012 , pp . 7180 .",
    "t.  a. henzinger , b.  horowitz , and c.  m. kirsch , `` giotto : a time - triggered language for embedded programming , '' in _ embedded software : first international workshop , ( emsoft ) _ ,",
    "t.  a. henzinger and c.  m. kirsch , eds . , 2001 , pp",
    ". 166184 .",
    "j.  t. buck and e.  a. lee , `` scheduling dynamic dataflow graphs with bounded memory using the token flow model , '' in _ international conference on acoustics , speech , and signal processing ( icassp ) _ , april 1993 , vol .  1 ,",
    "429432 vol.1 .",
    "e.  a. lee and e.  matsikoudis , `` the semantics of dataflow with firing , '' in _ from semantics to computer science : essays in memory of gilles kahn _ , g.  huet , g.  plotkin , j.j .",
    "lvy , and y.  bertot , eds .",
    "cambridge university press , 2009 .",
    "t.  gautier , j.  v.  f. lima , n.  maillard , and b.  raffin , `` xkaapi : a runtime system for data - flow task programming on heterogeneous architectures , '' in _ international symposium on parallel and distributed processing ( ipdps ) _",
    ", 2013 , pp . 12991308 .",
    "w.  thies , m.  karczmarek , and s.  amarasinghe , `` streamit : a language for streaming applications , '' in _ compiler construction _ , r.  nigel horspool , ed .",
    "2304 of _ lecture notes in computer science _ , pp . 179196 .",
    "springer , 2002 .",
    "j.  boutellier and a.  ghazi , `` multicore execution of dynamic dataflow programs on the distributed application layer , '' in _ ieee global conference on signal and information processing ( globalsip ) _ , 2015 ,",
    ". 893897 ."
  ],
  "abstract_text": [
    "<S> heterogeneous computing platforms consisting of general purpose processors ( gpps ) and graphics processing units ( gpus ) have become commonplace in personal mobile devices and embedded systems . for years , programming of these platforms was very tedious and simultaneous use of all available gpp and gpu resources required low - level programming to ensure efficient synchronization and data transfer between processors . </S>",
    "<S> however , in the last few years several high - level programming frameworks have emerged , which enable programmers to describe applications by means of abstractions such as dataflow or kahn process networks and leave parallel execution , data transfer and synchronization to be handled by the framework .    unfortunately , even the most advanced high - level programming frameworks have had shortcomings that limit their applicability to certain classes of applications . </S>",
    "<S> this paper presents a new , dataflow - flavored programming framework targeting heterogeneous platforms , and differs from previous approaches by allowing gpu - mapped actors to have data dependent consumption of inputs / production of outputs . </S>",
    "<S> such flexibility is essential for configurable and adaptive applications that are becoming increasingly common in signal processing . _ in our experiments it is shown that this feature allows up to 5@xmath0 increase in application throughput . </S>",
    "<S> _    the proposed framework is validated by application examples from the video processing and wireless communications domains . in the experiments </S>",
    "<S> the framework is compared to a well - known reference framework and it is shown that the proposed framework enables both a higher degree of flexibility and better throughput .    dataflow computing , signal processing , parallel processing , graphics processing units </S>"
  ]
}