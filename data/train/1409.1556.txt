{
  "article_text": [
    "convolutional networks ( convnets ) have recently enjoyed a great success in large - scale image and video recognition  @xcite which has become possible due to the large public image repositories , such as imagenet  @xcite , and high - performance computing systems , such as gpus or large - scale distributed clusters  @xcite . in particular , an important role in the advance of deep visual recognition architectures has been played by the imagenet large - scale visual recognition challenge ( ilsvrc )  @xcite , which has served as a testbed for a few generations of large - scale image classification systems , from high - dimensional shallow feature encodings  @xcite ( the winner of ilsvrc-2011 ) to deep convnets  @xcite ( the winner of ilsvrc-2012 ) .    with convnets becoming more of a commodity in the computer vision field , a number of attempts have been made to improve the original architecture of  @xcite in a bid to achieve better accuracy .",
    "for instance , the best - performing submissions to the ilsvrc-2013  @xcite utilised smaller receptive window size and smaller stride of the first convolutional layer .",
    "another line of improvements dealt with training and testing the networks densely over the whole image and over multiple scales  @xcite . in this paper",
    ", we address another important aspect of convnet architecture design  its depth . to this end",
    ", we fix other parameters of the architecture , and steadily increase the depth of the network by adding more convolutional layers , which is feasible due to the use of very small ( @xmath1 ) convolution filters in all layers .    as a result ,",
    "we come up with significantly more accurate convnet architectures , which not only achieve the state - of - the - art accuracy on ilsvrc classification and localisation tasks , but are also applicable to other image recognition datasets , where they achieve excellent performance even when used as a part of a relatively simple pipelines ( e.g.deep features classified by a linear svm without fine - tuning ) .",
    "we have released our two best - performing models to facilitate further research .",
    "the rest of the paper is organised as follows . in  sect .",
    "[ sec : arch_config ] , we describe our convnet configurations .",
    "the details of the image classification training and evaluation are then presented in  sect .",
    "[ sec : learning ] , and the configurations are compared on the ilsvrc classification task in  sect .",
    "[ sec : exp ] .",
    "[ sec : conclusion ] concludes the paper . for completeness",
    ", we also describe and assess our ilsvrc-2014 object localisation system in  appendix  [ sec : loc ] , and discuss the generalisation of very deep features to other datasets in  appendix  [ sec : dataset_transfer ] .",
    "finally ,  appendix  [ sec : revisions ] contains the list of major paper revisions .",
    "to measure the improvement brought by the increased convnet depth in a fair setting , all our layer configurations are designed using the same principles , inspired by  @xcite . in this section ,",
    "we first describe a generic layout of our configurations ( sect .",
    "[ sec : arch ] ) and then detail the specific configurations used in the evaluation ( sect .  [",
    "sec : config ] ) .",
    "our design choices are then discussed and compared to the prior art in  sect .",
    "[ sec : discuss ] .      during training , the input to our convnets is a fixed - size @xmath2 rgb image .",
    "the only pre - processing we do is subtracting the mean rgb value , computed on the training set , from each pixel .",
    "the image is passed through a stack of convolutional ( conv . )",
    "layers , where we use filters with a very small receptive field : @xmath1 ( which is the smallest size to capture the notion of left / right , up / down , center ) . in one of the configurations we also utilise @xmath3 convolution filters , which can be seen as a linear transformation of the input channels ( followed by non - linearity ) .",
    "the convolution stride is fixed to @xmath4 pixel ; the spatial padding of conv .",
    "layer input is such that the spatial resolution is preserved after convolution , i.e.the padding is @xmath4 pixel for @xmath5 conv .  layers .",
    "spatial pooling is carried out by five max - pooling layers , which follow some of the conv .",
    "layers ( not all the conv",
    ".  layers are followed by max - pooling ) .",
    "max - pooling is performed over a @xmath6 pixel window , with stride @xmath7 . a stack of convolutional layers ( which has a different depth in different architectures )",
    "is followed by three fully - connected ( fc ) layers : the first two have 4096 channels each , the third performs 1000-way ilsvrc classification and thus contains 1000 channels ( one for each class ) .",
    "the final layer is the soft - max layer .",
    "the configuration of the fully connected layers is the same in all networks .",
    "all hidden layers are equipped with the rectification ( relu  @xcite ) non - linearity .",
    "we note that none of our networks ( except for one ) contain local response normalisation ( lrn ) normalisation  @xcite : as will be shown in  sect .",
    "[ sec : exp ] , such normalisation does not improve the performance on the ilsvrc dataset , but leads to increased memory consumption and computation time .",
    "where applicable , the parameters for the lrn layer are those of  @xcite .      the convnet configurations , evaluated in this paper , are outlined in  table  [ tab : config ] , one per column . in the following",
    "we will refer to the nets by their names ( a  e ) .",
    "all configurations follow the generic design presented in  sect .",
    "[ sec : arch ] , and differ only in the depth : from 11 weight layers in the network a ( 8 conv .  and 3 fc layers ) to 19 weight layers in the network e ( 16 conv .  and",
    "3 fc layers ) . the width of conv .",
    "layers ( the number of channels ) is rather small , starting from @xmath8 in the first layer and then increasing by a factor of @xmath7 after each max - pooling layer , until it reaches @xmath9 .    in  table",
    "[ tab : num_params ] we report the number of parameters for each configuration . in spite of a large depth , the number of weights in our nets is not greater than the number of weights in a more shallow net with larger conv .",
    "layer widths and receptive fields ( 144 m weights in  @xcite ) .     a & a - lrn & b & c & d & e + 11 weight & 11 weight & 13 weight & 16 weight & 16 weight & 19 weight + layers & layers & layers & layers & layers & layers +   + conv3 - 64 & conv3 - 64 & conv3 - 64 & conv3 - 64 & conv3 - 64 & conv3 - 64 + & * lrn * & * conv3 - 64 * & conv3 - 64 & conv3 - 64 & conv3 - 64 +   + conv3 - 128 & conv3 - 128 & conv3 - 128 & conv3 - 128 & conv3 - 128 & conv3 - 128 + & & * conv3 - 128 * & conv3 - 128 & conv3 - 128 & conv3 - 128 +   + conv3 - 256 & conv3 - 256 & conv3 - 256 & conv3 - 256 & conv3 - 256 & conv3 - 256 + conv3 - 256 & conv3 - 256 & conv3 - 256 & conv3 - 256 & conv3 - 256 & conv3 - 256 + & & & * conv1 - 256 * & * conv3 - 256 * & conv3 - 256 + & & & & & * conv3 - 256 * +   + conv3 - 512 & conv3 - 512 & conv3 - 512 & conv3 - 512 & conv3 - 512 & conv3 - 512 + conv3 - 512 & conv3 - 512 & conv3 - 512 & conv3 - 512 & conv3 - 512 & conv3 - 512 + & & & * conv1 - 512 * & * conv3 - 512",
    "* & conv3 - 512 + & & & & & * conv3 - 512 * +   + conv3 - 512 & conv3 - 512 & conv3 - 512 & conv3 - 512 & conv3 - 512 & conv3 - 512 + conv3 - 512 & conv3 - 512 & conv3 - 512 & conv3 - 512 & conv3 - 512 & conv3 - 512 + & & & * conv1 - 512 * & * conv3 - 512 * & conv3 - 512 + & & & & & * conv3 - 512 * +   +   +   +   +   +    [ tab : config ]    .*number of parameters * ( in millions ) . [ cols=\"<,^,^,^,^,^,^\",options=\"header \" , ]     [ tab : generalise_action ]    our representation achieves the state of art on the voc action classification task even without using the provided bounding boxes , and the results are further improved when using both images and bounding boxes . unlike other approaches",
    ", we did not incorporate any task - specific heuristics , but relied on the representation power of very deep convolutional features .",
    "[ [ other - recognition - tasks . ] ] other recognition tasks .",
    "+ + + + + + + + + + + + + + + + + + + + + + + +    since the public release of our models , they have been actively used by the research community for a wide range of image recognition tasks , consistently outperforming more shallow representations .",
    "for instance , @xcite achieve the state of the object detection results by replacing the convnet of  @xcite with our 16-layer model .",
    "similar gains over a more shallow architecture of  @xcite have been observed in semantic segmentation  @xcite , image caption generation  @xcite , texture and material recognition  @xcite .",
    "here we present the list of major paper revisions , outlining the substantial changes for the convenience of the reader ."
  ],
  "abstract_text": [
    "<S> in this work we investigate the effect of the convolutional network depth on its accuracy in the large - scale image recognition setting . our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small ( @xmath0 ) convolution filters , which shows that a significant improvement on the prior - art configurations can be achieved by pushing the depth to 1619 weight layers . </S>",
    "<S> these findings were the basis of our 2014 submission , where our team secured the first and the second places in the localisation and classification tracks respectively . </S>",
    "<S> we also show that our representations generalise well to other datasets , where they achieve state - of - the - art results . </S>",
    "<S> we have made our two best - performing convnet models publicly available to facilitate further research on the use of deep visual representations in computer vision . </S>"
  ]
}