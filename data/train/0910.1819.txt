{
  "article_text": [
    "importance sampling procedures aim at reducing the calculation time which is necessary in order to evaluate integrals , often in large dimension .",
    "we consider the case when the integral to be numerically computed is the probability of an event defined by a large number of random components ; this case has received quite a lot of attention , above all when the event is of _ small _ probability , typically of order @xmath0 or so , as occurs frequently in industrial applications or in communication devices .",
    "the order of magnitude of the probability to be estimated is here somehow larger , and aims at coping with `` moderate probabilities '' as dealt with in statistics .",
    "the basic situation in is can be stated as follows .",
    "let @xmath1 be some random variable , say on @xmath2 with probability measure @xmath3 and density @xmath4 .",
    "let @xmath5 be a subset of @xmath6 with @xmath7 let @xmath8 denote a sample of i.i.d",
    ". observations of @xmath1 . by the law of large numbers @xmath9estimates",
    "@xmath10 without bias , when the @xmath11 are sampled under the density @xmath12 an altenative unbiased estimate of @xmath10 can be defined through @xmath13for all density @xmath14 when the support of @xmath4 is a subset of the support of @xmath14 , and the @xmath15are i.i.d .",
    "observations of a r.v . @xmath16 with density @xmath17 as is well known the optimal choice for the is sampling density @xmath14 is @xmath18 , the density of @xmath1 conditioned upon the event @xmath19 unfortunately an unpracticable choice which presumes the knowledge of @xmath20 the quantity to be estimated .",
    "would this sampling density be at hand , the required number @xmath21 of replications of @xmath16 to be performed would reduce to @xmath22 and the estimate would be exactly @xmath23 this fact motivates efforts in order to approximate @xmath24 in the case when the variable @xmath1 has a distribution which allows it .",
    "sometimes the random variable @xmath1 is obtained as a function of a large number of random variables , say @xmath25 and the event @xmath26 is of small or moderate probability . also the density of @xmath27 can not be evaluated analytically , due to the very definition of @xmath27 , but the random variables @xmath28 s have known distribution .",
    "this happens for instance when @xmath1 is a moment estimator or when it is the linear part of the expansion of an m or l -estimate ( see section 4 ) .",
    "the example which we have in mind is the following , which helps as a benchmark case in the is literature .",
    "the r.vs @xmath29 are i.i.d .",
    ", are centered with variance 1 , with common density @xmath30 on @xmath6 , and @xmath31is the empirical mean of the @xmath32 the set @xmath5 is @xmath33 where @xmath34 tends slowly to @xmath35 from above and we intend to estimate@xmath36for large but fixed @xmath37 many asymptotic results provide sharp estimates for @xmath38 but it is a known fact that asymptotic expansions are not always good tools when dealing with numerical approximations for fixed ( even large ) @xmath37 for example , citing ermakov ( 2004 , p 624 , ermakov2003 ) , the berry - esseen approximation for the evaluation of risks of order @xmath39 in testing is pertinent for sample sizes of order 5000 - 10000 ; also the accuracy of available moderate deviation probabilities as developped by inglot , kallenberg and ledwina in inglotkallenbergledwina1992 has not been investigated .",
    "this motivates our interest in numerical techniques in this field .    according to ( [ lln ] ) the basic estimate of @xmath38",
    "is defined as follows : generate @xmath21 i.i.d .",
    "samples @xmath40 with underlying density @xmath41 and define @xmath42where @xmath43here @xmath44 @xmath45 the statistics",
    "@xmath46 estimates the _ moderate deviation _",
    "probability of the sample mean of the @xmath32 also denoting @xmath14 a sampling density of the vector @xmath47 the associated is estimate is @xmath48    in the range of moderate deviations the two major contributions to is schemes for the estimation of @xmath49 are fuh and hu @xcite and ermakov @xcite .",
    "the paper by fuh and hu does not consider events of moderate deviations as intended here ; it focuses on is schemes for the estimation of @xmath50 where @xmath51 is a given multinormal random vector and @xmath5 is a fixed set in @xmath52 the authors consider efficiency with respect to the variance of the estimate and state that for the case of interest the efficient sampling scheme is deduced from the distribution of @xmath53 by a shift in the mean inside the set @xmath54 the papers by ermakov instead handle similar problems as we do . ermakov",
    "s 2007 paper  @xcite considers a sampling scheme where @xmath14 is the density of i.i.d",
    ". components .",
    "he proves that this scheme is efficient in the sense that the computational burden necessary to obtain a relative precision of the estimate with respect to @xmath49 does not grow exponentially as a function of @xmath37 he considers statistics of greater generality than the sample mean , such as m and l estimators ; in the range of moderate deviations the asymptotic behavior of those objects is captured however through their linear part which is the empirical mean of their influence function , which puts the basic situation back at the center of the scene .",
    "we discuss efficiency in section 3 and present some results in connection with ermakov s pertaining to m and l estimators in section 4 .",
    "the numerator in the expression  ( [ form is ] ) is the product of the @xmath55 while the denominator need not be a density of i.i.d .",
    "copies evaluated on the @xmath56 . indeed the optimal choice for @xmath14 is the density of @xmath57 conditioned upon @xmath58 say @xmath59    since the optimal solution is known to be @xmath60 , the best its approximation , the best the sampling scheme , at least when it does not impose a large calculation burden ; classical sampling schemes consist in simulation of independent copies of r.v.s @xmath61 , @xmath62 , and efficiency is defined in terms of variance of the estimate inside this class of sampling , which , by nature , is suboptimal with respect to sampling under good approximations of @xmath63 for long runs , i.e. for large @xmath64the present paper explores the choice of good sampling schemes from this standpoint . obviously mimicking the optimal scheme  results in a net gain on the number @xmath21 of replications of the runs which are necessary to obtain a given accuracy of the estimate with respect to @xmath49 @xmath45",
    "however the criterion which we consider is different from the variance , and results as an evaluation of the mse of our estimate on specific subsets of the runs generated by the sampling scheme , which we call typical subsets , namely having probability going to @xmath22 under the sampling scheme as @xmath65 increases . on such sets ,",
    "the mse is proved to be of very small order with respect to the variance of the classical estimate , whose mse  can not be diminuished on any such typical subsets .",
    "we believe that this definition makes sense and prove it also numerically .",
    "this is the scope of section 3 in which  it will be shown that the relative gain in terms of simulation runs necessary to perform an @xmath66 relative error on @xmath49 drops by a factor @xmath67 with respect to the classical is  scheme .",
    "our proposal therefore hinges on the local approximation of the conditional distribution of longs runs @xmath68 from @xmath69 this can not be achieved through the classical theory of moderate deviations , first developped by de acosta and more recently by ermakov ; at the contrary the ad hoc procedure developped in the range of large deviations by diaconis and freedman @xcite  for the local approximation of the conditional distribution of @xmath68 given the value of @xmath70 is the starting point of the present approach .",
    "we find it useful to briefly expose these two different points of view .",
    "we also mention the approximation technique for moderate deviations of sub linear functionals of the empirical measure by inglot , kallenberg and ledwina inglotkallenbergledwina1992 , based on strong approximation techniques ; these results provide explicit equivalents for the probability of moderate deviations , but do not lead to adequate approximations for the obtention of their numerical counterparts by is methods .",
    "the following notation and assumptions will be kept throughout this paper .",
    "we assume that @xmath71 satisfies the cramer condition , i.e. @xmath72 has a finite moment generating function @xmath73 in a non void neighborhood of @xmath74 denote @xmath75and @xmath76when defined .",
    "the values of @xmath77 and @xmath78 are the expectation and the variance of the _ tilted _ density @xmath79where @xmath80 is the only solution of the equation @xmath81 when @xmath82 belongs to the support of @xmath12 denote @xmath83 the probability measure with density @xmath84 .",
    "the _ chernoff function _ of @xmath71 is@xmath85for @xmath86 in the support of @xmath71 and it holds@xmath87where @xmath88 denotes the reciprocal function of @xmath89    denote @xmath90the characteristic function of @xmath91 assume that @xmath92for some @xmath93 this condition entails the validity of the edgeworth expansions to be used in the sequel ( see e.g. feller @xcite ) .",
    "the notation @xmath94 is used to denote the value of the density @xmath4 of the r.v .",
    "@xmath95 at point @xmath96 the notation @xmath97 is used to define the value of the density of the r.v .",
    "@xmath98 under @xmath4 , i.e. when the summands are i.i.d . with density @xmath12",
    "also we may write @xmath99 to denote the density ( on the corresponding image space ) of some function @xmath100 of the sample @xmath101 we write @xmath102 the distribution of @xmath57 given @xmath103 and @xmath104 its density .",
    "the symbol @xmath105 denotes the standard normal density on @xmath106      a basic requirement for a good is sampling scheme is that it mimicks the conditional _ density _ @xmath59 we first expose a general argument in this direction in order to clarify that there is no bypass through the general theory of large or moderate deviations to achieve this goal .",
    "also the present discussion motivates the choices of classical is sampling schemes ( ermakov ) , emphasizing that the general theory provides the proof that the _ marginal _ conditional distribution of @xmath57 under @xmath103 is well approximated by @xmath107 a statement which is usually refered to as a _ gibbs conditional principle .",
    "_ we need some tools from the moderate deviation principle as developped by @xcite following deacosta1992 .",
    "let @xmath108 be a class of measurable functions defined on @xmath6 and @xmath109 be the class of all signed finite measures on @xmath6 which satisfy@xmath110on @xmath111 define the @xmath112 topology , which is the coarsest for which all mappings @xmath113 ( @xmath114 ) are continuous for all @xmath115 in @xmath108 . for @xmath3 a probability measure and @xmath116 in @xmath117 the so - called chi - square distance between @xmath3 and @xmath116",
    "is defined through@xmath118whenever @xmath116 is absolutely continuous with respect to @xmath119 and equals @xmath120 otherwise .",
    "@xmath121the following _ moderate deviation _",
    "sanov result holds ; see ermakov2007 .",
    "assume that @xmath34 tends to @xmath122 and @xmath123 tends to infinity .",
    "let @xmath124 denote the empirical measure pertaining to an i.i.d .",
    "sample @xmath125 write @xmath126 it holds    @xmath127    where the interior and closure of the set @xmath128 refer to the @xmath112 topology on @xmath129    consider now the asymptotic distribution of @xmath71 conditionally upon the sequence of events @xmath130 , so - called moderate deviation events . with @xmath131 and @xmath132",
    "the class of all bounded measurable functions , @xmath133 holds with @xmath128 substitued by @xmath134 the subset of @xmath111 defined through@xmath135    with @xmath3 the probability measure of the r.v .",
    "@xmath71 denote @xmath136 the @xmath137 _ projection of _",
    "@xmath3 on @xmath138 namely @xmath139the set @xmath134 is closed in @xmath111 @xmath140 equipped with the @xmath141 @xmath121topology .",
    "existence of a @xmath137 projection of @xmath3 on a @xmath142closed subset of @xmath143 holds as a consequence of theorem 2.6  in @xcite when @xmath144 is finite for all @xmath100 in @xmath145 which clearly holds since @xmath146 is finite .",
    "uniqueness follows from the convexity of @xmath134 and the strict convexity of @xmath147 from ( [ sanov mdp ] ) it can easily be obtained that@xmath148with @xmath149 which in turn yields the following    [ prop gibbs moderate ]  with the above notation@xmath150    the proofs of ( [ cond sanov mdp ] ) and of the above proposition are differed to the appendix .",
    "this way can not provide an equivalent expression for the conditional _ density _ of @xmath71 which requires strong regularity assumptions .",
    "furthermore it can not be extended to the case of interest here , when @xmath71 is substituted by @xmath151 for large values of @xmath152 , i.e.  when an approximation of the law of the path @xmath57 is needed , at least on long runs .",
    "however the result in proposition [ prop gibbs moderate ] is a strong argument in favor of ermakov s sampling scheme , namely simulating i.i.d .",
    "r.v.s with common density @xmath153 in ( [ form is ] ) .",
    "the other way follows zabell @xcite and diaconis and freedman @xcite approaches , which were developped in the range of large deviations .",
    "see also van camperhout and cover vancamperhoutcover1981 , who considered the density or the c.d.f . of @xmath154 conditioned on the value of @xmath98 for fixed @xmath155",
    "it is restricted in essence to the context of the sample mean .",
    "the sketch of the method is as follows .",
    "the density of @xmath71 given @xmath156 writes@xmath157where we used the symbol @xmath4 to emphasize that the @xmath158 are i.i.d .",
    "with common density @xmath159 it is a known fact , and easy to establish , that the density defined in ( [ cond dens ] ) is invariant when sampling from any density of the form ( [ tilted density ] ) instead of @xmath159 this yields , selecting @xmath160 @xmath161when the r.vs @xmath28 s obey a local central limit theorem under the sampling density @xmath162 it can be proved that @xmath163as @xmath65 tends to @xmath164 diaconis and freedman obtain such a statement when @xmath71 is substituted by @xmath68 with @xmath165 we will continue this approach in the range of moderate deviations , enhancing it to the density of @xmath166 with @xmath167 integrating with respect to the conditional distribution of @xmath98 under the event @xmath168 provides the required approximation@xmath45    the scope of the present paper is to present some technique which provides typical realisations of runs @xmath68 under the conditional event @xmath103 for very large @xmath155 therefore it aims at the exploration of the support of the distribution of @xmath57 under @xmath169 the application which is presented pertains to importance sampling for the estimation of rare events probabilities through the adaptive twisted is  scheme .",
    "section 2 of this paper is devoted to the approximation of the conditional density of @xmath68 under @xmath169 section 3 presents the atis algorithm , a number of remarks for its practical implementation , and discusses efficiency .",
    "section 4 is devoted to m and l estimates and their moderate deviation probabilities .",
    "we have postponed many proofs to the appendix , but the main one of section 2 .",
    "moderate deviations results for sums of i.i.d .",
    "real valued random variables under our assumptions have been studied since the 50 s by many authors .",
    "we will make use of a _ local _ result , due to richter @xcite , which we state as    [ lemma richter local ] under the general hypotheses and notation of this paper , when @xmath34 is a sequence satisfying @xmath170 together with @xmath171 it holds@xmath172    the _ global _ counterpart of lemma [ lemma richter local ] in the form used here is due to jensen ( see @xcite , corollary 6.4.1 ) and states    [ lemma jensen ] under the same hypotheses as above@xmath173where @xmath174    the following known fact is used repetedly .",
    "it sets that the conditional densities of sub - partial sums given the partial sum is invariant through any tilting .",
    "assume @xmath175 i.i.d .",
    "with density @xmath4 and note @xmath176 the corresponding tilted density for some parameter @xmath177    [ lemma inv conditional]for @xmath178 for all @xmath179 in  the support of @xmath119 for all @xmath180 and @xmath181 @xmath182      the sequence of constants @xmath34  defining @xmath5 in ( [ a ] ) and ( [ e_n ] ) satisfies    @xmath183    in this section we obtain a close approximation for @xmath184 for @xmath185 where @xmath34 and @xmath186 satisfy the following set of conditions .",
    "the value of @xmath187 satisfies @xmath188 with    @xmath189    we denote ( a1), ... ,(a4 ) , ( c1), ... ,(c4 ) the above conditions .",
    "it appears clearly from ( [ form is ] ) that the optimal choice @xmath190 need only to hold on paths @xmath191 sampled under @xmath14 and not on all @xmath192  in a similar way the approximation of the optimal density need to be realized only when evaluated on samples @xmath193 generated according to this approximation , and approximation of @xmath194 on the entire space @xmath195 is not needed@xmath45 the approximation of @xmath196 by such a density @xmath197 is difficult to obtain on realizations under @xmath197 and much easier under @xmath198 the following lemma proves that approximating @xmath196 by @xmath197 under @xmath104 is similar to approximating @xmath104 by @xmath197 under @xmath199    let @xmath200 and @xmath201 denote two p.ms on @xmath202 with respective densities @xmath203 and @xmath204    [ lemmafrompntogn ] suppose that for some sequence @xmath205 @xmath121which tends to @xmath122 as @xmath65 tends to infinity@xmath206as @xmath65 tends to @xmath164 then @xmath207    denote @xmath208it holds for all positive @xmath209@xmath210where @xmath211since @xmath212it follows that @xmath213which proves the claim .",
    "this shows that the approximation of @xmath104 need not to be achieved on the whole space @xmath195 but only on _ typical paths _ under the conditionning event @xmath169 it appears thatsuch a sharp approximation is possible on quite long portions @xmath214of sample paths generated under @xmath102,@xmath121when @xmath186 tends to @xmath215  together with @xmath65 and @xmath216 goes to @xmath217    let @xmath218 such that @xmath219 with @xmath220 small enough .",
    "we prove that the sequence of conditional densities @xmath221 is closely approximated by a sequence of suitably modified tilted densities when evaluated at @xmath222 a realization under the density @xmath223 this is the scope of proposition [ prop approx local cond density ] hereunder .",
    "the size of @xmath220 is such that @xmath224 can be substituted by an integral of @xmath225 with respect to the distribution of @xmath98 conditionally on @xmath226 this is the scope of proposition [ prop p_n equiv g under s_n > na_n ] .",
    "define @xmath227 @xmath228 and @xmath229 through@xmath230@xmath231and@xmath232which are the variance and the kurtosis of @xmath233 reflecting the corresponding characteristics of @xmath4 , since @xmath229 is close to @xmath122 as shown in the following result .",
    "[ lemmaorderoftinetc ] let @xmath218 belong to @xmath234 and assume that ( a ) holds together with ( c2 ) and ( c3 ) .",
    "then under @xmath235 , @xmath229 tends to @xmath122 , @xmath236 tends to @xmath22 and @xmath237 tends to the third centered moment of @xmath4 uniformly upon @xmath238 in @xmath239    write @xmath240which goes to @xmath122 under @xmath102 uniformly upon @xmath218 under ( c2 ) and ( c3 ) where we used lemma [ lemma m_i , n under conditioning ] ; therefore @xmath229 goes to @xmath122 uniformly in @xmath218 which concludes the proof .",
    "the following density @xmath241 defined in ( [ g_s ] ) on @xmath242 provides the sharp approximation of @xmath243 this density is defined on @xmath244 as a product of conditional densities which are set in the following displays .",
    "it only approximates @xmath245 on typical vectors @xmath246 which are realizations of @xmath68 under @xmath169 chose any density @xmath247 ( for convenience denoted @xmath248 in ( g_s).and for @xmath249 define recursively the sequence of conditional densities @xmath250 through @xmath251and @xmath252a density on @xmath6 , with @xmath229 the unique solution of the equation@xmath253where @xmath254 the normalizing factor",
    "@xmath255 is @xmath256define @xmath257 the density on @xmath244 through@xmath258the definition in,([g_i ] ) can also be stated as @xmath259where @xmath260 is the normal density with mean @xmath261 and variance @xmath262 at @xmath86 . here",
    "@xmath263@xmath264and the constant @xmath265 is @xmath266 .",
    "this form is appropriate for the simulation .",
    "the density @xmath250 is a slight modification from @xmath267 .",
    "it approximates sharply p@xmath268 .  for small values of @xmath269 ,",
    "the contribution of @xmath270 and of @xmath271 is small and @xmath250 fits nearly with @xmath272 , when @xmath218 is close to @xmath34 , which is in accordance both with diaconis and freedman s approximation when translated in the moderate deviation range and with ermakov s is scheme .    when the @xmath273 s are i.i.d .",
    "normal then @xmath274 for all @xmath275    we then have    [ prop approx local cond density]set @xmath218 with @xmath276 and assume ( a ) together with ( c2 ) and ( c3 ) .",
    "let @xmath47 be a sample with distribution @xmath277 then uniformly upon @xmath218 @xmath278    the proof uses a bayes formula to write @xmath279 as a product of @xmath186 conditional densities of individual terms of the trajectory evaluated at @xmath214 , and the invariance property stated in lemma [ lemma inv conditional ] .",
    "each term of this product is approximated through an edgeworth expansion which together with the three preceeding lemmas , conclude the proof .",
    "it holds @xmath280by the independence of the r.vs @xmath28 ; we have set @xmath281 by lemma [ lemma inv conditional]@xmath282where we used bayes formula and the independence of the @xmath283 s under @xmath284 a precise evaluation of the dominating terms in this lattest expression is needed in order to handle the product ( [ joint density ] ) .    under the sequence of densities",
    "@xmath285 the i.i.d .",
    "r.vs @xmath286 define a triangular array which satisfies a local central limit theorem , and an edgeworth expansion . under @xmath285 , @xmath287 has expectation @xmath288 and variance @xmath289 center and normalize both the numerator and denominator in the fraction which appears in the last display .",
    "denote @xmath290 the density of the normalized partial sum @xmath291 when the summands are i.i.d . with common density @xmath284 hence",
    ", evaluating both @xmath290 and its normal approximation at point @xmath292 @xmath293the sequence of densities @xmath290 converges pointwise to the standard normal density under the assumptions , when @xmath294 tends to infinity , i.e. when @xmath295 tends to infinity , and an edgeworth expansion to the order 5 is performed for the numerator and the denominator .",
    "set @xmath296 using lemma [ lemmaminunderconditioning ] we have @xmath297it then holds@xmath298   \\label{hermite } \\\\ & & + o_{\\mathfrak{p}_{n}}\\left ( \\frac{1}{\\left ( n - i-1\\right ) ^{3/2}}\\right ) .",
    "\\notag\\end{aligned}\\ ] ] we perform an expansion in @xmath299 up to the order @xmath300 with a first order term @xmath301 namely@xmath302where @xmath303 with @xmath304 only the first order term is relevant when handling the conditional density of the sub trajectory @xmath305    write @xmath306and use lemmas [ lemma m_i , n under conditioning ] and [ lemma max y_i under e_n ] to obtain@xmath307and@xmath308where the @xmath309 terms stem from the convergence of @xmath310 to @xmath22 by lemma [ lemmaorderoftinetc]@xmath45 assuming ( c2 ) it follows that @xmath311and@xmath312which yields @xmath313    the hermite polynomials depend upon the moments of the underlying density @xmath314 since @xmath315 has expectation @xmath122 and variance @xmath22 the terms corresponding to @xmath316  and @xmath317 vanish . up",
    "to the order @xmath318 the polynomials write @xmath319 , @xmath320 .    in order to obtain a development of the polynomial bracket in",
    "( [ hermite ] ) in terms of powers of @xmath321 only the term in @xmath86 from @xmath322 and the constant term from @xmath323 are relevant .",
    "it holds@xmath324when ( c3 ) holds then @xmath325for the term of order @xmath318 it holds @xmath326when ( c2 ) and ( c3 ) hold it follows that @xmath327the fifth term in the expansion plays no role in the asymptotics , under ( a ) . to sum up and using ( a ) and lemma [ lemma max y_i under e_n ] we get@xmath328    turn back to ( [ condtilt ] ) and do the same edgeworth expansion in the demominator , which writes@xmath329summarizing and using both ( [ p3 ] ) and ( [ p4 ] ) we obtain @xmath330    the term @xmath331 in @xmath332 comes from the ratio of the two gaussian densities @xmath299 and @xmath333 taking logarithms and using standard calculus provides the result in ( [ g_i ] ) ; indeed the constant term @xmath334 in ( [ p4 ] ) combines with the corresponding one in ( [ pi 0 ] ) to produce a term of order @xmath335 whose sum is @xmath336 .",
    "we now prove that @xmath337 as defined in ( [ k_i ] ) satisfies @xmath338 this will conclude the proof .",
    "use the classical bounds @xmath339to obtain on both sides of the above inequalities the second order approximation of @xmath340 the upper bound is @xmath341 .\\end{aligned}\\]]the lower bound is the same up to order 2 and the third order term plays no role .    use lemma [ lemmaorderoftinetc ] to conclude , making a taylor expansion in @xmath342 @xmath343 and @xmath344 the dominating terms are due to @xmath345 and @xmath346 which yield the @xmath347 term in ( [ kiapproximation ] ) .",
    "the other terms are indeed @xmath348 using lemma [ lemmaminunderconditioning ] , leading to ( [ kiapproximation ] ) . hence ( [ ratiofixed i ] ) writes as @xmath349 putting the pieces together yields under ( a ) @xmath350uniformity upon @xmath218 is a consequence of lemma [ lemmaorderoftinetc ] .",
    "this closes the proof of the proposition .    when the @xmath273 s are i.i.d .",
    "normal , then the result in the above proposition holds with @xmath351 stating that @xmath352 for all @xmath353 in @xmath195 .",
    "the density in ( [ g_i ] ) is a slight modification of @xmath284 however second order terms are required here in order to handle the approximation of the density of @xmath354conditioned upon @xmath355 and @xmath356 the modification from @xmath357 to @xmath358 is a small shift in the location parameter , which reflects the asymmetry of the underlying distribution @xmath359 and a change in the variance : large values of @xmath360 have smaller weight for large @xmath361 which is to say that the distribution of @xmath360 tends to concentrate around @xmath288 as @xmath269 approaches @xmath155    the `` moderate deviation '' case is typically @xmath362 for @xmath363 in @xmath364 in this case the condition @xmath365 holds for all values of @xmath366 the other case is when @xmath34 is `` nearly constant '' , in the range @xmath367,@xmath368 decreasing very slowly to @xmath369 with @xmath370    [ remark edgeworth array]in lemmas [ lemma m_i , n under conditioning ] and [ lemma max x_i under conditioning ] , as in the previous proposition , we use an edgeworth expansion for the density of the normalized sum of the @xmath371th row of some triangular array of row - wise independent r.vs with common density . consider the i.i.d . r.vs @xmath175 with common density @xmath372 where @xmath218 may depend on @xmath65 but remains bounded@xmath45 the edgeworth expansion pertaining to @xmath373 can be derived following closely the proof given for example in @xcite , pp 532 and followings substituting the cumulants of @xmath4 by those of @xmath374 .",
    "denote @xmath375 the characteristic function of @xmath376 clearly for any @xmath377 there exists @xmath378 such that @xmath379 @xmath380 and since @xmath34 is bounded , @xmath381 therefore the inequality ( 2.5 ) in @xcite p533 holds . with @xmath382 defined as in feller1971 ( 2.6 )",
    "holds with @xmath383 replaced by @xmath384 and @xmath218 by @xmath385 ( 2.9 ) holds , which completes the proof of the edgeworth expansion in the simple case .",
    "the proof goes in the same way for higher order expansions .",
    "this justifies our argument in the lemmas cited above . in the proofs of proposition [ prop approx local cond density ] we made use of such expansions when the r.vs @xmath386 are i.i.d . with common density",
    "@xmath387the same argument as sketched hereabove applies in this case also .",
    "let @xmath388 @xmath389 with distribution under the conditioning event @xmath169 hence for any borel set @xmath5 @xmath390the distribution of @xmath391 is concentrated on a small neighborhood of @xmath392 indeed we have    [ lemma magnitude of t ] assume that ( a1 ) holds@xmath45 for any sequence @xmath393 such that ( c1 ) holds@xmath394@xmath395    use lemma [ lemma jensen ]",
    ".    moreover @xmath391 is asymptotically exponentially distributed .",
    "the asymptotic distribution of @xmath391 is captured in the following    [ lemma approx exponential for tbold]when ( a1 ) holds then for all @xmath180 in @xmath396 the r.v .",
    "@xmath397 satisfies@xmath398where @xmath399 and therefore @xmath400    write @xmath401and use lemmas [ lemma richter local]and [ lemma jensen ]",
    ". a first order expansion yields @xmath402 which proves the claim .    in this section proposition [ prop approx local cond density ] is extended in order to provide an approximation of @xmath403 when @xmath404 is a random vector generated under @xmath223 this is obtained through an integration w.r.t .",
    "@xmath218 in ( [ local approx under exact value ] ) ; indeed it holds    @xmath405    and the domain of integration can be reduced to a small neighborhood of @xmath406 which contains nearly all the realizations of @xmath391 under @xmath407 .",
    "this argument allows the interchange of asymptotic equivalents and integration .",
    "define @xmath408where @xmath409 is defined in ( [ g_s ] ) .",
    "when @xmath257 is substituted by @xmath197 then @xmath410does not stand .",
    "let @xmath411  where @xmath412 is fitted compatibly with proposition [ prop approx local cond density ] .",
    "define @xmath413    [ prop p_n equiv g under s_n > na_n ] when @xmath214 is a random vector generated with density @xmath104 and @xmath121(a ) and ( c ) hold then @xmath414    the proof of proposition [ prop p_n equiv g under s_n > na_n ] relies upon the following lemma , whose proof is postponed to the appendix .",
    "[ lemma from local cond to global cond ] let @xmath415 satisfy @xmath416 and ( a ) and ( c ) hold then when @xmath47 is generated under @xmath104 it holds@xmath417    we now prove proposition [ prop p_n equiv g under s_n > na_n ] through an integration of the local approximation given in proposition [ prop approx local cond density ] .    for all @xmath218 in @xmath234@xmath418uniformly on @xmath218",
    "when @xmath47 is sampled under @xmath223 it then holds @xmath419where we used lemmas [ lemma from local cond to global cond ] together with ( c4 ) which helps to keep the @xmath420 term .",
    "this concludes the proof of proposition [ prop p_n equiv g under s_n > na_n ] .    as a consequence of lemma [ lemmafrompntogn ] the following result holds , which asseses that when sampled under @xmath421 @xmath121the likelihood of the random vector @xmath422 approximates @xmath423    [ prop global approx inverse ] assume ( a ) and ( c ) .",
    "let @xmath422 be a random vector with p.m.  @xmath424 with density @xmath421 on @xmath244 defined in ( [ g global ] ) .",
    "it holds @xmath425as @xmath426",
    "the last result in proposition [ prop global approx inverse ] above suggests that an importance sampling density deduced from @xmath421 would benefit from some optimality as defined in the introduction since it fits with the conditional density on long runs .",
    "it is enough to approximate the conditional distribution of @xmath427 under @xmath407 by lemma [ lemma approx exponential for tbold ] and to plug in this approximation in ( [ g global ] ) .",
    "let @xmath428 denote a r.v .",
    "with exponential distribution with parameter @xmath429 on @xmath430@xmath431    using again lemmas [ lemma richter local ] and [ lemma jensen ] it is easily checked that @xmath432for some sequence @xmath433 whinch tends to @xmath369 from which @xmath434with @xmath435 , which proves that we may substitute @xmath391 by the exponential r.v . @xmath428 while keeping the properties of the is procedure .",
    "we denote @xmath436the sampling scheme under which the estimate ( [ form is ] ) is computed ; in ( [ new sampling ] ) the value of @xmath437 is defined through@xmath438with @xmath439      since the r.v .",
    "@xmath428 is highly concentrated in a small neighborhood of @xmath34 we suggest to forget about @xmath440 in the definition ( [ new sampling ] ) of @xmath441 above and to integrate on @xmath442 instead of @xmath239 numerical experiments argue in favor of this heuristic .",
    "the remarks at the end of this paragraph provide simple and efficient solutions for the effective calculation of the estimate .",
    "1-  draw @xmath443 independent random variables @xmath444 with distribution ( [ densityt ] ) and define the density on @xmath195@xmath445where @xmath446 is defined as @xmath447where @xmath448 is defined in ( [ g_i ] ) for @xmath449 , @xmath450 and @xmath451where @xmath452 and @xmath453 @xmath121is the only solution of the equation @xmath454  with @xmath455 with @xmath456    2-define @xmath21 which is the number of replications of the simulated random trajectory to be performed    3-for @xmath457 between @xmath22 and @xmath21 do    \\ {    draw a random variable @xmath458 with distribution ( densityt )    draw the first @xmath186 variables @xmath459 recursively with density @xmath460 as defined in ( [ g_t ] ) with @xmath461 substituted by @xmath458 .",
    "draw the @xmath462 random variables @xmath463 independently with common density @xmath464 defined in ( pi^alpha_k ) with @xmath461 substituted by @xmath465    }    4- define    @xmath466    where @xmath467      a number of remarks hereunder show that atis is not difficult to implement . since the first order efficiency of i.i.d sample schemes is reached",
    "if and only if the sampling distribution is the twisted one with parameter @xmath34 ( see @xcite ) , the present algorithm should be compared with it .",
    "the classical is scheme which uses i.i.d .",
    "replicates with density @xmath468 is easy to implement but may lead to biased estimates of @xmath49 ; the simulation of a r.v . with density",
    "@xmath153 is difficult in non standard cases when @xmath4 is easy to simulate then an acceptance / rejection algorithm can be used ; however this requires to truncate the support of @xmath4 , what should precisely be avoided in order to obtain unbiaised estimates ; see @xcite .",
    "when @xmath153 is easy to simulate , atis may take more time to run , due to the various intermediate calculations which are required at each stage of the algorithm .    the generation of the r.v .",
    "@xmath459 above is easy and fast and does not require any simulation according to a twisted density .",
    "it holds @xmath469where @xmath260 is the normal density with mean @xmath261 and variance @xmath262 at @xmath86 . here",
    "@xmath263@xmath470a r.v .",
    "@xmath471 with density @xmath472 with @xmath473 and where @xmath4 is a given density and @xmath474 is easy to simulate : denote @xmath475 the c.d.f . with density @xmath476",
    "it is easily checked that @xmath477 is the density of the r.v .",
    "@xmath478 where @xmath479 is a r.v .  on @xmath480 $ ] with density @xmath481 denotes the reciprocal function of @xmath475 @xmath45 now an acceptance / rejection algorithm provides a realisation of @xmath479 .",
    "indeed let @xmath482 be a density such that @xmath483 for some constant @xmath484 and all @xmath86 in @xmath480 $ ] ; let @xmath485 be uniformly distributed on the hypograph of @xmath486 namely @xmath487 where @xmath488 has density @xmath115 and @xmath489 is uniform @xmath480 $ ] independent of @xmath490 when @xmath491 is less than @xmath492 then @xmath488 has density @xmath493    the calculation of @xmath494 above requires the value of @xmath495 in ( [ g_i+1(x_i+1/x_i)numerically ] ) .",
    "a monte carlo technique can be used : simulate @xmath496 i.i.d .",
    "r.vs @xmath497 with density @xmath498 , which is fast , and substitute @xmath265 by @xmath499 , which provides a very accurate approximation to be inserted in the calculation of the estimate .",
    "it may seem that this algorithm requires to solve @xmath500 equations of the form @xmath501 in order to obtain the @xmath229 which are necessary to perform the simulation of @xmath502 as described above as well as the calculation of @xmath503 .",
    "such is is not the case , and only @xmath21 equations have to be solved .",
    "consider for example the simulation of @xmath459 with density @xmath504 this is achieved as follows :    1- solve the equation @xmath505whose solution is @xmath506 generate @xmath507 according to @xmath508    2- since @xmath509use a first order approximation to derive@xmath510from which ( [ g_i+1(x_i+1/x_i)numerically ] ) is derived and @xmath511 can be simulated as mentioned above .  in the moderate deviation",
    "scale the function @xmath512 does not vary from @xmath22 and the above approximation is fair .",
    "the density @xmath513 on @xmath195 is a monte carlo approximation of @xmath197 defined by@xmath514where @xmath515 is replaced by @xmath516 and the integral is replaced by a finite mixture .",
    "@xmath443 is a free parameter .",
    "also notice that the @xmath462 i.i.d .",
    "r.vs have common tilted density @xmath464 with parameter given by ( [ start remaining tilted n - k rv s ] ) , thus identical to ermakov s sampling scheme with end point in@xmath517 and not in @xmath518        the critical parameter @xmath186 is the length of the partial sum run which is to be simulated according to the density @xmath519 as defined in ( [ g(x_1^k ) ] ) . by",
    "( [ g(x_1^k ) ] ) it would be enough to establish some statistics averaging the estimate ratios @xmath520 on a set of runs , and to select @xmath521 as some @xmath522 ensuring that this ratio keeps close to @xmath217 in the case when the r.vs @xmath273 are normally distributed the density @xmath523 as defined in ( [ g_i ] ) coincides with @xmath524 for all value of @xmath269 between @xmath22 and @xmath525 which entails that @xmath186 can be set equal to @xmath526 this very peculiar case is illustrated in figure 1 , for @xmath527 and @xmath49 is close to @xmath528 .",
    "we can see that atis  produces a very sharp estimate of @xmath49 for a small value of @xmath21 when compared to the classical is scheme .    in the other cases , when @xmath250 approximates @xmath524 only under some conditions on @xmath186 as described in conditions ( a ) , we propose the following heuristics , which works well and is easy to implement ; other choices are possible , which provide similar acceptable results . instead of",
    "@xmath441 consider the following construction , which will also be used in the is algorithm : simulate @xmath444 , i.i.d . with distribution ( [ densityt ] ) and define the density on @xmath529@xmath530where @xmath446 is defined as @xmath531where @xmath448 is defined in ( [ g_i ] ) for @xmath449 .",
    "the density @xmath532 is a monte carlo approximation of @xmath533 .    by ( [ p_n fraktur ] ) and following the same heuristics as for @xmath534",
    "define , with a new set of i.i.d .",
    "@xmath461 s @xmath535we use lemma [ lemma richter local ] in order to obtain an explicit approximation for @xmath536 it holds @xmath537define therefore @xmath538and @xmath539fix some integer @xmath21 which is the number of runs to be simulated in order to fix @xmath540 @xmath21 need not be large . for all @xmath457 between @xmath122 and @xmath21 draw independently a random variable @xmath541 with density ( [ densityt ] ) and the run @xmath542 with density @xmath543 defined as in ( [ g_s ] ) with @xmath186 substituted by @xmath522 and @xmath218 by @xmath544 @xmath545fix @xmath186 as the smallest @xmath522 which indicates a departure of this statistics from @xmath217      in atis  the distribution in ( [ g(x_1^k ) ] ) is substituted by a numerical approximation of @xmath546which is suboptimal with respect to ( [ g(x_1^k ) ] ) but is easily implemented .",
    "a monte carlo procedure produces @xmath547 as described above in ( [ gbar ] ) .",
    "it appears that @xmath443 should be large when @xmath186 is large .",
    "for example in the normal case with @xmath527 for @xmath548 , then @xmath549 produces excellent estimates for values of @xmath21 of order @xmath550 whereas for @xmath551 the value of @xmath443 should increase up to @xmath552 with the same @xmath21 .as seen in figure2@xmath45 the reason for this increase in @xmath443 is that ( [ gintegrale ] ) is a mixture of densities in very high dimension ,  which seems very sensitive with respect to the approximation of the mixture measure .",
    "this point should deserve a specific study , out of the scope of the present paper .  however the normal case is quite specific , since it allows @xmath186 to be as close to @xmath65 as wanted . in the other cases ,",
    "as examplified in the figures pertaining to the exponential case , @xmath186 is resticted to lower values and @xmath443 is rather low .",
    "the evaluation of the performances of is algorithm is a controversal argument .",
    "many criterions are at hand , for example the _ probability of hits _ which counts the relative number of simulations hitting the target @xmath553  or the _ variance _ of the estimator .",
    "we refer to the book by bucklew @xcite for a discussion on the relative merits of each approach .",
    "the variance of an is estimate of @xmath49 under the sampling density @xmath14 writes@xmath554with @xmath555    the situation which we face with our proposal lacks the possibility to provide an order of magnitude of the variance our our is estimate , since the properties necessary to define it have been obtained only on _ typical paths _ under the sampling density @xmath441  defined in ( [ new sampling ] ) and not on the whole space @xmath195 ( but in the case when the @xmath273 s are normally distributed)@xmath45 we will prove , however , that the performance of this new procedure can be considered favorably .",
    "not surprisingly the loss of performance with respect to the optimal sampling density @xmath556 is due to the @xmath462 last i.i.d .",
    "simulations , leading a quasi- mse of the estimate proportional to @xmath557    in order to discuss this we first go back to the classical is scheme , for which we evaluate the asymptotic variance .",
    "the asymptotic variance of the estimate of @xmath558 can be evaluated as follows .",
    "the classical is is defined simulating @xmath21 times a random sample of @xmath65 i.i.d .",
    "r.vs @xmath559 , @xmath560 with tilted density @xmath468 .",
    "the standard is estimate is defined through@xmath561where the @xmath562 are i.i.d . with density @xmath153 and @xmath563 is as in ( [ indics_n /",
    "n > a_n])@xmath45 set @xmath564the variance of @xmath565 is given by @xmath566the _ relative accuracy _ of the estimate @xmath567 is defined through @xmath568it holds    [ prop rel efficiency standard is]the relative accuracy of the estimate @xmath567 is given by @xmath569    it holds , omitting the index @xmath457 for brevity and noting @xmath179 for @xmath34 @xmath570the laplace integral above satisfies@xmath571as @xmath65 tends to infinity , which , together with the expansion @xmath572(which holds when @xmath573 @xmath574 ) concludes the proof .",
    "we have used lemma [ lemmaorderoftinetc ] to assess that @xmath575    we now come to a discussion of the above result .",
    "it is well known that the variance is not a satisfactory criterion to describe the variability of the outcomes of a random phenomenon : for example , a sequence of symmetric r.vs @xmath576 taking values @xmath577 with relative frequencies defined through @xmath578 has variance going to @xmath579 while being concentrated at @xmath580 in this case we can define an increasing family of sets @xmath581 with @xmath582 on which @xmath583 a much better indicator , obtained through trimming .",
    "we will prove that such an indicator can not be defined for the classical is scheme , stating therefore that the variance rate obtained in proposition prop rel efficiency standard is is indeed meaningfull .",
    "the easy case when @xmath175 are i.i.d . with standard normal distribution",
    "is sufficient for our need .",
    "the variance of the is estimate is proportional to @xmath584a set @xmath581 resulting as reducing the mse should penalize large values of @xmath585 while bearing nearly all the realizations of @xmath586 under the i.i.d .",
    "sampling scheme @xmath153 as @xmath65 tends to infinity",
    ". it should therefore be of the form @xmath587 for some @xmath440 so that    \\(a ) @xmath588and    ( b)@xmath589which means that the is  sampling density @xmath153 can lead a mse defined by @xmath590with a clear gain over the variance indicator .",
    "however when @xmath591 ( b ) does not hold and when @xmath592 ( a ) does not hold .",
    "so no reduction of this variance can be obtained by taking into account the properties of the _ typical paths _ generated under the sampling density : a reduction of the variance is possible only by conditioning on `` small '' subsets of the sample paths space . on no classes of subsets of @xmath593 with probability going to @xmath22 under the sampling",
    "is it possible to reduce the variability of the estimate , whose rate is definitely proportional to @xmath594 imposing a burden of order @xmath595 in order to achieve a relative efficiency of @xmath596 with respect to @xmath597      we will evaluate the performance of our estimate under @xmath441 since the algorithm envolves technical parameters ( typically @xmath443 ) ; in practice the monte carlo approximation introduces no significant bias .    at the contrary to just evidenced hereabove , the procedure which we propose has a small asymptotic variability",
    "when evaluated through trimming on classes of subsets of @xmath195 whose probability goes to @xmath22 under the sampling @xmath441 .",
    "these subsets of @xmath195 get smaller and smaller as @xmath65 increases as measured through the mse of the estimate with respect to the mse of the classical is estimate .",
    "we prove the existence of these trimming sets in the present section and state that the resulting gain in terms of the mse of our estimate is the proper measure of its performance .",
    "these sets are the @xmath598 described in the following lemma , whose proof is differed to the appendix . for sake of notational simplicity",
    "denote @xmath205 the @xmath599 defined in ( [ g(x_1^k ) ] ) .",
    "[ lemma set c_n for efficiency ] with the just mentioned @xmath600 define the family of sets @xmath598 in @xmath195 such that for all @xmath601 in @xmath602@xmath603and @xmath604where @xmath453  is defined through@xmath605and @xmath606 satisfies @xmath607together with@xmath608then @xmath609furthermore on @xmath598@xmath610    we now prove that our is algorithm provides a net improvement over the classical is scheme in terms of mean square error when evaluated on this family of sets .",
    "define@xmath611@xmath612we prove that    [ prop rel efficiency is]the relative accuracy of the estimate @xmath613 is given by @xmath614    denote @xmath615 the expectation with respect to the p.m. @xmath616 of @xmath40 conditioned upon @xmath617 ; we omit the index @xmath457 for brevity . using the definition of @xmath598 we get@xmath618the second line uses @xmath619 the third line is bayes formula .",
    "the fourth line is lemma [ lemma jensen ] .",
    "the fifth line uses ( [ order of t_k ] ) and uniformity in lemma [ lemma jensen ] , where the conditions in corollary 6.1.4  of jensen ( 1995 ) are easily checked since , in his notation , @xmath620 , condition ( i ) holds for @xmath621 in a neighborhood of @xmath122 ( @xmath622 undeed is resticted to such a set in our case ) , ( ii ) clearly holds and ( iii ) is ( [ f.c .",
    "edgeworth ] ) .",
    "[ prop rel efficiency]when @xmath623 then under ( a ) the ratio of the relative efficiencies of the adaptive is algorithm with respect to the standard is scheme is of order @xmath67 .. the same result holds when @xmath624",
    "this section provides some application of the previous results for some classical types of estimators for which sharp moderate deviation probabilities can be obtained through linear approximations .",
    "we follow closely the work by @xcite ; see also @xcite .",
    "let @xmath625 denote a real valued statistical functional defined on the space @xmath626 , where we assume that @xmath625 has an influence function .",
    "let @xmath3 be a given p.m.  we assume that for all  @xmath116 in @xmath111 there exists a function @xmath627 ( depending on @xmath3 ) such that @xmath628    where @xmath496 is a seminorm defined on @xmath111 , continuous in the @xmath112 topology , and @xmath629 is a continuous and strictly monotone function which satisfies @xmath630 as @xmath631    the function @xmath14 is the _ influence function _ of @xmath625  at @xmath632 the class @xmath108 considered here contains @xmath633    let @xmath634 be real valued function defined on @xmath635 and assume that @xmath3 satisfies @xmath636 define @xmath637 as any solution of the equation @xmath638if defined .",
    "when @xmath639 depends upon a real valued parameter @xmath640 such that @xmath641then @xmath625 is _ fisher consistent _ and the substitution of @xmath642 by @xmath643 in ( [ m estim])@xmath394 the empirical measure pertaining to an i.i.d .",
    "sample with unknown p.m. @xmath644 provides a consistent estimate of @xmath645 under appropriate regularity conditions ; see @xcite .",
    "such estimate is an m - estimator .",
    "we assume that all conditions m1 to m5 in @xcite hold , which implies that ( [ diff t ] ) above holds ( see @xcite theorem 4.2 ) .",
    "also in this case the function @xmath14 writes@xmath646the same situation holds for l - estimators ,    when ( [ sanov mdp ] ) holds in @xmath111 it can be checked that a strong mdp holds for @xmath647 indeed when @xmath14 belongs to the class @xmath108 and @xmath648 = -\\infty\\]]then using ( [ diff t ] ) and ( [ sanov mdp ] ) it can be proved that the remaining term in @xmath649 is negligible w.r.t .",
    "the linear approximation @xmath650 on the moderate deviation scale , as follows from ( 2.14 ) and ( 2.15 ) in @xcite . furthermore in this case the strong moderate deviation holds for @xmath651 and @xmath652 in the range @xmath653 see also inglot , kallenberg and ledwina @xcite .",
    "+    this graph illustrates proposition [ prop approx local cond density ] .",
    "+    the graph shows the role of @xmath186 in the behavior of the estimate .",
    "the @xmath273 s are standard normal , @xmath654 and @xmath655 when @xmath186 is less than @xmath656 the new estimate improves on the classical i.i.d .",
    "a change in @xmath657 leads no significant change ( here @xmath549 ) .",
    "the value of @xmath21 is @xmath658       +    the graph illustrates the accuracy of the asymptotic results in propositions [ prop rel efficiency standard is ] and [ prop rel efficiency is ] .",
    "the @xmath659 s are standard normal , @xmath527p@xmath660      the graph is an illustration of proposition [ prop rel efficiency ] .",
    "the r.vs @xmath273 s are standard normal , @xmath654 and @xmath655 in ordinate is the ratio of the empirical value of the mse  of the adaptive estimate w.r.t .",
    "the empirical mse of the i.i.d .",
    "twisted one .",
    "the value of @xmath186 is @xmath661 this ratio stabilizes to @xmath67 for large @xmath662 in full accordance with proposition [ prop rel efficiency ] .",
    "+         +    the graphs above are typical paths under the conditional distribution ( with @xmath663 ) and under the i.i.d . sampling with tilted density .",
    "the value of @xmath65 is @xmath664 and the approximation of the conditional density of the random walk is fair up to @xmath665 , as indicated by the fact that the is estimator of @xmath49 is correct up to @xmath665 , which can be seen as a pertinent indicator .",
    "+    the random variables @xmath666 are i.i.d . with exponential distribution with parameter @xmath22 on @xmath667",
    "the case treated here is @xmath668 with @xmath527 @xmath669 and @xmath670 these values are computed through a very long run of the standard is algorithm ( with i.i.d . sampling according to the twisted ) and",
    "are used as a benchmark.the estimates are calculated with @xmath671 and @xmath672 for @xmath673 , i.e. for the classical i.i.d . twisted sampler ( lower values of @xmath21",
    "lead unstable estimates )",
    "by theorem 3.4 ( 2 ) in broniatowski and keziou ( 2006 ) it holds @xmath678 for some constants @xmath82 and @xmath679 the projection @xmath680 satisfies both @xmath681  and @xmath682 which yield @xmath683 and @xmath684        observe that @xmath688 also denote @xmath689 ( resp @xmath690 ) the subset of @xmath691 defined through @xmath692 , resp @xmath693 using bayes formula and the above moderate deviation result ( [ sanov mdp ] ) it follows that for any measurable set @xmath694 in @xmath143      for any positive ( resp",
    ". negative ) @xmath640 it then holds @xmath696 if @xmath697 and @xmath698 ( resp @xmath699 if @xmath700 and @xmath701 ) , which is to say , going to the limit in @xmath702 that @xmath703 where @xmath704 is the lebesgue decomposition of @xmath705 this closes the proof of ( [ gibbs mdp ] ) . a second order expansion of @xmath706 in a neighborhood of @xmath707 yields@xmath708hence for all borel set @xmath5 it holds @xmath709 since both @xmath710 tends to @xmath10 and @xmath711 is a finite measure it follows that @xmath712 tends to @xmath580",
    "select @xmath181 in @xmath234 and denote @xmath715 the p.m on @xmath202 conditioned on @xmath716 it holds@xmath717we prove that for @xmath718 @xmath719as @xmath720 where @xmath721 denotes the variance of @xmath53 conditionally on @xmath722 integrating with respect to the distribution of @xmath98 conditioned upon @xmath103 concludes the proof@xmath45 using      with @xmath724 , normalizing both @xmath725 and @xmath726 and making use of a first order edgeworth expansion in those expressions yields @xmath727and @xmath728with a similar development for the joint density @xmath729 , using the same tilted distribution @xmath730 it readily follows that @xmath731since @xmath732it follows that when @xmath733 tends to @xmath122 , then @xmath734 since @xmath735 this amounts to @xmath736integration with respect to the distribution of @xmath98 conditioned upon @xmath103 and splitting the integeral on @xmath737 and @xmath738 , using ( c2 ) concludes the proof .",
    "it can be proved that @xmath739conditionally on @xmath740 this result is to be compared with the gibbs principle for moderate deviations stated in the introduction which assets that for _ fixed _ @xmath741 the joint distribution of @xmath742 conditioned upon @xmath407 converges weakly , as @xmath743 , to the joint distribution of @xmath741 r.vs @xmath744 which are independent copies of @xmath745 .the above result says that even for sequences depending upon @xmath65 , we may replace the original @xmath741 variables by the @xmath741 _ independent _ tilted ones when exploring the behavior of @xmath746 under @xmath58 since @xmath747 shares the same limit distribution .",
    "let @xmath181 such that @xmath750 @xmath751 .",
    "denote @xmath715 the probability measure of @xmath57 given the the value of @xmath752 since @xmath753we first state the order of magnitude of @xmath748 under @xmath715 in the next lemma .",
    "define @xmath755 for all @xmath640 it holds@xmath756center and normalize both @xmath98 and @xmath757with respect to the density @xmath758 in the last line above , denoting @xmath759 the density of @xmath760 when @xmath761 has density @xmath758 with mean @xmath363 and variance @xmath762 we get @xmath763under the sequence of densities @xmath758 the triangular array @xmath764 obeys a first order edgeworth expansion @xmath765for some constant @xmath766 independent of @xmath65 and @xmath363 and where @xmath767where @xmath768 is the third hermite polynomial ; @xmath769 and @xmath770 are the second and third centered moments of @xmath771 we used uniformity upon @xmath180 in the remaining term of the edgeworth expansions .",
    "let @xmath772 such that @xmath773 making use of chernoff inequality@xmath774for any @xmath675 such that @xmath775 is finite .",
    "@xmath776it holds @xmath777which proves the lemma .      as above",
    "write @xmath778where @xmath363 is defined as in the above lemma through @xmath755 use the same argument as in lemma [ lemma max x_i under conditioning ] to assess that when @xmath779 goes to infinity then the.rhs above tends to @xmath580 this closes the proof .",
    "it holds@xmath780by lemma [ lemma approx exponential for tbold ] it holds under ( c1 )",
    "@xmath781where @xmath782 denote @xmath783 @xmath45 set @xmath784with @xmath785 and @xmath786 it holds@xmath787use lemma [ lemma m_i , n under conditioning ] to obtain@xmath788where @xmath789 use lemma lemma jensen to obtain @xmath790which tends to @xmath122 under ( c ) .        in the above display , @xmath792 by the above definition @xmath793note",
    "also that @xmath794which goes to @xmath22 as @xmath65 tends to @xmath795 where we have used proposition [ prop p_n equiv g under s_n > na_n ] . in the above displays @xmath796 is the density of @xmath422 when @xmath797 is sampled under @xmath798 we have just proved that the sequence of sets @xmath799 contains roughly all the sample paths @xmath797 under the importance sampling density @xmath798            there exists @xmath806 such that for any @xmath601 in @xmath581 @xmath807indeed @xmath808and @xmath809 therefore@xmath810since @xmath811 is bounded so is @xmath812 and therefore @xmath813 as @xmath814 which implies ( [ control t_k / a_n ] ) ."
  ],
  "abstract_text": [
    "<S> this paper introduces a new importance sampling scheme , called adaptive twisted importance sampling , which is adequate for the improved estimation of rare event probabilities in he range of moderate deviations pertaining to the empirical mean of real i.i.d . </S>",
    "<S> summands . </S>",
    "<S> it is based on a sharp approximation of the density of long runs extracted from a random walk conditioned on its end value . </S>"
  ]
}