{
  "article_text": [
    "in the past 2 years ever better results have been achieved concerning what in principle can be done with the help of quantum error correcting codes . for a very readable review",
    "see e.g. @xcite ( @xcite by the same author is more generally about quantum computers ) .",
    "in particular it has been show @xcite that once elementary unitary operations ( `` gates '' ) in a quantum computer can be carried out with more than some threshold accuracy and also decoherence on resting qubits is sufficiently low , then it is possible to carry out arbitrary precision operations on suitably encoded `` computational '' qubits . from this",
    "it follows that one can then carry out computations with any number of steps without errors accumulating too much . in this paper",
    "i will take a more practical , engineer - like point of view .",
    "i will follow p.shor @xcite for fault tolerant error correction ( ftec ) and the fault tolerant implementation of elementary operations on states encoded by the 7-bit code .",
    "i consider only non - systematic stochastic gate errors and assume that gates can be applied to any two ( or three ) qubits of the quantum computer .",
    "also i will use ( and try to justify ) the most simple and natural error model . with these assumption",
    ", computer simulation of an optimized version of shors techniques indicates an ( astonishingly high ) threshold of the order @xmath0 on the tolerable error probability per gate .",
    "i will give arguments why the threshold can actually be expected to be even better ( = higher ) than that .",
    "for comparison i also provide a very rough calculation by hand .",
    "the simulation i actually make to get the mentioned result is very simple .",
    "i consider only one level of encoding and try to find the error rate below which the encoding starts to pay off .",
    "also i look only at one encoded qubit to which 1-qubit operations are applied .",
    "i would like to sketch a justification for the simple error model i use .",
    "the model is as follows : first of all i assume that errors happen with a certain probability ( per gate ) .",
    "i also assume that these probabilities are independent for different qubits , except when an operation acts on several ( 2 to 3 ) qubits at once ( like an xor ) . for 1-bit errors",
    "i assume that the three possible errors ( bit - flip , phase - flip and combined bit and phase - flip ) occur all with probability @xmath2 ( depolarizing channel ) .",
    "this is very natural as it is equivalent to the admixture of the unit density matrix to the original pure state .",
    "the analogous assumption will be made for several qubits taking part in an operation .",
    "thus the 15 different errors of the two qubits which took part in an xor are equally probable .",
    "the size is chosen such , that when we look only at one of the two qubits , we get the same probabilities as for a 1-qubit error .",
    "actually one sees that the quantity @xmath3 would be more natural than the usual @xmath4 . for simplicity",
    "i also assume that the error probability is the same for all operations and that such errors are the only ones occurring .",
    "thus i e.g. do nt consider decoherence on `` resting '' qubits .",
    "the motivation for only considering gate errors is as follows : it is imaginable that the decoherence on resting qubits can be made very small . on the other hand gates , in some sense",
    "being analog , will always have some error in their continuous parameters .",
    "such parameters are e.g. given by the intensity and time of a laser beam shining at an ion in an ion trap quantum computer .",
    "also , the interaction with exterior fields during the gate will cause additional decoherence .",
    "it would actually be easy to adapt my computer program to the case where decoherence on resting qubits is important .",
    "but then the result will depend on the degree of parallelism with which the quantum computation can be carried out and this in turn depends on the physical realisation of the qc .",
    "e.g. in an ion trap qc with just one center of mass motion bus - qubit , hardly any parallelism is possible .",
    "if different phonon modes could be used , some parallelism would be possible .",
    "nevertheless i have added a small paragraph roughly estimating the threshold for memory errors under a reasonable , if somewhat arbitrary , assumption on parallelism .    for * decoherence * a probabilistic error model immediately seems reasonable , as a mixed state ( which decoherence produces ) can be viewed as an ensemble of pure states together with their probabilities of occurrence . for this to be possible , the ensemble of states , taken as a basis , must diagonalize the density matrix . for depolarizing channel type of decoherence ( which we assume here )",
    "this is true for any orthogonal set of states which includes the undisturbed original state .    a second source of errors are * gate inaccuracies * ( unitary errors ) , thus deviations of the parameters of the unitary operation from the desired value .",
    "let s imagine a whole ensemble of qcs carrying out the same operation on the same state and assume that the unitary errors in different qcs are independent and have average 0 ( = statistical errors , as opposed to systematic ones ) .",
    "provided we know nothing about the actual errors in the individual qcs , the resulting ensemble of states can at best be described by a density matrix . for the appropriate natural assumption on the distribution of the unitary errors ,",
    "this leads to the depolarizing channel error model .",
    "the `` natural '' assumption is obviously that the error probability is `` isotropic '' , thus , loosely speaking , that it is the same for any three ( for su(2 ) ) orthonormal parameters .",
    "quite another problem are * systematic unitary errors * ( which we neglect here ) , e.g. when a rotation on a qubit tends to overrotate in all qcs .",
    "such errors could e.g. be diminished by some feedback mechanism which would correct gates after several preliminary test runs .",
    "also it can be expected that such errors would to some degree average each other out in some given quantum computation , contrary to the simple accumulation that would take place if we simply applied a gate a number of times to the same qubit . in this later case",
    "the effective error rate would roughly equal the amplitude error instead of its square , as for non - systematic errors .",
    "the codes used by shor are of the type described by calderbank and shor @xcite and steane @xcite , where a quantum code is constructed from two ( classical ) binary linear codes @xmath5 and @xmath6 with @xmath7 . for shors code we have @xmath8 and @xmath9 , thus @xmath10 and also @xmath11 , thus these codes encode 1 qubit . such a code can be obtained from a self dual ( @xmath12 ) reed - muller code by leaving away one of the @xmath13 bits . for the threshold",
    "the smallest such code that still can correct for 1 error is relevant .",
    "this is the 7-bit code given by the following 4 basis elements : +   + 1011100 + 1101010 + 1110001 + 0100011 +   + the dual code @xmath14 is given by the first 3 of these elements , thus @xmath15 , and the length @xmath16 . in the so called `` s - basis '' the quantum codewords are @xmath17 actually there are only 2 different codewords , and they will represent an encoded 0 resp . 1 : @xmath18 and @xmath19 where @xmath20 stands for `` logical '' which means the same as `` computational '' .",
    "by applying a hadamard transformation to each of the 7 qubits we go to the `` c - basis '' .",
    "one can show that : @xmath21    thus @xmath22 , like @xmath23 , is a linear combination of codewords out of @xmath24 .      in the theory of classical linear codes the syndrom of a received ( and possibly distorted ) codeword",
    "is obtained by scalar multiplication with 3 basis elements of @xmath14 .",
    "clearly when all 3 syndrom bits are 0 then there is no error in the codeword .",
    "the other 7 possibilities each correspond to a particular one of the 7 bits having flipped .",
    "thus knowledge of the syndrom allows to restore the original codeword ( provided there is at most 1 error ) . for quantum error correction",
    "it is crucial that one can measure the syndrom without measuring the encoded qubit .",
    "encoded qubits @xmath25 are in either basis linear combinations of basis states @xmath26 with @xmath27 . a bit - flip in one qubit",
    "will cause the same syndrom in all @xmath26 s , thus measuring the syndrom will not collapse the encoded qubit .",
    "phase - flips do nt affect the syndrom and combined bit and phase - flips will look like bit - flips . now",
    "a hadamard transform on a qubit will change a bit - flip into a phase - flip and vice versa .",
    "thus by measuring the syndrom in both , the @xmath28- and the @xmath29-basis we get the full `` quantum syndrom '' which allows us to restore the original state by applying appropriate flips to the state .",
    "we see here that the 7-bit code can actually handle more than just 1-bit errors as long as there is only one bit - flip and one phase - flip ( combined bit and phase - flips count as both ) .    to measure the syndrom bit corresponding to some @xmath30",
    ", we could take an auxiliary qubit in the initial state @xmath31 and then xor all qubits in the encoded state at positions where @xmath32 has a 1 into it .",
    "note that all non - zero elements of @xmath14 have four 1 s .",
    "shor proposes to measure syndrom bits in a different way .",
    "for every such measurement we need an auxiliary 4-qubit `` cat '' state @xmath33 which we hadamard transform to get @xmath34 thus a linear combination of all 4-bit words with an even number of 1 s . now instead of xoring the 4 qubits of the codeword into a single auxiliary qubit , we xor each one into one of the 4 auxiliary qubits .",
    "then we observe this state",
    ". the parity bit of the observed 4-bit word will then be the syndrom bit",
    ". one can wonder whether we collapse the encoded state in an unwanted way by observing 4 qubits instead of just the syndrom bit , but one can show that this is not so",
    ".      if computation with encoded qubits is to pay off , the error probability ( of making a codeword uncorrectable ) , should be smaller than the fundamental error rate @xmath4 one would have without encoding .",
    "this can be achieved by making sure that an error in error correction affects at most one bit of the codeword .",
    "then the probability of introducing errors into several qubits and thus making the codeword uncorrectable is of order @xmath35 .",
    "thus by making @xmath4 small enough we can make sure that encoding pays off .",
    "a conventional syndrom measurement with just 1 auxiliary qubit is nt fault tolerant , because , as one can check , the probability of affecting several qubits is of order @xmath4 , not @xmath35 as with shors method .",
    "to achieve fault tolerant quantum computation , besides fault tolerant error correction ( ftec ) we need a way to apply computational operations to the encoded qubits such that again the error probability is of order @xmath35 . for the 7-bit code several operations can be carried out bitwise , that is , to apply an operation to an encoded qubit we have to apply it individually to all 7 qubits .",
    "this is clearly fault tolerant .",
    "pauli matrix operations ( clifford group ) , not , phase flips and the xor between 2 computational qubits can be carried out in this way . to be able to carry out any calculation ,",
    "we need an additional operation , e.g. the toffoli gate . applying a toffoli gate to three encoded qubits",
    "is not this simple , but it can also be done fault tolerantly ( see @xcite ) . in fault",
    "tolerant quantum computation we carry out operations on the encoded computational qubits and once in a while we apply a recovery operation to prevent the acculmulating correctable errors from becoming uncorrectable ones . for fault",
    "tolerant quantum computation we also need to be able to prepare e.g. an encoded @xmath31 and to observe encoded qubits :      for preparing encoded states @xmath36 i propose to start with an arbitrary 7-qubit state and then essentially apply ftec to it till we get @xmath36 , where the possibility to throw away states that do nt seem to have come out right , is important . to be able to discriminate between @xmath36 and @xmath37 ,",
    "we need `` syndrom '' bits other than @xmath30 , namely we need at least one @xmath38 .",
    "we could proceed as follows : we take an arbitrary 7-qubit state and apply error correction to it .",
    "in addition to the usual @xmath39 syndrom bits we have to measure a `` 0/1-syndrom bit '' telling us whether we have @xmath36 or @xmath37 .",
    "if we get @xmath37 we can either throw it away or we can change it to @xmath36 by negating all 7 qubits",
    ". then we have to * verify * the thus obtained state , e.g. by again measuring all 6 + 1 syndrom bits .",
    "if they are not all 0 we start over .",
    "the probability of getting a @xmath37 instead of a @xmath36 then is of order @xmath35 , as required .",
    "the observation of an encoded qubit should be done in the @xmath40 basis , as only there one can tell @xmath36 from @xmath37 by observing a 7-bit word belonging to the superposition . because these words are in @xmath24 we get an error probability of @xmath41 .",
    "here i describe the improved fault tolerant error correction which i have simulated on a computer .",
    "first a cat state has to be constructed .",
    "this can be done by resetting 4 qubits to @xmath31 and then hadamard transform the first one to get @xmath42 .",
    "then i apply an xor from the 1 . to the 2 .",
    "qubit then from 2 .",
    "@xmath43 3 . and finally from 3 .",
    "@xmath43 4 .",
    "now this state would have a probability of order @xmath4 to have more than 1 bit - flip , which would be harmful .",
    "thus , as shor points out , we have to verify this state .",
    "i take an additional auxiliary qubit in state @xmath31 and xor the 1 . and",
    "cat qubit into it .",
    "if upon observation this qubit is nt 0 we have to try again to construct a cat state .",
    "hadamard transforming the 4 qubits in the last step is of course fault tolerant .",
    "as shor also points out , it is not enough to measure the syndrom just once to get error probability @xmath41 . on the other hand we should minimize the number of syndrom bit measurements as they threaten to destroy the encoded qubit . instead of repeating the whole syndrom measurement ( in one basis ,",
    "say the @xmath28-basis ) , i measure the parity bit of the 3 just measured syndrom bits .",
    "thus if @xmath44 are the 3 basis elements of @xmath14 , i next measure the syndrom bit corresponding to @xmath45 .",
    "if this parity check turns out to be wrong , i again measure the parity bit of the last three measurements , thus @xmath46 , and so on till the last 4 measurements are consistent .",
    "this strategy has the potential advantage that errors which have been introduced into the codeword by early syndrom bit measurements , may be detected and corrected .",
    "actually there is one case in this sceme where a ftec step can destroy an originally error free encoded qubit with probability @xmath47 .",
    "this is when the last two measured syndrom bits are 1 and the two preceeding ones are 0 .",
    "this case can specifically be taken care of .",
    "another improvement can be made when the syndrom indicates an undisturbed codeword , as will be the case most of the time . in this case",
    "i do nt measure the syndrom parity bit , as no erroneous error correction attempt threatens to introduce an additional error into the codeword .",
    "actually we can even go further and abandon the error correction step if the first syndrom bit measurement yields 0 .",
    "of course , which one we take as the first one should then cyclicly be changed between @xmath48 from error correction step to error correction step . in a way this is like carrying out only @xmath49 of an error correction step , but as actually 4 out of 7 errors will show up in a given single syndrom bit , it pays off .",
    "i will refer to this sceme as `` 1/3 ftec '' .",
    "schematically a syndrom bit measurement in the @xmath28-basis ( thus looking for bit - flips ) goes as follows :    ( 350,100 )    ( 10,67)@xmath50 ( 30,70)(1,0)270    ( 0,27)@xmath51 ( 30,30)(1,0)50 ( 85,27)@xmath52 ( 100,30)(1,0)180 ( 285,27)@xmath53    ( 150,68)(0,-1)36 ( 120,47)@xmath54    where @xmath52 stands for a hadamard transformation on each qubit and @xmath53 means measurement .",
    "the xor applys only to the 4 qubits of the codeword @xmath50 which are at the positions of 1s in @xmath30 .    measuring a single syndrom bit in the @xmath29-basis is more complicated , as we first have to transform the codeword to the @xmath29-basis and then back again :    ( 350,100 )    ( 10,67)@xmath50 ( 30,70)(1,0)50 ( 85,67)@xmath52 ( 100,70)(1,0)100 ( 205,67)@xmath52 ( 220,70)(1,0)80    ( 0,27)@xmath51 ( 30,30)(1,0)50 ( 85,27)@xmath52 ( 100,30)(1,0)180 ( 285,27)@xmath53    ( 150,68)(0,-1)36 ( 120,47)@xmath54    but an xor conjugated with hadamard transforms is simply an xor in the opposite direction , thus we get the same result with :    ( 350,100 )    ( 10,67)@xmath50 ( 30,70)(1,0)270    ( 0,27)@xmath51 ( 30,30)(1,0)170 ( 205,27)@xmath52 ( 220,30)(1,0)60 ( 285,27)@xmath53    ( 150,32)(0,1)36 ( 120,47)@xmath54",
    "if the error per operation is smaller on the encoded level than on the fundamental level , it seems that by iterated encoding we can achieve an arbitrary precision .",
    "so on the next level we would encode codewords with the 7-bit code where each qubit would again be encoded with this code ( thus 49 qubits per computational qubit ) .",
    "this requires that all operations needed for ftec can also be carried out on the encoded level ( with the reduced error probability ) .",
    "the necessary operations are : hadamard transformation , xor , preparation of @xmath31 and observation of a qubit . for",
    "my threshold result it will be crucial that the toffoli gate is nt needed for ftec . the hadamard transform and the xor",
    "can be carried out bitwise ( transversally ) , thus they can be carried out with the effective error rate @xmath55 , where @xmath56 .",
    "with the depolarizing channel error model it is possible to very efficiently simulate the errors and their propagation without actually having to store the potentially hughe quantum state of the qc .",
    "all we need are two classical bits for each qubit in the qc .",
    "one bit indicates whether a bit - flip has happened while the other one keeps track of phase - flips .",
    "when a hadamard transformation is applied to a qubit the bit - flip and phase - flip bits have to be exchanged .",
    "an xor between two qubits adds the bit - flip of the source qubit to the target qubit while phase - flips propagate in the opposite direction .",
    "the computer simulation i do is really a monte carlo simulation .",
    "thus i run the same `` quantum computation '' many times and introduce at each gate errors with some probability .",
    "what quantum computation do i actually simulate ?",
    "i consider a single encoded qubit ( taking up @xmath57 classical bits in my program ) .",
    "i start with an error - free codeword , then i apply alternatingly a number of computational 1-qubit operations and a ftec step to it .",
    "i assume all 1-qubit operations to be applicable bitwise .",
    "thus for my simulation this simply means , that i introduce errors into the individual qubits with the appropriate probability .",
    "the ftec step is more elaborate , as i have to construct cats , measure syndrom bits with them , ... .",
    "it turns out that there is a optimal number of 1-qubit operations between error correction steps .",
    "more generally there is a optimal probability of 1-qubit errors in the codeword when ftec should be applied .",
    "this is because the probability that the computational operations produce an unrecoverable error in the codeword increases quadratically with the number of operations . on the other hand ftec",
    "should also not be applied too often , as there is some probability ( of course of order @xmath35 ) that it destroys even an error - free codeword .",
    "the optimal number of 1-qubit operations before a `` 1/3 ftec '' step turns out to be about 5 , for a full ftec step it s about 15 .      in the simulation ,",
    "i now go on applying a number of 1-qubit operations followed by an ftec step to the same codeword until it gets an uncorrectable error .",
    "i then calculate the average number of 1-qubit operations i can carry out like that .",
    "the inverse of this gives the effective error probability for the encoded qubit per 1-qubit operation .",
    "a first rough estimate of the threshold is the error rate for which this effective error rate is equal to the fundamental error rate .",
    "i provide two figures with data from the computer simulation .",
    "for clarity i used only `` full ftec '' steps for both figures even though with `` 1/3 ftec '' steps somewhat better results could be obtained .    the first figure shows how the error rate per 1-qubit gate on the encoded level changes with the number of 1-qubit gates applied to the encoded qubit between full ftec steps .",
    "so this error rate is the error rate per ftec step divided by the number of 1-qubit operations between ftec steps .",
    "the function is of the form @xmath58 .",
    "the first term comes from the probability of an ftec step to destroy an undisturbed codeword ( destroy = introduce an uncorrectable error ) .",
    "the second ( constant ) term comes from a probability of destroying a codeword in an ftec step which is proportional to the probability of correctable errors in the codeword before the ftec step . the last term is the probability that the codeword gets an uncorrectable error by accumulating 1-qubit errors from operations , thus this term is independent of the ftec procedure .",
    "( for these three terms see also the paragraph about hand calculations . ) from the data one can see that around the optimal number of operations between ftec steps , which is about 15 , the middle ( constant ) term dominates .",
    "thus when trying to improve my ftec procedure , this term should be targeted .",
    "it is also interesting to note that the error rate per operation does nt increase much if we choose to make ftec steps less often ( e.g. to save time ) .",
    "+    the second figure shows how the error on the encoded level per 1-qubit gate applied to the encoded qubit increases with the fundamental error rate .",
    "the number of operations between full ftec steps has been set to the optimal number of 15 .",
    "fault tolerance , as i have defined it , means that the error rate on the encoded level is quadratic in leading order in the fundamental error rate .",
    "the deviation from a parabola can be seen in the right half of the figure .",
    "the `` break - even '' error rate can be seem to be about 0.002 .",
    "i claim that this `` break - even '' error rate is a reasonably good estimate of the threshold error rate ( here only for gate errors ) .",
    "following is a listing of the c - program that produced the data in the 2 figures .",
    "i ran it on a linux machine with gcc .    ....",
    "# include < stdio.h > # include < math.h >    # define rep 10000 # define for(var , lim ) for(var=0;var<(lim);var++ )    double p=4.0/3 * 0.002 ; int nop=15 ; int state[8][2 ] , cat[4][2 ] , ab[2 ] ;     / * total 12 qubits * / int code[6][7 ] , synd[5 ] ; int err[2][2][2 ] ; int i1,ssum , dpr=0,dc3,db,*v ; file * data ;    double drand48 ( ) ; void srand48(long ) ;",
    "int rb ( ) { return drand48 ( ) < 0.5 ; }    void e1b(int * qb ) { int i2 ; if(drand48()<p ) for(i2,2 ) qb[i2]^=rb ( ) ; } void e2b(int * qb1,int * qb2 ) { int i2 ;    if(drand48()<p ) for(i2,2 ) { qb1[i2]^=rb ( ) ; qb2[i2]^=rb ( ) ; } }     void xor(int * qb1,int * qb2 ) { qb2[0]^=qb1[0 ] ; qb1[1]^=qb2[1 ] ; e2b(qb1,qb2 ) ; }    void htr(int * qb ) { int h ; e1b(qb ) ; h = qb[0 ] ; qb[0]=qb[1 ] ; qb[1]=h ; } void hcat ( ) { int k ; for(k,4 ) htr(cat[k ] ) ; }    void estate(float p ) { int i2,j ;          for(j,7 ) if(drand48()<p ) for(i2,2 ) state[j][i2 ] ^=rb ( ) ; }    void stab ( ) { int i , j , i2,z , z1 ;   for(i2,2 ) { for(i,3 ) { z=0 ;     for(j,7 ) z^=code[i][j]*state[j][i2 ] ; synd[i]=z ; }    z = err[synd[0]][synd[1]][synd[2 ] ] ;    z1=0 ; for(j,7 ) z1^=state[j][i2 ] ;     for(j,7 ) state[j][i2]=0 ; if(z ! = 7 ) state[z][i2]=1 ;    if(z1 = = ( z==7 ) ) state[7][i2]^=1 ; } }    void makecat(float p ,",
    "int n ) { int k , h ; do{for(k , n ) { cat[k][0]=cat[k][1]=0 ; e1b(cat[k ] ) ; }     e1b(cat[0 ] ) ;    for ( k=1 ; k < n ; k++ ) xor(cat[k-1],cat[k ] ) ;    ab[0]=ab[1]=0 ; e1b(ab ) ;    xor(cat[0],ab ) ; xor(cat[n-1],ab ) ;    e1b(ab ) ; } while(ab[0 ] !",
    "= 0 ) ; }    void makecode ( ) { int c[6],i , j ;   c[0]=1110100 ; c[1]=1001110 ; c[2]=1101001 ; c[3]=1010011 ; c[4]=1111111 ; c[5]=1100010 ; for(i,6 ) for(j,7 ) { code[i][6-j]=c[i]%10 ; c[i]/=10 ; } }    void prstate ( ) { int j , i2 ; for(i2,2 ) { for(j,7 ) printf(\"%d \" , state[j][i2 ] ) ;     printf ( \"   % d\\n\",state[7][i2 ] ) ; } printf(\"\\n \" ) ; }    int syndv(int n , int i2 ) { int j , k=0,z ; makecat(p , n ) ; if(i2==0 ) { hcat ( ) ; for(j,7 ) if(v[j]){xor(state[j],cat[k ] ) ; k++ ; } } if(i2==1 ) { for(j,7 ) if(v[j]){xor(cat[k],state[j ] ) ; k++ ; } hcat ( ) ; } z=0 ; for(k , n ) { e1b(cat[k ] ) ; z^=cat[k][0 ] ; } return z ; }    int synd01 ( ) { v = code[5 ] ; return syndv(3,0 ) ; }       void ftec(int i2 ) { int i , j , k , z ; for(i=0 ; ; i++ ) { if(db ) printf(\"%d\",i ) ;     v = code[(i+i1)%4 ] ; synd[(i+i1)%4]=syndv(4,i2 ) ;      ssum = synd[0]^synd[1]^synd[2]^synd[3 ] ;    if(synd[(i+i1)%4 ] & & ! synd[(i+i1 + 1)%4 ] & &            !",
    "synd[(i+i1 + 2)%4 ] & & synd[(i+i1 + 3)%4 ] ) ssum=1 ;    / * if ( i==0 & & synd[i1%4]==0 ) { synd[0]=synd[1]=synd[2]=0 ; break ; } * /    if ( i>=3 & & ssum==0 ) break ; }      z = err[synd[0]][synd[1]][synd[2 ] ] ;      if(z!=7 ) { state[z][i2]^=1 ; e1b(state[z ] ) ; }    if(db ) printf ( \"   % d \\n\",z ) ; }    main ( ) { int i , i2,i3,j , k , z , bh ; double dm , dv , sd , sdr , eps , eps1 ;   srand48(time(null ) ) ; makecode ( ) ; err[0][0][0]=7 ; for(j,7 ) err[code[0][j]][code[1][j]][code[2][j]]=j ;    / * dv=0 ; for(i,10 ) { dv+=1000000000000000000ll ; printf(\"%ld\\n\",dv ) ; } exit(0 ) ; * /    / * data = fopen(\"gr\",\"w \" ) ; for(nop=1;nop<=60;nop++ ) { printf(\"%d\\n\\n\",nop ) ; * /   data = fopen(\"grv\",\"w \" ) ; for(i=1;i<=60;i++){eps=0.0002*i ; p=4.0/3*eps ;   for(i3=0,dm = dv=0;;i3++){sdr = sd=1 ;    for(j,8 ) { state[j][0]=state[j][1]=0 ; }    for(i1=1;;i1++){dpr++ ; db=(dpr%rep==0 ) ;      estate(1-pow(1-p , nop ) ) ; for(i2,2 ) ftec(i2 ) ;    stab ( ) ; if(db){prstate ( ) ; eps1=1.0*i3/dm ; sdr = sqrt(1.0*i3*dv / dm / dm-1.0)/sqrt(i3 ) ;    sd = eps1*sdr ;    printf(\"%d % f % d % 1.9f % 1.9f % 1.5f\\n\\n\\n\",nop , eps , i3,eps1,sd , sdr ) ; }     if(state[7][0]+state[7][1 ] ) { dm+=1.0*nop*i1 ; dv+=1.0*nop*nop*i1*i1 ; break ; } }    if(sdr*sqrt(eps1/0.002)<0.02 ) {    fprintf(data,\"%f % f % 1.7f\\n\",eps , eps1,sd ) ; break ; } } }     fclose(data ) ;     } ....      first of all we have not considered 2- or 3-qubit gates",
    ". these will propagate the 1-qubit errors in the codewords to other codewords and will thus make it necessary to apply ftec more often . to be on the save side , we could apply full ftec right after each gate in which a codeword has participated . for this case",
    "the simulation gives a threshold of @xmath59 .",
    "but this much ftec will hardly be necessary .",
    "say we apply just a `` 1/3 ftec '' step after each gate .",
    "then the threshold will be @xmath60 .",
    "another simplification is the assumption that the error will diminish in the same way from one level of encoding to the next , as it does from the fundamental level to the first one .",
    "this is not true .",
    "actually also the error pattern changes so that we should really consider more that just the probability @xmath4 to describe it .",
    "there are reasons to expect the error evolution to higher levels to become worse `` higher up '' but there are also good arguments to the contrary ( see below ) .",
    "so far i have only considered gates that can be applied bitwise to encoded qubits .",
    "this is not true for the toffoli gate , although shor @xcite gives a ( complicated ) fault tolerant implementation of the toffoli gate on encoded qubits .",
    "i claim that nevertheless the toffoli error will go down with additional levels of encoding as soon as this is true for the errors of the simpler operations .",
    "this is mostly because the toffoli gate is nt needed for ftec .",
    "a very rough estimate of the coefficients gives the following evolution equation for going from level @xmath61 to level @xmath62 for the toffoli error :    @xmath63    the implementation of the toffoli gate consists mostly of the preparation of a complicated auxiliary state .",
    "that s also where the next lower level toffoli gate has to be used .",
    "because we can verify the integrity of this state and redo it if necessary , there is no term @xmath64 in the above equation .",
    "the smallness of the last 2 coefficients is mainly due to my possibly too benign error model where an error in a toffoli gate is likely to affect all 3 bits , and thus is easily detected .",
    "but one sees that even for much larger coefficients the toffoli error will be `` dragged down '' once @xmath65 diminishes .",
    "actually the same argument about `` dragging down '' can be applied to other than the toffoli gate errors .",
    "the statement is that what really counts is that higher - level ftec can be improved because once this can be achieved , gate errors can be taken care of by applying ftec often enough .",
    "so for the threshold it is enough to analyze the `` inner workings '' of a higher - level ftec .",
    "most of these `` inner workings '' are xors .",
    "say we apply a `` 1/3 ftec '' step on the two encoded qubits before applying the xor .",
    "one can check that this more than counteracts the increase of errors in the xor due to new errors and due to `` copying '' errors ( error propagation ) . thus this procedure should keep the frequency of lower - level errors under control .",
    "i think this should justify the assumptions which led to the above estimate of @xmath60 .",
    "let s make a rough little calculation concerning the application of `` 1/3 ftec '' on both encoded qubits before each xor .",
    "let @xmath66 denote the error probability per qubit in units of the fundamental error probability @xmath4 .",
    "then the `` 1/3 ftec '' step will reduce this to @xmath67 .",
    "the xor will increase the error probability by @xmath68 due to error copying ( error propagation ) and introduce its own errors .",
    "thus :    @xmath69    this leads to the well acceptable equilibrium value @xmath70 .",
    "above we have not considered errors introduced by the `` 1/3 ftec '' step and neither have differentiated between bit - flips and phase - flips . with @xmath71 and @xmath72 for those probabilities , a more accurate calculation is straight forward .",
    "there are reasons why the error may go down faster on higher levels than what one might at first expect .",
    "first of all on higher levels auxiliary states can be verified more thoroughly before they are used .",
    "e.g. a cat on the first level consists of 4 codewords whose integrity we can check .    then , as mentioned above , it is generally ( not only for the toffoli gate ) true that what really counts is whether we can improve the ftec step when going to higher levels .",
    "thus we can deal with the error propagation problem specifically for the sequence of operations that make up an ftec step and can try to optimize this .",
    "so far i have assumed that the errors introduced by on the qubits dominate .",
    "let s now consider errors which affect all qubits at every timestep ( duration of an operation ) irrespective of whether they take part in an operation or not .",
    "it is clear that in the limit of large qcs , for such errors a ( non - zero ) threshold only exist if we allow operations to be carried out in parallel on different parts of the quantum computer .",
    "so this threshold will critically depend on how much parallelism we assume qcs will be capable of .",
    "here i assume that for every 7-qubit codeword in the qc we have an independent machinery .",
    "this machinery includes 4 auxiliary qubits for making cats plus 1 qubit for verifying them . within every such @xmath73-qubit block",
    "i assume that all operations are carried out sequentially .",
    "the preparation and verification of a 4-qubit cat takes 12 operations .",
    "the measurement of a single syndrom bit with this cat takes another 12 steps .",
    "thus while the 12 qubits on average are involved in 2 operations they each also have to wait for 24 time steps . thus on average 12 times more memory errors than operational errors affect each qubit . from this we can state that the memory - error threshold is roughly 10 times lower than the gate - error threshold ( for our assumptions on the degree of parallelism ) .",
    "i think that this type of rough estimates is adequate for the time being , as we are far from an optimal fault tolerant quantum computation sceme and as we know very little about the errors and the possible parallelism of a real quantum computer .",
    "consider the following diagram representing @xmath74 bitwise 1-qubit operations in a row , followed by an error correction step .",
    "note that the @xmath74 operations simply correspond to an error probability of @xmath75 ( for @xmath76 ) per qubit .",
    "practically the error probability @xmath77 will be produced by fewer than @xmath74 1- , 2- or 3-qubit operations due to the propagation of lower level errors , as mentioned above .",
    "( 350,120 )    ( 120,90)@xmath74 operations ( 230,90)error correction    ( -30,75)0 errors ( 95,80 ) .",
    "( -30,45)1 error ( correctable ) ( 95,50 ) .",
    "( -30,15)2 errors ( uncorrectable ) ( 95,20 ) .",
    "( 105,80)(3,-2)90 ( 150,68)@xmath78 ( 202,80 ) .",
    "( 105,80)(3,-1)90 ( 202,50 ) .",
    "( 125,25)@xmath79 ( 202,20 ) .",
    "( 210,80)(3,-2)90 ( 255,70)@xmath80 ( 308,80 ) .",
    "( 210,80)(3,-1)90 ( 268,47)@xmath81 ( 308,50 ) .",
    "( 210,50)(3,-1)90 ( 250,25)@xmath82 ( 308,20 ) .",
    "the lines represent transitions between the 3 different `` error states '' in which a codeword can be .",
    "i have marked only the transitions which will play a role in the following calculation . in the `` @xmath74 operations '' step of course",
    "most ( 100% to order @xmath83 ) codewords will remain error free .",
    "the same is true for the error correction step .",
    "i also assume that we have a `` full '' error correction step , which means that to order @xmath83 all correctable errors get corrected .",
    "in my `` optimized '' implementation of ftec where most of the time i measure only one syndrom bit in the @xmath28-basis and one in the @xmath29-basis , we would also have to take into account that @xmath84 , actually @xmath85 or so .",
    "it is also a simplification that i put the correctable errors into just one category .",
    "actually one should make a difference between single bit - flip or phase - flip errors and a bit - phase - flip error , as they behave differently .",
    "i hope the simplified picture is enough to give an impression of what is going on .",
    "another approximation is that i assume @xmath80 to be small compared to the amount of correctable errors introduced by the @xmath74 operations , thus i set @xmath86 .",
    "the quantity we are looking for , is the probability that a codeword gets an uncorrectable error .",
    "as the diagram shows , such errors happen during the operations stage as well as during the error correction step .",
    "as the @xmath74 operations are applied bitwise , the error probabilities for different qubits are independent .",
    "this gives @xmath79 for the probability that two errors occurred in different qubits .",
    "with all this we get for the probability of uncorrectable errors per bitwise operation :    @xmath87    for fault tolerant error correction we can write in leading order :    @xmath88    where the @xmath89 s are characteristic numbers for the ftec scheme . with this",
    "we get :    @xmath90    we now have to find the optimal number @xmath74 of bitwise operations per error correction step by minimizing this expression .",
    "we get :    @xmath91    thus the apropriate numbers for characterizing the performance of a ftec scheme are @xmath74 and @xmath89 .",
    "the hard part of the calculation is to determine the combinatoric constants @xmath92 and @xmath93 , which is why eventually i used a computer simulation .",
    "nevertheless i try to show how in principle one could proceed by presenting a very crude calculation .",
    "the quantity @xmath94 is the probability that an initially undisturbed codeword gets destroyed in an ftec step due to the occurence of 2 errors .",
    "thus @xmath92 is the number of possibilities how two errors in ftec ( both of probability @xmath4 ) can destroy a codeword .",
    "let s look at @xmath92 and @xmath93 for the case where we only try to correct errors in one basis ( thus e.g. only bit flips ) .",
    "most of the time we will get 0 for the first syndrom bit and stop there ( using here my `` 1/3 ftec '' scheme ) . thus both errors would have to be introduced into the codeword by the syndrom bit measurement .",
    "one can estimate that this does nt give a big contribution .",
    "it seems that the main contribution to @xmath92 comes from the case where one error causes the first syndrom bit measurement to yield 1 and at the same time the codeword to get an error .    to estimate these contributions",
    ", we should first know the probabilities for errors in the cat state . here",
    "i take these probabilities from my computer simulation , although with some patience it could be done by hand .",
    "a variant of my program gives the exact leading term of the taylor expansion in @xmath4 .",
    "a cat state has at most 1 phase - flip ( pf ) .",
    "i get the following numbers :    @xmath95    from this we next calculate the probabilities of a wrong syndrom bit measurement and of introducing an error into the codeword . note that under the hadamard transformation the cat phase - flips become bit - flips which give an erroneous syndrom bit .",
    "so the syndrom bit error is :    @xmath96    where the 3 .",
    "term is the xor error .",
    "the probability of introducing an error into the codeword during a syndrom bit measurement is :    @xmath97    the first two terms are phase - flips that are transported from `` @xmath98cat '' to the codeword by the xor .",
    "term is again from the xor error .",
    "the probability that both , the syndrom bit and the codeword get wrong is :    @xmath99    say this happened in the first syndrom bit measurement .",
    "then in the following 3 to 4 such measurements either the codeword gets another error or another syndrom bit is wrong which may lead to an erroneous error correction attempt that makes the codeword uncorrectable . with an average number of @xmath100 syndrom bit measurements these two probabilities are @xmath101 and @xmath102 . taking only these contributions we get very roughly :    @xmath103    for @xmath93",
    "we take the probability that a second error gets introduced into the codeword during the 4 syndrom bit measurements .",
    "but only a fraction of about @xmath104 of the correctable errors will show up in the first syndrom bit and will thus lead to more measurements , thus we get :    @xmath105    now we have estimated these values for 1/6 ftec and there is really no clean way to obtain from this the corresponding values for a full ftec step without knowing more constants . but",
    "as we want to get some answer , we simply multiply both constants with 6 and calculate @xmath89 from this .",
    "we get :    @xmath106    which confirms the order of magnitude of the threshold given by the computer simulation .",
    "i claim that the threshold is determined only by the operations needed in a fault tolerant error correction step . for the 7 bit code",
    "these are : xor , hadamard transformation , qubit measurement and preparation of @xmath31 .",
    "as long as the toffoli gate can be applied fault tolerantly to encoded qubits , its error can eventually be brought down by sufficient concatenation , though it may always remain much larger than e.g. the error of an xor .",
    "an improved implementation of ftec with the 7 bit code allows me to achieve a threshold of @xmath0 or better for gate errors .",
    "the present scheme is not thought to be applied directly to a physical quantum computer , as much more efficient methods may take care of the special error patterns usually occurring and as it is expected that more space and time efficient methods exist than concatenation .",
    "the result @xmath0 may rather be seen as a guideline about what kind of gate accuracy is required .",
    "my scheme can certainly be improved further .",
    "the following observation wo nt help to improve the threshold , but may allow to reduce the number of encoding levels : if the error @xmath4 is sufficiently below the threshold it becomes worthwile to use longer than 7-qubit codes which can correct more than 1 error .",
    "this is particularly true for the higher concatenation levels .",
    "also we may want to use a code which allows a simpler implementation of the toffoli gate ( or an equivalent one , see e.g @xcite ) and thus a faster reduction of the toffoli error .",
    "eventually a compact unified understanding of fault tolerant quantum computing may allow more progress as the concatenation scheme is thought to be far from optimal , especially for space ( number of qubits ) and time requirements .",
    "i could also imagine that eventually for every quantum algorithm we will try to find a taylor made fault tolerant version .",
    "i did this work at the quantum computation and quantum coherence program at the institut of theoretical physics , university of california , santa barbara and at lanl in november 96 .",
    "revisions were made in the following months at lanl .",
    "i would like to thank manny knill and raymond laflamme for discussions and especially adrian gentle for help with programming in c. i m supported by the swiss national science foundation ( schweizerischer nationalfonds ) ."
  ],
  "abstract_text": [
    "<S> i make a rough estimate of the accuracy threshold for fault tolerant quantum computing with concatenated codes . </S>",
    "<S> first i consider only gate errors and use the depolarizing channel error model . </S>",
    "<S> i will follow p.shor @xcite for fault tolerant error correction ( ftec ) and the fault tolerant implementation of elementary operations on states encoded by the 7-qubit code . </S>",
    "<S> a simple computer simulation suggests a threshold for gate errors of the order @xmath0 or better . </S>",
    "<S> i also give a simple argument that the threshold for memory errors is about 10 times smaller , thus @xmath1 . </S>"
  ]
}