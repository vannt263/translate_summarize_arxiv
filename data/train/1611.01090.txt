{
  "article_text": [
    "* research challenges tackled . *   in this work we tackle computational problems on hypergraph decompositions , which play a prominent role for efficiently answering conjunctive queries ( cqs ) and solving constraint satisfaction problems ( csps ) , which we discuss further below .",
    "many -hard graph - based problems become tractable for instances whose corresponding graphs have bounded treewidth .",
    "there are , however , many problems for which the structure of an instance is better described by a hypergraph than by a graph , for example , the above - mentioned cqs and csps . given that treewidth does not generalize hypergraph acyclicity - acyclicity .",
    "this notion is more general than other types of acyclicity that have been introduced in the literature . ] , proper hypergraph decomposition methods have been developed , in particular , _ hypertree decompositions ( hds ) _",
    "@xcite , the more general _ generalized hypertree decompositions ( ghds ) _  @xcite , and the yet more general _ fractional hypertree decompositions ( fhds ) _  @xcite , and corresponding notions of width of a hypergraph @xmath0 have been defined : the _ hypertree width _",
    "@xmath1 , of @xmath0 , the _ generalized hypertree width _",
    "@xmath2 , and the _ fractional hypertree width _",
    "@xmath3 , where for each hypergraph @xmath0 , @xmath14 .",
    "definitions are given further below .",
    "a number of highly relevant hypergraph - based problems , among which cq - evaluation and csps , become tractable for classes of instances of bounded @xmath15 , @xmath11 , or , @xmath12 . for each of the mentioned types of hypergraph decompositions it would thus be most useful to be able to recognize for each constant @xmath6 whether a given hypergraph @xmath0 has corresponding width at most @xmath6 , and if so , to compute a corresponding decomposition .",
    "more formally , for _ decomposition _",
    "@xmath16hd , ghd , fhd@xmath17 and @xmath18 , we consider the following family of problems ;     + * input * hypergraph @xmath19 ; + * output * of @xmath0 of width @xmath20 if it exists and answer ` no ' otherwise .",
    "as shown in  @xcite ,   is in .",
    "however , little was known so far about .",
    "in fact , this has been a long standing open problem . in their 2006 paper",
    "@xcite , grohe and marx state : it remains an important open question whether there is a polynomial - time algorithm that determines ( or approximates ) the fractional hypertree width and constructs a corresponding decomposition . in the 2014 journal version of this paper ,",
    "they still mention this as an open problem and conjecture the problem might be -hard .",
    "the open problem is restated in @xcite , where further evidence for the hardness of the problem is given by showing that `` it is not expressible in monadic second - order logic whether a hypergraph has bounded ( fractional , generalized ) hypertree width '' . in the present paper",
    "we tackle this open problem :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ * research challenge 1 : *  is tractable ? _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    let us now turn to generalized hypertree decompositions . in  @xcite the complexity of was stated as an open problem . in @xcite , it was shown that testing @xmath21 is -complete for @xmath10 , and therefore also is -hard for @xmath10 .",
    "for @xmath22 the problem can be seen to be trivially tractable ( @xmath23 just means @xmath0 is acyclic ) . however the case @xmath7 has been left open .",
    "this case is quite interesting , because it was observed that the majority of practical queries from various benchmarks that are not acyclic have @xmath24 , and that a decomposition in such cases can be very helpful .",
    "our second research goal is thus to finally settle the complexity of completely .    _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _",
    "_ * research challenge 2 : *  is tractable ? _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    for those problems that are already known to be intractable , for example , for @xmath10 , and for those others that shall turn out to be intractable , we would like to find large islands of tractability or approximability that correspond to meaningful restrictions of the input hypergraph instances .",
    "ideally , such restrictions should fulfill two main criteria : ( i ) they need to be _",
    "realistic _ in the sense that they apply to a very large number of instances of real - life benchmarks of cqs and csps , and ( ii ) they need to be _ non - trivial _ in the sense that the restriction itself does not already imply bounded @xmath15 , @xmath11 , or @xmath12 .",
    "( trivial restrictions would be , for example , hypergraph acyclicity or bounded treewidth . ) where we do not achieve ptime algorithms for the precise computation of a decomposition of optimal width , we would like to find tractable methods for achieving good approximations . in  @xcite ,",
    "marx proved that for every fixed @xmath25 , there is a polynomial - time algorithm that , given a hypergraph @xmath0 with @xmath5 , computes a fractional hypertree decomposition of width @xmath26 for @xmath0 .",
    "we would like to find realistic restrictions that guarantee significantly tighter approximations .",
    "our third research problem is thus formulated as follows :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ * research challenge 3 : *  find realistic , non - trivial restrictions on hypergraphs that entail the tractability of problem for _ decomposition _",
    "@xmath16ghd , fhd@xmath17 , or that allow us to find ptime - algorithms which compute good approximations of a width @xmath6 decomposition , in case such a decomposition exists . _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    * background and applications . *",
    "hypergraph decompositions have meanwhile found their way into commercial database systems such as logicblox @xcite and advanced research prototypes such as emptyheaded  @xcite . moreover , since cqs and csps of bounded hypertree width fall into the highly parallelizable complexity class logcfl , hypergraph decompositions have also been discovered as a useful tool for parallel query processing with mapreduce @xcite .",
    "hypergraph decompositions , in particular , hds and ghds have been used in a plethora of other contexts , e.g. , in combinatorial auctions  @xcite and automated selection of web services based on recommendations from social networks  @xcite .",
    "there exist exact algorithms for computing the generalized or fractional hypertree width @xcite ; of course , they are exponential .",
    "cqs are the most basic and arguably the most important class of queries in the database world .",
    "likewise , csps constitute one of the most fundamental classes of problems in artificial intelligence .",
    "formally , cqs and csps are the same problem and correspond to first - order formulae using @xmath27 but disallowing @xmath28 as connectives , that need to be evaluated over a set of finite relations : the _ database relations _ for cqs , and the _ constraint relations _ for csps . in practice ,",
    "cqs have often fewer conjuncts ( query atoms ) and larger relations , while csps have more conjuncts but smaller relations .",
    "unfortunately , these problems are well - known to be -complete @xcite .",
    "consequently , there has been an intensive search for tractable fragments of cqs and/or csps over the past decades . for our work ,",
    "the approaches based on decomposing the structure of a given cq or csp are most relevant , see e.g.@xcite .",
    "the underlying structure of both , cqs and csps is nicely captured by hypergraphs . the hypergraph @xmath29 underlying a cq ( or a csp ) @xmath30 has as vertex set @xmath31 the set of variables occurring in @xmath30",
    "; moreover , for every atom in @xmath30 , @xmath32 contains a hyperedge consisting of all variables occurring in this atom . from now on , we shall mainly talk about hypergraphs with the understanding that all our results are equally applicable to cqs and csps .    * definition and properties of relevant hypergraph decomposition methods . *",
    "( for more details , see appendix [ app : preliminaries ] . )",
    "let @xmath29 be a hypergraph and consider functions @xmath33 and @xmath34 $ ] . for @xmath35 , we define @xmath36 , i.e. , @xmath37 denotes the set of vertices that are _ covered _ by @xmath38",
    ". then a _ generalized hypertree decomposition _ ( ghd ) of @xmath0 is a tuple @xmath39 , such that @xmath40 is a rooted tree and the following conditions hold :    \\(1 ) for each @xmath41 , there is a node @xmath42 with @xmath43 ;    \\(2 ) for each @xmath44 , the set @xmath45 is connected in @xmath46 ;    \\(3 ) for each @xmath47 , @xmath48 is a function @xmath49 with @xmath50 .",
    "a _ hypertree decomposition _ ( hd ) of @xmath0 is a ghd , which in addition also satisfies the following condition :    \\(4 ) for each @xmath47 , @xmath51 ,    where @xmath52 denotes the subtree of @xmath46 rooted at @xmath53 .",
    "a _ fractional hypertree decomposition _ ( fhd ) @xcite of @xmath0 is a tuple @xmath54 , where conditions ( 1 ) and ( 2 ) plus the following condition ( 3 ) hold :    ( 3 ) for each @xmath47 , @xmath55 is a function @xmath34 $ ] with @xmath56 .    for @xmath57 , the weight of such a function @xmath58 is defined as @xmath59 .",
    "then the width of a ghd , hd , or fhd is the maximum weight of the functions @xmath48 or @xmath55 , respectively , over all nodes @xmath42 .",
    "moreover , the generalized hypertree width , hypertree width , and fractional hypertree width of @xmath0 ( denoted @xmath2 , @xmath1 , @xmath3 ) is the minimum width over all ghds , hds , and fhds of @xmath0 , respectively .",
    "condition 2 is called the `` connectedness condition '' , and condition ( 4 ) is referred to as `` special condition '' @xcite .",
    "the set @xmath60 is often referred to as the `` bag '' at node @xmath53 . to avoid confusion",
    ", we will consequently refer to the elements in @xmath31 as _ vertices _ ( of the hypergraph ) and to the elements in @xmath61 as the _ nodes _ of @xmath46 ( of the decomposition ) . by slight abuse of notation",
    ", we will often write @xmath62 short for @xmath42 . the elements in @xmath32 are referred to as hyperedges or simply edges .",
    "note that , strictly speaking , only hds require that the underlying tree @xmath46 be rooted . for the sake of a uniform treatment",
    "we assume that also the tree underlying a ghd or an fhd is rooted ( with the understanding that the root is arbitrarily chosen ) .",
    "* main results . *",
    "first of all , we have investigated the above mentioned open problem concerning the recognizability of @xmath63 for fixed @xmath6 .",
    "our initial hope was to find a simple adaptation of the -hardness proof in @xcite for recognizing @xmath64 , for @xmath10 .",
    "unfortunately , this proof dramatically fails for the fractional case .",
    "in fact , the hypergraph - gadgets in that proof are such that both yes and to no instances may yield the same @xmath12 . however , via crucial modifications , including the introduction of novel gadgets , we succeeded to construct a reduction from 3sat that allows us to control the @xmath12 of the resulting hypergraphs such that those hypergraphs arising from yes 3sat instances have @xmath65 and those arising from no instances have @xmath66 .",
    "surprisingly , thanks to our new gadgets , the resulting proof is actually significantly simpler than the -hardness proof for recognizing @xmath64 in @xcite .",
    "we thus obtain the following result which solves a long standing open problem :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ * main result 1 : * deciding @xmath67 for hypergraphs @xmath0 is -complete , and therefore is intractable . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    this -hardness result can be extended to the problem of recognizing @xmath68 for arbitrarily large @xmath9 .",
    "it turns out that the same construction can also be used to prove that recognizing ghw @xmath69 is -hard , thus killing two birds with one stone .",
    "we can therefore finally close the gap ( for @xmath7 ) left open regarding the complexity of deciding @xmath8 , which has been mentioned as an open problem since 2001 ( pods version of  @xcite ) , and which was solved for @xmath10 in  @xcite :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ * main result 2 : * deciding @xmath70 for hypergraphs @xmath0 is -complete , and therefore is intractable .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    the main results 1 and 2 are presented in section [ sect : hardness ] .",
    "detailed full proofs are given in appendix  [ app : hardness ] .",
    "these results close some smoldering open problems with bad news .",
    "we thus further concentrate on research challenge 3 in order to obtain some positive results for restricted hypergraph classes .    for the computation of ghds",
    ", we succeeded to identify very general , realistic , and non - trivial restrictions .",
    "these results are based on new insights about the differences between ghds and hds and the introduction of a novel original technique for expanding a hypergraph @xmath0 to an edge - augmented hypergraph @xmath71 such that the width @xmath6 ghds of @xmath0 are precisely the width @xmath6 hds of @xmath71 .",
    "the crux here was to find restrictions under which only a polynomial number of edges need to be added to @xmath0 to obtain @xmath71 .",
    "the hds of @xmath71 can then be computed in polynomial time . in particular , we concentrate on the _ bounded edge intersection property ( bip ) _ , which , for a class @xmath72 of hypergraphs requires that for some constant @xmath73 , for each pair of distinct edges @xmath74 and @xmath75 of each hypergraph @xmath76 , @xmath77 , and its generalization , the _ bounded multi - intersection property ( bmip ) _ , which , informally , requires that for some constant @xmath78 any intersection of @xmath78 distinct hyperedges of @xmath0 has at most @xmath73 elements for some constant @xmath73 . in @xcite ( see appendix  [ app : empiricalstudy ] for a short summary ) , we report tests on a large number of known cq and csp benchmarks and it turns out that a very large number of instances coming from real - life applications enjoy the bip and yet more overwhelming number enjoys the bmip for very low constants @xmath78 and @xmath73 . we obtain the following good news , which are presented in section [ sect : ghd ] , with proofs worked out in full detail in appendix  [ app : bip ] :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ * main result 3 : * for classes of hypergraphs fulfilling the bip or bmip , for each constant @xmath6 , the problem is tractable .",
    "interestingly , this problem remains tractable even for classes @xmath72 of hypergraphs where for some constant @xmath78 all intersections of @xmath78 distinct edges of each @xmath79 of size @xmath80 have @xmath81 elements .",
    "we also show fixed - parameter tractability of the problem w.r.t .  the parameters @xmath73 and @xmath78 of the bip and bmip .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    the tractability proofs for bip and bmip unfortunately do not carry over to the fractional case and  apart from the case of bounded rank discusssed in appendix [ app : vc - and - eccp ]  we are currently not aware of any practically significant restriction that would allow us to solve the problem in polynomial time .",
    "we therefore investigate realistic restrictions that would give us polynomial - time algorithms for obtaining fhds of approximately minimum width , where the approximation scheme is significantly better than the best known approximation of width @xmath26 for the general case @xcite . towards this goal",
    ", we establish an interesting connection between the bip and bmip on the one hand and the vapnik  chervonenkis dimension ( vc - dimension ) of a hypergraph on the other hand . for further results ,",
    "we also study exact and approximate edge - cover compactness properties , which guarantee that if some finite fractional edge cover bound for a class of hypergraphs exists , then there also exists some some optimal / approximate sparse edge cover with a bounded number of edges .",
    "our research , presented in section  [ sect : fhd ] is summarized as follows ( full proofs and further material are provided in appendix  [ app : fhw - approximation ] ) :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ * main result 4 : * for rather general , realistic , and non - trivial hypergraph restrictions , there exist ptime algorithms that , for hypergraphs @xmath0 with @xmath82 , where @xmath6 is a constant , produce fhds whose widths are significantly smaller than the best previously known approximation . in particular ,",
    "the bip , the bmip , or bounded vc - dimension allow us to compute an fhd whose width is @xmath13 .",
    "we also identify another restriction on hypergraphs , which we will refer to as @xmath83-eccp , to allow for the efficient computation of an fhd whose width is @xmath84 .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _",
    "the main result in this section is the -hardness of with _ decomposition _",
    "@xmath16ghd , fhd@xmath17 and @xmath85 . at the core of the -hardness proof is the construction of a hypergraph @xmath0 with certain properties .",
    "the gadget in figure  [ fig : gadgeth0 ] will play an integral part of this construction .",
    "[ lem : gadgeth0 ] let @xmath86 , @xmath87 be disjoint sets and @xmath88 .",
    "let @xmath89 be a hypergraph and @xmath90 @xmath91 a subhypergraph of @xmath0 with @xmath92 and @xmath93 where no element from the set @xmath94 occurs in any edge of @xmath95 .",
    "then , every fhd @xmath96 of width @xmath69 of h has nodes @xmath97 such that :    * @xmath98 , * @xmath99 , * @xmath100 , and * @xmath101 is on the path from @xmath102 to @xmath103 .",
    "[ fig : gadgeth0 ]    the hypergraph @xmath104 is depicted in figure [ fig : gadgeth0 ] .",
    "note that @xmath104 contains 3 cliques of size 4 , namely @xmath105 , @xmath106 , and @xmath107 .",
    "the lemma is proved by making heavy use of the connectedness condition and of the fact that a clique of size 4 can only be covered by a fractional edge cover of weight @xmath108 .",
    "[ thm : npcomp ] the problem is -complete for _ decomposition _ @xmath16ghd , fhd@xmath17 and @xmath85 .",
    "the proof is by a complex reduction from 3sat",
    ". we can only give the main ideas here .",
    "all details are worked out in appendix  [ app : hardness ]",
    ".    _ main challenge . _ consider an arbitrary instance of 3sat , which is given by a propositional formula @xmath109 over the variables @xmath110 . from this",
    ", we construct a hypergraph @xmath89 such that @xmath111 if and only if @xmath111 if and only if @xmath112 is satisfiable .",
    "our construction of @xmath0 is guided by an intended fhd or ghd in mind .",
    "it turns out that , in case @xmath112 is satisfiable , it is easy to construct a ghd ( which of course is also a special case of an fhd ) of width 2 of the desired form . proving the opposite implications is much more tricky , i.e. : if @xmath113 then @xmath112 is satisfiable ; and if @xmath111 then @xmath112 is satisfiable .",
    "actually , since @xmath114 holds for every @xmath0 , we only need to concentrate on the latter implication , which is the crux of the whole construction .",
    "_ overall structure of @xmath0 . _",
    "the hypergraph @xmath0 contains two copies @xmath115 of the ( sub-)hypergraph @xmath104 of lemma  [ lem : gadgeth0 ] plus a multitude of edges connecting @xmath104 and @xmath116 .",
    "we thus aim at an fhd @xmath117 which has nodes @xmath118 ( resp .",
    "@xmath119 ) according to the lemma plus a `` long '' path @xmath120 connecting @xmath102 with @xmath121 . by the lemma , @xmath101 covers a set @xmath122 and @xmath123 covers a set @xmath124 .",
    "the overall structure of the intended fhd @xmath125 is depicted in figure  [ fig : intendedfhd ] .",
    "_ encoding truth values . _",
    "suppose that @xmath112 has @xmath80 variables .",
    "then we add to @xmath0 the sets @xmath126 and @xmath127 of vertices in @xmath0 to encode the truth values of the variables of @xmath112 , where the @xmath128 variables stand for `` true '' and the @xmath129 variables stand for `` false '' .",
    "the set @xmath130 is added to @xmath122 while the set @xmath131 is added to @xmath124 . by the connectedness condition ,",
    "this has the effect that along the path @xmath120 from @xmath102 to @xmath121 , we may remove elements @xmath128 from a bag but we may never reinsert an already removed one . likewise , we may introduce elements @xmath129 into a bag but we may never remove an already inserted one . intuitively , removing a vertex @xmath128",
    "encodes the decision that we want to set @xmath128 to false .",
    "now we also add edges @xmath132 for every @xmath133 to @xmath32 .",
    "to cover all these edges @xmath132 by some node on path @xmath120 , it is necessary that every node on the path @xmath120 must cover at least one vertex from @xmath132 .",
    "_ role of the path @xmath120 . _ the path @xmath120 is forced to be `` long '' by adding appropriate vertices and edges that we do not discuss in detail here . with this path",
    ", we pursue _ two goals _ : first , we want to construct ( the encoding of ) a truth assignment @xmath134 in the bags along @xmath120 and second , we want to check with the bags along @xmath120 that @xmath134 indeed satisfies the formula @xmath112 .    towards the _ first goal _",
    ", we make more concrete what is meant by @xmath120 being `` long '' : it means that @xmath120 contains at least @xmath135 nodes , which we can think of as being grouped into @xmath136 blocks of @xmath137 nodes each . by the above observation on the vertices @xmath128 and @xmath129",
    ", some vertices @xmath128 may be removed and/or some vertices @xmath129 may be inserted as we move along @xmath120 from @xmath102 to @xmath138 , passing through one block of @xmath120 after the other .",
    "for technical reasons , the first block must be ignored .",
    "then there are still @xmath139 blocks left and , hence , we have @xmath140 transitions between blocks .",
    "thus , there must be at least one transition ( say from block @xmath141 to block @xmath142 ) , where the sets of vertices @xmath128 and @xmath129 are left unchanged .",
    "in other words , there exists a subpath @xmath143 of @xmath120 such that @xmath143 contains at least @xmath137 nodes ( i.e. , the @xmath137 vertices of the @xmath141-th block in @xmath120 ) where all bags contain the same subset @xmath144 of @xmath145 .",
    "it is at such a subpath @xmath143 that we `` read off '' @xmath134 by setting @xmath146 = `` true '' if @xmath147 and @xmath146 = `` false '' otherwise .    towards the _ second goal _ , @xmath0 contains hyperedges that encode the form of the clauses in @xmath112 .",
    "our construction guarantees that each of the @xmath148 blocks in @xmath120 mentioned above contains @xmath137 nodes , such that each node encodes a clause of @xmath112 .",
    "in particular , the subpath @xmath143 contains nodes @xmath149 , such that each node @xmath150 encodes a clause of @xmath112 .",
    "it remains to show that the bag at the @xmath73-th node @xmath150 can be covered by a fractional edge cover of size 2 , only if @xmath134 indeed satisfies at least one literal in the @xmath73-th clause of @xmath112 .",
    "we conclude this section by mentioning that the above reduction is easily extended to @xmath151 for arbitrary @xmath152 : for integer values @xmath153 , simply add a clique of @xmath154 fresh vertices @xmath155 to @xmath0 and connect each @xmath156 with each `` old '' vertex in @xmath0 . to achieve a rational bound @xmath157 with @xmath158 , we add a clique of @xmath153 fresh vertices and additionally add hyperedges @xmath159 with @xmath160 to @xmath0 , where @xmath161 denotes @xmath162 modulo @xmath153 .",
    "again , we connect each @xmath156 with each `` old '' vertex in @xmath0 .",
    "we are interested in finding a criterion on hypergraphs that makes the problem tractable for fixed @xmath6 .",
    "as discussed in section [ sect : introduction ] , such a criterion should be realistic non - trivial .",
    "we thus propose a very simple property , namely bounded intersection of two or a larger number of edges .    [ def : bip ] the _ intersection width _",
    "@xmath163 of a hypergraph @xmath164 is the maximum cardinality of any intersection @xmath165 of two distinct edges @xmath74 and @xmath75 of @xmath164 .",
    "we say that a hypergraph @xmath0 has the _ @xmath73-bounded intersection property ( @xmath73-bip ) _ if @xmath166 holds .",
    "let @xmath72 be a class of hypergraphs .",
    "we say that @xmath72 has the _ bounded intersection property ( bip ) _ if there exists some integer constant @xmath73 such that every hypergraph @xmath0 in @xmath72 has the @xmath73-bip .",
    "class @xmath72 has the _ logarithmically - bounded intersection property ( logbip ) _ if for each of its elements @xmath164 , @xmath163 is @xmath81 , where @xmath80 denotes the size of hypergraph @xmath164 .",
    "@xmath167    note that the bip criterion is indeed non - trivial , as several well - known classes of unbounded @xmath11 enjoy the 1-bip , such as cliques and grids .",
    "moreover , our empirical study in appendix  [ app : empiricalstudy ] suggests that the overwhelming number of cqs enjoys the @xmath168-bip ( i.e. , one hardly joins two relations over more than 2 attributes ) . to allow for a yet bigger class of hypergraphs",
    ", the bip can be relaxed as follows .",
    "[ def : bmip ] the _ @xmath78-multi - intersection width _",
    "@xmath169 of a hypergraph @xmath164 is the maximum cardinality of any intersection @xmath170 of @xmath78 distinct edges @xmath171 of @xmath164 .",
    "we say that a hypergraph @xmath0 has the _",
    "@xmath73-bounded @xmath78-multi - intersection property ( ) _ if @xmath172 holds .",
    "let @xmath72 be a class of hypergraphs .",
    "we say that @xmath72 has the _ bounded multi - intersection property ( bmip ) _ if there exist constants @xmath78 and @xmath73 such that every hypergraph @xmath0 in @xmath72 has the .",
    "class @xmath72 of hypergraphs has the _ logarithmically - bounded multi - intersection property ( logbmip ) _ if there is a constant @xmath78 such that for the hypergraphs @xmath173 , @xmath169 is @xmath81 , where @xmath80 denotes the size of hypergraph @xmath164 .",
    "@xmath167    clearly , the most liberal restriction on classes of hypergraphs introduced in definitions  [ def : bip ] and [ def : bmip ] is the logbmip .",
    "the main result in this section is that problem with fixed @xmath6 is tractable for any class of hypergraphs satisfying this very criterion .",
    "[ theo : logbmip ] for every hypergraph class @xmath72 that enjoys the logbmip , and for every constant @xmath6 , the problem is tractable , i.e. , given a hypergraph @xmath164 , it is feasible in polynomial time to check @xmath174 and , in case this holds , to compute a ghd of width @xmath6 of @xmath164 .",
    "( for details see appendix  [ app : bip ] . )",
    "we proceed in several steps .",
    "let @xmath0 be a hypergraph and @xmath175 a ghd of @xmath0 .",
    "for any node @xmath53 in @xmath46 , we have @xmath176 .",
    "first , we observe that it is sometimes possible to take some vertices from @xmath177 and add them to @xmath60 without violating the connectedness condition .",
    "we call a ghd _ bag - maximal _ , if for every node @xmath53 , adding a vertex @xmath178 to @xmath60 would violate the connectedness condition . it is easy to verify that bag - maximality can always be achieved by appropriately adding vertices from @xmath179 to @xmath60 without increasing the width @xmath6 . hence , we assume w.l.o.g .  that @xmath180 is bag - maximal .",
    "our goal is to define a polynomial - time computable function @xmath181 which , to each hypergraph @xmath164 and integer @xmath6 , associates a set @xmath182 of additional hyperedges such that @xmath183 iff @xmath184 , and thus @xmath185 is computable in polynomial time .",
    "moreover , a ghd of the same width can be easily obtained from any hd of @xmath186 .",
    "the function @xmath181 is defined in such a way that @xmath182 only contains subsets of hyperedges of @xmath164 , thus @xmath181 is a _",
    "subedge function _ as described in  @xcite .",
    "it is easy to see and well - known @xcite that for each subedge function @xmath181 , and each @xmath0 and @xmath6 , @xmath187 .",
    "moreover , for the `` limit '' subedge function @xmath188 where @xmath189 consists of all possible non - empty subsets of edges of @xmath164 , we have that @xmath190  @xcite .",
    "of course , in general , @xmath188 contains an exponential number of edges .",
    "the crux is that our function @xmath181 will achieve the same , while generating a polynomial and -computable set of edges only . for the logbip",
    ", we set @xmath191 in words , @xmath182 consists of all subsets of intersections of edges @xmath192 with unions of @xmath6 or fewer edges of @xmath164 other than @xmath193 .",
    "intuitively , each union @xmath194 of @xmath6 or fewer edges represents a potential set @xmath179 of some node @xmath53 in any ghd of @xmath164 of width @xmath20 . by the logbip , the intersection of @xmath193 with @xmath195 has at most @xmath196 elements for some constant @xmath197",
    "hence , the powerset has at most @xmath198 elements . if @xmath0 has @xmath137 edges , then there are no more than @xmath199 powersets generated .",
    "we shall discuss later how @xmath182 has to be extended in case of the less restrictive logbmip holds .",
    "now suppose that there is a _ special condition violation _ ( scv ) at some node @xmath53 in the ghd @xmath180 , i.e. , @xmath200 , where @xmath201 is the set of vertices occurring in some bag of subtree @xmath52 of @xmath46 .",
    "that is , @xmath202 but there exists @xmath203 , such that @xmath204 and @xmath205 . by the connectedness condition , @xmath193 must be covered by some node @xmath206 in @xmath52 .",
    "now consider the path @xmath120 from @xmath53 down to @xmath53 : clearly , we can not have @xmath207 for very node @xmath208 on @xmath120 , because then we could add @xmath209 to every bag @xmath210 on @xmath120 , which contradicts the bag - maximality of @xmath180 .",
    "hence , there must exist some node @xmath208 on the path @xmath120 with @xmath211 .",
    "this means that the edges chosen by @xmath212 are all distinct from @xmath193 .",
    "moreover , by connectedness , the subset @xmath213 with @xmath214 must also be covered by @xmath208 .",
    "hence , @xmath215 is contained in @xmath216 and we can modify @xmath48 by setting @xmath217 and choosing @xmath218 instead , which `` repairs '' this particular scv . by exhaustively applying this transformation , we can eventually repair all scvs .",
    "now let us move from the logbip to the logbmip and consider the same kind of scv as above .",
    "it can be shown that , for bag - maximal ghd @xmath180 , the equality @xmath219 holds .",
    "in fact , the inclusion `` @xmath220 '' holds by the connectedness condition and the inclusion `` @xmath221 '' can be shown to follow from the bag - maximality .",
    "each of the sets @xmath222 is equal to the union of up to @xmath6 edges from @xmath0 . by distributivity",
    ", we can transform the intersection of unions @xmath223 into a union of intersections @xmath224 for some @xmath225 .",
    "of course , since @xmath120 can be arbitrarily long , each @xmath226 can be the intersection of an arbitrary number of edges .",
    "however , we can stop the computation after the intermediate result @xmath227 of intersecting @xmath193 with @xmath228 distinct edges , since intersecting @xmath227 with further edges is guaranteed to give a subset thereof .",
    "care has to be taken to avoid stopping the intersection of edges too early in case of duplicate edges inside some intersection @xmath226 .",
    "to this end , we introduce the notion of _ transversals _ of a path @xmath120 of a ghd of some hypergraph , where a transversal is a set @xmath229 of hyperedges of @xmath164 such that each hyperedge of @xmath229 appears in some @xmath230 of some node @xmath231 of @xmath120 , and each @xmath230 of each node @xmath231 of @xmath120 has a non - empty intersection with @xmath229 .",
    "moreover , we present a systematic way of enumerating all transversals by arranging them in a tree structure @xmath232 , where each branch corresponds to a transversal and the nodes along each branch carry as labels the hyperedges of the transversal .",
    "each inner node of @xmath232 has at most @xmath6 child nodes  corresponding to the hyperedges @xmath233 with @xmath234 for a node @xmath231 along the path @xmath120 .",
    "the tree structure allows for efficient elimination of duplicate hyperedges from a transversal . by pruning the tree @xmath232 at depth @xmath228 ,",
    "we get the upper bound @xmath235 on the possible number of branches and the upper bound @xmath236 on the number of possible subsets that we may have to consider for repairing a given scv .",
    "the desired polynomial upper bound on @xmath237 and on the time needed to compute @xmath182 is obtained by deriving the upper bound @xmath199 on the number of `` distinct '' scvs .",
    "for details see appendix  [ app : bip ] .",
    "an interesting special case of the class of hypergraphs enjoying the bmip is any class of hypergraphs with bounded degree : suppose that each vertex occurs in at most @xmath238 hyperedges for some constant @xmath238 .",
    "then the intersection of @xmath239 hyperedges is guaranteed to be empty .",
    "the following corollary is thus immediate .",
    "[ corol : degreeghd ] for every class @xmath72 of hypergraphs of bounded degree , for each constant @xmath6 , the problem is tractable .",
    "note that in the above proof sketch of theorem  [ theo : logbmip ] , we get the upper bound @xmath240 on the number of subedges to be generated by @xmath182 in case the logbmip holds .",
    "for the , this bound improves to @xmath241 ( for details , see appendix  [ app : bip ] ) .",
    "we thus get the following parameterized complexity result .",
    "[ theo : bmipftp ] for each constant @xmath6 , the problem is fixed - parameter tractable w.r.t .",
    "the parameter @xmath242 for hypergraphs enjoying the .",
    "in the previous section , we have seen that under certain conditions ( with the bip as most specific and the logbmip as most general condition presented here ) the problem of computing a ghd of some width @xmath6 can be reduced to the ( well - known tractable ) problem of computing an hd of width @xmath6 .",
    "however , fhds behave significantly differently from ghds .",
    "we therefore turn our attention to approximations of the @xmath12 . from  @xcite we know that a tractable cubic approximation always exists , i.e. : for @xmath25 , there exists a polynomial - time algorithm that , given a hypergraph @xmath0 with @xmath68 , finds an fhd of @xmath0 of width @xmath26 . in this section , we search for conditions which guarantee a better approximation of @xmath12 and which are again realistic . a natural first candidate for restricting hypergraphs",
    "are the bip and , more generally , the bmip from the previous section . indeed , by combining some classical results on the vapnik - chervonenkis ( vc ) dimension with some novel observations",
    ", we will show that the bmip yields a better approximation . to this end",
    ", we first recall the definition of the vc - dimension of hypergraphs .",
    "[ def : vc ] let @xmath243 be a hypergraph , and @xmath244 a set of vertices . denote by @xmath245 .",
    "@xmath246 is called _ shattered _ if @xmath247 .",
    "the _ vapnik - chervonenkis dimension ( vc dimension ) @xmath248 _ of @xmath164 is the maximum cardinality of a shattered subset of @xmath249 .",
    "@xmath167    we now provide a link between the vc - dimension and our first approximation result for the @xmath12 .",
    "[ def : transversality ] let @xmath89 be a hypergraph . a",
    "_ transversal _",
    "( also known as _",
    "hitting set _ ) of @xmath0 is a subset @xmath250 that has a non - empty intersection with every edge of @xmath0 .",
    "the _ transversality _",
    "@xmath251 of @xmath0 is the minimum cardinality of all transversals of @xmath0 .",
    "clearly , @xmath251 corresponds to the minimum of the following integer linear program : find a mapping @xmath252 which minimizes @xmath253 under the condition that @xmath254 holds for each hyperedge @xmath255 .",
    "the _ fractional transversality _",
    "@xmath256 of @xmath0 is defined as the minimum of the above linear program when dropping the integrality condition .",
    "finally , the _ transversal integrality gap _ @xmath257 of @xmath164 is the ratio @xmath258 .",
    "@xmath167    recall from @xcite that computing the mapping @xmath48 for some node @xmath53 in a ghd can be seen as searching for a minimal edge cover @xmath259 of the vertex set @xmath60 , whereas computing the mapping @xmath55 in an fhd corresponds to the search for a minimal fractional edge cover @xmath260 .",
    "again , these problems can be cast as linear programs where the first problem has the integrality condition and the second one has not .",
    "further , we can define the _ cover integrality gap _",
    "@xmath261 of @xmath0 as the ratio @xmath262 .    with this machinery at hand",
    ", we can state our first approximation result for @xmath12 .",
    "[ theo : approxvc ] let @xmath72 be a class of hypergraphs with vc - dimension bounded by some constant @xmath238 and let @xmath25 .",
    "then there exists a polynomial - time algorithm that , given a hypergraph @xmath263 with @xmath68 , finds an fhd of @xmath0 of width @xmath264 .",
    "( sketch . )",
    "the proof proceeds in several steps .",
    "_ reduced hypergraphs .",
    "_ we are interested in hypergraphs which are _ essential _ in the following sense : let @xmath19 be a hypergraph and let @xmath265 .",
    "then the edge - type of @xmath209 is defined as @xmath266 .",
    "we call @xmath0 _ essential _ if there exists no pair @xmath267 of distinct vertices with the same edge - type .",
    "every hypergraph @xmath0 can be transformed into an essential hypergraph @xmath268 by exhaustively applying the following simple reduction rule : if there are two vertices @xmath269 with @xmath270 and @xmath271 , then delete @xmath272 .",
    "it is easy to verify that @xmath273 , @xmath274 , and @xmath275 hold for any hypergraph @xmath0 with corresponding essential hypergraph @xmath268 .",
    "hence , w.l.o.g .",
    ", we may restrict our further considerations to _ essential _ hypergraphs .",
    "_ dual hypergraphs . _ given a hypergraph @xmath276 , the dual hypergraph @xmath277 is defined as @xmath278 and @xmath279 . w.l.o.g .",
    ", we assume that @xmath0 is _ essential_. then @xmath280 clearly holds .",
    "moreover , the following relationships between @xmath0 and @xmath281 are well - known and easy to verify ( see , e.g. , @xcite ) :    \\(1 ) the edge coverings of @xmath164 and the transversals of @xmath282 coincide .",
    "\\(2 ) the fractional edge coverings of @xmath164 and the fractional transversals of @xmath282 coincide .",
    "\\(3 ) @xmath283 , @xmath284 , and @xmath285 .",
    "_ vc - dimension .",
    "_ by a classical result of @xcite , for every hypergraph @xmath89 , we have @xmath286 moreover , in @xcite , it is shown that @xmath287 always holds . in total",
    ", we thus get @xmath288    _ approximation of @xmath12 by @xmath11 . _",
    "suppose that @xmath0 has an fhd @xmath39 of width @xmath6 .",
    "then there exists a ghd of @xmath0 of width @xmath289 with @xmath290 .",
    "indeed , we can find such a ghd by leaving the tree structure @xmath46 and the bags @xmath60 for every node @xmath53 in @xmath46 unchanged and replacing each fractional edge cover @xmath55 of @xmath60 by an optimal integral edge cover @xmath48 of @xmath60 . by the above inequality",
    ", we thus increase the weight at each node @xmath53 only by a factor @xmath291 .",
    "moreover , we know from @xcite that computing an hd instead of a ghd increases the width only by the constant factor 3",
    ".    we can establish the following relationship between bmip and vc - dimension ( for details , see appendix  [ app : fhw - approximation ] ) . together with theorem [ theo : approxvc ] , the corollary below is then immediate .",
    "[ lemma : bmipvsvc ] if a class @xmath72 of hypergraphs has the bmip then it has bounded vc - dimension",
    ". however , there exist classes @xmath72 of hypergraphs with bounded vc - dimension that do not have the bmip .",
    "[ cor : approxbmip ] let @xmath72 be a class of hypergraphs enjoying the bmip and let @xmath25 .",
    "then there exists a polynomial - time algorithm that , given a hypergraph @xmath263 with @xmath68 , finds an fhd ( actually , even a ghd ) of @xmath0 of width @xmath264 .",
    "we would like to identify classes of hypergraphs that allow for a yet better approximation of the @xmath12 .",
    "below we show that the hypergraphs of bounded degree indeed allow us to approximate the @xmath12 by a constant factor in polynomial time .",
    "we proceed in two steps . first , in lemma  [ lem : approxboundeddegree ]",
    ", we establish a relationship between @xmath12 and @xmath11 via the degree ( the proof is given in appendix  [ app : vc - and - eccp ] ) .",
    "then we make use of results from the previous section on the computation of a ghd to get the desired approximation of @xmath12 .",
    "[ lem : approxboundeddegree ] let @xmath0 be an arbitrary hypergraph and let @xmath238 denote the degree of @xmath0 .",
    "then the following inequality holds : @xmath292 .",
    "together with corollary [ corol : degreeghd ] , we get the following approximation result for @xmath12 .",
    "[ cor : approxdegree ] let @xmath72 be a class of hypergraphs whose degree is bounded by some constant @xmath293 and let @xmath25 .",
    "then there exists a polynomial - time algorithm that , given a hypergraph @xmath263 with @xmath68 , finds an fhd ( actually , even a ghd ) of @xmath0 of width @xmath294 .    to identify further classes of hypergraphs that allow for an efficient approximation of the fractional hypertree width",
    ", we introduce a new criterion , referred to as @xmath83-eccp .",
    "it allows us to restrict the number of edges with non - zero weight in the mappings @xmath55 . with this criterion , we will again approximate the @xmath12 up to a constant factor in polynomial time .",
    "[ def : eccp ] let @xmath295 be a class of hypergraphs and let @xmath296 be functions .",
    "we say that @xmath295 has the @xmath83-eccp ( _ edge cover compactness property _ ) if , for every hypergraph @xmath297 , @xmath298 and fractional edge cover @xmath299 with @xmath300 , there exists a fractional edge cover @xmath301 with @xmath302 such that @xmath303 and @xmath304 with @xmath305 .",
    "@xmath167    in words , the @xmath83-eccp ensures that , for fixed @xmath6 , when we search for a function @xmath55 to cover the vertex set @xmath60 at some node in an fhd , we only need to consider functions @xmath55 that assign non - zero weight to constantly many edges .",
    "this property is exploited in the following theorem .",
    "[ theo : approxeccp ] let @xmath296 be functions and let @xmath72 be a class of hypergraphs enjoying the @xmath83-eccp .",
    "then there exists a polynomial - time algorithm that , given a hypergraph @xmath263 with @xmath68 , finds an fhd of @xmath0 of width @xmath306 .",
    "( sketch . )",
    "we propose an  alternating algorithm , which is inspired by the -algorithm for hds in @xcite .",
    "below we describe some crucial ideas of our algorithm .",
    "a detailed description of the algorithm and full proofs of the correctness and the membership are given in appendix  [ app : approx - algorithm ] .",
    "_ special condition .",
    "_ our algorithm only searches for fhds satisfying the special condition .",
    "we thus make use of a fundamental result in @xcite that every hypergraph @xmath0 with @xmath68 has an fhd satisfying the special condition and whose width is @xmath307 .    _ fractional normal form .",
    "_ the hd - algorithm in @xcite aims at computing a hd in a certain normal form , which imposes a condition strongly related to bag - maximality on the sets @xmath60 .",
    "unfortunately , such a bag - maximal normal form can not be ensured for fhds .",
    "we thus define our own fractional normal form , which is inspired by a normal form on hds in @xcite and which aims at a kind of _ bag - minimality_. the normal form in @xcite has several properties which are important to restrict the search for an hd in the alternating algorithm . by proving analogous results ,",
    "we make sure that our fractional normal form also provides a sufficiently strong restriction of the search space for our fhd - algorithm .",
    "_ restricting the candidate sets @xmath60 .",
    "_ in the existential step of the atm in @xcite , it suffices to guess the set @xmath229 of edges @xmath193 with @xmath202 .",
    "the set @xmath60 is then fully determined by the normal form . by the @xmath83-eccp",
    ", we can also restrict the set @xmath229 of edges with non - zero weight in @xmath55 .",
    "however , in principle , there still exists an unrestricted number of concrete mappings @xmath55 with this property .",
    "we therefore prove a decisive lemma which shows that we only need to consider @xmath308 many candidate mappings @xmath55 for some function @xmath181 ( i.e. , constantly many ) . with the help of our fractional normal form",
    ", we thus also get a restriction on the number of candidate sets @xmath60 .",
    "below we give a simple example of a class of hypergraphs which enjoys the @xmath83-eccp .",
    "we leave it as in interesting task for future work to identify further classes with this property .",
    "[ lem : eccpdegree ] let @xmath25 and let @xmath72 be a hypergraph class which has bounded rank bounded by @xmath309 . then @xmath72 has the @xmath83-eccp , where @xmath310 and @xmath311 .    by putting theorem [ theo : approxeccp ] and lemma [ lem : eccpdegree ] together , we get the following approximation result of @xmath12 .",
    "[ cor : approxrank ] let @xmath72 be a class of hypergraphs whose rank is bounded by some constant @xmath309 and let @xmath25 .",
    "then there exists a polynomial - time algorithm that , given a hypergraph @xmath263 with @xmath68 , finds an fhd of @xmath0 of width @xmath312 .",
    "theorem [ theo : approxeccp ] gives us an easy to use instrument for discovering tractable cases of linear approximation of the fractional hypertree width .",
    "actually , by taking additional properties of hypergraphs of bounded rank into account , the above corollary can even be further improved to a polynomial - time _ exact _",
    "algorithm for the problem .",
    "the details are worked out in appendix [ app : vc - and - eccp ] .",
    "in this paper we have settled the complexity of deciding @xmath82 for fixed constant @xmath9 , and of checking for generalized hypertree width for @xmath313 by proving these problems np complete .",
    "this gives negative answers to two long standing open problems . in a more positive vein ,",
    "we have identified rather mild restrictions such as the bip , bmip , and bounded vc dimension , that give rise to algorithms or at least approximations for the and problems . as our empirical tests reported in appendix [ app : empiricalstudy ] show , these restrictions are extremely well - suited for real - life instances of cqs and csps .",
    "we believe they deserve further attention .",
    "our work does not finish here .",
    "we plan to explore several further issues regarding the computation and approximation of the fractional hypertree width .",
    "we find the following questions particularly appealing : ( i ) does the special condition defined by grohe and marx  @xcite lead to tractable recognizability also for fhds , i.e. , in case we define `` _ sfhw@xmath314 _ '' as the smallest width an fhd of @xmath0 satisfying the special condition , can @xmath315 be recognized efficiently ?",
    "( ii ) what is the relationship between bip or bmip on the one hand and eccp on the other hand ? more specifically , can bip or bmip ( which we have seen to be a stronger restriction than bounded vc - dimension ) give a linear approximation of fhw ?   ( iii )",
    "can non - approximability results be obtained under reasonable complexity - theoretic assumptions ? ( iv )",
    "is it possible to find non - trivial and meaningful restrictions that ensure tractable recognizability of @xmath5 ?",
    "* appendix *",
    "a _ hypergraph _ is a pair @xmath29 , consisting of a set @xmath31 of _ vertices _ and a set @xmath32 of _ hyperedges _ ( or , simply _ edges _ ) , which are non - empty subsets of @xmath31 .",
    "we assume that hypergraphs do not have isolated vertices , i.e.  for each @xmath44 , there is at least one edge @xmath41 , s.t .",
    "@xmath203 . for a set @xmath316",
    ", we define @xmath317 and for a set @xmath318 , we define @xmath319 .    for a hypergraph @xmath0 and a set @xmath320 , we say that a pair of vertices @xmath321 is if there exists an edge @xmath41 such that @xmath322 .",
    "a @xmath120 from @xmath209 to @xmath272 consists of a sequence @xmath323 of vertices and a sequence of edges @xmath324 ( @xmath325 ) such that @xmath326 , for each @xmath327 $ ] .",
    "we denote by @xmath328 the set of vertices occurring in the sequence @xmath329 .",
    "likewise , we denote by @xmath330 the set of edges occurring in the sequence @xmath331 .",
    "a set @xmath332 of vertices is if @xmath333 there is a from @xmath209 to @xmath272 .",
    "a is a maximal , non - empty set of vertices @xmath334 .",
    "let @xmath89 be a hypergraph and consider functions @xmath335 and @xmath336 $ ] . recall that we have defined @xmath337 where @xmath35 .",
    "the weight of such a function @xmath38 is defined as @xmath338 we can also view @xmath339 as a set with @xmath340 and the weight as the cardinality of such a set of edges . for the sake of a uniform treatment with function",
    "@xmath299 we prefer to treat @xmath339 as a function as well .",
    "an _ edge cover _ ( ec ) of a hypergraph @xmath341 is a function @xmath33 such that @xmath342 .",
    "the _ edge cover number _ of @xmath0 , denoted by @xmath343 , is the minimum weight of all edge covers of @xmath0 .",
    "@xmath167    note that edge covers can be calculated by the following integer linear program .",
    "@xmath344 by relaxing the last condition of the integer linear program above , we arrive at the definition of fractional edge covers .",
    "actually , we substitute the last condition by @xmath345 .",
    "note that even though our weight function is defined to take values between 0 and 1 , we do not need to add @xmath346 as a constraint , because implicitly by the the minimization itself the weight on an edge for an edge cover is never greater than 1 .",
    "also note that now the program above is a linear program , which can be solved in , whereas finding an edge cover of weight @xmath20 is -complete .",
    "a _ fractional edge cover _",
    "( fec ) of a hypergraph @xmath347 is a function @xmath34 $ ] such that @xmath348 .",
    "the _ fractional edge cover number _ of @xmath0 , denoted by @xmath349 , is the minimum weight of all fractional edge covers of @xmath0 .",
    "we write @xmath350 to denote the set of edges with non - zero weight , i.e. , @xmath351 .",
    "@xmath167    clearly , we have @xmath352 for every hypergraph @xmath0 , and @xmath349 can possibly be much smaller than @xmath343 .",
    "however , below we give an example , which is important for our proof of theorem [ thm : npcomp ] and where @xmath349 and @xmath343 coincide .",
    "[ lem : cliquewidth ] let @xmath353 be a clique of size @xmath354",
    ". then @xmath355 .",
    "since we have to cover each vertex with weight @xmath356 , the total weight on the vertices of the graph is @xmath357 .",
    "as the weight of each edge adds to the weight of at most 2 vertices , we need at least weight @xmath80 on the edges to achieve @xmath357 weight on the vertices . on the other hand",
    ", we can use @xmath80 edges each with weight 1 to cover @xmath354 vertices .",
    "hence , in total , we get @xmath358 .",
    "we have already defined hypertree decompositions ( hds ) , general hypertree decompositions ( ghds ) , and fractional hypertree decompositions ( fhds ) as well as the corresponding notions @xmath15 , @xmath11 , and @xmath12 of width in section [ sect : introduction ] .",
    "note that these decompositions are based on another type of decompositions , namely _ tree decompositions _ ( tds ) .",
    "a td of @xmath0 is a tuple @xmath359 , such that @xmath40 is a rooted tree and the following conditions hold : the conditions ( 1 ) and ( 2 ) from the previous section hold .",
    "below we recall two fundamental properties of the various notions of decompositions and width .",
    "[ lem : subhypergraph ] let @xmath0 be a hypergraph and let @xmath268 be an induced subhypergraph of @xmath0 , then @xmath360 , @xmath361 , and @xmath362 hold .",
    "[ lem : clique ] let @xmath0 be a hypergraph",
    ". if @xmath0 has a subhypergraph @xmath268 such that @xmath268 is a clique , then every hd , ghd , or fhd of @xmath0 has a node @xmath53 such that @xmath363 .    strictly speaking ,",
    "lemma  [ lem : clique ] is a well - known property of tree decompositions  independently of the @xmath339- or @xmath299-label .",
    "let @xmath364 be an fhd and let @xmath53 be a node of @xmath46 , then @xmath52 denotes the subtree of @xmath46 rooted at @xmath53 .",
    "moreover , by slight abuse of notation , we shall write @xmath62 to denote that @xmath53 is a node in @xmath46 . for a set @xmath365",
    ", we define @xmath366 . for any node @xmath53 of @xmath46",
    ", we will often use @xmath53 as a synonym for @xmath60 .",
    "in particular , _ _ denotes ; likewise , is a synonym for ; and so on .",
    "further , we define @xmath367 , where @xmath53 is a node in @xmath46 .",
    "let @xmath368 be an fhd of @xmath0 of width @xmath20 , then a node @xmath53 is said to be _ full in @xmath125 _ ( or simply _ full _ , if @xmath125 is understood from the context ) , if for any vertex @xmath369 it is the case that @xmath370 @xmath167",
    "in this section , we give detailed proofs of lemma [ lem : gadgeth0 ] and theorem  [ thm : npcomp ] .",
    "_ let @xmath86 , @xmath87 be disjoint sets and @xmath88 .",
    "let @xmath89 be a hypergraph and @xmath90 @xmath91 a subhypergraph of @xmath0 with @xmath92 and @xmath93 where no element from the set @xmath94 occurs in any edge of @xmath95 .",
    "then , every fhd @xmath96 of width @xmath69 of h has nodes @xmath97 such that : _      observe that @xmath371 and @xmath372 form a clique of size 4 .",
    "hence , by lemma  [ lem : clique ] , there is a node @xmath102 , such that @xmath98 . by lemma  [ lem : cliquewidth ] we have that @xmath373 .",
    "now observe that @xmath102 is full : whenever we try to add a vertex @xmath374 or @xmath375 to @xmath376 , then ( with the given hyperedges of @xmath0 ) we need weight @xmath377 on edges not yet used to cover @xmath105 .",
    "the same holds for the cliques @xmath378 and @xmath379 .",
    "now , let @xmath101 be the node , such that @xmath380 and @xmath103 be the node , such that @xmath381 .",
    "then by the same argument as for @xmath102 also @xmath101 and @xmath103 are full .",
    "we now show that @xmath101 is on the path between @xmath102 and @xmath103 .",
    "suppose to the contrary that it is not .",
    "we distinguish two cases .",
    "first , assume that @xmath102 is on the path between @xmath101 and @xmath103 .",
    "by connectedness , @xmath382 , which contradicts the fact that @xmath102 is full .",
    "second , assume @xmath103 is on the path between @xmath102 and @xmath101",
    ". in this case , we have @xmath383 , which contradicts the fact that @xmath103 is full .",
    "it only remains to prove @xmath384 .",
    "first , let @xmath385 be the subgraph of @xmath46 induced by @xmath386 and let @xmath387 be the subgraph of @xmath46 induced by @xmath388 .",
    "we first show that each of the subgraphs @xmath385 and @xmath387 is connected ( i.e. , a subtree of @xmath46 ) and that the two subtrees are disjoint .",
    "the connectedness is immediate : by the connectedness condition , each of @xmath389 , @xmath390 , @xmath391 , and @xmath392 is connected .",
    "moreover , since @xmath0 contains an edge @xmath393 ( resp .",
    "@xmath394 ) , the two subtrees induced by @xmath389 , @xmath390 ( resp .",
    "@xmath391 , @xmath392 ) must be connected , hence @xmath385 and @xmath387 are subtrees of @xmath46 .",
    "it remains to show that @xmath385 and @xmath387 are disjoint .",
    "suppose to the contrary that they are not .",
    "then , there is a node @xmath53 in @xmath46 with @xmath395 for some @xmath73 and @xmath141 .",
    "we claim that @xmath53 must be on the path between @xmath102 and @xmath103 .",
    "suppose it is not .",
    "this means that either @xmath102 is on the path between @xmath53 and @xmath103 or @xmath103 is on the path between @xmath53 and @xmath102 . in the first case",
    ", @xmath376 has to contain @xmath396 by the connectedness condition .",
    "this contradicts the fact that @xmath102 is full . in the second case",
    ", @xmath397 has to contain @xmath398 , which contradicts the fact that @xmath103 is full .",
    "hence , @xmath53 is indeed on the path between @xmath102 and @xmath103 .",
    "we have already shown above that also @xmath101 is on the path between @xmath102 and @xmath103 . hence , there are two cases depending on how @xmath53 and @xmath101 are arranged on the path between @xmath102 and @xmath103 .",
    "first , assume @xmath53 is on the path between @xmath102 and @xmath101 .",
    "in this case , @xmath399 also contains @xmath396 , which contradicts the fact that @xmath101 is full .",
    "second , assume @xmath53 is on the path between @xmath101 and @xmath103",
    ". then @xmath399 has to contain @xmath398 , which again contradicts the fact that @xmath101 is full .",
    "thus , there can be no node @xmath53 in @xmath46 with @xmath395 for some @xmath73 , @xmath141 and therefore the subtrees @xmath385 and @xmath387 are disjoint and connected by a path containing @xmath101 .    clearly , as every edge must be covered , there are nodes in @xmath385 that cover @xmath400 and @xmath401 , respectively .",
    "hence , the subtree @xmath385 covers @xmath402 , i.e. , @xmath403 .",
    "likewise , @xmath387 covers @xmath122 .",
    "since both subtrees are disjoint and @xmath101 is on the path between them , by the connectedness condition , we have @xmath384 .",
    "the proof of -hardness is by a reduction from 3sat .",
    "below , we first describe the problem reduction , i.e. , given an arbitrary instance @xmath112 of 3sat , we will construct a hypergraph @xmath0 .",
    "for the correctness of this construction , we have to prove that @xmath113 if and only if @xmath111 if and only if @xmath112 is satisfiable .",
    "we will show the two directions of these equivalences separately , i.e. , on the one hand , we show @xmath113 @xmath406 @xmath112 is satisfiable and @xmath111 @xmath406 @xmath112 is satisfiable . on the other hand",
    ", we show @xmath113 @xmath407 @xmath112 is satisfiable and @xmath111 @xmath407 @xmath112 is satisfiable ;      * problem reduction . *",
    "we now state our reduction from 3sat .",
    "let @xmath408 be an arbitrary instance of 3sat with @xmath137 clauses and variables @xmath409 .",
    "we construct a hypergraph @xmath89 such that @xmath113 if and only if @xmath111 if and only if @xmath112 is satisfiable .    for @xmath410 , we denote @xmath411 by @xmath412 $ ] . for each @xmath413 $ ]",
    ", we denote by @xmath414 ( @xmath415 ) the successor ( predecessor ) of @xmath231 in the usual lexicographic order on pairs , that is , the order @xmath416 @xmath417 .",
    "we refer to the first element @xmath418 of such a set as @xmath419 and to the last element @xmath420 as @xmath421 .",
    "we denote by @xmath412 ^ -$ ] the set @xmath412\\setminus\\{\\max\\}$ ] , i.e.  @xmath412 $ ] without the last element .",
    "the hypergraph @xmath0 consists of two copies @xmath115 of the ( sub-)hypergraph @xmath104 of lemma  [ lem : gadgeth0 ] plus additional edges connecting @xmath104 and @xmath116 .",
    "we will use the sets @xmath126 and @xmath127 to encode the truth values of the variables of @xmath112 .",
    "we will denote by @xmath422 ( @xmath423 ) the set @xmath424 ( @xmath425 ) .",
    "furthermore , we use the sets @xmath426 \\}$ ] and @xmath427\\}$ ] . for subsets of @xmath428 or @xmath429 , we define the sets @xmath430 , @xmath431 , @xmath432 and @xmath433 as @xmath434    in addition , we will use another set @xmath229 of elements , that controls and restricts the ways in which edges are combined in a possible fhd @xmath435 .",
    "such an fhd will have , implied by lemma  [ lem : gadgeth0 ] , two nodes @xmath101 and @xmath123 in each possible @xmath46 such that @xmath436 and @xmath437 . from this",
    ", we will reason on the path connecting @xmath101 and @xmath123 .",
    "we now give a detailed construction of @xmath0 .",
    "let @xmath438 \\cup     \\{(0,1),(0,0),(1,0)\\}$ ] , hence @xmath30 is an extension of the set @xmath439 $ ] with special elements @xmath440 .",
    "now let @xmath229 be defined as @xmath441 an element in this set will be denoted by @xmath442 , thereby we split the 3 items into 2 groups .",
    "recall that the values @xmath443 are themselves pairs of integers @xmath444 .",
    "intuitively , @xmath445 indicates the position of a node in the `` long '' path @xmath120 in a desired fhd or ghd .",
    "the integer @xmath6 refers to a literal in the @xmath141-th clause while the values @xmath446 and @xmath377 of @xmath447 will be used to indicate `` complementary '' edges of hypergraph @xmath0 in a sense to be made precise later ( see definition  [ def : complementary ] ) .",
    "we will write the wildcard @xmath448 to indicate that a component in some element of @xmath229 can take an arbitrary value .",
    "if both @xmath6 and @xmath447 may take arbitrary values , then we will use the single symbol @xmath449 as a shorhand for @xmath450 .",
    "for example , @xmath451 denotes the set of tuples @xmath442 where @xmath452 and the pair @xmath453 can take an arbitrary value in @xmath454 .",
    "we will denote by @xmath455 the set @xmath456 .",
    "for instance , @xmath451 will be denoted as @xmath457 .",
    "further , for @xmath458 $ ] , @xmath459 , and @xmath460 , we define singleton sets @xmath461 as @xmath462        * let @xmath464 be the hypergraph of lemma  [ lem : gadgeth0 ] with @xmath465 , @xmath466 and @xmath467 , where we set @xmath468 and @xmath469 .",
    "* let @xmath470 be the corresponding hypergraph , where the set of basic nodes is @xmath471 @xmath472 and @xmath473 are the primed versions of the egde sets and @xmath474 and @xmath475 .    in the second step ,",
    "we define the edges which ( as we will see ) enforce the existence of a `` long '' path  @xmath120 between the nodes covering @xmath104 and the nodes covering @xmath116 in any ghd or fhd .",
    "we thus define the following edges :            [ bsp : nphardnessproof ] suppose that an instance of 3sat is given by the propositional formula @xmath486 , i.e. : we have @xmath487 variables and @xmath488 clauses . from this",
    "we construct a hypergraph @xmath89 .",
    "first , we instantiate the sets @xmath489 , and @xmath131 from our problem reduction .",
    "@xmath490 according to our problem reduction , the set @xmath31 of vertices of @xmath0 is defined as @xmath463    the set @xmath32 of edges of @xmath0 is defined in several steps .",
    "first , the edges in @xmath104 and @xmath116 are defined : we thus have the subsets @xmath491 , whose definition is based on the sets @xmath492 , @xmath493 , @xmath494 , and @xmath495 .",
    "the definition of the edges @xmath496 is straightforward .",
    "we concentrate on the edges @xmath497 and @xmath498 for @xmath499 and @xmath459 .",
    "these edges play the key role for covering the bags of the nodes along the `` long '' path @xmath120 in any fhd or ghd of @xmath0 . recall that this path can be thought of as being structured in 9 blocks .",
    "consider an arbitrary @xmath500 .",
    "then @xmath501 and @xmath502 encode the @xmath6-th literal of the first clause and @xmath503 and @xmath504 encode the @xmath6-th literal of the second clause ( the latter is only defined for @xmath505 ) .",
    "these edges are defined as follows : the edges @xmath506 and @xmath507 encode the first literal of the first clause , i.e. , the positive literal @xmath508 .",
    "we thus have @xmath509 the edges @xmath510 and @xmath511 encode the second literal of the first clause , i.e. , the negative literal @xmath512 .",
    "likewise , @xmath513 and @xmath514 encode the third literal of the first clause , i.e. , the positive literal @xmath515 .",
    "we thus have @xmath516 analogously , the edges @xmath517 and @xmath518 ( encoding the first literal of the second clause , i.e. , @xmath519 ) , the edges @xmath520 and @xmath521 ( encoding the second literal of the second clause , i.e. , @xmath522 ) , and the edges @xmath523 and @xmath524 ( encoding the third literal of the second clause , i.e. , @xmath525 ) are defined as follows : @xmath526 where @xmath527 with @xmath528 and @xmath459 is defined as the singleton @xmath529 . the crucial property of these pairs of edges @xmath530 and @xmath531 is that they together encode the @xmath6-th literal of the @xmath141-th clause in the following way : if the literal is of the form @xmath532 ( resp .  of the form @xmath533 )",
    ", then @xmath534 covers all of @xmath145 except for @xmath535 ( resp .",
    "except for @xmath536 ) .    clearly , @xmath112 is satisfiable , e.g. , by the truth assignment @xmath134 with @xmath537 true and @xmath538 false .",
    "hence , for the problem reduction to be correct , there must exist a ghd ( and thus also an fhd ) of width 2 of @xmath0 . in figure",
    "[ fig : decomppath ] , the tree structure @xmath46 plus the bags @xmath539 of such a ghd is displayed .",
    "moreover , in table  [ tab : np_decomp ] , the precise definition of @xmath540 and @xmath541 of every node @xmath542 is given .",
    "the set @xmath144 in the bags of this ghd is defined as @xmath543 true@xmath544 false@xmath17 . in this example , for the chosen truth assignment @xmath134 , we thus have @xmath545 . the bags @xmath540 and the edge covers @xmath541 for each @xmath542",
    "are explained below .",
    "the nodes @xmath546 to cover the edges of the subhypergraph @xmath104 and the nodes @xmath119 to cover the edges of the subhypergraph @xmath116 are clear by lemma [ lem : gadgeth0 ] .",
    "the purpose of the nodes @xmath53 and @xmath208 is mainly to make sure that each edge @xmath132 is covered by some bag .",
    "recall that the set @xmath144 contains exactly one of @xmath128 and @xmath129 for every @xmath73 .",
    "hence , the node @xmath53 ( resp .",
    "@xmath208 ) covers each edge @xmath132 , such that @xmath547 ( resp .",
    "@xmath147 ) .",
    "we now have a closer look at the nodes @xmath548 to @xmath549 on the `` long '' path @xmath120 .",
    "more precisely , let us look at the nodes @xmath550 and @xmath551 for some @xmath552 , i.e. , the `` @xmath73-th block '' .",
    "it will turn out that the bags at these nodes can be covered by edges from @xmath0 because @xmath112 is satisfiable . indeed , our choice of @xmath553 and @xmath554 is guided by the literals satisfied by the truth assignment @xmath134 , namely : for @xmath555 , we have to choose some @xmath556 , such that the @xmath556-th literal in the @xmath141-th clause is true in @xmath134 .",
    "for instance , we may define @xmath553 and @xmath554 as follows : @xmath557 the covers @xmath553 and @xmath554 were chosen because the first literal of the first clause and the third literal of the second clause are true in @xmath134 .",
    "now let us verify that @xmath553 and @xmath554 are indeed covers of @xmath558 and @xmath559 , respectively . by the definition of the edges @xmath560 for @xmath528 and @xmath459 , it is immediate that @xmath534 covers @xmath561 .",
    "the only non - trivial question is if @xmath555 also covers @xmath144 .",
    "recall that by definition , @xmath562 .",
    "our truth assignment @xmath134 sets @xmath563 true .",
    "hence , by our definition of @xmath144 , we have @xmath564 and @xmath565 .",
    "this means that @xmath566 indeed covers @xmath144 and , hence , all of @xmath558 .",
    "note that we could have also chosen @xmath567 , since also the second literal of the first clause ( i.e. , @xmath512 ) is true in @xmath134 . in this case",
    ", we would have @xmath568 and @xmath144 indeed does not contain @xmath569 .",
    "conversely , setting @xmath570 would fail , because in this case , @xmath571 since @xmath515 occurs positively in the first clause . on the other hand",
    ", we have @xmath572 by definition of @xmath144 , because @xmath573 false holds .",
    "checking that @xmath554 as defined above covers @xmath144 is done analogously .",
    "note that in the second clause , only the third literal is satisfied by @xmath134 .",
    "hence , setting @xmath574 is the only option to cover @xmath559 ( in particular , to cover @xmath144 ) .",
    "finally , note that @xmath134 as defined above is not the only satisfying truth assignment of @xmath112 .",
    "for instance , we could have chosen @xmath575 true . in this case",
    ", we would define @xmath576 and the covers @xmath555 would have to be chosen according to an arbitrary choice of one literal per clause that is satisfied by this assignment @xmath134 . @xmath167",
    "[ def : complementary ] let @xmath193 and @xmath215 be two edges from the hypergraph @xmath0 as defined before .",
    "we say @xmath215 is the _ complementary _ edge of @xmath193 ( or , simply , @xmath577 are complementary edges ) whenever      observe that for every edge in our construction that covers @xmath581 for some @xmath579 there is a complementary edge that covers @xmath582 , for example @xmath497 and @xmath498 , @xmath583 and @xmath584 , and so on .",
    "in particular note that there is no edge that covers @xmath229 completely .",
    "moreover , consider arbitrary subsets @xmath585 of @xmath229 , s.t .",
    "( syntactically ) @xmath586 is part of the definition of @xmath587 for some @xmath588 with @xmath589",
    ". then @xmath590 and @xmath591 are  disjoint .",
    "[ lem : compl_edge ] let @xmath592 be an fhd of width @xmath69 of the hypergraph @xmath0 constructed above . for every node @xmath53 with @xmath593 and every pair @xmath594 of complementary edges , the equality @xmath595 must hold .",
    "first , we try to cover @xmath596 and @xmath597 .",
    "for @xmath596 we have to put total weight  @xmath377 on the edges  @xmath598 , and to cover @xmath597 we have to put total weight  @xmath377 on the edges  @xmath599 , where @xmath600 ^ - \\mbox { and } 1 \\leq k \\leq 3\\ } \\cup \\ { e^0_{(0,0 ) } ,                     e^0_{\\max } , \\ { a_1,b_1 \\ } \\cup m_1 , \\ { b_1,c_1\\}\\cup m_1 , \\\\               &      \\{c_1,d_1\\}\\cup m_1 \\ }              \\cup \\{\\ { a'_1,b'_1 \\ } \\cup m'_1 , \\ { b'_1,c'_1\\}\\cup m'_1 ,                    \\{c'_1,d'_1\\}\\cup m'_1 \\ } \\\\       e^1 = \\ { e^{k,1}_p & \\mid p\\in [ 2n+3;m]^- \\mbox { and } 1 \\leq k \\leq 3\\ }   \\cup                     \\ { e^1_{(0,0 ) } ,                     e^1_{\\max } ,",
    "\\ { a_2,b_2 \\ } \\cup m_2 , \\ { b_2,c_2\\}\\cup m_2 , \\\\               &      \\{c_2,d_2\\}\\cup m_2 \\ }              \\cup \\ { \\ { a'_2,b'_2 \\ } \\cup m'_2 , \\ { b'_2,c'_2\\}\\cup m'_2 ,                    \\{c'_2,d'_2\\}\\cup m'_2 \\ }       \\end{aligned}\\ ] ] in order to also cover @xmath229 with weight 2 , we are only allowed to assign weights to the above edges .",
    "let @xmath601 be a subset of @xmath229 , s.t .",
    "@xmath602 , where @xmath603 .",
    "suppose @xmath604 . still , we need to put weight @xmath377 on the vertices in @xmath601 . in order to do so",
    ", we can put at most weight @xmath605 on the edges @xmath606 , which covers @xmath601 with weight at most @xmath605 . the only edge in @xmath599 that intersects @xmath601 is the complementary edge @xmath607 of @xmath608 .",
    "hence , we have to set @xmath609 .",
    "this holds for all edges @xmath610 .",
    "moreover , recall that both @xmath611 and @xmath612 hold .",
    "hence , we can not afford to set @xmath613 for some @xmath73 , since this would lead to @xmath614 .",
    "we thus have @xmath615 for every @xmath616 and its complementary edge @xmath617 .",
    "[ lem : covering ] let @xmath592 be an fhd of width @xmath69 of the hypergraph @xmath0 constructed above and let @xmath477 ^ -$ ] . for every node @xmath53 with @xmath618 , the condition @xmath619 holds for all edges @xmath193 in @xmath32 except for @xmath497 and @xmath498 with @xmath459 ,",
    "i.e.  the only way to cover @xmath620 with weight @xmath69 is by using only edges @xmath497 and @xmath498 with @xmath459 .    clearly , as in the proof of lemma  [ lem : compl_edge ] , to cover @xmath596 we have to put weight @xmath377 on the edges @xmath598 and to cover @xmath597 we have to put weight @xmath377 on the edges @xmath599 , where @xmath598 and @xmath599 are defined as in the proof of lemma  [ lem : compl_edge ] .",
    "since we have @xmath621 , we have to cover @xmath622 with the weight already on the edges @xmath598 and @xmath599 . in order to cover @xmath432",
    ", we have to put weight 1 on the edges @xmath623 , where @xmath624 notice that , @xmath625 and therefore @xmath626 .",
    "similar , in order to cover @xmath431 , we have to put weight 1 on the edges @xmath627 , where @xmath628 again , since @xmath629 , @xmath630 .",
    "it remains to cover @xmath631 . by lemma  [ lem : compl_edge ] , in order to cover @xmath229 , @xmath596 and @xmath597 , we have to put the same weight @xmath632 on complementary edges @xmath193 and @xmath215 .",
    "the only complementary edges in the sets @xmath627 and @xmath623 are edges of the form @xmath497 and @xmath498 with @xmath459 ; hence we are only allowed to use these edges .",
    "* proof of `` @xmath633''-direction .",
    "* we will first assume that @xmath112 is satisfiable .",
    "it suffices to show that then @xmath0 has a ghd of width @xmath69 , because @xmath634 holds .",
    "let @xmath134 be a satisfying truth assignment .",
    "let us fix for each @xmath635 , some @xmath636 such that @xmath637 .",
    "by @xmath638 , we denote the index of the variable in the literal @xmath639 , that is , @xmath640 or @xmath641 .",
    "for @xmath642 , let @xmath643 refer to @xmath556 and let @xmath644 refer to @xmath639 . finally , we let @xmath144 be the set @xmath645 .",
    "a ghd @xmath646 of width 2 for @xmath0 is constructed as follows .",
    "@xmath46 is a path @xmath103 , @xmath101 , @xmath102 , @xmath53 , @xmath647, ",
    ",@xmath648 , @xmath121 , @xmath123 , @xmath649 .",
    "the construction is illustrated in figure  [ fig : decomppath ] .",
    "the precise definition of @xmath60 and @xmath48 is given in table  [ tab : np_decomp ] .",
    "note that the ghd has width @xmath69 .",
    "we now show that @xmath650 is indeed a ghd of @xmath0 :    1 .   for each edge @xmath651 , there is a node @xmath62 , such that @xmath43 : * @xmath652 , * @xmath653 , * @xmath654 , * @xmath655 , * @xmath656 , * @xmath657 , * @xmath658 for @xmath477 $ ] , * @xmath659 or @xmath660 depending on @xmath144 , * @xmath661 for @xmath477 $ ] , * @xmath662 for @xmath477 $ ] , * @xmath663 , @xmath664 , * @xmath665 and @xmath666 . +",
    "all of the above inclusions can be easily verified in table  [ tab : np_decomp ] .",
    "2 .   for each vertex @xmath265",
    ", the set @xmath667 induces a connected subtree of @xmath46 : + again , it is easy to verify in table  [ tab : np_decomp ] that all vertices induce subpaths on @xmath46 .",
    "3 .   for each @xmath62 , @xmath176 : + the only inclusion which can not be easily verified in table  [ tab : np_decomp ] is @xmath668 .",
    "in fact , this is the only place in the proof where we make use of the assumption that @xmath112 is satisfiable .",
    "first , notice that the set @xmath669 is clearly a subset of @xmath670 .",
    "it remains to show that @xmath671 .",
    "assume that @xmath672 , for some @xmath477 ^ -$ ] .",
    "thus , @xmath673 and therefore @xmath674 .",
    "but , by definition of @xmath675 and @xmath676 , vertex @xmath677 is the only element of @xmath145 not contained in @xmath670 . since @xmath678 and @xmath674",
    ", we have that @xmath671 .",
    "it remains to consider the case @xmath679 , for some @xmath477 ^ -$ ] .",
    "thus , @xmath680 and therefore @xmath681 .",
    "but , by definition of @xmath675 and @xmath676 , vertex @xmath682 is the only element of @xmath145 not contained in @xmath670 .",
    "since @xmath678 and @xmath681 , we have that @xmath671 .",
    "rrrrrr + & & & & & + 0 & 0 & 0 & 596 & 597 & 0 + 1 & 0 & 1036 & 465 & 492 & 0 + 2 & 596 & 59 & 34 & 7 & 1070 + 3 & 1 & 0 & 1 & 0 & 26 + 4 & 1 & 0 & 0 & 0 & 0 + 5 & 2 & 0 & 0 & 0 & 0 + @xmath6835 & 496 & 1 & 0 & 0 & 0 +    rrrrrr + & & & & & + 0 & 0 & 0 & 0 & 0 & 0 + 1 & 0 & 200 & 200 & 244 & 0 + 2 & 0 & 300 & 312 & 401 & 220 + 3 & 0 & 0 & 148 & 96 & 515 + 4 & 12 & 184 & 160 & 96 & 57 + 5 & 8 & 96 & 14 & 1 & 71 + @xmath6835 & 843 & 83 & 29 & 25 & 0 +      the csp instances were taken from the website @xcite .",
    "this site not only contains programs for parsing and solving csp instances , but also hosts a huge collection of csp instances .",
    "their interface allowed us to filter and download instances that can be easily represented as hypergraphs .",
    "we have selected and downloaded only csp instances that have less than 100 constraints which are all extensional . in this way",
    ", we have still got 1,959 instances . for the purpose of our evaluation",
    "we have divided them into instances from concrete applications ( 1,096 instances ) and randomly generated instances ( 863 instances ) .",
    "a summary of the properties of the hypergraphs of these csps is given in table  [ tab : cspstats ] .",
    "* concrete applications*. even though 496 ( 45.3% ) hypergraphs from the concrete application instances have a high degree ( @xmath6835 ) , nearly all instances have bip or bmip of less than 3 .",
    "most instances have a vc - dim of 2 .    *",
    "random instances*. nearly all random instances have a significantly higher degree ( 843 out of 863 instances with a degree @xmath6835 ) .",
    "nevertheless , in contrast to the high degree , many instances have small bip and bmip . for nearly all hypergraphs ( 837 out of 863 )",
    "it is the case that for bmip with intersections of 4 edges the @xmath684 .",
    "none of the instances has a vc - dimension greater than 5 .",
    "m.  aref , b.  ten cate , t.  j. green , b.  kimelfeld , d.  olteanu , e.  pasalic , t.  l. veldhuizen , and g.  washburn . design and implementation of the logicblox system . in _ proceedings of sigmod 2015",
    "_ , pages 13711382 .",
    "acm , 2015 .                h.  chen and v.  dalmau . beyond hypertree",
    "width : decomposition methods without decompositions . in _ proceedings of cp 2005",
    "_ , volume 3709 of _ lecture notes in computer science _ , pages 167181 .",
    "springer , 2005 .",
    "v.  dalmau , p.  g. kolaitis , and m.  y. vardi .",
    "constraint satisfaction , bounded treewidth , and finite - variable logics .",
    "in _ proceedings of cp 2002 _ , volume 2470 of _ lecture notes in computer science _ , pages 310326 .",
    "springer , 2002 ."
  ],
  "abstract_text": [
    "<S> hypertree decompositions , as well as the more powerful generalized hypertree decompositions ( ghds ) , and the yet more general fractional hypertree decompositions ( fhd ) are hypergraph decomposition methods successfully used for answering conjunctive queries and for the solution of constraint satisfaction problems . </S>",
    "<S> each hypergraph @xmath0 has a width relative to each of these decomposition methods : its hypertree width @xmath1 , its generalized hypertree width @xmath2 , and its fractional hypertree width @xmath3 , respectively . </S>",
    "<S> while @xmath4 can be checked in polynomial time , the complexity of checking whether @xmath5 holds for a fixed constant @xmath6 was unknown and was stated by grohe and marx ( soda 2006 ) as an important open problem . </S>",
    "<S> we settle this problem by proving that checking whether @xmath5 is np - complete , even for @xmath7 . </S>",
    "<S> the same construction settles another problem by showing that deciding whether @xmath8 is np complete for @xmath9 . </S>",
    "<S> hardness was previously known for @xmath10 only , whilst the case @xmath7 has remained open since 2001 .    after proving these hardness results , </S>",
    "<S> we investigate meaningful restrictions , for which checking for bounded @xmath11 is easy . in particular , we study classes of hypergraphs that enjoy the bounded edge - intersection property ( bip ) and the more general bounded multi - edge intersection property ( bmip ) . for such classes , for each constant @xmath6 , checking whether @xmath8 , and if so , computing a ghd of width @xmath6 of @xmath0 is tractable and actually fpt with respect to certain intersection parameters . </S>",
    "<S> finally we derive some approximability results for @xmath12 . </S>",
    "<S> we consider classes of hypergraphs whose @xmath12 is bounded by a constant @xmath6 , which , moreover , enjoy the bip or mip , or bounded vc - dimension . </S>",
    "<S> for each hypergraph in such a class , we are able to compute an fhd of width @xmath13 efficiently . </S>",
    "<S> we define a different restriction on classes of hypergraphs to achieve a linear approximation in ptime . </S>",
    "<S> hypergraphs of bounded rank are a simple example of such a class . </S>"
  ]
}