{
  "article_text": [
    "cloud radio access network ( c - ran ) is an emerging architecture for the fifth - generation ( 5 g ) of wireless system , in which a centralized baseband signal processing unit ( bbu ) implements the baseband processing functionalities of a set of remote radio heads ( rrhs ) , which are connected to the bbu by means of fronthaul links @xcite-@xcite . in the digital fronthauling adopted by the common public radio interface ( cpri ) specification @xcite , the bbu quantizes and compresses the encoded baseband signals prior to the transfer to the rrhs ( see , e.g. , @xcite-@xcite ) .",
    "recently , an evolved network architecture , referred to as _ fog radio access network _ ( f - ran ) , has been proposed , which enhances the c - ran architecture by allowing the rrhs to be equipped with storage and signal processing functionalities @xcite-@xcite .",
    "the resulting rrhs are referred to here as _ enhanced rrhs _ ( errhs ) . in an f - ran",
    ", edge caching can be performed to pre - fetch the most frequently requested files to the errhs local caches , as illustrated in fig .",
    "[ fig : system - model ] . in this way",
    ", fronthaul overhead can be reduced and higher spectral efficiencies or lower delivery latency can be obtained .",
    "it is emphasized that , unlike c - ran @xcite , the goal of the f - ran architecture is not that of minimizing the deployment and operating costs by means of reduced - complexity edge nodes , but rather that of maximizing the system performance in terms of delivery rate by leveraging both _ cloud ( bbu ) and edge ( caching ) resources _ @xcite-@xcite .    as a cache - aided system ,",
    "an f - ran operates in two phases , namely the pre - fetching and the delivery phases @xcite-@xcite ( see also @xcite@xcite ) .",
    "pre - fetching operates at the large time scale corresponding to the period in which content popularity remains constant .",
    "this time scale encompasses multiple transmission intervals , as seen in fig .",
    "[ fig : time - scale ] . based on the cached file messages , the delivery phase , instead , operates separately on each transmission interval .",
    "* related works : * in @xcite , the fronthaul - aware design of the pre - fetching policy was studied with the aim of minimizing the average delivery latency while satisfying the cache memory constraints . since the optimization problem turns out to be a mixed integer nonlinear program , the authors obtained a difference - of - convex ( dc ) problem by means of smooth approximation and integer relaxation , and proposed a successive convex approximation algorithm . in @xcite ,",
    "the authors consider the joint design of cooperative beamforming and errh clustering for the delivery phase , under an arbitrary fixed pre - fetching strategy , with the goal of minimizing the network cost , which is defined as the sum of transmit power and backhaul cost , under quality - of - service constraints .",
    "a similar problem was tackled in @xcite by assuming that coded , instead of uncoded , caching is exploited ( see also @xcite ) . in @xcite ,",
    "a stochastic geometry - based analysis is provided of a specific hybrid caching strategy ( see sec .",
    "ii - b ) ) .",
    "reference @xcite proposes a hypergraph - based framework to obtain first - order quantitative insights into the performance of an f - ran architecture without the need to perform the non - convex optimization studied in @xcite-@xcite .",
    "an information - theoretic framework for the analysis of latency in f - rans is developed in @xcite .",
    "illustration of an f - ran , which has both cloud and edge processing capabilities : the bbu , in the `` cloud '' , can perform joint baseband processing and the errhs are equipped with local caches.,width=498,height=283 ]    * main contributions : * in all the references @xcite-@xcite summarized above , the fronthaul links in an f - ran are leveraged in a _ hard - transfer mode _ to convey to the errhs the requested content that is not present in the local caches .",
    "in contrast , in this work , we consider not only the mentioned hard - transfer mode , but also a novel _ soft - transfer mode _ for the use of the fronthaul links .",
    "the proposed approach is based on fronthaul quantization and superposition coding : each errh transmits the superposition of two signals , one that is locally encoded based on the content of the cache and another that is encoded at the bbu and quantized for transmission on the fronthaul link .",
    "specifically , we study the joint design of cloud and edge processing for the delivery phase of an f - ran for an arbitrary pre - fetching strategy by considering hard - transfer and soft - transfer fronthauling strategies . for both fronthauling modes",
    ", we tackle the problem of optimizing cloud and edge processing , i.e. , processing at the bbu and at the errhs , with the goal of maximizing the delivery rate while satisfying fronthaul capacity and per - errh power constraints .",
    "furthermore , to reap the advantages of the two fronthauling approaches , we also propose a hybrid design of hard- and soft - transfer modes , which is akin to @xcite , where it was studied in the absence of caching .",
    "numerical results are provided to compare the performance of hard- and soft - transfer fronthauling modes , as well as the hybrid scheme , for baseline pre - fetching strategies .",
    "the rest of the paper is organized as follows .",
    "we describe the system model in sec . [",
    "sec : system - model ] and review some baseline pre - fetching strategies in sec .",
    "[ sec : pre - fetching ] .",
    "we discuss the design of delivery phase under hard - transfer fronthaul mode in sec .",
    "[ sec : hard - transfer ] and then propose a novel soft - transfer strategy in sec . [",
    "sec : soft - transfer ] .",
    "a hybrid design of hard- and soft - transfer modes is studied in sec .",
    "[ sec : hybrid - fronthauling ] , and extensive numerical results are presented in sec .",
    "[ sec : numerical - results ] .",
    "we close the paper with some concluding remarks in sec . [",
    "sec : conclustion ]",
    ".    _ notation _ : we adopt standard information - theoretic definitions for the mutual information @xmath0 between the random variables @xmath1 and @xmath2 @xcite . the circularly symmetric complex gaussian distribution with mean @xmath3 and covariance matrix @xmath4 is denoted by @xmath5 .",
    "the set of all @xmath6 complex matrices is denoted by @xmath7 , and @xmath8 represents the expectation operator . the operation",
    "@xmath9 denotes hermitian transpose of a matrix or vector , and @xmath10 is defined as @xmath11 for a binary variable @xmath12 . for a scalar @xmath13 , @xmath14 denotes the largest integer not larger than @xmath13 .",
    "illustration of the time scales of pre - fetching and delivery phases.,width=453,height=113 ]    as illustrated in fig .",
    "[ fig : system - model ] , we consider the downlink of an f - ran , where @xmath15 multi - antenna user equipments ( ues ) are served by @xmath16 multi - antenna errhs that are connected to a bbu in the `` cloud '' through digital fronthaul links .",
    "in addition to the functionalities performed by conventional rrhs in c - ran , such as upconversion and rf transmission , each errh @xmath17 in an f - ran is equipped with a cache , which can store @xmath18 bits , where @xmath19 is the number of ( baud - rate ) symbols of each downlink coded transmission block .",
    "furthermore , it also has baseband processing capabilities .",
    "each errh @xmath17 is connected to the bbu with a fronthaul link of capacity @xmath20 bit per symbol of the downlink channel for @xmath21 .",
    "we denote the numbers of antennas of errh @xmath17 and ue @xmath22 by @xmath23 and @xmath24 , respectively , and define the notations @xmath25 and @xmath26 .",
    "we consider communication for content delivery via the outlined f - ran system . accordingly ,",
    "ues request contents , or files , from a library of @xmath27 files , each of size @xmath28 bits , which are delivered by the network across a number of transmission intervals ( see fig .",
    "[ fig : time - scale ] ) . labeling the files in order of popularity ,",
    "the probability @xmath29 of a file @xmath30 to be selected is defined by zipf s distribution ( see , e.g. , @xcite-@xcite ) @xmath31 for @xmath32 , where @xmath33 is a given popularity exponent and @xmath34 is set such that @xmath35 .",
    "note that , as the exponent @xmath36 increases , the popularity distribution becomes more skewed towards the most popular files .",
    "each ue @xmath22 requests file @xmath37 with the probability ( [ eq : zipf - distribution ] ) , and the requested files @xmath38 are independent across the index @xmath22 .    assuming flat - fading channel , the baseband signal @xmath39 received by ue @xmath22 in each transmission interval is given as @xmath40 where @xmath41 is the baseband signal transmitted by errh @xmath17 in a given downlink discrete channel use , or symbol ; @xmath42 denotes the channel response matrix from errh @xmath17 to ue @xmath22 ; @xmath43 is the additive noise distributed as @xmath44 for some covariance matrix @xmath45 ; @xmath46\\in\\mathbb{c}^{n_{u , k}\\times n_{r}}$ ] collects the channel matrices @xmath47 from each errh @xmath17 to any ue @xmath22 ; and @xmath48\\in\\mathbb{c}^{n_{r}\\times1}$ ] is the signal transmitted by all the errhs .",
    "we assume that each errh @xmath17 is subject to the average transmit power constraint stated as @xmath49 furthermore , the channel matrices @xmath50 are assumed to remain constant during each transmission interval and to be known to the bbu and errhs . the robust design with imperfect csi or via alternating distributed optimization @xcite is out of the scope of this work .",
    "the system operates in two phases , namely pre - fetching and delivery ( see , e.g. , @xcite ) .",
    "pre - fetching operates at a large time scale corresponding to the period in which file popularity remains constant .",
    "this time scale encompasses multiple transmission intervals as illustrated in fig .",
    "[ fig : time - scale ] .",
    "the delivery phase operates separately on each transmission interval .",
    "we assume that files are transmitted in successive transmission intervals , until all current requests are satisfied , i.e. , ue @xmath22 successfully decodes the requested file @xmath38 for all @xmath51 . then , new requests @xmath52 are considered and the corresponding files are transmitted .    in the * pre - fetching phase * , each errh @xmath17 downloads and stores up to @xmath18 bits from the library of files , which is of size @xmath53 bits ( see fig .",
    "[ fig : system - model ] ) .",
    "we define the _ fractional caching capacity _ @xmath54 of errh @xmath17 as @xmath55 accordingly , each errh can potentially store a fraction @xmath54 of each file ( see @xcite@xcite@xcite ) .",
    "different standard pre - fetching policies will be considered as detailed in sec .",
    "[ sec : pre - fetching ] . note that pre - fetching strategies can not be adapted to the channel matrices or requested file profile @xmath52 in each transmission interval .    in the * delivery phase * , the errhs transmit in the downlink in order to deliver the requested files @xmath56 to the ues .",
    "the transmitted signal @xmath57 of each errh @xmath17 is obtained as a function of the information stored in its local cache , as well as of the information received from the bbu on the fronthaul link .",
    "we consider two different approaches depending on the type of the information transferred on the fronthaul links : _ hard - transfer fronthauling _ and _ soft - transfer fronthauling_. in the former , the fronthaul links are used for the transfer of hard information regarding the missing files that are not cached by the errhs as in @xcite-@xcite ; while , with the soft - transfer mode , the fronthaul links transfer quantized version of the precoded signals for the missing files , in line with the c - ran paradigm .",
    "soft- and hard - mode fronthauling strategies were compared for c - ran systems , i.e. , with no caching , in terms of achievable rates under an ergodic fading channel model in @xcite and in terms of energy expenditure in @xcite . in the next sections ,",
    "we detail separately the pre - fetching and delivery phases .",
    "moreover , for the delivery phase , we will consider separately operations with hard- and soft - transfer fronthauling , and also with a hybrid scheme that combines the advantages of the two fronthauling approaches .",
    "the pre - fetching policy chooses @xmath18 bits out of the library of @xmath53 bits to be stored in the cache of errh @xmath17 .",
    "different policies for caching can be considered , including coded caching @xcite@xcite .",
    "the pre - fetching strategy is determined based only on long - term state information about the popularity distribution @xmath29 , as well as on the cache memory sizes @xmath58 , file size @xmath28 and the fronthaul capacities @xmath59 .",
    "illustration of the pre - fetching phase for an example with @xmath60 errhs.,width=453,height=264 ]    in this paper , as in @xcite@xcite@xcite , we limit our attention to uncoded strategies . to this end , for the sake of generality , we assume that each file @xmath30 is split into @xmath61 subfiles @xmath62 such that each subfile @xmath63 is of size @xmath64 bits with @xmath65 and @xmath66 ( see , e.g. , ( * ? ? ?",
    "then , the pre - fetching strategy can be modeled by defining binary caching variables @xmath67 as @xmath68 while satisfying the cache memory constraint at errh @xmath17 as @xmath69 fig .",
    "[ fig : caching - variable ] illustrates an example .    while the problem formulation to be given in later sections applies to any choice of pre - fetching variables ( [ eq : caching - variable - definition ] ) , the following subsections discuss three explicit standard pre - fetching strategies that will be considered in sec .",
    "[ sec : numerical - results ] for numerical performance evaluation . for the rest of this section",
    ", we set @xmath70 for @xmath71 in order to avoid a more cumbersome notation .",
    "we first consider a pre - fetching strategy in which all errhs cache the same @xmath72 most popular files , namely @xmath73 , where @xmath72 is given as @xmath74 in order to satisfy the cache constraints .",
    "this approach , which was also considered in ( * ? ? ?",
    "v ) , is expected to be a good choice when the parameter @xmath36 of the distribution @xmath29 is large , i.e. , when only a few popular files are frequently requested by ues .",
    "we obtain it by setting @xmath75 and @xmath76 we refer to this strategy as cache most popular ( cmp ) .",
    "when the parameter @xmath36 is small , it may be advantageous to store as many distinct files as possible in the caches .",
    "thus , we also consider a pre - fetching strategy where errh 1 stores files @xmath77 ; errh 2 stores files @xmath78 ; and so on , until caches are full .",
    "this pre - fetching strategy , referred to as cache distinct ( cd ) , is obtained by choosing @xmath75 and @xmath79 the number @xmath72 of files that can be stored in each cache is again @xmath74 .",
    "unlike cmp , cd does not enable cooperative transmission from multiple errhs based only on the content of the caches , since each file can not be stored by multiple errhs . to address this issue , which can be significant",
    "if the fronthaul capacities @xmath20 are small , we consider a fractional cache distinct ( fcd ) pre - fetching strategy , where each file @xmath30 is split into multiple subfiles , i.e. , @xmath80 , and distributed over the errhs as described below .      in this case",
    ", there is not enough caching capacity to store all files .",
    "each file @xmath30 is then split into @xmath82 disjoint subfiles , i.e. , @xmath83 , so that the first @xmath16 fragments @xmath84 are distributed over errhs chosen randomly without replacement , while the last fragment @xmath85 is not cached . to this end ,",
    "the sizes of the files are set to @xmath86 and @xmath87 for @xmath88 and @xmath89 , respectively .",
    "this policy can be implemented by setting the caching variables @xmath90 to @xmath91 where @xmath92 are obtained as random permutations of the numbers @xmath93 , which are independent across the file index @xmath30 .",
    "randomized caching was also considered in ( * ? ? ?",
    "v ) without file splitting , i.e. , with @xmath75 .      in this case , errhs can potentially store overlapping fragments of all files .",
    "each file @xmath30 is split into @xmath16 disjoint subfiles , i.e. , @xmath95 , each of equal size @xmath96 .",
    "each cache can hence store up to @xmath97 segments of each file . to populate the caches",
    ", we divide each cache into @xmath97 disjoint parts each of @xmath64 bits .",
    "each part @xmath98 across all errhs is populated by means of a random permutation of the errhs indices for each file as discussed above , with the caveat that we exclude permutations by which an errh would store a segment @xmath63 more than once .",
    "we close this section with two remarks .",
    "first , a hybrid cmp and fcd caching policy was proposed in @xcite , whereby part of the cache of each errh is used to cache the same most popular files and the rest is instead leveraged to store distinct fragments of less popular files .",
    "the second remark is that the optimization of pre - fetching strategy based on long - term state information could be addressed by adopting stochastic optimization techniques ( see , e.g. , @xcite ) , but here we leave this challenging aspect as an interesting open problem .",
    "for a given pre - fetching strategy , in this section , we consider the design of the delivery phase in each transmission interval under the hard - transfer fronthaul mode , where the fronthaul links are used to transfer hard information of subfiles that are not cached by errhs .",
    "this mode was also considered in @xcite-@xcite .",
    "the formulation considered here is akin to that of @xcite , with the difference that in this paper we study the maximization of the delivery rate under fronthaul capacity constraints , rather than the minimization of a compound cost function that includes both downlink power and fronthaul capacity as in @xcite .",
    "the analysis of hard - mode fronthaul is included here mostly for the purpose of comparison with the soft - transfer mode .",
    "we allow any subfile @xmath63 to be delivered to the ue at a rate @xmath99 , so that @xmath100 bits are transmitted to the ue in the given transmission interval .",
    "the remaining @xmath101 bits can then be sent in the following transmission intervals by solving a similar optimization problem .",
    "our goal is that of maximizing the rates @xmath102 that can be transmitted on a per - transmission interval basis .",
    "hard - mode fronthauling requires the determination of the set of errhs to which each subfile @xmath63 is transferred on the fronthaul link .",
    "we do this by defining the binary variable @xmath103 as @xmath104 the fronthaul capacity constraint for each errh @xmath17 is stated as @xmath105    based on the cached or transferred subfiles @xmath63 with @xmath106 or @xmath107 , respectively , each errh @xmath17 performs channel encoding to produce the encoded baseband signal @xmath57 . denoting as @xmath108 the set of subfiles available at errh @xmath17",
    ", the errh performs linear precoding as in @xcite to obtain the transmitted signal @xmath57 as @xmath109 where @xmath110 is the precoding matrix for the baseband signal @xmath111 that encodes the subfile @xmath63 and is distributed as @xmath112 .    with ( [ eq : linear - precoding - hard ] ) , the received signal @xmath113 in ( [ eq : received - signal ] )",
    "can be written as @xmath114 where the aggregated precoding matrix @xmath115 for subfile @xmath63 is defined as @xmath116.\\label{eq : aggregated - precoding - matrix - hard}\\ ] ] in ( [ eq : received - signal - hard ] ) , the first term is the desired signal to be decoded by the receiving ue @xmath22 , and the second term is the superposition of the interference signals encoding the files requested by the other ues .",
    "we assume that , based on ( [ eq : received - signal - hard ] ) , each ue @xmath22 performs successive interference cancellation ( sic ) decoding . without loss of generality",
    ", we consider the decoding order @xmath117 so that the rate @xmath118 of the subfile @xmath119 is bounded as @xmath120 where we defined the notation @xmath121 .",
    "we aim at maximizing the minimum - user rate @xmath122 defined as @xmath123 while satisfying per - errh fronthaul capacity and power constraints , where @xmath124 denotes the achievable delivery rate for file @xmath30 .",
    "we recall from our discussion above that maximizing @xmath122 is instrumental in reducing the number of transmission intervals needed to deliver all the files @xmath125 to the requesting ues .",
    "the problem is stated as    [ eq : problem - hard - original ] @xmath126    where we define the matrix @xmath127 containing zero entries except for the rows from @xmath128 to @xmath129 containing the identity matrix of size @xmath23 , and the notation @xmath130 . in the problem ,",
    "the constraint ( [ eq : problem - hard - original - file - size - constraint ] ) imposes that the rate @xmath102 of each subfile be limited by the subfile size @xmath131 , and the constraint ( [ eq : problem - hard - original - power - constraint ] ) is equivalent to the per - errh power constraints ( [ eq : per - errh - power - constraint ] ) within the precoding model ( [ eq : linear - precoding - hard ] ) .",
    "we emphasize that in ( [ eq : problem - hard - original ] ) , the pre - fetching variables ( [ eq : caching - variable - definition ] ) and the fronthaul transfer variables ( [ eq : assignment - variable - definition ] ) are fixed .",
    "the solution of problem ( [ eq : problem - hard - original ] ) is made difficult by the non - convexity in the constraint ( [ eq : problem - hard - original - rate - constraint ] ) . here , noting that the left - hand side of ( [ eq : problem - hard - original - rate - constraint ] ) has the dc structure when stated in terms of the covariance matrices @xmath132 , as in @xcite@xcite@xcite , we adopt the concave - convex procedure ( cccp ) for tackling ( [ eq : problem - hard - original ] ) .",
    "specifically , we address problem ( [ eq : problem - hard - original ] ) with optimization variables @xmath133 by relaxing the rank constraints @xmath134 .    the resulting algorithm is described in algorithm 1 , where the function @xmath135 is defined as @xmath136 with the notation @xmath137 . after the convergence of the algorithm , each precoding matrix @xmath138 is obtained as @xmath139 , where @xmath140 takes the @xmath141 leading eigenvectors of the matrix @xmath142 as its columns , @xmath143 is a vector whose elements are given as the corresponding eigenvalues , and each precoding matrix @xmath144 for errh @xmath17 can be obtained as @xmath145 .",
    "we refer to @xcite for a discussion of known results on the convergence of cccp .",
    "we also note that , an alternative approach , not based on rank relaxation , would be to use successive convex approximation methods @xcite based on lower bounds obtained from fenchel duality ( see , e.g. , @xcite ) .",
    "initialize the matrices @xmath146 to arbitrary positive semidefinite matrices that satisfy the per - errh power constraints ( [ eq : problem - hard - original - power - constraint ] ) and set @xmath147 .",
    "* update the matrices @xmath148 as a solution of the following convex problem :    [ eq : problem - hard - dc ] @xmath149    * 3 . *",
    "stop if a convergence criterion is satisfied .",
    "otherwise , set @xmath150 and go back to step 2 .",
    "unlike the hard - transfer mode that uses the fronthaul links to transfer hard information on missing files , in the soft - transfer mode typical of c - ran , the fronthaul links are used to transfer a quantized version of the precoded signals of the missing files .",
    "accordingly , the signal @xmath57 transmitted by errh @xmath17 on the downlink channel is given as the superposition of two signals , one that is locally encoded based on the content in the cache and another that is encoded at the bbu and quantized for transmission on the fronthaul link .",
    "this yields @xmath151 where @xmath110 is the precoding matrix for the baseband signal @xmath152 encoding the cached file @xmath63 , while @xmath153 represents the quantized baseband signal received from the bbu on the fronthaul link .",
    "note that in a c - ran , the transmitted signal would be given solely by the quantized signal @xmath153 , which is discussed next .",
    "the bbu precodes the subfiles that are not stored in each errh @xmath17 producing the signal @xmath154 where @xmath155 is the precoding matrix for the baseband signal @xmath152 that encodes the fragment @xmath63 not available at errh @xmath17 .",
    "the signal ( [ eq : precoding - bbu - soft ] ) is quantized , obtaining the signal @xmath153 as @xmath156 where @xmath157 denotes the quantization noise independent of @xmath158 and distributed as @xmath159 with the covariance matrix @xmath160 .",
    "the signals @xmath158 and @xmath161 for different errhs @xmath162 are quantized independently so that the quantization noise signals @xmath157 and @xmath163 are independent @xcite and @xmath161 for different errhs @xmath162 to be jointly quantized , hence obtaining correlated quantization noises",
    ". we do not further pursue the application of multivariate compression here , although its inclusion in the analysis could be carried out in a similar manner . ] . using standard information theoretic results ( see , e.g. , ( * ? ? ?",
    "3 ) ) , the signal @xmath153 can be reliably recovered by errh @xmath17 if the condition @xmath164 is satisfied , where we define the notations @xmath165 and @xmath166 .    with ( [ eq : transmitted - signal - soft - transfer ] ) , the signal @xmath113 received by ue @xmath22 in ( [ eq : received - signal ] )",
    "can be written as @xmath167 where we defined the aggregated precoding matrix @xmath168 $ ] for subfile @xmath63 with @xmath169 and the quantization noise vector @xmath170 $ ] distributed as @xmath171 with @xmath172 .",
    "similar to the case with hard - transfer fronthauling , we assume that ue @xmath22 performs sic decoding based on ( [ eq : received - signal - soft ] ) with the decoding order @xmath117 , so that the rate @xmath118 of the subfile @xmath119 is bounded as @xmath173 where we defined the notation @xmath121 .      as in sec .",
    "[ sub : problem - formulation - hard ] , we aim at maximizing the minimum - user rate @xmath123 subject to per - errh fronthaul capacity and transmit power constraints .",
    "the problem is stated as    [ eq : problem - soft - original ] @xmath174    where the function @xmath175 is defined , with a small abuse of notation , from ( [ eq : fronthaul - constraint - soft ] ) , as @xmath176 given that , if @xmath177 , then @xmath178 .    as for problem ( [ eq : problem - hard - original ] ) , we tackle ( [ eq : problem - soft - original ] ) by means of the cccp approach as applied to a rank - relaxed version of ( [ eq : problem - hard - original ] ) , where the optimization variables are given as @xmath179 and the rank constraints @xmath134 are relaxed .",
    "the resulting algorithm is detailed in algorithm 2 , where we defined the functions @xmath180 after the convergence of the algorithm , each precoding matrix @xmath138 is obtained as @xmath139 as in sec .",
    "[ sub : problem - formulation - hard ] .",
    "initialize the matrices @xmath146 and @xmath181 to arbitrary positive semidefinite matrices that satisfy the per - errh fronthaul capacity constraints ( [ eq : problem - soft - original - fronthaul - constraint ] ) and power constraints ( [ eq : problem - soft - original - power - constraint ] ) and set @xmath147 .    *",
    "2 . * update the matrices @xmath148 and @xmath182 as a solution of the following convex problem :    [ eq : problem - soft - dc ] @xmath183    * 3 . *",
    "stop if a convergence criterion is satisfied .",
    "otherwise , set @xmath150 and go back to step 2 .",
    "in this section , we consider the design of a hybrid hard- and soft - transfer mode fronthauling scheme , whereby , unlike the strategies discussed in sec .",
    "[ sec : hard - transfer ] and sec .",
    "[ sec : soft - transfer ] , the capacity of each fronthaul link is generally used to carry both hard and soft information about the uncached files .",
    "a similar scheme was also considered in @xcite for a system with no caching . in this scheme , as a hybrid of ( [ eq : linear - precoding - hard ] ) or ( [ eq : transmitted - signal - soft - transfer ] ) , the signal @xmath57 transmitted by errh @xmath17 on the downlink channel is given as @xmath184 where , as for ( [ eq : transmitted - signal - soft - transfer ] ) , @xmath110 is the precoding matrix applied by errh @xmath17 on the baseband signal @xmath152 encoding the subfile @xmath63 , and @xmath153 represents the quantized baseband signal received from the bbu on the fronthaul link .",
    "similar to ( [ eq : transmitted - signal - soft - transfer ] ) , the first term for subfile @xmath63 is non - zero if the subfile @xmath63 is available at the errh by caching or via hard - mode fronthauling , i.e. , with @xmath106 or @xmath107 , respectively .",
    "the bbu precodes the subfiles @xmath63 that are not available at errh @xmath17 , i.e. , with @xmath185 , producing the signal @xmath186 where @xmath155 is the precoding matrix for the baseband signal @xmath152 .",
    "the quantized signal @xmath153 in the right - hand side of ( [ eq : transmitted - signal - hybrid - transfer ] ) is given as ( [ eq : quantized - signal - soft ] ) which can be reliably recovered by errh @xmath17 if the condition @xmath187 is satisfied , where we recall that @xmath188 denotes the covariance matrix of the quantization noise in ( [ eq : quantized - signal - soft ] ) , and we defined @xmath189 as the rate used on the @xmath17th fronthaul for the soft - transfer mode .",
    "the rest of the frontahul link of @xmath190 bit / symbol can be used for the hard - transfer mode , i.e. , for transferring the subfiles @xmath63 with @xmath107 .",
    "accounting for both soft- and hard - transfer fronthauling , the fronthaul capacity constraint for each errh @xmath17 is then stated as @xmath191    with ( [ eq : transmitted - signal - hybrid - transfer ] ) , the signal @xmath113 received by ue @xmath22 in ( [ eq : received - signal ] ) can be written as ( [ eq : received - signal - soft ] ) , with the only difference that the aggregated precoding matrix @xmath168 $ ] for subfile @xmath63 consists of the submatrices @xmath192 . assuming the sic decoding with the same decoding order , the rate @xmath118 of the subfile @xmath119 is achievable if the condition ( [ eq : achievable - rate - soft ] ) is satisfied .",
    "we aim at optimizing the precoding matrices @xmath193 and @xmath194 applied at the errhs and the bbu , along with the capacities @xmath195 used for soft - transfer fronthauling , with the goal of maximizing the minimum - user rate , as in sec .",
    "[ sub : problem - formulation - hard ] and sec .",
    "[ sub : problem - formulation - soft ] , while satisfying the fronthaul capacity ( [ eq : fronthaul - capacity - constraint - hybrid - transfer ] ) and per - errh power constraints ( [ eq : per - errh - power - constraint ] ) .",
    "the problem can be formulated as    [ eq : problem - hybrid - original ] @xmath196    as for problems ( [ eq : problem - hard - original ] ) and ( [ eq : problem - soft - original ] ) , we can apply the cccp approach to a rank - relaxed version of the problem ( [ eq : problem - hybrid - original ] ) , where the rank constraints @xmath134 are removed .",
    "the procedure follows in the same manner as for algorithms 1 and 2 , and will not be detailed here .",
    "average minimum rate @xmath122 versus the parameter @xmath36 of the zipf s distribution in ( [ eq : zipf - distribution ] ) for a f - ran downlink under soft - transfer fronthauling mode ( @xmath197 , @xmath198 , @xmath199 , @xmath200 and @xmath201 and @xmath202 db).,width=453,height=340 ]    in this section , we present some numerical results that compare the performance of hard - transfer and soft - transfer fronthauling modes , as well as of the hybrid scheme , with the pre - fetching strategies discussed in sec .",
    "[ sec : pre - fetching ] .",
    "we consider an f - ran system where the positions of errhs and ues are uniformly distributed within a circular cell of radius @xmath203 m .",
    "the channel @xmath47 from errh @xmath17 to ue @xmath22 is modeled as @xmath204 , where the channel power @xmath205 is given as @xmath206 and the elements of @xmath207 are independent and identically distributed ( i.i.d . ) as @xmath208 .",
    "we set the parameters @xmath209 m and @xmath210 .",
    "we consider a symmetric setting where the covariance matrix @xmath45 is given as @xmath211 for all ues @xmath51 , and the errhs have the same transmit power and fronthaul capacity , i.e. , @xmath212 and @xmath213 for @xmath71 and are equipped with caches of equal size , i.e. , @xmath214 and @xmath70 for @xmath71 . for hard - transfer fronthauling , we assume that the fronthaul transfer variables @xmath215 are set such that the subfile @xmath119 requested by ue @xmath22 is transferred on the fronthaul links to the @xmath216 errhs that have the largest channel gains @xmath217 to the ue and have not stored the subfile , where @xmath218 is a parameter that defines the scheme . note",
    "that this implies that the cooperative cluster of errhs for the transmission of any subfile for the hard - transfer mode is of size @xmath216 plus the number of errhs that cache that subfile .",
    "moreover , the variables @xmath215 of the hybrid fronthauling strategy proposed in sec .",
    "[ sec : hybrid - fronthauling ] is set to those of the hard - transfer mode with @xmath216 giving the best performance . if not stated otherwise , we set @xmath219 and @xmath220 .",
    "we first study the impact of the file popularity on the f - ran performance . to this end , in fig .",
    "[ fig : graph - as - gamma ] , we plot the average minimum rate @xmath122 versus the parameter @xmath36 of the zipf s distribution in ( [ eq : zipf - distribution ] ) , where the average is taken with respect to the channel , ues requests and the system geometry , for an f - ran downlink with soft - transfer fronthauling .",
    "we set the parameters @xmath198 , @xmath199 , @xmath200 and @xmath221 and @xmath202 db . we compare the performance of cmp and cd pre - fetching with @xmath222 with the case of full ( @xmath223 ) and no ( @xmath224 ) caching ( fcd is not shown here to avoid clutter ) .",
    "note that full caching is equivalent to the mimo broadcast part of the cut - set upper bound ( * ? ? ?",
    "* theorem 14.10.1 ) .",
    "it is observed from the figure that the performance gain of the cmp pre - fetching strategy with a larger @xmath36 , and hence with an increased bias towards the most popular files , is more pronounced for lower values of the fronthaul capacity @xmath225 .",
    "this is because , in the regime of small @xmath225 , cooperative transmission by means of cloud processing , as in c - ran , can not compensate for the lack of cooperation opportunities on the cached files that affects the cd approach .",
    "in contrast , when @xmath36 is sufficiently small , the cd strategy outperforms cmp approach , which suffers from a significant number of cache misses , particularly for low values of @xmath225 .",
    "we also note that , when @xmath36 is sufficiently large , the performance of cmp approaches that of full caching scheme even with a small fronthaul capacity , due to the high probability that cooperative transmission across all errhs is possible based only on the cached contents .",
    "average minimum rate @xmath122 versus the fractional caching capacity @xmath226 for an f - ran downlink under fcd pre - fetching ( @xmath227 and @xmath228 , @xmath229 , @xmath199 and @xmath202 db).,width=453,height=340 ]    in fig .",
    "[ fig : graph - as - mu ] , we investigate the effect of the fractional caching capacity @xmath226 on the average minimum rate in two regimes of fronthaul capacity , namely low , here , @xmath227 bit / symbol , and moderate , here , @xmath230 bit / symbol .",
    "we adopt the fcd strategy and compare the performance of soft- and hard - transfer fronthauling modes with the hybrid mode proposed in sec .",
    "[ sec : hybrid - fronthauling ] .",
    "note that , as per the definition in sec .",
    "[ sub : fractional - cache - distinct ] , fcd modifies its operation only at the values of @xmath224 , @xmath231 , @xmath232 and @xmath201 , which are marked in the figure .",
    "note that all schemes provide the same performance for @xmath223 , since every errh has access to the requested contents .",
    "the plot emphasizes the different relative behavior of the soft and hard fronthauling strategies in different fronthaul and caching set - ups .",
    "in particular , the soft - transfer fronthauling strategy is seen to offer potentially large gains for low fronthaul and sufficiently large caching capacities .",
    "this suggests that , if the errhs have sufficient caching capabilities , soft - transfer fronthauling provides the best way to use low - capacity fronthaul links .",
    "conversely , if the fronthaul capacity is large enough as compared to the minimum delivery rate , and if the caching capacity is sufficiently large , hard fronthauling can offer some , albeit not major , performance gains over soft - mode fronthauling .",
    "we also observe that , for the hard - transfer mode , the optimal size of the cooperative cluster , which depends on @xmath216 , increases with the fronthaul capacity .",
    "finally , the hybrid scheme is seen to outperform the soft- and hard - transfer modes , particularly at lower caching capacities .",
    "average minimum rate @xmath122 versus the fronthaul capacity @xmath225 for an f - ran downlink under fcd pre - fetching ( @xmath222 and @xmath201 , @xmath229 , @xmath233 , @xmath234 and @xmath202 db).,width=453,height=340 ]    we then further study the role of the fronthaul capacity by plotting in fig .",
    "[ fig : graph - as - c ] the average minimum rate @xmath122 versus the fronthaul capacity @xmath225 for an f - ran system with the fcd pre - fetching , and with @xmath222 and @xmath201 , @xmath229 , @xmath233 , @xmath234 and @xmath202 db . from the figure , we observe that the partial caching capacity of the errhs , here with @xmath222 , can be compensated by a larger fronthaul capacity @xmath225 .",
    "for instance , the soft - transfer fronthauling mode with @xmath222 needs a fronthaul capacity of @xmath235 bit / symbol to achieve the full - caching upper bound within 5% .",
    "also , it is seen that , for small fronthaul capacity @xmath225 , it is desirable to reduce the cluster size , and hence @xmath216 , for hard - transfer fronthauling , since a larger cluster size requires the transfer of each subfile to more errhs on the fronthaul links of small capacity , which limits the rate of the subfile .",
    "the figure confirms the observation in fig .",
    "[ fig : graph - as - mu ] that , if the fronthaul capacity @xmath225 is sufficiently large , the hard - transfer mode can provide some performance gains over soft - transfer fronthauling , as long as the cooperative cluster size is properly selected .",
    "furthermore , we note that the hybrid scheme has the capability to improve over both soft- and hard - mode fronthauling , except for very low- and very high - fronthaul capacity regime , in which it reverts to the soft- and hard - mode schemes , respectively .",
    "average minimum rate @xmath122 versus the normalized file size @xmath236 for an f - ran downlink under soft - transfer mode fronthauling ( @xmath237 and @xmath201 , @xmath229 , @xmath227 , @xmath238 and @xmath239 db).,width=453,height=340 ]    we now examine the impact of the file size @xmath236 on the optimal caching policy . in fig .",
    "[ fig : graph - as - s ] , we show the average minimum rate @xmath122 versus the normalized file size @xmath236 for an f - ran downlink with soft - transfer mode fronthauling .",
    "we set the parameters @xmath229 , @xmath227 , @xmath238 and @xmath239 db . the figure suggests that , for all pre - fetching strategies , the minimum rate @xmath122 increases with a larger @xmath236 in the regime of small file sizes , in which the performance is limited by the file size @xmath236 rather than the fronthaul capacity @xmath225 .",
    "moreover , the performance gain of the fcd strategy compared to the cmp and cd is more pronounced for larger @xmath236 , since the partitioning of a file into multiple fragments becomes more advantageous for the purpose of caching as the file size @xmath236 increases .",
    "average minimum rate @xmath122 versus the snr @xmath240 for an f - ran downlink under fcd pre - fetching ( @xmath222 and @xmath201 , @xmath229 , @xmath227 , @xmath238 and @xmath199).,width=453,height=340 ]    finally , fig .",
    "[ fig : graph - as - snr ] plots the average minimum rate @xmath122 versus the snr @xmath240 for an f - ran downlink with the fcd pre - fetching and parameters set as @xmath222 and @xmath201 , @xmath229 , @xmath227 , @xmath238 and @xmath199 .",
    "it can be seen that , when the snr is large , the performance is limited by the fronthaul capacity @xmath225 , and thus increasing the cluster size of the hard - transfer fronthauling results in a performance degradation .",
    "we can also see that soft - transfer fronthauling , which has the flexibility to automatically control the cluster size via the design of the precoding and quantization noises covariance matrices , in this example , improves over the hard - transfer scheme at sufficiently large snrs .",
    "in this work , we have studied joint design of cloud and edge processing for an f - ran architecture in which each edge node is equipped not only with the functionalities of standard rrhs in c - ran , but also with local cache and baseband processing capabilities . for any given pre - fetching strategy , we considered the optimization of the delivery phase with the goal of maximizing the minimum delivery rate of the requested files while satisfying the fronthaul capacity and per - errh power constraints .",
    "we considered two basic fronthauling modes , namely hard- and soft - transfer fronthauling , as well as a hybrid mode .",
    "specifically , with the hard - transfer mode , the fronthaul links are used to transmit the requested files that are not in the local caches , while the soft - transfer mode employs the fronthaul links following the c - ran principle of transferring quantized baseband signals .",
    "we compared the performance of hard- , soft- and hybrid - transfer fronthauling modes with different baseline pre - fetching strategies .",
    "it was concluded , by means of extensive numerical results , that soft - transfer provides a more effective way to use fronthaul resources than the hard - transfer mode in most operating regimes except for very low snr regime and moderate fronthaul capacity . in such regimes ,",
    "hard - transfer fronthauling with a carefully selected cluster size can provide minor gains .",
    "it is emphasized that these results hold under the assumptions of information - theoretically optimal point - to - point compression for communication on the fronthaul links .",
    "while it is known that point - to - point compression can be improved upon @xcite , the comparison between the two modes should be revisited in the presence of less effective compression or even only quantization ( see also @xcite for further discussion in the context of c - ran ) .",
    "moreover , the numerical results highlighted the trade - off between fronthaul and caching resources , whereby a smaller fronthaul capacity can be compensated for by a larger cache , particularly for more skewed popularity distributions .",
    "15 a. checko , h. l. christiansen , y. yan , l. scolari , g. kardaras , m. s. berger and l. dittmann , `` cloud ran for mobile networks - a technology overview , '' _ ieee comm .",
    "surveys tutorials _ , vol .",
    "1 , pp . 405 - 426 , first quart .",
    "2015 . m. peng , c. wang , v. lau and h. v. poor , `` fronthaul - constrained cloud radio access networks : insights and challenges , '' _ ieee wireless comm .",
    "152 - 160 , apr . 2015 .",
    "o. simeone , a. maeder , m. peng , o. sahin and w. yu , `` cloud radio access network : virtualizing wireless access for dense heterogeneous systems , '' arxiv:1512.07743 , dec .",
    "ericsson ab , huawei technologies , nec corporation , alcatel lucent and nokia siemens networks , `` common public radio interface ( cpri ) : interface specification , '' cpri specification v5.0 , sep . 2011 .",
    "o. simeone , o. somekh , h. v. poor and s. shamai ( shitz ) , `` downlink multicell processing with limited backhaul capacity , '' _ eurasip journal on advances in signal processing _ , 2009 .",
    "h . park , o. simeone , o. sahin and s. shamai ( shitz ) , `` joint precoding and multivariate backhaul compression for the downlink of cloud radio access networks , '' _ ieee trans .",
    "sig . processing _ , vol .",
    "22 , pp . 5646 - 5658 ,",
    "s .- h . park , o. simeone , o. sahin and s. shamai ( shitz ) , `` fronthaul compression for cloud radio access networks : signal processing advances inspired by network information theory , '' _ ieee sig",
    ". processing mag .",
    "69 - 79 , nov . 2014 .",
    "p. patil and w. yu , `` hybrid compression and message - sharing strategy for the downlink cloud radio - access network , '' _ proc .",
    "theory and application workshop 2014 _ , san diego , ca , usa , feb . 2014 . m. peng , s. yan , k. zhang and c. wang , `` fog computing based radio access networks : issues and challenges , '' arxiv:1506.04233 , jun . 2015 . s. bi , r. zhang , z. ding and s. cui , `` wireless communications in the era of big data , '' arxiv:1508.06369 , aug .",
    "china mobile , `` next generation fronhtaul interface , '' white paper , oct .",
    "china mobile , `` c - ran : the road towards green ran , '' white paper , oct . 2011 .",
    "x. peng , j .- c .",
    "shen , j. zhang and k. b. letaief , `` backhaul - aware caching placement for wireless networks , '' arxiv:1509.00558 , sep .",
    "m. tao , e. chen , h. zhou and w. yu , `` content - centric sparse multicast beamforming for cache - enabled cloud ran , '' arxiv:1512.06938 , dec .",
    "y. ugur , z. h. awan and a. sezgin , `` cloud radio access networks with coded caching , '' arxiv:1512.02385 , dec .",
    "b. azari , o. simeone , u. spagnolini and a. tulino , `` hypergraph - based analysis of clustered cooperative beamforming with application to edge caching , '' to appear in _ ieee wireless comm .",
    "letters_. r. tandon and o. simeone , `` cloud - aided wireless networks with edge caching : fundamental latency trade - offs in fog radio access networks , '' submitted , jan .",
    "r. tandon and o. simeone , `` fog radio access networks : fundamental latency trade - offs , '' _ proc .",
    "theory and applications workshop ( ita ) 2016 _ , la jolla , ca , jan .",
    "y. ugur , z. h. awan and a. sezgin , `` cloud radio access networks with coded caching , '' _ proc .",
    "theory and applications workshop ( ita ) 2016 _ , la jolla , ca , jan .",
    "m. chiang , `` fog networking : an overview on research opportunities , '' arxiv:1601.00835 , jan .",
    "m. a. maddah - ali and u. niesen , `` cache - aided interference channels , '' _ proc .",
    "ieee intern .",
    "symp . on inf .",
    "theory ( isit ) 2015 _ , hong kong , china , jun .",
    "a. sengupta , r. tandon and o. simeone , `` cache aided wireless networks : tradeoffs between storage and latency , '' arxiv:1512.07856 , dec . 2015 .",
    "v. bioglio , f. gabry and i. land , `` optimizing mds codes for caching at the edge , '' arxiv:1508.05753 , aug .",
    "z. chen , j. lee , t. q. s. quek and m. kountouris , `` cooperative caching and transmission design in cluster - centric small cell networks , '' arxiv:1601.00321 , jan . 2016 .",
    "a. e. gamal and y .- h .",
    "network information theory _ , cambridge university press , 2011 .",
    "a. m. fouladgar , o. simeone , s .- h .",
    "park , o. sahin and s. shamai ( shitz ) , `` signal and interference alignment via message passing for mimo interference channels , '' to appear in _ trans .",
    "emerging telecomm .",
    "technol . _ ,",
    "j. kang , o. simeone , j. kang and s. shamai ( shitz ) , `` fronthaul compression and precoding design for c - rans over ergodic fading channel , '' to appear in _ ieee trans .",
    "technology _ ,",
    "b. dai and w. yu , `` energy efficiency of downlink transmission strategies for cloud radio access networks , '' arxiv:1601.01070 , jan .",
    "m. razaviyayn , m. sanjabi and z .- q .",
    "luo , `` a stochastic successive minimization for nonsmooth nonconvex optimization with applications to transceiver design in wireless communications networks , '' arxiv:1307.4457 , jul .",
    "h. a. l. thi and p. tao , `` the dc programming and dca revised with dc models of real world nonconvex optimization problems , '' _ annals of operations research _ , vol . 133 , no . 1 - 4 , pp .",
    "23 - 46 , jan . 2005 .",
    "g. scutari , f. facchinei , l. lampariello and p. song , `` distributed methods for constrained nonconvex multi - agent optimization - part i : theory , '' arxiv:1410.4754 , oct .",
    "j. borwein and a. lewis , _ convex analysis and nonlinear oprimitzation : theory and examples _ , springer verlag , 2006 .",
    "t. cover and j. thomas , _ elements of information theory , _ ser .",
    "wiley series in telecomm . ,",
    "new york ny , usa : wiley , 1991 .",
    "w. lee , o. simeone , j. kang and s. shamai ( shitz ) , `` multivariate fronthaul quantization for downlink c - ran , '' arxiv:1510.08030 , oct . 2015 ."
  ],
  "abstract_text": [
    "<S> this work studies the joint design of cloud and edge processing for the downlink of a fog radio access network ( f - ran ) . in an f - ran , as in cloud - ran ( c - ran ) , a baseband processing unit ( bbu ) can perform joint baseband processing on behalf of the remote radio heads ( rrhs ) that are connected to the bbu by means of the fronthaul links . </S>",
    "<S> in addition to the minimal functionalities of conventional rrhs in c - ran , the rrhs in an f - ran may be equipped with local caches , in which frequently requested contents can be stored , as well as with baseband processing capabilities . </S>",
    "<S> they are hence referred to as enhanced rrh ( errh ) . </S>",
    "<S> this work focuses on the design of the delivery phase for an arbitrary pre - fetching strategy used to populate the caches of the errhs . </S>",
    "<S> two fronthauling modes are considered , namely a _ </S>",
    "<S> hard - transfer mode _ </S>",
    "<S> , whereby non - cached files are communicated over the fronthaul links to a subset of errhs , and a _ soft - transfer mode _ , whereby the fronthaul links are used to convey quantized baseband signals as in a c - ran . </S>",
    "<S> unlike the hard - transfer mode in which baseband processing is traditionally carried out only at the errhs , the soft - transfer mode enables both centralized precoding at the bbu and local precoding at the errhs based on the cached contents , by means of a novel superposition coding approach . to attain the advantages of both approaches , </S>",
    "<S> a hybrid design of soft- and hard - transfer modes is also proposed . </S>",
    "<S> the problem of maximizing the delivery rate is tackled under fronthaul capacity and per - errh power constraints . </S>",
    "<S> numerical results are provided to compare the performance of hard- and soft - transfer fronthauling modes , as well as of the hybrid scheme , for different baseline pre - fetching strategies .    fog radio access network , edge caching , pre - fetching , fronthaul compression , beamforming , c - ran . </S>"
  ]
}