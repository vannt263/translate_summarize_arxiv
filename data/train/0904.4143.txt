{
  "article_text": [
    "there are two basic categories of discrete - time controlled markov processes that deal with random temporal horizons .",
    "the first is the well - known _ optimal stopping problem _",
    "@xcite , in which the random horizon arises from some dynamic optimization protocol based on the past history of the process .",
    "the random ` stopping time ' thus generated is regarded as a decision variable .",
    "this problem arises in , among other areas , stochastic analysis , mathematical statistics , mathematical finance , and financial engineering ; see the comprehensive monograph  @xcite for details and further references .",
    "the second is relatively less common , and is characterized by the fact that the random horizon arises as a result of an endogenous event of the stochastic process , e.g. , the process hitting a particular subset of the state - space , variations in the process paths crossing a certain threshold .",
    "this problem arises in , among others , optimization of target - level criteria  @xcite , optimal control of retirement investment funds  @xcite , minimization of ruin probabilities in insurance funds  @xcite , ` satisfaction of needs ' problems in economics  @xcite , risk minimizing stopping problems  @xcite , attainability problems under stochastic perturbations  @xcite , and optimal control of markov control processes up to an exit time  @xcite .",
    "the problem treated in this article falls under the second category above . in broad strokes ,",
    "we consider a discrete - time markov control process with borel state and action spaces .",
    "we assume that there is a certain target set located inside a safe region , the latter being a subset of the state - space .",
    "the problem is to maximize the probability of attaining the target set before exiting the safe set ( or equivalently , hitting the cemetery set or unsafe region ) .",
    "this ` reach a good set while avoiding a bad set ' formulation arises in , e.g. , air traffic control , where aircraft try to reach their destination while avoiding collision with other aircraft or the ground despite uncertain weather conditions .",
    "it also arises in portfolio optimization , where it is desired to reach a target level of wealth without falling below a certain baseline capital with high probability . finally , it forms the core of the computation of safe sets for hybrid systems where the ` good ' and the ` bad ' sets represent states from which a discrete transition into the unsafe set is possible  @xcite .",
    "special cases of this problem have been investigated in , e.g. ,  @xcite in the context of air traffic applications ,  @xcite in the context of probabilistic safety ,  @xcite in the context of maximizing the probability of attaining a preassigned comfort level of retirement investment funds .",
    "it is clear from the description of our problem in the preceding paragraph that there are two random times involved , namely , the hitting times of the target and the cemetery sets . in this article",
    "we formulate our problem as the maximization of an expected total reward accumulated up to the minimum of these two hitting times . as such",
    ", this formulation falls under the broad framework of optimal control of markov control processes up to an exit time , which has a long and rich history .",
    "it has mostly been studied as the minimization of an expected total cost until the first time that the state enters a given target set , see e.g. ,  ( * ? ? ?",
    "* chapter  ii ) , ( * ? ? ?",
    "* chapter  8) , and the references therein .",
    "in particular , if a unit cost is incurred as long as the state is outside the target set , then the problem of minimizing the cost accumulated until the state enters the target is known variously as the _ pursuit problem _  @xcite , _ transient programming _",
    "@xcite , the _ first passage problem _",
    "@xcite , the _ stochastic shortest path problem _",
    "@xcite , and _ control up to an exit time _  @xcite . here",
    "we exploit certain additional structures of our problem in the dynamic programming equations that we derive leading to methods fine - tuned to the particular problem at hand .",
    "our main results center around the assertion that there exists a deterministic stationary policy that maximizes the probability of hitting the target set before the cemetery set .",
    "this maximal probability as a function of the initial state is the optimal value function for our problem .",
    "we obtain a bellman equation for our problem which is solved by the optimal value function .",
    "furthermore , we provide martingale - theoretic conditions characterizing ` thrifty ' , ` equalizing ' , and optimal policies via methods derived from  @xcite ; see also  @xcite and the references therein for martingale characterization of average optimality .",
    "the principal techniques employed in this article are similar to the ones in  @xcite , where the authors studied optimal control of a markov control process up its first entry time to a safe set . in  @xcite we developed a recovery strategy to enter a given target set from its exterior while minimizing a discounted cost .",
    "the problem was posed as one of minimizing the sum of a discounted cost - per - stage function @xmath0 up to the first entry time @xmath1 to a target set , namely , minimize @xmath2 $ ] over a class of admissible policies @xmath3 , where @xmath40,1[$ ] is a discount factor .",
    "here we extend this approach to problems with two sets , a target and a cemetery , and the case of @xmath5 .",
    "this article unfolds as follows .",
    "the main results are stated in   [ s : results ] . in   [ s : prelims ] we define the general setting of the problem , namely , markov control processes on polish spaces , their transition kernels , and the admissible control strategies . in   [ s : mainres ] we present our main theorem  [ t : exist ] which guarantees the existence of a deterministic stationary policy that leads to the maximal probability of hitting the target set while avoiding the specified dangerous set , and also provides a bellman equation that the value function must satisfy . in   [ s : martchar ] we look at a martingale characterization of the optimal control problem ; thrifty and equalizing policies are defined in the context of our problem , and we establish necessary and sufficient conditions for optimality in terms of thrifty and equalizing policies in theorem  [ t : martcharpolicy ] .",
    "we discuss related reward - per - stage functions and their relationships to our problem and treat several examples in   [ s : disc ] .",
    "proofs of the main results appear in   [ s : proof ] .",
    "the article concludes in   [ s : concl ] with a discussion of future work .",
    "our main results are stated in this section after some preliminary definitions and conventions .",
    "we employ the following standard notations .",
    "let @xmath6 denote the natural numbers @xmath7 and @xmath8 denote the nonnegative integers @xmath9 .",
    "let @xmath10 be the usual indicator function of a set @xmath11 , i.e. , @xmath12",
    "if @xmath13 and @xmath14 otherwise . for real numbers @xmath15 and @xmath16 let @xmath17 .",
    "a function @xmath18 restricted to @xmath19 is depicted as @xmath20 .",
    "given a nonempty borel set @xmath21 ( i.e. , a borel subset of a polish space ) , its borel @xmath22-algebra is denoted by @xmath23 . by convention , when referring to sets or functions , `` measurable '' means `` borel - measurable . ''",
    "if @xmath21 and @xmath24 are nonempty borel spaces , a _ stochastic kernel _ on @xmath21 given @xmath24 is a function @xmath25 such that @xmath26 is a probability measure on @xmath21 for each fixed @xmath27 , and @xmath28 is a measurable function on @xmath24 for each fixed @xmath29 .",
    "we briefly recall some standard definitions below , see , e.g. ,  @xcite for further details .",
    "a _ markov control model _ is a five - tuple @xmath30 consisting of a nonempty borel space @xmath21 called the _ state - space _ , a nonempty borel space @xmath11 called the _ control _ or _ action set _ , a family @xmath31 of nonempty measurable subsets @xmath32 of @xmath11 , where @xmath32 denotes the set of _ feasible controls _ or _",
    "actions _ when the system is in state @xmath33 and with the property that the set @xmath34 of feasible state - action pairs is a measurable subset of @xmath35 , a stochastic kernel @xmath36 on @xmath21 given @xmath37 called the _ transition law _ , and a measurable function @xmath38 called the _ reward - per - stage function_.    [ a : basic ] the set @xmath37 of feasible state - action pairs contains the graph of a measurable function from @xmath21 to @xmath11 .",
    "consider the markov model  , and for each @xmath39 define the space @xmath40 of _ admissible histories _ up to time @xmath41 as @xmath42 and @xmath43 .",
    "a generic element @xmath44 of @xmath40 , which is called an admissible @xmath41-history , or simply @xmath41-history , is a vector of the form @xmath45 , with @xmath46 for @xmath47 , and @xmath48 .",
    "hereafter we let the @xmath22-algebra generated by the history @xmath44 be denoted by @xmath49 , @xmath50 .",
    "recall that a _ policy _ is a sequence @xmath51 of stochastic kernels @xmath52 on the control set @xmath11 given @xmath40 satisfying the constraint @xmath53 .",
    "the set of all policies is denoted by @xmath54 .",
    "let @xmath55 be the measurable space consisting of the ( canonical ) sample space @xmath56 and let @xmath57 be the corresponding product @xmath22-algebra .",
    "the elements of @xmath58 are sequences of the form @xmath59 with @xmath48 and @xmath60 for all @xmath50 ; the projections @xmath61 and @xmath62 from @xmath58 to the sets @xmath21 and @xmath11 are called _ state _ and _ control _ ( or _ action _ ) variables , respectively .",
    "let @xmath51 be an arbitrary control policy , and let @xmath63 be an arbitrary probability measure on @xmath21 , referred to as the initial distribution . by a theorem of ionescu - tulcea  (",
    "* chapter 3 ,  4 , theorem  5 ) , there exists a unique probability measure @xmath64 on @xmath55 supported on @xmath65 , such that for all @xmath29 , @xmath66 , @xmath67 , @xmath50 , we have @xmath68 ,    [ e : probmeasure ] @xmath69    [ d : mcp ] the stochastic process @xmath70 is called a discrete - time _ markov control",
    "process_.    we note that the markov control process in definition  [ d : mcp ] is not necessarily markovian in the usual sense due to the dependence on the entire history @xmath44 in  ; however , it is well - known  ( * ? ? ?",
    "* proposition  2.3.5 ) that if @xmath71 is restricted to a suitable subclass of policies , then @xmath72 is a markov process .",
    "let @xmath73 denote the set of stochastic kernels @xmath74 on @xmath11 given @xmath21 such that @xmath75 for all @xmath33 , and let @xmath76 denote the set of all measurable functions @xmath77 satisfying @xmath78 for all @xmath33 . the functions in @xmath76 are called _ measurable selectors _ of the set - valued mapping @xmath79 .",
    "recall that a policy @xmath80 is said to be _",
    "randomized markov _ if there exists a sequence @xmath81 of stochastic kernels @xmath82 such that @xmath83 ; _ deterministic markov _ if there exists a sequence @xmath84 of functions @xmath85 such that @xmath86 ; _ deterministic stationary _ if there exists a function @xmath87 such that @xmath86 . as usual",
    "let @xmath54 , @xmath88 , @xmath89 , and @xmath90 denote the set of all randomized history - dependent , randomized markov , deterministic markov , and deterministic stationary policies , respectively .",
    "the transition kernel @xmath36 in   under a policy @xmath91 is given by @xmath92 , which is defined as the transition kernel @xmath93 .",
    "occasionally we suppress the dependence of @xmath94 on @xmath95 and write @xmath96 in place of @xmath97 , and @xmath98 .",
    "we simply write @xmath99 for a policy @xmath100 .",
    "let @xmath101 and @xmath102 be two nonempty measurable subsets of @xmath21 with @xmath103 .",
    "let @xmath104 be the first hitting times of the above sets .. ] these random times are stopping times with respect to the filtration @xmath105 .",
    "suppose that the objective is to maximize the probability that the state hits the set @xmath101 before exiting the set @xmath102 ; in symbols the objective is to attain @xmath106 where the @xmath107 is taken over a class @xmath54 of admissible policies .",
    "[ pgr : policies ] _ admissible policies .",
    "_ it is clear at once that the class of admissible policies for the problem   is different from the classes considered in   [ s : prelims ] .",
    "indeed , since the process is killed at the stopping time @xmath108 , it follows that the class of admissible policies should also be truncated at the stage @xmath109 . for a given stage @xmath110",
    "we define the @xmath111-th policy element @xmath112 only on the set @xmath113 .",
    "note that with this definition @xmath112 becomes a @xmath114-measurable randomized control .",
    "it is also immediate from the definitions of @xmath1 and @xmath115 that if the initial condition @xmath116 , then the set of admissible policies is empty in the sense that there is nothing to do by definition .",
    "indeed , in this case @xmath117 and no control is needed .",
    "we are thus interested only in @xmath118 , for otherwise the problem is trivial .",
    "in other words , the domain of @xmath112 is contained in the ` spatial ' region @xmath119 .",
    "equivalently , in view of the definitions of the ` temporal ' elements @xmath1 and @xmath115 , @xmath112 is well - defined on the set @xmath113 .",
    "we re - define @xmath120 , and also let @xmath76 to be the set of measurable selectors of the set - valued map @xmath121 .",
    "_ throughout this subsection we shall denote by @xmath122 the class of markov policies such that if @xmath123 , then @xmath112 is defined on @xmath37 for each @xmath111 . _",
    "[ pgr : recalldef ] recall that a transition kernel @xmath36 on a measurable space @xmath21 given another measurable space @xmath24 is said to be _ strongly feller _ if the mapping @xmath124 is continuous and bounded for every measurable and bounded function @xmath125 .",
    "a function @xmath126 is _ upper semicontinuous _",
    "( u.s.c . )",
    "if for every sequence @xmath127 converging to @xmath128 , we have @xmath129 ; or , equivalently , if for every @xmath130 , the set @xmath131 is closed in @xmath37 . a set - valued map @xmath132 between topological spaces is _ upper hemicontinuous at a point @xmath95 _ if for every neighborhood @xmath133 of @xmath134 there exists a neighborhood @xmath135 of @xmath95 such that @xmath136 implies that @xmath137 ; @xmath138 is _ upper hemicontinuous _ if it is upper hemicontinuous at every @xmath95 in its domain . if @xmath21 is equipped with a @xmath22-algebra @xmath139 , then the set - valued map @xmath138 is called _ weakly measurable _ if @xmath140 for every open @xmath141 , where @xmath142 is the lower inverse of @xmath138 , defined by @xmath143 .",
    "see , e.g. ,  ( * ? ? ?",
    "* chapters  17 - 18 ) for further details on set - valued maps . whenever @xmath144 is a nonempty measurable set and we are concerned with any set - valued map @xmath145 , we let @xmath146 be equipped with the trace of @xmath23 on @xmath146 .",
    "let @xmath147 denote the convex cone of nonnegative , bounded , and measurable real - valued functions on @xmath21 , and we define @xmath148 .",
    "[ a : key ]    in addition to assumption  [ a : basic ] , we stipulate that    1 .",
    "the set - valued map @xmath121 is compact - valued , upper hemicontinuous , and weakly measurable ; 2 .",
    "the transition kernel @xmath36 on @xmath21 given @xmath37 is strongly feller , i.e. , the mapping @xmath149 is continuous and bounded for all bounded and measurable functions @xmath125 .",
    "the following theorem gives basic existence results for the problem  ; a proof is presented in   [ s : mainproof ] .",
    "[ t : exist ] suppose that assumption   holds , and that @xmath108 is finite for every policy in @xmath122 .",
    "then :    1 .",
    "the value function @xmath150 is a pointwise bounded and measurable solution to the _ bellman equation _ in @xmath151 : @xmath152 moreover , @xmath150 is minimal in @xmath153 .",
    "2 .   there exists a measurable selector @xmath154 such that @xmath155 attains the maximum in   for each @xmath118 , which satisfies[co : exist:2 ] @xmath156 where @xmath150 is as defined in  .",
    "moreover , the deterministic stationary policy @xmath157 is optimal .",
    "conversely , if @xmath157 is optimal , then it satisfies  .",
    "[ pgr : altrep ] as a matter of notation we shall henceforth represent the functional equation   with the less formal version : @xmath158 note that the measure @xmath159 is not well - defined for @xmath116 for @xmath160 in view of the definition in paragraph  [ pgr : policies ] .",
    "as such the integral @xmath161 is undefined for @xmath116 . however , to preserve the form of   and simplify notation , we shall stick to the representation   by defining any object that is written as an integral of a bounded measurable function with respect to the measure @xmath162 to be @xmath14 whenever @xmath116 and @xmath163 .",
    "_ we now return to the more general class of all possible policies ( not just markovian ) , denoted by @xmath54 .",
    "_    fix an initial state @xmath33 and a policy @xmath164 . for each @xmath165",
    "we define the random variable @xmath166 .",
    "let us consider the process @xmath167 defined by @xmath168    we follow the basic framework of  @xcite .",
    "a policy @xmath164 is called _ thrifty at @xmath33 _ if @xmath169 , and _ equalizing at @xmath33 _ if @xmath170 .",
    "the action @xmath171 , defined on @xmath172 , is said to _",
    "conserve @xmath150 at @xmath173 _ if @xmath174 .",
    "connections between equalizing , thrifty , and optimal policies for our problem   are established by the following    [ t : martcharpolicy ] a policy @xmath164 is    * equalizing at @xmath33 if and only if @xmath175 = 0;\\ ] ] * optimal at @xmath33 if and only if @xmath3 is both thrifty and equalizing .    a connection between thrifty policies , the process @xmath167 defined in  , and actions conserving the optimal value function @xmath150 is established by the following    [ t : thriftychar ] for a given policy @xmath164 and an initial state @xmath33 the following are equivalent :    1 .",
    "@xmath3 is trifty at @xmath95 ; 2 .",
    "@xmath167 is a @xmath105 -martingale under @xmath176 ; 3 .",
    "@xmath176-almost everywhere on @xmath172 the action @xmath171 conserves @xmath150 .",
    "it is possible to make a connection , relying purely on martingale - theoretic arguments , between the process @xmath167 and the value function corresponding to an optimal policy .",
    "this is the content of the following theorem , which may be viewed as a partial converse to theorem  [ t : thriftychar ] .",
    "[ t : vprimechar ] suppose that either one of the stopping times @xmath1 and @xmath115 defined in   is finite for every policy in @xmath54 .",
    "let @xmath177 be a nonnegative measurable function such that @xmath178 , @xmath179 , and bounded above by @xmath180 elsewhere .",
    "for a policy @xmath164 define the process @xmath181 as @xmath182 where @xmath183 is as in  .",
    "if for some policy @xmath184 the process @xmath181 is a @xmath105 -martingale under @xmath185 , then @xmath186 .",
    "proofs of the above results are presented in   [ s : martproofs ] .",
    "let us look at the stopped process @xmath187 .",
    "it is clear that in this case @xmath188 whenever @xmath189 and @xmath190 whenever @xmath191 for all policies in @xmath122 ; otherwise for @xmath118 we have @xmath192 since the @xmath193-th term on the right - hand side is @xmath194 $ ] , it follows that @xmath195\\\\                  & = { \\ensuremath{\\mathsf{e}}}^\\pi_x\\biggl[\\sum_{t=1}^{(n-1){\\ensuremath{\\wedge}}\\tau } { \\ensuremath{\\boldsymbol{1}_{o}}}(x_{t{\\ensuremath{\\wedge}}\\tau'})\\biggr ] = { \\ensuremath{\\mathsf{e}}}^\\pi_x\\biggl[\\sum_{t=1}^{(n-1){\\ensuremath{\\wedge}}\\tau{\\ensuremath{\\wedge}}\\tau ' } { \\ensuremath{\\boldsymbol{1}_{o}}}(x_{t})\\biggr ] .          \\end{aligned}\\ ] ] we note that @xmath190 whenever @xmath116 .",
    "a policy that maximizes @xmath196 is defined only on the set @xmath197 , and it is left undefined elsewhere . once the process exits @xmath197 or the stage reaches @xmath198 , the task of our control policy is over .",
    "such a deterministic stationary policy ( which exists , as demonstrated below ) with a measurable selector @xmath87 should be represented as @xmath199 since it is applied only for the first @xmath108 stages ; however , for notational brevity we simply write @xmath99 hereafter .",
    "quite clearly , letting @xmath200 , the monotone convergence theorem gives @xmath201 = { \\ensuremath{\\mathsf{e}}}^\\pi_x\\biggl[\\sum_{t=1}^{\\tau}{\\ensuremath{\\boldsymbol{1}_{o}}}(x_{t{\\ensuremath{\\wedge}}\\tau{\\ensuremath{\\wedge}}\\tau'})\\biggr ] .",
    "\\end{aligned}\\ ] ] we note that by definition , the random sum inside the expectation on the right - hand side of the last equality above is the limit of partial ( finite ) sums , and this ensures that the term inside the expectation is defined on the event @xmath202 . by definition note that @xmath203.\\ ] ]    consider again the value - iteration functions defined by @xmath204 for @xmath33 and @xmath165 .",
    "the function @xmath205 is clearly identifiable with the optimal value function for the problem of maximizing @xmath206 of the process stopped at the @xmath207-th stage , @xmath165 . to get an intuitive idea , fix a deterministic markov policy @xmath208 and take the first iterate @xmath209 .",
    "( of course the assumption underlying the notation @xmath210 is that @xmath211 is defined on @xmath113 . )",
    "it is immediately clear that the reward at the first step is @xmath180 if and only if @xmath212 and @xmath14 otherwise , and that is precisely @xmath209 irrespective of the policy . for the second iterate note",
    "the reward under the policy @xmath213 is @xmath214 .",
    "this is because the reward is @xmath180 if @xmath189 and the process terminates at the first stage , or @xmath118 and the reward at the second stage is the probability of hitting @xmath101 at the second stage .",
    "of course there is no reward if @xmath191 .",
    "similarly , for the third iterate the reward is @xmath215 .",
    "note that only those sample paths that stay in @xmath197 at the first step contribute to the reward at the second stage , only those sample paths that stay in @xmath197 for the first and the second stages contribute to the reward at the third stage , and so on .",
    "our problem   can be viewed as a special case of a more general setting . to wit , consider a nonnegative upper semicontinuous reward - per - stage function @xmath216 and the problem of maximizing the total reward up to ( and including ) the hitting time @xmath108 , i.e. , maximize @xmath217 $ ] over a class of policies .",
    "this corresponds to maximization of the reward until exit from the set @xmath197 .",
    "the value - iteration functions @xmath218 corresponding to this problem can be written down readily : for @xmath33 and @xmath165 let @xmath219 .",
    "\\end{aligned}\\ ] ] our problem   corresponds to the case of @xmath220 .",
    "modulo the additional technical complications involving integrability of the value - iteration functions at each stage and the total reward corresponding to initial conditions being well - defined real numbers , the analysis of this more general problem can be carried out in exactly the same way as we do below for the problem  . while the above more general problem treats both the target set @xmath101 and the cemetery state @xmath221 equally , the bias towards the target set @xmath101 is provided in our problem   by the special structure of the reward @xmath220 .    from the general framework it is not difficult to arrive at reward - per - stage functions that are meaningful in the context of reachability , avoidance , and safety .",
    "for the sake of simplicity , till the end of this subsubsection we suppose that for all initial conditions and admissible policies @xmath164 the stopping times @xmath1 and @xmath115 are finite @xmath176-almost surely . with this assumption in place ,",
    "let us look at some examples :    * consider a discounted version of our problem  , namely , let @xmath222,\\ ] ] where @xmath40 , 1[$ ] is a constant discount factor . from the definitions of @xmath1 and @xmath115 it follows that @xmath223 , and in view of the range of @xmath224 it follows that maximization of @xmath225 over admissible policies leads to small values of @xmath1 on the set @xmath226 on an average , but it is silent about the values of @xmath1 on @xmath227 .",
    "+ to get a more quantitative idea of the role that the discount factor @xmath224 plays , let @xmath228 be a random variable independent of the markov control process defined in definition  [ d : mcp ] , can be defined in a standard way by enlarging the probability space . ] with distribution function @xmath229 for all @xmath230 . in a standard way we construct the product probability measure @xmath231 and denote the expectation with respect to this measure as @xmath232 $ ] .",
    "we can write @xmath233 = ( 1-\\alpha)^{-1}{\\ensuremath{\\mathsf{e}}}^{\\pi , \\tilde\\tau}_x\\bigl[{\\ensuremath{\\boldsymbol{1}_{o}}}(x_{\\tilde\\tau}){\\ensuremath{\\boldsymbol{1}_{\\{\\tilde\\tau { \\ensuremath{\\leqslant}}\\tau{\\ensuremath{\\wedge}}\\tau'\\}}}}\\bigr].\\ ] ] in view of the definitions of @xmath1 and @xmath115 we get @xmath234 $ ] .",
    "this alternative characterization shows that maximization of @xmath225 over admissible policies leads to smaller values of @xmath1 compared to @xmath115 ; moreover , the random variable @xmath228 gives a quantitative idea of how the choice of @xmath224 determines the outcome since @xmath228 is a geometric random variable with parameter @xmath235 .",
    "choosing a small @xmath224 implies smaller @xmath228 with higher probability and may appear to be profitable ; however , in certain problems it is possible that the set @xmath101 may be reachable at @xmath228 with small probability and the corresponding event of interest @xmath236 may be relatively small for a given initial condition @xmath95 . moreover , the factor @xmath237 is small for small values of @xmath224 , and contributes to this phenomenon . + a second quantitative view of the role of @xmath224 is offered by the fact that @xmath238 $ ] .",
    "indeed , we have @xmath239 = { \\ensuremath{\\mathsf{e}}}^{\\pi , \\tilde\\tau}_x\\biggl[\\sum_{t=0}^{\\tilde\\tau}{\\ensuremath{\\boldsymbol{1}_{o}}}(x_t){\\ensuremath{\\boldsymbol{1}_{\\{t{\\ensuremath{\\leqslant}}\\tau{\\ensuremath{\\wedge}}\\tau'\\}}}}\\biggr]\\\\                  & = { \\ensuremath{\\mathsf{e}}}^\\pi_x\\biggl[\\sum_{n=0}^\\infty \\alpha^n(1-\\alpha)\\sum_{t=0}^n { \\ensuremath{\\boldsymbol{1}_{o}}}(x_t){\\ensuremath{\\boldsymbol{1}_{\\{t{\\ensuremath{\\leqslant}}\\tau{\\ensuremath{\\wedge}}\\tau'\\}}}}\\biggr]\\\\                  & = { \\ensuremath{\\mathsf{e}}}^\\pi_x\\biggl[\\sum_{n=0}^\\infty \\sum_{t=0}^n \\alpha^n{\\ensuremath{\\boldsymbol{1}_{o}}}(x_t){\\ensuremath{\\boldsymbol{1}_{\\{t{\\ensuremath{\\leqslant}}\\tau{\\ensuremath{\\wedge}}\\tau'\\ } } } } - \\sum_{n=0}^\\infty\\sum_{t=0}^n\\alpha^{n+1}{\\ensuremath{\\boldsymbol{1}_{o}}}(x_t){\\ensuremath{\\boldsymbol{1}_{\\{t{\\ensuremath{\\leqslant}}\\tau{\\ensuremath{\\wedge}}\\tau'\\}}}}\\biggr]\\\\                  & = { \\ensuremath{\\mathsf{e}}}^\\pi_x\\biggl[\\sum_{t=0}^\\infty \\sum_{n = t}^\\infty \\alpha^n{\\ensuremath{\\boldsymbol{1}_{o}}}(x_t){\\ensuremath{\\boldsymbol{1}_{\\{t{\\ensuremath{\\leqslant}}\\tau{\\ensuremath{\\wedge}}\\tau'\\ } } } } - \\sum_{t=0}^\\infty\\sum_{n = t}^\\infty\\alpha^{n+1}{\\ensuremath{\\boldsymbol{1}_{o}}}(x_t){\\ensuremath{\\boldsymbol{1}_{\\{t{\\ensuremath{\\leqslant}}\\tau{\\ensuremath{\\wedge}}\\tau'\\}}}}\\biggr]\\\\                  & = { \\ensuremath{\\mathsf{e}}}^\\pi_x\\biggl[\\sum_{t=0}^\\infty \\frac{\\alpha^t}{1-\\alpha}{\\ensuremath{\\boldsymbol{1}_{o}}}(x_t){\\ensuremath{\\boldsymbol{1}_{\\{t{\\ensuremath{\\leqslant}}\\tau{\\ensuremath{\\wedge}}\\tau'\\ } } } } - \\sum_{t=0}^\\infty\\frac{\\alpha^{t+1}}{1-\\alpha}{\\ensuremath{\\boldsymbol{1}_{o}}}(x_t){\\ensuremath{\\boldsymbol{1}_{\\{t{\\ensuremath{\\leqslant}}\\tau{\\ensuremath{\\wedge}}\\tau'\\}}}}\\biggr]\\\\                  & = { \\ensuremath{\\mathsf{e}}}^\\pi_x\\biggl[\\sum_{t=0}^\\infty\\alpha^t{\\ensuremath{\\boldsymbol{1}_{o}}}(x_t){\\ensuremath{\\boldsymbol{1}_{\\{t{\\ensuremath{\\leqslant}}\\tau{\\ensuremath{\\wedge}}\\tau'\\}}}}\\biggr ] = { \\ensuremath{\\mathsf{e}}}^\\pi_x\\biggl[\\sum_{t=0}^{\\tau{\\ensuremath{\\wedge}}\\tau'}\\alpha^t{\\ensuremath{\\boldsymbol{1}_{o}}}(x_t)\\biggr ] = v^{(1)}(\\pi , x ) .              \\end{aligned}\\ ] ] in this setting we do not have the @xmath237 factor outside the expectation as in the second version of @xmath225 above , and it demonstrates that maximizing @xmath240 over admissible policies leads to maximizing the probability of the event @xmath241 , where @xmath224 controls the values of @xmath228 as before . *",
    "consider the reward - per - stage function @xmath242 .",
    "under integrability assumption on @xmath108 under all admissible policies , we have @xmath243\\\\                  & = { \\ensuremath{\\mathsf{e}}}^\\pi_x\\biggl[\\sum_{t=0}^{\\tau{\\ensuremath{\\wedge}}\\tau'}\\bigl({\\ensuremath{\\boldsymbol{1}_{o}}}(x_t ) - { \\ensuremath{\\boldsymbol{1}_{k{\\ensuremath{\\smallsetminus}}o}}}(x_t ) - {",
    "\\ensuremath{\\boldsymbol{1}_{x{\\ensuremath{\\smallsetminus}}k}}}(x_t)\\bigr)\\biggr]\\\\                  & = { \\ensuremath{\\mathsf{p}}}^\\pi_x(\\tau < \\tau ' ) - { \\ensuremath{\\mathsf{p}}}^\\pi_x(\\tau ' < \\tau ) - { \\ensuremath{\\mathsf{e}}}^\\pi_x[\\tau{\\ensuremath{\\wedge}}\\tau ' ] .              \\end{aligned}\\ ] ] clearly , maximization of @xmath244 over admissible policies leads to both the maximal enlargement of the set @xmath226 and minimization of the hitting time @xmath1 on this set . *",
    "consider @xmath245 .",
    "this leads to the expected total reward until escape from @xmath197 as[page : v3 ] @xmath246 = { \\ensuremath{\\mathsf{p}}}^\\pi_x(\\tau < \\tau ' ) - { \\ensuremath{\\mathsf{p}}}^\\pi_x(\\tau ' < \\tau).\\ ] ] since @xmath247 , maximization of @xmath248 over admissible policies maximizes the probability of the event @xmath226 .",
    "thus , maximizing @xmath249 over @xmath164 is a different formulation of the objective of our problem  .",
    "the above analysis also shows that the same objective results if we take the reward - per - stage function to be @xmath250 for any @xmath251 . *",
    "suppose that @xmath108 is integrable for all admissible policies and consider the reward - per - stage @xmath252 .",
    "let @xmath253.\\ ] ] maximization of @xmath254 over admissible policies leads to large values of @xmath108 on an average .",
    "this is a form of safety problem , the state stays inside @xmath197 for as long as possible on an average .",
    "* suppose that @xmath108 is integrable for all admissible policies and consider @xmath255 for @xmath256 .",
    "consider @xmath257,\\ ] ] we see that @xmath258 $ ] .",
    "we see that maximization of @xmath259 over admissible policies leads to a balance between maximizing the probability that the state hits the set @xmath101 before getting out of @xmath102 and exiting @xmath102 quickly .",
    "this is because it is more profitable to exit from @xmath102 and get a zero reward than incur negative reward by prolonging the duration of stay in @xmath197 .",
    "the factor @xmath260 decides the priorities of the two alternatives .",
    "it is trivially clear that @xmath261 leads to rapid exit from @xmath102 if the initial condition is in @xmath197 .",
    "not all the reward - per - stage functions mentioned above can be handled in our present framework .",
    "in particular , we make the crucial assumption that the reward - per - stage function is nonnegative , which does not hold in some of the cases above .",
    "however , under appropriate growth - rate conditions on the reward - per - stage function , the nonnegativity assumption can be dispensed with .    in classical finite or infinite - horizon",
    "optimal control problems a translation of the ( fixed ) reward - per - stage function would not change the solution to the problem . however , translations of the reward - per - stage function in random - horizon problems may lead to drastically different policies .",
    "we give two examples :    * consider the reward - per - stage functions @xmath262 and @xmath263 ; in this case we translate @xmath264 on @xmath21 by @xmath180 , i.e. , @xmath265 .",
    "on the one hand , maximizing @xmath266 $ ] yields a policy that @xmath267 as we have seen before ( this is @xmath248 above ) . on the other hand , maximizing @xmath268 $ ] yields a policy that tries to keep the state in @xmath197 for as long as possible , and at each stage accrue a reward of @xmath180 , which is certainly better than jumping to @xmath101 and accruing a reward of @xmath269 at most . * consider @xmath262 and @xmath270 ; in this case we translate @xmath264 by @xmath271 only on its support @xmath272 .",
    "we have noted above that maximizing @xmath273 $ ] yields a policy that maximizes @xmath267 .",
    "however , maximizing @xmath274 $ ] yields a policy that tries to keep the state in @xmath197 for the longest possible duration to avoid incurring negative reward .      for one - dimensional stochastic processes initialized somewhere between two different levels @xmath15 and @xmath16 , problems such as calculating the probability of hitting the level @xmath15",
    "before the level @xmath16 are fairly common , e.g. , in random walks , brownian motion , and diffusions , see , e.g. ,  ( * ? ? ?",
    "* chapters  2 - 3 ) ,  @xcite .",
    "it is possible to obtain explicit expressions of these probabilities in a handful of cases .",
    "let us consider a controlled markov chain @xmath275 with a finite state - space @xmath276 and a transition probability matrix @xmath277_{m\\times m}$ ] , where @xmath15 is the action or control variable .",
    "let @xmath278 , @xmath279 be subsets of @xmath21 with @xmath103 . since @xmath21 is finite , assumption  [ a : key ] is satisfied .",
    "consider the problem   in the context of this markov chain @xmath275 initialized at some @xmath280 . by theorem  [ t : exist ]",
    "the optimal value function @xmath150 must satisfy the equation @xmath281 for all @xmath282 .",
    "if the control actions are finite in number , searching for a maximizer over an enumerated list all control actions corresponding to each of the states may be possible if the state and action spaces are not too large .",
    "however , the memory requirement for storing such enumerated lists clearly increases exponentially with the dimension of the state and action spaces if the markov chain is extracted by a discretization procedure based on a grid on the state - space of a discrete - time markov process evolving , for example , on a subset of euclidean space . as an alternative ,",
    "it is possible to search for a maximizer from a parametrized family of functions ( vectors ) by applying well - known suboptimal control strategies  ( * ? ? ?",
    "* chapter  6 ) , @xcite .",
    "note that in the case of an uncontrolled markov chain the equation above reduces to @xmath283 , and can be solved as a linear equation on @xmath197 for the vector @xmath284 .",
    "thus , solving for @xmath150 yields a method of calculating the probability of hitting @xmath101 before hitting @xmath221 in uncontrolled markov chains , and can serve as a verification tool  @xcite .    in certain cases of uncountable state - space markov chains",
    "the policies and value functions corresponding to maximization of @xmath206 can be explicitly calculated for small values of @xmath285 . as an illustration ,",
    "consider a scalar linear controlled system @xmath286 here @xmath287 is the state of the system at time @xmath111 , @xmath288 is the action or control at time @xmath111 taking values in @xmath289 $ ] , and @xmath290 is a sequence of independent and identically distributed ( i.i.d ) standard normal random variables treated as noise inputs to the system . let us suppose that our target set is @xmath291 - 1 , 1[$ ] , safe set is @xmath292 $ ] , and let us find a greedy policy for our problem , i.e. , a policy that maximizes @xmath293 .",
    "l[0mm]0.5        the greedy policy tries to maximize @xmath294 - 1 , 1[\\bigr ) = { \\ensuremath{\\mathsf{p}}}_x\\bigl(x + a + w\\in\\;]-1 , 1[\\bigr ) = \\mathfrak",
    "n(1-x - a ) -\\mathfrak n(-1-x - a ) = : g(x , a)$ ] , where @xmath295 is the cumulative distribution function of the standard normal random variable .",
    "the function @xmath296 can be expressed in terms of the complementary error function , where @xmath297 is the standard error function . ] as @xmath298 , and @xmath299}g(x , a)$ ] can be solved in closed form .",
    "indeed , @xmath300 gives @xmath301 as the unconstrained optimizer .",
    "since @xmath302 $ ] , we have the constrained maximizer as @xmath303 , where @xmath304 is the standard saturation function .",
    "equals @xmath305 if @xmath306 , @xmath180 if @xmath307 and @xmath308 otherwise . ] in other words , we get a bang - bang controller since @xmath309 on the interior of @xmath197 .",
    "it is easy to discern the maximizer from the accompanying figure .",
    "the corresponding maximal probability is found by substituting the above optimizer back into the dynamic programming equation , and this yields @xmath310 .",
    "for @xmath311 it turns out that we can no longer compute the optimizer corresponding to the first stage in closed form ; the optimizer for the second stage is , of course , @xmath303 calculated above .",
    "it is also evident from the accompanying figure that even in this simple example there will arise nontrivial issues with nonconvexity for @xmath312 .",
    "so far in our discussion we have not addressed the issue of uniqueness of the optimal policy in our problem  .",
    "( theorem  [ t : exist ] shows that an optimal policy exists , so the uniqueness question is meaningful . ) it becomes clear from considerations of the geometry of the sets @xmath101 and @xmath102 in simple examples that the optimal controller @xmath313 in theorem  [ t : exist]_[co : exist:2 ] _ is nonunique in general .",
    "for instance , consider the linear system considered in   above with initial condition @xmath314 , and let @xmath315 - 2 , -1[\\;\\cup\\;]1 , 2[$ ] and @xmath292 $ ] . since the noise is symmetric about the origin , from symmetry considerations it immediately follows that the optimal controller @xmath313 is nonunique at the origin .",
    "note that @xmath313 is , of course , defined on @xmath197 .",
    "let us digress a little and consider the following probabilistic safety problem : maximize the probability that the state remains inside a safe set @xmath316 for @xmath285 stages , beginning from an initial condition @xmath317 .",
    "this , as mentioned earlier , is the probabilistic safety problem addressed in  @xcite .",
    "of course the probability of staying inside @xmath318 for the first @xmath285 stages is given by @xmath319 $ ] .",
    "if @xmath22 is the first exit time from @xmath318 , then @xmath320 $ ] . therefore , in this particular problem there is no difference between the maximal values of @xmath321 $ ] or @xmath322 $ ] . however , the policies arising from the two different maximizations are quite unlike each other . indeed , whereas the former yields a deterministic markov policy  @xcite whose every element is defined on all of @xmath21 , the stopping time version yields a deterministic markov policy whose @xmath111-th element @xmath112 is defined on the set @xmath323 , just as discussed in paragraph  [ pgr : policies ] . on the one hand note that the reward in the former case is not affected by further application of the control actions once the state has exited the safe set @xmath318 ; the policy resulting from this formulation , however , dictates that the control actions are carried out until ( and including ) the @xmath324-th stage nonetheless . on the other hand , the reward in the latter stopping time version saturates at the stage the state leaves @xmath318 and future control actions are not defined .",
    "it is interesting to note that the bellman equation developed for probabilistic safety and reachability in  @xcite may be obtained as a special case of   in theorem  [ t : exist ] above .",
    "this comes as no surprise .",
    "the problem of maximizing the probability of staying inside a ( measurable ) safe set @xmath316 for @xmath325 steps is given by the maximization of @xmath326 $ ] , where @xmath22 is the first time to exit @xmath318 and this clearly translates to minimizing @xmath327 . in our setting , if we let @xmath102 be the entire state - space @xmath21 , @xmath328 , and @xmath1 the first time to hit the set @xmath101 , then our problem   is precisely that in  @xcite with the exception of maximization in place of minimization .",
    "it must be mentioned however , that the analysis carried out in  @xcite relies on the approach in  @xcite and is purely analytical ; the strong feller assumption on the transition kernel in our formulation plays no role there .",
    "this section collects the proofs of the various results in   [ s : results ] .",
    "we recall a few standard results about set - valued maps first , followed by sequence of lemmas before getting to the proof of theorem  [ t : exist ] .",
    "the various definitions in paragraphs  [ pgr : policies ] , [ pgr : recalldef ] , and  [ pgr : altrep ] will be employed without further reference . just as in   [ s : mainres ] , for the purposes of this subsection , we let @xmath122 denote the set of admissible markov policies such that @xmath112 is defined on @xmath37 whenever @xmath123 .",
    "[ p : uhccorr ] let @xmath132 be an upper hemicontinuous set - valued map between topological spaces with nonempty compact values , and let @xmath329 be upper semicontinuous .",
    "is the set @xmath330 , the graph of the set - valued map @xmath138 . ]",
    "define the function @xmath331 by @xmath332 .",
    "then the function @xmath333 is upper semicontinuous .",
    "[ p : meascorr ] let @xmath21 be a separable metrizable space and @xmath334 a measurable space .",
    "let @xmath335 be a weakly measurable correspondence with nonempty compact values , and suppose @xmath336 is a carathodory function .",
    "is a mapping that is measurable in the first variable and continuous in the second , where @xmath334 is a measurable space and @xmath337 are topological spaces . in particular , if @xmath21 is a separable and metrizable space , and @xmath24 is a metrizable space , every carathodory function @xmath338 is jointly measurable  ( * ? ? ?",
    "* lemma  4.51 ) ; this is clearly true in the carathodory functions we consider .",
    "] let us also define the function @xmath339 by @xmath340 , and the correspondence @xmath341 of maximizers by @xmath342 .",
    "then the argmax correspondence @xmath343 is measurable and admits a measurable selector .     for @xmath344",
    "we define the mapping @xmath345 @xmath346 the operator @xmath347 is called the _ dynamic programming operator _ corresponding to the problem  .",
    "[ l : l0tol0 ] suppose that assumption   holds .",
    "then the dynamic programming operator @xmath347 defined in   takes @xmath348 into itself .",
    "moreover , there exists a measurable selector @xmath87 such that @xmath349    fix @xmath344 .",
    "since the transition kernel @xmath36 is strongly feller on @xmath37 , the mapping @xmath350 is continuous on @xmath37 .",
    "also , @xmath351 is bounded whenever @xmath352 is , a bound of @xmath353 being the essential supremum norm of @xmath352 .",
    "therefore , since @xmath32 is compact for each @xmath33 , the function @xmath354 is well - defined on @xmath197 , i.e. , the sup is attained on @xmath32 for @xmath118 .",
    "we also note that since @xmath197 is a measurable set , by assumption  [ a : key ]    * the correspondence @xmath121 is upper hemicontinuous , and since @xmath353 is continuous on @xmath37 , the map @xmath355 is an u.s.c .",
    "function by proposition  [ p : uhccorr ] ; * the correspondence @xmath121 is weakly measurable , and since @xmath353 is continuous on @xmath37 ( and therefore is a carathodory function ) , there exists a measurable selector @xmath87 such that @xmath356 for all @xmath118 by proposition  [ p : meascorr ] .",
    "it follows at once that @xmath357 is a member of the set @xmath147 , and the assertion follows .",
    "[ l : dominate ] suppose that hypotheses of theorem   hold . if @xmath344 satisfies the inequality @xmath358 pointwise on @xmath21 , then also @xmath359 pointwise on @xmath21 , where @xmath347 is the dynamic programming operator in  .    by definition of @xmath347",
    "it is clear that we only need to examine the validity of the assertion on @xmath197 .",
    "suppose that @xmath344 satisfies the inequality @xmath360 pointwise on @xmath21 .",
    "by lemma  [ l : l0tol0 ] we know that there exists @xmath87 satisfying @xmath361 a straightforward calculation shows that if @xmath358 then @xmath362 on @xmath197 .",
    "fix @xmath118 . applying the inequality @xmath360",
    "repeatedly we have @xmath363\\\\                  & \\cdots              \\end{aligned}\\ ] ] and after @xmath285 steps @xmath364\\cdots\\biggr]\\\\                  & = \\biggl({\\ensuremath{\\boldsymbol{1}_{o}}}(x ) + { \\ensuremath{\\boldsymbol{1}_{k{\\ensuremath{\\smallsetminus}}o}}}(x)\\int_k q({\\ensuremath{\\mathrm{d}}}\\xi_1|x , f)\\biggl[{\\ensuremath{\\boldsymbol{1}_{o}}}(\\xi_1 ) + \\ldots \\\\                  & \\qquad\\qquad \\ldots + { \\ensuremath{\\boldsymbol{1}_{k{\\ensuremath{\\smallsetminus}}o}}}(\\xi_{n-2})\\int_o q({\\ensuremath{\\mathrm{d}}}\\xi_{n-1}|\\xi_{n-2 } , f)\\biggr]\\biggr)\\\\                  & \\quad + \\biggl({\\ensuremath{\\boldsymbol{1}_{k{\\ensuremath{\\smallsetminus}}o}}}(x)\\int_{k{\\ensuremath{\\smallsetminus}}o}q({\\ensuremath{\\mathrm{d}}}\\xi_1|x , f)\\int_{k{\\ensuremath{\\smallsetminus}}o}q({\\ensuremath{\\mathrm{d}}}\\xi_2|\\xi_1 , f)\\cdots\\int_{k}q({\\ensuremath{\\mathrm{d}}}\\xi_{n}|\\xi_{n-1 } , f)u(\\xi_n)\\biggr ) .",
    "\\end{aligned}\\ ] ] we claim that the right - hand side of the last equality above is @xmath365 + { \\ensuremath{\\mathsf{e}}}^{f^\\infty}_x\\bigl[{\\ensuremath{\\boldsymbol{1}_{k{\\ensuremath{\\smallsetminus}}o}}}(x_{(n-1){\\ensuremath{\\wedge}}\\tau{\\ensuremath{\\wedge}}\\tau'})({\\ensuremath{\\boldsymbol{1}_{k}}}\\cdot u)(x_{n{\\ensuremath{\\wedge}}\\tau{\\ensuremath{\\wedge}}\\tau'}){\\ensuremath{\\boldsymbol{1}_{\\{\\tau{\\ensuremath{\\wedge}}\\tau ' < \\infty\\}}}}\\bigr],\\ ] ] where @xmath366 for @xmath367 . to see this note that the first term is clear by definition .",
    "the second term above is due to the fact that only those trajectories that stay in @xmath197 for @xmath285 steps ( i.e. , from stage @xmath14 through stage @xmath198 ) contribute to the integrand that features @xmath352 , and this accounts for the factor @xmath368 .",
    "since @xmath202 is a full measure set , the factor @xmath369 does not change the value of the integral . taking the limit of the first term above as @xmath200 , the monotone convergence theorem gives @xmath370 = { \\ensuremath{\\mathsf{e}}}^{f^\\infty}_x\\biggl[\\sum_{t=0}^{\\tau{\\ensuremath{\\wedge}}\\tau'}{\\ensuremath{\\boldsymbol{1}_{o}}}(x_t)\\biggr ] = v(f^\\infty ,",
    "x ) { \\ensuremath{\\leqslant}}v^\\star(x),\\ ] ] where the last inequality follows from the definition of @xmath150 . since @xmath352 is bounded and nonnegative , taking the limit of the second term above as @xmath200 , the dominated convergence theorem gives @xmath371\\\\                  & = { \\ensuremath{\\mathsf{e}}}^{f^\\infty}_x\\bigl[{\\ensuremath{\\boldsymbol{1}_{k{\\ensuremath{\\smallsetminus}}o}}}(x_{\\tau{\\ensuremath{\\wedge}}\\tau'})({\\ensuremath{\\boldsymbol{1}_{k}}}\\cdot u)(x_{\\tau{\\ensuremath{\\wedge}}\\tau'}){\\ensuremath{\\boldsymbol{1}_{\\{\\tau{\\ensuremath{\\wedge}}\\tau ' < \\infty\\}}}}\\bigr]\\\\                  & = 0              \\end{aligned}\\ ] ] since @xmath372 on the set @xmath202 by definition of the stopping times @xmath1 and @xmath115 . substituting back",
    "we see that @xmath373 , and the assertion follows since @xmath118 is arbitrary .",
    "[ l : vstarsatisfy ] suppose that assumption   holds",
    ". then the value iteration functions @xmath374 defined in   satisfy @xmath375 , and the function @xmath150 satisfies the bellman equation  .    from the definition of the value - iteration functions",
    "@xmath374 in   we see that @xmath374 is a monotone increasing sequence bounded above by @xmath376 .",
    "therefore there exists a measurable function @xmath377 $ ] such that @xmath378 pointwise on @xmath21 . by definition of @xmath205",
    "we have @xmath379 { \\ensuremath{\\leqslant}}\\sup_{\\pi\\in\\pi_m}{\\ensuremath{\\mathsf{e}}}^\\pi_x\\biggl[\\sum_{t=0}^{(n-1){\\ensuremath{\\wedge}}\\tau{\\ensuremath{\\wedge}}\\tau'}{\\ensuremath{\\boldsymbol{1}_{o}}}(x_t)\\biggr ] = v_n(x),\\ ] ] and the monotone convergence theorem shows that @xmath380 = { \\ensuremath{\\mathsf{e}}}^\\pi_x\\biggl[\\sum_{t=0}^{\\tau{\\ensuremath{\\wedge}}\\tau'}{\\ensuremath{\\boldsymbol{1}_{o}}}(x_t)\\biggr ] = v(\\pi , x).\\ ] ] taking the supremum over @xmath381 on the right - hand side shows that @xmath382 pointwise on @xmath21 .",
    "note that @xmath383 and @xmath384 for all @xmath285 ; therefore @xmath385 and @xmath386 .",
    "let us define the maps @xmath387,\\\\                  \\mathbb k\\ni ( x , a){\\ensuremath{\\longmapsto}}t'v^\\star(x , a ) & { \\mathrel{\\mathop:\\!\\!=}}\\int_{k}q({\\ensuremath{\\mathrm{d}}}y|x , a ) v^\\star(y)\\in[0 , 1 ] .",
    "\\end{aligned}\\ ] ] we note that the transition kernel @xmath36 is strongly feller by assumption  [ a : key ] , and therefore @xmath388 and @xmath389 are continuous functions on @xmath37 .",
    "moreover , for all @xmath230 we define @xmath390 since @xmath378 pointwise on @xmath21 , it follows from the definitions above and the monotone convergence theorem that for all @xmath33 and @xmath391 @xmath392 fix @xmath118 .",
    "since @xmath393 and @xmath389 are continuous functions on @xmath37 , for each @xmath230 both @xmath394 and @xmath395 are attained on @xmath32 . from the definition of @xmath374 in",
    "we have @xmath396 for all @xmath230 .",
    "also , @xmath397 is a nondecreasing sequence of numbers bounded above by @xmath180 , and therefore it attains a limit .",
    "if this limit is strictly less than @xmath398 , standard easy arguments may be invoked to show that the sequence of continuous functions @xmath399 can not converge pointwise to @xmath400 on @xmath32 , which contradicts  .",
    "it follows that whenever @xmath118 , @xmath401 together with   this shows that @xmath402 satisfies the bellman equation   pointwise on @xmath21 , i.e. , @xmath403 .",
    "we have already seen above that @xmath382 pointwise on @xmath21 . since @xmath403",
    ", the reverse inequality follows from lemma  [ l : dominate ] . therefore",
    ", we conclude that @xmath404 identically on @xmath21 .",
    "[ l : dsstrategy ] let @xmath99 be a deterministic stationary policy",
    ". then we have @xmath405    for @xmath116 the assertions are trivial .",
    "fix @xmath118 . from the definition of @xmath406 we have @xmath407\\nonumber\\\\                  & = { \\ensuremath{\\mathsf{e}}}^{f^\\infty}\\biggl[{\\ensuremath{\\boldsymbol{1}_{o}}}(x_0){\\ensuremath{\\boldsymbol{1}_{\\{\\tau{\\ensuremath{\\wedge}}\\tau ' = 0\\ } }",
    "} } + { \\ensuremath{\\boldsymbol{1}_{\\{\\tau{\\ensuremath{\\wedge}}\\tau ' > 0\\}}}}\\sum_{t=1}^{\\tau{\\ensuremath{\\wedge}}\\tau'}{\\ensuremath{\\boldsymbol{1}_{o}}}(x_t)\\,\\bigg|\\,x_0 = x\\biggr]\\nonumber\\\\                  & = { \\ensuremath{\\boldsymbol{1}_{o}}}(x ) + { \\ensuremath{\\mathsf{e}}}^{f^\\infty}\\biggl[{\\ensuremath{\\boldsymbol{1}_{\\{\\tau{\\ensuremath{\\wedge}}\\tau ' > 0\\}}}}\\sum_{t=1}^{\\tau{\\ensuremath{\\wedge}}\\tau'}{\\ensuremath{\\boldsymbol{1}_{o}}}(x_t)\\,\\bigg|\\ , x_0 = x\\biggr ] .",
    "\\end{aligned}\\ ] ] since @xmath408 and this event is @xmath409-measurable , @xmath410 = { \\ensuremath{\\boldsymbol{1}_{k{\\ensuremath{\\smallsetminus}}o}}}(x){\\ensuremath{\\mathsf{e}}}^{f^\\infty}\\biggl[\\sum_{t=1}^{\\tau{\\ensuremath{\\wedge}}\\tau'}{\\ensuremath{\\boldsymbol{1}_{o}}}(x_t)\\,\\bigg|\\,x_0 = x\\biggr].\\ ] ] therefore , @xmath411\\\\                  & = { \\ensuremath{\\boldsymbol{1}_{o}}}(x ) + { \\ensuremath{\\boldsymbol{1}_{k{\\ensuremath{\\smallsetminus}}o}}}(x){\\ensuremath{\\mathsf{e}}}^{f^\\infty}\\biggl[\\sum_{t=1}^{\\tau}{\\ensuremath{\\boldsymbol{1}_{o}}}(x_{t{\\ensuremath{\\wedge}}\\tau{\\ensuremath{\\wedge}}\\tau'})\\,\\bigg|\\,x_0 = x\\biggr ] .",
    "\\end{aligned}\\ ] ] considering the fact that @xmath412 for @xmath191 by definition , the markov property shows that the second term on the right - hand side above equals @xmath413\\,\\bigg|\\,x_0 = x\\biggr]\\\\                  & = { \\ensuremath{\\boldsymbol{1}_{k{\\ensuremath{\\smallsetminus}}o}}}(x ) \\int_k q({\\ensuremath{\\mathrm{d}}}y|x , f){\\ensuremath{\\mathsf{e}}}^{f^\\infty}\\biggl[\\sum_{t=1}^{\\tau}{\\ensuremath{\\boldsymbol{1}_{o}}}(x_{t{\\ensuremath{\\wedge}}\\tau{\\ensuremath{\\wedge}}\\tau'})\\,\\bigg|\\,x_{1{\\ensuremath{\\wedge}}\\tau{\\ensuremath{\\wedge}}\\tau ' } = y\\biggr]\\\\                  & = { \\ensuremath{\\boldsymbol{1}_{k{\\ensuremath{\\smallsetminus}}o}}}(x ) \\int_k q({\\ensuremath{\\mathrm{d}}}y|x , f ) v(f^\\infty , y ) .",
    "\\end{aligned}\\ ] ] collecting the above equations we obtain  , and this completes the proof .",
    "we are now ready for the proof of the first main result .",
    "\\(i ) note that by definition @xmath150 is nonnegative .",
    "the fact that @xmath150 satisfies the bellman equation follows from lemma  [ l : vstarsatisfy ] . in view of the definition of @xmath414 in theorem  [ t : exist ] and lemma  [ l : vstarsatisfy ] we conclude that @xmath150 is minimal in @xmath348 because @xmath415 pointwise on @xmath197 implies that @xmath359 pointwise on @xmath197 for any @xmath344 .",
    "\\(ii ) lemma  [ l : l0tol0 ] guarantees the existence of a selector @xmath154 such that   holds .",
    "iterating the equality   ( or  ) it follows as in the proof of lemma  [ l : dominate ] that for @xmath33 , @xmath416 + { \\ensuremath{\\mathsf{e}}}^{f_\\star^\\infty}_x\\bigl[{\\ensuremath{\\boldsymbol{1}_{k{\\ensuremath{\\smallsetminus}}o}}}(x_{(n-1){\\ensuremath{\\wedge}}\\tau{\\ensuremath{\\wedge}}\\tau'})({\\ensuremath{\\boldsymbol{1}_{k } } } v^\\star)(x_{n{\\ensuremath{\\wedge}}\\tau{\\ensuremath{\\wedge}}\\tau'})\\bigr].\\ ] ] taking limits as @xmath200 on the right , the monotone and dominated convergence theorems give @xmath417 .",
    "since @xmath95 is arbitrary , @xmath418 on @xmath197 and that @xmath157 is an optimal policy .",
    "conversely , by lemma  [ l : dsstrategy ] it follows that under the stationary deterministic strategy @xmath157 we have   with @xmath313 in place of @xmath419 , which is identical to  .      for the purposes of this subsection we let @xmath54 denote the set of admissible policies such that @xmath112 is defined on @xmath37 whenever @xmath420 .",
    "[ l : bothsupmart ] for every policy @xmath164 and initial state @xmath33 the processes @xmath167 and @xmath421 are both nonnegative @xmath105- supermartingales under @xmath176 .",
    "it is clear that both processes are nonnegative and @xmath105-adapted .",
    "fix @xmath165 , an initial state @xmath33 , a policy @xmath164 , and on the event @xmath172 fix a history @xmath422 .",
    "let @xmath423 on @xmath172 .",
    "then @xmath424 since @xmath425 , we have @xmath426 since @xmath427 , it follows that @xmath428 therefore , keeping in mind the definition of @xmath171 above , @xmath429 & = w_n(\\pi , x ) + { \\ensuremath{\\boldsymbol{1}_{k{\\ensuremath{\\smallsetminus}}o}}}(x_{(n-1){\\ensuremath{\\wedge}}\\tau{\\ensuremath{\\wedge}}\\tau ' } ) t'v^\\star(x_{n{\\ensuremath{\\wedge}}\\tau{\\ensuremath{\\wedge}}\\tau ' } , a_n)\\nonumber\\\\                  & { \\ensuremath{\\leqslant}}w_n(\\pi , x ) + { \\ensuremath{\\boldsymbol{1}_{k{\\ensuremath{\\smallsetminus}}o}}}(x_{(n-1){\\ensuremath{\\wedge}}\\tau{\\ensuremath{\\wedge}}\\tau'})v^\\star(x_{n{\\ensuremath{\\wedge}}\\tau{\\ensuremath{\\wedge}}\\tau'})\\\\                  & = \\zeta_n,\\nonumber              \\end{aligned}\\ ] ] where the inequality holds @xmath176-almost surely .",
    "therefore , the process @xmath167 is a nonnegative @xmath430- supermartingale , and hence also a @xmath105- supermartingale . considering that the sequence @xmath431 is nondecreasing , from the definitions in   and the fact that the process @xmath167 is a @xmath105- supermartingale we see that the process @xmath432 is also a @xmath105- supermartingale under @xmath176 .",
    "lemma  [ l : bothsupmart ] confirms that both of the two adapted processes @xmath167 and @xmath433 converge almost surely and are nonincreasing in expectation , both under @xmath176 . let @xmath434 $ ] .",
    "we then have @xmath435 { \\ensuremath{\\geqslant}}\\lim_{n\\to\\infty}{\\ensuremath{\\mathsf{e}}}^\\pi_x[\\zeta_n]\\nonumber\\\\                  & = \\lim_{n\\to\\infty}\\bigl({\\ensuremath{\\mathsf{e}}}^\\pi_x\\bigl[w_n(\\pi , x)\\bigr ] + { \\ensuremath{\\mathsf{e}}}^\\pi_x\\bigl[{\\ensuremath{\\boldsymbol{1}_{k{\\ensuremath{\\smallsetminus}}o}}}(x_{(n-1){\\ensuremath{\\wedge}}\\tau{\\ensuremath{\\wedge}}\\tau'})({\\ensuremath{\\boldsymbol{1}_{k}}}v^\\star)(x_{n{\\ensuremath{\\wedge}}\\tau{\\ensuremath{\\wedge}}\\tau'})\\bigr]\\bigr)\\\\                  & { \\ensuremath{\\geqslant}}v(\\pi , x).\\nonumber              \\end{aligned}\\ ] ] the assertion is now an immediate consequence of  .",
    "suppose that ( i ) holds .",
    "since @xmath436 $ ] is nonincreasing with @xmath285 it follows that @xmath437 = { \\ensuremath{\\mathsf{e}}}^\\pi_x[\\zeta_n ] = \\ldots = { \\ensuremath{\\mathsf{e}}}^\\pi_x[\\zeta_0 ] = v^\\star(x)$ ] for every @xmath165 .",
    "therefore , equality must hold @xmath176-almost surely in  , and ( ii ) follows .",
    "suppose that ( ii ) holds .",
    "then equality holds in   almost surely under @xmath176 , and therefore @xmath176-almost everywhere on the set @xmath438 we have @xmath439 , and ( iii ) follows .",
    "suppose that ( iii ) holds .",
    "then taking expectations in   we arrive at @xmath437 = { \\ensuremath{\\mathsf{e}}}^\\pi_x[\\zeta_n ] = \\ldots = { \\ensuremath{\\mathsf{e}}}^\\pi_x[\\zeta_0 ] = v^\\star(x)$ ] . as a result",
    "we have @xmath440 , and ( i ) follows .",
    "it follows readily from the definition of the stopping times @xmath1 and @xmath115 that the process @xmath181 defined in   is a bounded process , and by assumption it is a @xmath105 -martingale under @xmath185 .",
    "doob s optional sampling theorem  ( * ? ? ?",
    "* theorem  2 , p.  422 ) applied to @xmath181 at the stopping time @xmath108 gives us @xmath441 = { \\ensuremath{\\mathsf{e}}}^{\\pi^\\star}_x\\bigl[\\zeta'_0\\bigr ] = v'(x),\\ ] ] where the last equality follows from the definition of @xmath442 . from",
    "we get @xmath443 & = { \\ensuremath{\\mathsf{e}}}^{\\pi^\\star}_x\\bigl[w_{\\tau{\\ensuremath{\\wedge}}\\tau'-1}(\\pi^\\star , x ) + { \\ensuremath{\\boldsymbol{1}_{k{\\ensuremath{\\smallsetminus}}o}}}(x_{\\tau{\\ensuremath{\\wedge}}\\tau'-1})\\bigl({\\ensuremath{\\boldsymbol{1}_{k}}}\\cdot v'\\bigr)(x_{\\tau{\\ensuremath{\\wedge}}\\tau'})\\bigr]\\\\                  & = { \\ensuremath{\\mathsf{e}}}^{\\pi^\\star}_x\\biggl[\\sum_{t=0}^{\\tau{\\ensuremath{\\wedge}}\\tau'-1 } { \\ensuremath{\\boldsymbol{1}_{o}}}(x_t ) + { \\ensuremath{\\boldsymbol{1}_{k{\\ensuremath{\\smallsetminus}}o}}}(x_{\\tau{\\ensuremath{\\wedge}}\\tau'-1})\\bigl({\\ensuremath{\\boldsymbol{1}_{k}}}\\cdot v'\\bigr)(x_{\\tau{\\ensuremath{\\wedge}}\\tau'})\\biggr]\\\\                  & = { \\ensuremath{\\mathsf{e}}}^{\\pi^\\star}_x\\bigl[{\\ensuremath{\\boldsymbol{1}_{k{\\ensuremath{\\smallsetminus}}o}}}(x_{\\tau{\\ensuremath{\\wedge}}\\tau'-1})\\bigl({\\ensuremath{\\boldsymbol{1}_{k}}}\\cdot v'\\bigr)(x_{\\tau{\\ensuremath{\\wedge}}\\tau'})\\bigr ] .",
    "\\end{aligned}\\ ] ] by definition of @xmath1 and @xmath115 , @xmath444 equals @xmath180 on @xmath202 , and by our hypotheses the set @xmath202 is a @xmath185-full - measure set . continuing from the last equality above we arrive at @xmath443 & = { \\ensuremath{\\mathsf{e}}}^{\\pi^\\star}_x\\bigl[{\\ensuremath{\\boldsymbol{1}_{\\{\\tau{\\ensuremath{\\wedge}}\\tau ' < \\infty\\}}}}\\bigl({\\ensuremath{\\boldsymbol{1}_{k}}}\\cdot v'\\bigr)(x_{\\tau{\\ensuremath{\\wedge}}\\tau'})\\bigr]\\nonumber\\\\                                  & = { \\ensuremath{\\mathsf{e}}}^{\\pi^\\star}_x\\bigl[{\\ensuremath{\\boldsymbol{1}_{\\{\\tau{\\ensuremath{\\wedge}}\\tau ' < \\infty\\}}}}\\bigl({\\ensuremath{\\boldsymbol{1}_{\\{\\tau < \\tau'\\}}}}{\\ensuremath{\\boldsymbol{1}_{k}}}(x_\\tau)v'(x_{\\tau } ) + { \\ensuremath{\\boldsymbol{1}_{\\{\\tau > \\tau'\\}}}}{\\ensuremath{\\boldsymbol{1}_{k}}}(x_{\\tau'})v'(x_{\\tau'})\\bigr)\\bigr]\\nonumber\\\\                  & = { \\ensuremath{\\mathsf{e}}}^{\\pi^\\star}_x\\bigl[{\\ensuremath{\\boldsymbol{1}_{\\{\\tau{\\ensuremath{\\wedge}}\\tau ' < \\infty\\}}}}{\\ensuremath{\\boldsymbol{1}_{\\{\\tau < \\tau'\\}}}}\\bigr]\\label{e : bydef}\\\\                  & = { \\ensuremath{\\mathsf{p}}}^{\\pi^\\star}_x\\bigl(\\tau < \\tau ' , \\tau < \\infty\\bigr),\\nonumber              \\end{aligned}\\ ] ] where the equality in   follows from the assumptions on @xmath177 and the definitions of @xmath1 and @xmath115 . collecting the equations above",
    "we get @xmath186 as asserted .",
    "it is of interest to note that the hypotheses of theorem  [ t : vprimechar ] requires at least one of the stopping times @xmath1 or @xmath115 to be finite .",
    "let us examine the case of @xmath108 being @xmath445 on a set of positive probability .",
    "following the proof of theorem  [ t : vprimechar ] , we see that in this case we have to agree on the value of @xmath446 on @xmath447 .",
    "if @xmath448 exists , then we can always let @xmath446 take this value on the set @xmath447 .",
    "however , the context of the problem offers another alternative , namely , to set @xmath449 on @xmath447 . this is because if @xmath450 for all @xmath110 , then the value of @xmath451 is of no consequence at all .",
    "the purpose of this article was to present a dynamic programming based solution to the problem of maximizing the probability of attaining a target set before hitting a cemetery set , and furnish an alternative martingale characterization of optimality in terms of thrifty and equalizing policies .",
    "several related problems of interest were sketched in   [ s : disc : ss : gensetting ] .",
    "some of these problems do not admit an immediate solution in the dynamic programming framework we established here because of our central assumption that the cost - per - stage function is nonnegative .",
    "this issue deserves further investigation .",
    "the results in this article also provide clear indications to the possibility of developing verification tools for probabilistic computation tree logic  @xcite in terms of dynamic programming operators .",
    "this matter is under investigation and will be reported in  @xcite .",
    "implementation of the dynamic - programming algorithm in this article is challenging due to integration over subsets of the state - space , and suboptimal policies are needed . in this context development of a possible connection with ` greedy - time - optimal ' policies  ( * ? ? ?",
    "* chapters  4 , 7 ) , originally proposed as a tractable alternative to optimal policies in demand - driven large - scale production systems , is being sought .",
    "the authors thank onsimo hernndez - lerma for helpful suggestions and pointers to references , and sean summers for posing the problem .",
    "bertsekas , d.  p. , shreve , s.  e. , 1978 .",
    "stochastic optimal control : the discrete - time case .",
    "139 of mathematics in science and engineering",
    ". academic press inc .",
    "[ harcourt brace jovanovich publishers ] , new york .                              karatzas , i. , sudderth , w. , 2009 .",
    "two characterizations of optimality in dynamic programming . applied mathematics & optimization ; http://www.springerlink.com / content/340m82862p817446/?p = f54a99eb8ef3432% cb45724c3d5ee8baa&pi=0[http://www.springerlink.com / content/340m82862p817446/?p = f54a99eb8ef3432% cb45724c3d5ee8baa&pi=0 ] .",
    "prandini , m. , hu , j. , 2006 . a stochastic approximation method for reachability computations . in : stochastic hybrid systems .",
    "337 of lecture notes in control and information sciences .",
    "springer , berlin , pp .",
    "107139 .",
    "watkins , o. , lygeros , j. , 2003 .",
    "stochastic reachability for discrete - time systems : an application to aircraft collision avoidance . in : 42nd ieee conference on decision and control .",
    "vol .  5 .",
    "53145319 .",
    "zhu , q. , guo , x. , 2006 . a semimartingale characterization of average optimal stationary policies for markov decision processes . journal of applied mathematics and stochastic analysis , art .",
    "i d 81593.http://www.hindawi.com / getarticle.aspx?doi=10.1155/jamsa/2006/815% 93[http://www.hindawi.com / getarticle.aspx?doi=10.1155/jamsa/2006/815% 93 ] ."
  ],
  "abstract_text": [
    "<S> we present a dynamic programming - based solution to the problem of maximizing the probability of attaining a target set before hitting a cemetery set for a discrete - time markov control process . under mild hypotheses </S>",
    "<S> we establish that there exists a deterministic stationary policy that achieves the maximum value of this probability . </S>",
    "<S> we demonstrate how the maximization of this probability can be computed through the maximization of an expected total reward until the first hitting time to either the target or the cemetery set . </S>",
    "<S> martingale characterizations of thrifty , equalizing , and optimal policies in the context of our problem are also established . </S>"
  ]
}