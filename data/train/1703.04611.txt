{
  "article_text": [
    "many of the signal and image processing problems can be posed as problems of learning a low dimensional linear or multi - linear model .",
    "algorithms for learning linear models can be seen as a special case of subspace fitting .",
    "many of these algorithms are based on least squares estimation techniques , such as principal component analysis ( pca ) @xcite , linear discriminant analysis ( lda ) @xcite , and locality preserving projection @xcite .",
    "but in general , training data may contain undesirable artifacts due to occlusion , illumination changes , overlaying component ( such as foreground texts and graphics on top of smooth background image ) .",
    "these artifacts can be seen as outliers for the desired signal .",
    "as it is known from statistical analysis , algorithms based on least square fitting fail to find the underlying representation of the signal in the presence of outliers @xcite .",
    "different algorithms have been proposed for robust subspace learning to handle outliers in the past , such as the work by torre @xcite , where he suggested an algorithm based on robust m - estimator for subspace learning .",
    "robust principal component analysis @xcite is another approach to handle the outliers . in @xcite ,",
    "lerman et al proposed an approach for robust linear model fitting by parameterizing linear subspace using orthogonal projectors .",
    "there have also been many works for online subspace learning / tracking for video background subtraction , such as grasta @xcite , which uses a robust @xmath0-norm cost function in order to estimate and track non - stationary subspaces when the streaming data vectors are corrupted with outliers , and t - grasta @xcite , which simultaneously estimate a decomposition of a collection of images into a low - rank subspace , and sparse part , and a transformation such as rotation or translation of the image .    in this work",
    ", we present an algorithm for subspace learning from a set of images , in the presence of structured outliers and noise .",
    "we assume some structure on outliers that suits many of the image processing applications , which is connectivity and sparsity . as a simple example we can think of smooth images overlaid with texts and graphics foreground , or face images with occlusion ( as outliers ) . to promote the connectivity of the outlier component",
    ", the group - sparsity @xcite of outlier pixels is added to the cost function ( it is worth mentioning that total - variation @xcite can also be used to promote connectivity ) .",
    "we also impose the smoothness prior on the learned subspace representation , by penalizing the gradient of the representation .",
    "we then propose an algorithm based on the sparse decomposition framework for subspace learning .",
    "this algorithm jointly detect the outlier pixels and learn the low - dimensional subspace for underlying image representation .",
    "after learning the subspace , we present its application for background - foreground segmentation in still images , and show that it achieves better performance than previous algorithms .",
    "we compare our algorithm with some of the prior approaches , including k - means clustering in djvu @xcite , shape primitive extraction and coding ( spec ) @xcite , least absolute deviation fitting ( lad ) @xcite .",
    "the proposed algorithm has applications in text extraction , medical image analysis , and image decomposition @xcite-@xcite .",
    "one problem with previous clustering - based segmentation techniques is that if the intensity of background pixels has a large dynamic range , some part of the background could be segmented as foreground , but our proposed model can correctly segment the image .",
    "one such example is shown in fig .",
    "1 , where the foreground mask ( a binary mask showing the location of foreground pixels ) for a sample image by clustering and our algorithm are shown .",
    "the structure of the rest of this paper is as follows : section ii presents the proposed framework for subspace learning .",
    "the detail of alternating optimization problem is presented in section ii .",
    "a , and the application of this framework for image segmentation is presented in ii .",
    "b. section iii provides the experimental results for the proposed algorithm and its application for image segmentation . and",
    "finally the paper is concluded in section iv .",
    "despite the high - dimensionality of images ( and other kind of signals ) , many of them have a low - dimensional representation .",
    "for some category of images , this low - dimensional representation may be a very complex manifold which is not simple to find , but for many of the smooth images this low - dimensional representation can be assumed to be a subspace .",
    "therefore each signal @xmath1 can be efficiently represented as : @xmath2 where @xmath3 where @xmath4 , and @xmath5 denotes the representation coefficient in the subspace .",
    "+ there have been many approaches in the past to learn @xmath6 efficiently , such as pca and robust - pca .",
    "but in many scenarios , the desired signal can be heavily distorted with outliers and noise , and those distorted pixels should not be taken into account in subspace learning process , since they are assumed to not lie on the desired signal subspace .",
    "therefore a more realistic model for the distorted signals should be : @xmath7 where @xmath8 and @xmath9 denote the outlier and noise components respectively .",
    "here we propose an algorithm to learn a subspace , @xmath6 , from a training set of @xmath10 samples @xmath11 , by minimizing the noise energy ( @xmath12 ) , and some regualrization term on each component , as : @xmath13 where @xmath14 and @xmath15 denote suitable regularization terms on the first and second components , promoting our prior knowledge about them .",
    "here we assume the underlying image component is smooth , therefore it should have a small gradient . and for the outlier , we assume it is sparse and also connected , therefore we need to promote the sparsity and connectivity @xcite .",
    "hence @xmath16 , and @xmath17 , where @xmath18 shows the m - th group in the outlier ( the pixels within each group are supposed to be connected ) .",
    "+ putting all these together , we will get the following optimization problem : @size9@mathfonts @xmath19 here by @xmath20 we mean all elements of the vector @xmath21 should be non - negative .",
    "note that @xmath22 denotes the spatial gradient , which can be written as : @xmath23 where @xmath24 and @xmath25 denote the horizontal and vertical derivative matrix operators , and @xmath26^t$ ] .",
    "the optimization problem in eq ( 4 ) can be solved using alternating optimization over @xmath27 , @xmath21 and @xmath6 . in the following part",
    ", we present the update rule for each variable by setting the gradient of cost function w.r.t that variable to zero .",
    "+ the update step for @xmath27 would be :    @xmath28    the update step for the @xmath29-th group of the variable @xmath21 is as follows :    @xmath30    note that , because of the constraint @xmath31 , we can approximate @xmath32 , and then project the @xmath33 from soft - thresholding result onto @xmath31 , by setting its negative elements to 0 . the block - soft ( . )",
    "@xcite is defined as : @xmath34 + for the subspace update , we first ignore the orthonormality constraint ( @xmath35 ) , and update the subspace column by column , and then use gram - schmidt algorithm @xcite to orthonormalize the columns .",
    "if we denote the j - th column of @xmath6 by @xmath36 , its update can be derived as :    @xmath37    where @xmath38 , and @xmath39 .",
    "after updating all columns of @xmath6 , we apply gram - schmidt algorithm to project the learnt subspace onto @xmath35 .",
    "note that orthonormalization should be done at each step of alternating optimization .",
    "it is worth to mention that for some applications the non - negativity assumption for the structured outlier may not be valid , so in those cases we will not have the @xmath20 constraint . in that case",
    ", the problem can be solved in a similar manner , but we need to introduce an auxiliary variable @xmath40 , to be able to get a simple update for each variable .      after learning the subspace , it can be used for different applications , such as segmentation and classification of signals .",
    "here we use this framework for background - foreground segmentation in still images .",
    "suppose we want to separate the foreground texts and graphics from background regions .",
    "we can think of foreground as the outliers overlaid on top of background , and use the learned subspace along with the following sparse decomposition framework to separate them : @xmath41 in our image segmentation problem , the m - th column of each block is chosen as the m - th group , @xmath18 .",
    "the reason being there are more vertical connectivity in english texts than horizontal .",
    "we could also impose both column - wise and row - wise connectivity , but it would require introducing auxiliary variables in the optimization framework . the problem in ( 6 ) can be easily solved using admm @xcite , and proximal optimization @xcite . after solving this problem , the @xmath8 component will be thresholded to find the foreground position .",
    "to evaluate the performance of our algorithm , we trained the proposed framework on image patches extracted from some of the images of the screen content image segmentation dataset provided in @xcite . before showing the results , we will report the weight parameters in our optimization .",
    "we used @xmath42 , @xmath43 and @xmath44 , which are tuned by testing on a validation set .",
    "we provide the results for subspace learning and image segmentation in the following sections .",
    "we extracted around 8,000 overlapping patches of size 32x32 , with stride of 5 from a subset of these images and used them for learning the subspace , and learned a 64 dimensional subspace ( which means 64 basis images of size 32x32 ) .",
    "the learned atoms of this subspace are shown in figure 2 .        as we can see",
    "the learned atoms contain different edge and texture patterns , which is reasonable for image representation .",
    "the right value of subspace dimension highly depends to the application . for image segmentation problem",
    "studied in this paper , we found that using only first 20 atoms performs well on image patches of 32x32 .",
    "the experiments are performed using matlab 2015 on a laptop with core i5 cpu running at 2.2ghz .",
    "it takes around 78 seconds to learn the 64 dimensional subspace .      after learning the subspace",
    ", we use this representation for background - foreground segmentation in still images , as explained in section ii.b .",
    "the segmentation results in this section are derived by using a 20 dimensional subspace for background modeling .",
    "we use the same model as the one in eq ( 6 ) for decomposition of an image into background and foreground , and @xmath45 s are set to the same value as mentioned before .",
    "we then evaluate the performance of this algorithm on the remaining images from screen content image segmentation dataset @xcite , and some other images , and compare the results with three previous algorithms ; hierarchical k - means clustering in djvu @xcite , spec @xcite , sparse and low - rank decomposition @xcite , and lad @xcite . for sparse and low rank decomposition , we apply the fast - rpca algorithm @xcite on the image blocks , and threshold the sparse component to find the foreground location . for low - rank decomposition",
    ", we have used the matlab implementation provided by stephen becker at @xcite .    to provide a numerical comparison ,",
    "we report the average precision , recall and f1 score @xcite achieved by different algorithms over this dataset .",
    "the average precision , recall and f1 score by different algorithms are given in table 1 .",
    "recall &   f1 score + spec @xcite &  50% &   64% &  56.1% + hierarchical clustering @xcite &  64% &  69% &  66.4% + low - rank decomposition @xcite &   78% &   86.5% &   82.1% + least absolute deviation @xcite &   91.4% &   87% &   89.1% + the proposed algorithm &  93% &  86% &   89.3% +    [ tblcomp ]    the precision and recall are defined as in eq .",
    "( 7 ) , where tp , fp and fn denote true positive , false positive and false negative respectively . in our evaluation",
    ", we treat a foreground pixel as positive .",
    "the balanced f1 score is defined as the harmonic mean of precision and recall , as it is shown in eq 8 .",
    "@xmath46 @xmath47 as it can be seen , the proposed scheme achieves much higher precision and recall than hierarchical k - means clustering and spec algorithms .",
    "compared to the least absolute deviation fitting , the proposed formulation has slightly better performance .",
    "0.18        0.18        0.18      +    0.18        0.18        0.18      +    0.18        0.18        0.18      +    0.18        0.18        0.18      +    0.18        0.18        0.18      +    0.18        0.18        0.18     to see the visual quality of the segmentation , the results for 3 test images ( each consisting of multiple 64@xmath4864 blocks ) are shown in fig .",
    "it can be seen that the proposed algorithm gives superior performance over djvu and spec in all cases .",
    "there are also noticeable improvement over least absolute deviation ( lad ) fitting and low - rank decomposition in one of the images .",
    "we would like to note that , this dataset mainly consists of challenging images where the background and foreground have overlapping color ranges . for simpler cases where the background has a narrow color range that is quite different from the foreground , djvu , lad and low - rank decomposition will work well",
    "this paper proposed a subspace learning algorithm for a set of smooth signals in the presence of structured outliers and noise .",
    "the outliers are assumed to be sparse and connected , and suitable regularization terms are added to the optimization framework to promote this properties .",
    "we then solve the optimization problem by alternatively updating the model parameters , and the subspace .",
    "we also show the application of this framework for background - foreground segmentation in still images , where the foreground can be thought as the outliers in our model , and achieve better results than the previous algorithms for background / foreground separation .",
    "the authors would like to thank ivan selesnick , arian maleki , and carlos fernandez - granda for their valuable comments and feedback .",
    "we would also like to thanks stephen becker for providing the matlab implementation of fastrpca algorithm .",
    "h abdi , lj williams , `` principal component analysis '' , wiley interdisciplinary reviews : computational statistics , 2010 .",
    "aj izenman , `` linear discriminant analysis '' , modern multivariate statistical techniques , springer , pp .",
    "237 - 280 , 2013 .",
    "x niyogi , `` locality preserving projections '' , in neural information processing systems , vol . 16 , 2004 .",
    "pj huber ,  robust statistics  , springer berlin heidelberg , 2011 .",
    "f de la torre , mj black , `` a framework for robust subspace learning '' , international journal of computer vision , pp.117 - 142 , 2003 .",
    "j wright , a ganesh , s rao , y peng , y ma , `` robust principal component analysis : exact recovery of corrupted low - rank matrices via convex optimization '' , in advances in neural information processing systems , 2009 .",
    "g lerman , mb mccoy , ja tropp , t zhang , `` robust computation of linear models by convex relaxation '' , foundations of computational mathematics 15 , no . 2 : 363 - 410 , 2015 .",
    "j he , l balzano , a szlam , `` incremental gradient on the grassmannian for online foreground and background separation in subsampled video '' , in computer vision and pattern recognition , pp . 1568 - 1575 , ieee , 2012 .",
    "j he , d zhang , l balzano , t tao , `` iterative online subspace learning for robust image alignment '' , international conference and workshops on automatic face and gesture recognition , ieee , 2013 .",
    "r chartrand , b wohlberg , `` a nonconvex admm algorithm for group sparsity with sparse groups '' , international conference on acoustics , speech and signal processing .",
    "ieee , 2013 .",
    "jf cai , b dong , s osher , z shen , `` image restoration : total variation , wavelet frames , and beyond '' , journal of the american mathematical society 25.4 : 1033 - 1089 , 2012 .",
    "p. haffner , p.g .",
    "howard , p. simard , y. bengio and y. lecun , `` high quality document image compression with djvu '' , journal of electronic imaging , 7(3 ) , 410 - 425 , 1998 .",
    "t. lin and p. hao , `` compound image compression for real - time computer screen image transmission '' , ieee transactions on image processing , 14(8 ) , 993 - 1005 , 2005 .",
    "s. minaee and y. wang , `` screen content image segmentation using least absolute deviation fitting '' , ieee international conference on image processing , pp.3295 - 3299 , sept .",
    "j. zhang and r. kasturi , `` extraction of text objects in video documents : recent progress '' , document analysis systems , 2008 .",
    "s minaee and y wang , `` screen content image segmentation using sparse decomposition and total variation minimization '' , international conference on image processing , ieee , 2016 .",
    "m. soltani and c. hegde , `` a fast iterative algorithm for demixing sparse signals from nonlinear observations '' , ieee global conference on signal and information processing , 2016 .",
    "s zhang , y zhan , m dewan , j huang , dn metaxas , s zhou , `` towards robust and effective shape modeling : sparse shape composition '' , medical image analysis , 2012 .",
    "a taalimi , h qi , r khorsandi , `` online multi - modal task - driven dictionary learning and robust joint sparse representation for visual tracking '' , advanced video and signal based surveillance ( avss ) , ieee , 2015 .",
    "s minaee and y wang , `` screen content image segmentation using robust regression and sparse decomposition '' , ieee journal on emerging and selected topics in circuits and systems , 2016 .",
    "m soltani , c hegde , `` iterative thresholding for demixing structured superpositions in high dimensions '' , nips workshop , 2016 .",
    "s minaee , a abdolrashidi and y wang , `` screen content image segmentation using sparse - smooth decomposition '' , asilomar conference on signals , systems , and computers , ieee , 2015 .",
    "a aravkin , s becker , v cevher , p olsen , `` a variational approach to stable principal component pursuit '' , conference on uncertainty in artificial intelligence , 2014",
    ".    f bach , r jenatton , j mairal , g obozinski , `` optimization with sparsity - inducing penalties '' , \" foundations and trends in machine learning 4.1 : 1 - 106 , 2012 . s. boyd , n. parikh , e. chu , b. peleato and j. eckstein , `` distributed optimization and statistical learning via the alternating direction method of multipliers '' , foundations and trends in machine learning , 3(1 ) , 1 - 122 , 2011 . pl combettes , jc pesquet , `` proximal splitting methods in signal processing '' , fixed - point algorithms for inverse problems in science and engineering .",
    "springer , 185 - 212 , 2011 .",
    "sj leon , a bjorck , w gander , `` gramschmidt orthogonalization : 100 years and more '' , numerical linear algebra with applications 20.3 : 492 - 532 , 2013 .    https://sites.google.com/site/shervinminaee/research/image-segmentation https://github.com/stephenbeckr/fastrpca dm powers , ``",
    "evaluation : from precision , recall and f - measure to roc , informedness , markedness and correlation '' , 2011 ."
  ],
  "abstract_text": [
    "<S> subspace learning is an important problem , which has many applications in image and video processing . </S>",
    "<S> it can be used to find a low - dimensional representation of signals and images . </S>",
    "<S> but in many applications , the desired signal is heavily distorted by outliers and noise , which negatively affect the learned subspace . in this work </S>",
    "<S> , we present a novel algorithm for learning a subspace for signal representation , in the presence of structured outliers and noise . </S>",
    "<S> the proposed algorithm tries to jointly detect the outliers and learn the subspace for images . </S>",
    "<S> we present an alternating optimization algorithm for solving this problem , which iterates between learning the subspace and finding the outliers . </S>",
    "<S> this algorithm has been trained on a large number of image patches , and the learned subspace is used for image segmentation , and is shown to achieve better segmentation results than prior methods , including least absolute deviation fitting , k - means clustering based segmentation in djvu , and shape primitive extraction and coding algorithm . </S>"
  ]
}