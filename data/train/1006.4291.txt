{
  "article_text": [
    "in cell biology , neuroscience , as well as the study of collective behavior of organisms , networks of interacting agents or elements orchestrate the cellular , organismal or group response to the changes in the _ environment _ or the _ internal conditions _ of the system . for example , in cells , signaling proteins on the membrane can detect external chemicals and respond by chemically modifying other intracellular proteins , leading to a cascade of activity that can end with up- or down - regulation of the appropriate genes . similarly , a genetic regulatory network comprises a set of regulatory proteins , called transcription factors , that find and bind special non - coding regions on the dna , thus causing a change in the expression levels of the regulated genes . in the nervous system , signals are propagated as `` digital '' action potentials : each neuron in the human brain receives synaptic input from other neurons and integrates it into its own decision to spike or not .",
    "finally , flocks of birds , aggregating collections of single - celled amoeba ( _ dictyostelium _ ) , schools of fish and even groups of people can exhibit collective behaviors that are not necessarily trivially understood from the properties of single group members .    as physicists ,",
    "we often see collective behaviors as emerging from interactions among basic `` simple '' elements . yet in biology , even the building blocks of information processing networks are not simple .",
    "proteins can have many conformational states that are hard to predict from the amino - acid sequence .",
    "the integration of information at the enhancer site in metazoan gene regulation  that is , how levels of regulatory proteins together determine the expression level of the regulated gene ",
    "is still mostly unknown . and in the nervous system",
    ", examples in which single units change their information - processing properties through adaptation to sensory statistics or where the network dynamically modifies its inter - neural connections as a consequence of learning , have been studied extensively , but are still poorly understood .    despite this complexity in network building blocks and",
    "the fact that processes in biological networks can occur on many ( not necessarily well - separated ) timescales , we can still hope to find phenomenological or coarse - grained descriptions .",
    "there is no underlying theory of biological networks in the sense known to hard physical science .",
    "but our view is that while they operate and are essentially constrained by basic physics ( some of the examples we will see later ) , the biological networks are also subject to evolutionary pressures for _ function_. this is a crucial distinction in comparison with inanimate systems , and there is hope that the intuition of a `` network x being driven to perform function y well '' might generate a predictive theory for biological network x. for example , in the metabolic pathway of _ escherichia coli _ , the function that `` given the level of nutrients , the bacteria should maximize the growth rate '' can be mathematically formulated and actually leads to verifiable predictions about the network architecture @xcite .    in this introduction",
    ", we motivate the lectures by asking three questions",
    "@xcite :    1 .   _ when considering biological networks that _ process information , _ how might one quantify the network function in a mathematically concise way ?",
    "is it possible to derive network properties by optimizing for such function , as is the case with metabolic networks ?",
    "are there general principles that underlie information processing in living systems ?",
    "_ what kinds of measurements can we perform on biological information processing networks and , having these measurements , how can they be analyzed ?",
    "_ how is the analysis of such networks different from the typical analyses of collective behaviors in physics ? which concepts and tools from physics can be borrowed to dissect and understand biological networks ? _    we ll use transcriptional regulation as a concrete example to illustrate these questions throughout the lecture notes .",
    "analogies in neuroscience and other fields will be commented on .",
    "these notes are organized as follows : section [ lec1 ] provides an introduction to biological information processing networks by defining the basic terminology and approaches , and illustrating why these systems are interesting to study ; section [ lec2 ] discusses the response properties of single network elements , e.g. genes or neurons ; section [ lec3 ] discusses the role , types and origins of noise in biological networks ; section [ lec4 ] lays the groundwork for information theoretic approach , defining quantities such as entropy , mutual- and multi - information , synergy , redundancy etc ; section [ lec5 ] illustrates how tools from information theory can be used to infer models of transcriptional regulation , i.e. transcription factor ",
    "dna interaction ; section [ lec6 ] proceeds to extend the tools to analyze simultaneous interactions of more than pairs of elements in network ; and finally , section [ lec7 ] proposes a new information - theoretic principle that can perhaps explain the design of several developmental transcriptional regulatory networks .",
    "the primary source for this section is ref @xcite , which provides a more complete bibliography and a review of the study of biological networks .",
    "let us start by describing several biological networks and reviewing some of their general properties : * transcriptional regulatory networks .",
    "* in their genomes , organisms contain from several hundred to several tens of thousands of genes .",
    "the expression levels of these genes are primarily regulated by a set of proteins known as transcription factors ( tfs ) , which are encoded by a few up to about @xmath0 of genes in the genome .",
    "tfs bind specifically to short regulatory sequences of @xmath1 nucleotides in length , also known as _ binding sites _",
    ", on the dna , thereby modifying the expression levels of regulated genes .",
    "tfs can cross- and self - regulate , opening up a possibility of feedback regulation .",
    "they are usually present in nuclei in small , nanomolar range concentrations ( for a nucleus with several @xmath2 radius , these concentrations correspond to several hundred to thousands of tf molecules per nucleus ) .",
    "the timescales of such regulation span from minutes to hours .",
    "some known examples of such regulation are the lac operon in _ escherichia coli _",
    ", the @xmath3 repressor switch , many examples in yeast , genes of early development in _ drosophila melanogaster _ ( such as bicoid , hunchback , even skipped ) , hox genes etc .",
    "* signaling networks .",
    "* `` sensory proteins , '' such as g - protein - coupled receptors , sense various extracellular molecules .",
    "they respond to incident photons , like rhodopsin , and bind neurotransmitters and environmental molecules to which we respond by sense of smell .",
    "similarly , in bacteria , histidine kinase proteins ( one part of two component signaling systems ) are also membrane - bound proteins that detect their specific ligands . upon binding their ligands these proteins change confirmation and cause a chain of phosphorylation / dephosphorylation reactions that chemically modify their target proteins ( e.g. in bacterial two component signaling systems , the targets are the so - called `` response regulator '' proteins ) , thus altering their activity .",
    "these proteins can be present in thousands per cell , and the chemical reactions are much faster than in the case of transcriptional regulation , with equilibration times on the order of milliseconds to seconds .",
    "the reaction specificity is thought to occur via molecular ` lock - and - key ' like recognition mechanisms , but there exist cases of both unwanted crosstalk and intentional signal integration , where the same molecular targets are modified by various upstream enzymes .    * neural networks .",
    "* neurons transmit signals by propagating stereotyped voltage pulses , or _ action potentials _ , across their membranes @xcite .",
    "these excitations are driven by ionic currents that flow through special proteins embedded in the membrane , called _ ion channels_. the speed of propagation along the fibre is on the order of meters per second , and the timing precision of spikes can below a millisecond .",
    "most neurons are all - or - nothing devices : upon receiving input from other neurons through its dendrites ( which can number into tens of thousands , in the mammalian cortex ) , a neuron with some probability either produces a spike and sends it down its axon , or not .",
    "the axon synapses upon thousands of other neuron s dendrites .",
    "the complexity of neural network processing stems from the fact that synapses are state- and history - dependent , as their transmission probabilities can be adjusted on long timescales by chemical modification ( this is responsible for learning ) .",
    "neurons too have complex internal states and exhibit many interesting computational capabilities , such as nonlinear input summation , adaptation , resonance properties , and different regimes of operation dependent on the precisely controlled ion channel composition .",
    "these networks share a number of common features :    * biological networks are * dynamical systems*. the relevant timescales are the time on which the input fluctuates , the timescale on which single elements respond ( neural spiking , protein decay rates ) and potentially the timescale on which the network itself changes its properties ( learning in neural networks , change in signaling protein concentrations in signaling networks ) .",
    "networks can be ( self-)tuned to special operating points ( e.g. dynamical criticality ) , where new , `` emergent '' timescales might appear in the system .",
    "the networks often contain positive or negative * feedback loops*. * the wiring in the network is * specific*. specificity can be achieved by spatial organization ( neural networks , chromosomal organization , metazoan gene regulation ) and selective establishment or death of connections ( neural networks ) , or by molecular mechanisms of recognition ( tf - dna interaction , signaling enzymes ) .",
    "* the network dynamics is * noisy*. this is a consequence of the stochasticity in single molecular events at low concentrations of the relevant molecules .",
    "neuronal spikes are not completely reproducible even if the same stimulus is played to the neuron over and over again , because fluctuations in opening and closing of a finite number of ion channels in the membrane are not negligible .",
    "the nanomolar concentrations of tfs in the cell mean that the precise timing when a tf finds and binds a regulatory site on the dna is a random variable which results in stochastic gene activation .",
    "we discuss the importance of noise below . *",
    "the network elements are * nonlinear .",
    "* there are saturation effects , as in when all enzymes of the signaling pathway are operating at capacity , or a gene is fully activated .",
    "neurons themselves are excitable systems , that either do nt respond or respond fully with a spike .",
    "functionally , nonlinearities enable the systems to make `` decisions '' ( e.g. by thresholding ) and to re - represent their inputs in nontrivial ways ( e.g. not by simple linear , rotation - like transformations ) .",
    "various formal levels of description have been used to analyze biological networks , and different approaches emphasize some aspects enumerated above at the expense of the others :    * topological models * discuss networks in terms of wiring diagrams .",
    "the focus is on summarizing experimental data about the patterns of interconnection using a ( possibly directed ) graph .",
    "in genetic regulation , a particular kind of arrow in a wiring diagram might imply that gene a is activating gene b , while another kind might imply repression .",
    "topological models are concerned with statistical properties of such graphs , in particular , in how they differ from various simple models of random graphs .",
    "for instance , global statistical properties , such as node - degree distributions , clustering coefficients , mean path lengths etc have been studied for metabolic and regulatory networks , and the network of interconnections of all 302 neurons of _ _ c elegans__. the advantage of this method is that reasonably complete regulatory network diagrams exist , and their properties can be compared to other networks , including engineered ones ( e.g. transport , internet routing etc ) .",
    "a parallel line of inquiry has shown that certain local graph connectivity features , known as _ motifs _ , are overrepresented in , for example , transcriptional regulatory networks compared to randomized network ensembles @xcite ; see fig .",
    "[ f - motifs ] .",
    "one should bear in mind , however , that the connectivity graph is a drastic oversimplification of the true network : without knowing * ( i ) * the kinetic parameters on the arrows , * ( ii ) * how the regulatory arrows converging onto a single node combine in their effects , and * ( iii ) * what are the internal states of each of the nodes in the regulatory graph ( e.g. often the same node represents both mrna and its protein product , both of which have their own dynamics with delays ) , one can not predict from the connectivity alone how the network will behave , although certain classes of dynamical behavior can be excluded .",
    "interesting findings pertaining to biological networks described by connectivity graphs have been : * ( i ) * their scale free degree distribution , with the probability of a node to be connected to @xmath4 neighbors being @xmath5 ( with @xmath6 ) @xcite , and the consequent identification of _ hub _ nodes ( often essential proteins ) ; * ( ii ) * robustness to breakup of the connected component with respect to removal of most nodes , but fragility with respect to removal of hubs ; * ( iii ) * `` small world '' architecture , with short mean path lengths between pairs of nodes , and high clustering coefficients @xcite ; * ( iv ) * hierarchical yet clustered nature ( no preferred size of the cluster , consistent with scale - free property ) @xcite ; * ( v ) * `` dissociative structure '' , in which hubs are often _ not _ connected to each other ( in contrast to social networks , where friends with lots of friends are often friends among each other ) .    * boolean models . * here , the network is represented as a collection of boolean variables @xmath7 , which can take `` on '' ( @xmath8 ) and `` off '' ( @xmath9 , sometimes @xmath10 ) values , and a set of dynamical update rules , @xmath11 , that evolve the system forward in time in discrete steps . the variables might be thought of as two - state genes ( or neurons ) , and the update rules are combinatorial ( boolean ) expressions involving input tfs on the promoters ( or dendritic inputs in neurons ) .",
    "generalizations to more than 2 states have been used , e.g. in modeling _ drosophila _ developmental gene network @xcite .",
    "this method scales well to simulations of many genes and emphasizes the dynamic and nonlinear nature of the network , but can introduce serious artifacts due to synchronous update rule . in neuroscience ,",
    "the hopfield network is of the similar form , with asynchronous update , and provides a clean theoretical model of associative memory that is able to recall a stored binary pattern from any closely matching subpattern @xcite . in that case",
    "the states of @xmath12 neurons are given by @xmath7 , the update rule is downhill descent @xmath13 evaluated under the network wiring parameters @xmath14 , the input pattern is the initial state of the network @xmath15 , and the final state is the attractor of the dynamics .",
    "the memories are @xmath16 binary patterns @xmath17 , @xmath18 , stored into @xmath19 by the prescription @xmath20 .",
    "interesting applications of boolean network modeling include the description of the _ drosophila _ gap - gene system in which 4 gap genes respond to 3 maternal tf inputs with spatially varying profiles ; this model could describe correctly the expression patterns in a number of known mutants @xcite . another interesting case involved describing the budding yeast cell cycle driven by a network of 11 interacting nodes @xcite . in this network",
    "the topology induces a robust sequence of state transitions ( growth , dna duplication , pause , division ) , triggered by a `` cell - size '' checkpoint ; robustness here refers to the fact that the dynamical trajectory through the states remains unchanged upon perturbation of update rules , small changes in topology and the parameters .",
    "* dynamical systems . * in the field of dynamical systems analysis , one usually assumes that each network element can have a certain degree of `` activity '' ( expression level for a gene , fraction of activated proteins of a given type in a signaling network , firing rate of a neuron ) .",
    "these activities @xmath21 are treated as continuous variables undergoing network dynamics . as a simple example one could write : @xmath22 here",
    ", the first term describes relaxation towards equilibrium with timescale @xmath23 , while the second `` activation '' term adds up contributions from other network elements weighted by a connection matrix @xmath19 , and a possible direct input @xmath24 to element @xmath25 .",
    "@xmath26 is a nonlinear function , often saturating ( or sigmoid ) . in the case of gene regulation",
    ", @xmath21 could be the expression level of gene @xmath25 , @xmath23 the protein decay rate , @xmath19 the contributions of transcription factor @xmath27 to the expression of gene @xmath25 , @xmath24 the direct external influence on @xmath25 by e.g. induction , and @xmath26 would be the promotor input / output function , discussed later .",
    "of course more complex and realistic examples are possible , potentially including spatial effects due to , for example , diffusion of tf molecules in the cells . in the study of dynamical systems one",
    "focuses on the search for universality classes of dynamical behaviors , and looks for limit cycles and steady states in dynamics and their sensitivity to network control parameters [ such as @xmath19 in eq ( [ dsys ] ) ] .",
    "well - known applications of this approach involve modeling the chemotaxis module of _ escherichia coli _",
    "@xcite , a model of cell cycle control in fission yeast ( approximately 10 proteins and 30 rate constants ) @xcite , and the circadian clock in mammals ( a system of about 20 rate equations ) that exhibits autonomous oscillations and reproduces the entrainment of oscillations through light - induced gene expression @xcite .",
    "this approach is popular also for modeling of smaller and simpler ( sometimes synthetic ) systems , such as the repressillator @xcite or the min oscillator in bacteria .",
    "* probabilistic models and stochastic dynamics .",
    "* probabilistic models try to capture the noise inherent in biological processes and experimental protocols . for a set of ( for example )",
    "binary variables @xmath7 that denote the simultaneous expression levels of genes ( or firing / silence states of the neurons ) , one class of probabilistic models tries to find good approximations for @xmath28 , that is , the probability distribution that all genes ( or neurons ) are in a particular configuration @xmath7 given the external conditions ( or stimulus ) @xmath29 .",
    "this is then compared to experimental data , which is a sample of many measurements of @xmath7 across cells or time .",
    "@xmath28 gives a generative model from which synthetic data that resembles real measurements can be drawn .",
    "various approaches differ in what forms for @xmath30 are assumed .",
    "we will mention bayesian network inference and maximum entropy models in section [ lec6 ] . a second class of probabilistic models attempts to generalize dynamical equations , e.g. eq ( [ dsys ] ) .",
    "if the noise is not too big , the simplest way is to write : @xmath31 where @xmath32 is the langevin noise strength , i.e. a random force whose variance @xmath33 might depend on the state of the system ( braces denote averaging over many realizations of the noise time series ) . techniques from statistical mechanics and diffusion can then be used not only to calculate the _",
    "mean _ dynamics @xmath34 of this system , but also the evolution of the `` noise '' or the fluctuation around the mean , characterized by the covariance matrix of all @xmath21 , @xmath35 . when concentrations of constituents are low ( or when we are interested in single neural spikes ) , the continuous description with @xmath21 must break down and the state space is replaced by @xmath36 , the integer counts of individual molecules such as dna or tfs .",
    "one switches to describing the full evolution of the probability distribution using the master equation @xcite : @xmath37 where @xmath38 is some linear evolution operator .    finally , there are techniques like the stochastic simulation algorithm ( ssa ) of gillespie @xcite and generalizations to spatially extended systems , where the discrete stochastic dynamics can exactly be simulated at the expense of slow execution speeds .",
    "one of the pioneering studies with ssa was the simulation of the @xmath3 lysis / lysogeny switch @xcite , where the simulation tried to reproduce the fraction of lysogenic phages as a function of multiplicity of infection .",
    "let s start by discussing the simplest possible example of genetic regulation ; we will develop this example as we progress through the lectures .",
    "let the transcription factors ( tfs ) be present at concentration @xmath39 in the cell . on the dna",
    ", there is a single specific binding site that can be occupied or empty ; we ll denote this occupancy with @xmath40 .",
    "when the site is occupied , the regulated gene will get transcribed into mrna , which is later translated into proteins whose count we denote by @xmath41 , at the combined rate that we denote by @xmath42 .",
    "the proteins are degraded with the characteristic time @xmath23 . in this case",
    ", our tf thus acts as an activator , see fig .",
    "[ f - sscheme ] . here and afterwards",
    "we will refer to the transcription factor @xmath39 as an _ input _ , and the regulated gene product @xmath43 as _",
    "output_.    this model discards a lot of molecular complexity : there is no explicit treatment of diffusion of tfs , no non - specific binding , no separate treatment of mrna and protein , no chromatin opening / closing etc ; in addition , we group many multi - stage molecular processes ( such as tf binding , rnap assembly , processive transcription etc ) into single steps .",
    "thus , our model is a gross but tractable oversimplification . as an illustration ,",
    "let us formulate it in all of the mathematical frameworks discussed above .",
    "the topological diagram for this example is simple @xmath44 . in the case of boolean network models ,",
    "the state space of this network is @xmath45 ^ 2 $ ] , indicating that both the transcription factor @xmath39 and the regulated gene @xmath43 can be `` on '' or `` off . ''",
    "the update rules are trivial : @xmath46 .",
    "treating now concentrations @xmath39 and @xmath43 as continuous , we can describe the same regulatory process by the set of differential equations : @xmath47 equation ( [ occ ] ) is an equation for occupancy @xmath48 , which is a number between 0 and 1 .",
    "nominally , the site can only be fully empty or occupied , but in this approximation , we treat it as a continuous variable that can be interpreted as a `` probability of the site being bound . ''",
    "@xmath49 is the tf - concentration - dependent on - rate , and @xmath50 is the first - order off - rate .",
    "often , it is assumed that there is a separation of time scales : the first equation for occupancy equilibrates much faster than @xmath23 , meaning that the mean occupancy @xmath51 can be inserted into eq ( [ prot ] ) to get @xmath52 in this simple case without feedback , the approach to the equilibrium at fixed @xmath39 is exponential with the rate @xmath23 , and the steady state is simple : @xmath53 .",
    "equation ( [ prot1 ] ) has precisely the form of eq ( [ dsys ] ) with @xmath26 having a sigmoidal shape .",
    "we discuss in the next section how the particular sigmoidal regulation functions are connected to equilibrium statistical mechanics of this system , how noise can be added by an introduction of the langevin force into eq ( [ prot ] ) , and why the assumption of fast equilibration of @xmath48 strongly influences the noise .",
    "finally , if we wanted to fully capture the noise in this model , the object of our inquiry would be @xmath54 : the time - dependent joint probability of observing @xmath43 molecules of the resulting gene and the state of the binding site being @xmath55 ( empty , occupied ) , given some concentration of the input @xmath39 .",
    "one can marginalize over @xmath48 to get the evolution of probability of observing @xmath43 output molecules : @xmath56 .",
    "writing down the master equation and for simplicity suppressing the parameters @xmath57 on which all terms @xmath58 are conditioned , we find : @xmath59 the reader should recognize degradation - related terms ( proportional to @xmath60 ) , the protein production terms ( prefixed with @xmath42 and present only in the case when the gene is on , i.e. @xmath61 ) and the switching terms of the promoter containing @xmath62 and @xmath50 , which couple the @xmath63 to @xmath61 states . in this simple case",
    ", the equilibrium distribution can be solved by zeroing out the left - hand side of eq ( [ mastereq ] ) .",
    "this yields an infinite dimensional system in @xmath43 that can be truncated at some @xmath64 ; we would end up with a homogenous linear system that can be supplemented by a normalization condition @xmath65 , which can be inverted and solved for steady state @xmath66 .",
    "more sophisticated methods are available when the number of genes grows and they are interacting @xcite .",
    "note that in this example we treated the @xmath43 as discrete , but @xmath39 is still a continuous input parameter ( not a variable whose distributions we are also interested in ) .",
    "finally , let s mention the gillespie algorithm .",
    "for this algorithm we start with enumerating all reactions and their rates : @xmath67 one initializes the state of the system as a vector @xmath68 of integer counts of molecular species ( here @xmath69 denotes a molecular complex of a c molecule bound to the promoter ; there can only be 0 or 1 @xmath48 and @xmath69 , and you can quickly convince yourself that @xmath70 ) .",
    "then the probability per unit time of each of the 4 reactions is the product of the rate constant and the number of reactants properly normalized by the relevant volume .",
    "the algorithm randomly draws the next reaction consistent with the probabilities per unit time , updates the state of the system and repeats .",
    "this algorithm is exact for well - mixed systems , but * ( i ) * can be slow in case there are fast and slow reactions in the system ; * ( ii ) * one needs to sample many simulation runs to accumulate the noise statistics . from the presented example it is clear that the fully stochastic dynamical description can be relatively complicated even for a very simple system . to proceed and be able to connect to data , we will in these lectures drop the time dependence and only focus on the steady state , while emphasizing the nonlinear and noisy nature of the system .",
    "sections [ lec2 ] and [ lec3 ] therefore use the langevin description to treat noise in a dynamical system , and section [ lec6 ] presents a probabilistic maximum entropy model of an interacting network .",
    "our assumption to only study the steady state will preclude us from discussing network phenomena that are intrinsically dynamic , e.g. the cell cycle clock , the circadian clock , or the detailed nature of excitability in neurons and _ dictystelium _ cell cultures . but for many biologically realistic cases , such as in developmental biology , or in many experimental settings , such as measuring the gene response to constant levels of inducer , the steady state approach is useful .",
    "in this lecture we will first explore simple thermodynamical models of gene regulation , by studying how the concentration of a transcription factor relates to promotor occupancy and thus to the expression level of the regulated gene .",
    "we will then look at one possible model for combinatorial regulation and introduce the notion of the input / output relation .",
    "the section finishes by briefly surveying the experimental measurements of input / output relations .",
    "let s first revisit our simple description of gene regulation from eqs ( [ occ],[prot ] ) .",
    "we found that in steady state the occupancy of the promoter is @xmath71 , where @xmath72 and @xmath50 are on- and off rates , respectively .",
    "since this is an equilibrium system , we can ask for the equivalent statistical mechanics description .",
    "suppose we have a site @xmath48 that can be occupied or full . in case",
    "it is occupied , there is a binding energy @xmath73 favoring the occupied state , relative to the reference energy 0 in the unbound state .",
    "but in order to occupy the state , one needs to remove one molecule of tf from the solution .",
    "the chemical potential of tfs , or the free energy cost of removing a single molecule of tf from the solution , is @xmath74 , where @xmath39 is the tf concentration , measured in some dimensionless units of choice . in statistical physics",
    "we can calculate every equilibrium property of the system if we know how to compute the _ partition sum _",
    ", which is @xmath75 , where the sum is taken over all possible states of the system ( in our case binding site empty and binding site occupied ) , @xmath76 is the energy of the system is the state @xmath25 , and @xmath77 is the number of molecules in the system in the state @xmath25 .    in our case of a single binding site ,",
    "the partition sum is over the empty ( @xmath63 ) and occupied ( @xmath61 ) state : @xmath78 where @xmath79 , @xmath33 is the temperature in kelvin and @xmath80 is the boltzmann constant .",
    "the probability that the site is occupied is then @xmath81 inserting the definition of @xmath82 , we get @xmath83 where we write @xmath84 .",
    "but @xmath85 , so by comparing with eq ( [ occ ] ) we can make the identification @xmath86 which connects our statistical mechanics and dynamical pictures .",
    "note that @xmath50 is measured in units of inverse time , @xmath87 , @xmath72 is measured in units of @xmath88^{-1}$ ] ( but by convention we here measure concentration in dimensionless units , as in @xmath89 ) , so @xmath90 has units of concentration .",
    "suppose we make the model somewhat more complicated : let us have two binding sites , which together will constitute a system with 4 possible states of occupancy : both sites empty , either one occupied , and both occupied , which we ll write compactly as @xmath91 .",
    "let s also assume that there is cooperativity in the system  if both sites are occupied , then there will be an additional favorable energetic contribution of @xmath92 to the total energy of the state @xmath93 . finally , when promoters can have multiple internal states , we need to decide which state is the `` active '' state , when the gene is being transcribed ; here we pick the state @xmath93 as the active state .",
    "the probability of being active is then @xmath94 where we use the units where @xmath95 , that is , we express the energies and chemical potential in thermal units of @xmath96 .",
    "if the cooperativity is strong , i.e. the additional gain in energy @xmath92 is larger than the favorable energy of putting a molecule of tf out of the solution onto the binding site , @xmath97 , we can drop the middle term of the denominator in eq ( [ p11 ] ) and simplify it into : @xmath98 with @xmath99 $ ] , where again we have used the definition of chemical potential @xmath82 .",
    "this problem with 2 binding sites and 4 states of occupancy also has a complementary dynamical picture , which is already quite complicated , see fig .",
    "[ f-2state ] .",
    "readers used to molecular biology models of gene regulation will recognize sigmoidal functions in eqs ( [ occ],[hill2 ] ) , also known as hill functions , with a general form ( see fig .",
    "[ f - hill ] ) : @xmath100 where the dissociation constant @xmath90 is interpreted as the concentration at which the promoter is half induced , and @xmath101 is known as the cooperativity or hill coefficient , usually interpreted as the `` number of binding sites '' can activate its own transcription in addition to being activated by the input @xmath39 , that conclusion is incorrect . ] . here",
    "we have shown how such phenomenological curves arise from simple statistical mechanics models of gene regulation with cooperative interactions . for repressors",
    ", one can show that @xmath102 .    before proceeding ,",
    "let s inspect more closely the relation between the dynamical rates and the binding energy for a single site : @xmath103 .",
    "as we have shown in eq  ( [ db ] ) , this equality is required by detailed balance if thermodynamic and kinetic pictures are to match .",
    "molecularly  and we will devote the entire lecture of section [ lec5 ] to this  the energy of binding @xmath73 in the case of transcription factor ",
    "dna interaction depends on the sequence .",
    "so if we were to vary the sequence and binding energy @xmath73 would change , which of the two rates , @xmath50 or @xmath72 would vary as a result ? in general one can not answer this question without knowing in detail the sequence of molecular transitions that happen at the binding site .",
    "however , there is a useful limit , called the _ diffusion - limited on rate _",
    ", that is often applicable . in this regime ,",
    "the limit to how quickly the tf can bind is given by the speed at which it can diffuse to the binding site .",
    "it has been shown that if tf diffuses with diffusion constant @xmath104 and is trying to bind a site with linear dimension @xmath105 , the fastest on rate is @xmath106 , for spherical tf and binding site will change.]@xcite . in the diffusion - limited approach ,",
    "if the binding site is empty , as soon as a tf diffuses into a region of size @xmath105 around the binding site , it will immediately bind .",
    "then , all dependence on binding energy @xmath73 will be absorbed into the off rate @xmath50 .",
    "intuitively we can understand this by imagining that once the tf is bound in an energetically favorable configuration , it has to wait for a random thermal kick of typical size @xmath96 to unbind , and the probability of that kick being able to overcome the binding energy barrier @xmath73 is @xmath107 ( remember , the more negative the binding energy , the stronger the binding ) .      in the previous chapter",
    "we have shown how thermodynamic and kinetic models are connected for simple cases of gene regulation where a single transcription factor binds cooperatively to different numbers of binding sites . in many cases ,",
    "however , several transcription factors together regulate a single gene .",
    "how can such situations be addressed from a theoretical perspective ? here we briefly discuss three possibilities , their drawbacks and benefits .",
    "* first , * if one knows the detailed molecular map of the states and their transitions , it is possible to write down the diagram as in fig .",
    "[ f-2state ] and compute the steady - state occupancies ; alternatively , this can be done in the thermodynamic picture if one knows the binding energies and cooperativities . for simple cases , such as a single activator and repressor jointly controlling a gene and having an energetic interaction , this is feasible and has been done for , e.g. , the _ lac _ operon in _ e coli _ , as we discuss later .",
    "as we advance towards more and more complex organisms , however , this approach loses its appeal : for metazoan enhancers , for instance , we do nt even know the microscopic states ( much less their energies ) , and so can not write down the partition function .",
    "while correct , this approach does not scale to more complex regulatory strategies well .",
    "* second , * we can decide for an ad hoc approach .",
    "here , we write down a model probability that the gene is on as a function of its tf concentrations , but do not worry whether this probability is actually derivable from some statistical mechanical system , or alternatively , if there is a realistic dynamical scheme that would generate this model probability .",
    "often , such approaches borrow the intuition from simple thermodynamics results and combine them into a more complicated regulatory scheme .",
    "for example , if the gene @xmath43 is activated by tf @xmath108 , present at concentration @xmath109 , and repressed by tf @xmath110 , present at concentration @xmath111 , one could postulate ( without deriving ) that the occupancy of the promoter is @xmath112 this expression assumes that molecules of @xmath108 bind independently to @xmath113 sites with dissociation constant @xmath114 , and molecules of @xmath110 bind to @xmath115 sites with dissociation constant @xmath116 ; importantly , we also assume that the joint regulation is _",
    "and_-like , meaning that gene @xmath43 will only be activated when both @xmath108 is bound and b is _ not _ bound [ that s why there is a product in eq ( [ andreg ] ) ] .",
    "more complex schemes like this can clearly be derived , and while they will not necessarily correspond to any possible thermodynamic system , they might be useful",
    "_ phenomenological _ models that can be fit to the data .",
    "* third , * we can pick a real thermodynamic model that is flexible enough to encompass many possible combinatorial strategies of gene regulation but will have a small enough number of parameters to connect to available data .",
    "as in the previous case , this model might not correspond on a molecular level to the events on the promoter , and would thus also qualify as a phenomenological model .",
    "it would , however , have the advantage of being more easily interpretable and understandable within the context of statistical physics .",
    "one such model is the so - called monod - wyman - changeaux model , which we discuss below .      in this section",
    "we ll discuss a thermodynamic model that can easily be extended to include combinatorial regulation .",
    "the model has been motivated by the work on allosteric transitions and was used to explain hemoglobin function @xcite . when applied to the case of gene regulation ,",
    "the central idea is that as a whole , the promoter can be in two states , `` on '' ( 1 ) and `` off '' ( 0 ) . remember that in our previous examples we had to declare one of the combinatorial states as the `` active '' state ; here , this distinction is built into the model by assumption .",
    "the regulatory region has @xmath117 binding sites for transcription factor @xmath108 .",
    "these sites can be bound in both the active and inactive state , and molecules of @xmath108 always bind independently , see fig .",
    "[ f - mwc ] . however",
    ", the binding energy for each molecule of @xmath108 to its binding site is state dependent , i.e. @xmath118 when the whole promoter is `` off '' vs @xmath119 when it is `` on . ''",
    "let s work out the thermodynamics of this system .",
    "for each of the two states , we can write down the free energies of @xmath4 molecules of type @xmath108 bound : @xmath120 where @xmath121 ( we are writing everything in units of @xmath96 and dimensionless concentration again ) , and @xmath122 is how favoured the `` off '' state is against `` on '' state even with no tf molecules bound .",
    "the partition function is then @xmath123    recognizing that the sums are simply binomial expansions . ] , we get for the probability of the `` on '' state ( proportional to the expression of the gene ) : @xmath124 equation ( [ mwcclass ] ) is written in the standard form , with the identifications @xmath125 , @xmath126 and @xmath127 . a regulatory impact of transcription factor @xmath108 onto the regulated gene is described by quantities @xmath128 in the mwc model .",
    "there is one additional parameter @xmath129 , the offset ( or `` leak '' ) favoring the `` off '' state .",
    "note that the parameters @xmath130 of the mwc model are not directly comparable to hill model parameter @xmath90 ; however , we can make the identification in the regime where @xmath131 and @xmath132 .",
    "then the term @xmath133 in eq  ( [ mwcclass ] ) can be approximated with 1 , and @xmath134 .",
    "equation  ( [ mwcclass ] ) then reduces to @xmath135 and we can identify the parameter @xmath48 in the mwc model with the hill coefficient @xmath101 , and the dissociation constant of the hill model , @xmath90 , with @xmath136 .    in general , for a single gene , the mwc model is not much different from hill , producing sigmoidal curves that do nt necessarily cover the whole range from 0 to 1 in induction as the input changes over a wide range .",
    "however , in the limit where @xmath131 , we can easily generalize mwc to regulation by several transcription factors . to see how , rewrite eq  ( [ mwce ] ) as @xmath137 where @xmath138 . in this picture , the binding and unbinding of transcription factors simply shifts the free energy of `` on '' vs `` off '' state .",
    "we can easily see that if @xmath16 transcription factors @xmath139 with concentrations @xmath140 regulate the expression of a gene , we can retain eq  ( [ fenergy ] ) , but write @xmath141 it is easy to check that positive @xmath142 represent activating influences , while flipping the sign of @xmath82 makes that gene @xmath82 repress the expression of @xmath43 @xcite .",
    "these considerations lead to a useful abstraction that phenomenologically describes the behavior of single genetic regulatory elements , and summarizes how the input tf levels get integrated on the promoter into the activity of the regulated gene .",
    "we need to plot the curve ( or surface in case of combinatorial regulation ) of gene activity as a function of all relevant input tf concentrations , @xmath143 : this is a nonlinear mapping that combines all inputs into a given output . in simple organisms ( prokaryotes ) ,",
    "the molecular understanding of these relations is probably close to correct : the promoter activity is just the occupancy of the promoter by the rna polymerase and thus is proportional to the rate of making new transcripts . for higher organisms ,",
    "the molecular picture is likely incorrect .",
    "nevertheless , input / output surfaces are useful abstractions for thinking about regulation , and concrete models such as mwc can compactly summarize experimental data .",
    "are there quantitiative measurements of input / output relations in gene regulation ?    for systems with a single input and a single output , it is commonplace to measure such relations and characterize them with hill - like functions .",
    "one example of a single input , single output function is shown in fig .  [ f - noise2 ] .",
    "this relation has been obtained in quantitative measurements using immunostaining methods and microscopy in the fruit fly embryos @xcite ; the degree of reproducibility is evident from the match between measurements on multiple embryos .",
    "this curve can be fit very well by a hill - like activation , eq  ( [ hillg ] ) , with the fitted hill coefficient of 5 .",
    "the slight dip at high induction is a consequence of the fact that in the embryo , hunchback ( the output ) is regulated by other transcription factors , not only the input ( bicoid ) .",
    "the situation where the factors other than the explicitly measured input influence the expression level of the target gene is common in higher organisms  the list of all inputs is not necessarily even known , and the extracted input / output relations are of necessity phenomenological , reflecting the direct influence of the observed input regulator , but also the indirect influences through unobserved intermediaries . perhaps the best worked out example is that of the lac operon in _ escherichia coli _",
    "@xcite , see fig  [ f - lac ] .",
    "the work of refs  @xcite has constructed a thermodynamic model of joint regulation of lac by its two transcription factors , crp ( activator ) and lacr ( repressor ) . in a series of experiments",
    "the concentrations of iptg ( an inducer for lacr ) and camp ( an inducer for crp ) has been varied and the 2d input / output surface has been mapped out . making this surface",
    "consistent with known molecular facts about the regulatory proteins ( such as the cooperativity of iptg - lacr interaction ) has required an in depth understanding of the system , including the thermodynamics of dna looping and finding other mechanisms that influenced the intra - cellular concentrations of camp ( such as an enzyme called pde that degrades camp ) .",
    "this body of work demonstrated how thermodynamical models of regulation , information about relevant molecular properties of the regulatory proteins , and quantitative experiments can generate real understanding in a ( simple ) biological system . on the other hand , the same work highlighted practical problems connected with inferring the input / output relations when input is externally experimentally controlled : part of the mystery of making the models consistent with the measurements was the discrepancy between externally delivered concentrations of the inducer , and its actual intracellular concentration ( _ e coli _ possesses alternative mechanisms that affect these concentrations ) . in the end , understanding even a simple bacterial system such as the lac operon proved quite challenging . in the case of _ drosophila _ hunchback / bicoid regulation ,",
    "similar problems can be avoided , because the input ( bicoid ) gradient is established naturally during early morphogenesis , and no experimental ( possibly physiologically irrelevant ) interference with the system is needed .",
    "finally , in metazoan regulation our knowledge is much more limited . in enhancer regions that control the expression levels of genes possibly far away on the dna , transcription factor binding sites form clusters and combinatorial regulation is abundant .",
    "several kinds of tfs might bind , each to possibly more than one specific binding site in the enhancer .",
    "these binding sites surprisingly appear to be less specific ( i.e. have shorter recognition sequence lengths ) than in bacteria .",
    "genetic studies have shown that in constructs in which some of these sites have been permuted , the biological function is retained , while other tweaks disrupt the function ; it is not clear what is the appropriate `` grammar '' that separates viable from non - functioning binding site configurations .",
    "attempts are being made , however , to both fit simple thermodynamical models of regulation to the data in a predictive fashion @xcite , and to map out the input / output surfaces of genes involved in early fruit fly patterning @xcite , when gap genes respond to spatially varying concentrations of the morphogens ( maternally deposited transcription factors ) .",
    "these studies have revealed a strong role for genetic cross - repression among the gap genes , as well as spatial effects in positioning of the binding sites that might be due to the packing and regulatory role of chromatin that can make the genes ( in)accessible for expression .",
    "neurons , especially in the sensory periphery , can also be viewed as input / output devices @xcite . in the retina ,",
    "the so - called retinal ganglion cells are sensitive to _ features _ in the visual space : each neuron observes a small visual angle and fires when the spatio - temporal pattern of light in that visual angle matches the feature that the neuron is looking for .",
    "the output of the neuron can be viewed as a scalar , the probability of spiking @xmath144 . in a typical experimental paradigm",
    ", visual stimuli can be precisely repeated many times and played to the neuron , so the probability of firing at each point in time , @xmath145 , is accessible as empirical probability , or firing rate , computed across many aligned stimulus presentation repeats .",
    "the input characterization is more problematic . in principle , one projects a movie , that is , a set of image frames of @xmath146 pixels each , refreshed every @xmath147 milliseconds , onto the neuron .",
    "even if the neuron is only locally sensitive in time , i.e. its spiking at the current moment only depends on @xmath33 previous movie frames , the dimensionality of the input space is huge .",
    "therefore , naively charting out an input / output relation , @xmath148 , is infeasible .",
    "it turns out , however , that the features that neurons look for in this huge dimensional input space are often simple .",
    "the neuron s sensitivity can be described by a spatio - temporal linear filter @xmath149 , local in space and time , also known as the _ receptive field_. a good model of the typical sensory neuron is that the neuron first takes a convolution of the filter with the movie , @xmath150 .",
    "the resulting@xmath151 is now a scalar that gets mapped through the point - wise ( instantaneous ) input / output relation into the spiking rate @xmath145 .",
    "this is the traditional phenomenological model of a neural response , called the ln ( linear - nonlinear ) model .",
    "the linear part describes `` feature extraction '' and reduces a stimulus of high - dimensionality to a single scalar projection .",
    "the nonlinear part maps that projection through a nonlinearity to generate probability of spiking , @xmath152 .",
    "some neurons are sensitive to more than one feature , and thus have , e.g. , two linear filters @xmath153 , @xmath154 , generating two projections @xmath155 at each instant in time .",
    "the input / output function is then a surface , or a 2d nonlinearity in neuroscience jargon , @xmath156 .",
    "a large effort in neuroscience is expended on deriving methods of experimentally probing , and inferring the linear filters and non - linearities . as an additional complication ,",
    "the neural behavior is adaptive , meaning that the properties of both filters and non - linearities can be dynamically tuned on slow timescales to reflect the changes in the statistics of neural inputs ( e.g. the change in the movie properties , such as average luminosity or contrast ) .",
    "information flow , in biological as well as engineered networks , is limited due to noise . to gain intuition about the influence of noise",
    ", we consider an information transmission system as a `` black box '' that takes some input signal @xmath39 , transforms ( encodes ) it and transmits it .",
    "the output signal @xmath43 is delivered to a readout device  a decoder  that then tries to determine which input was sent . if there were no noise , each input would be uniquely mapped to some output , and this mapping would be fully specified by a one - to - one input / output relation @xmath157 .",
    "when noise is present , there is no such one - to - one map in general , and we must take into account the possibility that given an input symbol @xmath39 , the system output is not uniquely determined . instead , there exists a distribution over @xmath43 , @xmath158 , that tells us how likely we are to receive a particular @xmath43 at the output if the symbol @xmath39 was transmitted .",
    "this distribution is also known as the _ encoding distribution_. a listener at the output could then use the bayes rule : @xmath159 to construct the _ decoding distribution _ , that is , an inverse mapping for the likelihood of each input signal @xmath39 , given that @xmath43 was received .",
    "two things are worthy of note : * ( i ) * the decoding party needs to know @xmath160 , the distribution of inputs that are being sent ( for instance , if @xmath39 are the letters of the english alphabet , one needs to know the letter frequencies in the written language to decode optimally ) ; * ( ii ) * @xmath161 is not the final decoding result  the decoding party does not want a distribution over possible @xmath39 that were sent , but instead want the specific @xmath39 that was `` most likely '' sent .",
    "decoding thus requires an additional rule for choosing the best guess of @xmath39 from @xmath161 , and there are various optimal choices for this rule , depending on how and which errors in decoding are penalized .",
    "for example , if @xmath39 were continuous , we might want to choose a decoding rule that picks the best guess @xmath162 out of the decoding distribution @xmath161 , such that the estimated l2 norm between the true transmitted @xmath39 and decoded @xmath162 is minimized , @xmath163 @xcite .",
    "we return to an in - depth discussion of probabilistic encoding , decoding , and information transmission in section  [ lec4 ] .",
    "to proceed , we note that there is a useful simplification at hand in the case when the symbols @xmath39 and @xmath43 are continuous : suppose that given @xmath39 , the responses @xmath43 are well clustered around some _ mean response _ ,",
    "@xmath164 , but there is also some `` spread '' around the mean , characterized by the variance @xmath165 . the connection between these two quantities and the fully probabilistic picture is as follows : @xmath166 these two functions are known as conditional mean and conditional variance , and they can easily be extracted from the distribution @xmath158 , if it is known .",
    "a noise - free deterministic limit is recovered as @xmath167 , in which case @xmath158 tends to a dirac - delta distribution , @xmath168 .",
    "unfortunately , the full conditional distribution of responses given the inputs , @xmath158 , is usually only available in theoretical calculations or simulations , since in reality we rarely have enough data to sample it . in the case of gene regulation",
    ", sampling would involve changing the input concentration of tf , @xmath39 , and for each input concentration , measuring the full distribution of expression levels @xmath43 . more often than not we only have enough samples to measure a few moments of the conditional output distribution , perhaps the conditional mean and conditional variance .",
    "given these measurements and @xmath158 that is experimentally inaccessible directly by sampling , we can try making the approximation @xmath169 that is , we _ assume _ that @xmath158 is a gaussian , with some input - dependent mean and variance . in the presented",
    "setting , the mean input / output response and the noise in the response cleanly separate : one is given by the conditional mean , and the other by conditional variance .",
    "the noise can be thought of as _ the fluctuations in the output variable while the input is held fixed_. recall that we are discussing all information processing systems in equilibrium , that is , when the dynamics in @xmath43 has reached steady state ( and all variation in @xmath43 at given @xmath39 is due to noise ) .",
    "with the conditional mean and variance in hand , we can now create a detailed characterization of a noisy input / output regulatory element by means of two functions , as shown in fig .",
    "[ f - schemeio ] .      what factors contribute to the noise in the response ?    let us start by briefly considering a purely physical system first . in the times of analog modems and noisy telephone lines , the modems information rates increased but started to saturate at about 30kbit / s .",
    "this is close to the theoretical limit predicted by shannon s information theory ( that we introduce in section [ lec4 ] ) , given the level of noise and available bandwidth in the transmission lines .",
    "such noise in electronic devices is well understood .",
    "two fundamental sources of noise in electronic equipment that contribute are the _ johnson noise _ and the _ shot noise_. johnson noise is due to random thermal fluctuations that jiggle the charges and thus induce random fluctuations in voltage ( or current flowing through the resistance ) .",
    "shot noise is due to quantal nature of charge carriers .",
    "`` current '' is a macroscopic ( average ) quantity , and is a result of an integer number @xmath48 of elementary charges @xmath170 , flowing through the cable in a time interval @xmath33 .",
    "we can write the current as the total charge flowing during time @xmath33 , i.e. @xmath171 . if we repeated the measurement of duration @xmath33 several times and were able to count individual charges , we would see that _ on average _",
    ", @xmath172 charges flow , but this number has a poisson fluctuations around the mean across our repeats of the experiment . a characteristic of a poisson random process such events in a time window @xmath33 .",
    "the probability of observing @xmath48 events in each instance of the time window @xmath33 is then poisson distributed , i.e. @xmath173 the mean number @xmath172 , or alternatively the rate @xmath174 , are sufficient statistics for poisson processes . ]",
    "is that the mean is equal to the variance , that is @xmath175 we can then compute the observed fluctuations in the current : @xmath176 . in an experiment in which a constant current @xmath177 is flowing , and we measure for time @xmath33",
    ", @xmath178 is the variance in the current that we would observe across the repeats of the experiment simply due to the fact that the charge is composed of elementary units @xmath170 which are not infinitely divisible .",
    "sources of noise that are directly analogous to the johnson noise and the shot noise also act on the molecular level and can be observed in a wide variety of settings in biology . before continuing ,",
    "consider two additional interesting examples . * in human vision ,",
    "* the photoreceptors in our retinas are very efficient at responding to small photon fluxes at low ambient light levels , when the retina is dark adapted . in an interesting set of experiments ,",
    "various groups have delivered flashes of light of mean intensity @xmath177 to human observers that needed to report whether they saw the flash or not .",
    "this procedure allowed the experimenters to trace out the psychometric response curve , with mean intensity @xmath177 on @xmath179 axis , and the probability of detection on @xmath180 axis , summarizing the limits to human vision .",
    "this curve is not a step function , but rather has a smooth transition region , and for a while it was hypothesized that this `` fuzziness '' in transition might be due to the processing downstream from the retina : after all , the signals need to travel into the brain , where we take a conscious decision that might be corrupted by noise , because , for example , our attention during the experiment faltered , or for many other possible reasons .",
    "retinal processes that underlie vision are able to detect to single photons : a photon hitting retinal ( the pigment in rhodopsin molecules ) can cause a chain of chemical reactions with high gain that ends up delivering a pulse at the photoreceptor output , and that pulse subsequently gets reported to the central brain in the spike trains of retinal ganglion cells .",
    "the fuzziness in the transition region that was observed in the experiments was not due to imperfect circuitry of the retina or the brain ; rather , when delivering light pulses with intensity @xmath177 , the experimenters were really delivering @xmath181 photons ( variance due to poisson shot noise ) in a given interval of time .",
    "the smooth rise in the psychometric curve was due to this spread in the number of photons actually delivered  humans really respond reliably to as few as 6 photons , and at those low light levels , the fractional fluctuation in the number of emitted photons at each pulse is significant ( i.e. @xmath182 ) .",
    "remember that the inability to deliver a precise number @xmath12 of photons is not due to experimenters lack of attention to detail : the emission of photons is a quantum probabilistic process and the poisson shot noise is a basic physical limit that can not be circumvented by a classical light source .",
    "in addition to shot noise , we can also find the analogs of thermal ( johnson ) noise in early vision .",
    "due to thermal fluctuations , there is a small chance that the molecule of retinal will undergo a spontaneous conformational transition exactly mimicking the one that would normally have been caused by an impinging photon .",
    "there is no way for the downstream neural circuitry to distinguish whether such an event was a `` real , '' photon - induced transition , or a thermal fluctuation",
    ". both in our eyes and in ccd cameras , this so - called `` dark current '' acts as a constant background hash causing false positives even if the detection circuit were otherwise perfect @xcite .",
    "* in bacterial chemotaxis , * bacteria like _ escherichia coli _ implement a well - studied strategy of swims and tumbles , that is , periods of swimming in straight lines when the flagella coherently bundle in a cork - screw - like propeller , and periods when flagella turn incoherently , causing the bacterium to randomize its direction .",
    "the bacteria also like to swim towards sources of molecules that they find useful ( `` chemoattractants '' ) , and they achieve this by modulating the frequency of random tumbles : as long as the concentration of chemoattractants that the bacterium senses is increasing with time , the tumbling is repressed ( since the swimming is in the correct direction ) ; if the concentration is decreasing , tumbling is enhanced .",
    "often , these chemoattracting chemicals will be present at very low concentrations , and one can ask the question `` how well can bacteria , even in principle , tell along which direction in space the concentration is increasing '' ? if the chemoattractant @xmath39 were at high enough concentration , one could imagine the bacterium having a detector for @xmath39 in its front and its back , which would allow it to measure the gradient of @xmath39 by simply measuring the front - to - back difference",
    ". operating at very low @xmath39 concentrations , however , we need to stop thinking about continuous and infinitely precise concentration fields and start thinking about single ligand molecules . as this hypothetical bacterium `` sniffs '' with its front detector ,",
    "it might measure , in time @xmath33 , @xmath183 molecules on average at the front , and @xmath184 molecules in the back .",
    "but the molecules are discrete entities , so each of these measurements will fluctuate around the mean by @xmath185 and @xmath186 from measurement to measurement . taking a difference between the front and the back counts , in the presence of this noise ( and with no temporal averaging ) , is a very bad strategy for inferring the direction of the chemoattractant source . if @xmath187 , then the estimate of the gradient will be completely swamped by noise .    while this direct strategy for estimating the gradient is implemented by certain eukaryotic cells ( which are much bigger and therefore able to measure the concentration differences better ) , bacteria  to deal with the noise problem  implement a very different strategy of integrating the change of measured chemoattractant concentration over time .",
    "the trick is to realize that @xmath188 ; therefore , in a temporally constant gradient , the time derivative of the concentration measured by the bacterium at its position , @xmath189 , swimming with velocity @xmath190 , is related to the spatial gradient of the concentration .",
    "it is also clear that with this strategy , bacteria can be experimentally `` tricked '' into believing that they move in a spatial gradient of the concentration , where really the concentration is spatially uniform but variable in time ; this has been the basis of many beautiful chemotactic experiments by h. berg and coworkers @xcite . in summary , in biology many important processes depend on events that occur between very small numbers of molecules .",
    "this can either be the detection of a single photon by the photopigment in the retina , or the detection of chemoattractant molecules by the swimming bacterium , or perhaps the binding of the transcription factor to its binding site .",
    "after all , in the last example one can think of the binding site trying to detect or `` measure '' the tf concentration , making this example analogous to detecting chemoattractants or photons ; it does nt really matter that in one case the ligands are internal to the cell and in the other the ligands are external . on general grounds , we expect that in all instances where small numbers of molecules are involved in control processes , noise might be an issue .",
    "when we study problems in mechanics , we begin by clearly delineating what is our system of study and what is the environment .",
    "the same distinction is useful when we talk about noise .",
    "for example , our system of study might be a single genetic regulatory element , denoted by @xmath44 , and its environment is the cellular environment of the particular single cell in which this system is embedded .",
    "this distinction is central because in an experiment , we will often observe many _ instances _ of the system , and in each instance measure the input @xmath39 and output @xmath43  this is how many noise experiments using single - cell microscopy or facs ( fluorescence activated cell sorting ) are performed .",
    "once we measure the response @xmath43 given the input @xmath39 and the fluctuation in the response @xmath165 , we need to ask what sources of variability contribute to that measured fluctuation .",
    "one source is the _ intrinsic noise _ in the regulatory element @xmath44 itself , contributed by the inherently stochastic molecular processes that we discussed above and will soon return to .",
    "another source of noise , however , called _ extrinsic noise _ , arises because the cellular environment changes from cell to cell ; that is , one can not guarantee that the system of study is always exposed to the same conditions . for example , the rna polymerase concentration might fluctuate from cell to cell , and even if the process @xmath44 would in itself contribute no intrinsic noise , the fact that this is transcriptional regulation process that involves rnap and rnap varies in the environment ( from cell to cell ) , will induce some variance in measured @xmath43 across the population of cells .",
    "there is nothing fundamentally different about the intrinsic and extrinsic noise ; the distinction is useful solely when a system of study can be enclosed into a conceptual box and separated from the environment , and the noise in the system can be separated from the noise in its environment by clever experimental techniques @xcite .",
    "we introduced the abstraction of input / output devices in the previous lecture .",
    "correspondingly , it makes sense to divide the intrinsic noise into the input and output contributions . in a regulatory process @xmath44 , where tf @xmath39 controls gene @xmath43 , the total noise in @xmath43 , @xmath165 , can arise from two kinds of sources .",
    "the first source , the _ output noise _ , deals with the generation of output . in our case",
    "this is the transcription of mrna molecules and their translation into protein molecules @xmath43 .",
    "this source of noise would be present even if there were no transcriptional regulation whatsoever , i.e. if the gene were constitutively expressed . by making more and more mrna and protein molecules ,",
    "the relative impact of the output noise can be reduced .",
    "the second source of noise is called the _ input noise _ , and this arises because the concentration @xmath39 at the binding site location itself is fluctuating ( we will discuss why soon ) .",
    "this source of noise is important for two reasons : * ( i ) * it gets mapped through the nonlinear input / output relation @xmath164 to give rise to the total measured noise in @xmath43 ; * ( ii ) * the input noise can not simply be reduced by clever design at the output end .",
    "this is familiar to anyone who has dealt with electronics ",
    "the noise in the input to the amplifier is the noise that no amount of gain can reduce away .",
    "when studying biological systems , we are faced with additional sources of fluctuation that are sometimes also referred to as noise , but contribute in addition to the fundamental sources of variability ( such as thermal or shot noise sources discussed above ) .",
    "the fundamental sources of noise , or physical limits to precision in biology , are the lower bound on the noise that biology can not avoid .",
    "but clearly biological processes can be more noisy than the lower bound set by physics .",
    "one such additional source is _ experimental noise _ that corrupts our measurements , independently of the actual noise in the biological system .",
    "often , we do nt have any theoretical understanding of what form this noise has , unlike in physics where the responses of the measurement devices can precisely be characterized .",
    "for example , microarray assays are a very popular high - throughput way of measuring the activity levels of various genes",
    ". however , there is no clear understanding of how the real level of mrna in some physical units maps into the log light intensity ratios usually reported [ in other words , what is @xmath191log light ratio@xmath192mrna level@xmath193 .",
    "therefore , inference from the measurement to the underlying quantity of interest ( which you can think of as decoding the raw experimental data into the the true mrna levels ) is often done using some ad hoc procedure ; in section [ lec5 ] we discuss how information - theoretic inference can circumvent precisely this problem of unknown experimental noise .",
    "finally , how important really is noise to biology ?",
    "the rough answer is that this depends on the system , and in particular to whether ultimately we can trace cellular ( or neural ) decisions to single microscopic rare events .",
    "if that is the case , the expectation is that the noise will play a large role .",
    "for example , the @xmath3 switch in the phage controls the fate of the virus , i.e. whether it will stay lysogenic or turn lytic .",
    "the bistable switch is controlled by a small number of transcription factor repressor molecules , called cro and ci , that compete for the same binding sites @xcite . in this case , the fate of the cell is tied to a single molecular decision , and therefore the stochasticity is important @xcite . the same can be said for rates of `` spontaneous switching , '' where thermal noise is able to flip a genetic switch .",
    "this is a rare , yet potentially important event , and considerable theoretic effort goes into computing the frequencies of such rare events .",
    "overall , in both genetic regulation and neural systems , the noise limits the amount of information that the network can transmit .",
    "nevertheless , the noise can often be treated as a small fluctuation riding on top of the signal . in protein - protein signaling networks ( such as the two - component systems in bacteria ) , the intrinsic noise is thought to be small , because the reactions involve hundreds to thousands of signaling molecules . on the other hand ,",
    "these molecules are proteins , transcribed from the genes and regulated by transcription factors , so the extrinsic noise can be large due to the slow ( compared to the timescales of signaling reactions ) random fluctuation in the total numbers of signaling proteins . there is evidence that biology tries to choose network wirings that make signaling networks _ robust _ with respect to this extrinsic source of slow fluctuations @xcite .",
    "let s return to the simple gene regulation scenario of fig .",
    "[ f - sscheme ] .",
    "we will sketch how the noise can be derived in this model using the langevin approximation , and give a back - of - the envelope estimate for the terms that we do not compute here .",
    "the reader is invited to view the full derivation in ref  @xcite .",
    "we start with the dynamical equations : @xmath194 where again we take the binding site occupancy @xmath48 to be between 0 and 1 , and the expression level of the output gene is @xmath43 ; @xmath43 is produced with rate @xmath42 when the binding site is occupied , and the proteins have a lifetime of @xmath23 .",
    "we have already shown that the equilibrium solution of this system is @xmath195 and @xmath196 . here",
    "we are interested in the fluctuations , @xmath197 , around the steady state , that arise purely due to intrinsic noise sources : * ( i ) * the fact that the binding site only has two binary states that switch on some characteristic timescale , * ( ii ) * the fact that we make a finite number of discrete proteins at the output , and * ( iii ) * the fact that the input concentration @xmath39 might itself fluctuate at the binding site location",
    ".    one approach would be to simulate the system of eqs  ( [ noise1],[noise2 ] ) exactly using the gillespie ssa algorithm .",
    "for a given and fixed level of input @xmath39 , the results of 20 such simulation runs are shown in fig .",
    "[ f - gillespie ] .    to compute this noise analytically instead of using the simulation , we have introduced random langevin forces @xmath198 , @xmath199 . consider the second equation , eq  ( [ noise2 ] ) .",
    "a single protein is produced anew , or is degraded , as an elementary step ( since you do nt make half a protein ) . in equilibrium , the production term @xmath200 balances the degradation term , @xmath201 .",
    "now consider some time @xmath33 in which @xmath202 , i.e. one molecule is produced or destroyed on average and with equal probability . while the expected change in the total number in equilibrium in time @xmath33 is zero , the variance is not : the variance is equal to @xmath203 ( production of 1 molecule)@xmath204 + @xmath203 ( degradation of 1 molecule)@xmath204 = 1 . in general , the variance will be @xmath205 if we measure for time @xmath33 .",
    "if you are familiar with random walks in 1d , this sounds very familiar : the mean displacement is 0 ( because leftwards and rightwards steps are equally likely ) , but the variance in displacement from the origin grows with time @xmath33 .",
    "statistical physics tells us that in order to reproduce this variance in a dynamical system , we have to insert langevin forces with the following prescription : @xmath206 the mean random force is zero , it is uncorrelated in time , and it has an amplitude such that the random kicks have variance equal to the leftward and rightward step size ; this will recover our intuition about 1d random walks .",
    "similarly , @xmath207 . to proceed , we first linearize eqs  ( [ noise1],[noise2 ] ) around the equilibrium , by writing @xmath208 , @xmath209",
    ". then we introduce fourier transforms : @xmath210 fourier transforms of @xmath198 and @xmath199 are simply @xmath211 and @xmath212 , respectively ( because the fourier transform of a delta - function is 1 , and we have also used the fact that in equilibrium , the two terms that contribute to each langevin force are equal ) .    with this in mind , the system of equations in the fourier space ( denoted by tildes ) now reads : @xmath213 where @xmath214 .",
    "we ultimately want to compute @xmath165 .",
    "the total variance is composed from fluctuations at each frequency @xmath215 , integrated over frequencies will depend on the difference in time only , and going into the fourier basis will diagonalize the covariance matrix .",
    "the total noise variance is the integral over these independent fourier components , and that is equal by parseval s theorem to the total noise variance obtained by doing the corresponding integral in the time domain . ] : @xmath216 where @xmath217 is called the _ noise power spectral density _ of @xmath43 , and the asterisk denotes complex conjugate .",
    "we see that we need to solve for @xmath218 first from eqs .",
    "( [ deriv1],[deriv1a ] ) : @xmath219 next , we compute @xmath220 . recalling the definitions of @xmath221 [ eq  ( [ lngforce ] ) ] , we find that @xmath222 the binding and unbinding of the promoter is usually much faster than the protein decay time , @xmath223 .",
    "using this and the fact that @xmath224 , we finally find @xmath225 if we normalize the expression level @xmath43 such that it ranges between 0 ( no induction ) to 1 ( full induction ) by defining @xmath226 , then the noise in @xmath227 is @xmath228 our result is lacking at least one important contribution to the total noise .",
    "the formal derivation of this term is involved @xcite , so we will estimate it here up to a prefactor . in our derivation",
    "we have not taken into account that the molecules of transcription factor are brought to the binding site by diffusion .",
    "the diffusive arrival of molecules into a small volume around the binding site is a random process as well : it will induce some noise in occupancy of the binding site , and thus in the expression level @xmath227 .",
    "this is the contribution we are going to estimate .",
    "suppose that the binding site is fully contained in a physical box of side @xmath105 .",
    "when the average tf concentration in the nucleus is fixed at @xmath229 , the average number of molecules in the box is @xmath230 .",
    "this , however , is only the mean number ; if we were to actually sample many times the number of molecules in the box , we would find that our counts are distributed in a poisson fashion , with a variance equal to the mean : @xmath231 .",
    "this is just the familiar shot noise in a new , molecular disguise !",
    "how can one reduce the fluctuations @xmath232 ?",
    "as always , one can make more independent measurements , and average the noise away . with @xmath233 independent measurements , the effective noise should decrease , @xmath234 .",
    "suppose the binding site measures for a time @xmath23 ( the protein lifetime , the longest time in the system ) .",
    "how many independent measurements were made in the best possible case ?",
    "it takes @xmath235 time for the molecules to diffuse out of the box of size @xmath105 and be replaced with new molecules ; if we take snapshots and count the molecules at intervals faster than @xmath147 , we are not making independent measurements .",
    "therefore @xmath236 .",
    "plugging this into the expression for effective noise , we find @xmath237 . since @xmath230",
    ", it follows that @xmath238 , and finally : @xmath239 equation ( [ cnoise ] ) is a fundamental result : any detector of linear size @xmath105 measuring concentration @xmath39 , to which ligands are transported by diffusion with coefficient @xmath104 , and making measurements for time @xmath23 , will suffer from the error in measurement in concentration , given by @xmath240 .",
    "this contribution to the noise is called _ diffusive noise _ , and it is a special form of input noise .    to assess how this error maps into the error in the gene expression @xmath43 , note that any error at the input can be propagated to the output through the input / output relation , @xmath164",
    "[ see fig  [ f - noiseprop ] ] : @xmath241    adding the diffusive noise to previously computed terms in eq  ( [ fnoise1 ] ) , we find : @xmath242 let us stop here with the derivation , interpret the terms and summarize what we have learned so far .",
    "we tried to compute various contributions to the noise in the expression of gene @xmath43 , in a simple regulatory element where the tf @xmath39 regulates @xmath43 . in any real organism",
    ", such a small regulatory element will be embedded into the regulatory network , and @xmath39 will experience fluctuations on its own that will be transmitted into fluctuations in @xmath43 , the so - called _ transmitted _ noise , in addition to intrinsic noise calculated here @xcite .    on top of intrinsic and transmitted noise sources , the output will also fluctuate due to the extrinsic noise because the cellular environment of the regulatory network is not stable . but even without these complications , we can identify at least three contributions intrinsic to the @xmath44 regulatory process : * output noise .",
    "* this is the first term in eq  ( [ noisefinal ] ) , where the variance @xmath243 .",
    "funamentally , this is a form of shot noise that arises because we produce a finite number of discrete output molecules . in the simple",
    "setting discussed here , the proportionality factor really is 1 [ when @xmath43 is measured in counts , as in eq  ( [ rawnoise ] ) ] , and this is a true poisson noise where variance is equal to the mean .",
    "if we treated the system more realistically , with separate transcription and translation steps , the proportionality constant could be different from 1 ; a more careful derivation shows that then , @xmath244 , where @xmath245 is the burst size , or the number of proteins produced per single mrna transcript , on average @xcite .",
    "this is easy to understand : the `` rare '' event is the transcription of a mrna molecule , and that has true poisson noise statistics , but for each single mrna the system produces @xmath245 proteins , and the variance is thus multiplied by @xmath245 . *",
    "input promoter switching noise .",
    "* this is the second term in eq  ( [ noisefinal ] ) .",
    "the source of this noise is binomial switching of the promoter , as it can only be in an induced ( @xmath61 ) or empty ( @xmath63 ) states .",
    "if we interpret @xmath172 as the probability of being occupied , then the variance must be binomial @xmath246 .",
    "fluctuations between empty and full states of occupancy happen with the timescale @xmath247 [ see eq  ( [ deriv1 ] ) ] , and the system averages for time @xmath23 , so @xmath248 independent measurements are made , reducing the binomial variance to @xmath249 .",
    "since @xmath250 and @xmath251 , we recover the switching term , @xmath252 .",
    "this term depends on the microscopic way the promoter is put together , hence the dependence on the kinetic parameter @xmath50 .",
    "regardless of these details , however , every promoter that has an `` on '' and `` off '' state will experience fluctuations similar in form to these derived here . in our example",
    ", @xmath50 is the rate of tf unbinding from the binding site and this is usually assumed to be very fast compared to the protein lifetime ( in other words , the occupancy of the promoter is equilibrated on the timescale of protein production ) . in other scenarios that effectively induce gene switching ,",
    "however , this assumption of fast equilibration might not be true .",
    "in particular , attention has lately been paid to dna packing and regulation via making the genes ( in)accessible to transcription using chromatin modification .",
    "the packing / unpacking mechanisms are thought to occur with slow rates , and such switching term might be an important contribution to the total noise in gene expression @xcite .",
    "* input diffusion noise . * the last term in eq  ( [ noisefinal ] ) , as discussed , captures the intuition that even with the fixed average concentration @xmath229 in the nucleus ( that is , even if @xmath39 did not undergo any fluctuation relating to its own production , degradation and regulation ) , there would still be _ local _ fluctuations at its tf binding site location , causing noise in @xmath43 .",
    "this contribution is important when @xmath39 is present at low concentrations . as an exercise",
    ", one can consider the approximate relevance of this term in case of prokaryotic transcriptional regulation , where @xmath253 , the size of the binding site @xmath254 , the relevant tf concentrations are in nanomolar range , and the integration times in minutes .",
    "it has been shown that this kind of noise also represents a physical limit in the sense that it is independent of the molecular machinery at the promoter , as long as the predominant tf transport mechanism is free diffusion .",
    "what we presented here theoretically was a simple example , but even so we ll see in the next section that the correspondence with the experiment is unexpectedly good .",
    "what is important for the lecture , however , can be summarized in the following observations : * ( i ) * not only can we make models for _ mean _ input / output relations , but we can compute the noise itself , as a function of the input .",
    "noise behavior is connected to the kinetic rates of molecular events , which are inaccessible in any equilibrium measurement of mean input / output behavior .",
    "therefore , if noise is experimentally accessible , it provides a powerful complementary source of information about transcriptional regulation . *",
    "( ii ) * there are fundamental ( physical ) sources of noise which biology can not avoid by any `` clever '' choice of regulatory apparatus ; thus the precision of every regulatory process must be limited .",
    "these sources all fundamentally trace back to the finite , discrete and stochastic nature of molecular events . in theory ,",
    "the corresponding noise terms thus have simple , universal forms , and we can hope to measure them in the experiment . *",
    "( iii ) * there are sources of noise in addition to the fundamental , intrinsic ones , including extrinsic , experimental , etc .",
    "the hallmark of a good experiment is the ability to separate these sources by clever experimental design and/or analysis .",
    "we ll show how extrinsic and intrinsic noise sources can be separated in the examples below ; in section [ lec5 ] we show how to deal with unknown experimental noise .      with the advent of quantitative microscopy ,",
    "the use of protein - gfp fusions and facs measurements , noise , precision and reproducibility in gene regulation have become central themes in biophysics and molecular biology .",
    "a milestone has certainly been the _ two - color experiment _ of elowitz and coworkers @xcite , allowing the separation of intrinsic and extrinsic noise sources .",
    "the basic idea of the two - color experiment is simple . to study a genetic regulatory mechanism @xmath44 , one engineers a bacterium to have two ( almost ) identical genes differing only in the color protein fusions ;",
    "say @xmath255 and @xmath256 .",
    "both of these genes are regulated by the same transcription factor , @xmath39 , and have the same promoters .",
    "the bacteria grow under the microscope , and for each bacterium , it is possible to collect the joint measurements of @xmath257 at a given fixed induction level ( related to @xmath39 or the concentration of its inducer ) .",
    "the basic realization of the experiment is as follows : scatter - plotting the values of @xmath257 collected from a cell , one can split the total variance in this cloud of points into the variance along the `` correlated '' axis ( along the equality line ) , and the `` perpendicular '' axis , as in fig .",
    "[ f-2color ] .",
    "these two orthogonal contributions are then identified with the extrinsic and intrinsic noise strengths , respecticely .",
    "the fluctuations in @xmath258 and @xmath259 can be correlated only because they do nt happen in the system @xmath44 itself , but in its intracellular environment , which affects both copies of @xmath258 and @xmath259 equally , in a correlated fashion .",
    "the intrinsic noise , however , is due to the terms we previously discussed in relation to eq  ( [ noisefinal ] ) , and would be present even if the cellular environments were perfectly stable and reproducible .",
    "the intrinsic noise is uncorrelated , because random events in the @xmath44 regulatory system happen independently in each of the two - color replicas in the cell .",
    "this `` two - color '' trick has enabled a whole set of experiments in which contributions from various steps in more complicated regulatory schemes , e.g. cascades @xmath260 , have been teased apart @xcite . again ,",
    "note that `` intrinsic '' and `` extrinsic '' are a matter of where one chooses to draw the boundary of the system and which part of the regulatory element gets replicated to apply the two - color paradigm .",
    "a number of studies have since focused on the noise in prokaryotic gene expression .",
    "the findings indicate that the dominant sources of noise are the output ( intrinsic ) noise of making mrna transcripts with relatively short correlation time ( in minutes ) , and the extrinsic noise with long correlation time ( of the order of a cell cycle ) @xcite .",
    "the noise in units of the mean , @xmath261 , is very roughly of the order of @xmath262 .",
    "a similar set of results was obtained in a high - throughput essay in yeast , where the noise was found to scale with the mean with a large prefactor , consistent with bursty expression @xcite . an earlier study in the gal promoter in yeast",
    "has , however , found a significant contribution of a noise that looks like the input switching noise , and has explained it by the cycling of the promotor through its microscopic states @xcite .",
    "later work in higher organisms has revealed an ever more important role of the intrinsic input noise , both the switching and the diffusive components . in mammalian cells ,",
    "it has been possible to observe the number of mrna molecules using the fish method , and it was found that whole genes ( or even sets of collocalized genes on the dna ) stochastically switch on and off ; this might be a consequence of chromatin remodeling mechanisms @xcite .",
    "our work in gene regulation during early _ drosophila _ morphogenesis has tried to quantitatively connect the model of eq  ( [ noisefinal ] ) with the experimental data @xcite . during development , each nucleus in the embryo of the fruit fly experiences a spatially varying concentration of the input transcription factor , bicoid , @xmath39 , and activates the expression of hunchback , @xmath43 ; both of these quantities can simultaneously be measured using immunostaining and microscopy methods .",
    "many nuclei experience the same level of input , @xmath39 , in the same embryo .",
    "we can thus ask , for each input @xmath39 , about the mean input / output relation , @xmath164 , and also for the noise @xmath197 , and these two measurements can be combined into @xmath263 , the noise in hunchback expression as a function of mean induction , shown in fig .",
    "[ f - noise5 ] .",
    "all three fits of the theoretical models to the data shown in fig .",
    "[ f - noise5 ] are two parameter fits .",
    "we fit essentially the same model as that of eq  ( [ noisefinal ] ) ; the only exception is that the noise is derived for a cooperative promoter with cooperativity of @xmath264 , which can be read off from the hb / bcd input / output relation , see fig .",
    "[ f - noise2 ] .",
    "one parameter is always the magnitude of the output noise [ the prefactor to the output noise term of eq([noisefinal ] ) ] .",
    "the second parameter is the magnitude of the input diffusive noise ( for solid black and red lines ) , or the magnitude of switching noise ( blue line ) .",
    "the solid black fit describes the data excellently , and the following conclusions can be drawn from this study : * ( i ) * qualitatively , input noise sources produce a peak in the noise at intermediate expressions when one plots @xmath265 vs @xmath227 .",
    "the input noise goes to 0 for zero or full induction .",
    "in contrast , the output noise increases monotonically with the induction .",
    "therefore , whenever the experiment claims a peak in the noise , this is likely due to the non - negligible contribution of input noise to the total . *",
    "( ii ) * the previous intuition also enables us to interpret the two fitted parameters .",
    "the strength of the output noise is proportional to the noise magnitude at full induction , @xmath266 , while the fitted strength of the input noise is proportional to the size of the peak at intermediate induction . *",
    "( iii ) * we find that the fitted values of parameters are consistent with plausible values for transcriptional regulation : i.e. , the magnitude of output noise is related to the number of molecules of hunchback per nucleus ( estimated from the fit to be @xmath267 ) , and the magnitude of the input noise is consistent with the measured bicoid diffusion constant and integration time .",
    "processes that underlie the limits to temporal precision of single neurons are physically analogous to the noise sources discussed in gene regulation ; indeed , the study of temporal jitter in neural spiking predates the study of noise in gene regulation by several decades .",
    "a neuron generates the ionic currents by opening and closing of ion channels .",
    "these proteins have voltage - dependent probabilities , @xmath268 , of being open or closed .",
    "this nonlinear dependence , combined with the cable equation for propagating voltage disturbances in a medium with some capacitance , gives rise to self - excitability and generation of action potentials .    by making an analogy to the binomial",
    "`` switching noise '' in gene regulation , we see that for each ion channel , there will be an associated binomial variance in its activity , proportional to @xmath269 .",
    "this variance is reduced because there are many channels in each neuron that open and close independently ( here we have population noise averaging , similar to temporal averaging in gene expression ) , but it is not reduced to zero . using patch - clamp techniques it has been possible to electrically isolate a small patch of the membrane containing a very small number of channels , and to observe the quantal pulses of current flowing through single channels .",
    "this randomness in opening and closing of ion channels is one of the reasons why the neurons do not respond with identical spike trains to presentations of exactly repeated inputs .",
    "up to this point we have stressed the role of noise in biological networks and mentioned several time that noise limits the ability of the network to transmit information ; in this lecture we will turn this intuition into a mathematical statement .",
    "recall that in our introduction to noise , we started with a probabilistic description of an information transmission system : given some input @xmath39 , the system maps will map it into the output @xmath43 using a probabilistic mapping , @xmath158 . in case",
    "there were no noise , there would be no ambiguity , and @xmath270 would be a one - to - one function .",
    "suppose that the inputs are drawn from some distribution @xmath160 and fed into the system which responds with the appropriate @xmath43 .",
    "then , pairs of input / output symbols are distributed jointly according to @xmath271 in what follows , we will be concerned with finding ways to measure how strongly the inputs ( @xmath39 ) and the outputs ( @xmath43 ) are dependent on each other .",
    "it will turn out that the general measure of interdependency will be tightly related to the concept of _",
    "let s suppose that our information transmission `` black box '' would be a hoax , and instead of encoding @xmath39 into @xmath43 in some fashion , the system would simply return a random value for @xmath43 no matter the input @xmath39",
    ". then @xmath39 and @xmath43 would be _ statistically independent _ , and @xmath272 ; such a box could not be used to transmit any information . as long as this is not true , however",
    ", there will be some statistical relation between @xmath39 and @xmath43 , and we want to find a measure that would quantify `` how much '' can i know , in principle , about the value of @xmath39 by receiving outputs @xmath43 , given that there is some input / output relation @xmath158 and some distribution of input symbols @xmath160 .    the first quantity that comes to mind as the interdependency measure between @xmath39 and @xmath43 is just the covariance : @xmath273 it is not hard , however , to construct cases in which the covariance is 0 , yet @xmath39 and @xmath43 are statistically dependent .",
    "covariance alone ( or correlation coefficient ) only tells us about whether @xmath39 and @xmath43 are _ linearly related _ , but there are many possible nonlinear relationships that covariance does not detect ; for example , see fig  [ scall ] .",
    "moreover , we would like our dependency measure to be very general ( free of assumptions about the form of the probability distribution that generated the data ) and definable for both continuous , as well as discrete outputs .",
    "we will claim , following shannon , that there is a unique , assumption - free measure of interdependency , called the _ mutual information _ between @xmath39 and @xmath43 .",
    "before we define it , however , we need to define another quantity , called the _ entropy _ of a distribution @xmath160 : @xmath274=-\\int dc\\ ; p(c ) \\log_2 p(c)\\ ] ]    to keep things simple , let s for now assume that the value of interest is discrete , that is , that @xmath39 can only take on the values @xmath275 , @xmath276 . in that case",
    "@xmath274=-\\sum_{i=1}^k p(c_i ) \\log_2 p(c_i).\\ ] ] if the data were continuous , we would have discretized it prior to computing the entropy ( we discuss the discretization later ) ; the measure that we are after , the mutual information , will turn out to be independent of discretization .",
    "entropy can be defined for any distribution .",
    "it is always positive , measured in bits , and always takes a value between two limits : @xmath277 \\leq \\log_2 k$ ] ( in discrete case ) .",
    "the entropy is zero when the distribution has its whole weight of 1 concentrated at a single @xmath275 .",
    "the entropy is maximal when @xmath278 , i.e. @xmath30 is a uniform distribution .",
    "the entropy is a unique measure of uncertainty about the value of @xmath39 : the uncertainty is 0 when the distribution is peaked at a single value , and maximal when all @xmath275 are equally likely .    in one of the fundamental works of the 20th century science",
    ", shannon has argued that this quantity , the entropy , is connected to the amount of _ information _ that needs to be supplied to specify a particular value of @xmath39 .",
    "suppose @xmath39 can take on 8 different values @xmath279 , and @xmath280 , that is , the distribution is uniform , and by our definition , has an entropy of @xmath281 bits .",
    "i draw a particular @xmath275 from the distribution and do nt share the value with you .",
    "you are allowed to ask a series of yes / no questions about the value i chose and your task is to determine my choice in as few questions as possible .",
    "what is _ the minimum number of questions that you need to ask , on average _",
    "this turns out to be the same as the entropy , and in case when @xmath282 is uniform , one of the optimal strategies is bisection :  is the chosen @xmath275 larger than 4 ? \"",
    "if yes , the next question could be `` is @xmath275 larger or equal to 7 ? '' otherwise , you could ask `` is the chosen value less or equal to 2 ? '' and so on , until the correct @xmath275 is identified .",
    "bisection is optimal because with a single binary question , it partitions the set of possible values into two equally likely subsets . to show that the number of questions is equal to the entropy even in the case of non - uniform @xmath282 one needs some extra work , but the intuition remains the same .",
    "note that the entropy is the minimum number of questions , _ on average _  across many repeats of the game . in single instances of the game",
    "you might be lucky and hit the correct number by simply asking `` is the correct value @xmath275 equal to 7 ? '' .",
    "however , this strategy will only terminate in @xmath283 of the games with a single question , and on average , it is worse than the strategy of bisection .    in case of continuous variables , no number of questions can pin down the exact value of a real number , because , mathematically , real numbers have infinite precision . in practice",
    "this is not a concern , because the precision of physical data is always limited by noise or measurement error .",
    "we can therefore always discretize a continuous measurement into bins with the size of the error bar . formally , all information theoretic quantities can be properly defined also for continuous variables , but in the interest of clarity we will skip these generalizations here .    to summarize : a `` bit '' is thus amount information contained in a single binary response to an optimally posed question  in other words , a bit is the maximum amount of information that a binary question can convey .",
    "for each distribution @xmath160 of some quantity @xmath39 we can define a measure called its entropy , a positive number expressed in bits , that quantifies the uncertainty about the value of @xmath39 , and is connected to the minimal number of yes / no questions that need to be asked to find out the value of @xmath39 on average .",
    "let s now return to the original problem , where we think about two variables , @xmath39 and @xmath43 , jointly distributed as @xmath284 , and we would like to quantify how statistically dependent the two variables are .",
    "let s start by computing @xmath285 $ ] , and assume that our values are discretized ( so we are dealing with @xmath286 and @xmath275 , where @xmath25 and @xmath27 run over all possible discrete choices for @xmath43 and @xmath39 , respectively ) : @xmath287=-\\sum_j p(g_j)\\log_2p(g_j).\\ ] ] according to what we have just learned , this is the uncertainty about the value of @xmath43 .",
    "we can also compute the following : @xmath288=-\\sum_j p(g_j|c_i ) \\log_2 p(g_j|c_i).\\ ] ] this entropy still depends on @xmath39 , because the sum is taken only over the possible values for @xmath286 .",
    "the interpretation of this quantity is the _ uncertainty about the value of @xmath43 if we know the value of @xmath39 to be @xmath275_. if @xmath39 and @xmath43 are related in any statistical way whatsoever , we expect that by knowing @xmath39 , our uncertainty about @xmath43 will be less , on average , than if we do nt know @xmath39 . in other words , @xmath39 will give us some information about @xmath43 , if there is any statistical interdependency . in equations , let s define mutual information @xmath177 as : @xmath289- \\sum_i p(c_i ) s_{n}(c_i ) .",
    "\\label{mut1}\\ ] ] the crucial insight is that without any knowledge of @xmath39 , @xmath43 will have the uncertainty @xmath285 $ ] ; with the knowledge of @xmath39 , the average uncertainty about @xmath43 is smaller , @xmath290 .",
    "the difference between these two quantities is the mutual information , and shannon has shown that this is a unique assumption - free measure of any statistical dependency that does not make any assumption about the form of the joint distribution @xmath284 .",
    "mutual information is a number in bits , and can be shown to be always positive .",
    "algebraic manipulation of eq  ( [ mut1 ] ) quickly produces a more compact expression : @xmath291 where @xmath282 and @xmath292 are marginal distributions of the joint @xmath293 .",
    "note that the mutual information is a single number , not a function , although it is conventionally written with the arguments in parenthesis , @xmath294 , to denote that it is information between @xmath39 and @xmath43 .",
    "mutual information has a number of very appealing properties :    * * it can be defined for continuous or discrete quantities .",
    "* mutual information is a functional of a probability distribution , and probability distributions are very generic objects . @xmath39 and @xmath43 could both be continuous , or any one or both can be discrete . * * it is reparametrization invariant . *",
    "mutual information betwen @xmath39 and @xmath43 is the same than mutual information between any one - to - one function of @xmath39 , @xmath295 , and any one - to - one function of @xmath43 , @xmath296 , that is @xmath297 . in biological experiments ,",
    "this is a great asset , as we will soon see : experiments often report , e.g. intensities or log - intensities on the microarray chips or in facs sorting , and there is a lot of discussion about how this data should be normalized and transformed prior to any analysis .",
    "this is important because some statistical measures of correlation , like correlation coefficients , depend on it .",
    "mutual information , in contrast , is invariant to such reparametrizations of the variables . * * it is symmetric . *",
    "mutual information tells us , in bits , how much i learn about @xmath43 if i know the value of @xmath39 .",
    "as is evident from eq  ( [ mut2 ] ) , @xmath294 is symmetric with respect to the change in @xmath39 and @xmath43 , i.e. @xmath298 .",
    "this means that i can equally well learn about @xmath39 by knowing the value of @xmath43 . *",
    "* it obeys data processing inequality . *",
    "suppose that @xmath43 depends on @xmath39 and @xmath4 depends on @xmath43 ( but not directly on @xmath39 ) , in some probabilistic fashion .",
    "in other words , one can imagine that there is a markov process , @xmath299 , where arrows denote a noisy mapping from one value to the next one : @xmath39 gives rise to @xmath43 and @xmath43 to @xmath4 .",
    "then @xmath300 , that is , information necessarily either gets lost or stays the same at each noisy step in the transmission process , but it is never `` spontaneously '' created .",
    "there is a number of powerful theorems relating to mutual information which we will not go into here , but the interested reader is referred to the classical text of thomas and cover for details . to summarize",
    ", shannon has shown that there is a unique , positive , assumption - free measure of statistical interdependency of two variables @xmath39 and @xmath43 that is called the mutual information and which is given by eq  [ mut2 ] .",
    "this measure is zero if and only if the two variables are statistically independent .",
    "it does not describe _ what _ kind of interdependency there is between the two variables , rather , it only quantifies how much of interdependency there is , in bits .",
    "since this is a measure over probability distributions , it is extremely generic . before focusing on one in - depth example in section",
    "[ lec5 ] , let s first enumerate a number of possible applications relevant to biology :    * first , * @xmath39 and @xmath43 could be expression levels of different genes .",
    "the levels can be statistically correlated because the genes are regulated by a common transcription factor , because they regulate each other , or because their expression is modified coherently by some other cellular property ( such as volume change ) .",
    "mutual information can be used to measure the dependency between the two expression levels . in particular , in microarray experiments one measures the simultaneous expression of many ( possibly all ) genes , across a range of conditions , such as changes in nutrient concentrations , ph , temperature etc .",
    "then , we can construct a similarity matrix of @xmath301 mutual information values between all @xmath16 genes , computed across all experimental conditions .",
    "this matrix measures the degree to which the genes are coexpressed .",
    "commonly , correlation coefficients of log intensity values are used for this purpose , but it has been shown that mutual information can discover nonlinear dependencies , such as that in fig .",
    "[ f - miex ] , which the correlation measure will miss .",
    "* second , * in these lecture notes we have set up an example where the transcription factor @xmath39 regulates the expression of gene @xmath43 .",
    "computing the mutual information between @xmath39 and @xmath43 then can answer , in a mathematically precise way , an interesting question : `` are genetic regulatory elements binary switches ( i.e. do they have the capacity of 1 bit ) or are they able to convey more than 1 bit of information , and if so , how much ? '' we explore this in section [ lec7 ] .    * third , * one could ask about how strongly any dna sequence , for instance that of a tf binding site , influences the expression level of a reporter gene .",
    "this is an interesting problem that is looking for a relation between a short segment of dna sequence of length @xmath129 , @xmath302 , and the expression level @xmath43 .",
    "using the usual measures of dependency we might face practical difficulties because the sequences live in a space of @xmath303 , whereas the expression levels are real - valued measured quantities , @xmath304 . since mutual information is defined on probability distributions and @xmath305 is a well - defined object , finding @xmath306 is possible .",
    "we explore this in section [ lec5 ] .",
    "* fourth , * we could ask about the information between the presence or absence of a given gene , or set of genes , and the phenotype of the organism @xcite .    * fifth , * in visual neuroscience , neurons in the retina are sensitive to spatio - temporal correlations of light ; when exposed to the preferred stimulus , the neuron might spike .",
    "how much information does a spike carry about the neural input ? again , answering this question requires us to find statistical dependency between the stimulus and a point object in time , such as a spike , and @xmath307 is a natural way of quantifying this dependency .",
    "* sixth , * one could use information as a measure over discrete objects , such as sequences . for instance , how much information does a single base - pair carry about whether the region of the genome in which the base pair is located is a coding vs noncoding region ? how much do pairs , or consecutive triplets of base - pairs carry about the coding vs non - coding region ?",
    "another possible example would be to compute the mutual information between the sequence snippets of related organisms , @xmath308 , as a measure of evolutionary distance .      to be concrete ,",
    "let s focus on a real dataset .",
    "the data was reported in ref .",
    "@xcite , where the authors studied a map kinase cascade signaling network in human immune system cells . to this end , they designed probes against specific phoshorylated ( or otherwise activated ) forms of 11 signaling proteins in the network ; each probe was tagged with a fluorophore of a different color .",
    "many cells were fixed and stained , and ran through the facs machine to obtain simultaneous readouts of the activation levels of 11 proteins , for each cell .",
    "the measurements were done in 9 conditions @xmath309 , @xmath310 , and in each condition a sample of around @xmath311 cells was recorded .",
    "conditions differed in the chemical environment that the cells were exposed to : in some conditions , naturally occurring ligands were presented , while in the others , artificial blockers or activators , specific for some of the signaling proteins in the network , were applied .    for our purposes ,",
    "the experiment provides us with a dataset of @xmath312 samples , where each sample is a simultaneous recording of 11 activation levels , @xmath21 , @xmath313 ; see fig .",
    "[ f - expt ] .",
    "let us first quantify how correlated are pairs of elements in this signaling network , across all conditions presented ; this is similar to the procedure that would be used in microarray experiments . figure  [ f - pn - cc ] shows the pairwise correlation coefficients using two different normalization schemes .",
    "one immediate problem that we face is that the correlation values strongly depend on the normalization of our data .",
    "more problems , however , are revealed when we look at the histograms and scatter - plots of the activities  fig .",
    "[ f - pn - scatter ] shows that the histograms @xmath314 have very nontrivial , multi - peaked structure , and the scatterplots of pairs of activity levels reveal very non - linear dependence",
    ".    our first task will be to measure the pairwise dependencies using the mutual information measure of eq  ( [ mut2 ] ) . to compute the mutual information , the equation instructs us discretize both @xmath39 and @xmath43 into @xmath245 bins , histogram @xmath284 from the data",
    "( @xmath284 will be a @xmath315 matrix ) , and from there compute @xmath294 in a straightforward way  we will refer to such direct calculation with binned and sampled data the _ naive _ estimator with @xmath12 samples and @xmath245 bins , and denote it by @xmath316 .",
    "two problems , however , are in our way : * ( i ) * we need to discretize ( bin ) the data and there is a question of where to draw the discretization boundaries to gain the best statistical power ; * ( ii ) * it can be shown that mutual information is a sensitive statistic to compute ; in particular , it gives a biased estimate of the true value when evaluated on probability distributions sampled from any finite dataset .",
    "this happens because the empirical probability , @xmath317 , that is obtained by sampling , has bins with small ( or even zero ) counts .",
    "one of the most straightforward ways to correct for this bias is the so - called _ direct _ estimation method , which addresses both issues ( i ) and ( ii ) simultaneously .",
    "the crucial realization was to derive the small - sample effect on the naive estimator : @xmath318 this equation says that if we hold the number of bins @xmath245 fixed and change the number of samples , the naive estimator and the true value ( which we would get if the number of samples were infinite ) , differ by a bias that scales as @xmath319 .",
    "we can use the equation as a prescription for getting rid of the bias : if our true dataset is of size @xmath320 , we can subsample the data at fractions of the total size , for example at @xmath321 , many times , and compute an average naive estimator at each fraction of @xmath320 . with these estimators in hand",
    ", we can use linear extrapolation in @xmath319 from eq  ( [ esti ] ) to obtain an unbiased estimate of information with @xmath245 bins , @xmath322 . what remains to be done ,",
    "then , is to choose a correct number of bins for discretization . with too small a number , we will lose the structure in the joint distribution ",
    "e.g. if one only discretizes into 2 levels , for instance , fine scale details in @xmath323 of fig .",
    "[ f - pn - scatter ] might be lost .",
    "if one discretizes into too many bins , however , then the linear correction term in eq  ( [ esti ] ) will no longer suffice to counter the sampling problems , and our estimates will be wrong . for a reference on direct estimation technique , consult ref .",
    "@xcite .",
    "figure  [ f - estmi ] documents the _ direct _ estimation procedure .",
    "we see that as the number of bins @xmath245 grows , we capture more and more information in the data , and the slope of the extrapolation line [ and thus finite - size corrections of eq  ( [ esti ] ) ] are increasing in size .",
    "if we used @xmath324 bins , the extrapolation would break down and we would lose control over information estimation .    if the data were inherently discrete , then the technique is more straightforward : one only does the @xmath319 extrapolation to correct for the sample size at the given number of bins that correspond to the number of discrete levels in the data .",
    "finally , we can apply the estimation procedure to the map kinase signaling network dataset to extract the @xmath325 pairwise mutual - information matrix , summarizing the statistical dependencies between all pairs of activities @xmath21 , @xmath286 , see fig .",
    "[ f - minolan ] .",
    "interestingly , for example , the mutual information analysis reveals that the pair @xmath326 has about 0.4 bits of mutual information , yet the pairwise correlation coefficient is only @xmath327 , signaling that most of the statistical dependency is not linear .",
    "there are many other ways to estimate mutual information differing in how they handle the small - sample bias , which is the biggest technical difficulty with estimations of this sort ; the naive estimators are very quick , but resamplings necessary to handle the bias lengthen the computational time considerably .",
    "nevertheless , mutual information has been used to compute pairwise similarity matrices between all pairs of genes in high throughput experiments @xcite , and overall , this statistic is gaining in popularity in life sciences .      before concluding this lecture , let us discuss two generalizations of mutual information .",
    "the first generalization extends the measure to include higher - than - pairwise structure .",
    "suppose that we have three interacting elements , @xmath258 , @xmath259 , and @xmath328 .",
    "there are 3 pairwise mutual informations that one can compute , @xmath329 , @xmath330 and @xmath331 , describing pairwise statistical dependence .",
    "however , there might be statistical dependencies between three elements of the network that no pairwise measure can detect .",
    "the simplest example can be constructed if @xmath258 , @xmath259 , @xmath328 are binary variables , related by @xmath332 , where the binary function xor returns 1 exactly when @xmath258 and @xmath259 are different , and 0 otherwise ; see fig  [ f - xor ] .    in order to detect this higher - order dependence ,",
    "we need an information - theoretic measure that generalizes mutual information .",
    "this measure is called the multi - information , and is defined as follows : @xmath333 where the numerator contains the joint distribution over @xmath233 elements , @xmath334 , and the denominator contains the product of marginal distributions .",
    "multi - information captures all statistical structure between pairs , triplets , up to the complete statistical correlation between all @xmath233 elements . while powerful , this quantity is usually very hard to estimate because one would need to sample the full joint distribution over @xmath233 elements .",
    "we can , however , restrict ourselves to triplets of elements .",
    "for the synthetic xor example we would find that the multi - information is 1 bit ( because if @xmath258 , @xmath259 , @xmath328 were completely random , uncorrelated binary variables , they would have 3 bits of entropy ; however , only @xmath258 and @xmath259 are randomly and independently drawn , while @xmath328 is a deterministic function of both , so the true entropy of the joint distribution is only 2 bits ; this reduction of 1 bit is the multi - information ) . in case of the map network data , the full multi - information would require the 11 dimensional joint distribution , but we could restrict ourselves to triplets @xmath335 and ask about how much interdependency there is in such combinations . up to now , we have been looking for statistical structure among @xmath336 irrespective of the conditions , @xmath29",
    ". we could also ask about the mutual information between the activation level of protein @xmath25 and condition @xmath29 , that is , @xmath337 , using the estimation techniques already developed .",
    "when we consider such condition ( or stimulus ) dependence , there is also a new set of statistical questions that we can ask . for two signaling proteins , @xmath21 and @xmath286 , we can compute separately @xmath337 and @xmath338 , respectively .",
    "but we could also ask about @xmath339 : how much information does a pair @xmath340 of two activation levels together tell us about the condition @xmath29 . in principle , this can be more or less than the sum @xmath341 .",
    "we define the quantity @xmath42 as : @xmath342 when @xmath42 is negative , the pair of activity levels together is more informative about the condition than both levels considered separately ; @xmath340 are said to be synergistic .",
    "alternatively , when @xmath42 is positive , @xmath21 and @xmath286 are not providing independent information about the condition  they are redundant .",
    "synergy and redundancy are extensively used in neuroscience to ask how groups of neurons _ together _ encode the stimulus ( stimulus in neuroscience is analogous to conditions @xmath29 in our example ) , as compared to how single neurons on their own encode the stimulus . in our map kinase example , we find that pairs of activity levels provide redundant information about the condition .",
    "further details can be found in ref @xcite .",
    "information theoretic measures , such as mutual information , multi - information , redundancy , synergy ( and others that we do nt discuss here , such as kullback - leibler divergence , jensen - shannon divergence etc ) provide a very powerful , assumption - free framework for discovering statistical dependencies in the data . there",
    "exist systematic approaches that discover correlations , both linear and non - linear , between pairs of elements , triplets , quadruplets etc @xcite ; we are usually limited by the availability of data and run into sampling problems for such higher - order dependencies , but in principle they could be computed .",
    "in our toy example of transcriptional regulation we have been assuming that transcription factors bind to a well - defined `` binding site '' somewhere on the dna .",
    "but what distinguishes the particular binding site  a sequence of 10 - 20 nucleotides  from all other possible short sequences in the genome",
    "? how does the tf molecule _",
    "find _ the correct binding site ?",
    "there is a substantial amount of existing work addressing each of the two questions which are stated more precisely below :    * the `` specificity problem '' * arises because the correct statistical mechanics problem for tf binding is not only that of a single ( specific ) site being occupied or empty , as schematized in fig .",
    "[ f - sscheme ] . instead of a single site",
    ", there is really a large number @xmath233 of sites on the genome , and they have a distribution of binding energies @xmath343 : most likely , the specific site is one of the best binders ( having the most negative @xmath73 ) , but there might also be some non - functional sites with low energies as well as a huge number ( millions for a prokaryote , or billions for an eukaryote ) of spurious non - specific sites that the tf molecule could bind weakly",
    ". our partition function should reflect this : @xmath344 , where the sum is taken across _ all _ the sites in the genome ( including the specific site that we denote as having the energy @xmath345 ) .",
    "the real question is as follows : how does the cell make sure that the tf spends most of the time occupying the ( functional ) binding site , and not sitting wastefully on a large number of non - functional traps ? clearly , the binding energy to the specific site must be much stronger than to the non - specific sites , @xmath346 .",
    "but the sites only differ in their sequence of nucleotides @xmath302 , so there must exist an `` energy function '' @xmath347 such that @xmath348 .",
    "what are the energy functions for real transcription factors ?",
    "* the `` search problem '' * arises when we realize that even if _ equilibrium _",
    "occupancies were to work out and the specific site is occupied with larger probability than non - specific sites , there remains the question of the speed of equilibration .",
    "to equilibrate , tf molecules in the nucleus they must sample various sites on the genome and must therefore physically move from site to site on the dna . because the translocation of tfs is driven by random diffusion , this puts a computable upper bound on how quickly the sites can be sampled and how quickly the system can equilibrate .",
    "a lot of excitement was generated when it was observed that some transcription factors can find their sites faster than predicted given the 3d diffusion limit ; more complex modes of tf translocation were proposed , including sliding and hopping of transcription factor molecules along the 1d contour of the dna .",
    "it seems that a combination of 1d and 3d diffusion can reconcile the measured rapid tf search times with the theoretical expectations @xcite .    here",
    "we will focus on the first problem of specificity in tf - dna interactions .",
    "in particular , we will discuss how information theory can be used to infer the energy function , @xmath347 , for a given transcription factor whose binding has been probed in various high - throughput assays .",
    "why is the problem of dna - tf interaction important ? if we want to ultimately understand genetic regulatory networks , we need to know which transcription factors bind where in the genome  in particular , which sets of genes they are regulating .",
    "the latter question can be answered if one knows the energy model for tf - dna interaction and is in possession of the complete genome sequence .",
    "whole genome sequences are available today , so the difficult part of this program is learning the model of tf - dna interaction from various datasets , such as protein binding microarrays , chromatin immunoprecipitation assays , microarrays and high throughput sequencing techniques .",
    "we start by giving a brief overview of how the interaction between tf molecules and dna has traditionally been described and inferred from data .",
    "we continue by pointing out the flaws in the traditional approach and show how it can generate biased models of tf - dna interaction .",
    "we end by proposing a new information - theoretic inference method that can avoid these problems if enough data is available .",
    "nucleotides and sequence @xmath302 .",
    "the energy of this interaction @xmath347 is given by an _ energy matrix _",
    "@xmath349 of dimension @xmath350 , here represented as the matrix in the tf molecule .",
    "each nucleotide @xmath351 in the sequence contributes independently to the total binding energy , which is a linear function of sequence : @xmath352 . at each position",
    "@xmath353 we look up the base at that position @xmath354 in the short sequence , then look up the corresponding entry in the energy matrix @xmath355 , and add it to the total binding energy.,width=288 ]    the simplest model of tf - dna interaction is the so - called energy matrix model , shown in fig .",
    "[ f - pwm ] . in this model ,",
    "tf binds short sequences @xmath356 of length @xmath129 on the dna . each base pair in a short sequence , @xmath351 , contributes independently to the total binding energy .",
    "these energy contributions are parametrized by the energy matrix @xmath355 of dimension @xmath357 , where each entry in the matrix at position @xmath25 specifies how much energy is contributed by a particular base @xmath354 at that position , as shown in fig .",
    "[ f - pwm ] .",
    "this independent energy matrix model is likely not literally true , but the number of free parameters @xmath358 can be small enough so that reasonable energy matrix models can be fit from available data , but @xmath359 instead . ] .",
    "models that include higher - order contributions to the energy are more realistic , but the number of parameters explodes .",
    "moreover , the simple model has had a number of successes in predicting tf binding sites , so we adopt it here .      when no high - throughput experiments were available , the primary data that could serve as input for inference of energy matrices were lists of known and experimentally verified binding sites .",
    "frequently , these lists were incomplete , both because it was time - consuming to probe many candidates , and because the experimentalists preferred to set stringent criteria for a `` true '' site and thus avoid the controversial issue of possible weak , but functional , sites .",
    "suppose a list of @xmath233 known binding sites , @xmath360 , @xmath361 , is given .",
    "then , there exists a concise summary of tf sequence preference known as the _ position weight matrix _ , or pwm : @xmath362 that is , the pwm is simply a frequency table of how often a particular base @xmath245 appears at position @xmath363 in the set of known binding sites . in a seminal paper , berg and von hippel have shown that under certain conditions there exists a simple relation between the pwm of a given transcription factor , and its energy matrix @xcite : @xmath364 up to the arbitrary energy offset in each row of the energy matrix , and the overall unit of energy ( scale factor ) .",
    "since this paper has appeared , the connection between pwm and energy matrix has become the cornerstone of inferring energy matrices : first , a list of known ( putative ) binding sites is produced , a pwm is extracted from it and the energy matrix is constructed using the equality in eq  ( [ bvh ] ) , and the list of putative binding sites is then usually refined in some iterative procedure that involves experimental data .",
    "even when the experimental techniques progressed and the data was not restricted to short lists of verified binding sites , most inference procedures still relied on the berg - von hippel equality .",
    "moreover , pwm slowly emerged as _ the _ relevant object that characterizes tf - dna interaction , together with the picture that one must look for _ statistical signals _ in the promoter regions of the genes that signify sequences different from some _ null background _",
    "expectation for what a non - functional sequence should look like .",
    "this `` statistical view , '' which regards tfs as objects that look for `` patterns in the sequence , '' can be deceiving , if one forgets that tfs are not algorithms , but physical objects , and therefore must be described by physical quantities : energy of dna - tf interaction is such a quantity , while a pwm is not .",
    "what are the assumptions that must be true in order for eq  ( [ bvh ] ) to hold ? * ( i ) *",
    "the true binding sites are embedded into genomic background which is large and where bases are used independently at each site ; * ( ii ) * the true binding sites have sequences that are as random as possible ( maximum entropy ) , with the only constraint that the _ average _ binding energy of the sites in the known sites list is fixed , @xmath365 . in other words ,",
    "this assumption states that the only distinguishing feature of functional sites is that their binding energy is approximately @xmath365 , presumably lower than the other nonfunctional sites in the genome ;",
    "* ( iii ) * the concentrations of tf are not such that some sites would be fully saturated ; * ( iv ) * the known sites list is complete , or at least an unbiased sample of the true binding sites .",
    "what role do these assumptions play in combination with modern data sets when inferring tf energy matrices ?",
    "figure  [ f - mukherjee ] shows data from one high - throughput experiment that can probe simultaneously the binding of a single transcription factor to all intergenic regions in yeast ( see figure caption for details ) .",
    "usually the analysis proceeds by thresholding the dataset to isolate sequences in which there are binding sites ( true positives ) and to minimize those sequences mingled in that do not have a binding site yet pass the threshold ( false positives ) .",
    "data above threshold is retained , while data below it is discarded . with the data above threshold in hand",
    ", some model is assumed that links the direct experimental readout ( e.g. the light intensity in the pbm chip ) with the putative binding of the transcription factor somewhere in the corresponding intergenic region .",
    "often , an initial guess will be made for the energy matrix , which will then be scanned across the sequences passing the cut to identify possible ` hits ' in those regions , i.e. sites of length @xmath129 that score well with the assumed energy matrix .",
    "the predicted hits will give rise to predicted light intensity , which can be compared to the true intensity , and an update in the energy matrix guess can then be made .",
    "most often , the iterative step will make use of eq  ( [ bvh ] ) to improve the guess of the energy matrix .",
    "our motivation for devising a new method for inferring tf - dna interactions was based on the following observations about the existing approaches :    * ( i ) the assumptions underlying the berg - von hippel equation that links pwms with energy matrices might not hold . *    in particular",
    ", the genomic background is _ not _ always simple , as has been amply demonstrated by failed attempts to identify transcription factor binding sites in _ plasmodium falciparum _",
    ", the malaria parasite ; this parasite has non - coding regions with a lot of statistical structure , including complicated repeats , and simple models of genomic background fail to capture these dependencies , leading to a failure in algorithms that exploit eq  ( [ bvh ] ) to search for binding sites @xcite .",
    "moreover the concentration of tfs in the experiment may be saturating for some sites , which is problematic for the original berg - von hippel formulation , but has been addressed by , e.g. ref  @xcite .    *",
    "( ii ) discarding most of the experimental data ( e.g. measurements that lie below the threshold of light intensity in the pbm example ) is wasteful . *",
    "the experimental observation that the tf _ does not _ bind in some intergenic region is in fact as informative as the observation that it does bind in certain other regions .",
    "in other words , these `` negative '' samples inform us about what the energy matrix can not be ( because with a wrong model , we could predict binding in those regions that indeed do not show any binding experimentally ) , and thus are informative about the model as well .    *",
    "( iii ) we do nt know the `` error model '' of the experiment .",
    "* for a principled , unbiased inference of any model from the data ( including tf energy models ) , we would have to write down the likelihood of the observed data given the model , @xmath366 . to do proper bayesian inference",
    ", we would then maximize this likelihood with respect to the model parameters ( e.g. the energy matrix ) .",
    "however , in most of the experiments , we have no idea about what form the error model  the probability @xmath30  has .",
    "that is because experiments such as binding arrays , microarrays etc usually involve many complicated biochemical and detection steps , such as hybridization , washing , sonication etc , and therefore there is no principled way of writing down the probability of raw experimental readout ( i.e. light intensity ) given that the tf is or is not bound . without the knowledge of @xmath30 and the subsequent inability to do proper bayesian inference ,",
    "most researchers have resorted to ad hoc approaches , such as setting thresholds . moreover",
    ", these ad hoc approaches usually contain many algorithmic details , involving data normalization and representation ( e.g. does one analyze light intensity , or log light intensity ) , that can strongly influence the results .",
    "we would like to reexamine the premise that unbiased inference is impossible without the explicit knowledge of @xmath30 .    *",
    "( iv ) analysis of the same tf using different methods often gives inconsistent results .",
    "*        as fig .",
    "[ f - pbmvschip ] shows , despite best efforts of the experimentalists to select regions that are true positives , the intersection of regions declared bound by pbm and chip - chip experiments is rather low .",
    "while such inconsistent results are not rare in the field , it is not clear how to interpret the inconsistency : as the experimental imprecision , difference in experimental conditions ( including the state of the yeast culture ) , biased inference of the bound regions , biological noise , etc .",
    "* ( v ) we would like to put proper error bars on any inferred model . *",
    "+ in a paper by kinney et al @xcite , we argued that some of these problems are related : for instance , if we could compensate properly for our lack of knowledge about the error model , perhaps the inferred binding sites from different experiments could be made consistent ; likewise , if we did not need to assume anything about the statistics of the background sequence , perhaps the existing experiments would reveal binding sites in _ plasmodium _ parasite . in the next section",
    ", we present an information - theoretic approach to modeling transcription factor  dna interactions that will address some of these concerns .",
    "we start by representing data from a typical high - throughput experiment in a new form .",
    "suppose that a high - throughput experiment probes sequence fragments @xmath367 .",
    "these fragments can be longer than the suspected binding site size , which we assume is of length @xmath129 ; for example , sequence fragments @xmath367 could be intergenic regions in yeast , as in ref .  @xcite .",
    "we do nt know where in these sequences the binding sites are , if they are present at all , or how many binding sites there might be for the tf of interest .",
    "the experiment provides us with a raw experimental readout that corresponds to each intergenic region . in protein - binding microarrays ,",
    "this is the light intensity level that is correlated with the probability that a fluorescently tagged tf is bound in that intergenic region .",
    "similarly , we can use the chip arrays .",
    "but the framework is more flexible : _ any quantity , either continuous or discrete , that is experimentally accessible and is thought to correlate with the binding of tf of interest , may be used ; this in principle includes a combination of such measured quantities_. to be concrete , consider a set of microarray experiments where expression levels of genes are probed at many different conditions .",
    "these results are then used as input to clustering , and genes are grouped into co - regulated clusters .",
    "for example , there is a group of genes that is determined by clustering to be in group @xmath368 .",
    "we can now assign to every intergenic region a value 0 , if the corresponding downstream gene is not in @xmath368 , and value 1 , if the corresponding gene is in @xmath368 . instead of pbm or chip experimental data ,",
    "in this case we would use the result of the clustering partition as the variable ( binary in this case ) that correlates with the presence or absence of a tf binding site .",
    "before we proceed , we will bin ( or discretize ) the data into a number of discrete bins , if the data is continuous .",
    "this discretization is in principle arbitrary , and for best results one should make a tradeoff between increasing the number of bins ( to increase the resolution of the method ) and the sample size ( so that the number of samples in each bin is large enough ) . in pbm experiments , for instance",
    ", the log light intensity levels are discretized into @xmath369 bins ( to show that the results will not depend on this discretization ) .",
    "the bins group together log light intensities that are similar .",
    "we will use this discretized data to estimate mutual information ; as shown in section  [ lec4 ] , mutual information is insensitive to monotonic transformations of data , and this is exactly what we want  our inference will be insensitive to whether we use log light intensity , raw light intensity , or any nonlinear function thereof .",
    "we have also mentioned that in the limit of large enough data set , the way we discretize does not influence the computed mutual information , so our method is robust with respect to this choice .    to summarize , the input for our analysis will be pairs of ( sequence , data bin ) , where sequences may or may not contain binding sites for the tf of interest , and the data is any experimentally determined quantity that is though to have a statistical dependence with the presence or absence of tf binding sites .",
    "in particular , after the discretization , our analysis does not even require the raw data values any longer , just the _ data bin _ into which the data was assigned on discretization .",
    "let us denote the input data @xmath370 mathematically as @xmath16 pairs indexed by @xmath276 pairs : @xmath371 , where @xmath367 are the sequences potentially containing the binding sites , and @xmath372 are the ( discrete ) bins associated with those sequences and summarizing the experimentally measured values that correlate with tf binding .",
    "we now explain the core of the argument on which our inference is based .",
    "we assume that the experimental results @xmath372 are some unknown function of the sequence @xmath373 , but the statistical dependence between the two can only be established through binding energy @xmath73 of tfs to sites in the sequence @xmath373 .",
    "suppose that there are many subsequences in @xmath373 of length @xmath129 , where the tf _ could _ bind . if i knew the correct energy matrix @xmath92 for the tf , i could evaluate the energy of the tf to bind onto each site in @xmath367 . in the simplest case , i could declare that if any of these binding energies is below some threshold , the tf will bind in that intergenic region ( at least once ) , and i would declare that intergenic region bound , @xmath374 .",
    "if there is no such sequence of length @xmath129 in @xmath367 , then i would declare the intergenic region unbound , @xmath375 , the matrices will be largely independent of these assumptions . here , concretely , a simple rule was used : apply @xmath92 to any site of length @xmath129 within the region @xmath367 . if the energy of binding is favorable , i.e. below threshold @xmath376 , declare that site bound , and declare the whole region bound , @xmath374",
    ". if none of the energies is below the threshold , the region is unbound , @xmath375 .",
    "the matrix @xmath92 can only be determined up to a scale , i.e. @xmath349 and @xmath377 , where @xmath3 is a positive scalar , are both equally good guesses ( in this setup it can be shown that the experimental data can not predict the absolute scale of the matrix in physical units of , say , joules ) .",
    "we can get rid of this arbitrariness by fixing the threshold for binding , @xmath378 . ] .",
    "formally , the argument we are making can be represented as follows : @xmath379 that is , the sequence determines the energy of binding ( that depends on the energy matrix @xmath92 which we would like to infer ) , and the energy determines whether the region is bound or not @xmath380 ; that _ alone _ determines the experimental data bin @xmath372 reflecting the measurement .",
    "there is no other statistical dependence between the sequence and the experimental data , _ on average _ , than through the binding energy ! with these remarks in mind ,",
    "a typical representation of a dataset might look as shown in fig .",
    "[ f - mitable ] .    .",
    "if we make a guess at the energy matrix @xmath92 , we can decide whether each intergenic region is bound or not ( see text ) , and assign @xmath380 to each region .",
    "in addition , each region has produced some experimental readout , that has been discretized and so each region is assigned to one of the bins @xmath381 ( maximum number of bins is 250 in this example ) .",
    "the table illustrates that there is some statistical dependence between the region being bound ( @xmath374 ) and being assigned into a bin corresponding to e.g. higher light intensities on the pbm chip ( higher corresponding bin number @xmath372 ) .",
    "this table can be constructed if some energy matrix @xmath92 is assumed , because @xmath382 is a function of sequences @xmath367 and @xmath92.,width=240 ]    if the experimental result depends only on binding , and the binding depends on the sequence through binding energy alone as in eq .",
    "( [ condind ] ) , we can formulate the following inference principle : @xmath383 where @xmath384 is the energy matrix that we are looking for , and argmax is returns that @xmath92 that maximizes the mutual information @xmath177 .",
    "let us now parse this equation in detail .",
    "we believe that the experimental results @xmath385 should be maximally dependent on whether the corresponding regions are bound or not , @xmath386 . to characterize the full statistical dependency without making any assumption about the probability distribution @xmath387 , we compute the mutual information @xmath388 . remember that this independence of any error model was one of our initial motivations . from a table like the one in fig .",
    "[ f - mitable ] , @xmath388 can be directly computed , by simply accumulating the joint probability distribution @xmath389 across all @xmath16 pairs ( sequence , data ) [ k=5812 in the example ] , and using eq .",
    "( [ mut2 ] ) to compute the information ] .",
    "information @xmath388 can be computed for any choice of the energy matrix @xmath92 .",
    "we should now search the space of all energy matrices ( @xmath390 parameters ) for that matrix @xmath384 that will maximize this information . while nontrivial , this search can be implemented using metropolis monte carlo ( mmc ) methods .",
    "this search does not only yield the best matrix @xmath384 , but _ an ensemble _  a solution set  of matrices , all of which explain the data almost equally well and yield the same value for information @xmath177 .",
    "we will not go into the details here beyond stressing that since we end up with a set of good solutions , we can compute how well constrained the energy matrix elements @xmath355 are and put rigorous error bars onto them .",
    "how do the results look like for the yeast abf1p example inferred from pbm data ?",
    "figure  [ f - pbmmx1 ] is reproduced from ref .",
    "@xcite , and it shows the inferred energy matrix and the error bars for each of the matrix elements .",
    "we see that most of the energy matrix elements are constrained very well by the data ; a pattern emerges where abf1p makes contact to the dna in two regions , with small ( but still significant ) energy contributions from the basepairs between the two regions .",
    "these results are broadly consistent with , but more precise than , previous energy models for abf1p .    , with hotter colors indicating larger energy matrix contributions , and darker colors smaller contributions .",
    "panel b ) shows the error bars on each of the energy matrix elements , @xmath391 .",
    "panel c ) plots the matrix elements vs their errorbars ( y axis ) , and also shows in the two example insets , the distribution of values for two particular energy matrix elements in the solution ensemble found by mmc optimization .",
    "here we looked for an energy matrix of length @xmath392 basepairs .",
    "the search can be repeated for @xmath393 to show that the core elements remain unchanged , and the same energy matrix is found each time .",
    "the inference can also be performed by splitting the total dataset ( 5812 sites ) into random halves , and showing that on each half consistent energy matrices are found , so that there is no overfitting [ not shown , c.f .",
    "@xcite].,width=336 ]     intergenic regions of yeast are categorized as bound @xmath374 or unbound @xmath375 by energy matrices in the solution set .",
    "plotted is the histogram of the `` hit fraction '' , @xmath394 , i.e. the average value of @xmath382 for each region across all solution energy matrices .",
    "the regions clearly separate into two classes : most of the regions are declared unbound ( hf@xmath395 ) by all energy matrices ( the histogram bar corresponding to hf@xmath396 would extend beyond 1500 counts in the plot , but is cut for clarity ) , and a smaller set of regions that is declared bound ( hf@xmath397 ) , by most of the energy matrices .",
    "panel b ) shows the histogram of raw experimental data in blue , the experimentalists threshold ( green line ) , and the _ inferred _ @xmath398 ( sigmoidally shaped scatterplot with errorbars ) . the sigmoidal shape has not been assumed , but is the result of our inference .",
    "panel c ) shows the energies assigned to sites of length @xmath129 in every intergenic region in _",
    "s. cerevisiae _",
    "( the yeast species on which the analysis was run ) vs the energies assigned to orthologous sites in a related yeast species , _ s bayanus_. those sites that are declared bound ( below threshold @xmath378 ) in _ s cerevisiae _ also have correspondingly low energies in the other yeast species , forming an island of points in the lower left corner of the plot . for sites above the threshold which are non - functional , the correlation between the energies in the two species is much weaker . , width=316 ]    figure  [ f - jbk ] shows that the resulting energy matrices unambiguously split all intergenic regions into those that are bound and those that are not .",
    "more surprisingly , as part of our results ( not as an assumption ! ) , we also learn @xmath398 , the probability that the site is bound given the experimental data bin , @xmath372 ; this quantity is related to the error model @xmath387 , which we did not want to assume a priori .",
    "this curve has a sigmoidal shape , showing that no single hard threshold ( as has traditionally been done ) will perfectly separate regions that are bound from those that are not .",
    "this finding also has biological implication ",
    "it is saying that there are both strong and weak binding sites , and some of the weakly bound sites are mixed into experimentally determined bins with regions that truly do nt contain binding sites .",
    "lastly , fig .",
    "[ f - jbk]c shows that our inferred binding energies are conserved across two yeast species despite significant difference in aligned sequences due to evolutionary distance .",
    "we find many more binding sites than the number inferred by ref .",
    "@xcite , where they set a very strict experimental threshold to avoid false positives .",
    "interestingly , we can run exactly the same analysis on the chip data by lee et al @xcite ; we find that the inferred binding sites from two different experimental assays performed by two separate experimental groups can be made consistent , unlike the discrepancy observed in direct region comparison , see fig .",
    "[ f - miexcomp ] .",
    "we think that this finding illustrates that proper inference can lead to more complete and consistent identification of binding sites , including the weak ones .        in conclusion ,",
    "let s comment on why mutual - information inference was able to provide us with good energy matrix models despite our inability to write down the likelihood ( or error model ) @xmath366 .",
    "the answer lies in the observation that with enough data , one can simultaneously infer this error model along with the energy matrix .",
    "there is a formal way to show the connection between mutual information inference of eq .",
    "( [ miinfer ] ) and the bayes maximum likelihood inference , and we point the reader to details of ref .",
    "the key point is that one can formulate the problem as maximum likelihood inference using an unknown error model @xmath387 and then average over all such error models with some prior ; in that case one obtains an `` error model averaged '' log likelihood @xmath399 for the data , and this turns to be directly related to the mutual information of eq  ( [ miinfer ] ) : @xmath400 ( irrelevant terms ) .",
    "thus a mathematical connection can be established between mutual information and bayesian inference .",
    "to summarize , a new method for inferring tf energy models from a wide variety of experimental data has been proposed and shown to bring various existing experiments into concordance .",
    "high - throughput datasets provide enough data  if _ all _ data is indeed used for inferrence and not ignored by arbitrary thresholds  to swamp the uncertainty introduced because of our ignorance of the real error model .",
    "it can be shown that this inference also works well when genomic background is complicated , as in ref .",
    "@xcite ; that reference also provides an online tool which uses the same framework to learn many tf energy models simultaneously across the genome .",
    "mutual information inference procedure does not rely on the relation between the position weight matrix ( pwm ) and the energy matrix , and thus does not require the validity of assumptions underlying the berg & von hippel argument @xcite .",
    "we conclude this lecture by briefly reviewing the work of kinney et al @xcite , that has combined the mutual - information inference with a new high - throughput deep - sequencing based approach , in order to * ( i ) * precisely quantify the contribution of each basepair in the regulatory sequence to the function ; and * ( ii ) * build detailed biophysical models of combinatorial regulation . in ref .",
    "@xcite , the authors decided to reexamine the regulatory region of lac operon , where both the crp transcriptional activator , and the rnap polymerase bind to regulate the expression of lac genes ; see fig .",
    "[ f - lac ] .",
    "the key to the experiment was to create a large library of plasmids that differ only in that the regulatory sequence of interest has been mutated , see fig .",
    "[ f - jbk2 ] ; this regulatory sequence controlled the expression level of gfp , which could easily be recorded in the experiment . the cells with different regulatory sequences @xmath367 drove various levels of fluorescence , that the experimenters sorted into 9 bins , @xmath372 .",
    "despite being seemingly very different from the pbm / chip setups described in the previous section , here too one is working with a large number ( @xmath401 per experiment ) of pairs of sequences and the experimental readouts , and an almost identical inference technique can be applied .",
    "first , one may ask directly about the mutual information @xmath402 , about the identity of the base pair @xmath403 at position @xmath404 in the mutated regulatory sequence , about the expression level @xmath405 of gfp , as measured by fluorescence activated cell sorting ( facs ) . this is a direct measure , without making any modeling assumptions , about how each base pair on its own affects expression ; see fig .",
    "[ f - jbk3 ] .     is shown , in bits , about the identity of a single nucleotide and the final grp fluorescence , together with the error bars . in the third row",
    "we see the zoom - in of the small information values .",
    "the method yields precise results with very small error bars ; the results are broadly consistent with what is known , but also show that some positions carry small , but significant information about promoter activity .",
    "panel b ) shows the same analysis performed when crp is not bound . within error bars ,",
    "most of the positions that are informative about expression with crp bound are now 0 , as expected .",
    ", width=288 ]    as fig .",
    "[ f - jbk3 ] shows , the method yields extremely precise _ information footprints _ that characterize the functional impact of every nucleotide on the promoter activity , using the mutual information measure .",
    "this method is clearly applicable to unknown regulatory regions if one wishes to quantitatively determine which nucleotides are functionally important .",
    "finally , it is possible to use the mutual - information inference to learn the energy matrices of the crp and rnap , @xmath406 and @xmath407 , and the possible energetic interaction between the two proteins . here",
    ", the interaction even helps in constraining the absolute energy scale of the energy models , so the binding energies can be expressed in physical units , as shown in fig .",
    "[ f - jbk4 ] . using a convincing series of information - theoretic arguments",
    ", the authors can compare how much information the sequence gives about the promoter activity @xmath408 ( this is computable directly from the data without any model ) , with the fraction of that information that is captured by any particular model  this can inform us how good any model is with respect to reality .",
    "they show that the thermodynamic model of combinatorial regulation , developed in line with the reasoning of section  [ lec2 ] , does an excellent job of accounting for the data , and that the models inferred using mutual - information inference outperform the models constructed using the berg & von hippel relation in eq .",
    "( [ bvh ] ) . for many other interesting details and controls",
    "we refer the reader to the original reference @xcite .    .",
    "the matrices in c ) are consistent with the separately learned matrices in a , b ) . due to the presence of cooperative interaction @xmath409 , it is possible to put absolute units on all energies .",
    "figure reproduced from ref .",
    "@xcite.,width=288 ]    hopefully these examples present a strong case for the usefulness of information - theoretic measures and methods , and demonstrate that inference should develop in step with advances in experimental techniques . in particular , the examples highlight the difference between traditional physics experiments in which the instruments can be calibrated and understood well enough for us to obtain a handle on @xmath366 , and quantitative biology , when such understanding is often lacking . if the latter case and when using biased or ad hoc inference methods , it is not clear that a larger dataset would actually lead to better models . on the other hand , principled methods can give a very detailed , quantitative and physical account of what is happening in the regulatory regions of the genome .",
    "the price for this performance is large required amount of data and computational time , but as the field progresses , those factors are becoming less and less important as practical constraints .      a very similar method has been devised to probe the behavior of sensory neurons . as we mentioned in section  [ lec2 ] ,",
    "sensory neurons are often described in terms of a linear - nonlinear ( ln ) model : a stimulus , e.g. a movie displayed to a retinal ganglion cell , is convolved first with a linear kernel @xmath149 that parametrizes the preference of the neuron for some linear feature ( dimension ) in a normally highly - dimensional stimulus .",
    "the result of this convolution is then passed through a nonlinear function that yields the probability rate for generating a spike .",
    "as discussed , various methods have been developed to infer the linear filter @xmath149 from traditional experimental setups , in which a large number of stimulus snippets @xmath367 are presented , and the spike / no - spike @xmath372 is recorded .",
    "note the analogy with gene regulation : we have stimulus of high dimensionality ( sequence or a movie ) , experimental output ( gfp level or spikes ) , we are looking for a linear function on the stimulus space ( energy matrix @xmath92 or linear kernel @xmath149 ) , and we do nt know the probabilistic model of how the output is generated given the product of stimulus with the kernel ( or sequence with the energy matrix ) .    if we knew the nonlinearity that the neuron implements and its likelihood function for determining when it spikes , we could infer the linear kernel @xmath149 by writing down the probability of data given the model , and do bayesian inference of the model .",
    "but just as in the case of transcriptional regulation , these quantities too are often unknown . a method called _ maximally informative dimensions _ that finds the linear kernel @xmath149 by maximizing",
    "the mutual information between the stimulus projection and the spike trains has been developed and successfully applied in several sensory systems @xcite .",
    "one of the most pressing questions in systems biology today deals with deciphering the structure of regulatory networks from data .",
    "the traditional way in which such networks were dissected was through genetic experiments , where painstaking experimentation and mutagenic studies helped deconstruct the networks one link at a time . with the advent of high - throughput experiments , such as microarrays , chip and protein binding arrays , as well as simultaneous stains and fluorescent protein fusions etc , the need arose for computational tools that would be able to infer networks from such datasets directly .",
    "apart from being high - throughput , some of these techniques have opened up another window : instead of looking at bunches of cells mixed together ( like in microarrays ) , they are enabling experimenters to record _ simultaneous _ expression or activation levels of the nodes of a single biological network , without pooling over many `` copies '' of such networks ( e.g. extracted from different cells ) . in physics terms",
    ", this means that not only are the mean activation or expression levels indicative of the network activity , but so are the correlated fluctuations among the nodes . to make use of this fact",
    ", we are looking for physical models that include modeling of the ( correlated ) noise .",
    "the structure of fluctuations can potentially tell us a lot about the wiring diagram of the system .",
    "the simplest  and still most widely used ",
    "approaches for detecting network structure rely on studying correlations directly . in a typical microarray experiment ,",
    "the cell cultures are exposed to various external perturbations and the mrna levels for genes across perturbations are recorded .",
    "then a pairwise correlation matrix is computed across the perturbations , yielding a @xmath410 pairwise similarity matrix between @xmath12 genes ( generalizations are possible by measuring mutual information instead of correlation coefficients ) .",
    "such a similarity matrix can then be used as an input to , for example , clustering .",
    "clustering is one of the simplest and most scalable methods of understanding the collective behavior of a network .",
    "consider the information matrix of fig .",
    "[ f - minolan ] as a matrix of weights between the nodes of a graph : the graph has strongly connected components that correspond to clusters ( blocks on the diagonal of the information matrix ) and these blocks are weakly coupled to other blocks .",
    "one might even threshold the information matrix and draw binary links in the graph whenever the similarity measure exceeds the threshold value , and some researchers have indeed taken this approach .",
    "clustering turns out to be an extremely powerful approach for several reasons .",
    "firstly , in gene regulation we know that out of the whole set of genes , the total number of genes that regulate other genes  so called _ transcription factors _  is on the order of a few percent .",
    "although this , much smaller , group of genes with regulatory power could conspire combinatorially and still regulate every other gene in a complicated individual fashion , many genes need to be up- or down - regulated together , because they act as enzymes in connected reaction pathways or they need to be active in a specific tissue . this _ coregulation _ is the basis for the success of the clustering approach : coregulated genes cluster and cluster members are assumed to be regulated in identical ways by their ( one or few ) transcription factor(s ) .",
    "although clustering is clearly productive as a first step in understanding genetic regulatory networks , it is not a generative model of the network .",
    "it reorders the nodes so that the structure ( hopefully ) becomes apparent , but does not give any prescription about _ how _ the activity of one gene influences the activity of the others  the only input to the clustering procedure is the mutual information , and we explicitly stated that information measures dependency without revealing anything about underlying functional relationships .",
    "moreover , as we will soon see , understanding that network elements @xmath411 and @xmath412 are correlated , which is the basis of clustering , tells us nothing about whether @xmath411 is really directly influencing @xmath412 ; in particular , in gene regulation , the genes are coregulated and are therefore coexpressed , and correlation does not imply causation or direct interaction . despite being very practical , clustering leaves too many questions unanswered if we want to understand network behavior .      can we disentangle the mesh of correlations and separate the correlations caused by real underlying interactions from the correlations induced indirectly by other interactions , as is illustrated in fig .",
    "[ c2_i3 ] ?    to start , we recall a classic problem in statistical physics : we are given a lattice of ising spins ( binary variables ) , and some specification of exchange couplings ( interactions )  perhaps between nearest neighbor only  and the exercise requires us to find the equilibrium correlation function between the spins , i.e.  @xmath413 . in our case however , we will be dealing with network `` reverse engineering . ''",
    "the exchange interactions themselves will be unknown , yet we will observe a mesh of correlations .",
    "the problem will then be to compute the exchange interactions from the measured correlations , with the hope of finding a network defined by the interactions to be _ simpler _",
    "( for instance sparser ) than the network of correlations .",
    "let us formulate the problem more precisely .",
    "the network consists of @xmath12 nodes with activities @xmath411 , @xmath414 , which , we will for now assume , can take on only two values , @xmath415 .",
    "an experimental snapshot of the network activity is then described by a vector , @xmath416 .",
    "our data consist of patterns @xmath417 , i.e.  there are a total of @xmath33 simultaneous measurements of the activities at all nodes , while the network is in some stationary state .",
    "these samples can be thought of as `` instantaneous '' snapshots of the system or , in simulation , draws made during a monte carlo sampling run . from the samples we can estimate the moments of @xmath7 at successively increasing orders : first order moments are @xmath12 mean activity values , @xmath418 ; second moments are @xmath419 correlations , @xmath420 ; and so on .",
    "because the system is noisy , there will be fluctuations around the stationary state and not all @xmath33 patterns are going to be equal .",
    "we expect some patterns to be more likely than the others , and the full description of the system in equilibrium must be contained in a joint probability distribution , @xmath421 . getting a handle on this distribution",
    "is therefore our final goal , and as we will soon discover , computing successive approximations to it will give us the desired interactions that underlie the observed correlations .     modulates the activity of @xmath412 and @xmath422 through some microscopic mechanism ( denoted by thick lines ) .",
    "we can expect to observe strong correlations between @xmath411 and @xmath412 , and between @xmath411 and @xmath422 due to this direct influence . on the contrary , @xmath412 and @xmath422",
    "are not directly coupled , but can still show significant correlation ( dashed line ) because of common control by @xmath411 .",
    ", width=192 ]    except for a very small number of network nodes there is no hope of directly sampling the distribution from the data .",
    "its size grows exponentially in @xmath12 and for a modest network of 10 binary nodes we would generally need to estimate @xmath423 parameters . to proceed",
    ", we clearly need a simplifying principle .",
    "a commonly used procedure is called bayesian network reconstruction @xcite , and it is a method from the more general class of graphical models .",
    "one starts by assuming a specific ( initial ) factorization of the joint probability distribution over all nodes and represents it as a graph @xmath424 , as in fig [ c2_i4 ] .",
    "remembering that the activities are discrete variables , all conditional distributions in the factorization can be represented as probability tables with unknown entries that need to be fit from the data .",
    "such fitting procedure can be performed in many ways , and one can evaluate the likelihood of the fit @xmath425-th step , we are considering graph @xmath426 , hence the index . ] .",
    "of course , we have no prior knowledge of what the correct graph factorization of the initial distribution is , therefore a procedure is devised that wanders in the space of possible graph topologies and tries a likelihood on each , producing a sequence @xmath427 .",
    "the complexity of each graph , e.g.  the number of links , is penalized and combined together with the fit likelihood into a scoring function .",
    "the goal is to find the factorization of the probability distribution with the best score .",
    "presumably , we will then have discovered a simple graph that fits the data well .",
    "there have been successful network reconstructions using this approach @xcite .",
    "the key simplifying assumption that makes this approach feasible is that the graph of interactions is sparse , i.e.  that there are many fewer real than potential interactions .",
    "given such sparsity , the factorized probability distribution will have a far smaller number of unknown parameters than the full joint distribution , and there will be reasonable hope of fitting them from the data .",
    "the method allows interactions of arbitrary complexity ( as many arrows converging on a single node as possible ) , but has some drawbacks .",
    "firstly , there is an exploding number of graph topologies over @xmath12 elements , and no hope in exhaustively trying all of them ; whatever algorithm one devises to explore the space of topologies , it can get stuck in local extrema of the scoring function .",
    "secondly , due to computational constraints not all kinds of graphs can be explored ",
    "usually one has to exclude loops and this is a big handicap for biological systems where feedback plays a very important role . finally ,",
    "because we are looking for a tradeoff between the best likelihood fit and the simplicity of the model , we have to ( arbitrarily ) decide how to penalize complex topologies .",
    "it is not _ a priori _ clear that one should simply minimize the number of links and disregard other features of the graph .",
    "in particular , we expect that for systems , in which collective effects are driven by the presence of weak interactions between lots of pairs , bayesian method will perform poorly .",
    "implies that the joint probability distribution can be written as follows : @xmath428 .",
    "this form has @xmath429 free parameters in case of binary variables ( remember that conditional probability distributions are normalized ) , and is much simpler than the completely arbitrary @xmath430 , that for 5 binary nodes would have @xmath431 free parameters . , width=192 ]    .",
    "[ c2_i4 ]      here we will try to take a radically different route to the solution , motivated by inverse problems in statistical mechanics .",
    "this methodology has been applied successfully to a diverse set of biological interacting networks , such as neurons , human immune system , and signaling networks @xcite ; the full analysis of the dataset presented here can be found in ref @xcite .",
    "we start with the realization that with a limited number of samples , @xmath33 , we can successfully estimate several lowest - order moments of the sought - for joint distribution @xmath432 that generated the data , for example , the means @xmath433 and covariances @xmath434 , or , in general , a set of mean values of some of the statistics of the unknown distribution , also called its `` operators , '' @xmath435 ( which can be arbitrary functions of @xmath7 ) . for any reasonable choice of the operators",
    "there is an infinite number of joint distributions over @xmath12 elements with the same mean operator values .",
    "nevertheless , there is only one distribution that also has maximum entropy , i.e.  there is one distribution that is _ as random as possible _ but still satisfies those statistics that have been measured in an experiment .",
    "this is the distribution that we would like to find , and the maximum entropy principle embodies the idea that any structure ( or constraint ) in the distribution has to be induced by the measurement ( and not by explicit or hidden assumptions on our part ) . in other words , we will approximate the true distribution @xmath432 that we can not measure in full ( but can estimate some of its statistics @xmath436 ) , with the _ maximum entropy distribution _ that is as random as possible but matches the true distribution in the values of all of the measured statistics .",
    "formally , we are looking for the extremum of the following functional : @xmath437&=&s[p(\\vec{\\sigma } ) ] - \\sum_\\mu g_\\mu \\langle \\hat{o}_\\mu(\\vec{\\sigma } ) \\rangle - \\lambda \\int d\\vec{\\sigma}\\,p(\\vec{\\sigma})\\nonumber\\\\ & = & -\\int d\\vec{\\sigma}\\,p(\\vec{\\sigma } ) \\log_2 p(\\vec{\\sigma } ) -   \\label{c2_mef}\\\\ & -&\\sum_\\mu g_\\mu \\int d\\vec{\\sigma}\\,p(\\vec{\\sigma } )   \\hat{o}_\\mu(\\vec{\\sigma } )   - \\lambda \\int d\\vec{\\sigma}\\,p(\\vec{\\sigma}).\\nonumber\\end{aligned}\\ ] ] the first term is the entropy of the distribution , and there are @xmath82 constraints enforced by their lagrange multipliers @xmath438 : @xmath439 such that the average values of the operators over the sought - after distribution @xmath440 are equal to the averages over data patterns , @xmath441 .",
    "the lagrange multiplier @xmath442 enforces the normalization of the distribution .",
    "it is easy to take the variation in eq ( [ c2_mef ] ) and write the explicit form for the maximum entropy solution : @xmath443}. \\label{c2_mem}\\ ] ] we call eq ( [ c2_mem ] ) the maximum entropy distribution with constraints @xmath444 .",
    "operators that constrain the distribution can be arbitrary , but we can gain further insight by restricting ourselves to the moments of increasing orders ( the activity variables are still binary for simplicity ) . if one chooses @xmath445 , then the mean values , @xmath446 , are constrained , and the maximum entropy distribution is the factor distribution : @xmath447 this factor distribution is easy to compute , but it does not include any interactions ",
    "each element behaves in an independent fashion ( similar to the mean - field theories in physics ) .",
    "we could continue constraining the maximum entropy distribution with correlation functions of higher and higher orders .",
    "if we were to fix both mean values and two - point correlations , the resulting distribution , eq ( [ c2_mem ] ) , would have an ising form : @xmath448 this is the simplest distribution that contains pairwise interactions between the network elements .",
    "constraining the three - point correlations would induce a new term in the exponent of the form @xmath449 .",
    "there is clearly a `` ladder , '' where higher and higher order constraints are imposed on the distribution , and as a result , better and better maximum entropy approximations are constructed .",
    "let us call , then , @xmath450 a maximum entropy distribution consistent with correlations of order @xmath4 and smaller , in line with our notation for the factor distribution , @xmath451 . in an @xmath12-body system ,",
    "the highest order of correlation is @xmath12 , and @xmath452 must therefore be the exact joint distribution  at this order our approximation _ is _ the exact solution , with entropy equal to @xmath453 $ ] . in ref",
    "@xcite it has been shown that this sequence of ever better maximum entropy approximations defines a unique decomposition of multi - information of eq  ( [ multii ] ) : @xmath454&=&\\sum_{k=2}^{n } i^{(k ) } \\\\ i^{(k)}&=&s[p^{(k-1)}(\\vec{\\sigma})]-s[p^{(k)}(\\vec{\\sigma } ) ] .",
    "\\label{c2_multiicon}\\end{aligned}\\ ] ] in words , the _ connected information of order k _ , @xmath455 , is the difference of the entropies of the maximum entropy distribution consistent with correlations of order @xmath456 and one higher order . for example , connected information of the second order is the reduction of the entropy due to pairwise interactions ; one creates the best factor ( independent ) model for the data and the best pairwise ( two - body ising ) model for the data , and compares their entropies to see how much of the total structure in the joint distribution has been explained by purely pairwise terms .      how do we use this framework to model real networks ?",
    "once we collected the measured correlations , we would postulate the maximum entropy model of eq ( [ c2_mem ] ) and solve the equations that determine all couplings , eq ( [ c2_const ] ) ; mathematically , we need to find @xmath457 that solve the following equations : @xmath458 where the expectation values on the right - hand side are measured in the dataset @xmath370 .",
    "this procedure yields two important results : * ( i ) * since we have a generative model of the data , i.e. the probability distribution , we can calculate and predict any expectation value ( especially of those statistics that were not used as constraints ) , and compare it to experiment ; * ( ii ) * we can examine the couplings @xmath459 , conjugate to the constrained operators , and interpret these as _ interactions _ that cause and explain the observed correlations .    as is done in bayesian network reconstruction , once we have computed the couplings , we can draw a graphical model of the network with a link for each nonzero coupling @xmath19 connecting the elements @xmath411 and @xmath412 would correspond to the distribution @xmath460 , where @xmath461 in the maximum entropy picture . ] .",
    "these weighted links are undirected as there is generally no way of determining the `` direction '' of the interactions from an equilibrium model .",
    "assumptions underlying maximum entropy reconstruction are quite different from its bayesian relative : whereas in the latter case we assume sparse a network of ( arbitrarily complex ) interactions , we assume an arbitrarily dense network of simple ( low order , e.g.  pairwise or triplet ) interactions in the former case . to explain all @xmath419 pairwise correlations one needs the full matrix of @xmath419 exchange couplings @xmath19 . ] , and therefore no discrete topology on the graph is assumed _ a priori_. there is hence no problem of searching and scoring the space of topologies , no exclusion of graphs that include loops , and reduced dependence on the implementation details of the algorithm .",
    "the drawback is the _ ab initio _ exclusion of complex irreducible interactions between many nodes .",
    "clearly , the real question to ask is about the approximation regime that is more suitable to biological systems , if a general answer exists at all .    in practice , unfortunately , the maximum entropy network reconstruction is made difficult by two problems .",
    "one is technical  solving coupling eqs ( [ c2_const ] ) is very hard .",
    "in essence , one needs to solve @xmath462 where @xmath463 is the partition function of the maximum entropy distribution in eq ( [ c2_mem ] ) .",
    "this set of equations is both nonlinear in couplings @xmath43 and requires the evaluation of the partition function , @xmath464 , or effectively a complete solution of the statistical mechanics problem .",
    "the other problem concerns the identification of the nodes that are observed in the experiment .",
    "first , one will usually be able to take measurements of only a small subset of the nodes comprising the network and we need to be concerned about how the hidden nodes influence models of visible nodes .",
    "second , even if all nodes were identified , there is an issue of `` coarse - graining . ''",
    "is a node with two states really an elementary , physical object that only has two states ( a protein with two phosphorylation states ) , or is it in itself a complex with many states , but for which a two - state model might ( or not ) be a valid approximation ?",
    "we do not have time to systematically address these issues in the lecture notes , but do wish to point them out .",
    "in which the network operates ) .",
    "these chemical interventions change the state of the whole network by locking the activity of the nodes on which they act into activated ( green ) or deactivated ( red ) state .",
    "chemicals 0 , 1 and 2 represent naturally occurring stimulatory agents ; 0 and 1 are present in all @xmath29 , while 2 is present in @xmath465 .",
    "the arrows represent experimentally verified chemical interactions ; there are a number of known interactions through intermediaries that are known , but not plotted .",
    "gray nodes were not observed in the experiment . ]      here we present a maximum - entropy - based approach to biochemical network reconstruction following the steps outlined in previously .",
    "we tackle these questions on the set of 11 interacting proteins and phospholipids ( jointly referred to as _",
    "biomolecules _ here ) in a signaling network of human primary immune system t cells .",
    "we use data from ref @xcite , where approximately 600 single - cell measurements of the activity level of biomolecules have been made for each of the 9 available conditions @xmath29 using flourescent cell cytometry ; this dataset has already been presented in section  [ lec5 ] . the network has been studied in detail and fig .",
    "[ f_mapk ] shows the conventionally accepted interactions , placing the observed proteins into their biological context .",
    "we will assume that , given a set of @xmath466 network nodes , their interactions can be well - described as occurring only between pairs or perhaps triplets , and not as combinatorial interactions involving quadruplets or larger groups .",
    "we ll assess the validity of this assumption at the end of the lecture ; detailed checks are presented in ref @xcite .    a typical experiment to which maximum - entropy network reconstruction can be applied will yield a large number of simultaneous observations of @xmath12 real - valued activation levels for each external stimulus . as a first step in the analysis , we discretize the data into two binary levels .",
    "we illustrate the maximum entropy reconstruction by focusing on each of the nine experimental conditions separately , and attempt to address the questions presented above .",
    "it is possible to formulate maximum entropy problem such that the network reconstruction takes advantage of all experimental conditions simultaneously ; for details see ref @xcite .",
    "the data collected for conditions 1 and 2 describe the activation levels of 11 biomolecules when the cells are exposed to their natural stimulatory signals .",
    "if we focus on each of the two conditions separately , we will be dealing with draws from two stationary distributions .",
    "we first discretize separately the data in each condition , and end up with 11 bit binary words that represent fluctuations around the steady state in that condition . because the nodes are functionally connected , the fluctuations are not independent , and must reflect local couplings between nodes near the given steady state .",
    "can we learn something from the correlated fluctuations in the activities ?",
    "having quantized the data into two levels and calculated the correlations and mean values , we write down the form of maximum entropy distribution consistent with these operators ; to be consistent with physics conventions , let s write @xmath467 , such that @xmath468 ( @xmath469 denotes the `` off '' state and @xmath470 denotes the `` on '' state ) : @xmath471 we proceed to calculate the _ interaction map _ @xmath19 and the biases @xmath472 that explain the measured observables [ eq [ ccsol ] ] , by using a numerical nonlinear equation solver and the problem is convex . ] .",
    "( color map ) and biases @xmath472 ( blue line ) for all external conditions @xmath473 , proceeding top down , left to right , computed ( both quantization and maximum entropy reconstruction ) separately for each condition .",
    "all interactions @xmath19 are drawn on the same scale , with red color indicating positive and green color indicating negative couplings .",
    "conditions 1 and 2 represent cells exposed to the naturally occurring stimulatory chemical signals ; other conditions represent environments where `` intervention '' chemicals  which are supposed to lock the activity states of certain nodes to either `` on '' or `` off ''  have been added to the stimulatory chemicals of condition 1 . ]",
    "figure [ fig_pn2 ] shows reconstructed interaction maps @xmath19 and biases for each condition s data quantized and analyzed separately that we compute simply reflect the overall bias of the , e.g. , node @xmath474 to tend towards -1 vs 1 .",
    "this is not really a property of the data , but of where we draw the discretization thresholds ; this is in contrast to the interactions @xmath19 which truly reflect the interactions in the data . ] .",
    "interestingly , both condition 1 and 2 exhibit a similar pattern of interactions , with those of condition 1 being a subset of condition 2 ; moreover they also agree with the conventional map of interactions in fig .",
    "[ f_mapk ] , except for the interaction between 10 and 11 ( p38 , jnk ) in condition 2 .",
    "a possible explanation for this interaction is the cross - talk in the mapkk pathway upstream of p38 and jnk : unobserved biomolecules that couple pairs of observed proteins would induce effective interactions between them .",
    "in general , the interaction matrices are sparse , and most of the small coupling constants can be set to zero with minimal change to the distribution ( not shown ) , i.e.  one would need on the order of 70 samples to distinguish the full maximum entropy from the pruned distribution . ] .",
    "note again that we are looking only at fluctuations around a naturally stimulated steady state .",
    "these fluctuations are much smaller then those induced by intervening chemicals , which is presumably why we detect only a subset of full interactions .    ) ] .",
    "the blue ( green ) segment represents the information of the second ( third ) order , @xmath475 $ ] , of eq ( [ c2_multiicon ] ) .",
    "the error bars are entropy estimation errors from the _ direct _ estimation obtained by 100 repeated reestimations @xcite . ]    how much of the complexity of the true distribution is captured by the maximum entropy approximation ? to answer this question we look at the fraction of the multi - information of the real distribution that is captured by the pairwise model . as fig .",
    "[ fig_info ] demonstrates , in case of condition 2 it recovers almost all of the 2.8 bits of total information ; for condition 1 , however , the fraction is around 70 percent out of the total of 1.5 bits .",
    "a test of the pairwise model involves comparing the predictions about connected three - point correlations @xmath476 with values estimated from the data , as shown in fig .",
    "[ fig_threepoint ] .",
    "thee - point statistics have not been constrained by construction in our model , and are therefore a real prediction of the maximum - entropy distribution .",
    "as expected , the match between predictions and measurement is good in condition 2 ( not shown ) , while for condition 1 we see a single three - point predicted correlation deviating strongly from its measured value .",
    "the corresponding biomolecules are @xmath477 , @xmath478 and @xmath479 , namely plc@xmath480 , pip2 and pip3 , and they are suspected to form a feedback loop [ fig [ f_mapk ] ] . to ascertain that it is not only the observed correlation , but actually a true triplet interaction between the molecules that generates the discrepancy , we can build a new maximum - entropy model consistent with three - point marginals . the corresponding distribution has the following form : @xmath481",
    "when we solve for the unknown @xmath482 in the distribution of eq ( [ eq_triplet ] ) , the largest three - point interaction term is @xmath483 .",
    "moreover , in order to convincingly show that it really is @xmath483 that fixes the offending three - point correlation ( as opposed to all other triplet degrees of freedom in eq ( [ eq_triplet ] ) ) , we construct yet another maximum entropy model : a pairwise ising system that in addition to all pairwise correlations constrains exactly one three - point marginal , @xmath484 , and has a single three - point coupling , @xmath483 .",
    "the agreement between prediction and observations is then restored up to third - order in correlations , at the cost of one additional underlying interaction .",
    "experimentally it is also known that plc@xmath480 hydrolyses its substrate pip2 to produce pip3 ; furthermore it is suspected that pip3 can recruit plc@xmath480 . the example analysis presented in this lecture sweeps a lot of checks and details under the rug in order for the lecture to remain straightforward ; for details see ref @xcite .        in summary",
    ", we believe that the maximum - entropy network reconstruction procedure offers a viable alternative to bayesian network reconstruction . the theoretical foundation provides a way of decomposing the total information of a given distribution into a sum of positive terms [ eq  ( [ c2_multiicon ] ) ] , each of which indicates the extent to which maximum - entropy models incorporating successively higher order marginals recover the total complexity @xcite .",
    "a failure to account for the total information with a simple model is diagnostic of complexity being unaccounted for in the model ; to pinpoint the problem , one compares the prediction and measurement of next order correlations ; hopefully , the failure is localized and not distributed through the network .",
    "if this is the case and fixing the failure requires the introduction of a single new interaction , we might believe that we have learned something new about the system . in the presented example of the map cascade , the pairwise model accounted very well for data in condition @xmath465 , and less well in @xmath485 ; but even in the latter case , an addition of a single combinatorial three - point interaction has lead to a considerably improved model .",
    "more importantly , the analysis approach is not good for a single system only , but is a principled framework that can include systematically more and more complexity until the data can be accounted for .    in general , principled methods for inferring network structure from the data",
    "are not yet widely used ; part of the reason is that the power of these methods ultimately derives from the quality of the measurements .",
    "if the experimental noise levels swamp the intrinsic noise of the regulatory process , then the benefits of observing the correlated fluctuations in the system are lost . in signaling pathways and genetic regulation",
    "the network reconstruction procedures deployed to date have mostly been technical demonstrations that the approach is possible or feasible , and its correctness was judged by comparison to a manually curated `` gold standard '' network , assembled from the literature .      in the case of the neural networks in the retina ,",
    "true new insight about how the network works was provided by maximum - entropy models @xcite .",
    "recordings of neural activities there have consistently shown that any pair of neurons in close physical proximity in the retina has activities that are weakly , but statistically significantly correlated ( i.e. the average correlation coefficients in pairs of neural spike trains were @xmath486 ) .",
    "it was usually assumed that this meant that correlations are a small effect and can safely be neglected , leading to an interpretation that separate retinal ganglion cells are independent encoders of information about the light in the visual field .",
    "however , when looking at larger and larger groups of neurons together ( not just pairs ) , it became increasingly clear that the assumption of neural independence leads to worse and worse predictions about how groups should behave in comparison to the experiments ; at groups comprising @xmath487 neurons the mismatch was extremely large .    ref .",
    "@xcite proceeded to fit maximum entropy models with pairwise interactions to groups of up to 15 neurons .",
    "the resulting models accounted for data very well , leading to a reinterpretation of the neural behavior , where a dense network of weak interactions induces strong effects on how groups or populations of neurons behave .",
    "these analyses were later extended to groups of 40 neurons , and analogies could be made between the behavior of these inferred networks and the theoretical models of frustrated collective behaviors ( spin glasses ) in physics @xcite .",
    "in the last lecture , we will seriously consider the idea that the _ function of biological regulatory networks is to transmit information_. armed with the mathematical concept of information introduced in section  [ lec4 ] , we will be able to formalize the notion that a transcription factor present at concentration @xmath39 drives a set of downstream genes , @xmath336 , and that the expression levels of these genes therefore jointly carry information about @xmath39 .",
    "we will argue that there exist certain regulatory wiring diagrams for the network @xmath488 along with the associated regulatory parameters ( such as interaction strengths ) , which increase , or even maximize , the information transmission between the transcription factor and its regulatory targets .",
    "if we believe that the ability to transmit information is under positive selection , then evolution might drive real regulatory networks towards such maxima .",
    "we end by proposing that such an optimization principle could be a good candidate for a `` design principle '' for biological information processing networks .",
    "we will use measurements from early _ drosophila _ development to illustrate these ideas .      after fertilization",
    ", interesting processes are taking place in the ellipsoidally shaped egg , about half a millimeter in length , of the fruit fly .",
    "a single nucleus undergoes 14 rounds of nuclear divisions , before large - scale spatial rearrangements , easily observed under the microscope , start happening approximately 3 hours after fertilization . during these first hours , all nuclei are floating in a shared pool of cytoplasm , in a structure that is known as a syncytium ; only at division cycle 14 do individual nuclei cellularize .    in a groundbreaking series of genetic experiments",
    ", researchers have shown that during these early developmental stages when all nuclei look identical and no differentiated structures are visible , important cell - fate determination steps are already taking place .",
    "looking along the long axis of the ellipsoidal egg , known as the ap ( anterior - posterior ) axis , one can see about 100 rows of nuclei at cell cycle 14 .",
    "these nuclei express proteins ( mostly transcription factors ) that will confer cell fate : nuclei belonging to various spatial domains of the embryo express specific combinations of genes that will lead these nuclei to become precursors of different tissues .",
    "stainings for relevant transcription factors have shown a remarkable degree of precision with which the spatial domain boundaries are drawn in each single embryo , and a stunning reproducibility in positioning of these domains between embryos .",
    "although probably a slight overgeneralization , we can say that at the end of cell cycle 14 , along the ap axis , each row of nuclei reliably and reproducibly expresses a gene expression pattern that is characteristic of that row only  in other words , the nuclei have unique _ identities _ encoded by expression levels of developmental tfs along the long axis of the embryo .",
    "decades of research have focused on the following questions about early development , with the hope that what is learned in _ drosophila _ will shed light on how development and cell differentiation proceed in general : * ( i ) * how are the spatial domains established ?",
    "what are the inputs that break the initial symmetry where all nuclei start out in the same state with the same genetic material ? *",
    "( ii ) * what is the wiring diagram of a network that takes the input information and processes it to the point where the nuclei have their identity encoded in the expression pattern of late developmental genes ? * ( iii ) * what is responsible for the precision and reproducibility of cell fate determination ?",
    "what are the limits to this precision ?",
    "are there mechanisms that confer robustness to certain environmental fluctuations , such as natural variation in temperature or physical size of the egg ? *",
    "( iv ) * what are the molecular mechanisms of regulation and cross - regulation implicated in the developmental network ? * ( v ) * what are the mechanisms that allow the signals to propagate spatially in the developing egg and that coordinate the response of different nuclei , such that e.g. the expression domains are not `` noisy '' or jagged ?    the answers to some of these questions are certainly known qualitatively , although we are still trying to make the models and measurements fit quantitatively .",
    "briefly , the mother breaks the symmetry by depositing sources of so - called maternal _ morphogens _ , or diffusible transcription factors , at key points of the embryo . for example , the source mrna for the bicoid protein that was discussed in section  [ lec3 ] , is positioned at the anterior pole of the embryo .",
    "there , mrna is translated into protein , which diffuses along the ap axis and is continuously degraded , establishing a steady - state concentration profile along the ap axis which is well - fit by an exponential : @xmath489 where @xmath179 is the distance on the ap axis measured from the anterior pole and @xmath490 ( and @xmath129 is the total length of the embryo ) .",
    "this spatial gradient is a chemical coordinate system : it is thought that each nucleus can read off the local concentration of bicoid ( and other morphogens ) , and based on these inputs , drive the expression of the second layer of developmental genes ( called the gap genes , which we denote by @xmath21 ) ; these in turn lead to ever more refined spatial patterns of gene expression that ultimately generate the cell fate specification precise to a single - nuclear row .",
    "let s attempt to put together all that we have learned up to now about gene regulation , noise in gene regulation and information theory .",
    "on one hand we can make a simple back - of - the - envelope calculation : if there are 100 distinguishable states of gene expression along the ap axis responsible for 100 distinct rows of nuclei , some mechanism must have delivered @xmath491 bits of information to the nuclei . that s the minimum amount of information needed to make a decision about the cell fate along the ap axis .",
    "similar patterning mechanisms also act along the other axes of the embryo , and if each of the 6000 nuclei at cell cycle 14 were uniquely determined , these systems together would have to deliver about 13 bits of information .",
    "we also know something about the information flow in genetic regulatory networks , and we can start by asking not how much information the nuclei need , but how much can be delivered .",
    "we have studied how bicoid regulates one of the gap genes , hunchback , in sections  [ lec2 ] and [ lec3 ] .",
    "we will first take a look at this single regulatory element and ask if , given the measured noise , the element is used optimally as part of the regulatory network .",
    "then we will generalize by assuming that @xmath488 , i.e. that bicoid input @xmath39 regulates a set of ( possibly interacting ) gap genes @xmath21 .",
    "the noise in gene expression was discussed in section  [ lec3 ] for the regulation of hunchback by bicoid ; if that can be taken as typical for other elements of the network , we can indeed compute @xmath492 and ask if that quantity can approach the @xmath493 bits of information that is needed on theoretical grounds .      by simultaneously observing the concentrations of bicoid ( @xmath39 ) and hunchback ( @xmath43 ) across the nuclei of an embryo",
    ", one can sample the joint distribution @xmath284 , see fig .",
    "[ f - droso - ap ] .",
    "usually it was assumed that hunchback provides a sharp , step - like response to its input , bicoid ; mathematically , this would mean that the bcd / hb input / output relation is switch - like , with an `` on '' and an `` off '' state , yielding information transmission capacities of about 1 bit . however , is this really the case ?",
    "using our estimation methods from section  [ lec4 ] we can measure directly how much information bicoid @xmath39 and hunchback @xmath43 carry about each other . the result @xmath494 bits , where the error bar is computed across 9 embryos .",
    "this is an experimentally determined quantity , and the errors ( apart from the estimation bias ) are related mostly to our ability to fairly sample the distribution @xmath284 across the ensemble of nuclei .",
    "our sampling is not complete because a single microscope view only records about a quarter of all nuclei , but we believe that that sampling is not very biased . another point to have in mind is that the computation of @xmath294 reflects all statistical dependency in the probabilistic relation @xmath44 : both the direct regulation , as well as any possible indirect regulation through an unknown intermediary @xmath179 , e.g. @xmath495 . if , however , @xmath43 is regulated also by an input @xmath180 independent of @xmath39 , that is @xmath496 , and our experiment does not record @xmath180 , then we might be assigning some variability ( or noise ) to @xmath43 , although that noise really would be a systematic regulatory effect caused by @xmath180 . in this last case , we would measure a smaller value of @xmath294 than would underestimate the real precision in the system ; the true value would only be revealed upon recording the unobserved regulator @xmath180 and computing @xmath497 .    having these caveats in mind , our first finding is that the information transmission of 1.5 bits between bicoid and hunchback that we measure from the data is larger than 1 bit , which would be needed if bicoid / hunchback transformation were a simple binary switch . to our knowledge",
    "this was one of the first times that a quantitative measure of `` regulatory power '' was computed for a genetic regulatory element that was measured in a high - precision experiment .",
    "given the noise in gene expression , can we put an upper bound of how much information could have maximally been transferred between bicoid and hunchback ? to do this , let s start by writing : @xmath498 as shown in sections  [ lec3],[lec4 ] , the term @xmath158 describes the input / output properties of the regulatory element . from experiment",
    ", we can determine the mean response @xmath164 of the regulatory element and the noise in the response , @xmath165 .",
    "these quantities have been plotted in figs .",
    "[ f - noise2],[f - noise5 ] ; if the noise is gaussian ( and to a good approximation , it is ) , these two measurements determine @xmath158 fully .",
    "to ask about the maximum achievable information transmission given the measured input / output relation @xmath158 , we write the lagrangean @xmath499= i(c;g ) - \\lambda\\int dc\\;p_{tf}(c),\\ ] ] where @xmath442 is a lagrange multiplier that will enforce the normalization of @xmath500 , while @xmath501 is the mutual information , and @xmath502 .",
    "we can now look for the optimal distribution of inputs , @xmath500 , which must satisfy : @xmath503}{\\delta p_{tf}(c)}=0 . \\label{variation}\\ ] ] one way to solve this variational problem is numerically .",
    "for details see refs @xcite ; here we only report on the results .",
    "we find that holding @xmath158 fixed as determined from the data on bicoid / hunchback relationship , and optimizing @xmath500 numerically , yielded the maximal channel capacity of @xmath504 bits , see fig .",
    "[ f - infoinfo ] . additionally the optimal",
    "@xmath505 predicts the optimal distribution of hunchback expression levels observed across the ensemble of nuclei , through @xmath506 , and the optimally predicted distribution matches the measured distribution very well [ fig .",
    "[ f - optinfo ] ] .",
    "the value found for the maximal information transmission ( channel capacity ) shows that the real biological system is operating close to what is achievable given the noise , that is @xmath507 .",
    "the high value is somewhat unexpected given that we know that hunchback is regulated also by other inputs , and that bicoid also regulates other targets .",
    "nevertheless this finding is a good motivation to consider taking maximization of information transmission seriously as a possible design principle .",
    "can we comment on the values in the range of @xmath508 bits ?",
    "it turns out that the bicoid gradient is read out directly by 4 gap genes : hunchback , kruppel , giant and knirps .",
    "if each would independently be able to encode @xmath509 bits , then together this genes could convey @xmath510 bits of information about bicoid and would thus achieve the amount needed for ap patterning .",
    "in this case , we would be able to claim consistency with the back - of - the - envelope calculation that _ requires _ at least this amount of information for the ap specification . before reaching such a conclusion , however , we need to resolve the following issues : * ( i ) * the readout ( gap ) genes @xmath336 are probably not independent , but have some redundancy , which will mean that they convey less than the sum of their individual information values about @xmath39 ; such redundancy , as we find below , can be alleviated by proper network wiring ; * ( ii ) * the next layer of developmental cascade after the gap genes is not regulated _ solely _ through the gap genes , but receives inputs from maternal morphogens directly ; therefore , the gap genes are not a single bottleneck through which the information can flow ; * ( iii ) * especially at the poles of the embryo , gradients other than bicoid provide spatial information about the ap position ; * ( iv ) * our formulation of the problem assumes steady state gap gene readout from a stable gradient ; it is not clear that such steady state is really reached in the timeframe necessary for nuclear specification .",
    "further experiments and theory will be needed to successfully address these , and possibly other , issues . despite these concerns ,",
    "we hope that the discussion provides motivation for looking at quantities like @xmath511  the information that the morphogen gradient encodes about the physical location @xmath179 ; at @xmath492 , and at @xmath512  the information that later developmental genes ( like gap genes ) carry about the physical location .",
    "information processing inequalities also constrain the relationships between these ( directly measurable ) quantities , providing an implicit check of whether we have missed some unobserved regulatory pathway . before proceeding",
    ", we note that experiments that probe these quantities are not easy , because they require us to measure simultaneously the expression levels of a number of genes , nucleus by nucleus , in order to estimate both the mean response @xmath513      analytically , the problem of eq  ( [ variation ] ) is tractable in the so - called small - noise limit , which we present here and use to explore the optimal architecture of small regulatory networks .    having seen that in at least one biological system the information transmission can come close to the channel capacity ( maximum achievable transmission given noise ) , we would like to elevate this finding to a principle : let us find network wiring diagrams and interaction parameters that transmit the most information from input tfs to the regulated output genes .",
    "we will consider networks where a single transcription factor at concentration @xmath39 can regulate a set of @xmath16 target genes @xmath336 , which may be interacting in a feed - forward network .",
    "for now , we will not consider feedback loops that can cause multistable behavior .",
    "it is clear that without any constraint , the information transmission can trivially be increased by decreasing the noise , and in biochemical networks noise can be decreased arbitrarily by increasing the number of signaling molecules , both on the input side ( @xmath39 ) and on the output side ( @xmath336 ) .",
    "the crucial idea is therefore _ to optimize information subject to biophysical constraints , i.e. subject to using a fixed number of signaling molecules_. with these assumptions in mind , we sketch the derivation of information transmission in the following text ; for details see refs @xcite . for additional work on information transmission in biochemical networks",
    "see refs @xcite .",
    "the dynamics of gene expression for genes @xmath336 is given by @xmath514 where @xmath23 is the protein lifetime , @xmath515 is the langevin noise term ( explained in section  [ lec3 ] ) , and @xmath516 $ ] is the regulatory ( input / output ) function , describing the activation rate of gene @xmath21 , given the input @xmath39 and the expression levels of all the other genes .",
    "various regulation functions were discussed in section  [ lec2 ] ; for combinatorial regulation , the most flexible one that we have examined was the monod - wyman - changeaux ( mwc ) regulation function : @xmath517 in this model , every regulatory input to @xmath21 contributes a term to the `` free energy '' @xmath26 , and each such term is parametrized by @xmath518 , the number of binding site for @xmath286 in the promoter of @xmath21 , and @xmath519 , related to the energy of binding to that binding site ; as before , @xmath122 is the free energy offset between the `` on '' and `` off '' states when no transcription factor is bound . if we want to avoid feedback and multistability , we can always renumber the genes such that each gene @xmath21 only depends on the input @xmath39 and other genes @xmath286 where @xmath520 .",
    "the regulation in a network of a single input @xmath39 and @xmath16 target genes @xmath21 is then described by unknown constants @xmath521 . when @xmath522 , the regulation of gene @xmath27 by gene @xmath25 is absent , that is , in the wiring diagram the arrow from @xmath286 to @xmath21 disappears . before proceeding ,",
    "we need also to compute the noise in this regulatory network .",
    "the noise in @xmath21 is given by two contributions : the output noise from generating a finite number of proteins of @xmath21 , and the input diffusive noise because @xmath21 is regulated by @xmath39 and other @xmath286 .",
    "the noise in our setup with @xmath16 target genes is fully determined by a @xmath301 covariance matrix : @xmath523 which can be computed from eqs  ( [ lgvn ] ) , as shown in refs  @xcite .",
    "in addition to computing this matrix , we find that there is a _ single dimensionless parameter @xmath524 _ describing the dynamic range of the input , @xmath525 $ ] , that will control the shape of the optimal solutions have the same parameters ( such as diffusion constant and degradation times ) , an approximation that we make . ] .",
    "@xmath524 is the maximal concentration for the input @xmath39 , expressed in `` natural units of concentration , '' @xmath526 , i.e. the maximum number of independent molecules of the output @xmath527 , divided by the relevant diffusion constant , typical size of the binding site @xmath105 and the integration protein lifetype @xmath23 .",
    "large values for @xmath524 mean that the output noise is dominant over the input noise , while a small dynamic range and therefore small @xmath524 means that the input diffusive noise in @xmath39 is the dominant noise in the system .    with the covariance matrix in hand , the distribution of outputs given the input @xmath39 is a multivariate gaussian : @xmath528 in the language introduced in section  [ lec4 ] , this is the `` encoding '' distribution .",
    "suppose that we now ask the `` decoding '' question : having seen the values of gap genes @xmath336 , what is the most likely value of @xmath39 that produced them , and what is the variance in @xmath39 ?",
    "if the noise is small , @xmath529 will also be gaussian , which can be found from eq  ( [ gnoise ] ) and the bayes theorem : @xmath530 where @xmath531 is the most likely value for @xmath39 that gives rise to the observed @xmath532 , and @xmath533 @xmath240 is the effective noise level in the input that accounts for all the noise in the system . ] .",
    "information @xmath534 is @xmath535 - \\langle s[p(c|\\{g_j\\})]\\rangle_{p_{tf}(c)},\\end{aligned}\\ ] ] where the distribution of inputs , @xmath500 is unknown .",
    "we want to find the maximal information transmission given the known noise , therefore , we look for the maximum of @xmath177 with respect to @xmath500 , just as we did in eq  ( [ variation ] ) , while insisting that @xmath500 be normalized .",
    "we find that @xmath536 that is , the system should optimally use those input levels @xmath39 more frequently that have proportionately smaller effective noise .",
    "using this optimal choice , the information , in bits , will be : @xmath537 this is as far as we can puch analytically ; @xmath534 still depends on the parameters @xmath521 that determine the wiring diagram of the network and the strengths of the regulatory arrows .",
    "the last remaining task is , therefore , to numerically optimize eq  ( [ infofinal ] ) with respect to these parameters , and examine the structure of optimal solutions .",
    "we can finally ask what are the optimal input / output curves for @xmath16 genes @xmath336 , regulated by the single input @xmath39 , if we do or do not allow for mutual interactions between the outputs .",
    "these results are a function of @xmath524 , the dynamic range of the input .",
    "figure  [ f-5genes ] shows the example solutions for @xmath538 noninteracting genes as a function of @xmath524 .",
    "we see that there are two regimes : at low @xmath524 , the optimal solutions for all 5 genes have exactly the same parameters , and therefore their input / output curves overlap perfectly . why is this behavior optimal , if at first glance all the genes appear completely redundant ? at low @xmath524 ,",
    "the input noise is dominant , and the best strategy is to have all @xmath538 genes read out the input @xmath39 and lower the input noise by averaging : using @xmath16 readouts should lower the effective noise by a factor of @xmath539 .    at high @xmath524",
    "another strategy , called the _ tiling _ solution , becomes optimal : here , each gene @xmath21 changes its expression considerably over some limited range of inputs , and various genes @xmath21 encode various non - overlapping input ranges ; in other words , each @xmath21 `` reports '' on its own range of inputs , while the other @xmath286 have either not switched on yet , or are already saturated .",
    "we can explore the transition from redundant to tiling solutions in detail , and we can carefully study the scaling of information capacity @xmath492 with the number of genes @xmath16 in each solution @xcite .",
    "although interesting from a theoretical perspective , the redundant and tiling solutions are not what is actually observed in the real regulatory networks in _ drosophila_. in particular , when @xmath336 are independent , the only possible input / output relations are sigmoid ; there are no stripe forming solutions , where @xmath21 would turn on at some concentration @xmath39 and turn off at some higher concentration .",
    "can such solutions emerge if the activating and repressing interactions between the output genes are allowed ?    indeed we find that this is the case , as shown in fig .",
    "[ f - combgenes ] . if the interactions between two output genes @xmath540 are allowed , the information maximizing wiring diagram includes `` lateral repression '' between the two genes that are jointly activated by a common input .",
    "this also generates apparent input / output curves that are non - monotonic : @xmath259 as a function of @xmath39 is seen to exhibit a stripe of activation .",
    "further work has confirmed that such stripe - like patterns optimize information transmission .",
    "interestingly , a similar pattern of interconnections ( `` lateral inhibition '' ) is known to occur in neural networks involved in early sensory processing . the function of such connections is to decrease the redundancy in the outputs  with no interconnections in the tiling solution , when the gene with the highest @xmath90 is saturated and fully active , we _ know _ that all the other genes are also fully on and saturated : they are therefore providing redundant information . in other words , when there is no interactions , the only patterns of activation ( in a simplified picture when the genes are binary ) are @xmath541 for a case of 3 genes .",
    "patterns such as @xmath542 or @xmath543 can not be accessed if there is no lateral interactions .",
    "if they exist , however , these patterns can be generated and they can encode additional useful information about their input @xmath39 , increasing information transmission .    our understanding of information transmission in transcriptional networks is far from complete .",
    "nevertheless , the richness of solutions and network topologies that emerges from a single optimization principle in a one - parameter ( @xmath524 ) problem is very encouraging , as is the qualitative matching to the stripe - like solutions in early _ drosophila _ development .",
    "further efforts need to be invested into understanding multi - stability , feedback loops and autoregulation , and in the incorporation of other biologically realistic detail .",
    "hopefully , this ( or some other ) design principle will in the future enable us to understand the wiring of biological networks and derive it from a mathematical measure of their function , rather than reconstructing it back from painstaking molecular disassembly of the network into its component parts .",
    "biology presents an interesting challenge to physicists : many symmetries and simplifications applicable in ordered ( but dead ) systems are absent in biology , and this complexity of life can be intimidating . on the other hand ,",
    "biological systems have evolved for function , and as we make progress in formalizing this notion mathematically , we hope to gain new insights and predictive power .",
    "assembling real physical models of biological information processing networks and connecting them to the genotypes on one hand , and to their function and selection on the other , will require tools from physics , biology , population dynamics , computer science , information theory and other disciplines , and this cross - disciplinary nature should make such research attractive to new students .",
    "i hope these lecture notes provide one interesting entry point to this new and exciting field .",
    "i would like to thank the organizers of qecg 2010 summer school , especially prof .",
    "jonathan miller , for their kind invitation . in addition , i am grateful to colleagues who have contributed to the research presented in these lectures : vijay balasubramanian , michael berry , william bialek , curt callan , thomas gregor , justin kinney , phil nelson , elad schneidman , and aleksandra walczak",
    ".    99 ibarra ru , edwards js , palsson bo ( 2002 ) escherichia coli k-12 undergoes adaptive evolution to achieve in silico predicted optimal growth .",
    "_ nature _ * 420 : * 1869 .",
    "tkaik g ( 2007 ) information flow in biological networks .",
    "_ dissertation , princeton university_. tkaik g , bialek w ( 2009 ) cell biology : networks , regulation , pathways .",
    "encyclopedia of complexity and systems science , ed r meyers , pp 719741 ( springer , berlin ) .",
    "rieke f , warland d , de ruyter van steveninck rr & bialek w , _ spikes : exploring the neural code _",
    "( mit press , cambridge , 1997 ) .",
    "shen - orr ss , milo r , mangan s , alon u ( 2002 ) network motifs in the transcriptional regulation network of escherichia coli .",
    "_ nat genet _ * 31 : * 648 .",
    "barabasi al , oltvai zn ( 2004 ) network biology : understanding the cell s functional organization .",
    "_ nat rev genet _ * 5 : * 101103 .",
    "strogatz sh ( 2001 ) exploring complex networks .",
    "_ nature _ * 410 : * 26876 .",
    "ravasz e , somera al , mongru da , oltvai zn , baravasi al ( 2002 ) hierarchical organization of modularity in metabolic networks .",
    "_ science _ * 297 : * 15515 .",
    "sanchez l , thieffry d ( 2001 ) a logical analysis of the drosophila gap - gene system .",
    "_ j theor biol _ * 211 : * 11541 .",
    "hopfield jj ( 1982 ) neural networks and physical systems with emergent collective computational abilities .",
    "_ proc natl acad sci usa _ * 79 : * 25548 .",
    "li f , long t , lu y , quyang q , tang c ( 2004 ) the yeast cell - cycle network is robustly designed .",
    "_ proc natl acad sci usa _ * 101 : * 47816 .",
    "bray d , bourret rb , simon mi ( 1993 ) computer simulation of the phosphorylation cascade controlling bacterial chemotaxis .",
    "_ mol biol cell _ * 4 : * 46982 .",
    "novak b , tyson jj ( 1997 ) modeling the control of dna replication in fission yeast .",
    "_ proc natl acad sci usa _ * 94 : * 914752 .",
    "leloup jc , goldbeter a ( 2003 ) toward a detailed computational model for the mammalian circadian clock .",
    "_ proc natl acad sci usa _ * 100 : * 70516 .",
    "elowitz mb , leibler s ( 2000 ) a synthetic oscillatory network of transcriptional regulators .",
    "_ nature _ * 403 : * 3358 .",
    "ng van kampen , _",
    "stochastic processes in physics and chemistry , third edition _ , ( north holland , 2007 ) .",
    "gillespie dt ( 2007 ) stochastic simulation of chemical kinetics .",
    "_ annu rev phys chem _ * 58 : * 3555 .",
    "mcadams hh , arkin a ( 1997 ) stochastic mechanisms in gene expression .",
    "_ proc natl acad sci usa _ * 94 : * 8149 .",
    "berg og , von hippel ph ( 1985 ) diffusion - controlled macromolecular reations .",
    "_ annu rev biophys biophys chem _ * 14 : * 131 .",
    "monod j , wyman j , changeaux jp ( 1965 ) on the nature of allosteric transitions : a plausible model .",
    "_ j mol biol _ * 12 : * 88118 .",
    "gregor t , tank dw , wieschaus ef , bialek w ( 2007 ) probing the limits to positional information . _ cell _ * 130 : * 153164 .",
    "tkaik g , gregor t , bialek w ( 2008 ) the role of input noise in transcriptional regulation .",
    "_ plos one _ * e2774*. jacob f , monod j ( 1961 ) genetic regulatory mechanisms in the synthesis of proteins . _ j mol biol _ * 3 : * 31856 .",
    "setty y , mayo ae , surette mg , alon u ( 2003 ) detailed map of a cis - regulatory input function . _ proc natl acad sci usa _ * 100 : * 77027 .",
    "kuhlman t , zhang z , saier jmh , hwa t ( 2007 ) combinatorial transcriptional control of the lactose operon of escherichia coli .",
    "_ proc natl acad sci usa _ * 104 : * 60438 .",
    "schroeder md , pearce m , fak j , fan h , unnerstall u , emberly e , rajewsky n , siggia ed , gaul u ( 2004 ) transcriptional control in the segmentation gene network of drosophila . _",
    "plos biology _ * 2 : * e271 .",
    "segal e , sadka t , schroeder m , unnerstall u , gaul u ( 2008 ) predicting expression patterns from regulatory sequence in drosophila segmentation .",
    "_ nature _ * 451 : * 535540 .",
    "fakhouri wd , ay a , sayal r , dresch j , dayringer e , arnosti dn ( 2010 ) . deciphering a transcriptional regulatory code : modeling short - range repression in the drosophila embryo .",
    "_ mol sys biol _ * 6 : * 341 .",
    "bialek w ( 2002 ) physics of biomolecules and cells ,",
    "h. flyvbjerg et al eds ( edp sciences , les ulis ; springer berlin ) ; thinking about the brain , _ arxiv : physics/0205030_. berg hc , brown da ( 1972 ) chemotaxis in escherichia coli analyzed by three - dimensional tracking",
    ". _ nature _ * 239 : * 5004 .",
    "swain ps , elowitz mb , siggia ed ( 2002 ) intrinsic and extrinsic contributions to stochasticity in gene expression . _ proc natl acad sci usa _ * 99 : * 12795800 .",
    "ptashne m ( 1989 ) a genetic switch .",
    "gene control and phage @xmath3 .",
    "blackwell scientific publishing and cell press .",
    "barkai n , leibler s ( 1997 ) robustness in simple biochemical networks .",
    "_ nature _ * 387 : * 9137 .",
    "setayeshgar s , bialek w ( 2005 ) physical limits to biochemical signaling .",
    "_ proc natl acad sci usa _ * 102 * : 100405 .",
    "pedraza jm , van oudenaarden a ( 2005 ) noise propagation in gene networks .",
    "_ proc natl acad sci usa _ * 307 : * 19659 .",
    "raj a , peskin cs , tranchina d , vargas dy , tyagi s ( 2006 ) stochastic mrna synthesis in mammalian cells . _ plos biology _ * 4 : * e309 .",
    "elowitz mb , levine aj , siggia ed , swain ps ( 2002 ) stochastic gene expression in a single cell .",
    "_ science _ * 297 : * 11836 .",
    "hooshangi s , thiberge s , weiss r ( 2005 ) ultrasensitivity and noise propagation in a synthetic transcriptional cascade .",
    "_ proc natl acad sci usa _ * 102 : * 35816 .",
    "rosenfeld n , young jw , alon u , swain ps , elowitz mb ( 2005 ) gene regulation at the single - cell level .",
    "_ science _ * 307 : * 19625 .",
    "bar - even a , paulsson j , maheshri n , carmi m , oshea e , pilpel y , barkai n ( 2006 ) noise in protein expression scales with natural protein abundance .",
    "_ nature _ * 38 : * 63643 .",
    "blake wj , kaern m , cantor cr , collins jj ( 2003 ) noise in eukaryotic gene expression .",
    "_ nature _ * 422 : * 633 - 7 .",
    "sachs k , perez o , peer d , lauffenburger da , nolan gp ( 2005 ) causal protein - protein signaling networks derived from multiparameter single - cell data .",
    "_ science _ * 308 : * 523 .",
    "friedman n ( 2004 ) inferring cellular networks using probabilistic graphical models .",
    "_ science _ * 303 : * 799 .",
    "schneidman e , berry mj 2nd , segev r , bialek w ( 2006 ) weak pairwise correlations imply strongly correlated network states in a neural population .",
    "_ nature _ * 440 : * 100712 .",
    "tkaik g , schneidman e , berry mj 2nd , bialek w ( 2009 ) spin glass models for a network of real neurons .",
    "_ arxiv.org : _ * 0912.5409*. mora t ,",
    "walczak am , bialek w , callan cg jr ( 2010 ) maximum entropy models for antibody diversity .",
    "_ proc natl acad sci usa _ * 107 : * 540510 .",
    "schneidman e , susanne s , berry mj 2nd , bialek w ( 2003 ) network information and connected correlations .",
    "_ phys rev lett _ * 91 : * 238701 .",
    "slutsky m , mirny la ( 2004 ) kinetics of protein - dna interaction : facilitated location in sequence - dependent potential .",
    "_ biophys j _ * 87 : * 4021 .",
    "berg og , von hippel ph ( 1987 ) .",
    "selection of dna binding sites by regulatory proteins .",
    "statistical - mehcnanical theory and application to operators and promoters .",
    "_ j mol biol _ * 193 : * 723 .",
    "mukherjee s , berger mf , jona g , wang xs , muzzey d , snyder m , young ra , bulyk ml ( 2004 ) rapid analysis of the dna - binding specificities of transcription factors with dna microarrays .",
    "_ nat genet _",
    "* 36 : * 1331 .",
    "lee ti , rinaldi nj , robert f , odom dt , bar - joseph z , gerger gk , hannett nm , harbison ct , thomson cm , simon i , et al ( 2002 ) _ science _ * 298 : * 799804 .",
    "elemento o , slonim n , tavazoie s ( 2007 ) a universal framework for regulatory element discovery across all genomes and data types .",
    "_ mol cell _ * 28 : * 33750 .",
    "djordjevic m , sengupta am , shraiman bi ( 2003 ) a biophysical approach to transcription factor binding site discovery .",
    "_ genome res _ * 13 : * 238190 .",
    "kinney jb , tkaik g , callan cg jr ( 2006 ) precise physical models of protein - dna interaction from high - throughput data .",
    "_ proc natl acad sci usa _ * 104 : * 501 .",
    "tkaik g , callan cg jr , bialek w ( 2008 ) information capacity of genetic regulatory elements .",
    "_ phys rev e _ * 78 : * 011910 .",
    "tkaik g , callan cg jr , bialek w ( 2008b ) information flow and optimization in transcriptional regulation .",
    "_ proc natl acad sci usa _ * 105 : * 1226570 .",
    "tkaik g , walczak am , bialek w ( 2009b ) optimizing information flow in small genetic networks .",
    "_ phys rev e _ * 80 : * 031920 .",
    "walczak am , tkaik g , bialek w ( 2010 ) optimizing information flow in small genetic networks .",
    "ii . feed - forward interactions .",
    "_ phys rev e _ * 81 : * 041905 .",
    "ziv e , nemenman i , wiggins ch ( 2007 ) optimal signal processing in small stochastic biochemical networks .",
    "_ plos one _ * 2 : * e1077 .",
    "tostevin f , ten wolde pr ( 2009 ) mutual information between input and output trajectories of biochemical networks .",
    "_ phys rev lett _ * 102 : * 218101 .",
    "walczak am , mugler a , wiggins ch ( 2009 ) a stochastic spectral analysis of transcriptional regulatory cascades . _ proc natl acad sci usa _ * 106 : * 652934 ."
  ],
  "abstract_text": [
    "<S> these are notes for a set of 7 two - hour lectures given at the 2010 summer school on quantitative evolutionary and comparative genomics at oist , okinawa , japan . </S>",
    "<S> the emphasis is on understanding how biological systems process information . </S>",
    "<S> we take a physicist s approach of looking for simple phenomenological descriptions that can address the questions of biological function without necessarily modeling all ( mostly unknown ) microscopic details ; the example that is developed throughout the notes is transcriptional regulation in genetic regulatory networks . </S>",
    "<S> we present tools from information theory and statistical physics that can be used to analyze noisy nonlinear biological networks , and build generative and predictive models of regulatory processes . </S>"
  ]
}