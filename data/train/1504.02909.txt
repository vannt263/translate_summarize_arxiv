{
  "article_text": [
    "when does a graph @xmath0 have a triangle decomposition ?",
    "( by this we mean a partition of its edge set into triangles . ) there are two obvious necessary ` divisibility conditions ' : the number of edges must be divisible by three , and the degree of any vertex must be even .",
    "we say that @xmath0 is _ tridivisible _ if it satisfies these divisibility conditions .",
    "in 1847 kirkman proved that any tridivisible complete graph has a triangle decomposition ; equivalently , there is a steiner triple system on @xmath1 vertices if @xmath1 is @xmath2 or @xmath3 mod @xmath4 . in @xcite",
    "we showed more generally that a tridivisible graph has a triangle decomposition if we assume a certain pseudorandomness condition .",
    "in fact , we proved a more general result on clique decompositions of simplicial complexes , which in particular proved the existence conjecture for combinatorial designs .",
    "one purpose of the current paper is to illustrate the new technique ( randomised algebraic construction ) of @xcite in the simplified setting of triangle decompositions ; we will also prove a conjecture of wilson @xcite on the number of steiner triple systems .",
    "these results are proved in the next three sections , roughly following the method of @xcite , but introducing some novelties in technique that lead to considerable simplifications in the case of triangle decompositions ; the material here closely follows a lecture series that the author recently gave at the israel institute for advanced studies . in section [ rtr ]",
    "we sketch an argument of bennett and bohman @xcite on the random greedy matching process and adapt the calculations to the version needed in this paper .",
    "we generalise from steiner triple systems to designs in section [ des ] .",
    "we conclude by noting that it remains open to obtain an asymptotic formula for the number of designs , or even just for the number of regular graphs .",
    "we start by stating our result that tridivisible pseudorandom graphs have triangle decompositions .",
    "the pseudorandomness condition is as follows .",
    "let @xmath0 be a graph on @xmath1 vertices .",
    "the _ density _ of @xmath0 is @xmath5 .",
    "we say that @xmath0 is _",
    "@xmath6-typical _ if every vertex has @xmath7 neighbours and every pair of vertices have @xmath8 common neighbours .",
    "( we write @xmath9 for any real between @xmath10 and @xmath11 . )",
    "[ qrtri ] there exists @xmath12 and @xmath13 so that if @xmath14 and @xmath0 is a @xmath6-typical tridivisible graph on @xmath1 vertices with @xmath15 and @xmath16 then @xmath0 has a triangle decomposition .",
    "note that in theorem [ qrtri ] we allow the density to decay polynomially with @xmath1 ; this will be important for the application in the next subsection , but in many cases of interest one can consider @xmath17 and @xmath6 to be fixed constants independent of @xmath1 .",
    "one such consequence of theorem [ qrtri ] noted in @xcite is that the standard random graph model @xmath18 with high probability ( whp ) has a partial triangle decomposition that covers all but @xmath19 edges .",
    "indeed , deleting a perfect matching on the set of vertices of odd degree and then at most two @xmath20-cycles gives a graph satisfying the hypotheses of the theorem .",
    "this is asymptotically best possible , as whp there are @xmath21 vertices of odd degree , and any set of edge - disjoint triangles must leave at least one edge uncovered at each vertex of odd degree .",
    "we remark that our definition of typicality here is weaker than that used in @xcite .",
    "in fact , for most of the paper we will assume the stronger version , then explain at the end how the proof can be modified to work with the current definition .",
    "we also make the ( well - known ) remark that typicality implies the standard regularity property ( for appropriate constants ) that appears in szemerdi s regularity lemma , but the converse is not true , as regularity allows individual vertices to behave badly , even to be isolated .",
    "another purpose of our paper is to prove the following conjecture of wilson @xcite on the number of steiner triple systems on @xmath1 vertices , i.e.  triangle decompositions of the complete graph @xmath22 ; denote this by @xmath23 .",
    "[ wilson - conj ] if @xmath1 is @xmath2 or @xmath3 mod @xmath4 , then @xmath24 .",
    "note that @xmath22 is tridivisible if and only if @xmath1 is @xmath2 or @xmath3 mod @xmath4 , so @xmath25 for all other @xmath1 .",
    "the upper bound in theorem [ wilson - conj ] was recently proved by linial and luria @xcite , who showed that @xmath26 .",
    "our lower bound will be @xmath27 for some small @xmath28 .",
    "theorem [ wilson - conj ] will follow quite easily from theorem [ qrtri ] and the semirandom method ( nibble )",
    ". it will be most convenient for us to apply the results of bohman , frieze and lubetzky @xcite on the triangle removal process ( although we could make do with a simpler nibble argument , or the argument of bennett and bohman @xcite sketched in section [ rtr ] ) .",
    "we say that an event @xmath29 holds _ with high probability _",
    "( whp ) if @xmath30 for some @xmath31 as @xmath32 ; note that when @xmath1 is sufficiently large , by union bounds we can assume that any specified polynomial number of such events all occur .    in the triangle removal process , we start with the complete graph @xmath22 , and at each step we delete the edges of a uniformly random triangle in the current graph .",
    "it is shown in @xcite that whp the process persists until only @xmath33 edges remain , but we will stop at @xmath34 edges ( i.e.  at the nearest multiple of @xmath3 to this number ) so that we can apply theorem [ qrtri ] .",
    "we need the following additional facts from @xcite about this stopped process : whp the final graph is @xmath35-typical , and when @xmath36 edges remain the number of choices for the deleted triangle is @xmath37 .",
    "* proof of theorem [ wilson - conj ] . * consider the following procedure for constructing a steiner triple system on @xmath1 vertices : run the triangle removal process until @xmath34 edges remain , then apply theorem [ qrtri ] ( if its hypotheses are satisfied , which occurs in @xmath38 proportion of all instances of the process ) . writing @xmath39 for the number of steps and @xmath40 , the logarithm of the number of choices in this procedure is @xmath41 since @xmath42 and @xmath43 . also , for any fixed steiner triple system , the logarithm of the number of times it is counted by this procedure is at most @xmath44 therefore @xmath45 , which implies the stated bound on @xmath23 .",
    "the strategy of the proof of theorem [ qrtri ] is encapsulated by the following setup ( we give motivation and discussion below ) .",
    "we say that @xmath46 is _ @xmath6-bounded _ if @xmath47 for every @xmath48 , where @xmath49 is the _ neighbourhood _ of @xmath50 in @xmath51 .",
    "[ strategy ] suppose we have @xmath52 with a ` template ' triangle decomposition @xmath53 such that    nibble : :    @xmath54 contains a set @xmath55 of    edge - disjoint triangles with ` leave '    @xmath56 that is    @xmath57-bounded , cover : :    for any @xmath58 that is    @xmath57-bounded , there is a set @xmath59 of    edge - disjoint triangles such that    @xmath60 and the ` spill '    @xmath61 is @xmath62-bounded , hole : :    for any tridivisible @xmath63 that is    @xmath62-bounded , there are ` outer ' and ` inner ' sets    @xmath64 of edge - disjoint triangles in @xmath65    such that @xmath66 is @xmath67-bounded and    @xmath68 is a partition of @xmath66 , completion : :    given @xmath69 , @xmath59 , @xmath70 and    @xmath71 as above , there are sets @xmath72 ,    @xmath73 , @xmath74 , @xmath75 of    edge - disjoint triangles in @xmath65 such that    @xmath76 is a partition of @xmath77 ,    @xmath78 , @xmath79 and    @xmath80 .",
    "the key step is choosing @xmath53 ( which determines @xmath65 ) .",
    "we will use our method of randomised algebraic construction , which takes a particularly simple form for triangle decompositions . to motivate the construction ,",
    "suppose that @xmath81 is an abelian group , and consider the set @xmath82 of triples @xmath83 such that @xmath84 .",
    "we note that @xmath82 is a good ` model ' for a triangle decomposition , as for any @xmath85 there is a unique @xmath86 such that @xmath84 .",
    "however , we can not simply take @xmath82 , as not all such @xmath83 are triangles of @xmath0 ; moreover , @xmath87 may not even be pairwise distinct .",
    "the idea of the construction is that a suitable random subset of @xmath82 can act as a template , which covers a constant fraction of @xmath0 .",
    "next we find an approximate decomposition of the rest of @xmath0 by random greedy algorithms : this is accomplished by steps * nibble * and * cover * of setup [ strategy ] .",
    "after these steps , every edge of @xmath0 has been covered once or twice , and the spill @xmath88 is the set of edges that have been covered twice .",
    "finally , we use local modifications built into the template to turn the approximate decomposition into an exact decomposition : this is accomplished by steps * hole * and * completion * of setup [ strategy ] .    to motivate * completion * , we imagine first that we have * hole * and also @xmath89 . then we could delete @xmath70 and take @xmath71 instead , thus reducing by one the multiplicity of every edge in @xmath88 , so that we have a triangle decomposition of @xmath0",
    ". however , specifying a triangle of @xmath53 is very restrictive , as there are only order(@xmath90 ) such triangles out of a total of order(@xmath91 ) triangles in @xmath0 .",
    "if we had chosen @xmath53 uniformly at random it would be hopeless to obtain any useful configuration formed by triangles of @xmath53 .",
    "however , the algebraic structure implies that certain configurations of triangles are dense within a sparse configuration space ( described by linear constraints ) .",
    "this forms the basis of a modification procedure that replaces @xmath59 , @xmath70 and @xmath71 by other sets of triangles with the same properties , where @xmath72 plays the role of @xmath92 , @xmath73 of @xmath70 , and each triangle @xmath93 of @xmath73 can be embedded in a small subgraph that has one triangle decomposition ( part of @xmath75 ) using @xmath93 and another triangle decomposition ( part of @xmath74 ) contained in @xmath53 .",
    "it is not hard to see that @xmath0 contains a triangle decomposition in setup [ strategy ] .",
    "indeed , we start by taking the sets @xmath55 provided by * nibble * and then the sets @xmath59 and @xmath88 provided by * cover*. now we note that @xmath94 is tridivisible , as any integer linear combination of tridivisible graphs is tridivisible .",
    "so we can apply * hole * to obtain @xmath70 and @xmath71 .",
    "then we can apply * completion * to obtain @xmath95 . finally , @xmath96 is a triangle decomposition of @xmath0 .",
    "thus the remainder of the proof will be to show that we can achieve setup [ strategy ] .",
    "we choose the template as follows .",
    "[ rac ] let @xmath97 be such that @xmath98 .",
    "let @xmath99 be a uniformly random injection .",
    "let @xmath100    to avoid cumbersome notation , we use @xmath83 to denote either the vertex set @xmath101 or the edge set @xmath102 of a triangle .",
    "the context determines which interpretation is intended , e.g.  in construction [ rac ] the graph @xmath65 is the ( disjoint ) union of the edge - sets of the triangles in @xmath53 .    in this subsection",
    "we will show that whp the pair @xmath103 is ` typical ' ( in a precise sense defined below ) ; this will allow us to implement the approximate decomposition in steps * nibble * and * cover*. moreover , we will show in section [ sec : completion ] that @xmath65 is ` linearly typical ' ( roughly speaking : we can count subgraph extensions with linear constraints on the vertices ) ; this will imply the existence of the local modifications used in steps * hole * and * completion*.    we start with some notation and preliminary observations .",
    "throughout we write @xmath104 .",
    "we identify @xmath0 with its edge set @xmath105 , so that @xmath106 denotes the number of edges of @xmath0 ( rather than the number of vertices , as is used by some authors ) .",
    "we write @xmath107=\\{1,\\dots , n\\}$ ] .",
    "we define @xmath108 and note that @xmath109 .",
    "we observe that if @xmath110 and @xmath84 then @xmath87 are pairwise distinct .",
    "we note that @xmath111 in @xmath112 , so we can use @xmath113 and @xmath114 interchangeably in @xmath112-arithmetic .",
    "we consider @xmath112 as a vector space over @xmath115 , and observe that any two nonzero elements span a subspace of dimension two .",
    "next we introduce the stronger typicality assumption used in @xcite .",
    "we say that @xmath0 is _ @xmath116-typical _ if @xmath117 note that being @xmath6-typical is essentially the same as being @xmath118-typical ( up to a factor of @xmath119 in @xmath6 ) .",
    "for most of the paper we will assume that @xmath0 is @xmath120-typical ; at the end we will explain how the proof can be modified to work with the weaker assumption that @xmath0 is @xmath6-typical .",
    "now we define the typicality condition for @xmath103 and show that it holds whp .",
    "let @xmath65 be a subgraph of @xmath0 .",
    "we say that @xmath103 is _ @xmath116-typical _ if @xmath121 for any @xmath122 with @xmath123 .",
    "[ template - typ ] whp @xmath124 and @xmath103 is @xmath125-typical .",
    "the proof uses the following consequence of azuma s inequality .",
    "[ def : lip2 ] let @xmath126 be the symmetric group , @xmath127 and @xmath128 .",
    "we say that @xmath93 is _ @xmath129-lipschitz _ if for any @xmath130 such that @xmath131 for some transposition @xmath132 we have @xmath133 .",
    "[ lip2 ] ( see e.g.  @xcite ) suppose @xmath127 is @xmath129-lipschitz , @xmath134 is uniformly random and @xmath135",
    ". then @xmath136    * proof of lemma [ template - typ ] . * we start by estimating @xmath137 . for any @xmath138 , given @xmath139 and @xmath140",
    ", we have @xmath141 if and only if @xmath142 for some @xmath86 such that @xmath143",
    ". since @xmath0 is @xmath120-typical , there are @xmath144 choices for @xmath86 .",
    "each satisfies @xmath142 with probability @xmath145 , so @xmath146 .",
    "we can view @xmath147 as @xmath148 , where @xmath149 is any fixed injection and @xmath150 is a random permutation of @xmath151 .",
    "any transposition of @xmath150 affects @xmath152 by @xmath153 , so by lemma [ lip2 ] whp @xmath154 .",
    "similarly , we consider any @xmath122 with @xmath155 , write @xmath156 , and estimate @xmath157 . for any @xmath158 , given @xmath140 and @xmath139 for all @xmath159",
    ", we have @xmath160 if and only if for all @xmath161 there is @xmath162 such that @xmath163 .",
    "since @xmath0 is @xmath120-typical , there are @xmath164 choices for @xmath165 . by excluding @xmath166 choices of @xmath165",
    "we can assume @xmath167 for all @xmath168 .",
    "then for each @xmath161 there are @xmath144 choices for @xmath169 , and for any set of choices , with probability",
    "@xmath170 they all satisfy @xmath163 .",
    "this gives @xmath171 any transposition of @xmath150 affects @xmath172 by @xmath166 , so by lemma [ lip2 ] whp @xmath173 .    since @xmath124 and @xmath109 we have @xmath174 for small @xmath6 .",
    "also , as @xmath103 is @xmath125-typical we can deduce that @xmath54 is @xmath175-typical .",
    "indeed , for any @xmath48 we have @xmath176 furthermore , for any @xmath177 we estimate @xmath178 as @xmath179 applying the following theorem , we deduce * nibble * with @xmath180 .",
    "[ nibble - deg ] there are @xmath181 and @xmath13 so that if @xmath182 , @xmath183 and @xmath0 is a @xmath129-typical graph on @xmath1 vertices with @xmath184 , then there is a set @xmath55 of edge - disjoint triangles in @xmath0 such that @xmath185 is @xmath186-bounded .",
    "we remark that the parameters in theorem [ nibble - deg ] are not very sharp : we have just fixed some convenient values that suffice for our purposes .",
    "similar results are well - known , but we are not aware of any reference that implies the theorem as stated , so we will sketch a proof in section [ rtr ] .    for convenient reference ,",
    "we give here the values of some other parameters that will be used below : @xmath187 the tightest constraint on @xmath6 that will be required in our calculations is @xmath188 ; this holds for small @xmath189 if @xmath190 .",
    "( this is the bound we need if @xmath0 is @xmath120-typical , but if @xmath0 is @xmath6-typical we need the stronger bound in theorem [ qrtri ] . )      consider the following random greedy algorithm .",
    "let @xmath191\\}$ ] ( with edges ordered arbitrarily ) .",
    "let @xmath192\\}$ ] be triangles such that @xmath193 consists of @xmath194 and two edges of @xmath65 , and is chosen uniformly at random from all such triangles that are edge - disjoint from all previous choices ; if there is no available choice for @xmath193 then the algorithm aborts .    to analyse the algorithm we require a concentration inequality .",
    "we say that a random variable @xmath195 is _ @xmath196-dominated _ , if there are constants @xmath197 with @xmath198 , and we can write @xmath199 , such that @xmath200 for all @xmath201 , and conditional on any given values of @xmath202 for @xmath203 we have @xmath204 .",
    "the following lemma follows easily from freedman s inequality @xcite ( see ( * ? ? ?",
    "* lemma 2.7 ) ) .",
    "[ dom ] if @xmath195 is @xmath196-dominated then @xmath205 .",
    "sometimes we will use a modified inequality with @xmath119 replaced by @xmath206 .",
    "we also note that if the @xmath207 are independent ( not necessarily identically distributed ) indicator variables we recover a version of the chernoff bound for ( pseudo)binomial variables ( where better concentration is known ) . for the following lemma",
    ", we recall that @xmath69 is @xmath57-bounded , where @xmath180 , and that @xmath208 .",
    "[ cover - leave ] whp the algorithm to choose @xmath59 does not abort , and @xmath61 is @xmath62-bounded .    * proof . * for @xmath209 $ ] we let @xmath210 be the bad event that @xmath211 is not @xmath62-bounded .",
    "we define a stopping time @xmath212 be the smallest @xmath201 for which @xmath210 holds or the algorithm aborts , or @xmath213 if there is no such @xmath201 .",
    "it suffices to show whp @xmath214 .",
    "we fix @xmath215 $ ] and bound @xmath216 as follows . for any @xmath217 , since @xmath210 does not hold , @xmath218 is @xmath62-bounded . writing @xmath219 , we can bound the number of excluded choices for @xmath193 by @xmath220 , so at most one half of the triangles on @xmath194 are excluded .",
    "next we fix @xmath221 , and estimate @xmath222 , where @xmath223 denotes the conditional probability given the choices made before step @xmath201 .",
    "we compare @xmath224 to the expected number of times that @xmath225 would be covered if we chose all triangles independently . to be precise , we let @xmath226 where each @xmath227 is a uniform random triangle consisting of @xmath194 and two edges of @xmath65 , and @xmath228)$ ] are independent . by the bound on excluded choices , @xmath229 , so @xmath230 .",
    "the @xmath201th summand in @xmath231 is only nonzero when @xmath232 .",
    "as @xmath69 is @xmath57-bounded , the number of such @xmath201 is at most @xmath233 .",
    "also , for each @xmath201 such that @xmath234 spans a triangle , we have @xmath235 therefore @xmath236 .",
    "finally , fix @xmath48 and consider @xmath237 , where @xmath238 .",
    "we have @xmath239 and @xmath240 by lemma [ dom ] we have @xmath241 .",
    "taking a union bound over @xmath242 , whp @xmath243 , i.e.  @xmath88 is @xmath62-bounded and @xmath214 .",
    "below we will require several more random greedy algorithms similar to that above .",
    "one could formulate an abstract general lemma to cover all cases ( see ( * ? ? ?",
    "* lemma 4.11 ) ) , but here we will prefer the more intuitive approach of identifying the key principles of the proof , so that it will be clear how it may be adapted to future instances . for a general random greedy algorithm",
    ", we identify some desired boundedness conclusion , then at each step of the algorithm , assuming that boundedness has not failed , we show that at most one half ( say ) of the choices of the required configuration have been excluded . then for each edge",
    "@xmath225 in the underlying graph @xmath244 we estimate the expected number @xmath231 of times that @xmath225 would be covered if we chose all configurations independently .",
    "if @xmath245 and the configurations have constant size ( not depending on @xmath1 ) then the graph of all covered edges is whp @xmath129-bounded .",
    "we record some estimates that are useful for such arguments .",
    "suppose @xmath244 is a small fixed graph ( @xmath246 say ) , @xmath247 and @xmath248 is an embedding of @xmath249 $ ] in @xmath65 .",
    "we call @xmath250 an _ extension_. let @xmath251 be the number of embeddings @xmath252 of @xmath244 in @xmath65 that restrict to @xmath248 on @xmath253 .",
    "we suppose that @xmath29 is _ @xmath254-degenerate _ , meaning that we can construct the embedding one vertex at a time , so that at each step we add a vertex adjacent to at most @xmath254 existing vertices .",
    "as @xmath103 is @xmath125-typical , when we add a vertex adjacent to @xmath255 existing vertices , there are @xmath256 choices . multiplying these estimates ,",
    "we obtain the following estimate for @xmath251 .",
    "[ ext ] suppose @xmath250 is a @xmath254-degenerate extension with @xmath246 . then @xmath257| } n^{|v(h)|-|f|}.\\ ] ]    now suppose that we wish to exclude embeddings @xmath252 that use some edge in @xmath51 , which is @xmath6-bounded . fix @xmath258 $ ] and consider the embeddings @xmath252 with @xmath259 . if @xmath260 there are at most @xmath261 choices for the embedding of @xmath225 then at most @xmath262 choices for the remainder of @xmath252 . if @xmath263 there are at most @xmath264 choices for the embedding of @xmath225 then at most @xmath265 choices for the remainder of @xmath252 .",
    "thus at most @xmath266 choices of @xmath252 are excluded , which is a negligible fraction of @xmath251 .",
    "in this section we establish * hole*. our first step is to consider an integral relaxation , in the following sense . instead of thinking of @xmath68 as a partition of @xmath66 , we think of @xmath88 as a weighted sum of edge sets of triangles , where triangles in @xmath70 have weight @xmath2 and triangles in @xmath71 have weight @xmath267 .",
    "we can express this by the equation @xmath268 , where @xmath269 is the corresponding @xmath270-vector indexed by triangles , and @xmath271 is the inclusion matrix of triangles against edges , i.e.  @xmath272 for any edge @xmath225 and triangle @xmath93 .",
    "it is straightforward to show that this equation has a solution if we allow @xmath269 to have any integer weights on triangles ( see @xcite for more general results ) .",
    "it will be more convenient to work with linear maps rather than matrices .",
    "for any graph @xmath244 we define @xmath273-linear boundary / shadow maps @xmath274 for @xmath275 by @xmath276 for @xmath277 , i.e.  for @xmath278 and @xmath279 we define @xmath280 . for example , if @xmath281 then @xmath282 is defined by @xmath283 .    it will also be notationally convenient to identify vectors with ( generalised ) sets .",
    "it is standard to identify @xmath284 with the set @xmath285 .",
    "similarly , we can identify @xmath286 with the multiset in @xmath287 in which @xmath288 has multiplicity @xmath289 ( for our purposes @xmath290 ) .",
    "we also apply similar notation and terminology as for multisets to vectors @xmath291 ( ` intsets ' ) . here",
    "our convention is that ` for each @xmath292 ' means that @xmath288 is considered @xmath293 times in any statement or algorithm , and has a sign attached to it ( the same as that of @xmath289 ) ; we also refer to @xmath288 as a ` signed element ' of @xmath50 . for @xmath291",
    "we write @xmath294 , where @xmath295 and @xmath296 for @xmath297 . given @xmath298 and @xmath48 , we define @xmath299 by @xmath300",
    ". then we can extend the definition of boundedness to multigraphs : @xmath51 is @xmath6-bounded if @xmath301 for every @xmath48 .    with this notation ,",
    "our integral relaxation of * hole * is expressed by the following lemma ( in which @xmath22 denotes the complete graph on @xmath81 ) ; for * hole * we will need the additional properties that @xmath302 for any @xmath303 , and @xmath304 for all @xmath305 , as then we can write @xmath306 .",
    "[ intrelax ] there is @xmath307 with @xmath308 such that @xmath309 is @xmath310-bounded .",
    "* we will construct @xmath311 such that @xmath312 , @xmath313 , @xmath314 satisfy @xmath315 for @xmath316 .",
    "recalling that @xmath88 is tridivisible , each @xmath317 will be tridivisible , in the ` intgraph ' sense : i.e.  @xmath318 is divisible by @xmath3 and @xmath319 is divisible by @xmath119 for all @xmath50 .",
    "_ step 0 : _ for @xmath320 , we choose @xmath321 independent uniformly random triangles in @xmath22 ; then @xmath312 satisfies @xmath322 . for each vertex @xmath50 ,",
    "the number of these triangles containing @xmath50 is binomial with mean @xmath323 , so by the chernoff bound whp @xmath324 is @xmath325-bounded .",
    "_ step 1 : _ we let @xmath326 , so @xmath327 , i.e. @xmath328 . note for all @xmath329 that @xmath330 is even , as @xmath331 is tridivisible , and @xmath332 .",
    "we fix an arbitrary sequence @xmath333)$ ] so that each @xmath329 occurs @xmath334 times as some @xmath335 and @xmath336 times as some @xmath337 . for each @xmath201",
    "we choose @xmath338 independently uniformly at random , and let @xmath339 } ( \\{x^+_ia_ib_i\\}-\\{x^-_ia_ib_i\\})$ ] ; then @xmath313 satisfies @xmath340 .",
    "we claim that whp @xmath341 are @xmath342-bounded . to see this",
    ", we first fix any @xmath343 and estimate the expected contributions to @xmath225 from each step @xmath201 , according to whether @xmath225 contains @xmath335 , @xmath337 , or neither .",
    "each endpoint of @xmath225 occurs at most @xmath344 times as @xmath345 , and for such @xmath201 we cover @xmath225 with probability @xmath346 , so the expected contribution to @xmath347 from all such @xmath201 is at most @xmath348 . at any other step ,",
    "we cover @xmath225 with probability @xmath349 , so the total expected contribution to @xmath347 from these steps is at most @xmath325 .",
    "now , for each vertex @xmath50 , summing over its incident edges , @xmath350 are both @xmath351-dominated , so the claim holds by lemma [ dom ] .",
    "_ step 2 : _ we start by fixing an arbitrary expression @xmath352 , where each @xmath353 is a closed walk in @xmath65 with edge weights alternating between @xmath2 and @xmath267 , and there are no cancellations , i.e.  every edge appears in the sum only with weight @xmath2 or only with weight @xmath267 .",
    "as is well - known , such an expression may be found by a greedy algorithm : each @xmath353 can be obtained by following an arbitrary alternating walk on the signed elements of @xmath354 until we return to our starting point using an edge with the opposite sign to that of the first edge , whereupon we add @xmath355 to @xmath354 and repeat the procedure .",
    "( we note that this argument leads to a convenient shortcut for triangle decompositions , but does not generalise to hypergraph decompositions . )",
    "next we express each @xmath356 as a sum of signed four - cycles in the complete graph @xmath22 on @xmath81 , where we write each closed walk of length @xmath357 as a chain of @xmath358 signed four - cycles , using the identity ( see figure 1 ) @xmath359 this identity can be used as is if @xmath360 for @xmath361 $ ] . for each @xmath201 such that @xmath362 , we note that @xmath363 , @xmath364 , @xmath365 , and @xmath366 , so we can replace the four - cycles for summands @xmath367 and @xmath201 by @xmath368 thus we can write @xmath369 , where each summand is a signed four - cycle in @xmath22 . furthermore , the above construction has the property that for each @xmath48 and @xmath370 we use at most @xmath371 edges at @xmath50 with weight @xmath372 .    for each @xmath373",
    "we choose @xmath374 independently uniformly at random , and add @xmath375 to @xmath376 ; then @xmath377 .",
    "let @xmath378 denote the multigraph formed by summing @xmath379 over all such @xmath353 .",
    "for any @xmath343 , at most @xmath380 elements of @xmath381 can contribute to @xmath382 , so @xmath383 .",
    "then for any @xmath50 , summing over its incident edges , @xmath384 is @xmath385-dominated , so by lemma [ dom ] ( modified ) whp @xmath378 is @xmath386-bounded .",
    "defining @xmath311 , we have @xmath308 and @xmath309 is @xmath310-bounded .        to obtain * hole * , we will modify @xmath269 using the following ` octahedral ' configurations ( see figure 2 ) .",
    "consider a copy of @xmath387 , the complete tripartite graph with @xmath119 points in each part , with parts @xmath388 for @xmath389 $ ] .",
    "we denote its triangles by @xmath390 , where @xmath391\\}$ ] .",
    "the sign of @xmath392 is @xmath393 .",
    "thus each edge is in one triangle of each sign . defining @xmath394",
    ", we see that @xmath395 .",
    "this gives a method to eliminate any signed triangle @xmath93 from @xmath269 without altering @xmath396 : we add some copy of @xmath397 with the opposite sign to @xmath93 in which ( say ) @xmath398 , thus replacing @xmath93 by seven other signed triangles that have the same total @xmath119-shadow .",
    "similarly ( and more importantly ) , we can eliminate any pair of triangles @xmath399 that have opposite sign and share an edge @xmath225 , replacing @xmath399 by six other signed triangles that have the same total @xmath119-shadow and do not use @xmath225 .",
    "we apply this method in the following two - phase algorithm .",
    "_ octahedral elimination algorithm ( phase i ) .",
    "_ we eliminate all triangles in @xmath269 , according to a random greedy algorithm , where in each step we consider some original signed element @xmath93 of @xmath269 , and choose an octahedral configuration @xmath400 to replace @xmath93 .",
    "we refer to edges of @xmath400 not in @xmath93 as _ new _ edges , and choose @xmath400 uniformly at random subject to the new edges belonging to @xmath65 and being disjoint from @xmath309 and all new edges from previous steps .",
    "let @xmath401 denote the result of phase i ( if it does not abort ) .",
    "then @xmath402 , and we can write @xmath403 , where @xmath378 is the graph of new edges , and every signed element of @xmath401 contains at most one edge of @xmath309 .",
    "_ octahedral elimination algorithm ( phase ii ) .",
    "_ we replace all signed edges apart from those in @xmath88 and @xmath378 . to do this",
    ", we fix a sequence @xmath404 of pairs of signed elements of @xmath401 , so that ( i ) for each @xmath405 , there is some @xmath406 such that @xmath93 and @xmath407 both contain @xmath225 , and @xmath93 and @xmath407 have opposite signs , and ( ii ) the multiset consisting of all @xmath225 as in ( i ) is @xmath408 .",
    "now we eliminate each @xmath405 , according to a random greedy algorithm , by subtracting some copy @xmath409 of @xmath397 with @xmath398 and @xmath410 , or vice versa , depending on the signs .",
    "we refer to edges of @xmath409 not in @xmath93 or @xmath407 as _ new _ edges , and choose @xmath409 uniformly at random subject to the new edges belonging to @xmath65 and being distinct from @xmath411 and all new edges from previous steps .",
    "let @xmath412 denote the result of this algorithm ( if it does not abort ) and @xmath413 the graph of new edges for phase ii",
    ". then @xmath414 and @xmath415 .",
    "this implies @xmath416 for any @xmath303 , and @xmath417 for all @xmath305 , so @xmath418 , where @xmath70 and @xmath71 are as in * hole * , once we have verified the boundedness condition .",
    "whp the octahedral elimination algorithm produces @xmath70 and @xmath71 as in * hole*.    * proof .",
    "* we first show that whp @xmath378 is @xmath419-bounded , where @xmath420 .",
    "the proof follows the discussion after the proof of lemma [ cover - leave ] , where a configuration for @xmath93 consists of the new edges of some @xmath400 . by lemma [ ext ] , at each step , the number of choices of @xmath400 with all new edges belonging to @xmath65 ( with no excluded configurations ) is @xmath421 . assuming that the graph of previous new edges is @xmath419-bounded ,",
    "as @xmath309 is @xmath422-bounded , the number of excluded configurations is at most @xmath423 , which is less than half of the total .",
    "next , for each @xmath141 , we consider separately the contributions to @xmath231 , according to whether @xmath225 intersects @xmath93 in @xmath424 or @xmath2 vertex ( there is no contribution to new edges from triangles containing @xmath225 ) .",
    "there are at most @xmath425 signed elements of @xmath269 that intersect @xmath225 in @xmath2 vertex .",
    "for each of these , a random configuration covers @xmath225 with probability at most @xmath426 , so the total contribution to @xmath231 from such elements is at most @xmath427 .",
    "also , @xmath269 has at most @xmath428 signed elements , and for each one that is disjoint from @xmath225 the contribution to @xmath231 is at most @xmath429 , so the total contribution from such elements is at most @xmath430 .",
    "we obtain @xmath431 , which implies the claimed bound on @xmath378 .",
    "next we claim that whp @xmath413 is @xmath432-bounded , where @xmath433 .",
    "the argument is very similar to that given for @xmath378 . now",
    "a configuration for @xmath434 consists of the new edges of some @xmath409 . by lemma [ ext ] , at each step , the number of choices of @xmath409 with all new edges belonging to @xmath65 ( with no excluded configurations ) is @xmath435 . assuming that the graph of previous new edges is @xmath432-bounded ,",
    "as @xmath411 is @xmath436-bounded , the number of excluded configurations is at most @xmath437 , which is less than half of the total .",
    "next , for each @xmath141 , we consider separately the contributions to @xmath231 according to whether @xmath225 intersects @xmath438 in @xmath424 or @xmath2 vertex ( there is no contribution to new edges if @xmath439 ) .",
    "first we consider those @xmath405 that intersect @xmath225 in @xmath2 vertex @xmath288 .",
    "there are two choices for @xmath440 .",
    "if @xmath441 then there are at most @xmath442 choices for @xmath443 , which determines @xmath93 and @xmath407 . if @xmath444 then there are at most @xmath445 choices for @xmath93 , and so @xmath407 . the same bound applies if @xmath446 , so there are at most @xmath447 such @xmath434",
    "each contributes at most @xmath448 to @xmath231 , so the total contribution from such @xmath434 is at most @xmath449 .",
    "also , @xmath450 , and for each @xmath405 with @xmath451 the contribution to @xmath231 is at most @xmath452 , so the total contribution from such elements is at most @xmath453 .",
    "we obtain @xmath454 , which implies the claimed bound on @xmath413 . recalling that @xmath455 and @xmath456 we see that @xmath457 is @xmath67-bounded , so we have the required properties for * hole*.",
    "for * completion * , we divide the analysis into two parts .",
    "firstly , we will determine what conditions on @xmath72 and @xmath73 enable us to find @xmath74 and @xmath75 .",
    "secondly , we will show that the sets @xmath59 , @xmath70 and @xmath71 from * cover * and * hole * can be modified to give @xmath72 and @xmath73 satisfying the required conditions . for convenient notation",
    "we suppress the embedding @xmath458 whenever we do not need to refer to it , instead thinking of @xmath81 as a subset of @xmath112 .",
    "suppose we have a set @xmath73 of edge - disjoint triangles in @xmath65 , and we want to find sets @xmath74 and @xmath75 of edge - disjoint triangles in @xmath65 such that @xmath78 , @xmath79 and @xmath80 .",
    "our basic building blocks ( ` shuffles ' ) will be edge - disjoint subgraphs of @xmath65 , each having two different triangle decompositions , one only using triangles in @xmath53 , and the other including any specified triangle of @xmath73",
    ". then the unions over all blocks of the two triangle decompositions will give @xmath74 and @xmath75 as required .",
    "we define the shuffles as follows .",
    "fix @xmath459 and @xmath460 such that @xmath461 is linearly independent over @xmath115 .",
    "let @xmath462 be the subspace of @xmath112 generated by @xmath463 .",
    "the @xmath464-shuffle @xmath465 is the complete tripartite graph with parts @xmath466 , @xmath467 $ ] , where @xmath468 .",
    "if @xmath469 then it has a triangle decomposition @xmath470 only using triangles in @xmath53 : take all triangles @xmath471 where each @xmath472 and @xmath473 .",
    "we define another triangle decomposition @xmath474 of @xmath465 by translating each triangle of @xmath470 by @xmath475 , i.e.  @xmath474 consists of all triangles @xmath471 where each @xmath472 and @xmath476 .    to construct @xmath74 and @xmath75 ,",
    "we choose shuffles according to a random greedy algorithm , where in each step we consider some @xmath477 , and choose some shuffle @xmath469 such that @xmath478 for all @xmath467 $ ] .",
    "we will see in lemma [ shuffle - count ] that the randomised algebraic construction is whp such that there are many choices for such a shuffle .",
    "this is the most important property of the construction , and it would not hold if we had chosen the template to be a uniformly random set of edge - disjoint triangles ; in fact the expected number of shuffles ( or any ` shuffle - like ' configuration ) would be @xmath479 .",
    "first we identify a property that we need for triangles in @xmath73 so that the required shuffles exist and can be chosen to be edge - disjoint .",
    "we say that @xmath480 is _ octahedral _ if @xmath481 and there is a copy @xmath482 of @xmath387 in @xmath0 such that @xmath483 has parts @xmath484 , @xmath485 and @xmath486 ; we call @xmath482 the _ associated octahedron _ of @xmath480 .",
    "we assume    * all triangles in @xmath73 are octahedral , with edge - disjoint associated octahedra .",
    "[ shuffle - count ] under the random choice of @xmath147 used in the definition of @xmath53 , whp for any octahedral @xmath480 there are @xmath487 shuffles @xmath469 such that @xmath488 for @xmath467 $ ] .",
    "* we can write the number of such shuffles as a sum of indicator variables @xmath489 , where the sum ranges over all @xmath490 such that @xmath491 is a copy of @xmath492 in @xmath0 containing the associated octahedron @xmath482 of @xmath480 , @xmath493 is a bijective labelling of each part of @xmath491 by @xmath494 , we let @xmath495 be the event that @xmath496 for all @xmath467 $ ] and @xmath372 in the @xmath201th part of @xmath491 , and we assume @xmath493 is consistent with @xmath482 , in that @xmath497 and @xmath498 for @xmath499 $ ]",
    ".    as @xmath0 is @xmath120-typical , there are @xmath500 choices of @xmath501 .",
    "there are @xmath502 choices of @xmath503 , which determines @xmath288 given @xmath86 , as only @xmath153 choices of @xmath503 are excluded by the condition that @xmath461 is linearly independent over @xmath115 : there are @xmath166 possible linear relations between them , and each such relation is linearly independent or contradictory to the system @xmath488 for @xmath467 $ ] ( as @xmath481 ) , so is satisfied by at most @xmath504 choices of @xmath503 . given @xmath490 , conditional on @xmath505 , we have @xmath506",
    ". therefore @xmath507 .",
    "also , any transposition @xmath212 of @xmath147 affects @xmath287 by at most @xmath508 . to see this",
    ", we estimate the number of shuffles containing @xmath480 and any fixed @xmath509 .",
    "consider any @xmath389 $ ] , @xmath510 , and the equations @xmath511 and @xmath488 for @xmath467 $ ] in @xmath512 .",
    "we have four linearly independent constraints , so there are at most @xmath504 solutions .",
    "including multiplicative factors for @xmath201 , @xmath129 and @xmath212 gives the required bound .",
    "now by lemma [ lip2 ] whp @xmath513 .      we digress to note a more general estimate for future reference .",
    "suppose @xmath244 is a graph , @xmath514)$ ] are variables , and for all @xmath515 we have distinct linear forms @xmath516 for some @xmath517 and @xmath518 $ ] .",
    "we call @xmath519 a _ linear extension _ with _ base _ @xmath520 .",
    "let @xmath251 be the number of _",
    "@xmath69-embeddings _ of @xmath244 , i.e.  embeddings @xmath248 of @xmath244 in @xmath65 such that for some @xmath521 we have @xmath522 for all @xmath515 .",
    "the above argument ( see also ( * ? ? ?",
    "* lemma 5.15 ) ) gives the following formula analogous to that obtained for shuffles .",
    "[ linext ] let @xmath519 be a @xmath254-degenerate linear extension with @xmath246 .",
    "suppose    * @xmath244 has a triangle decomposition @xmath523 such that for each @xmath524 we have @xmath525 , * the incidence matrix of @xmath526 has full column rank @xmath527 .",
    "then @xmath528| } { \\gamma}^{|v(h ) { \\setminus}f| } 2^{ga}.\\ ] ]      recalling our general framework for random greedy algorithms , we want to show that , of the potential shuffles @xmath465 with @xmath488 for @xmath467 $ ] , at most half are excluded due to sharing an edge with a previous shuffle , assuming some boundedness condition on the graph @xmath378 of new edges from previous shuffles .",
    "we classify the potential restrictions according to the label of the shuffle edge involved , which is specified by some @xmath529 $ ] and @xmath530 such that @xmath531 or @xmath532 ( here we do not consider edges of the associated octahedra : these are already determined , and edge - disjoint by ( p1 ) . ) for any @xmath533 , the shuffles excluded because of mapping the given labelled shuffle edge to @xmath534 are given by the @xmath535-solutions of the system @xmath404 of equations @xmath536 , @xmath537 and @xmath488 for @xmath467 $ ]",
    ". there may be @xmath424 , @xmath2 or @xmath504 solutions .",
    "we can ignore the case of @xmath424 solutions , as it does not exclude anything . for the cases with @xmath2 solution",
    ", we can bound the number of excluded choices by the number of edges covered by all shuffles , which is @xmath538 .",
    "it remains to consider the case that @xmath404 has @xmath504 solutions , which occurs when one of the equations is redundant , due to being a linear combination of the other equations .",
    "there are a constant number of linear combinations , and each constrains @xmath539 to lie on a line , as may be seen from general considerations of linear algebra , or simply by enumerating the possibilities : wlog @xmath537 is redundant , due to    a.   @xmath540 and @xmath541 , b.   @xmath542 and @xmath543 , c.   @xmath544 and @xmath545 , d.   @xmath546 and @xmath547 , where @xmath548=\\{i , j , k\\}$ ] .    in cases ( i ) and ( ii ) where @xmath549 is fixed , assuming that @xmath378 is @xmath550-bounded , there are at most @xmath551 choices for @xmath552 such that @xmath553 . in cases ( iii ) and",
    "( iv ) we need an additional boundedness condition :    we say that @xmath378 is _ linearly @xmath550-bounded _ if @xmath378 is @xmath550-bounded and also contains at most @xmath554 edges from any line of the form @xmath555 .",
    "we also need similar conditions so that we can avoid the associated octahedra ; writing @xmath556 for the union of all associated octahedra of triangles in @xmath73 , we will ensure that    * @xmath556 is linearly @xmath557-bounded .",
    "then the total number of excluded shuffles is at most @xmath558 , which is less than half of the total .",
    "next we fix @xmath141 and estimate @xmath231 . to do so , we fix @xmath559 as above , write @xmath560 and estimate the sum over @xmath477 of the probability @xmath561 that a random shuffle @xmath465 with @xmath488 for @xmath467 $ ] satisfies @xmath536 and @xmath537 .",
    "for fixed @xmath480 , if the system @xmath404 as above has @xmath55 solutions then @xmath562 . when @xmath563 the total contribution is at most @xmath564 .",
    "if @xmath565 then @xmath566 is constrained to lie in a certain plane ( this can be seen by linear algebra , or by considering each possibiity as above : e.g.  in case ( iii ) the plane is @xmath545 ) .",
    "thus we see the final property that we need from @xmath73 :    * @xmath73 contains at most @xmath567 elements @xmath480 from any _ basic plane _ of the form @xmath568 where @xmath569 .",
    "( note that by ( p1 ) we can assume @xmath570 in ( p3 ) . )",
    "then the total contribution is at most @xmath571 . summing over @xmath572 , @xmath573 and @xmath574",
    ", we can estimate @xmath575 .",
    "applying lemma [ dom ] as in the proof of lemma [ cover - leave ] , we deduce that whp the boundedness assumptions on @xmath378 used above do not fail ( linear boundedness follows in the same way as boundedness ) , and so the algorithm does not abort .",
    "this completes the analysis of the first part of * completion * : given @xmath72 and @xmath73 as in * completion * , under the conditions ( p1p3 ) on @xmath73 , we can find @xmath74 and @xmath75 as in * completion*.      to complete the proof of * completion * , and so of the theorems , it remains to show that we can find @xmath72 and @xmath73 satisfying the conditions ( p1p3 ) .",
    "we apply a similar two - phase algorithm to that used in * hole*.    _ phase i. _ we start with @xmath576 , so @xmath577 , @xmath578 , @xmath579 .",
    "next we eliminate all triangles in @xmath269 according to a random greedy algorithm , where in each step we consider some original signed element @xmath93 of @xmath269 , and choose an octahedral configuration @xmath400 to replace @xmath93 .",
    "we say that a triangle @xmath407 of @xmath400 is _ far _ if @xmath580 , and that @xmath400 is _ valid _ if ( i ) none of its triangles are template triangles , with the possible exception of @xmath93 , and ( ii ) all of its far triangles are octahedral , and their associated octahedra share edges only in @xmath400 , in which case we denote their union by the extended configuration @xmath581 .",
    "we say that an edge of @xmath581 not in @xmath93 is _ new _ , and choose a valid @xmath400 uniformly at random subject to the new edges being distinct from all new edges from previous steps .",
    "let @xmath401 denote the result of phase i ( if it does not abort ) .",
    "we have @xmath582 , and writing @xmath378 for the graph of new edges , every signed element of @xmath401 is either a far triangle consisting of three edges of @xmath378 , or is not far and consists of two edges of @xmath378 and one edge of @xmath309 .    _",
    "_ now we will eliminate all triangles of @xmath401 apart from those that contain an edge of @xmath69 or were far in the previous modification procedure .",
    "we partition all such triangles into a sequence @xmath404 of pairs of signed elements of @xmath401 , so that for each @xmath405 , there is some @xmath406 such that @xmath93 and @xmath407 both contain @xmath225 , and @xmath93 and @xmath407 have opposite signs .",
    "we eliminate each @xmath405 , according to a random greedy algorithm , by subtracting some copy @xmath409 of @xmath397 with @xmath398 and @xmath410 , or vice versa , depending on the signs .",
    "now we say that @xmath409 is _ valid _ if all of its triangles apart from @xmath93 and @xmath407 are octahedral , and their associated octahedra share edges only in @xmath409 , in which case we denote their union by the extended configuration @xmath583 .",
    "we refer to edges of @xmath583 not in @xmath93 or @xmath407 as _ new _ edges , and choose a valid @xmath409 uniformly at random subject to the new edges being distinct from @xmath378 and all new edges from previous steps .",
    "let @xmath412 denote the result of this algorithm ( if it does not abort ) and @xmath413 the graph of new edges for phase ii .",
    "since @xmath584 , defining @xmath585 and @xmath586 , we see that @xmath587 and @xmath588 , so @xmath76 is a partition of @xmath77 .",
    "the following lemma completes the proof of * completion * , and so of the theorems , under the assumption that @xmath0 is @xmath120-typical .",
    "whp @xmath73 satisfies ( p1 ) , ( p2 ) and ( p3 ) .",
    "* to analyse phase i , we first estimate the number of choices for an extended configuration on a triangle @xmath93 .",
    "this can be described by the linear extension @xmath589 , where @xmath581 is as above , we have variables @xmath590 , which we also use to label the vertices of @xmath591 , we define @xmath592 for all @xmath593 , and define @xmath594 for all other @xmath288 as required for the far triangles in @xmath400 to be octahedral , i.e.   in the associated octahedron for a triangle @xmath595 , the linear forms on the two vertices in each of the three parts are @xmath596 , @xmath597 and @xmath598 . by lemma [ linext ]",
    "whp @xmath65 is such that for any triangle @xmath93 in @xmath269 , there are @xmath599 valid choices of @xmath400 .",
    "here we also use the fact that for any triangle @xmath595 of @xmath400 other than @xmath93 there are only @xmath600 solutions to @xmath601 .",
    "the precise exponents of @xmath17 and @xmath602 ( which are not important for the argument ) may be easily calculated from the observation that adding an octahedron to a triangle adds @xmath3 new vertices and @xmath603 new edges , and @xmath581 is the composition of @xmath604 such extensions .",
    "next we claim that whp the graph @xmath378 of new edges is linearly @xmath605-bounded , where @xmath606 .",
    "we assume this bound on the current graph of new edges and estimate how many configurations are excluded .",
    "consider any edge @xmath607 of the extended configuration .",
    "suppose first that @xmath608 .",
    "if @xmath609 is not constant , then for any @xmath610 the number of @xmath69-embeddings with @xmath611 and @xmath612 is at most @xmath504 .",
    "there are at most @xmath613 choices for a previous new edge @xmath614 , so this excludes at most @xmath615 configurations . on the other hand ,",
    "if @xmath609 is constant , then @xmath616 and @xmath617 are constrained to lie on a basic line ; there are at most @xmath618 choices for @xmath614 by linear boundedness , and each such @xmath614 excludes at most @xmath600 configurations .",
    "the latter estimate also applies to the case when one of @xmath619 or @xmath620 is in @xmath93 . summing these bounds over all @xmath607 , we see that fewer than half of the total configurations are excluded .",
    "next we fix any edge @xmath607 of the extended configuration , any @xmath610 , and estimate the sum over @xmath621 of the probability @xmath561 that a random configuration satisfies @xmath611 and @xmath612 .",
    "if @xmath608 and @xmath609 is not constant , then @xmath622 for any @xmath621",
    ". there are at most @xmath623 choices for @xmath93 , so the total contribution is at most @xmath624 . otherwise , if @xmath609 is constant or one of @xmath619 or @xmath620 is in @xmath93 , then one vertex of @xmath93 is specified by @xmath625 .",
    "for example , writing @xmath626 , in the associated octahedron for @xmath627 , if @xmath628 and @xmath629 then @xmath630 is specified by @xmath625 .",
    "then there are at most @xmath631 choices for @xmath93 ( as @xmath66 is @xmath67-bounded ) . for each such @xmath93",
    "we have a contribution of at most @xmath632 , so again the total contribution is at most @xmath624 . summing these bounds over all @xmath607 we can estimate @xmath633 .",
    "applying lemma [ dom ] as in the proof of lemma [ cover - leave ] , we deduce the claimed bound on @xmath378 .",
    "we also claim that whp there are at most @xmath634 far triangles in any basic plane @xmath635 . to see this ,",
    "we first consider the contribution from the template triangles @xmath636 .",
    "since @xmath637 is linearly independent or contradictory to the defining equation of @xmath638 we have @xmath639 . summing @xmath640 over an edge @xmath614 in each triangle of @xmath641 , by lemma [ dom ] whp @xmath638 contains at most @xmath618 template triangles .",
    "now fix any far non - template triangle @xmath407 of the extended configuration , any @xmath642 , and estimate the sum over @xmath621 of the probability @xmath561 that a random configuration satisfies @xmath643 . if @xmath644 then as @xmath407 is non - template it determines the configuration , so @xmath645 , giving a total contribution of at most @xmath646 .",
    "otherwise , @xmath407 determines one of the associated octahedra , so specifies one vertex of @xmath93 , for example , writing @xmath626 , if @xmath647 then @xmath630 is specified .",
    "then there are at most @xmath631 choices for @xmath93 ; for each such @xmath93 we have @xmath648 , so again the total contribution is at most @xmath646 . summing over @xmath407 and applying lemma [ dom ] as in the proof of lemma [ cover - leave ] , we deduce the claimed bound on @xmath638 .",
    "this completes the analysis of phase i.    to analyse phase ii , we first estimate the number of choices for an extended configuration on a pair @xmath434 .",
    "this can be described by the linear extension @xmath649 , where @xmath583 is as above , we have variables @xmath650 , which we also use to label the vertices of @xmath651 , we define @xmath592 for all @xmath652 , and define @xmath594 for all other @xmath288 as required for the triangles in @xmath409 other than @xmath93 and @xmath407 to be octahedral .",
    "the linear forms are distinct , as @xmath93 and @xmath407 are not template triangles . by lemma [ linext ]",
    "there are @xmath653 valid @xmath409 .",
    "again , the precise exponents of @xmath17 and @xmath602 are not important for the argument , but are straightforward to calculate : e.g.  @xmath602 appears with exponent @xmath654 , as @xmath409 and each of the @xmath655 associated octahedra adds @xmath3 new vertices to the extension , but @xmath20 vertices in the associated octahedra belong to the base of the extension , being the third vertex of the template triangle containing an edge in @xmath93 or @xmath407 other than @xmath225 .",
    "we claim that whp @xmath413 is linearly @xmath656-bounded .",
    "the argument is very similar to that given above for @xmath378 . assuming this bound on the current graph of new edges",
    ", one can show similarly to before that fewer than half of the total configurations are excluded .",
    "we also need to estimate the sum over @xmath621 of the probability that a random configuration satisfies @xmath611 and @xmath612 , for any @xmath607 in the extended configuration and @xmath610 . for most choices for @xmath607",
    "the required bound follows as before , but there is an additional case , namely when @xmath657 and @xmath609 is constant , it may be that no vertex of @xmath438 is specified by @xmath625 , but instead some pair ( not @xmath225 ) is constrained to lie on a basic line .",
    "for example , writing @xmath626 and @xmath658 , if @xmath659 and @xmath660 then @xmath625 specifies @xmath661 , but not @xmath129 or @xmath6 . in this case , we use the fact that @xmath378 is linearly @xmath605-bounded to see that there are at most @xmath618 choices for @xmath434 .",
    "each such @xmath434 contributes at most @xmath662 , giving a total contribution of at most @xmath663 .",
    "summing over all @xmath607 we estimate @xmath664 , so the claim follows from lemma [ dom ] .    finally , @xmath73 satisfies the conditions ( p1p3 ) : indeed , ( p1 ) holds by definition of the extended configurations and random greedy algorithms , ( p2 ) holds as @xmath665 , and ( p3 ) holds as whp @xmath412 has at most @xmath666 triangles in any basic plane : this holds for the new triangles in this algorithm by the same argument as for @xmath401 , and we may include the far triangles from the previous algorithm in this estimate .",
    "this completes the proof of * completion * , and so of theorem [ qrtri ] , under the assumption that @xmath0 is @xmath120-typical .",
    "the following modification proves the theorem under the assumption that @xmath0 is @xmath6-typical .",
    "it is well - known that @xmath0 is @xmath667-regular ( say ) in the ` szemerdi sense ' ( see e.g.  ( * ? ? ?",
    "* theorem 2.2 ) ) . for @xmath668 with @xmath155 , say that @xmath88 is _ good _ if @xmath669 , otherwise _",
    "bad_. as @xmath0 is @xmath6-typical , there are no bad sets of size @xmath2 or @xmath119 . by regularity , for @xmath670 , any good @xmath671-set",
    "is contained in at most @xmath672 bad @xmath673-sets .",
    "the proof of lemma [ template - typ ] still applies if we assume that all subsets of @xmath88 are good .",
    "thus we can avoid using bad sets with negligible changes to the calculations .",
    "in this section we sketch a proof of theorem [ nibble - deg ] , by describing how to apply the analysis of random greedy hypergraph matching by bennett and bohman @xcite ( we choose this for simplicity , but there are several other alternative approaches ) .",
    "consider the random triangle removal algorithm starting with @xmath0 rather than @xmath22 .",
    "the intuition is that after @xmath201 steps the remaining graph @xmath674 should look like a random subgraph of @xmath0 where edges are retained independently with probability @xmath675 , where @xmath676 . for any @xmath677 let @xmath678 denote the number of triangles of @xmath674 containing @xmath225 and @xmath679 denote the total number of triangles of @xmath674 . by assumption ,",
    "@xmath680 for all @xmath677 , where @xmath681 .",
    "note also that @xmath682 .",
    "we will show that for @xmath683 whp @xmath684 where @xmath685 and @xmath686 .",
    "we restrict attention to the upper bounds , as the lower bounds are similar .",
    "a convenient reformulation is to show negativity of shifted variables @xmath687 this follows whp from martingale concentration inequalities ( e.g.  @xcite ) after we verify the following ` trend ' and ` boundedness ' hypotheses , supposing that the required estimates for @xmath688 and @xmath689 hold at previous steps ( i.e.  @xmath690 , where the stopping time @xmath212 is the first step where any of the required estimates fails , or @xmath213 ) ; we use primes to denote conditional expectation given the history of the process .",
    "_ trend hypothesis : _ if @xmath691 then @xmath692 ; if @xmath693 then @xmath694 .",
    "_ boundedness hypothesis : _",
    "@xmath695 , and @xmath696 with @xmath697 and @xmath698 .",
    "we start with the boundedness hypothesis , which holds with room to spare . indeed , @xmath699 , so @xmath700 , whereas @xmath701 . also , for any @xmath702 we have @xmath703 . the change in @xmath704",
    "is @xmath705 and in @xmath706 is @xmath707 , so we can take @xmath708 and @xmath709 .",
    "then @xmath710 , whereas @xmath711 .",
    "next consider the trend hypothesis for @xmath688 .",
    "conditional on the required estimates at step @xmath201 , if @xmath691 we have @xmath712   = - q(i)^{-1 } \\sum_{e \\in g^i } t_e(i)^2 + o(1 ) \\\\ & = -9q(i)/|g|p \\pm 2|g|pe_d^2/q(i ) + o(1 ) \\\\ & \\le - 3dp^2 - 9e_q/|g|p + 9bd / p +   ( 6+o(1))e_d^2/dp^2.\\end{aligned}\\ ] ] also , as @xmath713 is increasing , the one - step change in @xmath714 is at most @xmath715 . as @xmath716",
    ", we deduce @xmath717 \\le - 9e_q/|g|p + 9bd / p + 7e_d^2/dp^2 \\\\ & \\le -18(1 - 3\\log p)^2",
    "bd / p + 9bd / p + 28(1 - 3\\log p)^2 b^{4/3}d / p^2 \\le 0.\\end{aligned}\\ ] ]    now consider the trend hypothesis for @xmath689 .",
    "conditional on the required estimates at step @xmath201 , if @xmath693 we have @xmath718 = - q(i)^{-1 } t_e(i ) 2(dp^2 \\pm e_d   + o(1 ) ) \\\\ & \\le - 2q(i)^{-1}(dp^2+e_d - b^{2/3}d ) ( dp^2-e_d - o(1 ) ) \\\\ & \\le - 6(dp^2)^2/|g|dp^3 + ( 6+o(1))(b^{2/3}d)(dp^2)/|g|dp^3 + o(e_q/|g|^2p^2).\\end{aligned}\\ ] ] also , the one - step change in @xmath719 is at most @xmath720 , and in @xmath721 is at most @xmath722 .",
    "we deduce @xmath723 \\le -10b^{2/3}d/|g|p +   o(\\log^2 p ) bd/|g|p^2 \\le 0.\\ ] ]    thus the required estimates hold , i.e.  for @xmath683 whp @xmath724 and @xmath725 for all @xmath702 .",
    "now we apply the same method to deduce the boundedness conclusion of theorem [ nibble - deg ] . for @xmath683",
    "we show whp @xmath726 where @xmath727 . the upper bound",
    "@xmath728 will follow whp after we verify the following two conditions .",
    "_ trend hypothesis : _ if @xmath729 then @xmath730 .",
    "_ boundedness hypothesis : _",
    "@xmath731 with @xmath697 and @xmath732 .    for the boundedness hypothesis",
    ", we can take @xmath733 and @xmath734 , so @xmath735 , whereas @xmath736 .",
    "for the trend hypothesis , if @xmath729 we have @xmath737 = - \\sum_{e : v \\in e \\in g^i } t_e(i)/q(i ) \\\\ & \\le - ( p|g(v)|+e_v - b^{1/3}d(g)n)(dp^2-e_d)/(|g|dp^3/3+e_q ) \\\\ & \\le -3|g(v)|/|g| - 3(e_v - b^{1/3}d(g)n)/|g|p + o(e_d ) \\tfrac{|g(v)|}{|g|dp^2 } + o(e_q ) \\tfrac{|g(v)|}{|g|^2dp^3}.\\end{aligned}\\ ] ] the one - step change in @xmath738 is at most @xmath739 , so @xmath740   \\le -6b^{1/3 } + o(e_d / dp ) + o(e_q/|g|dp^2 ) \\le 0,\\ ] ] as @xmath741 , @xmath742 and @xmath716 .",
    "thus , letting @xmath55 be the set of triangles removed during the process , whp @xmath185 is @xmath186-bounded .",
    "in this section we generalise theorem [ wilson - conj ] to estimate the number of designs . we start by describing the results of @xcite on the existence of designs .",
    "let @xmath743 be a @xmath744-graph ( i.e.  a set of subsets of size @xmath744 ) of a set @xmath287 of size @xmath1 .",
    "we say that @xmath743 is a _",
    "design _ with parameters @xmath745 if every subset of @xmath287 of size @xmath746 belongs to exactly @xmath747 elements of @xmath88 .",
    "note that if @xmath748 , @xmath749 , @xmath750 then @xmath743 is a steiner triple system .",
    "the necessary divisibility conditions generalise in a straightforward way : if @xmath743 exists then @xmath751 must divide @xmath752 for every @xmath753 ; to see this , fix any @xmath201-subset @xmath754 of @xmath287 and consider the sets in @xmath743 that contain @xmath754 .",
    "in @xcite we proved the ` existence conjecture ' , which states that these divisibility conditions are also sufficient for the existence of a design with parameters @xmath745 , assuming @xmath755 are fixed and @xmath756 is large .",
    "we will generalise theorem [ wilson - conj ] as follows .",
    "[ count ] for any @xmath755 there is @xmath757 such that if @xmath182 and @xmath758 for all @xmath753 , writing @xmath759 and @xmath760 , the number @xmath761 of designs with parameters @xmath745 satisfies @xmath762    the proof of theorem [ count ] follows that of theorem [ wilson - conj ] : the lower bound generalises the argument given earlier in this paper , and the upper bound generalises that of linial and luria @xcite .",
    "we start with the lower bound . in the same way as a steiner triple system",
    "can be viewed as a triangle decomposition of @xmath22 , we can view a design with parameters @xmath745 as a @xmath763-decomposition of @xmath764 , where @xmath763 denotes the complete @xmath746-graph on @xmath744 vertices and @xmath764 denotes the multi(hyper)graph in @xmath765 in which each edge has multiplicity @xmath747 . to generalise theorem [ qrtri ]",
    ", we first need to define the divisibility and typicality conditions for general @xmath746-graphs ( we will omit multiplicities in the definitions , as we do not need them for our application here ) .    for @xmath668 ,",
    "the _ neighbourhood _ @xmath766 is the @xmath767-graph @xmath768 .",
    "we say that @xmath0 is _",
    "@xmath763-divisible _ if @xmath751 divides @xmath769 for any @xmath201-set @xmath770 , for all @xmath771 .",
    "we say that @xmath0 is _",
    "@xmath116-typical _ if there is some @xmath772 such that for any set @xmath271 of @xmath773-subsets of @xmath81 with @xmath774 we have @xmath775 .",
    "now we can state the @xmath746-graph generalisation of theorem [ qrtri ] .",
    "when @xmath17 is at least a constant independent of @xmath1 this follows from ( * ? ? ?",
    "* theorem 1.4 ) ; the same proof shows that @xmath17 can decay polynomially in @xmath1 .",
    "[ hyp - decomp ] for any @xmath776 there are @xmath777 and @xmath778 so that if @xmath14 and @xmath0 is a @xmath763-divisible @xmath116-typical @xmath746-graph on @xmath1 vertices with @xmath779 and @xmath780 then @xmath0 has a @xmath763-decomposition .    in the proof of theorem [ count ] it is more convenient to count designs together with a choice for each @xmath781 of a bijection between the @xmath747 copies of @xmath225 in @xmath764 and the @xmath747 sets of the design containing @xmath225",
    "; we will refer to such a structure as an _ edge - labelled design _ with parameters @xmath745 and denote their number by @xmath782 .",
    "as @xmath783 , it suffices to show @xmath784    * proof of theorem [ count ] .",
    "* for the lower bound we start by setting aside a random subgraph @xmath785 of @xmath765 in which each edge is chosen with probability @xmath786 , where we can apply theorem [ hyp - decomp ] with @xmath630 and @xmath493 , and we suppose without loss of generality that @xmath787 ( i.e.  parameters are chosen from left to right to satisfy various inequalities below ) .",
    "next we will consider the random greedy matching process in the following auxiliary hypergraph @xmath271 .",
    "we let @xmath788 consist of @xmath747 copies of each edge of @xmath789 and @xmath790 copies of each edge of @xmath785 .",
    "we let @xmath791 consist of all @xmath792-sets in @xmath788 that are edge - sets of a copy of @xmath763 in @xmath765 .    in the random greedy matching process",
    ", we start with @xmath271 , and at each step we select a uniformly random edge @xmath225 of the current hypergraph , then delete all vertices of @xmath225 ( and all incident edges ) to obtain the hypergraph for the next step .",
    "we stop the process when fewer than @xmath793 vertices of @xmath271 remain and let @xmath69 denote the multigraph in @xmath765 consisting of the remaining vertices of @xmath271 . similarly to the previous section , one can adapt the analysis of bennett and bohman @xcite to show that whp ( i ) when @xmath794 edges remain the number of choices for the next edge of the process is @xmath795 , and ( ii ) @xmath796 for any @xmath773-set @xmath797 $ ] .",
    "next we apply a random greedy algorithm to sequentially cover each edge of @xmath69 by a copy of @xmath763 in which all other edges are in @xmath785 ; as usual , at each step we make a uniformly random choice subject to not using any previously covered edge .",
    "the proof of lemma [ cover - leave ] generalises to show that whp the algorithm does not abort , and writing @xmath88 for the subgraph of @xmath785 covered by the algorithm , whp @xmath798 for any @xmath773-set @xmath797 $ ] . by chernoff bounds",
    "whp @xmath785 is @xmath799-typical . also whp @xmath800 , so @xmath801 is @xmath802-typical with @xmath803 .",
    "furthermore , @xmath804 was obtained from @xmath764 by deleting edge - disjoint copies of @xmath763 , and @xmath764 is @xmath763-divisible by assumption , so @xmath804 is @xmath763-divisible",
    ". therefore @xmath804 has a @xmath763-decomposition by theorem [ hyp - decomp ] .",
    "combining this with the previous choices of @xmath763 s we have constructed an edge - labelled design with parameters @xmath745 ( the vertices of @xmath271 specify the edge - labelling ) .",
    "now we may calculate similarly to the proof of theorem [ wilson - conj ] .",
    "writing @xmath39 for the number of steps in the random greedy matching process , and @xmath805 for the approximate density at the @xmath201th step , the logarithm of the number of choices is @xmath806 also , for any fixed design , the logarithm of the number of times it is counted is at most @xmath807 as @xmath808 we deduce @xmath809    for the upper bound in theorem [ count ] we apply the entropy method , following the argument of linial and luria @xcite for steiner triple systems ( see their paper for motivation and exposition of the method ) .",
    "we let @xmath287 be a uniformly random edge - labelled design with parameters @xmath745 , and consider the entropy @xmath810 ( using natural logarithms ) .",
    "we have @xmath811 , so it suffices to estimate @xmath812 .",
    "we consider the labelled edges of @xmath764 in a uniformly random order : it is convenient to select @xmath813^{{\\lambda}k^r_n}$ ] uniformly at random , and to proceed by decreasing order of @xmath814 . at each step ,",
    "when we consider @xmath225 , we reveal the block @xmath815 of @xmath287 that contains @xmath225 and is assigned to @xmath225 according to the edge - labelling .",
    "conditional on @xmath816 , we have @xmath817    we estimate @xmath818 , where @xmath819 is the size of the support of the random variable @xmath820 , i.e.  @xmath821 if @xmath225 is a labelled edge of @xmath822 for some @xmath823 that precedes @xmath225 , otherwise @xmath819 is the number of choices of a labelled @xmath744-set @xmath93 containing @xmath225 ( i.e.  we fix labellings of the other @xmath824 edges in @xmath93 ) such that for each such labelled edge @xmath823 in @xmath93 , no labelled edge of the block @xmath822 precedes @xmath225 .",
    "next we condition on @xmath287 , fix @xmath225 , and write @xmath825 for the event that @xmath826 for all @xmath827 .",
    "we estimate @xmath828 , where the expectation is with respect to @xmath816 , and we suppress the @xmath287-conditioning in our notation .",
    "we have @xmath829 ) = { \\mathbb{e } } ( \\mu_e^{q-1 } { \\mathbb{e } } [ \\log n^\\mu_e \\mid \\mu_e , f_e])\\ ] ] and by jensen s inequality @xmath830 \\le \\log { \\mathbb{e } } [ n^\\mu_e \\mid \\mu_e , f_e]$ ] .",
    "now we write @xmath831 = 1 + \\sum_f { \\mathbb{p}}[e_f \\mid \\mu_e , f_e]$ ] , where the sum is over all labelled @xmath744-sets @xmath832 containing @xmath225 , and @xmath833 is the event that for each labelled edge @xmath823 in @xmath93 , no labelled edge of the block @xmath822 precedes @xmath225 .",
    "note that there are only @xmath834 such @xmath93 with @xmath835 for some block @xmath407 of @xmath287 .",
    "for any other such @xmath93 we have @xmath836 = \\mu_e^{q(q-1)}$ ] .",
    "we deduce @xmath831 = \\mu_e^{q(q-1 ) } { \\lambda}^{q-1 } n + o(n / n)$ ] .",
    "finally , @xmath837 \\\\ & = { \\lambda}\\tbinom{n}{r } \\int_0 ^ 1 t^{q-1 } \\log ( t^{q(q-1 ) } { \\lambda}^{q-1 } n ) + o(1/n ) \\ dt .",
    "\\end{aligned}\\ ] ] for any @xmath838 we have @xmath839 . setting @xmath840 , @xmath841 , @xmath842 we deduce @xmath843",
    "although we have proved ( and generalised ) wilson s conjecture , one may still ask for more precise estimates ( even an asymptotic formula ) for the number of steiner triple systems , and more generally designs .",
    "such results have been obtained by kuperberg , lovett and peled @xcite , using very different methods to ours , but only for designs within a certain range of parameters .",
    "one open case of particular interest ( recently drawn to my attention by ron peled ) is the problem of estimating the number @xmath844 of @xmath845-regular graphs on @xmath1 vertices .",
    "these may be viewed as designs with parameters @xmath846 , for which our methods give @xmath847 .",
    "much more precise results have been obtained by mckay and wormald , including asymptotic enumeration for @xmath848 ( see @xcite ) and @xmath849 ( see @xcite ) ; their conjecture in @xcite regarding a general asymptotic formula remains open ."
  ],
  "abstract_text": [
    "<S> we give estimates on the number of combinatorial designs , which prove ( and generalise ) a conjecture of wilson from 1974 on the number of steiner triple systems . </S>",
    "<S> this paper also serves as an expository treatment of our recently developed method of randomised algebraic construction : we give a simpler proof of a special case of our result on clique decompositions of hypergraphs , namely triangle decompositions of quasirandom graphs . </S>"
  ]
}