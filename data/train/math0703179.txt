{
  "article_text": [
    "this paper proposes a general solution method of stochastic impulse control problems for one dimensional diffusion processes .",
    "stochastic impulse control problems have attracted a growing interest of many researchers for the last two decades . under a typical",
    "setting , the controller faces some underlying process and reward / cost structure . there exist continuous and instantaneous components of reward / cost functions . by exercising impulse controls ,",
    "the controller moves the underlying process from one point to another . at the same time",
    ", the controller receives rewards associated with the instantaneous shifts of the process .",
    "then the controller s objective is to maximize the total discounted expected net income .",
    "the mathematical framework to these types of problems is in bensoussan and lions @xcite .",
    "impulse control has been studied widely in inventory control ( harrison et al .",
    "@xcite ) , exchange rate problem ( jeanblanc - picqu @xcite , mundaca and ksendal @xcite , cadenillas and zapatero @xcite ) , dividend payout problems ( jeanblac - picqu and shiryaev @xcite ) , and portfolio optimization with transaction costs ( korn @xcite , morton and pliska @xcite ) .",
    "korn @xcite surveys the applications in mathematical finance . also see chancelier et al.@xcite for a combination of optimal stopping and impulse control problems .",
    "in many economic and financial applications where the controlled process is described as an it diffusion , the solution to the problem demands a through study of a related hamilton - jacobi - bellman equation and quasi - variational inequalities . the method of quasi - variational inequalities split by a guess the state space into intervention and no intervention ( continuation ) regions . one guesses the form of ( a ) continuation region , ( b ) associated optimal policy , and",
    "( c ) the value function",
    ". then optimality of the candidate policy must be verified .",
    "both steps are often very difficult and the success depends heavily on the form of the controlled process , reward and cost functions .",
    "alternatively , an impulse control problem can be viewed as a sequence of optimal stopping problems .",
    "the connection between impulse control and optimal stopping has been investigated by davis @xcite and ksendal and sulem @xcite among others . in this",
    "setting , the value functions of a sequence of optimal stopping problems converge to the value function of the impulse control problem under suitable conditions .    in this paper , we utilize this connection together with a novel method of dayanik and karatzas  @xcite for optimal stopping problems .",
    "we use it to identify a new and useful characterization of the solution of the original impulse control problem .",
    "at the end we get rid of the sequence of optimal stopping problems altogether : the new characterization allow us to propose a new direct solution method for impulse control problems .    in the next section",
    ", we briefly go over the solution method for optimal stopping problems of one - dimensional diffusions .",
    "we describe the impulse control problem and its solution in section 3 .",
    "examples are presented in section 4 .",
    "finally , extensions and concluding remarks are in section 5 .",
    "let @xmath0 be a complete probability space with a standard brownian motion @xmath1 and consider the diffusion process @xmath2 with state pace @xmath3 and dynamics @xmath4 for some borel functions @xmath5 and @xmath6 .",
    "we emphasize here that @xmath2 is an uncontrolled process .",
    "we assume that @xmath7 is an interval with endpoints @xmath8 , and that @xmath2 is regular in @xmath9 ; in other words , @xmath2 reaches @xmath10 with positive probability starting at @xmath11 for every @xmath11 and @xmath10 in @xmath12 .",
    "we shall denote by @xmath13 the natural filtration generated by @xmath2 .",
    "let @xmath14 be a real constant and @xmath15 a borel function such that @xmath16 $ ] is well - defined for every @xmath17-stopping time @xmath18 and @xmath19 .",
    "let @xmath20 be the first hitting time of @xmath21 by @xmath2 , and let @xmath22 be a fixed point of the state space .",
    "we set : @xmath23 , & x\\leq c , \\\\                   1/{\\mathbb{e}}^{c}[e^{-\\alpha\\tau_x}1_{\\{\\tau_x<\\infty\\ } } ] ,                   & x >",
    "c,\\end{cases } \\hspace{0.4 cm }      \\varphi(x ) & = \\begin{cases }                   1/{\\mathbb{e}}^{c}\\left[e^{-\\alpha\\tau_x}1_{\\{\\tau_x<\\infty\\}}\\right ] , & x\\leq c , \\\\                   { \\mathbb{e}^{x}}[e^{-\\alpha\\tau_c}1_{\\{\\tau_c<\\infty\\ } } ] ,                   & x > c ,       \\end{cases } \\end{aligned}\\end{aligned}\\ ] ] and @xmath24 then @xmath25 is continuous and strictly increasing . it should be noted that @xmath26 and @xmath27 consist of an increasing and a decreasing solution of the second - order differential equation @xmath28 in @xmath7 where @xmath29 is the infinitesimal generator of @xmath2 .",
    "they are linearly independent positive solutions and uniquely determined up to multiplication .",
    "for the complete characterization of @xmath26 and @xmath27 corresponding to various types of boundary behavior , refer to it and mckean @xcite .",
    "let @xmath30\\rightarrow\\mathbb{r}$ ] be a strictly increasing function .",
    "a real valued function @xmath31 is called _ @xmath32-concave _ on @xmath33 $ ] if , for every @xmath34 and @xmath35 $ ] , @xmath36 we denote by @xmath37 , \\hspace{0.5 cm } x\\in[c , d]\\ ] ] the value function of the optimal stopping problem with the reward function @xmath15 where the supremum is taken over the class @xmath38 of all @xmath17-stopping times",
    ". then we have the following results , the proofs of which we refer to dayanik and karatzas  @xcite .",
    "[ prop:2 ] the value function @xmath39 of ( [ eq : value ] ) is the smallest nonnegative majorant of @xmath15 such that @xmath40 is @xmath32-concave on @xmath41 $ ] .",
    "[ prop:3 ] let @xmath42 be the smallest nonnegative concave majorant of @xmath43 on @xmath44 $ ] , where @xmath45 is the inverse of the strictly increasing function @xmath25 in ( [ eq : f ] ) .",
    "then @xmath46 for every @xmath47 $ ] .",
    "[ prop:4 ] define @xmath48 : v(x)=h(x)\\ } , \\hspace{0.5cm}\\text{and } \\hspace{0.5 cm } \\tau^{*}\\triangleq \\inf\\{t\\geqq0 : x^0_t\\in s\\}.\\ ] ] if @xmath15 is continuous on @xmath33 $ ] , then @xmath49 is an optimal stopping rule .",
    "suppose that at any time @xmath50 and any state @xmath51 , we can intervene and give the system an impulse @xmath52 .",
    "once the system gets intervened , the point moves from @xmath11 to @xmath53 with associated rewards earned .",
    "an impulse control for the system is a double sequence , @xmath54 where @xmath55 are an increasing sequence of @xmath17-stopping times and @xmath56 , @xmath57 are @xmath58-measurable random variables representing impulses exercised at the corresponding intervention times @xmath59 with @xmath60 for all @xmath61 where @xmath62 is a given set of admissible impulse values .",
    "the controlled process is , in general , described as follows : @xmath63 with some mapping @xmath64 .    in this section ,",
    "we consider the absorbing boundary problem .",
    "let @xmath65 be the absorbing state , without loss of generality , and @xmath66 the ruin time . with the absorbing state at @xmath65 ,",
    "it is natural to consider a set of problems where @xmath67 ( i.e. , @xmath68 for all @xmath61 ) and @xmath69 .",
    "( we shall comment on cases where interventions are allowed in both positive and negative directions in section [ sec : conclusion ] . )    with each pair @xmath70 , we associate the interventions @xmath71 where @xmath72 is a given continuous function in the first and second argument that represents benefit / cost at interventions .",
    "our result below does not depend on the specification of @xmath73 .",
    "we assume that , for any point @xmath74 , @xmath75 due to the fixed cost incurred .",
    "we consider the following performance measure with @xmath76 , a collection of admissible strategies , @xmath77\\ ] ] where @xmath78 is a constant penalty at the ruin time and @xmath79 is a continuous function , satisfying : @xmath80<\\infty.\\ ] ] our goal is to find the optimal strategy @xmath81 and the corresponding value function , @xmath82 let us briefly go over our plan . in section [ sec : first ] we shall characterize optimal intervention times @xmath59 as exit times of the process @xmath83 from an interval by implementing recursive optimal stopping scheme that eventually solves the original impulse control problem . using the results , in section [ sec : sec ]",
    ", we consider a special case where the mapping @xmath84 @xmath85 is @xmath32-concave .",
    "we show , under this assumption , that the optimal intervention times @xmath59 are characterized as exit times from an interval , say @xmath86 for every @xmath61 .",
    "then we characterize the value function for impulse control problems and present a solution method based on the characterization of the intervention times and value function . in section [ sec : gen ] , we consider the general case where the @xmath32-concavity assumption above does not hold .      in this subsection",
    ", we consider a recursive optimal stopping with a view to characterizing intervention times for the impulse control problems . here",
    "we assume that no absorbing boundary exists . as we will see in the next subsection , the existence of an absorbing state is easily incorporated .",
    "hence by using the same @xmath87 , we consider the problem , @xmath88,\\ ] ] and define the set @xmath89 and the objective function @xmath90 as follows : @xmath91 and @xmath92.\\ ] ] in other words , we are allowed to make at most @xmath93 interventions .",
    "for this recursive approach , see , for example , davis @xcite and ksendal and sulem @xcite .",
    "we use the following simple notation : @xmath94.\\ ] ] let @xmath95 denote the space of all borel functions .",
    "define the two operators @xmath96 and @xmath97 as follows : @xmath98,\\ ] ] and @xmath99,\\ ] ] for @xmath100 . from the definition of the two operators , @xmath101 for @xmath102 implies @xmath103 and @xmath104 for all @xmath74 .",
    "consider the following recursive formula : @xmath105,\\ ] ] which is equivalent to @xmath106\\ ] ] by applying the strong markov property with ( [ eq : fcon ] ) to the integral term .",
    "in fact , this derivation is explained in detail in subsection [ sec : sec ] . by defining @xmath107 and adding and subtracting @xmath108 on the right hand side of ( [ eq : wrec2 ] )",
    ", it becomes @xmath109.\\ ] ] it should be noted that , for each @xmath93 , this is an optimal stopping problem over @xmath18 and can be written , by using the operator defined in ( [ eq : l ] ) , @xmath110    let us start this recursive scheme with @xmath111 ( i.e. , no interventions are allowed , equivalently @xmath112 ) and define recursively @xmath113 .",
    "clearly , @xmath114\\nonumber\\\\ & = \\sup_{\\tau \\in { \\mathcal{s } } , \\xi\\in { \\mathbb{r}}_+}{\\mathbb{e}^{x}}[e^{-\\alpha\\tau}\\left\\{k(x_{\\tau- } , x_\\tau)-g(x_{\\tau-})+g(x_\\tau)\\right\\}].\\end{aligned}\\ ] ] on the other hand , @xmath115-{\\mathbb{e}^{x}}\\left[\\int_0^{\\infty}e^{-\\alpha s}f(x_s^0)ds\\right]\\\\ & = \\sup_{\\tau \\in { \\mathcal{s } } , \\xi\\in { \\mathbb{r}}_+}{\\mathbb{e}^{x}}\\big[\\int_0^{\\tau}e^{-\\alpha s}f(x_s)ds+e^{-\\alpha \\tau}\\left({\\mathbb{e}}^{x_{\\tau}}\\left[\\int_0^\\infty e^{-\\alpha s}f(x_s)ds\\right]+k(x_{\\tau-},x_{\\tau})\\right ) \\\\ & \\hspace{2.7cm}-\\int_0^\\tau e^{-\\alpha s } f(x_s^0)ds - e^{-\\alpha\\tau}g(x_{\\tau-})\\big]\\\\ & = \\sup_{\\tau \\in { \\mathcal{s } } , \\xi\\in { \\mathbb{r}}_+}{\\mathbb{e}^{x}}[e^{-\\alpha\\tau}\\left\\{k(x_{\\tau-},x_{\\tau})+g(x_{\\tau})-g(x_{\\tau-})\\right\\}].\\end{aligned}\\ ] ] the last equation is due to the fact that only one intervention is allowed .",
    "hence we have @xmath116 . by the definition of the recursive scheme",
    ", @xmath117 is an increasing sequence ( i.e , @xmath118 for all @xmath74 ) .",
    "in fact , we shall prove that @xmath119 for all @xmath93 in lemma [ lem : davis ] . before that , we need the following lemma to relate this recursive scheme with the method described in section [ sec : summary ] .",
    "+    [ lem : lop ] the mapping @xmath120 @xmath121 is @xmath32-concave .",
    "we shall fix some @xmath122 $ ] . since @xmath123 is bounded there , for a given @xmath124 , there are admissible @xmath125-optimal intervention pairs @xmath126 and @xmath127 such that @xmath128 > \\mathcal{l}\\phi(l)-\\varepsilon ,    \\quad\\text{and}\\quad   { \\mathbb{e}}^r [ e^{-\\alpha\\sigma^r_\\varepsilon } \\mathcal{m}\\phi(x_{\\sigma^r_\\varepsilon } ) ] >   \\mathcal{l}\\phi(r)-\\varepsilon.\\ ] ] define another stopping time @xmath129 with @xmath130 putting all together , with the strong markov property of @xmath83 , we have @xmath131\\\\ & > ( \\mathcal{l}\\phi(l)-\\varepsilon){\\mathbb{e}^{x}}[e^{-\\alpha\\tau^l}1_{\\{\\tau^l<\\tau^r\\ } } ] + ( \\mathcal{l}\\phi(r)-\\varepsilon){\\mathbb{e}^{x}}[e^{-\\alpha\\tau^r}1_{\\{\\tau^l>\\tau^r\\}}]\\\\ & \\geq \\frac{\\mathcal{l}\\phi(l)}{\\varphi(l)}\\varphi(x)\\frac{f(r)-f(x)}{f(r)-f(l ) } + \\frac{\\mathcal{l}\\phi(r)}{\\varphi(r)}\\varphi(x)\\frac{f(x)-f(l)}{f(r)-f(l)}-\\varepsilon.\\end{aligned}\\ ] ] since @xmath125 is arbitrary , we have an @xmath32-concavity .",
    "this lemma guarantees that we can use proposition [ prop:2 ] to [ prop:4 ] to identify the value function and an optimal stopping rule for each of the recursive optimal stopping problems ( [ eq : wrec ] ) .",
    "let us define , for notational convenience , @xmath132 further , we prove the following properties of the recursive optimization scheme .    [",
    "lem : davis ] if we define @xmath117 by ( [ eq : wrec ] ) ( with @xmath133 ) and @xmath90 by ( [ eq : vn ] ) , then @xmath134 moreover , @xmath135 is the smallest solution majorizing @xmath136 of the functional equation @xmath137 .",
    "the proof is given in appendix .    hence if we solve the optimal stopping problem @xmath138\\ ] ]",
    "recursively for each @xmath93 , then we obtain @xmath139 . summarizing the above argument",
    ", we have the following proposition :    [ fconc ] the value function @xmath87 for ( [ eq : newv ] ) is given by the smallest solution majorizing @xmath136 of the functional equation @xmath140 , and @xmath141 is always @xmath32-concave .",
    "the first statement comes from lemma [ lem : davis ] . by the recursive method that we described above",
    ", we are solving a series of optimal stopping problems for each @xmath142 . hence lemma [ lem : lop ] and proposition [ prop:2 ]",
    "give the second statement .",
    "based on the results in the previous subsection , we first consider a special case where the mapping @xmath143 @xmath85 is @xmath32-concave . the argument in the previous subsection",
    "is modified to incorporate the existence of the ruin state . instead of ( [ eq : vn ] ) and ( [ eq : wrec ] ) , we define , respectively , @xmath144\\\\ w_{n+1}(x)&\\triangleq\\sup_{\\tau\\in\\mathcal{s } , \\xi}{\\mathbb{e}^{x}}\\big[\\int_0^{\\tau_0\\wedge\\tau } e^{-\\alpha s}f(x_s)ds + e^{-\\alpha\\tau_0}p1_{\\{\\tau_0<\\tau\\ } } \\\\ & \\hspace{6cm}+ e^{-\\alpha\\tau}\\{k(x_{\\tau- } , x_{\\tau})+w_n(x_\\tau)\\}1_{\\{\\tau<\\tau_0\\}}\\big]\\end{aligned}\\ ] ] with @xmath145\\triangleq g_0(x).\\ ] ] then by defining the operator @xmath146 instead of ( [ eq : l ] ) , @xmath147,\\ ] ] we have the same recursion formula as in ( [ eq : stops ] ) .",
    "we can obtain the same results as in lemma [ lem : lop ] and lemma [ lem : davis ] .",
    "proposition [ fconc ] also holds with one change that the value function is given by the smallest solution majorizing @xmath148 of the functional equation @xmath140 where @xmath149 is given by ( [ eq : l2 ] ) .",
    "now we consider the characterization of the intervention times .",
    "[ prop : exitchar ] if the mapping @xmath143 @xmath85 is @xmath32-concave and 0 is an absorbing state , then the optimal intervention times @xmath150 are given , for some @xmath151 , by @xmath152    our proof is constructive , describing the procedure of recursive optimization steps . for any @xmath153 , in view of lemma [ lem : lop ]",
    ", @xmath154 is the smallest @xmath32-concave majorant of @xmath155 .",
    "this majorant ( that passes @xmath156 in the transformed space ) always exists . indeed ,",
    "since we consider the case of @xmath157 , i.e , @xmath158 for @xmath159 and @xmath160=\\sup_{y\\in \\mathbb{r}_+}[k(x , y)-(g(x)-g(y))+(g_0(y)-g(y))],\\end{aligned}\\ ] ] we should check whether the concave majorant exists , namely , @xmath161 holds when @xmath162 .",
    "note that @xmath163 and @xmath164 as @xmath165 due to the continuity of @xmath166 .",
    "hence ( [ eq : check0 ] ) holds in the neighborhood of @xmath167 because of ( [ eq : kneg ] ) .",
    "in the subsequent iterations , we consider @xmath168 . \\ ] ] we should check if the expression inside the supremum operator becomes less than @xmath169 as @xmath170 and @xmath162 .",
    "since @xmath171 by the concavity ( hence continuity ) of @xmath172 and since @xmath173 , we have in the neighborhood of @xmath167 , @xmath174 holds .",
    "hence the concave majorant always exist also in the subsequent iterations .",
    "now the @xmath32-concavity of @xmath142 is obviously maintained for all @xmath93 .",
    "the limit function , @xmath175 exists and is also @xmath32-concave .",
    "accordingly , @xmath176 is @xmath32- concave .",
    "hence @xmath177 and @xmath178 meet once and only once . recall that the value function satisfies @xmath179 .",
    "this implies that the continuous region is in the form of @xmath86 for some @xmath151 , which completes the proof .    by using the above characterization of intervention times ,",
    "we next want to characterize the value function and reduce the impulse control problem ( [ eq : impulsevalue ] ) to some optimal stopping problem . moreover ,",
    "we shall present a method that does not have to go through the iteration scheme .",
    "let us first simplify @xmath180 : @xmath181.\\ ] ] this is just a reproduction of ( [ eq : j ] ) .",
    "let us split the right hand side of ( [ eq : u ] ) into pieces and use the strong markov property ( together with the shift operator @xmath182 ) to each of them .",
    "the first term becomes @xmath183={\\mathbb{e}^{x}}\\left[1_{\\{t_1<\\tau_0\\}}\\left\\{\\int_0^{t_1}e^{-\\alpha s}f(x_s)ds+ e^{-\\alpha t_1}{\\mathbb{e}^{x_{t_1}}}\\int_{0}^{\\infty}e^{-\\alpha s}f(x_s)1_{\\{s<\\tau_0\\}}ds\\right\\}\\right]\\\\ & \\hspace{7cm}+{\\mathbb{e}^{x}}\\left[1_{\\{t_1>\\tau_0\\}}\\int_0^{\\tau_0}f(x_s)ds\\right]\\end{aligned}\\]]the second and third terms become @xmath184\\right]+{\\mathbb{e}^{x}}\\left[1_{\\{t_1>\\tau_0\\}}e^{-\\alpha\\tau_0}p\\right]\\\\ & = { \\mathbb{e}^{x}}\\left[1_{\\{t_1<\\tau_0\\}}e^{-\\alpha t_1}{\\mathbb{e}^{x}}[e^{-\\alpha(\\tau_0\\circ\\theta(t_1))}p|\\mathcal{f}_{t_1}]\\right]+{\\mathbb{e}^{x}}\\left[1_{\\{t_1>\\tau_0\\}}e^{-\\alpha\\tau_0}p\\right]\\\\ & = { \\mathbb{e}^{x}}\\left[1_{\\{t_1<\\tau_0\\}}e^{-\\alpha t_1}{\\mathbb{e}^{x_{t_1}}}(e^{-\\alpha\\tau_0}p)\\right]+{\\mathbb{e}^{x}}\\left[1_{\\{t_1>\\tau_0\\}}e^{-\\alpha\\tau_0}p\\right]\\end{aligned}\\ ] ] and @xmath185\\\\ & = { \\mathbb{e}^{x}}\\left[1_{\\{t_1<\\tau_0\\}}\\left\\{e^{-\\alpha t_1}k(x_{t_1-},x_{t_1})+e^{-\\alpha t_1}\\sum_{i=2}e^{-\\alpha ( t_i - t_1)}k(x_{t_i-},x_{t_i})1_{\\{t_i<\\tau_0\\}}\\right\\}\\right]\\nonumber \\\\ & = { \\mathbb{e}^{x}}\\left[1_{\\{t_1<\\tau_0\\}}\\left\\{e^{-\\alpha t_1}k(x_{t_1-},x_{t_1})+e^{-\\alpha t_1}{\\mathbb{e}^{x}}[\\sum_{t_i<\\tau_0}e^{-\\alpha ( t_i\\circ\\theta(t_1))}k(x_{s_{i-}},x_{s_i})|\\mathcal{f}_{t_1}]\\right\\}\\right ] \\nonumber\\\\ & = { \\mathbb{e}^{x}}\\left[1_{\\{t_1<\\tau_0\\}}e^{-\\alpha t_1}\\left\\{k(x_{t_1-},x_{t_1})+{\\mathbb{e}^{x_{t_1}}}\\sum_{i=1}e^{-\\alpha t_i}k(x_{t_i-},x_{t_i})1_{\\{t_i<\\tau_0\\}}\\right\\}\\right],\\end{aligned}\\ ] ] where @xmath186 and the index @xmath61 runs from @xmath187 for the sum in the second equality . combining the three terms and rearranging , we have @xmath188\\\\ + { \\mathbb{e}^{x}}\\left[1_{\\{t_1>\\tau_0\\}}\\left\\{\\int_0^{\\tau_0}e^{-\\alpha s}f(x_s)ds+e^{-\\alpha\\tau_0}p\\right\\}\\right].\\end{gathered}\\ ] ] for any @xmath17 stopping time @xmath18 , the strong markov property with our assumption ( [ eq : fcon ] ) gives us @xmath189=g(x)-{\\mathbb{e}^{x}}\\left [ e^{-\\alpha    \\tau}g(x_{\\tau}^0)\\right]\\ ] ] where @xmath190 is defined as in ( [ eq : gf ] ) .",
    "we apply this result to ( [ eq : simple ] ) by reading @xmath191 and @xmath192 to derive@xmath193\\\\ + { \\mathbb{e}^{x}}\\left[1_{\\{t_1>\\tau_0\\}}e^{-\\alpha\\tau_0}\\{p - g(x_{\\tau_0})\\}\\right]+g(x).\\end{gathered}\\ ] ] noting that @xmath194 , adding and subtracting @xmath195 and further defining @xmath196 ( [ eq : lastj ] ) finally becomes @xmath197\\\\ + { \\mathbb{e}^{x}}\\left[1_{\\{t_1>\\tau_0\\}}e^{-\\alpha\\tau_0}\\{p - g(x_{\\tau_0})\\}\\right],\\end{gathered}\\ ] ] and we consider the maximization of this @xmath198 function and add back @xmath199 since @xmath200 .",
    "note that this simplification leading to ( [ eq : simple2 ] ) does not depend on the @xmath32-concavity assumption .",
    "+ since we have confirmed that optimal intervention times are exit times of the process from an interval , let us use a simpler notation that @xmath201 and @xmath202 for all @xmath61 .",
    "we can denote @xmath203 . by observing ( [ eq : simple2 ] ) , @xmath204 we have @xmath205 where @xmath206 + { \\mathbb{e}^{x}}[1_{\\{\\tau_b>\\tau_0\\}}e^{-\\alpha\\tau_0}u(0)].\\ ] ] + the second equation of ( [ eq : twoside ] ) is obtained from ( [ eq : simple2 ] ) by noticing that , on @xmath207 , @xmath208 .",
    "indeed , in this case , we immediately jump to @xmath209 , so that @xmath210 and @xmath211 . since @xmath212 , @xmath213 .",
    "now let us note that we have the following representations in ( [ eq : simple2 ] ) @xmath214=\\frac{\\psi(l)\\varphi(x)-\\psi(x)\\varphi(l ) } { \\psi(l)\\varphi(r)-\\psi(r)\\varphi(l ) } , \\hspace{0.5 cm } x\\in[l , r]\\ ] ] where @xmath215 and @xmath216 and @xmath27 and @xmath26 defined in the previous section .",
    "finally , with @xmath25 being defined as in ( [ eq : f ] ) , we have a characterization of @xmath217 , @xmath218.\\ ] ] + define @xmath219 , this becomes , for any @xmath209 and @xmath220 , @xmath221.\\ ] ] this represents a _ linear function _ that passes a fixed point , @xmath222 .    to discuss how to find the optimal pair @xmath223 , we write @xmath217 as @xmath224 to emphasize the dependence on @xmath225 , then on @xmath226 $ ] , @xmath227+{\\mathbb{e}^{x}}[1_{\\{\\tau_b>\\tau_0\\}}e^{-\\alpha\\tau_0}u_{a , b}(0)]\\}.\\label{eq : twostage}\\end{aligned}\\ ] ]",
    "this can be considered as a two - stage optimization problem .",
    "first , let @xmath209 be fixed . for each @xmath209 ,",
    "the inner maximization of ( [ eq : twostage ] ) becomes @xmath228+{\\mathbb{e}^{x}}[1_{\\{\\tau_b>\\tau_0\\}}e^{-\\alpha\\tau_0}(p - g(0))]\\}\\ ] ] and , among @xmath229 , choose an optimal @xmath209 in the sense , @xmath230 for any @xmath11 .",
    "it should be pointed out that @xmath231 may take negative values if @xmath169 does .",
    "now , we discuss a solution method of the first stage optimization ( [ eq : stage1 ] ) . for this purpose , we need a lemma :    [ lem:0 ] if we define @xmath232 , \\quad x\\in\\mathbb{r } , \\gamma\\in\\mathbb{r}\\ ] ] for some borel function @xmath233 and with condition ( [ eq : fcon ] ) , then , for @xmath234 , @xmath235 for any @xmath11 .",
    "the left hand side of ( [ eq : contraction ] ) is well - defined due to ( [ eq : fcon ] ) .",
    "it is clear that @xmath236 is convex in @xmath237 for any @xmath11",
    ". then @xmath238 exists at every @xmath239 , and @xmath240 consider the bound of @xmath241 for @xmath11 fixed : @xmath242    the first term on the right hand side is constant in @xmath237 and the second term is linear in @xmath237 and the @xmath243\\leq 1 $ ] for any @xmath244 . due to the convexity of @xmath236 in @xmath237 , for the above inequality to hold , @xmath245 for all @xmath246 . on account of ( [ eq : d+ ] ) , we have ( [ eq : contraction ] ) .    coming back to ( [ eq : stage1 ] ) , we need some care because the value function @xmath231 contains its value at @xmath209 , @xmath247 in the definitive equation .",
    "let us consider a family of optimal stopping problem parameterized by @xmath248 .",
    "@xmath249\\nonumber + { \\mathbb{e}^{x}}[1_{\\{\\tau>\\tau_0\\}}e^{-\\alpha\\tau_0}(p - g(0))]\\right\\ } \\nonumber \\\\ & = \\sup_{\\tau\\in\\mathcal{s}}{\\mathbb{e}^{x}}[e^{-\\alpha \\tau}r^\\gamma(x_\\tau , a ) ] \\ ] ] where @xmath250 obviously , this parameterized problem can be solved by using proposition [ prop:2 ] to [ prop:4 ] .",
    "now we link this parameterized optimal stopping problem to ( [ eq : stage1 ] ) .",
    "[ lem:1 ] for @xmath251 given , if there exists a solution to ( [ eq : gamma ] ) , then there always exists unique @xmath237 such that @xmath252 holds , provided that ( [ eq : kneg ] ) holds .    without loss of generality , we need only to consider the case where @xmath253 for some @xmath251 . indeed , suppose that there is no such @xmath209 and let us consider a sequence of optimal stopping scheme . in each iteration ,",
    "the value function for the optimal stopping problem takes negative values , so that @xmath254 for all @xmath93 .",
    "then in the next iteration , @xmath255 function will be shifted downwards , leading to @xmath256 .",
    "hence the  no interventions \" strategy is trivially optimal .    in ( [ eq : gamma ] ) , since @xmath237 is some constant parameter , we benefit from proposition [ prop:2 ] and claim that @xmath257 is characterized as the smallest @xmath32-concave majorant of @xmath258 that passes @xmath259 . in terms of the notation of proposition [ prop:4 ] ,",
    "if we define @xmath260 such that @xmath261 then @xmath260 passes through the fixed point @xmath262 and is the smallest concave majorant of @xmath263 .",
    "now fix @xmath209 .",
    "our approach here is by starting with @xmath264 , we move @xmath237 and evaluate @xmath265 and try to find @xmath237 such that @xmath252 . due to ( [ eq : positive - condition ] ) , we have @xmath266 . by the monotonicity of @xmath32",
    ", it is equivalent to saying that @xmath267 . as @xmath237 increases",
    ", @xmath268 increases monotonically by the right hand side of ( [ eq : gamma ] ) .",
    "lemma [ lem:0 ] implies that for @xmath234 , @xmath269 for any @xmath51 .",
    "note that @xmath270 .",
    "however , since @xmath271 has less than the linear growth in @xmath237 as demonstrated by ( [ eq : contraction2 ] ) , there is a certain @xmath272 large enough such that @xmath273 for @xmath274 .",
    "this implies @xmath275 where the inequality is due to the assumption ( [ eq : kneg ] ) . for this @xmath272 , we have @xmath276 .",
    "the monotonicity and continuity of @xmath277 ( due to the convexity of @xmath278 ) with respect to @xmath237 , together with ( [ eq : contraction2 ] ) , implies that , for any @xmath209 , there exists one and only one @xmath237 such that @xmath279 .      using ( [ eq : uchar ] ) , namely the characterization of @xmath280",
    ", we describe an optimization procedure based on proposition [ prop:3 ] and [ prop:4 ] .    1 .",
    "fix @xmath209 .",
    "consider the function @xmath281 define @xmath282 such that @xmath283 and by the characterization ( [ eq : u ] ) , it is a straight line with a slope , say @xmath284 and passes through @xmath285 .",
    "we can write the linear majorant , in general , @xmath286 2 .   for each slope",
    "@xmath284 , we can calculate the value of @xmath287 , but we have to find the @xmath282 function such that , at some point @xmath288 , we have @xmath289 where we write @xmath290 for notational simplicity . this requirement is equivalent to finding @xmath237 in ( [ eq : gamma ] ) in lemma [ lem:1 ] such that @xmath291 by proposition [ prop : exitchar ] , @xmath292 is the continuation region .",
    "if @xmath293 is a differentiable function with respect to the first argument , we can find the optimal point @xmath294 analytically . in effect , it is to find a point @xmath294 such that the linear majorant and the shifted function @xmath295 have a tangency point .",
    "this is equivalent to calculating the maximum slope that majorizes @xmath296 after it is shifted .",
    "explicitly , we solve @xmath297 for @xmath294 where @xmath284 is @xmath298 for the absorbing boundary case , these equations can be easily modified .",
    "let us denote @xmath299 .",
    "then ( [ eq : simplesystem ] ) and ( [ eq : beta ] ) become @xmath300 and @xmath301 respectively .",
    "3 .   now , let @xmath209 vary and choose , among @xmath284 , find @xmath302 , if exists , and also the corresponding @xmath303 and @xmath304 .",
    "due to the characterization of the value function , these @xmath304 and @xmath305 must be the solution to ( [ eq : impulsevalue ] ) .",
    "suppose that @xmath306 is a decreasing function of @xmath209 .",
    "as @xmath209 becomes closer to @xmath65 , the quantity @xmath306 becomes larger , while @xmath287 smaller .",
    "hence we can expect the existence of @xmath304 that maximizes the slope @xmath307 .    with respect to the third point of the proposed method above , we should check if there exists a concave majorant as @xmath308 .",
    "namely , we consider whether @xmath309 holds in the neighborhood of @xmath310 .",
    "since @xmath311 and @xmath312 by the continuity of @xmath31 , the last inequality holds due to ( [ eq : kneg]).@xmath313      let us move on to a general case where the mapping @xmath143 @xmath85 is not necessarily @xmath32-concave .",
    "first , we extend proposition [ prop : exitchar ] to characterize optimal intervention times .    [ prop : genk ] the value function @xmath87 for ( [ eq : impulsevalue ] ) is given by the smallest solution majorizing @xmath136 of @xmath140 and optimal intervention times @xmath150 are given by exit times from an interval if and only if , for all @xmath53 , @xmath314 where @xmath315 .",
    "for any given @xmath316 , if we can find the smallest linear majorant of @xmath317 for an arbitrary @xmath318 , we can find @xmath319 by lemma [ lem:1 ] . due to the constancy of @xmath237",
    ", it suffices to show that condition ( [ eq : iff ] ) is necessary and sufficient for the existence of concave majorant of @xmath320 on @xmath321 .",
    "the sufficiency is immediate . for the necessity",
    ", we assume that @xmath322 . we can take a sequence of points @xmath323 such that @xmath324 and @xmath325 as @xmath326 .",
    "if necessary , by taking a subsequence , we can make this sequence @xmath327 monotone .",
    "consider the smallest concave majorant of @xmath328 on @xmath329 $ ] .",
    "call it @xmath330 .",
    "it is clear that @xmath330 is monotone increasing in @xmath331 for all @xmath332 $ ] . as @xmath326 , @xmath324 and @xmath333 .",
    "we thus have @xmath334 for all @xmath51 .",
    "there is no optimal intervention policy .",
    "suppose that the @xmath32-concavity of the reward function is violated , so that the intervention point may be multiple .",
    "let us consider a strategy that we have two intervention points , @xmath335 and @xmath336 being arbitrarily chosen such that @xmath337 .",
    "we want to characterize function @xmath338 as in ( [ eq : j ] ) again .",
    "recall that there are no controls in a way that the process is pulled up to avoid ruin .",
    "in other words , @xmath339=1 $ ] . assume , for the moment , that we always apply control at these boundaries @xmath335 and @xmath336 and then , once applied , the process moves to @xmath340 and @xmath341 , respectively .    if we start with a point @xmath342 $ ] , the problem is equivalent to the case we considered already , since the process can not go beyond the level @xmath335 . hence following ( [ eq : twoside ] ) , we have for @xmath342 $ ] @xmath343\\end{aligned}\\ ] ] and @xmath344 + { \\mathbb{e}^{x}}[1_{\\{\\tau_{b_1}>\\tau_0\\}}e^{-\\alpha\\tau_0}u_1(0 ) ] , & x\\in[0 , b_1]\\end{aligned}\\ ] ] by defining @xmath345 .",
    "if we start with a point @xmath346 $ ] , there are two strategies available :    * let @xmath347 move along .",
    "( it either hits @xmath335 or @xmath336 first . ) * apply the control immediately @xmath348 by moving the process from @xmath11 to @xmath349 ( the post - control point that corresponds to @xmath335 ) and let the process start at @xmath349 .",
    "( recall that we do not let @xmath83 enter into @xmath350 after moving to @xmath349 . )",
    "consider strategy ( a ) first .",
    "let us define @xmath351 \\quad x\\in[b_1 , b_2].\\ ] ] using the strong markov property , we can reduce @xmath352 to a simpler form . for any @xmath353 and @xmath354",
    ", we have @xmath355+g(x).\\end{gathered}\\ ] ] we shall use @xmath356 in the first term . now let us define @xmath357 .",
    "then the last equation becomes @xmath358\\nonumber\\\\ & = { \\mathbb{e}^{x}}[1_{\\{\\tau_{b_1}<\\tau_{b_2}\\}}e^{-\\alpha \\tau_{b_1}}(\\bar{k}(b_1,a_1)+u_1(a_1))]+{\\mathbb{e}^{x}}[1_{\\{\\tau_{b_1}>\\tau_{b_2}\\}}e^{-\\alpha \\tau_{b_2}}(\\bar{k}(b_2 , a_2)+u_2(a_2))]\\end{aligned}\\ ] ] on @xmath346 $ ] . by identifying @xmath359 and @xmath360 that shows @xmath361 and @xmath362",
    "are connected at @xmath363 .",
    "thus , @xmath364.\\ ] ] to summarize this result , if we define @xmath365 for @xmath366 on @xmath321 , this is again a linear function for each @xmath61 .",
    "hence by defining @xmath367 \\\\",
    "w_2(f(x))=w_2(f(b_1))\\frac{f(b_2)-f(x)}{f(b_2)-f(b_1)}+w_2(f(b_2))\\frac{f(x)-f(b_1)}{f(b_2)-f(b_1 ) } ,                   \\hspace{0.2cm}x\\in[b_1 , b_2 ] ,       \\end{cases}\\end{aligned}\\ ] ] we have a piecewise linear function on @xmath321 . moreover , since we can treat @xmath335 as an absorbing boundary , we have @xmath368",
    ".    next consider strategy ( b ) , whose value function is @xmath369    [ lem:2 ] ( a ) is better than ( b ) only if @xmath370    since the value function of strategy ( b ) is ( [ eq : w - b ] ) , choosing ( a ) over ( b ) is equivalent to @xmath371 if @xmath372 majorizes @xmath373 on @xmath374 , then this problem reduces to @xmath32-concavity case discussed in the previous subsection .",
    "hence we consider the case where there exists some @xmath375 such that @xmath376 now suppose that we have @xmath377 .",
    "then it is clear that we can not have @xmath378 on @xmath379 .",
    "there are two cases to consider :    * if @xmath380 majorizes @xmath373 on @xmath381 , then we adopt the point @xmath336 as an intervention point . in this case , @xmath382 holds .",
    "however , this implies that if we connect @xmath383 and @xmath384 , then this line segment @xmath385 is above the line segment connecting , piece by piece , points @xmath386 , @xmath387 and @xmath388 .",
    "we can show that there exists a point @xmath389 such that its corresponding linear majorant @xmath390 satisfies @xmath391 on @xmath342 $ ] and @xmath392 on @xmath393 $ ] .",
    "the proof of the existence of a post - intervention point @xmath394 corresponding to this point @xmath395 follows in a similar manner to lemma [ lem:1 ] . *",
    "if @xmath380 does not majorize @xmath373 , we can find another point @xmath396 , instead of @xmath335 , such that the linear ( not piecewise linear ) function @xmath397 corresponds to @xmath396 majorizes @xmath398 on @xmath399 by proposition [ prop : genk ] .    in either case",
    ", the value function in the transformed space should be a linear function that attains the largest slope among all the possible linear majorant .",
    "this argument holds true for any @xmath335 and @xmath336 with @xmath400 .",
    "we can continue this argument inductively to the case of @xmath93 intervention points , @xmath401 .",
    "we here summarize our argument up to this point as a main proposition :    suppose that ( [ eq : iff ] ) holds and the optimal continuation region is connected .",
    "the value function corresponding to ( [ eq : j ] ) of the impulse problem described in ( [ eq : z])@xmath402 ( [ eq : impulsevalue ] ) is written as @xmath403 where @xmath404 is the line segment connects @xmath405 and @xmath406 and satisfy the following :    1 .",
    "@xmath407 is the smallest linear majorant of @xmath408 and meets with @xmath409 at point @xmath410 and passes @xmath411 . if @xmath293 is differentiable , @xmath412 satisfy ( [ eq : simplesystem ] ) .",
    "the slope of @xmath404 , denoted as @xmath302 , is the largest slope among @xmath413 s of all the possible linear majorants @xmath282 .",
    "moreover , if the mapping @xmath143 @xmath121 is @xmath32-concave , then the optimal continuation region @xmath86 is uniquely determined .",
    "note that , at @xmath414 , @xmath415 as expected .",
    "[ rmk : pathology ] if the @xmath32-concavity of @xmath416 is violated , there are two possible cases ( and combination of them ) of multiple continuation regions .    1 .   for some @xmath417 with @xmath418",
    ", we have the common @xmath302 .",
    "this is the case which we shall show in the next example . in this case , the continuation region is @xmath419 where @xmath420 corresponds to @xmath417 for each @xmath61 , and the intervention region is @xmath421 . each time the process hits one of the points @xmath422 , the control pulls the process back to the corresponding @xmath417 .",
    "another case is that , for the unique optimal @xmath304 , there exists non - unique @xmath423 and @xmath424 . in this case ,",
    "the continuation region is @xmath425 , and the stopping region is @xmath426 .",
    "if the process hits @xmath423 or @xmath424 , then the control pulls the process back to @xmath304 in either situation .",
    "it makes sense to continue in the region @xmath427 because there is a positive probability that one can extract @xmath428 within a finite time .",
    "next , we extend our argument to a problem without the absorbing boundary .",
    "hence the process can move along in the state space in an infinite amount of time .",
    "the problem becomes @xmath429\\ ] ] we can characterize intervention times as exit times from certain boundary and simplify the performance measure ( [ eq : fj ] ) @xmath430\\nonumber\\\\ & = { \\mathbb{e}^{x}}[e^{-\\alpha t_1}\\{k(x_{t_1- } , x_{t_1})-g(x_{t_1-})+j^\\nu(x_{t_1})\\}]+g(x).\\end{aligned}\\ ] ] the second equation is easily obtained in the same way as in the previous section by noting @xmath431 .",
    "the last term does not depend on controls , so we define @xmath432 : @xmath433.\\ ] ] again , we consider the @xmath32-concave case with the notation @xmath434 for all @xmath61 and we have @xmath435={\\mathbb{e}^{x}}[e^{-\\alpha \\tau_b}(\\bar{k}(b , a)+u(a))].\\end{aligned}\\ ] ] by defining @xmath436 , we have @xmath437.\\end{aligned}\\ ] ] we should note that @xmath438 and @xmath439 for any @xmath440 $ ] . for more detailed mathematical meaning of this value @xmath441 , we refer the reader to dayanik and karatzas@xcite .",
    "we can effectively consider @xmath442 as the absorbing boundary .",
    "in this section , we work out some examples from financial engineering problems . for this purpose , we recall some useful observations",
    ". if @xmath15 is twice - differentiable at @xmath19 and @xmath443 , then @xmath444 and @xmath445 with @xmath446 with strict inequality if @xmath447 .",
    "these identities are of practical use in identifying the concavities of @xmath448 when it is hard to calculate its derivatives explicitly .",
    "[ ex : oks ] ksendal @xcite considers the following problem : @xmath449\\ ] ] where @xmath450 is a standard brownian motion and @xmath451 and @xmath452 are constants . the brownian motion represents the exchange rate of some currency and each impulse represents an interventions taken by the central bank in order to keep the exchange rate in a given target zone .",
    "here we are only allowed to give the system impulses @xmath453 with values in @xmath454 . by reducing a level from @xmath220 to @xmath209",
    "( i.e. , @xmath455 ) through interventions , one can save continuously incurred cost ( which is high if the process is at a high level ) .",
    "the problem is to minimize the expected total discounted cost @xmath456 .",
    "we want to solve its sup version and change the sign afterwards ( i.e. @xmath457 ) : @xmath458.\\ ] ] the continuous cost rate @xmath459 and the intervention cost is @xmath460 in our terminology . by solving the equation @xmath461 , we find @xmath462 and @xmath463 .",
    "hence @xmath464 and @xmath465 .",
    "following our characterization of the value function , we obtain @xmath466+g(x)\\end{aligned}\\ ] ] where @xmath199 can be calculated by fubini s theorem : @xmath467 by defining @xmath468 , we have @xmath469 $ ] .",
    "note that when @xmath455 , @xmath470 is the source of cost savings .",
    "let us fix @xmath251 and consider @xmath471 and @xmath472 . by the first equation in ( [ eq : devh ] )",
    ", the sign of @xmath473 will lead us to conclude that @xmath474 is increasing from a certain point , say @xmath475 on @xmath476 , so is @xmath474 . also , by direct calculation , @xmath477 , from which we can assert that the value function is finite by proposition [ prop : genk ] . if we set @xmath478 , then @xmath479 for every @xmath480 .",
    "this quadratic function @xmath481 possibly has one or two positive roots .",
    "let @xmath331 be the largest one .",
    "since @xmath482 , by the second inequality in ( [ eq : devh ] ) , @xmath448 is concave on @xmath483 . hence @xmath484 is increasing and concave on @xmath485 .",
    "since the cost function in the transformed space is increasing and concave from a certain point on , there is a linear majorant that touches the cost function once and only once .",
    "we can conclude that for any @xmath251 and the parameter set , we have a connected continuation region in the form of @xmath86 .",
    "for this fixed @xmath209 , let us define @xmath282 such that @xmath283 and @xmath486 if @xmath487 and @xmath488 if @xmath489 .",
    "then we have for any @xmath251 , @xmath490 recall that the left boundary @xmath491 is natural for a brownian motion",
    ". hence @xmath492 that passes the origin of the transformed space is the straight - line majorant of @xmath493 where @xmath494 is defined in ( [ eq : myr ] ) : @xmath495 we can represent @xmath496 as @xmath497 . since @xmath498 is differentiable with respect to @xmath11 on @xmath499 , we can use ( [ eq : simplesystem ] ) to find @xmath294 and corresponding @xmath284 . then varying @xmath209",
    ", one can find the optimal @xmath500 .",
    "going back to the original space , on @xmath501 $ ] @xmath502 to get @xmath503 , we add back @xmath199 , @xmath504 finally , flip the sign and obtain the optimal cost function @xmath505 which coincides with the solution given by ksendal @xcite .",
    "figure 1 displays the solution with parameters @xmath506 .     against @xmath209 ,",
    "the former being maximized at @xmath507 with @xmath508 .",
    "( b ) the functions @xmath509 shifted by the amount @xmath510 ( lower curve ) and the majorant @xmath511 ( upper curve ) corresponding to @xmath304 , giving us @xmath512 .",
    "( c ) the cost function @xmath513 .",
    "( d ) the derivative of @xmath513 , showing that the smooth - fit principle holds at @xmath514.,title=\"fig : \" ] + ( a )     against @xmath209 , the former being maximized at @xmath507 with @xmath508 .",
    "( b ) the functions @xmath509 shifted by the amount @xmath510 ( lower curve ) and the majorant @xmath511 ( upper curve ) corresponding to @xmath304 , giving us @xmath512 .",
    "( c ) the cost function @xmath513 .",
    "( d ) the derivative of @xmath513 , showing that the smooth - fit principle holds at @xmath514.,title=\"fig : \" ] + ( b )     against @xmath209 , the former being maximized at @xmath507 with @xmath508 .",
    "( b ) the functions @xmath509 shifted by the amount @xmath510 ( lower curve ) and the majorant @xmath511 ( upper curve ) corresponding to @xmath304 , giving us @xmath512 .",
    "( c ) the cost function @xmath513 .",
    "( d ) the derivative of @xmath513 , showing that the smooth - fit principle holds at @xmath514.,title=\"fig : \" ] + ( c )     against @xmath209 , the former being maximized at @xmath507 with @xmath508 .",
    "( b ) the functions @xmath509 shifted by the amount @xmath510 ( lower curve ) and the majorant @xmath511 ( upper curve ) corresponding to @xmath304 , giving us @xmath512 .",
    "( c ) the cost function @xmath513 .",
    "( d ) the derivative of @xmath513 , showing that the smooth - fit principle holds at @xmath514.,title=\"fig : \" ] + ( d )    [ fig:2 ]     +    [ ex : ou ] this example is a dividend payout problem where the underlying process follows an ornstein - uhlenbeck process .",
    "this problem was originally studied by cadenillas et al.@xcite in an ingenious way , but the existence of the finite value function and the connectedness of the continuation region were left open .",
    "suppose that @xmath2 has the dynamics @xmath515 where @xmath516 , @xmath517 and @xmath518 .",
    "only positive impulse is allowed in this problem .",
    "we consider the impulse control problem , @xmath519.\\ ] ] with some positive constant @xmath520 , @xmath331 and the risk - aversion parameter @xmath521 $ ] .",
    "since @xmath522 , we have @xmath523 the functions @xmath26 and @xmath27 are positive , increasing and decreasing solutions of the differential equation @xmath524 .",
    "we denote , by @xmath525 and @xmath526 , the functions of the fundamental solutions for the auxiliary process @xmath527 , which satisfies @xmath528 . for every @xmath529 , @xmath530 and @xmath531 and @xmath532 , where @xmath533 is the parabolic cylinder function ; ( see borodin and salminen ( 2002 , appendices 1.24 and 2.9 ) and carmona and dayanik ( 2003 , section 6.3 ) ) . by using the relation @xmath534 in terms of the hermite function @xmath535 of degree @xmath536 and its integral representation @xmath537 ( see for example , lebedev(1972 , pp284 , 290 ) ) .",
    "let us consider the function @xmath538.\\ ] ] since the function @xmath15 is increasing , the function @xmath539 is also increasing .",
    "let us define the function @xmath540 which satisfies @xmath479 . by using ( [ eq :",
    "devh ] ) , @xmath541 and @xmath542 have the same sign at every @xmath10 where @xmath543 is twice - differentiable .",
    "hence we study the ( positive ) roots of @xmath544 .",
    "we have to divide two cases : ( 1 ) @xmath545 and ( 2 ) @xmath546 . in either case",
    ", it can be shown that @xmath547 by using ( [ eq : dft ] ) and ( [ eq : hermite ] ) and the identity @xmath548 .",
    "therefore , by proposition [ prop : genk ] , the finiteness of the value function is proved .",
    "* @xmath545 : @xmath15 reduces to a linear function and the @xmath544 always has a one positive root , say @xmath549 .",
    "@xmath448 function is convex on @xmath550 and concave on @xmath551 .",
    "hence we have a connected continuation region @xmath552 . *",
    "@xmath546 : we observe that @xmath553 , @xmath554 , @xmath555 , and @xmath556 .",
    "a direct analysis of @xmath557 shows that there is only one stationary point in @xmath558 and the number of the roots of @xmath544 is either @xmath559 or @xmath560 .",
    "hence in the first two cases , @xmath448 is concave on @xmath561 and the continuation region is connected . in the last case",
    "where there are two roots , say @xmath562 .",
    "the @xmath448 function is then concave on @xmath563 and is convex on @xmath564 . since @xmath448 increases and concave on @xmath565 , we can conclude that the continuation region is connected in this case as well .",
    "let us move on to finding an optimal continuation region . by fixing @xmath251 ,",
    "let us define @xmath566 if @xmath414 , @xmath567 if @xmath568 and @xmath569 if @xmath499 .",
    "when we solve ( [ eq : simplesystem ] ) for this @xmath209 , it is not easy ( at least analytically ) to solve @xmath570 explicitly .",
    "we can bypass this difficulty by using the first identity of ( [ eq : devh ] ) so that ( [ eq : simplesystem - absorbing ] ) with @xmath571 becomes @xmath572 as in the previous examples , @xmath282 is a straight line passing @xmath573 in the form of @xmath574 .",
    "the value function @xmath87 in @xmath575 is @xmath576 therefore , the solution to the problem is @xmath577 this solves the problem . see figure 2-(b ) for the value function in case of parameters @xmath578 , @xmath579 , @xmath580 , @xmath581 for the diffusions . as for the reward / cost function parameters , @xmath582 , @xmath583 and @xmath584 .",
    "the solution is @xmath585 .",
    "[ ex : sin ] we show a simple example where we have multiple continuation regions , the first case of remark [ rmk : pathology ] . let the uncontrolled process is a standard brownian motion @xmath586 and let @xmath587 , @xmath588 and @xmath589 with @xmath590 and @xmath591 being some constant parameters .",
    "we want to solve @xmath592.\\ ] ] in this case @xmath593 and let us define @xmath594 by solving ( [ eq : simplesystem ] ) with some parameter @xmath595 , we find that @xmath596 and @xmath597 with @xmath598 .",
    "for all these pairs , @xmath302 has a common value of @xmath599 .",
    "hence all these pairs are optimal .",
    "this implies that if the initial state @xmath600 , then we let the process move until it reaches @xmath601 or @xmath602 .",
    "if it reaches @xmath601 first , then an intervention is made to @xmath603 .",
    "now we are in the interval @xmath604 .",
    "we continue until the process is absorbed at @xmath414 .",
    "before we conclude this article , we shall mention an immediate extension to two boundary impulse control problems : @xmath605\\ ] ] and @xmath606 for all @xmath529 , where @xmath607 with @xmath608 corresponds to interventions at the upper boundary at intervention time @xmath59 and @xmath609 at the lower boundary at intervention time @xmath610 .",
    "examples of this type include the storage model analyzed by harrison et al .",
    "@xcite and foreign exchange rate model studied by jeanblanc - picqu  @xcite .",
    "the former problem , for example , is that a controller continuously monitors the inventory so that the inventory level will not fall below the zero level .",
    "he is allowed to make interventions by increasing and decreasing the inventory by paying costs associated with interventions . in this case , the process remains within some band(s ) . in other words ,",
    "the optimal intervention times are characterized as exit times from an interval in the form of @xmath611 for @xmath612 .",
    "see korn @xcite for survey .",
    "under suitable assumptions , we can develop a similar argument to the previous chapters . among others ,",
    "the intervention times can be characterized as exit times from an interval @xmath611 .",
    "we can also simplify the performance measure ,    @xmath613\\\\ + { \\mathbb{e}^{x}}[1_{\\{t_1>s_1\\}}e^{-\\alpha s_1}\\{c_2(x_{s_1-},x_{s_1})-g(x_{s_1-})+j^\\nu(x_{s_1})\\}]+g(x)\\end{gathered}\\ ] ]    where @xmath614 as usual .",
    "again , the last term does not depend on controls , we define @xmath217 as @xmath468 ,    @xmath615 + { \\mathbb{e}^{x}}[1_{\\{\\tau_b>\\tau_p\\}}e^{-\\alpha \\tau_p}u(p ) ] , \\quad x\\in[p , b ] \\ ] ]    where @xmath616 and @xmath617 and it follows that @xmath618.\\label{eq : complex}\\end{aligned}\\ ] ] hence if we define @xmath219 , we have linear characterization again in the transformed space ; @xmath619.\\ ] ] and the solution to the problem is described as @xmath620 + { \\mathbb{e}^{x}}[1_{\\{\\tau_b>\\tau_p\\}}e^{-\\alpha \\tau_p}u(p ) ] , & p\\leq x \\leq b\\\\                          \\bar{c}_1(x , a)+u_0(a ) , & b\\leq x          \\end{cases}\\end{aligned}\\ ] ] where @xmath621 for @xmath622 and @xmath560 .",
    "+ we have studied impulse control problems .",
    "the intervention times are characterized as exit times of the process from a finite union of disjoint intervals on the real line .",
    "a sufficient condition is given for the connectedness of the continuation region .",
    "the value function is shown to be linear in certain transformed space and a direct calculation method is described for it .",
    "this method can handle impulse control problems with non - smooth reward and cost functions .",
    "the finiteness of the value function is shown to be equivalent to the existence of a concave majorant of a suitable transformation .",
    "the latter is easier to check by using geometric arguments .",
    "the new characterization of the value function and optimal strategies can be extended to other optimization problems , such as optimal switching , singular stochastic control and combined problems of optimal stopping and impulse control .",
    "if an optimal strategy exists in the class of exit times , then the problem can be reduced to a sequence of optimal stopping problems and an effective characterization of the value function is possible .",
    "to make the proof more intuitive , we will work with ( [ eq : wrec ] ) rather than with ( [ eq : wrec2 ] ) where the integration part is converted to @xmath136 functions .",
    "for this purpose , it is convenient to define the following two operators @xmath623 and @xmath624 : @xmath625\\ ] ] and @xmath626.\\ ] ] hence we can proceed with the arguments developed in davis @xcite . in terms of the two operators",
    "just defined , ( [ eq : wrec ] ) becomes @xmath627\\\\ & = \\mathcal{l}_ow_n(x).\\end{aligned}\\ ] ] ( 1 ) @xmath119 for all @xmath93 : let us now prove @xmath628 for all @xmath629 .",
    "we show already @xmath630 .",
    "we assume , to make an induction argument , that @xmath628 and prove @xmath631 .",
    "we should note that , for each @xmath93 , the optimization problem in ( [ eq : lo ] ) is an optimal stopping problem .",
    "hence by proposition [ prop:4 ] , we can confine the set of strategy @xmath89 in ( [ eq : vn ] ) into a smaller set , i.e. barrier strategies ; @xmath632 now we proceed with the planned induction argument , @xmath633\\\\ & = \\sup_{(\\tau , \\xi ) \\in \\bar{s}_1}{\\mathbb{e}^{x}}\\left[\\int_0^{\\tau}e^{-\\alpha s}f(x_s)ds+e^{-\\alpha \\tau}(k(x_{\\tau- } , x_{\\tau})+v_n(x_\\tau))\\right]\\\\ & = \\sup_{(\\tau , \\xi ) \\in \\bar{s}_1}{\\mathbb{e}^{x}}\\left[\\int_0^{\\tau}e^{-\\alpha s}f(x_s)ds+e^{-\\alpha \\tau}(k(x_{\\tau- } , x_{\\tau})+w_n(x_\\tau))\\right]\\\\ & = \\sup_{\\tau \\in \\mathcal{s}}{\\mathbb{e}^{x}}\\left[\\int_0^{\\tau}e^{-\\alpha s}f(x_s)ds+e^{-\\alpha \\tau}\\mathcal{m}_o w_n(x_\\tau)\\right]=\\mathcal{l}_ow_n(x)=w_{n+1}(x)\\end{aligned}\\ ] ] for all @xmath74 .",
    "the second equality is due to the strong markov property justified by ( [ eq : bars ] ) .",
    "the third equality is by the induction hypothesis .",
    "this proves the first statement of the lemma .",
    "\\(2 ) @xmath634 : since @xmath117 is monotone increasing , the limit @xmath635 exists .",
    "since @xmath636 , @xmath637 .",
    "hence @xmath638 . to show the reverse inequality , we define @xmath639 be a set of interventions such that @xmath640 let us assume that @xmath641 and consider strategy @xmath642 and another strategy @xmath643 that coincides with @xmath644 up to and including time @xmath645 and then takes no further interventions . @xmath646,\\end{aligned}\\ ] ] which implies @xmath647.\\ ] ] as @xmath648",
    ", the right hand side goes to @xmath65 by the dominated convergence theorem .",
    "hence it is shown @xmath649 so that @xmath650 .",
    "next , consider the case of @xmath651 . by proposition [ prop : genk ]",
    ", we have @xmath322 in this case .",
    "then by the recursive method described in section [ sec : first ] , we see that @xmath652 . by the first statement of this lemma",
    ", we can conclude @xmath653 for all @xmath629 , obtaining @xmath654 .",
    "this completes the proof of the second statement .",
    "\\(3 ) @xmath655 : since @xmath656 , we have the following chain of equalities : @xmath657 = \\sup_{y\\in \\mathbb{r}}\\sup_{n\\in \\mathbb{n}}[k(x , y ) + w_n(y)]\\\\ & = \\sup_{n\\in \\mathbb{n}}\\sup_{y\\in \\mathbb{r}}[k(x , y)+w_n(y)]=\\sup_{n\\in \\mathbb{n}}\\mathcal{m}_o w_n(x).\\end{aligned}\\ ] ] in view of this , if we take the limit on the both sides of ( [ eq : wn+1 ] ) as @xmath658 , by the monotone convergence theorem , @xmath659.\\ ] ] this shows that @xmath655 .",
    "suppose @xmath660 satisfies @xmath661 and majorizes @xmath662 . then @xmath663 .",
    "if we assume that @xmath664 , then @xmath665 by the induction argument , we have @xmath666 for all @xmath93 , leading to @xmath667 .",
    "thus it shows that @xmath135 is the smallest solution majorizing @xmath136 of the functional equation , @xmath137 .",
    "this completes the third statement of the lemma ."
  ],
  "abstract_text": [
    "<S> we consider stochastic impulse control problems where the process is driven by a general one - dimensional diffusions . </S>",
    "<S> impulse control problems are widely used to financial engineering / decision - making problems such as dividend payout problem , portfolio optimization with transaction costs , and inventory control . </S>",
    "<S> we shall show a new mathematical characterization of the value function as a linear function in certain transformed space . our approach can ( 1 ) relieve us from the burden of guessing and proving the optimal strategy , ( 2 ) present a simple method to find the value function and the corresponding control policies , and ( 3 ) handle systematically a broader class of reward and cost functions than the conventional methods of quasi variational inequalities , especially because the existence of the finite value function can be shown in much a simpler way . </S>",
    "<S> +   + key words : stochastic impulse control , diffusions , optimal stopping , concavity . </S>",
    "<S> + ams subject classification : primary : 49n25 secondary : 60g40 . </S>"
  ]
}