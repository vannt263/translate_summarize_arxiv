{
  "article_text": [
    "markov chain monte carlo ( mcmc ) algorithms are one of the key tools in computational statistics .",
    "they are used for the approximation of expectations with respect to probability measures given by unnormalized densities . for almost all classical mcmc methods it is essential to evaluate the target density . in many cases ,",
    "this requirement is not an issue , but there are also important applications where it is a problem .",
    "this includes applications where the density is not available in closed form , see @xcite , or where an exact evaluation is computationally too demanding , see @xcite .",
    "problems of this kind lead to the approximation of markov chains and to the question of how small differences in the transitions of two markov chains affect the differences between their distributions .    in bayesian inference",
    "when _ big data _ sets are involved an exact evaluation of the target density is typically very expensive .",
    "for instance , in each step of a metropolis - hastings algorithm the likelihood of a proposed state must be computed .",
    "every observation in the underlying data set contributes to the likelihood and must be taken into account in the calculation .",
    "this may result in evaluating several terabytes of data in each step of the algorithm .",
    "these are the reasons for the recent interest in numerically cheaper approximations of classical mcmc methods , see @xcite .",
    "a reduction of the computational costs can , e.g. , be achieved by relying on a moderately sized random subsample of the data in each step of the algorithm .",
    "the function value of the target density is thus replaced by an approximation .",
    "naturally , subsampling and alternative attempts at `` cutting the metropolis - hastings budget '' @xcite induce additional biases .",
    "these biases can lead to dramatic changes in the properties of the algorithms as discussed in @xcite .",
    "we thus need a better theoretical understanding of the behavior of such _ approximate mcmc _ methods .",
    "indeed , a number of recent papers prove estimates of these biases , see @xcite .",
    "a key tool in these papers are perturbation bounds for markov chains .",
    "one such result for uniformly ergodic markov chains due to mitrophanov @xcite is used in @xcite .",
    "a similar perturbation estimate implicitly appears in @xcite .",
    "the focus on uniformly ergodic markov chains is rather restrictive , especially for high - dimensional , non - compact state spaces such as @xmath1 . working with wasserstein distances",
    "has recently turned out to be a fruitful alternative in several contributions on high - dimensional mcmc algorithms , see @xcite .",
    "we provide perturbation bounds based on wasserstein distances , which lead to flexible quantitative estimates of the biases of approximate mcmc methods .",
    "our first main result is the wasserstein perturbation bound of theorem [ thm : drift ] . under a wasserstein ergodicity assumption , explained in section  [ secprelim ]",
    ", it provides an upper bound on the distance of the @xmath0th step distribution between an ideal and an approximating markov chain in terms of the difference between their one - step transition probabilities .",
    "the result is well - suited for applications on a non - compact state space , since the difference of the one - step transition probabilities is measured by a weighted supremum with respect to a suitable lyapunov function . for an autoregressive model ,",
    "we show in section [ subsec : auto_regr_proc ] that the resulting perturbation bound can not be improved in general . as a consequence of the wasserstein approach we also obtain perturbation estimates for geometrically ergodic markov chains .",
    "we first adapt our wasserstein perturbation bound to this setting .",
    "then , as a second main result , theorem [ thm geom3 ] , we prove a refined estimate for geometrically ergodic chains where the perturbation is measured by a weighted total variation distance .",
    "our perturbation bounds , and earlier ones in @xcite , establish a direct connection between an exponential convergence property for markov chains and their robustness to perturbations .",
    "in particular , fast convergence to stationarity implies insensitivity to perturbations in the transition probabilities .",
    "geometric ergodicity has been studied extensively in the mcmc literature .",
    "thus , our estimates can be used in combination with many existing convergence results for mcmc algorithms . in section [ sec : appl ] , we illustrate the applicability of both theorems by generalizing recent findings on approximate metropolis - hastings algorithms from @xcite and on noisy langevin algorithms for gibbs random fields from @xcite .",
    "we refer to @xcite for an overview of the classical literature on perturbation theory for markov chains .",
    "however , as stuart and shardlow observed in @xcite , the classical assumptions on the perturbation might be too restrictive for many interesting applications . as a consequence , they develop a perturbation theory for geometrically ergodic markov chains @xcite which requires to control perturbations of iterated transition kernels in a weaker sense . in our bounds for geometrically ergodic markov chains , we have similar flexibility in the perturbation due to the lyapunov - type stability condition , and require only a control on the errors of one - step transition kernels .",
    "mitrophanov , in @xcite , considers uniformly ergodic markov chains and provides the best estimates in those settings . in the geometrically ergodic case ,",
    "there are further related results , see @xcite and the references therein .",
    "compared to @xcite , our focus is on non - asymptotic estimates with explicit constants , while their main focus is on qualitative results such as inheritance of geometric ergodicity by the perturbation . earlier related results on perturbations induced by floating - point roundoff errors are shown in @xcite .",
    "finally , let us point out that our paper is complementary to the work of pillai and smith @xcite who also present wasserstein perturbation bounds for markov chains . when moving beyond the uniformly ergodic markov chain case , an important challenge is to handle the issue that in many applications suprema of relevant quantities over the whole state space are infinite .",
    "the authors of @xcite guarantee finiteness of supremum norms by restricting attention to subsets of the state space . their bounds thus involve exit probabilities from these subsets .",
    "our approach circumvents these issues by relying on lyapunov - type stability conditions for the approximate algorithm .",
    "let @xmath2 be a polish space and @xmath3 be the corresponding borel @xmath4-algebra .",
    "let @xmath5 be a metric , possibly different from the one which makes the space polish , which is assumed to be lower semi - continuous with respect to the product topology of @xmath2 .",
    "let @xmath6 be the set of all borel probability measures on @xmath7 .",
    "then , we define the wasserstein distance of @xmath8 by @xmath9 where @xmath10 is the set of all couplings of @xmath11 and @xmath12 , that is , all probability measures @xmath13 on @xmath14 with marginals @xmath11 and @xmath12 .",
    "indeed , on @xmath6 the wasserstein distance satisfies the properties of a metric but is not necessarily finite , see ( * ? ? ?",
    "* chapter  6 ) . for a measurable function @xmath15",
    "we define @xmath16 which leads to the well - known duality formula @xmath17 for details we refer to ( * ? ? ?",
    "* chapter  1.2 ) . by @xmath18",
    "we denote the probability measure concentrated at @xmath19 .",
    "hence @xmath20 is finite for @xmath21 .",
    "let @xmath22 be a transition kernel on @xmath7 which defines a linear operator @xmath23 given by @xmath24 with this notation we have @xmath25 .",
    "further , for a measurable function @xmath15 and @xmath26 we have @xmath27 with @xmath28 whenever one of the integrals exist , see for example ( * ? ? ?",
    "* lemma  3.6 ) .",
    "now , by @xmath29 we define the _ generalized ergodicity coefficient _ of transition kernel @xmath22 .",
    "this coefficient can be understood as a generalized dobrushin ergodicity coefficient , see @xcite .",
    "dobrushin himself called @xmath30 the kantorovich norm of @xmath22 , see ( * ? ?",
    "* formula ( 14.34 ) ) . finally , @xmath30 also provides a lower bound of the coarse ricci curvature of @xmath22 introduced in @xcite .",
    "two essential properties of the ergodicity coefficient are submultiplicativity and contractivity , see ( * ? ? ? * proposition  14.3 and proposition  14.4 ) .",
    "[ prop : contr_subm ] for two transition kernels @xmath22 and @xmath31 on @xmath7 and @xmath32 , we have @xmath33    as an immediate consequence of this contractivity , we obtain the following corollary .",
    "[ cor : wass_erg ] let @xmath22 be a transition kernel with stationary distribution @xmath34 , i.e. @xmath35 , and assume for some ( and hence any ) @xmath36 it holds that @xmath37 .",
    "then @xmath38    because of the assumption @xmath37 we have that @xmath39 is finite for any @xmath40 .",
    "thus , the assertion follows by proposition  [ prop : contr_subm ] and stationarity of @xmath34 .    for some special cases",
    "one also has an estimate of the form in the other direction .",
    "to this end , consider the trivial metric @xmath41 with indicator function @xmath42 further , let @xmath43 be the total variation norm of a signed measure @xmath44 on @xmath2 . in this setting @xmath45 .",
    "for @xmath21 with @xmath46 we have @xmath47 so that @xmath48 the `` @xmath49 '' in the subscript of @xmath50 indicates that we use the trivial metric . by applying the triangle inequality of the total variation norm",
    "we obtain @xmath51 .",
    "if additionally @xmath34 is atom - free , i.e. , @xmath52 for all @xmath53 , we have @xmath54 then , the previous consideration and lead to @xmath55 for the moment , let us assume that @xmath22 is uniformly ergodic , that is , there exist numbers @xmath56 and @xmath57 such that @xmath58 an immediate consequence of the uniform ergodicity is that @xmath59 .",
    "also note that if there is an @xmath60 for which @xmath61 we have by the submultiplicativity , see proposition  [ prop : contr_subm ] , that @xmath62 converges exponentially to zero .",
    "this motivates to impose the following assumption which contains the idea to measure convergence of @xmath63 to @xmath34 in terms of @xmath64 .",
    "[ ass : wass_contr ] for the transition kernel @xmath22 there exist numbers @xmath56 and @xmath57 such that @xmath65    for any probability measure @xmath66 , a transition kernel @xmath22 with stationary distribution @xmath34 and @xmath67 we have under the wasserstein ergodicity condition that @xmath68",
    "by @xmath69 we denote the non - negative integers and assume that all random variables are defined on a common probability space @xmath70 mapping to a polish space @xmath2 equipped with a lower semi - continuous metric @xmath5 .",
    "let the sequence of random variables @xmath71 be a markov chain with transition kernel @xmath22 and initial distribution @xmath72 , i.e. , we have almost surely @xmath73 and @xmath74 for any measurable set @xmath75 .",
    "assume that @xmath76 is another markov chain with transition kernel @xmath31 and initial distribution @xmath77 .",
    "we denote by @xmath78 the distribution of @xmath79 and by @xmath80 the distribution of @xmath81 . throughout the paper , @xmath82 is considered to be the ideal , unperturbed markov chain we would like to simulate while @xmath76 is the perturbed markov chain that we actually implement .",
    "similar as in ( * ? ? ?",
    "* theorem  3.1 ) , we show quantitative bounds on the difference of @xmath78 and @xmath80 , but use the wasserstein distance instead of total variation . besides assumption  [ ass : wass_contr ] , the bounds depend on the difference of the initial distributions and on a suitably weighted one - step difference between @xmath22 and @xmath83 .",
    "[ thm : drift ] let assumption  [ ass : wass_contr ] be satisfied with the numbers @xmath57 and @xmath84 , i.e. , @xmath85 .",
    "assume that there are numbers @xmath86 and @xmath87 and a measurable lyapunov function @xmath88 of @xmath31 such that @xmath89 let @xmath90 with @xmath91 .",
    "then @xmath92    by induction one can show that @xmath93 we have @xmath94 moreover , for @xmath95 we have @xmath96 so that we obtain @xmath97 . by this fact we have @xmath98 then , by , and the triangle inequality of the wasserstein distance we have @xmath99 finally , by we obtain @xmath100 which allows us to complete the proof .",
    "[ rem : triv_drift ] the parameter @xmath101 is an upper bound on @xmath102 . it can be interpreted as a measure for the stability of the perturbed markov chain .",
    "the parameter @xmath103 quantifies with a weighted supremum norm the one - step difference between @xmath22 and @xmath31 .",
    "the use of the lyapunov function increases the flexibility of the resulting estimate , since larger values of @xmath104 compensate larger values of the wasserstein distance between the kernels .",
    "notice that the existence of a lyapunov function satisfying is weaker than assuming @xmath104-uniform ergodicity of @xmath31 since it is not associated with a small set condition .",
    "in particular , the condition is satisfied for any @xmath31 with the trivial choice @xmath105 for all @xmath40 , see corollary [ thm : was_mith ] . as we will see in section [ sec : appl ] , allowing for non - trivial choices of @xmath104 considerably increases the applicability of our results .",
    "if @xmath31 has a stationary distribution , say @xmath106 , as a consequence of the previous theorem , we obtain bounds on the difference between @xmath34 and @xmath107 .",
    "[ cor : wass_pi_pi_tilde ] let the assumptions of theorem  [ thm : was_mith ] be satisfied .",
    "assume that @xmath31 has a stationary distribution @xmath108 and let @xmath109 be finite .",
    "then @xmath110    by theorem  [ thm geom3 ] we obtain with @xmath111 , @xmath112 , the stationarity of the distributions @xmath34 , @xmath107 and by letting @xmath113 that @xmath114 by the lyapunov condition and ( * ? ? ?",
    "* proposition  4.24 ) , it holds that @xmath115 which leads to @xmath116 and finishes the proof .",
    "it may seem artificial to assume @xmath117 but this is needed for the limit argument in the proof .",
    "this condition is often satisfied a priori .",
    "for example , it holds if the metric is bounded , i.e. , @xmath118 is finite , or , more generally , if the distributions @xmath34 and @xmath107 possess a first moment in the sense that there exist @xmath119 such that @xmath120    as pointed out in remark [ rem : triv_drift ] , we do not need to impose condition to obtain a non - trivial perturbation bound :    [ thm : was_mith ] assume that assumption  [ ass : wass_contr ] holds with the numbers @xmath57 and @xmath84 , i.e. , @xmath85 , and let @xmath121 then @xmath122    the statement follows by theorem  [ thm : drift ] with @xmath123 and @xmath124 .    for the trivial metric @xmath41 the last corollary states essentially the result of (",
    "* theorem  3.1 ) , where instead of the general wasserstein distance the total variation distance is used .",
    "there , the bound s dependence on @xmath125 and @xmath126 can be further improved by using the a priori bound @xmath127 in addition to uniform ergodicity . for another metric @xmath5",
    "such an a priori bound is in general not available .",
    "table  [ table : comp ] provides a detailed comparison between our theorem  [ thm : drift ] and the related wasserstein perturbation result of pillai and smith , ( * ? ? ?",
    "* lemma  3.3 ) .",
    "an important ingredient in their estimate is a set @xmath128 which can be interpreted as the part of @xmath2 where both markov chains remain with high probability .",
    "when a good uniform upper bound on @xmath129 for all @xmath130 is available , we can choose @xmath131 in ( * ? ? ?",
    "* lemma  3.3 ) and @xmath132 in theorem  [ thm : drift ] . in that case",
    ", both results essentially simplify to corollary [ thm : was_mith ] .",
    "the results become entirely different when such a bound is not available or too rough . in our estimate , one then needs a non - trivial lyapunov function for @xmath31 and a uniform upper bound on @xmath133 . to apply their estimate",
    ", one needs a uniform bound on @xmath129 for all @xmath134 .",
    "in addition , a bound on @xmath135 , lyapunov functions and estimates of the exit probabilities from @xmath136 of both markov chains need to be available .",
    "finally , while ( * ? ? ?",
    "* lemma  3.3 ) requires slightly more regularity on the lyapunov function , contractivity of the unperturbed transition kernel @xmath22 ( with @xmath137 ) is not needed on the whole state space but only on @xmath136 .",
    "[ table : comp ]        @c@ +   +   +    &    .comparison of the wasserstein perturbation bound of ( * ? ? ? * lemma  3.3 ) and theorem  3.1 .",
    "here @xmath138 , @xmath139 , @xmath140 , @xmath141 and @xmath142 [ cols=\"^ \" , ]      +      in this section , we derive general perturbation bounds for geometrically ergodic markov chains .",
    "first , we recall some results from @xcite , @xcite and @xcite which are helpful to apply our wasserstein perturbation bounds in the geometrically ergodic case",
    ". then we present the new estimates :    * corollary  [ cor geom1 ] is an application of theorem [ thm : drift ] with wasserstein distances replaced by @xmath143-norms of differences between measures . * in corollary  [ cor geom2 ] , we show that having a lyapunov function @xmath143 for @xmath22 is sufficient for our bounds if the transition kernels @xmath22 and @xmath31 are sufficiently close ( in a suitable sense ) . * in theorem [ thm geom3 ] ,",
    "we provide a quantitative perturbation bound which still applies if we can only control the total variation distance between @xmath144 and @xmath145 .",
    "to measure the perturbation in such a weak sense is new for geometrically ergodic markov chains .",
    "a transition kernel @xmath22 with stationary distribution @xmath34 is called geometrically ergodic if there is a constant @xmath84 and a measurable function @xmath146 such that for @xmath34-a.e .",
    "@xmath40 we have @xmath147 for @xmath148-irreducible and aperiodic markov chains , it is well known that geometric ergodicity is equivalent to @xmath143-uniform ergodicity , see ( * ? ? ?",
    "* proposition  2.1 ) .",
    "namely , if @xmath22 is geometrically ergodic , then there exists a @xmath34-a.e .",
    "finite measurable function @xmath149 $ ] with finite moments with respect to @xmath34 and there are constants @xmath84 and @xmath150 such that @xmath151 thus @xmath152 the following result establishes the connection between @xmath143-norms and certain wasserstein distances .",
    "it is basically due to hairer and mattingly @xcite , see also @xcite .",
    "[ lem dist ] assume that @xmath143 is lower semi - continuous on @xmath2 . for @xmath21 ,",
    "let us define the metric @xmath153 then , for any @xmath154 we have @xmath155 where @xmath156 denotes the wasserstein distance based on the metric @xmath157 .",
    "lower semi - continuity of @xmath143 implies lower semi - continuity of @xmath157 , which leads to the duality formula by ( * ? ? ?",
    "* theorem  1.14 ) .",
    "we thus impose the standing assumption of lower semi - continuity of @xmath143 whenever we speak of @xmath143-uniform ergodicity in the following . in principle",
    ", this requirement can be removed and remains true , but we do not go into further detail in that direction . in applications ,",
    "this is typically not restrictive since @xmath143 is continuous anyway .    by similar arguments as in the proof of (",
    "* theorem  1.1 ) we observe that implies a suitable upper bound on @xmath158    [ lem : v_unif_contr ] if is satisfied for the transition kernel @xmath22 , then @xmath159    for any positive real numbers",
    "@xmath160 we have the following elementary inequality @xmath161 by we obtain @xmath162 now , by using we obtain the assertion .",
    "the lemmas above and theorem  [ thm : drift ] lead to the following new perturbation bound for geometrically ergodic markov chains .",
    "[ cor geom1 ]",
    "let @xmath22 be @xmath143-uniformly ergodic , i.e. , there are constants @xmath84 and @xmath150 such that @xmath163 we also assume that there are numbers @xmath86 and @xmath87 and a measurable lyapunov function @xmath88 of @xmath31 such that @xmath164 let @xmath165 with @xmath166 .",
    "then @xmath167    in ( * ? ? ?",
    "* theorem  3.1 ) , a related perturbation bound is proven .",
    "the convergence property of the unperturbed transition kernel is slightly weaker than our @xmath143-uniform ergodicity , but also based on a kind of lyapunov function .",
    "more restrictively , there it is assumed that the difference of @xmath168 and @xmath169 for all @xmath170 can be controlled .",
    "in addition , the perturbation error is measured with a weight given by the same lyapunov function as in the convergence property of @xmath22 , but by taking a supremum over a subset of test functions . with our approach",
    "we can take the supremum over all test functions and obtain similar estimates by setting @xmath171 .",
    "the next corollary demonstrates how the lyapunov function of @xmath31 can be replaced by a lyapunov function of @xmath22 , provided that the distance between the transition kernels is sufficiently small . notice that assuming the existence of a lyapunov function of @xmath22 in addition to the @xmath143-uniform ergodicity is a definition of constants rather than an additional requirement , see , e.g. , @xcite .",
    "[ cor geom2 ] let @xmath22 be @xmath143-uniformly ergodic , i.e. , there are constants @xmath84 and @xmath150 such that @xmath163 moreover , @xmath172 is a measurable lyapunov function of @xmath22 , such that @xmath173 with constants @xmath174 and @xmath175 .",
    "let @xmath176 with @xmath177 .",
    "if @xmath178 , then @xmath167    it suffices to show that @xmath179 and then to apply corollary [ cor geom1 ] .",
    "we have @xmath180 which implies .",
    "the assertion follows by the assumption that @xmath181 and an application of corollary  [ cor geom1 ] .    for discrete state spaces and under the requirement @xmath182 ,",
    "a result similar to the previous corollary is obtained in ( * ? ? ?",
    "* theorem  3 , corollary 3 ) .",
    "the authors of @xcite replace our constant @xmath101 by @xmath183 .",
    "this we could do as well , see the proof of theorem [ thm : drift ] .    in the perturbation bound of corollary  [ cor geom1 ] ,",
    "the function @xmath143 plays two roles . in its first role",
    ", @xmath143 appears in the @xmath143-uniform ergodicity condition and thus is used to quantify convergence of @xmath22 . in its second role , @xmath143 appears in the constant @xmath103 , with which we compare @xmath22 and @xmath31 , as well as in the definition of the distance between @xmath78 and @xmath80 .",
    "we can interpret @xmath103 of corollary  [ cor geom1 ] as an operator norm of @xmath184 . to this end , let @xmath185 be the set of all measurable functions @xmath186 with finite @xmath187 which means @xmath188 it is easily seen that @xmath189 is a normed linear space . in the setting of corollary  [ cor geom1 ]",
    ", we have @xmath190 in corollary  [ cor geom2 ] , the more restrictive case @xmath191 is considered .",
    "the corresponding operator norm @xmath192 appears in classical perturbation theory for markov chains , see @xcite .",
    "but as discussed in @xcite and @xcite it might be too restrictive to measure the perturbation with this operator norm for @xmath191 .    by relying , e.g. , on ( * ? ? ?",
    "* proposition  2 ) we have some flexibility in the choice of @xmath143 .",
    "there it is shown that , for @xmath193 , @xmath143-uniform ergodicity implies @xmath194-uniform ergodicity .",
    "this leads to less favorable constants in the @xmath194-uniform ergodicity of @xmath22 , but can relax the requirements on the similarity of @xmath22 and @xmath31 .",
    "namely , with a lyapunov function @xmath104 of @xmath31 we can apply corollary  [ cor geom1 ] with a @xmath195-uniformly ergodic @xmath22 and @xmath196 .",
    "unfortunately , this approach breaks down for @xmath197 . to see this , notice that @xmath194-uniform ergodicity with @xmath197 is just uniform ergodicity which is not implied by geometric ergodicity .",
    "the next theorem overcomes this limitation by separating the two roles of the function @xmath143 in the previous perturbation bounds . roughly , we set @xmath198 in the sense that we measure the distances between @xmath22 and @xmath31 as well as between @xmath78 and @xmath80 in the total variation distance .",
    "at the same time , we set @xmath191 in the sense that we assume @xmath22 is @xmath104-uniformly ergodic with lyapunov function @xmath104 .",
    "[ thm geom3 ] let @xmath22 be @xmath104-uniformly ergodic , i.e. , there are constants @xmath84 and @xmath150 such that @xmath199 moreover , @xmath141 is a measurable lyapunov function of @xmath31 and @xmath22 , such that @xmath200 with constants @xmath174 and @xmath175 .",
    "let @xmath201 with @xmath166 .",
    "then , for @xmath202 we have @xmath203    from the proof of theorem  [ thm : was_mith ] we know that @xmath204 by lemma  [ lem : v_unif_contr ] , we have @xmath205 fix a real number @xmath193 and let @xmath206 . by considering one can see that @xmath207 .",
    "this leads to @xmath208 we also have @xmath209 moreover , for @xmath95 we obtain @xmath210 and , by @xmath211 we have @xmath212 then @xmath213 finally , by lemma  [",
    "lem : v_unif_contr ] we obtain @xmath214 for @xmath215 , we can choose the numbers @xmath216 and @xmath217 .",
    "this yields @xmath218 and the proof is complete .",
    "[ rem : thm geom3 ] let @xmath106 be a stationary distribution of @xmath31 . notice that by the assumption that @xmath104 is lyapunov function of @xmath31 and ( * ? ? ?",
    "* proposition  4.24 ) it follows that @xmath219 .",
    "further , by the @xmath104-uniform ergodicity of @xmath22 we also know that @xmath220 is finite .",
    "thus , @xmath221 now , by theorem  [ thm geom3 ] we can bound @xmath222 with @xmath111 , @xmath112 and by letting @xmath113 .",
    "we obtain @xmath223    [ rem : thm geom4 ] let us comment on the dependence of @xmath103 .",
    "in section [ sec : langevin ] , we apply theorem  [ thm geom3 ] combined with in a setting where we have @xmath224 for a constant @xmath225 and some parameter @xmath226 of the perturbed transition kernel . for @xmath227 and",
    "any @xmath228 we have @xmath229 .",
    "then , with some simple calculations , we obtain for @xmath182 and @xmath230 the bound @xmath231    [ rem : kell_liv ] in the setting of theorem  [ thm geom3 ] , we can also interpret @xmath103 as an operator norm .",
    "namely , @xmath232 here the subscript `` @xmath49 '' in @xmath233 indicates @xmath234 for all @xmath40 , see . for @xmath235 and a family of perturbations @xmath236 let @xmath237 for @xmath238",
    "this condition appears in ( * ? ? ?",
    "* theorem  1 , condition ( 2 ) ) and is an assumption introduced by keller and liverani , see @xcite .",
    "we illustrate our perturbation bounds in three different settings . we begin with studying an autoregressive process",
    "also considered in @xcite .",
    "after this , we show quantitative perturbation bounds for approximate versions of two prominent mcmc algorithms , namely the metropolis - hastings and stochastic langevin algorithms .",
    "let @xmath239 and assume that @xmath71 is the autoregressive model defined by @xmath240 here @xmath241 is an @xmath242-valued random variable , @xmath243 and @xmath244 is an i.i.d .",
    "sequence of random variables , independent of @xmath241 .",
    "we also assume that the distribution of @xmath245 , say @xmath12 , admits a first moment .",
    "it is easily seen that @xmath246 is a markov chain with transition kernel @xmath247 and it is well known that there exists a stationary distribution , say @xmath248 , of @xmath249 .",
    "now , let the transition kernel @xmath250 with @xmath251 be an approximation of @xmath249 .",
    "for @xmath21 , let us consider the metric which is given by the absolute difference , i.e. , @xmath252 .",
    "we assume that @xmath253 is small and study the wasserstein distance , based on @xmath5 , of @xmath254 and @xmath255 with two probability measures @xmath72 and @xmath77 on @xmath256 .",
    "we intend to apply theorem  [ thm : drift ] .",
    "notice that for @xmath257 with @xmath258 we have @xmath259 which guarantees that condition is satisfied with @xmath260 and @xmath261 .",
    "furthermore @xmath262 leads to @xmath263 .",
    "similarly , one obtains @xmath264 which implies that @xmath265 we set @xmath266 and @xmath267 , @xmath268 .",
    "then , inequality of theorem  [ thm : drift ] gives @xmath269 and for @xmath270 we have @xmath271 from the previous two inequalities one can see that if @xmath272 is sufficiently close to @xmath273 , then the distance of the distribution @xmath274 and @xmath275 is small .",
    "let us emphasize here that we provide an explicit estimate rather than an asymptotic statement .",
    "note that by ( * ? ? ?",
    "* proposition  4.24 ) and the fact that @xmath276with @xmath277 and @xmath278 we obtain @xmath279 which leads to a finite @xmath280 . as a consequence we obtain for the stationary distributions of @xmath249 and @xmath250 by estimate that @xmath281 the dependence on @xmath253 in the previous inequality can not be improved in general . to see this ,",
    "let us assume that @xmath282 and @xmath283 are real - valued random variables with distribution @xmath248 and @xmath284 , respectively . then , because of the stationarity we have that @xmath285 and @xmath286 are also distributed according to @xmath248 and @xmath284 , respectively .",
    "thus @xmath287 now , for @xmath288 with @xmath289 , we have @xmath290 and thus @xmath291 hence , whenever @xmath292 we have a non - trivial lower bound with the same dependence on @xmath253 as in the upper bound of .",
    "this fact shows that we can not improve the upper bound .",
    "let us now discuss the application of corollary  [ cor geom2 ] and theorem  [ thm geom3 ] .",
    "under the additional assumption that @xmath12 , the distribution of @xmath245 , has a lebesgue density @xmath293 , it is shown in ( * ? ? ?",
    "* section  4 ) that the autoregressive model is also @xmath104-uniformly ergodic .",
    "precisely , there is a constant @xmath294 such that @xmath295 moreover , from ( * ? ? ?",
    "* example  1 ) we know that @xmath296 does not go to @xmath297 when @xmath298 .",
    "hence , corollary  [ cor geom2 ] can not quantify for small @xmath299 whether the @xmath0th step distributions are close to each other .",
    "however , also in ( * ? ? ?",
    "* example  1 ) it is proven that @xmath300 this indicates that theorem  [ thm geom3 ] is applicable . by assuming in addition that @xmath293 is _ _ weakly unimodal _ _ is called _ weakly unimodal _ if there exists @xmath301 such that @xmath302 is nondecreasing for @xmath303 and nonincreasing for @xmath304 . ] and bounded from above by @xmath305 , we can quantify the result .",
    "namely , @xmath306 to see the final estimate , define @xmath307 for @xmath308 . by unimodality , there exists for any fixed @xmath309 a constant @xmath310 such that @xmath311 the first summand on the right hand side we can bound by @xmath312 and similarly for the second summand . using that @xmath313 , we obtain @xmath314 . finally , by substitution we can write @xmath315 for simplicity set @xmath316 and assume that @xmath317 as well as @xmath318 . then , theorem  [ thm geom3 ] implies @xmath319 which seems to be new .",
    "we apply our perturbation results to the approximate ( or noisy ) metropolis - hastings algorithms analyzed in @xcite .",
    "we assume either that the unperturbed transition kernel of the metropolis - hastings algorithm satisfies the wasserstein ergodicity condition stated in assumption  [ ass : wass_contr ] or is geometrically ergodic .",
    "in particular , we do not assume that the transition kernel is uniformly ergodic .",
    "let @xmath34 be a probability distribution on @xmath7 and assume that we are interested in sampling realizations from this distribution .",
    "let @xmath320 be a transition kernel which serves as the proposal for the metropolis - hastings algorithm . from (",
    "* proposition  1 ) we know that there exists a set @xmath321 such that we can define the `` acceptance ratio '' for @xmath322 as @xmath323 then , let the acceptance probability be @xmath324 . with this notation",
    "the metropolis - hastings algorithm defines a transition kernel @xmath325 with @xmath326 we provide a step of a markov chain @xmath246 with transition kernel @xmath249 in algorithmic form .    [ alg mh ] a single transition from @xmath79 to @xmath327 of the metropolis - hastings algorithm works as follows :    1 .",
    "draw a sample @xmath328 and @xmath329 $ ] independently , call the result @xmath330 and @xmath331 ; 2 .",
    "set @xmath332 , with the ratio @xmath333 defined in ; 3 .",
    "if @xmath334 , then accept the proposal , and set @xmath335 , else reject the proposal and set @xmath336 .    now , suppose we are unable to evaluate @xmath337 , so that we are forced to work with an approximation of @xmath338 .",
    "the key idea behind approximate metropolis - hastings algorithms is to replace @xmath337 by a non - negative random variable @xmath339 with distribution , say @xmath340 , depending on @xmath21 and @xmath341 $ ] . for concrete choices of the random variable @xmath339 we refer to @xcite .",
    "we present a step of the corresponding markov chain @xmath342 in algorithmic form .",
    "[ alg amh ] a single transition from @xmath81 to @xmath343 works as follows :    1 .",
    "draw a sample @xmath344 and @xmath329 $ ] independently , call the result @xmath330 and @xmath331 ; 2 .   draw a sample @xmath345 , call the result @xmath346 ; 3 .",
    "if @xmath347 , then accept the proposal , and set @xmath348 , else reject the proposal and set @xmath349 .",
    "the algorithm has acceptance probability @xmath350}(u )   = \\int_0 ^ 1 \\int_0^\\infty \\mathbf{1}_{[0,\\min\\{1,\\widetilde r\\}]}(u)\\ ; { { \\rm d}}\\mu_{x , y , u } ( \\widetilde r ) { { \\rm d}}u\\ ] ] and the transition kernel of such a markov chain is still of the form with @xmath338 substituted by @xmath351 , i.e. , it is given by @xmath250 .",
    "the following results hold in the slightly more general case where @xmath351 is any approximation of the acceptance probability @xmath338 .",
    "the next lemma provides an estimate for the wasserstein distance between transition kernels of the form in terms of the acceptance probabilities .",
    "[ lem : noisy_wass ] let @xmath320 be a transition kernel on @xmath7 and let @xmath352 $ ] and @xmath353 $ ] be measurable functions . by @xmath354 and @xmath250",
    "we denote the transition kernels of the form with acceptance probabilities @xmath273 and @xmath272 .",
    "then , for all @xmath40 , we have @xmath355 with @xmath356 .    by the use of the dual representation of the wasserstein distance",
    "it follows that @xmath357    by the previous lemma and theorem  [ thm : drift ] , we obtain the following wasserstein perturbation bound for the approximate metropolis - hastings algorithm .",
    "[ cormh ] let @xmath320 be a transition kernel on @xmath7 and let @xmath352 $ ] and @xmath353 $ ] be measurable functions .",
    "by @xmath354 and @xmath250 we denote the transition kernels of the form with acceptance probabilities @xmath273 and @xmath272 .",
    "let the following conditions be satisfied :    * assumption  [ ass : wass_contr ] holds for the transition kernel @xmath249 , i.e. , @xmath358 for @xmath56 and @xmath57 .",
    "* there are numbers @xmath86 , @xmath87 and a measurable lyapunov function @xmath88 of @xmath250 , i.e. , @xmath359 * let @xmath360 and assume that @xmath361    then , for any @xmath66 and finite @xmath362 we have @xmath363 where @xmath364 .",
    "let us point out several aspects of condition .",
    "recall that is always satisfied with @xmath365 for all @xmath40 .",
    "however , in this case it seems more difficult to control @xmath103 .",
    "if some additional knowledge in form of a lyapunov function @xmath172 of @xmath249 , i.e. , @xmath366 for some @xmath86 and @xmath367 , is available , then a non - trivial candidate for @xmath104 is @xmath143 . for sufficiently small @xmath368",
    "this is indeed true .",
    "namely , we have @xmath369 then , @xmath370 and whenever @xmath371 it is clear that condition is verified .    to highlight the usefulness of a non - trivial lyapunov function , we consider the following scenario which is related to a local perturbation of an independent metropolis - hastings algorithm .",
    "let us assume that for @xmath249 assumption  [ ass : wass_contr ] , as formulated in corollary  [ cormh ] , is satisfied .",
    "for some probability measure @xmath12 on @xmath7 define @xmath372 and @xmath373 . for @xmath374",
    "let @xmath375 hence , for @xmath376 the transition kernel @xmath377 accepts any proposed state and for @xmath378 we have @xmath379 .",
    "it is easily seen that @xmath380 . for arbitrary @xmath381 and @xmath382 set @xmath383 and",
    "note that @xmath384 the last inequality of the previous formula follows by distinguishing the cases @xmath376 and @xmath385 .",
    "define @xmath386 and observe @xmath387 then , corollary  [ cormh ] leads to @xmath388 for arbitrary @xmath389 and @xmath382 . under the assumption that @xmath390 is finite and letting @xmath391 as well as @xmath392 we obtain @xmath393 which tells us that basically @xmath394 measures the difference of the distributions .",
    "a small perturbation set @xmath395 with respect to @xmath12 , thus implies a small bias .",
    "in contrast , with the trivial lyapunov function @xmath396 , and if there is @xmath397 such that @xmath398 , we only obtain @xmath399 the resulting upper bound on @xmath400 will typically be bounded away from zero regardless of the set @xmath395 .",
    "[ rem_noisy_metro ] the constant @xmath103 essentially depends on the distance @xmath401 and the difference of the acceptance probabilities @xmath402 . by applying the cauchy - schwarz inequality to the numerator of @xmath103 , we can separate the two parts , i.e. , @xmath403 if both integrals remain finite we see that an appropriate control of @xmath402 suffices for making the constant @xmath103 small .",
    "[ it : noisy_metr ] by using a hoeffding - type bound , in bardenet et al .",
    "* lemma  3.1 . )",
    "it is shown that for their version of the approximate metropolis - hastings algorithm with adaptive subsampling the approximation error @xmath402 is bounded uniformly in @xmath19 and @xmath330 by a constant @xmath404 .",
    "moreover , @xmath405 can be chosen arbitrarily small for the implementation of the algorithm .",
    "now we consider the case where the unperturbed transition kernel @xmath354 is geometrically ergodic .",
    "motivated by remark  [ it : noisy_metr ] , we also assume that @xmath406 for a sufficiently small number @xmath407 . the following corollary generalizes a main result of bardenet et al .",
    "* proposition  3.2 ) to the geometrically ergodic case .",
    "[ cor : metro_geom ] let @xmath320 be a transition kernel on @xmath7 and let @xmath352 $ ] and @xmath353 $ ] be measurable functions . by @xmath354 and @xmath250 we denote the transition kernels of the form with acceptance probabilities @xmath273 and @xmath272 .",
    "let the following conditions be satisfied :    * the unperturbed transition kernel @xmath249 is @xmath143-uniformly ergodic , that is , @xmath408 for numbers @xmath56 , @xmath57 and a measurable function @xmath409 .",
    "moreover , @xmath143 is a lyapunov function of @xmath354 , i.e. , @xmath410 for numbers @xmath86 and @xmath87 . * a uniform bound @xmath404 on the difference of the acceptance probabilities is given , that is , for all @xmath411 , we have @xmath412 * the constant @xmath413 satisfies @xmath414    if @xmath415 , then , for any @xmath66 with finite @xmath416 we have @xmath417    we consider the metric @xmath157 , defined in lemma [ lem dist ] , set @xmath191 and use @xmath418 so that it is easily seen that the constant @xmath103 from corollary [ cormh ] satisfies @xmath419 . from the proof of corollary [ cor geom2 ] , we know that @xmath143 is a lyapunov function of @xmath250 provided that @xmath420 . thus , we have @xmath421 now if @xmath415 , then @xmath422 and the assertion follows from corollary [ cormh ] by writing the wasserstein distances in terms of @xmath143-norms as in section [ sec : pert geom ] .    without @xmath423 in the denominator ,",
    "i.e. , if we had relied on corollary [ thm : was_mith ] instead of theorem [ thm : drift ] , the constant @xmath413 would often be infinite .",
    "consider the following toy example : let @xmath34 be the exponential distribution with density @xmath424 on @xmath425 and assume that @xmath426 is a uniform proposal with support @xmath427 $ ] . with @xmath428 it is well known that the metropolis - hastings algorithm is @xmath143-uniformly ergodic , see @xcite or ( * ? ? ?",
    "* example  4 ) . in this example",
    "@xmath429 whereas @xmath430 is unbounded in @xmath19 .",
    "notice that @xmath413 only depends on the unperturbed markov chain so that a bound on @xmath413 can be combined with any approximation .",
    "let @xmath250 and @xmath354 be @xmath148-irreducible and aperiodic .",
    "then , one can prove under the assumptions of corollary  [ cor : metro_geom ] that @xmath250 is @xmath143-uniformly ergodic if @xmath405 is sufficiently small . to see this , note that by ( * ? ? ?",
    "* theorem  16.0.1 ) the @xmath143-uniform ergodicity of @xmath354 implies that @xmath354 satisfies their drift condition ( v4 ) . by the arguments stated in the proof of corollary [ cor geom2 ] , one obtains that @xmath250 also satisfies ( v4 ) for sufficiently small @xmath405 and this implies @xmath143-uniform ergodicity . in this case , clearly @xmath250 possesses a stationary distribution , say @xmath107 , and @xmath431 the previous inequality follows by and the fact that @xmath432 here the finiteness of @xmath433 follows by the @xmath143-uniform ergodicity of @xmath22 and @xmath434 follows by and ( * ? ? ? * proposition  4.24 ) .",
    "an alternative to the metropolis - hastings algorithm is the langevin algorithm , see @xcite .",
    "unfortunately , in its implementation one needs the gradient of the density of the target distribution . to overcome this problem ,",
    "different approximate langevin algorithms have been proposed and studied , see @xcite .",
    "this section is mainly based on alquier et al .",
    "* section  3.4 ) where a noisy langevin algorithm for gibbs random fields is considered .",
    "we provide a quantitative version of ( * ? ? ?",
    "* theorem  3.2 ) .",
    "the setting is as follows .",
    "let @xmath435 be a finite set and with @xmath436 let @xmath437 be an observed data set on nodes @xmath438 of a certain graph .",
    "the likelihood of @xmath330 with parameter @xmath439 is defined by @xmath440 where @xmath441 is a given statistic .",
    "the density of the posterior distribution with respect to the lebesgue measure on @xmath256 given the data @xmath442 is determined by @xmath443 where the prior density @xmath444 is the lebesgue density of the normal distribution @xmath445 with @xmath446 .",
    "we consider the langevin algorithm , a first order euler discretization of the sde of the langevin diffusion , see @xcite .",
    "it is given by @xmath71 with @xmath447 here @xmath241 is a real - valued random variable and @xmath448 is an i.i.d .",
    "sequence of random variables , independent of @xmath241 , with @xmath449 for a parameter @xmath450 which can be interpreted as the step size in the discretization of the diffusion .",
    "it is easily seen that @xmath71 is a markov chain with transition kernel @xmath451 in general @xmath452 is not a stationary distribution of @xmath453 , but there exists a stationary distribution ( see proposition  [ prop : langevin ] below ) , say @xmath454 , which is close to @xmath452 depending on @xmath4 .",
    "let @xmath455 then , by the definition of @xmath452 we have @xmath456 where @xmath457 is a random variable on @xmath458 distributed according the likelihood distribution determined by @xmath459 .",
    "we do not have access to the exact value of the mean @xmath460 since in general we do not know the normalizing constant of the likelihood .",
    "we assume that we can use a monte carlo estimate . for @xmath461 let @xmath462 be an i.i.d .",
    "sequence of random variables with @xmath463 independent of @xmath244 from .",
    "then , @xmath464 is an approximation of @xmath465 which leads to an estimate of @xmath466 given by @xmath467 we substitute @xmath466 by @xmath468 in and obtain a sequence of random variables @xmath469 defined by @xmath470 the sequence @xmath471 is again a markov chain with transition kernel @xmath472 for @xmath473 and @xmath474 .",
    "let us state a transition of this noisy langevin markov chain according to @xmath475 in algorithmic form .    a single transition from @xmath81 to @xmath343 works as follows :    1 .",
    "[ it : draw_y ] draw an i.i.d .",
    "sequence @xmath476 with @xmath477 , call the result @xmath478 ; 2 .   calculate @xmath479 3 .",
    "draw @xmath480 , independent from step [ it : draw_y ] .",
    ", call the result @xmath481",
    ". set @xmath482    from ( * ? ? ? * lemma  3 ) and by applying arguments of @xcite , we obtain the following facts about the noisy langevin algorithm .    [ prop : langevin ] let @xmath483 be finite with @xmath484 , let @xmath485 be given by @xmath486 and assume that @xmath487",
    ". then    1 .",
    "[ en : 3 . ]",
    "the function @xmath143 is a lyapunov function for @xmath453 and @xmath475 .",
    "we have @xmath488 with @xmath489 , @xmath490 and the interval @xmath491 2 .",
    "there are distributions @xmath454 and @xmath492 on @xmath256 which are stationary with respect to @xmath453 and @xmath475 , respectively .",
    "[ en : 1 . ]",
    "the transition kernels @xmath453 and @xmath475 are @xmath143-uniformly ergodic .",
    "[ en : 4 ] for @xmath493 we have @xmath494    we use the same arguments as in ( * ? ? ?",
    "* section  3.1 ) .",
    "one can easily see that the markov chains @xmath71 and @xmath471 are irreducible with respect to the lebesgue measure and weak feller .",
    "thus , all compact sets are petite , see ( * ? ? ?",
    "* proposition  6.2.8 ) .",
    "hence , for the existence of stationary distributions , say @xmath454 and @xmath492 , ( * ? ? ?",
    "* theorem  12.3.3 ) , as well as for the @xmath143-uniform ergodicity ( * ? ? ?",
    "* theorem  16.0.1 ) it is enough to show that @xmath143 satisfies . with @xmath495",
    ", we have @xmath496 by the fact that @xmath497 \\leq 2 { \\left\\vert s \\right\\vert}_\\infty\\ ] ] we obtain with the same arguments that @xmath498 thus , the assertions from [ en : 3 . ] . to [",
    "en : 1 . ] . are proven .",
    "the statement of [ en : 4 ] . is a consequence of ( * ? ? ?",
    "* lemma  3 ) .",
    "there it is shown that for @xmath499 it holds that @xmath500 by using @xmath501 and @xmath502 we further estimate the right - hand side by @xmath503 since @xmath504 , we have the bound @xmath505 provided that @xmath506 which follows from @xmath507 .",
    "the assertion of follows now by a simple calculation .    by using the facts collected in the previous proposition",
    ", we can apply the perturbation bound of theorem  [ thm geom3 ] and obtain a quantitative perturbation bound for the noisy langevin algorithm .",
    "let @xmath72 be a probability measure on @xmath256 and set @xmath508 as well as @xmath509 .",
    "suppose that @xmath510 . then , there are numbers @xmath511 and @xmath150 , independent of @xmath512 , determining @xmath513 with @xmath514 , so that for @xmath515 we have @xmath516    we have by proposition  [ prop : langevin ] that @xmath453 is @xmath143-uniformly ergodic with @xmath486 , i.e. , there are numbers @xmath84 and @xmath57 such that @xmath517 now , by combining theorem  [ thm geom3 ] and remark  [ rem : thm geom4 ] with the results from proposition  [ prop : langevin ] we obtain the result .",
    "we want to point out that the assumptions imposed are the same as in ( * ? ? ?",
    "* theorem  3.2 ) , but instead of the asymptotic result we provide an explicit estimate . the numbers @xmath56 and @xmath57 are not stated in terms of the model parameters . in principle , these values can be derived from the drift condition through ( * ? ? ?",
    "* theorem  1.1 ) .",
    "we thank alexander mitrophanov and the referees for their valuable comments which helped to improve the paper .",
    "d.r . was supported by the dfg research training group 2088 ."
  ],
  "abstract_text": [
    "<S> perturbation theory for markov chains addresses the question of how small differences in the transition probabilities of markov chains are reflected in differences between their distributions . we prove powerful and flexible bounds on the distance of the @xmath0th step distributions of two markov chains when one of them satisfies a wasserstein ergodicity condition . </S>",
    "<S> our work is motivated by the recent interest in approximate markov chain monte carlo ( mcmc ) methods in the analysis of big data sets . by using an approach based on lyapunov functions , we provide estimates for geometrically ergodic markov chains under weak assumptions . in an autoregressive model , our bounds </S>",
    "<S> can not be improved in general . </S>",
    "<S> we illustrate our theory by showing quantitative estimates for approximate versions of two prominent mcmc algorithms , the metropolis - hastings and stochastic langevin algorithms . </S>"
  ]
}