{
  "article_text": [
    "optimal experimental design ( approximate theory ) is a well - developed area , and we refer to kiefer ( @xcite ) , silvey ( @xcite ) , pzman ( @xcite ) and pukelsheim ( @xcite ) for a general introduction and basic results .",
    "we consider computational aspects of optimal designs , focusing on a finite design space @xmath0 .",
    "suppose the probability density or mass function of the response is specified as @xmath1 where @xmath2 is the parameter of interest .",
    "let @xmath3 denote the @xmath4 expected fisher information matrix from a unit assigned to @xmath5 with the @xmath6 entry [ the expectation is with respect to @xmath7 @xmath8.\\ ] ] the moment matrix , as a function of the design measure @xmath9 , is defined as @xmath10 which is proportional to the fisher information for @xmath11 when the number of units assigned to @xmath5 is proportional to @xmath12 . here",
    "@xmath13 , and @xmath14 denotes the closure of @xmath15 . throughout",
    "we assume that @xmath3 are well defined and hence nonnegative definite .",
    "the set @xmath16 is assumed nonempty .",
    "our approach may conceivably extend to the case where @xmath17 is allowed to be singular , by using generalized inverses , although we do not pursue this here .",
    "given an optimality criterion @xmath18 defined on positive definite matrices , the goal is to maximize @xmath19 with respect to @xmath20 .",
    "typical optimality criteria include :    the d - criterion @xmath21 ,    the a - criterion @xmath22 ,    more generally , the @xmath23th mean criterion @xmath24 and    the c - criterion @xmath25 , where @xmath26 is a nonzero constant vector .    often only a linear combination @xmath27 , for example , a subvector of @xmath11 , is of interest . the fisher information for @xmath27 is naturally defined as @xmath28 , assuming invertibility [ pukelsheim ( @xcite ) ]",
    ". we may therefore consider the d- and a - criteria for @xmath27 defined , respectively , as @xmath29\\\\[-8pt ] \\phi_{-1 , k}(m ) & = & -\\operatorname{tr}(k^\\top m^{-1 } k).\\nonumber\\end{aligned}\\ ] ] the c - criterion is a special case of @xmath30 .",
    "motivations for such optimality criteria are well known . in a linear problem ,",
    "the a - criterion seeks to minimize the sum of variances of the best linear unbiased estimators ( blues ) for all coordinates of @xmath11 while the c - criterion seeks to minimize the variance of the blue for @xmath31 .",
    "similar interpretations ( with asymptotic arguments ) apply to nonlinear problems",
    ".    in general @xmath17 also depends on the unknown parameter @xmath11 which complicates the definition of an optimality criterion .",
    "a simple solution is to maximize @xmath19 with @xmath11 fixed at a prior guess @xmath32 ; this leads to _ local optimality _ [ chernoff ( @xcite ) ] .",
    "local optimality may be criticized for ignoring uncertainty in @xmath11 . however , in a situation where real prior information is available , or where the dependence of @xmath33 on @xmath11 is weak , it is nevertheless a viable approach and has been adopted routinely [ see , e.g. , li and majumdar ( @xcite ) ] .",
    "henceforth we assume a fixed @xmath32 and suppress the dependence of @xmath33 on @xmath11 .",
    "possible extensions are mentioned in section  [ sec5 ] .",
    "optimal designs do not usually come in closed form . as early as wynn ( @xcite ) , fedorov ( @xcite ) , atwood ( @xcite ) and wu and wynn ( @xcite ) , and as late as torsney ( @xcite ) , harman and pronzato ( @xcite ) and dette , pepelyshev and zhigljavsky ( @xcite ) ,",
    "various procedures have been studied for numerical computation .",
    "we shall focus on the following multiplicative algorithm [ titterington ( @xcite , @xcite ) , silvey , titterington and torsney ( @xcite ) ] which is specified through a power parameter @xmath34 $ ] .",
    "[ algorithmi ] set @xmath35 $ ] and @xmath36 . for",
    "@xmath37 compute @xmath38 where @xmath39 iterate until convergence .    for a heuristic explanation ,",
    "observe that ( [ alg1 ] ) is equivalent to @xmath40 the value of @xmath41 indicates the amount of gain in information , as measured by @xmath18 , by a slight increase in @xmath12 , the weight on the @xmath42th design point .",
    "so ( [ heur ] ) can be seen as adjusting @xmath43 so that relatively more weight is placed on design points whose increased weight may result in a larger gain in @xmath18 . if @xmath18 is increasing and concave , then a convenient convergence criterion , based on the general equivalence theorem [ kiefer and wolfowitz ( @xcite ) , whittle ( @xcite ) ] , is @xmath44 where @xmath45 and @xmath46 is a small positive constant .",
    "algorithm i is remarkable in its generality .",
    "for example , little restriction is placed on the underlying model @xmath1 .",
    "part of the reason , of course , is that we focus on fisher information and local optimality , which essentially reduces the problem to a linear one .",
    "there exists a large literature on algorithm [ algorithmi ] and its relatives [ see , e.g. , titterington ( @xcite , @xcite ) , silvey , titterington and torsney ( @xcite ) , pzman ( @xcite ) , fellman ( @xcite ) , pukelsheim and torsney ( @xcite ) , torsney and mandal ( @xcite ) , harman and pronzato ( @xcite ) , dette , pepelyshev and zhigljavsky ( @xcite ) and torsney and martn - martn ( @xcite ) ] . one feature that has attracted much attention is that algorithm [ algorithmi ] appears to be monotonic , that is , @xmath47 increases in @xmath48 , at least in some special cases .",
    "for example , when @xmath49 ( for d - optimality ) and @xmath50 , titterington ( @xcite ) and pzman ( @xcite ) have shown monotonicity using clever probabilistic and analytic inequalities [ see also dette , pepelyshev and zhigljavsky ( @xcite ) and harman and trnovsk ( @xcite ) ] .",
    "algorithm [ algorithmi ] is also known to be monotonic for @xmath51 as in ( [ phik ] ) , assuming @xmath52 and @xmath3 are rank - one [ fellman ( @xcite ) , torsney ( @xcite ) ] .",
    "monotonicity is important because convergence then holds under mild assumptions ( see section [ sec4 ] ) .",
    "results in these special cases suggest a monotonic convergence theory for a broad class of @xmath18 which is also supported by numerical evidence presented in some of the references above .",
    "we aim to state general conditions on @xmath18 that ensure that algorithm [ algorithmi ] converges monotonically . as a consequence certain known theoretical results are unified and generalized , and one particular conjecture [ titterington ( @xcite ) ]",
    "is confirmed .",
    "define @xmath53 the functions @xmath18 and @xmath54 are assumed to be differentiable on invertible matrices .",
    "our conditions are conveniently stated in terms of @xmath54 . as usual , for two symmetric matrices , @xmath55 means @xmath56 is nonnegative ( positive ) definite .",
    "* @xmath57 is increasing : @xmath58 or , equivalently , @xmath59 is nonnegative definite for positive definite @xmath33 .",
    "* @xmath57 is concave : @xmath60 for @xmath61 , m_1 , m_2>0 $ ] .",
    "equivalently , @xmath62    condition ( [ increase ] ) is usually satisfied by any reasonable information criterion .",
    "also note that , if ( [ increase ] ) fails , then @xmath41 on the right - hand side of ( [ heur ] ) is not even guaranteed to be nonnegative .",
    "the real restriction is the concavity condition ( [ concave0 ] ) .",
    "for example , ( [ concave0 ] ) is not satisfied by @xmath63 ( the @xmath23th mean criterion ) when @xmath64 .",
    "[ it is usually assumed that @xmath65 , rather than @xmath57 , is concave . ] nevertheless , ( [ concave0 ] ) _ is _ satisfied by a wide range of criteria , including the commonly used d- , a- or c - criteria [ see cases ( i ) and ( ii ) in the illustration of the main result below ] .",
    "our main result is as follows .",
    "[ main ] assume ( [ increase ] ) and ( [ concave0 ] ) .",
    "assume that in iteration ( [ alg1 ] ) , with @xmath66 , we have @xmath67 then @xmath68    in other words , under mild conditions which ensure that ( [ alg1 ] ) is well defined [ specifically , the denominator in ( [ alg1 ] ) is nonzero ] , ( [ increase ] ) and ( [ concave0 ] ) imply that ( [ alg1 ] ) never decreases the criterion @xmath18 .",
    "let us illustrate theorem [ main ] with some examples . for simplicity , in ( i)(iv )",
    "we display formulae for @xmath69 only , although monotonicity holds for all @xmath35 $ ] .",
    "take @xmath70 then @xmath71 satisfies ( [ increase ] ) and ( [ concave0 ] ) . by theorem [ main ] ,",
    "algorithm [ algorithmi ] is monotonic for @xmath72 $ ] .",
    "this generalizes the previously known cases @xmath73 and @xmath74 ( with particular values of @xmath75 ) .",
    "the iteration ( [ alg1 ] ) reads @xmath76    more generally , given a full rank @xmath77 matrix @xmath78 ( @xmath79 ) , consider @xmath80 then @xmath81 satisfies ( [ increase ] ) and ( [ concave0 ] ) . by theorem [ main ] ,",
    "algorithm [ algorithmi ] is monotonic for @xmath82 $ ] .",
    "the iteration ( [ alg1 ] ) reads @xmath83    in particular , taking @xmath84 ( an @xmath85 vector ) and @xmath74 in case  ( ii ) , we obtain that algorithm [ algorithmi ] is monotonic for the c - criterion @xmath86 .",
    "the iteration ( [ pk ] ) reduces to @xmath87    as noted by a referee , with @xmath74 , the choice @xmath69 may lead to an oscillating behavior in the sense that @xmath88 alternates between two points at which @xmath89 takes the same value . while this does not contradict theorem [ main ]",
    ", it suggests that other values of @xmath75 are more desirable for fast convergence .",
    "following fellman ( @xcite ) and torsney ( @xcite ) , a practical recommendation is @xmath52 in the @xmath74 case .",
    "consider another example of case ( ii ) , with @xmath90 and @xmath91 .",
    "henceforth @xmath92 denotes the @xmath93 vector of zeros , and @xmath94 denotes the @xmath95 identity matrix .",
    "assume @xmath96 and @xmath97 is @xmath98 .",
    "this corresponds to a d - optimal design problem for @xmath99 under the linear model , @xmath100 where the parameter is @xmath101 .",
    "that is , interest centers on all coefficients other than the intercept .",
    "nevertheless , as far as the design measure @xmath43 is concerned , the optimality criterion , @xmath102 , coincides with @xmath103 , that is , @xmath104 after some algebra , ( [ pk ] ) reduces to @xmath105 where @xmath106 thus ( [ alg2 ] ) satisfies @xmath107 .",
    "monotonicity of ( [ alg2 ] ) has been conjectured since titterington ( @xcite ) , and considerable numerical evidence has accumulated over the years . recently , extending the arguments of pzman ( @xcite ) , dette , pepelyshev and zhigljavsky ( @xcite ) have obtained results which come very close to resolving titterington s conjecture .",
    "nevertheless , we have been unable to extend their arguments further .",
    "instead we prove the general theorem [ main ] using a different approach , and settle this conjecture as a consequence .",
    "the proof of theorem [ main ] is achieved by using a method of _ auxiliary variables_. when a function @xmath108 [ e.g. , @xmath109 to be minimized is complicated , we introduce a new variable @xmath110 and a function @xmath111 such that @xmath112 for all @xmath43 , thus transforming the problem into minimizing @xmath111 over @xmath43 and @xmath110 jointly .",
    "then we may use an iterative conditional minimization strategy on @xmath111 .",
    "this is inspired by the em algorithm [ dempster , laird and rubin ( @xcite ) , meng and van dyk ( @xcite ) ; in particular , see csiszr and tusnady s ( @xcite ) interpretation ; see yu ( @xcite ) for a related interpretation of the data augmentation algorithm ] .    in section [ sec3 ]",
    "we analyze algorithm [ algorithmi ] using this strategy .",
    "although attention is paid to the mathematics , our focus is on intuitively appealing interpretations which may lead to further extensions of algorithm [ algorithmi ] with the same desirable monotonicity properties .",
    "if the algorithm is monotonic , then convergence can be established under mild conditions ( section [ sec4 ] ) .",
    "section [ sec5 ] contains an illustration with optimal designs for a simple logistic regression model .",
    "a key observation is that the problem of maximizing @xmath19 , or , equivalently , minimizing @xmath113 can be formulated as a joint minimization over both the design and the estimator .",
    "specifically , let us compare the original problem [ problemp1 ] with its companion problem [ problemp2 ]",
    ". throughout @xmath114 denotes the symmetric nonnegative definite ( snnd ) square root of an snnd matrix @xmath115 .",
    "[ problemp1 ] minimize @xmath116 over @xmath117 .",
    "[ problemp2 ] minimize @xmath118 over @xmath117 and @xmath110 [ an @xmath119 matrix ] , subject to @xmath120 , where @xmath121    though not immediately obvious , problems [ problemp1 ] and [ problemp2 ] are equivalent , and this may be explained in statistical terms as follows . in ( [ gwq ] ) , @xmath122 is simply the variance matrix of a linear unbiased estimator , @xmath123 , of the @xmath85 parameter @xmath11 in the model @xmath124 where @xmath125 is the @xmath126 vector of observations .",
    "the constraint @xmath120 ensures unbiasedness .",
    "[ note that @xmath127 is full - rank since @xmath17 is nonsingular by assumption .",
    "] of course , the weighted least squares ( wls ) estimator is the best linear unbiased estimator , having the smallest variance matrix ( in the sense of positive definite ordering ) and , by ( [ increase ] ) , the smallest @xmath54 for that matrix .",
    "it follows that , for fixed @xmath43 , @xmath111 is minimized by choosing @xmath123 as the wls estimator , @xmath128 however , from ( [ gwq ] ) and ( [ qwls ] ) we get @xmath129 that is , problem [ problemp2 ] reduces to problem [ problemp1 ] upon minimizing over @xmath110 .    since problem [ problemp2 ] is not immediately solvable , it is natural to consider the subproblems : ( i ) minimizing @xmath111 over @xmath110 for fixed @xmath43 and ( ii ) minimizing @xmath111 over @xmath43 for fixed @xmath110 . part ( ii )",
    "is again formulated as a joint minimization problem . for a fixed @xmath119 matrix @xmath110 such that @xmath130 , let us consider problems [ problemp3 ] and [ problemp4 ] .",
    "[ problemp3 ] minimize @xmath111 as in ( [ gwq ] ) over @xmath117 .",
    "[ problemp4 ] minimize the function @xmath131 over @xmath117 and the @xmath4 positive - definite matrix @xmath132 .",
    "the concavity assumption ( [ concave ] ) implies that @xmath133 with equality when @xmath134 , that is , problem [ problemp4 ] reduces to problem [ problemp3 ] upon minimizing over @xmath132 .    since problem [ problemp4 ] is not immediately solvable , it is natural to consider the subproblems : ( i ) minimizing @xmath135 over @xmath132 for fixed @xmath43 and @xmath110 and ( ii ) minimizing @xmath135 over @xmath43 for fixed @xmath132 and @xmath110 . part ( ii ) , which amounts to minimizing @xmath136",
    "admits a closed - form solution : if we write @xmath137 where each @xmath138 is @xmath4 , then @xmath139 should be proportional to @xmath140 . but algorithm [ algorithmi ] may not perform an exact minimization here [ see ( [ s3 ] ) ] .    based on the above discussion",
    ", we can express algorithm [ algorithmi ] as an iterative conditional minimization algorithm involving @xmath141 and @xmath132 . at iteration @xmath48 , define @xmath142 then we have @xmath143}\\nonumber\\\\ & = & h\\bigl(\\sigma^{(t ) } , w^{(t ) } , q^{(t)}\\bigr ) \\qquad\\mbox{[by ( \\ref{hmin2})]}\\nonumber\\\\ \\label{s3 } & \\geq & h\\bigl(\\sigma^{(t ) } , w^{(t+1 ) } , q^{(t)}\\bigr ) \\qquad\\mbox{(see below)}\\\\ \\label{s4 } & \\geq & g\\bigl(w^{(t+1 ) } , q^{(t)}\\bigr ) \\qquad\\mbox{[by ( \\ref{hmin1 } ) , ( \\ref{gwq})]}\\\\ \\label{s5 } & \\geq & \\psi\\bigl(m^{-1}\\bigl(w^{(t+1)}\\bigr)\\bigr ) \\qquad\\mbox{[by ( \\ref{gmin1 } ) , ( \\ref{gmin2})]}.\\end{aligned}\\ ] ] the choice of @xmath144 leads to ( [ s3 ] ) as follows .",
    "after simple algebra , the iteration ( [ alg1 ] ) becomes @xmath145 where @xmath146 since @xmath147 , jensen s inequality yields @xmath148 that is , @xmath149 hence @xmath150 which produces ( [ s3 ] ) .",
    "choosing @xmath52 , that is , @xmath151 , leads to exact minimization in ( [ s3 ] ) ; choosing @xmath69 yields equality in ( [ s3 ] ) . but",
    "any choice of @xmath144 that decreases @xmath152 at ( [ s3 ] ) would have resulted in the desired inequality , @xmath153 we may allow @xmath75 to change from iteration to iteration , and monotonicity still holds , as long as @xmath35 $ ] .",
    "see silvey , titterington and torsney ( @xcite ) and fellman ( @xcite ) for investigations concerning the choice of @xmath75 . also note that we assume @xmath154 for all @xmath42 .",
    "this is not essential , however , because ( i ) the possibility of @xmath155 can be handled by restricting our analysis to all design points @xmath42 such that @xmath156 , and ( ii ) the possibility of @xmath157 can be handled by a standard limiting argument .",
    "monotonicity holds as long as @xmath158 and @xmath159 are both positive definite , as noted in the statement of theorem [ main ] .",
    "monotonicity ( theorem [ main ] ) plays an important role in the following convergence theorem .",
    "[ thm2 ] denote the mapping ( [ alg1 ] ) by @xmath160 .",
    "assume @xmath161    assume ( [ alg1 ] ) is strictly monotonic , that is , @xmath162    assume @xmath18 is strictly concave and @xmath163 is continuous on positive definite matrices .",
    "assume that , if @xmath33 ( a positive definite matrix ) tends to @xmath164 such that @xmath65 increases monotonically , then @xmath164 is nonsingular .",
    "let @xmath88 be generated by ( [ alg1 ] ) with @xmath165 for all @xmath42 .",
    "then :    all limit points of @xmath88 are global maxima of @xmath19 on @xmath166 , and    as @xmath167 , @xmath47 increases monotonically to @xmath168 .",
    "the proof of theorem [ thm2 ] is somewhat subtle .",
    "standard arguments show that all limit points of @xmath88 are fixed points of the mapping @xmath160 .",
    "this alone does not imply convergence to a global maximum , however , because there often exist sub - optimal fixed points on the boundary of @xmath169 .",
    "( global maxima occur routinely on the boundary also . )",
    "our goal is therefore to rule out possible convergence to such sub - optimal points ; details of the proof are presented in yu ( @xcite ) , an extended version of this paper .",
    "we shall comment on conditions ( a)(d ) .",
    "condition ( a ) ensures that starting with @xmath170 , all iterations are well defined .",
    "moreover , if @xmath165 for all @xmath42 , then @xmath171 for all @xmath48 and @xmath42 .",
    "this highlights the basic idea that , in order to converge to a global maximum @xmath172 , the starting value @xmath173 must assign positive weight to every support point of @xmath172 .",
    "such a requirement is not necessary for monotonicity . on the other hand ,",
    "assigning weight to nonsupporting points of @xmath172 tends to slow the algorithm down .",
    "hence methods that quickly eliminate nonoptimal support points are valuable [ harman and pronzato ( @xcite ) ] .    condition ( b ) simply says that unless @xmath43 is a fixed point , the mapping @xmath160 should produce a better solution .",
    "let us assume ( [ increase ] ) , ( [ concave ] ) and condition ( a ) so that theorem  [ main ] applies .",
    "then , by checking the equality condition in ( [ s3 ] ) , it is easy to see that condition ( b ) is satisfied if @xmath174 . [",
    "the argument leading to ( [ iff ] ) technically assumes that all coordinates of @xmath43 are nonzero , but we can apply it to the appropriate subvector of @xmath43 . ] if @xmath69 , then ( [ s3 ] ) reduces to an equality .",
    "however , by checking the equality conditions in ( [ s4 ] ) and ( [ s5 ] ) , we can show that condition ( b ) is satisfied if @xmath54 is strictly increasing and strictly concave : @xmath175\\\\[-8pt ] & & \\qquad m_1\\neq m_2 \\quad \\longrightarrow\\quad \\psi(m_1)<\\psi ( m_2);\\nonumber\\\\ \\label{sconcave } & & m_1 , m_2>0,\\nonumber\\\\[-8pt]\\\\[-8pt ] & & \\qquad m_1\\neq m_2 \\quad\\longrightarrow\\quad\\psi(m_2)<\\psi ( m_1)+\\operatorname{tr}\\bigl(\\psi'(m_1)(m_2-m_1)\\bigr).\\nonumber\\end{aligned}\\ ] ]    conditions ( c ) and ( d ) are technical requirements that concern @xmath18 alone . condition ( c ) ensures uniqueness of the optimal moment matrix which simplifies the analysis .",
    "condition ( d ) ensures that positive definiteness of @xmath17 is maintained in the limit .",
    "conditions ( c ) and ( d ) are satisfied by @xmath176 with @xmath177 , for example .",
    "let us mention a typical example of theorem [ thm2 ] .",
    "[ coro1 ] assume @xmath178 , and @xmath179 .",
    "then the conclusion of theorem [ thm2 ] holds for algorithm [ algorithmi ] with @xmath49 .",
    "conditions ( a ) , ( c ) and ( d ) are readily verified .",
    "condition ( b ) is satisfied by ( [ sincrease ] ) and ( [ sconcave ] ) .",
    "the claim follows from theorem [ thm2 ] .",
    "when ( [ sincrease ] ) or ( [ sconcave ] ) fails , and @xmath69 , it is often difficult to appeal to theorem [ thm2 ] because strict monotonicity [ condition ( b ) ] may not hold .",
    "we illustrate this with an example where the monotonicity is not strict , and the algorithm does not converge [ see pronzato , wynn and zhigljavsky ( @xcite ) , chapter 7 ; also the remark in case ( iii ) following theorem [ main ] ] .",
    "consider iteration ( [ alg2 ] ) with @xmath180 and design space @xmath181 .",
    "it is easy to show that , for any @xmath182 , iteration ( [ alg2 ] ) maps @xmath88 to @xmath183 . thus , unless @xmath184 to begin with , the algorithm alternates between two distinct points .",
    "this appears to be a rare example , as ( [ alg2 ] ) usually converges in practical situations .",
    "one can think of several reasons for the wide interest in algorithm [ algorithmi ] and its relatives .",
    "similar to the em algorithm , algorithm [ algorithmi ] is simple , easy to implement and monotonically convergent for a large class of optimality criteria ( although this was not proved in the present generality ) .",
    "algorithm [ algorithmi ] is known to be slow sometimes .",
    "but it serves as a foundation upon which more effective variants can be built [ see , e.g. , harman and pronzato ( @xcite ) and dette , pepelyshev and zhigljavsky ( @xcite ) ] . while solving the conjectured monotonicity of ( [ alg2 ] ) holds mathematical interest , our main contribution is a way of interpreting such algorithms as optimization on augmented spaces .",
    "this opens up new possibilities in constructing algorithms with the same desirable monotonic convergence properties .    as a numerical example , consider the logistic regression model @xmath185 the expected fisher information for @xmath11 from a unit assigned to @xmath5 is @xmath186 we compute locally optimal designs with prior guess @xmath187 , and design spaces , @xmath188 the design criteria considered are @xmath189 ( for d - optimality ) and @xmath190 .",
    "we use algorithm [ algorithmi ] with @xmath69 , starting with equally weighted designs .    for @xmath189 , corollary [ coro1 ]",
    "guarantees monotonic convergence .",
    "this is illustrated by figure [ fig1 ] , the first row , where @xmath191 is plotted against iteration @xmath48 . using the convergence criterion ( [ conv ] ) with @xmath192 , the number of iterations until convergence is 93 for @xmath193 and 2121 for @xmath194 .",
    "the actual locally d - optimal designs are @xmath195 for @xmath193 and @xmath196 for @xmath197 , as can be verified using the general equivalence theorem .",
    "this simple example serves to illustrate both the monotonicity of algorithm [ algorithmi ] ( when theorem [ main ] applies ) and its potential slow convergence .     and",
    "@xmath198 for algorithm [ algorithmi ] with design spaces @xmath193 and @xmath194 . ]    for @xmath199 , although algorithm [ algorithmi ] can be implemented just as easily , theorem [ main ] does not apply because the concavity condition ( [ concave ] ) no longer holds . indeed ,",
    "algorithm [ algorithmi ] ( with @xmath69 ) is not monotonic , as is evident from figure [ fig1 ] , in the second row , where @xmath200 is plotted against iteration @xmath48 .",
    "this shows the potential danger of using algorithm [ algorithmi ] when monotonicity is not guaranteed .",
    "although theorem [ main ] does not cover the @xmath201 criterion for @xmath64 , it is still possible that monotonicity holds for a smaller range of @xmath75 .",
    "calculations in special cases lead to the conjecture [ silvey , titterington and torsney ( @xcite ) ] that algorithm [ algorithmi ] is monotonic if @xmath202 .",
    "theorem [ main ] provides further evidence for this conjecture , but new insights are needed to resolve it .    we have focused on local optimality .",
    "an alternative , _ bayesian optimality _ [ chaloner and larntz ( @xcite ) , chaloner and verdinelli ( @xcite ) ] , seeks to maximize the expected value of @xmath203 over a prior distribution @xmath204 .",
    "the notation @xmath205 emphasizes the dependence of the moment matrix on the parameter @xmath206 .",
    "it would be worthwhile to extend our strategy in section [ sec3 ] to bayesian optimality , and we plan to report both theoretical and empirical evaluations of such extensions in future works .",
    "the author would like to thank don rubin , xiao - li meng and david van dyk for introducing him to the field of statistical computing .",
    "he is also grateful to mike titterington , ben torsney and the referees for their valuable comments .",
    "torsney , b. ( 1983 ) . a moment inequality and monotonicity of an algorithm . in _ proceedings of the international symposium on semi - infinite programming and appl . _ ( k. o. kortanek and a. v. fiacco , eds . ) . _ lecture notes in economics and mathematical systems _ * 215 * 249260 .",
    "springer , berlin ."
  ],
  "abstract_text": [
    "<S> monotonic convergence is established for a general class of multiplicative algorithms introduced by silvey , titterington and torsney [ _ comm . </S>",
    "<S> statist . theory methods _ * 14 * ( 1978 ) 13791389 ] for computing optimal designs . a conjecture of titterington [ _ appl . </S>",
    "<S> stat . _ </S>",
    "<S> * 27 * ( 1978 ) 227234 ] is confirmed as a consequence . </S>",
    "<S> optimal designs for logistic regression are used as an illustration .    .    . </S>"
  ]
}