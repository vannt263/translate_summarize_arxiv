{
  "article_text": [
    "the hankel transform of order @xmath2 of a function @xmath3\\rightarrow\\mathbb{c}$ ] is defined as  ( * ? ? ? * chap .  9 )",
    "@xmath4 where @xmath5 is the bessel function of the first kind with parameter @xmath6 . when @xmath7 ,   is essentially the two - dimensional fourier transform of a radially symmetric function with support on the unit disc and appears in the fourier ",
    " abel cycle  ( * ? ? ?",
    "furthermore , the hankel transform of integer order @xmath8 is equivalent to the fourier transform of functions of the form @xmath9 , where @xmath10 . throughout this paper",
    "we take @xmath6 to be an integer .",
    "various semi - discrete and discrete variants of   are employed in optics  @xcite , electromagnetics  @xcite , medical imaging  @xcite , and the numerical solution of partial differential equations  @xcite . at some stage",
    "these require the computation of the following sums : @xmath11 where @xmath6 is an integer , @xmath12 , and @xmath13 .",
    "special cases of   that are considered in this paper are : ( 1 ) the evaluation of schlmilch expansions at @xmath14  @xcite ( @xmath15 or @xmath16 ) ; ( 2 ) the evaluation of fourier  bessel expansions of order @xmath0 at @xmath14 ( @xmath7 and @xmath17 , where @xmath18 is the @xmath19th positive root of @xmath20 ) ; and",
    "( 3 ) the discrete hankel transform of order @xmath0  @xcite ( @xmath7 , @xmath17 , and @xmath21 ) . for algorithms that rely on the fast fourier",
    "transform ( fft ) , such as the algorithm described in this paper , tasks ( 1 ) , ( 2 ) , and ( 3 ) are incrementally more difficult .",
    "we consider them in turn in sections  [ sec : schlomilch ] ,  [ sec : fourierbessel ] , and  [ sec : discretehankeltransform ] , respectively .",
    "our algorithm is based on carefully replacing @xmath22 by an asymptotic expansion for large arguments that , up to a certain error , expresses @xmath22 as a weighted sum of trigonometric functions .",
    "this allows a significant proportion of the computation involved in   to be achieved by the discrete cosine transform of type i ( dct ) and the discrete sine transform of type i ( dst ) .",
    "these are @xmath23 fft - based algorithms for computing matrix - vector products with the matrices @xmath24 and @xmath25 , where @xmath26    asymptotic expansions of special functions are notoriously tricky to use in practice because it is often difficult to determine the precise regime for which they are accurate approximations .",
    "however , for transforms involving orthogonal polynomials , such as the chebyshev ",
    "legendre transform  @xcite , successful fast algorithms have been derived based on asymptotic expansions . at the point of evaluation , these algorithms are competitive with multipole - like approaches  @xcite , but have the advantage of no precomputation .",
    "this allows for more adaptive algorithms such as a convolution algorithm for chebyshev expansions  @xcite .    in this paper",
    "we will use error bounds to determine the precise regime for which an asymptotic expansion of bessel functions is an accurate approximation and from there derive all the algorithmic parameters to achieve a near - optimal computational cost for any accuracy goal ( see table  [ tab : algorithmicparameters ] ) .",
    "for each task ( 1)-(3 ) there are just two user - defined inputs : a vector of coefficients @xmath27 in   and a working accuracy @xmath28 .",
    "the values of @xmath29 in   are then calculated to an accuracy of @xmath30 .",
    "the resulting algorithm has a complexity of @xmath31 , where @xmath32 for task ( 1 ) , @xmath33 for task ( 2 ) , and @xmath34 for task ( 3 ) . for the majority of this paper we state algorithmic complexities without the dependency on @xmath35 .",
    "previous algorithms based on asymptotic expansions for computing  @xcite have either a poor accuracy or a dubious numerical stability  @xcite . here",
    ", we find that once an asymptotic expansion of bessel functions is carefully employed the resulting algorithm is numerically stable , can be adapted to any accuracy goal , and requires no precomputation .",
    "moreover , we show how the equally - spaced restriction , which is inherited from the reliance on dcts and dsts , can be alleviated .",
    "we use the following notation . a column vector with entries @xmath36",
    "is denoted by @xmath37 , a row vector is denoted by @xmath38 , a diagonal matrix with diagonal entries @xmath36 is written as @xmath39 , and the @xmath40 matrix with @xmath41 entry @xmath42 is denoted by @xmath43 where @xmath44 .",
    "the paper is organized as follows . in section  [ sec : existing ] we briefly discuss existing methods for computing   and in section  [ sec : besselfunctionproperties ] we investigate the approximation power of three expansions for bessel functions . in section  [ sec : schlomilch ] we first describe an @xmath45 algorithm for evaluating schlmilch expansions before deriving a faster @xmath1 algorithm . in sections  [ sec : fourierbessel ] and  [ sec : discretehankeltransform ] we use the neumann addition formula to extend the algorithm to the evaluation of fourier  bessel expansions and the computation of the discrete hankel transform .",
    "we now give a brief description of some existing methods for evaluating   that roughly fall into four categories : ( 1 ) direct summation ; ( 2 ) evaluation via an integral representation ; ( 3 ) evaluation using asymptotic expansions , and ; ( 4 ) butterfly schemes .",
    "for other approaches see  @xcite .",
    "one of the simplest ideas is to evaluate @xmath46 for @xmath47 and then naively compute the sums in  . by using the taylor series expansion in   for small @xmath48 , the asymptotic expansion in   for large @xmath48 , and miller s algorithm  ( * ? ? ?",
    "3.6(vi ) ) ( backward recursion with a three - term recurrence ) otherwise , each evaluation of @xmath49 costs @xmath50 operations  @xcite . therefore",
    ", this simple algorithm requires a total of @xmath51 operations and is very efficient for small @xmath52 ( @xmath53 ) .",
    "however , the @xmath51 cost is prohibitive for large @xmath52 .",
    "note that in general there is no evaluation scheme for @xmath49 that is exact in infinite precision arithmetic . at some level a working accuracy of @xmath28 must be introduced .",
    "thus , even in the direct summation approach , the relaxation of the working accuracy that is necessary for deriving a faster algorithm , has already been made .",
    "the sums in   are equivalent to the matrix - vector product @xmath54 .",
    "one reason that an @xmath1 algorithm is possible is because the argument , @xmath55 , is a rank @xmath56 matrix .",
    "a fact that we will exploit several times .",
    "when @xmath6 is an integer , @xmath22 can be replaced by its integral representation  ( * ? ? ?",
    "* ( 10.9.2 ) ) , @xmath57 where @xmath58 is the imaginary unit and the last equality holds because @xmath59 is even about @xmath60 .",
    "the integrand in   is @xmath61-periodic and the integral can be approximated by a @xmath62-point trapezium rule .",
    "substituting this approximation into   gives a double sum for @xmath63 that can be evaluated with one fft followed by an interpolation step in @xmath64 operations  @xcite .",
    "the major issue with this approach is that the integrand in   is highly oscillatory for large @xmath48 and often @xmath65 , resulting in @xmath51 operations .",
    "one can replace @xmath22 in   by an asymptotic expansion that involves trigonometric functions . a fast , but perhaps numerically unstable ( see figure  [ fig : partition ] ) , algorithm then follows by exploiting dcts and dsts .",
    "existing work has approximated @xmath49 using asymptotic expansions with rational coefficients  @xcite , the approximation @xmath66",
    "@xcite , and for half - integer @xmath6 the asymptotic expansion in  @xcite .",
    "however , none of these approaches have rigorously determined the regime in which the employed asymptotic expansion is an accurate approximation and instead involve dubiously chosen algorithmic parameters . in this paper",
    "we will use a well - established asymptotic expansion and rigorously determine the regime in which it is an accurate approximation .      in 1995 ,",
    "kapur and rokhlin described an algorithm for computing the integral in   when @xmath67  @xcite .",
    "the main idea is to write   as a product of two integrals as follows  ( * ? ? ?",
    "* ( 6 ) ) : @xmath68 the inner integral can be discretized by a ( corrected ) trapnezium rule and computed via a discrete cosine transform , while the outer integral involves a singular kernel and can be computed with the fast multipole method .",
    "as described in  @xcite the algorithm can be used to evaluate schlmilch expansions in @xmath23 operations ( see section  [ sec : schlomilch ] ) . with modern advances in fast algorithms for nonuniform transforms , it could now be adapted to the computation of the discrete hankel transform though we are not aware of such work .",
    "recently , a new algorithm was developed for a class of fast transforms involving special functions  @xcite .",
    "the algorithm compresses the ranks of submatrices of a change of basis matrix by constructing skeleton decompositions in a hierarchical fashion .",
    "this hierarchical decomposition of the matrix means that it can then be applied to a vector in @xmath23 operations .",
    "the compression step of the algorithm is the dominating cost and is observed to require @xmath51 operations  ( * ? ? ?",
    "* table .",
    "fortunately , in many applications the compression step can be regarded as a precomputational cost because it is independent of the values of @xmath27 in  , though it does depend on @xmath52 .",
    "the methodology behind butterfly schemes is more general than what we present in this paper as it does not require knowledge of asymptotics . here",
    ", we will derive a fast transform that has no precomputational cost and is better suited to applications where @xmath52 is not known in advance",
    ".    some of the ideas in the spherical harmonic transform literature  @xcite may be useful for reducing the precomputational cost in  @xcite , though we are not aware of work in this direction .",
    "in this section we investigate three known expansions of bessel functions  ( * ? ? ? * chap .",
    "10 ) : ( 1 ) an explicit asymptotic expansion for large arguments ; ( 2 ) a convergent taylor series expansion for small arguments ; and ( 3 ) the neumann addition formula for perturbed arguments .",
    "mathematically , these three expansions are infinite series , but for practical use they must be truncated . here",
    ", we will focus on deriving criteria to ensure that the errors introduced by such truncations are negligible .",
    "related techniques were successfully used to derive a fast algorithm for the discrete legendre transform  @xcite .",
    "the graph of @xmath22 on @xmath69 is often said to look like an oscillating trigonometric function that decays like @xmath70 .",
    "this observation can be made precise by an asymptotic expansion of @xmath22 for large @xmath48 .",
    "let @xmath6 and @xmath71 be integers and @xmath72 .",
    "the first @xmath73 terms of the hankel asymptotic expansion of @xmath22 is given by  ( * ? ? ?",
    "* ( 10.17.3 ) ) ( also see  @xcite ) : @xmath74 where @xmath75 , @xmath76 is the error term , @xmath77 , and @xmath78    the first term in   shows that the leading asymptotic behavior of @xmath22 as @xmath79 is @xmath80 , which is an oscillating trigonometric function that decays like @xmath70 .",
    "the first @xmath73 terms show that , up to an error of @xmath76 , @xmath22 can be written as a weighted sum of @xmath81 and @xmath82 for @xmath83 .",
    "figure  [ fig : asydivergence ] ( left ) shows the error term @xmath84 on @xmath85 $ ] for @xmath86 .",
    "as expected , the asymptotic expansion becomes more accurate as @xmath48 increases .",
    "in particular , for sufficiently large @xmath48 the error term is negligible , i.e. , @xmath87 .",
    "it is important to appreciate that   is an asymptotic expansion , as opposed to a convergent series , and does not converge pointwise to @xmath22 as @xmath88 . in practice , increasing @xmath89 will eventually be detrimental and lead to severe numerical overflow issues .",
    "figure  [ fig : asydivergence ] ( right ) shows the error @xmath90 as @xmath88 and @xmath91 .",
    "thus , the appropriate use of   is to select an @xmath71 and ask : `` for what sufficiently large @xmath48 is the asymptotic expansion accurate ? '' .",
    "for example , from figure  [ fig : asydivergence ] ( left ) we observe that for @xmath92 we have @xmath93 for any @xmath94 and hence , we may safely replace @xmath95 by a weighted sum of @xmath81 and @xmath82 for @xmath96 when @xmath94 .    besselasymptotics ( 50,0 )",
    "@xmath48 ( -1.5,27 ) ( 75,51.5 ) ( 74,41 ) ( 73,32 ) ( 71,25.2 ) ( 68,19 ) ( 44,20 ) ( 35.2,22.2 )    fixedz ( 50,0 ) @xmath89 ( -1.5,27 )    more generally , it is known that the error term @xmath76 is bounded by the size of the first neglected terms  @xcite ) .",
    "since @xmath97 and @xmath98 we have @xmath99 this is essentially a sharp bound since for any @xmath100 there is a @xmath72 such that @xmath101 is larger than the magnitude of the first neglected terms . of the form @xmath102 for sufficiently large @xmath103 . ]",
    "let @xmath104 be the smallest real number so that if @xmath105 then @xmath106",
    ". from   we can take @xmath104 as the number that solves @xmath107 in general , the equation above has no closed - form solution , but can be solved numerically by a fixed - point iteration .",
    "we start with the initial guess of @xmath108 and iterate as follows : @xmath109 we terminate this after four iterations and take @xmath110 .",
    "table  [ tab : smtable ] gives the calculated values of @xmath111 for @xmath112 and @xmath113 .",
    "cccccccccccc    ' '' ''    @xmath89    ' '' ''    & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 +    ' '' ''    @xmath114    ' '' ''    & 180.5 & 70.5 & 41.5 & 30.0 & 24.3 & 21.1 & 19.1 & 17.8 & 17.0 & 16.5 + @xmath115 & 185.2 & 71.5 & 41.9 & 30.2 & 24.4 & 21.1 & 19.2 & 17.9 & 17.1 & 16.5 + @xmath116 & 200.2 & 74.8 & 43.1 & 30.8 & 24.8 & 21.4 & 19.3 & 18.0 & 17.2 & 16.6 + @xmath117 & 2330.7 & 500.0 & 149.0 & 64.6 & 41.4 & 31.4 & 26.0 & 22.9 & 20.9 & 19.6 +      for an integer @xmath6 , the taylor series expansion of @xmath22 about @xmath118 is given by  ( * ? ? ?",
    "* ( 10.2.2 ) ) @xmath119 in contrast to  , the taylor series expansion converges pointwise to @xmath22 for any @xmath48 .",
    "however , for practical application the infinite series in   must still be truncated .",
    "let @xmath120 be an integer and consider the truncated taylor series expansion that is given by @xmath121 where @xmath122 is the error term . as @xmath123 the leading asymptotic behavior of @xmath122 matches the order of the first neglected term and hence , @xmath124 .",
    "in particular , there is a real number @xmath125 so that if @xmath126 then @xmath127 .    to calculate the parameter @xmath125 we solve the equation @xmath128 .",
    "remarkably , an explicit closed - form expression for @xmath129 is known  @xcite and is given by @xmath130 where @xmath131 is the generalized hypergeometric function that we approximate by @xmath56 since we are considering @xmath48 to be small  ( * ? ? ?",
    "* ( 16.2.1 ) ) . solving @xmath128",
    "we find that @xmath132 table  [ tab : tttable ] gives the calculated values of @xmath133 for @xmath134 and @xmath113 .",
    "ccccccccccc    ' '' ''    @xmath135    ' '' ''    & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 +    ' '' ''    @xmath136    ' '' ''    & @xmath137 & 0.001 & 0.011 & 0.059 & 0.165 & 0.337 & 0.573 & 0.869 & 1.217 + @xmath138 & @xmath139 & 0.003 & 0.029 & 0.104 & 0.243 & 0.449 & 0.716 & 1.039 & 1.411 + @xmath140 & 0.001 & 0.012 & 0.061 & 0.168 & 0.341 & 0.579 & 0.876 & 1.225 & 1.618 + @xmath141 & 0.484 & 0.743 & 1.058 & 1.420 & 1.823 & 2.262 & 2.733 & 3.230 & 3.750 +      the neumann addition formula expresses @xmath142 as an infinite sum of products of bessel functions of the form @xmath143 for @xmath144 .",
    "it is given by  ( * ? ? ?",
    "* ( 10.23.2 ) ) @xmath145 here , we wish to truncate   and use it as a numerical approximation to @xmath142 .",
    "fortunately , when @xmath146 is small ( so that @xmath147 can be considered as a perturbation of @xmath48 ) the neumann addition formula is a rapidly converging series for @xmath148 .",
    "let @xmath6 be an integer , @xmath72 , and @xmath149 .",
    "then , for @xmath150 we have @xmath151 where @xmath152 is euler s number .",
    "[ lem : neumannbound ]    let @xmath6 be an integer , @xmath72 , @xmath149 , and @xmath150 . denote the left - hand side of the inequality in   by @xmath153 so that @xmath154 since @xmath155  ( * ? ? ?",
    "* ( 10.14.1 ) ) and @xmath156  ( * ? ? ?",
    "* ( 10.4.1 ) ) , we have @xmath157 by kapteyn s inequality  ( * ? ? ?",
    "* ( 10.14.8 ) ) we can bound @xmath158 from above as follows : @xmath159 where the last inequality comes from @xmath160 for @xmath161 .",
    "therefore , by substituting   into   we find that @xmath162 where we used @xmath163 and @xmath164 .",
    "lemma  [ lem : neumannbound ] shows that @xmath165 approximates @xmath166 , up to an error of @xmath35 , provided that @xmath167 .",
    "equivalently , for any @xmath168 table  [ tab : neumanntable ] gives the values of @xmath169 for @xmath170 .",
    "ccccccccccc    ' '' ''    @xmath62    ' '' ''    & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 +    ' '' ''    ' '' ''    & @xmath171 & @xmath172 & 0.001 & 0.002 & 0.004 & 0.008 & 0.013 & 0.020 +    at first it may not be clear why lemma  [ lem : neumannbound ] is useful for practical computations since a single evaluation of @xmath173 is replaced by a seemingly trickier sum of products of bessel functions .",
    "however , in sections  [ sec : fourierbessel ] and  [ sec : discretehankeltransform ] the truncated neumann addition formula will be the approximation that will allow us to evaluate fourier ",
    "bessel expansions and compute the discrete hankel transform .",
    "the crucial observation is that the positive roots of @xmath95 can be regarded as a perturbed equally - spaced grid .",
    "let @xmath18 denote the @xmath19th positive root of @xmath95 .",
    "we know from   that the leading asymptotic behavior of @xmath95 is @xmath175 for large @xmath48 .",
    "therefore , since @xmath176 for @xmath177 the leading asymptotic behavior of @xmath18 is @xmath178 for large @xmath19 . similarly , the leading asymptotic behavior of @xmath179 is @xmath180 for large @xmath103 and @xmath52 .",
    "the next lemma shows that @xmath181 and the ratios @xmath182 can be regarded as perturbed equally - spaced grids .",
    "let @xmath18 denote the @xmath19th positive root of @xmath95 .",
    "then , @xmath183 and @xmath184 [ lem : besselinequalities ]    the bounds on @xmath185 are given in  ( * ? ? ?",
    "3 ) . for the bound on @xmath186",
    "we have ( since @xmath187 and @xmath188 ) @xmath189 the result follows from @xmath190 and @xmath191 .",
    "lemma  [ lem : besselinequalities ] shows that we can consider @xmath181 as a small perturbation of @xmath192 and that we can consider @xmath182 as a small perturbation of @xmath193 .",
    "this is an important observation for sections  [ sec : fourierbessel ] and  [ sec : discretehankeltransform ] .",
    "a schlmilch expansion of a function @xmath194\\rightarrow \\mathbb{c}$ ] takes the form  @xcite : @xmath195 here , we take @xmath196 to be an integer and develop a fast @xmath1 algorithm for evaluating schlmilch expansions at @xmath197 , where @xmath198 .",
    "the evaluation of   at @xmath197 is equivalent to computing the matrix - vector product @xmath199 , i.e. , @xmath200 where @xmath201 and @xmath15 .",
    "the @xmath41 entry of @xmath202 is @xmath203 , which takes a similar form to the @xmath204 entry of @xmath205 , @xmath206 , and the @xmath41 entry of @xmath207 , @xmath208 , see  .",
    "we will carefully use the asymptotic expansion in   to approximate @xmath202 by a weighted sum of @xmath205 and @xmath207 .      to derive a fast matrix - vector product for @xmath202",
    ", we first substitute @xmath209 into the asymptotic expansion  . by the trigonometric addition formula we have @xmath210 as a matrix decomposition we can write this as the following sum of @xmath211 and @xmath212 : @xmath213 where @xmath214 is a zero column vector , @xmath215^\\intercal$ ] , @xmath216 , and @xmath217 .",
    "similarly , for sine we have @xmath218    thus , by substituting   and   into   with @xmath219 we obtain a matrix decomposition for @xmath202 , @xmath220 where we used the fact that @xmath55 is a rank @xmath56 matrix .",
    "we can write   more conveniently as @xmath221    one could now compute @xmath222 by first computing the vector @xmath223 and then correcting it by @xmath224 .",
    "the matrix - vector product @xmath223 can be computed in @xmath23 operations since the expression in   decomposes @xmath225 as a weighted sum of diagonal matrices and @xmath73 dcts and dsts .    while this does lead to an @xmath23 evaluation scheme for schlmilch expansions , it is numerically unstable because the asymptotic expansion is employed for entries @xmath226 for which @xmath227 is small ( see section  [ sec : asymptoticexpansion ] ) .",
    "numerical overflow issues and severe cancellation errors plague this approach . figure  [ fig : partition ] illustrates the entries that cause the most numerical problems .",
    "we must be more careful and only employ the asymptotic expansion for the @xmath41 entry of @xmath228 if @xmath229 .",
    "( 0,0 ) ; ( 5,0 ) ",
    "( 8,0 )  ( 8,3 ) ",
    "( 5,0 ) ; at ( .8,1.5 ) ( l1 ) @xmath202 ; at ( 5.6,1.5 ) ( l1 ) @xmath225 ; at ( 9.6,1.5 ) ( l2 ) @xmath230 ; at ( 8.5,1.7 ) ( l2 ) @xmath231 ; at ( 4,1.7 ) ( l2 ) @xmath232 ; ( 9,0)(0.200 * 3/5 + 9,0.000 * 3/5)(0.216 * 3/5 + 9,0.366 * 3/5)(0.221 * 3/5 + 9,0.476 * 3/5)(0.226 * 3/5 + 9,0.581 * 3/5)(0.232 * 3/5 + 9,0.682 * 3/5)(0.237 * 3/5 + 9,0.778 * 3/5)(0.242 * 3/5 + 9,0.870 * 3/5)(0.247 * 3/5 + 9,0.957 * 3/5)(0.253 * 3/5 + 9,1.042 * 3/5)(0.258 * 3/5 + 9,1.122 * 3/5)(0.263 * 3/5 + 9,1.200 * 3/5)(0.268 * 3/5 + 9,1.275 * 3/5)(0.274 * 3/5 + 9,1.346 * 3/5)(0.279 * 3/5 + 9,1.415 * 3/5)(0.284 * 3/5 + 9,1.481 * 3/5)(0.289 * 3/5 + 9,1.545 * 3/5)(0.295 * 3/5 + 9,1.607 * 3/5)(0.300 * 3/5 + 9,1.667 * 3/5 ) (0.385 * 3/5 + 9,2.400 * 3/5)(0.513 * 3/5 + 9,3.050 * 3/5)(0.641 * 3/5 + 9,3.440 * 3/5)(0.769 * 3/5 + 9,3.700 * 3/5)(0.897 * 3/5 + 9,3.886 * 3/5)(1.026 * 3/5 + 9,4.025 * 3/5)(1.154 * 3/5 + 9,4.133 * 3/5)(1.282 * 3/5 + 9,4.220 * 3/5)(1.410 * 3/5 + 9,4.291 * 3/5)(1.538 * 3/5 + 9,4.350 * 3/5)(1.667 * 3/5 + 9,4.400 * 3/5)(1.795 * 3/5 + 9,4.443 * 3/5)(1.923 * 3/5 + 9,4.480 * 3/5)(2.051 * 3/5 + 9,4.513 * 3/5)(2.179 * 3/5 + 9,4.541 * 3/5)(2.308 * 3/5 + 9,4.567 * 3/5)(2.436 * 3/5 + 9,4.589 * 3/5)(2.564 * 3/5 + 9,4.610 * 3/5)(2.692 * 3/5 + 9,4.629 * 3/5)(2.821",
    "* 3/5 + 9,4.645 * 3/5)(2.949 * 3/5 + 9,4.661 * 3/5)(3.077 * 3/5 + 9,4.675 * 3/5)(3.205 * 3/5 + 9,4.688 * 3/5)(3.333 * 3/5 + 9,4.700 * 3/5)(3.462 * 3/5 + 9,4.711 * 3/5)(3.590 * 3/5 + 9,4.721 * 3/5)(3.718 * 3/5 + 9,4.731 * 3/5)(3.846 * 3/5 + 9,4.740 * 3/5)(3.974 * 3/5 + 9,4.748 * 3/5)(4.103 * 3/5 + 9,4.756 * 3/5)(4.231 * 3/5 + 9,4.764 * 3/5)(4.359 *",
    "3/5 + 9,4.771 * 3/5)(4.487 * 3/5 + 9,4.777 * 3/5)(4.615 * 3/5 + 9,4.783 * 3/5)(4.744 * 3/5 + 9,4.789 * 3/5)(4.872 * 3/5 + 9,4.795 * 3/5)(5.000 * 3/5 + 9,4.800 * 3/5)(12,3)(9,3)(9,0 ) ; ( 0.200 * 3/5 + 9,0.000 * 3/5)(0.216 * 3/5 + 9,0.366 * 3/5)(0.221 * 3/5 + 9,0.476 * 3/5)(0.226 * 3/5 + 9,0.581 * 3/5)(0.232 * 3/5 + 9,0.682 * 3/5)(0.237",
    "* 3/5 + 9,0.778 * 3/5)(0.242 * 3/5 + 9,0.870 * 3/5)(0.247 * 3/5 + 9,0.957 * 3/5)(0.253 * 3/5 + 9,1.042 * 3/5)(0.258 * 3/5 + 9,1.122 * 3/5)(0.263 * 3/5 + 9,1.200 * 3/5)(0.268 * 3/5 + 9,1.275 * 3/5)(0.274 * 3/5 + 9,1.346 * 3/5)(0.279",
    "* 3/5 + 9,1.415 * 3/5)(0.284 * 3/5 + 9,1.481 * 3/5)(0.289 * 3/5 + 9,1.545 * 3/5)(0.295 * 3/5 + 9,1.607 * 3/5)(0.300 * 3/5 + 9,1.667 * 3/5 ) (0.385 * 3/5 + 9,2.400 * 3/5)(0.513 * 3/5 + 9,3.050 * 3/5)(0.641 * 3/5 + 9,3.440 * 3/5)(0.769 * 3/5 + 9,3.700 * 3/5)(0.897 * 3/5 + 9,3.886 * 3/5)(1.026 * 3/5 + 9,4.025 * 3/5)(1.154 * 3/5 + 9,4.133 * 3/5)(1.282 * 3/5 + 9,4.220 * 3/5)(1.410 * 3/5 + 9,4.291 * 3/5)(1.538 * 3/5 + 9,4.350 * 3/5)(1.667 * 3/5 + 9,4.400 * 3/5)(1.795 * 3/5 + 9,4.443 * 3/5)(1.923 * 3/5 + 9,4.480 * 3/5)(2.051 * 3/5 + 9,4.513 * 3/5)(2.179 * 3/5 + 9,4.541 * 3/5)(2.308 * 3/5 + 9,4.567 * 3/5)(2.436 * 3/5 + 9,4.589 * 3/5)(2.564 * 3/5 + 9,4.610 * 3/5)(2.692",
    "* 3/5 + 9,4.629 * 3/5)(2.821 * 3/5 + 9,4.645 * 3/5)(2.949 * 3/5 + 9,4.661 * 3/5)(3.077 * 3/5 + 9,4.675 * 3/5)(3.205 * 3/5 + 9,4.688 * 3/5)(3.333",
    "* 3/5 + 9,4.700 * 3/5)(3.462 * 3/5 + 9,4.711 * 3/5)(3.590 * 3/5 + 9,4.721 * 3/5)(3.718 * 3/5 + 9,4.731 * 3/5)(3.846 * 3/5 + 9,4.740 * 3/5)(3.974 * 3/5 + 9,4.748 * 3/5)(4.103 * 3/5 + 9,4.756 * 3/5)(4.231 * 3/5 + 9,4.764 * 3/5)(4.359 * 3/5 + 9,4.771 * 3/5)(4.487 * 3/5 + 9,4.777 * 3/5)(4.615 * 3/5 + 9,4.783 * 3/5)(4.744 * 3/5 + 9,4.789 * 3/5)(4.872 * 3/5 + 9,4.795 * 3/5)(5.000 * 3/5 + 9,4.800 * 3/5 ) ; ( 5,3 * 3/5+.3)(0.5 * 3/5 + 4.7,3 * 3/5+.3)(0.513 * 3/5 + 4.7,3.050 * 3/5+.3)(0.641 * 3/5 + 4.7,3.440 * 3/5+.3)(0.769 * 3/5 + 4.7,3.700 * 3/5+.3)(0.897 * 3/5 + 4.7,3.886 * 3/5+.3)(1.026 * 3/5 + 4.7,4.025 * 3/5+.3)(1.154 * 3/5 + 4.7,4.133 * 3/5+.3)(1.282",
    "* 3/5 + 4.7,4.220 * 3/5+.3)(1.410 * 3/5 + 4.7,4.291 * 3/5+.3)(1.538",
    "* 3/5 + 4.7,4.350 * 3/5+.3)(1.667 * 3/5 + 4.7,4.400 * 3/5+.3)(1.795 * 3/5 + 4.7,4.443 * 3/5+.3)(1.923 * 3/5 + 4.7,4.480 * 3/5+.3)(2 * 3/5 + 4.7,4.5 * 3/5+.3)(2 * 3/5 + 4.7,3)(5,3)(5,3 * 3/5+.3 ) ; ( 5 + 4,3 * 3/5+.3)(0.5 * 3/5 + 4.7 + 4,3 * 3/5+.3)(0.513 * 3/5 + 4.7 + 4,3.050 * 3/5+.3)(0.641 * 3/5 + 4.7 + 4,3.440 * 3/5+.3)(0.769 * 3/5 + 4.7 + 4,3.700 * 3/5+.3)(0.897 * 3/5 + 4.7 + 4,3.886 * 3/5+.3)(1.026 * 3/5 + 4.7 + 4,4.025 * 3/5+.3)(1.154 * 3/5 + 4.7 + 4,4.133 * 3/5+.3)(1.282 * 3/5 + 4.7 + 4,4.220 * 3/5+.3)(1.410 * 3/5 + 4.7 + 4,4.291 * 3/5+.3)(1.538 * 3/5 + 4.7 + 4,4.350 * 3/5+.3)(1.667 * 3/5 + 4.7 + 4,4.400 * 3/5+.3)(1.795 * 3/5 + 4.7 + 4,4.443 * 3/5+.3)(1.923 * 3/5 + 4.7 + 4,4.480 * 3/5+.3)(2 * 3/5 + 4.7 + 4,4.5 * 3/5+.3)(2 * 3/5 + 4.7 + 4,3)(5 + 4,3)(5 + 4,3 * 3/5+.3 ) ; ( 9,0 )  ( 12,0 )  ( 12,3 )  ( 9,3 )  ( 9,0 ) ;    by section  [ sec : asymptoticexpansion ] we know that if @xmath233 then @xmath87 .",
    "therefore , we can use   for the @xmath41 entry of @xmath202 provided that @xmath234 .",
    "this is guaranteed , for instance , when @xmath235 where @xmath236 .",
    "therefore , we can be more careful by taking the @xmath40 diagonal matrix @xmath237 with @xmath238 for @xmath239 and @xmath0 otherwise , and compute @xmath240 using the following matrix decomposition : @xmath241 where @xmath242 is the matrix @xmath243    if the @xmath41 entry of @xmath244 is nonzero , then @xmath245 and hence ,   only approximates @xmath46 by a weighted sum of trigonometric functions when it is safe to do so . figure",
    "[ fig : decomposition ] shows how the criterion   partitions the entries of @xmath202 .",
    "a stable @xmath45 algorithm for evaluating schlmilch expansions   follows , as we will now explain .",
    "( 1,0 )  ( 1,4 ) ",
    "( 0,0 ) ; ( 0,0 ) ",
    "( 0,0 ) ; ( 0.200,0.000)(0.216,0.366)(0.221,0.476)(0.226,0.581)(0.232,0.682)(0.237,0.778)(0.242,0.870)(0.247,0.957)(0.253,1.042)(0.258,1.122)(0.263,1.200)(0.268,1.275)(0.274,1.346)(0.279,1.415)(0.284,1.481)(0.289,1.545)(0.295,1.607)(0.300,1.667 ) (0.385,2.400)(0.513,3.050)(0.641,3.440)(0.769,3.700)(0.897,3.886)(1.026,4.025)(1.154,4.133)(1.282,4.220)(1.410,4.291)(1.538,4.350)(1.667,4.400)(1.795,4.443)(1.923,4.480)(2.051,4.513)(2.179,4.541)(2.308,4.567)(2.436,4.589)(2.564,4.610)(2.692,4.629)(2.821,4.645)(2.949,4.661)(3.077,4.675)(3.205,4.688)(3.333,4.700)(3.462,4.711)(3.590,4.721)(3.718,4.731)(3.846,4.740)(3.974,4.748)(4.103,4.756)(4.231,4.764)(4.359,4.771)(4.487,4.777)(4.615,4.783)(4.744,4.789)(4.872,4.795)(5.000,4.800 ) ; at ( 1.5,2 ) ( l1 ) @xmath246 ; at ( -.1,4.2 ) ( l2 ) ; at ( 5,4.9 ) ( l2 ) ; at ( 0.1,0 ) ( l2 ) @xmath52 ; at ( 0.1,4 ) ( l2 ) @xmath247 ; at ( 1,4.9 ) ( l2 ) ;    by construction all the entries of @xmath248 are less than @xmath35 in magnitude so its contribution to the matrix - vector product @xmath240 can be ignored , i.e. , we make the approximation @xmath249 the matrix - vector product @xmath250 can be computed in @xmath23 operations using dcts and dsts by  .",
    "moreover , the number of nonzero entries in @xmath242 is @xmath251 and hence , the matrix - vector product @xmath252 can be computed in @xmath45 operations using direct summation .",
    "this algorithm successfully stabilizes the @xmath23 matrix - vector product that results from   as it only employs the asymptotic expansion for entries of @xmath226 for which @xmath227 is sufficiently large . in practice , this algorithm is faster than direct summation for @xmath253 ( see figure  [ fig : schlomilchresults ] ) .",
    "however , the algorithm has an @xmath45 complexity because the criterion   is in hindsight too cautious .",
    "we can do better .",
    "note that the asymptotic expansion   is accurate for all @xmath51 entries of @xmath202 except for @xmath254 of them , where @xmath255 is the indicator function and the last equality is from the leading asymptotic behavior of the @xmath52th harmonic number as @xmath256 .",
    "therefore , a lower complexity than @xmath45 seems possible if we use the asymptotic expansion for more entries of @xmath202 .",
    "roughly speaking , we need to refine the partitioning of @xmath202 so that the black curve , @xmath257 , in figure  [ fig : decomposition ] is better approximated .    first , we are only allowed to partition @xmath202 with rectangular matrices since for those entries that we do employ the asymptotic expansion we need to be able to use dcts and dsts to compute matrix - vector products .",
    "second , there is a balance to be found since each new rectangular partition requires @xmath73 more dcts and dsts .",
    "too many partitions and the cost of computing dcts and dsts will be overwhelming , but too few and the cost of computing @xmath252 will dominate . these two competing costs must be balanced .    to find the balance we introduce a parameter @xmath258 . roughly speaking , if @xmath259 then we partition as much as possible and the asymptotic expansion is used for every entry satisfying @xmath260 .",
    "if @xmath261 then we do not refine and we keep the @xmath45 algorithm from section  [ sec : singlepartition ] . an intermediate value of @xmath262 will balance the two competing costs .    figure  [ fig : hdecomposition ] shows the partition of @xmath202 that we consider and it is worth carefully examining that diagram .",
    "the partition corresponds to the following matrix decomposition : @xmath263 where @xmath264 is the number of partitions , @xmath237 is the diagonal matrix in section  [ sec : singlepartition ] , and the @xmath40 matrices @xmath265 and @xmath266 are diagonal matrices with @xmath267    note that if the @xmath41 entry of the matrix @xmath268 is nonzero , then @xmath269 and @xmath270 .",
    "hence , @xmath271 and @xmath272 .",
    "similarly , if the @xmath41 entry of @xmath273 is nonzero , then @xmath260 . therefore , we are only employing the asymptotic expansion   on entries of @xmath274 for which it is accurate and numerically stable to do so .",
    "( 0.23255,0 ) ",
    "( 0.23255,.7 ) ",
    "( 0.43478,.7 ) ",
    "( 0.43478,2.7 ) ",
    "( 1,2.7 ) ",
    "( 2.3,4 ) ",
    "( 2.3,4.56522 ) ",
    "( 4.3,4.56522 ) ",
    "( 4.3,4.76744 ) ",
    "( 5,4.76744 ) ",
    "( 0,0 ) ; ( 0,0 ) ",
    "( 0,0 ) ; ( 0.200,0.000)(0.216,0.366)(0.221,0.476)(0.226,0.581)(0.232,0.682)(0.237,0.778)(0.242,0.870)(0.247,0.957)(0.253,1.042)(0.258,1.122)(0.263,1.200)(0.268,1.275)(0.274,1.346)(0.279,1.415)(0.284,1.481)(0.289,1.545)(0.295,1.607)(0.300,1.667 ) (0.385,2.400)(0.513,3.050)(0.641,3.440)(0.769,3.700)(0.897,3.886)(1.026,4.025)(1.154,4.133)(1.282,4.220)(1.410,4.291)(1.538,4.350)(1.667,4.400)(1.795,4.443)(1.923,4.480)(2.051,4.513)(2.179,4.541)(2.308,4.567)(2.436,4.589)(2.564,4.610)(2.692,4.629)(2.821,4.645)(2.949,4.661)(3.077,4.675)(3.205,4.688)(3.333,4.700)(3.462,4.711)(3.590,4.721)(3.718,4.731)(3.846,4.740)(3.974,4.748)(4.103,4.756)(4.231,4.764)(4.359,4.771)(4.487,4.777)(4.615,4.783)(4.744,4.789)(4.872,4.795)(5.000,4.800 ) ; at ( 1.5,2 ) ( l1 ) @xmath246 ; at ( 2.4,4.25 ) ( l11 ) ; at ( .42,1.34 ) ( l11 ) ; at ( -.1,4.2 ) ( l2 ) ; at ( 0.1,4.5 ) ( l2 ) @xmath275 ; at ( 0.1,4 ) ( l2 ) @xmath276 ; at ( 0.1,2.7 ) ( l2 ) @xmath277 ; at ( 0.1,.7 ) ( l2 ) @xmath278 ; at ( 0.1,0 ) ( l2 ) @xmath52 ; at ( 5,4.9 ) ( l2 ) ; at ( .9,4.9 ) ( l2 ) ; at ( .35,4.9 ) ( l2 ) ; at ( 5 - 2.7,4.9 ) ( l2 ) ; at ( 4.3,4.9 ) ( l2 ) ; ( 0.43478,0)(0.43478,1 ) ; ( 1,0)(1,3 ) ; ( 4,4.56522)(5,4.56522 ) ; ( 2,4)(5,4 ) ;    each matrix - vector product of the form @xmath279 requires @xmath73 dcts and dsts from   and hence , costs @xmath23 operations .",
    "there are a total of @xmath280 matrices of this form in   so exploiting the asymptotic expansion requires @xmath281 operations .",
    "the cost of the matrix - vector product @xmath252 is proportional to the number of nonzero entries in @xmath242 . ignoring the constant @xmath282 ,",
    "this is approximately ( by counting the entries in rectangular submatrices of @xmath242 , see figure  [ fig : hdecomposition ] ) @xmath283 where the last equality follows from the assumption that @xmath284 .    to balance the competing @xmath285 cost of exploiting the asymptotic expansion with the @xmath286 cost of computing @xmath252 , we set @xmath287 and find that @xmath288 .",
    "moreover , to ensure that the assumption @xmath289 holds we take @xmath290 .",
    "thus , the number of partitions should slowly grow with @xmath52 to balance the competing costs . with these asymptotically optimal choices of @xmath262 and",
    "@xmath264 the algorithm for computing the matrix - vector product @xmath240 via   requires @xmath291 operations . more specifically , the complexity of the algorithm is @xmath292 since @xmath293 , see figure  [ fig : schlomilchresults ] .",
    "though , the implicit constants in @xmath288 and @xmath294 do not change the complexity of the algorithm , they must still be decided on . after numerical experiments we set @xmath295 and @xmath296 for computational efficiency reasons .",
    "table  [ tab : algorithmicparameters ] summarizes the algorithmic parameters that we have carefully selected .",
    "the user is required to specify the problem with an integer @xmath6 , a vector of expansion coefficients @xmath297 in  , and then provide a working accuracy @xmath28 .",
    "all other algorithmic parameters are selected in a near - optimal manner based on analysis .",
    "ccc    ' '' ''    parameter    ' '' ''    & short description & formula +    ' '' ''    @xmath89    ' '' ''    & number of terms in   & @xmath298 + @xmath104 & @xmath299 & see table  [ tab : smtable ] + @xmath282 & partitioning parameter & @xmath300 + @xmath262 & refining parameter & @xmath301 + @xmath264 & number of partitions & @xmath302 +    [ rmk : gammashift ] a fast evaluation scheme for @xmath303 , where @xmath304 is a constant , immediately follows from this section .",
    "the constants @xmath305 and @xmath306 in   and   should be replaced by diagonal matrices @xmath39 and @xmath307 , where @xmath308 and @xmath309 , respectively .",
    "we now compare three algorithms for evaluating schlmilch expansions : ( 1 ) direct summation ( see section  [ sec : existing ] ) ; ( 2 ) our @xmath45 algorithm ( see section  [ sec : singlepartition ] ) , and ; ( 3 ) our @xmath1 algorithm ( see section  [ sec : recursivepartition ] ) .",
    "the three algorithms have been implemented in matlab and are publicly available from  @xcite .",
    "figure  [ fig : schlomilchresults ] ( left ) shows the execution time for the three algorithms for evaluating schlmilch expansions for @xmath7 . here",
    ", we select the working accuracy as @xmath170 and use table  [ tab : algorithmicparameters ] to determine the other algorithmic parameters .",
    "we find that our @xmath1 algorithm in section  [ sec : recursivepartition ] is faster than direct summation for @xmath253 and faster than our @xmath45 algorithm for @xmath310 .",
    "in fact , for @xmath311 the number of partitions , @xmath264 , is selected to be @xmath0 and the @xmath1 algorithm in section  [ sec : recursivepartition ] is identical to the @xmath45 algorithm in section  [ sec : singlepartition ] . for a relaxed working accuracy of @xmath312 or @xmath313",
    "our @xmath1 algorithm becomes even more computationally advantageous over direct summation .",
    "figure  [ fig : schlomilchresults ] ( right ) shows the execution time for our @xmath1 algorithm with @xmath314 , @xmath315 , and working accuracies @xmath316 . for each @xmath28",
    "there is a choice of @xmath89 that minimizes the execution time .",
    "numerical experiments like these motivate the choice @xmath317 in  .",
    "schlomilchtimings ( 41,53 ) ( 53,48 ) ( 51,27 ) ( 50,0 ) @xmath52 ( 0,20 )    optimalm ( 50,0 ) @xmath89 ( 0,20 ) ( 32,44 ) ( 22,28.2 ) ( 20,11 )",
    "in this section we adapt the @xmath1 algorithm in section  [ sec : recursivepartition ] to an evaluation scheme for expansions of the form : @xmath318 , \\label{eq : fourierbessel}\\ ] ] where @xmath6 is an integer and @xmath18 is the @xmath19th positive root of @xmath319 . for @xmath7 ,",
    "is the fourier ",
    "bessel expansion of order @xmath0 of the function @xmath194\\rightarrow \\mathbb{c}$ ] .",
    "the algorithm that we describe evaluates   at @xmath198 for @xmath320 , which is equivalent to computing the matrix - vector product @xmath321 , where @xmath322 is a column vector with entries @xmath181 .    developing a fast algorithm for computing the matrix - vector product @xmath321 is a challenge for fft - based algorithms because the positive roots of @xmath319 are not equally - spaced . here , we are able to derive a fast evaluation scheme by considering @xmath181 as a perturbed equally - spaced grid ( see section  [ sec : besselrootsperturbed ] ) .",
    "first , we derive a matrix decomposition for @xmath323 , where @xmath324 , @xmath37 , and @xmath325 are column vectors .",
    "afterwards , we will consider @xmath326 as a perturbation of @xmath37 .    for integers @xmath6 and @xmath327 and for column vectors",
    "@xmath324 , @xmath37 , and @xmath325 of length @xmath52 , we have the following matrix decomposition : @xmath328 [ thm : besseldecomposition ]    we prove   by showing that the @xmath41 entry of the matrix on the left - hand side and right - hand side are equal for @xmath47 .",
    "pick any @xmath47 . by the neumann addition formula   we have @xmath329 moreover , by applying the taylor series expansion of bessel functions   we have @xmath330 by substituting   into   we obtain @xmath331 and",
    "the result follows .",
    "we now wish to write down a particular instance of   that is useful for computing @xmath321 . by lemma  [",
    "lem : besselinequalities ] we can write @xmath332 , where @xmath333 and @xmath185 is a number such that @xmath334 .",
    "in vector notation we have @xmath335 .",
    "hence , by proposition  [ thm : besseldecomposition ] we have @xmath336 this is a useful matrix decomposition since each term in the double sum can be applied to a vector in @xmath337 operations .",
    "the diagonal matrices @xmath338 and @xmath339 have @xmath340 matrix - vector products and @xmath341 has @xmath337 matrix - vector products ( see section  [ sec : recursivepartition ] and remark  [ rmk : gammashift ] ) . however , for   to be practical we must truncate the inner and outer sums .",
    "let @xmath150 be an integer and truncate the outer sum in   to @xmath342 .",
    "by lemma  [ lem : neumannbound ] , with @xmath343 and @xmath344 , the truncated neumann addition formula is still accurate , up to an error of @xmath35 , for the @xmath41 entry of @xmath345 provided that @xmath346 solving for @xmath19 we find that @xmath347 that is , once we truncate the outer sum in   to @xmath342 the matrix decomposition is still accurate for all the columns of @xmath345 except the first @xmath348 .",
    "for example when @xmath349 , @xmath350 and hence , once the outer sum is truncated we must not use   on the first @xmath351 columns of @xmath345 . based on numerical experiments we pick @xmath150 to be the smallest integer so that @xmath352 and hence , @xmath353 .",
    "next , we let @xmath354 be an integer and truncate the inner sum to @xmath355 . by section  [ sec : besseltaylor ]",
    "the truncated taylor series expansion is accurate , up to an error of @xmath35 , for the @xmath41 entry of @xmath345 provided that @xmath356 where the minimization is taken over @xmath357 , instead of @xmath358 , because of the relation @xmath359  ( * ? ? ? * ( 10.4.1 ) ) . solving for @xmath19",
    "we find that @xmath360 thus , once the inner sum is truncated in   to @xmath361 the decomposition is accurate for all but the first @xmath362 columns of @xmath345 .",
    "for example when @xmath363 , @xmath364 and we must not use   on the first @xmath365 columns of @xmath345 . in practice , we select @xmath354 to be the smallest integer so that @xmath366 .    to avoid employing the decomposition   with truncated sums @xmath367 on the first @xmath368 columns of @xmath345",
    ", we partition the vector @xmath297 .",
    "that is , we write @xmath369 , where @xmath370 first , we compute @xmath371 using   with truncated sums @xmath367 in @xmath1 operations and then compute @xmath372 using direct summation in @xmath340 operations .      at first",
    "it seems that computing @xmath321 is @xmath373 times the cost of evaluating a schlmilch expansion , since there are @xmath373 terms in @xmath367 .",
    "however , the computation can be rearranged so the evaluation of   is only @xmath374 times the cost . for @xmath349 and @xmath363 , the values",
    "that we take when @xmath375 , we have @xmath376 and @xmath377 so there is a significant computational saving here .",
    "since @xmath378  ( * ? ? ?",
    "* ( 10.4.1 ) ) we have @xmath379 d_{\\underline{b}}^{2t+s}\\underline{c}\\\\    & = \\!\\!\\!\\sum_{u=0}^{2t+k-3}\\!\\!\\!\\!\\ !",
    "d_{\\underline{r}}^{u}\\!\\ ! \\left[\\!\\sum_{t=\\max(\\lceil \\frac{u - k+1}{2}\\rceil,0)}^{\\min(\\lfloor \\frac{u}{2}\\rfloor , t-1)}{}^{\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!''\\,\\,\\,\\,\\,\\ , } \\frac{(-1)^t2^{-u}}{t!(u - t)!}\\!\\ ! \\left[\\mathbf{j}_{\\nu - u+2t}(\\ , \\underline{r}\\,\\tilde{\\underline{\\omega}}^\\intercal ) + ( -1)^{u-2t}\\mathbf{j}_{\\nu+u-2t}(\\ , \\underline{r}\\,\\tilde{\\underline{\\omega}}^\\intercal ) \\right ] \\",
    "! \\right ] \\!\\ !",
    "d_{\\underline{b}}^{u}\\underline{c},\\\\    \\end{aligned}\\ ] ] where the single prime on the sum indicates that the first term is halved and the double prime indicates that the last term is halved . here",
    ", the last equality follows by letting @xmath380 and performing a change of variables .",
    "now , for each @xmath381 , the inner sum can be computed at the cost of one application of the @xmath1 algorithm in section  [ sec : recursivepartition ] . since each evaluation of a schlmilch expansion costs @xmath382 operations and @xmath383 , a fourier ",
    "bessel evaluation costs @xmath384 operations .",
    "figure  [ fig : fbresults1 ] ( left ) shows the execution time for evaluating fourier ",
    "bessel expansions of order @xmath0 with direct summation and our @xmath1 algorithm with working accuracies of @xmath385 .",
    "our algorithm is faster than direct summation for @xmath386 when @xmath170 .",
    "relaxing the working accuracy not only decreases @xmath62 and @xmath135 , but also speeds up the evaluation of each schlmilch expansion . when @xmath387 , our algorithm is faster than direct summation for @xmath253 .",
    "the algorithmic parameters are selected based on careful analysis so that the evaluation scheme is numerically stable and the computed vector @xmath63 has a componentwise accuracy of @xmath388 , where @xmath389 is the vector 1-norm . in figure",
    "[ fig : fbresults1 ] ( right ) we verify this for @xmath385 by considering the error @xmath390 , where @xmath391 is the absolute maximum vector norm and @xmath392 is the vector of values computed in quadruple precision using direct summation . for these experiments",
    "we take the entries of @xmath297 as realizations of independent gaussians so that @xmath393 .",
    "fourierbesseltimings ( 47,53 ) ( 43.5,40 ) ( 50,-1 ) @xmath52 ( -.5,20 )    fourierbesselerrors ( 45,29.5 ) ( 45,46.5 ) ( 45,61.5 ) ( 50,-1 ) @xmath52 ( -4,23 )",
    "we now adapt the algorithm in section  [ sec : fourierbessel ] to the computation of the discrete hankel transform ( dht ) of order @xmath0 , which is defined as  @xcite @xmath394 where @xmath18 is the @xmath19th positive root of @xmath95 .",
    "it is equivalent to the matrix - vector product @xmath395 and is more difficult for fft - based algorithms than the task in section  [ sec : fourierbessel ] because it may be regarded as evaluating a fourier  bessel expansion at points that are not equally - spaced .    to extend our @xmath1 algorithm to this setting we consider the ratios @xmath182 as a perturbed equally - spaced grid . by lemma  [ lem : besselinequalities ]",
    "we have @xmath396 we can write this in vector notation as @xmath397 , where @xmath398 . since @xmath399 and @xmath400 , we have by theorem  [ thm : besseldecomposition ] the following matrix decomposition : @xmath401    each term in   can be applied to a vector in @xmath337 operations .",
    "the diagonal matrices @xmath402 and @xmath403 have @xmath340 matrix - vector products and by section  [ sec : fourierbessel ] the matrix - vector product @xmath404 can be computed in @xmath337 operations .",
    "so to compute @xmath404 pad the vector @xmath297 with @xmath405 zeros , use the algorithm in section  [ sec : fourierbessel ] with @xmath52 replaced by @xmath406 , and then only keep @xmath407 for @xmath408 .",
    "] however , for   to be practical we must truncate the double sum .",
    "let @xmath150 and @xmath354 be integers and consider truncating the sum in   to @xmath409 . using similar reasoning to that in section  [ sec : fourierbessel ] , if we truncate   then the matrix decomposition is accurate , up to an error of @xmath35 , provided that @xmath410 and @xmath411 where we used the bound @xmath412 for @xmath413 .",
    "equivalently , provided that @xmath414 where @xmath415 and @xmath416 are defined in   and  , respectively .",
    "that is , after truncating the sums in   we can use the decomposition on all the entries of @xmath417 except for those in the first @xmath418 rows . in practice , we take @xmath150 and @xmath354 to be the smallest integers so that @xmath419 .    to avoid employing a truncated version of   on the first few rows we compute @xmath420 using   with sums @xmath421 in @xmath1 operations ,",
    "discard the first @xmath418 entries of @xmath63 , and then compute the discarded entries using direct summation in @xmath340 operations .    in the same way as section  [ sec :",
    "rearrange ] , we can rearrange the computation so that only @xmath374 , instead of @xmath373 , fourier ",
    "bessel evaluations are required .",
    "each fourier  bessel evaluation requires @xmath374 schlmilch evaluations .",
    "hence , a discrete hankel transform requires @xmath422 schlmilch evaluations .",
    "since @xmath423 , our algorithm for the dht requires @xmath424 operations .",
    "the exposition in this section may suggest that the same algorithmic ideas continue to work for @xmath425 . while this is correct , the computational performance rapidly deteriorates as @xmath6 increases .",
    "this is because the vector of bessel roots @xmath426 and the vector of ratios @xmath427 are distributed less like an equally - spaced grid for @xmath425 .",
    "this significantly increases the number of terms required in the taylor expansion and neumann addition formula . for large @xmath425 ,",
    "different algorithmic ideas should be employed , for example , one should take into account that @xmath428 can be very small when @xmath429 .",
    "it is expected that the matched asymptotic ( transition ) region of @xmath22 , when @xmath430 , will be the most difficult to exploit when deriving a fast algorithm .",
    "we have implemented our @xmath1 algorithm for computing the dht in matlab .",
    "it is publicly available from  @xcite .",
    "figure  [ fig : hankelresults1 ] ( left ) shows the execution time for computing the dht of order @xmath0 with direct summation and our @xmath1 algorithm with working tolerances of @xmath385 . our algorithm is faster than direct summation for @xmath431 when @xmath170 , for @xmath432 when @xmath433 , and for @xmath253 when @xmath434 .",
    "figure  [ fig : hankelresults1 ] ( right ) verifies that the selected algorithmic parameters do achieve the desired error bound of @xmath435 , where @xmath63 is the vector of the computed values of   and @xmath392 is the vector of values computed in quadruple precision using direct summation . in this experiment",
    "we take the entries of @xmath297 to be realizations of independent gaussians ( with mean @xmath0 and variance @xmath56 ) so that @xmath436 .    dhttimings ( 60,55 ) ( 46,30 ) ( 50,-1 ) @xmath52 ( 0,18 )    dhterrors ( 45,30 ) ( 45,47 ) ( 45,62 ) ( 50,-1 ) @xmath52 ( -5,22 )    the dht is , up to a diagonal scaling , its own inverse as @xmath256 .",
    "in particular , by  @xcite we have , as @xmath256 , @xmath437 where @xmath39 is a diagonal matrix with entries @xmath438 , and @xmath439 is the @xmath40 identity matrix .",
    "we can use the relation   to verify our algorithm for the dht .",
    "figure  [ fig : hankelresults2 ] shows the error @xmath440 , where @xmath297 is a column vector with entries drawn from independent gaussians and @xmath441 for small @xmath52 , @xmath440 will be large because   only holds as @xmath256 .",
    "however , even for large @xmath52 , we observe that @xmath440 grows like @xmath45 .",
    "this can be explained by tracking the accumulation of numerical errors .",
    "since the entries of @xmath297 are drawn from independent gaussians and @xmath442 we have @xmath443 and hence , we expect @xmath444 . by the same reasoning",
    "we expect @xmath445 .",
    "finally , this gets multiplied by @xmath446 in   so we expect @xmath447 . if in practice we desire @xmath448 , then it is sufficient to have @xmath449 .",
    "dhtinverse ( 52,32 ) ( 23,36 ) ( 50,-1.5 ) @xmath52 ( -4,27 )",
    "an asymptotic expansion of bessel functions for large arguments is carefully employed to derive a numerically stable @xmath1 algorithm for evaluating schlmilch and fourier ",
    "bessel expansions as well as computing the discrete hankel transform .",
    "all algorithmic parameters are selected based on error bounds to achieve a near - optimal computational cost for any accuracy goal . for a working accuracy of @xmath450 ,",
    "the algorithm is faster than direct summation for evaluating schlmilch expansions when @xmath253 , fourier ",
    "bessel expansions when @xmath386 , and the discrete hankel transform when @xmath431 .",
    "i thank the authors and editors of the digital library of mathematical functions ( dlmf ) . without it",
    "this paper would have taken longer .",
    "i also thank the referees for their time and consideration .",
    "6 , _ a fast algorithm for the evaluation of legendre expansions _ , siam j.  sci .",
    ", 12 ( 1991 ) , pp .",
    "158179 . ,",
    "_ algorithm 644 : a portable package for bessel functions of a complex argument and nonnegative order _ , acm trans .  math .",
    ", 12 ( 1986 ) , pp .",
    "265273 . , _",
    "the fast hankel transform as a tool in the solution of the time dependent schrdinger equation _ , j.  comput .",
    "phys . , 59 ( 1985 ) , pp .",
    "136151 . , _ dual algorithms for fast calculation of the fourier - bessel transform _ , ieee trans .",
    ". , 29 ( 1981 ) , pp .",
    "963972 . , _ algorithms to numerically evaluate the hankel transform _ , computers and mathematics with applications , 26 ( 1993 ) , pp",
    ".  112 . , _ fast computation of zero order hankel transform _",
    ", j. franklin institute , 316 ( 1983 ) , pp .",
    "317326 . , _ computation of quasi - discrete hankel transforms of integer order for propagating optical wave fields _ , j.  opt .",
    "a , 21 ( 2004 ) , pp .",
    "5358 . , _ a fast , simple , and stable chebyshev ",
    "legendre transform using an asymptotic formula _",
    ", siam j.  sci .",
    "comput . , 36 ( 2014 ) ,",
    ", _ an algorithm for the convolution of legendre series _ , siam j. sci . comput . , 36 ( 2014 ) , a1207a1220 .",
    ", _ a fast fft - based discrete legendre transform _ , submitted .",
    ", _ die cylinderfunctionen erster und zweiter art _",
    "ann . , 1 ( 1869 ) , pp .",
    "467501 . , _",
    "bounds for zeros of some special functions _ , proc .",
    "soc . , 25 .",
    "1970 , pp .  7274 .",
    ", _ a hankel transform approach to tomographic image reconstruction _",
    ", ieee transactions on medical imaging , 7 ( 1988 ) , pp .",
    "5972 . , _ an algorithm for the fast hankel transform _ , yale technical report , august 1995 . , _ an improved method for computing a discrete hankel transform _ ,",
    "computer physics communications , 43 ( 1987 ) , pp .",
    "181202 . , _ an improvement on orszag s fast algorithm for legendre polynomial transform _ , trans .",
    "processing soc .",
    "japan , 40 ( 1999 ) , pp .",
    ", _ a fourier bessel transform method for efficiently calculating the magnetic field of solenoids _",
    ", j. comput .",
    "phys . , 37 ( 1980 ) , pp .",
    "4155 . , _ nist handbook of mathematical functions _ , cambridge university press , 2010 .",
    ", _ an algorithm for the rapid evaluation of special function transforms _ , appl .",
    "comput .  harm .",
    ", 28 ( 2010 ) , pp .",
    "203226 . , _",
    "approximation for bessel functions and their application in the computation of hankel transforms _ , comput .",
    "8 ( 1982 ) , pp .  305311 . , _",
    "transforms and applications handbook , third edition _ , crc press , 2010 . , _ fast algorithms for spherical harmonic expansions _ , siam j. sci .",
    ", 27 ( 2006 ) , pp .",
    "19031928 . , _ note sur la variation des constantes arbitraires dune intgrale dfinie _ , journal fr die reine und angewandte mathematik , 33 ( 1846 ) , pp .",
    "268280 . ,",
    "_ numerical evaluation of spherical bessel transforms via fast fourier transforms _ , j. comput .",
    "phys . , 100 ( 1992 ) , pp .",
    "294296 . , fastasytransforms , http://github.com/ajt60gaibb/fastasytransforms . , _ fast algorithms for spherical harmonic expansions , ii _ , j. comput .",
    "phys . , 227 ( 2008 ) , pp .",
    "42604279 . , http://functions.wolfram.com/03.01.06.0037.01 ."
  ],
  "abstract_text": [
    "<S> a fast and numerically stable algorithm is described for computing the discrete hankel transform of order @xmath0 as well as evaluating schlmilch and fourier  </S>",
    "<S> bessel expansions in @xmath1 operations . </S>",
    "<S> the algorithm is based on an asymptotic expansion for bessel functions of large arguments , the fast fourier transform , and the neumann addition formula . </S>",
    "<S> all the algorithmic parameters are selected from error bounds to achieve a near - optimal computational cost for any accuracy goal . </S>",
    "<S> numerical results demonstrate the efficiency of the resulting algorithm .    </S>",
    "<S> hankel transform , bessel functions , asymptotic expansions , fast fourier transform    65r10 , 33c10 </S>"
  ]
}