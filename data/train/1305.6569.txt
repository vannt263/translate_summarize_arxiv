{
  "article_text": [
    "consider the stochastic dynamics @xmath0 on @xmath1 satisfying @xmath2 called _ brownian dynamics _ or _ overdamped langevin dynamics_. here @xmath3 is a smooth function , @xmath4 is a positive constant , and @xmath5 is a standard @xmath6-dimensional brownian motion @xcite .",
    "the dynamics   is used to model the evolution of the position vector @xmath0 of @xmath7 particles ( in which case @xmath8 ) in an energy landscape defined by the potential energy  @xmath9 .",
    "this is the so - called _",
    "molecular dynamics_. typically this energy landscape has many metastable states , and in applications it is of interest to understand how @xmath0 moves between them .",
    "temperature accelerated dynamics ( tad ) is an algorithm for computing this _ metastable dynamics _ efficiently .",
    "( see @xcite for the original algorithm , @xcite for some modifications , and @xcite for an overview of tad and other similar methods for accelerating dynamics . )",
    "each metastable state corresponds to a basin of attraction @xmath10 for the gradient dynamics @xmath11 of a local minimum of the potential @xmath9 . in tad",
    ", temperature is raised to force @xmath0 to leave each basin more quickly .",
    "what would have happened at the original low temperature is then extrapolated . to generate metastable dynamics of @xmath12 at low temperature",
    ", this procedure is repeated in each basin .",
    "this requires the assumptions :    * @xmath0 immediately reaches local equilibrium upon entering a given basin @xmath10 ; and * an arrhenius law may be used to extrapolate the exit event at low temperature .",
    "the arrhenius ( or eyring - kramers ) law states that , in the small temperature regime , the time it takes to transition between neighboring basins @xmath10 and @xmath13 is @xmath14,\\ ] ] where @xmath15 is the difference in potential energy between the local minimum in @xmath10 and the lowest saddle point along a path joining @xmath10 to @xmath13 . here",
    "@xmath16 is a constant ( called a _ prefactor _ ) depending on the eigenvalues of the hessian of @xmath9 at the local minimum and at the saddle point , but not on the temperature . in practice",
    "the arrhenius law is used when @xmath17 .",
    "we refer to @xcite for details .",
    "tad is a very popular technique , in particular for applications in material sciences ; see for example @xcite . in this article",
    "we provide a mathematical framework for tad , and in particular a mathematical formalism for ( h1)-(h2 ) .",
    "our analysis will actually concern a slightly modified version of tad . in this modified version , which we call _ modified tad _ , the dynamics is allowed to reach local equilibrium after entering a basin , thus circumventing assumption  ( h1 ) .",
    "the assumption ( h1 ) is closely related to the no recrossings assumption in transition state theory ; in particular one can see the local equilibration steps ( modifications ( m1 ) and ( m2 ) below ) in modified tad as a way to account for recrossings . we note that modified tad can be used in practice and , since it does not require the assumption ( h1 ) , may reduce some of the numerical error in ( the original ) tad .    to analyze modified tad ,",
    "we first make the notion of local equilibration precise by using _ quasistationary distributions _ , in the spirit of @xcite , and then we circumvent ( h2 ) by introducing an idealized extrapolation procedure which is _",
    "exact_. the result , which we call _ idealized tad _ , yields exact metastable dynamics ; see theorem  [ mainthm ] below .",
    "idealized tad is not a practical algorithm because it depends on quantities related to quasistationary distributions which can not be efficiently computed .",
    "however , we show that idealized tad agrees with modified tad at low temperature .",
    "in particular we justify ( h2 ) in modified tad by showing that at low temperature , the extrapolation procedure of idealized tad agrees with that of modified tad ( and of tad ) , which is based on the arrhenius law  ; see theorem  [ theorem2 ] below .    in this article , we focus on the overdamped langevin dynamics   for simplicity .",
    "the algorithm is more commonly used in practice with the langevin dynamics @xmath18 the notion of quasistationary distributions still makes sense for the langevin dynamics  @xcite , so an extension of our analysis to that dynamics is in principle possible , though the mathematics there are much more difficult due to the degeneracy of the infinitesimal generator of . in particular , some results on the low temperature asymptotics of the principal eigenvalue and eigenvector for hypoelliptic diffusions are still missing .    the paper is organized as follows . in section  [ sec : tad ] , we recall tad and present modified tad . in section  [ sec :",
    "idealtad ] , we introduce idealized tad and prove it is exact in terms of metastable dynamics . finally , in section  [ sec : theta ] , we show that idealized tad and modified tad are essentially equivalent in the low temperature regime .",
    "our analysis in section  [ sec : theta ] is restricted to a one - dimensional setting .",
    "the extension of this to higher dimensions will be the purpose of another work .    throughout the paper it will be convenient to refer to various objects related to the dynamics   at a high and low temperature , @xmath19 and @xmath20 , as well as at a generic temperature , @xmath21 .",
    "to do so , we use superscripts @xmath22 and @xmath23 to indicate that we are looking at the relevant object at @xmath24 or @xmath25 , respectively .",
    "we drop the superscripts to consider objects at a generic temperature  @xmath21 .",
    "let @xmath26 be a stochastic dynamics obeying   at a low temperature @xmath25 , and let @xmath27 be a function which labels the basins of @xmath9 .",
    "( so each basin @xmath10 has the form @xmath28 where @xmath29 . )",
    "the goal of tad is to efficiently estimate the metastable dynamics at low temperature ; in other words :    *   efficiently generate a trajectory @xmath30 which has approximately the same distribution as @xmath31 .",
    "the aim then is to get approximations of _ trajectories _ , including distributions of hitting times , time correlations , etc ... and thus not only the evolution of the averages of some observables or averages of observables with respect to the invariant distribution .    at the heart of tad",
    "is the problem of efficiently simulating an exit of @xmath26 from a generic basin @xmath10 , since the metastable dynamics are generated by essentially repeating this . to efficiently simulate an exit of @xmath26 from @xmath10",
    ", temperature is raised so that @xmath32 and a corresponding high temperature dynamics @xmath33 is evolved .",
    "the process @xmath33 is allowed to search for various exit paths out of @xmath10 until a stopping time @xmath34 ; each time @xmath33 reaches @xmath35 it is reflected back into @xmath10 , the place and time of the attempted exit is recorded , and the arrhenius law   is used to extrapolate a low temperature exit . after time @xmath34 the fastest extrapolated low temperature exit is selected .",
    "this exit is considered an approximation of the first exit of @xmath26 from @xmath10 .",
    "the original algorithm is described in section  [ originaltad ] below ; a modified version is proposed in section  [ modifiedtad ] below .      in the following ,",
    "we let @xmath10 denote a generic basin .",
    "we let @xmath36 be the minimum of @xmath9 inside @xmath10 , and we assume there are finitely many saddle points , @xmath37 ( @xmath38 ) , of @xmath9 on @xmath35 .",
    "the original tad algorithm @xcite for generating the approximate metastable dynamics @xmath39 is as follows :    [ alg1 ] let @xmath40 be in the basin @xmath10 , and start a low temperature simulation clock @xmath41 at zero : @xmath42 .",
    "then iterate on the visited basins the following :    1 .",
    "let @xmath43 and @xmath44 .",
    "these are the simulation and stopping times for the high temperature exit search .",
    "2 .   evolve @xmath45 at @xmath24 starting at @xmath46 until the first time after @xmath47 at which it exits @xmath10 .",
    "( exits are detected by checking if the dynamics lands into another basin via gradient descent , i.e. the deterministic dynamics @xmath48 . )",
    "call this time @xmath49 .",
    "3 .   associate a nearby saddle point , @xmath37 , of @xmath9 on @xmath35 to the place where @xmath45 exited  @xmath10 .",
    "( this can be done by using , for example , the nudged elastic band method @xcite ; see below . )",
    "advance the high temperature simulation clock by @xmath50 : @xmath51 .",
    "5 .   if an exit at @xmath37 has already been observed , go to step 8 .",
    "if an exit at @xmath37 has not yet been observed , set @xmath52 and extrapolate the high temperature exit time to low temperature using the formula : @xmath53 this equation comes from the arrhenius law   for exit rates in the low temperature regime ; see the remarks below",
    "update the smallest extrapolated exit time : @xmath54 and the ( index of ) the corresponding exit point : @xmath55 7 .",
    "update @xmath34 .",
    "the stopping time is chosen so that with confidence @xmath56 , an extrapolated low temperature exit time smaller than @xmath57 will not be observed .",
    "see equation   below for how this is done . 8 .   if @xmath58 , reflect @xmath33 back into @xmath10 and go back to step 2",
    "otherwise , proceed to step  9 .",
    "set @xmath59,\\ ] ] and advance the low temperature simulation clock by @xmath57 : @xmath60 10 . send @xmath33 to the new basin , namely the neighboring basin of @xmath10 which is attained through the saddle point @xmath61 . then , go back to step 1 , the domain @xmath10 now being the neighboring basin .",
    "the nudged elastic band method @xcite consists , starting from a trajectory leaving @xmath10 , of computing by a gradient descent method the closest minimum energy path leaving @xmath10 , with the end points of the trajectory being fixed .",
    "this minimum energy path necessarily leaves @xmath10 through a saddle point .",
    "when the overdamped langevin dynamics leaves a basin near a saddle point , its first re - entrance into that basin is immediate .",
    "thus , algorithm  [ alg1 ] does not really make sense for overdamped langevin dynamics .",
    "( with the langevin dynamics  , however , this difficulty does not arise . ) in modified tad , defined below , we will allow the dynamics to evolve away from the boundary of a basin after an exit event , thus circumventing this problem .",
    "below we comment on the equation   from which low temperature exit times are extrapolated , as well as the stopping time @xmath34 .",
    "* * low temperature extrapolation*. + the original tad uses the following kinetic monte carlo ( kmc ) framework  @xcite . for a given basin @xmath10",
    ", it is assumed that the time @xmath62 to exit through the saddle point @xmath37 of @xmath9 on @xmath35 is exponentially distributed with rate @xmath63 given by the arrhenius law  : @xmath64 where we recall @xmath65 is a temperature independent prefactor and @xmath36 is the minimum of @xmath9 in @xmath10 .",
    "an exit event from @xmath10 at temperature @xmath21 is obtained by sampling independently the times @xmath62 for all the saddle points @xmath37 on @xmath35 , then selecting the smallest time and the corresponding saddle point . + in tad , this kmc framework is used for both temperatures @xmath20 and @xmath19 .",
    "that is , it is assumed that the high and low temperature exit times @xmath66 and @xmath67 through each saddle point @xmath37 satisfy : @xmath68 where @xmath69 observe that then @xmath70 has the same probability law as @xmath67 .",
    "this leads to the extrapolation formula  .",
    "+ the assumption of exponentially distributed exit times @xmath71 and @xmath72 is valid only if the dynamics at both temperatures immediately reach local equilibrium upon entering a basin ; see ( h1 ) and theorem  [ theorem0a ] below . in modified tad , described below",
    ", we circumvent this immediate equilibration assumption by allowing the dynamics at both temperatures to reach local equilibrium .",
    "in particular , in modified tad the low temperature assumption is no longer needed to get exponential exit distributions as in  . on the other hand , to get the _ rate constants _ in    and by extension the extrapolation rule  ; see ( h2 )  a low temperature assumption is required .",
    "we will justify both   and   in the context of modified tad .",
    "more precisely we show that   will be valid at any temperature , while a low temperature assumption is needed to justify  .",
    "note that , inspecting equation  , the low temperature assumption will be required for _ both _",
    "temperatures used in tad ",
    "so @xmath73 will be small in an absolute sense , but large compared to @xmath74 . * * stopping time . *",
    "+ the stopping time @xmath34 is chosen so that if the high temperature exit search is stopped at time @xmath34 , then with probability @xmath56 , the smallest extrapolated low temperature exit time will be correct . here",
    "@xmath75 is a user - specified parameter .",
    "+ to obtain a formula for the stopping time @xmath34 it is assumed that , in addition to ( h1)-(h2 ) : * * there is a minimum , @xmath76 , to all the prefactors in equation  : @xmath77 + where @xmath78 denotes the number of saddle points on @xmath35 . + let us now explain how this assumption is used to determine @xmath34 .",
    "let @xmath79 be a deterministic time .",
    "if a high temperature first exit time through @xmath37 , @xmath80 , extrapolates to a low temperature time less than @xmath57 , then from  , @xmath81 and so @xmath82 in tad it is required that this event has a low probability @xmath75 of occurring , that is , @xmath83 using   in  , one sees that it suffices that @xmath84 < \\delta.\\ ] ] solving this inequality for @xmath79 , one obtains @xmath85 the stopping time @xmath34 is then chosen to be the right hand side of the above : @xmath86 ( it is calculated using the current value of @xmath57 . ) the above calculation shows that at simulation time @xmath34 , with probability at least @xmath56 , @xmath57 is the same as the smallest extrapolated low temperature exit time which would have been observed with no stopping criterion . + for tad to be practical , the stopping time @xmath34 must be ( on average ) smaller than the exit times at low temperature . the stopping time of course depends on the choice of @xmath76 and @xmath75 .",
    "in practice a reasonable value for @xmath76 may be known a priori @xcite or obtained by a crude approximation @xcite . for a given @xmath75 ,",
    "if too large a value of @xmath76 is used , the low temperature extrapolated times may be incorrect with probability greater than @xmath75 .",
    "on the other hand , if the value of @xmath76 is too small , then the extrapolated times will be correct with probability @xmath56 , but computational efficiency will be compromised .",
    "the usefulness of tad comes from the fact that , in practice , @xmath76 and @xmath75 can often be chosen such that the correct low temperature exit event is found by time @xmath34 with large probability @xmath56 , _ and _ @xmath34 is on average much smaller than the exit times which would be expected at low temperature . in practical applications ,",
    "tad has provided simulation time scale boosts of up to @xmath87  @xcite .",
    "one alternative to tad is a brute force saddle point search method , in which one evolves the system at a high temperature @xmath19 to locate saddle points of @xmath9 on @xmath35 .",
    "( there are other popular techniques in the literature to locate saddle points , many of which do not use high temperature or dynamics ; see for example  @xcite . )",
    "once one is confident that all the physically relevant saddle points are found , the times @xmath67 to exit through each @xmath37 at low temperature can be directly sampled from exponential distributions with parameters @xmath63 as in  , using @xmath88 .",
    "( estimates are available for the @xmath65 at low temperature ; they depend on the values of @xmath9 and the hessian matrix of @xmath9 at @xmath37 and @xmath36 .",
    "see for example @xcite . )",
    "the advantage of tad over a brute force saddle point search method is that in tad , there is a well - defined stopping criterion for the saddle point search at temperature @xmath19 , in the sense that the saddle point corresponding to the correct exit event at temperature @xmath20 will be obtained with a user - specified probability . in particular",
    ", tad does not require all the saddle points to be found .",
    "below we consider some modifications , ( m1)-(m3 ) , to tad , calling the result _ modified tad_. the main modifications , ( m1)-(m2 ) below , will ensure that the exponential rates assumed in tad are justified .",
    "we also introduce a different stopping time , ( m3 ) .",
    "( see the discussion below algorithm  [ alg2 ] . )",
    "we note that some of these features are currently being used by practitioners of tad  @xcite . here",
    "are the three modifications :    * we include a decorrelation step in which an underlying low temperature dynamics @xmath89 finds local equilibrium in some basin @xmath10 before we start searching for exit pathways at high temperature ; * before searching for exit pathways out of @xmath10 , we sample local equilibrium at high temperature in the current basin @xmath10 , without advancing any clock time ; * we replace the stopping time   with @xmath90 where @xmath91 is a lower bound of the minimum of @xmath92 over all the saddle points , @xmath37 , of @xmath9 on @xmath35 .    in ( m3 )",
    "above we are assuming some a priori knowledge of the system , in particular a lower bound of the energy barriers @xmath93 , @xmath94 .",
    "such a lower bound will not be known in every situation , but in some cases , practitioners can obtain such a bound , see for example  @xcite .",
    "see also the discussion in the section `` stopping time '' below .",
    "the modified algorithm is as follows ; for the reader s convenience we have boxed off the steps of modified tad which are different from tad .    [ alg2 ]",
    "let @xmath95 be in the basin @xmath10 , set a low temperature simulation clock @xmath41 to zero : @xmath42 , and choose a ( basin - dependent ) decorrelation time @xmath96 .",
    "then iterate on the visited basins the following :    [ html]e9f0e9    1 .",
    "* exit step : *    [ html]e9f0e9    1 .",
    "evolve @xmath45 at @xmath24 starting at @xmath46 until the first time after @xmath47 at which it exits @xmath10 .",
    "call this time @xmath49 .",
    "2 .   using the nudged elastic band method ,",
    "associate a nearby saddle point , @xmath37 , of @xmath9 on @xmath35 to the place where @xmath45 exited @xmath10 .",
    "3 .   advance the simulation clock by @xmath50 : @xmath51 .",
    "4 .   if an exit at @xmath37 has already been observed , go to step 8 . if an exit at @xmath37 has not yet been observed , set @xmath52 and @xmath97 5 .",
    "update the lowest extrapolated exit time : @xmath54 and the ( index of ) the corresponding exit point : @xmath55    [ html]e9f0e9    1 .",
    "set @xmath59,\\ ] ] and advance the low temperature simulation clock by @xmath57 : @xmath60    [ html]e9f0e9    * * local equilibrium in @xmath10 : ( m1 ) and ( m2 ) . * + we introduce the decorrelation step ",
    "see ( m1 )  in order to ensure that the low temperature dynamics reaches local equilibrium in @xmath10 . indeed , for sufficiently large",
    "@xmath98 the low temperature dynamics reaches local equilibrium in some basin .",
    "the convergence to local equilibrium will be made precise in section  [ sec : idealtad ] using the notion of the _ quasistationary distribution_. see also  @xcite , in particular for a discussion of the choice of @xmath98 .",
    "local equilibrium will in general be reached at different times in different basins , so we allow @xmath98 to be basin dependent .",
    "we note that a similar decorrelation step is used in another accelerated dynamics proposed by a.f .",
    "voter , the parallel replica dynamics  @xcite .",
    "the decorrelation step accounts for barrier recrossing events : the dynamics is allowed to evolve exactly at low temperature after the exit step , capturing any possible barrier recrossings , until local equilibrium is reached in one of the basins . +",
    "the counterpart of the addition of this decorrelation step is that , from ( m2 ) , in the exit step we also start the high temperature dynamics from local equilibrium in the current basin @xmath10 .",
    "a similar step is actually being used by current practitioners of tad  @xcite , though this step is not mentioned in the original algorithm  @xcite . to sample local equilibrium in @xmath10 , one can for example take the end position of a a sufficiently long trajectory of   which does not exit @xmath10 .",
    "see @xcite for some algorithms to efficiently sample local equilibrium ; we remark that this is expected to become more computationally demanding as temperature increases .",
    "+ to extrapolate the exit event at low temperature from the exit events at high temperature , we need the dynamics at both temperatures to be in local equilibrium .",
    "we note that the changes ( m1)-(m2 ) in modified tad are actually a practical way to get rid of the error associated with the assumption ( h1 ) in tad . * * stopping time : ( m3 ) . *",
    "+ in ( m3 ) we introduce a stopping @xmath34 such that , with probability @xmath99 , the shortest extrapolated low temperature exit time is found by time @xmath34 .",
    "( recall that with the stopping time of tad , we have only a confidence level @xmath56 . ) + note that for the stopping time @xmath34 to be implemented in  , we need some a priori knowledge about energy barriers , in particular a lower bound @xmath100 for all the differences @xmath93 , where @xmath37 ranges over the saddle points on the boundary of a given basin : * * there is a minimum , @xmath101 , to all the energy barriers : @xmath102 + if a lower bound @xmath101 is known , then we can choose @xmath91 accordingly so that in equation   we obtain @xmath103 a simple computation then shows that under assumption ( h3 ) , any high temperature exit time occurring after @xmath34 can not extrapolate to a low temperature exit time smaller than @xmath57 . to see that   leads to an efficient algorithm , recall that tad is expected to be correct only in the regime where @xmath104 , which since @xmath105 means the exponential in   should be very small .",
    "+ as the computational savings of tad comes from the fact that the simulation time of the exit step , namely @xmath34 , is much smaller than the exit time that would have been observed at low temperature , the choice of stopping time in tad is of critical importance .",
    "both of the stopping times   and   are used in practice ; see @xcite for a presentation of tad with the stopping formula  , and @xcite for an application .",
    "the original stopping time   requires a lower bound for the prefactors in the arrhenius law   ( see assumption ( h3 ) above , in the remarks following algorithm  [ alg1 ] ) .",
    "the stopping time   requires an assumption on the minimum energy barriers ; see assumption ( h3 ) above .",
    "the formula   may be preferable in case minimum energy barriers are known , since it is known to scale better with system size than .",
    "the formula   is advantageous if minimum energy barriers are unknown but a reasonable lower bound for the minimum prefactor @xmath76 is available .",
    "+ we have chosen the stopping time   instead of   mostly for mathematical convenience  in particular so that in our section  [ sec : idealtad ] analysis we do not have the error @xmath75 associated with  .",
    "a similar analysis can be done under assumption ( h3 ) with the stopping time  , modulo the error @xmath75 .",
    "we comment that modified tad is an algorithm which can be implemented in practice , and which circumvents the error in the original tad arising from the assumption ( h1 ) .",
    "in this section we show that under certain idealizing assumptions , namely ( i1)-(i3 ) and ( a1 ) below , modified tad is _ exact _ in the sense that the simulated metastable dynamics @xmath30 has the same law as the true low temperature metastable dynamics @xmath31 .",
    "we call this idealization of modified tad _ idealized tad_. our analysis will show that idealized tad and modified tad agree in the limit @xmath106 and @xmath107 .",
    "since idealized tad is exact , it follows that modified tad is exact in the limit @xmath106 and @xmath107 .    in idealized tad , we assume that at the end of the decorrelation step and at the start of the exit step of modified tad , we are in _ exact _ local equilibrium ; see ( a1 ) and ( i1 ) .",
    "we formalize this using the notion of quasistationary distributions , defined below .",
    "we also assume that the way in which we exit near a given saddle point @xmath37 in the exit step does not affect the metastable dynamics in the decorrelation step ; see ( i2 ) .",
    "the remaining idealization , whose relation to modified tad is maybe not so clear at first sight , is to replace the exponential @xmath108 $ ] of   with a certain quantity @xmath109 depending on the flux of the quasistationary distribution across @xmath35 ; see  ( i3 ) . in section  [ sec : theta ]",
    "we justify this by showing that the two agree asymptotically as @xmath106 in a one - dimensional setting .      here and throughout , @xmath10 is an ( open ) domain with @xmath110 boundary @xmath35 and @xmath111 is a stochastic process evolving according to   starting at @xmath112 ( we suppress the superscript where it is not needed ) .",
    "we write @xmath113 and @xmath114 $ ] for various probabilities and expectations , the meaning of which will be clear from context . we write @xmath115 for a random variable sampled from the probability measure @xmath116 and @xmath117 for an exponentially distributed random variable with parameter @xmath118 .    recalling the notation of section  [ sec : tad ] , we assume that @xmath35 is partitioned into @xmath78 ( lebesgue measurable ) subsets @xmath119 containing the saddle points @xmath37 of @xmath9 , @xmath120 ( see fig  [ fig1 ] ) : @xmath121 we assume that any exit through @xmath119 is associated to the saddle point @xmath37 in step 3 of tad . in other words , @xmath119 corresponds to the basin of attraction of the saddle point @xmath37 for the nudged elastic band method .     with boundary partitioned into @xmath122 ( here @xmath123 ) by the black line segments .",
    "@xmath9 has exactly one saddle point in each @xmath119 , located at @xmath37 . ]",
    "essential to the analysis below will be the notion of _ quasistationary distribution _ , which we define below , recalling some facts which will be needed in our analysis .",
    "consider the infinitesimal generator of  : @xmath124 and let @xmath125 be the principal eigenvector / eigenvalue pair for @xmath126 with homogeneous dirichlet ( absorbing ) boundary conditions on @xmath35 : @xmath127 it is known ( see @xcite ) that @xmath128 is signed and @xmath129 ; we choose @xmath130 and for the moment do not specify a normalization .",
    "define a probability measure @xmath16 on @xmath10 by @xmath131 the measure @xmath16 is called the _ quasistationary distribution _ ( qsd ) on @xmath10 ; the name comes from the fact that @xmath16 has the following property : for @xmath132 a solution to  , starting from any distribution with support in @xmath10 , @xmath133 the following is proved in @xcite , and will be essential for our results :    [ theorem0a ] let @xmath0 be a solution to   with @xmath134 , and let @xmath135 then : ( i ) @xmath136 and ( ii ) @xmath50 and @xmath137 are independent .",
    "we will also need the following formula from @xcite for the exit point distribution :    [ theorem0b ] let @xmath0 and @xmath50 be as in theorem  [ theorem0a ] , and let @xmath138 be lebesgue measure on @xmath35 .",
    "the measure @xmath139 on @xmath35 defined by @xmath140 is a probability measure , and for any measurable @xmath141 , @xmath142    as a corollary of these two results we have the following , which will be central to our analysis :    [ corollary1 ] let @xmath0 , @xmath50 and @xmath139 be as in theorems  [ theorem0a]-[theorem0b ] , and define @xmath143 to be the exit probability through @xmath119 .",
    "let @xmath144 be the discrete random variable defined by : for @xmath145 , @xmath146 then ( i ) @xmath136 , ( ii ) @xmath147 , and ( iii ) @xmath50 and @xmath144 are independent .",
    "throughout we omit the dependence of @xmath148 , @xmath16 , and @xmath139 on the basin @xmath10 ; it should be understood from context .",
    "we assume that @xmath10 has @xmath110 boundary so that standard elliptic regularity results and trace theorems give a meaning to the formula   used to define @xmath139 in theorem  [ theorem0b ] .",
    "for basins of attraction this assumption will not be satisfied , as the basins will have `` corners '' .",
    "this is actually a minor technical point .",
    "the probability measure @xmath139 can be defined for any lipschitz domain @xmath10 using the following two steps : first , @xmath139 can be defined in @xmath149 using the definition ( equivalent to  ): for any @xmath150 @xmath151 where @xmath152 is any lifting of @xmath153 ( @xmath154 ) .",
    "second , it is easy to check that @xmath139 actually defines a _ non - negative _ distribution on @xmath35 , for example by using as a lifting the solution to @xmath155 since , by the maximum principle , @xmath156 , and then , @xmath157 .",
    "one finally concludes using a riesz representation theorem due to schwartz : any non - negative distribution with total mass one defines a probability measure .      in this section",
    "we consider an idealized version of modified tad , which we call _",
    "idealized tad_. the idealizations , ( i1)-(i3 ) below , are introduced so that the algorithm can be rigorously analyzed using the mathematical formalisms in section  [ section2b ] .",
    "* at the start of the exit step , the high temperature dynamics is initially distributed according to the qsd in @xmath10 : @xmath158 ; * at the end of the exit step , the extrapolated low temperature exit point @xmath159 is sampled exactly from the conditional exit point distribution in @xmath160 at low temperature : @xmath161^{-1 } \\rho^{lo}|_{\\partial d_{i_{min}^{lo}}}\\ ] ] * in the exit step , the quantity @xmath162 is everywhere replaced by @xmath163 where , as in  , @xmath164 and @xmath165 .",
    "thus , the extrapolation equation   is replaced by @xmath166 and the formula for updating @xmath34 is : @xmath167 where @xmath91 is chosen so that @xmath168 .",
    "we state idealized tad below as an `` algorithm '' , even though it is not practical : in general we can not exactly sample @xmath169 or the exit distributions @xmath170^{-1 } \\rho^{lo}|_{\\partial d_{i}^{lo}}$ ] , and the quantities @xmath109 are not known in practice .",
    "( see the discussion below algorithm  [ alg3 ] . )    for the reader s convenience we put in boxes those steps of idealized tad which are different from modified tad .",
    "[ alg3 ] let @xmath95 be in the basin @xmath10 , set the low temperature clock time to zero : @xmath171 , let @xmath96 be a ( basin - dependent ) decorrelation time , and iterate on the visited basins the following :    1 .",
    "* decorrelation step : * 2 .",
    "starting at time @xmath172 , evolve @xmath26 at temperature @xmath25 according to   in the current basin @xmath10 .",
    "if @xmath26 exits @xmath10 at a time @xmath173 , then set @xmath174,\\ ] ] advance the low temperature clock by @xmath50 : @xmath175 , then go back to step 1 , where @xmath10 is now the new basin . otherwise , set @xmath176,\\ ] ] advance the low temperature clock by @xmath98 : @xmath177 , and initialize the exit step by setting @xmath43 and @xmath44 .",
    "then proceed to the exit step .    1",
    ".   * exit step : *    [ html]e9f0e9    1 .",
    "evolve @xmath33 at @xmath24 starting at @xmath46 until the first time after @xmath47 at which it exits @xmath10 .",
    "call this time @xmath49 .",
    "2 .   record the set @xmath119 through which @xmath33 exited @xmath10 .",
    "3 .   advance the simulation clock by @xmath50 : @xmath51 .",
    "[ html]e9f0e9    1 .",
    "update the lowest extrapolated exit time and corresponding exit spot : @xmath178    [ html]e9f0e9    1 .   if @xmath58 , go back to step 1 of the exit step ;",
    "otherwise , proceed to step 9 .    1 .",
    "set @xmath59,\\ ] ] and advance the low temperature simulation clock by @xmath57 : @xmath60    [ html]e9f0e9    below we comment in more detail on idealized tad .    * * the quasistationary distribution in @xmath10 : ( i1 ) and ( a1 ) . *",
    "+ in idealized tad , the convergence to local equilibrium ( see ( m1 ) and ( m2 ) above ) is assumed to be reached , and this is made precise using the qsd @xmath16 .",
    "in particular , we start the high temperature exit search exactly at the qsd @xmath169 ; see ( i1 ) .",
    "we will also assume the low temperature dynamics reaches @xmath179 at the end of the decorrelation step : * * after the decorrelation step of idealized tad , the low temperature dynamics is distributed according to the qsd in @xmath10 : @xmath180 .",
    "+ this will be crucial for extrapolating the exit event at low temperature .",
    "assumption ( a1 ) is justified by the fact that the law of @xmath26 in the decorrelation step approaches @xmath179 exponentially fast in @xmath98 ; see @xcite for details .",
    "we also refer to  @xcite for a presentation of algorithms which can be used to sample the qsd . *",
    "* the exit position : ( i2 ) . * + to get exact metastable dynamics , we have to assume that the way the dynamics leaves @xmath10 near a given saddle point @xmath37 does not affect the metastable dynamics in the decorrelation step ; see ( i2 ) .",
    "this can be justified in the small temperature regime by using theorem  [ theorem0b ] and some exponential decay results on the normal derivative of the qsd away from saddle points .",
    "indeed , the conditional probability that , given the dynamics leaves through @xmath119 , it leaves outside a neighborhood of @xmath37 is of order @xmath181 as @xmath182 ( for a constant @xmath183 ) ; see @xcite . * * replacing the arrhenius law extrapolation rule : ( i3 ) . *",
    "+ in idealized tad , we replace the extrapolation formula   based on the arrhenius law by the idealized formulas  -  ; see ( i3 ) .",
    "this is a severe modification , since it makes the algorithm impractical .",
    "in particular the quantities @xmath184 and @xmath185 are not known : if they were , it would be very easy to simulate the exit event from  @xmath10 ; see corollary  [ corollary1 ] above . + it is the aim of section  [ sec : theta ] below to explain how the small temperature assumption is used to get practical estimates of the ratios @xmath109 .",
    "for simplicity we perform this small temperature analysis in one dimension .",
    "we will show that @xmath109 is indeed close to the formula @xmath108 $ ] used in the original and modified tad ; compare   with   and  .",
    "we expect the same relation to be true in higher dimensions under appropriate conditions ; this will be the subject of another paper .    in the analysis below",
    ", we need idealizations ( i1 ) and ( i3 ) to exactly replicate the law of the low temperature exit time and exit region in the exit step ; see theorem  [ theorem1 ] below . with ( i1 ) and",
    "( i3 ) , the inferred low temperature exit events are statistically exact . this",
    "is based in particular on ( a1 ) , namely the fact that the low temperature process is distributed according to @xmath179 at the end of the decorrelation step .",
    "in addition , after an exit event , the dynamics in the next decorrelation step depends on the exact exit _ point _ in @xmath119 : this is why we also need ( i2 ) to get exact metastable dynamics ; see theorem  [ mainthm ] below .",
    "the aim of this section is to prove the following result :    [ mainthm ] let @xmath26 evolve according to   at @xmath25 .",
    "let @xmath186 be the metastable dynamics produced by algorithm  [ alg3 ] ( idealized tad ) , assuming ( a1 ) , and let idealized tad have the same initial condition as @xmath26 .",
    "then : @xmath187 that is , the metastable dynamics produced by idealized tad has the same law as the ( exact ) low temperature metastable dynamics .    due to corollary  [ corollary1 ] , ( a1 ) ,",
    "( i2 ) , and the fact that the low temperature dynamics is simulated exactly during the decorrelation step , it suffices to prove that the exit step of idealized tad is exact in the following sense :    [ theorem1 ] let @xmath26 evolve according to   at @xmath25 with @xmath26 initially distributed according to the qsd in @xmath10 : @xmath188 .",
    "let @xmath189 and @xmath144 be the discrete random variable defined by : for @xmath120 , @xmath190 let @xmath57 and @xmath191 be the random variables produced by the exit step of idealized tad .",
    "then , @xmath192 has the same probability law as @xmath193 : @xmath194    the proof of theorem  [ theorem1 ] will use ( i1 ) and ( i3 ) in particular .",
    "the theorem shows that the exit event from @xmath10 produced by idealized tad is exact in law compared to the exit event that would have occurred at low temperature : the random variable @xmath195 associated with idealized tad has the same law as the first exit time and location ( from @xmath10 ) of a dynamics @xmath196 obeying   with @xmath197 and @xmath188 .",
    "to begin , we provide a simple lemma which shows that we can assume @xmath198 without loss of generality .",
    "we need this result in order to properly define all the random variables @xmath199 , for @xmath200 , where we recall @xmath78 denotes the number of saddle points of @xmath9 on @xmath35 .",
    "[ lem : tstop ] consider the exit step of the idealized tad , and modify step 8 as follows :    * _ go back to step 1 of the exit step .",
    "_    thus we loop between step 1 and step 8 of the exit step for infinite time , regardless of the values of @xmath47 and @xmath34 . then , @xmath201 remains constant for all times @xmath202 .",
    "we want to show that without ever advancing to step 10 , the exit step of idealized tad produces the same random variable @xmath192 as soon as @xmath202 . to see this , note that if @xmath203 , then from  , @xmath204 and so , comparing with  , @xmath205 thus , if @xmath202 , any escape event will lead to an extrapolated time @xmath72 which will be larger than @xmath57 , and thus will not change the value of @xmath57 anymore .",
    "let us now identify the laws of the random variables @xmath206 produced by idealized tad .",
    "[ prop : thi ] consider idealized tad in the setting of lemma  [ lem : tstop ] , so that all the @xmath199 are defined , @xmath207 .",
    "let @xmath208 be independent and identically distributed random variables such that @xmath209 is independent from @xmath210 , @xmath211 and for @xmath120 , @xmath210 is a discrete random variable with law @xmath212 for @xmath120 define @xmath213 then we have the following equality in law : @xmath214 moreover , ( i ) @xmath215 and ( ii ) @xmath216 are independent .",
    "the equality   follows from corollary  [ corollary1 ] , since in the exit step of idealized tad , the dynamics restarts from the qsd @xmath169 after each escape event .",
    "let us now consider the statement @xmath217 .",
    "observe that the moment generating function of an exponential random variable @xmath50 with parameter @xmath148 is : for @xmath218 , @xmath219 = \\int_{0}^\\infty e^{st}\\lambda e^{-\\lambda t}\\,dt = \\frac{\\lambda}{\\lambda - s}.\\ ] ] so , dropping the superscript @xmath220 for ease of notation , we have : for @xmath221 , and for @xmath222 , @xmath223 & = \\sum_{m=1}^\\infty{\\mathbb e}\\left[\\exp\\left(s t_i\\right)\\big| n_i = m\\right]{\\mathbb p}\\left(n_i = m\\right ) \\\\ & = \\sum_{m=1}^\\infty { \\mathbb e}\\left[\\exp\\left(s \\sum_{j=1}^{m}\\tau^{(j)}\\right)\\right](1-p_i)^{m-1}p_i\\\\ & = \\sum_{m=1}^\\infty { \\mathbb e}\\left[\\exp\\left(s \\tau^{(1)}\\right)\\right]^m(1-p_i)^{m-1}p_i\\\\ & = \\frac{\\lambda p_i}{\\lambda - s}\\sum_{m=1}^\\infty \\left(\\frac{\\lambda\\left(1 -   p_i\\right)}{\\lambda - s}\\right)^{m-1}\\\\ & = \\frac{\\lambda p_i}{\\lambda p_i - s}.\\end{aligned}\\ ] ] this shows @xmath215 .    before turning to the proof of the statement @xmath224 in proposition  [ prop : thi ] , we need the following technical lemma :    [ lemmasym ] let @xmath225 be positive real numbers , and let @xmath226 be the symmetric group on @xmath227 . then @xmath228    note that   is of course true for @xmath229 .",
    "assume it is true for @xmath230 , and let @xmath231 then @xmath232 by induction   is valid for all @xmath233 .",
    "we are now in position to prove statement @xmath224 of proposition  [ prop : thi ] .    in this proof",
    ", we drop the superscript @xmath220 for ease of notation . to show that the @xmath234 s are independent , it suffices to show that for @xmath235 in a neighborhood of zero we have @xmath236 = \\prod_{i=1}^k { \\mathbb e}\\left[\\exp\\left(s_i t_i\\right)\\right].\\ ] ] we saw in the proof of part @xmath217 that : for @xmath237 , @xmath238 = \\frac{\\lambda p_i}{\\lambda p_i -s_i}.\\ ] ] consider then the left - hand - side of  .",
    "we start by a preliminary computation .",
    "let @xmath239 , @xmath240 , and @xmath237 for @xmath120 .",
    "then @xmath241{\\mathbb p}\\left(\\cap_{i=1}^k \\{n_i = m_i\\}\\right ) \\nonumber \\\\ & = \\sum_{1<m_2<m_3\\ldots < m_k } { \\mathbb e}\\left[\\exp\\left(\\sum_{i=1}^k \\left(s_i \\sum_{j=1}^{m_i}\\tau^{(j)}\\right)\\right)\\right ] p_1 \\prod_{i=2}^k p_i\\left(1-\\sum_{j = i}^k p_j\\right)^{m_i - m_{i-1}-1}\\nonumber\\\\ & = p_1\\sum_{1<m_2<m_3\\ldots < m_k}\\,\\prod_{i=1}^k   { \\mathbb e}\\left[\\exp\\left(\\left(\\sum_{j = i}^k s_j\\right)\\sum_{j = m_{i-1}+1}^{m_i}\\tau^{(j)}\\right)\\right]\\prod_{i=2}^k p_i\\left(1-\\sum_{j = i}^k p_j\\right)^{m_i - m_{i-1}-1 } \\nonumber\\\\ & = p_1 \\sum_{1<m_2<m_3\\ldots < m_k}\\,\\prod_{i=1}^k { \\mathbb e}\\left[\\exp\\left(\\tau^{(1)}\\sum_{j = i}^k s_j\\right)\\right]^{m_i - m_{i-1}}\\prod_{i=2}^k p_i\\left(1-\\sum_{j = i}^k p_j\\right)^{m_i - m_{i-1}-1 } \\nonumber\\\\ & = \\left(\\frac{\\lambda p_1}{\\lambda - \\sum_{j=1}^k s_j}\\right ) \\sum_{1<m_2<m_3\\ldots <",
    "m_k}\\,\\prod_{i=2}^k p_i \\left(\\frac{\\lambda}{\\lambda - \\sum_{j = i}^k s_j}\\right)\\left(\\frac{\\lambda\\left(1-\\sum_{j = i}^k p_j\\right)}{\\lambda - \\sum_{j = i}^k s_j}\\right)^{m_i - m_{i-1}-1}\\nonumber\\\\ & = \\left(\\frac{\\lambda p_1}{\\lambda - \\sum_{j=1}^k s_j}\\right)\\prod_{i=2}^k p_i \\left(\\frac{\\lambda}{\\lambda - \\sum_{j = i}^k s_j}\\right )   \\left(1-\\frac{\\lambda\\left(1 - \\sum_{j = i}^k p_j\\right)}{\\lambda - \\sum_{j = i}^k s_j}\\right)^{-1 } \\nonumber\\\\ & = \\left(\\frac{\\lambda p_1}{\\lambda - \\sum_{j=1}^k s_j}\\right)\\prod_{i=2}^k \\lambda p_i \\left(\\sum_{j = i}^k \\lambda p_j - s_j\\right)^{-1}\\nonumber\\\\ & = \\prod_{i=1}^k \\lambda p_i \\left ( \\sum_{j = i}^k \\lambda p_j - s_j\\right)^{-1}. \\nonumber\\\\ \\label{long}\\end{aligned}\\ ] ] from   observe that @xmath242   & = \\sum_{\\sigma \\in s_k}\\prod_{i=1}^k \\lambda p_{\\sigma(i ) } \\left ( \\sum_{j = i}^k \\lambda p_{\\sigma(j ) } - s_{\\sigma(j)}\\right)^{-1}\\\\ & = { \\left(\\prod_{i=1}^k \\lambda p_i\\right ) } \\sum_{\\sigma \\in s_k}\\prod_{i=1}^k \\left ( \\sum_{j = i}^k \\lambda p_{\\sigma(j ) } - s_{\\sigma(j)}\\right)^{-1}\\\\ & = \\prod_{i=1}^k \\frac{\\lambda p_i}{\\lambda p_{i } - s_{i } } , \\end{split}\\end{aligned}\\ ] ] where in the last step we have used lemma  [ lemmasym ] .",
    "comparing   with   and  , we are done .    to complete the proof of theorem  [ theorem1 ]",
    ", we finally need the following lemma .",
    "[ lemma2 ] let @xmath243 be independent random variables such that @xmath244 , with @xmath129 , @xmath245 and @xmath246 .",
    "set @xmath247 then : ( i ) @xmath248 , ( ii ) @xmath249 , and ( iii ) @xmath79 and @xmath144 are independent .",
    "since the @xmath234 s are assumed to be independent , it is well known that @xmath250 is an exponential random variable with parameter @xmath251 .",
    "this proves @xmath217 . turning to @xmath224 and @xmath252 , note that @xmath253 is an exponential random variable independent of @xmath234 with parameter @xmath254 thus , @xmath255",
    "setting @xmath256 we obtain @xmath249 , which proves @xmath224 .",
    "now @xmath252 follows from  .",
    "we are now in position to prove theorem  [ theorem1 ] .",
    "first , by lemma  [ lem : tstop ] , we can assume that @xmath257 so that all the @xmath71 s are well defined , for @xmath258 .",
    "then proposition  [ prop : thi ] implies that the @xmath71 s are independent exponential random variables with parameters @xmath259 .",
    "so by  , the @xmath72 s are independent exponential random variables with parameters @xmath260 . now by applying lemma  [ lemma2 ] to the @xmath72 s , we get @xmath261 , @xmath262 , and @xmath57 is independent of @xmath191 .",
    "referring to corollary  [ corollary1 ] , we are done .",
    "observe that the proof of theorem  [ theorem1 ] does not use ( i2 ) , which is needed only to obtain correct metastable dynamics by iterating the exit step .",
    "also , notice that we did not use the fact that @xmath10 is the basin of attraction of a local minimum of @xmath9 or that each set @xmath119 in the partition of @xmath35 is associated to a saddle point @xmath37 for the moment .",
    "the latter assumption is crucial in the next section , in which we obtain computable estimates of the ratios @xmath109 , @xmath120 ; this will also require an assumption of large @xmath21 which was not needed for theorem  [ theorem1 ] .",
    "in the last section we showed that modified tad ( algorithm  [ alg2 ] ) is _ exact _ with the idealizations ( i1)-(i3 ) and the assumption ( a1 ) ; see idealized tad ( algorithm  [ alg3 ] ) . in this section",
    "we justify ( i3 ) . in particular , we show in theorem  [ theorem2 ] below how the ratios @xmath109 ( see  ) can be approximated by explicit practical formulas in one dimension . compared to theorem  [ theorem1 ] ,",
    "the proof of theorem  [ theorem2 ] will require the additional assumption that temperature is sufficiently small .",
    "we recall that the ratios @xmath109 , @xmath120 are unknown in practice . in tad these ratios are approximated using the arrhenius law .",
    "the main result of this section , theorem  [ theorem2 ] , gives precise asymptotics for @xmath109 as @xmath263 .",
    "in particular , we show that @xmath109 converges to @xmath108 $ ] .    throughout this section",
    "we assume that we are _ in a one dimensional setting_. moreover , we assume that @xmath10 is the basin of attraction of the gradient dynamics @xmath264 associated to a local minimum of @xmath9 ( this is what is done in practice by a.f .",
    "voter and co - workers ) . finally , the potential @xmath9 is assumed to be a morse function , which means that the critical points of @xmath9 are non - degenerate . under these assumptions",
    ", we may assume without additional loss of generality that ( see figure  [ fig2 ] ) :    * @xmath265 , with @xmath266 , @xmath267 , and @xmath268 for @xmath269 , * @xmath270 and @xmath271 , @xmath272 , * @xmath273 and @xmath274 .",
    "we also normalize @xmath128 ( see  ) so that    * @xmath275 .",
    "in particular , the location of the minimum of @xmath9 and the value of @xmath9 at @xmath276 are chosen for notational convenience and without loss of generality . in the following , we write @xmath277 and @xmath278 .     satisfying ( b1)-(b3 ) . ]",
    "we will prove the following :    [ theorem2 ] under the assumptions stated above , we have the formula : for @xmath279 , @xmath280 as @xmath106 , @xmath281 where @xmath282 , @xmath283 and @xmath284 , and @xmath285 is constant .",
    "the ratios @xmath286 involve integrals of the form @xmath287 at high and low temperature .",
    "we will use laplace expansions to analyze the integrals , but since @xmath128 depends on @xmath21 , extra care must be taken in the analysis .      in all what follows , @xmath125 denotes the principal eigenvector / eigenvalue pair of @xmath126 with homogeneous dirichlet boundary conditions ; see  .",
    "we are interested in how the pair @xmath125 varies in the small temperature regime @xmath182 .    throughout this section ,",
    "we write @xmath288 to denote a _ positive _ constant , the value of which may change without being explicitly noted . to begin , we will need some asymptotics for @xmath148 and @xmath128 , lemma  [ lemma4 ] and lemma  [ lemma5 ] below .",
    "the contents of both lemmas are found in or implied by @xcite , @xcite , and @xcite ( see also @xcite and @xcite ) in the case where @xmath289 on @xmath35 , with @xmath233 the normal to @xmath35 ( in our setting @xmath229 on @xmath290 and @xmath291 on @xmath292 ) . here",
    ", we consider the case of _ characteristic boundary _",
    ", where from ( b2 ) @xmath293 on @xmath35 ,",
    "so we adapt the classical results to this case .",
    "[ lemma4 ] there exists @xmath183 such that @xmath294    let @xmath295 be a domain containing @xmath99 such that @xmath296 , and let @xmath297 the principal eigenvector / eigenvalue pair for @xmath126 on @xmath13 with homogeneous dirichlet boundary conditions on @xmath298 .",
    "recall that @xmath148 is given by the rayleigh formula @xmath299 where @xmath300 is the space of functions vanishing on @xmath301 such that @xmath302 and similarly for @xmath303 .",
    "since every function vanishing on @xmath304 also vanishes on @xmath305 , we have @xmath306 now let @xmath307 obey   with @xmath308 , and define @xmath309 .",
    "since @xmath13 is a sub - basin of attraction such that @xmath310 points outward on @xmath298 , we can use the following classical results ( see e.g. lemmas 34 of  @xcite ) : @xmath311=\\lim_{\\beta \\to \\infty } \\beta^{-1 } \\log { \\mathbb e}[\\tau ' ] = \\inf_{z \\in \\partial d'}\\inf_{t>0}\\ , i_{z , t}\\ ] ] where , by definition , @xmath312 } \\frac{1}{4}\\int_0^t |{\\dot f}(s)+v'(f(s))|^2\\,ds\\\\ & h_1^z[0,t ] = \\left\\{f\\,:\\ , \\exists { \\dot f } \\in",
    "l^2[0,t]\\,\\,s.t.\\,\\,f(t ) = z,\\,\\forall s \\in [ 0,t ] , \\,f(s ) = 1 + \\int_0^s { \\dot f}(r)\\,dr\\right\\}.\\end{aligned}\\ ] ] observe that for any @xmath313 and @xmath314 $ ] we have @xmath315 since @xmath298 is disjoint from @xmath99 we can conclude that for @xmath316 , @xmath317 uniformly in @xmath313 , for a positive constant @xmath288 .",
    "thus , @xmath318 \\ge c > 0\\ ] ] which , combined with   and  , implies the result .    next we need the following regularity result for @xmath128 :    [ lemma5 ]",
    "the function @xmath128 is uniformly bounded in @xmath21 , that is , @xmath319 where @xmath320 is the @xmath321 norm on @xmath322 $ ] .",
    "define @xmath323 and set @xmath324 where @xmath111 obeys   with @xmath112 .",
    "fix @xmath325 . by it",
    "s lemma , for @xmath326 $ ] we have @xmath327 setting @xmath328 and taking expectations gives @xmath329 = { { \\mathbb e}}\\left[e^{\\lambda t\\wedge\\tau^x}u(x_{t\\wedge\\tau^x}^x)\\right].\\ ] ] recall that @xmath128 is bounded for fixed @xmath21 .",
    "we show in equations   below that @xmath330 $ ] is finite , so we may let @xmath331 in   and use the dominated convergence theorem to obtain @xmath332 \\le { { \\mathbb e}}\\left[e^{\\lambda \\tau^x}\\right],\\ ] ] where we have recalled @xmath333 and , from ( b4 ) , @xmath275 .",
    "the idea is then to compare @xmath334 to the first hitting time of @xmath99 of a brownian",
    "motion reflected at zero .",
    "define @xmath335 where @xmath336 with @xmath337 as in  .",
    "let @xmath338 and @xmath339 be given by reflecting @xmath340 and @xmath111 at zero .",
    "since @xmath341 on @xmath342 , it is clear that @xmath343 for each @xmath344 and @xmath345 .",
    "thus , @xmath346 we will bound from above the last line of  .",
    "let @xmath347 solve the heat equation @xmath348 with @xmath349 for @xmath350 and @xmath351 .",
    "an elementary analysis shows that @xmath352 ( the fourier sine series for @xmath353 on @xmath354 $ ] at @xmath355 is an alternating series , and its first term gives the upper bound above . )",
    "we claim that for fixed @xmath356 and @xmath357 $ ] , @xmath358 to see this , let @xmath359 and observe that @xmath360 , so by it s lemma , for @xmath361 $ ] @xmath362 by taking expectations and setting @xmath363 we obtain @xmath364 \\\\ & = { \\mathbb e}\\left[w\\left(t , b_t^x\\right)\\,1_{\\{t\\le \\sigma^x\\}}\\right ] + { \\mathbb e}\\left[w\\left(\\sigma^x , b_{\\sigma^x}^x\\right)\\,1_{\\{t>\\sigma^x\\}}\\right ] \\\\ & = { \\mathbb e}\\left[v\\left(0,b_{t}^x\\right)\\,1_{\\{t\\le \\sigma^x\\}}\\right ] \\\\ & = { \\mathbb p}(\\sigma^x \\ge t).\\end{aligned}\\ ] ] from  ,   and  , for @xmath365 @xmath366 by lemma  [ lemma4 ] , @xmath367 as @xmath182 .",
    "so for all sufficiently large @xmath21 , @xmath368   & = 1 + \\int_1^\\infty { \\mathbb p}(e^{\\lambda \\tau^x } \\ge t)\\,dt \\\\ & \\le 1 + \\frac{4}{\\pi}\\int_1^\\infty   t^{-\\pi^2/(4\\lambda\\beta)}\\,dt\\\\ & = 1 + \\frac{4}{\\pi}\\frac{4\\lambda\\beta}{\\pi^2 - 4\\lambda\\beta}. \\end{split}\\end{aligned}\\ ] ] now recalling  , @xmath369\\le 1 + \\frac{4}{\\pi}\\frac{4\\lambda \\beta}{\\pi^2 - 4 \\lambda \\beta}.\\ ] ] using lemma  [ lemma4 ] we see that the right hand side of   approaches @xmath99 as @xmath182 .",
    "an analogous argument can be made for @xmath370 $ ] , showing that @xmath128 is uniformly bounded in @xmath21 as desired .",
    "next we define a function which will be useful in the analysis of  . for @xmath371 $ ]",
    "let @xmath372 we compare @xmath128 and @xmath373 in the following lemma :    [ lemma6 ] let @xmath320 the @xmath321 norm on @xmath374 $ ] . with @xmath373 defined by  , we have , in the limit @xmath182 , @xmath375    observe that @xmath376 , defined on @xmath377 $ ] , satisfies @xmath378 multiplying by @xmath379 in   leads to @xmath380 so that @xmath381 integrating   and using @xmath382 , @xmath383 using lemma  [ lemma5 ] we have @xmath384 . from ( b1 ) and ( b3 ) we see that @xmath9 is decreasing on @xmath377 $ ] . so putting @xmath385 in   we obtain , for all sufficiently large @xmath21 , @xmath386 where in the last line laplace s method is used . using lemma  [ lemma4 ] , for all sufficiently large @xmath21 , latexmath:[\\[\\label{bound }    @xmath9 is nonpositive on @xmath377 $ ] , so from  , @xmath388 using lemma  [ lemma4 ] again , we get @xmath389 . as @xmath390",
    "this implies @xmath391 .",
    "this completes the proof .",
    "[ remark2 ] a result analogous to lemma  [ lemma5 ] holds , with @xmath392 for @xmath393 $ ] .",
    "we are now in position to prove theorem  [ theorem2 ] .",
    "it suffices to prove the case @xmath394 , so we will look at the endpoint @xmath395 . from theorem  [ theorem0b ]",
    "we have @xmath396 so that @xmath397 introducing again the superscripts @xmath22 and @xmath23 , @xmath398 dropping the superscripts , recalling the function @xmath373 from  , and using lemma  [ lemma6 ] , we see that @xmath399 since @xmath400 where @xmath401 is a @xmath21-independent constant coming from the second term in the laplace expansion .",
    "thus @xmath402 this takes care of the third term of the product in  .",
    "we now turn to the fourth term .",
    "let @xmath403 $ ] and note that for @xmath404 $ ] , @xmath405 where here @xmath288 depends on @xmath406 . since @xmath407 , for all sufficiently large @xmath21 , latexmath:[\\[\\label{leveling }    different @xmath288 .",
    "also , @xmath409 where @xmath410 is a @xmath21-independent constant coming from the second term in the laplace expansion .",
    "thus @xmath411 using   and lemma  [ lemma6 ] again , @xmath412 from remark  [ remark2 ] , we can make an identical argument on @xmath413 to get @xmath414 with a different but still @xmath21-independent @xmath410 .",
    "this takes care of the fourth term in the product in  .",
    "observe that in the limit @xmath106 , @xmath415 we have : @xmath416 reintroducing the superscripts @xmath22 and @xmath23 and using   and   in   now gives @xmath417 as desired .",
    "we have presented a mathematical framework for tad which is valid in any dimension , along with a complete analysis of tad in one dimension under this framework .",
    "this framework uses the notion of quasi - stationary distribution , and is useful in particular to clarify the immediate equilibration assumption ( or no - recrossing assumption ) which is underlying the original tad algorithm and to understand the extrapolation rule using the arrhenius law .",
    "we hope to extend this justification of the extrapolation rule to high dimensions , using techniques from  @xcite ; the analysis seems likely to be technically detailed .",
    "we hope that our framework for tad will be useful in cases where the original method is not valid .",
    "indeed , we have shown that tad can be implemented wherever accurate estimates for the ratios in   are available .",
    "this fact is important for transitions which pass through degenerate saddle points , in which case a pre - exponential factor is needed on the right hand side of  . for example , in one dimension , a simple modification of our analysis shows that if we consider degenerate critical points on @xmath35 , then a factor of the form @xmath418 must be multiplied with the right hand side of  .",
    "d. aristoff gratefully acknowledges enlightening discussions with g. simpson and o. zeitouni .",
    "d. aristoff and t. lelivre acknowledge fruitful input from d. perez and a.f . voter .",
    "part of this work was completed while t. lelivre was an ordway visiting professor at the university of minnesota .",
    "the work of d. aristoff was supported in part by doe award de - sc0002085 ."
  ],
  "abstract_text": [
    "<S> we give a mathematical framework for temperature accelerated dynamics ( tad ) , an algorithm proposed by m.r . </S>",
    "<S> srensen and a.f . </S>",
    "<S> voter in  @xcite to efficiently generate metastable stochastic dynamics . using the notion of _ quasistationary distributions _ , we propose some modifications to tad . then considering the modified algorithm in an idealized setting , </S>",
    "<S> we show how tad can be made mathematically rigorous </S>",
    "<S> .    accelerated molecular dynamics , temperature accelerated dynamics , langevin dynamics , stochastic dynamics , metastability , quasi - stationary distributions , kinetic monte carlo    82c21 , 82c80 </S>"
  ]
}