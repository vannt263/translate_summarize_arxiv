{
  "article_text": [
    "unprecedented growth in transmit data volumes throughout the networks in recent years demands more efficient use of storage devices while providing high quality of service ( qos ) to the users .",
    "currently , large files are stored on servers and users requests are stored in queues waiting to get service from them .",
    "naturally , one approach to reduce congestion in such networks is to increase the service rate of such servers .",
    "however , this will put additional burden on such nodes .",
    "as the cost of storage devices has decreased over the years , another viable option is to provide geographical content replication in the network through use of the so - called low - capacity _ caching _ nodes .",
    "the idea of using such nodes for data replication and providing easier local access to data is already covered in the literature ( see for example @xcite ) .",
    "recently , in their seminal work , maddah - ali and niesen considered a single server network and have shown that through a two - phase cache placement and content delivery strategy , server load can be reduced inversely proportional to the total size of cache introduced in the network .",
    "in fact , in the cache placement phase , contents are stored on caches without knowing the actual demands of the users and in content delivery phase the server transmits packets to fulfill the demands .",
    "the fact that such _ global caching gain _ can be achieved in such network is surprising as the demands are not known apriori at the cache placement phase .",
    "maddah - ali and niesen s cache placement strategy is based on shattering each file into many pieces and only distributing them throughout the caching nodes _ without _ replication .",
    "it should be noted that such approach is in contrast to the conventional local cache placement strategies where a file or a single piece of it is replicated in caches .",
    "the astounding feature of their strategy is that transmission of a single packet at content delivery phase can then simultaneously serve several users .",
    "imagine that two pieces of two files are stored at two different caches and each of them requires the piece available at the other .",
    "a single packet containing the sum of two packets can be sent to fulfill both users demands .",
    "they have shown that their strategy is 12-approximation of the optimal strategy .",
    "the network considered in @xcite is a simple broadcast network where a packet transmitted by the server arrives unaltered at all users .",
    "a fundamental problem is to see how network topology affects the optimal coding strategy through both placement and delivery phases .",
    "one of the simplest topologies is the tree network . in @xcite",
    ", maddah - ali and niesen proved that their original strategy can be used directly for such a network and what is needed to achieve 12-approximation of the optimal strategy is a simple topology - aware routing strategy at the internal nodes ; an internal node routes a packet on its output port if the packet is useful for at least one of the port s children .",
    "while the topology - aware routing scheme for tree networks is shown to be an order - optimal solution , real - world topologies are much more sophisticated than the simple tree structure . in this paper",
    ", we characterize the effect of network topologies on code design and performance analysis of coded caching in a more general setup .",
    "in particular , we investigate a multi - server network topology where a set of servers are connected to the clients through an error - free and delay - free intermediate network of nodes ( see fig .",
    "[ fig_multi_server_model ] ) .",
    "we assume that each node in the intermediate network can perform any causal processing on its input data , to generate its outgoing data .",
    "this can consist of simple routing or more sophisticated network coding schemes .",
    "the objective considered in @xcite is minimizing the traffic load imposed to the single server .",
    "however , in general , other objectives may be of higher importance when designing network operation strategy .",
    "one such key criterion is the _ service delay _ of the network which is specially critical in content delivery networks ( see eg .",
    "we define the service delay of the network as the total time required to serve any given set of the clients requests for a specific strategy .",
    "we distinguish between two types of delay , _ network delay _ @xmath0 and _ coding delay _",
    "@xmath1 , where the total service delay , @xmath2 , is given by @xmath3 . to be more precise",
    ", @xmath0 is the time it takes for packets to be routed through the network and arrive at their requesting nodes .",
    "naturally , @xmath0 mainly captures the links and queues delays in the network which are intrinsic characteristics of the network . on the other hand",
    ", @xmath1 captures the transmission block length required to serve all the users for a specific coding strategy . in this paper , we focus on the coding delay and design strategies to minimize such delays .",
    "we consider three classes of networks : 1- dedicated networks , 2- flexible networks , and 3- linear networks .",
    "these networks are characterized based on the richness of their internal connections , as shown in fig .",
    "[ fig_model_example ] . in each class ,",
    "an important network topology aspect is the number of servers connected to the network , and their points of contact .",
    "in dedicated networks , we can dedicate each server to serve a fixed subset of clients , where each server can send a common message to its corresponding subset , interference - free from other servers .",
    "although in dedicated networks the assignment of clients to the servers is fixed , in flexible networks the network topology is rich - enough to let us adapt these assignments during network operation .",
    "finally , in linear networks we assume random linear network coding operations at the internal nodes .",
    "consequently , in linear networks , the network input - output relation is characterized by a random matrix . as we show in this paper , in order to minimize the coding delay , designing the coding strategy for each class should carefully utilize the flexibility of that class . as will be shown subsequently ,",
    "there exist coding strategies outperforming that of @xcite for all of the three classes of networks .",
    "interestingly , we obtain an order optimal solution for the flexible networks .",
    "finally , let us review some notations used in this paper .",
    "we use lower case bold - face symbols to represent vectors , and upper case bold - face symbols to represent matrices . for any matrix @xmath4",
    ", @xmath5 denotes the transpose of @xmath4 and for any vector @xmath6 , @xmath7 shows that the condition @xmath8 is satisfied .",
    "for any two sets @xmath9 and @xmath10 , the set @xmath11 consists of those elements of @xmath9 not present in @xmath10 .",
    "also we define @xmath12=\\{1,\\dots , k\\}$ ] and @xmath13 to be the set of integer numbers .",
    "moreover , @xmath14 shows a finite field with @xmath15 elements , and @xmath16 denotes the set of all @xmath17-by-@xmath18 matrices whose elements belong to @xmath14 .",
    "finally , let @xmath19 , then @xmath20 is a random linear combination of @xmath21 where the random coefficients are uniformly chosen from @xmath14 .",
    "the rest of the paper is organized as follows . in section [ sec_model ]",
    ", we describe the network model and different classes of networks . in section [ sec_main_results ] ,",
    "we review the main results of the paper , present some examples , and discuss their implications .",
    "the next two sections , i.e. sections [ sec_flexible ] and [ sec_linear ] , present the details of the coding strategies proposed for flexible and linear networks , respectively .",
    "finally , we conclude the paper in section [ sec_conclusions ] .",
    ", scaledwidth=40.0% ]    consider @xmath22 servers connected to @xmath23 users through a network . by network",
    "we mean a _ directed acyclic graph _ ( dag ) @xmath24 , in which the set of vertices @xmath25 consists of internal nodes , and every edge @xmath26 on the graph represents an _ error - free _ and _ delay - free _ link with capacity of one symbol per channel use .",
    "each server and each user is connected to the network by a single link with capacity of one symbol per channel use . at each channel use each node inside the network sends symbols on its output links based on ( deterministic / random ) functions of the symbols on its input links , without introducing any delay , where functions corresponding to different output ports need not be the same .",
    "also , we assume that there is no inter - link interference .",
    "data is represented by @xmath27-bit _",
    "_ symbol__s which are members of a finite field @xmath28 , where @xmath29 .    consider a library of @xmath30 files @xmath31 each of @xmath32 bits is available to all servers .",
    "each user is also assumed to have a cache of size @xmath33 bits . during its operation ,",
    "the network experiences two different traffic conditions , namely _ low - peak _ and _ high - peak _ leading to different network transmission costs for the two conditions .",
    "based on the given traffic condition , the network operates in two distinctive phases .",
    "the first phase that is performed during low - peak condition is called the _ cache content placement _ phase at which servers send data to the users without knowing the actual requests of the users .",
    "this data is cached at the users with the size constraint of @xmath33 bits and is stored to be used in the future . in the second phase that is performed during high - peak network condition ,",
    "each user requests one of the files ( demand @xmath34 of user @xmath35 denotes requesting file @xmath36 ) , and according to these requests the servers send proper packets over the network .",
    "subsequently , upon receipt of packets over the network , users try to decode their requested files with the help of their own cache contents . assuming that the cache placement transmission delay during the low - peak condition puts no constraint on overall network performance , the goal is to design the cache placement strategy such that the service delay at the time of _ content delivery _ is minimized .",
    "channel uses in the network are indexed by time slots @xmath37 . at time",
    "slot @xmath38 , servers transmit symbols @xmath39 and users receive symbols @xmath40 without delay .",
    "we consider the most general case , i.e. , @xmath41 in which we have assumed that the network is memory - less across time slots .",
    "functions @xmath42 depend on the topology of the network and the local operations of the nodes inside the network .",
    "we define : @xmath43 where @xmath44 , and @xmath45 .    in the first phase , users store data from the servers without knowing the actual requests .",
    "the only concern in the first phase is respecting the memory constraint of each user .",
    "however , in the second phase , we focus on the time needed to deliver the requested files to the users .",
    "the second phase consists of @xmath1 time slots ( channel uses ) .",
    "in other words , during the second phase , servers sequentially transmit @xmath46 , and the users receive @xmath47 .",
    "consequently , @xmath48 is the number of times slots required to satisfy demands @xmath49 .",
    "then , we define the optimum _ coding delay _ as : @xmath50 where the minimization is over all strategies . in this paper , we are interested in characterizing @xmath51 for a network , given its specific topology .    for a given network topology ,",
    "the network input - output relation depends on operational design of internal nodes .",
    "as we will show , the _ richer _ the network topology is , the broader the design space will be .",
    "therefore , we consider the following three classes of network topologies :    , scaledwidth=100.0% ]    * * dedicated networks * + in this class of networks , each packet transmitted by a server is routed to a fixed subset of the users . in other words , we can dedicate each server to a fixed subset of users , and this server can send packets to these users , concurrently and without interference to other servers .",
    "we assume these subsets to be non - overlapping so that each user is assigned to a single server . also , we assume we can balance these assignments such that the number of users assigned to a server is almost the same for all servers .",
    "if network topology allows us to perform such assignments , we call the network a _ dedicated network_. + more formally , there exists a coding ( in this case just routing would suffice ) strategy at the network nodes such that there _ exists a partitioning _",
    "@xmath52 of @xmath53=\\{1,2 , \\dots , k'\\}$ ] where @xmath54 in which @xmath55 is the smallest number larger than or equal to @xmath23 which is divisible by @xmath22 .",
    "+ consider fig .",
    "[ fig_model_example]-(a ) in which @xmath56 servers are connected to @xmath57 users via a dedicated network . in this example",
    ", we have @xmath58 , and it is easy to verify that we can find a routing strategy at intermediate nodes such that : @xmath59 * * flexible networks * + in this class of networks , we assume that there exists a coding ( routing ) strategy at network nodes such that for _ every partitioning _ @xmath52 of @xmath12=\\{1,2 , \\dots , k\\}$ ] we have : @xmath60 + it should be noted that in the dedicated networks , each server was assigned to a _ fixed",
    "_ subset of users , while in flexible networks we can flexibly change these assignments during the data delivery phase . in the example shown in fig .",
    "[ fig_model_example]-(b ) , we have chosen two sample partitionings , i.e. @xmath61 for the top figure , and @xmath62 for the bottom figure . it is obvious that every flexible network is a dedicated network , but the converse is not true . hence , flexible networks are generally _ richer _ than dedicated networks in terms of their internal connectivity . * * linear networks * + in the aforementioned dedicated and flexible networks , the intermediate nodes should know the topology of the network in order to do a proper routing of their input data onto their output ports .",
    "however , in the case of linear networks , we assume that such knowledge is not available at intermediate nodes .",
    "thus , we assume that each node generates a random linear combination of data at its input ports to be transmitted on its output ports .",
    "consequently , the overall transmit and receive vectors of the network are linearly related at each time slot : @xmath63 where @xmath64 .",
    "@xmath65 is called the _ network transfer matrix _ ( ntm ) .",
    "let us define : @xmath66 ,    \\\\",
    "\\mathbf{y}&\\triangleq&[\\mathbf{r}(1 ) , \\mathbf{r}(2 ) , \\dots , \\mathbf{r}(t_c)].\\end{aligned}\\ ] ] we call matrices @xmath67 and @xmath68 , transmit and receive blocks , respectively",
    ". then , transmit and receive blocks are also linearly related : @xmath69 + in _ linear networks _ ,",
    "we assume that network topology is _ rich - enough _ to guarantee that the elements of @xmath65 are i.i.d . random variables .",
    "similar to most existing papers employing random linear network coding , we assume large - enough @xmath29 to assure that ntm exhibits full rank matrix properties , with high probability @xcite . also , we assume uniform distribution on the elements of @xmath65 , which is a proper assumption for large scale networks with many sources of randomness @xcite .",
    "+ finally , for later reference , define @xmath70 as @xmath71^t , k=1,\\dots , k.\\end{aligned}\\ ] ] + it should be noted that we assume a static network transfer matrix @xmath65 , such that it does not change for the duration of @xmath1 time slots . as changes in the network transfer matrix is due to topology changes ( e.g. failure of a node ) , such assumption is valid in most practical scenarios .",
    "[ fig_model_example]-(c ) illustrates an example of a linear network in the case of @xmath56 and @xmath57 .",
    "finally , it should be noted that in this paper , we assume @xmath72 .",
    "such assumption will lead to more clear presentation in the rest of this paper and will also exclude the possibility of using uncoded multi - casting schemes that may trivially be adopted for the case of small number of files . extending the results to the case @xmath73",
    "is straightforward , and the readers are referred to @xcite .",
    "it should be noted that if a server is connected to the network by a number of links ( each of integer capacity ) with the total capacity of @xmath38 symbols per time slot , our model can accommodate this scenario by splitting this server into @xmath38 separate servers .",
    "the random linear network coding approach at intermediate nodes is also used in other papers such as @xcite , @xcite , and @xcite , in the context of uni - casting via interference alignment .",
    ", scaledwidth=40.0% ]    the simplest approach in designing a coding scheme for the multi - server case is to directly transform it to a single - server scenario and use the scheme presented in @xcite .",
    "such approach can be simply adopted by adding a _ super server _ node and connecting it with edges of infinite capacity to all other servers ( see fig .",
    "[ fig_main_result_1 ] ) .",
    "as shown in @xcite , we only need to route packets that are transmitted by the super - server to those users that can benefit from receiving them . for tree networks , such approach results in the following simple topology - aware routing scheme : at each interior node , the packets received at the input port benefiting at least one of the descendants of the node , is sent on the corresponding output port . as proved in @xcite , the minimum traffic load imposed on each link , in the scaling sense , can be achieved by such simple routing scheme .",
    "such approach also leads to an order - optimal coding delay for tree networks under our formulation .",
    "one can , however , think of another naive and simple approach to the multi - server problem",
    ". we can simply dedicate each server to a subset of users and make it responsible for satisfying the requests of the corresponding subset of users .",
    "it is clear that , in order to prevent congestion at a specific server , we should balance out loads of the servers so that each of @xmath22 servers will be responsible for about @xmath74 users .",
    "consequently , one can easily arrive at the following theorem for the coding delay in dedicated networks :    [ thm_dedicated ] the coding delay for a dedicated network is upper bounded by a piecewise - linear curve with corner points @xmath75 where @xmath76 should be satisfied , and @xmath55 is the smallest number larger than or equal to @xmath23 which is divisible by @xmath22 .",
    "the proof of theorem [ thm_dedicated ] is straightforward , and thus , we just draw the main sketch here .",
    "first , let us review the main concept behind the coded caching scheme for a single server in a broadcast scenario @xcite .",
    "in this case , if we do not have any cache at the users , it is clear that the server should in sequence send all the requested files to the users ( considering that the users request different files ) .",
    "this will lead to a total amount of @xmath77 bits to be transmitted .",
    "since the server is only able to transmit @xmath27 bits ( a symbol in @xmath14 ) at each time slot , the coding delay will be @xmath78 time slots . by providing cache at the users , the _ local caching gain _",
    "will reduce the coding delay to @xmath79 .",
    "the main result in @xcite indicates that by exploiting the additional _ global caching gain _ , the coding delay for @xmath80 reduces to : @xmath81 which is order optimal for this scenario .    as we extend to the multi - server case ,",
    "let us assume for simplicity that @xmath23 is divisible by @xmath22 .",
    "splitting the original @xmath22-server problem with @xmath23 users into @xmath22 single - server problems with @xmath82 users is possible in this case .",
    "since the sub - networks may operate in parallel , the delay is further reduced to : @xmath83 where @xmath84 . since in any scheme we can benefit at most all the @xmath23 users simultaneously ,",
    "the total multi - casting gain of any scheme is at most @xmath23 , and the denominator should be compared to @xmath23 ( by the @xmath85 operator in the denominator of ( [ eq_dedicated_theorem ] ) ) .",
    "extension to the case where @xmath23 is not divisible by @xmath22 can be accomplished by adding virtual users .",
    "the following example compares the above two naive approaches :    [ examp_intro_1 ]    consider the network shown in fig .",
    "[ fig_intro_examp1 ] for @xmath57 users .",
    "we also assume the library contains @xmath86 files , and each user can store @xmath87 files during the cache content placement phase . by adding a super server",
    "a tree network is obtained , and in the delivery phase , the scheme in @xcite suggests to send @xmath88 bits at the super server s output . in their scheme , at each node only those packets benefiting the descendants of an output port will be copied on that port .",
    "however , in our case each packet benefits @xmath89 users , and thus should be copied on both output ports of node @xmath90 .",
    "this results in : @xmath91 and since we assumed a capacity of one symbol per time slot for each internal edge , the delay of this scheme is : @xmath92    at this stage , the key question is whether it is possible to further reduce the required number of time slots or not ?",
    "in fact , with a closer look at this network it becomes evident that we can reduce this network to a dedicated network with : @xmath93 therefore , the original problem can be divided into two sub - problems ( see fig .",
    "[ fig_intro_examp1 ] ) and each server can address the load of its corresponding sub - network by : @xmath94 since the sub - networks operate in parallel , the delay of this scheme will be @xmath95 time slots .    .",
    "[ fig_intro_examp1],scaledwidth=80.0% ]    the above example shows that although the scheme in @xcite is order - optimal for tree networks , however , by designing a topology - aware scheme it may be possible to arrive at a better pre - constant factor .    next ,",
    "let us consider another class of networks with more flexibility , i.e. flexible networks .",
    "in such networks , similar to dedicated networks , we can assign a subset of users to each server , and the network allows parallel operation of the servers .",
    "however , unlike dedicated networks , such assignment can be changed arbitrarily in subsequent transmissions .",
    "such extra freedom in user assignments allows a significant reduction in the coding delay as shown in the following example .",
    "[ examp_flexible_1 ] for a single server case , the scheme proposed in @xcite achieves the following delay for @xmath96 : @xmath97 in order to get a better insight on this result , consider fig .",
    "[ fig_flexible_exmp1]-(a ) which shows the cache content placement and the delivery scheme for requests @xmath98 by users @xmath99 , respectively . in the cache content placement phase ,",
    "each file is divided into four equal - sized parts and cached as shown in fig .",
    "[ fig_flexible_exmp1]-(a ) . in the delivery phase",
    ", the single server sends the following data in sequence : @xmath100 as a result , six transmissions are required while each has the delay @xmath101 .",
    "thus , the total delay will be @xmath102 . in the above scheme",
    ", each transmission benefits a pair of users , and is of no value for the other pair .",
    "if we have two servers , by the definition of flexible networks each server is able to transmit a given data to a pair of users simultaneously and interference - free from transmission of the other server . in fig .",
    "[ fig_flexible_exmp1]-(b ) , transmissions of the left and right servers are colored as blue and red , respectively .",
    "thus , a pair of transmissions in fig . [ fig_flexible_exmp1]-(a ) can be sent simultaneously as shown in fig .",
    "[ fig_flexible_exmp1]-(b ) , resulting in the achievable pair @xmath103 .",
    "thus , exploiting the extra flexibility of the network in this example results in the coding delay enhancement , compared with the single - server case .    .",
    "[ fig_flexible_exmp1],scaledwidth=80.0% ]    in dedicated networks , we exploit the network topology to assign a fixed number of users to each server . in this way",
    ", a user receives packets only from a certain server and this assignment is fixed during the course of transmission . in flexible networks , however , at different time slots users can be served by different servers where the assignment strategy is fixed for each server .",
    "[ fig_strategy ] shows two servers connected to three users through such flexible network .",
    "the blue packets originating from server 1 are intended for one user ( which may change at different time slots ) and the red packets originating from server 2 are intended for two users ( which may change at different time slots ) .",
    "we assign blue packets to be associated with strategy @xmath104 and red packets with strategy @xmath105 .",
    "[ fig_strategy ] shows consequent transmissions in such network where strategy 1 is associated with server 1 and strategy 2 with server 2 . in general ,",
    "we associate strategy @xmath106 to a packet if it is intended for @xmath106 users .",
    "now , if we fix a strategy for a server , it means that all the packets transmitted by that server have the same strategy .",
    "it is worth mentioning that packets received by a user do not necessarily have the same strategy , since they may have arrived from different servers ( see fig .",
    "[ fig_strategy ] ) .    ,",
    "scaledwidth=80.0% ]    consider server @xmath107 with strategy @xmath108 .",
    "also , we assign a fraction @xmath109 bits of each file to be delivered by server @xmath107 . in order to employ the scheme in @xcite for this server",
    ", we allocate a memory of size @xmath110 bits from all the users to be used only by server @xmath107 where @xmath111 therefore , server @xmath107 can deliver @xmath109 bits to all the users in @xmath112 time slots where @xmath113 we assume that a routing strategy exists where packets from different servers do not interfere with each other . in this case , the total delay is limited by the maximum delay of the servers",
    ". therefore , in order to balance out the servers loads , we can simply set : @xmath114 where @xmath115 does not depend on @xmath107 and satisfies : @xmath116 therefore , @xmath117 since the total memory is @xmath118 , we have @xmath119 hence , @xmath120    the aforementioned result is based on a strong assumption that a routing strategy exists for parallel and interference - free transmission of the packets . in section [ sec_flexible ] , we show that such a strategy does in fact exist for flexible networks .",
    "the preceding discussion is a rough proof of the following theorem :    [ thm_flexible ] suppose a flexible network with @xmath22 servers .",
    "then , for all @xmath121 the following @xmath122 pairs ( and the straight lines connecting them ) are achievable @xmath123 and thus lead to an upper bound for the optimum coding delay @xmath51 .",
    "see section [ sec_flexible ] for the proof .    in the following example",
    ", we present a network in which employing the flexible network strategy results will go beyond earlier results and paves the way for scaling improvement in the coding delay compared with the super - server strategy .",
    "[ examp_intro_2 ] consider the network depicted in fig .",
    "[ fig_intro_examp2]-(a ) . in this network , @xmath22 ( an even number ) servers",
    "are connected to @xmath124 users via @xmath22 intermediate nodes where each intermediate node has dedicated links to all the users .",
    "we also assume : @xmath125 in order to use the super - server strategy with the tree approach proposed in @xcite , we need to choose an appropriate tree inside the network . it can be easily verified that the tree illustrated in fig .",
    "[ fig_intro_examp2]-(b ) is the best choice .",
    "therefore , @xmath126 , the minimum rate of the super - server , is given by @xmath127 the load @xmath128 on each server consists of those packets that are useful for at least a user which is a descendant of that server .",
    "we know that each packet benefits a subset of users of size : @xmath129 therefore , the ratio of packets routed on a specific edge to the total number of packets is : @xmath130 for large @xmath22 .",
    "thus , almost a constant number of packets generated by the server will be routed on each edge .",
    "this will result in a delay of :    @xmath131    time slots .",
    "a closer look at the network topology shows that the network is indeed flexible . setting @xmath132 which satisfies @xmath133 and using memory size @xmath118 where @xmath134 theorem [ thm_flexible ] can be used to achieve the following coding delay : @xmath135    the above delay in ( [ eq_mainresults_examp3_delay_flex ] ) is not only a scaling improvement compared with the super - server tree - based strategy with delay ( [ eq_mainresults_examp3_delay_super ] ) , but also the optimal delay .",
    "this is due to the fact that each user can store at most @xmath136 bits of each file .    .",
    "[ fig_intro_examp2],scaledwidth=80.0% ]    the optimality of the preceding coding scheme can be generalized to any flexible network where @xmath23 is divisible by @xmath22 as the following theorem states .",
    "[ thm_order_optimal ] if @xmath23 is divisible by @xmath22 , then the upper bound in theorem [ thm_flexible ] is optimal within a multiplicative constant gap .",
    "see section [ sec_flexible ] for the proof .    for flexible and topologically complex networks , finding a proper routing strategy that achieves the optimal coding delay may not be straightforward . to overcome this difficulty , internal nodes can perform simple random linear network coding which is oblivious to the network s topology .",
    "although this strategy may not be optimal , it has the advantage of being practical and robust . in this way",
    ", the network model reduces to a linear network model and the following theorem provides an achievable coding delay for such networks .",
    "[ thm_linear ] the coding delay for a linear network with @xmath22 servers is upper bounded by a piecewise - linear curve with the corner points @xmath137 where @xmath80 should be satisfied .    see section [ sec_linear ] for the proof .    in linear networks ,",
    "a packet intended for a certain number of users , in general , interferes with all other users .",
    "proper pre - coding schemes can be adopted to reduce interference in such networks .",
    "consequently , simultaneous transmission of multiple packets will further reduce network coding delay . in order to clarify the implications of theorem [ thm_linear",
    "] , we present the following example :    : @xmath138.[fig_4_4_curves_together],scaledwidth=40.0% ]    [ examp_linear_2 ] consider a network with @xmath139 . using theorem [ thm_linear ] ,",
    "the coding delay for any @xmath140 is given by @xmath141 the above delay is plotted in fig .",
    "[ fig_4_4_curves_together ] for @xmath140 .",
    "the problem for @xmath142 reduces to that of @xcite . for @xmath143",
    ", we obtain a multiplexing gain of @xmath144 by constructing four parallel interference - free links each from one server to one user ( e.g. through singular value decomposition ) and the optimal coding delay is achieved .",
    "networks with @xmath145 are interesting cases where interference management is required to achieve the gain @xmath146 in the denominator .",
    "the detail of the coding strategy is rather involved and we delegate it to appendices b and c.",
    "in this section , we present an achievable scheme for the flexible networks leading to the result given in theorem [ thm_flexible ] . we also provide a proof for the optimality result in theorem [ thm_order_optimal ] through cut - set analysis .    for the achievability part , we need to provide the cache content placement and content delivery strategies .",
    "let us start with defining the following parameters : let @xmath121 and consider an integer solution of the following equation : @xmath147 where @xmath148 and @xmath149 .",
    "we also define @xmath150 + * cache placement strategy : * first , split each file @xmath151 into @xmath22 sub - files @xmath152 where @xmath153 is of size @xmath154 .",
    "then , split each sub - file @xmath153 into @xmath155 equal - sized mini - files : @xmath156 , |\\tau_i|=p_i-1 \\right).\\end{aligned}\\ ] ] finally , split each mini - file @xmath157 into @xmath158 equal - sized pico - files of size @xmath159 bits : @xmath160 where @xmath158 is an integer number . for each user @xmath35",
    ", we cache pico - file @xmath161 if @xmath162 , for all possible @xmath163 .",
    "then , the required memory size for each user is : @xmath164 which is consistent with the assumptions of theorem [ thm_flexible ] .",
    "+   + * content delivery strategy : * define @xmath165 to be the collection of all @xmath108-subsets of @xmath12 $ ] for all @xmath166 .",
    "the delivery phase consists of @xmath167 transmit slots .",
    "each transmit slot is in one - to - one correspondence with one @xmath168-partition of @xmath12 $ ] .",
    "consider the transmit slot associated with the partition @xmath169 where @xmath170 .",
    "then , the server @xmath107 sends @xmath171 to the subset of users @xmath172 , interference - free from other servers , where the sum is in @xmath14 and is over all @xmath173 .",
    "since we have assumed a flexible network , simultaneous transmissions by all servers is feasible .",
    "also , the index @xmath174 is chosen such that each new transmission consists of a fresh ( not transmitted earlier ) pico - file .",
    "obviously , the virtual server @xmath175 does not transmit any packet .",
    "since each pico - file consists of @xmath176 symbols , at each transmission slot we should send a block of size @xmath22-by-@xmath176 by the servers .",
    "also , since this action should be performed for all @xmath167 slots , the delay of this scheme will be : @xmath177 as stated in theorem [ thm_flexible ] . consequently , if we show that through the aforementioned number of transmit slots all users will be able to recover their requested files , the proof is complete . + * correctness proof : * the main theme of this scheme is to divide each file into @xmath22 sub - files , and to assign each sub - file to a single server .",
    "then , each server s task is to deliver the assigned sub - files to the desired users ( see fig .",
    "[ fig_flexible_proof ] ) .",
    "consider server @xmath107 .",
    "this server handles sub - files @xmath178 $ ] though the following delivery tasks : @xmath179 the above formulation leads to a single server problem @xcite with files of size @xmath180 bits .",
    "it can be easily verified that the proposed cache placement strategy for each sub - file mimics that of @xcite for single - server problems .",
    "therefore , if we demonstrate that this server is able to send a common message of size @xmath181 symbols to all @xmath108-subsets of users , then this server can handle this single - server problem successfully .",
    "however , in the above scheduling scheme , the server benefits each @xmath108-subset of the users by a common message of size @xmath176 symbols ( a pico - file size ) , @xmath158 times .",
    "consequently , the total volume of common message that this server is able to send to each @xmath108-subset is @xmath182 symbols .",
    "since by proper scheduling scheme in flexible networks all servers can perform the same task simultaneously , all requested portions of files will be delivered .",
    "it should be noted that the portion of each file assigned to the virtual server is @xmath183 .",
    "algorithm 1 presents the pseudo - code of the procedure described above .    .",
    "[ fig_flexible_proof],scaledwidth=70.0% ]    [ alg_main_flexible ]    @xmath184 , @xmath185 @xmath186 , @xmath187 @xmath188 @xmath189 , @xmath185 @xmath190 split @xmath151 into @xmath191 , where @xmath192 split @xmath153 into @xmath193 , |\\tau_i|=p_i-1)$ ] of equal size split @xmath157 into @xmath194 of equal size @xmath195 , |\\tau_i|=p_i-1 , k \\in",
    "\\tau_i , j=1,\\dots,\\gamma_i , n \\in [ n])$ ] + @xmath196 @xmath197 selected partition * transmit * @xmath198 $ ]    @xmath199    to prove theorem [ thm_order_optimal ] , we first state the following lemma :    [ lem_converse ] the coding delay for a general network with @xmath22 servers is lower bounded by @xmath200    see appendix a for the proof .",
    "the above lemma can be used to prove optimality of the proposed scheme in some range of parameters .",
    "the following corollary states the result .",
    "[ cor_converse ] all @xmath201 pairs in theorem [ thm_flexible ] corresponding to @xmath202 are optimal .",
    "thus , the converse line @xmath203 is achieved for @xmath204 , where @xmath205    theorem [ thm_flexible ] states that all the @xmath201 pairs in ( [ eq_main_resuls_flexile_th ] ) are achievable . by some simple calculations",
    "one can show that for these achievable pairs we have : @xmath206 therefore , if we put @xmath202 in theorem [ thm_flexible ] , all the corresponding @xmath201 pairs satisfy @xmath207 on the other hand , by considering the case of @xmath208 in lemma [ lem_converse ] we know that the optimal coding delay satisfies : @xmath209 which is matched to our achievable coding delay .",
    "therefore , by setting @xmath202 in theorem [ thm_flexible ] , for all @xmath210 the achievable coding delay is optimum . by minimizing the cache size , over all partitionings satisfying @xmath211 ,",
    "the proof is complete .",
    "there is an interesting intuition behind eq .",
    "( [ eq_flexible_converse_cor_1 ] ) . in the proposed scheme for flexible networks",
    ", we assigned a subset of @xmath212 users to the virtual server , and all the other @xmath213 users benefited from other servers .",
    "thus , through each transmission , the ratio @xmath214 of users will be real users .",
    "this is exactly the coefficient that shows how close is the achieved delay to the optimal curve @xmath215 .    finally , we are ready to prove theorem [ thm_order_optimal ] .",
    "we consider two regimes for cache sizes .",
    "first , we let @xmath216 in the first regime where @xmath217 , using theorem [ thm_flexible ] with @xmath202 and @xmath218 , we obtain : @xmath219 as corollary [ cor_converse ] states , for this case the optimal curve is achieved .    for the second regime where @xmath220 ( such that @xmath80 ) , set @xmath221 then ,",
    "we obtain : @xmath222    on the other hand , from lemma [ lem_converse ] we have :    @xmath223    where the last inequality follows from @xcite .",
    "this concludes the proof of theorem [ thm_order_optimal ] .",
    "in order to explain the main concepts behind the coding strategy proposed for linear networks , we will first present a simple example :     ( @xmath224 ) : lower and upper bounds on the coding delay.[fig_multi_server_3_3_2_example],scaledwidth=50.0% ]    [ examp_linear_1 ] in this example , we consider a network consisting of @xmath56 servers , @xmath225 users , and a library of @xmath226 files , namely @xmath227 , @xmath228 , and @xmath229 . by definition of linear networks the input - output relation of this network",
    "is characterized by a @xmath230-by-@xmath105 random matrix @xmath65 .",
    "lower and upper bounds for the coding delay of this setting are shown in fig . [ fig_multi_server_3_3_2_example ] .",
    "the lower bound is due to lemma [ lem_converse ] as follows : @xmath231 the upper bound is due to theorem [ thm_linear ] except the achievable pair @xmath232 , which will be discussed later . we have also exploited the fact that the straight line connecting every two achievable points on the @xmath233 curve is also achievable , as shown in @xcite . in order to get a glimpse of the ideas of the coding strategy behind theorem [ thm_linear ] , next we discuss the achievable @xmath122 pair @xmath234 . in this case , as we will show , we can benefit both from the local / global caching gain ( provided by cache of each user ) , and the multiplexing gain ( provided by multiple servers in the network ) .",
    "the question is how to design an scheme so that we can exploit both gains simultaneously . in what follows",
    "we provide the solution :    suppose that ( without loss of generality ) in the second phase , the first , second , and third users request files @xmath235 , @xmath236 , and @xmath237 respectively .",
    "assume that the cache content placement is similar to that of @xcite : first , divide each file into three equal - sized non - overlapping sub - files : @xmath238 \\\\ \\nonumber b&=&[b_1,b_2,b_3 ] \\\\",
    "\\nonumber c&=&[c_1,c_2,c_3].\\end{aligned}\\ ] ] then , put the following contents in the cache of users : @xmath239 \\\\ \\nonumber z_2&=&[a_2,b_2,c_2 ] \\\\",
    "\\nonumber z_3&=&[a_3,b_3,c_3].\\end{aligned}\\ ] ] let @xmath20 be a random linear combination of @xmath21 as defined earlier . consequently , in this strategy , the two servers send the following transmit block : @xmath240.\\ ] ] where the random linear combination operator @xmath241 operates on sub - files , in an element - wise manner , and @xmath242 is an orthogonal vector to @xmath243 ( i.e. @xmath244 ) .",
    "let us focus on the first user who will receive : @xmath245 \\\\   & = & [ l^1(a_2,a_3,c_1,b_1),l^2(a_2,a_3,b_1,c_1)].\\end{aligned}\\ ] ] as the first user has already cached @xmath246 and @xmath247 in the first phase , by subtracting the effect of interference terms , the first user can recover : @xmath248,\\end{aligned}\\ ] ] which consists of two independent ( with high probability for large field size @xmath15 ) linear combinations of @xmath249 and @xmath250 .",
    "by solving these independent linear equations , such user can decode @xmath249 and @xmath250 , and with the help of @xmath251 cached at the first phase , he can recover the whole requested file @xmath235 .",
    "it can easily be verified that other users can also decode their requested files in a similar fashion .",
    "the transmit block size indicated in ( [ eq_l2_k3_n3_m1_transmit ] ) is @xmath105-by-@xmath252 , resulting in @xmath253 time slots .",
    "let us forget about one of the servers for a moment and assume we have just one server .",
    "then , the scheme proposed in @xcite only benefits two users per transmission through pure global caching gain .",
    "also , in the case of two servers and no cache memory ( the aforementioned case of @xmath254 ) , we could design an scheme which benefited only two users through pure multiplexing gain .",
    "however , through the proposed strategy , we have designed an scheme which exploited both the global caching and multiplexing gains such that all the three users could take advantage from each transmission .",
    "finally , let us discuss the achievable pair @xmath232 , where we need to adopt a different strategy .",
    "assume we divide each of files @xmath235 , @xmath236 and @xmath237 into three equal parts and fill the caches as follows : @xmath255 \\\\ \\nonumber z_2&=&[a_2+b_2+c_2 ] \\\\",
    "\\nonumber z_3&=&[a_3+b_3+c_3].\\end{aligned}\\ ] ] consequently , the servers transmit the following vectors : @xmath256 it can be easily verified that the first user receives @xmath249 , @xmath250 , and @xmath257 .",
    "so , with the help of its cache content , it can decode the whole file @xmath235 .",
    "similarly , the other users can decode their requested files .",
    "as each block @xmath258 is a @xmath105-by-@xmath259 matrix of symbols , the total delay required to fulfill the users demands is @xmath260 time slots .",
    "example [ examp_linear_2 ] , also , discusses the coding delay for a linear network with four users .",
    "the details of the coding strategy of example [ examp_linear_2 ] , which are provided at appendices b and c , further clarify the basic ideas behind the proposed scheme .",
    "however , in the rest of this section , we provide the formal proof of theorem [ thm_linear ] .",
    "+   + * cache placement strategy : * the cache content placement phase is identical to @xcite : define @xmath261 , and divide each file into @xmath262 non - overlapping sub - files as : @xmath263 , |\\tau|=t\\right ) , n=1,\\dots , n,\\end{aligned}\\ ] ] where each sub - file consists of @xmath264 bits . in the first phase , we store the sub - file @xmath265 in the cache of user @xmath35 if @xmath266 .",
    "therefore , the total amount of cache each user needs for this placement is : @xmath267 bits .",
    "we further divide each sub - file into @xmath268 non - overlapping equal - sized mini - files as follows : @xmath269 thus , each mini - file consists of @xmath270 bits .",
    "+   + * content delivery strategy : * consider an arbitrary @xmath271-subset of users denoted by @xmath272 ( i.e. @xmath273 , |s|=t+l$ ] ) . for",
    "this specific subset @xmath272 denote all @xmath274-subsets of @xmath272 by @xmath275 ( i.e. @xmath276 ) .",
    "first , we assign a @xmath22-by-@xmath104 vector @xmath277 to each @xmath278 such that @xmath279 the following lemma specifies the required field size such that the aforementioned condition is met with high probability :    if the elements of the network transfer matrix @xmath65 are uniformly and independently chosen from @xmath14 , then we can find vectors which satisfy ( [ eq_vector_constraints ] ) with high probability if : @xmath280    first , since the set @xmath281 has @xmath282 elements , we require @xmath277 to be orthogonal to @xmath282 arbitrary vectors , which is feasible in an @xmath22 dimensional space of any field size .",
    "second , the total number of non - orthogonality constraints in ( [ eq_vector_constraints ] ) for all possible subsets @xmath272 is @xmath283 . on the other hand",
    ", it can be easily verified that the probability that two uniformly chosen random vectors in @xmath14 are orthogonal is @xmath284 .",
    "thus , by using the union bound , the probability that at least one non - orthogonality constraint in ( [ eq_vector_constraints ] ) is violated is upper bounded by @xmath285 which concludes the proof .    for each @xmath278",
    "define : @xmath286 where @xmath287 is a mini - file which is available in the cache of all users in @xmath278 , except @xmath288 , and is required by user @xmath288 .",
    "also @xmath289 represents a random linear combination of the corresponding mini - files for all @xmath290 .",
    "note that the index @xmath291 is chosen such that such mini - files have not been observed in the previous @xmath271-subsets .",
    "thus , if we define @xmath292 as the index of the next fresh mini - file required by user @xmath288 , which is present in the cache of users @xmath293 , then we can rewrite : @xmath294 subsequently , we make the following definition for such @xmath271-subset @xmath272 : @xmath295 we repeat the above procedure @xmath296 times for the given @xmath271-subset @xmath272 in order to derive different independent versions of @xmath297 . in other words ,",
    "s only differ in the random coefficients chosen for calculating the linear combinations in ( [ eq_linear_general_gti_1 ] ) , which makes them independent linear combinations of the corresponding mini - files , with high probability .",
    "thus , to distinguish between these different versions notationally we define : @xmath299    subsequently , for this @xmath271-subset @xmath272 , the servers transmit the block @xmath300,\\ ] ] and we update @xmath301 for those mini - files which have appeared in the linear combinations in ( [ eq_linear_general_gti_1 ] ) .",
    "when the above procedure for this specific subset @xmath272 is completed , we consider another @xmath271-subset of users and do the above procedure for that subset , and repeat this process until all @xmath271-subsets of @xmath12 $ ] have been taken into account .",
    "next , let us calculate the coding delay of this scheme , after which we prove the correctness of this content delivery strategy . for a fixed @xmath271-subset @xmath272",
    "each @xmath298 is a @xmath22-by-@xmath302 block of symbols .",
    "thus , the transmit block for @xmath272 , i.e. @xmath303 $ ] , is a @xmath22-by-@xmath304 block .",
    "since this transmission should be repeated for all @xmath305 @xmath271-subsets of users , the whole transmit block size will be @xmath306 which will result in the coding delay of @xmath307 time slots .",
    "algorithm 2 shows the pseudo - code of the aforementioned procedure for linear networks . + * correctness proof * : suppose the user @xmath35 , who is interested in acquiring the file @xmath36 .",
    "this file is partitioned into two parts : 1- the part already cached in this user at the first phase and constitutes of sub - files : @xmath308 , |\\tau|=t , k \\in \\tau\\right).\\end{aligned}\\ ] ] 2- those parts which should be delivered to this user through the content delivery strategy , which constitutes of sub - files : @xmath308 , |\\tau|=t , k \\not \\in \\tau\\right).\\end{aligned}\\ ] ] thus , since due to the following lemma [ lem_linear_proof_2 ] , the sub - files in the second category are successfully delivered to this user through the content delivery strategy , this user will decode the requested file .",
    "moreover , since this user was arbitrarily chosen , all users will similarly decode their requested files .    before proving lemma [ lem_linear_proof_2 ] we need another lemma which is proved first :    [ lem_linear_proof_1 ]",
    "suppose an arbitrary subset @xmath309 $ ] such that @xmath310 , and @xmath311 .",
    "then , through the above content placement and delivery strategy , user @xmath35 will be able to decode the sub - file @xmath312 .",
    "consider those transmissions which are assigned to the @xmath271-subsets which contain @xmath2 .",
    "there exist @xmath268 of such subsets .",
    "let us focus on one of them , namely @xmath272 .",
    "corresponding to @xmath272 , the following transmit block is sent by the servers : @xmath313,\\end{aligned}\\ ] ] and subsequently , user @xmath35 receives : @xmath314.\\end{aligned}\\ ] ] let s focus on @xmath315 : @xmath316 where ( a ) follows from ( [ eq_linear_proof_x_s ] ) , ( b ) follows from the fact that @xmath317 and ( c ) is due to ( [ eq_linear_proof_g_t ] ) . in ( [ eq_linear_proof_recieve_k_2 ] ) , user @xmath35 can extract @xmath318 from the linear combination @xmath319 , since all the other interference terms are present at his cache .",
    "thus , by removing interference terms , user @xmath35 can carve the following linear combination from ( [ eq_linear_proof_recieve_k_2 ] ) : @xmath320 which is a random linear combination of @xmath296 mini - files desired by user @xmath35 .",
    "however , since in ( [ eq_linear_proof_recieve_k_1 ] ) user @xmath35 receives @xmath296 independent random linear combinations of these mini - files , he can recover the whole set of mini - files : @xmath321 thus , for the @xmath2 specified in this lemma , he can recover the mini - file @xmath318 .",
    "now , since there exist a total of @xmath268 @xmath271-subsets containing this specific @xmath2 , by considering the transmissions corresponding to each , this user will recover @xmath268 _ distinct _ mini - files of form @xmath318 . the distinctness is guaranteed by the appropriate updating of the index @xmath322 .",
    "these mini - files will recover the sub - file @xmath323 and the proof is concluded .",
    "[ lem_linear_proof_2 ] through the above content delivery strategy an arbitrary user @xmath35 will be able to decode all the sub - files : @xmath308 , |\\tau|=t , k \\not \\in \\tau\\right).\\end{aligned}\\ ] ]    consider an arbitrary @xmath324 $ ] such that @xmath325 .",
    "define @xmath326 .",
    "then , since to lemma [ lem_linear_proof_1 ] , user @xmath35 is able to decode @xmath327 .",
    "since @xmath328 was chosen arbitrarily , the proof is complete .",
    "[ alg_main ]    @xmath329 split @xmath151 into @xmath330 , |\\tau|=t)$ ] of equal size split @xmath265 into @xmath331 of equal size @xmath332 , |\\tau|=t , k \\in \\tau , j=1,\\dots,{k - t-1 \\choose l-1 } , n \\in [ n])$ ] + @xmath329 @xmath333 design @xmath334 such that : for all @xmath335 , @xmath336 if @xmath337 and @xmath338 if @xmath339    @xmath340 @xmath341    * transmit * @xmath342 $ ]    @xmath343",
    "in this paper , we investigated coded caching in a multi - server network where servers are connected to multiple cache - enabled clients .",
    "based on the topology of the network , we defined three types of networks , namely , dedicated , flexible , and linear networks . in dedicated and flexible networks , we assume that the internal nodes are aware of the network topology , and accordingly route the data . in linear networks , we assume no topology knowledge at internal nodes , and thus , internal nodes perform random linear network coding .",
    "we have shown that knowledge of type of network topology plays a key role in design of proper caching mechanisms in such networks .",
    "our results show that all network types can benefit from both caching and multiplexing gains .",
    "in fact , in dedicated and linear networks the global caching and multiplexing gains appear in additive form .",
    "however , in flexible networks they appear in multiplicative form , leading to an order - optimal solution in terms of coding delay .",
    "1    j. kangasharju , j. roberts , and k. ross , `` object replication strategies in content distribution networks , '' _ computer communications _ , vol .",
    "376 - 383 , 2002 .",
    "i. baev , r. rajaraman , and c. swamy , `` approximation algorithms for data placement problems , '' _ siam journal on computing _ , vol .",
    "4 , pp . 1411 - 1429 , 2008 .",
    "l. w. dowdy and d. v. foster , `` comparative models of the file assignment problem , '' _ acm computing surveys _ , vol .",
    "287 - 313 , 1982 .",
    "s. podlipnig and s. boszormenyi , `` a survey of web cache replacement strategies '' , _ acm computing surveys _ , vol .",
    "374 - 398 , 2003 .",
    "s. borst , v. gupta , and a. walid , `` distributed caching algorithms for content distribution networks '' , _ proc . of ieee infocom 2010 _ , san diego - ca , march 2010 , pp . 1 - 9 .",
    "s. gitzenis , g. s. paschos , and l. tassiulas , `` asymptotic laws for joint content replication and delivery in wireless networks , '' _ proc . of ieee infocom 2012 _ , orlando - fl , march 2012 , pp . 531 - 539 .",
    "m. a. maddah - ali and u. niesen , `` fundamental limits of caching , '' _ ieee transactions on information theory _ , vol .",
    "2856 - 2867 , 2014 .",
    "m. a. maddah - ali and u. niesen , `` decentralized caching attains order - optimal memory - rate tradeoff , '' accepted for publication in _",
    "ieee / acm transactions on networking _ , 2014 .",
    "s. y. r. li , r. w. yeung , and n. cai , `` linear network coding , '' _ ieee transactions on information theory _ , vol .",
    "371 - 381 , 2003 .",
    "s. yang and r. w. yeung , `` coding for a network coded fountain , '' _ proc . of ieee isit 2011 _ , st .",
    "petersburg , august 2011 , pp .",
    "2647 - 2651 .",
    "m. j. siavoshani , c. fragouli , and s. diggavi , `` non - coherent multi - source network coding , '' _ proc . of ieee isit 2011 _ , toronto - on , july 2008 , pp .",
    "817 - 821 .",
    "m. j. siavoshani , s. mohajer , c. fragouli , and s. n. diggavi , `` on the capacity of non - coherent network coding , '' _ ieee transactions on information theory _ , vol .",
    "2 , pp . 1046 - 1066 , 2011 .",
    "d. silva , f. r. kschischang , and r. kotter , `` communication over finite - field matrix channels , '' _ ieee transactions on information theory _",
    "1296 - 1305 , 2010 .",
    "s. yang , s .- w . ho , j. meng , e .- h .",
    "yang , and r. w. yeung , `` linear operator channels over finite fields , '' corr , vol .",
    "abs/1002.2293 , 2010 .",
    "[ online ] .",
    "available : http://arxiv.org/abs/1002.2293    y. chen , r. h. katz , and j. d. kubiatowicz , `` dynamic replica placement for scalable content delivery , '' _ lecture notes in computer science _ ,",
    "vol . 2429 , pp .",
    "306 - 318 , 2002 .",
    "a. vakali and g. pallis , `` content delivery networks : status and trends , '' _",
    "ieee internet computing _ ,",
    "vol . 7 , no .",
    "68 - 74 , 2003 .",
    "u. niesen and m. a. maddah - ali , `` coded caching for delay - sensitive content , '' arxiv:1407.4489v1 [ cs.it ] 16 jul 2014 .",
    "a. das , s. vishwanath , s. a. jafar , and a. markopoulou , `` network coding for multiple unicasts : an interference alignment approach '' , _ proc .",
    "of ieee isit 2011 _ , austin - tx , june 2010 , pp .",
    "1878 - 1882 .    c. meng , a. ramakrishnan , a. markopoulou , and s. a. jafar , `` on the feasibility of precoding - based network alignment for three unicast sessions , '' _ proc . of ieee isit 2012 _ , cambridge - ma , pp .",
    "1907 - 1911 .    c. meng , a. das , a. ramakrishnan , s. a. jafar , a. markopoulou , and s. vishwanath , `` precoding - based network alignment for three unicast sessions , '' may 2013 , e - print arxiv:1305.0868 .",
    "m. sharif and b. hassibi , `` on the capacity of mimo broadcast channels with partial side information '' _ ieee transactions on information theory _ , vol .",
    "506 - 522 , 2005 .",
    ", scaledwidth=60.0% ]    the proof is similar to the cut - set method presented in @xcite .",
    "[ fig_converse_proof ] and let us concentrate on the first @xmath344 users . define @xmath345 to be the transmit block sent by the servers such that these users , with the help of their cache contents @xmath346 , will be able to decode @xmath347 . also , define @xmath348 to be the block which enables the users to decode @xmath349 , and continue the same process such that @xmath350 is the block which enables the users to decode @xmath351 . also , define @xmath352 to be the maximum information needed to pass through the two cuts shown in the figure , by each transmit block transmission .",
    "then we will have : @xmath353 which will result in @xmath354 however , we have : @xmath355 now we can maximize on the free parameter @xmath344 to arrive at the tightest bound , which concludes the proof .",
    "in this appendix , we consider the scenario in example [ examp_linear_2 ] for the case of two servers .",
    "for each memory size @xmath357 , we present the scheme which achieves the coding delay as stated in example [ examp_linear_2 ] .",
    "* @xmath254 + in this case , we do not have any cache space available at the users .",
    "suppose we divide each file into three equal - sized non - overlapping parts : @xmath358 \\\\",
    "\\nonumber b&=&[b^1,b^2,b^3 ] \\\\",
    "\\nonumber c&=&[c^1,c^2,c^3 ] \\\\",
    "\\nonumber d&=&[d^1,d^2,d^3].\\end{aligned}\\ ] ] then , the servers transmit the following blocks , in sequence : @xmath359 let s focus on the first user which receives : @xmath360 from the above data , this user can recover the whole file @xmath235 .",
    "similarly , other users can decode their requested files .",
    "+ the transmission stated in ( [ eq_l2_k4_n4_m0_transmit ] ) consists of six blocks of size @xmath105-by-@xmath259 , resulting in a coding delay of @xmath361 . * @xmath96 + consider the cache content placement used in @xcite : first divide each file into @xmath144 equal - sized non - overlapping sub - files : @xmath362 \\\\",
    "\\nonumber b&=&[b_1,b_2,b_3,b_4 ] \\\\",
    "\\nonumber c&=&[c_1,c_2,c_3,c_4 ] \\\\",
    "\\nonumber d&=&[d_1,d_2,d_3,d_4],\\end{aligned}\\ ] ] and then , fill the caches as follows : @xmath363 \\\\ \\nonumber z_2&=&[a_2,b_2,c_2,d_2 ] \\\\",
    "\\nonumber z_3&=&[a_3,b_3,c_3,d_3 ] \\\\ \\nonumber z_4&=&[a_4,b_4,c_4,d_4].\\end{aligned}\\ ] ] such placement respects the memory constraint of @xmath96 .",
    "also , divide each sub - file into two equal parts of size @xmath364 bits : @xmath365 ,   \\\\",
    "\\nonumber b_i&=&[b_i^1,b_i^2 ] ,   \\\\ \\nonumber c_i&=&[c_i^1,c_i^2 ] ,   \\\\ \\nonumber d_i&=&[d_i^1,d_i^2 ] , \\end{aligned}\\ ] ] where @xmath366 . in the second phase",
    ", we send the following blocks of size @xmath105-by-@xmath367 bits : @xmath368 \\\\",
    "\\nonumber \\mathbf{x}(\\{1,2,4\\})&=&[\\mathbf{h}_1^{\\perp } l_{\\{2,4\\}}^1(b_4 ^ 1,d_2 ^ 1)+\\mathbf{h}_2^{\\perp } l_{\\{1.4\\}}^1(a_4 ^ 1,d_1 ^ 1)+\\mathbf{h}_4^{\\perp } l_{\\{1,2\\}}^1(a_2 ^ 2,b_1 ^ 2 ) , \\\\",
    "\\nonumber & & \\mathbf{h}_1^{\\perp } l_{\\{2,4\\}}^2(b_4 ^ 1,d_2 ^ 1)+\\mathbf{h}_2^{\\perp } l_{\\{1,4\\}}^2(a_4 ^ 1,d_1 ^ 1)+\\mathbf{h}_4^{\\perp }",
    "l_{\\{1,2\\}}^2(a_2 ^ 2,b_1 ^ 2 ) ] \\\\ \\nonumber \\mathbf{x}(\\{1,3,4\\})&=&[\\mathbf{h}_1^{\\perp}l_{\\{3,4\\}}^1(c_4 ^ 1,d_3 ^ 1)+\\mathbf{h}_3^{\\perp}l_{\\{1,4\\}}^1(a_4 ^ 2,d_1 ^ 2)+\\mathbf{h}_4^{\\perp}l_{\\{1,3\\}}^1(a_3 ^ 2,c_1 ^ 2 ) , \\\\",
    "\\nonumber & & \\mathbf{h}_1^{\\perp}l_{\\{3,4\\}}^2(c_4 ^ 1,d_3 ^ 1)+\\mathbf{h}_3^{\\perp}l_{\\{1,4\\}}^2(a_4 ^ 2,d_1 ^ 2)+\\mathbf{h}_4^{\\perp}l_{\\{1,3\\}}^2(a_3 ^ 2,c_1 ^ 2 ) ] \\\\",
    "\\nonumber \\mathbf{x}(\\{2,3,4\\})&=&[\\mathbf{h}_2^{\\perp}l_{\\{3,4\\}}^1(c_4 ^ 2,d_3 ^ 2)+\\mathbf{h}_3^{\\perp}l_{\\{2,4\\}}^1(b_4 ^ 2,d_2 ^ 2)+\\mathbf{h}_4^{\\perp}l_{\\{2,3\\}}^1(b_3 ^ 2,c_2 ^ 2 ) , \\\\",
    "\\nonumber & & \\mathbf{h}_2^{\\perp}l_{\\{3,4\\}}^2(c_4 ^ 2,d_3 ^ 2)+\\mathbf{h}_3^{\\perp}l_{\\{2,4\\}}^2(b_4 ^ 2,d_2 ^ 2)+\\mathbf{h}_4^{\\perp}l_{\\{2,3\\}}^2(b_3 ^ 2,c_2 ^ 2 ) ] .",
    "\\\\\\end{aligned}\\ ] ] let s focus on the first user . from the above transmissions he recovers : @xmath369 \\\\ \\nonumber & = & [ l^1(a_3 ^ 1,c_1 ^ 1,a_2 ^ 1,b_1 ^ 1),l^2(a_3 ^ 1,c_1 ^ 1,a_2 ^ 1,b_1 ^ 1 ) ] \\\\",
    "\\nonumber \\mathbf{h}_1 .",
    "\\mathbf{x}(\\{1,2,4\\})&=&[(\\mathbf{h}_1.\\mathbf{h}_2^{\\perp } ) l_{\\{1,4\\}}^1(a_4 ^ 1,d_1 ^ 1)+(\\mathbf{h}_1.\\mathbf{h}_4^{\\perp } ) l_{\\{1,2\\}}^1(a_2 ^ 2,b_1 ^ 2 ) , \\\\",
    "\\nonumber & & ( \\mathbf{h}_1.\\mathbf{h}_2^{\\perp } ) l_{\\{1,4\\}}^2(a_4 ^ 1,d_1 ^ 1)+(\\mathbf{h}_1.\\mathbf{h}_4^{\\perp } ) l_{\\{1,2\\}}^2(a_2 ^ 2,b_1 ^ 2 ) ] \\\\ \\nonumber & = & [ l^1(a_4 ^ 1,d_1 ^ 1,a_2 ^ 2,b_1 ^ 2),l^2(a_4 ^ 1,d_1 ^ 1,a_2 ^ 2,b_1 ^ 2 ) ] \\\\ \\nonumber \\mathbf{h}_1 .\\mathbf{x}(\\{1,3,4\\})&=&[(\\mathbf{h}_1 .\\mathbf{h}_3^{\\perp})l_{\\{1,4\\}}^1(a_4 ^ 2,d_1 ^ 2)+(\\mathbf{h}_1 .\\mathbf{h}_4^{\\perp})l_{\\{1,3\\}}^1(a_3 ^ 2,c_1 ^ 2 ) , \\\\",
    "\\nonumber & & ( \\mathbf{h}_1 .\\mathbf{h}_3^{\\perp})l_{\\{1,4\\}}^2(a_4 ^ 2,d_1 ^ 2)+(\\mathbf{h}_1 .\\mathbf{h}_4^{\\perp})l_{\\{1,3\\}}^2(a_3 ^ 2,c_1 ^ 2 ) ] \\\\ \\nonumber & = & [ l^1(a_4 ^ 2,d_1 ^ 2,a_3 ^ 2,c_1 ^ 2),l^2(a_4 ^ 2,d_1 ^ 2,a_3 ^ 2,c_1 ^ 2 ) ] .",
    "\\\\\\end{aligned}\\ ] ] ( although user 1 also receives @xmath370 , such information is of no value to him . ) with the help of its cache contents the first user can eliminate the undesired terms and obtain : @xmath371 \\rightarrow a_3 ^ 1,a_2 ^ 1 \\\\ \\nonumber & & [ l(a_4 ^ 1,a_2 ^ 2),l'(a_4 ^ 1,a_2 ^ 2 ) ] \\rightarrow a_4 ^ 1,a_2 ^ 2 \\\\ \\nonumber & & [ l(a_4 ^ 2,a_3 ^ 2),l'(a_4 ^ 2,a_3 ^ 2 ) ] \\rightarrow a_4 ^ 2,a_3 ^ 2.\\end{aligned}\\ ] ] since @xmath372 and @xmath373 is already available in first user s cache location , he can subsequently recover the whole block @xmath235 .",
    "similarly , all other users can recover their requested files .",
    "+ the transmission scheme adopted in ( [ eq_l2_k4_n4_m1_transmit ] ) consists of four @xmath105-by-@xmath374 blocks which will result in the coding delay @xmath375 time slots",
    ". * @xmath87 + consider the cache content placement used in @xcite : first divide each file into @xmath376 equal - sized non - overlapping sub - files : @xmath377 \\\\ \\nonumber b&=&[b_1,b_2,b_3,b_4,b_5,b_6 ] \\\\ \\nonumber c&=&[c_1,c_2,c_3,c_4,c_5,c_6 ] \\\\",
    "\\nonumber d&=&[d_1,d_2,d_3,d_4,d_5,d_6],\\end{aligned}\\ ] ] and then , fill the caches as follows : @xmath378 \\\\ \\nonumber z_2&=&[a_1,a_4,a_5,b_1,b_4,b_5,c_1,c_4,c_5,d_1,d_4,d_5 ] \\\\",
    "\\nonumber z_3&=&[a_2,a_4,a_6,b_2,b_4,b_6,c_2,c_4,c_6,d_2,d_4,d_6 ] \\\\ \\nonumber z_4&=&[a_3,a_5,a_6,b_3,b_5,b_6,c_3,c_5,c_6,d_3,d_5,d_6].\\end{aligned}\\ ] ] in the second phase , we send the following block of symbols of size @xmath105-by-@xmath379 : @xmath380 . \\\\\\end{aligned}\\ ] ] let s focus on the first user who receives : @xmath381.\\end{aligned}\\ ] ] this user also has the unwanted terms @xmath382 in his cache , and after removing them from above linear combinations he has three different linear combinations of its required terms @xmath383 , @xmath384 , and @xmath385 .",
    "after solving these equations , and with the help of @xmath251 , @xmath249 , and @xmath250 stored in his cache , he can recover the whole file @xmath235 .",
    "similarly the other users are able to decode their required files .",
    "+ the transmit block stated in ( [ eq_l2_k4_n4_m2_transmit ] ) is of size @xmath105-by-@xmath379 vector , resulting in @xmath386 time slots .",
    "* @xmath387 + in this case , by the scheme proposed in @xcite , all four users can get useful information through a single transmission from a single server .",
    "thus , we can not further reduce the delay by activating the other server .",
    "thus , by activating just one server and based on @xcite a coding delay of @xmath388 time slots is obtained .",
    "* @xmath389 + in the case of @xmath389 , all four files can be stored in the cache of each user , and the required delivery delay in the second phase is zero @xmath390 .",
    "in this example , we consider the three server case in example [ examp_linear_2 ] , and for all values of @xmath357 present the schemes that lead to achievable rates .",
    "* @xmath254 + in this case , we do not have any cache space available at the user locations .",
    "suppose we divide each file into three equal - sized non - overlapping parts : @xmath358 \\\\",
    "\\nonumber b&=&[b^1,b^2,b^3 ] \\\\",
    "\\nonumber c&=&[c^1,c^2,c^3 ] \\\\",
    "\\nonumber d&=&[d^1,d^2,d^3].\\end{aligned}\\ ] ] the three servers can then send the following @xmath230-by-@xmath104 vectors : @xmath392 where we require @xmath393 in this example , since we have three dimensional transmit vectors ( three servers ) and @xmath394 , such vectors can be found . + let s focus on the first user who receives : @xmath395 the first user can then successfully decode its requested file .",
    "similarly , the other users will also be able to decode their requested files .",
    "+ the transmission stated in ( [ eq_l3_k4_n4_m0_transmit ] ) consists of four @xmath230-by-@xmath259 blocks , resulting in @xmath396 time slots .",
    "* @xmath96 + the cache content placement is the same as @xcite .",
    "then , the transmit block by the three servers is : @xmath397,\\ ] ] where ( for @xmath398 ) @xmath399 + now let s focus on the first user who receives : @xmath400.\\ ] ] let s consider first the term : @xmath401 as this user has cached @xmath402 in the first phase , it can remove these terms from this linear combination to obtain @xmath403 thus , user @xmath104 can recover a linear combination of its requested sub - files from @xmath404 . from , @xmath405 and @xmath406 he can obtain two other independent linear combinations from which he can recover all three subfiles @xmath407 . since he already has @xmath251 in his cache , he can decode the whole @xmath235 file . similarly , all the other users can also decode their requested files .",
    "+ the transmit block stated in ( [ eq_l3_k4_n4_m1_transmit ] ) consists of one @xmath230-by-@xmath408 vectors , resulting in @xmath409 time slots . * @xmath87 in this case , we only activate two of the servers and thus the problem reduces to the case with @xmath356 for which we achieved @xmath386 .",
    "* @xmath387 in this case , we only activate one server and thus the problem reduces to @xcite with @xmath388 .",
    "* @xmath389 in this case we have @xmath390 ."
  ],
  "abstract_text": [
    "<S> in this paper , we consider multiple cache - enabled clients connected to multiple servers through an intermediate network . </S>",
    "<S> we design several topology - aware coding strategies for such networks . based on topology richness of the intermediate network , and types of coding operations at internal nodes , </S>",
    "<S> we define three classes of networks , namely , dedicated , flexible , and linear networks . for each class , </S>",
    "<S> we propose an achievable coding scheme , analyze its coding delay , and also , compare it with an information theoretic lower bound . for flexible networks , we show that our scheme is order - optimal in terms of coding delay and , interestingly , the optimal memory - delay curve is achieved in certain regimes . in general , our results suggest that , in case of networks with multiple servers , type of network topology can be exploited to reduce service delay . </S>"
  ]
}