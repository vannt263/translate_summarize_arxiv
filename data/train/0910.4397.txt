{
  "article_text": [
    "this paper studies learning problems of the following form . consider a finite , but potentially very large , collection of binary - valued functions @xmath2 defined on a domain @xmath3 . in this paper , @xmath2 will be called the _ hypothesis space _ and @xmath3 will be called the _ query space_. each @xmath4 is a mapping from @xmath3 to @xmath5 . throughout the paper",
    "we will let @xmath0 denote the cardinality of @xmath2 .",
    "assume that the functions in @xmath2 are unique and that one function , @xmath6 , produces the correct binary labeling .",
    "it is assumed that @xmath7 is fixed but unknown , and the goal is to determine @xmath7 through as few queries from @xmath3 as possible . for each query @xmath8 , the value @xmath9 , possibly corrupted with independently distributed binary noise , is observed .",
    "the goal is to strategically select queries in a sequential fashion in order to identify @xmath7 as quickly as possible .",
    "conditions are established under which gbs ( and a noise - tolerant variant ) have a near - optimal query complexity .",
    "the main contributions of this paper are two - fold .",
    "first , incoherence and geometric relations between the pair @xmath10 are studied to bound the number of queries required by gbs .",
    "this leads to an easily verifiable sufficient condition that guarantees that gbs terminates with the correct hypothesis after no more than a constant times @xmath11 queries .",
    "second , noise - tolerant versions of gbs are proposed .",
    "the following noise model is considered .",
    "the binary response @xmath12 to a query @xmath8 is an independent realization of the random variable @xmath13 satisfying @xmath14 , where @xmath15 denotes the underlying probability measure . in other words ,",
    "the response to @xmath16 is only probably correct .",
    "if a query @xmath16 is repeated more than once , then each response is an independent realization of @xmath13 . a new algorithm based on a weighted ( soft - decision ) gbs procedure",
    "is shown to confidently identify @xmath7 after a constant times @xmath1 queries even in the presence of noise ( under the sufficient condition mentioned above ) .",
    "an agnostic algorithm that performs well even if @xmath7 is not in the hypothesis space @xmath2 is also proposed .",
    "the following notation will be used throughout the paper .",
    "the hypothesis space @xmath2 is a finite collection of binary - valued functions defined on a domain @xmath3 , which is called the query space .",
    "each @xmath4 is a mapping from @xmath3 to @xmath5 . for any subset @xmath17",
    ", @xmath18 denotes the number of hypotheses in @xmath19 . the number of hypotheses in @xmath2 is denoted by @xmath20 .",
    "the efficiency of classic binary search is due to the fact at each step there exists a query that splits the pool of viable hypotheses in half .",
    "the existence of such queries is a result of the special ordered structure of the problem . because of ordering",
    ", optimal query locations are easily identified by bisection . in the general",
    "setting in which the query and hypothesis space are arbitrary it is impossible to order the hypotheses in a similar fashion and `` bisecting '' queries may not exist .",
    "for example , consider hypotheses associated with halfspaces of @xmath21 .",
    "each hypothesis takes the value @xmath22 on its halfspace and @xmath23 on the complement .",
    "a bisecting query may not exist in this case . to address such situations",
    "we next introduce a more general framework that does not require an ordered structure .",
    "while it may not be possible to naturally order the hypotheses within @xmath3 , there does exist a similar local geometry that can be exploited in the search process .",
    "observe that the query space @xmath3 can be partitioned into equivalence subsets such that every @xmath4 is constant for all queries in each such subset .",
    "let @xmath24 denote the smallest such partition splits @xmath3 into two disjoint sets .",
    "let @xmath25 and let @xmath26 denote its complement .",
    "@xmath27 is the collection of all non - empty intersections of the form @xmath28 , where @xmath29 , and it is the smallest partition that refines the sets @xmath30 .",
    "@xmath27 is known as the _ join _ of the sets @xmath30 . ] .",
    "note that @xmath31 .",
    "for every @xmath32 and @xmath4 , the value of @xmath33 is constant ( either @xmath22 or @xmath23 ) for all @xmath34 ; denote this value by @xmath35 .",
    "observe that the query selection step in gbs is equivalent to an optimization over the partition cells in @xmath27 .",
    "that is , it suffices to select a partition cell for the query according to @xmath36 .",
    "the main results of this paper concern the query complexity of gbs , but before moving on let us comment on the computational complexity of the algorithm .",
    "the query selection step is the main computational burden in gbs .",
    "however , given @xmath27 the computational complexity of gbs is @xmath37 , up to a constant factor , where @xmath38 denotes the number of partition cells in @xmath27 .",
    "the size and construction of @xmath27 is manageable in many practical situations .",
    "for example , if @xmath3 is finite , then @xmath39 , where @xmath40 is the cardinality of @xmath3 . later , in section  [ linear ] , we show that if @xmath2 is defined by @xmath0 halfspaces of @xmath41 , then @xmath38 grows like @xmath42 .",
    "the partition @xmath27 provides a geometrical link between @xmath3 and @xmath2 .",
    "the hypotheses induce a distance function on @xmath27 , and hence @xmath3 . for every pair @xmath43 the hamming distance between the response vectors @xmath44 and",
    "@xmath45 provides a natural distance metric in @xmath3 .",
    "two sets @xmath46 are said to be _ @xmath47-neighbors _ if @xmath47 or fewer hypotheses ( along with their complements , if they belong to @xmath2 ) output different values on @xmath48 and @xmath49 .",
    "[ neighbor ]    for example , suppose that @xmath2 is symmetric , so that @xmath4 implies @xmath50 .",
    "then two sets @xmath48 and @xmath49 are @xmath47-neighbors if the hamming distance between their respective response vectors is less than or equal to @xmath51 . if @xmath2 is non - symmetric ( @xmath52 implies that @xmath53 is not in @xmath2 ) , then @xmath48 and @xmath49 are @xmath47-neighbors if the hamming distance between their respective response vectors is less than or equal to @xmath47 .",
    "the pair @xmath10 is said to be _",
    "@xmath47-neighborly _ if the @xmath47-neighborhood graph of @xmath27 is connected ( i.e. , for every pair of sets in @xmath27 there exists a sequence of @xmath47-neighbor sets that begins at one of the pair and ends with the other ) .",
    "[ neighborly ]    if @xmath10 is @xmath47-neighborly , then the distance between @xmath48 and @xmath49 is bounded by @xmath47 times the minimum path length between @xmath48 and @xmath49 . moreover",
    ", the neighborly condition implies that there is an incremental way to move from one query to the another , moving a distance of at most @xmath47 at each step .",
    "this local geometry guarantees that near - bisecting queries almost always exist , as shown in the following lemma .",
    "_ assume that @xmath10 is @xmath47-neighborly and define the coherence parameter @xmath54 where the minimization is over all probability mass functions on @xmath27 . for every @xmath55 and any constant @xmath56 satisfying @xmath57 there exists an @xmath32 that approximately bisects @xmath19 @xmath58 or",
    "the set @xmath19 is a small @xmath59 where @xmath18 denotes the cardinality of @xmath19 .",
    "_ [ lemma1 ]    _ proof : _ according to the definition of @xmath60 it follows that there exists a probability distribution @xmath61 such that @xmath62 this implies that there exists an @xmath32 such that @xmath63 or there exists a pair @xmath48 and @xmath49 such that @xmath64 in the former case , it follows that a query from @xmath48 will reduce the size of @xmath19 by a factor of at least @xmath65 ( i.e. , every query @xmath66 approximately bisects the subset @xmath19 ) . in latter case , an approximately bisecting query does not exist , but the @xmath47-neighborly condition implies that @xmath18 must be small . to see this note that the @xmath47-neighborly condition guarantees that there exists a sequence of @xmath47-neighbor sets beginning at @xmath48 and ending at @xmath49 . by assumption in this case , @xmath67 on every set and",
    "the sign of @xmath68 must change at some point in the sequence .",
    "it follows that there exist @xmath47-neighbor sets @xmath48 and @xmath49 such that @xmath69 and @xmath70 .",
    "two inequalities follow from this observation .",
    "first , @xmath71 .",
    "second , @xmath72 .",
    "note that if @xmath73 and its complement @xmath74 belong to @xmath19 , then their contributions to the quantity @xmath75 cancel each other . combining these inequalities yields @xmath76 . @xmath77     and @xmath78 . without loss of generality",
    "we may assume that all hypotheses agree with @xmath7 at these two points .",
    "the dashed path between the points @xmath79 and @xmath80 reveals a bisecting query location .",
    "as the path crosses a decision boundary the corresponding hypothesis changes its output from @xmath22 to @xmath23 ( or vice - versa , depending on the direction followed ) . at a certain point , indicated by the shaded cell , half of the hypotheses output @xmath22 and half output @xmath23 .",
    "selecting a query from this cell will _ bisect _ the collection of hypotheses .",
    ", title=\"fig:\",width=377 ]       the coherence parameter @xmath60 quantifies the informativeness of queries .",
    "the coherence parameter is optimized over the choice of @xmath61 , rather than sampled at random according to a specific distribution on @xmath3 , because the queries may be selected as needed from @xmath3 .",
    "the minimizer in ( [ cstar ] ) exists because the minimization can be computed over the space of finite - dimensional probability mass functions over the elements of @xmath27 . for @xmath60 to be close to @xmath81 , there must exist a distribution @xmath61 on @xmath27 so that the moment of every @xmath82 is close to zero ( i.e. , for each @xmath4 the probabilities of the responses @xmath22 and @xmath23 are both close to @xmath83 ) .",
    "this implies that there is a way to randomly sample queries so that the expected response of every hypothesis is close to zero . in this sense ,",
    "the queries are incoherent with the hypotheses . in lemma  [ lemma1 ] , @xmath60 bounds the proportion of the split of _ any _ subset @xmath19 generated by the best query ( i.e. , the degree to which the best query bisects any subset @xmath19 ) .",
    "the coherence parameter @xmath84 leads to a bound on the number of queries required by gbs .     _",
    "if @xmath10 is @xmath47-neighborly , then gbs terminates with the correct hypothesis after at most @xmath85 queries , where @xmath86 .",
    "_ [ thm1 ]    _ proof : _ consider the @xmath87th step of the gbs algorithm .",
    "lemma  [ lemma1 ] shows that for any @xmath88 either there exists an approximately bisecting query and @xmath89 or @xmath90 .",
    "the uniqueness of the hypotheses with respect to @xmath3 implies that there exists a query that eliminates at least one hypothesis .",
    "therefore , @xmath91 .",
    "it follows that each gbs query reduces the number of viable hypotheses by a factor of at least @xmath92 therefore , @xmath93 and gbs is guaranteed to terminate when @xmath87 satisfies @xmath94 .",
    "taking the logarithm of this inequality produces the query complexity bound .",
    "theorem  [ thm1 ] demonstrates that if @xmath10 is neighborly , then the query complexity of gbs is near - optimal ; i.e. , within a constant factor of @xmath95 . the constant depends on coherence parameter @xmath60 and @xmath47 , and clearly it is desirable that both are as small as possible .",
    "note that gbs does not require knowledge of @xmath60 or @xmath47 .",
    "we also remark that the constant in the bound is not necessarily the best that one can obtain .",
    "the proof involves selecting @xmath56 to balance splitting factor @xmath96 and the `` tail '' behavior @xmath97 , and this may not give the best bound .",
    "the coherence parameter @xmath60 can be computed or bounded for many pairs @xmath10 that are commonly encountered in applications , as covered later in section  [ coherence ] .",
    "in noisy problems , the search must cope with erroneous responses .",
    "specifically , assume that for any query @xmath8 the binary response @xmath12 is an independent realization of the random variable @xmath13 satisfying @xmath14 ( i.e. , the response is only probably correct ) .",
    "if a query @xmath16 is repeated more than once , then each response is an independent realization of @xmath13 . define the _ noise - level _ for the query @xmath16 as @xmath98 . throughout the paper we will let @xmath99 and assume that @xmath100 . before presenting the main approach to noisy gbs , we first consider a simple strategy based on repetitive querying that will serve as a benchmark for comparison .",
    "we begin by describing a simple noise - tolerant version of gbs .",
    "the noise - tolerant algorithm is based on the simple idea of repeating each query of the gbs several times , in order to overcome the uncertainty introduced by the noise .",
    "similar approaches are proposed in the work k \" a \" ari \" ainen @xcite . karp and kleinberg @xcite analyze of this strategy for noise - tolerant classic binary search .",
    "this is essentially like using a simple repetition code to communicate over a noisy channel .",
    "this procedure is termed noise - tolerant gbs ( ngbs ) and is summarized in fig .  [",
    "fig : ngbs ] .",
    "[ thm : ngbs ]    consider a specific query @xmath101 repeated @xmath102 times , let @xmath103 denote the frequency of @xmath22 in the @xmath102 trials , and let @xmath104 $ ] .",
    "the majority vote decision is correct if @xmath105 . by chernoff s",
    "bound we have @xmath106 .",
    "the results follows by the union bound .    based on the bound above",
    ", @xmath102 must satisfy @xmath107 to guarantee that the labels determined for all @xmath108 queries are correct with probability @xmath109 .",
    "the query complexity of ngbs can thus be bounded by @xmath110 recall that @xmath111 , the cardinality of @xmath2 . if @xmath112 , then bound on the query complexity of ngbs is proportional to @xmath113 , a logarithmic factor worse than the query complexity in the noiseless setting . moreover ,",
    "if an upper bound on @xmath108 is not known in advance , then one must assume the worst - case value , @xmath114 , in order to set @xmath102 .",
    "that is , in order to guarantee that the correct hypothesis is determined with probability at least @xmath109 , the required number of repetitions of each query is @xmath115 in this situation , the bound on the query complexity of ngbs is proportional to @xmath116 , compared to @xmath117 in the noiseless setting .",
    "it is conjectured that the extra logarithmic factor can not be removed from the query complexity ( i.e. , it is unavoidable using repetitive queries ) . as we show next ,",
    "these problems can be eliminated by a more sophisticated approach to noisy gbs .",
    "a more effective approach to noisy gbs is based on the following soft - decision procedure .",
    "a similar procedure has been shown to be near - optimal for the noisy ( classic ) binary search problem by burnashev and zigangirov @xcite and later independently by karp and kleinberg @xcite .",
    "the crucial distinction here is that gbs calls for a more general approach to query selection and a fundamentally different convergence analysis .",
    "let @xmath118 be a known probability measure over @xmath2 .",
    "that is , @xmath119 $ ] and @xmath120 .",
    "the measure @xmath118 can be viewed as an initial weighting over the hypothesis class .",
    "for example , taking @xmath118 to be the uniform distribution over @xmath2 expresses the fact that all hypothesis are equally reasonable prior to making queries .",
    "we will assume that @xmath118 is uniform for the remainder of the paper , but the extension to other initial distributions is trivial .",
    "note , however , that we still assume that @xmath6 is fixed but unknown .",
    "after each query and response @xmath121 @xmath122 the distribution is updated according to @xmath123 where @xmath124 , @xmath125 is any constant satisfying @xmath126 , and @xmath127 is normalized to satisfy @xmath128 .",
    "the update can be viewed as an application of bayes rule and its effect is simple ; the probability masses of hypotheses that agree with the label @xmath129 are boosted relative to those that disagree .",
    "the parameter @xmath125 controls the size of the boost .",
    "the hypothesis with the largest weight is selected at each step : @xmath130 if the maximizer is not unique , one of the maximizers is selected at random . note that , unlike the hard - decisions made by the gbs algorithm in fig .",
    "[ fig : gbs ] , this procedure does not eliminate hypotheses that disagree with the observed labels , rather the weight assigned to each hypothesis is an indication of how successful its predictions have been .",
    "thus , the procedure is termed soft - decision gbs ( sgbs ) and is summarized in fig .  [",
    "fig : sgbs ] .",
    "the goal of sgbs is to drive the error @xmath131 to zero as quickly as possible by strategically selecting the queries .",
    "the query selection at each step of sgbs must be informative with respect to the distribution @xmath132 .",
    "in particular , if the _ weighted prediction _",
    "@xmath133 is close to zero for a certain @xmath16 ( or @xmath48 ) , then a label at that point is informative due to the large disagreement among the hypotheses .",
    "if multiple @xmath32 minimize @xmath134 , then one of the minimizers is selected uniformly at random .    to analyze sgbs ,",
    "define @xmath135 , @xmath136 .",
    "the variable @xmath137 was also used by burnashev and zigangirov @xcite to analyze classic binary search .",
    "it reflects the amount of mass that @xmath138 places on incorrect hypotheses .",
    "let @xmath15 denotes the underlying probability measure governing noises and possible randomization in query selection , and let @xmath139 denote expectation with respect to @xmath15 .",
    "note that by markov s inequality @xmath140 \\ .",
    "\\label{markov } \\end{aligned}\\ ] ] at this point , the method of analyzing sgbs departs from that of burnashev and zigangirov @xcite which focused only on the classic binary search problem .",
    "the lack of an ordered structure calls for a different attack on the problem , which is summarized in the following results and detailed in the appendix .    _",
    "consider any sequence of queries @xmath141 and the corresponding responses @xmath142 .",
    "if @xmath143 , then @xmath144 is a nonnegative supermartingale with respect to @xmath145 ; i.e. , @xmath146 \\leq c_n$ ] for all @xmath136 .",
    "_ [ martingale ]    the lemma is proved in the appendix .",
    "the condition @xmath147 ensures that the update ( [ update1 ] ) is not overly aggressive .",
    "it follows that @xmath148 \\leq c_0 $ ] and by the martingale convergence theorem we have that @xmath149 exists and is finite ( for more information on martingale theory one can refer to the textbook by brmaud @xcite ) .",
    "furthermore , we have the following theorem .",
    "_ _ [ thm2 ]    first observe that for every positive integer @xmath87 @xmath150 & = & \\e[(\\mm_n/\\mm_{n-1 } ) \\ , \\mm_{n-1 } ] \\ = \\",
    "\\e\\left[\\e[(\\mm_n/\\mm_{n-1 } ) \\ , \\mm_{n-1}|p_{n-1}]\\right ] \\\\   & = & \\e\\left[\\mm_{n-1 } \\ ,   \\e[(\\mm_n/\\mm_{n-1})|p_{n-1}]\\right ] \\ \\leq \\ \\e[\\mm_{n-1 } ] \\ , \\max_{p_{n-1}}\\e[(\\mm_n/\\mm_{n-1})|p_{n-1 } ] \\\\ & \\leq & \\mm_0 \\left(\\max_{i = 0,\\dots , n-1 } \\max_{p_i}\\ , \\e[(\\mm_{i+1}/\\mm_{i})|p_i]\\right)^n \\ .\\end{aligned}\\ ] ] in the proof of lemma  [ martingale ] , it is shown that if @xmath151 , then @xmath152<1 $ ] for every @xmath153 and therefore @xmath154~<~1 $ ] .",
    "it follows that the sequence @xmath155\\right)^n$ ] is monotonically decreasing .",
    "the result follows from ( [ markov ] ) .",
    "note that if we can determine an upper bound for the sequence @xmath154\\leq",
    "1-\\lambda < 1 $ ] , @xmath156 , then it follows that that @xmath157 .",
    "the modified sgbs algorithm is outlined in fig .",
    "[ fig : msgbs ] .",
    "it is easily verified that lemma  [ martingale ] and theorem  [ thm2 ] also hold for the modified sgbs algorithm .",
    "this follows since the modified query selection step is identical to that of the original sgbs algorithm , unless there exist two neighboring sets with strongly bipolar weighted responses . in the latter case ,",
    "a query is randomly selected from one of these two sets with equal probability .    for every @xmath32 and any probability measure @xmath158 on @xmath2 the _ weighted prediction _ on @xmath48",
    "is defined to be @xmath159 , where @xmath35 is the constant value of @xmath73 for every @xmath34 .",
    "the following lemma , which is the soft - decision analog of lemma  [ lemma1 ] , plays a crucial role in the analysis of the modified sgbs algorithm .     _",
    "if @xmath10 is @xmath47-neighborly , then for every probability measure @xmath158 on @xmath2 there either exists a set @xmath32 such that @xmath160 or a pair of @xmath47-neighbor sets @xmath46 such that @xmath161 and @xmath162 . _ [ lemma2 ]    suppose that @xmath163 . then there must exist @xmath46 such that @xmath164 and @xmath165 , otherwise @xmath60 can not be the incoherence parameter of @xmath2 , defined in ( [ cstar ] ) .",
    "to see this suppose , for instance , that @xmath164 for all @xmath166 .",
    "then for every distribution @xmath61 on @xmath3 we have @xmath167 .",
    "this contradicts the definition of @xmath60 since @xmath168 .",
    "the neighborly condition guarantees that there exists a sequence of @xmath47-neighbor sets beginning at @xmath48 and ending at @xmath49 . since @xmath169 on every set and",
    "the sign of @xmath170 must change at some point in the sequence , it follows that there exist @xmath47-neighbor sets satisfying the claim .",
    "the lemma guarantees that there exists either a set in @xmath27 on which the weighted hypotheses significantly disagree ( provided @xmath60 is significantly below @xmath171 ) or two neighboring sets in @xmath27 on which the weighted predictions are strongly bipolar . in either case , if a query is drawn randomly from these sets , then the weighted predictions are highly variable or uncertain , with respect to @xmath158 .",
    "this makes the resulting label informative in either case .",
    "if @xmath10 is @xmath171-neighborly , then the modified sgbs algorithm guarantees that @xmath172 exponentially fast .",
    "the @xmath171-neighborly condition is required so that the expected boost to @xmath173 is significant at each step .",
    "if this condition does not hold , then the boost could be arbitrarily small due to the effects of other hypotheses .",
    "fortunately , as shown in section  [ coherence ] , the @xmath171-neighborly condition holds in a wide range of common situations .",
    "_ let @xmath15 denote the underlying probability measure ( governing noises and algorithm randomization ) . if @xmath151 and @xmath10 is @xmath171-neighborly , then the modified sgbs algorithm in fig .",
    "[ fig : msgbs ] generates a sequence of hypotheses satisfying @xmath174 with exponential constant @xmath175 , where @xmath60 is defined in ( [ cstar ] ) .",
    "_ [ thm3 ]    the theorem is proved in the appendix .",
    "the exponential convergence rate in the exponential rate parameter @xmath176 is a positive constant strictly less than @xmath171 . for a noise level @xmath177",
    "this factor is maximized by a value @xmath178 which tends to @xmath179 as @xmath177 tends to @xmath83 . ]",
    "is governed by the coherence parameter @xmath180 . as shown in section  [ coherence ] , the value of @xmath60 is typically a small constant much less than @xmath171 that is independent of the size of @xmath2 . in such situations ,",
    "the query complexity of modified sgbs is near - optimal .",
    "the query complexity of the modified sgbs algorithm can be derived as follows .",
    "let @xmath181 be a pre - specified confidence parameter .",
    "the number of queries required to ensure that @xmath182 is @xmath183 , which is near - optimal . intuitively , about @xmath1 bits are required to encode each hypothesis .",
    "more formally , the noisy classic binary search problem satisfies the assumptions of theorem  [ thm3 ] ( as shown in section  [ cbs ] ) , and hence it is a special case of the general problem . using information - theoretic methods ,",
    "it has been shown by burnashev and zigangirov @xcite ( also see the work of karp and kleinberg @xcite ) that the query complexity for noisy classic binary search is also within a constant factor of @xmath184 .",
    "in contrast , the query complexity bound for ngbs , based on repeating queries , is at least logarithmic factor worse .",
    "we conclude this section with an example applying theorem  [ thm3 ] to the halfspace learning problem .",
    "_ consider learning multidimensional halfspaces .",
    "let @xmath185 and consider hypotheses of the form @xmath186 where @xmath187 and @xmath188 parameterize the hypothesis @xmath189 and @xmath190 is the inner product in @xmath191 .",
    "the following corollary characterizes the query complexity for this problem .",
    "_     let @xmath2 be a finite collection of hypotheses of form ( [ halfspace ] ) and assume that the responses to each query are noisy , with noise bound @xmath100 .",
    "then the hypotheses selected by modified sgbs with @xmath192 satisfy @xmath193 with @xmath194 .",
    "moreover , @xmath195 can be computed in time polynomial in @xmath196 .",
    "[ thms ]    the error bound follows immediately from theorem  [ thm3 ] since @xmath197 and @xmath198 is @xmath171-neighborly , as shown in section  [ linear ] .",
    "the polynomial - time computational complexity follows from the work of buck @xcite , as discussed in section  [ linear ] .",
    "suppose that @xmath2 is an @xmath199-dense set with respect to a uniform probability measure on a ball in @xmath191 ( i.e. , for _ any _ hyperplane of the form ( [ halfspace ] ) @xmath2 contains a hypothesis whose probability of error is within @xmath199 of it ) .",
    "the size of such an @xmath2 satisfies @xmath200 , for a constant @xmath201 , which is the proportional to the minimum query complexity possible in this setting , as shown by balcan et al @xcite .",
    "those authors also present an algorithm with roughly the same query complexity for this problem .",
    "however , their algorithm is specifically designed for the linear threshold problem .",
    "remarkably , near - optimal query complexity is achieved in polynomial - time by the general - purpose modified sgbs algorithm .",
    "so far we have assumed that the correct hypothesis @xmath7 is in @xmath2 . in this section",
    "we drop this assumption and consider _ agnostic _ algorithms guaranteed to find the best hypothesis in @xmath2 even if the correct hypothesis @xmath7 is not in @xmath2 and/or the assumptions of theorem  [ thm1 ] or [ thm3 ] do not hold .",
    "the best hypothesis in @xmath2 can be defined as the one that minimizes the error with respect to a probability measure on @xmath3 , denoted by @xmath202 , which can be arbitrary .",
    "this notion of `` best '' commonly arises in machine problems where it is customary to measure the error or _",
    "risk _ with respect to a distribution on @xmath3",
    ". a common approach to hypothesis selection is _ empirical risk minimization _ ( erm ) , which uses queries randomly drawn according to @xmath202 and then selects the hypothesis in @xmath2 that minimizes the number of errors made on these queries . given a budget of @xmath87 queries , consider the following agnostic procedure . divide the query budget into three equal portions .",
    "use gbs ( or ngbs or modified sgbs ) with one portion , erm ( queries randomly distributed according @xmath202 ) with another , and then allocate the third portion to queries from the subset of @xmath3 where the hypothesis selected by gbs ( or ngbs or modified sgbs ) and the hypothesis selected by erm disagree , with these queries randomly distributed according to the restriction of @xmath202 to this subset . finally , select the hypothesis that makes the fewest mistakes on the third portion as the final choice .",
    "the sample complexity of this agnostic procedure is within a constant factor of that of the better of the two competing algorithms .",
    "for example , if the conditions of theorems  [ thm1 ]  or  [ thm3 ] hold , then the sample complexity of the agnostic algorithm is proportional to @xmath117 . in general , the sample complexity of the agnostic procedure is within a constant factor of that of erm alone . we formalize this as follows .",
    "[ runoff]_let @xmath202 denote a probability measure on @xmath3 and for every @xmath82 let @xmath203 denote its probability of error with respect to @xmath202 .",
    "consider two hypotheses @xmath204 and let @xmath205 denote the subset of queries for which @xmath206 and @xmath207 disagree ; i.e. , @xmath208 for all @xmath209 .",
    "suppose that @xmath210 queries are drawn independently from @xmath211 , the restriction of @xmath202 to the set @xmath212 , let @xmath213 and @xmath214 denote average number of errors made by @xmath206 and @xmath207 on these queries , let @xmath215 $ ] and @xmath216 $ ] , and select @xmath217 .",
    "then @xmath218 with probability less than @xmath219 . _    define @xmath220 and let @xmath221 . by hoeffding s inequality",
    "we have @xmath222 $ ] with probability at least @xmath223 .",
    "it follows that @xmath224 .",
    "for example , if @xmath225 then since @xmath226 we may take @xmath227 to obtain @xmath228 .",
    "the result follows since @xmath206 and @xmath207 agree on the complement of @xmath212 .",
    "note that there is a distinct advantage to drawing queries from @xmath229 rather than @xmath202 , since the error exponent is proportional to @xmath230 which is greater than or equal to @xmath231 .",
    "now to illustrate the idea , consider an agnostic procedure based on modified sgbs and erm .",
    "the following theorem is proved in the appendix .",
    "[ thm5 ] _ let @xmath202 denote a measure on @xmath3 and suppose we have a query budget of @xmath87 .",
    "let @xmath206 denote the hypothesis selected by modified sgbs using @xmath232 of the queries and let @xmath207 denote the hypothesis selected by erm from @xmath232 queries drawn independently from @xmath202 . draw the remaining @xmath232 queries independently from @xmath229 , the restriction of @xmath202 to the set @xmath212 on which @xmath206 and @xmath207 disagree , and let @xmath213 and @xmath214 denote the average number of errors made by @xmath206 and @xmath207 on these queries .",
    "select @xmath217 . then , in general , @xmath233   & \\leq   & \\min\\{\\e[r(h_1)],\\e[r(h_2)]\\ } \\",
    ", + \\ , \\sqrt{3/n } \\ , \\end{aligned}\\ ] ] where @xmath203 , @xmath82 , denotes the probability of error of @xmath73 with respect to @xmath202 . furthermore ,",
    "if the assumptions of theorem  [ thm3 ] hold and @xmath6 , then @xmath234 where @xmath177 is the noise bound . _    note that if the assumptions of theorem  [ thm3 ] hold , then the agnostic procedure performs almost as well as modified sgbs alone .",
    "in particular , the number of queries required to ensure that @xmath235 is proportional to @xmath184 ; optimal up to constant factors . also observe that the probability bound implies the following bound in expectation : @xmath233   & \\leq   & r(h^ * ) + \\",
    "ne^{-\\lambda n/3 } \\",
    "+ \\ 2 e^{-n|1 - 2\\alpha|^2/6 } \\\\",
    "& \\leq & r(h^ * ) \\ + \\",
    "\\n e^{-c n } \\ , \\end{aligned}\\ ] ] where @xmath201 is a constant depending on @xmath176 and @xmath177 .",
    "the exponential convergence of the expected risk is much faster than the usual parametric rate for erm .",
    "if the conditions of theorem  [ thm3 ] are not met , then modified sgbs ( alone ) may perform poorly since it might select inappropriate queries and could even terminate with an incorrect hypothesis . however , the expected error of the agnostic selection @xmath236 is within @xmath237 of the expected error of erm , with no assumptions on the underlying distributions .",
    "note that the expected error of erm is proportional to @xmath238 in the worst - case situation .",
    "therefore , the agnostic procedure is near - optimal in general .",
    "the agnostic procedure offers this safeguard on performance .",
    "the same approach could be used to derive agnostic procedures from any _ active learning _",
    "scheme ( i.e. , learning from adaptively selected queries ) , including gbs or ngbs",
    ". we also note that the important element in the agnostic procedure is the selection of queries ; the proposed selection of @xmath236 based on those queries is convenient for proving the bounds , but not necessarily optimal .",
    "in this section we examine a variety of common situations in which the neighborliness condition can be verified .",
    "we will confine the discussion to gbs in the noise - free situation , and analogous results hold in the presence of noise . for a given pair @xmath10 ,",
    "the effectiveness of gbs hinges on determining ( or bounding ) @xmath60 and establishing that @xmath10 are neighborly .",
    "recall the definition of the bound @xmath60 from ( [ cstar ] ) and that @xmath111 , the cardinality of @xmath2 .",
    "a _ trivial _ bound for @xmath60",
    "is @xmath239 which is achieved by allocating @xmath240 mass to each hypothesis and evenly distributing @xmath241 mass to set(s ) @xmath48 where @xmath242 and @xmath241 on set(s ) @xmath48 where @xmath243 .",
    "non - trivial coherence bounds are those for which there exists a @xmath61 and @xmath244 that does not depend on @xmath0 such that @xmath245 the coherence parameter @xmath60 is analytically determined or bounded in several illustrative applications below .",
    "we also note that it may be known a priori that @xmath60 is bounded far way from @xmath171 .",
    "suppose that for a certain @xmath61 on @xmath3 ( or @xmath27 ) the absolute value of the first - moment of the correct hypothesis ( w.r.t .",
    "@xmath61 ) is known to be upper bounded by a constant @xmath246 .",
    "then all hypotheses that violate the bound can be eliminated from consideration .",
    "thus the constant @xmath56 is an upper bound on @xmath60 .",
    "situations like this can arise , for example , in binary classification problems with side / prior knowledge that the marginal probabilities of the two classes are somewhat balanced .",
    "then the moment of the correct hypothesis , with respect to the marginal probability distribution on @xmath3 , is bounded far away from @xmath171 and @xmath23 .",
    "the neighborly condition can be numerically verified in a straightforward fashion .",
    "enumerate the equivalence sets in @xmath27 as @xmath247 . to check whether the @xmath47-neighborhood graph is connected , form an @xmath248 matrix @xmath249",
    "whose @xmath250 entry is @xmath171 if @xmath251 and @xmath252 are k - neighbors and @xmath81 otherwise .",
    "normalize the rows of @xmath249 so that each sums to @xmath171 and denote the resulting _",
    "matrix by @xmath253 .",
    "the @xmath47-neighborhood graph is connected if and only if there exists an integer @xmath254 , @xmath255 , such that @xmath256 contains no zero entries .",
    "this follows from the standard condition for state accessibility in markov chains ( for background on markov chains one can refer to the textbook by brmaud @xcite ) .",
    "the smallest @xmath47 for which the @xmath47-neighborhood graph is connected can be determined using a binary search over the set @xmath257 , checking the condition above for each value of @xmath47 in the search .",
    "this idea was suggested to me by clayton scott .",
    "thus , the neighborly condition can be verified in polynomial - time in @xmath258 .",
    "alternatively , in many cases the neighborly condition can be verified analytically , as demonstrated in following applications .",
    "first we show that gbs reduces to classic binary search .",
    "let @xmath259 be the collection of binary - valued functions on @xmath260 $ ] of the following form , @xmath261 for @xmath262 ( and @xmath263 ) .",
    "assume that @xmath6 .",
    "first consider the neighborly condition . recall that @xmath27 is the smallest partition of @xmath3 into equivalence sets induced by @xmath2 . in this case , each @xmath48 is an interval of the form @xmath264 , @xmath262 .",
    "observe that only a single hypothesis , @xmath189 , has different responses to queries from @xmath251 and @xmath265 and so they are @xmath171-neighbors , for @xmath266 .",
    "moreover , the @xmath171-neighborhood graph is connected in this case , and so @xmath10 is @xmath171-neighborly .",
    "next consider coherence parameter @xmath60 .",
    "take @xmath61 to be two point masses at @xmath267 and @xmath268 of probability @xmath83 each .",
    "then @xmath269 for every @xmath4 , since @xmath270 and @xmath271 .",
    "thus , @xmath272 . since @xmath273 and @xmath274 , we have @xmath275 and the query complexity of gbs is proportional to @xmath1 according to theorem  [ thm1 ]",
    ". the reduction factor of @xmath276 , instead of @xmath83 , arises because we allow the situation in which the number of hypotheses may be odd ( e.g. , given three hypotheses ) , the best query may eliminate just one ) .",
    "if @xmath0 is even , then the query complexity is @xmath277 , which is information - theoretically optimal .",
    "now let @xmath260 $ ] and consider a finite collection of hypotheses @xmath278 , where @xmath189 takes the value @xmath22 when @xmath279 , for a pair @xmath280 , and @xmath23 otherwise .",
    "assume that @xmath6 .",
    "the partition @xmath27 again consists of intervals , and the neighborly condition is satisfied with @xmath274 . to bound @xmath60 , note that the minimizing @xmath61 must place some mass within and outside each interval @xmath281 .",
    "if the intervals all have length at least @xmath282 , then taking @xmath61 to be the uniform measure on @xmath283 $ ] yields that @xmath284 , regardless of the number of interval hypotheses under consideration .",
    "therefore , in this setting theorem  [ thm1 ] guarantees that gbs determines the correct hypothesis using at most a constant times @xmath1 steps .",
    "however , consider the special case in which the intervals are disjoint .",
    "then it is not hard to see that the best allocation of mass is to place @xmath285 mass in each subinterval , resulting in @xmath286 .",
    "and so , theorem  [ thm1 ] only guarantees that gbs is will terminate in at most @xmath0 steps ( the number of steps required by exhaustive linear search ) .",
    "in fact , it is easy to see that no procedure can do better than linear search in this case and the query complexity of any method is proportional to @xmath287 .",
    "however , note that if queries of a different form were allowed , then much better performance is possible . for example ,",
    "if queries in the form of dyadic subinterval tests were allowed ( e.g. , tests that indicate whether or not the correct hypothesis is @xmath22-valued anywhere within a dyadic subinterval of choice ) , then the correct hypothesis can be identified through @xmath288 queries ( essentially a binary encoding of the correct hypothesis ) .",
    "this underscores the importance of the geometrical relationship between @xmath3 and @xmath2 embodied in the neighborly condition and the incoherence parameter @xmath60 . optimizing the query space to the structure of @xmath2",
    "is related to the notion of arbitrary queries examined in the work of kulkarni et al @xcite , and somewhat to the theory of compressed sensing developed by candes et al @xcite and donoho @xcite .",
    "let @xmath289 be a collection of multidimensional threshold functions of the following form .",
    "the threshold of each @xmath189 determined by ( possibly nonlinear ) decision surface in @xmath290-dimensional euclidean space and the queries are points in @xmath41 .",
    "it suffices to consider linear decision surfaces of the form @xmath291 where @xmath187 , @xmath292 , the offset @xmath293 satisfies @xmath294 for some constant @xmath295 , and @xmath190 denotes the inner product in @xmath191 . each hypothesis is associated with a halfspace of @xmath191 . note that hypotheses of this form can be used to represent nonlinear decision surfaces , by first applying a mapping to an input space and then forming linear decision surfaces in the induced query space .",
    "the problem of learning multidimensional threshold functions arises commonly in computer vision ( see the review of swain and stricker@xcite and applications by geman and jedynak @xcite and arkin et al @xcite ) , image processing studied by korostelev and kim @xcite , and active learning research ; for example the investigations by freund et al @xcite , dasgupta @xcite , balcan et al @xcite , and castro and nowak @xcite .",
    "first we show that the pair @xmath198 is @xmath171-neighborly .",
    "each @xmath166 is a polytope in @xmath191 .",
    "these polytopes are generated by intersections of the halfspaces corresponding to the hypotheses .",
    "any two polytopes that share a common face are @xmath171-neighbors ( the hypothesis whose decision boundary defines the face , and its complement if it exists , are the only ones that predict different values on these two sets ) . since the polytopes tessellate @xmath191 , the @xmath171-neighborhood graph of @xmath27 is connected .",
    "we next show that the the coherence parameter @xmath197 .",
    "since the offsets of the hypotheses are all less than @xmath296 in magnitude , it follows that the distance from the origin to the nearest point of the decision surface of every hypothesis is at most @xmath296 .",
    "let @xmath297 denote the uniform probability distribution on a ball of radius @xmath298 centered at the origin in @xmath191 .",
    "then for every @xmath73 of the form ( [ surface ] ) there exists a constant @xmath201 ( depending on @xmath296 ) such that @xmath299 and @xmath300 .",
    "therefore @xmath272 , and it follows from theorem  [ thm1 ] guarantees that gbs determines the correct multidimensional threshold in at most @xmath301 steps . to the best of our knowledge this is a new result in the theory of learning multidimensional threshold functions , although similar query complexity bounds have been established for the subclass of linear threshold functions with @xmath302 ( threshold boundaries passing through the origin ) ; see for example the work of balcan et al @xcite . these results are based on somewhat different learning algorithms , assumptions and analysis techniques .    observe that if @xmath2 is an @xmath199-dense ( with respect lesbegue measure over a compact set in @xmath191 ) subset of the continuous class of threshold functions of the form ( [ surface ] ) , then the size of the @xmath2 satisfies @xmath303 .",
    "therefore the query complexity of gbs is proportional to the metric entropy of the continuous class , and it follows from the results of kulkarni et al @xcite that no learning algorithm exists with a lower query complexity ( up to constant factors ) .",
    "furthermore , note that the computational complexity of gbs for hypotheses of the form ( [ surface ] ) is proportional to the cardinality of @xmath27 , which is equal to the number of polytopes generated by intersections of half - spaces .",
    "it is a well known fact ( see buck @xcite ) that @xmath304 .",
    "therefore , gbs is a polynomial - time algorithm for this problem . in general",
    ", the cardinality of @xmath27 could be as large as @xmath305 .",
    "next let @xmath2 again be the hypotheses of the form ( [ surface ] ) , but let @xmath306^d$ ] , instead of all of @xmath191 .",
    "this constraint on the query space affects the bound on the coherence @xmath60 . to bound @xmath60 ,",
    "let @xmath61 be point masses of probability @xmath307 at each of the @xmath308 vertices of the cube @xmath309^d$ ] ( the natural generalization of the @xmath61 chosen in the case of classic binary search in section  [ cbs ] above ) .",
    "then @xmath310 for every @xmath4 , since for each @xmath73 there is at least one vertex on where it predicts @xmath22 and one where it predicts @xmath23 .",
    "thus , @xmath311 . we conclude that the gbs determines the correct hypothesis in proportional to @xmath312 steps .",
    "the dependence on @xmath308 is unavoidable , since it may be that each threshold function takes that value @xmath22 only at one of the @xmath308 vertices and so each vertex must be queried .",
    "a noteworthy special case is arises when @xmath302 ( i.e. , the threshold boundaries pass through the origin ) . in this case , with @xmath61 as specified above , @xmath272 , since each hypothesis responds with @xmath22 at half of the vertices and @xmath23 on the other half .",
    "therefore , the query complexity of gbs is at most @xmath301 , independent of the dimension . as discussed above , similar results for this special case",
    "have been previously reported based on different algorithms and analyses ; see the results in the work of balcan et al @xcite and the references therein .",
    "note that even if the threshold boundaries do not pass through the origin , and therefore the number of queries needed is proportional to @xmath1 so long as @xmath313 . the dependence on dimension @xmath290",
    "can also be eliminated if it is known that for a certain distribution @xmath61 on @xmath3 the absolute value of the moment of the correct hypothesis w.r.t .",
    "@xmath61 is known to be upper bounded by a constant @xmath246 , as discussed at the beginning of this section .",
    "finally , we also mention hypotheses associated with axis - aligned rectangles in @xmath283^d$ ] , the multidimensional version of the interval hypotheses considered above .",
    "an axis - aligned rectangle is defined by its boundary coordinates in each dimension , @xmath314 , @xmath315 .",
    "the hypothesis associated with such a rectangle takes the value @xmath316 on the set @xmath317^d : \\",
    "a_j \\leq x_j \\leq b_j , \\ j=1,\\dots , d\\}$ ] and @xmath23 otherwise . the complementary hypothesis may also be included .",
    "consider a finite collection @xmath2 of hypotheses of this form .",
    "if the rectangles associated with each @xmath82 have volume at least @xmath318 , then by taking @xmath61 to be the uniform measure on @xmath283^d$ ] it follows that the coherence parameter @xmath319 for this problem .",
    "the cells of partition @xmath27 of @xmath283 $ ] associated with a collection of such hypotheses are rectangles themselves .",
    "if the boundaries of the rectangles associated with the hypotheses are distinct , then the @xmath171-neighborhood graph of @xmath27 is connected .",
    "theorem  [ thm1 ] implies that the number of queries needed by gbs to determine the correct rectangle is proportional to @xmath320 .      in many situations both the hypothesis and query spaces may be discrete .",
    "a machine learning application , for example , may have access to a large ( but finite ) pool of unlabeled examples , any of which may be queried for a label . because obtaining labels can be costly , `` active '' learning algorithms select only those examples that are predicted to be highly informative for labeling .",
    "theorem  [ thm1 ] applies equally well to continuous or discrete query spaces .",
    "for example , consider the linear separator case , but instead of the query space @xmath191 suppose that @xmath3 is a finite subset of points in @xmath191 .",
    "the hypotheses again induce a partition of @xmath3 into subsets @xmath24 , but the number of subsets in the partition may be less than the number in @xmath321 . consequently , the neighborhood graph of @xmath24 depends on the specific points that are included in @xmath3 and may or may not be connected .",
    "as discussed at the beginning of this section , the neighborly condition can be verified in polynomial - time ( polynomial in @xmath39 ) .",
    "consider two illustrative examples .",
    "let @xmath2 be a collection of linear separators as in ( [ surface ] ) above and first reconsider the partition @xmath321 .",
    "recall that each set in @xmath321 is a polytope .",
    "suppose that a discrete set @xmath3 contains at least one point inside each of the polytopes in @xmath321 .",
    "then it follows from the results above that @xmath10 is @xmath171-neighborly .",
    "second , consider a simple case in @xmath322 dimensions .",
    "suppose @xmath3 consists of just three non - colinear points @xmath323 and suppose that @xmath2 is comprised of six classifiers , @xmath324 , satisfying @xmath325 , @xmath326 , @xmath327 , and @xmath328 , @xmath327 . in this case ,",
    "@xmath329 and the responses to any pair of queries differ for four of the six hypotheses .",
    "thus , the @xmath330-neighborhood graph of @xmath24 is connected , but the @xmath171-neighborhood is not .    also note that a finite query space naturally limits the number of hypotheses that need be considered .",
    "consider an uncountable collection of hypotheses .",
    "the number of unique labeling assignments generated by these hypotheses can be bounded in terms of the vc dimension of the class ; see the book by vapnik for more information on vc theory @xcite . as a result",
    ", it suffices to consider a finite subset of the hypotheses consisting of just one representative of each unique labeling assignment .",
    "furthermore , the computational complexity of gbs is proportional to @xmath331 in this case .",
    "generalized binary search can be viewed as a generalization of classic binary search , shannon - fano coding as noted by goodman and smyth @xcite , and channel coding with noiseless feedback as studied by horstein @xcite .",
    "problems of this nature arise in many applications , including channel coding ( e.g. , the work of horstein @xcite and zigangirov @xcite ) , experimental design ( e.g. , as studied by rnyi @xcite ) , disease diagnosis ( e.g. , see the work of loveland @xcite ) , fault - tolerant computing ( e.g. , the work of feige et al @xcite ) , the scheduling problem considered by kosaraju et al @xcite , computer vision problems investigated by geman and jedynak @xcite and arkin et al @xcite ) , image processing problems studied by korostelev and kim @xcite , and active learning research ; for example the investigations by freund et al @xcite , dasgupta @xcite , balcan et al @xcite , and castro and nowak @xcite .",
    "past work has provided a partial characterization of this problem .",
    "if the responses to queries are noiseless , then selecting the sequence of queries from @xmath3 is equivalent to determining a binary decision tree , where a sequence of queries defines a path from the root of the tree ( corresponding to @xmath2 ) to a leaf ( corresponding to a single element of @xmath2 ) . in general the determination of the optimal ( worst- or average - case )",
    "tree is np - complete as shown by hyafil and rivest @xcite .",
    "however , there exists a greedy procedure that yields query sequences that are within a factor of @xmath1 of the optimal search tree depth ; this result has been discovered independently by several researchers including loveland @xcite , garey and graham @xcite , arkin et al @xcite , and dasgupta @xcite .",
    "the greedy procedure is referred to here as _ generalized binary search _",
    "( gbs ) or the _ splitting algorithm _ , and it reduces to classic binary search , as discussed in section  [ cbs ] .",
    "the number of queries an algorithm requires to determine @xmath7 is called the _ query complexity _ of the algorithm . since the hypotheses are assumed to be distinct , it is clear that the query complexity of gbs is at most @xmath0 ( because it is always possible to find query that eliminates at least one hypothesis at each step ) .",
    "in fact , there are simple examples ( see section  [ cbs ] ) demonstrating that this is the best one can hope to do in general .",
    "however , it is also true that in many cases the performance of gbs can be much better , requiring as few as @xmath277 queries . in classic binary search , for example ,",
    "half of the hypotheses are eliminated at each step ( e.g. , refer to the textbook by cormen et al @xcite ) . rnyi first considered a form of binary search with noise @xcite and explored its connections with information theory @xcite . in particular , the problem of sequential transmission over a binary symmetric channel with noiseless feedback , as formulated by horstein @xcite and studied by burnashev and zigangirov @xcite and more recently by pelc et al @xcite , is equivalent to a noisy binary search problem .    there is a large literature on learning from queries ; see the review articles by angluin @xcite .",
    "this paper focuses exclusively on membership queries ( i.e. , an @xmath332 is the query and the response is @xmath9 ) , although other types of queries ( equivalence , subset , superset , disjointness , and exhaustiveness ) are possible as discussed by angluin @xcite . _ arbitrary queries _",
    "have also been investigated , in which the query is a subset of @xmath2 and the output is @xmath22 if @xmath7 belongs to the subset and @xmath23 otherwise .",
    "a finite collection of hypotheses @xmath2 can be successively halved using arbitrary queries , and so it is possible to determine @xmath7 with @xmath95 arbitrary queries , the information - theoretically optimal query complexity discussed by kulkarni et al @xcite .",
    "membership queries are the most natural in function learning problems , and because this paper deals only with this type we will simply refer to them as queries throughout the rest of the paper .",
    "the number of queries required to determine a binary - valued function in a finite collection of hypotheses can be bounded ( above and below ) in terms of a combinatorial parameter of @xmath10 due to hegeds@xcite ( see the work of hellerstein et al @xcite for related work ) . due to its combinatorial nature , computing such bounds are generally np - hard . in contrast , the geometric relationship between @xmath3 and @xmath2 developed in this paper leads to an upper bound on the query complexity that can be determined analytically or computed in polynomial time in many cases of interest .",
    "the term gbs is used in this paper to emphasize connections and similarities with classic binary search , which is a special case the general problem considered here .",
    "classic binary search is equivalent to learning a one - dimensional binary - valued threshold function by selecting point evaluations of the function according to a bisection procedure .",
    "consider the threshold function @xmath333 on the interval @xmath334 $ ] for some threshold value @xmath335 . throughout the paper",
    "we adopt the convention that @xmath336 .",
    "suppose that @xmath337 belongs to the discrete set @xmath338 and let @xmath2 denote the collection of threshold functions @xmath339 .",
    "the value of @xmath337 can then determined from a constant times @xmath117 queries using a bisection procedure analogous to the game of twenty questions .",
    "in fact , this is precisely what gbs performs in this case ( i.e. , gbs reduces to classic binary search in this setting ) .",
    "if @xmath340 for some integer @xmath210 , then each point evaluation provides one bit in the @xmath210-bit binary expansion of @xmath337 .",
    "thus , classic binary search is information - theoretically optimal ; see the book by traub , wasilkowski and wozniakowski @xcite for a nice treatment of classic bisection and binary search .",
    "the main results of this paper generalize the salient aspects of classic binary search to a much broader class of problems .",
    "in many ( if not most ) applications it is unrealistic to assume that the responses to queries are without error . a form of binary search with noise appears to have been first posed by rnyi @xcite .",
    "the noisy binary search problem arises in sequential transmission over a binary symmetric channel with noiseless feedback studied by horstein @xcite and zigangirov @xcite .",
    "the survey paper by pelc et al @xcite discusses the connections between search and coding problems . in channel coding with feedback",
    ", each threshold corresponds to a unique binary codeword ( the binary expansion of @xmath337 ) .",
    "thus , channel coding with noiseless feedback is equivalent to the problem of learning a one - dimensional threshold function in binary noise , as noted by burnashev and zigangirov @xcite .",
    "the near - optimal solutions to the _ noisy binary search _ problem first appear in these two contexts .",
    "discrete versions of horstein s probabilistic bisection procedure @xcite were shown to be information - theoretically optimal ( optimal decay of the error probability ) in the works of zigangirov and burnashev @xcite .",
    "more recently , the same procedure was independently proposed and analyzed in the context of noise - tolerant versions of the classic binary search problem by karp and kleinberg @xcite , which was motivated by applications ranging from investment planning to admission control in queueing networks .",
    "closely related approaches are considered in the work of feige et al @xcite .",
    "the noisy binary search problem has found important applications in the minimax theory of sequential , adaptive sampling procedures proposed by korostelov and kim @xcite for image recovery and binary classification problems studied by castro and nowak @xcite .",
    "we also mention the works of rivest et al @xcite , spencer @xcite and aslam and dhagat @xcite , and dhagat et al @xcite , which consider adversarial situations in which the total number of erroneous oracle responses is fixed in advance .",
    "one straightforward approach to noisy gbs is to follow the gbs algorithm , but to repeat the query at each step multiple times in order to decide whether the response is more probably @xmath22 or @xmath23 .",
    "this simple approach has been studied in the context of noisy versions of classic binary search and shown to perform significantly worse than other approaches in the work of karp and kleinberg @xcite ; perhaps not surprising since this is essentially a simple repetition code approach to communicating over a noisy channel .",
    "a near - optimal noise - tolerant version of gbs was developed in this paper .",
    "the algorithm can be viewed as a non - trivial generalization of horstein s probabilistic bisection procedure .",
    "horstein s method relies on the special structure of classic binary search , namely that the hypotheses and queries can be naturally ordered together in the unit interval .",
    "horstein s method is a sequential bayesian procedure .",
    "it begins with uniform distribution over the set of hypotheses . at each step",
    ", it queries at the point that bisects the probability mass of the current distribution over hypotheses , and then updates the distribution according to bayes rule .",
    "horstein s procedure is nt directly applicable to situations in which the hypotheses and queries can not be ordered togetherl , but the geometric condition developed in this paper provides similar structure that is exploited here to devise a generalized probabilistic bisection procedure .",
    "the key elements of the procedure and the analysis of its convergence are fundamentally different from those in the classic binary search work of burnashev and zigangirov @xcite and karp and kleinberg @xcite .",
    "this paper investigated a generalization of classic binary search , called gbs , that extends it to arbitrary query and hypothesis spaces . while the gbs algorithm is well - known , past work",
    "has only partially characterized its capabilities .",
    "this paper developed new conditions under which gbs ( and a noise - tolerant variant ) achieve the information - theoretically optimal query complexity .",
    "the new conditions are based on a novel geometric relation between the query and hypothesis spaces , which is verifiable analytically and/or computationally in many cases of practical interest .",
    "the main results are applied to learning multidimensional threshold functions , a problem arising routinely in image processing and machine learning .",
    "let us briefly consider some possible extensions and open problems .",
    "first recall that in noisy situations it is assumed that the binary noise probability has a known upper bound @xmath100 . it is possible to accommodate situations in which the bound is unknown a priori .",
    "this can be accomplished using an ngbs algorithm in which the number of repetitions of each query , @xmath102 , is determined adaptively to adjust to the unknown noise level .",
    "this procedure was developed by the author in @xcite , and is based on a straightforward , iterated application of chernoff s bound .",
    "similar strategies have been suggested as a general approach for devising noise - tolerant learning algorithms @xcite . using an adaptive procedure for adjusting the number of repetitions of each query yields an ngbs algorithm with query complexity bound proportional to @xmath341 , the same order as that of the ngbs algorithm discussed above which assumed a known bound @xmath177 . whether or not the additional logarithmic factor can be removed",
    "if the noise bound @xmath177 is unknown is an open question .",
    "adversarial noise models in which total number of errors is fixed in advance , like those considered by rivest et al @xcite and spencer @xcite , are also of interest in classic binary search problems .",
    "repeating each query multiple times and taking the majority vote of the responses , as in the ngbs algorithm , is a standard approach to adversarial noise .",
    "thus , ngbs provides an algorithm for generalized binary search with adversarial noise .",
    "finally , we suggest that the salient features of the gbs algorithms could be extended to handle continuous , uncountable classes of hypotheses . for example , consider the continuous class of halfspace threshold functions on @xmath191 . this class is indexed parametrically and it is possible to associate a volume measure with the class ( and subsets of it ) by introducing a measure over the parameter space . at each step of a gbs - style algorithm ,",
    "all inconsistent hypotheses are eliminated and the next query is selected to split the volume of the parameter space corresponding to the remaining hypotheses , mimicking the splitting criterion of the gbs algorithm presented here .",
    "+   + acknowledgements .",
    "the author thanks r.  castro , a.  gupta , c.  scott , a.  singh and the anonymous reviewers for helpful feedback and suggestions .",
    "first we derive the precise form of @xmath342 is derived as follows .",
    "let @xmath343 , the weighted proportion of hypotheses that agree with @xmath344 . the factor that normalizes the updated distribution in ( [ update1 ] )",
    "is related to @xmath345 as follows .",
    "note that @xmath346 .",
    "thus , @xmath347 denote the reciprocal of the update factor for @xmath348 by @xmath349 where @xmath350 , and observe that @xmath351 .",
    "thus , @xmath352 we prove that @xmath353\\leq\\mm_i$ ] by showing that @xmath354 \\leq 1 $ ] . to accomplish this",
    ", we will let @xmath153 be arbitrary .",
    "for every @xmath355 and every @xmath4 let @xmath35 denote the value of @xmath73 on the set @xmath48 .",
    "define @xmath356 , the proportion of hypotheses that take the value @xmath22 on @xmath48 .",
    "let @xmath251 denote that set that @xmath357 is selected from , and consider the four possible situations : @xmath358 to bound @xmath359 $ ] it is helpful to condition on @xmath251 .",
    "define @xmath360 .",
    "if @xmath361 , then @xmath362     & = &   \\frac{(1-\\delta_{a_i}^+)\\beta+\\delta_{a_i}^+ ( 1-\\beta)}{1-\\beta}(1-q_i)\\ + \\",
    "\\frac{\\delta_{a_i}^+\\beta+(1-\\delta_{a_i}^+ ) ( 1-\\beta)}{\\beta}q_i    \\\\ & = & \\delta_{a_i}^+ + ( 1-\\delta_{a_i}^+)\\left[\\frac{\\beta(1-q_i)}{1-\\beta}+\\frac{q_i(1-\\beta)}{\\beta } \\right ] \\",
    ".\\end{aligned}\\ ] ] define @xmath363 $ ] .",
    "similarly , if @xmath364 , then @xmath365   & = & ( 1- \\delta_{a_i}^+ ) + \\delta_{a_i}^+ \\left[\\frac{\\beta(1-q_i)}{1-\\beta}+\\frac{q_i(1-\\beta)}{\\beta } \\right ] \\",
    "\\gamma_i^{-}(a_i ) \\end{aligned}\\ ] ] by assumption @xmath366 , and since @xmath367 the factor @xmath368 ( strictly less than @xmath171 if @xmath369 ) .",
    "define @xmath370 to obtain the bounds @xmath371 observe that for every @xmath48 we have @xmath372 , since at least one hypothesis takes the value @xmath23 on @xmath48 and @xmath373 for all @xmath82 .",
    "therefore both @xmath374 and @xmath375 are less or equal to @xmath171 , and it follows that @xmath354\\leq1 $ ] ( and strictly less than @xmath171 if @xmath151 )",
    ". @xmath77      the proof amounts to obtaining upper bounds for @xmath374 and @xmath375 , defined above in ( [ pb ] ) and ( [ nb ] ) .",
    "consider two distinct situations .",
    "define @xmath376 .",
    "first suppose that there do not exist neighboring sets @xmath48 and @xmath49 with @xmath377 and @xmath378 .",
    "then by lemma  [ lemma1 ] , this implies that @xmath379 , and according the query selection step of the modified sgbs algorithm , @xmath380 .",
    "note that because @xmath381 , @xmath382 .",
    "hence , both @xmath374 and @xmath375 are bounded above by @xmath383 .",
    "now suppose that there exist neighboring sets @xmath48 and @xmath49 with @xmath377 and @xmath384 .",
    "recall that in this case @xmath251 is randomly chosen to be @xmath48 or @xmath49 with equal probability .",
    "note that @xmath385 and @xmath386 .",
    "if @xmath387 , then applying ( [ pb ] ) results in @xmath388   & < & \\frac{1}{2}(1 + \\frac{1-b_i}{2}+\\frac{1+b_i}{2}(1-\\varepsilon_0 ) ) \\ = \\ \\frac{1}{2}(2-\\varepsilon_0\\frac{1+b_i}{2 } )   \\ \\leq \\ 1-\\varepsilon_0/4 \\ , \\end{aligned}\\ ] ] since @xmath389 .",
    "similarly , if @xmath390 , then ( [ nb ] ) yields @xmath391 < 1-\\varepsilon_0/4 $ ] . if @xmath392 on @xmath48 and @xmath393 , then applying ( [ nb ] ) on @xmath48 and ( [ pb ] ) on @xmath49 yields @xmath388 &   \\leq & \\frac{1}{2}\\left(\\delta_{a}^+ ( 1-\\varepsilon_0 ) + ( 1- \\delta_{a}^+ ) + \\delta_{a'}^+ + ( 1-\\delta_{a'}^+)(1-\\varepsilon_0)\\right ) \\\\ & = &   \\frac{1}{2}(1-\\delta_a^+ + \\delta_{a'}^+ + ( 1-\\varepsilon_0)(1+\\delta_a^+ -\\delta_{a'}^+ ) )   \\\\ & = &   \\frac{1}{2}(2-\\varepsilon_0(1+\\delta_a^+-\\delta_{a'}^+ ) ) \\\\ & = & 1-\\frac{\\varepsilon_0}{2 } ( 1+\\delta_a^+-\\delta_{a'}^+ )   \\ \\leq",
    "\\ 1-\\varepsilon_0/2 \\ , \\end{aligned}\\ ] ] since @xmath394 .",
    "the final possibility is that @xmath395 and @xmath396",
    ". apply ( [ pb ] ) on @xmath48 and ( [ nb ] ) on @xmath49 to obtain @xmath388 & \\leq & \\hspace{-.1 in } \\frac{1}{2}\\left(\\delta_a^+ + ( 1-\\delta_a^+)(1-\\varepsilon_0)+\\delta_{a'}^+ ( 1-\\varepsilon_0 ) + ( 1- \\delta_{a'}^+)\\right ) \\\\   & = &   \\frac{1}{2}(1+\\delta_a^+-\\delta_{a'}^+ + ( 1-\\varepsilon_0)(1-\\delta_a^++\\delta_{a'}^+))\\end{aligned}\\ ] ] next , use the fact that because @xmath48 and @xmath49 are neighbors , @xmath397 ; if @xmath398 does not belong to @xmath2 , then @xmath399 .",
    "hence , @xmath388    & \\leq &   \\frac{1}{2}(1+\\delta_a^+-\\delta_{a'}^+ + ( 1-\\epsilon_0)(1-\\delta_a^++\\delta_{a'}^+ ) ) \\\\ & = &   \\frac{1}{2}(1+p_i(h^*)-p_i(-h^ * ) + ( 1-\\epsilon_0)(1-p_i(h^*)+p_i(-h^ * ) ) ) \\\\ & \\leq &   \\frac{1}{2}(1+p_i(h^ * ) + ( 1-\\epsilon_0)(1-p_i(h^ * ) ) ) \\ = \\   1-\\frac{\\varepsilon_0}{2}(1-p_i(h^*))\\ , \\end{aligned}\\ ] ] since the bound is maximized when @xmath400 .",
    "now bound @xmath359 $ ] by the maximum of the conditional bounds above to obtain @xmath401 &   \\leq & \\max \\left\\{1-\\frac{\\varepsilon_0}{2}(1-p_i(h^ * ) ) \\ , , \\ , 1-\\frac{\\varepsilon_0}{4 } \\ , , \\ ,      1-(1-\\ch)\\frac{\\varepsilon_0}{2 } \\right\\ } \\ , \\end{aligned}\\ ] ] and thus it is easy to see that @xmath402 & = & \\frac{\\e\\left [    \\gamma_i|p_i\\right]- p_i(h^ * ) } { 1-p_i(h^ * ) } \\ \\leq \\ 1-\\min\\left\\{\\frac{\\varepsilon_0}{2}(1-\\ch),\\frac{\\varepsilon_0}{4}\\right\\ } \\ .",
    "\\hspace{.5 in } \\blacksquare \\end{aligned}\\ ] ]      first consider the bound on @xmath403 $ ] .",
    "let @xmath404 and consider the conditional expectation @xmath405 $ ] ; i.e. , expectation with respect to the @xmath232 queries drawn from the region @xmath212 , conditioned on the @xmath406 queries used to select @xmath206 and @xmath207 . by lemma  [ runoff ] @xmath407   & \\leq   & ( 1-\\delta_n ) \\ , \\min\\{r(h_1),r(h_2)\\ }   \\ + \\   \\delta_n \\ , \\max\\{r(h_1),r(h_2)\\ }   \\ , \\\\ & = & \\min\\{r(h_1),r(h_2)\\ }",
    "\\ + \\ \\delta_n \\",
    ", \\left[\\max\\{r(h_1),r(h_2)\\}-\\min\\{r(h_1),r(h_2)\\}\\right ]    \\ , \\\\ & = & \\min\\{r(h_1),r(h_2)\\ } \\ + \\ \\delta_n \\ , |r(h_1)-r(h_2)|     \\ , \\\\ & = & \\min\\{r(h_1),r(h_2)\\ } \\ + \\ 2 \\ , |r(h_1)-r(h_2)|   \\ , e^{-n|r_\\delta(h_1)-r_\\delta(h_2)|^2/6 }   \\ ,   \\\\ & \\leq & \\min\\{r(h_1),r(h_2)\\}+ 2 |r(h_1)-r(h_2)|   \\ , e^{-n|r(h_1)-r(h_2)|^2/6 }    \\ , \\end{aligned}\\ ] ] where the last inequality follows from the fact that @xmath408 .",
    "the function @xmath409 attains its maximum at @xmath410 , and therefore @xmath407   & \\leq   & \\min\\{r(h_1),r(h_2)\\ } \\ , + \\ ,",
    "\\sqrt{3/n } \\ .\\end{aligned}\\ ] ] now taking the expectation with respect to @xmath206 and @xmath207 ( i.e. , with respect to the queries used for the selection of @xmath206 and @xmath207 ) @xmath233   & \\leq   & \\e[\\min\\{r(h_1),r(h_2)\\ } ] \\ , + \\",
    ", \\sqrt{3/n } \\ , \\\\ & \\leq   & \\min\\{\\e[r(h_1)],\\e[r(h_2)]\\ } \\ , + \\ ,",
    "\\sqrt{3/n } \\ , \\end{aligned}\\ ] ] by jensen s inequality .",
    "next consider the bound on @xmath411 .",
    "this also follows from an application of lemma  [ runoff ] .",
    "note that if the conditions of theorem  [ thm3 ] hold , then @xmath412 .",
    "furthermore , if @xmath413 and @xmath414 , then @xmath415 .",
    "the bound on @xmath416 follows by applying the union bound to the events @xmath413 and @xmath417 .",
    "@xmath77              a.  rnyi , `` on a problem in information theory , '' _ mta mat .",
    "_ , p. 505516",
    ", 1961 , reprinted in _ selected papers of alfred rnyi _ , vol .  2 , p. turan , ed . , pp .",
    "631 - 638 .",
    "akademiai kiado , budapest , 1976 .",
    "e.  j. cands , j.  romberg , and t.  tao , `` robust uncertainty principles : exact signal reconstruction from highly incomplete frequency information , '' _ ieee trans .",
    "inform . theory _",
    "52 , no .  2 ,",
    "489509 , feb . 2006 ."
  ],
  "abstract_text": [
    "<S> this paper investigates the problem of determining a binary - valued function through a sequence of strategically selected queries . </S>",
    "<S> the focus is an algorithm called generalized binary search ( gbs ) . </S>",
    "<S> gbs is a well - known greedy algorithm for determining a binary - valued function through a sequence of strategically selected queries . at each step </S>",
    "<S> , a query is selected that most evenly splits the hypotheses under consideration into two disjoint subsets , a natural generalization of the idea underlying classic binary search . </S>",
    "<S> this paper develops novel incoherence and geometric conditions under which gbs achieves the information - theoretically optimal query complexity ; i.e. , given a collection of @xmath0 hypotheses , gbs terminates with the correct function after no more than a constant times @xmath1 queries . </S>",
    "<S> furthermore , a noise - tolerant version of gbs is developed that also achieves the optimal query complexity . </S>",
    "<S> these results are applied to learning halfspaces , a problem arising routinely in image processing and machine learning . </S>"
  ]
}