{
  "article_text": [
    "the importance of equilibrium magnetic field reconstruction in tokamaks is well understood throughout fusion science.@xcite indeed , it is the geometry of the equilibrium magnetic field that provides a canonical coordinate , via indexing of nested flux surfaces , which is needed for a wide variety of post shot theoretical and diagnostic data analysis.@xcite equilibrium reconstruction also gives the outer boundary of the plasma : a key element to many open - circuit , real - time control methodologies.@xcite while schemes exist for plasma control using only classical electrostatics to determine the boundary reconstruction@xcite , the vast majority of reconstructions of the internal magnetic geometry rely upon solving kinetic force - balance equations with a single solution being chosen as the best fit to available diagnostic data @xcite .",
    "this approach to internal reconstruction is most famously implemented through the efit code ( or variants thereof ) that uses picard iteration to find solutions of the grad - shafranov ( gs ) force - balance equation , which best fit data observed from equilibrium magnetic diagnostics ( e.g. fluxloops and pickup coils).@xcite while this approach of leveraging the gs equation to perform equilibrium reconstruction has been successfully utilised throughout the field , the accuracy of the method is intrinsically linked to how accurately the gs equation accounts for all the equilibrium forces in the plasma .",
    "indeed , factors such as flow and isotropy need to be explicitly added into the underpinning force - balance equations to be correctly accounted for in the equilibrium reconstruction.@xcite moreover , solutions to equilibrium reconstruction are not generally unique@xcite ; and thus , experiment - specific numerical schemes are frequently employed to guarantee that the picard iteration converges to a physical solution .    in parallel to the inclusion of more physics in equilibrium solvers ,",
    "there has been the improvement in the diversity , accuracy and resolution of plasma diagnostics .",
    "interpretation , however , often requires a detailed knowledge of the plasma equilibrium .",
    "for example , inference of the toroidal current profile @xmath0 from line of sight measurements of the polarisation angle requires a knowledge of the poloidal flux @xmath1 across the plasma .",
    "formally , diagnostic forward functions relate the vector of plasma parameters @xmath2 to the measurement vector @xmath3 . for a linear system , such as toroidal current inference in a double null configuration , @xmath2 and @xmath3",
    "are normally related through a response matrix @xmath4 with additional contributions @xmath5 , such that @xmath6 .",
    "inference , or parameter estimation , involves inverting this relationship to give plasma parameters @xmath2 that are consistent with the data @xmath3 .",
    "a widespread technique used is least - square fitting , used for instance in efit , in which prior assumptions are included via a penalty term in the fit .",
    "given the large data - sets and complicated models , an arguably more rigorous approach to the integrated data - modelling challenge is the bayesian approach to inference in fusion plasmas .",
    "in contrast to least square fitting , the bayesian approach to inference in fusion plasmas , developed by multiple authors , @xcite involves the specification of an initial prior probability distribution function ( pdf ) , @xmath7 , which is then updated by taking into account information that the measurements provide through the likelihood pdf @xmath8 .",
    "the result is the posterior distribution @xmath9 given by bayes formula    @xmath10    the advantage of the bayesian approach over traditional inversion techniques is two - fold : ( i ) prior knowledge , including known parameter inter - dependencies is made explicit , and ( ii ) as the formulation is probabilistic , random errors , systematic uncertainties and instrumental bias are an integral part of the analysis rather than an afterthought .",
    "the application of bayesian approach to inference and parameter estimation in complex physics problems is not new , with fields ranging from astronomy to nuclear reaction analysis @xcite .",
    "a topical illustrative example comes from parameter estimation in the climate science community , in modelling land - surface - atmosphere processes and global carbon dioxide concentrations in the atmosphere.@xcite the models for carbon dioxide exchange are complex and span more equations of state than a plasma .",
    "the community atmosphere biosphere land exchange model ( cable ) is a land surface model , @xcite used to calculate the fluxes of momentum , energy , water and carbon between the land surface and the atmosphere and to model the major biogeochemical cycles of the land ecosystem .",
    "it solves radiation , heat and mass flow transport on a global scale , accounting for many different land ecosystems .",
    "data is disparate and vast , and comes from an flux towers , carbon stock , carbon in biomass , litter falls , meteorological data , stream flow and satellite imagery.@xcite in this community , the challenge of model and data integration , also called model  data fusion or model  data synthesis , is defined as combining models and observations by varying some properties of the model , to give the optimal combination of both.@xcite the topic of model  data fusion is crucial to give credibility to the calculation of carbon dioxide fluxes and processes in the atmosphere , and thus provide a reliable basis for public policy on climate change .",
    "bayesian inference , together with other model - data fusion techniques , is extensively utilised .",
    "in contrast to climate science , the systematic inclusion of uncertainties in both data and models has , to - date , not been a strength of the fusion community .",
    "several facets are driving change .",
    "iter discharges will be extremely expensive , and so it will be crucial to maximise the value of acquired data .",
    "the challenging environment of a fusion reactor will mean fusion power plants will operate with a very much reduced set of diagnostics .",
    "finally , as more physics is added to force - balance descriptions , there is a need to validate physics models .",
    "once validated , such models may be able to be used as a constraint in equilibrium reconstruction to infer additional information about the plasma , and thereby create `` model diagnostics '' .",
    "these aspects have motivated the recent development of a bayesian approach to equilibrium reconstruction@xcite , with one line of research producing a code called the bayesian equilibrium analysis and simulation tool ( beast ) , which is able to quantify fit degeneracies and infer spatially - localised discrepancies from a force - balance solution@xcite .",
    "this paper presents further research advancements since the introduction of beast by the authors@xcite and that have subsequently been used to advance the code .",
    "the paper is structured as follows :  [ sec1 ] gives a brief overview of bayesian inference and its application to equilibrium reconstruction .",
    "this is followed by a general discussion on the computational challenges surrounding bayesian equilibrium reconstruction and how these have been addressed by recent advancements , coded into beast .",
    "state - of - the - art results coming from the use of beast to analyse discharges on the mega - ampere spherical tokamak ( mast ) are then presented , followed up be a concluding remarks encompassing future research endeavours and a summary of the current status of beast . finally , two appendices detail specifics on recent advancements surrounding posterior optimisation and integration .",
    "bayesian inference offers an alternate approach to equilibrium modelling in fusion plasmas @xcite , and a pathway to validate different equilibrium model descriptions @xcite .",
    "some understanding can be gleaned by understanding the application of bayes theorem to a single observation with @xmath11 and @xmath12 . in this case ,",
    "bayes formula becomes @xmath13 where @xmath14 has been dropped to simplify the notation ; this convention will be maintained throughout the remainder of the paper .",
    "as @xmath3 and @xmath15 are given and thus assumed to be constant , so is @xmath16 , which is reflected by the proportionality in eq.([eq2 ] ) . the _ forward model _ , @xmath17 ,",
    "is implicitly contained within @xmath18 and is a deterministic mapping from the space of model parameters to the space of associated diagnostic observations .",
    "that is , the forward model generates a prediction of what the diagnostic observations would be , given a set of model parameters .    in most treatments likelihoods",
    "are assumed to be of the form @xmath19 where @xmath20 is represents a gaussian distribution over pair - wise independent variables .",
    "the first argument of the gaussian distribution represents the mean vector , with the second being the entries in a diagonal covariance matrix .",
    "the justification for the form of the likelihood is discussed elsewhere@xcite .    using the likelihood in eq.([eq2a ] ) , the following form can be written for the posterior : @xmath21 from eq.([eq3 ] ) , it is clear that the posterior represents a probability distribution over model parameters , if given a set of diagnostic observations and uncertainties .",
    "equation  ( [ eq3 ] ) is the form which is ultimately integrated to find statistical moments of model parameters and various marginalisations thereof .",
    "hole _ et .",
    "_  have implemented bayesian inversion on mast using the minerva framework.@xcite within this framework , probabilistic graphical models are used to project the dependence of the posterior distribution function on the prior , the data , and the likelihood .",
    "an advantage of this approach is that it visualises the complex interdependency between data and model , and thus expedites model development .",
    "the techniques of bayesian inference have also been inverted to provide a tool to check data consistency.@xcite    various authors have developed bayesian inference techniques for fusion plasmas that combine information from a wealth of diagnostics to enable probabilistic calculation of plasma configuration , @xcite provide automatic identification of faulty diagnostics,@xcite and developed a validation tool for generalised force - balance models @xcite .",
    "critically , bayesian techniques propagate experimental uncertainty correctly , and enable the relative uncertainty between acceptable physical models to be quantified . in von nessi _ et .",
    "al._@xcite , a new method , based on bayesian analysis , is presented which unifies the inference of plasma equilibria parameters in a tokamak with the ability to quantify differences between inferred equilibria and gs solutions . at the heart of this technique",
    "is the new concept of weak observation , which allows multiple forward models to be associated with a single diagnostic observation .",
    "this new idea subsequently provides a means by which the space of gs solutions can be efficiently characterised via a prior distribution . the posterior evidence ( a normalisation constant of the inferred posterior distribution ) is also inferred in the analysis and is used as a proxy for determining how relatively close inferred equilibria are to force - balance for different discharges / times .",
    "figure [ fig:22254 ] shows expectation values of the toroidal current density inferred from ( a ) a toroidal current beam model , ( b ) a gs constraint , in which @xmath22 is computed from gs from a @xmath1 surface , together with fits to the pressure and toroidal flux function , and forward models for magnetics , total plasma current and mse predictions , and ( c ) the difference between the two .",
    "the difference in @xmath22 can give some indication to physical effects neglected in the gs equation , and/or reflect diagnostic disagreement .",
    "in this case the discrepancy is largest at the outboard mid - plane , and of order of 10% . using nested sampling , it is possible to integrate over the evidence , and thus compute @xmath23 of the inferred hyper - parameter , @xmath24 , which is the average current variance between gs and toroidal current beam values . the smaller the value of @xmath23 , the larger the degree of freedom necessary to predict diagnostic observations relative to other cases . for 22254 at 350  ms @xmath25  ( ka)@xmath26 and @xmath27 , while @xmath28  ( ka)@xmath26 and @xmath29 for adjacent discharge # 24600 at 265ms .",
    "this meant # 22254 was much closer to gs , and/or had fewer diagnostics in conflict , than # 24600 .",
    "expectation values of @xmath30 and @xmath31 inferred for mast discharge # 22254 at 350 ms , as calculated from 1800 samples of the posterior , using pickup coils , flux loops , mse and rogowski coil data .",
    "the inferred last closed flux surface is indicated in white on each figure .",
    "flux loop locations are indicated by stars outside the plasma region ; position and orientation of pickup coils are indicated via heavy bars on the out - board edge of the first wall and as a vertically oriented column line along the solenoid ; and mse observation positions are indicated by the stars across the mid - plane inside the plasma region .",
    "panel ( a ) shows @xmath32 current density data , with the current densities in ( b ) reflecting that of @xmath33 . note that the number and size of beams representing @xmath32 and @xmath33 are allowed to differ in beast inferences .",
    "( c ) shows the magnitude of the current density difference as averaged across each 2d rectangular step corresponding to @xmath32 .",
    "reproduced with permission from fig .",
    "2 of von nessi and hole@xcite .",
    "the equilibria inference described in  [ sec1 ] poses a number of unique computational challenges when it comes to analysing the associated , high - dimensional ( i.e. having more than 1000 dimensions ) posterior distribution .",
    "this section discusses emergent points and recent research pursuits surrounding the computational aspects of bayesian equilibrium reconstruction , some of which have led to recent advances in the beast code beyond its original introduction in von nessi _ et .",
    "al._@xcite      the beam model used to represent the toroidal plasma current in the beast code , typically uses 524 model parameters to simulate a mast discharge.@xcite this high dimensionality alone constitutes a significant computational challenge in analysing the associated posterior distribution , as no efficient , general means exist to sample from such distributions.@xcite however , the plasma beam model obviously imposes no intrinsic spatial correlation between cross - sectional points contained within different beams , i.e. without the presence of an informative prior .",
    "alternative , more compact ( i.e. potentially more computationally efficient ) , representations for the beam currents have been trialled .",
    "specifically , both a 2d fourier and 2d bessel - fourier representations have been investigated .",
    "neither produced a computational procedure that could achieve the levels of accuracy of the beam model .",
    "this outcome is not surprising , given the non - linear nature of the force - balance constraint and the fact that there are no strict symmetries in the plasma current .",
    "indeed , these two points eliminate many paths by which a more compact representation of the beam currents could be achieved , under a force - balance constraint .      between flux loops , pickup coils and mse , there are about 150 diagnostic observations available for equilibrium reconstruction for a typical mast discharge .",
    "thus , fitting the parameters of the beam model above constitute an underdetermined problem , neglecting any priors .",
    "this underdetermined nature affords many  screening \" solutions to exist , where only currents nearest to diagnostic observation points need to be adjusted to compensate for any , otherwise arbitrary , configuration of beam currents .",
    "this translates into the posterior having many local maxima , with the global maxima  called the maximum of the posterior ( map)generally not corresponding to a physically realistic plasma configuration . while the addition of a force - balance prior serves to greatly reduce the number of these local minima ( in addition to making the global maxima correspond to a physically realistic plasma configuration ) , finding this global maxima is still computationally difficult and constitutes the majority of the computational time in beast inferences.@xcite indeed , even with the inclusion of a force - balance constraint , many screening solutions ( i.e. local maxima ) are still present , with many lying in close proximity to the global maxima .",
    "a significant increase in accuracy in inferring the map has been achieved through the development of a new non - linear optimisation algorithm , outlined in appendix [ smo3 ] .",
    "this optimiser is based on the hookes and jeeves algorithm@xcite but has been heavily modified to avoid screening solutions , when exploring the posterior .",
    "thus , we call this algorithm the `` screening mitigation optimiser '' ( smo ) .",
    "the posterior distribution associated with beast equilibrium reconstruction is high - dimensional and non - gaussian , having the majority of the probability `` mass '' in a highly - localised region of model parameter space.@xcite sampling from such distributions is inherently problematic and extremely computationally intensive.@xcite indeed , markov - chain monte - carlo ( mcmc ) methods are too inefficient to employ , as there is little chance for the chain to find ( and subsequently stay in ) the region of high probability density . moreover , it is difficult to find bounds on the accuracy of an analytic approximation of the posterior .",
    "thus , beast uses a statistical quadrature to build up moments of the posterior directly , rather than approximating these moments through sampling statistics .",
    "the method currently employed by beast to integrate the posterior is a generalisation of the modified nested sampling@xcite ( ns ) algorithm presented in von nessi _ et .",
    "al._@xcite , called the stochastic lebesgue quadrature ( slq ) .",
    "slq was developed to alleviate inefficiencies in employing mcmc techniques to generate prior samples under a likelihood constraint , which is intrinsically required by ns@xcite .",
    "moreover , slq is not affected by possibly ambiguities in classifying a pdf in the inference as part of the likelihood or a prior .",
    "slq is general enough to work with inferences that even use uninformative priors .    generally , the method works be approximating the set @xmath34 for any given @xmath35 by a collection of pairwise disjoint hypercubes .",
    "these hypercubes are generated from an evolving swarm of model parameter vectors , each of which is already guaranteed to satisfy the given posterior constraint . extracting a uniform sample from the union of hypercubes is a fast computation that is not only leveraged to evolve the swarm at each step but also provides the statistical basis for the construction of any posterior quadrature .",
    "the details of this method are explained in appendix [ slq ] .",
    "finally , slq has recently been deployed in beast and has resulted in more thorough exploration of the posterior during quadrature construction , which has ultimately lead to more consistent results coming from the computations ( see  [ results ] for more details ) .",
    "this has been achieved while maintaing the same to slightly shorter computational times , relative to those reported in von nessi _ et .",
    "expectation and standard deviation values of @xmath36 , along with the expectation values of @xmath37 inferred for mast discharge # 22254 at 350ms , as calculated from beast , using pickup coils , flux loops , mse and rogowski coil data . in each subfigure",
    "the lcfs , as inferred from beast , is drawn in black .",
    "flux loop locations are indicated by stars outside the plasma region ; position and orientation of pickup coils are indicated via heavy bars on the out - board edge of the first wall and as a vertically oriented column line along the solenoid ; and mse observation positions are marked by the stars across the mid - plane inside the plasma region .",
    "( a ) shows the expectation of @xmath36 : the current density data , with ( b ) presenting the magnitude of one standard deviation thereof .",
    "( c ) shows the magnitude of the @xmath37 expectation ( introduced in von nessi _ et .",
    "al._@xcite ) , which directly correspond to local deviations from force - balance , as dictated by the gs equation , with larger magnitudes reflecting a larger deviation . ]    here we present results from two mast discharges , which demonstrate beast s growth in capabilities since being initially introduced .",
    "the discharges analysed were # 22254 at 350ms and # 24600 at 280ms .",
    "both are dnd plasmas , with the former being in h - mode and the latter in l - mode .",
    "discharge # 22254 was part of a hybrid scenario study carried out in mast and is heated with 3.13mw of nbi power .",
    "contrasting this is # 24600 that was part of an l - mode study being injected with 3.35mw of nbi power .",
    "discharge # 22254 was studied in von nessi _ et .",
    "al._@xcite and is revisited here to show how the inference has been improved with recent advancements in beast .",
    "we look at # 24600 at 280ms , a time shortly after one of the two nbi beams disrupts , to study the impact of nbi disruption on the equilibrium .",
    "the following results are obtained from 76 pickup coils , 24 flux loops and 31 mse observations .",
    "finally , additive bias corrections and conducting surface currents are inferred in every beast inference@xcite ; however , these are treated as nuisance parameters , as they do not typically impact the physics interpretation of the results and thus , will not be reported here .    to interpret the results below",
    ", we note that beast outputs a cross - sectional quantity , @xmath37 , which indicates how close an associated configuration is to axisymmetric force - balance , with smaller values indicating configurations being relatively closer to force - balance.@xcite .",
    "qualitatively , @xmath37 reflects the level of discrepancy between the toroidal current density , calculated from the gs equation ( which ultimately uses pressure , poloidal current and toroidal current model parameters ) and that calculated directly from the plasma beam model ; for more details see von nessi _ et .",
    "thus , relatively large values of @xmath37 can be viewed as an indicator for missing physics in the force - balance model .      in  [ sec2 ]",
    "the smo algorithm was introduced , which has consistently found diagnostic fits that were closer to force - balance than results coming from other optimisers .",
    "this is exemplified in fig.[fig::22254beamdata ] , where a fit for # 22254 is found with a @xmath37 with values @xmath38 times smaller than the initial results presented in von nessi _ et .",
    "al._@xcite , which are reproduced in fig.[fig:22254 ] .",
    "in particular , a force - balance solution was able to be much better reconciled on the outboard edge of the plasma around the mse measurements .",
    "ultimately this has resulted in a retraction of the plasma boundary compared to the efit lcfs ( shown in fig.[fig::22254poloidalflux ] for comparison ) , which is only constrained by flux loops and inboard pickup coils , not mse .",
    "the difference in plasma volume accounts largely for the discrepancy of @xmath39 between efit and beast : @xmath40 and @xmath41 , respectively , with @xmath42 confidence intervals on the beast result .",
    "this small uncertainty in the beast result coincides with the inference being over - determined ( i.e. a very small degree of degeneracy ) , when a force - balance prior is leveraged against the unbiased space of model parameters .",
    "this makes sense , as the gs equation is an elliptic , semi - linear pde having unique solutions@xcite , which is paramaterised only by pre - defined representations of the pressure and poloidal current profiles ( polynomials of degree 3 and 5 respectively for these results ) .",
    "thus , the space of all configurations is biased toward an eight - dimensional submanifold , on which the problem becomes over determined , when reconciled against over 100 diagnostic observations .",
    "one may argue that the boundary paramaterization also needs to be accounted for ; but this can be determined independently of solving the gs equation@xcite and does not embody genuine degrees of freedom in the inference .",
    "poloidal flux function expectation and standard deviation as calculated by beast for # 22254 at 350ms .",
    "positions of magnetics and mse observation points are indicated as they were in fig.[fig::22254beamdata ] . in both subfigures",
    "the efit lcfs is plotted in white with the beast lcfs overlaid in black . ]",
    "figure [ fig::22254beamdata](b ) shows the magnitude of a single standard deviation for the current density distribution , which are noted to be uniformly much smaller compared to the expectation values in fig.[fig::22254beamdata](a ) .",
    "this is also consistent with a small uncertainty in the @xmath39 for the beast result .",
    "figure [ fig::22254poloidalflux ] shows the poloidal current expectation and first standard deviation magnitude . here",
    "again , the uncertainties are much smaller , as compared to those presented in von nessi _ et .",
    "in addition to , the uncertainty being on the order of five times smaller , the area of greatest uncertainty is larger , being spread across the outboard edge of the plasma , as opposed to be consolidated around the pf coils in von nessi _ et .",
    "the very small uncertainty in the poloidal flux reflects a very high precision in flux - surface positions for a gs model of force - balance .",
    "the expectation value of the poloidal flux function is very similar to the results in von nessi _ et .",
    "al._@xcite , with the biggest difference being that the outboard lcfs has slightly migrated toward the core of the plasma .    for # 22254 at 350ms , the inferred pressure , poloidal current and q - profiles were all inferred with very similar expectations and uncertainties , compared to previous results@xcite . in general , these profiles exhibit expectations that are in good agreement with efit and have extremely small uncertainties .",
    "moreover , these profile appear to be close to gaussian marginalisations , showing symmetric uncertainties and having their expectations coincide with their respective maps .",
    "expectation and standard deviation values of @xmath36 , along with the expectation values of @xmath37 inferred for mast discharge # 24600 at 280ms , using the same diagnostics as in fig.[fig::22254poloidalflux ] .",
    "the lcfs and diagnostic positions are also likewise indicated .",
    "( a ) shows the expectation of @xmath36 , with ( b ) again showinging the magnitude of one standard deviation thereof .",
    "( c ) shows the magnitude of the @xmath37 expectation . ]",
    "reflecting 280ms immediately following a nbi disruption , fig.[fig::24600beamdata ] shows an equilibrium inference that is significantly out of force - balance .",
    "the force - balance discrepancy peaks out around @xmath43 at four , spatially separated point , clearly indicated in fig.[fig::24600beamdata](a ) .",
    "moreover , the uncertainties on the toroidal current are generally one to two orders magnitude greater than those for # 22254 at 350ms .",
    "this relative increase in uncertainty is due to an increase in fit degeneracy , as more degrees of freedom will emerge the farther away from force - balance the inference gets . interpreting @xmath39 between beast and efit is challenging in this context , as the beast inference is not in force - balance .",
    "however , comparing the efit and beast values of @xmath44 and @xmath45 , respectively , for this quantity show that both agree that this value be less about the same amount , when compared to the results from # 22254 .",
    "moreover , the uncertainties on the beast result are about an order of magnitude greater , which is consistent with the arguments put forth above .",
    "poloidal flux function and q - profile expectations calculated by beast for # 24600 at 280ms .",
    "positions of magnetics and mse observation points in ( a ) are indicated as they were in fig.[fig::22254beamdata ] . in ( a )",
    ", the efit lcfs is plotted in white with the inferred lcfs overlaid in black .",
    "( b ) displays the q - profile as calculated by beast ( the expectation ) and efit , represented by the purple and green lines , respectively .",
    "uncertainties on the beast q - profile are too small to visually resolve on the scale of the figure and have thus been suppressed . ]",
    "figure [ fig::24600poloidalflux](a ) shows a good agreement between both the efit an beast lcfs .",
    "again , this can be explained by the arguments in the preceding paragraph regarding the growth of degeneracy uncertainty and recalling that the boundary can be inferred independently of force - balance constraints .",
    "however , fig.[fig::24600poloidalflux](b ) shows a discrepancy of about @xmath46 between the q - profiles of efit and beast .",
    "this is mostly due to the fact that beast s q - profile is strongly constrained to mse measurements , while the efit reconstruction is not .",
    "this discrepancy in q - profile coincides with the difference between the beast and efit inferences of @xmath39 ( despite both plasmas having similar volumes ) , as @xmath47 depends on magnetic field geometry .    inferred poloidal current for # 24600 at 280ms , right after the southwest neutral beam disrupts .",
    "the dotted line indicates the map profile , with the thick line being the expectation .",
    "the thin lines represent upper / lower confidence intervals of 95% , with the shading posterior probabilities of quadrature points . ]    in fig.[fig::24600pandf ] , the profile for the poloidal current is shown , demonstrating the non - gaussian nature of the quantity .",
    "indeed , the plot shows the map of the profile lying outside the @xmath42 confidence intervals , surrounding the expectation , implicating the profile as highly non - gaussian in the core region of the plasma .",
    "this result demonstrates beast s ability to resolve non - gaussian structures in even high - dimensional marginalisation of the posterior . echoing the discussion put forth in von nessi _ et .",
    "al._@xcite , we ascribe no rigorous physical interpretation to the kinetic pressure , as the inference is far from force - balance and there exists no direct constraint on the kinetic pressure in the inference .",
    "thus , we do not present the pressure profile for this inference here .      beast routinely outputs various information theoretic scalars , such as the evidence and relative entropy between posterior and prior distributions . however , interpreting the meaning of these quantities , outside the realm of model comparison , becomes difficult for the following reasons .",
    "first , it is well easily understood that likelihoods are not probability distributions@xcite ; and even in the form of eq.([eq2a ] ) , likelihoods still enjoy a gauge freedom corresponding to an arbitrary scalar multiplier , which will directly affect the value of the evidence .",
    "moreover , the number of observations itself will also have an obvious impact on the evidence ( c.f .",
    "eq.([eq3 ] ) ) .    when leveraging implicit techniques to construct priors , like the methods employed in beast to bias toward force - balance , faithfully calculating the relative entropy between prior and posterior distributions is difficult , as the prior is not normalised during the quadrature construction .",
    "indeed , we only need to leverage relative probabilities from the prior to construct the posterior quadratures , when using a technique like slq .",
    "it is possible to classify the force - balance prior as part of the likelihood in this situation , but this leads to ambiguities as to how to classify distributions as priors or likelihoods . given this , we instead report the relative entropy , @xmath48 , between posterior and the approximating uniform distribution used in the slq calculation ( see appendix [ slq ] ) . to give some context to the meaning of @xmath48 , the volume of the approximating uniform distribution , @xmath49 , is reported via its natural logarithm , @xmath50 , to be consistent with the notation in appendix [ slq ] .    for # 22254 at 350ms the relative entropy between the posterior and the initial approximating uniform distribution having @xmath51 was @xmath52 bits , with the uncertainty being the @xmath42 confidence interval .",
    "discharge # 24600 at 280ms had @xmath53 bits relative to an initial uniform distribution having @xmath54 . generally speaking ,",
    "these values reflect how much information was provided by both diagnostic observations and the force - balance prior in the inference . as uncertainties were generally higher for # 24600 at 280ms",
    ", a higher relative entropy means that the observations and prior were more effective at excluding outlier configurations , relative to those for # 22254 .",
    "thus , while @xmath55 s posterior had less degeneracy around its expectation , it had relatively heavier `` wings '' , as compared to @xmath56 .",
    "this interpretation is reinforced by the fact that # 24600 started out with a more informed uniform distribution , as compared to # 22254 , but still maintained a higher relative entropy despite this .",
    "research in the area of bayesian equilibrium reconstruction has rapidly advanced since the work of svesson and werner@xcite , which has gone from analytic inversion leveraging very few physical assumptions to the current state - of - the - art where complex force - balance models can be seamlessly folded into a non - analytic , robust inference on over 1000 model parameter dimensions .",
    "today , bayesian equilibrium reconstruction compensates for broken diagnostics _ _ in situ__@xcite in addition to being able to marginalise out uncertainties due to conducting surface currents , all while preserving the integrity of the inference results .",
    "this paper presents the most recent advancements in the area , which surround the computational aspects of analysing the posterior .",
    "the end result being that the equilibrium for a high - performance mast discharge has been shown to be consistent with static gs force - balance , implying that the current selection of diagnostics used in this analysis will need to be expanded , if one wishes to resolve physics not already represented in the gs equation .    developing research endeavours in this area include adding in a toroidal flow component into the force - balance relation , along with more diagnostic data , and seeing how this affects the inference on mast discharges . work is also progressing on deploying beast on the kstar experiment , where both 2d mse and diamagnetic loop data can be leveraged to better constrain the equilibrium inference . on the computational end of research ,",
    "the possibility of deploying machine learning techniques to generate better initial guesses for posterior optimisation is being explored , as it is now the search for the map which takes up the majority of computational time ( as opposed to the construction of posterior quadratures ) .",
    "in this section we briefly outline the directional search algorithm developed for use in beast s optimisation of the posterior .",
    "the direction search starts from an initial guess , @xmath57 , a given , scalar increment , @xmath58 , and proceeds as follows .    1 .   at @xmath57 the target function",
    "is evaluated , with the value stored ( denoted @xmath59 ) .",
    "2 .   if @xmath58 is smaller than a pre - defined threshold , the algorithm terminates .",
    "otherwise , the procedure continues onto the next step .",
    "3 .   evaluate the target function at @xmath60 , where @xmath61 is the unit vector for the @xmath62th coordinate , for all coordinate directions .",
    "sign / direction combinations showing no improvement over @xmath59 ( in the case of the posterior , are less than @xmath59 ) are discarded , with all other combinations being recorded and ranked according to which ones gave the largest improvement over @xmath59 .",
    "we label each improving coordinate increment as @xmath63 , with lower indices having greater improvement over @xmath59 ; i.e. @xmath63 will generally have the form @xmath64 , with @xmath62 and @xmath65 uncorrelated . if no direction is found that improves @xmath59 , the value of @xmath58 is scaled down ( in beast @xmath58 is scaled down by a factor of @xmath66 ) and the algorithm returns to step 2 .",
    "4 .   count the number of @xmath63 s and record this value as @xmath67 .",
    "5 .   evaluate the target at @xmath68 6 .",
    "if the evaluation at @xmath69 produces a result better than @xmath59 , a line search is performed along @xmath70 from the point @xmath57 .",
    "the result of this search replaces the value of @xmath57 and the algorithm returns to step 1 , with @xmath58 being set to it s initial value .",
    "otherwise , @xmath67 is decremented by one and the algorithm returns to step 5 .    in beast , a golden section@xcite line search is used in the above ; but any line search method could be applied .",
    "the key point to tho above approach in that it is a `` breadth - first '' algorithm in that it will try to change as many model parameter coordinates as possible in each step , as opposed to accepting possibly better gains by moving along just a few coordinates . indeed , moving along one coordinate at any given step , may indeed produce a better immediate result ; but this has a tendency to drive the optimiser into local maxima presented by the screening solutions discussed in  [ smo2 ] .",
    "this is the same problem has also been found with both steepest descent and conjugate gradient optimisers , when deployed in beast .",
    "this last point is unsurprising , as one would nt expect such algorithms to be effective on functions with many local maxima .",
    "the above algorithm is designed specifically to avoid these local maxima and has proven to be extremely robust in beast inferences and has the added advantage that it does not require gradient calculations .",
    "one can argue that all of bayesian inference can be reduced to posterior quadrature calculations .",
    "indeed , any statistical moments of model parameters or marginalisations thereof can be represented as @xmath71 where @xmath72 being the number of model parameters , with diagnostic observations implicitly held as parameters within @xmath73 . with this , we seek to develop a numerical scheme to integrate @xmath74 for possibly large values of @xmath72 .    first , we assume @xmath75 , to guarantee the existence of a bounded set @xmath76 such that @xmath77 for any given @xmath78 . thus , we are able to make the following approximation @xmath79 where @xmath49 denotes the @xmath72-dimensional volume of @xmath76 and @xmath80 one will note that the co - area formula@xcite has been employed in the last step of eq.([slq3 ] ) .",
    "it is clear that @xmath81 is normalised to one by definition and thus , constitutes a uniform probability distribution .",
    "the motivation for this particular factorisation is embodied in the following definition @xmath82 which hints at a way in which uniform sampling may be employed to obtain the desired integral . to fully realise this , we note eq.([slq4 ] ) directly indicates that @xmath83 may be statistically inverted via ordering uniform samples of @xmath76 with respect to their @xmath84 evaluations .",
    "indeed , given a collection of @xmath85 uniform samples of @xmath76 , denoted @xmath86 , indexed according to @xmath87 then eq.([slq4 ] ) indicates that @xmath88 to use this insight , we employ the definition in eq.([slq4 ] ) and make the substitution @xmath89 to reduce the expression in eq.([slq3 ] ) : @xmath90\\nonumber\\\\ & = & |\\mathcal{b}|\\left[-\\inf_\\mathcal{{\\overline{\\lambda}}\\in b}\\mathcal{q({\\overline{\\lambda}})}+\\int_0 ^ 1\\xi^{-1}(v)\\,dv\\right]\\nonumber\\\\ & \\approx & |\\mathcal{b}|\\int_0 ^ 1\\xi^{-1}(v)\\,dv,\\label{slq7}\\end{aligned}\\ ] ] where we have used integration by parts and the assumption that @xmath76 can be chosen to make @xmath91 small enough to satisfy the desired level of accuracy for the quadrature .",
    "one will note that the assumption of @xmath75 automatically implies that @xmath92 .    while the above is very similar to the development presented in von nessi _ et .",
    "al._@xcite , it differs from that derivation in that the quadrature transformation has no intrinsic reliance on the demarkations of likelihoods and priors .",
    "indeed , the above result is quite general in that @xmath73 need not be related to a probability distribution .",
    "moreover , the definition of @xmath83 needed to be altered to accommodate the transform s reliance on uniform distributions , which ultimately leads to the addition of the @xmath49 term in the final expression .",
    "the expression in eq.([slq6 ] ) indicates that a graph of @xmath83 can be statistically constructed by taking an ordered set of @xmath84 evaluations coming from @xmath85 uniform samples of @xmath76 with an abscissa constructed of @xmath85 ordered uniform samples taken on @xmath93 $ ] .",
    "concretely , given the @xmath85 samples denoted in eq.([slq6 ] ) , one can take @xmath85 uniform samples , @xmath94 , from @xmath93 $ ] indexed so that @xmath95 to approximate @xmath96 one can refine the resolution of any part of this graph by adding , say @xmath97 , abscissa values coming from uniform samples on @xmath98 $ ] and @xmath97 values coming from uniform samples taken from @xmath99 and reordering both sets of @xmath100 values according to eq.([slq5])eq.([slq8 ] ) .",
    "this is a general prescription for graph refinement , for which skilling s ns is a particular instance of.@xcite indeed , this method can be directly leveraged to design both single - threaded and multi - threaded generalisations of ns .",
    "however , for the results presented in this paper , we retain the original ns methodology for refining the graph in eq.([slq8 ] ) , which is detailed elsewhere@xcite .",
    "once a refinement of sufficient accuracy has been achieved , @xmath74 is simply evaluated via eq.([slq7 ] ) , eq.([slq8 ] ) and the application of a trapezoidal quadrature rule .",
    "the computational tractability of slq relies on the ability to generate uniform samples from the set @xmath101 for any @xmath102 efficiently . clearly , _",
    "ab initio _ uniform sampling of @xmath76 will be rendered unacceptably inefficient as a proxy for sampling on @xmath103 for values of @xmath104 approaching @xmath105 .",
    "one approach to dealing with this is to approximate @xmath103 by a collection of @xmath72 dimensional , pair - wise disjoint hypercubes , denoted @xmath106 , each with their coordinate axis corresponding to the collection of model parameters in the problem .",
    "these cubes need not be of the same volume or proportion .",
    "each cube is then assigned a relative probability based on its volume : @xmath107 to uniformly sample from @xmath108 , one first needs to randomly select a particular hypercube s index according to the probability in eq.([slq9 ] ) , then one can perform uniform gibb s sampling on the selected cube to finally generate the next uniform sample from @xmath109 .",
    "indeed , this prescription can be viewed as a gibb s sampling over @xmath72 dimensions , plus one discretised dimension corresponding to the indexing on the hypercube approximation .",
    "this sampling over a union of hypercubes can be carried out very quickly , even in high - dimensions with many cubes in the collection ; and thus offers an appealing foundation on which to build a statistical quadrature .",
    "the next point to be addressed is how to create and maintain a collection of hypercubes which closely approximates @xmath103 . to this end",
    "a collection of points @xmath110 is first created and evolved to directly correspond to the pool of samples used in the ns quadrature construction .",
    "in addition to these points , the map and a collection of _ ab initio _ uniform samples from @xmath76 are initially added to the collection of @xmath111 .",
    "once any of these points fail to meet the @xmath84 constraint in the ns progression , skilling s multi - state leapfrog algorithm ( see  30.4 in mackay@xcite for details ) is employed on the collection of @xmath111 to find new points to replace those that no longer meet the @xmath84-constraint . if a fixed number of attempts fails to produce points that satisfy the new @xmath84-constraint , then effort is abandoned and the collection of @xmath111 is reduced accordingly .      1 .   establish a minimal hypercube with axes corresponding to model parameters in the inference which contains all @xmath111 .",
    "we denote this hypercube @xmath112 .",
    "2 .   for each @xmath111 create a hypercube , @xmath106 of the same size and orientation as @xmath112 .",
    "3 .   perform a pairwise comparison between all @xmath106 , going through each dimensions to see if they are disjoint .",
    "note that the cubes need only be non - overlapping in one dimension to be disjoint .",
    "if a pair of hypercubes , @xmath106 and @xmath113 , are overlapping , establish the coordinate that constitutes their greatest separation .",
    "we will label this the @xmath97th coordinate for convenience .",
    "2 .   if both @xmath106 and @xmath113 have their current bounding hyperplane along the @xmath97th coordinate lying between @xmath111 and @xmath114 , these hyperplanes are adjusted to have their @xmath97th coordinate be the average of the @xmath97th coordinates of both their previous positions .",
    "if only one of @xmath106 or @xmath113 has their current bounding hyperplane along the @xmath97th coordinate lying between @xmath111 and @xmath114 , then the other s bounding hyperplane s @xmath97th coordinate is adjusted to coincide with that of the one that separates @xmath111 and @xmath114 .",
    "4 .   if neither @xmath106 nor @xmath113 has their current bounding hyperplane along the @xmath97th coordinate lying between @xmath111 and @xmath114 , then then both bounding hyperplanes are adjusted so their @xmath97th coordinate coincides with the @xmath97th coordinate of the average position between @xmath111 and @xmath114 .",
    "once the collection of approximating hypercubes is first established , changes , additions and removals ( corresponding to the evolution of @xmath111 ) can be made in accordance with the above pseudo - code in @xmath115 time , where @xmath85 is the current number of cubes .",
    "this is achieved primarily by tracking the coordinates along which each pair of cubes is separated and by noting which bounding hyperplanes correspond to those of @xmath112 for each @xmath106 and subsequently using this information to minimise the number of comparisons made on hypercube insertions and deletions .",
    "the above algorithm ensures that @xmath108 contains all @xmath116 with no overlaps between cubes ; although this union will not be a cover for @xmath112 , in general .",
    "as @xmath112 will typically be a poor approximation of @xmath103 , a global scaling factor , @xmath117 , along with a family of linear mappings @xmath118 on the collection of @xmath106 , having the properties @xmath119 and @xmath120 is also introduced .",
    "ultimately , new uniform samples are drawn from @xmath121 where @xmath117 is dynamically adjusted on the interval @xmath122 to achieve a desired level of efficiency for uniform samples having @xmath84-evaluations greater than @xmath104 .",
    "this work was jointly funded by the australian government through international science linkages grant cg130047 , the australian research council grant ft0991899 , the australian national university , the united kingdom engineering and physical sciences research council under grant ep / g003955 , and by the european communities under the contract of association between euratom and ccfe . the views and opinions expressed herein do not necessarily reflect those of the european commission .",
    "d.  mazon , j.  blum , c.  boulbe , b.  faugeras , a.  boboc , m.  brix , p.  de - vries , s.  e. sharapov , and l.  zabeo . .",
    "4th international conference on physics and control _ , catania , italy , 2010 .",
    "world scientific ."
  ],
  "abstract_text": [
    "<S> we present recent results and technical breakthroughs for the bayesian inference of tokamak equilibria using force - balance as a prior constraint . </S>",
    "<S> issues surrounding model parameter representation and posterior analysis are discussed and addressed . </S>",
    "<S> these points motivate the recent advancements embodied in the bayesian equilibrium analysis and simulation tool ( beast ) software being presently utilised to study equilibria on the mega - ampere spherical tokamak ( mast ) experiment in the uk ( von nessi _ et . </S>",
    "<S> al._2012 _ j. phys . </S>",
    "<S> a _ * 46 * 185501 ) . </S>",
    "<S> state - of - the - art results of using beast to study mast equilbria are reviewed , with recent code advancements being systematically presented though out the manuscript . </S>"
  ]
}