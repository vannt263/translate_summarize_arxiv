{
  "article_text": [
    "randomized experiments are the `` gold standard '' for estimating causal effects , because randomization balances all potential confounding factors _ on average_. however , if in a particular experiment , a randomization creates groups that are notably unbalanced on important covariates , should we proceed with the experiment , rather than rerandomizing and conducting the experiment on balanced groups ?    with @xmath0 independent covariates , the chance of _ at least one _ covariate showing a `` significant difference '' between treatment and control groups , at significance level @xmath1 , is @xmath2 . for a modest 10 covariates and a 5% significance level ,",
    "this probability is 40% .",
    "`` most experimenters on carrying out a random assignment of plots will be shocked to find how far from equally the plots distribute themselves '' @xcite .",
    "the danger of relying on pure randomization to balance covariates has been described in @xcite ; @xcite ; @xcite ; @xcite ; @xcite ; @xcite and @xcite .",
    "also , there exists much discussion historically over whether randomization should be preferred over a purposefully balanced assignment [ @xcite ( @xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ] .",
    "our view is that with rerandomization , we can retain the advantages of randomization , while also ensuring balance .",
    "it is standard in randomized experiments today to collect covariate data and check for covariate balance , yet typically this is done after the experiment has started .",
    "if covariate data are available before the physical experiment has started , a randomization should be checked for balance _ before _ the physical experiment is conducted . if lack of balance is noted , as gosset stated , `` it would be pedantic to continue with an arrangement of plots known beforehand to be likely to lead to a misleading conclusion '' @xcite .",
    "it appears that fisher would agree . in @xcite",
    ", rubin recounts the following conversation with his advisor bill cochran :    _ rubin _ : what if , in a randomized experiment , the chosen randomized allocation exhibited substantial imbalance on a prognostically important baseline covariate",
    "?    _ cochran _ : why did nt you block on that variable ?    _ rubin _ : well , there were many baseline covariates , and the correct blocking was nt obvious ; and i was lazy at that time .    _ cochran _ :",
    "this is a question that i once asked fisher , and his reply was unequivocal :    _ fisher ( recreated via cochran ) _ : of course , if the experiment had not been started , i would rerandomize .    a similar conversation between fisher and savage , wherein fisher advocates rerandomization when faced with an undesirable randomization , is documented in @xcite [ ( @xcite ) , page 88 ] .",
    "checking covariates and rerandomizing when needed for balance has been advocated repeatedly .",
    "@xcite recommend rerandomization when `` obvious '' lack of balance is observed .",
    "@xcite suggests that if `` important imbalances exist , rerandomize , and continue to do so until satisfied . '' for clinical trials , @xcite states that `` if such baseline imbalances are found then the recommendation ",
    "is to re - randomize in the hope that this time no baseline imbalances will occur . ''",
    "@xcite and @xcite have advocated rerandomization , suggesting either to do multiple randomizations and pick the `` best , '' or to specify a  bound for the difference in treatment and control covariate means for each covariate , following the `` big stick '' method of @xcite , and rerandomize until all differences are within these bounds .",
    "the latter rerandomization method was used in @xcite .",
    "there are also many sources giving reasons _ not _ to rerandomize .",
    "good accounts of the debate over rerandomization can be found in @xcite and @xcite .",
    "the most common critique of rerandomization is that forms of analysis utilizing gaussian distribution theory are no longer valid [ @xcite ( @xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ; holschuh(@xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ; bailey and rowley ( @xcite ) ] .",
    "rerandomization changes the distribution of the test statistic , most notably by decreasing the true standard error , thus traditional methods of analysis that do not take this into account will result in overly `` conservative '' inferences in the sense that tests will reject true null hypotheses less often than the nominal level and confidence intervals will cover the true value more often than the nominal level . however , randomization - based inference is still valid [ @xcite ( @xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ] , because the rerandomization can be accounted for during analysis .",
    "all other critiques of rerandomization , of which we are aware , deal with `` ad - hoc '' rerandomization , that is , rejecting randomizations without specifying a rejection criterion in advance .",
    "we only advocate rerandomization if the decision to rerandomize or not is based on a pre - specified criterion . by specifying an objective rerandomization rule before randomizing , and then analyzing results using randomization - based methods , we can , in most circumstances , finesse all existing criticisms of rerandomizing .",
    "some may think that rerandomization is unnecessary with large sample sizes , because as the sample size increases , the difference in covariate means between groups gets smaller , essentially proportional to the square root of the sample size .",
    "however , at the same rate , confidence intervals and significance tests are getting more sensitive to small differences in outcome means , which can be driven by small differences in covariate means .    despite the ongoing discussion about rerandomization and the fact that it  is widely used in practice [ @xcite ( @xcite ) ; @xcite ( @xcite ) ; bailey and rowley ( @xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ] , little has been published on the mathematical implications of rerandomization .",
    "remarkably , it appears that no source even makes explicit the conditions under which rerandomization is valid .",
    "although a few rerandomization methods have been proposed [ @xcite ( @xcite ) ; @xcite ( @xcite ) ; bruhn and mckenzie ( @xcite ) ; @xcite ( @xcite ) ] , the implications have not been theoretically explored , to the best of our knowledge .",
    "the only published theoretical results accompanying a rerandomization procedure appear to be those in @xcite , which proposed rerandomization to lower the sampling variance of covariance - adjusted estimates . here",
    "we aim to fill these lacuna by ( a ) making explicit the sufficient conditions under which rerandomization is valid , ( b ) describing in detail a principled procedure for implementing rerandomization and ( c ) providing corresponding theoretical results .",
    "the procedure for implementing rerandomization is depicted in figure  [ flowchart ] , and has the following steps :    collect covariate data .",
    "specify a balance criterion determining when a randomization is acceptable .",
    "randomize the units to treatment groups .",
    "check the balance criterion ; if the criterion is met , go to step ( 5 ) .",
    "otherwise , return to step ( 3 ) .",
    "conduct the experiment using the final randomization obtained in step ( 4 ) .",
    "analyze the results using a randomization test , keeping only simulated randomizations that satisfy the balance criterion specified in step  ( 2 ) .",
    "let @xmath3 be the @xmath4 covariate matrix representing @xmath0 covariates measured on @xmath5 experimental units .",
    "here we assume that a sample of units has already been selected and is fixed . because we are not considering the sampling mechanism , we are only interested in the extent to which a causal effect estimate obtained in _ this _ randomized experiment is a good estimate of the true causal effect within the selected sample .",
    "the @xmath3 matrix includes all the observed covariates for which balance between groups is desired , which may include original covariates , and any functions of original covariates , such as transformations , powers and interactions .",
    "let @xmath6 be the @xmath5-dimensional treatment assignment vector indicating the treatment group for each unit .",
    "the rerandomization criterion is based on a row - exchangeable scalar function of  @xmath3 and @xmath6 .",
    "@xmath7 the function @xmath8 can vary depending on the relative importance of balancing different covariates , on the level of covariate balance desired and on the computational power available , but it is specified in advance .    more generally , we can define a set of acceptance criteria , @xmath9 , from which we choose at each step , @xmath10 , either deterministically or stochastically , where this choice can depend on the step , so that , for example , we can become more lenient as the steps increase without success . in this more general situation",
    ", @xmath11 denotes the acceptance criterion for step @xmath10 .",
    "although our theoretical results in sections [ implementing ] and [ mahalanobis ] hold for this more general setup , in practice we expect that the common choice will be one function for all steps , and to avoid notational clutter , we present results with one criterion.=1    once @xmath8 has been specified , units are randomized to treatment groups ( step 3 ) . in the simplest form of rerandomization ,",
    "this can be done with no restrictions ; for example , randomly choose an assignment vector @xmath6 from all possible vectors , or equivalently from all possible partitions of the units into groups .",
    "in practice , the initial randomization is typically done with some restriction to equalize treatment group sizes .",
    "rerandomization is simply a tool that allows us to draw from some predetermined set of acceptable randomizations , @xmath12 .",
    "rerandomization is analogous to rejection sampling ; a way to draw from a set that may be tedious to enumerate .",
    "specifying a set of acceptable randomizations and then choosing randomly from this set is recommended by @xcite ( @xcite ) and @xcite , and @xcite notes that rerandomization may be required for implementation of this idea when the set of acceptable randomizations is difficult to enumerate a priori .    within this framework ,",
    "rerandomization simply generalizes classical experimental designs .",
    "for the basic completely randomized experiment with fixed sample sizes in each treatment group , @xmath13 when the number of units assigned to each group matches the predetermined group sizes . for a randomized block experiment , @xmath14 when predetermined numbers of units within each block are assigned to each treatment group . for a latin square , @xmath14 when the randomization satisfies the latin square design .",
    "these classical designs can be readily sampled from , so rerandomization is computationally inefficient , although equivalent , but for other functions ,  @xmath8 , rerandomization may be a more straightforward technique .",
    "rerandomization can also be used together with any classical design .",
    "for example , in a medical experiment on hypertensive drugs , we may block on sex and a  coarse categorization of baseline blood pressure , and use rerandomization to balance the remaining covariates , including fine baseline blood pressure.=1    researchers are free to chose any function @xmath8 , provided it is chosen in advance .",
    "section [ unbiasedsec ] describes the conditions necessary to maintain general unbiasedness of simple point estimation , section [ mahalanobis ] recommends a particular class of functions and studies theoretical properties of this choice and section  [ affinerr ] discusses some reasons for choosing an affinely invariant @xmath8 .",
    "under most forms of rerandomization , increasing balance in the covariates will typically create more precise estimated treatment effects , making traditional gaussian distribution - based forms of analysis statistically too conservative .",
    "however , the final data can be analyzed using a randomization test , maintaining valid frequentist properties .",
    "as fisher stated , `` it seems to have escaped recognition that the physical act of randomization   affords the means , in respect of any particular body of data , of examining a wider hypothesis in which no normality of distribution is implied '' @xcite .",
    "this physical act of randomization need not be pure randomization , but any randomization scheme that can be replicated when conducting the randomization test .",
    "we are interested in the effect of treatment assignment , @xmath15 , on an outcome , @xmath16 .",
    "let @xmath17 denote the @xmath18th unit s , @xmath19 , potential outcome under treatment assignment @xmath20 , following the rubin causal model @xcite .",
    "although rerandomization can be applied to any number of treatment conditions , to convey essential ideas most directly , we consider only two , and refer to these conditions as treatment and control .",
    "let @xmath21 let @xmath22 denote the vector of observed outcome values : @xmath23 where for notational simplicity the subscript @xmath24 means @xmath25 . under the sharp null hypothesis of no treatment effect on any unit , @xmath26 for every @xmath18 , and thus the vector @xmath27 is the same for every treatment assignment @xmath15 .",
    "consequently , leaving @xmath27 fixed and simulating many acceptable randomization assignments , @xmath6 , we can empirically create the distribution of any estimator , @xmath28 , if the null hypothesis were true . to account for the rerandomization",
    ", each simulated randomization must also satisfy @xmath29 .",
    "once the desired number of randomizations has been simulated , the proportion of simulated randomizations with estimated treatment effect as extreme or more extreme than that observed in the experiment is the @xmath30-value .",
    "although a full permutation test ( including all the acceptable randomizations ) is necessary for an exact @xmath30-value , the number of simulated randomizations can be increased to provide a @xmath30-value with any desired level of accuracy .",
    "this test can incorporate whatever rerandomization procedure was used , will preserve the significance level of the test @xcite and works for any estimator .",
    "@xcite , @xcite and @xcite [ ( @xcite ) , chapter 7 ] suggest using randomization tests to assess significance when restricted randomization schemes are used .",
    "because analysis by a randomization test requires generating many acceptable randomizations , computational time can be important to consider in advance .",
    "define @xmath31 to be the proportion of acceptable randomizations .",
    "the choice of @xmath32 involves a trade - off between better balance and computational time ; smaller values of @xmath32 ensure better balance , but they also imply a longer expected waiting time to obtain an acceptable randomization , at least without clever computational devices .",
    "the number of randomizations required to get one acceptable randomization follows a geometric distribution with parameter @xmath32 , so @xmath33 simulated acceptable randomizations for a randomization test will require on average @xmath34 randomizations to be generated .",
    "the chosen @xmath32 must leave enough acceptable randomizations to perform a randomization test . in practice",
    "this is rarely an issue , because the number of possible randomizations is huge even for modest @xmath5 .",
    "to illustrate , the number of possible randomizations for @xmath35 randomizing to two equally sized treatment groups , @xmath36 , is on the order of @xmath37 , respectively .",
    "however , for small sample sizes , care should be taken to ensure the number of acceptable randomizations does not become too small , for example , less than 1000 .    by employing the duality between confidence intervals and tests , for additive treatment effects",
    "a confidence interval can be produced from a randomization distribution as the set of all values for which the observed data would not reject such a null hypothesized value [ @xcite ( @xcite ) ; @xcite ( @xcite ) , section  3.5 , section 1.4 ] .",
    "@xcite provides an efficient algorithm for generating a confidence interval for additive effects from a randomization test .",
    "the assumption of additivity is statistically conservative , at least asymptotically , as implied by neyman s @xcite results on standard errors being overestimated when assuming it relative to the actual standard errors .",
    "a randomization test can be applied to any sharp null hypothesis , that is , a hypothesis such that the observed data implies specific values for all missing potential outcomes .",
    "when the covariates being balanced are correlated with the outcome variable , then rerandomization increases precision ( section [ precisionsec ] ) .",
    "a randomization test reflects this increase in precision .",
    "standard asymptotic - based frequentist analysis procedures that do not take the rerandomization into account will be statistically conservative . not only will distribution - based standard errors not incorporate the increase in precision , but the act of rerandomizing itself will increase the _ estimated _ standard error beyond that of pure randomization . if the total variance in the outcome is fixed , decreasing the actual sampling variance between treatment group means ( by ensuring better balance ) , increases the variance within groups , and it is this variance within groups that is traditionally used to estimate the standard error @xcite .",
    "thus , although rerandomization decreases the _ true _ standard error , it actually increases the standard error as estimated by traditional methods . for both of these reasons , the regular estimated standard errors will overestimate the true standard error , and using the corresponding distribution - based methods of analysis after rerandomization results in overly wide confidence intervals and less powerful tests of hypotheses .",
    "although not needed to motivate rerandomization , we assume one goal is to estimate the average treatment effect @xmath38\\\\[-8pt ] & = & \\frac{\\sum_{i=1}^n y_i(1)}{n } - \\frac{\\sum_{i=1}^n y_i(0)}{n}.\\nonumber\\end{aligned}\\ ] ] the fundamental problem in causal inference is that , because we only observe @xmath17 for each unit , we can not calculate ( [ pace ] ) directly , and we must estimate @xmath39 using only @xmath27 . in this section , we assume the stable unit treatment value assumption ( sutva ) @xcite : the potential outcomes are fixed and do not change with different possible assignment vectors @xmath6 .",
    "the average treatment effect @xmath39 is usually estimated by the difference in observed sample means , @xmath40 where @xmath41    [ unbiased ] suppose @xmath42 and @xmath43 ; then @xmath44 .    under the specified conditions , @xmath45 and @xmath46 are exchangeable .",
    "therefore , after rerandomization @xmath47 @xmath48 , so @xmath49 @xmath50 .",
    "hence @xmath51    theorem [ unbiased ] holds for all outcome variables .",
    "corollary [ covunbiased ] follows by the same logic .",
    "[ covunbiased ] if @xmath42 and @xmath52 , then @xmath53 for any observed or unobserved covariate @xmath54 .",
    "if sample sizes are not fixed in advance , but each unit has @xmath55 in the initial randomization , @xmath56 is only necessarily an unbiased estimate under the assumption of additivity . as a small example under nonadditivity ,",
    "consider @xmath57 , @xmath58 and @xmath59 .",
    "when @xmath60 if the difference in @xmath61 means between the two groups is @xmath62 and @xmath63 otherwise , the only two acceptable randomizations are @xmath64 and @xmath65 . for either acceptable randomization , @xmath66 , yet @xmath67 .",
    "this artificial example also illustrates that if the treatment groups are of unequal size , @xmath56 will not necessarily be an unbiased estimate after rerandomization .",
    "if the treatment group includes two units and the control group one unit , and @xmath68 is the same as before , then the only acceptable randomization is @xmath69 , and once again , @xmath66 , whereas @xmath67 .",
    "to simplify the statement of theoretical results , we assume the sample sizes for the treatment and control groups are fixed in advance , with @xmath70 the fixed proportion of treated units , @xmath71    let @xmath72 be the @xmath0-dimensional vector of the difference in covariate means between the treatment and control groups , @xmath73    we consider mahalanobis distance as a rerandomization criterion because it is an affinely invariant scalar measure of multivariate covariate balance .",
    "mahalanobis distance is defined by @xmath74^{-1 } ( \\overline{\\mathbf { x}}_t - \\overline{\\mathbf { x}}_c   )   \\\\ \\label{m}&= & np_w(1-p_w ) ( \\overline{\\mathbf { x}}_t - \\overline{\\mathbf { x}}_c   ) ' { \\operatorname{cov}}(\\mathbf{x})^{-1 }   ( \\overline{\\mathbf { x}}_t - \\overline{\\mathbf { x}}_c   ) , \\end{aligned}\\ ] ] where @xmath75 represents the sample covariance matrix of @xmath76 .",
    "the quantities  @xmath5 , @xmath70 and @xmath75 are known and constant across randomizations .",
    "if @xmath75 is singular , for example , if @xmath77 , then @xmath78 can be replaced with the pseudo - inverse of @xmath75 . for cluster randomized experiments ,",
    "see @xcite .",
    "due to the finite population central limit theorem , @xmath79 is asymptotically multivariate normally distributed over its randomization distribution [ @xcite ( @xcite ) ; @xcite ( @xcite ) ] .",
    "normality of @xmath79 is not necessary for rerandomization , but assuming normality allows for the theoretical results of this section .",
    "if @xmath72 is multivariate normal , then under pure randomization , @xmath80 [ @xcite , page 62 ] ; @xmath81 is the statistic used in hotelling s @xmath82 test , but note that here @xmath81 follows a @xmath83 distribution because @xmath84 is considered fixed .",
    "a randomization is deemed `` acceptable '' whenever @xmath81 falls below a certain threshold , @xmath85 .",
    "let @xmath32 be the proportion of randomizations that are acceptable , so that @xmath86 .",
    "either @xmath85 or @xmath32 can be specified a priori , and then the other is fixed either using @xmath87 if sample sizes are large enough or using an empirical distribution of @xmath81 achieved through simulation . the rerandomization criterion , @xmath88 ,",
    "is @xmath89      [ covariates ] assume rerandomization is conducted using @xmath88 with @xmath90 , and the covariate means are multivariate normal ; then @xmath91 where @xmath92 and @xmath93 denotes the incomplete gamma function : @xmath94 .",
    "the proof of theorem [ covariates ] is in the .    in the field of matching ,",
    "emphasis has been placed on `` percent reduction in bias '' @xcite . in the context of randomized experiments",
    "there is no bias , and rerandomization instead reduces the sampling variance of the difference in covariate means , yielding differences that are more closely concentrated around @xmath62 .",
    "define the _ percent reduction in variance _ , the percentage by which rerandomization reduces the randomization variance of the difference in means , for each covariate , @xmath95 , by @xmath96 by theorem [ covariates ] , the percent reduction in variance for each covariate , and for any linear combination of these covariates , is @xmath97 and is shown as a function of @xmath0 and @xmath32 in figure  [ privfig ] , where by ( [ va ] ) , @xmath98 . the lower the acceptance probability and the fewer covariates being balanced , the larger the percent reduction in variance .",
    "notice that theorem [ covariates ] holds for any covariate distribution , as long as the sample size is large enough for the central limit theorem to ensure normally distributed covariate means . an exact value is not needed , and an estimate is used only to guide the choice of @xmath32 ; it has no influence on the validity of resulting inferences .",
    "rerandomization improves precision , provided the outcome and covariates are correlated .",
    "thus researchers can increase the power of tests and decrease the width of confidence intervals simply at the expense of computational time .",
    "[ precisionthm ] if rerandomization is conducted using @xmath88 with @xmath90 , the covariate and outcome means are normally distributed , and the treatment effect is additive , then the percent reduction in variance of @xmath56  is @xmath99 where @xmath100 represents the squared multiple correlation between @xmath16 and @xmath3 within a treatment group and @xmath101 is as defined in ( [ va ] ) .",
    "regardless of the true relationship between the outcome and covariates , by additivity we can write @xmath102 where @xmath103 is the projection of @xmath104 onto the space spanned by @xmath105 , and @xmath106 is a residual that encompasses any deviations from the linear model . then the estimated treatment effect , @xmath56 ,",
    "can be expressed as @xmath107 because @xmath39 is constant and the first and last terms are uncorrelated , we can express the variance of @xmath56 as @xmath108\\\\[-8pt ] & = & \\beta ' { \\operatorname{cov } } ( \\overline{\\mathbf { x}}_t - \\overline{\\mathbf { x}}_c   ) \\beta + { \\operatorname{var}}(\\overline{e}_t - \\overline{e}_c   ) .\\nonumber\\end{aligned}\\ ] ] by theorem [ covariates ] , rerandomization modifies the first term by the factor @xmath101 . because under normality , orthogonality implies independence , the difference in residual means is independent of the difference in covariate means , and thus rerandomization has no affect on the second term .",
    "therefore , the variance of @xmath56 after rerandomization restricting @xmath109 is @xmath110\\\\[-12pt ] & = & v_a   \\beta ' { \\operatorname{cov } } ( \\overline{\\mathbf { x}}_t - \\overline{\\mathbf { x}}_c \\mid \\mathbf { x }   ) \\beta + { \\operatorname{var}}(\\overline{e}_t - \\overline{e}_c \\mid \\mathbf { x }   ) .\\nonumber\\end{aligned}\\ ] ] let @xmath111 be the variance of the residuals and @xmath112 be the variance of the outcome within each treatment group , where @xmath113 . thus @xmath114 and @xmath115    . ]",
    "therefore by ( [ vartauhat1 ] ) , ( [ evar ] ) and ( [ xvar ] ) , the variance of @xmath56 after rerandomization  is @xmath116 thus the percent reduction in variance is @xmath117 .",
    "the percent reduction in variance for the estimated treatment effect , shown as a function of @xmath0 , @xmath32 and @xmath100 in figure [ privy ] , is simply the percent reduction in variance for each covariate , scaled by @xmath100 . because under the specified conditions @xmath56 is unbiased by theorem [ unbiased ] , @xmath118 is not only the percent reduction in variance in the estimated treatment effect , but also the percent reduction in mean square error ( mse ) .",
    "if regression ( i.e. , analysis of covariance ) is used to adjust for imbalance in a completely randomized experiment , the percent reduction in variance  is @xmath119\\ ] ] @xcite , where @xmath81 is as in ( [ m ] ) . comparing ( [ ancova ] ) to ( [ priv ] )",
    ", we see that rerandomization can increase precision more than regression adjustment because there is no estimation of regression coefficients with the former .",
    "note that the highest percent reduction in variance achievable by either rerandomization or regression is @xmath120 , achieved with perfect covariate mean balance .",
    "in this section we explore the theoretical implications of choosing an affinely invariant rerandomization criterion , meaning that for any affine transformation of @xmath3 , @xmath121 , @xmath122 .",
    "measures based on inner products , such as mahalanobis distance or the estimated best linear discriminant , are affinely invariant , as are criteria based on propensity scores estimated by linear logistic regression @xcite .",
    "results in this section parallel those for affinely invariant matching methods @xcite .    in the previous sections , we regarded @xmath3 as fixed , and only the randomization vector , @xmath6 was random . in this section , to use ellipsoidal symmetry of  @xmath3 , we regard both @xmath3 and @xmath6 as random , so expectations are over repeated draws of @xmath3 and repeated randomizations .",
    "[ affinethm ] if @xmath8 is affinely invariant , and if @xmath3 is ellipsoidally symmetric , then @xmath123    first , by ellipsoidal symmetry there is an affine transformation of @xmath3 to a canonical form with mean ( center ) zero and covariance ( inner product ) @xmath124 , the @xmath0-dimensional identity matrix .",
    "the distribution of the matrix @xmath3 in the treated group of size @xmath125 and the control group of size @xmath126 are both independent and identically distributed samples from this zero centered spherical distribution . any affinely invariant rule for selecting subsets of treated and control units will be a function of affinely invariant statistics in the treatment and control groups that are also zero - centered spherically symmetric .",
    "applying @xmath8 creates concentric zero - centered sphere(s ) that partition the space of these statistics into regions where @xmath127 and @xmath63 , and therefore the distribution of such statistics remains zero - centered and spherically symmetric .",
    "transforming back to the original form completes the proof .",
    "[ linearfunction ] if @xmath8 is affinely invariant and if @xmath3 is ellipsoidally symmetric , then rerandomization leads to unbiased estimates of any linear function of @xmath3 .",
    "note that , unlike corollary [ covunbiased ] , corollary [ linearfunction ] applies no matter how the sample sizes are chosen .",
    "[ correlations ] if @xmath8 is affinely invariant and if @xmath3 is ellipsoidally symmetric , then @xmath128    one possible method of rerandomization , suggested by @xcite , @xcite , @xcite and @xcite , is to place bounds separately on each entry of @xmath129 and ensure that each covariate difference is within its specified caliper . however , this method is not affinely invariant and will generally destroy the correlational structure of @xmath130 , even when @xmath3 is ellipsoidally symmetric .    analogous to `` equal percent bias reducing '' ( epbr ) matching methods @xcite ,",
    "a rerandomization method is said to be `` equal percent variance reducing '' ( epvr ) if the percent reduction in variance is the same for each covariate .    if @xmath8 is affinely invariant and if @xmath3 is ellipsoidally symmetric , then rerandomization is epvr for @xmath3 and any linear function of @xmath3 .",
    "rerandomization methods that are not affinely invariant could increase the variance of some linear combinations of covariates @xcite .",
    "although affinely invariant methods have desirable properties in general , they are not always preferred .",
    "for example , if covariates are known to vary in importance , a rerandomization method that is not epvr may be more desirable , allowing greater percent reduction in variance for more important covariates .",
    "rerandomization criteria that take into account covariates of varying importance are discussed in @xcite [ ( @xcite ) , chapter 4 ] .",
    "rerandomization is certainly not the only way to balance covariates before the experiment .",
    "with only a few categorical covariates , simple blocking can successfully balance all covariates , and there is no need for rerandomization . with many covariates",
    "each taking on many values , however , blocking on all covariates can be impossible , and in this case we recommend blocking on the most important covariates , and rerandomizing to balance the components of the covariates orthogonal to the blocks . blocking and rerandomization can ,",
    "and we feel should , be used together .",
    "multivariate matching [ @xcite ( @xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ; xu and kalbfleisch ( @xcite ) ] is a special case of blocking that can better handle many covariates .",
    "restricted ( or constrained ) randomization [ @xcite ( @xcite ) ; grundy and healy ( @xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ] restricts the set of acceptable randomizations in a way that preserves the validity of asymptotic - based distributional methods of analysis .",
    "however , most work on restricted randomization is specific to agricultural plots , and apparently has not been extended to multiple covariates .",
    "blocking , matching and restricted randomization can all also be implemented through rerandomization by specifying the set of acceptable randomizations through @xmath8 .",
    "the finite selection model ( fsm ) [ @xcite ( @xcite ) ; @xcite ( @xcite ) ] provides balance for multiple covariates , but provides a fixed amount of balance in a fixed amount of computational time .",
    "rerandomization has the flexibility to choose the desired tradeoff between balance and computational time .",
    "more details comparing fsm with rerandomization are in [ @xcite , section 5.5 ] .",
    "covariate - adaptive randomization schemes [ @xcite ( @xcite ) ; white and freedman ( @xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ; @xcite ( @xcite ) ] are designed for clinical trials with sequential treatment allocation over extended periods of time .",
    "rerandomization as proposed here is not applicable to sequential allocation , and instead readers interested in such trials can refer to the above sources .",
    "if covariates are not balanced before the experiment , post - hoc methods such as regression adjustment are commonly used , which rely on assumptions that often can not be verified [ @xcite ( @xcite ) ; @xcite ( @xcite ) ] . moreover , unlike post - hoc methods , rerandomization is conducted entirely at the design stage , and so can not be influenced by outcome data .",
    "@xcite and @xcite give convincing reasons for why as much as possible should be done in the design phase of an experiment , before outcome data are available , rather than in the analysis stage when the researcher has the potential to bias the results , consciously or unconsciously .      for multiple treatment groups , any of the test statistics commonly used in multivariate analysis of variance ( manova )",
    "can be used to measure balance .",
    "the standard statistics are all equivalent to mahalanobis distance in the special case of two groups .",
    "extensions for multiple treatment groups are discussed in @xcite [ ( @xcite ) , section 5.2 ] .    for unbiased estimates using rerandomization with treatment groups of unequal sizes , multiple treatment groups of equal size",
    "can be created , and then merged as needed after the rerandomization procedure , but before the physical experiment .",
    "if extra units are discarded to form equal sized treatment groups and rerandomization is employed , precision can actually increase if covariates are highly correlated with the outcome [ @xcite , section 5.3 ] .    in a bayesian analysis ,",
    "as long as all covariates relevant to @xmath131 are conditioned on , the design is ignorable @xcite , and theoretically , the analysis can proceed as usual .",
    "randomization balances covariates across treatmentgroups , but only on average , and in any one experiment covariates may be unbalanced .",
    "rerandomization provides a simple and intuitive way to improve covariate balance in randomized experiments .    to perform rerandomization , a criterion determining whether a randomization is acceptable needs to be specified . for unbiasedness",
    ", this rule needs to be symmetric regarding the treatment groups .",
    "if the criterion is affinely invariant , then for ellipsoidally symmetric distributions , balance improvement will be the same for all covariates ( and all linear combinations of the covariates ) , and correlations between covariate differences in means will be maintained .",
    "one such criterion is to rerandomize whenever mahalanobis distance exceeds a certain threshold .",
    "when the covariates are correlated with the outcome , rerandomization increases precision .",
    "if the analysis reflects the rerandomization procedure , this leads to more precise estimates , more powerful tests and narrower confidence intervals .",
    "proof of theorem [ covariates ] because @xmath80 under pure randomization when the covariate means are normally distributed , rerandomization affects the mean of @xmath81 as follows : @xmath132    to prove ( [ covx ] ) , we convert the covariates to canonical form [ rubin and thomas ( @xcite ) ] .",
    "let @xmath133 , and define @xmath134 where @xmath135 is the cholesky square root of @xmath136 , so @xmath137 . by the assumption of normality , @xmath138 due to normality",
    ", uncorrelated implies independent and thus the elements of @xmath139 are independent and identically distributed ( i.i.d . )",
    ". therefore , the elements of @xmath139 are exchangeable .    by ( [ m1 ] ) , @xmath140 .",
    "therefore for each @xmath141 we have @xmath142 where ( [ exchangeable ] ) follows from the exchangeability of the elements of @xmath139 .    after enforcing @xmath143 ,",
    "the elements of @xmath139 are no longer independent ( they will be negatively correlated in magnitude ) , but with signs they remain uncorrelated due to symmetry : @xmath144 where ( [ unbiasedz ] ) follows from corollary [ covunbiased ] , and ( [ cov=0 ] ) follows because @xmath145 , thus @xmath146 for all @xmath147 .    thus after rerandomization the covariance matrix of @xmath139 is @xmath148 , hence @xmath149",
    "we appreciate the extraordinarily helpful comments of the editor , professor bhlmann , and two reviewers ."
  ],
  "abstract_text": [
    "<S> randomized experiments are the `` gold standard '' for estimating causal effects , yet often in practice , chance imbalances exist in covariate distributions between treatment groups </S>",
    "<S> . if covariate data are available before units are exposed to treatments , these chance imbalances can be mitigated by first checking covariate balance _ before _ the physical experiment takes place . </S>",
    "<S> provided a precise definition of imbalance has been specified in advance , unbalanced randomizations can be discarded , followed by a rerandomization , and this process can continue until a randomization yielding balance according to the definition is achieved . by improving covariate balance , rerandomization provides more precise and trustworthy estimates of treatment effects.=1    .    . </S>"
  ]
}