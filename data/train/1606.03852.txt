{
  "article_text": [
    "_ single photon emission computed tomography _ ( spect ) is a popular medical imaging technique which , like _ positron emission tomography _ ( pet ) , provides an insight into the physiological processes of a living organism .",
    "a radioactive substance , the so - called radiotracer , is injected into the patient s body and participates in its natural processes in a way depending on the particular properties of the tracer substance .",
    "for example , a radioactive type of glucose might be appropriate to visualize active tumor cells within healthy tissue .",
    "the emission of gamma rays is measured by surrounding gamma cameras , which contain a perforated honeycomb - like sheet , the so - called collimator , to ensure that only photons from a specified angle are counted . the measurements in turn",
    "can be used to gain a visualization of the tracer concentration @xcite .",
    "whereas static spect imaging yields a single static image neglecting any temporal aspects within a physiological process , dynamic spect reconstruction aims at providing a series of images visualizing time - dependent processes within an organism . from the mathematical point of view , the connection between given measurements @xmath0 and the unknown time - dependent tracer concentration @xmath1 in every point @xmath2 of a certain region @xmath3 for @xmath4 or @xmath5 at time @xmath6 is given by the so - called attenuated radon transform @xmath7 where @xmath8 and @xmath9 defines the position of a collimator bin while the camera position is specified by the angle @xmath10 .",
    "@xmath11 specifies the section of the straight line @xmath12 which lies in between @xmath2 and the collimator and @xmath13 defines the grade of attenuation of gamma rays on their way through different types of tissue . in this work",
    ", we make the assumption that @xmath14 is known a priori and directly included in the radon transform . in small animal spect ,",
    "the attenuation map is negligible , while for human spect scans , one usually uses a given attenuation map which is pre - estimated before , for example from an additional scan",
    ". another approach would be to perform a simultaneous reconstruction of both the tracer concentration and the attenuation map , but this is beyond the scope of this work , hence we can ignore it in the following @xcite .    the most intuitive approach to reconstruct @xmath15 out of given measurements",
    "@xmath0 is to perform static spect reconstruction for each time step independently .",
    "obviously , the main drawback of this idea is the fact that any temporal correlation between the images is neglected .",
    "furthermore , the approach might not provide suitable results : in order to guarantee a good temporal resolution , we assume that every camera position is accompanied by a new time step and therefore we only have access to measurements from one ( or two , depending on the actual number of rotating cameras ) angles per time step . as a result ,",
    "the solution is strongly underdetermined .",
    "we therefore need to search for a reconstruction method which includes the temporal coherence and allows the integration of given a priori information about the structure of the solution .",
    "there exist several discussions about dynamic image reconstruction in emission tomography .",
    "an overview about the state of the art in both pet and spect imaging is given in @xcite .",
    "the main reconstruction methods as well as several clinical applications of dynamic spect are listed in @xcite .",
    "the ideas are commonly based on kinetic modeling ( cp .",
    "section [ sec : simultaneoussegmentationandreconstruction ] ) and aim at minimizing the kullback - leibler divergence between the given data and the radon transform of the underlying tracer distribution .",
    "an interesting approach which is comparable to the one in this paper is presented in @xcite . here",
    ", the authors construct a sparse binary matrix defining the affiliation of a pixel to a certain region by pre - segmentation of a static reconstructed image , assuming that the tracer concentration within certain regions remains spatially constant .",
    "afterwards , the concentration in each region is modelled by a linear combination of b - spline basis functions . in @xcite , a simultaneous segmentation and reconstruction approach of dynamic pet data",
    "is performed by decomposing the spatial region into foreground and background regions , which also have a spatially constant concentration curve and differ in the magnitude of the latter .",
    "the main contribution of this work is the development and analysis of a novel approach for dynamic spect reconstruction based on image segmentation .",
    "the paper is organized as follows . in section [ sec : simultaneoussegmentationandreconstruction ] , we present the proposed simultaneous segmentation and reconstruction model . then in section [ sec : analysis ] , the existence of minimizers and error estimates of the proposed variational model are provided . in section [ sec : alg ] , we present the numerical algorithm to solve the proposed variational problems . finally , the numerical results are presented in section [ sec : num ] .",
    "in order to include the temporal correlation between the slices of the image sequence , there already exists a common approach which we use a basis for a slightly different model .",
    "the approach is based on compartmental modeling of the region of interest and is described in detail in @xcite .",
    "the region @xmath16 is assumed to be separated into so - called compartments : regions , in which the tracer concentration varies in time , but not in space .",
    "one compartment can either be one pixel ( or voxel ) or a whole region consisting of the same tissue .",
    "one of the main model assumption is furthermore that the tracer input is represented by the concentration in the blood , which is modelled as a function of time and is assumed to be known ( since it can be measured separately ) .",
    "hence , the blood vessel is not seen as a compartment as such , but as an additional region where the concentration is given a priori .",
    "the compartmental modelling starts from a very simple model , which only describes the tracer flux between blood and a single tissue type described by a differential equation for the unknown concentration in the tissue . in a subsequent approach ,",
    "the blood compartment is extended by distinguishing between an arterial and a venous part . a relation between these parts",
    "is modelled applying the fick principle .",
    "this leads to an extended differential equation for the concentration in the tissue @xmath17 @xmath18 where @xmath19 are the concentration in the arterial or , likewise , the venous part of the blood vessel and @xmath20 is the blood flow rate ( i.e. the volume of blood that passes through a vessel per unit time ) . by the assumption that the concentration reaches an equilibrium state very fast , the rate between tissue and venous concentration @xmath21 can be regarded as a constant , such that substituting @xmath22 by @xmath23 leads to @xmath24 this model can again be extended by separating the tissue region into several independent compartments and therefore adding a space component to the concentration in the tissue @xmath17 .",
    "this way , equation ( [ eq : odekineticmodeling ] ) turns into a partial differential equation @xmath25 and the solution with initial value @xmath26 can easily be computed as @xmath27    under the assumption that we have prior knowledge about @xmath28 , we can provide a set of possible values",
    "@xmath29 , @xmath30 for some fixed number @xmath31 for this factor and therefore , obtain a set of possible concentration curves .",
    "this set might not contain the true concentration curve in every single compartment , but still it makes sense to conclude that every concentration curve can be written as a linear combination of at most a few of these basis functions .",
    "this leads to the common approach @xmath32 where for every @xmath2 , only a few coefficients @xmath33 are nonzero , which leads to a sparsity term in our model presented within this section .",
    "the idea of kinetic modelling ( see @xcite ) is usually applied for dynamic pet reconstruction as in @xcite , but also for spect imaging @xcite , @xcite .",
    "another comparable approach uses splines as temporal basis functions @xcite or @xcite . in @xcite ,",
    "the authors provide an algorithm which alternatingly estimates the coefficients and updates the temporal basis , where only the number of basis function must be specified , whereas @xcite uses a pre - segmentation of the image region and b - spline basis functions for the temporal tracer concentration curves . in @xcite , an alternating updating of low rank matrix factorization model is proposed and further constraints are introduced to limit the solution space .",
    "another approach already mentioned in the introduction which is also based on low - rank matrix decomposition is presented in @xcite .",
    "the new approach which is introduced here is , referring to the underlying philosophy , a slightly different one , but will lead to a similar model .",
    "we assume that the contemplated region @xmath16 of the patient s body can be separated into a certain number of disjoint regions @xmath34 , whose boundaries remain static over time . the tracer distribution in every region now does not spatially change , so that every @xmath35 has its own space - independent concentration curve @xmath36 .    in the mathematical sense , this approach leads to a very similar model to the one emerging from the basis pursuit . under the assumption that every spatial point @xmath2 belongs to exactly one region ,",
    "@xmath15 can be written as a sum of the regional concentrations @xmath37 and spatial labelling functions @xmath33 , i.e. @xmath38 where @xmath39 in practice , this model makes sense and is easily transferable to the anatomical reality , e.g. thinking of roughly separating the patient s body into different tissue types , where each has its own unique chemical texture , which in turn causes a different behaviour of the added radiotracer .",
    "the task arising from this model is to reconstruct the indicator functions @xmath40 and to search for the subregional concentration curves @xmath41 .",
    "thereby , a reconstruction of the radiotracer concentration and a simultaneous segmentation of the region of interest are performed .",
    "the solution is formulated as a minimizer of the general variational framework @xmath42 where @xmath43 \\ \\forall x\\right\\}\\end{aligned}\\ ] ] and @xmath44 represents the kullback leibler divergence @xmath45 which is the data fidelity of choice in case of poisson noise - corrupted data .",
    "@xmath46\\rightarrow\\sigma\\times\\left[0,t\\right]$ ] is the radon operator as mentioned in ( [ eq : radonoperator ] ) , which transforms an image sequence @xmath15 into sinogram data @xmath0 . as regularization terms we chose for the indicator functions",
    "@xmath47 the total variation for each subregion to enforce sharp edges as well as a convex sparsity regularization via the @xmath48-norm .",
    "furthermore , we include a smoothness regularization for the tracer concentration in each subregion by penalizing the @xmath49-norm of the gradient .",
    "we want to investigate the variational problem of minimizing the functional    @xmath50    defined via @xmath51 where @xmath52 are regularization parameters which have to be chosen in a suitable way .",
    "furthermore , we assume @xmath53)$ ] .",
    "we start with the basic question of existence of minimizers and then proceed to stability estimates , which are carried out in terms of bregman distances as nowadays common for nonlinear variational regularization ( cf .",
    "@xcite ) .      in order to prove existence of a minimizer we employ standard compactness and lower semicontinuity arguments .",
    "indeed we shall look for a minimizer satisfying the additional constraints @xmath54    let us first clarify the topologies to work with . as we shall see below the functional @xmath55",
    "is indeed coercive in the norms of @xmath56 , and we can thus obtain the banach - alaoglu theorem to immediately obtain weak- * respectively weak star compactness . note for this sake that @xmath57 is the dual of a banach space ( cf .",
    "@xcite ) and @xmath58 is a hilbert space .",
    "+ let @xmath59 , @xmath60 and @xmath61 .",
    "then there exists @xmath62 such that @xmath63 is not empty and compact in the weak- * topology .",
    "first of all @xmath64 and @xmath65 are admissible elements that lead to a finite value of @xmath55 , hence choosing @xmath66 yields a nonempty @xmath67 .",
    "now let @xmath68 , then the nonnegativity of each term yields @xmath69 and the fact that @xmath70 has bounded components in @xmath71 yields a bound for the norm of @xmath47 in @xmath72 .    for @xmath73 , we find by the same arguments @xmath74 and the left - hand side is an equivalent norm on @xmath75 due to the poincar - friedrichs inequality .",
    "finally the banach - alaoglu theorem yields the assertion .",
    "secondly , we show the lower semi - continuity of the functional @xmath55 : +     + let @xmath76 , @xmath77 and @xmath78 .",
    "then the functional @xmath55 is lower semi - continuous on the constraint set with respect to the weak- * topology in @xmath79 and weak topology in @xmath58 .",
    "we can verify the lower semicontinuity of all terms separately due to the additive structure of @xmath55 . since the norm in @xmath57 is the convex conjugate of the characteristic function of the unit ball in its predual space , it is lower semicontinuous in the weak - star topology ( cf .",
    "also @xcite for an explicit proof ) .",
    "due to the compact embedding of @xmath57 into @xmath80 , the @xmath48-norms are even continuous .",
    "the squared equivalent norms in @xmath81 are lower semicontinuous due to weak semicontinuity of norms in reflexive banach spaces ( @xcite ) .",
    "it hence remains to verify the lower semicontinuity of the data fidelity term .",
    "for this sake we employ the weak sequential lower semicontinuity of the kullback - leibler divergence in @xmath82 ( cf .",
    "@xcite , lemma 3.4 ) .",
    "consequently it remains to show that for nonnegative sequences @xmath83 in @xmath57 and @xmath84 in @xmath81 we obtain weak @xmath48-convergence of @xmath85 . however , from the compact embeddings into @xmath80 and @xmath86 we obtain an even stronger property , namely strong @xmath48-convergence of @xmath87 due to @xmath88    finally we need to prove the closedness of the constraint set to finish the proof of existence .",
    "note that we have a compact embedding of @xmath57 into @xmath80 and of @xmath81 into @xmath89 .",
    "those are sufficient to pass to the limit in lower and upper bounds on @xmath40 respectively @xmath41 . moreover ,",
    "interpreting @xmath90 as an @xmath48 function , by the equation @xmath91 @xmath92 is continuous in @xmath48 and hence the constraint set is closed .",
    "summing up , we obtain the following existence result for @xmath55 :    let @xmath93 , @xmath60 , @xmath61",
    ". then there exists a minimizer of @xmath55 in @xmath94 with all @xmath41 nonnegative almost everywhere .      in the following",
    "we briefly want to outline a popular application of the bregman distance as stated in @xcite in order to derive error estimates for minimizers of regularized variational models in the context of inverse problems .",
    "although this result can state the convergence under certain conditions , it is based on a nonlinearity condition ( [ eq : nonlinearitycondition ] ) , which we can not verify for our particular case .",
    "since other convergence theorems which could be used here also suffer from slightly different conditions on the data ( see for example @xcite,@xcite ) , we nevertheless state the results here . for more details , see @xcite .",
    "let @xmath95 and @xmath96 be some banach spaces . to keep the notation simple",
    "we will use the notation @xmath97 throughout this part .",
    "let @xmath98 be the exact solution of the inverse problem @xmath99 with a continuous and frchet - differentiable nonlinear operator @xmath100 .",
    "in practice we face the problem that we only have access to noisy data @xmath101 .",
    "we are interested in an approximate solution of @xmath102 which is close to the exact solution @xmath103",
    ". therefore we apply a regularized variational technique as above , which in short - hand notation is written as @xmath104 with a data fidelity @xmath105 and convex regularization term @xmath106 with parameter @xmath107 .",
    "we assume in the abstract setting that @xmath108 is frchet - differentiable , which is indeed true in our setting . in order to estimate errors between a minimizer @xmath109 of ( [ eq : generalvarmodel ] ) and @xmath110 we shall use bregman distances and , as well - known in regularization theory ,",
    "need some kind of source condition .    as in @xcite",
    "we use the source condition @xmath111    here , @xmath112 denotes the subgradient of @xmath113 , @xmath114 the frchet - derivative of the operator @xmath115 and @xmath116 its convex conjugate . combining ideas from @xcite for",
    "non - quadratic fidelities and @xcite for nonlinear forward operators we obtain the following result : +     + [ th : errorestimatebregman ] let @xmath103 be the exact solution of the inverse problem @xmath117 and let the source condition ( [ eq : sourcecondition ] ) be satisfied .",
    "let @xmath106 be convex .",
    "furthermore , let the nonlinearity condition @xmath118 hold for @xmath119 from equation ( [ eq : sourcecondition ] ) .",
    "if there exists a minimizer @xmath109 of the variational model ( [ eq : generalvarmodel ] ) for @xmath120 which satisfies the kkt optimality conditions , then @xmath121    from the definition of @xmath109 we obtain that @xmath122 , hence it follows that @xmath123 and by adding @xmath124 to both sides and @xmath125 we obtain @xmath126 by inserting the source condition @xmath127 it follows that @xmath128",
    "in order to find a minimizer of the proposed variational model ( [ eq : continuousvarmodel ] ) , we apply an alternating updating structure based on a forward - backward splitting em - type method with a variable damping parameter @xcite .",
    "let @xmath129 be the total number of image pixels , @xmath130 the number of time steps and @xmath131 the number of image regions as before .",
    "then we can introduce a @xmath132-matrix @xmath133 and a @xmath134-matrix @xmath135 , which correspond to the previously defined @xmath136 , respectively @xmath137 .",
    "each row of @xmath133 corresponds to one image pixel , where the entry in column @xmath138 states the rate of affiliation of this image pixel to the @xmath138-th region .",
    "note that due to convexity reasons , we do not force @xmath139 , but allow @xmath140 $ ] with the restriction @xmath141 for every row @xmath142 .",
    "the @xmath143-th column of the matrix @xmath135 represents the tracer concentration over time within region @xmath143 .",
    "it follows that @xmath144 is a @xmath145-matrix , where @xmath146 is the tracer concentration in pixel @xmath142 at time @xmath138 . setting @xmath147 as the total number of detector bins ( accumulated over all measurement angles )",
    ", the data can be represented by a @xmath148-matrix , where every row contains the measurements in one detector bin over time .",
    "the radon transform operator can be written as a @xmath149-matrix , which can be applied to every column of @xmath15 to obtain the radon transform of each frame ( cp .",
    "@xcite ) . in this",
    "discrete setting , the convex set @xmath150 reads @xmath151 \\ \\forall \\ i , j \\}.\\ ] ]    we use an unconstrained discretized model version of ( [ eq : continuousvarmodel ] ) @xmath152 where @xmath153 ( or likewise @xmath154 ) is given by @xmath155    in order to compute the derivative of @xmath156 with respect to @xmath133 and @xmath135 easily , we define linear operators @xmath157 and @xmath158 such that @xmath159 and @xmath160 , where @xmath161 denotes the column - by - column vectorization of a matrix .",
    "the detailed construction of @xmath157 and @xmath158 as well as the discretization of the operator @xmath162 can be found in @xcite . in the following algorithm ,",
    "we use the vectorized versions of all matrices , although we still use the same notation as before instead of writing @xmath161 for the sake of simplicity .",
    "let @xmath143 be the outer iteration index , @xmath163 and @xmath164 be the operators such that @xmath165 and @xmath166 .",
    "let @xmath167 and @xmath168 , thus the subproblems for @xmath133 and @xmath169 are solved by the following iterations :    [ eq : u ]    _ ,   i+ = w_i ( a_k^t ( ) ) + ( 1-w_i ) u _",
    ",   i [ eq : emu ] + u _ ,   i+1 = _ u   _ 2 ^ 2 + w_i_l=1^k _ x u ( : ,  l)_1 + + w_i_l=1^k u(:,l)_1 + w_i_s(u ) [ eq : subproblemu ]    and for @xmath169 respectively    [ eq : c ]    ^t _ ,  i+ = w_i ( b_k+1^t ( ) ) + ( 1-w_i ) c^t _ ,  i + c^t _ ,   i+1 = _ c^ t   _ 2 ^ 2 + w_i_l=1^k _ tc(:,l)^2_2 + + w_i_+(c^t ) [ eq : subproblemc ]    with a damping parameter",
    "@xmath170 $ ] ( cp .",
    "@xcite , @xcite ) .",
    "@xmath171 denotes the @xmath172-th column of the orginial matrix @xmath133 , hence , in the vectorized version the entries @xmath173 .",
    "we note that the divisions in the two steps are all performed componentwisely . in the first step of both updating procedures ,",
    "a standard em step is performed , while in the second step we have to solve a slightly simpler minimization problem consisting of a weighted gaussian data term plus the original regularization terms , which are now also scaled by the damping parameter @xmath174 .",
    "the subproblems ( [ eq : subproblemu ] ) and ( [ eq : subproblemc ] ) are solved via a modified primal dual hybrid gradient algorithm ( @xcite@xcite ) , which in turn leads to a set of simple minimization problems that can be solved by direct updates .",
    "the method proposes an updating scheme for functionals of the general form @xmath175 with finite dimensional real vector spaces @xmath176 and @xmath177 , a continuous linear operator @xmath178 and @xmath179 , @xmath180 convex and lower semicontinuous . for subproblem ( [ eq : subproblemu ] )",
    "we define @xmath181 and , in the same way , for subproblem ( [ eq : subproblemc ] ) @xmath182    let us have a closer look at subproblem ( [ eq : subproblemu ] ) . for @xmath133 ,",
    "as proposed in @xcite , for a parameter @xmath183 and steps @xmath184 we obtain the three - step method    y_i+1 = _ f_1^ * ( y_i+k_1v_i ) + v_i+1 = _ g_1(v_i - k_1^*y_i+1 ) + u_i+1 = v_i+1+(v_i+1-v_i )    where the proximity operator is given by @xmath185    this method mainly consists of two minimization problems for @xmath186 and @xmath115 respectively , and therefore splits the original functional into two separated parts .",
    "each minimization problem can be interpreted as an implicit gradient descent method . to avoid the computation of the conjugate functional @xmath186",
    ", we can apply the famous moreau s identity @xcite :    @xmath187    then , the first step changes to @xmath188 where @xmath189 . from the definition of the operator",
    "@xmath190 we see that the dual iterate @xmath191 is actually three - dimensional and most parts of @xmath192 contain only one component .",
    "therefore , we can separate the single components to receive the minimization problems    y^1_i+1 = z^1_i-  _ y^1  w_k_iy_:,i^1_1+y^1-z_i^1_2 ^ 2 + y^2_i+1 = z^2_i-  _ y^2  w_ky^2_1+y^2-z_i^2_2 ^ 2 + y^3_i+1 = z^3_i-  _ y^3  w_k_s(y^3)+y^3-z_i^3_2 ^ 2 .",
    "the iterates @xmath193 and @xmath194 can be directly computed via the well - known soft shrinkage operator .",
    "@xmath195 is simply the projection of the minimizer of the @xmath49-term onto the convex set @xmath150 .",
    "the remaining minimization problem for @xmath196 only consists of two @xmath49-norm terms and can be solved directly as well . in the same way we can proceed for subproblem ( [ eq : subproblemc ] ) . in this case ,",
    "the resulting minimization problems are quite similar to the ones above and can be solved without more effort .",
    "to test our reconstruction method , we created different synthesized data sets consisting of @xmath197 pixels with varying complexity of the image structure and with a different number of subregions and a total of 90 time steps in each sequence . based on these subregions , we created three - dimensional matrices containing the true image in one time step within each slice . the underlying concentration in each subregion",
    "is related to a realistic shape of a the time - dependent behaviour of the tracer in different tissue types .    the first data set consists of a heart - shaped region and three circles on a static background ( see figure [ fig : phantoms ] ( a ) ) .",
    "the two smaller circles are assumed to belong to the same tissue type and therefore to the same subregion , which causes a total of four subregions , including the background . to simulate a more realistic application of dynamic spect imaging",
    ", we used a synthesized representation of a rat liver as a second data set ( see figure [ fig : phantoms ] ( b ) ) .",
    "the temporal concentration curves used to simulate the data sets are shown in figure [ fig : timecurves ] .",
    "as before , the total number of subregions was chosen to be equal to four in order to provide a both simple and realistic shape model .",
    "+    to simulate the synthesized spect data , we apply a radon transform assuming a double detector gamma camera , which counts photons from two opposing projection angles per time step . for the more simple data set , we let the camera rotate clockwise around two degree per time step , in case of the complex data set we used modified projection angles , i.e. the camera alternatingly projects from an angle of i and 45+i degrees , in order to simplify the reconstruction .",
    "each collimator consists of @xmath198 detector bins , so we obtain @xmath199 data points per time step and projection angle . the resulting sinogram data of the two underlying data sets are shown in figure [ fig : sinograms ] .",
    "both data sets were reconstructed via the previously described forward - backward em - type method in matlab@xmath200 . @xmath201 and @xmath202 in the subproblems are chosen as one over the maximum over the sums of all rows ( resp .",
    "columns ) of the corresponding operator @xmath131 to guarantee the condition @xmath203 for which convergence was shown in @xcite . according to @xcite",
    ", we also chose @xmath204 in both subproblems .",
    "the damping parameters @xmath174 are set to @xmath205 to remain close to the undamped version of the algorithm ( convergence of the method for some conditions on @xmath174 have been proven in @xcite ) .",
    "the parameters @xmath206 , @xmath207 and @xmath208 were optimized by comparing the final results with the existing ground truth in both cases . here",
    "we mention that the choice of parameters is not a trivial task , since the result strongly varies with a change in the parameters . in figure",
    "[ fig : errorparams ] , the scaling between the error in the @xmath49-norm between exact and reconstructed image sequence per pixel per time step and the choice of each parameter out of a certain range is displayed examplarily for the heart data set . here",
    ", we chose @xmath209 $ ] , @xmath210 $ ] and @xmath211 $ ] and kept two parameters fixed while plotting the error in the third one .",
    "the adaption of parameters in case of real data and , if possible , the elimination of some of them remains a future task .    in a first test , every image sequence was reconstructed out of the exact given sinograms .",
    "additionally we tested noise corrupted data by first scaling the sinogram by a parameter @xmath212 , corrupting them with poisson noise via the matlab imaging toolbox command ` imnoise ` and finally rescaling the image to the original range ( see figure [ fig : noisysinograms ] ) .",
    "the average count number per time step ( i.e. the average of the discrete @xmath213-norm of the data at each time step ) is approximately @xmath214 in case of the heart - shaped data set and ca .",
    "@xmath215 in case of the rat liver simulation .",
    "the results at a certain number of time steps can be seen in figure [ fig : resultset1 ] and [ fig : resultset2 ] . for comparison",
    ", we additionally performed a reconstruction with a simple alternating em method , keeping the assumption that the tracer can be modelled as a sum of indicator functions and subconcentration curves , but neglecting any regularization terms . in all tests ,",
    "the outer iteration number was set to 1000 with 10000 inner iterations per subproblem , to obtain a result within a reasonable time period . as stopping criterion",
    ", we chose the primal dual residual ( cp .",
    "@xcite ) for the inner and the maximum over the frobenius norms of @xmath133 and @xmath135 for the outer iterations .",
    "the results are displayed in [ fig : resultset1 ] and [ fig : resultset2 ] respectively .",
    "as one can see in both figures , the reconstruction method applied to each data set performs very well , especially in contrast to the simple alternating em method .",
    "this clearly shows the benefits of the proposed regularization methods .",
    "in case of noise - free given data , the shape of every object , where especially the heart is of higher interest , is clearly defined .",
    "as expected , we often observe errors in the edges of each region and where two regions are directly connected ( the heart and the upper left circle ) .",
    "this causes the algorithm to incorrectly assign these pixels to another region .",
    "furthermore , the reconstruction difficulties increase with an increase in noise .",
    "some more pixels are assigned to the wrong region , which leads to a small hole - like structure within the heart region and causes a slight blurring effect . in the second data set the method clearly outperforms several other approaches by providing very clearly defined regions and even reconstructing fine structures of the phantom . however , as mentioned before , a clear reconstruction of the rat liver required highly optimized parameter sets , which makes the whole problem quite susceptible to parameter changes .",
    "all in all , the results presented in this work offer a novel point of view to the topic and provide a flexible reconstruction approach which allows some room for improvement until it is suitable for being applied to real clinical data ( cp . section [ sec : conclusion ] ) .      in order to test the behaviour of the proposed method in a more realistic , random - based test case",
    ", we performed a monte carlo simulation for dynamic spect imaging .",
    "first , we created a simple @xmath216 image phantom consisting of an outer and two inner circles which represents the structure of the region of interest ( see figure [ fig : montecarlodata](a ) ) . within those regions we assumed concentration curves over a time period of 90 time steps as displayed in figure [ fig : montecarlodata](b ) .",
    "based on the tracer intensity in an image frame at each time step , we created a variable number of random decay events ( where the number is proportional to the average concentration in one pixel in the whole image frame per time step ) with a probability proportional to the concentration in every subregion .",
    "they are detected by a virtual double head gamma camera rotating around the patient by 46 degrees per time step , which consists of 374 detector bins .",
    "every simulated decay event is projected onto the scanner and counted by the corresponding detector bin .    in two different tests we fixed the number of events counted by the detector equal to @xmath217 ( resp .",
    "@xmath218 ) times the average concentration in one pixel .",
    "the resulting sinogram images of the accumulated counts in each bin are shown in figure [ fig : montecarlosinograms ] .",
    "based on the sinogram data we applied the proposed algorithm in order to reconstruct the original image sequence .",
    "the results for both test cases are shown in figure [ fig : montecarloresults ] .",
    "as one can see , the method is able to reconstruct the regions properly , even in case of a low count number . within a number of iterations ( average of 100 outer and 10000 inner iterations ) , the algorithm presents a reasonable reconstruction of the region of interest and the corresponding regional tracer concentration curves . here",
    ", the parameters were not optimized as in the case of the synthesized data sets in the previous section , but kept fixed as @xmath219 , @xmath220 and @xmath221 . with futher optimized parameter values one could possibly provide even better results .",
    "all in all , the proposed method provides promising results that could be able to be applied to several studies in biomedical imaging .",
    "in this paper we presented a new simultaneous reconstruction approach in dynamic spect imaging , derived and implemented a suitable variational model and presented promising results on synthesized data .",
    "the proposed method yields promising results , which we have demonstrated on both exact and noisy data .",
    "the results were quite plausible and the reconstructed image sequences significantly match the exact ones .",
    "the reconstructions prove that the choice of the regularization methods as well as the reconstruction approach is reasonable for a proof - of - concept study .",
    "however , some limitations and open questions arising from this work that could be addressed in future work are the following :    * although our method provides promising results for the different data sets , we think that a direct comparison to other existing approaches like the ones mentioned in the first sections may not be significant as the current model does not take into account the motion on the boundary , and those methods use a dictionary of basis functions for the tracer concentration curves or make additional assumptions on the structure of the region of interest .",
    "such a comparison in case of real data would thus be the next step in order to further promote this novel approach . *",
    "the proposed variational formulation contains at least , as in the constrained version , three regularization parameters .",
    "furthermore , some of the proposed algorithms require additional proximal parameters , which have to be chosen with respect to certain properties of the data and regularization functionals . a future task could be to discuss the parameter choice in detail and maybe to improve the model by eliminating some of them by setting some parameter proportional to another , for instance ( e.g. fixing a ratio between @xmath222- and @xmath48-regularization ) . * in order to make the approach applicable to real data , one also has to face the problem of extending the idea to three - dimensional real image sequences .",
    "therefore , this would automatically lead to a computational problem that we may need to address in the future .",
    "this work has been initiated during a stay of cr at shanghai funded by the heinrich hertz foundation and the china scholarship council , whose support is gratefully acknowledged .",
    "mb acknowledges further support by the german science foundation dfg through grant bu 2327/6 - 1 as well as sfb 656 molecular cardiovascular imaging , and by erc via grant eu fp 7 - erc consolidator grant 615216 lifeinverse . the work of xz is partially supported by nsfc91330102 and sino - german center grant ( gz1025 ) , and 973 program ( # 2015cb856004 ) .",
    "the authors thank qiu huang from shanghai jiao tong university for providing the test rat liver phantom , frank wbbeling from the westflische wilhelms - universitt mnster for creating the monte carlo simulation and the anonymous referees for their useful advice .",
    "10                                                        huang q li b chen  k zan  y , boutchko  r and gullberg  g t. fast direct estimation of the blood input function and myocardial time activity curve from dynamic spect projections via reduction in spatial and temporal dimensions . , 2013 ."
  ],
  "abstract_text": [
    "<S> this work deals with the reconstruction of dynamic images that incorporate characteristic dynamics in certain subregions , as arising for the kinetics of many tracers in emission tomography ( spect , pet ) . </S>",
    "<S> we make use of a basis function approach for the unknown tracer concentration by assuming that the region of interest can be divided into subregions with spatially constant concentration curves . applying a regularized variational framework reminiscent of the chan - vese model for image segmentation </S>",
    "<S> we simultaneously reconstruct both the labelling functions of the subregions as well as the subconcentrations within each region . </S>",
    "<S> our particular focus is on applications in spect with poisson noise model , resulting in a kullback - leibler data fidelity in the variational approach .    </S>",
    "<S> we present a detailed analysis of the proposed variational model and prove existence of minimizers as well as error estimates . </S>",
    "<S> the latter apply to a more general class of problems and generalize existing results in literature since we deal with a nonlinear forward operator and a nonquadratic data fidelity . a computational algorithm based on alternating minimization and splitting techniques </S>",
    "<S> is developed for the solution of the problem and tested on appropriately designed synthetic data sets . </S>",
    "<S> for those we compare the results to those of standard em reconstructions and investigate the effects of poisson noise in the data .    </S>",
    "<S> december 2015 </S>"
  ]
}