{
  "article_text": [
    "* remark . *",
    "to simplify notation we use einstein summation convention then @xmath0 where @xmath1 } _ { n \\times 1 } \\ , & r & = & \\underbrace { \\left [ \\begin{array}{c } \\rho_{\\it 1j } \\\\ \\vdots \\\\ \\rho_{\\it nj } \\\\",
    "\\end{array } \\right ] } _ { n\\times 1 } \\end{array}\\ ] ] are given vectors and @xmath2 where @xmath3}_{n \\times n } } \\end{array}\\ ] ] is given matrix .",
    "let us consider the random field @xmath4 with an unknown constant mean @xmath5 and variance @xmath6 its estimation statistics @xmath7 and the variance of the difference @xmath8 , where @xmath9 , as covariance @xmath10 and the linear estimation statistics ( weighted variable ) @xmath11 at @xmath12 then @xmath13 where @xmath14 is given vector of correlations and @xmath15 is given ( symmetric ) matrix of correlations  ( see  appendix  [ sec : a ] ) .",
    "+ the unbiasedness constraint ( the first constraint on the estimation statistics ) @xmath16 equal to @xmath17 gives the first equation @xmath18}_{1 \\times n } } & \\cdot & \\underbrace { \\left [ \\begin{array}{c } \\omega^1_j \\\\ \\vdots \\\\ \\omega^n_j \\\\ \\end{array } \\right ] } _ { n \\times 1 } & = & { \\underbrace { \\left [ \\begin{array}{ccc } \\omega^1_j & \\ldots & \\omega^n_j \\end{array } \\right]}_{1 \\times n } } & \\cdot & \\underbrace { \\left [ \\begin{array}{c } 1 \\\\ \\vdots \\\\ 1 \\\\ \\end{array } \\right ] } _ { n \\times 1 } & = & 1 \\ . \\end{array}\\ ] ] the minimization constraint ( the second constraint on the estimation statistics  the statistics is the best ) @xmath19 where  ( [ d ] ) @xmath20 produces @xmath21 equations in @xmath22 unknowns the kriging weights @xmath23 and a lagrange parameter @xmath24 @xmath25}_{n\\times(n+1 ) } } & \\cdot & \\underbrace { \\left [ \\begin{array}{c } \\omega_j^{\\it 1 } \\\\ \\vdots \\\\ \\omega_j^{\\it",
    "\\mu_j^{\\it 1 } \\\\ \\end{array } \\right ] } _ { ( n+1 ) \\times 1 } & = & \\underbrace { \\left [ \\begin{array}{c } \\rho_{\\it 1j }",
    "\\\\ \\rho_{\\it nj } \\\\",
    "\\end{array } \\right ] } _ { n \\times 1 } \\end{array}\\ ] ] this system of equations if multiplied by @xmath26 @xmath27 and substituted into @xmath28 ^ 2\\}-\\underbrace{e^2\\{v_j-\\hat{v}_j\\}}_0 \\\\    & = & e\\{[(v_j - m)-(\\hat{v}_j - m)]^2\\ } \\\\    & = & e\\{[v_j - m]^2\\}-2(e\\{v_j\\hat{v}_j\\}-m^2)+e\\{[\\hat{v}_j - m]^2\\ } \\\\    & = & \\sigma^2 -2 \\sigma^2|\\omega^i_j\\rho_{ij}| + \\sigma^2|\\omega^i_j\\rho_{il } \\omega^l_j| \\\\    & = & \\sigma^2 \\pm 2 \\sigma^2 \\omega^i_j \\rho_{ij } \\mp \\sigma^2 \\omega^i_j \\rho_{il } \\omega^l_j   \\end{array}\\ ] ] since variance of the ( estimation ) statistics is minimized @xmath29 ^ 2\\ } & = & cov\\{(\\omega^i_j v_i)(\\omega^i_j v_i)\\ } \\nonumber \\\\ & = & \\sum_i\\sum_l\\omega^i_j\\omega^l_j cov\\{v_i v_l\\ } \\nonumber \\\\ & = & \\sigma^2|\\omega^i_j \\rho_{il } \\omega^l_j| \\nonumber \\\\ & = & \\mp \\sigma^2 \\omega^i_j \\rho_{il } \\omega^l_j \\nonumber \\\\ & = & \\mp \\sigma^2 ( \\omega^i_j \\rho_{ij}-\\mu_j^{\\it 1 } ) \\label{o}\\end{aligned}\\ ] ] gives @xmath30 ^ 2\\ } = e\\{[(v_j - m)-(\\hat{v}_j - m)]^2\\ } = \\sigma^2 ( 1 \\pm ( \\omega^i_j \\rho_{ij}+\\mu^{\\it 1}_j ) ) \\label{oo}\\ ] ] the constraints  ( [ uc ] ) and  ( [ mc ] ) produce @xmath22 equations in @xmath22 unknowns @xmath31}_{(n+1 ) \\times ( n+1 ) } } & \\cdot & \\underbrace { \\left [ \\begin{array}{c } \\omega_j^{\\it 1 } \\\\ \\vdots \\\\ \\omega_j^{\\it",
    "\\mu^{\\it 1}_j \\\\ \\end{array } \\right ] } _ { ( n+1 ) \\times 1 } & = & \\underbrace { \\left [ \\begin{array}{c } \\rho_{\\it 1j }",
    "\\\\ \\vdots \\\\",
    "\\rho_{\\it nj } \\\\ 1 \\\\ \\end{array } \\right ] } _ { ( n+1 ) \\times 1 } \\ . \\end{array } \\label{ke}\\ ] ]",
    "* remark . *",
    "when we consider an independent set of the random variables @xmath32 with an unknown constant mean @xmath5 and variance @xmath6 the best linear unbiased ordinary ( estimation ) statistics @xmath33 of the field @xmath34 has the asymptotic property @xmath35 ^ 2\\ } = 0 \\label{sal}\\ ] ] whilst for spatial dependence between random variables ( the best linear unbiased generalized statistics ) we get  ( see  appendix  [ sec : b ] ) @xmath36 ^ 2\\ } = 0 \\ . \\label{tal}\\ ] ] due to different asymptotic limits between  ( [ sal ] ) and  ( [ tal ] ) the ordinary least - squares estimator of an unknown constant mean @xmath5 of the field , the best linear unbiased estimator of an unknown constant mean @xmath5 of the field , can not be so easy generalized ( like it was in past ) .",
    "let us constraint the best linear unbiased generalized ( estimation ) statistics @xmath33 of the random field @xmath34 , when for finite @xmath21 and @xmath37 the vector of correlations simplifies to @xmath38 } _",
    "{ n \\times 1 } = \\xi \\underbrace { \\left [ \\begin{array}{c } 1 \\\\ \\vdots \\\\ 1 \\\\ \\end{array } \\right ] } _ { n \\times 1 } \\qquad \\xi \\rightarrow 0 ^ -~(\\mbox{or } ~\\xi \\rightarrow 0^+ ) \\label{cv}\\ ] ] then from  ( [ uc ] ) @xmath39 it holds  ( [ oo ] ) @xmath40 ^ 2\\ } = \\lim_{j \\rightarrow \\infty } \\sigma^2 ( 1 \\pm ( \\omega^i_j \\rho_{ij}+\\mu^{\\it 1}_j ) ) = \\sigma^2 ( 1 \\pm ( \\xi + \\mu^{\\it 1}_j ) ) \\label{joo}\\ ] ] for the co - ordinate independent statistics of an unknown constant mean of the field @xmath41 with the constraint on  ( [ joo ] ) @xmath40 ^ 2\\ } = \\sigma^2 = e\\{[v_j - m]^2\\ } \\label{tc}\\ ] ] given by constrained from  ( [ joo ] ) @xmath42 and from  ( [ cv ] ) the system of equations  ( [ ke ] ) @xmath31}_{(n+1 ) \\times ( n+1 ) } } & \\cdot & \\underbrace { \\left [ \\begin{array}{c } \\omega_j^{\\it 1 } \\\\ \\vdots \\\\ \\omega_j^{\\it n } \\\\ - \\xi \\\\ \\end{array } \\right ] } _ { ( n+1 ) \\times 1 } & = & \\underbrace { \\left [ \\begin{array}{c } \\xi \\\\ \\vdots \\\\ \\xi \\\\ 1 \\\\ \\end{array } \\right ] } _ { ( n+1 ) \\times 1 } & \\end{array}\\ ] ] equivalent to @xmath43 and @xmath44 where @xmath45 } _ { n \\times 1 } \\ , & f & = & \\underbrace { \\left [ \\begin{array}{c } 1 \\\\ \\vdots \\\\ 1 \\\\ \\end{array } \\right ] } _ { n \\times 1 } &    , & \\lambda & = & \\lambda ' & = & { \\underbrace { \\left [ \\begin{array}{ccc } \\rho_{\\it 11 } & \\ldots & \\rho_{\\it 1n } \\\\ \\vdots & \\ddots & \\vdots \\\\ \\rho_{\\it n1 } & \\ldots & \\rho_{\\it nn } \\\\",
    "\\end{array } \\right]}_{n \\times",
    "n } } \\ , \\end{array}\\ ] ] with the solution @xmath46 and @xmath47 of the classic best linear unbiased generalized statistics for finite @xmath21 and @xmath37 of an unknown constant mean of the field @xmath48 where @xmath49 } _ { n \\times 1 } \\ , \\ ] ] with constrained minimized variance of the best linear unbiased generalized ( estimation ) statistics  ( [ o ] ) as its variance  ( from([wrho ] )  and  ( [ mu ] ) ) @xmath50 ^ 2\\ } = \\lim_{j \\rightarrow \\infty } \\mp\\sigma^2(\\omega^i_j \\rho_{ij}-\\mu_j^{\\it 1 } ) = \\mp\\sigma^2 ( \\xi - \\mu_j^{\\it 1 } ) = \\mp\\sigma^2 2\\xi\\ ] ] then  ( from([xii ] ) ) @xmath51 ^ 2\\ } = \\mp\\sigma^2 2\\xi = \\frac{\\mp\\sigma^2}{f'\\lambda^{-1}f } \\ , \\ ] ] with the classic generalized least - squares estimator for finite @xmath21 and @xmath37 of an unknown constant mean @xmath5 of the field @xmath52 based on observation @xmath53 seen as outcome of @xmath54 .",
    "to remove the asymptotic limit of the classic best linear unbiased generalized statistics for finite @xmath21 and @xmath37 of an unknown constant mean @xmath55 of the field @xmath41 with the constraint  ( [ tc ] ) @xmath56 ^ 2\\ } = \\sigma^2 = e\\{[v_j - m]^2\\ } \\ , \\ ] ] the best linear unbiased generalized ( estimation ) statistic of the field @xmath34 at finite @xmath57 @xmath58 given by the kriging algorithm  ( [ ke ] ) for @xmath59 @xmath60 } _ { ( n+1 ) \\times 1 } & = { \\underbrace { \\left [ \\begin{array}{cccc } \\rho_{\\it 11 } & \\ldots & \\rho_{\\it 1n } & 1 \\\\ \\vdots & \\ddots & \\vdots & \\vdots \\\\ \\rho_{\\it n1 } & \\ldots & \\rho_{\\it nn } & 1 \\\\ 1 & \\ldots & 1 & 0 \\\\ \\end{array } \\right]}_{(n+1 ) \\times ( n+1)}}^{-1 } & \\cdot & \\underbrace { \\left [ \\begin{array}{c } \\rho_{\\it 1j } \\\\ \\vdots",
    "\\\\ \\rho_{\\it nj } \\\\ 1 \\\\ \\end{array } \\right ] } _ { ( n+1 ) \\times 1 } \\end{array}\\ ] ] the negative correlation function with the parameter @xmath61",
    "@xmath62 ^ 2 } , &        \\qquad \\mbox{for}~~\\delta_{ij}=|i - j| > 0,\\\\        + 1 , & \\qquad \\mbox{for}~~\\delta_{ij}=|i - j|=0,\\\\        \\end{array }        \\right . \\label{cf}\\ ] ] was constrained  ( from  ( [ oo ] ) ) on computer ( 139 times ) for the numerical best linear unbiased generalized statistics for finite @xmath21 at finite @xmath63 of an unknown constant mean @xmath55 of the field @xmath41 with the third constraint of spatial statistics @xmath64",
    "^ 2\\ } = \\sigma^2 = e\\{[v_j - m]^2\\ } \\label{coss}\\ ] ] equivalent to @xmath65 with constrained minimized variance of the best linear unbiased generalized ( estimation ) statistics  ( [ o ] ) as its variance ( see  fig .  [ fig1 ] ) .",
    "variance of the numerical best linear unbiased generalized statistics for finite @xmath21 at finite @xmath57 of an unknown constant mean @xmath55 of the field @xmath41 in units of the variance @xmath6 of the field computed 139 times for the negative correlation function  ( [ cf ] ) with the parameter @xmath61.,width=453,height=226 ]    our aim was to derive for the negative correlation function  ( [ cf ] ) with the parameter @xmath61 the numerical generalized least - squares estimator @xmath66 of an unknown constant mean @xmath55 of the field @xmath41 in fact the proper best linear unbiased ( generalized ) estimator of an unknown constant mean @xmath55 of the field @xmath41     long - lived asymmetric index profile , xetra dax index from 23 x 1997 up to 10 iii 2000 ( 600 close quotes ) the numerical generalized least - squares estimator @xmath66 of an unknown constant mean @xmath55 of the field @xmath67 ( black dots ) based on @xmath68 is compared for the negative correlation function  ( [ cf ] ) with the parameter @xmath61 at finite @xmath57 to the classic generalized least - squares estimator @xmath69 of an unknown constant mean @xmath55 of the field @xmath41 ( grey line ) with the same correlation function and based on the same sample .",
    "the classic estimator is the first approximation of the numerical estimator at final @xmath70 for final @xmath71 .",
    "the dashed vertical line represents @xmath72.,width=453,height=226 ]    given at finite @xmath57 by numerical approximation to root of the equation  ( [ ce ] ) .",
    "this ( co - ordinate dependent ) generalized least - squares estimator @xmath66 was compared to the ( co - ordinate independent ) classic generalized least - squares estimator @xmath69 of an unknown constant mean of the field  ( [ cglse ] ) @xmath73 based on the same observation an initial amplification @xmath68 of long - lived asymmetric index profile recorded by @xmath74 close quotes of xetra dax index shown in  fig .",
    "[ fig2 ] then @xmath75 } _ { n \\times 1}\\ ] ] with the same correlation function  ( [ cf ] ) .",
    "since the classic best linear unbiased generalized statistics for finite @xmath21 and @xmath37 of an unknown constant mean @xmath55 of the field @xmath41 with the constraint @xmath40",
    "^ 2\\ } = \\sigma^2 = e\\{[v_j - m]^2\\ } \\ , \\ ] ] is an asymptotic disjunction for @xmath37 of the numerical best linear unbiased generalized statistics for finite @xmath21 at finite @xmath63 of an unknown constant mean @xmath55 of the field @xmath41 with the constraint @xmath64 ^",
    "2\\ } = \\sigma^2 = e\\{[v_j - m]^2\\ } \\ , \\ ] ] then the correct classic generalized least - squares estimator @xmath76 of an unknown constant mean @xmath5 of the field is an asymptotic disjunction for @xmath37 of the numerical generalized least - squares estimator @xmath66 of an unknowm constant mean @xmath5 of the field ( see  fig .  [ fig2 ] ) .",
    "it was shown that the ( estimation ) statistics of the field @xmath77 with an unknown constant mean @xmath5 and variance @xmath6 @xmath78 that assumes  the unbiasedness constraint  ( [ uc ] ) @xmath79 that assumes  the minimization constraint  ( [ mc ] ) @xmath80 given by the kriging system of equations  ( [ ke ] ) @xmath31}_{(n+1 ) \\times ( n+1 ) } } & \\cdot & \\underbrace { \\left [ \\begin{array}{c } \\omega_j^{\\it 1 } \\\\ \\vdots \\\\ \\omega_j^{\\it n } \\\\",
    "\\mu^{\\it 1}_j \\\\ \\end{array } \\right ] } _ { ( n+1 ) \\times 1 } & = & \\underbrace { \\left [ \\begin{array}{c } \\rho_{\\it 1j } \\\\ \\vdots",
    "\\\\ \\rho_{\\it nj } \\\\ 1 \\\\ \\end{array } \\right ] } _ { ( n+1 ) \\times 1 }   \\end{array}\\ ] ] is the best linear unbiased generalized ( estimation ) statistics of random field @xmath41 with minimized variance of the statistics",
    "@xmath81 ^ 2\\ } = \\mp\\sigma^2 \\left ( \\omega^i_j \\rho_{ij}- \\mu^{\\it 1}_j \\right ) \\label{o2}\\ ] ] and ( minimized ) @xmath64 ^ 2\\ } = \\sigma^2 \\left ( 1 \\pm \\left(\\omega^i_j \\rho_{ij } + \\mu^{\\it 1}_j \\right)\\right ) \\label{oo2}\\ ] ] with the asymptotic property  ( appendix  [ sec : b ] ) @xmath82 ^ 2\\}=0\\ ] ] and @xmath83 ^ 2\\ } = \\sigma^2\\ ] ] constrained once again from  ( [ oo2 ] ) on computer  the third constraint of spatial statistics @xmath64 ^ 2\\ } = \\sigma^2 = e\\{[v_j - m]^2\\}\\ ] ] is the numerical best linear unbiased generalized statistics for finite @xmath21 at finite @xmath63 of an unknown constant mean @xmath55 of the field @xmath41 with the numerical generalized least - squares estimator @xmath66 of an unknown constant mean of the field and its asymptotic disjunction for @xmath37 the classic generalized least - squares estimator @xmath76 of an unknown constant mean of the field .",
    "000 e. h. isaaks and r. m. srivastava , _ an introduction to applied geostatistics _",
    ", new york : oxford univ . press ( 1989 ) .",
    "if for correlation matrix @xmath15 that consists of unit diagonal elements  ( see  ( [ cf ] ) ) and non - positive off - diagonal elements holds @xmath84 like at @xmath85 for vector @xmath14 that consists of non - positive correlations holds @xmath86 then  ( [ d ] ) @xmath87 for non - negative correlation function @xmath88 for white noise @xmath89 where @xmath90 is the identity matrix .",
    "from the minimization constraint  ( [ mc ] ) @xmath91 we get @xmath92 where @xmath93 substituted into  ( [ uc ] ) @xmath94 gives @xmath95 for @xmath37  ( [ cv ] ) @xmath96 then the lagrange parameter simplifies to @xmath97 from the unbiasedness condition  ( [ uc ] ) it also holds @xmath98 then the minimized variance of the estimation statistics  ( [ o ] ) @xmath81 ^ 2\\ } = \\mp\\sigma^2(\\omega^i_j \\rho_{ij}-\\mu^{\\it 1}_j)\\ ] ] simplifies to @xmath99 ^ 2\\ } = \\mp\\sigma^2\\left(\\xi - \\xi + ( f_{\\it 1l } \\rho^{li } f_{\\it i1})^{-1 } \\right)\\ ] ] and  ( [ oo ] ) @xmath64 ^ 2\\ } = \\sigma^2 ( 1 \\pm ( \\omega^i_j \\rho_{ij}+\\mu^{\\it 1}_j))\\ ] ] simplifies to @xmath56 ^ 2\\ } = \\sigma^2 ( 1 \\pm ( \\xi + \\xi - ( f_{\\it 1l } \\rho^{li } f_{\\it i1})^{-1}))\\ ] ] since @xmath100 and @xmath101 we get the asymptotic property of the best linear unbiased generalized statistics of random field @xmath36 ^ 2\\ } = 0\\ ] ] and @xmath83 ^ 2\\ } = \\sigma^2 \\ .\\ ] ]"
  ],
  "abstract_text": [
    "<S> we constraint on computer the best linear unbiased generalized statistics of random field for the best linear unbiased generalized statistics of an unknown constant mean of random field and derive the numerical generalized least - squares estimator of an unknown constant mean of random field . </S>",
    "<S> we derive the third constraint of spatial statistics and show that the classic generalized least - squares estimator of an unknown constant mean of the field is only an asymptotic disjunction of the numerical one . </S>"
  ]
}