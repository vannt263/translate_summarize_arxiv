{
  "article_text": [
    "as the statistical understanding of applied scientists increases and new techniques deliver larger , more complicated data sets , applied statisticians are faced with increasingly complex models . naturally , as the complexity of these models increase , it becomes harder and harder to perform inference .",
    "appropriately , a great deal of effort has been expended on constructing numerical methods for performing approximate bayesian inference .",
    "undoubtably , the most popular family of approximate inference methods in bayesian statistics is the class of markov chain monte carlo ( mcmc ) methods .",
    "these methods , which exploded into popularity in the mid 1980s and have remained at the forefront of bayesian statistics ever since , with the basic framework being extended to cope with increasingly more complex problems .",
    "the key advantage of mcmc methods is that , in their most vanilla incarnation , they are extremely simple to program .",
    "this simplicity , together with their incredible flexibility , has lead to the proliferation of these methods .",
    "of course , there are problems : a single site auxiliary gibbs sampler for spatial logistic regression is known to fail spectacularly .",
    "this is just the tip of the iceberg  for even mildly complicated models , it can be extremely difficult to construct a mcmc scheme that converges in a reasonable amount of time .    for large models , and especially spatial models ,",
    "fast convergence is nt enough .",
    "even if you could sample exactly from the posterior , sampling  based methods converge like @xmath0 , where @xmath1 is the number of samples , which suggests that you need @xmath2 samples to get an error of around @xmath3",
    ". clearly , if computing a single sample is even reasonably expensive , this cost will be prohibitive . in the best case",
    ", this means that mcmc schemes for large problems typically take hours or even days to deliver estimates that are only correct to three or four decimal places .",
    "clearly this is less than ideal !    the only way around this efficiency problem is to consider alternatives to sampling - based methods .",
    "the first step in constructing an efficient approximate inference scheme is to greatly restrict the class of models that we will consider : it is nave to expect that an efficient algorithm exists that will solve all of the problems that mcmc treats . with this in mind , we restrict our attention to the class of _ latent gaussian models _ , which we define in three stages as @xmath4 where @xmath5 is the _ precision matrix _ ( that is , the inverse of the covariance matrix ) of the gaussian random vector @xmath6 . in the interest of having a computable model",
    ", we will restrict @xmath7 to be either sparse or small enough that computing multiple factorisations is not an issue .",
    "these models cover a large chunk of classical statistical models , including dynamic linear models , stochastic volatility models , generalised linear ( mixed ) models , generalised additive ( mixed ) models , spline smoothing models , disease mapping , log - gaussian cox processes , model - based geostatistics , spatio - temporal models and survival analysis .",
    "the integrated nested laplace approximation ( inla ) , builds upon the use of laplace approximations , which were originally for approximating posterior distributions by @xcite .",
    "the first step in the inla approximation is to perform a laplace approximation to the joint posterior @xmath8 where @xmath9 is the gaussian approximation to @xmath10 that matches the true distribution at the mode @xcite .",
    "the approximate posterior marginals for the non - gaussian parameters can then be constructed through numerical integration as long as the dimension of @xmath11 is not too large .",
    "the posterior marginals for the latent field @xmath12 are constructed by computing a laplace approximation to @xmath13 and then integrating out against the approximate joint posterior for @xmath14 .",
    "full details of the approximation scheme can be found in @xcite .",
    "the inla method was designed to be provide fast inference for a large class of practical bayesian problems . in order to fulfil this aim ,",
    "the ` r - inla `  package was created as an ` r ` interface to the inla program , which is itself written in ` c ` .",
    "the syntax for the ` r - inla `  package is based on the inbuilt ` glm ` function in ` r ` , which highlights the effectiveness of the inla method as a general solver for generalised linear ( mixed ) models .",
    "the ` r - inla `  package is available from ` http://r-inla.org ` .",
    "they key to the computational efficiency of the ` r - inla `  program is that it is based on ` gmrflib ` , a ` c ` library written by hvard rue for performing efficient computations on gaussian markov random fields . as such , ` r - inla `  is particularly effective when the latent gaussian field has the markov property .",
    "this covers the case of spline smoothing ( in any dimension ) , as well as conditional autoregressive models and some matrn random fields @xcite .",
    "such a latent field is specified through the ` formula ` mechanism in ` r ` .    to demonstrate the ` r - inla `  package , let us consider some survival data for myeloid leukaemia cases in the north - west of england . the model is a cox proportional hazard model , where the hazard depends linearly on the age and sex of the patient , smoothly on the white blood count ( ` wbc ` ) and an econometric covariate ( ` tpi ` ) .",
    "furthermore , it is assumed that there is a spatially correlated random effect , which takes into account which district the patient is in .",
    "the following code performs full bayesian inference on the appropriate generalised additive mixed model in around seven seconds .",
    "the posterior mean spatial effect is shown in figure [ postmean ]    >",
    "data(leuk ) > g = system.file(``demodata/leuk.graph '' , package = `` inla '' ) > formula = inla.surv(leuk@xmath15cens )   1 + age + sex + f(inla.group(wbc ) , + model = `` rw1 '' ) + f(inla.group(tpi ) , model = `` rw2 '' ) + f(district , + model = `` besag '' , graph.file = g ) > result = inla(formula , family = `` coxph '' , data = leuk )    , scaledwidth=70.0% ]",
    "since the original inla paper , there have been a number of new developments . in this section , we outline some of the most recent additions to the ` r - inla `  package .    [",
    "[ manipulating - the - likelihood ] ] manipulating the likelihood + + + + + + + + + + + + + + + + + + + + + + + + + + +    the original inla method was limited to observation models where each observation depended on one element of the latent gaussian field . while this is commonly the case ,",
    "this assumption is violated , for example , when the observed data consists of area averages of the latent field . in this case , @xmath16 we further assume that the dependence of the data on the latent field is `` local '' in the sense that most elements of the `` @xmath17 matrix '' are zero . with this assumption , everything stays markovian and fast inference is still possible .",
    "this is implemented in the ` r - inla `  program by modifying the ` control.compute ` parameter in the ` r - inla `  function call :    > res = inla(formula , family = `` ... '' , data = ... , control.compute = list(a = amat ) )    beyond relaxing this restriction to the class of models considered by the ` r - inla `  program , there are a number of other new methods for building new models .",
    "the ` f ( ) ` function , which ` r - inla `  uses to specify random effects , has two new options : ` replicate ` and ` copy ` .",
    "the first option can be used to simply deal with the case where the likelihood requires independent replicates of the model with the same hyperparameters .",
    "the ` copy ` option is useful in situations where the latent field uses the same random field multiple times , possibly with different scalings .",
    "finally , ` r - inla `  has been extended to include models where the data comes from different sources . in this case",
    ", different subsets of the data will require different likelihood functions .",
    "this can be programmed in ` r - inla `  by re - writing the data as a matrix where the number of columns are equal to the number of likelihoods . in the case",
    "where there are two likelihoods , each containing @xmath18 data points , this is achieved through the command    > y = matrix(na , n , 2 ) > y[1:n , 1 ] = y[1:n ] > y[1:n + n , 2 ] = y[(n + 1):(2 * n ) ]    the ` r - inla `  command is then modified appropriately by setting ` family = c(model1 , model2 ) ` .",
    "[ [ survival - models ] ] survival models + + + + + + + + + + + + + + +    a class of models that were not considered in the original inla paper were bayesian survival models .",
    "the trick is to see bayesian survival models as just another set of latent gaussian models . in some situations ,",
    "this is straightforward , while at other times it requires data augmentation tricks , which are implemented in the ` inla.surv ( ) ` function , demonstrated in section [ section2 ] .",
    "these methods are outlined in @xcite , which also discuss ways to deal with different types of censoring .",
    "[ [ stochastic - partial - differential - equations ] ] stochastic partial differential equations + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    a new method for constructing computationally efficient gaussian random fields by taking advantage of the spatial markov property was presented in a recent read paper by @xcite . the idea is to use the fact that these fields can be represented as the solution to stochastic partial differential equations ( spdes ) to construct computationally efficient approximations to them . beyond building computationally efficient approximations to standard spatial models , this method also allows for the construction of _ new _ classes of random fields with physically interpretable non - stationary .",
    "these models have been implemented in ` r - inla `  .",
    "the following chunk of code fits a bayesian spline through some noisy data points .",
    "it begins by constructing a mesh on the unit square with vertices at the observation locations ( ` points ` )    > bnd = inla.mesh.segment(matrix(c(0 , 0 , 1 , 0 , 1 , 1 , 0 , 1 ) , ncol = 2 , + byrow = true ) ) > mesh = inla.mesh.create(points , boundary = bnd , refine = list(max.edge = 0.1 ) )    the second step is to construct the spde model    > spde = inla.spde.create(mesh , model = `` imatern '' )    where ` imatern ` is the intrinsic matern model with @xmath19 , i.e. the spline smoothing model .",
    "finally the formula is constructed and the inference is performed in the standard way :    > formula = y   f(data_points , model = spde ) - 1 > r = inla(formula , family = `` gaussian '' , data = list(y = y , data_points = mesh@xmath20loc ) )",
    "there are an almost endless number of ways that the inla method ` r - inla `  program can be extended . in this section",
    "we describe some of the new features that we are currently working on .",
    "[ [ fixing - failures - global - gaussian - approximations ] ] fixing `` failures '' : global gaussian approximations + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the laplace approximation proceeds by fitting a gaussian approximation around the mode of @xmath21 , however there are situations in which this is not the most appropriate approximation . for instance , if the true distribution is bimodal , a better ` fit ' would be obtained by constructing a gaussian approximation that _ globally _ approximates the distribution .",
    "another situation where these more global approximation would be of use is the following case of `` failure '' . consider the problem of approximating the latent random field for the following logistic regression model .",
    "> n = 100 > eta = 1 + rnorm(n ) > p = exp(eta)/(1 + exp(eta ) ) > y = rbinom(n , size = 1 , prob = p ) > bad.result = inla(y   1 + f(num , model = `` iid '' ) , family = `` binomial '' , + ntrials = rep(1 , n ) , data = list(y = y , num = c(1:100 ) ) )    figure [ binomial_bad ] shows the posterior for the precision of the random effect .",
    "inla has clearly missed the correct precision , which was @xmath22 .    .",
    "[ binomial_bad],scaledwidth=60.0% ]    so what went wrong ?",
    "quite simply there is very little information in the data and hence the model is very prior sensitive .",
    "this sensitivity , combined with the vague prior that ` r - inla `  uses as a default produced the nonsense results in figure [ binomial_bad ] .",
    "[ [ kronecker - product - models ] ] kronecker product models + + + + + + + + + + + + + + + + + + + + + + + +    in a number of applications , the precision matrix in the gaussian random field can be written as a kronecker product of two standard covariance matrices . a simple example of this is the separable space - time model constructed by using spatially correlated innovations in an ar(1 ) model : @xmath23 where @xmath24 is a scalar and @xmath25 . in this case , the precision matrix is @xmath26 , where @xmath27 is the kronecker product .    due to the prevalence of kronecker product models , it is desirable to add a kronecker product mechanism to ` r - inla `  .",
    "the general kronecker product mechanism is currently in progress , but a number of special cases are already available in the code through the undocumented ` group ` feature .",
    "for example , a separable spatiotemporal spde model can be constructed using the command    > frm = y   f(loc , model = spde , group = time , control.group = list(model = `` ar1 '' ) )    in which every observation ` y ` is assigned a location ` loc ` and a time ` time ` . at each time",
    ", the spatial points are linked by an spde model , while across the time periods , they evolve according to an ar(1 ) process .    [ [ extending - the - spde - methodology ] ] extending the spde methodology + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the grouping mechanism described above can be used to produce separable space - time models , that is models in which the covariance function can be factored into a purely spatial and a purely temporal component . in some situations ,",
    "this type of separability is an unrealistic assumption and a great deal of research has gone into constructing classes of non - separable spatiotemporal covariance functions .",
    "an interesting property of spde models is that _ any _ model built with a sensible space - time partial differential operator will lead to a non - separable model .",
    "furthermore , these models will inherit the good physical properties of the deterministic pde models , such as causality and non - reversibility .",
    "this guarantees that the non - separability is _ useful _",
    ", rather than simply present .",
    "we are currently working to include the stochastic heat equation model @xmath28 where the noise process @xmath29 is white in time , but correlated and markovian in space .",
    "the challenge here is not simply placing the model into the ` r - inla `  framework .",
    "this model includes temporally varying anisotropy and temporally varying drift , and therefore , even parameterising this model is an open problem .",
    "[ [ gamma - frailty - models - relaxing - the - gaussian - assumptions ] ] gamma frailty models : relaxing the gaussian assumptions + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the assumption of gaussian random effects is at the very heart of the inla approximation . however , there are a number of situations in which this is not a realistic assumption .",
    "an example of this comes when incorporating frailty into cox proportional hazard models . in these models ,",
    "the hazard function for individual @xmath30 is modelled as @xmath31 where @xmath32 is a linear model containing covariates and @xmath33 is the frailty term , which models unobserved heterogeneity in the population .",
    "clearly , if we take @xmath33 to be log - normal , the resulting model fits firmly in the standard inla framework .",
    "unfortunately , log - normal frailties are an uncommon model , typically the frailty term is taken to be gamma distributed .",
    "the question is , therefore , can we incorporate gamma frailty models into the inla framework .",
    "the solution to this problem comes in the guise of `` importance sampling''type decomposition : @xmath34 with this type of formulation , it is possible to include gamma frailty models into the inla framework .",
    "this approach is not entirely satisfactory  although we can theoretically do this for any model suitably close to the log - normal ( such as the log - t distribution ) , it is not particularly flexible .",
    "the aim of this work is to incorporate ideas from bayesian nonparametrics to construct a class of suitable non - gaussian random effects models that can be incorporated into this framework",
    ". this will massively increase the class of models for which inla is available .",
    "this article was finished on 15th may , 2011 and all of the information about inla is correct at this time .",
    "this statement is necessary  inla is still a project in active development . by the time you read this , some of the ` present ' features will have moved into the ` past ' , and the ` future ' features will be edging ever closer to inclusion .",
    "in fact , those who are interested can follow the progress of the inla project at ` http://inla.googlecode.com ` , or by frequently updating the ` testing ' version of inla using the command      this ` testing ' version of inla updates frequently and includes experimental interfaces to the newest features .",
    "this build also has the pleasant feature of matching with the documentation on ` http://r-inla.org ` !    the ` r - inla ` project was created to provide an easy to use tool for performing bayesian inference on latent gaussian models . as such ,",
    "the set of problems that ` r - inla ` can solve is limited to those that someone has wanted to solve",
    ". there are any number of possible extensions not listed in the ` future ' section that we are not currently considering because no one has asked for them yet .",
    "the lesson here is _ if you want ` r - inla ` to have a particular feature , observation model or prior model , you need to ask us ! _ the development of the inla project is driven entirely by the research interests of the development team and the requests that we receive from the user community ."
  ],
  "abstract_text": [
    "<S> latent gaussian models are an extremely popular , flexible class of models . </S>",
    "<S> bayesian inference for these models is , however , tricky and time consuming . </S>",
    "<S> recently , rue , martino and chopin introduced the integrated nested laplace approximation ( inla ) method for deterministic fast approximate inference . in this paper </S>",
    "<S> , we outline the inla approximation and its related r package . </S>",
    "<S> we will discuss the newer components of the r - inla program as well as some possible extensions . </S>"
  ]
}