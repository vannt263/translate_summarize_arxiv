{
  "article_text": [
    "the ability to apply available previously learned knowledge to new tasks is a hallmark of general intelligence .",
    "_ transfer learning _ is the process of reusing knowledge from previously learned _ source _ tasks to bootstrap learning of _ target _ tasks . in long - range sequential control domains , such as robotics and video game - playing",
    ", transfer is particularly important , because previous experience can help agents explore new environments efficiently @xcite .",
    "knowledge acquired during previous tasks also contains information about an agent s domain - independent decision making and learning dynamics , and thus can be useful even if the domains seem unrelated .",
    "existing approaches to transfer learning in such domains have demonstrated successful transfer of varying kinds of knowledge , but they make two fundamental assumptions that restrict their generality : ( 1 ) some sort of a priori human - defined understanding of how tasks are related , and ( 2 ) separability of knowledge extraction and target learning .",
    "the first assumption limits how well the approach can be applied by restricting its use only to cases where the agent has been provided with this additional relational knowledge , or , if it can be learned @xcite , cases where task mappings are useful .",
    "the second assumption implies that it is known what knowledge will be useful and how it should be incorporated _ before _ learning on the target task begins , preventing the agent from adapting the way it uses source knowledge as it gains information about the target domain",
    ".    general reuse of static modules ( grusm ) is proposed in this paper as a general neural network approach to transfer learning that avoids both of these assumptions .",
    "grusm augments the learning process to allow learning networks to route through existing neural modules ( source networks ) selectively as they simultaneously develop new structure for the target task . unlike previous work , which has dealt with mapping task variables between source and target ,",
    "grusm is domain - independent , in that no knowledge about the structure of the source domain or even knowledge about where the network came from is required for it to be reused . instead of using mappings between task - spaces to facilitate transfer , it searches directly for mappings in the solution space , that is , connections between existing source networks and the target network .",
    "this approach is motivated by studies that have shown in both naturally occurring complex networks @xcite and in artificial neural networks @xcite that certain network structures repeat and can be useful across domains , without any context for how exactly this structure should be used .",
    "this work is further motivated by the idea that neural resources in the human brain are reused for countless purposes in varying complex ways @xcite .    in this paper ,",
    "an implementation of grusm based on the enforced subpopulations ( esp ) neuroevolution framework @xcite is presented .",
    "the approach is validated on the stochastic atari 2600 general game playing platform , finding that grusm - esp improves learning for more complex target games , and that these improvements may be predicted based on domain complexity features .",
    "this result demonstrates that even without traditional transfer learning assumptions , successful knowledge transfer via general reuse of existing neural modules is possible and useful for long - range sequential control tasks . in principle , this approach scales naturally to transfer from an arbitrary number of source tasks , which suggests that in the future it may be possible to build grusm agents that accumulate and reuse knowledge throughout their lifetimes across a variety of diverse domains .",
    "transfer learning encompasses machine learning techniques that involve reusing existing _ source _ knowledge in a different _ target _ task or domain .",
    "domain _ is an environment in which learning takes place , characterized by the input and output space ; a _ task _ is a particular function from input to output to be learned @xcite . in sequential - decision domains ,",
    "a task is characterized by the values of sensory - action sequences corresponding to the pursuit of a given goal .",
    "a taxonomy of types of knowledge that may be transferred was also enumerated by pan and yang .",
    "because the grusm approach reuses the structure of existing neural networks , it falls under _ feature representation transfer_.      transfer learning for sequential decision - making domains has been studied extensively within the _ reinforcement learning _ ( rl ) paradigm @xcite .",
    "reinforcement learning domains are often formulated as markov decision processes ( mdps ) in which the state space comprises all possible observations , and the probability of an observation depends only on the previous observation and action taken by a learning agent .",
    "however , many real world rl domains are non - markovian , including many atari 2600 games , for example , the velocity of a moving object can not be determined by looking at a single frame .",
    "the atari 2600 platform also supports a wide variety of games .",
    "existing rl approaches to transfer differ on the types of differences allowed between source and target task .",
    "some approaches that are general with respect to the kind of knowledge that can be transferred are restricted in that they require a consistent _ agent - space _ @xcite , or an a priori specification of inter - task _ mappings _ defining relationships between source and target state and action variables @xcite .",
    "existing approaches to transfer learning that encode policies as neural networks require such a specification @xcite . on the other hand , existing modular neuroevolution approaches that are more general with respect to connectivity @xcite have not been applied to cross - domain transfer .",
    "some of the most general existing approaches to transfer for rl automatically learn task mappings , so they need not be provided beforehand .",
    "these approaches are general enough to apply to any reinforcement learning domains , but initial approaches @xcite were intractable for high dimensional state and action spaces due to combinatorial blowup in the number of possible mappings .",
    "however , recent approaches in policy gradient rl @xcite can both tractably learn mappings and be applied across diverse domains .",
    "these approaches have been successful in continuous control domains , but it is unclear how they would scale to domains with many discretely - valued features such as atari .",
    "also , the above approaches assume mdp environments , whereas grusm can use recurrent neural networks to extend to pomdps .",
    "there are existing algorithms similar to grusm in that they make it possible to reuse existing neural structure .",
    "they can apply to a wide range of domains and tasks in that they automatically select source knowledge and avoid inter - task mappings .",
    "for example , @xcite ( @xcite ) developed a technique to build increasingly complex networks by inserting source networks chosen by how much they reduce error .",
    "this technique is only applicable to supervised learning , because the source selection depends heavily on an immediate error calculation . also",
    ", connectivity between source and target networks is limited to the input and output layer of the source . as another example",
    ", @xcite ( @xcite ) introduced an approach that creates sparse networks out of primitives , or commonly used sub - networks , mined from a library of source networks .",
    "this subgraph mining approach depends on a computationally expensive graph mining algorithm , and tends to favor exploitation over innovation and small primitives rather than larger networks as sources .",
    "the grusm approach is more general in that it can be applied to unsupervised and reinforcement learning tasks , makes few a priori assumptions about what kind of sources and mappings should work best , and is able to develop memory via recurrent connections . although an evolutionary approach is developed in this paper , grusm should be extensible to any neural network - based learning algorithm .",
    "this section introduces the general idea behind grusm , provides an overview of the esp neuroevolution framework , and describe the particular implementation : grusm - esp .",
    "the underlying idea is that an agent learning a neural network for a target task can reuse knowledge selectively from existing neural modules ( source networks ) while simultaneously developing new structure unique to a target task",
    ". this approach attempts to balance reuse and innovation in an integrated architecture .",
    "both source networks and new hidden nodes are termed _",
    "recruits_. recruits are added to the target network during the learning process .",
    "recruits are incorporated adaptively into the target network as it learns connection parameters from the target to the recruit and from the recruit to the target .",
    "all internal structure of source networks is _ frozen _ to allow learning of connection parameters to remain consistent across recruits .",
    "this mechanism forces the target network to transfer learned knowledge , rather than simply overwrite it .",
    "connections to and from source networks can , in the most general case , connect to any nodes in the source and target , minimizing assumptions about what knowledge will be useful .    a grusm network is a 3-tuple @xmath0 where @xmath1 is a traditional neural network ( feedforward or recurrent ) containing the new nodes and connections unique to the target task , with input and output nodes corresponding to inputs and outputs defined by the target domain ; @xmath2 is a ( possibly empty ) set of pointers to recruited source networks @xmath3 ; and @xmath4 is a set of weighted _ transfer connections _ between nodes in @xmath1 and nodes in source networks , that is , for any connection @xmath5 , @xmath6 for some @xmath7 .",
    "this construction strictly extends traditional neural networks so that each @xmath8 can be a traditional neural network or a grusm network of its own .",
    "when @xmath9 is evaluated , only the network induced by directed paths from inputs of @xmath1 to outputs of @xmath1 , including those which pass through some @xmath8 via connections in @xmath4 is evaluated . during each evaluation of @xmath9 ,",
    "all recruited source network inputs are fixed at 0 , since the agent is concerned only with performing the current target task .",
    "the parameters to be learned are the usual parameters of @xmath1 , along with the contents of @xmath2 and @xmath4 .",
    "the internal parameters of each @xmath8 are _ frozen _ in that they can not be rewritten through @xmath9 .",
    "the motivation for this architecture is that if the solution to a source task contains _ any _ information relevant to solving a target task , then the neural network constructed for the source task will contain _ some _ structure ( subnetwork or module ) that will be useful for a target network .",
    "this has been previously observed in naturally occurring complex networks @xcite , as well as cross - domain artificial neural networks @xcite . unlike the subgraph - mining approach to neural structure transfer @xcite",
    ", this general formalism makes no assumptions as to what subnetworks actually will be useful .",
    "one interpretation is that a lifelong learning agent maintains a system of interconnected neural modules that it can potentially reuse at any time for a new task . even if existing modules are unlabeled , they may still be useful , due to the fact that they contain knowledge of how the agent can successfully learn",
    "furthermore , advances in reservoir computing @xcite have demonstrated the power of using large amounts of frozen neural structure to facilitate learning of complex and chaotic tasks .",
    "the above formalism is general enough to allow for an arbitrary number of source networks and arbitrary connectivity between source and target . in this paper , to validate the approach and simplify analysis , at most one source network is used at a time and only connections from target input to source hidden layer and source output layer to target output are permitted . by not allowing target input to connect to source input ,",
    "this restriction avoids high - dimensional transformations between domain - specific sensor substrates , and more intuitively captures the domain - agnostic goals of the approach , differentiating the approach from previous methods that have used direct mappings between sensor spaces .",
    "this restriction is sufficient to show that the implementation can reuse hidden source features successfully , and it is possible to analyze the cases in which transfer is most useful .",
    "future refinements are discussed in the discussion and future work section .",
    "the current implementation , described below , is a neuroevolution approach based on esp .",
    "enforced sub - populations ( esp ; @xcite @xcite ; @xcite ) is a neuroevolution technique in which different components of a neural network are evolved in separate _",
    "subpopulations _ rather than evolving the whole network in a single population .",
    "esp has been shown to perform well in a variety of reinforcement learning domains , and has shown promise in extending to pomdp environments , in which use of recurrent connections for memory is critical @xcite . in traditional esp , there is a single hidden layer , each neuron of which is evolved in its own subpopulation .",
    "recombination occurs only between members of the same subpopulation , and mutants in a subpopulation derive only from members of that subpopulation .",
    "the genome of each individual in a subpopulation is a vector of weights corresponding to the weights of connections to and from that neuron , including node bias . in each generation , networks to be evaluated are randomly constructed by inserting one neuron from each subpopulation .",
    "each individual that participated in the network receives the fitness achieved by that network .",
    "when fitness converges , i.e. , does not improve over several consecutive generations , esp makes use of _ burst phases_. in initial burst phases each subpopulation is repopulated by mutations of the single best neuron ever occuring in that subpopulation , so that it reverts to searching a @xmath10-neighborhood around the best solution found so far .",
    "if a second consecutive burst phase is reached , i.e. , no improvements were made since the previous burst phase , a new neuron with a new subpopulation may be added @xcite .",
    "the idea of enforced sub - populations is extended to transfer learning via grusm networks .",
    "for each reused source network @xmath8 , the transfer connections in @xmath4 between @xmath8 and @xmath1 evolve in a distinct subpopulation .",
    "at the same time new hidden nodes can be added to @xmath1 ; they evolve within their own subpopulations in the manner of standard esp . in this way , the integrated evolutionary process simultaneously searches the space for how to reuse each potential source network and how to innovate with each new node . the grusm - esp architecture ( figure  [ figuregesp ] )",
    "is composed of the following elements : ( 1 ) a pool of potential source networks . in the experiments in this paper ,",
    "each target network reuses at most one source at a time ; ( 2 ) _ transfer genomes _ encoding the weights of cross - network connections between source and target .",
    "each potential source network in the pool has its own subpopulation for evolving transfer genomes between it and the target network .",
    "each connection in @xmath4 is contained in some transfer genome . in our experiments , the transfer connections included are those such that the target s inputs are fully connected to the source s hidden layer , and the source s outputs are fully connected into the target s outputs ; ( 3 ) a burst mechanism that determines when innovation is necessary based on a recent history of performance improvement . new hidden recruits ( source networks when available , and single nodes otherwise ) added during the burst phase evolve within their own subpopulations as in standard esp .     the grusm - esp architecture , showing the balance between reused and new structure . in this example , the target network has three recruits : one source network , and two single nodes .",
    "each bold edge between target network nodes and source network recruit indicate connections to multiple source nodes .",
    "the genome in each subpopulation encodes weight information for the connections from and to the corresponding recruit.,scaledwidth=46.5% ]    all hidden and output neurons use a hyperbolic tangent activation function .",
    "networks include a single hidden layer , and include recurrent self loops on hidden nodes ; they are otherwise feedforward .",
    "the details of the genetic algorithm in our implementation used to evolve each subpopulation mirror those described by @xcite ( @xcite ) .",
    "this algorithm has been shown to work well within the esp framework , though any suitable evolutionary algorithm could potentially be substituted in its place .",
    "( preliminary experiments using this approach were discussed in @xcite ( @xcite ) . )",
    "grusm - esp was evaluated in a stochastic version of the atari 2600 general video game - playing platform using the arcade learning environment simulator ( ale ; @xcite @xcite ) .",
    "atari 2600 is currently a very popular platform , because it challenges modern approaches , contains non - markovian games , and entertained a generation of human video game players , who would regularly reuse knowledge gained from previous games when playing new games . to make the simulator more closely resemble the human game - playing experience , the @xmath11-repeat action approach as suggested by @xcite ( @xcite ) is used in this paper to make the environment stochastic ;",
    "in this manner , like human players , the algorithm can not as easily find loopholes in the deterministic nature of the simulator .",
    "the recommended @xmath12[multiblock footnote omitted ] is used . note that the vast majority of previously published atari 2600 results are in the deterministic setting ; we are unaware of any existing scores that have been published in the @xmath11-repeat setting .",
    "agents were trained to play eight games : pong , breakout , asterix , bowling , freeway , boxing , space invaders , and seaquest .",
    "neuroevolution techniques are competitive in the atari 2600 platform @xcite , and esp in particular has yielded state - of - the - art performance for several games @xcite .",
    "three grusm - esp conditions are evaluated : `` , `` , and `` . in the ` scratch ` condition , networks are trained from scratch on a game using standard esp ( grusm - esp with @xmath13 ) . in",
    "the ` transfer ` condition , each scratch network is reused as a source network in training new grusm networks for different target games . in",
    "the ` random ` control condition , random networks are initialized and reused as source networks .",
    "such networks contain on average the same number of parameters as fully - trained scratch networks .",
    "each run lasted 200 generations with 100 evaluations per generation . since the environment is stochastic , each evaluation consists of five independent trials of individual @xmath14 playing game @xmath15 , and the resulting score @xmath16 is the average of the scores across these trials .",
    "the score of an evolutionary run at a given generation is the highest @xmath16 achieved by an individual by that generation .",
    "a total of 333 runs were run split across all possible setups .",
    "evolutionary parameters were selected based on their success with standard esp .    to interface with ale ,",
    "the output layer of each network consists of a 3x3 substrate representing the nine directional movements of the atari joystick in addition to a single node representing the fire button .",
    "the input layer consisted of a series of object representations manually generated as previously described by @xcite ( @xcite ) .",
    "the location of each object on the screen was represented in an @xmath17 input substrate corresponding to the object s class .",
    "the numbers of object classes varied between one and four .",
    "although object representations were used in these experiments , pixel - level vision could also be learned from scratch below the neuroevolution process , e.g. , via convolutional networks as was done by @xcite ( @xcite ) . + * domain characterization * understanding _ when _ transfer will be useful is important for any transfer learning approach . in many cases , attempting transfer can impede learning , leading to _ negative transfer _",
    ", when an approach is not able to successfully adapt knowledge from the source to the target domain .",
    "negative transfer is a serious concern for many practitioners @xcite . to help understand when grusm - esp should be applied , it is useful to consider the diverse array of games within a unified descriptive framework .",
    "biological neural reuse is generally thought to be most useful in transferring knowledge from simple behaviors to more complex , and the vast majority of previous computational approaches do exactly that .",
    "thus , the characterization of games in this paper is grounded by a sense of relative complexity .    each game can be characterized by generic binary features that determine what successful game play requires : ( 1 ) horizontal movement ( joystick left / right ) , ( 2 ) vertical movement ( joystick up / down ) , ( 3 ) shooting ( fire button ) ; ( 4 ) delayed rewards ; and ( 5 ) long - term planning .",
    "intuitively , more complex games will include more of these features .",
    "a partial ordering of games by complexity defined by these features is shown in figure  [ figurefeaturelattice ] .",
    "the assignment of features ( 1 ) , ( 2 ) and ( 3 ) is completely defined based on game interface @xcite . freeway and seaquest are said to have _ delayed rewards _ because a high score can only be achieved by long sequences of rewardless behavior . only space invaders and seaquest were deemed to require long - term planning @xcite , since the long - range dynamics of these games penalize reflexive strategies , and as such , agents in these games can perform well with a low frequency decision - making @xcite .",
    "in addition to being intuitive , these features are validated below based on how well they characterize games by complexity and how well they predict successful transfer .",
    "+     ( left ) feature representation for each game , and ( right ) games partially - ordered by feature inclusion : every path from _ none _ to @xmath15 contains along its edges each complexity feature of @xmath15 exactly once , showing how games are related across the feature space .",
    "the existence of such a hierarchy motivates the use of atari for transfer . ]    * analysis methods * there are many possible metrics for evaluating success of transfer , depending on what kind of transfer is desired or expected .",
    "learning curves are irregular across different games , as illustrated in figure  [ figurelearningcurves ] , which makes it difficult to choose a single metric that makes sense across all source - target pairs .",
    "thus , the analysis is focused on a broad notion of _ transfer effectiveness _ ( te ) , which aggregates metrics such as jumpstart and max overall score , with a weighted approximation of area under the curve @xcite .",
    "_ success _ of a setup is defined as the sum of the average score of that setup at a series of non - uniformly - spaced generations : @xmath18 $ ] .",
    "this series favors early performance over later performance , as in general , in the long run , training from transfer and scratch should converge , as scratch eventually relearns everything that was effectively transferred .",
    "then , the te of a setup is its success minus the success of the control on the target game , the difference normalized by the size of the range of max scores achieved across all runs for that game , in order to draw comparison across games .",
    "the first hypothesis is that ` transfer ` would outperform ` scratch ` in some setups , and that those setups could be predicted ( i.e. , they are not coincidental ) .",
    "however , any outperformance of ` transfer ` over ` scratch ` could be due to a larger number of network parameters .",
    "therefore , as a second hypothesis , ` random ` setups were used as a control for the number of parameters , to test how ` transfer ` could predictably outperform ` random ` .",
    "we postulated and tested several useful indicators for predicting the outperformance of transfer , i.e. , te : ( 1 ) _ feature similarity _ : count of features that are 1 for both source and target ) ; ( 2 ) _ source feature complexity _ : feature count of source game ; ( 3 ) _ target feature complexity _ : feature count of target game ; ( 4 ) _ source training complexity _",
    ": source game average time to threshold ; ( 5 ) _ target training complexity _ : target game average time to threshold , where the threshold for each game is the minimum max score achieved across all `` runs for that game , and time to threshold is the average number of generations to reach this threshold .",
    "to predict te , a linear regression model was trained in a leave - one - out cross - validation analysis . for each possible source - target pair @xmath19 ,",
    "the model was trained on all pairs @xmath20 with te as the dependent variable and the five indicators as the independent variables .",
    "subsequently , the trained model was used to predict the te of @xmath19 .",
    "correlation between the actual and predicted te across all test pairs was used to gauge the predictability of te .",
    "this experiment was conducted identically for both ` transfer ` versus ` scratch ` and ` transfer ` versus ` random ` conditions .      for both hypotheses ,",
    "the indicator - based model proved to be a statistically significant predictor of transfer effectiveness in the test data : correlation @xmath21 and p - value @xmath22 for ` transfer ` versus ` scratch ` ; correlation @xmath23 and p - value @xmath24 for ` transfer ` versus ` random ` ( figure  [ figurescatterplots ] ) .",
    "the strongest indicators for ` transfer ` versus ` scratch ` were target feature complexity and target training complexity , and for ` transfer ` versus ` random ` the strongest indicator was target feature complexity .",
    "the fact that more complex games are more successful targets should not be surprising . as noted before , in most transfer learning scenarios , only simple - to - complex transfer is considered .",
    "the ability to predict when grusm - esp will work is an important tool when applying this method to larger problems , and it is encouraging that the predictive indicator coincides with the ` common sense ' expectations of transfer effectiveness in the current experiments . te for all source - target pairs",
    "is visualized in figure  [ figuretransfernetworks ] . also ,",
    "although it is difficult to compare to the deterministic atari 2600 domain , table  [ tablecomparison ] provides a comparison of grusm - esp to recent results in that domain for context @xcite .",
    "the results show that grusm - esp ( an evolutionary algorithm for general transfer of neural network structure ) can improve learning in atari game playing by reusing previously developed knowledge .",
    "they also make it possible to characterize the conditions under which transfer may be useful .",
    "more specifically , the improvement in learning performance in the target domain depends heavily on the complexity of the target domain .",
    "the effectiveness of transfer in complex games aligns with the common - sense notion of hierarchical knowledge representation , as argued previously in transfer learning @xcite as well as in biology @xcite",
    ". it will be interesting to investigate whether the same principles extend to other general video game playing platforms , such as vgdl @xcite .",
    "such work should help understand how subsymbolic knowledge can be recycled indefinitely across diverse domains .",
    "transfer is likely inefficient in simpler games due to the effort involved in finding the necessary connections for reusing knowledge from a given source network effectively , in which case it is more efficient to relearn from scratch .",
    "for particular low - complexity games , it can also be seen that ` random ` consistently outperforms both ` scratch ` and ` transfer ` ( e.g. , pong ) .",
    "the initial flexibility of untrained parameters in the ` random ` condition may explain this result .",
    "unfreezing reused networks , and allowing them to change with a low learning rate may help close this gap .",
    "some ` transfer ` pairs do not consistently outperform training from ` scratch ` or ` random ` , indicating negative transfer .",
    "this highlights the importance of source and target selection in transfer learning .",
    "these results have taken a step towards answering the target - selection problem : what kinds of games make good targets for transfer ?",
    "more data across many more games is required to answer the source - selection problem : for a given game , what sources should be used ?",
    "a next step will involve pooling multiple candidate sources and testing grusm - esp s ability to exploit the most useful structure available .    despite negative transfer in some of the setups , the technique of training a classifier to predict transfer success",
    "is shown to be a useful approach for helping decide when to transfer : given some space of complex disparate domains , try transfer with a subset of source - target pairs , and use the results to build a classifier to inform when to attempt transfer in the future . in this paper , domain - characterization features were provided , but domain - agnostic features could be learned from analysis of the networks and/or learning process ; this is an interesting avenue for future work .",
    "another area of future work involves increasing the flexibility in the combined architecture by ( 1 ) relaxing the requirement for all transfer connections to be input - to - hidden and output - to - output , ( 2 ) allowing deeper architectures for the source and target networks , and ( 3 ) including multiple source networks with adaptive connectivity to each .",
    "these extensions will promote reuse of subnetworks of varying depth , along with flexible positioning and combination of modules .",
    "however , for grusm - esp , as networks become large and plentiful , maintaining full connectivity between layers will become intractable , and it will be necessary to enforcing sparsity .",
    "grusm - esp can also be extended to include lstm units , e.g. , as by @xcite ( @xcite ) , when deep memory is a primary concern .",
    "this paper introduced an approach for general transfer learning using neural networks .",
    "the approach minimizes a priori assumptions of task relatedness and enables a flexible approach to adaptive learning across many domains . in a stochastic version of the atari 2600 general video game - playing platform , a specific implementation developed in this paper as grusm - esp can boost learning by reusing neural structure across disparate domains .",
    "the success of transfer is shown to correlate with intuitive notions of domain complexity .",
    "these results indicate the potential for general neural reuse to predictably assist agents in increasingly complex environments .",
    "+ * acknowledgments * we would like to thank ruohan zhang for useful feedback .",
    "this research was supported in part by nsf grant dbi-0939454 , nih grant r01-gm105042 , and an npsc fellowship sponsored by nsa ."
  ],
  "abstract_text": [
    "<S> a general approach to knowledge transfer is introduced in which an agent controlled by a neural network adapts how it reuses existing networks as it learns in a new domain . </S>",
    "<S> networks trained for a new domain can improve their performance by routing activation selectively through previously learned neural structure , regardless of how or for what it was learned . </S>",
    "<S> a neuroevolution implementation of this approach is presented with application to high - dimensional sequential decision - making domains . </S>",
    "<S> this approach is more general than previous approaches to neural transfer for reinforcement learning . </S>",
    "<S> it is domain - agnostic and requires no prior assumptions about the nature of task relatedness or mappings . </S>",
    "<S> the method is analyzed in a stochastic version of the arcade learning environment , demonstrating that it improves performance in some of the more complex atari 2600 games , and that the success of transfer can be predicted based on a high - level characterization of game dynamics . </S>"
  ]
}