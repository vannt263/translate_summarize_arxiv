{
  "article_text": [
    "stochastic volatility ( sv ) models were proposed by @xcite .",
    "this model and its generalizations has been applied successfully to model the time - varying volatility present in financial time series . to estimate these models",
    "several estimation methods have been proposed in the literature , quasi - maximum likelihood methods @xcite , generalized method of moments @xcite , markov chain monte carlo methods ( mcmc ) ( pioneered by * ? ? ?",
    "* ) and integrated nested laplace approximations @xcite , to name a few . for an account of recent developments in the estimation of sv models see @xcite and @xcite and the references therein .",
    "in particular , mcmc methods are considered one of the most efficient estimation method .",
    "proposals include for example @xcite and @xcite .",
    "recently , @xcite proposed a methodology based on metropolis adjusted langevin and hamiltonian monte carlo sampling methods .",
    "these methods take advantage of the relationship between riemann geometry and statistics to overcome some of the shortcomings of existing monte carlo algorithms .",
    "they provide evidence that some sort of local calibration in the mcmc scheme may lead to strong improvements in large dimensional problems .",
    "in particular , one of the examples discussed by these authors is the estimation of sv models with normal perturbations .",
    "since these models often give rise to posterior distributions with high correlations the methods proposed can be particularly useful for estimation .",
    "more recently , @xcite presented an algorithm based on hamiltonian monte carlo methods for the estimation of realized stochastic volatility models .    in this paper",
    "we discuss the use langevin and modified langevin methods to the estimation of sv models with @xmath0-student and ged perturbations for the observations .",
    "we give the expressions , assess the performance and illustrate with two real data sets .",
    "because the computational time is critical for stochastic volatility models we implemented a hybrid method in which a riemann manifold mala ( mmala ) scheme is applied for the parameters and a mala scheme is applied for the volatilities . in particular",
    ", all the computations in this paper were implemented using the open - source statistical software language and environment r ( @xcite ) .",
    "the remainder of this paper is organized as follows .",
    "the models are presented in section [ models ] and the methodology for estimation is discussed in section [ estimation ] . to assess the estimation methodology some monte carlo experiments are presented in section [ simulations ] .",
    "section [ illustrations ] illustrates with empirical data , and some final remarks are given in section [ conclusions ] .",
    "we consider the following stochastic volatility ( sv ) model , @xmath1 where @xmath2 is a sequence of independent identically distributed ( iid ) random variables with zero mean and unit variance , @xmath3 is an iid sequence of random variables such that @xmath4 , @xmath5 and @xmath6 are independent for all @xmath0 . in addition , we assume that @xmath7 and @xmath8 .    in the sv model , conditional to the information set @xmath9 , the standard deviation of @xmath10 is given by , @xmath11 in finance ,",
    "if @xmath10 represents the @xmath0-th return then @xmath12 is the _ volatility _ at time @xmath0 .",
    "the original formulation of the sv model by @xcite considers @xmath6 following a standard normal distribution .",
    "however , many empirical studies indicate that this model does not account for the kurtosis observed in most financial time series returns .",
    "consequently , several other error distributions have been considered .",
    "for example , we consider @xmath6 following an exponential power distribution ( or generalized error distribution , ged ) with zero mean , unit variance ( see @xcite and @xcite ) with density function , @xmath13 where @xmath14 and the shape parameter @xmath15 .",
    "important special cases are , the laplace ( or double exponential ) distribution for @xmath16 and the standard normal distribution when @xmath17 .",
    "the kurtosis is given by @xmath18 so that when @xmath19 this distribution reproduces heavy - tails .",
    "in addition , we consider @xmath6 following a @xmath0-student distribution with @xmath20 degrees of freedom and density function , @xmath21 when @xmath22 this distribution approaches the standard normal distribution .",
    "let @xmath23 be the observed time series .",
    "in order to estimate this model we use the metropolis adjusted langevin ( mala ) and the riemannian manifold metropolis adjusted langevin ( mmala ) monte carlo methods proposed by @xcite .",
    "the estimation procedure is performed in a two - step blocking approach . in the first step , the latent variables @xmath24 ( the log - squared volatilities )",
    "are sampled and then , conditional on these sampled values , we sample the parameters @xmath25 . at each step",
    ", a metropolis - hastings sampling scheme is applied using the methods described below .",
    "let @xmath26 be the random vector of interest with density @xmath27 .",
    "then the metropolis adjusted langevin algorithm mala is based on a langevin diffusion process whose stationary distribution is @xmath27 and its stochastic differential equation is discretized to give the following proposal mechanism , @xmath28 } + \\frac{\\epsilon^2}{2}\\nabla_{\\xi } \\ln f({\\mbox{\\boldmath $ \\xi$}}^{[n ] } ) + \\epsilon{\\mbox{\\boldmath $ z$}}\\end{aligned}\\ ] ] where @xmath29 with @xmath30 the identity matrix of order @xmath31 and @xmath32 is the integration step size . a metropolis acceptance probability",
    "is then employed to ensure convergence to the invariant distribution as follows . a new value @xmath33 is sampled from a multivariate normal distribution with mean @xmath34},\\epsilon ) = { \\mbox{\\boldmath $ \\xi$}}^{[n ] } + \\frac{\\epsilon^2}{2 } \\nabla_{\\xi } \\ln f({\\mbox{\\boldmath $ \\xi$}}^{[n]})$ ] and variance - covariance matrix @xmath35 .",
    "this value is accepted with probability given by @xmath36 } | { \\mbox{\\boldmath $ \\xi$}})/ f({\\mbox{\\boldmath $ \\xi$}}^{[n ] } ) q({\\mbox{\\boldmath $ \\xi$}}| { \\mbox{\\boldmath $ \\xi$}}^{[n ] } ) \\}$ ] where the proposal density is @xmath37 } ) = n(\\mu({\\mbox{\\boldmath $ \\xi$}}^{[n]},\\epsilon),\\epsilon^2 { \\mbox{\\boldmath $ i$}})$ ] .",
    "this algorithm is then employed to estimate the sv model following the two steps below .    1 .",
    "_ sample the latent variables _ @xmath38 . assuming the parameters as constants , apply ( [ eq - mala-1 ] ) with",
    "@xmath39 and gradient @xmath40 calculated with respect to @xmath38 .",
    "2 .   _ sample parameters _",
    "@xmath41 . given @xmath42 ,",
    "apply ( [ eq - mala-1 ] ) with @xmath43 and gradient @xmath40 calculated with respect to @xmath41 .",
    "@xcite developed a modification in the metropolis proposal mechanism in which the moves in @xmath44 are according to a riemann metric instead of the standard euclidian distance .",
    "this procedure is refered to as riemann manifold mala or mmala . the proposal mechanism is now given by , @xmath45},\\epsilon)_{i } + \\left\\{\\epsilon \\sqrt{{\\mbox{\\boldmath $ g$}}^{-1}}({\\mbox{\\boldmath $ \\xi$}}^{[n]}){\\mbox{\\boldmath $ z$}}\\right\\}_{i } , \\label{eq - mmala-1}\\\\   \\mu({\\mbox{\\boldmath $ \\xi$}}^{[n]},\\epsilon)_{i } & = & \\xi^{[n]}_{i } + \\frac{\\epsilon^2}{2 } \\left\\ { { \\mbox{\\boldmath $ g$}}^{-1}({\\mbox{\\boldmath $ \\xi$}}^{[n]})\\nabla_{\\xi } \\ln f({\\mbox{\\boldmath $ \\xi$}}^{[n ] } ) \\right\\}_{i } \\nonumber \\\\ & - & \\epsilon^2 \\sum_{j=1}^d \\left\\ { { \\mbox{\\boldmath $ g$}}^{-1}({\\mbox{\\boldmath $ \\xi$}}^{[n ] } )    \\frac{d    { \\mbox{\\boldmath $ g$}}({\\mbox{\\boldmath $ \\xi$}}^{[n]})}{d\\xi_j } { \\mbox{\\boldmath $ g$}}^{-1}({\\mbox{\\boldmath $ \\xi$}}^{[n ] } ) \\right\\}_{ij}\\nonumber \\\\   & + & \\frac{\\epsilon^2}{2 } \\sum_{j=1}^d \\left\\ { { \\mbox{\\boldmath $ g$}}^{-1}({\\mbox{\\boldmath $ \\xi$}}^{[n ] } ) \\right\\}_{ij } tr\\left\\{{\\mbox{\\boldmath $ g$}}^{-1}({\\mbox{\\boldmath $ \\xi$}}^{[n]})\\frac{d    { \\mbox{\\boldmath $ g$}}({\\mbox{\\boldmath",
    "$ \\xi$}}^{[n]})}{d\\xi_j}\\right\\}\\label{eq - mmala-2 }   \\end{aligned}\\ ] ] where @xmath29 and , @xmath46    then , employing a metropolis mechanism with proposal density given by @xmath37 } ) = n(\\mu({\\mbox{\\boldmath $ \\xi$}}^{[n]},\\epsilon),\\epsilon^2   { \\mbox{\\boldmath $ g$}}^{-1}({\\mbox{\\boldmath $ \\xi$}}^{[n ] } ) ) $ ] and the usual acceptance probability given by the quantity @xmath47 } |{\\mbox{\\boldmath $ \\xi$}})/f({\\mbox{\\boldmath $ \\xi$}}^{[n ] } ) q({\\mbox{\\boldmath $ \\xi$}}|{\\mbox{\\boldmath $ \\xi$}}^{[n ] } ) \\}$ ] ensures convergence to the invariant distribution .",
    "we note that in this case both the mean vector and covariance matrix in the proposal distribution depend on the current state of the markov chain .",
    "a simplified proposal mechanism is obtained when a constant curvature is assumed . in this case ,",
    "the last two terms in ( [ eq - mmala-2 ] ) vanish and the proposal mean becomes , @xmath48},\\epsilon ) = { \\mbox{\\boldmath $ \\xi$}}^{[n ] } + \\frac{\\epsilon^2}{2 } { \\mbox{\\boldmath $ g$}}^{-1}({\\mbox{\\boldmath $ \\xi$}}^{[n]})\\nabla_{\\xi } \\ln f({\\mbox{\\boldmath $ \\xi$}}^{[n]}).\\end{aligned}\\ ] ] in this simplified version of mmala , the state - dependent covariance matrix in the proposal mechanism still allows adaptation to the local curvature of the target @xmath27 which has been shown to increase algorithm efficiency in a number of applications ( @xcite , @xcite ) .",
    "this is the approach adopted here .",
    "we show in the simulation study that , in particular for stochastic volatility models , we have an efficient algorithm for estimation and prediction with a lower computational cost , which is important in practice .    in our sv model",
    "this algorithm is then applied following the two steps below .    1 .",
    "_ sample the latent variables _ @xmath38 . assuming the parameters as constants , apply ( [ eq - mala-1 ] ) with @xmath39 and gradient",
    "@xmath40 calculated with respect to @xmath38 .",
    "2 .   _ sample parameters _ @xmath41 . given @xmath42 ,",
    "apply ( [ eq - mmala-1 ] ) and ( [ eq - mmala-2 ] ) with @xmath43 , gradient @xmath40 and matrix @xmath49 calculated with respect to @xmath41 .    in appendix",
    "[ appendix ] we provide details on the required expressions of partial derivatives and metric tensors for both mala and mmala . also , it is worth mentioning that matrix invertion is less computationally demanding in the sv model since @xmath50 has a sparse tridiagonal form .",
    "the log - likelihood @xmath51 $ ] is given by @xmath52 where @xmath53 , @xmath54 for ged errors and @xmath55 for @xmath0-student errors .",
    "following the bayesian paradigm we need to complete the model specification with apropriate prior distributions for the parameters .",
    "independent prior distributions were assigned for @xmath56 and @xmath57 as in @xcite and @xcite , that is @xmath58 inv-@xmath59(10,0.05 ) , @xmath60 .",
    "in addition , we propose an exponential distribution with mean one as the prior for @xmath61 .",
    "the prior for the tail parameter @xmath20 depends on the distribution adopted for the error terms . for ged errors",
    "we propose the prior for @xmath62 inv-@xmath59(10,0.05 ) while for student-@xmath0 errors , following @xcite , we consider the truncated exponential density , @xmath63 for @xmath64 and zero otherwise , as the prior for @xmath20 .",
    "differently from @xcite we specified @xmath65 .    denoting the joint prior density of @xmath41 by @xmath66 , the log prior",
    "is then given by , @xmath67 where @xmath68 for ged errors and @xmath69 for @xmath0-student errors .",
    "it is worth noting that , in order to employ the algoritms described in the previous sections , we need to implement a transformation of @xmath57 , @xmath56 and @xmath20 to the real line . here",
    "we set @xmath70 and @xmath71 as in @xcite , and we propose @xmath72 and @xmath73 for ged and @xmath0-student errors , respectively .",
    "of course this introduces jacobian factors into the acceptance ratios given by @xmath74 , @xmath75 . for ged errors , @xmath76 and for @xmath0-student errors @xmath77 .",
    "to assess the methodology described in the previous section we conducted a monte carlo study .",
    "we generated @xmath781000 replications of 1000 observations from the sv model ( [ sv - eqn1])-([sv - eqn2 ] ) with parameters @xmath79 , @xmath80 and two values for @xmath57 , @xmath81 .",
    "these parameter values were used by @xcite and @xcite among others .",
    "we considered three distributions for the errors : gaussian , ged with parameter @xmath82 and student s @xmath0 with @xmath83 degrees of freedom .",
    "we then evaluated two estimation schemes : ( i ) mala scheme for both the parameters and the volatilities and ( ii ) mmala scheme for the parameters and mala scheme for the volatilities ( hybrid method ) . since the vector of volatilities has the same dimension as the sample size ( usually thousands of observations ) we adopted this hybrid option instead of using mmala for both parameters and volatilities",
    "this is because computation time is relevant in real - life applications .",
    "the true parameter values were used as initial values for the mcmc samplers and the prior distributions are as described in section [ sec : prior ] . for each time series we drew 20,000 mcmc samples discarding the first 10,000 samples as a burn - in .    to evaluate the performance of the estimation methods , two criteria were considered : the bias and square root of the mean square error ( smse ) , which are defined as , @xmath84 where @xmath85 is the estimate of parameter @xmath86 for the @xmath87-th replication , @xmath88 . in this paper",
    "we take the posterior means of @xmath86 as point estimates .",
    "the estimation results are given in tables 1 and 2 .",
    "overall the results are good .",
    "[ table 1 around here ]    [ table 2 around here ]    * gaussian .",
    "good results in terms of bias and smse ( all parameters ) .",
    "mmala better excepting fro bias @xmath61 * ged .",
    "good results in terms of bias and smse ( all parameters ) .",
    "mmala better for @xmath61 and @xmath20 * student s @xmath0 good results in terms of bias and smse for @xmath61 and @xmath20 but bad results for @xmath56 and @xmath57 .",
    "maybe we need a large sample @xmath89 ?",
    "mmala better excepting for bias @xmath61",
    "in this section we applied the described methodology to estimate two exchange rate time series data : the pound / dollar (  /usd ) and the canadian dollar /dollar ( can / usd ) .",
    "the time series under study are the daily continuously compounded returns in percentage , defined as @xmath90 $ ] where @xmath91 is the price at time @xmath0 .    the  /usd time series returns covers the period from 1/10/81 to 28/6/85 and the sv model was estimated by @xcite using quase maximum likelihood methods and by durbin and koopman [ 2001 , pp 236 ] using quase maximum likelihood and monte carlo importance sampling methods . in both cases the authors assumed gaussian errors .",
    "the can / usd returns are based on daily noon rates prices .",
    "the time series prices were obtained from the website http://www.bankofcanada.ca/rates/exchange/ and covers the period from january 2 , 2007 to february 7 , 2013 .",
    "we have 945 and 2509 returns for the  /usd and can / usd time series , respectively . in figures [ pd ] and [ cd ]",
    "we show the time series returns and table [ basic - stats ] consigns some descriptive statistics . from this table",
    ", we observe a little skewness and high kurtosis , indicating asymmetric distributions with heavy tails .",
    "in addition , even not shown , the autocorrelation function indicates non serial correlation .",
    "figure [ pd ] around here    figure [ cd ] around here    table [ basic - stats ] around here    the analysis was done on the demeaned returns . for each time series",
    ", we estimated sv models considering the following three different distributions for the errors @xmath6 in ( [ sv - eqn1 ] ) , the gaussian , the ged distribution with parameter @xmath20 and the student s @xmath0 distribution with @xmath20 degrees of freedom .    for each time series we drew 150,000 mcmc samples of parameters and volatilities .",
    "we discarded the first 50,000 as burn - in and skipped every 25th resulting in a final sample of 4000 values from the posterior distribution .",
    "the estimated posterior means and standard deviations for each parameter are shown in table [ est - results ] .",
    "we can observe high persistence estimates ( @xmath56 ) .",
    "in addition , we obtained moderate values of @xmath20 the degrees of freedom in the @xmath0- student distribution , indicating not too heavy tails , @xmath92 and @xmath93 , then @xmath94 and @xmath95 .",
    "@xcite report the following maximum likelihood estimates : @xmath96 , @xmath97 and @xmath98 but do not report the bayesian estimates . ] .",
    "in particular , when comparing point estimates under mala and mmala schemes we note the following .",
    "* for the  /usd , estimates do not change under gaussian errors but change under ged and student s @xmath0 errors with a large change in @xmath20 for student s @xmath0 errors .",
    "the mmala seems to be more efficient to capture heavy tail behaviour .",
    "* for the can / usd , estimates change slightly under gaussian errors but do not change under ged errors . for student s @xmath0 errors we notice changes in @xmath61 and @xmath20 and",
    "again the mmala scheme managed to capture heavy tail behaviour . *",
    "the posterior standard deviations of @xmath20 are a bit large corroborating the known fact that this parameter is often difficult to estimate . *",
    "the posterior standard deviations of @xmath61 are also large for mmala and student s @xmath0 errors .",
    "figure [ mcmc ] shows the sample autocorrelations , sample paths and marginal posterior densities of parameters @xmath61 , @xmath57 , @xmath56 and @xmath20 for the can / usd series using the mmala sampling scheme under ged errors .",
    "the autocorrelations vanish fairly rapidly and the sample paths show relatively good mixing in the parameter space .",
    "figure [ mcmc ] around here    figure [ vol - pound ] around here    figure [ vol - cd ] around here    in figures [ vol - pound ] and [ vol - cd ] are showed the estimated volatilities @xmath99 taking the posterior medians of @xmath100 as point estimates .",
    "as can be seen , the volatilities follow very well the observed volatility clustering of returns .",
    "the performance of the proposed models and methods can also be assessed by estimating the value at risk ( var ) for multiple time horizons . from a bayesian perspective , given the observed values of returns @xmath101 point estimates of the one - step ahead var could be obtained using a sample of values drawn from its predictive distribution , i.e. @xmath102 where @xmath103 is the predicted one - step ahead var in the mcmc iteration . because they are not available",
    "analytically we adopt the following procedure . given the parameter values and log - volatilities in the @xmath104-th iteration we obtain values of @xmath105 by drawing @xmath106 and setting @xmath107 .",
    "next , we generate @xmath108 replications @xmath109 from the error distribution ( with tail parameter @xmath110 for student s @xmath0 or ged distributions ) .",
    "finally , we form a sample of returns by setting @xmath111 which allow us to approximate @xmath103 of confidence @xmath112 by the negative value of the sample @xmath112-quantile .    for illustration",
    ", we estimated the one day 99% var for the last 252 observations ( which covers one stock market year approximately ) of both the  /dollar and the canadian - dollar / dollar time series .",
    "since we wanted to reproduce a real scenario , the model parameters were estimated and the var calculated based on observations @xmath113 , @xmath114 .",
    "consequently , we estimated the model 252 times .",
    "figure [ var - pd ] shows the last 252 returns and the var estimates using our hybrid mmala algorithm for the  /dollar series . in 252 observations we expected @xmath115 observations below the var . for the gaussian ,",
    "student @xmath0 and ged distributions we obtained 8 , 7 and 5 observations outside the var limits , respectively .",
    "we note also that the var estimates follow very well the volatility in the market and reacts well to extreme down movements ( large negative return values ) .",
    "figure [ var - pd ] around here    as for the canadian - dollar / dollar series we note from figure [ var - cd ] that , qualitively the results for the gaussian and ged errors are better and we obtained 2 observations outside the var limits in both cases .",
    "the var s for student s @xmath0 errors on the other hand are quite large ( unnecessarily large from a financial viewpoint ) .",
    "this was indeed expected given the estimates of @xmath20 in table 5 .",
    "the estimate of @xmath61 is also large compared to gaussian and ged errors . in our empirical experience ,",
    "it is usually better to work with ged distributions instead of student s @xmath0 .",
    "figure [ var - cd ] around here",
    "in this paper we discuss a bayesian estimation of the stochastic volatility model with gaussian and two heavy - tailed distributions : ged and student s @xmath0 . specifically , we implemented the metropolis adjusted langevin ( mala ) and riemann manifold mala algorithms .",
    "since the volatility has dimension equal to the sample size , the computational time could be high in real - life applications .",
    "then we implemented a hybrid method : mmala estimation for the parameters and mala for sampling volatilities .",
    "these methods were assessed in simulated data and time series returns .    as in any metropolis - hastings like algorithm , our hybrid sampling scheme may be sensitive to the choice of the step size parameter @xmath32 .",
    "tunning the sampler is simply unavoidable in practice and we recommend trying two different tuning parameters during the burn - in period and the stationary phase of the markov chain ( from which the final sample will be collected ) .",
    "this research was partially supported by fapesp and faepex grants for the first author .",
    "the third author received support from fapesp - brazil , under grant number 2011/22317 - 0 .",
    "in this appendix we present the expressions of gradients and matrix tensors needed for the implementation of mala and mmala for ged and student s @xmath0 errors . for the gaussian case see @xcite . in what follows ,",
    "let @xmath116 .",
    "the partial derivatives of this log - density with respect to the transformed parameters @xmath127 are , @xmath128-\\frac{1}{2 } \\sum_{t=1}^n \\left|\\frac{\\varepsilon_t}{\\lambda}\\right|^\\nu \\left\\ { \\ln \\left|\\frac{\\varepsilon_t}{\\lambda}\\right|^\\nu - \\nu \\left(\\frac{\\nu}{\\lambda}\\frac{d\\lambda}{d\\nu}\\right ) \\right\\ } \\end{aligned}\\ ] ] where @xmath129    in addition , @xmath130 ^ 2   \\right\\}\\end{aligned}\\ ] ] where and @xmath131 and @xmath132 are , respectively , the digamma and trigamma functions .",
    ".5 cm now let @xmath133 $ ] .",
    "then @xmath134 and the expectations of the second order derivatives of @xmath135 are given by , @xmath136 and zero elsewhere .",
    "finally , we use @xmath137 and @xmath138 .                                                            t.  watanabe and m.  asai .",
    "stochastic volatility models with heavy - tailed distributions : a bayesian analysis .",
    "technical report , discussion paper 2001-e-17 , institute for monetary and economic studies , bank of japan , 2001 .",
    ".monte carlo experiments .",
    "bias and square root of the mean squared error of posterior means .",
    "parameters : @xmath79 , @xmath80 , @xmath147 and @xmath82 ( for ged ) and @xmath83 ( for student s @xmath0 ) . [ cols=\"<,<,^,^,^,^,^,^,^,^ \" , ]"
  ],
  "abstract_text": [
    "<S> in this paper we perform bayesian estimation of stochastic volatility models with heavy tail distributions using metropolis adjusted langevin ( mala ) and riemman manifold langevin ( mmala ) methods . </S>",
    "<S> we provide analytical expressions for the application of these methods , assess the performance of these methodologies in simulated data and illustrate their use on two financial time series data sets . </S>",
    "<S> + * keywords : * bayesian , markov chain monte carlo , metropolis - hastings , value at risk . </S>"
  ]
}