{
  "article_text": [
    "if probabilities are known , optimal lossless source coding of individual symbols ( and blocks of symbols ) is usually done using david huffman s famous algorithm@xcite .",
    "there are , however , cases that this algorithm does not solve@xcite . problems with an infinite number of possible inputs  e.g. , geometrically - distributed variables  are not covered .",
    "also , in some instances , the optimality criterion  or _ _ penalty  is not the linear penalty of expected length .",
    "both variants of the problem have been considered in the literature , but not simultaneously .",
    "this discusses cases which are both infinite and nonlinear .",
    "an infinite - alphabet source emits symbols drawn from the alphabet @xmath9 .",
    "( more generally , we use @xmath10 to denote an input alphabet whether infinite or finite . )",
    "let @xmath11 be the sequence of probabilities for each symbol , so that the probability of symbol @xmath5 is @xmath12 .",
    "the source symbols are coded into binary codewords .",
    "the codeword @xmath13 in code @xmath14 , corresponding to input symbol @xmath5 , has length @xmath4 , thus defining length distribution @xmath15 .",
    "perhaps the most well - known such codes are the optimal codes derived by golomb for geometric distributions@xcite .",
    "there are many reasons for using infinite - alphabet codes rather than codes for finite alphabets , such as huffman codes .",
    "the most obvious use is for cases with no upper bound  or at least no known upper bound  on the number of possible items .",
    "in addition , for many cases it is far easier to come up with a general code for integers rather than a huffman code for a large but finite number of inputs .",
    "similarly , it is often faster to encode and decode such well - structured codes . for these reasons , infinite - alphabet codes and variants of them",
    "are widely used in image and video compression standards@xcite , as well as for compressing text , audio , and numerical data .",
    "to date , the literature on infinite - alphabet codes has considered only finding efficient uniquely decipherable codes with respect to minimizing expected codeword length @xmath16 .",
    "other utility functions , however , have been considered for finite - alphabet codes .",
    "campbell  @xcite introduced a problem in which the penalty to minimize , given some continuous ( strictly ) monotonic increasing _",
    "_ cost function @xmath17 , is @xmath18 and specifically considered the exponential subcases with exponent @xmath8 : @xmath19 that is , @xmath20 .",
    "note that minimizing penalty @xmath21 is also an interesting problem for @xmath22 and approaches the standard penalty @xmath16 for @xmath23@xcite . while @xmath24 decreases for @xmath7",
    ", one can map decreasing @xmath25 to a corresponding increasing function @xmath26 ( e.g. , for @xmath27 ) without changing the penalty value .",
    "thus this problem , equivalent to maximizing @xmath28 , is a subset of those considered by campbell .",
    "all penalties of the form ( [ expcost ] ) are called @xmath2-exponential means , where @xmath29@xcite .",
    "campbell noted certain properties for @xmath2-exponential means , but did not consider applications for these means .",
    "applications were later found for the problem with @xmath8@xcite .",
    "these applications relate to a problem in which we wish to minimize the probability of buffer overflow in communications ; this is discussed in the full version of this paper@xcite . also discussed in the full version",
    "is an application for @xmath7 introduced in @xcite , a problem of maximizing the chance of message receipt in single - shot communications .",
    "one can solve any instance of the exponential penalty with a finite number of inputs using a linear - time algorithm found independently by hu _",
    "et al . _",
    "@xcite , parker @xcite , and humblet @xcite,@xcite , although only the last of these considered @xmath30 .",
    "we present the exponential - penalty algorithm here ; even though it can not be used for an infinite alphabet , it can be used to derive and show the optimality of infinite - alphabet codes :    * procedure for exponential huffman coding *    this procedure minimizes ( [ expcost ] ) for any positive @xmath31 and @xmath32 , even if the `` probabilities '' do not add to @xmath33 .",
    "we refer to such arbitrary positive inputs as _ _ weights , denoted by @xmath34 instead of  @xmath35 :    1 .   each item",
    "@xmath5 has weight @xmath36 , where @xmath10 is the ( finite ) alphabet and @xmath37 is the set of all such weights . assume each item @xmath5 has codeword @xmath38 , to be determined later .",
    "2 .   combine the items with the two smallest weights @xmath39 and @xmath40 into one item with the combined weight @xmath41 .",
    "this item has codeword @xmath42 , to be determined later , while item @xmath43 is assigned codeword @xmath44 and @xmath45 codeword @xmath46 .",
    "since these have been assigned in terms of @xmath42 , replace @xmath39 and @xmath40 with @xmath47 in @xmath48 to form @xmath49 .",
    "repeat procedure , now with the remaining codewords ( reduced in number by @xmath33 ) and corresponding weights , until only one item is left .",
    "the weight of this item is @xmath50 .",
    "all codewords are now defined by assigning the null string to this trivial item .",
    "optimality of the algorithm is justified as in huffman coding , in that an exchange argument can be used to show that an optimal code exists for which the least likely two codewords differ in only their final bit , allowing a reduction to the equivalent smaller problem that linearly combines their weights .",
    "this algorithm can be modified to run in linear time ( to input size ) given sorted weights in the same manner as huffman coding  @xcite .",
    "note that this algorithm assigns an explicit weight to each node of the resulting code tree implied by having each item represented by a node with its parent representing the combined items : if a node is a leaf , its weight is given by the associated probability ; otherwise its weight is defined recursively as @xmath6 times the sum of its children .",
    "this concept is useful in visualizing both the coding procedure and its output .",
    "it is also worthwhile to note that @xmath51 is degenerate , always resulting in the _ _ unary code ( for infinite inputs ) or a unary - like code ( for finite inputs ) being optimal for any probability distribution .",
    "the unary code has ones terminated by a zero , i.e. , codewords of the form @xmath52 .",
    "the unary - like code is a truncated unary code , that is , a code with identical codewords to the unary code except for the longest codeword , which is of the form @xmath53 . for the unary - like code ,",
    "optimality for @xmath51 can be shown using the coding procedure ; the smallest two items , @xmath43 and @xmath45 , are combined , and the resulting item has weight @xmath54 .",
    "this is no larger than the larger of the constituent weights , meaning that the resulting item will be combined with third - smallest item , and so forth , resulting in a unary - like code .",
    "taking limits , informally speaking , results in a unary limit code ; formally , this is a straightforward corollary of theorem  [ tailthm ] in section  [ other ] .    if @xmath55 , a code with finite penalty exists if and only if rnyi entropy of order @xmath56 is finite@xcite .",
    "it was campbell who first noted the connection between the optimal code s penalty , @xmath57 , and rnyi entropy @xmath58 this relationship is @xmath59 which should not be surprising given the similar relationship between huffman coding and shannon entropy@xcite , which corresponds to @xmath23 , @xmath60  @xcite .",
    "one must be careful regarding the meaning of an `` optimal code '' when there are an infinite number of possible codes under consideration .",
    "one might ask whether there must exist an optimal code or if there can be an infinite sequence of codes of decreasing penalty without any code achieving the limit penalty value .",
    "fortunately the answer is the former , the proof being a special case of theorem  2 in  @xcite .",
    "the question is then how to find one of these optimal source codes given parameter @xmath6 and probability measure  @xmath1 .    as in the linear case ,",
    "this is not known for general @xmath1 , but can be found for certain common distributions . in the next section ,",
    "we consider geometric distributions and find that golomb codes are optimal , although the optimal golomb code for a given probability mass function varies according to @xmath6 .",
    "the main result of section  [ geometric ] is that , for @xmath61 and @xmath62 , g@xmath63 , the golomb code with parameter @xmath45 , is optimal for @xmath64 in section  [ other ] , we consider distributions that are relatively light - tailed , that is , that decline faster than certain geometric distributions .",
    "if there is a nonnegative integer @xmath65 such that for all @xmath66 and @xmath67 , @xmath68 then an optimal binary prefix code can be found which is a generalization of the unary code .",
    "a specific case of this is the poisson distribution , where an aforementioned @xmath65 is given by @xmath69 for @xmath70 .",
    "section  [ nonexp ] discusses the maximum pointwise redundancy penalty , which has a similar solution with light - tailed distributions and for which the golomb code g@xmath63 with @xmath71 is optimal for with geometric distributions .",
    "complete proofs and illustrations , as well as additional results , are given in the full version@xcite .",
    "consider the geometric distribution @xmath72 for parameter @xmath73 .",
    "this distribution arises in run - length coding as well as in other circumstances@xcite .    for the traditional linear penalty , a golomb code with parameter  @xmath63  or g@xmath63  is optimal for @xmath74 .",
    "such a code consists of a unary prefix followed by a binary suffix , the latter taking one of @xmath63 possible values .",
    "if @xmath63 is a power of two , all binary suffix possibilities have the same length ; otherwise , their lengths @xmath75 differ by at most @xmath33 and @xmath76 .",
    "such binary codes are called _ _ complete codes .",
    "this defines the golomb code ; for example , the golomb code for @xmath77 is :    @xmath78    where the space in the code separates the unary prefix from the complete suffix . in general ,",
    "codeword @xmath43 for g@xmath63 is of the form @xmath79 , where @xmath80 is a complete binary code for the @xmath81th of @xmath63 items .",
    "it turns out that such codes are optimal for the exponential penalty :    for @xmath62 , if @xmath82 for @xmath83 , then the golomb code g@xmath63 is the optimal code for @xmath84 .",
    "if no such @xmath63 exists , the unary code is optimal .",
    "[ optgeo ]    the proof of optimality ( in full version @xcite ) uses the procedure for exponential huffman coding to find an optimal exponential huffman code for a sequence of similar finite weight distributions .",
    "define an @xmath85-reduced geometric source @xmath86 as : @xmath87 for any @xmath88 .",
    "it can be shown that this distribution has an optimal code with lengths @xmath89 through @xmath90 that are identical to the golomb code in question .",
    "one can then show that the optimal code for the geometric distribution must have a penalty between that for the golomb code for the geometric distribution and the optimal code for @xmath86 ( for any @xmath85 ) .",
    "since the latter two penalties approach equality as @xmath91 , the golomb code must be optimal .",
    "this rule for finding an optimal golomb g@xmath63 code is equivalent to @xmath92 this is a generalization of the traditional linear result since this corresponds to @xmath23 .",
    "cases in which the left inequality of ( [ ineq ] ) is an equality have multiple solutions , as with linear coding ; see , e.g. , @xcite .",
    "it is equivalent for the bits of the unary prefix to be reversed , that is , to use @xmath93 ( as in @xcite ) instead of @xmath79 ( as in @xcite ) .",
    "the latter has the advantage of being alphabetic , that is , @xmath94 if and only if @xmath38 is lexicographically after @xmath95 .",
    "a little algebra reveals that , for a distribution @xmath84 and a golomb code with parameter @xmath63 ( lengths @xmath96 ) , @xmath97 where @xmath98 and @xmath99 .",
    "therefore , theorem  [ optgeo ] provides the @xmath63 that minimizes ( [ geosum ] ) . if @xmath55 , the corresponding rnyi entropy is @xmath100 where we recall that @xmath101 .",
    "( again , @xmath51 is degenerate , an optimal code being unary with no corresponding rnyi entropy . )    in evaluating the effectiveness of the optimal code , one might use the following definition of _ _ average pointwise redundancy ( or just _ _ redundancy ) : @xmath102 for nondegenerate values , we can plot the @xmath103 obtained from the minimization .",
    "this is done for @xmath8 and @xmath7 in fig .",
    "as @xmath23 , the plot approaches the redundancy plot for the linear case , e.g. , @xcite , reproduced as fig .",
    "[ shannon ] .",
    "in many potential applications of nonlinear coding  such as the aforementioned for @xmath8@xcite and @xmath7@xcite  @xmath6 is very close to  @xmath33 .",
    "since this analysis shows that the golomb code that is optimal for given @xmath6 and @xmath104 is optimal not only for these particular values , but for a range of @xmath6 ( fixing @xmath104 ) and a range of @xmath104 ( fixing @xmath6 ) , the golomb code is , in some sense , much more robust and general than previously appreciated .",
    "in this section we consider another type of probability distribution for binary coding , a type with a light tail .",
    "approach@xcite , later extended in @xcite , uses the fact that there is always an optimal code consisting of a finite number of nonunary codewords for any probability distribution with a relatively light tail , one for which there is an @xmath65 such that , for all @xmath66 and @xmath67 , @xmath105 and @xmath106 . due to the additive nature of huffman coding ,",
    "the unary part can be considered separately , and the remaining codewords can be found via the huffman algorithm . once again , this has to be modified for the exponential case .",
    "we wish to show that the optimal code can be obtained when there is a nonnegative integer @xmath65 such that , for all @xmath66 and @xmath67 , @xmath107    the optimal code is obtained by considering the reduced alphabet consisting of symbols @xmath108 with weights @xmath109 apply exponential huffman coding to this reduced set of weights . for items @xmath110 through @xmath65 , the huffman codewords for the reduced and the infinite alphabets are identical .",
    "each other item @xmath111 has a codeword consisting of the reduced codeword for item @xmath112 ( which , without loss of generality , consists of all @xmath113 ) followed by the unary code for @xmath114 .",
    "we call such codes _ _ unary - ended .",
    "let @xmath115 be a probability measure on the set of nonnegative integers , and let @xmath6 be the parameter of the penalty to be optimized . if there is a nonnegative integer @xmath65 such that for all @xmath66 and @xmath67 , @xmath116 then there exists a minimum - penalty binary prefix code with every codeword  @xmath66 consisting of @xmath117 @xmath113 followed by one @xmath110 for some fixed nonnegative integer  @xmath118 .",
    "[ tailthm ]    the proof of optimality ( in full version @xcite ) is similar to that for the geometric distribution . in this case , for a given @xmath119 , the corresponding codeword weights are @xmath120 where @xmath121 . for @xmath7 ,",
    "the proof is outlined similarly to that for the geometric case . for @xmath8 ,",
    "the key is to note that the combined weight of a node in an optimal code is upper - bounded by the weight of a node with the same children in a code for which the node is the root of a unary subtree .",
    "this allows an inductive proof that the unary subtree  and thus the proposed code  is optimal .",
    "consider the example of optimal codes for the poisson distribution , @xmath122 how does one find a suitable value for @xmath65 in such a case ?",
    "it has been shown that @xmath123 yields @xmath105 for all @xmath66 and @xmath67 , satisfying the first condition of theorem  [ tailthm ] @xcite . moreover , if , in addition , @xmath124 ( and thus @xmath125 ) , then @xmath126 \\\\ \\qquad & < & \\boldp(j ) \\left[\\frac{a \\lambda}{j+1 } + \\frac{a^2 \\lambda^2}{(j+1)^2 } + \\cdots \\right ] \\\\",
    "\\qquad & = & \\boldp(j ) \\frac{\\frac{a \\lambda}{j+1}}{1-\\frac{a \\lambda}{j+1 } } \\\\ \\qquad & \\leq & \\boldp(j ) \\\\",
    "\\qquad & \\leq & \\boldp(i ) . \\end{array } \\end{array}\\ ] ] thus , since we consider @xmath127 , @xmath69 is sufficient to establish an @xmath65 such that the above method yields the optimal infinite - alphabet code .    in order to find the optimal reduced code ,",
    "use @xmath128 for example , consider the poisson distribution with @xmath129 .",
    "we code this for both @xmath130 and @xmath131 . for both values , @xmath132",
    ", so both are easy to code . for @xmath130 , @xmath133 , while , for @xmath131 , @xmath134 . after using the appropriate huffman procedure on each reduced source of @xmath135 weights ,",
    "we find that the optimal code for @xmath130 has lengths @xmath136  those of the unary code  while the optimal code for @xmath131 has lengths @xmath137 .",
    "it is natural to ask whether the above results can be extended to other penalties .",
    "one penalty discussed in the literature is that of maximal pointwise redundancy@xcite , in which one seeks to find a code to minimize @xmath138.\\ ] ]    this can be shown to be a limit of the exponential case , as in @xcite , allowing us to analyze it using the same techniques as exponential huffman coding .",
    "this limit can be shown by defining _ _",
    "@xmath139th exponential redundancy as follows : @xmath140 thus @xmath141 , and the above methods should apply in the limit .",
    "in particular , the golomb code g@xmath63 for @xmath142 is optimal for minimizing maximum pointwise redundancy for @xmath84 . for light tails , a similar condition to ( [ cond ] ) holds ; in this case , we find an @xmath65 such that , @xmath143 and @xmath144 applications and proofs of these results are in the full version @xcite .",
    "t.  wiegand , g.  j. sullivan , g.  bjntegaard , and a.  luthra , `` overview of the h.264/avc video coding standard , '' _ ieee trans .",
    "circuits and systems for video technology _ , vol .  13 , no .  7 , pp .",
    "560576 , july 2003 .",
    "m.  weinberger , g.  seroussi , and g.  sapiro , `` the loco - i lossless image compression algorithm : principles and standardization into jpeg - ls , '' _ ieee trans .",
    "image processing _ , vol .  9 , no .  8 , pp . 13091324 , aug",
    ". 2000 , originally as hewlett - packard laboratories technical report no .",
    "hpl-98 - 193r1 , november 1998 , revised october 1999 .",
    "available from http://www.hpl.hp.com / loco/."
  ],
  "abstract_text": [
    "<S> let @xmath0 be a measure of strictly positive probabilities on the set of nonnegative integers . </S>",
    "<S> although the countable number of inputs prevents usage of the huffman algorithm , there are nontrivial @xmath1 for which known methods find a source code that is optimal in the sense of minimizing expected codeword length . for some applications , however , a source code should instead minimize one of a family of nonlinear objective functions , @xmath2-exponential means , those of the form @xmath3 , where @xmath4 is the length of the @xmath5th codeword and @xmath6 is a positive constant . applications of such minimizations include a problem of maximizing the chance of message receipt in single - shot communications ( @xmath7 ) and a problem of minimizing the chance of buffer overflow in a queueing system ( @xmath8 ) . </S>",
    "<S> this introduces methods for finding codes optimal for such exponential means . </S>",
    "<S> one method applies to geometric distributions , while another applies to distributions with lighter tails . </S>",
    "<S> the latter algorithm is applied to poisson distributions . </S>",
    "<S> both are extended to minimizing maximum pointwise redundancy . </S>"
  ]
}