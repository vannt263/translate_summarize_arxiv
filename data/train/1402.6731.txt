{
  "article_text": [
    "source coding , that is , the encoding of the output of an information source , is one of the fundamental problems of information theory .",
    "a source emits a sequence of possible messages .",
    "a simple model of a source thus consists of a discrete infinite sequence @xmath0 of random variables @xmath1 , whose actual values @xmath2 describe the @xmath3-th message , whereas @xmath4 stands for the range of the random variables .",
    "( we shall refer to the steps of this sequence as _ iteration steps _ throughout this paper . ) this is termed as a stochastic process .",
    "information theory provides asymptotic lower bounds on the number bits required per message to encode the output of such a source .",
    "these bounds are based on arguments involving the asymptotic equipartition property , a consequence of the weak law of large numbers .",
    "if the sequence @xmath0 consists of independent , identically distributed random variables @xmath5 , the required asymptotical number of bits per symbol is @xmath6 , where @xmath7 stands for the shannon entropy .",
    "if , however , the source is described by a generic stochastic process , in the arguments regarding the above - mentioned lower bound , the entropy is replaced by the so - called entropy - rate : @xmath8 if the limit exists .",
    "it can be shown that for stationary time - invariant stochastic processes , the entropy rate exists and is equal to a similar quantity defined via conditional entropies @xmath9 moreover , for a stationary time - independent markov - chain it simplifies to @xmath10 expressed in terms of the probability transition matrix @xmath11 where the indices @xmath12 label the elements of the range @xmath4 , and the stationary distribution @xmath13 ( that is , @xmath14 ) of the markov chain , the entropy rate can be calculated as @xmath15 all such markov processes are equivalent to a classical random walk on an undirected weighted graph , in which the probability transition matrix is expressed from the weights @xmath16 as @xmath17 these facts , the details of which can be found in many textbooks of information theory ( e.g. , ref .",
    "@xcite ) motivate our present investigation .",
    "quantum information theory is a nontrivial generalization of the classical one ; hence , one expects that the above arguments can be also generalized that way .",
    "indeed , there are various approaches of quantum information to form the concept of quantum entropy rate @xcite . in the present paper , however , we will focus on a description in terms of classical information theory .",
    "we consider the following simple scenario .",
    "let us assume that we have a source of information in a  black box \" .",
    "we know that there is some physical process inside , generating classical messages .",
    "however , this process might be either a classical random walk or some quantum process which generates classical information , and has a well defined classical counterpart : if decoherence is significant , it becomes a classical random walk .",
    "then we can utilize the above described apparatus of classical information theory to compare the classical random walk with one of its quantum generalizations .",
    "hence , we do not go beyond the concepts of classical information theory here ; instead , we utilize them in order to learn more about the classical - quantum transition : what is the difference between a classical and quantum black box from the point of view of entropy rates ?",
    "if one seeks a quantum process with a classical counterpart which is a discrete - time random walk , the discrete - time quantum walk ( qw ) is a suitable choice .",
    "quantum walks @xcite are nontrivial generalizations of the classical random walks , obeying unitary , and therefore deterministic , dynamics .",
    "this simple quantum model allows researchers to study various physical phenomena , including transport @xcite , percolation @xcite , and topological effects @xcite . similarly to classical walks , qws can be naturally utilized for algorithmic applications .",
    "the universality of qws is proven in refs .",
    "@xcite . for an overview of quantum informational applications of qws ,",
    "@xcite . in the recent years",
    ", several experimental breakthroughs have been achieved @xcite , these experimental successes naturally motivate the theoretical study of qws .",
    "this paper is organized as follows : first , we calculate the entropy rate of certain classical random walks .",
    "then we define quantum walks and a scenario in which they serve as signal sources . we give explicit and approximate methods to calculate the upper bound of entropy rate and the actual entropy rate of the source considered .",
    "finally , classical and quantum cases are compared and conclusions are drawn .",
    "let us summarize the properties of certain classical walks , which we shall refer to later in this paper .",
    "the results presented here can be obtained by a straightforward application of the definitions given in the previous section .",
    "we remark here that for a general classical walk as a stationary markov process , the entropy rate , according to eq .  , is the average of the entropy of the rows of the probability transition matrix taken with the stationary probability of each vertex .",
    "( as each row corresponds to a vertex where the walker may stand in a step , and each column to an edge pointing to a possible vertex he can jump to . ) in particular , if the stationary distribution is uniform and , for some symmetry reason , the rows are permutations of each other ( thus having the same entropy ) , the entropy rate is simply the entropy of a row . that is , in the graph picture , the process is equivalent to a sequence of independent identically distributed random variables describing the random decision taken by the the walker in each step .",
    "this reasoning is applicable in some of the cases we discuss here .",
    "an unbiased ( isotropic ) classical random walk ( cw ) on a @xmath18-regular simple graph , for instance , has the entropy rate of @xmath19 : wherever we find the walker , it has @xmath18 equal - probability edges to follow ( isotropy ) , and the stationary distribution is obviously uniform .",
    "hence , in this model , for every step we need @xmath19 classical bits to encode the direction where the walker has moved randomly",
    ".    now let us consider a one - dimensional walk ( on a finite cycle with @xmath20 vertices ) and suppose that we intend to encode the position only at every @xmath21-th step of the walk .",
    "this reads @xmath22 which is the shannon entropy of the binomial distribution and the gaussian distribution respectively .",
    "we derive formula in eq .   later , concluding in eq .  .",
    "note , that the @xmath23 prefactor is a consequence of the diffusive spreading of the cw .",
    "the parameter @xmath21 will be termed as `` waiting time '' in what follows , which will also be the time we wait between two subsequent quantum measurements in the corresponding quantum protocol .",
    "note that eq .",
    "is valid for both infinite and finite systems , as long as @xmath24 . for finite @xmath20 and",
    "that are rates high enough ( in one - dimensional ( 1d ) cycle graphs , for instance , this occurs for @xmath25 ) , the walker mixes with itself , making the rate given by eq .",
    "inaccurate . in this case",
    "the sequence becomes a series of independent random variables with a uniform distribution over the accessible positions , thus the entropy rate becomes the upper bound of the possible entropy rates , @xmath26 the difference caused by the parity is due to the fact that the positions accessible for the walker may be restricted . in a 1d cycle graph with even number of sites ( @xmath20 )",
    ", the walker , from a given position , can reach either the even or the odd labeled sites only , depending on the waiting time @xmath21 .",
    "therefore , even for the limiting @xmath27 , only half of the sites can be reached by the walker . for cycles with an odd number of sites",
    ", this restriction does not hold .",
    "the system under consideration is translationally invariant ( homogeneous in space ) : the transfer probabilities @xmath28 between arbitrary lattice sites @xmath29 and @xmath30 depend only on the difference ( distance ) @xmath31 of the two sites .",
    "thus , we introduce the probability of a @xmath31 length shift @xmath32 in systems obeying this symmetry , it is common to encode the difference @xmath31 of the actual random position outcome from the previous random outcome , leading to the usage of at most @xmath33 symbols , thus a finite alphabet . it is straightforward to see that the two encoding methods  encoding the absolute position outcomes and encoding the relative position differences  are equivalent . from ( [ entropy_stationary_markov ] ) and ( [ delta_equivalence ] )",
    "one can readily calculate the entropy rate as @xmath34 which after a short calculation results in eq .",
    "( [ entropy_classical ] ) .",
    "we can conclude that the entropy rate of a process arising from a one - dimensional classical walk with waiting time @xmath21 is simply the shannon entropy of the distribution of the shifts .",
    "note that for the sake of readability the sum in eq .",
    "is taken between @xmath35 and @xmath21 ; however , since the classical walker leaves its position in every step , there is a parity correspondence between @xmath21 and @xmath36 , thus we have @xmath33 symbols to encode at most . in the next section",
    "we extend the concept of entropy rate to sources driven by quantum walks by following the procedure presented above .",
    "given a @xmath37 @xmath18-regular simple graph , the hilbert space of a discrete - time coined quantum walk ( qw ) is defined as @xmath38 where @xmath39 is the position space corresponding to the vertices of the graph and @xmath40 is the coin - space corresponding to an internal ,  coin \" degree of freedom , i. e. , directions pointing to the nearest neighbors .",
    "let us use the following shorthand for hilbert - space vectors : @xmath41 the discrete - time unitary evolution is given by @xmath42 where @xmath43 } | v \\oplus   c , c\\rangle \\langle v , c |\\,.\\ ] ] @xmath44 stands for the identity operator on the position space , and @xmath45 is the coin operator acting on the internal degree of freedom .",
    "the abstract sum @xmath46 represents the nearest neighbor of the vertex @xmath47 in the direction indicated by the coin state @xmath48 .",
    "we wish to use this deterministic quantum process as the source of messages ( classical random variables ) .",
    "thus , we introduce measurement into the system , closely following the procedure we employed for the classical case : we let the walker evolve for @xmath21 steps and we measure its position afterwards . should someone measure the position of the walker , she will get a random position @xmath29 with probability @xmath49 where @xmath50 is the hilbert vector corresponding to the quantum state of the qw at the @xmath3th iteration step .",
    "the corresponding @xmath1 is the random variable describing the position outcome at the @xmath3th iteration . from now on",
    ", we consider the sequence of @xmath1 random variables as the stochastic process generating the message we wish to encode efficiently .",
    "a similar model is considered in ref .",
    "@xcite , where the authors address the randomness induced by the frequent measurements . however , our case is differs fundamentally as we do not reset the coin state after every measurements and we focus on the entropic properties of the system .    like classical walks ,",
    "the qws considered in the present paper are translationally invariant : @xmath51 for all @xmath52 and @xmath48-s .",
    "consequently , in place of encoding the @xmath53 measurement outcomes , one can encode position differences @xmath54 .",
    "note , that this encoding simplification does not affect the value of the entropy rates , it is just the standard notation for systems with translation invariance .",
    "equivalently , the original problem can be rephrased so the black box outputs the relative position differences @xmath31 instead of absolute positions .",
    "the proposed definition of a qw - driven message source has a well - defined classical connection : should one consider an unbiased coin matrix @xmath55 ( with all complex elements having the same absolute value in the natural ( computational ) basis ) , a quantum walk measured in every single step ( waiting time @xmath56 ) behaves exactly like a classical unbiased ( isotropic ) walk .",
    "throughout this paper we will investigate 1d qws and use the @xmath57 hadamard matrix as the coin operator , @xmath58 in most of the cases , unless stated otherwise .",
    "we use the hadamard coin since it is unbiased , thus we have a very well controlled quantum - classical transition at our hands .",
    "let us calculate the entropy rate of the process defined in the previous section .",
    "we note , that here we address the 1d problem , but the methods we give could be generalized for higher dimensional qws .",
    "first , we show a way to calculate the joint probability distribution @xmath59 of the possible outcomes . employing eq .",
    "( [ stochprocc_def ] ) , the joint probability distribution of the random variable sequence @xmath1 is given by    @xmath60    where @xmath61 is the projector of the von neumann measurement corresponding to the position @xmath62 and @xmath63 is the initial state of the 1d qw in the black box .",
    "next we employ the definition in eq .",
    "( [ eq : entrate ] ) to obtain the entropy rate . note , that we have to use the original definition as we are not considering a markovian process here .",
    "however , calculating ( [ joint_distrib ] ) and therefore the actual entropy rate in the asymptotic limit is quite demanding both numerically and analytically . in the following",
    "we present a method to make the calculation manageable .",
    "it is based on the fact that the transition probabilities between subsequent measurement outcomes depend on a parameter which in fact can be taken into account .",
    "it is the internal quantum coin state , which carries additional information in the following sense .",
    "after every position measurement , the wave function collapses to a single position site , but the information carried in the coin degree of freedom that particular site survives the process : it serves as the initial coin state in the following iteration . after acquiring any position measurement outcome ( a black box output ) @xmath64 ,",
    "since the evolution of qw is unitary ( deterministic ) until the position measurement , the full quantum state of the actual collapsed qw can be reconstructed with the knowledge of the full quantum state of the preceding ( initial ) iteration . in summary ,",
    "the coin degree of freedom serves as a memory , carrying some information about the previous steps .",
    "the importance of this observation is twofold : first , the information carried in this internal memory can be used to improve our encoding method .",
    "second , we use the coin to aid our calculation of the joint probability distribution , thus the entropy rate .    to employ the coin as a hidden continuous parameter of the model , we introduce an extended , @xmath65 stochastic transition matrix , where @xmath66 is an abstract continuous parameter representing an internal coin state .",
    "the definition is given as @xmath67 since we know the initial ( previous ) quantum state of the system , the quantum state of the next iteration step can be calculated as follows : @xmath68 where we defined function @xmath69 giving the unambiguous coin state . employing these definitions while using eqs .",
    "( [ joint_distrib ] ) and ( [ position_projector ] ) we arrive at @xmath70 where @xmath71 and @xmath72 corresponds to the initial coin state .",
    "let us use the translation invariance ( [ homogeneousity ] ) of the system .",
    "we shall see that @xmath73 and @xmath74 for all values of @xmath29 , @xmath75 and @xmath31 .",
    "thus @xmath76 where @xmath77 and @xmath78 with @xmath79 .",
    "note that the product form of the probability shows the true markov chain like nature of the system : the probability of any outcome can only depend on the previous quantum state of the system , that is , the internal coin state and its position ( which is in the @xmath31 difference picture is neglected due to translation invariance ) .",
    "the shannon entropy of the joint distribution can be calculated using the chain rule as @xmath80 where @xmath81 is the distribution of coin states at the @xmath82th iteration step , with @xmath83 and @xmath84 . in our notation ,",
    "the @xmath31 symbol with two indices ( @xmath85 ) is the kronecker @xmath31 . by @xmath86",
    "we denote the continuous set of all abstract coin states .",
    "the entropy rate is then given by taking the limit as in eq .",
    "( [ eq : entrate ] ) , @xmath87 which in this case is equivalent with @xmath88 where @xmath89 is the asymptotic distribution of coin states . note that since in this paper we use the hadamard coin matrix ( [ coin_hadamard ] ) the ( asymptotic ) coin states do not form a continuous set , thus the use of a discrete sum over all coins states ( @xmath86 ) is sufficient .    in summary , the method of calculating the entropy rate is the following : first , one should determine the asymptotic coin distribution @xmath90 . then @xmath91 shift probabilities can be determined easily using formulas in eqs .",
    "( [ matrix_generalized ] ) and ( [ pcdelta_def ] ) .",
    "finally , the entropy rate can be obtained using ( [ erate_qw_final ] ) .",
    "note that the method proposed here can be applied directly for both finite or infinite systems .",
    "also it can be extended in a straightforward way to higher dimensional quantum walks .",
    "however , such extension goes beyond the scope of the current paper .    we have not yet addressed the method for determining the asymptotic coin distribution @xmath90",
    "this can be done by defining a stochastic matrix , @xmath92 that is , the probability that from a @xmath66 coin state after applying @xmath93 the walker is in the @xmath94 coin state after the position measurement .",
    "it is straightforward to see that @xmath95 is indeed a stochastic matrix , @xmath96 after constructing the complete @xmath95 transition matrix , the @xmath90 asymptotic coin distribution can be readily found as the stationary state of the stochastic matrix @xmath95 .",
    "moreover , 1d qws have some symmetries which can be employed to make the calculation more efficient .",
    "first , 1d qws bear a spin - flip symmetry .",
    "this symmetry implies that , compared to the general initial coin state @xmath97 , the orthogonal @xmath98 produces a mirrored position probability distribution .",
    "we use a single important consequence of this property : a walk started from @xmath99 produces the exact same amount of entropy for any @xmath21 waiting times as the walk started form @xmath100 , that is , @xmath101    second , for 1d hadamard qws , @xmath102 moreover , for arbitrary mixing coins of 1d qws using the coin operator @xmath103 with @xmath104 and @xmath105 @xmath106 here , we defined the summarized transition probability for the abstract `` joined '' coin state @xmath107 .",
    "this property has an immediate consequence : the black box based on a qw always forgets its initial state .",
    "since from an arbitrary coin state a transition to @xmath107 happens according to eq .",
    "( [ maptolr ] ) the part carrying information about the initial state @xmath72 at the iteration step @xmath3 is proportional to @xmath108 , which is in the asymptotic @xmath109 limit tends to @xmath110 .",
    "this is one of our main results .",
    "using the method we gave above it is straightforward to determine the entropy rate of the qw with @xmath111 as the simplest , nontrivial case , @xmath112 the details of the exact calculation using this approach can be seen in appendix  [ w2entrrate ] . for reference ,",
    "the entropy rate of the cw for @xmath111 is @xmath113 bits as given by eq .",
    "( [ entropy_classical ] ) .",
    "we numerically approximated the entropy rate using eq .",
    "( [ eq : entrate ] ) , for finite @xmath114 s ( iterations ) . we found , that the obtained numerical data are converging to the rate we determined as illustrated in fig [ figure1 ] .",
    "this result somehow contradicts the assumption that qws generate more entropy because of the faster spreading .",
    "in fact , revealing the coin as a carrier of information , thus extracting more information from simple position measurement outcomes , allows for a more efficient prediction of the next step , essentially leading us to a more efficient source coding method  and a lower entropy rate .",
    "however , it should be noted that for higher @xmath21 waiting times the entropy rate of the faster spreading qw inevitably surpasses the cw  the proof behind this result is discussed in the following section .     for @xmath111 waiting time .",
    "we have evaluated the definition of eq .",
    "( [ eq : entrate ] ) for the first @xmath114 iteration steps , using the joint probability distribution in eq .",
    "( [ joint_distrib ] ) .",
    "we used the 1d qw with hadamard coin ( see eq .",
    "( [ coin_hadamard ] ) ) ; the triangles and circles correspond to the walk started from initial states @xmath115 and @xmath116 , respectively .",
    "the continuous line corresponds to the analytically determined rate for the simulated model : @xmath117 bits .",
    "the dashed line corresponds to the rate of the cw : @xmath118 bits .",
    ", scaledwidth=47.5% ]    the above given process is adequate when @xmath90 is nonzero for only a finite number of @xmath66 coin states , i.e. , the number of coin states arising under the full time evolution is finite or , equivalently , the size of @xmath95 is finite .",
    "however , depending on the coin operator and the waiting time we choose , the @xmath95 matrix can grow to infinite size .",
    "this issue can be solved by introducing a truncated ( finite ) basis ; however , this will cause an uncertainty in the result .",
    "we introduce a set of unknown coin states denoted by @xmath119 , which we use when we do not wish to calculate the elements of @xmath95 further . in other words , the abstract set ",
    "@xmath120 \" collects the coin states which the system does not touch up to the iteration step @xmath3 , i. e. , @xmath121 \\right\\}\\ , , \\label{qmarkdef}\\ ] ] where @xmath122 is the coin state distribution at the @xmath82th iteration step as given in eq .",
    "( [ coindistrib ] ) .",
    "we note that rule of eq .",
    "( [ maptolr ] ) applies to  @xmath120 \" as well , and it can be employed to make the truncated @xmath95 matrix a proper stochastic matrix .    since the value @xmath123 is unknown , eq .",
    "( [ erate_qw_final ] ) can not be used , but it can be bounded by giving an upper bound , @xmath124 and a lower bound , @xmath125 considering this , the value of the exact entropy rate ( [ erate_qw_final ] ) are in the interval @xmath126 here we note that we use the compact form with a @xmath127 sign to denote the interval where the exact entropy rate resides .    the now proposed truncating method can be applied to approximate the entropy rates for arbitrary @xmath21 s . however , with the increasing of @xmath21 the size of stochastic matrices grows rapidly , @xmath128 + 1\\ , , \\label{approxdimmatr}\\ ] ] where @xmath3 is the number of iterations of the procedure we take during the calculation of the matrix @xmath129  and is also in the definition ( [ qmarkdef ] ) . similarly , the scaling of @xmath130 can be approximated as it is proportional to the relative error of the calculated entropy rate . after a lengthy , but straightforward , calculation this turns out to be @xmath131 where we used @xmath132 from eq .",
    "( [ maptolr ] ) . despite the exponential scaling of the precision and the dimension with respect to the number of the iterations @xmath3",
    ", we found that our method converge much faster than mere brute force simulations reconstructing the joint probability distribution in eq .",
    "( [ joint_distrib ] ) .",
    "this is due to the fact that the approximations ( [ approxdimmatr ] ) and ( [ approxmuquest ] ) are based on a worst - case scenario , while as it can be seen in the explicit calculations of this paper , the convergence of the @xmath90 distribution is much better . to achieve an even better convergence",
    ", one can extend the proposed simplifications  by use of the spin flip symmetry  in order to find further isentropic states like the ones in eq .",
    "( [ lrentropyequiv ] ) .",
    "we determined the entropy rate of @xmath133 walks using the given methods . for the 1d hadamard qw the approximative calculation gave @xmath134 in comparison",
    ", the cw walk has the entropy rate of @xmath135 bits .",
    "more details of the calculation based on the approximative method can be seen in appendix  [ approxentrrate ] .",
    "we illustrate the results in fig .",
    "[ figure2 ] .     of the frequently measured walks on a 1d line as functions of waiting time @xmath21 .",
    "the circles correspond to the entropy rate @xmath136 ( see eq .",
    "( [ entropy_classical ] ) ) of the classical walk .",
    "we used the hadamard coin of eq .",
    "( [ coin_hadamard ] ) for the quantum walk .",
    "the black disks corresponds to the exactly calculated entropy rate @xmath137 given by eq .",
    "( [ erate_qw_final ] ) , while the vertical line segments correspond to the interval defined by the lower and upper bound on the entropy rate in eq .",
    "( [ erate_qw_final_bounded ] ) .",
    "the rectangles correspond to the upper bound entropy rate @xmath138 defined in sec .",
    "[ naivesection ] , while the continuous line represents the analytic approximation @xmath139 of eq  ( [ erate_mixed_coin_approx ] ) .",
    ", scaledwidth=45.0% ]    in the following we give an upper bound for the just now determined entropy rate which is easier to measure or compute .",
    "we will also discuss the scaling of the entropy rate of qws with respect to waiting time @xmath21 .",
    "here we describe a method which will give us an easy - to - understand and compute upper bound to the entropy rates of qws .",
    "if one is not aware of the quantum nature of the walk on which the information source ( the `` black box '' ) is based , she or he might follow a measurement protocol which is suitable for classical walks , thus ignoring the internal quantum coin state .",
    "such an absence of the information carried by the coin leads to a less efficient encoding and , thus , higher entropy rates .",
    "this statement is also supported by the fact that a function of a markov chain  a hidden markov chain  has a higher or equal entropy rate than the original chain @xcite , meaning essentially an upper bound ( and lower encoding efficiency ) .",
    "let us propose the measurement protocol which ignores the hidden coin ( memory ) of the qw in the black box .",
    "written in a standardized manner , the protocol consists of the following steps :    1 .",
    "initialize the walker at state @xmath140 , set position indicator @xmath141 .",
    "2 .   let the walk evolve for @xmath21 steps .",
    "3 .   perform a position von - neumann measurement , which results a random position outcome @xmath142 $ ] .",
    "4 .   make a note that a @xmath143 transition happened .",
    "repeat steps 2 . - 5 . with @xmath144 as the new @xmath29 .",
    "applying the protocol above for infinitely many times , the probabilities of @xmath143 transitions are calculated as relative frequencies . in this way",
    ", a stochastic transition matrix @xmath145 describing the qw - driven process is obtained .",
    "note that in this way it is implicitly assumed that the system can be described via a time stationary classical markov chain  which is not true in general . finally , the entropy rate is calculated using eq .",
    "( [ entropy_stationary_markov ] ) .",
    "one should note that for an infinite system the matrix @xmath145 is not easy to handle .",
    "however , qws under consideration are translationally invariant ( cf .",
    "( [ homogeneousity ] ) ) .",
    "consequently , @xmath146 for all @xmath31 s . like in the classical case",
    ", we introduce @xmath36 by eq .",
    "( [ delta_equivalence ] ) .",
    "thus , the upper bound entropy rate @xmath147 can be readily determined by eq .  , it is the shannon entropy of the distribution of the arising position differences ( shifts ) in the stationary case .",
    "we numerically calculated the upper bound for 1d qw and the actual entropy rate of 1d cw - driven black boxes using the above protocol .",
    "we used the monte carlo method to simulate the behavior of the black boxes , repeating the protocol until @xmath36 appeared to converge .",
    "we found that @xmath36 corresponding to the 1d qw in all cases converges to @xmath148 where @xmath149 note that since @xmath150 is completely mixed in coin space , the effect of the initial @xmath151 is lost , which is expected for a markov chain .",
    "this result is in perfect agreement with our result given in the previous section : the system always forgets its initial state .",
    "we found that for waiting times @xmath152 the upper bound rate of qws with an unbiased coin coincides with the entropy rate of cws , which can be viewed as classical correspondence in the strongly decohered limit .",
    "however , for the @xmath153 regime the upper bound surpasses the cw entropy rate , which is a direct consequence of the ballistic spreading .    to showcase the possible effects appearing on finite systems , we also performed simulations on finite @xmath20-cycles ( 1d cycle graphs with @xmath20 vertices ) . increasing @xmath21 beyond @xmath154 in",
    "such a system causes an interesting effect : the cw starts to evolve towards the uniform distribution . as a consequence ,",
    "the entropy rate becomes close to its absolute bound @xmath155 defined in eq .",
    "( [ entropy_limit ] ) .",
    "in contrast to that , qws do not mix due to the unitary nature of the system . consequently , the self - overlap of the wave function might induce fluctuations in the entropy rate . in this self - overlapping regime the entropy production of cws are usually higher .",
    "of periodically measured walks as the function of waiting time @xmath21 .",
    "we used qw ( triangles ) with hadamard coin ( see eq .",
    "( [ coin_hadamard ] ) ) and the unbiased cw ( circles ) on the cycle graph with 16 vertices . for the qws we plotted the protocol giving the upper bound .",
    "the straight line corresponds to the theoretical entropy rate limit of eq .",
    "( [ entropy_limit ] ) : @xmath156 bits . in the inset plot",
    ", we show traces of the collapse and revive like effects on the same system for high @xmath21 waiting times : for @xmath157 the time evolution operator comes very close to a simple permutation matrix , resulting in a very predictable behavior and an entropy rate upper bound @xmath158 bits . meanwhile , the cw is totally mixing , resulting in an unpredictable outcome , with the maximal possible entropy rate @xmath159 bits .",
    "we calculated all plotted data numerically using the monte carlo method until convergence occurred .",
    ", scaledwidth=47.5% ]    increasing the @xmath21 waiting time even further , the unitary nature of qws eventually produces more interesting effects in finite systems : a behavior similar to collapses and revivals @xcite can be observed in the upper bound of entropy rate as a function of @xmath21 and in the entropy rate itself .",
    "the appearance of these phenomena demonstrates the fundamental difference between the unitary and stochastic time evolutions in a black box .",
    "we illustrate these results in fig .",
    "[ figure3 ] .    the observation in eq .",
    "( [ completelymixing ] ) allows us to approximate the scaling of the entropy rate . for the approximation we use the weak limit theory of quantum",
    "walks @xcite . for high number of steps ( high",
    "@xmath21 s ) the symmetric probability distribution of a 1d hadamard qw can be approximated with the formula @xmath160 to be evaluated for @xmath161 $ ] .",
    "note that this distribution corresponds to the walk started from the initial state localized at the origin , with a totally mixed initial coin state @xmath162 of eq .",
    "( [ rhotilde0 ] ) , thus @xmath163 employing ( [ delta_erate ] ) the upper bound of the entropy rate can be readily approximated by the integral @xmath164 which evaluates to @xmath165 with high numerical precision .",
    "it is apparent that the scaling of the upper bound of entropy rate goes with @xmath166 , in contrast with the scaling of the classical system ( cf .",
    "( [ entropy_classical ] ) ) , which goes with @xmath167 .",
    "this result can be interpreted as the consequence of the ballistic spreading of the qw",
    ". our numerical test showed , that although the weak limit theorem predicts the @xmath166 scaling , the scaling of the upper bound rate is for low waiting times are still close to @xmath167 .",
    "even for the regime around @xmath168 , we obtained scaling with @xmath169 .",
    "however , the scaling of the upper bound of the entropy rate for higher waiting times should converge to @xmath166 .",
    "we illustrate these results in fig .",
    "[ figure4 ] .     of an 1d qw with hadamard coin",
    "( [ coin_hadamard ] ) ) , denoted by circles , for infinite or finite ( @xmath170 ) systems .",
    "we used high precision numerical simulations , and plotted the converged results .",
    "the dashed line corresponds to the analytically calculated entropy rate of cws ( see eq .",
    "( [ entropy_classical ] ) ) , while the continuous line corresponds to the weak - limit - based approximation of eq .",
    "( [ erate_mixed_coin_approx ] ) . , scaledwidth=47.5% ]",
    "let us discuss the scaling of the exact entropy rate @xmath137 . using the weak limit approach calculating integrals similar to ( [ approx_integral ] )",
    "reveal the scaling for other initial states , i. e. , the initial states giving the maximum and minimum entropy production @xmath171 and @xmath172 of ( [ maxentr ] ) and ( [ minentr ] ) .",
    "in both cases the scaling is proportional to @xmath166 , thus the precisely calculated @xmath137 entropy rate is also scales with @xmath166 for high @xmath21 values .    in summary",
    ", the proposed protocol gives a straightforward way to measure , calculate , and approximate the upper bound of entropy rates of qw driven message sources .",
    "since , the exact entropy rate can be quite hard to calculate , the easy - to - calculate and -measure upper bound is a proper tool for distinguishing walks with high waiting times @xmath21 living in a black box by their entropy production .",
    "we summarize the results given by all proposed methods in fig .",
    "[ figure2 ] .",
    "when we gave the definition of the walker living in the black box , we explicitly stated that all measurements are performed on the same system .",
    "however , for the case of qws the frequent measurements mean loss of coherence , thus a step towards the classical world .",
    "one can easily create the  most quantum \" case , when at every iteration step the measurement is performed on a new , yet undisturbed system .",
    "thus , in the first iteration step we perform a position measurement on a qw which took @xmath21 undisturbed steps , and then we discard the system . in the second iteration step ,",
    "we perform a position measurement on another qw which took @xmath173 undisturbed steps , and then we discard the system .",
    "all further steps are performed accordingly .",
    "thus , the @xmath1 sequence of stochastic variables is given by @xmath174 where @xmath175 is the position measurement projector given in ( [ position_projector ] ) and @xmath72 is the initial coin state of the qw .",
    "since at every iteration step we perform measurement on a so - far undisturbed system , this is the `` most quantum '' case .",
    "however , this process erases all memory effects , and all correlations between subsequent measurements , thus all @xmath1 s are independent random variables .",
    "consequently , the entropy rate of such system is simply given by @xmath176 let us use our result about the scaling of the shannon entropy of @xmath172 given in sec .",
    "[ precapproachsection ] .",
    "the scaling of @xmath177 is @xmath178 for 1d qws in the infinite line .",
    "employing this , the entropy rate of the system is @xmath179 this is a straightforward consequence of the spreading of the system on an infinite line .",
    "one can easily see that the entropy rate of both classical and quantum walks on infinite systems diverge to infinity , when we consider independent systems at each iteration steps .",
    "however , one can address a question about the entropy rates on finite systems .",
    "for the classical case on finite cycles with odd number of edges , the entropy rate is given by eq .",
    "( [ entropy_limit ] ) due to the mixing behavior of the system .",
    "however , since in the quantum case the system is unitary , mixing does not occur but collapses and revivals might appear as discussed in sec .",
    "[ naivesection ] .",
    "consequently , the entropy rate of independent unitary qws does not exist due to the lack of convergence .",
    "similarly , for 1d cws on cycles with even number of sites , due to the oscillation of the shannon entropy limit given in eq .",
    "( [ entropy_limit ] ) , the entropy rate does not exist .",
    "summarizing the results , for the case of the independent systems  which is the most quantum scenario  the entropy rate is not a suitable tool for describing the asymptotic information generation of the considered systems .",
    "entropy rate is an important quantity in classical information theory which has a sound operational meaning : it is the asymptotic limit of the lossless compression of the output of a discrete - time stochastic process",
    ". there can be many protocols in which some kind of dynamical system produces a sequence of characters as output according to some protocol , thereby realizing a classical stochastic process .",
    "here we have studied an example and asked the question of whether the entropy rate of a so - arising classical process captures some features of the underlying dynamics ( influenced , however , by the protocol ) .",
    "the studied case involves a quantum walk , which is compared to one of its classical limits .",
    "we have found that in this case the behavior of the entropy rate of the generated classical stochastic process indeed differs for classical and quantum walks and reflects some features of the underlying dynamics .",
    "although the classical definition of the entropy rate is extended to quantum walks , the rich behavior of the quantum world is still apparent .",
    "we note that all results of the paper are given for 1d walks , but the developed methods are more powerful and could be applied for more general systems .",
    "we have given two approaches to calculate the entropy rates of such processes .",
    "first , we described an elaborate method to determine the exact entropy rates of 1d qws .",
    "it turns out that in this case the internal coin state  which is not effected by the position measurements  serves as a memory , which allows us to develop a more sophisticated coding , thus achieving a lower entropy rate . in the case of frequent measurements",
    "the exactly calculated entropy rate can be lower than the rate of classical walks , due to the predictability provided by the coin state .",
    "second , we gave an easy - to - measure and -calculate upper bound protocol that describes the entropy production of 1d qws when the observer is neglecting the quantum coin as the memory of the walk .",
    "in both cases the scaling of the entropy rate tends to @xmath166 for high @xmath21 s in contrast with the @xmath167 scaling of the classical walks , which is due to the ballistic spread of the quantum model . in both the exact and the upper bound calculation we found that the entropy rate is independent of the initial state of the 1d qw",
    " this is a particularly important result .",
    "both approaches can be employed to test thequantumness \" of the frequently measured 1d walk residing in a black box ; for low waiting times ( @xmath21 s ) the exact entropy rate is easy to determine , thus it is easy to distinguish between the classical and quantum models .",
    "for @xmath180 the @xmath166 scaling of the rate corresponding to 1d qws can be used as the indicator of quantumness . in this regime",
    "even the easy - to - calculate upper bound measurement protocol should be enough to distinguish between the classical and quantum walks .",
    "we also investigated themost quantum \" scenario , when each von neumann measurement is performed on a new , undisturbed system , thus , the system does not have memory . however , in this case the entropy rate is not a suitable tool for describing per symbol information generation due to the spreading nature of the system . even on finite systems qws show no convergence due to the lack of mixing .    the fact ,",
    "however , that the frequently measured 1d qw has a definite entropy rate and can be described with a generalized stochastic matrix also provides that the system which we have studied here can be simulated with a well - designed classical walk , at least from the point of view of the information content of the resulting classical stochastic process .",
    "the question arises , and remains open for the time being , if one can find dynamics and a protocol in which the behavior or the mere existence of the classical entropy rate reflects some fundamental nonclassicality .",
    "we thank a. b. frigyik for helpful discussions .",
    "we acknowledge support by the hungarian scientific research fund ( otka ) under contract no .",
    "k83858 and the hungarian academy of sciences ( lendlet program , lp2011 - 016 ) .",
    "b. k. acknowledges support by the european union and the state of hungary , co financed by the european social fund in the framework of tmop 4.2.4 .",
    "a/2 - 11 - 1 - 2012 - 0001  national excellence program \" ( nemzeti kivlsg program ) .",
    "m. k. acknowledges the support of the grant srop-4.2.2/b-10/1 - 2010 - 0029  supporting scientific training of talented youth at the university of pcs \" .",
    "we show our calculation scheme for the entropy rate of qw driven  black boxed \" stochastic process @xmath1 ( eq . ( [ eq : entrate ] ) ) , using the simplest nontrivial example of the 1d hadamard walk , driven by the coin ( [ coin_hadamard ] ) .",
    "let us stick to the simplest case , when we initialized the walk in the coin state @xmath181 at the origin , thus @xmath182 and @xmath111 .",
    "we apply @xmath183 on @xmath184 , resulting in the following quantum state : @xmath185 this yields some elements of @xmath95 ( see eq .",
    "( [ coinstochmatrix ] ) ): @xmath186 we repeat this process again for the newly obtained coin states @xmath100 and @xmath187 , thus we apply @xmath183 again , and we calculate new elements of the transition matrix @xmath95 as follows : @xmath188 note that in the second step of constructing the matrix , only a single new coin state @xmath189 appeared .",
    "thus , we apply again @xmath183 on this new state to obtain the following : @xmath190 we arrived to a complete coin state circle as no new coin states appeared , thus the @xmath95 transition matrix is complete . in the abstract coin state basis of @xmath191",
    "it takes the form @xmath192 @xmath90 is found readily as the left eigenvector of @xmath193 corresponding to eigenvalue @xmath194 .",
    "expanded in the same basis as the transition matrix , it takes the form of @xmath195 the single step missing is the calculation of the shannon entropies @xmath196 , which can be done in a straightforward manner , resulting in the following : @xmath197 finally , employing eq .",
    "( [ erate_qw_final ] ) , the entropy rate is @xmath198    in this particular example we restricted ourselves to initial state @xmath181 .",
    "one can repeat the process for a general initial coin state @xmath199 with @xmath200 . after a more involving but still straightforward calculation it turns out that the size of @xmath95 is still finite in this case , and the entropy rate is @xmath201 bits independently from the initial coin state .",
    "moreover , this result holds true even for any mixed initial coin states .",
    "we repeat the calculation of entropy rate for @xmath111 from initial coin state @xmath202 to demonstrate the refined method using property ( [ lrentropyequiv ] ) .",
    "we write the transitions corresponding to the abstract @xmath107 coin state @xmath203 investigating @xmath204 leads to @xmath205 and , hence , we obtain the transition matrix @xmath206 in the basis of @xmath107 and @xmath207 .",
    "the asymptotic coin distribution @xmath90 turns out to be @xmath208 . according to eq .",
    "( [ lrentropyequiv ] ) , the shannon entropy of @xmath107 reads @xmath209 thus , by employing eq .",
    "( [ erate_qw_final ] ) , we obtain @xmath210 again .",
    "in the following we demonstrate the approximative method for determining @xmath90 for the case of @xmath111 and @xmath211 .",
    "( even though for @xmath111 the approximation is not necessary , it is comparable with our previous consideration and it is easier to follow than the @xmath212 cases . ) we restrict ourselves to the calculation of the exact mapping only for the initial state , thus @xmath203 since we do not wish to calculate further , using eq .  ( [ maptolr ] )",
    "we get the following map @xmath213 where we used",
    " @xmath120 \" to mark the set of unknown coin states @xmath214 which we do not wish to determine ( see eq .",
    "( [ qmarkdef ] ) ) .",
    "to build a proper stochastic matrix we need an additional set of rules for the state  @xmath120 \" , which , using eq .",
    "( [ maptolr ] ) , are @xmath215 thus , the transition matrix on the basis of @xmath107 and @xmath216 is @xmath217 the corresponding asymptotic coin distribution is @xmath218 . using eq .",
    "( [ erate_qw_final_bounded ] ) we finish our calculation , in this particular case @xmath219 bits and @xmath220 bit .",
    "the exact entropy rate is in the interval @xmath221    we move to the case of @xmath133 . for convenience ,",
    "we use @xmath222 as the initial state .",
    "we apply @xmath223 on @xmath224 resulting in the following : @xmath225 thus , we have transitions @xmath226 continuing with the new , yet undiscovered coin state , we obtain @xmath227 we end our calculation here and introduce the unknown coin state  @xmath120 \" once again . using eq .",
    "( [ maptolr ] ) we complete the transition matrix , arriving at @xmath228 which is written with respect to the basis @xmath229 . from here , @xmath90 , @xmath230 can be determined readily . with the use of eq .",
    "( [ erate_qw_final_bounded ] ) , the entropy rate for the 1d hadamard qw is in the interval @xmath231    if we iterate the above procedure further , the interval ( uncertainty ) shrinks , i. e. , the precision of the entropy rate increases . for @xmath232 iterations the entropy rate of the 1d hadamard qws with @xmath133",
    "is @xmath134    34ifxundefined [ 1 ] ifx#1 ifnum [ 1 ] # 1firstoftwo secondoftwo ifx [ 1 ] # 1firstoftwo secondoftwo `` `` # 1''''@noop [ 0]secondoftwosanitize@url [ 0 ] ",
    "+ 12$12  & 12#1212_12%12@startlink[1]@endlink[0]@bib@innerbibempty http://books.google.hu/books?id=0quawymc2pic[__ ]  ( ,  ) @noop _ _  ( ,  ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) link:\\doibase 10.1103/physreva.48.1687 [ * * , ( ) ] @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) http://stacks.iop.org/1751-8121/46/i=37/a=375305 [ * * ,   ( ) ] @noop * * ,   ( ) @noop * * ,   ( ) link:\\doibase 10.1103/physrevb.88.121406 [ * * , ( ) ] link:\\doibase    10.1103/physrevx.3.031005 [ * * ,   ( ) ] @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) link:\\doibase    10.1103/physreva.81.062129 [ * * ,   ( ) ] @noop * * ,   ( ) @noop * * ,   ( )"
  ],
  "abstract_text": [
    "<S> the amount of information generated by a discrete time stochastic processes in a single step can be quantified by the entropy rate . </S>",
    "<S> we investigate the differences between two discrete time walk models , the discrete time quantum walk and the classical random walk in terms of entropy rate . </S>",
    "<S> we develop analytical methods to calculate and approximate it . </S>",
    "<S> this allows us to draw conclusions about the differences between classical stochastic and quantum processes in terms of the classical information theory . </S>"
  ]
}