{
  "article_text": [
    "traditionally , learning classifier systems ( lcs ) @xcite use a ternary encoding to generalize over the environmental inputs and to associate appropriate actions .",
    "a number of representations have previously been presented beyond this scheme however , including real numbers @xcite , lisp s - expressions @xcite , fuzzy logic @xcite and neural networks @xcite . to date , no temporally dynamic representation schemes have been used in lcs , a potentially important approach since temporal behaviour of such kinds is viewed as a significant aspect of cognition in general .    in this paper",
    "we explore the use of a dynamical system representation within xcs @xcite  what is herein termed `` dynamical genetic programming '' ( dgp ) .",
    "traditional tree - based genetic programming ( gp ) @xcite has been used within lcs both to calculate the action @xcite and to represent the condition @xcite .",
    "dgp uses a graph - based representation , each node of which is constantly updated with asynchronous parallelism , and evolved using an open - ended , self - adaptive scheme . in the discrete case ,",
    "each node is a boolean function and therefore equivalent to a form of random boolean network ( rbn ) ( e.g. , @xcite ) .",
    "we show that xcs is able to solve a number of well - known immediate and delayed reward tasks using this temporally dynamic knowledge representation scheme .",
    "a number of representations have been presented by which to enable the evolution of computer programs , the most common being tree - based lisp s - expressions @xcite .",
    "other forms of gp include the use of machine code instructions ( e.g. , @xcite ) and finite state machines ( e.g. , @xcite ) .",
    "most relevant to the form of gp used in this paper is the small amount of prior work on graph - based representations .",
    "teller and veloso s [ 30 ] `` neural programming '' uses a directed graph of connected nodes , each with functionality defined in the standard gp way , with recursive connections included . significantly , each node is executed with synchronous parallelism for some number of cycles before an output node s value is taken .",
    "poli ( e.g. , @xcite ) presented a very similar scheme wherein the graph is placed over a two - dimensional grid and executes its nodes synchronously in parallel .",
    "other examples of graph - based gp typically contain sequentially updating nodes ( e.g. , @xcite ) .",
    "schmidt and lipson @xcite have recently demonstrated a number of benefits from graph encodings over traditional trees , such as reduced bloat and increased computational efficiency .    as noted above , tree - based s - expressions",
    "have been used within lcs . recently",
    ", wilson @xcite has explored the use of a form of gene expression programming ( gep ) @xcite within lcs . here",
    "the rules are represented as expression trees which are evaluated by assigning the environmental inputs to the tree s terminals , evaluating the tree , and then comparing the result with a predetermined threshold . whenever the threshold value is exceeded",
    ", the rule is added to the match set .",
    "the most common form of discrete dynamical system is the cellular automaton ( ca ) @xcite which consists of an array of cells ( lattice of nodes ) where the cells exist in states from a finite set and update their states with synchronous parallelism in discrete time .",
    "traditionally , each cell calculates its next state depending upon its current state and the states of its closest neighbours .",
    "that is , cas may be seen as a graph with a ( typically ) restricted topology .",
    "packard @xcite was the first to use evolutionary computing techniques to design cas such that they exhibit a given emergent global behaviour .",
    "following packard , mitchell et al .",
    "( e.g. , @xcite ) have investigated the use of a genetic algorithm ( ga ) @xcite to learn the rules of uniform binary cas . as in packard",
    "s work , the ga produces the entries in the update table used by each cell , candidate solutions being evaluated with regard to their degree of success for the given task .",
    "andre et al .",
    "@xcite repeated mitchell et al.s work whilst using traditional gp to evolve the update rules .",
    "they report similar results .",
    "sipper ( e.g. , @xcite ) presented a non - uniform , or heterogeneous , approach to evolving cas .",
    "each cell of a one- or two - dimensional ca is also viewed as a ga population member , mating only with its lattice neighbours and receiving an individual fitness .",
    "he shows an increase in performance over mitchell et al.s work by exploiting the potential for spatial heterogeneity in the tasks .",
    "sipper and ruppin @xcite extended this approach to enable heterogeneity in the node connectivity , along with the node function ; they evolved a form of random boolean networks .",
    "the discrete dynamical systems known as random boolean networks ( rbn ) were originally introduced by kauffman ( see @xcite ) to explore aspects of biological genetic regulatory networks . since then they have been used as a tool in a wide range of areas , such as self - organisation ( e.g. , @xcite ) and computation ( e.g. , @xcite ) .",
    "an rbn typically consists of a network of @xmath0 nodes , each performing a boolean function with @xmath1 inputs from other nodes in the network , all updating synchronously ( see figure  [ fig : examplerbn ] ) . as such",
    ", rbn may be viewed as a generalisation of binary cellular automata ( ca ) @xcite and unorganized machines @xcite .",
    "since they have a finite number of possible states ( @xmath2 ) and they use deterministic boolean functions , the dynamics of rbn eventually fall into a basin of attraction .",
    "it is well - established that the value of @xmath1 affects the emergent behaviour of rbn wherein attractors typically contain an increasing number of states with increasing @xmath1 .",
    "three phases of behaviour are suggested : ordered when @xmath3 , with attractors consisting of one or a few states ; chaotic when @xmath4 , with a very large number of states per attractor ; and , a critical regime around @xmath5 , where similar states lie on trajectories that tend to neither diverge nor converge and 515% of nodes change state per attractor cycle ( see @xcite for discussions of this critical regime , e.g. , with respect to perturbations ) .",
    "analytical methods have been presented by which to determine the typical time taken to reach a basin of attraction and the number of states within such basins for a given degree of connectivity @xmath1 ( see @xcite ) .",
    "closely akin to the work described here , kauffman @xcite describes the use of simulated evolution to design rbn which must play a ( mis)matching game wherein mutation is used to change connectivity , the boolean functions , @xmath1 and @xmath0 .",
    "he reports the typical emergence of high fitness solutions with @xmath1=2 to 3 , together with an increase in @xmath0 over the initialised size .    as noted above , traditional rbn consist of @xmath0 nodes updating synchronously in discrete time steps , but asynchronous versions",
    "have also been presented , after @xcite , leading to a classification of the space of possible forms of rbn @xcite .",
    "asynchronous forms of ca have also been explored ( e.g. , @xcite ) wherein it is often suggested that asynchrony is a more realistic underlying assumption for many natural and artificial systems .",
    "asynchronous logic devices are known to have the potential to consume less power and dissipate less heat @xcite , which may be exploitable during efforts towards hardware implementations of such systems .",
    "asynchronous logic is also known to have the potential for improved fault tolerance , particularly through delay insensitive schemes ( e.g. , @xcite ) .",
    "this may also prove beneficial for hardware implementations .",
    "harvey and bossomaier @xcite showed that asynchronous rbn exhibit either point attractors , as seen in asynchronous cas , or `` loose '' attractors where `` the network passes indefinitely through a subset of its possible states '' [ ibid . ] ( as opposed to distinct cycles in the synchronous case ) .",
    "thus the use of asynchrony represents another feature of rbn with the potential to significantly alter their underlying dynamics thereby offering another mechanism by which to aid the simulated evolutionary design process for a given task .",
    "di paolo @xcite showed it is possible to evolve asynchronous rbn which exhibit rhythmic behaviour at equilibrium .",
    "asynchronous cas have also been evolved ( e.g. , @xcite ) .",
    "to use asynchronous rbn as the rules within xcs , the following scheme is adopted .",
    "each of an initial randomly created rule s nodes has @xmath1 randomly assigned connections , here @xmath6 .",
    "there are as many nodes @xmath0 as input fields @xmath7 for the given task and its outputs @xmath8 , plus one other , as will be described , i.e. , @xmath9 . the first connection of each input node is set to the corresponding locus of the input message .",
    "the other connections are assigned at random within the rbn as usual . in this way",
    ", the current input state is always considered along with the current state of the rbn itself per network update cycle by such nodes ( see figure  [ fig : ddgp - examplerule ] ) .",
    "nodes are initialised randomly each time the network is run to determine [ m ] , etc .",
    "the population is initially empty and covering is applied to generate rules as in the standard xcs approach .",
    "l l l +   +   + & truth table : & connections : + node 0 ( m ) : & 10011000100000001110011010101000 & 7 , 4 , 0 , 3 , 1 + node 1 ( out ) : & 10 & 3 + node 2 ( i ) : & 00011111 & _ input1 _ , 2 , 5 + node 3 ( i ) : & 0001 & _ input2 _ , 2 + node 4 ( i ) : & 11101110 & _ input3 _ , 6 , 3 + node 5 ( i ) : & 0110110100001010 & _",
    "input4 _ , 2 , 7 , 6 + node 6 ( i ) : & 0001011101010101 & _",
    "5 , 2 , 3 + node 7 ( i ) : & 0100 & _ input6 _ , 3 + node 8 ( n ) : & 00010111 & 3 , 1 , 5 +    matching consists of executing each rule for @xmath10 cycles based on the current input .",
    "the value of @xmath10 is chosen to be a value typically within the basin of attraction of the rbn .",
    "asynchrony is here implemented as a randomly chosen node being updated on a given cycle , with as many updates per overall network update cycle as there are nodes in the network before an equivalent cycle to one in the synchronous case is said to have occurred .",
    "see @xcite for alternative schemes .",
    "in this study , when well - known boolean problems are explored there are only two possible actions and thus only one output node is required . where well - known maze problems are explored there are eight possible actions and accordingly three required output nodes . an extra `` matching '' node",
    "is also required to enable rbns to ( potentially ) only match specific sets of inputs . if a given rbn has a logical ` 0 ' on the match node , regardless of its output node s state , the rule does not join [ m ] ( see figure  [ fig : ddgp - examplerule ] ) .",
    "this scheme has also been exploited within neural lcs @xcite .",
    "a ` windowed approach ' is utilised where the output is decided by the most common state over the last @xmath11 steps up to @xmath10 .",
    "for example , if the last few states on a node updating prior to cycle @xmath10 is 0101001 and @xmath12 , then the ending node s state would be ` 0 ' and not ` 1 ' . in this paper , @xmath11 is set to 3 .",
    "thereafter , match set and action set processing proceeds as standard in xcs ( the reader is referred to @xcite for an algorithmic description of xcs ) .    when covering is necessitated , a randomly constructed rbn is created and then executed for @xmath10 cycles to determine the status of the match and output nodes",
    ". this procedure is repeated until an rbn is created that matches the environment state .",
    "parameter self - adaptation was first explored in lcs by bull et al .",
    "@xcite wherein the mutation rate is a locally evolving entity in itself ; each rule has its own mutation rate @xmath13 mutation only is used here and applied to the node s truth table and connectivity map at rate @xmath13 .",
    "a node s truth table is represented by a binary string and its connectivity by a list of @xmath1 integers in the range @xmath14 $ ] .",
    "since each node has a given fixed @xmath1 value , each node maintains a binary string of length @xmath15 which forms the entries in the look - up table for each of the possible @xmath15 input states of that node , i.e. , as in the aforementioned work of @xcite on evolving cas , for example .",
    "these strings are subjected to mutation on reproduction at the self - adapting rate @xmath13 for that rule .",
    "hence , within the rbn representation , evolution can define different boolean functions for each node within a given network rule , along with its connectivity map .",
    "specifically , each rule has its own mutation rate stored as a real number and initially seeded uniform randomly in the range @xmath16 $ ] .",
    "this parameter is passed to its offspring .",
    "the offspring then applies its mutation rate to itself using a gaussian distribution , i.e. , @xmath17 , before mutating the rest of the rule at the resulting rate .    due to the need for a possible different number of nodes within the rules for a given task , the dgp scheme is also of variable length . once the truth table and connections have been mutated , a new randomly connected node is either added or the last added node is removed with the same probability @xmath13 .",
    "the latter case only occurs if the network currently consists of more than the initial number of nodes .",
    "thus dgp is temporally dynamic both in the search process and the representation scheme .",
    "evolving variable - length solutions via mutation only has previously been explored a number of times , e.g. , @xcite .",
    "traditional gp can be seen to primarily rely upon recombination to search the space of possible tree sizes , although the standard mutation operator effectively increases or decreases tree size also .    whenever an offspring classifier is created and no changes occur to its rbn when undergoing mutation , the parent s numerosity is increased and mutation rate set to the offspring s .",
    "we now apply this discrete version of dgp - xcs ( ddgp - xcs ) to the well - known multiplexer task .",
    "these boolean functions are defined for binary strings of length @xmath18 under which the @xmath19 bits index into the remaining @xmath20 bits , returning the value of the indexed bit . the correct classification to a randomly generated input results in a payoff of 1000 , otherwise 0 .",
    "figures  [ fig : ddgp - xcs-6mux - asynch][fig : ddgp - xcs-6mux - asynch - top ] show the performance of the constructed system on the 6-bit multiplexer problem updated asynchronously with @xmath21 , @xmath22 , @xmath23 , @xmath24 , @xmath25 , @xmath26 , @xmath12 , and @xmath27 ( 6 inputs , 1 output , 1 match node ) .",
    "after @xcite , performance from exploit trials only is recorded ( fraction of correct responses are shown ) , using a 50-point running average , averaged over ten runs .    from figure",
    "[ fig : ddgp - xcs-6mux - asynch ] it can be seen that a near optimal solution is learnt around 35,000 trials and optimality is observed around trial 58,000 .",
    "the parameter governing rbn mutation ( see figure  [ fig : ddgp - xcs-6mux - asynch ] ) declines rapidly until reaching a bottom around 40,000 trials , which is shortly after discovering an optimal solution .",
    "the number of ( non - unique ) rules initially grows rapidly , before declining to around 650 .",
    "furthermore , the average degree of connectivity @xmath1 decreases fractionally , whilst , on average , each network grows approximately one extra node ( see figure  [ fig : ddgp - xcs-6mux - asynch - top ] .",
    "this behaviour indicates that the evolutionary process is able to identify an appropriate typical topology with which to generate complex behaviour , i.e. , in this case a computation . for other tasks , other values of @xmath1 may prove beneficial ;",
    "high @xmath1 may be expected in random number generation , for example .",
    "it can be noted that a growth event under which a new node is added into an rbn is essentially neutral here since the new node receives inputs from the existing nodes ( or itself ) on addition but only provides inputs to other nodes after subsequent connectivity mutations . for comparative purposes , figure  [ fig : ddgp - xcs-6mux - synch ]",
    "shows the performance with the same parameters on the 6-bit multiplexer when updated synchronously .",
    "it is shown that the performance is very similar regardless of the updating scheme and that there is thus apparently very little overhead when updating asynchronously , with the possible benefits mentioned above .",
    "figure  [ fig : ddgp - examplerule ] provides an illustration of a rule generated whilst solving the 6-bit multiplexer problem when updated asynchronously .",
    "there is one new node in addition to the initial eight .",
    "the truth table shows to which state each node will transition , given each of the possible inputs .",
    "for example , the output node ( node 1 ) has a truth table of ` 10 ' which is synonymous with a not gate where if node 3 is in state ` 0 ' then the output node will be set to ` 1 ' , and if node 3 is in state ` 1 ' then the output node will be set to ` 0 ' .",
    "the truth table of node 3 is synonymous with an and gate , etc .",
    "the rule has a prediction of 1000.00 and an error of 0.0 , whilst having an experience of 822 , showing that this is a highly accurate rule .",
    "analysis of this rbn rule was undertaken by executing it for each of the sixty - four 6-bit inputs .",
    "each input was run twenty times with @xmath26 and @xmath12 .",
    "the results show that for the majority of environment states the network will return a false match node , preventing it from being added to [ m ] .",
    "however , the network is general as the match node will always return true when the environment states are 110000 , 110010 , 110100 , 110110 , 111000 , 111010 , 111100 , and 111110 . in all of those cases the output node always advocates action",
    "in addition , there are several environment states for which the match node will only sometimes return true . however , in all cases when the match node does permit the rule to be added to [ m ] , the action advocated will always be consistent .",
    "there are four such additional environment states ( 010000 , 010010 , 011000 , and 011010 ) for which the rule will match , albeit with a probability less than 50% .",
    "the rule in figure  [ fig : ddgp - examplerule ] was then re - run as before , however using a traditional synchronous updating scheme .",
    "the results of the match node and output nodes are extremely similar regardless of the updating mechanism .",
    "that is , xcs has evolved an rbn which is very robust to the random nature of the asynchronous updating , meaning it is accurate even for the relatively rare case of all nodes updating concurrently , i.e. , the synchronous case .",
    "in addition to the single - step multiplexer problems , ddgp - xcs is applied to versions of three well - known multi - step maze environments , woods1 ( see figure  [ fig : woods1 ] ) , maze4 ( see figure  [ fig : maze4 ] ) , and woods101 ( see figure  [ fig : woods101 ] ) .    each cell in the maze environments is encoded with two binary bits , where white space is represented as a ` * ' , obstacles as ` o ' , and food as ` f ' .",
    "furthermore , actions are encoded in binary as shown in figure  [ fig : maze - encoding ] .",
    "the task is simply to find the shortest path to the food ( f ) given a random start point .",
    "obstacles ( o ) represent cells which can not be occupied .",
    "a teletransportation mechanism is employed whereby a trial is reset if the agent has not reached the goal state within 50 discrete movements . in woods1",
    "the optimal number of steps to the food is 1.7 , in maze4 optimal is 3.5 steps , and in woods101 it is 2.9 .",
    "+    figures  [ fig : ddgp - xcs - woods1][fig : ddgp - xcs - woods1-topology ] show the performance of ddgp - xcs in the woods1 environment .",
    "the parameters used are identical to those applied in the aforementioned multiplexer experiments , except that @xmath28 ( 16 inputs , 3 outputs , 1 match node ) ( @xmath21 ) . as can be seen from figure  [ fig : ddgp - xcs - woods1 ] , optimality",
    "is observed around 2,500 trials .",
    "this roughly matches the performance of neural xcs using self - adaptive constructivism ( @xmath292,500 trials , @xmath30 ) @xcite and faster than xcs using messy conditions ( @xmath298,000 trials , @xmath21 ) @xcite , xcs using stack - based gp conditions ( @xmath2910,000 trials , @xmath31 ) @xcite , and xcs with lisp s - expression conditions ( @xmath295,000 trials , @xmath21 ) @xcite .",
    "figure  [ fig : ddgp - xcs - woods1-sizemut ] shows that there is an average of 745 ( non - unique ) rules evolved .",
    "in addition , figure  [ fig : ddgp - xcs - woods1-sizemut ] shows that the mutation rate declines rapidly by 2,800 trials , shortly after the optimal solution is learnt .",
    "figure  [ fig : ddgp - xcs - woods1-topology ] shows that on average the networks add one extra node ( from the original 20 ) and the average number of connections decreases slightly .",
    "+    figures  [ fig : ddgp - xcs - maze4-perf][fig : ddgp - xcs - maze4-topology ] present the performance of ddgp - xcs in the maze4 environment .",
    "the parameters used are identical to those in the woods1 environment , however a bigger population limit of @xmath30 is used , reflecting the larger search space .",
    "optimality is observed around trial 23,000 ( see figure  [ fig : ddgp - xcs - maze4-perf ] ) , which is again similar to the performance observed using a neural xcs with self - adaptive constructivism ( @xmath2923,000 trials , @xmath32 ) @xcite .",
    "the average number of rules evolved is around 1,800 ( see figure  [ fig : ddgp - xcs - maze4-sizemut ] ) .",
    "the average number of nodes in the networks also increases by almost one , and the average number of connections declines slightly from 3 ( see figure  [ fig : ddgp - xcs - maze4-topology ] ) .",
    "the parameter governing rbn mutation ( figure  [ fig : ddgp - xcs - maze4-sizemut ] ) declines rapidly after 4,000 trials , before finally stabilising after 15,000 trials .",
    "+    the woods101 maze is a non - markov environment containing two _ communicating aliasing states _ ,",
    "i.e. , two positions which border on the same non - aliasing state and are identically sensed , but require different optimal actions .",
    "thus , to solve this maze optimally , a form of memory must be utilised ( with at least two internal states ) .",
    "optimal performance has previously been achieved in woods101 through the addition of a memory register mechanism in xcs @xcite , a corporate xcs using rule - linkage @xcite , a neural lcs using recurrent links @xcite , and by a form of acs with explicit memory @xcite .",
    "furthermore , in a proof of concept experiment , the cyclical directed graph from neural programming has been shown capable of representing rules with memory to solve woods101 , however it was only found to do so twice in fifty experiments @xcite .",
    "the simplest form of short - term memory is a fixed - length buffer containing the @xmath33 most recent inputs ; a common extension is to then apply a kernel function to the buffer to enable non - uniform sampling of the past values , e.g. an exponential decay of older inputs @xcite .",
    "simple forms of memory are _ static _",
    ", i.e. , the memory parameters are fixed in advance and the memory state is thus a predetermined function of the input sequence . however , it is not clear that biological systems make use of such shift registers .",
    "registers require some interface with the environment which buffers the input so that it can be presented simultaneously .",
    "they impose a rigid limit on the duration of patterns , defining the longest possible pattern and requiring that all input vectors be of the same length .",
    "furthermore , such approaches struggle to distinguish relative temporal position from absolute temporal position @xcite .",
    "the hypothesis of inherent content - addressable memory existing within synchronous rbn due to different possible routes to a basin of attraction @xcite for the asynchronous case is here explored and extended by simply not resetting the node states on each step .",
    "a significant advantage of this approach is that each rule / network s short - term memory is variable - length and _ adaptive _ , i.e. , the networks can adjust the memory parameters , selecting within the limits of the capacity of the memory , what aspects of the input sequence are available for computing predictions @xcite .",
    "in addition , as open - ended evolution is used , the maximum size of the short - term memory is potentially also open - ended , increasing as the number of nodes within the network grows .    here , nodes are initialised at random for the initial random placing in the maze but thereafter they are not reset for each subsequent matching cycle .",
    "consequently , each network processes the environmental input and the final node states then become the starting point for the next processing cycle , whereupon the network receives the new environmental input and places the network on a trajectory toward a ( potentially ) different locally stable limit point . therefore , a network given the same environmental input ( i.e. , the agent s current maze perception ) but with different initial node states ( representing the agent s history through the maze ) may fall into a different basin of attraction ( advocating a different action ) . _",
    "thus the rules dynamics are ( potentially ) constantly affected by the inputs as the system executes .",
    "_    figures  [ fig : ddgp - xcs - woods101][fig : ddgp - xcs - woods101-topology ] show the performance in the woods101 environment where all parameters used are identical to those applied in the previous maze4 environment .",
    "as can be seen from figure  [ fig : ddgp - xcs - woods101 ] , ddgp - xcs , without node resets , is able to achieve optimal performance in woods101 after approximately 12,000 trials ( this is slower than xcs using an explicit 1-bit memory register ( @xmath297,000 trials , @xmath21 ) @xcite . figure  [ fig : ddgp - xcs - woods101-sizemut ] shows the mutation rate and macro - classifiers .",
    "figure  [ fig : ddgp - xcs - woods101-topology ] shows the average number of nodes and connections .",
    "optimal performance is unattainable however when the nodes are reset randomly between matching ( figure  [ fig : ddgp - xcs - woods101-reset ] ) , proving that the system is exploiting the potential for memory within asynchronous rbn here .",
    "the mechanism works within xcs because rules / rbn experience each input but need not match on each cycle .",
    "hence for the ambiguous states they remain accurate for the payoff received on providing the action but do so having processed the previous input in an appropriate way , _ potentially without matching_.     +",
    "in this paper a form of xcs has been presented with which to design asynchronous random boolean networks .",
    "it has been shown that xcs is able to design ensembles of rbn that collectively solve a computational task under a reinforcement learning scheme .",
    "in particular , it has been shown possible to exploit the inherent dynamics of the representation scheme to solve a non - markov maze , i.e. , without extra mechanisms .",
    "current research is exploring the possibilities of dgp as a general representation scheme by which to solve complex problems with lcs .",
    "balan , g.c . , luke , s. : a demonstration of neural programming applied to non - markovian problems . in : proceedings of the 6th annual conference on genetic and evolutionary computation .",
    "gecco 04 , acm ( 2004 )      bull , l. : on using constructivism in neural classifier systems . in : merelo , j.j . ,",
    "adamidis , p. , beyer , h.g .",
    "parallel problem solving from nature : ppsn vii , lecture notes in computer science , vol .",
    "2439 , pp .",
    "springer berlin / heidelberg ( 2002 )    bull , l. , hurst , j. , tomlinson , a. : self - adaptive mutation in classifier system controllers . in : meyer , j.a . ,",
    "berthoz , a. , floreano , d. , roitblat , h. , wilson , s.w .",
    "( eds . ) from animals to animats 6 , proceedings of the sixth international conference on simulation of adaptive behavior .",
    "460468 . mit press ( 2000 )    bull , l. , hurst , j. : a neural learning classifier system with self - adaptive constructivism . in : evolutionary computation , 2003 .",
    "the ieee congress on .",
    "vol .  2 , pp .",
    "991997 . ieee press ( december 2003 )    butz , m.v . ,",
    "wilson , s.w . : an algorithmic description of xcs . in : revised papers from the third international workshop on advances in learning classifier systems .",
    "iwlcs 00 , springer - verlag , london , uk ( 2001 )    di , j. , lala , p.k . : cellular array - based delay - insensitive asynchronous circuits design and test for nanocomputing systems .",
    "journal of electronic testing : theory and applications 23 , 175192 ( june 2007 )          fogel , l.j . ,",
    "owens , a.j . ,",
    "walsh , m.j . : artificial intelligence through a simulation of evolution . in : biophysics and cybernetic systems : proceedings of the 2nd cybernetic sciences symposium .",
    ". 131155 .",
    "spartan book co. , washington , d.c . , usa ( 1965 )            howard , g.d . , bull , l. , lanzi , p.l . : self - adaptive constructivism in neural xcs and xcsf . in : proceedings of the 10th annual conference on genetic and evolutionary computation .",
    ". 13891396 .",
    "gecco 08 , acm , new york , ny , usa ( 2008 )          lanzi , p.l . : extending the representations of classifier conditions part",
    "i : from binary to messy coding . in",
    ": proceedings of the genetic and evolutionary computation conference .",
    "gecco 99 , morgan kaufmann ( 1999 )      lanzi , p.l .",
    ", perrucci , a. : extending the representation of classifier conditions part ii : from messy coding to s - expressions . in : proceedings of the genetic and evolutionary computation conference .",
    "gecco 99 , morgan kaufmann ( 1999 )        miller , j.f . : an empirical study of the efficiency of learning boolean functions using a cartesian genetic programming approach . in : proceedings of the genetic and evolutionary computation conference .",
    ". 11351142 .",
    "gecco 99 , morgan kaufmann ( 1999 )      mozer , m.c . : neural net architectures for temporal sequence processing . in : weigend , a.s . ,",
    "gershenfeld , n.a .",
    "time series prediction : forecasting the future and understanding the past , pp .",
    "addison - wesley ( 1994 )      pujol , j.c.f . ,",
    "poli , r. : efficient evolution of asymmetric recurrent neural networks using a pdgp - inspired two - dimensional representation . in : proceedings of the first european workshop on genetic programming .",
    ". 130141 .",
    "springer - verlag , london , uk ( 1998 )    schmidt , m. , lipson , h. : comparison of tree and graph encodings as function of problem complexity . in : proceedings of the 9th annual conference on genetic and evolutionary computation .",
    ". 16741679 .",
    "gecco 07 , acm , new york , ny , usa ( 2007 )            valenzuela - rendn , m. : the fuzzy classifier system : a classifier system for continuously varying variables . in : proceedings of the fourth international conference on genetic algorithms .",
    ". 346353 .",
    "morgan kaufmann publishers inc .",
    ", san francisco , ca , usa ( 1991 )            wilson , s.w .",
    ": classifier conditions using gene expression programming . in : bacardit , j. , bernado - mansilla , e. , butz , m.v . , kovacs , t. , llora , x. , takadama , k. ( eds . ) learning classifier systems .",
    ". 206217 .",
    "springer - verlag , berlin , heidelberg ( 2008 )    wuensche , a. : basins of attraction in network dynamics : a conceptual framework for biomolecular networks . in : schlosser , g. , wagner , g.p .",
    "modularity in development and evolution , pp .",
    "chicago , university press ( 2004 )    zatuchna , z.v .",
    ", bagnall , a.j .",
    ": agentp classifier system : self - adjusting vs. gradual approach . in : evolutionary computation , 2005 .",
    "the 2005 ieee congress on .",
    "vol .  3 , pp .",
    "ieee press ( september 2005 )"
  ],
  "abstract_text": [
    "<S> a number of representation schemes have been presented for use within learning classifier systems , ranging from binary encodings to neural networks . </S>",
    "<S> this paper presents results from an investigation into using a discrete dynamical system representation within the xcs learning classifier system . </S>",
    "<S> in particular , asynchronous random boolean networks are used to represent the traditional condition - action production system rules . </S>",
    "<S> it is shown possible to use self - adaptive , open - ended evolution to design an ensemble of such discrete dynamical systems within xcs to solve a number of well - known test problems . </S>"
  ]
}