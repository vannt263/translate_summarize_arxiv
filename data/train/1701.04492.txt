{
  "article_text": [
    "the nonuniform discrete fourier transform ( nudft ) is an important task in computational mathematics that appears in signal processing  @xcite , the numerical solution of partial differential equations  @xcite , and in magnetic resonance imaging  @xcite .",
    "quasi - optimal algorithms for computing the nudft are referred to as nonuniform fast fourier transforms ( nuffts ) , and state - of - the - art nuffts are usually based on oversampling , discrete convolutions , and the fast fourier transform ( fft ) on an oversampled grid  @xcite . in this paper , we propose a nufft that is embarrassingly parallelizable .",
    "it is numerically stable without the need for oversampling , and costs @xmath3 ffts , where @xmath3 is a carefully selected integer .",
    "our central idea is to exploit a low rank observation ( see  ) .",
    "let @xmath4 be an integer and @xmath5 be an @xmath6 vector with complex entries .",
    "the one - dimensional nudft computes the vector @xmath7 , defined by the following sums : @xmath8 where @xmath9 $ ] are _ samples _ and @xmath10 $ ] are _",
    "frequencies_. since   involves @xmath1 sums with each sum containing @xmath1 terms , computing the vector @xmath11 naively costs @xmath12 operations .",
    "if the samples are equispaced , i.e. , @xmath13 , and the frequencies are integer , i.e. , @xmath14 , then the transform is fully uniform and   can be computed by the fft in @xmath15 operations by exploiting algebraic redundancies  @xcite .",
    "unfortunately , these algebraic redundancies are `` brittle ''  @xcite and the ideas behind the fft are not immediately useful when either the samples are nonequispaced or the frequencies are noninteger . to develop a nufft",
    ", one has to exploit a nonzero working precision of @xmath16 and make careful approximations .",
    "there are three types of nudfts  @xcite :    * nudft - i ( uniform samples and noninteger frequencies ) : in   the samples are equispaced , i.e. , @xmath13 , and the frequencies @xmath17 are noninteger .",
    "this corresponds to evaluating a generalized fourier series at equispaced points . in section  [ sec : nufft - i ] , we describe a quasi - optimal algorithm for computing the nudft - i referred to as a nufft - i . * nudft - ii ( nonuniform samples and integer frequencies ) : in   the frequencies are integers and the samples @xmath18 are nonequispaced points in @xmath19 $ ] .",
    "this nudft corresponds to evaluating a fourier series at nonequispaced points . in section  [ sec : typetwo ] , we describe an @xmath0 algorithm , referred to hereafter as the nufft - ii , for computing the nudft - ii with a working precision of  @xmath20 .",
    "note that this transform also goes by the acronym nfft  @xcite .",
    "* nudft - iii ( nonuniform samples and nonuniform frequencies ) : in   the samples @xmath18 are nonequispaced and the frequencies @xmath17 are noninteger .",
    "this is the fully nonuniform transform and corresponds to evaluating a generalized fourier series at nonequispaced points .",
    "the nudft - iii and its applications in image processing and the numerical solution of partial differential equations are discussed in  @xcite . in section  [ sec : nufft - iii ] , we derive an @xmath0 complexity algorithm for computing the nudft - iii by combining our nufft - i and nufft - ii . we refer to this as a nufft - iii  @xcite , but others use the acronym nnfft  @xcite .    initially , we focus on computing the nudft - ii .",
    "this is perhaps the easiest to think about as it corresponds to evaluating a fourier series at nonequispaced points .",
    "a convenient and compact way to write the nudft - ii in   is as a matrix - vector product : given fourier coefficients @xmath21 , compute values @xmath22 such that @xmath23 where @xmath24 are sample points .",
    "therefore , a nufft - ii is simply a quasi - optimal complexity algorithm for computing the matrix - vector product @xmath25 . in the fully uniform case",
    "when @xmath13 and @xmath14 , we use the notation @xmath26 for the dft matrix and note that the fft algorithm computes @xmath27 in @xmath15 operations  @xcite .",
    "our nufft - ii algorithm is based on the simple observation that if the samples are near - equispaced , then @xmath28 can be well - approximated by a low rank matrix .",
    "that is , for a small integer @xmath3 ( see table  [ tab : optimalk ] ) , we find that @xmath29 where ` @xmath30 ' denotes the hadamard division , i.e. , @xmath31 means that @xmath32 . with   in hand",
    ", we have @xmath33 where ` @xmath34 ' is the hadamard product , then @xmath35 . ] and @xmath36 is the diagonal matrix with the entries of @xmath37 on the diagonal .",
    "therefore , the nufft - ii can be computed in @xmath38 operations via @xmath3 diagonally - scaled ffts .",
    "the approximation in   is the main idea in this paper .",
    "all that remains is to select the integer @xmath3 and compute the vectors @xmath39 .",
    "the observation will lead to a nufft - ii algorithm that is quasi - optimal for any set of samples and frequencies ( see section  [ sec : typetwo ] ) and similar observations lead to our nufft - i and nufft - iii algorithms .",
    "the major computational cost of our nuffts is @xmath3 ffts that can be performed in parallel , where @xmath3 is an adaptively selected integer that depends on the working precision @xmath16 and the distribution of the samples and frequencies .",
    "this allows us to reduce the cost of our nuffts  by reducing @xmath3  when the working precision is loosened , the samples are near - equispaced , or the frequencies are close to being integers .",
    "in particular , if any of our nufft codes are given equispaced samples and integer frequencies , then @xmath40 , and our implementation reduces to a single fft . by always computing the nudft via @xmath3 ffts , we are able to leverage the efficient fftw library that has an implementation of the fft that adapts to individual computer architectures  @xcite .",
    "our algorithm relies on ffts that are of the same size as the original nufft and we automatically exploit the distribution of the samples and frequencies if they happen to be quasi - uniform for extra computational speed .",
    "there are many other nuffts in the literature based on various ideas such as discrete convolutions and oversampling  @xcite , min - max interpolation  @xcite , oversampling and interpolation  @xcite , and a taylor - based approach  @xcite .",
    "the taylor - based approach results in an easily implementable algorithm , which is avoided in practice because it is numerically unstable  ( * ? ? ?",
    "* ex .  3.10 ) .",
    "for the last two decades , discrete convolutions and oversampling have been preferred .",
    "the transforms that we develop here are convenient and simple while being numerically stable .",
    "we benchmark our algorithms against the julia implementation of the nfft software  @xcite to demonstrate that our proposed algorithm is competitive with existing state - of - the - art approaches .",
    "the paper is structured as follows . in section  [ sec : typetwo ] , we derive the nufft - ii algorithm by first assuming that the nonuniform samples are a perturbed equispaced grid ( see section  [ sec : typeii_perturbed ] ) before generalizing to any distribution of samples ( see section  [ sec : generalposition_typeii ] ) . in section  [ sec : typeone ] we extend the algorithm to derive a nufft - i , nufft - iii , and inverse transforms . in section  [ sec : twodimensional ] , we describe the two - dimensional analogue of our nufft - ii .",
    "in this section , we describe an @xmath41 algorithm to compute the nudft - ii of size @xmath1 ( see  ) with a working precision of @xmath16 .",
    "we begin by making the simplifying assumption that the samples @xmath24 are nearly equispaced before describing the general algorithm .",
    "suppose that the samples @xmath24 are distributed such that there exists a parameter @xmath42 satisfying @xmath43 this assumption guarantees that a closest equispaced point to @xmath44 is @xmath45 , which simplifies the description of our algorithm .",
    "using the fact that @xmath14 for @xmath46 and properties of the exponential function , we can factor the entries of @xmath47 as @xmath48 which shows that the @xmath49 entry of @xmath47 can be written as a complex number multiplied by the @xmath49 entry of the dft matrix .",
    "the expression in   gives us the following matrix decomposition : @xmath50 where ` @xmath34 ' is the hadamard product .",
    "the observation in   is equivalent to the matrix @xmath51 being well - approximated by a low rank matrix so that @xmath52 . since @xmath53 , we conclude that @xmath54 therefore , an approximation to @xmath25 can be computed in @xmath55 operations via the fft as each term in the sum in   involves diagonal matrices and the dft matrix . moreover , each matrix - vector product in the sum can be computed independently and the resulting vectors added together afterwards .    all that remains is to show that @xmath51 can in fact be well - approximated by a low rank matrix , or equivalently , that @xmath3 is relatively small , and to construct a low rank approximation @xmath56 for @xmath51 .",
    "we can not use the singular value decomposition for this , formed by taking the first @xmath3 singular vectors and values , leads to the best rank @xmath3 approximation to @xmath51 in the spectral norm  @xcite . ] because that costs @xmath57 operations and would dominate the algorithmic complexity of the nufft - ii .",
    "instead , we note that @xmath51 can be viewed as a matrix obtained by sampling @xmath58 at points in @xmath59\\times [ 0,2\\pi]$ ] and we construct a low rank approximation via an approximation of the function @xmath58 .      a natural way to construct a low rank approximation to @xmath51 is via taylor expansion by exploiting the fact that @xmath60 is relatively small for @xmath61 .",
    "the nufft developed here is equivalent to  @xcite ( without oversampling ) and is numerically unstable . in this direction , consider the taylor expansion of @xmath62 about @xmath63 . applying this taylor series to each entry of @xmath51",
    ", we find that for @xmath61 @xmath64 where the expansion is truncated after @xmath3 terms to deliver an approximation . now ,",
    "if we let @xmath65 , @xmath66 , and @xmath67 , then   can be applied to each entry of @xmath51 to find that @xmath68 here , the notation @xmath69 denotes a rank  1 matrix , @xmath70 is the matrix formed by applying the exponential function entry - by - entry to @xmath69 , and @xmath71 is the entry - by - entry @xmath72th power of @xmath69 .    since @xmath73 for @xmath61 , error estimates for the truncated taylor expansion of @xmath74 for @xmath75 $ ] shows that @xmath76 for @xmath77  @xcite , where @xmath78 is the absolute maximum matrix entry . to avoid overflow issues",
    ", one should take the vectors @xmath79 and @xmath80 for @xmath81 in  .",
    "unfortunately , we observe that the taylor - based approach is numerically unstable ( even with modest oversampling ) in agreement with the experiments in  ( * ? ? ?",
    "this is because for moderate @xmath3 ( @xmath82 ) the matrix @xmath56 is constructed by evaluating high - degree monomial powers .",
    "for this reason , the nufft - ii described in  @xcite is seldom used .",
    "we must construct the matrix @xmath56 in a different way .",
    "one can often stabilize high - degree taylor expansions by replacing them with chebyshev expansions .",
    "we do that now .    for an integer @xmath83 ,",
    "the chebyshev polynomial of degree @xmath84 is given by @xmath85 on @xmath86 $ ] and the set @xmath87 is an orthogonal basis for the space of polynomials of degree at most @xmath88 , with respect to the weight function @xmath89 on @xmath90 $ ] .",
    "we can use a chebyshev series to represent nonperiodic functions , in the same way that a fourier series can represent periodic functions  @xcite .    in the appendix in theorem  [ thm : lowrankapproximation ] , we derive a low rank approximation for @xmath51 by using chebyshev expansions .",
    "if @xmath91 , then @xmath51 is the matrix of all ones and the low rank approximation is trivial .",
    "if @xmath92 , then for @xmath2 we find an integer @xmath3 ( see  ) and a matrix @xmath56 such that @xmath93 , where @xmath78 denotes the absolute maximum matrix entry .",
    "the matrix @xmath56 is defined by ( see theorem  [ thm : lowrankapproximation ] ) @xmath94}_{=\\underline{u}_{r}}\\underbrace{t_{r}(\\tfrac{2\\underline{\\omega}^\\intercal}{n}-\\mathbf{1}^\\intercal)}_{\\tiny = \\begin{cases}\\underline{v}_r^\\intercal & r\\geq 1\\\\ 2\\underline{v}_0^\\intercal & r=0 \\end{cases } } , \\label{eq : chebyshevlowrank}\\ ] ] where @xmath95 is the @xmath6 vector of ones and the primes on the summands indicate that the first term is halved .",
    "the coefficients @xmath96 for @xmath97 are known explicitly as @xmath98 where @xmath99 is the bessel function of parameter @xmath100 at @xmath101  ( * ? ? ?",
    "10 ) . here in  ,",
    "@xmath102 and @xmath103 denote the exponential and chebyshev polynomial evaluated at each entry of @xmath104 to form another vector , respectively .",
    "the expansion in   provides us with a rank @xmath3 matrix that approximates @xmath51 as @xmath105 . from the convergence properties of chebyshev expansions , for each fixed @xmath3 , an explicit upper bound",
    "is known for @xmath106 ( see appendix  [ sec : appendix ] ) .",
    "the vectors @xmath39 in   are evaluated via computing the chebyshev polynomials using a three - term recurrence relation  ( * ? ? ?",
    "this requires a total of @xmath107 operations .",
    "this cost should strictly be included in the final complexity of the nufft - ii , but we will not include it because this is part of the `` planning stage '' ( see section  [ sec : algorithmicdetails ] ) .    in   for @xmath92 , the integer @xmath3 is given by the expression ( see theorem  [ thm : lowrankapproximation ] ) @xmath108 where @xmath109 is the lambert - w function  ( * ? ? ? * ( 4.13.1 ) ) , @xmath110 is the perturbation parameter from  , and @xmath111 is the nearest integer above or equal to @xmath112 . by asymptotic approximations of @xmath109 as @xmath113 , we find that @xmath114 as @xmath115  ( * ? ? ?",
    "* ( 4.13.10 ) ) and hence , @xmath25 can be computed in a total of @xmath0 operations using  .",
    "it is relatively common in practice to have perturbed equispaced samples so we always compute the parameter @xmath42 in   in order to select the smallest possible integer @xmath3 with @xmath76 . in our implementation of the nufft - ii",
    ", we do not use the formula for @xmath3 in   because it is only asymptotically sharp and the constants are not tight . instead ,",
    "in   we use the values of @xmath3 given in table  [ tab : optimalk ] , which are selected from empirical observations .",
    "in particular , in double precision we use at most @xmath116 , corresponding to the cost of a nufft - ii being approximately 16 ffts of size @xmath1 .",
    "ccccccc + & @xmath117 & @xmath118 & @xmath119 & @xmath120 & @xmath121 & @xmath122 +   + @xmath123 & @xmath124 & 8 & 9 & 11 & 13 & 16 + @xmath125 & @xmath124 & 5 & 6 & 7 & 8 & 10 + @xmath126 & @xmath124 & 3 & 3 & 4 & 5 & 7 +    in practice , it is also common to not always need a working precision of @xmath127 so we adaptively select the integer @xmath3 based on that parameter too .",
    "for example , with a working precision of @xmath128 the nufft - ii costs at most seven ffts of size @xmath1 .      suppose that the samples @xmath18 in   are arbitrarily distributed real numbers .",
    "the properties of the complex exponential , @xmath129 for @xmath46 , allow us to assume , without loss of generality , that the samples are in the interval @xmath130 ; otherwise , they can be translated to that interval using periodicity . for convenience , in this section",
    "we assume that @xmath131 , though our implementation does not have this restriction . in this general",
    "setting , the observation in   is no longer valid because the samples are arbitrarily distributed .    instead , define a sequence @xmath132 that takes values from @xmath133 and is defined so that @xmath134 is the closest node to @xmath44 from an equispaced grid of size @xmath135 ( ties can be broken arbitrarily ) . since each",
    "@xmath44 is a distance of at most @xmath136 from these equispaced nodes , we have @xmath137 figure  [ fig : generalnufft ] illustrates this process when @xmath138 .",
    "the sequence can be easily computed via the relationship @xmath139 , where @xmath140 returns the nearest integer to each entry of the vector @xmath141 .",
    "( 0,0)(8,0 ) ; ( 0,3)(8,3 ) ; ( 0,0 ) circle ( .5ex ) ; ( 1,0 ) circle ( .5ex ) ; ( 2,0 ) circle ( .5ex ) ; ( 3,0 ) circle ( .5ex ) ; ( 4,0 ) circle ( .5ex ) ; ( 5,0 ) circle ( .5ex ) ; ( 6,0 ) circle ( .5ex ) ; ( 7,0 ) circle ( .5ex ) ; ( 8,0 ) circle ( .5ex ) ; ( .23,3 ) circle ( .5ex ) ; ( .35,3 ) circle ( .5ex ) ; ( .55,3 ) circle ( .5ex ) ; ( 3.4,3 ) circle ( .5ex ) ; ( 4.6,3 ) circle ( .5ex ) ; ( 5.1,3 ) circle ( .5ex ) ; ( 6.3,3 ) circle ( .5ex ) ; ( 7.55,3 ) circle ( .5ex ) ; ( .23,2.8)(0,.2 ) ; ( .35,2.8)(0,.2 ) ; ( .55,2.8)(1,.2 ) ; ( 3.4,2.8)(3,.2 ) ; ( 4.6,2.8)(5,.2 ) ; ( 5.1,2.8)(5,.2 ) ; ( 6.3,2.8)(6,.2 ) ; ( 7.55,2.8)(8,.2 ) ; at ( 0,3.25 ) @xmath142 ; at ( .4,3.25 ) @xmath143 ; at ( .8,3.25 ) @xmath144 ; at ( 3.4,3.25 ) @xmath145 ; at ( 4.6,3.25 ) @xmath146 ; at ( 5.2,3.25 ) @xmath147 ; at ( 6.35,3.25 ) @xmath148 ; at ( 7.6,3.25 ) @xmath149 ; at ( 0,-.3 ) @xmath150 ; at ( 1,-.3 ) @xmath151 ; at ( 2,-.3 ) @xmath152 ; at ( 3,-.3 ) @xmath153 ; at ( 4,-.3 ) @xmath154 ; at ( 5,-.3 ) @xmath155 ; at ( 6,-.3 ) @xmath156 ; at ( 7,-.3 ) @xmath157 ; at ( 8,-.3 ) @xmath158 ;    if @xmath159 then we must reassign @xmath44 because the uniform dft does not contain a sample at @xmath160 . using the periodicity of the complex exponential , we use the identity @xmath161 to assign @xmath44 to the equispaced node at @xmath162 .",
    "this can be done simply by defining another sequence @xmath163 , which takes values from @xmath164 , and is given by @xmath165 in practice , one can easily compute the vector @xmath166 directly from @xmath104 since @xmath167 where @xmath168 is the modulo-@xmath1 operation on each entry of @xmath169 .    from the properties of the exponential function and the definition of @xmath163",
    ", we find that @xmath170 this means that the @xmath49 entry of @xmath47 can be expressed as a product of @xmath171 and the @xmath172 entry of @xmath173 for @xmath61 .",
    "equivalently , by setting @xmath174 for @xmath61 , we can write   as the following matrix decomposition : @xmath175 where @xmath176 . note that @xmath177 denotes the matrix formed by extracting the rows indexed by @xmath178 from the dft matrix .",
    "since @xmath179 $ ] and @xmath180 $ ] , we find that @xmath51 can be well - approximated by a low rank matrix using the same idea as in section  [ sec : chebyshevlowrank ] .",
    "this leads to the rank  @xmath3 approximation @xmath56 to @xmath51 , given by @xmath181}_{=\\underline{u}_{r}}\\underbrace{t_{r}(\\tfrac{2\\underline{\\omega}^\\intercal}{n}-\\mathbf{1}^\\intercal)}_{\\tiny = \\begin{cases}\\underline{v}_r^\\intercal & r\\geq 1\\\\ 2\\underline{v}_0^\\intercal & r=0 \\end{cases}},\\ ] ] where @xmath182 . here",
    ", @xmath76 for some @xmath2 and @xmath3 is the value in   with @xmath183 .    in summary , we find that the matrix - vector product , @xmath25 , can be approximately computed with a working accuracy of @xmath16 via the approximation @xmath184 this leads to an @xmath0 complexity nufft - ii because : ( 1 ) the matrix - vector products with the diagonal matrices @xmath185 and @xmath186 can be performed in @xmath187 operations , and ( 2 ) the matrix - vector product @xmath188 can be computed in @xmath15 operations via the fft and the relationship @xmath189 , where @xmath190 is the @xmath191 identity matrix and @xmath192 denotes the matrix obtained by extracting the @xmath178 rows of the identity matrix . again",
    ", each term in the sum in   can be computed in parallel and the resulting vectors added together afterwards .",
    "there are a handful of algorithmic details .",
    "* * oversampling : * in section  [ sec : generalposition_typeii ] , we assign @xmath1 samples @xmath24 to an equispaced grid of size @xmath1 .",
    "the process of oversampling , which occurs in many other nuffts , translates @xmath1 samples to an equispaced grid of size @xmath193 , where @xmath194 .",
    "in our setting , this results in ffts of size @xmath193 in   with potentially a smaller integer @xmath3 because @xmath195 . naively , since our algorithm is numerically stable without oversampling , it would seem that oversampling is never beneficial for us .",
    "for example , in double precision if @xmath196 , then @xmath197 ffts of size @xmath198 are required ( see table  [ tab : optimalk ] ) instead of @xmath199 ffts of size @xmath1 . in practice",
    ", it is a little more complicated as one may benefit from selecting an integer @xmath200 that has a convenient prime factorization for the fft  @xcite .",
    "we have not explored this possibility yet . * * vectorization : * one can vectorize the ffts in   by computing @xmath25 in two steps : @xmath201 where @xmath202 denotes the @xmath203th column of @xmath204 . in the programming language julia  @xcite",
    "this can be implemented in the one - liner : + ....        nufft2(c ) = ( u.*(fft(diagonal(c)*v,1)[t+1,:]))*ones(k ) , .... + where @xmath205 $ ] , @xmath206 $ ] , and the variable @xmath207 is the vector  @xmath166 . * * planning the transform : * most implementations of fast transforms these days have a _ planning stage _",
    "@xcite , where ancillary quantities are computed that do not depend on the entries of @xmath208 .",
    "this stage may also involve memory allocation and the finalization of recursion details  @xcite . for our nufft - ii ,",
    "the planning stage consists of computing @xmath209 , @xmath166 , and @xmath3 , planning the ffts  @xcite , as well as computing the vectors @xmath210 for the low rank approximation @xmath56 .",
    "these quantities and data structures are then stored in memory so that the nufft - ii is computationally faster .",
    "after the planning stage of our nufft - ii , there is an _ online stage _",
    ", where the transform is essentially the one - liner for the nufft2(c ) call above .",
    "it is particularly important to plan a nufft - ii when the matrix - vector product with @xmath47 is desired for many vectors .",
    "we have two different implementations of the transforms in this paper : ( 1 ) a matlab implementation , where the nufft - ii transform is assessable via the chebfun.nufft command in chebfun  @xcite , and ( 2 ) a julia implementation , which is publicly available via the nufft2 command in the fasttransforms.jl package  @xcite .",
    "since the dominating computational cost of our transforms are ffts , and these are computed via the fftw library  @xcite , the cost of our algorithms are approximately the same in matlab and julia .",
    "recall that there are two stages of the transform : ( 1 ) a planning stage in which ancillary quantities are computed ( see section  [ sec : algorithmicdetails ] ) and ( 2 ) an online stage , where the transform needs knowledge of the vector @xmath208 in   and the desired vector @xmath11 is computed .",
    "when the same nufft - ii transform is applied to multiple vectors , the planning stage is only performed once while the online stage is executed for every new vector .",
    "figure  [ fig : nufft_eps ] ( left ) shows the execution times of the nufft - ii transform in both the planning stage and the online stage the nufft - ii ( right ) .",
    "the online stage of the nufft - ii is approximately 16 ffts in double precision , as expected from table  [ tab : optimalk ] , and takes approximately 8 seconds to compute the transform when @xmath1 is 16 million .",
    "figure  [ fig : nufft_eps ] shows that our nufft - ii is competitive to the julia implementation of the nfft software  @xcite .",
    "planning ( 50,0 ) ( 3,15 ) ( 60,44 )    executiontimings ( 50,0 ) ( 3,15 ) ( 60,37 )    figure  [ fig : nufft_gamma ] ( left ) demonstrates the execution times of the online stage of our nufft - ii for samples that are perturbed equispaced grids with @xmath211 , @xmath212 , @xmath213 , and @xmath117 ( see  ) . for definitiveness",
    ", we chose the samples to be the so - called _ worst grid _ for each @xmath209 in the nufft - ii ( see  ( * ? ? ? * sec .",
    "3.3.1 ) ) , i.e. , @xmath214 we see that the nufft - ii is more computationally efficient when the samples are closer to an equispaced grid , as expected from the values of @xmath3 in table  [ tab : optimalk ] .",
    "our nufft - ii relies on a matrix approximation ; namely , the approximation of the matrix @xmath51 in   by a low rank approximation @xmath56 .",
    "therefore , if @xmath215 is the vector calculated from @xmath216 , then our algorithm calculates the approximation @xmath217 . the incurred error can be simply bounded as follows : @xmath218 where @xmath219 denotes the matrix frobenius norm and the last inequality follows from the fact that @xmath76 and @xmath220 . in figure  [ fig : nufft_gamma ] ( right )",
    "we observe that the relative error @xmath221 grows like @xmath222 , where the extra @xmath223 is probably due to the fact that a sum of @xmath1 gaussian random variable is of size @xmath223 .",
    "when we repeat the experiment with a random vector @xmath208 with @xmath224 decay , i.e. , c = randn(n)./(1:n).^2 in julia , the relative error @xmath221 grows like @xmath187 .",
    "more often than not , fourier coefficients do decay as the coefficients are derived from expanding a smooth periodic function .",
    "gammatimings ( 50,0 ) ( 3,15 ) ( 60,37 )    nufft_accuracy ( 50,0 ) ( 65,22 ) ( 0,8 )",
    "many other nonuniform discrete fourier transforms are related to the nudft - ii including : ( 1 ) the nudft - i , ( 2 ) nudft - iii , ( 3 ) inverse nudfts .",
    "we describe these transforms in this section .",
    "the nudft - i transform computes the vector @xmath11 , given the vector @xmath21 and frequencies @xmath225 $ ] , such that @xmath226 it is equivalent to evaluating a generalized fourier series at equispaced points and computing the matrix - vector product @xmath227 , where @xmath228 for @xmath61 .    for this transform",
    ", we immediately find that @xmath229 where the frequencies @xmath230 act as nonequispaced sampled in a nudft - ii .",
    "therefore , we see that the nudft - i matrix is equivalent to a transposed nudft - ii matrix .",
    "since the transpose of a sum of matrices is equal to the sum of the individual terms transposed ,   immediately leads to our nufft - i : @xmath231 therefore , @xmath227 , can be computed in @xmath0 operations using the relationship @xmath232 and the inverse fft .    for implementations of this transform ,",
    "see the chebfun.nufft command in chebfun  @xcite and the nufft1 command in fasttransforms.jl  @xcite .",
    "let @xmath233 be samples and @xmath234 be frequencies .",
    "suppose that we wish to compute the vector @xmath11 in  , given @xmath235 .",
    "this is equivalent to computing the matrix - vector product @xmath236 , where @xmath237 . from the properties of the exponential function , the sequence @xmath238 in  , and the sequence @xmath163 in  , we can write @xmath239 applying the product above to every entry of @xmath240 leads to the following matrix decomposition : @xmath241 where @xmath242 denotes the nudft - i matrix permuted by the sequence @xmath163 .    since @xmath243 for @xmath244 and @xmath245 for @xmath46 , we know from theorem  [ thm : lowrankapproximation ] that @xmath51 can be approximated by a rank @xmath3 matrix @xmath56 such that @xmath76 and @xmath114 , where @xmath16 is a working precision .",
    "moreover , the matrix @xmath246 is of rank at most @xmath247 since @xmath248 where @xmath95 is the @xmath6 column vector of ones .",
    "therefore , @xmath249 can be well - approximated by a rank @xmath250 matrix and hence , @xmath236 can be computed in @xmath251 operations .    in double precision , the cost of this nufft - iii is at most @xmath252 nufft - i s or , equivalently , @xmath253 ffts of size @xmath1 .",
    "these ffts can all still be performed in parallel . in the case",
    "when the sequences @xmath238 and @xmath163 are the same , which often occurs ( see  ) , the matrix @xmath246 is the matrix of all ones . in this situation , @xmath254 and the cost of the nufft - iii",
    "is reduced by a factor of @xmath247 .",
    "this transform is available in the chebfun.nufft command in chebfun  @xcite .      in the nufft - i , -ii , and -iii , severely nonequispaced samples or noninteger frequencies",
    "were not a numerical issue and the parameter @xmath209 in   only mildly affected the computational cost of the transform . for the inverse transforms , nonuniform samples or frequencies",
    "are far more detrimental in terms of both accuracy and computational cost .",
    "the inverse nudft - ii requires that the linear system @xmath255 is solved for the vector @xmath208 , where @xmath47 is given in  . here",
    ", we will assume that the samples @xmath24 are perturbed equispaced samples with @xmath256 ( see  ) to ensure that @xmath257 exists .",
    "since we have a fast matrix - vector product for @xmath47 ( see section  [ sec : typetwo ] ) , one naturally tries a variety of krylov methods . after trying several of them",
    ", we advocate the following approach based on the conjugate gradient method ( cg ) .",
    "the matrix @xmath47 is not a positive definite matrix , i.e. , it is not symmetric with positive eigenvalues , so the conjugate gradient method can not be immediately applied .",
    "instead , we use the conjugate gradient method on the normal equations : @xmath258 . by considering the @xmath49 entry of @xmath259",
    ", we find that it only depends on the value of @xmath260 : @xmath261 hence , @xmath259 is a toeplitz matrix , i.e. , a matrix with constant diagonal entries , as noted previously in  @xcite .",
    "therefore , a matrix - vector product with @xmath259 can be computed using a fast toeplitz multiply , costing just one fft and one inverse fft of size @xmath198  ( * ? ? ?",
    "are the same due to symmetry and the first column of @xmath259 can be obtained via the relation @xmath262 , where @xmath263 is the first canonical vector . ]",
    "let the number of conjugate gradient iterations be denoted by @xmath264 .",
    "since cg requires one matrix - vector product per iteration , the inverse transform costs the same as @xmath265 ffts of size @xmath198 , ignoring @xmath250 ffts to compute @xmath266 and the calculation of the eigenvalues of a circulant matrix ( see  ( * ? ? ?",
    "4.7.7 ) ) .",
    "therefore , this iterative method leads to an inverse nufft - ii with a computational cost of @xmath267 operations , which is quasi - optimal provided that @xmath264 does not grow too quickly with @xmath1 .",
    "figure  [ fig : r_cg ] shows that empirically @xmath264 is observed to be small and , perhaps , bounded with @xmath1 when @xmath268",
    ". remains bounded as @xmath269 with @xmath270 , but grows with @xmath1 when @xmath271 .",
    "] when the samples are uniformly sampled , @xmath272 and @xmath273 . as the perturbation parameter , @xmath209 ,",
    "is increased from @xmath162 to @xmath274 , the condition number of @xmath47  and hence @xmath264  can increase without bound .",
    "for example , when @xmath211 , the samples may not be distinct and so @xmath257 may not exist .",
    "numberofiterations ( 50,0 ) ( 3,11 )    to fully understand the algorithmic complexity of our inverse nufft - ii , we need to bound @xmath264 .",
    "one can do this immediately if a bound on the condition number of @xmath47 is known .",
    "the recent theoretical work on the lebesgue constant for trigonometric interpolation with nonequispaced points in  @xcite is potentially helpful for bounding the condition number of @xmath47 ; however , we have not been able to derive a bound in terms of @xmath209 on this yet .",
    "an analogous idea applies @xmath275 to derive an inverse nufft - i because @xmath276 and @xmath277 is a toeplitz matrix ( see , also ,  @xcite ) .",
    "the inverse transforms are implemented in the chebfun.inufft command in chebfun  @xcite and the inufft commands in fasttransforms.jl  @xcite .",
    "given an @xmath278 matrix of fourier coefficients @xmath279 and nonuniform samples @xmath280 , the two - dimensional nudft - ii is the task of computing the following vector : @xmath281 naively , this requires @xmath282 operations since there are @xmath1 sums with each sum contain @xmath283 terms . here",
    ", we describe an algorithm that requires only @xmath284 operations .",
    "it is helpful to start by reviewing the uniform two - dimensional fft , which computes the vector @xmath285 ( by default @xmath286 ) such that @xmath287 the samples in   lie on the @xmath278 equispaced tensor grid @xmath288 for @xmath289 and @xmath290 . in the julia language ,",
    "the vector @xmath11 in   can be computed by the command fft(c ) in @xmath291 operations .    as in section",
    "[ sec : generalposition_typeii ] , we first define a sequence @xmath292 such that @xmath293 is the closest point from an @xmath278 equispaced grid to @xmath294 for @xmath244 . by definition",
    ", we have @xmath295 figure  [ fig : assignment ] illustrates this process when @xmath296 .",
    "( 0,0)(5,0)(5,5)(0,5)(0,0 ) ; in 0, ... ,4 in 0, ...",
    ",4 ( , ) circle ( .5ex ) ;    in 0, ... ,5 ( , 5 ) circle ( .5ex ) ;    in 0, ... ,5 ( 5 , ) circle ( .5ex ) ;    ( 3.2 , 3.4 ) to [ bend left = 40 ] ( 3,3 ) ; ( 3.2,3.4 ) node[cross=1ex , ultra thick ] ; ( 2.6 , 2.8 ) to [ bend left = 40 ] ( 3,3 ) ; ( 2.6,2.8 ) node[cross=1ex , ultra thick ] ; ( .6 , .2 ) to [ bend left = 40 ] ( 1,0 ) ; ( .6,.2 ) node[cross=1ex , ultra thick ] ; ( 2.55 , 4.8 ) to [ bend left = 40 ] ( 3,5 ) ; ( 2.55,4.8 ) node[cross=1ex , ultra thick ] ; ( 4.45 , .8 ) to [ bend left = 40 ] ( 4,1 ) ; ( 4.45,.8 ) node[cross=1ex , ultra thick ] ; ( .8,4.45 ) to [ bend left = 40 ] ( 1,4 ) ; ( .8,4.45 ) node[cross=1ex , ultra thick ] ; ( .3,2.45 ) to [ bend left = 40 ] ( 0,2 ) ; ( .3,2.45 ) node[cross=1ex , ultra thick ] ; ( 3.4,2.9 ) to [ bend left = 40 ] ( 3,3 ) ; ( 3.4,2.9 ) node[cross=1ex , ultra thick ] ; ( 1.55,2 ) to [ bend left = 40 ] ( 2,2 ) ; ( 1.55,2 ) node[cross=1ex , ultra thick ] ; ( 3.55,.4 ) to [ bend left = 40 ] ( 4,0 ) ; ( 3.55,.4 ) node[cross=1ex , ultra thick ] ; ( 4.6,3.25 ) to [ bend left = 40 ] ( 5,3 ) ; ( 4.6,3.25 ) node[cross=1ex , ultra thick ] ;    if @xmath297 or @xmath298 for any @xmath244 , the equispaced sample @xmath293 does not appear in the two - dimensional fft in  .",
    "analogous to the sequence @xmath163 in  , we reassign the sample @xmath294 using the periodicity of the complex exponential function .",
    "that is , we define a new sequence @xmath299 such that @xmath300    using these two sequences , we can rewrite   as @xmath301 here , @xmath302 and @xmath303 are matrices that can be well - approximated by low rank matrix because @xmath304 , @xmath305 $ ] , @xmath306 , and @xmath307 $ ] . using the ideas in section  [ sec : chebyshevlowrank ] , we can construct vectors such that @xmath308 and @xmath309 . in double precision , @xmath310 and @xmath311",
    "are both at most @xmath199 ( see table  [ tab : optimalk ] ) .",
    "moreover , we note that @xmath312 is closely related to the complex exponential function in the uniform two - dimensional dft in  .    substituting the low rank representations for @xmath313 and @xmath314 into  , absorbing the sums over @xmath315 and @xmath316 into matrix - matrix products , and using the fact that @xmath317",
    ", we find that   can be expressed as @xmath318_{mt_j^x+t_j^y } , \\qquad 0\\leq j\\leq n-1 .",
    "\\label{eq : nufftii_2d}\\ ] ] here , @xmath319_{mt_j^x+t_j^y}$ ] denotes the @xmath320 entry of the vector @xmath321 .",
    "the sum in   leads to a quasi - optimal complexity transform for the two - dimensional nufft - ii .",
    "there are @xmath322 terms in   each requiring an @xmath278 two - dimensional fft with a diagonally - scaled coefficient matrix @xmath323 .",
    "moreover , since each term is adding together @xmath6 vectors , the total cost of the transform is @xmath324 operations . with an explicit dependence on the working accuracy @xmath16 ,",
    "this becomes @xmath325 operations .",
    "the cost of the transform can be moderately reduced by noting that @xmath326 in   does not depend on @xmath327 and can be computed just once for each @xmath328 .",
    "this reduces the cost to @xmath329 operations .",
    "for implementations of this two - dimensional transform , see the chebfun.nufft2 command in chebfun  @xcite and the nufft2d command in fasttransforms.jl  @xcite .",
    "there are two other types of two - dimensional nuffts , which can be implemented with similar ideas as well as multidimensional nuffts .",
    "we thank the ministerio de economa y competitividad ( reference bes-2013 - 064743 ) for providing the financial support for the first author to visit cornell university for three months .",
    "the work for this paper began during the summer of 2016 and we are grateful to amparo gil and javier segura for helping to organize the research visit .",
    "we thank anthony austin for discussing with us the condition number of the nudft - ii matrix and kuan xu for providing extremely useful feedback on an earlier version of the manuscript .",
    "we are also grateful to mike oneil and heather wilber for reading the manuscript .    3 , _ rapid computation of the discrete fourier transform _ , siam j. sci .",
    "comput . , 17 ( 1996 ) , pp .",
    "913919 . , _ some new results on and applications of interpolation in numerical computation _ ,",
    "dphil thesis , university of oxford , 2016 . , _ trigonometric interpolation and quadrature in perturbed points _ , arxiv preprint arxiv:1612.04018 , ( 2016 ) . , _ the nonuniform discrete fourier transform and its applications in signal processing _ , vol .",
    "463 , springer science and business media , 2012 . , _ a short course on fast multipole methods _ , wavelets , multilevel methods and elliptic pdes , 1 ( 1997 ) , pp .  137 .",
    ", _ julia : a fresh approach to numerical computing _ , arxiv preprint arxiv:1411.1607 , 2016 .",
    ", _ a fast algorithm for chebyshev , fourier , and sinc interpolation onto an irregular grid _ ,",
    "_ j. comput .",
    "_ , 103 ( 1992 ) , pp .  243257 . , _ an algorithm for the machine calculation of complex fourier series _ , math .",
    "comput . , 19 ( 1965 ) , pp .",
    "297301 . , editors , _ chebfun guide _ , pafnuty publications , oxford , 2014 .",
    ", _ fast fourier transforms for nonequispaced data _ , siam j. sci .",
    "comput . , 14 ( 1993 ) , pp .",
    "13681393 . , _",
    "the approximation of one matrix by another of lower rank _ , psychometrika , 1 ( 1936 ) , pp .",
    ", _ nonuniform fast fourier transforms using min - max interpolation _ ,",
    "ieee trans .",
    "signal proc . , 51 ( 2003 ) ,",
    ", _ fftw : an adaptive software architecture for the fft _ , acoustics , speech and signal processing , proceedings of the 1998 ieee international conference on . , vol .",
    "3 . ieee , 1998 .",
    ", _ matrix computations _ , johns hopkins university press , 1996 .",
    ", _ accelerating the nonuniform fast fourier transform _ , siam review , 46 ( 2004 ) , pp .",
    "443454 . , _ the exact value of the paley - wiener constant _ , soviet math .",
    "dokl . , 5 ( 1964 ) , pp .",
    "559561 . , https://github.com/tknopp/nfft.jl/graphs/contributors , jan .",
    ", _ nonequispaced fft : generalisation and inversion _ , universitt zu lbeck , 2006 .",
    ", _ fast evaluation of real and complex exponential sums _ ,",
    "preprint , univ .",
    "osnabrck , 2014 .",
    ", _ the type 3 nonuniform fft and its applications _ , j. comput .",
    "phys . , 206 ( 2005 ) , pp .",
    "_ nist handbook of mathematical functions _ , cambridge university press , 2010 .",
    ", _ fast summation at nonequispaced knots by nfft _ , siam j. sci .",
    "comput . , 24 ( 2003 ) , pp .",
    "20132037 . , _ fast fourier transforms for nonequispaced data : a tutorial _ ,",
    "modern sampling theory .",
    ", birkhuser , boston , ( 2001 ) , pp .",
    "247270 . , https://github.com/mikaelslevinsky/fasttransforms.jl , v0.0.6 , 2016 . ,",
    "_ computing with functions in two dimensions _ , dphil thesis , university of oxford , 2014 .",
    ", _ fast polynomial transforms based on toeplitz and hankel matrices _ , arxiv preprint arxiv:1604.07486 , ( 2016 ) . ,",
    "_ approximation theory and approximation practice _ , siam , 2013 .",
    ", _ fast approximate fourier transforms for irregularly spaced data _ ,",
    "siam review , 40 ( 1998 ) , pp .",
    "in section  [ sec : typeii_perturbed ] we require a low rank approximation for the matrix @xmath51 in  .",
    "we first note that we can consider @xmath51 as the matrix obtained by sampling the bivariate function @xmath330 on the domain @xmath331\\times [ 0,2\\pi]$ ] .",
    "if we construct a bivariate polynomial approximation @xmath332 of degree @xmath88 in both the @xmath333- and @xmath334-variable to @xmath58 on @xmath331\\times [ 0,2\\pi]$ ] , then @xmath335 is a rank @xmath3 approximation to @xmath51  ( * ? ? ?",
    "we construct the polynomial @xmath332 by a truncated bivariate chebyshev expansion for @xmath58 .",
    "let @xmath16 be a working precision and @xmath336 .",
    "the following holds : @xmath337\\times [ 0,2\\pi]}\\left| e^{-i x y } - \\sum_{r=0}^{k-1}\\!{}^ { ' } \\!\\sum_{p=0}^{k-1}\\!{}^ { ' }   a_{pr } e^{-i\\pi x}t_p(\\tfrac{x}{\\gamma})t_r(\\tfrac{y}{\\pi}-1)\\right|\\leq \\epsilon,\\ ] ] where @xmath338 is the degree @xmath84 chebyshev polynomial , the @xmath339 coefficients are given in  , and the primes on the summands indicate that the first term should be halved . here",
    ", the integer @xmath3 satisfies : @xmath340 where @xmath109 is the lambert w function  ( * ? ? ?",
    "* ( 4.13.1 ) ) .",
    "[ lem : chebyshevexpansion ]    a bivariate chebyshev expansion of @xmath341 on @xmath342\\times [ 0,2\\pi]$ ] is given by  ( * ? ? ? * lem .",
    "a.3 ) @xmath343\\times [ 0,2\\pi],\\ ] ] where @xmath338 is the degree @xmath84 chebyshev polynomial and the primes on the summands indicate that the first term should be halved",
    ". moreover , the expansion coefficients are given by  ( * ? ? ?",
    "a.3 ) @xmath344 pick @xmath345 to be an integer . then , by the triangle inequality , @xmath346 for @xmath86 $ ] , and @xmath347 , we have @xmath337\\times [ 0,2\\pi]}\\left| e^{-i x y } - \\sum_{p=0}^{k-1}\\!{}^ { ' } \\sum_{r=0}^{k-1}\\!{}^ { ' }   a_{pr } e^{i\\pi x}t_p(\\tfrac{x}{\\gamma})t_r(\\tfrac{y}{\\pi}-1)\\right|\\leq \\sum_{p = k}^{\\infty } \\sum_{r = k}^{\\infty } |a_{pr}|.\\ ] ] using  ( * ? ? ?",
    "* ( 10.14.1 ) and ( 10.14.7 ) ) , we find that @xmath348 therefore , by setting @xmath349 , we can bound the error as @xmath350 assuming @xmath351 , we find that @xmath352 with @xmath353 .",
    "hence , we have @xmath354 where the last inequality used @xmath355 , @xmath356 , and @xmath357 . by solving for @xmath358 such that @xmath359",
    ", we find that we can take @xmath3 to be @xmath360 where @xmath109 is the lambert w function .",
    "the asymptotic approximation for the lower bound on @xmath3 as @xmath115 is derived from the asymptotic expansion for @xmath109 as @xmath361  ( * ? ? ?",
    "* ( 4.13.10 ) ) .",
    "we now evaluate the truncated chebyshev expansion constructed in lemma  [ lem : chebyshevexpansion ] to derive a rank @xmath3 approximation to the matrix @xmath51 in  .",
    "we make the additional restriction that @xmath362 in the statement of the theorem below because we do not construct low rank approximations to @xmath51 when @xmath363 ( see section  [ sec : generalposition_typeii ] ) .",
    "let @xmath4 be an integer , @xmath16 , and @xmath18 samples such that   holds with @xmath364 .",
    "consider the @xmath191 matrix @xmath365 where @xmath366 $ ] .",
    "then , there exists a rank @xmath3 matrix @xmath56 such that @xmath76 , where @xmath367 and @xmath368 is the absolute maximum entry of @xmath51 .",
    "[ thm : lowrankapproximation ]    let @xmath369 , @xmath370 and @xmath371 .",
    "then , @xmath372 , where the exponential function is applied entry - by - entry to its matrix input .",
    "since the entries in @xmath141 are in @xmath373 $ ] and the entries of @xmath374 are in @xmath375 $ ] , we can apply lemma  [ lem : chebyshevexpansion ] to each entry of @xmath51 .",
    "we conclude that for @xmath376 we have @xmath377 where @xmath378 is the degree @xmath84 chebyshev polynomial , the coefficients @xmath96 are given in  , @xmath95 is the @xmath6 column vector of ones , and the prime on the summands indicate that the first term is halved .    each term in the double sum in",
    "is a rank-1 term so it may look like @xmath56 is of rank at most @xmath379 ; however , by appropriately grouping the terms as follows : @xmath380 we conclude that @xmath56 is a matrix of rank at most @xmath3 , as required .",
    "the asymptotic order of @xmath3 given in the statement of the theorem comes from the asymptotic expansion of @xmath109 as @xmath113  ( * ? ? ?",
    "* ( 4.13.10 ) ) ."
  ],
  "abstract_text": [
    "<S> by viewing the nonuniform discrete fourier transform ( nudft ) as a perturbed version of a uniform discrete fourier transform , we propose a fast , stable , and simple algorithm for computing the nudft that costs @xmath0 operations based on the fast fourier transform , where @xmath1 is the size of the transform and @xmath2 is a working precision . </S>",
    "<S> our key observation is that a nudft and dft matrix divided entry - by - entry is often well - approximated by a low rank matrix , allowing us to express a nudft matrix as a sum of diagonally - scaled dft matrices . </S>",
    "<S> our algorithm is simple to implement , automatically adapts to any working precision , and is competitive with state - of - the - art algorithms . in the fully uniform case , </S>",
    "<S> our algorithm is essentially the fft . </S>",
    "<S> we also describe quasi - optimal algorithms for the inverse nudft and two - dimensional nudfts . </S>"
  ]
}