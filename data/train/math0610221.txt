{
  "article_text": [
    "functional data analysis is a well - known area of modern statistics .",
    "advances in computer sciences make it now possible to collect data from an underlying continuous - time processe , say @xmath0 , at high frequencies .",
    "the traditional point of view consisting in discretizing @xmath1 at @xmath2 and studying it by classical multidimensional tools is outperformed by interpolation methods ( such as splines or wavelets ) .",
    "these techniques provide the statistician with a reconstructed curve on which inference may be carried out through what we may call `` functional models '' i.e. versions of the classical multidimensional models designed and suited for data that are curves .",
    "thus , functional pca , anova or canonical analysis -even density estimation for curves or processes have been investigated .",
    "we refer to ramsay , silverman ( 1997 , 2002 ) , bosq ( 2000 ) , ferraty vieu ( 2006 ) for monographs on functional data analysis .",
    "recently many authors focused on various versions of the regression model introduced by ramsay and dalzell ( 1991 ) : @xmath3 where we assume that the sample @xmath4 is made of independent copies from @xmath5 each @xmath6   } $ ] is a curve defined on the set @xmath7   , $ ] @xmath8 , @xmath9 is a real number , @xmath10 is a white noise and @xmath11 is an unknown function to be estimated . in other words",
    "the @xmath12 s are random elements defined on an abstract probability space and taking values in a function space , say @xmath13 the vector space @xmath14 endowed with norm @xmath15 will be described soon.we refer for instance to cardot , mas , sarda ( 2006 ) or cai , hall ( 2006 ) for recent results .    in this article",
    "we study a new ( linear ) regression model defined below derived from ( [ mod1 ] ) and echoing the recent paper of mas and pumo ( 2006 ) .",
    "the key idea relies on the fact that most statisticians dealing with functional data do not fully enjoy their functional properties .",
    "for instance in several models integrals such as@xmath16 are computed .",
    "the integral above is nothing but a scalar product .",
    "nevertheless derivatives were not given the same interest .",
    "explicit calculations of derivatives sometimes appear indirectly in kernel methods ( when estimating the derivatives of the density or the regression function ) or through seminorms or norms on @xmath14 .",
    "but surprisingly @xmath17 ( or @xmath18 ) never appear in the models themselves whereas people dealing with functional data often say that `` derivatives contain much information , sometimes more than the initial curves themselves '' .",
    "our starting idea is the following . since in a functional data framework ,",
    "the curve - data are explicitely known and not just discretized , their derivatives may also be explicitely computed . as a consequence these derivatives may be `` injected '' in the model , which may enhance its prediction power .",
    "the reader is referred to the forthcoming display ( [ modele ] ) for an immediate illustration and to mas , pumo ( 2006 ) for a first article dealing with a functional autoregressive model including derivatives .",
    "the paper is rather theoretic even if it is illustrated by a real case study .",
    "it is organized as follows .",
    "the next section provides the mathematical material , dealing with hilbert spaces and linear operators , then the model is introduced .",
    "the next section is devoted to presenting the estimation method and its stumbling stones .",
    "the main results are given before we focus on a real case application to food industry .",
    "the last section contains the derivation of the theorems .",
    "silverman ( 1996 ) provided a theoretical framework for a smoothed pca .",
    "jim ramsay ( 2000 ) enlightened the very wide scope of differential equations in statistical modelling .",
    "our work is in a way based on this mathematically involved article .",
    "we are aiming at proving that derivatives may be handled in statistical models quite easily when the space @xmath14 is well - chosen .",
    "the choice of the space @xmath14 is crucial .",
    "we have to think that if @xmath19 , @xmath20 does not necessarily belong to @xmath14 but to another space @xmath21 that may be tremendously different ( larger ) than @xmath14 .",
    "we decide to take @xmath22 the sobolev space of order @xmath23 defined by @xmath24   , u^{\\prime}\\in l^{2}\\left [ 0,1\\right ]   \\right\\}\\ ] ] for at least three reasons :    * if @xmath19 , @xmath25   $ ] which is a well known space . *",
    "both spaces are hilbert spaces as well as@xmath26   , u^{\\left (   p\\right )   } \\in l^{2}\\left [   0,1\\right ]   \\right\\ }   .\\ ] ] this is of great interest for mathematical reasons : bases are denumerable , projections operators are easy to handle , covariance operators admit spectral representations , etc . *",
    "the classical interpolation methods mentioned above ( splines and wavelets ) provide estimates belonging to sobolev spaces .",
    "so from a practical point of view @xmath27 -and in general @xmath28 @xmath29 ( see adams and fournier ( 2003 ) for definitions)- is a natural space in which our curves should be imbedded .    in the sequel @xmath27 will be denoted @xmath30 and @xmath31 will be denoted @xmath32 for the sake of simplicity .",
    "we keep in mind that @xmath30 ( resp .",
    "@xmath32 ) could be replaced by a space of higher smoothness index : @xmath33 where @xmath34 ( resp .",
    "@xmath35 ) . the spaces @xmath30 and @xmath32 are separable hilbert spaces endowed with scalar product : @xmath36 and with associated norms @xmath37 and @xmath38 .",
    "we refer to ziemer ( 1989 ) or to adams and fournier ( 2003 ) for monographs dedicated to sobolev spaces . obviously if we set @xmath39 then @xmath40 maps @xmath30 onto @xmath32 ( @xmath40 is the ordinary differential operator)@xmath41 furthermore sobolev s imbedding theorem ensures that ( see adams and fournier ( 2003 ) theorem 4.12 p.85 ) that@xmath42 ( where @xmath43 is some constant which does not depend on @xmath44 ) i.e. @xmath40 * * is a bounded operator from * * @xmath30 * * to * * @xmath45 this is a crucial point to keep in mind and the fourth reason why the functional space was chosen to be @xmath27 : the differential operator @xmath40 may be viewed as a continuous linear mapping from @xmath30 to @xmath32 .    within all the paper and especially all along the proofs we will need basic notions about operator theory .",
    "we recall a few important facts .",
    "a linear mapping @xmath46 from a hilbert space @xmath47 to another hilbert space @xmath48 is continuous whenever@xmath49 the adjoint of operator @xmath46 will be classically denoted @xmath50 .",
    "some finite rank operators are defined by means of the tensor product : if @xmath44 and @xmath51 belong to @xmath47 and @xmath48 respectively @xmath52 is the operator defined on @xmath47 by , for all @xmath53  : @xmath54    * compact operators * : amongst linear operators the class of compact operators is one of the best known .",
    "compact operators generalize matrix to the infinite - dimensional setting and feature nice properties .",
    "the general definition of compact operators may be found in dunford schwartz ( 1988 ) or gohberg , goldberg and kaashoek ( 1991 ) for instance .",
    "by @xmath55 ( resp .",
    "@xmath56 ) we denote the space of compact operators on the hilbert space @xmath47 ( resp . mapping the hilbert space @xmath47 onto @xmath57 ) .",
    "if @xmath46 is a compact operator from a hilbert space @xmath58 to another hilbert space @xmath59 @xmath46 admits the schmidt decomposition : @xmath60 where @xmath61 ( resp .",
    "@xmath62 ) is a complete orthonormal system in @xmath58 ( resp . in @xmath63 ) and @xmath64 are the characteristic numbers of @xmath46 ( i.e. the square root of the eigenvalues of @xmath65 ) and @xmath66 from ( [ normsup ] ) we obtain@xmath67 when @xmath46 is symmetric @xmath64 is the @xmath68 eigenvalue of @xmath46 ( then @xmath69 ) . in this situation and from ( [ decomp.schmidt ] ) one may define the square root of @xmath46 whenever @xmath46 maps @xmath47 ont @xmath47 and is positive : @xmath70 is still a linear operator defined by : @xmath71 note that finite rank operators are always compact.*hilbert - schmidt operators * : we also mention the celebrated space of hilbert - schmidt operators @xmath72 - a subspace of @xmath73 let @xmath74 be a basis of @xmath58 then @xmath75 whenever@xmath76 the space @xmath77 is itself a separable hilbert space endowed with scalar product@xmath78 and @xmath79 does not depend on the choice of the basis @xmath80 finally the following bound is valid for all @xmath81 : @xmath82 * unbounded operators * : if @xmath46 is a one to one ( injective ) selfadjoint compact operator mapping a hilbert space @xmath47 onto @xmath47 , @xmath46 admits an inverse @xmath83 . the operator @xmath83 is defined on a dense ( and distinct ) subspace of @xmath47 : @xmath84 it is unbounded which also means that @xmath83 is continuous at no point for which it is defined and @xmath85",
    "we are now in position to introduce this ( random input - linear ) regression model : @xmath86 where all random variables are assumed to be centered .",
    "the main result of the paper ( see next section ) gives an asymptotic expansion for the mean square prediction error in ( [ modele ] ) .",
    "the unknown functions @xmath87 and @xmath88 belong to @xmath30 and @xmath32 respectively .    obviously we are going to face two issues :    * studying the identifiability of @xmath87 and @xmath88 in the model above . * providing a consistent estimation procedure for @xmath87 and @xmath88 .    from now on",
    "we suppose that : @xmath89    this assumption could be relaxed for milder moment assumptions . we claim that our main result holds whenever@xmath90 is true . but considering @xmath91 would lead us to longer and more intricate methods of proof .",
    "inference is based on moment formulas . from ( [ modele ] )",
    "we derive the two following normal equation -multiply with @xmath92 and @xmath93 successively then take expectation : @xmath94{l}% $ \\delta=\\gamma\\phi+\\gamma^{\\prime}\\psi,$\\\\ $ \\delta^{\\prime}=\\gamma^{\\prime\\ast}\\phi+\\gamma^{\\prime\\prime}\\psi.$% \\end{tabular } \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\right .",
    "\\label{syst}%\\ ] ] where @xmath95 @xmath96 @xmath97 @xmath98 are the covariance and cross - covariance of the couple @xmath99 defined by : @xmath100 and@xmath101    under assumption @xmath102 or @xmath91 the covariance operators belong to @xmath103 , @xmath104 , @xmath105 or to @xmath106 .",
    "besides the covariance and cross - covariance mentioned above are linked through the relation@xmath107    resolving the system ( [ syst ] ) is apparently easy but we should be aware of two facts :    * operators ( here , @xmath108 . ) do not commute ! * the inverse operators of @xmath95 and @xmath109 do not necessarily exist and when they do , they are unbounded , i.e. not continuous ( recall that @xmath95 and @xmath109 are compact operators and that compact operators have no bounded inverses ) .    before trying to solve ( [ syst ] ) we will first study identifiability of the unknown infinite dimensional parameter @xmath110 in the next subsection .",
    "we complete our definitions and notations first .",
    "we start from a sample @xmath111 . by @xmath112 and @xmath113",
    "we denote the empirical counterparts of the operators and vectors introduced above and based on the sample @xmath114 .",
    "for example : @xmath115      both equations in ( [ syst ] ) are the starting point of the estimation procedure .",
    "we should make sure that solutions to these equations are well and uniquely defined .",
    "suppose for instance that @xmath116 and take @xmath117 in it .",
    "now set @xmath118 then @xmath119 so @xmath120 and since @xmath121 it is plain that @xmath122 consequently @xmath123 is another solution to ( [ syst ] ) .",
    "there are indeed even infinitely many solutions in the space @xmath124@xmath125 . for similar reasons about @xmath88 we should impose @xmath126 for @xmath127",
    "it turns out that the only necessary assumption is@xmath128 it is easily seen that @xmath129 implies @xmath130 with other words we suppose that both operators @xmath125 and @xmath109 above are one to one .",
    "we are now ready to solve the identification problem .",
    "[ ident]the couple @xmath131 is identifiable for the moment method proposed in ( [ syst ] ) if and only if @xmath129 holds and @xmath132 where @xmath133 is the vector subspace of @xmath134 defined by : @xmath135    the above proposition is slightly abstract but ( [ fluke ] ) may be simply rewritten : @xmath136 whenever for all function @xmath137 in @xmath138@xmath139    note that @xmath133 is a closed set in @xmath134 . from now on we will assume that : @xmath140",
    "the estimates stem from ( [ syst ] ) which is a non invertible system . under assumption",
    "@xmath129 the solution exists and is unique : @xmath94{l}% $ \\phi=\\left (   \\gamma-\\gamma^{\\prime}\\gamma^{\\prime\\prime-1}\\gamma^{\\prime\\ast } \\right )   ^{-1}\\left [   \\delta-\\gamma^{\\prime}\\gamma^{\\prime\\prime-1}% \\delta^{\\prime}\\right ]   , $ \\\\",
    "$ \\psi=\\left (   \\gamma^{\\prime\\prime}-\\gamma^{\\prime\\ast}\\gamma^{-1}% \\gamma^{\\prime}\\right )   ^{-1}\\left [   \\delta^{\\prime}-\\gamma^{\\prime\\ast}% \\gamma^{-1}\\delta\\right ]   .$% \\end{tabular } \\ \\ \\ \\ \\ \\ \\ \\ \\right",
    ".   \\label{soluce}%\\ ] ] let us denote @xmath141 the reader should note two crucial facts . on the one hand @xmath142 and @xmath143",
    "are unbouded operators but closed graphs argument ensure that @xmath144 and @xmath145 exist in @xmath30 and @xmath32 respectively . on the other hand @xmath146 ( resp .",
    "@xmath147 ) belong to the domain of the unbounded operator @xmath148 ( resp .",
    "@xmath149 ) which also ensures the finiteness of both solutions given in the display above .    finding approximations to the solutions of ( [ soluce ] ) is known in the mathematical literature as `` solving a linear inverse problem '' .",
    "the book by tikhonov and arsenin ( 1977 ) -as many other references therein- is devoted to this theory well - known in image reconstruction .",
    "the unboundedness of @xmath150 may cause large variation of @xmath151 even for small variations of @xmath152 .",
    "this lack of stability turns out to damage , as well as the traditional `` curse of dimensionality '' , the rates of convergence of our estimates .",
    "unfortunately we can not simply replace `` theoretical '' operators and vectors by their empirical estimates because @xmath153 and @xmath154 are not invertible .",
    "indeed they are finite - rank operators ( for example the image of @xmath125 is @xmath155 ) hence not even injective .",
    "we are classically going to add a small perturbation to regularize @xmath153 and @xmath154 ( see tikhonov and arsenin ( 1977 ) ) and another one for @xmath148 and make them invertible . at last @xmath142 is approximated by @xmath156 @xmath143 by @xmath157 and @xmath148 by @xmath158 where@xmath159 and @xmath160 @xmath161 we also set : @xmath162    in the sequel we will assume that both strictly positive sequences @xmath163 and @xmath164 decay to zero in order to get the asymptotic convergence of the estimates .",
    "the estimate of the couple @xmath165 is @xmath166 based on ( [ soluce ] ) and defined by : @xmath94{l}% $ \\widehat{\\phi}_{n}=\\left (   s_{n,\\phi}+\\beta_{n}i\\right )   ^{-1}u_{n,\\phi } , \\smallskip$\\\\ $ \\widehat{\\psi}_{n}=\\left (   s_{n,\\psi}+\\beta_{n}i\\right )   ^{-1}u_{n,\\psi}.$% \\end{tabular } \\ \\right .",
    "\\label{estim}%\\ ] ] the predictor is defined as@xmath167",
    "in mas , pumo ( 2006 ) the authors obtained convergence in probability for their estimates in a quite different model .",
    "we are now in position to assess deeper results .",
    "mean square prediction error is indeed given an asymptotic development depending on both smoothing sequences @xmath168 and @xmath164 .    before stating the main result of this article , we give and comment the next and last assumption : @xmath169{l}% $ \\left\\vert \\gamma^{-1/2}\\phi\\right\\vert _ { w}<+\\infty$\\\\ $ \\left\\vert \\left (   \\gamma^{\\prime\\prime}\\right )   ^{-1/2}\\psi\\right\\vert _ { l}<+\\infty$% \\end{tabular } \\ \\ \\ \\ \\ \\right .",
    "\\label{a4}%\\ ] ]    for the definition of @xmath170 and @xmath171 we refer to ( [ racop ] ) .",
    "let us explain briefly what both conditions in ( [ a4 ] ) mean . to that aim",
    "we rewrite the first by developing @xmath172 in a basis of eigenvectors of @xmath95 say @xmath173@xmath174 hence@xmath175 the first part of assumption @xmath176 tells us that `` @xmath177 should tend to zero quickly enough with respect to @xmath178 '' . in other words",
    "@xmath87 should belong to an ellipsod of @xmath30 which may be more or less `` flat '' depending on the rate of decay of the @xmath178 s to zero .",
    "assumption @xmath176 is in fact * a regularity condition * on functions @xmath87 and @xmath88 : function @xmath87 ( resp .",
    "@xmath88 ) should be smoother than @xmath179 ( resp .",
    "@xmath20 ) .    we could try and state convergence results for @xmath180 and @xmath181 separatedly but it turns out that :    * the real statistical interest of the model relies on its predictive power .",
    "the statistician is mainly interested in @xmath182 not in @xmath180 and @xmath181 in a first attempt .",
    "the issue of goodness of fit tests ( involving @xmath87 and @xmath88 alone ) is beyond the scope of this article . * considering the mean square norm of @xmath183 ( instead of @xmath180 or",
    "even of @xmath184 for a nonrandom @xmath152 ) has a smoothing effect on our estimates and partially counterbalance the side effects of the underlying inverse problem as will be seen within the proofs ( especially along lemma [ placebo ] ) .    turning to @xmath182",
    "the next question is : what should we compare @xmath185 with  ?",
    "the right answer is not @xmath186 obviously we could , but it is also plain that , due to the random @xmath187 the best possible prediction for @xmath188 knowing @xmath189 ( or even the `` past '' i.e. @xmath190 ) is the conditional expectation : @xmath191 we are now ready to state the main theoretical result of this article .",
    "[ conv]when assumptions @xmath192 hold the following expansion is valid for the prediction mean square error : @xmath193    replacing @xmath194 with @xmath188 is still possible .",
    "we may easily prove that  : @xmath195    from theorem [ conv ] above an optimal choice for @xmath196 is @xmath197 then the convergence rate is : @xmath198 and may be quite close from @xmath199 .    the proof of the corollary will be omitted .",
    "studying the optimality of this rate of convergence over the classes of functions defined by @xmath176 is beyond the scope of this article but could deserve more attention .    originally the linear model ( [ modele ] ) is subject to serious multicolinearity troubles since @xmath200 even if the curve @xmath201 usually looks quite different from @xmath202 there is a total stochastic dependence between them .",
    "the method used in this article to tackle this problem ( as well as the intrinsic `` inverse problem '' aspects related to the inversion of the covariance operators @xmath125 and @xmath203 ) is new up to the authors knowledge . as it can be seen through above at display ( [ estim ] ) or in the proofs below",
    ", it relies on a double penalization technique first by the index @xmath168 then by @xmath164 linking both indexes in order to suppress the bias terms asymptotically .",
    "in this section we will present an application of the functional linear regression with derivatives ( flrd ) introduced in this paper to a spectroscopic calibration problem . quantitative nir ( near - infrared )",
    "spectroscopy is used to analyze food and agricultural materials .",
    "the nir spectrum of a sample is a continuous curve giving the absorption , that is @xmath204 where @xmath205 is the reflection of the sample , against wavelength measured in nanometers ( nm ) .",
    "in the ` cookie ` example considered here the aim is to predict the percentage of each ingredient @xmath206 given the nir spectrum @xmath152 of the sample ( see osborne et al .",
    "( 1984 ) for a full description of the experiment ) .",
    "the constituents under investigation are : fat , sucrose , dry flour , and water .",
    "there were 39 samples in the calibration set , sample number 23 having been excluded from the original 40 as an outlier , and a further validation set with 31 samples , again after the exclusion of one outlier .",
    "an nir reflectance spectrum is available for each dough .",
    "the original spectral data consists of 700 points measured from 1100 to 1498 nm in steps of 2 nm .",
    "following brown et al .",
    "( 2001 ) we reduced the number of spectral points to 256 by considering only the spectral range 1380 - 2400 nm in step of 4 nm .",
    "samples of centered spectra are plotted in figure [ cookie_spectres ] .",
    "[ ptb ]    cookie_spectres.eps    a classical tool employed in the chemiometric literature for the prediction of @xmath206 knowing the associated nir spectra @xmath207 is the linear model:@xmath208 the problem then is to use the calibration data to estimate the unknown parameters @xmath209 . clearly in this application since @xmath210 the ordinary least squares fails and many authors proposed to use alternative methods to tackle the problem : principal component regression ( pcr ) or partial least squares regression ( pls ) .",
    "we invite the reader to look at the paper of frank and friedman ( 1993 ) for a statistical view of some chemiometrics regression tools .",
    "following an idea of hastie and mallows , in their discussion of frank and friedman s paper , we consider a spectrum as a functional observation . the functional linear regression ( flr ) corresponding to the model [ mult.lin.mod ] defined above is:@xmath211 where @xmath206 is a scalar random variable , @xmath152 a real function defined on @xmath212 $ ]  and @xmath213 the unknown parameter function .",
    "brown et al . ( 2001 ) , ferraty and vieu ( 2003 ) , marx and eilers ( 2002 ) or amato et al . ( 2006 ) used such a model for a prediction problem with spectrometric data .",
    "the model flrd introduced in this paper can be written as:@xmath214 where @xmath215 and @xmath216 are unknown functions ( see display ( [ modele ] ) for an equivalent definition ) . in this paragraph",
    "we compare the performance of pcr , pls , flr , flrd , spline smoothing model proposed by cardot , ferraty and sarda ( 2006 ) and bayes wavelet predictions proposed by brown et al .",
    "( 2001 ) .",
    "we used the calibration data set for the estimation of parameter functions @xmath215 and @xmath216 and validation data for calculation of the msep ( mean squared error of predictions):@xmath217 where @xmath218  is the prediction of @xmath219 obtained by the model with estimated parameters .",
    "the choice of the parameters @xmath220 and @xmath196 is crucial for the prediction model .",
    "we used a cross - validation approach based on the evaluation of the standard error of prediction @xmath221 : @xmath222,\\ ] ] where @xmath223 denotes the prediction of @xmath224  in the calibration set without sample @xmath225 .",
    "results for different methods of prediction of four ingredients are displayed in table [ table.msep ] .",
    "we used b - spline basis ( @xmath226 ) for obtaining predictions with spline smoothing , spline ridge rlf and spline rlfd methods .",
    "for each of those methods we give the values of the smoothing or penalty parameters based on an analogous cross - validation approach .",
    "[ c]|l|cccc| & + method and parameters & fat & sugar & flour & water + pls & 0.151 & 0.583 & 0.375 & 0.105 + pcr & 0.160 & 0.614 & 0.388 & 0.106 + spline smoothing ( @xmath227 ) & 0.546 & 0.471 & 2.226 & 0.183 + spline ridge flr",
    "( @xmath228 ) & 0.044 & 0.494 & 0.318 & 0.087 + spline flrd ( @xmath229 ) & 0.092 & 0.450 & 0.332 & 0.069 + bayes wavelet & 0.063 & 0.449 & 0.348 & 0.050 +    we note that functional approaches work better then pls or pcr methods for the four predicted variables with respect to @xmath230 criterion . our simulation , as noted also by marx and eilers ( 2002 ) ,",
    "show that functional methods lead to more stable prediction .",
    "the spline flrd method produces in general equivalent results in terms of predictions with the best methods presented in table [ table.msep ] .",
    "in the sequel @xmath231 and @xmath232 will stand for constants .",
    "the norm in the space @xmath238 where @xmath239 is a banach space is defined the following way : let @xmath179 be a random element in the banach space @xmath240 then @xmath241 when the notation is not ambiguous we systematically drop the index @xmath242 i.e : @xmath243 .",
    "* fact 2 * : as a consquence of assumption @xmath102 and of the strong law of large numbers for hilbert valued random elements ( see ledoux , talagrand ( 1991 ) chapter 7),@xmath248 whenever @xmath249 ( resp .",
    "@xmath250 ) since all theses random operators may be rewritten as sums of i.i.d .",
    "random variables .",
    "these sequences of random operators are almost surely bounded@xmath251 which also means that @xmath252 since ( for instance ) @xmath253 where @xmath254 is again a sum of i.i.d random elements : @xmath255 we also set@xmath256 ( see below for details ) .",
    "* fact 3 * : the central limit thorem in hilbert spaces ( or standards results on rates of convergence for hilbert valued random elements in square norm ) provide a rate in the @xmath257 convergence of several random variables of interest in the proofs .",
    "see for instance ledoux , talagrand ( 1991 ) or bosq ( 2000 ) .",
    "whenever @xmath258 ( resp .",
    "@xmath259 ) we have @xmath260 hence @xmath261 since all theses random operators may be rewritten as sums of i.i.d .",
    "random variables .",
    "the method of the proof may be adapted from the model studied in mas , pumo ( 2006 ) .",
    "the couple @xmath165 will be identified whenever , for any other couple @xmath262 , if @xmath94{l}% $ \\delta=\\gamma\\phi+\\gamma^{\\prime}\\psi=\\gamma\\phi_{a}+\\gamma^{\\prime}\\psi _ { a},$\\\\ $ \\delta^{\\prime}=\\gamma^{\\prime\\ast}\\phi+\\gamma^{\\prime\\prime}\\psi = \\gamma^{\\prime\\ast}\\phi_{a}+\\gamma^{\\prime\\prime}\\psi_{a}.$% \\end{tabular } \\right.\\ ] ] @xmath263",
    ". this will be true if@xmath94{l}% $ \\gamma\\left (   \\phi-\\phi_{a}\\right )   + \\gamma^{\\prime}\\left (   \\psi-\\psi _ { a}\\right )   = 0,$\\\\ $ \\gamma^{\\prime\\ast}\\left (   \\phi-\\phi_{a}\\right )   + \\gamma^{\\prime\\prime } \\left (   \\psi-\\psi_{a}\\right )   = 0.$% \\end{tabular } \\right.\\ ] ]    this means that the couple @xmath264 belongs to the kernel of the linear operator defined blockwise on @xmath134 by : @xmath265{cc}% \\gamma & \\gamma^{\\prime}\\\\ \\gamma^{\\prime\\ast } & \\gamma^{\\prime\\prime}% \\end{array } \\right )   .\\ ] ] as @xmath121 and @xmath266 , the proposition will be proved if the blockwise operator defined on @xmath267 and with values in @xmath30 : @xmath265{cc}% \\gamma & \\gamma^{\\prime}% \\end{array } \\right )   = \\left ( \\begin{array } [ c]{cc}% \\gamma & \\gamma d^{\\ast}% \\end{array } \\right)\\ ] ] is one to one .",
    "it is plain that the kernel of this operator is precisely the space @xmath133 that appears at display ( [ fluke ] ) .          we prove only the first bound since the method may be copied for the other ones .",
    "set @xmath269 then : @xmath270 at last,@xmath271 it is plain that@xmath272 if the schmidt decomposition of @xmath273 is : @xmath274 @xmath275 it is simple algebra to get : @xmath276 which yields @xmath277      the proof of this lemma is similar to lemma 7.4 in mas , pumo ( 2006 ) .",
    "it was then proved for @xmath233 instead of @xmath279 and all operators should be changed to their empirical counterparts ( e.g : @xmath153 insted of @xmath125 ) .",
    "we give a sketch of it .",
    "the proof relies on the schmidt decomposition of @xmath280 one would get@xmath281 where @xmath282 and @xmath283 are symmetric positive operators , which implies that @xmath279 itself is positive .",
    "it suffices then to apply * fact 2 * ( see the `` preliminary facts '' subsection ) to get the desired result .",
    "the following bound is valid : @xmath284 ^{2}\\\\ &   = \\left (   \\left\\langle \\phi-\\widehat{\\phi},x_{n+1}\\right\\rangle _ { w}+\\left\\langle \\psi-\\widehat{\\psi},x_{n+1}^{\\prime}\\right\\rangle _ { l}\\right )   ^{2}\\\\ &   \\leq2\\left [   \\left\\langle \\phi-\\widehat{\\phi},x_{n+1}\\right\\rangle _ { w}% ^{2}+\\left\\langle \\psi-\\widehat{\\psi},x_{n+1}^{\\prime}\\right\\rangle _ { l}% ^{2}\\right ]   .\\end{aligned}\\ ] ] then @xmath285 \\\\ &   = \\mathbb{e}\\left [   \\mathbb{e}\\left\\langle \\phi-\\widehat{\\phi}% , x_{n+1}\\right\\rangle _ { w}^{2}|\\widehat{\\phi}\\right ] \\\\ &   = \\mathbb{e}\\left [   \\left\\vert \\gamma^{1/2}\\left (   \\phi-\\widehat{\\phi } \\right )   \\right\\vert _ { w}^{2}\\right]\\end{aligned}\\ ] ] similarly,@xmath286\\ ] ] both preceding equations feature similar expressions .",
    "we focus on the term involving @xmath87 ; we will prove that : @xmath287   = o\\left (   \\frac{\\beta^{2}}{\\alpha^{2}}\\right ) + o\\left (   \\frac{1}{\\alpha^{2}\\beta^{2}n}\\right )   .\\ ] ] within the proof the reader will easily be convinced that the method would lead to an analogous result for the term with @xmath288 from now in order to alleviate notations we drop the index @xmath87 in @xmath289 and @xmath290 .",
    "the sequences @xmath291 and @xmath292 will be denoted @xmath220 and @xmath196 respectively and for short .",
    "the proof relies on the following decomposition : @xmath295 where@xmath296 along the forthcoming lemmas we determine rates of convergence for these three terms .",
    "we will prove that the rate of decrease to zero in @xmath257 norm is @xmath297 for @xmath298 and @xmath299 the rest of the proof of the main theorem is postponed to the end of the next and last subsection .",
    "first of all by ( [ l2 ] ) : @xmath302 we focus on@xmath303 then dealing with each of these three terms separatedly we get@xmath304 the last bound was derived from ( [ norm.delta ] ) and ( [ norm.res]).@xmath305 at last,@xmath306 then,@xmath307 by proposition [ lodge ] the second term may be bounded by@xmath308 since @xmath309 cauchy - schwartz inequality yields for the first : @xmath310 hence@xmath311 the proof of lemma [ cran ] is finished .",
    "we start with : @xmath313 clearly @xmath314 and we study the second term@xmath315 since @xmath113 is almost surely bounded ( see ( [ asd ] ) ) , @xmath316 @xmath317 and @xmath318 we get : @xmath319 the remaining term is@xmath320 where @xmath321",
    "first we drop @xmath322 since the norm of this operator may be bounded by a constant independent from @xmath220 ( see proposition [ lodge ] ) .",
    "we turn to : @xmath323 since @xmath324 almost surely .",
    "the consequence of the display above is @xmath325 and @xmath326    we can deal with @xmath327 as was done within the proof of the preceding lemma [ cran ] .",
    "clearly we may cope with @xmath327 as if the random @xmath328 was replaced by the non random @xmath329 .",
    "we should study@xmath330   \\left [   \\left (   \\gamma^{\\prime\\prime\\dag } \\right )   ^{1/2}e_{n}^{\\prime}\\right ]   .\\ ] ] it is enough to get a rate of decrease for each of the these terms .",
    "once again we have : @xmath331 which completes the proof of lemma [ u ] .",
    "the next lemma may be hard to understand at first glance . within the forthcoming proof of theorem [ conv ]",
    "the bias term @xmath340 will slightly change .",
    "we refer to displays ( [ e1 ] ) and ( [ e2 ] ) below for a deeper understanding .",
    "once again it takes two steps to get the result .",
    "first note that @xmath342 is a bounded linear operator .",
    "indeed@xmath343 where @xmath344@xmath345 the schmidt decomposition of @xmath205 is ( see ( [ mano ] ) above for the empirical version ) : @xmath346 where @xmath347 ( resp .",
    "@xmath348 ) is a complete orthonormal system in @xmath30 ( resp .",
    "@xmath32 ) . hence : @xmath349 the operator @xmath350 has a bounded inverse@xmath351 and @xmath352 for @xmath231 large enough ( or @xmath220 small enough).hence@xmath353 now ( second step ) we prove that : @xmath354 let us pick a given @xmath152 in @xmath30 , then @xmath355 it suffices to get for all @xmath206 in in the domain of operator @xmath170 : @xmath356 standard results on the spectrum of @xmath357 prove that @xmath358 and that @xmath359 which is enough to claim ( [ ct]).we are now in position to finixh the proof of the lemma .",
    "it is plain from ( [ ct ] ) that@xmath360 which is the claimed result .",
    "lemmas [ a_n ] gives the rates of convergence for @xmath362 and @xmath363 respectively .",
    "but lemma [ c_n ] is unfortunately not enough to get a rate in the last term .",
    "however this previous lemma enables to focus on : @xmath364 and @xmath365 by assumption @xmath176 , @xmath366 is finite .",
    "we deal with the central term , namely : @xmath367 ( see ( [ queer ] ) ) and@xmath368 collecting this last display with ( [ marin ] ) we get@xmath369 this finishes the proof of theorem [ conv ] .",
    "brown , p.j .",
    ", fearn , t. and vanucci m. , 2001 .",
    "bayesian wavelet regression on curves with application to a spectroscopic calibration problem , _ journal of the american statistical association .",
    "_ , 96 ( 454 ) , 398408 .                              osborne , b.j . ,",
    "fearn , t. , miller , a.r . and",
    "douglas , s. ( 1984 ) application of near - infrared reflectance spectroscopy to compositional analysis of biscuits dougts , _",
    "j. of the sc . of food and agricult .",
    "_ , * 35 * , 99105"
  ],
  "abstract_text": [
    "<S> we introduce a new model of linear regression for random functional inputs taking into account the first order derivative of the data . </S>",
    "<S> we propose an estimation method which comes down to solving a special linear inverse problem . </S>",
    "<S> our procedure tackles the problem through a double and synchronized penalization . </S>",
    "<S> an asymptotic expansion of the mean square prevision error is given . </S>",
    "<S> the model and the method are applied to a benchmark dataset of spectrometric curves and compared with other functional models .    * keywords * : functional data , linear regression model , differential operator , penalization , spectrometric curves . </S>"
  ]
}