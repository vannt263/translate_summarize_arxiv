{
  "article_text": [
    "the law of total probability is one of the fundamental building blocks of probability theory .",
    "its elementary version states that for an event @xmath0 and a partition @xmath1 , @xmath2 of the whole space the probability of @xmath0 can be calculated as @xmath3 & = \\sum_{i=1}^\\infty \\mathrm{p}[h_i]\\,\\mathrm{p}[a\\,|\\,h_i ] , \\label{eq : basic } \\intertext{where the conditional probabilities $ \\mathrm{p}[a\\,|\\,h_i]$ are defined as } \\mathrm{p}[a\\,|\\,h_i ] & =       \\begin{cases } \\frac{\\mathrm{p}[a\\cap h_i]}{\\mathrm{p}[h_i ] } , & \\text{if}\\ \\mathrm{p}[h_i ] > 0,\\\\ 0 , & \\text{if}\\ \\mathrm{p}[h_i ] = 0 .",
    "\\end{cases}\\notag\\end{aligned}\\ ] ] @xcite calls eq .   the theorem of total probability .",
    "it is also called rule or formula of total probability .",
    "virtually all text books on probability theory mention eq .",
    "but many authors ( e.g. * ? ? ?",
    "* chapter  v , eq .",
    "( 1.8 ) ) do not name it .",
    "@xcite comments on eq .   with the words `` this formula is useful because an evaluation of the conditional probabilities @xmath4 $ ] is frequently easier than a direct calculation of @xmath5 $ ] . ''",
    "sometimes it may even be impossible to directly calculate @xmath5 $ ] .",
    "in particular , this is the case when @xmath5 $ ] is assumed to be forecast but past observations of occurrences of event @xmath0 can not be relied on because the value of @xmath5 $ ] might have changed .",
    "such a situation is likely to be incurred in binary classification exercises where the unconditional ( or prior ) class probabilities in the training dataset may differ from the class probabilities of the population to which the classifier is applied ( see * ? ? ?",
    "* for a recent survey of data shift issues in classification ) .",
    "typically , a classifier produces class probabilities ( i.e.  probabilities of tested examples to be of  say  class @xmath0 ) conditional on already known features @xmath6 of the examples . if the unconditional distribution of the @xmath6 ( i.e.  the probabilities @xmath7 $ ] ) is also known , eq .",
    "then can be used to make a forecast ( or point estimate ) of @xmath5 $ ]",
    ".    it can be argued , however , that the forecasts of unconditional class probabilities produced this way are biased ( see section  2.2 of @xcite , or @xcite , and proposition  [ pr : biased ] below ) .",
    "this is a consequence of the fact that fundamentally the conditional class probabilities @xmath4 $ ] are determined by means of bayes formula ( assuming @xmath7>0 $ ] and @xmath5>0 $ ] ) : @xmath8 & = \\frac{\\mathrm{p}_0[a]\\,\\mathrm{p}[h_i\\,|\\,a]}{\\mathrm{p}_0[a]\\,\\mathrm{p}[h_i\\,|\\,a ] +              \\mathrm{p}_0[a^c]\\,\\mathrm{p}[h_i\\,|\\,a^c]}\\\\              & = \\frac{\\mathrm{p}_0[a]}{\\mathrm{p}_0[a ] +              \\mathrm{p}_0[a^c]\\,\\frac{\\mathrm{p}[h_i\\,|\\,a^c]}{\\mathrm{p}[h_i\\,|\\,a ] } } , \\end{split}\\ ] ] where @xmath9 denotes the event complementary to @xmath0 and @xmath10 $ ] and @xmath11 $ ] are the unconditional probabilities of class @xmath0 and @xmath9 respectively in the training dataset .",
    "the conditional probabilities @xmath12 $ ] and @xmath13 $ ] reflect the distributions of the characteristic features on class @xmath0 and its complementary class respectively .    on the one hand , eq .",
    "suggests a potentially unintended impact of the training set class probabilities on the population class estimates . on the other hand , eq .",
    "also suggests that an estimate of @xmath5 $ ] based solely on the conditional likelihood ratio @xmath14}{\\mathrm{p}[h_i\\,|\\,a]}$ ] would avoid this issue .",
    "this paper presents in theorem  [ th : main ] below a necessary and sufficient criterion for when it is possible to estimate a population class probability based on the unconditional distribution of the features of the tested examples and the conditional likelihood ratio .",
    "the likelihood ratio @xmath15 can also be written as @xmath16}{\\mathrm{p}[a\\,|\\,h_i]}\\ , \\frac{\\mathrm{p}_0[a]}{\\mathrm{p}_0[a^c]}.\\ ] ] by eq .",
    ", @xmath15 can alternatively be described as the ratio of the conditional and unconditional odds of class @xmath9 or the _ relative odds _ of class @xmath9 .",
    "this observation suggests that theorem  [ th : main ] is called _ law of total odds _ in analogy to the law of total probability eq .  .",
    "it turns out that the prior class probability estimator suggested by theorem  [ th : main ] is the two - class special case of the maximum likelihood estimator discussed by @xcite .",
    "equation   from theorem  [ th : main ] has recently been studied in the @xmath17-class case by ( * ? ? ?",
    "* eq .  ( 9 ) ) . the contributions of this paper ( limited to the case of binary classification ) to the existing literature can be described as follows :    * it is shown that the total odds estimator not only solves a prior probability shift problem but also , at the same time , a combined covariate shift and concept shift problem where only the relative odds are the same for training set and population ( or test set ) . * we demonstrate that the maximum likelihood estimator introduced by @xcite and studied in more detail by @xcite does not always exist . * we show how to determine conditional class distributions in the population or test set . *",
    "it becomes clear that  in the binary case  the total odds estimates can be computed by simple numerical root - finding .",
    "there is no need to deploy the expectation - maximisation or other more advance iterative algorithms as discussed by @xcite , @xcite or @xcite .",
    "* we provide sharp error bounds for the prior class probability estimate when the covariate shift is ignored .",
    "this approach is called total probability below .",
    "it is useful to consider the use of eq .   for estimating the class probability",
    "@xmath5 $ ] in a more general setting .    [ as : general ] @xmath18 is a probability space .",
    "@xmath19 is a sub-@xmath20-field of @xmath21 , i.e.@xmath22 .",
    "@xmath23 is a probability measure on @xmath24 that is absolutely continuous with respect to @xmath25 , i.e.  @xmath26 .",
    "@xmath27 denotes the expectation operator based on @xmath28 .",
    "the interpretation of assumption  [ as : general ] is as follows :    * @xmath18 is a model that has been fit to historical observations ( e.g.  the training set of a classifier ) . *",
    "@xmath20-field @xmath19 represents the scores produced by the model ( classifier ) while @xmath20-field @xmath21 additionally contains information regarding the classes of the tested examples .",
    "* @xmath29 is the outcome of an application of the model to a different set of  possibly more up - to - date  observations .",
    "@xmath29 could be a representation of the distribution of the scores produced by the classifier . *",
    "the general problem is to extend @xmath23 to @xmath21 , by using information from @xmath18 . * more specifically , the problem might only be to obtain an estimate @xmath30 $ ] for a fixed event ( or class ) @xmath31 , as described in section  [ se : intro ] .",
    "however , to make sure that the estimate is meaningful it should be based on a valid model  which would be an extension of @xmath23 to any @xmath20-field containing @xmath0 .",
    "* @xmath26 is a technical assumption that has intuitive appeal , however . for prediction based on @xmath18 would be pointless if there were events that were possible under @xmath23 but impossible under @xmath32 .",
    "the most obvious extension of @xmath33 to @xmath21 is by means of the conditional probabilities @xmath34 $ ] determined under the measure @xmath35 .",
    "formally , the extension is defined by @xmath36 = \\mathrm{e}_1\\bigl[\\mathrm{p}_0[a\\,|\\,\\mathcal{h}]\\bigr ] , \\ a \\in \\mathcal{a}.\\ ] ] we note without proof that under assumption  [ as : general ] @xmath37 behaves as we might have expected .",
    "[ pr : noproof ] under assumption  [ as : general ] the set function @xmath37 defined by is a probability measure on @xmath38 with @xmath39 and @xmath40 = \\mathrm{p}_0[a\\,|\\,\\mathcal{h}]$ ] .",
    ".   represents the special case of eq .   where @xmath41 is a @xmath20-field generated by a countable partition of @xmath42 .",
    "the odds - based alternative to eq .",
    "requires more effort and works for single events at a time only . for @xmath43",
    "let @xmath44 denote the complement of @xmath45 .",
    "[ as : lr ] assumption  [ as : general ] holds .",
    "an event @xmath46 with @xmath47 \\stackrel{\\text{def}}{= } p_0 < 1 $ ] is fixed .",
    "the two conditional distributions @xmath48 $ ] and @xmath49 $ ] , @xmath50 are absolutely continuous with respect to some @xmath20-finite measure @xmath51 on @xmath24 .",
    "denote by @xmath52 and @xmath53 the @xmath51-densities of @xmath54 $ ] and @xmath55 $ ] respectively .",
    "both @xmath52 and @xmath53 are positive @xmath51-almost everywhere .",
    "the assumption of absolute continuity of the conditional distributions is not really a restriction because one can always choose @xmath56 .",
    "typically , in practical applications @xmath19 is a proper sub-@xmath20-field of @xmath21 and generated by a statistic like a score function .",
    "it is therefore likely to have @xmath57 lebesgue measure on @xmath58 or @xmath57 some counting measure .",
    "the assumption of positive densities is more restrictive but intuitive because statistical prediction of events that were impossible in the past does not make much sense .",
    "the following proposition provides the general version of eq .  .",
    "we omit its well - known proof .",
    "[ pr : cond.prob ] under assumption  [ as : lr ] , define the conditional likelihood ratio @xmath59 by @xmath60 . then it holds that    * @xmath61 is a @xmath51-density of @xmath25 , and * @xmath34 $ ] can be represented as @xmath62 = \\frac{p_0}{p_0 + ( 1-p_0)\\,\\lambda_0}.$ ]    consider the special case of @xmath63 in proposition  [ pr : cond.prob ] .",
    "it holds that @xmath64 = 1 \\",
    "\\iff\\ \\mu(f_a \\not= f_{a^c } ) = 0 \\ \\iff\\ \\mathcal{h}\\ \\text{and}\\ a\\ \\text{are independent}.\\ ] ] this case is not of much interest for classification problems because it means that @xmath19 does not carry any information with regard to @xmath0 or @xmath9",
    ". we will therefore exclude it from the following discussions .",
    "but note that by the absolute continuity requirement of assumption  [ as : general ] @xmath65 = 1 $ ] implies @xmath66 = 1 $ ] but @xmath65 < 1 $ ] in general is not sufficient for @xmath66 < 1 $ ] .    with proposition  [ pr : cond.prob ] , we are in a position to state the main result of this note",
    ". denote by @xmath67 the indicator function of the event @xmath45 , i.e.  @xmath68 for @xmath69 and @xmath70 for @xmath71 .",
    "[ th : main ] let assumption  [ as : lr ] hold and define the likelihood ratio @xmath59 as in proposition  [ pr : cond.prob ] .",
    "suppose that @xmath66 < 1 $ ] .",
    "* there exists a solution @xmath72 to the equation @xmath73\\ ] ] if and only if @xmath74 > 1 $ ] and @xmath75 > 1 $ ] . if there is a solution @xmath72 to eq .",
    "it is unique .",
    "* let @xmath76 denote the @xmath20-field generated by @xmath19 and @xmath0 .",
    "then it holds that @xmath77 * if there is a solution @xmath72 to eq .   define @xmath78 $ ] for @xmath79 by @xmath80 = \\mathrm{e_1}\\left[\\mathbf{1}_{h}\\,\\frac{p_1}{p_1 + ( 1-p_1)\\,\\lambda_0}\\right ] +      \\mathrm{e_1}\\left[\\mathbf{1}_{g}\\,\\frac{(1-p_1)\\,\\lambda_0}{p_1 + ( 1-p_1)\\,\\lambda_0}\\right],\\ ] ] for any representation @xmath81 of @xmath82 with @xmath83 .",
    "then @xmath84 is a probability measure on @xmath85 with @xmath39 . *",
    "the conditional probability @xmath86 $ ] is given by @xmath87 = \\frac{p_1}{p_1 + ( 1-p_1)\\,\\lambda_0}.\\ ] ]    the proof of theorem  [ th : main ] is given in section  [ se : proofs ] below .",
    "let us note here instead some observations on theorem  [ th : main ] :    * the definition of @xmath84 and eq .",
    "imply @xmath88 = p_1 $ ] .",
    "hence we have shown that , by means of eq .  , the total odds approach provides a properly modelled population ( or test set ) estimate of the unconditional probability of class @xmath0 if the condition for likelihood ratio @xmath59 from theorem  [ th : main ] ( i ) is satisfied . * from proposition",
    "[ pr : cond.prob ] ( ii ) and theorem  [ th : main ] ( iv ) it follows that @xmath89}{\\mathrm{p}_0[a\\,|\\,\\mathcal{h}]}\\ ,          \\frac{p_0}{(1-p_0 ) } = \\lambda_0 = \\frac{\\mathrm{p}_1^\\ast[a^c\\,|\\,\\mathcal{h}]}{\\mathrm{p}_1^\\ast[a\\,|\\,\\mathcal{h}]}\\ ,          \\frac{p_1}{(1-p_1)}.\\ ] ] hence @xmath59 has an interpretation as relative odds and is the same for both the training set model @xmath32 and the population model @xmath84 .",
    "this justifies the naming of theorem  [ th : main ] . *",
    "the proof of theorem  [ th : main ] ( iv ) ( see section  [ se : proofs ] ) shows that @xmath90 = \\mathrm{e_1}\\left[\\mathbf{1}_{h}\\,\\frac{1}{p_1 + ( 1-p_1)\\,\\lambda_0}\\right ] , \\quad h \\in \\mathcal{h}.\\ ] ] hence , eq .",
    "ensures that the conditional distribution @xmath91 $ ] is properly normalised .",
    "* violation of the condition for @xmath59 from theorem  [ th : main ] ( i ) could be interpreted as evidence that between the observations of @xmath32 and @xmath23 circumstances have changed so much that the two models associated with the measures are incompatible . * in the special case where @xmath41 is a @xmath20-field generated by a countable partition of @xmath42 , eq",
    ".   reads @xmath92}{p_1+(1-p_1)\\,\\frac{\\mathrm{p}_0[h_n\\,|\\,a^c]}{\\mathrm{p}_0[h_n\\,|\\,a]}}.\\ ] ] basically , this is eq .",
    "( 3.11a ) of @xcite , but with a possibly infinite number of ` rating grades ' .",
    "[ co : unique ] the probability measure @xmath84 from theorem  [ th : main ] is unique in the following sense : if @xmath93 is any probability measure on @xmath85 with @xmath94 \\in ( 0,1)$ ] , @xmath95 , and @xmath96}{\\widetilde{\\mathrm{p}}_1[a\\,|\\,\\mathcal{h } ] } \\ ,      \\frac{\\widetilde{\\mathrm{p}}_1[a]}{\\widetilde{\\mathrm{p}}_1[a^c]}\\ = \\ \\lambda_0,\\ ] ] then it follows that @xmath97 .",
    "by corollary  [ co : unique ] , a probability measure on @xmath85 is uniquely determined by the marginal distribution on @xmath19 and the relative odds with respect to the event @xmath0 .",
    "see section  [ se : proofs ] for a proof of the corollary .",
    "the real - world estimation exercise from ( * ? ? ?",
    "* section  4.4 ) shows that the estimates of the unconditional class probability produced by eq .",
    "and eq .",
    "respectively , indeed can be different .",
    "in that example , actually the ` total probability ' estimate made by means of eq .   is better than the estimate by means of eq .",
    "( but still quite poor )  although we have argued above that conceptually the ` total odds ' is more convincing .",
    "hence , it is not clear whether ` total probability ' or ` total odds ' is better for the estimation of unconditional class probabilities .",
    "however , for an important special case of the probability measure @xmath23 ` total odds ' appears to be a more natural approach to the estimation of the unconditional class probabilities than ` total probability ' . under assumption  [ as : lr ] , define the probability measure @xmath98 on @xmath24 by @xmath99 for a fixed @xmath100 . by proposition  [ pr : cond.prob ] ( i ) , @xmath98 is then absolutely continuous with respect to @xmath25 .    intuitively , @xmath98 is a modification of @xmath35 with @xmath101 $ ] replaced by @xmath102 .",
    "but note that @xmath103 $ ] is undefined because @xmath104 ( otherwise the densities @xmath52 and @xmath53 could not be positive @xmath51-almost everywhere ) .",
    "nonetheless , with this intuition in mind it is natural to favour such extensions @xmath105 of @xmath98 to any sub-@xmath20-field of @xmath21 containing @xmath0 that satisfy @xmath106 ` total odds ' as described in theorem  [ th : main ] has this property , and hence provides an unbiased estimator of the unconditional class probability @xmath102 .",
    "[ co : unbiased ] let assumption  [ as : lr ] hold and define the likelihood ratio @xmath59 as in proposition  [ pr : cond.prob ] .",
    "suppose that @xmath65 < 1 $ ] .",
    "let @xmath107 with @xmath108 given by for some @xmath109 .",
    "then @xmath110 is the unique solution of in @xmath111 and for @xmath84 defined as in theorem  [ th : main ] ( iii ) it holds that @xmath88 = q$ ] .",
    "see section  [ se : proofs ] for the proof of corollary  [ co : unbiased ] .",
    "in contrast to ` total odds ' , the ` total probability ' extension of @xmath98 as given by does not satisfy for @xmath112 .",
    "this follows from the next proposition .",
    "[ pr : biased ] under assumption  [ as : lr ] , define the probability measure @xmath98 by .",
    "then it holds that @xmath113    see section  [ se : proofs ] for the proof of proposition  [ pr : biased ] .",
    "the case @xmath114 shows that both inequalities in are sharp .",
    "as @xmath115 is a measure of the classifier s discriminatory power ( bayesian error rate ) , proposition  [ pr : biased ] suggests that the bias of the estimate of @xmath102 is the smaller the more powerful the classifier is .",
    "interestingly enough , there is a slightly different estimation problem for which the practical performance of ` total odds ' is clearly superior to ` total probability ' .",
    "this problem is the estimation of conditional class probabilities if targets for the unconditional class probabilities are independently given .",
    "describe the problem and two standard solution approaches in the context of credit rating systems .    under assumption  [ as : general ] the new problem is described as follows :    * an estimate ( target ) @xmath116 < 1 $ ] for an event @xmath31 is given .",
    "possibly it was produced in a separate , independent estimation exercise .",
    "the problem is to construct conditional probabilities @xmath86 $ ] such that @xmath117 = \\mathrm{e_1}\\bigl[\\mathrm{p}_1^\\ast[a\\,|\\,\\mathcal{h}]\\bigr].\\ ] ] * again , ideally the estimate should be meaningful in the sense of being based on an extension of @xmath23 to any @xmath20-field containing @xmath0 , based on observations as given by @xmath118 .",
    "the simplest , ` total probability ' approach to solving eq .   is by setting @xmath119 = \\frac{\\mathrm{p}^\\ast_1[a ] }         { \\mathrm{e}_1\\bigl[\\mathrm{p}_0[a\\,|\\,\\mathcal{h}]\\bigr]}\\,\\mathrm{p}_0[a\\,|\\,\\mathcal{h}].\\ ] ] this approach is unsatisfactory because it is possible that @xmath86 > 1 $ ] with positive probability under @xmath23 .",
    "of course , this could be interpreted as evidence of incompatibility as in the case of violation of the likelihood ratio condition in theorem  [ th : main ] ( i ) .",
    "present an alternative approach which uses the ` change of base rate ' theorem ( * ? ? ?",
    "* theorem  2 ) .",
    "however , the solution by that approach in general does not solve because in practice often the outcome is @xmath30 \\not= \\mathrm{e_1}\\bigl[\\mathrm{p}_1^\\ast[a\\,|\\,\\mathcal{h}]\\bigr]$ ] .    an alternative estimation approach suggested by ( * ? ? ?",
    "* section 4.2 ,  scaled likelihood ratio  ) uses theorem  [ th : main ] :    * let @xmath120 $ ] .",
    "solve then the following equation for @xmath121 : @xmath122.\\ ] ] if @xmath59 is non - constant there is a unique solution @xmath123 of eq .  .",
    "* since @xmath124 , theorem  [ th : main ] ( i ) then implies @xmath125 } < c < \\mathrm{e}_1\\left[\\tfrac1{\\lambda_0}\\right].\\ ] ] * moreover , if the measure @xmath84 is defined with @xmath59 replaced by @xmath126 , theorem  [ th : main ] ( iii ) implies that the solution is meaningful because it results in a proper extension of @xmath23 to a @xmath20-field containing @xmath0 .",
    "* by theorem  [ th : main ] ( iv ) , the resulting estimate of the conditional probability @xmath86 $ ] is as follows : @xmath119 = \\frac{p_1}{p_1 + ( 1-p_1)\\,c\\,\\lambda_0}.\\ ] ]    with a view on eq .",
    ", the ` scaled likelihood ratio ' approach could also be called ` total odds ' approach .",
    "results from an estimation exercise on real - world data presented in @xcite suggest that ` total odds ' in general provides better solutions of problem   than ` total probability ' .",
    "@xcite assumed that the marginal distribution @xmath23 in assumption  [ as : general ] was given by a mixture distribution like in .",
    "they suggested estimating the parameter @xmath102 with a maximum likelihood approach . to describe their proposal in more detail , suppose there is a sample @xmath127 of independent observations under @xmath107 .",
    "the likelihood function @xmath128 is then given by @xmath129 with @xmath130 as in proposition  [ pr : cond.prob ] and theorem  [ th : main ] , one then obtains for the log - likelihood function @xmath131 this implies @xmath132 equating the derivative to @xmath133 as a necessary condition for a maximum gives @xmath134 equation is with @xmath135 replaced by @xmath102 and @xmath136 = \\frac 1 n \\sum_{i=1}^n \\mathbf{1}_h(\\omega_i)$ ] , @xmath137 , the empirical distribution associated with the sample @xmath127 .",
    "this observation shows that the sample version of the total odds estimator is identical with the maximum likelihood estimator of @xcite .",
    "based on theorem  [ th : main ] , therefore , we have identified a sufficient and necessary condition for the maximum likelihood estimator to exist ( in the binary classification setting ) . moreover",
    ", the derivation of shows that the maximum likelihood estimator works for any model where the ratio of the conditional class densities equals the relative odds @xmath59 . note that ( * ? ? ?",
    "* eq .  ( 9 ) )",
    "derived but did not discuss the existence of solutions .",
    "the proof of theorem  [ th : main ] is mainly based on the following lemma that generalises theorem  3.3 of @xcite .    [",
    "le : main ] let @xmath138 be a random variable such that @xmath139 < 1 $ ] . then there exists a solution @xmath140 to the equation @xmath141 = 1\\ ] ] if and only if @xmath142 > 1 $ ] and @xmath143 \\ge 1 $ ] .",
    "if there is a solution @xmath140 to eq .",
    "it is unique .",
    "the unique solution is @xmath144 if and only if @xmath143 = 1 $ ] .",
    "* proof . * in principle , the proof in this case is the same as the proof of theorem  3.3 of @xcite .",
    "however , we have to take care of the possibility that @xmath142 = \\infty$ ] or @xmath143 = \\infty$ ] .",
    "define the function @xmath146 \\to ( 0,\\infty]$ ] , @xmath147 by @xmath148.\\ ] ] then for @xmath149 we have @xmath150 solely for @xmath144 it may happen that @xmath151 , depending on whether or not @xmath152 is integrable . by the dominated convergence theorem @xmath153 is continuous in @xmath154 $ ] .",
    "if @xmath155 < \\infty$ ] then again by the dominated convergence theorem @xmath153 is also continuous in @xmath144 since @xmath156 .",
    "however , fatou s lemma implies that @xmath157 $ ] even if @xmath155 = \\infty$ ] .",
    "the function @xmath158 is twice continuously differentiable in @xmath111 with @xmath159 for fixed @xmath160 the random variable @xmath161 is integrable because it holds that @xmath162 hence it follows from the dominated convergence theorem that also @xmath145 as defined by is continuously differentiable in @xmath111 .",
    "moreover , since @xmath163 on @xmath164 and @xmath139 < 1 $ ] we obtain that the derivative of @xmath145 is strictly increasing for @xmath165 ( strict convexity ) . together with the ( quasi-)continuity of @xmath145 this observation implies uniqueness of any solution @xmath166 to if there is one .",
    "the strict convexity of @xmath145 implies that the graph of @xmath145 must look like one of the three stylised graphs in figure  [ fig:1 ] . only in case",
    "b is there a solution to eq .",
    "other than @xmath167 .",
    "case  b is characterised by the two conditions @xmath168 we have seen above that @xmath169 $ ] .",
    ".   implies by means of a combination of the dominated convergence theorem and fatou s lemma that for both the case @xmath142",
    "< \\infty$ ] and the case @xmath142 = \\infty$ ] we have @xmath170 = \\mathrm{e}[x ] - 1.\\ ] ] this proves the existence part of the lemma .",
    "the criterion for the solution to to be @xmath144 also follows from @xmath169 $ ] .",
    "@xmath171    * proof of theorem  [ th : main ] . * ( i ) is an immediate conclusion from lemma  [ le : main ] . since @xmath172 is a @xmath20-field ( ii )",
    "follows from the observation @xmath173 we begin the proof of ( iii ) with another lemma .",
    "[ le : null ] let @xmath174 . then @xmath175 = 0,\\\\ a^c \\cap h = \\emptyset & \\",
    "\\rightarrow    \\mathrm{e_1}\\left[\\mathbf{1}_{h}\\,\\frac{(1-p_1)\\,\\lambda_0}{p_1 + ( 1-p_1)\\,\\lambda_0}\\right ] = 0 .",
    "\\end{aligned}\\ ] ]    * proof of lemma  [ le : null ] . *",
    "denote by @xmath176 any @xmath19-measurable density of @xmath23 with respect to @xmath32 .",
    "proposition  [ pr : cond.prob ] ( ii ) then implies @xmath177 & = \\mathrm{e_0}\\left[\\varphi\\,\\mathbf{1}_{h}\\,\\frac{\\frac{p_1}{p_0}\\,\\mathrm{p}_0[a\\,|\\,\\mathcal{h } ] }                      { \\frac{p_1}{p_0}\\,\\mathrm{p}_0[a\\,|\\,\\mathcal{h } ] +                       \\frac{1-p_1}{1-p_0}\\,\\mathrm{p}_0[a^c\\,|\\,\\mathcal{h}]}\\right]\\\\              & = \\frac{p_1}{p_0}\\,\\mathrm{e_0}\\left[\\varphi\\,\\mathbf{1}_{h\\cap a}\\,\\frac{1 }                      { \\frac{p_1}{p_0}\\,\\mathrm{p}_0[a\\,|\\,\\mathcal{h } ] +                       \\frac{1-p_1}{1-p_0}\\,\\mathrm{p}_0[a^c\\,|\\,\\mathcal{h}]}\\right]\\\\                      & = 0.\\end{aligned}\\ ] ] the proof of the second implication in lemma  [ le : null ] is almost identical .",
    "@xmath171    * proof of theorem  [ th : main ] continued .",
    "* let @xmath79 with @xmath178 for some @xmath179 .",
    "then it follows that @xmath180 hence @xmath181 and @xmath182 .",
    "lemma  [ le : null ] now implies that @xmath84 is well - defined because it holds for any sets @xmath183 , @xmath184 that @xmath185    the properties @xmath186 = 0 $ ] , @xmath187 = 1 $ ] and @xmath188 = \\mathrm{p}_1[h]$ ] for @xmath50 are obvious .",
    "finite addivity of @xmath84 follows from lemma  [ le : null ] because @xmath189 implies @xmath190 and @xmath191 to complete the proof of ( iii ) we have to show that @xmath84 is @xmath20-continuous in @xmath192 , i.e. @xmath193 = 0,\\ ] ] for any @xmath194 with @xmath195 .",
    "let @xmath196 be such a sequence in @xmath85 with representation @xmath197 , for sequences @xmath198 , @xmath199 in @xmath19 .",
    "note that @xmath200 +                       \\frac{1-p_1}{1-p_0}\\,\\mathrm{p}_0[a^c\\,|\\,\\mathcal{h } ] \\ge                      \\min\\left(\\frac{p_1}{p_0 } , \\frac{1-p_1}{1-p_0}\\right).\\ ] ] therefore , similarly to the proof of lemma  [ le : null ] we see that @xmath201 & \\le \\frac{\\max\\bigl(p_1/p_0 , ( 1-p_1)/(1-p_0)\\bigr ) } { \\min\\bigl(p_1/p_0 , ( 1-p_1)/(1-p_0)\\bigr)}\\ , \\mathrm{e}_0\\left[\\varphi\\,\\bigl(\\mathbf{1}_{h_{n}}\\,\\mathrm{p}_0[a\\,|\\,\\mathcal{h } ] + \\mathbf{1}_{g_{n}}\\,\\mathrm{p}_0[a^c\\,|\\,\\mathcal{h}]\\bigr)\\right]\\\\ & = \\frac{\\max\\bigl(p_1/p_0 , ( 1-p_1)/(1-p_0)\\bigr ) } { \\min\\bigl(p_1/p_0 , ( 1-p_1)/(1-p_0)\\bigr)}\\ , \\mathrm{e}_0[\\varphi\\,\\mathbf{1}_{b_n } ] ,      \\end{aligned}\\ ] ] where @xmath176 is an @xmath19-measurable density as in lemma  [ le : null ] . by the dominated convergence theorem , eq .",
    "follows .    with regard to ( iv ) , observe that by the definition of @xmath37 and the fact that @xmath39 it holds for @xmath50 that @xmath202 =   \\mathrm{p}^\\ast_1[a\\cap h ] = \\mathrm{e}_1^\\ast\\bigl[\\mathbf{1}_h\\,\\mathrm{p}_1^\\ast[a\\,|\\,\\mathcal{h}]\\bigr ] = \\mathrm{e}_1\\bigl[\\mathbf{1}_h\\,\\mathrm{p}_1^\\ast[a\\,|\\,\\mathcal{h}]\\bigr].\\ ] ] this implies ( iv ) because @xmath59 is @xmath19-measurable .",
    "@xmath171    * proof of corollary  [ co : unique ] .",
    "* note that is equivalent to @xmath203 & =   \\frac{\\widetilde{\\mathrm{p}}_1[a]}{\\widetilde{\\mathrm{p}}_1[a ] + ( 1-\\widetilde{\\mathrm{p}}_1[a])\\,\\lambda_0.}\\\\ \\intertext{this implies } 1 & = \\mathrm{e_1}\\left[\\frac{1}{\\widetilde{\\mathrm{p}}_1[a ] + ( 1-\\widetilde{\\mathrm{p}}_1[a])\\,\\lambda_0}\\right ] .",
    "\\end{aligned}\\ ] ] therefore , by theorem  [ th : main ] ( i ) we can conclude that @xmath94 = p_1 $ ] . by theorem",
    "[ th : main ] ( iv ) , it follows that @xmath204 = \\mathrm{p}^\\ast_1[a\\,|\\,\\mathcal{h}]$ ] and hence @xmath205 \\ = \\",
    "\\mathrm{e}_1\\bigl[\\mathbf{1}_h\\,\\mathrm{p}^\\ast_1[a\\,|\\,\\mathcal{h}]\\bigr ] \\ = \\",
    "\\mathrm{p}^\\ast_1[a \\cap h ] , \\quad h \\in \\mathcal{h}.\\ ] ] this implies @xmath97 because @xmath206 is a @xmath207-stable generator of @xmath85 . @xmath171    * proof of corollary  [ co : unbiased ] . *",
    "observe that @xmath208 is a @xmath51-density of @xmath107 .",
    "this implies @xmath209 = \\int \\frac{q\\,f_a + ( 1-q)\\,f_{a^c}}{p_1\\,f_a + ( 1-p_1)\\,f_{a^c}}\\,f_a\\,d\\mu = 1,\\ ] ] if we choose @xmath210 .",
    "as @xmath52 and @xmath53 are positive @xmath51-almost everywhere , @xmath65 < 1 $ ] implies @xmath66 = \\mathrm{q}[\\lambda_0 = 1 ] < 1 $ ] . by theorem",
    "[ th : main ] ( i ) , hence the moment conditions on @xmath59 are satisfied and there is no other solution to than @xmath102 . from this",
    "it follows that @xmath23 can be extended to @xmath85 as defined in theorem  [ th : main ] ( ii ) and that the extension satisfies @xmath88 = q$ ] .",
    "@xmath171    * proof of proposition  [ pr : biased ] . * if @xmath211 then all three parts of equal @xmath212 .",
    "suppose now that @xmath213 . by proposition",
    "[ pr : cond.prob ] ( ii ) we can calculate as follows : @xmath214\\,d q - q & = p_0 \\int f_a\\,\\frac{q\\,f_a + ( 1-q)\\,f_{a^c}}{p_0\\,f_a + ( 1-p_0)\\,f_{a^c}}\\,d\\mu - q\\notag\\\\ & = \\int f_a\\,\\frac{p_0\\,q\\,f_a + p_0\\,(1-q)\\,f_{a^c } - q\\,p_0\\,f_a -q\\ , ( 1-p_0)\\,f_{a^c}}{p_0\\,f_a + ( 1-p_0)\\,f_{a^c}}\\,d\\mu\\notag\\\\ & = ( p_0 - q ) \\int \\frac{f_a\\,f_{a^c}}{p_0\\,f_a + ( 1-p_0)\\,f_{a^c}}\\,d\\mu .",
    "\\label{eq : estimate }      \\end{aligned}\\ ] ] observing that @xmath215 we obtain the first inequality in . with regard to the second inequality , define a probability measure @xmath216 on @xmath24 by @xmath217 \\ = \\ \\int_h f_{a^c}\\,d\\mu , \\quad h \\in \\mathcal{h}.\\ ] ] with @xmath218 then if follows for all @xmath219 $ ] that @xmath220.\\ ] ] note that @xmath221\\ = \\ \\int f_a \\,d\\mu = 1 $ ] .",
    "in addition , since @xmath222 is positive @xmath213 implies @xmath139 < 1 $ ] .",
    "hence we can apply lemma  [ le : main ] to conclude that @xmath144 is the only @xmath223 such that @xmath224 = 1 $ ] .",
    "the proof of lemma  [ le : main ] shows that in this case for @xmath165 we have @xmath225.\\ ] ] by and , the second inequality in follows .",
    "@xmath171            c.  elkan .",
    "the foundations of cost - sensitive learning . in b.",
    "nebel , editor , _ proceedings of the seventeenth international joint conference on artificial intelligence , ijcai 2001 _ , pages 973978 .",
    "morgan kaufmann , 2001 .",
    "j.c . xue and g.m .",
    "quantification and semi - supervised classification methods for handling changes in class distribution . in _ proceedings of the 15th acm sigkdd international conference on knowledge discovery and data mining _ ,",
    "pages 897906 , new york , 2009 ."
  ],
  "abstract_text": [
    "<S> the law of total probability may be deployed in binary classification exercises to estimate the unconditional class probabilities if the class proportions in the training set are not representative of the population class proportions . </S>",
    "<S> we argue that this is not a conceptually sound approach and suggest an alternative based on the new law of total odds . </S>",
    "<S> we quantify the bias of the total probability estimator of the unconditional class probabilities and show that the total odds estimator is unbiased . </S>",
    "<S> the sample version of the total odds estimator is shown to coincide with a maximum - likelihood estimator known from the literature . </S>",
    "<S> the law of total odds can also be used for transforming the conditional class probabilities if independent estimates of the unconditional class probabilities of the population are available . </S>",
    "<S> + keywords : total probability , likelihood ratio , bayes formula , binary classification , relative odds , unbiased estimator , supervised learning , dataset shift . </S>"
  ]
}