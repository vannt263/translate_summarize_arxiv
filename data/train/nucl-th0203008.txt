{
  "article_text": [
    "recently , we derived a new class of fourth order algorithms for solving both classical@xcite and quantum dynamical@xcite problems .",
    "these algorithms are based on factorizing the evolution operator @xmath0 to fourth order with purely positive coefficients and require knowing the gradient of the force in the classical case and the gradient of the potential in the quantum case .",
    "the resulting algorithms are symplectic or unitary , respectively . while positive coefficients are absolutely necessary for simulating the diffusion process in monte carlo algorithms@xcite , or doing imaginary time projections@xcite , they are not essential in quantum or classical algorithms .",
    "nevertheless , we have shown that this class of _ gradient symplectic algorithms _ is far superior to existing fourth order algorithms with negative coefficients@xcite . in this work , using suzuki s method@xcite of implementing operator time - ordering , we prodouce a class of even more effective algorithms for solving quantum dynamical problems with explicit time - dependent potentials . despite the vast literature on this subject @xcite , we believe our work has initiated a new direction in algorithm development . in the past , one labors assiduously to avoid higher order commutators . here",
    ", we show that their inclusion can yield algorithms of great efficiency .",
    "our algorithm 4a , to be discuss below , is the fastest fourth order algorithm known , needing only four fast fourier transforms ( fft ) per iteration .",
    "this is only twice the computational effort of the second order split - operator method@xcite , but the algorithm can converge at time step sizes an order of magnitude larger .",
    "our optimized algorithms , when compared on an equal effort basis , have fourth order error coefficients that are three orders of magnitude smaller than forest - ruth s algorithm@xcite and a factor of 30 smaller than mclachlan s algorithm@xcite ; both are fourth order algorithms with negative coefficients .    while these gradient symplectic algorithms are very efficient when the potential gradient is known analytically , they remain equally effective when the gradient is obtained numerically@xcite .",
    "these algorithms are of particular interest in solving the time - dependent schrdinger in a large 3d mesh . in 3d , even for a modest grid size of ( 256)@xmath1 , the number of mesh points already exceed 16 millions .",
    "if the wave function array is double precision and complex , its storage alone would have required 268 mb .",
    "for such a large number of grid points , any vector - matrix multiplication would be prohibitively expensive and must be avoided . for our algorithms ,",
    "the costliest computational step is just the use of fft .",
    "the unitary character and the large time step acceptance of these algorithms make them ideal for doing long time quantum simulations .",
    "the key problem in solving the schrdinger equation with time - dependent potentials is the time ordering of operators .",
    "this problem is solved variously in the literature by transforming it into a classical problem@xcite , treating time as another  spatial coordinate\"@xcite ,",
    "introducing auxiliary variables@xcite , etc .. most end up with some sort of time derivative operator , but none has the simplicity of suzuki s method@xcite of directly implementing time - ordering via a _",
    "forward _ time derivative operator .",
    "no time integration is necessary .",
    "since this work is less accessible , but is of special relevance to the operator factorization approach of deriving algorithms , we summarize it in some detail in the next section . in section iii ,",
    "we apply suzuki s method and derive four gradient symplectic algorithms for solving the time - dependent schrdinger equation . in section iv , we use these algorithms to solve the walker - preston model@xcite and compare their convergent properties with existing algorithms . in section",
    "v , we derive one - parameter families of these algorithms and show that they can be further optimized for specific applications .",
    "section vi summarizes our conclusions .",
    "for @xmath2 a time - dependent operator , the evolution equation @xmath3 has the operator solution @xmath4 the time - ordered exponential not only has the conventional expansion @xmath5 but also the more intuitive interpretation @xmath6 there are many ways of solving the time - ordering problem . for this work on operator factorization , we prefer suzuki s method@xcite , which directly implements time ordering without any additional formalism@xcite or auxiliary variables@xcite .",
    "let @xmath7 denotes the _ forward time derivative _ operator @xmath8 such that for any two time - dependent functions @xmath9 and @xmath10 , @xmath11 suzuki s proved@xcite that @xmath12 . \\label{tdecom}\\ ] ] using the more intuitive definition of time - ordering ( [ torder ] ) , and invoking trotter s formula , one proof only requires two lines : @xmath13 = & & \\lim_{n\\rightarrow\\infty}\\bigr ( { \\rm e}^ { { { \\delta t}\\over n}h(t ) }       { \\rm e}^ { { { \\delta t}\\over n}d}\\bigr)^n,\\nonumber\\\\ = & & \\lim_{n\\rightarrow\\infty } { \\rm e}^ { { { \\delta t}\\over n}h(t+\\delta t ) } \\cdots { \\rm e}^ { { { \\delta t}\\over n}h(t+{{2\\delta t}\\over n } ) } { \\rm e}^ { { { \\delta t}\\over n}h(t+{{\\delta t}\\over n } ) } , \\label{altas}\\end{aligned}\\ ] ] where property ( [ fg ] ) has been applied repeatedly and accumulatively .    for the widely applicable case of @xmath14 , where only one of the operator is explicitly dependent on time , the short time evolution of ( [ expth ] ) can be written using ( [ tdecom ] ) as @xmath15}\\psi(t ) , \\label{tindd}\\ ] ] which is just like the time - independent case but with an effective @xmath16 .",
    "this suggests a two - step approach of deriving time - dependent algorithms .",
    "first , decompose @xmath17}$ ] in terms of @xmath18 and @xmath19 using any factorization scheme applicable in the time - independent case .",
    "next , since @xmath20=0 $ ] , factorize exactly @xmath21 and incorporate all time - dependent requirements by applying ( [ fg ] ) .",
    "for example , a second order factorization of ( [ tindd ] ) gives , @xmath22 which is the well known midpoint algorithm for time - dependent problems .",
    "the other second order factorization gives the alternative second order algorithm , @xmath23 thus , for @xmath14 , _ the effect of time - ordering is to increment the time - dependence of each potential operator @xmath24 by the sum of time steps of all the @xmath25 operators to its right_.    for the schrdinger equation with a time - dependent potential , the wave function is evolved forward in a short time @xmath26 by @xmath27}\\psi(0 ) , \\label{schexp}\\ ] ] where @xmath28 , @xmath29 , @xmath30 , @xmath31 we will work in atomic units such that the kinetic energy operator has this standard form .",
    "moreover , to do away with messy notations involving @xmath32 , we will use @xmath33 as the time step variable everywhere .",
    "when @xmath33 appears as the argument of the wave function or potential , it is to be understood that it denotes only the real time step variable @xmath26 without the factor @xmath32 .",
    "( in this way , algorithms can be directly applied to the classical case with @xmath33 purely real without change in form . ) for conciseness , we will always regard the present time step as time zero .",
    "thus , the two second order algorithms for solving the schrdinger equation with step size @xmath26 can be denoted simply as @xmath34    since the kinetic energy operator is diagonal in momentum space , the operator @xmath35 can be implemented as a vector - vector multiplication in fourier space .",
    "every occurrence of @xmath36 requires two ffts , one direct to fourier space for the kinetic energy multiplication , and one inverse back to real space for the potential energy multiplication . to minimize the call for ffts",
    ", one favors algorithms with the fewest occurrence of the kinetic energy operator .",
    "following our two - step approach , we can transcribe any time - independent factorization algorithm into a time - dependent algorithm .",
    "for example , the well known forest - ruth ( fr ) algorithm@xcite(also discovered independently by campostrini and rossi@xcite , and candy and rozmus@xcite ) can now be transcribed to solve time - dependent problems as @xmath37 where , @xmath38 , @xmath39 and @xmath40 , @xmath41 . for easy identification",
    ", we adopt the convention of labelling the time step coefficients of operators @xmath25 and @xmath42 by @xmath43 and @xmath44 respectively , and denote the intermediate time _",
    "arguments _ of @xmath42 by coefficients @xmath45 .",
    "the coefficient of the first operator on the right will be denote by @xmath46 or @xmath47 , followed by paired coefficients of @xmath44 and @xmath43 for @xmath48 .",
    "if one were to decompose @xmath49 only in terms of @xmath35 and @xmath50 , then forest - ruth is the only fourth order algorithm possible with 6 ffts per iteration .",
    "the alternative algorithm with @xmath25 and @xmath42 interchanged , with appropriate modifications of the @xmath45 coefficients , is also possible , but would have required 8 ffts .",
    "notice that some of the coefficients are negative , requiring backward propagation and evaluating the potential at a time prior to the present .",
    "this is a consequence of suzuki s  no - go \" theorem@xcite , which proved that beyond second order , @xmath51 can not be decomposed into a finite products of @xmath52 and @xmath53 with purely positive coefficients @xmath43 and @xmath44 .",
    "thus without exception , all higher order factorization algorithms heretofore proposed in the literature@xcite contain negative coefficients .",
    "it is the search for positive coefficient factorizations schemes@xcite that led one of us to derive fourth order symplectic algorithms for solving classical@xcite and subsequently quantum dynamical@xcite problems . to circumvent suzuki s  no - go \" theorem ,",
    "these factorization schemes employ an additional operator , @xmath54={1\\over\\mu}\\sum_i\\biggl({{\\partial v}\\over{\\partial x_i}}\\biggr)^2,\\ ] ] which is just the square of the gradient of the potential@xcite .",
    "this can be computed analytically or numerically . for brevity ,",
    "we will transcribe four previously derived gradient algorithms@xcite to their time - dependent form . in the next section",
    ", we will describe in more detail the one - parameter family of these algorithms .    our algorithm 4a@xcite",
    "( see also ref.@xcite ) , when applied to the time - dependent case of ( [ schexp ] ) , gives @xmath55 with @xmath56 defined by @xmath57 , \\nonumber\\\\ & & = v(t)+{1\\over 48}\\epsilon^2[v(t),[t , v(t ) ] ] .",
    "% \\nonumber\\\\ % & & = v(t)+{1\\over 48}\\epsilon^2 % \\sum_i{1\\over\\mu}\\bigl({{\\partial v(x_i , t)}\\over{\\partial x_i}}\\bigr)^2 . \\label{superv}\\end{aligned}\\ ] ] note that this is a crucial simplification , because @xmath58=0 $ ] !",
    "thus the addition of the forward time derivative operator @xmath7 causes no additional complication to the gradient term .",
    "( this is very fortunate , because if one were required to keep the alternative double commutator @xmath59 $ ] , this commutator would have given rise to complicated new terms involving @xmath60 and @xmath61 ! ) with the introduction of the gradient term , algorithm 4a can achieve fourth order acccuracy with only four ffts .",
    "note also that in order to minimize the evaluation of the gradient term , the double commutator has been placed at the center .",
    "this choice seems obvious , but there is intrinsic freedom to redistribute the commutator term among the three potential operator without affecting the fourth order convergence of the algorithm .",
    "this is true for all algroithms described below .",
    "we will assume that this redistribution can be done when necessary .",
    "similarly algorithm 4b can be transcribed as @xmath62 where @xmath63 and with @xmath64 given by @xmath65 .",
    "\\label{duperv}\\ ] ] the time - dependent forms of algorithm 4c and 4d are respectively , @xmath66 @xmath67 where @xmath68 is as defined by ( [ superv ] ) .",
    "the number of fft required by each algorithm is given in table [ tabal ] .",
    "to demonstrate the effectiveness of these new algorithms , we use them to solve the walker and preston model@xcite of a diatomic molecule in a strong laser field .",
    "since this problem has been used by many authors@xcite to test their time - dependent algorithms , it is an excellent choice for comparing our algorithms .",
    "the model is defined by the one dimensional hamiltonian ( in atomic units ) , @xmath69 with @xmath70 and where @xmath71 , @xmath72 , @xmath73 , @xmath74 , and @xmath75 .",
    "the wave function is initially chosen to be the morse oscillator ground state , which has the corresponding ground state energy @xmath76 $ ] with @xmath77 . in conformity with the above authors , we discretize the wave function @xmath78 using 64 uniform points at @xmath79 , with @xmath80 .",
    "the natural time scale defined by the laser oscillation frequence is @xmath81 .    in fig.[fone ] , the percentage errors of the total energy , @xmath82 , is plotted as a function of the step size @xmath26 used in the calculation .",
    "@xmath83 is the converged value at very small time steps .",
    "the plotting symbols indicate calculated results .",
    "the lines are monomial fits in either @xmath84 or @xmath85 .",
    "so is our calculation using the second order split - operator algorithm ( [ al2b ] ) .",
    "rs3 is gray and verosky s best convergent results@xcite .",
    "they use a third order algorithm , but the error is degraded by the magnus approximation to second order . both can be well - fitted by a single quadratic @xmath86 , with coefficients @xmath87 and @xmath88 .",
    "these are plotted as lines running through the data .",
    "the convergent range for both is below @xmath89 .",
    "algorithm rs3 requires three times as much effort as so .",
    "for the same amount of computational effort , one can run so three times at @xmath90 and gain an reduction of @xmath91 in its error coefficient .",
    "this projected convergence curve @xmath92 is plotted as a broken line and labelled as so@xmath93 .",
    "for the same effort ( 6 ffts ) one can also run the forest - ruth algorithm and obtain results shown as solid triangles , with a fitted line @xmath94 .",
    "this equal effort comparison clearly demonstrates the greater efficiency of fourth order algorithms . for errors in the range of 0.1 to 0.01 percent",
    ", fr s time step size can be 4 to 6 times as large as so@xmath93 s",
    ". this ratio would increase if greater accuracy is required .",
    "algorithm 4a , which requires only 2/3 the effort of fr , can be fitted by @xmath95 .",
    "this fit is plotted as a dotted line barely visible above the zero error line over the range of the plot .    to discuss the convergence of our gradient symplectic algorithms , we greatly expanded the plotting range in fig.[ftwo ] . here ,",
    "we plot directly the convergence of @xmath96 .",
    "the plotting symbols indicate calculated results .",
    "we retained so and fr for comparison .",
    "the so result is well - fitted by @xmath97 .",
    "algorithm 4c and 4d yielded indistinguishable results , despite the fact that 4d uses only 6 ffts , two less than 4c .",
    "obviously one should not use algorithm 4c in the present case ; we only included it here for completeness .",
    "since the fr algorithm is known to have rather large errors , we have also implemented mclachlan s fourth order algorithm@xcite and obtained results labelled as m. this algorithm requires 8 ffts per iteration and is the best algorithm tested by sanz - serna and portillo@xcite . both fr and m",
    "are examples of fourth order algorithms with negative coefficients .",
    "the step size convergence of all fourth order algorithms can be very well - fitted by @xmath98 .",
    "these are plotted as lines going through data points .",
    "the coefficient @xmath99 for each algorithm is listed in table [ tabal ] . since the computational effort per time step is proportional to the number of ffts , @xmath100 , the error per unit effort , taking into account the variation of step size with effort , would be proportinal to @xmath101 , _",
    "i.e. _ , this is a measure of error of equal computational effort for all fourth order algorithms .",
    "again , for example , algorithm 4a only requires half the number of of ffts as mclachlan s algorithm . at a given @xmath26 in running mclachlan s algorithm",
    ", one can execute algorithm 4a twice at @xmath102 and reduce its error by a factor of @xmath103 .",
    "thus despite the appearance in fig.[ftwo ] , algorithm 4a actually has a much smaller error per unit effort than mclachlan s algorithm .",
    "we normalize this _ equal effort _",
    "error to the value of fr and define the normalized , equal - effort error coefficient as @xmath104 .",
    "this value for each algorithm is listed in table [ tabal ] .",
    "thus , excluding 4c , our gradient algorithms are roughly a factor of @xmath105 smaller in error than fr and a factor of 3 to 8 smaller than mclachlan s algorithm .",
    "a even more useful measure is to consider @xmath106 , which would give the time step size relative to rf for achieving the same error with equal effort .",
    "this is also given in table [ tabal ] . from examining fig.[fone ] and",
    "[ ftwo ] , it certainly seems reasonable that our algorithms can converge at time steps nearly 5 times as large as rf s and on the order of 30 times as large as so@xmath93 s .",
    "we will discuss further optimized algorithms 4acb and 4bda in the next section .",
    "algorithms 4a and 4c are special cases of the more general algorithm @xmath107 by use of a mathematica program@xcite to symbolically combine exponentials of operators , it is easy to determine these positive coefficients to yield a fourth order algorithm . for the above form of the algorithm ,",
    "there is one free parameter , which we will take to be @xmath47 . given @xmath47 ,",
    "the rest of the coefficients are : @xmath108 where @xmath56 here is given by @xmath109 , \\label{vtac}\\ ] ] with @xmath110 , @xmath111 , @xmath112 , and @xmath113 .",
    "\\label{acofac}\\ ] ] for @xmath114 , one has algorithm 4a . for @xmath115 ,",
    "one recovers algorithm 4c .",
    "thus one can change continuously from algorithm 4a to 4c , and beyond , by  dialing \" the parameter @xmath116 . at the upper limit of @xmath117 , @xmath118 , and",
    "the algorithm becomes a variant of algoirthm 4b , where the commutator term remained at the center rather than equally distributed between the two potential operators at positions @xmath119 and @xmath120 .",
    "we shall refer to this algorithm as 4b@xmath93 .",
    "algorithm 4b@xmath93 can be continuously transformed to 4b by redistributing the commutator term from the center to both sides .",
    "for example , one can multiply the central commutator term by a factor @xmath121 and add @xmath122 times the commutator term to each potential operator on the side .",
    "as @xmath123 ranges from 0 to 1 , algorithm 4b@xmath93 is continuously transformed to 4b .",
    "when @xmath123 reaches 1 , the central commutator disappears and the number of ffts collapses from 8 to 6 .",
    "thus both algorithms 4a and 4b are singular end points of this general algorithm with discontinuous changes in the numbers of fft .",
    "algorithm 4b and 4d are special cases of the general algorithm @xmath124 all requiring 6 ffts . here",
    ", we choose @xmath125 as the free parameter .",
    "the coefficients are then @xmath126 here @xmath56 is given by @xmath109 , \\label{vtbd}\\ ] ] with @xmath40 , @xmath127 , and @xmath128 .",
    "\\label{bdofac}\\ ] ] algorithm 4b corresponds to setting @xmath129 and selecting the smaller of the two quadratic solution , @xmath130 .",
    "when @xmath131 , one obtains a variant of algorithm 4d , which we will denote as 4d@xmath93 .",
    "again , one can transform 4d@xmath93 to 4d continuously by distributing the commutator term at positions @xmath119 and @xmath132 to @xmath46 and @xmath120 .",
    "however , in order to keep the number of gradient terms at a minimum , we will not bother with this refinement here . for positive coefficients , we must have @xmath133 . at the upper limit of @xmath134 , @xmath135 , and the algorithm collapses back to algorithm 4a .",
    "thus , there are two continuous families of algorithms , the c - type requiring eight ffts and the d - type requiring six .",
    "they are joined at both ends by algorithms 4a and 4b with discontinuous changes in the numbers of ffts .",
    "( recently , omelyan , mryglod and folk@xcite have considered the one - parameter factorization schemes from 4a to 4c and 4b to 4d separately , without realizing that they can be further extended and joined into one . )",
    "fig.[ftwo ] shows that the fourth order convergence error is negative for algorithm 4a and 4b , and positive for 4c and 4d . since algorithm 4a",
    "can be continuously changed to 4c , and algorithm 4b be transformed to 4d , there must be parameter values such that this fourth order error can be made to vanish .",
    "this immediately suggests a simple strategy for further optimization : for each application , one can first minimized the convergence error for a _ short _ time run with respect to @xmath47 in @xmath136 or @xmath125 in @xmath137 .",
    "one can then use the algorithm at that value and at a large time step , to do long time simulations . since the error term is generally time dependent ,",
    "there is no guarantee that when it is small for one time , it will remain small for all time .",
    "for the important case of periodic time - dependence , one can hope to reduce the bound within which the error can fluctuate .",
    "this seems to work for the present case .    from fig .",
    "[ ftwo ] , as the algorithm is changed continuously from 4a to 4c and back to 4b , one should observe two zero error crossings . in varying @xmath47 in @xmath136 , we only see one .",
    "this suggests that the second crossing is when 4b@xmath1384b , which we did not consider in this work .",
    "the one zero crossing we observed is at @xmath139 , precisely between 4a(@xmath47=0 ) and 4c ( @xmath47=1/6 ) .",
    "a short run ( @xmath140 ) to determine the optimal value for @xmath47 is shown as solid symbols with solid fitting lines in fig.[fthree ] . for @xmath141 and @xmath142 ,",
    "the convergence errors can be well fitted by fourth order lines as shown . at the value of @xmath139",
    ", the fourth order coefficient is an order of magnitude smaller .",
    "we deem it sufficient to determine the zero - crossing parameter value to three - digit accuracy .",
    "the resulting long run is shown as 4acb in fig.[ftwo ] .",
    "as shown in table [ tabal ] , @xmath143 in this case is reduce by an order of magnitude and @xmath144 lengthened to 8.5@xmath145 .",
    "the convergence error curve for 4acb remained very flat in going from @xmath140 to @xmath146 .    in the case of @xmath137 ,",
    "algorithm 4d@xmath93 is sufficiently dissimilar to 4d such that the convergence error remained negative as 4b is morphed to 4d@xmath93 at @xmath147 .",
    "however , as @xmath125 increases above @xmath148 , the convergence error moves up and turns positive . since @xmath137 ends up at 4a , the error must cross zero again on its way down .",
    "the first crossing is at @xmath149 .",
    "this is shown in fig.[fthree ] with hollow symbol connected by fitted , broken lines .",
    "the second crossing is near @xmath150 , but we do not bother to show this similar result .",
    "the long - run results using @xmath151 in @xmath137 is shown on fig.[ftwo ] as 4bda .",
    "as listed in table [ tabal ] , its equal effort error and effective time step factor are virtually identical to those of 4acb . in both cases , without any additional computational effort , we have reduced the error by a factor of five and lengthen the time step size by a factor 1.5@xmath145 .",
    "both algorithms can achieve 10@xmath152 accuracy in total energy at a time step size 50 times as large as so@xmath93 .",
    "a key advantage of these factorization algorithms is that one can obtain analytically their energy error terms by use of mathematica . for fourth order gradient algorithms ,",
    "there are four non - vanishing error operators in the hamiltonian , @xmath153+e_2[ttvtv]+e_3[vtttv]+e_4[ttttv ] ) ,   \\label{er}\\ ] ] where @xmath154 are coefficient functions depending on @xmath47 or @xmath125 , and @xmath155\\equiv[a,[b,[c]]]$ ] , etc .. the zero - crossing values of @xmath47 in @xmath136 and @xmath125 in @xmath137 , are closely matched to the crossing points of the first two error coefficients , @xmath156 . for 4acb and 4bda ,",
    "the predicted zero - crossing values from solving @xmath157 numerically are @xmath158 and @xmath159 respectively , in excellent agreement with empirical values .",
    "it seems that out of the four error operators , only two are dominant and they are opposite in sign .",
    "it should be noted that these crossing points have nothing to do with the minimum of @xmath160 .",
    "these algorithms are not optimized by simply minimizing the sum of squares of error coefficients@xcite .",
    "further discussions on the above one - parameter family of gradient algorithms will be presented in a separate publication .",
    "in this work , we have derived a new class of fourth order algorithms for solving the time - dependent schrdinger equation with explicit time - dependent potentials .",
    "this class of algorithms is characterized by having only positive factorization coefficients and can achieve great efficiency by knowing the gradient of the potential . for the walker - preston model , on an equal effort basis , the convergence errors of these algorithms can be 5000 and 30 times smaller than negative - coefficient algorithms such as the forest - ruth and the mclachlan algorithm , respectively .",
    "these gradient algorithms should be further tested on more realistic problems where the gradient of potential may have to be computed numerically .",
    "our discovery of the one parameter family of gradient algorithms illustrates the power of the operator factorization approach of solving any evolution equation .",
    "the ability to tailor a specific algorithm for a particular application reflects great versatility of our method .",
    "our work encourages further systematic study of these and other parametrized families of algorithm and their optimization .",
    "in particular , one should explore the freedom in redistributing the commutator term@xcite in going from 4b to 4b@xmath93 and from 4d to 4d@xmath93 .",
    "we have not done so here in order to concentrate on algorithms with the minimum number of gradient evaluations . with the development of these powerful gradient algorithms for solving the schrdinger equation directly , we can see no practical advantage in solving the corresponding classical problem@xcite using classical methods .",
    "this is in agreement with sanz - serna and portillo s earlier assessment@xcite .",
    "this work spurs further interest in finding six and higher order factorization algorithms with purely positive coefficients . despite intense effort",
    ", we have yet to find a sixth order factorization scheme with positive coefficients .",
    "it is most likely that one does nt exist , even with the inclusion of the double commutator term .",
    "a recent work@xcite reached the same conclusion , but offered no proof either .",
    "such a proof , if exists , would make these fourth order gradient algorithms unique . there would be no higher order generalizations .",
    "this would raise many other interesting questions , such as what other operators are necessary for a higher order positive time step factorization , what would be the optimal sixth order algorithm with minimal of negative coefficients , etc .. all such investigations would deepen our understanding of the operator factorization method of solving evolution equations .",
    "m. suzuki , in _",
    "computer simulation studies in condensed matter physics viii _ , edited by d. p. landau , k. k. mon , and h .- b .",
    "shttler , springer - verlag , berlin , 1996 .",
    "s. jang , s. jang , and g. voth , j. chem .",
    "phys . * 115 * , 7832 ( 2001 ) .            .",
    "equal computational effort comparison of all fourth order algorithms discussed in this work .",
    "all algorithms except fr and m are our new time - dependent algorithms .",
    "@xmath100 is the numbers of ffts per execution for each algorithm , @xmath161 is the corresponding fourth order error coefficient , @xmath143 is the equal - effort fourth order error coefficient normalized to fr s value , and @xmath144 is the effective time - step size relative to fr s value , _",
    "e.g. _ , for the same amount of effort , algorithm 4acb can achieve the same convergence error of fr at a time step 8.5 times as large . [ cols=\"^,^,^,^,^,^,^,^,^\",options=\"header \" , ]"
  ],
  "abstract_text": [
    "<S> we show that the method of factorizing the evolution operator to fourth order with purely positive coefficients , in conjunction with suzuki s method of implementing time - ordering of operators , produces a new class of powerful algorithms for solving the schrdinger equation with time - dependent potentials . when applied to the walker - preston model of a diatomic molecule in a strong laser field </S>",
    "<S> , these algorithms can have fourth order error coefficients that are three orders of magnitude smaller than the forest - ruth algorithm using the same number of fast fourier transforms . </S>",
    "<S> when compared to the second order split - operator method , some of these algorithms can achieve comparable convergent accuracy at step sizes 50 times as large . </S>",
    "<S> morever , we show that these algorithms belong to a one - parameter family of algorithms , and that the parameter can be further optimized for specific applications .    </S>",
    "<S> pacs : 31.15.-p , 02.70.hm , 03.65.-w + keywords : time - dependent schrdinger equation , time - dependent potential , time - dependent hamiltonian , operator splitting , symplectic integrators . </S>"
  ]
}