{
  "article_text": [
    "the massive growth of available data has moved data analysis and machine learning to center stage in many industrial as well as scientific fields , ranging from web and sensor data to astronomy , health science , and countless other applications . with the increasing size of datasets ,",
    "machine learning methods are limited by the scalability of the underlying optimization algorithms to train these models , which has spurred significant research interest in recent years .",
    "however , practitioners face a significant problem arising with the larger model complexity in large - scale machine learning and in particular deep - learning methods - it is increasingly hard to diagnose if the optimization algorithm used for training works well or not . with the optimization algorithms also becoming more complex ( e.g. , in a distributed setting )",
    ", it can often be very hard to pin down if _ bad performance of a predictive model either comes from slow optimization , or from poor modeling choices .",
    "_ in this light , easily verifiable guarantees for the quality of an optimization algorithm are very useful  note that the optimum solution of the problem is unknown in most cases .",
    "for convex optimization problems , a primal - dual gap can serve as such a certificate .",
    "if available , the gap also serves as a useful stopping criterion for the optimizer .",
    "so far , the majority of popular optimization algorithms for learning applications comes without a notion of primal - dual gap . in this paper",
    ", we aim to change this for a relevant class of machine learning problems .",
    "we propose a primal - dual framework which is algorithm - independent , and allows to equip existing algorithms with additional primal - dual certificates as an add - on .",
    "our approach is motivated by the recent analysis of sdca @xcite .",
    "we extend their setting to the significantly larger class of convex optimization problems of the form @xmath1 for a given matrix @xmath2 , @xmath3 being smooth , and @xmath4 being a general convex function .",
    "this problem class includes the most prominent regression and classification methods as well as generalized linear models .",
    "we will formalize the setting in more details in section [ sec : primaldual ] , and highlight the associated dual problem , which has the same structure .",
    "an overview over some popular examples that can be formulated in this setting either as primal or dual problem is given in table [ tbl : mlproblems ] .",
    "* contributions . *",
    "the main contributions in this work can be summarized as follows :    * our new primal - dual framework is algorithm - independent , that is it allows users to equip existing algorithms with primal - dual certificates and convergence rates . *",
    "we introduce a new lipschitzing trick allowing duality gaps ( and thus accuracy certificates ) which are globally defined , for a large class of convex problems which did not have this property so far .",
    "our approach does not modify the original problems in the region of interest .",
    "in contrast to existing methods adding a small strongly - convex ( @xmath5 ) term as , e.g. , in  @xcite , our approach leaves both the algorithms and the optima unaffected . * compared with the well - known duality setting of sdca @xcite which is restricted to strongly convex regularizers and finite sum optimization problems , our framework encompasses a significantly larger class of problems .",
    "we obtain new primal - dual convergence rates , e.g. , for the lasso as well as many @xmath0 , elastic net , group lasso and tv - regularized problems .",
    "the theory applies to any norm - regularized generalized linear model . *",
    "existing primal - dual guarantees for the class of erm problems with lipschitz loss from @xcite ( e.g. , svm ) are valid only for an `` average '' iteration .",
    "we show that the same rate of convergence can be achieved , e.g. , for accelerated sdca , but without the necessity of computing an average iterate . *",
    "our primal - dual theory captures a more precise notion of data - dependency compared with existing results ( which relied on per - coordinate information only ) . to be precise",
    ", our shown convergence rate for the general algorithms is dependent on the _ spectral norm of the data _ , see also @xcite .",
    "* linearized admm solvers . * for the problem structure of our interest here , one of the most natural algorithms is the splitting method known as the chambolle - pock algorithm ( also known as primal - dual hybrid gradient , arrow - hurwicz method , or linearized admm ) @xcite . while this algorithm can give rise to a duality gap , it is significantly less general compared to our framework . in each iteration",
    ", it requires a complete solution of the proximal operators of both @xmath3 and @xmath4 , which can be computationally expensive .",
    "its convergence rate is sensitive to the used step - size @xcite .",
    "our framework is not algorithm - specific , and holds for arbitrary iterate sequences .",
    "more recently , the spdc method @xcite was proposed as a coordinate - wise variant of @xcite , but only for strongly convex @xmath4 .    * stochastic coordinate solvers .",
    "* coordinate descent / ascent methods have become state - of - the - art for many machine learning problems @xcite . in recent years",
    ", theoretical convergence rate guarantees have been developed for the primal - only setting , e.g. , by @xcite , as well as more recently also for primal - dual guarantees , see , e.g. , @xcite .",
    "the influential stochastic dual coordinate ascent ( sdca ) framework @xcite was motivated by the @xmath5-regularized svm , where coordinate descent is very efficient on the dual svm formulation , with every iteration only requiring access to a single datapoint ( i.e. a column of the matrix @xmath6 in our setup ) .",
    "in contrast to primal stochastic gradient descent ( sgd ) methods , the sdca algorithm family is often preferred as it is free of learning - rate parameters , and has a fast linear ( geometric ) convergence rate .",
    "sdca and recent extensions @xcite require @xmath4 to be strongly convex .    under the weaker assumption of weak strong convexity @xcite ,",
    "a linear rate for the primal - dual convergence of sdca was recently shown by @xcite .    in the lasso literature ,",
    "a similar trend in terms of solvers has been observed recently , but with the roles of primal and dual problems reversed .",
    "for those problems , coordinate descent algorithms on the primal formulation have become the state - of - the - art , as in glmnet  @xcite and extensions @xcite . despite the prototypes of both problem types ",
    "svm for the @xmath7-regularized case and lasso for the @xmath8-regularized case  being closely related @xcite , we are not aware of existing primal - dual guarantees for coordinate descent on unmodified @xmath0-regularized problems .    [ cols=\"<,<,^,<,<,^ \" , ]        & @xmath9",
    "& for @xmath10 or @xmath11 + & least squares & @xmath12 & for @xmath10 or @xmath11 +    [ tbl : mlproblems ]    * comparison to smoothing techniques . * existing techniques for bringing @xmath8-regularized and related problems into a primal - dual setting compatible with sdca do rely on the classical nesterov - smoothing approach - by adding a small amount of @xmath7 to the part @xmath4 , the objective becomes strongly convex ; see , e.g. ,  @xcite . however , the appropriate strength of smoothing is difficult to tune .",
    "it will depend on the accuracy level , and will influence the chosen algorithm , as it will change the iterates , the resulting convergence rate as well as the tightness of the resulting duality gaps .",
    "the line of work of @xcite provides duality gaps for smoothed problems and rates for proximally tractable objectives @xcite and also objectives with efficient fenchel - type operator @xcite . in contrast , our approach preserves all solutions of the original @xmath8-optimization  it leaves the iterate sequences of existing algorithms unchanged , which is desirable in practice , and allows the reusability of existing solvers .",
    "we do not assume proximal or fenchel tractability .",
    "* distributed algorithms . * for @xmath8-problems exceeding the memory capacity of a single computer , a communication - efficient distributed scheme leveraging this lipschitzing trick is presented in @xcite .",
    "in this paper , we consider optimization problems of the following primal - dual structure .",
    "as we will see , the relationship between primal and dual objectives has many benefits , including computation of the duality gap , which allows us to have certificates for the approximation quality .",
    "we consider the following pair of optimization problems , which are dual . ] to each other : @xmath13,\\   \\\\",
    "\\label{eq : b}\\tag{b}\\quad          \\min _ { { { \\bf w}}\\in { \\mathbb{r}}^{d } } \\quad & \\big [ \\ \\       { \\mathcal{p } } ( { { \\bf w } } ) : = & & f^ * ( { { \\bf w } } )      \\ + \\ g^*(-a^\\top { { \\bf w } } ) & \\!\\!\\big].\\ \\end{aligned}\\ ] ] the two problems are associated to a given data matrix @xmath2 , and the functions @xmath14 and @xmath15 are allowed to be arbitrary closed convex functions . here",
    "@xmath16 and @xmath17 are the respective variable vectors .",
    "the relation of and is called _ fenchel - rockafellar duality _ where the functions @xmath18 in formulation   are defined as the _ _ convex conjugates__. ] of their corresponding counterparts @xmath19 in  .",
    "the two main powerful features of this general duality structure are first that it includes many more machine learning methods than more traditional duality notions , and secondly that the two problems are fully symmetric , when changing respective roles of  @xmath3 and  @xmath4 . in typical machine learning problems ,",
    "the two parts typically play the roles of a data - fit ( or loss ) term as well as a regularization term .",
    "as we will see later , those two roles can be swapped , depending on the application .    * optimality conditions . *",
    "the first - order optimality conditions for our pair of vectors @xmath20 in problems   and are given as    @xmath21    @xmath22    see , e.g. ( * ? ? ?",
    "* proposition 19.18 ) .",
    "the stated optimality conditions are equivalent to @xmath23 being a saddle - point of the lagrangian , which is given as @xmath24 if @xmath25 and @xmath26",
    ". * duality gap .",
    "* from the definition of the dual problems in terms of the convex conjugates , we always have @xmath27 , giving rise to the definition of the general duality gap @xmath28 .    for differentiable @xmath3",
    ", the duality gap can be used more conveniently : given @xmath29 s.t .",
    "@xmath30 in the context of  , a corresponding variable vector @xmath17 for problem   is given by the first - order optimality condition   as @xmath31 under strong duality , we have @xmath32 and @xmath33 , where @xmath34 is an optimal solution of .",
    "this implies that the suboptimality @xmath35 is always bounded above by the simpler duality gap function @xmath36 which hence acts as a certificate of the approximation quality of the variable vector @xmath37 .",
    "in this section we state an important lemma , which will later allow us to transform a suboptimality guarantee of any algorithm into a duality gap guarantee , for optimization problems of the form specified in the previous section .",
    "[ lemma : dualitygapanddualsuboptimality ] consider an optimization problem of the form  .",
    "let @xmath3 be @xmath38-smooth w.r.t . a norm @xmath39 and let @xmath4 be @xmath40-strongly convex with convexity parameter @xmath41 w.r.t .",
    "a norm @xmath42 .",
    "the general convex case @xmath43 is explicitly allowed , but only if @xmath4 has bounded support .",
    "then , for any @xmath44 and any @xmath45 $ ] , it holds that @xmath46 where @xmath47 is the gap function defined in and @xmath48    we note that the improvement bound here bears similarity to the proof of ( * ? ? ?",
    "* prop 4.2 ) for the case of an extended frank - wolfe algorithm .",
    "in contrast , our result here is algorithm - independent , and leads to tighter results due to the more careful choice of @xmath49 , as we ll see in the following .      in this section",
    "we assume that we are using an arbitrary optimization algorithm applied to problem  .",
    "it is assumed that the algorithm produces a sequence of ( possibly random ) iterates @xmath50 such that there exists @xmath51 , d \\geq 0 $ ] such that @xmath52    \\leq ( 1-c)^t \\ d.\\ ] ] in the next two theorems , we define @xmath53 , i.e. , the squared spectral norm of the matrix @xmath6 in the euclidean norm case .",
    "let us assume @xmath4 is @xmath40-strongly convex ( @xmath54 ) ( equivalently , its conjugate @xmath55 has lipschitz continuous gradient with a constant @xmath56 ) .",
    "the following theorem provides a linear convergence guarantee for any algorithm with given linear convergence rate for the suboptimality @xmath57 .",
    "[ thm : convfastscg ] assume the function @xmath3 is @xmath38-smooth w.r.t .",
    "a norm @xmath39 and @xmath4 is @xmath40-strongly convex w.r.t .",
    "a norm @xmath42 .",
    "suppose we are using a linearly convergent algorithm as specified in .",
    "then , for any @xmath58 it holds that @xmath59 \\leq \\epsilon$ ] .    from we",
    "can obtain that after @xmath60 iterations , we would have a point @xmath61 such that @xmath62\\leq \\epsilon$ ] .",
    "hence , comparing with only few more iterations are needed to get the guarantees for the duality gap .",
    "the rate   is achieved by most of the first order algorithms , including proximal gradient descent @xcite or sdca @xcite with @xmath63 or accelerated sdca @xcite with @xmath64 .      in this section",
    "we will assume that @xmath55 is lipschitz ( in contrast to smooth as in theorem [ thm : convfastscg ] ) and show that the linear convergence rate is preserved .",
    "[ thm : convfastlipsch ] assume that the function @xmath3 is @xmath38-smooth w.r.t .",
    "a norm @xmath65 , @xmath55 is @xmath66-lipschitz continuous w.r.t the dual norm @xmath67 , and we are using a linearly convergent algorithm . then , for any @xmath68 it holds that @xmath59 \\leq \\epsilon$ ] .    in @xcite",
    ", it was proven that feasible descent methods when applied to the dual of an svm do improve the objective geometrically as in .",
    "later , @xcite extended this to stochastic coordinate feasible descent algorithms ( including sdca ) . using our new theorem [ thm : convfastlipsch ]",
    ", we can therefore extend their results to linear convergence for the duality gap for the svm application .",
    "in this case we will focus only on general @xmath66-lipschitz continuous functions @xmath55",
    "( if @xmath4 is strongly convex , then many existing algorithms are available and converge with a linear rate ) .",
    "+ we will assume that we are applying some ( possibly randomized ) algorithm on optimization problem which produces a sequence ( of possibly random ) iterates @xmath50 such that @xmath69    \\leq \\tfrac{c}{d(t)},\\ ] ] where @xmath70 is a function wich has usually a linear or quadratic growth ( i.e. @xmath71 or @xmath72 ) .",
    "the following theorem will allow to equip existing algorithms with sub - linear convergence in suboptimality , as specified in  , with duality gap convergence guarantees .",
    "[ thm : convboundsup ] assume the function @xmath3 is @xmath38-smooth w.r.t .",
    "the norm @xmath65 , @xmath55 is @xmath66-lipschitz continuous , w.r.t .",
    "the dual norm @xmath67 , and we are using a sub - linearly convergent algorithm as quantified by . then , for any @xmath73 such that @xmath74 it holds that @xmath59 \\leq \\epsilon$ ] .",
    "let us comment on theorem [ thm : convboundsup ] stated above . if @xmath71 then this shows a rate of @xmath75 .",
    "we note two important facts :    1 .",
    "the guarantee holds for the duality gap of the iterate @xmath76 and not for some averaged solution .",
    "2 .   for the svm case ,",
    "this rate is consistent with the result of @xcite .",
    "our result is much more general as it holds for any @xmath66-lipschitz continuous convex function @xmath55 and any @xmath77-strongly convex @xmath78 .",
    "let us make one more important remark .",
    "in @xcite the authors showed that sdca ( when applied on @xmath66-lipschitz continuous @xmath55 ) has @xmath71 and they also showed that an averaged solution ( over few last iterates ) needs only @xmath79 iterations to have duality gap @xmath80 .",
    "however , as a direct consequence of our theorem  [ thm : convboundsup ] we can show , e.g. , that fista @xcite ( aka .",
    "accelerated gradient descent algorithm ) or approx @xcite being separable . ]",
    "( a.k.a . accelerated coordinate descent algorithm ) will need @xmath79 iterations to produce an iterate @xmath37 such that @xmath81 .",
    "indeed , e.g. , for approx , the function @xmath82 ( where @xmath83 is the size of a mini - batch ) and @xmath84 is a constant which depends on @xmath85 and @xmath34 and @xmath83 .",
    "hence , to obtain an iterate @xmath61 such that @xmath86\\leq \\epsilon$ ] it is sufficient to choose @xmath87 such that @xmath88 is satisfied .",
    "in this section we present a trick that allows to generalize our results of the previous section from lipschitz functions  @xmath55 to non - lipschitz functions .",
    "the approach we propose , which we call the _ lipschitzing trick _ , will make a convex function lipschitz on the entire domain  @xmath89 , by modifying its conjugate dual to have bounded support .",
    "formally , the modification is as follows : let @xmath90 be some closed , bounded convex set .",
    "we modify @xmath91 by restricting its support to the set @xmath92 , i.e. @xmath93 by definition , this function has bounded support , and hence , by lemma [ lem : duallipschitz ] , its conjugate function @xmath94 is lipschitz continuous",
    ".    * motivation .",
    "* we will apply this trick to the part @xmath4 of optimization problems of the form ( such that @xmath55 will become lipschitz ) .",
    "we want that this modification to have no impact on the outcome of any optimization algorithm running on  . instead , this trick should only affect convergence theory in that it allows us to present a strong primal - dual rate . in the following , we will discuss how this can indeed be achieved by imposing only very weak assumptions on the original problem  .",
    "the modification is based on the following duality of lipschitzness and bounded support , as given in lemma  [ lem : duallipschitz ] below , which is a generalization of  ( * ? ? ?",
    "* corollary 13.3.3 ) .",
    "we need the following definition :    [ def : lbounded ] a function @xmath95 has _",
    "@xmath96-bounded support _ if its effective domain is bounded by @xmath96 w.r.t .",
    "a norm @xmath65 , i.e. , @xmath97    [ lem : duallipschitz ] given a proper convex function @xmath4 , it holds that @xmath4 has @xmath66-bounded support w.r.t .",
    "the norm @xmath65 if and only if @xmath55 is @xmath66-lipschitz w.r.t . the dual norm @xmath67 .    the following theorem [ thm : convgeneral ] generalizes our previous convergence results , which were restricted to lipschitz @xmath55 .",
    "[ thm : convgeneral ]    for an arbitrary optimization algorithm running on problem  , let @xmath61 denote its iterate sequence .",
    "assume there is some closed convex set @xmath92 containing all these iterates .",
    "then , the same optimization algorithm run on the modified problem  given by lipschitzing of @xmath55 using @xmath92  would produce exactly the same iterate sequence .",
    "furthermore , theorem  [ thm : convfastlipsch ] as well as theorem  [ thm : convboundsup ] give primal - dual convergence guarantees for this algorithm ( for @xmath66 such that @xmath92 is @xmath66-bounded ) .",
    "assume the objective of optimization problem   has bounded level sets . for @xmath61 being the iterate sequence of a _ monotone _",
    "optimization algorithm on problem   we denote @xmath98 and let @xmath99 be the @xmath100-level set of @xmath101 .",
    "write @xmath102 for a value such that @xmath99 is @xmath103-bounded w.r.t . the norm @xmath65 .",
    "then , at any state @xmath104 of the algorithm , the set @xmath99 contains all future iterates and theorem [ thm : convgeneral ] applies for @xmath105 .",
    "node[above , at end]@xmath106(-1,0.5 ) ; ( -1.5,0 ) ",
    "node[right , at end]@xmath107(-0.5,0 ) ; ( -1,0 )  ( -1.5,0.5 ) ; ( -1,0 ) ",
    "( -0.5,0.5 ) ; ( -1,0 ) ",
    "( -1.4,0.4 ) ; ( -1,0 ) ",
    "( -0.6,0.4 ) ; ( -1.4,0.4 ) ",
    "node[below , at end , black]@xmath108(-1.4,0 ) ; ( -1.4,0.4 )  ( -1.4,0.6 ) ; ( -0.6,0.4 )  node[below ,",
    "at end , black]@xmath96(-0.6,0 ) ; ( -0.6,0.4 )  ( -0.6,0.6 ) ; ( 0.5,0 )  node[above , at end]@xmath109(0.5,0.5 ) ; ( 0,0 )  node[right , at end]@xmath110(1,0 ) ; ( 0.8,0 )  ( 0.8,0.5 ) ; ( 0.2,0 )  ( 0.2,0.5 ) ; ( 0.2,0 )  ( 0.8,0 ) ; ( 0.2,0 )  ( 0.8,0 ) ; ( 0.8,0 )  ( 0.9,0.5 ) ; ( 0.2,0 )  ( 0.1,0.5 ) ; ( -0.2,0 )  node[black , above , at end]@xmath111(-0.2,0.2 ) ;    -0.4",
    "cm      we now focus on some applications .",
    "first , we demonstrate how the lipschitzing trick can be applied to find primal - dual convergence rates for problems regularized by an arbitrary norm .",
    "we discuss in particular the lasso problem and show how the suboptimality bound can be evaluated in practice . in a second part",
    ", we discuss the elastic net regularizer and show how it fits into our framework .",
    "we consider a special structure of problem , namely @xmath112 where @xmath3 is some convex non - negative smooth loss function regularized by any norm @xmath65 .",
    "we choose @xmath92 to be the @xmath65-norm ball of radius @xmath96 , such that @xmath113 for every iterate .",
    "the size , @xmath96 , of this ball can be controled by the amount of regularization @xmath114 . using the lipschitzing trick with this @xmath92 , the convergence guarantees of theorem [ thm : convgeneral ] apply to the general class of norm regularized problems .",
    "note that for any monotone algorithm ( initialized at @xmath115 ) applied to we have @xmath116 for every iterate .",
    "furthermore , at every iterate @xmath37 we can bound @xmath117 for every future iterate @xmath118 .",
    "hence , @xmath119 is a safe choice , e.g. @xmath120 for least squares loss and @xmath121 for logistic regression loss .",
    "* duality gap .",
    "* for any problem of the form we can now determine the duality gap .",
    "we apply the lipschitzing trick to @xmath122 as in , then the convex conjugate of @xmath123 is @xmath124 where @xmath67 denotes the dual norm of @xmath65 .",
    "hence , using the primal - dual mapping @xmath125 we can write the duality gap of the modified problem as @xmath126 note that the computation of the modified duality gap @xmath127 is not harder than the computation of the original gap @xmath47 - it requires one pass over the data , assuming the choice of a suitable set @xmath92 in .",
    "furthermore , note that in contrast to the unmodified duality gap @xmath47 , which is only defined on the set @xmath128 , our new gap @xmath127 is defined on the entire space  @xmath89 .    as an alternative , ( * ? ? ?",
    "1.4.1 and app .",
    "d.2 ) has defined a different duality gap by shrinking the dual @xmath129 variable until it becomes feasible in @xmath130 .",
    "the results from the previous section can be ported to the important special case of @xmath0-regularization : @xmath131 we choose @xmath92 to be the @xmath0-norm ball of radius @xmath96 and then apply the lipschitzing trick with @xmath92 to the regularization term in .",
    "an illustration of this modification as well as the impact on its dual are illustrated in figure [ fig : lipschitzingtrick ] .",
    "hence , our theory ( theorem [ thm : convgeneral ] ) gives primal - dual convergence guarantees for any algorithm applied to the lasso problem  .",
    "furthermore , if the algorithm is monotone ( initialized at @xmath132 ) we know that @xmath92 is @xmath133-bounded .",
    "* duality gap . *",
    "the duality gap for the modified lasso problem can be computed at every iterate @xmath37 as @xmath134_+ + \\lambda \\| { { \\boldsymbol \\alpha}}\\|_1\\label{eq : glasso}\\ ] ] for @xmath135 . for the derivation ,",
    "see appendix [ sec : dualitygaplasso ] .",
    "our algorithm - independent , primal - dual convergence guarantees and certificates presented so far are not restricted to @xmath136-regularized problems , but do in fact directly apply to many more general structured regularizers , some of them shown in see table  [ tbl : mlproblems ] .",
    "this includes group lasso ( @xmath137 ) and other norms inducing structured sparsity @xcite , as well as other penalties such as e.g. the fused lasso @xmath138 .",
    "the total variation denoising problem is obtained for suitable choice of the matrix @xmath139 .",
    "the second application we will discuss is elastic net regularization @xmath140 for fixed trade - off parameter @xmath141 $ ] .",
    "our framework allows two different ways to solve problem  : either mapping it to formulation ( for @xmath142=@xmath3 smooth ) as in row  2 of table [ tbl : mlproblems ] , or to ( for general @xmath142 ) as in row  3 of table  [ tbl : mlproblems ] . in both scenarios ,",
    "theorem [ thm : convfastscg ] gives us a fast linear convergence guarantee for the duality gap , if  @xmath142 is smooth .",
    "the other theorems apply accordingly for general  @xmath142 when the problem is mapped to . + whether the choice of a dual or primal optimizer will be more beneficial in practice depends on the case , and will be discussed in more detail for coordinate descent methods in section [ sec : cd ] .",
    "* duality gap .",
    "* for the elastic net problem mapped to  , we can compute the duality gap as follows : @xmath143_+^2\\\\ & + \\lambda \\left(\\tfrac{\\eta}{2 } \\| { { \\boldsymbol \\alpha}}\\|_2 ^ 2 + ( 1-\\eta)\\| { { \\boldsymbol \\alpha}}\\|_1\\right)\\end{aligned}\\ ] ] with @xmath144 , see appendix [ sec : dualitygapelastic ] .",
    "as @xmath145 we approach the pure @xmath0-case and this gap blows up as @xmath146 . comparing this to",
    ", we see that the lipschitzing trick allows to get certificates even in cases where the duality gap of the unmodified problem is infinity .",
    "we now focus on a very important class of algorithms , that is coordinate descent methods . in this section ,",
    "we show how our theory implies much more general primal - dual convergence guarantees for coordinate descent algorithms",
    ".    * partially separable problems . *",
    "a widely used subclass of optimization problems arises when one part of the objective becomes separable .",
    "formally , this is expressed as @xmath147 for univariate functions @xmath148 for @xmath149 $ ] . nicely in this case , the conjugate of @xmath4 also separates as @xmath150 .",
    "therefore , the two optimization problems and write as @xmath151 where @xmath152 denotes the @xmath153-th column of @xmath6 .",
    "[ [ the - algorithm . ] ] the algorithm .",
    "+ + + + + + + + + + + + + +    we consider the coordinate descent algorithm described in algorithm [ alg : sdca ] .",
    "initialize @xmath154 and then , at each iteration , sample and update a random coordinate @xmath149 $ ] of the parameter vector @xmath37 to iteratively minimize . finally , after @xmath155 iterations output @xmath156 , the average vector over the latest @xmath157 iterates . the parameter @xmath158 is some positive number smaller than @xmath155 .",
    "data matrix @xmath6 .",
    "+ starting point @xmath159 , @xmath160 . pick @xmath149 $ ] randomly find @xmath161 minimizing @xmath162",
    "@xmath163 @xmath164 let @xmath165    as we will show in the following section , coordinate descent on @xmath166 is not only an efficient optimizer of the objective @xmath166 , but also provably reduces the duality gap .",
    "therefore , the same algorithm will simultaneously optimize the dual objective @xmath167 .",
    "we first show linear primal - dual convergence rate of algorithm [ alg : sdca ] applied to for strongly convex @xmath168 .",
    "later , we will generalize this result to also apply to the setting of general lipschitz @xmath168 .",
    "this generalization together with the lipschitzing trick will allow us to derive primal - dual convergence guarantees of coordinate descent for a much broader class of problems , including the lasso problem .    for the following theorems",
    "we assume that the columns of the data matrix @xmath6 are scaled such that @xmath169 for all @xmath149 $ ] and @xmath170 for all @xmath171 $ ] , for some norm @xmath65 .",
    "[ thm : sdcathm5 ] consider algorithm [ alg : sdca ] applied to .",
    "assume @xmath3 is a @xmath38-smooth function w.r.t .",
    "the norm @xmath65 . then , if @xmath168 is @xmath40-strongly convex for all  @xmath153 , it suffices to have a total number of iterations of @xmath172 \\tfrac{\\epsilon_d^{(0)}}{\\epsilon}\\right)\\end{aligned}\\ ] ] to get @xmath173 \\leq \\epsilon$ ] .",
    "moreover , to obtain an expected duality gap of @xmath174 \\leq \\epsilon$ ] it suffices to have @xmath175 with @xmath176 \\tfrac{\\epsilon_d^{(0)}}{(t - t_0)\\epsilon}\\right)\\end{aligned}\\ ] ] where @xmath177 is the initial suboptimality in @xmath166 .",
    "theorem [ thm : sdcathm5 ] allows us to upper bound the duality gap , and hence the suboptimality , for every iterate @xmath178 , as well as the average @xmath156 returned by algorithm [ alg : sdca ] . in the following",
    "we generalize this result to apply to @xmath66-lipschitz functions  @xmath168 .",
    "[ thm : sdcathm2 ] consider algorithm [ alg : sdca ] applied to .",
    "assume @xmath3 is a @xmath38-smooth function w.r.t .",
    "the norm @xmath65 .",
    "then , if @xmath179 is @xmath66-lipschitz for all @xmath153 , it suffices to have a total number of iterations of @xmath180 to get @xmath174 \\leq \\epsilon$ ] . moreover , when @xmath181 with @xmath182 we have the suboptimality bound of @xmath183\\leq \\epsilon/2 $ ] , where @xmath177 is the initial suboptimality .",
    "theorem [ thm : sdcathm2 ] shows that for lipschitz @xmath179 , algorithm [ alg : sdca ] has @xmath184 convergence in the suboptimality and @xmath184 convergence in @xmath185 . comparing this result to theorem [ thm : convboundsup ] which suggests @xmath186 convergence in @xmath47 for @xmath184 convergent algorithms",
    ", we see that averaging the parameter vector crucially improves convergence in the case of non - smooth @xmath3 .",
    "[ rem : recoversdca ] note that our algorithm  [ alg : sdca ] recovers the widely used sdca setting @xcite as a special case , when we choose @xmath187 in .",
    "furthermore , their convergence results for sdca are consistent with our results and can be recovered as a special case of our analysis .",
    "see corollaries [ cor : thm5sdca ] , [ cor : thm2sdca ] , [ cor : lemma19sdca ] in appendix [ sec : cdproofs ] .",
    "we now apply algorithm [ alg : sdca ] to the @xmath0-regularized problems , as well as elastic net regularized problems .",
    "we state improved primal - dual convergence rates which are more tailored to the coordinate - wise setting .",
    "* coordinate descent on @xmath0-regularized problems .",
    "* in contrast to the general analysis of @xmath0-regularized problems in section [ sec : lasso ] , we can now exploit separability of @xmath188 and apply the lipschitzing trick coordinate - wise , choosing @xmath189 .",
    "this results in the following stronger convergence results :    [ cor : l1cd ] we can use the lipschitzing trick together with theorem [ thm : sdcathm2 ] to derive a primal - dual convergence result for the lasso problem .",
    "we find that the @xmath179 are @xmath96-lipschitz after applying the lipschitzing trick to every  @xmath168 , and hence the total number of iterations needed on the lasso problem to get a duality gap of @xmath174 \\leq \\epsilon$ ] is @xmath190    we specify the different parameters of corollary [ cor : l1cd ] for least squares loss as well as the logistic regression loss ( defined in table [ tbl : mlproblems ] ) .",
    "both are @xmath191-smooth ( @xmath78 is @xmath191-strongly convex ) and we have @xmath192 .",
    "the initial suboptimality @xmath193 can be upper bounded by @xmath194 for the former and by @xmath195 for the latter . for @xmath96",
    "we choose @xmath196 .",
    "* coordinate descent on elastic net regularized problems . * in section [ sec : elasticnet ] we discussed how the elastic net problem in can be mapped to our setup . in the first scenario ( row  2 ,",
    "table [ tbl : mlproblems ] ) we note that the resulting problem is partially separable and an instance of .",
    "+ in the second scenario we map to @xmath197 ( row  3 , table [ tbl : mlproblems ] ) . assuming that the loss function @xmath142 is separable , this problem is an instance of .",
    "the convergence guarantees when applying algorithm  [ alg : sdca ] on the primal or on the dual are summarized in corollary  [ cor : elasticcd ] .",
    "[ cor : elasticcd ] consider algorithm [ alg : sdca ] for an elastic net regularized problem , running on either the primal or the dual formulation .",
    "then , to obtain a duality gap of @xmath198 \\leq \\epsilon$ ] , it suffices to have a total of @xmath199 \\tfrac{\\epsilon_d^{(0)}}{\\epsilon } ) \\end{aligned}\\ ] ] iterations for coordinate descent on the primal and @xmath200 \\tfrac{\\epsilon_d^{(0)}}{\\epsilon } ) \\end{aligned}\\ ] ] for coordinate descent on the dual of .    according to corollary [ cor : elasticcd ] ,",
    "the convergence rate is comparable for both scenarios .",
    "the constants however depend on the data matrix @xmath6  for @xmath201 the primal version is beneficial , whereas for @xmath202 the dual version is leading .",
    "here we illustrate the usefulness of our framework by showcasing it for two important applications , each one showing two algorithm examples for optimizing",
    ".    * lasso . *",
    "the top row of figure [ fig : svm ] shows the primal - dual convergence of algorithm [ alg : sdca ] ( cd ) as well as the accelerated variant of cd ( approx , @xcite ) , both applied to the lasso problem  .",
    "we have applies the lipschitzing trick as described in section [ lipschtrick ] .",
    "this makes sure that @xmath203 will be always feasible for the modified dual  , and hence the duality gap can be evaluated .",
    "it was shown in @xcite that if cd ( sdca ) is run on the dual svm formulation , and we consider an `` average '' solution ( over last few iterates ) , then the duality gap evaluated at averaged iterates has a sub - linear convergence rate @xmath204 . as a consequence of theorem [ thm : convboundsup ] , we have that the approx algorithm @xcite will provide the same sub - linear convergence in duality gap , but holding for the iterates themselves , not only for an average .",
    "on the bottom row of figure [ fig : svm ] we compare cd with its accelerated variant on two benchmark datasets.cjlin/libsvmtools/datasets ] .",
    "] we have chosen @xmath205 .",
    "we have presented a general framework allowing to equip existing optimization algorithms with primal - dual certificates . for future research , it will be interesting to study more applications and algorithms fitting into the studied problem structure , including more cases of structured sparsity , and generalizations to matrix problems .",
    "[ [ acknowledgments . ] ] acknowledgments .",
    "+ + + + + + + + + + + + + + + +    we thank francis bach , michael p. friedlander , ching - pei lee , dmytro perekrestenko , aaditya ramdas , virginia smith and an anonymous reviewer for fruitful discussions .",
    "a function @xmath206 is _ @xmath66-lipschitz continuous _",
    "w.r.t . a norm @xmath65 if @xmath207 , we have @xmath208    def : lbounded[@xmath96-bounded support ] a function @xmath206 has _",
    "@xmath96-bounded support _ if its effective domain is bounded by @xmath96 w.r.t .",
    "a norm @xmath65 , i.e. , @xmath209    [ def : levelset ] the @xmath210-level set of a function @xmath211 is defined as @xmath212 .    a function @xmath213 is called _ @xmath66-smooth _",
    "w.r.t . a norm @xmath65 , for @xmath214 ,",
    "if it is differentiable and its derivative is @xmath66-lipschitz continuous w.r.t . @xmath65 , or equivalently",
    "@xmath215    a function @xmath213 is called _",
    "@xmath40-strongly convex _ w.r.t .",
    "a norm @xmath65 , for @xmath216 , if @xmath217 and analogously if the same holds for all subgradients , in the case of a general closed convex function @xmath218 .",
    "we recall some basic properties of convex conjugates , which we use in the paper .",
    "the convex conjugate of a function @xmath219 is defined as @xmath220 some useful properties , see ( * ? ? ?",
    "* section 3.3.2 ) :    * double conjugate : @xmath221 if @xmath3 is closed and convex . * value scaling : ( for @xmath222 ) @xmath223 * argument scaling : ( for @xmath224 ) @xmath225 * conjugate of a separable sum : @xmath226    lem : duallipschitz[duality between lipschitzness and l - bounded support .",
    "a generalization of  ( * ? ? ?",
    "* corollary 13.3.3 ) ] given a proper convex function @xmath4 , it holds that @xmath4 has @xmath66-bounded support w.r.t . the norm @xmath65 if and only if @xmath55 is @xmath66-lipschitz w.r.t . the dual norm @xmath67 .",
    "[ lem : dualsmooth ] given a closed convex function  @xmath3 , it holds that @xmath3 is @xmath40-strongly convex w.r.t .",
    "the norm @xmath65 if and only if @xmath78 is @xmath227-smooth w.r.t . the dual norm  @xmath67 .",
    "[ lem : normconjugates ]    1 .",
    "the conjugate of the indicator function @xmath228 of a set @xmath229 ( not necessarily convex ) is the support function of the set @xmath230 , that is @xmath231 2 .",
    "the conjugate of a norm is the indicator function of the unit ball of the dual norm .",
    "* examples 3.24 and 3.26 )",
    "the relation of the primal and dual problems and is a special case of the concept of fenchel duality . using the combination with the linear map @xmath6 as in our case",
    ", the relationship is called _ fenchel - rockafellar duality _ ,",
    "see , e.g. , ( * ? ? ?",
    "* theorem 4.4.2 ) or ( * ? ? ?",
    "* proposition 15.18 ) .    for completeness",
    ", we here illustrate this correspondence with a self - contained derivation of the duality .    starting with the formulation ,",
    "we introduce a helper variable @xmath232 .",
    "the optimization problem   becomes : @xmath233 introducing dual variables @xmath234 $ ] , the lagrangian is given by : @xmath235 the dual problem follows by taking the infimum with respect to @xmath37 and @xmath236 : @xmath237 we change signs and turn the maximization of the dual problem into a minimization and thus we arrive at the dual formulation @xmath197 as claimed : @xmath238 \\ , .\\ ] ]",
    "the proof is partially motivated by proofs in @xcite but come with some crucial unique steps and tricks",
    ".    we have @xmath239 } \\big ( g ( { { \\boldsymbol \\alpha } } ) -g ( { { \\boldsymbol \\alpha}}+s ( { { \\bf u}}- { { \\boldsymbol \\alpha } } ) )   + f(a { { \\boldsymbol \\alpha } } )   - f(a ( { { \\boldsymbol \\alpha}}+s ( { { \\bf u}}- { { \\boldsymbol \\alpha } } ) ) ) \\big ) \\\\ & \\geq   g ( { { \\boldsymbol \\alpha } } ) -g ( { { \\boldsymbol \\alpha}}+s ( { { \\bf u}}- { { \\boldsymbol \\alpha } } ) )   + f(a { { \\boldsymbol \\alpha } } ) - f(a ( { { \\boldsymbol \\alpha}}+s ( { { \\bf u}}- { { \\boldsymbol \\alpha } } ) ) .    { \\addtocounter{equation}{1}\\tag{\\theequation}}\\label{adsfsafsafa}\\end{aligned}\\ ] ]    here we have chosen @xmath240 with @xmath49 defined as in and some @xmath241 $ ] .",
    "note that for @xmath49 to be well defined , i.e. , the subgradient in not to be empty , we need the domain of @xmath55 to be the whole space .",
    "for @xmath54 this is given by strong convexity of @xmath4 , while for @xmath43 this follows from the bounded support assumption on @xmath4 .",
    "( for the duality of lipschitzness and bounded support , see our lemma [ lem : duallipschitz ] ) .",
    "now , we can use the fact , that function @xmath242 has lipschitz continuous gradient w.r.t .",
    "some norm @xmath39 , with constant @xmath38 , to obtain @xmath243 now , we will use a strong convexity property of a function @xmath4 w.r.t .",
    "@xmath42 to obtain @xmath244    now let us examine the relation of the equation above with duality gap .",
    "therefore we use the definition of the optimization problems and , and the definition of the convex conjugates to write the duality gap as : @xmath245 where we have used the mapping @xmath246 .",
    "now , let us analyze the expression @xmath247 from .",
    "we have @xmath248 now , using the convex conjugate maximal property and we have @xmath249 plugging , and into gives us @xmath250 and follows .      lemma [ lem : duallipschitz ] generalizes the result of ( * ? ? ?",
    "* corollary 13.3.3 ) from the @xmath5-norm to a general norm @xmath65 .",
    "it can be equivalently formulated as follows :    let @xmath273 be a proper convex function . in order that dom(@xmath78 ) be @xmath66-bounded w.r.t @xmath67 ( a real number @xmath274 ) , it is necessary and sufficient that @xmath3 be finite everywhere and that @xmath275    we follow the line of proof in @xcite .",
    "it can be assumed that @xmath3 is closed , as @xmath3 and its closure @xmath276 have the same conjugate , and the lipschitz condition is satisfied by @xmath3 if and only if it is satisfied by @xmath276 .",
    "note that from ( * ? ? ?",
    "* theorem 13.3 ) we know @xmath277 is the support function of @xmath278 .",
    "further , from ( * ? ? ?",
    "* theorem 10.5 ) we know : @xmath278 is bounded if and only if @xmath279 is finite everywhere . in more detail , the lipschitz condition on @xmath3 , choosing @xmath280 , is equivalent to having @xmath281 and by definition of @xmath279",
    "this is equivalent to @xmath282 note that @xmath283 is a finite positively homogenous convex function , we know by ( * ? ? ?",
    "* corollary 13.2.2 ) that it is the support function of a non - empty bounded convex set .",
    "call this set @xmath284 .",
    "we will later show that @xmath285 where @xmath92 is the @xmath67-norm ball .",
    "hence @xmath286 means @xmath287 , as @xmath279 is the support function of @xmath278 . and",
    "this shows that the lipschitz condition holds for some @xmath66 if and only if @xmath288 and hence @xmath289 and @xmath78 is @xmath66-bounded for every @xmath290 .",
    "it remains to show that @xmath291 is the support function of @xmath285 : the support function of a set @xmath230 is defined as @xmath292 by the definition of the dual norm we find @xmath293 and hence @xmath4 is the support function of the set @xmath294 .",
    "let us upper bound the second term in as given in the main lemma  [ lemma : dualitygapanddualsuboptimality ] . recall the definition of the data complexity parameter @xmath53 .",
    "we have @xmath251    \\| { { \\bf u}}- { { \\boldsymbol \\alpha}}\\|_g^2.\\end{aligned}\\ ] ] now , if we choose @xmath252 then this term vanishes , and therefore @xmath253 & \\ \\overset{\\eqref{eq : dualitygapanddualsuboptimality}}{\\leq } \\   { \\mathbb{e } } [   { \\mathcal{d } } ( { { { \\boldsymbol \\alpha}}^{(t)}})-{\\mathcal{d } } ( { { \\boldsymbol \\alpha}}^\\star ) ] \\ \\overset{\\eqref{eq : afcewwa}}{\\leq } \\     ( 1-c)^t \\ d.\\end{aligned}\\ ] ] after multiplying the equation above by @xmath254 and requiring rhs to be @xmath80 we will get @xmath255 and our claimed convergence bound follows .",
    "from lemma [ lemma : dualitygapanddualsuboptimality ] and the definition of @xmath256 we have that @xmath257 & \\ \\overset{\\eqref{eq : dualitygapanddualsuboptimality } } { \\leq}\\   { \\mathbb{e}}\\big [ { \\mathcal{d } } ( { { { \\boldsymbol \\alpha}}^{(t ) } } ) - { \\mathcal{d } } ( { { \\boldsymbol \\alpha}}^\\star ) +    \\tfrac{s^2}{2\\beta }    \\|    a    ( { { \\bf u}}- { { \\boldsymbol \\alpha } } ) \\|_f^2 \\big ] \\ \\overset{\\eqref{eq : afcewwa}}{\\leq}\\   ( 1-c)^t \\ d +    \\frac\\sigma \\beta \\tfrac{s^2}2    { \\mathbb{e}}[\\|      { { \\bf u}}- { { \\boldsymbol \\alpha}}\\|_g^2 ] \\ .\\end{aligned}\\ ] ]    now using lemma [ lem : duallipschitz ] , because @xmath55 is @xmath66-lipschitz w.r.t .",
    "the norm @xmath67 , we have that @xmath4 is @xmath66-bounded w.r.t . the norm @xmath258 and",
    "hence for @xmath25 we obtain @xmath259 . from the standard characterization of lipschitzness as by bounded subgradient norm ( see e.g. ( * ? ? ?",
    "* lemma 2.6 ) or other references ) we have for any @xmath260 that @xmath261 , and hence for any @xmath262 we must have @xmath263 by the triangle inequality .",
    "therefore we conclude that @xmath264   \\overset{\\eqref{eq : afsdfawvfaw}}{\\leq }    \\frac1s ( 1-c)^t d +   s \\frac \\sigma\\beta   l^2 .",
    "\\label{eq : affeawvfrwaefc}\\end{aligned}\\ ] ] now , let us choose @xmath265 . to have the rhs of @xmath266 it is enough to choose @xmath267 and the claimed convergence bound follows .",
    "using lemma [ lemma : dualitygapanddualsuboptimality ] and the bound @xmath263 derived in the previous section , we have that @xmath268 & \\ \\overset{\\eqref{eq : dualitygapanddualsuboptimality}}{\\leq}\\   \\frac1s { \\mathbb{e}}[{\\mathcal{d } } ( { { { \\boldsymbol \\alpha}}^{(t)}})-{\\mathcal{d } } ( { { \\boldsymbol \\alpha}}^\\star ) ]    + \\frac{s}2    \\frac\\sigma\\beta   l^2 \\ \\overset{\\eqref{eq : sublinearalgorithm}}{\\leq}\\    \\frac1s \\frac{c}{d(t ) }    + \\frac{s}2   \\frac\\sigma\\beta   l^2 .",
    "\\label{eq : afsewfwavfwav}{\\addtocounter{equation}{1}\\tag{\\theequation}}\\end{aligned}\\ ] ] now , by choosing @xmath269 $ ] we obtain that @xmath268 & \\overset{\\eqref{eq : afsewfwavfwav}}{\\leq }     \\sqrt{\\frac{2 c \\sigma l^2}{\\beta   d(t)}}.\\end{aligned}\\ ] ] we see that the assumption guarantees that the rhs of the above inequality becomes @xmath80 , as claimed .",
    "we note that in the special case of constrained optimization , motivated by the frank - wolfe algorithm , ( * ? ? ?",
    "* theorem 2 ) has shown another algorithm - independent bound for the convergence in duality gap , also requiring order of @xmath270 steps to reach accuracy @xmath271 .",
    "on the other hand , for the algorithm - specific result by ( * ? ? ? * prop 4.2 ) for the case of an extended frank - wolfe algorithm , @xmath272 steps are shown to be sufficient .",
    "consider the lasso problem given in , which we directly map to our primal optimization problem .",
    "we use the @xmath0-norm ball of radius @xmath96 to apply the lipschitzing trick , i.e. @xmath295 and modify the @xmath0 norm term @xmath188 as suggested in .",
    "the convex conjugate hence becomes : @xmath296_+\\label{eq : duall1}\\ ] ] and using the optimality condition the gap follows immediately as @xmath297_+ + \\lambda \\| { { \\boldsymbol \\alpha}}\\|_1\\\\ & = \\langle \\nabla f(a { { \\boldsymbol \\alpha } } ) , a { { \\boldsymbol \\alpha}}\\rangle+ b \\left[\\| a^\\top { { \\bf w } } ( { { \\boldsymbol \\alpha}})\\|_\\infty-\\lambda\\right]_+ + \\lambda \\| { { \\boldsymbol \\alpha}}\\|_1\\end{aligned}\\ ] ] where we used the first - order optimality @xmath298 by definition of @xmath203 .    from we know @xmath299",
    "it remains to consider the non zero part , where @xmath300 .",
    "lets consider the optimization @xmath301 assume the largest element of @xmath49 is at index @xmath153 and we know @xmath302_i>\\lambda$ ] , hence the maximizing @xmath37 in @xmath303 is the vector with a single entry of value @xmath96 at position @xmath153 , and follows .",
    "consider the elastic net regularized problem formulation .",
    "the conjugate dual of the elastic net regularizer is given in lemma [ lem : elasticnetconjugate ] .",
    "we first map to , as suggested in row 2 of table [ tbl : mlproblems ] .",
    "then its dual counterpart is given by : @xmath304_+\\right)^2.\\ ] ] in light of the optimality condition we now use the definition of the primal - dual correspondence @xmath305 , and hence obtain @xmath306_+\\right)^2 + \\lambda \\left(\\frac{\\eta}{2 } \\| { { \\boldsymbol \\alpha}}\\|_2 ^ 2 + ( 1-\\eta)\\| { { \\boldsymbol \\alpha}}\\|_1\\right).\\end{aligned}\\ ] ] note that when alternatively mapping to ( as suggested in row 3 of table [ tbl : mlproblems ] ) instead of , the duality gap function will be similarly structured , but in that case the variable mapping @xmath203 will be defined using the gradient of the elastic net penalty , instead of @xmath142 .",
    "for the proof of theorem [ thm : sdcathm5 ] and [ thm : sdcathm2 ] and we will need the following lemma , which we will prove below in section [ sec : lembasic ] .",
    "this lemma allows us to lower bound the expected per - step improvement in terms of @xmath101 for coordinate descent algorithms on @xmath101 .",
    "[ lemma : basic]consider problem formulation and .",
    "let @xmath3 be @xmath38-smooth w.r.t .",
    "a norm @xmath65 .",
    "further , let @xmath168 be @xmath40-strongly convex with convexity parameter @xmath41 @xmath307 $ ] . for the case @xmath43 we need",
    "the additional assumption of @xmath168 having bounded support .",
    "then for any iteration @xmath104 and any @xmath45 $ ] , it holds that @xmath308 \\geq \\frac{s}{n } g ( { { \\boldsymbol \\alpha}}^{t-1 } ) -\\frac{s^2 f^{(t)}}{2},\\end{aligned}\\ ] ] where @xmath309,\\label{eq : f}\\end{aligned}\\ ] ] and @xmath310 .",
    "the expectations are with respect to the random choice of coordinate @xmath153 in step @xmath104 .      for the following",
    ", we again assume that the columns of the data matrix @xmath6 are scaled such that @xmath169 for all @xmath149 $ ] and @xmath170 for all @xmath171 $ ] and some norm @xmath65 .",
    "thm : sdcathm5 consider algorithm [ alg : sdca ] applied to .",
    "assume @xmath3 is a @xmath38-smooth function w.r.t .",
    "the norm @xmath65 . then , if @xmath168 is @xmath40-strongly convex for all  @xmath153 , it suffices to have a total number of iterations of @xmath172 \\tfrac{\\epsilon_d^{(0)}}{\\epsilon}\\right)\\end{aligned}\\ ] ] to get @xmath173 \\leq \\epsilon$ ] .",
    "moreover , to obtain an expected duality gap of @xmath174 \\leq \\epsilon$ ] it suffices to have @xmath175 with @xmath176 \\tfrac{\\epsilon_d^{(0)}}{(t - t_0)\\epsilon}\\right)\\end{aligned}\\ ] ] where @xmath177 is the initial suboptimality in @xmath166 .",
    "the proof of this theorem is motivated by proofs in @xcite but generalizing their result in ( * ? ? ?",
    "* theorem 5 ) . to prove theorem [ thm : sdcathm5 ] we apply lemma [ lemma : basic ] with @xmath311 $ ] .",
    "this choice of @xmath312 implies @xmath313 as defined in .",
    "hence , @xmath314 \\geq",
    "\\frac s n g ( { { { \\boldsymbol \\alpha}}^{(t-1 ) } } ) = \\frac{s}{n } { \\mathcal{p } } ( { { { \\bf w}}^{(t-1)}})+{\\mathcal{d } } ( { { { \\boldsymbol \\alpha}}^{(t-1 ) } } ) .\\ ] ] here expectations are over the choice of coordinate @xmath153 in step @xmath104 , conditioned on the past state at @xmath315 .",
    "let @xmath316 denote the suboptimality @xmath317 .",
    "as @xmath318 and @xmath319 , we obtain @xmath320 \\leq \\left(1-\\frac{s}{n}\\right ) { \\epsilon_d^{(t-1 ) } } \\leq \\left(1-\\frac{s}{n}\\right)^t   { \\epsilon_d^{(0 ) } }",
    "\\leq \\exp(-st / n ) { \\epsilon_d^{(0 ) } } \\leq \\exp\\left(-\\frac{\\mu \\beta t}{n(r^2 + \\mu\\beta)}\\right ) { \\epsilon_d^{(0)}}.\\end{aligned}\\ ] ] to finally upper bound the expected suboptimality as @xmath321\\leq \\epsilon_d$ ] we need @xmath322 and towards obtaining small duality gap as well , we observe that at all times @xmath323 \\leq \\frac{n}{s}{\\mathbb{e}}[{\\epsilon_d^{(t-1)}}-{\\epsilon_d^{(t ) } } ] \\leq \\frac{n}{s } { \\mathbb{e}}[{\\epsilon_d^{(t-1 ) } } ] \\ .\\ ] ] hence with @xmath324 $ ] we must have a duality gap smaller than @xmath271 .",
    "therefore we require @xmath325 this proves the first part of theorem [ thm : sdcathm5 ] and the second part follows immediately if we sum over @xmath326 .    from theorem [ thm : sdcathm5 ]",
    "it follows that for @xmath327 and @xmath328 we need @xmath329    [ [ recovering - sdca - as - a - special - case . ] ] recovering sdca as a special case .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    [ cor : thm5sdca ] we recover theorem 5 of @xcite as a special case of our theorem [ thm : sdcathm5 ] .",
    "we consider their optimization objectives , namely @xmath330 .\\end{aligned}\\ ] ] where @xmath331 are the columns of the data matrix @xmath332 .",
    "we assume that @xmath333 is @xmath334-strongly convex for @xmath149 $ ] .",
    "we scale the columns of @xmath332 such that @xmath335 .",
    "hence , we find that @xmath336\\frac{1}{\\epsilon ( t - t_0)}\\right)\\end{aligned}\\ ] ] iterations are sufficient to obtain a duality gap of @xmath337\\leq   \\epsilon$ ] .",
    "we consider and as a special case of the separable problems and .",
    "we set @xmath338 and @xmath339 . in this case @xmath340 and @xmath341 . defining @xmath342 and using the assumption @xmath335 we have @xmath343 and using @xmath344 we have @xmath345and applying theorem [ thm : sdcathm5 ] to this setting",
    "concludes the proof .",
    "this theorem generalizes the results of ( * ? ? ?",
    "* theorem 2 ) .",
    "thm : sdcathm2consider algorithm [ alg : sdca ] applied to .",
    "assume @xmath3 is a @xmath38-smooth function w.r.t .",
    "the norm @xmath65 . then , if @xmath179 is @xmath66-lipschitz for all @xmath153 , it suffices to have a total number of iterations of @xmath346 to get @xmath174 \\leq \\epsilon$ ]",
    ". moreover , when @xmath181 with @xmath347 we have the suboptimality bound of @xmath183\\leq \\epsilon/2 $ ] , where @xmath177 is the initial suboptimality .",
    "we rely on the following lemma :    [ lemma : f ] suppose that for all @xmath153 , @xmath179 is @xmath66-lipschitz .",
    "let @xmath348 be as defined in lemma [ lemma : basic ] ( with @xmath43 ) and assume @xmath349 .",
    "then , @xmath350 .",
    "we apply the duality of lipschitzness and bounded support ( lemma [ lem : duallipschitz ] ) to the case of univariate functions @xmath168 .",
    "the assumption of @xmath179 being @xmath66-lipschitz therefore gives that @xmath168 has @xmath66-bounded support , and so @xmath351 for @xmath352 as defined in  .",
    "furthermore for @xmath353 , by the equivalence of lipschitzness and bounded subgradient ( see e.g. ( * ? ? ?",
    "* lemma 2.6 ) ) we have @xmath354 and thus , @xmath355 . together with @xmath356 the claimed bound on @xmath357 follows .    in the case of lasso",
    "we have @xmath358 .",
    "using the lipschitzing trick , we replace @xmath359 by @xmath360   \\\\",
    "+ \\infty & : \\text{otherwise , }          \\end{cases}\\end{aligned}\\ ] ] which has @xmath96-bounded support .",
    "hence , its conjugate @xmath361   \\\\              b ( |x| - \\lambda ) & : \\text{otherwise , }          \\end{cases}\\ ] ] is @xmath96-lipschitz and lemma [ lem : duallipschitz ] and lemma [ lemma : f ] apply with @xmath362 .",
    "now , to prove theorem [ thm : sdcathm2 ] , let @xmath363 and recall that by lemma [ lemma : f ] we can upper bound @xmath364 by @xmath365 .",
    "furthermore , our main lemma [ lemma : basic ] on the improvement per step tells us that @xmath366 \\geq \\frac{s}{n } g ( { { { \\boldsymbol \\alpha}}^{(t-1 ) } } ) -\\frac{s^2}{2 } f , \\end{aligned}\\ ] ]    with @xmath367 and @xmath368 , this implies @xmath369&\\geq&\\frac{s}{n } { \\epsilon_d^{(t-1 ) } } -   \\frac { s^2   f}{2}\\\\ { \\epsilon_d^{(t-1)}}-{\\mathbb{e}}[{\\epsilon_d^{(t)}}]&\\geq&\\frac{s}{n } { \\epsilon_d^{(t-1 ) } } -\\frac { s^2   f}{2}\\\\ { \\mathbb{e}}[{\\epsilon_d^{(t)}}]&\\leq&\\left(1-\\frac{s}{n}\\right ) { \\epsilon_d^{(t-1 ) } } + \\frac { s^2   f}{2}\\\\\\end{aligned}\\ ] ] expectations again only being over the choice of @xmath153 in steps @xmath104 . we next show that this inequality can be used to bound the suboptimality as @xmath370\\leq\\frac{2 f n^2}{2n+t - t_0}\\ ] ] for @xmath371 .",
    "indeed , let us choose @xmath372 . then at @xmath373",
    ", we have @xmath374&\\leq & \\left(1-\\frac{1}{n}\\right)^t \\epsilon_d^{(0 ) } + \\sum_{i=0}^{t-1 } \\left(1-\\frac{1}{n}\\right)^i \\frac { f}{2}\\\\ & \\leq & \\left(1-\\frac{1}{n}\\right)^t \\epsilon_d^{(0 ) } + \\frac{1}{1-(1 - 1/n ) } \\frac { f}{2}\\\\ & \\leq & e^{-t / n } \\epsilon_d^{(0 ) } + \\frac{n   f } { 2}\\\\ & \\leq &    f n\\end{aligned}\\ ] ] for @xmath375 we use an inductive argument .",
    "suppose the claim holds for @xmath315 , therefore @xmath374&\\leq & \\left(1-\\frac{s}{n}\\right ) { \\mathbb{e}}[\\epsilon_d^{(t-1 ) } ] + \\frac{s^2 f}{2}\\\\ & \\leq & \\left(1-\\frac{s}{n}\\right)\\frac{2   f n^2}{2n+(t-1)-t_0 } + \\frac{s^2 f}{2}\\end{aligned}\\ ] ] choosing @xmath376 $ ] yields @xmath374&\\leq & \\left(1-\\frac{2}{2n+t-1-t_0}\\right)\\frac{2   f n^2}{2n+(t-1)-t_0 } + \\left(\\frac{2n}{2n+t-1-t_0}\\right)^2\\frac { f}{2}\\\\ & = & \\left(1-\\frac{2}{2n+t-1-t_0}\\right)\\frac{2   f n^2}{2n+(t-1)-t_0 } + \\left(\\frac{1}{2n+t-1-t_0}\\right)\\frac{2 f n^2}{2n+t-1-t_0}\\\\ & = & \\left(1-\\frac{1}{2n+t-1-t_0}\\right)\\frac{2   f n^2}{2n+(t-1)-t_0 } \\\\ & = & \\frac{2   f n^2}{(2n+t-1-t_0 ) } \\frac{2n+t-2-t_0}{2n+t-1-t_0}\\\\ & \\leq & \\frac{2   f n^2}{(2n+t - t_0)}\\end{aligned}\\ ] ] this proves the bound on the suboptimality . to get a result on the duality gap we sum over the interval @xmath377 and obtain @xmath378 \\geq \\frac{s}{n } { \\mathbb{e}}\\left[\\sum_{t = t_0 + 1}^t p ( { { \\bf w}}^{(t-1)})+d ( { { \\boldsymbol \\alpha}}^{(t-1)})\\right ] - ( t - t_0)\\frac{s^2}{2 }   f,\\ ] ] and rearranging terms we get @xmath379 \\leq \\frac{n}{s ( t - t_0 ) }   { \\mathbb{e } } [ { \\mathcal{d } } ( { { { \\boldsymbol \\alpha}}^{(t_0)}})- { \\mathcal{d } } ( { { { \\boldsymbol \\alpha}}^{(t ) } } ) ] + \\frac{s n}{2 }   f,\\ ] ] now if we choose @xmath380 to be the average vectors over @xmath381 , then the above implies @xmath382 =   { \\mathbb{e}}\\left [ p(\\bar { { \\bf w}})+d(\\bar { { \\boldsymbol \\alpha}})\\right ] \\leq \\frac{n}{s ( t - t_0 ) }   { \\mathbb{e } } [   { \\mathcal{d } } ( { { { \\boldsymbol \\alpha}}^{(t_0)}})-{\\mathcal{d } } ( { { { \\boldsymbol \\alpha}}^{(t ) } } ) ] + \\frac{s n}{2 }   f,\\ ] ] if @xmath383 and @xmath384 , we can set @xmath385 and combining this with we obtain @xmath386 = & \\leq &    { \\mathbb{e } } [ { \\mathcal{d } } ( { { { \\boldsymbol \\alpha}}^{(t_0)}})- { \\mathcal{d } } ( { { { \\boldsymbol \\alpha}}^{(t ) } } ) ] + \\frac { f n^2}{2 ( t - t_0 ) } \\\\ & \\leq &    { \\mathbb{e } } [    { \\mathcal{d } } ( { { { \\boldsymbol \\alpha}}^{(t_0)}})-{\\mathcal{d } } ( { { \\boldsymbol \\alpha}}^\\star)]+\\frac { f n^2}{2 ( t - t_0 ) } \\\\ & \\leq &   \\frac{2   f n^2}{2n+t - t_0}+\\frac {   f n^2}{2 ( t - t_0 ) } \\end{aligned}\\ ] ] a sufficient condition to upper bound the duality gap by @xmath271 is that @xmath387 and @xmath388 which also implies @xmath389\\leq \\epsilon/2 $ ] .",
    "since we further require @xmath384 and @xmath390 , the overall number of required iterations has to satisfy @xmath391 using lemma [ lemma : f ] we can bound the total number of required iterations to reach a duality gap of @xmath271 by @xmath392 which concludes the proof of theorem [ thm : sdcathm2 ] .    [ [ recovering - sdca - as - a - special - case.-1 ] ] recovering sdca as a special case .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    [ cor : thm2sdca ] we recover theorem 2 of @xcite as a special case of our theorem [ thm : sdcathm2 ] .",
    "we consider the optimization objectives in and .",
    "we assume that @xmath393 is @xmath139-lipschitz for @xmath149 $ ] and @xmath394 .",
    "we scale the columns of @xmath332 such that @xmath335 .",
    "hence , we find that @xmath395 iterations are sufficient to obtain a duality gap of @xmath174\\leq   \\epsilon$ ] .",
    "we consider and as a special case and .",
    "we set @xmath338 and @xmath339 .",
    "hence , @xmath396 is @xmath139-lipschitz and we set @xmath397 and @xmath341 .",
    "we further use lemma ( * ? ? ?",
    "* lemma 20 ) with @xmath394 to bound the primal suboptimality as @xmath345 .",
    "finally , by the assumption @xmath398 and the definition @xmath342 we have @xmath343 and applying theorem [ thm : sdcathm2 ] to this setting concludes the proof .      the proof of lemma [ lemma : basic ] is motivated by the proof of ( * ? ? ? * lemma 19 ) but we adapt it to apply to a much more general setting .",
    "first note that the one step improvement in the dual objective can be written as @xmath399\\end{aligned}\\ ] ] note that in a single step of sdca @xmath400 only one dual coordinate is changed . without loss of generality",
    "we assume this coordinate to be @xmath153 .",
    "writing @xmath401 , we find @xmath402}_{(\\gamma)}-\\underbrace{\\left [   g_i({\\alpha_i^{(t ) } } ) + f ( { { \\bf v } } ( { { { \\boldsymbol \\alpha}}^{(t)}}))\\right]}_{(\\lambda ) } .\\end{aligned}\\ ] ] in the following , let us denote the columns of the matrix @xmath6 by @xmath403 for @xmath404 $ ] for reasons of readability . then , by definition of the update we have for all @xmath241 $ ] : @xmath405\\\\ & = & \\min_{\\delta \\alpha_i}\\left [ g_i({\\alpha_i^{(t-1)}}+\\delta\\alpha_i ) +   f\\left ( { { \\bf v } } ( { { { \\boldsymbol \\alpha}}^{(t-1)}})+ { { \\bf a}}_i \\delta\\alpha_i\\right)\\right]\\\\ & \\leq&\\left [ g_i({\\alpha_i^{(t-1)}}+s({u_i^{(t-1)}}-{\\alpha_i^{(t-1 ) } } ) ) + f\\left ( { { \\bf v } } ( { { { \\boldsymbol \\alpha}}^{(t-1)}})+ { { \\bf a}}_i s({u_i^{(t-1)}}-{\\alpha_i^{(t-1)}})\\right)\\right]\\\\\\end{aligned}\\ ] ] where we chose @xmath406 with @xmath407 for @xmath241 $ ] . as in section [ sec : prooflemma1 ] , in order for @xmath49 to be well - defined , we again need the assumption on @xmath4 to be strongly convex ( @xmath54 ) , or to have bounded support . using @xmath40-strong convexity of @xmath168 , namely @xmath408 and @xmath409-smoothness of @xmath3 @xmath410 we find that @xmath411 \\\\ & & + \\left [      f ( { { \\bf v } } ( { { \\boldsymbol \\alpha}}^{(t-1)}))+\\langle\\nabla f ( { { \\bf v } } ( { { \\boldsymbol \\alpha}}^{(t-1)})),s(u_i^{(t-1)}-\\alpha_i^{(t-1 ) } ) { { \\bf a}}_i\\rangle + \\tfrac{1}{2 \\beta}\\big\\|s(u_i^{(t-1)}-\\alpha_i^{(t-1 ) } ) { { \\bf a}}_i\\big\\|^2 \\right].\\end{aligned}\\ ] ] we further note that from the optimality condition we have @xmath412 and rearranging terms yields : @xmath413 using this inequality to bound @xmath414 yields : @xmath415.\\nonumber\\end{aligned}\\ ] ] note that for @xmath416 we used the optimality condition which translates to @xmath417 and yields @xmath418 .",
    "similarly , by again exploiting the primal - dual optimality condition we have @xmath419 and hence we can write the duality gap as : @xmath420\\\\ & = &   \\sum_{i=1}^n\\left[g_i^*(- { { \\bf a}}_i^\\top { { \\bf w}})+g_i(\\alpha_i)\\right]+f^ * ( { { \\bf w}})+f(a { { \\boldsymbol \\alpha}})\\\\ & = &   \\sum_{i=1}^n\\left[g_i^*(- { { \\bf a}}_i^\\top { { \\bf w}})+g_i(\\alpha_i)\\right ] + ( a { { \\boldsymbol \\alpha}})^\\top { { \\bf w}}\\\\ & = &   \\sum_{i=1}^n\\left[g_i^*(- { { \\bf a}}_i^\\top { { \\bf w}})+g_i(\\alpha_i ) + \\alpha_i { { \\bf a}}_i^\\top { { \\bf w}}\\right]\\end{aligned}\\ ] ] using this we can write the expectation of with respect to @xmath153 as @xmath421 & \\geq & s \\left(\\frac{1}{n } g ( { { { \\boldsymbol \\alpha}}^{(t-1 ) } } ) \\right ) -\\frac{s^2}{2 } \\underbrace { \\left[\\frac{1}{n}\\sum_{i=1}^n { \\mathbb{e}}\\left[\\big({u_i^{(t-1)}}-{\\alpha_i^{(t-1)}}\\big)^2\\right]\\left (   \\frac{1 } { \\beta}\\| { { \\bf a}}_i\\|^2-\\frac{(1-s)\\mu } { s}\\right)\\right ] } _ { f^{(t)}}.\\end{aligned}\\ ] ] and we have obtained that @xmath422 & \\geq & \\frac{s}{n } g ( { { { \\boldsymbol \\alpha}}^{(t-1 ) } } ) -\\frac{s^2 } { 2 } f^{(t)}.\\end{aligned}\\ ] ] for the expectation being over the choice of coordinate @xmath153 in step @xmath104 .",
    "[ cor : lemma19sdca ] we recover lemma 19 of @xcite as a special case of our lemma [ lemma : basic ] .",
    "we consider their pair of primal and dual optimization objectives , and where @xmath331 are the columns of the data matrix @xmath332 .",
    "assume that @xmath423 is @xmath334-strongly convex for @xmath149 $ ] , where we allow @xmath424 .",
    "then , for any @xmath104 , any @xmath241 $ ] and @xmath425 we have @xmath426 \\\\ & \\geq \\frac{s}{n } { \\mathbb{e}}[{\\mathcal{p } } ( { { \\boldsymbol \\theta}}^{t-1})-(-{\\mathcal{d } } ( { { \\boldsymbol \\alpha}}^{t-1 } ) ) ] -\\left(\\frac{s}{n}\\right)^2 \\frac{\\hat   f^{(t)}}{2\\lambda } , \\notag\\end{aligned}\\ ] ] where @xmath427\\nonumber,\\end{aligned}\\ ] ]    we set @xmath428 and @xmath339 . from the definition of strong convexity it immediately follows that @xmath429 and @xmath430 .",
    "as our algorithm works for any data matrix @xmath6 , we choose @xmath342 and scale the input vectors @xmath331 , i.e. @xmath431 before we feed @xmath403 into the algorithm . to conclude the proof we apply lemma [ lemma : basic ] to this setting and observe that @xmath432 which yields @xmath433 .",
    "further note that the conjugate of @xmath78 is given by @xmath434 and this leads to the dual - to - primal mapping @xmath435",
    "[ [ elastic - net . ] ] elastic net .",
    "+ + + + + + + + + + + +    [ lem : elasticnetconjugate ] for @xmath436 $ ] , the elastic net function @xmath437 has the convex conjugate @xmath438_+\\big)^2 , \\ ] ] where @xmath439_+$ ] is the positive part operator , @xmath440_+ = s$ ] for @xmath441 , and zero otherwise .",
    "furthermore , this @xmath179 is @xmath442-smooth .",
    "we start by applying the definition of convex conjugate , that is : @xmath443 \\ , .\\vspace{-1mm}\\ ] ]    we now distinguish two cases for the optimal : @xmath444 , @xmath445 . for the first case we get that @xmath446 \\ , .\\ ] ] setting the derivative to @xmath447 we get @xmath448 . to satisfy @xmath444 , we must have @xmath449 . replacing with @xmath450",
    "we thus get : @xmath451 @xmath452 similarly we can show that for @xmath453 @xmath454 finally , by the fact that @xmath455 is convex , always positive , and @xmath456 , it follows that @xmath457 for every @xmath458 $ ] .    for the smoothness properties ,",
    "we consider the derivative of this function @xmath459 and see that @xmath459 is smooth , i.e. has lipschitz continuous gradient with constant @xmath442 , assuming @xmath460 . alternatively ,",
    "use lemma  [ lem : dualsmooth ] for the given strongly convex function @xmath168 .",
    "[ [ group - lasso . ] ] group lasso .",
    "+ + + + + + + + + + + +    the group lasso regularizer is a norm on @xmath461 , and is defined as @xmath462 for a fixed partition of the indices into disjoint groups , @xmath463 .",
    "here @xmath464 denotes the part of the vector @xmath37 with indices in the group @xmath465 $ ] .",
    "its dual norm is @xmath466 .",
    "therefore , by lemma  [ lem : normconjugates ] , we obtain the conjugate @xmath467 see , e.g. ( * ? ? ?",
    "* example 3.26 ) .",
    "[ [ logistic - loss . ] ] logistic loss .",
    "+ + + + + + + + + + + + + +    [ lem : logisticlossconj ] the logistic classifier loss function @xmath3 is given as @xmath468 its conjugate @xmath78 is given as : @xmath469 with the box constraint @xmath470 $ ] .",
    "furthermore , @xmath471 is @xmath191-strongly convex over its domain if the labels satisfy @xmath472 $ ] .",
    "see e.g. @xcite or @xcite ."
  ],
  "abstract_text": [
    "<S> we propose an algorithm - independent framework to equip existing optimization methods with primal - dual certificates . </S>",
    "<S> such certificates and corresponding rate of convergence guarantees are important for practitioners to diagnose progress , in particular in machine learning applications . </S>",
    "<S> + we obtain new primal - dual convergence rates , e.g. , for the lasso as well as many @xmath0 , elastic net , group lasso and tv - regularized problems . </S>",
    "<S> the theory applies to any norm - regularized generalized linear model . </S>",
    "<S> our approach provides efficiently computable duality gaps which are globally defined , without modifying the original problems in the region of interest .    </S>",
    "<S> = 1 </S>"
  ]
}