{
  "article_text": [
    "the basic problem in statistics is testing the agreement between actual observations and an underlying probability model .",
    "pearson in 1900 @xcite introduced the famous @xmath0 _ test _ where the sampling distribution approaches , as the sample size increases , to the @xmath0 distribution . recall that if @xmath1 are independent and identically distributed standard normal random variables , @xmath2 , then the distribution of ^2_n:=x_1 ^ 2++x_n^2[chisq]has density f_n(x)=\\ {    ll 12^n/2 ( n/2 ) x^n/2 -1 e^-x/2 & x>0 , + 0 & x0 ,    .[chidensity ] where @xmath3 is the gamma function .    in classical",
    "_ _ multivariate statistics _ _ it is commonly assumed that the underlying distribution is the multivariate normal distribution . if @xmath4 is a @xmath5-variate normal with @xmath6 and @xmath7 covariance matrix @xmath8 , and @xmath9 are vectors we denote by @xmath10 the matrix with @xmath11 matrix element @xmath12 . ]",
    "denoted @xmath13 , then if @xmath14 the density function of @xmath4 is @xmath15 , \\",
    ">   x\\in{\\mathbb{r}}^p,\\ ] ] where @xmath16 is the standard inner product on @xmath17 .",
    "it is convenient to introduce a matrix notation : if @xmath4 is a @xmath18 matrix ( the _ data matrix _ ) whose rows @xmath1 are independent @xmath13 random variables , @xmath19 then we say @xmath4 is @xmath20 where @xmath21 and @xmath22 is the @xmath23 identity matrix .",
    "we now introduce the multivariate generalization of ( [ chisq ] ) .    if @xmath24 , where the @xmath18 matrix @xmath4 is @xmath25 , then @xmath26 is said to have _ wishart distribution _ with @xmath27 degrees of freedom and covariance matrix @xmath28 .",
    "we write @xmath26 is @xmath29 .    to state the generalization of ( [ chidensity ] ) we first introduce the _ multivariate gamma function_. if @xmath30 is the space of @xmath7 positive definite , symmetric matrices , then @xmath31 where @xmath32 and @xmath33 is the product lebesgue measure of the @xmath34 distinct elements of @xmath26 .",
    "by introducing the matrix factorization @xmath35 where @xmath36 is upper - triangular with positive diagonal elements , one can evaluate this integral in terms of ordinary gamma functions , see , page 62 in @xcite .",
    "note that @xmath37 is the usual gamma function @xmath38 .",
    "the basic fact about the wishart distributions is    if @xmath26 is @xmath29 with @xmath39 , then the density function of @xmath26 is e^-12 ( ^-1 a ) ( a)^(n - p-1)/ 2 .",
    "[ wishartdensity ]    for @xmath40 and @xmath41 ( [ wishartdensity ] ) reduces to ( [ chidensity ] ) .",
    "the case @xmath42 was obtained by fisher in 1915 and for general @xmath43 by wishart in 1928 using geometrical arguments .",
    "most modern proofs follow james @xcite .",
    "the importance of the wishart distribution lies in the fact that the _ sample covariance matrix _ , @xmath44 , is @xmath45 where @xmath46 and @xmath1 , @xmath47 , are independent @xmath13 random vectors , and @xmath48 .",
    "principle component analysis , a multivariate data reduction technique , requires the eigenvalues of the sample covariance matrix ; in particular , the largest eigenvalue ( the largest principle component variance ) is most important .",
    "the next major result gives the joint density for the eigenvalues of a wishart matrix .",
    "if @xmath26 is @xmath29 with @xmath39 the joint density function of the eigenvalues @xmath49 of @xmath26 is @xmath50 where @xmath51 is the orthogonal group of @xmath7 matrices , @xmath52 is normalized haar measure and @xmath53 is the diagonal matrix @xmath54 .",
    "( we take @xmath55 . )",
    "the difficult part of this density function is the integral over the orthogonal group @xmath51 .",
    "there is no known closed formula for this integral though james and constantine ( see chap .",
    "7 in @xcite for references ) developed the theory of _ zonal polynomials _ which allow one to write infinite series expansions for this integral .",
    "however , these expansions converge slowly ; and zonal polynomials themselves , lack explicit formulas such as are available for schur polynomials . for complex wishart matrices , the group integral is over the unitary group @xmath56 ; and this integral can be evaluated using the harish - chandra - itzykson - zuber integral @xcite",
    ".    there is one important case where the integral can be ( trivially ) evaluated .    if @xmath57 , then the joint density ( [ wisharteigdensity ] ) simplifies to _ j=1^p _ j^(n - p-1)/2 ( -12_j _ j ) _ j < k(_j-_k ) .",
    "this section uses the theory of zonal polynomials as can be found in chap .  7 of muirhead @xcite or macdonald @xcite .",
    "this section is not used in the remainder of the chapter .",
    "let @xmath59 be a partition into not more than @xmath43 parts .",
    "we let @xmath60 denote the zonal polynomial of @xmath61 corresponding to @xmath62 .",
    "it is a symmetric , homogeneous polynomial of degree @xmath63 in the eigenvalues @xmath64 of @xmath61 .",
    "the normalization we adopt is defined by @xmath65 the fundamental integral formula for zonal polynomials is    let @xmath66 , then _ (",
    "p ) c_(x h y h^t ) dh = c_(x ) c_(y)c_(i_p ) [ zonalintegral]where @xmath52 is normalized haar measure .    by expanding the exponential and using ( [ zonalintegral ] ) it follows that _ ( p )",
    "( z ( xhyh^t ) ) dh = _",
    "k0 z^kk ! _ k ( ) p c_(x ) c_(y)c_(i_p ) .",
    "[ zonalexpansion ]    we examine ( [ zonalexpansion ] ) for the special case ( @xmath67 ) @xmath68 we have @xmath69 and @xmath70 for this choice of @xmath28 , let @xmath71 where @xmath72 , then @xmath73 where we used the fact that the only partition @xmath74 for which @xmath60 is nonzero is @xmath75 . and for this partition , @xmath76 . define the symmetric functions @xmath77 are the analogue of the complete symmetric functions @xmath78 .",
    "] by @xmath79 then it is known that @xcite @xmath80 using the known value of @xmath81 we find @xmath82 where @xmath83 is the pochammer symbol .",
    "in this section we define three fredholm determinants from which the edge eigenvalue distributions , for the three symmetry classes orthogonal , unitary and symplectic , will ensue .",
    "this section follows @xcite ; see also , @xcite",
    ".    in the unitary case ( @xmath84 ) , define the trace class operator @xmath85 on @xmath86 with _ airy kernel _ @xmath87 and associated fredholm determinant , @xmath88 , @xmath89 then we introduce the distribution functions f_2(s)=f_2(s,1 ) = d_2(s,1 ) , [ tw2 ] and for @xmath90 , the distribution functions @xmath91 are defined recursively below by ( [ lderiv ] ) .    in the symplectic case ( @xmath92 ) , we define the trace class operator @xmath93 on @xmath94 with matrix kernel k_4(x , y):=12 (    cc s_4(x , y ) & sd_4(x , y ) + is_4(x , y ) & s_4(y , x )    ) [ k4 ] where @xmath95 and the associated fredholm determinant , @xmath96 , @xmath97 then we introduce the distribution functions ( note the square root ) f_4(s)=f_4(s,1 ) = , [ tw4 ] and for @xmath90 , the distribution functions @xmath98 are defined recursively below by ( [ betaderiv ] ) .    in the orthogonal case ( @xmath99 )",
    ", we introduce the matrix kernel k_1(x , y):= (    cc s_1(x , y ) & sd_1(x , y ) + is_1(x , y)-(x , y ) & s_1(y , x )    ) [ k1 ] where @xmath100 the operator @xmath101 on @xmath94 with this matrix kernel is _ not _ trace class due to the presence of @xmath102 . as discussed in @xcite , one must use the weighted space @xmath103 , @xmath104 .",
    "now the determinant is the 2-determinant , @xmath105 where @xmath106 is the characteristic function of the interval @xmath107 .",
    "we introduce the distribution functions ( again note the square root ) f_1(s)=f_1(s,1 ) = , [ tw1 ] and for @xmath90 , the distribution functions @xmath108 are defined recursively below by ( [ betaderiv ] ) .",
    "this is the first indication that the determinant @xmath109 might be more subtle than either @xmath110 or @xmath111 .",
    "suppose @xmath26 is @xmath112 with eigenvalues @xmath113 .",
    "we define scaling constants @xmath114 the following theorem establishes , under the null hypothesis @xmath57 , that the largest principal component variance , @xmath115 , converges in law to @xmath116 .",
    "[ sec : wishart - ensembles-3 ] if @xmath117 such that @xmath118 , then @xmath119    johnstone s theorem generalizes to the @xmath120 largest eigenvalue .",
    "[ sec : wishart - ensembles-4 ] if @xmath117 such that @xmath118 , then @xmath121    soshnikov proved his result under the additional assumption @xmath122 .",
    "we remark that a straightforward generalization of johnstone s proof @xcite together with results of dieng @xcite show this restriction can be removed .",
    "subsequently , el karoui @xcite extended theorem [ sec : wishart - ensembles-4 ] to @xmath123 .",
    "the extension to @xmath124 is important for modern statistics where @xmath125 arises in applications .",
    "going further , soshnikov lifted the gaussian assumption , again establishing a @xmath116 universality theorem . in order to state the generalization precisely ,",
    "let us redefine the @xmath18 matrices @xmath126 such that @xmath127 to satisfy    1 .",
    "@xmath128 , @xmath129 .",
    "2 .   the random variables @xmath130 have symmetric laws of distribution .",
    "all even moments of @xmath130 are finite , and they decay at least as fast as a gaussian at infinity : @xmath131 .",
    "4 .   @xmath122 .    with these assumptions ,",
    "@xmath132    it is an important open problem to remove the restriction @xmath122 .    for real symmetric matrices , deift and gioev @xcite , building on the work of widom @xcite , proved @xmath116 universality when the gaussian weight function @xmath133 is replaced by @xmath134 where @xmath135 is an even degree polynomial with positive leading coefficient .",
    "table  [ table ] in section [ sec : numerics ] displays a comparison of the percentiles of the @xmath136 distribution with percentiles of empirical wishart distributions .",
    "here @xmath137 denotes the @xmath138 largest eigenvalue in the wishart ensemble .",
    "the percentiles in the @xmath137 columns were obtained by finding the ordinates corresponding to the @xmath136percentiles listed in the first column , and computing the proportion of eigenvalues lying to the left of that ordinate in the empirical distributions for the @xmath137 .",
    "the bold entries correspond to the levels of confidence commonly used in statistical applications .",
    "the reader should compare table  [ table ] to similar ones in @xcite .",
    "the gaussian @xmath139ensembles are probability spaces on @xmath140-tuples of random variables @xmath141 , with joint density functions @xmath142 given by ( times @xmath143 ) appears in front of the summation inside the exponential factor ( [ jointdensity ] ) , in addition to being the power of the vandermonde determinant .",
    "that convention originated in @xcite , and was justified by the alternative physical and very useful interpretation of as a one  dimensional coulomb gas model . in that language the potential @xmath144 and @xmath145 , so that @xmath146 plays the role of inverse temperature .",
    "however , by an appropriate choice of specialization in selberg s integral , it is possible to remove the @xmath139 in the exponential weight , at the cost of redefining the normalization constant @xmath147 .",
    "we choose the latter convention in this work since we will not need the coulomb gas analogy .",
    "moreover , with computer simulations and statistical applications in mind , this will in our opinion make later choices of standard deviations , renormalizations , and scalings more transparent .",
    "it also allows us to dispose of the @xmath148 that is often present in @xmath149 . ]",
    "@xmath150\\prod_{j < k}|\\ell_{j}-\\ell_{k}|^{\\beta}.\\ ] ] the @xmath147 are normalization constants , given by @xmath151 by setting @xmath152 we recover the ( finite @xmath140 ) _ gaussian orthogonal ensemble _ ( @xmath153 ) , _ gaussian unitary ensemble _ ( @xmath154 ) , and _ gaussian symplectic ensemble _ ( @xmath155 ) , respectively . for the remainder of the chapter we restrict to these three cases , and refer the reader to @xcite for recent results on the general @xmath139 case .",
    "originally the @xmath137 are eigenvalues of randomly chosen matrices from corresponding matrix ensembles , so we will henceforth refer to them as eigenvalues . with the eigenvalues ordered so that @xmath156 , define @xmath157 to be the rescaled @xmath120 eigenvalue measured from edge of spectrum .",
    "for the largest eigenvalue in the @xmath139ensembles ( proved only in the @xmath158 cases ) we have @xmath159 whose law is given by the tracy  widom distributions .",
    "@xmath160,\\label{guemax}\\\\      f_{1}(s)&=&{\\mathbb{p}}_{1}(\\hat{\\ell}_{1}\\leq s)=\\left(f_{2}(s)\\right)^{1/2 } \\ , \\exp\\left[-\\hf \\int_{s}^{\\infty}q(x)d\\,x\\right ] , \\label{goemax}\\\\      f_{4}(s)&=&{\\mathbb{p}}_{4}(\\hat{\\ell}_{1}\\leq s)=\\left(f_{2}(s)\\right)^{1/2 } \\ , \\cosh\\left[-\\frac{1}{2}\\int_{s}^{\\infty}q(x)d\\,x\\right ] .",
    "\\label{gsemax }    \\end{aligned}\\ ] ]    the function @xmath161 is the unique ( see @xcite ) solution to the painlev ii equation @xmath162 such that @xmath163 as @xmath164 , where @xmath165 is the solution to the airy equation which decays like @xmath166 at @xmath167 .",
    "the density functions @xmath168 corresponding to the @xmath169 are graphed in figure [ twdensities ] . , the density of @xmath170 is graphed to agree with mehta s original normalization @xcite as well as with @xcite . ]",
    "[ twdensities ]     let @xmath171 denote the distribution for the @xmath120 largest eigenvalue in gue .",
    "tracy and widom showed @xcite that if we define @xmath172 , then @xmath173 where ( [ fred2 ] ) has the painlev representation @xmath174,\\ ] ] and @xmath175 is the solution to such that @xmath176 as @xmath164 . the same combinatorial argument used to obtain the recurrence in the @xmath84 case also works for the @xmath177 cases , leading to @xmath178 where @xmath179 .",
    "given the similarity in the arguments up to this point and comparing to , it is natural to conjecture that @xmath180 can be obtained simply by replacing @xmath181 by @xmath175 in and .",
    "that this is not the case for @xmath99 was shown by dieng @xcite . a hint that @xmath99 is different comes from the following interlacing theorem .",
    "[ baikthm ] in the appropriate scaling limit , the distribution of the largest eigenvalue in gse corresponds to that of the second largest in goe .",
    "more generally , the joint distribution of every second eigenvalue in the goe coincides with the joint distribution of all the eigenvalues in the gse , with an appropriate number of eigenvalues .",
    "this interlacing property between goe and gse had long been in the literature , and had in fact been noticed by mehta and dyson @xcite . in this context , forrester and rains @xcite classified all weight functions for which alternate eigenvalues taken from an orthogonal ensemble form a corresponding symplectic ensemble , and similarly those for which alternate eigenvalues taken from a union of two orthogonal ensembles form an unitary ensemble .",
    "the following theorem gives explicit formulas for @xmath109 and @xmath111 ; and hence , from ( [ betaderiv ] ) , a recursive procedure to determine @xmath182 and @xmath183 for @xmath90 .    [ mainthm ] in the edge scaling limit , the distributions for the @xmath120 largest eigenvalues in the and satisfy the recurrence with    @xmath184    @xmath185    where @xmath186 and @xmath175 is the solution to such that @xmath176 as @xmath164 .",
    "note the appearance of @xmath187 in the arguments on the right hand side of ( [ goedet ] ) . in fig .",
    "2 we compare the densities @xmath188 , @xmath189 , with finite @xmath140 goe simulations .",
    "this last theorem also provides a new proof of the baik - rains interlacing theorem .",
    "@xmath190    the proofs of these theorems occupy the bulk of the remaining part of the chapter . in the last section , we present an efficient numerical scheme to compute @xmath191 and the associated density functions @xmath192 .",
    "we implemented this scheme using matlab , and compared the results to simulated wishart distributions .",
    "[ nextfigure ]   realizations of @xmath193 goe matrices ; the solid curves are , from right to left , the theoretical limiting densities for the first through fourth largest eigenvalue.,title=\"fig:\",height=245 ]",
    "we gather in this short section more or less classical results for further reference .",
    "[ vandthm ] @xmath194    [ detthm ] if @xmath195 are hilbert ",
    "schmidt operators on a general hilbert space @xmath196 , then @xmath197    [ debruijnthm ] @xmath198 @xmath199",
    "@xmath200    where @xmath201 denotes the pfaffian . the last two integral identities were discovered by de bruijn @xcite in an attempt to generalize the first one .",
    "the first and last are valid in general measure spaces . in the second identity",
    ", the space needs to be ordered . in the last identity ,",
    "the left hand side determinant is a @xmath202 determinant whose columns are alternating columns of the @xmath203 and @xmath204 ( i.e. the first four columns are @xmath205 , @xmath206 , @xmath207 , @xmath208 , respectively for @xmath209 ) , hence the notation , and asymmetry in indexing .    a large portion of the foundational theory of random matrices , in the case of invariant measures , can be developed from theorems  [ detthm ] and [ debruijnthm ] as was demonstrated in @xcite .      with the joint density function defined as in ,",
    "let @xmath210 denote the interval @xmath211 , and @xmath212 its characteristic function .",
    "is taken to be a finite union of open intervals in @xmath213 ( see @xcite ) .",
    "however , since we will only be interested in edge eigenvalues we restrict ourselves to @xmath211 from here on . ]",
    "we denote by @xmath214 the characteristic function of the complement of @xmath210 , and define @xmath215 .",
    "furthermore , let @xmath216 equal the probability that exactly the @xmath217 largest eigenvalues of a matrix chosen at random from a ( finite @xmath140 ) @xmath139ensemble lie in @xmath210 .",
    "we also define @xmath218 for @xmath219 this is just @xmath220 , the probability that no eigenvalues lie in @xmath211 , or equivalently the probability that the largest eigenvalue is less than @xmath221 .",
    "in fact we will see in the following propositions that @xmath222 is in some sense a generating function for @xmath216 .",
    "@xmath223    using the definition of the @xmath224 and multiplying out the integrand of gives @xmath225 where , in the notation of @xcite , @xmath226 is the @xmath227 elementary symmetric function .",
    "indeed each term in the summation arises from picking @xmath228 of the @xmath229-terms , each of which comes with a negative sign , and @xmath230 of the @xmath231 s .",
    "this explains the coefficient @xmath232 .",
    "moreover , it follows that @xmath233 contains @xmath234 terms .",
    "now the integrand is symmetric under permutations of the @xmath235 .",
    "also if @xmath236 , all corresponding terms in the symmetric function are @xmath237 , and they are @xmath231 otherwise",
    ". therefore we can restrict the integration to @xmath238 , remove the characteristic functions ( hence the symmetric function ) , and introduce the binomial coefficient to account for the identical terms up to permutation .",
    "@xmath239    this is proved by induction . as noted above",
    ", @xmath240 so it holds for the degenerate case @xmath241 .",
    "when @xmath242 we have @xmath243 the integrand is symmetric under permutations so we can make all terms look the same .",
    "there are @xmath244 of them so we get @xmath245 when @xmath246 then @xmath247 where we used the previous case to get the first equality , and again the invariance of the integrand under symmetry to get the second equality . by induction",
    "then ,    @xmath248    if we define @xmath249 to be the distribution of the @xmath120 largest eigenvalue in the ( finite @xmath140 ) @xmath139ensemble , then the following probabilistic result is immediate from our definition of @xmath216 .",
    "we follow @xcite for the derivations that follow .",
    "the gue case corresponds to the specialization @xmath84 in so that @xmath251 where @xmath252 , @xmath253 , and @xmath254 depends only on @xmath140 . in the steps that follow",
    ", additional constants depending solely on @xmath140 ( such as @xmath255 ) which appear will be lumped into @xmath254 . a probability argument",
    "will show that the resulting constant at the end of all calculations simply equals @xmath231 . expressing the vandermonde as a determinant @xmath256 and using with @xmath257 and @xmath258 yields @xmath259",
    "let @xmath260 be the sequence obtained by orthonormalizing the sequence @xmath261 .",
    "it follows that @xmath262 the last expression is of the form @xmath263 for @xmath264 with kernel @xmath265 whereas @xmath266 with kernel @xmath267 .",
    "note that @xmath268 has kernel @xmath269 whereas @xmath270 has kernel @xmath271 from theorem [ detthm ] it follows that @xmath272 where @xmath273 has kernel @xmath274 and @xmath275 acts on a function by first multiplying it by @xmath276 and acting on the product with @xmath273 . from we",
    "see that setting @xmath277 in the last identity yields @xmath278 .",
    "thus the above simplifies to @xmath279      we specialize @xmath252 , @xmath253 , so that the @xmath260 are in fact the hermite polynomials times the square root of the weight . using the plancherel - rotach asymptotics of hermite polynomials , it follows that in the _ edge scaling limit _ , @xmath280 is @xmath281 as defined in . as operators ,",
    "the convergence is in trace class norm to @xmath85 .",
    "( a proof of this last fact can be found in @xcite . ) for notational convenience , we denote the corresponding operator @xmath85 by @xmath282 in the rest of this subsection .",
    "it is convenient to view @xmath282 as the integral operator on @xmath283 with kernel @xmath284 where @xmath285 , @xmath286 and @xmath210 is @xmath287 with @xmath288 note that although @xmath289 , @xmath290 and @xmath291 are functions of @xmath292 as well , this dependence will not affect our calculations in what follows .",
    "thus we omit it to avoid cumbersome notation .",
    "the airy equation implies that @xmath290 and @xmath291 satisfy the relations @xmath293 we define @xmath294 to be the fredholm determinant @xmath295 .",
    "thus in the edge scaling limit @xmath296 we define the operator @xmath297 whose kernel we denote @xmath298 .",
    "incidentally , we shall use the notation @xmath299 in reference to an operator to mean `` has kernel '' .",
    "for example @xmath300 .",
    "we also let @xmath301 stand for the operator whose action is multiplication by @xmath302 .",
    "it is well known that @xmath303 for functions @xmath276 and @xmath304 , we write @xmath305 to denote the operator specified by @xmath306 and define @xmath307 then straightforward computation yields the following facts @xmath308 } & = & \\varphi\\otimes\\psi - \\psi\\otimes\\varphi,\\nonumber\\\\    { \\left[\\,m\\,,\\left(i - k\\right)^{-1}\\,\\right ] } & = & \\left(i - k\\right)^{-1}{\\left[\\,m\\,,k\\,\\right]}\\left(i - k\\right)^{-1 } \\nonumber\\\\    & = & q\\otimes p - p\\otimes q.\\end{aligned}\\ ] ] on the other hand if @xmath309 , then @xmath310 and it follows that @xmath311 } \\doteq ( x - y)\\rho(x , y)=(x - y)r(x , y).\\ ] ] equating the two representation for the kernel of @xmath312}$ ] yields @xmath313 taking the limit @xmath314 and defining @xmath315 , @xmath316 , we obtain @xmath317 let us now derive expressions for @xmath318 and @xmath319 . if we let the operator @xmath320 stand for differentiation with respect to @xmath302 , @xmath321\\varphi\\nonumber\\\\    & = & \\left(i - k\\right)^{-1 } \\psi +    \\left[d,\\left(i - k\\right)^{-1}\\right]\\varphi\\nonumber\\\\    & = & p(x ) + \\left[d,\\left(i - k\\right)^{-1}\\right]\\varphi . \\label{qderiv1}\\end{aligned}\\ ] ] we need the commutator @xmath322=\\left(i - k\\right)^{-1 } \\left[d , k\\right ] \\left(i - k\\right)^{-1}.\\ ] ] integration by parts shows @xmath323 \\doteq \\left ( \\frac{\\partial k}{\\partial x } + \\frac{\\partial k}{\\partial y}\\right ) + k(x , s ) \\delta(y - s).\\ ] ] the @xmath324 function comes from differentiating the characteristic function @xmath325 . moreover , @xmath326 thus @xmath327\\doteq - q(x ) q(y ) + r(x , s ) \\rho(s , y).\\ ] ] ( recall @xmath328 . )",
    "we now use this in ( [ qderiv1 ] ) to obtain @xmath329 where the inner product @xmath330 is denoted by @xmath331 .",
    "evaluating at @xmath332 gives @xmath333 we now apply the same procedure to compute @xmath334 .",
    "@xmath335\\psi\\\\    & = & m \\left(i - k\\right)^{-1 } \\varphi +   \\left[\\left(i - k\\right)^{-1},m\\right]\\varphi+    \\left[d,\\left(i - k\\right)^{-1}\\right]\\psi\\\\    & = & x q(x ) + \\left(p\\otimes q - q\\otimes p\\right)\\varphi + ( -q\\otimes q)\\psi +   r(x , s ) p(s)\\\\    & = & x q(x ) + p(x)\\left(q,\\varphi\\right ) -   q(x ) \\left(p,\\varphi\\right )   - q(x ) \\left(q,\\psi\\right)+r(x , s)p(s)\\\\    & = & x q(x ) - 2 q(x ) v(s ) + p(x ) u(s ) + r(x , s ) p(s).\\end{aligned}\\ ] ] here @xmath336 .",
    "setting @xmath332 we obtain @xmath337 using this and the expression for @xmath338 in ( [ rdiag ] ) gives @xmath339 using the chain rule , we have @xmath340 the first term is known .",
    "the partial with respect to @xmath341 is @xmath342 where we used the fact that @xmath343 adding the two partial derivatives and evaluating at @xmath332 gives @xmath344 a similar calculation gives @xmath345 we derive first order differential equations for @xmath346 and @xmath9 by differentiating the inner products .",
    "recall that @xmath347 thus @xmath348 similarly , @xmath349 from the first order differential equations for @xmath161 , @xmath346 and @xmath9 it follows immediately that the derivative of @xmath350 is zero .",
    "examining the behavior near @xmath351 to check that the constant of integration is zero then gives @xmath352 we now differentiate ( [ qeqn ] ) with respect to @xmath341 , use the first order differential equations for @xmath43 and @xmath346 , and then the first integral to deduce that @xmath161 satisfies the painlev ii equation ( [ pii ] ) . checking the asymptotics of the fredholm determinant @xmath353 for large @xmath341 shows we want the solution with boundary condition @xmath354 that a solution @xmath161 exists and is unique follows from the representation of the fredholm determinant in terms of it .",
    "independent proofs of this , as well as the asymptotics as @xmath355 were given by @xcite , @xcite , @xcite . since @xmath356}\\doteq ( \\partial/\\partial x~+~\\partial/\\partial y)~r(x , y)$ ] , ( [ dcomm ] ) says @xmath357 in computing @xmath358 we showed that @xmath359 adding these two expressions , @xmath360 and then evaluating at @xmath361 gives @xmath362 integration ( and recalling ( [ rderiv ] ) ) gives , @xmath363 and hence , @xmath364 to summarize , we have shown that @xmath365 has the painlev representation ( [ d2 ] ) where @xmath161 satisfies the painlev ii equation ( [ pii ] ) subject to the boundary condition ( [ bc ] ) .",
    "the gse corresponds case corresponds to the specialization @xmath92 in so that @xmath366 where @xmath252 , @xmath253 , and @xmath367 depends only on @xmath140 .",
    "as in the gue case , we will absorb into @xmath367 any constants depending only on @xmath140 that appear in the derivation .",
    "a simple argument at the end will show that the final constant is @xmath231 .",
    "these calculations follow @xcite . by ,",
    "@xmath368 is given by the integral @xmath369 which , if we define @xmath370 and @xmath371 and use the linearity of the determinant , becomes @xmath372 now using , we obtain @xmath373 where we let @xmath374 and @xmath375 in the last line .",
    "remembering that the square of a pfaffian is a determinant , we obtain @xmath376 row operations on the matrix do not change the determinant , so we can replace @xmath377 by an arbitrary sequence @xmath378 of polynomials of degree @xmath379 obtained by adding rows to each other .",
    "note that the general @xmath380 element in the matrix can be written as @xmath381\\,w(x ) \\,\\left(1+f(x)\\right).\\ ] ] thus when we add rows to each other the polynomials we obtain will have the same general form ( the derivatives factor ) . therefore we can assume without loss of generality that @xmath382 equals @xmath383\\,w(x)\\,\\left(1+f(x)\\right)\\,d\\,x\\right)_{_{0\\leq j , k\\leq 2\\,n-1}},\\ ] ] where the sequence @xmath378 of polynomials of degree @xmath379 is arbitrary .",
    "let @xmath384 so that @xmath385 . substituting this into the above formula and simplifying , we obtain @xmath386_{_{0\\leq j , k\\leq 2\\,n-1}}\\\\    &",
    "= & c_{4}^{(n)}\\ , \\det\\left[m + l\\right ] = c_{4}^{(n)}\\ , \\det[m]\\,\\det[i+ m^{-1}\\cdot l],\\end{aligned}\\ ] ] where @xmath387 are matrices given by @xmath388 @xmath389 note that @xmath390 $ ] is a constant which depends only on @xmath140 so we can absorb it into @xmath367 .",
    "also if we denote @xmath391 it follows that @xmath392 let @xmath393 be the operator defined by the @xmath394 matrix @xmath395 thus if @xmath396 we have @xmath397 similarly we define @xmath398 given by the @xmath399 matrix @xmath400 explicitly if @xmath401 then @xmath402 observe that @xmath403 .",
    "indeed @xmath404 \\alpha_{i } } \\\\        \\displaystyle{\\sum_{i=0}^{2n-1}\\left[\\int\\left ( \\eta_{1}\\psi_{i}^{\\prime}-\\eta_{1}^{\\prime}\\psi_{i}\\right)f\\ , d\\,x\\right ] \\alpha_{i } } \\\\        \\vdots      \\end{array }    \\right ) \\\\    & = & \\left\\{\\int\\left(\\eta_{j}\\psi_{k}^{\\prime}-\\eta_{j}^{\\prime}\\psi_{k}\\right)f\\ , d\\,x \\right\\}\\cdot     \\left (      \\begin{array}{c }        \\alpha_{0 }   \\\\        \\alpha_{1 } \\\\         \\vdots      \\end{array }    \\right )     = \\left ( m^{-1}\\cdot l\\right ) \\alpha.\\end{aligned}\\ ] ] therefore , by @xmath405 where @xmath406 . from our definition of @xmath26 and",
    "@xmath407 it follows that @xmath408 where @xmath409 is the integral operator with matrix kernel @xmath410 recall that @xmath411 so that @xmath412 define @xmath413 to be the following integral operator @xmath414 as before , let @xmath320 denote the operator that acts by differentiation with respect to @xmath302 .",
    "the fundamental theorem of calculus implies that @xmath415 .",
    "we also define @xmath416 since @xmath301 is antisymmetric , @xmath417 after re - indexing .",
    "note that @xmath418 and @xmath419 thus we can now write succinctly @xmath420 to summarize , we have shown that @xmath421 .",
    "setting @xmath422 on both sides ( where the original definition of @xmath368 as an integral is used on the left ) shows that @xmath423 .",
    "thus @xmath424 where we define @xmath425 and @xmath409 is the integral operator with matrix kernel .",
    "we would like to specialize the above results to the case of a gaussian weight function @xmath426 and indicator function @xmath427 we want the matrix @xmath428 to be the direct sum of @xmath140 copies of @xmath429 so that the formulas are the simplest possible , since then @xmath430 can only be @xmath237 or @xmath431 . in that case",
    "@xmath301 would be skew ",
    "symmetric so that @xmath432 . in terms of the integrals defining the entries of @xmath301",
    "this means that we would like to have @xmath433 @xmath434 and otherwise @xmath435 it is easier to treat this last case if we replace it with three non - exclusive conditions @xmath436 @xmath437 ( so when the parity is the same for @xmath438 , which takes care of diagonal entries , among others ) and @xmath439 whenever @xmath440 , which targets entries outside of the tridiagonal .",
    "define @xmath441 where the @xmath442 are the usual hermite polynomials defined by the orthogonality condition @xmath443 then it follows that @xmath444 now let @xmath445 this definition satisfies our earlier requirement that @xmath384 with @xmath446 defined in .",
    "in particular we have in this case @xmath447 let @xmath413 as in , and @xmath320 denote the operator that acts by differentiation with respect to @xmath302 as before , so that @xmath448 .",
    "it follows that @xmath449d\\,x\\\\      & = \\frac{1}{2}\\int_{\\mathbb{r}}\\left[-\\epsilon\\,\\varphi_{_{2j+1}}\\left(x\\right)\\frac{d}{d\\,x}\\,\\varphi_{_{2k+1}}\\left(x\\right ) + \\varphi_{_{2k+1}}\\left(x\\right)\\frac{d}{d\\,x}\\,\\epsilon\\,\\varphi_{_{2j+1}}\\left(x\\right)\\right]d\\,x\\\\      & = \\frac{1}{2}\\int_{\\mathbb{r}}\\left [ -\\epsilon\\,\\varphi_{_{2j+1}}\\left(x\\right)\\frac{d}{d\\,x}\\,\\varphi_{_{2k+1}}\\left(x\\right ) + \\varphi_{_{2k+1}}\\left(x\\right)\\varphi_{_{2j+1}}\\left(x\\right)\\right]d\\,x\\\\    \\end{aligned}\\ ] ] we integrate the first term by parts and use the fact that @xmath450 and also that @xmath451 vanishes at the boundary ( i.e. @xmath452 ) to obtain @xmath453d\\,x\\\\      & = \\frac{1}{2 } \\int_{\\mathbb{r}}\\left[-\\epsilon\\,\\varphi_{_{2j+1}}\\left(x\\right)\\frac{d}{d\\,x}\\,\\varphi_{_{2k+1}}\\left(x\\right ) + \\varphi_{_{2k+1}}\\left(x\\right)\\varphi_{_{2j+1}}\\left(x\\right)\\right]d\\,x\\\\      & = \\frac{1}{2 }   \\int_{\\mathbb{r}}\\left [ \\varphi_{_{2j+1}}\\left(x\\right)\\,\\varphi_{_{2k+1}}\\left(x\\right)+\\varphi_{_{2k+1}}\\left(x\\right)\\varphi_{_{2j+1}}\\left(x\\right)\\right]d\\,x\\\\      & = \\frac{1}{2 }   \\int_{\\mathbb{r}}\\left [ \\varphi_{_{2j+1}}\\left(x\\right)\\,\\varphi_{_{2k+1}}\\left(x\\right)+\\varphi_{_{2k+1}}\\left(x\\right)\\varphi_{_{2j+1}}\\left(x\\right)\\right]d\\,x\\\\      & = \\frac{1}{2 } \\left(\\delta_{j , k}+ \\delta_{j , k}\\right)\\\\      & = \\delta_{j , k } ,    \\end{aligned}\\ ] ] as desired .",
    "similarly @xmath454d\\,x\\\\      & = \\frac{1}{2}\\int_{\\mathbb{r}}\\left[-\\varphi_{_{2j+1}}\\left(x\\right)\\frac{d}{d\\,x}\\,\\epsilon\\,\\varphi_{_{2k+1}}\\left(x\\right ) + \\epsilon\\,\\varphi_{_{2k+1}}\\left(x\\right)\\frac{d}{d\\,x}\\,\\varphi_{_{2j+1}}\\left(x\\right)\\right]d\\,x \\\\      & = -\\delta_{j , k}.    \\end{aligned}\\ ] ] moreover , @xmath455 is certainly an odd function , being the multiple of and odd hermite polynomial . on the other hand ,",
    "one easily checks that @xmath413 maps odd functions to even functions on @xmath456",
    ". therefore @xmath457 is an even function , and it follows that @xmath458d\\,x\\\\      & = \\int_{\\mathbb{r}}\\left[p_{2j}(x)\\frac{d}{d\\,x}\\,p_{2k}(x)-p_{2k}(x)\\frac{d}{d\\,x}\\,p_{2j}(x)\\right]w(x)\\,d\\,x\\\\      & = 0 ,    \\end{aligned}\\ ] ] since both terms in the integrand are odd functions , and the weight function is even .",
    "similarly , @xmath459d\\,x\\\\      & = \\int_{\\mathbb{r}}\\left[p_{2j+1}(x)\\frac{d}{d\\,x}\\,p_{2k+1}(x)-p_{2k+1}(x)\\frac{d}{d\\,x}\\,p_{2j+1}(x)\\right]w(x)\\,d\\,x\\\\      & = 0 .",
    "\\end{aligned}\\ ] ] finally it is easy to see that if @xmath440 then @xmath460d\\,x=0.\\ ] ] indeed both differentiation and the action of @xmath413 can only `` shift '' the indices by @xmath231 . thus by orthogonality of the @xmath203 , this integral",
    "will always be @xmath237 .",
    "hence by choosing @xmath461 we force the matrix @xmath462 to be the direct sum of @xmath140 copies of @xmath463 hence @xmath432 where @xmath464 . moreover , with our above choice , @xmath465 if @xmath438 have the same parity or @xmath440 , and @xmath466 for @xmath467 . therefore @xmath468 .",
    "\\end{aligned}\\ ] ] recall that the @xmath469 satisfy the differentiation formulas ( see for example @xcite , p. 280 ) @xmath470 @xmath471 combining ( [ gsevarphi ] ) and ( [ hermrec1 ] ) yields @xmath472 similarly , from ( [ gsevarphi ] ) and ( [ hermrec2 ] ) we have @xmath473 combining and , we obtain @xmath474 let @xmath475 and @xmath476",
    ". then we can rewrite as @xmath477 where @xmath478 is the infinite antisymmetric tridiagonal matrix with @xmath479 .",
    "hence , @xmath480 moreover , using the fact that @xmath448 we also have @xmath481 combining the above results , we have @xmath482 note that @xmath483 unless @xmath484 , that is unless @xmath228 is even . thus we can rewrite the sum as @xmath485 where the last term takes care of the fact that we are counting an extra term in the sum that was not present before .",
    "the sum over @xmath379 on the right is just @xmath486 , and @xmath487 .",
    "therefore @xmath488 it follows that @xmath489 .",
    "\\end{aligned}\\ ] ] we redefine @xmath490 so that the top left entry of @xmath491 is @xmath492 if @xmath493 is the operator with kernel @xmath494 then integration by parts gives @xmath495 so that @xmath496 is in fact the kernel of @xmath497 .",
    "therefore now holds with @xmath409 being the integral operator with matrix kernel @xmath498 whose @xmath11entry @xmath499 is given by @xmath500 , \\\\",
    "k_{4,n}^{(1,2)}(x , y ) & = \\frac{1}{2}\\left [ sd_{n}(x , y ) -\\frac{d}{d\\,y } \\ , \\left(\\sqrt{\\frac{2n+1}{2}}\\ , \\varphi_{_{2n}}\\left(x\\right)\\epsilon\\,\\varphi_{_{2n+1 } } \\left(y\\right ) \\right ) \\right ] , \\\\",
    "k_{4,n}^{(2,1)}(x , y ) & = \\frac{\\epsilon}{2}\\left [ s_{n}(x , y ) +   \\sqrt{\\frac{2n+1}{2}}\\ , \\varphi_{_{2n}}\\left(x\\right)\\epsilon\\,\\varphi_{_{2n+1}}\\left(y\\right ) \\right],\\\\       k_{4,n}^{(2,2)}(x , y ) & = \\frac{1}{2}\\left [ s_{n}(x , y ) + \\sqrt{\\frac{2n+1}{2}}\\ , \\epsilon\\,\\varphi_{_{2n+1}}\\left(x\\right)\\,\\varphi_{_{2n}}\\left(y\\right)\\right ] .",
    "\\end{aligned}\\ ] ] we let @xmath501 so that @xmath140 is assumed to be odd from now on ( this will not matter in the end since we will take @xmath502 ) . therefore the @xmath499 are given by @xmath503 , \\\\",
    "k_{4,n}^{(1,2)}(x , y ) & = \\frac{1}{2}\\left [ sd_{n}(x , y ) -\\sqrt{\\frac{n}{2}}\\ , \\varphi_{_{n-1}}(x)\\,\\varphi_{_{n } } ( y ) \\right ] , \\\\      k_{4,n}^{(2,1)}(x ,",
    "y ) & = \\frac{\\epsilon}{2}\\left [ s_{n}(x , y ) +   \\sqrt{\\frac{n}{2}}\\ , \\varphi_{_{n-1}}(x)\\epsilon\\,\\varphi_{_{n}}(y ) \\right ] , \\\\      k_{4,n}^{(2,2)}(x ,",
    "y ) & = \\frac{1}{2}\\left [ s_{n}(x , y ) + \\sqrt{\\frac{n}{2}}\\ , \\epsilon\\,\\varphi_{_{n } } ( x)\\,\\varphi_{_{n-1}}(y)\\right ] ,    \\end{aligned}\\ ] ] where @xmath504 define @xmath505 so that @xmath506 \\,{\\raisebox{.4ex}{$\\chi$}}(y),\\\\       k_{4,n}^{(1,2)}(x , y ) & = \\frac{1}{2}\\,{\\raisebox{.4ex}{$\\chi$}}(x)\\,\\left [ sd_{n}(x , y ) - \\psi(x)\\varphi(y )   \\right]\\,{\\raisebox{.4ex}{$\\chi$}}(y),\\\\      k_{4,n}^{(2,1)}(x , y ) & = \\frac{1}{2}\\,{\\raisebox{.4ex}{$\\chi$}}(x)\\,\\left [ \\epsilon s_{n}(x , y ) + \\epsilon\\,\\psi(x)\\epsilon\\,\\varphi(y ) \\right]\\,{\\raisebox{.4ex}{$\\chi$}}(y),\\\\      k_{4,n}^{(2,2)}(x , y ) & = \\frac{1}{2}\\,{\\raisebox{.4ex}{$\\chi$}}(x)\\,\\left [ s_{n}(x , y ) + \\epsilon\\,\\varphi ( x)\\,\\psi(y)\\right]\\,{\\raisebox{.4ex}{$\\chi$}}(y ) .",
    "\\end{aligned}\\ ] ] notice that @xmath507 therefore @xmath508 note that this is identical to the corresponding operator for @xmath92 obtained by tracy and widom in @xcite , the only difference being that @xmath290 , @xmath291 , and hence also @xmath44 , are redefined to depend on @xmath292 .",
    "this will affect boundary conditions for the differential equations we will obtain later .",
    "we want to compute the fredholm determinant with @xmath409 given by and @xmath509 .",
    "this is the determinant of an operator on @xmath510 .",
    "our first task will be to rewrite the determinant as that of an operator on @xmath511 .",
    "this part follows exactly the proof in @xcite . to begin ,",
    "note that @xmath512}=\\varphi\\otimes\\psi + \\psi\\otimes\\varphi\\ ] ] so that , using the fact that @xmath448 , @xmath513 } & = & \\epsilon\\,s - s\\,\\epsilon\\nonumber\\\\    & = & \\epsilon\\,s\\,d\\,\\epsilon-\\epsilon\\,d\\,s\\,\\epsilon = \\epsilon\\,{\\left[\\,s\\,,d\\,\\right]}\\,\\epsilon\\nonumber\\\\    & = & \\epsilon\\,\\varphi\\otimes\\psi\\,\\epsilon + \\epsilon\\,\\psi\\otimes\\varphi\\,\\epsilon\\nonumber\\\\    & = & \\epsilon\\,\\varphi\\otimes\\epsilon^{t}\\psi + \\epsilon\\,\\psi\\otimes\\epsilon^{t}\\,\\varphi\\nonumber\\\\    & = & - \\epsilon\\,\\varphi\\otimes\\epsilon\\,\\psi -    \\epsilon\\,\\psi\\otimes\\epsilon\\,\\varphi,\\end{aligned}\\ ] ] where the last equality follows from the fact that @xmath514 .",
    "we thus have @xmath515 the expressions on the right side are the top matrix entries in .",
    "thus the first row of @xmath409 is , as a vector , @xmath516 now implies that @xmath517 similarly gives @xmath518 } = \\epsilon\\,\\varphi\\otimes\\psi + \\epsilon\\,\\psi\\otimes\\varphi,\\ ] ] so that @xmath519 using these expressions we can rewrite the first row of @xmath409 as @xmath520 now use to show the second row of @xmath409 is @xmath521 therefore , @xmath522 since @xmath409 is of the form @xmath523 , we can use [ detthm ] and deduce that @xmath524 is unchanged if instead we take @xmath525 to be @xmath526 therefore @xmath527 now we perform row and column operations on the matrix to simplify it , which do not change the fredholm determinant .",
    "justification of these operations is given in @xcite .",
    "we start by subtracting row 1 from row 2 to get @xmath528 next , adding column 2 to column 1 yields @xmath529    thus the determinant we want equals the determinant of @xmath530 so we have reduced the problem from the computation of the fredholm determinant of an operator on @xmath510 , to that of an operator on @xmath511 .",
    "next we want to write the operator in in the form @xmath531 where the @xmath532 and @xmath533 are functions in @xmath511 . in other words , we want to rewrite the determinant for the gse case as a finite dimensional perturbation of the corresponding gue determinant .",
    "the fredholm determinant of the product is then the product of the determinants .",
    "the limiting form for the gue part is already known , and we can just focus on finding a limiting form for the determinant of the finite dimensional piece .",
    "it is here that the proof must be modified from that in @xcite .",
    "a little rearrangement of yields ( recall @xmath514 ) @xmath534 writing @xmath535}+{\\raisebox{.4ex}{$\\chi$}}$ ] for @xmath536 and simplifying gives @xmath537 } - \\frac{\\lambda}{2}\\,\\epsilon\\,\\varphi\\,\\otimes\\,\\psi\\,\\epsilon\\,{\\left[\\,{\\raisebox{.4ex}{$\\chi$}}\\,,d\\,\\right]}.\\ ] ] let @xmath538 , and @xmath539 so that @xmath540 and goes to @xmath541 } - \\frac{1}{2}\\,\\epsilon\\,\\varphi\\,\\otimes\\,\\psi\\,\\epsilon\\,{\\left[\\,{\\raisebox{.4ex}{$\\chi$}}\\,,d\\,\\right]}.\\ ] ] now we define @xmath542 ( the resolvent operator of @xmath543 ) , whose kernel we denote by @xmath298 , and @xmath544 . then factors into @xmath545 where @xmath407 is @xmath546 } - \\frac{1}{2}\\,(q_{\\epsilon}\\,\\otimes\\,\\psi)\\,\\epsilon\\,{\\left[\\,{\\raisebox{.4ex}{$\\chi$}}\\,,d\\,\\right]}\\ ] ] hence @xmath547 in order to find @xmath548 we use the identity @xmath549}=\\sum_{k=1}^{2m}(-1)^{k}\\,\\epsilon_{k}\\otimes\\delta_{k},\\ ] ] where @xmath550 and @xmath551 are the functions @xmath552 and @xmath553 respectively , and the @xmath554 are the endpoints of the ( disjoint ) intervals considered , @xmath555 . in our case @xmath242 and @xmath556 , @xmath557 .",
    "we also make use of the fact that @xmath558 where @xmath559 is the usual @xmath560inner product .",
    "therefore @xmath561 } & = \\sum_{k=1}^{2 } ( -1)^{k}q_{\\epsilon}\\otimes\\psi\\cdot\\epsilon_{k}\\otimes\\delta_{k } \\\\     & = \\sum_{k=1}^{2 } ( -1)^{k}{\\left(\\,\\psi\\,,\\epsilon_{k}\\,\\right)}\\,q_{\\epsilon}\\otimes\\,\\delta_{k}.\\end{aligned}\\ ] ] it follows that @xmath562 is the determinant of @xmath563\\otimes\\delta_{k}.\\ ] ] we now specialize to the case of one interval @xmath564 , so @xmath242 , @xmath556 and @xmath557 .",
    "we write @xmath565 , and @xmath566 , and similarly for @xmath551 .",
    "writing out the terms in the summation and using the fact that @xmath567 yields @xmath568\\otimes\\delta_{t } + \\frac{1}{4}\\,\\left[(s+r\\,s)\\,1 + { \\left(\\,\\psi\\,,1\\,\\right)}\\,q_{\\epsilon}\\right]\\otimes\\delta_{\\infty}\\ ] ] now we can use the formula @xmath569 in order to simplify the notation in preparation for the computation of the various inner products , define @xmath570 @xmath571 @xmath572 where we remind the reader that @xmath573 stands for the function @xmath574 .",
    "note that all quantities in and are functions of @xmath221 and @xmath292 alone .",
    "furthermore , let @xmath575 recall from the previous section that when @xmath92 we take @xmath140 to be odd .",
    "it follows that @xmath290 and @xmath291 are odd and even functions respectively .",
    "thus when @xmath92 , @xmath576 while computation using known integrals for the hermite polynomials gives @xmath577 hence computation yields @xmath578 at @xmath579 , @xmath580 @xmath581 in , @xmath582 and if we denote @xmath583 , then we have explicitly @xmath584,\\quad\\alpha_{3 } = -\\frac{1}{4}\\,\\left[(s+r\\,s)\\,1 + { \\left(\\,\\psi\\,,1\\,\\right)}\\,q_{\\epsilon}\\right],\\ ] ] @xmath585 however notice that @xmath586 and @xmath587",
    ". therefore the terms involving @xmath588 are all @xmath237 and we can discard them reducing our computation to that of a @xmath589 determinant instead with @xmath584 , \\quad \\beta_{1}={\\raisebox{.4ex}{$\\chi$}}\\psi , \\quad   \\beta_{2}=\\delta_{t}.\\ ] ] hence @xmath590 we want the limit of the determinant @xmath591 as @xmath592 . in order to get our hands on the limits of the individual terms involved in the determinant , we will find differential equations for them first as in @xcite .",
    "adding @xmath593 times row 1 to row 2 shows that @xmath594 falls out of the determinant , so we will not need to find differential equations for it .",
    "thus our determinant is now @xmath595          \\frac{1}{2 } \\,\\mathcal{p}_{4 } & 1 + \\frac{1}{2}\\,\\mathcal{r}_{4 } \\\\[6pt ]        \\end{array }      \\right).\\ ] ] proceeding as in @xcite we find the following differential equations @xmath596 now we change variable from @xmath221 to @xmath341 where @xmath597 and take the limit @xmath592 , denoting the limits of @xmath598 , @xmath599 , @xmath600 , @xmath601 and the common limit of @xmath602 and @xmath603 respectively by @xmath604 , @xmath605 , @xmath606 , @xmath607 and @xmath608 . also @xmath605 and @xmath606 differ by a constant , namely @xmath609 .",
    "these limits hold uniformly for bounded @xmath341 so we can interchange @xmath610 and @xmath611 .",
    "also @xmath612 , where @xmath161 is as in .",
    "we obtain the systems @xmath613 @xmath614 the change of variables @xmath615 transforms these systems into constant coefficient ordinary differential equations @xmath616 @xmath617 since @xmath618 , corresponding to the boundary values at @xmath579 which we found earlier for @xmath619 , we now have initial values at @xmath620",
    ". therefore @xmath621 @xmath622 we use this to solve the systems and get @xmath623    substituting these expressions into the determinant gives , namely @xmath624 where @xmath625 .",
    "note that even though there are @xmath292terms in and , these do not appear in the final result , making it similar to the gue case where the main conceptual difference between the @xmath242 ( largest eigenvalue ) case and the general @xmath217 is the dependence of the function @xmath161 on @xmath292 .",
    "the right hand side of the above formula clearly reduces to the @xmath92 tracy - widom distribution when we set @xmath219 .",
    "note that where we have @xmath626 above , tracy and widom ( and hence many rmt references ) write @xmath627 instead .",
    "tracy and widom applied the change of variable @xmath628 in their derivation in @xcite so as to agree with mehta s form of the @xmath92 joint eigenvalue density , which has @xmath629 in the exponential in the weight function , instead of @xmath630 in our case . to switch back to the other convention",
    ", one just needs to substitute in the argument @xmath631 for @xmath341 everywhere in our results . at this point",
    "this is just a cosmetic discrepancy , and it does not change anything in our derivations since all the differentiations are done with respect to @xmath292 anyway .",
    "it change conventions for rescaling data while doing numerical work though .",
    "the goe corresponds case corresponds to the specialization @xmath99 in so that @xmath632 where @xmath252 , @xmath253 , and @xmath633 depends only on @xmath140 .",
    "as in the gse case , we will lump into @xmath633 any constants depending only on @xmath140 that appear in the derivation . a simple argument at the end will show that the final constant is @xmath231 .",
    "these calculations more or less faithfully follow and expand on @xcite .",
    "we want to use , which requires an ordered space .",
    "note that the above integrand is symmetric under permutations , so the integral is @xmath634 times the same integral over ordered pairs @xmath635 .",
    "so we can rewrite [ eq:17 ] as @xmath636 where we can remove the absolute values since the ordering insures that @xmath637 for @xmath638 .",
    "recall that the vandermonde determinant is @xmath639 therefore what we have inside the integrand above is , up to sign @xmath640 note that the sign depends only on @xmath140 .",
    "now we can use with @xmath641 in using we square both sides so that the right hand side is now a determinant instead of a pfaffian .",
    "therefore @xmath642 equals @xmath643 shifting indices , we can write it as @xmath644 where @xmath645 is a constant depending only on @xmath140 , and is such that the right side is @xmath231 if @xmath422 .",
    "indeed this would correspond to the probability that @xmath646 , or equivalently to the case where the excluded set @xmath210 is empty .",
    "we can replace @xmath647 and @xmath648 by any arbitrary polynomials @xmath649 and @xmath650 , of degree @xmath379 and @xmath228 respectively , which are obtained by row operations on the matrix .",
    "indeed such operations would not change the determinant .",
    "we also replace @xmath651 by @xmath652 which just produces a factor of @xmath653 that we absorb in @xmath645 .",
    "thus @xmath642 now equals @xmath654 let @xmath655 so the above integral becomes @xmath656 partially multiplying out the term we obtain @xmath657 define @xmath658 so that @xmath642 is now @xmath659 let @xmath413 be the operator defined in .",
    "we can use operator notation to simplify the expression for @xmath642 a great deal by rewriting the double integrals as single integrals . indeed @xmath660 similarly , @xmath661 finally , @xmath662 it follows that @xmath663\\,d\\,x \\right)_{_{0\\leq j , k\\leq n-1}}.\\ ] ] if we let @xmath664 , and factor @xmath665 out , then @xmath666 equals @xmath667\\,d\\,x\\right)_{_{0\\leq j , k\\leq n-1 } } } i + \\right . \\nonumber\\\\ & \\left .",
    "m^{-1}\\cdot\\left(\\int\\left [ f\\,\\psi_{j}\\,\\epsilon\\,\\psi_{k } - f\\,\\psi_{k}\\,\\epsilon\\,\\psi_{j } -   f\\,\\psi_{k}\\,\\epsilon\\,(f\\,\\psi_{j } ) \\right]\\,d\\,x\\right)_{_{0\\leq j , k\\leq n-1 } } \\right)_{_{0\\leq j , k\\leq n-1}}\\end{aligned}\\ ] ] where the dot denotes matrix multiplication of @xmath668 and the matrix with the integral as its @xmath669entry .",
    "define @xmath670 and use it to simplify the result of carrying out the matrix multiplication . from it",
    "follows that @xmath665 depends only on @xmath140 we lump it into @xmath645 . thus @xmath642 equals @xmath671\\,d\\,x\\right)_{_{0\\leq j , k\\leq n-1 } } \\right)_{_{0\\leq j , k\\leq n-1}}.\\ ] ] recall our remark at the very beginning of the section that if @xmath422 then the integral we started with evaluates to @xmath231 so that @xmath672 which implies that @xmath673 .",
    "now @xmath642 is of the form @xmath263 where @xmath674 is a @xmath675 matrix @xmath676 whose @xmath138 row is given by @xmath677 therefore , if @xmath678 then @xmath679 is a column vector whose @xmath138 row is @xmath680 @xmath681\\,g_{1}\\,d\\,x + \\int f\\,\\eta_{j}\\,g_{2}\\,d\\,x.\\ ] ] similarly , @xmath682 is a @xmath683 matrix @xmath684 whose @xmath138 column is given by @xmath685 thus if @xmath686 then @xmath687 is the column vector of @xmath688 given by @xmath689 clearly @xmath690 and @xmath691 with kernel @xmath692 hence @xmath693 has kernel @xmath694 which can be written as @xmath695 since we are taking the determinant of this operator expression , and the determinant of the second term is just 1 , we can drop it .",
    "therefore @xmath696 where @xmath697 and @xmath698 has matrix kernel @xmath699 we define @xmath700 since @xmath301 is antisymmetric , @xmath701 note that @xmath702 whereas @xmath703 so we can now write succinctly @xmath704 so we have shown that @xmath705 where @xmath706 where @xmath698 is the integral operator with matrix kernel @xmath707 given in .",
    "we specialize the results above to the case of a gaussian weight function @xmath708 and indicator function @xmath709 note that this does not agree with the weight function in .",
    "however it is a necessary choice if we want the technical convenience of working with exactly the same orthogonal polynomials ( the hermite functions ) as in the @xmath710 cases . in turn",
    "the painlev function in the limiting distribution will be unchanged .",
    "the discrepancy is resolved by the choice of standard deviation .",
    "namely here the standard deviation on the diagonal matrix elements is taken to be @xmath231 , corresponding to the weight function . in",
    "the @xmath710 cases the standard deviation on the diagonal matrix elements is @xmath711 , giving the weight function .",
    "now we again want the matrix @xmath712 to be the direct sum of @xmath713 copies of @xmath714 so that the formulas are the simplest possible , since then @xmath430 can only be @xmath237 or @xmath431 . in that case",
    "@xmath301 would be skew ",
    "symmetric so that @xmath432 . in terms of the integrals defining the entries of @xmath301",
    "this means that we would like to have @xmath715 @xmath716 and otherwise @xmath717 it is easier to treat this last case if we replace it with three non - exclusive conditions @xmath718 @xmath719 ( so when the parity is the same for @xmath438 , which takes care of diagonal entries , among others ) , and @xmath720 whenever @xmath440 , which targets entries outside of the tridiagonal .",
    "define @xmath721 where the @xmath722 are the usual hermite polynomials defined by the orthogonality condition @xmath723 it follows that @xmath724 now let @xmath725 this definition satisfies our earlier requirement that @xmath726 for @xmath727 in this case for example @xmath728 with @xmath413 defined as in , and recalling that , if @xmath320 denote the operator that acts by differentiation with respect to @xmath302 , then @xmath448 , it follows that @xmath729 as desired . similarly ,",
    "integration by parts gives @xmath730 also @xmath731 is even since @xmath732 and @xmath733 are .",
    "similarly , @xmath734 is odd .",
    "it follows that @xmath735 , and @xmath736 , are respectively odd and even functions . from these observations ,",
    "we obtain @xmath737 since the integrand is a product of an odd and an even function .",
    "similarly @xmath738 finally it is easy to see that if @xmath440 , then @xmath739 indeed both differentiation and the action of @xmath413 can only `` shift '' the indices by @xmath231 .",
    "thus by orthogonality of the @xmath203 , this integral will always be @xmath237 .",
    "thus by our choice in , we force the matrix @xmath740 to be the direct sum of @xmath713 copies of @xmath741 this means @xmath432 where @xmath742 .",
    "moreover , @xmath743 if @xmath438 have the same parity or @xmath440 , and @xmath744 for @xmath745 .",
    "therefore @xmath746 .",
    "\\end{aligned}\\ ] ] manipulations similar to those in the @xmath92 case ( see through ) yield @xmath747 .",
    "\\end{aligned}\\ ] ] we redefine @xmath748 so that the top left entry of @xmath707 is @xmath749 if @xmath493 is the operator with kernel @xmath494 then integration by parts gives @xmath750 so that @xmath496 is in fact the kernel of @xmath497",
    ". therefore now holds with @xmath698 being the integral operator with matrix kernel @xmath707 whose @xmath11entry @xmath751 is given by @xmath752 , \\\\",
    "k_{1,n}^{(1,2)}(x , y ) & = \\left [ sd_{n}(x , y ) -\\frac{d}{d\\,y } \\ , \\left(\\sqrt{\\frac{n}{2}}\\ , \\varphi_{_{n-1}}\\left(x\\right)\\left(\\epsilon\\,\\varphi_{_{n}}\\right ) \\left(y\\right ) \\right ) \\right ] , \\\\",
    "k_{1,n}^{(2,1)}(x , y ) & = \\epsilon\\,\\left [ s_{n}(x , y ) +   \\sqrt{\\frac{n}{2}}\\ , \\varphi_{_{n-1}}\\left(x\\right)\\left(\\epsilon\\,\\varphi_{_{n}}\\right)\\left(y\\right)-1 \\right ] , \\\\",
    "k_{1,n}^{(2,2)}(x , y ) & = \\left [ s_{n}(x , y ) + \\sqrt{\\frac{n}{2}}\\,\\left(\\epsilon\\,\\varphi_{_{n}}\\right)\\left(x\\right)\\ , \\varphi_{_{n-1 } } \\left(y\\right)\\right ] .",
    "\\end{aligned}\\ ] ] define @xmath753 so that @xmath754 \\,{\\raisebox{.4ex}{$\\chi$}}(y),\\\\",
    "k_{1,n}^{(1,2)}(x , y ) & = { \\raisebox{.4ex}{$\\chi$}}(x)\\,\\left [ sd_{n}(x , y ) - \\psi(x)\\,\\varphi(y )   \\right]\\,{\\raisebox{.4ex}{$\\chi$}}(y ) , \\\\      k_{1,n}^{(2,1)}(x , y ) & = { \\raisebox{.4ex}{$\\chi$}}(x)\\,\\left [ \\epsilon s_{n}(x , y ) + \\epsilon\\,\\psi(x)\\,\\epsilon\\,\\varphi(y ) - \\epsilon(x - y ) \\right]\\,{\\raisebox{.4ex}{$\\chi$}}(y ) , \\\\      k_{1,n}^{(2,2)}(x , y ) & = { \\raisebox{.4ex}{$\\chi$}}(x)\\,\\left [ s_{n}(x , y ) + \\epsilon\\,\\varphi(x)\\,\\psi(y)\\right]\\,{\\raisebox{.4ex}{$\\chi$}}(y ) .",
    "\\end{aligned}\\ ] ] note that @xmath755 hence @xmath756    note that this is identical to the corresponding operator for @xmath99 obtained by tracy and widom in @xcite , the only difference being that @xmath290 , @xmath291 , and hence also @xmath44 , are redefined to depend on @xmath292 .",
    "the above determinant is that of an operator on @xmath757 .",
    "our first task will be to rewrite these determinants as those of operators on @xmath511 .",
    "this part follows exactly the proof in @xcite . to begin ,",
    "note that @xmath758}=\\varphi\\otimes\\psi + \\psi\\otimes\\varphi\\label{sdcom}\\ ] ] so that ( using the fact that @xmath448 ) @xmath759 } & = & \\epsilon\\,s - s\\,\\epsilon\\nonumber\\\\    & = & \\epsilon\\,s\\,d\\,\\epsilon-\\epsilon\\,d\\,s\\,\\epsilon = \\epsilon\\,{\\left[\\,s\\,,d\\,\\right]}\\,\\epsilon\\nonumber\\\\    & = & \\epsilon\\,\\varphi\\otimes\\psi\\,\\epsilon + \\epsilon\\,\\psi\\otimes\\varphi\\,\\epsilon\\nonumber\\\\    & = & \\epsilon\\,\\varphi\\otimes\\epsilon^{t}\\psi + \\epsilon\\,\\psi\\otimes\\epsilon^{t}\\,\\varphi\\nonumber\\\\    & = & - \\epsilon\\,\\varphi\\otimes\\epsilon\\,\\psi -    \\epsilon\\,\\psi\\otimes\\epsilon\\,\\varphi ,    \\label{escom}\\end{aligned}\\ ] ] where the last equality follows from the fact that @xmath514 .",
    "we thus have    @xmath515    the expressions on the right side are the top entries of @xmath698 .",
    "thus the first row of @xmath698 is , as a vector , @xmath516 now implies that @xmath517 similarly gives @xmath518 } = \\epsilon\\,\\varphi\\otimes\\psi + \\epsilon\\,\\psi\\otimes\\varphi,\\ ] ] so that @xmath519 using these expressions we can rewrite the first row of @xmath698 as @xmath520 applying @xmath413 to this expression shows the second row of @xmath698 is given by @xmath760 now use to show the second row of @xmath698 is @xmath761 therefore , @xmath762 since @xmath698 is of the form @xmath523 , we can use the fact that @xmath763 and deduce that @xmath764 is unchanged if instead we take @xmath698 to be @xmath765 therefore @xmath766 now we perform row and column operations on the matrix to simplify it , which do not change the fredholm determinant . justification of these operations is given in @xcite .",
    "we start by subtracting row 1 from row 2 to get    @xmath767    next , adding column 2 to column 1 yields @xmath768 then right - multiply column 2 by @xmath769 and add it to column 1 , and multiply row 2 by @xmath770 and add it to row 1 to arrive at    @xmath771    thus the determinant we want equals the determinant of @xmath772 so we have reduced the problem from the computation of the fredholm determinant of an operator on @xmath510 , to that of an operator on @xmath511 .",
    "next we want to write the operator in in the form @xmath773 where the @xmath532 and @xmath533 are functions in @xmath511 . in other words , we want to rewrite the determinant for the goe case as a finite dimensional perturbation of the corresponding gue determinant",
    ". the fredholm determinant of the product is then the product of the determinants .",
    "the limiting form for the gue part is already known , and we can just focus on finding a limiting form for the determinant of the finite dimensional piece .",
    "it is here that the proof must be modified from that in @xcite .",
    "a little simplification of yields @xmath774 writing @xmath535}+{\\raisebox{.4ex}{$\\chi$}}$ ] for @xmath536 and simplifying @xmath775 to @xmath776 gives    @xmath777 } - \\lambda\\,\\left(\\epsilon\\,\\varphi\\,\\otimes\\,\\psi\\right)\\,\\left(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}}\\right)\\,\\epsilon\\,{\\left[\\,{\\raisebox{.4ex}{$\\chi$}}\\,,d\\,\\right ] }   \\\\ & = i -   ( 2\\lambda-\\lambda^{2})\\,s\\,{\\raisebox{.4ex}{$\\chi$}}- ( 2\\lambda-\\lambda^{2})\\,(\\epsilon\\,\\varphi\\,\\otimes\\,{\\raisebox{.4ex}{$\\chi$}}\\,\\psi )    - \\lambda\\,s\\,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,\\epsilon\\,{\\left[\\,{\\raisebox{.4ex}{$\\chi$}}\\,,d\\,\\right ] } \\\\",
    "&    \\qquad    -   \\lambda\\,(\\epsilon\\,\\varphi\\,\\otimes\\,\\psi)\\,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,\\epsilon\\,{\\left[\\,{\\raisebox{.4ex}{$\\chi$}}\\,,d\\,\\right]}.\\end{aligned}\\ ] ]    define @xmath778 and let @xmath779 , and @xmath780 so that @xmath781 and goes to @xmath782 } \\\\ & -   \\frac{\\lambda}{\\tilde{\\lambda}}\\,(\\epsilon\\,\\varphi\\,\\otimes\\,\\psi)\\,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,\\epsilon\\,{\\left[\\,{\\raisebox{.4ex}{$\\chi$}}\\,,d\\,\\right]}.\\end{aligned}\\ ] ] now we define @xmath542 ( the resolvent operator of @xmath543 ) , whose kernel we denote by @xmath298 , and @xmath544 .",
    "then factors into    @xmath545    where @xmath407 is    @xmath783}\\\\ & -    \\frac{\\lambda}{\\tilde{\\lambda}}\\,(q_{\\epsilon}\\,\\otimes\\,\\psi)\\,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,\\epsilon\\,{\\left[\\,{\\raisebox{.4ex}{$\\chi$}}\\,,d\\,\\right]},\\qquad \\lambda\\neq 1.\\end{aligned}\\ ] ]    hence @xmath784 note that because of the change of variable @xmath781 , we are in effect factoring @xmath785 , rather that @xmath786 as we did in the @xmath92 case .",
    "the fact that we factored @xmath787 as opposed to @xmath788 is crucial here for it is what makes @xmath407 finite rank .",
    "if we had factored @xmath788 instead , @xmath407 would have been @xmath789 the first term on the last line is not finite rank , and the methods we have used previously in the @xmath92 case would not work here .",
    "it is also interesting to note that these complications disappear when we are dealing with the case of the largest eigenvalue ; then is no differentiation with respect to @xmath292 , and we just set @xmath219 in all these formulae . all the new troublesome terms vanish",
    "in order to find @xmath548 we use the identity @xmath790}=\\sum_{k=1}^{2 m } ( -1)^{k}\\,\\epsilon_{k}\\otimes\\delta_{k},\\ ] ] where @xmath550 and @xmath551 are the functions @xmath552 and @xmath553 respectively , and the @xmath554 are the endpoints of the ( disjoint ) intervals considered , @xmath555 .",
    "we also make use of the fact that @xmath558 where @xmath559 is the usual @xmath560inner product .",
    "therefore    @xmath791 } & = \\sum_{k=1}^{2 m } ( -1)^{k}q_{\\epsilon}\\otimes\\psi\\cdot ( 1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,\\epsilon_{k}\\otimes\\delta_{k } \\\\ & = \\sum_{k=1}^{2 m } ( -1)^{k}{\\left(\\,\\psi\\,,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,\\epsilon_{k}\\,\\right)}\\,q_{\\epsilon}\\otimes\\,\\delta_{k}.\\end{aligned}\\ ] ]    it follows that    @xmath792    equals the determinant of @xmath793\\otimes\\delta_{k}.\\ ] ] we now specialize to the case of one interval @xmath564 , so @xmath242 , @xmath556 and @xmath557 . we write @xmath565 , and @xmath566 , and similarly for @xmath551 . writing the terms in the summation and using the facts that @xmath567 and",
    "@xmath794 then yields @xmath795\\otimes(\\delta_{t}-\\delta_{\\infty})\\\\ \\qquad    + \\frac{\\lambda}{\\tilde{\\lambda } } \\left[(s+r\\,s)\\,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,{\\raisebox{.4ex}{$\\chi$}}+ { \\left(\\,\\psi\\,,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,{\\raisebox{.4ex}{$\\chi$}}\\,\\right)}\\,q_{\\epsilon}\\right]\\otimes\\delta_{t}\\end{aligned}\\ ] ] which , to simplify notation , we write as @xmath796\\otimes(\\delta_{t}-\\delta_{\\infty } ) \\\\",
    "\\qquad    + \\frac{\\lambda}{\\tilde{\\lambda } } \\left[(s+r\\,s)\\,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,{\\raisebox{.4ex}{$\\chi$}}+ \\tilde{a}_{1,\\lambda}\\,q_{\\epsilon}\\right]\\otimes\\delta_{t},\\end{aligned}\\ ] ] where @xmath797 now we can use the formula : @xmath798 in this case , @xmath582 , and @xmath799\\nonumber , \\\\",
    "\\alpha_{3}= & -\\frac{\\lambda}{\\tilde{\\lambda } } \\left[(s+r\\,s)\\,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,{\\raisebox{.4ex}{$\\chi$}}+ \\tilde{a}_{1,\\lambda}\\,q_{\\epsilon}\\right],\\nonumber \\\\ & \\beta_{1}={\\raisebox{.4ex}{$\\chi$}}\\psi , \\qquad   \\beta_{2}=\\delta_{t}-\\delta_{\\infty } , \\qquad \\beta_{3}=\\delta_{t}.\\end{aligned}\\ ] ] in order to simplify the notation , define    @xmath800",
    "@xmath801    @xmath802    note that all quantities in and are functions of @xmath221 alone .",
    "furthermore , let @xmath803 recall from the previous section that when @xmath99 we take @xmath140 to be even .",
    "it follows that @xmath290 and @xmath291 are even and odd functions respectively .",
    "thus @xmath804 for @xmath99 , and computation gives @xmath805 hence computation yields @xmath806 and at @xmath579 we have @xmath580 @xmath807 @xmath808 hence @xmath809 , \\\\",
    "{ \\left(\\,\\alpha_{2}\\,,\\beta_{2}\\,\\right ) } & = \\frac{\\lambda}{2\\,\\tilde{\\lambda}}\\,\\left[\\mathcal{r}_{1,\\lambda } + a_{1,\\lambda}\\,(q_{\\epsilon}-c_{\\varphi})\\right]\\label{example } , \\\\ { \\left(\\,\\alpha_{2}\\,,\\beta_{3}\\,\\right ) } & = \\frac{\\lambda}{2\\,\\tilde{\\lambda}}\\,\\left[\\mathcal{r}_{1,\\lambda } + a_{1,\\lambda}\\,q_{\\epsilon}\\right ] , \\\\ { \\left(\\,\\alpha_{3}\\,,\\beta_{1}\\,\\right ) } & = -\\frac{\\lambda}{\\tilde{\\lambda}}\\,\\left[\\tilde{\\mathcal{p}}_{1,\\lambda } - \\tilde{a}_{1,\\lambda}\\,(1-\\tilde{v}_{\\epsilon})\\right ] , \\\\ { \\left(\\,\\alpha_{3}\\,,\\beta_{2}\\,\\right ) } &",
    "= -\\frac{\\lambda}{\\tilde{\\lambda}}\\,\\left[\\tilde{\\mathcal{r}}_{1,\\lambda}+\\tilde{a}_{1,\\lambda}\\,(q_{\\epsilon } - c_{\\varphi})\\right ] , \\\\   { \\left(\\,\\alpha_{3}\\,,\\beta_{3}\\,\\right ) } & = -\\frac{\\lambda}{\\tilde{\\lambda}}\\ , \\left[\\tilde{\\mathcal{r}}_{1,\\lambda}+\\tilde{a}_{1,\\lambda}\\,q_{\\epsilon}\\right].\\end{aligned}\\ ] ] as an illustration ,",
    "let us do the computation that led to in detail .",
    "as in @xcite , we use the facts that @xmath810 , and @xmath811 which can be easily seen by writing @xmath812 .",
    "furthermore we write @xmath813 to mean @xmath814 in general , since all evaluations are done by taking the limits from within @xmath210 , we can use the identity @xmath815 inside the inner products .",
    "thus @xmath816\\\\ & = \\frac{\\lambda}{\\tilde{\\lambda}}\\,\\left[{\\left(\\,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,,(s+r^{t}\\,s)\\,\\left(\\delta_{t}-\\delta_{\\infty}\\right)\\,\\right ) } + a_{1,\\lambda}\\left(q_{\\epsilon}(t)-q_{\\epsilon}(\\infty)\\right)\\right]\\\\ & = \\frac{\\lambda}{\\tilde{\\lambda}}\\,\\left[{\\left(\\,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,,(s+r^{t}\\,s)\\,{\\raisebox{.4ex}{$\\chi$}}\\,\\left(\\delta_{t}-\\delta_{\\infty}\\right)\\,\\right ) } + a_{1,\\lambda}\\left(q_{\\epsilon}-c_{\\varphi}\\right)\\right]\\\\ & = \\frac{\\lambda}{\\tilde{\\lambda}}\\,\\left[{\\left(\\,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,,r(x , t)-r(x,\\infty)\\,\\right ) } + a_{1,\\lambda}\\left(q_{\\epsilon}-c_{\\varphi}\\right)\\right]\\\\ & = \\frac{\\lambda}{\\tilde{\\lambda}}\\,\\left[\\mathcal{r}_{1,\\lambda}(t)-\\mathcal{r}_{1,\\lambda}(\\infty ) + a_{1,\\lambda}\\left(q_{\\epsilon}-c_{\\varphi}\\right)\\right]\\\\ & = \\frac{\\lambda}{\\tilde{\\lambda}}\\,\\left[\\mathcal{r}_{1,\\lambda}(t ) + a_{1,\\lambda}\\left(q_{\\epsilon}-c_{\\varphi}\\right)\\right].\\end{aligned}\\ ] ] we want the limit of the determinant @xmath817 as @xmath592 .",
    "in order to get our hands on the limits of the individual terms involved in the determinant , we will find differential equations for them first as in @xcite .",
    "row operation on the matrix show that @xmath818 and @xmath819 fall out of the determinant ; to see this add @xmath820 times row 1 to row 2 and @xmath821 times row 1 to row 3 .",
    "so we will not need to find differential equations for them .",
    "our determinant is @xmath822          -\\frac{\\lambda\\,\\mathcal{p}_{1,\\lambda}}{2\\,\\tilde{\\lambda } } & 1 - \\frac{\\lambda\\,\\mathcal{r}_{1,\\lambda}}{2\\,\\tilde{\\lambda } }   & -\\frac{\\lambda\\,\\mathcal{r}_{1,\\lambda}}{2\\,\\tilde{\\lambda } } \\\\[6pt ]           \\frac{\\lambda\\,\\tilde{\\mathcal{p}}_{1,\\lambda}}{\\tilde{\\lambda } } & \\frac{\\lambda\\,\\tilde{\\mathcal{r}}_{1,\\lambda}}{\\tilde{\\lambda } } & 1 + \\frac{\\lambda\\,\\tilde{\\mathcal{r}}_{1,\\lambda}}{\\tilde{\\lambda } }        \\end{array }      \\right).\\ ] ] proceeding as in @xcite we find the following differential equations @xmath823 let us derive the first equation in for example . from @xcite ( equation @xmath824 ) , we have @xmath825 therefore @xmath826\\\\ & = q_{_{n } } + \\int_{-\\infty}^{t}\\frac{\\partial q}{\\partial t}\\,d\\,x - ( 1-\\lambda)\\left[q_{_{n}}+\\int_{\\infty}^{t}\\frac{\\partial q}{\\partial t}\\,d\\,x\\right ] \\\\ & = q_{_{n } } - q_{_{n}}\\int_{-\\infty}^{t}r(x , t)\\,d\\,x - ( 1-\\lambda)\\,q_{_{n}}+(1-\\lambda)\\,q_{_{n}}\\,\\int_{\\infty}^{t}r(x , t)\\,d\\,x \\\\ & = \\lambda\\,q_{_{n}}-q_{_{n}}\\,\\int_{-\\infty}^{\\infty}(1-\\lambda)\\,r(x , t)\\,d\\,x\\\\ & = \\lambda\\,q_{_{n}}-q_{_{n}}\\,\\mathcal{r}_{1,\\lambda } = q_{_{n}}\\left(\\lambda-\\mathcal{r}_{1,\\lambda}\\right).\\end{aligned}\\ ] ] now we change variable from @xmath221 to @xmath341 where @xmath827 .",
    "then we take the limit @xmath592 , denoting the limits of @xmath828 and the common limit of @xmath602 and @xmath603 respectively by @xmath829 and @xmath608 .",
    "we eliminate @xmath830 and @xmath831 by using the facts that @xmath832 and @xmath833 .",
    "these limits hold uniformly for bounded @xmath341 so we can interchange @xmath834 and @xmath611 .",
    "also @xmath835 , where @xmath161 is as in .",
    "we obtain the systems    @xmath836    @xmath837    @xmath838    the change of variables @xmath839 transforms these systems into constant coefficient ordinary differential equations    @xmath840    @xmath841    @xmath842    since @xmath618 , corresponding to the boundary values at @xmath579 which we found earlier for @xmath843 , we now have initial values at @xmath620 . therefore @xmath844 we use this to solve the systems and",
    "get @xmath845 substituting these expressions into the determinant gives , namely @xmath846 where @xmath625 . as mentioned in section [ sec : edgedistr ] , the functional form of the @xmath99 limiting determinant is very different from what one would expect , unlike in the @xmath92 case . also noteworthy",
    "is the dependence on @xmath847 instead of just @xmath292 .",
    "however one should also note that when @xmath292 is set equal to @xmath231 , then @xmath848 .",
    "hence in the largest eigenvalue case , where there is no prior differentiation with respect to @xmath292 , and @xmath292 is just set to @xmath231 , a great deal of simplification occurs .",
    "the above formula then nicely reduces to the @xmath99 tracy - widom distribution .",
    "the following series of lemmas establish corollary  :    define @xmath849 then @xmath850 satisfies the following recursion @xmath851 [ ajlemma ]    consider the expansion of the generating function @xmath852 around @xmath219 @xmath853 since @xmath854 , the statement of the lemma reduces to proving the following recurrence for the @xmath855 @xmath856 let @xmath857 these are the even and odd parts of @xmath276 relative to the reflection @xmath858 or @xmath859 .",
    "recurrence is equivalent to @xmath860 which is easily shown to be true .",
    "[ flemma ] define @xmath861 for @xmath778 . then @xmath862    the case @xmath863 is readily checked . the main ingredient for the general case is fa di bruno s formula @xmath864 where @xmath865 and the above sum is over all partitions of @xmath27 , that is all values of @xmath866 such that @xmath867 .",
    "we apply fa di bruno s formula to derivatives of the function @xmath868 , which we treat as some function @xmath869 . notice that for @xmath870 , @xmath871 is nonzero only when @xmath872 , in which case it equals @xmath873 . hence",
    ", in , the only term that survives is the one corresponding to the partition all of whose parts equal @xmath653 .",
    "thus we have @xmath874    @xmath875    therefore , recalling the definition of @xmath850 in and setting @xmath876 , we obtain @xmath877 similarly , using @xmath878 instead yields @xmath879 since @xmath880 . rearranging this last equality leads to .",
    "let @xmath881 and @xmath882 be as in and",
    ". then @xmath883    using the facts that @xmath884 , @xmath885 and @xmath886 we get    @xmath887    for notational convenience , define @xmath888 , and @xmath889 .",
    "then    for @xmath890 , @xmath891\\,d_{1}(s,\\lambda)\\,\\,\\bigg{\\vert}_{\\lambda=1}=\\frac{(-1)^{n}}{n!}\\,\\frac{\\partial^{n}}{\\partial\\,\\lambda^{n}}\\,d_{4}(s,\\lambda)\\,\\,\\bigg{\\vert}_{\\lambda=1}.\\ ] ] [ dlemma ]    let @xmath892 by the previous lemma , we need to show that @xmath893\\,d_{4}(s,\\tilde{\\lambda})\\,f(s,\\lambda)\\,\\,\\bigg{\\vert}_{\\lambda=1}\\ ] ] equals @xmath894 now formula applied to @xmath895 gives @xmath896 therefore @xmath897 similarly , @xmath898 therefore the expression in equals @xmath899\\,\\,\\bigg{\\vert}_{\\lambda=1}.\\end{aligned}\\ ] ]    now lemma  [ flemma ] shows that the square bracket inside the summation is zero unless @xmath900 , in which case it is @xmath231 .",
    "the result follows .    in an inductive proof of corollary  [ interlacingcor ] ,",
    "the base case @xmath901 is easily checked by direct calculation .",
    "lemma  [ dlemma ] establishes the inductive step in the proof since , with the assumption @xmath902 , it is equivalent to the statement @xmath903",
    "let @xmath904 so that @xmath905 equals @xmath161 from . in order to compute @xmath191",
    "it is crucial to know @xmath906 with @xmath907 accurately .",
    "asymptotic expansions for @xmath906 at @xmath908 are given in @xcite .",
    "in particular , we know that , as @xmath909 , @xmath910 is given by @xmath911 whereas @xmath912 can be expanded as @xmath913 these expansions are used in the algorithms below .",
    "quantities needed to compute @xmath914 are not only @xmath905 and @xmath915 but also integrals involving @xmath905 , such as @xmath916 instead of computing these integrals afterward , it is better to include them as variables in a system together with @xmath905 , as suggested in @xcite . therefore all quantities needed are computed in one step , greatly reducing errors , and taking full advantage of the powerful numerical tools in matlab . since @xmath917 the system closes , and can be concisely written @xmath918 we first use the matlab built  in runge ",
    "kutta  based ode solver ` ode45 ` to obtain a first approximation to the solution of between @xmath919 , and @xmath920 , with an initial values obtained using the airy function on the right hand side .",
    "note that it is not possible to extend the range to the left due to the high instability of the solution a little after @xmath921 .",
    "( this is where the transition region between the three different regimes in the so  called `` connection problem '' lies .",
    "we circumvent this limitation by patching up our solution with the asymptotic expansion to the left of @xmath920 . )",
    "the approximation obtained is then used as a trial solution in the matlab boundary value problem solver ` bvp4c ` , resulting in an accurate solution vector between @xmath919 and @xmath922 .",
    "similarly , if we define @xmath923 then we have the first  order system @xmath924 which can be implemented using ` bvp4c ` together with a `` seed '' solution obtained in the same way as for @xmath905 .                                                                                    &",
    "@xmath956 & @xmath957 & @xmath958 & @xmath956 & @xmath959 & @xmath958 + & @xmath960 & @xmath961 & @xmath962 & @xmath960 & @xmath963 & @xmath964 + & @xmath965 & @xmath966 & @xmath967 & @xmath968 & @xmath969 & @xmath970 + & @xmath971 & @xmath972 & @xmath973 & @xmath974 & @xmath975 & @xmath976 + & @xmath977 & @xmath978 & @xmath979 & @xmath980 & @xmath981 & @xmath982 + & @xmath983 & @xmath984 & @xmath985 & @xmath986 & @xmath987 & @xmath988 + & @xmath989 & @xmath990 & @xmath991 & @xmath992 & @xmath993 & @xmath994 + & @xmath995 & @xmath996 & @xmath997 & @xmath998 & @xmath997 & @xmath999 +        * acknowledgments : * the authors wish to thank harold widom without whom none of this would have been possible .",
    "we thank john harnad for the invitation to participate in the program on _ random matrices , random processes and integrable systems _ at the centre de recherches mathmatiques on the campus of the universit de montral .",
    "this work was supported by the national science foundation under grant dms0304414 .",
    "j. forrester and e.  m. rains , , in p.  bleher , a.  its , and s.  levy , editors , _ random matrix models and their applications _ , volume  40 of _ math .",
    "_ , pages 171207 .",
    "cambridge univ . press ,",
    "cambridge , 2001 ."
  ],
  "abstract_text": [
    "<S> this is an expository account of the edge eigenvalue distributions in random matrix theory and their application in multivariate statistics . </S>",
    "<S> the emphasis is on the painlev representations of these distribution functions . </S>"
  ]
}