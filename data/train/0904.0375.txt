{
  "article_text": [
    "non  abelian gauge theories are the most important ingredient in our present understanding of elementary particles and their interactions .",
    "in particular , quantum chromodynamics ( qcd ) is now universally believed to be the correct theory of the strong interactions . however , while perturbation theory has been used successfully in describing the scattering of particles by partons , the perturbative series does not converge at hadronic energy scales .",
    "moreover , the phenomena of confinement and the hadronic spectrum are fundamentally beyond the reach of perturbation theory . therefore , non - perturbative monte carlo simulations of lattice - regularised qcd are crucial in order to obtain a full description and understanding of qcd phenomena .",
    "the lattice regularisation with a lattice spacing @xmath0 does , however , introduce a sharp momentum cutoff at the momentum scale @xmath1 . connecting lattice measurements to their continuum counterparts therefore requires renormalisation factors accounting for the excluded high - frequency modes .",
    "in particular , renormalisation is needed for qcd matrix elements , and for fixing the bare quark masses to be used in the lattice lagrangian .",
    "renormalisation is also necessary to determine the running of the strong coupling constant @xmath2 and to relate the lattice regularisation scale @xmath3 to @xmath4 .",
    "since the lattice regularisation also introduces discretisation errors , renormalisations are also used to `` improve '' the lattice action in order to reduce these discretisation errors at a given lattice spacing .    while in some cases the renormalisation constants can be determined non - perturbatively @xcite",
    ", results at finite lattice spacing can depend upon the method used ( cf .",
    "e.g. @xcite ) , and non - perturbative methods do not cope well with operators that mix under renormalisation . for these reasons , lattice perturbation theory plays an important role in determining the renormalisation constants needed to extract continuum predictions from lattice qcd .",
    "given the breakdown of perturbation theory in low energy qcd , one might doubt whether it could work on the lattice .",
    "an argument in favour of its use is given in @xcite : since the renormalisation factors may be thought of as compensating for the ultraviolet modes excluded by the lattice regulator , and since for typical lattice spacings @xmath5 , the excluded modes have momenta in excess of 5 gev , the running qcd coupling @xmath6 is small enough that perturbation theory should rapidly converge .",
    "the wide range of results reviewed in @xcite show that perturbation theory is useful for a large range of lattice qcd processes .",
    "the assumption that non - perturbative effects do not contribute on these short length scales , can be tested directly in some cases by comparing higher order perturbative calculations with monte carlo simulations performed at a range of weak couplings @xcite ) , or by using so - called stochastic techniques @xcite . in all these cases , the non - perturbative contributions turned out to be small .",
    "other comparisons , such as @xcite , can not distinguish non - perturbative effects from higher - order perturbative corrections .",
    "lattice perturbation theory therefore provides a reliable , and the only systematically improvable , method for determining the full range of renormalisation constants @xcite . as in the continuum ,",
    "the calculation of lattice feynman diagrams is a two  stage process .",
    "first , the lattice action and any operator insertions are taylor  expanded in the ( bare ) coupling constant to give the propagators and vertices that form the feynman rules ( the `` vertex expansion '' stage ) .",
    "secondly , these rules are then used to construct and numerically evaluate feynman diagrams , possibly after some algebraic simplification ( the `` feynman diagram evaluation '' stage ) .",
    "the latter task is more complicated than in the continuum due to the presence of lorentz symmetry violating terms at finite lattice spacing , and on a finite lattice volume also by the more complicated nature of discrete momentum sums as compared to momentum integrals .",
    "diagrams are therefore usually evaluated using numerical routines like vegas@xcite , or proprietary mathematical packages , possibly after manipulation using other computer algebra packages like form @xcite .",
    "the greater difficulty is posed , however , by the task of vertex expansion .",
    "deriving the feynman results on the lattice is far more complicated than in the continuum for a number of reasons .",
    "firstly , lattice gauge fields are elements of the gauge lie group itself rather than of its lie algebra . to obtain the perturbative expansion of the action",
    ", we must therefore expand exponentials of non  commuting objects . as a consequence ,",
    "the feynman rules even for the simplest lattice action are already much more complicated than their continuum counterparts .",
    "secondly , modern lattice theories generally contain a large number of additional ( renormalisation group irrelevant ) terms chosen to improve specific aspects of the monte carlo simulation , such as the rate of approach to the continuum or chiral limits of qcd .",
    "since there is no unique prescription for these terms , and the best choice depends on which quantities we are most interested in simulating , a large number of different lattice actions and operators are in use .",
    "subtle though the differences between the lattice formulations may be , each choice provides a completely separate regularisation of qcd with its own set of renormalisation constants and in particular its own lattice feynman rules .",
    "for a long time , the complications of the perturbative expansion have led to the calculations of renormalisation factors lagging far behind new developments in the improvement of lattice theories . in many cases",
    "this has restricted the physical predictions that could be obtained from the simulations .    an automated method for deriving lattice feynman rules for as wide a range of different theories as possible",
    "is therefore highly desirable .",
    "the vertex expansion should be fast enough not to impose undue constraints on the choice of action . to avoid human error",
    ", the user should be able to specify the action in a compact and intuitive manner . since the evaluation of the feynman diagrams can be computationally intensive , and",
    "will often need to be carried out in parallel on costly supercomputing facilities , parsimony dictates that the feynman rules should be calculated in advance on a different system , and rendered as machine readable files that can be copied to the supercomputer for the feynman diagram evaluation stage .    in this paper",
    "we describe a pair of software packages for deriving the feynman rules for arbitrary lattice actions and for evaluating the resulting vertices in a numerical feynman diagram calculation .",
    "our algorithm is based through our older algorithm @xcite on the seminal work of lscher and weisz @xcite .",
    "a different implementation of the latter has been used in @xcite , and a similar method is employed in @xcite .",
    "the new feature of the algorithm presented here is that it is capable of expanding not only gluonic actions like the algorithm of @xcite , and fermionic actions like our algorithm from @xcite , but also far more complicated multiply - smeared fermionic actions with reunitarisation such as hisq @xcite , and that it supports taking advantage of the factorisation inherent in some lattice actions , such as improved lattice formulations of nrqcd @xcite . as in @xcite and @xcite ,",
    "the vertex expansion is performed completely independently of any boundary conditions , allowing for instance , the use of twisted periodic boundary conditions as a gauge  invariant infrared regulator @xcite or for changing the discrete momentum spectrum in other ways @xcite .",
    "we have used the software packages described for calculations of the renormalised anisotropy in gauge theories @xcite , to study the mean link in landau gauge for tadpole improvement @xcite , to measure the electromagnetic decays of heavy quark systems using nrqcd @xcite , to calculate the radiative corrections to the gluonic action due to highly improved staggered ( hisq ) sea quarks @xcite and the renormalisation of the self energy of heavy quarks using moving nrqcd ( mnrqcd ) @xcite .",
    "the code is flexible and can be easily extended , as has already been done for lattice  regularised chiral perturbation theory @xcite , perturbative calculations in the schrdinger functional @xcite and anisotropy calculations @xcite .",
    "the structure of this paper is as follows . in the next section ,",
    "we review the basic expansion algorithm described in ref .",
    "@xcite , outlining some improvements in , for instance , the handling of automatic derivatives and spin matrices . in sec .",
    "[ sec_new_stuff ] , we present novel extensions to the algorithm that are needed to describe complicated fermion actions , including hisq , nrqcd and mnrqcd .    sec .",
    "[ sec_software ] provides details of the implementation of the algorithm in the hippy  and hpsrc  codes and of their installation , testing and use .",
    "we make some concluding remarks in sec .",
    "[ sec_conc ] .",
    "technical details are relegated to the appendices .",
    "the hippy  and hpsrc  codes are released under the second version of the gnu general public licence ( gpl v2 ) .",
    "therefore anyone is free to use or modify the code for their own calculations .    as part of the licensing",
    ", we ask that any publications including results from the use of this code or of modifications of it cite refs .",
    "@xcite as well as this paper .",
    "finally , we also ask that details of these publications , as well as of any bugs or required or useful improvements of this core code , would be communicated to us .",
    "in this section we describe the algorithms used to give the most efficient , yet generic , implementation of the feynman rules for lattice actions .",
    "these extend the original work of lscher and weisz @xcite and developments described in ref .",
    "@xcite .",
    "we consider a @xmath7-dimensional hypercubic spacetime lattice with lattice spacing @xmath0 and extent @xmath8 in the @xmath9-direction : @xmath10 where lattice sites are labelled by a vector @xmath11 . in the following",
    ", we will usually set @xmath12 ( a lattice anisotropy can be introduced by rescaling the coupling constants in the action @xcite ) .",
    "let @xmath13 be a right - handed orthonormal basis , and @xmath14 .",
    "a lattice path consisting of @xmath15 links starting at site @xmath16 can be specified by an ordered set of directions given by integers , @xmath17 : @xmath18 \\ } \\ ; , \\label{eqn_path_def}\\ ] ] with the @xmath19 point on the path being @xmath20 and @xmath21",
    ".    for periodic boundary conditions , the momentum vectors are @xmath22 and the fourier expansion of a function @xmath23 is@xmath24 where @xmath25 is the lattice volume .",
    "twisted boundary conditions @xcite provide a useful gauge - invariant infrared regulator in perturbative calculations @xcite .",
    "these change the momentum spectrum , converting colour factors into `` twist matrices '' associated with momenta interstitial to the reciprocal lattice ( with the introduction of an additional quantum number , `` smell '' , for fermions @xcite ) .",
    "the hpsrc  code fully supports such boundary conditions but for simplicity we only discuss periodic boundary conditions in this paper .    following ref .",
    "@xcite , we denote the gauge field associated with a link as @xmath26 , and define @xmath27 .",
    "the gauge potential @xmath28 associated with the midpoint of the link is defined through @xmath29 where @xmath30 is the bare coupling constant . in terms of the anti - hermitian generators of @xmath31 ,",
    "@xmath32 = -f_{abc } t_c , \\qquad { \\mathop{\\mathrm{tr}}}\\left ( t_a t_b \\right ) = -{\\frac{1}{2}}\\ , \\delta_{ab } \\;.\\ ] ] quark fields @xmath33 transform according to the representation chosen for the generators @xmath34 , which we take to be the fundamental representation ( other choices will affect the colour factors , but not the structure of our algorithm ) .",
    "the wilson line @xmath35 associated with the lattice path @xmath36 is a product of links @xmath37 \\ ; .\\ ] ] as all actions and operators can be written as sums of wilson lines ( possibly terminated by fermion fields ) , our goal is to efficiently expand @xmath38 in terms of the gauge potential in momentum space : @xmath39 the vertex functions @xmath40 factorise as @xmath41 with a momentum- and path - independent clebsch ",
    "gordan ( colour ) factor @xmath42 @xmath43 it is therefore more efficient to calculate just the expansion of the reduced vertex functions , @xmath44 ( with an appropriate description of the colour trace structure where ambiguous  see appendix  b of ref .",
    "@xcite for further details ) . the reduced vertex function can be written as a sum of terms , each of which contains an exponential . for convenience",
    ", we will call each term a `` monomial '' : @xmath45 where for each combination of @xmath46 lorentz indices we have @xmath47 terms , each with an amplitude @xmath48 and locations @xmath49 of the @xmath46 factors of the gauge potential , which are drawn from the locations of the midpoints of the links in the path @xmath50 . to avoid floating point ambiguities",
    ", we express the components of all position @xmath7-vectors as integer multiples of @xmath51 ( accounting for the factor of @xmath52 in the exponent ) .    in the hpsrc  code , we use the convention that all momenta flow into the vertex , so @xmath53 .",
    "( [ eqn_y ] ) makes clear that the number of monomials depends not just on the number of gluons @xmath46 , but also on the choice of lorentz indices @xmath54 , and that each monomial has a different amplitude and set of @xmath46 positions . for clarity of presentation",
    ", we will , however , suppress these additional arguments in later expressions ( notably eqns .",
    "( [ eqn_sy ] ,  [ eqn_gy ] ,  [ eqn_diff_y ] ,  [ eqn_zy ] ,  [ eqn_xy ] ) ) .",
    "the generation of the feynman rules for generic momenta thus reduces to a calculation of the amplitudes @xmath48 and locations @xmath49 of the monomials that build up the various reduced vertices @xmath55 .",
    "this is all carried out in the hippy  code , a description of which can be found in sec .  4 of ref .",
    "the amplitudes and locations defining each monomial are encoded as an instance of the class ` entity ` , and the collection of monomials that make up the reduced vertices is encoded as an instance of class ` field ` .",
    "the data structures have been chosen to ensure that equivalent monomials are combined to minimise the size of the reduced vertex description .",
    "once expanded , the monomials required for the reduced vertices at each order are written to disk as a text file .",
    "the hpsrc  code reads these ( previously generated ) vertex files at runtime . for given momenta @xmath56 , lorentz indices @xmath57 and colour indices , the @xmath55 are constructed as given in eqn .  ( [ eqn_y ] ) , which is then multiplied by the appropriate clebsch - gordan colour factor(s ) to form the ( euclidean ) feynman rule , @xmath58 .",
    "realistic lattice fermion and gauge actions require some refinements to this generic description .",
    "we begin with the fermion sector .",
    "the most general gauge- and translation - invariant action can be written as @xmath59 and consists of wilson lines @xmath60 defined by open paths @xmath61 , each carrying an associated coupling constant @xmath62 and a spin matrix @xmath63 ( possibly the identity ) .    using the convention that all momenta flow into the vertex ,",
    "the perturbative expansion is @xmath64 the euclidean feynman rule for the @xmath46-point gluon ",
    "anti - fermion vertex is @xmath65 , where the symmetrised vertex is : @xmath66 where @xmath67 is the permutation group of @xmath46 objects and @xmath68 is applied to the gluonic variables , @xmath56 , @xmath57 and @xmath69 .",
    "the normalisation factor of @xmath70 for this is additional to the @xmath70 factor arising from the taylor expansion of the exponential in eqn .",
    "( [ eqn_ss ] ) .",
    "the reduced vertex @xmath71 is the sum of contributions from paths @xmath72 .    in most cases",
    "the clebsch - gordan colour factor is the matrix element : @xmath73 and the reduced vertex function has the structure : @xmath74 where we understand @xmath75 .",
    "cases with more complicated colour structures do arise , for example the use of traceless field strengths in qcd .",
    "such structures are accommodated in the codes ; monomials with different colour structures are distinguished using `` pattern lists '' ( discussed in appendix  b of ref .",
    "@xcite ) and appropriate colour factors are applied to each when the feynman rule is constructed .",
    "as there are no permutation symmetries in @xmath76 , there is no advantage to carrying out any symmetrisation in the hippy  expansion code . in the hpsrc  code , symmetrisation of the feynman rule shown in eqn .",
    "( [ eqn_ferm_symm ] ) carries a potentially significant computational overhead : the reduced vertices must be calculated afresh for each permutation .",
    "not all such permutations may be needed because symmetries of a feynman diagram can reduce the number of distinct contributions to its value from the terms in eqn .",
    "( [ eqn_ferm_symm ] ) . for this reason",
    ", symmetrisation is not carried automatically in the hpsrc  code and the user must therefore explicitly construct all permutations requiring a different calculation from eqn .",
    "( [ eqn_ferm_symm ] ) , applying the appropriate normalisation factor .",
    "a typical gluonic action is @xmath77   \\ ; , \\label{eqn_gen_glue}\\ ] ] built of wilson loops @xmath78 defined by closed paths @xmath79 , each with coupling constant @xmath80 .",
    "the perturbative action is @xmath81 the euclidean feynman rule for the @xmath46-point gluon vertex function is @xmath82 , and the vertex @xmath83 is @xcite @xmath84 the reduced vertex @xmath85 is the sum of contributions from paths @xmath86 . as before , the @xmath87 factor normalises the symmetrisation .",
    "@xmath88 can be expanded as @xmath89 in most cases we expect the lattice action to be real .",
    "thus , for every monomial @xmath90 in eqn .",
    "( [ eqn_gy ] ) , there must be a corresponding term @xmath91 . we can therefore speed up the evaluation of the feynman rules by removing the latter term , and replacing the exponentiation in eq .",
    "( [ eqn_gy ] ) with `` @xmath92 '' for @xmath46 even , and with `` @xmath93 '' for @xmath46 odd .",
    "this can either be done by recognising conjugate contours in the action ( e.g. @xmath94 $ ] ) and expanding only one , or by attaching a flag to each monomial to signal whether its complex conjugate has already been removed .    if in addition the action has the form eq .",
    "( [ eqn_gen_glue ] ) with a single trace in the fundamental representation , the colour factors are @xmath95 \\ ; . \\label{cg_notwist}\\ ] ] which has a number of permutation symmetries : @xmath96 there is thus a great advantage in carrying out some of the symmetrisation in eqn .",
    "( [ eqn_symmetrise ] ) at the expansion stage in the hippy  code .",
    "many of the extra monomials generated by symmetrising over subgroup @xmath97 ( generated by cyclic permutations and inversion ) are equivalent and can be combined in the hippy  code , significantly reducing the number of exponentiation operations required to construct the partially - symmetrised @xmath98 : @xmath99 @xmath100 the @xmath101 factors go into the amplitudes of the new monomials coming from the partial symmetrisation .",
    "the number of symmetrisation steps remaining to be carried out in the hpsrc  code is the number of cosets in @xmath102 ( one for @xmath103 , three for @xmath104 , twelve for @xmath105 etc . ) .",
    "these symmetrisation steps ( and the normalisation ) are carried out automatically in the hpsrc  gluon vertex modules .      in many cases , such as when computing wavefunction renormalisation constants , one needs to calculate the derivative of a feynman diagram with respect to one or more momenta . whilst derivatives can be computed numerically using an appropriate local difference operator , such differencing schemes are frequently numerically unstable and require computing the feynman diagram multiple times .",
    "automatic differentiation methods @xcite are a stable and cost - saving alternative",
    ".    we can easily construct the differentiated feynman vertex using eqn .",
    "( [ eqn_y ] ) .",
    "if we want to differentiate with repsect to momentum component @xmath106 , we first construct a rank @xmath46 object @xmath107 $ ] which represents the proportion of momentum @xmath108 in each leg of the feynman diagram .",
    "momentum conservation dictates @xmath109 . for instance , for a gluon 3-point function with incoming momenta @xmath110 , we would have @xmath111 $ ] .",
    "the differentiated vertex is @xmath112 and so on for higher derivatives .",
    "we may therefore simultaneously calculate as many differentials as we need for the cost of just one exponentiation . if this momentum expansion is placed into an appropriate data structure for which appropriately overloaded operations have been defined , it is straightforward to create the taylor series for a feynman diagram by simply multiplying the vertex factors together .",
    "we use a slightly modified version of the taylur package @xcite to do this , which encodes the taylor series expansion in the hpsrcfortran code as a derived type ` taylor ` , for which all arithmetic operations and elementary functions have been overloaded so as to respect leibniz s and fa di bruno s rules for higher derivatives of products and functions .    in calculations that require only certain higher - order derivatives ,",
    "the taylor multiplication can be significantly sped up by defining a mask that only propagates certain terms in the taylor expansion .",
    "this has not , however , been implemented in the distributed version of the code .",
    "the feynman rules for fermions contain spin matrices ( which may be pauli matrices , e.g. for nrqcd , or dirac matrices for relativistic fermions ) .",
    "we can expand a generic spin matrix @xmath60 using a basis @xmath113 : @xmath114 the product of any two spin basis matrices @xmath115 and @xmath116 is another basis matrix ( with label @xmath117 ) times a phase : @xmath118 we choose the basis so that these phases @xmath119 are real .",
    "where another convention is desired , the amplitudes @xmath120 need to be adjusted appropriately .",
    "for pauli matrices , we use a basis @xmath121 and @xmath122 , giving : @xmath123 for the ( euclidean ) dirac matrices , we choose @xmath124 and @xmath125 .",
    "we define @xmath126 and note the definition here @xmath127 $ ] .",
    "the multiplication for the basic @xmath128 matrices is thus @xmath129 we can thus write the product of two general spin matrices as @xmath130 where @xmath131 .",
    "we use this implicit representation of the spin matrices .",
    "matrix operations on explicit dirac matrices take @xmath132 operations and introduce additional rounding errors .",
    "( [ eqn_spin_multiply ] ) , by contrast , needs @xmath133 multiplications , depending on how many basis matrices are needed to describe @xmath60 and @xmath134 . if @xmath135 , the latter method is more efficient and this is almost always the case .",
    "there are greater gains when inverting spin matrices of the form @xmath136 as we might do when obtaining the propagator of a relativistic quark ( for nrqcd , the propagator is spin diagonal in the pauli matrices and trivial to invert ) .",
    "the inverse is @xmath137 which is far more efficient than inverting a @xmath138 matrix .",
    "inversion of a general spin matrix ( not of the form eqn .",
    "( [ eq_specialspinor ] ) ) is less efficient with an implicit representation , but this is irrelevant in most perturbative calculations .",
    "since all basis matrices except the identity are traceless , taking the trace of a spin matrix is a free operation in the implicit representation .      in the hippy  code ,",
    "spin basis matrices are associated with monomials using an appropriate integer @xmath139 , which is part of the ` entity ` data structure .",
    "when terms are multiplied together , the factors @xmath140 are absorbed into the amplitude @xmath48 of the resulting monomial .    in the hpsrc  code , we represent a spin matrix @xmath60 as a defined type , ` spinor ` , which is encoded as a double array @xmath141 it turns out to be significantly more efficient for the order of terms in this array to not necessarily match a standard order of basis elements @xmath113 , hence the use of the index array @xmath142 . in particular , this allows us to omit basis elements with zero coefficient .",
    "arithmetic operations have been overloaded to act appropriately on objects of this type , including implemention of the multiplication table . during inversion ,",
    "an additional function argument , ` short_spinor ` , is used to employ the more efficient expression in eqn .",
    "( [ eq_specialspinor_invert ] ) .",
    "sec .  [ sec_old_stuff ]",
    "summarised the general method that was described in ref .  @xcite . in general , fermionic actions",
    "are much more complicated than gluonic actions and several algorithmic improvements are needed to efficiently calculate the associated feynman rules .",
    "we stress that by efficient we mean speed - ups of at least an order of magnitude .",
    "the algorithms described in this section can be used independently or together , with the choice configurable at runtime of the code .",
    "all of these features have also been implemented using taylor - valued variables ( as per sec .",
    "[ sec_taylor ] ) to provide automatic differentiation of feynman rules .      in many cases",
    "an action has a block - like structure that we can exploit to make the evaluation of the reduced vertices more efficient .",
    "this is particularly useful in the case of nrqcd and mnrqcd actions , which can be heuristically written as @xmath143 .",
    "such an action can be expanded directly in the hippy  code but the extremely large number of monomials makes this is inefficient ( or impossibly slow and memory - hungry ) .",
    "it is clear why : there is often little scope for monomial compression between blocks . for instance , in ( m)nrqcd , blocks @xmath144 and @xmath145 live on different timeslices of the lattice , and no compression is possible when combining them .    instead , we recognise that the blocks are combined in a gauge covariant manner , so that in @xmath144 , for instance , each contour in @xmath146 starts where a contour in @xmath147 finishes .",
    "summing over the start / end location of each block we obtain a convolution of terms and can use the convolution theorem to construct the overall reduced vertex ( i.e. the momentum - space fourier transform ) from those of the individual blocks .",
    "we refer to the action as being a sum over terms that we call `` summands '' . in the above example , there are two .",
    "each summand is the convolution of a number of `` factors '' , with one factor in the first summand and four in the second .",
    "the overall reduced vertex @xmath148 is the sum of the reduced vertices for each summand . for each summand ,",
    "@xmath148 is calculated by combining the reduced vertices @xmath149 for each of @xmath150 factors that make up that summand , @xmath151 .",
    "we generate these by expanding each factor of the action separately in the hippy  code , with the convolution then carried out in the hpsrc  code .    here",
    "we give the method for constructing @xmath148 for a summand with @xmath150 factors for general @xmath46 .",
    "expressions for specific @xmath152 are given in appendix  [ sec_concrete_factors ] .",
    "in giving the general expression , we first establish some useful notation .",
    "consider the ordered set of the first @xmath46 integers : @xmath153 .",
    "we can form an ordered partition of this set : @xmath154 , where the cardinality @xmath155 is the number of elements in the partition .",
    "the set of all such partitions we denote @xmath156 .",
    "for instance , the partitions @xmath156 for @xmath157 ,  @xmath158 ,  @xmath159 are shown in table  [ tab_partitions ] .",
    "note that we do not consider unordered partitions ( e.g. @xmath160 ) because the gauge fields are explicitly ordered in the paths ( wilson lines ) making up the action .",
    ".[tab_partitions ] the elements @xmath78 in the set of ordered partitions , @xmath156 , of the ordered set of the first @xmath46 integers , @xmath153 , for @xmath157 ,  @xmath158 and  @xmath159 . [ cols=\"^,^,^\",options=\"header \" , ]     the general reduced vertex for a summand with @xmath150 factors is then : @xmath161 \\\\ \\left",
    ". \\times \\left ( \\prod_{k = n_{|p|}+1}^{n } y_{f,0}^{(k)}(-{\\bm{q}},{\\bm{q } } ) \\right ) \\right\\ } \\label{eqn_factors}\\end{gathered}\\ ] ] where @xmath162 is the position of element @xmath163 in the ordered set @xmath78 and @xmath164 .",
    "momentum is conserved in the diagram , so @xmath165 and subsequent @xmath166 ( with @xmath139 defined as above ) . here",
    "@xmath167 refers to the summed momenta for the set @xmath163 ( e.g. @xmath168 ) , implying @xmath169 .",
    "fermion actions often use fattened links to reduce discretisation errors in numerical simulations . by fattening or smearing a link",
    ", we will , in general , end up with an @xmath170 complex colour matrix @xmath171 , which can be expanded in powers of the gauge field @xmath172 .",
    "it is often the case that this matrix is reunitarised by projecting it back onto the gauge group @xmath31 or , more usually , simply back onto the related group @xmath173 .",
    "fattened links can then be further fattened , in an iterative procedure .",
    "an example of this is the hisq action .    to complement these numerical simulations",
    ", we need to do perturbative calculations using the same actions .",
    "we confine our attention here to the hisq action ( and simpler variants of the same form , for testing ) , with an iterated , two - level smearing procedure with an intermediate reunitarisation : @xmath174\\ ] ] where @xmath175 is the unsmeared gauge field , @xmath176 denotes the polar projection onto @xmath177 ( as used in simulations , and _ not _ @xmath178",
    "@xcite ) , and the fat7 and asq ( a slightly modified version of asq ) smearings are defined in ref .",
    "straightforward application of the expansion algorithm above is theoretically possible but practically unfeasible : the number of monomials is huge and the memory requirements of the hippy  code quickly become excessive .",
    "we get around this by taking advantage of the two - level structure inherent in the definition of the action and that the intermediate reunitarisation .",
    "this allows us to express the partially - smeared gauge field as a member of the associated gauge lie algebra , allowing us to split the derivation and subsequent application of the feynman rules into two steps .",
    "in the first step , the feynman rules for the outer ( or `` top '' ) layer , the asq action , are derived in the same way as before .",
    "representing the reunitarised ( and so far uncalculated ) fat7r smeared links by a new , lie - algebra  valued gauge potential , @xmath179 : @xmath180 = e^{b_\\mu(x+\\tfrac{1}{2}\\hat\\mu ) } \\;,\\ ] ] we can use the hippy  code to expand the asq action in terms of @xmath179 as before .",
    "we obtain similar position - space contributions @xmath181 that fourier transform to give monomials of the usual form .",
    "to complete the derivation of the hisq feynman rules , we also need to know the expansion of @xmath179 in terms of the original gauge potential @xmath172 . to obtain this , we write inner ( or `` bottom '' ) layer , the fat7-smeared link , as @xmath182 = m = hw$ ] , where @xmath183 and @xmath184 ( we suppress lorentz and lattice site indices in the following ) .",
    "we again use the hippy  code to obtain an expansion @xmath185 \\label{eqn_m_reunit}\\ ] ] where @xmath186 is a normalisation constant which , for simplicity in the text , we assume has been rescaled to unity .",
    "the notation here is , for instance , @xmath187 then unitarity of @xmath60 implies that @xmath188 and hence @xmath189 using the expansion @xmath190 rearranging the result as @xmath191 , i.e. @xmath192 finally yields the desired expansion of @xmath146 . these formul",
    "are implemented in this form in the hippy  code .",
    "given this , we can now numerically reconstruct the hisq feynman rules for any given set of momenta from eqn .",
    "( [ eqn : asqfr ] ) by a convolution of the asq feynman rules of eqn .",
    "( [ eqn : asqfr ] ) with the expansion of @xmath179 in terms of @xmath172 , summing up all the different ways in which the gluons @xmath172 going into the vertex could have come from the fields @xmath179 appearing in eqn .",
    "( [ eqn : asqfr ] ) .    in more detail",
    ", we now separately have the expansions of the asq action in terms of the fattened gauge fields @xmath146 , and of @xmath146 in terms of the unfattened gauge field @xmath147 . to obtain the correct reduced vertex , we must find all the ways that we can get unfattened gluons of the correct lorentz polarisations ( `` directions '' ) .",
    "in doing this , we bear in mind that @xmath179 contains , in principle , gauge fields @xmath193 in all directions and not just @xmath194 .",
    "below we give an expression for the reduced vertex for general @xmath46 .",
    "explicit formulfor @xmath103 , as implemented in the hpsrc  code , are given in appendix  [ sec_concrete_algebra ] .",
    "using the partitions @xmath156 as before , the reduced vertex for a two - level action is : : @xmath195 where @xmath162 is again the position of element @xmath163 in the ordered set @xmath78 . in the algebra",
    "reduced vertex @xmath196 , the momenta @xmath197 are each one of the arguments to the overall reduced vertex @xmath198 .",
    "as before , in the field reduced vertex @xmath199 , @xmath200 refers to the summed momenta for the partition @xmath201 .    in fig .",
    "[ fig_upper_lower ] we represent this expansion graphically for @xmath202 .",
    "solid circles represent the @xmath148 , whilst crossed and open circles represent @xmath203 and @xmath204 respectively .",
    "top - level , fattened gluons @xmath179 are represented by dashed ( brown ) lines , whilst bottom - level , unfattened gluons @xmath172 are shown as wavy ( blue ) lines .",
    "the two sub - diagrams represent the two partition contributions listed in eqn .",
    "( [ eqn_y_f2 ] ) .",
    "as we shall discuss later , this partitioning translates naturally into blocks of code . for certain calculations",
    ", symmetries of the feynman diagram will lead to the contributions of some of these blocks being zero .",
    "we can then improve the performance of the code by commenting them out in these circumstances .",
    "for instance , in the `` tadpole '' diagram in the one - loop fermion self energy , we can remove the term in @xmath205 that is proportional to @xmath206 @xcite .",
    "similarly , in the calculation of the radiative corrections to the gauge action @xcite , we can suppress the term proportional to @xmath207 in the `` octopus '' diagram .",
    "we can further optimise the calculation of the reduced vertices @xmath148 by reusing terms @xmath208 that appear multiple times in the expressions .",
    "for instance , in eqn .",
    "( [ eqn_y_f3 ] ) in appendix  [ sec_concrete_algebra ] we can reuse @xmath209 and @xmath210 .    for testing it",
    "is useful to define a simpler variant of the smearings described on page  3 of ref .",
    "@xcite , which we call `` fat3 '' .",
    "it is composed just of a central link and adjacent 3-staples with weights @xmath211 , @xmath212 .",
    "the field reduced vertex essentially calculates the feynman rule for obtaining @xmath46 _ fattened _ gluons in particular directions @xmath213 .",
    "the effect of fattening is treated separately in the @xmath204 .",
    "@xmath203 is composed of a sum of @xmath47 monomials , each representing a different way of obtaining the required gluons from the contours comprising the action : @xmath214 where @xmath215 is a spin matrix .    note that if there is no fattening of the underlying gluons , this is precisely the reduced vertex @xmath148 described in eqn .",
    "( [ eqn_sy ] ) , if we incorporate the @xmath216 factor that was in eqn .",
    "( [ eqn_ss ] ) .",
    "if the gluons are fattened , the effect of this is contained in the reduced vertices @xmath204 .",
    "these represent how we would choose @xmath46 unfattened gluons in directions @xmath217 from a fattened link in the @xmath218 direction : @xmath219 note that there is no spin matrix in @xmath196 , so the order of the multiplication in the expression for @xmath198 does not matter .",
    "the position vectors @xmath220 refer to the position of the unfattened link relative to the start of the fattened .",
    "as such , we need to remove the half - link shift that was implicit in the definition of @xmath221 as the _ centre _ of the link in the basic expansion algorithm",
    ".    the start and end sites of the contour @xmath16 and @xmath222 do not appear in @xmath196 , making @xmath223 for @xmath224 .",
    "of course , the actual values of @xmath47 , @xmath225 and @xmath226 will be different in eqns .",
    "( [ eqn_zy ] ) and  ( [ eqn_xy ] ) , as they come from different smearing prescriptions .",
    "we described above how splitting a fermion action such as hisq into two parts simplifies the generation of the feynman rules .",
    "this allowed us to exploit the reunitarisation of the inner fat7r smeared links allows them to be expressed in terms of a new gauge potential @xmath146 ( suppressing the lorentz index ) .    nonetheless , the feynman rules for @xmath146 ( as calculated in @xmath204 ) are still too complicated to derive for @xmath227 .",
    "the reason is clear if we look a tthe formula for the reunitarisation .",
    "using eqn .",
    "( [ eqn_m_reunit ] ) , the reunitarised field is @xmath228 , which we can express as an element of the algebra @xmath229 : @xmath230 + \\left[a_{\\mu \\nu } + a^\\dagger_{\\mu \\nu}\\right ] a_\\sigma \\right )   + \\frac{1}{3 } a_\\mu a_\\nu a_\\sigma   \\label{eqn_reunit}\\end{aligned}\\ ] ] if there are @xmath231 monomials in @xmath232 , there will be at least @xmath233 in @xmath234 arising from the term @xmath235 .",
    "there will be some compression , but this will at best only reduce this number by a factor of around  2 . for the simpler smearing fat3 , @xmath236 and already the hippy  code struggles to produce @xmath237 for fat3r .",
    "for fat7 , @xmath238 and direct reunitarisation to produce fat7r links using the hippy  code is out of the question .",
    "the alternative is to use the hippy  code to produce the @xmath69 and to do the reunitarisation in the hpsrc  code by hardwiring the formul  in eqn .",
    "( [ eqn_reunit ] ) . as before , the @xmath204 algebra reduced vertices are based on expansion coefficients @xmath239 .",
    "the inputs from the hippy  code , however , implement the coefficients @xmath69 .",
    "we use these to build a set of algebra reduced vertices @xmath240 and eqn .",
    "( [ eqn_reunit ] ) gives the relation between the reunitarised @xmath204 and the @xmath240 : @xmath241 \\right .",
    "\\\\ \\left .",
    "+ \\left [ w^\\nu_{f,2}({\\bm{k}}_1,\\mu_1;{\\bm{k}}_2,\\mu_2 ) + w^\\nu_{f,2}({\\bm{k}}_2,\\mu_2;{\\bm{k}}_1,\\mu_1 ) \\right ]   w^\\nu_{f,1}({\\bm{k}}_3,\\mu_3 ) \\right ) \\\\",
    "+ \\frac{1}{3 } w^\\nu_{f,1}({\\bm{k}}_1,\\mu_1 ) w^\\nu_{f,1}({\\bm{k}}_2,\\mu_2 ) w^\\nu_{f,1}({\\bm{k}}_3,\\mu_3 ) \\ ; . \\end{split } \\label{eqn_wy}\\end{gathered}\\ ] ]",
    "the hippy  code is used to taylor expand lattice actions , producing output files encoding the monomials making up the reduced vertices that can later be used by the hpsrc  code to evaluate feynman diagrams and integrals .",
    "the code is written in python , for which interpreters are freely available for a wide range of computational platforms @xcite .",
    "the hippy  code can be run on any machine which has python version 2.5.x installed on it .",
    "it is also expected to work with any version 2.x , but is not ( yet ) compatible with version 3.x .",
    "only the packages supplied in a standard installation of python are required .",
    "installation consists of unpacking the source files in the chosen location .      a set of unit test programs",
    "are contained in subdirectory ` tests ` .",
    "they are run from the command line with no options and the code is expected to pass all of these .",
    "no input files are needed for the tests .    whilst the unit testing does not cover each code feature separately , those in ` test_class_field.py ` do cover most features combined .",
    "the hippy  code consists of the following main programs that make use of the core routines described below .",
    "a full list of options for each of the main programs can be obtained by running them from the command line with option ` help ` .",
    "[ [ sample_link.py ] ] ` sample_link.py ` + + + + + + + + + + + + + + + +    used to generate monomials from the algebra of the group for a single fattened link in the specified direction .",
    "these are used to evaluate @xmath204 in eqn .",
    "( [ eqn_xy ] ) or @xmath240 in eqn .",
    "( [ eqn_wy ] ) in the hpsrc  code .",
    "the fattening style is specified using ` bottom_style ` .",
    "the output filenames have the form ` algebra_%s%i_qq*.in ` , where ` % s ` is replaced by the name of the fattening style and ` % i ` by the direction of the link ( with value ` parameters.d ` mapped to zero ) .",
    "wildcard ` * ` is @xmath46 copies of the character `` ` g ` '' ( up to maximum ` parameters.r ` ) .    for monomials that will be used in eqn .",
    "( [ eqn_wy ] ) ( with hardwired reunitarisation carried out in the hpsrc  code ) , the option ` fld_as_alg ` should be specified . in this case ` %",
    "s ` is a concatenation of character `` ` f ` '' and the name of the fattening .",
    "if an undefined fattening style is specified with ` --bottom_style ` , a list of acceptable styles is printed .",
    "[ [ sample_naive.py ] ] ` sample_naive.py ` + + + + + + + + + + + + + + + + +    used to generate monomials for the naive ( or , equivalently , staggered ) lattice dirac action using fattened links .",
    "these are used to evaluate @xmath149 in eqn .",
    "( [ eqn_factors ] ) in the hpsrccode .",
    "the fattening style(s ) are specified using ` top_style ` and ` bottom_style ` , and should not include fattening already carried out at the algebra stage above .",
    "the output filenames have the form ` vertex_%s_qq*.in ` , where ` % s ` is replaced by the name of the top fattening style and ` * ` is @xmath46 copies of the character `` ` g ` '' . for complicated fattening prescriptions ,",
    "there is likely to be some filename clashes , so care should be exercised .",
    "if an undefined fattening style is specified with ` --top_style ` , a list of acceptable styles is printed .",
    "[ [ sample_glue.py ] ] ` sample_glue.py ` + + + + + + + + + + + + + + + +    used to generate monomials for a range of simple gauge actions , specified by a command line argument .",
    "as described above , these vertices have been ( partially ) symmetrised .      as an example , here are the commands one would use to generate the four - dimensional hisq reduced vertex files using a two - level action with hardwired reunitarisation and mass @xmath242 :    .... python sample_link.py --bottom_style fat7 --fld_as_alg 1 python sample_link.py --bottom_style fat7 --fld_as_alg 2 python sample_link.py --bottom_style fat7 --fld_as_alg 3 python sample_link.py --bottom_style fat7 --fld_as_alg 4 python sample_naive.py --top_style asq_for_hisq 0.2 ....    which creates files ` algebra_ffat7%i_qq*.in ` and ` vertex_asq_for_hisq_qq*.in ` .",
    "the same feynman rules can be generated using    ....",
    "python sample_naive.py --top_style asq_for_hisq \\     --bottom_style fat7r 0.2 ....    but this generates _ far _ more monomials , which soon becomes prohibitive as @xmath46 increases , as discussed above .    for hisq fermions ,",
    "there is the option to set the mass  dependent parameter @xmath243 to zero for small @xmath244 .",
    "this is done using a command line option ` --hisq_eps_zero ` for ` sample_naive.py ` .    for main programs to calculate feynman rules for other actions , e.g. nrqcd",
    ", interested readers should contact the authors .",
    "these main programs make use of the following core routines :    [ [ parameters.py ] ] ` parameters.py ` + + + + + + + + + + + + + + +    defines physical and numerical parameters associated with the expansion .",
    "if the monomials require complex - valued amplitudes , e.g. for mnrqcd actions , this is enabled here .",
    "[ [ template.py ] ] ` template.py `",
    "+ + + + + + + + + + + + +    defines some link fattening prescriptions that can be used to define actions .",
    "each fattening is a set of paths which do not need to be gauge covariant , so three - link naik terms can be included , for instance . instructions for adding new fattenings",
    "are included in this file .",
    "[ [ spin_multiplication.py ] ] ` spin_multiplication.py ` + + + + + + + + + + + + + + + + + + + + + + + +    implements the implicit representations of the spin algebras described in sec .",
    "[ sec_spinor ] . running this from the command line displays the multiplication table from eqn .",
    "( [ eqn_spin_mult ] ) for either pauli or dirac spin matrices .",
    "[ [ wilson.py ] ] ` wilson.py ` + + + + + + + + + + +    the main expansion engine that converts a collection of wilson lines into a taylor expansion in the form of reduced vertices built from monomials .",
    "the collection of wilson lines is defined by    ....",
    "thepath = [ [ c1,c2,\\dots],[p1,p2,\\dots ] ] ....    where ` c1 ` , ` c2 ` etc .",
    "are the amplitude of each contour , the path of which is defined by a set of signed integers .",
    "for instance , a plaquette would be ` p1=[1,2,-1,-2 ] ` .",
    "as an example of a complete path , a two - dimensional naive fermion action would be defined by a path :    .... thepath = [ [ 0.5,-0.5,0.5,-0.5,m ] , [ [ 1],[-1],[2],[-2 ] , [ ] ] ] ....    the expansion is not symbolic , so the mass ` m ` must take a specific numerical value .",
    "it is assumed that all links are of the same , fattened style .",
    "the fattening can contain any number of iterated styles defined in ` template.py ` , given as a list ` top_style ` interpreted from right to left .",
    "at the lowest level of this iteration , a further single level of fattening can be specified using ` bottom_style ` .",
    "uniquely , a reunitarisation by projection onto @xmath173 can be imposed after this fattening by appending character `` r '' to the end of the name of the style ( again , chosen from the definitions in ` template.py ` ) .",
    "[ [ class_entity.py ] ] ` class_entity.py ` + + + + + + + + + + + + + + + + +",
    "each monomial in the reduced vertex is encoded as an instance of this class , a description of which can be found in sec .  4 of ref .",
    "translation invariance is exploited so that all paths are assumed to start at the origin , @xmath245 .",
    "if this is not the case ( e.g. for open boundary conditions in the temporal direction for schrdinger functional calculations @xcite ) , then an attribute ` start_site ` would need to be introduced to this class and appropriate changes made to ensure gauge covariance in the multiplication and in other places .",
    "[ [ class_field.py ] ] ` class_field.py ` + + + + + + + + + + + + + + + +    the collection of monomials defining the reduced vertices returned by ` wilson.path ( ) ` are stored as a dictionary in an instance of this class .",
    "a fuller description can be found in sec .  4 of ref .",
    "@xcite .",
    "[ [ class_algebra.py ] ] ` class_algebra.py `",
    "+ + + + + + + + + + + + + + + + + +    very similar in form to ` class_field.py ` , this class contains the reduced vertices associated with the algebra in eqn .",
    "( [ eqn_algebra2 ] ) .",
    "[ [ mathfns.py ] ] ` mathfns.py ` + + + + + + + + + + + +    contains a collection of methods not tied to any particular class .",
    "the hpsrc  code uses the input files from the hippy  code to create feynman rules , and combines these to evaluate feynman integrals by exact mode summation or statistical estimation using the vegas  algorithm @xcite .",
    "the hpsrc  code requires a standards - compliant fortran95 compiler with support for minimal cpp directives ( chiefly ` # ifdef ` and ` # ifndef ` ) .",
    "the command ` make ` is optional but useful .",
    "an appropriate mpi wrapper for the compiler will be needed for creating a parallel version of the executable .",
    "no additional libraries are required .",
    "the code is known to compile and execute correctly with the following compilers : intel ifort , portland pgf90 , nag f95 and gnu gfortran on unix - based systems ( the first two also with mpi on parallel machines ) and silverfrost / salford ftn95 and lahey - fujitsu lf95 on microsoft windows systems using cygwin .    to install the code ,",
    "the source should be unpacked in a suitable directory and the file ` makefile_details ` ( which contains machine - dependent information ) edited to point to the correct compiler .",
    "it is a good idea to execute ` make clean ` before compiling the code . a given target ` this_executable `",
    "can be compiled using the command    .... make this_executable ....    use the command ` make ` to see a list of possible executables , or examine ` makefile ` .",
    "main programs are named ` main_.f90 ` and compile to form executables with the same filestem and extension ` .$(exe ) ` as specified by ` makefile_details ` . typically `",
    "$ ( exe ) = x ` , but certain compilers expect ` $ ( exe ) = exe ` .    a fortran module ` this ` is typically contained in a file named ` mod_this.f90 ` .",
    "input files containing information that should be specified at compile time are named with extension ` .i ` .",
    "the command ` make clean ` must be executed before recompiling if any of these files are changed .",
    "these files typically contain unavoidable cpp directives and the number of these has been kept to a minimum .",
    "input files that are read at runtime are have names with extension ` .in ` .",
    "most input files have a filename that reflects that of the module that reads them .",
    "the code has been rigorously tested as a whole in a number of scientific calculations , being compared with identical calculations carried out using different programs .",
    "in addition , various manual and automatic tests are routinely carried out to verify the continued correctness of the code .",
    "the manual tests are located in subdirectory ` tests/ ` .",
    "[ [ automatic - differentiation ] ] automatic differentiation + + + + + + + + + + + + + + + + + + + + + + + + +    without a templating option in fortran , each vertex is effectively coded twice : once as a complex - valued object and once as a taylor - valued object that includes the automatic derivatives .",
    "the code exploits this by performing a finite difference of the first to compare with the derivatives included in the second . to avoid multiplication of errors in higher - order difference operators ,",
    "the tests are carried out as follows .",
    "first , the non - taylor version is compared with the zero - order derivative from the taylor version . if this agrees , a first - order , symmetric difference is made of the zero - order derivative in the taylor in direction @xmath246 .",
    "we check that , for all @xmath246 , this agrees ( within a specified tolerance ) with the analytic first order derivative in the taylor object .",
    "if so , we form first - order differences of the analytic first - order derivatives and compare these with the analytic second order derivatives and so on .",
    "these comparisons are done at runtime when the vertex modules are first initialised .",
    "this test checks not only that the automatic differentiation ( and associated overloading of operators ) is working correctly , but also that there are no coding inconsistencies between the taylor and non - taylor versions of the vertices .",
    "it can not , of course , detect algorithmic errors that have been consistently coded in both versions .",
    "an additional , lower level test of the taylur package is provided by ` test_taylors.x ` .    [",
    "[ test_compare_vertices.x ] ] ` test_compare_vertices.x",
    "` + + + + + + + + + + + + + + + + + + + + + + + + +    can be used to check that the feynman rules are the same for two different implementations of the same quark action .",
    "this provides a rigorous check of the algorithms in ` mod_vertex_qq*.f90 ` . having compiled ` test_compare_vertices.x ` , a python script ` test_compare_vertices.py `",
    "can be executed to complete various independent checks of the two  level action decomposition , the hardwired reunitarisation and the summand / factor division of the action .",
    "the last is based on an nrqcd action and also provides a strong test of the implementation of the pauli spin algebra .",
    "[ [ tests - of - vegas ] ] tests of vegas + + + + + + + + + + + + + +    the vegas  code is automatically tested at runtime , evaluating the area under a two - dimensional , normalised gaussian as well as a contour integral .",
    "these tests can also be run using ` test_vegas.x ` .",
    "[ [ lower - level - hpsrctests ] ] lower level hpsrc  tests + + + + + + + + + + + + + + + + + + + + + + +    ` test_spinors.x ` tests type ` spinor ` defined in sec .",
    "[ sec_spinor ] .",
    "in addition , ` test_pauli_dirac_spinors.x ` tests the embedding of pauli two - spinors into dirac 4-spinors . `",
    "test_print_vertices.x ` prints the values of the fermionic vertices for a random set of momenta .",
    "the same random number seed is used each time , so running the code for different ` vertex_qq_composite.in ` on the same machine will yield outputs that can be directly compared .      to illustrate the use of the hpsrc  code , we provide three sample programs with makefile targets :    [ [ quark_sigma.x ] ] ` quark_sigma.x ` + + + + + + + + + + + + + + +    calculates the one - loop renormalisation of asqtad improved staggered fermions . to do this",
    ", it evaluates the self - energy feynman diagrams and their derivatives .",
    "[ [ nrqcd_sigma.x ] ] ` nrqcd_sigma.x ` + + + + + + + + + + + + + + +    performs a similar calculation for heavy nrqcd fermions .",
    "[ [ nflwimp.x ] ] ` nflwimp.x ` + + + + + + + + + + +    calculates the hisq fermion contribution to the one - loop radiative corrections to the lscher - weisz gauge action , as per refs .",
    "@xcite .",
    "this subsection describes modules that are needed to use the vertex modules .",
    "if mpi is to be used , the file ` use_mpi.i ` must be changed prior to compilation .",
    "similarly , if monomials require complex amplitudes , e.g. for mnrqcd calculations , this is enabled in ` use_complex_amplitudes.i ` .",
    "[ [ mod_num_parm.f90 ] ] ` mod_num_parm.f90 ` + + + + + + + + + + + + + + + + + +    numerical parameters that are used by most of the other modules .",
    "most parameters in this module will not need to be changed .",
    "it also optionally reads from file ` paths.in ` the pathnames of the directories holding the vertex and algebra files generated by the hippy  code .",
    "[ [ mod_phys_parm.f90 ] ] ` mod_phys_parm.f90 ` + + + + + + + + + + + + + + + + + + +    physical parameters used in the calculation .",
    "the code has only been tested for number of dimensions ` ndir ` @xmath247 and colours ` ncol ` @xmath248 .",
    "other choices will require careful testing before use .",
    "values for many parameters can be changed at runtime by editing file ` phys_parm.in ` twisted boundary conditions are selected by setting the number of twisted directions ` ntwisted_dirs ` to 2 , 3 or 4 .",
    "value 0 gives periodic boundary conditions .",
    "for finite lattices , the lattice size is specified in ` latt_size(0:ndir-1 ) ` , with the first component the temporal one .",
    "if momenta are to be squashed @xmath249 @xcite , the squash factors @xmath250 in each direction are specified in ` mom_squash(0:ndir-1 ) ` .",
    "the anisotropy metric ` anis ` is only supported currently for gluonic vertices .    [ [ mod_momenta.f90 ] ] ` mod_momenta.f90 ` + + + + + + + + + + + + + + + + +    defines type ` mom ` which encodes momenta .",
    "each instance contains the momentum components , the twist vector ( only relevant for twisted boundary conditions ) and a route variable that is used in automatic differentiation .",
    "[ [ mod_taylors.f90 ] ] ` mod_taylors.f90 ` + + + + + + + + + + + + + + + + +    defines type ` taylor ` , as described in sec .",
    "[ sec_taylor ] .",
    "[ [ mod_spinors.f90 ] ] ` mod_spinors.f90 ` + + + + + + + + + + + + + + + + +    defines types ` spinor ` and ` tayl_spinor ` , as described in + sec .",
    "[ sec_spinor ] .",
    "[ [ mod_matrices.f90 ] ] ` mod_matrices.f90 ` + + + + + + + + + + + + + + + + + +    defines types ` mat4x4 ` , used to explicitly represent objects such as the gluon propagator in lorentz index space . a corresponding taylor - valued type ` tayl_mat4x4 ` is also defined .",
    "[ [ mod_colour.f90 ] ] ` mod_colour.f90 ` + + + + + + + + + + + + + + + +    calculates the clebsch - gordan factors for both gluonic and fermionic vertices , for periodic and twisted boundary conditions .",
    "colour factors for periodic boundary condition are pre - computed and stored in the compile - time files ` tr_cols_n.i ` and ` mat_cols_n.i ` .",
    "for twisted boundary conditions , the clebsch - gordan factors are computed as needed .",
    "[ [ mod_mod_mpi.f90 ] ] ` mod_mod_mpi.f90 ` + + + + + + + + + + + + + + + + +    the code can either be run as a scalar code on a single processor or as a parallel code using mpi . to achieve this with the minimum of compile - time code modifications ( either by hand or using cpp directives ) , ` mod_mod_mpi.f90 `",
    "contains a set of dummy mpi subroutines . whether these dummy routines are used or not is controlled by the single cpp directive in file ` use_mpi.i ` .",
    "note that ` mod_mod_mpi.f90 ` is the only file that reads ` use_mpi.i ` .",
    "only the mpi commands we use are included in ` mod_mod_mpi.f90 ` .",
    "we do not know of any externally maintained library of dummy mpi commands for use in such situations .",
    "if this were to exist , it could easily be used to replace this file .    throughout the code",
    "we are ( or try to be ) careful that input / output files are only opened by one processor , with information then shared using mpi commands .    [ [ mod_vegasrun.f90 ] ] ` mod_vegasrun.f90 ` + + + + + + + + + + + + + + + + + +    provides an implementation of the vegas  algorithm , based on the original code of peter lepage @xcite , who also helped convert the code to a parallel version using mpi . on parallel machines",
    ", the processors are divided into farms , each of which does an independent vegas  estimate of the integral . within the farm ,",
    "all processors carry out the same calculation , interacting only to share the work of evaluating the integrand at each of the monte carlo points .",
    "the number of processors per farm is controlled in file ` vegas_parm.in ` , and must be a factor of the number of processors .",
    "farming has the advantage of avoiding potentially slow global communications on large clusters .",
    "an improved parallel implementation is currently being prepared as part of a deisa deci - funded project @xcite .",
    "feynman rules @xmath83 for the gluonic vertices are implemented in + ` mod_vertex_*.f90 ` , where ` * ` is @xmath46 ( the number of gluons ) copies of character `` ` g ` '' .",
    "currently vertices for @xmath251 have been implemented .",
    "the modules for @xmath252 are called ` vertex _ * ` and have a very similar structure . the top level routine is ` vert_(k , lorentz , colour ) ` , which takes as arguments the momenta , lorentz and colour indices and returns the complete _ symmetrised _ feynman rule for that vertex as a complex number .",
    "the colour array is ignored if we are using twisted boundary conditions .",
    "the module assumes that the monomials written by the hippy  code have been partially symmetrised as described above .",
    "the remaining symmetrisation over the distinct cosets is carried out automatically in the top level routine .",
    "the reduced vertex is calculated from the monomials in ` yvertex _ * ( ) ` .",
    "this code structure is repeated using instances of type ` taylor ` instead of complex numbers , providing analytic derivatives of the feynman rules .",
    "the top level routine in this case is called ` taylor_vert _ ( ) ` . as detailed above , coding the algorithm twice in this way is exploited in the runtime testing of the code .    the remainder of the ` mod_vertex_qq*.f90 ` files is taken up with initialisation code ( which reads in all the vertex files at runtime ) and testing routines .    only `",
    "mod_vertex_gg.f90 ` differs from this overall structure .",
    "this calculates the gluon propagator . in this case , the top - level routine is + ` gluon_prop(k , colour ) ` .",
    "the propagator is simultaneously calculated for all lorentz index combinations , packaged as a @xmath253 matrix implemented as derived type ` mat4x4 ` .",
    "the choice of gauge is controlled by variable ` galpha ` , specified in runtime input file ` vertex_gg_parm.in ` .",
    "value ` 1 ` corresponds to feynman gauge and ` 0 ` to landau gauge . as detailed in ref .",
    "@xcite , the inverse propagator does not exist in landau gauge , so an intermediate gauge parameter ` gbeta ` should be used . `",
    "gauge_family = ' landau ' ` is the usual choice , where the gauge correction is based on the four - vector @xmath254 .",
    "changing this to ` ' coulomb ' ` uses just the spacelike components instead , but this option is not fully tested .    as evaluation of the gluon propagator",
    "can be an expensive part of a perturbative calculation , the propagators for various gluon actions are hardwired in ` mod_vertex_gg.f90 ` .",
    "their use is specified by changing variable ` action ` in ` vertex_gg_parm.in ` from ` ' python ' ` to appropriate other character strings which are listed in subroutine ` vertex_gg_params ( ) ` .",
    "a gluon mass can be added to the propagator .",
    "its square is ` gluon_mass2 ` , specified in ` vertex_gg_parm.in ` .",
    "again , this code is repeated using automatic derivatives packaged instead in a ` taylor`-valued matrix of type ` tayl_mat4x4 ` .",
    "the remainder of the module contains runtime tests and initialisation routines .",
    "associated with the gluon modules are modules calculating the feynman rules associated with the fadeev - popov ghost fields and the haar measure .",
    "these are implemented as hardwired formul  in ` mod_vertex_hhstar.f90 ` ( for @xmath255 ) and in ` mod_vertex_meas_gg.f90 ` ( only for @xmath202 ) .",
    "feynman rules @xmath256 for the fermionic vertices ( the _ unsymmetrised _ version of eqn .",
    "( [ eqn_ferm_symm ] ) ) are calculated in the files ` mod_vertex_qq*.f90 ` , where ` * ` is @xmath46 ( the number of gluons ) copies of character `` ` g ` '' . currently vertices for @xmath103 have been implemented .",
    "the modules for @xmath252 are called ` vertex_qq * ` and have a very similar structure .",
    "the top level routine is ` vert_qq*(k , lorentz , colour ) ` , which takes as arguments the momenta , lorentz and colour indices and returns the complete feynman rule for that vertex as an instance of type ` spinor ` .",
    "the convention is that ` k(1:r+2 ) ` is @xmath257 .",
    "the colour array has the same ordering , but is ignored if we are using twisted boundary conditions .",
    "internally , this function calculates the reduced vertex using ` yvertex_qq * ( ) ` and multiplies on the appropriate clebsch - gordon factor , calculated using + ` mod_colour.f90 ` .",
    "[ [ yvertex_qq ] ] ` yvertex_qq * ( ) ` + + + + + + + + + + + + + + +    implements the summands and factors decomposition described in sec .",
    "[ sec_summands_factors ] .",
    "the reduced vertices for each factor are calculated in + ` yvertex_qq*_partial ( ) ` .",
    "the sum over partitions @xmath258 naturally translates into a block structure for this routine , the order of which follows that of the expressions in appendix  [ sec_concrete_factors ] .",
    "[ [ yvertex_qq_partial ] ] ` yvertex_qq*_partial ( ) ` + + + + + + + + + + + + + + + + + + + + + + +    implements the two - level field / algebra algorithm as per section  [ sec_two_level ] .",
    "the `` upper - level '' , fattened , field vertices @xmath203 are calculated in ` yvertex_qq*_partial_noalg ( ) ` , combining monomials that have been read into the module at runtime .",
    "the `` lower - level '' , algebra vertices @xmath204 are calculated in ` yvertex_qq*_algebra ( ) ` .",
    "once more , the sum over partitions translates into a block structure for the code , and the order reflects the expressions in appendix  [ sec_concrete_algebra ] . as discussed earlier , for certain feynman diagrams we can comment out some blocks on symmetry grounds .    [ [ yvertex_qq_algebra ] ] ` yvertex_qq*_algebra ( ) ` + + + + + + + + + + + + + + + + + + + + + + +    calculates @xmath204 in terms of the monomial - calculated @xmath240 from ` y_qq*_alg_basic ( ) ` , as detailed in sec .",
    "[ sec_reunit ] .",
    "there is the option to apply no reunitarisation ( setting @xmath259 ) , or the hardwired projection described in the text .",
    "additional projection methods , such as `` stouting '' @xcite , could also be implemented here .",
    "this code structure is repeated using instances of type ` tayl_spinor ` instead of type ` spinor ` , providing analytic derivatives of the feynman rules .",
    "the top level routine in this case is called ` taylor_vert_qqg * ( ) ` . as detailed above , coding the algorithm twice in this way is exploited in the runtime testing of the code .    the remainder of the ` mod_vertex_qq*.f90 ` files is taken up with initialisation code ( which reads in all the vertex files at runtime ) and testing routines .    only `",
    "mod_vertex_qq.f90 ` differs from this overall structure .",
    "this calculates the fermion propagator . in this case , the top - level routine is + ` quark_prop(k , colour ) ` where the momentum specified is @xmath260 ( which flows in the direction of the fermion arrow ) . `",
    "inv_quark_prop ( ) ` calculates the two - point function for the fermions and implements the summands and factors decomposition described in sec .",
    "[ sec_summands_factors ] .",
    "the reduced vertex for each factor is calculated in ` inv_quark_prop_partial ( ) ` .",
    "this is the lowest - level routine , as there is no algebra contribution for @xmath224 .",
    "these routines are followed in the code by type ` tayl_spinor ` versions and by initialisation and tests .",
    "the hpsrc  code allows for the use of multiple fermion types , each with their own feynman rules constructed in their own way .",
    "the details of all of this are specified at runtime by the file ` vertex_qq_composite.in ` , which is read by all the ` mod_vertex_qq*.f90 ` files .",
    "the input takes the form of a namelist .",
    "a typical example is given in appendix  [ app_composite ] .",
    "the accuracy of simulations of lattice qcd ( and other field theories ) has been markedly improved by the use of symanzik- and radiatively - improved actions and measurement operators .",
    "in addition to the calculation of the radiative corrections , this improvement programme also requires a concomitant effort in calculating associated renormalisation parameters that are vital to the continuum and chiral extrapolations .",
    "lattice perturbation theory is an essential tool in these calculations .",
    "for some quantitities we can use other techniques , in particular non - perturbative renormalisation ( npr ) @xcite , high-@xmath261 simulations @xcite and stochastic techniques @xcite . in cases where these can be used , lattice perturbation theory provides a valuable check of their results and , in the case of high-@xmath261 simulations , important constraints on the coefficients of the low powers of @xmath2 .",
    "when there is complicated mixing of operators , which happens in a lot of physically relevant measurements , statistical errors lead to the failure of the npr and high-@xmath261 techniques and lattice perturbation theory is the only alternative .",
    "stochastic perturbation theory is also very expensive for theories with dynamical fermions .",
    "lattice perturbation theory for improved actions is complicated : not only does it include many vertices not present in the continuum , the feynman rules also contain a very large number of terms .",
    "these complications vanish , of course , in the continuum limit as the lattice spacing @xmath0 tends to zero .",
    "the point is , however , that lattice perturbation theory is used to correct for the missing momentum modes on a discrete lattice , so the presence of these complications are central to its utility .",
    "many of the complicating terms violate lorentz symmetry and are mathematically complicated .",
    "this makes analytic evaluation of feynman integrals impossible in almost all cases .",
    "it is therefore crucial that we develop a robust computational method for deriving and then using these feynman rules in perturbation theory .",
    "this method must be efficient as well as accurate .    in this paper",
    "we have described such a method .",
    "we have used a two - pronged approach , with separate programs to expand the action and derive the feynman rules , and then to use these rules to calculate feynman integrals . in both cases ,",
    "we have developed efficient algorithms to minimise the computational expense .",
    "indeed , without these efficient algorithms we find the calculations to be impossible for many realistic action choices .",
    "we have also presented a full , working implementation of the algorithm in the form of the hippy  and hpsrc  codes .",
    "the programming languages used for the implementations are python and fortran95 , respectively .",
    "python offers good list - handling and object - orientation features that are suited to the expansion of the action to derive the feynman rules .",
    "fortran95 is numerically efficient , an over - riding concern for the evaluation ( or estimation ) of expensive feynman integrals .",
    "we stress that our method is generically applicable . in the text ,",
    "we have focused on the features of our method that make possible calculations using realistic nrqcd and hisq fermion actions .",
    "this bias merely reflects the problems for which we have used the method most so far .",
    "we have considered other actions , both by expanding them using the hippy  code and by hardwiring the hand - derived feynman rules in the hpsrc  vertex modules .",
    "particular strengths of our approach are the ability to deal with complicated colour and spin structures in actions and the breaking down of actions into simpler sub - structures for faster evaluation .",
    "we have also provided a particularly simple way of describing actions that reduces the scope for transcription errors .",
    "the comprehensive suite of tests in the code also give confidence in the accuracy of the basic components of both the hippy  and hpsrc  code suites .    as well as extending the basic functionality of the codes , e.g. to describe actions with multiply nested levels of link fattening ,",
    "the codes are easily extended to a wide range of related problems in lattice simulation , as has already been done for lattice chiral perturbation theory @xcite and schrdinger functional calculations @xcite .",
    "another area in which the code might be used is in calculations where the lattice gauge field is split into a fluctuating , quantum piece and an external background field @xcite .",
    "the authors are happy to provide further details on the implementation of this , as well as additional advice on the use of the hippy  and hpsrc  codes .",
    "a.h . thanks the u.k . royal society for financial support .",
    "the university of edinburgh is supported in part by the scottish universities physics alliance ( supa ) .",
    "is supported by the deutsche forschungsgemeinschaft in the sfb / tr  09 .",
    "this work has made use of the resources provided by the edinburgh compute and data facility ( ecdf ; http://www.ecdf.ed.ac.uk ) .",
    "the ecdf is partially supported by the edikt initiative ( http://www.edikt.org.uk ) .",
    "we also acknowledge support from the deisa extreme computing initiative ( http://www.deisa.eu/science/deci ) .",
    "using table  [ tab_partitions ] , we here give explicit expressions for eqn .",
    "( [ eqn_factors ] ) for @xmath148 for a summand in the action with @xmath150 factors , for @xmath262 ( the range of @xmath46 implemented in the hpsrc  code ) : @xmath263 @xmath264 @xmath265 @xmath266",
    "the reduced vertex from the @xmath267 is denoted @xmath268 .",
    "the formula for @xmath269 is illustrated graphically in fig .",
    "[ fig_summands ] .",
    "to make things more concrete , we give explicit formul  for the @xmath157 ,  @xmath202 and  @xmath269 reduced vertices for a two - level action as defined in eqn .",
    "( [ eqn_algebra ] ) .",
    "this is the range of @xmath46 implemented in the hpsrc  code . using the partitions in table  [ tab_partitions ]",
    "we obtain : @xmath270 @xmath271 @xmath272",
    "here we provide an explicit example of the runtime file used to specify the feynman rules used by the hpsrc  code .",
    "the calculation will use two types of quarks : relativistic hisq and heavy nrqcd .",
    "it is assumed that the appropriate vertex and , where relevant , algebra files have been precomputed using the hippy  code and stored in the locations specified in the hpsrc  file ` paths.in ` .    .... & vertex_qq_composite          no_quark_types = 2 ! first quark type : hisq !",
    "all rh indices set to 1 to denote first quark type          summands(1 ) = 1          factors(1:1,1 ) = 1          summand_amps(1:1,1 ) = 1.d0          opname(1:1,1,1 ) = \" asq_for_hisq _ \"          algname(1 ) = \" ffat7 \"      reunit_to_apply_to_alg(1 ) = \" project \" ! second quark type : nrqcd !",
    "all rh indices set to 2 to denote second quark type          summands(2 ) = 2          factors(1:2,2 ) = 0,4          summand_amps(1:2,2 ) = 1.d0,-1.d0          opname(1:4,2,2 ) = \" nrqcd_a\",\"nrqcd_b\",\"nrqcd_c\",\"nrqcd_a \"          algname(2 ) = \" simple \"      reunit_to_apply_to_alg(2 ) = \" none \" !",
    "no opname(:,1,2 ) definition because first summand has no !    hippy inputs because it is a constant / ....    that there are two quark types is specified in the namelist using + ` no_quark_types ` . within the hpsrc  code",
    "we control which set of feynman rules we use by setting variable ` quark_type ` to  1 or  2 prior to calling + ` quark_prop ( ) ` or ` vert_qqg * ( ) ` .",
    "the first fermions are relativistic hisq quarks .",
    "there is no splitting of the action into summands and factors , so ` summands(qt)=1 ` and + ` factors(1:summands(qt),qt)=1 ` .",
    "similarly , the only summand has amplitude ` summand_amps(1:summands(qt),qt)=1.0d0 ` .",
    "the files used to construct @xmath203 for each factor for each summand are assumed to have been generated by the hippy  code and stored in files named ` vertex_%sqq*.in ` where ` % s ` is replaced by appropriate text for each factor for each summand as specified in ` opname(ft , sm , qt ) ` , where ` ft ` runs from 1 to ` factors(sm , qt ) ` and ` sm ` runs from 1 to ` summands(qt ) ` . in this case , the only vertex files are those with ` % s ` replaced by ` asq_for hisq _ ` .",
    "the name of the algebra file is given by ` algname(qt ) ` ( note there is no trailing underscore in this case ) .",
    "we specify that hardwired projection is required to relate @xmath240 in eqn .",
    "( [ eqn_wy ] ) to @xmath204 in eqn .",
    "( [ eqn_xy ] ) using ` reunit_to_apply_to_alg(qt ) ` .",
    "the hpsrc  code currently assumes that the same algebra files are used for all factors and summands of a particular quark type .",
    "again , it is assumed that the files defining these have been pre - produced using the hippy  code and stored in files named ` algebra_%s%i_qq*.in ` .",
    "` % s ` is replaced by ` algname(qt ) ` and ` % i ` runs from 0 to @xmath273 , where @xmath7 is the number of dimensions .      the second block of the namelist defines an nrqcd action of the heuristic form @xmath274 .",
    "there are two summands , the first with 0 factors ( which gives default answer 1 ) and the second with 4",
    ". the minus sign in front of the second summand is specified in ` summand_amps ` .",
    "the first summand has no factors , so ` opname ` is not specified .",
    "the second summand has 4 factors , and the filenames are specified .",
    "note that the first and last filenames are the same .",
    "the algebra is specified as before , and no hardwired reunitarisation is required .",
    "g.  martinelli , c.  pittori , c.  t. sachrajda , m.  testa , a.  vladikas , a general method for nonperturbative renormalization of lattice operators , nucl .",
    "b445 ( 1995 ) 81108",
    ". http://arxiv.org/abs/hep-lat/9411010 [ ] , http://dx.doi.org/10.1016/0550-3213(95)00126-d [ ] .",
    "r.  sommer , non - perturbative qcd : renormalization , o(a)-improvement and matching to heavy quark effective theory , lectures given at workshop on perspectives in lattice qcd , nara , japan ( 2006 ) . http://arxiv.org/abs/hep-lat/0611020 [ ] .",
    "t.  bhattacharya , r.  gupta , w .- j .",
    "lee , s.  r. sharpe , order @xmath0 improved renormalization constants , phys .",
    "d63 ( 2001 ) 074505 . http://arxiv.org/abs/hep-lat/0009038 [ ] , http://dx.doi.org/10.1103/physrevd.63.074505 [ ] .",
    "h.  d. trottier , higher - order perturbation theory for highly - improved actions , nucl .",
    "suppl . 129",
    "( 2004 ) 142148 .",
    "http://arxiv.org/abs/hep-lat/0310044 [ ] , http://dx.doi.org/10.1016/s0920-5632(03)02515-5 [ ] .",
    "g.  p. lepage , p.  b. mackenzie , n.  h. shakespeare , h.  d. trottier , perturbative two- and three - loop coefficients from large beta monte carlo , nucl .",
    "phys . proc .",
    "83 ( 2000 ) 866871 . http://arxiv.org/abs/hep-lat/9910018 [ ] .",
    "r.  horsley , p.  e.  l. rakow , g.  schierholz , separating perturbative and non - perturbative contributions to the plaquette , nucl .",
    "106 ( 2002 ) 870872 . http://arxiv.org/abs/hep-lat/0110210 [ ] , http://dx.doi.org/10.1016/s0920-5632(01)01870-9 [ ] .",
    "h.  d. trottier , n.  h. shakespeare , g.  p. lepage , p.  b. mackenzie , perturbative expansions from monte carlo simulations at weak coupling : wilson loops and the static - quark self- energy , phys .",
    "d65 ( 2002 ) 094502 . http://arxiv.org/abs/hep-lat/0111028 [ ] , http://dx.doi.org/10.1103/physrevd.65.094502 [ ] .",
    "a.  hart , r.  r. horgan , l.  c. storoni , perturbation theory vs. simulation for tadpole improvement factors in pure gauge theories , phys .",
    "d70 ( 2004 ) 034501 . http://arxiv.org/abs/hep-lat/0402033 [ ] , http://dx.doi.org/10.1103/physrevd.70.034501 [ ] .",
    "a.  hart , g.  m. von hippel , r.  r. horgan , l.  c. storoni , automatically generating feynman rules for improved lattice field theories , j. comput .",
    "( 2005 ) 340353 .",
    "http://arxiv.org/abs/hep-lat/0411026 [ ] , http://dx.doi.org/10.1016/j.jcp.2005.03.010 [ ] .",
    "m.  a. nobes , h.  d. trottier , g.  p. lepage , q.  mason , second order perturbation theory for improved gluon and staggered quark actions , nucl .",
    "106 ( 2002 ) 838840 .",
    "http://arxiv.org/abs/hep-lat/0110051 [ ] , http://dx.doi.org/10.1016/s0920-5632(01)01860-6 [ ] .",
    "m.  a. nobes , h.  trottier , one loop renormalization of fermilab fermions , nucl .",
    "suppl . 119",
    "( 2003 ) 461463 .",
    "http://arxiv.org/abs/hep-lat/0209017 [ ] , http://dx.doi.org/10.1016/s0920-5632(03)01586-x [ ] .",
    "m.  a. nobes , h.  d. trottier , progress in automated perturbation theory for heavy quark physics , nucl .",
    "suppl . 129 ( 2004 ) 355357 .",
    "http://arxiv.org/abs/hep-lat/0309086 [ ] , http://dx.doi.org/10.1016/s0920-5632(03)02580-5 [ ] .",
    "b.  alles , m.  campostrini , a.  feo , h.  panagopoulos , lattice perturbation theory by computer algebra : a three loop result for the topological susceptibility , nucl .",
    "b413 ( 1994 ) 553566 . http://arxiv.org/abs/hep-lat/9301012 [ ] , http://dx.doi.org/10.1016/0550-3213(94)90632-7 [ ] .",
    "e.  follana , et  al .",
    ", highly improved staggered quarks on the lattice , with applications to charm physics , phys . rev .",
    "d75 ( 2007 ) 054502 .",
    "http://arxiv.org/abs/hep-lat/0610092 [ ] , http://dx.doi.org/10.1103/physrevd.75.054502 [ ] .",
    "g.  p. lepage , l.  magnea , c.  nakhleh , u.  magnea , k.  hornbostel , improved nonrelativistic qcd for heavy quark physics , phys .",
    "d46 ( 1992 ) 40524067 . http://arxiv.org/abs/hep-lat/9205007 [ ] , http://dx.doi.org/10.1103/physrevd.46.4052 [ ]",
    ".        g.  m. de  divitiis , r.  petronzio , n.  tantalo , on the discretization of physical momenta in lattice qcd , phys .",
    "b595 ( 2004 ) 408413 . http://arxiv.org/abs/hep-lat/0405002 [ ] , http://dx.doi.org/10.1016/j.physletb.2004.06.035 [ ] .    i.  t. drummond , a.  hart , r.  r. horgan , l.  c. storoni , one loop calculation of the renormalised anisotropy for improved anisotropic gluon actions on a lattice , phys .",
    "d66 ( 2002 ) 094509 . http://arxiv.org/abs/hep-lat/0208010 [ ] , http://dx.doi.org/10.1103/physrevd.66.094509 [ ] .",
    "i.  t. drummond , a.  hart , r.  r. horgan , l.  c. storoni , the contribution of @xmath276 radiative corrections to the renormalised anisotropy and application to general tadpole improvement schemes , phys .",
    "d68 ( 2003 ) 057501",
    ". http://arxiv.org/abs/hep-lat/0307010 [ ] , http://dx.doi.org/10.1103/physrevd.68.057501 [ ] .",
    "i.  t. drummond , a.  hart , r.  r. horgan , l.  c. storoni , lattice perturbation theory for gluonic and fermionic actions , nucl .",
    "suppl . 119",
    "( 2003 ) 470475 .",
    "[ ] , http://dx.doi.org/10.1016/s0920-5632(03)01589-5 [ ] .",
    "a.  hart , g.  m. von hippel , r.  r. horgan , leptonic widths of heavy quarkonia : s - wave qcd / nrqcd matching coefficients for the electromagnetic vector annihilation current at o(@xmath277 ) , phys .",
    "d75 ( 2007 ) 014008 .",
    "http://arxiv.org/abs/hep-lat/0605007 [ ] , http://dx.doi.org/10.1103/physrevd.75.014008 [ ] .",
    "a.  hart , g.  m. von hippel , r.  r. horgan , leptonic widths of heavy quarkonia : qcd / nrqcd matching for the electromagnetic current at o(@xmath277 ) , pos lat2006 ( 2006 ) 098 . http://arxiv.org/abs/hep-lat/0609002 [ ] .",
    "a.  hart , g.  m. von hippel , r.  r. horgan , heavy quarkonium decays on and off the lattice , in : g.  grindhammer , k.  sachs ( eds . ) , proceedings of 15th international workshop on deep - inelastic scattering and related subjects ( dis2007 ) , 2007 , p. 162 .",
    "a.  hart , g.  m. von hippel , r.  r. horgan , radiative corrections to the lattice gluon action for hisq improved staggered quarks and the effect of such corrections on the static potential , phys .",
    "d ( in press ) http://arxiv.org/abs/0812.0503 [ ] .                      g.  m. von hippel , taylur , an arbitrary - order automatic differentiation package for fortran 95 , comput .",
    "174 ( 2006 ) 569576 . http://arxiv.org/abs/physics/0506222 [ ] , http://dx.doi.org/10.1016/j.cpc.2005.12.016 [ ] .          k.  orginos , d.  toussaint , r.  l. sugar , variants of fattening and flavor symmetry restoration , phys . rev .",
    "d60 ( 1999 ) 054503 . http://arxiv.org/abs/hep-lat/9903032 [ ] , http://dx.doi.org/10.1103/physrevd.60.054503 [ ] .        c.  morningstar , m.  j. peardon , analytic smearing of su(3 ) link variables in lattice qcd , phys .",
    "d69 ( 2004 ) 054501 . http://arxiv.org/abs/hep-lat/0311018 [ ] , http://dx.doi.org/10.1103/physrevd.69.054501 [ ] .",
    "m.  lscher , p.  weisz , background field technique and renormalization in lattice gauge theory , nucl . phys . b452 ( 1995 ) 213233 .",
    "http://arxiv.org/abs/hep-lat/9504006 [ ] , http://dx.doi.org/10.1016/0550-3213(95)00346-t [ ] .",
    "m.  lscher , p.  weisz , computation of the relation between the bare lattice coupling and the ms coupling in su(n ) gauge theories to two loops , nucl .",
    "b452 ( 1995 ) 234260 . http://arxiv.org/abs/hep-lat/9505011 [ ] , http://dx.doi.org/10.1016/0550-3213(95)00338-s [ ] ."
  ],
  "abstract_text": [
    "<S> the derivation of the feynman rules for lattice perturbation theory from actions and operators is complicated , especially for highly improved actions such as hisq . </S>",
    "<S> this task is , however , both important and particularly suitable for automation . </S>",
    "<S> we describe a suite of software to generate and evaluate feynman rules for a wide range of lattice field theories with gluons and ( relativistic and/or heavy ) quarks . our programs are capable of dealing with actions as complicated as ( m)nrqcd and hisq . </S>",
    "<S> automated differentiation methods are used to calculate also the derivatives of feynman diagrams .    </S>",
    "<S> quantum chromodynamics , qcd , lattice qcd , perturbation theory    11.15.ha , 12.38.gc    81 - 04 , 81t13 , 81t15 , 81t18 , 81t25 , 81v05 , 65s05 , </S>",
    "<S> 41a58    * program summary *    _ manuscript title : _ automated generation of lattice qcd feynman rules + _ authors : _ a. hart , g.m . </S>",
    "<S> von hippel , r.r . </S>",
    "<S> horgan , e.h . </S>",
    "<S> mller . </S>",
    "<S> + _ program title : _ hippy , hpsrc + _ journal reference : _ </S>",
    "<S> + _ catalogue identifier : _ + _ licensing provisions : _ gplv2 ( see note in sec .  [ sec_licence ] . ) </S>",
    "<S> + _ programming languages : _ python , fortran95 + _ ram : _ problem specific , typically less than 1 gb for either code . + _ keywords : _ quantum chromodynamics , qcd , lattice qcd , perturbation theory + _ pacs : _ 11.15.ha ; 12.38.gc + _ classification : _ 4.4 feynman diagrams ; 11.5 quantum chromodynamics , lattice gauge theory + _ nature of problem : _ </S>",
    "<S> + derivation and use of perturbative feynman rules for complicated lattice qcd actions . </S>",
    "<S> + _ solution method : _ + an automated expansion method implemented in python ( hippy ) and code to use expansions to generate feynman rules in fortran95 ( hpsrc ) . </S>",
    "<S> + _ restrictions : _ + no general restrictions . </S>",
    "<S> specific restrictions are discussed in the text . + _ running time : _ </S>",
    "<S> + very problem specific , depending on the complexity of the feynman rules and the number of integration points . typically between a few minutes and several weeks . </S>"
  ]
}