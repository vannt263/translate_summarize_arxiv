{
  "article_text": [
    "despite the media hype , collaborative security approaches are seldom implemented as they raise several important challenges .",
    "security data , such as firewall logs or attack intelligence , might expose confidential and/or sensitive information , challenge corporations competitiveness , or even reveal negligence .    as a consequence , previous work proposed to sanitize data prior to sharing  @xcite .",
    "however , this makes data less useful  @xcite and still prone to de - anonymization  @xcite .",
    "one alternative is to let entities contribute encrypted data to a semi - trusted central repository that obliviously aggregates contributions  @xcite , or use distributed data aggregation protocols based on secure multi - party computation  @xcite . while aggregation can help compute traffic statistics , it only identifies most prolific attack sources and yields global models .",
    "as shown in  @xcite , however , generic attack models miss a significant number of attacks , especially when attack sources choose targets strategically and focus on a few known vulnerable networks . in theory , fully homomorphic encryption ( fhe )  @xcite could be used to compute personalized recommendations , however , fhe is still far from being practical and it remains unclear whether complex machine learning algorithms needed for the prediction could effectively run over encrypted data .",
    "* intuition .",
    "* this paper explores a novel approach to collaborative threat mitigation where organizations find suitable collaboration partners in a distributed and privacy - preserving way , and organize into coalitions prior to sharing .",
    "this way , sharing takes place within groups of related victims , i.e. , that share relevant sources of information . in our model",
    ", parties first identify a set of _ potential _ partners from a larger pool of organizations , e.g. , corporations in the same sector , and then select the _",
    "best _ partners . in practice , this can be repeated over time to ensure relevant and near real - time protection .",
    "we introduce the _ sharing is caring ( sic ) _ framework , which supports two types of algorithms : one for estimating the benefits of sharing in a privacy - preserving way ( i.e. , without disclosing plaintext data ) , and the other for sharing agreed - upon datasets with selected partners , e.g. , only common attacks .",
    "we focus on data sharing for predictive blacklisting , namely forecasting attack sources based on logs generated by different organizations firewalls and/or intrusion detection systems .",
    "as shown in previous work  @xcite , collaboration improves defense accuracy , as attackers tend to target victims in similar ways .",
    "* experiments .",
    "* one of our main goals is to investigate which collaboration strategies work best , in terms of the resulting improvement in prediction accuracy . to this end",
    ", we conduct several experiments on a real - world dataset of 2 billion suspicious ip addresses collected by dshield.org  @xcite over 2 months .",
    "this dataset contains a large variety of contributors , as confirmed by our analysis , which allows us to test the effectiveness of data sharing among diverse groups of victims .",
    "* main results .",
    "* our analysis yields several key findings , as we observe that : ( 1 ) the more information is available about attackers , the better the prediction , as intuitively expected ; ( 2 ) different collaboration strategies yield a large spectrum of performances , in fact , with some strategies , sharing does not actually help much ; ( 3 ) sharing information only about common attackers is almost as useful as sharing everything .",
    "this highlights both the importance of selecting the right partners and the usefulness of controlled data sharing .",
    "* summary of contributions . *",
    "our work is the first to provide a privacy - enhanced solution for collaborative predictive blacklisting .",
    "we demonstrate that data sharing does not have to be an `` all - or - nothing '' process : by relying on efficient cryptographic protocols for privacy - preserving information sharing , it is possible to share relevant data , and only when beneficial . compared to prior work , our approach has several advantages : ( 1 ) it helps privately identify entities with good partnership potential , ( 2 ) it minimizes information disclosure , and ( 3 ) it increases speed of malicious activity detection , leading to near real - time mitigation .",
    "our work could also be applied to other security - related applications that benefit from data sharing , such as spam filtering  @xcite , malware detection  @xcite , or ddos mitigation  @xcite .",
    "* paper organization . * the rest of the paper is organized as follows .",
    "next section presents some preliminary notions .",
    "section  [ sec : framework ] introduces the sharing is caring ( sic ) framework , while section  [ sec : dshield ] presents a measurement - based analysis of a real - world dataset of security logs .",
    "section  [ sec : experiments ] covers an experimental evaluation of proposed techniques , followed by related work , in section  [ sec : related ] .",
    "the paper concludes with section  [ sec : conclusion ] .",
    "this section presents our system assumptions and some relevant background information .",
    "we assume a network of entities @xmath0 .",
    "each @xmath1 maintaining a dataset @xmath2 of suspicious events , such as suspicious ip addresses observed by a firewall @xmath3ip , time , port@xmath4 .",
    "we denote this list of events as @xmath5 ( for each entity @xmath1 ) . hence , @xmath6 .",
    "each entity @xmath1 aims to predict and block ( i.e. , blacklist ) future attacks .",
    "* existing approaches . *",
    "thus far , two main approaches have been used for predictive blacklisting : ( 1 ) no collaboration , i.e. , each entity @xmath1 independently performs the prediction based only its own dataset @xmath2 , or ( 2 ) community - based , i.e. , each entity @xmath7 submits its dataset @xmath2 to a central repository , which returns a customized blacklist for @xmath1 , also based on all entities datasets .",
    "the latter provides increased accuracy  @xcite but requires entities to reveal their datasets to a central repository .     * our novel model .",
    "* we introduce a privacy - friendly collaborative model for predictive blacklisting , whereby entities identify good collaboration partners via pairwise secure computations ( without the need for a trusted third - party ) , and then share data . this way , data sharing takes place in groups of related victims .",
    "each entity performs predictions based not only on its own dataset but also on an augmented dataset that comprises information possibly shared by the counterpart , aiming to improve prediction and , at the same time , avoiding the wholesale disclosure of datasets .     * threat model .",
    "* we denote with @xmath8 an adversary attempting to learn information about other entities datasets .",
    "( external adversaries are not considered , since their actions can be mitigated via standard network security techniques . ) in the worst case , @xmath9 may try to collaborate with all other entities and collect available information after each data sharing attempt .",
    "@xmath9 obtains network traces that allow inference of strategic information .",
    "hence , we aim to protect data confidentiality for each @xmath10 .",
    "we assume adversary @xmath9 to be semi - honest ( or honest - but - curious ) : @xmath9 follows protocols specifications and does not misrepresent any of its inputs , but , during or after protocol execution , it might attempt to infer additional information about other parties inputs .",
    "we now review some cryptographic primitives used through the rest of the paper .     * secure two - party computation ( 2pc ) * allows two parties , on input @xmath11 and @xmath12 , respectively , to privately compute the output of any public function @xmath13 over @xmath14 .",
    "both parties learn nothing beyond what can be inferred from the output of the function . for more details on 2pc",
    "refer to  @xcite . *",
    "private set intersection ( psi ) * allows two parties , a server , on input a set @xmath15 , and a client , on input a set @xmath16 , to interact in such a way that the latter only learns @xmath17 , and the former learns nothing beyond the size of @xmath16 .",
    "state - of - the - art instantiations , include both garbled - circuit based techniques  @xcite and specialized protocols  @xcite . in our experiments",
    ", we use the psi construction presented in  @xcite , secure under the one - more - rsa assumption  @xcite in the random oracle model ( rom ) , with computational and communication complexities linear in set sizes .",
    "note , however , that one can select any psi construction , without affecting our design .     * private set intersection cardinality ( psi - ca ) * allows two parties , a server , on input a set @xmath15 , and a client , on input a set @xmath16 , to interact in such a way that the latter only learns @xmath18 , while the former learns nothing beyond @xmath19 .",
    "psi - ca is a more `` stringent '' variant than psi , as it only reveals the magnitude of the intersection , but not the actual contents .",
    "there are several instantiations of psi - ca  @xcite , and , in our experiments , we use the construction presented in @xcite , which has linear complexities , with security under the one - more - dh assumption  @xcite in the random oracle model ( rom ) . again , note that any psi - ca construction can be employed .",
    "* private jaccard similarity ( pjs ) * allows two parties , a server , on input a set @xmath15 , and a client , on input a set @xmath16 , to interact in such a way that the client only learns @xmath20 , where @xmath21 denotes the jaccard similarity index  @xcite between sets @xmath15 and @xmath16 .",
    "blundo et al .",
    "@xcite slightly relax the above definition and shows how to privately compute the jaccard similarity index using only psi - ca . since @xmath22",
    ", parties can obtain @xmath23 without disclosing the actual sets content .      as mentioned earlier , we focus on predictive blacklisting , i.e. , forecasting future malicious sources based on past attacks",
    ".     * algorithm .",
    "* let @xmath24 denote the day an attack was reported and @xmath25 the current time , so @xmath26 .",
    "we partition @xmath25 into two windows of consecutive days : a training window , @xmath27 and a testing window , @xmath28 .",
    "prediction algorithms rely on information in the training data , @xmath29 , to tune their model and validate the predictions for the testing data , @xmath30 .",
    "the global worst offender list ( gwol ) is a basic prediction algorithm that selects top attack sources from @xmath27 , i.e. , highest number of globally reported attacks  @xcite .",
    "local worst offender list ( lwol ) is the local version of gwol and operates on a local network based entirely on its own history  @xcite .",
    "lwol fails to predict on attackers not previously seen , while gwol tends to be irrelevant to small victims .",
    "thus , machine learning algorithms were suggested to improve gwol and lwol  @xcite .",
    "we use the _ exponentially weighted moving average _ ( ewma ) algorithm , as proposed by soldo et al .",
    "@xcite , to perform blacklisting prediction .",
    "ewma uses time series aggregation : it consists in aggregating attack events from @xmath27 to predict future attacks .",
    "other features one could consider include the historical malicious activity of an ip address , the clustering of ip addresses with similar malicious behavior , and the network centrality of a target .",
    "it is out of the scope of this paper to improve on existing prediction algorithms  rather , we focus on how to help organizations identify useful partners in a privacy - preserving way , and how different collaboration strategies perform in comparison to each other .",
    "* accuracy metrics . *",
    "as commonly done with prediction algorithms , we measure accuracy with _ true positives _ ( tp ) , which is the number of predictions that correctly match future events . in the blacklisting scenario , tp correspond to the number of attacks in the blacklist that are correctly predicted .    in practice",
    ", sources might not be blacklisted at once and blacklisting algorithms might rely on several observations over time before blacklisting a source , such as the rate at which the source is attacking , the payload of suspicious packets , etc .",
    "it is important to distinguish between the _ prediction algorithm _ , which identifies potential malicious sources and/or creates a watch - list from the _ blacklisting algorithm _ , which actually blocks sources .",
    "blacklisting algorithms are site - specific and need to optimize , among others , false negative and false positive ratios .",
    "the prediction algorithm enables the identification of suspicious ip addresses that deserve further scrutiny and improve the effectiveness of blacklisting algorithms .",
    "therefore , just like prior work  @xcite , we focus on measuring the tp of the prediction algorithm , i.e. , the ability to identify potential sources of attacks , and do not consider false positives as it is out of the scope of our work .",
    "* upper bounds . *",
    "a future attack can be predicted if it already appeared in the logs of some victims .",
    "traditional upper - bounds on collaboration algorithms capture this and we use them to evaluate the performance of our collaboration algorithms .",
    "the global upper bound @xmath31 measures , for every target @xmath1 , the number of attackers that are both in the training window _ of any victim _ and in @xmath1 s testing window . for every @xmath1",
    ", we define the local upper bound @xmath32 , as the number of attackers that are both in @xmath1 s training and testing windows .",
    "starts interacting with entity @xmath33 and they jointly and privately estimate the benefits of collaboration ; ( 2 ) entities decide whether or not to partner ; ( 3 ) partners decide how to merge their datasets . ]      we now describe , in details , the logics behind our intuition for privacy - enhanced collaborative predictive blacklisting by introducing the sharing is caring ( sic ) framework .",
    "it involves two types of algorithms : one supporting the secure _ selection _ of collaboration partners , and another for the privacy - preserving _ merging _ of ( i.e. , sharing ) datasets among partners . as discussed in section  [ sec : preliminaries ] , we assume a network of @xmath34 entities and define @xmath2 to be the set of unique ip addresses held by @xmath1 : @xmath35 .",
    "a high - level sketch of the sic framework is presented in fig .",
    "[ fig : diagram ] . in ( 1 ) , potential partner entities @xmath1 and @xmath33 estimate the benefits they would receive from sharing their security data with each other .",
    "they could do so by securely computing one or multiple metrics .",
    "such as size of intersection , jaccard similarity , pearson correlation , or cosine similarity between their datasets . in ( 2 ) , then , based on the estimated benefits , entities decide whether to partner or not . for instance ,",
    "@xmath1 and @xmath33 become partners if the expected benefit is above a certain threshold ; alternatively , each entity might partner with @xmath36 other entities that yield the maximum benefits . finally , in ( 3 )",
    ", partners merge their datasets , e.g. , by only sharing common attacks .",
    "| c | c | c | & * operation * & * private * + * mation metric * & & * protocol * + _ intersection- _ & [ 2]*@xmath37 & [ 2]*psi - ca  @xcite    ' '' ''     + _ size _ & & + _ jaccard _ & @xmath38 & pjs  @xcite    ' '' ''    ' '' ''     + [ 2]*_pearson _ & [ 2]*@xmath39 & garbled    ' '' ''     + & & circuits  @xcite    ' '' ''     + [ 2]*_cosine _ & [ 2]*@xmath40 & garbled    ' '' ''     + & & circuits  @xcite    ' '' ''     +      entities select partners by privately evaluating , _ in pairwise interactions _ , the benefits of sharing their data with each other . * supported metrics . *",
    "we consider several similarity metrics for partner selection .",
    "metrics are reported in table  [ tab : metric-1 ] , along with the corresponding protocols for their privacy - preserving computation .",
    "we consider similarity metrics since previous work  @xcite showed that collaborating with correlated victims works well .",
    "victims are correlated if they are targeted by correlated attacks , i.e. , attacks mounted by the same source ip against different networks around the same time .",
    "intuitively , correlation arises from attack trends ; in particular , correlated victim sites may be on a single hit list or might be natural targets of a particular exploit ( e.g. , php vulnerability ) .",
    "then , collaboration helps re - enforce knowledge about an on - going attack and/or learn about an attack before it hits .     *",
    "set - based and correlation - based similarity .",
    "* we consider two set - based metrics : _ intersection - size _ and _ jaccard _ , which measure set similarity and operate on unordered sets .",
    "we also consider _ pearson _ and _ cosine _ , which provide a more refined measure of similarity than set - based metrics , as they also capture statistical relationships .",
    "the last two metrics operate on data structures representing attack events , such as a binary vector , e.g. , @xmath41 $ ] , of all possible ip addresses with 1-s if an ip attacked at least once and 0-s otherwise .",
    "this can make it difficult to compute correlation in practice , as both parties need to agree on the range of ip addresses under consideration to construct vector @xmath42 .",
    "considering the entire range of ip addresses is not reasonable ( i.e. , this would require a vector of size 3.7 billion , one entry for each routable ip address ) .",
    "instead , parties could either agree on a range via 2pc or fetch predefined ranges from a public repository .",
    "in practice , entities could decide to compute any combination of metrics .",
    "note that the list in table  [ tab : metric-1 ] is non - exhaustive and other metrics could be considered , as long as it is possible to efficiently support their privacy - preserving computation .     * establishing partnerships .",
    "* after assessing the potential benefits of data sharing , entities make an informed decision as to whether or not to collaborate , based , e.g. , on :    1",
    ".   _ threshold : _",
    "@xmath1 and @xmath33 partner up if the estimated benefit of sharing is above a certain threshold ; 2 .   _ maximization : _ @xmath1 and @xmath33",
    "independently enlist @xmath36 potential partners to maximize their overall benefits ( i.e. , @xmath36 entities with maximum expected benefits ) ; 3 .   _",
    "@xmath1 and @xmath33 enlist @xmath36 potential partners to maximize their overall benefits , but also partner with entities for which estimated benefits are above a certain threshold .    while in practice entities",
    "could refuse to collaborate with other entities , one could rely on well - known collaboration algorithms that offer stability ( e.g. , stable marriage / roommate matching  @xcite ) . without loss of generality",
    ", we leave this for future work and assume cooperative parties , i.e. , entities systematically accept collaboration requests .",
    "* symmetry of benefits . * some of the protocols used for secure computation of benefits , such as psi - ca  @xcite and pjs  @xcite , reveal the output of the protocol to only one party . without loss of generality , we assume that this party always reports the output to its counterpart .",
    "we operate in the semi - honest model , thus parties are assumed not to prematurely abort protocols .",
    "metrics discussed above are _ symmetric _ , i.e. , both parties obtain the same value , and facilitate partner selection as both parties have incentive to select each other .",
    "after the select stage , entities are organized into coalitions , i.e. , groups of victims that agreed to share data with each other .",
    "entities can now merge their datasets with selected partners .",
    "* strategies .",
    "* partners could share their datasets in several ways : e.g. , they can disclose their whole data or only share which ip addresses they have in common , or transfer all attack events associated to common addresses and/or a selection thereof .",
    "* privacy - preserving merging . *",
    "our goal is to ensure that nothing about datasets is disclosed to partners beyond what is agreed .",
    "for instance , if partners agree to only share information about attackers they have in common , they should not learn any other information .",
    "possible merging strategies , along with the corresponding privacy - preserving protocols , are reported in table  [ tab : metric-3 ] .",
    "again , we assume that the output of the merging protocol is revealed to both parties .",
    "strategies denoted as _ intersection / union with associated data _ mean that parties not only compute and share the intersection ( resp .",
    ", union ) , but also all events related to items in the resulting set .",
    "obviously , union with associated data does not yield any privacy , as all events are mutually shared .",
    "organizations could also limit the information sharing in time , e.g. , by only disclosing data older than a month or of the last week , and previously proposed sanitization techniques  @xcite could be used on top of sic s merging strategies .",
    "| c | c | c | & * operation * & * private protocol * + _ intersection _ & @xmath43 &  psi  @xcite    ' '' ''    ' '' ''     + _ intersection with _ & @xmath44 & psi with     ' '' ''     + _ associated data _ & @xmath45 & data transfer  @xcite + _ union with _ & @xmath44 & [ 2]* no privacy     ' '' ''     + _ associated data _ & @xmath46 & +       * privacy . * our approach guarantees privacy through limited information sharing . only data explicitly authorized by parties",
    "is actually shared .",
    "data sharing occurs by means of secure two - party computation techniques , thus , security follows , provably , from that of underlying cryptographic primitives .     * authenticity .",
    "* recall that we assume semi - honest adversaries , i.e. , entities do not alter their input datasets . if one relaxes this assumption , then it would become possible for a malicious entity to inject fake inputs or manipulate datasets to violate counterpart s privacy . nonetheless , we argue that assuming honest - but - curious entities is realistic in our model .",
    "first , organizations can establish long - lasting relations and reduce the risk of malicious inputs as misbehaving entities will eventually get caught . also , one could also leverage peer - to - peer techniques to detect malicious behavior  @xcite .     * incentives and competitiveness . *",
    "since data exchanges are bi - directional , each party directly benefits from participation and can quantify the contribution of its partners .",
    "if collaboration metrics do not indicate high potential , each entity can deny collaboration .",
    "that is , the incentive to participate is immediate as benefits can be quantified before establishing partnerships .",
    "* trust . *",
    "sic relies on data to establish trust automatically .",
    "if multiple entities report similar data , then it is likely correct and contributors can be considered as trustworthy .",
    "sic enables entities to estimate each others datasets and potential collaboration value .",
    "this increases awareness of the contribution value and enables automation of trust establishment",
    ".     * speed .",
    "* due to the lack of a central authority and vetting processes , data sharing in sic is instantaneous , thus , entities can interact as often and as fast as they like .",
    "[ fig : average ]",
    "in order to assess the effectiveness of our approach , we should ideally obtain security data from real - world organizations .",
    "such datasets are hard to come by because of their sensitivity .",
    "therefore , we turn to dshield.org  @xcite and obtain a dataset of firewall and ids logs mostly contributed by individuals and small organizations .",
    "dshield contains data contributors are willing to report , however , as in previous work  @xcite , we can assume strong correlation between the amount of reporting and the amount of attacks .    in this section ,",
    "we show that dshield dataset contains data from a large variety of contributors ( in terms of the amount of contributions ) and provides a reasonable alternative to experiment with our privacy - enhanced collaborative approach .",
    "we obtained two months worth of logs from the dshield repository .",
    "each entry in the logs includes a contributor i d , a source ip address , a target port number , and a timestamp  see table  [ tab : illustrationdshield ] .",
    "the _ source _ of an attack refers to the attacker and _ target _ ( or contributor ) refers to a victim ( @xmath1 ) .",
    "note that dshield anonymized the `` contributor i d '' field by replacing it with a random yet _ unique _ string that maps to a single victim .",
    "data obtained from dshield consists of about 2 billion entries , from @xmath47k unique contributors , including more than @xmath48 m malicious ip sources , for a total of @xmath49 gb .",
    "we pre - processed the dataset in order to reduce noise and erroneous entries , following the same methodology adopted by previous work on dshield data  @xcite .",
    "we removed approximately 1% of of all entries , which belonged to invalid , non - routable , or unassigned ip addresses , or referred to non - existent port numbers .",
    "we now present a measurement analysis of the dshield dataset , aiming to better understand characteristics of attackers and victims .",
    "overall , our observations are in line with prior work  @xcite and highlight how attackers tend to hit victims in a coordinated fashion , thus confirming the potential of collaboration .     * general statistics .",
    "* we observe that @xmath50 of targets contribute less than @xmath51 of the time , while @xmath52 of targets ( @xmath53 targets ) contribute daily .",
    "we describe , at the end of this section how we filter out targets that seldom contribute . for more details and statistics ,",
    "we refer to the appendix .     * victims profile . * fig .",
    "[ fig : average : subfig1 ] shows the number of attacks per day on targets , with mean number of daily attacks on targets of @xmath54 and median of @xmath55 .",
    "we observe three distinct victims profiles : ( 1 ) rarely attacked victims : @xmath56 of targets get less than @xmath57 attacks day , indicating many victims seldom attacked ; ( 2 ) lightly attacked victims : @xmath58 of victims get @xmath57 to @xmath59 attacks a day ; ( 3 ) heavily attacked victims : only @xmath60 of targets are under high attack ( peaking at @xmath61 m a day ) . in other words ,",
    "most attacks target few victims",
    ".     * attackers profile . * fig .",
    "[ fig : average : subfig2 ] shows the number of victims attacked by each source per day , with mean number of daily attacks of @xmath62 and median of @xmath63 .",
    "we observe that @xmath64 of sources initiate less than @xmath57 attacks a day , i.e. , most sources appear stealthy .",
    "a small number of sources generates most attacks ( up to @xmath57 m daily ) .",
    "this indicates two main categories of attackers : stealth and heavy hitters . in our data",
    "set , we observe that several of top heavy attackers ( more than @xmath65 m attacks ) come from ip addresses owned by isps in the uk .",
    "* attacks characteristics . * fig .  [ fig : average : subfig3 ] shows the cdf of the number of unique sources seen by each active target a day .",
    "we focus on active victims : victims that did report an event on that particular day because , as previously discussed , many victims report attacks rarely thus creating a strong bias towards @xmath66 otherwise .",
    "the figure contains attackers shared with other targets ( common attackers ) and attackers unique to a specific victim .",
    "90% of victims are attacked by at most @xmath67 unique sources and @xmath68 shared sources .",
    "this shows that , from the victim s perspective , targets observe more shared sources than unique ones .",
    "compared to previous work  @xcite , this reinforces the past trend of targets having many common attackers .",
    "[ fig : average : subfig4 ] shows that @xmath69 of sources attack @xmath70 common victims and @xmath68 unique victims .",
    "although attackers share a large number of common victims , they also uniquely attack specific victims .",
    "note that in fig .",
    "[ fig : average : subfig3 ] and fig .",
    "[ fig : average : subfig4 ] , we observe again three types of victims and two types of attackers .",
    "* observations . *",
    "a significant proportion of victims ( @xmath7170% ) contributes a single event overall .",
    "after thorough investigation , we find that these _ one - time contributors _ can be grouped into clusters all reporting the same ip address within close time intervals ( often within one second ) .",
    "many contributors share only one attack event , at the same time , about the same potentially malicious ip address .",
    "similarly , many contributors only contribute one day out of the two months .",
    "these contributors correlate with the aforementioned one - time contributors .",
    "we remove victims that do not share much , specifically , we remove victims that ( 1 ) share one event overall , and ( 2 ) contribute only one day and less than 20 events over the two month ( i.e. , 10% of mean total contributions per victim @xmath63,@xmath72 ) .",
    "this data processing maintains properties identified in this section and reduces the number of considered victims from @xmath47,@xmath73 to @xmath74,@xmath75 , corresponding to the removal of about 2 million attacks .",
    "this filtering maintains a high diversity of contributors , and seeks to model real - world scenarios ( as opposed to focusing on large contributors ) .",
    "we now present an experimental evaluation of the sic framework focused on ( 1 ) investigating which _ select metrics _",
    "work best to estimate the benefits of sharing ( measured as the resulting improvement in prediction accuracy ) , and ( 2 ) measuring what _ merging strategies _ ( i.e. , what data to share ) provide the best privacy / accuracy trade - off . to do so , we use the dshield dataset built in section  [ sec : dshield ] .",
    "experiments involve 188,522 contributing entities , each reporting an average of 2,000 attacks , for a total of 2 billion attacks .",
    "experiments are implemented in r. source code is available upon request . *",
    "general parameters . * for the prediction algorithm , we use a one - week window for training ( @xmath76 ) and aim to predict attacks for the next day ( @xmath77 ) .",
    "as previously discussed , organizations do not run sic with all possible other organizations , but focus on a few potential partners . to model this ,",
    "we take a _ sampling _ approach : for each iteration , we select @xmath59 victims at random from the set of all @xmath74,@xmath75 possible victims and run our select / merge algorithms .",
    "we average our results over @xmath59 iterations .",
    "* select algorithms .",
    "* we analyze how well different collaboration metrics ( i.e. , select strategies ) perform in comparison to each other , where performance is measured in terms of resulting improvement in prediction accuracy .",
    "sic supports both set - based ( _ intersection - size _ and _ jaccard _ ) and correlation - based ( _ pearson _ and _ cosine _ ) metrics . with the former , the input of each entity @xmath1 is a set of unique attacking ip addresses @xmath2 .",
    "_ intersection - size _ returns the number of ip addresses attacking both parties , while _ jaccard _ is the ratio between the size of set intersection and the size of the union .",
    "by contrast , for correlation to work between two entities @xmath1 and @xmath33 , they need to agree on the range of ips captured in @xmath42 and @xmath78 .",
    "we assume that both parties know the global list of suspicious ip addresses . in practice",
    ", parties can agree on the range via secure computation or fetch known malicious ip address lists from repositories such as dshield .",
    "metrics are computed pairwise , thus , we obtain a matrix estimating data sharing benefits among all possible pairs .",
    "we assume that parties select partners by maximizing their potential benefits in the collaboration matrix .",
    "typically , each party picks the list of partners with the largest potential benefits .",
    "we consider that the @xmath79 largest collaboration pairs are selected ( i.e. , only 1% of @xmath80 possible pairs as we consider 100 victims ) .",
    "such a small number provides a high degree of privacy and takes a conservative stance by limiting the possible improvement in the prediction accuracy .",
    "recall that the goal of our experimental evaluation is to understand _ which _ metrics work _",
    "better _ , not to establish the optimal size of collaboration pools .",
    "[ fig : alpha ]     * merge algorithms . *",
    "we consider two types of algorithms , _ union with associated data _ and _ intersection with associated data _ ( see section  [ subsec : merge ] ) .",
    "with the former , partners share all data known by each party prior to current time @xmath24 and share it with each selected partner .",
    "it is a generous strategy that enriches others datasets rapidly . with the latter ,",
    "partners only share events from those ip addresses that belong to the intersection ( i.e. , that attacked both partners ) and thus is a more conservative option .",
    "this approach can help reinforce knowledge about given adversaries , and thus help better predict attacks .",
    "* accuracy . * as discussed in section  [ subsec : predictive ] , we measure the prediction success by computing the number of true positives ( tp ) , as in prior work  @xcite , i.e. , successfully predicted attacks .",
    "specifically , we measure improvement as @xmath81 , where @xmath82 is the number of true positives before collaboration and @xmath83 is the number of true positives after collaboration . we note that improvement can be measured over all entities , or for specific entities . in the following , we give both improvement measures .      [",
    "fig : collaboration ]    * determining the value of @xmath84 . * before testing the performance of select / merge algorithms , we need to identify appropriate @xmath84 values for the ewma prediction algorithm by evaluating the performance of the prediction . for small values of @xmath84 , the prediction algorithm aggregates past information uniformly across the training window to craft predictions . in other words ,",
    "events in the far past have a similar weight to events in the short past and the algorithm has a long memory . on the contrary , with a large @xmath84 , the prediction algorithm focuses on the most recent past events ; it has short memory .",
    "[ fig : prediction : alpha ] shows the evolution of the baseline prediction for different values of @xmath84 , plotting the true positives ( tp ) sum of all @xmath59 victims averaged over @xmath59 iterations .",
    "values between @xmath85 and @xmath86 perform best .",
    "this can be explained by remembering the `` bursty nature '' of web attacks , as discussed in section  [ sec : dshield ] .",
    "prediction algorithms that react fast to the apparition of new attackers perform better .",
    "we set @xmath87 .     * visualizing predictions . *",
    "[ fig : prediction : visual ] shows a visualization of the prediction . when an attack occurs ( blue square )",
    ", the algorithm systematically predicts an attack ( red cross ) in the next time slot . because @xmath86 , the last attack event has a larger weight",
    ".     * baseline prediction . *",
    "we verify the effectiveness of the prediction algorithm by correlating the information known prior to collaboration with the ability to predict attacks .",
    "we obtain that , as expected , targets that know more about past attacks ( large @xmath2 ) , successfully predict more future attacks .",
    "we measure correlation @xmath88 on average , which indicates strong correlation .",
    "this , once again , suggests that collaboration increases prediction success .",
    "we visualize this correlation for a specific simulation in fig .",
    "[ fig : collaboration : subfig1 ] .     * select strategies .",
    "[ fig : collaboration : subfig2 ] shows the accuracy of predictions for different select methods over the course of one week , fixing the merge algorithm to _ intersection with associated data _ , as it provides the strongest privacy protection .",
    "we sum the total number of tp for `` collaborators '' ( i.e. , entities that do share data ) and `` non - collaborators '' ( entities that do not share data , thus performing as in the baseline ) .",
    "we observe that _ intersection - size _ performs best , followed by _",
    "jaccard _ , and _",
    "cosine / pearson_. the overall decrease in sum of true positives after day @xmath57 is due to the decrease of attacks on those days as discussed in the appendix ( see fig .",
    "[ fig : general : subfig1 ] ) .     * improvement over baseline . * in fig .",
    "[ fig : collaboration : subfig3 ] , we compare the prediction accuracy of upper - bounds , baseline , and collaboration using _ intersection - size _ as the select metric and merging data using _ intersection with associated data_. we sum the total number of tp for collaborators selected by the _ intersection - size _ metric .",
    "remind that with the global upper bound ( gub ) , every victim shares with every other victim and predicts perfectly . with the local upper bound ( lub ) ,",
    "organizations do not share anything but still predict perfectly .",
    "the accuracy of _ intersection - size _ predictions tends to match lub , showing that collaboration helps perform as well as a local perfect predictor .",
    "note that prediction performance can be significantly improved ( thus , reducing the `` gap '' with gub ) by enabling more collaboration pairs than the conservative @xmath79 ( 1% of all pairs ) considered in our experiments .     *",
    "effects of selective collaboration .",
    "* table  [ tab : improvements ] summarizes prediction improvements for collaborators given different select metrics , reporting the mean , max , and min improvement , as well as number of collaborators .",
    "correlation - based metrics provide a less significant prediction improvement than set - based metrics .",
    "mean @xmath89 for _ pearson _ and _ cosine _ is about @xmath90 .",
    "notably , the _ intersection - size _ has a @xmath91 mean improvement .",
    "also , mean @xmath89 for _ jaccard _ is about @xmath92 .",
    "naturally , the improvement can also be measured for each entity : @xmath89 for _ intersection - size _ is up to @xmath93 .",
    "differences between select metrics are due to several reasons .",
    "first , metrics that use a normalization factor ( i.e. , all but _ intersection - size _ ) tend to create partnerships of small collaborators .",
    "by contrast , _ intersection - size _ leads to better performance because it promotes collaboration with larger victims . to confirm this hypothesis",
    ", we measure the set size of collaborators according to different metrics ( fig .  [",
    "fig : boxplot ] ) and confirm that metrics with a normalization factor tend to pick collaborators that know less .",
    "second , correlation - based metrics tend to select partners that are _ too _ similar : maximum correlation values are close to @xmath55 , whereas maximum _ jaccard _ values get to @xmath94 only .",
    "although this implies that targets learn to better defend against specific adversaries , it also leads to little acquired knowledge .",
    "third , depending on the select metric , at each time step , victims may partner with previous collaborators , or with new ones .",
    "we find that _ intersection - size _ , _ pearson _ , and _ cosine _ lead to stable groups of collaborators with about 90% reuse over time , whereas _ jaccard _ has larger diversity of collaborators over time .",
    "this is because about 20% of victims have high _ jaccard _ similarity versus only 4% for correlation - based metrics providing a larger pool of potential collaborators .",
    "hence , if _ intersection - size _ helps a few learn a lot , _ jaccard _ helps many victims over time .",
    "* statistical analysis . *",
    "a t - test analysis shows that the mean of the number of events known by collaborators differs significantly ( @xmath95 ) across all pairs of select metrics but _ cosine _ and _ pearson_. if one categorizes collaborators as `` large '' if they know more than @xmath96 events , and `` small '' otherwise , and consider _ cosine _ and _ pearson _ as one ( given the t - test result ) , we obtain a @xmath97x@xmath63 table of select metrics and size categories .",
    "a @xmath98-test shows that categorization differences are statistically significant : _ intersection - size _ tends to select larger collaborators , but also more collaborators than _ pearson / cosine _ ( see table  [ tab : improvements ] ) .",
    "other metrics tend to select small collaborators .",
    "we obtain @xmath99 , where @xmath63 is the degrees of freedom of the @xmath98 estimate , and @xmath100 is the total number of observations .     * coalitions . *",
    "recall that , at each time step , entities can decide to partner with a number of other entities . table  [ tab : improvements ] shows the mean , standard deviation , and median number of collaborators per party for different collaboration metrics .",
    "we observe that with _ jaccard _ , entities tend to select less collaborators .",
    "other metrics tend to have similar behavior and have entities to collaborate with about @xmath101 other entities out of @xmath59 .",
    "this is in line with previous work  @xcite , which showed the existence of small groups of correlated entities .",
    "we also observe that , after a few days ( usually @xmath63 ) , _ intersection - size _ , _ pearson _ , and _ cosine _ converge to a relatively stable group of collaborators . from one time - step to another , parties continue to collaborate with about 90% of entities they previously collaborated . in other words",
    ", coalitions are relatively stable over time .",
    "comparatively , _ jaccard _ has a larger diversity of collaborators over time .",
    "* merge algorithms .",
    "* the next step is to compare the average prediction improvement @xmath89 for different merge algorithms . as showed in fig .",
    "[ fig : union ] , _ intersection with associated data _ performs almost as good as _ union with associated data _ with all select strategies",
    "actually , it performs better with _",
    "jaccard_. merging using the union entails sharing more information , thus , one would expect it to always perform better .",
    "however , using _",
    "union with associated data _ , organizations quickly converge to a stable set of collaborators , and obtain a potentially lower diversity of insights over time . with most metrics , the set of collaborators is stable over time anyways , and so union does perform better than intersection .",
    "but , as previously discussed , _ jaccard _ tends to yield a larger diversity of collaborators over time and thus benefits more from _ intersection with associated data _ as it re - enforces such diversity of insights .",
    ".fraction of prediction improvements @xmath89 for collaborators , number of collaborators , and size of coalitions . [ cols=\"^,^,^,^,^,^,^,^,^ \" , ]      we now estimate the operational cost of our techniques and show that it is appreciably low .",
    "specifically , we evaluate the overhead introduced by the privacy protection layer . excluding correlation - based metrics ( due to lower accuracy improvement ) , the protocols for privately selecting partners ( _ intersection - size _ and _ jaccard _ ) can be realized based on private set intersection cardinality ( psi - ca ) , and we choose the instantiation proposed in @xcite , which incur computation and communication overhead linear in sets size .",
    "privacy - preserving merging relies on the private set intersection ( psi ) with data transfer protocol from  @xcite in order to realize _ intersection with associated data_. we implemented protocols from  @xcite and  @xcite in c , and conducted experiments on intel xeon desktops with 3.10ghz cpu , connected by a 100mbps ethernet link .",
    "[ fig : average : subfig3 ] shows that 98% of targets are attacked by about @xmath102 sources .",
    "using sets of size @xmath102 , it takes approximately @xmath103 to execute psi from  @xcite and @xmath104 for psi - ca from  @xcite . assuming that @xmath105 organizations contribute to our framework",
    ", we have a total of @xmath106 interactions per entity , and a total of @xmath107 pairwise executions .",
    "naturally , it is not reasonable to consider all possible partnerships in a large pool of organizations .",
    "parties first identify a set of _ potential _ partners , such as organizations within an industry , and then select the _",
    "best _ partners within .",
    "realistically , we can thus assume @xmath108 .",
    "we obtain that the running time amounts to @xmath109 for one entity to estimate benefits , using psi - ca , with all other ( @xmath110 ) parties . following a conservative stance , i.e. , assuming that entities select and share with all possible @xmath110 partners , privacy - preserving merging via psi - dt takes @xmath111 ( in the worst case scenario ) .",
    "pairwise executions can obviously be performed in parallel , at least , between different pairs . even if we assumed a worst - case scenario , where data sharing occur in a sequential manner across all organizations , the total computation overhead ( again , assuming @xmath108 partners and merging with all partners ) would amount to @xmath112 minutes for benefit estimation and @xmath113 minutes for dataset merging , which is still reasonable for computations that are performed , e.g. , once a day .",
    "thus , we conclude that overhead introduced by the privacy protection layer is appreciably low and does not impede the deployment and the adoption of our techniques .       * knowing more means predicting more . *",
    "our experiments show that targets that know more tend to successfully predict more attacks .",
    "this confirms our hypothesis about the opportunity to collaborate with targets exposed to numerous attacks .",
    "however , the simple `` more - data - the - better '' approach conflicts with privacy , thus , the challenge consists in identifying partners that help most .",
    "choosing partners based on higher values of _ intersection - size _ works best and provides convenient privacy properties since it only discloses information about attackers entities already know of .     *",
    "sometimes sharing does not help much .",
    "* in some cases , data sharing does not yield significant improvements : we show that differences in similarity definition may lead to significant variations in accuracy .",
    "when considering correlation - based similarity between victims profiles , small contributors are paired together , leading to small overall improvements . by contrast , set - based metrics favor larger contributors and thus yield larger overall improvement .     *",
    "sharing only common attacks is almost as useful as sharing everything . *",
    "when merging datasets , organizations sharing only information about common attacks ( i.e. , using _ intersection with associated data _ ) achieve a good trade - off between privacy and utility as the improvement is almost as good as when sharing everything .",
    "intuitively , merging using intersection helps because it reinforces knowledge of a particular attacker , while using union helps victims targeted by varying group of attackers .",
    "thus , victims benefit as much from improving their knowledge of current attackers , as learning about sources that attack them next .",
    "in other words , learning information about attackers targeting a victim in the past is similar to learning about attackers that might target a victim in the future .",
    "we acknowledge that the dshield dataset used in our experiments might be biased toward small organizations voluntarily reporting data , thus it might not be directly evident how to generalize our results . however , our findings show strong statistical evidence that collaboration metrics affect data sharing performance in interesting ways .",
    "our proposed algorithms and methodology can serve as the basis for further experiments that explore the concept of privacy - enhanced sharing of security - relevant data .",
    "also , as in previous work  @xcite , we do not consider false positives but focus on measuring algorithm s tp rate .",
    "nonetheless , as discussed in section  [ subsec : predictive ] , this is reasonable as the _ prediction _ algorithm identifies suspicious ip addresses that deserve further scrutiny and that are subsequently processed by _ blacklisting _ algorithms , which actually block sources , even though false positives might increase the computational load and complexity of the blacklisting algorithm by providing larger inputs .",
    "finally , note that this paper does not aim to present a finished product , but to demonstrate the viability and effectiveness of privacy - enhancing technologies on collaborative threat mitigation .",
    "while the overhead introduced by our peer - to - peer approach is still non - negligible , it is significantly lower than existing alternatives such as fhe .",
    "also , a few improvements could be explored in future work to improve performance , including parallelization , centralization , and/or sampling .",
    "* public sector . * in 1998 ,",
    "president clinton initiated a national program on critical infrastructure protection  @xcite , which promoted collaboration between government and private sector , and created the financial sector information sharing and analysis center ( fs - isac ) . in 2003 , this was extended to virtual systems and it infrastructures with the homeland security presidential directive 7 ( hspd-7 ) , and recently reinforced  @xcite . in 2013 ,",
    "the us house of representatives passed the cyber intelligence sharing and protection act ( cispa ) , which met huge opposition as it granted broad immunity to data sharing entities , and took generous views on what data could be shared and with whom .",
    "the bill was not voted on by the senate and the debate is still ongoing with similar proposals  @xcite .",
    "standardization bodies also push collaborative frameworks and established appropriate data formats ( idmef , iodef rfc 5070  @xcite ) , collaboration protocols ( the real - time inter - network defense rfc 6545  @xcite ) , and guidelines ( iso 27010 , itu - t sg17 )",
    ".     * private sector . *",
    "the redsky alliance  @xcite helps security professionals share intelligence after a vetting process for trust establishment .",
    "another example is tf - csirt ( task force of computer security incident response teams )  @xcite , which improves coordination among european community emergency response teams ( certs ) . besides dshield  @xcite",
    ", other community - based initiatives focus on sharing and correlating security data .",
    "domino ( distributed overlay for monitoring internet outbreaks )  @xcite provides distributed intrusion detection promoting collaboration among nodes . in europe , the worldwide observatory of malicious behaviors and attack threats ( wombat ) gathers security related data in real - time .",
    "symantec also introduced a data sharing platform , wine .",
    "finally , the mitre corporation  @xcite developed file formats ( stix ) , collaboration protocols ( taxii ) , and repository formats ( capec , maec ) for structure threat information exchange .",
    "* barriers to adoption . * these initiatives",
    "have had little success , as pointed out by the federal communications commission s working group on communications security , reliability and interoperability council s ( csric )  @xcite .",
    "existing solutions rely on manual out - of - band channels to establish _",
    "trust_. for instance , the redsky alliance relies on a long and costly vetting process that requires manual labor to verify the trustworthiness of potential partners .",
    "furthermore , organizations need to reveal their datasets to a centralized third - party and rely on it to for security .",
    "thus , they have limited control over how their data is shared with other participants .",
    "these solutions have a turnover of a few days for redsky alliance , to a few weeks for isacs .",
    "feedback is significantly slower than the spread of malware .",
    "it is difficult for companies to quantify how much others are contributing , and the lack of transparency discourages contributions .",
    "most of previous works for collaborative predictive blacklisting  @xcite rely on central repositories and provide no privacy protection .",
    "katti et al .",
    "@xcite show that correlated attacks , i.e. , mounted by same sources against different victims , are prevalent on the internet .",
    "they cluster victims that share common attacks and find that : ( 1 ) correlations among victims are persistent over time , and ( 2 ) collaboration among victims from correlated attacks improves malicious ip detection time .",
    "pouget at al .",
    "@xcite also obtain similar results using distributed honeypots for observation of malicious online activities .",
    "then , zhang et al .  @xcite experiment with predictive blacklisting , suggesting that victims can predict future attackers , with significantly improved accuracy , based on their logs and those of other similar victims .",
    "soldo et al .",
    "@xcite also aim to forecast attack sources based on shared attack logs , using an implicit recommendation system and improve on prediction accuracy as well as robustness against poisoning attacks .      as data sharing raises important confidentiality and privacy concerns ,",
    "the security community has suggested , in slightly different contexts , to use anonymization or cryptographic techniques to protect privacy .",
    "lincoln et al .",
    "@xcite suggest sharing sanitized security data for collaborative analysis of security threats . specifically , they remove , prior to sharing , sensitive data such as ip addresses .",
    "other mechanisms include prefix - preserving anonymization of ip addresses  @xcite and statistical obfuscation  @xcite . however , inference attacks can de - anonymize network traces  @xcite , and it is quite difficult to maintain data utility  @xcite .",
    "applebaum et al .",
    "@xcite introduce privacy - preserving data aggregation protocols geared for anomaly detection .",
    "their approach requires a semi - trusted proxy aggregator and only provides participants with aggregated counts of common data points across multiple entities .",
    "burkhart et al .",
    "@xcite explore a distributed solution , based on secure multi - party computation and secret sharing , that supports aggregation of security alerts and traffic measurements among peers , e.g. , to estimate global traffic volume .",
    "these protocols are secure as long as the majority of peers do not collude , assume a reliable infrastructure to distribute key shares , and incur a large number of rounds and high communication overhead .",
    "while aggregation can help compute traffic statistics , it mainly identifies most prolific attack sources and yields global models .",
    "however , as shown in  @xcite , generic attack models miss a significant number of attacks , especially when attack sources choose targets strategically and focus on a few known vulnerable networks . in theory ,",
    "fully homomorphic encryption ( fhe )  @xcite could be used to compute personalized recommendations , but fhe is still far from being practical and it is unclear whether complex prediction algorithms could effectively be run over encrypted data .",
    "this paper presented a novel privacy - friendly approach to collaborative threat mitigation .",
    "we showed how organizations can quantify expected benefits in a privacy - preserving way ( i.e. , without disclosing their datasets ) before deciding whether or not to collaborate .",
    "based on these benefits , they can then organize into coalitions and decide what / how much to share .",
    "we focused on collaborative predictive blacklisting , evaluated our techniques on a real - world dataset , and observed a significant improvement in prediction accuracy ( up to 105% , even when only 1% of all possible partners collaborate ) .",
    "our analysis showed that some collaboration strategies work better than others .",
    "the number of common attacks provides a good estimation of the benefits of sharing , as it drives entities to partner with more knowledgable collaborators .",
    "interestingly enough , only sharing information about common attacks proves to be almost as useful as sharing everything .",
    "this suggests that victims benefit as much from improving their knowledge about entities that currently attack them , as from learning about entities that do not attack them now , but might in the future .",
    "we demonstrated the benefits of privacy - preserving information sharing on collaborative threat mitigation and established that data sharing does not have to be an `` all - or - nothing '' process : by relying on efficient secure computation , it is possible to only share relevant data , and only when beneficial . privately assessing whether or not , and how , entities should partner up prompts interesting challenges , which our work is really the first to tackle . as part of future work , we intend to study other metrics for partner selection ( e.g. , dissimilarity ) and experiment with other prediction algorithms and incentive mechanisms .",
    "we will also explore how to adapt our approach to other collaborative security problems , e.g. , spam filtering  @xcite , virus detection  @xcite , or ddos mitigation  @xcite .",
    "[ app : dshield ]",
    "in this appendix , we provide further details about the dshield dataset .      we start by presenting , in fig .  [",
    "fig : general : subfig1 ] , the histogram of the number of attacks per day , indicating about @xmath70 m daily attacks .",
    "we observe a significant increase around day @xmath79 to @xmath59 m attacks .",
    "careful analysis reveals that a series of ip addresses start to attack more aggressively around day @xmath79 , indicating what might be the beginning of a dos attack .",
    "[ fig : general : subfig3 ] then shows the number of unique targets and sources over time .",
    "a detailed analysis shows a relatively stable number of sources and targets .",
    "this stability in number of attackers confirms that it should be possible to predict attackers tactics based on past observations .",
    "an analysis of attacked ports shows that top 10 attacked ports ( with more than 10 m hits ) are telnet , http , ssh , dns , ftp , bgp , active directory , and netbios ports .",
    "this shows a clear trend towards misuse of popular web services .",
    "[ fig : entropy ] shows the cdf of the shannon entropy of the different log entry elements .",
    "it helps us visualize the uncertainty about a given ip address , port number or target appearing in the logs , and thus estimate our ability to predict those values . to obtain this figure , we estimate the probability of each victim , source or port being attacked each day .",
    "for example , for each port @xmath114 , we compute : @xmath115    we also compute the entropy for each day and aggregate it overall using the cdf .",
    "previous work  @xcite showed that , following fano s inequality , entropy correlates with predictability .",
    "we observe that ports numbers have the lower entropy distribution , indicating a small set of targeted ports : @xmath64 of attacks target a set of @xmath116 ports , indicating high predictability .",
    "we also observe that victims are more predictable than sources , as @xmath69 of victims lie within a set of @xmath117 victims as compared to @xmath69 of sources being in a list of @xmath118 sources .",
    "victims set is thus significantly smaller and more predictable than attackers set .",
    "[ fig : interarrival : subfig1 ] shows the inter - arrival time of attacks in hours , and fig .",
    "[ fig : interarrival : subfig2 ] shows the inter - arrival time of attacks in seconds .",
    "we observe that almost all attacks occur within 3-minute windows .",
    "ip addresses and @xmath119 subnetworks have similar behavior .",
    "in particular , fig .",
    "[ fig : interarrival : subfig2 ] shows that in short time intervals , @xmath120 of @xmath121 subnetworks have short attack inter - arrival time indicating the bursty attacks on such networks .",
    "attackers target subnetworks for short time and then disappear ."
  ],
  "abstract_text": [
    "<S> sharing of security data across organizational boundaries has often been advocated as a promising way to enhance cyber threat mitigation . </S>",
    "<S> however , collaborative security faces a number of important challenges , including privacy , trust , and liability concerns with the potential disclosure of sensitive data . in this paper , we focus on data sharing for predictive blacklisting , i.e. , forecasting attack sources based on past attack information . </S>",
    "<S> we propose a novel privacy - enhanced data sharing approach in which organizations estimate collaboration benefits without disclosing their datasets , organize into coalitions of allied organizations , and securely share data within these coalitions . </S>",
    "<S> we study how different partner selection strategies affect prediction accuracy by experimenting on a real - world dataset of 2 billion ip addresses and observe up to a 105% prediction improvement . </S>"
  ]
}