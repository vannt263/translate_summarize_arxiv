{
  "article_text": [
    "in 1762 joseph louis lagrange formulated what is now known as the eigenvalue - eigenvector problem , which turns out to be of significant importance in the understanding several phenomena in applied mathematics as well as in optimization theory . the spectral theory for matrices",
    "is widely used in many scientific and engineering domains .    in many scientific domains ,",
    "data are presented in the form of tuples or groups , which naturally give rise to tensors .",
    "therefore , the generalization of the eigenvalue - eigenvector problem for tensors is a fundamental question with broad potential applications .",
    "many researchers suggested different forms of tensor decompositions to generalize the concepts of eigenvalue - eigenvector and singular value decomposition .    in this paper",
    "we propose a mathematical framework for high - order tensors algebra based on a high - order product operator .",
    "this algebra allows us to generalize familiar notions and operations from linear algebra including dot product , matrix adjoints , hermicity , permutation matrices , and most importantly the notion of orthogonality .",
    "our principal result is to establish a rigorous formulation of tensor spectral decomposition through the general spectral theorem .",
    "we prove the spectral theorem for hermitian finite order tensors with norm different from @xmath0 .",
    "finally we point out that one of the fundamental consequence of the spectral theorem is the existence of a spectral hierarchy which determines a given hermitian tensor of finite order .",
    "there are certain properties that a general spectral theory is expected to satisfy .",
    "the most fundamental property one should expect from a general formulation of the spectral theorem for tensors is a factorization of a cubic tensor into a certain number of cubic tensors of the same dimensions .",
    "our proposed factorization decomposes a hermitian tensor into a product of orthogonal and scaling tensors .",
    "our proposed factorization also extends to handle non - hermitian tensors .",
    "furthermore our proposed factorization offers an expansion of a tensor as a summation of lower order tensors that are obtained through outer products .",
    "our proposed factorization makes an explicit connection between the eigen - objects and the reduced set of characteristic polynomials .",
    "the proposed framework describes the spectral hierarchy associated with a tensor .",
    "finally the framework aims to extend linear algebraic problems found in many domains to higher degree algebraic formulations of corresponding problems .",
    "the organization of this paper is as follows ; section [ 2 ] reviews the state of the art in tensor decomposition and its relation to the proposed formulation .",
    "section [ 3 ] introduces our proposed tensor algebra for order three tensors .",
    "section [ 4 ] introduces and proves our proposed spectral theorem for order three tensors .",
    "section [ 5 ] discusses some important properties following from the proposed spectral decomposition . section [ 6 ] proposes a computational framework for describing the characteristic polynomials of a tensor .",
    "section [ 7 ] generalizes the introduced concepts to higher order tensors and introduces the notion of the spectral hierarchy .",
    "section [ 8 ] discusses in details the relation between the proposed framework and some existing tensor decomposition frameworks .",
    "section [ 9 ] concludes the paper with a discussion on the open directions .",
    "in this section we recall the commonly used notation by the multilinear algebra community where a @xmath1-tensor denotes a multi - way array with @xmath1 indices @xcite . therefore , a vector is a @xmath0-tensor and a matrix is a @xmath2-tensor .",
    "a @xmath3-tensor @xmath4 of dimensions @xmath5 denotes a rectangular cuboid array of numbers .",
    "the array consists of @xmath6 rows , @xmath7 columns , and @xmath8 depths with the entry @xmath9 occupying the position where the @xmath10 row , the @xmath11 column , and the @xmath12depth meet . for many purposes it will suffice to write    @xmath13",
    "we now introduce generalizations of complex conjugate and inner product operators .",
    "+ the _ order @xmath8 conjugates _ of a scalar complex number @xmath14 are defined by : @xmath15 where @xmath16 and @xmath17 respectively refer to the imaginary and real part of the complex number @xmath14 , equivalently rewritten as @xmath18 from which it follows that @xmath19 the particular _ inner product _ operator that we introduce relates the inner product of a @xmath8-tuple of vectors in @xmath20 to a particular @xmath21 norm operator @xmath20 in a way quite similar to the way the inner product of pairs of vectors relate to the usual @xmath22 vector norm .",
    "we refer to the norm operator @xmath23 ( for every integer @xmath24 ) as the @xmath21 norm defined for an arbitrary vector @xmath25 by @xmath26^{\\frac{1}{p}},\\ ] ] the inner product operator for a @xmath8-tuple of vectors in @xmath20 denoted @xmath27 is defined by    @xmath28    some of the usual properties of inner products follow from the definition    @xmath29    and most importantly the fact that @xmath30 and @xmath31 we point out that the definitions of inner products is extended naturally to tensors as illustrated bellow    @xmath32    @xmath33    more generally for arbitrarly finite order tensor the inner product for the family of tensors @xmath34 is defined by :    @xmath35    note that the addition in the indices are performed modulo @xmath7 .",
    "+ generalization of other concepts arising from linear algebra have been investigated quite extensively in the literature .",
    "cayley in @xcite instigated investigations on hyperdeterminants as a generalization of determinants .",
    "gelfand , kapranov and zelevinsky followed up on cayley s work on the subject of hyperdeterminants by relating hyperdeterminants to @xmath36-discriminants in their book @xcite .",
    "+ a recent approach for generalizing the concept of eigenvalue and eigenvector has been proposed by liqun qi in @xcite and followed up on by lek - heng lim@xcite , cartwright and sturmfels @xcite . the starting point for their approach",
    "will be briefly summarized using the notation introduced in the book @xcite . assuming a choice of a coordinate system @xmath37 associated with each one of the vector space @xmath38 .",
    "we consider a multilinear function @xmath39 expressed by :    @xmath40    equivalently the expression above can be rewritten as    @xmath41    which of course is a natural generalization of bilinear forms associated with a matrix representation of a linear map for some choice of coordinate system    @xmath42    it follows from the definition of the multilinear function @xmath43 that the function induces @xmath44 not necessarily distinct multilinear projective maps denoted by @xmath45 expressed as :    @xmath46    the various formulations of eigenvalue eigenvector problems as proposed and studied in @xcite arise from investigating solutions to equations of the form :    @xmath47    applying symmetry arguments to the tensor @xmath4 greatly reduces the number of map @xmath48 induced by @xmath4 .",
    "for instance if @xmath4 is supersymmetric ( that is @xmath4 is invariant under any permutation of it s indices ) then @xmath4 induces a single map . furthermore , different constraints on the solution eigenvectors @xmath49 distinguishes the @xmath50-eigenvectors from the @xmath51-eigenvectors and the @xmath52-eigenvectors as introduced and discussed in @xcite .",
    "our treatment considerably differs from the approaches described above in the fact that our aim is to find a decomposition for a given tensor @xmath4 that provides a natural generalization for the concepts of hermitian and orthogonal matrices .",
    "furthermore our approach is not limited to supersymmetric tensors .",
    "in connection with our investigations in the current work , we point out another concepts from linear algebra for which the generalization to tensor plays a significant role in complexity theory , that is the notion of matrix rank .",
    "indeed one may also find an extensive discussions on the topic of tensor rank in @xcite .",
    "the tensor rank problem is perhaps best described by the following optimization problem . given an @xmath44-tensor @xmath53 we seek to solve the following problem which attempts to find an approximation of @xmath4 as a linear combination of rank one tensors .",
    "@xmath54    our proposed tensor decomposition into lower order tensors relates to the tensor rank problem but differs in the fact that the lower order tensors arising from the spectral decomposition of @xmath3-tensors , named eigen - matrices are not necessarily rank @xmath0 matrices .",
    "several approaches have been introduced for decomposing @xmath1-tensors for @xmath55 in a way inspired by matrix svd .",
    "svd decomposes a matrix @xmath4 into @xmath56 and can be viewed as a decomposition of the matrix @xmath4 into a summation of rank-1 matrices that can be written as @xmath57 where @xmath44 is the rank of @xmath4 , @xmath58 are the @xmath59-th columns of the orthogonal matrices @xmath60 and @xmath61 , and @xmath62 s are the diagonal elements of @xmath63 , i.e. , the singular values . here",
    "@xmath64 denotes the outer product . the canonical and parallel factor decomposition ( canecomp - parafac , also caller the cp model ) , independently introduced by @xcite , generalize the svd by factorizing a tensor into a linear combination of rank-1 tensors .",
    "that is given @xmath65 , the goal is to find matrices @xmath66 , @xmath67 and @xmath68 such that @xmath69 where the expansion is in terms of the outer product of vectors @xmath70 are the i - th columns of @xmath60 , @xmath61 , and @xmath71 , which yields rank-1 tensors . the rank of @xmath4 is defined as the minimum @xmath44 required for such an expansion .",
    "here there are no assumption about the orthogonality of the column vectors of @xmath60 , @xmath61 , and @xmath71 .",
    "the cp decomposition have been show to be useful in several applications where such orthogonality is not required .",
    "there are no known closed - form solution to determine the rank @xmath44 , or to find a lower rank approximation as given directly by matrix svd .",
    "tucker decomposition , introduced in@xcite , generalizes over eq [ eq : rank1decomp ] , where an @xmath72 tensor @xmath4 is decomposed into rank-1 tensor expansion in the form @xmath73 where @xmath74 , @xmath75 , and @xmath76 .",
    "the coefficients @xmath77 form a tensor that is called the core tensor @xmath78 .",
    "it can be easily seen that if such core tensor is diagonal , i.e. , @xmath79 unless @xmath80 , tucker decomposition reduces to the cp decomposition in eq [ eq : rank1decomp ] .",
    "orthogonality is not assumed in tucker decomposition .",
    "orthogonality constraints can be added by requiring @xmath81 to be columns of orthogonal matrices @xmath60,@xmath61 , and @xmath71 .",
    "such decomposition was introduced in@xcite and was denoted by high order singular value decomposition ( hosvd ) .",
    "tucker decomposition can be written using the mode-@xmath7 tensor - matrix multiplication defined in @xcite as @xmath82 where @xmath83 is the mode-@xmath7 tensor - matrix multiplication .",
    "similar to tucker decomposition , the core tensor of hosvd is a dense tensor .",
    "however , such a core tensor satisfies an _ all - orthogonality _ property between its slices across different dimensions as defined in @xcite .",
    "hosvd of a tensor can be computed by flattening the tensor into matrices across different dimensions and using svd on each matrix .",
    "truncated version of the expansion yields a lower rank approximation of a tensor @xcite .",
    "several approaches have been introduced for obtaining lower rank approximation by solving a least square problem , _",
    "e.g. _ @xcite .",
    "recently an extension to tucker decomposition with non - negativity constraint was introduced with many successful applications @xcite .",
    "all the above mentioned decompositions factorizes a high order tensor as a summation of rank-1 tensors of the same dimension , which is inspired by such an interpretation of matrix svd as in eq [ eq : svd ] .",
    "however , none of these decomposition approaches can describe a tensor as a product of tensors as would be expected from an svd generalization .",
    "the only known approach to us for decomposing a tensor to a product of tensors was introduced in a technical report @xcite .",
    "this approach is based on the idea that a diagonalization of a circulant matrix can be obtained by discrete fourier transform ( dft ) .",
    "given a tensor , it is flattened then a block diagonal matrix is constructed by dft of the circulant matrix formed from the flattened tensor .",
    "matrix svd is then used on each of the diagonal blocks .",
    "the inverse process is then used to put back the resulting decompositions into tensors .",
    "this approach results in a decomposition in the form @xmath84 where the product is defined as @xcite @xmath85 however , such decomposition does not admit a representation of the decomposition into an expansion in terms of rank-1 tensors .",
    "the product is mainly defined by folding and unfolding the tensor into matrices .    from the above discussion we can highlight some fundamental limitations of the known tensor decomposition frameworks .",
    "existing tensor decomposition frameworks are mainly expansions of a tensor as a linear combination of rank-1 tensors , which are the outer products of vectors under certain constraints ( orthogonality , etc . ) and do not provide a factorization into product of tensors of the same dimensions .",
    "tucker decomposition , although a generalization of svd , falls short of generalizing the notion of the spectrum for high - order tensors .",
    "there is no connection between the singular values and the spectrum of the corresponding cubic hermitian tensors .",
    "unfortunately , no such relation is proposed by the tucker factorization .",
    "the tucker decomposition does not suggest at all how to generalize such objects as the trace and the determinant of higher order tensors . in the appendix of this paper",
    "we show that tucker decomposition and hosvd uses notion of matrix orthogonality .",
    "the most widely used formulation for tensor decomposition is the orthogonal version of tucker decomposition ( hosvd ) @xcite .",
    "hosvd is a multilinear rank revealing procedure @xcite and therefore , it has been widely used recently in many domains for dimensionality reduction and to estimate signal subspaces of tensorial data@xcite . in computer vision",
    ", hosvd has been used in@xcite for analysis of face images with different sources of variability , _",
    "e.g. _ different people , illumination , head poses , expressions , etc .",
    "it has been also used in texture analysis , compression , motion analysis @xcite , posture estimation , gait biometric analysis , facial expression analysis and synthesis , _ e.g. _",
    "@xcite , and other useful applications @xcite .",
    "hosvd decomposition gives a natural way for dealing with images as matrices @xcite .",
    "the relation between hosvd and independent component analysis ica was also demonstrated in @xcite with applications in communication , image processing , and others . beyond vision and image processing ,",
    "hosvd has also been used in data mining , web search , _",
    "@xcite , and in dna microarray analysis @xcite .",
    "we propose a formulation for a general spectral theory for tensors coined with consistent definitions from multilinear algebra . at the core of the formulation",
    "is our proposed _",
    "spectral theory for tensors _ . in this section ,",
    "the theory focuses on @xmath3-tensors algebra .",
    "we shall discuss in the subsequent section the formulations of our theory for @xmath7-tensor where @xmath7 is positive integer greater or equal to @xmath2 .",
    "a @xmath86 _ 3-tensor _ @xmath4 denotes a rectangular cuboid array of numbers having @xmath6 rows , @xmath7 columns , and @xmath8 depths .",
    "the entry @xmath9 occupies the position where the @xmath10 row , the @xmath11 column , and the @xmath12 depth meet . for",
    "many purposes it will suffice to write    @xmath87    we use the notation introduced above for matrices and vectors since they will be considered special cases of @xmath3-tensors . thereby , allowing us to indicate matrices and vectors respectively as oriented slice and fiber tensors .",
    "therefore , @xmath88 , @xmath89 , and @xmath90 tensors indicate vectors that are respectively oriented vertically , horizontally and along the depth direction furthermore they will be respectively denoted by @xmath91 , @xmath92 , @xmath93 .",
    "similarly @xmath94 , @xmath95 , and @xmath96 tensors indicate that the respective martrices of dimensions @xmath97 , @xmath98 and @xmath99 can be respectively thought of as a vertical , horizontal , or depth slice denoted respectively @xmath100 , @xmath101 , and @xmath102 .",
    "+   + there are other definitions quite analogous to their matrix ( @xmath2-tensors ) counterparts such as the definition of addition , kronecker binary product , and product of a tensor with a scalar , we shall skip such definitions here .",
    "+ _ ternary product of tensors : _ at the center of our proposed formulation is the definition of the ternary product operation for @xmath3-tensors .",
    "this definition , to the best of our knowledge has been first proposed by p. bhattacharya in @xcite as a generalization of matrix multiplication .",
    "let @xmath103 be a tensor of dimensions @xmath104 , @xmath105 a tensor of dimensions @xmath106 , and @xmath107 a tensor of dimensions @xmath108 ; the ternary product of @xmath4 , @xmath109 and @xmath78 results in a tensor @xmath110 of dimensions @xmath111 denoted    @xmath112    and the product is expressed by :    @xmath113        the specified dimensions of the tensors @xmath4 , @xmath109 and @xmath78 provide constraints for triplet of @xmath3-tensors that can be multiplied using the preceding product definition .",
    "the dimensions constraints are best illustrated by fig.[2 ] .",
    "there are several ways to generalize matrix product .",
    "we chose the previous definition because the entries of the resulting tensor @xmath114 relate to the general _ inner product _ operator as depicted by fig.[1 ] .",
    "therefore , the tensor product in eq [ eq : ternaryproduct ] expresses the entries of @xmath115 as inner products of the triplet of horizontal , depth , and vertical vectors of @xmath4 , @xmath109 and @xmath78 respectively as can be visualized in fig.[1 ] .",
    "we note that matrix product is a special instance of a tensor product and we shall discuss subsequently products of @xmath7-tensor where @xmath7 is positive integer greater or equal to @xmath2 . furthermore the proposed definition of the tensor multiplication suggests a generalization of the binary vector outer product operator to a ternary operator of slices .",
    "the ternary outer product is defined such that given tensors @xmath4 of dimensions @xmath116 , @xmath109 of dimensions @xmath117 , and @xmath78 of dimensions @xmath118 , their ternary outer product @xmath115 , noted @xmath119 , is an @xmath111 tensor defined by :    @xmath120    note that @xmath4 , @xmath121 and @xmath78 here are slices arising from oriented matrices .",
    "the above definition generalizes the binary vector outer product operation to a ternary matrix outer product operation defined by    @xmath122    similarly to matrix multiplication , where the operation of multiplying appropriate sized matrices can be viewed as a summation of outer product of vectors , the product of appropriate sized triplet of tensors in eq [ eq : ternaryproduct ] can be viewed as a summation of ternary outer product of slices    @xmath123    _ _ + _ ternary dot product with a background tensor : _ the ternary dot product above can be further generalized by introducing the notion of a background tensor as follows for @xmath124 , @xmath125 and @xmath126    @xmath127    the preceding will be referred to as the _ triplet dot product _ operator with _",
    "background tensor _ @xmath128 .",
    "background tensors plays a role analogous to that of the metric tensor .",
    "the triplet dot product with non trivial background tensor corresponds to a pure trilinear form .",
    "furthermore the outer product of @xmath2-tensors can be generalized using the notion of background tensors to produce a @xmath3-tensor @xmath115 which result from a product of three @xmath2-tensors namely @xmath129 , @xmath130 and @xmath131 as follows ,    @xmath132    the preceding product expression is the one most commonly used as a basis for tensor algebra in the literature as discussed in @xcite .",
    "+ we may note that the original definition of the dot product for a triplets of vectors corresponds to a setting where the background tensor is the kronecker delta @xmath133 that is @xmath134 where @xmath135 denotes hereafter the kronecker tensor and can be expressed in terms of the kronecker @xmath2-tensors as follows    @xmath136    equivalently @xmath133 can be expressed in terms of the canonical basis @xmath137 in @xmath138-dimensional euclidean space described by :    @xmath139     tensor . ]",
    "hence    @xmath140      in general it follows from the algebra described in the previous section for @xmath3-tensors that :    @xmath141    in some sense the preceding illustrates the fact that the product operator is non associative over the set of tensors .",
    "however tensor product is weakly distributive over tensor addition that is to say    @xmath142,\\,\\boldsymbol{c},\\,\\boldsymbol{d}\\right))=\\circ\\left(\\boldsymbol{a},\\boldsymbol{c},\\boldsymbol{d}\\right)+\\circ\\left(\\boldsymbol{b},\\boldsymbol{c},\\boldsymbol{d}\\right),\\ ] ]    however in general    @xmath143    _ _ + _ transpose of a tensor : _ given a tensor @xmath144 we define it s _ transpose _ @xmath145 and it s _ double transpose _ @xmath146as follows :    @xmath147    @xmath148    it immediately follows from the definition of the transpose that for any tensor @xmath4 , @xmath149 incidentally the transpose operator corresponds to a cyclic permutation of the indices of the entries of @xmath4 .",
    "therefore we can defined a inverse transpose @xmath150 , generally we have    @xmath151    furthermore , a tensor @xmath4 is said to be symmetrical if :    @xmath152    as a result for a given arbitrary @xmath3-tensor @xmath4 , the products @xmath153 , @xmath154 and @xmath155 all result in symmetric tensors .",
    "it also follows from the definitions of the transpose operation and the definition of ternary product operation that :    @xmath156^{t}=\\circ\\left(\\boldsymbol{b}^{t},\\boldsymbol{c}^{t},\\boldsymbol{a}^{t}\\right)\\ ] ]    and    @xmath156^{t^{2}}=\\left[\\circ\\left(\\boldsymbol{b}^{t},\\boldsymbol{c}^{t},\\boldsymbol{a}^{t}\\right)\\right]^{t}=\\circ\\left(\\boldsymbol{c}^{t^{2}},\\boldsymbol{a}^{t^{2}},\\boldsymbol{b}^{t^{2}}\\right).\\ ] ]     + _ adjoint operator : _ for @xmath157 we introduce the analog of the _ adjoint _ operator for @xmath3-tensors in two steps .",
    "the first step consists in writing all the entries of @xmath4 in their complex polar form .",
    "@xmath158    the final step expresses the adjoint of the tensor @xmath4 noted @xmath159 as follows    @xmath160    the adjoint operator introduced here allows us to generalize the notion of hermitian matrices or self adjoint matrices to tensors .",
    "a tensor is hermitian if the following identity holds    @xmath161    incidentally the products @xmath162 , @xmath163 and @xmath164 result in self adjoint tensors or hermitian tensors .",
    "+ _ identity tensor : _ let @xmath165 denotes the tensor having all it s entries equal to one and of dimensions @xmath111 . recalling that @xmath133 denotes the kronecker 3-tensor , we define the _ identity tensors _",
    "@xmath166 to be :    @xmath167    @xmath168    furthermore we have :    @xmath169    @xmath170    @xmath171    @xmath172    for all positive integer @xmath173 .",
    "the identity tensor plays a role quite analogous to the role of the identity matrix since @xmath174 we have    @xmath175    * proposition 1 : * _ @xmath176 _ + we prove the preceding assertion in two steps , the first step consists of showing that the @xmath166 is indeed a solution to the equation    @xmath177    let @xmath178 be the result of the product    @xmath179",
    "@xmath180    @xmath181    we note that    @xmath182    hence    @xmath183    the last step consists in proving by contradiction that @xmath166 is the unique solution with positive entries to the equation    @xmath177    suppose there were some other solution @xmath184 with positive entry to the above equation , this would imply that    @xmath185    @xmath186    @xmath187\\ ] ]    since this expression must be true for any choice of the values of @xmath188 we deduce that it must be the case that    @xmath189    @xmath190    @xmath191    the requirement that    @xmath192    which results in the sought after contradiction @xmath193 .",
    ", @xmath194and @xmath195,title=\"fig : \" ] , @xmath194and @xmath195,title=\"fig:\"],@xmath194and @xmath195,title=\"fig : \" ]    _ inverse : _ by analogy to matrix inverse @xmath196 we recall that for a matrix @xmath4 , @xmath196 is its inverse if @xmath197 , for any non zero matrix @xmath198 .",
    "we introduce here the notion of inverse pairs for tensors .",
    "the ordered pair @xmath199 and @xmath200 are related by inverse relationship if for any non zero @xmath3-tensor @xmath198 with appropriated dimensions the following identity holds    @xmath201    _ _ + _ permutation tensors : _ incidentally one may also discuss the notion of _ permutation tensors _ associated with any element @xmath202 of the permutation group @xmath203 .",
    "@xmath204    @xmath205    the @xmath3-tensor @xmath206 perform the permutation @xmath202 on the depth slices of a @xmath3-tensor @xmath4 through the product @xmath207 , consequently the products @xmath208 and @xmath209 perform the same permutation respectively on the row slices and the column slices of @xmath4 .",
    "+   + * proposition 2 : * any permutation of the depth slices of @xmath4 can be obtained by finite sequence of product of transposition , and the sequence is of the form    @xmath210 the preceding is easily verified using the definition above and the permutation decomposition theorem @xcite . furthermore permutation tensors suggest a generalization of bi - stochastic matrices to bi - stochastic tensors through the birkhoff - von neumann bi - stochastic matrix theorem .      from linear algebra we know that permutation matrices belong to both the set of bi - stochastic matrices and to the set of orthogonal matrices .",
    "we described above a approach for defining bi - stochastic @xmath3-tensors , we shall address in this section the notion of orthogonality for @xmath3-tensors .",
    "we recall from linear algebra that a matrix @xmath211 is said to be orthogonal if    @xmath212    when we consider the corresponding equation for 3-tensors two distinct interpretations arise . the first interpretation related to orthonormal basis induced by the row or column vectors of the orthogonal matrix @xmath211 that is :    @xmath213    the corresponding equation for a @xmath3-tensor @xmath214 of dimensions @xmath215",
    "is given by :    @xmath216    or explicitly we can write :    @xmath217    the second interpretation arises from the kronecker invariance equation expressed by :    @xmath218    the corresponding kronecker invariance equation for @xmath3-tensor is given by :    @xmath219    @xmath220^{\\dagger}=\\left[\\circ\\left(\\circ\\left(\\boldsymbol{q},\\circ\\left(\\boldsymbol{q}^{\\dagger},\\boldsymbol{q}^{\\dagger^{2}},\\boldsymbol{\\delta}\\right),\\boldsymbol{q}^{\\dagger^{2}}\\right),\\boldsymbol{q},\\boldsymbol{q}^{\\dagger}\\right)\\right]^{\\dagger^{2}}.\\label{eq : kronecker invariance}\\ ] ]    while kronecker invariance properly expresses a generalization of the conjugation operation and the @xmath3-uniform hypergraph isomorphism equation it does not follow from the first interpretation of orthogonality , that is to say    @xmath221    we now discuss _ scaling tensors . _ the scaling _",
    "_ tensor play a role analogous to diagonal matrices in the fact that tensor multiplication with scalling tensor results in a tensor whose vectors are scalled .",
    "first we observe that the identity pairs of tensors should corespond to special scaling tensors .",
    "the general family of diagonal tensors are expressed by pairs of tensors @xmath222 , @xmath223 such that    @xmath224    @xmath225    the product @xmath114 yields    @xmath226    @xmath227    the expression above illustrates the fact that @xmath228 and @xmath229 scale the entry @xmath230 of the tensor @xmath4 , or equivalently one may view the expression above as describing the non - uniform scaling of the following vector @xmath231 .",
    "the vector scaling transform is expressed by    @xmath232    furthermore the scaling factors for a given vector may be viewed as coming from the same vector of the scaling matrix @xmath233 if the matrix @xmath71 is symmetric .",
    "finally we may emphasize the analogy with diagonal matrices , which satisfy the following equation independently of the value assigned to their non zero entries .",
    "for a given @xmath115 , we solve for @xmath78 such that    @xmath234    we recall from matrix algebra that :    @xmath235    and furthermore    @xmath236    @xmath237    by analogy we may define scaling tensors to be tensors satisfying the following equation independently of the value of the nonzero tensors .",
    "@xmath238    a possible solution is given by    @xmath239    @xmath240    @xmath241    this is easily verified by computing the product    @xmath242    @xmath243    @xmath244    @xmath245    fig[4 ] provides an example of diagonal tensors .",
    "it so happens that @xmath4 , @xmath109 , @xmath78 discussed above are related by transpose relation for third order tensors .",
    "this fact considerably simplifies the formulation of the to diagonality property common to both matrices and @xmath3-tensors . by analogy to matrices",
    "we say for @xmath3-tensors that a tensor @xmath246 is diagonal if independently of the value of the non zero entries of @xmath115 we have :    @xmath247 * proposition 3 : * if a 3-tensor @xmath115 can be expressed in terms of a symmetric matrix @xmath248 in the form @xmath249 then @xmath115 is diagonal . + the proof of the proposition follows from the fact that :    @xmath250    @xmath251    from which it follows that    @xmath252",
    "[ [ observations - from - the - eigen - valuevector - equations . ] ] observations from the eigen - value / vector equations .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we briefly review well established properties of matrices and their spectral decomposition , in order to emphasize how these properties carry over to spectral decomposition of tensors . from the definition of eigen - value / vector equation ,",
    "we know that for a square hermitian matrix @xmath4 , there must exist pairs of matrices @xmath211 , @xmath178 and pairs of diagonal matrices @xmath115 , @xmath253 such that    @xmath254    where the columns of @xmath255 corresponds to the left eigenvectors of @xmath4 , the rows of @xmath178 corresponds to the right eigenvectors of @xmath4 and the entries of the diagonal matrix @xmath256 correspond to eigenvalues of @xmath4 .",
    "@xmath257    let @xmath258 , i.e. , the entries of the matrix resulting from the outer product of the @xmath1-th left eigenvector with the @xmath1-th right eigenvector , incidentally the spectral decomposition yields the following expansion which is crucial to the principal component analysis scheme .",
    "@xmath259    the preceding amounts to assert that the spectral decomposition offers for every entry of the @xmath2-tensor @xmath4 a positional encoding in a basis formed by the eigenvalues of the matrix .",
    "assuming that the eigenvalues are sorted in decreasing order , the preceding expression suggest an approximation scheme for the entries of @xmath4 and , therefore , an approximation scheme for the @xmath2-tensor @xmath4 itself .",
    "[ [ definition ] ] definition + + + + + + + + + +    the spectrum of an @xmath7-tensor corresponds to the collection of lower order tensors the entry of which are solutions to the characteristic system of equations .",
    "[ [ spectrum - of - hermitian - tensors ] ] spectrum of hermitian tensors + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the aim of this section is to rigorously characterize the spectrum of a symmetric tensor of dimensions @xmath260 .",
    "fig.[5 ] depicts the product and the slice that will subsequently also be referred to as eigen - matrices .",
    "we may state the _ spectral theorem _ as follows + * theorem 1 : * _ ( spectral theorem for @xmath3-tensors ) : _ for an arbitrary hermitian non zero @xmath3-tensor @xmath4 with @xmath261 there exist a factorization of the form :    @xmath262^{\\dagger^{2}},\\left[\\circ\\left(\\boldsymbol{s},\\boldsymbol{f},\\boldsymbol{f}^{t}\\right)\\right]^{\\dagger}\\right)\\\\ \\boldsymbol{\\delta } & = & \\circ\\left(\\boldsymbol{q},\\:\\boldsymbol{r}^{\\dagger^{2}},\\:\\boldsymbol{s}^{\\dagger}\\right ) \\end{array}\\end{cases}\\label{eq:3tensor_factorization}\\ ] ]    where @xmath115 , @xmath253 , @xmath263 denote scaling tensors . for convenience",
    "we introduce the following notation for scaled tensors    @xmath264    and simply expresses the tensor decomposition of @xmath4 as :    @xmath265      in what follows the polynomial ideal generated by the set of polynomials @xmath266 is noted @xmath267 .",
    "we first emphasize the similarity between the spectral theorem for tensors and matrices , by providing an alternative proof of a weaker form of the spectral theorem for hermitian matrices with forbenius norm different from @xmath0 .",
    "finally we extend the proof technic to @xmath3-tensors and subsequently to @xmath7-tensors .",
    "our aim is to prove that the spectral decomposition exists for an arbitrary matrix @xmath4 with forbenius norm different @xmath0 . for this",
    "we consider the ideals induced by the characteristic system of equations for matrices .",
    "the spectral decomposition of @xmath4 refers to the decomposition :    @xmath268    the spectral decomposition equation above provides us with polynomial system of equations in the form    @xmath269    conveniently rewritten as    @xmath270    the ideal being considered is :    @xmath271.\\ ] ]    where the variables are the entries of the pairs of matrices @xmath211 , @xmath178 and @xmath272 * weak spectral theorem * _ _ ( for @xmath2-tensors ) _ _ * * : * * for an arbitrary non zero hermitian @xmath2-tensor @xmath4 with @xmath273 the spectral system of polynomial equations : @xmath274 admits a solution .",
    "we prove this theorem by exhibiting a polynomial @xmath275 which does not belong to the following ideal @xmath276 consider the polynomial @xmath277 we claim that @xmath278 since @xmath279 which contradicts to the assumption that @xmath280 .",
    "hence we conclude that @xmath281 which completes the proof .",
    "@xmath193 + in the proof above hermicity played a crucial role in that it ensures that the eigenvalues are not all zeros since for non zero hermitian @xmath2-tensor @xmath4 @xmath282      we procede to derive the existence of spectral decomposition for @xmath3-tensors using the proof thechnic discussed above    @xmath262^{\\dagger^{2}},\\left[\\circ\\left(\\boldsymbol{s},\\boldsymbol{f},\\boldsymbol{f}^{t}\\right)\\right]^{\\dagger}\\right)\\\\ \\boldsymbol{\\delta } & = & \\circ\\left(\\boldsymbol{q},\\:\\boldsymbol{r}^{\\dagger^{2}},\\:\\boldsymbol{s}^{\\dagger}\\right ) \\end{array}\\end{cases}\\ ] ]    equivalently written as @xmath283 the variables in the polynomial system of equations are the entries of the @xmath3-tensor @xmath211 , @xmath178 , @xmath284 and the entries of the scaling tensors @xmath115 , @xmath253 , @xmath263 . + it is somewhat insightfull to express the system of equations in a similar form to that of matrix spectral system of equations using inner product moperators : @xmath285 where @xmath286 is a diagonal matrix whose entries are specified by @xmath287 the characteristic system of equations yields the ideal @xmath288 defined by    @xmath289    where @xmath290 . which corresponds to a subset of the polynomial ring over the indicated set of variables .",
    "the following theorem is equivalent to theorem 1 . +",
    "* theorem : * _ ( for @xmath3-tensors ) _ if @xmath4 is a non zero hermitian and @xmath261 then the spectral system of equations expressed as @xmath285 admits a solution .      similarly to the @xmath2-tensor case , we exhibit a polynomial @xmath8 which does not belong to the ideal @xmath288 defined bellow .",
    "@xmath291 such a polynomial @xmath8 is expressed by @xmath292 @xmath293 since @xmath294 which contradicts our assumption that @xmath261 , this completes the proof .",
    "@xmath193 + hermiticity also ensure that the solution to the spectral decomposition is not the trivial all zero solution since for non zero @xmath3-tensor @xmath4 @xmath295",
    "similarly to the formulation for the spectral theorem for matrices , we can also discuss the notion of eigen - objects for tensors . in order to point out the analogy",
    "let us consider the matrix decomposition equations in eq [ eq : matrix_decomp1 ] and eq [ eq : matrix_decomp2 ] , one is therefore led to consider the matrices @xmath296 as the scaled matrix of eigenvectors . according to our proposed decomposition",
    ", the corresponding equations for @xmath3-tensors is given by    @xmath297    recall that the tensor @xmath298 collects as slices what we refer to as the _ scaled eigen - matrices_. the analogy with eigenvectors is based on the following outerproduct expansion .",
    "@xmath299    the equation emphasizes the fact that a hermitian matrices can be viewed as a sum of exterior products of scaled eigenvectors and the scaling factor associated to the rank one matrix resulting from the outerproduct corresponds to the eigenvalue .",
    "similarly , a symmetric @xmath3-tensor may also be viewed as a sum outer products of slices or matrices and therefore we refer to the corresponding slices as scaled _ eigen - matrices_. the outerproduct sum follows from the identity    @xmath300    expressed as :    @xmath301    which can be equivalently written as @xmath302    @xmath303    where @xmath304 denote the @xmath1-th component expressed    @xmath305    _ we may summarize by simply saying that : as one had eigenvalues and eigenvectors for matrices one has eigenvectors and eigen - matrices for @xmath3-tensors . _",
    "we shall first provide an algorithmic description of the characteristic polynomial of matrix without assuming the definition of the determinant of matrices and furthermore show how the description allows us to define characteristic polynomials for tensors .",
    "we recall for a matrix that the characteristic system of equations is determined by the algebraic system of equations @xmath306 as discussed above induces the following polynomial ideal    @xmath307.\\ ] ]    let @xmath308 be the reduced gr@xmath309bner basis of @xmath288 using the ordering on the monomials induced by the following lexicographic ordering of the variables .",
    "@xmath310 in the case of matrices it has been established that there is a polynomial relationship between the eigenvalues ; more specifically the eigenvalues are roots to the algebraic equation    @xmath311    by the elimination theorem @xcite we may computationaly derive the characteristic polynomials as follows    @xmath312=\\det\\left(\\boldsymbol{a}-\\lambda_{l}\\boldsymbol{i}\\right)\\ ] ]    it therefore follows from this observation that the reduced gr@xmath309bner basis of @xmath288 determines the characteristic polynomial of @xmath4 .",
    "let @xmath308 denote the reduced gr@xmath309bner basis of the ideal @xmath288 using the the lexicographic order on the monimials induced by the following lexicographic order of the variables .",
    "@xmath313 where @xmath314 the reduced characteristic set of polynomials @xmath315 associated with the hermitian @xmath3-tensor @xmath4 is a subset of the reduced groebner basis @xmath308 such that    @xmath316\\ ] ]    where @xmath317 $ ] denotes the polynomial ring in the entries of the sacaling tensor with complex coefficients . the reduced should here be thougth of as generalization of the characteristic polynomial associated with matrices .",
    "an @xmath318 @xmath7-tensor @xmath4 is a set of elements of a field indexed by the set resulting from the cartesian product    @xmath319 the dimensions of @xmath4 is specified by @xmath318 where @xmath320 @xmath321 , @xmath322 specifies the dimensions of the tensor . we may also introduce a dimension operator defined by    @xmath323    finally",
    ", we shall simply use the notation convention @xmath324 for describing @xmath4 once the dimensions have been specified .",
    "+ in what follows we will discuss general tensor products for @xmath7-tensors where @xmath7 is a positive integer greater or equal to 2 .",
    "let us start by recalling the definition of matrix multiplication    @xmath325    the preceding matrix product generalizes to the proposed @xmath3-tensor product as follows    @xmath326    by closely inspecting the expression of the product we note that if * @xmath327 * is a @xmath328 tensor , and @xmath329 is a @xmath330 tensor then the resulting tensor @xmath109 expressed by    @xmath331    will be of dimensions @xmath94 . the product above expresses the action of @xmath3-tensor @xmath332 of dimension @xmath333 on the pair of matrices arising from @xmath327 and @xmath329 .",
    "furthermore for @xmath332 having entries such that    @xmath334    the result of the action of @xmath332 on the pair of matrices arising from the tensors@xmath327 and @xmath329 simply corresponds to a matrix multiplication . for @xmath335-tensor the product operator is expressed as :    @xmath336    similarly the tensor @xmath329 can be chosen to be all - one tensor which reduces the product above to the product operation for @xmath3-tensors .",
    "this nested relationship will also apply to higher order tensors .",
    "+ we may now write the expression for the product of @xmath7-tensor . let @xmath34 denotes a set of @xmath7-tensors .",
    "the product operator has therefore @xmath7 operands and is noted :    @xmath337    defined by    @xmath338    @xmath339    it follows from the definition that the dimensions of the tensors in the set @xmath34must be chosen so that :    @xmath340    which describes the constraints on the dimension relating all the @xmath7 tensors in the product . the constraints accross the @xmath341 other dimensions for each tensor are described by the following relation .",
    "@xmath342    the tensor @xmath109 resulting from the product is a @xmath7-tensor of dimensions .",
    "@xmath343    _ note that the product of tensors of lower order all arise as special cases of the general product formula describe above .",
    "_    _ tensor action : _ + the action of @xmath344 order tensor @xmath324 on @xmath345-tuple of order @xmath345 tensors @xmath346is defined as    @xmath347    the equation above generalizes the notion of matrices action on a vector",
    ".    _ tensor outerproduct : _ the outer - product of @xmath7-tuple @xmath345-tensors is denoted by :    @xmath348    and defined such that :    @xmath349    the kronecker @xmath7-tensor is defined as    @xmath350    _ order @xmath7 tensor transpose / adjoint : _ + given a tensor @xmath351 the transpose @xmath145 is defined such that    @xmath352    for a complex valued tensor where the entries are expressed in their polar form as follows :    @xmath353    the generalized adjoint is given by    @xmath354    @xmath355    where @xmath356 denotes the composition of @xmath1 cyclic permutation of the indices from which it follows that    @xmath357      in order to formulate the spectral theorem for @xmath358 we will briefly discussed notion of orthogonal and scaling @xmath7-tensors , which can be expressed as    @xmath359    that is    @xmath360    where @xmath361 denotes the transpose operation , which still corresponds to a cyclic permutation of the indices .",
    "we first provide the formula for the scaling tensor whose product with @xmath4 leaves the tensor unchanged .",
    "@xmath362    @xmath363    @xmath364    the above family of tensors play the role of identity operator and are related to one another by transposition of the indices .",
    "the more general expression for the scaling tensors is therefore given by    @xmath365    where @xmath233 is a symmetric matrix .",
    "the expression for the scaled orthogonal tensor is therefore expressed by    @xmath366    we therefore obtain that the scaled tensor which will be of the form :    @xmath367    * theorem 2 : * _ ( spectral theorem for @xmath7-tensors ) : _ for any non zero hermitian tensor @xmath358 such that @xmath368 , there exist a factorization in the form    @xmath369    the expression above generalizes eq [ eq : tensor factorization scaled ]      the spectral decompostion yields the following system of equations    @xmath369    more insightfully rewritten as    @xmath370    where @xmath371 is a diagonal matrix whose entries are specified by @xmath372 we had already pointed out earlier in the proof for the spectral theorem for @xmath3-tensors that the proof technique would apply to @xmath7-tensors with norm @xmath373 , where @xmath7 is a positive integer greater or equal to @xmath2 .",
    "similarly we consider the polynomial expression @xmath374",
    "@xmath375    @xmath376    and observe that @xmath293 where @xmath288 defines the ideal iduced by the spectral system of equation since @xmath377 which contradicts our assumption that @xmath368 , hence we conclude that @xmath378 this completes the proof . @xmath193 + the @xmath138 `` slices '' of the scaled tensor @xmath379 constitutes what we call the _ scaled eigen - tensors _ of @xmath4 which are @xmath345-tensors .",
    "we recursively define the spectral hierarchy for a tensor @xmath358 .",
    "the base case for the recursion is the case of matrices .",
    "the spectrum of an @xmath380 matrix is characterized by a set of @xmath138 scaled eigen - vectors .",
    "the existence of the spectral hierarchy relies on the observation that the spectrum of an order @xmath7-tensor @xmath358 is determined by a collection of @xmath138-tuple @xmath345-tensors not necessarily distinct .",
    "each one of these @xmath138-tuples corresponding to a scaled orthogonal eigen - tensor . by recursively computing the spectrum of the resulting scaled orthogonal @xmath345-tensors",
    ", one determines a tree structure which completely characterizes the spectral hierarchy associated with the @xmath7-tensor @xmath4 .",
    "the leaves of the tree will be made of scaled eigenvectors when the spectral decomposition exists for all the resulting lower order tensors .",
    "it therefore follows that the tensor @xmath4 can be expressed as a nested sequence of sums of outer products .",
    "we illustrate the general principle with @xmath3-tensors .",
    "let @xmath4 denotes a third order tensor which admits a spectral decomposition in the form described by eq [ eq : outer product expansion ] .",
    "we recall that the spectral decomposition for @xmath3-tensors is expressed by    @xmath381    @xmath382    by computing the spectrum of the scaled eigen - matrices we have :    @xmath383    @xmath384    @xmath385    where @xmath386 , @xmath387,@xmath388,@xmath389 and @xmath390,@xmath391 denote the eigenvalues and corresponding eigenvectors respectively for the matrices @xmath392 , @xmath393 , @xmath394 .",
    "it therefore follows that @xmath4 can be expressed by the following nested sum of outer product expressions    @xmath395    @xmath396,\\right.\\ ] ]    @xmath397,\\left[\\sum_{1\\le j_{3}\\le l}\\left(\\sqrt{\\beta_{j_{3}}(k)}\\cdot\\vec{\\boldsymbol{y}}_{j_{3}}(k)\\right)\\otimes\\left(\\sqrt{\\beta_{j_{3}}(k)}\\cdot\\vec{\\boldsymbol{z}}_{j_{3}}(k)\\right)\\right]\\right)\\ ] ]",
    "we shall present in this section a brief overview of the relationship between our framework and earlier proposed tensor decompositions      let us show in this section how the tucker decomposition in fact uses matrix algebra more specifically orthogonality of matrices to express the singular value decomposition for @xmath3-tensors .",
    "we used for this section the notation and convention we introduced through this work .",
    "the tucker factorization scheme finds for an arbitrary @xmath3-tensor @xmath115 the following decomposition    @xmath398    where @xmath128 denotes a @xmath3-tensor and @xmath399 denote matrices .",
    "the product expression used for the decomposition written above corresponds to our proposed definition for triplet dot product with non trivial background as described in eq [ eq : matrices to tensor ] . using our notation we can express the decomposition of @xmath115 as follows :    @xmath400    our starting point is the following invariance relation , which arises from the matrix products with the identity matrix .    @xmath401    where @xmath402 , @xmath403 and @xmath404 which correspond to transposes of the identity matrix .",
    "for any orthogonal matrices @xmath211 , @xmath284 and @xmath60 we know that    @xmath405    incidentally the expression in eq [ eq : invariance tucker ] can be written as :    @xmath406    by interchanging the order of the sums we get :    @xmath407    we now separate out the products in the expressions to yield the general form of the tucker decomposition .",
    "@xmath408    @xmath409    the preceding emphasizes that the tucker decomposition reuses matrix orthogonality and does not provide a generalization of the notion of orthogonality for @xmath7-tensors . finally to determine the orthogonal matrices",
    "@xmath211 , @xmath284 and @xmath60 to use we specify the following constraints    @xmath410    @xmath411    @xmath412    which is referred to as the total orthogonality condition .",
    "the rank 1 decomposition of tensor @xcite corresponds to solving the following optimization problem .",
    "given an @xmath44-tensor @xmath53 we seek to find :    @xmath413    since johan h@xmath414stad in @xciteestablished the intractability of the tensor rank problem for @xmath3-tensors we briefly discuss the relationship to our framework .",
    "it follows from the definition of the outer product of matrices to form a @xmath3-tensor that    @xmath415    we point out that for the very special matrices essentially made up of the same vector as depicted bellow :    @xmath416    @xmath417    @xmath418    the outer product of the matrices    @xmath419    this allows us to formulate the tensor rank problem in eq [ eq : tensor rank ] in terms of the outer product operator for slices as follows    @xmath420    @xmath421    where @xmath422 are @xmath3-tensors arising from the collection of matrices associated with the collection of vectors .",
    "the preceding naturally related the tensor rank problem to our proposed tensor product .",
    "furthermore the generalized framework allows us to formulate the tensor rank problem for @xmath7-tensor where @xmath7 is a positive integer greater or equal to 2 as follows    @xmath423    one may point out that the spectral decomposition associated with a hermitian tensor comes quite close to the sought after decomposition at the cost of the trading of the requirement that the matrices should be rank one to the fact the matrices should arise from scaled eigen - tensors .",
    "in this paper we introduced a generalization of the spectral theory for @xmath7-tensors where @xmath7 is a positive integer greater or equal to @xmath2 . we propose a mathematical framework for @xmath3-tensors algebra based on a ternary product operator , which generalizes to @xmath7-tensors .",
    "this algebra allows us to generalize notions and operators we are familiar with from linear algebra including dot product , tensor adjoints , tensor hermicity , diagonal tensor , permutation tensors and characteristic polynomials .",
    "we proved the spectral theorem for tensors having forbenius norm different from @xmath0 .",
    "finally we discussed the spectral hierarchy which confirms the intractability of determining the orthogonal vector components whose exterior product result in a given @xmath7-tensor .",
    "starting from the recently proposed product formula in eq [ eq : ternaryproduct ] for order @xmath3-tensors proposed by p. bhattacharya in @xcite we were able to formulate a general algebra for finite order tensors .",
    "the order @xmath3-tensor product formula suggests a definition for outer product of matrices as discussed in eq [ eq : outer - product ] , it also suggests how to express the action of a tensor on lower order tensors .",
    "most importantly with eq [ eq : background - tensors ] we propose a natural generalization for the dot product operator and a generalization for the riemann metric tensor ideas .",
    "furthermore the tensor algebra that we discuss sketches possible approaches to investigate generalizations of inner product space theory",
    ".    one important characteristic of the product operator for tensor of order strictly greater than 2 is the fact that the product is not associative .",
    "incidentally by analogy to matrix theory where the lost of commutativity for matrix product results into a commutator theory and lie algeras which plays an important role in quantum mechanics , the lost of associativity as expressed in eq [ eq : non_associative ] could potentially give rise to an associator theory or generalizations of lie algebras .",
    "furthermore the transpose operator described in eq [ eq : transpose ] emphasizes the importance of the roots of unity in generalizing herminian and unitary tensors . the @xmath3-tensor permutation tensors provided a suprising representation for the permutation group @xmath203 which provide a glimpse at a tensor approach to a representation theory as well as a tensor approach to markov tensor models .    at the heart of our work",
    "lies the concept of orthogonal tensors .",
    "we emphasize the fact the orthogonal tensors discussed here are generalizations of orthogonal matrices and are significantly different from orthogonal matrices .",
    "one significant difference lie in the two distinct interpretation of the orthogonality property for tensor .",
    "the first interpretation expressed by eq [ eq : orthonormaility ] is analogous to orthonormal for a set of vectors .",
    "the second interpretation relates to the invariance of the kronecker delta tensor under conjugation as expressed in eq[eq : kronecker invariance ] .",
    "furthermore we have through this work provided a natural generalization for the familiar characteristic polynomial using the important tool set of grobner basis .",
    "spectral analysis plays an important role in the theory and investigations of graphs .",
    "graph spectra have proved to be a relatively useful graph invariant for determining isomorphism class of graphs .",
    "it seem of interest to note that the symmetries of a graph described by it s corresponding automorphism group can also be viewed as depicting a 3-uniform hypergraph which can in turn be investigated by through it spectral properties .",
    "determining the relationship between spectral properties of a graph and the spectral properties of it corresponding automorphism seems worthy of attention in the context of determining isomorphism classes of graphs . the general framework which address the algebra for arbitrarily finite order tensor allowed us to derive the spectral hierarchy .",
    "the spectral hierarchy induces a bottom up construction for finite order tensor from vectors .",
    "this explicit construction may in fact prove useful in the context investigations on tensor rank problems which also validate as illustrated in eq [ eq : tensor rank problem ] our product operator .",
    "we are grateful to emilie hogan , professor doron zeilberger and professor henry cohn for helpful discussion regarding properties of ideals .",
    "the first author was partially supported by the national science foundation grant nsf - dge-0549115 .",
    "a.  elgammal and c .- s .",
    "lee . separating style and content on a nonlinear manifold . in _ proceedings of the ieee computer society conference on computer vision and pattern recognition ( cvpr )",
    "_ , volume  1 , pages 478485 , 2004 .                m.e .",
    "kilmer , c.d .",
    "martin , and l.  perrone .",
    "a third - order generalization of the matrix svd as a product of third - order tensors .",
    "technical report technical report number tr-2008 - 4 , tufts university department of computer science , medford , ma , october 2008 .",
    "tamara  g. kolda , brett  w. bader , and joseph  p. kenny .",
    "higher - order web link analysis using multilinear algebra . in _",
    "icdm 05 : proceedings of the fifth ieee international conference on data mining _ , pages 242249 , washington , dc , usa , 2005 .",
    "ieee computer society .",
    "tamara  g. kolda and jimeng sun .",
    "scalable tensor decompositions for multi - aspect data mining . in _",
    "icdm 2008 : proceedings of the 8th ieee international conference on data mining _ , pages 363372 , december 2008 .",
    "chan - su lee and ahmed elgammal .",
    "facial expression analysis using nonlinear decomposable generative models . in _ proceedings of ieee workshop on on analysis and modeling of faces and gestures ( amfg ) _ , pages 1731 , 2005 .",
    "chan - su lee and ahmed  m. elgammal .",
    "towards scalable view - invariant gait recognition : multilinear analysis for gait . in _ proceedings of ieee conference on audio , video biometric people authentication ( avbpa ) _ , pages 395405 , 2005 .",
    "amnon shashua and tamir hazan .",
    "non - negative tensor factorization with applications to statistics and computer vision . in _ icml 05 : proceedings of the 22nd international conference on machine learning _ , pages 792799 , new york , ny , usa , 2005 .",
    "jian tao sun , hua - jun zeng , huan liu , and yuchang lu .",
    "cubesvd : a novel approach to personalized web search .",
    "in _ in proc . of the 14 th international world",
    "wide web conference ( www _ , pages 382390 . press , 2005 ."
  ],
  "abstract_text": [
    "<S> in this paper we propose a general spectral theory for tensors . </S>",
    "<S> our proposed factorization decomposes a tensor into a product of orthogonal and scaling tensors . at the same time , our factorization yields an expansion of a tensor as a summation of outer products of lower order tensors . </S>",
    "<S> our proposed factorization shows the relationship between the eigen - objects and the generalised characteristic polynomials . </S>",
    "<S> our framework is based on a consistent multilinear algebra which explains how to generalise the notion of matrix hermicity , matrix transpose , and most importantly the notion of orthogonality . </S>",
    "<S> our proposed factorization for a tensor in terms of lower order tensors can be recursively applied so as to naturally induces a spectral hierarchy for tensors . </S>"
  ]
}