{
  "article_text": [
    "in recent years , the field of topology has grown to include a large set of computational tools @xcite .",
    "one of the fundamental tools is persistent homology , which tracks how topological features appear and disappear in a nested sequence of topological spaces .",
    "this multiscale information can be represented as a _ persistence diagram _ ( pd ) , a collection of points in the plane where each point @xmath1 corresponds to a topological feature that appears at scale @xmath2 and disappears at scale @xmath3 .",
    "there has been considerable interest in applying these tools to the analysis of data , which has become an area of research in its own right , _ topological data analysis_. the presence of topological structures can be used to understand patterns within a data set or to compare different data sets .",
    "topological approaches to understanding data have been used in a variety of applications , including image webs , signal analysis , neuroscience , and biological aggregations @xcite .",
    "concurrent with this revolution in computational topology , a growing general interest in data analysis has driven advances in data mining , pattern recognition , and machine learning ( ml ) . since",
    "the space of pds can be equipped with a metric ( _ bottleneck _ or _ wasserstein _",
    "@xcite ) , it is possible to perform a variety of ml techniques using pds as a statistic for clustering data sets , etc .",
    "however , many other useful ml tools and techniques ( _ e.g. _ , support vector machines ( svm ) , decision tree classification , neural networks , feature selection , and dimension reduction methods ) require more than a metric structure . as a result , there has been much recent work , which we review in  [ sec : relatedwork ] , on representing pds in alternative formats which are suitable for other ml tools @xcite .    all of the ml techniques listed above can be applied when the input is a set of vectors .",
    "thus , we are led to pose the following question :    * problem statement : * how can we represent a persistence diagram as a vector in a way that is stable with respect to input noise ?    a vector representation of pds opens the door to alternative ways to measure distance between pds , such as @xmath4-norms ( _ e.g. _  taxicab , euclidean , infinity ) and angle based metrics .",
    "these measures are significantly less computationally expensive than the bottleneck distance where the computational cost grows quickly as the number of off - diagonal points in the diagrams increases @xcite .",
    "the main contribution of this paper is to provide a vector - based representation of a pd called a _ persistence image _ ( pi ) .",
    "we first map a persistence diagram @xmath5 to an integrable function @xmath6 called a _",
    "persistence surface_. the surface @xmath7 is defined as a weighted and [ thm : image - stable ] ) . ]",
    "sum of gaussian functions , one centered at each point in the pd . taking a discretization of a subdomain of @xmath7 defines a grid .",
    "an image , _",
    "i.e. _  a matrix of pixel values , can be created by computing the integral of @xmath7 on each grid box .",
    "this `` vectorization '' of a pd provides a solution to the problem statement above .",
    "the remainder of this article is organized as follows .",
    "related work connecting topological data analysis and ml is reviewed in  [ sec : relatedwork ] , and  [ sec : background ] gives a brief introduction to the persistent homology of point cloud data , including pds and the bottleneck and wasserstein metrics .",
    "pis are defined in ",
    "[ sec : persistenceimages ] and their stability with respect to the 1-wasserstein distance between pds is proved in  [ sec : stability ] .",
    "[ sec : experiments ] contains examples of ml techniques applied to pis generated from samples of common topological spaces and an applied dynamical system modeling turbulent mixing .",
    "the space of pds can be equipped with a bottleneck or wasserstein metric ( defined in  [ sec : background ] ) .",
    "one reason for the popularity of pds is that these metrics are stable with respect to small deviations in the inputs @xcite .",
    "furthermore , the bottleneck metric allows one to define frchet means and variances for a collection of pds @xcite . the structure of a metric space alone is insufficient for many ml techniques , and a recent area of interest in the topological data analysis community has been encoding pds in ways that broaden the applicability of persistence . for example in @xcite , bubenik develops the notion of a persistence landscape , a stable functional representation of a pd that lies in a banach space ; @xcite studies a ring of algebraic functions on the space of persistence barcodes ; and @xcite uses the coefficients of the complex polynomial that has the points of the pd as its roots .",
    "the work @xcite produces vectors from pds by rearranging entries of the distance matrix between points in a pd . their stability result ( * ? ? ? * theorem  3.2 ) for the @xmath8 norm between vectors is well - behaved , but their constant for the euclidean norm scales undesirably with the number of points in the pd .",
    "they remark that while the @xmath8 norm is useful for nearest - neighbor classifiers , the euclidean norm allows for more elaborate algorithms such as svm .",
    "we provide this as motivation for our theorem  [ thm : image - stable ] containing better - scaling stability results on ( differently constructed ) vectors with the euclidean norm .",
    "the authors of @xcite create a feature vector representation by superimposing a grid over the pd and counting the number of topological features in each bin .",
    "an advantage of this approach is that the output is easier to interpret than other more complicated representations , but a disadvantage is that the vectors are not stable for two reasons :    * \\(i ) an arbitrarily small movement of a point in a pd may move it to another bin , and * \\(ii ) a pd point emerging from the diagonal creates a discontinuous change .",
    "source ( i ) of instability can be improved by first smoothing a pd into a surface .",
    "this idea has appeared multiple times in various forms  even prior to the development of persistent homology , the papers @xcite convert size functions ( closely related to 0-dimensional pds ) into surfaces by taking a sum of gaussians centered on each point in the diagram .",
    "this conversion is not stable due to ( ii ) , and we view our work as a continued study of these surfaces , now also in higher homological dimensions , in which we introduce a weighting function to address ( ii ) and obtain stability . the work @xcite produces a surface by convolving a pd with the characteristic function of a disk , and @xcite produces a surface by centering a gaussian on each point , but both of these methods lack stability again due to ( ii ) .",
    "surfaces produced from random pds are related to the empirical intensity plots of @xcite .",
    "the paper @xcite produces a stable surface from a pd by taking the sum of a positive gaussian centered on each pd point together with a negative gaussian centered on its reflection below the diagonal ; the resulting surface is zero along the diagonal .",
    "this approach is similar to ours , and indeed we use ( * ? ? ?",
    "* theorem  3 ) to show that our persistence surfaces are stable only with respect to the 1-wasserstein distance .",
    "nevertheless , we propose our independently - developed surfaces as an alternative stable representation of pds with the following potential advantages .",
    "first , our sum of non - negatively weighted gaussians may be easier to interpret than a sum including negative gaussians .",
    "second , we produce vectors from our surfaces with well - behaved stability bounds , allowing one to use vector - based learning methods such as linear svm .",
    "third , while the surface of @xcite weights persistence points further from the diagonal more heavily , there are situations in which one may prefer different weightings . indeed , the authors of @xcite find that in their ml task of identifying a human brain s age from its geometry , it is the points of medium persistence ( not long persistence ) that best distinguish the data .",
    "hence , one may want weightings on pd points that are non - increasing with the distance from the diagonal , an option available in our approach .",
    "we produce a persistence surface from a pd by taking a weighted sum of gaussians centered at each point .",
    "we create vectors or pis by integrating our surfaces over a grid , allowing ml techniques for finite - dimensional vector spaces to be applied to pds .",
    "our pis are stable , and distinct homology dimensions may be concatenated together and analyzed simultaneously .",
    "our surfaces are studied from the statistical point of view in @xcite , which cites a preprint version of our work ; their applications in section 4 use the @xmath9 norm between these surfaces , which can be justified as a reasonable notion of distance due to our theorem  [ thm : surface - stable ] , proving that the @xmath9 distance between such surfaces is stable .",
    "given a topological space @xmath10 , homology is an invariant that characterizes topological properties of the space . roughly speaking",
    ", homology measures the number of connected components , loops , and trapped volumes ( of arbitrary integrer dimension ) which can be used to distinguish spaces from one another .",
    "the @xmath11-dimensional holes of a space @xmath10 generate a homology group , @xmath12 .",
    "the rank of this group is referred to as the _ @xmath11-th betti number _ , @xmath13 , and counts the number of @xmath11-dimensional holes . for a comprehensive study of homology ,",
    "see @xcite .",
    "given a nested sequence of topological spaces @xmath14 the inclusion @xmath15 for @xmath16 induces a linear map on the corresponding @xmath11-th homology @xmath17 for all @xmath18 .",
    "the idea of _ persistent homology _ is to track elements of @xmath19 as the scale parameter ( or `` time '' ) increases to a larger @xmath20 @xcite .",
    "a standard way to represent persistent homology information is as a _ persistence diagram _ ( pd ) , which is a multiset of points in the cartesian plane @xmath21 .",
    "each homological feature is represented by a point @xmath1 , whose _ birth _ and _ death _ indices @xmath2 and @xmath3 are the scale parameters at which that feature first appears and disappears , respectively .",
    "since all features die after they are born , necessarily each point appears on or above the diagonal line @xmath22 .",
    "a pd is a multiset of such points as distinct topological features may have the same birth and death coordinates . by convention ,",
    "all points on the diagonal are taken with infinite multiplicity .",
    "data often comes equipped with measures of internal dissimilarity . as such , a data set is readily considered to be a finite metric space , rich with latent geometric content .",
    "one approach to extracting this content is to consider data as vertices of a simplicial complex , with the presence of edges and higher - dimensional simplices determined by a choice of scale and the dissimilarity of the vertices .",
    "the homology of this simplicial complex depends crucially on the choice of scale .",
    "persistent homology eliminates this choice by computing homology on a range of scales , recording the persistence of homological features across those scales @xcite .",
    "we focus on sets of point cloud data and use ml techniques to classify the point clouds by their topological features .",
    "we obtain pds from data using the vietoris ",
    "rips filtered simplicial complex , which we then `` vectorize '' into a pi .",
    "while the focus of this paper is on point cloud data , a pi could be used in any setting where a pd represents topological information ( _ e.g. _  sub - level set persistence ) .",
    "let @xmath23 denote the set of all pds .",
    "the space @xmath23 can be endowed with a metric as studied in @xcite .",
    "the _ @xmath4-wasserstein distance _ defined between two pds @xmath5 and @xmath24 is given by @xmath25 where @xmath26 and @xmath27 ranges over bijections between @xmath5 and @xmath24 .",
    "another standard choice of distance between diagrams is @xmath28 referred to as the _ bottleneck distance_.",
    "we propose a method for converting a pd into a vector while maintaining an interpretable connection to the original pd .",
    "first , we transform the pd from birth - death coordinates to birth - persistence coordinates .",
    "next , we center a probability distribution at each point in the transformed pd and produce a persistence surface as a weighted sum of these distributions .",
    "we overlay a grid of pixels in the plane and define a pi by assigning to each pixel the integral of the persistence surface over that pixel .",
    "more precisely , let @xmath29 be the linear transformation @xmath30 .",
    "given @xmath5 , a pd in birth - death coordinates feature corresponding to the connectedness of the complete simplicial complex ) .",
    "] , let @xmath31 be the transformed multiset in birth - persistence coordinates , where each point @xmath32 corresponds to a point @xmath33 . a natural choice of probability distribution is the gaussian , which we use for the remainder of the paper .",
    "let @xmath34 be the normalized gaussian distribution with mean @xmath35 and variance @xmath36 , defined via @xmath37/2\\sigma^2}$ ] where @xmath38 .",
    "let @xmath39 be a nonnegative weighting function that is zero along the horizontal axis , continuous , and piecewise differentiable ; the presence of this weighting function is critical to our stability results .",
    "note that the horizontal axis in birth - persistence coordinates corresponds to the diagonal in birth - death coordinates . for @xmath5 a pd ,",
    "we define a corresponding persistence surface @xmath7 as a sum of weighted gaussian distributions .    for @xmath5 a pd , we define its _ persistence surface _ @xmath40 via @xmath41    since a pd is a multiset of points in the plane , there may be multiple gaussian distributions in the sum with the same center .",
    "fix a grid in the plane with @xmath42 boxes or pixels . for any @xmath43 ,",
    "define the vector @xmath44 to be the concatenation over all pixels @xmath4 of the pixel values @xmath45 .    for @xmath5 a pd",
    ", we define its _ persistence image _ to be the vector @xmath46 .        as an illustrative example we consider spectral and spatial information in @xmath47 from an immunofluorescent image of a circulating tumor cell @xcite ( ` data ' in figure [ fig : pipeline ] ) . given a matrix of pairwise distances between points in the cloud ,",
    "persistent homology software can generate a pd ( ` diagram b ' in figure [ fig : pipeline ] ) , and consequently the transformed pd ( ` diagram t(b ) ' in figure [ fig : pipeline ] ) .",
    "it is not necessary to generate both diagrams in practice , but both are included for didactic purposes .",
    "next , a function is generated based on the selection of the probability distribution and weighting function ( ` surface ' in figure [ fig : pipeline ] ) .",
    "finally , based on the chosen resolution , a grid is overlaid and the value of each pixel is computed .",
    "figure [ fig : pipeline ] shows pis at different resolutions ( labeled ` image ' ) .",
    "a reshaping of the image into a vector completes the algorithmic pipeline and provides a solution to the problem in  [ sec : background ] .",
    ", it is possible to generate a 1-dimensional ( instead of 2-dimensional ) pi using 1-dimensional gaussians restricted to the @xmath3-axis .",
    "this is the approach we adopt . ]",
    "appendix [ app : piex ] displays a variety of pis .",
    "there are three choices the user makes when generating a pi : the resolution , the distribution ( and its associated parameters ) , and the weighting function .",
    "* resolution of the .    * the distribution : * our method requires the choice of a probability distribution which is associated to each of the points in the pd .",
    "the stability results and examples in this paper use a gaussian centered at each point , but other distributions may be used . the gaussian distribution depends on a choice of variance .",
    "* the weighting function : * in order for our stability results in  [ sec : stability ] to hold , our weighting function @xmath39 must be zero along the horizontal axis ( the analogue of the diagonal in birth - persistence coordinates ) , continuous , and piecewise differentiable .",
    "a simple choice is a weighting function that depends only on the vertical persistence coordinate @xmath3 . in order to weight points of higher persistence more heavily ,",
    "functions which are nondecreasing in @xmath3 , such as sigmoidal functions , are a natural choice . however , in certain applications such as @xcite it may be points of small or medium persistence that perform best for ml tasks , and hence one may choose to use more general weighting functions . in our experiments in  [ sec : experiments ] , we use a piecewise linear weighting function @xmath39 which only depends on the persistence coordinate @xmath3 . given @xmath48 , define @xmath49 by letting @xmath50 be @xmath51 if @xmath52 , @xmath53 if @xmath54 , and @xmath55 if @xmath56 .",
    "we use @xmath57 , where @xmath58 is the persistence value of the most persistent feature in all trials of the experiment .",
    "due to the unavoidable presence of noise or measurement error , tools for data analysis ought to be stable with respect to small perturbations of the inputs .",
    "indeed , one reason for the popularity of pds in topological data analysis is that the conversion from a data set to a pd is stable ( lipschitz ) with respect to the bottleneck metric @xcite . in this section ,",
    "we show that persistence surfaces and images are stable with respect to the 1-wasserstein distance between pds .    our results for 2-dimensional gaussians will rely on the following lemma for 1-dimensional gaussians .",
    "[ lem : l1surfbound_1d ] for @xmath59 , let @xmath60 be the normalized 1-dimensional gaussians , defined via @xmath61 . if @xmath62 , then @xmath63    let @xmath64 .",
    "it can be shown that @xmath65 , where @xmath66 is defined by @xmath67 furthermore , function @xmath68 is differentiable for @xmath69 with    @xmath70 the result follows by letting @xmath71 .    for @xmath72 differentiable ,",
    "define @xmath73 to be the maximal norm of the gradient vector of @xmath74 , i.e.  the largest directional derivative of @xmath74 . recall that our nonnegative weighting function @xmath39 is defined to be zero along the horizontal axis , continuous , and piecewise differentiable .",
    "[ lem : l1surfbound_2d ] for @xmath75 , let @xmath76 be normalized 2-dimensional gaussians . then @xmath77    the proof of lemma [ lem : l1surfbound_2d ] is shown in appendix [ app : lemma3proof ] and uses a similar construction as that of lemma [ lem : l1surfbound_1d ] . we are prepared to prove the stability of persistence surfaces .",
    "[ thm : surface - stable ] the persistence surface @xmath78 is stable with respect to the 1-wasserstein distance between diagrams : for @xmath79 we have @xmath80 .",
    "since we assume @xmath5 and @xmath24 consist of finitely many off - diagonal points , there exists a matching @xmath27 that achieves the infimum in the wasserstein distance .",
    "then @xmath81    it follows as a consequence that persistence images are also stable .",
    "[ thm : image - stable ] the persistence image @xmath46 is stable with respect to the 1-wasserstein distance between diagrams .",
    "more precisely , @xmath82    we have @xmath83 by theorem  [ thm : surface - stable ] .",
    "the claim follows since @xmath84 for vectors in @xmath85 .",
    "recall @xmath23 is the set of all pds .",
    "the kernel @xmath86 defined by @xmath87 is non - trivial and additive , and hence theorem 3 of @xcite implies that @xmath11 is not stable with respect to @xmath88 for any @xmath89 .",
    "that is , when @xmath89 there is no constant @xmath90 such that for all @xmath91 we have @xmath92 .",
    "several examples in this section deal with a synthetic data set consisting of point clouds in the unit cube sampled from six different topological spaces : the solid cube , a circle , a sphere , three clusters , three clusters within three clusters , and a torus .",
    "the data set contains 25 point clouds of 500 sample points from each space for two levels of gaussian random noise @xmath93 . by design",
    ", high classification accuracy is expected due to the differentiating topological features across the point cloud classes .",
    "the final example considers data arising from an applied dynamical system , the linked twist map , discussed further in  [ sec : linkedtwist ] .",
    "-medoid confusion matrices ( colored by number of samples classified ) and corresponding overall accuracies of the synthetic data set sampled from 6 common topological spaces ( solid cube , a circle , a sphere , three clusters , three clusters within three clusters , and a torus , respectively ) with noise level ( left block of four ) @xmath94 and ( right block of four ) @xmath95 for both the pd and pi frameworks with homological information labeled.,scaledwidth=90.0% ]    the clustering algorithm @xmath0-medoids iteratively identifies @xmath0 data clusters by choosing for each cluster an existing data point as a center which minimizes the distance between each point in the cluster and its corresponding center @xcite .",
    "the data input for @xmath0-medoids is a pairwise distance matrix .",
    "thus , the metric structure of the pd space with the bottleneck distance is sufficient to use pds as a statistic for clustering and allows for a direct comparison to clustering using pis .",
    "in addition to clustering based on the @xmath96 and @xmath97 topological information , pis allow classification based on both @xmath96 and @xmath97 information by the concatenation of the corresponding pi vectors . it is worth noting that the comparison of concatenated pis using a similarity measure analyzes the distance between respective homological dimensions ; the same can not be said of overlaying pds of different homological dimension and using the bottleneck distance .",
    "this is a distinct difference between pis and pds .",
    "the left and right blocks of four matrices of figure [ fig : cmkmed ] display the overall classification accuracies and the images of the corresponding confusion matrices for noise level @xmath98 and @xmath99 , respectively . and @xmath97 .",
    "pairwise euclidean distance matrices were computed for the pis corresponding to @xmath96 , @xmath97 , and the concatenation of the @xmath96 and @xmath97 pi vectors .",
    "the pis were computed using a @xmath100 grid resolution , variance @xmath101 , and the weighting function defined in  [ sec : persistenceimages ] .",
    "the @xmath0-medoids algorithm was initialized with starting centers to be randomly chosen , one from each class . ]",
    "recall the data consists of 25 samples of each of six different classes .",
    "correctly labeled classes are displayed on the diagonal with errors elsewhere .",
    "the pd framework equipped with the bottleneck distance misclassified samples more often than the pi framework equipped with the euclidean distance .-",
    "medoids  where starting centers are chosen randomly  this behavior was also observed ] for this data set the concatenated pis had the same performance as @xmath96 and are thus omitted .",
    "in addition to improved classification accuracy using pis , we also note a drastic improvement in computational time . to generate one pairwise bottleneck distance matrix for our synthetic data set took approximately three orders of magnitude longer than generating a set of pis and computing the pairwise euclidean distance matrix .      as pis",
    "are a vector representation , additional ml algorithms may be implemented on this data set , such as a linear svm  a robust supervised binary classification method .",
    "we implement a linear @xmath102-norm regularized svm for classification @xcite . for multiclass experiments ,",
    "we adopt the one - against - one svm , _",
    "i.e. _  where a class label is assigned to a testing point based on majority voting over all possible pairwise binary svm models between the classes . for a typical experiment , we partition data randomly into @xmath103 for training and @xmath104 for testing , _ i.e. _  20 pis for training and 5 pis for testing per class .    .",
    "the results are averaged over three runs .",
    "( a ) noise level @xmath94 .",
    "( b ) noise level @xmath95.,scaledwidth=90.0% ]    in any system that relies on multiple parameters , it is important to understand the effect of parameter values on the system .",
    "as such , we complete a search of the parameter space used to generate pis and measure svm classification accuracy as a function of the parameters .",
    "we explore 20 different resolutions , use a gaussian function with 40 different choices of variance , and the weighting function described in  [ sec : persistenceimages ] . to @xmath105 in increments of 5 , and variances range from 0.0001 to 0.2 in increments of 0.005 . ] for each set of parameters , we compute the classification accuracy on the two sets of noise levels for the homology dimensions @xmath96 and @xmath97 as well as the concatenation of the two . we observe that for a fixed variance , resolution has little to no effect on accuracy . in figure",
    "[ fig : svm_acc ] , we plot the classification accuracy of both noise levels using the svm algorithm averaged over three runs as a function of variance for the fixed resolution of @xmath100 .",
    "although the plots are not constant , we see that there is a large set of variances which yield consistent accuracy for each homology type , and each parameter choice results in high accuracy .",
    "the lack of smoothness in the accuracy plots is likely attributable to the random partitioning of data for training and testing .",
    "pis from two classes of the synthetic data :",
    "( a ) a noisy circle with two selected features , marked by blue crosses .",
    "( b ) a noisy torus with two selected features , marked by blue crosses .",
    "the parameters used are resolution @xmath106 and variance @xmath107 , for noise level @xmath99.,scaledwidth=60.0% ]    an @xmath108-norm regularized svm ( _ a.k.a .",
    "_  sparse svm ( ssvm ) ) simultaneously classifies data and selects input space features that contribute to the classification process @xcite .",
    "such a model can be used for reducing data dimension and removing redundant features .",
    "for example , using a one - against - all approach on the sets of @xmath96 and @xmath97 pis from the six class synthetic data set , variance @xmath107 , and noise level @xmath99 .",
    "] , ssvm of data for training and @xmath104 for testing . ] results in @xmath109 accuracy comparing six sparse models with indications of the discriminatory features .",
    "feature selection is performed by retaining the features with non - zero ssvm weights , determined by magnitude comparison using weight ratios ; for details see @xcite .",
    "figure  [ fig : featureselection1 ] provides an example , indicating the features of @xmath97 pis that discriminate circles and tori from the other classes in the synthetic data set .",
    "feature selection produces highly interpretable results .",
    "the discriminatory @xmath97 features that separate circles from the other classes correspond to the region where highly persistent @xmath97 features exist across all samples of a noisy circle ( highlighted in figure  [ fig : featureselection1]a ) .",
    "alternatively , the discriminatory features that separate tori from the other classes , using @xmath97 pis , correspond to points of short to moderate persistence ( see figure  [ fig : featureselection1]b ) .",
    "similar conclusions can be drawn from the discriminatory features of others classes ; see appendix  [ app : featureselection ] for details on each of the six classes . in this way ,",
    "figure  [ fig : featureselection1]b reiterates an observation of @xcite : that points of short to moderate persistence can contain important discriminatory information .",
    "our classification accuracy of 100% is obtained using only those features selected by ssvm , further supporting the observation in @xcite .",
    "we approach a classification problem with data arising from the linked twist map , a discrete dynamical system modeling fluid flow .",
    "@xcite use the linked twist map to model flows in dna microarrays with a particular interest in understanding turbulent mixing .",
    "this demonstrates a primary mechanism giving rise to chaotic advection . the linked twist map is a poincar section of _ eggbeater - type flow _",
    "@xcite in continuous dynamical systems .",
    "the poincar section captures the behavior of the flow by viewing a particle s location at discrete time intervals .",
    "the linked twist map is given by the discrete dynamical system @xmath110 where @xmath111 is a positive parameter .",
    "for some values of @xmath111 , the orbits @xmath112 are dense in the domain .",
    "however , for other parameter values , voids form . in either case , the truncated orbits @xmath113 exhibit complex structure .    for this experiment",
    ", we choose a set of parameter values , @xmath114 2.5 , 3.5 , 4.0 , 4.1 and 4.3 , which produce a variety of orbit patterns . for each parameter value ,",
    "50 randomly - chosen initial conditions are selected , and 1000 iterations of the linked twist map are used to generate point clouds in @xmath115 .",
    "figure [ fig : ltm ] shows examples of typical orbits generated for each parameter value .",
    "the goal is to classify the trials by parameter value using pis to capitalize on distinguishing topological features of the data . and a gaussian with variance @xmath116 , to generate the pis .",
    "these parameters were chosen after a preliminary parameter search and classification effort .",
    "similar results hold for a range of pi parameter values . ]",
    "[ h ]   of the linked twist map with parameter values @xmath114 2.5 , 3.5 , 4.0 , 4.1 and 4.3 , respectively.,title=\"fig : \" ]     of the linked twist map with @xmath117 for different initial conditions @xmath118 . ]    for a large number of points ( many thousands ) , the patterns formed by the orbits for various parameter values show only small visible variations in the patterns formed under perturbations of the initial condition . with only 1000 points",
    ", there are more significant variations in the patterns which causes classification to be difficult ; see figure [ fig : ltm4 - 3var ] .",
    "pis enable the use of both @xmath96 and @xmath97 concatenated as a single representation .",
    "this capitalizes on the fact that @xmath96 distinguishes @xmath119 from the other classes , while @xmath97 captures distinguishing information on the presence and magnitude of the voids in the last three classes .",
    "for this data set , classification was performed and cross - validated with a discriminant subspace ensemble and achieves a classification accuracy of 84.8% .",
    "this ml algorithm trains many `` weak '' learners on randomly chosen subspaces of the data ( of a fixed dimension ) , classifies and assigns a score to each point based on the current subspace .",
    "the final classification arises from an average of the scores of each data point over all learners @xcite .",
    "when solely @xmath96 pis are used , the classification accuracy is 51% and when @xmath97 pis are used , the classification accuracy is 74% , demonstrating the value of being able to incorporate multiple dimensions of homological information into a single vector .",
    "this highlights two strengths of pis : one may choose the appropriate machine learning algorithm that has strengths appropriate to handling the data under consideration and homological information from multiple dimensions may be leveraged simultaneously .    even using a coarse resolution , pis are capable of detecting topological differences between parameter choices .",
    "this application is a brief example of the utility of pis in classification of data from dynamical systems and modeling real - world phenomena which provides a promising direction for further applications of pis .",
    "pis offer a stable representation of the topological characteristics captured by a pd . through this vectorization ,",
    "we open the door to a myriad of ml tools .",
    "this serves as a vital bridge between the fields of ml and topological data analysis and enables one to capitalize on topological structure ( even in multiple homological dimensions ) in the classification of data .",
    "we have shown pis yield improved classification accuracy over pds on sampled data of common topological spaces at multiple noise levels with @xmath0-medoids .",
    "additionally , computing distances between pis requires significantly less computation time compared to computing distances between pds . through pis ,",
    "we have gained access to a wide variety of ml tools , such as svm and ssvm which can be used for feature selection . due to the interpretable mapping between pds and pis , features selected in a pi directly correlate with regions in a pd .",
    "for many data sets , like the linked twist map , there are distinguishing features of a topological nature .",
    "pis encapsulate this information in a form amenable to ml tools , resulting in high accuracy rates for data that is difficult to classify .",
    "the classification accuracy is robust to the choice of parameters for building pis , providing evidence that it is not necessary to perform large - scale parameter searches to achieve reasonable classification accuracy .",
    "this indicates the utility of pis even when there is not prior knowledge of the underlying data ( _ i.e. _  high noise level , expected holes , etc . ) .",
    "the flexibility of pis allows for customization tailored to a wide variety of real - world data sets .",
    ".5 cm * acknowledgments : * we would like to acknowledge the research group of paul bendich at duke university for allowing us access to a persistent homology package which greatly reduced computational time and made analysis of large point clouds feasible . this code can be accessed via gitlab after submitting a request to paul bendich .",
    "10    aaron adcock , erik carlsson , and gunnar carlsson .",
    "the ring of algebraic functions on persistence bar codes . , 2013 .",
    "paul bendich , sang chin , jesse clarke , jonathan desena , john harer , elizabeth munch , andrew newman , david porter , david rouse , nate strawn , et  al .",
    "topological and statistical behavior classifiers for tracking applications . , 2014 .",
    "paul bendich , js  marron , ezra miller , alex pieloch , and sean skwerer . persistent homology analysis of brain artery trees . , 2015 .",
    "to appear .",
    "paul  s. bradley and olvi  l. mangasarian .",
    "feature selection via concave minimization and support vector machines . in _",
    "machine learning proceedings of the fifteenth international conference _ , icml 98 , pages 8290 .",
    "morgan kaufmann , 1998 .",
    "peter bubenik .",
    "statistical topology using persistence landscapes .",
    ", 2012 .",
    "christopher j.  c. burges . a tutorial on support vector machines for pattern recognition .",
    ", 2:121167 , 1998 .",
    "gunnar carlsson .",
    "topology and data . , 46(2):255308 , 2009 .",
    "mathieu carrire , steve  y oudot , and maks ovsjanikov .",
    "stable topological signatures for points on 3d shapes . in _ computer graphics forum _ , volume  34 , pages 112 , 2015 .",
    "frdric chazal , vin de  silva , and steve oudot .",
    "persistence stability for geometric complexes .",
    ", 173(1):193214 , 2014 .",
    "yen - chi chen , daren wang , alessandro rinaldo , and larry wasserman . statistical analysis of persistence intensity functions . , 2015 .",
    "sofya chepushtanova , christopher gittins , and michael kirby .",
    "band selection in hyperspectral imagery using sparse support vector machines . in _ proceedings spie dss",
    "2014 _ , volume 9088 , pages 90881f90881f15 , 2014 .",
    "moo  k chung , peter bubenik , and peter  t kim .",
    "persistence diagrams of cortical surface data . in _ information processing in medical imaging _ , pages 386397 .",
    "springer , 2009 .",
    "david cohen - steiner , herbert edelsbrunner , and john harer . stability of persistence diagrams .",
    ", 37(1):103120 , 2007 .",
    "david cohen - steiner , herbert edelsbrunner , john harer , and yuriy mileyko .",
    "lipschitz functions have @xmath120-stable persistence .",
    ", 10(2):127139 , 2010 .",
    "yu  dabaghian , facundo memoli , l  frank , and gunnar carlsson . a topological paradigm for hippocampal spatial map formation using persistent homology .",
    ", 8(8):e1002581 , 2012 .",
    "barbara di  fabio and massimo ferri .",
    "comparing persistence diagrams through complex vectors .",
    ", 2015 .",
    "pietro donatini , patrizio frosini , and alberto lovato .",
    "size functions for signature recognition . in _",
    "spie s international symposium on optical science , engineering , and instrumentation _ , pages 178183 , 1998 .",
    "herbert edelsbrunner and john harer .",
    "persistent homology - a survey .",
    ", 453:257282 , 2008 .",
    "herbert edelsbrunner and john  l. harer . .",
    "american mathematical society , 2010 .",
    "herbert edelsbrunner , a  ivanov , and r  karasev .",
    "current open problems in discrete and computational geometry . , 19(5):517 , 2012 .    tegan emerson , michael kirby , kelly bethel , anand kolatkar , madelyn luttgen , stephen ohara , paul newton , and peter kuhn .",
    "fourier - ring descriptor to characterize rare circulating cells from images generated using immunofluorescence microscopy .",
    ", 40:7087 , 2015 .",
    "massimo ferri , patrizio frosini , alberto lovato , and chiara zambelli .",
    "point selection : a new comparison scheme for size functions ( with an application to monogram recognition ) . in _",
    "computer vision accv98 _ , pages 329337 .",
    "springer , 1997 .",
    "robert ghrist .",
    "barcodes : the persistent topology of data . , 45(1):6175 , 2008 .",
    "allen hatcher . .",
    "cambridge university press , 2002 .",
    "kyle heath , natasha gelfand , maks ovsjanikov , mridul aanjaneya , and leonidas  j guibas .",
    "image webs : computing and exploiting connectivity in image collections . in _",
    "computer vision and pattern recognition ( cvpr ) , 2010 ieee conference on _ , pages 34323439 .",
    "ieee , 2010 .",
    "jan - martin hertzsch , rob sturman , and stephen wiggins . microarrays : design principles for maximizing ergodic , chaotic mixing .",
    ", 3(2):202218 , 2007 .",
    "tin  kam ho .",
    "the random subspace method for constructing decision forests .",
    ", 20(8):832844 , 1998 .",
    "leonard kaufman and peter rousseeuw . .",
    "north - holland , 1987 .",
    "yuriy mileyko , sayan mukherjee , and john harer .",
    "probability measures on the space of persistence diagrams .",
    ", 27(12):124007 , 2011 .",
    "deepti pachauri , christian hinrichs , moo  k chung , sterling  c johnson , and vikas singh .",
    "topology - based kernels with application to inference problems in alzheimer s disease .",
    ", 30(10):17601770 , 2011 .    hae - sang park and chi - hyuck jun . a simple and fast algorithm for @xmath0-medoids clustering",
    ", 36(2):33363341 , 2009 .",
    "jose  a perea and john harer .",
    "sliding windows and persistence : an application of topological methods to signal analysis .",
    ", pages 140 , 2013 .",
    "jan reininghaus , stefan huber , ulrich bauer , and roland kwitt . a stable multi - scale kernel for topological machine learning . , 2014 .",
    "gurjeet singh , facundo memoli , tigran ishkhanov , guillermo sapiro , gunnar carlsson , and dario  l ringach .",
    "topological analysis of population activity in visual cortex .",
    ", 8(8):11 , 2008 .",
    "chad  m. topaz , lori ziegelmeier , and tom halverson .",
    "topological data analysis of biological aggregation models .",
    ", 10(5):e0126383 , 05 2015 .",
    "katharine turner , yuriy mileyko , sayan mukherjee , and john harer .",
    "frchet means for distributions of persistence diagrams .",
    ", 52(1):4470 , 2014 .",
    "vladimir  n. vapnik . .",
    "springer - verlag new york , inc .",
    ", new york , ny , usa , 1995 .    yuan wang , hernando ombao , and moo  k chung .",
    "persistence landscape of functional signal and its application to epileptic electroencaphalogram data .",
    "li  zhang and weida zhou . on the sparseness of 1-norm support vector machines . , 23(3):37385 , april 2010 .",
    "ji  zhu , saharon rosset , trevor hastie , and rob tibshirani .",
    "1-norm support vector machines . , ( 16 ) , 2003 .",
    "afra zomorodian and gunnar carlsson .",
    "computing persistent homology .",
    ", 33(2):249274 , 2005 .",
    "homology is an invariant that characterizes the topological properties of a topological space @xmath10 . in particular , homology measures the number of connected components , loops , trapped volumes , and so on of a topological space , and can be used to distinguish distinct spaces from one another .",
    "more explicitly , the @xmath11-dimensional holes of a space generate a homology group , @xmath12 .",
    "the rank of this group is referred to as the _ @xmath11-th betti number _ , @xmath13 , and counts the number of @xmath11-dimensional holes of @xmath10 . for a comprehensive study of homology ,",
    "see @xcite .",
    "given a point cloud of data , its shape can be measured by first constructing connections between nearby data points , and then computing homology on the topological space formed by these connections ( called a simplicial complex ) .",
    "the notion of ` near ' , and hence the resulting topological features , depends on a choice of scale .",
    "the idea of persistent homology is to compute homology at many scales and observe which topological features persist across those scales . for further details ,",
    "see  [ ph_data ] and @xcite .",
    "simplicial complexes are one way to define topological spaces combinatorially",
    ". more precisely , a _ simplicial complex _",
    "@xmath121 consists of vertices ( 0-simplices ) , edges ( 1-simplices ) , triangles ( 2-simplices ) , tetrahedra ( 3-simplices ) , and higher - dimensional @xmath11-simplices ( containing @xmath122 vertices ) , such that    * if @xmath123 is a simplex in @xmath121 then @xmath121 contains all lower - dimensional simplices of @xmath123 , and * the non - empty intersection of any two simplices in @xmath121 is a simplex in @xmath121 .",
    "the following setup is necessary for a rigorous definition of homology . to a simplicial complex ,",
    "one can associate a chain complex of vector spaces over a field @xmath124 ( often a finite field @xmath125 for @xmath4 a small prime ) , @xmath126 here vector space @xmath127 consists of all @xmath124-linear combinations of the @xmath11 simplices of @xmath121 , and has as a basis the set of all @xmath11-simplices . the linear map @xmath128 , known as the _ boundary operator _ , maps a @xmath11-simplex to its boundary , a sum of its @xmath129-faces .",
    "more formally , the boundary map acts on a @xmath11-simplex @xmath130 $ ] by @xmath131 ) = \\sum_{i=0}^k ( -1)^i [ v_0 , \\ldots , \\hat{v_i } , \\ldots , v_k],\\ ] ] where @xmath132 $ ] is the @xmath133-simplex obtained from @xmath134 $ ] by removing vertex @xmath135 .",
    "we define two subspaces of @xmath127 : subspace @xmath136 is known as the _ @xmath11-cycles _ , and subspace @xmath137 is known as the _",
    "@xmath11-boundaries_. the boundary operator satisfies the property @xmath138 , which implies the inclusion @xmath139 .    homology seeks to uncover an equivalence class of cycles that enclose a @xmath11-dimensional hole  that is , cycles which are not also boundaries of @xmath11-simplices . to this end , the @xmath11-th order homology is defined as @xmath140 , a quotient of vector spaces .",
    "the @xmath11-th betti number @xmath141 is the dimension of this vector space , and counts the number of independent holes of dimension @xmath11 .",
    "more explicitly , @xmath142 counts the number of connected components , @xmath143 the number of loops , @xmath144 the number of trapped volumes , and so on .",
    "betti numbers are a topological invariant , meaning that topologically equivalent spaces have the same betti number .",
    "one way to approximate the topological characteristics of a point cloud data set is to build a simplicial complex on top of it .",
    "though there are a variety of methods to do so , we restrict attention to the _ vietoris  rips simplicial complex _ due to its computational tractability @xcite . given a data set @xmath145 ( equipped with a metric ) and a scale parameter @xmath146 , the vietoris",
    " rips complex @xmath147 has @xmath145 as its set of vertices and has a @xmath11-simplex for every collection of @xmath122 vertices whose pairwise distance is at most @xmath148 .",
    "however , it is often not apparent how to choose scale @xmath148 . selecting @xmath148 too small results in a topological space with a large number of small connected components , and selecting @xmath148 too large results in a topological space that is contractible ( equivalent to a single point ) .",
    "one solution to this problem is to consider a collection of nested simplicial complexes indexed by scale parameter @xmath148 .",
    "that is , if @xmath149 , then the corresponding vietoris  rips simplicial complexes satisfy @xmath150 . as @xmath148 varies , so does the homology of @xmath147 , and indeed for any @xmath11 we get a sequence of linear maps @xmath151 .",
    "persistent homology tracks the homological features over a range of values of @xmath148 .",
    "those features which persist over a larger range are considered to be true topological characteristics , while short - lived features are often considered as noise .    for each choice of homological dimension @xmath11 ,",
    "the information measured by persistent homology can be presented as a _ persistence diagram _ ( pd ) , a multiset of points in the plane .",
    "each point @xmath1 corresponds to a topological feature that appears ( is ` born ' ) at scale parameter @xmath2 and which no longer remains ( ` dies ' ) at scale @xmath3 . since all topological features die after they are born ,",
    "this is an embedding into the upper half plane , above the diagonal line @xmath22 .",
    "points near the diagonal are considered to be noise while those further from the diagonal represent more robust topological features .",
    "arising from a noisy circle with a variety of resolutions and variances .",
    "the first row has resolution @xmath152 while the second has @xmath153 .",
    "the columns have variance @xmath154 , @xmath155 , and @xmath101 , respectively . ]     arising from a noisy torus with a variety of resolutions and variances .",
    "the first row has resolution @xmath152 while the second has @xmath153 .",
    "the columns have variance @xmath154 , @xmath155 , and @xmath101 , respectively . ]",
    "* lemma 2 . * for @xmath75 ,",
    "let @xmath76 be normalized 2-dimensional gaussians .",
    "then@xmath77    let @xmath156 and @xmath157 ; we may assume @xmath158 w.l.o.g . let @xmath159 be the magnitude and angle of vector @xmath160 when expressed in polar coordinates .",
    "the change of variables @xmath161 , where @xmath162 is the clockwise rotation of the plane by @xmath163 , gives @xmath164/2\\sigma^2 } - \\frac{f(v)}{2\\pi \\sigma^2 } e^{-[(x - v_x)^2+(y - v_y)^2]/2\\sigma^2 } \\right| dy \\ ; dx \\\\ = & \\int_{-\\infty}^{\\infty } \\int_{-\\infty}^{\\infty } \\left|\\frac{f(u)}{2\\pi \\sigma^2 } e^{-[w^2+(z - r)^2]/2\\sigma^2 } - \\frac{f(v)}{2\\pi \\sigma^2 } e^{-[w^2 + z^2]/2\\sigma^2 } \\right| dz \\ ; dw \\\\ = & \\int_{-\\infty}^{\\infty } \\frac{1}{\\sigma \\sqrt{2\\pi } } e^{-w^2/2\\sigma^2 } \\left [ \\int_{-\\infty}^{\\infty}\\left|\\frac{f(u)}{\\sigma\\sqrt{2\\pi } } e^{-(z - r)^2/2\\sigma^2 } - \\frac{f(v)}{\\sigma\\sqrt{2\\pi}}e^{-z^2/2\\sigma^2 } \\right| dz \\right ] dw \\\\",
    "= & \\|f(u)g_0-f(v)g_r\\|_1 \\int_{-\\infty}^{\\infty } \\frac{1}{\\sigma \\sqrt{2\\pi } } e^{-w^2/2\\sigma^2 } dw \\quad \\mbox{with } g_0,g_r\\mbox { 1-dimensional gaussians } \\\\ = & \\|f(u)g_0-f(v)g_r\\|_1 \\\\ \\le & |f(u)-f(v)|+\\sqrt{\\frac{2}{\\pi}}\\frac{\\min\\{f(u),f(v)\\}}{\\sigma}\\|u - v\\|_2 \\quad \\mbox{by lemma~\\ref{lem : l1surfbound_1d } } \\\\ \\le & \\left(|\\nabla f|+\\sqrt{\\frac{2}{\\pi}}\\frac{\\min\\{f(u),f(v)\\}}{\\sigma}\\right)\\|u - v\\|_2.\\end{aligned}\\ ] ]",
    "in  [ param_selection : sec ] , we completed a parameter space search on pis generated from the synthetic data set , measuring the svm classification accuracy as a function of the parameters . in this section",
    ", we consider the same parameter space search using the @xmath0-medoid algorithm to classify .",
    "we explore 20 different resolutions ranging from @xmath165 to @xmath105 in increments of 5 .",
    "we select a gaussian function with 40 different choices of variance ranging from 0.0001 to 0.2 in increments of 0.005 weighted by the function described in  [ sec : persistenceimages ] . for each set of parameters , we compute the classification accuracy on the two sets of noise levels for the homology dimensions @xmath96 and @xmath97 as well as the concatenation of the two .",
    "one hundred runs of the @xmath0-medoids algorithm where centers were initialized randomly  without using any prior knowledge of the classes  were averaged to compute this classification accuracy .",
    "we observe that for a fixed variance , resolution has little to no effect on accuracy .",
    "thus , in figure [ fig : clustering_kmed ] , we plot the classification accuracy of the noise levels 0.1 and 0.05 using the @xmath0-medoids algorithm as a function of variance for the fixed resolution of @xmath100 . although the plots are not constant , we see that there is a large set of variances which yield consistent accuracy for each homology type .",
    "svm classification is more accurate than @xmath0-medoids for this data set , particularly when no prior knowledge of the data is used to designate initial centers . yet",
    ", both methods show robustness to parameter choice .",
    "-medoids classification accuracy as a function of variance for fixed resolution @xmath100 .",
    "this accuracy was averaged over 100 runs of the @xmath0-medoids algorithm where centers were initialized randomly .",
    "( a ) noise level @xmath94 . ( b ) noise level @xmath95 . ]",
    "we performed feature selection using one - against - all ( oaa ) ssvm on the six classes of synthetic data with noise level @xmath95 .",
    "the pis used in the experiments were generated from the @xmath97 pds , with the parameter choices of resolution @xmath166 and variance @xmath154 .",
    "note that because of the resolution parameter choice of @xmath106 , each pi is a @xmath167-dimensional vector , and the selected features will be a subset of indices corresponding to pixels within the pi .",
    "we trained an oaa ssvm model for pis of dimension @xmath97 . in the experiment , we used @xmath103 of data for training and @xmath104 for testing and obtained @xmath109 overall accuracy .",
    "feature selection was performed by retaining the features with non - zero ssvm weights , determined by magnitude comparison using weight ratios @xcite .",
    "the resulting six sparse models contain subsets of discriminatory features for each class . note that one can use only these selected features for classification without loss in accuracy .",
    "these features correspond to discriminatory pixels in the persistence images ."
  ],
  "abstract_text": [
    "<S> many data sets can be viewed as a noisy sampling of an underlying topological space . </S>",
    "<S> a suite of tools in topological data analysis allows one to exploit this structure for the purpose of knowledge discovery . </S>",
    "<S> one such tool is persistent homology which provides a multiscale description of the homological features within a data set . </S>",
    "<S> a useful representation of this homological information is a _ persistence diagram _ ( pd ) . </S>",
    "<S> the space of pds can be given a metric structure allowing a given diagram to be used as a statistic for the purpose of comparison against other diagrams . </S>",
    "<S> we convert a pd to a _ persistence image _ ( pi ) and prove stability with respect to small perturbations in the inputs . </S>",
    "<S> the pi is a vector representation allowing the application of vector - based machine learning tools , such as linear and sparse support vector machines . </S>",
    "<S> these tools help to identify discriminatory features which can have a topological interpretation . </S>",
    "<S> the pis and pds derived from randomly sampled topological spaces are compared by applying the @xmath0-medoids clustering algorithm . to further illustrate the pi technique , linear and sparse support vector machines </S>",
    "<S> are implemented on this data set and classification is performed on additional data arising from a discrete dynamical system called the _ linked twist map_. </S>"
  ]
}