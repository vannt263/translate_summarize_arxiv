{
  "article_text": [
    "in the last two years the rapidly growing field of compressed sensing has attracted much attention @xcite .",
    "its basic idea is that sparse or compressible signals can be reconstructed from vastly incomplete non - adaptive information . by `` sparse '' we mean that a vector has only few non - zero coefficients , while `` compressible '' expresses that a vector can be well - approximated by a sparse one .",
    "previous work on this topic includes the reconstruction of fourier coefficients from samples taken randomly on a lattice by the _ basis pursuit _ ( bp ) principle @xcite .",
    "this consists in minimizing the @xmath0-norm of the fourier coefficients subject to the condition that the corresponding trigonometric polynomial matches the sampling points .",
    "indeed , it was proven by cands , romberg and tao in @xcite in the setting of the discrete fourier transform that this scheme recovers the coefficients exactly with high probability provided the number of samples is high enough compared to the sparsity , i.e. , the number of non - zero coefficients .",
    "this result has been generalized by the second author of the present paper in @xcite for the case of samples taken uniformly at random from the cube @xmath1^d$ ] .",
    "another line of research suggests greedy methods such as ( orthogonal ) matching pursuit ( omp ) and thresholding for sparse reconstruction tasks @xcite .",
    "omp and thresholding are conceptually simple to implement and potentially faster than bp .",
    "in particular , they may easily take into account fast algorithms for multiplication with the involved matrices , while most standard software for convex optimization @xcite does not allow this .",
    "this paper is devoted to the theoretical and numerical investigation and comparison of thresholding , omp and bp for the recovery of sparse trigonometric polynomials from randomly taken samples .",
    "our theoretical results indicate that indeed all the methods are suitable for this task .",
    "the novelty in the present paper is a performance analysis for omp and thresholding , although the theoretical achievements for omp are only partial so far . in contrast to bp ,",
    "the greedy algorithms give only a non - uniform guarantee of recovery at a sufficiently small ratio of the number of samples to the sparsity .",
    "this means that they guarantee recovery with high probability only for the given trigonometric polynomial , while bp can actually guarantee recovery of _ all _ sufficiently sparse trigonometric polynomials from a single sampling set .    in practice",
    "however , a non - uniform guarantee might be sufficient .",
    "indeed , our numerical experiments suggest that omp even slightly outperforms bp on generic signals with respect to reconstruction rate . considering that greedy algorithms are usually significantly faster than bp one",
    "would probably use omp for most applications despite its lack of uniformity .    for related work on this topic ,",
    "also known as compressed sensing , we refer to @xcite and the references therein . for more information on sampling of (",
    "not necessarily sparse ) trigonometric polynomials in a probabilistic setting the reader may consult @xcite .",
    "+    the paper is organized as follows : after introducing the necessary notation , including the orthogonal matching pursuit algorithm , we first review known results for basis pursuit",
    ". then we present our main result concerning thresholding and omp .",
    "based on the coherence parameter we also provide uniform reconstruction results for thresholding and omp , cf .",
    "subsection [ coherence ] .",
    "in section [ sect : proofs ] all proofs of the obtained results are given .",
    "section [ sect : num ] presents extensive numerical experiments .",
    "finally , section 5 makes conclusions and discusses possible future work .",
    "for some finite subset @xmath2 , @xmath3 , we let @xmath4 denote the space of all trigonometric polynomials in dimension @xmath5 whose coefficients are supported on @xmath6 .",
    "clearly , an element @xmath7 of @xmath4 is of the form @xmath8^d,\\ ] ] with some fourier coefficients @xmath9 .",
    "the dimension of @xmath4 will be denoted by @xmath10 .",
    "taking @xmath11 yields the space @xmath12 of all trigonometric polynomials of maximal order @xmath13 .",
    "we will mainly deal with `` sparse '' trigonometric polynomials , i.e. , we assume that the sequence of coefficients @xmath14 is supported only on a set @xmath15 , which is much smaller than @xmath6",
    ". however , a priori nothing is known about @xmath15 except for its maximum size .",
    "thus , it is useful to introduce the set @xmath16 of all trigonometric polynomials whose fourier coefficients are supported on a set @xmath17 satisfying @xmath18 . note that @xmath19 is not a linear space .",
    "our aim is to sample a trigonometric polynomial @xmath7 of @xmath20 at @xmath21 points @xmath22^d$ ] and try to reconstruct @xmath7 from these samples .",
    "if for some @xmath23 the sampling points are located on the grid @xmath24 then this problem can also be interpreted as reconstructing a sparse vector from partial information on its discrete fourier transform .",
    "basis pursuit consists in solving the following @xmath0-minimization problem @xmath25 this task can be performed with convex optimization techniques @xcite . for real - valued coefficients ( [ bp ] )",
    "can be reformulated as a linear program while for complex - valued coefficients we obtain a second order cone program . for both kind of problems",
    "standard software exists , such as mosek @xcite or cvx @xcite ( internally using sedumi @xcite ) and since recently also l1magic @xcite ( only for real - valued coefficients ) .",
    "as an alternative to bp we also use greedy algorithms to recover the fourier coefficients of @xmath7 from few samples .",
    "in particular , we study orthogonal matching pursuit ( algorithm [ algo : omp ] ) as well as the very simple thresholding algorithm ( algorithm [ algo : thresh ] ) .",
    "we need to introduce some notation .",
    "let @xmath26 be the set of ( random ) sampling points .",
    "we denote by @xmath27 the @xmath28 matrix ( recall that @xmath29 ) with entries @xmath30 then clearly , @xmath31 if @xmath32 is the vector of fourier coefficients of @xmath7 .",
    "let @xmath33 denote the @xmath34-th column of @xmath27 , i.e. , @xmath35 so @xmath36 . by @xmath37",
    "we denote the restriction of @xmath27 to sequences supported only on @xmath15 .",
    "furthermore , let @xmath38 be the usual euclidean scalar product and @xmath39 the associated norm .",
    "we have @xmath40 for all @xmath41 , i.e. , all the columns of @xmath27 have the same @xmath42-norm .",
    "we postpone a detailed discussion on the implementation of algorithm [ algo : omp ] to section [ sect : num ] ."
  ],
  "abstract_text": [
    "<S> we investigate the problem of reconstructing sparse multivariate trigonometric polynomials from few randomly taken samples by basis pursuit and greedy algorithms such as orthogonal matching pursuit ( omp ) and thresholding . </S>",
    "<S> while recovery by basis pursuit has recently been studied by several authors , we provide theoretical results on the success probability of reconstruction via thresholding and omp for both a continuous and a discrete probability model for the sampling points . </S>",
    "<S> we present numerical experiments , which indicate that usually basis pursuit is significantly slower than greedy algorithms , while the recovery rates are very similar .    </S>",
    "<S> * key words : * random sampling , trigonometric polynomials , orthogonal matching pursuit , basis pursuit , thresholding , sparse recovery , random matrices , fast fourier transform , nonequispaced fast fourier transform    * ams subject classification : * 94a20 , 42a05 , 15a52 , 90c05 , 90c25 </S>"
  ]
}