{
  "article_text": [
    "ordinary differential equations model large classes of applications such as planetary motion , chemical reactions , population dynamics or consumer behaviour .",
    "a breakthrough in the understanding of ordinary differential equations was initiated by poincar and lyapunov in the late 19th century , who developed an approach that embraced the use of topological and geometrical techniques for the study of dynamical systems .",
    "a key component of this theory is lyapunov functions , which can be used to determine the basin of attraction of an asymptotically stable equilibrium .    in general",
    ", it is not possible to find an explicit analytical expression for a lyapunov function associated to a nonlinear differential equation .",
    "many methods have been proposed to numerically construct lyapunov functions , see @xcite for a recent review .",
    "these methods include the sos ( sums of squares ) method , which constructs a polynomial lyapunov function by semidefinite optimization @xcite .",
    "another method constructs a continuous piecewise affine ( cpa ) lyapunov function using linear optimization @xcite .",
    "a further method is based on zubov s equation and computes a solution of this partial differential equation @xcite .",
    "lyapunov functions can also be constructed using set oriented methods @xcite .",
    "the method that is also used in this paper is based on approximating the solution of a pde using radial basis functions @xcite .",
    "all these methods to approximate lyapunov functions rely on the knowledge of the right hand side of the differential equation .    in this paper",
    ", we develop a method to approximate lyapunov functions where the right hand side is unknown , but we have sampled data of the system , which is contaminated by noise .",
    "we will first approximate the right hand side of the differential equation , and then use this approximation to approximate the lyapunov function .",
    "our approach combines and develops previous results from statistical learning theory @xcite together with existing methods using radial basis functions @xcite , which use the framework of reproducing kernel hilbert spaces ( rkhs ) .",
    "the use of rkhs spaces to approximate important quantities in dynamical systems has previously been exploited by smale and zhou to approximate a hyperbolic dynamical system @xcite .",
    "bouvrie and hamzi also use rkhs spaces to approximate some key quantities in control and random dynamical systems @xcite .",
    "we consider ordinary differential equations of the form @xmath0 where @xmath1 is a smooth vector field and dot denotes differentiation with respect to time .",
    "we define the flow @xmath2 by @xmath3 , where @xmath4 solves with @xmath5 .",
    "we assume that has a fixed point @xmath6 that is exponentially asymptotically stable .",
    "define the basin of attraction as @xmath7 .",
    "note that @xmath8 and @xmath9 is open .",
    "subsets of the basin of attraction can be determined by the use of lyapunov functions , which are functions decreasing along solutions of .",
    "we consider two types of lyapunov functions @xmath10 and @xmath11 , as described in theorems  [ thm : vlyapunovconverse ] and [ thm : tlyapunovconverse ] below .",
    "these lyapunov functions satisfy @xmath12 where @xmath13 is a smooth function with @xmath14 for @xmath15 and @xmath16 , and @xmath17 is a positive constant .",
    "the scalar products on the left hand sides are called the orbital derivatives of @xmath10 and @xmath11 with respect to , which are the derivatives of @xmath10 and @xmath11 along solutions of .",
    "the orbital derivatives of @xmath10 and @xmath11 are negative , which implies that @xmath10 and @xmath11 are decreasing along solutions .",
    "we assume that the function @xmath18 is unknown , but we have sampled data of the form @xmath19 in @xmath20 , @xmath21 , with @xmath22 .",
    "we assume that the one - dimensional random variables @xmath23 , where @xmath21 and @xmath24 , are independent random variables drawn from a probability distribution with zero mean and variance @xmath25 bounded by @xmath26 . here",
    "@xmath27 is a nonempty and compact subset of @xmath28 with @xmath29 boundary .    in  [ sec : algorithm ] we provide an algorithm to approximately reconstruct the lyapunov functions @xmath10 and @xmath11 by functions @xmath30 and @xmath31 .",
    "the following main theorem provides error estimates in a compact set @xmath32 , which depend on the density of the data , measured by two key quantities : the fill distance of the data @xmath33 ( see definition [ def : filldistance ] ) and the norm of the volume weights @xmath34 corresponding to the voronoi tessellation of the data ( see definition  [ def : voronoi ] ) .",
    "[ thm : mainresult ] consider such that @xmath35 with @xmath36 if @xmath37 is odd , or @xmath38 if @xmath37 is even .",
    "let @xmath39 and @xmath40 be such that @xmath41 with @xmath42 , and @xmath43 ( if @xmath37 is odd ) or @xmath44 ( if @xmath37 is even ) .",
    "define @xmath45 .",
    "let @xmath46 be a compact set and @xmath47 , with @xmath48 small enough so that @xmath49 .",
    "for @xmath33 , @xmath50 and @xmath51 sufficiently small , the following holds :    1 .   for every @xmath52 ,",
    "the reconstruction @xmath30 of the lyapunov function @xmath10 defined in theorem [ thm : vlyapunovconverse ] satisfies the following estimate with probability @xmath53 : @xmath54 where @xmath55 is a certain compact subset of @xmath9 , and @xmath56 .",
    "2 .   for every @xmath52",
    ", the reconstruction @xmath31 of the lyapunov function @xmath11 defined in theorem [ thm : tlyapunovconverse ] satisfies the following estimates with probability @xmath53 : @xmath57 where @xmath58 is a non - characteristic hypersurface on which @xmath11 has defined values ( see definition [ def : noncharhyp ] ) , @xmath59 is a certain compact subset of @xmath9 , and @xmath56",
    ". +    figure.eps ( 5,38 ) ( 22,41 ) ( 17,28 ) ( 40,36 ) ( 32.4,26 ) ( 48.,29.8 ) ( 50.3,24.5 )    the main point is that the expressions on the right hand side of  can be made arbitrarily small as the data density increases and for suitably chosen @xmath60 ( see equation ) .",
    "therefore the orbital derivative of our lyapunov function approximations @xmath30 and @xmath31 become arbitrarily close in the infinity norm to those of @xmath10 and @xmath11 respectively .",
    "estimate implies that the orbital derivative of @xmath30 will be negative in @xmath61 ( which does not contain a small neighbourhood of the equilibrium @xmath6 ) , since @xmath62 where @xmath13 is a positive definite function ( see theorem [ thm : vlyapunovconverse ] ) .",
    "the analogous statement is true for @xmath31 , since @xmath63 . in principle",
    "the neighbourhood @xmath64 can shrink as the data density increases ( as @xmath33 and @xmath50 tend to zero ) .",
    "the above estimate contains @xmath65 as a regularisation parameter of our algorithm , and @xmath51 as the fill distance of a set of sampled points in @xmath66 ( resp .",
    "@xmath67 ) of our choosing . similarly , @xmath68 is the fill distance of a set of sampled points on @xmath58 , which we are able to choose .",
    "the constants in the above estimates depend on @xmath37 , @xmath69 , the choice of function spaces for approximation and the vector field @xmath18 .",
    "the rest of the paper is organised as follows . in ",
    "[ sec : conversethms ] we provide the converse theorems for the lyapunov functions @xmath10 and @xmath11 . in ",
    "[ sec : background ] we set out the framework for the function spaces that are used to approximate the lyapunov functions , as well as previous results on the approximation of lyapunov functions when the right hand side of is known .",
    "the algorithms themselves that are used to compute @xmath30 and @xmath31 are detailed in  [ sec : algorithm ] . in  [ sec : errorf ] we provide an estimate for our approximation of the right hand side of , which is then used in the proof of theorem [ thm : mainresult ] in  [ sec : proofofmainthm ] .",
    "the concept of a lyapunov function dates back to 1893 , where lyapunov introduced these functions for the stability analysis of an equilibrium for a given differential equation , without the explicit knowledge of the solutions @xcite .",
    "many converse theorems have been proved that guarantee the existence of a lyapunov function under certain conditions , see @xcite for an overview .",
    "massera @xcite provided the first main converse theorem for @xmath29 vector fields where @xmath70 , with further developments by several authors to prove the existence of smooth lyapunov functions under weak smoothness assumptions on the right hand side ( see e.g. @xcite ) .",
    "the existence of a lyapunov function for system with given values of the orbital derivative has been shown by bhatia @xcite , as stated in the following theorems ( see also @xcite ) .",
    "we also refer to @xcite for a proof that the conditions on the function @xmath13 given here are sufficient to define the lyapunov function @xmath10 , in contrast to the conditions given in @xcite .",
    "first we make the following definition .",
    "[ def : classk ] a continuous function @xmath71 is a class @xmath72 function if @xmath73 and @xmath74 is strictly monotonically increasing .",
    "[ thm : vlyapunovconverse ] consider the autonomous system of differential equations @xmath75 , where @xmath76 , @xmath77 , @xmath78 .",
    "we assume the system to have an exponentially asymptotically stable equilibrium @xmath6 .",
    "let @xmath79 be a function with the following properties :    1 .",
    "@xmath14 for @xmath80 , and @xmath81 .",
    "2 .   there is a class @xmath72 function @xmath74 such that @xmath82 for all @xmath83",
    ".    then there exists a lyapunov function @xmath84 ( where @xmath9 is the basin of attraction of @xmath6 ) , such that @xmath85 holds for all @xmath86 .",
    "the lyapunov function @xmath10 is uniquely defined up to a constant .",
    "we may also choose @xmath87 to be a positive constant in equation to obtain a lyapunov function @xmath11 , defined on @xmath88 , for which @xmath89 .",
    "[ thm : tlyapunovconverse ] consider the autonomous system of differential equations @xmath75 , where @xmath76 , @xmath77 , @xmath78 .",
    "we assume the system to have an exponentially asymptotically stable equilibrium @xmath6 .",
    "then for all @xmath90 , there exists a lyapunov function @xmath91 such that @xmath92 moreover , @xmath93 .",
    "the lyapunov function @xmath11 will be uniquely defined if its values are given on a non - characteristic hypersurface @xmath94 @xcite by a function @xmath95 ; that is , @xmath96 for @xmath97 .",
    "[ def : noncharhyp ] consider @xmath75 , where @xmath76 , @xmath77 , @xmath78 .",
    "let @xmath98 and recall @xmath99 denotes the flow mapping .",
    "the set @xmath100 is called a non - characteristic hypersurface if    1 .",
    "@xmath58 is compact , 2 .",
    "@xmath101 if and only if @xmath102 , 3 .",
    "@xmath103 holds for all @xmath102 , and 4 .   for each @xmath104",
    "there is a time @xmath105 such that @xmath106 .",
    "an example of a non - characteristic hypersurface is the level set of a ( local ) lyapunov function , see @xcite . in what follows",
    "we assume that we have chosen a non - characteristic hypersurface @xmath58 together with a function @xmath95 so that @xmath11 is uniquely defined .",
    "the lyapunov function @xmath10 is smooth and defined on the entire basin of attraction @xmath9 .",
    "however , its orbital derivative vanishes at the equilibrium @xmath6 , and therefore estimates that bound the error of the orbital derivative for numerical approximations of @xmath10 can not guarantee negative orbital derivative arbitrarily close to the equilibrium @xmath6 . on the other hand ,",
    "the lyapunov function @xmath11 is not even defined at @xmath6 and is unbounded near the equilibrium",
    ". however , its definition has the advantage that it is not required that we know where the equilibrium is .    in our approach to approximate lyapunov functions directly from data , we will provide estimates for the approximation of both @xmath10 and @xmath11 .",
    "the strategy is to first approximate @xmath18 from the data , and use this in turn to approximate the lyapunov function .",
    "the function spaces that we use to search for our approximations to both @xmath18 and the lyapunov functions @xmath10 and @xmath11 will be reproducing kernel hilbert spaces ( rkhs ) . for a survey of the main properties of rkhs spaces mentioned in this section , we refer to @xcite .    in order to define an rkhs function space we first fix a continuous , symmetric , positive definite function ( a `` kernel '' ) @xmath107 , and set @xmath108 .",
    "define the hilbert space @xmath109 by first considering all finite linear combinations of functions @xmath110 , that is @xmath111 with finitely many @xmath112 nonzero .",
    "an inner product @xmath113 on this space is defined by @xmath114 and extending linearly .",
    "one takes the completion to obtain @xmath109 .",
    "alternatively , an equivalent definition of an rkhs is as a hilbert space of real - valued functions on @xmath27 for which the evaluation functional @xmath115 is continuous for all @xmath116 .",
    "finite dimensional subspaces of @xmath109 can also be naturally defined by taking a finite number of points @xmath117 and considering the linear span @xmath118 in practice we will seek functions in these finite dimensional subspaces as approximations for @xmath18 .    within these hilbert spaces",
    "the reproducing property holds : @xmath119 if we denote @xmath120 , then @xmath121 and it follows that @xmath122    the rkhs @xmath109 can also be defined by means of an integral operator .",
    "let @xmath123 be any ( finite ) strictly positive borel measure on @xmath27 ( e.g. lebesgue measure ) and @xmath124 be the hilbert space of square integrable functions on @xmath27 . then define the linear operator @xmath125 by @xmath126 when composed with the inclusion @xmath127 we obtain an operator from @xmath128 to @xmath128 , which we also denote by @xmath129 .",
    "@xmath129 is then a self - adjoint compact operator , and it is also positive if the kernel @xmath130 is positive definite . also the map @xmath131 defines an isomorphism of hilbert spaces .",
    "@xmath132 is well defined as an operator on @xmath124 in the sense that @xmath133 .      in this paper",
    "we will work with reproducing kernel hilbert spaces that are sobolev spaces .",
    "given the open domain @xmath134 , for @xmath135 , @xmath136 , the sobolev space @xmath137 consists of all functions @xmath138 with weak derivatives @xmath139 , @xmath140 .",
    "we also use the following notation to define the ( semi-)norms @xmath141 the norms are defined in the natural way : @xmath142 we will also use fractional order sobolev spaces . for a detailed discussion",
    "see e.g. @xcite .    the sobolev embedding theorem states that for @xmath143 , @xmath144 can be embedded into @xmath145 , and therefore it follows that @xmath144 is a rkhs , using the fact that the pointwise evaluation functional is then continuous .",
    "several kernel functions are known to generate rkhs spaces that are norm - equivalent to sobolev spaces @xcite",
    ". we will choose to work with the wendland functions @xcite .",
    "these are positive definite , compactly supported radial basis function kernels that are represented by a univariate polynomial on their support .",
    "let @xmath146 , @xmath147 .",
    "we define by recursion @xmath148 for @xmath149 . here ,",
    "@xmath150 for @xmath151 and @xmath152 for @xmath153 .",
    "setting @xmath154 , the wendland functions are characterised by a smoothness index @xmath155 , and belong to @xmath156 . for a domain @xmath157 with a lipschitz boundary ,",
    "the wendland function kernel is given by @xmath158 , @xmath159 , for @xmath160 .",
    "the wendland function kernel generates an rkhs consisting of the same functions as the sobolev space @xmath161 with @xmath162 , with an equivalent norm ( * ? ? ?",
    "* corollary 10.48 ) .",
    "therefore the generated sobolev space is of integer order when @xmath37 is odd , and integer plus one half when @xmath37 is even .    from now on we shall use rkhs spaces generated by wendland function kernels .",
    "we will use two such rkhs spaces for the two parts of our algorithm : to approximate the vector field @xmath18 in we use the space @xmath163 defined on @xmath27 , corresponding to the wendland function kernel @xmath164 with smoothness index @xmath165 , such that @xmath41 with @xmath166 .",
    "then @xmath167 is norm - equivalent to @xmath168 . in this case , when @xmath37 is odd we have that @xmath169 , and the assumption that @xmath170 implies that @xmath171 .",
    "when @xmath37 is even , @xmath172 , and the assumption that @xmath173 gives @xmath174 ( cf .",
    "theorem [ thm : mainresult ] ) .    in the second part of our algorithm we approximate the lyapunov function .",
    "for this , we use the rkhs space @xmath175 defined on @xmath66 ( resp .",
    "@xmath67 ) corresponding to the wendland function kernel @xmath176 with smoothness index @xmath177 , such that @xmath43 if @xmath37 is odd , or @xmath178 if @xmath37 is even .",
    "correspondingly , this implies that @xmath179 when @xmath37 is odd , and @xmath180 when @xmath37 is even . here , @xmath181 is norm - equivalent to @xmath182 ( resp .",
    "@xmath183 ) , where @xmath184 .",
    "these function spaces consist of smooth functions as a consequence of the following generalised sobolev inequality ( for a proof , see e.g. ( * ? ? ?",
    "* chapter 5.7 , theorem 6 ) ) .",
    "[ lem : gensobolev ] let @xmath185 be a bounded open set with @xmath29 boundary .",
    "for @xmath186 where @xmath187 , we have @xmath188 if @xmath37 is odd , and @xmath189 is any element in @xmath190 if @xmath37 is even .",
    "[ cor : smoothnessk1k2 ] for @xmath191 and @xmath192 , we have @xmath193 that extends @xmath194 to @xmath195 such that @xmath196 on @xmath27 .",
    "then , from lemma [ lem : gensobolev ] we have @xmath197 then and follow from using the norm equivalence of @xmath167 to @xmath168 , and that @xmath41 .",
    "inequality follows similarly , also using @xmath179 when @xmath37 is odd , and @xmath180 when @xmath37 is even .      in this section",
    "we introduce the generalised interpolant that is used to approximate the lyapunov functions @xmath10 and @xmath11 .",
    "consider a general interpolation setting where @xmath198 is a bounded domain having a lipschitz boundary .",
    "let @xmath199 be a linear differential operator and @xmath200 be a set of pairwise distinct points which do not contain any singular points of @xmath199 .",
    "( a point @xmath201 is a singular point of @xmath199 if @xmath202 , see also @xcite . )",
    "we define linear functionals @xmath203    [ def : genint ] suppose we have values @xmath204 for @xmath205 for a function @xmath206 . given a sufficiently smooth kernel @xmath207 , define the generalised interpolant as @xmath208 where @xmath209 is the linear function applied to one argument of the kernel .",
    "the coefficient vector @xmath74 is the solution of @xmath210 with the interpolation matrix @xmath211 given by @xmath212    [ rem : sgenint ] according to the above definition , we have @xmath213 . in addition , it can be shown that the generalised interpolant above is the unique norm - minimal interpolant in @xmath109 , see @xcite .",
    "the matrix @xmath214 is guaranteed to be invertible due to our choice of the wendland function kernel @xmath130 ( * ? ? ?",
    "* section 3.2.2 ) , and since @xmath215 does not contain any singular points .",
    "we conclude this section by citing the following theorem from @xcite , which provides convergence estimates for approximating lyapunov functions @xmath216 ( resp .",
    "@xmath217 ) with the generalised interpolants @xmath218 ( resp .",
    "@xmath219 ) as above , for a known dynamical system @xmath220 .",
    "[ thm : giewen ] let @xmath221 with @xmath222 , where @xmath177 is the smoothness index of the compactly supported wendland function .",
    "let @xmath223 if @xmath37 is odd or @xmath224 if @xmath37 is even .",
    "consider the dynamical system defined by the ordinary differential equation @xmath220 , where @xmath225 .",
    "let @xmath226 be an equilibrium such that the real parts of all eigenvalues of @xmath227 are negative , and suppose @xmath228 is bounded in @xmath9 .",
    "let @xmath58 be a non - characteristic hypersurface as in definition [ def : noncharhyp ] , with @xmath229 and @xmath230 .",
    "let @xmath231 , @xmath232 be the lyapunov functions of theorems [ thm : vlyapunovconverse ] and [ thm : tlyapunovconverse ] for the system @xmath220 , with @xmath233 for @xmath102 .",
    "given pairwise distinct sets of points @xmath234 in @xmath9 ( not containing @xmath6 ) and @xmath235 in @xmath58 , and let @xmath46 be a bounded domain with lipschitz boundary , with @xmath236 .",
    "let @xmath218 and @xmath219 be the generalised interpolants satisfying @xmath237 and let the fill distance of the set of points @xmath215 in @xmath238 and @xmath239 in @xmath58 be @xmath240 and @xmath241 respectively .",
    "then for @xmath242 sufficiently small , the following estimates hold : @xmath243 the algorithm -------------    here we present the algorithm for which the estimate given in theorem [ thm : mainresult ] holds . the algorithm is actually split into two parts .",
    "the first part computes @xmath244 as an approximation to @xmath18 ( algorithm [ alg : approxf ] ) , and the second part computes @xmath30 or @xmath31 as an approximation to the lyapunov functions @xmath10 or @xmath11 respectively given in theorems [ thm : vlyapunovconverse ] and [ thm : tlyapunovconverse ] ( algorithm [ alg : approxv ] or [ alg : approxt ] ) . as discussed in  [ sec : sobolevspacerkhs ] , we will use two rkhs spaces @xmath163 and @xmath175 for the two parts of the algorithm , corresponding to the wendland function kernels @xmath164 and @xmath176 with smoothness indices @xmath165 and @xmath177 respectively .",
    "we recall that the smoothness indices are chosen such that @xmath41 with @xmath245 , and @xmath246 if @xmath37 is odd , or @xmath247 if @xmath37 is even .",
    "recall that our sampled data values @xmath248 take the form @xmath22 , with @xmath249 a random variable drawn from a probability distribution with zero mean and variance @xmath250 .",
    "our approximation scheme for @xmath18 employs a regularised least squares algorithm ( see e.g. @xcite and its references ) to approximate each component @xmath251 , @xmath252 .",
    "we also introduce a weighting @xmath253 corresponding to the voronoi tessellation associated with the points @xmath254 @xcite .",
    "[ def : voronoi ] let @xmath255 be compact .",
    "for a set of pairwise distinct points @xmath256 , the voronoi tessellation is the collection of pairwise disjoint open sets @xmath257 , @xmath258 defined by @xmath259    the weighting @xmath253 is then defined by @xmath260 , where @xmath123 is the strictly positive borel measure from  [ sec : rkhs ] .",
    "[ alg : approxf ] fix a regularisation parameter @xmath261 , and define @xmath262 as the diagonal matrix with diagonal elements @xmath263 , @xmath258 .",
    "the approximation @xmath244 for @xmath18 is constructed component - wise .",
    "that is , for each @xmath264 , we approximate the @xmath265-th component @xmath251 by @xmath266 , defined by @xmath267 , where the coefficients @xmath268 may be calculated as the solution to the matrix equation @xmath269 here @xmath270 where @xmath271 is simply the @xmath265-th component of @xmath272 , and @xmath273 is a symmetric matrix defined by @xmath274 .",
    "we note here that due to our choice of rkhs the matrix @xmath275 is positive definite ( * ? ? ?",
    "* proposition 3.3 ) , and therefore the matrix @xmath276 is invertible , as it is the sum of two positive definite matrices .",
    "the error in our approximation of @xmath18 by @xmath244 is studied in  [ sec : errorf ] .",
    "we will show that this error may be bounded in the supremum norm on the domain @xmath27 , depending on the density of the data in @xmath27 and the choice of regularisation parameter @xmath60 .",
    "once we have our approximation @xmath244 , then we construct our lyapunov function approximation with the generalised interpolant as in theorem [ thm : giewen ] , where we set @xmath277 .",
    "therefore we have the following algorithm [ alg : approxv ] for @xmath30 , or algorithm [ alg : approxt ] for @xmath31 .",
    "these algorithms involve sampling our approximation @xmath244 at a discrete set of points .    algorithm    [ alg : approxv ] first run algorithm [ alg : approxf ] on the sampled data set @xmath278 to compute @xmath279 .",
    "define a set of pairwise distinct points @xmath280 , with @xmath281 for all @xmath205 .",
    "the approximation @xmath282 for the lyapunov function @xmath10 ( see theorem [ thm : vlyapunovconverse ] ) is given by @xmath283 , where @xmath284 is the linear functional @xmath285 applied to one argument of the kernel .",
    "the coefficients @xmath286 are given by @xmath287 here @xmath288 is a symmetric matrix defined by @xmath289 and @xmath290 .    as before ,",
    "the choice of rkhs guarantees that the matrix @xmath291 will be positive definite , provided that @xmath292 for all @xmath293 .",
    "to approximate @xmath11 , we assume that a non - characteristic hypersurface for @xmath18 has been defined as @xmath294 according to definition [ def : noncharhyp ] , for which @xmath96 on @xmath58 , @xmath95 .",
    "[ alg : approxt ] first run algorithm [ alg : approxf ] on the sampled data set @xmath278 to compute @xmath279 .",
    "define a set of pairwise distinct points @xmath295 , with @xmath281 for all @xmath205 , and @xmath296 for @xmath297 .",
    "the approximation @xmath298 for the lyapunov function @xmath11 ( see theorem [ thm : tlyapunovconverse ] ) is given by @xmath299 , where the coefficients @xmath300 are computed as the solution to the matrix equation @xmath301 and the submatrices @xmath302 , @xmath303 and @xmath304 have elements defined by @xmath305 , @xmath306 and @xmath307 .",
    "the vector @xmath308 is given by @xmath309 , @xmath205 and @xmath310 , @xmath297 .",
    "it may again be shown that the matrix @xmath311 will be positive definite , providing that @xmath292 for all @xmath205 , for details see ( * ? ? ?",
    "* section 3.2.2 ) .",
    "our error in the approximations @xmath30 and @xmath31 will depend primarily on the error induced by algorithm [ alg : approxf ] , which in turn depends on the density of the data , as well as the regularisation parameter .",
    "in addition , there will be an error due to the discrete sampling of @xmath244 in algorithms [ alg : approxv ] and [ alg : approxt ] .",
    "this error will depend on the density of the sample points @xmath215 ( chosen by the user ) , which in principle can be entirely independent of the original set of points @xmath312 provided by the data .",
    "the overall error is the subject of  [ sec : proofofmainthm ] , which will prove the estimate given in theorem [ thm : mainresult ] .",
    "in this section we estimate the error @xmath314 for each @xmath252 .    we have sampled data of the form @xmath19 in @xmath20 , @xmath21 , with @xmath22 .",
    "we assume that the one - dimensional random variables @xmath23 , where @xmath21 and @xmath24 , are independent random variables drawn from a probability distribution with zero mean and variance @xmath25 bounded by @xmath26 .    in order to ease notation , and since each @xmath315 is calculated independently for each @xmath265 , we shall henceforth drop the superscript @xmath265 and consider the data to be of the form @xmath316 . note that in this section we shall only be working with the rkhs @xmath167 .",
    "the following operator definition will enable convenient function representations ( c.f .",
    "@xcite ) .    given a set @xmath317 of pairwise distinct points in @xmath28 , the sampling operator @xmath318 is defined as @xmath319    the adjoint operator @xmath320 can also be derived as follows .",
    "let @xmath321 , then we have @xmath322 the final equality follows from the reproducing property .",
    "so then @xmath323 for all @xmath321 .",
    "the following lemma shows that the function @xmath244 calculated in algorithm [ alg : approxf ] is the minimiser of a regularised cost function .",
    "we omit the proof , which is similar to that contained in ( * ? ? ?",
    "* theorem 1 ) , except for the introduction of the weights @xmath324 .",
    "[ lem : fzlambda ] let @xmath325 let @xmath326 be the diagonal matrix with entries @xmath327 , and let @xmath328 .",
    "if @xmath329 is invertible , then @xmath244 exists and is given by @xmath330 furthermore , if @xmath331 , then the coefficients @xmath268 may be calculated as @xmath332 where @xmath273 is the symmetric matrix defined by @xmath333 .",
    "our strategy to prove convergence of the estimate @xmath244 to @xmath18 combines and adapts results contained in @xcite .",
    "the main difference in our case to the standard assumptions in learning theory is that the data @xmath334 is not necessarily generated from an underlying probability distribution . instead",
    ", our data is generated by the underlying dynamical system , and the data sites may be situated arbitrarily .",
    "they could potentially be chosen deterministically , or indeed may be generated randomly .",
    "the assumptions made in @xcite correspond to this setting , but we would like to provide estimates in terms of the density of the data .",
    "this is why we have introduced the weights @xmath335 corresponding to the @xmath123-volume voronoi tessellation ( c.f . also @xcite , where a weighting scheme is introduced in a different setting ) .",
    "[ def : filldistance ] let @xmath336 be a compact set and @xmath337 be a grid , where @xmath338 .",
    "we denote the _ fill distance _ of @xmath312 in @xmath339 as @xmath340 in particular , for all @xmath341 there is a grid point @xmath342 such that @xmath343 .    in order to provide an estimate for @xmath344 , we first define @xmath345 by @xmath346 where @xmath347 .",
    "recall from section [ sec : rkhs ] that @xmath123 is a finite strictly positive borel measure on @xmath27 .",
    "the function @xmath348 may be seen as a ` noise - free ' version of @xmath244 , such that in the case of no noise , i.e. @xmath349 for all @xmath116 , then we would have @xmath350 .",
    "correspondingly , the function @xmath351 can be seen as a ` data - free ' limit of @xmath348 , or the limiting function as the data sites @xmath312 become arbitrarily dense in @xmath27 . finally , if @xmath352 , then @xmath18 is the ` regularisation - free ' version of @xmath351  the limit of @xmath351 as @xmath353 .",
    "the strategy is to break down the estimate of @xmath354 according to @xmath355 and estimate each of the three terms in the inequality .",
    "these three terms correspond to errors incurred by the noise ( sample error ) , the finite set of data sites ( integration error ) and the regularisation parameter @xmath60 ( regularisation error ) .",
    "an estimate for @xmath356 for an unweighted approximation scheme is given in theorem 2 of @xcite .",
    "a similar result is given in the following lemma , that incorporates the weights of our scheme .",
    "the proof follows that of @xcite , and here we will just sketch the main adaptations .",
    "importantly , our estimate provides convergence of @xmath244 to @xmath348 as the data sites @xmath312 become more dense , or as the quantity @xmath50 tends to zero .",
    "[ lem : sampleerror ] for @xmath357 , for every @xmath358 , with probability @xmath359 , we have @xmath360 where @xmath361 and @xmath362 .    first note that if @xmath65 then @xmath363 is invertible .",
    "this follows since it is the sum of a positive and a strictly positive operator on @xmath167 .",
    "similar to ( * ? ? ?",
    "* theorem 2 ) , we have @xmath364 since we have assumed that the @xmath365 random variables are independent with zero mean , we have that @xmath366 where the inequality follows from our assumption that @xmath367",
    ". then it follows that @xmath368 the operator @xmath369 is estimated analagously to ( * ? ? ?",
    "* proposition 1 ) to obtain @xmath370 finally , for @xmath358 , application of the markov inequality to the random variable @xmath356 gives @xmath371 combining the above together with proves the lemma .      to establish our estimate for the integration error we need to make additional assumptions on the choice of borel measure @xmath123 .",
    "namely , we will require that it is strongly continuous ( c.f .",
    "@xcite ) :    a borel measure @xmath123 is strongly continuous if for all hyperplanes @xmath372 , we have @xmath373 .    note that this requirement implies that the boundaries of the voronoi tessellation have @xmath123-measure zero .",
    "lebesgue measure is still an example measure that satisfies all of our assumptions , recall section [ sec : rkhs ] .",
    "an estimate for the integration error @xmath374 is given in the following lemma .",
    "[ lem : integrationerror ] let @xmath123 be a ( finite ) strictly positive , strongly continuous borel measure on @xmath27 . for @xmath357 , we have @xmath375    it is shown in @xcite that the solution to for @xmath357 is given by @xmath376 where @xmath377 was defined in equation .",
    "now we have @xmath378 where the second equality follows from and the final equality follows from the definition of @xmath379 and its adjoint .",
    "recall that we have chosen the weighting @xmath34 to be equal to the @xmath123-volume of the voronoi tessellation associated to the data sites @xmath312  that is , @xmath380 .",
    "also , since @xmath123 is strongly continuous it holds that @xmath381 and so @xmath382 the second equality follows from the fact that @xmath383 and @xmath110 belong to @xmath167 , and are therefore bounded and lipschitz on @xmath27 ( cf . corollary [ cor : smoothnessk1k2 ] ) .",
    "this , together with proves the lemma .      for the regularisation error we recall the following result from ( * ? ? ?",
    "* lemma 3 ) ( c.f . also ( * ? ? ? * theorem 4 ) ) :      altogether , from lemmas [ lem : sampleerror ] , [ lem : integrationerror ] and [ lem : regularisationerror ] and equation we have with probability @xmath53 @xmath386 applying equation again yields @xmath387 where the constant @xmath388 depends on @xmath18 , @xmath37 , @xmath69 and the choice of rkhs @xmath167 .",
    "now it is clear that the above bound can be made arbitrarily small as @xmath50 and @xmath389 tend to zero , if @xmath60 also tends to zero at an appropriate rate . with the choice of regularisation parameter @xmath390 with probability @xmath53 , we obtain the estimate @xmath391 proof of theorem [ thm : mainresult ] ---------------------------------    let @xmath84 and @xmath91 be the lyapunov functions for @xmath18 as defined in theorems [ thm : vlyapunovconverse ] and [ thm : tlyapunovconverse ] .",
    "then we have @xmath392 with @xmath87 also defined in theorem [ thm : vlyapunovconverse ] .",
    "similarly , @xmath393 for @xmath159 , where @xmath294 is a non - characteristic hypersurface according to definition [ def : noncharhyp ] ( with @xmath98 ) , and @xmath95 .",
    "as stated in theorem [ thm : vlyapunovconverse ] , the lyapunov function @xmath10 is uniquely defined up to a constant .",
    "we will fix @xmath10 by setting @xmath394 .",
    "the lyapunov function @xmath11 is uniquely defined according to the above properties .",
    "the following lemma provides an alternative characterisation of the lyapunov function @xmath10 , which will be useful later in the section .",
    "[ lem : vxiv ] let @xmath84 be the uniquely defined lyapunov function as above , and @xmath294 ( @xmath98 ) is a non - characteristic hypersurface according to definition [ def : noncharhyp ] . define @xmath395 by @xmath396 for @xmath102 .",
    "also recall @xmath397 denotes the flow operator of , and define the function @xmath398 by @xmath399 .",
    "then @xmath400    it is shown in ( * ? ? ?",
    "* theorem 2.38 ) that the function @xmath401 is well - defined and belongs to @xmath402 .",
    "also in ( * ? ? ?",
    "* theorem 2.46 ) it is shown that @xmath403 let @xmath404 .",
    "then , for @xmath104 , @xmath405 which proves the lemma .    [ rem : xit ] similarly , the lyapunov function @xmath11 has the representation @xmath406 with @xmath95 as above .",
    "we aim to approximate the lyapunov functions @xmath10 and @xmath11 in a compact subset of the basin of attraction @xmath9 .",
    "this subset is given by @xmath407 for a given @xmath408 , where @xmath238 is compact , cf .",
    "theorem [ thm : mainresult ] .",
    "see figure [ fig : domains ] for a sketch of these domains .    for the approximation of @xmath10",
    ", we define @xmath409 with @xmath410 large enough so that @xmath411 .",
    "similarly for @xmath11 , we choose @xmath412 with @xmath410 large enough so that @xmath413 .",
    "recall that @xmath58 is a non - characteristic hypersurface for @xmath18 ( and thus also for @xmath244 , if @xmath244 and @xmath18 are sufficiently close in supremum norm ) .",
    "additionally , we may define @xmath414 with @xmath415 sufficiently large so that @xmath416 .",
    "note that @xmath417 is a non - characteristic hypersurface for @xmath18 ( also for @xmath244 ) , defined by some @xmath418 .",
    "then we define the lipschitz domains @xmath419 and @xmath420 ( cf . theorem [ thm : giewen ] ) , and note that @xmath421 and @xmath422 . also note that all orbits ( for @xmath18 and @xmath244 ) enter and exit @xmath423 ( and @xmath424 ) only once .",
    "our algorithm detailed in ",
    "[ sec : algorithm ] computes the generalised interpolant approximations @xmath30 and @xmath31 corresponding to the vector field approximation @xmath244 ( as in theorem [ thm : giewen ] with @xmath277 ) .",
    "note that for @xmath425 sufficiently small ( recall the superscript @xmath265 denotes the @xmath265-th component ) , @xmath244 does not have any equilibria in @xmath66 ( resp .",
    "@xmath67 ) . similarly , @xmath426 are both non - characteristic hypersurfaces for @xmath244 , and all trajectories in @xmath66 ( resp .",
    "@xmath67 ) eventually enter ( and stay in ) the region defined by @xmath427 .",
    "in fact , for @xmath50 and @xmath389 sufficiently small , @xmath244 and @xmath18 are even close in a @xmath428 sense , as we will show in the following lemmas [ lem : fzlambdafstarbounded ] and [ lem : fzlambdafstarepsilon ] .",
    "[ lem : fzlambdafstarbounded ] for @xmath65 , for every @xmath52 , with probability @xmath53 , we have @xmath429 and equation , we see that for each @xmath252 : @xmath430 we will show that @xmath431 is bounded independently of @xmath432 . to see this , first note that due to the choice of the positive definite wendland function kernel @xmath433 , that it is always possible to find a norm - minimal function @xmath434 that interpolates the data .",
    "that is , @xmath435 is the solution to the problem @xmath436 therefore we have that @xmath437 . now from we have the following : @xmath438 so then @xmath439 .",
    "in lemma [ lem : sampleerror ] we have provided a bound for @xmath440 for a given probability @xmath359 . then together we find with probability @xmath359 ,",
    "@xmath441 which proves the lemma .    we will need the following convergence result in lemma [ lem : fzlambdafstarepsilon ] .",
    "[ thm : wenrie ] suppose @xmath442 is bounded and satisfies an interior cone condition with radius @xmath443 and angle @xmath444 .",
    "let @xmath445 be a positive integer , @xmath446 , @xmath136 , @xmath447 and let @xmath448 satisfy @xmath449 , or , if @xmath450 , @xmath451 .",
    "then there exists a constant @xmath452 depending only on @xmath453 such that every discrete set @xmath454 with mesh norm @xmath455 sufficiently small , and every @xmath456 the estimate @xmath457 is satisfied . here , @xmath458 , and",
    "we use the notation @xmath459 to denote the restriction of @xmath460 to the set @xmath461 .",
    "[ lem : fzlambdafstarepsilon ] let @xmath408 be arbitrarily small . for every @xmath358 , there exists @xmath462 such that when @xmath463 , and @xmath464 chosen according to , the following estimate holds with probability @xmath53 : @xmath465 ( @xmath37 odd ) , and @xmath466 ( @xmath37 even ) .",
    "note that since @xmath27 has a @xmath29 boundary , it satisfies the interior cone condition from theorem  [ thm : wenrie ] ( see ( * ? ? ? * definition 3.6 ) ) .",
    "let @xmath467 be such that @xmath468 . recall that @xmath41 with @xmath245 .",
    "then when @xmath37 is odd , we have @xmath469 . when @xmath37 is even , we have @xmath470 and so @xmath471 .",
    "using theorem [ thm : wenrie ] , and the fact that @xmath167 and @xmath472 are norm - equivalent , we have the following estimate : @xmath473 note that we have replaced @xmath474 in theorem [ thm : wenrie ] with @xmath314 . then the discrete set @xmath461 from theorem [ thm : wenrie ]",
    "may be taken to be any discrete set in @xmath27 , and so the fill distance @xmath455 in the above can be taken to be arbitrarily small .",
    "now , from we see that @xmath314 can be made arbitrarily small for small @xmath50 and @xmath389 , and suitably chosen @xmath464 as in .",
    "the estimate holds with probability @xmath53 ( for @xmath52 ) , where @xmath475 here is the same as in lemma [ lem : fzlambdafstarbounded ] , as the estimate depends on the same probabilistic inequality for @xmath476 ( cf . ) .",
    "then we have from ( and using again the norm - equivalance of @xmath167 and @xmath472 ) , that @xmath477 is bounded , say @xmath478 .",
    "now , given @xmath479 , setting @xmath480 we have that @xmath481 now using @xmath482 gives the bound @xmath483 then by lemma [ lem : gensobolev ] ( also using arguments similar to corollary [ cor : smoothnessk1k2 ] since @xmath27 is closed ) , we have that @xmath484 and setting @xmath485 proves the lemma .",
    "it follows that for sufficiently small @xmath50 and @xmath389 , that ( with probability @xmath53 ) @xmath244 will have an equilibrium close to @xmath6 which is also exponentially asymptotically stable .",
    "in addition , the non - characteristic hypersurfaces @xmath58 and @xmath486 for @xmath18 will also be non - characteristic hypersurfaces for @xmath244 ( as will the level sets @xmath487 , resp .",
    "@xmath488 ) . in this case",
    "we can define the following ` lyapunov - type ' functions for @xmath244 .",
    "[ def : vzlambdatzlambda ] let @xmath489 denote the flow operator for the system @xmath490 . for @xmath50 and @xmath389 sufficiently small , @xmath464 chosen according to , and @xmath52 , @xmath58 will be a non - characteristic hypersurface for @xmath244 with probability @xmath53 .",
    "then the function @xmath491 given by @xmath492 is well - defined . by a slight abuse of notation",
    "we will also similarly define @xmath493 .",
    "we define the functions @xmath494 and @xmath495 by @xmath496 where @xmath497 and @xmath95 are as in lemma [ lem : vxiv ] and equation respectively .    in the proof of the following lemma",
    "we show that in fact @xmath498 , @xmath499 and @xmath500 .",
    "[ lem : vzlambdabounded ] for every @xmath501 , and every @xmath358 , there is @xmath502 such that if @xmath503 and @xmath464 is chosen according to , then we have with probability @xmath359 : @xmath504 , as the proof for @xmath505 is similar .",
    "we will show that @xmath499 , and @xmath506 can be made arbitrarily small as @xmath507 .",
    "then the result will follow from lemma [ lem : fzlambdafstarepsilon ] .",
    "the proof follows the ideas contained in ( * ? ? ?",
    "* theorem 2.38 ) .",
    "we consider a one - parameter family of vector fields @xmath508 , @xmath509 , in the @xmath428 topology such that @xmath510 .",
    "let @xmath511 denote the corresponding one - parameter family of flow operators and note that @xmath512 is @xmath428 in each of its arguments . for @xmath48",
    "sufficiently small , @xmath513 , @xmath58 is a non - characteristic hypersurface for each @xmath514 , and all orbits of @xmath514 in @xmath66 enter and exit @xmath66 precisely once .",
    "then we define the one - parameter family of functions @xmath515 by @xmath516 .",
    "we show that @xmath517,\\mathbb{r})$ ] by the implicit function theorem .",
    "note that @xmath444 is the solution @xmath518 to @xmath519 where @xmath520 is as in definition [ def : noncharhyp ] .",
    "let @xmath521 be a solution to .",
    "then we have @xmath522 by definition [ def : noncharhyp ] .",
    "but since @xmath98 and @xmath512 is a @xmath428 function in @xmath523 , we have that @xmath517,\\mathbb{r})$ ] by the implicit function theorem .    for each @xmath524 , define @xmath525 then it follows that @xmath526,\\mathbb{r})$ ] .",
    "it may also readily be verified that @xmath527 note that @xmath528 by lemma [ lem : vxiv ] .",
    "now it is clear by that @xmath529 as @xmath530 .",
    "but since @xmath514 is any one parameter family in the @xmath428 topology with @xmath531 , we use lemma [ lem : fzlambdafstarepsilon ] ( and @xmath532 ) to deduce that @xmath499 , and @xmath533 as @xmath534 for @xmath50 and @xmath389 sufficiently small , and @xmath464 chosen according to .",
    "[ rem : orbdervtzlambda ] it follows from the proof of lemma [ lem : vzlambdabounded ] and from and that provided @xmath535 is well defined ( which is guaranteed with probability @xmath53 ) , we have : @xmath536    we now define a pairwise distinct , discrete set of points @xmath537 ( resp .",
    "@xmath67 ) . note that these points need not be the same as @xmath312 .",
    "let @xmath240 be the fill distance of @xmath215 in @xmath66 ( resp .",
    "@xmath67 ) .",
    "we compute our approximations @xmath30 and @xmath31 according to our algorithm given in  [ sec : algorithm ] .",
    "we have ( for @xmath30 , the arguments for @xmath31 are similar ) @xmath538 then we have , for @xmath539 , @xmath540 where recall that @xmath541 is the degree of the sobolev rkhs @xmath181 .",
    "the last inequality above follows from remark [ rem : orbdervtzlambda ] , theorem [ thm : giewen ] and @xmath542 .",
    "recall the superscript @xmath265 denotes the @xmath265-th component of a @xmath37-dimensional vector .",
    "now we use an estimate similar to ( 3.16 ) from ( * ? ? ? * lemma 3.9 ) : recall that @xmath543 . then from corollary [ cor : smoothnessk1k2 ] we have @xmath544 recall that @xmath30 is the norm - minimal generalised interpolant to @xmath545 in @xmath181 ( since @xmath545 satisfies ) , and @xmath181 is norm - equivalent to @xmath182",
    ". then @xmath546 .",
    "in addition , lemma [ lem : vzlambdabounded ] shows that @xmath547 and so @xmath548 for sufficiently small @xmath50 , @xmath389 with probability @xmath53 .",
    "then it follows that @xmath549 we may similarly show @xmath550    furthermore , we can directly apply from theorem [ thm : giewen ] to obtain @xmath551.@xmath552    furthermore , as @xmath314 converges to zero , we can shrink the ball @xmath64 ( and therefore also @xmath417 ) towards @xmath6 . the domains @xmath66 and @xmath67 will converge towards @xmath553 and @xmath554 respectively , and therefore @xmath545 and @xmath505 will converge to @xmath10 and @xmath11 respectively .",
    "however , we do not give estimates for how fast @xmath389 and @xmath34 would need to converge to zero relative to @xmath555 .",
    "b. hamzi was supported by a marie curie fellowship grant number 112c006 .",
    "m. rasmussen was supported by an epsrc career acceleration fellowship ep / i004165/1 and k.n",
    ". webster was supported by the epsrc grant ep / l00187x/1 and a marie skodowska - curie individual fellowship grant number 660616 .",
    "99 r.  a.  adams , _ sobolev spaces _ , adademic press , new york , 1975",
    ". n.  bhatia , _ on asymptotic stability in dynamical systems _ , math .",
    "systems theory * 1 * ( 1967 ) , 113128 .",
    "n.  bhatia and g.  szeg , _ stability theory of dynamical systems _ , grundlehren der mathematischen wissenschaften * 161 * , springer , berlin , 1970 .",
    "j.  bouvrie , and b.  hamzi , balanced reduction of nonlinear control systems in reproducing kernel hilbert space , in _ proc .",
    "48th annual allerton conference on communication , control , and computing _ ( 2010 ) , 294301 , http://arxiv.org/abs/1011.2952 .",
    "j.  bouvrie and b.  hamzi , empirical estimators for the controllability energy and invariant measure of stochastically forced nonlinear systems , in _ proc . of the 2012 american control conference _",
    "( 2012 ) , ( long version at http://arxiv.org/abs/1204.0563 ) .",
    "f.  cucker and s.  smale , _ on the mathematical foundations of learning _ , bull .",
    "39 * number 1 ( 2001 ) , 149 .",
    "f.  cucker and s.  smale , _",
    "best choices for regularisation parameters in learning theory _ , found .",
    "* 2 * ( 2002 ) , 413428 .",
    "l.  evans , _ partial differential equations _ , vol .",
    "19 of _ graduate studies in mathematics _ , ams , providence , rhode island , 1998 .",
    "t.  evgeniou , m.  pontil and t.  poggio , _ regularization networks and support vector machines _ ,",
    "comput . math .",
    "* 13 * ( 2000 ) , 150 .",
    "p.  giesl , _ construction of global lyapunov functions using radial basis functions _ , lecture notes in mathematics .",
    "springer berlin heidelberg , 2007 .",
    "p.  giesl and s.  hafstein , _ computation and verification of lyapunov functions _",
    ", siam j. appl .",
    "* 14 * no .",
    "4 ( 2015 ) , 16631698 .",
    "p.  giesl and s.  hafstein , _ review on computational methods for lyapunov functions _",
    ", discrete and continuous dynamical systems series b * 20 * no . 8 ( 2015 ) , 22912331 .",
    "p.  giesl and h.  wendland , _ meshless collocation : error estimates with application to dynamical systems _ , siam j. num . anal .",
    "* 45 * no . 4 ( 2007 ) , 17231741 .",
    "w.  hahn , _ theorie und anwendung der direkten methode von ljapunov _",
    ", ergebnisse der mathematik und ihrer grenzgebiete * 22 * , springer , berlin , 1959 . w.  hahn , _ stability of motion _ , springer , new york , 1967 .",
    "a.m.  lyapunov , _ problme gnral de la stabilit du mouvement _ , ann .",
    "toulouse * 9 * ( 1907 ) , 203474 . translation of the russian version , published 1893 in comm .",
    "newly printed : ann . of math .",
    "* 17 * , princeton , 1949 .",
    "y.  lin , e.  d.  sontag and y.  wang , _ a smooth converse lyapunov theorem for robust stability _ , siam j. control optim . * 34 * ( 1996 ) , 124160 . c.  kellett , _ classical converse theorems in lyapunov s second method _ , discrete contin .",
    "b , * 8 * ( 2015 ) ,",
    "23332360 . j.  l.  massera , _ on liapounoff s conditions of stability _",
    ", ann . of math . * 50 * number 3 ( 1949 ) , 705721 . f.j .",
    "narcowich , j.d .",
    "ward , and h.  wendland , _ sobolev bounds on functions with scattered zeros , with applications to radial basis function surface fitting _ , mathematics of computation , * 74 * ( 2004 ) , 743763 .",
    "r.  opfer , _ multiscale kernels _ , adv .",
    "* 25 * ( 2006 ) , 357380 .",
    "r.  opfer , _ tight frame expansions of multiscale reproducing kernels in sobolev spaces _ , appl .",
    ", * 20 * ( 2006 ) , 357374 .",
    "a.  papachristodoulou and s.  prajna , on the construction of lyapunov functions using the sum of squares decomposition , proceedings of the 41st ieee conference on decision and control , 2002 .",
    "g.  pags , _ a space quantization method for numerical integration _ , j. comp .",
    "appl . math .",
    "* 89 * ( 1997 ) , 138 .",
    "s.  smale and d .- x .",
    "shannon sampling and function reconstruction from point values _ , bull .",
    "* 41 * ( 2004 ) , 279305 .",
    "s.  smale and d .- x .",
    "shannon sampling ii : connections to learning theory _ ,",
    "19 * ( 2005 ) , 285302 .",
    "s.  smale and d .- x .",
    "zhou , _ learning theory estimates via their integral operators and their approximations _ ,",
    "* 26 * issue 2 ( 2007 ) , 153172 .    s.  smale and d .- x .",
    "zhou , _ online learning with markov sampling _ , anal .",
    "appl . , * 7 * ( 2009 ) , 87113 .",
    "g.  voronoi , _ recherches sur les parallelodres primitives _ , j. reine angew . math . * 134 * ( 1908 ) , 198287 .",
    "f.  wesley wilson , jr .",
    ", _ smoothing derivatives of functions and applications _ ,",
    "amer . math .",
    "* 139 * ( 1969 ) , 413428 .",
    "h.  wendland , _ piecewise polynomial , positive definite and compactly supported radial functions of minimal degree _ , adv .",
    ", * 4 * ( 1995 ) , 3489396 .",
    "h.  wendland , _ scattered data approximation _ , cambridge monogr . appl .",
    "math . , cambridge university press , cambridge , uk , 2005 .",
    "h.  wendland and c.  rieger , _ approximate interpolation with applications to selecting smoothing parameters _",
    ", numer . math .",
    "* 101 * ( 2005 ) , 729748 ."
  ],
  "abstract_text": [
    "<S> methods have previously been developed for the approximation of lyapunov functions using radial basis functions . </S>",
    "<S> however these methods assume that the evolution equations are known . </S>",
    "<S> we consider the problem of approximating a given lyapunov function using radial basis functions where the evolution equations are not known , but we instead have sampled data which is contaminated with noise . </S>",
    "<S> we propose an algorithm in which we first approximate the underlying vector field , and use this approximation to then approximate the lyapunov function . </S>",
    "<S> our approach combines elements of machine learning / statistical learning theory with the existing theory of lyapunov function approximation . </S>",
    "<S> error estimates are provided for our algorithm . </S>"
  ]
}