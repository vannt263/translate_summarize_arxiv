{
  "article_text": [
    "average - consensus formation implies that a group of distinct nodes come to agree on the average of their initial values , see @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite for related work .",
    "past results indicate that obtaining average - consensus on a set of of @xmath11 initial vectors each with dimension @xmath12 requires at least one of the following assumptions :    * storage and communication of a set with cardinality upper bounded by @xmath13 at each node , e.g. the `` flooding '' method described for example in @xcite , @xcite ( where @xmath14 denotes the landau big oh ) * construction of directed acyclical graphs in the network topology @xcite , @xcite , @xcite * knowledge at the transmitting node of the receiving node s identity @xcite , @xcite , @xcite , @xcite * instantaneous communication as well as knowledge at the transmitting node of its out - degree @xcite , @xcite * strictly bi - directional and instantaneous communication @xcite , @xcite , @xcite , @xcite , @xcite , @xcite * instantaneous communication and symmetric probabilities of node communication @xcite , @xcite * an approximate average - consensus based on randomized number generation @xcite , @xcite , @xcite * pre - determined bounds on the communication delays as well as the use of averaging - weights that are globally balanced and pre - determined off - line @xcite , @xcite , @xcite , @xcite , @xcite , @xcite .",
    "this paper proposes four algorithms to solve the average - consensus problem under weaker communication conditions than those listed above .",
    "we denote the four algorithms _ bench - mark ( bm ) , distributed - averaging ( da ) , one - hop ( oh ) _ , and _ discretized distributed - averaging ( dda ) _ .",
    "+ ( i ) the bm algorithm is based on the `` flooding '' method described in @xcite , @xcite . we show in theorems @xmath15 that the bm algorithm achieves average - consensus given the weakest communication condition necessary for average - consensus under any distributed algorithm ( this is the @xmath16 condition , defined in sec.iv ) .",
    "+ ( ii ) as the main result , we show in theorem @xmath17 that the da algorithm ( a reduction of the bm algorithm ) can achieve average - consensus under a _ recurring _ @xmath16 condition ( this is the @xmath18 condition , defined in sec.iv ) . by `` recurring ''",
    "we mean that for an infinite set of disjoint time intervals , the @xmath16 condition occurs on each interval .",
    "previous results based on iterative averaging ( e.g. @xcite,@xcite,@xcite,@xcite,@xcite ) require special cases of the @xmath18 condition",
    ". + ( iii ) the oh and dda algorithms can be viewed respectively as simplified versions of the bm and da algorithms .",
    "we will show that analogous results hold under these algorithms with respect to the @xmath19 and @xmath20 conditions defined in sec.iv .",
    "in contrast to earlier work , the main results of this paper show that under general uni - directional connectivity conditions on the communication sequence , each proposed algorithm achieves average - consensus in the presence of    * arbitrary communication delays , * arbitrary link failures .",
    "another distinct contrast each of the proposed algorithms has with previously considered consensus algorithms is ,    * each node will know exactly when the true average - consensus estimate has been locally obtained , regardless of the communication pattern between nodes .",
    "of course our general results come at a price .",
    "the main drawback of three of our proposed algorithms ( da , dda , oh ) is that they require local storage and transmission upper bounded by @xmath21 , where we recall that @xmath11 is the network size and @xmath12 is the dimension of the initial consensus vectors .",
    "most average - consensus algorithms in the literature require only @xmath22 costs , however they also require assumptions such as instantaneous communication , pre - determined averaging weights , or control at the transmitting node of the receiver identity . our algorithms ( da , dda , oh ) require none of these assumptions and are particularly advantageous for average - consensus involving @xmath23 distinct scalars . in this case",
    "the transmission and storage cost of each algorithm is @xmath22 , hence the assumption of relatively weak communication conditions can be leveraged against past algorithms .",
    "there are several examples in the literature where @xmath23 .",
    "for instance , if each node observes a @xmath24 dimensional process or parameter in noise , then a distributed kalman filter or maximum - likelihood estimate requires an average - consensus on @xmath25 scalars ( see @xcite , @xcite ) .",
    "the first algorithm we consider ( bm ) is an obvious solution and is presented here only because ( i ) it serves as a bench - mark for the other algorithms ( ii ) the communication conditions necessary for its convergence will be used in our main results , and ( iii ) its formal description has many of the same properties as the other three proposed algorithms .",
    "the bm algorithm requires local storage and transmission of @xmath13 and has optimal convergence rate ( see theorem @xmath26-@xmath27 , in sec.iv ) .",
    "since the literature in consensus formation is substantial , we now give an overview of existing results and compare them with the results of this paper .",
    "for sufficiently small @xmath28 , if @xmath29 \\in \\mathbb{r}^n$ ] denotes the network state at time @xmath30 , then @xcite proves that each element in the sequence @xmath31 converges asymptotically to @xmath32 if each graph laplacian @xmath33 in the sequence @xmath34 is balanced and induces a strongly connected graph .",
    "the work @xcite generalizes this result by allowing @xmath35 to decrease at a sufficiently slow rate , and assuming only that there exists some integer @xmath36 such that the union of all graph laplacians over the interval @xmath37 $ ] induces a strongly connected graph for each @xmath38 .",
    "however , each graph laplacian in @xcite is still assumed to be balanced , and as is typical of many interesting papers on average - consensus , neither @xcite nor @xcite explain any method by which the nodes can _ distributively _ ensure each @xmath33 is balanced _ while _ the sequence @xmath39 is occurring .",
    "hence the results of these works assume that all averaging weights are globally pre - determined off - line , or in other words , every node in the network is assumed to know what averaging weights they should locally be using at each iteration to guarantee the resulting @xmath33 is globally balanced .",
    "in contrast , @xcite proposes a `` metropolis '' algorithm that requires a `` two - round '' signaling process wherein nodes can _ distributively _ compute local averaging weights .",
    "it is shown in @xcite that each element in the sequence @xmath31 converges asymptotically to @xmath32 under mild connectivity conditions on the sequence @xmath39 .",
    "the work @xcite also proposes a distributed algorithm that does not require pre - determined averaging weights , however @xcite assumes each transmitting node knows the number of nodes that will receive its message , even before the message is transmitted .",
    "similarly , the algorithm in @xcite assumes bi - directional communication , and furthermore each of the stated results in @xcite , @xcite , @xcite , @xcite assume that the communication is instantaneous .",
    "in contrast , only @xcite , @xcite and @xcite assume the communication is noiseless .",
    "the results in this paper do not assume instantaneous or bi - directional communication , nor do they assume that the transmitting node knows what node will receive their message or when .",
    "however , our results do require noiseless communication .",
    "the issue of noisy communication can be treated as a `` meta - problem '' that may be super - imposed upon the framework considered here .",
    "similar to our current approach , there has been much research that assumes noiseless communication ( for instance @xcite , @xcite , @xcite ) .",
    "conversely , there is a growing body of work that considers average - consensus formation in specifically noisy communication settings @xcite , @xcite , @xcite .",
    "works such as @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite require node communication properties that are special cases of the @xmath18 condition defined in sec.@xmath40 . however , besides the flooding bm method and the da algorithm proven to converge here , the only other known algorithm that can even be conjectured to almost surely obtain average - consensus under all @xmath18 sequences is a specific adaptation of the randomized information spreading ( ris ) algorithm proposed in @xcite .",
    "our adaptation of this algorithm is referred to as aris and is detailed in sec.@xmath41 of appendix vii .",
    "we note , however , that the lower bound on convergence rate derived in @xcite assumes instantaneous bi - directional communication , and furthermore , any version of the ris algorithm assumes that the initial consensus variables are all positive valued .",
    "the gossip algorithm proposed in @xcite as well as the aris algorithm are used as points of reference for the four algorithms proposed in this paper . in sec.@xmath42",
    "we compare the resource costs of all six algorithms , and in sec.@xmath43 the performance of each algorithm is illustrated by simulation under various randomized communication sequences when assuming a full network graph .",
    "we note that @xcite , @xcite , @xcite , @xcite , @xcite do not guarantee the final consensus value will equal the initial average ; @xcite proposes an update rule that assumes instantaneous bi - directional communication ; and @xcite , @xcite , @xcite assume pre - determined bounds on the communication delays as well as averaging - weights that are globally balanced at each iteration ( see theorem 5 , @xcite ) .",
    "in contrast , theorem @xmath17 in sec.iv states that the da algorithm will guarantee average - consensus under _ all _ @xmath18 sequences , regardless of the communication delays and without requiring any pre - determined balancing of the averaging weights .",
    "we note that a distinct feature that all four of the proposed algorithms have is that they each require the local initial consensus vector to be stored in the respective database of each node until average - consensus is locally obtained at that node . without this property ,",
    "each algorithm could still ensure a `` consensus formation '' under the exact same communication conditions assumed in our main results , however the final consensus value would not necessarily equal the initial average , which is desirable in most applications @xcite , @xcite , @xcite , @xcite , @xcite , @xcite .",
    "in further contrast to past results , the proofs of convergence used in this work do not rely on matrix theory @xcite , @xcite , lyapunov techniques @xcite , @xcite , or stochastic stability @xcite , @xcite , @xcite ; instead , for our main results we obtain a variety of lower bounds on the `` error '' reduction and show that under ( deterministic ) recurring connectivity conditions an average - consensus will asymptotically obtain in the @xmath44 norm . as a final note",
    ", we clarify that the communication is assumed to be causal , hence a signal can not be received at node @xmath45 before it has left node @xmath46 .",
    "given this assumption , our framework considers _ every _ possible sequence of signals , hence any realization of a ( causal ) stochastic communication model is a special case of our deterministic framework .",
    "sec.ii formulates the problem statement as well as our assumptions regarding the node communication and algorithm framework .",
    "sec.iii defines the four proposed algorithms .",
    "sec.iv states the communication conditions that are necessary and sufficient for each algorithm to obtain average - consensus .",
    "sec.v considers the numerical implementation of the four algorithms together with the two comparison algorithms gossip and aris .",
    "resource costs are given in sec.@xmath42 , and numerical simulations are presented in sec.@xmath43 .",
    "a summary of the results and suggested future work is provided sec.vi .",
    "the appendix vii presents the proofs of all theorems , the two comparison algorithms , four conjectures , the resource cost derivations , and an important example .",
    "this section formulates the average - consensus problem and lists the assumptions regarding communication between nodes .",
    "sec.@xmath47 below defines the graph theoretic model for consensus formation that will be subsequently analyzed , and sec.@xmath48 defines the class of the distributed algorithms we consider .",
    "sec.@xmath49 details the remaining assumptions that will be made on the node communication and computational abilities , and also explains the technique by which the four proposed algorithms will obtain average - consensus .",
    "let @xmath50 denote time ( the results of this paper assume a continuous time framework ; any discrete time index is a special case of this framework ) . at initial time @xmath51 ,",
    "consider a finite set of arbitrarily numbered nodes @xmath52 and a set of @xmath12-dimensional vectors @xmath53 .",
    "the set @xmath53 is referred to as the set of `` initial consensus vectors '' .",
    "suppose each node can locally store a `` knowledge set '' @xmath54 that consists of a group of scalars each with a distinct meaning .    * ( a1 ) : ( knowledge set assumption ) at any time @xmath50 , each node @xmath55 is equipped with a device that can update and store a `` knowledge set '' @xmath54 .",
    "for each @xmath55 , the knowledge set @xmath54 may have a time - varying cardinality .",
    "next we assume that a set @xmath56 can be transmitted from node @xmath46 at a time denoted @xmath57 , and received at node @xmath45 at a time denoted as @xmath58 , where due to causality @xmath59 .",
    "we refer to @xmath56 as a `` signal '' , or `` signal set '' .    *",
    "( a2 ) : ( signal set assumption ) at any time @xmath57 , each node @xmath60 has the ability to transmit a `` signal set '' @xmath61 that will be received at some node @xmath55 at time @xmath59 .    as our final condition",
    ", we assume that at @xmath51 each node @xmath55 will `` know '' its unique node identifier value @xmath45 , the network size @xmath11 , and the respective initial consensus vector @xmath62 .",
    "this is formalized as ,    * ( a3 ) : at time @xmath51 , the knowledge set @xmath63 of each node @xmath55 satisfies @xmath64 .    [ def1 ] under ( a1)-(a3 )",
    ", the average - consensus problem is solved at some time instant @xmath65 if and only if ( iff ) the _ average _ of the initial consensus vectors , @xmath66 is contained in the knowledge set @xmath54 of all nodes @xmath55 .",
    "we say that a specific node @xmath45 has obtained average - consensus at time @xmath65 iff @xmath67 .",
    "@xmath68    the four algorithms analyzed in this paper can be adapted so that the size of the network @xmath11 and unique node identifier @xmath55 can be computed during the averaging process , and thus they need not be initially known at any node . for simplicity , however , it will be assumed that the network size @xmath11 and unique node identifier @xmath45 are initially known at each node @xmath55 .      to provide a unifying theme for the algorithms discussed in this paper",
    ", we first define the class of distributed algorithms that will be considered for consensus formation .",
    "given the assumptions @xmath69 , we define a `` distributed algorithm '' in terms of its `` knowledge set updating rule '' @xmath70 together with a `` signal specification rule '' @xmath71 .",
    "the knowledge set updating rule @xmath72 defines the effect that a set of signals has on the knowledge set @xmath73 at the receiving node @xmath45 , whereas the signal specification rule @xmath74 defines the elements contained in the signal @xmath75 given as a function of the knowledge set @xmath76 at the transmitting node @xmath46 .",
    "if we assume that upon reception of a set of signals @xmath77 time elapses before the knowledge set is fully updated , then the class of distributed algorithms we consider may be defined as follows .",
    "@xmath78 @xmath79 @xmath80    the algorithms in this paper will assume that every knowledge set @xmath54 contains a local `` consensus estimate '' @xmath81 that represents the `` belief '' of node @xmath45 in regard to the average - consensus @xmath82 defined in @xmath83 , @xmath84 notice that using a local consensus estimate @xmath85 is necessary for any algorithm seeking to solve the average - consensus problem ; if there is no local consensus estimate then there is no means by which the knowledge set of any node can contain @xmath82 and hence the problem stated in definition @xmath86 is ill - posed .",
    "in contrast from any known past consensus algorithm , the four proposed algorithms here will also assume that at any time @xmath50",
    "the knowledge set @xmath54 of each node @xmath55 will contain a local `` normal consensus estimate '' @xmath87 , @xmath88 combining @xmath89 , @xmath90 , and @xmath91 we then have the initial knowledge set for each of the four proposed algorithms ,    * @xmath92 : @xmath93    define the `` error '' of the consensus estimate @xmath85 as follows , @xmath94 where @xmath82 is defined in @xmath83 .",
    "denote the `` network consensus error '' @xmath95 .",
    "we conclude this section with the following definition of what constitutes the solution to the average - consensus problem .",
    "[ def10 ] the average - consensus problem is solved at time @xmath65 iff the network consensus error is zero , that is , @xmath96",
    "@xmath97      below we detail the node communication and update assumptions that will be used by each of the four proposed algorithms .",
    "the final update condition we propose will explain the technique by which all four algorithms achieve average - consensus .    for any @xmath50 ,",
    "define @xmath98 as the right - hand limit of @xmath65 , that is @xmath99 . to construct a suitable average - consensus algorithm",
    "we assume the following conditions on the node communication and knowledge set updates :    * ( a5 ) : at no time does any node @xmath60 have the ability to know _ when _ the signal @xmath100 is transmitted , _ when _ the signal @xmath100 is received , or _",
    "node @xmath55 will receive the signal @xmath100 . *",
    "( a6 ) : at no time does any node @xmath55 have the ability to control _ when _ the signal @xmath100 is received , _ what _",
    "node @xmath60 transmitted the signal @xmath100 , or _ when _ the signal @xmath100 was transmitted .",
    "* ( a7 ) : each knowledge set satisfies @xmath101 at any time @xmath50 that node @xmath45 does not receive a signal ( recall that @xmath98 denotes the right - hand limit of @xmath65 ) . * ( a8 ) : when a signal @xmath100 is received , the knowledge set @xmath102 of the receiving node is updated in an arbitrarily small amount of time . * ( a9 ) : at most one signal can be received and processed by a given node at any given time instant .    note that ( a5)-(a6 ) imply the communication process is _ a priori _ unknown at every node .",
    "the assumption ( a7 ) implies that the node knowledge set @xmath54 can only change if a signal is received at node @xmath45 , and ( a8 ) implies that any signal @xmath100 transmitted from node @xmath46 is allowed to contain information that has been updated by a signal received at node @xmath46 at any time preceding @xmath103 .",
    "notice that ( a8 ) is realistic since all four of the proposed algorithms will require only a few arithmetic operations in the update process .",
    "assumption ( a9 ) is a technical requirement that simplifies the proofs of convergence .",
    "together ( a8 ) and ( a9 ) imply the knowledge set updating rule @xmath104 defined in @xmath105 reduces to , @xmath106 each algorithm we propose can be easily adapted if ( a8)-(a9 ) were relaxed , however this would be at the expense of simplicity in both our framework and analysis .    as our final update condition , we require that the local consensus estimate @xmath107 at the receiving node @xmath45 , as defined above @xmath90 , is updated based on the updated normal consensus estimate @xmath108 via the relation , @xmath109 where @xmath110 \\in \\mathbb{r}^{d \\times n}$ ] . under @xmath111",
    "it is clear that @xmath112 if @xmath113 , where @xmath114 denotes a vector that consists only of unit - valued elements .",
    "thus , in terms of definition @xmath115 , under @xmath111 and @xmath91 the average - consensus problem is solved at time @xmath65 if @xmath116 for all nodes @xmath55 .",
    "motivated by this fact , we propose for each of the four algorithms that the normal consensus estimate @xmath117 is updated based on the following optimization problem , @xmath118 note that from @xmath90 and @xmath91 each node @xmath55 will know it has obtained the true average - consensus value @xmath119 when the local normal consensus estimate @xmath117 satisfies the condition @xmath116 . in the next section we will define the knowledge set updating rule @xmath70 and signal specification rule @xmath71 for each of the four algorithms .",
    "we shall find that for each algorithm the update problem @xmath120 reduces to a least - squares optimization and a closed - form expression can be obtained for updated normal consensus estimate @xmath108 .",
    "with the above definitions , we are now ready to describe the four distributed algorithms that achieve average - consensus .",
    "the details of the two comparison algorithms can be found in sec.@xmath41 of appendix vii .",
    "all six algorithms ( the four presented below and the two comparison algorithms in sec.@xmath41 ) are defined using the abstract definition of the `` distributed algorithm '' given in sec.ii , that is @xmath121 .",
    "this section sets the stage for the convergence theorems presented in sec.iv .",
    "the bm algorithm obtains average - consensus trivially ; we propose it formally because the remaining three algorithms are specific reductions of it , and also because it requires communication conditions that will be used in our main result .",
    "the bm algorithm implies that the initial consensus vectors @xmath122 are essentially flooded through - out the network . in @xcite , @xcite the general methodology of the bm algorithm is discussed wherein it is referred to as `` flooding '' . for completeness of our results",
    ", we show in theorems @xmath26,@xmath27 that regardless of the communication pattern between nodes , there exists no distributed algorithm @xmath123 that can obtain average - consensus before the bm algorithm .",
    "this is why we have named it the `` bench - mark '' algorithm .",
    "let @xmath124 $ ] denote the kronecker delta function applied element - wise , and @xmath125 denote the @xmath126 standard unit vector in @xmath127 .",
    "the bm signal specification @xmath128 and knowledge set update @xmath129 are respectively defined as @xmath130 and @xmath131 below .",
    "@xmath132 @xmath133 @xmath134 @xmath135\\ ] ] @xmath136 @xmath137 @xmath138 @xmath139    in lemma @xmath140 and lemma @xmath141 of appendix vii we will prove that @xmath142 is the unique solution to @xmath120 under @xmath130 and @xmath131 , and that @xmath143 is the unique solution to @xmath120 under the initial knowledge set @xmath92",
    ". the update @xmath144 follows immediately from @xmath142 and the relation @xmath111 .",
    "notice that the bm algorithm updates @xmath131 , @xmath142 together with the signal specification @xmath130 imply @xmath145 iff @xmath146 , and likewise @xmath147 iff @xmath148 and @xmath149 .",
    "it thus follows that @xmath130 , @xmath131 and @xmath142 imply that the consensus estimate update @xmath150 defined in @xmath144 can be locally computed at node @xmath45 based only on @xmath102 and the received signal @xmath151 .",
    "besides flooding the initial consensus vectors , the bm algorithm @xmath0 has an additional feature that is not necessary but is rather practical : if @xmath152 then all @xmath11 of the initial consensus vectors are stored in @xmath153 , when this occurs the consensus estimate @xmath154 defined in @xmath144 will equal @xmath82 and thus node @xmath46 has obtained average - consensus . in this case",
    "all of the initial consensus vectors are deleted from @xmath153 , and any signal transmitted from @xmath46 contains only the consensus estimate @xmath155 and the vector @xmath152 . upon reception of a signal containing @xmath152 , the receiving node @xmath45 can delete all of their locally stored initial consensus vectors and set @xmath156 . in this way the average - consensus value @xmath82 can be propagated through - out the network without requiring all @xmath11 initial consensus vectors to be contained in every signal .",
    "see conjecture @xmath157 in sec.@xmath158 for a conjecture regarding the bm algorithm .",
    "the da algorithm that we now introduce , to the best of our knowledge , is new . to define the da update procedure ,",
    "let @xmath159 denote the pseudo - inverse of an arbitrary matrix v. the da signal specification @xmath128 and knowledge set update @xmath129 are defined as @xmath160 and @xmath161 below .",
    "@xmath162 @xmath163 @xmath164 @xmath165\\ ] ] @xmath166 \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\\\ ] ] @xmath167    the lemma @xmath141 and lemma @xmath168 in appendix vii , respectively , prove that @xmath169 is the unique solution of @xmath120 under @xmath92 , and that @xmath170 is the unique solution to @xmath120 under @xmath160 and @xmath161 . based on the normal consensus update @xmath170 the relation @xmath111 reduces to @xmath171 . from @xmath171 it is clear that the da consensus estimate update @xmath150 can be locally computed at node @xmath45 based only on @xmath102 and the received signal @xmath151 .",
    "notice that @xmath172 is a @xmath173 matrix , thus the pseudo - inverse in @xmath170 will have an immediate closed - form expression , see @xmath174 , @xmath175 and @xmath176 in lemma @xmath177 . also note that under the da algorithm every signal contains only the local consensus estimate @xmath154 together with the local normal consensus estimate @xmath178 .      under the oh algorithm",
    "each signal @xmath179 will either contain the local initial consensus vector @xmath180 and transmitting node identity @xmath46 , or the average - consensus value @xmath82 and a scalar @xmath181 to indicate that the transmitted vector is the true average - consensus value .",
    "for this reason the conditions for average - consensus under the oh algorithm are relatively straight - forward to derive ( see theorem @xmath182 in sec.iv and the proof in appendix vii ) .",
    "the oh algorithm signal specification and knowledge set update are respectively defined by @xmath183 and @xmath184 below .",
    "@xmath185 @xmath186 @xmath187 @xmath188 @xmath189\\ ] ] @xmath190 @xmath191 @xmath192    the lemma @xmath141 and lemma @xmath193 in appendix vii respectively prove that @xmath194 is the unique solution to @xmath120 under @xmath92 , and that @xmath195 is the unique solution to @xmath120 under @xmath183 and @xmath184 .",
    "notice that @xmath195 implies the relation @xmath111 reduces to @xmath196 . given @xmath183 , @xmath184 and @xmath195",
    "it follows that the oh consensus estimate update @xmath150 defined in @xmath196 can be locally computed at node @xmath45 based only on @xmath102 and the received signal @xmath151 .      for the dda algorithm",
    "let the discrete set of vectors @xmath197 be defined , @xmath198 the discretized version of @xmath120 that we consider under the dda algorithm is , @xmath199 to define the dda normal consensus update it is convenient to denote @xmath200 as the vector @xmath201 with element @xmath202 deleted .",
    "the dda signal specification and knowledge set update are defined below ,    @xmath203 @xmath204 @xmath205 @xmath206 @xmath207 @xmath208 @xmath209 @xmath210    notice that the dda signal specification @xmath211 and knowledge set update @xmath212 are identical to those of the da algorithm .",
    "also notice that under @xmath213 the relation @xmath111 implies @xmath214 .",
    "the lemma @xmath141 and lemma @xmath215 in appendix vii respectively prove that @xmath216 is the unique solution to @xmath217 under @xmath92 , and that @xmath218 is a global solution to @xmath217 under @xmath211 and @xmath212 . from @xmath211 and @xmath212",
    "it is clear that the dda consensus estimate update @xmath150 defined in @xmath214 can be locally computed at node @xmath45 based only on @xmath102 and the received signal @xmath151 .",
    "_ summary : _ we have defined four algorithms that in sec.iv will be shown to achieve average - consensus . the algorithms were derived as special cases of the distributed algorithm @xmath121 , where @xmath129 is a special case of @xmath105 .",
    "computationally , each algorithm requires only a few elementary arithmetic operations .",
    "in sec.@xmath42 we discuss the storage and communication costs of these four algorithms .",
    "this section proves that algorithms @xmath219 described in sec.iii achieve average - consensus under different communication conditions , we state this below in five theorems . under assumptions ( a1)-(a9 ) listed in sec.@xmath220 , these theorems provide necessary and sufficient conditions on the communication between nodes for average - consensus formation under algorithms @xmath219 ( recall definition @xmath115 defines the solution to the average - consensus problem ) .",
    "the main implication of these results is that , with or without flooding , an average - consensus can be achieved in the presence of arbitrary communication delays and link failures , provided only that there is a uni - directional connectivity condition among nodes .",
    "each theorem below will assume a certain condition on the communication among nodes .",
    "to specify these conditions we require the following two definitions .",
    "for any @xmath221 , an arbitrary `` communication sequence '' @xmath222 is defined as the set of all signals transmitted after time @xmath223 and received before time @xmath224 , that is , @xmath225 } = \\ { s^{i_1 j_1 } , s^{i_2 j_2 }   , s^{i_3 j_3 } , \\ldots \\}\\ ] ] where we have omitted the time indices but it is understood that the transmission time @xmath226 and reception time @xmath227 of each signal @xmath228 belong to the interval @xmath229 $ ] .",
    "recall that a signal @xmath56 as stated in ( a2 ) implies that a well - defined subset of @xmath230 leaves node @xmath46 at time @xmath231 and is received at node @xmath45 at time @xmath58 ( the specific subset depends on the algorithm considered ) .",
    "next we define the notion of a `` communication path '' .",
    "intuitively , a communication path from node @xmath46 to @xmath45 implies that node @xmath46 transmits a signal received by some node @xmath232 , and _ then _ node @xmath232 sends a signal received by some node @xmath233 , and _ then _ node @xmath233 sends a signal received by some node @xmath234 , and so on , until node @xmath45 receives a signal from node @xmath235 .",
    "technically , we say that @xmath236}$ ] contains a `` communication path '' from node @xmath46 to node @xmath45 iff @xmath236}$ ] contains a sub - sequence @xmath237}$ ] with the following connectivity property , @xmath238 } \\supseteq \\ { s^{\\ell_1 j }   , s^{\\ell_2 \\ell_1 } ,   s^{\\ell_3 \\ell_2 } , \\\\ & \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ldots , s^{\\ell_{k(ij ) } \\ell_{k(ij)-1 } } , s^{i \\ell_{k(ij ) } }   \\ }   \\end{array}\\ ] ] where again we have omitted the time indices but it is understood that the transmission time @xmath239 of each signal @xmath240 occurs _",
    "after _ the reception time @xmath241 of the preceding signal @xmath242 . note that the communication path @xmath237}$ ] has a cardinality @xmath243 } | \\geq k(ij ) + 1 $ ] .",
    "we are now ready to present the main convergence theorems for algorithms @xmath219 .      to prove convergence of the bm algorithm , consider the following communication condition .",
    "let us denote @xmath244 for an arbitrary node @xmath55 .",
    "( s@xmath6sc ) a communication sequence @xmath245}$ ] is `` singly @xmath6-strongly connected '' ( s@xmath6sc ) iff there exists a communication path from each node @xmath55 to every node @xmath246 .",
    "@xmath247    we will let `` @xmath236 } \\in \\mbox{s$\\mathcal{v}$sc}$ ] '' denote that a sequence @xmath236}$ ] is s@xmath6sc .",
    "the definition @xmath248 implies that @xmath236 } \\in \\mbox{s$\\mathcal{v}$sc}$ ] iff , @xmath249 } \\subset c_{[0,t_1 ] } \\ , \\ \\",
    "j \\in \\mathcal{v}_{-i } \\ , \\ \\",
    "i \\in \\mathcal{v } \\ .\\ ] ] the following theorem establishes the sufficient communication conditions for the bm algorithm @xmath0 .",
    "[ bmthm](bm sufficient conditions ) consider algorithm 1 , namely the bm algorithm @xmath0 .",
    "then the average - consensus @xmath250 is achieved at time @xmath251 for any communication sequence @xmath245}$ ] satisfying the @xmath16 condition @xmath7 .    see appendix vii .",
    "the bm algorithm implies a `` flooding '' of the initial consensus vectors @xmath122 through - out the network .",
    "there is no other algorithm in the literature that does not use a protocol `` equivalent '' to the flooding technique and still guarantees average - consensus for every communication sequence @xmath245}$ ] satisfying @xmath7 , we state this formally as conjecture @xmath157 in sec.@xmath158 . also related to this is conjecture @xmath252 in sec.@xmath41 of appendix vii .",
    "when combined with theorem @xmath26 , the following theorem implies that the communication condition _ sufficient _ for average - consensus under the bm algorithm is the exact same communication condition that is _ necessary _ for average - consensus under any algorithm .",
    "this is why the bm algorithm can be said to possess optimal convergence properties .",
    "[ bmcor](bm , da , oh and dda necessary conditions ) if a communication sequence @xmath245}$ ] does not satisfy the @xmath16 condition @xmath7 , then no distributed algorithm @xmath123 can achieve average - consensus @xmath250 at time @xmath251 .",
    "see appendix vii .",
    "although theorem @xmath27 is somewhat obvious , it is also a valid necessary communication condition and will be referred to through - out the paper .",
    "note that theorem @xmath182 below states that the oh algorithm requires even stronger necessary conditions than the @xmath16 condition @xmath7 implied by theorem @xmath27 .",
    "however , the da and dda algorithms do not ; there exist many @xmath16 sequences under which the da and dda algorithms will obtain average - consensus at the same instant as the bm algorithm .",
    "an example is the `` unit - delay double cycle sequence '' defined in @xmath253 of appendix vii .",
    "together with theorem @xmath27 , the example @xmath253 implies that the da and dda algorithms possess the weakest possible necessary conditions for average - consensus that any algorithm can have , this is illustrated in fig.@xmath254 below .",
    "the convergence of algorithm 2 depends on the following i@xmath6sc condition .",
    "( i@xmath6sc ) a communication sequence @xmath245}$ ] is `` infinitely @xmath6-strongly connected '' ( i@xmath6sc ) iff for each time instant @xmath255 there exists a finite span of time @xmath256 such that @xmath257}$ ] satisfies the s@xmath6sc condition @xmath7 . @xmath258",
    "it follows that a sequence @xmath245}$ ] is i@xmath6sc iff we can define the infinite set of ordered pairs @xmath259 , @xmath260 } \\in \\mbox{s$\\mathcal{v}$sc } \\ } \\\\ & t^\\ell_0 = t^{\\ell-1}_1 ( + ) \\ , \\ \\ell = 1,2 , \\ldots . \\end{array}\\ ] ] a sequence @xmath245}$ ] being i@xmath6sc is then equivalent to the condition , @xmath261 } = \\bigcup _ {   \\ell \\in \\mathbb{n } }   \\",
    "c_{[t^\\ell_0 , t^\\ell_1 ] }   \\\\ &   c_{[t^\\ell_0 , t^\\ell_1 ] } \\in \\mbox{s$\\mathcal{v}$sc } \\ , \\ \\forall \\",
    "\\ell \\in \\mathbb{n } \\ . \\end{array}\\ ] ]",
    "we now proceed to the convergence of the da algorithm .",
    "the following theorem is our main result .",
    "[ thm6](da sufficient conditions ) consider algorithm 2 , namely the da algorithm @xmath1",
    ". then average - consensus @xmath250 is achieved at time @xmath251 for any communication sequence @xmath245}$ ] satisfying the i@xmath6sc condition @xmath9 .    see appendix vii .",
    "the above result is interesting because the @xmath18 condition @xmath9 assumes a weak recurring connectivity between nodes , and also because the resource costs of the da algorithm are significantly lower than the bm algorithm ( see sec.@xmath42 ) .",
    "many papers on average - consensus formation such as @xcite,@xcite,@xcite,@xcite,@xcite,@xcite assume communication conditions that are special cases of the ivsc condition .",
    "see also conjecture @xmath262 in sec.@xmath41 of appendix vii .      the following s@xmath6cc condition will be shown sufficient for convergence of the oh algorithm .",
    "( s@xmath6cc ) a communication sequence @xmath245}$ ] is `` singly @xmath6-completely connected '' ( s@xmath6cc ) iff there exists a node @xmath263 and a time instant @xmath264 such that , @xmath265 } \\ \\ , \\ \\",
    "\\ j \\in \\mathcal{v}_{-\\hat{i } } \\\\ & s^{j \\hat{i } } ( t^{j \\hat{i } } _ 0 ,",
    "t^{j \\hat{i}}_1 ) \\in c_{(t_{1/2 } , t_1 ] } \\ , \\ \\",
    "j \\in \\mathcal{v}_{-\\hat{i } } \\ . \\end{array}\\ ] ] @xmath266    the first line in @xmath8 implies that during the interval @xmath267 $ ] every node @xmath268 will have transmitted a signal that was received by node @xmath269 .",
    "the second line in @xmath8 implies that during the interval @xmath270 $ ] the node @xmath269 will have transmitted a signal that is received by each node @xmath268 .",
    "we will let `` @xmath236 } \\in \\mbox{s$\\mathcal{v}$cc}$ ] '' denote that a sequence @xmath236}$ ] is s@xmath6cc .",
    "note that the identity of node @xmath269 need not be known by any node .",
    "we now consider convergence of the oh algorithm .",
    "[ aaacor5](oh necessary and sufficient conditions ) consider algorithm 3 , namely the oh algorithm @xmath2",
    ". then average - consensus @xmath250 is achieved at time @xmath271 iff the communication sequence @xmath245}$ ] satisfies the following condition :    * ( c ) : for each node @xmath45 for which there exists a node @xmath246 such that @xmath272}$ ] for all @xmath273 , there exists a communication path @xmath274 } \\in c_{[0,t_1]}$ ] from at least one node @xmath275 such that @xmath276 for all @xmath277 .    see appendix vii .",
    "notice that any communication sequence that satisfies the s@xmath6cc condition @xmath8 will also satisfy the condition ( c ) stated in theorem @xmath182 ; take @xmath278 , @xmath279 , and @xmath280 } = s^{j \\hat{i } } ( t^{j \\hat{i } } _ 0 , t^{j \\hat{i}}_1)$ ] for all @xmath277 .",
    "this relation motivates the position of the oh algorithm in the venn diagrams presented in fig.@xmath254 .",
    "see also remark @xmath281 in sec.@xmath158 .",
    "the condition ( c ) is more general than s@xmath6cc , it implies that each node @xmath55 will either receive a signal directly from every other node @xmath246 , or have a communication path from some node @xmath275 after the node @xmath275 has received a signal directly from every other node @xmath277 .",
    "we have defined the s@xmath6cc condition not only because it is sufficient for average - consensus under the oh algorithm , but also because it is necessary for the definition of the communication condition i@xmath6cc described next .",
    "the sufficient conditions for convergence under algorithm 4 requires the following definition .",
    "( i@xmath6cc ) a communication sequence @xmath245}$ ] is `` infinitely @xmath6-completely connected '' ( i@xmath6cc ) iff for each time instant @xmath255 there exists a finite span of time @xmath256 such that @xmath257}$ ] satisfies the @xmath19 condition @xmath8 .",
    "@xmath282    it follows that a sequence @xmath245}$ ] is i@xmath6cc iff we can define the infinite set of ordered pairs @xmath259 , @xmath260 } \\in \\mbox{s$\\mathcal{v}$cc } \\ } \\\\ & t^\\ell_0 = t^{\\ell-1}_1 ( + ) \\ , \\",
    "\\ell = 1,2 , \\ldots .",
    "\\end{array}\\ ] ] a sequence @xmath245}$ ] being i@xmath6cc is then equivalent to the condition , @xmath283 } = \\bigcup _ {   \\ell \\in \\mathbb{n } }   c_{[t^\\ell_0 , t^\\ell_1 ] } \\\\ &   c_{[t^\\ell_0 , t^\\ell_1 ] } \\in \\mbox{s$\\mathcal{v}$cc } \\ , \\ \\forall \\ \\ell \\in \\mathbb{n } \\ . \\end{array}\\ ] ] we note that the specific node @xmath269 can vary between each @xmath284}$ ] sequence , and furthermore we do not assume that any node knows the identity of @xmath269 .",
    "the following theorem deals with the convergence of algorithm 4 .",
    "[ aaathm5](dda sufficient conditions ) consider algorithm 4 , namely the dda algorithm @xmath3",
    ". then average - consensus @xmath250 is achieved at some time @xmath285 for any communication sequence @xmath245}$ ] satisfying the @xmath20 condition @xmath10 .",
    "see appendix vii .",
    "the above result is not quite as interesting as theorem @xmath17 , since even though the dda algorithm is a discretized version of the da algorithm , the @xmath20 condition @xmath10 is far stronger than the @xmath18 condition @xmath9 .",
    "also observe that the oh algorithm obtains average - consensus for any @xmath245 } \\in \\mbox{s$\\mathcal{v}$cc}$ ] , whereas the dda algorithm will obtain average - consensus under the much stronger condition that @xmath245}$ ] satisfies @xmath10 .",
    "however , as mentioned above , due to example @xmath253 of appendix vii the dda and da algorithms both can obtain average - consensus under suitable @xmath16 sequences , thus they possess much weaker necessary conditions than the oh algorithm .",
    "in fact , any communication sequence @xmath245}$ ] that strictly satisfies @xmath8 implies algorithms @xmath219 all obtain average - consensus at the exact same time instant .",
    "this is noteworthy because many past algorithms can only achieve average - consensus asymptotically ( e.g. most iterative averaging schemes ) , in contrast all four of the algorithms considered here can achieve the ( finite ) bench - mark time for average - consensus under appropriate communication sequences ( e.g. any sequence @xmath245}$ ] that strictly satisfies @xmath8 ) .    _ summary . _",
    "theorems @xmath286 above state necessary and sufficient communication conditions for average - consensus under algorithms @xmath219 given the assumptions ( a1)-(a9 ) .",
    "each theorem is associated with one of four connectivity assumptions on the communication sequence @xmath245}$ ] , denoted by @xmath287 @xmath16 , @xmath18 , @xmath19 , @xmath20 @xmath288 defined in @xmath7,@xmath9,@xmath8 , and @xmath10 .",
    "observe that assumptions @xmath18 and @xmath19 are sufficient conditions for @xmath16 .",
    "furthermore , @xmath20 implies that both @xmath18 and @xmath19 are satisfied , see fig.@xmath254 .",
    "notice that each connectivity condition assumes a set of directed signals with an arbitrary delay in the transmission time of each signal .",
    "this is significant because , apart from the flooding technique , no other consensus protocol in the current literature can ensure average - consensus in the presence of arbitrary delays in the transmission time of each signal for _ a priori _ unknown communication sequences .",
    "of course if the communication sequence is known _ a priori _ , then specific update protocols can always be constructed that guarantee average - consensus at the same instant as the bm algorithm .",
    "current results on average - consensus that do allow communication delays assume the delays have pre - determined upper - bounds , and also require the use of averaging weights that are globally balanced and pre - determined off - line ( see for example @xcite , @xcite , @xcite ) . on a related note , besides flooding there appears to be no consensus protocol in the literature that has been proven to guarantee average - consensus for _ every _ communication sequence @xmath289}$ ] satisfying any one of the conditions @xmath7,@xmath9,@xmath8 , or @xmath10 .",
    "the majority of past results on average - consensus either require special cases of the @xmath18 condition , or else can only guarantee approximate average - consensus under the @xmath16 condition @xcite , @xcite , @xcite . on the other hand , the two non - trivial algorithms da and dda require a set with cardinality upper - bounded bounded by @xmath21 to be communicated and stored at each node , and all previous algorithms besides the flooding and randomized protocols do not possess this drawback .    the venn diagrams in fig.@xmath254",
    "summarize theorems @xmath286 , as well as their relation to the gossip and aris algorithms that will be used as comparisons to the four proposed algorithms .",
    "it remains an open problem whether any protocol exists that guarantees average - consensus for all @xmath18 sequences without requiring a set with cardinality upper bounded by @xmath21 to be stored and communicated at each node .",
    "is omitted for simplicity of presentation . ]",
    "this section presents the communication and storage costs of the various algorithms proposed above . in sec.@xmath42 below we define the resource costs for the six algorithms compared in this paper ( four proposed in sec.iii and two others in sec.@xmath41 ) . in sec.@xmath43",
    "we present numerical simulations of the six algorithms under various randomized full network graphs when assuming instantaneous communication .",
    "each of the four average - consensus algorithms as well as the two comparison algorithms presented in sec.@xmath41 require that the knowledge set @xmath54 and signal set @xmath290 are respectively defined by a set of scalars , where each scalar has a particular meaning .",
    "we are thus motivated to quantify the `` resource cost '' of each algorithm in terms of the total number of scalar values that are required to define the two sets @xmath54 and @xmath290 .",
    "in particular , for any @xmath50 we define the `` storage cost '' of an arbitrary node @xmath55 as @xmath291 , @xmath292 likewise we define the `` communication cost '' @xmath293 of an arbitrary signal @xmath294 as follows , @xmath295 next define the total resource cost of node @xmath45 at time @xmath50 as @xmath296,@xmath297 based on the knowledge set and signal specifications defined in sec.iii , the table i presents the resource cost computations of each algorithm when using the definitions @xmath298 , @xmath299 , and @xmath300",
    ". the entries of table i are derived in sec.@xmath301 of appendix vii .    [ tab1 ]    .minimum and maximum resource costs obtained by applying each algorithm in sec.iii to @xmath298 , @xmath299 , and @xmath300 . here",
    "@xmath12 denotes the dimension of the initial consensus vectors , @xmath11 denotes the number of nodes , @xmath302 denotes the signal set dimension , @xmath303 the knowledge set dimension , and @xmath296 is the sum of @xmath302 and @xmath303 .",
    "we let @xmath304 denote the `` floor '' operation . [ cols=\"<,<,<,<,<,<,<\",options=\"header \" , ]     note that the storage cost @xmath303 is defined per node , and the communication cost @xmath302 is defined per signal .",
    "the total maximum resource costs of the bm algorithm increase on the order @xmath13 , whereas the total maximum resource costs of the da and dda algorithm increase on the order @xmath21 . although the total maximum resource costs of the oh algorithm increase on the order @xmath21 , the maximum resource cost of each signal under the oh algorithm increases only on the order @xmath22 . however , the communication conditions necessary for average - consensus under the oh algorithm are much stronger than the conditions necessary under the bm , da , and dda algorithms .",
    "this disparity makes it difficult to state definitive results regarding the least costly algorithm under general communication sequences . if condition ( c ) in theorem @xmath182 is known to hold _ a priori _ , then the oh algorithm may be preferable to the da and dda due to the lower communication costs @xmath305 . on the other hand , under example @xmath253 in appendix vii",
    "the dda algorithm is preferable to both the da and oh algorithm , since the former implies larger resource costs and the latter will not obtain average - consensus .",
    "the gossip algorithm in @xcite has total resource costs that increase on the order @xmath22 , however this algorithm requires strictly bi - directional and instantaneous communication , see sec.@xmath41 as well as fig.@xmath306 in sec.@xmath43 .",
    "the total resource costs of the aris algorithm increase on the order @xmath307 , where @xmath308 is an aris algorithm parameter explained in sec.@xmath41 . if @xmath309 then aris is more costly than the bm algorithm . for this reason ,",
    "the simulations presented in sec.@xmath43 assume @xmath310 .",
    "the ris algorithm proposed in @xcite requires @xmath308 random variables to be initially generated at each node for each element of the respective local initial consensus vector @xmath311 , the ris algorithm also requires these random variables to be communicated between nodes , thus both the storage and communication costs of the ris algorithm increase on the order @xmath312 .",
    "we present here numerical simulations of the four proposed algorithms together with the two comparison algorithms .",
    "the algorithm parameters were chosen as @xmath313 ( number of nodes ) , @xmath314 ( dimension of the initial consensus vectors ) , @xmath310 ( number of aris random variables generated per initial consensus element ) , and @xmath315 ( initial consensus vector values ) .",
    "the node communication is assumed to be instantaneous and in discrete - time , using the following randomized protocol :    * at each @xmath316 , two nodes @xmath317 are uniformly chosen at random such that @xmath318 , * with probability one , the node @xmath45 sends a signal to the node @xmath46 at time @xmath30 , * with probability @xmath319 the node @xmath46 sends a signal to the node @xmath45 at time @xmath30 .",
    "we compare four choices of @xmath319 , namely @xmath320 .",
    "note that @xmath321 implies instantaneous bi - directional communication .",
    "as @xmath319 decreases there will be fewer expected signals per time instant , thus we expect that each algorithm will have slower convergence for lower values of @xmath319 .",
    "fig.@xmath306 shows the network consensus error under each algorithm for each value of @xmath320 .",
    "it is clear that the gossip algorithm only converges to average - consensus for @xmath321 .",
    "for @xmath322 the gossip algorithm converges to a consensus that is increasingly distant from the average - consensus .",
    "the bm algorithm converges fastest in all simulations , as expected from theorems @xmath15 .",
    "initially the da algorithm can be observed to almost match the bm algorithm in all simulations , however as time proceeds for @xmath323 the gossip and aris algorithm eventually overcome da , and in @xmath324 the aris algorithm eventually overcomes da .",
    "however , the resource costs of aris in our simulations is greater than even the bm algorithm , thus further research is needed to objectively evaluate the trade - off between resource cost and network consensus error for each algorithm under various communication conditions .",
    "this paper has described and analyzed four distributed algorithms designed to solve the average - consensus problem under general uni - directional connectivity conditions .",
    "we derived necessary and sufficient conditions for the convergence to average - consensus under each respective algorithm .",
    "the conditions for convergence were based on two types of connectivity conditions , namely the singly @xmath6-strongly connected sequence ( defined in sec.@xmath325 ) , and the singly @xmath6-completely connected sequence ( defined in sec.@xmath326 ) .",
    "both connectivity conditions allow arbitrary delays in the transmission time of each signal , and we did not assume that the sending node knows the identity of the receiving node .",
    "the resource costs for each of the algorithms were derived and shown to differ in regard to their order of magnitude with respect to the parameters @xmath11 ( number of nodes ) and @xmath12 ( dimension of the initial consensus vectors ) .",
    "comparisons were made with two known consensus algorithms , referred to as the gossip algorithm and the adapted randomized information spreading ( aris ) algorithm .",
    "simulations were provided as well as venn diagrams of the connectivity conditions required for average - consensus under each algorithm .",
    "the non - trivial algorithms considered here are relatively advantageous under weak communication conditions if the dimension @xmath12 of the initial consensus vectors exceeds the network size @xmath11 .",
    "the works @xcite and @xcite provide two practical examples of when @xmath23 might typically be the case , e.g. distributed inference regarding a @xmath24 dimensional process or parameter in noise .",
    "the four communication conditions we proposed were deterministic ; there were no stochastic properties assumed in regard to the signal process between nodes .",
    "however , our framework allowed directed signals as well as arbitrary delays in transmission time , hence _ every _ causal signal sequence is a special case of our framework .",
    "this suggests that the four proposed algorithms can be applied to stochastic communication models for which there is a non - zero probability of consensus under any distributed algorithm , however future work is needed in this direction .",
    "future work is also needed to obtain a lower bound on the convergence rate to average - consensus for given characterizations of the communication sequence under each proposed algorithm , as well as improved algorithms designed specifically for particular communication sequences . for an objective evaluation of the various average - consensus algorithms , additional research",
    "is needed to compare the evolution of a cost function of the resource cost and network consensus error under a variety of communication sequences .",
    "lastly , an interesting generalization of the average - consensus problem is to allow the initial consensus vectors @xmath62 to vary with time , as discussed for instance by @xcite , @xcite , @xcite , @xcite , @xcite , @xcite .",
    "applying the algorithms and communication conditions proposed in this work could yield further results with regard to ensuring the average @xmath327 is contained in the knowledge set @xmath54 of each node @xmath55 at some time instants @xmath65 for given dynamic models of the set @xmath328 .    as a final note",
    ", it is worth mentioning that each of the four proposed algorithms can obtain a consensus on any _ linear combination _ of the initial consensus vectors @xmath53 under the exact same communication conditions as stated in the main results . in other words , suppose a vector @xmath329 was initially known at each node , then if each algorithm updated the normal consensus estimate based on @xmath120 with @xmath330 replaced by the vector @xmath331 , the same conditions stated in sec.iv will imply the respective algorithms ensure @xmath332 for all @xmath55 .",
    "the proofs of these results follow by identical arguments to those presented in this work , simply by replacing @xmath330 by the vector @xmath331 .",
    "in sec.@xmath158 of this appendix we derive the consensus estimate initialization for each of the four proposed algorithms , as well as the proofs for theorems @xmath26,@xmath27,@xmath17,@xmath182 , and @xmath333 . in sec.@xmath334",
    "we define the gossip algorithm proposed in @xcite in terms of the class of distributed algorithms @xmath121 , and then we define the aris algorithm in these terms as well . in sec.@xmath301",
    "we derive the resource costs presented in table i of sec.@xmath42 , and in sec.@xmath335 we define the `` unit - delay double cycle sequence '' as an example of a @xmath16 sequence that implies the da , dda , and bm algorithm all obtain average - consensus at the same instant .",
    "we present two conjectures in sec.@xmath158 , and two conjectures in sec.@xmath334 .",
    "through - out the appendix we denote the `` error '' of the normal consensus estimate @xmath117 as , @xmath336 the total reduction in normal consensus squared error resulting from the sequence @xmath236}$ ] is then , @xmath337 } ) \\equiv \\sum_{s^{i j } ( t^{i j}_0 , t^{i j}_1 ) \\in c_{[t_0,t_1 ] } } \\mathbf{e}^2 \\big ( s^{i j } ( t^{i j}_0 , t^{i j}_1 ) \\big )   \\ , \\ ] ] where @xmath338 is defined using the normal consensus error @xmath339 in @xmath340 , @xmath341      [ def11 ] under @xmath111 , @xmath90 , and @xmath91 , the average - consensus problem is solved at time @xmath65 iff the `` network normal consensus error '' @xmath342 is zero , that is , @xmath343 where @xmath344 is defined in @xmath340 .        under ( a4 )",
    "the update @xmath120 becomes , @xmath346 observe that the vector @xmath125 can be locally constructed at each node @xmath55 based only on the data @xmath347 .",
    "next observe that @xmath348 for all @xmath55 .",
    "given that @xmath349 is known by node @xmath45 at @xmath51 , the set of vectors @xmath350 for which @xmath111 holds is @xmath351 , thus @xmath352 becomes , @xmath353 \\\\ & = v ( v ' v)^{-1 } v ' \\frac{1}{n } \\mathbf{1}_n   = \\frac{1}{n } e_i \\ .",
    "\\end{array}\\ ] ] if @xmath354 then @xmath111 implies @xmath355 .",
    "note that @xmath356 and @xmath357 can both be initially computed at node @xmath45 given that @xmath358 .",
    "the solution @xmath359 implies @xmath360 and thus @xmath359 is a feasible solution to @xmath217 .",
    "it then follows that @xmath359 is also the unique solution to @xmath217 since the feasible space of @xmath217 is contained in the feasible space of @xmath120 , and both @xmath120 and @xmath217 minimize the same objective function .",
    "if @xmath361 then @xmath111 implies @xmath362 and thus node @xmath45 need not update its knowledge state regardless of the signal @xmath179 .",
    "if @xmath363 then @xmath130 together with @xmath111 implies , @xmath364 in this case @xmath120 can be re - written , @xmath365 since @xmath366 is known we can let @xmath112 and thus obtain @xmath113 as the unique global solution to @xmath367 ( note that @xmath330 can be computed since ( a4 ) and ( a7 ) imply @xmath368 ) .",
    "notice that this solution coincides with @xmath142 .",
    "next assume that @xmath369 and @xmath370 . under @xmath130 and @xmath131",
    "we can then re - write @xmath120 as , @xmath371 given that @xmath372 for all @xmath373 is known , the set of vectors @xmath108 for which @xmath111 holds is @xmath374 , thus @xmath375 becomes , @xmath376 \\ . \\end{array}\\ ] ] let @xmath377 denote cardinality of the set @xmath373 . since the columns of @xmath378 are linearly independent , the right - hand side ( rhs ) of @xmath379 can be computed as , @xmath380 where @xmath381 denotes the identity matrix of dimension @xmath382 .      by the bm update @xmath142",
    "when any node receives a signal @xmath179 , the receiving node @xmath45 either receives the desired average - consensus value @xmath82 , or receives the initial consensus vector @xmath383 of every node that has a communication path to node @xmath46 within the time span @xmath384 .",
    "if @xmath245}$ ] satisfies @xmath7 then every node has a communication path to every other node within the time span @xmath385 $ ] , thus ( a7 ) and @xmath142 together imply that at time @xmath386 every node @xmath45 will compute @xmath387 .",
    "this implies @xmath388 holds at @xmath386 and hence by definition @xmath389 a network average - consensus is obtained at time @xmath271 .      if @xmath245 } \\notin \\mbox{s$\\mathcal{v}$sc}$ ] then there exists a node @xmath55 that does not have a communication path to some node @xmath246 within the time span @xmath390 $ ] . at time @xmath224 the node @xmath46 thus can not have any knowledge that is contained in @xmath54 for any @xmath391 , regardless of the knowledge set update rule @xmath105 and signal specification @xmath128 .",
    "hence @xmath392 can not be a function of @xmath62 for an arbitrary initial consensus vector @xmath62 .",
    "it then follows that no distributed algorithm @xmath123 can imply @xmath250 is satisfied at time @xmath393 for an arbitrary set of initial consensus vectors @xmath394 .      *",
    "( p ) : @xmath395 } \\subset c_{[0,t_1 ] } \\rightarrow \\left\\ { \\begin{array}{l l } \\mathcal{k}_i(t_1(+ ) ) \\supseteq \\ { s_j(0 ) \\ } \\ & , \\",
    "\\mbox{if $ \\exists",
    "\\ \\ell$ s.t .",
    "$ c^{i \\ell}_{[t_0(i \\ell),t_1(i \\ell ) ] } \\nsubseteq c_{[0,t_1]}$ } \\\\",
    "\\mathcal{k}_i(t_1(+ ) ) \\supseteq \\ { \\bar{s}(0 ) \\ } \\ & , \\ \\mbox{if",
    "$ c^{i \\ell}_{[t_0(i \\ell),t_1(i \\ell ) ] } \\subset c_{[0,t_1 ] } \\ \\forall \\ \\ell \\in \\mathcal{v}_{-i}$ } \\end{array } \\right.\\ ] ]    the condition ( p ) forms an equivalence class among all algorithms @xmath396 defined by @xmath105 and @xmath128 . from the second line in ( p ) it follows that any algorithm @xmath396 that satisfies ( p ) will imply @xmath250 holds at time @xmath251 for any communication sequence @xmath245}$ ] satisfying @xmath7 .",
    "we now conjecture that if an algorithm @xmath396 implies @xmath250 holds at time @xmath251 for every communication sequence @xmath245}$ ] satisfying @xmath7 , then algorithm @xmath396 must have resource costs at least as great as any algorithm @xmath396 that satisfies ( p ) .",
    "[ conject0 ] if an algorithm @xmath396 guarantees @xmath250 holds at time @xmath251 for every communication sequence @xmath245}$ ] satisfying @xmath7 , then the algorithm @xmath396 will require that a set with cardinality upper bounded by at least @xmath13 can be communicated and stored at each node .",
    "the above conjecture implies that any algorithm @xmath396 that satisfies ( p ) will require that a set with cardinality upper bounded by @xmath13 can be communicated and stored at each node , this is why searching for less costly algorithms is of importance .",
    "the problem is , less costly algorithms tend to require stronger communication conditions than the bm algorithm , and they also do not guarantee average - consensus is obtained as quickly as the bm algorithm .",
    "we note that due to the resource costs associated with the ris and aris algorithms , the conjecture @xmath252 in sec.@xmath397 does not contradict conjecture @xmath157 .",
    "_ ( theorem @xmath17 ) lemmas @xmath168 - @xmath398 .",
    "_ overview of proof . _ to prove theorem @xmath17 we initially show in lemma @xmath399 that the update @xmath170 implies each normal consensus estimate @xmath117 satisfies the normalization property @xmath400 .",
    "the lemma @xmath177 proves that each normal consensus estimate @xmath117 also satisfies the `` zero local error '' property @xmath401 . without the latter ,",
    "the following lemmas would still imply convergence of all consensus estimates , but the final consensus value would not necessarily equal the average @xmath82 defined in @xmath83 .",
    "the essence of the convergence proof is that the reduction in error that results from any signal will eventually vanish if @xmath245 } \\in \\mbox{i$\\mathcal{v}$sc}$ ] , see lemma @xmath402 .",
    "applying this result to the da lower bounds on the reduction in error derived in lemmas @xmath403 and @xmath404 , we can show that each normal consensus vector will necessarily converge to a common vector , see lemma @xmath405 .",
    "together with the two technical results derived in lemmas @xmath406 and @xmath407 , we then combine the triangle inequality and the `` zero local error '' property to prove that the common vector will approach @xmath330 in the @xmath44 norm as time approaches @xmath224 .",
    "this implies @xmath388 holds at @xmath386 and hence by definition @xmath389 a network average - consensus is obtained at time @xmath271 .      under @xmath160 and @xmath161",
    "we can re - write @xmath120 as , @xmath408 given that @xmath409 , and @xmath348 are known , the set of vectors @xmath108 for which @xmath111 holds is @xmath410 , thus @xmath411 can be re - written as @xmath412 the update @xmath170 follows immediately from @xmath413 .",
    "note that @xmath415 satisfies @xmath400 for each @xmath55 .",
    "next observe that under @xmath416 the estimate @xmath117 will not change unless a signal @xmath56 is received at node @xmath45 .",
    "if a signal is received then by lemma @xmath168 the estimate @xmath117 is updated to the unique solution of @xmath413 .",
    "thus to finish the proof it suffices to show that if a vector @xmath201 does not satisfy @xmath400 then the vector @xmath417 is not the solution to @xmath413 . to prove this",
    "we show that if @xmath400 does not hold then the vector @xmath331 defined , @xmath418 will satisfy the inequality @xmath419 notice that since @xmath331 is contained in @xmath420 , the inequality @xmath421 implies that @xmath417 is not the solution to @xmath413 .",
    "next observe that if a vector @xmath417 does not satisfy @xmath400 then , @xmath422 expanding @xmath423 yields , @xmath424 re - arranging @xmath425 then implies @xmath421 , @xmath426      note that under ( a7 ) the estimate @xmath117 will not change unless a signal is received at node @xmath45 .",
    "if a signal @xmath56 is received then the da update problem @xmath413 implies the update @xmath108 must satisfy , @xmath428 since @xmath429 the inequality @xmath430 implies , @xmath431 next observe that if a vector @xmath201 satisfies @xmath400 then , @xmath432 due to lemma @xmath399 , all normal consensus estimates satisfy @xmath400 , thus we can apply @xmath433 to @xmath434 and obtain , @xmath435 subtracting both sides of @xmath436 from @xmath437 then yields , @xmath438 thus each magnitude @xmath427 is a non - decreasing function of @xmath50 for all @xmath55 .",
    "if @xmath439 and @xmath442 are linearly dependent then there exists some @xmath443 such that @xmath444 , thus if both vectors also satisfy @xmath400 then , @xmath445 combining the rhs of the first and second lines in @xmath446 implies @xmath447 and thus @xmath448 since @xmath443 .",
    "we then obtain @xmath449 since @xmath450 , thus @xmath451 and the result follows .      by lemma @xmath141 , @xmath453 for each @xmath55 .",
    "next observe that under @xmath416 the estimate @xmath117 will not change unless a signal @xmath56 is received at node @xmath45 .",
    "if a signal is received then @xmath117 is updated to the solution of @xmath413 .",
    "we now show that under the assumption @xmath454 the solution @xmath455 to @xmath413 will imply @xmath454 for every set vectors @xmath456 .",
    "first assume @xmath457 , @xmath458 , and @xmath125 are linearly dependent . in this case",
    "the update problem @xmath413 reduces to the rhs of @xmath459 and thus implies @xmath454 .",
    "next assume that any two vectors in the set @xmath460 are linearly dependent . in this case",
    "@xmath413 reduces to @xmath461 where @xmath462 is linearly independent of @xmath125 .",
    "the objective function in @xmath463 is @xmath464 the lemma @xmath399 implies that @xmath417 satisfies @xmath400 .",
    "note also that @xmath356 satisfies @xmath400 , thus the objective function @xmath465 can be simplified , @xmath466 the first - order partial derivatives of @xmath467 are , @xmath468 the second - order partial derivatives of @xmath467 are , @xmath469 the determinant of the hessian matrix of @xmath467 is thus , @xmath470 since @xmath356 and @xmath417 are linearly independent , the determinant @xmath471 is strictly positive by the cauchy - schwartz inequality .",
    "this implies the hessian matrix @xmath472 is positive - definite , thus setting the rhs of @xmath473 to zero and solving for @xmath474 yields the unique optimal values @xmath475 ,",
    "@xmath476 from @xmath477 the unique solution to @xmath463 is thus obtained , @xmath478 based on @xmath174 the element @xmath479 can be expressed , @xmath480 note that the last equality in @xmath481 follows since lemma @xmath482 implies @xmath483 under the assumption that @xmath417 satisfies @xmath400 and is linearly independent from @xmath356 .",
    "next assume that @xmath457 , @xmath458 and @xmath125 are linearly independent . in this case",
    "the solution @xmath170 can be expressed , @xmath484 \\ .",
    "\\end{array}\\ ] ] for notational convenience we denote @xmath485 and @xmath486 .",
    "note that @xmath487 has the inverse @xmath175 below , @xmath488 where the determinant @xmath489 can be computed as , @xmath490 right - multiplying @xmath175 by @xmath491 and then left - multiplying by the first row of @xmath172 yields @xmath479 , @xmath492 the last line in @xmath176 follows since @xmath489 is non - zero if @xmath493 and @xmath442 are linearly independent .      by lemma @xmath399",
    "we can apply @xmath433 to the left - hand side ( lhs ) of @xmath495 , @xmath496 applying the first line of @xmath497 to the rhs of @xmath498 then yields , @xmath499 next observe that for any two vectors @xmath500 , @xmath501 it thus follows that , @xmath502 let @xmath485 , @xmath486 and @xmath503 for notational convenience . from @xmath504 we have , @xmath505 where the last line holds due to lemma @xmath399 , and @xmath506 is defined , @xmath507 note that lemma @xmath508 together with the initialization @xmath359 implies @xmath439 and @xmath442 are non - zero .",
    "next assume that @xmath439 and @xmath442 are linearly dependent .",
    "in this case @xmath509 reduces to , @xmath510 \\ , \\\\ & = \\hat{v}_i \\frac{\\hat{v}_i ' \\mathbf{1}_n}{n \\hat{v}_i^2 } \\ , \\\\ & = \\hat{v}_i \\ , \\end{array}\\ ] ] where the last line follows due to lemma @xmath399 .",
    "applying @xmath511 to @xmath512 implies , @xmath513 where the last line follows by lemma @xmath482 since lemma @xmath399 implies both @xmath439 and @xmath442 satisfy @xmath400 , and we are assuming @xmath439 and @xmath442 are linearly dependent .",
    "next assume @xmath439 and @xmath442 are linearly independent . in this case",
    "@xmath509 can be solved analogous to @xmath174 based on the optimization problem @xmath463 , @xmath514 substituting the second line of @xmath515 for @xmath506 in the third line of @xmath512 then yields , @xmath516 where the last line follows since @xmath517 implies @xmath518 . combining @xmath512 and @xmath519 implies , @xmath520 together @xmath521 , @xmath522 and @xmath523 imply @xmath495 .",
    "the first line in @xmath497 implies that for any signal @xmath56 , @xmath525 thus for any communication path @xmath237}$ ] defined as in @xmath248 , @xmath526 where every second inequality holds due to lemma @xmath508 since @xmath527 for each @xmath528 , where @xmath529 and @xmath530 .",
    "we then obtain @xmath531 again by lemma @xmath508 since @xmath532 and @xmath533 because @xmath534 and @xmath535 respectively .",
    "[ lemkda4a](error expression for @xmath245}$ ] satisfying @xmath9 ) for any communication sequence @xmath245}$ ] satisfying @xmath9 the total reduction in normal consensus squared error @xmath536 } ) $ ] defined in @xmath537 is , @xmath538 } ) & = \\sum_{i=1}^n \\big ( e^2_{\\frac{1}{n } \\mathbf{1}_n } ( \\hat{v}_i(0 ) ) - e^2_{\\frac{1}{n } \\mathbf{1}_n } ( \\hat{v}_i(t_1(+ ) ) ) \\big ) \\\\ & = \\frac{n-1}{n } - \\sum_{i=1}^n e^2_{\\frac{1}{n } \\mathbf{1}_n } ( \\hat{v}_i(t_1(+ ) ) \\\\ & = \\sum_{\\ell \\in \\mathbb{n } } \\mathbf{e}^2 ( c_{[t^{\\ell}_0,t^{\\ell}_1 ] } ) \\ , \\",
    "c_{[t^{\\ell}_0,t^{\\ell}_1 ] } \\in \\mbox{s$\\mathcal{v}$sc } \\\\ & \\leq \\frac{n-1}{n } \\ . \\end{array}\\ ] ]    the first line follows from ( a7),(a8 ) and the definitions @xmath539 . the second line in @xmath540 is due to the initialization @xmath359 .",
    "the third line in @xmath540 follows since any communication sequence @xmath245}$ ] satisfying @xmath9 can be partitioned into an infinite number of disjoint sequences @xmath541 } \\in \\mbox{s$\\mathcal{v}$sc}$ ] .",
    "the last line in @xmath540 follows since the minimum error of any normal consensus estimate is @xmath181 .",
    "[ lemkda4b](vanishing reduction in error for @xmath245}$ ] satisfying @xmath9 ) for any communication sequence @xmath245}$ ] satisfying @xmath9 there exists an integer @xmath542 such that , @xmath543 } ) \\leq \\varepsilon \\ , \\ \\forall \\",
    "\\ell \\geq \\ell_\\varepsilon \\ , \\ ] ] for any @xmath544 , where @xmath545 } ) $ ] is defined by @xmath537 .",
    "the third line of @xmath540 implies that for any @xmath245}$ ] satisfying @xmath9 the quantity @xmath536 } ) $ ] is the sum of an infinite number of non - negative terms @xmath545 } ) $ ] , the fourth line in @xmath540 implies @xmath536 } ) $ ] is bounded above , thus @xmath546 follows by the monotonic sequence theorem .",
    "[ lemkda4d](da lower bound on reduction in error for any @xmath245}$ ] satisfying @xmath7 ) any communication sequence @xmath236}$ ] satisfying @xmath7 implies , @xmath547 } ) \\geq n \\big ( \\min_{i \\in \\mathcal{v } } \\ { \\hat{v}_i(t_1(+ ) ) ^2 \\ } \\\\ & \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ - \\max_{i \\in \\mathcal{v } } \\ { \\hat{v}_i(t_0 ) ^2 \\ } \\big ) \\ , \\\\ & \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\geq 0 \\ . \\end{array}\\ ] ]    the first line in @xmath548 holds for any communication sequence @xmath236}$ ] , @xmath549 } ) = \\sum_{i = 1}^n \\big ( e^2_{\\frac{1}{n}\\mathbf{1}_n } ( \\hat{v}_i(t_0 ) ) - e^2_{\\frac{1}{n}\\mathbf{1}_n } ( \\hat{v}_i(t_1(+ ) ) ) \\big ) \\\\ & \\ \\ \\ \\ = \\sum_{i = 1}^n \\big ( \\hat{v}_i(t_1(+ ) ) ^2 - \\hat{v}_i(t_0 ) ^2 \\big ) \\\\ & \\ \\ \\ \\ \\geq n \\big ( \\ \\min_{i \\in \\mathcal{v } } \\ { \\hat{v}_i(t_1(+ ) ) ^2 \\ } - \\max_{i \\in \\mathcal{v } } \\ { \\hat{v}_i(t_0 ) ^2 \\ } \\",
    "\\big ) \\ . \\end{array}\\ ] ] to prove the second line in @xmath548 it is required that @xmath236}$ ] satisfies @xmath7 .",
    "we define , @xmath550 since @xmath236}$ ] satisfies @xmath7 there exists a communication path @xmath551 } \\in c_{[t_0,t_1]}$ ] .",
    "the lemma @xmath404 then implies , @xmath552 the second line in @xmath548 then follows because , @xmath553 where the first and third inequality hold due to lemma @xmath508 because @xmath554 and @xmath555 respectively .",
    "[ lemkda6](da local convergence of normal consensus estimates ) for any communication sequence @xmath245}$ ] satisfying @xmath9 there exists an integer @xmath556 such that for all @xmath557 , @xmath558 } \\ , \\ ] ] for any @xmath559 .    for any communication sequence @xmath245}$ ] satisfying @xmath9 the lemma @xmath402 implies there exists an integer @xmath542 such that @xmath546 holds for any @xmath544 .",
    "for all @xmath560 we thus have for any signal @xmath561}$ ] , @xmath562 } ) \\leq \\varepsilon \\ . \\end{array}\\ ] ] note that the first inequality in @xmath563 holds by lemma @xmath508 since @xmath564 and @xmath565 for any @xmath566}$ ] .",
    "the second inequality in @xmath563 holds since , @xmath567 where @xmath568 holds due to lemma @xmath508 , and , @xmath569 where the second inequality in @xmath570 holds due to lemma @xmath571 since @xmath541 } \\in \\mbox{s$\\mathcal{v}$sc}$ ] and thus satisfies @xmath7 .",
    "together @xmath572 , @xmath573 and @xmath570 imply the second inequality in @xmath563 . applying lemma @xmath403 to lemma",
    "@xmath402 implies that for all @xmath566}$ ] and @xmath560 , @xmath574 } ) \\\\ &",
    "\\geq \\mathbf{e}^2 \\big ( s^{ij } ( t^{i j}_0 , t^{i j}_1 ) \\big ) \\ , \\\\ & = e_{\\frac{1}{n } \\mathbf{1}_n } ^2 \\big ( \\hat{v}_i(t^{ij}_1 ) \\big ) - e_{\\frac{1}{n } \\mathbf{1}_n } ^2 \\big ( \\hat{v}_i(t^{ij}_1(+ ) ) \\big ) \\ , \\\\ & \\geq \\mbox{max } \\ { \\hat{v}_j(t^{ij}_0 ) ^2 - \\hat{v}_i(t^{ij}_1 ) ^2 \\ , \\\\ & \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ n \\big ( \\hat{v}_j(t^{ij}_0 ) ' ( \\hat{v}_j(t^{ij}_0 ) - \\hat{v}_i(t^{ij}_1 ) ) \\big)^2 \\ } \\ , \\end{array}\\ ] ] for any @xmath544 . for notational",
    "convenience denote @xmath485 and @xmath486 . combining @xmath563 and",
    "@xmath575 implies that for any @xmath544 there exist an integer @xmath542 such that , @xmath576 for any @xmath566}$ ] and @xmath560 . to obtain @xmath577",
    "note that @xmath578 implies , @xmath579$. } \\end{array}\\ ] ] we thus define @xmath580 , @xmath581 for any @xmath582 and @xmath583 $ ] the result @xmath577 then follows from @xmath584 .",
    "[ lemkda7a](da properties of the normal consensus update ) upon reception of any signal @xmath585 the normal consensus estimate @xmath108 that results from the update problem @xmath413 will satisfy , @xmath586    let us define @xmath587 , @xmath588 where @xmath108 is given by @xmath413 . note that @xmath589 implies , @xmath590 from @xmath591 we have , @xmath592 and thus combining @xmath593 and @xmath433 implies , @xmath594 next observe that since @xmath587 is defined by @xmath595 , if @xmath596 is applied to the signal @xmath597 then , @xmath598 applying lemma @xmath403 to the signal @xmath599 then implies , @xmath600 where the first line follows from @xmath601 and the last line implies @xmath602 .",
    "[ lemkda7b](da vanishing change in normal consensus update ) for any communication sequence @xmath245}$ ] satisfying @xmath9 there exists an integer @xmath542 such that for all @xmath560 , @xmath603 } \\ , \\ ] ] for any @xmath544 .",
    "recall that lemma @xmath402 implies that for any communication sequence @xmath245}$ ] satisfying @xmath9 there exists an integer @xmath542 such that @xmath546 holds for any @xmath544 , we thus observe for @xmath560 , @xmath604 } \\big ) \\\\ & \\geq \\mathbf{e } ^2 ( s^{i j } ( t^{i j}_0 , t^{i j}_1 ) ) \\ , \\ \\forall \\ s^{i j } ( t^{i j}_0 , t^{i j}_1 ) \\in c_{[t^{\\ell}_0,t^{\\ell}_1 ] } \\\\ & = \\hat{v}_i ( t^{ij}_1(+ ) ) ^2 - \\hat{v}_i ( t^{ij}_1 ) ^2 \\ . \\end{array}\\ ] ] for all @xmath560 and signals @xmath566}$ ] we then have , @xmath605 where the first inequality follows from lemma @xmath606 and the second inequality from lemma @xmath406 .",
    "[ lemkda7c](da vanishing change between normal consensus update and signal ) for any communication sequence @xmath245}$ ] satisfying @xmath9 there exists an integer @xmath607 such that , @xmath608 } , \\ ] ] for all @xmath609 and any @xmath610 .    for any communication sequence @xmath245}$ ] satisfying @xmath9 the lemma @xmath405 implies that @xmath577 holds for any @xmath582 and @xmath583 $ ] , where @xmath580 is given by @xmath611 .",
    "the lemma @xmath406 implies that @xmath612 holds for any @xmath544 , thus for any @xmath613 and @xmath566}$ ] the triangle inequality then implies , @xmath614 any @xmath615 $ ] and @xmath583 $ ] thus yields @xmath616 for any @xmath617 $ ] .",
    "[ thmkda7c](da network convergence to average - consensus ) for any communication sequence @xmath245}$ ] satisfying @xmath9 there exists an integer @xmath618 such that for all @xmath619 , @xmath620 } \\in c_{[0,t_1 ] } , \\ ] ] for any @xmath621 .",
    "since @xmath245}$ ] satisfies @xmath9 we have @xmath541 } \\in \\mbox{s$\\mathcal{v}$sc}$ ] for each @xmath622 , thus there exists a communication path @xmath237 } \\in c_{[t^{\\ell}_0,t^{\\ell}_1 ] } $ ] for any @xmath55 , @xmath246 , and @xmath622 . for any @xmath55 , @xmath246 and @xmath622 the triangle inequality then implies , @xmath623 } } \\\\ & \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\sqrt{\\big ( \\hat{v}_{r j}(t^{rp}_1(+ ) ) - \\hat{v}_{p j } ( t^{rp}_0 ) \\big)^2 } \\\\ & \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ + \\sum_{q = 1}^{k(ij)+1 } \\sum_{s^{rp}(t^{rp}_0 , t^{rp}_1 ) \\in q^\\ell_q ( ij ) } \\\\ & \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\sqrt { \\big ( \\hat{v}_{r j}(t^{r p}_1(+ ) ) - \\hat{v}_{r j } ( t^{rp}_1 ) \\big)^2 } \\end{array}\\ ] ] where we define @xmath624 } = c_{[t^\\ell_0 , t^\\ell_1 ] } \\setminus c^{ij}_{[t_0(ij),t_1(ij)]}$ ] and , @xmath625 } \\ : \\\\ & \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\",
    "t^{\\ell_q m}_1 \\in ( t^{\\ell_q \\ell_{q-1}}_1 , t^{\\ell_{q+1 } \\ell_q}_0 ) \\ } , \\\\ & \\mbox{for $ q = 1 , \\ldots , k(ij)$ , where $ \\ell_0 = j$ , $ \\ell_{k(ij)+1 } = i$ } , \\\\ & q^\\ell_{k(ij)+1}(ij ) = \\ { s^{i m}(t^{i m}_0 , t^{i m}_1 ) \\",
    "\\in c_{[t^\\ell_0 , t^\\ell_1 ] } \\ : \\\\ & \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\",
    "t^{i m}_1 > t_1(ij ) \\ } \\ . \\end{array}\\ ] ] we clarify that the rhs of @xmath626 includes the differences between the received normal consensus vector @xmath627 and the updated normal consensus vector @xmath628 that results from each signal contained in the communication path @xmath237 } \\in c_{[t^{\\ell}_0,t^{\\ell}_1 ] } $ ] .",
    "each set @xmath629 defined in @xmath630 contains the signals received at each node _ after _ the respective signal in communication path was received , but _ before _ the respective signal in the communication path was sent , as is required for an application of the triangle inequality .",
    "the set @xmath631 contains the signals received at node @xmath45 _ after _ the last signal in the communication path @xmath237}$ ] was received , but _ before or at _ the end of the communication sequence @xmath541}$ ] , again this is required for application of the triangle inequality .    for any communication sequence @xmath245}$ ] satisfying @xmath9 the lemma @xmath406 implies there exists an integer @xmath542 such that @xmath612 holds for any @xmath544 .",
    "likewise , for any communication sequence @xmath245}$ ] satisfying @xmath9 the lemma @xmath407 implies there exists an integer @xmath607 such that @xmath616 holds for any @xmath610 .",
    "thus for any @xmath632 $ ] if we let @xmath615 $ ] and @xmath633 $ ] then for any @xmath613 , @xmath634 } | \\sqrt{\\gamma } \\\\ & \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ + \\sum_{q = 1}^{k(ij)+1 } |q^\\ell_q ( ij)| \\sqrt{\\overline{\\varepsilon}(\\chi ) } \\ , \\\\ & \\ \\ \\ \\ \\leq \\big ( | c^{ij}_{[t_0(ij),t_1(ij ) ] } | + \\sum_{q = 1}^{k(ij)+1 } |q^\\ell_q ( ij)| \\big ) \\sqrt{\\gamma } \\ , \\\\ & \\ \\ \\ \\ \\leq |c_{[t^{\\ell}_0,t^{\\ell}_1 ] } | \\sqrt{\\gamma } \\ , \\end{array}\\ ] ] where the second inequality holds since @xmath635 , and the last inequality holds since every signal contained in @xmath541}$ ] is represented by at most one term on the rhs of @xmath626 , that is , @xmath636 } | \\geq | c^{ij}_{[t_0(ij),t_1(ij ) ] } | + \\sum_{q = 1}^{k(ij)+1 } | q^\\ell_q(ij ) | \\ .\\ ] ] due to @xmath637 , any @xmath621 and @xmath638 } | ) ^2 ] $ ] then implies , @xmath639 for any @xmath317 , where the first equality holds due to lemma @xmath177 . the result",
    "@xmath640 then follows from @xmath641 since @xmath642 where the first equality holds again due to lemma @xmath177 .    _",
    "proof._(theorem @xmath182 ) lemma @xmath193-@xmath643 .",
    "_ overview of proof . _",
    "the lemma @xmath193 proves the oh normal consensus update @xmath195 .",
    "as stated in lemma @xmath644 , the update @xmath195 implies the error of each element of every normal consensus vector is a non - increasing function of time , and thus @xmath195 will imply the conditions stated in lemma @xmath643 are sufficient and necessary for any node to obtain average - consensus .",
    "the theorem @xmath182 then follows immediately from lemma @xmath643 .      if @xmath363 then @xmath646 , in this case @xmath183 together with @xmath111 implies @xmath647 .",
    "the update @xmath120 can thus be re - written as @xmath367 .",
    "since @xmath366 is known we can let @xmath112 and thus obtain @xmath113 as the unique solution to @xmath367 .",
    "note that this coincides with @xmath195 .",
    "next assume that @xmath370 and thus @xmath648 . under @xmath183 and @xmath184",
    "we can re - write @xmath120 as , @xmath649 given that @xmath650 , and @xmath348 are known , the set of vectors @xmath108 for which @xmath111 holds is @xmath651 , thus @xmath652 can be re - written as , @xmath653 if @xmath654 then @xmath655 becomes , @xmath656 \\ . \\end{array}\\ ] ] since @xmath125 is linearly independent of @xmath657 we then have , @xmath658 note that if @xmath654 then the last line in @xmath659 coincides with @xmath195 . next assume @xmath660 .",
    "in this case @xmath655 can be expressed , @xmath661 \\ . \\end{array}\\ ] ] recall the discrete set of vectors @xmath197 is defined in @xmath662 .",
    "note that the initialization @xmath359 implies @xmath663 and thus @xmath664 .",
    "also note that @xmath659 implies @xmath665 and @xmath666 .",
    "we thus assume , @xmath667 observe that under @xmath668 if the result @xmath195 is proven , then the assumptions @xmath668 are valid . for notational",
    "convenience denote @xmath669 .",
    "given @xmath668 the matrix @xmath670 has an inverse @xmath671 below , @xmath672 where the determinant @xmath673 can be computed as , @xmath674 next observe that,@xmath675 from @xmath676 we observe that right - multiplying @xmath671 by @xmath677 and left - multiplying by @xmath678 then yields @xmath195 , @xmath679        [ aaalemis2](oh normal consensus estimate convergence to average - consensus ) under the oh algorithm , any node @xmath55 obtains average - consensus by time @xmath224 for some communication sequence @xmath683 iff at least one of the following two conditions holds ,      ( sufficiency . )",
    "if a communication sequence @xmath683 implies ( c1i ) for some node @xmath45 then under the update @xmath195 there will exist a time @xmath685 such that @xmath686 for each @xmath246 , and thus lemma @xmath644 together with @xmath359 imply @xmath687 and hence by @xmath111 the node @xmath45 reaches average - consensus by time @xmath224 .",
    "if a communication sequence @xmath683 implies ( c2i ) then by the previous reasoning the node @xmath275 will obtain average - consensus by time @xmath688 , and thus by the update @xmath195 any node @xmath60 that @xmath275 sends a signal @xmath689 will obtain average - consensus at @xmath690 .",
    "if the node @xmath275 has a communication path @xmath274 } \\in c_{[0,t_1)}$ ] to node @xmath45 it then follows that node @xmath45 will have obtained average - consensus by time @xmath691 , and thus by lemma @xmath644 node @xmath45 obtains average - consensus at time @xmath224 .",
    "( necessity . ) under the oh update @xmath195 , if there is not a signal @xmath684 then there will not exist a time @xmath692 such that @xmath693 unless there exists a communication path @xmath274 } \\in c_{[0,t_1)}$ ] from some node @xmath275 such that @xmath276 for all @xmath277 .",
    "it thus follows that node @xmath45 can not obtain average - consensus by time @xmath224 for any communication sequence @xmath683 that does not imply either ( c1i ) or ( c2i ) .        _",
    "proof._(theorem @xmath333 ) lemma @xmath694-@xmath695 .",
    "_ overview of proof . _",
    "similar to theorem @xmath17 , we show that every normal consensus estimate @xmath117 satisfies the normalization property @xmath400 , the `` zero local error '' property @xmath454 , and furthermore the discretization @xmath696 . the lemma @xmath697 and",
    "lemma @xmath698 shows that the update @xmath699 respectively implies the error of each normal consensus estimate is non - decreasing with time , and that the normal consensus estimate will not change unless there is a reduction in error .",
    "we then show , analogous to lemma @xmath402 , that the reduction in error that results from any signal will eventually vanish if @xmath245}$ ] satisfies @xmath10 . due to the discretization @xmath696",
    "this implies the reduction in error that results from any signal will eventually strictly equal zero if @xmath245}$ ] satisfies @xmath10 , see lemma @xmath695 .",
    "when this occurs we can show that @xmath116 by utilizing lemma @xmath700 , lemma @xmath701 , together with the `` zero local error '' property @xmath454 , hence @xmath388 holds and so by definition @xmath702 a network average - consensus is obtained .",
    "note that the initialization @xmath359 implies @xmath664 .",
    "the optimization problem @xmath217 requires that any solution @xmath703 satisfies @xmath704 . under the dda algorithm",
    ", the assumption ( a7 ) implies every normal consensus estimate remains fixed unless updated via @xmath217 , it thus follows that @xmath696 for all @xmath55 and @xmath50 .",
    "the lemma @xmath141 implies @xmath453 for each @xmath55 .",
    "next observe that under @xmath416 the estimate @xmath117 will not change unless a signal @xmath56 is received at node @xmath45 .",
    "if a signal is received then @xmath117 is updated by @xmath699 given below .",
    "we now show that under the assumption @xmath454 , the solution @xmath455 specified by @xmath699 will imply @xmath454 for every set vectors @xmath710 . if @xmath711 then @xmath712 and thus , @xmath713 if @xmath714 and @xmath715 then @xmath716 and thus , @xmath717 finally , if @xmath714 and @xmath718 then @xmath719 and thus @xmath454 follows by assumption .",
    "[ aaalemkda1](dda normal consensus estimate update ) applying @xmath211 and @xmath212 to the optimization problem @xmath217 implies the dda normal consensus estimate update @xmath108 can be defined as in @xmath218 .",
    "note that @xmath218 implies , @xmath725 we thus will prove that @xmath211 and @xmath212 imply optimization problem @xmath217 yields the dda normal consensus estimate update @xmath108 defined by @xmath699 . under @xmath211 and @xmath212",
    "we can re - write @xmath217 as , @xmath726 given that @xmath409 , and @xmath348 are known , the set of vectors @xmath108 for which @xmath111 holds is @xmath410 , thus @xmath727 can be re - written as @xmath728 for notational convenience denote @xmath485 , @xmath486 , and @xmath729 .",
    "note that the constraint in @xmath730 can be expressed as follows , @xmath731 due to lemma @xmath732 the @xmath126 constraint in @xmath733 is , @xmath734 if @xmath735 we then have the candidate update @xmath736 , @xmath737 where the magnitude @xmath738 is computed using lemma @xmath722 .",
    "if @xmath739 we then have the candidate update @xmath740 , @xmath741 since @xmath742 for all @xmath743 , the @xmath126 constraint of @xmath744 is the only constraint involving the optimization variable @xmath745 , thus by applying lemma @xmath746 it follows from @xmath747 that if @xmath748 then the resulting solution @xmath749 can not be a solution to @xmath730 , hence @xmath750 . next observe that if @xmath751 then the @xmath752 constraint in @xmath733 places no restriction on @xmath753 or @xmath754 , thus due to lemma @xmath694 and lemma @xmath732 we can consider the three possible scenarios posed by @xmath733 given the @xmath126 constraint is satisfied by @xmath747 : one constraint , @xmath755 two constraints , @xmath756 or three constraints @xmath757 if @xmath758 and there is one constraint , then lemma @xmath732 implies @xmath759 and hence @xmath760 . in this case",
    "we have @xmath761 and the following candidate solutions , @xmath762 where the second line in @xmath763 simplifies to @xmath764 .",
    "the solutions in @xmath763 possess the following magnitudes , @xmath765 and thus since lemma @xmath732 implies @xmath766 , the optimal solution is , @xmath767 where the last line follows under the given assumption @xmath761 . if @xmath758 and there are two constraints then @xmath768 necessarily follows . in this case",
    "@xmath769 and we have the candidate solutions , @xmath770 the solutions in @xmath771 possess the following magnitudes , @xmath772 and thus since lemma @xmath732 implies @xmath766 , the optimal solution is , @xmath773 if @xmath774 and there is one constraint then we necessarily have @xmath775 and thus @xmath776 . in this case",
    "the candidate solutions are , @xmath777 note that the first and second line in @xmath778 correspond respectively to when @xmath779 and @xmath780 , also note that each line simplifies respectively to @xmath764 and @xmath356 .",
    "the solutions in @xmath778 thus possess the following magnitudes , @xmath781 and since lemma @xmath732 implies @xmath766 , the optimal solution is , @xmath782 where the last line follows under the assumption @xmath775 .",
    "if @xmath774 and there are two constraints , then if @xmath783 it follows that @xmath784 holds .",
    "the candidate solutions in this case are , @xmath785 the solutions in @xmath786 possess the following magnitudes , @xmath787 the assumption @xmath788 then implies the optimal solution , @xmath789 if @xmath774 and there are two constraints , then if @xmath790 it follows that @xmath791 holds .",
    "the candidate solutions in this case are , @xmath792 the solutions in @xmath793 possess the following magnitudes , @xmath794 the assumption @xmath795 then implies the global solution , @xmath796 if @xmath774 and there are three constraints then @xmath797 necessarily follows .",
    "the candidate solutions in this case are , @xmath798 the solutions in @xmath799 possess the following magnitudes , @xmath800 the assumption @xmath788 then implies the optimal solution , @xmath801 in contrast , the assumption @xmath795 implies the global solution , @xmath802 combining @xmath803 , @xmath804 , @xmath805 , @xmath806 , @xmath807 , @xmath808 , and @xmath809 , together imply @xmath699 .",
    "note that if @xmath810 and @xmath811 then there are two global solutions to @xmath730 . by specifying @xmath807 and @xmath809",
    "we have chosen the global solutions that are necessary for lemma @xmath698 , which is in turn necessary for the dda algorithm to obtain average - consensus under the sufficient communication condition stated in theorem @xmath333 .",
    "the lemma @xmath215 implies that upon reception of any signal @xmath151 , the normal consensus estimate @xmath812 is updated to a solution of @xmath730 , thus @xmath813 the lemma @xmath694 implies @xmath814 , thus @xmath815 implies that any candidate solution @xmath816 that does not satisfy @xmath817 can not be a solution @xmath730 .",
    "applying lemma @xmath746 to the lhs of @xmath819 implies , @xmath820 to prove @xmath819 we thus have only to show , @xmath821 under the update @xmath699 , to prove @xmath822 we need only to show that either of the two cases , @xmath823 will imply @xmath824 .",
    "if @xmath711 then @xmath825 together with @xmath400 imply , @xmath826 where the last inequality holds because @xmath454 implies @xmath827 for all @xmath246 and @xmath50 .",
    "if @xmath714 and @xmath715 , then due to @xmath825 it follows that , @xmath828 where the final inequality holds under the given assumption that @xmath715 , and the second last equality holds due to lemma @xmath732 .      if @xmath711 then @xmath712 and thus applying @xmath709 implies , @xmath830 if @xmath714 and @xmath715 then @xmath716 and thus , @xmath831 where the last inequality holds by the assumption @xmath715",
    ". finally , if @xmath714 and @xmath718 then @xmath719 and thus @xmath832 where the last inequality holds by the assumption @xmath718 .",
    "[ aaalemdda4a](error expression for @xmath245}$ ] satisfying @xmath10 ) for any communication sequence @xmath245}$ ] satisfying @xmath10 the total reduction in normal consensus error from @xmath840 to @xmath251 is , @xmath841 } ) & = \\sum_{i=1}^n \\big ( e^2_{\\frac{1}{n } \\mathbf{1}_n } \\big ( \\hat{v}_i(0 ) \\big ) - e^2_{\\frac{1}{n } \\mathbf{1}_n } \\big ( \\hat{v}_i(t_1(+ ) ) \\big ) \\big ) \\\\ & = \\frac{n-1}{n } - \\sum_{i=1}^n e^2_{\\frac{1}{n } \\mathbf{1}_n } \\big ( \\hat{v}_i(t_1(+ ) ) \\big ) \\\\ & = \\sum_{\\ell \\in \\mathbb{n } } \\mathbf{e}^2 ( c_{[t^{\\ell}_0,t^{\\ell}_1 ] } ) \\ , \\ c_{[t^{\\ell}_0,t^{\\ell}_1 ] } \\in \\mbox{s$\\mathcal{v}$cc } \\\\ &",
    "\\leq \\frac{n-1}{n } \\ . \\end{array}\\ ] ]      [ aaalemdda4b](dda vanishing reduction in error for @xmath245}$ ] satisfying @xmath10 ) for any communication sequence @xmath245}$ ] satisfying @xmath10 there exists an integer @xmath542 such that , @xmath844 } ) \\leq \\varepsilon \\ , \\ \\forall \\",
    "\\ell \\geq \\ell_\\varepsilon \\ , \\ ] ] for any @xmath544 .",
    "[ aaalemdda4c](dda lower bound on non - zero reduction in error ) for any communication sequence @xmath236}$ ] we have , @xmath845 } ) > 0 \\ \\rightarrow \\ \\mathbf{e}^2 ( c_{[t_0,t_1 ] } ) \\geq \\frac{1}{n^2 } \\ .\\ ] ]    applying lemma @xmath746 to the lhs of @xmath846 implies there exists some signal @xmath847}$ ] such that , @xmath848 we now show that @xmath849 implies @xmath850 , the result @xmath846 then follows directly by lemma @xmath697 together with lemma @xmath746 .",
    "the lemma @xmath694 implies @xmath696 for all @xmath55 and @xmath50 , thus under @xmath849 it follows that , @xmath851 from @xmath852 it then follows , @xmath853 under the constraint @xmath696 the last inequality in @xmath854 implies @xmath850 .",
    "[ aaalemdda4d](dda existence of a time for zero reduction in error ) for any communication sequence @xmath245}$ ] satisfying @xmath10 there exists an integer @xmath855 such that , @xmath856 } ) = 0 \\ , \\ \\forall \\",
    "\\ell \\geq \\ell_{\\frac{1}{n^2 } } \\ .\\ ] ]        for any communication sequence @xmath245}$ ] satisfying @xmath10 the lemma @xmath695 implies there exists an integer @xmath855 such that @xmath859 holds .",
    "we now show that the condition , @xmath860 } ) = 0 \\ , \\",
    "c_{[t^{\\ell}_0,t^{\\ell}_1 ] } \\in \\mbox{s$\\mathcal{v}$cc}\\ ] ] implies @xmath388 at @xmath861 , and hence by definition @xmath702 a network average - consensus is obtained at @xmath862 .",
    "applying lemma @xmath700 to @xmath863 implies , @xmath864 where the last inequality holds due to lemma @xmath701 . likewise , applying lemma @xmath700 and lemma @xmath701 to @xmath863 implies , @xmath865 note that applying lemma @xmath698 to @xmath863 implies that @xmath866 and @xmath867 can be combined to obtain , @xmath868 the second line in @xmath869 together with lemma @xmath732 implies , @xmath870 and thus @xmath871 .",
    "since @xmath541 } \\in \\mbox{s$\\mathcal{v}$cc}$ ] , the lemma @xmath698 together with the update @xmath699 implies @xmath872 for each @xmath268 , thus @xmath388 holds and so by definition @xmath702 average - consensus is obtained at time @xmath873 .",
    "[ rem1 ] we observe that if the @xmath19 condition is defined by the condition ( c ) stated in theorem @xmath182 , then using the definition @xmath10 for the @xmath20 condition will not imply theorem @xmath333 . in other words , using condition ( c ) to define an @xmath19 sequence will imply there exist examples of @xmath20 sequences for which the dda algorithm will not obtain average - consensus .",
    "this is why we have defined @xmath19 only by @xmath8 , which is actually a special case of the condition ( c ) stated in theorem @xmath182 .",
    "furthermore , the dda algorithm normal consensus update @xmath699 is only a global solution to @xmath217 , it is not a unique solution . under @xmath183 and @xmath184 ,",
    "the alternative global solution to @xmath217 is , @xmath874 the above remark still holds even when the alternative global solution @xmath875 is used to update the normal consensus estimate ; however , by randomly switching between the updates @xmath699 and @xmath875 leads to the following conjecture .    [ conject4 ]",
    "let the @xmath19 condition be defined by the condition ( c ) stated in theorem @xmath182 .",
    "suppose upon reception of each signal the normal consensus estimate update is defined by @xmath699 with probability @xmath876 and defined by @xmath875 with probability @xmath877 .",
    "then @xmath250 holds at time @xmath271 almost surely for any communication sequence @xmath245}$ ] satisfying @xmath10 .",
    "the significance of the above result is due to the fact that condition ( c ) in theorem @xmath182 is considerably weaker than @xmath8 .",
    "if conjecture @xmath878 holds , then by defining the dda algorithm using the above randomized protocol , and defining the @xmath19 condition by the condition ( c ) stated in theorem @xmath182 , the venn diagram in fig.@xmath254 will then be completely accurate .",
    "we note there are alternative definitions of the @xmath19 condition and oh algorithm that will also lead to the same venn diagram as fig.@xmath254 .",
    "however , we know of no _ weaker _ sufficient condition than that stated in theorem @xmath333 for convergence of the dda algorithm @xmath3 , and this sufficient condition is based entirely on the @xmath19 condition @xmath8 .",
    "we note that under the gossip algorithm the only communication conditions proven to ensure average - consensus require instantaneous and bi - directional communication , thus implying @xmath885 } \\leftrightarrow s^{ji}(t^{ji}_0,t^{ji}_1 ) \\in c_{[0,t_1 ] } \\ , \\\\ & \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ t^{ij}_0 = t^{ij}_1 = t^{ji}_0 = t^{ji}_1 \\ , \\end{array}\\ ] ] for any signal @xmath886}$ ] . under the assumption @xmath887 , any @xmath289}$ ] satisfying the i@xmath6sc condition",
    "@xmath9 will imply the gossip algorithm obtains average - consensus at time @xmath888 , that is @xmath250 is satisfied at @xmath888 .",
    "we note that in some works ( e.g. @xcite , @xcite ) the gossip algorithm is referred to as `` pairwise averaging '' .",
    "we clarify that the @xmath895 element in the matrix @xmath896 is an independent realization of a random variable from an exponential distribution with rate parameter @xmath897 , this is why the elements of each initial consensus vector @xmath62 are required to be positive valued under any version of the ris algorithm .",
    "we next define the aris update for each term in the knowledge set @xmath898 , we will omit the time indices for convenience .",
    "@xmath899 @xmath900 , & \\",
    "\\mbox{if $ k_j = k_i,$ } \\\\ \\mathbf{1}_n - \\delta [ e_i + \\hat{w}_j ] , & \\",
    "\\mbox{if $ k_j > k_i$ , } \\\\ 0 , & \\",
    "\\mbox{if $ k_j < k_i$ , } \\end{array } \\right . \\end{array}\\ ] ] @xmath901 @xmath902 @xmath903 @xmath904 @xmath905 @xmath906    the integer @xmath308 is an ris algorithm parameter that affects the convergence error of the algorithm ; as @xmath308 increases the algorithm is expected to converge closer to the true average - consensus vector @xmath82 .",
    "based on the strong law of large numbers we make the following conjecture .    [ conject1 ] for any @xmath289}$ ] satisfying the s@xmath6sc condition @xmath7 , both the ris algorithm proposed in @xcite and the aris algorithm @xmath5 imply @xmath250 at time @xmath271 almost surely in the limit as @xmath308 approaches infinity .",
    "as explained in sec.@xmath42 , the total resource cost of the ris algorithm increases on the order @xmath312 , and likewise , the total resource cost of the aris algorithm increases on the order @xmath307 , thus it is not practical to assume @xmath308 can be made arbitrarily large as the conjecture @xmath252 requires .",
    "note that due to the resource costs of the ris and aris algorithms , the conjecture @xmath252 does not contradict conjecture @xmath157 , even though both assume the same communication conditions .",
    "an informal description of the aris algorithm is as follows : at @xmath907 each node generates @xmath308 random variables independently from an exponential distribution with rate parameter @xmath908 for each @xmath909 a local counter @xmath910 is set to zero and a local vector @xmath911 is set to @xmath125 . upon reception of any signal ,",
    "if the transmitted counter @xmath912 is less than the local counter @xmath910 , then the signal is ignored , if @xmath913 then the receiving node records the minimum between the received @xmath308 random variables and local @xmath308 random variables for each @xmath914 .",
    "the vector @xmath911 maintains a record of the set of nodes that have a communication path with the node @xmath45 for any given counter value .",
    "whenever @xmath915 is updated to @xmath916 , then the counter @xmath910 is increased by one , the consensus estimate @xmath85 is updated as a running average of the inverse of the currently recorded mean of the minimum random variables for each @xmath917 , @xmath915 is reset to @xmath125 , and a new set of @xmath918 random variables are locally generated . if @xmath919 then the local counter @xmath910 is set to @xmath912 , the consensus estimate @xmath85 is set to the received estimate @xmath920 , @xmath915 is reset to @xmath125 and updated by @xmath921 , a new set of @xmath918 random variables are locally generated , and the node @xmath45 then records the minimum between the received @xmath308 random variables and the newly generated local @xmath308 random variables for each @xmath914 .",
    "it is not difficult to see that the local counter of each node will approach infinity iff @xmath289}$ ] satisfies the i@xmath6sc condition @xmath9 , thus each element in the consensus estimate @xmath85 of each node @xmath55 will approach the inverse of the mean of the minimum of infinitely many random variables . by a well - known property of the minimum of a set of",
    "independently generated exponential random variables , together with the strong law of large numbers , we thus make the following conjecture .      the above conjecture is significant because , besides the flooding technique and the da algorithm @xmath1 , there is no other consensus protocol in the literature that guarantees average - consensus for every communication sequence @xmath289}$ ] that satisfies the i@xmath6sc condition @xmath9 .      in this section",
    "we explain how the entries of table i in sec.@xmath42 are obtained .",
    "we will assume an arbitrary vector @xmath922 requires @xmath923 scalars to be defined , and similarly , an unordered set of scalars @xmath924 with cardinality @xmath925 requires @xmath925 scalars to be defined , that is @xmath926 the rationale for @xmath927 is that each element in @xmath417 requires one scalar to define the location of the element , and one scalar to define the value of the element itself .",
    "the location of each scalar in @xmath924 is irrelevant because @xmath924 is an unordered set , thus @xmath924 can be defined using only @xmath925 scalars .",
    "an alternative to @xmath927 is to assume that an arbitrary vector @xmath922 requires @xmath928 scalars to be defined .",
    "although this alternative will imply different entries for the _ exact _ values in table i , the _ order _ of the storage and communication costs under each algorithm would remain the same .",
    "we adhere to @xmath927 for our resource cost computations due to its relative precision .",
    "next observe that under the bm , oh , and dda algorithms each normal consensus estimate @xmath117 will contain only elements belonging to the set @xmath929 , similarly each vector @xmath915 under the aris algorithm contains only elements belonging to the set @xmath930 . under the bm ,",
    "oh , and dda algorithms we can thus define each @xmath117 based only on the set @xmath931 , @xmath932 a set @xmath933 can be defined analogous to @xmath934 to specify @xmath915 .",
    "note that both @xmath931 and @xmath933 are unordered sets of scalars , and thus , assuming average - consensus has not been obtained , we have from @xmath934 , @xmath359 , and @xmath935 , @xmath936 under the condition @xmath359 , applying @xmath927 and @xmath937 to the algorithm update equations @xmath130 , @xmath131 , @xmath183 , @xmath184 , @xmath211 , @xmath212 , then yield the respective upper and lower resource costs for the bm , oh , and dda algorithms stated in table i in sec.@xmath42 . likewise , applying @xmath927 and @xmath937 to @xmath889-@xmath938 yield the respective upper and lower resource costs for the aris algorithm . as detailed in @xmath4 , the gossip algorithm proposed in @xcite",
    "requires only the local consensus estimate @xmath85 to be communicated and stored at each node , thus the communication and storage cost are both fixed at @xmath939 under this algorithm .",
    "we next observe that under the da algorithm @xmath1 , if a normal consensus estimate @xmath117 contains any elements equal to zero then these elements may be omitted from the signal and knowledge set .",
    "given the condition @xmath359 it follows from @xmath927 that the minimum number of scalars required to define @xmath117 under the da algorithm is @xmath940 , while the maximum number of scalars required to define @xmath117 is @xmath941 . together with these upper and lower limits on the resource cost of @xmath117",
    ", applying @xmath927 to @xmath160 and @xmath161 then yields the upper and lower resource costs for the da algorithm stated in table i in sec.@xmath42 .",
    "the sequence defined in @xmath253 below is an @xmath16 sequence that implies the da , dda , and bm algorithm all obtain average - consensus at the same instant .",
    "@xmath942 } = \\ { s_1 , s_2 , \\ldots , s_{2(n-1 ) } \\ } \\ , \\\\ & s_i = s^{i+1,i } ( 2(i-1),2i -1 ) \\ , \\ i = 1,2 , \\ldots , n-1 , \\\\ & s_n = s^{1,n}(2(n-1),2n-1 ) \\ , \\\\ & s_i = s^{i - n+1,i - n}(2(i-1),2i-1 ) \\ , \\",
    "i = n+1 , n+2 , \\ldots , 2n-2 \\ . \\end{array}\\ ] ] it is a `` unit - delay '' sequence because each signal sent at time @xmath65 is received at time @xmath943 , and if a signal is received at time @xmath943 then the next signal is sent at time @xmath944 .",
    "together with theorem @xmath27 , the example @xmath253 implies that the da and dda algorithms possess the weakest possible necessary conditions for average - consensus that any algorithm can have .",
    "in contrast , the oh algorithm does not achieve average - consensus under @xmath253 .",
    "v. blondel , j. hendrickx , a. olshevsky , and j. tsitsiklis , _ convergence in multi - agent coordination , consensus , and flocking _ , in proceedings of ieee conf . on decision and control , seville , spain , 2005 .",
    "s. boyd , l. xiao , and s. lall , _ a scheme for robust distributed sensor fusion based on average consensus _ , in proceedings of the @xmath945 international ieee symposium on information processing in sensor networks , los angeles , ca , 2005 .",
    "s. boyd , l. xiao , and s. lall , _ distributed average consensus with time - varying metropolis weights _ , in proceedings of the @xmath945 international conference on information processing in sensor networks , los angeles , ca , 2005 .",
    "m. franceschelli , a. giua , and c. seatzu , _ consensus on the average on arbitrary strongly connected digraphs based on broadcast gossip algorithms _ , @xmath946 ifac workshop on estimation and control of networked systems , venice , italy , 2009 .",
    "s. kar and j. moura , _ distributed consensus algorithms in sensor networks with imperfect communication : link failures and channel noise _ , ieee transactions on signal processing , vol.57 , no.1 , pp.355 - 369 , 2009 ."
  ],
  "abstract_text": [
    "<S> we consider the average - consensus problem in a multi - node network of finite size . </S>",
    "<S> communication between nodes is modeled by a sequence of directed signals with arbitrary communication delays . </S>",
    "<S> four distributed algorithms that achieve average - consensus are proposed . </S>",
    "<S> necessary and sufficient communication conditions are given for each algorithm to achieve average - consensus . </S>",
    "<S> resource costs for each algorithm are derived based on the number of scalar values that are required for communication and storage at each node . </S>",
    "<S> numerical examples are provided to illustrate the empirical convergence rate of the four algorithms in comparison with a well - known `` gossip '' algorithm as well as a randomized information spreading algorithm when assuming a fully connected random graph with instantaneous communication .    distributed algorithm , linear update , recurring connectivity , least - squares problem , average - consensus    glossary    * bm , bench - mark algorithm , proposed here in @xmath0 . * da , distributed - averaging algorithm , proposed here in @xmath1 . </S>",
    "<S> * oh , one - hop algorithm , proposed here in @xmath2 . * dda , discretized distributed - averaging , proposed here in @xmath3 . * gossip , gossip algorithm , proposed in @xcite , also defined in @xmath4 . </S>",
    "<S> * ris , randomized information spreading , proposed in @xcite . * </S>",
    "<S> aris , adapted randomized information spreading , defined in @xmath5 . </S>",
    "<S> * s@xmath6sc , a `` singly @xmath6-strongly connected '' communication sequence , defined in @xmath7 . * </S>",
    "<S> s@xmath6cc , a `` singly @xmath6-completely connected '' communication sequence , defined in @xmath8 . * </S>",
    "<S> i@xmath6sc , an `` infinitely @xmath6-strongly connected '' communication sequence , defined in @xmath9 . * </S>",
    "<S> i@xmath6cc , an `` infinitely @xmath6-completely connected '' communication sequence , defined in @xmath10 . </S>"
  ]
}