{
  "article_text": [
    "periodically modulated stochastic processes have been studied intensely over the last two decades under the paradigm of stochastic resonance : the transduction of signals is optimal in the presence of a particular amount of noise .",
    "first suggested to explain the periodicity of ice - ages  @xcite , stochastic resonance has since been demonstrated in a wide range of experiments and the underlying mechanisms are well understood .",
    "a recent review of the field is given in  @xcite .",
    "the concept of stochastic resonance has met with particular attention in the neurosciences  @xcite .",
    "the brain achieves an enormous signal processing performance in the presence of noise from a wide range of sources , ranging from stochastic membrane channel openings on a molecular level , via highly irregular firing patterns of individual neurons to distracting stimuli in perception .",
    "the improvement of signal transduction on all of these levels has now been demonstrated experimentally  @xcite .",
    "recently , the first direct evidence for the behavioral relevance of stochastic resonance has been reported  @xcite , underlining the importance of stochastic resonance in neurobiology .    in short , neurons are threshold devices that receive an input @xmath0 which charges the membrane of the neuron like a leaky capacitor .",
    "when the potential @xmath1 across the membrane reaches a threshold @xmath2 , a _ spike _ is fired : the membrane potential makes a brief but strong excursion ( duration @xmath3ms , amplitude @xmath4mv ) .",
    "this spike is transmitted as output to other neurons .",
    "after the spike , the membrane potential is reset to a resting value @xmath5 , some @xmath6mv below the threshold  @xcite .",
    "as the shape of the spikes is stereotypical , information is only conveyed by the spike times .",
    "this has led to the leaky integrate - fire model of neuronal dynamics  @xcite . in between two spikes ,",
    "the membrane potential is governed by @xmath7 here , @xmath8 is the time - constant of the membrane , which represents the internal time - scale of the neuron and @xmath9 is an as yet undefined noise process , comprising , e.g. , stochastic membrane potential fluctuations and irregular input to the neuron from sources uncorrelated to @xmath0 .",
    "as the potential reaches the threshold , a spike is recorded and the potential is reset to @xmath10 instantaneously .    for gaussian white noise @xmath9",
    "the evolution of the membrane potential @xmath1 from reset potential to threshold is equivalent to an ornstein  uhlenbeck process with drift @xmath0 and an absorbing boundary at @xmath11 .",
    "the output of the neuron is modeled as a sequence of delta pulses @xmath12 at the times of threshold crossings @xmath13 ( _ spike train _ ) .",
    "the spike train is a stochastic point process , specified entirely by the spike times @xmath14 .",
    "this biologically most interesting stochastic process has so far escaped a rigorous analysis , in spite of several partially successful attempts  @xcite .",
    "for a list of open issues see sec .",
    "v.c.4 of the review by gammaitoni et al .",
    "this is in marked contrast to the treatment of mathematically more accessible , but biologically less plausible models , such as bistable dynamic systems  @xcite and threshold devices _ without reset _",
    "@xcite , in which stochastic resonance has been well established .",
    "the essential difficulty arises from the reset after each spike : there is no well - defined membrane potential distribution for asymptotic times , as used in the case of reset - free threshold detectors .",
    "instead we have to analyze each inter - spike - interval separately and then put these pieces together to obtain the spike train as a whole . to facilitate this , past",
    "work has assumed that the durations of all inter - spike - intervals ( @xmath15 ) were identically and independently distributed ( i.i.d . ) , i.e.  that the spike train is a stationary renewal process  @xcite .",
    "but in the presence of time - dependent input @xmath0 , this would require _ identical input _ within each inter - spike - interval ( isi ) .",
    "this is the much criticized reset assumption : if the model neuron were to describe a neuron in the auditory nerve while you are listening to a music tape , the reset assumption requires that upon the firing of each spike the tape should be rewound to exactly the position it had at the time of the last spike !    in this work we show how to analyze the response of the leaky integrate - fire neuron to periodic stimuli without undue assumptions .",
    "the distribution of the length of individual inter - spike intervals is computed numerically  @xcite , and spike trains are then assembled as markov chains from these intervals .",
    "we obtain probability distributions for the length of inter - spike intervals and the stimulus phases at which spikes occur .",
    "these distributions should be directly comparable to experiments employing sustained stimulation with periodic signals",
    ". the signal processing performance of the neuron is judged by the signal - to - noise ratio ( snr ) of the output spike train .",
    "the snr is maximal at an optimal noise amplitude for fixed stimulus frequency and at a resonance frequency for fixed noise amplitude .",
    "the latter resonance is a consequence of a time - scale matching between stimulus and membrane time - constant .",
    "all computations are verified by simulations .    in sec .",
    "[ sec : markov ] , we show how to exploit the markov property of the integrate - fire neuron to determine its response to sinusoidal input @xmath0 .",
    "the performance of the model neuron as a signal processing device is investigated in sec .",
    "[ sec : sr ] .",
    "the results are discussed in sec .",
    "[ sec : disc ] .",
    "for an input current consisting of a constant offset and a sinusoidal component , and gaussian white noise the langevin equation  ( [ eq : if_model ] ) reads @xmath16 where time and potential have been scaled to their respective natural units @xmath8 and @xmath2 ; the reset potential is set to @xmath17 .",
    "the input is characterized by the dc offset @xmath18 , stimulus amplitude @xmath19 , frequency @xmath20 and initial phase @xmath21 .",
    "the noise has amplitude @xmath22 and autocorrelation @xmath23 . in the remainder of this article",
    ", we will investigate this model . for a derivation of the type of input current used here from more elementary models , see  @xcite .    in the absence of noise ( @xmath24 ) , spikes will only be generated if @xmath25 therefore , we classify stimuli as sub - threshold if @xmath26 and as supra - threshold otherwise . in this work",
    ", we will focus on the biologically more interesting sub - threshold regime  @xcite .",
    "the methods presented here are applicable independent of the choice of stimulus parameters .",
    "we only require the presence of noise , i.e.  @xmath27 .",
    "suppose that an initial spike has occured at time @xmath28 , corresponding to stimulus phase @xmath21 .",
    "the next spike follows at time @xmath29 and stimulus phase @xmath30 , whence @xmath31 for @xmath32 .",
    "this suggests to re - write eq .",
    "( [ eq : if_scaled ] ) in terms of the time @xmath33 that has passed since the most recent spike at phase @xmath34 .",
    "thus , given this phase , the potential evolves from @xmath35 until the next spike according to @xmath36 the next spike is fired after an interval @xmath37 , as soon as the threshold condition is met @xmath38 the inter - spike intervals are connected by the iteration equations @xmath39 leading to the output spike train @xmath40    the reset of the membrane potential to @xmath41 after each spike completely erases the memory of the neuron .",
    "the subsequent behavior of the neuron therefore depends on its past only through the absolute time of the spike @xmath42 , i.e.  the spike train is a markov process .",
    "we have thus split the task of solving the dynamics of the integrate - fire neuron into two parts .",
    "we will first solve the first - passage - time problem posed by eqs .",
    "( [ eq : langevin ] ) and  ( [ eq : threshold ] ) for a given phase @xmath34 of the last spike , before assembling the spike train from the inter - spike intervals according to eqs .",
    "( [ eq : iterate ] ) and  ( [ eq : train ] ) .",
    "the first - passage - time problem for the membrane potential posed by eqs .",
    "( [ eq : langevin ] , [ eq : threshold ] ) yields the distribution @xmath43 of the inter - spike - interval lengths @xmath37 for a given stimulus phase @xmath34 at the beginning of the interval ( conditional isi distribution ) . to the best of our knowledge",
    ", no analytic solution is known for this seemingly simple first - passage time problem of the ornstein  uhlenbeck process .",
    "the approximations suggested in  @xcite are valid in a restricted parameter range only  low stimulus frequencies in particular  and appear to yield qualitative rather than quantitative agreement with simulations .",
    "we employ here a numerical method to compute the inter - spike - interval distributions .",
    "the method is discussed in detail in  @xcite , and we only sketch it here . in the absence of an absorbing threshold",
    "the probability @xmath44 that the membrane potential is @xmath45 at time @xmath33 if it was @xmath46 at time @xmath47 is a gaussian distribution .",
    "the mean is given by the solution at time @xmath33 of eq .",
    "( [ eq : langevin ] ) for the noise - free case ( @xmath24 ) with initial condition @xmath48 , while the variance is @xmath49 .",
    "then , the inter - spike - interval distribution is given by the integral equation  @xcite @xmath50 this equation is solved for @xmath51 using standard techniques  @xcite .",
    "source code is available on request .    as shown in fig .",
    "[ fig : cisi ] , the conditional inter - spike - interval distributions @xmath43 may depend strongly on @xmath34 .",
    "first , they contain a series of exponentially decaying peaks that are separated by the stimulus period @xmath52 .",
    "these peaks represent spikes that are well phase - locked to the stimulus and we will refer to them as _ periodic peaks_. an additional peak appears at short intervals @xmath37 for certain phases @xmath34 .",
    "this peak reflects the rise time of the membrane potential towards threshold .",
    "its location is not related to the stimulus period @xmath53 , but reflects the intrinsic time - scale of the neuron and defines its refractory time , i.e.  the minimum interval between two spikes .",
    "thus , we will refer to this peak as the _ refractory peak_. it corresponds to two or more spikes fired in rapid succession within a single stimulus period ( a _ burst _ ) .",
    "there is thus a qualitative dependence of the distributions @xmath51 on the phase @xmath34 that can lead to interesting consequences for the firing behavior of the neuron .",
    "the relation between periodic and refractory peaks depends on the stimulus parameters , particularly on the frequency and the noise amplitude .",
    "we will discuss this relationship in sec .",
    "[ ssec : stat ] .",
    "let us now turn to the problem of assembling spike trains from inter - spike - intervals according to eqs .",
    "( [ eq : iterate ] , [ eq : train ] ) .",
    "the length of an interval following a spike at time @xmath54 and stimulus phase @xmath55 \\bmod 2\\pi$ ] is distributed according to @xmath43 .",
    "therefore , the probability that the next spike will occur at phase @xmath56 is given by @xmath57 \\bmod 2\\pi )      \\frac{d\\tau}{\\omega } \\;.",
    "\\label{eq : tdef}\\ ] ] we will call @xmath58 the transition probability of the spike phase . we will now consider the markov process of the spike phases @xmath59 instead of the markov process made up of the spike times @xmath42 .    if we define the spike phase distribution @xmath60 as the probability ( across an ensemble of neurons or repetitions of an experiment ) that the @xmath61 spike in a train will be fired at stimulus phase @xmath34 , then this probability will evolve according to @xmath62 as the neuron fires repetitively while driven by a stationary periodic stimulus , the spike train emitted by the neuron will approach a stationary markov process with phase distribution @xmath63 the stationary phase distribution @xmath64 is the eigenfunction to eigenvalue @xmath65 of the kernel @xmath58 , and is guaranteed to exist because this kernel is a conditional probability distribution  @xcite .",
    "any initial phase distribution will converge to the unique stationary solution provided that @xmath66 everywhere  @xcite . that the latter condition holds in the presence of noise can be seen as follows . for sub - threshold stimuli",
    ", noise may drive the potential across the firing threshold at any time @xmath67 in principle , yielding a possibly tiny , but non - zero probability of spikes at any phase .",
    "the same argument holds true for supra - threshold stimuli , where noise may keep potential below threshold up to any time . in the absence of noise ,",
    "neither convergence nor uniqueness are assured .    to facilitate numerical treatment , we discretize the phase . since the conditional inter - spike - interval distributions @xmath43 are smooth in both time and phase due to the presence of noise in the input",
    ", this discretization will introduce only minor numerical errors .",
    "it is largely equivalent to applying numerical methods to solve the kernel eigenvalue problem  @xcite .",
    "using @xmath68 bins of width @xmath69 ( @xmath70 ) we obtain the spike phase distribution vector @xmath71 and the phase transition matrix @xmath72 with elements @xmath73 the evolution equation ( [ eq : chi_evol ] ) simplifies from convolution to matrix - vector multiplication @xmath74 and the stationary distribution @xmath75 is the eigenvector to eigenvalue @xmath65 of the matrix @xmath72 . we have thus reduced the markov process to a markov chain .    in practice , we obtain the transition matrix @xmath72 by numerically evaluating equations  ( [ eq : tdef ] ) and  ( [ eq : td ] ) , with @xmath43 from eq .",
    "( [ eq : volterra ] ) .",
    "the stationary distribution is then found using standard eigenvector routines .",
    "for all data shown here , we used the discretization @xmath76 , @xmath77 . in figures of transition matrices and phase distributions",
    "the axis will run from @xmath78 to @xmath79 as this renders structures more clearly .",
    "an example for the phase evolution of an initially uniform distribution towards the stationary state under the influence of a transition matrix @xmath72 is given in fig .",
    "[ fig : mc_sample ] . to `` read '' the transition matrix , note that the matrix columns correspond to the phase @xmath59 of the spike preceding the interval , the rows to the phase @xmath80 of the spike terminating it .",
    "the phase axes run from @xmath78 to @xmath79 from bottom to top in phase distribution vectors @xmath81 and the rows of the transition matrix @xmath72 , and _ from right to left _ across the columns of @xmath72 .",
    "thus , the horizontal bar in the transition matrix shown in fig .  [ fig : mc_sample ] indicates that for most values of @xmath59 the next spike will occur around @xmath82 .",
    "this bar corresponds to the periodic peaks of the isi distributions . for @xmath83 ,",
    "the matrix is dominated by a `` finger '' , running parallel to the matrix diagonal . within this range of phases ,",
    "a spike will be followed by another spike at a slightly later phase , as shown in fig .",
    "[ fig : mc_sample]b . figuratively speaking ,",
    "the neuron fires a burst of spikes , but there is always a chance that two subsequent spikes will be one or more stimulus periods apart , even though they are close in phase : in the markov chain description , all information about actual interval lengths is lost .",
    "the finger results from the refractory peak of the isi distributions .",
    "figure  [ fig : chis_low ] shows the dependence of transition matrix and stationary phase distribution on the noise amplitude for slow stimuli ( @xmath84 ) . for low noise , the transition matrix is dominated by the horizontal bar , which intersects with the matrix diagonal , indicating a stochastic fixed point .",
    "this results in a sharply peaked spike phase distribution . at intermediate noise , the finger is more pronounced , while the bar barely touches the matrix diagonal , leading to a stochastic limit cycle with two preferred phases : the neuron often fires bursts of two successive spikes . at high noise ,",
    "the finger stretches all along the matrix diagonal , while the horizontal bar has disappeared altogether .",
    "the neuron fires rapidly , but largely uncorrelated with the stimulus and the phase distribution is virtually flat .",
    "this means that for very low noise the spike train of the neuron is nearly a stationary renewal process with inter - spike - intervals i.i.d.according to @xmath85 . here",
    "@xmath86 is the location of the maximum of the stationary phase distribution , which depends not only on the stimulus parameters , but also on the noise amplitude .",
    "for high noise amplitudes , the response of the neuron is largely independent of the stimulus , and may thus be described by a stationary renewal process as well  the isis reduce to the refractory peak .",
    "but at intermediate noise levels  i.e .  those essential to the observation of stochastic resonance ",
    "the stationary phase distribution may be multimodal .",
    "thus the correlations between the phases of subsequent spikes have to be taken into account using the markov ansatz .",
    "multimodal phase distributions as discussed here are not just hypothetical : they have been observed in sensory neurons of goldfish upon stimulation with sinusoidal water waves  @xcite .    for fast stimuli ( @xmath87 ) ,",
    "the stationary phase distribution smears out much more along the phase axis , and does not show multimodality , because the refractory time of the neuron becomes comparable to the stimulus period and bursting is no longer possible , see fig .",
    "[ fig : chis_high ] . at low to intermediate noise",
    ", the distribution is too wide to be replaced by its mode as in the renewal ansatz , but still sufficiently narrow to provide for a response that is well phase - locked to the stimulus .",
    "therefore , the markov approach is essential for high frequency stimuli as well .",
    "once the stationary phase distribution is known , the inter - spike - interval distribution of the stationary firing process is obtained by averaging the conditional isi distributions over phase @xmath88 the average interval length thus is @xmath89 @xmath90 is the inter - spike - interval distribution that we expect to find in experiments with tonic stimulation .",
    "in contrast to a stationary renewal process , this averaged isi distribution does _ not _ contain a full description of the spike train .",
    "typical isi distributions @xmath90 are given in figs .",
    "[ fig : jisi_low ] and [ fig : jisi_high ] for the same parameters as used in figs .",
    "[ fig : chis_low ] ,  [ fig : chis_high ] , respectively . for low noise",
    ", they contain only periodic peaks , located precisely at integer multiples of the stimulus period @xmath53 : the neuron can only fire in a small time window within each period , and several periods may be skipped in between spikes .",
    "this indicates a firing pattern that is well phase - locked to the stimulus .",
    "isi distributions with comparable structure have been found in neurons of the auditory system in different species  @xcite . for high noise ,",
    "the isi distributions reduce to the refractory peak , i.e.  a largely random firing pattern .",
    "for intermediate noise , the isi distributions depend strongly on the stimulus frequency . for high frequency ( fig .",
    "[ fig : jisi_high ] ) , we find merely a superposition of periodic and refractory peaks : spikes preferentially occur at intervals that are multiples of the stimulus period , but this phase - locking is weak .",
    "this is very different for slow stimuli ( fig .",
    "[ fig : jisi_low ] ) , where the refractory peak is clearly separated from a wide peak at @xmath91 , the latter exposing some sub - structure .",
    "this can be understood as follows .",
    "the maximum of @xmath90 at @xmath92 corresponds to two spikes fired each at the optimal phase in two subsequent periods .",
    "in contrast , if a period that contained a burst of two spikes is followed by another period containing a burst , then typically the first spike will be slightly earlier than the optimal phase , the second one a bit later .",
    "thus , the interval between the second spike of the first burst and the first spike of the second burst is shorter than the stimulus period , leading to the side - peak at @xmath93 .",
    "the bursts themselves give rise to the refractory peak .",
    "this again indicates that the spike train is not a stationary renewal process .    along with results obtained using the markov chain approach , figs .",
    "[ fig : chis_low][fig : jisi_high ] display phase and isi distributions obtained from simulated trains of 20,000 spikes .",
    "the agreement between markov model and simulation is excellent .",
    "source code for the simulation based on  @xcite is available on request .",
    "to assess the performance of the integrate - fire neuron as a signal processing device , we evaluate the signal - to - noise ratio ( ) of the spike train generated in response to periodic input . in doing so",
    ", one should keep in mind the purpose of the output spike train .",
    "it has to convey information to other neurons in the brain _ within a certain time window _ , as the brain has to respond quickly to stimuli .",
    "therefore , the relevant quantity is the signal - to - noise ratio that can be achieved by measuring the spike train over a finite observation time @xmath94  @xcite .      the one - sided power spectral density of a stationary spike train @xmath95 [ as defined in eq .",
    "( [ eq : train ] ) ] over a time interval @xmath94 is  @xcite @xmath96 the average is to be taken over the ensemble of all spike trains , that is , over the set of all conditional isi distributions and their @xmath97-fold convolutions .",
    "this problem appears intractable .",
    "the situation is greatly simplified if @xmath98 is the stimulus frequency @xmath20 or one of its harmonics . expressing the spike times as @xmath99 , eq .",
    "( [ eq : psd_t ] ) for @xmath100 simplifies to @xmath101 where @xmath102 are integers , @xmath103 , and @xmath52 is the stimulus period . in the observation period @xmath94 , on average",
    "@xmath104 spikes will occur , regardless of the detailed structure of the spike train .",
    "we therefore fix the upper limit of the summation at @xmath105 , where @xmath106 is the average interval length from eq .",
    "( [ eq : mfpt ] ) and @xmath107 is the largest integer not exceeding @xmath108 .",
    "this yields as an approximation @xmath109    the task of computing an expectation with respect to all possible spike trains is now reduced to that of averaging over all possible sequences of _ spike phases_. their distribution and correlations are completely characterized by the transition matrix @xmath72 , permitting for evaluation of eq .",
    "( [ eq : psd_app ] ) in closed form .",
    "the actual calculation is straightforward albeit lengthy algebra and is provided in the appendix .",
    "the final result may be written as @xmath110    \\label{eq : psd_fin}\\ ] ] where the functions @xmath111 and @xmath112 are given in the appendix .",
    "note that @xmath113 is bounded as @xmath114 . for a poissonian spike train ,",
    "both @xmath115 and @xmath116 are identically zero , yielding a white power spectrum  @xcite .    at first",
    ", it might seem surprising that the spectrum contains a term , @xmath117 , that scales linearly with the number of spikes in the train .",
    "this is a consequence of the periodic component of the spike train introduced by the driving stimulus , leading to a mixed spectrum consisting of a continuous background and a discrete spectrum of harmonics  @xcite . for infinite observation time ,",
    "i.e.@xmath114 , this gives rise to the terms @xmath118 in the power spectrum .    a typical power spectrum is shown in fig .  [ fig : psd ] , indicating close agreement of eq .",
    "( [ eq : psd_fin ] ) with results obtained by numerical fourier transformation of simulated spike trains .",
    "the approximation made in fixing the summation limit in eq .",
    "( [ eq : psd_app ] ) is therefore well justified .",
    "the dip in the noise background of the spectrum at low frequencies is a consequence of the refractory period of the neuron , while the weak hump at @xmath119 indicates the presence of bursts  @xcite .",
    "spectra consisting only of this background have been found in neurons of higher cortical areas of monkeys in the absence of periodic input  @xcite .",
    "since the power spectral density can only be evaluated in closed form at multiples of the stimulus frequency , we approximate the noise background as poissonian white noise @xmath120 of a spike train of equal intensity  @xcite .",
    "the signal - to - noise ratio obtainable from the spike train within the observation time @xmath94 is therefore given by @xmath121    the signal - to - noise ratio for three different stimulus frequencies is shown in fig .",
    "[ fig : snr_d ] vs.  the noise amplitude , again in excellent agreement with simulation results .",
    "stochastic resonance ( sr ) is clearly present at all frequencies , as the attains its maximum for an intermediate noise level .",
    "the striking new feature is that the overall maximum in the is reached at an intermediate frequency @xmath122 , which we thus call the _ resonance frequency_. the same qualitative dependence of the on noise amplitude and stimulus frequencies is observed over a wide range of stimulus parameters , including weakly supra - threshold cases ( @xmath123 , @xmath124 ; data not shown ) .",
    "note that the stochastic resonance reported in an earlier paper  @xcite is an artifact of the renewal ansatz employed in that work .",
    "there , the stimulus phase is reset to an arbitrarily chosen value @xmath21 after each spike , and the signal - to - noise ratio is computed for an infinite observation time . the is maximized for that noise level at which the periodic peaks of the isi distribution @xmath125 are centered about the multiples of the stimulus period @xmath53 .",
    "but if , for low noise , one uses for each noise level @xmath126 a different @xmath127 , namely the mode of the stationary phase distribution as discussed in sec .",
    "[ ssec : chain ] , the periodic peaks are at multiples of @xmath53 for all noise intensities , whence the does not drop off for @xmath128 and no resonance occurs ( data not shown ) .",
    "this observation underlines the importance of the markov approach .",
    "in contrast to stochastic resonance in dynamical systems , sr with respect to the noise amplitude is not induced by the matching of time - scales in threshold systems , but results from stochastic linearization of the response function of the neuron  @xcite . in contrast , the additional resonance along the frequency axis arises in the integrate - fire neuron as a consequence of matching the stimulus period to the intrinsic time scale of the neuron in an appropriate manner .",
    "this is demonstrated in fig .",
    "[ fig : timescales ] . for a stimulus at the resonance frequency @xmath129",
    ", the peak at @xmath92 in the stationary isi distribution can `` grow '' in place as noise is increased , without being disturbed by the refractory peak .",
    "indeed , the latter arises at the location of the first periodic peak and shifts away from @xmath92 only for very large noise . in this way",
    ", the firing rate of the neuron can be increased without loosing the phase - locking to the stimulus .",
    "compare this to the cases of lower ( fig .",
    "[ fig : jisi_low ] ) and higher ( fig .",
    "[ fig : jisi_high ] ) frequencies : in both cases , high firing rates can only be achieved by raising the noise amplitude to a point where the refractory peak has either replaced ( @xmath130 ) or smeared out ( @xmath131 ) the periodic peaks , resulting in a firing pattern poorly phase - locked to the stimulus .",
    "this competition of precision and intensity is demonstrated by a phenomenological ansatz for the .",
    "a measure of phase - locking between stimulus and response is the vector strength @xmath132 , where @xmath56 are the spike phases  @xcite .",
    "@xmath133 indicates perfect and @xmath134 no locking . if the neuron attempts to measure the degree of phase - locking from a train of @xmath135 spikes , the quality of measurement will be @xmath136 .",
    "thus , we expect that the signal - to - noise ratio will roughly given by @xmath137 figure  [ fig : snr_model ] demonstrates that this simple model describes the behavior of the well . in particular , the two - fold stochastic resonance is reproduced .    in short , to elicit a strong output signal from the model neuron , a sufficient input noise level is required . but",
    "this comes at a cost , as the quality of the output , i.e.  the precision of the phase locking , deteriorates as noise is added .",
    "the maximum represents the optimal compromise between signal strength and quality .",
    "in this paper , we have shown that the periodically driven integrate - fire neuron can be analyzed in the framework of a markov process .",
    "this avoids the unrealistic assumption of a stimulus reset after each spike , the most serious shortcoming of previous work  @xcite , and this answers question  ( 1 ) raised by gammaitoni et al .  in sec .",
    "v.4.c of their review  @xcite .",
    "their second questions concerns the fact that the neural membrane is a rectifier : even a strong negative input current will not lower the membrane potential more than a few millivolts below the reset potential @xmath5 .",
    "this would indeed be a problem if the dc offset @xmath18 of the input were much smaller than the amplitude @xmath19 of the ac stimulus .",
    "preliminary evidence suggests that the best fit of inter - spike - interval distributions generated by the model with experimental data from the cat s auditory system  @xcite is obtained for sub - threshold stimuli with @xmath138 . in this regime , the membrane potential is quickly raised to @xmath139 and then oscillates around this level , unaffected by rectification .",
    "finally , gammaitoni and co - authors question the validity of the approximations used to compute the isi distributions in  @xcite .",
    "this matter is avoided here by numerically computing these distributions .",
    "a study of the validity of approximate closed - form isi distributions will be given elsewhere  @xcite .",
    "the markov formalism presented in this paper is applicable to any periodically driven stochastic process with a reset .",
    "the only required ingredients are the conditional first - passage - time distributions @xmath43 and the iteration equations  ( [ eq : iterate ] ) .",
    "the generalization to more complex stimuli , e.g.  including amplitude modulation , is straightforward .    with the markov machinery at hand",
    ", we have demonstrated that the signal - to - noise ratio of the output of the neuron is maximized at an optimal noise amplitude for fixed frequency and at a resonance frequency for fixed noise intensity .",
    "stochastic resonance with respect to the stimulus frequency , termed _ bona fide _",
    "stochastic resonance , has been described in bistable systems before  @xcite .",
    "therefore , our findings for a non - dynamical threshold neuron extend the universality of stochastic resonance to the case of _ bona fide _ sr .",
    "recent criticism  @xcite of the original definition of _ bona fide _ sr , based on residence time distributions , does not apply to our study .",
    "neurons in the auditory system can phase lock to acoustic stimuli with high acuity and utilize this for the precise localization of sound sources  @xcite .",
    "our results show that strong signals that are well phase locked to a stimulus may be achieved in spite of the noise ubiquitous in the neural system .",
    "stochastic resonance might therefore be one of the underlying mechanisms of stereo hearing .",
    "first qualitative comparisons indicate good agreement between response properties of the integrate - fire neuron and of auditory neurons . an intriguing question in this respect is the relevance of the _ bona fide _ sr to the neural system .",
    "it may serve to tune neurons as bandpass filters of a special kind : only stimuli in a certain frequency window will be transmitted with high intensity _ and _ precise phase locking",
    ". a detailed study will be the topic of a future publication .",
    "this work was supported by deutsche forschungsgemeinschaft through sfb  185 `` nichtlineare dynamik '' .",
    "hep gratefully acknowledges the hospitality of the laboratory for neural modeling , frontier research program , riken , wako - shi , saitama , japan , where this work started .",
    "to prove eq .",
    "( [ eq : psd_fin ] ) , i.e.   @xmath140 \\;,\\end{aligned}\\ ] ] we split the double sum into the diagonal and off - diagonal terms @xmath141 \\ ; ,    \\label{eq : s_by_h}\\ ] ] @xmath142 the asterisk denoting complex conjugation and @xmath143 .",
    "since we are considering a stationary markov process , all @xmath144 are identically distributed according to @xmath75 , while correlations between @xmath144 and @xmath145 are given by the @xmath146 power of the transition matrix @xmath72 yielding @xmath147 with vectors @xmath148 @xmath149    upon inserting eq .",
    "( [ eq : mean_einp ] ) into eq .",
    "( [ eq : def_h ] ) , we observe that the expression for @xmath150 depends only on @xmath151 but not on @xmath152 so that we may perform the outer summation to obtain @xmath153         { { \\bf \\hat{b}}}(n ) \\;.\\ ] ] diagonalizing @xmath72 leads to @xmath154 here , the diagonal matrix @xmath155 is given by @xmath156 with @xmath157 @xmath158 inserting eq .",
    "( [ eq : h_by_sm ] ) into eq .",
    "( [ eq : s_by_h ] ) , we have @xmath159 \\;. \\label{eq : s_by_sm}\\ ] ]    finally , we split the matrix @xmath155 into the parts pertaining to the discrete and the continuous parts of the spectrum and define the functions @xmath115 and @xmath116 @xmath160 @xmath161 \\;,\\ ] ] @xmath162 \\;.\\ ] ] rewriting eq .",
    "( [ eq : s_by_sm ] ) accordingly , we arrive at the desired expression for the power spectral density @xmath163 \\;.\\ ] ]"
  ],
  "abstract_text": [
    "<S> we model the dynamics of the leaky integrate - fire neuron under periodic stimulation as a markov process with respect to the stimulus phase . </S>",
    "<S> this avoids the unrealistic assumption of a stimulus reset after each spike made in earlier work and thus solves the long - standing reset problem . </S>",
    "<S> the neuron exhibits stochastic resonance , both with respect to input noise intensity and stimulus frequency . </S>",
    "<S> the latter resonance arises by matching the stimulus frequency to the refractory time of the neuron . </S>",
    "<S> the markov approach can be generalized to other periodically driven stochastic processes containing a reset mechanism . </S>"
  ]
}