{
  "article_text": [
    "since the early days of computer science , a major concern has been to cope with strong memory constraints .",
    "this started in the 70s  @xcite when memory was expensive . nowadays , a major motivation comes from a proliferation of small embedded devices where large memory is neither feasible nor desirable ( e.g. , due to constraints on budget , power , size , or simply to discourage potential thievery ) .    even when memory size is not an issue",
    ", we might want to limit the number of write operations : one can read flash memory quickly , but writing ( or even reordering ) data is slow and may reduce the lifetime of the storage system ; write - access to removable memory may be limited for technical or security reasons , ( e.g. , when using read - only media such as dvds or to prevent leaking information about the algorithm ) .",
    "similar problems occur when concurrent algorithms access data simultaneously . a natural way to address this is to consider algorithms that do not modify the input .",
    "the exact setting may vary , but there is a common theme : the input resides in read - only memory , the output must be written to a write - only structure , and we can use @xmath6 additional variables to find the solution ( for a parameter @xmath5 ) . the goal is to design algorithms whose running time decreases as @xmath5 grows , giving a _ time - space trade - off _  @xcite .",
    "one of the first problems considered in this model is _ sorting _  @xcite . here",
    ", the time - space product is known to be @xmath10  @xcite , and matching upper bounds for the case @xmath11 were obtained by pagter and rauhe  @xcite ( @xmath12 denotes the available workspace in _ bits _ ) .",
    "our current notion of memory constrained algorithms was introduced to computational geometry by asano  _ et al . _",
    "@xcite , who showed how to compute many classic geometric structures with @xmath13 workspace ( related models were studied before  @xcite ) .",
    "later , time - space trade - offs were given for problems on simple polygons , e.g. , shortest paths  @xcite , visibility  @xcite , or the convex hull of the vertices  @xcite .",
    "we consider a model in which the set @xmath0 of @xmath1 points is in an array such that random access to each input point is possible , but we may not change or even reorder the input . additionally , we have @xmath6 variables ( for a parameter @xmath14 ) .",
    "we assume that each variable or pointer contains a data word of @xmath7 bits .",
    "other than this , the model allows the usual word ram operations . under this model",
    "we study two problems : computing an arbitrary triangulation for @xmath0 and computing the voronoi diagram @xmath15 for @xmath0 .",
    "since the output can not be stored explicitly , the goal is to report the edges of the triangulation or the vertices of @xmath15 successively , in no particular order .",
    "dually , the latter goal may be phrased in terms of delaunay triangulations .",
    "we focus on voronoi diagrams , as they lead to a more natural presentation .",
    "both problems can be solved in @xmath16 time with @xmath13 workspace  @xcite or in @xmath2 time with @xmath3 workspace  @xcite . however , to the best of our knowledge , no trade - offs were known before .",
    "our triangulation algorithm achieves a running time of @xmath17 using @xmath6 variables .",
    "a key ingredient is the recent time - space trade - off by asano and kirkpatrick for a special type of simple polygons  @xcite .",
    "this also lets us obtain significantly better running times for the case that the input is sorted in @xmath18-order ; see section  [ sec_triang ] . for voronoi diagrams , we use random sampling to find the result in expected time @xmath19 ; see section  [ sec_cs ] .",
    "together with recent work of har - peled  @xcite , this appears to be one of the first uses of random sampling to obtain space - time trade - offs for geometric algorithms .",
    "the sorting lower bounds also apply to triangulations and voronoi diagrams ( since we can reduce the former to the latter ) .",
    "this implies that our second algorithm is almost optimal .",
    "in this section we describe an algorithm that outputs the edges of a triangulation for a given point set @xmath0 in arbitrary order . for ease in the presentation",
    "we first assume that @xmath0 is presented in sorted order . in this case",
    ", a time - space trade - off follows quite readily from known results .",
    "we then show how to generalize this for arbitrary inputs , which requires a careful adaptation of the existing data structures .",
    "is a mountain that is uniquely associated with a long convex hull edge.,scaledwidth=50.0% ]    suppose the input points @xmath20 are stored by increasing @xmath18-coordinate and that all @xmath18-coordinates are distinct , i.e. , @xmath21 for @xmath22 , where @xmath23 denotes the @xmath18-coordinate of @xmath24 .",
    "a crucial ingredient in our algorithm is a recent result by asano and kirkpatrick for triangulating _ _ monotone mountains _ _ ( or _ mountains _ for short ) .",
    "a mountain is a simple polygon with vertex sequence @xmath25 such that the @xmath18-coordinates of the vertices increase monotonically .",
    "the edge @xmath26 is called the _",
    "base_. mountains can be triangulated very efficiently with bounded workspace .",
    "[ obs : asanokirck ] let @xmath27 be a mountain with @xmath1 vertices , stored in sorted @xmath18-order in read - only memory .",
    "let @xmath28 .",
    "we can report the edges of a triangulation of @xmath27 in @xmath29 time and @xmath6 words of space .    since",
    "@xmath30 is given in @xmath18-order , the edges @xmath31 , for @xmath32 , form a monotone simple polygonal chain .",
    "let @xmath33 be the subdivision obtained by the union of this chain with the edges of the convex hull of @xmath0  ( denoted by @xmath34 ) .",
    "a convex hull edge is _ long _ if the difference between its indices is at least two ( i.e. , the endpoints are not consecutive ) .",
    "the following lemma ( illustrated in fig .  [ fig : monotone ] ) lets us decompose the problem into smaller pieces .",
    "[ lempartition ] any bounded face of @xmath33 is a mountain whose base is a long convex hull edge .",
    "moreover , no point of @xmath30 lies in more than four faces of @xmath33 .",
    "any point @xmath35 has at most four neighbors in @xmath33 : @xmath36 , @xmath37 , its predecessor and its successor along the convex hull ( if @xmath24 lies on @xmath34 ) .",
    "thus , no point of @xmath0belongs to more than four faces of @xmath33 .",
    "next we show that every face @xmath38 of @xmath33 is a mountain with a _ long _ convex - hull edge as its base .",
    "the boundary of @xmath38 contains at least one long convex - hull edge @xmath39 ( @xmath40 , as other edges connect only consecutive vertices . since the monotone path @xmath41 forms a cycle with the edge @xmath42 and the boundary of @xmath38 is a simple polygon ,",
    "we conclude that @xmath42 is the only long convex - hull edge bounding @xmath38 .",
    "recall that @xmath42 is a convex hull edge , and thus all points @xmath43 lie on one side of @xmath42 and form a monotone chain ( and in particular @xmath38 is a mountain with base @xmath42 ) .",
    "the algorithm for sorted input is now very simple .",
    "we compute the edges of the convex hull ( starting from the leftmost point and proceeding in clockwise order ) .",
    "whenever a long edge would be reported we pause the convex hull algorithm , and triangulate the corresponding mountain .",
    "once the mountain has been triangulated we resume with the convex hull algorithm until all convex hull edges have been computed .",
    "the trade - off follows from already existing trade - offs in the various subroutines .",
    "[ theo_sorted ] let @xmath30 be a set of @xmath1 points , sorted in @xmath18-order .",
    "we can report the edges of a triangulation of @xmath30 in @xmath16 time using @xmath13 variables , in @xmath44 time using @xmath6 variables ( for any @xmath45 ) , and in @xmath46 time using @xmath47 variables ( for any @xmath48 ) .",
    "correctness follows from lemma  [ lempartition ] , so we focus on the performance analysis .",
    "the main steps are : ( i ) computing the convex hull of a point set given in @xmath18-order ; and ( ii ) triangulating a mountain .    by theorem  [ obs : asanokirck ]",
    ", we can triangulate a mountain @xmath49 with @xmath50 vertices in time @xmath51 with @xmath6 variables .",
    "we do not need to store @xmath49 explicitly , since its vertices constitute a consecutive subsequence of @xmath0 and can be specified by the two endpoints of the base .",
    "no vertex appears in more than four mountains by lemma  [ lempartition ] , so the total time for triangulating the mountains is @xmath52 . by reusing space",
    ", we can ensure that the total space requirement is @xmath6 .",
    "now we bound the time for computing @xmath34 .",
    "this algorithm is paused to triangulate mountains , but overall it is executed only once .",
    "there are several convex hull algorithms for sorted point sets under memory constraints . if @xmath53 , we can use gift - wrapping ( jarvis march  @xcite ) , which runs in @xmath16 time .",
    "barba  _ et al . _",
    "@xcite provided a different algorithm that runs in @xmath44 time using @xmath6 variables ( for any @xmath54).-coordinate .",
    "] this approach is desirable for @xmath55 .",
    "as soon as @xmath56 , we can use the approach of chan and chen  @xcite .",
    "this algorithm runs in @xmath46 time and uses @xmath47 variables , for any @xmath57 .",
    "regardless of the size of the workspace , the time for computing the convex hull dominates the time needed for triangulating all mountains .    a similar approach is unlikely to work for the delaunay triangulation , since knowing the @xmath18-order of the input does not help in computing it  @xcite .",
    "the algorithm from section  [ sec_sorted ] uses the sorted order in two ways .",
    "firstly , the algorithms of barba  _ et al . _",
    "@xcite and of chan and chen  @xcite work only for simple polygons ( e.g. , for sorted input ) .",
    "instead , we use the algorithm by darwish and elmasry  @xcite that gives the upper ( or lower ) convex hull of any sequence of @xmath1 points in @xmath58 time with @xmath6 variables , but they measure workspace in bits while we use words . ] , matching known lower bounds . secondly , and more importantly , the asano - kirkpatrick ( ak ) algorithm requires the input to be sorted . to address this issue , we simulate sorted input using multiple heap structures .",
    "this requires a close examination of how the ak - algorithm accesses its input .",
    "let @xmath38 be a mountain with @xmath1 vertices .",
    "let @xmath59 and @xmath60 denote the vertices of @xmath38 in ascending and in descending @xmath18-order .",
    "the ak - algorithm has two phases , one of which focuses on @xmath59 and the other one on @xmath60.-order .",
    "this implies an nsl - algorithm by reading the input in reverse . ]",
    "each pass computes a portion of the triangulation edges , uses @xmath6 variables and scans @xmath61 times the input .",
    "we focus on the approach for @xmath59 .    in round @xmath62 , it partitions @xmath38 into blocks of @xmath63 consecutive points that are processed from left to right .",
    "each block is further subdivided into @xmath6 sub - blocks @xmath64 of size @xmath65 .",
    "the algorithm does two scans over the sub - blocks .",
    "the first scan processes the elements in @xmath18-order .",
    "whenever the first scan finishes reading a sub - block @xmath66 , the algorithm makes @xmath66 _ active _ and creates a pointer @xmath67 to the rightmost element of @xmath66 .",
    "the second scan goes from right to left and is concurrent to the first scan . in each step",
    ", it reads the element at @xmath67 in the rightmost active sub - block @xmath66 , and it decreases @xmath67 by one .",
    "if @xmath67 leaves @xmath66 , then @xmath66 becomes inactive .",
    "as the first scan creates new active sub - blocks as it proceeds , the second scan may jump between sub - blocks .",
    "the interested reader may find a more detailed description in  [ app : ak ] .",
    "we need the heap by asano  _ et al . _",
    "@xcite to provide the input for the ak - algorithm .",
    "we shortly restate its properties , a more detailed description can be found in  [ app : heap ] .",
    "[ lem : heap ] let @xmath0 be a set of @xmath1 points .",
    "there is a heap that supports insert and extract - min ( resp .",
    "extract - max ) in @xmath68 time using @xmath6 variables , where @xmath69 is the time to decide whether a given element currently resides in the heap ( is _ alive _ ) .",
    "since the authors studied a setting similar to lemma  [ lem : minheap ] where it takes @xmath13 time to decide whether an element is alive . ]",
    "[ lem : minheap ] let @xmath0 be a set of @xmath1 points . we can build a heap with all elements in @xmath0 in @xmath3 time that supports extract - min in @xmath70 time using @xmath6 variables .    the construction time is given in  @xcite . to decide in @xmath13 time if some @xmath71 is alive , we store the last extracted minimum @xmath72 and test whether @xmath73 .",
    "we now present the complete algorithm .",
    "we show how to subdivide @xmath0 into mountains @xmath49 and how to run the ak - algorithm on each @xmath74 . by reversing the order",
    ", the same discussion applies to @xmath75 .",
    "sorted input is emulated by two heaps @xmath76 , @xmath77 for @xmath0 according to @xmath18-order . by lemma  [ lem : minheap ]",
    ", each heap uses @xmath6 space , can be constructed in @xmath3 time , and supports extract - min in @xmath78 worst - case time .",
    "we will use @xmath76 to determine the size of the next mountain @xmath49 and @xmath77 to process the points of @xmath49 .",
    "we execute the convex hull algorithm with @xmath79 space until it reports the next convex hull edge @xmath80 . throughout the execution of the algorithm ,",
    "heaps @xmath76 and @xmath77 contain exactly the points to the right of @xmath81 .",
    "we repeatedly extract the minimum of @xmath76 until @xmath82 becomes the minimum element .",
    "let @xmath83 be the number of removed points .    if @xmath84 , then @xmath80 is short .",
    "we extract the minimum of @xmath77 , and we continue with the convex hull algorithm . if @xmath85 , then lemma  [ lempartition ] shows that @xmath80 is the base of a mountain @xmath38 that consists of all points between @xmath81 and @xmath82 .",
    "these are exactly the @xmath86 smallest elements in @xmath77 ( including @xmath81 and @xmath82 ) . if @xmath87 , we extract them from @xmath77 , and we triangulate @xmath38 in memory .",
    "if @xmath88 , we execute the ak - algorithm on @xmath38 using @xmath6 variables . at the beginning of the @xmath62th round ,",
    "we create a copy @xmath89 of @xmath77 , i.e. , we duplicate the @xmath6 variables that determine the state of @xmath77 .",
    "further , we create an empty max - heap @xmath90 using @xmath6 variables to provide input for the second scan . to be able to reread a sub - block , we create a further copy @xmath91 of @xmath77 .",
    "whenever the ak - algorithm requests the next point in the first scan , we simply extract the minimum of @xmath89 .",
    "when a sub - block is fully read , we use @xmath91 to reread the elements and insert them into @xmath90 .",
    "now , the rightmost element of all active sub - blocks corresponds exactly to the maximum of @xmath90 .",
    "one step in the second scan is equivalent to an extract - max on @xmath90 .    at the end of a round ,",
    "we delete @xmath89 , @xmath91 , and @xmath90 , so that the space can be reused in the next round .",
    "once the ak - algorithm finishes , we repeatedly extract the minimum of @xmath77 until we reach @xmath82 .",
    "[ theo_unsorted ] we can report the edges of a triangulation of a set @xmath0of @xmath1 points in time @xmath92 using @xmath6 additional variables .",
    "as before , correctness directly follows from lemma  [ lempartition ] and the correctness of the ak - algorithm .",
    "the bound on the space usage is immediate .",
    "computing the convex hull now needs @xmath58 time  @xcite . by lemma  [ lem : minheap ]",
    ", the heaps @xmath76 and @xmath77 can be constructed in @xmath3 time . during execution , we perform @xmath1 extract - min operations on each heap , requiring @xmath93 time in total .",
    "let @xmath94 be a mountain with @xmath95 vertices that is discovered by the convex hull algorithm .",
    "if @xmath96 , then @xmath94 is triangulated in memory in @xmath97 time , and the total time for such mountains is @xmath3 .",
    "if @xmath98 , then the ak - algorithm runs in @xmath99 time . we must also account for providing the input for the algorithm .",
    "for this , consider some round @xmath100 .",
    "we copy @xmath77 to @xmath89 in @xmath6 time .",
    "this time can be charged to the first scan , since @xmath98 .",
    "furthermore , we perform @xmath95 extract - min operations on @xmath89 . hence the total time to provide input for the first scan is @xmath101 .    for the second scan",
    ", we create another copy @xmath91 of @xmath77 .",
    "again , the time for this can be charged to the scan .",
    "also , we perform @xmath95 extract - min operations on @xmath91 which takes @xmath101 time . additionally , we insert each fully - read block into @xmath90 .",
    "the main problem is to determine if an element in @xmath90 is alive : there are at most @xmath6 active sub - blocks . for each active sub - block @xmath66 , we know the first element @xmath102 and the element @xmath103 that @xmath67 points to .",
    "an element is alive if and only if it is in the interval @xmath104 $ ] for some active @xmath66 .",
    "this can be checked in @xmath105 time .",
    "thus , by lemma  [ lem : heap ] , each insert and extract - max on @xmath90 takes @xmath106 time . since each element is inserted once , the total time to provide input to the second scan",
    "is @xmath107 .",
    "this dominates the time for the first scan .",
    "there are @xmath108 rounds , so we can triangulate @xmath94 in time @xmath109 .",
    "summing over all @xmath94 , the total time is @xmath92 .",
    "given a planar @xmath1-point set @xmath0 , we would like to find the vertices of @xmath15 .",
    "let @xmath110 be a triangle with @xmath111 so that all vertices of @xmath15 are vertices of @xmath112 .",
    "we use random sampling to divide the problem of computing @xmath112 into @xmath6 subproblems of size @xmath113 .",
    "first , we show how to take a random sample from @xmath0 with small workspace .",
    "one of many possible approaches is the following deterministic one that ensures a worst - case guarantee :    [ lem : sampling ] we can sample a uniform random subset @xmath114 of size @xmath5 in time @xmath115 and space @xmath6 .",
    "we sample a random sequence @xmath116 of @xmath5 distinct numbers from @xmath117 .",
    "this is done in @xmath5 _ rounds_. at the beginning of round @xmath83 , for @xmath118 , we have a sequence @xmath116 of @xmath119 numbers from @xmath117 .",
    "we store @xmath116 in a binary search tree @xmath120 .",
    "we maintain the invariant that each node in @xmath120 with value in @xmath121 stores a pointer to a unique number in @xmath122 that is not in @xmath116 . in round @xmath83 , we sample a random number @xmath18 from @xmath121 , and we check in @xmath120 whether @xmath123 . if not , we add @xmath18 to @xmath116 . otherwise , we add to @xmath116 the number that @xmath18 points to .",
    "let @xmath124 be the new element .",
    "we add @xmath124 to @xmath120 .",
    "then we update the pointers : if @xmath125 , we do nothing .",
    "now suppose @xmath126 .",
    "then , if @xmath127 , we put a pointer from @xmath18 to @xmath128 .",
    "otherwise , if @xmath129 , we let @xmath18 point to the element that @xmath128 points to .",
    "this keeps the invariant and takes @xmath105 time and @xmath6 space .",
    "we continue for @xmath5 rounds .",
    "any sequence of @xmath5 distinct numbers in @xmath117 is sampled with equal probability .",
    "finally , we scan through @xmath0 to obtain the elements whose positions correspond to the numbers in @xmath116 .",
    "this requires @xmath3 time and @xmath6 space .",
    "we use lemma  [ lem : sampling ] to find a random sample @xmath114 of size @xmath5 .",
    "we compute @xmath130 , triangulate the bounded cells and construct a planar point location structure for the triangulation .",
    "this takes @xmath131 time and @xmath6 space  @xcite .",
    "given a vertex @xmath132 , the _ conflict circle _ of @xmath133 is the largest circle with center @xmath133 and no point from @xmath134 in its interior . the _ conflict set _",
    "@xmath135 of @xmath133 contains all points from @xmath0 that lie in the conflict circle of @xmath133 , and the _ conflict size _",
    "@xmath136 of @xmath133 is @xmath137 .",
    "we scan through @xmath0 to find the conflict size @xmath136 for each vertex @xmath132 : every voronoi vertex has a counter that is initially @xmath138 . for each @xmath139",
    ", we use the point location structure to find the triangle @xmath140 of @xmath130 that contains it .",
    "at least one vertex @xmath133 of @xmath140 is in conflict with @xmath81 .",
    "starting from @xmath133 , we walk along the edges of @xmath130 to find all voronoi vertices in conflict with @xmath81 .",
    "we increment the counters of all these vertices .",
    "this may take a long time in the worst case , so we impose an upper bound on the total work .",
    "for this , we choose a _ threshold _ @xmath141 .",
    "when the sum of the conflict counters exceeds @xmath141 , we start over with a new sample @xmath142 . the total time for one attempt",
    "is @xmath143 , and below we prove that for @xmath144 the success probability is at least @xmath145 .",
    "next , we pick another threshold @xmath120 , and we compute for each vertex @xmath133 of @xmath130 the _ excess _",
    "@xmath146 . the excess measures how far the vertex deviates from the desired conflict size @xmath147 .",
    "we check if @xmath148 .",
    "if not , we start over with a new sample .",
    "below , we prove that for @xmath149 , the success probability is at least @xmath145 .",
    "the total success probability is @xmath150 , and the expected number of attempts is @xmath151 .",
    "thus , in expected time @xmath152 , we can find a sample @xmath114 with @xmath153 and @xmath154 .",
    "we now analyze the success probabilities , using the classic clarkson - shor method  @xcite .",
    "we begin with a variant of the chazelle - friedman bound  @xcite .",
    "[ lem : chazelle_friedman ] let @xmath155 be a planar point set of size @xmath156 , and let @xmath157 with @xmath158 .",
    "for fixed @xmath159 $ ] , let @xmath160 be a random subset of size @xmath161 and let @xmath162 be a random subset of size @xmath163 , for @xmath164 .",
    "suppose that @xmath165 .",
    "fix @xmath166 , and let @xmath167 be the voronoi vertex defined by @xmath168 .",
    "let @xmath169 be the number of points from @xmath155 in the largest circle with center @xmath167 and with no points from @xmath142 in its interior .",
    "then , @xmath170 \\leq 64 e^{-pb_{\\ensuremath{\\mathbf{u}}\\xspace}/2 } \\pr[v_{\\ensuremath{\\mathbf{u}}\\xspace}\\in \\operatorname{vd}(r ' \\cup y)].\\ ] ]    let @xmath171 $ ] and @xmath172 $ ] .",
    "the vertex @xmath167 is in @xmath173 precisely if @xmath174 and @xmath175 , where @xmath176 are the points from @xmath155 in the conflict circle of @xmath167 . if @xmath177 , then @xmath178 , and the lemma holds",
    "thus , assume that @xmath179 .",
    "let @xmath180 , the number of points in @xmath168 not in @xmath181 .",
    "there are @xmath182 ways to choose a @xmath161-subset from @xmath155 that avoids all points in @xmath176 and contains all points of @xmath183 , so    @xmath184    similarly , we get @xmath185 and since @xmath165 and @xmath186 , it follows that @xmath187 therefore , since @xmath164 , @xmath188    we can now bound the total expected conflict size .",
    "[ lem : conflict_size ] we have @xmath189 = o(n)$ ] .    by expanding the expectation , we get @xmath190 & = \\sum_{{\\ensuremath{\\mathbf{u}}\\xspace}\\in s^3}\\pr[v_{\\ensuremath{\\mathbf{u}}\\xspace}\\in \\operatorname{vd}(r \\cup k ) ] b_{\\ensuremath{\\mathbf{u}}\\xspace},\\\\ \\intertext{$v_{\\ensuremath{\\mathbf{u}}\\xspace}$ being the voronoi vertex of $ { \\ensuremath{\\mathbf{u}}\\xspace}$ and $ b_{\\ensuremath{\\mathbf{u}}\\xspace}$ its conflict size . by lemma~\\ref{lem : chazelle_friedman } with $ x = s$ , $ y = k$ and $ p = s / n$ , }      & \\leq \\sum_{{\\ensuremath{\\mathbf{u}}\\xspace}\\in s^3 } 64 e^{-pb_{\\ensuremath{\\mathbf{u}}\\xspace}/2 } \\pr[v_{\\ensuremath{\\mathbf{u}}\\xspace}\\in \\operatorname{vd}(r ' \\cup k)]b_{\\ensuremath{\\mathbf{u}}\\xspace},\\\\ \\intertext{where $ r ' \\subseteq s$ is a sample of size $ s/2$. we estimate } & \\leq      \\sum_{t = 0}^{\\infty}\\sum_{\\substack{{\\ensuremath{\\mathbf{u}}\\xspace}\\in s^3\\\\          b_{\\ensuremath{\\mathbf{u}}\\xspace}\\in [ \\frac{t}{p } ,   \\frac{t+1}{p } ) } }      \\frac{64 e^{-t/2}(t+1)}{p }      \\pr[v_{\\ensuremath{\\mathbf{u}}\\xspace}\\in \\operatorname{vd}(r ' \\cup k)]\\\\ & \\leq      \\frac{1}{p}\\ , \\sum_{{\\ensuremath{\\mathbf{u}}\\xspace}\\in s^3 }      \\pr[v_{\\ensuremath{\\mathbf{u}}\\xspace}\\in \\operatorname{vd}(r ' \\cup k ) ]      \\sum_{t = 0}^{\\infty }      64 e^{-t/2}(t+1)\\\\ & = o(s / p ) =   o(n ) ,    \\end{aligned}\\ ] ] since @xmath191 = o(s)$ ] is the size of @xmath192 and @xmath193 .    by lemma  [ lem : conflict_size ] and markov s inequality , it follows that there is an @xmath144 with @xmath194 \\leq 1/4 $ ] .",
    "[ lem : excess ] @xmath195    = o(s)$ ] .    by lem .",
    "[ lem : chazelle_friedman ] with @xmath196 , @xmath197 , and @xmath198 , @xmath199      & =      \\sum_{{\\ensuremath{\\mathbf{u}}\\xspace}\\in s^3}\\pr[v_{\\ensuremath{\\mathbf{u}}\\xspace}\\in \\operatorname{vd}(r \\cup k)]\\ , t_{\\ensuremath{\\mathbf{u}}\\xspace}\\log t_{\\ensuremath{\\mathbf{u}}\\xspace}\\\\      & \\leq \\sum_{{\\ensuremath{\\mathbf{u}}\\xspace}\\in s^3 } 64 e^{-pb_{\\ensuremath{\\mathbf{u}}\\xspace}/2 } \\pr[v_{\\ensuremath{\\mathbf{u}}\\xspace}\\in \\operatorname{vd}(r ' \\cup k)]t_{\\ensuremath{\\mathbf{u}}\\xspace}\\log t_{\\ensuremath{\\mathbf{u}}\\xspace}\\\\ & \\leq      \\sum_{t = 0}^{\\infty}\\sum_{\\substack{{\\ensuremath{\\mathbf{u}}\\xspace}\\in s^3\\\\          b_{\\ensuremath{\\mathbf{u}}\\xspace}\\in [ \\frac{t}{p } , \\frac{t+1}{p } ) } }          64 e^{-\\frac{t}{2}}(t+1)^2      \\pr[v_{\\ensuremath{\\mathbf{u}}\\xspace}\\in \\operatorname{vd}(r ' \\cup k)]\\\\ & \\leq      \\sum_{t = 0}^{\\infty }      64 e^{-\\frac{t}{2}}(t+1)^2      \\sum_{{\\ensuremath{\\mathbf{u}}\\xspace}\\in s^3 }      \\pr[v_{\\ensuremath{\\mathbf{u}}\\xspace}\\in \\operatorname{vd}(r ' \\cup k ) ] =    o(s ) .",
    "\\end{aligned}\\ ] ]    by markov s inequality and lemma  [ lem : excess ] , we can conclude that there is a @xmath149 with @xmath200 \\leq 1/4 $ ] .",
    "this finishes the first sampling phase .",
    "the next goal is to sample for each vertex @xmath133 with @xmath201 a random subset @xmath202 of size @xmath203 for large enough @xmath204 ( recall that @xmath135 is the conflict set of @xmath133 ) .    in total time @xmath205",
    ", we can sample for each vertex @xmath132 with @xmath201 a random subset @xmath202 of size @xmath203 .",
    "first , we perform @xmath6 rounds to sample for each vertex @xmath133 with @xmath201 a sequence @xmath206 of @xmath207 distinct numbers from @xmath208 . for this",
    ", we use the algorithm from lemma  [ lem : sampling ] in parallel for each relevant vertex from @xmath130 .",
    "since @xmath209 , this takes total time @xmath210 and total space @xmath6 .",
    "after that , we scan through @xmath0 . for each vertex @xmath133 , we have a counter @xmath211 , initialized to @xmath138 . for each @xmath212",
    ", we find the conflict vertices of @xmath81 , and for each conflict vertex @xmath133 , we increment @xmath211 . if @xmath211 appears in the corresponding set @xmath206 , we add @xmath81 to @xmath213 .",
    "the total running time is @xmath205 , as we do one point location for each input point and the total conflict size is @xmath3 .",
    "we next show that for a _ fixed _",
    "vertex @xmath132 , with constant probability , all vertices in @xmath214 have conflict size @xmath147 with respect to @xmath135 .    [",
    "lem : second_sample ] let @xmath132 with @xmath201 , and let @xmath202 be the sample for @xmath133 .",
    "the expected number of vertices @xmath215 in @xmath214 with at least @xmath147 points from @xmath135 in their conflict circle is at most @xmath216 .",
    "recall that @xmath146 .",
    "we have @xmath217 & =      \\sum_{\\substack{{\\ensuremath{\\mathbf{u}}\\xspace}\\in b_v^3\\\\b'_{\\ensuremath{\\mathbf{u}}\\xspace}\\geq n / s } }      \\pr[v'_{\\ensuremath{\\mathbf{u}}\\xspace}\\in \\operatorname{vd}(r_v ) ] , \\\\",
    "\\intertext{where $ b'_{\\ensuremath{\\mathbf{u}}\\xspace}$ is the conflict size of $ v'_{\\ensuremath{\\mathbf{u}}\\xspace}$        with respect to $ b_v$. using lemma~\\ref{lem : chazelle_friedman } with $ x = b_v$ , $ y = \\emptyset$ , and $ p = ( \\alpha t_v \\log t_v)/b_v",
    "= \\alpha(s / n)\\log t_v$ , this is }      & \\leq \\sum_{\\substack{{\\ensuremath{\\mathbf{u}}\\xspace}\\in b_v^3\\\\b'_{\\ensuremath{\\mathbf{u}}\\xspace}\\geq n / s } } 64 e^{-pb'_{\\ensuremath{\\mathbf{u}}\\xspace}/2 } \\pr[v'_{\\ensuremath{\\mathbf{u}}\\xspace}\\in \\operatorname{vd}(r'_v)]\\\\ & \\leq 64 e^{-(\\alpha/2 ) \\log t_v } \\sum_{{\\ensuremath{\\mathbf{u}}\\xspace}\\in b_v^3 } \\pr[v'_{\\ensuremath{\\mathbf{u}}\\xspace}\\in \\operatorname{vd}(r'_v)]\\\\ & = o(t_v^{-\\alpha/2 } t_v \\log t_v ) \\leq 1/4 ,    \\end{aligned}\\ ] ] for @xmath218 large enough ( remember that @xmath201 ) .",
    "the two red square vertices of @xmath130 are not good and we need to resample within their conflict list ( the blue crosses ) and compute the new voronoi diagram ( right ) . ]    by lemma  [ lem : second_sample ] and markov s inequality , the probability that all vertices from @xmath214 have at most @xmath147 points from @xmath135 in their conflict circles is at least @xmath145 .",
    "if so , we call @xmath133 _ good _ , see figure  [ fig : resampledvd ] . scanning through @xmath0 , we can identify the good vertices in time @xmath205 and space @xmath6 .",
    "let @xmath219 be the size of @xmath130 .",
    "if we have less than @xmath220 good vertices , we repeat the process .",
    "since the expected number of good vertices is @xmath221 , the probability that there are at least @xmath220 good vertices is at least @xmath150 by markov s inequality .",
    "thus , in expectation , we need to perform the sampling twice . for the remaining vertices ,",
    "we repeat the process , but now we take two samples per vertex , decreasing the failure probability to @xmath216 .",
    "we repeat the process , taking in each round the maximum number of samples that fit into the work space . in general ,",
    "if we have @xmath222 active vertices in round @xmath62 , we can take @xmath223 samples per vertex , resulting in a failure probability of @xmath224 .",
    "thus , the expected number of active vertices in round @xmath225 is @xmath226 .",
    "after @xmath227 rounds , all vertices are good . to summarize :    [ lem : main_sample ] in total expected time @xmath228 and space @xmath6 , we can find sets @xmath114 and @xmath229 for each vertex @xmath230 such that ( i ) @xmath231 : ( ii ) @xmath232 ; and ( iii ) for every @xmath213 , all vertices of @xmath214 have at most @xmath147 points from @xmath135 in their conflict circle .",
    "we set @xmath233 . by lemma  [ lem : main_sample ] , @xmath234 .",
    "we compute @xmath235 and triangulate its bounded cells . for a triangle @xmath140 of the triangulation ,",
    "let @xmath236 be the site whose cell contains @xmath140 , and @xmath237 the vertices of @xmath140 .",
    "we set @xmath238 . using the next lemma ,",
    "we show that @xmath239 .",
    "[ lem : ccirc_cov ] let @xmath240 and @xmath241 a triangle in the triangulation of @xmath15 .",
    "let @xmath242 .",
    "then any circle @xmath243 with center @xmath18 that contains no points from @xmath0 is covered by the conflict circles of @xmath244 and @xmath245 .",
    "let @xmath246 and let @xmath247 be the site whose cell contains @xmath140 .",
    "we show that @xmath81 is contained in the conflict circle of @xmath248 , @xmath249 , or @xmath245 .",
    "consider the bisector @xmath250 of @xmath81 and @xmath251 .",
    "since @xmath243 contains @xmath81 but not @xmath251 , we have @xmath252 , so @xmath18 lies on the same side of @xmath250 as @xmath81 . since @xmath242 ,",
    "at least one of @xmath248 , @xmath249 , @xmath245 , is on the same side of @xmath250 as @xmath81 ; say @xmath248 .",
    "this means that @xmath253 , so @xmath81 lies inside the circle around @xmath248 with @xmath251 on the boundary .",
    "this is precisely the conflict circle of @xmath248 .",
    "any triangle @xmath140 in the triangulation of @xmath254 has @xmath239 .",
    "let @xmath133 be a vertex of @xmath140 .",
    "we show that @xmath255 .",
    "let @xmath256 be the triangle in the triangulation of @xmath257 that contains @xmath133 .",
    "by lemma  [ lem : ccirc_cov ] , we have @xmath258 .",
    "we consider the intersections @xmath259 , for @xmath260 . if @xmath261 , then @xmath262 and @xmath263",
    "otherwise , we have sampled a set @xmath264 for @xmath265 .",
    "let @xmath266 be the triangle in the triangulation of @xmath267 that contains @xmath133 .",
    "again , by lemma  [ lem : ccirc_cov ] , we have @xmath268 and thus also @xmath269 . however , by construction of @xmath264",
    ", @xmath270 is at most @xmath147 for @xmath271 .",
    "hence , @xmath263 and @xmath272 .",
    "the following lemma enables us to compute the voronoi diagram of @xmath273 locally for each triangle @xmath140 in the triangulation of @xmath254 by only considering sites in @xmath274 .",
    "it is a direct consequence of lemma  [ lem : ccirc_cov ] .",
    "[ lem : d_n_c ] for every triangle @xmath140 in the triangulation of @xmath235 , we have @xmath275 .",
    "[ thm : voronoi ] let @xmath0 be a planar @xmath1-point set . in expected time @xmath276 and space @xmath6",
    ", we can compute all voronoi vertices of @xmath0 .",
    "we compute a set @xmath277 as above .",
    "this takes @xmath278 time and space @xmath6 .",
    "we triangulate the bounded cells of @xmath235 and compute a point location structure for the result . since there are @xmath6 triangles , we can store the resulting triangulation in the workspace .",
    "now , the goal is to compute simultaneously for all triangles @xmath140 the voronoi diagram @xmath279 and to output all voronoi vertices that lie in @xmath140 and are defined by points from @xmath0 . by lemma  [ lem : d_n_c ] , this gives all voronoi vertices of @xmath15 .",
    "given a planar @xmath72-point set @xmath155 , the algorithm by asano et al .",
    "finds all vertices of @xmath280 in @xmath281 scans over the input , with constant workspace  @xcite .",
    "we can perform a simultaneous scan for all sets @xmath274 by determining for each point in @xmath0 all sets @xmath274 that contain it .",
    "this takes total time @xmath205 , since we need one point location for each @xmath212 and since the total size of the @xmath274 s is @xmath3 .",
    "we need @xmath282 such scans , so the second part of the algorithm needs @xmath283 time .    as mentioned in the introduction , theorem  [ thm : voronoi ] also lets us report all edges of the delaunay triangulation of @xmath0 in the same time bound : by duality , the three sites that define a vertex of @xmath15 also define a triangle for the delaunay triangulation . thus , whenever we discover a vertex of @xmath15 , we can instead output the corresponding delaunay edges , while using a consistent tie - breaking rule to make sure that every edge is reported only once .",
    "[ [ acknowledgments ] ] acknowledgments + + + + + + + + + + + + + + +    this work began while w.  mulzer , p.  seiferth , and y.  stein visited the tokuyama laboratory at tohoku university .",
    "we would like to thank takeshi tokuyama and all members of the lab for their hospitality and for creating a conducive and stimulating research environment .",
    "10    t.  asano , k.  buchin , m.  buchin , m.  korman , w.  mulzer , g.  rote , and a.  schulz .",
    "memory - constrained algorithms for simple polygons . , 46(8):959969 , 2013 .",
    "t.  asano , a.  elmasry , and j.  katajainen .",
    "priority queues and sorting for read - only data . in _ theory and applications of models of computation _ , pages 3241 .",
    "t.  asano and d.  kirkpatrick .",
    "time - space tradeoffs for all - nearest - larger - neighbors problems . in _ proc .",
    "algorithms and data structures ( wads ) _ , pages 6172 , 2013 .",
    "t.  asano , w.  mulzer , g.  rote , and y.  wang .",
    "constant - work - space algorithms for geometric problems .",
    ", 2(1):4668 , 2011 .",
    "l.  barba , m.  korman , s.  langerman , k.  sadakane , and r.  i. silveira .",
    "time trade - offs for stack - based algorithms . , 72(4):10971129 , 2015 .",
    "l.  barba , m.  korman , s.  langerman , and r.  i. silveira .",
    "computing the visibility polygon using few variables .",
    ", 47(9):918926 , 2013 .",
    "m.  de  berg , o.  cheong , m.  van kreveld , and m.  overmars .",
    "springer - verlag , third edition , 2008 .",
    "a.  borodin and s.  cook . a time - space tradeoff for sorting on a general sequential model of computation .",
    ", 11:287297 , 1982 .",
    "h.  brnnimann , t.  m. chan , and e.  y. chen . towards in - place geometric algorithms and data structures . in _ proc .",
    "20th annu .",
    "( socg ) _ , pages 239246 , 2004",
    ".    t.  m. chan and e.  y. chen .",
    "multi - pass geometric algorithms . , 37(1):79102 , 2007 .",
    "b.  chazelle and j.  friedman . a deterministic view of random sampling and its use in geometry .",
    ", 10(3):229249 , 1990 .",
    "k.  l. clarkson and p.  w. shor .",
    "applications of random sampling in computational geometry , ii . , 4:387421 , 1989 .",
    "o.  darwish and a.  elmasry .",
    "optimal time - space tradeoff for the 2d convex - hull problem . in _ proc .",
    "22nd annu .",
    "european sympos .",
    "algorithms ( esa ) _ , pages 284295 , 2014 .",
    "h.  djidjev and a.  lingas . on computing voronoi diagrams for sorted point sets .",
    ", 5(3):327337 , 1995 .",
    "a.  fournier and d.  y. montuno . triangulating simple polygons and equivalent problems .",
    ", 3:153174 , 1984 .",
    "s.  har - peled . .",
    "( socg ) _ , pages 111125 , 2015 .",
    "r.  jarvis . on the identification of the convex hull of a finite set of points in the plane .",
    ", 2(1):1821 , 1973 .",
    "d.  kirkpatrick .",
    "optimal search in planar subdivisions .",
    ", 12(1):2835 , 1983 .",
    "j.  i. munro and m.  paterson .",
    "selection and sorting with limited storage .",
    ", 12:315323 , 1980 .",
    "j.  i. munro and v.  raman .",
    "selection from read - only memory and sorting with minimum data movement .",
    ", 165(2):311323 , 1996 .",
    "j.  pagter and t.  rauhe .",
    "optimal time - space trade - offs for sorting . in _ proc .",
    "39th annu .",
    "ieee sympos . found .",
    "( focs ) _ , pages 264268 , 1998 .",
    "i.  pohl . a minimum storage algorithm for computing the median .",
    "technical report rc2701 , ibm , 1969 .",
    "j.  e. savage . .",
    "addison - wesley , 1998 .",
    "we give more details on the algorithm of asano and kirkpatrick  @xcite .",
    "let @xmath38 be a mountain with vertices @xmath284 sorted in @xmath18-order and base @xmath285 .",
    "we define the _ height _ @xmath286 of @xmath24 , @xmath287 , as the distance from @xmath24 to the line through the base .",
    "let @xmath288 be the input array .",
    "a vertex @xmath289 is the _ nearest - smaller - right - neighbor _ ( nsr ) of a vertex @xmath290 if ( i ) @xmath291 ; ( ii ) @xmath292 ; and ( iii ) @xmath293 for @xmath294 .",
    "we call @xmath295 a _ nsr - pair _ , with _ left endpoint _ @xmath290 and _ right endpoint _ @xmath289 . _ nearest - smaller - left - neighbors _ ( nsl ) and nsl - pairs are defined similarly .",
    "let @xmath142 be the set of all nsr - pairs and @xmath296 be the set of all nsl pairs .",
    "asano and kirkpatrick show that the edges @xmath297 triangulate @xmath38 .",
    "we describe the algorithm for computing @xmath142 .",
    "the algorithm for @xmath296 is the same , but it reads the input in reverse .",
    "let @xmath5 denote the space parameter .",
    "the algorithm runs in @xmath298 _ rounds_. in round @xmath62 , @xmath299 , we partition @xmath300 into @xmath301 consecutive _ blocks _ of size @xmath302 .",
    "each block @xmath250 is further partitioned into @xmath5 consecutive _ sub - blocks _ @xmath303 of size @xmath304 . in each round , we compute only nsr - pairs with endpoints in different sub - blocks of the same block .",
    "we handle each block @xmath250 individually as follows .",
    "the sub - blocks of @xmath250 are visited from left to right .",
    "when we visit a sub - block @xmath305 , we compute all nsr - pairs with a right endpoint in @xmath305 and a left endpoint in the sub - blocks @xmath306 .",
    "initially , we visit the first sub - block @xmath307 and we push a pointer to the rightmost element in @xmath307 onto a stack @xmath0 .",
    "we call a sub - block with a pointer in @xmath0 _",
    "active_. assume now that we have already visited sub - blocks @xmath308 .",
    "let @xmath309 be the topmost pointer in @xmath0 , referring to an element @xmath290 in @xmath310 , @xmath311 .",
    "furthermore , let @xmath251 be a pointer to the leftmost element @xmath289 in @xmath312 . if @xmath292 , we output @xmath295 and we decrement @xmath309 until we find the first element whose height is smaller than the current @xmath313 .",
    "if @xmath309 leaves @xmath310 , this sub - block becomes inactive and we remove @xmath309 from @xmath0 .",
    "we continue with the new topmost pointer as our new @xmath309 . on the other hand , if @xmath314 , we increment @xmath251 by one .",
    "we continue until either @xmath251 leaves @xmath312 or @xmath0 becomes empty .",
    "then we push a pointer to the rightmost element in @xmath312 onto @xmath0 and proceed to the next sub - block .    in each round",
    ", the algorithm reads the complete input once in @xmath18-order .",
    "in addition , the algorithm reads at most once each active sub - blocks in reverse order .",
    "note that a sub - block becomes active only once .",
    "we first describe the data structure .",
    "then we discuss how to perform insertions and extract - min operations .",
    "we partition the input into @xmath315 consecutive _ buckets _ of equal size , and we build a complete binary tree @xmath120 over the buckets .",
    "let @xmath133 be a node of @xmath120 with height @xmath316 .",
    "then , there are @xmath317 buckets below @xmath133 in @xmath120 .",
    "we store @xmath318 _ information bits _ in @xmath133 to specify the minimum alive element below @xmath133 .",
    "the first @xmath316 bits identify the bucket containing the minimum .",
    "we further divide this bucket into @xmath317 consecutive parts of equal size , called _",
    "quantiles_. the second @xmath316 bits in @xmath133 specify the quantile containing the minimum .",
    "if @xmath319 , we use @xmath320 bits to specify the minimum directly .",
    "hence , the total number of bits is bounded by @xmath321 therefore we need @xmath6 variables in total .",
    "let @xmath133 be a node with height @xmath316 . to find the minimum alive element in @xmath120 below @xmath133",
    ", we use the @xmath318 information bits stored in @xmath133 .",
    "first , we identify the bucket containing the minimum and the correct quantile within this bucket .",
    "this quantile contains @xmath322 elements . for each element in the quantile",
    ", we decide in @xmath69 time whether it is alive , and we return the minimum such element .",
    "this takes @xmath323 time in total .",
    "insert : : :    assume we want to insert an element @xmath18 that is at    position @xmath62 in the input array .",
    "let @xmath133 be    the parent of the leaf of @xmath120 corresponding to the bucket    that contains @xmath18 .",
    "we update the information bits at each    node @xmath324 on the root path starting at @xmath133 .",
    "to    do so , we use the information bits in @xmath324 to find the    minimum element in the buckets covered by @xmath324 , as    described above .",
    "then we compare it with @xmath18 .",
    "if    @xmath18 is larger , we are done and we stop the insertion .    otherwise , we update the information bits at @xmath324 to the    bucket and quantile that contain @xmath18 .",
    "if we reach and    update the root node , we also update the pointer that points to the    minimum element in the heap .",
    "the work per node is dominated by the    costs for finding the minimum , which is    @xmath323 .",
    "thus , the total cost for    insertion is bounded by    @xmath325 extract - min : : :    first we use the pointer to the minimum alive element to determine the    element @xmath18 to return",
    ". then we use a similar update    strategy as for insertions .",
    "let @xmath133 be the leaf node    corresponding to the bucket of @xmath18 .",
    "we first update the    information bits of @xmath133 by scanning through the whole    bucket of @xmath133 and determining the smallest alive element .",
    "since a bucket contains @xmath326 elements , this    needs time @xmath327 .",
    "then we update the    information bits of each node @xmath324 on the path for    @xmath133 as follows : let @xmath248 and    @xmath249 be the two children of @xmath324 .",
    "we determine    the minimum alive element in the buckets covered by @xmath248    and @xmath249 , take the smaller one , and use it to update the    information bits at @xmath324 .",
    "once we reach the root , we also    update the pointer to the minimum element of the heap to the new    minimum element of the root .",
    "the total time again is bounded by    @xmath328 ."
  ],
  "abstract_text": [
    "<S> let @xmath0 be a planar @xmath1-point set . </S>",
    "<S> a _ triangulation _ for @xmath0 is a maximal plane straight - line graph with vertex set @xmath0 . </S>",
    "<S> the _ voronoi diagram _ for @xmath0 is the subdivision of the plane into cells such that each cell has the same nearest neighbors in @xmath0 . </S>",
    "<S> classically , both structures can be computed in @xmath2 time and @xmath3 space . </S>",
    "<S> we study the situation when the available workspace is limited : given a parameter @xmath4 , an @xmath5-workspace algorithm has read - only access to an input array with the points from @xmath0 in arbitrary order , and it may use only @xmath6 additional words of @xmath7 bits for reading and writing intermediate data . the output should then be written to a write - only structure . </S>",
    "<S> we describe a deterministic @xmath5-workspace algorithm for computing a triangulation of @xmath0 in time @xmath8 and a randomized @xmath5-workspace algorithm for finding the voronoi diagram of @xmath0 in expected time @xmath9 . </S>"
  ]
}