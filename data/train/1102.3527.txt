{
  "article_text": [
    "linear network coding provides an excellent solution to the wireless broadcasting problem in terms of reliability and channel utilization @xcite .",
    "the idea is to send encoded packets that are obtained by taking linear combinations over a finite field of all the original packets .",
    "the encoding vector specifies the coefficients for the linear combination and is determined by the transmitter .",
    "an encoded packet together with a header which contains the corresponding encoding vector is broadcasted to all users .",
    "an encoded packet is said to be _ innovative to a user _ if the corresponding encoding vector is not in the subspace spanned by the encoding vectors already received by that user .",
    "it is called _ innovative _ if it is innovative to all users who have not yet received enough packets for decoding . obviously , if all the encoded packets generated by the transmitter for transmission are _ innovative _ , the total number of packet transmissions for all users to obtain the complete set of packets can be minimized .    to utilize the radio channel efficiently ,",
    "it is important to generate innovative packets . in  @xcite",
    ", it is shown that if the size of the finite field is equal to the number of users , an innovative packet can always be found . in @xcite ,",
    "the authors consider a system with perfect feedback , in which the transmitter knows the status of all users and tries to find an innovative packet by a probabilistic algorithm .",
    "this approach is shown to be _ rate - optimal _ if the underlying finite field is sufficiently large .",
    "the average number of transmissions is analyzed in  @xcite . by exploiting the feedback information from users ,",
    "some authors develop algorithms to generate instantly decodable network - coded packets in @xcite so that innovative packets can be decoded once the packets are available at the receivers without waiting for the complete reception of the full set of packets .",
    "randomized broadcast coding without utilizing any feedback is analyzed in  @xcite .",
    "the computation with large finite field may be costly for mobile hand - held devices . in order to reduce encoding and decoding complexity ,",
    "random linear network code over the binary field without feeding back what the receivers have received is considered in  @xcite .",
    "this approach lowers computational complexity at the expense of larger number of retransmissions .",
    "when the finite field size is small , an innovative encoding vector may not exist . in section  [ sec : nphard ] , we prove that the problem of determining the existence of innovative encoding vector is np - complete .",
    "a related result is also obtained in  @xcite , where the broadcast channel is assumed to be noiseless , and the problem of minimizing the number of packets required to finish off the file transmission with the binary finite field is shown to be np - complete . in section iv , we show that we can always find a sparse and innovative encoding vector with at most @xmath0 non - zero components using a deterministic algorithm called the cofactor method . in section",
    "[ sec : pe ] , the cofactor method is compared with some other transmission schemes by simulation , for both small and large finite fields .",
    "we consider a wireless single - hop system consisting of one transmitter and @xmath0 receivers / users . we denote @xmath1 as the source node and @xmath2 as the @xmath3-th receiver , where @xmath4 .",
    "the source node @xmath1 wants to broadcast a file to all receivers via a wireless channel , which is modeled as a broadcast erasure channel .",
    "the input to the broadcast erasure channel is a @xmath5-ary alphabet .",
    "we will also call a @xmath5-ary alphabet a packet .",
    "each receiver successfully receives the transmitted packet with probability @xmath6 , independent of each other , where @xmath7 denotes the erasure probability .",
    "an erased packet is unrecoverable and discarded , while a successfully received packet is assumed to be error - free .",
    "we assume that there is a feedback channel from each receiver to the source . upon receiving a packet successfully",
    ", a receiver sends an acknowledgement to the source node .",
    "we assume that the feedback channel has no delay and no error .",
    "the source node keeps track of the status of each receiver .",
    "the transmitted packet is a function of the source file and the acknowledgements from the @xmath0 receivers .    in this paper , we focus on transmission schemes with linear network coding . the alphabet size @xmath5 is a power of prime and the alphabet set is identified with the finite field @xmath8 .",
    "the file is packetized into @xmath9 packets .",
    "the transmitted packet is a linear combination of the @xmath9 packets , with coefficients drawn from @xmath8 .",
    "an encoding vector is an @xmath9-vector whose components are the @xmath9 coefficients used in the generation of a transmitted packet .",
    "each user returns an acknowledgement to the source node if a packet is received successfully , until he has already received @xmath9 packets whose encoding vectors are linearly independent over @xmath8 . in order to minimize the delay of each user , it is crucial to generate encoding vectors which are innovative to all users .",
    "our objectives are ( i ) to determine whether an innovative encoding vector exists , and ( ii ) to devise an effective algorithm for generating innovative and sparse encoding vectors .",
    "if the field size @xmath5 is larger than or equal to @xmath0 , it is known that an innovative encoding can always be found  @xcite . indeed , the number of non - zero encoding vectors which are _ not _ innovative to user @xmath3 is equal to @xmath11 , where @xmath12 is the rank of the subspace spanned by the encoding vectors already received by user  @xmath3 and @xmath13 , and hence by the union bound , the number of non - zero vectors which are not innovative is at most @xmath14 .",
    "when @xmath15 , the number of non - zero and non - innovative encoding vector is strictly less than @xmath16 , and hence we can always find an innovative packet .",
    "when the underlying finite field is small , an innovative encoding vector may not exist .",
    "* problem * @xmath5-@xmath17 : a problem instance consists of @xmath0 matrices @xmath18 over @xmath8 , @xmath19 , and each matrix has @xmath9 columns .",
    "determine whether there is an @xmath9-dimensional vector over @xmath8 which is not in the row space of @xmath18 , for all @xmath3 .",
    "2-@xmath17 is np - complete .",
    "the idea is to reduce the 3-@xmath20 problem , well - known to be np - complete  @xcite , to the 2-@xmath17 problem .",
    "recall that the 3-@xmath20 problem is a boolean satisfiability problem , whose instance is a boolean expression written in conjunctive normal form with three variables per clause ( 3-@xmath21 ) , and the question is to decide if there is some assignment of true and false to the variables such that the given boolean expression has a true value .",
    "let @xmath22 be a given boolean expression with @xmath23 variables @xmath24 , and @xmath25 clauses in 3-cnf .",
    "we want to reduce the 3-@xmath20 problem to the 2-@xmath17 problem with @xmath26 packets and @xmath27 users .    to the @xmath3-th clause ( @xmath28 ) ,",
    "we first construct a @xmath29 matrix @xmath30 . if the @xmath31-th literal ( @xmath32 ) in the @xmath3-th clause is @xmath33 , then let the @xmath34-th component in the @xmath31-th row of @xmath30 be 1 , and the other elements be all zero .",
    "otherwise , if the @xmath31-th literal in the @xmath3-th clause is @xmath35 , then let the @xmath34-th and the @xmath36-st component in the @xmath31-th row of @xmath30 be 1 , and the remaining components be all zero .",
    "let @xmath18 be the matrix whose rows form a basis of the orthogonal complement of the row space of @xmath30 .",
    "we will use the fact that a vector @xmath37 is in the row space of @xmath18 if and only if @xmath38 .",
    "consider an example with @xmath39 boolean variables . from the clause @xmath40 , we get @xmath41 it can be verified that each row in @xmath30 is orthogonal to the rows in @xmath18 , i.e. , the row space of @xmath18 is the orthogonal complement of the row space of @xmath30 .    for the extra user , user @xmath42 ,",
    "let @xmath43 be the @xmath44 matrix @xmath45 $ ] , where @xmath46 stands for the @xmath47 all - zero vector .",
    "the problem reduction can be done in polynomial time .",
    "let @xmath48 $ ] be a boolean row vector and @xmath49 $ ] .",
    "obviously , any solution @xmath50 to a 3-@xmath20 problem would cause the product @xmath51 a non - zero vector for @xmath52 and @xmath45\\hat { \\mathbf{x}}^t \\neq 0 $ ] .",
    "therefore @xmath53 is not in the row space of @xmath54 for all @xmath31 .",
    "hence @xmath53 is also a solution to the derived 2-@xmath17 problem .",
    "conversely , any solution to the derived 2-@xmath17 problem also yields a solution to the original 3-@xmath20 problem as well .",
    "let @xmath55 \\in gf(2)^{n+1}$ ] be a solution to the derived 2-@xmath17 problem .",
    "note that we must have @xmath56 because of @xmath43 .",
    "let @xmath3 be an integer between 1 and  @xmath25 .",
    "since @xmath57 is not in the row space of @xmath18 , the product @xmath58 is a non - zero vector , for otherwise @xmath57 would belong to the orthogonal complement of @xmath30 .",
    "hence , if we assign true to @xmath33 if @xmath59 and false to @xmath33 if @xmath60 , for @xmath61 , then the @xmath3-th clause will have a true value . since this is true for all @xmath3 , the whole boolean expression also has a true value .",
    "the problem 2-@xmath17 is clearly in np , since it is efficiently verifiable .",
    "hence it is np - complete .",
    "after receiving @xmath9 packets whose encoding vectors are linearly independent over @xmath8 , a user can recover the source data by solving a system of @xmath9 linear equations .",
    "the standard gaussian elimination requires @xmath62 operations over @xmath8 .",
    "one way to reduce the decoding complexity is to choose encoding vectors which are sparse .",
    "a vector is called _",
    "@xmath63-sparse _ if there are no more than @xmath63 non - zero components .",
    "if @xmath15 , we can find an innovative encoding vector which is @xmath0-sparse .",
    "[ thm : cofactor ]    suppose that user @xmath34 , for @xmath64 , has received @xmath65 packets whose encoding vectors are linearly independent .",
    "let @xmath66 be the @xmath67 matrix obtained by putting together the @xmath65 encoding vectors .",
    "we want to find a @xmath0-sparse innovative encoding vector @xmath68 $ ] .",
    "since @xmath66 is full - rank , we can find @xmath65 columns of @xmath66 which are linearly independent .",
    "let @xmath69 be a set of indices of @xmath65 linear independent columns in @xmath66 .",
    "for each @xmath34 , we arbitrarily pick a column whose index is not in @xmath69 .",
    "we call this the _ extra column _ and let @xmath70 be the union of @xmath69 and the index of this extra column",
    ". the cardinality of @xmath70 is @xmath71 . for each @xmath64",
    ", we construct an @xmath72 matrix @xmath73 , by first appending the vector @xmath74 $ ] to the bottom of matrix @xmath66 , and then deleting all columns of the resulting matrix except the columns with indices in @xmath70 .    for each @xmath34 , we compute the @xmath71 cofactors of the entries in the last row of @xmath73 .",
    "let @xmath75 be the variable with largest index in the last row of @xmath73 whose cofactor is non - zero .",
    "the column indices @xmath76 so obtained may not be distinct .",
    "let @xmath77 be the set of distinct indices such that @xmath78 and @xmath79 . also , for @xmath80 , we let @xmath81 be the set of users such that @xmath82 if and only if @xmath83",
    ". we remark that @xmath84 contains at most @xmath0 distinct indices , i.e. , @xmath85 .",
    "we obtain a @xmath0-sparse innovative encoding vector as follows .",
    "first , we set all variables @xmath86 , for @xmath87 , to zero . then we assign values to @xmath88 sequentially , so that the determinant of @xmath73 is nonzero for all @xmath34 . for @xmath89 , the last row of @xmath73 has only one variable , namely @xmath90 , whose value is not yet assigned ( the rest are all set to zero ) .",
    "the cofactor of @xmath90 in @xmath73 is non - zero .",
    "if we expand the determinant of @xmath73 in the last row , we see that the determinant can be written as @xmath91 , where @xmath92 is the cofactor of @xmath75 in @xmath73 .",
    "we have a non - zero value if @xmath90 is non - zero , for all @xmath89 .",
    "we can assign any non - zero element of @xmath8 to @xmath90 , and make @xmath73 non - zero for all @xmath93 .",
    "inductively , suppose that the values of @xmath94 have been assigned .",
    "consider the determinants of @xmath73 for @xmath95 .",
    "the only variable in the last row of @xmath73 which has not been assigned a value yet is @xmath96 .",
    "if we expand the determinant on the last row , we obtain a linear polynomial in the form of @xmath97 , where @xmath98 is a constant and @xmath92 is the cofactor of @xmath96 in @xmath73 .",
    "there are at most @xmath0 such degree - one polynomials , and thus we can assign a value to @xmath96 such that all determinants of @xmath73 are non - zero . here",
    "we have used the assumption that @xmath15 . note that the assignment of @xmath96 does not affect the determinants of previous users with indices in @xmath99 , because @xmath100 either does not appear in @xmath101 or the corresponding cofactor in @xmath102 is equal to zero for @xmath103 .",
    "after the end of the process , we have chosen the values for @xmath104 such that @xmath105 is non - zero for all @xmath64 .",
    "this encoding vector is innovative to all users and contains at most @xmath0 non - zero components .",
    "we call the the method described in the proof of theorem  [ thm : cofactor ] the _ cofactor method_. using the cofactor method , we can produce innovative and @xmath0-sparse encoding vectors .",
    "for the decoding , the number of non - zero coefficients in the linear system is no more than @xmath106 .",
    "_ example 1 .",
    "_ when @xmath107 , @xmath108 and @xmath109 , consider    @xmath110 _ 2 =    1 & 0 & 1 + 0 & 1 & 1    ,  _ 3 =    1 & 0 & 0 + 0 & 2 & 0    .",
    "suppose that @xmath111 , @xmath112 .",
    "we have @xmath113 in @xmath114 the cofactors of @xmath115 and @xmath116 are @xmath117 and 0 respectively .",
    "hence , @xmath118 . in @xmath119 ,",
    "all cofactors of @xmath115 , @xmath116 and @xmath120 are non - zero .",
    "we thus have @xmath121 . in @xmath122 ,",
    "the cofactor of @xmath120 is nonzero , and so @xmath123 .",
    "the index set @xmath84 is equal to @xmath124 .",
    "the two index sets of users are @xmath125 and @xmath126 . by the cofactor method ,",
    "we first assign 0 to @xmath116 .",
    "then we go through the variable indices in @xmath84 in ascending order . for @xmath115",
    ", we can assign any nonzero value to @xmath115 .",
    "for example , we pick @xmath127 . once @xmath115 and @xmath116 are fixed , we compute the determinants of @xmath119 and @xmath122 , which are @xmath128 and @xmath129 respectively .",
    "finally , we want to assign a value to @xmath120 such that @xmath130 and @xmath131 .",
    "the only choice in this example is @xmath132 .",
    "the resulting encoding vector is @xmath133 $ ] .    in the cofactor method ,",
    "the main complexity is related to the computation of @xmath134 cofactors in an @xmath135 matrix .",
    "a straightforward calculation of an @xmath136 determinant requires @xmath137 arithmetic operations .",
    "the calculation of all cofactors in a matrix would require @xmath138 operations per each user in each step .",
    "we can use a more efficient algorithm , called the _",
    "bareiss algorithm_. the number of arithmetic operations over @xmath8 required in the computation of cofactors per user can be reduced to  @xmath62 .",
    "summing over all @xmath0 users , the complexity for computing all cofactors is @xmath139 .",
    "the complexity of the rest of the cofactor method is of @xmath140 .",
    "the overall complexity of the cofactor method is @xmath141 . if jaggi - sanders algorithm in @xcite is applied to solve the encoding problem , the complexity is @xmath142 .",
    "it means that the cofactor method is no worse than the algorithm in @xcite in terms of the encoding complexity . but certainly the encoding vector produced by jaggi - sanders algorithm is not sparse",
    ". details on the bareiss algorithm is given in the appendix .",
    "the cofactor method assumes that @xmath143 .",
    "if @xmath144 , the cofactor method may fail to find an assignment of the @xmath86 s such that all determinants are non - zero . in that case",
    ", we set those @xmath86 s to zero and the encoding vectors so generated may not be innovative .",
    "but anyway , the returned encoding vector is @xmath0-sparse .",
    "hence we can still apply the cofactor method for the case @xmath10 to obtain @xmath0-sparse encoding vectors , which are innovative to only a fraction of the @xmath0 users .    in @xcite , the problem of generating the sparest innovative",
    "is considered , and is shown to be np - hard when @xmath143 .",
    "we evaluate the cofactor method via simulations . in the simulations ,",
    "we divide the transmission into two phases .",
    "the source node first transmits all packets one by one uncoded .",
    "the @xmath0 users acknowledge the packets they have successfully received .",
    "the source node sets up @xmath0 matrices @xmath66 , for @xmath145 .",
    "the rows of @xmath18 are the encoding vectors received by user  @xmath34 .",
    "since the packets are uncoded in the first phase , each row of @xmath66 contains exactly one nonzero component .",
    "we initialize @xmath146 to be the set of non - zero columns in @xmath66 .",
    "in the second phase , we transmit the packets using the encoding vectors generated by the cofactor method .    each simulation points involved 1000 random realizations and we assume that @xmath147 and @xmath148 .",
    "the worst - case delay is defined as the average of total number of transmissions for @xmath1 to ensure that all users receive an intact file over 1000 random realizations .",
    "the average delay means the average number of transmissions for @xmath1 so that an intact file can be received by a user . for the decoding complexity",
    ", we count the number of additions and multiplications in decoding . in our simulations , an addition operation involving two non - zero operands is counted .",
    "a multiplication operation is counted when none of the two operands is 1 or 0 .",
    "= 2.7 in    = 2.7 in    = 2.7 in    = 2.7 in    figure  [ f1 ] shows the worst - case delay performance of our system with the cofactor method , the random linear network code ( rlnc ) scheme in which the components are selected according to a uniform distribution , the sorted opportunistic method ( som ) in @xcite and the maximum weight vertex search ( mwvs ) algorithm in @xcite for encoding vector generations , where both som and mwvs generate instantly decodable packets .",
    "it is found that , for @xmath10 , the cofactor method always performs better than rlnc , som and mwvs in terms of the worst - case delay .",
    "in addition , we also find that the worst - case delay performance of the cofactor method with a small finite field size ( @xmath10 ) is comparable to that of rlnc with a large finite field size ( @xmath149 ) .",
    "next , we consider the average delay performance . according to information theory ,",
    "the best we can do is to have @xmath150 transmissions on average . in figure",
    "[ f2 ] , we observe that both the cofactor method and rlnc with large enough finite field size ( @xmath149 ) can achieve the limit . from the figure",
    ", we also see that although all concerned methods may not be optimal when @xmath10 , the cofactor method always results in a smaller average delay .",
    "the decoding algorithms in most of the previous work are basically gauss - jordan elimination except the instantly decodable schemes in @xcite .",
    "we implement the gauss - jordan elimination for sparse matrix in our simulation .",
    "note that the @xmath0-sparse property of the cofactor method implies an upper bound on the number of non - zero entries in an encoding vector . in practice ,",
    "the average number of non - zero entries is significantly less than both @xmath0 and @xmath9 even for @xmath151 . as a result",
    ", significant decoding complexity reduction is expected for a system with the cofactor method .",
    "figures  [ f3 ] and  [ f4 ] show the average total number of operations for all users in the system when @xmath10 and @xmath149 , respectively .",
    "the cofactor method indeed yields significant reduction in both the average total number of addition and multiplication operations when compared with rlnc . from figure  [ f3 ]",
    ", we observe that , with both som and mwvs which are instantly decodable , a receiver enjoys a low decoding complexity at the expense of larger delay . as a result , the cofactor method which always generates sparse encoding vectors is a promising choice in terms of delay performance and decoding complexity",
    "we devise a cofactor method to generate @xmath0-sparse encoding vector . when @xmath143 , it is guaranteed that the resulting encoding vector is innovative , and hence the broadcast system is delay - optimal .",
    "the sparsity can be exploited in devising faster decoding algorithm .",
    "simulation result shows that the cofactor method outperforms rlnc , som and mwvs in terms of both the worst - case delay and average delay . on the other hand , when @xmath10 , the problem of determining the existence of an innovative encoding vector is np - complete .",
    "[ app ] the bareiss algorithm is a fraction - free algorithm for computing determinant  @xcite .",
    "to illustrate the idea , we apply bareiss algorithm to an @xmath152 matrix @xmath153 whose elements are integers and the last row consists of indeterminates @xmath115 , @xmath154 . at the end of the algorithm ,",
    "the entry in the lower - right corner of @xmath153 is a linear polynomial in @xmath115 , @xmath155 , and the coefficient of @xmath86 is the corresponding cofactor of @xmath86 in the original @xmath153 .",
    "we remark that this is an in - place algorithm , and the complexity is in the order of @xmath156 .",
    "_ example 2 .",
    "_ consider @xmath164 , as an example .",
    "after the first pass of the for - loop ( @xmath165 ) , the partial result is @xmath166 after the end of the algorithm , we have @xmath167 the coefficients of @xmath115 , @xmath116 and @xmath120 of the polynomial in the @xmath168-entry are the cofactors @xmath169 , @xmath170 , and @xmath171 respectively .",
    "furthermore , the algorithm can be run incrementally .",
    "suppose that only the first @xmath172 rows in a matrix @xmath173 is available , @xmath174 the entries marked by `` @xmath175 '' are not known yet and will be revealed later .",
    "we can apply the bareiss algorithm to the submatrix obtained by removing the `` @xmath175 '' entries and the right @xmath176 columns .",
    "when the value of the @xmath177-st row is known , we can run the bareiss algorithm again on the submatrix obtained by removing rows @xmath178 to @xmath179 and the @xmath180 columns on the right .",
    "we can see that the @xmath181 entries in the first @xmath172 rows and the first @xmath172 columns are the same as before and we do not need to re - calculate them . only the calculation of the @xmath182 new entries are required . for each user ,",
    "the source node essentially runs the bareiss algorithm on an @xmath183 matrix , and the complexity per user is @xmath62 .",
    "summing over all users , the complexity involving the computation of the cofactors is @xmath184 .",
    "l.  keller , e.  drinea , and c.  fragouli , `` online broadcasting with network coding , '' in _ proc . of the fouth workshop on network coding , theory , and applications ( netcod 08 )",
    "_ , hong kong , jan .",
    "2008 , pp . 6873 .",
    "j.  heide , m.  v. pedersen , f.  h.  p. fitzek , and t.  larsen , `` network coding for mobile devices ",
    "systematic binary random rateless codes , '' in _ ieee int .",
    "workshops ( icc workshop 2009 ) _ , dresden , jun .",
    "2009 , pp .",
    "s.  y. el rouayheb , m.  a.  r. chaudhry , and a.  sprintson , `` on the minimum number of transmissions in single - hop wireless coding networks , '' in _ ieee information theory workshop ( itw ) _ , lake tahoe , sep .",
    "2007 , pp . 120125 .",
    "s.  jaggi , p.  sanders , p.  chou , m.  effros , s.  egner , k.  jain , and l.  tolhuizen , `` polynomial time algorithms for multicast network code construction , '' _ ieee trans .",
    "inf . theory _",
    "51 , no .  6 , pp . 19731982 , jun . 2005 .    c.  w. sung , k.  w. shum , and h.  y. kwan , `` on the sparsity of a linear network code for broadcast systems with feedback , '' to appear in _ proc .",
    "symp . on network coding ( netcod 11 )",
    "_ , beijing , jul ."
  ],
  "abstract_text": [
    "<S> in the application of linear network coding to wireless broadcasting with feedback , we prove that the problem of determining the existence of an innovative encoding vector is np - complete when the finite field size is two . </S>",
    "<S> when the finite field size is larger than or equal to the number of users , it is shown that we can always find an encoding vector which is both innovative and sparse . </S>",
    "<S> the sparsity can be utilized in speeding up the decoding process . </S>",
    "<S> an efficient algorithm to generate innovative and sparse encoding vectors is developed . </S>",
    "<S> simulations show that the delay performance of our scheme with binary finite field outperforms a number of existing schemes in terms of average and worst - case delay . </S>"
  ]
}