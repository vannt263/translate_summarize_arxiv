{
  "article_text": [
    "having to administer a large number of workstations has long been a headache to system administrators working for big businesses , universities and research laboratories . in the case of unix - style operating systems , system maintenance tasks",
    "can very rarely be delegated to the end users , which means that the whole burden of taking care of the company s computers falls on the system administrators .",
    "unless some kind of special system maintenance scheme is devised , the required administration effort scales linearly with the number of machines and a synchronous major software upgrade is essentially impossible ( unless , of course , the company employs an army of sysadmins and the upgrade takes place during the christmas shutdown ) .",
    "the _ babar _ experiment , which began operation at the stanford linear accelerator center in 1999 , requires an immense amount of computing power , most of which is currently provided by solaris sparc systems .",
    "the 300 + -node analysis and prompt reconstruction farm  and especially the 79-node online data flow farm  perform tasks that are critical for experiment operation and demand minimal downtime in case of a hardware malfunction , operating system crash , or a software upgrade .    without using any special scripts or system administration tools , setting up a sun solaris",
    "stand - alone `` from scratch '' and configuring it to make the best use of the slac computing environment ( afs , nis , amd , etc . ) and to conform to certain security standards ( ` ssh ` , ` sudo ` , ` sendmail ` , disabling ` telnet ` and ` rlogin ` , applying patches ) is a task that takes at least 10 hours , of which 3 to 5 hours require active administrator involvement . `",
    "tailor `  a collection of system administration tools developed by the slac computing services over the past 10 years for many flavors and versions of unix  greatly simplifies integration of a unix workstation into the slac environment and saves a lot of time : the process takes 3 to 5 hours with periodical administrator involvement totalling about 1 hour per machine .    but even with the help of ` tailor ` , managing such a large number of machines is a formidable task , so in summer 1998 we started looking for ways to make deployment or replacement of solaris machines faster and system management more straightforward .",
    "the three techniques that we have come up with are 1 ) `` non - invasive '' hard drive cloning with the help of the _ diskless client _ technology , which allows us to make a fully functional copy of a `` tailor`ed ' solaris stand - alone system in about 20 minutes ( including changing identity information ) ; 2 ) a combination of ` tailor ` and sun s _ _ jumpstart _ _ , which requires a network installation server with custom install / finish scripts that allow ` tailor`ing to take place without administrator intervention ( this technique of making a solaris stand - alone takes about 1 hour plus 30 to 60 minutes to initialize the afs cache ) ; and 3 ) sun microsystems _ autoclient _ , which will be discussed in the rest of this article .",
    "sun microsystems _ autoclient _ and _ adminsuite _ products were designed to centralize and simplify administration of a large number of solaris workstations . to understand what an autoclient is , let s compare it with a stand - alone system and a diskless client :    ._autoclient _ vs. _ diskless client _ and",
    "stand - alone systems [ cols= \" < , < , < , < , < , < \" , ]     [ the table ]    _ autoclient _ allows us to keep all clients file systems , except ` swap ` , on the autoclient server and _ * locally cache * _ root ( ` / ` ) and the shared read - only ` /usr ` and ` /opt ` using the _ cachefs _ technology , which is the most important component of _",
    "autoclient_.    _ cachefs _ caches files that have been accessed by the autoclient , so that subsequent requests to the same files get referenced to the cache rather than being sent to the server .",
    "a cache consistency check is performed every 24 hours by a cron job running on the autoclient , on reboot , or at request .",
    "all writes immediately update the back file system on the server , unless the autoclient is configured as ` disconnectable ' and the server is temporarily unavailable .",
    "this consistency check policy relies on the assumption that the cached file systems do not get changed from the server side except in rare cases by the administrator who explicitly requests a consistency check after he is done .",
    "specific files or directories can be _ * packed * _ into the _ cachefs _ cache , which guarantees that they will always be in the cache and will not be purged if the cache becomes full .",
    "this feature can be particularly useful with ` disconnectable ' clients .    in a nutshell ,",
    "an _ autoclient _",
    "system has all the advantages of a diskless client ( with the exception of not needing a hard drive ) while not putting a heavy load on the network and possessing performance closely matching that of a stand - alone system .",
    "since autoclients do not require any swap space on the server and share ` /usr ` and ` /opt ` filesystems , each autoclient requires only about 40 mb of space on the server for its root file system . in order to backup each _",
    "autoclient _ system , we only need to backup the server . we also can manipulate autoclient root file systems ( read log files , apply patches , etc . ) directly from the server .",
    "autoclients can be configured to be _ * disconnectable * _ , which means that they will continue to function using their cached filesystems while the server is temporarily unavailable .",
    "autoclients can be halted and rebooted remotely ; they reboot directly from the cache , so the network traffic during a system - wide reboot is limited to a cache consistency check . since no persistent information is stored on the autoclient itself , it can be considered a _ field - replaceable unit * ( fru)*_. replacing a failed unit or deploying a new autoclient takes just a few minutes . most of the management tasks normally associated with stand - alone solaris systems are thus almost completely eliminated .",
    "the quintessence of the centralized administration model , of which _ autoclient _ is a key component , is a significant reduction of the cost of management  that is , if everything works as advertised .",
    "we started experimenting with _",
    "autoclient _ in june 1998 , about a year before _ babar",
    "_ took its first @xmath0 collision data . our first autoclient server and",
    "two dozen or so autoclients were ultra-5 s with a 270 mhz ultrasparc - iii cpu , 128 mb ram and a 4.3 gb 5,400 rpm eide hdd running solaris 2.6 hw 3/98 ; we used this prototype autoclient farm as console and online data flow machines during the winter 1998/99 _ babar _ cosmic ray run . in order to speed up creation of additional autoclients",
    ", we developed a set of scripts that ` clone ' the root file system of a fully configured autoclient , modify identity - related files in ` /export",
    "/ root / clientname ` , and make necessary adjustments to the server configuration files  all in about one minute .",
    "although the process of configuring the server and the first fully functional client was quite bumpy ( mostly having to do with getting proper patches installed , see @xcite ) , we were satisfied with the farm s performance and decided to use the _ autoclient _ technology on all _ babar _ computer farms at slac . at this time",
    "( january 2000 ) , there are 309 autoclients on 6 autoclient servers in the analysis and prompt reconstruction farm , which is located in the scs building , and 100 autoclients and 1 autoclient server in the online data flow and console farms , which are located in the ir-2 building that houses the _ babar _ detector .",
    "so , we have been operating over 400 autoclients under real life conditions ( running online , prompt reconstruction and analysis jobs around the clock at close to 100% capacity ) for about 8 months .",
    "overall , the farms performed their goals very well . however , the required management effort turned out to be much bigger than we expected , primarily because of a bug in _ cachefs _ , which has been identified by sun microsystems .",
    "a fix for this bug is reportedly available for solaris 7 , but sun still has not been able to come up with a fix for solaris 2.6 that _",
    "babar _ is currently using .",
    "the bug leads to cache corruption and , occasionally , to disappearance of files on the client s root file system during power outages or if connection to the server is lost due to a server reboot or crash or a network outage , probably only if the autoclient was in the process of writing into a file .",
    "such accidents have so far occurred about one a week , and each time about 15 - 20% of autoclients had to be manually rebooted with the ` boot -f ` command that forces cache reconstruction ; sometimes an autoclient had to be recloned .",
    "this means that after an outage the status of each autoclient has to be checked manually or _ all _ autoclients have to be rebooted with ` boot -f `  either way , this takes a lot of time .",
    "it also turns out that while in most cases a solaris stand - alone system does not have to be rebooted after a patch is applied to it , autoclients often do , the reason being differences in the ufs and nfs file locking mechanisms . an _ autoclient _ system has to be idle before patching takes place  otherwise running applications can crash ; a global farm outage has to be scheduled to patch ` /usr ` .    we have undertaken several measures to minimize the impact of the outages : the autoclient servers and network equipment at scs have been connected to ups power ; the network topology has been modified to remove path redundancies that under certain circumstances can lead to brief periods of network unavailability .",
    "we have also realized that putting the responsibility of being the autoclient server on the main ir-2 server was a big mistake because it often crashed due a kernel memory leak or had to be rebooted .      at this point , we are quite disappointed by our experience with _ autoclient _ , and unless sun fixes the _ cachefs _ bug in the nearest future , we will replace autoclients in the scs farm with solaris stand - alone systems which will be net - booted from a net - install server using _",
    "jumpstart _ and ` tailor ` ; the recovery strategy in this case would be to reinstall .",
    "we are far from certain whether we will completely drop the _ autoclient _ technology and think that it has a great potential , so we want to try the more classical approach and see how the management effort compares to using _",
    "autoclient_. the main goal of our presentation at chep 2000 was to make the high energy physics community aware of _ autoclient _ s existence , its pros and cons , and our experience with it  and let you decide whether you want to try it out or not .",
    "we hope that this goal has been achieved .",
    "telnov , `` management of computer farms at babar '' , babar note # 446 , march 29 , 1999 .",
    "this note can be downloaded from @xcite .",
    "more information on the use of _ autoclient _ in the _ babar _ experiment along with a collection of solaris - related documentation in pdf format can be found at http://www.slac.stanford.edu/bfroot/www/computing/environment/admin/autoclient/autoclient.html ."
  ],
  "abstract_text": [
    "<S> modern hep experiments require immense amounts of computing power . in the babar experiment at slac , </S>",
    "<S> most of it is provided by solaris sparc systems . _ </S>",
    "<S> autoclient _ , a product of sun microsystems , was designed to make setting up and managing large numbers of solaris systems more straightforward . </S>",
    "<S> _ autoclient _ machines keep all filesystems , except _ swap _ , </S>",
    "<S> on a server and employ _ cachefs _ to cache them onto a local disk , which makes them field replaceable units with performance of stand - alone systems . </S>",
    "<S> we began exploring the technology in summer 1998 , and currently operate online , reconstruction , analysis and console autoclient farms with the total number of nodes exceeding 400 . </S>",
    "<S> although the technology has been available since 1995 , it has not been widely used , and the available documentation does not adequately cover many important details of _ autoclient _ installation and management . </S>",
    "<S> this paper discusses various aspects of our experience with _ autoclient _ , including tips and tricks , performance and maintainability , scalability and server requirements , existing problems and possible future enhancements .       </S>",
    "<S> _ this paper has been submitted to proceedings of the conference on computing in high energy and nuclear physics ( chep 2000 ) , february 7 - 11 , 2000 , padova , italy . _ </S>"
  ]
}