{
  "article_text": [
    "as demand for big data analysis grows , high  dimensional data and algorithms have become increasingly important in scientific computing .",
    "the total number of entries in a _ tensor _ ( an array with @xmath0 indices ) grows exponentially with dimension @xmath1 even for a moderate @xmath2 it is impossible to process , store or compute all elements of a tensor by standard methods . this issue is known in numerical analysis and related areas as the _ curse of dimensionality_. different techniques are used to relax or to overcome this problem , e.g. low ",
    "parametrical representation on sparse grids  @xcite , ( markov chain ) monte carlo sampling in statistics  @xcite , model / dimensionality reduction , etc .",
    "significant progress has been made in the development and understanding of the _ tensor product _ methods ( see reviews  @xcite ) .",
    "the tensor product methods implement the _ separation of variables _ at the discrete level , which in the two  dimensional case is known as the _ low rank decomposition _ of a matrix .",
    "several approaches have been developed to generalize rank ",
    "structured low ",
    "parametrical models to tensors ( see  @xcite for details ) , and a particularly simple and efficient  _ tensor train _ ( tt ) format has been proposed recently  @xcite .",
    "it is equivalent to the _ matrix product states _ ( mps ) introduced in the quantum physics community to represent the quantum states of the many ",
    "body systems  @xcite .",
    "the optimization algorithms for the mps include _ alternating least squares _ ( als ) algorithm , which works with the fixed tensor structure , and the _ density matrix renormalization group _",
    "( dmrg ) algorithm  @xcite , which adaptively changes the _ ranks _ of the tensor format , and manifests much faster convergence in numerical experiments .",
    "when the tt format was re - discovered in the numerical linear algebra community , both the als and dmrg schemes were adapted for other high  dimensional problems and novel algorithms were proposed . as a result",
    "we can use the tt / mps format to approximate high  dimensional data and perform algebraic operations  @xcite ( cf .",
    "@xcite ) , solve linear systems  @xcite , compute the multidimensional fourier transform  @xcite and discrete convolution  @xcite . with these algorithms in hand ,",
    "high  dimensional scientific computations become possible as soon as all data are somehow translated into the tt format .",
    "it is crucial , therefore , to develop algorithms which construct the approximation of a given high  dimensional array in the tensor format .",
    "for some function  related tensors , the tt representation is written explicitly ( see e.g.  @xcite ) .",
    "in general , although every entry of a tensor can be computed _ on demand _",
    "( by a formula or as a solution of a feasible problem , e.g. pde in three dimensions ) , all elements can not be computed in a reasonable time .",
    "the question arises naturally whether a tensor can be _ reconstructed _ or _ interpolated _ in the tt format from a few elements , also known as _",
    "samples_.    for matrices , i.e. @xmath3tensors , this question is well studied .",
    "we know that a rank@xmath4 matrix is recovered from a _ cross _ of @xmath4 rows and columns if the submatrix on their intersection is nonsingular . when data are not exactly represented by the low ",
    "rank model , the accuracy of the _ cross interpolation _ depends crucially on the chosen cross .",
    "a notable choice is the  _ maximum volume _ cross , which has the @xmath5 submatrix with the maximum determinant in modulus on the intersection .",
    "for this cross , the interpolation accuracy differs from the accuracy of the best possible approximation by the factor @xmath6 i.e. is _ quasioptimal _  @xcite .    for tensors in the tt format an analog of the cross interpolation formula",
    "is given in  @xcite .",
    "it reconstructs a tensor from a few samples under mild non - singularity conditions , if the tt representation is exact . for the approximate case",
    ", the als type algorithm is suggested in  @xcite , which searches for the better crosses in order to improve the approximation accuracy .",
    "the rank  adaptive dmrg  like version of this algorithm is proposed in  @xcite .",
    "these algorithms are  _ heuristic _ , as well as interpolation algorithms developed for other tensor formats , e.g. the tucker  @xcite and the _ hierarchical tucker _ ( ht ) format  @xcite .",
    "the accuracy of the cross interpolation of tensors has not been well studied yet . for the @xmath7dimensional tucker model the quasioptimality with the factor @xmath8",
    "is shown in  @xcite . in @xmath0 dimensions",
    "we can expect an excessively large coefficient @xmath9 cf .",
    "@xmath10 for the ht format  @xcite .",
    "the main result of this paper is more optimistic .",
    "the quasioptimality of the maximum volume cross interpolation is generalized to the tt format with the coefficient @xmath11 that _ does not necessarily grow exponentially _ with @xmath1    the paper is organized as follows .",
    "[ sec : def ] presents notation and definitions . in sec .",
    "[ sec : mvol ] the quasioptimality of the maximum  volume cross interpolation is proven . in sec .",
    "[ sec : emb ] the interpolation on _ nested _ sets is considered , which reduces the search space , but results in the larger quasioptimality constant . in sec .",
    "[ sec : emb2 ] the interpolation property for the nested sets is shown . in sec .",
    "[ sec : alg ] practical cross interpolation algorithms for matrices are recalled and similar algorithms for tensor trains are proposed . in sec .  [",
    "sec : num ] the coefficient of the quasioptimality is measured for randomly generated tensors , and speed and accuracy of the proposed algorithm is demonstrated with numerical experiments .",
    "the _ tensor train _ ( tt ) decomposition of a tensor @xmath12 $ ] is written as follows @xmath13 in this equation @xmath14 @xmath15 are _ mode _ or physical indices , and @xmath16 are auxiliary _ rank _ indices .",
    "values @xmath17 are referred to as  _ mode sizes _ of a tensor , and @xmath18 are  _ tensor train ranks _ or tt  ranks .",
    "summation over @xmath19 means summation over all pairs of auxiliary indices @xmath20 where each index runs through all possible values .",
    "we use elementwise notation , i.e. assume that all equations hold for all possible values of _ free _ indices .",
    "therefore , eq .   represents every entry of a tensor by the product of matrices , where each @xmath21 $ ] has size @xmath22 and depends on the  _ parameter _ @xmath23 the three  dimensional array @xmath24 $ ] is referred to as",
    "core_. to unify the notation , we introduce the virtual _ border ranks _",
    "@xmath25 and consider @xmath26=[x^{(1)}(s_0,i_1,s_1)]$ ] and @xmath27=[x^{(d)}(s_{d-1},i_d , s_d)]$ ] as @xmath7tensors .",
    "the elementwise notation allows us to reshape tensors into vectors or matrices simply by moving indices .",
    "we have done this to present the tt ",
    "core @xmath28 $ ] as the parameter ",
    "dependent matrix @xmath29.$ ] more complicated transformations can be expressed by _ index grouping _ , which combines indices @xmath30 in the single multi ",
    "index @xmath31 or the _ little  endian _",
    "convention @xmath32 the big ",
    "endian notation is similar to numbers written in the positional system , while the little  endian notation is used in numerals in the arabic scripts and is consistent with the fortran style of indexing .",
    "the exact formula which maps indices to the multi ",
    "index is not essential in this paper . ] for example , the @xmath33th _ unfolding _ of a tensor is the @xmath34 matrix with elements @xmath35 here and further we use the following shortcuts to simplify the notation @xmath36 for @xmath37 in the tt  format   it holds @xmath38 in  @xcite the reverse is proven : for any tensor @xmath37 there exists the representation   with tt  ranks @xmath39 this gives the term _ tt  rank _ the definite algebraic meaning .    for a @xmath40 matrix @xmath41 $ ]",
    "the _ cross _ ( or _ skeleton _ ) interpolation is written as follows @xmath42^{-1 } a(\\i_s , j ) .    \\ ] ] here sets @xmath43 and @xmath44 define the positions of the interpolation rows and columns , respectively .",
    "the summation over @xmath45 ties the pairs of subsets together , similarly to the pairs of indices in  . in the matrix form",
    "the right hand side of   is the product of @xmath46 matrix of columns , the inverse of @xmath5 submatrix at the intersection and @xmath47 matrix of rows .",
    "the essential property of the interpolation is that   is  _ exact _ on its cross @xmath48^{-1 } a(\\i_s , j ) , \\qquad       \\mbox{if}\\quad   i\\in\\i \\mbox { or } j\\in\\j.\\ ] ]    when @xmath37 is not exactly a rank-@xmath4 matrix , the choice of interpolation sets @xmath49 may affect the interpolation accuracy significantly .",
    "a good choice of @xmath50 $ ] is the  _ maximum  volume _ @xmath5 submatrix , such that @xmath51 is maximal over all possible choices of @xmath52 and @xmath53 assuming that the ranks ( sizes of submatrices ) are defined _ a priori _ , we denote this choice by @xmath54 = \\arg\\max_{\\i',\\j'}\\vol [ a(\\i',\\j ' ) ] , \\qquad\\mbox{or}\\qquad   [ \\i,\\j ] = \\maxvol a.\\ ] ] for @xmath49 chosen by the maximum  volume principle , the following _ quasioptimality _ statements are proven in  @xcite and  @xcite , respectively . @xmath55",
    "another important property of the maximum ",
    "volume submatrix is that it is _ dominant _ ( see  @xcite for more details ) in the rows and columns which it occupies , i.e. @xmath56^{-1 } a(\\i_t , j ) \\right| \\leq 1 ,     \\qquad    \\left| \\sum_{s } a(i,\\j_s ) \\left [ a(\\i_t,\\j_s ) \\right]^{-1 } \\right| \\leq 1.\\ ] ]    in  @xcite it is shown that if a tensor @xmath37 is exactly given by   with tt ",
    "ranks @xmath57 it is recovered from @xmath58 tensor entries and @xmath59 in complexity estimates ] by the following formula .",
    "@xmath60^{-1 }   a(\\i_{s_1}^{\\leq 1},i_2,\\i^{>2}_{t_2 } )   \\ldots    a(\\i^{\\leq d-1}_{s_{d-1}},i_d )   \\\\ & = \\sum_{\\s,\\t } \\prod_{k=1}^d a(\\i^{\\leq k-1}_{s_{k-1}},i_k,\\i^{>k}_{t_k } ) \\left[a(\\i^{\\leq k}_{s_k},\\i^{>k}_{t_k})\\right]^{-1 } ,   \\end{split}\\ ] ] where @xmath61 and @xmath62 denote the positions of @xmath18 rows and columns in the @xmath33th unfolding @xmath63 to unify the notation , we introduce the empty border sets @xmath64 and @xmath65 we denote submatrices on the intersection of interpolation crosses as follows @xmath66_{t_k , s_k=1}^{r_k } = \\left[a(\\i^{\\leq k},\\i^{>k})\\right ] = a_k , \\qquad a_k^{-1 } = b^{[k]}.\\ ] ] throughout the paper we assume that tt ",
    "ranks of   and   are the same , i.e. , sets @xmath67 and @xmath68 have @xmath18 elements each and @xmath69 $ ] is @xmath70 matrix , where @xmath71 are tt",
    " ranks of  .",
    "when a  _ choice _ of @xmath72 is considered , it means that we choose @xmath18 ` left ' and ` right ' multiindices @xmath73 @xmath74    in  , @xmath75 denotes the  _ spectral _ norm of a matrix , and @xmath76 denotes the  _ chebyshev _ norm , also known as _ uniform _ , _ supremum _ , @xmath77norm , or the maximum entry in modulus . for tensors chebyshev and frobenius norms",
    "are defined as follows @xmath78",
    "we consider a tensor @xmath37 which is approximated by the tt format as follows @xmath79 where @xmath80 and @xmath81 are known or estimated from computations or theoretical properties of @xmath82 we apply   to @xmath33th unfolding and write the cross interpolation @xmath83^{-1 }        a^{\\{k\\}}(\\i^{\\leq k}_{s_k},i_{>k } ) .",
    "\\end{split}\\ ] ] for @xmath84 = \\maxvol a^{\\{k\\}}$ ] the accuracy is estimated by   as follows @xmath85    we can safely omit the superscript for unfoldings when we use the pointwise notation , since the grouping of indices clearly defines the shape of the resulted matrix .",
    "the equation for the unfolding is recast for the tensor as follows @xmath86}_{t_k , s_k }                           a(\\i^{\\leq k}_{s_k},i_{k+1},\\ldots , i_d )      + e(i_1,\\ldots , i_d ) , \\\\ & \\quad     | e |   \\leq ( r_k+1)^{\\phantom{2 } }     e_f ,",
    "\\qquad     | e |   \\leq ( r_k+1)^2                 e_c , \\qquad     b^{[k ] } = a_k^{-1}.   \\end{split}\\ ] ] the interpolation step splits a @xmath0tensor into a ` product ' of two tensors , which have @xmath33 and @xmath87 free indices , respectively . the same splitting is done in  @xcite , where a _ tree  tucker _ format ( later recast as the tensor train format ) has been proposed to break the curse of dimensionality . in  @xcite the quasioptimality of the approximations computed by the proposed tt ",
    "svd algorithm is shown .",
    "similarly , we estimate the accuracy of the interpolation  based formula  .",
    "[ lem1 ] if a tensor @xmath37 satisfies  , then for any @xmath88 it holds @xmath89}_{t_k , s_k }            a(\\i^{\\leq k}_{s_k},i_{k+1},\\i^ { > k+1 } )         \\\\ & + e(\\i^{\\leq k-1 } , i_k , i_{k+1},\\i^ { > k+1 } ) ,      \\\\ & \\quad     | e | \\leq ( r_k+1)^{\\phantom{2 } }     e_f ,   \\qquad     | e | \\leq ( r_k+1)^2                 e_c .",
    "\\end{split}\\ ] ]    in   we reduce free indices @xmath90 to the subset @xmath91 and similarly @xmath92 to @xmath93    [ lem2 ] if a tensor @xmath37 satisfies  , and for some @xmath94 for subtensors @xmath95 , \\qquad   a_\\rgt=\\left[a(\\i^{\\leq k } , i_{k+1:q},\\i^ { > q})\\right],\\ ] ] it holds @xmath96 and @xmath97 with @xmath98 and @xmath99 then @xmath100}_{t_k , s_k }              t_\\rgt(\\i^{\\leq k}_{s_k } , i_{k+1:q},\\i^ { > q } )        \\\\ & + \\e(\\i^{\\leq p-1 } , i_{p : q},\\i^ { > q } ) ,        \\\\",
    "\\frac{|\\e|}{|a| }   \\leq ( 2 + \\eps\\kappa_k ) \\eps r_k   & + \\frac{|e|}{|a| } ,    \\qquad \\kappa_k = r_k |a| |a_k^{-1}| , \\quad a_k= \\left [ a(\\i^{\\leq k},\\i^{>k } ) \\right ] ,      \\end{split}\\ ] ] where @xmath101 is estimated by  .    like in the previous lemma , by taking the subtensor in   we obtain @xmath102}_{t_k , s_k }               a_\\rgt(\\i^{\\leq k}_{s_k } , i_{k+1:q},\\i^ { > q } )        + e(\\i^{\\leq p-1 } , i_{p : q},\\i^ { > q } ) ,     \\end{split}\\ ] ] where @xmath101 is estimated by  .",
    "we have @xmath103 } a_\\rgt & = ( t_\\lft + e_\\lft ) b^{[k ] } ( t_\\rgt + e_\\rgt )    \\\\ & = t_\\lft b^{[k ] }   t_\\rgt + a_\\lft b^{[k ] }   e_\\rgt + e_\\lft b^{[k ] }   a_\\rgt - e_\\lft b^{[k ] }   e_\\rgt .",
    "\\end{split}\\ ] ] since @xmath104 $ ] is the maximum ",
    "volume submatrix in @xmath105,$ ] it dominates by   in the corresponding rows and columns of the unfolding and _ a fortiori _ in @xmath106 and @xmath107 i.e. @xmath108 and @xmath109 with @xmath110}=a_k^{-1}$ ] we have the following estimates @xmath111 } e_\\rgt| \\leq r_k |a_\\lft b^{[k ] } | \\ , |e_\\rgt| \\leq r_k \\eps |a| ,    \\qquad    |e_\\lft b^{[k ] } a_\\rgt|\\leq r_k\\eps |a| , \\qquad \\mbox{and }    \\\\[1.1ex ]    | e_\\lft b^{[k ] } e_\\rgt |   \\leq r_k^2 \\eps^2 | b^{[k ] } | \\ , | a |^2 = r_k^2 \\eps^2 | a_k^{-1 } | \\ , | a |^2 = r_k \\kappa_k \\eps^2 |a| ,    \\end{array}\\ ] ] which completes the proof .",
    "[ thm1 ] if a tensor @xmath37 satisfies  , and @xmath81 and/or @xmath80 are sufficiently small , then @xmath112 given by   with @xmath84=\\maxvol a^{\\{k\\}}$ ] provides the accuracy @xmath113 where @xmath114 @xmath115 by ` sufficiently small ' we mean such values of @xmath81 and/or @xmath80 that the corresponding estimate provides @xmath116    we will use the _ dimension tree _ suggested in  @xcite , see fig .",
    "[ fig : t1 ] .",
    "the interpolation step   splits a given group of indices @xmath117 in two parts @xmath118 and @xmath119 and introduces the auxiliary summation over the sets @xmath120 and @xmath121 at the point of splitting .",
    "no more than two auxiliary sets appear in each subtensor when the decomposition goes from the whole tensor down to leaves @xmath122,$ ] which constitute  .",
    "leaves consist of the original entries of @xmath123 therefore we have zero error at the ground level .",
    "the interpolation error at the level @xmath124 is estimated by   as follows @xmath125 when we move up by one level of the dimension tree , the error is amplified as shown by  , and the relative error in chebyshev norm propagates as follows @xmath126 here we use the inequality @xmath127 provided by the assumption that @xmath81 and @xmath80 are sufficiently small . clearly , @xmath128 for the balanced tree @xmath129 and @xmath130 which completes the proof .",
    "we are tempted to call @xmath131 the _ condition number _ of the submatrix @xmath132 w.r.t . the chebyshev norm .",
    "technically this is not correct , since in general @xmath133 and @xmath134 however , in  @xcite it is shown that the ratio of the chebyshev norms of a matrix and its maximum  volume submatrix is bounded as follows @xmath135 and often does not grow with rank .",
    "therefore , @xmath136 and usually @xmath137 the similar formula with spectral norms appears in the pioneering paper on the cross interpolation  ( * ? ? ?",
    "* eq . @xmath138 ) .",
    "the splitting of indices in the balanced dimension tree was used to estimate the accuracy of the interpolation in the ht format  @xcite .",
    "the upper bound for the quasioptimality constant in the ht format is @xmath139 where @xmath4 is the maximum representation rank .",
    "note that the upper bounds in   do not _ necessarily _ grow exponentially with  @xmath1 more strict statement is possible if @xmath140 remains bounded or grows moderately with @xmath0 as well , which certainly depends on the properties of a _ sequence _ of @xmath0tensors considered for @xmath141 such rigorous analysis is very important , but is beyond the scope of this paper .",
    "the result of thm .",
    "[ thm1 ] can be interpreted as the _ existence _ of a sufficiently good tt approximation computed from a few entries of a tensor by formula  , provided that the accurate representation in the tt format   is possible .",
    "the coefficient @xmath142 can be also understood as upper bound for the ratio of the accuracy of the  _ best cross _",
    "interpolation   and the _ best possible _ accuracy of the approximation   of the same tt  ranks . thm .",
    "[ thm1 ] is _ constructive _ and prescribes the choice of the interpolation sets @xmath143 to achieve the quasioptimal accuracy .",
    "however , the actual  _ computation _ of maximum  volume sets in unfoldings @xmath144 is impossible due to their restrictively large sizes . in the next sections we consider the nested choice of the interpolation sets which reduces the search space .",
    "in this section we switch to the ultimately unbalanced dimension tree , which splits indices one - by - one , see fig .",
    "[ fig : t2 ] . in  @xcite",
    "this tree has been used to develop the tt ",
    "svd algorithm which approximates a given @xmath0tensor by the tt format .",
    "we apply the same algorithm substituting the svd approximation steps by the interpolation . as in the previous section",
    ", we estimate the accuracy of the resulted approximation w.r.t .",
    "the best possible approximation of the same tt  ranks .    given a tensor @xmath12 $ ] that is approximated by the tensor train",
    ", we apply the interpolation formula   and separate the rightmost index from the others as follows @xmath145}_{t_{d-1},s_{d-1 } }            a(\\i^{\\leq d-1}_{s_{d-1}},i_d )      + e_{d-1}(i_1,\\ldots , i_d ) ,   \\ ] ] where @xmath146 = \\maxvol \\left[a(i_{\\leq d-1},i_d)\\right].$ ] then we interpolate the subtensor with @xmath147 free indices and separate the rightmost free index as follows @xmath148}_{t_{d-2},s_{d-2 } }       a(\\i^{\\leq d-2}_{s_{d-2}},i_{d-1},\\i^{>d-1 } )       + e_{d-2}(i_{\\leq d-1},\\i^ { > d-1 } ) ,    \\end{split}\\ ] ] where @xmath149 = \\maxvol \\left[a(i_{\\leq d-2},i_{d-1}\\i^{>d-1})\\right].$ ] the elements of @xmath150 are now chosen not from all possible values of bi - index @xmath151 but from the reduced set @xmath152 where index @xmath153 is restricted to @xmath154 elements of @xmath155 hereinafter we omit the overline for the sake of clarity , since the use of comma in the pointwise notation is sufficient to show which indices are grouped together . the maximum ",
    "volume subsets @xmath156 and @xmath150 are _ right  nested _ ( cf .",
    "@xcite ) which means that @xmath157 leads to @xmath158 as the interpolation develops further , it holds @xmath159    [ thm2 ] if a tensor @xmath37 satisfies  , then @xmath112 given by   with @xmath160=\\maxvol \\left[a(i_{\\leq k},i_{k+1}\\i^{>k+1})\\right ] , \\qquad k = d-1,\\ldots,1,\\ ] ] provides the following accuracy @xmath161    at the first level of the dimension tree the interpolation writes as follows @xmath162}_{t_1,s_1 }                   a(\\i^{\\leq1}_{s_1},i_2\\i^{>2 } ) + e_1(i_1,i_2\\i^{>2}),\\ ] ] and since @xmath163=\\maxvol\\left[a(i_1,i_2\\i^{>2})\\right],$ ] it holds @xmath164 suppose at the level @xmath33 of the tree it holds @xmath165}_{t_{1},s_{1 } }     \\ldots         b^{[k-1]}_{t_{k-1},s_{k-1 } }     a(\\i^{\\leq k-1}_{s_{k-1}},i_k,\\i^{>k } )   + \\e_k(i_{\\leq k},\\i^{>k } ) ,    \\end{split}\\ ] ] where @xmath166 interpolation at the next level writes as follows @xmath167}_{t_{k},s_{k } }       a(\\i^{\\leq k}_{s_k},i_{k+1}\\i^{>k+1 } )      + e_k(i_{\\leq k+1},\\i^{>k+1 } ) .",
    "\\end{split}\\ ] ] using the previous equation we obtain @xmath168}_{t_{1},s_{1 } }    \\ldots       b^{[k]}_{t_{k},s_{k } }    a(\\i^{\\leq k}_{s_k},i_{k+1},\\i^{>k+1 } )       \\\\      & + \\underbrace{\\sum_{s_k , t_k } \\e_k(i_{\\leq k},\\i^{>k}_{t_k } )      b^{[k]}_{t_{k},s_{k } }   a(\\i^{\\leq k}_{s_k},i_{k+1},\\i^{>k+1 } )     + e_k(i_{\\leq k+1},\\i^{>k+1})}_{\\e_{k+1}(i_{\\leq k+1},\\i^{>k+1})}.   \\end{split}\\ ] ] since @xmath72 are chosen by the maximum ",
    "volume principle , we have @xmath169}_{t_k , s_k } a(\\i^{\\leq k}_{s_k},i_{k+1}\\i^{>k+1 } ) \\right| \\leq 1,\\ ] ] and",
    "it follows that @xmath170 substitution @xmath171 completes the proof .",
    "[ lemi ] if @xmath112 is given by   and the interpolation sets are right  nested as shown by  , then for all @xmath88 it holds @xmath172}_{t_1,s_1 }    \\ldots       b^{[k-1]}_{t_{k-1},s_{k-1 } }    a(\\i^{\\leq k-1}_{s_{k-1}},i_k,\\i^{>k}).\\ ] ]    to prove the statement of the lemma for @xmath173 in   we restrict @xmath174 to @xmath155 the last core reduces to @xmath175_{i_d\\in\\i^{>d-1 } } = \\left[a(\\i^{\\leq d-1},\\i^{>d-1})\\right ] = a_{d-1},\\ ] ] and cancels out with the neighboring matrix @xmath176}.$ ]    suppose that the statement holds for @xmath177 i.e. @xmath178}_{t_1,s_1 }   \\ldots       b^{[p]}_{t_{p},s_{p } }   a(\\i^{\\leq p}_{s_p},i_{p+1},\\i^{>p+1}).\\ ] ] consider this equation for @xmath179 that by   assumes @xmath180 the rightmost core reduces as follows @xmath181_{i_{>p}\\in\\i^{>p } } = \\left[a(\\i^{\\leq p},\\i^{>p})\\right ] = a_p,\\ ] ] and cancels out with @xmath182}.$ ] this proves the statement for @xmath183 and the lemma by recursion .    since @xmath84=\\maxvol\\left[a(i_{\\leq k},i_{k+1}\\i^{>k+1})\\right],$ ]",
    "the quasioptimal estimate   holds for the entries of this subtensor only .",
    "however , @xmath69 $ ] is nonsingular and we can interpolate the whole unfolding @xmath144 by the cross based on @xmath132 with some ( presumably worse ) accuracy estimate @xmath184}_{t_k , s_k }             a(\\i^{\\leq k}_{s_k},i_{k+1},\\ldots , i_d )      + \\hat e_k(\\i ) .    \\ ] ] the following theorem estimates the accuracy of the same interpolation @xmath112 as in the previous theorem w.r.t .",
    "the errors @xmath185 in  .",
    "[ thm3 ] under the conditions of thm .",
    "[ thm2 ] assume additionally that the interpolation   provides sufficiently good accuracy @xmath186 then @xmath187 where @xmath140 is defined in  . by ` sufficiently small ' here we mean such @xmath188 that the denominator of   does not approach zero .",
    "the interpolation sets   have been constructed from right to left according to the dimension tree on fig .",
    "[ fig : t2 ] . in order to estimate the accuracy we separate indices one - by - one with the interpolation   proceeding from left to right .",
    "we begin with @xmath189}_{t_1,s_1 }           a(\\i^{\\leq 1}_{s_1},i_{>1 } ) + \\hat e_1(\\i),\\ ] ] and @xmath190 on the second step we write @xmath191}_{t_2,s_2 }      a(\\i^{\\leq 2}_{s_2},i_{>2 } ) + \\hat e_2(\\i).\\ ] ] we restrict @xmath192 to @xmath193 and substitute the result into the previous equation . @xmath194}_{t_1,s_1 }        a(\\i^{\\leq1}_{s_1},i_2,\\i^{>2}_{t_2 } )               b^{[2]}_{t_2,s_2 }        a(\\i^{\\leq 2}_{s_2},i_{>2 } )      \\\\ & +   \\underbrace{\\sum_{s_1,t_1 }              a(i_1,\\i^{>1}_{t_1 } )                        b^{[1]}_{t_1,s_1 }            \\hat e_2(\\i^{\\leq1}_{s_1},i_{>1 } ) + \\e_1(\\i)}_{\\e_2(\\i)}.   \\end{split}\\ ] ] since @xmath163=\\maxvol\\left[a(i_1,i_2\\i^{>2})\\right],$ ] submatrix @xmath195 dominates in the corresponding rows @xmath196}_{t_1,s_1}\\right|\\leq1 , $ ] and therefore @xmath197    the third interpolation step writes as follows @xmath198}_{t_3,s_3 }           a(\\i^{\\leq 3}_{s_3},i_{>3 } ) + \\hat e_3(\\i).\\ ] ] again , we restrict @xmath199 to @xmath200 and substitute the result into the previous equation . @xmath201}_{t_1,s_1 }                                                  \\ldots                            b^{[3]}_{t_3,s_3 }              a(\\i^{\\leq 3}_{s_3},i_{>3 } )                 + \\e_3(\\i ) ,    \\\\   \\e_3(\\i ) & = \\sum_{\\substack{s_1,s_2\\\\t_1,t_2 } }   \\underbrace{a(i_1,\\i^{>1}_{t_1 } )                           b^{[1]}_{t_1,s_1 }              a(\\i^{\\leq1}_{s_1},i_2,\\i^{>2}_{t_2})}_{\\tilde a(i_1,i_2,\\i^{>2}_{t_2 } ) }              b^{[2]}_{t_2,s_2 }       \\hat e_3(\\i^{\\leq2}_{s_2},i_{>2 } ) + \\e_2(\\i ) .",
    "\\end{split}\\ ] ]    we need to estimate the norm of the matrix in front of @xmath202 avoiding the exponential amplification of the coefficient . to do this",
    ", we replace the ` piece ' of the interpolation train with the subtensor of @xmath82 since @xmath203 the same holds for the subtensors @xmath204 and using lemma  [ lemi ] we write @xmath205}_{t_1,s_1 }   a(\\i^{\\leq1}_{s_1},i_2,\\i^{>2 } )    = a(i_1,i_2,\\i^{>2 } ) - \\e(i_1,i_2,\\i^{>2}).\\ ] ] substituting this into the previous equation , we use the domination of the maximum ",
    "volume submatrix @xmath206 to write @xmath207}_{t_2,s_2}\\right| \\leq 1   $ ] and obtain @xmath208 in further interpolation steps the error accumulates similarly .",
    "finally , @xmath209 which completes the proof .    theorems  [ thm2 ] and  [ thm3 ] estimate the accuracy of the interpolation formula   with the same interpolation sets . in thm .  [ thm2 ]",
    "the quasioptimality result is proven with the coefficient @xmath9 which is much larger than the one in  , cf .",
    "the coefficient  @xmath10 in  @xcite .",
    "since the coefficient in   grows exponentially with the dimension , it can be hardly used in the real estimates .",
    "the result of thm .",
    "[ thm3 ] improves the estimate of thm .",
    "[ thm2 ] provided the errors @xmath185 in   do not grow exponentially with @xmath1 in general we can not provide such upper bound for @xmath210 the estimate   is useful in special cases when the theoretical or numerical estimates available for the errors @xmath185 are bounded or grow moderately with @xmath1    note that the nestedness of the interpolation sets is essential in the proof of thm .",
    "the result of thm .",
    "[ thm3 ] can not be generalized to the ` fully ' maximum  volume case described in thm .",
    "in this section we consider the interpolation   where both left and right interpolation sets are nested , i.e. for all valid @xmath33 it holds @xmath211    the naive way to construct such sets is to run the right  to  left interpolation pass explained in sec .",
    "[ sec : emb ] and keep the right sets @xmath212 only .",
    "the left sets @xmath120 are computed by the left  to  right interpolation pass which separates the index @xmath213 then @xmath214 etc .",
    "we obtain @xmath215   = \\maxvol\\left[a(i_{\\leq k},i_{k+1}\\i^{>k+1})\\right ] , \\quad       \\left[\\i^{\\leq k},\\j^{>k}\\right ]   = \\maxvol\\left[a(\\i^{\\leq k-1}i_k , i_{>k})\\right].\\ ] ] note that @xmath216 $ ] is not necessarily the maximum ",
    "volume submatrix neither in the subtensor @xmath217,$ ] nor in @xmath218,$ ] nor even in their intersection @xmath219.$ ] therefore , we can not use   to estimate the accuracy of   with these interpolation sets .",
    "due to the restrictive sizes , the computation of the maximum volume submatrix is impossible even with implied nestedness . to make the problem tractable",
    ", we should further reduce the search space  the practical recipes will be discussed in the next section .    if both left and right interpolation sets are nested , eq .",
    "is indeed the _ cross interpolation formula _",
    ", as shown by the following theorem",
    ".    [ thmi ] for a tensor @xmath123 the approximation @xmath112 given by   with indices @xmath72 satisfying  , is exact on the positions of all entries evaluated in a tensor @xmath220    it is sufficient to repeat the arguments from the proof of lemma  [ lemi ] for the left and right interpolation sets .    a @xmath40 matrix @xmath37 of rank @xmath4 is defined by @xmath221 parameters , e.g. by @xmath222 elements of the svd decomposition @xmath223 minus @xmath224 normalization constraints @xmath225 @xmath226 the cross interpolation formula   recovers a rank@xmath4 matrix from @xmath221 entries , if a submatrix @xmath227 $ ] is nonsingular .",
    "if @xmath228 formula   provides the approximation @xmath229 which is exact on @xmath221 positions of a matrix .",
    "this fact is generalized to the tensor case by the following theorem .    a tensor @xmath37 with mode sizes @xmath230 and tt ",
    "ranks @xmath71 is defined by @xmath231 parameters . if the left and right interpolation sets satisfy  , and the matrices @xmath232 @xmath233 are nonsingular , formula   recovers @xmath37 from exactly @xmath234 entries .",
    "if a tensor @xmath37 is not given by   exactly , formula   interpolates it on at least @xmath234 positions .",
    "the first statement is proven in  ( * ? ? ?",
    "a.3 ) . taking into account the result of thm .",
    "[ thmi ] , the second and the third statements require to calculate the total number of tensor entries in all subtensors in  .",
    "each block @xmath122 $ ] consists of @xmath235 elements of a tensor , but some entries contribute to more than one block . for example , if   holds , subtensors @xmath236 $ ] and @xmath237 $ ] intersect by the submatrix @xmath238,$ ] which has @xmath239 elements .",
    "similarly , @xmath122 $ ] and @xmath240 $ ] have @xmath241 common elements in the submatrix @xmath242    the common elements of @xmath240 $ ] and @xmath243 $ ] are described by the following conditions @xmath244 if @xmath245 they are reduced by   to @xmath246 and @xmath179 and it holds @xmath247 therefore , all common entries of @xmath240 $ ] and @xmath243 $ ] belong to @xmath132 for @xmath248 the total number of entries which belong to more than one block equals @xmath249 which completes the proof .",
    "we start this section with a short overview of the cross interpolation algorithms for matrices . the idea of reconstruction and approximation of a matrix from several columns and rows by the  _ skeleton decomposition _   or the _ pseudoskeleton decomposition _ @xmath250 @xmath251,$ ] @xmath252,$ ] has been suggested by goreinov and tyrtyshnikov  @xcite . in  @xcite the accuracy of the pseudoskeleton approximation",
    "has been studied and it has been pointed out that a good cross should intersect by a well bounded submatrix . the connection with the maximum ",
    "volume submatrix has been mentioned in  @xcite , and the maximum  volume principle has been presented in more detail in  @xcite .",
    "function to compute entries of a tensor @xmath12 $ ] cross interpolation   with the nested interpolation sets   @xmath253 @xmath254 @xmath15 @xmath255 @xmath256 find a pivot @xmath257 s.t .",
    "@xmath258 add @xmath259 to @xmath260 and @xmath261 to @xmath262 @xmath88 update the interpolation @xmath112 by     the search for the maximum  volume submatrix _",
    "per se _ is an np  hard problem  @xcite . for practical computations ,",
    "it is necessary to find a _ sufficiently good _ submatrix reasonably fast .",
    "the alternating direction algorithm has been proposed in  @xcite , which adaptively increases the size of the interpolation cross following the maximum  volume principle at each step , and computes the approximation of a matrix in linear time w.r.t . the size .",
    "the greedy algorithm of such kind , equivalent to the gaussian elimination with partial pivoting , was then suggested by bebendorf  @xcite . due to its particular simplicity",
    ", it has become widely known as the _ adaptive cross approximation _ ( aca ) . in practical computations , aca and similar methods with minimal information are liable to breakdowns , i.e. they may quit when a good approximation is not yet obtained . a cheap remedy proposed in  @xcite",
    "is to check the accuracy on the random set of entries and restart the algorithm if necessary .",
    "another well  known sampling method is the @xmath263 algorithm of mahoney et al  @xcite , which is the pseudoskeleton @xmath264 decomposition where positions of the rows and columns are chosen randomly .    the accuracy of the maximum  volume cross approximation is estimated for any matrix  @xcite .",
    "algorithms which use a few elements ( e.g. aca ) are _ heuristic _ and construct the approximation which can be arbitrarily bad for other matrix elements .",
    "the accuracy of such algorithms can be estimated in special cases , e.g. for matrices generated by asymptotically smooth functions on quasi  uniform grids , see  @xcite , cf .",
    "@xcite in many dimensions .",
    "the existing cross interpolation algorithms for tensors can be classified similarly .",
    "the skeleton decomposition is generalized to the tensor case in  @xcite by formula  , where the submatrices @xmath69 $ ] play the same role as @xmath227 $ ] in  .",
    "the ` existence result ' is generalized from the matrix case  @xcite to the tt case by thm .",
    "[ thm1 ] . algorithm proposed in  @xcite approximates the maximum  volume positions in the als way , similarly to the one from  @xcite .",
    "a greedy cross interpolation algorithm for the tt format can be suggested similarly to the matrix case , see e.g. alg .",
    "[ algg ] . similarly to the aca , alg .",
    "[ algg ] relies on the interpolation property for the tensor trains , established by thm .",
    "[ thmi ] . on each step",
    ".  [ algg ] searches for a pivot @xmath265 where the error of the current approximation is ( quasi)maximum in modulus .",
    "then it adds the indices of @xmath266 to all subsets @xmath120 and @xmath262 @xmath233 to maintain the two  side nestedness  .",
    "the updated interpolation is exact on all _ lines _",
    "@xmath267 @xmath268 @xmath269    the full pivoting in higher dimensions is impossible due to the curse of dimensionality , and we need cheaper alternatives to find a new pivot and estimate the accuracy for the stopping criterion . following the tensor  cur algorithm of mahoney et al  @xcite we can choose indices randomly .",
    "another approach is to choose the maximum in modulus element of the current residual among a randomly sampled set .",
    "the third option is to choose the pivot from a _ restricted set _",
    "similarly to the aca approach , check the accuracy of the approximation over a random set of entries , and restart if necessary , see  ( * ? ? ?",
    "the restricted pivoting set can naturally arise from the _ locality _ requirement . by this",
    "we mean that with a new pivot we should modify only a few interpolation sets @xmath120 and @xmath212 and increase only a few tt  ranks of the approximation , not all of them .",
    "to put it differently , a pivoting algorithm should update only a few tt  cores of   at each step , similarly to the als and dmrg algorithms introduced in quantum physics .    following the dmrg algorithm",
    ", we choose a new pivot @xmath265 in the dmrg _ supercore _",
    "@xmath270.$ ] this choice provides @xmath271 and by   @xmath272 for @xmath273 similarly , @xmath274 and by nestedness @xmath275 for @xmath276 when we add @xmath259 to @xmath120 and @xmath261 to @xmath262 the two  side nestedness   is preserved _ ipso facto . _",
    "function to compute entries of a tensor @xmath12 $ ] cross interpolation   with the nested interpolation sets   choose @xmath260 @xmath262 @xmath15 which satisfy  , and compute @xmath112 by   apply the cross interpolation ( e.g.  ( * ? ? ?",
    "3 ) ) to the dmrg supercore matrix @xmath277,$ ] using sets @xmath72 as the initial guess , and compute   with @xmath278 and @xmath279 substitute @xmath120 and @xmath212 by the expanded sets @xmath280 and @xmath281 perform right  to - left half  sweep in the same way    the greedy algorithm with pivoting in @xmath282 can be implemented as a simple modification of the cross interpolation algorithm tt  rc from  @xcite . the tt ",
    "rc algorithm is of the dmrg type , which means that it updates two neighboring tt ",
    "cores at a step , computing the matrix @xmath282 in full . the proposed alg .",
    "[ algi ] substitutes this step with the cross interpolation and approximates @xmath283^{-1 }              a(\\j_{s_k}^{\\leq k } , i_{k+1}\\i^{>k+1}),\\ ] ] where @xmath280 and @xmath281 are computed by the matrix cross interpolation algorithm , s.t .",
    "@xmath284   \\simeq \\arg\\max_{\\substack{\\i^{\\leq k-1 } \\\\ \\i^{>k+1 } } } \\vol\\left[a(\\i^{\\leq k-1}i_k , i_{k+1}\\i^{>k+1})\\right].\\ ] ] the resulting algorithm requires @xmath285 evaluation of tensor elements and @xmath286 additional operations , i.e. scales linearly in the mode size and very moderately in the tt ",
    "the algorithm is rank  revealing , i.e. will not increase the tt  ranks of the approximation   over the tt  ranks of a given tensor .",
    "the greedy algorithms are not always good in practice , since the positions chosen as the initial guess may approximate the maximum ",
    "volume submatrices inaccurately and should be removed when the interpolation sets are sufficiently large .",
    "only a slight modification of alg .",
    "[ algi ] is required to develop a non  greedy version .",
    "the numerical results have been obtained using the iridis3 high performance computing facility at the university of southampton .",
    "ghz processors , for more specifications see http://cmg.soton.ac.uk/iridis[cmg.soton.ac.uk/iridis ] . ]",
    "cross interpolation and auxiliary tensor train subroutines are written in fortran@xmath287 by the author .",
    "the code was compiled using the intel composer and linked with lapack / blas subroutines provided with the mkl library .    in the experiments we use a very simple version of alg .",
    "[ algi ] . on each step (",
    "line  4 ) we improve the current approximation by adding only one cross to @xmath288 $ ] .",
    "the position of the new cross is computed as follows .",
    "first , a random sampling is performed on @xmath289 entries of the matrix @xmath277,$ ] and an element is chosen where the error of the current interpolation is maximum in modulus .",
    "then the residual for the row or column ( for left and right half ",
    "sweep , resp . ) which contains this element is evaluated , and the pivot @xmath265 is chosen among its entries . if pivot is not zero up to the machine precision , the obtained cross is added to interpolation sets @xmath290 if pivot is machine null , the rank @xmath18 is not increased .",
    "the interpolation sets are always initialized by the index @xmath291      to to    for a number of randomized experiments we measure the ratio between the accuracy of the approximation in the tt format   and the cross interpolation   with the same tt  ranks .",
    "given dimension @xmath2 mode size @xmath292 mode ranks @xmath4 and _ noise level _",
    "@xmath293 we consider the tensor @xmath294 where @xmath295 is random and @xmath296 is given by the tt format   with tt  ranks @xmath4 and random tt  cores .",
    "all random elements are independently and uniformly distributed on the unit set and we seed them using the internal pseudorandom generator provided with the compiler .",
    "we apply alg .",
    "[ algi ] to compute the initial cross interpolation @xmath297 with tt  ranks not larger than @xmath298 then we run @xmath299 additional sweeps of the dmrg  like tt  rc algorithm  @xcite to improve the positions of the interpolation crosses and obtain @xmath300 density distributions of the logarithm of the quasioptimality coefficient for @xmath297 and @xmath301 are shown on fig .",
    "[ fig : q ] .",
    "the number of tests for each density distribution curve is at least @xmath302    we note that for the randomly generated tensors , the quasioptimality coefficient is not very large .",
    "for example , the top left graph on fig .",
    "[ fig : q ] corresponds to @xmath303 and @xmath304 the estimate of thm .",
    "[ thm1 ] provides the upper bound for the quasioptimality coefficient @xmath305 the computed value is @xmath306 therefore , for the considered experiment the upper bound @xmath307 provided by thm .",
    "[ thm1 ] overestimates the actual value by a factor @xmath308    it is important how the accuracy of the interpolation depends on the dimension @xmath0 and the tt ",
    "rank @xmath298 the result of these experiments are shown in the right column of fig .",
    "[ fig : q ] .",
    "we see that the coefficient grows with rank and dimension slower than the upper bound  . for example , for @xmath309 the upper bound is @xmath310 assuming @xmath311 the actual coefficient computed in the numerical experiments is of the order @xmath312 for @xmath297 and @xmath313 for @xmath300 note that in this case the interpolation improved by the dmrg  like algorithm has worse accuracy than the interpolation returned by  alg .",
    "this may be explained by the fact that the tt ",
    "rc algorithm has the truncation step which reduces tt  ranks and introduces a perturbation to the tensor .",
    "the double  side nestedness   is not preserved during this step which may result in the loss of the interpolation property and deteriorate the accuracy .",
    "this emphasizes the importance of the interpolation property given by thm .",
    "[ thmi ] .",
    "finally , we analyze how the accuracy of the cross interpolation depends on the noise level @xmath314 on the bottom left graph on fig .  [",
    "fig : q ] we see that this parameter does not change the distribution significantly . when @xmath315 further reduction of the noise level has no effect on the distribution of the quasioptimality coefficient .",
    "we summarize that for random tensors the accuracy of the computed cross interpolation behaves much better than the upper bound in  .      #",
    "1#2#3    .accuracy and the cpu time for alg .",
    "[ algi ] applied for the interpolation of tensor   with dimension @xmath2 mode size @xmath316 and tt ",
    "ranks @xmath298 each cell contains the estimates of the relative error in the chebyshev norm @xmath317 and in the frobenius norm @xmath318 and the computation time in seconds . [ cols=\"^ \" , ]     c|ccc|ccc & & + @xmath4 & @xmath319 & @xmath320 & @xmath321 & @xmath319 & @xmath320 & @xmath321 + @xmath322 & & & & & & + @xmath323 & & & & & & + @xmath324 & & & & & & + @xmath325 & & & & & & + @xmath326 & & & & & & + @xmath327 & & & & & & +   + & & + @xmath4 & @xmath319 & @xmath320 & @xmath321 & @xmath319 & @xmath320 & @xmath321 + @xmath328 & & & & & & + @xmath329 & & & & & & + @xmath330 & & & & & & + @xmath331 & & & & & & + @xmath332 & & & & & & + @xmath333 & & & & & & +    we apply alg .",
    "[ algi ] to the tensor @xmath334 $ ] with elements @xmath335 this example is the standard test considered in e.g.  @xcite .",
    "we test the algorithm for large mode sizes @xmath316 and dimensions @xmath2 where the evaluation of the accuracy @xmath336 is impossible due to the restrictively large number of entries .",
    "we substitute the exact evaluation by estimates computed on a large number of randomly distributed elements as follows @xmath337 where indices @xmath338 are chosen randomly , and @xmath339 denotes the number of elements in the random set @xmath340 in our tests @xmath341    the results are collected in tab .  [ tab ] .",
    "it is not difficult to notice the linear scaling w.r.t .",
    "the mode size @xmath342 the scaling in dimension is between @xmath343 and @xmath344 since the algorithm requires @xmath343 evaluations of tensor elements , and each tensor element depends on @xmath0 indices .",
    "the scaling in tt ",
    "rank is almost quadratic , which shows that the evaluation of tensor elements takes longer than other operations .    for large ranks , the relative accuracy of the interpolation computed by alg .",
    "[ algi ] reduces almost to the machine precision threshold and does not stagnate at the level of @xmath345 or @xmath346 cf .",
    "the alg .",
    "[ algi ] also appears to be very fast : using one core on the iridis3 cluster , it is two to three times faster than the ht cross interpolation algorithm  @xcite applied to the same problem .",
    "we have generalized two results on the matrix cross interpolation to the tensor case , using the cross interpolation formula   proposed by oseledets and tyrtyshnikov  @xcite for the tensor train format .",
    "first , we have shown that the maximum ",
    "volume cross interpolation is quasioptimal , i.e. its accuracy in the chebyshev norm differs from the best possible accuracy by the factor which does not grow exponentially with dimension .",
    "this generalizes the matrix result of goreinov and tyrtyshnikov  @xcite .",
    "second , we have shown that for the nested interpolation indices formula   computes @xmath347 parameters of the tt format inspecting exactly the same number of tensor entries , and on these elements the interpolation is exact .",
    "this generalizes the classical result on the skeleton approximation of matrices to the tt case .    in the tensor case , the maximum ",
    "volume interpolation sets in general are not nested , and we can not have the quasioptimality and the interpolation property simultaneously .",
    "it would be interesting to find the nested interpolation sets which provide a moderate coefficient of the quasioptimality .",
    "using the interpolation property , we have proposed the fast and simple greedy cross interpolation algorithm , which provides very accurate results for the standard test , and is several times faster than other methods .",
    "many variants of this algorithm can be developed , taking in account the interpolation property and the available information on the error of the interpolation for different entries of a tensor .",
    "it is easy to overcome the breakdowns , if they occur , simply by taking random pivots in larger subtensors or in the whole tensor , as is suggested in alg .",
    "[ algg ] . in our experiments",
    "we have never had a breakdown using the restricted pivoting in alg .",
    "[ algi ] .",
    "the theoretical and experimental results of this paper show that the curse of dimensionality can not stop us from developing fast and reliable cross interpolation methods in higher dimensions .",
    "the cross interpolation allows to convert a given high  dimensional data array into the tensor train format , for which many operations essential for the scientific computing are already possible . for many high  dimensional problems we can try to substitute the randomized ( monte carlo ) sampling by the cross interpolation in order to benefit from its adaptivity",
    "this is a subject of further work .",
    "the theoretical results of this paper have been obtained when the author was with the institute of numerical mathematics ras , moscow .",
    "the author is grateful to prof .",
    "eugene tyrtyshnikov and dr .",
    "ivan oseledets for fruitful discussions .",
    "the author appreciates the use of the iridis high performance computing facility , and the associated support services at the university of southampton , that proved essential to carry out the extensive numerical experiments reported in this paper .",
    "the author acknowledges the hospitality of sam eth zrich , where the most of the manuscript has been drafted .",
    "j.  ballani , l.  grasedyck , and m.  kluge , black box approximation of tensors in hierarchical tucker format , _ linear alg .",
    "_ , 428:639657 , 2013 .",
    "doi : http://dx.doi.org/10.1016/j.laa.2011.08.010[10.1016/j.laa.2011.08.010 ] .",
    "s.  v. dolgov , b.  n. khoromskij , and d.  v. savostyanov , superfast fourier transform using qtt approximation , _",
    "j. fourier anal .",
    "_ , 18(5):915953 , 2012 .",
    "doi : http://dx.doi.org/10.1007/s00041-012-9227-4[10.1007/s00041-012-9227-4 ] .",
    "s.  v. dolgov and i.  v. oseledets , solution of linear systems and matrix inversion in the tt - format , _",
    "siam j. sci .",
    "_ , 34(5):a2718a2739 , 2012 .",
    "doi : http://dx.doi.org/10.1137/110833142[10.1137/110833142 ] .",
    "s.  v. dolgov and d.  v. savostyanov , alternating minimal energy methods for linear systems in higher dimensions .",
    "part i : spd systems , arxiv preprint 1301.6068 , 2013 .",
    "http://arxiv.org/abs/1301.6068 [ http://arxiv.org/abs/1301.6068 ] .",
    "height 2pt depth -1.6pt width 23pt , alternating minimal energy methods for linear systems in higher dimensions .",
    "part ii : faster algorithm and application to nonsymmetric systems , arxiv preprint 1304.1222 , 2013 .",
    "http://arxiv.org/abs/1304.1222 [ http://arxiv.org/abs/1304.1222 ] .",
    "p.  drineas , r.  kannan , and m.  w. mahoney , fast monte carlo algorithms for matrices iii : computing a compressed approximate matrix decomposition , _ siam j comput _",
    ", 36(1):184206 , 2006 .",
    "doi : http://dx.doi.org/10.1137/s0097539704442702[10.1137/s0097539704442702 ] .",
    "s.  a. goreinov , i.  v. oseledets , d.  v. savostyanov , e.  e. tyrtyshnikov , and n.  l. zamarashkin , how to find a good submatrix , in matrix methods : theory , algorithms , applications , v.  olshevsky and e.  tyrtyshnikov , eds . ,",
    "world scientific , hackensack , ny , 2010 , pp .",
    "247256 .",
    "height 2pt depth -1.6pt width 23pt , a theory of pseudo  skeleton approximations , _ linear algebra appl .",
    "_ , 261:121 , 1997 .",
    "doi : http://dx.doi.org/10.1016/s0024-3795(96)00301-1[10.1016/s0024-3795(96)00301-1 ] .",
    "l.  grasedyck , d.  kressner , and c.  tobler , a literature survey of low - rank tensor approximation techniques , arxiv preprint 1302.7121 , 2013 .",
    "http://arxiv.org/abs/1302.7121 [ http://arxiv.org/abs/1302.7121 ] .",
    "s.  holtz , t.  rohwedder , and r.  schneider , the alternating linear scheme for tensor optimization in the tensor train format , _",
    "siam j. sci .",
    "_ , 34(2):a683a713 , 2012 .",
    "doi : http://dx.doi.org/10.1137/100818893[10.1137/100818893 ] .",
    "v.  kazeev , b.  n. khoromskij , and e.  e. tyrtyshnikov , multilevel toeplitz matrices generated by tensor - structured vectors and convolution with logarithmic complexity , tech .",
    "36 , mpi mis , leipzig , 2011 .",
    "http://www.mis.mpg.de/publications/preprints/2011/prepr2011-36.html [    http://www.mis.mpg.de/publications/preprints/2011/prepr2011-36.html ] .",
    "b.  n. khoromskij , @xmath348quantics approximation of @xmath349@xmath0 tensors in high - dimensional numerical modeling , _ constr .",
    "_ , 34(2):257280 , 2011 .",
    "doi : http://dx.doi.org/10.1007/s00365-011-9131-1[10.1007/s00365-011-9131-1 ] .",
    "height 2pt depth -1.6pt width 23pt , tensor - structured numerical methods in scientific computing : survey on recent advances , _ chemometr .",
    "intell . lab .",
    "_ , 110(1):119 , 2012 .",
    "doi : http://dx.doi.org/10.1016/j.chemolab.2011.09.001[10.1016/j.chemolab.2011.09.001 ] .",
    "a.  klmper , a.  schadschneider , and j.  zittartz , matrix product ground states for one - dimensional spin-1 quantum antiferromagnets , _ europhys .",
    "_ , 24(4):293297 , 1993 .",
    "doi : http://dx.doi.org/10.1209/0295-5075/24/4/010[10.1209/0295-5075/24/4/010 ] .",
    "m.  w. mahoney , m.  maggioni , and p.  drineas , tensor - cur decompositions for tensor - based data , _",
    "siam j. matr .",
    "_ , 30(3):957987 , 2008 .",
    "doi : http://dx.doi.org/10.1137/060665336[10.1137/060665336 ] .",
    "height 2pt depth -1.6pt width 23pt , constructive representation of functions in low - rank tensor formats , _ constr .",
    "appr . _ , 37(1):118 , 2013 .",
    "doi : http://dx.doi.org/10.1007/s00365-012-9175-x[10.1007/s00365-012-9175-x ] .",
    "i.  v. oseledets , d.  v. savostianov , and e.  e. tyrtyshnikov , tucker dimensionality reduction of three - dimensional arrays in linear time , _ siam j. matrix anal .",
    "_ , 30(3):939956 , 2008 .",
    "doi : http://dx.doi.org/10.1137/060655894[10.1137/060655894 ] .",
    "i.  v. oseledets , d.  v. savostyanov , and e.  e. tyrtyshnikov , cross approximation in tensor electron density computations , _ numer .",
    "linear algebra appl .",
    "_ , 17(6):935952 , 2010 .",
    "doi : http://dx.doi.org/10.1002/nla.682[10.1002/nla.682 ] .",
    "i.  v. oseledets and e.  e. tyrtyshnikov , breaking the curse of dimensionality , or how to use svd in many dimensions , _ siam j. sci . comput .",
    "_ , 31(5):37443759 , 2009 .",
    "doi : http://dx.doi.org/10.1137/090748330[10.1137/090748330 ] .",
    "height 2pt depth -1.6pt width 23pt , tt - cross approximation for multidimensional arrays , _ linear algebra appl .",
    "_ , 432(1):7088 , 2010 .",
    "doi : http://dx.doi.org/10.1016/j.laa.2009.07.024[10.1016/j.laa.2009.07.024 ] .",
    "s.  stlund and s.  rommer , thermodynamic limit of density matrix renormalization , _ phys .",
    "_ , 75(19):35373540 , 1995 .",
    "doi : http://dx.doi.org/10.1103/physrevlett.75.3537[10.1103/physrevlett.75.3537 ] .",
    "t.  rohwedder and a.  uschmajew , local convergence of alternating schemes for optimization of convex problems in the tt format , _ siam j num .",
    "_ , 51(2):11341162 , 2013 .",
    "doi : http://dx.doi.org/10.1137/110857520[10.1137/110857520 ] .",
    "d.  v. savostyanov , polilinear approximation of matrices and integral equations , phd thesis , inm ras , moscow , 2006 .",
    "( in russian ) ,    http://www.inm.ras.ru/library/tyrtyshnikov/savostyanov_disser.pdf [    http://www.inm.ras.ru/library/tyrtyshnikov/savostyanov_disser.pdf ] .",
    "d.  v. savostyanov and i.  v. oseledets , fast adaptive interpolation of multi - dimensional arrays in tensor train format , in proceedings of 7th international workshop on multidimensional systems ( nds ) , ieee , 2011 .",
    "doi : http://dx.doi.org/10.1109/nds.2011.6076873[10.1109/nds.2011.6076873 ] .",
    "height 2pt depth -1.6pt width 23pt , tensor approximations of matrices generated by asymptotically smooth functions , _ sbornik : mathematics _",
    ", 194(6):941954 , 2003 .",
    "doi : http://dx.doi.org/10.1070/sm2003v194n06abeh000747[10.1070/sm2003v194n06abeh000747 ] .",
    "height 2pt depth -1.6pt width 23pt , kronecker - product approximations for some function - related matrices , _ linear algebra appl .",
    "_ , 379:423437 , 2004 .",
    "doi : http://dx.doi.org/10.1016/j.laa.2003.08.013[10.1016/j.laa.2003.08.013 ] ."
  ],
  "abstract_text": [
    "<S> we consider a cross interpolation of high  dimensional arrays in the tensor train format . </S>",
    "<S> we prove that the maximum  </S>",
    "<S> volume choice of the interpolation sets provides the quasioptimal interpolation accuracy , that differs from the best possible accuracy by the factor which does not grow exponentially with dimension . for nested interpolation sets we prove the interpolation property and propose greedy cross interpolation algorithms . </S>",
    "<S> we justify the theoretical results and test the speed and accuracy of the proposed algorithm with convincing numerical experiments .    _ </S>",
    "<S> keywords : _ high  dimensional problems , tensor train format , maximum  volume principle , cross interpolation .    _ </S>",
    "<S> ams : _ </S>",
    "<S> 15a69 , 15a23 , 65d05 , 65f99 . </S>"
  ]
}