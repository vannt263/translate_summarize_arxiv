{
  "article_text": [
    "[ t ]     crowdsourcing is quickly changing data collection practices in both industry and data - driven research areas such as natural language processing  @xcite , computer vision  @xcite , and information retrieval  @xcite .",
    "however , quality concerns persist , especially with rudimentary crowdsourcing platforms like amazon s mechanical turk ( mturk ) where factors such as anonymity , piece - work pay , and limited worker interaction can contribute to poor quality crowd work .",
    "various statistical approaches have been proposed for mitigating these issues , such as by aggregating inputs from multiple workers  @xcite or filtering out inaccurate workers  @xcite .",
    "mturk s default use case assumes workers self - select tasks . in principle",
    ", this is often a good idea .",
    "for example , using an in - house labor platform , law et al .  found higher quality work when workers were allowed to self - select work rather than be assigned it arbitrarily .",
    "however , an important assumption here is that workers are able to effectively search and find tasks of interest .",
    "in fact , prior work has shown that limited task search capabilities on mturk in practice often lead to task selection being more random than one might otherwise expect  @xcite . moreover ,",
    "lack of support for task routing in mturk s default setup has led to a dearth of research in this area .",
    "nonetheless , like spam filtering , the promise of work filtering / tailored work assignments is to better match workers to work for which they are best suited , with potential to increase work quality and satisfaction and reduce inefficiency of task selection .",
    "we describe methods to predict a crowd worker s accuracy on new tasks based on his accuracy on past tasks .",
    "such prediction provides a foundation for identifying the best workers to route work to in order to maximize accuracy on the new task .",
    "note our methods do _ not _ require example feature representations and so are broadly applicable across crowdsourcing tasks .",
    "our key insight , based on preliminary analysis on our mturk data ( section  [ sec : real_data ] ) , suggests cross - task worker accuracies being correlated based on task similarity .",
    "intuitively , more similar tasks should yield more similar worker accuracy across tasks .",
    "of course , `` spammers '' may still perform uncorrelated , inaccurate work across tasks . by modeling similarity to past tasks ,",
    "work history can be better integrated to predict new task accuracy .",
    "critically , note that such prediction can not be done for one - shot or small scale data collection , where there is no work history , or where workers completely little work before leaving and never returning . while many academic studies have tended to report low rates of worker retention across tasks and within - task completion , we posit this may reflect community sampling bias of one - off , infrequent academic studies .",
    "in contrast , commercial crowd work offers large volume and repetition that allows workers to amortize time to spent learning a task , returning to tasks for which they are already familiar for greater retention and completion rates .",
    "we describe two approaches to predict worker accuracies based on matrix factorization ( mf ) , widely used in collaborative filtering problems to predict missing values in a matrix using low - rank feature vectors  @xcite .",
    "to predict unobserved workers performance on a new task , we construct a worker - task matrix , where entries reflect a worker s observed accuracy on past tasks , evaluated against some sample of ground truth data ( figure  [ fig : mf_process ] ) .",
    "we investigate two well - known mf models : singular value decomposition ( svd ) and probabilistic matrix factorization ( pmf )  @xcite .",
    "prior work  @xcite describes the two mf s tradeoffs for general recommendation systems .",
    "we revisit such questions by investigating these issues in our setting of crowd worker accuracy prediction .",
    "experiments on synthetic and real - world datasets provide feasibility assessment and comparative evaluation of mf approaches vs.  two baseline methods . across a range of data scales and task similarity conditions ,",
    "we evaluate methods in two ways : rmse prediction error over all workers , and average accuracy of the top _",
    "k _ ranked workers according to each prediction method .",
    "rq1 : mf - based prediction accuracy : :    _ how does mf prediction performance vary as a function of task    similarity , matrix size , and matrix density for predicting worker    accuracies across tasks ? how feasible and robust is it to challenging    conditions ?",
    "_ rq2 : finding top workers : :    _ does task routing to predicted top @xmath0 workers outperform    random assignment ?",
    "if so , by what degree , and how do proposed mf    methods ( pmf and svd ) compare vs.  simpler baseline methods ( average    and weighted average ) ? _ rq3 : the effect of spammers : :    how robust is mf - based task routing to the existence of spammers ?",
    "results show the benefit of task routing over random assignment , the strength of probabilistic mf over baselines , and robustness of methods to different conditions .",
    "mturk s standard method of task self - selection has led to relatively few studies on task routing to better match workers to tasks , though work considered task assignment in other venues , such as wikipedia  @xcite .",
    "others have studied the cooperative refinement and task routing among on - line agents with regard to prediction tasks  @xcite .",
    "bernstein at al .",
    "@xcite investigate task routing in terms of real - time crowdsourcing .",
    "though informative , these studies do not address finding strong candidates for a particular task from a task requester s viewpoint .",
    "other work on task markets chains together of different worker competencies for problem solving  @xcite .",
    "karger et al .",
    "@xcite present a task assignment model based on random graph generation and a message - passing inference algorithm , in order to route tasks to crowd workers under homogeneous labeling tasks .",
    "ho et al .",
    "@xcite attempt to generalize this model to allow heterogeneous tasks by applying on - line primal - dual techniques .",
    "however , neither study answers the question of how to predict the unobserved workers performance , which is critical to task routing in practice .",
    "zhang et al .",
    "@xcite consider a related task routing task that seeks to engage people or automated agents to both contribute solutions and route tasks onward .",
    "jung and lease  @xcite study mf methods to improve the quality of crowdsourced labels , using a pmf model to infer unobserved labels in order to reduce the bias of the existing labels .",
    "they do not consider task routing .",
    "yi et al .",
    "investigate matrix completion for crowdclustering , and more recently inferring user preferences  @xcite .",
    "yuen et al .",
    "@xcite consider workers task selection preferences and propose a task recommendation model based on pmf .",
    "however , they motivated their approach on conceptual grounds and did not evaluate it .",
    "most recently , kolobov et al .",
    "@xcite investigate task routing of multiple tasks across a common pool of workers .",
    "matrix factorization ( mf ) has been studied for effectively recommending an item for a user in an online marketplace and advertisement .",
    "our intuition is that finding strong candidates for a specific task is very similar to the recommendation of items for a specific user in collaborative filtering  @xcite .",
    "in addition , latent features should capture how a worker successfully makes a label for a specific task .",
    "for example , two workers would achieve high accuracy for a task type if they both have similar amounts of domain knowledge for this task type .",
    "if we can discover these latent features , we should be able to predict workers accuracies by task . given a partially observed worker - task matrix , we aim to predict unobserved workers accuracies ( e.g. , on new tasks ) so that we might route work optimally , or recruit or exclude particular workers for a given new task .",
    "* singular value decomposition ( svd ) * seeks an approximation matrix @xmath1 of the given rank which minimizes the sum - squared distance between the original matrix @xmath2 and @xmath3 .",
    "it has a critical drawback : it is undefined for incomplete matrices .",
    "thus , it does not solve the problem of sparseness in the given @xmath2 .",
    "* probabilistic matrix factorization ( pmf ) * was introduced by ruslan  @xcite and has demonstrated excellent performance in the netflix challenge .",
    "we have _ m _ crowd workers , _",
    "n _ tasks , and a worker - task matrix @xmath2 in which @xmath4 indicates the accuracy of worker @xmath5 for task @xmath6 .",
    "let @xmath7 and @xmath8 be latent feature matrices for workers and tasks , with column vectors @xmath9 and @xmath10 representing @xmath11-dimensional crowd worker - specific and task - specific latent feature vectors , respectively .",
    "the conditional probability distribution over the observed cells @xmath12 is given by equation 2 .",
    "indicator @xmath13 equals 1 _ iff _ worker _ i _ s accuracy is measured over task _ j_. we place zero - mean spherical gaussian priors on worker and task feature vectors . to estimate model parameters ,",
    "we maximize the log - posterior over example and worker features with fixed hyper - parameters .",
    "maximizing the posterior with respect to _ w _ and _ t _ is equivalent to minimizing squared error with l2 regularization : @xmath14 where @xmath15 , and @xmath16 denotes the frobenius norm .",
    "we use gradient descent to find a local minimum of the objective for @xmath17 and @xmath18 .",
    "finally , we infer unobserved workers accuracies in the worker - task matrix @xmath2 by the scalar product of _ w _ and _ t_.",
    "[ t ]     [ t ]     our first set of experiments use synthetic data , letting us carefully control a variety of experimental variables for detailed analysis . following this ,",
    "we describe additional experiments with real crowd data to assess performance of methods for a specific case of actual operating conditions .",
    "we begin by describing these datasets .    our generative model for synthetic data",
    "is based up the the mturk dataset consisting of three tasks ( section  [ sec : real_data ] ) .",
    "figure  [ fig : real_turk_histogram ] plots histograms showing the number of workers achieving various levels of accuracy in each of three mturk tasks .",
    "these histograms show a strong normal tendency , which we quantify later via a shapiro - wilk test  @xcite ( table  [ table : summary_real_data ] ) .",
    "in addition , figure  [ fig : scatter_tasks ] ( left ) plots average worker accuracy for task 1 vs.  task2 and shows strong correlation at high accuracies ( similar plots for task 1 vs.  task 3 and task 2 vs.  task 3 are not shown ) . in other words ,",
    "the best workers appear to be fairly accurate across tasks , whereas other workers show less correlation across tasks , perhaps tending toward uncorrelated accuracies as average accuracy across tasks decreases ( e.g. , the increasing prevalence of `` spammers '' as we consider lower average accuracies ) .",
    "these observations suggest correlated worker accuracies across tasks , which might be reasonably well - fit by a multivariate normal distribution with appropriate covariance .",
    "we further develop this idea below .",
    "@xmath19 @xmath20 @xmath21 @xmath22 = m[t]$ ] @xmath23 $ ] @xmath24 @xmath25 @xmath26 @xmath27 @xmath280.9/(9-j*10 ) @xmath29}$ ] @xmath30 = uniform[0,max]$ ] @xmath31    our model of worker behavior makes three key assumptions .",
    "firstly , we model workers accuracies as following a normal distribution n(@xmath32 , @xmath33 ) , based on our real crowd accuracy histograms ( figure  [ fig : real_turk_histogram ] ) and supported by a shapiro - wilk test  @xcite confirming high normality ( table  [ table : summary_real_data ] ) . secondly , we assume worker accuracy is correlated across tasks in proportion to task similarity .",
    "in addition to knowing people naturally exhibit varying expertise / skill across tasks , we also observe this in our real crowd data ( correlation in figure  [ fig : scatter_tasks ] s left plot ) .",
    "thirdly , we posit the existence of `` spammers '' who exhibit low accuracy , uncorrelated across tasks , due to any number of factors , such as fatigue , low language competency , negligence , etc . because better workers are less likely to be spammers ( by definition ) , we expect fewer spammers when average worker accuracy is high , and the ratio increasingly shifting toward more spammers at lower accuracies .    our generative model for synthetic data ( algorithm  [ alg : data_gen ] ) takes three parameters as input which we vary as experimental variables : task similarity @xmath34 , number of tasks @xmath35 , and number of workers @xmath36 .",
    "we sample a multivariate normal distribution of accuracies ( per - task average accuracy ) , providing correlation across tasks by specifying covariance matrix @xmath33 filled with @xmath34 ( rmvnorm function from mvtnorm library in @xmath2 ) .",
    "this `` optimistic '' distribution is free of spammers and reflects an idealized model of correlated accuracies .",
    "next , we introduce spammers to produce an alternative `` pessimistic '' distribution by transforming a percentage of the idealized workers into spammers . to accomplish this , we first group workers by distributional strata over average accuracy across tasks ( using a sliding window of size @xmath37 ) .",
    "we then randomly sample a percentage of diligent workers from each strata and transform them into spammers by replacing their idealized per - task accuracy on each task with an accuracy sampled uniformly at random .",
    "note that as a function of strata , we must decide ( a ) what percentage of workers to transform , and ( b ) the maximum accuracy of the interval from which to sample spammer accuracies .",
    "while our choice of functions here for ( a ) and ( b ) are relatively ad hoc , they enforce our principle above of finding fewer spammers as worker accuracy increases .",
    "we argue strengths of this model include : ( i ) its full description for reproducibility by others  @xcite ; ( ii ) its implementation of over - arching modeling assumptions in some reasonable way ; and ( iii ) an explicit discussion of how more accurate simulation might be achieved by further analysis and characterization of real crowd data properties .",
    ".attributes of mturk data with three tasks .",
    "task similarity @xmath34 ranges from [ 0.545:0.719 ] .",
    "for all tasks , distribution of per - task worker accuracies follow a normal distribution with high statistical significance ( @xmath38 ) under the shapiro - wilk test  @xcite .",
    "[ cols=\"^,^,^,^\",options=\"header \" , ]      we experiment with a commercial mturk dataset which includes three different text processing tasks .",
    "only workers with high approval ratings were allowed to perform work .",
    "while we can not further describe the tasks or their similarity , we will show task similarity can be inferred automatically and varies .",
    "moreover , asking a person to articulate a similarity score for two tasks is not a natural activity and expected to be difficult anyway , without experience or guidelines . as such ,",
    "the ability to automatically infer task similarities without any reliance on manual tweaking is a strength of our approach .",
    "we also note ours is a retrospective study : workers self - selected what work to perform during actual data collection , and we simulate task assignment now after the fact .",
    "while such retrospective assignment methodology represents a common study design in active learning and community question answering research , we nonetheless method the usual limitations of such a study design . in practice",
    ", we would have to contend with workers not performing tasks assigned to them , or that accuracy could diminish when people are assigned work instead of self - selecting that which most interests them .    because a central goal of our work is to identify strong workers to whom work",
    "could be usefully assigned , there is little value in modeling workers who only briefly try out a task without completing much work .",
    "consequently , we exclude workers who completed fewer than ten examples per task ( 37.4% of workers retained for task1 , 43.2% for task2 , and 30.8% for task 3 ) .",
    "while modeling these other workers could be interesting in multiple respects ( e.g. , to study these `` flighty '' workers , or estimating worker accuracies from extremely sparse observations ) , we leave this for future work .",
    "table  [ table : summary_real_data ] characterizes remaining data for each task .",
    "443 workers completed at least 10 examples on all 3 tasks , and 43% of the ( 443 x 3 ) worker - task matrix observed .",
    "while prior crowdsourcing studies have tended to report lower rates of worker retention across tasks and within - task completion , the difference seen in our data may be indicative of a sampling bias between what is observed in one - off , infrequent academic studies vs.  what is seen in commercial crowd work , where volume and repetition of familiar tasks lead to greater worker retention and completion rates .",
    "greater study of commercial crowd data to assess such potential bias will be another interesting direction for future work .",
    "we report root - mean squared error ( rmse ) and the mean accuracy of the top _ k _ workers ( ma@xmath39 ) according to some ranking function : @xmath40 where @xmath41 and @xmath42 respectively denote the predicted vs.  observed worker accuracy for worker @xmath5 on task @xmath6 .",
    "while task similarity @xmath34 could be operationalized in many ways , in this study we adopt pearson s correlation coefficient @xmath43 ( i.e. , @xmath44 in our study , but we preserve distinct notation of @xmath34 for generality ) .",
    "following standard practice  @xcite , we distinguish four specific levels of correlation in our experiments : weak ( @xmath43=0.1 ) , medium ( @xmath43=0.4 ) , strong ( @xmath43=0.7 ) , and very strong ( @xmath43=0.9 ) .",
    "mf infers unobserved , low dimensional factors ( feature vectors ) to explain observed workers accuracies .",
    "we want to find an optimal dimensionality @xmath11 for these latent feature vectors . while larger @xmath11 is expected to yield more accurate prediction",
    ", it comes at a computational cost .",
    "thus , it is common to optimize @xmath11 on development data .",
    "this development data is also used to optimize pmf regularization parameters @xmath45 and @xmath46 and learning rate @xmath47 . unlike our pmf formulation , svd is parameter - free .",
    "@xmath45 and @xmath46 are selected via 5-fold cross - validation , using * only * 20% of data for training and leaving 80% for testing . for simplicity",
    ", we try only three settings each for @xmath45 and @xmath48 , ultimately selecting @xmath49 .",
    "we use @xmath50 without tuning .",
    "one goal of our work is to assess the potential benefit of task routing at all ( i.e. , any approach ) vs.  just assigning tasks arbitrarily ( i.e. , random task assignment ) .",
    "while random assignment represents a very simplified model of how mturk workers self - select tasks today , prior work has shown that mturk s limited task search capabilities lead to task selection often being more random than one might expect otherwise  @xcite .",
    "thus for task routing experiments , random assignment provides our simplest , uninformed baseline .    a related but distinct goal of our work is to assess relative improvement of specific approaches proposed in section  [ sec : mf_model ] ( svd and pmf ) vs.  alternative , simpler but reasonable baseline methods one might utilize for automatic task assignment .",
    "our first such informed baseline is to simply predict a worker s accuracy on a new task by his average accuracy on other tasks .",
    "a limitation of this baseline , however , is that it completely ignores task similarity .",
    "moreover , since our generative model for synthetic data explicitly generates worker accuracies correlated across tasks by similarity ( section  [ sec : data_gen ] ) , we expect a baseline exploiting this additional information should perform better .",
    "our second informed baseline therefore computes an expectation ( weighted average ) across tasks based on task similarity rather than a simple average .",
    "[ t ]         _ to what extent do task similarity , matrix size , and matrix density influence mf - based prediction of crowd worker accuracies for varying task similarity ? _ we",
    "first measure rmse of pmf and svd methods vs.  baseline methods for task similarity @xmath34 ( pearson s correlation @xmath43 ) @xmath51 , averaging 1,000 simulation trials for each setting of @xmath34 .",
    "results in figure  [ fig : task_similarity ] ( a ) and ( b ) show the rmse achieved along the y - axis .    our first set of experiments ( figure  [ fig : task_similarity](a ) ) evaluate our ability to effectively predict worker accuracies across varying task similarity @xmath34 , number of tasks , and number of workers .",
    "we vary the number of tasks from 5 to 30 ( by 5 ) and the number of workers from 100 to 3000 ( by 500 ) .",
    "four configurations of varying number of tasks @xmath35 vs.  number of workers are shown : ( 5,500 ) , ( 10,1000 ) , ( 20 , 2000 ) , and ( 30,3000 ) .",
    "task similarity @xmath34 is varied along the x - axis .",
    "matrix density is fixed at 20% and dimensionality @xmath11 is set by @xmath52 .",
    "our second set of experiments ( figure  [ fig : task_similarity](b ) ) evaluate our ability to effectively predict worker accuracies under varying task similarity @xmath34 and matrix density .",
    "each of the four plots corresponds to a different task similarity @xmath53 , matching the levels of pearson correlation @xmath43 from _ weak _ to _ very strong _ as defined in section  [ sec : metrics ] .",
    "matrix density varies along the x - axis ( from 10 - 90% ) .",
    "we fix the number of tasks ( @xmath54 ) , dimensionality ( @xmath52 ) , and the number of workers ( 2000 ) .",
    "[ t ]     * task similarity .",
    "* _ how similar do tasks need to be before we can make effective predictions ?",
    "how much do predictions improve with greater task similarity ?",
    "_ with only weak similarity @xmath55 ( left - most point in all 4 plots in ( a ) , left - most plot in ( b ) ) , rmse of 0.21 - 0.23 can still be achieved , though this is far below the best rmse@xmath560.13 observed with very high task similarity .",
    "baselines seem sufficient , without need for mf methods .    as task similarity increases ( across x - axis in ( a ) plots , and across plots in ( b ) ) , it tends to enable better prediction of worker accuracies across tasks , as expected .",
    "moreover , we see pmf predictions improve by exploiting greater task similarity : both as the number of tasks and workers increase ( a ) , or as matrix density increases ( b ) . in contrast , svd performs comparably to baselines in all four of the plots in ( a ) ; it does not benefit from increased task similarity even as the matrix size grows .",
    "while in ( b ) plots we do see svd perform much better as @xmath34 increases with greater density , pmf still outperforms svm by a wide margin .    * matrix size . * _ how effectively can we predict worker accuracies when only small worker - task matrices ( relatively few workers or tasks ) are observed ?",
    "at what point ( if any ) does accuracy prediction break due as the matrix becomes too small ?",
    "how much does prediction improve with larger matrix size ?",
    "_    figure  [ fig : task_similarity](a ) shows that in the smallest case of 5 tasks and 500 workers , rmse of 0.21 - 0.23 can still be achieved . moreover , baseline methods seem sufficient in this case ( comparable to mf methods ) .",
    "however , this is far below the sub-0.15 rmse achieved by pmf with larger matrix sizes .",
    "as noted above , we see pmf capitalize on increasing task similarity @xmath34 with larger matrices while svd does not .",
    "* the effect of matrix density / sparseness . * prior crowdsourcing studies often report workers are often transient and rarely complete all tasks available .",
    "_ what matrix density is needed to support effective worker accuracy predictions across tasks ?",
    "how does prediction accuracy improve with increasing density ?",
    "_    figure  [ fig : task_similarity](b ) shows across plots , rmse lies in [ 0.19 - 0.21 ] when density is only 10% . as before , baseline methods seem sufficient when density is so low , with no improvement from mf methods . however , as noted above , both svd and pmf improves dramatically vs. baselines with greater density , with pmf consistently dominating svd across ( b ) plots .",
    "the best case rmse@xmath560.13 is observed under ideal settings of an extremely dense matrix and large worker - task matrix",
    ".    * rq1 summary . * under worst case conditions ,",
    "results show worker accuracies can be predicted with rmse@xmath57 $ ] , and that even simple averaging suffices is comparable to mf methods .",
    "however , as tasks exhibit even medium task similarity ( @xmath58 ) significant gains are possible , and especially with steep with high correlation ( @xmath59 ) .",
    "similar wins occur as matrix size increases , and with steep rmse decreases beginning with matrix densities around only 30% .",
    "pmf consistently outperforms svd in all cases where sufficient data exists to outperform baselines .",
    "rq1 investigated our ability to predict worker accuracies across tasks in terms of rmse .",
    "for task routing , however , what we would really like to do is identify the top @xmath0 workers for a given task and route work to them ; we do not care about specific accuracies , nor do we care about workers below this top @xmath0 .",
    "we would like to know if routing work to some top @xmath0 workers ( via any method ) outperforms random assignment by some margin .",
    "if so , we would like to evaluate the relative benefit of proposed mf methods ( pmf and svd ) vs.  the simpler baseline methods ( average and weighted average ) .    to answer these questions",
    ", we use some method ( informed or random ) to identify a set of @xmath0 workers , and we measure the average accuracy of these @xmath0 workers to compute ma@xmath39 for each method . as in earlier experiments ,",
    "informed methods use limited training set knowledge ( 20% ) of a worker s accuracy on @xmath60 other tasks to predict the worker s accuracy on held out task @xmath35 , and we perform this prediction in round - robin fashion across tasks , with each task held out in turn and accuracy of workers on it predicted from the other tasks . in experiments here , after computing the average worker across @xmath0 workers for each task , we then average this average accuracy across tasks to arrive at ma@xmath39 for each method .",
    "we vary @xmath0 in these experiments .    as in figure",
    "[ fig : task_similarity ] , figure  [ fig : ma_exp ] shows two sets of experiments ( a ) and ( b ) of four plots each . the first figure ( a ) shows matrix dimension vs.  top _ 10 _ workers ma@xmath61 .",
    "the x - axis shows increasing task similarity [ 0.1:0.9 ] ; matrix dimension is increased across plots .",
    "the figure ( b ) shows task similarity vs.  top _ k _ workers mean accuracy ma@xmath39 .",
    "the x - axis shows increasing @xmath62 $ ] of top _ k _ workers .",
    "we evaluate ma@xmath39 across increasing task similarity ( 0.1 , 0.4 , 0.7 , 0.9 ) .",
    "15 tasks and 1,500 workers are used . both ( a ) and ( b ) fix matrix density at 20% .",
    "results here are simpler and easier to understand than those in rq1 : informed assignment methods consistently outperform random assignment , mf methods outperform baselines , and pmf outperforms svd .",
    "overall , increase in task similarity brings increase in ma@xmath61 ( figure  [ fig : task_similarity ] ( a ) ) .",
    "increase in matrix dimension also leads to a better performance in terms of finding strong candidates .",
    "when matrix dimension is very small ( 5,500 ) , we see some fluctuations due to spammers .",
    "[ t ]   workers mean accuracy ma@xmath39 ( left plot , bigger is better ) and rmse over all workers ( right plot , lower is better ) . task similarity is varied along the x - axis .",
    "we compare pmf vs.  the weighted average baseline.,title=\"fig:\",width=328 ]    as discussed in section  [ sec : data_gen ] , spammers can be expected to degrade predictions of worker accuracies across tasks since such workers accuracies across tasks are uncorrelated ( by definition ) . _ how robust are cross - task accuracy prediction methods to the presence of spammers ? _    figure  [ fig : random_effect ] compares the pmf vs.  the best informed baseline ( weighted average ) in the presence or absence of spammers . for the experiment , we use the fixed number of workers ( 1,500 ) and tasks(5 ) . in regard to ma@xmath39 ( left plot ) , pmf vs.  baseline results are basically equivalent with or without spammers , with pmf dominating weighted average as both trend slightly up with greater task similarity .",
    "as for rmse ( right plot ) , we also see pmf dominate the baseline across task similarity settings , with or without spammers .",
    "however , for rmse we see that with or without spammers , baseline performance is flat ( no error reduction from increasing task similarity ) , whereas pmf prediction error decreases with greater task similarity .",
    "trend lines for each method are remarkably parallel with or without spammers , with an offset of about 0.05 rmse absolute .",
    "we understand these findings as follows .",
    "to predict the top-@xmath0 workers for a given task , we focus on only the most accurate workers , which are easy to distinguish from spammers on the basis of higher accuracies on observed tasks ( training data ) . top-@xmath0 prediction therefore seems intuitively robust to spammers .",
    "rmse , on the other hand , is trying to predict accuracies of all workers , thus is inherently sensitive to spammers . nevertheless , we see pmf is still able to achieve increasing rmse reductions with greater task similarity , whereas average accuracy is not , as well as pmf dominating average accuracy for ma@xmath39 prediction as well .      whereas our experiments with synthetic data allowed us to carefully control a variety of experimental variables for detailed analysis , we also want to evaluate methods with real crowd data reflecting a specific case of actual operating conditions in which methods could be applied . with three tasks ,",
    "we fix dimensionality @xmath63 .",
    "we first consider the incomplete matrix of 443 workers who worked on all three tasks ( table  [ table : summary_real_data ] ) . due to sparsity , we do not always have training data on two other tasks to predict the third , so we can not compute average and weighted average baselines .",
    "we see pmf , svd , and random assignment achieve 0.170 , 0.170 , and .317 rmse , respectively . for ma@xmath61",
    ", they achieve 0.773 , 0.609 , and 0.381 , respectively .",
    "we see random assignment perform much worse , and pmf outperforming svd for ma@xmath61 , but not for rmse .",
    "[ t ]   of the top @xmath64 workers ( averaged across tasks ) as predicted by pmf , weighted average , and average , vs.  random assignment.,title=\"fig:\",width=245 ]    next we consider a smaller , denser matrix of the 54 workers who completed all examples for all tasks , allowing us to compute average and weighted average baselines .",
    "figure  [ fig : real_turk_ma ] shows ma@xmath39 achieved ( averaged across tasks ) by different methods ( informed pmf , weighted average , and average , vs.  uninformed random assignment ) for increasing @xmath65 .",
    "average task similarity across each pair of tasks is estimated as @xmath66 .",
    "table  [ table : summary_real_turkdata ] shows per task rmse and ma@xmath39 achieved by the same set of methods for fixed @xmath64 .",
    "overall , pmf is seen to dominate other methods except with @xmath67 , where both informed baselines perform comparably .",
    "interestingly , we do not see the weighted average offering benefit over the simple average here .",
    "we also observe that pmf and informed baselines all outperform uninformed random assignment by a wide margin , across settings .",
    "this supports our hypothesis of informed task assignment ( by any means ) being valuable over random assignment , and it is consistent with earlier findings on synthetic data .",
    "task - averaged pmf rmse in table  [ table : summary_real_turkdata ] of 0.21 appears consistent with synthetic experiments with 5 tasks , 500 workers , and @xmath66 ( figure  [ fig : task_similarity ] ( a ) ) , where pmf achieved rmse 0.23 .",
    "similarly , the trend of pmf ma@xmath39 degradation with increasing @xmath0 in figure  [ fig : real_turk_ma ] ( from roughly 0.98 to 0.86 ) appears consistent with figure  [ fig : ma_exp ] ( @xmath59 plot ) where ma@xmath39 is seen to decrease comparably ( from roughly 0.92 to 0.80 ) .",
    "task routing represents a relatively little explored and increasingly important area for future quality improvements in crowdsourcing .",
    "many interesting questions remain open , such as modeling time - varying worker accuracies , due to fatigue or training effects , in determining appropriate task routing .",
    "better ways to tackle sparse worker history data and longer term longitudinal worker studies could also be incredibly informative .",
    "we thank the anonymous reviewers for their time and feedback .",
    "this work is supported in part by darpa yfa award n66001 - 12 - 1 - 4256 , imls early career grant re-04 - 13 - 0042 - 13 , and nsf career grant 1253413 .",
    "any opinions , findings , and conclusions or recommendations expressed by the authors do not express the views of any of the supporting funding agencies ."
  ],
  "abstract_text": [
    "<S> we describe methods to predict a crowd worker s accuracy on new tasks based on his accuracy on past tasks . </S>",
    "<S> such prediction provides a foundation for identifying the best workers to route work to in order to maximize accuracy on the new task . </S>",
    "<S> our key insight is to model similarity of past tasks to the target task such that past task accuracies can be optimally integrated to predict target task accuracy . </S>",
    "<S> we describe two matrix factorization ( mf ) approaches from collaborative filtering which not only exploit such task similarity , but are known to be robust to sparse data . </S>",
    "<S> experiments on synthetic and real - world datasets provide feasibility assessment and comparative evaluation of mf approaches vs.  two baseline methods . across a range of data scales and task similarity conditions , </S>",
    "<S> we evaluate : 1 ) prediction error over all workers ; and 2 ) how well each method predicts the best workers to use for each task . </S>",
    "<S> results show the benefit of task routing over random assignment , the strength of probabilistic mf over baseline methods , and the robustness of methods under different conditions .    </S>",
    "<S> * keywords * : _ crowdsourcing , task routing , matrix factorization , task recommendation _ </S>"
  ]
}