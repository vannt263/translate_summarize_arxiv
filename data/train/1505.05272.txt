{
  "article_text": [
    "in this work we are concerned with identifiability in a particular kind of blind source separation ( bss ) motivated by different applications in digital communication ( see e.g.,@xcite ) , but also in cancer genetics ( see e.g.,@xcite ) . a prominent example is the separation of a mixture of audio or speech signals , which has been picked up by several microphones , simultaneously ( see e.g. , @xcite ) . in this case",
    "the different speech signals correspond to the sources and the recordings of the microphones to the mixture of signals with unknown mixture weights . from this mixture",
    "the individual signals have to be separated .",
    "more generally , in bss problems one observes @xmath0 mixtures of @xmath1 sources and aims to recover the original sources from the available observations . in this paper",
    "we focus on the linear case ( for the non - linear case see e.g. , @xcite ) , where the blindness refers to the fact that neither the sources nor the mixing weights are known .",
    "we also treat the case of unknown number of sources .    a minimal requirement underlying any recovery algorithm for sources and mixture weights ( in a deterministic or noisy setting ) to be valid is identifiability , i.e. , the unique decomposition of the mixture into sources and mixing weights . without any additional information on the source signals @xmath2 identifiability can not hold , of course , as from a linear system @xmath3 the matrices @xmath4 and @xmath2 are not uniquely determined , in general . in particular",
    "this applies to single linear mixtures ( @xmath5 ) .",
    "however , if we assume that the values of the sources are attained in a known finite set of real numbers ( finite alphabet ) , then bss identifiability holds under certain conditions , which is necessary for any recovery algorithm to be valid .",
    "therefore , the aim of this work is to give a comprehensive discussion of such conditions .",
    "we are able to give ( under weak assumptions ) a complete combinatorial characterization of identifiability . from this",
    "we derive sufficient conditions , which are easy to verify . moreover , these conditions yield an explicit construction to recover sources and weights in the noiseless case from the deterministic mixture . more specifically , using the notation @xmath6 for a vector @xmath7 and a matrix @xmath8 with @xmath9 rows and @xmath10 columns and @xmath11 for the corresponding row and column vectors , respectively , we assume from now on that the observed signal is linked to the sources via @xmath12 where @xmath13 is the deterministic mixture , @xmath14 are the unknown mixing weights , @xmath15 are the unknown source signals , and @xmath16 is a known alphabet , i.e. , the set of possible values the sources can attain .",
    "the row vectors @xmath17 with @xmath18 denote the single source signals ( of length @xmath19 ) and the row vectors @xmath20 with @xmath21 denote the mixing vectors ( of length @xmath1 ) of the different mixtures .    in an observational model",
    "we often have @xmath22 where @xmath23 is some random noise term with zero mean .",
    "all identifiability results for ( [ model ] ) transfer to this situation as well , of course .",
    "however , we stress that the primarily aim of this paper is not to provide a method which reconstructs the mixing weigths @xmath4 and the sources @xmath2 from the ( possibly ) noisy observations @xmath24 , but rather to clarify the scope of scenarios under which this is possible . to this end",
    ", we will analyze necessary and sufficient conditions under which the decomposition in ( [ model ] ) is unique .    for the moment",
    ", we assume that the number of sources @xmath1 is known . however , we point out that most of our results remain true even when @xmath1 is unknown ( see section [ sec : um ] ) , a case which has never been treated before to best of our knowledge .      as far as we are aware of , identifiability of model ( [ model ] ) has not yet been considered in the literature in this general form , although various special cases and variations of this bss problem have been addressed .",
    "the particular case of a binary alphabet , i.e. , when @xmath25 and @xmath26 , has been considered in @xcite .",
    "diamantaras and papadimitriou @xcite and rostami et al .",
    "@xcite assume the alphabet to be equally spaced , i.e. , @xmath27 .",
    "we consider arbitrary finite alphabets @xmath28 .",
    "moreover , several authors ( e.g.,@xcite ) assume a specific distribution on the alphabet , e.g. , uniform .",
    "our results show that it is already sufficient to observe some specific combinations of alphabet values ( which are minimal conditions in a sense ) , hence we do not need to assume such a specific distribution .",
    "diamantaras @xcite works with a general finite alphabet as well but considers a mixture of two sources , @xmath29 .",
    "@xcite gave necessary and sufficient identifiability criteria for sparse signals , i.e. , signals having many zero entries , in contrast to our work .",
    "although they consider underdetermined mixtures , their results require at least two sensors ( @xmath30 ) and do not hold for single linear mixture ( @xmath31 ) . bofill and zibulevsky @xcite",
    "suggest for @xmath32 a method for estimating the mixing weights for sparse signals as well , although without giving any explicit identifiability criteria .",
    "diamantaras @xcite considers a general finite alphabet but assumes the mixing weights to be complex .",
    "thus , he works with a 2-dimensional signal . combing the results from @xcite and @xcite yields a sufficient identifiability criterion for finite alphabet sources with complex mixing weights .",
    "however , this result does not hold when the mixing weights are real as considered here .",
    "there are further variations of the bss problem .",
    "some of them are associated with independent component analysis ( ica ) ( see e.g. , @xcite ) , which is based on the stochastic independence of the different sources ( assumed to be random ) .",
    "ica can be a powerful tool for ( over)determined models ( @xmath33 ) @xcite and there are approaches for underdetermined multiple linear mixture models ( @xmath34 ) as well @xcite . however , ica is not applicable for single linear mixtures ( @xmath31 ) , as the error terms of the single sources sum up to a single error term such that stochastic independence of the sources becomes irrelevant .",
    "also conceptually related is blind deconvolution ( see e.g. , @xcite ) , however , the convolution model makes analysis and identifiability severely different @xcite .",
    "another related problem is non - negative matrix factorization ( see e.g. , @xcite ) , where one assumes ( [ model ] ) , but instead of @xmath35 , both @xmath2 and @xmath4 are non - negative .",
    "indeed , the identifiability conditions derived in @xcite are quite related in nature to ours in section [ subsec : sc ] , where their simpliciality condition on @xmath4 corresponds to our condition ( [ emptyi ] ) and their separability condition on @xmath2 corresponds to our assumption a[assusuff ] .",
    "however , whereas their assumptions necessarily imply @xmath36 , ours yield identifiabiliy for single linear mixtures ( @xmath5 ) , explicitly exploring the finite alphabet .",
    "for the non - blind scenario , i.e. , when @xmath4 in model ( [ model ] ) is known , @xcite considers identifiability in a probabilistic framework .    to the best of our knowledge ,",
    "a comprehensive characterization and unifying treatment of identifiability of the mixing weights and the sources for model ( [ model ] ) has been elusive .",
    "this issue is , however , fundamental for identifying the scope of possible scenarios where recovery algorithms for @xmath2 and @xmath4 in ( [ model ] ) are applicable ( see , e.g. , @xcite ) . in this sense",
    "our work provides an almost `` minimal '' set of conditions under which any recovery algorithm for the bss problem only can be expected to be valid ; in the noiseless case as well as for the case with random error .",
    "we will start our analysis by making two simplifications , which lead to a better interpretation of the corresponding identifiability conditions .",
    "first , we will assume that @xmath5 , i.e. , that we observe a single linear mixture in ( [ model ] ) .",
    "clearly , when @xmath0 increases the identification problem becomes easier , as more mixtures of the same sources are observed .",
    "thus , the case @xmath5 corresponds to the most difficult scenario and therefore we treat this case in detail . generalizations to arbitrary @xmath0 will then follow easily from this case and are given in section [ sec : mlm ] .",
    "second , we start with considering probability mixing weights , i.e. , @xmath37 and @xmath38 for all @xmath39 .",
    "this is because the corresponding identifiability conditions have an easier interpretation when the mixing weights are positive .",
    "when we allow for negative mixing weights , the identifiability issue becomes slightly more difficult and the corresponding conditions become more complicated .",
    "generalizations to negative mixing weights are given in section [ sec : abw ] .",
    "the paper is organized as follows . after introducing a rigorous formulation of the problem and model ( section [ sec : probstat ] )",
    ", we will give a necessary and sufficient identifiability criterion for the mixing weights and the sources ( section [ subsec : nsc ] ) . to this end",
    ", we will first characterize the identifiability issue as a purely combinatorial problem . in sections [ subsec : sc ]",
    "we will then generalize a result from diamantaras and chassioti @xcite in order to derive a simple sufficient identifiability criterion .",
    "this characterizes those source signal combinations which make the variation of the mixture rich enough in order to become identifiable .",
    "this condition also provides an explicit construction ( see the algorithm in figure [ fig : algodetmu ] ) for recovery of the weights @xmath4 and the sources @xmath2 from the mixture @xmath13 in ( [ model ] ) .    in section",
    "[ sec : sp ] we will shortly discuss how likely it is for the identification criterion of section [ subsec : sc ] to be satisfied when the underlying sources @xmath40 are discrete markov processes . to this end",
    ", we will bound the probability of identification from below by a phase - type distribution . using a stopping time argument",
    ", we will show that the mixture becomes identifiable exponentially fast , which reveals identifiability as less a critical issue in many practical situations as one might expect .    although , we assume the number of source components @xmath1 to be known , in section [ sec : um ] we show that most of our results remain true even when @xmath1 is unknown .    in section [ sec :",
    "sim ] we simulate source signals from a two - state markov chain to illustrate how far our derived sufficient identifiability conditions ( section [ subsec : sc ] ) are from being necessary in this setting . to this end ,",
    "our results from section [ subsec : nsc ] are fundamental as they give an explicit way to decide whether a given mixture is identifiable or not .",
    "our simulation results reveal the simple sufficient condition in section [ subsec : sc ] as quite sharp as we find that the number of observations needed for this to hold is quite close to the actual number of observations required for identifiabiliy .",
    "this establishes the exponential bound in section [ sec : sp ] as a useful tool to estimate the required number of observations guaranteeing identifiability with high probability .",
    "we conclude in section [ sec : conc ] .",
    "as mentioned above , for ease of presentation , we start with analyzing identifiability in ( [ model ] ) for single linear mixtures , i.e. , @xmath5 ( for arbitrary @xmath0 see section [ sec : mlm ] ) and probability mixing weights ( for arbitrary mixing weights see section [ sec : abw ] ) . to this end , let @xmath41 denote the set of positive ( probability ) mixing vectors . note that @xmath42 for @xmath43 is always necessary to ensure identifiability of different sources @xmath44 ( if @xmath45 interchanging of @xmath46 results in the same mixture @xmath47 ) . for a given finite alphabet @xmath48 , with @xmath49 , and",
    "given @xmath50 let @xmath51 and @xmath52 .",
    "then the observed values are given by @xmath53 , i.e. , @xmath54    let @xmath55 ; @xmath56 as in ( [ modeld ] ) .",
    "then we denote the vector @xmath57 and the matrix @xmath2 as ( jointly ) identifiable from the observational vector @xmath47 when there exists exactly one @xmath58 such that @xmath59 .    in other words",
    ", identifiability means that @xmath60 in ( [ modeld ] ) implies that @xmath61 and @xmath62 . for simplicity",
    ", we refer to @xmath57 and @xmath2 being identifiable from @xmath47 just by saying that @xmath63 is identifiable .",
    "the aim of this paper is to study under which conditions @xmath64 is identifiable from @xmath47 .",
    "even though we assumes @xmath1 to be known , most of our results remain true when @xmath1 is unknown , i.e. , @xmath55 with @xmath65 ( see section [ sec : um ] ) .    to illustrate the problem and notation , let us start with a simple example of model ( [ modeld ] ) , where @xmath66 and the alphabet is binary with @xmath67 .",
    "this means that we consider mixing vectors of the form @xmath68 with @xmath69 , @xmath70 and two different sources @xmath71 , @xmath72 with @xmath73 for @xmath74 and @xmath75 .",
    "the question we would like to answer is , under which conditions on @xmath57 and @xmath2 is @xmath63 uniquely determined via @xmath55 .    for a given observation @xmath76 the underlying source vector @xmath77 equals one of the four different values @xmath78 and hence , @xmath79 clearly , if any two of the four values in the set on the r.h.s . of ( [ exampleeq2 ] )",
    "coincide , then two different source values in ( [ exampleeq1 ] ) lead to the same mixture value for @xmath76 and hence the sources are not identifiable , i.e. , they can not be distinguished .",
    "consequently , a necessary condition for identifiability is that all values in the r.h.s . of ( [ exampleeq2 ] )",
    "are different , which is equivalent to @xmath80 in other words , it is necessary that the alphabet values in @xmath81 are well separated via the mixing weights @xmath82 . a generalization of this argument to arbitrary alphabets and number of sources",
    "is done later in ( [ emptyi ] ) .",
    "further , we may assume w.l.o.g .",
    "@xmath83 , i.e. , we denote that source as @xmath84 which comes with the smaller weight .",
    "( [ exampleeq3 ] ) alone , however , is necessary but not sufficient for identifiability .",
    "for instance , if @xmath85 for all @xmath75 then @xmath86 and hence , @xmath57 is not identifiable from @xmath47 .",
    "thus , a certain variability of the two sources @xmath87 and @xmath88 is necessary to guarantee identifiability of @xmath57 . in this simple example",
    ", it is easy to check that a necessary and sufficient variability of @xmath87 and @xmath88 is that @xmath2 either takes the value @xmath89 ( i.e. , @xmath90 for some @xmath91 ) or @xmath92 ( i.e. , @xmath93 for some @xmath91 ) as by ( [ exampleeq3 ] ) and @xmath70 it follows that @xmath94 . in other words , it is necessary that the mixing weight @xmath95 ( or @xmath96 respectively ) is seen somewhere in the mixture @xmath47 on its own , without the influence of the other mixing weight",
    ". a generalization of these assumptions and this argument to general systems ( [ model ] ) is done later in theorem [ theoalgo ] and theorem [ theoalgoabw ] , respectively .",
    "in model ( [ modeld ] ) every observation @xmath76 , for @xmath97 , is given by a linear combination of @xmath98 ( unknown ) with one of the finitely many vectors in @xmath81 .",
    "so in order to identify @xmath99 , we have to determine the corresponding vector in @xmath81 .",
    "note that multiple observed values leave this identification problem invariant , i.e. , do not contribute further to identifiability .",
    "hence , w.l.o.g . we assume all observations @xmath100 to be pairwise different .",
    "note , that this implies @xmath101 .",
    "of course , when for a given mixing vector @xmath98 there exist @xmath102 with @xmath103 and one observes this value , it is not possible to identify the underlying sources @xmath40 uniquely .",
    "consequently , a necessary condition for identifiability is that those values are not observed , i.e. , @xmath104 for all @xmath97 . for arbitrary sources this",
    "is comprised in the condition of a positive _ alphabet separation boundary _",
    ", i.e. , @xmath105    let @xmath106 be the collection of injective maps from @xmath107 to @xmath108 , i.e. , for @xmath109 the vector @xmath110 corresponds to a selection of elements from @xmath111 .",
    "[ theoid ] assume model ( [ modeld ] ) with @xmath112 @xmath113 .",
    "let @xmath114 be an arbitrary invertible @xmath115 matrix with elements in @xmath116 .",
    "assume that @xmath117 and    [ asstheoid ] there exists @xmath109 such that @xmath118 .",
    "then @xmath63 is identifiable if and only if    [ condit ] there exists exactly one @xmath119 such that for @xmath120 @xmath121 i.e. , @xmath122 is a valid mixing weight and can reproduce all observations .    for a proof see appendix [ app : a ] .",
    "theorem [ theoid ] is fundamental for the following as a[condit ] provides a necessary and sufficient condition for identifiability of @xmath64 , given a[asstheoid ] holds . in section [ subsec : sc ]",
    ", it will serve to derive a simple sufficient identifiability condition which is easy to check . in the following",
    ", we will discuss condition a[asstheoid ] and a[condit ] more detailed .",
    "first , we consider assumption a[asstheoid ] . without further restrictions on the matrix @xmath123 , a[asstheoid ]",
    "simplifies to @xmath124 ( in particular implying @xmath125 ) , which is , indeed , an almost minimal condition . by simple linear algebra , it is easy to check that @xmath126 implies that for any @xmath98 exists an @xmath127 such that @xmath128 , i.e. , @xmath64 is not identifiable .",
    "when we allow for arbitrary mixing weights ( see section [ sec : abw ] ) , i.e. , not necessarily summing up to one , then by the same argument @xmath124 becomes even a necessary condition .",
    "intuitively , a[asstheoid ] ensures that the sources @xmath129 differ sufficiently such that one can identify @xmath57 from their mixture .",
    "for instance , if @xmath130 , it follows that @xmath131 , irrespective of @xmath57 .",
    "note that if @xmath132 different values @xmath133 are observed , i.e. , @xmath134 ( recall that w.l.o.g . in this section",
    "@xmath19 equals the number of pairwise different @xmath76 s ) , then it must hold true that @xmath135 .",
    "thus , a[asstheoid ] follows trivially for any invertible @xmath115 matrix @xmath123 with elements in @xmath116 . however , a[asstheoid ] is a much weaker assumption than @xmath134 .",
    "second , we comment on assumption a[condit ] . given a[asstheoid ]",
    ", assumption a[condit ] reveals @xmath57 as identifiable as soon as we can assign a collection of observations to rows in @xmath123 in a unique way .",
    "when @xmath57 is determined , identifiability of @xmath2 follows from @xmath136 . for a[condit ] to check , we need to assume a fixed , given @xmath123 which depends on @xmath137 in a[asstheoid ] .",
    "however , @xmath137 does not need to be known , in order to be able to verify condition a[condit ] , i.e. , one does not need to know which observations correspond to rows in @xmath123 . in practice , the choice of @xmath123 will depend on the specific application and different choices of @xmath123 lead to different identifiability conditions a[condit ] . in section [ subsec : sc ]",
    "we will show that for some specific choices of @xmath123 a[condit ] always holds , i.e. , a[asstheoid ] already implies identifiabiliy .",
    "the following example shows that this is not true in general , i.e. , not for any choice of @xmath123 .",
    "[ gsi ] with the notation of ( [ modeld ] ) and theorem [ theoid ] , let @xmath138 , @xmath139 , @xmath140 , and @xmath141 i.e. , @xmath137 in a[asstheoid ] is the identity map and @xmath142    for @xmath143 we find that @xmath144 which is a valid mixing weight .",
    "hence , @xmath64 is not identifiable .",
    "as mentioned before , in section [ subsec : sc ] we will show that some specific choices of @xmath123 already lead to uniqueness of the selection @xmath145 in a[condit ] , and thus ensure identifiability .",
    "the following remark illustrates how specific choices of rows in @xmath123 fix some subdomain of @xmath145 in a[condit ] .",
    "[ remark1 ] if @xmath134 with @xmath146 , then @xmath147 , the smallest observed value , corresponds to the situation when all sources @xmath148 take the smallest value of the alphabet ( denoted with @xmath149 ) , i.e. , if @xmath150 , then for all @xmath145 satisfying a[condit ] @xmath151 .",
    "the second smallest observed value , @xmath152 , corresponds to the situation when all sources @xmath153 take the smallest value @xmath149 , but the source @xmath154 with the smallest weight @xmath95 takes the second smallest value @xmath155 , i.e. , if @xmath156 , then for all @xmath145 satisfying a[condit ] @xmath157 .",
    "analogous holds for the largest observed value and the second largest observed value .",
    "we have seen in theorem [ theoid ] that the problem of identifying @xmath57 and @xmath2 from the observations @xmath100 reduces to identify the corresponding vectors @xmath158 for sufficiently many observations @xmath76 .",
    "namely , one has to find the corresponding observations @xmath76 for @xmath1 linear independent rows of an invertible @xmath115 matrix @xmath123 with elements in @xmath116 .",
    "remark [ remark1 ] points out that some observations @xmath76 can always be uniquely assigned to source vectors @xmath158 and thus , limit the possible maps @xmath145 in a[condit ] .",
    "the next theorem shows that there is even more structure in the observations @xmath100 and that certain variations in the sources , i.e. , certain choices of @xmath123 in a[asstheoid ] , already ensure identifiability .",
    "moreover , the proof of the following theorem gives an explicit construction of the unique @xmath64 from @xmath47 .",
    "[ theoalgo ] assume model ( [ modeld ] ) with @xmath112 @xmath113 . furthermore , assume that @xmath136 and    [ assusuff ] there exists @xmath109 such that @xmath159 with @xmath160 .",
    "then @xmath63 is identifiable .",
    "before we give a proof ( which is based on an explicit algorithm to compute @xmath57 from @xmath100 ) we will discuss relationships and differences between the previous results and their assumptions a[asstheoid ] - a[assusuff ] .",
    "assumption a[assusuff ] of theorem [ theoalgo ] has a simple interpretation .",
    "it means that each of the mixing weights @xmath161 appears somewhere in the mixture on its own ( without the influence of any other mixing weight @xmath162 ) via the mixture value @xmath163 .",
    "for instance , if the alphabet is of the form @xmath164 a[assusuff ] simplifies to the condition that the mixing weights appear somewhere in the mixture , i.e. , @xmath165 for all @xmath166 .",
    "intuitively , a[assusuff ] means that for each @xmath166 there exists one mixture observation @xmath76 such that only @xmath167 is active ( taking the value @xmath155 ) and all other sources @xmath168 with @xmath169 are silent ( taking the value @xmath155 ) .",
    "it is easy to check that the choice of alphabet values @xmath149 and @xmath155 ( the smallest and second smallest alphabet value ) in theorem [ theoalgo ] can be replaced by @xmath170 and @xmath171 ( the largest and second largest alphabet value ) .",
    "obviously , assumption a[assusuff ] arises from assumption a[asstheoid ] for a specific choice of @xmath123 in theorem [ theoid ] , namely with @xmath172 consequently , if the matrix in ( [ famatrix ] ) is invertible , a[assusuff ] implies a[asstheoid ] .",
    "the following lemma shows that this holds under mild conditions on @xmath116 and @xmath1 .",
    "[ aa ] for model ( [ modeld ] ) let a[assusuff ] be as in theorem [ theoalgo ] and a[asstheoid ] as in theorem [ theoid ] .",
    "+ if @xmath173 , then a[assusuff ] implies a[asstheoid ] .    for a proof see appendix [ app : b ]",
    "figure [ arelation ] summarizes all relations between a[asstheoid ] - a[assusuff ] in a diagram .",
    "\\(m ) [ matrix of math nodes , row sep=1em , column sep=1em , minimum width=1em ] & & & & & a3 + & & & & & + & & & & & + & & & & & + a1 & & & ( a2 & & ) + ; ( m-1 - 6 ) edge [ double ] node[sloped , midway , above ] ( m-5 - 1 ) ( m-1 - 6 ) edge [ double ] node[sloped , midway , above ] ( m-5 - 6 ) ( m-5 - 1 ) edge [ double ] node[sloped , midway , below ] ( m-5 - 4 ) ;    now we turn to the proof of theorem [ theoalgo ] , which is proven by explicit recovery of @xmath64 .",
    "this generalizes an algorithm of diamantaras and chassiot @xcite for the binary alphabet @xmath174 to a general finite alphabet .",
    "assumption a[assusuff ] implies that @xmath175 and hence , @xmath176 thus , it suffices to determine the map @xmath137 and the values @xmath177 , respectively , in order to determine @xmath57 .",
    "when @xmath57 is determined , identifiability of @xmath2 follows from @xmath136 .",
    "recall remark [ remark1 ] and note that @xmath178 which determines @xmath95 as in ( [ remarkomega ] ) .",
    "the following two lemmas show that successively all the other @xmath179 ( and hence @xmath180 ) for @xmath181 can be determined as well , which finishes the proof .",
    "let @xmath182 be the @xmath183-matrix , where the @xmath184th column of @xmath185 is the number @xmath186 written in the positional notation based on the number @xmath187 , identifying @xmath188 with @xmath149 , @xmath189 with @xmath155 , and so on , i.e. ,    @xmath190    and @xmath191 the @xmath132 dimensional vector of all possible values that @xmath47 can take .",
    "[ lemmad ] from @xmath192 one can determine @xmath193 uniquely .",
    "[ lemmacr ] it holds that @xmath194 .    for proofs",
    "see appendix [ app : bb ] and [ app : c ] , respectively .",
    "@xmath100 @xmath195 @xmath196 @xmath197 @xmath198 determine @xmath199 with lemma [ lemmad ] ( using @xmath200 ) .",
    "@xmath201 @xmath202 @xmath203 @xmath204 determine @xmath193 with lemma [ lemmad ] ( using @xmath192 ) .",
    "@xmath205 @xmath206 + @xmath1 and @xmath207    the proof of theorem [ theoalgo ] gives an explicit recovery construction for @xmath64 which is summarized in figure [ fig : algodetmu ] . for noisy data one may use algorithm [ fig : algodetmu ] to proceed similar as diamantaras and chassiot @xcite who suggest a clustering approach for estimating @xmath57 and @xmath2 from noisy observations of @xmath47 .",
    "however , as the purpose of this paper is not to propose a practical method for recovery from noisy data , but rather to analyze the scope of scenarios under which this is possible in principle , we are not going to follow this approach here further .",
    "in this subsection we will shortly discuss how likely it is for the identifiability condition of theorem [ theoalgo ] to be satisfied when @xmath208 is a stochastic process .",
    "therefore , let @xmath209 be as in theorem [ theoalgo ] , and define the hitting times @xmath210 for @xmath211 , and the stopping time @xmath212 then it follows from theorem [ theoalgo ] that @xmath213 note that this bound only depends on the distributions of the hitting times @xmath214 , which are often explicitly known or good estimates exist",
    ". a prominent class of examples for modeling the distribution of the source signals are markov processes including iid sequences ( see e.g. , @xcite ) .",
    "[ theoexp ] assume that the source signals @xmath208 in ( [ modeld ] ) constitute an irreducible markov process on the finite state space @xmath81 , with transition matrix @xmath215 , where we identify the first @xmath1 states of @xmath81 with @xmath216 from theorem [ theoalgo ] .",
    "let @xmath217 be such that @xmath218 and @xmath219 then @xmath220 and , if @xmath136 , @xmath221    for a proof see appendix [ app : e ] .",
    "bernoulli model[exb ] let us consider ( [ modeld ] ) for the simple case where we have two sources @xmath84 and @xmath222 that can take two different values , i.e. , @xmath223 .",
    "for instance , the source signals could come from a binary antipodal alphabet ( @xmath224 ) as they appear in many digital modulated schemes .",
    "if we assume that @xmath154 and @xmath225 are independent and identically distributed ( i.i.d . ) for all @xmath226 with @xmath227 and @xmath228 for @xmath74 and @xmath75 , then @xmath229 constitutes an irreducible markov process on the state space @xmath230 with transition matrix @xmath231 hence , @xmath232 , @xmath233 and @xmath234 .",
    "thus , theorem [ theoexp ] yields @xmath235 in this simple setting we can even calculate the probability of identifiabiliy exactly .",
    "note that @xmath63 is identifiable if and only if @xmath236 or @xmath237 is observed as @xmath238 and @xmath239 therefore , @xmath240    example [ exb ] shows that the bound in theorem [ theoexp ] does not need to be sharp in general but captures the exponential decay ( in @xmath19 ) well .",
    "this is mainly because in theorem [ theoexp ] the probability of @xmath64 being identifiable is bounded using the sufficient ( and not necessary ) identifiabiliy condition a[assusuff ] from theorem [ theoalgo ] . in section [ sec : sim ] the gap between this bound and the true probability @xmath241 in ( [ piexpb ] ) is further explored in a simulation study .",
    "after analyzing the most difficult scenario of a single linear mixture with @xmath5 in ( [ model ] ) , generalizations to arbitrary number of mixtures @xmath0 now follow easily . to this end , for a vector @xmath242 let @xmath243 denote the @xmath244-norm and define the set of @xmath0-mixtures as @xmath245 again , note that @xmath246 for @xmath43 is necessary to ensure identifiability of different sources . then for @xmath247 and @xmath248 the observed values are given by @xmath3 , i.e. , @xmath249 identifiability means to decompose the matrix @xmath250 uniquely into matrices @xmath251 and @xmath35 for given finite alphabet @xmath252 with @xmath253 and given @xmath254 .",
    "analog to before we define the alphabet separation boundary of a mixture matrix @xmath248 as @xmath255 clearly , @xmath256 is a necessary condition on @xmath4 for @xmath257 to be identifiable .",
    "theorem [ theoid ] , theorem [ theoalgo ] , and theorem [ theoexp ] assume that @xmath31 .",
    "it is straight forward to check that theorem [ theoid ] holds unchanged when @xmath36 with @xmath258 replaced by @xmath259 .",
    "the same is true for theorem [ theoalgo ] , where in the proof the minimum of a set of observations @xmath260 must be replaces by the minimum defined in terms of the ordering of @xmath261 .",
    "thus , clearly theorem [ theoexp ] also holds unchanged when @xmath36 .",
    "so far , we assumed the mixing weights to be positive and to sum up to one .",
    "however , in some applications this assumption is not satisfied ( e.g. , in digital communications @xcite ) and in the following we discuss such generalizations .",
    "let @xmath262 be an arbitrary subset of mixing weights @xmath263 .",
    "note that w.l.o.g .",
    "@xmath264 in order to assign the mixing weight to a source .",
    "it is easy to check that theorem [ theoid ] holds unchanged with @xmath258 replaced by @xmath265 .",
    "note , however , that if @xmath266 condition a[condit ] becomes more restrictive , i.e. , a mixture @xmath64 which is identifiable with respect to @xmath258 might not be identifiable with respect to @xmath265 .",
    "analogously , theorem [ theoalgo ] can be generalized for @xmath266 , where now the corresponding identifiabiliy assumption a[assusuff ] becomes more restrictive .",
    "the following theorem considers the most general case of arbitrary mixing weights in @xmath267 .",
    "[ theoalgoabw ] assume model ( [ modeld ] ) @xmath55 with @xmath268 .",
    "furthermore , assume that @xmath136 and there exists @xmath269 such that @xmath270 with @xmath271 for @xmath272 defined as @xmath273 for @xmath274 and @xmath275 .",
    "then @xmath63 is identifiable .",
    "the proof of theorem [ theoalgoabw ] is given in appendix [ sec : appthealgoabw ] .",
    "recall that for positive mixing weights the identifiability condition a[assusuff ] in theorem [ theoalgo ] had a very simple interpretation , namely that each of the sinlge mixing weights @xmath161 appears somewhere in the mixture @xmath47 on its own , without the influence of any of the other mixing weights @xmath276 for @xmath169 .",
    "the interpretation of ( [ assusuffabw ] ) is somewhat more difficult , but similar . in the case of probability mixing weights @xmath98 as in theorem [ theoalgo ] both , the sum and the absolute sum of the mixing weights were fixed via @xmath277 and this determined the scaling in which the mixing weights appear in the mixture @xmath47 .",
    "now for general mixing weights @xmath278 as in theorem [ theoalgoabw ] both , the sum and the absolute sum ( or equivalently the sum of the negative mixing weights and the sum of the positive mixing weights ) are unknown and thus , additional conditions to determined these unknown scaling parameters are needed .",
    "these correspond to @xmath279 and @xmath280 .",
    "they ensure that the smallest possible mixture value ( which corresponds to @xmath279 ) and the largest possible mixture value ( which corresponds to @xmath280 ) are observed and thus determine the scaling parameters .",
    "now analog to @xmath281 in a[assusuff ] of theorem [ theoalgo ] , @xmath281 and @xmath282 in ( [ assusuffabw ] ) of theorem [ theoalgoabw ] ensure that @xmath161 appears somewhere in the mixture @xmath47 on its own and can thus be determined . however , as the sign of @xmath161 is now unknown , too , we get the additional unambiguity that a mixture value can be increased either by increasing a source which corresponds to a positive mixing weight or by decreasing a source which corresponds to a negative mixing weight .    from theorem [ theoalgoabw ]",
    "it follows directly that theorem [ theoexp ] holds with @xmath1 replaced by @xmath283 , when we allow for arbitrary mixing weights in @xmath267 .",
    "so far , we assumed that the number of sources @xmath1 is fixed and known .",
    "now we consider the case where @xmath1 is unknown , i.e. @xmath55 with @xmath284 while it is not clear how to generalize theorem [ theoid ] for @xmath63 as in ( [ ddmum ] ) , condition a[assusuff ] in theorem [ theoalgo ] is still sufficient for identifiability when @xmath1 is unknown .    to see this , note that the proof of theorem [ theoalgo ] ( in particular lemma [ lemmad ] ) does not require the number of sources @xmath1 to be known , where @xmath1 is determined via @xmath285 and thus , we obtain the following theorem .",
    "[ cor : idm ] assume model ( [ modeld ] ) with @xmath112 @xmath286 .",
    "furthermore , assume that @xmath136 and a[assusuff ] holds .",
    "then @xmath63 ( and thus @xmath1 ) is identifiable .",
    "analogously , theorem [ theoexp ] and theorem [ theoalgoabw ] do not require @xmath1 to be known .",
    "finally , we explore in a simulation study how far assumption a[assusuff ] from theorem [ theoalgo ] is from being necessary when the sources come from an irreducible markov process ; which corresponds to exploring the tightness of the bound in theorem [ theoexp ] . to this end ,",
    "theorem [ theoid ] is fundamental as it enables us to explicitly examine identifiabilty of @xmath64 .",
    "we consider an example with a binary alphabet @xmath287 and a mixture of @xmath288 sources .",
    "the matrix @xmath123 in theorem [ theoid ] was chosen randomly over the set of invertible @xmath115 matrices with elements in @xmath116 .",
    "simulation runs were always @xmath289 .",
    "first , we assume the mixing weights @xmath290 .",
    "note that @xmath291 for all @xmath292 , i.e. , @xmath136 .      assuming the sources to be i.i.d . for all @xmath293 and @xmath75",
    ", with @xmath294 we find that @xmath63 is already identifiable on average for @xmath295 observations .",
    "for the sufficient identifiability condition from theorem [ theoalgo ] to hold we find an average value of @xmath296 observations .",
    "figure [ fig : id_hist ] shows the corresponding histograms and cumulative distribution functions .",
    "the results indicate that the number of observations needed for the sufficient identifiability condition a[assusuff ] from theorem [ theoalgo ] to be satisfied is not considerably higher then the actual number of observations until @xmath63 is identifiable and thus the bound in theorem [ theoexp ] is quite sharp in this example .",
    "is identifiable ( left ) and until the sufficient identifiability condition from theorem [ theoalgo ] is fulfilled ( right ) , bottom row : corresponding empirical cumulative distribution function , with @xmath288 , @xmath287 , @xmath290 and @xmath167 i.i.d . on @xmath116 . ]",
    "we consider a more general markov model for generating the sources , i.e. , we assume the sources to be independent markov processes on the state space @xmath287 with transition matrix @xmath297 in figure [ fig : id_markov ] we display the average numbers of observations until @xmath64 is identifiable and until the sufficient identifiability condition a[assusuff ] from theorem [ theoalgo ] is fulfilled , respectively , for each @xmath298 . note that @xmath299 corresponds to i.i.d .",
    "observations , with @xmath300 .     is identifiable ( left ) and until the sufficient identifiability condition from theorem [ theoalgo ] is fulfilled ( right ) in dependence of @xmath301 and @xmath302 from ( [ transm ] ) . ]    from figure [ fig : id_markov ] we draw that identifiability is achieved faster when @xmath301 and @xmath302 are close to @xmath303 , which corresponds to the i.i.d .",
    "bernoulli model from section [ subsec : simb ] .",
    "this is explained by condition a[condit ] in theorem [ theoid ] , where a richer variation in the sources , i.e. , many different observations @xmath304 , reduces the set of possible valid mixing weights and thus favor identifiability .",
    "the sufficient identifiability condition a[assusuff ] from theorem [ theoalgo ] , however , requires repeated occurrence of the smallest alphabet values @xmath149 .",
    "consequently , small @xmath301 and large @xmath302 discriminate against those variations .",
    "now , we consider multiple linear mixtures , i.e. , @xmath36 . therefore , for each run , we draw @xmath0 mixing weights , each of length @xmath288 , independently from the uniform distribution on @xmath258 ( implying @xmath136 ) . for the sources ,",
    "we consider a bernoulli model as in section [ subsec : simb ] .",
    "we find that @xmath63 is identifiable on average after @xmath305 for @xmath306 observations , revealing that identifiability ( condition a[condit ] in theorem [ theoid ] ) depends much more on the variability of the sources than on the specific mixing weights .",
    "this is confirmed in figure [ fig : id_hist_mlm ] , which shows the corresponding histograms and cumulative distribution functions .",
    "the histograms and cumulative distribution functions for @xmath5 and @xmath307 differ only slightly and for @xmath31 they look almost the same as in figure [ fig : id_hist ] , although in figure [ fig : id_hist ] @xmath57 is fixed , whereas in figure [ fig : id_hist_mlm ] it is random . for the sufficient identifiability condition from theorem [ theoalgo ] to hold we find an average value of @xmath308 observations .",
    "note that this condition depends on the sources only and , thus , is the same for all @xmath0 .",
    "is identifiable ( left ) and until the sufficient identifiability condition a[assusuff ] from theorem [ theoalgo ] is fulfilled ( right ) , bottom row : corresponding empirical cumulative distribution function , with @xmath288 , @xmath287 , @xmath57 uniformly distributed on @xmath258 and @xmath167 i.i.d . on @xmath116 . ]",
    "is identifiable ( left ) and until the sufficient identifiability condition from theorem [ theoalgo ] is fulfilled ( right ) , bottom row : corresponding empirical cumulative distribution function , with @xmath288 , @xmath287 , @xmath57 uniformly distributed on @xmath309^{{\\ensuremath { n } } } : { { \\ensuremath { a}}}_1 < \\ldots < { { \\ensuremath { a}}}_{{\\ensuremath { n}}}\\}$ ] and @xmath167 i.i.d . on @xmath116 . ]    finally , we consider arbitrary mixing weights in @xmath267 . therefore , for each run , we draw mixing weights ( @xmath5 , @xmath288 ) independently from the uniform distribution on @xmath309^{{\\ensuremath { n } } } : { { \\ensuremath { a}}}_1 < \\ldots < { { \\ensuremath { a}}}_{{\\ensuremath { n}}}\\}$ ] and for the sources we consider a bernoulli model as in section [ subsec : simb ] .    we find that @xmath63 is identifiable on average after @xmath310 observations . confirming , that identifiability , i.e. , condition a[condit ] in theorem [ theoid ] , is achieved slower , when we allow for larger sets of possible mixing weights . for the sufficient identifiability condition from theorem [ theoalgoabw ] to hold we find an average value of @xmath311 observations .",
    "figure [ fig : id_hist_aw ] shows the corresponding histograms and cumulative distribution functions .    in summary ,",
    "our simulations show that the number of observations needed for our simple sufficient identifiability condition a[assusuff ] to hold is relatively close to the actual number of observations until @xmath64 is identifiable and thus , serves as a good benchmark criterion for identifiability",
    ". this can be used as a simple proxy for validating the applicability of any recovery procedure in practice .",
    "in this paper we have established identifiability criteria for single linear mixtures of finite alphabet sources as well as its matrix analogue . we gave not only sufficient but also necessary criteria for identifiability .",
    "our work reveals the identification problem as a combinatorial problem utilizing the one to one correspondence between the mixture values and the mixing weights .",
    "we generalized the method of diamantaras and chassioti @xcite to an arbitrary finite alphabet in order to derive a simple sufficient identifiability criterion .",
    "the proof uses the specific hierarchical structure of possible mixture values leading to successive identification of the weights .",
    "thus , our results characterize and extend the range of settings under which recovery algorithms ( for statistical data ) are applicable .",
    "notably , we showed that our identifiability conditions extend to unknown number of sources @xmath1 .",
    "this lays the foundation to design algorithms to recover the number of active sources from a mixture and sketches a road map to pursue this in future research .",
    "finally , we showed that the probability of identifiability converges exponentially fast to @xmath189 when the underlying sources come from a discrete markov process .",
    "this provides a useful and simple tool to pre - determine the required number of observations in order to guarantee identifiability at a given probability .",
    "the derived sufficient identifiability conditions were briefly investigated in a simulation study and the required sample size for their validity was found to be quite close to the minimal sample size for identifiability .    this work is intended to give a solid theoretical background for a model that is used in a variety of applications in digital communications , but also in bioinformatics .",
    "+ for @xmath312 we define @xmath313 .",
    "`` @xmath314 '' + by assumption a[asstheoid ] @xmath315 , i.e. , @xmath316 and , consequently , @xmath317 which , by assumption a[condit ] , is not fulfilled for any other @xmath119 .",
    "thus , @xmath57 is uniquely determined . moreover , as @xmath136 , @xmath2 is uniquely determined as well .",
    "+ `` @xmath318 '' + assume a[condit ] does not hold , i.e. , there exists @xmath319 such that @xmath320 fulfills @xmath321 as we assume all observations to be pairwise different , @xmath322 and @xmath122 with the corresponding @xmath323 lead to the same observations @xmath100 . therefore , @xmath63 is not identifiable .",
    "obviously , a[assusuff ] arises from a[asstheoid ] when we choose the matrix @xmath123 in theorem [ theoid ] as in ( [ famatrix ] ) .",
    "hence , a[assusuff ] implies a[asstheoid ] if the matrix in ( [ famatrix ] ) is invertible .",
    "( [ famatrix ] ) can be written as @xmath324 and consequently , the matrix in ( [ famatrix ] ) has zero determinant if and only if @xmath325 is an eigenvalue of @xmath326 i.e. , @xmath327 or @xmath328 . as @xmath329 the assertion follows .",
    "for @xmath330 the assertion is obvious .",
    "so let @xmath331 .",
    "then for @xmath332 we have that @xmath333 where @xmath334 are the entries of the matrix @xmath185 in ( [ bmatrix ] ) .      by definition @xmath335 .",
    "therefore , @xmath336 and for @xmath337 @xmath338 if @xmath339 , then obviously @xmath340 .",
    "if @xmath341 , then by definition of @xmath185 there exists an @xmath342 such that @xmath343 , and therefore , @xmath344 consequently , @xmath345 .",
    "let @xmath214 be as in ( [ tr ] ) and let @xmath346 be the initial distribution of @xmath347 .",
    "define the stopped process @xmath348 for @xmath349 , which is a markov process as well ( see e.g. , ( * ? ? ?",
    "* proposition 4.11.1 . ) ) .",
    "it is obvious that for the markov process @xmath350 the state @xmath209 is absorbing and all other states are transient .",
    "moreover , when we reorder the states in @xmath81 such that @xmath209 is the first state , the transition matrix of @xmath350 is given by @xmath351 the distribution of @xmath214 is a discrete phase type distribution ( see e.g. , ( * ? ? ?",
    "* section 2.2 . ) ) , i.e. , @xmath352    as @xmath218 @xmath353 with @xmath354 for @xmath355 .",
    "consequently , all row sums of @xmath356 are smaller than @xmath189 , i.e. , @xmath357 and hence @xmath358 .",
    "next , we show by induction that @xmath359 for all @xmath360 . for @xmath361",
    "this holds by definition .",
    "so assume that @xmath362 for all @xmath363 and define @xmath364 , i.e. , @xmath365 if @xmath366 , then @xmath367 as @xmath368 and @xmath369 .    if @xmath370 , then @xmath371 and @xmath372 , with @xmath373 .",
    "therefore , @xmath374 with ( [ tq ] ) and ( [ poi ] ) it follows that @xmath375 and as @xmath376 the assertion follows .",
    "assume that @xmath377 .",
    "otherwise , we can multiply all observations by @xmath378 , such that the new alphabet becomes @xmath379 , which then fulfills @xmath377 . further , note that @xmath136 implies that @xmath380 for all @xmath381 .",
    "let @xmath382 be the set of the pairwise different observations .",
    "( [ assusuffabw ] ) implies that there exist @xmath383 such that @xmath384 and @xmath385 for @xmath386 .",
    "first , note that @xmath387 and thus @xmath388 if @xmath389 , all weights are positive and , as @xmath390 is identified and thus w.l.o.g equal to one , theorem [ theoalgo ] applies .",
    "thus , assume that @xmath391 and define @xmath392 and @xmath393 i.e. , @xmath394 .",
    "second , note that analog to ( [ remarkc1 ] ) @xmath395 and thus @xmath396 hence , if @xmath397 we find that @xmath398 and if @xmath399 that @xmath400 thus , we have identified the first weight , namely @xmath401 now assume that we have identified @xmath402 different weights , @xmath403 .",
    "if @xmath404 , all the remaining weights are positive and theorem [ theoalgo ] applies .",
    "thus assume that @xmath405 and define @xmath406 , with @xmath407 and @xmath408 note that analog to lemma [ lemmacr ] @xmath409 and thus @xmath410 hence , if @xmath411 we find that @xmath412 and if @xmath413 that @xmath414 thus , we have identified the @xmath415-th weight as @xmath416 by induction , we can identify all weights and thus , by @xmath417 the assertion follows .",
    "the authors acknowledge support of dfg crc 803 , 755 , rtg 2088 , and for 916 .",
    "helpful comments of an editor , two referees , c. holmes , p. rigollet , and h. sieling are gratefully acknowledged .",
    "s.  l. carter , k.  cibulskis , e.  helman , a.  mckenna , h.  shen , t.  zack , p.  w. laird , r.  c. onofrio , w.  winckler , b.  a. weir _",
    "et  al . _ , `` absolute quantification of somatic dna alterations in human cancer , '' _ nature biotechnology _ , vol .  30 , no .  5 , pp . 413421 , 2012 .",
    "b.  liu , c.  d. morrison , c.  s. johnson , d.  l. trump , m.  qin , j.  c. conroy , j.  wang , and s.  liu , `` computational methods for detecting copy number variations in cancer genome using next generation sequencing : principles and challenges , '' _ oncotarget _ , vol .  4 , no .",
    "11 , p. 1868 , 2013 .    a.  assa - el - bey , k.  abed - meraim , and y.  grenier , `` underdetermined blind audio source separation using modal decomposition , '' _ eurasip journal on audio , speech , and music processing _ , vol .",
    "2007 , no .  1 ,",
    "pp . 1414 , 2007 .",
    "m.  castella , `` inversion of polynomial systems and separation of nonlinear mixtures of finite - alphabet sources , '' vol .",
    "56 , no .  8 , pp . 39053917 .",
    "[ online ] .",
    "available : http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4567638    g.  ha , a.  roth , j.  khattra , j.  ho , d.  yap , l.  m. prentice , n.  melnyk , a.  mcpherson , a.  bashashati , e.  laks _ et  al .",
    "_ , `` titan : inference of copy number architectures in clonal cell populations from tumor whole - genome sequence data , '' _ genome research _ , vol .",
    "24 , no .  11 , pp . 18811893 , 2014 .",
    "c.  yau , o.  papaspiliopoulos , g.  o. roberts , and c.  holmes , `` bayesian non - parametric hidden markov models with applications in genomics , '' _ journal of the royal statistical society : series b ( statistical methodology ) _ , vol .",
    "73 , no .  1 , pp . 3757 , 2011 .",
    "s.  talwar , m.  viberg , and a.  paulraj , `` blind separation of synchronous co - channel digital signals using an antenna array .",
    "_ i. algorithms _",
    ", '' _ ieee transactions on signal processing _ , vol .",
    "44 , no .  5 , pp . 11841197 , 1996 .",
    "k.  diamantaras and e.  chassioti , `` blind separation of n binary sources from one observation : a deterministic approach , '' _ international workshop on independent component analysis and blind signal separation _ , pp . 9398 , 2000 .",
    "f.  gu , h.  zhang , n.  li , and w.  lu , `` blind separation of multiple sequences from a single linear mixture using finite alphabet , '' _ international conference on wireless communications and signal processing _ , pp . 15 , 2010 .",
    "m.  rostami , m.  babaie - zadeh , s.  samadi , and c.  jutten , `` blind source separation of discrete finite alphabet sources using a single mixture , '' _ ieee statistical signal processing workshop ( ssp ) _ , pp . 709712 , 2011 .",
    "y.  li , s .-",
    "amari , a.  cichocki , d.  w. ho , and s.  xie , `` underdetermined blind source separation based on sparse representation , '' _ ieee transactions on signal processing _",
    "54 , no .  2 ,",
    "423437 , 2006 .",
    "lee , m.  s. lewicki , m.  girolami , and t.  j. sejnowski , `` blind source separation of more sources than mixtures using overcomplete representations , '' _ ieee signal processing letters _ , vol .  6 , no .  4 , pp .",
    "8790 , 1999 .",
    "k.  diamantaras and t.  papadimitriou , `` blind deconvolution of multi - input single - output systems using the distribution of point distances , '' _ journal of signal processing systems _ , vol .",
    "65 , no .  3 , pp .",
    "525534 , 2011 .",
    "s.  arora , r.  ge , r.  kannan , and a.  moitra , `` computing a nonnegative matrix factorization - provably , '' in _ proceedings of the forty - fourth annual acm symposium on theory of computing _ , 2012 , pp .",
    "145162 .",
    "a.  aissa - el - bey , d.  pastor , s.  m.  a. sbai , and y.  fadlallah , `` sparsity - based recovery of finite alphabet solutions to underdetermined linear systems , '' _ information theory , ieee transactions on _ , vol .",
    "61 , no .  4 ,",
    "pp . 20082018 , 2015 ."
  ],
  "abstract_text": [
    "<S> we give under weak assumptions a complete combinatorial characterization of identifiability for linear mixtures of finite alphabet sources , with unknown mixing weights and unknown source signals , but known alphabet . </S>",
    "<S> this is based on a detailed treatment of the case of a single linear mixture . </S>",
    "<S> notably , our identifiability analysis applies also to the case of unknown number of sources .    </S>",
    "<S> we provide sufficient and necessary conditions for identifiabilty and give a simple sufficient criterion together with an explicit construction to determine the weights and the source signals for deterministic data by taking advantage of the hierarchical structure within the possible mixture values .    </S>",
    "<S> we show that the probability of identifiability is related to the distribution of a hitting time and converges exponentially fast to one when the underlying sources come from a discrete markov process . </S>",
    "<S> finally , we explore our theoretical results in a simulation study .    </S>",
    "<S> our work extends and clarifies the scope of scenarios for which blind source separation becomes meaningful .    </S>",
    "<S> blind source separation ; bss ; finite alphabet signals ; single mixture ; instantaneous mixtures ; markov processes , stopping time </S>"
  ]
}