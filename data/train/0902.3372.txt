{
  "article_text": [
    "we study the capacity of peak - power limited , single - antenna , discrete - time , flat - fading channels with memory .",
    "a noncoherent channel model is considered where the transmitter and receiver are both aware of the law of the fading process , but not of its realization .",
    "our focus is on the capacity at high signal - to - noise ratio ( snr ) . specifically , we study the capacity pre - log , which is defined as the limiting ratio of channel capacity to the logarithm of the snr , as the snr tends to infinity",
    ".    the capacity pre - log of _ gaussian _ fading channels was derived in @xcite ( see also @xcite ) .",
    "it was shown that the pre - log is given by the lebesgue measure of the set of harmonics where the derivative of the spectral distribution function that characterizes the memory of the fading process is zero . to the best of our knowledge , the capacity pre - log of _ non - gaussian _ fading channels is unknown .    in this work ,",
    "we demonstrate that the gaussian assumption in the analysis of fading channels at high snr is conservative in the sense that for a large class of fading processes the gaussian process is the worst .",
    "more precisely , we show that among all stationary & ergodic fading processes of a given spectral distribution function and whose law has no mass point at zero , the gaussian process gives rise to the smallest pre - log .",
    "this paper is organized as follows .",
    "section  [ sec : channel ] describes the channel model .",
    "section  [ sec : capacity ] defines channel capacity and the capacity pre - log .",
    "section  [ sec : results ] presents our main results .",
    "section  [ sec : proofprelog ] provides the proofs of these results .",
    "section  [ sec : miso ] discusses the extension of our results to multiple - input single - output ( miso ) fading channels with memory .",
    "section  [ sec : discussion ] concludes the paper with a summary and a discussion of our results .",
    "let @xmath0 and @xmath1 denote the set of complex numbers and the set of integers .",
    "we consider a single - antenna flat - fading channel with memory where the time-@xmath2 channel output @xmath3 corresponding to the time-@xmath2 channel input @xmath4 is given by @xmath5 here the random processes @xmath6 and @xmath7 take value in @xmath0 and model the additive and multiplicative noises , respectively .",
    "it is assumed that these processes are statistically independent and of a joint law that does not depend on the input sequence @xmath8 .",
    "the additive noise @xmath6 is a sequence of independent and identically distributed ( iid ) zero - mean , variance-@xmath9 , circularly - symmetric , complex gaussian random variables .",
    "the multiplicative noise ( `` fading '' ) @xmath7 is a mean-@xmath10 , unit - variance , stationary & ergodic stochastic process of spectral distribution function @xmath11 , @xmath12 , i.e. , @xmath13 is a bounded and nondecreasing function on @xmath14 $ ] satisfying @xmath15 where @xmath16 , and where @xmath17 denotes the complex conjugate of @xmath18 ( * ? ? ? * , thm .",
    "3.2 ) . since @xmath13 is monotonic , it is almost everywhere differentiable , and we denote its derivative by @xmath19 .",
    "( at the discontinuity points of @xmath13 the derivative @xmath19 is undefined . ) for example , if the fading process @xmath7 is iid , then @xmath20",
    "channel capacity is defined as the supremum of all achievable rates .",
    "( we refer to ( * ? ? ?",
    "8) for a definition of an achievable rate and for a more detailed discussion of channel capacity . )",
    "it was shown ( e.g. , ( * ? ? ?",
    "2 ) ) that the capacity of our channel under a peak - power constraint @xmath21 on the inputs is given by @xmath22 where @xmath23 is defined as @xmath24 @xmath25 denotes the sequence @xmath26 ; and where the maximization is over all joint distributions on @xmath27 satisfying with probability one @xmath28 the capacity pre - log is defined as @xcite @xmath29    for _ gaussian fading _ ,",
    "i.e. , when @xmath30 is a circularly - symmetric , complex gaussian process , the pre - log @xmath31 is given by the lebesgue measure of the set of harmonics where the derivative of the spectral distribution function is zero , i.e. , @xmath32 where @xmath33 denotes the lebesgue measure on the interval @xmath14 $ ] ; see @xcite , @xcite .",
    "( here the subscript `` g '' stands for `` gaussian '' . )",
    "this result indicates that if the fading process is gaussian and satisfies @xmath34 then the corresponding channel capacity grows logarithmically in the snr .",
    "note that otherwise the capacity can increase with the snr in various ways .",
    "for instance , in @xcite fading channels are studied that result in a capacity which increases double - logarithmically with the snr , and in @xcite spectral distribution functions are presented for which capacity grows as a fractional power of the logarithm of the snr .",
    "we show that , among all stationary & ergodic fading processes of a given spectral distribution function and whose law has no mass point at zero , the gaussian process gives rise to the smallest pre - log .",
    "this is made precise in the following theorem .",
    "[ thm : prelog ] consider a mean-@xmath10 , unit - variance , stationary & ergodic fading process @xmath7 whose spectral distribution function is given by @xmath13 and whose law satisfies @xmath35 then the corresponding capacity pre - log @xmath36 is lower bounded by @xmath37    see section  [ sub : proofprelog ] .",
    "the assumption that the law of the fading process has no mass point at zero is essential in the following sense .",
    "[ note : zero ] there exists a mean-@xmath10 , unit - variance , stationary & ergodic fading process @xmath7 of some spectral distribution function @xmath13 such that @xmath38 by theorem  [ thm : prelog ] , this process must satisfy @xmath39    see section  [ sub : zero ] .    [ note : phasenoise ] the inequality in can be strict .",
    "for example , consider the _ phase - noise channel _ with memoryless phase noise .",
    "this channel can be viewed as a fading channel where the fading process @xmath7 is given by @xmath40 and where @xmath41 is iid with @xmath42 being uniformly distributed over @xmath43 .",
    "this process gives rise to a pre - log @xmath44 , whereas the gaussian fading of equal spectral distribution function yields @xmath45 .",
    "for a derivation of the capacity pre - log of the phase - noise channel see section  [ sub : phasenoisepp ] .",
    "this section provides the proofs of our main results . for a proof of theorem  [ thm : prelog ]",
    "see section  [ sub : proofprelog ] , for a proof of note  [ note : zero ] see section  [ sub : zero ] , and for a proof of note  [ note : phasenoise ] see section  [ sub : phasenoisepp ] .      to prove theorem  [ thm : prelog ]",
    ", we derive in section  [ sub : lb ] a lower bound on the capacity , and proceed in section  [ sub : prelog ] to analyze its asymptotic growth as the snr tends to infinity .      to derive a lower bound on the capacity we consider inputs @xmath46 that are iid , zero - mean , circularly - symmetric , and for which @xmath47 is uniformly distributed over the interval @xmath48 $ ] .",
    "our derivation is based on the lower bound @xmath49 which follows from the chain rule    lcl i(x_1^n;y_1^n ) & = & i(x_1^n , h_1^n;y_1^n ) - i(h_1^n;y_1^n|x_1^n ) + & = & i(h_1^n;y_1^n ) + i(x_1^n;y_1^n|h_1^n ) - i(h_1^n;y_1^n|x_1^n )    and the nonnegativity of mutual information .",
    "we first study the first term on the right - hand side ( rhs ) of . making use of the stationarity of the channel and of the fact that the inputs are iid we have @xmath50 we lower bound the rhs of as follows . for any fixed @xmath51    lcl i(x_1;y_1|h_1 ) & = & h(h_1x_1+z_1|h_1)-h(z_1 ) + & = & _ |h_1| h(h_1x_1+z_1|h_1=h_1 ) p_h_1(h_1 ) + & & + _",
    "|h_1| < h(h_1x_1+z_1|h_1=h_1 ) p_h_1(h_1 ) - h(z_1 ) + & & _ |h_1|",
    "h(h_1x_1+z_1|h_1=h_1 ) p_h_1(h_1 ) + h(z_1)-h(z_1 ) + & & _ |h_1| ( |h_1|^2+h(x_1))p_h_1(h_1 ) + h(z_1)-h(z_1 ) + & & ( ^2+h(x_1 ) ) + h(z_1 ) - h(z_1 ) + & = & ( ^2++h(|x_1|^2 ) ) + h(z_1 ) - h(z_1 ) + & = & ^2 + ( ^2 ) + h(z_1 ) - h(z_1 ) + & = & ^2 + ( ^2 ) + ( -1)(e^2 ) + & = & - ( 1-^2 ) , [ eq : coherent ]    where @xmath52 denotes the distribution function of the fading @xmath53 . here",
    "the third step follows by conditioning the entropy in the second integral on @xmath54 ; the fourth step follows by conditioning the entropy in the first integral on @xmath55 and by the behavior of differential entropy under scaling ( * ? ? ?",
    "9.6.4 ) ; the fifth step follows because over the range of integration @xmath56 we have @xmath57 ; the sixth step follows because @xmath54 is circularly - symmetric ( * ? ? ?",
    "* lemma 6.16 ) ; the seventh step follows by computing the entropy of a random variable that is uniformly distributed over the interval @xmath48 $ ] ; the eighth step follows by evaluating the entropy of a zero - mean , variance-@xmath9 , circularly - symmetric , complex gaussian random variable @xmath58 ; and the last step follows from @xmath59 .",
    "we next turn to the second term on the rhs of . in order to upper bound it",
    "we proceed along the lines of @xcite , but for non - gaussian fading .",
    "let @xmath60 , @xmath61 , and @xmath62 be the random vectors @xmath63 , @xmath64 , and @xmath65 ( where @xmath66 denotes the transpose of @xmath67 ) , and let @xmath68 be a diagonal matrix with diagonal entries @xmath69 .",
    "it follows from that @xmath70 the conditional covariance matrix of @xmath60 , conditional on @xmath69 , is given by @xmath71 where @xmath72 is the @xmath73 identity matrix , @xmath74 denotes hermitian conjugation , and @xmath75 let @xmath76 denote the determinant of the matrix @xmath77 . using the entropy maximizing property of circularly - symmetric gaussian vectors ( * ? ? ?",
    "9.6.5 ) , we have    lcl i(h_1^n;y_1^n|x_1^n ) & = & h(y_1^n|x_1^n)- h(z_1^n ) + & & + & = & + & & ( _ n+ _ ) + & = & ( _ n+ _ ) + & = & _ k=1^n ( 1+_k ) , [ eq : noncoherent ]    where @xmath78 is a random diagonal matrix with diagonal entries @xmath27 , and where @xmath79 denote the eigenvalues of @xmath80 . here",
    "the third step follows from the identity @xmath81 ; the fourth step follows from which implies that @xmath82 is positive semidefinite with probability one ; the fifth step follows from the definition of @xmath23 ; and the last step follows because the determinant of a matrix is given by the product of its eigenvalues .    to evaluate the rhs of in the limit as @xmath83 tends to infinity , we apply szeg s theorem on the asymptotic behavior of the eigenvalues of hermitian toeplitz matrices @xcite ( see also ( * ? ? ?",
    "2.7.13 ) ) .",
    "we obtain    lcl _",
    "n i(h_1^n;y_1^n|x_1^n ) & & _ n _ k=1^n ( 1+_k ) + & = & _ -1/2 ^ 1/2 ( 1+f ( ) ) .[eq : spectrum ]    combining , , , and yields the final lower bound    lcl c ( ) & & - ( 1-^2 ) + & & - _ -1/2 ^ 1/2 ( 1 + f ( ) ) , > 0 , [ eq : lb ]    which holds for any fixed @xmath84 . note that this lower bound applies to all mean-@xmath10 , unit - variance , stationary & ergodic fading processes @xmath7 with spectral distribution function @xmath13 .",
    "in the following we prove by computing the limiting ratio of the lower bound to @xmath85 as @xmath23 tends to infinity .",
    "we first show that    lcl _ _",
    "-1/2 ^ 1/2 & = & ( \\{f()>0}).[eq : all ]    to this end , we divide the integral into three parts , depending on whether @xmath86 takes part in the set @xmath87 , @xmath88 , or @xmath89 , where    lcl _ 1 & & \\{f()=0 } + _ 2 & & \\{f ( ) 1 } + _ 3 & & \\{0<f()<1}.    for @xmath90 the integrand is zero and hence @xmath91 for @xmath92 , i.e. , when @xmath93 , we note that for sufficiently large snr the function @xmath94 is monotonically decreasing in @xmath23 .",
    "therefore , applying the monotone convergence theorem ( * ? ? ?",
    "* thm .  1.26 )",
    ", we have    lcl _ _ _ 2 & = & _ _ 2 _ + & = & ( _ 2 ) + & = & ( \\{f()1}).[eq : monotone ]    for @xmath95 , i.e. , when @xmath96 , we have @xmath97 where the last step follows because , for sufficiently large snr , the function @xmath98 is monotonically decreasing in @xmath23 .",
    "since @xmath99 is integrable over @xmath89 , we can apply the dominated convergence theorem ( * ? ? ?",
    "* thm .  1.34 ) to obtain    lcl",
    "_ _ _ 3 & = & _ _ 3 _ + & = & ( _ 3 ) + & = & ( \\{0<f()<1}).[eq : dominated ]    adding , , and yields .    to continue with the asymptotic analysis of we note that by    lcl & & _ + & & - ( \\{:f()>0 } ) + & = & ( \\{f()=0})-[eq : withgamma ]    for any @xmath84 .",
    "if the law of the fading process has no mass point at zero , then @xmath100 and therefore follows from by letting @xmath101 tend to zero from above .",
    "we prove note  [ note : zero ] by demonstrating that there exists a stationary & ergodic fading process of some spectral distribution function @xmath13 for which @xmath102 by theorem  [ thm : prelog ] , the law of such a process must have a mass point at zero , i.e. , @xmath39 to this end , we first show that the capacity pre - log is upper bounded by @xmath103 indeed , the capacity @xmath104 does not decrease when the receiver additionally knows the realization of @xmath7 , and when the inputs have to satisfy an average - power constraint rather than a peak - power constraint , i.e. , @xmath105 where the maximization is over all input distributions on @xmath27 satisfying the average - power constraint @xmath106 ( this follows because the availability of additional information can not decrease the capacity , and because any distribution on the inputs satisfying the peak - power constraint satisfies also . ) it is well known that the expression on the rhs of is equal to @xmath107 ( e.g. , ( * ? ? ?",
    "* eq .  ( 3.3.10 ) ) ) , which can be further upper bounded by    lcl & = & + & & ( 1 + ) + & = & ( 1+).[eq : csi2 ]    here the first step follows by writing the expectation as    lcl & = & + & & + ,    and by noting then that @xmath108 ; the second step follows from jensen s inequality ; and the last step follows because @xmath109 , which implies @xmath110 dividing the rhs of by @xmath85 , and computing the limit as @xmath23 tends to infinity yields .    in view of , it suffices to demonstrate that there exists a fading process of some spectral distribution function @xmath13 that satisfies @xmath111    a first attempt of defining such a process ( which , alas , does not work ) is @xmath112 \\ldots , b_{-1},b_0,b_1,b_2,\\ldots \\quad &    \\text{with probability $ 1-\\delta$,}\\end{array}\\right.\\ ] ] where @xmath113 is a zero - mean , circularly - symmetric , stationary & ergodic , complex gaussian process of variance @xmath114 and of spectral distribution function @xmath115 ; and where @xmath116 and @xmath115 are chosen so that @xmath117 this process satisfies because @xmath118 , and because @xmath119 which implies that @xmath120 almost everywhere , so @xmath121 alas , the above fading process is stationary but not ergodic .    in the following , we exhibit a fading process that is stationary & ergodic and satisfies .",
    "let @xmath122 \\ldots,1,0,1,0,\\ldots \\quad &    \\text{with probability $ \\frac{1}{2}$ } , \\end{array}\\right.\\ ] ] and let @xmath113 be a zero - mean , variance-@xmath123 , circularly - symmetric , stationary & ergodic , complex gaussian process of spectral distribution function @xmath115 .",
    "furthermore let @xmath124 and @xmath113 be independent of each other .",
    "we shall consider fading processes of the form @xmath125 note that @xmath7 is of zero mean , and its law has a mass point at zero @xmath126    we first argue that @xmath127 is stationary & ergodic .",
    "indeed , @xmath124 is stationary & ergodic . and",
    "since a gaussian process is ergodic if , and only if , it is weakly - mixing ( see , e.g. , ( * ? ? ?",
    "ii ) ) , we have that @xmath113 is stationary & weakly - mixing .",
    "( see ( * ? ? ?",
    "2.6 ) for a definition of weakly - mixing stochastic processes . )",
    "it thus follows from ( * ? ? ?",
    "1.6 ) that the process @xmath128 is jointly stationary & ergodic , which implies that @xmath129 is stationary & ergodic .",
    "we next demonstrate that @xmath115 can be chosen so that @xmath7 satisfies .",
    "we choose @xmath130 \\displaystyle 0,\\quad & \\text{otherwise}\\end{array } \\right.\\ ] ] for some @xmath131 , which corresponds to the autocovariance function @xmath132 here @xmath133 denotes the sinc - function , i.e. , @xmath134 for @xmath135 and @xmath136 . using that @xmath137 ( where @xmath138 is @xmath139 if the statement is true , and @xmath140 otherwise ) , we have for the autocovariance function of @xmath7    lcl & = & + & = & + & = & ( 2 m ) , m ,    and the corresponding spectrum is given by @xmath141 0 , & \\text{otherwise.}\\end{array}\\right.\\ ] ] evaluating the lebesgue measure of the set of harmonics where @xmath142 , we have @xmath143 and it follows from that @xmath144 thus there exist stationary & ergodic fading processes whose law has a mass point at zero and that give rise to a capacity pre - log that is strictly smaller than the pre - log of a gaussian fading channel of equal spectral distribution function .      to prove note  [ note : phasenoise ] , we first notice that , since the phase noise is memoryless , the derivative of the spectral distribution function is @xmath20 hence the capacity pre - log of the gaussian fading channel of spectral distribution function @xmath13 equals @xmath145    it thus remains to show that the pre - log of the phase - noise channel with memoryless phase noise is equal to @xmath146 in @xcite it was shown that at high snr the capacity of the phase - noise channel under an average - power constraint on the inputs is given by @xmath147 where @xmath148 tends to zero as @xmath23 tends to zero .",
    "( the subscript `` avg '' indicates that the inputs satisfy an average - power constraint and not a peak - power constraint . ) since any distribution on the inputs satisfying the peak - power constraint satisfies also the average - power constraint , it follows that @xmath149 and hence @xmath150 to prove it thus suffices to show that @xmath151 . to this end , we first note that , since the phase noise is memoryless , we have @xmath152 where the maximization is over all distributions on @xmath54 satisfying with probability one @xmath153    we derive a lower bound on @xmath104 by evaluating the rhs of for @xmath54 being a zero - mean , circularly - symmetric , complex random variable with @xmath154 uniformly distributed over the interval @xmath155 $ ] .",
    "we have    lcl i(x_1;y_1 ) & & i(x_1;|y_1|^2 ) + & = & h(|y_1|^2 ) - h(|y_1|^2|x_1 ) + & & h(|x_1|^2 ) - h(|y_1|^2|x_1),[eq : app1 ]    where the first step follows from the data processing inequality ( * ? ? ?",
    "2.8.1 ) ; and the last step follows by the circular symmetry of @xmath54 ( * ? ? ?",
    "* , after eq .",
    "( 20 ) ) .",
    "computing the differential entropy of a uniformly distributed random variable , the first term on the rhs of becomes @xmath156 as to the second term , we note that , for a given @xmath157 , the random variable @xmath158 has a noncentral chi - square distribution with noncentrality parameter @xmath159 and two degrees of freedom .",
    "its differential entropy can be upper bounded by ( * ? ? ?",
    "* eq .  ( 8) )    lcl h(|y_1|^2|x_1 ) & & - + & & ( 4e(2 + 2 ^ 2))- , [ eq : app3 ]    where the last step follows because @xmath160 with probability one . combining and with yields thus @xmath161 where @xmath162 we finally obtain the lower bound @xmath163 upon dividing the rhs of by @xmath85 and letting then @xmath23 tend to infinity .",
    "theorem  [ thm : prelog ] can be extended to multiple - input single - output ( miso ) fading channels with memory , when the fading processes corresponding to the different transmit antennas are independent . for such channels , the channel output @xmath164 at time @xmath165 corresponding to the channel input @xmath166 ( where @xmath167 stands for the number of antennas at the transmitter ) is given by @xmath168 where @xmath169 , and where the processes @xmath170 are jointly stationary & ergodic and independent .",
    "we assume that for each @xmath171 the process @xmath172 is of mean @xmath173 , of unit variance , and of spectral distribution function @xmath174 .",
    "we further assume that @xmath175 the additive noise @xmath6 is defined as in section  [ sec : channel ] .",
    "the capacity of this channel is given by , but with @xmath176 replaced by @xmath177 , and with the peak - power constraint altered accordingly : @xmath178 where @xmath179 denotes the euclidean norm of the vector @xmath180 , i.e. , @xmath181 let @xmath182 denote the pre - log of miso fading channels . following , we define @xmath182 as @xmath183 for gaussian fading , i.e. , when @xmath184 , @xmath185 are circularly - symmetric , complex gaussian processes , the pre - log was shown to be given by ( * ? ? ?",
    "13 ) @xmath186 ( a proof of this result can be found in ( * ? ? ?",
    "7.2.2 ) . )",
    "proving that the capacity pre - log @xmath182 of miso fading channels is lower bounded by the pre - log of the miso gaussian fading channel of equal spectral distribution functions ",
    "namely @xmath187is straightforward .",
    "let @xmath188 , @xmath185 denote the capacity pre - log of a single - antenna fading channel with fading process @xmath172 , and let @xmath189 by signaling only from antenna @xmath190 while keeping the others silent , we can achieve the pre - log @xmath191 , so @xmath192 theorem  [ thm : prelog ] yields then @xmath193 which together with proves the claim @xmath194",
    "we showed that , among all stationary & ergodic fading processes of a given spectral distribution function and whose law has no mass point at zero , the gaussian process gives rise to the smallest capacity pre - log .",
    "we further showed that if the fading law is allowed to have a mass point at zero , then the above statement is not necessarily true anymore . roughly speaking",
    ", we can say that for a large class of fading processes the gaussian process is the worst .",
    "this demonstrates the robustness of the gaussian assumption in the analysis of fading channels at high snr .    to give an intuition why gaussian processes give rise to the smallest pre - log",
    ", we recall that for gaussian fading ( * ? ? ?",
    "( 33 ) & ( 47 ) ) @xmath195 where @xmath196 denotes the mean - square error in predicting the present fading @xmath197 from a variance-@xmath116 noisy observation of its past @xmath198 ( with @xmath199 being a sequence of iid , zero - mean , variance-@xmath116 , circularly - symmetric , complex gaussian random variables ) .",
    "thus for gaussian fading the capacity pre - log is determined by @xmath200 , and it is plausible that also the pre - log of non - gaussian fading channels is connected with the ability of predicting the present fading from a noisy observation of its past . since , among all stationary & ergodic processes of a given spectral distribution function , the gaussian process is hardest to predict , it is therefore plausible that the gaussian process gives rise to the smallest pre - log .          , `` on the high snr capacity of stationary gaussian fading channels , '' in _ proceedings forty - first allerton conference on communication , control and computing _",
    ", allerton house , monticello , illinois , october 13 , 2003 .",
    "a.  lapidoth and s.  m. moser , `` capacity bounds via duality with applications to multiple - antenna systems on flat fading channels , '' _ ieee transactions on information theory _ , vol .",
    "49 , no .",
    "10 , pp . 24262467 , october 2003 .",
    "t.  koch and a.  lapidoth , `` the fading number and degrees of freedom in non - coherent mimo fading channels : a peace pipe , '' in _ proceedings ieee international symposium on information theory ( isit ) _ , adelaide , australia , september 49 , 2005 .",
    "t.  koch , `` on the asymptotic capacity of multiple - input single - output fading channels with memory , '' master s thesis , signal and information processing laboratory , eth zurich , switzerland , april 2004 , supervised by prof .",
    "amos lapidoth ."
  ],
  "abstract_text": [
    "<S> the capacity of peak - power limited , single - antenna , noncoherent , flat - fading channels with memory is considered . </S>",
    "<S> the emphasis is on the capacity pre - log , i.e. , on the limiting ratio of channel capacity to the logarithm of the signal - to - noise ratio ( snr ) , as the snr tends to infinity . </S>",
    "<S> it is shown that , among all stationary & ergodic fading processes of a given spectral distribution function and whose law has no mass point at zero , the gaussian process gives rise to the smallest pre - log . </S>",
    "<S> the assumption that the law of the fading process has no mass point at zero is essential in the sense that there exist stationary & ergodic fading processes whose law has a mass point at zero and that give rise to a smaller pre - log than the gaussian process of equal spectral distribution function . </S>",
    "<S> an extension of our results to multiple - input single - output fading channels with memory is also presented . </S>"
  ]
}