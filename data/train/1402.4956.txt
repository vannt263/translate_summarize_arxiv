{
  "article_text": [
    "on a complete probability space @xmath0 , we consider the following stochastic process @xmath1 in @xmath2 defined by @xmath3 where @xmath4 is a standard brownian motion , @xmath5 is a poisson process with intensity @xmath6 independent of @xmath7 , and we denote by @xmath8 the compensated poisson process @xmath9 .",
    "the parameters @xmath10 are unknown and @xmath11 and @xmath12 are closed intervals of @xmath13 and @xmath14 , where @xmath15 .",
    "let @xmath16 denote the natural filtration generated by @xmath7 and @xmath17 .",
    "we denote by @xmath18 the probability law induced by the @xmath19-adapted cdlg stochastic process @xmath20 starting at @xmath21 , and by @xmath22 the expectation with respect to @xmath18 .",
    "let @xmath23 and @xmath24 denote the convergence in @xmath18-probability and in @xmath18-law , respectively .    for @xmath10 , we consider an equidistant discrete observation of the process @xmath20 which is denoted by @xmath25 , where @xmath26 for @xmath27 , and @xmath28 .",
    "we assume that the high - frequency observation condition holds .",
    "that is , @xmath29 let @xmath30 denote the density of the random vector @xmath31 under the parameter @xmath32 . for @xmath33 ,",
    "set @xmath34 .",
    "the aim of this paper is to prove the following lan property .",
    "[ theorem ] assume condition .",
    "then , the lan property holds for all @xmath10 with rate of convergence @xmath35 and asymptotic fisher information matrix @xmath36 .",
    "that is , for all @xmath37 , as @xmath38 , @xmath39 where @xmath40 is a centered @xmath41-valued gaussian vector with covariance matrix @xmath42    theorem [ theorem ] extends in the linear case and in the presence of jumps the results of gobet in @xcite and @xcite for multidimensional continuous elliptic diffusions .",
    "the main idea of these papers is to use the malliavin calculus in order to obtain an expression for the derivative of the log - likelihood function in terms of a conditional expectation .",
    "some extensions of gobet s work with the presence of jumps are given for e.g. in @xcite , @xcite , and @xcite .",
    "however , in the present note , we estimate the coefficients and jump intensity parameters at the same time . the main motivation for this paper is to show some of the important properties and arguments in order to prove the lamn property in the non - linear case",
    "whose proof is non - trivial . in particular , we present four important lemmas of independent interest which will be key elements in dealing with the non - linear case . the key argument consists in conditioning on the number of jumps within the conditional expectation which expresses the transition density and outside it .",
    "when these two conditionings relate to different jumps one may use a large deviation principle in the estimate .",
    "when they are equal one uses the complementary set .",
    "within all these arguments the gaussian type upper and lower bounds of the density conditioned on the jumps is again strongly used .",
    "this idea seems to have many other uses in the set - up of stochastic differential equations driven by a brownian motion and a jump process .",
    "we remark here that a plain it - taylor expansion would not solve the problem as higher moments of the poisson process do not become smaller as the expansion order increases .",
    "in this section we introduce the preliminary results needed for the proof of theorem [ theorem ] . in order to deal with the likelihood ratio in theorem [ theorem ]",
    ", we will use the following decomposition @xmath43    for each of the above terms we will use a mean value theorem and then analyze each term .",
    "we start as in gobet @xcite applying the integration by parts formula of the malliavin calculus on each interval @xmath44 $ ] to obtain the following expressions for the derivatives of the log - likelihood function w.r.t . @xmath45 and @xmath46 .",
    "moreover , using girsanov s theorem , we obtain the following expression for the log - likelihood function w.r.t .",
    "@xmath47 . for any @xmath48",
    ", we denote by @xmath49 the transition density of @xmath50 conditioned on @xmath51 .",
    "[ prop1 ] for all @xmath52 , and @xmath53 , @xmath54,\\\\ & \\dfrac{\\partial_{\\sigma}p^{\\theta,\\sigma,\\lambda}}{p^{\\theta,\\sigma,\\lambda}}\\left(\\delta_n , x_{t_k},x_{t_{k+1}}\\right)=\\dfrac{1}{\\delta_n}{\\mathrm{e}}_{x_{t_k}}^{\\theta,\\sigma,\\lambda}\\left[\\left(b_{t_{k+1}}-b_{t_{k}}\\right)^2\\big\\vert x_{t_{k+1}}^{\\theta,\\sigma,\\lambda}=x_{t_{k+1}}\\right ] -\\frac{1}{\\sigma } , \\\\ &",
    "\\dfrac{\\partial_{\\lambda}p^{\\theta,\\sigma,\\lambda}}{p^{\\theta,\\sigma,\\lambda}}(\\delta_n , x_{t_k},x_{t_{k+1}})={\\mathrm{e}}_{x_{t_k}}^{\\theta,\\sigma,\\lambda } \\left[-\\dfrac{b_{t_{k+1}}-b_{t_{k}}}{\\sigma}+\\dfrac{\\widetilde{n}_{t_{k+1}}^{\\lambda}-\\widetilde{n}_{t_k}^{\\lambda}}{\\lambda}\\bigg\\vert x_{t_{k+1}}^{\\theta,\\sigma,\\lambda}=x_{t_{k+1}}\\right ] .",
    "\\end{split}\\ ] ]    we next present the four lemmas mentionned in the introduction . consider the events @xmath55 , for all @xmath56 and @xmath53 .",
    "[ lemma4 ] for all @xmath57 , and @xmath56 , @xmath58    for all @xmath59 and @xmath53 , we introduce the random variable @xmath60 . \\end{split}\\ ] ] we remark that heuristically the indicator functions @xmath61 and @xmath62 outside and inside the conditional expectation correspond to restrictions on @xmath63 and @xmath64 , respectively .",
    "[ lemma5 ] for all @xmath65 and @xmath53 , @xmath66    we next fix @xmath67 , and analyze @xmath68 in two separate cases as follows @xmath69 furthermore , we write @xmath70 and @xmath71 , where @xmath72 and @xmath73 contain the terms @xmath74 , and @xmath75 and @xmath76 contain the terms @xmath77 in ( [ eq44 ] ) .    [ lemma6 ] assume that @xmath78 and @xmath79 , for some constant @xmath80 .",
    "then for all @xmath81 , and for @xmath82 large enough , @xmath83    for all @xmath84 and @xmath53 , set @xmath85\\right],\\\\ m_{2,p}^{\\bar{\\theta},\\bar{\\sigma},\\bar{\\lambda}}:&=\\sum_{j=0}^{\\infty}{\\mathrm{e}}_{x_{t_k}}^{\\theta,\\sigma,\\lambda}\\left[{\\bf 1}_{j_j}{\\mathrm{e}}_{x_{t_k}}^{\\bar{\\theta},\\bar{\\sigma},\\bar{\\lambda}}\\left[{\\bf 1}_{j_j^c}\\left(n_{t_{k+1}}-n_{t_{k}}\\right)^p\\big\\vert x_{t_{k+1}}^{\\bar{\\theta},\\bar{\\sigma},\\bar{\\lambda}}=x_{t_{k+1}}\\right]\\right ] .",
    "\\end{split}\\ ] ]    [ lemma7 ] assume that @xmath78 and @xmath79 , for some constant @xmath80 .",
    "then , for any @xmath86 , @xmath84 , and for @xmath82 large enough , there exist constants @xmath87 such that for all @xmath67 , and @xmath88 , @xmath89    we next recall a convergence in probability result , and a central limit theorem for triangular arrays of random variables . for each @xmath90 , let @xmath91 and @xmath92 be two sequences of random variables defined on the filtered probability space @xmath93 , and assume that they are @xmath94-measurable .",
    "[ zero ] ( * ? ? ?",
    "* lemma 9 ) assume that @xmath95 \\overset{{\\mathrm{p}}}{\\longrightarrow } 0 $ ] , and @xmath96\\overset{{\\mathrm{p}}}{\\longrightarrow } 0 $ ] , as @xmath97 .",
    "then @xmath98 as @xmath97 .    [ clt ] ( * ? ?",
    "* lemma 4.3 ) assume that there exist real numbers @xmath99 and @xmath100 such that as @xmath97 , @xmath101 \\overset{{\\mathrm{p}}}{\\longrightarrow } m , \\quad \\sum_{k=0}^{n-1}\\left({\\mathrm{e}}\\left[\\zeta_{k , n}^2\\vert \\mathcal{f}_{t_k } \\right]-\\left({\\mathrm{e}}\\left[\\zeta_{k , n}\\vert \\mathcal{f}_{t_k}\\right]\\right)^2\\right)\\overset{{\\mathrm{p}}}{\\longrightarrow } v , \\text { and }   \\sum_{k=0}^{n-1}{\\mathrm{e}}\\left[\\zeta_{k , n}^4\\vert \\mathcal{f}_{t_k}\\right ] \\overset{{\\mathrm{p}}}{\\longrightarrow } 0 . \\end{split}\\ ] ] then as @xmath97 , @xmath102 , where @xmath103 is a centered gaussian variable with variance @xmath104 .",
    "for @xmath105 $ ] , set @xmath106 .",
    "applying the markov property and proposition [ prop1 ] to each term in ( [ eq : dec ] ) , we obtain that @xmath107d\\ell , \\end{split}\\ ] ] @xmath108 -\\frac{1}{\\sigma(\\ell ) } \\right)d\\ell , \\end{split}\\ ] ] and @xmath109d\\ell .",
    "\\end{split}\\ ] ] now using equation , we obtain the following expansion of the log - likelihood ratio @xmath110 where @xmath111d\\ell\\right ) , \\\\ \\eta_{k , n}&:=\\dfrac{v}{\\sqrt{n}}\\int_0 ^ 1\\dfrac{1}{\\delta_n}\\left(\\dfrac{\\sigma^2}{\\sigma(\\ell)^3}\\left(b_{t_{k+1}}-b_{t_{k}}\\right)^2-\\dfrac{\\delta_n}{\\sigma(\\ell)}\\right)d\\ell,\\\\ m_{k , n}&:=\\dfrac{v}{\\sqrt{n}}\\int_0 ^ 1\\dfrac{1}{\\delta_n}\\dfrac{1}{\\sigma(\\ell)^3}\\bigg\\{\\left(\\theta\\delta_n+\\widetilde{n}_{t_{k+1}}^{\\lambda}-\\widetilde{n}_{t_{k}}^{\\lambda}\\right)^2 + 2\\sigma\\left(b_{t_{k+1}}-b_{t_{k}}\\right)\\left(\\theta\\delta_n+\\widetilde{n}_{t_{k+1}}^{\\lambda}-\\widetilde{n}_{t_{k}}^{\\lambda}\\right)\\\\ & \\qquad\\qquad-{\\mathrm{e}}_{x_{t_k}}^{\\theta_n,\\sigma(\\ell),\\lambda_n } \\bigg[\\left(\\theta_n\\delta_n+\\widetilde{n}_{t_{k+1}}^{\\lambda_n}-\\widetilde{n}_{t_{k}}^{\\lambda_n}\\right)^2\\\\ & \\qquad\\qquad+2\\sigma(\\ell)\\left(b_{t_{k+1}}-b_{t_{k}}\\right)\\left(\\theta_n\\delta_n+\\widetilde{n}_{t_{k+1}}^{\\lambda_n}-\\widetilde{n}_{t_{k}}^{\\lambda_n}\\right ) \\bigg\\vert x_{t_{k+1}}^{\\theta_n,\\sigma(\\ell),\\lambda_n}=x_{t_{k+1}}\\bigg]\\bigg\\}d\\ell , \\\\ \\beta_{k , n}&:=-\\dfrac{w}{\\sqrt{n\\delta_n}}\\dfrac{1}{\\sigma^2}\\left(\\sigma\\left(b_{t_{k+1}}-b_{t_{k}}\\right)+\\dfrac{w\\delta_n}{2\\sqrt{n\\delta_n}}-\\dfrac{u\\delta_n}{\\sqrt{n\\delta_n}}\\right)\\\\ & \\qquad+\\dfrac{w}{\\sqrt{n\\delta_n}}\\int_0 ^ 1{\\mathrm{e}}_{x_{t_k}}^{\\theta_n,\\sigma,\\lambda(\\ell)}\\left[\\dfrac{\\widetilde{n}_{t_{k+1}}^{\\lambda(\\ell)}-\\widetilde{n}_{t_k}^{\\lambda(\\ell)}}{\\lambda(\\ell)}\\bigg\\vert x_{t_{k+1}}^{\\theta_n,\\sigma,\\lambda(\\ell)}=x_{t_{k+1}}\\right]d\\ell,\\\\ r_{k , n}&:=\\dfrac{w}{\\sqrt{n\\delta_n}}\\dfrac{1}{\\sigma^2}\\int_0 ^ 1\\left(\\widetilde{n}_{t_{k+1}}^{\\lambda(\\ell)}-\\widetilde{n}_{t_k}^{\\lambda(\\ell ) } -{\\mathrm{e}}_{x_{t_k}}^{\\theta_n,\\sigma,\\lambda(\\ell)}\\left [   \\widetilde{n}_{t_{k+1}}^{\\lambda(\\ell)}-\\widetilde{n}_{t_k}^{\\lambda(\\ell ) } \\bigg\\vert x^{\\theta_n,\\sigma,\\lambda(\\ell)}_{t_{k+1}}=x_{t_{k+1}}\\right]\\right)d\\ell . \\end{split}\\ ] ]    we next show that the random variables @xmath112 are the terms that contribute to the limit in theorem [ theorem ] , and @xmath113 and @xmath114 are the negligible contributions . indeed , using girsanov s theorem and lemma [ lemma7 ]",
    ", we can show that the conditions of lemma [ zero ] under @xmath18 hold for each term @xmath113 and @xmath114 .",
    "that is ,    [ lemma1 ] assume condition .",
    "then , as @xmath38 , @xmath115 \\overset{{\\mathrm{p}}_x^{\\theta,\\sigma,\\lambda}}{\\longrightarrow}-\\dfrac{u^2}{2\\sigma^2}-\\dfrac{v^2}{2}\\dfrac{2}{\\sigma^2}-\\dfrac{w^2}{2\\sigma^2}\\left(1+\\dfrac{\\sigma^2}{\\lambda}\\right)+\\dfrac{uw}{\\sigma^2}\\\\ & \\sum_{k=0}^{n-1}\\left({\\mathrm{e}}^{\\theta,\\sigma,\\lambda}\\left[\\xi_{k , n}^2+\\eta_{k , n}^2+\\beta_{k , n}^2\\vert \\mathcal{f}_{t_k}\\right]-{\\mathrm{e}}^{\\theta,\\sigma,\\lambda}\\left[\\xi_{k , n}\\vert\\mathcal{f}_{t_k}\\right]^2-{\\mathrm{e}}^{\\theta,\\sigma,\\lambda}\\left[\\eta_{k , n}\\vert \\mathcal{f}_{t_k}\\right]^2-{\\mathrm{e}}^{\\theta,\\sigma,\\lambda}\\left[\\beta_{k , n}\\vert \\mathcal{f}_{t_k}\\right]^2\\right ) \\\\ & \\qquad \\qquad\\qquad \\qquad\\overset{{\\mathrm{p}}_x^{\\theta,\\sigma,\\lambda}}{\\longrightarrow}\\dfrac{u^2}{\\sigma^2}+2\\dfrac{v^2}{\\sigma^2}+\\dfrac{w^2}{\\sigma^2}\\left(1+\\dfrac{\\sigma^2}{\\lambda}\\right)\\\\ & \\sum_{k=0}^{n-1 } { \\mathrm{e}}^{\\theta,\\sigma,\\lambda}\\left[\\xi_{k , n}^4+\\eta_{k , n}^4+\\beta_{k , n}^4\\vert \\mathcal{f}_{t_k}\\right]\\overset{{\\mathrm{p}}_x^{\\theta,\\sigma,\\lambda}}{\\longrightarrow}0 \\\\ & \\sum_{k=0}^{n-1}\\left({\\mathrm{e}}^{\\theta,\\sigma,\\lambda}\\left[\\xi_{k , n}\\eta_{k , n}\\vert \\mathcal{f}_{t_k}\\right]-{\\mathrm{e}}^{\\theta,\\sigma,\\lambda}\\left[\\xi_{k , n}\\vert \\mathcal{f}_{t_k}\\right]{\\mathrm{e}}^{\\theta,\\sigma,\\lambda}\\left[\\eta_{k , n}\\vert \\mathcal{f}_{t_k}\\right]\\right)\\overset{{\\mathrm{p}}_x^{\\theta,\\sigma,\\lambda}}{\\longrightarrow}0\\\\ & \\sum_{k=0}^{n-1}\\left({\\mathrm{e}}^{\\theta,\\sigma,\\lambda}\\left[\\xi_{k , n}\\beta_{k , n}\\vert \\mathcal{f}_{t_k}\\right]-{\\mathrm{e}}^{\\theta,\\sigma,\\lambda}\\left[\\xi_{k , n}\\vert \\mathcal{f}_{t_k}\\right]{\\mathrm{e}}^{\\theta,\\sigma,\\lambda}\\left[\\beta_{k , n}\\vert \\mathcal{f}_{t_k}\\right]\\right)\\overset{{\\mathrm{p}}_x^{\\theta,\\sigma,\\lambda}}{\\longrightarrow}-\\dfrac{uw}{\\sigma^2}\\\\ & \\sum_{k=0}^{n-1}\\left({\\mathrm{e}}^{\\theta,\\sigma,\\lambda}\\left[\\eta_{k , n}\\beta_{k , n}\\vert \\mathcal{f}_{t_k}\\right]-{\\mathrm{e}}^{\\theta,\\sigma,\\lambda}\\left[\\eta_{k , n}\\vert \\mathcal{f}_{t_k}\\right]{\\mathrm{e}}^{\\theta,\\sigma,\\lambda}\\left[\\beta_{k , n}\\vert \\mathcal{f}_{t_k}\\right]\\right)\\overset{{\\mathrm{p}}_x^{\\theta,\\sigma,\\lambda}}{\\longrightarrow}0 .",
    "\\end{aligned}\\ ] ]    finally , lemma [ clt ] applied to @xmath116 concludes the proof of theorem [ theorem ] .",
    "second author acknowledges support from the european union programme fp7-people-2012-cig under grant agreement 333938 .",
    "third author acknowledges support from the lia cnrs formath vietnam and the program arcus mae / idf vietnam ."
  ],
  "abstract_text": [
    "<S> in this paper , we consider a linear model with jumps driven by a brownian motion and a compensated poisson process , whose drift and diffusion coefficients as well as its intensity are unknown parameters . </S>",
    "<S> supposing that the process is observed discretely at high frequency we derive the local asymptotic normality ( lan ) property . in order to obtain this result , malliavin calculus and girsanov s theorem </S>",
    "<S> are applied in order to write the log - likelihood ratio in terms of sums of conditional expectations , for which a central limit theorem for triangular arrays can be applied . </S>",
    "<S> 0.5    * rsum * 0.5*la proprit lan pour un modle linaire avec sauts . </S>",
    "<S> * dans cet article , nous considrons un modle linaire avec sauts dirig par un mouvement brownien et un processus de poisson compens do nt les coefficients et lintensit dpendent de paramtres inconnus . </S>",
    "<S> supposant que le processus est observ  haute frquence , nous obtenons la proprit de normalit asymptotique locale . </S>",
    "<S> pour cela , le calcul de malliavin et le thorme de girsanov sont appliqus afin dcrire le logarithme du rapport de vraisemblances comme une somme desprances conditionnelles , pour laquelle un thorme centrale limite pour des suites triangulaires peut tre appliqu .    </S>",
    "<S> ,    , </S>"
  ]
}