{
  "article_text": [
    "a standard way to write a multivariate polynomial of degree @xmath5 over @xmath1 is@xmath6 the space of all such polynomials is denoted by @xmath7 .",
    "we consider here the alternative formulation@xmath8 with @xmath9 an orthonormal basis of the set of @xmath7 over the closed unit disk @xmath0 , for each @xmath10 .",
    "there is a large literature on such orthonormal polynomials ; and in contrast to the univariate case , there are many possible choices for this basis .",
    "see dunkl and xu @xcite and xu @xcite for an investigation of such multivariate orthonormal polynomials and a number of particular examples .    to use ( [ eq1 ] ) , it is important to be able to evaluate the orthonormal polynomials @xmath11 efficiently , just as is true with univariate polynomials .",
    "we consider a particularly good set of such polynomials in section [ sec2 ] , one that seems much superior to other choices . in the univariate case ,",
    "the best choices are based on using the triple recursion relation of the particular family @xmath12 being used .",
    "this extends to the multivariate case .",
    "we investigate a particular choice of  an orthonormal basis for @xmath7 that leads to an efficient way to evaluate the expression ( [ eq1 ] ) by making use of the triple recursion relation it satisfies . following that , in section [ sec3 ]",
    ", we also consider the calculation of the least squares approximation over @xmath7 of a given function @xmath13 . in section [ sec4 ] , these results are extended to polynomials over the unit ball .",
    "finally , in section [ sec5 ] , matlab codes are given for all of the problems being discussed .",
    "we review some notation and results from dunkl and xu @xcite and xu @xcite . for convenience ,",
    "we initially denote a point in the unit disk by @xmath14 , and later we revert to the more standard use of @xmath15 .",
    "we consider only the standard @xmath16 inner product @xmath17 define @xmath18 and let @xmath19 denote the one dimensional space of constant functions .",
    "thus @xmath20 is an orthogonal decomposition of @xmath7 .",
    "it is standard to give an orthonormal basis for each space @xmath21 as the way to give an orthonormal basis of @xmath7 .",
    "the dimension of @xmath21 equals @xmath22 , and the dimension of @xmath7 equals@xmath23    introduce @xmath24 ^{\\text{t}},\\quad\\quad n\\geq0,\\ ] ] with @xmath25 an orthonormal basis of @xmath26 . the triple recursion relation for @xmath27",
    "is given by@xmath28 the matrices @xmath29 and @xmath30 are @xmath31 and @xmath32 , respectively , and they are defined as follows:@xmath33 for additional details , see xu ( * ? ? ? * thm .",
    "one wants to use the relation ( [ triple ] ) to solve for @xmath34 .",
    "this amounts to solving an overdetermined system of @xmath35 equations for the @xmath36 components of @xmath34 .",
    "the expense of this will depend on the structure of the matrices @xmath29 and @xmath30 .",
    "there is a well - known choice that leads , fortunately , to the matrices @xmath30 being zero and the matrices @xmath29 being very sparse .    to define this choice , begin by recalling the gegenbauer polynomials",
    "they can be obtained using the following generating function:@xmath38 for particular cases,@xmath39@xmath40 their triple recursion relation is given by@xmath41 these polynomials are orthogonal over @xmath42 with respect to the inner product@xmath43 and for @xmath44 they are the legendre polynomials . for additional information on the gegenbauer polynomials , see ( * ? ? ?",
    "return to the use of @xmath15 in place of @xmath45 .",
    "using the gegenbauer polynomials , introduce @xmath46 for @xmath47 and @xmath48 .",
    "see dunkl and xu @xcite .",
    "note that@xmath49 the lead constant @xmath50 is given by@xmath51 and @xmath52 .",
    "the set @xmath53 is an orthonormal basis of @xmath26 , and @xmath54 is an orthonormal basis of @xmath7 , using the inner product of ( [ inner ] ) . here",
    "are the @xmath55 of degrees 0,1,2,3.@xmath56@xmath57@xmath58{ll}$q_{3}^{0}\\left (   x , y\\right )   = \\dfrac{4}{\\sqrt{\\pi}}x\\left (   2x^{2}-1\\right ) $ & $ \\quad q_{3}^{1}\\left (   x , y\\right )   = \\dfrac{4}{\\sqrt{5\\pi}}y\\left ( 6x^{2}-1\\right )   , \\smallskip$\\\\ $ q_{3}^{2}\\left (   x , y\\right )   = \\dfrac{4}{\\sqrt{\\pi}}x\\left (   3y^{2}+x^{2}-1\\right )   $ & $ \\quad q_{3}^{3}\\left (   x , y\\right )   = \\dfrac{4}{\\sqrt { 5\\pi}}y\\left (   5y^{2}-3 + 3x^{2}\\right )   .$\\end{tabular } \\label{poly3}\\ ] ] because the formula ( [ orthobasis ] ) is not well - defined at @xmath59 , we use@xmath60{c}0,\\quad\\quad k>0\\\\ 1,\\quad\\quad k=0 \\end{array } \\right.\\ ] ] when evaluating ( [ orthobasis ] ) .    applying ( [ triple ] ) to",
    "this choice of orthonormal polynomials leads to @xmath61 the coefficient matrices are given by@xmath62{ccccc}a_{0,n } & 0 & \\cdots & 0 & 0\\\\ 0 & a_{1,n } &   & 0 & 0\\\\ \\vdots &   & \\ddots & \\vdots & \\vdots\\\\ 0 & 0 & \\cdots & a_{n , n } & 0 \\end{array } \\right]\\]]@xmath63{cccccc}0 & d_{0,n } & 0 & \\cdots & 0 & 0\\\\ c_{1,n } & 0 & d_{1,n } & \\ddots & 0 & 0\\\\ \\vdots & \\ddots & \\ddots & \\ddots & \\vdots & \\vdots\\\\ 0 & \\cdots & c_{n-1,n } & 0 & d_{n-1,n } & 0\\\\ 0 & \\cdots & 0 & c_{n , n } & 0 & d_{n , n}\\end{array } \\right]\\]]@xmath58{l}$a_{k , n}=\\dfrac{1}{2}\\sqrt{\\dfrac{\\left (   n - k+1\\right )   \\left (   n+k+2\\right ) } { \\left (   n+1\\right )   \\left (   n+2\\right )   } } , \\medskip$\\\\ $ d_{k , n}=\\dfrac{k+1}{2}\\sqrt{\\dfrac{\\left (   n+k+3\\right )   \\left ( n+k+2\\right )   } { \\left (   2k+1\\right )   \\left (   2k+3\\right )   \\left (   n+1\\right ) \\left (   n+2\\right )   } } , \\medskip$\\\\ $ c_{k , n}=-\\dfrac{k}{2}\\sqrt{\\dfrac{\\left (   n - k+1\\right )   \\left (   n - k+2\\right ) } { \\left (   n+1\\right )   \\left (   n+2\\right )   \\left (   2k-1\\right )   \\left ( 2k+1\\right )   } } . $ \\end{tabular}\\ ] ] these results are taken from dunkl and xu @xcite ( in the formula for @xmath64 , change @xmath65 to @xmath66 ) .    from the first triple recursion relation in ( [ triple2 ] ) , @xmath67{c}q_{n}^{0}\\\\ q_{n}^{1}\\\\ \\vdots\\\\ q_{n}^{n}\\end{array } \\right ]    &   = \\left [ \\begin{array } [ c]{ccccc}a_{0,n } & 0 & \\cdots & 0 & 0\\\\ 0 & a_{1,n } &   & 0 & 0\\\\ \\vdots &   & \\ddots & \\vdots & \\vdots\\\\ 0 & 0 & \\cdots & a_{n , n } & 0 \\end{array } \\right ]   \\left [ \\begin{array } [ c]{c}q_{n+1}^{0}\\\\ q_{n+1}^{1}\\\\ \\vdots\\\\ q_{n+1}^{n}\\\\ q_{n+1}^{n+1}\\end{array } \\right ]   \\smallskip\\\\ &   + \\left [ \\begin{array } [ c]{cccc}a_{0,n-1 } & 0 & \\cdots & 0\\\\ 0 & a_{1,n-1 } &   & 0\\\\ \\vdots &   & \\ddots & \\vdots\\\\ 0 &   &   & a_{n-1,n-1}\\\\ 0 & 0 & \\cdots & 0 \\end{array } \\right ]   \\left [ \\begin{array } [ c]{c}q_{n-1}^{0}\\\\ q_{n-1}^{1}\\\\ \\vdots\\\\ q_{n-1}^{n-1}\\end{array } \\right]\\end{aligned}\\]]@xmath68 this allows us to solve for @xmath69 . the second triple recursion relation in ( [ triple2 ] )",
    "yields@xmath70{c}q_{n}^{0}\\\\ q_{n}^{1}\\\\ \\vdots\\\\ q_{n}^{n}\\end{array } \\right ]    &   = \\left [ \\begin{array } [ c]{cccccc}0 & d_{0,n } & 0 & \\cdots & 0 & 0\\\\ c_{1,n } & 0 & d_{1,n } & \\ddots & 0 & 0\\\\ \\vdots & \\ddots & \\ddots & \\ddots & \\vdots & \\vdots\\\\ 0 & \\cdots & c_{n-1,n } & 0 & d_{n-1,n } & 0\\\\ 0 & \\cdots & 0 & c_{n , n } & 0 & d_{n , n}\\end{array } \\right ]   \\left [ \\begin{array } [ c]{c}q_{n+1}^{0}\\\\ q_{n+1}^{1}\\\\ \\vdots\\\\ q_{n+1}^{n}\\\\ q_{n+1}^{n+1}\\end{array } \\right ]   \\smallskip\\\\ &   + \\left [ \\begin{array } [ c]{cccccc}0 & c_{1,n-1 } & 0 & \\cdots &   & 0\\\\ d_{0,n-1 } & 0 & c_{2,n-1 } & 0 & \\cdots & 0\\\\ 0 & d_{1,n-1 } & 0 & c_{3,n-1 } &   & 0\\\\ 0 & 0 & d_{2,n-1 } & \\ddots & \\ddots & \\\\ \\vdots &   &   & \\ddots & \\ddots & c_{n-1,n-1}\\\\ 0 &   &   &   & d_{n-2,n-1 } & 0\\\\ 0 & 0 & 0 & \\cdots & 0 & d_{n-1,n-1}\\end{array } \\right ]   \\left [ \\begin{array } [ c]{c}q_{n-1}^{0}\\\\ q_{n-1}^{1}\\\\ \\vdots\\\\ q_{n-1}^{n-1}\\end{array } \\right]\\end{aligned}\\ ] ] its last equation is@xmath71 and from it we can calculate @xmath72 .",
    "thus,@xmath73      what is the cost of using this to evaluate the orthonormal basis @xmath74 assume the coefficients @xmath75 have been computed",
    ". apply ( [ q1])-([q3 ] ) to the computation of @xmath76 , assuming the lower degree polynomials of degrees @xmath77 and @xmath78 are known .",
    "this requires @xmath79 arithmetic operations .",
    "the evaluation of @xmath80 from ( [ poly1 ] ) requires 2 arithmetic operations for each choice of @xmath81 .",
    "thus the calculation of @xmath82 requires@xmath83 arithmetic operations .",
    "recall ( [ dimen ] ) that the dimension of @xmath7 is approximately @xmath84 , and thus the cost of evaluating @xmath82 is only approximately 4 times the dimension of @xmath7 .",
    "qualitatively this is the same as in the univariate case . to evaluate a polynomial @xmath85 for which @xmath86 are given",
    ", we use @xmath87 arithmetic operations , approximately 6 times the dimension @xmath88 of @xmath89 .",
    "there are other known choices of an orthonormal basis for @xmath7 ; see dunkl and xu @xcite and xu @xcite . in a number of previous papers ( see @xcite , @xcite , @xcite , @xcite ) we have used the ` ridge polynomials ' of @xcite , in large part because of their simple analytic form  that is based on chebyshev polynomials of the second kind . however , we have calculated experimentally the matrices @xmath90 and have found them to be dense for low order cases , leading us to believe the same is true for larger values of @xmath5 .",
    "for that reason , solving the triple recursion relation ( [ triple ] ) would be much more costly than @xmath91 operations , making the choice ( [ orthobasis ] ) preferable in computational cost . as a particular example of the lack of sparsity in the coefficient matrices @xmath92 for the ridge polynomials , @xmath93{cccc}\\frac{1}{2 } & 0 & 0 & 0\\smallskip\\\\ 0 & \\frac{\\sqrt{2}}{8}+\\frac{\\sqrt{6}}{12 } & -\\frac{\\sqrt{3}}{12 } & -\\frac{\\sqrt{2}}{8}+\\frac{\\sqrt{6}}{12}\\smallskip\\\\ 0 & \\frac{\\sqrt{2}}{8}-\\frac{\\sqrt{6}}{12 } & \\frac{\\sqrt{3}}{12 } & -\\frac{\\sqrt{2}}{8}-\\frac{\\sqrt{6}}{12}\\end{array } \\right]\\]]@xmath94{cccc}0 & \\frac{\\sqrt{2}}{6 } & -\\frac{1}{6 } & \\frac{\\sqrt{2}}{6}\\smallskip\\\\ -\\frac{\\sqrt{3}}{12 } & \\frac{\\sqrt{2}}{24}+\\frac{\\sqrt{6}}{12 } & \\frac{1}{3 } & \\frac{\\sqrt{2}}{24}-\\frac{\\sqrt{6}}{12}\\smallskip\\\\ \\frac{\\sqrt{3}}{12 } & \\frac{\\sqrt{2}}{24}-\\frac{\\sqrt{6}}{12 } & \\frac{1}{3 } & \\frac{\\sqrt{2}}{24}+\\frac{\\sqrt{6}}{12}\\end{array } \\right]\\ ] ]      first derivatives of the orthonormal polynomials",
    "are required when implementing the spectral methods of @xcite , @xcite , @xcite , @xcite ) . from ( [ poly1 ] ) , ( [ poly2]),@xmath95{ll}\\dfrac{\\partial q_{0}^{0}}{\\partial x_{1}}=0 , & \\dfrac{\\partial q_{0}^{0}}{\\partial x_{2}}=0,\\medskip\\\\ \\dfrac{\\partial q_{1}^{0}}{\\partial x_{1}}=\\dfrac{2}{\\sqrt{\\pi } } , & \\dfrac{\\partial q_{1}^{0}}{\\partial x_{2}}=0\\medskip\\\\ \\dfrac{\\partial q_{1}^{1}}{\\partial x_{1}}=0 , & \\dfrac{\\partial q_{1}^{1}}{\\partial x_{2}}=\\dfrac{2}{\\sqrt{\\pi}}\\end{array}\\ ] ] to obtain the first derivatives of the higher degree polynomials , we differentiate the triple recursion relations of ( [ q1])-([q3 ] ) . in particular,@xmath95{l}\\dfrac{\\partial q_{n+1}^{i}}{\\partial x_{1}}=\\dfrac{1}{a_{i ,",
    "n}}\\left\\ { q_{n}^{i}+x_{1}\\dfrac{\\partial q_{n}^{i}}{\\partial x_{1}}-a_{i , n-1}\\dfrac{\\partial q_{n-1}^{i}}{\\partial x_{1}}\\right\\ }   , \\quad\\quad i=0,1,\\dots , n-1\\medskip\\\\ \\dfrac{\\partial q_{n+1}^{n}}{\\partial x_{1}}=\\dfrac{1}{a_{i , n}}\\left\\ { q_{n}^{n}+x_{1}\\dfrac{\\partial q_{n}^{n}}{\\partial x_{1}}\\right\\ }   \\medskip\\\\ \\dfrac{\\partial q_{n+1}^{n+1}}{\\partial x_{1}}=\\dfrac{1}{d_{n , n}}\\left\\ { x_{2}\\dfrac{\\partial q_{n}^{n}}{\\partial x_{1}}-c_{n , n}\\dfrac{\\partial q_{n+1}^{n-1}}{\\partial x_{1}}-d_{n-1,n-1}\\dfrac{\\partial q_{n-1}^{n-1}}{\\partial x_{1}}\\right\\ } \\end{array } \\label{deriv1}\\]]@xmath95{l}\\dfrac{\\partial q_{n+1}^{i}}{\\partial x_{2}}=\\dfrac{1}{a_{i , n}}\\left\\ { x_{1}\\dfrac{\\partial q_{n}^{i}}{\\partial x_{2}}-a_{i , n-1}\\dfrac{\\partial q_{n-1}^{i}}{\\partial x_{2}}\\right\\ }   , \\quad\\quad i=0,1,\\dots , n-1\\medskip\\\\ \\dfrac{\\partial q_{n+1}^{n}}{\\partial x_{2}}=\\dfrac{x_{1}}{a_{i , n}}\\dfrac{\\partial q_{n}^{n}}{\\partial x_{2}}\\medskip\\\\ \\dfrac{\\partial q_{n+1}^{n+1}}{\\partial x_{2}}=\\dfrac{1}{d_{n , n}}\\left\\ { q_{n}^{n}+x_{2}\\dfrac{\\partial q_{n}^{n}}{\\partial x_{2}}-c_{n , n}\\dfrac{\\partial q_{n+1}^{n-1}}{\\partial x_{2}}-d_{n-1,n-1}\\dfrac{\\partial q_{n-1}^{n-1}}{\\partial x_{2}}\\right\\ } \\end{array } \\label{deriv2}\\ ] ]",
    "when given a function @xmath96 , we are interested in obtaining the least squares approximation to @xmath4 from the polynomial subspace @xmath7 .",
    "when given the basis @xmath82 , this approximation is given by the truncated fourier expansion@xmath97 the linear operator @xmath98 is the orthogonal projection of @xmath99 onto @xmath7 . as an operator on @xmath99",
    ", it has norm 1 . as an operator on @xmath100 with the uniform norm @xmath101",
    ", @xmath98 has norm @xmath102 ; see @xcite .",
    "the fourier coefficients @xmath103 must be evaluated numerically , and we review a standard quadrature scheme to do so . use the formula@xmath104 here the numbers @xmath105 and @xmath106 are the nodes and weights , respectively , of the @xmath107-point gauss - legendre quadrature formula on @xmath108 $ ] .",
    "note that @xmath109 for all single - variable polynomials @xmath110 with @xmath111 . the formula ( [ quad ] )",
    "uses the trapezoidal rule with @xmath112 subdivisions for the integration over @xmath0 in the azimuthal variable .",
    "this quadrature is exact for all polynomials @xmath113 . for functions @xmath114 , let @xmath115 denote the approximation of @xmath116 by the scheme ( [ quad ] ) .",
    "our discrete approximation to ( [ lstsqapprox ] ) is @xmath117 when @xmath118 , this approximation is known as the ` discrete orthogonal projection of @xmath4 onto @xmath7 ' , ` hyperinterpolation of @xmath4 by @xmath7 ' , or the ` discrete least squares approximation ' . we denote it by @xmath119 in applying this numerical integration to the coefficients @xmath120 , we always require @xmath121 in order to force the formula ( [ lstsqapprox ] ) to reproduce all polynomials @xmath122 . with this requirement ,",
    "@xmath123 the operator @xmath124 is a discrete orthogonal projection of @xmath100 onto @xmath7 . for this specific case of approximation over @xmath0 ,",
    "see the discussion in @xcite . in particular,@xmath125",
    "the main computational cost in ( [ dsclstsq ] ) is the evaluation of the coefficients @xmath126 .",
    "we begin with the evaluation of the basis @xmath82 at the  points used in ( [ quad ] ) , of which there are @xmath127 the cost to evaluate @xmath82 will be @xmath128 arithmetic operations .  for comparison , recall that the dimension of @xmath7 is approximately @xmath84 .",
    "the evaluation of the function @xmath4 at these same nodes is @xmath129 with @xmath130 the cost of an individual evaluation of the function @xmath4 .",
    "the subsequent evaluations of the coefficients @xmath126 involves an additional@xmath131 arithmetic operations . having the coefficients @xmath126 ,",
    "the polynomial ( [ dsclstsq ] ) then requires @xmath132 arithmetic operations for each evaluation point @xmath15 .    in the case",
    "@xmath118 , the evaluation of @xmath133 is dominated by ( [ cost1 ] ) and ( [ cost3 ] ) , approximately @xmath134 arithmetic operations .",
    "if we then evaluate @xmath135 at the points used in the quadrature formula ( [ quad ] ) , then the cost is an additional @xmath136 operations , approximately .",
    "because the polynomials are dense in @xmath99 , we have @xmath137 for convergence in @xmath100 , we refer to the presentation in ( * ? ? ?",
    "* ,  5.7.1 ) . in particular,@xmath138 where@xmath139 the minimax error in the approximation of @xmath4 by polynomials from @xmath7",
    "let @xmath140 , functions that are @xmath141times continuously differentiable and whose @xmath142 derivatives are hlder continuous with exponent @xmath143 $ ] then@xmath144 combining these results with ( [ bound1])-([bound2 ] ) gives uniform convergence of both @xmath145 and @xmath133 to @xmath4 for all @xmath140 with @xmath146 .",
    "in this section we repeat for the three dimensional case some of the results from the two dimensional case of sections [ sec2 ] and [ sec3 ] . the orthonormal polynomials in this case",
    "are again taken from ( * ? ? ?",
    "* proposition 2.3.2 ) . here",
    "we first derive the coefficients of the three term recursion relation in ( [ triple2 ] ) .",
    "the orthonormal polynomials for the three dimensional unit ball are given by @xmath147 where @xmath148 , and @xmath149 is the degree of the polynomial @xmath150 .",
    "the normalization constant @xmath151 will be derived further below .",
    "we introduce the vector of all orthonormal polynomials @xmath152 of degree @xmath5 : @xmath153^{t},\\quad n\\geq0 . \\label{eq4002}\\ ] ] here we have @xmath154 polynomials of degree @xmath5 and the space @xmath7 has dimension @xmath155 , see @xcite . in formula ( [ triple2 ] )",
    "we have matrices @xmath29 , @xmath156 , of dimension @xmath157 .",
    "first we derive the normalization constant @xmath151 with a calculation which is typical for calculations involved in the calculation of the coefficients of the matrices @xmath29 . by definition",
    "we have @xmath158 using the substitution @xmath159 we get @xmath160}\\int_{-1}^{1}(c_{n - j - k}^{j+k+3/2}(x))^{2}(1-x^{2})^{j}\\\\ &   \\cdot\\int_{-\\sqrt{1-x^{2}}}^{\\sqrt{1-x^{2}}}(c_{j}^{k+1}(\\frac{y}{\\sqrt{1-x^{2}}}))^{2}(1-x^{2}-y^{2})^{k+1/2}\\;dy\\;dx\\end{aligned}\\ ] ] where we defined @xmath161})^{2}:=   &   \\int_{-1}^{1}(c_{k}^{\\mu}(x))^{2}(1-x^{2})^{\\mu -1/2}dx\\nonumber\\\\ &   = \\frac{\\pi\\gamma(2\\mu+k)}{2^{2\\mu-1}k!(\\mu+k)\\gamma^{2}(\\mu ) } \\label{eq4003}\\ ] ] see @xcite .",
    "now we use the substitution @xmath162 to obtain @xmath163}\\int_{-1}^{1}(c_{n - j - k}^{j+k+3/2}(x))^{2}(1-x^{2})^{j+k+1}\\\\ &   \\cdot\\int_{-1}^{1}(c_{j}^{k+1}(u))^{2}(1-u^{2})^{k+1/2}du\\;dx\\\\ &   = n_{k}^{[1/2]}n_{j}^{[k+1]}n_{n - j - k}^{[j+k+3/2]}\\ ] ] if we denote the coefficients of the matrices @xmath29 by @xmath164}$ ] @xmath148 and @xmath165 we get @xmath166 }   &   = \\int_{\\mathbb{b}_{3}}xq_{n}^{j , k}(x , y , z)q_{n+1}^{j^{\\prime},k^{\\prime}}(x , y , z)\\;d(x , y , z)\\\\ a_{j , k;j^{\\prime},k^{\\prime}}^{[n,2 ] }   &   = \\int_{\\mathbb{b}_{3}}yq_{n}^{j , k}(x , y , z)q_{n+1}^{j^{\\prime},k^{\\prime}}(x , y , z)\\;d(x , y , z)\\\\ a_{j , k;j^{\\prime},k^{\\prime}}^{[n,3 ] }   &   = \\int_{\\mathbb{b}_{3}}zq_{n}^{j , k}(x , y , z)q_{n+1}^{j^{\\prime},k^{\\prime}}(x , y , z)\\;d(x , y , z)\\\\ & \\end{aligned}\\ ] ] each of the integrals can be written in the same way as the integral in ( [ eq4004 ] ) and then the two above substitutions together with the orthonormal property of the gegenbauer polynomials allows us to calculate the coefficients of @xmath29 , @xmath156 .",
    "again we obtain very sparsely populated matrices .",
    "equation ( [ triple2 ] ) takes on the following form : @xmath167}q_{n+1}^{j , k}+a_{j , k;j , k}^{[n-1,1]}q_{n-1}^{j , k},:j+k\\leq n \\label{eq4005}\\ ] ] where @xmath168}=\\frac{1}{2}\\big(\\frac{(j+k+n+3)(n+1-j - k)}{(n+5/2)(n+3/2)}\\big)^{1/2 } \\label{eq4006}\\ ] ] and the term @xmath169}$ ] has to be replaced by @xmath170 if @xmath171 .",
    "furthermore we get @xmath172}q_{n+1}^{j+1,k}+a_{j , k;j-1,k}^{[n,2]}q_{n+1}^{j-1,k}\\nonumber\\\\ &   + a_{j+1,k;j , k}^{[n+1,2]}q_{n-1}^{j+1,k}+a_{j-1,k;j , k}^{[n-1,2]}q_{n-1}^{j-1,k},:j+k\\leq n \\label{eq4007}\\ ] ] where the terms of the matrix @xmath173 and @xmath174 have to substituted by zero if @xmath175 or @xmath176 in the case of @xmath173 . here",
    "@xmath177 }   &   = \\frac{1}{4}\\big(\\frac { ( j+2k+2)(j+1)(j+k+n+4)(j+k+n+3)}{(j+k+1)(j+k+2)(n+5/2)(n+3/2)}\\big)^{1/2}\\label{eq4008}\\\\ a_{j , k;j-1,k}^{[n,2 ] }   &   = -\\frac{1}{4}\\big(\\frac{j(j+2k+1)(n+2-j - k)(n+1-j - k)}{(j+k+1)(j+k)(n+3/2)(n+5/2)}\\big)^{1/2 } \\label{eq4009}\\ ] ]",
    "finally we get @xmath178}q_{n+1}^{j , k-1}+a_{j , k;j+2,k-1}^{[n,3]}q_{n+1}^{j+2,k-1}+a_{j , k;j , k+1}^{[n,3]}q_{n+1}^{j , k+1}\\nonumber\\\\ &   + a_{j , k;j-2,k+1}^{[n,3]}q_{n+1}^{j-2,k+1}+a_{j+2,k-1;j , k}^{[n-1,3]}q_{n-1}^{j+2,k-1}+a_{j , k-1;j , k}^{[n-1,3]}q_{n-1}^{j , k-1}\\nonumber\\\\ &   + a_{j-2,k+1;j , k}^{[n-1,3]}q_{n-1}^{j-2,k+1}+a_{j , k+1;j , k}^{[n-1,3]}q_{n-1}^{j , k+1},:j+k\\leq n \\label{eq4010}\\ ] ] where again the terms have to be replaced by zero if the indices are out of the range of the corresponding matrix . here",
    "@xmath179}\\nonumber\\\\ &   = -\\frac{k}{8}\\big(\\frac{(j+2k+1)(j+2k)(n+2-j - k)(n+1-j - k)}{(k+1/2)(k-1/2)(j+k+1)(j+k)(n+3/2)(n+5/2)}\\big)^{1/2}\\label{eq4011}\\\\ &   a_{j , k;j+2,k-1}^{[n,3]}\\nonumber\\\\ &   = -\\frac{k}{8}\\big(\\frac{(j+2)(j+1)(j+k+n+4)(j+k+n+3)}{(k+1/2)(k-1/2)(j+k+1)(j+k+2)(n+3/2)(n+5/2)}\\big)^{1/2}\\label{eq4012}\\\\ &   a_{j , k;j , k+1}^{[n,3]}\\nonumber\\\\ &   = \\frac{k+1}{8}\\big(\\frac{(j+2k+3)(j+2k+2)(j+k+n+4)(j+k+n+3)}{(k+1/2)(k+3/2)(j+k+1)(j+k+2)(n+3/2)(n+5/2)}\\big)^{1/2}\\label{eq4013}\\\\ &   a_{j , k;j-2,k+1}^{[n,3]}\\nonumber\\\\ &   = \\frac{k+1}{8}\\big(\\frac{(n+2-j - k)(n+1-j - k)j(j-1)}{(k+1/2)(k+3/2)(j+k)(j+k+1)(n+3/2)(n+5/2)}\\big)^{1/2 } \\label{eq4014}\\ ] ] the equations ( [ eq4005 ] ) , ( [ eq4007 ] ) , and ( [ eq4010 ] ) allow the calculation of all @xmath180 in the following way",
    ". for @xmath148 we can use ( [ eq4005 ] ) and solve for @xmath180 : @xmath181}q_{n-1}^{j , k}}{a_{j , k;j , k}^{[n,1 ] } } \\label{eq4015}\\ ] ] then we use ( [ eq4007 ] ) for the calculation of @xmath182 , @xmath183 : @xmath184}q_{n+1}^{j-1,n - j}\\nonumber\\\\ &   -a_{j-1,n - j;j , n - j}^{[n-1,2]}q_{n-1}^{j-1,n - j}\\big)\\big / a_{j , n - j;j+1,n - j}^{[n,2 ] } \\label{eq4016}\\ ] ] finally ( [ eq4010 ] ) allows us to calculate @xmath185 @xmath186}_{0,n;0,n-1}q^{0,n-1}_{n+1}- a^{[n,3]}_{0,n;2,n-1}q^{2,n-1}_{n+1}\\nonumber\\\\ &   -a^{[n-1,3]}_{0,n-1;0,n}q^{0,n-1}_{n-1 } \\big)\\big/ a^{[n,3]}_{0,n;0,n+1 } \\label{eq4017}\\ ] ] by taking partial derivatives in equation ( [ eq4015])([eq4017 ] ) we are able to derive recursion formulas for the partial derivatives of the orthonormal polynomials as in ( [ deriv1])([deriv2 ] ) .      similar to section 3 , the least square approximation in @xmath187 for a function @xmath188 is given by @xmath189 where the inner product is given by @xmath190 for practical calculations we have to replace the integral in ( [ eq4020 ] ) by a quadrature rule for @xmath191 .",
    "one choice is to use a quadrature rule which will integrate polynomials of degree smaller or equal to @xmath192 exactly , so we have @xmath193 we will use @xmath194\\medskip\\nonumber\\\\ q_{q}[g ]   &   : = \\sum_{i=1}^{2q}\\sum_{j=1}^{q}\\sum_{k=1}^{q}\\frac{\\pi}{q}\\,\\omega_{j}\\,\\nu_{k}\\widetilde{g}\\left (   \\frac{\\zeta_{k}+1}{2},\\frac { \\pi\\;i}{2q},\\arccos(\\xi_{j})\\right )   \\label{eq4022}\\ ] ] @xmath195 . here",
    "@xmath196 is the representation of @xmath197 in spherical coordinates . for the @xmath198 integration we use the trapezoidal rule , because the function is @xmath199periodic in @xmath198 .",
    "for the @xmath200 direction we use the transformation @xmath201 where the @xmath202 and @xmath203 are the weights and the nodes of the gauss quadrature with @xmath204 nodes on @xmath205 $ ] with respect to the inner product @xmath206 the weights and nodes also depend on @xmath204 but we omit this index . for the @xmath207 direction we use the transformation @xmath208 where the @xmath209 and @xmath210 are the nodes and weights for the gauss",
    " legendre quadrature on @xmath205 $ ] .",
    "this quadrature rule has been used in our earlier articles , see @xcite . for more information on this quadrature rule on the unit ball in @xmath3 ,",
    "see @xcite . for the complexity estimation in the next section",
    "we will assume that we use the smallest possible @xmath204 to satisfy ( [ eq4021 ] ) which is @xmath211 .",
    "although a little bit larger values of @xmath204 might improve the approximation property of ( [ eq4019 ] ) in practice . with this value of @xmath204",
    "the quadrature formula ( [ eq4022 ] ) uses @xmath212 points in the unit ball @xmath2 .    the discrete @xmath16 projection is now given by @xmath213q_{m}^{j , k}(x , y , z ) \\label{eq4023}\\ ] ]    regarding the convergence of the convergence of @xmath145 towards @xmath214 in @xmath187 and @xmath215 we have similar results to section 3.2 . because the polynomials are dense we have convergence in @xmath187 and formulas ( [ bound1 ] ) and ( [ bound2 ] ) hold as before , and the same is true for the estimate for @xmath216 in ( [ bound3 ] ) .",
    "but the lebesgue constant for the projection @xmath98 in @xmath215 is larger , @xmath217 see @xcite .",
    "together with ( [ bound3 ] ) we obtain the convergence in @xmath218 for functions which are in @xmath219 , @xmath220 .    for the bound of @xmath221 we can use the same arguments as in ( 2.10)(2.18 ) of our previous article @xcite together with the results about the reproducing kernel in @xcite .",
    "this shows @xmath222 and proves the convergence of the discrete @xmath16 approximation in the inifinity norm for functions which are in @xmath223 , @xmath224 .",
    "first we give here a brief analysis of the computational cost to evaluate all polynomials @xmath225 in @xmath7 at a given point .",
    "we assume again , that all coefficients in ( [ eq4015])([eq4017 ] ) have been calculated .",
    "if we further assume that @xmath225 and @xmath226 have been calculated then ( [ eq4015 ] ) , for @xmath227 , constitutes the dominant work for the calculation of @xmath228 , @xmath229 . to evaluate ( [ eq4015 ] ) for @xmath227 requires @xmath230 arithmetic operations .",
    "the evaluation of ( [ eq4016 ] ) and ( [ eq4017 ] ) will not change this asymptotic behavior . adding these up for @xmath231 leads to a total number of arithmetic operations given by @xmath232 .",
    "if we further consider the problem to evaluate the polynomial @xmath233 we have to add another @xmath234 operations , which means that the evaluation of ( [ eq4018 ] ) requires a total @xmath235 operations , if the recursion coefficients are known .",
    "the set @xmath7 has @xmath236 elements , so about 6 operations are needed in average per basis functions , exactly the same as in section 2 .    to calculate the discrete @xmath16 projection ( [ eq4023 ] )",
    "we first need to evaluate @xmath4 at the @xmath237 quadrature points of @xmath238 , this requires an effort of @xmath239 , where @xmath130 again measures the cost of an individual evaluation of @xmath4 .",
    "then we have to calculate all basis functions @xmath240 in @xmath7 for all @xmath241 points .",
    "this requires @xmath242 operations .",
    "the calculation of a single @xmath243 $ ] requires @xmath244 operations and we have to do this for all @xmath245 basis functions of @xmath7 which results in an additional @xmath246 operations .",
    "if we assume that the @xmath130 is less than @xmath247 we see that the evaluation of the discrete inner products @xmath248 $ ] is the dominant term and the complexity of the calculation of ( [ eq4023 ] ) is given by @xmath249 .",
    "we present matlab programs for using orthonormal polynomials over the unit disk .",
    "we compute the coefficients @xmath75 , the basis @xmath82 , and the discrete least squares approximation ( [ dsclstsq ] ) with @xmath121 . the program ` triplerecurcoeff ` is used to produce the needed coefficients @xmath250 , the program ` evalorthopolys ` is used to evaluate the polynomials in the basis @xmath82 , and the program ` leastsqcoeff `  evaluates the coefficients in ( [ dsclstsq ] ) .",
    "the program ` evallstsq ` is used to evaluate @xmath251 at a selected set of nodes in @xmath0 ; it also evaluates the error and produces various graphs of the error as the degree @xmath5 is increased .",
    "the program ` test_evallstsq ` is used to test the programs just listed .",
    "consider the function@xmath252 this was approximated using ` test_evallstsq ` for degrees 1 through 30 .",
    "figure [ approxdeg30 ] shows @xmath253 and figure [ errordeg30 ] shows its error .",
    "the error as it varies with the degree @xmath5 is shown in figure [ degvserror ] .",
    "this last graph suggests an exponential rate of convergence for @xmath254 to @xmath4 .",
    "we have found often that the error @xmath255 is slightly smaller than that of @xmath256 if @xmath204 is taken a small amount larger than @xmath5 , say @xmath257 . however , the qualitative behaviour shown in figure [ degvserror ] is still valid for @xmath258 .",
    "these programs can also be used for constructing approximations over other planar regions @xmath259 .",
    "for example , the mapping @xmath260 with @xmath261 , can be used to create polynomial approximations to a function defined over the ellipse@xmath262 if polynomials are not required , only an approximating function , then mappings @xmath263 with @xmath264 a 1 - 1 mapping can be used to convert an approximation problem over a planar region @xmath259 to one over @xmath0 .",
    "the construction of such mappings @xmath264 is explored in @xcite .",
    "k. atkinson , o .",
    "hansen , and d. chien .  a spectral method for parabolic differential equations , _ numerical algorithms _",
    ", doi 10.1007/s11075 - 012 - 9620 - 8 , to appear .",
    "a preliminary version is available at http://arxiv.org/abs/1203.6709      o. hansen , k. atkinson , and d. chien . on the norm of the hyperinterpolation operator on the unit disk and its use for the solution of the nonlinear poisson equation , _",
    "i m a  j. numerical analysis _",
    "* 29 * ( 2009 , 257 - 283 , doi : 10.1093/imanum / drm052 ."
  ],
  "abstract_text": [
    "<S> we investigate the use of orthonormal polynomials over the unit disk @xmath0 in @xmath1 and the unit ball @xmath2 in @xmath3 . an efficient evaluation of an orthonormal polynomial basis is given , and it is used in evaluating general polynomials over @xmath0 and @xmath2 . </S>",
    "<S> the least squares approximation of a function @xmath4 on the unit disk by polynomials of a given degree is investigated , including how to write a polynomial using the orthonormal basis . </S>",
    "<S> matlab codes are given . </S>"
  ]
}