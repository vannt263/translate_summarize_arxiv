{
  "article_text": [
    "individual - level information such as health data collected by , for example , government agencies , are often not publicly available in order to preserve confidentiality . on the other hand ,",
    "there is public demand on these individual - level data for research purposes . as an example ,",
    "associations of individual health with various risk factors are of great interest and concern nowadays . statistical research that addresses these two competing needs",
    "is known as _ statistical disclosure limitation _",
    ", where a large number of methods are developed on how to process and release information that is subject to confidentiality concern  [ @xcite ; @xcite ; @xcite ( @xcite , @xcite ) ] . in this paper",
    "we refer to those methods that alter the original data values as `` data masking . ''",
    "corresponding to the two competing needs , a  data masking method should be evaluated from both the utility of the masked data which represents the information retained after the masking , and the disclosure risk of the masked data which is the risk that a data intruder can obtain confidential information ( e.g. , obtain original data values and/or identify an individual to whom a data record belongs ) .",
    "ideally , masked data would have low disclosure risk while preserving data utility as much as possible .",
    "examples of commonly used data masking methods include aggregated tabular counts for categorical data  [ @xcite ] , data swapping which exchanges values between selected records , with its various extensions  [ @xcite ; @xcite ] , cell suppression where certain cells of contingency tables are not displayed  [ @xcite ] , simulating synthetic data which have the same ( conditional ) distribution as the original data  [ @xcite ; @xcite ; @xcite ; @xcite ( @xcite , @xcite ) ] , and additive random noise for continuous variables  [ @xcite ; @xcite ; @xcite ; @xcite ] , etc .    among these methods , data aggregation ,",
    "data swapping , additive random noise and many other methods can be formulated as _ matrix masking _ [ @xcite ] .",
    "suppose data on @xmath0 observations and @xmath1 variables are stored in a @xmath2 matrix .",
    "matrix masking takes the general form of @xmath3 , where @xmath4 is the original data matrix and @xmath5 is the masked data matrix .",
    "matrices @xmath6 , @xmath7 and @xmath8 are row  ( observation ) operator , column  ( variable ) operator and random noise , respectively .",
    "links between the above masking methods to matrix masking are investigated in  @xcite , @xcite , @xcite and @xcite .",
    "measuring and evaluating utility of masked data is important . in general",
    "there are two classes of utility measures .",
    "one is global utility measures which reflect the general distribution of masked data compared to that of the original data and are not specific to any analysis .",
    "such measures include the number of swaps in data swapping , the added variance in the additive random noise approach , differences between continuous original and masked data in their first and second moments , etc .",
    "more sophisticated measures that compare distributions of masked and original data can be found in @xcite , @xcite and @xcite . in addition , bayesian decision theory - based utility is discussed in  @xcite and  @xcite .",
    "the  second class of utility measures is analysis - specific tailored to analysts inference . for the utility associated with regression inference , @xcite examine the overlap in the confidence intervals of linear regression coefficients estimated with original and masked data .",
    "@xcite and @xcite show for the additive random noise approach that if masked data preserve the first two moments of original data , then coefficient estimates from linear regression using masked data are ( approximately ) unbiased .",
    "in addition , the methods of aggregated tabular counts and data swapping can produce valid results for loglinear models because they preserve the marginal total of contingency tables .",
    "this is equivalent to preserving sufficient statistics for loglinear models , given that the margins of all higher - order interactions that appear in the model are preserved  [ @xcite ; @xcite ] .",
    "recently , @xcite investigated logistic regression inference for contingency tables that preserve marginal total or conditional probabilities .",
    "however , for a general data structure additional research is needed .",
    "for example , bias and variance of parameter estimates from nonlinear regression using masked data are not quantified as functions of masking parameters .",
    "we propose a special case of matrix masking where we construct row ( observation ) transformed data , that is , @xmath9 , using spatial smoothing .",
    "we investigate the mean square error ( mse ) of the regression parameter estimates when fitting a generalized linear model  ( glm ) to the masked data , and we provide guidance on how to select the masking parameters to reduce the mse .",
    "specifically , for both regressors and outcome we construct masked data which are weighted averages of the original individual - level data by using linear smoothers .",
    "the  shape of the smoothing weight function defines the `` form '' of masking and the smoothness parameter measures the `` degree '' of masking . by choosing an appropriate weight function and smoothness parameter value ,",
    "the masked data can account for prior knowledge on the spatial pattern of individual - level data , and parameter estimates from nonlinear regression using such masked data may be less subject to bias and mse .",
    "although data utility is our main focus , we also evaluate identification disclosure risk .",
    "we consider the scenario wherein a data intruder has correct information on the risk factor regressors ( e.g. , exposure or demographic data ) from some external data sources , and his / her objective is to obtain the confidential information on the health outcome through record matching .",
    "using our method , we can evaluate both the utility and the disclosure risk as functions of the form and the degree of masking , which produces a risk - utility profile and can facilitate the selection of the masking parameters .",
    "we also derive a closed - form expression for calculating the first - order bias of the regression parameter estimates when estimated using the masked data , for any assumed distribution of the outcome given the regressors in the exponential family .",
    "we apply our method to a study of racial disparities in risks of mortality for a large sample of the u.s .",
    "medicare population .",
    "this study consists of more than 4  million individuals in the northeast region of the united states .",
    "we develop and apply statistical models to estimate the age and gender adjusted association between race and risks of mortality when using both the original individual - level data and the masked data .",
    "the  estimated association obtained from using the original individual - level data is the gold - standard , and we compare it to the estimated association obtained from using the masked data .",
    "we also calculate the identification disclosure risk of the masked data sets .    in section  [ sec2 ]",
    "we detail the method , and in section  [ sec3 ] we present the simulation studies . in section  [ sec4 ]",
    "we apply our method to the medicare data set , and in section  [ sec5 ] we discuss the method and the results .",
    "the  r code is provided in the supplement [ zhou , dominici and louis ( @xcite ) ] , while the medicare data set is not provided due to a confidentiality agreement .",
    "derivation of the closed - form expression for the first - order bias of the glm regression parameter estimates when estimated using the masked data is presented in the .",
    "assume that the outcome variable @xmath10 and the regressors @xmath11 are spatial processes @xmath12 , and the observed individual - level data @xmath13 are realizations of the spatial processes at locations @xmath14 , that is , @xmath15 , @xmath16 .",
    "we construct masked data at @xmath17 using spatial smoothing , and we show later that this masking approach is a special case of matrix masking by row  ( observation ) transformation .",
    "let @xmath18 denote the relative weight assigned to data at location @xmath19 when generating smoothed data for the target location @xmath20 , where @xmath21 is a smoothness parameter , and @xmath22 denotes all spatial locations in a study area so @xmath17 is a subset of @xmath22 .",
    "the  parameter @xmath23 controls the degree of smoothness , with smoothness increasing with @xmath23 . for notational convenience",
    "we suppress the dependence of @xmath24 on @xmath22 .",
    "we consider a subclass of linear smoothers under which the smoothed spatial processes at location @xmath20 are defined as follows . for @xmath25 , @xmath26\\\\[-8pt ] \\mathbf{x}_{\\lambda}(u ) & = & \\int\\mathbf{x}(s)w_\\lambda ( u , s)\\,dn(s ) \\big/ \\int w_\\lambda(u , s)\\,dn(s )    \\nonumber,\\end{aligned}\\ ] ] where @xmath27 is the counting process for locations with available data from the spatial processes @xmath12 . for @xmath28 we require that @xmath29 .",
    "if @xmath24 is continuous in @xmath23 , we define @xmath30 as @xmath31 . therefore , we have that @xmath32 , the original individual - level data .",
    "we generate masked data by taking the predictions from  ( [ sm ] ) at @xmath17 where the original individual - level data are available , that is , @xmath33 . by definition in  ( [ sm ] ) , the masked data are weighted averages of the original individual - level data @xmath34 .",
    "the  shape of the weight function @xmath24 and the degree of smoothness @xmath23 control the form and the degree of masking , respectively , where the degree of masking increases with the degree of smoothness . in practice ,",
    "the masked data at location @xmath35 are computed by @xmath36\\\\[-8pt ] \\mathbf{x}_\\lambda(s_i ) & = & \\sum _ { k=1}^n \\mathbf{x}_k w_\\lambda(s_i , s_k ) \\bigg/ \\sum_{k=1}^n w_\\lambda(s_i , s_k ) , \\nonumber\\end{aligned}\\ ] ] where the same @xmath37 and @xmath23 are applied to both @xmath10 and @xmath11 .",
    "examples of commonly used smoothers within this class include parametric linear regressions fitted by ordinary least square and weighted least square , penalized linear splines with truncated polynomial basis , kernel smoothers and loess smoothers  [ @xcite ; @xcite ; @xcite ; @xcite ] .",
    "let @xmath38 and @xmath39 denote the vectors of @xmath40 and @xmath41 , and let @xmath42 and @xmath43 denote the matrices of @xmath44 and @xmath45 , respectively , where @xmath46 and @xmath47 , are row vectors .",
    "it can be seen that @xmath48 and @xmath49 , where @xmath50 .",
    "therefore , constructing masked data by equation  ( [ smsum ] ) is a special case of matrix masking by row  ( observation ) transformation .",
    "reidentification from @xmath51 to @xmath52 requires knowledge of both @xmath24 and  @xmath23 as well as the existence of @xmath53 .",
    "bias may arise when a nonlinear model that is specified for the original individual - level data is fitted to the masked data . specifically",
    ", we assume the following model for the original individual - level data which is viewed as the `` truth , '' @xmath54 model ( [ indimodel ] ) implies the analogous model for the masked data @xmath55 only for a linear function @xmath56 , where @xmath57 is a constant  ( except for few special circumstances such as @xmath58 , i.e. , constant exposure ) .",
    "specifically , @xmath59 it follows that for a nonlinear regression model  ( [ indimodel ] ) , the coefficient estimate obtained by fitting model  ( [ maskmodel ] ) will be a biased estimate of @xmath60 .",
    "therefore , it is important to evaluate the bias of the coefficient estimate under model  ( [ maskmodel ] ) as well as how the bias varies as a function of the form and the degree of data masking . to consider both the bias and variance of the coefficient estimate obtained by fitting model  ( [ maskmodel ] ) , we evaluate the mse as a function of the form and the degree of masking .",
    "it is common to assume that the masked data are mutually independent .",
    "however , they are generally correlated , since they combine information across the same original data . to investigate the impact of this correlation on the uncertainty of the coefficient estimate when using the masked data",
    ", we compare the `` naive '' confidence interval under model  ( [ maskmodel ] ) which does not account for this correlation with an appropriate confidence interval obtained by using simulation or bootstrap methods  [ @xcite ; @xcite ] .",
    "we evaluate the identification disclosure risk of the masked data by calculating the probability of identification as developed in  @xcite . to compute the risk of the released masked data set ,",
    "we first compute the probability of matching for a particular data record .    specifically , let @xmath61 denote the unmasked data set and @xmath62 denote the released masked data set .",
    "let @xmath63 denote a data vector possessed by a data intruder , where @xmath63 contains the true values for a particular individual .",
    "@xmath64 can be divided into two components : @xmath65 which consists of variables that are not available in @xmath63 , and @xmath66 which consists of variables that are available in @xmath63 .",
    "@xmath67 is the same decomposition of the true data set .",
    "let @xmath68 be a random variable that equals @xmath69 if to match @xmath63 with the @xmath69th individual in @xmath64 .",
    "the  probability of matching is @xmath70 , assuming that @xmath63 always corresponds to an individual within  @xmath71 .",
    "assumptions about the knowledge and behavior of the intruder are used to determine this probability . using bayes rule , @xmath72 where @xmath73 can be decomposed into @xmath74 following the guidance in  @xcite , we compute each component of @xmath75 as follows :    1 .",
    "this is because the true values are replaced by some weighted averages upon releasing , so exact matching between @xmath63 and any @xmath77 record is not possible .",
    "@xmath78 equals @xmath79 which is the tail probability of a uniform distribution with density @xmath80 .",
    "we assume the intruder knows that the masked data are weighted averages of the original data . as we point out at the end of section  [ method ] , detailed information on @xmath24 and @xmath23",
    "shall not be released .",
    "therefore , it is a reasonable assumption that the intruder will assume a uniform distribution based on the difference from @xmath63 .",
    "the  larger the difference , the smaller the probability .",
    "@xmath81 is computed through @xmath82 where @xmath83 , @xmath84 is obtained through regression of @xmath85 on @xmath66 , and the integral is computed using monte carlo integration .",
    "4 .   latexmath:[$\\operatorname{pr}(\\mathbf{z } _ { \\lambda,1 } , \\ldots,\\mathbf{z } _ { \\lambda , j-1},\\mathbf{z } _ { \\lambda , j+1},\\ldots,\\mathbf{z } _ { \\lambda ,",
    "n }    to be equal to 1 .",
    "as pointed out in  @xcite , such assumption provides the upper limit on the identification risks and greatly simplifies the calculation .    assuming a record @xmath63 is matched to the individuals with the largest probability of matching , we measure the identification disclosure risk of the entire released data set using the expected percentage of correct matches .",
    "same as in  @xcite , we assume that the intruder possesses correct records for all individuals in the released data set and seeks to match each record with an individual with replacement , that is , matching of one record is independent from matching of another record .",
    "let @xmath87 be the number of individual records with the maximum matching probability for @xmath88 .",
    "let @xmath89 if the @xmath87 individual records contain the correct match , and @xmath90 otherwise .",
    "the  expected percentage of correct matches is @xmath91 .",
    "in this section we conduct simulation studies to illustrate that parameter estimates from regression using masked data may be less subject to bias and mse when the selection of the smoothing weight function accounts for the spatial patterns of exposure .",
    "we illustrate this point using three examples . in each case",
    ", we define the study area to be @xmath92\\times[-1,1]$ ] . within this study area",
    "we randomly select 1000 locations as @xmath17 where individual - level exposure and outcome data are obtained .    in each example",
    ", we define a spatial process of exposure @xmath93 and we obtain @xmath94 for @xmath95 . we simulate the individual - level outcome data at @xmath17 from a model of the general form @xmath96 with the individual - level exposure coefficient @xmath97 being the parameter of interest .",
    "the  values of @xmath98 and @xmath97 are selected to achieve reasonable variability of @xmath99 under model  ( [ llindi ] ) across the locations .",
    "we construct the masked data @xmath100 using kernel smoothers , and we estimate the exposure coefficient @xmath101 under model @xmath102 which is analogous to model  ( [ llindi ] ) but fitted to the masked data .",
    "the  masked data are constructed and @xmath101 is estimated for each combination of 20 @xmath23 values and two different kernel weights , respectively , so we can evaluate the bias and the mse as functions of both the smoothing weight and @xmath23 .",
    "in addition , we construct spatially aggregated data by equally partitioning the study area into @xmath103 cells and calculating @xmath104 and @xmath105 , where @xmath106 is the total number of individual - level data points in cell  @xmath69 , @xmath107 .",
    "we estimate the exposure coefficient @xmath108 using the aggregated data @xmath109 under the analogous model @xmath110    to evaluate the identification disclosure risk , we consider the scenario that a data intruder possesses the correct exposure data , that is , @xmath94 for @xmath95 , and seeks the matches with the released data set in order to obtain information on the health outcome @xmath10 .",
    "specifically , @xmath111 is @xmath112 and @xmath113 is @xmath10 .",
    "we generate 500 replicates of the individual - level outcome data . for each replicate @xmath114 and @xmath108",
    "are estimated as above , and the estimates are averaged across the 500 replicates .",
    "to select a weight function that may lead to less bias and possibly smaller mse when estimating the exposure coefficient using the masked data , we notice that expectation of the masked outcome @xmath115 with respect to model  ( [ llmask ] ) is @xmath116 while expectation of @xmath115 with respect to model  ( [ llindi ] ) is @xmath117}w_\\lambda(s_i , s)\\,dn(s),\\end{aligned}\\ ] ] where @xmath118 .",
    "the  comparison between @xmath119 and@xmath120 suggests that we can reduce the bias and possibly the mse of estimating @xmath98 and @xmath97 when using the masked data by selecting a @xmath24 s.t .",
    "@xmath121}w_\\lambda(s_i , s)\\,dn(s)$ ] is close to 1 .",
    "one way to construct such a @xmath24 is to assign high weights to locations that receive similar exposure as the target location and low weights otherwise .",
    "the  @xmath24 constructed in this way has the property that it accounts for prior knowledge on the spatial pattern of the exposure . in our examples , this is also the spatial pattern of the outcome due to the model assumption  ( [ llindi ] ) .",
    "therefore , to assess the difference in bias and mse when varying the smoothing weight function , we construct two different kernel weights for data masking in the way that one weight accounts for prior knowledge on the spatial pattern of the exposure as above , while the other does not .",
    "we assume that the exposure is eradiated from a point source @xmath6 and decreases symmetrically in all directions as the euclidean distance from @xmath6 increases .",
    "specifically , we define @xmath122 for @xmath123\\times[-1,1]$ ] , where @xmath124 is the euclidean distance between location @xmath19 and the point source  @xmath6 .",
    "figure  [ ringwt](a ) shows the contour plot of@xmath125 .",
    "the  individual - level outcome is simulated from @xmath126 .",
    "aggregated data of exposure and outcome are constructed by calculating group summaries of @xmath127 as described in section  [ simuframe ] .    , with cells for spatial aggregation .",
    "contour plot of ring weight function @xmath128 for calculating spatially smoothed exposure and outcome data at location @xmath129 , from individual - level exposure @xmath125 in and individual - level outcome @xmath130 simulated by @xmath131 where @xmath132 , with @xmath133 .",
    "estimates of @xmath114 with `` naive '' 95@xmath134 confidence intervals by fitting model @xmath135 where @xmath136 are constructed using the ring weight function in and using the euclidean weight function @xmath137 , with reference lines at @xmath132 and at the estimate from aggregated data .",
    "mean square error ( mse ) of @xmath114 using `` naive '' variance . identification disclosure risk measured by the expect percentage of correct record matching .",
    "disclosure risk versus mse for utility - risk trade - off . ]",
    "we construct masked data @xmath138 by using equation  ( [ smsum ] ) with both the euclidean kernel weight @xmath139 and the ring kernel weight @xmath140 which are defined as follows : @xmath141 the  ring kernel weight @xmath142 decreases exponentially as the difference between @xmath143 and @xmath144 increases , and such difference is positively associated with the difference between @xmath125 and @xmath145 according to the spatial pattern of the exposure .",
    "figure  [ ringwt](b ) shows the contour plot of @xmath146 . on the other hand ,",
    "the euclidean kernel weight @xmath147 solely depends on @xmath148 , the euclidean distance between location @xmath20 and location @xmath19 , and therefore does not account for prior knowledge on the spatial distribution of the exposure .",
    "we assume that the exposure is eradiated from a point source  @xmath6 and toward a certain direction .",
    "specifically , we define @xmath149 for @xmath123\\times[-1,1]$ ] , where @xmath150 is the angle between the direction from point source @xmath6 to location @xmath19 and the direction that the exposure is toward , and @xmath124 is defined the same as in example i. figure  [ ringanglewt](a ) shows the contour plot of @xmath151 .",
    "the  individual - level outcome is simulated from @xmath152 .",
    "aggregated data of exposure and outcome are constructed by calculating group summaries of @xmath153 as described in section  [ simuframe ] .",
    "we construct masked data @xmath154 by using equation  ( [ smsum ] ) with the euclidean kernel weight  ( [ euc ] ) and the ring angle kernel weight @xmath155 which decreases exponentially as the difference between @xmath143 and @xmath144 increases as well as the difference between @xmath156 and @xmath157 increases . figure  [ ringanglewt](b ) shows the contour plot of @xmath158 .",
    ", with cells for spatial aggregation .",
    "contour plot of ring angle weight function @xmath159 for calculating spatially smoothed exposure and outcome data at location @xmath129 , from individual - level exposure @xmath151 in and individual - level outcome @xmath160 simulated by @xmath161 where @xmath132 , with @xmath133 .",
    "estimates of @xmath114 with `` naive '' 95@xmath134 confidence intervals by fitting model @xmath162 where @xmath163 are constructed using the ring angle weight function in and using the euclidean weight function @xmath164 , with reference lines at @xmath132 and at the estimate from aggregated data .",
    "mean square error  ( mse ) of @xmath114 using `` naive '' variance .",
    "identification disclosure risk measured by the expect percentage of correct record matching .",
    "disclosure risk versus mse for utility - risk trade - off . ]",
    "we assume that the exposure is eradiated from a point source @xmath6 but blocked in a certain area , such as blocked by a mountain , so the blocked area receives no exposure .",
    "specifically , we define the unblocked area to be @xmath165 or @xmath166 for @xmath123\\times[-1,1]$ ] , where @xmath167 is the @xmath168-axis value of location @xmath19 and @xmath169 is the angle between the positive @xmath168-axis and the direction from point source @xmath6 to location @xmath19 .",
    "we define the exposure @xmath170 for @xmath123\\times[-1,1]$ ] , where @xmath171 is the indicator that @xmath19 is located within the unblocked area , and @xmath124 is defined the same as in examples i and ii .",
    "figure  [ ringblockwt](a ) shows the contour plot of @xmath172 .",
    "the  individual - level outcome is simulated from @xmath173 .",
    "aggregated data of exposure and outcome are constructed by calculating group summaries of @xmath174 as described in section  [ simuframe ] .     where @xmath171 is the indicator of location @xmath19 in the unblocked area , with cells for spatial aggregation .",
    "contour plot of ring block weight function @xmath175 for calculating spatially smoothed exposure and outcome data at location @xmath129 , from individual - level exposure @xmath172 in and individual - level outcome @xmath176 simulated by @xmath177 where @xmath132 , with @xmath133 .",
    "estimates of @xmath114 with `` naive '' 95@xmath134 confidence intervals by fitting model @xmath178 where @xmath179 are constructed using the ring block weight function in and using the euclidean weight function @xmath164 , with reference lines at @xmath132 and at the estimate from aggregated data .",
    "mean square error  ( mse ) of  @xmath114 using `` naive '' variance .",
    "identification disclosure risk measured by the expect percentage of correct record matching .",
    "disclosure risk versus mse for utility - risk trade - off . ]",
    "we construct masked data @xmath180 by using equation  ( [ smsum ] ) with the euclidean kernel weight  ( [ euc ] ) and the ring block kernel weight @xmath181 which assigns nonzero weight only when location @xmath20 and location @xmath19 are both in the blocked or unblocked area .",
    "in addition , the nonzero weight from @xmath182 decreases exponentially as the difference between @xmath143 and @xmath144 increases .",
    "figure  [ ringblockwt](b ) shows the contour plot of @xmath183 .",
    "results of example  i on parameter estimates , mse and identification risk averaged across the 500 simulation replicates are shown in figure  [ ringwt ] , respectively . specifically , figure  [ ringwt](c ) shows the estimated @xmath114 as a function of @xmath23 for the ring kernel weight  ( [ ring ] ) and the euclidean kernel weight  ( [ euc ] ) , with the `` naive '' 95@xmath134 confidence intervals . by `` naive ''",
    "we mean that the confidence intervals are computed by fitting model  ( [ llmask ] ) directly , and therefore do not account for the possible correlation between the masked data as pointed out earlier in section  [ biasmask ] .",
    "the  reference lines are placed at the true value of @xmath97 and at the estimated @xmath108 , from which the bias of estimating the exposure coefficient by using the estimated @xmath114 can be evaluated .",
    "figure  [ ringwt](d ) shows the mse as a function of @xmath23 for the two kernel weights , where in this example mse is largely determined by the bias .",
    "the  reference lines are placed at the mse from regression using the original data  ( in which the bias part is 0 ) and the mse of @xmath108 .",
    "figure  [ ringwt](e ) shows the identification disclosure risk of the masked data set measured by the expected percentage of correct record matching , as a function of @xmath23 for the two kernel weights .",
    "figure  [ ringwt](f ) plots the disclosure risk versus mse , which shows the trade - off between data utility and disclosure risk .",
    "we find that data masking using the ring kernel weight  ( [ ring ] ) leads to smaller bias and mse when estimating the exposure coefficient than masking using the euclidean kernel weight  ( [ euc ] ) , for all @xmath23 values that are considered .",
    "it suggests that when using the masked data for loglinear regression , a masking procedure that preserves the spatial pattern of the original individual - level exposure and outcome data can lead to better estimates in terms of smaller bias and mse than a masking procedure that does not do so . as @xmath23 increases , the bias and mse increase for both kernel weights , while the differences in the bias and mse between the two kernel weights decrease",
    "this increase in the bias / mse and decrease in the bias / mse differences suggest that in the presence of a high degree of masking , choice for the form of masking may be less influential on the resultant bias / mse .",
    "moreover , comparing the estimated @xmath114 and @xmath108 , we find that for small values of @xmath23 , the bias and mse is smaller when using the estimated @xmath114 from the ring kernel weight  ( [ ring ] ) .    on the other hand , we find that the disclosure risk is lower when using the euclidean kernel weight  ( [ euc ] ) for data masking compared to using the ring kernel weight  ( [ ring ] ) .",
    "this is not unexpected because masked data constructed using the ring kernel weight is more informative about the original true values .",
    "however , with a tolerable potential disclosure risk  [ @xmath1840.2 which is used as an example cutoff in @xcite ] , masked data when constructed using the ring kernel weight can lead to better mse which can not be achieved by using the euclidean kernel weight with a comparable @xmath23 .",
    "same as the trend for bias and mse , the differences in the disclosure risk between the two kernel weights become small as @xmath23 increases .",
    "similar results of example ii and example iii are shown in figure  [ ringanglewt](c)(f ) and figure  [ ringblockwt](c)(f ) .",
    "figure  [ wr ] shows the width ratios comparing the 95% `` naive '' confidence intervals versus the percentile confidence intervals obtained from the empirical distribution of the estimates across the 500 simulations , for the estimates of @xmath114 in the three examples respectively .",
    "width ratio when @xmath185  ( the solid dot ) is calculated using the nonsmoothed data , that is , the individual - level data .",
    "we find that in these three examples , the `` naive '' confidence intervals generally overestimate the uncertainty of the @xmath114 estimates , and the degree of overestimation increases as @xmath23 increases .",
    "in addition , for examples ii and iii where the spatial patterns of exposure are nonisotropic , the degree of overestimation differs for the weight functions with and without accounting for prior knowledge on the spatial pattern of exposure .     `` naive '' confidence intervals  ( ci ) versus the percentile ci obtained from the empirical distributions of the estimates across the 500 simulations , for the estimates of @xmath114 in  example ,  example , and  example of the simulation studies .",
    "width ratio when @xmath185  ( the solid dot ) is calculated using the nonsmoothed data . ]",
    "we apply our method to the study of racial disparities in risks of mortality for a sample of the u.s .",
    "medicare population .",
    "we extract a large data set at individual - level from the medicare government database .",
    "specifically , it includes individual age , race , gender and a day - specific death indicator over the period 19992002 , for more than 4 million black and white medicare enrollees who are 65 years and older residing in the northeast region of the u.s .",
    "people who are younger than 65 at enrollment are eliminated because they are eligible for the medicare program due to the presence of either a certain disability or end stage renal disease and therefore do not represent the general medicare population .",
    "figure  [ area ] shows the study area which includes 2095 zip codes in 64 counties in the northeast region of the u.s .",
    "we select the counties whose centroids are located within the range that covers the northeast coast region of the u.s . , and we exclude zip codes without available study population from the study map .",
    "this area covers several large , urban cities including washington dc , baltimore , philadelphia , new york city , new haven and boston .",
    "it has the advantage of high population density and substantial racial diversity .",
    "we categorize the age of individuals into 5 intervals based on age in his / her first year of observation : [ 65 , 70 ) , [ 70 , 75 ) , [ 75 , 80 ) , [ 80 , 85 ) and [ 85 , @xmath186 ) .",
    "this categorization facilitates detection of age effects because differences in the risks of mortality for one - year increase in age are relatively small .",
    "we `` coarsen '' the daily survival information into yearly survival indicators . by doing so",
    ", we define our outcome as the probability of the occurrence of death for an individual in one year .",
    "this definition adjusts for the differential follow - up time .",
    "let @xmath187 denote individual , @xmath69 denote zip code , @xmath188 denote year , and @xmath189 be the death indicator for individual @xmath187 in zip code @xmath69 in year @xmath188 .",
    "similarly as in @xcite , we define the individual - level model as @xmath190\\\\[-8pt ] & & { } + \\beta_3\\mathit{gender}_{ij } + ( \\mathit{age } \\times \\mathit{gender } ) _ { ij}\\bolds{\\beta}_4.\\nonumber\\end{aligned}\\ ] ] geographic locations for each individual are needed to spatially smooth the individual - level data . however , from the medicare data we only have the longitude and latitude of the zip code centroids .",
    "therefore , we apply a two - step masking procedure on the individual - level data , where we first aggregate the individual - level data to zip code - level , and we then spatially smooth the zip - code level aggregated data to construct the masked data at the zip code - level .    specifically , let @xmath191 denote the total death count and @xmath106 denote the total person - years of zip code @xmath69 .",
    "we first obtain from aggregation @xmath192 , @xmath193 , @xmath194 , @xmath195 , @xmath196 , @xmath197 , which are the marginal distributions of race , age , gender , the joint distribution of age and gender , and the mortality rate , respectively , of each zip code .",
    "due to the complex spatial pattern of the zip code - level covariates , we use kernel smoothers with bivariate normal density kernel weights for spatial smoothing , so the shape of the smoothing weight is flexible by varying the correlation parameter value of the bivariate normal distribution .",
    "let the vector @xmath198 denote the location of a zip code , where @xmath129 and @xmath199 are the longitude and latitude of the zip code centroid , respectively .",
    "we use smoothing kernel weights of the general form @xmath200 where @xmath201 @xmath202 and @xmath203 are the variances of the longitude and latitude data of the 2095 zip codes , respectively .",
    "we consider for @xmath204 the following three values :    1 .",
    "@xmath205 , so the weight solely depends on the euclidean distance @xmath206 ; 2 .",
    "@xmath207 , so higher weight is assigned to @xmath19 in the northeast and southwest directions of @xmath20 ; 3 .",
    "@xmath208 , so higher weight is assigned to @xmath19 in the northwest and southeast directions of @xmath20 .",
    "let @xmath209 denote the smoothed mortality rate of zip code @xmath69 from which we calculate the smoothed death count @xmath210 .",
    "let @xmath211 , @xmath212 , @xmath213 , @xmath214 denote the smoothed marginal distributions of race , age , gender and the smoothed joint distribution of age and gender , respectively , of zip code @xmath69 .",
    "we specify the model for masked data as @xmath215 the  zip code - level nonsmoothed aggregated data are also used to fit model ( [ ecoindep ] ) .",
    "to evaluate the identification disclosure risk , we consider the scenario that a data intruder possesses correct zip code - level demographic data and seeks the matching with the masked zip code - level data set in order to obtain information on the zip code - level mortality .",
    "specifically , the released data set consists of @xmath211 , @xmath212 , @xmath216 and @xmath217 , and the data intruder possess the correct @xmath218 , @xmath219 and @xmath220 .      the  common approach to report the association between race and mortality risks is to report the race coefficients @xmath221 in model  ( [ indiindep ] ) and @xmath222 in model  ( [ ecoindep ] ) , whose interpretation is subjected to the coding of the race covariate . for direct understanding of the difference in the risk of death between the black and white populations , we define and report the population - level odds ratio  ( or ) of death comparing blacks versus whites , which is a function of the predicted values [ @xcite ]",
    ". therefore , interpretation of this association measure does not depend on model parameterization ( e.g. , on covariate centering and scaling ) .",
    "specifically , let @xmath223 denote the predicted probabilities of death in year @xmath188 for a black person and a white person , respectively , whose other covariates values are the same as the @xmath187th individual in the @xmath69th zip code .",
    "we define the population - level or from the individual - level model  ( [ indiindep ] ) as follows : @xmath224 where @xmath225 similarly , we define population - level @xmath226 from model  ( [ ecoindep ] ) using summary probabilities @xmath227 where @xmath228 and @xmath229 are the predicted probabilities of death in one year for zip codes that consist of solely black and solely white populations , respectively , and whose marginal and joint distributions of age and gender are the same as zip code  @xmath69",
    ". `` naive '' standard errors of @xmath230 are calculated using the multivariate delta method  [ @xcite ] .",
    "in addition , bootstrap confidence intervals for @xmath230 are calculated using 1000 nonparametric bootstrap samples .",
    "both `` naive '' and bootstrap confidence intervals for @xmath226 are obtained by exponentiating the corresponding confidence intervals for @xmath230 .",
    "figure  [ orsehalf](a)(c ) shows the estimates of @xmath226 under model  ( [ ecoindep ] ) as a function of @xmath23 for the three kernel weights respectively , with the 95% `` naive '' confidence intervals , confidence intervals using bootstrap standard error estimates and bootstrap percentile confidence intervals .",
    "@xmath231 is estimated by fitting model  ( [ ecoindep ] ) to the nonsmoothed zip code - level aggregated data .",
    "the  reference line is placed at the estimate of or under the individual - level model  ( [ indiindep ] ) .     under model and identification disclosure risk as a function of @xmath23 for the three weight functions .",
    "estimates of @xmath226 is plotted with the 95@xmath134 `` naive '' confidence intervals ( ci ) , ci using bootstrap standard error ( se ) estimates , and bootstrap percentile ci .",
    "@xmath231 is estimated by fitting model to the nonsmoothed zip code - level aggregated data .",
    "estimates of @xmath226 for bivariate normal density kernel weight with @xmath205 . estimates of @xmath226 for bivariate normal density kernel weight with @xmath207 .",
    "estimates of @xmath226 for bivariate normal density kernel weight with @xmath208 .",
    "identification disclosure risk measured by expected percentage of correct matching . ]    for small values of @xmath23 ( @xmath1840.1 ) , the estimates of @xmath226 for all three kernel weights are smaller than the estimate of or and therefore produce negative bias , while for larger values of @xmath23 the bias differs substantially for different kernel weights .",
    "for example , data masking using the kernel weight with @xmath207 leads to consistent underestimation of the odds ratio for all @xmath23 values that are considered . when using the kernel weight with @xmath208 for data masking , the estimates of @xmath226 are less subject to bias than those from using the other two kernel weights .",
    "differences in mse between the three kernels can also be inferred from the plots , and we find that using the kernel weight with @xmath208 leads to much smaller mse than using the other two kernels .",
    "for all three kernel weights , the `` naive '' confidence intervals underestimate the uncertainty of the @xmath226 estimates , which is in the opposite direction of the relation between the `` naive '' and the appropriate confidence intervals in the simulation studies .",
    "the  two bootstrap confidence intervals are wider than the `` naive '' confidence interval when @xmath185 , which suggests a systematic difference between the bootstrap confidence intervals and the `` naive '' confidence intervals regardless of smoothing .",
    "this systematic difference occurs because the nonsmoothed zip code - level aggregated data may not satisfy the binomial model assumption in  ( [ ecoindep ] ) .",
    "figure  [ orsehalf](d ) shows the identification disclosure risk of the masked data set as measured by the expected percentage of correct matches when using the three kernel weights for masking , as a function of @xmath23 .",
    "the  disclosure risk for all three kernel weights are small , ranging from 0.010.04 .",
    "the  risk is similar for the masked data sets when using the kernel weight with @xmath205 and @xmath208 for masking , and the risk when @xmath207 is slightly higher .",
    "we propose a special case of matrix masking based on spatial smoothing techniques , where the smoothing weight function controls the form of masking , and the smoothness parameter value directly measures the degree of masking . therefore , data utility and disclosure risk can be calculated as functions of both the form and the degree of masking .",
    "in fact , the smoothing weight function  @xmath24 can be any weight function and is not restricted by existing smoothing methods . with the variety of combinations of weight functions and smoothness parameter values , it is feasible to construct masked data that maintain high data utility while preserving confidentiality .",
    "we consider a subclass of linear smoothers that produces masked data as weighted averages of the original data .",
    "therefore , the masked data values are within a reasonable range .",
    "more importantly , correlation among the variables is invariant under linear transformation , which may intrinsically contribute to better data utility of the masked data . on the other hand ,",
    "this subclass is a large class .",
    "it includes many commonly used smoothers .",
    "we do not expect major restriction by focusing on this subclass of linear smoothers .    using our method",
    ", we investigate the utility of the masked data in terms of bias , variance and mse of parameter estimates when using the masked data for loglinear and logistic regression analysis .",
    "note that similar studies can be applied to any glm .",
    "in addition , we evaluate the identification disclosure risk of the masked data set by calculating the expected percentage of correct record matching . in the simulation studies ,",
    "we provide guidance for constructing masked data that can lead to better regression parameter estimates in terms of smaller bias and mse for loglinear models , and we show the trade - off between better estimates and lower disclosure risk .",
    "specifically , masked data can be constructed by using a smoothing weight function that accounts for prior knowledge on the spatial pattern of individual - level exposure , together with a reasonably low degree of masking .",
    "we provide guidance for how to select such a smoothing weight function for loglinear models .",
    "in addition , we provide candidate weight functions for three simplified but representative spatial patterns of exposure .",
    "as is expected , masked data that can lead to better estimates are generally more informative about the original data values and therefore are subject to relatively higher identification disclosure risk . however , the flexibility in our data masking method enables constructing the masked data that can lead to good parameter estimates , while the disclosure risk is controlled at a low level . in the meanwhile",
    ", caution should be placed to the institute in releasing detailed information on the data masking approach along with masked data .",
    "it is pointed out in section  [ method ] that simultaneously releasing the smoothing weight function @xmath24 and the smoothness parameter @xmath23 in the existence of @xmath53 can lead to reidentification of original data .",
    "however , even if only partial information is released , for example , only the information that data are masked using smoothing and the smoothing weight function is released while the smoothing parameter value is not released , it is possible that a smart data intruder can still reconstruct the transformation matrix @xmath232 .",
    "we apply our data masking method to the study of racial disparities in risks of mortality for the medicare population , and show how the bias and the variance of the estimated or of death comparing blacks to whites , and how the identification disclosure risk , vary with the form and the degree of masking .",
    "the  results suggest that in the absence of clear guidance , it is helpful to explore a large flexible family such as the bivariate normal density kernel to identify a weight function that can lead to both good utility and low identification risk for the masked data .",
    "we compare the `` naive '' confidence intervals with the appropriate ones which account for the possible correlation among masked data in both the simulation studies and the data application , where we observe opposite directions in the relation between the `` naive '' and the appropriate confidence intervals .",
    "it suggests no general direction for that relation .",
    "one possible reason , which is also pointed out in section  [ darlt ] , is that the unmasked data in the simulation study are simulated from poisson distributions , while the unmasked data in the data application are real data and do not strictly follow the assumed binomial distribution . therefore , in the data application , the standard errors account for both the correlation among the masked data and the discrepancy of the original data distribution from binomial .",
    "the  simulation study and data application results show that masked data constructed using our method can well preserve confidentiality .",
    "specifically , the identification disclosure risk is reasonably low for all scenarios that we consider .",
    "note that our calculation of the disclosure risk is conservative : we assume that an intruder possesses true values for all the regressors , and we use probability 1 for the component latexmath:[$\\operatorname{pr}(\\mathbf{z } _",
    "{ \\lambda,1 } , \\ldots,\\mathbf{z } _ { \\lambda , j-1},\\mathbf{z } _ { \\lambda , j+1},\\ldots,\\mathbf{z } _ { \\lambda , n }    in addition , the flexibility in the selection of smoothing weight function @xmath24 and smoothness parameter @xmath23 can also help control disclosure risk in addition to improving data utility .    based on our method ,",
    "we additionally derive a closed - form expression for first - order bias of the parameter estimates obtained using the masked data , for glm that belong to the exponential family .",
    "the  first - order bias calculation is not necessary when both individual - level exposure and health outcome data are available so the actual bias can be computed .",
    "it may be used by researchers who have only the individual - level exposure information to explore the possible bias in their analysis using masked data .",
    "although our proposed method uses spatial smoothing and therefore applies to spatial data , it can be easily generalized to other data types because the masking procedure is a smoothing technique that takes weighted averages of the original data .",
    "for example , the proposed method can be generalized to smoothing time series data by using the smoothing weight function @xmath234 , where @xmath98 and @xmath19 denote time points .",
    "also , note that an alternative method to mask spatial data is to mask the individual spatial location [ see @xcite ; @xcite ] .",
    "we derive a closed - form expression for the first - order bias of estimating the regression coefficients in a glm that belongs to the exponential family , when using data masked by our method .",
    "let @xmath60 denote the vector of regression coefficients of a model specified for the original individual - level data .",
    "when the model belongs to the exponential family , its log likelihood can be expressed as @xmath235 @xmath236 , where @xmath237 is the derivative of function @xmath238 , and @xmath239 is the link function . substituting the individual - level data @xmath240 by the masked data @xmath241 , we obtain log likelihood of the analogous model when fitted to the masked data , @xmath242 where @xmath243 denotes the corresponding vector of regression coefficients . in order to calculate the mle of @xmath244 ,",
    "it is common procedure to calculate the score function from the likelihood ( [ llsm ] ) and take its expectation with respect to the `` true '' individual - level model @xmath245 .",
    "denote the expected score function as @xmath246 and denote @xmath247 as the solution s.t .",
    "it can be shown that @xmath249 .",
    "taking the derivative of @xmath248 with respect to @xmath23 and evaluating it at @xmath185 , we obtain the standard result : @xmath250 where @xmath251 and @xmath252 are the partial derivatives with respect to the first and second components of @xmath253 , respectively . specifically , @xmath254 where @xmath255 and @xmath256 , inverse of the link function of the glm . in practice , @xmath257 in  ( [ fob ] )",
    "is calculated by substituting the the integrals by summations over all locations where the original individual - level data are available .",
    "the  quantity @xmath258 denotes the instant bias of estimating @xmath60 using masked data , when changing from no masking to a very low degree of masking .",
    "as expected , when ( i ) @xmath259 is constant across all locations in @xmath17 , or ( ii ) @xmath239 is a linear function , @xmath257 is calculated to be 0 , and therefore @xmath260 .",
    "using @xmath261 , we can approximate the bias of estimating @xmath60 when fitting a glm using masked data whose degree of masking is @xmath23 , by calculating @xmath262 this bias calculation can be extended to any function of @xmath60 , for example , the predicted value . specifically , bias in estimating @xmath263 can be approximated by @xmath264    it can be seen that the first - order bias approximation can be easily generalized to approximation using higher - order terms of the taylor series expansion in addition to the first - order term . specifically , @xmath265\\\\[-8pt ] & & { } + \\bolds{\\beta}^{(n)}(0)\\cdot\\lambda^n / n!,\\qquad n \\geq1.\\nonumber\\end{aligned}\\ ] ] similarly",
    ", we can generalize the bias approximation of estimating @xmath263 .",
    "a limitation of the bias approximation using taylor series expansion  ( [ taylor ] ) is that we ignore the remainder term @xmath266 , @xmath267 , which may not be small for large values of @xmath23 .",
    "therefore , the approximation only captures the bias for @xmath268 , that is , the instant direction and magnitude of the bias when changing from no masking to a very low degree of masking .",
    "it may not capture the total bias for a specified degree of masking . in the application of our method to the medicare data ,",
    "the first - order bias is calculated to be 0 for all three kernel weights because @xmath269 in  ( [ fob ] ) equals 0 .",
    "in addition , when applying the bias approximation  ( [ taylor ] ) to the three examples in the simulation studies for @xmath270 , the bias approximation is calculated to be 0 , while nonzero bias is shown by comparing the parameter estimates when using the masked data with the true parameter value .",
    "thanks to dr .",
    "aidan mcdermott for the help on the medicare data sources .",
    "dobra , a. , fienberg , s.  e. and trottini , m. ( 2003 ) . assessing the risk of disclosure of confidential categorical data . in _ bayesian statistics _",
    "_ 7 _ , proceedings of the seventh valencia international meeting on bayesian statistics ( j. bernardo et al . , eds ) 125144 .",
    "oxford univ . press , oxford .",
    "fienberg , s.  e. , makov , u.  e. and steele , r.  j. ( 1998 ) .",
    "disclosure limitation using perturbation and related methods for categorical data ( with discussion ) .",
    "_ journal of official statistics _ * 14 * 485511 .",
    "fienberg , s.  e. and willenborg , l. c. r.  j. ( 1998 ) .",
    "introduction to the special issue : disclosure limitation methods for protecting the confidentiality of statistical data .",
    "_ journal of official statistics _",
    "* 14 * 337345 .",
    "kim , j. ( 1986 ) . a method for limiting disclosure in microdata based on random noise and transformation . in _ american statistical association , proceedings of the section on survey research methods _ 370374 .",
    "alexandria , va .",
    "slavkovic , a. and lee , j. ( 2010 ) .",
    "synthetic two - way contingency tables that preserve conditional frequencies .",
    "methodol_. doi : http://dx.doi.org/10.1016/j.stamet.2009.11.002[10.1016/j.stamet.2009.11.002 ] . to appear .",
    "sullivan , g. and fuller , w.  a. ( 1989 ) . the  use of measurement error to avoid disclosure . in",
    "_ american statistical association , proceedings of the section on survey research methods",
    "_ 802807 .",
    "alexandria , va .",
    "trottini , m. , fienberg , s. , makov , u.  e. and meyer , m. ( 2004 ) .",
    "additive noise and multiplicative bias as disclosure limitation techniques for continuous microdata : a simulation study .",
    "_ journal of computational methods for science and engineering _ * 4 * 516 ."
  ],
  "abstract_text": [
    "<S> individual - level health data are often not publicly available due to confidentiality ; masked data are released instead . therefore , it is important to evaluate the utility of using the masked data in statistical analyses such as regression . in this paper </S>",
    "<S> we propose a data masking method which is based on spatial smoothing techniques . </S>",
    "<S> the  proposed method allows for selecting both the form and the degree of masking , thus resulting in a large degree of flexibility . </S>",
    "<S> we investigate the utility of the masked data sets in terms of the mean square error  ( mse ) of regression parameter estimates when fitting a generalized linear model  ( glm ) to the masked data . </S>",
    "<S> we also show that incorporating prior knowledge on the spatial pattern of the exposure into the data masking may reduce the bias and mse of the parameter estimates . by evaluating both utility and disclosure risk as functions of the form and the degree of masking , </S>",
    "<S> our method produces a risk - utility profile which can facilitate the selection of masking parameters . </S>",
    "<S> we apply the method to a study of racial disparities in mortality rates using data on more than 4 million medicare enrollees residing in 2095 zip codes in the northeast region of the united states .    ,    . </S>"
  ]
}