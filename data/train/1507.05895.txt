{
  "article_text": [
    "when we look at the natural world , information processing in biological systems is elegantly coupled with their underlying physics  @xcite . this suggests a potential for establishing a new physics - based analog - computing paradigm .",
    "a proposal was made about ten years ago for a conceptually novel switching device , called the `` atomic switch , '' that is based on metal ion migration and electrochemical reactions in solid electrolytes  @xcite . because its resistance state is controlled continuously by the movement of a limited number of metal ions / atoms , the atomic switch can be regarded as a physics - based analog - computing element . in this paper , using atomic switches , we show that a physical constraint , the volume conservation law , allows for the efficient solving of decision - making problems which , in human beings , is one of the most important intellectual abilities .",
    "suppose there are @xmath0 slot machines , each of which returns a reward ; for example , coins , with a certain probability density function ( pdf ) that is unknown to a player .",
    "let us consider a minimal case : two machines a and b give rewards with individual pdf whose mean reward is @xmath1 and @xmath2 , respectively .",
    "the player makes a decision on which machine to play at each trial , trying to maximize the total reward obtained after repeating several trials .",
    "the multi - armed bandit problem ( mab ) is used to determine the optimal strategy for playing machines as accurately and quickly as possible by referring to past experience .    in the context of decision making algorithms ,",
    "the mab was originally described by robbins  @xcite , although the essence of the problem had been studied earlier by thompson  @xcite .",
    "the optimal strategy , called the `` gittins index , '' is known only for a limited class of problems in which the reward distributions are assumed to be known to the players  @xcite . even in this limited class , in practice ,",
    "computing the gittins index becomes intractable for many cases .",
    "for the algorithms proposed by agrawal and auer et al . , another index was expressed as a simple function of the reward sums obtained from the machines  @xcite . in particular ,",
    "the `` upper confidence bound 1 ( ucb1 ) algorithm '' for solving mabs is used worldwide in many practical applications  @xcite .",
    "the mab is formulated as a mathematical problem without loss of generality and , as such , is related to various stochastic phenomena .",
    "in fact , many application problems in diverse fields , such as communications ( cognitive networks  @xcite ) , commerce ( advertising on the web  @xcite ) , entertainment ( monte - carlo tree search , which is used for computer games  @xcite ) , can be reduced to mabs .",
    "kim et al . proposed a mab solution called `` tug - of - war ( tow ) , '' which uses a dynamical system .",
    "this algorithm was inspired by the spatiotemporal dynamics of a single - celled amoeboid organism ( the true slime mold _",
    "p. polycephalum _ )  @xcite , which maintains a constant intracellular - resource volume while collecting environmental information by concurrently expanding and shrinking its pseudopod - like terminal parts . in this bio - inspired algorithm ,",
    "the decision - making function is derived from its underlying physics , which resembles that of a tug - of - war game . the physical constraint in tow dynamics",
    ", the conservation law for the volume of the amoeboid body , entails a nonlocal correlation among the terminal parts .",
    "that is , the volume increment in one part is immediately compensated for by volume decrement(s ) in the other part(s ) . in our previous studies",
    "@xcite , we showed that , owing to the nonlocal correlation derived from the volume - conservation law , tow dynamics exhibit higher performance than other well - known algorithms such as the modified @xmath3-greedy algorithm and the modified softmax algorithm , which is comparable to the ucb1-tuned algorithm ( seen as the best choice among parameter - free algorithms  @xcite ) .",
    "these observations suggest that efficient decision - making devices could be implemented using any physical object as long as it holds some common physical attributes , such as the conservation law .",
    "in fact , kim et al . demonstrated that optical energy - transfer dynamics between quantum dots , in which energy is conserved , can be exploited for the implementation of tow dynamics  @xcite .       or / and @xmath4 ) is to be played at time @xmath5 according to whether the current @xmath6 is larger than @xmath7 or not .",
    "( b ) voltages @xmath8 and @xmath9 . here , added voltage @xmath10 is determined by each reward @xmath11 ( eq.([r ] ) ) at play @xmath12 ( @xmath6@xmath13@xmath7).,height=472 ]    here",
    ", we propose a simplified model for an atomic switch - based decision maker ( asdm ) .",
    "consider two atomic switches located close to each other , in which a solid electrolyte ( se ) is sandwiched between one top pt electrode and two bottom pt electrodes respectively on both sides , as shown in fig .",
    "[ fig : stow](a ) .",
    "each atomic switch is operated in a metal / ionic conductor / metal configuration , which is referred to as a `` gapless type atomic switch  @xcite . '' here we assume that operation of both switches is influenced by each other , which implies a certain interaction between the two switches . in the initial state , ag ions are distributed uniformly in the electrolyte . when a bias voltage of @xmath14 is applied to the bottom",
    "pt electrodes relative to the top pt electrode , ag ions migrate to the bottom electrodes and the same amount of ag atoms are precipitated on the respective electrode .",
    "we define the height of ag atoms by @xmath15 , and each displacement of the height of precipitated ag atoms from @xmath16 at time @xmath5 by @xmath17 ( @xmath18 ) .",
    "the total height results in @xmath15 @xmath19 @xmath20 .    if current @xmath6@xmath13@xmath7 , we consider that the asdm chooses machine @xmath21 , and obtains reward @xmath11 generated from each `` unknown pdf '' ( mean reward @xmath22 is also supposed to be unknown ) .",
    "according to the reward , the added voltage @xmath10 is determined by @xmath23 here , @xmath24 is a `` reward '' which has an arbitrary real value .",
    "@xmath25 is a parameter to be described in detail later on in this paper .",
    "then , each voltage becomes @xmath26    we assume the following conditions :    1 .   at initial equilibrium state ,",
    "the se is nearly empty of ag ions to be precipitated .",
    "this implies that an increment of one height is compensated by a decrement in the other ( eq.([diffe ] ) holds ) .",
    "2 .   if @xmath15 @xmath19 @xmath20 @xmath13 @xmath27 , current @xmath6 is larger than @xmath7 . here ,",
    "@xmath27 and @xmath7 are thresholds . if the @xmath27 is set to be smaller than @xmath15 , this dynamics works from the initial state without fluctuations .",
    "3 .   for simplicity ,",
    "we assume a linear dependence between @xmath28 and @xmath29 ( eq.([eq : org ] ) ) even though it depends on the shape of the ag atoms and the amount of ag ions remaining .",
    "4 .   the time interval for adding voltage @xmath30 is sufficiently larger than that for interval @xmath31 that the decaying effect of ag atoms during @xmath31 can be ignored .",
    "displacement @xmath32 ( @xmath33 ) is determined by the following equations : @xmath34 here , @xmath35 ( @xmath18 )",
    "is an `` estimate '' of information of past experiences accumulated from the initial time @xmath36 to the current time @xmath5 , @xmath37 counts the number of times that machine @xmath21 has been played , @xmath28 is the added voltage when playing machine @xmath21 , @xmath38 is an arbitrary fluctuation to which the body is subjected , and @xmath25 is a parameter .",
    "eqs.([r ] ) and ( [ eq : org ] ) are called the `` learning rule . ''",
    "consequently the asdm dynamics evolve according to a particularly simple rule : in addition to the fluctuation , if machine @xmath21 is played at each time @xmath5 , @xmath39@xmath40@xmath25 is added to @xmath20 ( fig .",
    "[ fig : stow ] ) .",
    "the softmax algorithm is a well - known algorithm for solving mab problems  @xcite . in this algorithm ,",
    "the probability of selecting a or b , @xmath41 or @xmath42 , is given by the following boltzmann distributions : @xmath43}{\\exp[\\beta \\cdot q_a(t ) ] + \\exp[\\beta \\cdot q_b(t)]},\\\\ p_b^{\\prime}(t ) & = &   \\frac{\\exp[\\beta \\cdot q_b(t)]}{\\exp[\\beta \\cdot q_a(t ) ] + \\exp[\\beta \\cdot q_b(t)]},\\end{aligned}\\ ] ] where @xmath35 ( @xmath18 ) is given by @xmath44 .",
    "here , @xmath45 is a time - dependent form in our study , as follows : @xmath46 @xmath47 corresponds to a random selection , and @xmath48 corresponds to a greedy action .",
    "@xmath49@xmath50 for the asdm and @xmath51@xmath49@xmath52 for softmax.,height=188 ]    from computer simulations , we confirmed that , in almost all cases , an asdm with the parameter @xmath53 ( @xmath49@xmath54 ) can acquire more rewards than a softmax algorithm with the optimized parameter @xmath51 , although softmax is well - known as a good algorithm for efficient decision - making  @xcite .",
    "figure [ fig : sim ] shows an example of an asdm / softmax performance comparison .",
    "the vertical axis denotes the sum of acquired rewards ( mean values of @xmath55 samples ) , and the horizontal axis denotes the number of plays . for the reward pdfs , we used normal distributions @xmath56 and @xmath57 , where @xmath1@xmath49@xmath58 , @xmath2@xmath49@xmath59 , and @xmath60@xmath49@xmath61 .",
    "computer simulations were executed under the condition that @xmath27@xmath49@xmath15 and @xmath62@xmath49@xmath63 .",
    "theoretical analyses of the tow dynamics for a bernoulli type mab problem , in which a reward is limited to @xmath64 or @xmath36 , are described in  @xcite . in this section ,",
    "theoretical analyses of the asdm are described for a general mab where a reward is not limited to @xmath64 or @xmath36 .       . here",
    ", the probability density function of @xmath39 has the mean @xmath22 .",
    "( b ) probability distributions of two random walks.,height=264 ]    to explore the mab solvability of the asdm dynamics , let us consider a random - walk model as shown in fig .",
    "[ fig : random](a ) . here , @xmath65 ( @xmath18 ) is a reward at time @xmath5 , and @xmath25 is a parameter ( see eq.([r ] ) ) .",
    "we assume that means of the probability density function of @xmath39 satisfy @xmath1 @xmath13 @xmath2 for simplicity .",
    "after time step @xmath5 , the displacement @xmath66 ( @xmath18 ) can be described by @xmath67 the expected value of @xmath68 can be obtained from the following equation : @xmath69    in the overlapping area between the two distributions shown in fig .",
    "[ fig : random](b ) , we can not accurately estimate which is larger .",
    "the overlapping area should decrease as @xmath37 increases so as to avoid incorrect judgments .",
    "this requirement can be expressed by the following forms : @xmath70 these expressions can be rearranged into the form @xmath71 in other words , the parameter @xmath25 must satisfy the above conditions so that the random walk correctly represents the larger judgment .",
    "we can easily confirm that the following form satisfies the above conditions : @xmath72 from @xmath35 and eq.([eq : fixed ] ) , we obtain @xmath73 here , we have set the parameter @xmath25 to @xmath53 .",
    "therefore , we can conclude that the asdm dynamics using the learning rule @xmath74 with the parameter @xmath53 can solve the mab correctly .      in many popular algorithms such as the @xmath3-greedy algorithm , at each time",
    "@xmath5 , an estimate of reward probability is updated for either of the two machines being played . on the other hand , in an imaginary circumstance",
    "in which the sum of the mean rewards @xmath75 @xmath49",
    "@xmath1 @xmath19 @xmath2 is known to the player , we can update both of the two estimates simultaneously , even though only one of the machines was played .",
    ".estimates for each mean reward based on the knowledge that machine @xmath76 was played @xmath77 times and that machine @xmath4 was played @xmath78 times  on the assumption that the sum of the mean rewards @xmath75 @xmath49 @xmath1 @xmath19 @xmath2 is known .",
    "[ cols=\"^,^,^,^\",options=\"header \" , ]     the top and bottom rows of table  [ table:1 ] provide estimates based on the knowledge that machine @xmath76 was played @xmath77 times and that machine @xmath4 was played @xmath78 times , respectively .",
    "note that we can also update the estimate of the machine that was not played , owing to the given @xmath75 .    from the above estimates ,",
    "each expected reward @xmath79 ( @xmath18 ) is given as follows : @xmath80 these expected rewards , @xmath81s , are not the same as those given by the learning rules of tow dynamics , @xmath82s in eqs.([r ] ) and ( [ eq : org ] ) .",
    "however , what we use substantially in tow dynamics is the difference @xmath83 when we transform the expected rewards @xmath81s into @xmath84 , we can obtain the difference @xmath85 comparing the coefficients of eqs.([eq : dq ] ) and ( [ eq : dqpp ] ) , the differences in their constituent terms are always equal when @xmath86 ( eq.([eq : w0 ] ) ) is satisfied .",
    "eventually , we can obtain the nearly optimal weighting parameter @xmath53 in terms of @xmath75 .",
    "this derivation implies that the learning rule for the asdm dynamics is equivalent to that of the imaginary system in which both of the two estimates can be updated simultaneously . in other words ,",
    "the asdm dynamics imitates the imaginary system that determines its next move at time @xmath87 in referring to the estimates of the two machines , even if one of them was not actually played at time @xmath5 .",
    "this unique feature in the learning rule , derived from the fact that the sum of mean rewards is given in advance , may be one of the origins of the high performance of the asdm dynamics .",
    "monte carlo simulations were performed it was verified that the asdm dynamics with @xmath53 exhibits an exceptionally high performance , which is comparable to its peak performance  achieved with the optimal parameter @xmath88 . to derive the optimal value @xmath88 accurately ,",
    "we need to take into account the fluctuations .",
    "in addition , the essence of the process described here can be generalized to @xmath0-machine cases . to separate distributions of the top @xmath89-th and top @xmath90-th machine , as shown in fig .",
    "[ fig : random](b ) , all we need is the following @xmath53 : @xmath91 here , @xmath92 denotes the top @xmath89-th mean , and @xmath89 is any integer from 1 to @xmath93 .",
    "the mbp is a special case where @xmath94 .",
    "in fact , for @xmath0-machine and @xmath95-player cases , we have designed a physical system that can determine the overall optimal state , called the `` social maximum , '' quickly and accurately  @xcite .      to characterize the high performance of the asdm dynamics ,",
    "let us consider the imaginary model for solving the mab , called the `` cheater algorithm . ''",
    "the cheater algorithm selects a machine to play according to the following estimate @xmath96 ( @xmath18 ) @xmath97 here , @xmath98 is a random variable . if @xmath99 @xmath13 @xmath100 at time @xmath101 , machine @xmath76 is played at time @xmath102 . if @xmath100 @xmath13 @xmath99 at time @xmath101 , machine @xmath4 is played at time @xmath102 .",
    "if @xmath99 @xmath49 @xmath100 at time @xmath101 , a machine is played randomly at time @xmath102 .",
    "note that the algorithm refers to results of both machines at time @xmath5 without any attention to which machine was played at time @xmath103 . in other words , the algorithm `` cheats '' because it plays both machines and collects both results , but declares that it plays only one machine at a time .",
    "the expected value and the variance of @xmath104 are defined as @xmath105 and @xmath106 . here",
    ", @xmath22 is the same as the @xmath107 defined earlier . from the central - limit theorem",
    ", @xmath96 has a gaussian distribution with @xmath108 and @xmath109 .",
    "if we define a new variable @xmath110 , @xmath111 has a gaussian distribution and carries the following values : @xmath112    : probability of selecting the lower - reward machine in the cheater algorithm , height=113 ]    from fig .",
    "[ fig : qfunc ] , the probability of playing machine @xmath4 , which has a lower reward probability , can be described as * q*@xmath113 . here , *",
    "q*@xmath114 is a * q*-function .",
    "we obtain @xmath115 here , @xmath116    using the chernoff bound @xmath117 , we can calculate the upper bound of a measure , called the `` regret , '' which quantifies the accumulated losses of the cheater algorithm .",
    "@xmath118 @xmath119 note that the regret becomes constant as @xmath120 increases .    using the `` cheated '' results",
    ", we can also calculate the regret of the asdm dynamics in the same way .",
    "in this case , @xmath121 @xmath98 is also a random variable .",
    "then , we obtain @xmath122 using the new variables @xmath110 , @xmath123 , and @xmath124 , we also obtain @xmath125    if the conditions @xmath126 and @xmath127 @xmath128 are satisfied , we then obtain @xmath129 and @xmath130 here , @xmath131    we can then calculate the upper bound of the regret for the asdm dynamics @xmath132 note that the regret for the asdm dynamics also becomes constant as @xmath120 increases .",
    "it is known that optimal algorithms for the mab , defined by auer et al .",
    ", have a regret proportional to @xmath133  @xcite .",
    "the regret has no finite upper bound as @xmath120 increases because it continues to require playing the lower - reward machine to ensure that the probability of incorrect judgment goes to zero .",
    "a constant regret means that the probability of incorrect judgment remains non - zero in the asdm dynamics , although this probability is nearly equal to zero .",
    "however , it would appear that the reward probabilities change frequently in actual decision - making situations , and their long - term behavior is not crucial for many practical purposes .",
    "for this reason , the asdm dynamics would be more suited to real - world applications .",
    "in this paper , we proposed an asdm for solving mab problems , and analytically validated that their high efficiency in making a series of decisions for maximizing the total sum of stochastically obtained rewards is embedded in a volume - conserving physical system when subjected to suitable operations involving fluctuations . in conventional decision - making algorithms for solving mab problems",
    ", the parameter for adjusting the `` exploration time '' must be optimized .",
    "this exploration parameter often reflects the difference between the rewarded experiences , i.e. , @xmath134 .",
    "in contrast , the asdm demonstrates that higher performance can be achieved by introducing a parameter @xmath53 that refers to the sum of the rewarded experiences , i.e. , @xmath1 @xmath19 @xmath2 .",
    "this type of optimization , using the sum of the rewarded experiences , is particularly useful for time varying environments ( reward probability or reward pdf )  @xcite . owing to this novelty",
    ", the high performance of the tow dynamics can be reproduced when implementing these dynamics with atomic switches .",
    "the asdm proposed in this paper is a simple `` ideal model . ''",
    "while the assumptions used for constructing the model may contain some points that do not match real experimental situations , we can more accurately extend the model so that the modified assumptions do match real experimental situations .",
    "as long as the tow dynamics between atomic switches is implemented , high performance decision - making can be guaranteed even in the extended model .",
    "the asdm will introduce a new physics - based analog computing paradigm , which will include such things as `` intelligent nanodevices '' and `` intelligent information networks '' based on self - detection and self - judgment .",
    "thus , our proposed physics - based analog - computing paradigm would be useful for a variety of real - world applications and for understanding the biological information - processing principles that exploit their underlying physics .",
    "the authors thank dr .",
    "etsushi nameda and prof .",
    "masashi aono for valuable discussions in the early stages of this work .",
    "this work was supported in part by the sekisui chemical grant program for `` research on manufacturing based on innovations inspired by nature . ''",
    "the authors declare that there is no conflicting of interest regarding the publication of this paper .",
    "lai l , jiang h , & poor h. v. ( 2008 ) medium access in cognitive radio networks : a competitive multi - armed bandit framework .",
    "_ proc . of ieee 42nd asilomar conference on signals , system and computers _ , 98 - 102 .",
    "kocsis l , & szepesv@xmath135ri c. ( 2006 ) bandit based monte - carlo planning , in : carbonell , j. g. et al . , _",
    "17th european conference on machine learning , lecture notes in artificial intelligence _ 4212 , springer , 282 - 293 .",
    "kim s - j , aono m , nameda e , & hara m. ( 2011 ) amoeba - inspired tug - of - war model : toward a physical implementation of an accurate and speedy parallel search algorithm . _",
    "technical report of ieice ( ccs-2011 - 025 ) _ , 36 - 41 [ in japanese ] .",
    "naruse m , nomura w , aono m , ohtsu m , sonnefraud y , drezet , a , huant s , & kim s - j .",
    "( 2014 ) decision making based on optical excitation transfer via near - field interactions between quantum dots .",
    "_ j appl phys _ 116 : 154303 .",
    "vermorel j , & mohri m. ( 2005 ) multi - armed bandit algorithms and empirical evaluation , in : gama j. , et al .",
    "_ 16th european conference on machine learning .",
    "lecture notes in artificial intelligence _ 3720 , springer , 437 - 448 .",
    "kim s - j , & aono m. ( 2015 ) decision maker using coupled incompressible - fluid cylinders .",
    "special issue of _ advances in science , technology and environmentology _ b11 : 41 - 45 , http://arxiv.org/abs/1502.03890 ."
  ],
  "abstract_text": [
    "<S> we propose a simple model for an atomic switch - based decision maker ( asdm ) , and show that , as long as its total volume of precipitated ag atoms is conserved when coupled with suitable operations , an atomic switch system provides a sophisticated `` decision - making '' capability that is known to be one of the most important intellectual abilities in human beings . </S>",
    "<S> we considered the multi - armed bandit problem ( mab ) ; the problem of finding , as accurately and quickly as possible , the most profitable option from a set of options that gives stochastic rewards . </S>",
    "<S> these decisions are made as dictated by each volume of precipitated ag atoms , which is moved in a manner similar to the fluctuations of a rigid body in a tug - of - war game . </S>",
    "<S> the `` tug - of - war ( tow ) dynamics '' of the asdm exhibits higher efficiency than conventional mab solvers . we show analytical calculations that validate the statistical reasons for the asdm dynamics to produce such high performance , despite its simplicity . </S>",
    "<S> these results imply that various physical systems , in which some conservation law holds , can be used to implement efficient `` decision - making objects . '' </S>",
    "<S> efficient mab solvers are useful for many practical applications , because mab abstracts a variety of decision - making problems in real - world situations where an efficient trial - and - error is required . the proposed scheme will introduce a new physics - based analog computing paradigm , which will include such things as `` intelligent nanodevices '' and `` intelligent information networks '' based on self - detection and self - judgment . </S>"
  ]
}