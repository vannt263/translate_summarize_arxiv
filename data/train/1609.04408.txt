{
  "article_text": [
    "* classical costs from computational mechanics .",
    "* we here present some minimal details from the mathematical framework of computational mechanics  @xcite to substantiate the claim that the classical simulator s minimal memory cost is equal to the precision @xmath122 .    in computational mechanics",
    ", the evolution of a dynamical property ( over domain @xmath123 ) is characterised by a discrete - time stochastic process @xmath19 , written as bi - infinite sequence of random variables @xmath5 , where each random variable @xmath124 governs the value @xmath125 of the dynamical property at time @xmath12 .",
    "the statistical behaviour of a process may be represented in a _ causal _ manner by writing it as the conditional probability distribution @xmath126 , where @xmath127 is the infinite string of random variables occuring after time @xmath12 , and @xmath128 is the infinite string of random variables occuring before ( and including ) time @xmath12 . for _ stationary _ processes ( such as the time - independent cyclic random walks described in this article ) , this distribution has no explicit time dependence , so we omit the superscript @xmath12 .    a faithful _ simulation _ of process @xmath19 is a machine ( or program ) that , having been initialized in accordance with the observation of past @xmath129 , then generates a series of outputs @xmath130 according to the distribution @xmath131 . since , storing infinite string @xmath129 may require an unbounded amount of memory , one instead configures the internal state of the simulator @xmath132 ( over configuration space @xmath133 ) according to some function @xmath134 , satisfying @xmath135 , where @xmath136 is the random variable describing the internal state of the simulator ( formed by applying the function @xmath47 on each variate of @xmath137 ) .",
    "moreover , once initiated into state @xmath138 , when the simulator outputs @xmath51 in the subsequent time - step , its internal state must then transition to the state @xmath52 ( where @xmath139 indicates the concatenation of @xmath51 to the end of string @xmath25 ) .",
    "the the memory cost of such a simulator is given by the information entropy of @xmath140 , @xmath141 .",
    "the function @xmath47 that minimizes this classically corresponds to identifying the _ causal state _ of a particular past  @xcite , defined by the equivalence relationship : @xmath142 for pasts @xmath25 and @xmath57 if and only if @xmath143 for all possible future values @xmath144 .",
    "the causal states are unique for any given process , and so their entropy @xmath145 is a property of the process itself known as its _ statistical complexity _",
    "@xmath54 , capturing the intuition that a more complex process requires more memory to simulate .    for markovian processes , such as discussed in this article",
    ", the number of causal states required is equal to the number of unique rows in the stochastic matrix describing the evolution .",
    "when these rows are generated by the discretization of a continuous process into @xmath61 divisions  such as when they are derived from the cyclic walk s shift function @xmath9  the number of states will be equal to @xmath61 , except for very specific ( e.g.  pathelogically fractal ) choices of @xmath9 and @xmath61 .",
    "since by symmetry the probability of the simulator being in any particular state is equal , the classical memory cost of a simulator hence scales with the number of sites as @xmath122 , or linearly with the precision @xmath146 .    * details of the quantum circuit in [ fig : circuit ] .",
    "* let us consider [ fig : circuit ] in more depth ( see also @xcite ) .",
    "the circuit consists of one persistent internal memory state , and as an `` output tape '' a line of quantum states , which are fed into the system one at a time .",
    "suppose each state on the output tape is initialized into some arbitrary state @xmath147 .",
    "for any two quantum states @xmath148 and @xmath149 in the same hilbert space , it is always possible to construct a unitary transformation @xmath150 such that @xmath151 .",
    "this will be of the form @xmath152 where @xmath153 are states orthogonal to each other and to @xmath148 , and @xmath154 are states orthogonal to each other and to @xmath149 .",
    "thus , in the joint hilbert space @xmath155 of two quantum systems of dimension @xmath61 , it is possible to build a `` controlled '' unitary operation @xmath156 containing the elements @xmath157 for every @xmath158 in an arbitrary ( generally non - orthogonal ) set of states @xmath159 . [",
    "note : the orthogonality of @xmath160 allows us to pairwise use the above construction for each @xmath158 . ]    for a markovian process discretized such that the stochastic matrix with elements @xmath35 describes its evolution , the above prescription supplies the unitary operation required for our quantum simulator when we set each @xmath161 , as per [ eq : qstates ] ( states @xmath69 and @xmath160 are in the same basis ) .",
    "we may now evaluate the action of a single time - step ( grey dashed box within [ fig : circuit ] ) . here",
    ", the joint hilbert space corresponds to that of the internal memory together with the output tape . in the figure",
    ", we explicitly wrote the initial state of the output tape as @xmath162 , but this is arbitrary ; any @xmath147 could be made into @xmath73 by acting on it first with a unitary gate containing @xmath163 . at the start of a time step ,",
    "the internal memory is in state @xmath164 .",
    "hence , the joint state of the memory and output tape is initially @xmath165 .",
    "after the controlled unitary is applied will be in the entangled state @xmath166 . applying a coherent swap operation ( i.e.  exchanging the labels of the hilbert spaces )",
    "will take this joint state to @xmath167  the state of the system at the end of the grey box .",
    "the tape system is then ejected from the simulator . if one were to measure this state in the @xmath69 basis , one projects onto state @xmath168 with probability @xmath169 , and hence the output statistics of this measurement match that of the process being simulated . moreover , after measuring , due to the entanglement , we know that when @xmath168 is measured , the internal memory must be in state @xmath170 , which is exactly the quantum state that would have been prepared if we had mapping the output statistics onto a classical causal state and then prepared @xmath170 directly .",
    "hence , the quantum circuit in [ fig : circuit ] can function as a discretized simulator for a markovian process .",
    "however , it is very important to note that there is no need whatsoever to measure the output tape @xmath168 for the quantum simulator to continue functioning .",
    "if it suits one s purpose to store the output states in quantum memory ( e.g.  to perform further quantum information processing on the output data ) , then the quantum simulator still functions correctly . in this mode of operation , the measurements can be omitted from [ fig : circuit ] , and after @xmath171 steps , the simulator would have produced the entangled state @xmath172 where @xmath173 is the quantum state that would have been prepared if the system was originally in causal state @xmath174 then outputted string @xmath175 , and a new causal state directly set according to this output sequence .",
    "measuring the string of output tape subsystems thus still ensures that the internal memory state collapses into the correct causal state @xmath176 , conditional on the string observed .",
    "* derivation of discrete eigenspectrum . *",
    "the quantum machine state corresponding to the system being in classical state @xmath178 is given as @xmath179 .",
    "assuming @xmath180 is simply connected , the quantum machine will reach a stationary state @xmath181 . rather than directly calculating the entropy of @xmath80",
    ", we can instead evaluate the entropy of the associated _ gram matrix _ @xmath182 , whose elements @xmath183 are given by the overlaps @xmath184 .",
    ", given @xmath185 ( where @xmath186 is an orthonormal basis ) such that @xmath187 and @xmath188 .",
    "since the von  neumann entropy of pure state @xmath189 is @xmath110 , it follows from triangle inequalities that @xmath190 . ] as the transition probabilities are translationally invariant , it follows that the gram matrix is _ circulant _  @xcite .",
    "since all rows can be derived by cyclic permutation of the top row , we shall drop one index and write the top row as @xmath191 .",
    "the eigenvalues of the gram matrix are given by @xmath192 for @xmath193 , which can immediately be recognized as the discrete fourier transform ( dft ) of @xmath194 , which we denote as @xmath195 .",
    "moreover , the inner product @xmath196 , has the form of a convolution @xmath197 , where we have rewritten @xmath198 as @xmath199 such that @xmath200 is the @xmath61-periodic extension of the reflection of @xmath201 ; @xmath202 and @xmath203 .",
    "we may then apply the circular convolution theorem to find the eigenvalues of @xmath182 , and therefore of  @xmath80 : @xmath204 \\mathcal{f}\\!\\left[\\sqrt{p_{(n - j)0}}\\right].\\ ] ] these eigenvalues can hence be found efficiently by numerical algorithms , such as the fast - fourier transform .",
    "_ example : dirac - delta shift function .",
    "_ let the shift function be @xmath205 for some @xmath206 .",
    "it can be seen that all @xmath207 except for the one at index @xmath208 that incorporates the delta peak where @xmath209 .",
    "hence , @xmath210 and @xmath211 , and so @xmath212 for all  @xmath213 .",
    "thus , the entropy requirement is @xmath122 .",
    "_ example : uniform shift function .",
    "_ consider the uniform shift function @xmath214 for @xmath60 .",
    "here , @xmath215 , and so @xmath216 = \\sqrt{n}$ ] for @xmath217 and @xmath110 for all other @xmath213 . as such , we find that the eigenvalue @xmath218 , and all other eigenvalues @xmath219 , and hence the entropy of the gram matrix is zero , for all values of  @xmath61 .",
    "* sampling fourier transforms .",
    "* it will be useful to show an auxiliary relationship between discrete and continuous fourier transforms .",
    "let @xmath220 be a function over the range @xmath221 $ ] that is sampled at @xmath61 equally spaced points with values given by @xmath222 for @xmath223 .",
    "we can construct a function @xmath224 , whose fourier transform is @xmath225 which when evaluated at integer @xmath213 is exactly the dft of the samples @xmath226 , which we write as @xmath227 .",
    "if @xmath182 is periodic , it is always possible to offset the position of the sample window of @xmath182 by some integer @xmath228 without changing the values of @xmath182 s dft . for the functions we consider in this article ,",
    "it is more convenient to start at @xmath229 , since typically @xmath230 and @xmath231 . moreover , once the sample window has been set , the values of @xmath220 outside this window can not affect @xmath79 , since they do not feature in the sum .",
    "thus , instead of considering sampling @xmath220 across a finite window , we can consider an infinite delta train sampled at the same intervals , but across a function @xmath232 where @xmath233 inside the range of the sample window ( i.e. @xmath234 for the window used in this article ) and @xmath235 outside this range . here",
    "@xmath236 where we have used the convolution theorem in the final step .",
    "the periodic sampling of @xmath220 causes the fourier transform to be periodic with period @xmath61 ( a phenomenon known as aliasing ) , such that @xmath237 ; the convolution with a delta train effectively makes @xmath79 a _ periodic sum _ of @xmath238 .",
    "this periodicity allows us the freedom to choose a convenient range of @xmath213 . in this article",
    ", we will typically use @xmath229 to @xmath239 .",
    "if @xmath240 outside the chosen range , then we can approximate @xmath241(k).\\ ] ]    * asymptotic limit of eigenvalues . * for large @xmath61 , we can derive an expression for @xmath79 in terms of the probability density function @xmath242 .",
    "we substitute @xmath243 with @xmath244 , which for riemann - integrable @xmath242 is an arbitrarily good approximation in the limit of @xmath42 .",
    "similarly , we may substitute @xmath198 with @xmath245 , where @xmath246 denotes the @xmath247-periodic extension to @xmath248 before evaluating @xmath242 .",
    "] of @xmath242 .",
    "we can then see , taking the limit of the riemann sum for a product of two functions , that @xmath249 , where @xmath250 . moreover ,",
    "since @xmath251 only has support in @xmath248 , we can rewrite the integral limits from @xmath252 to @xmath253 , and conclude that @xmath254(y)$ ] sampled at @xmath255 .",
    "thus by treating @xmath256 as samples from a function @xmath257 at discrete intervals of @xmath258 , we find that @xmath259 for large @xmath61 , and hence @xmath260\\left ( y \\right).\\ ] ]    as shown in eq .  ,",
    "the eigenvalues @xmath227 are given by @xmath261 $ ] evaluated at integers @xmath262 , where @xmath263 over an ( arbitrary ) single period of @xmath264 and takes the value zero elsewhere .",
    "due to the periodic summation , it can be seen also that @xmath237 , and so we are also free to choose the most convenient range for @xmath213 , which will typically be from @xmath229 to @xmath239 . if @xmath265(k ) \\approx 0 $ ] when @xmath266 , then the approximation @xmath267(k ) \\quad \\mathrm{for~ } k=-\\frac{n}{2 } , \\ldots \\frac{n}{2}-1\\ ] ] is reasonable .",
    "this corresponds to the case where aliased frequencies are negligible , and holds true for the examples we shall consider .",
    "* example 1 : gaussian noise .",
    "* suppose the shift function of the particle is given by a gaussian distribution @xmath92 about @xmath93 with standard deviation @xmath96 such that we can ignore the probability of the particle looping around the ring .",
    "likewise , we can express @xmath273 ^ 2 $ ] as a gaussian : @xmath274 ^ 2 & = \\sigma^{-2}\\left(2\\pi\\right)^{-1 } \\exp\\left(-\\frac{(x-\\mu)^2}{\\sigma^2}\\right ) \\nonumber \\\\ & \\hspace{-3em } = \\sigma^{-1}\\left(2\\pi\\right)^{-\\frac{1}{2 } } 2^{-\\frac{1}{2 } } ( \\frac{\\sigma}{\\sqrt{2}})^{-1 } \\left(2\\pi\\right)^{-\\frac{1}{2 } } \\exp\\left(-\\frac{(x-\\mu)^2}{2(\\frac{\\sigma}{\\sqrt{2}})^2}\\right ) \\nonumber \\\\ & \\hspace{-3em } = \\sigma^{-1}\\left(2\\pi\\right)^{-\\frac{1}{2 } } 2^{-\\frac{1}{2 } } g_{\\mu,\\frac{\\sigma}{\\sqrt{2}}}(x).\\end{aligned}\\ ] ]    taken together ( making sure to substitute in the correctly modified values of @xmath93 and @xmath94 ) , this allows us to provide an analytic solution for eq .   for gaussian shift functions : @xmath275 ^ 2 \\nonumber \\\\",
    "& = ( 2\\pi)^{-\\frac{1}{2 } } \\sigma^{-1 } ( \\frac{1}{2\\sqrt{2}\\pi\\sigma})^{-1 } ( 2\\pi)^{-\\frac{1}{2 } } 2^{-\\frac{1}{2 } } g_{0 , \\frac{1}{4\\pi\\sigma}}(k ) \\nonumber \\\\ & \\label{eq : gausstransapp } =   g_{0 , \\frac{1}{4\\pi\\sigma}}(k).\\end{aligned}\\ ] ] hence , we see that choosing gaussian transfer function with standard deviation @xmath96 corresponds to a spectrum of eigenvalues with standard deviation @xmath276 .    _ upper bound on quantum memory cost .",
    "_ we now demonstrate that the entropy of such a system , given @xmath277 , is finite by bounding it from above . for convenience , we write @xmath278 where @xmath279 and @xmath280 , and will perform the calculation in units of _",
    "nats_. thus , consider @xmath281 , explicitly @xmath282 by setting @xmath283 , we find that @xmath228 has stationary values at @xmath110 , @xmath284 and when @xmath285 when @xmath286 , these last two solutions disappear , and since we are in the regime of @xmath96 , this condition is satisfied .",
    "hence , for small @xmath94 , @xmath287 monotonically decreases from its maximum value at @xmath217 for both positive and negative @xmath213 .",
    "this allows us to apply the maclaurin ",
    "cauchy integral bound ( see e.g.  @xcite ) , @xmath288 which holds for any monotonically decreasing region @xmath289 of a function @xmath287 ( here , @xmath290 ) .    using known results for definite gaussian integrals , @xmath291",
    "we evaluate @xmath292 since @xmath293 , we find from equation   that @xmath294 to obtain a bound on @xmath82 , we double the above since @xmath287 is even , and multiply by @xmath295 to convert from _ nats _ to _ bits _ ( equivalently , change the base @xmath296 to @xmath297 since @xmath298 ) : @xmath299 . in terms of the shift function s",
    "standard deviation @xmath94 , this gives our result @xmath300    in the limit of small @xmath94 , the leading term of the entropy thus scales with @xmath121 , such that halving the width of the standard deviation adds one bit to the maximum required quantum memory cost .",
    "_ derivation of eigenvalues .",
    "_ taking the square root of this function alters its normalization , but not its shape : @xmath303 .",
    "suppose @xmath304 . in this case , @xmath305 yields the triangle function @xmath306 this function is independent of the constant displacement @xmath93 .",
    "indeed , non - zero @xmath93 only results in perfectly cancelling terms @xmath307 and @xmath308 in the fourier transform .",
    "basic fourier analysis tells us that @xmath309 transforms into a _ normalized sinc function _ ( @xmath310 ) , and the triangle function into the square of this : @xmath311 .",
    "as this tends to @xmath110 for large @xmath213 , we can approximate the values of @xmath79 for large @xmath61 using eq .  , to find the eigenspectrum @xmath312    _ upper bound on quantum memory cost . _ through the careful deployment of mildly  intimidating algebra",
    ", we can also derive an upper bound on entropy cost of simulating the square shift function .",
    "the outline of the proof is as follows . to bound @xmath313 where @xmath314",
    ", we first construct a monotonically decreasing function @xmath315 that satisfies @xmath316 at every @xmath213 , and then show that @xmath317 is bounded from above .",
    "this sum will hence also upper - bound @xmath313 . as with the gaussian example , for algebraic convenience",
    ", we will use natural logarithms and only consider the region of positive @xmath213 . in the final stage , we will convert from _ nats _ to _ bits _ , and use the evenness of @xmath287 to arrive at the full bound .      in the region @xmath320 , we can expand @xmath321.\\ ] ] the function @xmath322 has a maximum value of @xmath323 at @xmath324 , and so we can upper bound @xmath325 by making the substitution of @xmath326 with @xmath323 . since @xmath327 $ ] , in the region @xmath328 where @xmath329 , we can likewise upper bound @xmath325 by making the substitution of @xmath330 with @xmath247 .",
    "thus , for the region @xmath328 , we have a function @xmath331 given @xmath332.\\ ] ]    however , as we plan to ultimately apply the maclaurin  cauchy integral convergence test , it is only convenient to use this upper bound in the region of @xmath3 where @xmath333 monotonically decreases .",
    "we identify this region by setting @xmath334 , to find that @xmath333 decreases monotonically when @xmath335 , descending from its maximum value of @xmath336 .",
    "however , once again consider @xmath325 .",
    "since it has the form of @xmath337 , it follows that in _ any _ region , @xmath338 . since @xmath339 , we can then upper bound @xmath325 in the region of @xmath340 to form the monotonically decreasing function @xmath341 given @xmath342   & \\quad x >   \\sqrt{2\\delta }   \\exp\\left(\\frac{e-1}{2e}\\right ) , \\end{cases}\\ ] ] that is guaranteed to satisfy @xmath343 for all @xmath344 . at this point , it is convenient to express this again in terms of @xmath213 , making the substitution @xmath345 : @xmath346   & k >",
    "\\lceil k_{\\rm split } \\rceil , \\end{cases}\\ ] ] where @xmath347 represents the lowest integer above ( or including ) @xmath348 .",
    "this rounding is necessary since @xmath349 is in general not an integer . to upper bound @xmath287 at all points",
    ", we must round up this split between the regions of @xmath213 , since @xmath336 upper bounds all @xmath350 .",
    "( i.e.  being slightly too inclusive in the first region will result in a slightly higher value of @xmath315 for the first @xmath213 satisfying @xmath351 ) .",
    "having derived our monotonically decreasing function @xmath315 , we are now in a position to show that @xmath352 is finite for @xmath353 . writing @xmath354 ( for an upper bound , it is fine if a term is counted twice ! ) , we evaluate the two regions separately .",
    "firstly , @xmath355 where we have used @xmath356 . secondly , using the maclaurin - cauchy integral test ( see e.g.  @xcite ) , we bound @xmath357 where the second line follows by substituting @xmath358 with the maximum value of @xmath315 , and by failing to round up the lower bound of the integral ( thus including an extra contribution equal to @xmath359 ) .",
    "this integral may be analytically solved , @xmath360 \\hspace{-14.5em } & \\nonumber \\\\ & = \\left [ \\dfrac{-1}{2 \\pi^2 \\delta \\ ; k } \\left ( \\frac{1}{e } + 2 + 2\\ln \\left(\\pi\\sqrt{2 \\delta } k\\right ) \\right ) \\right]_{\\frac{1}{\\pi\\sqrt{2\\delta}}\\exp\\left(\\frac{e-1}{2e}\\right)}^\\infty \\nonumber \\\\ & = \\frac{3}{\\pi\\sqrt{2\\delta } } \\exp\\left(\\dfrac{1-e}{2e}\\right).\\end{aligned}\\ ] ]      finally , to bound the entropy @xmath362 , we must double the above ( @xmath287 is even , and equation   bounds only the region @xmath363 ) , and we convert from nats to bits ( by including a factor of @xmath364 ) : @xmath365          d.  deutsch . .",
    "_ proceedings of the royal society a : mathematical , physical and engineering sciences _ , 4000 ( 1818):0 97117 , jul 1985 .",
    "issn 1364 - 5021 .",
    "doi : 10.1098/rspa.1985.0070 .",
    "url http://rspa.royalsocietypublishing.org/content/400/1818/97 .",
    "l.  k. grover . .",
    "in _ proceedings of the twenty - eighth annual acm symposium on theory of computing _ , stoc 96 , pages 212219 , new york , ny , usa , 1996 .",
    "isbn 0 - 89791 - 785 - 5 .",
    "doi : 10.1145/237814.237866 .",
    "url http://doi.acm.org/10.1145/237814.237866 .",
    "gilles brassard . .",
    "_ foundations of physics _ , 330 ( 11):0 15931616 .",
    "issn 1572 - 9516 .",
    "doi : 10.1023/a:1026009100467 .",
    "url http://link.springer.com/article/10.1023/a{%}3a1026009100467[http://link.springer.com/article/10.1023/a\\{%}3a1026009100467 ] .",
    "c.  r. shalizi and j.  p. crutchfield . .",
    "_ journal of statistical physics _ , 1040 ( 3 - 4):0 817879 , 2001 .",
    "issn 00224715 .",
    "doi : 10.1023/a:1010388907793 .",
    "url http://link.springer.com/article/10.1023{%}2fa{%}3a1010388907793[http://link.springer.com/article/10.1023\\{%}2fa\\{%}3a1010388907793 ] .",
    "j.  p. crutchfield , c.  j. ellison , and j.  r. mahoney . .",
    "_ physical review letters _",
    ", page 094101 , 2009 .",
    "issn 00319007 .",
    "doi : 10.1103/physrevlett.103.094101 .",
    "url http://journals.aps.org/prl/abstract/10.1103/physrevlett.103.094101 .",
    "r.  haslinger , k.  l. klinkner , and c.  r. shalizi .",
    "_ neural computation _ , 220 ( 1):0 12157 , jan 2010 .",
    "issn 1530 - 888x .",
    "doi : 10.1162/neco.2009.12 - 07 - 678 .",
    "url http://www.mitpressjournals.org/doi/abs/10.1162/neco.2009.12-07-678{#}.vay3c{_}mqqko[http://www.mitpressjournals.org/doi/abs/10.1162/neco.2009.12-07-678\\{#}.vay3c\\{_}mqqko ] .",
    "c.  r. shalizi , k.  l. shalizi , and r.  haslinger .",
    "_ physical review letters _ , 930 ( 11):0 118701 , sep 2004 .",
    "issn 0031 - 9007 .",
    "doi : 10.1103/physrevlett.93.118701 .",
    "url http://www.ncbi.nlm.nih.gov/pubmed/15447385 .",
    "marques da silva , j.c .",
    "sartorelli , w.m .",
    "gonalves , and r.d .",
    "_ physics letters a _ , 2260 ( 5):0 269274 , feb 1997 .",
    "issn 03759601 .",
    "doi : 10.1016/s0375 - 9601(96)00941 - 3 .",
    "url http://www.sciencedirect.com/science/article/pii/s0375960196009413 .",
    "r.  w. clarke , m.  p. freeman , and n.  w. watkins . .",
    "_ physical review e _ , 670 ( 1):0 016203 , jan 2003 .",
    "issn 1063 - 651x .",
    "doi : 10.1103/physreve.67.016203 .",
    "url http://link.aps.org/doi/10.1103/physreve.67.016203 .    .",
    "_ physica a : statistical mechanics and its applications _ , 3790 ( 1):0 179187 , jun 2007 .",
    "issn 03784371 .",
    "doi : 10.1016/j.physa.2006.12.042 .",
    "url http://www.sciencedirect.com/science/article/pii/s0378437107000271 .",
    "li , h.  yang , and t.  komatsuzaki .",
    "_ proceedings of the national academy of sciences of the united states of america _ , 1050 ( 2):0 53641 , jan 2008 .",
    "issn 1091 - 6490 .",
    "doi : 10.1073/pnas.0707378105 .",
    "url http://www.pnas.org/content/105/2/536.abstract .",
    "c.  lu and r.  r. brooks . . in _ proceedings of the 2012 workshop on learning from authoritative security experiment results - laser 12 _ , pages 4146 , new york , new york , usa , jul 2012 .",
    "acm press .",
    "isbn 9781450311953 .",
    "doi : 10.1145/2379616.2379622 .",
    "url http://dl.acm.org/citation.cfm?id=2379616.2379622 .",
    "j.  r. mahoney , c.  aghamohammadi , and j.  p. crutchfield .",
    "_ scientific reports _ , 6:0 20495 , jan 2016 .",
    "issn 2045 - 2322 .",
    "doi : 10.1038/srep20495 .",
    "url http://www.nature.com/srep/2016/160215/srep20495/full/srep20495.html .",
    "p.  m. riechers , j.  r. mahoney , c.  aghamohammadi , and j.  p. crutchfield . .",
    "_ physical review a _ , 930 ( 5):0 052317 , may 2016 .",
    "issn 2469 - 9926 .",
    "doi : 10.1103/physreva.93.052317 .",
    "url http://journals.aps.org/pra/abstract/10.1103/physreva.93.052317 .",
    "j.  r. mahoney , c.  j. ellison , and j.  p. crutchfield . .",
    "_ journal of physics a : mathematical and theoretical _ , 420 ( 36):0 362002 , sep 2009 .",
    "issn 1751 - 8113 .",
    "doi : 10.1088/1751 - 8113/42/36/362002 .",
    "url http://stacks.iop.org/1751-8121/42/i=36/a=362002 .",
    "k.  wiesner , m.  gu , e.  rieper , and v.  vedral . .",
    "_ proceedings of the royal society a : mathematical , physical and engineering sciences _ , 468:0 40584066 , 2012 .",
    "issn 1364 - 5021 .",
    "doi : 10.1098/rspa.2012.0173 .",
    ".    s.  still , d.  a. sivak , a.  j. bell , and g.  e. crooks . .",
    "_ physical review letters _ , 1090 ( 12):0 120604 , sep 2012 .",
    "issn 0031 - 9007 .",
    "doi : 10.1103/physrevlett.109.120604 .",
    "url http://link.aps.org/doi/10.1103/physrevlett.109.120604 ."
  ],
  "abstract_text": [
    "<S> simulating the stochastic evolution of real quantities on a digital computer requires a trade - off between the precision to which these quantities are approximated , and the memory required to store them . </S>",
    "<S> the statistical accuracy of the simulation is thus generally limited by the internal memory available to the simulator . here , using tools from computational mechanics </S>",
    "<S> , we show that quantum processors with a fixed finite memory can simulate stochastic processes of real variables to arbitrarily high precision . </S>",
    "<S> this demonstrates a provable , unbounded memory advantage that a quantum simulator can exhibit over its best possible classical counterpart .    </S>",
    "<S> many macroscopic processes we wish to simulate involve the dynamics of real numbers . </S>",
    "<S> the dynamical properties we wish to track ( e.g.  the position of an object ) can take on almost any number , seemingly without noticeable quantization until one goes down to the planck scale . </S>",
    "<S> the simulation of such processes necessitates compromise between the resources allocated and the precision with which we track such properties . </S>",
    "<S> clever implementations to this problem , such as the floating point format  @xcite , form the heart of modern computing technology  but all subscribe to the same trade - off : treating a quantity with higher precision requires the allocation of more memory . to perfectly replicate the future statistics of a continuous variable dynamical system exactly </S>",
    "<S> would inevitably require unbounded memory .    </S>",
    "<S> the advent of quantum technology , however , opens new possibilities . </S>",
    "<S> not only has this technology shown great potential in solving problems many consider classically intractable  @xcite , it has demonstrated the capability to greatly reduce the amount of information one needs to send in certain tasks requiring communication between distributed parties  @xcite . </S>",
    "<S> could the memory required by a quantum machine that simulates dynamical processes likewise scale much more favourably with precision ?    here , we consider the simulation of a class of stochastic systems involving the dynamics of a parameters that takes on real numbers . </S>",
    "<S> classical simulation of such precesses digitally involves ` coarse - graining ' : the parameter at each point in time is approximated to @xmath0 bits of precision at some memory cost that scales linearly with @xmath0 . </S>",
    "<S> we construct quantum simulators the exhibit _ unbounded _ advantage . </S>",
    "<S> the quantum simulator can exactly replicate the statistics of a @xmath0 bit classical simulator for arbitrarily large @xmath0 using a bounded amount of memory . </S>",
    "<S> thus , quantum simulators can side - step the precision - memory tradeoff  </S>",
    "<S> finite quantum memory can simulate such processes to arbitrary fixed precision .    </S>",
    "<S> this unbounded divergence has practical and foundational consequences . </S>",
    "<S> practically , it suggests that quantum processors may be increasingly advantageous as we wish to simulate ever more memory - intensive systems , such as those arising from big data sets . </S>",
    "<S> foundationally , since the minimal memory required to simulate a process is a well established measure of its complexity  @xcite , our work suggests that there are certain processes which grow unboundedly in complexity , but yet remain simple to an observer with quantum capabilities .     </S>",
    "<S> * cyclic random walk . </S>",
    "<S> * at each time step , the system stochastically hops from state @xmath1 to @xmath2 $ ] . </S>",
    "<S> as @xmath3 is chosen according to the real random variable @xmath4 , the current value of the system is itself described by a sequence of real random variables @xmath5 that satisfy @xmath6 $ ] . , scaledwidth=30.0% ]    * cyclic random walks . * </S>",
    "<S> consider a small bead located on a circular ring ( as per [ fig : cyclicwalk ] ) . </S>",
    "<S> its position can always be described by some real number @xmath7 . at each discrete time @xmath8 , </S>",
    "<S> the bead s position is stochastically perturbed . </S>",
    "<S> this perturbation is described by a real random variable @xmath4 that is governed by a continuous probability density function @xmath9 ; such that @xmath10,\\ ] ] where @xmath11 represents the random variable that governs the location of the bead at time @xmath12 , and @xmath13 = y - \\lfloor y \\rfloor \\in [ 0,1)$ ] denotes the fractional part of @xmath14 ( @xmath15 is the lowest integer below or equal to @xmath14 ) ; and captures the fact that @xmath14 and @xmath16 represent the same location on the ring for any integer @xmath17 . </S>",
    "<S> we refer to @xmath9 as the _ shift function _ , and assume the process is stationary in the sense that @xmath9 has no explicit dependence on @xmath12 . </S>",
    "<S> although we motivate this process as a bead on a ring for clarity , the same formalism describes a diverse range of systems undergoing _ cyclic random walks _ </S>",
    "<S> , such as the azimuthal motion of gas molecules diffusing in an annular tube , or the position of a single electron travelling through an electric circuit with constant resistance .    </S>",
    "<S> we capture the dynamics of @xmath18 formally using the framework for describing stochastic processes . in general </S>",
    "<S> , a stochastic process @xmath19 is characterized by a bi - infinite sequence of random variables @xmath20 , that governs its value at each discrete time @xmath8 . for convenience , </S>",
    "<S> we often segregate past and future values , such that @xmath21 and @xmath22 respectively govern the values in the past and future with respect to time @xmath23 . </S>",
    "<S> the cyclic random walk above is then entirely captured by the joint probability distribution @xmath24 such that for any instance of the process with past values @xmath25 , future values @xmath26 will be observed with probability @xmath27 .    here , we consider the simulations of the above process to ever increasing precision . </S>",
    "<S> we adopt a natural technique of discretizing a continuous process , by introducing a family of stochastic processes @xmath28 that describe discrete approximations of this process , where in each the position of bead is represented to @xmath0 bits of precision by a @xmath0-digit binary number . </S>",
    "<S> this is done by limiting @xmath14 to a discrete set of @xmath29 equally  spaced values , @xmath30 ( for @xmath31 to @xmath32 ) . at each time - step , the probability that a bead in discrete location @xmath33 transitions to @xmath34 , is given by the probability @xmath35 that a bead initially at @xmath33 will transition to any value of @xmath14 whose @xmath0 bit binary representation is @xmath34 . </S>",
    "<S> that is @xmath36 where @xmath37 represents the interval on the ring that is ` rounded to ' @xmath34 . </S>",
    "<S> this results in a markovian stochastic process that emits a symbol from the finite alphabet @xmath38 at each time - step , whose dynamics are governed by the stochastic matrix with elements @xmath35 . as @xmath39 , the statistics of @xmath40 approach that of @xmath19 ; at the potential cost of tracking more information is uniformly distributed in @xmath41 . </S>",
    "<S> this yields asymptotically identical statistics as @xmath42 , and does not change the results of this article . ] .    </S>",
    "<S> * classical simulation costs scale with precision . </S>",
    "<S> * we can formally describe simulators using the tools of computational mechanics  @xcite . </S>",
    "<S> a simulator of a process is a device whose future output behaviour conditioned on any particular past should be statistically indistinguishable to the process itself . </S>",
    "<S> specifically , let the state of the simulator at each time - step be @xmath43 , such that at the subsequent time - step it can output @xmath44 and transition to state @xmath45 . </S>",
    "<S> for this device to be a statistically faithful simulation of a process @xmath46 , we require that :    1 .   for each specific past @xmath25 at each time @xmath12 , we can deterministically configure the device using a function @xmath47 into some state @xmath48 , such that it will produce future outputs @xmath26 with probability @xmath49 . </S>",
    "<S> 2 .   if a simulator is in state @xmath50 at time @xmath12 , and outputs @xmath51 in the subsequent time - step , its internal state must then transition to @xmath52 .    </S>",
    "<S> the first condition ensures the simulator can be initialized to simulate desired conditional future statistics ; the second that a correctly initialized simulator continues to exhibit statistically correct statistics at every time - step . </S>",
    "<S> the entropy of the simulator s internal state then represents the memory cost of the simulation , and is clearly bounded below by the information entropy of the random variable @xmath53 that governs it . </S>",
    "<S> thus , physically a simulator can be viewed as communication in time : it represents the exact object alice must give to bob at each time - step that captures sufficient past information for bob to replicate the processes conditional future behaviour . </S>",
    "<S> @xmath47 is known as the _ encoding function _ </S>",
    "<S> , that describes how the past is encoded within the .    the memory cost of the provably - optimal classical simulator  known as the _ statistical complexity _ </S>",
    "<S> , @xmath54  is extensively studied in complexity science  @xcite . </S>",
    "<S> this value captures the absolute minimum memory any classical simulator of a process must store , and thus is a prominent quantifier of a process s structure and complexity ( e.g.  @xcite ) . </S>",
    "<S> such an optimal simulator can be explicitly constructed , and corresponds to the simulator that stores in its internal memory the _ causal states _ of the process  @xcite : defined by an encoding function @xmath47 such that @xmath55 if and only if @xmath56 ( i.e. the conditional futures of @xmath25 and @xmath57 coincide ) .    in our cyclic </S>",
    "<S> random walks , each @xmath40 is markovian : the statistics of future outcomes depend only on the most - recent value of @xmath58 . when discretized , the causal states are thus typically in one - to - one correspondence with the @xmath59 discrete values that @xmath18 can take for @xmath60 , and the system jumps to a completely random point at each time - step ; here there is only one causal state for all @xmath61 , because the current position no longer affects the future outcomes at all . </S>",
    "<S> ] . </S>",
    "<S> that is , @xmath40 has @xmath59 causal states , labelled @xmath62 , where @xmath63 corresponds to the set of pasts ending in @xmath64 . at the steady state , </S>",
    "<S> @xmath65 , as all causal states occur with equiprobability , and thus classical statistical complexity @xmath66 scales linearly with the precision . </S>",
    "<S> * quantum simulations are memory  efficient . * </S>",
    "<S> quantum processors have recently being demonstrated the capability to simulate stochastic processes with less memory than any classically possible  @xcite . </S>",
    "<S> here , we construct an explicit quantum simulator for the cyclic random walk . instead of storing each causal states @xmath67 directly , our quantum simulator stores a corresponding quantum state @xmath68 where @xmath69 form an orthonormal basis .     </S>",
    "<S> * circuit for memory - efficient quantum simulation . * the above circuit illustrates a quantum simulator that samples @xmath70 when supplied with the appropriate quantum state @xmath71 that encodes the past . at @xmath72 , </S>",
    "<S> an ancilla system , initialized in state @xmath73 , is fed into the simulator . </S>",
    "<S> a controlled unitary is then enacted such that @xmath74 for each @xmath75 . </S>",
    "<S> the state of the ancillary system and memory are then coherently swapped , and the ancilla is then emitted as output . </S>",
    "<S> measurement of the ancilla then correct samples @xmath76 . </S>",
    "<S> iteration of this procedure then generates output behaviour statistical identical to that of the original process . </S>",
    "<S> , scaledwidth=40.0% ]    the stationary state of the quantum simulator is then given by the _ quantum ensemble state _ @xmath77 ( as all quantum states occur with equiprobability ) . </S>",
    "<S> thus the memory required to store these states is given by the von neumann entropy given @xmath78 , where @xmath79 are the eigenvalues of @xmath80 . </S>",
    "<S> the key improvement here is that @xmath81 are not in general mutually orthogonal , and thus @xmath82 is generally less than @xmath54 . </S>",
    "<S> nevertheless a quantum circuit ( outlined in figure  [ fig : circuit ]  with details in the _ technical appendix _ ) acting on these quantum states will produce statistically identical outputs to the classical simulator .    </S>",
    "<S> * unbounded advantage of quantum memory . </S>",
    "<S> * to the main claim of our paper : there are stochastic processes that can be simulated to infinite precision using a finite amount of quantum memory .    </S>",
    "<S> explicitly , we show that for certain cyclic processes , the quantum ensemble state s eigenvalues @xmath83 to satisfy @xmath84 for some finite value @xmath85 . </S>",
    "<S> our result relies on first observing that the eigenvalues @xmath79 can be directly related to transition probabilities @xmath86 via the relation @xmath87 \\mathcal{f}\\!\\left[\\sqrt{p_{(n - j)0}}\\right],\\ ] ] where @xmath88 denotes the _ discrete fourier transform _ , @xmath89 . </S>",
    "<S> ( the proof relies on invoking the cyclic symmetry of the process  and hence of the transition probabilities  and is explicitly derived in _ technical appendix _ ) . </S>",
    "<S> the spread @xmath90 ( as a function of @xmath75 ) is an indicator of how quickly a particle diffuses in the random walk . </S>",
    "<S> thus , the fourier - like relation between @xmath90 and @xmath79 indicates an inverse relationship between the amount of diffusion in the cyclic process and the spread of eigenvalues . </S>",
    "<S> the greater the variance of @xmath4 , the more quickly a particle diffuses , and the smaller the spread of @xmath79  resulting in a reduced quantum memory requirement . </S>",
    "<S> we now show that for some natural examples , this reduction is sufficiently large that @xmath91 remains bounded for all @xmath0 ( as illustrated in [ fig : examples ] ) .    </S>",
    "<S> 0.4     0.4      +    0.4     0.4      +    _ example 1 : gaussian noise . _ </S>",
    "<S> a cyclic process rotating at a constant rate subject to gaussian noise has a shift function given by a gaussian distribution @xmath92 about mean @xmath93 with standard deviation @xmath94 . </S>",
    "<S> here , @xmath93 characterises the average velocity ( in terms of the variable s mean displacement per time - step ) , and @xmath94 the size of the fluctuations . when @xmath95 , this process corresponds to gaussian diffusion . for our analysis </S>",
    "<S> , we take @xmath96 and thus ignore fluctuations where the particle travels more than a complete loop around the ring in a single time - step ( a value of @xmath97 ensures that such events are less likely than one part in a million . )    as can be seen in [ fig : gplot , fig : gslice ] , as the desired precision increases , the memory cost of simulating this process quickly converges onto a constant determined by the fluctuation strength @xmath94 ; ultimately , _ </S>",
    "<S> infinite - precision is possible using only a finite quantum memory_. this behaviour may be understood analytically by seeing that for large @xmath61 , the eigenvalues associated with the quantum simulator s internal memory are also given by samples from a gaussian distribution : @xmath98 for @xmath99 , where for convenience we have cyclicly offset the label of the eigenvalues indices by @xmath61 ( proof in _ technical appendix _ ) . </S>",
    "<S> this demonstrates that increasing @xmath94 tightens the spread of eigenvalues , and thus reduces the memory requirement for the quantum simulator .    in the _ technical appendix _ </S>",
    "<S> , we prove that as the precision @xmath100 increases , the sum @xmath101 converges on a finite value , bounded ( in bits ) by @xmath102 thus , for any fixed @xmath103 , the gaussian random walk may be simulated to arbitrarily high precision using a quantum simulator of bounded entropy . </S>",
    "<S> moreover , this also implies an unbounded divergence between the classical and the _ quantum statistical complexity _  </S>",
    "<S> @xcite @xmath104 , which is upper bounded by @xmath82 .    </S>",
    "<S> _ example 2 : uniform white noise . </S>",
    "<S> _ in the second example , we consider a particle that is perturbed by uniformly distributed noise . at each time - step </S>",
    "<S> , the particle can move anywhere in the range of @xmath105 from its current position with uniform probability , where @xmath106 . </S>",
    "<S> again , @xmath93 characterises the average velocity , and here @xmath107 the size of the fluctuations . </S>",
    "<S> the associated shift function is a _ top - hat function _ , that has a uniform value of @xmath108 in the range @xmath109 $ ] and @xmath110 everywhere else .    </S>",
    "<S> the entropy of the quantum simulator , @xmath91 is plotted for various precision in [ fig : thplot , fig : thslice ] . </S>",
    "<S> we see that for any fixed @xmath111 , the quantum memory required by our simulator converges to a bounded value . as in the gaussian scenario , </S>",
    "<S> the quantum simulate can replicate a classical simulation to any given precision using with finite entropy . </S>",
    "<S> in the _ technical appendix _ , we prove this analytically . </S>",
    "<S> we show that as @xmath112 , the entropy remains finite , and is bounded above by @xmath113 . </S>",
    "<S> in particular , for large @xmath61 , the eigenvalues of the relevant ensemble state obey @xmath114 for @xmath99 , where @xmath115 is the _ normalized sinc function _ </S>",
    "<S> , @xmath116 . </S>",
    "<S> larger values @xmath107 will result in a smaller spread of eigenvalues , and result is smaller @xmath91 . </S>",
    "<S> for any given @xmath111 the entropy is finite in the limit @xmath42 . </S>",
    "<S> this establishes a second natural example where the quantum simulator can demonstrate an unbounded memory advantage over its best possible classical counterpart .    * the origin of quantum advantage . * </S>",
    "<S> the source of classical inefficiency can be understood by considering dynamics on causal states . </S>",
    "<S> consider two instances of @xmath40 . </S>",
    "<S> one where @xmath64 , and the other where @xmath117 . </S>",
    "<S> as their conditional futures differ , a classical simulator must be configured differently for each instance ( corresponding to being initialized in one of two different causal states , @xmath63 or @xmath118 ) . </S>",
    "<S> nevertheless , there is finite probability that at the next time - step , both instances of the process emit the same output ( up to precision @xmath0 ) . </S>",
    "<S> should this happen , we would not be able to retrodict which causal state we came from . </S>",
    "<S> that is , there is some probability that the distinction between @xmath63 and @xmath118 will never be reflected in the future statistics of the process  a phenomenon known as crypticity  @xcite ) . </S>",
    "<S> as @xmath0 increases , this occurs with greater likelihood ( tending to unit probability as @xmath39 ) , and thus proportionally more information is wasted .    </S>",
    "<S> quantum simulators compensate for this waste by mapping these causal states to non - orthogonal quantum states . </S>",
    "<S> the quantum state ( [ eq : qstates ] ) associated with neighbouring causal states ( @xmath119 and @xmath120 ) also become increasingly similar with increasing @xmath0  resulting in progressively greater savings . </S>",
    "<S> consider the gaussian scenerio , where @xmath91 is bounded by equation  . for small @xmath94 , the memory cost scales as @xmath121 , such that halving the variance of flactuation s at each time - step adds one bit to the memory cost of the quantum simulator . </S>",
    "<S> the standard deviation of the shift function has set an effective length scale over which the system must be simulated classically . </S>",
    "<S> the statistical behaviour of future outputs from two systems that are initially prepared in points separated by more than one standard deviation are typically distinguishable , and so these points must be stored as nearly - orthogonal quantum states at some memory cost . on the other hand , when two points are initially closer than the standard deviation scale , the probability that they could be distinguished by their future behaviour diminishes , and they may be represented by increasingly overlapping quantum states . in this regime </S>",
    "<S> , a fixed finite memory can accommodate any desired precision .    </S>",
    "<S> * outlook and discussion . * in this article , we presented a task in which quantum mechanics has an unbounded memory advantage over the most memory - efficient classical alternative : the simulation of a classical cyclic stochastic process . </S>",
    "<S> we found that the classical simulator has a memory requirement that scales linearly with the precision required , while the quantum simulator s requirement may be bounded by a finite value , even at arbitrarily - high fixed precision . </S>",
    "<S> this establishes a rare scenario where the scaling advantage of quantum processing can be provably established .    </S>",
    "<S> this finding leads a number of natural open questions  the first being of generality . </S>",
    "<S> certainly , the examples presented are sufficiently simple that such divergences are unlikely to be merely a mathematical oddity . </S>",
    "<S> the unbounded quantum advantage relies on @xmath28 having two properties : ( a ) the number of causal states grows with @xmath0 , and ( b ) the conditional futures between different causal states converges sufficient quickly with @xmath0 . </S>",
    "<S> if these conditions can be formalized , we may be able to establish similar divergences much more general scenarios , such as the simulation of non - markovian or non - cyclic processes . </S>",
    "<S> meanwhile the inefficiency of classical simulators have show to directly results in unavoidable increased heat dissipation  @xcite . </S>",
    "<S> this hints that quantum processing may allow significant energetic savings for stochastic simulation , especially for systems that scale in complexity .    on a more foundational level </S>",
    "<S> , the statistical complexity is often regarded as a fundamental measure of a processes s intrinsic structure  the rationale being that it quantifies the minimal amount of causal information one most postulate to understand the process s future behaviour . </S>",
    "<S> the measure has been applied to understand structure within diverse settings , from the dynamics of neurons  @xcite to quantifying self - organization  @xcite , among other examples  @xcite . </S>",
    "<S> the discovery of more efficient quantum models led to great interest in the idea that complexity depends on what sort of information we use to observe a system  @xcite . in this context , </S>",
    "<S> our results establish a family of processes can look ever more complex classically , but remain simple quantum - mechanically . </S>",
    "<S> it would fascinating to see if such divergences can be found in existing studies , such that systems currently considered to be immensely complex may look rather simple through the lens of quantum theory .    </S>",
    "<S> * acknowledgements . * </S>",
    "<S> we thank thomas elliott , david  garner , larsson , and chengran  yang for helpful comments and discussions . </S>",
    "<S> we gratefully acknowledge funding from the john templeton foundation grant 53914 _ `` occam s quantum mechanical razor : can quantum theory admit the simplest understanding of reality ? '' _ ; the foundational questions institute ; the ministry of education in singapore , the academic research fund tier 3 moe2012-t3 - 1 - 009 ; and the the national research foundation of singapore ( award nos .  </S>",
    "<S> nrf  nrff201602 and nrf  crp14 - 2014 - 02 ) .     </S>"
  ]
}