{
  "article_text": [
    "in a typical longitudinal study , a number of variables are measured on a group of individuals and the goal is to analyze the relationships between the trajectories of the variables . in recent years , functional data analysis has provided efficient ways to analyze longitudinal data . in many cases",
    "the variable trajectories are discretized continuous curves that can be reconstructed by smoothing , and functional linear regression methods can be applied to study the relationship between the variables ( ramsay and silverman , 2005 ) .",
    "but in other situations the data is observed at sparse and irregular time points , which makes smoothing difficult or even unfeasible .",
    "therefore , functional regression methods that can be applied directly to the raw measurements become very useful .",
    "methods for functional data analysis of irregularly sampled curves have been proposed by a number of authors , for the one - sample problem as well as for the functional regression problem ( chiou et al . , 2004 ;",
    "james et al . , 2000 ; mller et al . , 2008 ; yao et al . , 2005a , 2005b ) .",
    "outlier - resistant techniques for the functional one - sample problem have also been proposed ( cuevas et al .",
    ", 2007 ; gervini , 2008 , 2009 ; fraiman and muniz , 2001 ; locantore et al . , 1999 ) , and two recent papers deal with robust functional regression for pre - smoothed curves ( zhu et al .  2011 ;",
    "maronna and yohai , 2012 ) .",
    "however , outlier - resistant functional regression methods for raw functional data have not yet been proposed in the literature . in this paper",
    "we address this problem and present a computationally simple approach based on random - effect models .",
    "our simulations show that this method attains the desired outlier resistance against atypical curves , and that the asymptotic distribution of the test statistic is approximately valid for small samples .    as an example of application",
    ", we will analyze the daily trajectories of oxides of nitrogen and ozone levels in the city of sacramento , california , during the summer of 2005 .",
    "the data is shown in figure fig : sample_curves .",
    "the goal is to predict ozone concentration from oxides of nitrogen .",
    "both types of curves follow regular patterns , but some atypical curves can be discerned in the sample .",
    "we will show in section sec : example that to a large extend it is indeed possible to predict ozone levels from oxides - of - nitrogen levels , but that the outlying curves distort the classical regression estimators and that the proposed robust method gives more reliable results .",
    "the paper is organized as follows .",
    "section [ sec : methods ] presents a brief overview of functional linear regression and introduces the new method .",
    "section [ sec : simulations ] reports the results of a comparative simulation study , and section [ sec : example ] presents a detailed analysis of the above mentioned ozone dataset .",
    "technical derivations and proofs are left to the appendix .",
    "matlab  programs implementing these procedures are available on the author s webpage .",
    "the functional approach to longitudinal data analysis assumes that the observations @xmath0 are discrete measurements of underlying continuous curves , so @xmath1where @xmath2 and @xmath3 are the trajectories of interest , @xmath4 and @xmath5 are random measurement errors , and @xmath6 and @xmath7 are the time points where the data is observed .",
    "the @xmath8s and the @xmath9s are random functions that we assume independent and identically distributed realizations of a pair @xmath10 .",
    "suppose @xmath11 and @xmath12 are square - integrable functions on an interval @xmath13 $ ] .",
    "define the norm @xmath14 and the inner product @xmath15 .",
    "if @xmath16 and @xmath17 are finite , then @xmath18 and @xmath12 admit the decomposition @xmath19known as the karhunen  love decomposition ( ash and gardner 1975 , ch .",
    "1.4 ) , where @xmath20 , @xmath21 , @xmath22 and @xmath23 are orthonormal functions ( i.e.@xmath24 and @xmath25 , where @xmath26 is kronecker s delta ) , and @xmath27 and @xmath28 are random variables with zero mean and finite variance ( without loss of generality , one can assume that @xmath29 and @xmath30 . )",
    "this is the functional equivalent of the principal - component decomposition in multivariate analysis , so the @xmath31s and @xmath32s are called principal components ,  and the @xmath33s and @xmath34s are called component scores . in principle",
    "@xmath35 and @xmath36 in ( [ eq : kl - x ] ) and ( [ eq : kl - y ] ) could be infinite , but since @xmath37 and @xmath38 are finite , the sequences @xmath39 and @xmath40 usually decrease to zero fast enough that for practical purposes @xmath35 and @xmath41 can be assumed to be finite .    methods for estimating the mean and",
    "the principal components of @xmath11 and @xmath42 can be found in ramsay and silverman ( 2005 ) , james et al .",
    "( 2000 ) , and yao et al .",
    "( 2005b ) .",
    "these methods are not resistant to outliers , though ; outlier - resistant estimators of the mean and principal components have been proposed by locantore et al .",
    "( 1999 ) , cuevas et al .",
    "( 2007 ) , and gervini ( 2008 , 2009 ) .",
    "we will use the method of gervini ( 2009 ) to estimate the mean and the principal components in ( [ eq : kl - x ] ) and ( [ eq : kl - y ] ) .",
    "this method is briefly reviewed in the appendix .",
    "now suppose that there is a functional linear relationship between @xmath11 and @xmath12 : @xmath43where @xmath44 is the intercept , @xmath45 the slope , and @xmath46 the error term .",
    "we assume @xmath47 and @xmath48 for all @xmath49 and @xmath50 .",
    "( note that the @xmath51 is not necessarily white noise ; it is just the portion of @xmath52 that is not explained by @xmath53 , and it is usually a smooth non - trivial process . )",
    "since ( [ eq : linear_model ] ) implies that @xmath54 , we can rewrite ( [ eq : linear_model ] ) as @xmath55then the only parameter that remains to be estimated is the regression slope @xmath56 .    since @xmath57 is an orthonormal basis of the @xmath53-space and @xmath58",
    "is an orthonormal basis of the @xmath52-space , without loss of generality the regression slope can be expressed as @xmath59 in matrix form , @xmath60 , where @xmath61 and @xmath62 .",
    "if we also collect the component scores @xmath27 and @xmath28 into vectors @xmath63 and @xmath64 , from ( [ eq : kl - x ] ) , ( [ eq : kl - y ] ) , ( [ eq : linear_model_2 ] ) and ( eq : beta ) we obtain @xmath65where @xmath66 is the random vector with elements @xmath67 .",
    "this reduces the functional regression model ( [ eq : linear_model_2 ] ) to a simpler multivariate regression model , @xmath68and the problem now is to estimate the regression matrix @xmath69 .",
    "as explained above , given the data @xmath70 we use the reduced - rank @xmath50 estimators of gervini ( 2009 ) to obtain robust estimators of @xmath71 , @xmath72 , @xmath57 , @xmath73 , @xmath74 and @xmath75 .",
    "by ( [ eq : beta ] ) and ( [ eq : reduced_linear_model ] ) , the least - squares estimator of @xmath45 would be @xmath76 with @xmath77however , this estimator is not robust .",
    "although the reduced - rank @xmath50 estimators of @xmath71 , @xmath78 , @xmath57 and @xmath73 are robust , the component scores @xmath79 and @xmath80 are individual parameters that will be outliers if the corresponding curves @xmath8 and @xmath9 are outliers .",
    "therefore , the estimator of @xmath81 has to incorporate a mechanism to downweight outlying @xmath82s and @xmath83s .",
    "this can be accomplished , for instance , by a modification of the @xmath50-type gm - estimators of he et al .",
    "( 2000 ) , that we will call gmt for short .",
    "let @xmath84where @xmath85 .",
    "these are the maximum likelihood estimators of @xmath86 and @xmath87 when @xmath88 in ( [ eq : reduced_linear_model ] ) follows a multivariate @xmath89 distribution with mean zero and scatter matrix @xmath90 , although we do not actually assume that @xmath88 follows this distribution ; as in he et al .",
    "( 2000 ) , this is just the motivation behind definition ( [ eq : wlne ] ) .",
    "it is shown in the appendix that @xmath91 and @xmath92 satisfy the fixed - point equations @xmath93where @xmath94 and @xmath95 .",
    "these equations can be solved iteratively by a reweighting algorithm .    as for the weights @xmath96 , they are essentially a by - product of the estimation of @xmath71 , @xmath57 and @xmath97 . since @xmath98 and @xmath99 , the @xmath100s are approximately uncorrelated with mean zero .",
    "the squared mahalanobis distance of @xmath79 is then @xmath101 , and large @xmath102s will correspond to @xmath53-outliers .",
    "the @xmath102s will follow an approximate @xmath103 distribution if the data is gaussian .",
    "this suggests a number of weighting schemes .",
    "one possibility is to use metric  trimming , @xmath104where @xmath105 is the @xmath106 quantile of the @xmath107 distribution .",
    "another possibility is to use rank - based  trimming , @xmath108the latter will always eliminate the @xmath109 observations with largest mahalanobis distances , even if they are not actual outliers ; so we recommend not using an unnecessarily large @xmath110 for rank - based trimming . in practice",
    ", the choice of @xmath110 can be based on the proportion of outliers observed in a boxplot or histogram of the @xmath102s .",
    "the estimator @xmath91 defined above belongs to the general class of m - estimators , which have well - known asymptotic properties ( van der vaart , 1998 , ch .",
    "as shown in the appendix , @xmath111 follows an approximate @xmath112 distribution for large @xmath113 , with @xmath114 .",
    "\\label{eq : b}\\end{aligned}\\]]the matrices @xmath115 and @xmath116 can be easily estimated , replacing expectations by averages .",
    "this asymptotic distribution can be used , for instance , to test significance of the regression : if @xmath117 , wald s statistic @xmath118 follows an approximate @xmath119 distribution for large @xmath113 , so we decide the regression is significant if @xmath120 for a given level @xmath110 .",
    "we can also construct marginal tests and confidence intervals for the individual coefficients @xmath121 .    in section [ sec :",
    "simulations ] we will study the accuracy of this asymptotic approximation . it is our experience that the distribution of @xmath122 approaches normality quite fast , but the above sandwich formula  tends to underestimate the variance when the sample size @xmath113 is small . in that case",
    "it is better to use bootstrap estimators of the covariance matrix of @xmath123 .",
    "in this section we study by simulation the finite - sample behavior of the estimators ( [ eq : wlne ] ) . to this end , we generated data from model ( eq : reduced_linear_model ) with @xmath124 and @xmath125 , where @xmath126 and @xmath127 .",
    "two regression parameters @xmath81 were considered : for the first set of simulations ( to study estimation error ) we took @xmath86 with @xmath128 and @xmath129 for @xmath130 ; for the second set of simulations ( to study the goodness of the asymptotic approximation of wald s test ) we took @xmath131 .",
    "the curves @xmath132 and @xmath3 were generated following ( [ eq : kl - x ] ) and ( [ eq : kl - y ] ) , with @xmath133 and @xmath134 equal to zero , @xmath135 and @xmath136 , for @xmath49 and @xmath50 in @xmath137 $ ] .",
    "the raw observations were generated following ( [ eq : raw - x ] ) and ( [ eq : raw - y ] ) , with random @xmath138s uniformly distributed in @xmath137 $ ] , @xmath139 and @xmath140 independent @xmath141 , and @xmath142 ; for simplicity we took the grid @xmath7 equal to @xmath6 .",
    "the first series of simulations were designed to study estimation error of the @xmath91s , both for clean and for outlier - contaminated data .",
    "we generated outliers by replacing @xmath143 $ ] of the pairs @xmath144 by @xmath145 , with @xmath146 and @xmath147 for @xmath148 , and @xmath149 .",
    "note that the contaminated data @xmath150 follows model ( [ eq : reduced_linear_model ] ) with @xmath131 and high - leverage @xmath151s , so the effect of this type of contamination is an underestimation of @xmath152 that tends to pull @xmath153 towards 0 .",
    "the estimation of @xmath86 requires two steps : first , to estimate @xmath154 and @xmath155 from the raw data , and then to compute @xmath91 from the @xmath79s and the @xmath83s .",
    "so we compared two procedures : a non - robust procedure , using reduced - rank normal models ( james et al . , 2000 ) to estimate the component scores , followed by the ordinary least - squares regression estimator ( [ eq : lse ] ) ; and a robust procedure , using reduced - rank @xmath50-models ( gervini , 2009 ) to estimate the component scores , followed by the gmt regression estimator ( [ eq : wlne ] ) .",
    "for the robust procedure , we considered the two types of weights @xmath96 discussed in section [ sec : robust - estim ] , with trimming proportions @xmath156 and @xmath157 ; degrees of freedom @xmath158 and @xmath159 were used for the @xmath50-models .",
    "four levels of contamination @xmath160 were considered : 0 ( clean data ) , @xmath161 , @xmath162 and @xmath163 .",
    "we took @xmath164 as sample size , @xmath165 as grid size , and @xmath166 as model dimensions . each case",
    "was replicated 1000 times . as measure of the estimation error we used the expected root",
    "integrated squared error @xmath167 , where @xmath168 .",
    "the results are reported in table [ tab : simulations_1 ] , along with monte carlo standard errors .",
    "we see that for non - contaminated data ( @xmath169 ) , there is no significant difference between metric and rank trimming for a given pair @xmath170 .",
    "the trimming proportion @xmath110 has a larger impact on the estimator s behavior than the degrees of freedom @xmath171 .",
    "for this reason we recommend choosing @xmath110 adaptively , so as not to cut off too much good data .",
    "when @xmath172 , we see that metric trimming  tends to outperform rank trimming  for a given pair @xmath173 .",
    "somewhat counterintuitively , estimators with @xmath159 tend to be more robust than those with @xmath158 for a given @xmath110 ; the reason is that for this type of contamination , which affects @xmath91 but not the @xmath174s or the @xmath175s , @xmath50 models with @xmath159 provide more accurate estimators of @xmath154 and @xmath176 than @xmath50 models with @xmath158 ( for other types of contamination this is no longer true , although @xmath50 models with @xmath159 are still very robust ; see gervini ( 2009 ) . ) in general , then , the recommendation is to use @xmath50-model estimators with metrically trimmed weights and a trimming proportion chosen adaptively .    .simulation results .",
    "mean root integrated squared errors of @xmath177 under various contamination proportions ( monte carlo standard errors in parenthesis ) . [",
    "cols=\"<,<,^,^,^,^ \" , ]",
    "ground - level ozone is an air pollutant known to cause serious health problems . unlike other pollutants",
    ", ozone is not emitted directly into the air but forms as a result of complex chemical reactions , including volatile organic compounds and oxides of nitrogen among other factors .",
    "modeling ground - level ozone formation has been an active topic of air - quality studies for many years .",
    "the california environmental protection agency database , available at http://www.arb.ca.gov/aqd/aqdcd/aqdcddld.htm , has collected data on hourly concentrations of pollutants at different locations in california for the years 1980 to 2009 . here",
    "we will focus on the trajectories of oxides of nitrogen ( nox ) and ozone ( o3 ) in the city of sacramento ( site 3011 in the database ) between june 6 and august 26 of 2005 , which make a total of 82 days ( shown in figure [ fig : sample_curves ] ) .",
    "there are a few days with some missing observations ( 9 in total ) , but since the method can handle unequal time grids , imputation of the missing data was not necessary .",
    "the first step in the analysis is to fit reduced - rank models to the sample curves .",
    "we used cubic b - splines with 7 equally spaced knots every 5 years , and fitted normal and @xmath178 ( cauchy ) reduced - rank models with up to 10 principal components . for both the response and the explanatory curves ,",
    "the leading three components explain at least 85% of the total variability , so we retained these models .",
    "the means and the principal components are plotted in figure [ fig : mean - pc ] . there is no substantial difference between the estimators obtained by these models , except perhaps for the mean and the third component of log - nox ( figures [ fig : mean - pc ] ( a ) and ( g ) ) .    with the normal component scores we computed the least squares estimator , obtaining @xmath179with the cauchy component scores we computed the gmt estimator with 1 degree of freedom and 10% metric trimming , obtaining @xmath180the latter cut off 5 observations out of the 82 .",
    "there are some noticeable differences between these two estimators , even leaving aside the third row ( which are not easily comparable , since @xmath181 and @xmath182 are rather different ) .",
    "the differences are more striking in the slope estimators @xmath183 and @xmath184 , shown in figure [ fig : betas ] .",
    "there is a bump  in @xmath184 around @xmath185 that does not appear in @xmath183 .",
    "this means that the robust slope estimator assigns positive weight to nox values around 8 am in the prediction of o3 levels around 4 pm , showing that there is a persistent effect of oxides - of - nitrogen level in ozone formation .    of course",
    ", none of this would be meaningful if the regression model was not statistically significant .",
    "but the estimated response curves , shown in figure [ fig : pred - y ] , clearly show that the model does predict the response curves to a large extent .",
    "the robust estimator provides a better fit overall , with a root median squared error of @xmath186 compared to the root median squared error of @xmath187 for the least squares estimator .",
    "the author was partly supported by nsf grants dms 0604396 and 1006281 .",
    "the method proposed by gervini ( 2009 ) to estimate the mean and the principal components of a stochastic process @xmath53 works as follows . the mean function @xmath188 and the principal components",
    "@xmath57 are modeled as spline functions ; that is , given a set of spline basis functions @xmath189 , chosen by the user , it is assumed that @xmath190 and @xmath191 .",
    "the observed vector @xmath192 can then be expressed as @xmath193where @xmath194_{(j , l)}$ ] , @xmath195 $ ] and @xmath196 .",
    "note that @xmath197 in this notation . by assuming @xmath198 has a standard multivariate @xmath50 distribution , robust maximum likelihood estimators of @xmath199 , @xmath200 , @xmath201 and @xmath202 are obtained .",
    "the estimators are computed via a standard em algorithm .",
    "the optimal number of components @xmath35 can be chosen via aic or bic criteria .",
    "see gervini ( 2009 ) for details .",
    "in addition to parameter estimates , the em algorithm yields predictors of the random effects @xmath203 , so one obtains @xmath204 as a by - product .",
    "the estimators of @xmath78 , @xmath205 , and @xmath176 are obtained in a similar way from the sample @xmath206 .",
    "the estimators @xmath91 and @xmath207 defined by ( [ eq : wlne ] ) are m - type estimators ( van der vaart , 1998 , ch .  5 ) , since they minimize a function of the form @xmath208 . specifically , @xmath209then",
    "@xmath91 and @xmath207 solve the equations @xmath210 and @xmath211 . to compute matrix derivatives we use the method of differentials ( magnus and neudecker , 1999 ) . differentiating with respect to @xmath212 we obtain @xmath213where @xmath214 .",
    "then @xmath215which can be rearranged in matrix form as @xmath216and ( [ eq : fixed - point - theta ] ) follows .",
    "differentiating @xmath217 with respect to @xmath218 we obtain @xmath219@xmath220so @xmath221@xmath222again , this can be expressed in matrix form as @xmath223@xmath224from which ( [ eq : fixed - point - sigma ] ) follows .",
    "we will simplify the derivation of the asymptotic distribution of @xmath225 by assuming that the true component scores @xmath226 are used , instead of the estimated scores @xmath227 , and by assuming that @xmath87 is fixed and known . in that case",
    "we can apply theorem 5.23 of van der vaart ( 1998 ) directly , and obtain that @xmath228 is asymptotically @xmath229 with @xmath230and @xmath231these expectations are taken with respect to the true parameters @xmath232 . without loss of generality we can eliminate the factor @xmath233 in ( [ eq : der - wrt - theta ] ) ; then it is easy to see that ( [ eq : b ] ) holds . to derive ( [ eq : a ] ) we use differentials again : @xmath234@xmath235so @xmath236@xmath237from which ( [ eq : a ] ) follows .",
    "ash , r. b. and gardner , m. f. ( 1975 ) . _ topics in stochastic processes_. probability and mathematical statistics ( vol .",
    "new york : academic press ."
  ],
  "abstract_text": [
    "<S> we present a robust regression estimator for longitudinal data , which is especially suited for functional data that has been observed on sparse or irregular time grids . </S>",
    "<S> we show by simulation that the proposed estimators possess good outlier - resistance properties compared with the traditional functional least - squares estimator . as an example of application </S>",
    "<S> , we study the relationship between levels of oxides of nitrogen and ozone in the city of san francisco .    _ </S>",
    "<S> key words : _ functional data analysis ; longitudinal data analysis ; mixed effects models ; robust statistics ; spline smoothing . </S>"
  ]
}