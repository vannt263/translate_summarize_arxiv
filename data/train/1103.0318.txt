{
  "article_text": [
    "clique finding procedures arise in the solutions to a wide variety of important application problems .",
    "the problem of finding cliques was first studied in social network analysis , as a way of finding closely - interacting communities of agents in a social network  @xcite . in bioinformatics , clique finding procedures",
    "have been used to find frequently occurring patterns in protein structures  @xcite , to predict the structures of proteins from their molecular sequences  @xcite , and to find similarities in shapes that may indicate functional relationships between proteins  @xcite .",
    "other applications of clique finding problems include information retrieval  @xcite , computer vision  @xcite , computational topology  @xcite , and e - commerce  @xcite .    for many applications",
    ", we do not want to report one large clique , but all maximal cliques .",
    "any algorithm which solves this problem must take exponential time in the worst - case because graphs can contain an exponential number of cliques  @xcite .",
    "however , graphs with this worst - case behavior are not typically encountered in practice .",
    "more than likely , the types of graphs that we will encounter are sparse  @xcite .",
    "therefore , the feasibility of clique listing algorithms lies in their ability to appropriately handle sparse input graphs .",
    "indeed , it has long been known that certain sparse graph families , such as planar graphs and graphs with low arboricity , contain only a linear number of cliques , and that all maximal cliques in these graphs can be listed in linear time  @xcite .",
    "in addition , there are also several methods to list all cliques in time polynomial in the number of cliques reported  @xcite , which can be done faster if parameterized on a sparsity measure such as maximum degree  @xcite .",
    "many different clique - finding algorithms have been implemented , and an algorithm of tomita et al .",
    "@xcite , based on the much earlier bron  kerbosch algorithm  @xcite , has been shown through many experiments to be faster by orders of magnitude in practice than others .",
    "an unfortunate drawback of the algorithm of tomita et al .",
    ", however , is that both its theoretical analysis and implementation rely on the use of an adjacency matrix representation of the input graph .",
    "for this reason , their algorithm has limited applicability for large sparse graphs , whose adjacency matrix may not fit into working memory .",
    "we therefore seek to have the best of both worlds : we would ideally like an algorithm that rivals the speed of the tomita et al .",
    "result , while having linear storage cost .",
    "recently , together with maarten lffler , the authors developed and published a new algorithm for listing maximal cliques , particularly optimized for the case that the input graph is sparse  @xcite .",
    "this new algorithm combines features of both the algorithm of tomita et al . and",
    "the earlier bron  kerbosch algorithm on which it was based , and maintains through its recursive calls a dynamic graph data structure representing the adjacencies between the vertices that remain relevant within each call . when analyzed using parameterized complexity in terms of the degeneracy of the input graph ( a measure of its sparsity ) its running time is near - optimal in terms of the worst - case number of cliques that a graph with the same sparsity could have .",
    "however , the previous work of the authors with lffler did not include any implementation or experimental results showing the algorithm to be good in practice as well as in theory .",
    "we implement the algorithm of eppstein , lffler , and strash for listing all maximal cliques in sparse graphs  @xcite . using a corpus of many large real - world graphs , together with synthetic data including the moon ",
    "moser graphs as well as random graphs , we compare the performance of our implementation with the algorithm of tomita et al .",
    "we also implement for comparison , a modified version of the tomita et al .",
    "algorithm that uses adjacency lists in place of adjacency matrices , and a simplified version of the eppstein ",
    "strash algorithm that represents its subproblems as lists of vertices instead of as dynamic graphs .",
    "our results show that , for large sparse graphs , the new algorithm is as fast or faster than tomita et al . , and sometimes faster by very large factors . for graphs that are not as sparse ,",
    "the new algorithm is sometimes slower than the algorithm of tomita et al . , but remains within a small constant factor of its performance .",
    "we work with an undirected graph @xmath0 with @xmath1 vertices and @xmath2 edges . for a vertex @xmath3 ,",
    "let @xmath4 be its neighborhood @xmath5 , and similarly for a subset @xmath6 let @xmath7 be the set @xmath8 , the common neighborhood of all vertices in @xmath9 .",
    "the degeneracy of a graph @xmath10 is the smallest number @xmath11 such that every subgraph of @xmath10 contains a vertex of degree at most @xmath11 .",
    "every graph with degeneracy @xmath11 has a _ degeneracy ordering _ , a linear ordering of the vertices such that each vertex has at most @xmath11 neighbors later than it in the ordering .",
    "the degeneracy of a given graph and a degeneracy ordering of the graph can both be computed in linear time  @xcite .",
    "* proc * tomita(@xmath12 , @xmath13 , @xmath14 )    report @xmath13 as a maximal clique choose a pivot @xmath15 to maximize @xmath16 tomita(@xmath17 , @xmath18 , @xmath19 ) @xmath20 @xmath21    the algorithm of tomita et al .",
    "@xcite is an implementation of bron and kerbosch s algorithm  @xcite , using a heuristic called _ pivoting",
    "_  @xcite .",
    "kerbosch algorithm is a simple recursive algorithm that maintains three sets of vertices : a partial clique @xmath13 , a set of candidates for clique expansion @xmath12 , and a set of forbidden vertices @xmath14 . in each recursive call , a vertex @xmath3 from @xmath12",
    "is added to the partial clique @xmath13 , and the sets of candidates for expansion and forbidden vertices are restricted to include only neighbors of  @xmath3 . if @xmath22 becomes empty , the algorithm reports @xmath13 as a maximal clique , but if @xmath12 becomes empty while @xmath14 is nonempty , the algorithm backtracks without reporting a clique .    in the basic version of the algorithm ,",
    "@xmath23 recursive calls are made , one for each vertex in @xmath12 .",
    "the pivoting heuristic reduces the number of recursive calls by choosing a vertex @xmath24 in @xmath25 called a _",
    "pivot_. all maximal cliques must contain a non - neighbor of @xmath24 ( counting @xmath24 itself as a non - neighbor ) , and therefore , the recursive calls can be restricted to the intersection of @xmath12 with the non - neighbors .",
    "the algorithm of tomita et al . chooses the pivot so that @xmath24 has the maximum number of neighbors in @xmath12 , and therefore the minimum number of non - neighbors , among all possible pivots . computing both the pivot and",
    "the vertex sets for the recursive calls can be done in time @xmath26 within each call to the algorithm , using an adjacency matrix to quickly test the adjacency of pairs of vertices .",
    "this pivoting strategy , together with this adjacency - matrix - based method for computing the pivots , leads to a worst - case time bound of @xmath27 for listing all maximal cliques  @xcite .",
    "* proc * degeneracy(@xmath28 , @xmath29 )    eppstein , lffler , and strash  @xcite provide a different variant of the bron ",
    "kerbosch algorithm that obtains near - optimal worst - case time bounds for graphs with low degeneracy .",
    "they first compute a degeneracy ordering of the graph ; the outermost call in the recursive algorithm selects the vertices @xmath3 to be used in each recursive call , in this order , without pivoting .",
    "then for each vertex @xmath3 in the order , a call is made to the algorithm of tomita et al .",
    "@xcite to compute all cliques containing @xmath3 and @xmath3 s later neighbors , while avoiding @xmath3 s earlier neighbors .",
    "the degeneracy ordering limits the size of @xmath12 within these recursive calls to be at most @xmath11 , the degeneracy of the graph .",
    "a simple strategy for determining the pivots in each call to the algorithm of tomita et al . , used as a subroutine within this algorithm , would be to loop over all possible pivots in @xmath30 and , for each one , loop over its later neighbors in the degeneracy ordering to determine how many of them are in @xmath12 .",
    "the same strategy can also be used to perform the neighbor intersection required for recursive calls . with the pivot selection and set intersection algorithms implemented in this way",
    ", the algorithm would have running time @xmath31 , a factor of @xmath11 larger than the worst - case output size , which is @xmath32 .    however , eppstein et al .",
    "provide a refinement of this algorithm that stores , at each level of the recursion , the subgraph of @xmath10 with vertices in @xmath22 and edges having at least one endpoint in @xmath12 . using this subgraph",
    ", they reduce the pivot computation time to @xmath33 , and the neighborhood intersection for each recursive call to time @xmath34 , which reduces the total running time to @xmath35 .",
    "this running time matches the worst - case output size of the problem whenever @xmath36 . as described by eppstein et al . ,",
    "storing the subgraphs at each level of the recursion may require as much as @xmath37 space .",
    "but as we show in section  [ sec : details ] , it is possible to achieve the same optimal running time with space overhead @xmath38 .      in our experiments , we were only able to run the algorithm of tomita et al .",
    "@xcite on graphs of small to moderate size , due to its use of the adjacency matrix representation . in order to have a basis for comparison with this algorithm on larger graphs",
    ", we also implemented a simple variant of the algorithm which stores the input graph in an adjacency list representation , and which performs the pivot computation by iterating over all vertices in @xmath22 and testing all neighbors for membership in @xmath12 .",
    "when a vertex @xmath3 is added to @xmath13 for a recursive call , we can intersect the neighborhood of @xmath39 with @xmath12 and @xmath14 by iterating over its neighbors in the same way .",
    "let @xmath40 be the maximum degree of the given input graph ; then the pivot computation takes time @xmath41 .",
    "additionally , preparing subsets for all recursive calls takes time @xmath42 . fitting these facts into the analysis of tomita et al .",
    "gives us a @xmath43 time algorithm .",
    "@xmath40 may be significantly larger than the degeneracy , so this algorithm s theoretical time bounds are not as good as those of tomita et al . or eppstein et al . ; nevertheless , the simplicity of this algorithm makes it competitive with the others for many problem instances .",
    "we implemented the algorithm of tomita et al . using the adjacency matrix representation , and the simple adjacency list representation for comparison .",
    "we also implemented three variants of the algorithm of eppstein , lffler , and strash : one with no data structuring , using the fact that vertices have few later neighbors in the degeneracy ordering , an implementation of the dynamic graph data structure that only uses @xmath44 extra space total , and an alternative implementation of the data structure based on bit vectors .",
    "the bit vector implementation executed no faster than the data structure implementation , so we omit its experimental timings and any discussion of its implementation details .",
    "is added to the partial clique @xmath13 , its neighbors in @xmath12 and @xmath14 ( highlighted in this example ) are moved toward the dividing line in preparation for the next recursive call . ]    , we keep an array containing neighbors in @xmath12 .",
    "we update these arrays whenever a vertex is moved from @xmath12 to @xmath13 , and whenever we need to intersect a neighborhood with @xmath12 and @xmath14 for a recursive call . ]",
    "we maintain the sets of vertices @xmath12 and @xmath14 in a single array , which is passed between recursive calls .",
    "initially , the array contains the elements of @xmath14 followed by the elements of @xmath12 .",
    "we keep a reverse lookup table , so that we can look up the index of a vertex in constant time . with this lookup table",
    ", we can tell whether a vertex is in @xmath12 or @xmath14 in constant time , by testing that its index is in the appropriate subarray . when a vertex @xmath3 is added to @xmath13 in preparation for a recursive call",
    ", we reorder the array .",
    "vertices in @xmath45 are moved to the end of the @xmath14 subarray , and vertices in @xmath46 are moved to the beginning of the @xmath12 subarray ( see figure  [ fig : pandx ] ) .",
    "we then make a recursive call on the subarray containing the vertices @xmath47 . after the recursive call",
    ", we move @xmath3 to @xmath14 by swapping it to the beginning of the @xmath12 subarray and moving the boundary so that @xmath3 is in the @xmath14 subarray .",
    "of course , moving vertices between sets will affect @xmath12 and @xmath14 in higher recursive calls . therefore , in a given recursive call , we maintain a list of the vertices that are moved from @xmath12 to @xmath14 , and move these vertices back to @xmath12 when the call ends .",
    "the pivot computation data structure is stored as set of arrays , one for each potential pivot vertex @xmath24 in @xmath22 , containing the neighbors of @xmath24 in @xmath12 .",
    "whenever @xmath12 changes , we reorder the elements in these arrays so that neighbors in @xmath12 are stored first ( see figure  [ fig : pandx - ds ] ) . computing the pivot is as simple as iterating through each array until we encounter a neighbor that is not in @xmath12 .",
    "this reordering procedure allows us to maintain one set of arrays throughout all recursive calls , requiring linear space total . making a new copy of this data structure for each recursive call would require space @xmath37 .",
    "we implemented all algorithms in the c programming language , and ran experiments on a linux workstation running the 32-bit version of ubuntu 10.10 , with a 2.53 ghz intel core i5 m460 processor ( with three cache levels of 128 kb , 512 kb , and 3,072 kb respectively ) and 2.6 gb of memory .",
    "we compiled our code with version 4.4.5 of the gcc compiler with the ` -o2 ` optimization flag .    in our tables of results , ``",
    "tomita '' is the algorithm of tomita et al .",
    ", `` maxdegree '' is the simple implementation of tomita et al.s algorithm for adjacency lists , and `` hybrid '' and `` degen '' are the implementations of eppstein , lffler , and strash with no data structure and with the linear space data structure , respectively .",
    "we provide the elapsed running running times ( in seconds ) for each of these algorithms ; an asterisk indicates that the algorithm was unable to run on that problem instance due to time or space limitations .",
    "in addition , we list the number of vertices @xmath1 , edges @xmath2 , the degeneracy @xmath11 , and the number of maximal cliques @xmath48 .    our primary experimental data consisted of four publicly - available databases of real - world networks , including non - electronic and electronic social networks as well as networks from bioinformatics applications .    * a data base curated by mark newman  @xcite ( table  [ table - uci ] ) which consists primarily of social networks ; it also includes word co - occurrence data and a biological neural network .",
    "many of its graphs were too small for us to time our algorithms accurately , but our algorithm was faster than that of tomita et al . on all four of the largest graphs ; in one case it was faster by a factor of approximately 130 . * the biogrid data  @xcite ( table  [ table - biogrid ] ) consists of several protein - protein interaction networks with from one to several thousand vertices , and varying sparsities .",
    "our algorithm was significantly faster than that of tomita et al .",
    "on the worm and fruitfly networks , and matched or came close to its performance on all the other networks , even the relatively dense yeast network .",
    "* we also tested six large social and bibliographic networks that appeared in the pajek data set but were not in the other data sets  @xcite ( table  [ table - pajek ] ) .",
    "our algorithm was consistently faster on these networks . due to their large size , the algorithm of tomita et al .",
    "was unable to run on two of these networks ; nevertheless , our algorithm found all cliques quickly in these graphs .",
    "* we also tested a representative sample of graphs from the stanford large network dataset collection  @xcite ( table  [ table - snap ] ) .",
    "these included road networks , a co - purchasing network from amazon.com data , social networks , email networks , a citation network , and two web graphs .",
    "nearly all of these input graphs were too large for the tomita et al .",
    "algorithm to fit into memory . for graphs which are extremely sparse",
    ", it is no surprise that the maxdegree algorithm was faster than our algorithm , but our algorithm was consistently fast on each of these data sets , whereas the maxdegree algorithm was orders of magnitude slower than our algorithm on the large soc - wiki - talk network .",
    ".experimental results for mark newman s data sets  @xcite [ cols=\"<,>,>,>,>,>,>,>,>,>\",options=\"header \" , ]     l@l@r@r@r@r@r@r & d & @xmath48 & tomita & maxdegree&hybrid & degen + n & p & & & & & & + & 0.6 & 51 & 59,898 & 0.08 & 0.26 & 0.25 & 0.14 + & 0.7 & 59 & 439,928 & 0.50 & 2.04 & 1.85 & 0.99 + & 0.8 & 70 & 5,776,276 & 6.29 & 28.00 & 24.86 & 11.74 + & 0.9 & 81 & 240,998,654 & 249.15 & 1136.15 & 1028.84&425.85 +",
    "+ & 0.1 & 21 & 3,663 & @xmath49&0.01 & 0.01 & @xmath49 + & 0.2 & 47 & 18,911 & 0.02 & 0.07 & 0.08 & 0.05 + & 0.3 & 74 & 86,179 & 0.10 & 0.44 & 0.49 & 0.24 + & 0.4 & 101 & 555,724 & 0.70 & 4.24 & 3.97 & 1.67 + & 0.5 & 130 & 4,151,668 & 5.59 & 42.37 & 36.35 & 13.05 + & 0.6 & 162 & 72,454,791 & 101.35 & 958.74 & 755.86 & 227.00 +   + & 0.1 & 39 & 15,311 & 0.02 & 0.03 & 0.06 & 0.04 + & 0.2 & 81 & 98,875 & 0.11 & 0.46 & 0.61 & 0.27 + & 0.3 & 127 & 701,292 & 0.86 & 5.90 & 6.10 & 2.29 + & 0.5 & 225 & 103,686,974 & 151.67 & 1888.20 & 1521.90&375.23 +   + & 0.1 & 56 & 38,139 & 0.04 & 0.10 & 0.19 & 0.09 + & 0.2 & 117 & 321,245 & 0.37 & 2.01 & 2.69 & 1.00 + & 0.3 & 184 & 3,107,208 & 4.06 & 36.13 & 38.12 & 11.47 +   + & 0.1 & 82 & 99,561 & 0.11 & 0.34 & 0.70 & 0.28 + & 0.2 & 172 & 1,190,899 & 1.45 & 10.35 & 14.48 & 4.33 + & 0.3 & 266 & 15,671,489 & 21.96 & 262.64 & 280.58 & 66.05 +   + 2,000 & 0.1 & 170 & 750,991 & 1.05 & 5.18 & 11.77 & 3.13 +   + 3,000 & 0.1 & 263 & 2,886,628 & 4.23 & 27.51 & 68.52 & 13.62 +   + & 0.001 & 7 & 49,716 & 1.19 & 0.04 & 0.07 & 0.07 + & 0.003 & 21 & 141,865 & 1.30 & 0.11 & 0.36 & 0.26 + & 0.005 & 38 & 215,477 & 1.47 & 0.25 & 1.03 & 0.51 + & 0.01 & 80 & 349,244 & 2.20 & 1.01 & 5.71 & 1.66 + & 0.03 & 262 & 3,733,699 & 9.96 & 20.66 & 133.94 & 20.67",
    "we have shown that the algorithm of eppstein , lffler , and strash is a practical algorithm for large sparse graphs .",
    "this algorithm is highly competitive with the algorithm of tomita et al . on sparse graphs , and within a small constant factor on other graphs .",
    "the advantage of this algorithm is that it requires only linear space for storing the graph and all data structures .",
    "it does not suffer from the drawback of requiring an adjacency matrix , which may not fit into memory .",
    "its closest competitor in this respect , the tomita et al .",
    "algorithm modified to use adjacency lists , is sometimes faster by a small factor but is also sometimes slower by a large factor .",
    "thus , the algorithm of eppstein et al . is a fast and reliable choice for listing maximal cliques , especially when the input graphs are large and sparse .    for future work",
    ", it would be interesting to compare our results with those of other popular clique listing algorithms .",
    "we attempted to include results from patric stergrd s popular cliquer program  @xcite in our tables ; however , at the time of writing , its newly implemented functionality for listing all maximal cliques returns incorrect results .",
    "we thank etsuji tomita and takeaki uno for helpful discussions .",
    "this research was supported in part by the national science foundation under grant 0830403 , and by the office of naval research under muri grant n00014 - 08 - 1 - 1015 .",
    "eppstein , d. , lffler , m. , strash , d. : listing all maximal cliques in sparse graphs in near - optimal time . in : cheong , o. ,",
    "chwa , k.y . ,",
    "park , k. ( eds . )",
    "isaac 2010 , lncs , vol .",
    "6506 , pp .",
    "springer - verlag ( 2010 )          grindley , h.m .",
    ", artymiuk , p.j . , rice , d.w . ,",
    "willett , p. : identification of tertiary structure resemblance in proteins using a maximal common subgraph isomorphism algorithm .",
    "229(3 ) , 707  721 ( 1993 )              kiss , g. , armstrong , c. , milroy , r. , , piper , j. : an associative thesaurus of english and its computer analysis . in : aitken  a.j . , bailey , r. , hamilton - smith , n. ( eds . ) the computer and literary studies .",
    "edinburgh : university press ( 1973 )                        leskovec , j. , lang , k.j . ,",
    "dasgupta , a. , mahoney , m.w . : community structure in large networks : natural cluster sizes and the absence of large well - defined clusters .",
    "internet mathematics 6(1 ) , 29123 ( 2009 )    lusseau , d. , schneider , k. , boisseau , o.j . , haase , p. , slooten , e. , dawson , s.m .",
    ": the bottlenose dolphin community of doubtful sound features a large proportion of long - lasting associations .",
    "behavioral ecology and sociobiology 54 , 396405 ( 2003 )                              zaki , m.j . ,",
    "parthasarathy , s. , ogihara , m. , li , w. : new algorithms for fast discovery of association rules . in : proc .",
    "knowledge discovery and data mining .",
    "aaai press ( 1997 ) , http://www.aaai.org/papers/kdd/1997/kdd97-060.pdf    zomorodian , a. : the tidy set : a minimal simplicial set for computing homology of clique complexes . in : proc .",
    "26th acm symp . computational geometry .",
    ". 257266 ( 2010 ) , http://www.cs.dartmouth.edu/~afra/papers/socg10/tidy-socg.pdf"
  ],
  "abstract_text": [
    "<S> we implement a new algorithm for listing all maximal cliques in sparse graphs due to eppstein , lffler , and strash ( isaac 2010 ) and analyze its performance on a large corpus of real - world graphs . </S>",
    "<S> our analysis shows that this algorithm is the first to offer a practical solution to listing all maximal cliques in large sparse graphs . </S>",
    "<S> all other theoretically - fast algorithms for sparse graphs have been shown to be significantly slower than the algorithm of tomita et al . </S>",
    "<S> ( theoretical computer science , 2006 ) in practice . </S>",
    "<S> however , the algorithm of tomita et al . uses an adjacency matrix , which requires too much space for large sparse graphs . </S>",
    "<S> our new algorithm opens the door for fast analysis of large sparse graphs whose adjacency matrix will not fit into working memory . </S>"
  ]
}