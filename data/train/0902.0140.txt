{
  "article_text": [
    "the feasibility of processing graphs in the data stream model was one of the early questions investigated in the streaming model @xcite .",
    "however the results were not encouraging , even to decide simple properties such as the connectivity of a graph , when the edges are streaming in an arbitrary order required @xmath3 space . in comparison to the other results in the streaming model ,",
    "@xcite which required polylogarithmic space , graph alogithms appeared to difficult in the streaming context and did not receive much attention subsequently .",
    "however in recent years , with the remergence of social and other interaction networks , questions of processing massive graphs have once again become prominent .",
    "technologically , since the publication of @xcite , it had become feasible to store larger quantities of data in memory and the semi - streaming model was proposed in @xcite . in this model",
    "we assume that the space is ( near ) linear in the number of vertices ( but not necessarily the edges ) .",
    "since its formulation , the model has become more appealing from the contexts of theory as well as practice . from a theoretical viewpoint",
    ", the model still offers a rich potential trade - off between space and accuracy of algorithm , albeit at a different threshold than polylogarithmic space . from a practical standpoint , in a variety of contexts involving large graphs , such as image segmentation using graph cuts ,",
    "the ability of the algorithm to retain the most relevant information in main memory has been deemed critical .",
    "in essence , an algorithm that runs out of main memory space would become unattractive and infeasible .",
    "in such a setting , it may be feasible to represent the vertex set in the memory whereas the edge set may be significantly larger .    in the semi - streaming model ,",
    "the first results were provided by @xcite on the construction of graph spanners .",
    "subsequently , beyond explorations of connectivity @xcite , and ( multipass ) matching @xcite , there has been little development of algorithms in this model . in this paper",
    "we focus on the problem of graph sparsification in a single pass , that is , constructing a small space representation of the graph such that we can estimate the size of any cut .",
    "graph sparsification @xcite remains one of the major building blocks for a variety of graph algorithms , such as flows and disjoint paths , etc . at the same time",
    ", sparsification immediately provides a way of finding an approximate min - cut in a graph .",
    "the problem of finding a min - cut in a graph has been one of the more celebrated problems and there is a vast literature on this problem , including both deterministic  @xcite as well as randomized algorithms  @xcite  see @xcite for a comprehensive discussion of various algorithms .",
    "we believe that a result on sparsification will enable the investigation of a richer class of problems in graphs in the semi - streaming model .",
    "in this paper we will focus exclusively on the model that the stream is adversarially ordered and a single pass is allowed . from the standpoint of techniques , our algorithm is similar in spirit to the algorithm of alon - matias - szegedy @xcite , where we simultaneously sample and estimate from the stream .",
    "in fact we show that in the semi - streaming model we can perform a similar , but non - trivial , simultaneous sampling and estimation .",
    "this is pertinent because sampling algorithms for sparsification exist  @xcite , which use @xmath4 edges .",
    "however these algorithms sample edges in an iterative fashion that requires the edges to be present in memory and random access to them .",
    "[ [ our - results ] ] our results : + + + + + + + + + + + +    our approach is to recursively maintain a summary of the graph seen so far and use that summary itself to decide on the action to be taken on seeing a new edge . to this end , we modify the sparsification algorithm of benczur and karger  @xcite for the semi  streaming model .",
    "the final algorithm uses a single pass over the edges and provides @xmath5 approximation for cut values with high probability and uses @xmath6 edges for @xmath7 node and @xmath8 edge graph .",
    "let @xmath9 denote the input graph and @xmath7 and @xmath8 respectively denote the number of nodes and edges .",
    "@xmath10 denotes the value of cut @xmath11 in @xmath9 .",
    "@xmath12 indicates the weight of @xmath13 in graph @xmath9 .",
    "@xcite a graph is * k - strong connected * if and only if every cut in the graph has value at least @xmath14 .",
    "* k - strong connected component * is a maximal node - induced subgraph which is k - strong connected .",
    "the * strong connectivity * of an edge @xmath13 is the maximum @xmath14 such that there exists a @xmath14-strong connected component that contains @xmath13 .    in @xcite ,",
    "they compute the strong connectivity of each edge and use it to decide the sampling probability .",
    "algorithm [ alg : sparsify ] is their algorithm .",
    "we will modify this in section [ sec : algdesc ] .",
    "[ alg : sparsify ] * benczur - karger*(@xcite )   + compute the strong connectivity of edge @xmath15 for all @xmath16 @xmath17    here @xmath18 is a parameter that depends on the size of @xmath9 and the error bound @xmath19 .",
    "they proved the following two theorems in their paper .",
    "[ thm : benczur_errorbound ]  @xcite given @xmath19 and a corresponding @xmath20 , every cut in @xmath21 has value between @xmath22 and @xmath1 times its value in @xmath9 with probability @xmath23 .",
    "[ thm : benczur_spacebound ]  @xcite with high probability @xmath21 has @xmath24 edges .    throughout this paper ,",
    "@xmath25 denotes the input sequence .",
    "@xmath26 is a graph that consists of @xmath27,@xmath28,@xmath29,@xmath30 .",
    "@xmath31 is the strong connectivity of @xmath13 in @xmath9 and @xmath12 is weight of an edge @xmath13 in @xmath9 .",
    "each edge has weight 1 in @xmath33 .",
    "@xmath34 where scalar multiplication of a graph and addition of a graph is defined as scalar multiplication and addition of edge weights .",
    "in addition , @xmath35 if and only if @xmath36 . @xmath37 is a sparsification of a graph @xmath26 , i.e. , a sparsified graph after considering @xmath30 in the streaming model .",
    "we can not use algorithm [ alg : sparsify ] in the streaming model since it is not possible to compute the strong connectivity of an edge in @xmath9 without storing all the data .",
    "the overall idea would be to use a strongly recursive process , where we use an estimation of the connectivity based on the current sparsification and show that subsequent addition of edges does not impact the process .",
    "the modification is not difficult to state , which makes us believe that such a modification is likely to find use in practice .",
    "the nontrivial part of the algorithm is in the analysis , ensuring that the various dependencies being built into the process does not create a problem . for completeness",
    "the modifications are presented in algorithm [ alg : streamsparsify ] .",
    "[ alg : streamsparsify ] * stream - sparsification * + @xmath38    we use @xmath39 given @xmath40 ; once again @xmath41 is a constant which determines the probability of success .",
    "we prove two theorems for algorithm [ alg : streamsparsify ] .",
    "the first theorem is about the approximation ratio and the second theorem is about its space requirement . for the simplicity of proof",
    ", we only consider sufficiently small @xmath19 .",
    "[ thm : correctness ] given @xmath40 , @xmath21 is a sparsification , that is @xmath35 , with probability @xmath42 .",
    "[ thm : space ] if @xmath35 , @xmath21 has @xmath43 edges .",
    "we use a sequence of ideas similar to that in benczur and karger  @xcite .",
    "let us first discuss the proof in @xcite .",
    "in that paper , theorem [ thm : benczur_errorbound ] is proved on three steps .",
    "first , the result of karger  @xcite , on uniform sampling is used .",
    "this presents two problems .",
    "the first is that they need to know the value of minimum cut to get a constant error bound .",
    "the other is that the number of edges sampled is too large .",
    "in worst case , uniform sampling gains only constant factor reduction in number of edges .    to solve this problem , benczur and karger  @xcite decompose a graph into @xmath14-strong connected components . in a @xmath14-strong connected component ,",
    "minimum - cut is at least @xmath14 while the maximum number of edges in @xmath14-strong connected component(without @xmath44-strong connected component as its subgraph ) is at most @xmath45 .",
    "they used the uniform sampling for each component and different sampling rate for different components . in this way",
    ", they guarantee the error bound for every cut .",
    "we can not use karger s result @xcite directly to prove our sparsification algorithm because the probability of sampling an edge depends on the sampling results of previous edges .",
    "we show that the error bound of a single cut by a suitable bound on the martingale process . using that we prove that if we do not make an error until @xmath46 edge , we guarantee the same error bound for every cut after sampling @xmath47 edge with high probability . using union bound , we prove that our sparsification is good with high probability .",
    "we prove theorem [ thm : correctness ] first .",
    "first , we prove the error bound of a single cut in lemma [ thm : errorbound_singlecut ] . the proof will be similar to that of chernoff bound  @xcite .",
    "@xmath48 in lemma [ thm : errorbound_singlecomponent ] is a parameter and we use different @xmath48 for different strong connected components in the later proof .",
    "[ thm : errorbound_singlecut ] let @xmath49 with @xmath50 be a cut in a graph @xmath9 such that @xmath51 and @xmath52 .",
    "the index of the edges corresponds to the arrival order of the edges in the data stream .",
    "let @xmath53 be an event such that @xmath54 for all @xmath55 .",
    "let @xmath21 be a sparsification of @xmath9 .",
    "then , @xmath56 < 2\\exp(-\\beta^2pc/4)$ ] for any @xmath57 .",
    "let @xmath58 and @xmath59=pw_g(e_{i_j})$ ] .",
    "then , @xmath60 if and only if @xmath61 .",
    "as already mentioned , we can not apply chernoff bound because there are two problems :    1 .",
    "@xmath62 are not independent from each other and 2 .",
    "values of @xmath62 are not bounded .",
    "the second problem is easy to solve because we have @xmath53 .",
    "let @xmath63 be random variables defined as follows : @xmath64 if @xmath53 happens , @xmath65 .",
    "thus , @xmath66   & = & { \\mathbb{p}}[a_{c}\\wedge(|\\sum_j x_j-\\sum_j \\mu_j|>\\beta pc ) ] \\nonumber \\\\   & = & { \\mathbb{p}}[a_{c}\\wedge(|\\sum_j y_j-\\sum_j \\mu_j|>\\beta pc ) ] \\nonumber \\\\   & \\leq & { \\mathbb{p}}[|\\sum_j y_j-\\sum_j \\mu_j|>\\beta pc ] \\label{eqn : conclusion}\\end{aligned}\\ ] ]    the proof of ( [ eqn : conclusion ] ) is similar to chernoff bound  @xcite . however , since we do not have independent bernoulli random variables , we need to prove the upperbound of @xmath67 $ ] given @xmath68 .",
    "we start with @xmath69 $ ] .",
    "[ thm : yibound ] @xmath70\\leq \\exp(\\mu_j(e^t-1))$ ] for any @xmath68 and @xmath71 .",
    "there are two cases . given @xmath71 , @xmath72 or @xmath73 . at the end of each case , we use the fact that @xmath74 .",
    "case 1 : if @xmath73 , @xmath75 .",
    "@xmath76   & = & \\exp(t\\mu_j ) \\nonumber \\\\   & < & \\exp(\\mu_j(e^t-1 ) ) .",
    "\\nonumber\\end{aligned}\\ ] ]    case 2 : if @xmath77 , @xmath65 .",
    "so @xmath70={p_{e_{i_j}}}\\exp(t\\mu_j/{p_{e_{i_j}}})+(1-{p_{e_{i_j}}})$ ] .",
    "let @xmath78 .",
    "observe that @xmath79 for @xmath80 .",
    "so @xmath81 is decreasing function .",
    "also we have @xmath82 since @xmath51 .",
    "hence , @xmath83 therefore , @xmath76 & \\leq & \\mu_j(\\exp(t)-1)+1 \\nonumber \\\\                       & \\leq & \\exp(\\mu_j(e^t-1 ) ) .",
    "\\nonumber\\end{aligned}\\ ] ] from case 1 and 2 , @xmath70\\leq\\exp(\\mu_j(e^t-1))$ ] for any @xmath71 .",
    "now , we prove the upperbound of @xmath67 $ ] .",
    "[ thm : sibound ] let @xmath84 . for any @xmath68 and @xmath71 , @xmath85\\leq\\exp(\\sum_{k = j}^{l}\\mu_j(e^t-1))$ ] .",
    "we prove by induction . for @xmath86 , @xmath85={\\mathbf e}[\\exp(ty_l)|{h_{i_j-1}}]\\leq\\exp(\\mu_l(e^t-1))$ ] by lemma [ thm : yibound ] .",
    "assume that @xmath87\\leq\\exp(\\sum_{k = j+1}^{l}\\mu_k(e^t-1))$ ] for any @xmath88 .",
    "then , @xmath89   & = & \\sum_{y } { \\mathbb{p}}[y_j = y|{h_{i_j-1 } } ] \\sum_{{h_{i_{j+1}-1 } } } { \\mathbf e}[\\exp(t(y+s_{j+1}))|{h_{i_{j+1}-1}}]{\\mathbb{p}}[{h_{i_{j+1}-1}}|y_j = y,{h_{i_j-1 } } ] \\nonumber \\\\   & = & \\sum_{y } \\exp(ty ) { \\mathbb{p}}[y_j = y|{h_{i_j-1 } } ] \\sum_{{h_{i_{j+1}-1 } } } { \\mathbf e}[\\exp(ts_{j+1})|{h_{i_{j+1}-1}}]{\\mathbb{p}}[{h_{i_{j+1}-1}}|y_j = y,{h_{i_j-1 } } ] \\nonumber \\\\   & \\leq & \\sum_{y } { \\mathbb{p}}[y_j = y|{h_{i_j-1 } } ] \\exp\\left(\\sum_{k = j+1}^{l}\\mu_k(e^t-1)\\right ) \\nonumber \\\\   & = & \\exp\\left(\\sum_{k = j+1}^{l}\\mu_k(e^t-1)\\right ) { \\mathbf e}[y_j|{h_{i_j-1 } } ] \\nonumber \\\\   & \\leq & \\exp\\left(\\sum_{k = j}^{l}\\mu_k(e^t-1)\\right ) \\nonumber\\end{aligned}\\ ] ] therefore , @xmath85\\leq\\exp(\\sum_{k = j}^{n}\\mu_k(e^t-1))$ ] for any @xmath71 and @xmath68 .",
    "now we prove lemma [ thm : errorbound_singlecut ] . remember that we only need to prove @xmath90 < 2\\exp(-\\beta^2pc/4)$ ] by ( [ eqn : conclusion ] ) .",
    "let @xmath91 and @xmath92 .",
    "we prove in two parts : @xmath93\\leq \\exp(-\\beta^2\\mu/4)$ ] and @xmath94\\leq \\exp(-\\beta^2\\mu/4)$ ] .",
    "we prove @xmath93<\\exp(-\\beta^2\\mu/4)$ ] first . by applying markov s inequality to @xmath95 for any @xmath96",
    ", we obtain @xmath97}{\\exp(t(1+\\beta)\\mu ) } \\nonumber \\\\   & \\leq & \\frac{\\exp(\\mu(e^t-1))}{\\exp(t(1+\\beta)\\mu)}. \\nonumber\\end{aligned}\\ ] ] the second line is from lemma [ thm : sibound ] . from this point , we have identical proof as chernoff bound  @xcite that gives us bound @xmath98 for @xmath99 . to prove that @xmath94<\\exp(-\\beta^2pc/4)$ ] we applying markov s inequality to @xmath100 for any @xmath96 , and proceed similar to above . using union bound to these two bounds , we obtain a bound of @xmath101 .",
    "now we prove the following lemma given a @xmath14-strong connected component and parameter @xmath48 .",
    "this corresponds to the proof of uniform sampling method in @xcite .",
    "[ thm : errorbound_singlecomponent ] let @xmath102 be a @xmath14-strong component such that each edge has weight at most 1 .",
    "@xmath103 is its sparsified graph .",
    "let @xmath104 for some constant @xmath105 .",
    "suppose that @xmath106 be an event such that every edge in @xmath102 has sampled with probability at least @xmath48 .",
    "then , @xmath107={\\mathcal{o}}(1/n^{2+d}m)$ ] .",
    "consider a cut @xmath11 whose value is @xmath108 in @xmath102 .",
    "if @xmath106 holds , every edge in @xmath11 is also sampled with probability at least @xmath48 . by lemma [ thm : errorbound_singlecut ] , @xmath109\\leq 2\\exp(-\\beta^2p\\alpha k/4)=2(n^{4+d}m)^{-\\alpha}$ ] .",
    "let @xmath110 .",
    "let @xmath111 be the number of cuts with value less or equal to @xmath108 .",
    "by union bound , we have @xmath112\\leq p(1)f(1)+\\int_1^{\\infty}p(\\alpha)\\frac{df}{d\\alpha}d\\alpha.\\ ] ] the number of cuts whose value is at most @xmath113 times minimum cut is at most @xmath114 . since the value of minimum cut of @xmath102 is @xmath14 , @xmath115 . since @xmath116 is a monotonically increasing function , this bound",
    "is maximized when @xmath117 .",
    "thus , @xmath118   & \\leq & f(1)p(1)+\\int_1^{\\infty}p(\\alpha)\\frac{df}{d\\alpha}d\\alpha \\nonumber \\\\   & \\leq & n^2p(1)+\\int_1^{\\infty}p(\\alpha)(2n^{2\\alpha}\\ln n)d\\alpha \\nonumber \\\\   & \\leq & \\frac{2}{n^{2+d}m}+\\int_1^{\\infty}\\frac{\\ln n}{n^{\\alpha ( 2+d)}m^{\\alpha}}d\\alpha \\nonumber \\\\   & = & { \\mathcal{o}}(1/n^{2+d}m ) .",
    "\\nonumber\\end{aligned}\\ ] ]      [ thm : errorbound_singlestep ] the probability of @xmath119 being the first integer such that @xmath120 is @xmath121 .",
    "if @xmath122 for all @xmath123 , @xmath124 . remember that @xmath31 denotes the strong connectivity of @xmath13 in graph @xmath9 .",
    "@xmath125 @xmath126 is a sparsification of @xmath127 .",
    "@xmath128 consists of @xmath129-strong connected components . for every @xmath130 , @xmath131 .",
    "so it is sampled with probability at least @xmath132 .",
    "if we consider one @xmath129-strong connected component and set @xmath39 , by lemma [ thm : errorbound_singlecomponent ] , every cut has error bound @xmath133 with probability at least @xmath134 . since there are less than @xmath135 such distinct strong connected components , with probability at least @xmath136 , @xmath137 for every @xmath138 .",
    "hence , @xmath139 therefore , @xmath140={\\mathcal{o}}(1/n^dm)$ ] .    from lemma [ thm : errorbound_singlestep ] , theorem [ thm : correctness ] is obvious .",
    "j < i.h_j \\in ( 1\\pm\\epsilon)g_j)\\wedge(h_i\\notin ( 1\\pm\\epsilon)g_i)]={\\mathcal{o}}(1/n^d)$ ] .      for the proof of theorem [ thm : space ] , we use the following property of strong connectivity .",
    "[ thm : connectivity_bound ]  @xcite if the total edge weight of graph @xmath9 is @xmath142 or higher , there exists a @xmath14-strong connected components .",
    "@xmath35 , total edge weight of @xmath21 is at most @xmath143 .",
    "let @xmath144 be a cut @xmath145 .",
    "since @xmath35 , @xmath146 .",
    "total edge weight of @xmath21 is @xmath147 since each edge is counted for two such cuts .",
    "similarly , @xmath9 has @xmath148 edges . therefore , if @xmath35 , total edge weight of @xmath21 is at most @xmath143 .",
    "let @xmath149 .",
    "@xmath150 is a set of edges that sampled with @xmath151 .",
    "we want to bound the total weight of edges in @xmath150 .",
    "@xmath152 .",
    "let @xmath153 be a subgraph of @xmath21 that consists of edges in @xmath150 .",
    "@xmath153 does not have @xmath154-strong connected component .",
    "suppose that it has .",
    "then there exists the first edge @xmath13 that creates a @xmath154-strong connected component in @xmath153 . in that case",
    ", @xmath30 must be in the @xmath154-strong connected component .",
    "however , since weight @xmath13 is at most @xmath155 , that component is at least @xmath44-strong connected without @xmath13 .",
    "this contradicts that @xmath156 .",
    "therefore , @xmath153 does not have any @xmath154-strong connected component . by lemma [ thm : connectivity_bound ] , @xmath152 .",
    "now we prove theorem [ thm : space ] .    if the total edge weight is the same , the number of edges is maximized when we sample edges with smallest strong connectivity .",
    "so in the worst case ,    @xmath157 in that case , @xmath14 is at most @xmath158 .",
    "let this value be @xmath159 . then",
    ", total number of edges in @xmath21 is @xmath160",
    "first , we prove a simple space lowerbound for weighted graphs , where the lowerbound depends on @xmath19 .",
    "[ thm : lowerbound ] for @xmath161 , @xmath162 bits are required in order to sparsify every cut of a weighted graph within @xmath163 factor where @xmath11 is maximum edge weight and @xmath164 is minimum edge weight .",
    "let @xmath165 be a set of graphs such that there is a center node @xmath166 and other nodes are connected to @xmath166 by an edge whose weight is one of @xmath167 .",
    "then , @xmath168 .",
    "for @xmath169 , they must have different sparsifications .",
    "so we need @xmath170 bits for sparsfication .",
    "it is easy to show that @xmath171 .",
    "now we use the same proof idea for unweighted simple graphs .",
    "since we can not assign weight as we want , we use @xmath172 nodes as a center instead of having one center node . in this way",
    ", we can assign degree of a node from @xmath164 to @xmath172 .",
    "[ thm : unweighted_lowerbound ] for @xmath161 , @xmath173 bits are required in order to sparsify every cut of a graph within @xmath163 .",
    "consider bipartite graphs where each side has exactly @xmath172 nodes and each node in one side has a degree @xmath174 or @xmath172 .",
    "for each degree assignment , there exists a graph that satisfies it .",
    "let @xmath165 be a set of graphs that has different degree assignments .",
    "then , @xmath175 .",
    "@xmath169 can not have the same sparsification .",
    "so we need at least @xmath176 bits .    another way of viewing the above claim is a direct sum construction , where we need to use @xmath177 bits to count upto a precision of @xmath1 .",
    "we presented a one pass semi - streaming algorithm for the adversarially ordered data stream model which uses @xmath178 edges to provide @xmath19 error bound for cut values with probability @xmath179 .",
    "if the graph does not have parallel edges , the space requirement reduces to @xmath180 . we can solve the minimum cut problem or other problems related to cuts with this sparsification . for the minimum cut problem , this provides one - pass @xmath181-approximation algorithm .",
    "andrs  a. benczr and david  r. karger . approximating s - t minimum cuts in o(n2 )",
    "time . in _",
    "stoc 96 : proceedings of the twenty - eighth annual acm symposium on theory of computing _ , pages 4755 , new york , ny , usa , 1996 .",
    "chandra  s. chekuri , andrew  v. goldberg , david  r. karger , matthew  s. levine , and cliff stein .",
    "experimental study of minimum cut algorithms . in _",
    "soda 97 : proceedings of the eighth annual acm - siam symposium on discrete algorithms _ , pages 324333 , philadelphia , pa , usa , 1997 .",
    "society for industrial and applied mathematics .",
    "jianxiu hao and james  b. orlin . a faster algorithm for finding the minimum cut in a graph . in _ soda 92 : proceedings of the third annual acm - siam symposium on discrete algorithms _ , pages 165174 , philadelphia , pa , usa , 1992 . society for industrial and applied mathematics .",
    "david  r. karger .",
    "global min - cuts in rnc , and other ramifications of a simple min - out algorithm . in _ soda 93 : proceedings of the fourth annual acm - siam symposium on discrete algorithms _ , pages 2130 , philadelphia , pa , usa , 1993 .",
    "society for industrial and applied mathematics .",
    "david  r. karger .",
    "random sampling in cut , flow , and network design problems . in _ stoc 94 : proceedings of the twenty - sixth annual acm symposium on theory of computing _ , pages 648657 , new york , ny , usa , 1994 .",
    "acm .",
    "daniel  a. spielman and nikhil srivastava .",
    "graph sparsification by effective resistances . in _",
    "stoc 08 : proceedings of the 40th annual acm symposium on theory of computing _ , pages 563568 , new york , ny , usa , 2008 ."
  ],
  "abstract_text": [
    "<S> analyzing massive data sets has been one of the key motivations for studying streaming algorithms . in recent years </S>",
    "<S> , there has been significant progress in analysing distributions in a streaming setting , but the progress on graph problems has been limited . </S>",
    "<S> a main reason for this has been the existence of linear space lower bounds for even simple problems such as determining the connectedness of a graph . </S>",
    "<S> however , in many new scenarios that arise from social and other interaction networks , the number of vertices is significantly less than the number of edges . </S>",
    "<S> this has led to the formulation of the semi - streaming model where we assume that the space is ( near ) linear in the number of vertices ( but not necessarily the edges ) , and the edges appear in an arbitrary ( and possibly adversarial ) order .    </S>",
    "<S> however there has been limited progress in analysing graph algorithms in this model . in this paper </S>",
    "<S> we focus on graph sparsification , which is one of the major building blocks in a variety of graph algorithms . </S>",
    "<S> further , there has been a long history of ( non - streaming ) sampling algorithms that provide sparse graph approximations and it a natural question to ask : since the end result of the sparse approximation is a small ( linear ) space structure , can we achieve that using a small space , and in addition using a single pass over the data ? </S>",
    "<S> the question is interesting from the standpoint of both theory and practice and we answer the question in the affirmative , by providing a one pass @xmath0 space algorithm that produces a sparsification that approximates each cut to a @xmath1 factor . </S>",
    "<S> we also show that @xmath2 space is necessary for a one pass streaming algorithm to approximate the min - cut , improving upon the @xmath3 lower bound that arises from lower bounds for testing connectivity . </S>"
  ]
}