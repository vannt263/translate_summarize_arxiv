{
  "article_text": [
    "the world wide web ( aka the internet ) has become a vast abundant source of information and data . especially with the growth and use of social media and the availability of digital cameras on smart phones",
    ", people can easily add data to the internet by taking photos , writing a short description , and immediately uploading them to the social media .",
    "people add more information to each photo by doing a tag , like , dislike , or comment on photos posted by friends or others on the web .",
    "it is estimated that over 430 million photos are uploaded to facebook and instagram servers every day  @xcite . among photos posted on the web ,",
    "facial images have the highest incidents ( e.g. selfies or self - portrait images are very popular nowadays ) .",
    "these facial photos are often taken in the wild under natural conditions with varying and diverse parameters such as scene lighting , user s head pose , camera view , image resolution and background , subject s gender , ethnicity , and facial expressions among others .",
    "furthermore , the labels given by users use a wide range of vocabulary that is commonly understood to describe emotions , facial attributes , and expressions , of the pictures contents .",
    "these photos are truly wild images both in terms of the image quality / conditions and the labels given by users .",
    "an interesting question that may arise is , how the labels given wildly to facial images on the web by general users are consistent with the six basic emotions defined by psychologists .    on the other hand",
    ", computer vision and machine learning techniques for facial expression recognition are finding their ways into the design of a new generation of human - computer interfaces . in order to train a machine learning system ,",
    "many researchers have created databases using human actors / subjects portraying basic emotions  @xcite . however , most of the captured datasets mainly contain posed expressions acquired in a controlled environment .",
    "this is mostly due to the fact that it is hard and time consuming to collect unposed facial expression data in lab settings .",
    "however , in real applications , the system needs to capture and recognize spontaneous expressions , which involve different facial muscles , less exaggeration / intensity and have different dynamics than posed expressions .",
    "researchers who have created spontaneous expression databases have captured the human face spontaneously while watching a short video or filling a questionnaires  @xcite .",
    "however , the datasets are still captured in controlled lab settings ( i.e. with the same illumination , resolution , etc . ) or have a limited number of subjects , ethnicities , and poses poorly representing the environment and conditions faced in real - world situations . existing databases in the wild settings , such as sfew  @xcite or fer2013  @xcite , are also either very small or have low resolution without facial landmark points necessary for pre - processing .",
    "moreover , state - of - the - art machine learning algorithms such as deep neural network requires big data for training and evaluation of the core algorithms .",
    "given all the aforementioned motivations , this paper presents the results of our recent study with the aim of resolving the following questions :    1 .",
    "how consistent are the expression labels given by general web users compared to the six basic expression labels annotated by expert annotators on facial images ? 2 .",
    "how accurately can a state - of - the - art algorithm classify images when trained on facial images collected from the web using query terms ( e.g. happy face , laughing man , etc ) ?",
    "to address these questions , we created a database of in - the - wild facial expressions by querying different search engines ( google , bing and yahoo ) we then annotated a subset of images using two human annotators and showed the general accuracy of the querying search engines for facial expression recognition .",
    "we trained two different deep neural network architectures with different training settings i.e. training on clean well - labeled data , training on a mixture of clean and noisy data , and training on mixture of clean and noisy data with a noise modeling approach using a general framework introduced in  @xcite .",
    "in other words , given the result of annotations , the noise level of each search engine is estimated as a prior distribution on the labels of our posterior set allowing for greater classification performance when we sample noisy labels and true labels in the same proportion . in order to achieve this",
    ", we learned a stochastic matrix where the entries are the probability of confusion in the labels . from this matrix",
    ", we can extract a posterior distribution on the true labels of the data conditioned on the true label given the noisy label , and the noisy label given the acquired data . for more information on the technique ,",
    "see  @xcite .",
    "the rest of this paper is organized as follows .",
    "section  [ sec : literature ] reviews existing databases and state - of - the - art methods for facial expression recognition in the wild . sec .",
    "[ sec : expressionnet ] explains the methodology of automatically collecting a large amount of facial expression images from the internet and procedure of verifying them by two expert annotators .",
    "section  [ sec : experimental ] presents experimental results on training two different network architectures with different training settings , and section  [ sec : conclusion ] concludes the paper .",
    "automatic facial expression recognition ( fer ) is an important part of social interaction in human - machine - interaction ( hmi ) systems  @xcite .",
    "traditionally , automatic facial expression recognition ( afer ) methods consist of three main steps  1 ) registration and preprocessing , 2 ) feature extraction , and 3 ) classification .",
    "preprocessing and registration form an important part of the afer pipeline .",
    "many studies have shown the advantages of using facial image registration to improve classification accuracy in both face identification and facial expression recognition  @xcite . in the feature extraction step ,",
    "many methods such as hog  @xcite , gabor filters  @xcite , local binary pattern ( lbp )  @xcite , facial landmarks  @xcite , pixel intensities  @xcite , and local phase quantization ( lpq )  @xcite , or a combination of multiple features using multiple kernel learning methods  @xcite have been proposed to extract discriminative features .",
    "classification is the final step of most afer techniques .",
    "support vector machines  @xcite , multiple kernel learning  @xcite , dictionary learning  @xcite etc . have been shown to have a great performance in classifying discriminative features extracted from the previous stage .",
    "although , traditional machine learning approaches have been successful when classifying posed facial expressions in a controlled environment , they do not have the flexibility to classify images captured in a spontaneous uncontrolled manner ( `` in the wild '' ) or when applied to databases for which they were not designed .",
    "the poor generalizability of traditional methods is primarily due to the fact that many approaches are subject or database dependent and only capable of recognizing exaggerated or limited expressions similar to those in the training database .",
    "many fer databases have tightly controlled illumination and pose conditions .",
    "in addition , obtaining accurate training data is particularly difficult , especially for emotions such as sadness or fear which are extremely difficult to accurately replicate and do not occur often in real life .",
    "recently , facial expression datasets with in the wild settings have attracted much attention .",
    "dhall  _ et al . _",
    "@xcite released acted _ facial expressions in the wild ( afew ) _ from movies by semi - automatic approach via a recommender system based on subtitles .",
    "afew addresses the issue of temporal facial expressions and it is the only temporal publicly available facial expression database in the wild . a static subset _",
    "static facial expressions in the wild ( sfew ) _ is created by selecting static frames which covers unconstrained facial expressions , different head poses , age range , and occlusions and close to real world illuminations .",
    "however , it contains only 1635 images and there are only 95 subjects in the database .",
    "in addition , due to the wild settings of the database , the released facial location and landmarks do not capture the faces in all images correctly making some training and test samples unusable ( see fig .",
    "[ fig : sample_sfew ] ) .",
    "the facial expression recognition 2013 ( fer-2013 ) database was introduced in the icml 2013 challenges in representation learning  @xcite .",
    "the database was created using the google image search api that match a set of 184 emotion - related keywords to capture the six basic expressions as well as the neutral expression .",
    "human labelers rejected incorrectly labeled images .",
    "images are resized to 48x48 pixels and converted to grayscale .",
    "the resulting database contains 35,887 images most of them in wild settings , yet only 547 of the images portray disgust .",
    "figure  [ fig : sample_fer2013 ] shows some sample images of fer2013 .",
    "fer2013 is currently the biggest publicly available facial expression database in wild settings , enabling many researchers to train machine learning methods where large amounts of data are needed such as deep neural networks .",
    "however , as shown in fig .",
    "[ fig : sample_fer2013 ] , the faces are not registered , and unfortunately most of facial landmark detectors fail to extract facial landmarks at this resolution and quality .",
    "in addition , fer in the wild is really a challenging task both in terms of machine and human performance .",
    "extensive experiments in  @xcite show that even humans are only capable of 53% agreement in terms of fleiss kappa over all classes to classify afew video clips without listening to the audio track .",
    "state - of - the - art automated methods have achieved 35% accuracy on afew video clips by using audio modalities  @xcite . even recognizing expression from still images or static frames using traditional machine learning approaches are not accurate and the best performance on sfew 2.0 database",
    "is reported as 50% accuracy ( with a baseline of 39.13% )  @xcite .",
    "recently , deep neural networks have seen a resurgence in popularity .",
    "recent state - of - the - art results have been obtained using neural networks in the fields of visual object recognition  @xcite , human pose estimation  @xcite , face verification  @xcite , and many more . even in the fer field results",
    "so far have been promising  @xcite , and most of the facial expression recognition challenge winners have used deep neural networks  @xcite .    in the fer problem , however , unlike visual object databases such as imagenet  @xcite , existing fer databases often have limited numbers of subjects , few sample images or videos per expression , or small variation between sets , making neural networks significantly more difficult to train .",
    "for example , the fer2013 database  @xcite ( one of the largest recently released fer databases ) contains 35,887 images of different subjects yet only less than 2% of the images portray disgust .",
    "similarly , the cmu multipie face database  @xcite contains around 750,000 images but is comprised of only 337 different subjects , where 348,000 images portray only a `` neutral '' emotion and the remaining images do not portray anger , fear or sadness .    in a recent study  @xcite ,",
    "the authors proposed a deep neural network architecture and combined seven well - known facial expression databases ( i.e. multipie , mmi , ck+ , disfa , fera , sfew , and fer2013 ) to perform an extensive study on subject - independent and cross database .",
    "the results of the proposed architecture were comparable to or better than the state - of - the - art methods , however , the majority of data were still posed images and performance on wild databases ( sfew and fer2013 ) were only comparable to the state - of - the - art methods .    considering the need to develop an automated fer in wild system , and issues with the current facial expression in wild databases , a possible solution is to automatically collect a large amount of facial expression images from the abundant images available on the internet , and directly use them as ground truth to train deep models .",
    "however , consideration should be done to avoid false samples in the search engine results for expressions such as disgust or fear .",
    "this is due to the higher tendancy of people to publish happy or neutral faces that can be mislabeled or associated with disgust or fear by web users .",
    "nonetheless , semi - supervised  @xcite , transfer learning  @xcite , or noise modeling approaches  @xcite can be used to train deep neural networks with noisy data by obtaining large amounts of facial expression images from search engines , along with a smaller subset of fully well - labeled images .",
    "to create our database with the larger amount of images necessary for deep neural networks , three search engines were queried by facial emotion related tags in six different languages .",
    "we used google , bing , and yahoo .",
    "other search engines were considered such as baidu and yandex . however they either did not produce a high percentage of the intended images or they did not have accessible apis for automatically querying and pulling image urls into the database .",
    "a total of 1250 search queries were compiled in six languages and used to crawl internet search engines for the image urls in our dataset .",
    "the first 200 urls returned for each query were stored in the database ( 258,140 distinct urls ) . among the 258,140 urls , 201,932 images were available for download .",
    "opencv face recognition was used to obtain bounding boxes around each face .",
    "bidirectional warping of active appearance model ( aam )  @xcite and a face alignment algorithm via regressing local binary features  @xcite were used to extract 66 facial landmarks .",
    "the employed facial landmark localization techniques have been trained using the annotations provided from the 300w competition  @xcite .",
    "images with at least one face with facial landmark points were kept for the next processing stages .",
    "a total of 119,481 images were kept .",
    "other attributes of the queries were stored if applicable such as ; intended emotion , gender , age , language searched , and its english translation if not in english .    on average 4000 images of each queried emotions",
    "were selected randomly , and in total 24,000 images were given to two expert annotators to categorize the face in the image into nine categories ( i.e. no - face , six basic expressions , neutral , none , and uncertain ) .",
    "the annotators were instructed to select the proper expression category on the face , where the intensity is not important as long as the face depicts the intended expressions .",
    "the _ no - face _ category was defined as images that : 1 ) there was no face in the image ; 2 ) there was a watermark on the face ; 3 ) the bounding box was not on the face or did not cover the majority of the face ; 3 ) the face is a drawing , animation , painted , or printed on something else ; and 4 ) the face is distorted beyond a natural or normal shape , even if an expression could be inferred .",
    "the _ none _",
    "category was defined as images that portrayed an emotion but the expression / emotions could be categorized as one of the six basic emotions or neutral ( such as sleepy , bored , tired , seducing , confused , shame , focused , etc . ) .",
    "if the annotators were uncertain about any of the facial expressions , images were tagged as _",
    "uncertain_. figure  [ fig : sample_expressionnet ] shows some examples of each category and the intended queries written in parentheses .",
    "the annotation was performed fully blind and independently , i.e. the annotators were not aware of the intended query or other annotator s response .",
    "the two annotators agreed on 63.7% of the images .",
    "for the images that were at a disagreement , favor was given to the intended query i.e. if one of the annotators labeled the image as the intended query , the image was labeled in the database with the intended query .",
    "this happened in 29.5% of the images with disagreement between the annotators . on the rest of the images with disagreement ,",
    "one of the annotations was assigned to the image randomly .",
    "table  [ tab : numimages ] shows the number of images in each category in the set of 24,000 images that were given to two human annotators .",
    "as shown , some expressions such as disgust , fear , and surprise have few images compared to the other expressions , despite the number of queries being the same .    .number of annotated images in each category [ cols=\"<,^\",options=\"header \" , ]     ^*^ ne , ha , sa , su , fe , di , an stand for neutral , happiness , sadness , surprised , fear , disgust , anger respectively .",
    "figure  [ fig : sample_missclassified ] shows a sample of randomly selected images misclassified by alexnet trained on the well - labeled and their corresponding ground - truth given in parentheses . as the figure shows , it is really difficult to classify some of the images .",
    "for example , we were unable to correctly classify the images in the first row .",
    "also , the images in the second row have similarities to the misclassified labels , such as nose wrinkle in disgust , or raised eyebrows in surprise .",
    "it should be mentioned that classifying complex facial expressions as discrete emotions , especially in the wild , can be very difficult and even there was only 63.7% agreement between two human annotators .",
    "facial expression recognition in a wild setting is really challenging .",
    "current databases with in wild setting are also either very small or have low resolution without facial landmark points necessary for pre - processing .",
    "the internet is a vast resource of images and it is estimated that over 430 million photos are uploaded on only social network servers every day . most of these images contain faces , that are captured in uncontrolled settings , illuminations , pose , etc .",
    "in fact it is word _ wild _ web of facial images and it can be a great resource for capturing millions of samples with different subjects , ages , and ethnicity .    two neural network architectures were trained in three training scenarios .",
    "it is shown that , training on only well - labeled data has higher overall accuracy than training on the mixture of noisy and well - labeled data , even with the noise estimation method .",
    "the noise estimation can increase the accuracy in sadness , surprise , fear and disgust expressions , as there were limited samples in well - labeled data . but still training on only well - labeled data has a higher overall accuracy .",
    "the reason is that as annotations of web images showed , most of the facial images queried from the web have less than 50% hit - rates and even for some emotions such as disgust and fear , the majority of the results portrayed other emotions or neutral faces .",
    "the whole database , query terms , annotated images subset , and their facial landmark points will be publicly available for the research community .",
    "this work is partially supported by the nsf grants iis-1111568 and cns-1427872 .",
    "we gratefully acknowledge the support of nvidia corporation with the donation of the tesla k40 gpu used for this research .",
    "j.  deng , w.  dong , r.  socher , l .- j .",
    "li , k.  li , and l.  fei - fei .",
    "imagenet : a large - scale hierarchical image database . in _ computer vision and pattern recognition , 2009 .",
    "cvpr 2009 .",
    "ieee conference on _ , pages 248255 .",
    "ieee , 2009 .",
    "a.  dhall , r.  goecke , j.  joshi , m.  wagner , and t.  gedeon .",
    "emotion recognition in the wild challenge 2013 . in _ proceedings of the 15th acm on international conference on multimodal interaction _ ,",
    "pages 509516 .",
    "acm , 2013 .",
    "a.  dhall , r.  goecke , s.  lucey , and t.  gedeon .",
    "static facial expression analysis in tough conditions : data , evaluation protocol and benchmark . in _",
    "computer vision workshops ( iccv workshops ) , 2011 ieee international conference on _ , pages 21062112 .",
    "ieee , 2011 .",
    "m.  drange .",
    "why is this canadian hacker better than facebook at detecting gun photos ?",
    "http://www.forbes.com/sites/mattdrange/2016/03/31/facebook-guns-beet_farmer-image-recognition/    # 23db8f4478ed[http://www.forbes.com / sites / mattdrange/2016/03/31/facebook - guns - beet_farmer - image - recognition/    # 23db8f4478ed ] , 2016 .",
    "i.  j. goodfellow , d.  erhan , p.  l. carrier , a.  courville , m.  mirza , b.  hamner , w.  cukierski , y.  tang , d.  thaler , d .- h .",
    "lee , et  al .",
    "challenges in representation learning : a report on three machine learning contests . , 64:5963 , 2015 .",
    "t.  gritti , c.  shan , v.  jeanne , and r.  braspenning .",
    "local features based facial expression recognition with face registration errors . in _ automatic face & gesture recognition , 2008 .",
    "8th ieee international conference on _ , pages 18 .",
    "ieee , 2008 .",
    "s.  e. kahou , c.  pal , x.  bouthillier , p.  froumenty ,  .",
    "glehre , r.  memisevic , p.  vincent , a.  courville , y.  bengio , r.  c. ferrari , et  al .",
    "combining modality specific deep neural networks for emotion recognition in video . in _ proceedings of the 15th acm on international conference on multimodal interaction _ , pages 543550 .",
    "acm , 2013 .",
    "h.  kobayashi and f.  hara . facial interaction between animated 3d face robot and human beings . in _ systems ,",
    "man , and cybernetics , 1997 . computational cybernetics and simulation . ,",
    "1997 ieee international conference on _ , volume  4 , pages 37323737 .",
    "ieee , 1997 .",
    "m.  liu , s.  li , s.  shan , and x.  chen .",
    "au - aware deep networks for facial expression recognition . in _",
    "automatic face and gesture recognition ( fg ) , 2013 10th ieee international conference and workshops on _ , pages 16 .",
    "ieee , 2013 .",
    "m.  lyons , s.  akamatsu , m.  kamachi , and j.  gyoba .",
    "coding facial expressions with gabor wavelets . in _",
    "automatic face and gesture recognition , 1998 .",
    "third ieee international conference on _ , pages 200205 .",
    "ieee , 1998 .",
    "d.  mcduff , r.  kaliouby , t.  senechal , m.  amr , j.  cohn , and r.  picard .",
    "affectiva - mit facial expression dataset ( am - fed ) : naturalistic and spontaneous facial expressions collected . in",
    "_ proceedings of the ieee conference on computer vision and pattern recognition workshops _ , pages 881888 , 2013 .",
    "a.  mollahosseini , g.  graitzer , e.  borts , s.  conyers , r.  m. voyles , r.  cole , and m.  h. mahoor .",
    "expressionbot : an emotive lifelike robotic face for face - to - face communication . in _ humanoid robots ( humanoids ) ,",
    "2014 14th ieee - ras international conference on _ , pages 10981103 .",
    "ieee , 2014 .",
    "m.  oquab , l.  bottou , i.  laptev , and j.  sivic . learning and transferring mid - level image representations using convolutional neural networks . in _ proceedings of the ieee conference on computer vision and pattern recognition _ ,",
    "pages 17171724 , 2014 .",
    "m.  pantic , m.  valstar , r.  rademaker , and l.  maat .",
    "web - based database for facial expression analysis . in",
    "_ multimedia and expo , 2005 .",
    "icme 2005 .",
    "ieee international conference on _ , pages 5pp .",
    "ieee , 2005 .",
    "s.  ren , x.  cao , y.  wei , and j.  sun .",
    "face alignment at 3000 fps via regressing local binary features . in",
    "_ proceedings of the ieee conference on computer vision and pattern recognition _ , pages 16851692 , 2014 .",
    "e.  rentzeperis , a.  stergiou , a.  pnevmatikakis , and l.  polymenakos .",
    "impact of face registration errors on recognition . in _ artificial intelligence applications and innovations _ , pages 187194 .",
    "springer , 2006 .      c.  sagonas , g.  tzimiropoulos , s.  zafeiriou , and m.  pantic .",
    "300 faces in - the - wild challenge : the first facial landmark localization challenge . in _ proceedings of the ieee international conference on computer vision workshops _ , pages 397403 , 2013 .    c.  sagonas , g.  tzimiropoulos , s.  zafeiriou , and m.  pantic .",
    "a semi - automatic methodology for facial landmark annotation . in _ proceedings of the ieee conference on computer vision and pattern recognition workshops _ , pages 896903 , 2013 .",
    "y.  taigman , m.  yang , m.  ranzato , and l.  wolf .",
    "deepface : closing the gap to human - level performance in face verification . in _",
    "computer vision and pattern recognition ( cvpr ) , 2014 ieee conference on _ , pages 17011708 .",
    "ieee , 2014 .",
    "t.  xiao , t.  xia , y.  yang , c.  huang , and x.  wang .",
    "learning from massive noisy labeled data for image classification . in _ proceedings of the ieee conference on computer vision and pattern recognition _",
    ", pages 26912699 , 2015 .",
    "z.  yu and c.  zhang . image based static facial expression recognition with multiple deep network learning . in _ proceedings of the 2015 acm on international conference on multimodal interaction _ , pages 435442 .",
    "acm , 2015 .",
    "x.  zhang , a.  mollahosseini , b.  kargar , h.  amir , e.  boucher , r.  m. voyles , r.  nielsen , and m.  mahoor .",
    "ebear : an expressive bear - like robot . in _",
    "robot and human interactive communication , 2014 ro - man : the 23rd ieee international symposium on _ , pages 969974 .",
    "ieee , 2014 .",
    "w.  zhen and y.  zilu .",
    "facial expression recognition based on local phase quantization and sparse representation . in _ natural computation ( icnc ) , 2012 eighth international conference on _ , pages 222225 .",
    "ieee , 2012 ."
  ],
  "abstract_text": [
    "<S> recognizing facial expression in a wild setting has remained a challenging task in computer vision . the world wide web is a good source of facial images which </S>",
    "<S> most of them are captured in uncontrolled conditions . </S>",
    "<S> in fact , the internet is a word wild web of facial images with expressions . </S>",
    "<S> this paper presents the results of a new study on collecting , annotating , and analyzing wild facial expressions from the web . </S>",
    "<S> three search engines were queried using 1250 emotion related keywords in six different languages and the retrieved images were mapped by two annotators to six basic expressions and neutral . </S>",
    "<S> deep neural networks and noise modeling were used in three different training scenarios to find how accurately facial expressions can be recognized when trained on noisy images collected from the web using query terms ( e.g. happy face , laughing man , etc ) ? </S>",
    "<S> the results of our experiments show that deep neural networks can recognize wild facial expressions with an accuracy of 82.12% . </S>"
  ]
}