{
  "article_text": [
    "two weight inequalities for maximal functions and other positive operators have been characterized in @xcite , @xcite , @xcite , with these characterizations being given in terms of obviously necessary conditions , that the operators be uniformly bounded on a restricted class of functions , namely indicators of intervals and cubes .",
    "thus , these characterizations have a form reminiscent of the @xmath24 theorem of david and journ .",
    "corresponding results for even the hilbert transform have only recently been obtained ( @xcite and @xcite ) and even then only for @xmath25 ; evidently these are much harder to obtain .",
    "we comment in more detail on prior results below , including the innovative work of nazarov , treil and volberg @xcite , @xcite , @xcite , @xcite .",
    "our focus is on providing characterizations of the boundedness of certain maximal truncations of a fixed operator of singular integral type .",
    "the singular integrals will be of the usual type , for example the hilbert transform or paraproducts . only size and",
    "smoothness conditions on the kernel are assumed , see .",
    "the characterizations are in terms of certain obviously necessary conditions , in which the class of functions being tested is simplified . for such examples ,",
    "we prove unconditional characterizations of both strong - type and weak - type two weight inequalities for certain maximal truncations of the hilbert transform , but with the additional assumption that @xmath0 is _ doubling _ for the strong type inequality .",
    "a major point of our characterizations is that they hold for _ all _ @xmath20 .",
    "the methods in @xcite , @xcite , @xcite , @xcite , @xcite apply only to the case @xmath25 , where the orthogonality of measure - adapted haar bases prove critical .",
    "the doubling hypothesis on @xmath0 may not be needed in our theorems , but is required by the use of caldern - zygmund decompositions in our method .",
    "as the precise statements of our general results are somewhat complicated , we illustrate them with an important case here .",
    "let @xmath26denote the hilbert transform , let@xmath27denote the usual maximal singular integral associated with @xmath28 , and finally let@xmath29denote the new _ strongly _ ( or _ noncentered _ ) maximal singular integral associated with @xmath28 that is defined more precisely below .",
    "suppose @xmath3 and @xmath1 are two locally finite positive borel measures on @xmath30 that have no point masses in common",
    ". then we have the following weak and strong type characterizations which we emphasize hold for _ all _ @xmath20 .    *",
    "the operator @xmath31 is _ weak _ type @xmath32 with respect to @xmath33 , i.e.@xmath34for all @xmath35 bounded with compact support , _ if and only if _ the two weight @xmath8 condition @xmath36holds for all intervals @xmath13 ; and the dual @xmath31 interval testing condition@xmath37holds for all intervals @xmath13 and @xmath38 ( part @xmath39 of theorem [ weaktwoweighthaar ] ) .",
    "the same is true for @xmath21 .",
    "it is easy to see that is equivalent to the more familiar dual interval testing condition@xmath40for all intervals @xmath13 and linearizations @xmath41 of the maximal singular integral @xmath31 ( see ) .",
    "* suppose in addition that @xmath0 is doubling and @xmath20 .",
    "then the operator @xmath21 is strong type @xmath32 with respect to @xmath33 , i.e. @xmath42for all @xmath35 bounded with compact support , _ if and only if _ these four conditions hold .",
    "( * 1 * ) the strengthened @xmath8 condition@xmath43@xmath10 , holds for all intervals @xmath13 ; ( * 2 * ) the dual @xmath21 interval testing condition@xmath44holds for all intervals @xmath13 and @xmath38 ; ( * 3 * ) the forward @xmath21 testing condition@xmath45holds for all intervals @xmath13 and all compact subsets @xmath46 of @xmath13 ; and ( * 4 * ) the poisson condition@xmath16for all pairwise disjoint decompositions @xmath17 of the dyadic interval @xmath13 into dyadic intervals @xmath18 , for any fixed dyadic grid . in the case @xmath4 , only the first three conditions are needed ( theorem [ improved ] ) .",
    "note that in we are required to test over all compact subsets @xmath46 of @xmath13 on the left side , but retain the upper bound over the ( larger ) cube @xmath13 on the right side .    as these results indicate , the imposition of the weight @xmath0 on both sides of is a standard part of weighted theory , in general necessary for the testing conditions to be sufficient .",
    "compare to the characterization of the two weight maximal function inequalities in theorem  [ sawyerthm ] below .    in",
    ", our testing condition is more complicated than one would like , in that one must test over all compact @xmath47 in .",
    "there is a corresponding feature of , seen after one unwinds the definition of the linearization @xmath48 .",
    "we do not know if these testing conditions can be further simplified .",
    "the form of these testing conditions is dictated by our use of what we call the ` maximum principle , ' see lemma  [ l.maxprin ] .",
    "we now recall the two weight inequalities for the maximal function as they are central to the new results of this paper .",
    "define the maximal function @xmath49where the supremum is taken over all cubes @xmath13 ( by which we mean cubes with sides parallel to the coordinate axes ) containing @xmath50 .",
    "[ sawyerthm]suppose that @xmath0 and @xmath1 are positive locally finite borel measures on @xmath19 , and that @xmath20 . the maximal operator @xmath51 satisfies the two weight norm inequality ( @xcite)@xmath52__if and only if _",
    "_ for all cubes @xmath53,@xmath54the maximal operator @xmath51 satisfies the _ weak - type _ two weight norm inequality ( @xcite)@xmath55__if and only if _ _ the two weight @xmath8 condition holds for all cubes @xmath56:@xmath57 ^{\\frac{1}{p% } } \\left [ \\frac{1}{\\left\\vert q\\right\\vert } \\int_{q}d\\sigma \\right ] ^{\\frac{1% } { p^{\\prime } } } \\leq c_{2}.   \\label{ap}\\ ] ]    the necessary and sufficient condition for the strong type inequality states that one need only test the strong type inequality for functions of the form @xmath58 . not only that , but the full @xmath59 norm of @xmath60 need not be evaluated . there is a corresponding weak - type interpretation of the @xmath61 condition",
    "finally , the proofs given in @xcite and @xcite for absolutely continuous weights carry over without difficulty for  the locally finite measures considered here .",
    "let us set notation for our theorems .",
    "consider a kernel function @xmath62 defined on @xmath63 satisfying the following size and smoothness conditions,@xmath64where @xmath65 is a dini modulus of continuity , i.e. a nondecreasing function on @xmath66 $ ] with @xmath67 and @xmath68 .",
    "next we describe the truncations we consider .",
    "let @xmath69 be fixed smooth functions on the real line satisfying@xmath70given @xmath71 , set @xmath72 and @xmath73 and define the smoothly truncated operator @xmath74 on @xmath75 by the absolutely convergent integrals @xmath76define the _ maximal _ singular integral operator @xmath31 on @xmath77 by@xmath78    we also define a corresponding _ new _ notion of _ strongly maximal _ singular integral operator @xmath21 as follows . in dimension",
    "@xmath79 we set@xmath80where @xmath81 and@xmath82thus the local singularity has been removed by a _",
    "noncentered _ smooth cutoff - @xmath83 to the left of @xmath50 and @xmath84 to the right of @xmath50 , but with controlled eccentricity @xmath85 .",
    "there is a similar definition of @xmath86 in higher dimensions involving in place of @xmath87 , a product of smooth cutoffs,@xmath88 , \\]]satisfying @xmath89 for @xmath90 .",
    "the advantage of this larger operator @xmath5 is that in many cases boundedness of @xmath21 ( or collections thereof ) implies boundedness of the maximal operator @xmath91 .",
    "our method of proving boundedness of @xmath31 and @xmath21 requires boundedness of the maximal operator @xmath51 anyway , and as a result we can in some cases give necessary and sufficient conditions for strong boundedness of @xmath21 . as for weak - type boundedness ,",
    "we can in many more cases give necessary and sufficient conditions for weak boundedness of the usual truncations @xmath31 .",
    "[ d.standard ] we say that @xmath28 is a _ standard singular integral operator with kernel @xmath92 _ if @xmath28 is a bounded linear operator on @xmath93 for some fixed @xmath94 , that is @xmath95if @xmath62 is defined on @xmath63 and satisfies both and the hrmander condition , @xmath96and finally if @xmath28 and @xmath92 are related by@xmath97whenever @xmath98 has compact support in @xmath22 .",
    "we call a kernel @xmath62 _ standard _ if it satisfies ( [ sizeandsmoothness ] ) and .    for standard singular integral operators",
    ", we have this classical result .",
    "( see the appendix on truncation of singular integrals on page 30 of @xcite for the case @xmath99 ; the case @xmath100 is similar . )",
    "[ classmax]suppose that @xmath28 is a standard singular integral operator .",
    "then the map @xmath101 is of weak - type @xmath102 , and bounded on @xmath103 for @xmath20 .",
    "there exist sequences @xmath104 and @xmath105 such that for @xmath106 with @xmath107,@xmath108exists for @xmath109 .",
    "moreover , there is a bounded measurable function @xmath110 ( depending on the sequences ) satisfying@xmath111    we state a conjecture , so that the overarching goals of this subject are clear .    [ j.toostrong ] suppose that @xmath0 and @xmath1 are positive borel measures on @xmath19 , @xmath20 , and @xmath28 is a standard singular integral operator on @xmath19",
    ". then the following two statements are equivalent : @xmath112 ^{\\frac{1}{p% } } \\left [ \\frac{1}{\\left\\vert q\\right\\vert } \\int_{q}d\\sigma \\right ] ^{\\frac{1% } { p^{\\prime } } } \\leq c\\ , , \\\\",
    "\\int_{q}\\lvert t\\chi _ { q}\\sigma \\rvert ^{p}\\leq c^{\\prime } \\int_{q}\\sigma \\ , , \\\\",
    "\\int_{q}\\lvert t^{\\ast } \\chi _ { q}\\omega \\rvert ^{p^{\\prime } } \\sigma \\leq c^{\\prime \\prime } \\int_{q}\\omega \\,,%",
    "\\end{array}% \\right . \\ \\ \\ \\ \\",
    "for\\ all\\ cubes\\ q.\\qquad\\end{gathered}\\ ] ]    [ r.poisson ] the first of the three testing conditions above is the two - weight @xmath113 condition .",
    "we would expect that this condition can be strengthened to a ` poisson two - weight @xmath113 condition . '",
    "see @xcite .",
    "the most important instances of this conjecture occur when @xmath28 is one of a few canonical singular integral operators , such as the hilbert transform , the beurling transform , or the riesz transforms .",
    "this question occurs in different instances , such as the sarason conjecture concerning the composition of hankel operators , or the semi - commutator of toeplitz operators ( see @xcite , @xcite ) , mathematical physics @xcite , as well as perturbation theory of some self - adjoint operators .",
    "see references in @xcite .",
    "to date , this has only been verified for positive operators , such as poisson integrals , and fractional integral operators @xcite , @xcite and @xcite .",
    "recently the authors have used the methods of nazarov , treil and volberg to prove a special case of the conjecture for the hilbert transform when @xmath25 and an energy hypothesis is assumed ( @xcite ) .",
    "earlier in @xcite ntv used a stronger pivotal condition in place of the energy hypothesis , but neither of these conditions are necessary ( lasaur ) .",
    "the two weight helson - szego theorem was proved many years earlier by cotlar and sadosky @xcite and @xcite , thus the @xmath114 case for the hilbert transform is completely settled .",
    "nazarov , treil and volberg @xcite , @xcite have characterized those weights for which the class of haar multipliers is bounded when @xmath25 .",
    "they also have a result for an important special class of singular integral operators , the ` well - localized ' operators of @xcite . citing the specific result here",
    "would carry us too far afield , but this class includes the important haar shift examples , such as the one found by s. petermichl @xcite , and generalized in @xcite .",
    "consequently , characterizations are given in @xcite and @xcite for the hilbert transform and riesz transforms in weighted @xmath114 spaces under various additional hypotheses .",
    "in particular they obtain an analogue of the case @xmath25 of the strong type theorem below .",
    "our results can be reformulated in the context there , which theme we do not pursue further here .",
    "we now characterize the weak - type two weight norm inequality for both maximal singular integrals and strongly maximal singular integrals .",
    "[ weaktwoweighthaar]suppose that @xmath0 and @xmath1 are positive locally finite borel measures on @xmath19 , @xmath20 , and let @xmath115 and @xmath21 be the maximal singular integral operators as above with kernel @xmath62 satisfying .    1 .",
    "suppose that the maximal operator @xmath51 satisfies ( weakm2weight ) .",
    "then @xmath21 satisfies the weak - type two weight norm inequality@xmath116_if and only if _ @xmath117for all cubes @xmath53 and all functions @xmath14 .",
    "2 .   the same characterization as above holds for @xmath31 in place of @xmath5 everywhere .",
    "3 .   suppose that @xmath0 and @xmath1 are absolutely continuous with respect to lebesgue measure , that the maximal operator @xmath51 satisfies , and that @xmath28 is a standard singular integral operator with kernel @xmath92 as above .",
    "if holds for @xmath21 or @xmath31 , then it also holds for @xmath28:@xmath118 4 .",
    "suppose @xmath119 and that @xmath120 is a collection of _ standard _ kernels such that for _ each _ unit vector @xmath121 there is @xmath122 satisfying @xmath123suppose also that @xmath0 and @xmath1 have no common point masses , i.e. @xmath124 for all @xmath125 .",
    "then@xmath126if and only if the two weight @xmath8 condition holds and@xmath127    while in ( 1)(3 ) , we assume that the maximal function inequality holds , in point ( 4 ) , we obtain an _ unconditional _ characterization of the weak - type inequality for  a large class of families of ( centered ) maximal singular integral operators @xmath31 .",
    "this class includes the individual maximal hilbert transform in one dimension , the individual maximal beurling transform in two dimensions , and the families of maximal riesz transforms in higher dimensions , see lemma  [ weakdom ] .",
    "note that in ( 1 ) above , there is only size and smoothness assumptions placed on the kernel , so that it could for instance be a degenerate fractional integral operator , and therefore unbounded on @xmath128 .",
    "but , the characterization still has content in this case , if @xmath1 and @xmath0 are not of full dimension .    in ( 3 )",
    ", we deduce a two weight inequality for standard singular integrals @xmath28 without truncations when the measures are absolutely continuous .",
    "the proof of this is easy . from and",
    "the pointwise inequality @xmath129 , we obtain that for any limiting operator @xmath130 the map @xmath131",
    "@xmath132 is bounded from @xmath133 to @xmath134 . by @xmath135",
    "is bounded , hence @xmath136 is bounded , and so theorem [ classmax ] shows that @xmath137 is also bounded , provided we initially restrict attention to functions @xmath35 for which @xmath138 is bounded with compact support .",
    "the characterizing condition is a weak - type condition , with the restriction that one only needs to test the weak - type condition for functions supported on a given cube , and test the weak - type norm over that given cube .",
    "it also has an interpretation as a dual inequality @xmath139 , which we return to below , see and .",
    "we now consider the two weight norm inequality for a strongly maximal singular integral @xmath21 , but assuming that the measure @xmath0 is doubling .",
    "[ twoweighthaar]suppose that @xmath0 and @xmath1 are positive locally finite borel measures on @xmath19 with @xmath0 doubling , @xmath140 , and let @xmath31 and @xmath21 be the maximal singular integral operators as above with kernel @xmath62 satisfying .    1 .",
    "suppose that the maximal operator @xmath51 satisfies ( m2weight ) and also the ` dual ' inequality@xmath141then @xmath21 satisfies the two weight norm inequality @xmath142for all @xmath143 that are bounded with compact support in @xmath19 , _ if and only if _ both the dual cube testing condition and the condition below hold : @xmath144for all cubes @xmath53 and all functions @xmath145 .",
    "2 .   the same characterization as above holds for @xmath31 in place of @xmath5 everywhere . in fact@xmath146 3 .   suppose that @xmath0 and @xmath1 are absolutely continuous with respect to lebesgue measure , that the maximal operator @xmath51 satisfies , and that @xmath28 is a standard singular integral operator .",
    "if holds for @xmath21 or @xmath31 , then it also holds for @xmath28:@xmath147 4 .",
    "suppose that @xmath148 is a collection of _ standard _ kernels satisfying for some @xmath119 , @xmath149where @xmath150 . if both @xmath1 and @xmath3 are doubling , then holds for @xmath151 and @xmath152 for all @xmath153 , _ if and only if _ both and hold for @xmath154 and @xmath155 for all @xmath156 .",
    "note that the second condition is a stronger condition than we would like : it is the @xmath157 inequality , applied to functions _ bounded by _ @xmath158 and supported on a cube @xmath13 , but with the @xmath159 norm of @xmath160 on the right side .",
    "it is easy to see that the bounded function @xmath161 in can be replaced by @xmath162 for every compact subset @xmath46 of @xmath13 . indeed",
    "if @xmath41 ranges over all linearizations of @xmath21 , then with @xmath163 we have @xmath164since @xmath165 takes on only the values @xmath166 , it is easy to see that we can take @xmath167 . point ( 3 ) is again easy , just as in the previous weak - type theorem .    and in ( 4 ) , we note that the truncations in the way that we formulate them , dominate the maximal function , so that our assumption on @xmath51 in ( 1)(3 ) is not unreasonable .",
    "the main result of @xcite assumes @xmath25 and that @xmath28 is the hilbert transform , and makes similar kinds of assumptions .",
    "in fact it is essentially the same as our result in the case @xmath168 , but without doubling on @xmath0 and only for @xmath28 and not @xmath31 or @xmath21 .",
    "finally , we observe that by our definition of the truncation @xmath21 , we obtain in point ( 4 ) , a characterization for doubling measures of the strong - type inequality for appropriate families of standard singular integrals and their adjoints , including the hilbert and riesz transforms , see lemma [ dom ] .",
    "we do not know if the bounded function @xmath161 in condition can be replaced by the constant function @xmath158 .",
    "we now give a characterization of the strong type weighted norm inequality for the _ individual _ strongly maximal hilbert transform @xmath21 when @xmath20 and the measure @xmath0 is _",
    "doubling_. when @xmath15 we use an extra necessary condition , see below , that involves a ` dyadic ' poisson function @xmath169 where @xmath170 is a dyadic interval and @xmath171 denotes its @xmath172 ancestor in the dyadic grid , i.e. the unique dyadic interval containing @xmath170 with @xmath173 .",
    "this condition is a variant of the pivotal condition of nazarov , treil and volberg in @xcite , and in the case @xmath4 it is a consequence of the @xmath8 condition .",
    "[ improved]suppose that @xmath0 and @xmath1 are positive locally finite borel measures on @xmath2 with @xmath0 _ doubling _ , @xmath140 , and let @xmath21 be the strongly maximal hilbert transform .",
    "then @xmath21 is _ strong _ type @xmath32 with respect to @xmath33 , i.e. @xmath42for all @xmath35 bounded with compact support , _ if and only if _ the following four conditions hold . in the case",
    "@xmath4 , the fourth condition is implied by the @xmath8 condition ( ap ) , and so in this case we only need the first _ three _ conditions below :    1 .",
    "the dual @xmath21 interval testing condition@xmath174holds for all intervals @xmath13 and @xmath38 ; 2 .",
    "the forward @xmath21 testing condition@xmath175holds for all intervals @xmath13 and all compact subsets @xmath46 of @xmath13 ; 3 .   the strengthened @xmath8 condition@xmath176holds for all intervals @xmath13 .",
    "the poisson condition@xmath177for all pairwise disjoint decompositions @xmath17 of the dyadic interval @xmath13 into dyadic intervals @xmath18 , for any fixed dyadic grid .",
    "the strengthened @xmath8 condition can be replaced with the weaker ` half ' condition where the first factor on the left is replaced by @xmath178 .",
    "we do not know if the first three conditions suffice when @xmath15 .",
    "the authors began this work during research stays at the fields institute , toronto canada , and continued at the centre de recerca matemtica , barcelona spain .",
    "they thank these institutions for their generous hospitality .",
    "in addition , this paper has been substantially improved by the careful attention of the referee , for which we are particularly grateful .",
    "if @xmath13 is a cube then @xmath179 is its side length , @xmath180 is its lebesgue measure and for a positive borel measure @xmath181 , @xmath182 is its @xmath183-measure .",
    "our starting place is the argument in @xcite used to prove a two weight norm inequality for fractional integral operators on euclidean space .",
    "of course the fractional integral is a positive operator , with a monotone kernel , which properties we do not have in the current setting .",
    "a central tool arises from the observation that for any positive borel measure @xmath184 , one has the boundedness of a maximal function associated with @xmath184 .",
    "define the dyadic @xmath184-maximal operator @xmath185 by @xmath186with the supremum taken over all dyadic cubes @xmath187 containing @xmath188 .",
    "it is immediate to check that @xmath189 satisfies the weak - type @xmath190 inequality , and the @xmath191 bound is obvious .",
    "hence we have @xmath192this observation places certain caldern - zygmund decompositions at our disposal",
    ". exploitation of this brings in the testing condition ( tsharpsigma ) involving the bounded function @xmath161 on a cube @xmath13 , and indeed , @xmath161 turns out to be the good  function in a caldern - zygmund decomposition of @xmath35 on @xmath13 .",
    "the associated ` bad ' function requires the dual testing condition as well .",
    "our operators are not dyadic operators , nor  in contrast to the fractional integral operators  can they be easily obtained from dyadic operators .",
    "this leads to the necessity of considering for instance triples of dyadic cubes , which are not dyadic .",
    "also , dyadic grids distinguish points by for instance making some points on the boundary of many cubes . as our measures are arbitrary , they could conspire to assign extra mass to some of these points . to address this point ,",
    "nazarov - treil - volberg @xcite use a random shift of the grid .",
    "a random approach would likely work for us as well , though the argument would be different from those in the cited papers above .",
    "instead , we will use a non - random technique of shifted dyadic grid from @xcite , which goes back to p. jones and j. garnett . define a _ shifted dyadic grid _ to be the collection of cubes @xmath193the basic properties of these collections are these :",
    "in the first place , each @xmath194 is a grid , namely for @xmath195 we have @xmath196 and @xmath13 is a union of @xmath197 elements of @xmath198 of equal volume . in the second place ( and this is the novel property for us ) , for any cube @xmath53 , there is a choice of some @xmath199 and some @xmath200 so that @xmath201 and @xmath202 .",
    "we define the analogs of the dyadic maximal operator in , namely @xmath203these operators clearly satisfy .",
    "shifted dyadic grids will return in   [ s.czd ] .",
    "a second central tool is a ` maximum principle ' ( or good @xmath204 inequality ) which will permit one to localize large values of a singular integral , provided the maximal function is bounded .",
    "it is convenient for us to describe this in conjunction with another fundamental tool of this paper , a family of whitney decompositions .",
    "we begin with the whitney decompositions .",
    "fix a finite measure @xmath183 with compact support on @xmath19 and for @xmath205 let@xmath206note that @xmath207 has compact closure for such @xmath181 .",
    "fix an integer @xmath208 .",
    "we can choose @xmath209 sufficiently large , depending only on the dimension and @xmath210 , such that there is a collection of cubes @xmath211 which satisfy the following properties : @xmath212    indeed , one should choose the the @xmath211 satisfying the whitney condition , and then show that the other properties hold .",
    "the different combinatorial properties above are fundamental to the proof . and",
    "alternate whitney decompositions are constructed in ",
    "s.whitneyshift below .",
    "[ 3n ] our use of the whitney decomposition and the maximum principle are derived from the two weight fractional integral argument of sawyer , see sec 2 of @xcite . in particular , the properties above are as in saw2 , aside from the the crowd control property above , which is @xmath213 in _ op .",
    "cit . _    [ r.super/sub ] in our notation for the whitney cubes , the superscript indicates a ` height ' and the subscript an arbitrary enumeration of the cubes .",
    "we will use super- and sub - scripts below in this manner consistently throughout the paper .",
    "it is important to note that a fixed cube @xmath13 can arise in _ many _ whitney decompositions : there are integers @xmath214 with @xmath215 for some choice of @xmath216 for all @xmath217 .",
    "( the last point follows from the nested property .",
    ") there is no _ a priori _ upper bound on @xmath218 .",
    "[ l.maxprin][maximum principle ] let @xmath219be a finite ( signed ) measure with compact support . for any cube @xmath220 as above",
    "we have the pointwise inequality @xmath221where @xmath222 and @xmath223 are defined by @xmath224    the bound in terms of @xmath225 should be regarded as one in terms of a modified poisson integral .",
    "it is both slightly sharper than that of @xmath226 , and a linear expression in @xmath227 , which fact will be used in the proof of the strong type estimates .    to see this ,",
    "take @xmath228 and note that for each @xmath229 there is @xmath230 with @xmath231 and @xmath232 such that@xmath233for convenience we take @xmath234 in the sequel . by the whitney condition in ,",
    "there is a point @xmath235 and it now follows that ( remember that @xmath236 ) , @xmath237thus@xmath238which yields since @xmath239 .",
    "we now make comments on the linearizations of our maximal singular integral operators .",
    "we would like , at different points , to treat @xmath21 as a linear operator , which of course it is not .",
    "nevertheless @xmath21 is a pointwise supremum of the linear truncation operators @xmath240 , and as such , the supremum can be linearized with measurable selection of the parameters @xmath230 and @xmath241 , as was just done in the previous proof .",
    "we make this a definition .",
    "[ d.linearization ] we say that @xmath41 is a linearization of @xmath21 if there are measurable functions @xmath242 and @xmath243 with @xmath244 , @xmath245 and @xmath246 such that @xmath247    for fixed @xmath35 and @xmath248 , we can always choose a linearization @xmath41 so that @xmath249 for all @xmath50 . in a typical application of this lemma ,",
    "one takes @xmath65 to be one .",
    "note that condition is obtained from inequality ( 2weight ) by testing over @xmath35 of the form @xmath250 with @xmath145 , and then restricting integration on the left to @xmath13 . by passing to linearizations @xmath41",
    ", we can ` dualize ' to the testing conditions@xmath251or equivalently ( note that in the presence of @xmath161 makes a difference , but not here),@xmath252with the requirement that these inequalities hold _ uniformly _ in all linearizations @xmath41 of @xmath21 .    while the smooth truncation operators @xmath253 are essentially self - adjoint , the dual of a linearization @xmath41 is generally complicated .",
    "nevertheless , the dual @xmath254 does satisfy one important property which plays a crucial role in the proof of theorem twoweighthaar , the @xmath157-norm inequalities .",
    "[ constant]@xmath255 is @xmath65-hlder continuous ( where @xmath256 is the dini modulus of continuity of the kernel @xmath92 ) with constant @xmath257 on any cube @xmath13 satisfying @xmath258 , i.e.@xmath259here , recall the definition and that @xmath260 .",
    "suppose @xmath41 is as in .",
    "then for any finite measure @xmath183,@xmath261fubini s theorem shows that the dual operator @xmath254 is given on a finite measure @xmath184 by@xmath262for @xmath263 and @xmath264 , we thus have@xmath265from which follows easily if we split the two integrals in @xmath50 over dyadic annuli centered at the center of @xmath13 .",
    "next we record the facts that @xmath28 and @xmath21 control @xmath51 for many ( collections of ) standard singular integrals @xmath28 , including the hilbert transform , the beurling transform and the collection of riesz transforms in higher dimensions .",
    "[ weakdom]suppose that @xmath0 and @xmath1 have no point masses in common , and that @xmath120 is a collection of _ standard _ kernels satisfying and . if the corresponding operators @xmath266 given by satisfy@xmath267for @xmath268 , then the two weight @xmath8 condition holds , and hence also the weak - type two weight inequality .",
    "part of the ` one weight ' argument on page 211 of stein @xcite yields the _ asymmetric _ two weight @xmath8 condition@xmath269where @xmath13 and @xmath270 are cubes of equal side length @xmath271 and distance approximately @xmath272 apart for some fixed large positive constant @xmath273 ( for this argument we choose the unit vector @xmath274 in to point in the direction from the center of @xmath13 to the center of @xmath270 , and then with @xmath122 as in , @xmath273 is chosen large enough by ( sizeandsmoothness ) that holds for all unit vectors @xmath274 pointing from a point in @xmath13 to a point in @xmath270 ) . in the one weight case treated in @xcite it is easy to obtain from this ( even for a _ single _ direction @xmath274 ) the usual ( symmetric ) @xmath8 condition ( ap ) . here",
    "we will instead use our assumption that @xmath0 and @xmath1 have no point masses in common for this purpose .",
    "so fix an open dyadic cube @xmath275 in @xmath19 , say with side length @xmath158 , let @xmath276  and set @xmath277    note that with @xmath278 , then can be written@xmath279where@xmath280here @xmath281 where @xmath282 denotes product measure on @xmath63 . for @xmath140",
    "we easily see that if @xmath283 is a pairwise disjoint union of cubes @xmath284 , then the lebesgue measures satisfy@xmath285    suppose first that @xmath4 .",
    "divide @xmath286 into @xmath287 congruent subcubes @xmath288 of side length @xmath289 , and set aside those @xmath290 ( those for which holds ) into a collection of _ stopping cubes _ @xmath291 .",
    "continue to divide the remaining @xmath292 into @xmath293 congruent subcubes @xmath294 of side length @xmath295 , and again , set aside those @xmath296 into @xmath291 , and continue subdividing those that remain .",
    "we continue with such subdivisions for @xmath210 generations so that all the cubes _ not _ set aside into @xmath291 have side length @xmath297 .",
    "the important property these cubes have is that they all lie within distance @xmath298 of the diagonal @xmath299 in @xmath300 since holds for all pairs of cubes @xmath13 and @xmath270 of equal side length @xmath271 having distance approximately @xmath272 apart .",
    "enumerate the cubes in @xmath291 as @xmath301 and those remaining that are not in @xmath291 as @xmath302 .",
    "thus we have the pairwise disjoint decomposition@xmath303 in the case @xmath25 , the countable additivity of the product measure @xmath304 shows that@xmath305for the more general case @xmath4 , note that at each division described above we have using @xmath306,@xmath307it follows that@xmath308    since @xmath1 and @xmath0 have no point masses in common , it is not hard to show , using that the side length of @xmath309 is @xmath297 and @xmath310 , that we have the following limit:@xmath311indeed , if @xmath0 has no point masses at all , then@xmath312if",
    "@xmath0 contains a point mass @xmath313 , then@xmath314since @xmath1 has no point mass at @xmath50 .",
    "the argument in the general case is technical , but involves no new ideas , and we leave it to the reader .",
    "we thus conclude that @xmath315which is . the case @xmath316 is proved in the same way using that can be written@xmath317    [ dom]if @xmath318 satisfies , then@xmath319    we prove the case @xmath79 , the general case being similar .",
    "then with @xmath320 and @xmath321 we have@xmath322 } d\\nu ( y).\\end{aligned}\\]]thus@xmath323 } d\\nu ( y),\\]]and similarly@xmath324 } d\\nu ( y).\\]]it follows that@xmath325 } d\\nu ( y ) \\\\ & = & \\sup_{r>0}\\sum_{k=0}^{\\infty } 2^{-k}\\frac{1}{2^{2-k}r}\\int_{\\left [ x-2^{1-k}r , x-2^{-1-k}r\\right ]",
    "\\cup \\left [ x+2^{-1-k}r , x+2^{1-k}r\\right ] } d\\nu ( y ) \\\\ & \\leq & ct_{\\natural } \\nu ( x).\\end{aligned}\\ ] ]    finally , we will use the following covering lemma of besicovitch type for multiples of dyadic cubes ( the case of triples of dyadic cubes arises in ( [ finover ] ) below ) .",
    "[ besicovitch]let @xmath326 be an odd positive integer , and suppose that @xmath327 is a collection of cubes @xmath328 with bounded diameters and having the form @xmath329 where @xmath13 is dyadic ( a product of clopen dyadic intervals ) .",
    "if @xmath330 is the collection of _ maximal _ cubes in @xmath331 , i.e. @xmath332 provided there is no strictly larger @xmath328 in @xmath327 that contains @xmath333 , then the cubes in @xmath334 have finite overlap at most @xmath335 .",
    "let @xmath336 and assign labels @xmath337 to the dyadic subcubes of side length one of @xmath338 .",
    "we say that the subcube labeled @xmath339 is of type @xmath339 , and we extend this definition by translation and dilation to the subcubes of @xmath340 having side length that of @xmath341 .",
    "now we simply observe that if @xmath342 is a set of cubes in @xmath334 containing the point @xmath50 , then for a given @xmath343 , there is at most one @xmath344 that contains @xmath50 in its subcube of type @xmath339 .",
    "the reason is that if @xmath345 is another such cube and @xmath346 , we must have @xmath347 ( draw a picture in the plane for example ) .      given a positive locally finite borel measure @xmath184 on @xmath19 , there exists a rotation such that all boundaries of rotated dyadic cubes have @xmath184-measure zero ( see @xcite where they actually prove a stronger assertion when @xmath184 has no point masses , but our conclusion is obvious for a sum of point mass measures ) .",
    "we will assume that such a rotation has been made so that all boundaries of rotated dyadic cubes have @xmath348-measure zero , where @xmath1 and @xmath0 are the positive borel measures appearing in the theorems above ( of course @xmath3 doubling implies that @xmath0 can not contain any point masses , but this argument works as well for general @xmath0 as in the weak type theorem ) .",
    "while this assumption is not essential for the proof , it relieves the reader of having to consider the possibility that boundaries of dyadic cubes have positive measure at each step of the argument below .",
    "recall also ( see e.g. theorem 2.18 in @xcite ) that any positive locally finite borel measure on @xmath19 is both inner and outer regular .",
    "we begin with the necessity of condition : @xmath349if we choose @xmath350 .",
    "now we turn to proving , assuming both ( [ tsharpomega ] ) and , and moreover that @xmath35 is bounded with compact support",
    ". we will prove the quantitative estimate@xmath351we should emphasize that the term is comparable to the two weight @xmath8 condition .",
    "standard considerations ( @xcite , section 2 ) show that it suffices to prove the following good-@xmath204 inequality : there is a positive constant @xmath352 so that for @xmath353 sufficiently small , and provided @xmath354we have this inequality : @xmath355our presumption holds due to the @xmath8 condition and the fact that@xmath356hence it is enough to prove .",
    "to prove we choose @xmath357 , and apply the decomposition in . in this argument , we can take @xmath339 to be fixed , so that we suppress its appearance as a superscript in this section .",
    "( when we come to @xmath157 estimates , we will not have this luxury . )",
    "define @xmath358then for @xmath359 , we can apply lemma  [ l.maxprin ] to deduce @xmath360    if we take @xmath353 so small that @xmath361 , then ( e.maxprinc ) implies that for @xmath359 @xmath362integrating this inequality with respect to @xmath1 over @xmath363 we obtain @xmath364    the disjoint cover condition in shows that the sets @xmath363 are disjoint , and this suggests we should sum their @xmath1-measures .",
    "we split this sum into two parts , according to the size of @xmath365 .",
    "the left - hand side of ( goodlam ) satisfies@xmath366    now@xmath367by the finite overlap condition in . from with @xmath368",
    "we have @xmath369by the finite overlap condition in again .",
    "this completes the proof of the good-@xmath204 inequality .",
    "the proof of assertion 2 regarding @xmath31 is similar .",
    "assertion 3 was discussed earlier and assertion 4 follows readily from assertion 2 and lemma [ weakdom ] .",
    "since conditions and are obviously necessary for , we turn to proving the weighted inequality ( [ 2weight ] ) for the strongly maximal singular integral @xmath21 .",
    "in particular , we will prove @xmath370where @xmath371 is a doubling constant for the measure @xmath0 , see ( [ doubling property ] ) below .",
    "note that @xmath372 appears only in conjunction with @xmath373 and @xmath374 .",
    "the norm estimates on the maximal function and are equivalent to the testing conditions in and its dual formulation",
    ". the term @xmath375 also appeared in .",
    "we suppose that both and hold , i.e. ( [ e.tfrakstar ] ) and are finite , and that @xmath35 is bounded with compact support on @xmath19 .",
    "moreover , in the case holds , we see that ( the finiteness of ( [ e.tfrakstar ] ) ) implies by lemma [ dom ] , and so by theorem sawyerthm we may also assume that the maximal operator @xmath51 satisfies the two weight norm inequality .",
    "it now follows that @xmath376 for @xmath35 bounded with compact support .",
    "indeed , @xmath377 far away from the support of @xmath35 , while @xmath378 is controlled by the finiteness of the testing condition near the support of @xmath35 .",
    "let @xmath379 be the cubes as in and , with the measure @xmath183 that appears in there being @xmath380 .",
    "we will use lemma  [ l.maxprin ] with this choice of @xmath183 as well . now define an ` exceptional set ' associated to @xmath220 to be @xmath381see figure  [ f.1 ] .",
    "one might anticipate the definition of the exceptional set to be more simply @xmath382 .",
    "we are guided to this choice by the work on fractional integrals @xcite . and",
    "indeed , the choice of exceptional set above enters in a decisive way in the analysis of the bad function at the end of the proof .    .",
    "]    we estimate the left side of in terms of this family of dyadic cubes @xmath383 by @xmath384    choose a linearization @xmath41 of @xmath21 as in so that ( recall @xmath385 is the upper limit of truncation)@xmath386for @xmath387 , the maximum principle yields @xmath388from we conclude that@xmath389thus either @xmath390 or @xmath391 .",
    "so we obtain either@xmath392or@xmath393    now consider the following decomposition of the set of indices @xmath394 : @xmath395where @xmath396 will be chosen sufficiently small at the end of the argument .",
    "( it will be of the order of @xmath397 for a small constant @xmath398 . ) by the ` bounded overlap ' condition of , we have @xmath399we then have the corresponding decomposition:@xmath400where @xmath401 .",
    "the last line is the claim that we take up in the remainder of the proof .",
    "once it is proved , note that if we take @xmath402 and use the fact that @xmath403 for @xmath35 bounded with compact support , we have proved assertion ( 1 ) of theorem twoweighthaar , and in particular .",
    "the proof of the strong type inequality requires a complicated series of decompositions of the dominating sums , which are illustrated for the reader s convenience as a schematic tree in figure  [ f.2 ] .",
    "[ level distance=20 mm ] child node[shape aspect=2,diamond , draw ] @xmath404 child node[rectangle , draw ] @xmath405 edge from parent node[left ] @xmath406 edge from parent node[below , sloped ] child[missing ] node child node[shape aspect=2,diamond , draw ] @xmath407 child node[shape aspect=2,diamond , draw ] @xmath408 child node[rectangle , draw ] @xmath409 edge from parent node[left ] @xmath410 edge from parent node[below , sloped ] child[missing ] node child node[shape aspect=2,diamond , draw ] ( iv ) @xmath411 child node[shape aspect=2,diamond , draw ] @xmath412 child node[rectangle , draw ] @xmath413 edge from parent node[left ] @xmath414 edge from parent node[below , sloped ] child[missing ] node child node[rectangle , draw ] @xmath415 edge from parent node[right ] @xmath416 edge from parent node[below , sloped ] child[missing ] node child[missing ] node child[missing ] node child node[shape aspect=2,diamond , draw ] @xmath417 child node[rectangle , draw ] @xmath418 $ ] edge from parent node[left ] @xmath419 edge from parent node[below , sloped ] child[missing ] node child[missing ] node child node[shape aspect=2,diamond , draw ] @xmath420 $ ] child node[rectangle , draw ] @xmath421 edge from parent node[left ] @xmath422 edge from parent node[below , sloped ] child[missing ] node child node[rectangle , draw ] @xmath423 edge from parent node[right ] @xmath424 edge from parent node[below , sloped ] child[missing ] node child node[rectangle , draw ] @xmath425 edge from parent node[right ] @xmath426 node[sloped , below ] child[missing ] node child node[rectangle , draw ] @xmath427 edge from parent node[right ] @xmath428 child[missing ] node child node[rectangle , draw ] @xmath429 edge from parent node[above , sloped ] absorb ;      note that the first term @xmath430 in satisfies @xmath431by the finite overlap condition . the second term @xmath432 is dominated by@xmath433by our assumption .",
    "it is useful to note that this is the _ only _ time in the proof that we use the maximal function inequality ( [ m2weight ] ) - from now on we use the _ dual _ maximal function inequality .    in the arguments below we can use theorem 2 of @xcite  to replace the dual maximal function assumption @xmath434 with two assumptions , namely a ` poisson two weight @xmath8 condition ' and the analogue of the dual pivotal condition of nazarov , treil and volberg ntv3 .",
    "the poisson two weight @xmath8 condition is in fact necessary for the two weight inequality , but the pivotal conditions are _ not _ necessary for the hilbert transform two weight inequality ( @xcite ) . on the other hand ,",
    "the assumption @xmath435 can not be weakened here , reflecting that our method requires the maximum principle in lemma l.maxprin .",
    "it is the third term @xmath436 that is the most involved , see figure  [ f.2 ] .",
    "the remainder of the proof is taken up with the proof of @xmath437where@xmath438once this is done , the proof of is complete , and the proof of assertion ( 1 ) is finished .      to carry out this proof , we implement caldern - zygmund decompositions relative to the measure @xmath0 .",
    "these decompositions will be done at _ all heights simultaneously_. we will use the shifted dyadic grids , see . suppose that @xmath371 is a doubling constant for the measure @xmath0:@xmath439for @xmath440 , let@xmath441@xmath442where @xmath443 are the maximal @xmath194 cubes in @xmath444 , and @xmath445 is the set of pairs we use to label the cubes .",
    "this implies that we have the nested property : if @xmath446 then @xmath447 .",
    "moreover , if @xmath448 there is some @xmath449 with @xmath450 .",
    "these are the cubes used to make a caldern - zygmund decomposition at height @xmath451 for the grid @xmath194 with respect to the measure @xmath0 .",
    "we will refer to the cubes @xmath452 as * principal cubes*.    of course we have from the maximal inequality in @xmath453the point of these next several definitions is to associate to each dyadic cube @xmath13 , a good shifted dyadic grid , and an appropriate height , at which we will build our caldern - zygmund decomposition .",
    "it is now that we will use the following consequence of the doubling condition for the measure @xmath0:@xmath454the average @xmath455 is thus at most @xmath456 by and the maximality of the cubes in : @xmath457    select a shifted grid : :    let @xmath458 be a map so that    for @xmath459 , there is a    @xmath460 so that    @xmath461 and    @xmath462 . here , @xmath352 is an appropriate constant depending    only on dimension .",
    "thus , @xmath463 picks a ` good '    shifted dyadic grid for @xmath13 .",
    "moreover we will assume that    @xmath464 is the smallest such cube .",
    "note that we are    discarding the extra requirement that    @xmath465 since this property    will not be used .",
    "also we have    @xmath466for some    positive dimensional constant @xmath326 .",
    "the cubes    @xmath467 will play a critical role below .",
    "see    figure  [ f.4 ] select a principal cube : :    define @xmath468 to be the smallest cube from the    collection    @xmath469 that contains @xmath470 ;    @xmath468 is uniquely determined by @xmath13    and the choice of function @xmath471 .",
    "define    @xmath472this    is an important definition for us .",
    "the combinatorial structure this    places on the corresponding cubes is essential for this proof to work .",
    "note that    @xmath473 .",
    "parents : :    for any of the shifted dyadic grids    @xmath194 , a    @xmath474 has a unique parent denoted    as @xmath475 , the smallest member of    @xmath194 that strictly contains    @xmath13 .",
    "we suppress the dependence upon @xmath199    here .",
    "indices : :    let    @xmath476we use a calligraphic    font @xmath477 for sets of indices related to the grid    @xmath478 , and a blackboard    font @xmath479 for sets of indices related to the grid    @xmath480 . the good and bad functions : :    let @xmath481 be the @xmath0-average of    @xmath35 on @xmath482 .",
    "define functions    @xmath483 and @xmath484    satisfying @xmath485 on    @xmath486 by @xmath487we extend both @xmath483 and    @xmath484 to all of @xmath488 by defining them to vanish outside    @xmath486 .",
    "now @xmath489 by ( [ average bound ] ) .",
    "thus lebesgue s differentiation theorem shows that ( any of the standard proofs can be adapted to the dyadic setting for positive locally finite borel measures on @xmath19 ) @xmath490that is , @xmath483 is the ` good ' function and @xmath484 is the ` bad ' function .",
    "we can now refine the final sum on the left side of according to the decomposition of @xmath491 .",
    "we carry this out in three steps . in the first step ,",
    "we fix an @xmath492 , and for the remainder of the proof , we only consider @xmath220 for which @xmath493 .",
    "namely , we will modify the important definition of @xmath494 in to @xmath495 in the second step , we partition the indices @xmath394 into the sets @xmath496 in for @xmath497 .",
    "in the third step , for @xmath498 , we split @xmath35 into the corresponding good and bad parts .",
    "this yields the decomposition @xmath499recall the definition of @xmath500 in . in the definitions of @xmath501 , @xmath502 and @xmath503 , @xmath504",
    "we will suppress the dependence on @xmath440 .",
    "the same will be done for the subsequent decompositions of the ( difficult ) term @xmath503 , although we usually retain the superscript @xmath199 in the quantities arising in the estimates .",
    "in particular , we emphasize that the combinatorial properties of the cubes associated with @xmath505 are essential to completing this proof .",
    "term @xmath170 requires only the forward testing condition and the maximal theorem , while term @xmath503 requires only the dual testing condition , along with the dual maximal function inequality and the maximal theorem .",
    "the reader is again directed to figure [ f.2 ] for a map of the various decompositions of the terms and the conditions used to control them .",
    "we claim that @xmath506    we use boundedness of the ` good ' function @xmath483 , as defined in , the testing condition for @xmath21 , see also , and finally the universal maximal function bound with @xmath507 . here",
    "are the details . for @xmath508",
    ", implies that @xmath509 and so @xmath510where we have used and with @xmath511 in the final inequality .",
    "this last sum is controlled by , and completes the proof of .",
    "it remains to estimate term @xmath503 , as in , but this is in fact the harder term . recall the definition of @xmath512 in .",
    "we now write@xmath513 \\chi _ { g_{r}^{\\alpha , t+1}}\\equiv \\sum_{r\\in \\mathcal{k}_{s}^{\\alpha , t}}b_{r } ,   \\label{e.brdef}\\]]where the ` bad ' functions @xmath514 are supported in the cube @xmath515 and have @xmath0-mean zero , @xmath516 . to take advantage of this , we will pass to the dual @xmath254 below .",
    "but first we must address the fact that the triples of the @xmath517 cubes @xmath482 do not form a grid .",
    "fix @xmath518 and let @xmath519be the collection of triples of the @xmath194 cubes @xmath520 with @xmath521 .",
    "we select the _ maximal _",
    "triples @xmath522from the collection @xmath523 , and assign to each @xmath524 the maximal triple @xmath525 containing @xmath526 with least @xmath527 . note that @xmath528 extends outside @xmath486 if @xmath520 and @xmath486 share a face . by lemma",
    "besicovitch applied to @xmath194 the maximal triples @xmath529 have finite overlap @xmath530 , and this will prove crucial in , and below .",
    "we will pass to the dual of the linearization.@xmath531note that implies @xmath532 is supported in @xmath533 if @xmath183 is supported in @xmath534 , explaining the range of integration above .",
    "continuing , we have for fixed @xmath535,@xmath536to see the above inequality , note that for @xmath521 we are splitting the set @xmath534 into @xmath537 and @xmath538 . on the latter set ,",
    "the hypotheses of lemma  [ constant ] are in force , namely the set @xmath538 does not intersect @xmath539 , whence we have an estimate on the @xmath65-hlder modulus of continuity of @xmath540 .",
    "combine this with the fact that @xmath514 has @xmath3-mean zero on @xmath482 to derive the estimate below , in which @xmath541 is the center of the cube @xmath482 .",
    "@xmath542    we have after application of , @xmath543 ^{p } \\label{e.iistdef2 } \\\\ & \\leq i\\!i_{s}^{t}(1)+i\\!i_{s}^{t}(2)\\ , ,   \\label{iitilda } \\\\",
    "i\\!i_{s}^{t}(1 ) & = \\sum_{(k , j)\\in \\mathbb{i}_{s}^{\\alpha , t}}r_{j}^{k}\\left\\vert \\sum_{r\\in \\mathcal{k}_{s}^{\\alpha , t}}\\int_{g_{r}^{\\alpha , t+1}}\\left ( l^{\\ast } \\chi _ { e_{j}^{k}\\cap t_{\\ell \\left ( r\\right ) } } \\omega \\right ) b_{r}\\sigma \\right\\vert ^{p } ,   \\label{e.ii1 } \\\\",
    "i\\!i_{s}^{t}(2 ) & = \\sum_{(k , j)\\in \\mathbb{i}_{s}^{\\alpha , t}}r_{j}^{k}\\left [ \\sum_{r\\in \\mathcal{k}_{s}^{\\alpha , t}}\\mathbf{p}\\left ( g_{r}^{\\alpha , t+1},\\chi _ { e_{j}^{k}}\\omega \\right ) \\int_{g_{r}^{\\alpha , t+1}}\\left\\vert f\\right\\vert \\sigma \\right ] ^{p}.   \\label{e.ii2}\\end{aligned}\\]]note that we may further restrict the integration in to @xmath544 since @xmath545 is supported in @xmath533 .      we claim that@xmath547recall the definition of @xmath374 in .",
    "we begin by defining a linear operator by @xmath548 in this notation , we have for @xmath549 ( see and ) , @xmath550    by assumption , the maximal function @xmath551 maps @xmath552 to @xmath553 , and we now note a particular consequence of this . in the definition",
    "we were careful to insert @xmath554 on the right hand side .",
    "these sets are pairwise disjoint , whence we have the inequality below for measures @xmath184 .",
    "@xmath555thus the inequality@xmath556follows immediately . by duality",
    "we then have @xmath557note that it was the linearity that we wanted in , so that we could appeal to the dual maximal function assumption .",
    "we thus obtain @xmath558 ^{p}.\\]]summing in @xmath559 and using @xmath560 for @xmath561 we obtain@xmath562 ^{p }   \\label{sum in ts } \\\\ & = & c\\gamma ^{2p}\\sum_{\\left ( t , s\\right ) \\in \\mathbb{l}^{\\alpha } } \\gamma ^{pt}\\sum_{(k , j)\\in \\mathbb{i}_{s}^{\\alpha , t}}\\left\\vert e_{j}^{k}\\right\\vert _ { \\omega } \\left [ \\frac{1}{\\left\\vert nq_{j}^{k}\\right\\vert _ { w}}\\int_{q_{j}^{k}}({\\mathbf{p}}_{j}^{k})^{\\ast } \\left ( \\chi _ { g_{s}^{\\alpha , t}}\\sigma \\right ) \\omega \\right ] ^{p }   \\notag \\\\ & \\leq & c\\gamma ^{2p}\\sum_{\\left ( t , s\\right ) \\in \\mathbb{l}^{\\alpha } } \\gamma ^{pt}\\int \\left [ \\mathcal{m}_{\\omega } ^{dy}\\left ( \\chi _ { g_{s}^{\\alpha , t}}\\sum_{(\\ell , i)\\in \\mathbb{i}_{s}^{\\alpha , t}}({\\mathbf{p}}_{i}^{\\ell } ) ^{\\ast } \\left ( \\chi _ { g_{s}^{\\alpha , t}}\\sigma \\right ) \\right ) \\right ] ^{p}\\omega \\\\ & \\leq & c\\gamma ^{2p}\\sum_{\\left ( t , s\\right ) \\in \\mathbb{l}^{\\alpha } } \\gamma ^{pt}\\int_{g_{s}^{\\alpha , t}}\\left [ \\sum_{(\\ell , i)\\in \\mathbb{i}% _ { s}^{\\alpha , t}}({\\mathbf{p}}_{i}^{\\ell } )",
    "^{\\ast } \\left ( \\chi _ { g_{s}^{\\alpha , t}}\\sigma \\right ) \\right ] ^{p}\\omega \\\\ & \\leq & c\\gamma ^{2p}\\mathfrak{m}_{\\ast } ^{p}\\sum_{\\left ( t , s\\right ) \\in   \\mathbb{l}^{\\alpha } } \\gamma ^{pt}\\left\\vert g_{s}^{\\alpha , t}\\right\\vert _ { \\sigma } ,   \\notag\\end{aligned}\\]]which is bounded by @xmath563 . in the last line we are applying with @xmath564 .",
    "we note that the term @xmath566 is dominated by @xmath567 , where@xmath568@xmath569the term @xmath570 includes that part of @xmath514 supported on @xmath571 , and the term @xmath572 includes that part of @xmath514 supported on @xmath573 , which is the more delicate case .",
    "[ r.gettingdifficult ] the key difference between the terms @xmath574 and @xmath575 is the range of integration : @xmath571 for @xmath570 and @xmath576 for @xmath575 .",
    "just as for the fractional integral case , it is the latter case that is harder , requiring combinatorial facts , which we come to at the end of the argument .",
    "an additional fact that we return to in different forms , is that the set @xmath576 can be further decomposed using whitney decompositions of @xmath577 in the grid @xmath194 .",
    "recall the definition of @xmath375 in .",
    "we claim @xmath578    let @xmath579 ( note that @xmath580 is much larger than @xmath534 ) .",
    "we will use the definition of @xmath500 in , and the fact that @xmath581provided @xmath582 .",
    "we will apply the form of ( tsharpomega ) with @xmath583 , also see , and with@xmath584 in the case @xmath585 is a cube , and with@xmath586 in the case @xmath585 is @xmath587 a cube ( this is possible since @xmath588 is the _",
    "triple _ of a @xmath589-cube ) . in each case",
    "we claim that@xmath590indeed , recall that @xmath467 is the cube in the shifted grid @xmath198 that is selected by @xmath220 as in the definition  * select a shifted grid * above and satisfies @xmath591 where @xmath210 is as in remark [ 3n ] , by choosing @xmath592 sufficiently large in .",
    "now @xmath588 is a triple of a cube in the grid @xmath194 and @xmath593 is a cube in @xmath194 .",
    "thus if @xmath594 is _ not _ a cube , then we must have @xmath595 and this proves the claim .",
    "we then have @xmath596 ^{p-1}\\int_{\\widetilde{e_{j}^{k}}}\\left\\vert h_{s}^{\\alpha , t}\\right\\vert ^{p}\\sigma \\\\ & \\leq & \\sum_{(k , j)\\in \\mathbb{i}_{s}^{\\alpha , t}}r_{j}^{k}\\left [ \\sum_{\\ell \\in \\mathcal{l}_{s}^{\\alpha , t}}\\int_{t_{\\ell } \\cap 3\\widehat{q_{j}^{k}}% } \\left\\vert l^{\\ast } \\chi _ { e_{j}^{k}\\cap t_{\\ell } } \\omega \\right\\vert ^{p^{\\prime } } \\sigma \\right ] ^{p-1}\\int_{\\widetilde{e_{j}^{k}}}\\left\\vert h_{s}^{\\alpha , t}\\right\\vert ^{p}\\sigma \\\\ & \\leq & \\mathfrak{t}_{\\ast } ^{p}\\sum_{(k , j)\\in \\mathbb{i}_{s}^{\\alpha , t}}r_{j}^{k}\\left [ \\sum_{\\ell \\in \\mathcal{l}_{s}^{\\alpha , t}}\\left\\vert t_{\\ell } \\cap 3\\widehat{q_{j}^{k}}\\right\\vert _ { \\omega } \\right ] ^{p-1}\\int_{% \\widetilde{e_{j}^{k}}}\\left\\vert h_{s}^{\\alpha , t}\\right\\vert ^{p}\\sigma \\\\ & \\leq & \\mathfrak{t}_{\\ast } ^{p}\\sum_{(k , j)\\in \\mathbb{i}_{s}^{\\alpha , t}}% \\frac{\\left\\vert e_{j}^{k}\\right\\vert _ { \\omega } } { \\left\\vert nq_{j}^{k}\\right\\vert _ { \\omega } } \\left\\vert nq_{j}^{k}\\right\\vert _ { \\omega } ^{p-1}\\int_{\\widetilde{e_{j}^{k}}}\\left\\vert h_{s}^{\\alpha , t}\\right\\vert ^{p}\\sigma \\\\ & \\leq & c\\mathfrak{t}_{\\ast } ^{p}\\sum_{(k , j)\\in \\mathbb{i}_{s}^{\\alpha , t}}\\int_{\\widetilde{e_{j}^{k}}}\\left\\vert h_{s}^{\\alpha , t}\\right\\vert ^{p}\\sigma",
    "\\leq c\\mathfrak{t}_{\\ast } ^{p}\\sum_{(k , j)\\in \\mathbb{g}^{\\alpha } \\cap \\mathbb{h}_{s}^{\\alpha , t}}\\int_{\\widetilde{e_{j}^{k}}}\\left ( \\left\\vert f\\right\\vert ^{p}+\\left\\vert \\mathcal{m}_{\\sigma } ^{\\alpha } f\\right\\vert ^{p}\\right ) \\sigma .\\end{aligned}\\]]using@xmath597we thus obtain .",
    "this is the most intricate and final case .",
    "we will prove@xmath598where @xmath373 , @xmath375 and @xmath374 are defined in , and respectively .",
    "the estimates , , , prove , and so complete the proof of assertion 1 of the strong type characterization in theorem [ twoweighthaar ] .",
    "assertions 2 and 3 of theorem [ twoweighthaar ] follow as in the weak - type theorem [ weaktwoweighthaar ] . finally , to prove assertion 4 we note that lemma [ dom ] and condition imply , which by theorem [ sawyerthm ] yields .",
    "we now use the shifted grid @xmath194 in place of the dyadic grid @xmath599  to form a whitney decomposition of @xmath600 in the spirit of .",
    "however , in order to fit the @xmath589-cubes @xmath467 defined above in `` * * select a shifted grid * * '' , it will be necessary to use a smaller constant than the constant @xmath601 already used for the whitney decomposition of @xmath600 into @xmath602-cubes .",
    "recall the dimensional constant @xmath326 defined in ( qhatcontained ) : it satisfies @xmath603 .",
    "define the new constant @xmath604we now use the decomposition of @xmath600 in , but with @xmath602 replaced by @xmath194 and with @xmath592 replaced by @xmath605 .",
    "we have thus decomposed@xmath606into a whitney decomposition of pairwise disjoint cubes @xmath607 in @xmath198 satisfying@xmath608and the following analogue of the nested property in : @xmath609    now we introduce yet another construction . for",
    "every pair @xmath610 let @xmath611 be the unique @xmath194-cube @xmath612 containing @xmath467 .",
    "note that such a cube @xmath613 exists since @xmath614 by and @xmath615 by imply that @xmath616 .",
    "of course the cube @xmath617 satisfies @xmath618moreover , we can arrange to have@xmath619where @xmath210 is as in remark [ 3n ] , by choosing @xmath592 sufficiently large in .",
    "see figure  [ f.4 ] .    ,",
    "@xmath620 , and @xmath611 inside a set @xmath600 . ]",
    "we will use this decomposition for the set @xmath621 in our arguments below . the corresponding cubes @xmath622 that arise as certain of the @xmath623 satisfy the conditions , @xmath624 note that the set of indices @xmath625 arising in the decomposition of @xmath626 into @xmath194 cubes @xmath623 is _ not _ the same as the set of indices @xmath627 arising in the decomposition of @xmath628 into @xmath599 cubes @xmath629 , but this should not cause confusion .",
    "so we will usually write @xmath630 with dummy index @xmath627 unless it is important to distinguish the cubes @xmath630 from the cubes @xmath629 . this distinction will be important in the proof of the ` bounded occurrence of cubes ' property in ",
    "[ combinatorics ] below .",
    "now use @xmath631 to split the term @xmath572 in into two pieces as follows:@xmath632where @xmath633and where @xmath634denotes the @xmath0-average of @xmath635 on the cube @xmath636 .",
    "thus @xmath637 corresponds to the case where the averages are ` big ' and @xmath417 where the averages are ` small ' .",
    "the analysis of @xmath638 in is the hard case , taken up later",
    ".      bounded occurrence of cubes : :    a given cube @xmath639 can occur only a    _ bounded _ number of times as @xmath630    where@xmath640specifically , let    @xmath641 , as defined in [ e.gdefalpha ] , be such that    @xmath642 for some @xmath643 and    @xmath644 for    @xmath645 .",
    "it follows that @xmath646 , where @xmath647 is the small constant    chosen in the definition of @xmath648 .",
    "the    constant @xmath352 here depends only on dimension .",
    "the whitney structure , see , is decisive here , as well as the fact that @xmath649 for @xmath650 . for this proof it will be useful to use @xmath625 to index the cubes @xmath651 and to use @xmath627 to index the cubes @xmath629 .",
    "the following lemma captures the main essence of the whitney structure , and will be applied to cubes @xmath623 satisfying ( [ whitney alpha ] ) and cubes @xmath652 satisfying ( [ whitney ] ) .",
    "[ whitney comparability]suppose that @xmath13 is a member of the whitney decomposition of @xmath653 with respect to the grid @xmath599 and with whitney constant @xmath592 .",
    "suppose also that a cube @xmath654 is a member of a whitney decomposition of the same open set @xmath653 but with respect to the grid @xmath194 and with whitney constant @xmath605 .",
    "if @xmath655 and @xmath656 , then the sidelengths of @xmath13 and @xmath654 are comparable:@xmath657    since @xmath655 and @xmath13 is a whitney cube we have @xmath658then since @xmath656 and @xmath654 is a whitney cube ( for the other decomposition ) we have@xmath659    so suppose that @xmath660 and @xmath661 for @xmath645 , with the pairs of indices @xmath662 being distinct .",
    "observe that the finite overlap property in applies to the cubes @xmath663 in the whitney decompostion ( [ whitney alpha ] ) of @xmath664 with grid @xmath194 and whitney constant @xmath605 .",
    "thus for fixed @xmath339 the number of @xmath665 with @xmath666 is bounded by the finite overlap constant since @xmath654 is inside each @xmath667 .",
    "this gives us the observation that a single integer @xmath339 can occur only a _ bounded _",
    "number @xmath668 of times among the @xmath669 .    after a relabeling",
    ", we can assume that all the @xmath670 for @xmath671 are distinct , listed in increasing order , and that the number @xmath672 of @xmath670 satisfies @xmath673 .",
    "the nested property of assures us that @xmath654 is an element of the whitney decomposition ( [ whitney alpha ] ) of @xmath600 for _ all _ @xmath674 .",
    "[ intermediate cubes]note that the @xmath670 are not necessarily consecutive since we require that @xmath675 .",
    "nevertheless , the cube @xmath654 _ does _ occur among the @xmath636 for any @xmath339 that lies between @xmath670 and @xmath676 .",
    "these latter occurrences of @xmath654 may be unbounded , but we are only concerned with bounding those for which @xmath677 , and it is these occurrences that our argument is treating .",
    "thus for @xmath678 , we have @xmath679 , and it follows from remark [ intermediate cubes ] that the cube @xmath654 is a member of the whitney decomposition ( [ whitney alpha ] ) of the open set @xmath680 with grid @xmath517 and whitney constant @xmath605 .",
    "but we also have that @xmath681 is a member of the whitney decomposition ( whitney ) of @xmath680 with grid @xmath599 and whitney constant @xmath592 .",
    "thus lemma [ whitney comparability ] gives us the equivalence of side lengths @xmath682 .",
    "combined with the containment @xmath683 , we see that the number of possible locations for the cubes @xmath684 is bounded by a constant @xmath685 depending only on dimension .",
    "apply the pigeonhole principle to the possible locations of the @xmath681 .",
    "after a relabeling , we can argue under the assumption that all @xmath686 equal the same cube @xmath687 for all choices of @xmath688 where @xmath689 .",
    "now comes the crux of the argument where the condition that the indices @xmath690 lie in @xmath648 , as given in ( [ e.gdefalpha ] ) , proves critical .",
    "in particular we have @xmath691 where @xmath210 is as in remark [ 3n ] .",
    "the @xmath670 are distinct , and the sets @xmath692 are pairwise disjoint , hence @xmath693implies @xmath694 .",
    "thus @xmath695 and our proof of the claim is complete .      the first task in the analysis of the terms @xmath696 and @xmath697 will be to replace part of the ` bad functions ' @xmath698 by their averages over @xmath630 , or more exactly the averages @xmath699 .",
    "we again appeal to the hlder continuity of @xmath700 . by construction , @xmath701 does not meet @xmath534 , so that lemma  [ constant ] applies .",
    "if @xmath702 for some @xmath271 , then there is a constant @xmath703 satisfying @xmath704 such that@xmath705indeed , if @xmath706 is the center of the cube @xmath630 , we have@xmath707now , the functions @xmath514 are given in , and by construction , we note that@xmath708so with@xmath709we have @xmath710 and@xmath711 in the special case where @xmath630 is equal to @xmath482 , then @xmath712 and the above proof shows that@xmath713since @xmath714 .",
    "our next task is to organize the sum over the cubes @xmath630 relative to the cubes @xmath482 .",
    "this is necessitated by the fact that the cubes @xmath630 are _ not _ pairwise disjoint in @xmath339 , and we thank tuomas hytonen for bringing this point to our attention . the cube @xmath636 must intersect @xmath715 since otherwise@xmath716thus @xmath630 satisfies exactly one of the following two cases which we indicate by writing @xmath717 or @xmath718 :    * case ( a ) : * @xmath630 _ strictly _ contains at least one of the cubes @xmath482 , @xmath521 ;    * case ( b ) : * @xmath702 for some @xmath524 .    note that the cubes @xmath630 with @xmath719 can only satisfy case ( b ) , while the cubes @xmath630 with @xmath720 can can satisfy either of the two cases above . however , we have the following claim .    [ bounded triples]for each fixed @xmath521 , we have@xmath721where the sum is taken over all _ admissible _ index _ triples _ @xmath722 , i.e. those for which the cube @xmath630 arises in term @xmath575 with both @xmath702 and @xmath723 .",
    "but we first establish a containment that will be useful later as well . recall that @xmath577 decomposes as a pairwise disjoint union of cubes @xmath630 , and",
    "thus we have@xmath724since the support of @xmath725 is contained in @xmath726 by .",
    "since both @xmath630 and @xmath727 lie in the grid @xmath194 and have nonempty intersection , one of these cubes is contained in the other .",
    "now @xmath636 can not _ strictly _ contain @xmath611 since @xmath728 for some @xmath527 and the cubes @xmath729 satisfy the nested property .",
    "it follows that we must have@xmath730    now we return to claim [ bounded triples ] , and note that for a fixed index pair @xmath731 , the bounded overlap condition in ( whitney ) shows that there are only a bounded number of indices @xmath122 such that @xmath732 - see ( qtilda contained ) .",
    "we record this observation here:@xmath733thus claim [ bounded triples ] is reduced to this one .",
    "[ bounded pairs]@xmath734    as is the case with similar assertations in this argument , a central obstacle is that a given cube @xmath735 can arise in many different ways as a @xmath736 .",
    "we will appeal to the ` bounded occurrence of cubes ' in  [ combinatoric ] above .",
    "this principle relies upon the definition of @xmath648 in ( [ e.gdefalpha ] ) , and applies in this setting due to the definition of @xmath505 in .",
    "we also appeal to the following fact:@xmath737to see ( [ follows easily ] ) , we note that both of the cubes @xmath515 and @xmath611 lie in the grid @xmath194 and have nonempty intersection ( they contain @xmath630 ) , so that one of these cubes must be contained in the other .",
    "however , if @xmath738 , then @xmath739 implies @xmath740 , which contradicts @xmath741 .",
    "so we must have @xmath742 as asserted in ( [ follows easily ] ) .",
    "so to see that holds , suppose that @xmath743 and @xmath744 with an associated cube @xmath611 as in .",
    "then by ( [ follows easily ] ) and ( [ modified ] ) the side length @xmath745 of @xmath220 satisfies @xmath746also , if @xmath747 is _ any _ whitney cube at level @xmath339 that is contained in @xmath482 , then by ( [ follows easily ] ) and ( modified ) we have @xmath748so that lemma [ whitney comparability ] shows that @xmath747 and @xmath749 have comparable side lengths:@xmath750moreover , if @xmath751 is any whitney cube at level @xmath752 that is contained in @xmath482 , then there is some whitney cube @xmath747 at level @xmath339 such that @xmath753 .",
    "thus we have the containments @xmath754 , and it follows from ( [ csl ] ) that@xmath755    now momentarily _ fix _ @xmath756 such that there is a cube @xmath757 satisfying the conditions in ( [ k bounded ] ) . then _ all _ of the cubes @xmath758 that arise in ( [ k bounded ] ) with @xmath759 satisfy @xmath760thus all of the cubes @xmath758 with @xmath761 , except perhaps those with @xmath762 , have side lengths bounded below by @xmath763 , which bounds the number of possible locations for these cubes by a dimensional constant",
    ". however , those cubes @xmath764 at level @xmath765 are pairwise disjoint , as are those cubes @xmath766 at level @xmath767 .",
    "consequently , we can apply the ` bounded occurrence of cubes ' to show that the sum in ( [ k bounded ] ) , when restricted to @xmath761 , is bounded by a constant @xmath352 independent of @xmath756 . since @xmath756 is arbitrary , this completes the proof of claim [ bounded pairs ] .    as a result of , for those @xmath627 in either @xmath768 or @xmath769 that satisfy case ( b ) , we will be able to apply below the poisson argument used to estimate term @xmath770 in above .",
    "we now further split the sum over @xmath771 in term @xmath772  into two sums according to the cases ( a ) and ( b ) above:@xmath773 + i\\!v_{s}^{t}\\left ( 2\\right)[b ] .",
    "\\notag\\end{aligned}\\ ] ]    we apply the definition of case ( b ) and , to decompose @xmath774 $ ] as follows .",
    "@xmath775 & = & \\sum_{(k , j)\\in \\mathbb{i}% _ { s}^{\\alpha , t}}r_{j}^{k}\\left\\vert \\sum_{r\\in \\mathcal{k}_{s}^{\\alpha , t}}\\sum_{i\\in \\mathcal{j}_{s}^{t}:b_{i}^{k+2}\\subset g_{r}^{\\alpha , t+1}}\\int_{b_{i}^{k+2}}\\left [ l^{\\ast } \\chi _ { e_{j}^{k}\\cap t_{\\ell \\left ( r\\right ) } } \\omega \\right ] b_{r}\\sigma \\right\\vert ^{p }   \\notag \\label{e.v2def } \\\\ & \\leq & \\sum_{(k , j)\\in \\mathbb{i}_{s}^{\\alpha , t}}r_{j}^{k}\\left\\vert \\sum_{r\\in \\mathcal{k}_{s}^{\\alpha , t}}\\sum_{i\\in \\mathcal{j}% _ { s}^{t}:b_{i}^{k+2}\\subset g_{r}^{\\alpha , t+1}}\\left [ \\int_{b_{i}^{k+2}}% \\left ( l^{\\ast } \\chi _ { e_{j}^{k}\\cap t_{\\ell \\left ( r\\right ) } } \\omega \\right ) \\sigma \\right ] \\right .",
    "\\label{e.3456}\\\\ & & \\qquad \\left .",
    "\\times c_{i}^{k+2}\\left ( \\left\\vert a_{r}^{\\alpha , t+1}\\right\\vert + \\mathsf{a}_{i}^{k+2}\\right ) \\right\\vert ^{p }   \\notag \\\\ & & + \\sum_{(k , j)\\in \\mathbb{i}_{s}^{\\alpha , t}}r_{j}^{k}\\left\\vert \\sum_{r\\in   \\mathcal{k}_{s}^{\\alpha , t}}\\sum_{i\\in \\mathcal{j}_{s}^{t}:b_{i}^{k+2}% \\subset g_{r}^{\\alpha , t+1}}\\mathbf{p}\\left ( b_{i}^{k+2},\\chi _ { e_{j}^{k}\\cap t_{\\ell \\left ( r\\right ) } } \\omega \\right ) \\int_{b_{i}^{k+2}}\\left\\vert b_{r}\\right\\vert \\sigma \\right\\vert ^{p } \\\\ & = & v_{s}^{t}(1 ) + v_{s}^{t}(2 ) .",
    "\\notag\\end{aligned}\\ ] ]      we claim that @xmath776here , @xmath374 is defined in , and @xmath777 is defined in .    the estimate for term @xmath778 is similar to that of @xmath779 above , see , except that this time we use claim [ bounded triples ] to handle a complication arising from the extra sum in the cubes @xmath630 .",
    "we define @xmath780we observe that by the sum of these operators satisfies @xmath781and hence the analogue of holds with @xmath782 defined as above:@xmath783 for our use below , we note that this conclusion holds independent of the assumption , imposed in , that @xmath784 .    with this notation , the summands in the definition of @xmath785 ,",
    "as given in , are@xmath786    we then have from and by the argument for term @xmath787 , @xmath788 ^{p}\\;\\omega \\\\ & \\leq & c\\gamma ^{2p}\\mathfrak{m}_{\\ast } ^{p}\\sum_{\\left ( t , s\\right ) \\in   \\mathbb{l}^{\\alpha } } \\gamma ^{pt}\\sum_{\\ell } \\left\\vert g_{s}^{\\alpha , t}\\right\\vert _ { \\sigma } \\leq c\\gamma ^{2p}\\mathfrak{m}_{\\ast } ^{p}\\int \\lvert f\\rvert ^{p}\\;\\sigma \\,.\\end{aligned}\\]]in last lines we are using the boundedness of the maximal operator .",
    "we will use the same method to treat term @xmath789 and term @xmath790 below , and we postpone the argument for now .",
    "we turn to the term defined in . in case ( a )",
    "the cubes @xmath636 satisfy@xmath791and so recalling that @xmath771 and @xmath792 , we obtain from that@xmath793 & = & \\sum_{(k , j)\\in \\mathbb{i}% _ { s}^{\\alpha , t}}r_{j}^{k}\\left\\vert \\sum_{i\\in \\mathcal{j}_{s}^{t}\\text { and } i\\in\\textup{case}\\left ( a\\right ) } \\sum_{r : g_{r}^{\\alpha , t+1}\\subset b_{i}^{k+2}}\\int_{g_{r}^{\\alpha , t+1}}\\left ( l^{\\ast } \\chi _ { e_{j}^{k}}\\omega \\right ) b_{r}\\sigma \\right\\vert ^{p } \\\\ & \\leq & c\\sum_{(k , j)\\in \\mathbb{i}_{s}^{\\alpha , t}}r_{j}^{k}\\left\\vert \\sum_{i\\in\\textup{case}\\left ( a\\right ) } \\sum_{r : g_{r}^{\\alpha , t+1}\\subset b_{i}^{k+2}}\\mathbf{p}\\left ( g_{r}^{\\alpha , t+1},\\chi _ { e_{j}^{k}}\\omega \\right ) \\int_{g_{r}^{\\alpha , t+1}}\\left\\vert f\\right\\vert \\sigma \\right\\vert ^{p } \\\\ & \\leq & c\\gamma ^{p\\left ( t+2\\right ) } \\sum_{(k , j)\\in \\mathbb{i}_{s}^{\\alpha , t}}r_{j}^{k}\\left\\vert \\sum_{r : g_{r}^{\\alpha , t+1}\\subset 3q_{j}^{k}}% \\mathbf{p}\\left ( g_{r}^{\\alpha , t+1},\\chi _ { e_{j}^{k}}\\omega \\right ) \\left\\vert g_{r}^{\\alpha , t+1}\\right\\vert _ { \\sigma } \\right\\vert ^{p}.\\end{aligned}\\]]but this last sum is identical to the estimate for the term @xmath787 used in above .",
    "the estimate there thus gives@xmath794 \\leq c\\gamma ^{2p}\\mathfrak{m}_{\\ast } ^{p}\\sum_{\\left ( t , s\\right ) \\in \\mathbb{l}^{\\alpha } } \\gamma ^{pt}\\left\\vert g_{s}^{\\alpha , t}\\right\\vert _ { \\sigma } \\leq c\\gamma ^{2p}\\mathfrak{m}_{\\ast } ^{p}\\int \\left\\vert f\\right\\vert ^{p}\\sigma ,   \\label{e.ivts2a<}\\]]which is the desired estimate .",
    "this term is the first term on the right hand side of .",
    "recall that for @xmath719 we have @xmath796 and so @xmath797 for some @xmath521 . from",
    "we also have @xmath798 . to estimate @xmath799 in",
    ", we again apply to be able to write @xmath800 \\mathsf{a}_{i}^{k+2}\\right ] ^{p }   \\label{e.vi2def } \\\\ & & { } + { } c\\sum_{(k , j)\\in \\mathbb{i}_{s}^{\\alpha , t}}r_{j}^{k}\\left [ \\sum_{\\ell } \\sum_{i\\in \\mathcal{i}_{s}^{t}:b_{i}^{k+2}\\subset t_{\\ell } \\cap \\widetilde{% q_{j}^{k}}}\\mathbf{p}\\left ( b_{i}^{k+2},\\chi _ { e_{j}^{k}\\cap t_{\\ell } } \\omega \\right ) \\int_{b_{i}^{k+2}}\\left\\vert f\\right\\vert \\sigma \\right ] ^{p } \\\\ & = & v\\!i_{s}^{t}(1)+v\\!i_{s}^{t}(2 ) .",
    "\\notag\\end{aligned}\\]]we comment that we are able to dominate the averages on @xmath630 of the bad function @xmath514 by @xmath801 , since in this case @xmath802 , see , and this implies that the average of @xmath803 over the cube @xmath630 is dominated by @xmath804      we claim that @xmath806 in this display , the sum on the right is over all pairs of integers @xmath807 such that @xmath808 , for some @xmath809 , with @xmath810 .",
    "( below , we will need a similar sum , with the condition @xmath811 replaced by @xmath812 and @xmath813 . )",
    "this is a provisional bound , one that requires additional combinatorial assertations in  [ combinatorics ] to control .",
    "the term @xmath814 can be handled the same way as the term @xmath815 , see , with these two changes .",
    "first , in the definition of @xmath816 , we replace @xmath817 by @xmath818 , and second , we use the function @xmath819 in .",
    "that argument then obtains @xmath820here we are using the bounded overlap of the cubes @xmath630 given in claim [ bounded triples ] , along with the fact recorded in ( [ record ] ) that for fixed @xmath731 , only a bounded number of @xmath122 satisfy @xmath723 .",
    "claim [ bounded triples ] applies in this setting , as we are in a subcase of the analysis of @xmath821 .",
    "we then use the universal maximal function bound .",
    "@xmath822 ^{p } \\\\ &",
    "= & c\\sum_{(k , j)\\in \\mathbb{i}_{s}^{\\alpha , t}}r_{j}^{k}\\bigl\\lvert% \\int_{q_{j}^{k}}(\\mathbf{p}_{j}^{k})^{\\ast } ( h\\sigma ) \\;\\omega \\bigr\\rvert% ^{p } \\\\ & \\leq & c\\int \\bigl[\\mathcal{m}_{\\omega } \\bigl(\\chi _ { g_{s}^{\\alpha , t}}\\sum_{(k , j)\\in \\mathbb{i}_{s}^{\\alpha , t}}(\\mathbf{p}_{j}^{k})^{\\ast } ( \\chi _ { g_{s}^{\\alpha , t}}h\\sigma ) \\bigr)\\bigr]^{p}\\;\\omega \\\\ & \\leq & c\\int \\left [ \\chi _ { g_{s}^{\\alpha , t}}\\sum_{(k , j)\\in \\mathbb{i}% _ { s}^{\\alpha , t}}(\\mathbf{p}_{j}^{k})^{\\ast } ( \\chi _ { g_{s}^{\\alpha , t}}h\\sigma ) \\right ] ^{p}\\;\\omega\\end{aligned}\\ ] ] in view of , this completes the proof of the provisional estimate .",
    "recall the definition of @xmath824 from , and also from that @xmath798 whenever @xmath825 .",
    "we claim that @xmath826 the notation here is as in , but since @xmath827 implies @xmath828 belong to @xmath829 , the sum over the right is over @xmath830 such that @xmath831 , for some integers @xmath832 , with @xmath810 . as with , this is a provisional estimate .",
    "we first estimate the sum in @xmath627 inside term @xmath833 .",
    "recall that the sum in @xmath627 is over those @xmath627 such that @xmath834 for some @xmath271 with @xmath835 , and where @xmath836 is the set of maximal cubes in the collection @xmath837 .",
    "see the discussion at , and .",
    "we will write @xmath838 when @xmath839 .",
    "it is also important to note that the sum in @xmath627 deriving from term @xmath572 is also restricted to those @xmath627 such that @xmath798 by , so that altogether , @xmath840 . we have @xmath841   \\mathsf{a}_{i}^{k+2}\\right\\vert ^{p } \\\\ & & \\qquad \\leq \\sum_{i}\\left\\vert b_{i}^{k+2}\\right\\vert _ { \\sigma } ( \\mathsf{a}% _ { i}^{k+2})^{p}\\left [ \\sum_{i}\\left\\vert b_{i}^{k+2}\\right\\vert _ { \\sigma } ^{1-p^{\\prime } } \\left [ \\int_{b_{i}^{k+2}}\\left\\vert l^{\\ast } \\chi _ { e_{j}^{k}\\cap t_{\\ell \\left ( i\\right ) } } \\omega \\right\\vert \\sigma \\right ] ^{p^{\\prime } } \\right ] ^{p-1 } \\\\ & & \\qquad \\leq \\sum_{i}\\left\\vert b_{i}^{k+2}\\right\\vert _ { \\sigma } ( \\mathsf{a}% _ { i}^{k+2})^{p}\\left [ \\sum_{i}\\int_{b_{i}^{k+2}}\\left\\vert l^{\\ast } \\chi _ { e_{j}^{k}\\cap t_{\\ell \\left ( i\\right ) } } \\omega \\right\\vert ^{p^{\\prime } } \\sigma \\right ] ^{p-1 } \\\\ & & \\qquad \\leq c\\sum_{i}\\left\\vert b_{i}^{k+2}\\right\\vert _ { \\sigma } ( \\mathsf{a}_{i}^{k+2})^{p}\\left [ \\sum_{\\ell } \\sum_{i:\\ell \\left ( i\\right ) = \\ell } \\int_{b_{i}^{k+2}}\\left\\vert l^{\\ast } \\chi _ { e_{j}^{k}\\cap t_{\\ell \\left ( i\\right ) } } \\omega \\right\\vert ^{p^{\\prime } } \\sigma \\right ] ^{p-1}.\\end{aligned}\\]]now we will apply the form of ( [ tsharpomega ] ) with @xmath842 and @xmath13 chosen to be either @xmath588 or @xmath727 depending on the relative positions of @xmath588 and @xmath611 . since @xmath588 is",
    "a triple of a cube in the grid @xmath194 and @xmath611 is a cube in the grid @xmath194 , we must have either@xmath843if @xmath844 we choose @xmath13 in to be @xmath611 and note that  by bounded overlap of whitney cubes , there are only a bounded number of such cases . if on the other hand @xmath845 , then we choose @xmath13 to be @xmath846 and note that the cubes @xmath588 have bounded overlap .",
    "this gives@xmath847and hence@xmath848   \\mathsf{a}_{i}^{k+2}\\right\\vert ^{p}\\leq c\\mathfrak{t}_{\\ast } ^{p}\\sum_{i}\\left\\vert b_{i}^{k+2}\\right\\vert _ { \\sigma } ( \\mathsf{a}% _ { i}^{k+2})^{p}\\left\\vert nq_{j}^{k}\\right\\vert _ { \\omega } ^{p-1},\\]]since @xmath849 by ( [ qtilda contained ] ) . with this",
    "we obtain,@xmath850where we are using @xmath851 and ( [ record ] ) in the final line .",
    "we will use the same method as in the estimate for term @xmath852 above to obtain @xmath853recall from , that @xmath854 is given by @xmath855 c_{i}^{k+2}\\left ( \\left\\vert a_{r}^{\\alpha , t+1}\\right\\vert + \\mathsf{a}% _ { i}^{k+2}\\right ) \\right\\vert ^{p}.   \\notag\\]]the main difference here , as opposed to the previous estimate , is that @xmath856 rather than in @xmath857 , see . as a result",
    ", we have the estimate@xmath858instead of @xmath859 , which holds when @xmath860 .",
    "we follow the argument leading up to and including ( [ e.vi .",
    "] ) in the estimate for term @xmath861 above , but using instead ( [ new estimate ] ) .",
    "the result is as below , where we are using the notation of , with the condition @xmath811 replaced by @xmath812 and @xmath813 , and so we use an asterix and @xmath862 in the notation below . @xmath863now",
    "we collect those cubes @xmath630 that lie in a given cube @xmath520 and write the right hand side above as a constant times @xmath864by claim [ bounded triples ] , which applies as we are in a subcase of @xmath821 , we have @xmath865 , and it follows that@xmath866and hence from ( [ e.mgst ] ) that@xmath867      our final estimate in the proof of is to dominate by @xmath868 the sum of the right hand sides of ( [ e.vi2 < ] ) and over @xmath869 , namely @xmath870the proof of will require combinatorial facts related to the principal cubes , and the definition of the collection @xmath648 in . also essential",
    "is the implementation of the shifted dyadic grids .",
    "we now detail the arguments .",
    "[ type]we say that a cube @xmath630 satisfying the defining condition in @xmath871 , namely @xmath872is a _ final type _ cube for the pair @xmath497 generated from @xmath220 .    the collection of cubes @xmath873satisfies the following three properties :    property 1 : :    @xmath874 is a nested grid in the sense that given    any two _ distinct _ cubes in @xmath874 , either one is    strictly contained in the other , or they are disjoint ( ignoring    boundaries ) .",
    "property 2 : :    if @xmath630 and    @xmath875 are two _ distinct _ cubes    in @xmath876 with    @xmath877 , and @xmath878 have    the same parity ,    then@xmath879 property 3 : :    a given cube @xmath630 can occur at most a bounded    number of times in the grid @xmath876 .",
    "property 1 is obvious from the properties of the dyadic shifted grid @xmath198 .",
    "property 3 follows from the ` bounded occurrence of cubes ' noted above .",
    "so we turn to property 2 .",
    "it is this property that prompted the use of the shifted dyadic grids .",
    "indeed , since @xmath880 , it follows from the nested property that @xmath881 . by definition [ type ] there are cubes @xmath882 and @xmath749 satisfying@xmath883and also cubes @xmath884 such that @xmath885 and @xmath535 with @xmath886 , so that in particular,@xmath887now @xmath888 and in the extreme case where @xmath889 , it follows that the @xmath194-cube @xmath890 is one of the cubes @xmath891 , so in fact it must be @xmath630 since @xmath892 .",
    "thus we have@xmath893 in the general case @xmath888 we have instead@xmath894    now @xmath895 by definition [ type ] , and so there is @xmath896 determined by the condition@xmath897and also @xmath898 such that@xmath899where the label @xmath900 need not be principal . combining inclusions we have@xmath901and since @xmath902 , we obtain @xmath903 .",
    "since @xmath904 is a principal label , we have the key property that@xmath905indeed , if @xmath906 then holds because @xmath907 is a principal label , and otherwise the maximality of @xmath908 shows that@xmath909thus using and we obtain@xmath910which is property 2 .",
    "now for @xmath911 set @xmath912    with the above three properties we can now prove as follows . recall that in term @xmath913 we have @xmath719 which implies @xmath630 satisfies case ( b ) . in the display below by @xmath914 we mean the sum over @xmath627 such that @xmath636 is contained in some @xmath915 , and also in some @xmath611 with @xmath741 , and satisfying @xmath916 .",
    "the left side of is dominated by @xmath917 ^{p } \\\\ & = & \\int_{\\mathbb{r}^{n}}\\sum_{q\\in \\mathcal{f}}\\chi _ { q}\\left ( x\\right ) % \\left [ \\frac{1}{\\left\\vert q\\right\\vert _ { \\sigma } } \\int_{q}\\left\\vert f\\right\\vert \\sigma \\right ] ^{p}d\\sigma ( x ) \\\\ & \\leq & c\\int_{\\mathbb{r}^{n}}\\sup_{x\\in q : q\\in \\mathcal{f}}\\left [ \\frac{1}{% \\left\\vert q\\right\\vert _ { \\sigma } } \\int_{q}\\left\\vert f\\right\\vert \\sigma % \\right ] ^{p}d\\sigma ( x ) \\\\ & \\leq & c\\int_{\\mathbb{r}^{n}}\\mathcal{m}_{\\sigma } ^{\\alpha } f\\left ( x\\right ) ^{p}\\sigma ( dx)\\leq c\\int_{\\mathbb{r}^{n}}\\left\\vert f\\left ( x\\right ) \\right\\vert ^{p}d\\sigma ( x),\\end{aligned}\\]]where the second to last line follows since for fixed @xmath125 , the sum @xmath918 ^{p}\\]]is super - geometric by properties 1 , 2 and 3 above , i.e. for any two distinct cubes @xmath13 and @xmath270 in @xmath876  each containing @xmath50 , the ratio of the corresponding values is bounded away from @xmath158 , more precisely,@xmath919 ^{p}}{\\left [ \\frac{1}{\\left\\vert q^{\\prime } \\right\\vert _ { \\sigma } } \\int_{q^{\\prime } } \\left\\vert f\\right\\vert \\sigma % \\right ] ^{p}}\\notin \\lbrack { \\gamma ^{-p}},\\gamma ^{p}),\\ \\ \\ \\ \\",
    "\\gamma \\geq 2.\\]]this completes the proof of .",
    "to prove theorem [ improved ] we first show that in the proof of theorem [ twoweighthaar ] above , we can replace the use of the dual maximal function inequality with the dual weighted poisson inequality defined below .",
    "after that we will show that in the case of standard kernels satisfying ( [ sizeandsmoothness ] ) with @xmath920 in dimension @xmath79 , the dual weighted poisson inequality is implied by the _ half - strengthened _",
    "@xmath8 condition@xmath921for all intervals @xmath13 , together with the dual pivotal condition of nazarov , treil and volberg @xcite , namely that@xmath922holds for all decompositions of an interval @xmath275 into a union of pairwise disjoint intervals @xmath923 .",
    "we will assume @xmath924 for this latter implication . finally ,",
    "for @xmath15 , we show that ( [ poissonweightedineq ] ) is implied by , and the poisson condition .",
    "it follows from work in @xcite and @xcite that the strengthened @xmath925 condition is necessary for the two weight inequality for the hilbert transform , and also from @xcite that the dual pivotal condition is necessary for the dual testing condition@xmath926for",
    "@xmath28 when @xmath25 and @xmath0 is doubling .",
    "we show below that these results extend to @xmath20 .",
    "a slightly weaker result was known earlier from work of nazarov , treil and volberg - namely that the pivotal conditions are necessary for the hilbert transform @xmath927 when _ both _ of the weights are @xmath1 and @xmath0 are doubling and @xmath25 . however , in @xcite , an example is given to show that is _ not _ in general necessary for boundedness of the hilbert transform @xmath28 when @xmath168 .    finally , we show below that when @xmath0 is doubling , the dual weighted poisson inequality is implied by the two weight inequality for the hilbert transform . since the poisson condition ( poisson condition ) is a special case of the inequality dual to ( poissonweightedineq ) , we obtain the necessity of ( [ poisson condition ] ) for the two weight inequality for the hilbert transform .",
    "we begin working in @xmath19 with @xmath20 .",
    "recall the definition of the poisson integral @xmath928 of a measure @xmath183 relative to a cube @xmath13 given by,@xmath929we will consider here only the standard poisson integral with @xmath930 in , and so we also suppose that @xmath930 in above .",
    "we now fix a cube @xmath275 and a collection of pairwise disjoint subcubes @xmath931 . corresponding to these cubes we define a positive linear operator@xmath932    we wish to obtain _ sufficient _ conditions for the following ` dual ' weighted poisson inequality , @xmath933uniformly in @xmath275 and pairwise disjoint subcubes @xmath931 .",
    "as we will see below , this inequality is necessary for the two weight hilbert transform inequality when @xmath0 is doubling .",
    "the reason for wanting the dual poisson inequality ( poissonweightedineq ) is that in theorem [ twoweighthaar ] above , we can replace the assumption on dual boundedness of the maximal operator @xmath51 by the dual poisson inequality ( poissonweightedineq ) .",
    "indeed , this will be revealed by simple modifications of the proof of theorem [ twoweighthaar ] above .",
    "in fact ( [ poissonweightedineq ] ) can replace in estimating term @xmath787 , as well as in the similar estimates for terms @xmath815 and @xmath814 .",
    "we turn now to the proofs of these assertions before addressing the question of sufficient conditions for the dual poisson inequality .",
    "we begin by demonstrating that the term @xmath787 in can be handled using the ` dual ' poisson inequality ( poissonweightedineq ) in place of the maximal inequality ( m2weightdual ) .",
    "we are working here in @xmath19 with @xmath20 .",
    "in fact we claim that@xmath934where @xmath935 is the norm of the dual poisson inequality ( poissonweightedineq ) if we take @xmath275 and its collection of pairwise disjoint subcubes @xmath936 to be @xmath937 and @xmath938 .",
    "now the maximal inequality was used in the proof of only in establishing , @xmath939where@xmath940we now note that@xmath941proves @xmath942which yields as before .",
    "the terms @xmath943 and @xmath944 are handled similarly . indeed , yields the following analogue of ( sum of pkj),@xmath945from which the arguments above yield both and with @xmath374 replaced by @xmath935 .",
    "we continue to work in @xmath19 with @xmath20 .",
    "we note that ( [ poissonweightedineq ] ) can be rewritten@xmath946and this latter inequality can then be expressed in terms of the poisson operator @xmath947 in the upper half space @xmath948 given by@xmath949indeed , let @xmath950 be the point in @xmath948 that lies above the center @xmath951 of @xmath952 at a height equal to the side length @xmath953 of @xmath952 .",
    "define an atomic measure @xmath954 in @xmath948 by@xmath955then is equivalent to the inequality ( this is where we use @xmath920),@xmath956    we can use theorem 2 in @xcite to characterize this latter inequality in terms of testing conditions over @xmath947 and its dual @xmath957 given by@xmath958let @xmath464 denote the cube in @xmath948 with @xmath13 as a face .",
    "theorem 2 in @xcite yields the following .",
    "[ pivandfat]let @xmath79 and suppose that @xmath0 is doubling .",
    "first assume that @xmath20 .",
    "then for the special measure @xmath959 in , inequality follows from the dual pivotal condition , the poisson condition , and the half - strengthened @xmath8 condition .",
    "now assume that @xmath924",
    ". then for the special measure @xmath959 in , ( [ upper ] ) follows from and without .",
    "[ poisson sufficiency]let @xmath79 and suppose that @xmath0 is doubling .",
    "first assume that @xmath20 .",
    "then the dual poisson inequality ( poissonweightedineq )  holds uniformly in @xmath275 and @xmath962 satisfying @xmath963 provided the half - strengthened @xmath8 condition ( ap half skirt ) , the dual pivotal condition , and the poisson condition all hold .",
    "now assume that @xmath4 .",
    "then  holds uniformly in @xmath964 and @xmath936 satisfying @xmath965 provided and both hold .          instead of applying theorem [ testing poisson ] directly , we first reduce matters to proving that certain @xmath194-dyadic analogues hold of the two conditions in theorem [ testing poisson ]",
    ". for @xmath966 we use the following atomic measures @xmath967 on @xmath968 , along with the following @xmath198-dyadic analogues of the poisson operators @xmath969 and @xmath947 ( with @xmath920),@xmath970where    1 .",
    "the interval @xmath971 is chosen to be a _ maximal _",
    "@xmath198-interval contained in @xmath952 with _ maximum _ length ( there can be at most two such intervals , in which case we choose the leftmost one ) , 2 .   the @xmath194-poisson integral @xmath972 is given by@xmath973where @xmath974 denotes the @xmath172 dyadic parent of @xmath975 in @xmath194 , 3 .",
    "the point @xmath976 in @xmath968 lies above the center @xmath977 of @xmath971 at a height equal to the side length @xmath978 of @xmath971 .",
    "we claim that for any positive measure @xmath183 , the collection of shifted dyadic grids @xmath981 satisfies@xmath982for all @xmath271 . indeed , for each interval @xmath983 , there is @xmath984 and an interval @xmath985 containing @xmath983 whose length is comparable to that of @xmath983 .",
    "thus @xmath986 for some universal positive integer @xmath398 .",
    "now@xmath987since @xmath0 is _ doubling _ and @xmath971 is a maximal @xmath198-interval in @xmath952 with maximum length , we thus have @xmath988 and@xmath989this together with theorem [ testing poisson dyadic ]  reduces the proof of claim [ pivandfat ] to showing that holds for all @xmath990 .    now",
    "the definition of @xmath991 in shows that the left side of the first line in is@xmath992recall that @xmath993 .",
    "now if @xmath994 for some @xmath271 , then the above sum consists of just one term that satisfies@xmath995otherwise we have@xmath996where the local term has been estimated by the dual pivotal condition ( dual pivotal condition ) applied to @xmath13 .",
    "now if @xmath997 , then @xmath998 only if @xmath999",
    ". thus the second term on the right can be estimated by@xmath1000where we have used@xmath1001and the half - strengthened @xmath8 condition in the final inequality .",
    "now we turn to showing that the second line in holds using only the @xmath8 condition .",
    "first we compute the dual operator @xmath1002 .",
    "since the kernel of @xmath1003 is@xmath1004 \\equiv \\sum_{i\\in \\mathcal{d}^{\\alpha } : \\ell \\left ( i\\right ) \\geq t}\\chi _ { i}\\left ( x\\right ) \\frac{t}{\\ell \\left ( i\\right ) } \\frac{1}{\\left\\vert i\\right\\vert } % \\chi _ { i}\\left ( y\\right ) , \\]]we have for any positive measure @xmath1005 on the upper half space @xmath968,@xmath1006using the third line in we compute that@xmath1007and@xmath1008    thus we must prove@xmath1009but this is the poisson condition in theorem improved for the shifted dyadic grid @xmath194 .",
    "this completes the proof of the first assertion in claim [ pivandfat ] regarding the case @xmath20 .",
    "we now assume that @xmath4 for the remainder of the proof .",
    "note that for @xmath1013 and @xmath1014 , @xmath1015is decreasing on @xmath1016 since@xmath1017since @xmath1018 we have @xmath1019 for @xmath1020 , i.e.@xmath1021now fix an interval @xmath13 in and arrange the intervals @xmath1022 that are contained in @xmath13 into a sequence @xmath1023 in which the lengths @xmath1024 are increasing ( we may suppose without loss of generality that @xmath210 is finite ) .",
    "recall we are now assuming @xmath4 .",
    "integrate by parts and apply ( [ ineq ] ) to estimate the left side of by@xmath1025where we have used with @xmath1026 and @xmath1027 , and then used @xmath1028 for @xmath1029 , which follows from @xmath1030 and @xmath1031 . if @xmath1032 and @xmath1029 , then @xmath1033 and so @xmath1034        here we consider the two weight hilbert transform inequality for @xmath1036 .",
    "we show the necessity of the strengthened @xmath8 condition for general weights , as well as the necessity of the dual pivotal condition for the dual testing condition , and the dual poisson inequality for the dual hilbert transform inequality , when @xmath0 is doubling .      here",
    "we derive a necessary condition for the weighted inequality ( 2weight ) but with the hilbert transform @xmath28 in place of @xmath21,@xmath1037that is stronger than the two weight @xmath8 condition , namely the _ strengthened _ @xmath8 condition@xmath1038for all intervals @xmath13 .",
    "preliminary results in this direction were obtained by muckenhoupt and wheeden , and in the setting of fractional integrals by gabidzashvili and kokilashvili , and here we follow the argument proving ( 1.9 ) in sawyer and wheeden @xcite , where ` two - tailed ' inequalities of the type originated in the fractional integral setting . a somewhat different approach to this for the conjugate operator in the disk when @xmath25 uses conformal invariance and appears in @xcite , and provides the first instance of a strengthened @xmath1039 condition being proved necessary for a two weight inequality for a singular integral .",
    "fix an interval @xmath13 and for @xmath1040 and @xmath321 let @xmath1041where @xmath1042 is the center of the interval @xmath13 . for convenience",
    "we assume that neither @xmath1 nor @xmath0 have any point masses - see lasaur for the modifications necessary when point masses are present .",
    "for @xmath1043 we have@xmath1044and so@xmath1045thus for @xmath1046 we obtain that@xmath1047and hence by for the hilbert transform @xmath927,@xmath1048      [ [ necessity - of - the - dual - pivotal - condition - and - the - dual - poisson - inequality - for - a - doubling - measure ] ] necessity of the dual pivotal condition and the dual poisson inequality for a doubling measure ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    here we show first that if @xmath0 is a _ doubling _ measure , then the dual pivotal condition with @xmath930 is implied by the @xmath8 condition and the dual testing condition for the hilbert transform @xmath927,@xmath1057after this we show that the dual poisson inequality ( poissonweightedineq ) is implied by the @xmath8 condition and the dual hilbert transform inequality,@xmath1058      * proof * : we begin by proving that for any interval @xmath170 and any positive measure @xmath183 supported in @xmath1060 , we have@xmath1061where we here redefine@xmath1062with @xmath1063 the center of @xmath170 .",
    "note that this definition of @xmath1064 is comparable to that in with @xmath1065 .",
    "note also that @xmath1066 is defined by on @xmath170 , and increasing on @xmath170 when @xmath183 is positive , so that the infimum in is nonnegative .    to see , we suppose without loss of generality that @xmath1067 , and a calculation then shows that for @xmath1068,@xmath1069since @xmath1070 is positive and satisfies@xmath1071on each interval @xmath1072 and @xmath1073 in @xmath1060 when @xmath1074 .",
    "thus we have from ( redef),@xmath1075    now we return to the dual pivotal condition , and let @xmath1076 be the best constant in the dual testing condition for @xmath927 .",
    "let @xmath1077 be a pairwise disjoint decomposition of @xmath275 and consider @xmath1078 which will be chosen at the end of the proof ( we will take @xmath1079 and @xmath1080 very small ) .",
    "for each interval @xmath952 let @xmath1081 minimize @xmath1082 on @xmath952 , i.e.@xmath1083and set@xmath1084now for each interval @xmath952 , consider the following three mutually exclusive and exhaustive cases :      if @xmath952 is a case # 1 interval we have @xmath1089 and so@xmath1090if @xmath952 is a case # 2 or case # 3 interval we have from with @xmath1091 that for all @xmath1092 , @xmath1093if now @xmath952 is a case # 2 interval we also have @xmath1094 and so@xmath1095where the final inequality follows from with @xmath1096 and then @xmath1097 .",
    "now we use our assumption that @xmath0  is doubling .",
    "there are @xmath1098 such that@xmath1099whenever @xmath1100 is a subinterval of an interval @xmath13 .",
    "if @xmath952 is a case # 3 interval we have both@xmath1101which altogether yields@xmath1102which is a contradiction if @xmath1079 and @xmath1080 is chosen sufficiently small , @xmath1103 . with this choice ,",
    "there are no case # 3 intervals , and so we are done .      * proof * : the proof is virtually identical to that of lemma [ doub piv ] but with @xmath1104 in place of @xmath1105 where @xmath1106 . indeed ,",
    "if @xmath952 is a case # 1 interval we then have @xmath1107 and so@xmath1108if @xmath952 is a case # 2 interval , then @xmath1109 and@xmath1110upon using with @xmath275 and @xmath952 , which is ( poissonweightedineq ) . as before ,",
    "case # 3 intervals do nt exist if @xmath3 is doubling and @xmath1080 is sufficiently small .",
    "theorem [ poisson sufficiency ] shows that the dual poisson inequality ( [ poissonweightedineq ] )  holds uniformly in @xmath275 and pairwise disjoint @xmath936 satisfying @xmath965 , provided both the half - strengthened @xmath8 condition and the dual pivotal condition hold when @xmath4 - and provided , and the poisson condition hold when @xmath15 .",
    "since @xmath0 is doubling , lemma [ doub piv ] shows that the dual pivotal condition ( dual pivotal condition ) follows from the dual testing condition - and lemma [ doub ineq ] shows that the dual poisson inequality , hence also the poisson condition , follows from the dual hilbert transform inequality .",
    "thus theorem [ improved ] now follows from the claim proved in subsubsection [ suff p ] that ( poissonweightedineq ) can be substituted for in the proof of theorem [ twoweighthaar ] .",
    "99 m. cotlar and c. sadosky , _ on the helson - szeg theorem and a related class of modified toeplitz kernels , _ harmonic analysis in euclidean spaces , part 1 ( proc .",
    "pure math .",
    "xxxv , williams coll . ,",
    "williamstown , mass . , 1978 ) , mr\\{545279 ( 81j:42022)}.      d. cruz - uribe , j. m. martell and c. prez , _ sharp two weight inequalities for singular integrals , with applications to the hilbert transform and the sarason conjecture , _ adv .",
    "* 216 * ( 2007 ) , 647676 , mr\\{2351373}.                      f. peherstorfer , a. volberg and p.yuditskii , _ two weight hilbert transform and lipschitz property of jacobi matrices associated to hyperbolic polynomials , _",
    "* 246 * ( 2007 ) , 130 , mr\\{2316875}."
  ],
  "abstract_text": [
    "<S> let @xmath0 and @xmath1 be positive borel measures on @xmath2 with @xmath3 doubling . </S>",
    "<S> suppose first that @xmath4 . </S>",
    "<S> we characterize boundedness of certain maximal truncations of the hilbert transform @xmath5 from @xmath6 to @xmath7 in terms of the strengthened @xmath8 condition@xmath9@xmath10 , and two testing conditions . </S>",
    "<S> the first applies to a restricted class of functions and is a strong - type testing condition , @xmath11and the second is a weak - type or dual interval testing condition , @xmath12for all intervals @xmath13 in @xmath2 and all functions @xmath14 . in the case </S>",
    "<S> @xmath15 the same result holds if we include an additional necessary condition , the poisson condition@xmath16for all pairwise disjoint decompositions @xmath17 of the dyadic interval @xmath13 into dyadic intervals @xmath18 . </S>",
    "<S> we prove that analogues of these conditions are sufficient for boundedness of certain maximal singular integrals in @xmath19 when @xmath0 is doubling and @xmath20 . </S>",
    "<S> finally , we characterize the weak - type two weight inequality for certain maximal singular integrals @xmath21 in @xmath22  when @xmath20 , without the doubling assumption on @xmath3 , in terms of analogues of the second testing condition and the @xmath23 condition . </S>"
  ]
}