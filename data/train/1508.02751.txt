{
  "article_text": [
    "the jagiellonian - pet ( j - pet ) collaboration is developing a prototype tof - pet detector based on plastic scintillators  @xcite .",
    "the detector is a cylinder made of long scintillator strips .",
    "its large acceptance allows for full 3-d image reconstruction .",
    "the main advantage of the j - pet solution is its excellent time resolution ( see e.g. results in  @xcite ) , which makes it suitable not only for medical purposes , but also for precise studies of the discrete symmetries in positronium systems  @xcite .",
    "the tof - pet data processing and reconstruction are time- and resource - demanding operations , especially in case of a large acceptance j - pet detector , which works in the so - called trigerless mode , in which all events ( digitized time and amplitudes ) from the front - end electronics ( fee ) are stored to disks without any master trigger condition applied  @xcite .",
    "next , the collected raw data undergoes a process of low- and high- level reconstructions .",
    "the registered data is first transformed into the hit positions in the scintillator modules , and in the next step the hits are combined to form the lines of response(lor ) . in the last stage ,",
    "the image reconstruction procedures are used to obtain the final image based on the set of lors . in order to efficiently process this high data stream ,",
    "parallel computing techniques have been applied at several levels of the data collection and reconstruction .",
    "the parallel processing can be defined as a type of computation in which the task is divided into independent subtasks , which are then calculated simultaneously , by several computing resources .",
    "the results of the individual computations are merged together .",
    "parallelization techniques can be classified according to several criteria , e.g. instruction - level parallelization corresponds to the simultaneous performance of several operations in the computer program . in the case of the data parallelization",
    ", the data set is distributed among many computing nodes , while in case of the task parallelization the code is divided into threads and executed across the computing nodes . typically , to take advantage of the parallelization",
    ", the software procedures must be designed in a special way , e.g. by using dedicated programming environments and libraries such as mpi  @xcite , openmp  @xcite or cuda  @xcite .",
    "overview of different parallelization techniques can be found in  @xcite . in the past parallel processing",
    "was the domain of high - performance computing by means of supercomputers .",
    "however , thanks to a very fast development of the overall performance of the cpus , to keeping the prices relatively low and the introduction of new techniques such as multi - core processors , the parallelization has become more accessible and popular in many different fields .",
    "apart from the cpu processing , recently , even more efficient technologies such as graphical processor units ( gpu ) or field programmable gate array ( fpga ) gained a lot of attention . in the j - pet project ,",
    "parallelization by using multi - core cpus , gpus and fpgas are used at different stages of data processing .",
    "fpga is a programmable silicon chip which combines two important features : on one hand , the fpga is reprogrammable , therefore any logic can be implemented and changed if needed in hardware description languages such as verilog or vhdl . on the other hand , the compiled program is translated to the set of physical connections between the logical arrays , therefore it is really the hardware realization of the designed logic with the functionality of the real - time speed processing , analogically to the one offered by the dedicated asic processors . finally fpga chips are perfect for the parallelization and very cost - effective .",
    "the fpga devices are the core computing nodes of the jpet fee and data acquisition system ( daq )  @xcite .",
    "the j - pet fee was designed in view of sampling in the voltage domain of very fast signals at many levels , with a raising time of about 1 ns  @xcite . a novel technique for precise measurement of time and charge",
    "is based solely on fpga devices and few satellite discrete electronic components .",
    "one computing board ( called trigger readout board ",
    "trb ) consists of five lattice ecp3 - 150 fpgas .",
    "four fpgas are used as time - to - digital converters and one as a central fpga node that steers the whole board .",
    "the multiple computing boards are interconnected via network concentrators .",
    "the global time synchronization is provided through a reference channel .",
    "the j - pet daq system allows for continuous data recording over the whole measurement period . in total , more than 500 channels with 1gb / s data rates can be read .",
    "the overall constant read - out rate is equal to 50 khz , while reducing the dead time to the level of tens of ns .",
    "the described triggerless mode of operation allows to store every event without information loss due to preliminary selection . on the other hand ,",
    "a significant amount of disk storage is needed ( about tb per measurement ) to save the data , whereas most of the currently registered events contain useless noise information only . in order to reduce the data flow and to eliminate background events a new central controller module ( ccm )",
    "is introduced as an intermediate computing node between the trb boards and the disk storage .",
    "the ccm is being developed based on xilinix zynq chip which contains fpga integrated with the arm processor .",
    "it is capable of hardware processing up to 16 gbit ethernet stream in parallel as well as online filtering of the data .",
    "moreover , it is even possible to implement some online reconstruction algorithms .",
    "finally , the online monitoring with a dedicated data substream will be added .",
    "the raw data stored on the disks , is processed in the j - pet framework , which serves as a programming environment which provides useful tools for various reconstruction algorithms , calibration procedures and which standardizes the common operations , e.g : input / output process and more .",
    "it also provides the necessary information about run conditions , geometry and electronic setups by communicating with the parameter database .",
    "the architecture of the analysis framework was already described in  @xcite . in this paragraph",
    "we will describe the important parts in the context of understanding framework parallelization . in the j - pet framework",
    ", the analysis chains are decomposed into series of standardized modular blocks .",
    "each module corresponds to a particular computing task , e.g. reconstruction algorithm or calibration procedure , with defined input and output methods .",
    "the processing chain is built by registering chosen modules in the jpetmanager , which is responsible for the synchronization of the data flow between the modules .",
    "the framework parallelization is implemented by using the proof  @xcite ( parallel root facility ) extension for the root library  @xcite .",
    "proof enables parallel file processing on cluster of computers or many core machines . in the case of the j - pet framework",
    "the multi - core processing was tested .",
    "two options are being developed .",
    "the first solution is a realization of data parallel computing .",
    "first , a set of chosen computing tasks , in the form of processing chain , is registered in the jpetmanager as described before .",
    "the same processing chain will be multiplied and executed in parallel for every input file provided .",
    "this approach assumes that the input files can be analyzed independently . in the second mode",
    ", a single processing chain can contain modules ( subtasks ) that can operate in parallel .",
    "this solution is currently being implemented .",
    "the final output of the low - level reconstruction phase is a reconstructed set of lors that is provided as the input data for the image reconstruction procedures .",
    "the most popular approach based on iterative algorithms derived from maximum likelihood estimation method ( mlem )  @xcite has been adopted .",
    "the available time - of - flight information is incorporated to improve the accuracy and the quality of the reconstruction . in order to reduce the processing time , parallelization techniques are applied . currently two implementations are used .",
    "the first solution exploits the processing capability of graphical processing units ( gpu ) .",
    "the efficient image reconstruction using list - mode mlem algorithm with approximation kernels was implemented for gpu  @xcite . here , the cuda platform was adopted .",
    "the second approach is a full 3-d reconstruction based on a multi - core cpu architecture  @xcite . in this case , the most time - consuming operations such as projection and back - projections are parallelized .",
    "the code is based on the openmp library . for the current test implementation ,",
    "the time of one mlem iteration , processed on 40 cores with 128 gb , is about 70 minutes , when using the large field - of - view ( 88 cm x 88 cm x 50 cm ) with a binning of 0.5 cm and 1 degree .",
    "typically about 10 iterations are enough to reach mlem optimal reconstruction point .",
    "in order to reduce the processing time of the data flow , we use the parallel computing approach on several stages .",
    "we presented the implemented solution in the ffe and daq level based on the fpga chips .",
    "also , the multi - core cpu - based and gpu - based algorithms are used for the low - level and high - level reconstructions .",
    "currently , works are ongoing to further reduce the processing time , e.g. by implementing the online event filters . apart from the presented computing schemes , in which the data processing is performed locally , several remote processing concepts are considered as a replacement to the traditional in - site computing .",
    "the basic idea is to carry outs the resource - heavy computations remotely by using cloud or grid - computing  @xcite .",
    "we acknowledge technical and administrative support by t. gucwa - ry , a. heczko , m. kajetanowicz , g. konopka - cupia , w. migda , and the financial support by the polish national center for development and research through grant no .",
    "innotech - k1/in1/64/159174/ncbr/12 , the foundation for polish science through mpd programme and the eu , mshe grant no .",
    "poig.02.03.00 - 161 00 - 013/09 and doctus  the malopolska phd scholarship fund .",
    "p. moskal et al . , patent applications : pct / pl2010/00062 , pct / pl2010/00061 ( 2010 ) p. moskal et al . , bio - algorithms and med - systems 7 ( 2011 ) 73 ; [ arxiv:1305.5187 [ physics.med-ph ] ] p. moskal et al",
    ". , nuclear instruments and methods in physics research section a 764 ( 2014 ) 317 ; [ arxiv:1407.7395 [ physics.ins-det ] ] .",
    "l. raczyski et al . , nuclear instruments and methods in physics research section a 764 ( 2014 ) 186 ; [ arxiv:1407.8293 [ physics.ins-det ] ] .",
    "p. moskal et al .",
    ", nuclear instruments and methods in physics research section a 775 ( 2015 ) 54 ; [ arxiv:1412.6963 [ physics.ins-det ] ] .",
    "a. wieczorek a. et al . , ( 2015 ) , acta phys .",
    "a127 1487 - 1490 ( 2015 ) ; arxiv:1502.02901 [ physics.ins-det ] moskal p. et al .",
    ", acta phys . pol .",
    "a127 1495 - 1499 ( 2015 ) ; arxiv:1502.07886 [ physics.ins-det ] p. kowalski et al .",
    ", acta phys . pol .",
    "a127 1505 - 1512 ( 2015 ) ;",
    "arxiv:1502.04532 [ physics.ins-det ] d. kamiska et al . ,",
    "nukleonika ( 2015 ) , this issue .",
    "m. paka et al . ,",
    "bio - algorithms and med - systems 10 ( 2014 ) 41 ; [ arxiv:1311.6127 [ physics.ins-det ] ] .",
    "w. krzemien et al . , acta phys .",
    "polonica a vol .",
    "127 , no . 5 ( 2015 ) .",
    "arxiv:1503.00465 [ physics.ins-det ] w. krzemien et al . , bio - algorithms and med - systems vol .",
    "1 , ( 2014 ) 27 ; arxiv:1311.6153 [ physics.ins-det ] r. brun , f. rademakers nuclear instruments and methods in physics research section a 389 ( 1997 ) ."
  ],
  "abstract_text": [
    "<S> the jagiellonian - pet ( j - pet ) collaboration is developing a prototype tof - pet detector based on long polymer scintillators . </S>",
    "<S> this novel approach exploits the excellent time properties of the plastic scintillators , which permit very precise time measurements . </S>",
    "<S> the very fast , fpga - based front - end electronics and the data acquisition system , as well as , low- and high - level reconstruction algorithms were specially developed to be used with the j - pet scanner . </S>",
    "<S> the tof - pet data processing and reconstruction are time and resource demanding operations , especially in case of a large acceptance detector , which works in triggerless data acquisition mode . in this article </S>",
    "<S> , we discuss the parallel computing methods applied to optimize the data processing for the j - pet detector . </S>",
    "<S> we begin with general concepts of parallel computing and then we discuss several applications of those techniques in the j - pet data processing    ` daq ` , ` computing ` , ` tof - pet ` </S>"
  ]
}