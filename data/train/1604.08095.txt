{
  "article_text": [
    "improving speech recognition for accented speakers is becoming increasingly more important as businesses become more international .",
    "however , handling calls with accents is still a major challenge for companies specializing in speech recognition support services .",
    "it requires an accurate and efficient accent classification algorithm , which can identify the accent of the call during a short amount of time , after which , an accent - adapted speech recognition engine can be employed to better recognize accented speech .",
    "accent classification recently gains more interests , probably due to the increasing demands for better speaker recognition with accented speech .",
    "recently , choueiter et al . achieved 32% classification rate on 23-way classification of accented english @xcite , using methods such as maximum mutual information ( mmi ) training and gaussian tokenization .",
    "omar et al . used support vector machine ( svm ) classifier integrated with universal background model ( ubm ) and claimed they outperformed the results in @xcite by 75.3% relatively @xcite .",
    "another work in @xcite reported classification rates of 73% and 58.9% for german vs. spanish classification using gaussian mixture models ( gmms ) and naive bayes classification respectively .",
    "in addition , classification rates of 36.2% , 17.7% and 13.2% were reported for 4- , 13- and 23-way classification using naive bayes . to the best of our knowledge , these are the only three works , which used the same dataset as we used in this work .    in this paper , a baseline accent classifier",
    "is created using gmms with purely acoustic features , such as perceptual linear predictive ( plp ) , which were then discriminatively optimized by heteroscedastic linear discriminant analysis ( hlda ) . based on the fact that most of accents are presented from the pronunciation of vowels rather than consonants , for each type of accents ,",
    "various gmms are computed using the same plp - hlda features for the vowels extracted from speech .",
    "then , these gmms are combined to form a single gmm . with the partial transcription of the database for 7 major types of accents , which is absent in @xcite and @xcite ,",
    "the vowels are extracted and with these phonetic information , the classification rate of 7-way classification is improved from 46% to 51% , compared with the baseline .",
    "this work was initiated during the first author s internship at interactive intelligence @xcite .",
    "the algorithm and experiment was later refined for better accuracy and efficiency .",
    "the following sections are organized as follows : sec .",
    "[ sec : data ] introduces the database and features used here ; the main concept of creating accent - adapted features based on vowel representation is illustrated in sec .",
    "[ sec : vowel_representation ] ; in sec .",
    "[ sec : baseline ] and [ sec : improved ] , the implementation and results for the baseline gmm - hlda classier and the improved accent classifier with vowel extraction and representation are described in details , followed by the summary and future work in sec . [ sec : conclusion ] .",
    "the database used here for developing accent classifiers is foreign accented english ( fae ) corpus .",
    "it was originally collected by the center of speech & language understanding ( cslu ) at oregon health & science university ( ohsu ) .",
    "it contains 4925 sentences about 20 seconds long each , from speakers with 23 types of accents .",
    "we group them into 7 regional accents and one type of accents in each group was selected for developing a 7-way accent classifier , including arabic ( ar ) , brazilian portuguese ( br ) , french ( fr ) , german ( ge ) , hindi ( hi ) , mandarin ( ma ) and russian ( ru ) . tab .",
    "[ tab : fae_summary ] provides a summary of these accents with the number of utterances in each type and their proportion of the entire fae corpus . in order to perform phoneme alignment which is necessary to extract features with phonetic information",
    ", we also transcribed the audio data of these 7 major accents , which is originally absent in the ldc s release .",
    "@ cccccc @ accents & no . of & proportion & total & total & comp .",
    "+ ( abbr . ) & utterances & ( % ) & duration@xmath0 & duration@xmath1 & rate ( % ) + ar & 112 & 2.27 & 0:34:32 & 0:29:11 & 84.5 + bp & 459 & 9.32 & 2:34:24 & 2:09:58 & 84.2 + fr & 284 & 5.77 & 1:31:05 & 1:18:44 & 86.4 + ge & 325 & 6.6 & 1:36:04 & 1:22:18 & 85.7 + hi & 348 & 7.07 & 1:56:10 & 1:36:31 & 83.1 + ma & 282 & 5.73 & 1:30:37 & 1:16:06 & 84.0 + ru & 236 & 4.79 & 1:11:13 & 0:59:54 & 84.1 +    data from these accents were then preprocessed with silence removal by thresholding on its short - time energy rate and spectral centroids , using method in @xcite .",
    "given the audio samples @xmath2 $ ] in the @xmath3 frame , its short - time energy rate , denoted as @xmath4 , can be formulated as @xmath5 where @xmath6 is the number of samples in one frame .",
    "the spectral centroid can be defined as @xmath7 where @xmath8 $ ] is the discrete fourier transform ( dft ) coefficients of @xmath9 .",
    "the short - time energy rate is the most useful feature to discriminate silence with environmental noise from speech , and the spectral centroids can be used to remove non - speech noise , such as coughing , due to its lower energy concentration in the spectrum , ralative to that of regular human speech .    ,",
    "width=264,height=170 ]    fig .",
    "[ fig : silence_removal_example ] demonstrates the silence removal using both measurements on file far00042.wav in fae corpus with arabic accents .",
    "the portion of speech is considered to be silence when either the smoothed short - time energy rate and the smoothed spectral centroids are below certain thresholds . tab .",
    "[ tab : fae_summary ] shows the total durations before and after silence removal and their corresponding compression rate .",
    "the silence - removed data of the selected accents were then converted to 39-dimensional plp features @xcite .",
    "feature mean and variance normalization ( mvn ) were applied afterwards .",
    "they were randomly divided into training , development and testing with ratio @xmath10 .",
    "inspired by the work from minematsu et al .",
    "@xcite and suzuki et al .",
    "@xcite , where they measured the overall structure of the speaker s phonetic space , one type of accent - adapted features can be obtained by extracting vowels from speech and use them to identify accents . for each type of accented version of a target language , such as english , as well as the standard one , it is assumed that the features of the five fundamental vowels are located relatively constantly in the feature space . in fig .",
    "[ fig:5vowels ] , the first two feature dimensions are taken to illustrate the position of five vowels in accented and non - accented ( standard ) languages @xcite . the center in each pentagon is the weighted average of five vowels based on their positions in feature space and frequency of appearance in the corpus . by matching the center of the pentagon of the standard and the accented language into the overlapped pentagon in the bottom of fig .",
    "[ fig:5vowels ] , the bhattacharyya distances @xcite between each pair of corresponding vowels and their angles can be computed and stored in a vector .",
    "this vector @xmath11 represents the difference from the accented language @xmath12 to the standard one @xmath13 . to classify the test speech into one of the accent categories @xmath14 , where @xmath6 is the number of accents , the difference from @xmath15 to @xmath16 $ ] and @xmath17 ( category of the standard language ) are computed and classified to the nearest category of accent .    ]",
    "as mentioned in sec . [ sec : introduction ] , the baseline accent classification system is implemented using gmm classifier with plp feature discriminatively optimized by hlda , which is a generalization of lda allowing features to have different variances in different feature dimensions . here",
    "we briefly describe the key components of gmm , lda and hlda , then discuss the implementation and results of the baseline .",
    "motivated by the method of modeling attributes of speakers using gaussian mixture models ( gmms ) in @xcite , here we use gmms to model the attributes of accents .",
    "gaussian mixture density models the feature distribution of each accent as a weighted sum of multiple gaussian distributions . given row feature vector @xmath18 in @xmath19 feature matrix @xmath20 , where @xmath21 is feature dimension and @xmath22 is the number of feature vectors , in the probability of @xmath18 can be formulated as @xmath23 where @xmath6 is the number of mixture components , and @xmath24 @xmath25 , @xmath26 , are the component densities , @xmath27 are the mixture weight for @xmath28 mixture , and @xmath29 } is the collective representation of the parameters .",
    "given feature matrix @xmath20 of accent type @xmath30 , maximum likelihood estimation ( mle ) is used to maximize the gmm likelihood , which can be written as @xmath31 since this expression is non - linear and direct maximization is difficult , the parameter set @xmath32 is iteratively estimated using a special case of the expectation - maximization ( em ) algorithm and is summarized below : @xmath33 where @xmath34 , @xmath35 are the mixture weights , means , and variances for the @xmath36th component ; @xmath37 is the _ a posteriori _",
    "probability for the @xmath36-th component given by @xmath38 these estimates are based on the assumption of independence among feature dimension , so for each accent type @xmath30 , the non - zero values of the covariance matrix are only on the diagonals .",
    "this algorithm guarantees a monotonic increase of the model s likelihood on each em iteration .    after obtaining",
    "the gmm parameter set @xmath39 for accent class @xmath40 $ ] , the gmm - based classifier , which maximize _ a posteriori _ probability for feature matrix @xmath20 is : @xmath41}p(\\lambda_s|x ) = \\operatorname*{arg\\,max}_{s \\in [ 1,s]}\\frac{p(x|\\lambda_s)p(\\lambda_s)}{p(x ) } \\nonumber \\\\              & \\propto & \\operatorname*{arg\\,max}_{s \\in [ 1,s]}p(x|\\lambda_s ) \\nonumber \\\\              & \\propto & \\operatorname*{arg\\,max}_{s \\in [ 1,s]}\\sum^{k}_{k=1}\\mathrm{log}p(\\mathbf{x}_{k}|\\lambda_s).\\end{aligned}\\ ] ] the first equation is due to bayes rule .",
    "the first proportion is assuming @xmath42 and @xmath43 is the same for all accent models .",
    "the second proportion uses logarithm and independence between input samples @xmath44 , @xmath45 $ ] .",
    "compared with principle component analysis ( pca ) , which transforms data into eigenspace and preserves the data dimensions with larger variation @xcite , linear discriminant analysis ( lda ) reduces dimensions by mapping data into a subspace while maximizing the discriminative information .",
    "assume there are @xmath46 number of @xmath21-dimensional data vectors @xmath47 in @xmath48 classes , where @xmath49 is the number of vectors in class @xmath40 $ ] .",
    "let the global mean @xmath50 over all classes be @xmath51 and the local mean @xmath52 for each class @xmath30 be @xmath53 respectively .",
    "then , we define between - class scatter @xmath54 and within - class scatter @xmath55 by @xmath56 @xmath57 if we choose @xmath58 from the underlying space @xmath59 , then @xmath60 and @xmath61 are the projections of @xmath54 and @xmath55 onto the direction @xmath58 . searching the directions @xmath58 for the best class discrimination",
    "is equivalent to maximizing the ratio of @xmath62 subject to @xmath63 .",
    "the latter is called the fisher discriminant function and can be converted to by lagrange multipliers and solved by eigen - decomposition of @xmath64 . by selecting eigenvectors associated with the most significant @xmath65 eigenvalues of @xmath64 , one can map the original @xmath21-dimensional data into a @xmath65-dimensional subspace for discriminative feature reduction .",
    "lda is derived with the assumption that features in various dimensions have the same variance , which may not be the case in the real problem .",
    "for example , consider two classes of data with the gaussian distributions shown in fig .",
    "[ fig : demo_hlda ] .",
    "they have the same variance and slightly different means in one direction , while same mean and significantly different variances in the other distribution .",
    "lda will project the data to the first direction , since it maximizes the ratio of between - class scatter @xmath54 and within - class scatter @xmath55 . however , the other direction will lead to the best discriminant information in this case .",
    "this work uses kumar s",
    "method @xcite to generalize lda to hlda using maximum likelihood estimation ( mle ) on gaussian distributions .",
    "the diagram of the 7-way accent classification based on pure acoustic information is demonstrated in fig .",
    "[ fig : accentdetect_base ] .        plp - hlda features with context - size 1 and reduced dimension 20 is used .",
    "the context - size factor is used to duplicate features for potential performance improvement .",
    "for example , with context - size 1 , the original feature frame is elongated with the concatenation from its 1 left frame and 1 right frame .",
    "both the gmm classifier and the improved gmm - hlda classifier were trained with features of various types of accents of 256 gaussian mixtures .",
    "these parameters , including order of gmm , feature dimension in plp and hlda , and context - size were optimized with development set .",
    "the performance on the testing set achieve 40% and 46% accuracies using gmm classifier and gmm - hlda classifier .",
    "to construct the classifier with vowel representation , instead of directly measuring vowel shifting from standard speech to accented one , the same vowel of various types of accents are trained as separated gmms ; instead of using only the fundamental 5 vowels described in sec .",
    "[ sec : vowel_representation ] , the same concept is generalized and all 15 vowels in arpabet @xcite listed in tab . [",
    "tab : vowels ] are used .    @ l*9l @ * vowel * & aa & ae & ah & ao & aw & ay & eh & er + * example * & f**a**ther & f**a**st & s**u**n & h**o**t & h**ow * * & m**y * * & r**e**d & b**ir**d + * vowel * & ey & ih & iy & ow & oy & uh & uw & + * example * & s**ay * * & b**i**g & m**ee**t & sh**ow * * & b**oy * * & b**oo**k & f**oo**d +    given @xmath48 types of accents and @xmath66 numbers of vowels , @xmath67 is the extracted feature set for @xmath68 vowel , the improved gmm classifer as the combination of gmm classifers of all vowels , can be formulated as : @xmath69}\\sum_{t=1}^{t}w_{t}p(\\lambda_{s , t}|x^{(t ) } ) \\nonumber \\\\              & \\propto & \\operatorname*{arg\\,max}_{s \\in [ 1,s ] } \\sum_{t=1}^{t}w_{t}\\sum^{k}_{k=1}\\mathrm{log}p(\\mathbf{x}_{k}^{(t)}|\\lambda_{s , t}).\\end{aligned}\\ ] ] where @xmath70 is the gmm for @xmath71 accent and @xmath68 type of vowels , and @xmath72 is the proportion of @xmath68 vowel in the whole vowel set .",
    "adding this additional layer on the gmm classifier is critical for finding the vowel sets which preserve the accents and is shown to improve on classifying accents .",
    "however , it requires recognizing these vowels in the front end . during training and development ,",
    "the phoneme alignment is performed to extract vowels , while during testing , a subset of the recognized vowels with certain level of confidence are selected after phoneme recognition .",
    "the htk speech recognition toolkit was used here for the phoneme alignment and recognition with triphone acoustic models .      in the system developement , with the partial in - house transcriptions of the speech from 7 major accents , we prepare dictionary needed for phoneme alignment using hvite in htk . fig .",
    "[ fig : dppa ] demonstrates the process of dictionary preparation and phoneme alignment for fae .",
    "the dictionary file is a list of word - pronunciations pairs in htk format , which can be obtained through the process of word collection , word - to - pronunciation conversion with an in - house lexicon tester and htk dictionary file creation . in the phoneme alignment , the htk configuration file , the hmm model definition and the tired list are all trained using fisher corpus .    in the system test , since there is no transcription available , in order to find features corresponding to vowels , accented speech is recognized using htk and only a subset of recognized vowels with certain level of confidence based on the @xmath73-gram log likelihood are used .",
    "this threshold is predefined with training and development data .",
    "here 39-dimensional plp features with mvns are used in the implementation of accent classification .",
    "after training gmms on seperated vowels , gmms of 7 vowels out of 15 of each accent are selected to form the mixed gmm classifer for that accent .",
    "the overall classification accuracy is 50.9% , which gains 4.5% improvement from the gmm classifer trained with hlda features . tab . [",
    "tab : result_accentclassification ] compares the performances of all three methods .",
    "the combination of classifier and features include a ) gmms with plp , trained per accent ; b ) gmms with hdla ( 20 dimensions with context size 1 , optimized from 39-dimensional plp ) , trained per accent ; and c ) gmms with hlda , trained per accent and per vowel",
    ". the accuracy is obtained from accented speech about 20-second duration , and is competitive compared with the state - of - art results in @xcite , @xcite and @xcite .",
    ".result comparison of 7-way accent classification [ cols= \" < ,",
    "< , < , < \" , ]",
    "this work shows the classification accuracy improvement with hlda feature optimization and extracted vowels from accented speech for developing gmm classifiers .",
    "there are at least several areas that can be addressed for further improvement .",
    "first , more sophisticated classifiers such as deep neural network classifier @xcite may also be used for accent classification .",
    "second , since the data for each accent is very limited , a universal classifier based on restricted boltzmann machine ( rbm ) , instead of traditional gmms for each accents can be explore @xcite .",
    "rbm is trained using data of all accents , with capability to deviate with different accents .",
    "third , accent clustering based on certain distance measurements , such as bhattacharyya distance @xcite can also be used to pre - classify accents into several clusters , which may potentially help narrow down the search scope and improve the classification accuracy . forth ,",
    "in the triphone phoneme alignment and recognition , currently all triphones with the same mid - phone are treated the same .",
    "however , the accent patterns may stay in the transition of phonemes , which can be investigated later ."
  ],
  "abstract_text": [
    "<S> previous accent classification research focused mainly on detecting accents with pure acoustic information without recognizing accented speech . </S>",
    "<S> this work combines phonetic knowledge such as vowels with acoustic information to build guassian mixture model ( gmm ) classifier with perceptual linear predictive ( plp ) features , optimized by hetroscedastic linear discriminant analysis ( hlda ) . with input about 20-second accented speech , </S>",
    "<S> this system achieves classification rate of 51% on a 7-way classification system focusing on the major types of accents in english , which is competitive to the state - of - the - art results in this field . </S>"
  ]
}