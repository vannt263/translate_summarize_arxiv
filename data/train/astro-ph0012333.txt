{
  "article_text": [
    "correlation functions are some of the most widely used statistics within astrophysics ( see peebles 1980 for a extensive review ) .",
    "they are often used to quantify the clustering of objects in the universe ( _ e.g. _ galaxies , quasars _ etc .",
    "_ ) compared to a pure poission process .",
    "more recently , they have also been used to measure fluctuations in the cosmic microwave background ( see szapudi et al . 2000 ) . on large scales ,",
    "the higher  order correlation functions ( 3-point and above ) can be used to test several fundamental assumptions about the universe ; for example , our hierarchical scenario for structure formation , the gaussianity of the initial conditions as well as testing various models for the biasing between the luminous and dark matter .",
    "the reader is referred to szapudi ( 2000 ) , szapudi et al .",
    "( 1999a , b ) and scoccimarro ( 2000 ; and references therein ) for an overview of the usefulness of @xmath0point correlation functions in constraining cosmological models .    over the coming decade , several new , massive cosmological surveys will become available to the astronomical community . in this new era , the quality and quantity of data will warrant a more sophisticated analysis of the higher  order correlation functions of galaxies ( and other objects ) over the largest range of scales possible .",
    "our ability to perform such studies will be severely limited by the computational time needed to compute such functions and no - longer by the amount of data available . in this paper",
    ", we address this computational `` bottle - neck '' by outlining a new algorithm that uses innovative computer science to accelerate the computation of @xmath0point correlation functions far beyond the naive @xmath1 scaling law ( where @xmath2 is the number of objects in the dataset and @xmath0 is the power of correlation function desired ) .",
    "the algorithm presented here was developed as part of the `` computational astrostatistics '' collaboration ( see nichol et al . 2000 ) and is a member of a family of algorithms for a very general class of statistical computations , including nearest - neighbor methods , kernel density estimation , and clustering .",
    "the work presented here was initially presented by gray & moore ( 2001 ) and will soon be discussed in a more substantial paper by connolly et al .",
    "( 2001 ) . in this conference",
    "proceeding , we provide a brief review of _ k_d - trees ( section [ kdtr ] ) , a discussion of the use of _ k_d - trees in range searches ( section [ range ] ) , an overview of the development of a fast @xmath0point correlation function code ( section [ npt ] ) as well as presenting the concept of controlled approximations in the calculation of the correlation function ( section [ apprx ] ) .",
    "in section 6 , we provide preliminary results on the computation speed - up achieved with this algorithm and discuss future prospects for further advances in this field through the use of other tree structures .",
    "our fast @xmath0point correlation function algorithm is built upon the _ k_d - tree data structure which was introduced by friedman et al .",
    "k_d - tree is a way of organizing a set of datapoints in @xmath3-dimensional space in such a way that once built , whenever a query arrives requesting a list all points in a neighborhood , the query can be answered quickly without needing to scan every single point .",
    "the root node of the _ k_d - tree owns all the data points .",
    "each non - leaf - node has two children , defined by a splitting dimension @xmath4 and a splitting value @xmath5 .",
    "the two children divide their parent s data points between them , with the left child owning those data points that are strictly less than the splitting value in the splitting dimension , and the right child owning the remainder of the parent s data points : @xmath6 < { { { { { n}}.{{\\mbox{\\scriptsize \\sc splitvalue}}}}}}\\mbox { and }   { { { { { \\mbox{\\bf x}}}}_{i}}}\\in { n}\\\\ { { { { { \\mbox{\\bf x}}}}_{i}}}\\in { { { { { n}}.{{\\mbox{\\scriptsize \\sc right } } } } } } & \\leftrightarrow & { { { { { \\mbox{\\bf x}}}}_{i}}}[{{{{{n}}.{{\\mbox{\\scriptsize \\sc splitdim } } } } } } ] \\geq { { { { { n}}.{{\\mbox{\\scriptsize \\sc splitvalue}}}}}}\\mbox { and }   { { { { { \\mbox{\\bf x}}}}_{i}}}\\in { n}\\end{aligned}\\ ] ] as an example , some of the nodes of a _ k_d - tree are illustrated in figures  1 .        _",
    "k_d - trees are usually constructed top - down , beginning with the full set of points and then splitting in the center of the widest dimension .",
    "this produces two child nodes , each with a distinct set of points .",
    "this procedure is then repeated recursively on each of the two child nodes .",
    "a node is declared to be a leaf , and is left unsplit , if the widest dimension of its bounding box is @xmath7 some threshold , @xmath8 .",
    "a node is also left unsplit if it denotes fewer than some threshold number of points , @xmath9 .",
    "a leaf node has no children , but instead contains a list of @xmath3-dimensional vectors : the actual datapoints contained in that leaf .",
    "the values @xmath10 and @xmath11 would cause the largest _ k_d - tree structure because all leaf nodes would denote singleton or coincident points . in practice ,",
    "we set @xmath8 to @xmath12 of the range of the data point components and @xmath9 to around 10 .",
    "the tree size and construction thus cost considerably less than these bounds because in dense regions , tiny leaf nodes are able to summarize dozens of data points .",
    "the operations needed in tree - building are computationally trivial and therefore , the overhead in constructing the tree is negligible . also , once a tree is built it can be re - used for many different analysis operations .    since the introduction of _ k_d - trees , many variations of them have been proposed and used with great success in areas such as databases and computational geometry ( preparata & shamos 1985 ) .",
    "r - trees ( guttman 1984 ) are designed for disk resident data sets and efficient incremental addition of data .",
    "metric trees ( see uhlmann 1991 ) place hyperspheres around tree nodes , instead of axis - aligned splitting planes . in all cases ,",
    "the algorithms we discuss in this paper could be applied equally effectively with these other structures .",
    "for example , moore ( 2000 ) shows the use of metric trees for accelerating several clustering and pairwise comparision algorithms .",
    "before proceeding to fast @xmath0point calculations , we will begin with a very standard _ k_d - tree search algorithm that could be used as a building block for fast 2-point computations .    for simplicity of exposition we will assume the every node of the _ k_d - tree contains one extra piece of information : the bounding box of all the points it contains . call this box @xmath13 .",
    "the implication of this is that every node must contain two new @xmath3 dimensional vectors to represent the lower and upper limits of each dimension of the bounding box .",
    "the range search operation takes two inputs .",
    "the first is a @xmath3-dimensional vector @xmath14 called the _ query point_. the second is a separation distance @xmath15 .",
    "the operation returns the complete set of points in the _ k_d - tree that lie within distance @xmath15 of @xmath14 .",
    "* @xmath16 + returns a set of points @xmath17 such that @xmath18 : = the closest distance from @xmath14 to @xmath13 . *",
    "if @xmath19 then it is impossible that any point in @xmath20 can be within range of the query .",
    "so simply return the empty set of points without doing any further work .",
    "* else , if @xmath20 is a leaf node , we must iterate through all the datapoints in its leaf list . for each point , find if it is within distance @xmath15 of @xmath14 . if so , add it to the set of results .",
    "* else , @xmath20 is not a leaf node .",
    "then : * * let @xmath21 * * let @xmath22 * * return @xmath23 .",
    "figure 2a shows the result of running this algorithm in two dimensions .",
    "many large nodes are pruned from the search .",
    "117 distance calculations were needed for performing this range search , compared with 499 that would have been needed by a naive method .",
    "note that it is not essential that _ k_d - tree nodes have bounding boxes explicitly stored .",
    "instead a hyper - rectangle can be passed to each recursive call of the above function and dynamically updated as the tree is searched .",
    "range searching with a _ k_d - tree can be much faster than without if the range is small , containing only a small fraction of the total number of datapoints .",
    "but what if the range is large ?",
    "figure 2b shows an example in which _ k_d - trees provide little computational saving because almost all the points match the query and thus need to be visited . in general",
    "this problem is unavoidable .",
    "but in one special case it _ can _ be avoided ",
    "if we merely want to count the number of datapoints in a range instead of explicitly find them all .",
    "we will add the following field to a _ k_d - tree node .",
    "let @xmath24 be the number of points contained in node @xmath20 .",
    "this is the first and simplest of a set of _ k_d - tree decorations we refer to as _ cached sufficient statistics _",
    "( see moore & lee 1998 ) .",
    "in general , we frequently stored the centroid of all points in a node and their covariance matrix .",
    "once we have @xmath24 it is trivial to write an operation that counts the number of datapoints within some range without explicitly visiting them .",
    "* @xmath25 + returns an integer : the number of points that are both inside the @xmath20 and also within distance @xmath15 of @xmath14 .",
    "* let @xmath26 : = the closest distance from @xmath14 to @xmath13 . * if",
    "@xmath19 then it is impossible that any point in @xmath20 can be within range of the query .",
    "so simply return 0 .",
    "* let @xmath27 : = the furthest distance from @xmath14 to @xmath13 . * if @xmath28 then every point in @xmath20 must be within range of the query .",
    "so simply return @xmath24 .",
    "* else , if @xmath20 is a leaf node , we must iterate through all the datapoints in its leaf list .",
    "start a counter at zero .",
    "for each point , find if it is within distance @xmath15 of @xmath14 .",
    "if so , increment the counter by one .",
    "return the count once the full list has been scanned .",
    "* else , @xmath20 is not a leaf node .",
    "then : * * let @xmath29 * * let @xmath30 * * return @xmath31 .",
    "the same query that gave the poor range search performance in figure 2b gives good performance in figure 3 .",
    "the difference is that a second type of pruning of the search is possible : if the hyperrectangle surrounding the n is either entirely outside _ or inside _ the range then we prune .     ]",
    "it is easy to see that the 2-point correlation function is simply a repeated set of range counts .",
    "for example , given a minimum and maximum separation @xmath32 and @xmath15 we run the following algorithm :    * @xmath33 + input @xmath34 is a dataset , represented as a matrix in which the @xmath3th row corresponds to the @xmath3th datapoint .",
    "@xmath34 has @xmath2 rows and @xmath3 columns .",
    "input @xmath20 is the root of a kdtree built from the data in @xmath34 .",
    "output integer : the number of pairs of points @xmath35 such that @xmath36 .",
    "* c : = 0 * for @xmath37 between @xmath38 and @xmath2 do : * * @xmath39    note that in practice we do not use two range counts at each iteration , but one slightly more complex rangecount operation    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ @xmath40 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    that directly counts the number of points whose distance from @xmath14 is between @xmath32 and @xmath15 .",
    "the previous algorithm iterates over all datapoints , issuing a range count operation for each .",
    "we can save further time by turning that outer iteration into an additional kd - tree search .",
    "the new search will be a recursive procedure that takes two nodes , @xmath41 and @xmath42 , as arguments .",
    "the goal will be to compute the number of pairs of points @xmath43 such that @xmath44 , @xmath45 , and @xmath46 .",
    "* @xmath47 + returns an integer : the number of pairs of points @xmath43 such that @xmath44 , @xmath45 , and @xmath46 .",
    "* let @xmath26 : = the closest distance between @xmath48 and @xmath49 . * if @xmath19 then it is impossible that any pair of points can match .",
    "so simply return 0 .",
    "* let @xmath27 : = the furthest distance between @xmath48 and @xmath49 . * if @xmath50 then it is again impossible that any pair of points can match .",
    "so simply return 0 . *",
    "if @xmath51 then all pairs of points must match .",
    "use @xmath52 and @xmath53 to compute the number of resulting pairs @xmath54 , and return that value .",
    "* else , if @xmath41 and @xmath42 are both leaf nodes , we must iterate through all pairs of datapoints in their leaf lists .",
    "return the resulting ( slowly computed ) count .",
    "* else at least one of the two nodes is a non - leaf .",
    "pick the non - leaf with the largest number of points ( breaking ties arbitrarily ) , and call it @xmath55 . call the other node @xmath56 . then : * * let @xmath57 * * let @xmath58 * * return @xmath31 .    computing a 2-point function on a dataset @xmath34",
    "then simply consists of computing the value @xmath59 , where @xmath60 is a kd - tree built from @xmath34 , for a range of bins with minimum and maximum boundaries of @xmath32 and @xmath61 .",
    "we note here that the 2-point correlation function , the quanity of interest is not simply @xmath62 , but @xmath63 ( the number of unique pairs of objects ) .",
    "a further speed  up can be obtained by simultaneously computing the @xmath64 over a series of bins .",
    "we will discuss this in further detail in connolly et al .",
    "( 2001 ) .",
    "so far , we have discussed two operations  exclusion and subsumption  which remove the need to traverse the whole tree thus speeding  up the computation of the correlation function .",
    "another form of pruning is to eliminate node - node comparisons which have been performed already in the reverse order .",
    "this can be done simply by ( virtually ) ranking the datapoints according to their position in a depth - first traversal of the tree , then recording for each node the minimum and maximum ranks of the points it owns , and pruning whenever @xmath41 s maximum rank is less than @xmath42 s minimum rank .",
    "this is useful for all - pairs problems , but will later be seen to be _ essential _ for all - k - tuples problems .",
    "this kind of pruning is not practical for single - tree search .",
    "the advantages of dual - tree over single - tree are so far two fold .",
    "first , dual - tree can be faster , and second it can exploit redundancy elimination .",
    "but two more advantages remain .",
    "first , we can extend the `` 2-tree for 2-point '' method up to `` n - trees for n - point '' .",
    "second ( discussed in section  [ se : approx ] ) , we can perform effective approximation with dual - trees ( or n - trees ) .",
    "we now discuss the first of these advantages .",
    "the @xmath0point computation is parameterized by two @xmath65 symmetric matrices : @xmath66 and @xmath67 .",
    "we wish to compute @xmath68 where @xmath69 is zero unless the following conditions hold ( in which case it takes the value 1 ) : @xmath70 we will achieve this by calling a recursive function @xmath71 on an @xmath72-tuple of kdtree nodes @xmath73 .",
    "this recursive function much return @xmath74    * @xmath75 + * let @xmath76 * for @xmath77 to @xmath72 do * * for @xmath78 to @xmath72 do * * * let @xmath26 : = the closest distance between @xmath79 and @xmath80 . * * * if @xmath81 then it is impossible that any @xmath72-tuple of points can match because the distance between the @xmath37th and @xmath82th points in any such @xmath72-tuple must be out of range .",
    "so simply return 0 . *",
    "* * let @xmath27 : = the furthest distance between @xmath79 and @xmath80 .",
    "* * * if @xmath83 then similarly return 0 . * * * if @xmath84 then every @xmath72tuple has the property the the @xmath37th member and @xmath82th member match .",
    "we are interested in whether this is true for all @xmath85 pairs and so the first time we are disappointed ( by discovering the above expression does not hold ) then we will update the @xmath86 flag .",
    "thus the actual computation at this step is : + _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ if @xmath87 or @xmath88 then + @xmath89 . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ * if @xmath86 has remained true throughout the above double loop , we can be sure that every @xmath72tuple derived from the nodes in the recursive call must match , and so we can simply return @xmath90 * else , if all of @xmath91 are leaf nodes we must iterate through all @xmath72tuples of datapoints in their leaf lists .",
    "return the resulting ( slowly computed ) count .",
    "* else at least one of the nodes is a non leaf .",
    "pick the non - leaf with the largest number of points ( breaking ties arbitrarily ) , and assume it has index @xmath92 . then : * * let @xmath93 * * let @xmath94 * * return @xmath31",
    ".    the full @xmath0point computation is achieved by calling @xmath71 with arguments consisting of an @xmath72tuple of copies of the root node .",
    "we should note once again it is possible to save considerable amounts of computation by eliminating redundancy .",
    "for example , in the 4-point statistic , the above implementation will recount each matching 4-tuple of points",
    "@xmath95 in 24 different ways : once for each of the @xmath96 permutations of @xmath95 .",
    "again , this excess cost can be avoided by ordering the datapoints via a depth - first tree indexing scheme and then pruning any @xmath72tuple of nodes violating that order .",
    "but the reader should be aware of an extremely messy problem regarding how much to award to the count in the case that a subsume type of pruning can take place .",
    "if all nodes own independent sets of points the answer is simple : the product of the node counts .",
    "if all nodes are the same then the answer is again simple : @xmath97 , where @xmath72 is the number of points in the node .",
    "somewhat more subtle combinatorics are needed in the case where some nodes in the @xmath72-tuple are identical and others are not . and fearsome computation is needed in the various cases in which some nodes are descendants of some other nodes .",
    "in general , when the final answer comes back from @xmath71 , the majority of the quantity in the count will be the sum of components arising from large subsume prunes .",
    "but the majority of the computational effort will have been spent on accounting for the vast number of small but unprunable combinations of nodes .",
    "we can improve the running time of the algorithm by demanding that it also prunes it search in cases in which only a tiny count of @xmath72tuples is at stake .",
    "this is achieved by adding a parameter , @xmath98 , to the @xmath71 algorithm , and adding the following lines at the start :    * let @xmath99 * if @xmath100 then quit this recursive call .",
    "this will clearly cause an inaccurate result , but fortunately it is not hard to maintain tight lower and upper bounds on what the true answer would have been if the approximation had not been made .",
    "thus @xmath101 now returns a pair of counts @xmath102 where we can guarantee that the true count @xmath62 lies in the range @xmath103 .",
    "suppose the true value of the @xmath0point function is @xmath62 but that we are prepared to accept a fractional error of @xmath104 : we will be happy with any value @xmath105 such that latexmath:[\\[\\label{awareapprox }    possible to adapt the n - tree algorithm using a best - first iterative deepening search strategy to guarantee this result while exploiting permission to approximate effectively by building the count as much as possible from `` easy - win '' node pairs while doing approximation at hard deep node - pairs .",
    "this is simply achieved by repeatedly calling the previous approximate algorithm with diminishing values of @xmath98 until a value is discovered that satisfies equation  [ awareapprox ] .",
    "is shown and agrees well with the observed data .",
    "the naive @xmath107 law is also plotted for comparison [ fig4 ] ]",
    "we plan to present a more detailed discussion of the techniques presented here in a forthcoming paper ( connolly et al .",
    "2001 ) . that paper will also include a full analysis of the computational speed and overhead of our @xmath0point correlation function algorithm and compare those with existing software for computing the higher  order correlation functions _",
    "e.g. _ szapudi et al .",
    "however , in figure [ fig4 ] , we present preliminary results on the scaling of computational timing needed for a 2-point correlation function as a function of the number of objects in the data set . for these tests , we computed all the data  data pairs for random data sets and real , projected 2-dimensional galaxy data .",
    "these data show that our 2-point correlation function algorithm scales as @xmath108 ( for projected 2-dimensional data ) compared to the naive all - pairs scaling of @xmath109 where here @xmath0 is the size of the dataset under consideration . to emphasis the speed  up obtained by our algorithm ( figure [ fig4 ] ) , an all  pairs count for a database of @xmath110 objects would take only 10 hours ( on our dec alpha workstation ) using our methodology compared to @xmath111 hours ( @xmath112 year ) using the naive @xmath107 method .",
    "clearly , binning the data would also drastically increase the speed of analyses over the naive all ",
    "pairs @xmath109 scaling but at the price of lossing of resolution .",
    "similar spectacular speed  ups will be achieved for the 3 and 4point functions and we will report these results elsewhere ( connolly et al .",
    "furthermore , controlled approximations can further accelerate the computations by several orders of magnitude .",
    "such speed  ups are vital to allow monte carlo estimates of the errors on these measurements . in summary ,",
    "our algorithm now makes it possible to compute an exact , all  pairs , measurement of the 2 , 3 and 4point correlation functions for data sets like the sloan digital sky survey ( sdss ) .",
    "these algorithms will also help in the speed - up of cosmic microwave background analyses as outlined in szapudi et al .",
    "( 2000 ) .",
    "finally , we note here that we have only touched upon one aspect of how trees data structures ( and other computer science techniques ) can help in the analysis of large astrophysical data sets .",
    "moreover , there are other tree structures beyond _ k_d - trees such as ball trees which could be used to optimize our correlation function codes for higher dimensionality data .",
    "we will explore these issues in future papers ."
  ],
  "abstract_text": [
    "<S> we present here a new algorithm for the fast computation of @xmath0point correlation functions in large astronomical data sets . </S>",
    "<S> the algorithm is based on _ k_d - trees which are decorated with cached sufficient statistics thus allowing for orders of magnitude speed  </S>",
    "<S> ups over the naive non - tree - based implementation of correlation functions . </S>",
    "<S> we further discuss the use of controlled approximations within the computation which allows for further acceleration . in summary , </S>",
    "<S> our algorithm now makes it possible to compute exact , all  pairs , measurements of the 2 , 3 and 4point correlation functions for cosmological data sets like the sloan digital sky survey ( sdss ; york et al . </S>",
    "<S> 2000 ) and the next generation of cosmic microwave background experiments ( see szapudi et al . </S>",
    "<S> 2000 ) . </S>"
  ]
}