{
  "article_text": [
    "agent - based modelling is an important tool for studying the autonomous actions of individual entities and their interactions  @xcite in complex systems .",
    "the interactions often reflect how agents compete , especially in the context of competing games .",
    "examples of some extensively studied games are the prisoner s dilemma ( pd ) , snowdrift game ( sg ) , and stag hunt game ( sh )  @xcite .",
    "these are two - strategy games with agents having a choice of two possible options . in the present work ,",
    "we focus on the rock - paper - scissors ( rps ) game  @xcite , characterized by three strategies that dominate each other _ cyclically_. depending on the context , the strategy of an agent can be regarded as his state , character , opinion or species .",
    "the strategies are related cyclically through : rock ( r ) crushes scissors ( s ) , scissors ( s ) cuts paper ( p ) , and paper ( p ) covers rock ( r )  @xcite . despite its simplicity",
    ", many phenomena in nature can be described within the framework of rps game .",
    "a well - known example is related to the mating strategy of the common side - blotched lizards ( _ uta stansburiana _ ) , a species of lizards found in the western coast of north america @xcite .",
    "other examples include phenomena in marine ecological communities  @xcite , coexistence of different kinds of microbes  @xcite , and in chemical and biological systems  @xcite .",
    "there are phenomena in economic and social systems , e.g. , human decision - making processes and epidemic diseases , that also involve cyclical dominance and they can be studied within the rps framework  @xcite .    an interesting question is how network structures  @xcite affect the rps game .",
    "the focus so far has been on static networks , i.e. , the links connecting two competing agents are fixed",
    ". for rps agents interact in a square lattice  @xcite with the loser updating the strategy to be that of the winner , spatial self - organized patterns emerged .",
    "_ studied the small - world effect on rps game by replacing a fraction @xmath4 of the links in a square lattice by links that connect two randomly selected agents  @xcite .",
    "it was found that two qualitatively different phases result , depending on the value of @xmath4 .",
    "szolnoki and szab studied the rps game in kagome , honeycomb , triangular , cubic , and ladder - shape lattices  @xcite .",
    "they found that while the spatial dimension of the lattices affects the transitions between different phases strongly , the clustering coefficient does not .",
    "going beyond static networks , co - evolving networks have attracted much attention in recent years  @xcite . in co - evolving networks ,",
    "an agent may switch his strategy or alter his competing neighbors so as to attain an environment that is to his advantage .",
    "such adaptive actions couple the dynamics of strategy selections and network evolution .",
    "co - evolving networks invoking pd , sg , sh games have been studied  @xcite . in particular",
    ", the present work is motivated by the two - option adaptive co - evolving voter model  @xcite and the dissatisfied adaptive snowdrift game  @xcite . in the co - evolving voter model  @xcite , there are two opposite opinions competing for dominance in an initially random regular network and agents prefer to be surrounded by like - opinion neighbors .",
    "when an agent interacts with a randomly chosen neighbor of the opposite opinion , he has a probability @xmath0 to cut the link to the neighbor and rewire it to a randomly chosen agent of the same opinion . with a probability @xmath1 ,",
    "the agent is convinced by the neighbor and switches to the opposite opinion .",
    "both actions are rational in that the agents tend to pursue local consensus . despite its simplicity , the phenomena are rich . for values of @xmath0 below ( above ) a critical value , the system evolves into an active ( a frozen ) phase in which the network evolution and strategy selection continue ( cease ) .",
    "similar adaptive actions ( i.e. switching strategies and rewiring the links to dissatisfying neighbors ) were included in the model of dissatisfied adaptive snowdrift game ( dasg )  @xcite . in dasg",
    ", adaptive actions are taken when agents become dissatisfied with non - cooperative neighbors .",
    "the resulting network is either in a disconnected , dynamically frozen , and character - segregated phase or a connected , dynamical , and character - mixed phase , depending on a payoff parameter .",
    "analytic approaches to co - evolving networks require careful treatment of spatial correlations  @xcite .",
    "other examples in which similar adaptive actions are invoked include a reversed opinion - formation model  @xcite and an inverse voter model  @xcite .",
    "networking effects , including co - evolving networks , also pose challenging questions to analytic approaches .",
    "typically approaches such as mean field approximation and pair approximation  @xcite often only give results in qualitative agreement with simulations  @xcite .",
    "the reason is that the adaptive actions are sensitive to the local competing environment and thus spatial correlations are important .",
    "we have made various attempts in understanding the key factors in formulating theories that better capture spatial correlations  @xcite .",
    "an improved mean field theory was shown to give good results for dasg  @xcite and the inverse voter model  @xcite .    here",
    ", we generalize the study of adaptive co - evolving models to cyclic multiple - strategy case .",
    "in particular , an adaptive and co - evolving rps model , abbreviated as aprs , is proposed and studied in detail .",
    "our model is different from the adaptive rps model studied by demirel  _ et al .",
    "_  @xcite .",
    "the agents in adaptive rps model prefers to have neighbors of the same option by an adaptive mechanism in which an agent who lost a rps game adopts the strategy of the winner or to seek a new neighbor of the same opinion .",
    "the authors focused on the time evolution of the fractions of agents using the different strategies .",
    "in our model , the agents take adaptive actions to enhance their chance of winning .",
    "we focus on the different phases exhibited in the steady state and the formulation of analytic approaches . in sec .  2 , we define our model and identify the key features as revealed by simulations .",
    "the model is parameterized by a probability @xmath0 of rewiring an unfavorable link .",
    "the system evolves to two different phases for different ranges of @xmath0 . in sec .  3 , a theory based on the densities of different kinds of links connecting agents of different strategies is constructed .",
    "results are found to be in good agreement with simulations , with small yet noticeable discrepancies . in sec .  4",
    ", we point out that the small discrepancies are important hints for studying the validity of the assumptions in a theory .",
    "we analyze the dependence of the probabilities of winning and losing of different types of agents .",
    "these probabilities are found to depend on the role of an agent in an adaptive process and his degree .",
    "these features are usually not included in analytic approaches .",
    "although the context of arps is studied , the discussions on the formalism of mean field theory and its validity are intentionally carried out in a general form . as such",
    ", the analysis here can be readily applied to other co - evolving network models with two or more options or strategies .",
    "results are summarized in sec .",
    "consider a system of @xmath5 agents . for concreteness , the agents are initially connected via a random regular graph of uniform degree @xmath6 and each of them is assigned one of the three strategies ( r , p , or s ) with equal probabilities . in a time step , an agent , referred to as the _ active agent _ , is selected randomly .",
    "if there is no connected neighbor , i.e. of degree zero , there will be no action and the time step ends .",
    "otherwise , the active agent selects a connected neighbor , referred to as the _ passive agent _ , at random .",
    "they interact via a rps game . if the active agent wins or there is a draw , he is satisfied and no adaptive actions take place .",
    "if the active agent loses , he is dissatisfied and he will take one of the following adaptive actions : ( i ) with a probability @xmath0 to cut the link to the passive agent and rewire it to another agent ( called the rewiring target ) randomly chosen from all the agents in the system who are not a neighbor , or ( ii ) with a probability @xmath7 to switch his strategy to the one that can defeat the passive agent .",
    "figure  [ fig01 ] illustrates the possible events and adaptive actions in a time step with examples .",
    "as one active agent is picked at a time step , the interactions are asynchronous .",
    "the probability @xmath0 is the only parameter in aprs .",
    "the adaptive actions are rational in that an agent always aims to prevent losing to the same opponent by altering the local competing environment .",
    "they drive the strategies employed by the agents and the network connections to co - evolve .",
    "the process continues until the network achieves a macroscopically steady state .",
    "the long - time behavior of the system can be characterized by a few macroscopic quantities .",
    "they include the fractions @xmath8 , @xmath9 , and @xmath10 of agents using the strategies - r , p , and s , respectively , the fractions of undirected _ inert _ links @xmath11 , @xmath12 and @xmath13 connecting agents using the same strategy that would lead to a draw , and the fractions of undirected active links @xmath14 , @xmath15 and @xmath16 connecting agents using different strategies that would lead to a win - lose situation .",
    "it should be pointed out that arps can be implemented with different initial strategy assignments and initial network connections . here , we take advantage of the simplicity provided by random initial strategy assignments and the symmetry among the three strategies so that we could focus on the discussion of the @xmath0-dependence of two link densities , one for inert and the other for active links .",
    "detailed numerical simulations were carried out for arps . here",
    "we focus on an initial network of uniform degree @xmath17 and @xmath18 agents .",
    "the results illustrated that @xmath19 , @xmath20 and @xmath21 .",
    "these are expected as no strategy plays a special role in rps and the adaptive actions in arps .",
    "the random initial conditions make sure that all strategies are evenly present .",
    "this allows us to focus the discussion on how @xmath22 and @xmath23 behave at long time .",
    "[ fig02 ] shows the simulation results ( symbols ) .",
    "[ fig02](a ) confirms @xmath19 for all values of @xmath0 , as expected from symmetry consideration .",
    "[ fig02](b ) shows the behavior of @xmath22 ( squares ) and @xmath23 ( circles ) .",
    "these quantities reveal the two different phases classified by @xmath0 . for @xmath24 ,",
    "@xmath11 increases monotonically with @xmath0 and approaches @xmath25 at @xmath26 continuously while @xmath14 drops monotonically with @xmath0 and vanishes continuously at @xmath26 . in the range @xmath27 , @xmath25 and @xmath28 .",
    "we found that @xmath29 for @xmath17 .",
    "we also studied initial networks of different values of @xmath6 .",
    "the results show the same qualitative behavior , but @xmath30 increases with @xmath6 .",
    "for example , @xmath31 for @xmath32 . here , we focus on analyzing the results for @xmath17 .    for @xmath33 ,",
    "the system has active links and it is in the _ active phase_. these active links promote agents interactions and adaptive actions .",
    "this is a dynamic phase as strategy switching and network rewiring persist . for @xmath34 ,",
    "the system has only inert links and it is in an inactive and _",
    "frozen phase_. there is no more adaptive action .",
    "the two phases also differ drastically in network structure . in the active phase",
    ", the system has a main cluster consisting of agents using the three strategies with both active and inert links . in the frozen phase ,",
    "the system breaks into three segregated pure - strategy clusters of equal size , with each cluster having agents using only r , p , or s. another noticeable feature is the discontinuous jump from @xmath35 at @xmath36 to a larger value when @xmath0 becomes finite .",
    "there is a similar discontinuous jump from @xmath37 at @xmath36 to a smaller value .",
    "these discontinuities will be discussed in sec .",
    "inspired by previous analytic approaches  @xcite for co - evolving agent - based models , we formulate a theory by tracing the expected changes in the macroscopic quantities in a time step . in principle , the system has many macroscopic variables . at the single - agent level , we have the fractions @xmath38 , @xmath39 , and @xmath40 . at the two - agent or link level ,",
    "there are the link densities @xmath11 , @xmath12 , @xmath13 , @xmath14 , @xmath15 and @xmath16",
    ". as discussed , symmetry implies @xmath41 and @xmath42 .",
    "therefore , we could take @xmath11 and @xmath14 as variables .",
    "together with @xmath43 , the two variables obey @xmath44 .",
    "this sum rule is also demonstrated by the simulation results in fig .",
    "[ fig02](b ) . as a result ,",
    "a single variable suffices for a theory up to the level of links .",
    "we choose @xmath14 as the variable , although other choices can also be made .",
    "we formulate a theory in a way that can be readily generalized to other co - evolving network problems . to proceed",
    ", we aim at writing down an equation for the change @xmath45 in @xmath14 in a time step . based on the adaptive actions , @xmath45",
    "is determined by : ( i ) the strategy of the active agent , ( ii ) his local configuration including the degree @xmath46 and the numbers of neighbors using the different strategies , ( iii ) the probability of losing the rps game , ( iv ) the adaptive action taken after losing , ( v ) the change in the _ number _ of links @xmath47 connecting an agent using strategy - r and an agent using strategy - p ( called rp - links ) due to the adaptive action . table  [ tab01 ] gives the possible values of @xmath48 due to the adaptive actions .",
    "schematically , the expected change in the link density @xmath45 can be expressed in terms of the probabilities of all possible local configurations , strategies and adaptive actions , and the corresponding local changes in the number of rp - links as follows : @xmath49.\\end{aligned}\\ ] ] here , @xmath50 is the probability of an agent using strategy - x and having degree @xmath46 , y ( z ) is the strategy which wins over ( loses to ) x , @xmath51 is the probability of an agent using strategy - x and having degree @xmath46 to have @xmath52 xy - links and @xmath53 xz - links , @xmath54 ( @xmath55 ) is the local change in rp - links due to rewiring ( switching ) with its possible values listed in table  [ tab01 ] , and @xmath56 is the total number of links in the network .",
    ".changes in the number of rp - links for different adaptive actions . [ cols=\"^,^\",options=\"header \" , ]     eq .",
    "( [ eq01 ] ) is general but hard to solve .",
    "formally , the quantities in the right - hand side changes with time as the adaptive actions proceed , and dynamical equations tracing their variations should also be established .",
    "fortunately , simplifications are possible when we focus only on the long time behavior when various quantities become stable in time and close the equation by proper approximations .",
    "( [ eq01 ] ) can be written into three terms , each corresponding to the active agent using x = r , p , s , respectively , i.e. , @xmath57 for given strategy - x and value of @xmath46 , there is an expected value @xmath58 for the agents using strategy - x and having exactly degree @xmath46 to be carried out .",
    "the notation @xmath59 stresses two points : ( i ) the average is taken over possible @xmath60 s and ( ii ) the result is a function of x and @xmath46 .",
    "similarly , we further define an expected value over possible values of the degrees for agents using strategy - x as : @xmath61 with the result depending on the strategy - x .",
    "the quantities @xmath62 , @xmath63 , and @xmath64 in eq .",
    "( [ eq02 ] ) can be expressed in terms of these expected values .",
    "explicitly , they can be expressed by using table  [ tab01 ] as @xmath65 where the terms proportional to @xmath0 are due to rewiring and those proportional to @xmath66 are due to strategy switching .",
    "to proceed , we make approximations to the expected values so as to close the equations .",
    "firstly , the equations can be simplified by the symmetry of the three strategies . as a result , it is sufficient to consider the expected values in regard to only one of the strategies . without loss of generality , we retain averages over agents using strategy - r .",
    "the other expected values for strategies - p and s are given by : @xmath67 , @xmath68 and @xmath69 are readily given by @xmath70 the first equation follows from @xmath71 , where @xmath72 is the number of agents using strategy - x .",
    "it says that the total number of xy - links is given by the product of @xmath72 and the average number of xy - links per agent using strategy - x .",
    "the second equation relates the mean degree @xmath69 among agents using strategy - x to the link densities .    for agents using strategy - r of a certain degree @xmath46 , the first moment @xmath73 and the second moment @xmath74",
    "are related to the expected value and the variance of @xmath75 respectively , and the mixed moment @xmath76 is related to the covariance of @xmath75 and @xmath77 via  @xcite @xmath78 we invoke a trinomial closure scheme to handle @xmath79 , @xmath80 and @xmath81 and close the equations .",
    "it is an extension of the binomial closure scheme in two - strategy models  @xcite .",
    "the essence is to treat averages @xmath82 that involve the sums @xmath83 approximately .",
    "physically , @xmath84 is the probability of having exactly @xmath52 xy - links , @xmath53 xz - links and @xmath85 xx - links , giving an agent with @xmath46 neighbors using the strategy - x .",
    "this echoes the question on the distribution of three possible outcomes @xmath86 , each occurring with the probability @xmath87 , in @xmath88 independent trials .",
    "the resulting trinomial distribution gives the expected numbers @xmath89 for the three outcomes , with the variances given by @xmath90 and the covariances between different outcomes @xmath91 and @xmath92 given by @xmath93  @xcite .",
    "here , the degree @xmath46 plays the role of @xmath88 .",
    "the probabilities @xmath94 , @xmath95 and @xmath96 are the conditional probabilities of encountering a neighbor using strategies - r , p and s respectively , given the strategy - x of an agent of degree @xmath46 .",
    "re - defining the symbols of the probabilities as @xmath97 , @xmath98 and @xmath99 respectively and invoking the trinomial closure scheme , we have @xmath100 to express all quantities in terms of the link densities , we make the further approximation @xmath101 that the probability @xmath102 is given by the fraction of out - going xy - links pointing to the neighbors using strategy - y from all agents using strategy - x .",
    "note that this assumption does not distinguish between different degrees @xmath46 as @xmath103 is independent of @xmath46 .    finally , using eqs .",
    "( [ eq05 ] ) ,  ( [ moments2 ] ) , and ( [ rhoy ] ) allows us to express all the quantities in eq .",
    "( [ eq02 ] ) in terms of a link density and thus close the equation . the expected value in eq .",
    "( [ eq02 ] ) vanish at long time .",
    "setting the resulting equation to zero gives the link density @xmath14 as a function of the rewiring probability @xmath0 .",
    "the non - trivial solution of @xmath23 is found to be @xmath104 for @xmath105 with @xmath106 and @xmath107 for @xmath108 .",
    "results for @xmath22 follow form @xmath109 .    the analytic results in eqs .",
    "( [ eq10 ] ) and ( [ eq11 ] ) are shown in fig .",
    "[ fig02](b ) ( lines ) for comparison for the case of @xmath17 .",
    "the results and the simulation results are in good agreement .",
    "the theory captures the two phases and the behavior of the phase transition .",
    "there are slight discrepancies near the phase transition .",
    "the theory predicts that @xmath110 for @xmath17 , which is slightly lower than @xmath111 obtained by numerical simulations .",
    "the theory predicts a shift in @xmath30 to a higher value with increasing @xmath6 , which is a feature also observed in numerical simulations .",
    "the discrepancies between analytic and simulation results , despite small , reveals important information on the validity of the assumptions in the mean - field approach and the effects of the co - evolving mechanism , as we now show . in every turn",
    ", the active agent may win , lose , or draw .",
    "recording the probabilities of winning , losing , and drawing of the active agents over many rounds , the averages @xmath112 , @xmath113 and @xmath114 of these probabilities for the active agents can be obtained .",
    "due to the cyclic symmetry of the strategies , we could focus on any strategy for an active agent , say r , and express the three probabilities as follows : @xmath115 the quantities @xmath116 , @xmath117 and @xmath118 were introduced in eq .",
    "( [ moments2 ] ) .",
    "they are conditional probabilities of encountering a neighbor using strategies - r , p and s respectively , given that the strategy of the active agent is r and the degree is @xmath46 . in the present context",
    ", they are also the probabilities of winning ( @xmath119 ) , drawing ( @xmath120 ) and losing ( @xmath121 ) of an active agent who has a degree @xmath46 .    ,",
    "@xmath113 and @xmath114 in the steady state as a function of @xmath0 .",
    "the simulation data are obtained by averaging over 300 realizations in networks of @xmath122 .",
    "the mean degree is @xmath17 . ]",
    "[ fig03 ] shows the numerical results of these probabilities as a function of @xmath0 for the case of mean degree @xmath17 .",
    "these results are illuminating . at @xmath36 , @xmath123 . a slight deviation from @xmath36",
    "immediately makes @xmath124 , @xmath125 and @xmath114 different from 1/3 with a jump . for @xmath126",
    ", these quantities also illustrate the existence of two phases . in the active phase , @xmath112 and @xmath114 drops monotonically with @xmath0 and",
    "vanish for @xmath108 , while @xmath113 increases monotonically with @xmath0 and becomes unity for @xmath108 .",
    "the most important feature is @xmath127 for active agents in the active phase , i.e. , active agents are more likely to win on average .",
    "in contrast , passive agents are more likely to loss on average .",
    "thus , examining the numerical results of @xmath124 , @xmath125 and @xmath114 indicates a deficiency in the theory .",
    "the theory assumes @xmath128 and approximates them by @xmath129 ( see eq .",
    "( [ rhoy ] ) ) .",
    "the analytic results of @xmath112 , @xmath114 and @xmath113 are also shown in fig .",
    "[ fig03 ] ( lines ) for comparison . for a large part of @xmath0 below @xmath30",
    ", the analytic results lie between the actual @xmath112 and @xmath114 .",
    "however , for @xmath130 , the analytic results go below both @xmath112 and @xmath114 .",
    "the analytic results are in exact agreement with the simulation results right at @xmath36 , but do not predict the jump in @xmath112 , @xmath113 and @xmath114 for any deviation from @xmath36 .",
    "we now discuss the validity of the mean field theory in light of these features . in the theory ,",
    "the quantity @xmath131 , which is the fraction of links to neighbors using strategy - y for agents using strategy - x and having @xmath46 neighbors , is approximated by eq .",
    "( [ rhoy ] ) and assumed to be independent of @xmath46 .",
    "thus , @xmath119 , @xmath121 and @xmath121 are also assumed to be independent of @xmath46 . at @xmath36 , there is no rewiring .",
    "the network is static and every agent has the same number @xmath6 of neighbors . the fact that the theory gives the correct value at @xmath36 but not for @xmath132 implies that the spread in the values of @xmath46 becomes important when rewiring is present .",
    "indeed , agents acquire different values of @xmath46 due to the rewiring mechanism .",
    "[ fig04 ] shows the simulation results of @xmath119 and @xmath121 as a function of @xmath46 at a fixed @xmath133 for two different systems of @xmath17 and @xmath32 .",
    "we also recorded the winning and losing probabilities @xmath134 and @xmath135 of passive agents of degree @xmath46 and showed the results .",
    "it is important to note that @xmath119 and @xmath121 do depend on @xmath46 , and so do @xmath134 and @xmath135 .",
    "this dependence on @xmath46 , which enters for any @xmath136 , causes the mean field theory to miss the jump in the probabilities as @xmath0 starts to take on finite values ( see fig .",
    "[ fig03 ] ) .    closer inspection of the results in fig .  [ fig04 ]",
    "reveal that @xmath137 and @xmath138 for @xmath139 ; but @xmath140 and @xmath141 for @xmath142 .",
    "although the results in fig .  [ fig04 ] were obtained for @xmath133 , we examined the range of @xmath143 and found the same features .",
    "thus , an active or passive agent with a degree smaller ( larger ) than the mean degree @xmath6 is more likely to win than to lose ( to lose than to win ) in a rps game , while the probabilities of winning and losing of an active or passive agent who has a degree @xmath144 are nearly identical .",
    "more importantly , @xmath145 and @xmath146 for all @xmath46 , implying that an active agent is more likely to win than a passive agent of the same @xmath46 .",
    "the @xmath46-dependence of the winning and losing probabilities can be understood qualitatively as follows .",
    "an agent takes actions to make his neighborhood better , i.e. , to enhance his chance of winning .",
    "switching strategy helps an active agent to win over the same opponent if they meet again ( provided that their strategies are not further altered before they meet again ) .",
    "rewiring dissatisfying link lowers the losing probability of an active agent when he becomes involved in a rps game later . generally , the neighborhood of an active ( a passive ) agent gets better ( gets worse ) after an adaptive action takes place .",
    "the probability of an agent to be chosen as an active agent in a time step is @xmath147 .",
    "however , the probability of an agent being a passive agent depends on his degree @xmath46 . ignoring spatial correction in the network for simplicity , the probability of being a passive agent is @xmath148 , as given by the ratio of his out - links to the total number of out - links in the network . here , the ratio @xmath149 emerges . for agents with @xmath150 ,",
    "they are more likely to be active agents and thus a better chance to shape his neighborhood to his advantage .",
    "the more favorable neighborhood gives them a larger winning probability than losing in the next rps game , no matter which role they play .",
    "therefore , the co - evolving mechanism leads to @xmath151 and @xmath152 for @xmath150 , as shown in fig .",
    "[ fig04 ] . following a similar argument",
    ", agents with @xmath153 are more likely to be passive agents . on one hand",
    ", they do not have much chance to make his neighborhood better . on the other hand ,",
    "their neighbors adaptive actions make the neighborhood worse .",
    "these agents will have a higher losing probability than winning .",
    "therefore , the co - evolving mechanism leads to @xmath140 and @xmath141 for @xmath142 , also observed in fig .",
    "[ fig04 ] .",
    "the physical picture is that agents with many neighbors ( high @xmath46 ) are those often defeated by their neighbors and so the neighbors want to keep the relationship , while agents with only a few neighbors can protect themselves from losing and strive for higher chance of winning in the next rps game .",
    "the analysis on how @xmath119 and @xmath121 depend on @xmath46 brings out the inadequacy of the mean field theory in capturing the spatial correlation between neighboring agents strategies after the system evolves to a steady state .",
    "the results in fig .",
    "[ fig04 ] imply @xmath154 for @xmath155 while @xmath156 for @xmath157 .",
    "such correlations are not captured by the approximation of @xmath158 by eq .",
    "( [ rhoy ] ) .",
    "this inadequacy also leads to the discrepancies in evaluating @xmath14 and @xmath11 for @xmath143 , in addition to @xmath112 , @xmath113 and @xmath114 . finally , the analysis in fig .",
    "[ fig04 ] provides an understanding of why the averaged probabilities @xmath159 , as shown in fig .",
    "[ fig03 ] .",
    "it is a combined effect of ( i ) a randomly selected neighbor ( passive agent ) is expected to have a higher degree than a randomly selected agent ( active agent ) @xcite , and ( ii ) @xmath160 ( @xmath146 ) and they decrease ( increase ) monotonically as @xmath46 increases ( see fig .",
    "[ fig04 ] ) .",
    "to summarize , we have proposed and studied an adaptive rock - paper - scissors model ( arps ) in detail , with a focus on issues related to formulating a mean field theory for co - evolving network problems with multiple strategies . in arps ,",
    "three cyclically dominating strategies are involved in a co - evolving network .",
    "an agent with a dissatisfied neighbor takes action to improve his competing neighborhood by rewiring the dissatisfying link with a probability @xmath0 or switching to a strategy that could defeat the neighbor with a probability @xmath66 .",
    "the network shows two different phases : an active phase for @xmath2 and a frozen phase for @xmath3 .",
    "the active phase is characterized by one connected network with agents using different strategies continually interacting and taking adaptive actions .",
    "the frozen phase is characterized by three separate clusters of agents using r , p , and s , respectively and terminated adaptive actions .",
    "we have discussed in detail the formulation of a mean - field theory that starts with tracing the changes in a link density due to all possible adaptive actions as the network evolves .",
    "a trinomial closure scheme , which approximates the distribution of different types of lines that an agent carries given his strategy and degree , has been invoked to close the equation . ignoring the dependence on the degree",
    ", the theory gives an analytic expression for the link density as a function of @xmath0 .",
    "the results agree with simulation results well and capture the two - phase structure .",
    "closer examination of the small deviations between analytic and simulation results turns out to be illuminating .",
    "we have studied the averaged probabilities of winning ( @xmath112 ) , drawing ( @xmath113 ) and losing ( @xmath114 ) for active agents .",
    "it was found that @xmath112 is always higher than @xmath114 in the active phase - a feature that the mean field theory does not capture .",
    "the origin has been traced to the spread in the degrees among agents due to rewiring _ and _ the dependence of the winning and losing probabilities on the degree of agents .",
    "we have found that agents with a degree smaller ( larger ) than the mean degree @xmath6 have a larger ( smaller ) probability of winning than losing .",
    "physically , active agents tend to have smaller degrees than passive agents because links are retained or increased only for agents who are being taken advantage of .",
    "the results are useful in that the inclusion of correlations between the nearest neighbors strategies and degrees should give a more accurate theory .",
    "we close with a discussion on a few possible extensions . in the present work , we simplified the discussion by using the symmetry that comes from the cyclically dominating strategies as well as the random initial strategy assignments",
    ". it will be interesting to study the sensitivity of the steady state to different initial strategy distributions .",
    "the theory presented here can also be modified to study the problem . here , we discussed the analytic approach not only for applying the results to arps , but also in a general way that could be readily modified to other co - evolving network models involving multiple strategies .",
    "these models need not be cyclically dominating and the number of strategies could be more than three .",
    "the detailed study on the reasons of the small deviation between analytic and simulation results provides useful information on how better theories can be formulated .",
    "the analytic results also provides a guide for further studies on the scaling behavior near the transition between the two phases .",
    "99 g. szab and g. fth , phys . rep .",
    "* 446 * , 97 ( 2007 ) . c. castellano , s. fortunato , and v. loreto , rev .",
    "phys . * 81 * , 591 ( 2009 ) .",
    "j. hofbauer and k. sigmund , _ evolutionary games and population dynamics _",
    "( cambridge university press , cambridge , 1998 ) . b. skyrms , _ the stag hunt and the evolution of social structure _ ( cambridge university press , cambridge , 2004 ) .",
    "r. axelrod , _ the evolution of cooperation _ ( basic , new york , 1984 ) .",
    "a. szolnoki , m. mobilia , l .- l .",
    "jiang , b. szczesny , a. m. rucklidge , and m. perc , j. r. soc .",
    "interface * 11 * , 20140735 ( 2014 ) .",
    "zhou , contemp .",
    "phys . * 57 * , 151 ( 2016 ) .",
    "b. sinervo and c. m. lively , nature * 380 * , 240 ( 1996 ) .",
    "l. w. buss and j. b. c. jasckson , am .",
    "nat . * 113 * , 223 ( 1979 ) .",
    "b. kerr , m. a. riley , m. w. feldman , and b. j. m. bohannan , nature * 418 * , 171 ( 2002 ) .",
    "b. c. kirkup and m. a. riley , nature * 428 * , 412 ( 2004 ) .",
    "g. krolyi , z. neufeld , and i. scheuring , j. theor . biol . * 236 * , 12 ( 2005 ) .",
    "r. durrett and s. levin , theor .",
    ". biol . * 53 * , 30 ( 1998 ) .",
    "z. wang , b. xu , and h .- j .",
    "zhou , sci .",
    "rep . * 4 * , 5830 ( 2014 ) .",
    "k. tainaka , phys .",
    "e * 50 * , 3401 ( 1994 ) .",
    "g. szab , a. szolnoki , and r. izsk , j. phys .",
    "a * 37 * , 2599 ( 2004 ) .",
    "a. szolnoki and g. szab , phys .",
    "e * 70 * , 037102 ( 2004 ) .",
    "t. gross and b. blasius , j. r. soc .",
    "interface * 5 * , 259 ( 2008 ) .",
    "m. perc and a. szolnoki , biosystems * 99 * , 109 ( 2010 ) .",
    "o. grser , c. xu , and p. m. hui , europhys . lett . * 87 * , 38003 ( 2009 ) .",
    "w. zhang , y. s. li , c. xu , and p. m. hui , physica a * 443 * , 161 ( 2016 )",
    ". f. vazquez , v. m. eguluz , and m. s. miguel , phys .",
    "* 100 * , 108702 ( 2008 ) .",
    "o. grser , c. xu , and p. m. hui , new j. phys .",
    "* 13 * , 083015 ( 2011 ) .",
    "m. ji , c. xu , c. w. choi , and p. m. hui , new j. phys .",
    "* 15 * , 113024 ( 2013 ) . c. nardini , b. kozma , and a. barrat , phys .",
    "* 100 * , 158701 ( 2008 ) .",
    "zhu , h. kong , l. li , z .- m .",
    "gu , and s .- j .",
    "xiong , phys .",
    "a * 375 * , 1378 ( 2011 ) . c. w. choi , c. xu , and p. m. hui , phys lett .",
    "a * 379 * , 3029 ( 2015 ) .",
    "w. zhang , c. xu , and p. m. hui , eur .",
    "j. b * 86 * , 196 ( 2013 ) .",
    "w. zhang , y. s. li , p. du , c. xu , and p. m. hui , phys .",
    "e * 90 * , 052819 ( 2014 ) .",
    "e. h. w. xu , w. wang , c. xu , m. tang , y. do , and p. m. hui , phys .",
    "e * 92 * , 022812 ( 2015 ) .",
    "g. demirel , r. prizak , p. n. reddy , and t. gross , eur .",
    "j. b * 84 * , 541 ( 2011 ) .",
    "l. wasserman , _ all of statistics : a concise course in statistical inference _",
    "( springer , berlin , 2004 ) . c. forbes , m. evans , n. hastings and b. peacock , _ statistical distributions _ , john wiley & sons , hoboken , 2011 .",
    "s. l. feld , am .",
    "j. sociol .",
    "* 96 * , 1464 ( 1991 ) ."
  ],
  "abstract_text": [
    "<S> a co - evolving and adaptive rock ( r)-paper ( p)-scissors ( s ) game ( arps ) in which an agent uses one of three cyclically dominating strategies is proposed and studied numerically and analytically . </S>",
    "<S> an agent takes adaptive actions to achieve a neighborhood to his advantage by rewiring a dissatisfying link with a probability @xmath0 or switching strategy with a probability @xmath1 . </S>",
    "<S> numerical results revealed two phases in the steady state . </S>",
    "<S> an active phase for @xmath2 has one connected network of agents using different strategies who are continually interacting and taking adaptive actions . </S>",
    "<S> a frozen phase for @xmath3 has three separate clusters of agents using only r , p , and s , respectively with terminated adaptive actions . </S>",
    "<S> a mean - field theory of link densities in co - evolving network is formulated in a general way that can be readily modified to other co - evolving network problems of multiple strategies . </S>",
    "<S> the analytic results agree with simulation results on arps well . </S>",
    "<S> we point out the different probabilities of winning , losing , and drawing a game among the agents as the origin of the small discrepancy between analytic and simulation results . as a result of the adaptive actions , </S>",
    "<S> agents of higher degrees are often those being taken advantage of . </S>",
    "<S> agents with a smaller ( larger ) degree than the mean degree have a higher ( smaller ) probability of winning than losing . </S>",
    "<S> the results are useful in future attempts on formulating more accurate theories . </S>"
  ]
}