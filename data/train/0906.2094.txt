{
  "article_text": [
    "ever since it was introduced in @xcite , the notion of a nash equilibrium and its refinements have remained among the most prominent solution concepts of noncooperative game theory . in its turn , not only has noncooperative game theory found applications in such diverse topics as economics , biology and network design , but it has also become the standard language to actually _ describe _ complex agent interactions in these fields .    still , the issue of why and how players may arrive to equilibrial strategies in the first place remains an actively debated question .",
    "after all , the complexity of most games increases exponentially with the number of players and , hence , identifying a game s equilibria quickly becomes prohibitively difficult .",
    "accordingly , as was first pointed out by aumann in @xcite , a player has no incentive to play his component of a nash equilibrium unless he is convinced that all other players will play theirs . and",
    "if the game in question has multiple nash equilibria , this argument gains additional momentum : in that case , even players with unbounded deductive capabilities will be hard - pressed to choose a strategy .    from this point of view",
    ", rational individuals would appear to be more in tune with aumann s notion of a correlated equilibrium where subjective beliefs are also taken into account @xcite .",
    "nevertheless , the seminal work of maynard smith on animal conflicts @xcite has cast nash equilibria in a different light because it unearthed a profound connection between evolution and rationality : roughly speaking , one leads to the other .",
    "so , when different species contend for the limited resources of their habitat , evolution and natural selection steer the ensuing conflict to an equilibrial state which leaves no room for irrational behavior . as a consequence ,",
    "instinctive `` fight or flight '' responses that are deeply ingrained in a species can be seen as a form of rational behavior , acquired over the species evolutionary course .",
    "of course , this evolutionary approach concerns large populations of different species which are rarely encountered outside the realm of population biology .",
    "however , the situation is not much different in the case of a finite number of players who try to learn the game by playing again and again and who strive to do better with the help of some learning algorithm .",
    "therein , evolution does not occur as part of a birth / death process ; rather , it is a byproduct of the players acquired experience in playing the game  see @xcite for a most comprehensive account .",
    "it is also worth keeping in the back of our mind that in some applications of game theory , `` rationality '' requirements precede evolution .",
    "for example , recent applications to network design start from a set of performance aspirations ( such as robustness and efficiency ) that the players ( network devices ) seek to attain in the network s equilibrial state .",
    "thus , to meet these requirements , one has to literally reverse - engineer the process by finding the appropriate game whose equilibria will satisfy the players  the parallel with mechanism design being obvious .    in all these approaches ,",
    "a fundamental selection mechanism is that of the _ replicator dynamics _ put forth in @xcite and @xcite which reinforces a strategy proportionately to the difference of its payoff from the mean ( taken over the species or the player s strategies , depending on the approach ) . as was shown in the multi - population setting of samuelson and zhang @xcite ( which is closer to learning than the self - interacting single - population scenaria of @xcite and @xcite ) , these dynamics are particularly conducive to rationality .",
    "strategies that are suboptimal when paired against any choice of one s adversaries rapidly become extinct , and in the long run , only rationally admissible strategies can survive .",
    "even more to the point , the only attracting states of the dynamics turn out to be precisely the ( strict ) nash equilibria of the game  see @xcite for a masterful survey .",
    "we thus see that nash equilibria arise over time as natural attractors for rational individuals , a fact which further justifies their prominence among noncooperative solution concepts . yet , this behavior is also conditional on the underlying game remaining stationary throughout the time horizon that it takes players to adapt to it  and unfortunately , this stationarity assumption is rarely met in practical applications . in biological models , for example , the reproductive fitness of an individual may be affected by the ever - changing weather conditions ; in networks , communication channels carry time - dependent noise and interference as well as signals ; and when players try to sample their strategies , they might have to deal with erroneous or imprecise readings .",
    "it is thus logical to ask : _ does rational behavior still emerge in the presence of stochastic perturbations that interfere with the underlying game _ ?    in evolutionary games ,",
    "these perturbations traditionally take the form of `` aggregate shocks '' that are applied directly to the population of each phenotype .",
    "this approach by fudenberg and harris @xcite has spurred quite a bit of interest and there is a number of features that differentiate it from the deterministic one .",
    "for example , cabrales showed in @xcite that dominated strategies indeed become extinct , but only if the variance of the shocks is low enough .",
    "more recently , the work of imhof and hofbauer @xcite revealed that even equilibrial play arises over time but again , conditionally on the variance of the shocks .",
    "be that as it may , if one looks at games with a finite number of players , it is hardly relevant to consider shocks of this type because there are no longer any populations to apply them to .",
    "instead , the stochastic fluctuations should be reflected directly on the stimuli that incite players to change their strategies : their payoffs .",
    "this leads to a picture which is very different from the evolutionary one and is precisely the approach that we will be taking .      in this paper",
    ", we analyze the evolution of players in stochastically perturbed games of this sort .",
    "the particular stimulus - response model that we consider is simple enough : players keep cumulative scores of their strategies performance and employ exponentially more often the one that scores better .",
    "after a few preliminaries in section [ sec : preliminaries ] , this approach is made precise in section  [ sec : replicator ] where we derive the stochastic replicator equation that governs the behavior of players when their learning curves are subject to random perturbations .",
    "the replicator equation that we get is different from the `` aggregate shocks '' approach of @xcite and , as a result , it exhibits markedly different rationality properties as well . in stark contrast to the results of @xcite , we show in section [ sec : dominated ] that dominated strategies become extinct irrespective of the noise level ( proposition [ prop : dominated ] ) and provide an exponential bound for the rate of decay of these strategies ( proposition [ prop : timetolive ] ) .",
    "in fact , by induction on the rounds of elimination of dominated strategies , we show that this is true even for _ iteratively _ dominated strategies : despite the noise , only rationally admissible strategies can survive in the long run ( theorem [ thm : rational ] ) .",
    "then , as an easy corollary of the above , we infer that players will converge to a strict equilibrium ( corollary [ cor : dominance ] ) whenever the underlying game is dominance - solvable .",
    "we continue with the issue of equilibrial play in section [ sec : congestion ] by making a suggestive detour in the land of congestion games . if the noise is relatively mild with respect to the rate with which players learn , we find that the game s potential is a lyapunov function which ensures that strict equilibria are stochastically attracting ; and if the game is dyadic ( i.e. , players only have two choices ) , this tameness assumption can be dropped altogether .    encouraged by the results of section [ sec : congestion ] , we attack the general case in section  [ sec : equilibrium ] .",
    "as it turns out , strict equilibria are _ always _ asymptotically stochastically stable in the perturbed replicator dynamics that stem from exponential learning ( theorem  [ thm : stability ] ) .",
    "this begs to be compared to the results of @xcite where it is the equilibria of a suitably modified game that are stable , and not necessarily those of the actual game being played .",
    "fortunately , exponential learning seems to give players a clearer picture of the original game and there is no need for similar modifications in our case .      given a finite set @xmath0 , we will routinely identify the set @xmath1 of probability measures on @xmath2 with the standard @xmath3-dimensional simplex of @xmath4 and @xmath5 . under this identification",
    ", we will also make no distinction between @xmath6 and the vertex @xmath7 of @xmath1 ; in fact , to avoid an overcluttering of indices , we will frequently use @xmath8 to refer to either @xmath9 or @xmath7 , writing , for example , `` @xmath10 '' or `` @xmath11 '' instead of `` @xmath6 '' or `` @xmath12 , '' respectively .    to streamline our presentation",
    ", we will consistently employ latin indices for players ( @xmath13 ) and greek for their strategies ( @xmath14 ) , separating the two by a comma when it would have been sthetically unpleasant not to . in like manner , when we have to discriminate between strategies",
    ", we will assume that indices from the first half of the greek alphabet start at @xmath15 ( @xmath16 ) while those taken from the second half start at @xmath17 ( @xmath18 ) .",
    "finally , if @xmath19 is some stochastic process in @xmath20 starting at @xmath21 , its law will be denoted by @xmath22 or simply by @xmath23 if there is no danger of confusion ; and if the context leaves no doubt as to which process we are referring to , we will employ the term `` almost surely '' in place of the somewhat unwieldy `` @xmath23-almost surely . ''",
    "as is customary , our starting point will be a ( finite ) set of @xmath24 _ players _ , indexed by @xmath25 .",
    "the players possible actions are drawn from their _ strategy sets _ @xmath26 and they can combine them by choosing their @xmath27th ( pure ) strategy with probability @xmath28 . in that case , the players _ mixed strategies _ will be described by the points @xmath29 or , more succinctly , by the _ strategy profile _ @xmath30 .    in particular , if @xmath31 denotes the @xmath8th vertex of the @xmath32th component simplex , the ( pure ) profile @xmath33 simply corresponds to player @xmath32 playing @xmath34 . on the other hand ,",
    "if we wish to focus on the strategy of a particular player @xmath35 against that of his _ opponents _ @xmath36 , we will employ the shorthand notation @xmath37 to denote the profile where @xmath32 plays @xmath38 against his opponents strategy @xmath39 .",
    "so , once players have made their strategic choices , let @xmath40 be the reward of player @xmath32 in the profile @xmath41 , that is , the payoff that strategy @xmath34 yields to player @xmath32 against the strategy @xmath42 of @xmath32 s opponents . then",
    ", if players mix their strategies , their expected reward will be given by the ( multilinear ) _ payoff functions _",
    "@xmath43 : @xmath44 under this light , the payoff that a player receives when playing a pure strategy @xmath45 deserves special mention and will be denoted by @xmath46    this collection of _ players",
    "_ @xmath35 , their _ strategies _ @xmath34 and their _ payoffs _ @xmath47 will be our working definition for a _ game in normal form _ , usually denoted by @xmath48or @xmath49 if we need to keep track of more data .",
    "needless to say , rational players who seek to maximize their individual payoffs will avoid strategies that always lead to diminished payoffs against any play of their opponents .",
    "we will thus say that the strategy @xmath38 is ( _ strictly _ ) _ dominated _ by @xmath50 and we will write @xmath51 when @xmath52 for all strategies @xmath53 of @xmath32 s opponents @xmath54 .    with this in mind , dominated strategies can be effectively removed from the analysis of a game because rational players will have no incentive to ever use them .",
    "however , by deleting such a strategy , another strategy ( perhaps of another player ) might become dominated and further deletions of _ iteratively dominated _ strategies might be in order ( see section [ sec : dominated ] for more details ) .",
    "proceeding ad infinitum , we will say that a strategy is _ rationally admissible _ if it survives every round of elimination of dominated strategies .",
    "if the set of rationally admissible strategies is a singleton ( e.g. , as in the prisoner s dilemma ) , the game will be called _ dominance - solvable _ and the sole surviving strategy will be the game s _ rational solution_.    then again , not all games can be solved in this way and it is natural to look for strategies which are stable at least under unilateral deviations .",
    "hence , we will say that a strategy profile @xmath55 is a _",
    "nash equilibrium _ of the game @xmath48 when @xmath56 if the equilibrium profile @xmath57 only contains pure strategies @xmath58 , we will refer to it as a _ pure equilibrium _ ; and if the inequality ( [ eq : nash ] ) is strict for all @xmath59 , the equilibrium @xmath57 will carry instead the characterization _",
    "strict_.    clearly , if two pure strategies @xmath60 are present with positive probability in an equilibrial strategy @xmath61 , then we must have @xmath62 as a result of @xmath47 being linear in @xmath63 .",
    "consequently , only pure profiles can satisfy the strict version of ( [ eq : nash ] ) so that strict equilibria must also be pure .",
    "the converse implication is false but only barely so : a pure equilibrium fails to be strict only if a player has more than one pure strategies that return the same rewards . since this is almost always true ( in the sense that the degenerate case can be resolved by an arbitrarily small perturbation of the payoff functions )",
    ", we will relax our terminology somewhat and use the two terms interchangeably .    to recover the connection of equilibrial play with strategic dominance , note that if a game is solvable by iterated elimination of dominated strategies , the single rationally admissible strategy that survives will be the game s unique strict equilibrium .",
    "but the significance of strict equilibria is not exhausted here : strict equilibria are exactly the evolutionarily stable strategies of multi - population evolutionary games  proposition 5.1 in @xcite . moreover , as we shall see a bit later , they are the only asymptotically stable states of the multi - population replicator dynamics ",
    "again , see chapter 5 , pages 216 and 217 of @xcite .    unfortunately , strict equilibria do not always exist , rock - paper - scissors being the typical counterexample .",
    "nevertheless , pure equilibria do exist in many large and interesting classes of games , even when we leave out dominance - solvable ones .",
    "perhaps the most noteworthy such class is that of _ congestion games_.",
    "[ def : congestion ] a game @xmath64 will be called a _ congestion game _ when :    1 .",
    "all players @xmath35 share a common set of _ facilities _ @xmath65 as their strategy set : @xmath66 for all @xmath35 ; 2 .   the payoffs are functions of the number of players sharing a particular facility : @xmath67 where @xmath68 is the number of players choosing the same facility as @xmath32 .    amazingly enough",
    ", monderer and shapley made the remarkable discovery in @xcite that these games are actually equivalent to the class of _ potential games_.    [ def : potential ] a game @xmath64 will be called a _ potential game _ if there exists a function @xmath69 such that @xmath70 for all players @xmath35 and all strategies @xmath71 , @xmath72 .",
    "this equivalence reveals that both classes of games possess equilibria in pure strategies : it suffices to look at the vertices of the face of @xmath73 where the ( necessarily multilinear ) potential function @xmath74 is minimized .      as one would expect , locating the nash equilibria of a game is a rather complicated problem that requires a great deal of global calculations , even in the case of potential games ( where it reduces to minimizing a multilinear function over a convex polytope ) .",
    "consequently , it is of interest to see whether there are simple and distributed learning schemes that allow players to arrive at a reasonably stable solution .",
    "one such scheme is based on an exponential learning behavior where players play the game repeatedly and keep records of their strategies performance . in more detail , at each instance of the game all players @xmath35 update the cumulative scores @xmath75 of their strategies @xmath45 as specified by the recursive formula @xmath76 where @xmath77 is the players strategy profile at the @xmath78th iteration of the game and , in the absence of initial bias , we assume that @xmath79 for all @xmath80 .",
    "these scores reinforce the perceived success of each strategy as measured by the average payoff it yields and hence , it stands to reason that players will lean towards the strategy with the highest score .",
    "the precise way in which they do that is by playing according to the namesake exponential law : @xmath81    for simplicity , we will only consider the case where players update their scores in continuous time , that is , according to the coupled equations    @xmath82    then , if we differentiate ( [ eq : detlogit ] ) to decouple it from ( [ eq : detscore ] ) , we obtain the _ standard _ ( _ multi - population _ ) _ replicator dynamics _",
    "@xmath83    alternatively ,",
    "if players learn at different speeds as a result of varied stimulus - response characteristics , their updating will take the form @xmath84 where @xmath85 represents the _ learning rate _ of player @xmath32 , that is , the `` weight '' which he assigns to his perceived scores @xmath75 . in this way , the replicator equation evolves at a different time scale for each player , leading to the _ rate - adjusted _ dynamics @xmath86 naturally , the uniform dynamics ( [ eq : rd ] ) are recovered when all players learn at the `` standard '' rate @xmath87 .",
    "if we view the exponential learning model ( [ eq : discretelogit ] ) from a stimulus - response angle , we see that that the payoff of a strategy simply represents an ( exponential ) propensity of employing said strategy .",
    "it is thus closely related to the algorithm of _ logistic fictitious play _",
    "@xcite where the strategy @xmath88 of ( [ eq : ratelogit ] ) can be seen as the ( unique ) best reply to the profile @xmath89 in some suitably modified payoffs @xmath90 .",
    "interestingly enough , @xmath91 turns out to be none other than the _ entropy _ of @xmath88 : @xmath92 that being so , we deduce that the learning rates @xmath85 act the part of ( player - specific ) inverse temperatures : in high temperatures ( small @xmath85 ) , the players learning curves are `` soft '' and the payoff differences between strategies are toned down ; on the contrary , if @xmath93 the scheme `` freezes '' to a myopic best - reply process .",
    "the replicator dynamics were first derived in @xcite in the context of population biology , first for different phenotypes within a single species ( single - population models ) , and then for different species altogether ( multi - population models ; @xcite and @xcite provide excellent surveys ) . in both these cases , one begins with large populations of individuals that are programmed to a particular behavior ( e.g. , for `` hawks '' or for `` doves '' ) and matches them randomly in a game whose payoffs directly affect the reproductive fitness of the individual players .",
    "more precisely , let @xmath94 be the population size of the phenotype ( strategy ) @xmath45 of species ( player ) @xmath95 in some multi - population model where individuals are matched to play a game @xmath48 with payoff functions @xmath47 .",
    "then , the relative frequency ( share ) of @xmath8 will be specified by the _ population state _",
    "@xmath96 where @xmath97 .",
    "so , if @xmath24 individuals are drawn randomly from the @xmath24 species , their expected payoffs will be given by @xmath98 , @xmath35 , and if these payoffs represent a proportionate increase in the phenotype s fitness ( measured as the number of offsprings in the unit of time ) , we will have @xmath99 as a result , the population state @xmath100 will evolve according to @xmath101 which is exactly ( [ eq : rd ] ) viewed from an evolutionary perspective .",
    "on the other hand , we should note here that in _ single - population _ models the resulting equation is cubic and not quadratic because strategies are matched against themselves . to wit , assume that individuals are randomly drawn from a large population and are matched against one another in a ( symmetric ) 2-player game @xmath48 with strategy space @xmath102 and payoff matrix @xmath103 . then",
    ", if @xmath104 denotes the population share of individuals that are programmed to the strategy @xmath105 , their expected payoff in a random match will be given by @xmath106 ; similarly , the population average payoff will be @xmath107 .",
    "hence , by following the same procedure as above , we end up with the single - population replicator dynamics @xmath108 which behave quite differently than their multi - population counterpart ( [ eq : erd ] ) .",
    "as far as rational behavior is concerned , the replicator dynamics have some far - reaching ramifications .",
    "if we focus on multi - population models , samuelson and zhang showed in @xcite that the share @xmath109 of a strategy @xmath45 which is strictly dominated ( even iteratively ) converges to zero along any interior solution path of  ( [ eq : rd ] ) ; in other words , _ dominated strategies become extinct in the long run_. additionally , there is a remarkable equivalence between the game s nash equilibria and the stationary points of the replicator dynamics : _ the asymptotically stable states of coincide precisely with the strict nash equilibria of the underlying game _",
    "@xcite .",
    "a large part of our work will be focused on examining whether the rationality properties of exponential learning ( elimination of dominated strategies and asymptotic stability of strict equilibria ) remain true in a stochastic setting . however , since asymptotic stability is ( usually ) too stringent an expectation for stochastic dynamical systems , we must instead consider its stochastic analogue .",
    "that being the case , let @xmath110 be a standard wiener process in @xmath20 and consider the stochastic differential equation ( sde ) @xmath111 following @xcite , the notion of asymptotic stability in this sde is expressed by the following .",
    "[ def : stability ] we will say that @xmath112 is _ stochastically asymptotically stable _ when , for every neighborhood @xmath113 of @xmath114 and every @xmath115 , there exists a neighborhood @xmath74 of @xmath114 such that @xmath116 for all initial conditions @xmath117 of the sde ( [ eq : sde ] ) .",
    "much the same as in the deterministic case , stochastic asymptotic stability is often established by means of a lyapunov function . in our context , this notion hinges on the second order differential operator that is associated to ( [ eq : sde ] ) , namely the _ generator _",
    "@xmath118 of @xmath19 : @xmath119 the importance of this operator can be easily surmised from it s lemma ; indeed , if @xmath120 is sufficiently smooth , the generator @xmath118 simply captures the drift of the process @xmath121 : @xmath122 in this way , @xmath118 can be seen as the stochastic version of the time derivative @xmath123 ; this analogy then leads to the following .",
    "[ def : lyapunov ] let @xmath112 and let @xmath113 be an open neighborhood of @xmath114 .",
    "we will say that @xmath124 is a ( local ) _ stochastic lyapunov function _ for the sde ( [ eq : sde ] ) if :    1 .",
    "@xmath125 for all @xmath126 , with equality iff @xmath127 ; 2 .",
    "there exists a constant @xmath128 such that @xmath129 for all @xmath126 .",
    "whenever such a lyapunov function exists , it is known that the point @xmath112 where @xmath124 attains its minimum will be stochastically asymptotically stable  for example , see theorem 4 in pages 314 and 315 of @xcite .",
    "a final point that should be mentioned here is that our analysis will be constrained on the compact polytope @xmath130 instead of all of @xmath131 .",
    "accordingly , the `` neighborhoods '' of definitions [ def : stability ] and [ def : lyapunov ] should be taken to mean `` neighborhoods in @xmath73 , '' that is , neighborhoods in the subspace topology of @xmath132 .",
    "this minor point should always be clear from the context and will only be raised in cases of ambiguity .",
    "of course , it could be argued that the rationality properties of the exponential learning scheme are a direct consequence of the players receiving accurate information about the game when they update their scores .",
    "however , this is a requirement that can not always be met : the interference of nature in the game or imperfect readings of one s utility invariably introduce fluctuations in ( [ eq : detscore ] ) , and in their turn , these lead to a perturbed version of the replicator dynamics ( [ eq : rd ] ) .    to account for these random perturbations",
    ", we will assume that the players scores are now governed instead by the _",
    "differential equation @xmath133 where , as before , the strategy profile @xmath134 is given by the logistic law @xmath135 in this last equation , @xmath136 is a standard wiener process living in @xmath131 and the coefficients @xmath137 measure the impact of the noise on the players scoring systems . of course",
    ", these coefficients need not be constant : after all , the effect of the noise on the payoffs might depend on the state of the game in some typically continuous way .",
    "for this reason , we will assume that the functions @xmath138 are continuous on @xmath73 , and we will only note en passant that our results still hold for essentially bounded coefficients @xmath137 ( we will only need to replace @xmath139 and @xmath140 with @xmath141 and @xmath142 , respectively , in all expressions involving @xmath137 ) .    a very important instance of this dependence can be seen if @xmath143 for all @xmath144 , in which case equation ( [ eq : score ] ) becomes a convincing model for the case of insufficient information .",
    "it states that when a player actually uses a strategy , his payoff observations are accurate enough ; but with regards to strategies he rarely employs , his readings could be arbitrarily off the mark .",
    "now , to decouple ( [ eq : score ] ) and ( [ eq : logit ] ) , we may simply apply it s lemma to the process @xmath19 . to that end ,",
    "recall that @xmath136 has independent components across players and strategies , so that @xmath145 ( the kronecker symbols @xmath146 being @xmath15 for @xmath147 and @xmath17 , otherwise )",
    ". then , it s formula gives @xmath148\\\\[-8pt ] & = & \\sum_{\\beta } \\biggl(u_{i\\beta}(x)\\,\\frac{\\partial x_{i\\alpha}}{\\partial u_{i\\beta } } + \\frac{1}{2}\\eta_{i\\beta}^{2}(x)\\,\\frac{\\partial^{2}x_{i\\alpha } } { \\partial u_{i\\beta}^{2 } } \\biggr ) \\,dt\\nonumber\\\\ & & { } + \\sum_{\\beta } \\eta_{i\\beta}(x)\\frac{\\partial x_{i\\alpha } } { \\partial u_{i\\beta } } \\,dw_{i\\beta}.\\nonumber\\end{aligned}\\ ] ] on the other hand , a simple differentiation of ( [ eq : logit ] ) yields    @xmath149    and by plugging these expressions back into ( [ eq : dxprelim ] ) , we get @xmath150 \\,dt\\nonumber\\\\ & & { } + x_{i\\alpha } \\biggl[\\frac{1}{2}\\eta_{i\\alpha}^{2}(x)(1 - 2 x_{i\\alpha } ) - \\frac{1}{2}\\sum_{\\beta}\\eta_{i\\beta}^{2}(x ) x_{i\\beta } ( 1 - 2x_{i\\beta } ) \\biggr ] \\,dt\\\\ & & { } + x_{i\\alpha } \\biggl[\\eta_{i\\alpha}(x ) \\,dw_{i\\alpha } - \\sum_{\\beta } \\eta _ { i\\beta}(x ) x_{i\\beta } \\,dw_{i\\beta } \\biggr]\\nonumber.\\end{aligned}\\ ] ] alternatively , if players update their strategies with different learning rates @xmath85 , we should instead apply it s formula to ( [ eq : ratelogit ] ) .",
    "in so doing , we obtain    @xmath151 \\,dt\\nonumber\\\\ & & { } + \\frac{\\lambda_{i}^{2}}{2}x_{i\\alpha } \\biggl[\\eta_{i\\alpha}^{2}(x)(1 - 2 x_{i\\alpha } ) -\\sum_{\\beta}\\eta_{i\\beta}^{2}(x ) x_{i\\beta } ( 1 - 2x_{i\\beta } ) \\biggr ] \\,dt\\nonumber\\\\[-8pt]\\\\[-8pt ] & & { } + \\lambda_{i } x_{i\\alpha } \\bigl[\\eta_{i\\alpha}(x)\\ , d w_{i\\alpha } - \\sum\\eta_{i\\beta}(x ) x_{i\\beta } \\,dw_{i\\beta } \\bigr]\\nonumber\\\\ & = & b_{i\\alpha}(x ) \\,dt + \\sum_{\\beta } \\sigma_{i,\\alpha\\beta } ( x ) \\,d w_{i\\beta},\\nonumber\\end{aligned}\\ ] ]    where , in obvious notation , @xmath152 and @xmath153 are , respectively , the drift and diffusion coefficients of the diffusion @xmath19 .",
    "obviously , when @xmath87 , we recover the uniform dynamics ( [ eq : srd ] ) ; equivalently ( and this is an interpretation that is well worth keeping in mind ) , the rates @xmath154 can simply be regarded as a commensurate inflation of the payoffs and noise coefficients of player @xmath35 in the uniform logistic model ( [ eq : logit ] ) .",
    "equation ( [ eq : srd ] ) and its rate - adjusted sibling ( [ eq : slrd ] ) will constitute our stochastic version of the replicator dynamics and thus merit some discussion in and by themselves . first , note that these dynamics admit a ( unique ) strong solution for any initial state @xmath155 , even though they do not satisfy the linear growth condition @xmath156 that is required for the existence and uniqueness theorem for sdes ( e.g. , theorem 5.2.1 in @xcite ) .",
    "instead , an addition over @xmath45 reveals that every simplex @xmath157 remains invariant under ( [ eq : srd ] ) : if @xmath158 , then @xmath159 and hence , @xmath160 will stay in @xmath161 for all @xmath162actually , it is not harder to see that every face of @xmath73 is a trap for @xmath19 .",
    "so , if @xmath163 is a smooth bump function that is equal to @xmath17 on some open neighborhood of @xmath164 and which vanishes outside some compact set @xmath165 , the sde    @xmath166    _ will _ have bounded diffusion and drift coefficients and will thus admit a unique strong solution .",
    "but since this last equation agrees with ( [ eq : srd ] ) on @xmath73 and any solution of ( [ eq : srd ] ) always stays in @xmath73 , we can easily conclude that our perturbed replicator dynamics admit a unique strong solution for any initial @xmath167 .",
    "it is also important to compare the dynamics ( [ eq : srd ] ) , ( [ eq : slrd ] ) to the `` aggregate shocks '' approach of fudenberg and harris @xcite that has become the principal incarnation of the replicator dynamics in a stochastic environment .",
    "so , let us first recall how aggregate shocks enter the replicator dynamics in the first place .",
    "the main idea is that the reproductive fitness of an individual is not only affected by deterministic factors but is also subject to stochastic shocks due to the `` weather '' and the interference of nature with the game .",
    "more precisely , if @xmath168 denotes the population size of phenotype @xmath45 of the species @xmath95 in some multi - population evolutionary game @xmath48 , its growth will be determined by @xmath169 where , as in ( [ eq : offspring ] ) , @xmath134 denotes the population shares @xmath170 . in this way , it s lemma yields the _ replicator dynamics with aggregate shocks _ : @xmath171 \\,dt\\nonumber\\\\[-8pt]\\\\[-8pt ] & & { } + x_{i\\alpha } \\bigl[\\eta_{i\\alpha } \\,dw_{i\\alpha } - \\sum\\eta _ { i\\beta } x_{i\\beta } \\,dw_{i\\beta } \\bigr].\\nonumber\\end{aligned}\\ ] ]    we thus see that the effects of noise propagate differently in the case of exponential learning and in the case of evolution . indeed , if we compare equations ( [ eq : srd ] ) and ( [ eq : asrd ] ) term by term , we see that the drifts are not quite the same : even though the payoff adjustment @xmath172 ties both equations back together in the deterministic setting ( @xmath173 ) , the two expressions differ by @xmath174 \\,dt.\\ ] ] innocuous as this term might seem , it is actually crucial for the rationality properties of exponential learning in games with randomly perturbed payoffs .",
    "as we shall see in the next sections , it leads to some miraculous cancellations that allow rationality to emerge in all noise levels .",
    "this difference further suggests that we can pass from ( [ eq : srd ] ) to ( [ eq : asrd ] ) simply by modifying the game s payoffs to @xmath175 .",
    "of course , this presumes that the noise coefficients @xmath137 be constant ",
    "the general case would require us to allow for games whose payoffs may not be multilinear . this apparent lack of generality does not really change things but we prefer to keep things simple and for the time being , it suffices to point out that this modified game was precisely the one that came up in the analysis of @xcite . as a result",
    ", this modification appears to play a pivotal role in setting apart learning and evolution in a stochastic setting : whereas the modified game is deeply ingrained in the process of natural selection , exponential learning seems to give players a clearer picture of the actual underlying game .",
    "thereby armed with the stochastic replicator equations ( [ eq : srd ] ) , ( [ eq : slrd ] ) to model exponential learning in noisy environments , the logical next step is to see if the rationality properties of the deterministic dynamics carry over to this stochastic setting . in this direction , we will first show that dominated strategies always become extinct in the long run and that only the rationally admissible ones survive .    as in @xcite ( implicitly ) and @xcite ( explicitly ) , the key ingredient of our approach will be the _ cross entropy _ between two mixed strategies @xmath176 of player @xmath35 : @xmath177 where @xmath178 is the _ entropy _ of @xmath179 and @xmath180 is the intimately related _ kullback  leibler divergence _ ( or _ relative entropy _ )",
    ": @xmath181 this divergence function is central in the stability analysis of the ( deterministic ) replicator dynamics because it serves as a distance measure in probability space  @xcite .",
    "as it stands however , @xmath180 is not a distance function per se : neither is it symmetric , nor does it satisfy the triangle inequality .",
    "still , it has the very useful property that @xmath182 iff @xmath88 employs with positive probability all pure strategies @xmath45 that are present in @xmath179 [ i.e. , iff @xmath183 or iff @xmath179 is absolutely continuous w.r.t .",
    "@xmath88 ] . therefore ,",
    "if @xmath185 for all dominated strategies @xmath179 of player @xmath32 , it immediately follows that @xmath88 can not be dominated itself . in this vein , we have the following .    [ prop : dominated ] let @xmath19 be a solution of the stochastic replicator dynamics ( [ eq : srd ] ) for some interior initial condition @xmath186 .",
    "then , if @xmath38 is ( strictly ) dominated , @xmath187 in particular , if @xmath188 is pure , we will have @xmath189 ( a.s . ) : strictly dominated strategies do not survive in the long run .",
    "note first that @xmath190 and hence , @xmath160 will almost surely stay in @xmath191 for all @xmath192 ; this is a simple consequence of the uniqueness of strong solutions and the invariance of the faces of @xmath193 under the dynamics ( [ eq : srd ] ) .",
    "let us now consider the cross entropy @xmath194 between @xmath179 and @xmath160 : @xmath195 as a result of @xmath160 being an interior path , @xmath194 will remain finite for all @xmath162 ( a.s . ) .",
    "so , by applying it s lemma we get @xmath196\\\\[-8pt ] & = & -\\sum_{\\beta } \\frac{q_{i\\beta}}{x_{i\\beta } } \\,dx_{i\\beta } + \\frac{1}{2 } \\sum_{\\beta } \\frac{q_{i\\beta}}{x_{i\\beta}^{2 } } ( d x_{i\\beta } ) ^{2}\\nonumber\\end{aligned}\\ ] ] and , after substituting @xmath197 from the dynamics ( [ eq : srd ] ) , this last equation becomes @xmath198 \\,dt\\nonumber\\\\[-8pt]\\\\[-8pt ] & & { } + \\sum_{\\beta } q_{i\\beta}\\sum_{\\gamma } ( x_{i\\gamma } - \\delta _ { \\beta \\gamma } ) \\eta_{i\\gamma } ( x)\\,dw_{i\\gamma}.\\nonumber\\end{aligned}\\ ] ]    accordingly , if @xmath199 is another mixed strategy of player @xmath32 , we readily obtain @xmath200\\\\[-8pt ] & & { } + \\sum_{\\beta } ( q_{i\\beta } ' - q_{i\\beta } ) \\eta_{i\\beta}(x ) \\,dw_{i\\beta}\\nonumber\\end{aligned}\\ ] ] and , after integrating , @xmath201\\\\[-8pt ] & & { } + \\sum_{\\beta}(q_{i\\beta}'-q_{i\\beta})\\int_{0}^{t}\\eta_{i\\beta } ( x(s ) ) \\,dw_{i\\beta}(s).\\nonumber\\end{aligned}\\ ] ] suppose then that @xmath202 and let @xmath203 . with @xmath204 compact",
    ", it easily follows that @xmath205 and the first term of ( [ eq : gint ] ) will be bounded from below by @xmath206 .",
    "however , since monotonicity fails for it integrals , the second term must be handled with more care . to that end , let @xmath207 and note that the cauchy  schwarz inequality gives @xmath208\\\\[-8pt ] & \\leq & s_{i}\\eta_{i}^{2 } \\sum_{\\beta } ( q'_{i\\beta } -q_{i\\beta})^{2}\\leq 2 s_{i } \\eta_{i}^{2},\\nonumber\\end{aligned}\\ ] ] where @xmath209 is the number of pure strategies available to player @xmath32 and @xmath210 ; recall also that @xmath211 for the last step .",
    "therefore , if @xmath212 denotes the martingale part of ( [ eq : gcomp ] ) and @xmath213 is its quadratic variation , the previous inequality yields @xmath214(t ) = \\int_{0}^{t}\\xi _ { i}^{2}(s)\\,ds \\leq2 s_{i } \\eta_{i}^{2 } t.\\ ] ]    now , if @xmath215 , it follows from the time - change theorem for martingales ( e.g. , theorem 3.4.6 in @xcite ) that there exists a wiener process @xmath216 such that @xmath217 . hence , by the law of the iterated logarithm we get @xmath218 on the other hand , if @xmath219 , it is trivial to obtain @xmath220 by letting @xmath221 in ( [ eq : gint ] ) .",
    "therefore , with @xmath222 , we readily get @xmath223 ( a.s . ) ; and since @xmath224 for all pure strategies @xmath45 , our proof is complete .    as in @xcite , we can now obtain the following estimate for the lifespan of pure dominated strategies .",
    "[ prop : timetolive ] let @xmath19 be a solution path of ( [ eq : srd ] ) with initial condition @xmath225 and let @xmath23 denote its law . assume further that the strategy @xmath45 is dominated ; then , for any @xmath226 and for @xmath78 large enough , we have @xmath227 where @xmath228 is the number of strategies available to player @xmath32 , @xmath229 and the constants @xmath205 and @xmath230 do not depend on @xmath78 .",
    "the proof is pretty straightforward and for the most part follows @xcite .",
    "surely enough , if @xmath231 and we use the same notation as in the proof of proposition [ prop : dominated ] , we have @xmath232 where @xmath233 and @xmath234",
    ". then @xmath235\\\\[-8pt ] & = & \\frac{1}{2}\\operatorname{erfc}\\biggl(\\frac{m - h_{i}(x_{i } ) - v_{i}t}{\\sqrt{2\\rho _ { i}(t ) } } \\biggr)\\nonumber\\end{aligned}\\ ] ] and , since the quadratic variation @xmath213 is bounded above by @xmath236 ( [ eq : quvar ] ) , the estimate ( [ eq : timetolive ] ) holds for all sufficiently large @xmath78 [ i.e. , such that @xmath237 .",
    "some remarks are now in order : first and foremost , our results should be contrasted to those of cabrales @xcite and imhof @xcite where dominated strategies die out only if the noise coefficients ( shocks ) @xmath137 satisfy certain tameness conditions . the origin of this notable difference is the form of the replicator equation ( [ eq : srd ] ) and , in particular , the extra terms that are propagated there by exponential learning and which are absent from the aggregate shocks dynamics ( [ eq : asrd ] ) . as can be seen from the derivations in proposition [ prop : dominated ] , these terms are precisely the ones that allow players to pick up on the true payoffs @xmath238 instead of the modified ones @xmath239 that come up in @xcite ( and , indirectly , in @xcite as well ) .",
    "secondly , it turns out that the way that the noise coefficients @xmath240 depend on the profile @xmath241 is not really crucial : as long as @xmath242 is continuous ( or essentially bounded ) , our arguments are not affected . the only way in which a specific dependence influences the extinction of dominated strategies is seen in proposition [ prop : timetolive ] : a sharper estimate of the quadratic variation of @xmath243 could conceivably yield a more accurate estimate for the cumulative distribution function of ( [ eq : timetolive ] ) .",
    "finally , it is only natural to ask if proposition [ prop : dominated ] can be extended to strategies that are only _ iteratively _ dominated . as it turns out , this is indeed the case .",
    "[ thm : rational ] let @xmath19 be a solution path of ( [ eq : srd ] ) starting at @xmath244 . then ,",
    "if @xmath38 is iteratively dominated , @xmath245 that is , _ only rationally admissible strategies survive in the long run . _    as in the deterministic case @xcite , the main idea is that the solution path @xmath19 gets progressively closer to the faces of @xmath246 that are spanned by the pure strategies which have not yet been eliminated .",
    "following @xcite , we will prove this by induction on the rounds of elimination of dominated strategies ; proposition [ prop : dominated ] is simply the case @xmath247 .    to wit ,",
    "let @xmath248 , @xmath249 and denote by @xmath250 the set of strategies @xmath251 that are admissible ( i.e. , not dominated ) with respect to any strategy @xmath252 .",
    "so , if we start with @xmath253 and @xmath254 , we may define inductively the set of strategies that remain admissible after @xmath3 elimination rounds by @xmath255 where @xmath256 ; similarly , the pure strategies that have survived after @xmath3 such rounds will be denoted by @xmath257 .",
    "clearly , this sequence forms a descending chain @xmath258 and the set @xmath259 will consist precisely of the strategies of player @xmath32 that are rationally admissible .",
    "assume then that the cross entropy @xmath260 diverges as @xmath261 for all strategies @xmath262 that die out within the first @xmath263 rounds ; in particular , if @xmath264 this implies that @xmath265 as @xmath266",
    ". we will show that the same is true if @xmath179 survives for @xmath263 rounds but is eliminated in the subsequent one .",
    "indeed , if @xmath267 but @xmath268 , there will exist some @xmath269 such that @xmath270 now , note that any @xmath271 can be decomposed as @xmath272 where @xmath273 is the `` admissible '' part of @xmath89 , that is , the projection of @xmath89 on the subspace spanned by the surviving vertices @xmath274 . hence , if @xmath275 , we will have @xmath205 and , by linearity , @xmath276 moreover , by the induction hypothesis , we also have @xmath277 as @xmath266 .",
    "thus , there exists some @xmath278 such that @xmath279 for all @xmath280 [ recall that @xmath281 is spanned by already eliminated strategies ] .",
    "therefore , as in the proof of proposition [ prop : dominated ] , we obtain for @xmath280 @xmath282 where @xmath283 is a constant depending only on @xmath278 . in this way , the same reasoning as before gives @xmath284 and the theorem follows .    as a result ,",
    "if there exists only one rationally admissible strategy , we get the following .",
    "[ cor : dominance ]",
    "let @xmath19 be an interior solution path of the replicator equation ( [ eq : srd ] ) for some dominance - solvable game @xmath48 and let @xmath285 be the ( unique ) strict equilibrium of @xmath48 . then @xmath286 that is , _ players converge to the game s strict equilibrium _",
    "_ ) .    in concluding this section",
    ", it is important to note that all our results on the extinction of dominated strategies remain true in the adjusted dynamics ( [ eq : slrd ] ) as well : this is just a matter of rescaling . the only difference in using different learning rates @xmath85 comes about in proposition [ prop : timetolive ] where the estimate ( [ eq : timetolive ] ) becomes @xmath287    as it stands , this is not a significant difference in itself because the two estimates are asymptotically equal for large times . nonetheless , it is this very lack of contrast that clashes with the deterministic setting where faster learning rates accelerate the emergence of rationality .",
    "the reason for this gap is that an increased learning rate @xmath85 also carries a commensurate increase in the noise coefficients @xmath288 , and thus deflates the benefits of accentuating payoff differences .",
    "in fact , as we shall see in the next sections , the learning rates do not really allow players to learn any faster as much as they help diminish their shortsightedness : by effectively being lazy , it turns out that players are better able to average out the noise .",
    "having established that irrational choices die out in the long run , we turn now to the question of whether equilibrial play is stable in the stochastic replicator dynamics of exponential learning .",
    "however , before tackling this issue in complete generality , it will be quite illustrative to pay a visit to the class of congestion games where the presence of a potential simplifies things considerably . in this way",
    ", the results we obtain here should be considered as a motivating precursor to the general case analyzed in section [ sec : equilibrium ] .      to begin with",
    ", it is easy to see that the potential @xmath74 of definition [ def : potential ] is a lyapunov function for the deterministic replicator dynamics .",
    "indeed , assume that player @xmath35 is learning at a rate @xmath289 and let @xmath100 be a solution path of the rate - adjusted dynamics ( [ eq : lrd ] ) .",
    "then , a simple differentiation of @xmath290 gives @xmath291\\\\[-8pt ] & = & -\\sum_{i } \\lambda_{i } \\biggl(\\sum_{\\alpha } x_{i\\alpha } u^{2}_{i\\alpha } ( x ) - u_{i}^{2}(x ) \\biggr)\\leq0,\\nonumber\\end{aligned}\\ ] ] the last step following from jensen s inequality  recall that @xmath292 on account of ( [ eq : potential ] ) and also that @xmath293 .",
    "in particular , this implies that the trajectories @xmath100 are attracted to the local minima of @xmath74 , and since these minima coincide with the strict equilibria of the game , we painlessly infer that strict equilibrial play is asymptotically stable in ( [ eq : lrd])as mentioned before , we plead guilty to a slight abuse of terminology in assuming that all equilibria in pure strategies are also strict .",
    "it is therefore reasonable to ask whether similar conclusions can be drawn in the noisy setting of ( [ eq : slrd ] ) . mirroring the deterministic case , a promising way to go about",
    "this question is to consider again the potential function @xmath74 of the game and try to show that it is stochastically lyapunov in the sense of definition [ def : lyapunov ] . indeed ,",
    "if @xmath294 is a local minimum of @xmath74 ( and hence , a strict equilibrium of the underlying game ) , we may assume without loss of generality that @xmath295 so that @xmath296 in a neighborhood of @xmath297 .",
    "we are thus left to examine the negativity condition of definition [ def : lyapunov ] , that is , whether there exists some @xmath128 such that @xmath298 for all @xmath299 sufficiently close to @xmath297 .    to that end ,",
    "recall that @xmath300 and that @xmath301 .",
    "then , the generator @xmath118 of the rate - adjusted dynamics ( [ eq : slrd ] ) applied to @xmath74 produces @xmath302\\\\[-8pt ] & & { } -\\sum_{i,\\alpha } \\frac{\\lambda_{i}^{2}}{2 } x_{i\\alpha } u_{i\\alpha}(x ) \\biggl(\\eta_{i\\alpha}^{2}(1 - 2x_{i\\alpha } ) - \\sum_{\\beta}\\eta_{i\\beta}^{2 } x_{i\\beta}(1 - 2x_{i\\beta } ) \\biggr),\\nonumber\\end{aligned}\\ ] ] where , for simplicity , we have assumed that the noise coefficients @xmath138 are constant",
    ".    we will study ( [ eq : genv ] ) term by term by considering the perturbed strategies @xmath303 where @xmath304 belongs to the face of @xmath193 that lies opposite to @xmath305 ( i.e. , @xmath306 , @xmath307 and @xmath308 ) and @xmath309 measures the distance of player @xmath32 from @xmath305 . in this way",
    ", we get @xmath310\\\\ & = & u_{i,0}(x ) -\\varepsilon_{i } \\sum_{\\mu } y_{i\\mu } \\delta u_{i\\mu } + \\mathcal o(\\varepsilon_{i}^{2 } ) , \\nonumber\\end{aligned}\\ ] ] where @xmath311 .",
    "then , by going back to ( [ eq : genv ] ) , we obtain @xmath312\\nonumber\\\\ & & \\qquad= ( 1-\\varepsilon_{i } ) u_{i,0}(x ) [ u_{i,0}(x ) - u_{i}(x ) ] \\nonumber\\\\ & & \\qquad\\quad { } + \\varepsilon_{i } \\sum_{\\mu } y_{i\\mu } u_{i\\mu } ( x ) [ u_{i\\mu}(x ) - u_{i}(x ) ] \\nonumber\\\\ & & \\qquad= ( 1-\\varepsilon_{i } ) u_{i,0}(x ) \\cdot\\varepsilon_{i } \\sum_{\\mu } y_{i\\mu } \\delta u_{i\\mu}\\\\ & & \\qquad\\quad{}- \\varepsilon_{i } \\sum_{\\mu } y_{i\\mu } u_{i\\mu}(q_{0 } ) \\delta u_{i\\mu } + \\mathcal o(\\varepsilon_{i}^{2 } ) \\nonumber\\\\ & & \\qquad= \\varepsilon_{i } \\sum_{\\mu } y_{i\\mu } u_{i,0}(q_{0 } ) \\delta u_{i\\mu } - \\varepsilon_{i } \\sum_{\\mu } y_{i\\mu } u_{i\\mu}(q_{0 } ) \\delta u_{i\\mu } + \\mathcal o(\\varepsilon_{i}^{2 } ) \\nonumber\\\\ & & \\qquad= \\varepsilon_{i } \\sum_{\\mu } y_{i\\mu } ( \\delta u_{i\\mu } ) ^{2 } + \\mathcal o(\\varepsilon_{i}^{2 } ) .\\nonumber\\end{aligned}\\ ] ] as for the second term of ( [ eq : genv ] ) , some easy algebra reveals that @xmath313\\\\[-8pt ] & & \\qquad\\quad { } + 2(1-\\varepsilon_{i})^{2 } \\eta_{i,0}^{2 } + 2\\varepsilon_{i}^{2}\\sum_{\\mu } \\eta_{i\\mu}^{2 } y_{i\\mu } ^{2}\\nonumber\\\\ & & \\qquad= -\\varepsilon_{i } \\biggl(\\eta_{i,0}^{2 } + \\sum_{\\mu } y_{i\\mu } \\eta _ { i\\mu } ^{2 } \\biggr ) + \\mathcal o(\\varepsilon_{i}^{2 } ) \\nonumber\\end{aligned}\\ ] ] and , after a ( somewhat painful ) series of calculations , we get @xmath314\\\\[-8pt ] & & \\qquad= -\\varepsilon_{i } u_{i,0}(q_{0 } ) \\biggl ( \\eta_{i,0}^{2 } + \\sum_{\\mu}y_{i\\mu}\\eta_{i\\mu}^{2 } \\biggr)\\nonumber\\\\ & & \\qquad\\quad{}+ \\varepsilon_{i}\\sum_{\\mu } y_{i\\mu } u_{i\\mu}(q_{0 } ) ( \\eta_{i\\mu } ^{2 } + \\eta_{i,0}^{2 } ) + \\mathcal o(\\varepsilon_{i}^{2 } ) \\nonumber\\\\ & & \\qquad= -\\varepsilon_{i}\\sum_{\\mu } y_{i\\mu } \\delta u_{i\\mu } ( \\eta _ { i\\mu } ^{2 } + \\eta_{i,0}^{2 } ) + \\mathcal o(\\varepsilon_{i}^{2 } ) .\\nonumber\\end{aligned}\\ ] ] finally , if we assume without loss of generality that @xmath295 and set @xmath315 ( i.e. , @xmath316 and @xmath317 for all @xmath35 , @xmath318 ) , we readily get @xmath319\\\\[-8pt ] & = & -\\sum_{i,\\alpha } u_{i\\alpha}(q_{0 } ) \\xi_{i\\alpha } + \\mathcal o(\\varepsilon^{2 } ) \\nonumber\\\\ & = & \\sum_{i}\\varepsilon_{i}\\sum_{\\mu } y_{i\\mu}\\delta u_{i\\mu } + \\mathcal o(\\varepsilon^{2 } ) , \\nonumber\\end{aligned}\\ ] ] where @xmath320 . therefore , by combining ( [ eq : paystep ] ) , ( [ eq : noisestep ] ) and ( [ eq : potstep ] ) , the negativity condition @xmath321 becomes @xmath322\\nonumber\\\\[-8pt]\\\\[-8pt ] & & \\qquad\\geq k\\sum_{i}\\varepsilon_{i } \\sum_{\\mu } y_{i\\mu}\\delta u_{i\\mu } + \\mathcal o ( \\varepsilon^{2}).\\nonumber\\end{aligned}\\ ] ] hence , if @xmath323 for all @xmath324 , this last inequality will be satisfied for some @xmath128 whenever @xmath325 is small enough .",
    "essentially , this proves the following .",
    "[ prop : potential ] let @xmath326 be a strict equilibrium of a congestion game @xmath48 with potential function @xmath74 and assume that @xmath327 . assume further that the learning rates @xmath85 are sufficiently small so that , for all @xmath328 and all @xmath35 , @xmath329 then @xmath114 is stochastically asymptotically stable in the rate - adjusted dynamics ( [ eq : slrd ] ) .",
    "we thus see that no matter how loud the noise @xmath288 might be , stochastic stability is always guaranteed if the players choose a learning rate that is slow enough as to allow them to average out the noise ( i.e. , @xmath330 ) . of course , it can be argued here that it is highly unrealistic to expect players to be able to estimate the amount of nature s interference and choose a suitably small rate @xmath85 . on top of that , the very form of the condition ( [ eq : payvsnoise ] ) is strongly reminiscent of the `` modified '' game of , a similarity which seems to contradict our statement that exponential learning favors rational reactions in the _ original _ game .",
    "the catch here is that condition ( [ eq : payvsnoise ] ) is only _ sufficient _ and proposition [ prop : potential ] merely highlights the role of a potential function in a stochastic environment . as we shall see in section [ sec : equilibrium ]",
    ", nothing stands in the way of choosing a different lyapunov candidate and dropping requirement ( [ eq : payvsnoise ] ) altogether .      to gain some further intuition into why the condition ( [ eq : payvsnoise ] ) is redundant , it will be particularly helpful to examine the case where players compete for the resources of only two facilities ( i.e. , @xmath331 for all @xmath332 ) and try to learn the game with the help of the uniform replicator equation ( [ eq : srd ] ) .",
    "this is the natural setting for the el farol bar problem @xcite and the ensuing minority game @xcite where players choose to `` buy '' or `` sell '' and are rewarded when they are in the minority  buyers in a sellers market or sellers in an abundance of buyers .",
    "as has been shown in @xcite , such games always possess strict equilibria , even when players have distinct payoff functions .",
    "so , by relabeling indices if necessary , let us assume that @xmath333 is such a strict equilibrium and set .",
    "then , the generator of the replicator equation ( [ eq : srd ] ) takes the form @xmath334\\ , \\frac{\\partial}{\\partial x_{i}}\\nonumber\\\\[-8pt]\\\\[-8pt ] & & { } + \\frac{1}{2}\\sum_{i}x_{i}^{2}(1-x_{i})^{2 } \\eta_{i}^{2}(x)\\ , \\frac { \\partial^{2}}{\\partial x_{i}^{2}},\\nonumber\\end{aligned}\\ ] ] where now @xmath335 and @xmath336 .",
    "it thus appears particularly appealing to introduce a new set of variables @xmath304 such that @xmath337 ; this is just the `` logit '' transformation : @xmath338 . in these new variables , ( [ eq:2dgen ] ) assumes the astoundingly suggestive guise @xmath339 which reveals that the noise coefficients can be effectively decoupled from the payoffs .",
    "we can then take advantage of this by letting @xmath118 act on the function @xmath340 ( @xmath341 ) : @xmath342 hence , if @xmath343 is chosen small enough so that @xmath344 for all sufficiently large @xmath304 [ recall that @xmath345 since @xmath297 is a strict equilibrium ] , we get @xmath346 where @xmath347 . and since @xmath124 is strictly positive for @xmath348 and only vanishes as @xmath349 ( i.e. , at the equilbrium @xmath297 ) , a trivial modification of the stochastic lyapunov method ( see , e.g. , pages 314 and 315 of @xcite ) yields the following .    [ prop : minority ] the strict equilibria of minority games are stochastically asymptotically stable in the uniform replicator equation ( [ eq : srd ] ) .",
    "it is trivial to see that strict equilibria of minority games will also be stable in the rate - adjusted dynamics ( [ eq : slrd ] ) : in that case we simply need to choose @xmath343 such that @xmath350 .",
    "a closer inspection of the calculations leading to proposition  [ prop : minority ] reveals that nothing hinges on the minority mechanism per se : it is ( [ eq:2dygen ] ) that is crucial to our analysis and @xmath118 takes this form whenever the underlying game is a _ dyadic _ one ( i.e. , @xmath351 for all @xmath35 ) . in other words ,",
    "proposition [ prop : minority ] also holds for all games with 2 strategies and should thus be seen as a significant extension of proposition [ prop : potential ] .",
    "[ prop : dyadic ] the strict equilibria of dyadic games are stochastically asym ptotically stable in the replicator dynamics ( [ eq : srd ] ) , ( [ eq : slrd ] ) of exponential learning .",
    "in deterministic environments , the `` folk theorem '' of evolutionary game theory provides some pretty strong ties between equilibrial play and stability : strict equilibria are asymptotically stable in the multi - population replicator dynamics ( [ eq : rd ] ) @xcite . in our stochastic setting",
    ", we have already seen that this is always true in two important classes of games : those that can be solved by iterated elimination of dominated strategies ( corollary [ cor : dominance ] ) and dyadic ones ( proposition [ prop : dyadic ] ) .",
    "although interesting in themselves , these results clearly fall short of adding up to a decent analogue of the folk theorem for stochastically perturbed games",
    ". nevertheless , they are quite strong omens in that direction and such expectations are vindicated in the following .",
    "[ thm : stability ] the strict equilibria of a game @xmath48 are stochastically asymptotically stable in the replicator dynamics ( [ eq : srd ] ) , ( [ eq : slrd ] ) of exponential learning .    before proving theorem",
    "[ thm : stability ] , we should first take a slight detour in order to properly highlight some of the issues at hand . on that account ,",
    "assume again that the profile @xmath352 is a strict equilibrium of @xmath48 .",
    "then , if @xmath297 is to be stochastically stable , say in the uniform dynamics ( [ eq : srd ] ) , one would expect the strategy scores @xmath353 of player @xmath32 to grow much faster than the scores @xmath354 of his other strategies .",
    "this is captured remarkably well by the `` adjusted '' scores    [ eq : ratescore ] @xmath355    where @xmath289 is a sensitivity parameter akin ( but not identical ) to the learning rates of ( [ eq : slrd ] ) ( the choice of common notation is fairly premeditated though ) .",
    "clearly , whenever @xmath356 is large , @xmath353 will be much greater than any other score @xmath357 and hence , the strategy @xmath358 will be employed by player @xmath32 far more often . to see this in more detail ,",
    "it is convenient to introduce the variables    [ eq : ydef ] @xmath359    where @xmath360 is a measure of how close @xmath361 is to @xmath362 and @xmath363 is a direction indicator ; the two sets of coordinates are then related by the transformation @xmath364 , @xmath45 , @xmath365 . consequently , to show that the strict equilibrium @xmath366 is stochastically asymptotically stable in the replicator equation ( [ eq : srd ] ) , it will suffice to show that @xmath360 diverges to infinity as @xmath266 with arbitrarily high probability .",
    "our first step in this direction will be to derive an sde for the evolution of the @xmath367 processes . to that end ,",
    "it s lemma gives @xmath368\\\\[-8pt ] & = & \\sum_{\\beta } \\biggl ( u_{i\\beta}\\frac{\\partial y_{i\\alpha}}{\\partial u_{i\\beta } } + \\frac{1}{2 } \\eta_{i\\beta}^{2 } \\,\\frac{\\partial^{2 } y_{i\\alpha } } { \\partial u_{i\\beta}^{2 } } \\biggr ) \\,dt + \\sum_{\\beta } \\eta_{i\\beta } \\,\\frac{\\partial y_{i\\alpha}}{\\partial u_{i\\beta } } \\,dw_{i\\beta},\\nonumber\\end{aligned}\\ ] ] where , after a simple differentiation of ( [ eq : y0 ] ) , we have    @xmath369\\end{aligned}\\ ] ]    @xmath370    and , similarly , from ( [ eq : ym ] )    @xmath371\\end{aligned}\\ ] ]    @xmath372\\\\[-8pt ] \\frac{\\partial^{2 } y_{i\\mu}}{\\partial u_{i\\nu}^{2 } } & = & \\lambda_{i}^{2 } y_{i\\mu}(\\delta_{\\mu\\nu } - y_{i\\nu})(1 - 2y_{i\\nu}).\\nonumber\\end{aligned}\\ ] ]    in this way , by plugging everything back into ( [ eq : itoy ] ) we finally obtain    [ eq : dy ] @xmath373 \\,dt\\nonumber\\\\[-8pt]\\\\[-8pt ] & & { } + \\lambda_{i } y_{i,0 } \\biggl [ \\eta_{i,0 } \\,dw_{i,0 } -\\sum_{\\mu } \\eta_{i\\mu } y_{i\\mu } \\,dw_{i\\mu } \\biggr],\\nonumber\\\\ \\label{eq : dym } dy_{i\\mu } & = & \\lambda_{i}y_{i\\mu } [ u_{i\\mu } - \\sum_{\\nu } u_{i\\nu } y_{i\\nu } ] \\,dt\\nonumber\\\\ & & { } + \\frac{\\lambda_{i}^{2}}{2}y_{i\\mu } \\biggl[\\eta_{i\\mu}^{2}(1 - 2 y_{i\\mu } ) -\\sum_{\\nu}\\eta_{i\\nu}^{2 } y_{i\\nu } ( 1 - 2y_{i\\nu } ) \\biggr ] \\,dt\\\\ & & { } + \\lambda_{i } y_{i\\mu } \\biggl[\\eta_{i\\mu } \\,dw_{i\\mu } - \\sum_{\\nu } \\eta _ { i\\nu } y_{i\\nu } \\,dw_{i\\nu } \\biggr],\\nonumber\\end{aligned}\\ ] ]    where we have suppressed the arguments of @xmath47 and @xmath288 in order to reduce notational clutter .    this last sde is particularly revealing : roughly speaking , we see that if @xmath85 is chosen small enough , the deterministic term @xmath374 will dominate the rest ( cf . with the `` soft '' learning rates of proposition [ prop : potential ] ) . and",
    ", since we know that strict equilibria are asymptotically stable in the deterministic case , it is plausible to expect the sde ( [ eq : dy ] ) to behave in a similar fashion .",
    "proof of theorem [ thm : stability ] tying in with our previous discussion , we will establish stochastic asymptotic stability of strict equilibria in the dynamics ( [ eq : srd ] ) by looking at the processes @xmath375 of ( [ eq : ydef ] ) . in these coordinates",
    ", we just need to show that for every @xmath376 and any @xmath115 , there exist @xmath377 such that if @xmath378 , then , with probability greater than @xmath379 , @xmath380 and @xmath381 for all @xmath162 . in the spirit of the previous section , we will accomplish this with the help of the stochastic lyapunov method",
    ".    our first task will be to calculate the generator of the diffusion @xmath382 , that is , the second order differential operator @xmath383 where @xmath384 and @xmath385 are the drift and diffusion coefficients of the sde ( [ eq : dy ] ) , respectively .",
    "in particular , if we restrict our attention to sufficiently smooth functions of the form @xmath386 , the application of @xmath118 yields @xmath387\\ , \\frac{\\partial f_{i}}{\\partial y_{i,0}}\\\\ & & { } + \\frac{1}{2 } \\sum_{i\\in\\mathcal{n } } \\lambda_{i}^{2 } y_{i,0}^{2 } \\biggl [ \\eta_{i,0}^{2 } + \\sum_{\\mu } \\eta_{i\\mu}^{2 } y_{i\\mu}^{2 } \\biggr]\\ , \\frac{\\partial^{2 } f_{i}}{\\partial^{2}y_{i,0}}.\\nonumber\\end{aligned}\\ ] ]    therefore , let us consider the function @xmath388 for @xmath389",
    ". with @xmath390 and @xmath391 , ( [ eq : generator ] ) becomes @xmath392\\\\[-8pt ] & & \\hspace*{54.1pt } { } - \\frac{\\lambda_{i}}{2}\\sum_{\\mu } y_{i\\mu}(1-y_{i\\mu})\\eta _ { i\\mu } ^{2 } \\biggr].\\nonumber\\end{aligned}\\ ] ] however , since @xmath366 has been assumed to be a strict nash equilibrium of @xmath48 , we will have @xmath393 for all @xmath394 .",
    "then , by continuity , there exists some positive constant @xmath205 with @xmath395 whenever @xmath396 is large enough ( recall that @xmath397 ) .",
    "so , if we set @xmath398 and pick positive @xmath85 with @xmath399 , we get @xmath400 for all sufficiently large @xmath396 .",
    "moreover , @xmath124 is strictly positive for @xmath348 and vanishes only as @xmath401 .",
    "hence , as in the proof of proposition [ prop : minority ] , our claim follows on account of @xmath124 being a ( local ) stochastic lyapunov function .    finally , in the case of the rate - adjusted replicator dynamics ( [ eq : slrd ] ) , the proof is similar and only entails a rescaling of the parameters @xmath85 .",
    "if we trace our steps back to the coordinates @xmath402 , our lyapunov candidate takes the form @xmath403 .",
    "it thus begs to be compared to the lyapunov function @xmath404 employed by imhof and hofbauer in @xcite to derive a conditional version of theorem [ thm : stability ] in the evolutionary setting . as it turns out , the obvious extension @xmath405 works in our case as well , but the calculations are much more cumbersome and they are also shorn of their ties to the adjusted scores ( [ eq : ratescore ] ) .",
    "we should not neglect to highlight the dual role that the learning rates @xmath85 play in our analysis . in the logistic learning model ( [ eq : ratelogit ] ) , they measure the players convictions and how strongly they react to a given stimulus ( the scores @xmath75 ) ; in this role , they are fixed at the outset of the game and form an intrinsic part of the replicator dynamics ( [ eq : slrd ] ) . on the other hand",
    ", they also make a virtual appearance as free temperature parameters in the adjusted scores ( [ eq : ratescore ] ) , to be softened until we get the desired result . for this reason ,",
    "even though theorem [ thm : stability ] remains true for any choice of learning rates , the function @xmath406 is lyapunov only if the sensitivity parameters @xmath154 are small enough .",
    "it might thus seem unfortunate that we chose the same notation in both cases , but we feel that our decision is justified by the intimate relation of the two parameters .",
    "our aim in this last section will be to discuss a number of important issues that we have not been able to address thoroughly in the rest of the paper ; truth be told , a good part of this discussion can be seen as a roadmap for future research .      in single - population evolutionary models ,",
    "an evolutionarily stable strategy ( ess ) is a strategy which is robust against invasion by mutant phenotypes @xcite .",
    "strategies of this kind can be considered as a stepping stone between mixed and strict equilibria and they are of such significance that it makes one wonder why they have not been included in our analysis .",
    "the reason for this omission is pretty simple : even the weakest evolutionary criteria in multi - population models tend to reject all strategies which are not strict nash equilibria @xcite .",
    "therefore , since our learning model ( [ eq : rd ] ) corresponds exactly to the multi - population environment ( [ eq : erd ] ) , we lose nothing by concentrating our analysis only on the strict equilibria of the game .",
    "if anything , this equivalence between ess and strict equilibria in multi - population settings further highlights the importance of the latter .",
    "however , this also brings out the gulf between the single - population setting and our own , even when we restrict ourselves to 2-player games ( which are the norm in single - population models ) .",
    "indeed , the single - population version of the dynamics ( [ eq : asrd ] ) is : @xmath407 \\,dt\\nonumber\\\\[-8pt]\\\\[-8pt ] & & { } + x_{\\alpha } \\bigl[\\eta_{\\alpha } \\,dw_{\\alpha } - \\sum\\eta_{\\beta } x_{\\beta } \\,dw_{\\beta } \\bigr].\\nonumber\\end{aligned}\\ ] ]    as it turns out , if a game possesses an interior ess and the shocks are mild enough , the solution paths @xmath19 of the ( single - population ) replicator dynamics will be recurrent ( theorem 2.1 in @xcite ) . theorem",
    "[ thm : stability ] rules out such behavior in the case of strict equilibria ( the multi - population analogue of ess ) , but does not answer the following question : if the underlying game only has mixed equilibria , will the solution @xmath19 of the dynamics ( [ eq : srd ] ) be recurrent ?    this question is equivalent to showing that a profile @xmath299 is stochastically asymptotically stable in the replicator equations ( [ eq : srd ] ) , ( [ eq : slrd ] ) only if it is a strict equilibrium . since theorem [ thm : stability ] provides the converse `` if '' part , an answer in the positive would yield a strong equivalence between stochastically stable states and strict equilibria ; we leave this direction to be explored in future papers .      for comparison purposes ( but also for simplicity ) ,",
    "let us momentarily assume that the noise coefficients @xmath137 do not depend on the state @xmath19 of the game . in that case , it is interesting ( and very instructive ) to note that the sde ( [ eq : score ] ) remains unchanged if we use stratonovich integrals instead of it ones : @xmath408 then , after a few calculations , the corresponding replicator equation reads @xmath409    the form of this last equation is remarkably suggestive .",
    "first , it highlights the role of the modified game @xmath239 even more crisply than ( [ eq : srd ] ) : the payoff terms are completely decoupled from the noise , in contrast to what one obtains by introducing stratonovich perturbations in the evolutionary setting @xcite .",
    "secondly , one can seemingly use this simpler equation to get a much more transparent proof of proposition [ prop : dominated ] : the estimates for the cross entropy terms @xmath410 are recovered almost immediately from the stratonovich dynamics .",
    "however , since ( [ eq : stratonovich ] ) takes this form only for constant coefficients @xmath138 ( the general case is quite a bit uglier ) , we chose the route of consistency and employed it integrals throughout our paper .      before closing , it is worth pointing out the applicability of the above approach to networks where the presence of noise or uncertainty has two general sources .",
    "the first of these has to do with the time variability of the connections which may be due to the fluctuations of the link quality because of mobility in the wireless case or because of external factors ( e.g. , load conditions ) in wireline networks .",
    "this variability is usually dependent on the state of the network and was our original motivation in considering noise coefficients @xmath137 that are functions of the players strategy profile ; incidentally , it was also our original motivation for considering randomly fluctuating payoffs in the first place : travel times and delays in traffic models are not determined solely by the players choices , but also by the fickle interference of nature .",
    "the second source stems from errors in the measurement of the payoffs themselves ( e.g. , the throughput obtained in a particular link ) and also from the lack of information on the payoff of strategies that were not employed .",
    "the variability of the noise coefficients @xmath411 again allows for a reasonable approximation to this problem .",
    "indeed , if @xmath412 is continuous and satisfies @xmath413 for all @xmath80 , this means that there are only errors in estimating the payoffs of strategies that were not employed ( or small errors for pure strategies that are employed with high probability ) . of course",
    ", this does not yet give the full picture [ one should consider the discrete - time dynamical system ( [ eq : discretescore ] ) instead where the players _ actual _ choices are considered ] , but we conjecture that our results will remain essentially unaltered .",
    "we would like to extend our gratitude to the anonymous referee for his insightful comments and to david leslie from the university of bristol for the fruitful discussions on the discrete version of the exponential learning model ."
  ],
  "abstract_text": [
    "<S> we study repeated games where players use an exponential learning scheme in order to adapt to an ever - changing environment . </S>",
    "<S> if the game s payoffs are subject to random perturbations , this scheme leads to a new stochastic version of the replicator dynamics that is quite different from the `` aggregate shocks '' approach of evolutionary game theory . </S>",
    "<S> irrespective of the perturbations magnitude , we find that strategies which are dominated ( even iteratively ) eventually become extinct and that the game s strict nash equilibria are stochastically asymptotically stable . </S>",
    "<S> we complement our analysis by illustrating these results in the case of congestion games .    and    .    </S>"
  ]
}