{
  "article_text": [
    "the problem of multiple camera calibration , or camera network calibration , has been a central topic for the pattern recognition and robotics communities since their inception .",
    "moreover , the use of camera networks has become pervasive in our society ; beside their use in surveillance and security enforcement , cameras are heavily relied upon in application domains related to entertainment and sports , geriatrics and elderly care , the study of natural and social phenomena , etc . motivated by all these developments , a large body of work has been devoted to the problem of estimating accurately the camera network topology , i.e. camera positions and orientations in a common reference system .",
    "inferring the topology in camera networks with non - overlapping fields of view ( fov ) is a topic specific to wide - area tracking relying more on high - level image processing and statistical inference and will not be addressed in the current work ; the focus of the current article is on estimating the geometric topology for cameras with overlapping fov .",
    "although such a network may be composed of a large number of cameras firmly attached to a mobile object such as a robot , car , or uav , most commonly camera networks are static and point towards a specific scene of interest . in these cases ,",
    "multiple camera calibration is performed by using a specific calibration pattern or object @xcite , which is deployed and moved in the scene during a dedicated calibration phase .",
    "if the use of a calibration object is not possible , scene based calibration may be performed by exploiting visible interest points in methods based on pose refinement @xcite , or if applicable by using dynamic silhouettes , such as in @xcite .    the analysis of a homogeneous scene which is not accessible , or where using calibration objects is not feasible , raises a problem which is not solved by the common methods used for multiple camera calibration .",
    "we approach this problem by replacing cameras with hybrid static stereo rigs , where a long focal camera is used for analysis and a large fov camera is used for registration with other rigs .",
    "the large fov cameras do use salient features of the larger scene in order to perform relative pose estimation , but in relying on this relatively straightforward solution we avoid using active cameras which require complex models for the dynamic evolution of their intrinsic parameters .",
    "other benefits of possessing simultaneous large and small fov images of the scene are the fact that the registration does not assume anything about the analysed scene , the fact that the salient features do not have to be static as long as the cameras are accurately synchronized , but then if they are static they can be used to re - estimate continuously the pose and correct phenomena such as camera shaking .",
    "although our aim and the experiments in the current work are related to pattern analysis in highly dense crowds , we hope that the proposed algorithm may be useful in a variety of applications requiring accurate analysis of homogeneous scenes inaccessible for calibration .",
    "the outline of the paper is as follows . in section [ sec : related ] we illustrate the fundamental problem that we address , and discuss related work and alternative solutions .",
    "then , section [ sec : background ] recalls the fundamental notions which are required for scene based calibration and for the understanding of the proposed algorithm , which is presented in section [ sec : algo ] .",
    "section [ sec : results ] illustrates an application of the proposed algorithm to the analysis of a highly crowded scene , and section [ sec : conclusion ] presents the conclusions .",
    "[ sec : related ]      based on the simple pinhole projection model ( also recalled in section [ subsec : model ] ) , let us illustrate an issue related to the representation of a homogeneous region of interest in a camera sensor ( for all the following tests and examples we will employ sony icx274 sensors with a 8.923 mm diagonal and an effective pixel resolution of 1624 @xmath0 1234 ) . in figure [",
    "fig : comp ] , we provide a visual comparison between the fov of a 4 mm lens and the fov of lenses with progressively higher focal lengths ( 8 , 12 and 16 mm ) , superposed on the initial image .",
    "the relative comparison highlights the fact that the scarcity of salient features increases dramatically as the fov focuses on the central interest area .",
    "consequently , this has an immediate impact on the feasibility and robustness of relative pose estimations between this view and other possible views aimed from different positions at the same area .     for a visual comparison .",
    "the fov are highlighted as : red for @xmath1 mm ; green for @xmath2 mm ; blue for @xmath3 mm . , scaledwidth=47.0% ]    nevertheless , we ought also take into account the actual aim of retrieving information related to the area of interest .",
    "for this purpose , we have acquired from the same position and with the same camera three shots using lenses with 4 , 8 and 12 mm focals respectively . in the left column of fig .",
    "[ fig : lenspatches ] we present from top to bottom three 50 @xmath0 50 pixel patches from the shots taken with increasing focal lengths .",
    "the adjacent images from left to right show areas from these patches ( of initial size 20 @xmath0 30 and zoomed for visualization purposes with no interpolation applied ) . in this case , the long focal lenses are required for retrieving with enough detail entities such as body parts , bags etc . which are essential for a wide range of tasks related to action understanding , monitoring , tracking and surveillance .        from the above illustrations",
    ", we may thus notice that for the purpose of analysis of a specific area of interest , a wide fov is beneficial for accurate registration in a camera network , whilst a narrow fov is beneficial for retrieving details from the area of interest .",
    "these details are often homogeneous , and by lacking salient features the narrow fov is not able to solve robustly or at all the relative pose problem .    a calibration pattern visible from all views set on the area of interest can solve the relative pose problem .",
    "however , there are multiple applications where this solution is not practical",
    ". the area of interest may be far and thus quite large , or it may be inaccessible . during the analysis",
    ", the camera poses might change accidentally due to shocks , periodically due to vibrations , or by design ( mobile observers ) ; all these scenarios require frequent relative pose estimation updates . in the following paragraphs",
    ", we recall briefly some works that are relevant for the problem of multiple view detailed analysis _ and _ relative pose estimation , highlighting their respective benefits and shortcomings for this scenario .",
    "one possible solution is to deploy a network of cameras which use motorized zoom lenses .",
    "each camera will switch from a wide fov used for the relative pose estimation to a narrow fov used for analysis .",
    "one major consequence is that the zooming process modifies the intrinsic and distortion parameters of the cameras .",
    "these parameters have to be re - estimated in order to perform either epipolar search or 3d - image plane correspondences , which are systematically used in camera networks with overlapping views .",
    "various solutions for zooming recalibration based on the scene have been proposed ; these solutions are often denoted as self - calibration methods .",
    "for optical center and distortion parameter estimation , common strategies make use of straight lines in the scene @xcite or interest point correspondences @xcite . for the rest of the intrinsic parameters ,",
    "these methods rely on matching salient features , usually interest points , of a rigid scene either between frames ( see for example @xcite for proposing pre - calibration to model the interdependence of intrinsic parameters , or @xcite ) , or with respect to an existing 3d scene model @xcite . furthermore , some works investigate the self - calibration of a stereo system ( intrinsic and extrinsic parameters ) , but they consider typically a subset of the intrinsic parameters . for example , @xcite propose a scene based estimation method for the focal lengths and the relative rotation for a stereo system ; however , the system being tested in a real scenario has fixed focal lengths , and the method is only shown to be robust to noisy initializations of the focal length values .",
    "actual focal length variations would have an impact on other assumptions ( i.e. fixed principal point or straightforward removal of distortion effects ) .",
    "generally , the self - calibration scenarios make some simplifying assumptions ( i.e. fixing the principal point , ignoring focus effects ) that are inaccurate and thus have a detrimental effect on the projection function accuracy .      ptz cameras have a built - in zooming function and are specifically designed for live monitoring .",
    "however , tasks such as surveillance or auto tracking do not require necessarily accurate self - calibration . in the area of ptz camera network calibration",
    ", the work introduced in @xcite builds high resolution panoramas of the scene , which are then used for extrinsic calibration .",
    "this solution has been shown to be effective for static environments rich in salient features . in terms of tracking dynamic targets , @xcite",
    "propose a wide fov ( master ) to narrow fov ( slave ) registration process , which is again limited by the presence of static landmarks .",
    "another work , investigating this time the coupling between a static wide fov camera and an active camera , has been presented in @xcite , with an application to gaze control . also in order to cope with and exploit the presence of moving objects , some approaches actually rely on aligning trajectories for relative pose estimation , especially in the case of wide baseline stereo  @xcite ; however , these solutions can not be applied to calibration in scenarios such as crowded scenes when calibration itself is a prerequisite of successful tracking .",
    "the strategies recalled up to this point propose interesting solutions for self - calibration and camera registration in the presence of a sufficient number of salient features , but they are not applicable for a camera view if the lens is zoomed on a _ homogeneous _ and/or _ dynamic _ scene .",
    "although these scenarios are less common , examples of possible applications abound in the study of crowds and of different types of flows encountered in natural phenomena . the underlying idea for the solution we propose",
    "is about transferring pose information in a scene - independent manner to the zoomed camera from a secondary camera able to infer its pose .",
    "this leads to a straightforward minimal solution based on a rigid stereo rig featuring two cameras , one with a small fov used for analysis , and one with a large fov used for registration within a network of such rigs .",
    "surprisingly , this solution has not been applied to the analysis of homogeneous scenes . even considering a broader range of applications ,",
    "the use of hybrid stereo systems featuring large and narrow fov is limited . in robotics ,",
    "the use of a hybrid setup has been illustrated recently by @xcite who employ a fisheye and a perspective camera on a uav .",
    "the authors show how the richer information from both views may be used conveniently for a sequential estimation of the unknowns in the following order : attitude , altitude , then motion .",
    "another application where a hybrid system has been used is the recent stereo solar observation mission @xcite .",
    "each of the two stereo spacecraft features two heliospheric imagers , hi1 and hi2 , with fov of 20@xmath4 and 70@xmath4 respectively . the imagers do have a common fov , but this property is used only for photometric cross - calibration , since both imagers are able to estimate their pose accurately with respect to a star catalogue .",
    "the main interest of using this setup is the ability to study the propagation of coronal mass ejections along the whole sun - earth line , with an increased resolution close to the sun .    with respect to the previous works ,",
    "the solution based on a hybrid stereo system has clear benefits for the analysis of dynamic homogeneous scenes .",
    "as long as the study within a specific region is applicable , the advantage of the fixed calibration parameters is twofold .",
    "we do not have to adopt any simplifying assumptions about the variations of intrinsic parameters , and the calibration precision will be maintained at the optimal level provided by state of the art calibration algorithms .",
    "secondly , the extrinsic parameters of each stereo rig can be estimated independently of the scene . unlike in the scenario of a zooming camera , the availability at each instant of an accurately registered pair of a high resolution image and of a panoramic image of the scene allows for accurate pose re - estimation between rigs as often as necessary , overcoming the effect of movement and vibrations .",
    "in the following , we will briefly recall the pinhole camera and optical distortion models that we employ . a point in 3d space @xmath5^\\mathrm{t}$ ] projects within the image space into a pixel @xmath6^\\mathrm{t}$ ] according to : @xmath7 \\left (     \\begin{array}{c }      \\mathbf{x } \\\\      1    \\end{array } \\right ) \\ ] ] with @xmath8 being an undetermined scale factor , @xmath9 the orientation of the camera and @xmath10 the location of its optical center in world coordinates ( we also note @xmath11 ) , and @xmath12 the intrinsic parameters : @xmath13\\ ] ] above , @xmath14 and @xmath15 are the focal lengths , @xmath16^\\mathrm{t}$ ] represents the principal point , and the skew parameter @xmath17 is considered 0 .    in order to switch to different coordinate frames , we rely on elements of @xmath18 , the group of rigid body transformations in @xmath19 .",
    "a transformation matrix @xmath20 takes the form :    @xmath21\\ ] ]    element multiplication amounts to transitive chaining coordinate frame transformations : @xmath22 would transfer a 3d point in homogeneous coordinates from reference system @xmath23 to reference system @xmath24 , based on both @xmath23 and @xmath24 relative relations to reference system @xmath25 .    in order to account for radial distortion , the extension of the pinhole model assumes that if the 3d point @xmath26 is projected to @xmath27^\\mathrm{t}$ ] under the initial assumptions , then @xmath26 would be actually imaged to the distorted location @xmath28^\\mathrm{t}$ ] : @xmath29 where @xmath30 .",
    "thus , @xmath31 is in most scenarios the suitable parameter set for a full intrinsic calibration .",
    "one tool that we will employ in the following sections is the epipolar constraint , which is a direct implication of the projective geometry between two views .",
    "it is worth noting that this constraint is independent of the scene structure , depending exclusively on the intrinsic parameters and the relative pose - as long as the the salient features of the scene are static , or as long as the cameras are accurately synchronized .    considering two projections @xmath32 and @xmath33 of the same point @xmath26 in cameras @xmath34 and @xmath35 , the epipolar constraint defines the relationship between the projections as : @xmath36    in the above",
    ", @xmath37 is known as the fundamental matrix @xcite , which depends explicitly on the calibration parameters in the following way : @xmath38 where @xmath39 is the skew - symmetric matrix associated to @xmath40 .",
    "the main interest of the epipolar constraint is that it does not make any assumptions about the 3d structure of the scene .",
    "thus , compared to other optimisation algorithms that are commonly employed to estimate the relative pose , the determination of @xmath41 using the epipolar geometry provides a practical minimal parametrization and does not require an initialization .",
    "however , the result may be used for the initialization of more complex optimisations , such as the bundle adjustment procedure , briefly recalled in the following section .",
    "assuming a zero - mean gaussian distribution of the corner detection errors , bundle adjustment @xcite is the maximum likelihood estimator for the joint estimation problem of relative camera poses and of observed 3d point locations .",
    "the bundle adjustment procedure will minimize the following reprojection error : @xmath42 in the error function above , @xmath43 is the location hypothesis for a point observed by the @xmath44 camera .",
    "the projection function @xmath45 related to the pinhole model ( accounting for radial distortion too ) depends on the @xmath44 camera pose ; we consider that the intrinsic parameters are known and are not part of the optimization problem .",
    "the bundle adjustment will thus minimize jointly for all the possible camera - point pairs @xmath46 the distance between the reprojection @xmath47 and the actual measurement @xmath48 . solving this optimization problem",
    "is studied in depth in the literature , and it generally boils down to exploiting the sparsity of its hessian matrix and to employing an adapted non - linear least squares algorithm such as levenberg - marquardt @xcite .",
    "although bundle adjustment seems like an ideal solution for multiple view pose estimation , it does have some well - known shortcomings that we will briefly discuss in connection with our specific aim .",
    "one common criticism is related to the computational requirements , but this issue is more prevalent in large scale robotics applications , especially if there are real - time constraints to take into account . for a relatively small camera network ,",
    "the size of the problem is reasonable even for frequent updates .",
    "another important aspect is related to the initialization , which has to be relatively accurate in order to allow the problem to converge to the correct solution . in order to cope with this",
    ", we will rely on an initialization based on the epipolar constraint discussed in section [ subsec : epigeom ] , but other options are possible too ( see for example @xcite , or @xcite if 3d information about some scene features is available ) .",
    "finally , some practical aspects are equally relevant . given the high number of parameters which are usually involved , constraining the relative pose variables is more effective if the adjacent camera views for the large fov cameras are close enough in order to allow for a significant fov overlap .",
    "stability is also improved if the corner correspondences are spread onto the common field of view .",
    "let us consider a network of @xmath49 hybrid stereo rigs , the @xmath44 rig featuring a small fov camera @xmath50 used for analysis , and a large fov camera @xmath51 employed for pose estimation in a global frame .",
    "the aim of the following procedure is to align accurately the cameras @xmath52 .",
    "we assume that for each rig , the cameras @xmath50 and @xmath51 have been calibrated . in the following , we will denote by @xmath53 the transform that transfers a point from the large fov camera to the analysis camera on the @xmath44 stereo rig .",
    "also , @xmath54 and @xmath55 are transforms that transfer points from the @xmath44 rig to the @xmath56 between the large fov cameras , and respectively between the analysis cameras .",
    "the fact that the stereo rigs are passive allows for a precise intrinsic and extrinsic calibration which can be performed independently of the scene in a controlled environment . thus the intrinsic parameters @xmath57 , @xmath58 as well as the rigid transform @xmath53 that projects a 3d point from the pose estimation camera of the rig to the analysis camera are considered as known .    for the next step ,",
    "let us consider a pair of spatially adjacent rigs @xmath46 ; in most scenarios , cameras are spread as much as possible , and thus it is necessary to consider adjacent pairs in order to obtain enough reliable interest point matches . due to initialization requirements , we can not apply bundle adjustment directly in order to estimate @xmath54 between the two large fov cameras on the rigs .",
    "we perform sift detection and matching @xcite , and use the normalized 8-point algorithm @xcite with ransac @xcite for robustness to outliers . for the matching step , we employ two filtering strategies based on the uniqueness assumption ( the ratio @xmath59 of the similarity scores for the top two candidates , @xcite and on married matching ( both features are the top candidate for each other @xcite ) .",
    "then , we decompose the fundamental matrix @xcite and choose the correct solution based on the chirality constraint @xcite .",
    "let us denote @xmath60 the rigid transformation estimated after this step .",
    "using @xmath60 , and based on the inlier set of matches that were validated during the ransac procedure , we build a set of 3d points @xmath61 by linear triangulation @xcite .    at this point",
    ", we can employ a bundle adjustment procedure using @xmath60 and @xmath61 as initial estimates , and we obtain a refined relative pose estimation @xmath62 for the large fov cameras in the pair of rigs @xmath46 .",
    "ideally , a bundle adjustment involving more than a pair of rigs should be performed afterwards whenever possible ; however , in a typical setting , cameras are spaced as much as possible around a scene , the limit being imposed by common fov considerations and the performance of the interest point matching procedure .",
    "thus , we may assume that in most situations non - adjacent rigs will have difficulties for the matching procedure , and will have matches corresponding to disjoint sets of 3d points , which effectively yields the bundle adjustment problems independent .",
    "a particular setting is that of a scene surrounded in a full circle by rigs , and in this case a full bundle adjustment may be beneficial .",
    "having the bundle adjustment estimations , it is trivial to express the @xmath51 poses in a common reference system ; in the following , we set this reference system as depicted by the position and orientation of @xmath63 .",
    "let @xmath64 be the rigid transform that links @xmath63 to @xmath51 .",
    "for any two rigs @xmath46 , we can now use the extrinsic calibrations @xmath53 , @xmath65 and the global allignment of the large fov cameras in order to infer the global allignment of the analysis cameras in the same reference system , as well as their relative pose : @xmath66 @xmath67      bundle adjustment can estimate accurately the relative pose up to an unknown scale factor .",
    "this limitation applies to the @xmath62 estimates only ; the values @xmath53 that specify the baseline for cameras on the same rig are not concerned as long as a known size calibration pattern is used for stereo extrinsic calibration",
    ". since the different bundle adjustment procedures depicted in the following paragraphs are typically independent , we have to enforce a common scale factor among all optimizations using additional information .",
    "depending on the application , it is easier to adopt one of the following strategies :    * for a small sized scene , add a known size object in the common fov of @xmath51 and @xmath68 ; we thus use @xmath61 in order to impose a metric scale to the reconstruction * for a large scene , either use a similar approach as for the previous setting , or if it is not applicable measure the distance between @xmath51 and @xmath68 ( using for example a laser rangefinder ) , thus using @xmath69 in order to impose a metric scale to the reconstruction .",
    "the main steps of the algorithm are synthetically recalled below .",
    "relative pose estimation for homogeneous scene analysis +   + * objective * : given a network of @xmath49 hybrid stereo rigs @xmath70 , estimate for any pair @xmath46 the rigid transform @xmath55 that projects a 3d point from the analysis camera of the @xmath44 rig to the analysis camera of the @xmath56 rig .",
    "* steps * :    1 .   for all rigs , estimation of @xmath71 , @xmath72 2 .   for all rigs , estimation of @xmath53 3",
    "for each pair of adjacent rigs @xmath46 : 1 .",
    "estimate @xmath73 2 .",
    "estimate @xmath74 , @xmath75 , @xmath60 3 .",
    "use @xmath60 to triangulate matches and obtain @xmath61 4 .",
    "enforce a metric scale , either through @xmath75 or through @xmath61 5 .",
    "apply bundle adjustment using @xmath60 , @xmath61 for initialization , and compute @xmath62 , @xmath76 4 .",
    "register all @xmath64 in the reference frame of @xmath63 5 .",
    "if applicable , reapply bundle adjustment for more than two adjacent rigs at a time , using previously computed values for initialization    * result * : for given @xmath46 , compute @xmath67    [ algo1 ]",
    "we have created a simple example in an indoor environment , using lego figurines placed closely in the middle of a homogeneous surface . we have used two hybrid stereo rigs and taken a snapshot of the figurines and surrounding environment .",
    "the resulting images are presented in figure [ fig : multilego ] : the upper and lower rows show the views from the large fov ( @xmath63,@xmath77 ) and small fov ( @xmath78,@xmath79 ) cameras respectively .",
    "we have also highlighted the results of the matching procedures ; the first matching set ( @xmath80 for uniqueness ) is required for step ( iii ) of the algorithm , while the second ( a more permissive value @xmath81 has been set in order to have enough matches ) is not used in the algorithm - as the scene is supposed to be poor in salient features - but it is used as ground truth for validating the result of the algorithm .",
    "we apply the steps highlighted in the previous section in order to compute @xmath82 : estimation of @xmath83 using sift matching followed by decomposition of @xmath84 and bundle adjustment , then exploitation of @xmath85 and @xmath86 provided by stereo calibration , and also the setup of the right scale by using an object of known size ( the long brick of length 79.8 mm ) .",
    "+ a )     +     + b )    in order to estimate numerically the quality of the rigid transform @xmath82 obtained , we have exploited the matches that we were able to determine directly between the small fov cameras in this example . in homogeneous scenes ,",
    "interest points may be completely absent , or the scarcity of matches may have a detrimental effect on the stability of the estimation of @xmath37 .",
    "therefore , in our example we set up a base bundle adjustment problem between @xmath78 and @xmath79 where we initialize the system by the decomposition of @xmath87 .",
    "alternatively , we use the rigid transform @xmath82 as initialization for the triangulation of matches and for the ba procedure . the resulting solutions and mean reprojection errors for these two scenarios are presented in table [ numberslego ] .",
    "as we notice , the two optimization problems converge towards the same solution , but @xmath82 brings the optimization much closer to the objective in terms of mean reprojection error .",
    "this result is interesting for a number of reasons .",
    "firstly , even though we do not have a case of optimization stuck in a local minimum due to the worse initialization , this is a good example of coarse to fine resolution of the relative pose estimation .",
    "this approach is helpful for robotics applications in case of unstable optimizations ( few matches in the small fov cameras ) , and also interesting for the computation gain due to a faster convergence of ba ( 25 iterations with initial subpixel mean reprojection error compared to 37 iterations ) .",
    "secondly , and most importantly , this example shows that in cases where we can not compute @xmath82 directly due to the complete absence of salient features , we are able using this algorithm to infer the unknown rigid transform from the adjacent large fov cameras with a high level of accuracy .",
    "-1in-1 in    [ cols=\"^,^,^,^,^,^,^,^\",options=\"header \" , ]     [ numbers ]     +   + a )     +   + b )     +   + c )     +   + d )     +     +   + e )     +   + f )     +   + g )     +   + h )    having thus obtained all the necessary relative poses ( rows 1 , 4 and 5 in table [ numbers ] ) , we are able to estimate the relative pose between the long focal cameras .",
    "ground truth estimations are not possible , but in order to estimate the accuracy of the result we have located in the crowd a number of salient elements ( either distinctive heads , or distinctive configurations of people ) and we illustrate the result by drawing for each feature the epipolar line , and judging by its proximity to the corresponding feature in the other image . in figure",
    "[ fig : smallres ] , the upper row corresponds to elements identified in @xmath78 ( figure [ fig : multim]b ) and the lower row presents the same elements identified in @xmath79 ( figure [ fig : multim]d ) .",
    "the following remarks are necessary at this point .",
    "firstly , the perspective change makes the correspondence search very tedious even for a human .",
    "secondly , the drawing of the epipolar line has actually assisted us in pinpointing most of these correspondences , and we are confident that the method will be helpful in automating these tasks .",
    "overall , the distance in the image space between the corresponding element and the corresponding epipolar line is in the range of a few pixels .",
    "the major factors responsible for these misalignments are the inaccuracies in estimating the intrinsic parameters , as well as the errors related to the relative pose estimations - but for the dimensions of the scene involved in the experiment , we argue that the results are very promising .",
    "moreover , some areas of the scene exhibit near perfect alignments .",
    "the first four matches presented in figure [ fig : smallres ] :    * the white cap man in a ) positioned under the epiline , in the left part of the patch ; * same for b ) , the person looking slightly towards the left ; * the woman in c ) wearing a white veil , and positioned in front of two other women similarly dressed ; * the woman in d ) wearing a white veil , and positioned with the back towards the second camera ;    are very accurate , in spite of the fact that in one of the images the first three persons are located near the border , a fact which potentially increases radial distortion related errors",
    ".    we could also identify the following correspondences which exhibit small but visible misalignments :    * the shiny circumference of the station of ibrahim , depicted in e ) * another two men wearing white caps , presented in f ) and g ) * a distinctively bearded man presented in h )    the fact that the epipolar line does not pass precisely through the corresponding element is not detrimental for the purpose of association and tracking in the crowd . assuming that the person is not occluded , using this extra information we would not only be able to trim down the research space to a band along the epipolar line , but also if we were able to position the ground plane within the same coordinate system we would further reduce the research space to a fraction of the band .",
    "of course , in order to do dense matching reliably we still need a neighborhood based similarity measure that has to be resilient to major perspective change and occlusions ; this is a promising direction of research that we intend to follow in order to benefit from the relative pose algorithm we propose , and ultimately in order to perform dense associations .",
    "finally , the present results of the proposed algorithm on this type of data are also encouraging as they illustrate the potential of multi - camera systems in extremely crowded environments . in the current research context",
    ", this application field has been associated mostly with single camera systems @xcite , but paradoxically it would greatly benefit from multi - view systems given the frequent occlusions and scene clutter that characterize it .",
    "in this paper we propose a new method for aligning multiple cameras analysing a homogeneous scene .",
    "our method addresses the settings where for practical reasons calibration pattern / object based registrations are not possible . by employing stereo rigs featuring a long focal analysis camera and a short focal registration camera ,",
    "the proposed solution alleviates the requirement to get access to the studied scene .",
    "the fact that we are using a large fov simultaneously allows us to avoid making any assumptions about the homogeneous region we analyse , such as the presence of shades , silhouettes etc .",
    "a first experiment has been conducted in an indoor environment and has shown , by using interest point correspondences in the analysis area as ground truth , that this method can guide the relative pose estimation for scenes poor in salient features in a coarse - to - fine manner supported by hardware .",
    "the second test has shown that in the absence of any salient features , the method is capable of providing a full calibration of the analysis cameras in a difficult , large scale scenario .    in the future",
    ", we would like to investigate the applicability of the proposed hybrid stereo solution in two frequently recurring settings .",
    "we intend to employ this method as a preprocessing step for a wide range of homogeneous pattern analysis applications , such as those related to the extraction of accurate models for highly dense crowd dynamics .",
    "secondly , we would like to evaluate further the potential of this solution in specific applications such as autonomous robot navigation or image alignment and stitching , which employ pyramid based coarse - to - fine optimizations ; our setup augments these systems by supplementing the image pyramid with a level provided by an independent data source .",
    "this work was funded by the qatar national research fund ( part of the qatar foundation ) under the grant nprp 09 - 768 - 1 - 114 .",
    "the authors acknowledge a. gutub and his team at the centre of research excellence in hajj and omrah ; and o. gazzaz , f. othman , a. fouda and b. zafar at the hajj research institute ( umm al - qura university , makkah ksa ) for their organisation and logistical support in the video data collection at the grand mosque ( al - harram ) in makkah , as well as for useful discussions .",
    "the authors would also like to thank f. ali for his help in data collection , and r. saussard for his assistance in the coding of some of the algorithms .",
    "lastly , the authors would like to thank the late professor maria petrou who was a co - investigator on this project and without whose consistent support the project would not have been possible  this article is dedicated to her memory .",
    "eyles , c. , harrison , r. , davis , c. , waltham , n. , shaughnessy , b. , mapson - menard , h. , bewsher , d. , crothers , s. , davies , j. , simnett , g. , et  al .",
    ": the heliospheric imagers onboard the stereo mission . solar physics * 254*(2 ) , 387445 ( 2009 )                      kneip , l. , scaramuzza , d. , siegwart , r. : a novel parametrization of the perspective - three - point problem for a direct computation of absolute camera position and orientation . in : cvpr , pp . 29692976 ( 2011 )        lourakis , m.i . , deriche rachid , d. : camera self - calibration using the singular value decomposition of the fundamental matrix : from point correspondences to 3d measurements",
    "rr-3748 , inria ( 1999 )"
  ],
  "abstract_text": [
    "<S> in this paper we address the problem of multiple camera calibration in the presence of a homogeneous scene , and without the possibility of employing calibration object based methods . </S>",
    "<S> the proposed solution exploits salient features present in a larger field of view , but instead of employing active vision we replace the cameras with stereo rigs featuring a long focal analysis camera , as well as a short focal registration camera . </S>",
    "<S> thus , we are able to propose an accurate solution which does not require intrinsic variation models as in the case of zooming cameras </S>",
    "<S> . moreover , the availability of the two views simultaneously in each rig allows for pose re - estimation between rigs as often as necessary . </S>",
    "<S> the algorithm has been successfully validated in an indoor setting , as well as on a difficult scene featuring a highly dense pilgrim crowd in makkah .    </S>",
    "<S> example.eps gsave newpath 20 20 moveto 20 220 lineto 220 220 lineto 220 20 lineto closepath 2 setlinewidth gsave .4 setgray fill grestore stroke grestore </S>"
  ]
}