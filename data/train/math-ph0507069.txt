{
  "article_text": [
    "let @xmath1 denote a sequence of independent random matrices identically distributed according to a probability measure @xmath2 on @xmath3 .",
    "the problem of determining the asymptotic behaviour of the product @xmath4 plays a crucial rle in the theory of products of random matrices and its applications , especially in mathematical physics @xcite .    the rate of growth of this product can be quantified by its _",
    "lyapunov exponent _",
    "@xmath5 where @xmath6 denotes some matrix norm .",
    "the lyapunov exponent exists whenever @xmath7 .",
    "the furstenberg ",
    "kesten theorem ( @xcite , @xcite p. 11 ) generalises the classical strong law of large numbers to the case of non - commuting random products and states that @xmath8    the case of unimodular matrices ( i.e. @xmath9 ) is of particular interest . in this case , under the natural additional assumption of _ noncompactness _ is not contained in any compact subgroup of @xmath10 . ] and _ strong irreducibility _ , with @xmath11 , for all realizations of @xmath12 .",
    "] furstenberg s theorem ( @xcite , cf .",
    "@xcite p. 30 ) , asserts that the lyapunov exponent is _",
    "strictly positive_. moreover , there exists a unique , continuous , @xmath2-invariant measure @xmath13 on the projective line @xmath14 that is , a measure that is invariant under the projective action of matrices drawn from the distribution @xmath2 ( cf .",
    "@xcite p. 30 ) .",
    "the calculation of the lyapunov exponent involves this @xmath2-invariant measure , but there are remarkably few non - trivial cases where @xmath13 has been found explicitly ; three well - known examples will be discussed presently ( others are given in @xcite ) .",
    "the prominent feature shared by these examples is that the invariant measure is found by considering a random continued fraction derived from the projective action of the relevant matrix ensemble .    the first example dates back to dyson s work on the disordered chain problem .",
    "[ dysonexample ] the disordered chain is modeled by a system of harmonic oscillators coupled by linear forces",
    ". a physical realisation is obtained by considering a sequence of @xmath15 particles joined by elastic springs obeying hooke s law .",
    "denote the mass and the displacement of the @xmath16th particle from its equilibrium position by @xmath17 and @xmath18 respectively , and let @xmath19 be the elastic modulus of the spring between the @xmath16th and @xmath20th particle .",
    "then the equation of motion takes the form @xmath21 by introducing additional variables , it is straightforward to express this as the first - order system @xmath22 where @xmath23 in matrix notation , @xmath24 where @xmath25 is the tridiagonal ( jacobi ) matrix @xmath26 dyson studied the spectral problem for @xmath25 when the @xmath27 are independent , identically distributed random variables .",
    "it turns out that the spectral properties of @xmath25 ( e.g. the eigenvalue density function ) can be deduced from the so - called characteristic function of the chain @xmath28 where @xmath29 is the distribution of the random continued fraction @xmath30 to illustrate his approach , dyson elaborated the particular case where the @xmath31 are gamma - distributed , i.e. for every lebesgue - measurable subset @xmath32 of @xmath33 , @xmath34 where @xmath35 then the probability density function of the random continued fraction ( [ dysoncontinuedfraction ] ) is given explicitly by @xmath36 where @xmath37 is a normalisation constant .    in terms of products of random matrices ,",
    "dyson s continued fraction ( [ dysoncontinuedfraction ] ) corresponds to the case where @xmath38 in the product ( [ productofrandommatrices ] ) .",
    "the distribution @xmath29 of the continued fraction is the @xmath2-invariant distribution associated with this product .",
    "one of the present paper s contribution is the calculation of the distribution of a random continued fraction that arises in another important physical model , namely the discrete schrdinger equation with a random potential . in this",
    "regard , lloyd s model ( cf .",
    "@xcite , @xcite , @xcite ) with a cauchy - distributed potential in one spatial dimension is possibly the best - known example where the invariant measure and the corresponding lyapunov exponent have been found explicitly .",
    "[ cauchyexample ] let @xmath39 with @xmath40 and denote by @xmath41 the distribution of the random variable @xmath42 , where @xmath43 is cauchy - distributed , i.e @xmath44 for every lebesgue - measurable subset @xmath32 of @xmath45 .",
    "set @xmath46 where the @xmath31 are independent and @xmath41-distributed .",
    "the invariant measure @xmath13 is then given by the distribution @xmath47 , where @xmath48 and @xmath49 are related by @xmath50 .",
    "it follows easily that @xmath51    we end our brief survey with an example that , once again , involves a continued fraction with gamma - distributed elements ; the resulting invariant distribution is a so - called generalised inverse gaussian distribution .",
    "[ letacseshadriexample ] set @xmath52 where the @xmath27 are independent , gamma - distributed random variables with parameters @xmath53 and @xmath54 .",
    "it was shown by letac and seshadri @xcite that the probability density function of the invariant measure @xmath13 is then @xmath55 \\ , , \\quad x \\ge 0 , \\label{letacseshadridistribution}\\ ] ] where @xmath56 is the modified bessel function of order @xmath53 .",
    "as we will show below , the lyapunov exponent can be expressed in terms of modified bessel functions .",
    "the details can be found in section [ lyapunov ] .",
    "see also @xcite and @xcite for some generalisations of this example .    in the papers that form the basis of examples",
    "[ dysonexample ] and [ letacseshadriexample ] , the authors were concerned  not with products of random matrices but rather with the problem of determining the distribution of a continued fraction with random coefficients .",
    "we have already mentioned dyson s continued fraction ( [ dysoncontinuedfraction ] ) .",
    "the continued fraction studied by letac & seshadri is of the form @xmath57 where , as in dyson s case , the @xmath31 are independent and gamma - distributed .    in this paper , we generalise this example to the case where the elements take values along a ray in the complex plane .",
    "hence , from now on , unless explicitly stated otherwise , we consider matrices in @xmath58 .",
    "fix a constant @xmath59 and consider the one - parameter family of complex matrices of the form @xmath60 where the @xmath27 are , again , independent gamma - distributed random variables .",
    "the corresponding random continued fraction is @xmath61 the random variable @xmath62 takes values in the cone @xmath63    ( 0,0 ) ( -95,210)(a ) ( 100,210)(b ) ( -95,0)(c ) ( 100,0)(d )    our main contribution is an explicit formula for the distribution of @xmath62 or , equivalently , for the @xmath2-invariant measure @xmath13 associated with the infinite product of the random matrices ( [ randommatrixforalpha ] ) .",
    "let @xmath64 .",
    "suppose that the @xmath27 are independent , gamma - distributed random variables with parameters @xmath65 , and write @xmath66 .",
    "then the probability density function of @xmath62 equivalently , that of the @xmath2-invariant measure @xmath13 is supported on @xmath67 and given by @xmath68^{p-1 } \\\\",
    "\\times \\exp \\left \\ { -\\frac{\\sin(2 \\alpha)}{s } \\left [ \\frac{1}{r \\sin(\\alpha-\\theta)}+ \\frac{r}{\\sin(\\alpha+\\theta ) } \\right ] \\right \\}\\,.\\end{gathered}\\ ] ] in particular , the density is a smooth function that decays exponentially fast at infinity in every direction contained in the cone @xmath67 .",
    "[ generalisedletacseshadrithm ]    plots of the probability density function @xmath69 for @xmath70 and various values of @xmath71 are shown in figure [ densityfigure ] .    in section [ lyapunov ] , we use the above result to calculate the corresponding lyapunov exponent and express it in terms of the logarithmic derivative of the modified bessel function , namely ( see theorem [ lyex ] ) @xmath72    by considering the weak limit in ( [ densityfunction ] ) as @xmath73 , we recover the distribution found originally by letac and seshadri ( see section [ weak ] ) .    the behaviour of the random variable @xmath62 as @xmath74 is particularly interesting .",
    "figure [ argumentfigure ] shows plots of the probability density function of @xmath75 for various values of @xmath71 when @xmath70 .",
    "as @xmath76 approaches @xmath77 , the support of the measure @xmath13 becomes concentrated on the imaginary axis .",
    "( 0,0 ) ( -75,115)@xmath78 ( -98,190)@xmath79 ( -10,190)@xmath80 ( 0,10)@xmath81    the weak limit as @xmath82 leads to our second result :    let @xmath83 . suppose that the @xmath27 are independent and gamma - distributed , with parameters @xmath65 , and write @xmath84 .",
    "then , the probability density function of @xmath62 equivalently , that of the @xmath2-invariant distribution @xmath13 is given by @xmath85 } \\,\\frac{1}{y^{p+1 } }   \\exp \\left [ \\pm \\frac{1}{s }   \\left ( \\frac{1}{y } -y \\right ) \\right ] \\\\ \\times \\int_{c(y)}^y   \\exp \\left [ \\mp \\frac{1}{s }   \\left ( \\frac{1}{t } -t\\right ) \\right ] \\,t^{p-1}\\,\\d t\\,,\\end{gathered}\\ ] ] where @xmath86 and @xmath87 is the dirac delta .",
    "in particular , @xmath13 is supported on the imaginary axis , where the density decays algebraically ( like @xmath88 ) at @xmath89 .",
    "[ alphaispiover2theorem ]    plots of @xmath90 for various values of @xmath53 and @xmath54 are shown in figure [ piover2pdffigure ] . for comparison , the figure includes a plot of the cauchy probability density function .",
    "we shall see in ",
    "[ alphaispiover2 ] that , for @xmath91 and @xmath54 small , @xmath62 is approximately cauchy - distributed along the imaginary axis .",
    "( 0,0 ) ( -128,124 ) ( -132,142 ) ( -135,195 ) ( -100,0)(a ) ( 140,40 ) ( 76,118 ) ( 60,150 ) ( 100,0)(b )    next , we discuss some interesting applications of these results .      in 1958",
    ", p. w. anderson @xcite postulated that the spectra of schrdinger operators with random potentials should exhibit a tendency towards a dense pure point spectrum with bound eigenstates .",
    "when the eigenstates decay exponentially fast , one speaks of strong or exponential localisation .",
    "this type of localisation has been proved for one - dimensional systems ; cf .",
    "@xcite , chap .",
    "higher - dimensional systems will not be considered here ; we refer the reader to @xcite for a discussion of that case .    in order to make the connection between this general theory and our own results , let us first note that by conjugating the matrices ( [ randommatrixforalpha ] ) for @xmath92 with a rotation that maps @xmath93 into the imaginary line , we obtain @xmath94 thus the corresponding random matrices reduce in this limiting case to the transfer matrices for the discrete stationary one - dimensional schrdinger equation @xmath95 with @xmath96 , @xmath97 ( tight - binding , nearest - neighbour laplacian ) , @xmath98 ( independent identically distributed random potential ) and energy level @xmath99 ( cf .",
    "@xcite , p. 187 ) .",
    "it is readily seen that the above equation can be rewritten in the form @xmath100    it is well known @xcite that the spectrum on @xmath101 of the hamiltonian associated with equation ( [ discreteschroedingerequation ] ) , i.e of the operator @xmath102 is given , with probability one , by @xmath103 where @xmath104 $ ] and @xmath2 denotes the probability measure of the potential .",
    "it has been shown in @xcite that , as long as @xmath2 is not concentrated on a single point and possesses some finite moment , the spectrum @xmath105 is pure - point with probability one .",
    "the eigenfunctions are exponentially localised with a rate determined by the _ value _ of the lyapunov exponent ( see @xcite ) .",
    "thus is view of our results we have    let @xmath106 be the hamiltonian of the anderson tight - binding model in dimension 1 with @xmath107-distributed potential .",
    "the exponential localization rate for the energy level @xmath108 is given by @xmath109    we note that the lyapunov exponent is a smooth function of the energy level @xmath110 ( cf .",
    "@xcite , proposition viii.1.1 ) .",
    "thus , although the above result is not sufficient to give estimates of the decay rate of all the eigenstates , it does yield quantitative information in the close enough neighbourhood of @xmath99 , which is almost surely in the bulk of the spectrum .",
    "another motivation for this work is to study the convergence of pad approximation for series that are random in some sense @xcite . consider the class of random stieltjes functions whose continued fraction expansion is @xmath111 where the @xmath112 are independent draws from the gamma distribution with parameters @xmath53 and @xmath113 . by truncating this continued fraction ,",
    "we obtain rational approximations of @xmath114 : @xmath115 it is a well - known fact that the @xmath116 are diagonal or near - diagonal pad approximants of @xmath114 @xcite . roughly speaking",
    ", this means that @xmath117 and that there is no other rational function with a numerator and a denominator of lesser degree with this property . the rate of decay of the error of pad approximation as @xmath118 , @xmath119 fixed , is of considerable practical interest .",
    "a simple calculation reveals that the distribution of @xmath120 is precisely that of the random variable @xmath62 defined by equation ( [ continuedfraction ] ) if we take @xmath121 the rate of convergence of pad approximation for a typical realisation of the function @xmath114 is then given by @xmath122 { }   -2 \\lambda_{p,\\frac{\\sigma}{\\sqrt{|t| } } } \\left ( - \\frac{\\arg t}{2 } \\right ) \\quad \\text{almost surely.}\\ ] ] the proof of this result requires a careful study of the ergodic properties of the markov chain associated with the continued fraction ; a detailed treatment will be given in a separate publication .",
    "the remainder of the paper provides the details of the proofs of these assertions . in the next section ,",
    "we introduce some notation , elaborate the correspondence between products of @xmath123 matrices and continued fractions , and derive an integral equation for the unknown probability density function of @xmath62 . in ",
    "[ alphasection ] , we deduce a partial differential equation , and solve it .",
    "the case @xmath91 is treated in  [ alphaispiover2 ] and , in ",
    "[ weak ] , we show that the singular measure obtained in this case is a weak limit of that found earlier . finally ,  [ lyapunov ] is concerned with the explicit calculation of the lyapunov exponent .",
    "the correspondence between continued fractions and products of @xmath123 matrices is well - known ( see for instance @xcite , part a , ",
    "vi.5 ) , but since it forms the basis of our approach , it is desirable to elaborate it here .",
    "the starting point is the observation that any linear fractional transformation @xmath124 corresponds to the action of a matrix @xmath125 on a complex or real projective line @xmath126 .",
    "indeed , denoting by @xmath127 any nonzero vector in @xmath128 and defining its projection by @xmath129 we obtain a natural identification of @xmath126 with @xmath130 .",
    "the action of @xmath131 on @xmath126 ( denoted by @xmath132 ) can then be defined via @xmath133    then , for the choice @xmath134 we get @xmath135    it is convenient to extend the notation for the set @xmath67 , defined by ( [ thesets ] ) for @xmath136 , to the limiting cases @xmath137 .",
    "we shall write @xmath138 then , for every @xmath139 , @xmath140 now , suppose that @xmath141 is a positive random variable distributed according to a probability measure @xmath142 on @xmath33 , and let @xmath143 be an arbitrary random variable taking values in @xmath144 .",
    "consider the iteration @xmath145 where the @xmath27 are independent draws from @xmath146 .",
    "under appropriate conditions on @xmath2 @xcite , it can be shown that the markov chain defined by equation ( [ forwarditeration ] ) has a stationary distribution @xmath147 independent of the starting value @xmath148 . moreover",
    ", the latter distribution coincides with the distribution of the random continued fraction ( [ continuedfraction ] ) , which can be constructed by means of the successive applications of the corresponding random matrices @xmath149 hence , the @xmath2-invariant measure on the projective line associated with the infinite product of the @xmath150 is precisely @xmath147 .    let us denote by @xmath151 the distribution of @xmath152 .",
    "we are only interested in the case where the measures @xmath153 and @xmath147 on @xmath144 are absolutely continuous with respect to the lebesgue measure @xmath154 ; so let @xmath155 and @xmath156 be the probability density functions of @xmath152 and @xmath62 respectively , i.e. @xmath157 our aim is to find an explicit formula for @xmath156 . to this end , we derive a recurrence relation for the @xmath155 and hence , by taking the limit as @xmath118 , find an integral equation satisfied by @xmath156 .",
    "we shall assume that @xmath155 and @xmath156 are smooth .",
    "we introduce the map @xmath158 , @xmath159 or @xmath160 defined by @xmath161 thus , @xmath162 is the left inverse of @xmath163 : @xmath164 on the other hand , for @xmath165 , @xmath166 only if @xmath167 .",
    "let @xmath32 be a measurable set .",
    "we have @xmath168 where @xmath169 for @xmath170 , we have @xmath171 where @xmath172 is the jacobian of the transformation",
    "@xmath173 hence @xmath174 now , consider the region @xmath175 it is readily verified that @xmath176 where @xmath177 hence , @xmath178 it follows that @xmath179    taking the limit as @xmath118 , we conclude that , if the continued fraction ( [ continuedfraction ] ) has a smooth probability density function @xmath156 , then @xmath156 satisfies the equation @xmath180    we shall henceforth assume that @xmath181 the lyapunov exponent will be denoted by @xmath182 here , @xmath183 where @xmath6 denotes the standard euclidean norm on @xmath184 .",
    "we can express the lyapunov exponent in terms of the measure @xmath13 as follows    @xmath185    a proof is given appendix [ lyap ] .",
    "an equivalent way of presenting our results is to work with the reciprocal of the continued fraction ( [ continuedfraction ] ) , i.e. @xmath186 the corresponding linear fractional transformation is @xmath187 and so the matrices in the product ( [ productofrandommatrices ] ) are of the form @xmath188 in particular , when @xmath92 , we have @xmath189 readers familiar with the application of the theory of products of random matrices to the spectral theory of schrdinger operators will easily recognize the schrdinger transfer matrix on the right - hand side of this equation .    finally , we remark that , if @xmath190 and @xmath156 is the probability density function of the random continued fraction ( [ continuedfraction ] ) , then the probability density function , say @xmath48 , of ( [ reciprocalcontinuedfraction ] ) is given by @xmath191 it will sometimes be convenient to work with @xmath48 instead of @xmath156 .",
    "note that in this case , i.e. for the matrices of the form ( [ umatrix ] ) the lyapunov exponent @xmath192 takes the form ( see appendix [ lyap ] ) @xmath193 [ inverseremark ]    letac & seshadri @xcite considered the particular case @xmath194 . by using the laplace transform , they showed that the density function of the stationary distribution is given by equation ( [ letacseshadridistribution ] ) .",
    "in this paper , we study the case @xmath195 by a different method .",
    "our approach is inspired by alain comtet s derivation of ( [ letacseshadridistribution ] ) in the particular case @xmath194 and @xmath196 @xcite : by using the fact that @xmath197 is a simple exponential , he showed how to replace equation ( [ equation4f ] ) by one that involves @xmath198 , @xmath199 and a derivative of @xmath200 .",
    "we shall develop this idea and seek to derive a differential equation for the unknown density function @xmath156 , making use of the fact that , for @xmath201 , the probability density function @xmath107 of the gamma distribution solves the differential equation @xmath202^p \\gamma_{p , s } = 0 , \\quad \\frac{\\d^{k}\\gamma_{p , s}}{\\d a^{k}}(0 ) = \\begin{cases } 0 & \\text{if $ 0 \\le k < p-1 $ } \\\\",
    "\\frac{1}{s^p } & \\text{if $ k = p-1 $ } \\end{cases } \\ , .",
    "\\label{ode4gamma}\\ ] ] the key observation is that this is a linear equation with constant coefficients .",
    "equation ( [ equation4f ] ) states that @xmath204 where @xmath205    for convenience , we use the notation @xmath206 and set @xmath207 by equation ( [ equation4fwhenalphaisnotzero ] ) , we then have @xmath208 where @xmath209    for the sake of clarity , let us begin by considering the case @xmath196 . in order to exploit the fact that @xmath197 solves equation ( [ ode4gamma ] ) , we introduce the first - order differential operator @xmath210 and apply it to both sides of equation ( [ equation4u ] ) . using @xmath211 we obtain @xmath212 hence , we have @xmath213    now , the characteristics of the first - order operator @xmath214 are the curves of equation @xmath215 thus , the functions that are constant along the characteristics depend only on @xmath216 .",
    "this suggests the introduction of the new independent variables @xmath217 set @xmath218 then , equation ( [ generalisedcomtet ] ) gives @xmath219\\ , .",
    "\\label{comtetxy}\\ ] ] evaluating @xmath220 at @xmath221 instead of @xmath222 , we deduce that @xmath223   \\\\",
    "= \\frac{r^4}{2xys } \\left [ r^{-4 } u(y , x)- u(x , y ) \\right ] \\,.\\end{gathered}\\ ] ] hence , we have the symmetry property @xmath224 this property can be used to eliminate the term @xmath225 from equation ( [ comtetxy ] ) but , although the resulting second - order partial differential equation for @xmath226 is linear , the presence of coefficients makes it awkward to solve .",
    "we shall seek to guess the form of the solution from equation ( [ comtetxy ] ) instead .",
    "the first observation is that , when @xmath227 , the solution is independent of @xmath228 .",
    "secondly , we know that the solution enjoys the symmetry property ( [ comtetsymmetryproperty ] ) . hence , we are led to the ansatz @xmath229 \\right \\ } , \\label{generalisedansatz}\\ ] ] where @xmath230 is some univariate function to be determined , and the prime symbol denotes differentiation .",
    "equation ( [ comtetxy ] ) then gives @xmath231 set @xmath232 then @xmath233 or , in terms of @xmath234 and @xmath235 , @xmath236 let @xmath237 .",
    "then @xmath238 and so @xmath239 hence , we have found @xmath240 and so @xmath241 reporting this in equation ( [ generalisedansatz ] ) we obtain @xmath242 \\right \\}\\,.\\ ] ] hence , in terms of @xmath243 , @xmath244 and @xmath81 , we have found that , when @xmath141 is @xmath107-distributed with @xmath196 , then @xmath245 \\right \\},\\ ] ] where @xmath246 is a normalisation constant .    for @xmath247 , we find by a similar calculation that the equation for @xmath48 is @xmath248^p u(x , y ) = \\frac{1}{r^4 s^p } u \\left ( \\frac{x}{x^2+y^2},\\frac{-y}{x^2+y^2}\\right ) \\ , . \\label{equation4largep}\\ ] ] it would be tedious to analyse this equation in detail .",
    "it is however natural to conjecture that , as in the case @xmath194 , @xmath48 consists of an exponential term independent of @xmath53 , multiplied by some algebraic part independent of @xmath54 .",
    "thus , we seek a solution of the form @xmath249 \\right \\}\\ , .",
    "\\label{ansatz4largep}\\ ] ] by setting @xmath227 in equation ( [ equation4largep ] ) , we find @xmath250 the general solution of this equation is @xmath251 for some univariate functions @xmath252 , @xmath253 . by substituting the resulting expression for @xmath48 in equation ( [ equation4largep ] ) , we obtain @xmath254    these results are summarised and stated in the most general form in theorem [ generalisedletacseshadrithm ] .",
    "the proof is a simple calculation carried out in appendix [ generalisedletacseshadriappendix ] .    in appendix",
    "[ momentappendix ] , we show how to express the moments of the distribution @xmath13 in terms of products of modified bessel functions . from these calculations ,",
    "we deduce in particular that @xmath255 furthermore , the mean and the variance are given respectively by @xmath256 and @xmath257",
    "for @xmath258 , we introduce a function @xmath259 defined by @xmath260 where @xmath261 is the normalisation constant and @xmath87 is the dirac delta . in order to find an equation for @xmath262",
    ", we write the iteration ( [ forwarditeration ] ) in terms of @xmath263 , where @xmath264 this gives @xmath265 it is then straightforward to obtain @xmath266 since @xmath267 we need only consider the case @xmath268 .    as in the previous section",
    ", we shall seek to replace ( [ equation4fwhenalphaispiover2 ] ) by a differential equation .",
    "set @xmath269 then , equation ( [ equation4fwhenalphaispiover2 ] ) gives @xmath270 differentiating with respect to @xmath235 , we obtain @xmath271 by using the fact that @xmath107 satisfies ( [ ode4gamma ] ) and repeating this calculation , we readily deduce the equation @xmath272^p u(y ) = \\frac{1}{s^p } \\frac{1}{y^2 } u(-1/y)\\ , .",
    "\\label{equation4uwhenalphaispiover2}\\ ] ]    again , in order to solve this equation , it is useful to consider the case @xmath196 first .",
    "we then have @xmath273 , \\label{anotherequation4uwhenalphaispiover2}\\ ] ] and so we deduce the property @xmath274 this property can be used to eliminate the @xmath275 term in equation ( [ anotherequation4uwhenalphaispiover2 ] ) . multiplying the equation by @xmath235 , differentiating , and then multiplying by @xmath276 , we obtain @xmath277 = \\frac{1}{s } \\left \\{- \\frac{1}{y } \\frac{\\d u}{\\d y } ( -1/y )   + y \\frac{\\d}{\\d y } \\left [ y^2 u(y ) \\right ] \\right \\ } \\\\ = \\frac{1}{s } \\left \\{y   \\frac{\\d u}{\\d y } ( y )   + y \\frac{\\d}{\\d y } \\left [ y^2 u(y ) \\right ] \\right \\}\\,.\\end{gathered}\\ ] ]    hence , after simplification and integration , we find @xmath278 for some constant @xmath279 ; integrating again , we obtain @xmath280 \\int^y t^{-2 }   \\exp \\left [ -\\frac{1}{s }   \\left ( \\frac{1}{t}-t \\right ) \\right ] \\,\\d t\\,.\\ ] ] in terms of @xmath281 , this gives , after some simple manipulations , @xmath282 \\int_{c(y)}^y   \\exp \\left [ -\\frac{1}{s }   \\left ( \\frac{1}{t}-t \\right ) \\right ] \\,\\d t\\ ] ] where @xmath283    this result generalises to arbitrary positive values of @xmath53 ; see theorem [ alphaispiover2theorem ] , which is proved in appendix [ p2thm ] .",
    "the rigorous determination of the normalisation constant requires some care , and we shall in fact make use of a weak limit result which will be discussed in the next section . for the moment , let us merely point out that the function @xmath262 thus defined is integrable .",
    "indeed , it is readily verified ( by use of lhospital s rule ) that the function is continuous at @xmath284 . by construction",
    ", it satisfies equation ( [ equation4fwhenalphaispiover2 ] ) .",
    "hence @xmath285 this shows that @xmath286 .",
    "we shall see in due course that @xmath287}\\ , .",
    "\\label{normalisationconstantforpiover2}\\ ] ] [ normalisabilitywhenalphaispiover2 ]    plots of @xmath288 for various choices of the parameters @xmath54 and @xmath53 are shown in figure [ piover2pdffigure ] .",
    "we can gain some insight into the behaviour of the random variable @xmath62 by considering the limit @xmath289 ( cf .",
    "appendix [ lyapunovappendix ] ) . set @xmath290 and",
    "note that @xmath291 then , using integration by parts , @xmath292 t^{p-1}\\,\\d t = s \\int_{c(y)}^y \\frac{1}{s } \\varphi'(t ) \\exp \\left [ \\frac{1}{s } \\varphi ( t ) \\right ] \\frac{t^{p+1}}{1+t^2}\\ , \\d t \\\\ = s \\exp \\left [ \\frac{1}{s } \\varphi ( y ) \\right ]   \\frac{y^{p+1}}{1+y^2 } + s \\int_{c(y)}^y \\exp \\left [ \\frac{1}{s } \\varphi ( t ) \\right ] \\frac{\\d}{\\d t } \\left ( - \\frac{t^{p+1}}{1+t^2 } \\right ) \\d t\\ , . \\end{gathered}\\ ] ] iterating , we readily obtain @xmath293 where @xmath294\\ , .",
    "\\label{recurrence4fn}\\ ] ] so by taking into account that ( cf .",
    "@xcite ,  13.74 ) @xmath295   \\sim \\pi s \\quad \\text{as $ s \\rightarrow 0$},\\ ] ] we see that , for @xmath54 small , @xmath62 is approximately cauchy - distributed along the imaginary axis ; figure [ piover2pdffigure ] ( a ) provides a graphical illustration of this fact .",
    "given the letac  seshadri result expressed in equation ( [ letacseshadridistribution ] ) , the form of the density function for @xmath296 , given in theorem [ generalisedletacseshadrithm ] , may seem somewhat surprising . in this section , we show that the random variable @xmath62 has a weak limit as @xmath297 , and that the density function of the limit is indeed given by the formula ( [ letacseshadridistribution ] ) . in the same way",
    ", it will be shown that @xmath62 has weak limits as @xmath74 whose density functions are those found in  [ alphaispiover2 ]",
    ". in fact , it was by considering this weak limit that we were able to discover the formula for @xmath298 when @xmath299 .    for this purpose , it will be convenient to extend the definition of @xmath156 to the whole of the complex plane as follows : @xmath300 then , we define a probability measure @xmath301 on sets @xmath302 via @xmath303 we also define the following singular probability measure on @xmath160 : @xmath304 } \\d x\\,.\\ ] ] we shall use the notation @xmath305{w}$ ] to indicate a weak limit ( limit in distribution ) .",
    "[ weaklimitthm ] let @xmath228 , @xmath306 and @xmath307 be random variables with probability measures @xmath308 , @xmath309 and @xmath301 respectively .",
    "then @xmath310{w } x \\quad \\text{and } \\quad z_\\alpha \\xrightarrow[\\alpha \\rightarrow \\pm \\pi/2\\mp]{w } \\text{{\\em i } } y_{\\pm}\\,.\\ ] ]    let @xmath311 be an arbitrary bounded and continuous function",
    ". it will be necessary and sufficient ( see @xcite ) to show that @xmath312 { } \\int_{\\mathbb c } g(z ) \\nu_{\\ell } ( \\d z ) , \\quad \\ell = 0 , \\ ,   \\pm \\pi/2\\mp\\ , .",
    "\\label{weaklimit}\\ ] ] furthermore , since @xmath313 we shall only consider positive values of @xmath71 .",
    "we express the integral on the left - hand side in polar coordinates , and then make the substitution @xmath314 note that @xmath315 @xmath316,\\ ] ] @xmath317 { }   \\begin{cases } 0 & \\text{if $ \\ell=0+$ } \\\\",
    "\\text{sgn}(r - t ) & \\text{if $ \\ell=\\pi/2-$ } \\end{cases}\\ ] ] and @xmath318 { }   \\begin{cases } 1 & \\text{if $ \\ell = 0+$ } \\\\ 0 & \\text{if $ \\ell = \\pi/2-$ }   \\end{cases}\\,.\\ ] ] so , the substitution ( [ tsubstitution ] ) yields @xmath319 where @xmath320\\ ] ] and @xmath321    our intention is to let @xmath71 tend to its limit and take the limit on the right - hand side of equation ( [ doubleintegral ] ) under the integral sign . for this purpose , we need to find an integrable function that provides an upper bound for the family @xmath322 . by using the elementary inequality @xmath323",
    "we obtain @xmath324 where @xmath325 is defined by @xmath326 \\| g \\|_{l^\\infty ( { \\mathbb c } ) } \\,.\\ ] ] furthermore , as will become clear very shortly when we consider the limit @xmath327 , we have @xmath328 \\int_{c(y)}^y \\exp \\left [ -\\frac{1}{s } \\left ( \\frac{1}{t}-t \\right ) \\right ] t^{p-1 } \\d t \\d y",
    "\\\\ = c_{p , s}(\\pi/2)^{-1}\\,.\\end{gathered}\\ ] ] we conclude ( see remark [ normalisabilitywhenalphaispiover2 ] ) that @xmath329 is integrable and so we can apply lebesgue s dominated convergence theorem : @xmath330 \\right ) } \\d t \\d r\\ , .",
    "\\label{lebesguelimit1}\\end{gathered}\\ ] ] the double integral on the right - hand side gives @xmath331 by using the substitution @xmath332 , and reporting the result in equation ( [ lebesguelimit1 ] ) , we obtain @xmath333 ^ 2 \\int_{{\\mathbb c } } g(z ) \\nu_0 ( \\d z ) \\\\ = \\int_{{\\mathbb c } } g(z ) \\nu_0 ( \\d z ) \\ , . \\label{weaklimitasalphatendstozero}\\end{gathered}\\ ] ]    similarly , @xmath334 } \\\\",
    "\\times \\int_{0}^\\infty \\int_0^ \\infty g(\\text{sgn}(r - t ) r ) \\frac{t^{p-1}}{r^{p+1 } } \\exp \\left \\ { -\\frac{1}{s } \\frac{|r - t|}{r+t } \\left [ t+\\frac{1}{t } + r+\\frac{1}{r } \\right ] \\right \\}\\ ,   \\d t \\d r\\ , . \\label{lebesguelimit2}\\end{gathered}\\ ] ] the double integral on the right - hand side equals @xmath335 \\right ) } \\d t \\d r   \\\\",
    "+ \\int_{0}^\\infty \\int_{r}^{\\infty } g(-r ) \\,\\frac{t^{p-1}}{r^{p+1 } }    \\exp{\\left ( -\\frac{1}{s } \\left [ t -r + \\frac{1}{r } - \\frac{1}{t } \\right ] \\right ) }   \\d t \\d r \\\\",
    "= \\int_{0}^{\\infty } \\int_{0}^{r } g(r ) \\ , t^{p-1}\\exp{\\left ( \\frac{1}{s } \\left[t - \\frac{1}{t}\\right]\\right ) } \\d t     \\frac{1}{r^{p+1 } }   \\exp{\\left ( -\\frac{1}{s } \\left[r - \\frac{1}{r}\\right]\\right ) }   \\d r \\\\",
    "+ \\int_{-\\infty}^{0}\\int_{-\\infty}^{r } g(r)\\ , ( -t)^{p-1}\\exp{\\left ( \\frac{1}{s } \\left[t - \\frac{1}{t}\\right]\\right ) } \\d t    \\frac{1}{(-r)^{p+1 } }   \\exp{\\left ( -\\frac{1}{s }    \\left[r - \\frac{1}{r}\\right ] \\right ) } dr\\\\ = \\int_{{\\mathbb r } } g(y)\\ ,     \\frac{1}{y^{p+1 } } \\exp { \\left \\ { -\\frac{1}{s } \\left [ y - \\frac{1}{y } \\right ]     \\right \\ } } \\int_{c(y)}^y t^{p-1 } \\exp { \\left ( \\frac{1}{s } \\left [ t - \\frac{1}{t } \\right ] \\right ) } \\d t \\d y \\\\",
    "= c_{p , s } ( \\pi/2)^{-1 } \\,\\int_{{\\mathbb c } } g(z ) \\,\\nu_{\\pi/2 } ( \\d z)\\,.\\end{gathered}\\ ] ] hence , after reporting this in equation ( [ lebesguelimit2 ] ) , we obtain @xmath336 } \\int_{\\mathbb c } g(z ) \\nu_{\\pi/2 } ( \\d z)\\,.\\ ] ] by setting @xmath337 in that equation , we deduce that @xmath338}\\ ] ] and the proof is complete .",
    "the lyapunov exponent associated with the random continued fraction ( [ continuedfraction ] ) features prominently in the applications considered in the introduction . by using the formulae given in theorems [ generalisedletacseshadrithm ] and [ alphaispiover2theorem ]",
    ", its computation reduces to a problem of quadrature . in this section ,",
    "we prove that the lyapunov exponent @xmath339 is in fact given by the logarithmic derivative of an appropriate modified bessel function for arbitrary @xmath65 and @xmath340 $ ] .",
    "in particular , the result yields explicit formulae for @xmath339 when @xmath201 , and simple asymptotic expansions for small and large @xmath54 when @xmath341 .",
    "[ lyex ] for any @xmath65 and @xmath340 $ ] , the lyapunov exponent @xmath339 associated with the invariant measure @xmath13 takes the form @xmath342    using equation ( [ lyapunovintegral ] ) and the substitution @xmath343 we have @xmath344 t^{p-1 } \\exp \\left \\ { -\\frac{\\sqrt{\\varphi ( t)}}{s } ( \\rho+1/\\rho ) \\right \\ } \\frac{\\d \\rho}{\\rho } \\d t",
    "\\\\ = \\int_0^\\infty \\ln t \\,t^{p-1 } \\frac{1}{2 } \\int_0^\\infty \\exp \\left \\ {   -\\frac{\\sqrt{\\varphi ( t)}}{s } ( \\rho+1/\\rho ) \\right \\ }   \\frac{\\d \\rho}{\\rho } \\d t\\ , .",
    "\\notag\\end{gathered}\\ ] ] now using the relation @xmath345 together with the uniform convergence ( for @xmath53 in compact sets ) of the above integral and reversing the change of variables we can continue as follows    @xmath346    hence , @xmath347    in the remarks below , we mention some of the most important consequences of the above theorem .",
    "it is easy to derive a general recurrence relation for the lyapunov exponent . to this end , it is useful to define its complex generalisation as follows : @xmath348 differentiating with respect to @xmath53 the following well - known recurrence relation for the modified bessel function ( see @xcite  3.71 ) @xmath349 one obtains the recurrence relation for @xmath350 @xmath351 which , in view of the fact that @xmath352 provides an efficient means of computing @xmath339 .",
    "( 0,0 ) ( 90,80)@xmath196 ( 90,130)@xmath353 ( 80,190)@xmath354    when @xmath355 , we have @xmath356 indeed , the result follows from theorem [ lyex ] and the formula ( see  9.6.45 in @xcite ) @xmath357_{p = n}= \\sum_{k=0}^{n-1 } \\frac{n!}{2(n - k)k ! } ( w/2)^{k - n}k_{k}(w)\\,.\\ ] ]    the two most important special cases of ( [ lyexn ] ) are :    1 .   * the lyapunov exponent for the generalized inverse gaussian law*. @xmath358 2 .   * the lyapunov exponent for the schrdinger case . * using the formula ( see @xcite   3.6 , 3.7 ) @xmath359 one immediately obtains @xmath360    next , we investigate the asymptotic behaviour of @xmath339 for arbitrary positive @xmath53 . in",
    "what follows , @xmath361 will denote the _ digamma function_.",
    "we start with the large @xmath54 asymptotics .    for arbitrary @xmath362 and @xmath340 $ ]",
    "we have the following large @xmath54 asymptotics of the lyapunov exponent @xmath363 where @xmath364 and @xmath365    although only the leading term of the expansion for the remainder @xmath366 is reported here , it will be clear from the proof that formula ( [ larges ] ) allows one to compute arbitrarily many terms .",
    "first , we note that , when @xmath201 , the lyapunov exponent is given explicitly by equation ( [ lyexn ] ) , and its asymptotics can be deduced directly from the asymptotic expansion of the modified bessel function of integral order ( see  8.446 in @xcite ) .",
    "so , from now on , we shall assume that @xmath53 is not an integer .",
    "as a starting point , we take the following representations ( equations ( 8.485 ) and ( 8.445 ) in @xcite ) @xmath367 where @xmath368 these representations yield ( cf . equations ( 9.6.42 - 3 ) in @xcite ) @xmath369 where @xmath370 thus @xmath371 for small @xmath372 , we then have the asymptotic expansion @xmath373    \\times \\\\   \\left [ 1 + \\sum_{n=1}^{\\infty } \\left ( \\sum_{k=0}^{\\infty } \\gamma(1-p)a_{k , p }   \\left(\\frac{w}{2 } \\right)^{2(k+p ) } -    \\sum_{k=1}^{\\infty } \\gamma(1-p)a_{k ,- p }   \\left(\\frac{w}{2 } \\right)^{2k } \\right)^n \\right]\\,.\\end{gathered}\\ ] ]    applying the identities ( cf . equation ( 8.365 ) , points ( 1 ) and ( 8) , @xcite ) @xmath374 and keeping only the most significant terms we obtain , for all positive noninteger @xmath53 and small @xmath372 , the expansion @xmath375 the behavior of the error term depends on the value of @xmath53 . for noninteger",
    "@xmath53 we have the following estimates of the error : @xmath376 for @xmath377 ; @xmath378 for @xmath379 and @xmath380 for @xmath381 .    substituting @xmath382 and taking the real part ( cf .",
    "theorem [ lyex ] ) completes the proof .",
    "it is worth noting that , when @xmath53 is large , there is an alternative way of obtaining the asymptotics of the lyapunov exponent . indeed , by using the integral representation",
    "@xmath383 one easily deduces the following version of equation ( 8.446 ) in @xcite : @xmath384 this yields ( [ ls ] ) for @xmath385 and explains the absence of `` logarithmic '' prefactors in the low order terms of the expansion for the lyapunov exponent when @xmath53 is large .",
    "next , we turn to the case of small @xmath54 .    for arbitrary @xmath362 and @xmath340 $ ] , we have the following small @xmath54 asymptotics of the lyapunov exponent : @xmath386 where @xmath387    higher order terms can be derived using formula ( [ smalls ] ) below .    when @xmath388 ( and only in this case ) the real part of all odd order terms in ( [ lnk ] ) vanish .",
    "thus the leading order term in this particular case is quadratic ( cf . figures [ lyexfigure ] and [ piover2lyapunovfigure ] ) .",
    "( 0,0 ) ( -50,62)@xmath196 ( -80,92)@xmath353 ( -80,143)@xmath389 ( -85,178)@xmath390 ( -100,0)(a ) ( -70,10)@xmath54 ( 140,48)@xmath391 ( 140,83)@xmath392 ( 145,143)@xmath393 ( 145,182)@xmath394 ( 100,0)(b ) ( 130,10)@xmath54    for small @xmath54 , the asymptotics follow from the behaviour of the modified bessel functions for large @xmath372 .",
    "we have ( see @xcite  7.23 ) @xmath395 where @xmath396 and where the constant @xmath397 satisfies @xmath398 ( if @xmath399 , then @xmath400 , see @xcite  7.30 ) .",
    "thus , we have @xmath401 where @xmath402.\\ ] ] this leads to the following expansion for large @xmath372 @xmath403 \\times\\\\   \\left[1 + \\sum_{n=1}^{\\infty}\\left(-\\sum_{m=1}^{n-1 } \\frac{(p , m)}{(2w)^{m}}-   \\theta(p ) \\frac{(p , n)}{(2w)^{n}}\\right)^n \\right]\\,.\\end{gathered}\\ ] ] from this expansion , every coefficient in ( [ lnk ] ) can be computed explicitly . in particular , by using the basic properties of the gamma and digamma functions , we obtain @xmath404 by setting @xmath382 and taking the real part , one obtains equation ( [ coef ] ) .",
    "although the series ( [ lnk ] ) is divergent , one can compute its sum by using standard summation techniques @xcite .",
    "the plots of @xmath405 against @xmath54 for various half - integer values of @xmath53 shown in figure [ piover2lyapunovfigure ] ( b ) were obtained by using a pad approximant i.e. a rational function of @xmath54 that matches the series to @xmath406",
    ".    we thank brian winn for a very helpful discussion leading to the discovery of formula ( [ lyexp ] ) .",
    "we begin with two integral representations of the modified bessel function : for @xmath407 , we have ( cf . @xcite ,  6.22 ) @xmath408    when calculating the moments of @xmath13 , we will use integrals of the form @xmath409 where @xmath410 , and the complex numbers @xmath48 and @xmath411 are such that @xmath412 for @xmath413 , the value is given by macdonald s formula @xcite ,  13.71 : @xmath414 differentiate this identity with respect to @xmath48 , and then multiply it by @xmath48 to obtain @xmath415\\,\\d \\tau \\\\ = \\frac{1}{2 } \\int_0^\\infty \\exp \\left \\ { -\\frac{\\tau}{2 } - \\frac{u^2+v^2}{2 \\tau } \\right \\ }   \\left [ -\\frac{1}{2 } + \\frac{v^2-u^2}{2 \\tau^2 } \\right ]   k_p \\left ( \\frac{uv}{\\tau } \\right ) \\d \\tau \\notag\\end{gathered}\\ ] ] after integration by parts .",
    "if we interchange @xmath48 and @xmath411 , this becomes @xmath416   k_p \\left ( \\frac{uv}{\\tau } \\right ) \\d \\tau \\ , .",
    "\\notag\\end{gathered}\\ ] ] hence , by adding these two identities , we find @xmath417 by similar calculations , we obtain easily the recurrence relations @xmath418\\,{\\mathcal i}_{p}^{(n-1 ) } , \\quad n \\in { \\mathbb n}\\ , .",
    "\\label{mcdonaldforwardrecurrence}\\ ] ] and @xmath419\\,{\\mathcal i}_{p}^{(n ) } , \\quad n \\in { \\mathbb z}\\ , .",
    "\\label{mcdonaldbackwardrecurrence}\\ ] ] the first of these enables the evaluation of the integral ( [ macdonaldintegral ] ) in terms of products of modified bessel functions when @xmath420 , whereas the second is appropriate when @xmath421 ( provided that @xmath422 ) .",
    "in this section , we show how to calculate the moments @xmath423 of the distribution @xmath13 . for simplicity , we shall assume that @xmath424 .",
    "we have @xmath425^{p-1 } \\\\ \\times \\exp \\left \\ { -\\frac{\\sin(2\\alpha)}{s } \\left [ \\frac{1}{r \\sin(\\alpha-\\theta)}+\\frac{r}{\\sin(\\alpha+\\theta ) } \\right ] \\right \\}\\ , r \\d r",
    "\\d \\theta \\,.\\end{gathered}\\ ] ] the substitution @xmath426 yields @xmath427 and @xmath428 where @xmath429 hence @xmath430^{m - n } \\\\ \\times\\exp\\left\\{-\\frac{1}{s } \\left [ \\frac{1}{r } \\sqrt{\\frac { \\varphi(t)}{t } } + r \\sqrt{t \\varphi(t)}\\right ] \\right\\ } \\d r \\d t\\end{gathered}\\ ] ] next , we make the change of variable @xmath431 to obtain @xmath432^{n } \\left ( \\e^{\\i \\alpha } + t \\e^{-\\i \\alpha } \\right)^{m - n }",
    "\\\\ \\times \\exp\\left\\{-\\frac{2}{s^2\\tau } \\left(t + \\frac{1}{t } \\right)\\right \\ } \\exp\\left \\{-\\frac{\\tau}{2 } - \\frac{4\\cos(2\\alpha)}{s^2\\tau } \\right \\ } \\d t \\d \\tau\\ , .",
    "\\label{momentsformula}\\end{gathered}\\ ] ]    by using the fact that @xmath433 we can , provided that @xmath434 , express this double integral in terms of the integrals ( [ macdonaldintegral ] ) .",
    "for instance , when @xmath435 , equation ( [ momentsformula ] ) yields @xmath436 this can be expressed as @xmath437 so we deduce the value of the normalisation constant from equation ( [ macdonaldformula ] ) . in the same way , by taking @xmath438 and @xmath439 , we obtain the mean : @xmath440 its value is given by equation ( [ mean ] ) . for the variance",
    ", we use @xmath441 equation ( [ momentsformula ] ) gives @xmath442 and so we deduce the value given in equation ( [ variance ] ) .",
    "in this appendix , we consider matrices distributed according to a measure @xmath2 on @xmath443 of the form @xmath444 with exactly one row being random . in other words ,",
    "the measure @xmath2 is such that one or the other of the following conditions holds : @xmath445 or @xmath446    let @xmath13 be @xmath2-invariant measure on the projective space @xmath447 . in this case , we have ( cf . equation ( 1 ) in @xcite , p. 9 ) @xmath448 for every bounded borel function @xmath329 .",
    "first , let us consider the case where condition ( [ casei ] ) holds .",
    "assume that @xmath13 has some positive moment .",
    "suppose also that @xmath2 satisfies the conditions required for the existence and positivity of the lyapunov exponent @xmath449 ( see theorem 3.6 in @xcite , p. 27",
    "which holds also in the complex domain ) .",
    "then @xmath450 we note that the splitting of the integrals in this calculation is permissible because the assumed existence of a positive moment of @xmath2 guarantees the integrability of @xmath451 and @xmath452 .",
    "the case where condition ( [ caseii ] ) holds involves a similar calculation ; hence @xmath453    now , we apply this result to the matrices ( [ randommatrix ] ) considered in section [ prelim ] . in this case ,",
    "condition ( [ casei ] ) holds ; there is only one random entry , and since it is gamma - distributed , the support of @xmath2 is not contained in any compact subgroup of @xmath58 .",
    "furthermore @xmath454 and hence the invariant measure for @xmath455 is continuous for all @xmath456 $ ] .",
    "we may therefore use proposition 3.3 in @xcite , p. 26 , to deduce the uniqueness of the invariant measure @xmath13 found in the paper .",
    "since , for all @xmath457 $ ] , this measure possesses positive moments of all orders less then one , we can apply formula ( [ gle ] ) to obtain ( [ lyapunovintegral ] ) .    for matrices of the form ( [ umatrix ] ) and for schrdinger matrices",
    ", it is condition ( [ caseii ] ) that holds , and the formula ( [ gle ] ) leads to ( [ ule ] ) .",
    "by direct substitution in equation ( [ equation4u ] ) . to facilitate the calculation , define @xmath458 we note that @xmath459    we can write @xmath460^{-(p+1 ) } \\exp \\left \\ { e(a)/s \\right \\ } , \\label{mutimesnu}\\end{gathered}\\ ] ] where @xmath461 a lengthy but straightforward calculation reveals that @xmath462 ^ 2\\,.\\ ] ] hence , by integrating equation ( [ mutimesnu ] ) with respect to @xmath141 , we obtain @xmath463 where @xmath464^{p-1 } e'(a ) \\exp \\left \\ { e(a)/s \\right \\}\\,\\d a\\,.\\ ] ] noting that @xmath465 = -\\frac{x \\sin \\alpha+y \\cos \\alpha}{r_a^4 x_a^2 } = \\frac{r^2 x}{r_a^4 x_a^2 } = -\\frac{r^2 x}{y^2 } e'(a),\\ ] ] we obtain , after integration by parts , @xmath466^{p-1 } \\exp \\left \\",
    "{ e(a)/s \\right \\ } \\right |_{0}^{a(x , y ) } + \\begin{cases } 0 & \\text{if $ p=1 $ } \\\\ \\frac{r^2 x}{y^2 } { \\mathcal e}_{p-1 } & \\text{if $ p>1 $ } \\end{cases } \\\\",
    "= \\begin{cases } \\exp \\left",
    "\\ { e(0)/s \\right \\ } & \\text{if $ p=1 $ } \\\\ \\frac{r^2 x}{y^2 } { \\mathcal e}_{p-1 } & \\text{if $ p>1 $ } \\end{cases } \\,.\\end{gathered}\\ ] ] thus , @xmath467^{p-1 } \\,\\exp \\left \\ { \\frac{\\sin(2 \\alpha)}{s } \\frac{1}{x } \\right \\}\\ ] ] and , reporting this in equation ( [ lefthandside ] ) , we have shown that @xmath468 \\right \\}\\,.\\end{gathered}\\ ] ] it follows easily that @xmath156 satisfies equation ( [ equation4u ] ) .",
    "we need only consider the case @xmath268 . as in the case",
    "@xmath469 , the proof is by direct substitution of the expression @xmath470   \\int_{c(y)}^y   \\exp \\left [ -\\frac{1}{s }   \\left ( \\frac{1}{t } -t\\right ) \\right ] \\,t^{p-1}\\,\\d t\\,,\\ ] ] where @xmath471 into the integral equation ( [ equation4fwhenalphaispiover2 ] ) .    by making the substitution @xmath472 in the integral on the right - hand side of equation ( [ equation4fwhenalphaispiover2 ] )",
    ", we obtain @xmath473 \\\\",
    "\\times t^{p-1 } \\frac{1}{s^p \\gamma(p ) } \\left ( -\\frac{1}{y } -u \\right ) ^{p-1 }   \\d t \\d u\\ , .",
    "\\label{righthandside}\\end{gathered}\\ ] ] at this point , it is helpful to treat the cases @xmath474 and @xmath475 separately .",
    "let us begin by assuming that @xmath40 .",
    "then @xmath476 on the right - hand side of the last equation and , by changing the order of integration , we obtain @xmath477 \\\\ \\times t^{p-1 } \\int_{t}^{-1/y } \\frac{1}{s^p \\gamma(p ) } \\left ( - \\frac{1}{u}-y \\right ) ^{p-1 } \\e ^{\\frac{1}{s u } } \\frac{1}{u^2 } \\d u \\d t\\,.\\end{gathered}\\ ] ] then , after making the substitution @xmath478 , followed by @xmath479 , this becomes @xmath480 \\int_0^y \\exp",
    "\\left [ -\\frac{1}{s } \\left ( \\frac{1}{\\tau } - \\tau \\right ) \\right ] \\frac{1}{\\tau^{p+1 } } \\varphi ( y-\\tau ) \\d \\tau , \\end{gathered}\\ ] ] where @xmath481 in order to prove that equation ( [ equation4fwhenalphaispiover2 ] ) holds for @xmath40 , we therefore only need to verify that @xmath482 t^{p-1 } \\d t   =   \\int_0^y \\exp \\left [ -\\frac{1}{s } \\left ( \\frac{1}{t } - t \\right ) \\right ] \\frac{1}{t^{p+1 } } \\varphi ( y - t )   \\d t\\ ] ] holds identically for every @xmath40 . clearly , it holds when @xmath483 , and so it will be sufficient to show that the _ derivatives _ are the same .",
    "the derivative of the right - hand side is @xmath484 \\frac{1}{y^{p+1 } } \\varphi(0 ) + \\int_0^y \\exp \\left [ -\\frac{1}{s } \\left ( \\frac{1}{t } - t   \\right ) \\right ] \\frac{1}{t^{p+1 } } \\varphi'(y - t ) \\d t \\\\",
    "= \\int_0^y \\exp \\left [ -\\frac{1}{s } \\left ( \\frac{1}{t } - t   \\right ) \\right ] \\frac{1}{t^{p+1 } } \\frac{1}{s^p \\gamma(p ) } ( y - t)^{p-1 } \\exp \\left [ \\frac{1}{s } ( y - t ) \\right ] \\d t \\\\ = y^{p-1 } \\e^{\\frac{y}{s } } \\int_0^y \\frac{1}{s^p \\gamma ( p ) } \\left ( \\frac{1}{t } - \\frac{1}{y } \\right ) ^{p-1 } \\e^{-\\frac{1}{s t } } \\frac{1}{t^2 } \\d t \\\\ = y^{p-1 } \\exp \\left [ - \\frac{1}{s } \\left ( \\frac{1}{y } - y \\right ) \\right ] \\int_0^\\infty \\frac{1}{s^p \\gamma(p ) } u^{p-1 } \\e^{-\\frac{u}{s } } \\d u,\\end{gathered}\\ ] ] after making the substitution @xmath485 .",
    "the result follows .    to complete the proof",
    ", we also need to consider the case @xmath474 . returning to equation ( [ righthandside ] )",
    ", we need to split the range of integration of the variable @xmath48 into positive and negative values . recalling the definition of @xmath486 and , as before , changing the order of integration , we obtain @xmath487 \\\\ \\times t^{p-1 } \\int_{t}^{0 }",
    "\\frac{1}{s^p \\gamma(p ) } \\left ( - \\frac{1}{u}-y \\right ) ^{p-1 } \\e ^{\\frac{1}{s u } } \\frac{1}{u^2 } \\d u \\d t \\\\",
    "= \\frac{\\e^{\\frac{1}{sy}}}{y^{p+1 } }   \\int_{0}^{-1/y } \\exp \\left [ -\\frac{1}{s } \\left ( \\frac{1}{t}-t \\right ) \\right ] \\\\ \\times t^{p-1 } \\int_{t}^{-1/y }",
    "\\frac{1}{s^p \\gamma(p ) } \\left ( - \\frac{1}{u}-y \\right ) ^{p-1 } \\e ^{\\frac{1}{s u } } \\frac{1}{u^2 } \\d u \\d t \\,.\\end{gathered}\\ ] ] after making the substitution @xmath488 , this becomes @xmath489    \\int_{-\\infty}^{-1/y } \\exp \\left [ -\\frac{1}{s } \\left ( \\frac{1}{t}-t \\right ) \\right ] \\phi(-1/t - y ) t^{p-1 } \\d t \\\\ -   \\frac{1}{y^{p+1 } } \\exp \\left [ \\frac{1}{s } \\left ( \\frac{1}{y } - y \\right ) \\right ]     \\int_{0}^{-1/y } \\exp \\left [   -\\frac{1}{s } \\left ( \\frac{1}{t}-t \\right ) \\right ] t^{p-1 } \\d t,\\end{gathered}\\ ] ] where @xmath490 therefore , we have to prove that @xmath491 t^{p-1 } \\d t \\\\ = \\int_{-\\infty}^{-1/y } \\exp \\left [ -\\frac{1}{s } \\left ( \\frac{1}{t}-t \\right ) \\right ] \\phi(-1/t - y ) t^{p-1 } \\d t \\\\ - \\int_{0}^{-1/y } \\exp \\left [   -\\frac{1}{s } \\left ( \\frac{1}{t}-t \\right ) \\right ] t^{p-1 } \\d t\\end{gathered}\\ ] ] holds for every @xmath474 . on both sides , the limit as @xmath492 is zero .",
    "furthermore , the derivative of the right - hand side is @xmath493 \\frac{(-1)^{p-1}}{y^{p+1 } } \\left [ \\phi ( 0)-1 \\right ] \\\\ - \\int_{-\\infty}^{-1/y } \\exp \\left [ -\\frac{1}{s } \\left (   \\frac{1}{t}-t \\right ) \\right ] t^{p-1 } \\phi'(-1/t - y ) \\\\ = \\int_{-\\infty}^{-1/y } \\exp \\left [ -\\frac{1}{s } \\left ( \\frac{1}{t } -t \\right ) \\right ] t^{p-1 } \\frac{1}{s^p \\gamma(p ) }   \\left ( -\\frac{1}{t}-y \\right ) ^{p-1 } \\exp \\left [ -\\frac{1}{s } \\left ( -\\frac{1}{t}-y \\right ) \\right ] \\d t \\\\",
    "= y^{p-1 } \\e^{\\frac{y}{s } } \\int_{-\\infty}^{-1/y } \\frac{1}{s^p \\gamma(p ) } \\left ( -\\frac{1}{y}-t\\right ) ^{p-1 } \\e^{\\frac{t}{s } } \\d t \\\\ = y^{p-1 } \\exp \\left [ -\\frac{1}{s } \\left ( \\frac{1}{y}-y \\right ) \\right ] \\int_0^\\infty \\frac{1}{s^p \\gamma(p ) } v^{p-1 } \\e^{-v } \\d v\\end{gathered}\\ ] ] after making the substitution @xmath494 .",
    "it is actually simpler to work with @xmath496 so let write @xmath497 where @xmath498 equation ( [ recurrence4fn ] ) then gives @xmath499 \\ , .",
    "\\label{recurrence4un}\\ ] ] a direct calculation of the first few terms reveals that the @xmath500 have a very simple structure : @xmath501 by substituting these expressions in equation ( [ recurrence4un ] ) , one obtains the recurrence relations @xmath502 with the starting value @xmath503 .",
    "we then have @xmath504 and @xmath505 as @xmath289 , where @xmath506 the @xmath507 and @xmath508 satisfy the recurrence relations @xmath509"
  ],
  "abstract_text": [
    "<S> we construct explicit invariant measures for a family of infinite products of random , independent , identically - distributed elements of @xmath0 . </S>",
    "<S> the matrices in the product are such that one entry is gamma - distributed along a ray in the complex plane . </S>",
    "<S> when the ray is the positive real axis , the products are those associated with a continued fraction studied by letac & seshadri [ _ z . </S>",
    "<S> wahr . </S>",
    "<S> verw . </S>",
    "<S> geb . _ </S>",
    "<S> * 62 * ( 1983 ) 485 - 489 ] , who showed that the distribution of the continued fraction is a generalised inverse gaussian . </S>",
    "<S> we extend this result by finding the distribution for an arbitrary ray in the complex right - half plane , and thus compute the corresponding lyapunov exponent explicitly . </S>",
    "<S> when the ray lies on the imaginary axis , the matrices in the infinite product coincide with the transfer matrices associated with a one - dimensional discrete schrdinger operator with a random , gamma - distributed potential . </S>",
    "<S> hence , the explicit knowledge of the lyapunov exponent may be used to estimate the ( exponential ) rate of localisation of the eigenstates . </S>"
  ]
}