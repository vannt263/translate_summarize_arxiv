{
  "article_text": [
    "optimal control of markov control processes ( mcp ) up to an exit time is a problem with a long and rich history .",
    "it has mostly been studied as the minimization of an expected undiscounted cost until the first time that the state enters a given target set , see e.g. ,  ( * ? ? ?",
    "* chapter  ii ) ,  ( * ? ? ?",
    "* chapter  8) , and the references therein .",
    "in particular , if a unit cost is incurred as long as the state is outside the target set , then the problem of minimizing the cost accumulated until the state enters the target is known variously as the _ pursuit problem _  @xcite , _ transient programming _",
    "@xcite , the _ first passage problem _",
    "@xcite , the _ stochastic shortest path problem _",
    "@xcite , and _ control up to an exit time _  @xcite .",
    "these articles deal with at most countable state and action spaces .",
    "the problem of optimally controlling a system until an exit time from a given set has gained significance in financial and insurance mathematics , see , e.g. , @xcite .",
    "our interest in this problem stems from our attempts to develop a general theory of stochastic model - predictive control ( mpc ) . in its bare essentials ,",
    "deterministic mpc  @xcite consists of two steps : ( i ) solving a finite - horizon optimal control problem with constraints on the state and the controlled inputs to get an optimal policy , and ( ii ) applying a controller derived from the policy obtained in step ( i ) in a rolling - horizon fashion .",
    "theoretical foundation of stochastic mpc is still in its infancy , see  @xcite and the references therein for some related work . in view of its close relationship with applications , any satisfactory theory of stochastic mpc",
    "must necessarily take into account its practical aspects . in this context",
    "an examination of a standard linear system with constrained controlled inputs affected by independent and identically distributed ( i.i.d . )",
    "unbounded ( e.g. , gaussian ) disturbance inputs shows that no control policy can ensure that with probability one the state stays confined to a bounded _",
    "safe set _ for all instants of time .",
    "this is because the noise is unbounded and the samples are independent of each other .",
    "although disturbances are not likely to be unbounded in practice , assigning an a priori bound seems to demand considerable insight . in case a bounded - noise model is adopted , existing robust mpc techniques  @xcite may be applied , in which the central idea is to synthesize a controller based on the bounds of the noise such that the target set becomes invariant with respect to the closed - loop dynamics .",
    "however , since the optimal policy is based on a worst - case analysis , it usually leads to rather conservative controllers and sometimes even to infeasibility .",
    "moreover , complexity of the optimization problem grows rapidly ( typically exponentially ) with the optimization horizon .",
    "an alternative is to replace the hard constraints by probabilistic ( soft ) ones .",
    "the idea is to find a policy that guarantees that the state constraints are satisfied with high probability over a sufficiently long time horizon .",
    "while this approach may improve feasibility aspects of the problem , it does not address the issue of what actions should be taken once the state violates the constraints .",
    "see  @xcite for recent results in this direction .    in view of the above considerations , developing recovery strategies appears to be a necessary step .",
    "such a strategy is to be activated once the state violates the constraints and to be deactivated whenever the system returns to the safe set . in general",
    ", a recovery strategy must drive the system quickly to the safe set while simultaneously meeting other performance objectives . in the context of mpc ,",
    "two merits are immediate : ( a ) once the constraints are transgressed , appropriate actions can be taken to bring the state back to the safe set quickly and optimally , and ( b ) if the original problem is posed with hard constraints on the state , in view of ( a ) they may be relaxed to probabilistic ones to improve feasibility .    in this article",
    "we address the problem of synthesizing optimal recovery strategies .",
    "we formulate the problem as the minimization of an expected discounted cost until the state enters the safe set .",
    "an almost customary assumption in the literature ( see , e.g. ,  @xcite and the references therein , ) concerned with stochastic optimal control up to an exit time is that the target set is absorbing .",
    "that is , there exists a control policy that makes the target set invariant with respect to the closed - loop stochastic dynamics .",
    "this is rather restrictive for mpc problems ",
    "it is invalid , for instance , in the very simple case of a linear controlled system with i.i.d .  gaussian noise inputs .",
    "we do not make this assumption , for , as mentioned above , our primary motivation for solving this problem is precisely to deal with the case that the target set is not absorbing . as a result of this , it turns out that the dynamic programming equations involve integration over subsets of the state - space and therefore are difficult to solve . at present",
    "there is no established method to solve such equations in uncountable state - spaces .",
    "however , in finite state - space cases tractable approximate dynamic programming methods  @xcite may be employed to arrive at suboptimal but efficient policies .",
    "this article unfolds as follows . in   [ s : prelims ] we define the general setting of the problem , namely , markov control processes on polish spaces , their transition kernels and the main types of control strategies . in   [ s : edc ] we establish our main theorem  [ t : edc ] under standard mild hypotheses .",
    "this result guarantees the existence of a deterministic stationary policy that leads to the minimal cost and also provides a bellman equation that the value function must satisfy .",
    "a contraction mapping approach to the problem is pursued in   [ s : contr ] under the ( standard ) assumption that the cost - per - stage function satisfies certain growth - rate conditions . the main result ( proposition  [ p : tfp ] ) of",
    "this section asserts both the existence and uniqueness of the optimal value function .",
    "asymptotic discount - optimality of the value - iteration policy is investigated in   [ s : ado ] under two different sets of hypotheses ; in particular , the results of this section show that rolling - horizon strategy approaches optimality as the length of the horizon window increases to infinity . a rolling - horizon strategy corresponding to our optimal control problem is developed in   [ s : rh ] ; in theorem  [ t : rh ] we establish quantitative bounds on the degree of sub - optimality of the rolling - horizon strategy with respect to the optimal policy .",
    "we conclude in   [ s : concl ] with a discussion of future work .",
    "the state and control / action sets are assumed to be borel subsets of polish spaces .",
    "we employ the following standard notations .",
    "let @xmath0 denote the natural numbers @xmath1 , and @xmath2 denote the nonnegative integers @xmath3 .",
    "let @xmath4 be the standard indicator function of a set @xmath5 , i.e. , @xmath6 if @xmath7 and @xmath8 otherwise . for two real numbers @xmath9 and @xmath10 , let @xmath11",
    ".    given a nonempty borel set @xmath12 ( i.e. , a borel subset of a polish space ) , its borel @xmath13-algebra is denoted by @xmath14 . by convention",
    "`` measurable '' means `` borel - measurable '' in the sequel .",
    "if @xmath12 and @xmath15 are nonempty borel spaces , a _ stochastic kernel _ on @xmath12 given @xmath15 is a mapping @xmath16 such that @xmath17 is a probability measure on @xmath12 for each fixed @xmath18 , and @xmath19 is a measurable function on @xmath15 for each fixed @xmath20 .",
    "we let @xmath21 be the family of all stochastic kernels on @xmath12 given @xmath15 .",
    "we briefly recall some standard definitions .",
    "[ d : mcm ] a _ markov control model _ is a five - tuple @xmath22 consisting of a nonempty borel space @xmath12 called the _ state space _ , a nonempty borel space @xmath5 called the _",
    "control _ or _ action set _ , a family @xmath23 of nonempty measurable subsets @xmath24 of @xmath5 , where @xmath24 denotes the set of _ feasible controls _ or _ actions _ when the system is in state @xmath25 , and with the property that the set @xmath26 of feasible state - action pairs is a measurable subset of @xmath27 , a stochastic kernel @xmath28 on @xmath12 given @xmath29 called the _ transition law _ , and",
    "a measurable function @xmath30 called the _ cost - per - stage function_.    [ a : basic ] the set @xmath29 of feasible state - action pairs contains the graph of a measurable function from @xmath12 to @xmath5 .",
    "we let @xmath31 , @xmath32 , @xmath33 and @xmath34 denote the set of all randomized and history - dependent admissible policies , randomized markov , deterministic markov and deterministic stationary policies , respectively . for further details and notations on policies",
    "see , e.g. ,  @xcite .",
    "consider the markov control model  , and for each @xmath35 define the space @xmath36 of _ admissible histories _ up to time @xmath37 as @xmath38 , and @xmath39 for @xmath40 . a generic element @xmath41 of @xmath36 , called an admissible @xmath37-history is a vector of the form @xmath42 , with @xmath43 for @xmath44 and @xmath45 .",
    "hereafter we let the @xmath13-algebra generated by the history @xmath41 be denoted by @xmath46 , @xmath47 .",
    "let @xmath48 be the measurable space consisting of the ( canonical ) sample space @xmath49 , and @xmath50 is the corresponding product @xmath13-algebra .",
    "let @xmath51 be an arbitrary control policy and @xmath52 an arbitrary probability measure on @xmath12 , referred to as the initial distribution . by a theorem of ionescu - tulcea  (",
    "* chapter 3 ,  4 ,",
    "theorem  5 ) , there exists a unique probability measure @xmath53 on @xmath48 supported on @xmath54 , and such that for all @xmath20 , @xmath55 , and @xmath56 , @xmath47 , @xmath57 and    @xmath58    the stochastic process @xmath59 is called a discrete - time _",
    "markov control process_. let @xmath60 denote the set of stochastic kernels @xmath61 in @xmath62 such that @xmath63 for all @xmath25 , and let @xmath64 denote the set of all measurable functions @xmath65 satisfying @xmath66 for all @xmath25 .",
    "the functions in @xmath64 are called _ selectors _ of the set - valued mapping @xmath67 .",
    "the transition kernel @xmath28 in   under a policy @xmath68 is given by @xmath69 , defined as @xmath70 .",
    "occasionally we suppress the dependence of @xmath71 on @xmath72 and write @xmath73 in place of @xmath74 .",
    "the cost - per - stage function at the @xmath75-th stage under a policy @xmath76 is written as @xmath77 .",
    "we simply write @xmath78 and @xmath79 , respectively , for policies @xmath80 and @xmath81 .    since we shall be exclusively concerned with markov policies and its subclasses , in the sequel we use the notation @xmath31 for the class of all randomized markov strategies .",
    "let @xmath82 be a measurable set , @xmath83 and let @xmath84 .. ] we note that @xmath85 is an @xmath86-stopping time .",
    "let us define @xmath87 , \\qquad \\alpha\\in\\:]0 , 1[,\\ ] ] as the _ @xmath88-discounted expected cost _ under policy @xmath89 corresponding to the markov control process @xmath59 .. ] our objective is to minimize @xmath90 over a class of control policies @xmath31 , i.e. , find the @xmath88-discount value function @xmath91 , \\qquad \\alpha\\in\\:]0 , 1[.          \\end{aligned}\\ ] ] a policy that attains the infimum above is said to be _",
    "@xmath88-discount optimal_.    as mentioned in the introduction , the optimization problem   with @xmath92 and the cost - per - stage function @xmath93 is known as the stochastic shortest path problem .",
    "the objective of this problem is to drive the state to a desired set ( @xmath94 in our case ) as soon as possible , and the expected cost @xmath95 for a policy @xmath96 corresponding to the above cost - per - stage function is readily seen to be @xmath97 $ ] . in this light we observe that the minimization problem in   with the cost - per - stage function @xmath93 can be viewed as a discounted stochastic shortest path problem .",
    "it follows immediately that the corresponding expected cost @xmath98 is @xmath99\\bigr)/(1-\\alpha)$ ] .",
    "note that the minimization of @xmath98 over a class of policies is always well - defined for @xmath100 .",
    "moreover , because of the monotonic behavior of the map @xmath1010 , 1[\\;\\ni\\alpha{\\ensuremath{\\longmapsto}}\\bigl(1-\\mathsf e^\\pi_x\\bigl[\\alpha^\\tau\\bigr]\\bigr)/(1-\\alpha)$ ] , one may hope to get a good approximation of the original stochastic shortest path problem .",
    "however , pathological examples can be constructed to show that a solution to the stochastic shortest path problem may not exist , whereas minimization of @xmath98 is always well defined , although in either case the state may never reach the desired set @xmath94 almost surely-@xmath102 .",
    "[ r : diffc ] given a cost - per - stage function @xmath103 on @xmath29 , one can redefine it to be @xmath104 to turn the problem   into the minimization of @xmath105 $ ] for @xmath1060 , 1[$ ] .",
    "this cost functional can be equivalently written as an infinite horizon cost functional , as in @xmath107 $ ] , or as in @xmath108 $ ] . however , the absence of a policy that guarantees that @xmath109 stays inside @xmath94 for all time after @xmath85 necessarily means that the problem   corresponding to the markov control model in definition  [ d : mcm ] is not equivalent to the minimization of the infinite horizon cost functional @xmath110 $ ] .",
    "[ pgr : policies ] _ a word about admissible policies . _",
    "it is clear at once that the class of admissible policies for the problem   is different from the classes considered in   [ s : prelims ] . indeed , since the process is killed at the stopping time @xmath85 , it follows that the class of admissible policies should also be truncated at the stage @xmath111 . for a given stage @xmath112",
    "we define the @xmath113-th policy element @xmath114 only on the set @xmath115 .",
    "note that with this definition @xmath114 becomes a @xmath116-measurable randomized control ( in general ) .",
    "it is also immediate from the definition of @xmath85 that if the initial condition @xmath72 is inside @xmath94 , then the set of admissible policies is empty ; indeed , in this case @xmath117 , and there is no control needed .",
    "in other words , the domain of @xmath114 is contained in the `` spatial '' region @xmath118 ; since @xmath114 is not defined on @xmath94 , this is equivalent to @xmath114 being well - defined on @xmath115 .",
    "[ pgr : convention ] _ some re - definitions . _ to simplify the formulas from now on we let the cost - per - stage function to be defined on @xmath119 . with this convention in place",
    "our problem   can be posed as the minimization of @xmath120 $ ] over admissible policies .",
    "also , henceforth we redefine the set @xmath29 of state - action pairs to be @xmath121 , and we note that this new set is a measurable subset of the original set of state - action pairs . also , we let @xmath64 be the set of selectors of the set - valued mapping @xmath122 .",
    "recall that a function @xmath123 is said to be _ inf - compact on @xmath29 _ if for every @xmath25 and @xmath124 the set @xmath125 is compact .",
    "a transition kernel @xmath28 on a measurable space @xmath12 given another measurable space @xmath15 is said to be _ strongly feller _ ( or _ strongly continuous _ ) if the mapping @xmath126 is continuous and bounded for every measurable and bounded function @xmath127 .",
    "a function @xmath123 is _ lower semicontinuous _ ( l.s.c . ) if for every sequence @xmath128 converging to @xmath129 , we have @xmath130 ; or , equivalently , if for every @xmath131 , the set @xmath132 is closed in @xmath29 .",
    "[ a : key ] in addition to assumption  [ a : basic ] , we stipulate that    1 .",
    "the set @xmath24 is compact for every @xmath25 , 2 .",
    "the cost - per - stage @xmath103 is lower semicontinuous , nonnegative , and inf - compact on @xmath29 , and 3 .",
    "the transition kernel @xmath28 is strongly feller .",
    "the following is our main result on expected discounted cost up to the first time @xmath85 to hit @xmath94 ; a proof is presented later in this section .",
    "[ t : edc ] suppose that assumption [ a : key ] holds",
    ". then    1 .",
    "the @xmath88-discount value function @xmath133 is the ( positive ) minimal measurable solution to the @xmath88-discounted cost optimality equation ( @xmath88-dcoe ) @xmath134\\qquad { \\ensuremath{\\forall\\,}}x\\in x{\\ensuremath{\\!\\smallsetminus}}k.\\ ] ] 2 .",
    "there exists a selector @xmath135 such that @xmath136 , @xmath137 , attains the minimum in  , i.e. , @xmath138 and the deterministic stationary policy @xmath139 is @xmath88-discount optimal ; conversely , if @xmath140 is @xmath88-discount optimal , then it satisfies  .",
    "we observe that theorem  [ t : edc ] does not assert that the optimal value function @xmath133 is unique in any sense . in   [",
    "s : contr ] we prove a result ( proposition  [ p : tfp ] ) under additional hypotheses that guarantees uniqueness of @xmath133 .",
    "since we do not assume that the cost - per - stage function @xmath103 is bounded , a useful approach is to consider the @xmath88-_value iteration _ ( @xmath88-vi ) _ functions _ defined by @xmath141 } ,          \\end{cases }          n\\in{\\ensuremath{\\mathbb{n}}},\\;\\ ; x\\in x{\\ensuremath{\\!\\smallsetminus}}k.\\ ] ] of course we have to demonstrate that @xmath142 for all @xmath25 .",
    "the functions @xmath143 , @xmath144 , may be identified with the optimal cost function for the minimization of the process stopped at the @xmath145-th step , i.e. , @xmath146.\\ ] ] to get an intuitive idea , fix a deterministic markov policy @xmath51 , and take the first iterate @xmath147 . from   it",
    "is immediately clear that @xmath148 if @xmath149 , and not defined otherwise . for the second iterate , we have @xmath150\\\\              & = \\inf_{\\pi\\in\\pi}\\left(c(x , \\pi_0(x ) ) + \\alpha\\!\\int_x \\ !",
    "q({\\ensuremath{\\mathrm{d}}}\\xi_1|x , \\pi_1(x)){\\ensuremath{\\boldsymbol{1}_{x{\\ensuremath{\\!\\smallsetminus}}k}}}(\\xi_1 ) c(\\xi_1 , \\pi_1)\\right ) .",
    "\\end{aligned}\\ ] ] note that only those sample paths that do not enter @xmath94 at the first step contribute to the cost at the second stage .",
    "this property is ensured by the indicator function that appears on the right - hand side of the last equality above .",
    "let @xmath109 be a markov chain with state - space @xmath151 and transition probability matrix @xmath152_{m\\times m}$ ] , where the argument of @xmath153 depicts the dependence on the action @xmath154 with @xmath5 being a compact subset of @xmath155 .",
    "let @xmath156 for @xmath157 , fix @xmath1580 , 1[$ ] and let @xmath159 .",
    "suppose further that @xmath160 for all @xmath161 ; this means , in particular , that the target set @xmath94 can not be absorbing for any deterministic stationary policy . our objective is to find an optimal policy corresponding to the the minimal cost  .",
    "the optimal value function @xmath133 is @xmath8 on @xmath94 and for every @xmath162 we have @xmath163 = 1 + \\alpha\\min_{a\\in a(i)}\\sum_{j = m'+1}^m q_{ij}(a ) v^\\star(j)$ ] .",
    "the most elementary case is that of @xmath164 ; then @xmath165 , and given a sufficiently regular function @xmath166 this can be solved at once to get @xmath167 , which characterizes the function ( vector ) @xmath133 completely .",
    "the optimal policy in this case is @xmath168 ; if the function @xmath166 is convex , then the minimum is attained on @xmath5 and thus leads to a unique optimal policy .",
    "recall from paragraph  [ pgr : convention ] that @xmath103 is defined on @xmath119 , @xmath169 and @xmath64 is the set of selectors of the set - valued map @xmath122 .",
    "we begin with a sequence of lemmas .",
    "[ l : keyconvergence ] let the functions @xmath170 and @xmath171 , @xmath172 , be l.s.c .",
    ", inf - compact and bounded below .",
    "if @xmath173 , then @xmath174    [ l : basicselector ] suppose that    * @xmath24 is compact for each @xmath137 and @xmath29 is a measurable subset of @xmath175 , and * @xmath176 is a measurable inf - compact function , @xmath177 is l.s.c .",
    "on @xmath24 for each @xmath25 .    then there exists a selector @xmath135 such that @xmath178 and @xmath179 is a measurable function .",
    "let @xmath180 denote the convex cone of nonnegative extended real - valued measurable functions on @xmath119 , and for every @xmath181 let us define the map @xmath182 by @xmath183.\\ ] ] the map @xmath184 is the _ dynamic programming operator _ corresponding to our problem  .",
    "having defined the dynamic programming operator @xmath184 above , it is important to distinguish conditions under which the function @xmath182 is measurable for @xmath185 .",
    "we have the following lemma .",
    "[ l : selector ] under assumption [ a : key ] , the mapping @xmath184 in   takes @xmath180 into itself .",
    "moreover , there exists a selector @xmath186 such that @xmath182 defined in   satisfies @xmath187    fix @xmath185 .",
    "the strong - feller property of @xmath28 on @xmath29 and lower - semicontinuity of the cost - per - stage function @xmath103 defined on @xmath94 show that the map @xmath188 is lower - semicontinuous . from nonnegativity of @xmath189",
    "it follows that for every @xmath137 and @xmath190 , @xmath191 and the set @xmath192 is compact by inf - compactness of @xmath103 . since by definition @xmath193 , by lemma [",
    "l : basicselector ] it would follow that a selector @xmath194 exists such that @xmath195 once we verify the hypotheses of this lemma .",
    "for this we only have to verify that @xmath196 is l.s.c .",
    "( which implies it is measurable ) and inf - compact on @xmath29 .",
    "we have seen above that @xmath196 is a l.s.c .",
    "function on @xmath29 .",
    "therefore , for each @xmath137 the map @xmath197 is also l.s.c .  on @xmath24 .",
    "thus , by definition of lower semicontinuity , the set @xmath198 in   is closed for every @xmath137 and @xmath131 . since",
    "a closed subset of a compact set is compact , it follows that @xmath198 is compact , which in turn shows inf - compactness of @xmath196 on @xmath29 and proves the assertion .",
    "the following lemma shows how functions @xmath185 satisfying @xmath199 relate to the optimal value function .",
    "[ l : tineq ] suppose that assumption [ a : key ] holds . if @xmath181 is such that @xmath199 , then @xmath200 .",
    "suppose @xmath185 satisfies @xmath201 , and let @xmath194 be a selector ( whose existence is guaranteed by lemma [ l : selector ] ) that attains the infimum in  .",
    "fix @xmath137 .",
    "we have @xmath202 the operator @xmath184 in   is monotone , for if @xmath203 are two functions with @xmath204 , then clearly @xmath205 due to nonnegativity of @xmath103 . therefore ,",
    "iterating the above inequality for a second time we obtain @xmath206 after @xmath207 such iterations we arrive at @xmath208 + \\mathsf e^{f^\\infty}_x\\bigl[\\alpha^{n } u(x_{n}){\\ensuremath{\\boldsymbol{1}_{\\{n < \\tau\\}}}}\\bigr].\\ ] ] since @xmath209 , letting @xmath210 we get @xmath211 since @xmath137 is arbitrary , the assertion follows .",
    "the next lemma deals with convergence of the value iterations to the optimal value function .",
    "[ l : viconv ] suppose that assumption [ a : key ] holds .",
    "then @xmath212 on @xmath119 , and the function @xmath133 satisfies the @xmath88-dcoe .",
    "note that since @xmath213 $ ] for @xmath137 , it follows that @xmath214 { \\ensuremath{\\leqslant}}\\mathsf e_x^\\pi\\!\\left[\\sum_{i=0}^{\\tau-1 } \\alpha^i c(x_i , a_i)\\right],\\ ] ] and therefore , taking the infimum over all policies @xmath89 on the right hand side , we get @xmath215 since the cost - per - stage function is nonnegative , @xmath184 is a monotone operator .",
    "therefore , since @xmath216 and @xmath217 for @xmath144 , it follows that the @xmath88-vi functions form a nondecreasing sequence in @xmath180 , which implies that @xmath218 for some function @xmath219 . for @xmath144",
    "we define @xmath220 the monotone convergence theorem guarantees that @xmath221 pointwise on @xmath29 . as in the proof of lemma",
    "[ l : selector ] one can establish inf - compactness and lower semicontinuity of @xmath222 , and @xmath223 on @xmath29 . from lemma",
    "[ l : keyconvergence ] it now follows that for every @xmath137 we have @xmath224 this shows that @xmath179 satisfies the @xmath88-dcoe , @xmath225 .",
    "it remains to show that @xmath226 .",
    "but by lemma [ l : tineq ] , @xmath225 implies that @xmath227 and the reverse inequality follows from   by taking limits as @xmath228 .",
    "[ l : adcoestat ] for every deterministic stationary policy @xmath79 we have @xmath229    fix a deterministic stationary policy @xmath79 and @xmath137 . the @xmath88-discounted cost @xmath230 corresponding to this policy satisfies , in view of the definition of @xmath85 and the fact that @xmath137 , @xmath231 = \\mathsf e_x^{f^\\infty}\\!\\left [ c(x , f ) + \\sum_{i=1}^{\\tau-1 } \\alpha^i c(x_i , f)\\right]\\nonumber\\\\                  & = c(x , f ) + \\alpha\\mathsf e_x^{f^\\infty}\\!\\left[\\sum_{i=1}^{\\tau-1 } \\alpha^{i-1 } c(x_i , f)\\right].\\label{e : spolicy1 }              \\end{aligned}\\ ] ] but then by the markov property , @xmath232 & = \\mathsf e^{f^\\infty}\\!\\left[\\mathsf e^{f^\\infty}\\!\\left[\\sum_{i=1}^{\\tau-1 } \\alpha^{i-1 } c(x_i , f)\\left.\\left.\\vphantom{\\sum_i^\\tau}\\right|x_{1{\\ensuremath{\\wedge}}(\\tau-1)}\\right]\\right|x_0 = x\\right]\\\\                  & = \\int_x { \\ensuremath{\\boldsymbol{1}_{x{\\ensuremath{\\!\\smallsetminus}}k}}}(y ) q({\\ensuremath{\\mathrm{d}}}y|x , f)\\ ; \\mathsf e^{f^\\infty}\\!\\left[\\sum_{i=1}^{\\tau-1 } \\alpha^{i-1 } c(x_i , f)\\left.\\vphantom{\\sum_i^\\tau}\\right|x_1 = y\\right]\\\\                  & = \\int_x { \\ensuremath{\\boldsymbol{1}_{x{\\ensuremath{\\!\\smallsetminus}}k}}}(y ) q({\\ensuremath{\\mathrm{d}}}y|x , f)\\ ; v(f^\\infty , y ) .",
    "\\end{aligned}\\ ] ] this substituted back in   gives  .",
    "\\(i ) that @xmath133 is a solution of the @xmath88-dcoe follows from lemma [ l : viconv ] , and that @xmath133 is the minimal solution follows from lemma  [ l : tineq ] , since @xmath233 implies @xmath234 .",
    "\\(ii ) lemma  [ l : selector ] guarantees the existence of a selector @xmath135 such that   holds .",
    "fix @xmath144 and @xmath137 . as in the proof of lemma",
    "[ l : tineq ] , iterating equation   @xmath207-times we arrive at @xmath235 + \\mathsf e^{f_\\star^\\infty}_x\\bigl[\\alpha^{n } v^\\star(x_{n}){\\ensuremath{\\boldsymbol{1}_{\\{n < \\tau\\}}}}\\bigr ] { \\ensuremath{\\geqslant}}\\mathsf e_x^{f_\\star^\\infty}\\!\\left[\\sum_{i=0}^{(n-1){\\ensuremath{\\wedge}}(\\tau-1 ) } \\alpha^i c(x_i , f_\\star)\\right ] .",
    "\\end{aligned}\\ ] ] by the monotone convergence theorem we have @xmath236 = \\mathsf e_x^{f_\\star^\\infty}\\!\\left[\\sum_{i=0}^{\\tau-1 } \\alpha^i c(x_i , f_\\star)\\right],\\ ] ] which shows that @xmath237 , and since @xmath137 is arbitrary , it follows that @xmath238 .",
    "the reverse inequality follows from the definition of @xmath133 in  .",
    "we conclude that @xmath239 , and that @xmath139 is an optimal policy .    for the converse ,",
    "if @xmath139 is an optimal deterministic stationary policy , then by lemma [ l : adcoestat ] , equation   becomes @xmath240 for @xmath137 , which is identical to  .",
    "for the purposes of this section we let @xmath241 denote the real vector space of real - valued measurable functions on @xmath12 , and @xmath180 be the convex cone of nonnegative elements of @xmath241 .",
    "( note that according to paragraph  [ pgr : convention ] we let the elements of @xmath180 take the value @xmath242 . )",
    "given a measurable _ weight function _",
    "@xmath243 in @xmath180 , we define the weighted norm @xmath244 .",
    "it is well - known that @xmath245 is a banach space .",
    "[ a : further ] in addition to assumption  [ a : key ] , we require that there exist @xmath246 , @xmath247 , and a measurable weight function @xmath243 such that for every @xmath137    1 .",
    "@xmath248 ; 2 .",
    "@xmath249 .",
    "if @xmath103 is bounded , the weight function @xmath250 may be taken to be @xmath251 .",
    "also , if @xmath72 and @xmath252 are the current and the next states of the markov control process , respectively , then assumption  [ a : further](ii ) implies that @xmath253 { \\ensuremath{\\leqslant}}\\beta w(x)\\qquad { \\ensuremath{\\forall\\,}}x\\in x{\\ensuremath{\\!\\smallsetminus}}k.\\ ] ] we observe that this bears a resemblance with classical lyapunov - like stability criteria , more specifically , the foster - lyapunov conditions  ( * ? ? ?",
    "* chapter  8) , @xcite . however , the condition in assumption  [ a : further](ii ) is uniform over the set of actions @xmath24 pointwise in @xmath72 .",
    "it connects the growth of the cost - per - stage function @xmath103 with a contraction induced by the discount factor @xmath88 .",
    "recall that a mapping @xmath254 on a nonempty complete metric space @xmath255 is a _ contraction _ if there exists a constant @xmath256 such that @xmath257 for all @xmath258 .",
    "the constant @xmath259 is said to the the _ modulus _ of the map @xmath194 .",
    "a contraction has a unique fixed point @xmath260 satisfying @xmath261 .",
    "[ p : contr ] let @xmath184 be a monotone map from the banach space @xmath245 into itself . if there exists a @xmath256 such that @xmath262 then @xmath184 is a contraction with modulus @xmath259 .",
    "we have the following lemma .",
    "[ l : tcontr ] under assumption [ a : further ] , the map @xmath184 in   is a contraction on @xmath263 with modulus @xmath264 .",
    "fix @xmath185 with @xmath265 . as in the proof of lemma",
    "[ l : selector ] , the mapping @xmath266 is well - defined and l.s.c .  in @xmath267 for all @xmath137 . by the same lemma we also know that @xmath184 maps @xmath180 into @xmath180 . for every @xmath129 , by assumption  [",
    "a : further ] , @xmath268 which shows that @xmath269 .",
    "therefore , @xmath184 maps @xmath263 into itself . since @xmath270 , it is clear that @xmath184 is a monotone map on @xmath263 . by assumption  [",
    "a : further](ii ) , for @xmath131 and @xmath137 we have @xmath271 this shows that   holds with @xmath272 , and proposition  [ p : contr ] implies that @xmath184 is a contraction on @xmath263 .",
    "the following proposition establishes bounds for the distance between the optimal value function @xmath133 and the @xmath88-vi functions @xmath273 by employing the contraction mapping @xmath184 of lemma  [ l : tcontr ] .",
    "[ p : tfp ] suppose that assumption [ a : further ] holds , and let @xmath274 .",
    "then :    1 .   the @xmath88-discount value function @xmath133 satisfies @xmath275 .",
    "2 .   the @xmath88-vi functions @xmath273 satisfy @xmath276 in particular , @xmath277 .",
    "the optimal value function @xmath133 is the unique function in @xmath263 that solves the @xmath88-dcoe  .",
    "\\(i ) let @xmath96 be an arbitrary markov policy .",
    "trivially we have @xmath278 { \\ensuremath{\\leqslant}}w(x)$ ] .",
    "fix @xmath172 , and a history @xmath279 . in view of assumption",
    "[ a : further](ii ) , on the event @xmath280 we have @xmath281 = \\int_{x{\\ensuremath{\\!\\smallsetminus}}k } q({\\ensuremath{\\mathrm{d}}}y|x_{i-1 } , a_{i-1 } ) w(y ) { \\ensuremath{\\leqslant}}\\beta w(x_{i-1})\\quad { \\ensuremath{\\forall\\,}}a_i\\in a(x_i ) ,              \\end{aligned}\\ ] ] which shows that @xmath282 { \\ensuremath{\\leqslant}}\\beta \\mathsf e^\\pi_x\\bigl[w(x_{i-1}){\\ensuremath{\\boldsymbol{1}_{\\{i < \\tau\\}}}}\\bigr]$ ] . iterating this inequality we arrive at @xmath282 { \\ensuremath{\\leqslant}}\\beta^i w(x)$ ] .",
    "also , by assumption  [ a : further](i ) we have @xmath283 for all @xmath47 such that @xmath284 , which in conjunction with the above inequality gives @xmath285 { \\ensuremath{\\leqslant}}{\\overline}c\\beta^i w(x).\\ ] ] by the monotone convergence theorem and   we have @xmath286 { \\ensuremath{\\leqslant}}\\sum_{i=0}^\\infty \\alpha^i \\mathsf e^\\pi_x\\bigl[c(x_i , a_i){\\ensuremath{\\boldsymbol{1}_{\\{i < \\tau\\}}}}\\bigr]\\\\                  & { \\ensuremath{\\leqslant}}{\\overline}c\\sum_{i=0}^\\infty ( \\alpha\\beta)^i w(x ) { \\ensuremath{\\leqslant}}w(x)\\cdot\\frac{{\\overline}c}{1-\\gamma}.              \\end{aligned}\\ ] ] it follows immediately that @xmath287 .",
    "\\(ii ) by definition , the @xmath88-vi functions @xmath273 satisfy @xmath288 , with @xmath216 .",
    "since @xmath184 is a contraction on @xmath263 by lemma [ l : tcontr ] , it follows that @xmath184 has a unique fixed point , which , by definition is @xmath133 , since @xmath289 by ( i ) .",
    "a standard property of contraction maps implies that @xmath290 with the bound on @xmath291 obtained in ( i ) , we get @xmath292 . since @xmath184 is also a contraction on @xmath263 , @xmath293 , and @xmath212 , the last inequality yields @xmath294 for every @xmath137 .",
    "\\(iii ) of course @xmath133 solves the @xmath88-dcoe  .",
    "uniqueness follows from the facts that the operator @xmath184 in   is a contraction by lemma [ l : tcontr ] , and that the fixed point of a contraction mapping in a banach space ( or more generally , in a complete metric space ) is unique .",
    "note that the conditions in assumption  [ a : further ] are automatic if @xmath103 is bounded .",
    "this gives the following straightforward result .",
    "[ c : tfp ] suppose that assumption [ a : key ] holds , and @xmath295 .",
    "then :    1 .   the @xmath88-discount value function @xmath133 satisfies @xmath296 .",
    "2 .   the @xmath88-vi functions @xmath273 satisfy @xmath297 in particular , @xmath298 .",
    "the optimal value function @xmath133 is the unique function in @xmath263 that solves the @xmath88-dcoe  .",
    "we have seen that the @xmath88-value iteration functions @xmath273 defined in   converge to @xmath133 by lemma  [ l : viconv ] . in this section",
    "we address the question whether the @xmath88-vi policies converge in some sense to a policy @xmath139 as @xmath210 .",
    "[ d : avip ] let @xmath273 be the sequence of @xmath88-vi functions in  , and let @xmath299 be a deterministic markov policy such that @xmath300 is arbitrary , and for @xmath144 , @xmath301 then @xmath302 is called an _ @xmath88-vi policy_.    under assumption  [ a : key ] we get the following basic existential result .",
    "[ p : ado ] suppose that assumption [ a : key ] holds , the action space @xmath5 is locally compact , and let @xmath303 be an @xmath88-vi policy as defined in definition  [ d : avip ] .",
    "then there exists a selector @xmath304 such that for every @xmath137 , @xmath305 is an accumulation point of @xmath306 , and the corresponding deterministic stationary policy @xmath307 is @xmath88-discount optimal .",
    "the proof is based on the following immediate adaptation of ( * ? ? ?",
    "* lemma 4.6.6 ) .",
    "[ l : ado ] let @xmath189 and @xmath308 , @xmath144 , be l.s.c .",
    "functions , bounded below , and inf - compact on @xmath29 .",
    "for every @xmath144 let @xmath309 and @xmath310 , let @xmath311 be a selector such that @xmath312 for all @xmath137 . if @xmath5 is locally compact and @xmath313 , then there exists a selector @xmath304 such that @xmath305 is an accumulation point of the sequence @xmath314 for every @xmath137 , and @xmath315 .    for @xmath129",
    "we define @xmath316 , and @xmath317 since @xmath270 , the functions @xmath308 and @xmath189 are nonnegative .",
    "since @xmath212 by lemma  [ l : viconv ] , the monotone convergence theorem implies that @xmath318 pointwise on @xmath29 .",
    "it is clear that @xmath313 , and the assertion follows at once from lemma  [ l : ado ] .    under the stronger assumption  [ a : further ]",
    "we get quantitative estimates of the rate at which the @xmath88-vi policy defined in definition  [ d : avip ] converges to an optimal one .",
    "the function @xmath319 defined by @xmath320 is called the _ @xmath88-discount discrepancy function_. the @xmath88-vi policy @xmath321 defined in definition  [ d : avip ] is called _ pointwise asymptotically discount optimal _ if for every @xmath137 we have @xmath322 .",
    "it is clear that for @xmath137 and a selector @xmath323 ( see paragraph  [ pgr : convention ] ) , the @xmath88-discount discrepancy function @xmath324 is @xmath8 if and only if @xmath79 is an optimal policy .",
    "the function @xmath325 measures closeness to an optimal selector in a weak sense .",
    "suppose that assumption [ a : further ] holds , and let @xmath274 .",
    "then the @xmath88-vi policy @xmath321 is pointwise asymptotically discount optimal , and for every @xmath137 and @xmath144 , @xmath326    the first inequality follows directly from the definition of @xmath133 . to prove the second inequality fix @xmath137 .",
    "we see that by the definition of the discrepancy function , @xmath327 by proposition  [ p : tfp](ii ) we have @xmath328 and in the light of assumption  [ a : further](ii ) we arrive at @xmath329 the assertion follows immediately after substituting   and   in  .    for bounded costs we have the following straightforward conclusion .",
    "suppose that assumption [ a : key ] holds , and @xmath295 .",
    "then the @xmath88-vi policy @xmath321 is pointwise asymptotically discount optimal , and for every @xmath137 and @xmath144 , @xmath330",
    "as mentioned in  [ s : intro ] , a motivation for this work was to come up with a suitable recovery strategy for mpc .",
    "tracing our development of the mpc methodology in  [ s : intro ] , one sees that in the presence of state and/or action constraints , one seeks a deterministic stationary policy @xmath331 that is active whenever the state is inside the safe set @xmath94 , and a recovery strategy outside @xmath94 .",
    "let us assume that for a given problem we have determined such a policy , and we have also determined a deterministic stationary policy @xmath139 corresponding to the recovery strategy corresponding to a cost - per - stage function defined on @xmath119 for the same problem as described in the preceding sections .",
    "one of the natural questions at this stage is whether one can find estimates of the average cost of recovery . to this end",
    "let us define two constants : @xmath332 where @xmath133 is as defined in .",
    "let @xmath333 be the deterministic stationary policy defined by @xmath334 to wit , @xmath333 consists of concatenation of @xmath139 and @xmath331 between exit and entry times to @xmath94 .",
    "we have the following result :    let @xmath331 be a deterministic stationary policy that is active whenever the state is inside the set @xmath94 , and let @xmath139 be a recovery strategy corresponding to the problem .",
    "let the initial condition @xmath72 be in @xmath119 .",
    "we define the average cost of recovery @xmath335,\\ ] ] where @xmath333 is as defined in , @xmath336 , @xmath337 is the first entry time to @xmath94 , @xmath338 is the first exit time from @xmath94 after @xmath337 , and so on .",
    "suppose that from any initial condition in @xmath119 the first hitting time of @xmath94 is finite almost surely under @xmath139 , and from any initial condition in @xmath94 the first hitting time of @xmath119 is finite almost surely under @xmath331 .",
    "then we have @xmath339 , where @xmath340 are as defined in .",
    "note that an identical bound holds if the initial condition @xmath341 , with an obvious relabelling of the stopping times @xmath342 .",
    "first of all , note that the policy @xmath333 is deterministic stationary , and under this policy the controlled process is stationary markov .",
    "now we have for a fixed @xmath343 : @xmath344 = \\sum_{i=0}^n { \\ensuremath{\\mathsf{e}}}^{{\\widetilde}f^\\infty}_x\\biggl[\\sum_{t=\\tau_{2i}}^{\\tau_{2i+1}-1 } \\alpha^{t-\\tau_{2i } } c(x_t , a_t)\\biggr]\\\\                  & = \\sum_{i=0}^n { \\ensuremath{\\mathsf{e}}}^{{\\widetilde}f^\\infty}_x\\biggl[{\\ensuremath{\\mathsf{e}}}^{f_\\star^\\infty}\\biggl[\\sum_{t=\\tau_{2i}}^{\\tau_{2i+1}-1 } \\alpha^{t-\\tau_{2i } } c(x_t , a_t)\\bigg|{\\ensuremath{\\mathfrak{f}}}_{\\tau_{2i}}\\biggr]\\biggr ] = \\sum_{i=0}^n { \\ensuremath{\\mathsf{e}}}^{{\\widetilde}f^\\infty}_x\\bigl[{\\ensuremath{\\mathsf{e}}}^{f_\\star^\\infty}\\bigl[v^\\star(x_{\\tau_{2i}})\\big|{\\ensuremath{\\mathfrak{f}}}_{\\tau_{2i}}\\bigr]\\bigr ] ,              \\end{aligned}\\ ] ] where the first equality follows from monotone convergence and the last equality from the strong markov property .",
    "appealing to the strong markov property once again we see that @xmath345 = { \\ensuremath{\\mathsf{e}}}^{f_\\star^\\infty}\\bigl[v^\\star(x_{\\tau_{2i}})\\big|x_{\\tau_{2i}}\\bigr]$ ] .",
    "finally , from the definition of @xmath346 it follows that @xmath347 { \\ensuremath{\\leqslant}}\\sup_{\\xi\\in k}\\int_x q({\\ensuremath{\\mathrm{d}}}y|\\xi , f_{\\mathrm{in } } ) v^\\star(y){\\ensuremath{\\boldsymbol{1}_{x{\\ensuremath{\\!\\smallsetminus}}k}}}(y ) = \\beta_2.\\ ] ] it is not difficult to arrive at the lower bound @xmath348{\\ensuremath{\\geqslant}}\\beta_1 $ ] by following the same steps as above . substituting in   and taking limits we arrive at the assertion .",
    "the _ rolling - horizon _ procedure can be briefly described as follows .",
    "fix a horizon @xmath349 and set @xmath350 . then    1 .",
    "we determine an optimal control policy , say @xmath351 , for the @xmath352-period cost function starting from time @xmath207 , given the ( perfectly observed ) initial condition @xmath353 ; standard arguments lead to a realization of this policy as a sequence of @xmath352 selectors @xmath354 ; 2 .",
    "we increase @xmath207 to @xmath355 , and go back to step ( a ) .",
    "accordingly , the @xmath207-th step of this procedure consists of minimizing the stopped @xmath352-period cost function starting at time @xmath207 , namely , the objective is to find a control policy that attains @xmath356          \\end{aligned}\\ ] ] for @xmath137 . by stationarity and markovian nature of the control model ,",
    "it is enough to consider the control problem of minimizing the cost for @xmath350 , i.e. , the problem of minimizing @xmath357 over @xmath89 . the corresponding policy @xmath96 is given by the policy that minimizes the @xmath352-stage @xmath88-vi function @xmath358 in  .",
    "this particular policy is realized as a sequence of @xmath352 selectors @xmath359 .",
    "thus , in the light of the above discussion , the rolling - horizon procedure yields the stationary suboptimal control policy @xmath360 for the original problem  .",
    "let @xmath361 be the value function corresponding to the deterministic stationary policy @xmath362 , @xmath137 .",
    "observe that @xmath363 , which follows from the more general estimate in  .",
    "our objective in this section is to give quantitative estimates of the extent of sub - optimality of the rolling - horizon policy @xmath302 , compared to the optimal policy @xmath364 that attains the infimum in  .",
    "we shall follow the notations of   [ s : contr ] above .",
    "[ t : rh ] suppose that assumption [ a : further ] holds , and let @xmath274 .",
    "for every @xmath365 and @xmath137 we have @xmath366 where @xmath358 is the @xmath352-th @xmath88-vi function defined in  . in particular , @xmath367    a proof of theorem [ t : rh ] is given in the appendix , if follows the arguments in  ( * ? ?",
    "? * theorem  1 ) for finite state - space markov decision processes and bounded costs .",
    "it is of interest to note that the bound in   is identical to the bound between @xmath368 and @xmath369 that appears in proposition  [ p : tfp ] .",
    "if the cost - per - stage function @xmath103 is bounded on @xmath29 , we have the following immediate corollary :    suppose the markov control process satisfies assumption [ a : key ] .",
    "let the cost - per - stage function @xmath370 be bounded , with @xmath371 .",
    "then @xmath372 for every @xmath137 , and @xmath373",
    "in this section we give a numerical example concerning fishery management .",
    "the example is motivated by  ( * ? ? ?",
    "* chapter  7 ) .",
    "the example considers a fishery modeled in discrete - time with the time period representing a fishing season .",
    "the state of the controlled markov chain is the population of the fish species of interest .",
    "fishermen might on the one hand want to harvest all that they can manage in order to increase their short - run profit , but on the other hand this might lead to very low levels of the population .",
    "our goal is to design a recovery strategy for the case that the population gets over - fished and goes below a critical level .    for doing so",
    ", we consider a simple model , with four possible fish population levels , 1 ( almost extinct ) , 2 , 3 , and 4 ( the target set ) .",
    "we assume that we can accurately measure the population size at the beginning of each season @xmath374 , @xmath375 . during a season",
    "the following set of actions are available : harvest ( 1 ) , harvest less ( 2 ) , do nothing ( 3 ) , import fish ( 4 ) , import less ( 5 ) .",
    "we also take as given the following transition probabilities between the markov states , where @xmath376 denotes the probability that the population level at the beginning of the next season will be @xmath75 , given that the current population is @xmath37 and action @xmath9 is applied during this season .",
    "@xmath377    the costs incurred at each state are @xmath378 , where @xmath379 represents a cost incurred for being at the current state and @xmath380 the action cost associated with each action and state .",
    "we assume a discount factor @xmath381 .    using this setting",
    ", one can compute the policy that attains the @xmath88-discount value function  .",
    "this turns out to be to import fish when in state @xmath382 , to import fewer fish in state @xmath383 , and do nothing at state @xmath384 .",
    "next , we search for the optimum policy , while using a rolling horizon control scheme , i.e. , finding the policy that attains  .",
    "we solve the problem for horizon lengths between @xmath385 and @xmath386 , in order to compare the results with the infinite horizon optimal policy .",
    "figure  [ f : cost ] shows the average and the standard - deviation of the accumulated costs over @xmath387 monte carlo runs , with the initial population level at state @xmath385 .",
    "similarly , figure  [ f : time ] shows the average and the standard - deviation of the time steps needed for the recovery into the target state @xmath388 .",
    "the results suggest that for the rolling horizon policy to match the optimal infinite horizon one , a horizon length of at least @xmath389 should be used .",
    "smaller horizons provide sub - optimal policies ( with respect to the infinite horizon one ) , with the sub - optimality gap reducing as the horizon length increases .",
    "note that the case of @xmath390 is not included in the data ; this is because for horizon length of @xmath385 the optimal policy is to harvest while the system is at state @xmath385 , leading to an @xmath391 cost and recovery time , which does not allow the system to ever recover to state @xmath388 .",
    "we established in   [ s : edc ] that the optimal value function @xmath133 is the minimal solution of the @xmath88-discounted cost optimality equation  .",
    "however , obtaining analytical expression of the optimal value function @xmath133 is difficult , particularly due to the integration over a subset @xmath119 of the state space . obtaining good approximations of @xmath133",
    "is of vital importance , and will be reported in subsequent articles .",
    "it is interesting to note that our basic framework of stochastic model - predictive control ( described in   [ s : intro ] ) naturally leads to a partitioning of the state - space with different dynamics in each partition ; thus , the controlled system may be viewed as a stochastic hybrid system .",
    "one of the basic questions in this context is that of stability of the controlled system , and in view of the fact that in general there will be infinitely many excursions of the state outside the safe set , establishing any stability property is a challenging task .",
    "classical lyapunov - based methods are difficult to apply directly precisely because of the infinitely many state - dependent switches between multiple regimes , each with different dynamics . however , excursion - theory of markov processes  @xcite enables us to establish certain stability properties of quite general stochastic hybrid systems with state - dependent switching ; some of these results are reported in  @xcite .",
    "the authors are grateful to vivek s. borkar , onsimo hernndez - lerma , and sean p. meyn for illuminating discussions and pointers to relevant literature .",
    "they also thank the anonymous reviewers for their helpful comments .",
    "for brevity of notation in this proof , we let @xmath360 , and let @xmath392 denote the ( ordered ) elements of the policy @xmath302 from stage @xmath37 through @xmath75 for @xmath393 .",
    "the first inequality in   is trivial because @xmath394 for all @xmath137 . before the proof of the second inequality in  ,",
    "let us fix some notation .",
    "pick @xmath365 . for @xmath395 , a policy @xmath396 for stages",
    "@xmath207 through @xmath397 , and @xmath398 , let @xmath399 denote @xmath37-th element of the policy @xmath396 .",
    "also , let @xmath400 denote the sub - stochastic kernel is a _ sub - stochastic kernel _ on @xmath119 given @xmath15 if @xmath19 is a measurable function on @xmath15 for each @xmath20 , and @xmath17 is a measure on @xmath12 with @xmath401 for each @xmath18 . ] defined for @xmath137 by @xmath402 for @xmath403 .",
    "let @xmath351 be an optimal policy for stages @xmath207 through @xmath397 , i.e. , let @xmath351 attain the infimum in  .",
    "fix @xmath137 .",
    "let @xmath404 be an @xmath352-period policy starting from stage @xmath355 , such that its first @xmath405 elements are identical to the last @xmath405 elements of @xmath351 , i.e. , @xmath406 for @xmath407 .",
    "by optimality of @xmath351 we have @xmath408\\\\                  { \\ensuremath{\\geqslant}}\\mathsf e^{\\pi^\\star_{n+1:n+n+1}}_x\\!\\left[\\sum_{i = n+1}^{n+n+1 } \\alpha^i c(x_i , a_i){\\ensuremath{\\boldsymbol{1}_{\\{i < \\tau\\}}}}\\left.\\vphantom{\\sum_{i = n+1}^{n+n+1}}\\right|x_{(n+1){\\ensuremath{\\wedge}}(\\tau-1)}\\right ] .",
    "\\end{gathered}\\ ] ] since @xmath409 by construction , conditional on @xmath410 , @xmath411{\\ensuremath{\\geqslant}}\\\\                  \\int_{x{\\ensuremath{\\!\\smallsetminus}}k}q\\bigl({\\ensuremath{\\mathrm{d}}}y\\big|x ' , { \\widehat}\\pi_{n : n+n}(n)\\bigr)\\mathsf e^{\\pi^\\star_{n+1:n+n+1}}_x\\!\\left[\\sum_{i = n+1}^{n+n+1 } \\alpha^i c(x_i , a_i){\\ensuremath{\\boldsymbol{1}_{\\{i < \\tau\\}}}}\\left.\\vphantom{\\sum_{i = n+1}^{n+n+1}}\\right|x_{(n+1){\\ensuremath{\\wedge}}(\\tau-1 ) } = y\\right ] .              \\end{gathered}\\ ] ] by definition of @xmath412 we have @xmath413\\\\                  & = \\mathsf e^{\\zeta_{n+1:n+n+1}}\\!\\left[\\sum_{i = n+1}^{n+n } \\alpha^i c(x_i , a_i){\\ensuremath{\\boldsymbol{1}_{\\{i < \\tau\\}}}}\\left.\\vphantom{\\sum_{i = n+1}^{n+n+1}}\\right|x_{(n+1){\\ensuremath{\\wedge}}(\\tau-1)}\\right ] \\\\                  & \\qquad+ \\mathsf e^{\\zeta_{n+1:n+n+1}}\\!\\left[\\alpha^{n+n+1 } c(x_{n+n+1 } , a_{n+n+1}){\\ensuremath{\\boldsymbol{1}_{\\{n+n+1 < \\tau\\}}}}\\big|x_{(n+1){\\ensuremath{\\wedge}}(\\tau-1)}\\right ] ,              \\end{aligned}\\ ] ] and the right - hand side equals @xmath414 \\\\",
    "+ \\mathsf e^{\\zeta_{n+1:n+n+1}}\\!\\left[\\alpha^{n+n+1 } c(x_{n+n+1 } , a_{n+n+1}){\\ensuremath{\\boldsymbol{1}_{\\{n+n+1 < \\tau\\}}}}\\big|x_{(n+1){\\ensuremath{\\wedge}}(\\tau-1)}\\right ] .",
    "\\end{gathered}\\ ] ] in conjunction with   and conditional on @xmath410 , we have @xmath415\\\\                      + \\int_{x{\\ensuremath{\\!\\smallsetminus}}k } q\\bigl({\\ensuremath{\\mathrm{d}}}y\\big|x ' , \\pi^\\star_{n : n+n}(n)\\bigr)\\mathsf e^{\\zeta_{n+1:n+n+1}}\\bigl[\\alpha^{n+n+1 } c(x_{n+n+1 } , a_{n+n+1}){\\ensuremath{\\boldsymbol{1}_{\\{n+n+1 < \\tau\\}}}}\\big|x_{(n+1){\\ensuremath{\\wedge}}(\\tau-1)}=y\\bigr]\\\\                      { \\ensuremath{\\geqslant}}\\int_{x{\\ensuremath{\\!\\smallsetminus}}k } q\\bigl({\\ensuremath{\\mathrm{d}}}y\\big|x ' , { \\widehat}\\pi_{n : n+n}(n)\\bigr)\\mathsf e^{\\pi^\\star_{n+1:n+n+1}}\\!\\left[\\sum_{i = n+1}^{n+n+1}\\alpha^i c(x_i , a_i){\\ensuremath{\\boldsymbol{1}_{\\{i < \\tau\\}}}}\\left.\\vphantom{\\sum_i^n}\\right|x_{(n+1){\\ensuremath{\\wedge}}(\\tau-1)}=y\\right ] .              \\end{gathered}\\ ] ] to wit , conditional on @xmath410 , @xmath416 - \\mathsf e^{\\pi^\\star_{n : n+n}}\\!\\left[\\alpha^n c(x_n , a_n){\\ensuremath{\\boldsymbol{1}_{\\{i < \\tau\\}}}}\\big|x_{n{\\ensuremath{\\wedge}}(\\tau-1 ) } = x'\\right]\\\\                      + \\alpha^{n+n+1 } \\int_{x{\\ensuremath{\\!\\smallsetminus}}k } \\!\\!q\\bigl({\\ensuremath{\\mathrm{d}}}y\\big|x ' , \\pi^\\star_{n : n+n}(n)\\bigr)\\mathsf e^{\\zeta_{n+1:n+n+1}}\\bigl[c(x_{n+n+1 } , a_{n+n+1}){\\ensuremath{\\boldsymbol{1}_{\\{n+n+1 < \\tau\\}}}}\\big|x_{(n+1){\\ensuremath{\\wedge}}(\\tau-1)}=y\\bigr]\\\\                      { \\ensuremath{\\geqslant}}\\int_{x{\\ensuremath{\\!\\smallsetminus}}k } q\\bigl({\\ensuremath{\\mathrm{d}}}y\\big|x ' , { \\widehat}\\pi_{n : n+n}(n)\\bigr)\\mathsf e^{\\pi^\\star_{n+1:n+n+1}}\\!\\left[\\sum_{i = n+1}^{n+n+1}\\alpha^i c(x_i , a_i){\\ensuremath{\\boldsymbol{1}_{\\{i < \\tau\\}}}}\\left.\\vphantom{\\sum_i^n}\\right|x_{(n+1){\\ensuremath{\\wedge}}(\\tau-1)}=y\\right ] .              \\end{gathered}\\ ] ] let @xmath417 be a selector that attains the minimal value of @xmath418\\ ] ] whenever @xmath419 , and let the corresponding minimal value be denoted by @xmath420 ; clearly @xmath421 is well - defined on @xmath119 , and is a measurable function of @xmath422 . with this notation ,",
    "the last inequality becomes @xmath423 - \\mathsf e^{\\pi^\\star_{n : n+n}}\\bigl[\\alpha^n c(x_n , a_n){\\ensuremath{\\boldsymbol{1}_{\\{n < \\tau\\}}}}\\big|x_{n{\\ensuremath{\\wedge}}(\\tau-1 ) } = x'\\bigr]\\\\                  + e_n(x ' ) { \\ensuremath{\\geqslant}}\\int_{x{\\ensuremath{\\!\\smallsetminus}}k } q\\bigl({\\ensuremath{\\mathrm{d}}}y\\big|x ' , { \\widehat}\\pi_{n : n+n}(n)\\bigr ) \\mathsf e^{\\pi^\\star_{n+1:n+n+1}}\\!\\left[\\sum_{i = n+1}^{n+n+1}\\alpha^i c(x_i , a_i){\\ensuremath{\\boldsymbol{1}_{\\{i < \\tau\\}}}}\\left.\\vphantom{\\sum_i^n}\\right|x_{(n+1){\\ensuremath{\\wedge}}(\\tau-1)}=y\\right ]              \\end{gathered}\\ ] ] whenever @xmath419 .",
    "therefore , @xmath424\\\\                      - \\int_{x{\\ensuremath{\\!\\smallsetminus}}k}q\\bigl({\\ensuremath{\\mathrm{d}}}y\\big|x , { \\widehat}\\pi_{0:n-1}\\bigr ) \\mathsf e^{\\pi^\\star_{n : n+n}}\\bigl[\\alpha^n c(x_n , a_n){\\ensuremath{\\boldsymbol{1}_{\\{n < \\tau\\}}}}\\big|x_{n{\\ensuremath{\\wedge}}(\\tau-1)}\\bigr ] + \\int_{x{\\ensuremath{\\!\\smallsetminus}}k}q\\bigl({\\ensuremath{\\mathrm{d}}}y\\big|x , { \\widehat}\\pi_{0:n-1}\\bigr ) e_n(y)\\\\                      { \\ensuremath{\\geqslant}}\\int_{x{\\ensuremath{\\!\\smallsetminus}}k}q\\bigl({\\ensuremath{\\mathrm{d}}}y\\big|x , { \\widehat}\\pi_{0:n}\\bigr ) \\mathsf e^{\\pi^\\star_{n+1:n+n+1}}\\!\\left[\\sum_{i = n+1}^{n+n+1}\\alpha^i c(x_i , a_i){\\ensuremath{\\boldsymbol{1}_{\\{i < \\tau\\}}}}\\left.\\vphantom{\\sum_i^n}\\right|x_{(n+1){\\ensuremath{\\wedge}}(\\tau-1)}=y\\right ] .",
    "\\end{gathered}\\ ] ] rearranging and summing over @xmath207 we arrive at @xmath425\\\\                  { \\ensuremath{\\leqslant}}\\sum_{n=0}^\\infty\\left(\\alpha^n\\int_{x{\\ensuremath{\\!\\smallsetminus}}k}q\\bigl({\\ensuremath{\\mathrm{d}}}y\\big|x , { \\widehat}\\pi_{0:n-1}\\bigr)\\mathsf e^{\\pi^\\star_{n :",
    "n+n}}\\!\\left[\\sum_{i = n}^{n+n}\\alpha^{i - n } c(x_i , a_i){\\ensuremath{\\boldsymbol{1}_{\\{i < \\tau\\}}}}\\left.\\vphantom{\\sum_i^n}\\right| x_{n{\\ensuremath{\\wedge}}(\\tau-1)}=y\\right]\\right.\\\\                  - \\left.\\alpha^{n+1}\\int_{x{\\ensuremath{\\!\\smallsetminus}}k } q\\bigl({\\ensuremath{\\mathrm{d}}}y\\big|x , { \\widehat}\\pi_{0:n}\\bigr)\\mathsf e^{\\pi^\\star_{n+1:n+n+1}}\\!\\left[\\sum_{i = n+1}^{n+n+1}\\alpha^{i - n-1 } c(x_i , a_i){\\ensuremath{\\boldsymbol{1}_{\\{i < \\tau\\}}}}\\left.\\vphantom{\\sum_i^n}\\right| x_{(n+1){\\ensuremath{\\wedge}}(\\tau-1)}=y\\right]\\right)\\\\                  + \\sum_{n=0}^\\infty \\int_{x{\\ensuremath{\\!\\smallsetminus}}k } q\\bigl({\\ensuremath{\\mathrm{d}}}y\\big|x , { \\widehat}\\pi_{0:n-1}\\bigr ) e_n(y ) .              \\end{gathered}\\ ] ] in   we have employed the notation @xmath426 for any policy @xmath96 .",
    "we observe that the left - hand side of   is just @xmath427 $ ] . by assumption  [ a : further](i ) , @xmath428 { \\ensuremath{\\leqslant}}{\\overline}c\\mathsf e^{\\pi^\\star_{n :",
    "n+n}}\\!\\left[\\sum_{i = n}^{n+n}\\alpha^{i - n } w(x_i){\\ensuremath{\\boldsymbol{1}_{\\{i < \\tau\\}}}}\\left.\\vphantom{\\sum_i^n}\\right| x_{n{\\ensuremath{\\wedge}}(\\tau-1)}=y\\right],\\ ] ] and by assumption  [ a : further](ii ) , @xmath429 { \\ensuremath{\\leqslant}}w(y)\\sum_{i = n}^{n+n}\\gamma^{i - n}.\\ ] ] we notice that since @xmath270 , the first series on the right - hand side of   is at most @xmath430 for a fixed @xmath395 , the quantity @xmath431 is at most @xmath432 in view of assumption  [ a : further](ii ) and the definition of the stochastic kernel @xmath433 at the beginning of this proof",
    ". therefore , @xmath434 this shows that series in   is summable .",
    "hence , cancellations of the telescopic terms in the first series on the right - hand side of   are justified .",
    "the inequality in   now simplifies to @xmath435 { \\ensuremath{\\leqslant}}\\mathsf e^{\\pi^\\star_{0:n}}_x\\!\\left[\\sum_{i=0}^{(n+1){\\ensuremath{\\wedge}}(\\tau-1)}\\!\\!\\alpha^{i } c(x_i , a_i)\\right ] + \\sum_{n=0}^\\infty \\int_{x{\\ensuremath{\\!\\smallsetminus}}k } q\\bigl({\\ensuremath{\\mathrm{d}}}y\\big|x , { \\widehat}\\pi_{0:n-1}\\bigr ) e_n(y ) .",
    "\\end{gathered}\\ ] ] by assumption  [ a : further](ii ) and the definition of @xmath421 , conditional on @xmath436 , @xmath437\\\\                  & { \\ensuremath{\\leqslant}}{\\overline}c w(x')\\alpha^n \\gamma^{n+1}.              \\end{aligned}\\ ] ] substituting the last inequality in   we arrive at @xmath438 { \\ensuremath{\\leqslant}}\\mathsf e^{\\pi^\\star_{0:n}}_x\\!\\left[\\sum_{i=0}^{(n+1){\\ensuremath{\\wedge}}(\\tau-1)}\\!\\!\\alpha^{i } c(x_i , a_i)\\right ] + \\frac{{\\overline}c\\gamma^{n+1}}{1-\\gamma}w(x),\\ ] ] which is the second bound in  .",
    "the inequality   follows immediately from the fact that @xmath439 for every @xmath144 ."
  ],
  "abstract_text": [
    "<S> we present a dynamic programming - based solution to a stochastic optimal control problem up to a hitting time for a discrete - time markov control process . </S>",
    "<S> first we determine an optimal control policy to steer the process toward a compact target set while simultaneously minimizing an expected discounted cost . </S>",
    "<S> we then provide a rolling - horizon strategy for approximating the optimal policy , together with quantitative characterization of its sub - optimality with respect to the optimal policy . </S>",
    "<S> finally we address related issues of asymptotic discount - optimality of the value - iteration policy . </S>"
  ]
}